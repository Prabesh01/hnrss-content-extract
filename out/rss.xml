<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 27 Sep 2025 07:32:09 +0000</lastBuildDate><item><title>Translating a Fortran F-16 Simulator to Unity3D</title><link>https://vazgriz.com/762/f-16-flight-sim-in-unity-3d/</link><description>&lt;doc fingerprint="3633da10e06c133a"&gt;
  &lt;main&gt;&lt;p&gt;I recently purchased the textbook ‚ÄúAircraft Control and Simulation‚Äù by Brian L. Stevens, Frank L. Lewis, and Eric N. Johnson1. This book covers the control and simulation of aircraft. It‚Äôs really dense and frankly hard to understand. As far as aerodynamics texts go, it‚Äôs pretty typical.&lt;/p&gt;&lt;p&gt;One interesting item in the appendices of the book is the source code for the simulation of an F-16. It has a flight model, based on scale model wind tunnel data. The flight model consists of a dozen lookup tables and the math equations to make it fly.&lt;/p&gt;&lt;p&gt;The only problem: it‚Äôs written entirely in Fortran.&lt;/p&gt;&lt;p&gt;The source code is available on Github.&lt;/p&gt;&lt;p&gt;You can play the finished project right now on itch.io&lt;/p&gt;&lt;p&gt;Or watch the demo on Youtube:&lt;/p&gt;&lt;p&gt;While I am a professional software engineer and I have worked in the aerospace industry, that doesn‚Äôt mean that I understand what I‚Äôm doing.&lt;/p&gt;&lt;p&gt;Table of Contents&lt;/p&gt;&lt;head rend="h1"&gt;Introduction&lt;/head&gt;&lt;p&gt;In previous posts on this blog2 3 4, I covered the development of a flight simulator based on the lift equation and hand-tuned parameters. This gives the game designer direct control over a lot of flight parameters. For example, you can directly choose the turn rate and the G-limit of the aircraft, allowing the designer to easily tune the corner speed. This works well for game development, since the designer, and ultimately the player, care more about these high-level parameters.&lt;/p&gt;&lt;p&gt;But real aircraft are designed from the other direction, starting from low-level parameters such as the size, shape, and position of airfoils. Engineers tune every aspect of the aircraft in order to reach those high-level behaviors. But every design decision has trade offs and reaching the goal for one parameter means compromising another. An airliner is designed very differently from a fighter jet because of this.&lt;/p&gt;&lt;p&gt;Simulating all of the low-level parameters is difficult. It‚Äôs possible to simulate air flow over the vehicle using computational fluid dynamics (CFD), but this kind of software is difficult to write and even more difficult to verify.&lt;/p&gt;&lt;p&gt;The F-16 flight model from the textbook does not simulate the low-level parameters, but it also doesn‚Äôt simulate the high-level parameters either. It sits somewhere in between, so it serves as a useful stepping stone from my previous projects. This project will explore more advanced flight dynamics and explain the limitations of the old flight model as well as the new one.&lt;/p&gt;&lt;head rend="h1"&gt;Aerospace Conventions&lt;/head&gt;&lt;head rend="h2"&gt;Coordinate System&lt;/head&gt;&lt;p&gt;Before we can write any code, we need to understand the conventions used for mathematically modeling aircraft that are used in the aerospace industry. The textbook uses aerospace conventions and to use them in this project, we must convert them to Unity conventions.&lt;/p&gt;&lt;p&gt;The first convention is the coordinate system axes. If you‚Äôve ever visited a graphics programming forum, you might have seen people arguing over how the X, Y, and Z axes should be arranged in their game. Especially whether to use a right handed or left handed, and Y-up or Z-up coordinate system.&lt;/p&gt;&lt;p&gt;This chart by Freya Holmer5 shows the axis choices made by a variety of 3D software tools.&lt;/p&gt;&lt;p&gt;The aerospace industry takes a different path. The most common coordinate system for aircraft is right handed, X forward, Y right, and Z down. This is completely different from every tool shown above. The textbook defines all of it‚Äôs math using this convention.&lt;/p&gt;&lt;p&gt;Luckily, translating between two coordinate systems is easy. You just swap the components around and then add or remove minus signs until it all works. Every calculation made by the textbook‚Äôs code can be easily translated into Unity‚Äôs coordinate system and vice versa.&lt;/p&gt;&lt;p&gt;Writing functions to do this is simple:&lt;/p&gt;&lt;quote&gt;public static Vector3 ConvertVectorToAerospace(Vector3 vector) { return new Vector3(vector.z, vector.x, -vector.y); } public static Vector3 ConvertVectorToUnity(Vector3 vector) { return new Vector3(vector.y, -vector.z, vector.x); }&lt;/quote&gt;&lt;p&gt;When translating euler angles, torque, or other angular values, one additional negation is needed:&lt;/p&gt;&lt;quote&gt;public static Vector3 ConvertAngleToAerospace(Vector3 angle) { // negate when switching handedness return -ConvertVectorToAerospace(angle); } public static Vector3 ConvertAngleToUnity(Vector3 angle) { // negate when switching handedness return -ConvertVectorToUnity(angle); }&lt;/quote&gt;&lt;head rend="h2"&gt;Units&lt;/head&gt;&lt;p&gt;For completely inscrutable reasons, American aerospace texts (and the industry!) insist on using US customary units for everything. All math is defined with these units. Distance is measured in feet. Mass is measured in slugs.&lt;/p&gt;&lt;p&gt;What the hell is a slug? A slug is the unit of mass in the US system. This is the equivalent unit of the kilogram in the metric system. Remember that weight and mass are not the same thing.&lt;/p&gt;\(1 \, \text{kg} * 9.81 \, \text{m/s}^2 = 9.81 \, \text{N}\) \(1 \, \text{slug} * 32.17 \, \text{ft/s}^2 = 32.17 \, \text{lb}\)&lt;p&gt;Mass is the measure of how much an object resists linear force. Moment of inertia is how much the object resists rotational force or torque. The unit for moment of inertia in metric is kg-m2. Thus, the equivalent unit in customary is slug-ft2.&lt;/p&gt;&lt;p&gt;You want to measure how much air mass is in a given volume? That‚Äôs gonna be slugs/ft3.&lt;/p&gt;&lt;p&gt;Speed is mostly measured in feet per second, unless you want to know the speed of the aircraft. Then you use knots, which means nautical miles per hour. Importantly, a nautical mile is not the same as a regular mile. A regular mile is 5,280 feet. A nautical mile is ~6,076 feet or exactly 1,852 meters (???).&lt;/p&gt;&lt;p&gt;Do you want to know how fast your ship is sailing? Just throw out this piece of wood tied to a spool of rope. The rope has knots tied at regular intervals. Count the number of knots that unspool in a given time frame. That‚Äôs how many knots your ship is making.&lt;/p&gt;&lt;p&gt;Finally, temperature is measured in degrees Rankine. You know how the Kelvin scale is just the Celsius scale adjusted so that 0 Kelvin equals absolute zero? Well Rankine is the same concept applied to Fahrenheit.&lt;/p&gt;\(0 \, \text{R} = \text{absolute zero} \\ 534 \, \text{R} = 75 \, \text{F} = \text{room temperature}\)&lt;p&gt;How the fuck did we ever build the SR-71? üíÄ&lt;/p&gt;&lt;p&gt;Unity by convention uses metric for all physics units. The flight model in the textbook uses US customary units, so every input and output of this system has to be converted. So we have to add functions to handle converting to and from US customary units. This is easy enough since conversion is just a multiplication or division operation.&lt;/p&gt;&lt;head rend="h2"&gt;Terminology&lt;/head&gt;&lt;p&gt;There are several terms used in aerospace that I need to define. I have used equivalent terms in the previous project, but I will clarify them here.&lt;/p&gt;&lt;p&gt;Alpha (Œ±) refers to the angle of attack.&lt;/p&gt;&lt;p&gt;Beta (Œ≤) refers to the angle of side slip.&lt;/p&gt;&lt;p&gt;Longitudinal axis is the X-axis, from tail to nose.&lt;/p&gt;&lt;p&gt;Normal axis is the Z- axis, the vertical axis pointing downwards.&lt;/p&gt;&lt;p&gt;Lateral axis is the Y-axis, or side axis, pointing right.&lt;/p&gt;&lt;p&gt;Phi (œÜ) is the aircraft‚Äôs roll around the X axis.&lt;/p&gt;&lt;p&gt;Theta (Œ∏) is the aircraft‚Äôs pitch around the Y axis.&lt;/p&gt;&lt;p&gt;Psi (œà) is the aircraft‚Äôs yaw around the Z axis.&lt;/p&gt;&lt;p&gt;P, Q, and R refer to the angular velocity around the X, Y, and Z axes respectively.&lt;/p&gt;&lt;p&gt;In general you will find that aerodynamics texts are allergic to good variable names. I suspect this is a form of gatekeeping. Or perhaps the authors have to pay by the letter to publish.&lt;/p&gt;&lt;head rend="h1"&gt;Air Data&lt;/head&gt;&lt;p&gt;Airplanes need air to fly [citation needed]. Every behavior of a plane is determined by the movement of air. Therefore it is critically important, for real and simulated planes, to be able to measure the air flowing around it.&lt;/p&gt;&lt;p&gt;Real planes need to measure static and dynamic air pressure to determine how fast the plane is moving. Static pressure is measured by a static pressure port. It‚Äôs the pressure that you would measure if you just lifted a pressure meter to the same altitude as the plane. Static pressure decreases with altitude.&lt;/p&gt;&lt;p&gt;Dynamic pressure measures the pressure added by the plane‚Äôs forward motion. This requires a pitot tube to measure. As the plane moves forward it rams air into the pitot tube and increases the pressure above the static pressure. The pitot measures the total pressure of the air. By subtracting the static pressure, we can obtain the dynamic pressure.&lt;/p&gt;&lt;p&gt;The static and dynamic pressures can then be used to calculate many of the variables the pilot needs to fly. Most important are the airspeed and altitude of the aircraft. Specifically, these values can be used to calculate the indicated airspeed of the aircraft. Indicated airspeed is calculated directly from the dynamic pressure.&lt;/p&gt;&lt;p&gt;At most subsonic speeds, the dynamic pressure of air flowing over the wings is the most important variable in flight. A plane‚Äôs performance can be defined in terms of indicated airspeed. For example, a plane may have a stall speed of 100 knots indicated airspeed. This means that no matter what altitude the plane is at, the indicated airspeed will be 100 when the plane stalls.&lt;/p&gt;&lt;p&gt;This is important since it gives a consistent number for the stall speed regardless of atmospheric conditions. The pressure and density of the air can vary based on weather, temperature, and other factors. So the true airspeed when a stall occurs can be very inconsistent. But as long as the pilot knows the indicated airspeed, they know how their plane will behave.&lt;/p&gt;&lt;p&gt;For this simulator, the calculation has to work backwards. We know the true airspeed and altitude of the plane from the velocity and position of the rigidbody. From that, we can calculate the dynamic pressure. This dynamic pressure is then used for later calculations in the flight model. Additionally, the plane‚Äôs speed in mach is calculated here as well.&lt;/p&gt;&lt;p&gt;The original Fortran source code is given:&lt;/p&gt;&lt;quote&gt;SUBROUTINE ADC(VT,ALT,AMACH,QBAR) DATA R0/2.377E-3/ TFAC = 1.0 - 0.703E-5 * ALT T = 519.0 * TFAC IF (ALT .GE. 35000.0) T= 390.0 RHO = R0 * (TFAC**4.14) AMACH= VT/SQRT(1.4*1716.3*T) QBAR = 0.5*RHO*VT*VT C PS = 1715.0 * RHO * T RETURN END&lt;/quote&gt;&lt;p&gt;It turns out, Fortran is actually pretty good at translating formulas. So this code is not as difficult to read as I expected.&lt;/p&gt;&lt;p&gt;To translate this to Unity, we create a class AirDataComputer to perform these calculations. The output of the calculation is the AirData struct.&lt;/p&gt;&lt;quote&gt;public struct AirData { public float altitudeMach; public float qBar; } public class AirDataComputer { /// &amp;lt;summary&amp;gt; /// Density in slugs/ft^3 /// &amp;lt;/summary&amp;gt; public const float SeaLevelDensity = 2.377e-3f; public const float MaxAltitude = 35000.0f; /// &amp;lt;summary&amp;gt; /// Calculates air data based on velocity and altitude /// &amp;lt;/summary&amp;gt; /// &amp;lt;param name="velocity"&amp;gt;Velocity in ft/s&amp;lt;/param&amp;gt; /// &amp;lt;param name="altitude"&amp;gt;Altitude in ft&amp;lt;/param&amp;gt; /// &amp;lt;returns&amp;gt;Air data&amp;lt;/returns&amp;gt; public AirData CalculateAirData(float velocity, float altitude) { ... } }&lt;/quote&gt;&lt;p&gt;Here we can see where the US customary units are used. The density of air at sea level is defined in slugs/ft3. The altitude is defined in feet. Theoretically, these values could be defined using metric. But the implementation of the function depends on even more values defined in customary.&lt;/p&gt;&lt;quote&gt;const float baseTemperature = 519.0f; // sea level temp in R const float minTemperature = 390.0f; // minimum temp in R const float temperatureGradient = 0.703e-5f; // gradient in R / ft altitude = Mathf.Clamp(altitude, 0, MaxAltitude); // calculate temperature in Rankine float temperatureFactor = 1.0f - (temperatureGradient * altitude); float T = Mathf.Max(minTemperature, baseTemperature * temperatureFactor);&lt;/quote&gt;&lt;p&gt;These calculations simulate the change in atmospheric conditions at different altitudes. Particularly important is how the temperature drops at higher altitudes. The temperature gradient approximates the decreases in temperature (in Rankine) as altitude increases.&lt;/p&gt;&lt;p&gt;This flight model supports altitudes up to 35,000 ft. Altitudes above this are not supported. At any altitude above this, the plane will behave as if it were at 35,000 ft. This is because the temperatures at this altitude no longer consistently decrease, as it does in the lower atmosphere. A more advanced atmosphere model would need to be used.&lt;/p&gt;&lt;p&gt;Temperature factor does not drop below about 0.75 in this range, so the resulting temperature T does not fall below 390 R.&lt;/p&gt;&lt;quote&gt;const float gamma = 1.4f; // ratio of specific heats const float gasConstant = 1716.3f; float speedOfSound = Mathf.Sqrt(gamma * gasConstant * T); float altitudeMach = velocity / speedOfSound;&lt;/quote&gt;&lt;p&gt;Now we can calculate the speed of sound at the plane‚Äôs current altitude and use it to find the plane‚Äôs Mach number. The speed of sound varies with density, which varies with temperature. The speed of sound is equal to the square root of the ratio of specific heat, called gamma, times the gas constant, gasConstant, times the absolute temperature, T.7&lt;/p&gt;&lt;p&gt;Once the speed of sound is known, calculating the Mach number is just a simple division.&lt;/p&gt;&lt;quote&gt;const float densityPower = 4.14f; float rho = SeaLevelDensity * Mathf.Pow(temperatureFactor, densityPower); float qBar = 0.5f * rho * velocity * velocity;&lt;/quote&gt;&lt;p&gt;And finally the dynamic pressure is calculated from the temperature factor. I‚Äôll admit, I don‚Äôt understand why exactly the formula is designed this way. It seems to calculate a density factor, called rho, based solely on the temperature factor, raised to an arbitrary value, densityPower.&lt;/p&gt;&lt;p&gt;The NASA reference provides a similar formula using metric units and using a different arbitrary power. I guess this value is just what results from using customaryü§∑‚ôÇÔ∏è&lt;/p&gt;&lt;p&gt;In any case, this gives us the two air data values we need for the rest of the simulation, dynamic pressure and mach number.&lt;/p&gt;&lt;head rend="h1"&gt;Table Interpolation&lt;/head&gt;&lt;p&gt;Throughout this flight model, various forms of table lookups are used to determine the aircraft‚Äôs behavior. Lookup tables are commonly used in flight simulators to represent complex curves and functions. In fact, Unity‚Äôs AnimationCurve class in the previous project is used to define a few lookup tables, such as lift coefficient.&lt;/p&gt;&lt;p&gt;This animation curve serves as a 1 dimensional lookup table. The input dimension is AOA and the output value is lift coefficient.&lt;/p&gt;&lt;p&gt;Fortran code doesn‚Äôt have the luxury of using AnimationCurves, but a simple table of values with an interpolation function is almost as powerful.&lt;/p&gt;&lt;head rend="h2"&gt;1D Lookup Table&lt;/head&gt;&lt;p&gt;The interpolation functions provided by the textbook look something like this:&lt;/p&gt;&lt;quote&gt;FUNCTION LOOKUP(ALPHA, RESULT) REAL A(-2:9) C DATA A / .770,.241,-.100,-.416,-.731,-1.053, &amp;amp; -1.366,-1.646,-1.917,-2.120,-2.248,-2.229 / C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) RESULT = A(K) + ABS(DA)*(A(L)-A(K)) RETURN END&lt;/quote&gt;&lt;p&gt;This function takes alpha (AOA) and uses it to lookup a value from the table. Alpha is a float that can have any value from [-10, 45]. The table ‚ÄúA‚Äù represents values for every 5 degree increment of alpha. Note that Fortran supports arrays with an arbitrary starting index, in this case -2. So this table supports indices in the range [-2, 9].&lt;/p&gt;&lt;p&gt;This first step is multiplying alpha by a scaling value to create a float S, which maps alpha to the range [-2, 9]. An integer index K is created from S and then clamped to values one less than the table‚Äôs index range. The value DA is calculated as the difference between S and K.&lt;/p&gt;&lt;p&gt;The value L is calculated to be one index away from K, in the same direction as S. So now we have two indices to the table, K and L, which we use to read two values from the table, A(K) and A(L). DA is then used to blend between these table values and produce the final result.&lt;/p&gt;&lt;p&gt;This has two effects. The first is the simplest to understand. If alpha falls within the input range of the table, L and K are selected as the closest table values. For example, if alpha is 12, the two indices would be 2 and 3. The difference between S and K would be less than 1. The values A(2) and A(3) can be read from the table and then interpolated based on the value of DA. This is a fairly normal interpolation calculation.&lt;/p&gt;&lt;p&gt;The other effect is what happens when alpha is outside of the input range of the table. K is guaranteed to not be the first or last index, and L is allowed to be one index off of K. L and K are still valid indices, but the value of DA may be larger than 1. This means when we interpolate between A(L) and A(K), we can extrapolate values for inputs beyond the range of the table.&lt;/p&gt;&lt;p&gt;This means our lookup table can handle values outside of it‚Äôs input range. But there is still a limitation. As the input value gets further away from the input range, the extrapolated values will become more and more unrealistic. This allows our plane to fly slightly outside the flight envelope of the lookup tables.&lt;/p&gt;&lt;p&gt;I translated this function into C# like this:&lt;/p&gt;&lt;quote&gt;public static float ReadTable(float[] table, int i, int start) { return table[i - start]; } public static (int k0, int k1, float t) GetLookUpIndex(float value, float scale, int min, int max) { float scaled = value * scale; int K0 = Mathf.Clamp((int)scaled, min, max); float T = scaled - K0; int K1 = K0 + (int)Mathf.Sign(T); return (K0, K1, T); } public static float LinearLookup(float value, float scale, float[] table, int min, int max) { (int k0, int k1, float kT) = GetLookUpIndex(value, scale, min + 1, max - 1); float T = ReadTable(table, k0, min); float U = ReadTable(table, k1, min); float result = T + Math.Abs(kT) * (U - T); return result; }&lt;/quote&gt;&lt;p&gt;GetLookUpIndex calculates K, L, and DA. These variables are renamed to k0, k1, and kT respectively.&lt;/p&gt;&lt;p&gt;ReadTable is a function that maps array indices to a new range, to support arbitrary starting indices like Fortran. (C# surprisingly supports this feature natively, but who actually uses that?)&lt;/p&gt;&lt;p&gt;LinearLookup reads the k0 and k1 values from the array and performs the interpolation. This allows us to calculate values for any input to the lookup table.&lt;/p&gt;&lt;p&gt;Note that the expression ‚ÄúT + Math.Abs(kT) * (U ‚Äì T)‚Äù is effectively equivalent to Mathf.LerpUnclamped.&lt;/p&gt;&lt;head rend="h2"&gt;2D Lookup Table&lt;/head&gt;&lt;p&gt;All of the above code is needed to perform a one dimensional table lookup. Performing this kind of table lookup with two input dimensions is called a bilinear interpolation. Extending this to two dimensions is not that much more complicated.&lt;/p&gt;&lt;p&gt;The two input values to the table form a two dimensional space. Our input values form a two dimensional point. Instead of selecting two array indices K and L, we need to select four array indices. These four indices form a box around our input point. We simply perform 2 one dimensional lookups, and then interpolate between them to produce the final value.&lt;/p&gt;&lt;p&gt;The 2 one dimensional lookups are marked in red. The final interpolation is marked in blue.&lt;/p&gt;&lt;p&gt;Implementing this in C# is a simple extension of the LinearLookup function:&lt;/p&gt;&lt;quote&gt;public static float BilinearLookup(float xValue, float xScale, float yValue, float yScale, float[,] table, int xMin, int xMax, int yMin, int yMax) { (int x0, int x1, float xT) = GetLookUpIndex(xValue, xScale, xMin + 1, xMax - 1); (int y0, int y1, float yT) = GetLookUpIndex(yValue, yScale, yMin + 1, yMax - 1); float T = ReadTable(table, x0, y0, xMin, yMin); float U = ReadTable(table, x0, y1, xMin, yMin); float V = T + Math.Abs(xT) * (ReadTable(table, x1, y0, xMin, yMin) - T); float W = U + Math.Abs(xT) * (ReadTable(table, x1, y1, xMin, yMin) - U); float result = V + (W - V) * Math.Abs(yT); return result; }&lt;/quote&gt;&lt;p&gt;A bilinear interpolation is a very common operation in computer graphics. This is how textures are sampled when placed on 3D geometry.&lt;/p&gt;&lt;p&gt;In the next section, we will see that the engine thrust calculation interpolates between the output of 2 two dimensional tables. Adding this third interpolation means this calculation is now a trilinear interpolation. Interpolating between two tables is how mipmaps are blended together in computer graphics. How neat is that?&lt;/p&gt;&lt;head rend="h1"&gt;Engine&lt;/head&gt;&lt;p&gt;The next system we‚Äôre going to add is the engine. In my previous project, the engine was dead simple. The player selected a throttle value from [0, 1], which is multiplied by the plane‚Äôs total thrust. This works fine for that simulation and even gives us the ability to reduce thrust to zero, so the plane becomes a glider.&lt;/p&gt;&lt;p&gt;However, it is not a realistic simulation of how a jet engine works. In reality, a jet engine still produces some thrust at idle throttle. And there are more factors that affect thrust output than just the throttle setting.&lt;/p&gt;&lt;p&gt;The thrust output of a jet engine decreases with altitude and increases with speed. As altitude increases, the air gets thinner and the jet engine becomes weaker. But as speed increases, dynamic pressure, and thus pressure in the engine, increases and the engine becomes stronger. These two effects need to be considered at the same time to find the thrust output at any given moment.&lt;/p&gt;&lt;p&gt;Additionally, we have to consider how jet engines behave in terms of RPM. Just like piston engines (like in a typical car), jet engines have rotating components whose speed increases with throttle. The max RPM of a jet is much higher than a piston engine, however the range of possible RPM is smaller.&lt;/p&gt;&lt;p&gt;The engine in an F-16 has a maximum RPM of about 14,000. This is at the maximum non-afterburner power, called military power. When throttle is reduced to the lowest setting, idle, the RPM falls to about 8,400 RPM or about 60% of the max. Planes of course do not have a transmission like a car does, so this range of RPM also covers the range of thrust needed at all stages of flight.&lt;/p&gt;&lt;p&gt;At idle throttle, the engine runs at 60% max RPM, but only produces 8% of max thrust. At military power, the engine runs at 100% RPM and produces 100% thrust.&lt;/p&gt;&lt;p&gt;Military power is selected when the pilot moves the throttle lever to 77% of it‚Äôs max setting. Pushing the throttle beyond that engages the afterburner and produces even more thrust. Setting the throttle lever to 100% is called max power. Max power provides about 57% more thrust than military power. Engine RPM does not increase when using afterburner.&lt;/p&gt;&lt;p&gt;A significant difference between a piston engine and a jet engine is how fast the engine can change RPM. In a car, you can put the transmission in neutral and rev the engine up and down very quickly. But a jet engine is much slower to respond to changes in throttle, regardless of how fast the pilot moves the throttle lever. Generally, it can take several seconds to go from idle to military power or vice versa.&lt;/p&gt;&lt;p&gt;The reasons why jet engines are slower to change RPM are complicated. The change in throttle is managed by a computer to avoid compressor stall, which can cause damage or shut down of the engine. This computer will change engine parameters slowly to avoid compressor stall or any other problems that might be caused by moving the throttle too quickly.&lt;/p&gt;&lt;head rend="h2"&gt;Power&lt;/head&gt;&lt;p&gt;The behavior of the jet engine is included in the textbook‚Äôs flight model. RPM is not explicitly modeled, but is abstracted as power. The pilot chooses a commanded power level and the engine‚Äôs current power setting will move towards this over time. This behavior is spring-like, thus a larger difference will cause the current power setting to change faster. It takes about 2 seconds to increase from idle to military power in this flight model.&lt;/p&gt;&lt;p&gt;The first step is to translate the player‚Äôs throttle setting into engine power. This is a fairly simple function that maps military power, or 77% throttle, to 50% power. Full afterburner, or 100%, is mapped to 100% power. This is called the ‚Äúthrottle gearing‚Äù, but don‚Äôt confuse that with a car‚Äôs gearing. It‚Äôs much simpler.&lt;/p&gt;&lt;quote&gt;FUNCTION TGEAR(THTL) ! Power command v. thtl. relationship IF(THTL.LE.0.77) THEN TGEAR = 64.94*THTL ELSE TGEAR = 217.38*THTL-117.38 END IF RETURN END&lt;/quote&gt;&lt;p&gt;In C#, this is translated as:&lt;/p&gt;&lt;quote&gt;public static float CalculateThrottleGear(float throttle) { // maps throttle 0 - 0.77 to power 0% - 50% // maps throttle 0.77 - 1.0 to power 50% - 100% float power; if (throttle &amp;lt;= militaryPowerThrottle) { power = 64.94f * throttle; } else { power = 217.38f * throttle - 117.38f; } return power; }&lt;/quote&gt;&lt;p&gt;Those constants might seem weird, but they just define two lines with different slopes. The two lines intersect when the throttle is 0.77.&lt;/p&gt;&lt;p&gt;The player‚Äôs throttle setting is used to calculate the commanded power level. The rate of change of engine power also depends on the current power level. This rate is calculated in the functions PDOT and RTAU:&lt;/p&gt;&lt;quote&gt;FUNCTION PDOT(P3,P1) ! PDOT= rate of change of power IF (P1.GE.50.0) THEN ! P3= actual power, P1= power command IF (P3.GE.50.0) THEN T=5.0 P2=P1 ELSE P2=60.0 T=RTAU(P2-P3) END IF ELSE IF (P3.GE.50.0) THEN T=5.0 P2=40.0 ELSE P2=P1 T=RTAU(P2-P3) END IF END IF PDOT=T*(P2-P3) RETURN END FUNCTION RTAU(DP) ! used by function PDOT IF (DP.LE.25.0) THEN RTAU=1.0 ! reciprocal time constant ELSE IF (DP.GE.50.0)THEN RTAU=0.1 ELSE RTAU=1.9-.036*DP END IF RETURN END&lt;/quote&gt;&lt;p&gt;PDOT means power rate of change. In C#, this is translated as:&lt;/p&gt;&lt;quote&gt;float CalculatePowerRateOfChange(float actualPower, float commandPower) { // calculates how fast power output should change based on commanded power float T; float p2; if (commandPower &amp;gt;= 50.0) { if (actualPower &amp;gt;= 50.0) { T = 5.0f; p2 = commandPower; } else { p2 = 60.0f; T = CalculateRTau(p2 - actualPower); } } else { if (actualPower &amp;gt;= 50.0) { T = 5.0f; p2 = 40.0f; } else { p2 = commandPower; T = CalculateRTau(p2 - actualPower); } } float pdot = T * (p2 - actualPower); return pdot; } float CalculateRTau(float deltaPower) { float rTau; if (dp &amp;lt;= 25.0) { rTau = 1.0f; } else if (dp &amp;gt;= 50.0) { rTau = 0.1f; } else { rTau = 1.9f - 0.036f * dp; } return rTau; }&lt;/quote&gt;&lt;p&gt;Power rate of change is the velocity of the power level. The most important line is this:&lt;/p&gt;&lt;quote&gt;float pdot = T * (p2 - actualPower);&lt;/quote&gt;&lt;p&gt;The velocity depends on the quantity (p2 ‚Äì actualPower). Let‚Äôs call this value deltaPower. A larger deltaPower means a larger velocity. This is scaled by the factor T. The complexity comes from selecting the values for p2 and T. p2 is sometimes the commandPower value. T is sometimes the result of calling CalculateRTau.&lt;/p&gt;&lt;p&gt;These values are selected by the if statements above. These check for two conditions, the commandedPower being above 50%, and the actualPower being above 50%. This is checking whether the afterburner is being requested, and whether the afterburner is currently active. Remember that afterburner starts at 77% throttle, but 50% power.&lt;/p&gt;&lt;p&gt;If the afterburner is not active, then the T is given the value of CalculateRTau. If it is active, then T is given the constant value of 5.0. This matches with our expectation of how the engine‚Äôs RPM changes. When not in afterburner, the engine RPM should change slowly, thus power changes slowly. When in afterburner, fuel flow into the afterburner can change quickly, thus power changes quickly.&lt;/p&gt;&lt;p&gt;If we look at the function CalculateRTau, we can see that T can vary in the range [0.1, 1.0]. This depends on deltaPower. When the engine is not in afterburner, T can be at most 1.0. In afterburner, T is 5.0. That means power can change about 5 times faster when in afterburner. When multiplied with deltaPower, pdot can be as large as 250% per second.&lt;/p&gt;&lt;p&gt;The smallest value of T occurs when deltaPower is 50 or greater. This occurs when actualPower is 0 and commanded power is 50%, for example. This will cause the power rate of change to be quite small at only 6% per second. Note that this is simply the instantaneous rate of change. As the actual power rises, T will become larger and the rate of change will increase.&lt;/p&gt;&lt;p&gt;Now the reason why p2 is used instead of commandedPower is to handle the case where commandedPower is over 50% and actualPower is below 50%, or vice versa. The pilot is requesting afterburner, but the engine has not reached military power yet. In that case, deltaPower would become very large and the simulation would change power levels too quickly. To avoid this, an arbitrary constant is chosen that is on the opposite side of 50%, but not very far.&lt;/p&gt;&lt;p&gt;So if the actualPower is 0%, but commandedPower is 100%, p2 is set to the value of 60. This limits deltaPower to a maximum value of 60, instead of 100. And in the case where actualPower is 100% and commandedPower is 0%, deltaPower is limited to -60.&lt;/p&gt;&lt;p&gt;Another behavior of this code is that CalculateRTau does not handle cases where deltaPower is negative. In this case, the function returns 1, the highest value it can return. This means that the power can decrease 10 times faster than it can increase, in the most extreme case.&lt;/p&gt;&lt;p&gt;I don‚Äôt know if this is an intentional effect. This may match the behavior of real jet engines, or it may be an oversight by the authors. You can play with the behavior by adding a few calls to Mathf.Abs().&lt;/p&gt;&lt;p&gt;The practical effect of all this is that the plane‚Äôs power will lag behind the player‚Äôs throttle setting. The pilot needs to make sure that they provide enough time for the power level to change when moving the throttle.&lt;/p&gt;&lt;p&gt;The HUD for this project is mostly reused from the previous flight sim project. But the throttle indicator must be updated, since it can‚Äôt show the difference between commanded power and current power.&lt;/p&gt;&lt;p&gt;Previously, the red bar used to show the player‚Äôs throttle setting. This worked fine since power lag was not modeled. In this project, the red bar shows the engine‚Äôs current power level. I added a triangle marker to show the commanded power setting.&lt;/p&gt;&lt;p&gt;As you move the throttle, you‚Äôll see that current power level changes quickly when there is a large difference from commanded power, and it slows down as it approaches. And when the engine enters afterburner, the power level changes very quickly.&lt;/p&gt;&lt;head rend="h2"&gt;Thrust&lt;/head&gt;&lt;p&gt;Engine power is a fairly abstract variable in this flight model. It doesn‚Äôt really correspond to any physical variable. Once we calculate the current power, we use it to find the thrust generated by the engine. Thrust in this flight model is defined in terms of pounds-force (lbf).&lt;/p&gt;&lt;p&gt;Thrust is defined by a group of look up tables. Each table has two dimensions as input, mach number and altitude, and the output is thrust. This gives us different thrust values in different flight conditions. Mach is input as 0.0 to 1.0 mach, in increments of 0.2 mach. Altitude is input as 0 to 50,000 ft, in increments of 10,000 ft. In other words, the table has dimensions 6√ó6.&lt;/p&gt;&lt;p&gt;The lookup tables in this flight model correspond to idle power, military power, and max power (full afterburner). The engine‚Äôs power value is used to perform a third interpolation between the output values of these tables. This makes the thrust calculation a trilinear interpolation.&lt;/p&gt;&lt;p&gt;At idle throttle, the thrust output has 100% influence from the idle table. When the throttle is halfway to military power, the output has 50% influence from the idle table and 50% influence from the military table. Above military power, the output will have some influence from the military power table and the max power table.&lt;/p&gt;&lt;p&gt;The code to read one table in Fortran is given:&lt;/p&gt;&lt;quote&gt;DATA A/ [IDLE TABLE OMITTED] DATA B/ [MIL TABLE OMITTED] DATA C/ [MAX TABLE OMITTED] H=0.0001*ALT I=INT(H) IF (I.GE.5) I=4 DH=H-FLOAT(I) RM=5.*RMACH M=INT(RM) IF (M.GE.5) M=4 DM=RM-FLOAT(M) CDH=1.0-DH&lt;/quote&gt;&lt;p&gt;These parameters are used to perform the table lookups:&lt;/p&gt;&lt;quote&gt;TMIL= S + (T-S)*DM IF (POW.LT.50.0) THEN S= A(I,M)*CDH + A(I+1,M)*DH T= A(I,M+1)*CDH + A(I+1,M+1)*DH TIDL= S + (T-S)*DM THRUST= TIDL + (TMIL-TIDL)*POW/50.0 ELSE S= C(I,M)*CDH + C(I+1,M)*DH T= C(I,M+1)*CDH + C(I+1,M+1)*DH TMAX= S + (T-S)*DM THRUST= TMIL + (TMAX-TMIL)*(POW-50.0)*0.02 END IF&lt;/quote&gt;&lt;p&gt;The output of the military power table, TMIL, is always calculated. If the power level is under 50, then the idle table is calculated as well, TIDL. Otherwise the max table is calculated, TMAX. The output of the two table lookups is then interpolated again to calculate the final thrust value, THRUST.&lt;/p&gt;&lt;p&gt;Altogether, this forms a trilinear lookup. To translate this to C#, we call BilinearLookup twice. Then those two results are interpolated based on the power level:&lt;/p&gt;&lt;quote&gt;float InterpolateThrust(float thrust1, float thrust2, float power) { float result = Mathf.LerpUnclamped(thrust1, thrust2, power * 0.02f); return result; } float CalculateThrust(float power, float altitude, float rMach) { float a = Mathf.Max(0, altitude); float m = Mathf.Max(0, rMach); float thrust; float thrustMilitary = Table.BilinearLookup(a, 0.0001f, m, 5, militaryPowerTable, 0, 6, 0, 6); // perform trilinear interpolation if (power &amp;lt; 50.0) { float thrustIdle = Table.BilinearLookup(a, 0.0001f, m, 5, idlePowerTable, 0, 6, 0, 6); thrust = InterpolateThrust(thrustIdle, thrustMilitary, power); } else { float thrustMax = Table.BilinearLookup(a, 0.0001f, m, 5, maxPowerTable, 0, 6, 0, 6); thrust = InterpolateThrust(thrustMilitary, thrustMax, power - 50.0f); } return thrust; }&lt;/quote&gt;&lt;p&gt;The output of this calculation is the plane‚Äôs thrust in pounds-force. A simple unit conversion allows us to apply it in newtons to a Unity rigidbody:&lt;/p&gt;&lt;quote&gt;void UpdateThrust(float dt) { engine.ThrottleCommand = Throttle; engine.Mach = Mach; engine.Altitude = AltitudeFeet; engine.Update(dt); Rigidbody.AddRelativeForce(new Vector3(0, 0, engine.Thrust * poundsForceToNewtons)); }&lt;/quote&gt;&lt;head rend="h1"&gt;Forces&lt;/head&gt;&lt;head rend="h2"&gt;Lift force vs Normal force&lt;/head&gt;&lt;p&gt;In the previous flight sim project, we calculated a plane‚Äôs lift force using the angle of attack and an AnimationCurve. This is the very core of the flight simulator and is what enables flight. The flight model from the textbook does not calculate lift force.&lt;/p&gt;&lt;p&gt;Instead what this flight model calculates is normal force. Recall that lift force is perpendicular to the aircraft‚Äôs velocity vector. Normal force is perpendicular to the aircraft‚Äôs nose. This distinction is subtle at a low angle of attack, but it becomes significant at a high angle of attack.&lt;/p&gt;&lt;p&gt;There are two more analogous forces to consider, drag and axial force. Drag is always exactly opposite to the aircraft‚Äôs velocity vector while axial force is opposite the aircraft‚Äôs nose. Lift and drag are perpendicular to each other and form one set of forces. Normal and axial form another perpendicular set. It‚Äôs important to understand that these two sets of forces are equally valid. In fact, they are simply the consequence of choosing different basis vectors for measuring force.&lt;/p&gt;&lt;p&gt;And of course there is the side force that points to the right. These forces are applied on the normal, side, and longitudinal (axial) axes, which are equivalent to the X, Y, and Z axes.&lt;/p&gt;&lt;p&gt;Imagine all of the forces being produced by the aircraft are summed into a single force vector. This vector would be strongly vertical, because the plane is generating enough lift to support it‚Äôs own weight, and somewhat backwards because of drag. When this vector is projected onto the lift vector, the result is the lift force. When it‚Äôs projected onto the normal vector, the result is the normal force.&lt;/p&gt;&lt;p&gt;Choosing to represent these forces as lift/drag or normal/axial is arbitrary. The textbook flight model only deals with normal/axial force. I suspect that‚Äôs because it‚Äôs easier to measure the physical forces when using normal/axial forces in a wind tunnel, since those are always aligned with the plane‚Äôs local axes.&lt;/p&gt;&lt;p&gt;The normal force is very similar to lift for low angles of attack. Lift force peaks at the stall AOA and then declines. Normal force similarly peaks at stall AOA, but it then increases again to peak at 90 AOA, with an even higher force. 90 degrees AOA means the plane is falling downwards belly first, so it‚Äôs no longer producing lift over the wings. Instead the normal vector and the drag vector are now aligned. All of the drag force projected onto the normal vector results in a large normal force.&lt;/p&gt;&lt;p&gt;We can calculate the lift force from the normal and axial force. Both normal and axial force may contribute to the lift force, so a complete projection needs to use both. This is the formula:&lt;/p&gt;\(\text{Lift} = \text{normal} * \cos{(\text{alpha})} ‚Äì \text{axial} * \sin{(\text{alpha})}\)&lt;p&gt;When we apply this formula to the normal force from the textbook, this is the result:&lt;/p&gt;&lt;p&gt;Oh wait, that‚Äôs upside down. Recall that the Z axis points downward in this coordinate system. So a negative Z value is an upwards force. Still though, the chart is a little confusing. I inverted the values below to make it more intuitive.&lt;/p&gt;&lt;p&gt;We can see at 90 degrees AOA, the normal force stays relatively high while the lift force drops to zero. This roughly matches with the chart from aerospaceweb.org above.&lt;/p&gt;&lt;p&gt;Also note that the textbook only provides table values up to 45 degrees AOA. The extrapolation of the table lookup function is what allows us to have normal force values up to 90 degrees AOA. Additionally, the table only goes down to -10 degrees AOA. We can extrapolate further, but the data will be inaccurate by -30 degrees AOA. Large negative AOA values will quickly become inaccurate. So when you‚Äôre flying, don‚Äôt do that.&lt;/p&gt;&lt;p&gt;Anyways, adding these forces to our simulator is easy. The functions are fairly simple. They are called CZ, CY, and CX. These calculate the coefficients of force on the Z, Y, and X axes respectively. Note that these functions are the coefficients, not the force values themselves. They are used to calculate the force later on.&lt;/p&gt;&lt;p&gt;CZ or the normal coefficient is calculated like this:&lt;/p&gt;&lt;quote&gt;FUNCTION CZ(ALPHA,BETA,EL) REAL A(-2:9) C DATA A/ [TABLE OMITTED] C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = A(K) + ABS(DA)*(A(L)-A(K)) CZ = S*(1-(BETA/57.3)**2) - .19*(EL/25.0) C RETURN END&lt;/quote&gt;&lt;p&gt;The bulk of this code is just the table interpolation function. The table only depends on ALPHA and the output is S. The only new part here is the last line, where CZ is assigned a value. S is reduced based on the value of BETA and another term is subtracted based on EL, the elevator angle.&lt;/p&gt;&lt;p&gt;This is very easy to translate to C#:&lt;/p&gt;&lt;quote&gt;float GetZAxisForceCoefficient(float alpha, float beta, float elevator) { float S = Table.LinearLookup(alpha, 0.2f, zAxisTable, -2, 10); float CZ = S * (1 - Mathf.Pow(beta * Mathf.Deg2Rad, 2)) - 0.19f * (elevator / 25.0f); return CZ; }&lt;/quote&gt;&lt;p&gt;CY or the side coefficient is even simpler. It doesn‚Äôt even have a lookup table. Side force is perpendicular to both normal and axial force.&lt;/p&gt;&lt;quote&gt;FUNCTION CY(BETA,AIL,RDR) CY = -.02*BETA + .021*(AIL/20.0) + .086*(RDR/30.0) C RETURN END&lt;/quote&gt;&lt;p&gt;Side coefficient depends solely on beta, aileron angle, and rudder angle.&lt;/p&gt;&lt;p&gt;In C#:&lt;/p&gt;&lt;quote&gt;float GetYAxisForceCoefficient(float beta, float aileron, float rudder) { float CY = -0.02f * beta + 0.021f * (aileron / 20.0f) + 0.086f * (rudder / 30.0f); return CY; }&lt;/quote&gt;&lt;p&gt;CX or the axial coefficient is basically what creates drag on the aircraft. This function is a little more complicated since it performs a bilinear interpolation, with alpha and elevator angle as the inputs.&lt;/p&gt;&lt;quote&gt;FUNCTION CX(ALPHA,EL) REAL A(-2:9,-2:2) C DATA A/ [TABLE OMITTED] C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = EL/12.0 M = INT(S) IF(M.LE.-2) M=-1 IF(M.GE.2) M=1 DE = S - FLOAT(M) N = M + INT(SIGN(1.1,DE)) V = A(K,M) + ABS(DA)*(A(L,M)-A(K,M)) W = A(K,N) + ABS(DA)*(A(L,N)-A(K,N)) CX = V + (W-V)*ABS(DE) C RETURN END&lt;/quote&gt;&lt;p&gt;Thanks to the table lookup functions, this is easy to translate to C#:&lt;/p&gt;&lt;quote&gt;float GetXAxisForceCoefficient(float alpha, float elevator) { float result = Table.BilinearLookup(alpha, 0.2f, elevator, 1f / 12f, xAxisTable, -2, 9, -2, 2); return result; }&lt;/quote&gt;&lt;p&gt;These three functions define all of the linear force coefficients applied to the aircraft during flight. None of these will rotate the aircraft. That is handled by a different and more complicated set of calculations.&lt;/p&gt;&lt;head rend="h1"&gt;Moments&lt;/head&gt;&lt;p&gt;Moment is another word for torque. (There is a subtle difference, but who cares?ü§ì) The F-16 flight model uses another set of look up tables to compute the moment for the aircraft.&lt;/p&gt;&lt;p&gt;In the previous flight sim, torque was not actually calculated. Instead, the flight model calculates the angular acceleration directly. This ignores the mass of the plane when applying the torque. This is a simplification. A more realistic flight model would take into account the mass of the aircraft when applying torque.&lt;/p&gt;&lt;p&gt;Note that mass is not sufficient to model rotations. When it comes to rotation, the analogy to mass is called moment of inertia. Just like mass is the property that measures an object‚Äôs resistance to force, moment of inertia is the resistance to torque. But unlike mass, moment of inertia can differ on all 3 axes. This means a torque on the X axis will result in a different angular acceleration than the same torque on the Y axis, for example.&lt;/p&gt;&lt;p&gt;Moment of inertia is a four-dimensional value, called AXX, AYY, AZZ, and AXZ in the textbook code. This flight model contains it‚Äôs own calculations for angular velocity using these moment of inertia values.&lt;/p&gt;&lt;p&gt;The flight model contains several functions that calculate the moment of the aircraft. The three basic functions are called CM, CL, and CN. These calculate the moments around the Y, X, and Z axes, AKA pitch, roll, and yaw, respectively. (L stands for longitudinal, which is the X axis. N stands for normal, which is the Z axis. M stands for‚Ä¶ something)&lt;/p&gt;&lt;p&gt;These functions are all simple look up tables. CM (pitch) uses alpha and elevator angle as the input. CL (roll) and CN (yaw) use alpha and beta as the input. CM is basically the same as the other lookup table functions. CL and CN are similar to each other since they both use a symmetric table. This is because the plane is symmetric on the lateral axis, so a single table can represent the left and right sides. Their final output is then multiplied by the sign of beta.&lt;/p&gt;&lt;quote&gt;FUNCTION CL(ALPHA,BETA) REAL A(-2:9,0:6) DATA A/ [DATA OMITTED] S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = .2*ABS(BETA) M = INT(S) IF(M.EQ.0) M=1 IF(M.GE.6) M=5 DB = S - FLOAT(M) N = M + INT(SIGN(1.1,DB)) T = A(K,M) U = A(K,N) V = T + ABS(DA)*(A(L,M) - T) W = U + ABS(DA)*(A(L,N) - U) DUM = V + (W - V) * ABS(DB) CL = DUM + SIGN(1.0,BETA) RETURN END&lt;/quote&gt;&lt;p&gt;Note that there is an error in the textbook code. The final operation ‚ÄúCL = DUM + SIGN(‚Ä¶)‚Äù should use multiplication instead of addition. Otherwise this operation doesn‚Äôt make any sense.&lt;/p&gt;&lt;p&gt;When translated into C#:&lt;/p&gt;&lt;quote&gt;float GetYAxisMoment(float alpha, float elevator) { float result = Table.BilinearLookup(alpha, 0.2f, elevator, 1f / 12f, yMomentTable, -2, 9, -2, 2); return result; } float GetXAxisMoment(float alpha, float beta) { float DUM = Table.BilinearLookup(alpha, 0.2f, Mathf.Abs(beta), 0.2f, xMomentTable, -2, 9, 0, 7); float CL = DUM * Mathf.Sign(beta); return CL; } float GetZAxisMoment(float alpha, float beta) { float DUM = Table.BilinearLookup(alpha, 0.2f, Mathf.Abs(beta), 0.2f, zMomentTable, -2, 9, 0, 7); float CL = DUM * Mathf.Sign(beta); return CL; }&lt;/quote&gt;&lt;p&gt;Notice that CM takes ‚Äúelevator‚Äù as an argument, so this is where the elevator‚Äôs turning effect is calculated. But CL and CN do not take any control surface as an argument. These functions only apply moment based on alpha and beta. For example, at high angles of sideslip, the plane tends to roll. On real planes, this is caused by wing sweep. In this flight model, it‚Äôs caused by the CL function.&lt;/p&gt;&lt;p&gt;Elevators are applied in CM, but rudder and ailerons are not. Those are actually handled by four more functions, called DLDA, DLDR, DNDA, and DNDR. The names are cryptic, but it just means which axis is affected from which control surface.&lt;/p&gt;&lt;p&gt;The ‚ÄúL‚Äù stands for longitudinal, so DLDA is the longitudinal moment from the ailerons, A. DLDR is the longitudinal moment from the rudder, R. The ‚ÄúN‚Äù stands for normal, so those functions are the normal axis moment from aileron and rudders.&lt;/p&gt;&lt;p&gt;These four functions are eventually summed with the CL and CN functions above. These functions mean that roll is affected by aileron and rudder, and yaw is affected by aileron and rudder.&lt;/p&gt;&lt;head rend="h2"&gt;Damping&lt;/head&gt;&lt;p&gt;There is one more set of coefficients that must be calculated. These are the damping coefficients and they depend solely on alpha. These values are stored in 9 distinct 1D lookup tables. The code for these lookups is the same as the other lookup code.&lt;/p&gt;&lt;p&gt;These values are stored in an array of length 9 called D.&lt;/p&gt;&lt;p&gt;Damping is the moment that opposes the angular velocity of an aircraft, essentially angular drag. They affect the other moment values in somewhat complex ways. For example, some of them are combined with the plane‚Äôs current bank value to affect the roll moment.&lt;/p&gt;&lt;p&gt;What isn‚Äôt clear is what the damping values actually represent. In the C# code, I added these comments explaining their meaning:&lt;/p&gt;&lt;quote&gt;// D[0] = CXq // D[1] = CYr // D[2] = CYp // D[3] = CZq // D[4] = Clr // D[5] = Clp // D[6] = Cmq // D[7] = Cnr // D[8] = Cnp&lt;/quote&gt;&lt;p&gt;Hope this helps!&lt;/p&gt;&lt;p&gt;The best I can tell is that ‚ÄúCXq‚Äù is the damping moment on the X axis relative to q, which is the angular velocity around the Y axis. The other damping values follow this naming scheme.&lt;/p&gt;&lt;p&gt;This is yet another example of aerodynamics texts with poor variable names.&lt;/p&gt;&lt;head rend="h1"&gt;Complete Flight Model&lt;/head&gt;&lt;p&gt;With all of the individual coefficients defined, we can now implement the complete flight model for the F-16. This flight model actually contains it‚Äôs own physics integrator. The text provides it‚Äôs own code for calculating velocity and angular velocity from the aerodynamic forces.&lt;/p&gt;&lt;p&gt;Strictly speaking, we don‚Äôt need to use this code since Unity allows us to provide those same forces and then performs the physics calculation for us. Setting the mass is easy enough, we just have to convert slugs to kilograms. The textbook code calculates acceleration by dividing the force by the aircraft mass. We simply omit this division, convert the forces to newtons, and apply it to the rigidbody.&lt;/p&gt;&lt;p&gt;However the moment of inertia is more complicated. The textbook provides the 4 dimensional MOI values, but Unity expects a 3 dimensional inertia tensor. That inertia tensor is then rotated by a quaternion called ‚ÄúinertiaTensorRotation‚Äù. I have no idea how to calculate this quaternion from the textbook‚Äôs provided value.&lt;/p&gt;&lt;p&gt;Therefore, we continue to use the textbook‚Äôs code for applying moment and simply apply the resulting angular acceleration to the rigidbody.&lt;/p&gt;&lt;p&gt;The Fortran code for the flight model is concise, yet scrutable. The first step is to read the plane‚Äôs current state from the input state vector X. This is simply an array that contains all of the relevant data for this frame.&lt;/p&gt;&lt;quote&gt;VT= X(1); ALPHA= X(2)*RTOD; BETA= X(3)*RTOD PHI=X(4); THETA= X(5); PSI= X(6) P= X(7); Q= X(8); R= X(9); ALT= X(12); POW= X(13)&lt;/quote&gt;&lt;p&gt;VT is the plane‚Äôs velocity in feet per second.&lt;/p&gt;&lt;p&gt;ALPHA and BETA are the plane‚Äôs AOA and AOS in degrees. RTOD is the constant to convert from radians to degrees.&lt;/p&gt;&lt;p&gt;PHI, THETA, and PSI are the plane‚Äôs roll, pitch, and yaw in radians.&lt;/p&gt;&lt;p&gt;P, Q, and R are the plane‚Äôs angular velocities (or roll rate, pitch rate, and yaw rate) in radians per second.&lt;/p&gt;&lt;p&gt;ALT is the altitude in feet.&lt;/p&gt;&lt;p&gt;POW is the current power level of the engine (0 ‚Äì 100).&lt;/p&gt;&lt;p&gt;The air data computer (ADC) and engine model are then called using these variables:&lt;/p&gt;&lt;quote&gt;CALL ADC(VT,ALT,AMACH,QBAR); CPOW= TGEAR(THTL) XD(13) = PDOT(POW,CPOW); T= THRUST(POW,ALT,AMACH)&lt;/quote&gt;&lt;p&gt;The ADC function populates the variables AMACH and QBAR, which are the altitude mach and dynamic pressure.&lt;/p&gt;&lt;p&gt;CPOW is the pilot‚Äôs commanded power setting. That is, the power level returned by calling the throttle gear function, TGEAR, on the throttle lever position, THTL.&lt;/p&gt;&lt;p&gt;The array XD is the output state vector. Specifically, it holds the calculated derivative for every input value. XD(13) is set to the value calculated by PDOT, which is the velocity of the power level.&lt;/p&gt;&lt;p&gt;T is the thrust in pounds-force output by the engine, calculated using the power level, altitude, and altitude mach.&lt;/p&gt;&lt;p&gt;Then the aerodynamic coefficients are calculated using the force and moment functions:&lt;/p&gt;&lt;quote&gt;CXT = CX (ALPHA,EL) CYT = CY (BETA,AIL,RDR) CZT = CZ (ALPHA,BETA,EL) DAIL= AIL/20.0; DRDR= RDR/30.0 CLT = CL(ALPHA,BETA) + DLDA(ALPHA,BETA)*DAIL &amp;amp; + DLDR(ALPHA,BETA)*DRDR CMT = CM(ALPHA,EL) CNT = CN(ALPHA,BETA) + DNDA(ALPHA,BETA)*DAIL &amp;amp; + DNDR(ALPHA,BETA)*DRDR&lt;/quote&gt;&lt;p&gt;The values CXT, CYT, and CZT are the coefficients on the X, Y, and Z axes, calculated by calling their respective coefficient functions.&lt;/p&gt;&lt;p&gt;EL, AIL, and RDR are the current position of the elevators, ailerons, and rudder in degrees. DAIL and DRDR are simply the angle of these surfaces divided by the max angle. Their range is [-1, 1].&lt;/p&gt;&lt;p&gt;The values CLT, CMT, and CNT are the moment coefficients on the longitudinal, m‚Äôlateral, and normal axes. Note that CM calculates moment caused by the elevator position. The effects of the other control surfaces are calculated in the DLDA, DLDR, DNDA, and DNDR functions.&lt;/p&gt;&lt;p&gt;Then some other values are calculated and the damping coefficients are added to the above values:&lt;/p&gt;&lt;quote&gt;TVT= 0.5/VT; B2V= B*TVT; CQ= CBAR*Q*TVT CALL DAMP(ALPHA,D) CXT= CXT + CQ * D(1) CYT= CYT + B2V * ( D(2)*R + D(3)*P ) CZT= CZT + CQ * D(4) CLT= CLT + B2V * ( D(5)*R + D(6)*P ) CMT= CMT + CQ * D(7) + CZT * (XCGR-XCG) CNT= CNT + B2V*(D(8)*R + D(9)*P) - CYT*(XCGR-XCG) * CBAR/B&lt;/quote&gt;&lt;p&gt;I‚Äôll be honest, I straight up don‚Äôt know what any of these values are or why they are being applied like this. The effect appears to be angular damping (AKA angular drag) which opposes the plane‚Äôs angular velocity.&lt;/p&gt;&lt;p&gt;The value (XCGR ‚Äì XCG) is the center of gravity reference minus the current center of gravity. This allows us to alter the center of gravity of the aircraft and see how that affects stability.&lt;/p&gt;&lt;p&gt;XCGR is 0.35 for this flight model. XCG is 0.35 by default. XCG is the normalized position of the center of gravity, with a possible range of [0, 1]. This means that when XCG is 0.35, the term (XCGR ‚Äì XCG) becomes zero and the aircraft is balanced around it‚Äôs center of gravity.&lt;/p&gt;&lt;p&gt;The center of gravity term affects CMT and CNT, which are the pitch and yaw axes. The roll axis is not affected.&lt;/p&gt;&lt;p&gt;The next block of code is fun:&lt;/p&gt;&lt;quote&gt;CBTA = COS(X(3)); U=VT*COS(X(2))*CBTA V= VT * SIN(X(3)); W=VT*SIN(X(2))*CBTA STH = SIN(THETA); CTH= COS(THETA); SPH= SIN(PHI) CPH = COS(PHI) ; SPSI= SIN(PSI); CPSI= COS(PSI) QS = QBAR * S ; QSB= QS * B; RMQS= QS/MASS GCTH = GD * CTH ; QSPH= Q * SPH AY = RMQS*CYT ; AZ= RMQS * CZT&lt;/quote&gt;&lt;p&gt;This writhing mass of arithmetic is simply pre-calculating a lot of the values that are used to calculate the aerodynamic forces. Some of these values are used in multiple places, so to avoid repeating them, they are pulled out of those equations and placed here.&lt;/p&gt;&lt;p&gt;This is essentially the ‚Äúcommon subexpression‚Äù optimization pass of a compiler, but applied manually.&lt;/p&gt;&lt;p&gt;The important variables are U, V, and W, which is the plane‚Äôs velocity on the X, Y, and Z axes respectively.&lt;/p&gt;&lt;p&gt;QS is QBAR (dynamic pressure) times S (wing area).&lt;/p&gt;&lt;p&gt;Now the aerodynamic forces are calculated:&lt;/p&gt;&lt;quote&gt;UDOT = R*V - Q*W - GD*STH + (QS * CXT + T)/MASS VDOT = P*W - R*U + GCTH * SPH + AY WDOT = Q*U - P*V + GCTH * CPH + AZ DUM = (U*U + W*W) xd(1) = (U*UDOT + V*VDOT + W*WDOT)/VT xd(2) = (U*WDOT - W*UDOT) / DUM xd(3) = (VT*VDOT- V*XD(1)) * CBTA / DUM&lt;/quote&gt;&lt;p&gt;Once again, I don‚Äôt actually understand what I‚Äôm reading. UDOT etc are the accelerations on each axis. These values are then used to update the output state vector xd(1), xd(2), and xd(3), which are the VT, ALPHA, and BETA that will be used in the next frame.&lt;/p&gt;&lt;p&gt;It appears that this flight model is calculating the change in alpha and beta directly from the change in velocity. This is not necessary in C#, since we can calculate alpha and beta fresh in each frame.&lt;/p&gt;&lt;p&gt;But I don‚Äôt fully understand how UDOT is calculated. R and Q are angular velocities, so multiplying them with linear velocity doesn‚Äôt make any sense. Perhaps this is some physics equation that I‚Äôm not familiar with.&lt;/p&gt;&lt;p&gt;GD * STH is the gravity acceleration times sin(theta). This is simply how gravity is applied. When the plane is level (theta = 0), sin(theta) is 0. The plane experiences no gravity acceleration on the X axis (the forward axis). When the plane is pointed straight down, sin(theta) = 1, so the plane experiences the full force of gravity pulling on the X axis.&lt;/p&gt;&lt;p&gt;A similar calculation is made for every axis.&lt;/p&gt;&lt;p&gt;For UDOT, the final term is (QS * CXT + T) / MASS. This is the coefficient CXT plus the thrust from the engine, divided by mass. VDOT and WDOT have similar final terms, made more difficult to read by the common subexpression optimization.&lt;/p&gt;&lt;p&gt;Ignoring the other terms, the 3 accelerations can be written:&lt;/p&gt;&lt;quote&gt;UDOT = (QS * CXT + T)/MASS VDOT = AY WDOT = AZ&lt;/quote&gt;&lt;p&gt;Then the variables can be expanded and rewritten:&lt;/p&gt;&lt;quote&gt;UDOT = (QBAR * S * CXT + T) / MASS VDOT = (QBAR * S * CYT) / MASS WDOT = (QBAR * S * CZT) / MASS&lt;/quote&gt;&lt;p&gt;This is simply the force coefficient times QBAR (dynamic pressure) times S (wing area). Then thrust is added to the X axis. This is how all forces are applied to the aircraft.&lt;/p&gt;&lt;p&gt;Recall the lift equation from my previous project:&lt;/p&gt;\(L=\frac12\times A\times\rho\times C_L\times v^2\)&lt;list rend="ul"&gt;&lt;item&gt;L is the resulting lift force&lt;/item&gt;&lt;item&gt;A is the surface area&lt;/item&gt;&lt;item&gt;œÅ (rho) is the air density&lt;/item&gt;&lt;item&gt;CL is the coefficient of lift&lt;/item&gt;&lt;item&gt;v is the velocity&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The surface area A is equivalent to the wing area S in the Fortran code. CL is equivalent to the variables CXT, CYT, or CZT. The factor œÅ * v2 is equivalent to QBAR. Thus we are essentially calculating a lift force on all three axes. But remember that we are specifically calculating normal force, not lift force.&lt;/p&gt;&lt;p&gt;The roll, pitch, and yaw state vectors are then updated:&lt;/p&gt;&lt;quote&gt;xd(4) = P + (STH/CTH)*(QSPH + R*CPH) xd(5) = Q*CPH - R*SPH xd(6) = (QSPH + R*CPH)/CTH&lt;/quote&gt;&lt;p&gt;Once again, these equations make zero sense to meü§∑‚ôÇÔ∏è. It‚Äôs important for the Fortran code, but we will be calculating roll, pitch, and yaw differently in C#.&lt;/p&gt;&lt;p&gt;Aerodynamic moment is about to be calculated. However this depends on the moment of inertia values and some more values derived from those:&lt;/p&gt;&lt;quote&gt;PARAMETER (AXX=9496.0, AYY= 55814.0, AZZ=63100.0, AXZ= 982.0) PARAMETER (AXZS=AXZ**2, XPQ=AXZ*(AXX-AYY+AZZ),GAM=AXX*AZZ-AXZ**2) PARAMETER (XQR= AZZ*(AZZ-AYY)+AXZS, ZPQ=(AXX-AYY)*AXX+AXZS) PARAMETER ( YPR= AZZ - AXX )&lt;/quote&gt;&lt;p&gt;Now the aerodynamic moment is calculated:&lt;/p&gt;&lt;quote&gt;ROLL = QSB*CLT PITCH = QS *CBAR*CMT YAW = QSB*CNT PQ = p*Q QR = Q*R QHX = Q*HX xd(7) = ( XPQ*PQ - XQR*QR + AZZ*ROLL + AXZ*(YAW + QHX) )/GAM xd(8) = ( YPR*P*R - AXZ*(P**2 - R**2) + PITCH - R*HX )/AYY xd(9) = ( ZPQ*PQ - XPQ*QR + AXZ*ROLL + AXX*(YAW + QHX) )/GAM&lt;/quote&gt;&lt;p&gt;There‚Äôs a lot of stuff going on here. The output state vectors are updated using the moment of inertia values as well as HX, which is the angular momentum of the spinning engine mass. I don‚Äôt know enough about physics to fully understand why these equations are defined like this.&lt;/p&gt;&lt;p&gt;But we can at least see how the moment coefficients are used if we expand the ROLL, PITCH, and YAW variables:&lt;/p&gt;&lt;quote&gt;ROLL = QBAR * S * B * CLT PITCH = QBAR * S * CBAR * CMT YAW = QBAR * S * B * CNT&lt;/quote&gt;&lt;p&gt;ROLL and YAW depend on B, the wingspan of the plane. Pitch depends on CBAR, the mean aerodynamic chord.&lt;/p&gt;&lt;p&gt;The final step is to calculate the world space position of the aircraft. Since we are using Unity rigidbodies to implement the flight model, this step is not translated to C#. But for reference:&lt;/p&gt;&lt;quote&gt;T1= SPH * CPSI; T2= CPH * STH; T3= SPH * SPSI S1= CTH * CPSI; S2= CTH * SPSI; S3= T1 * STH - CPH * SPSI S4= T3 * STH + CPH * CPSI; S5= SPH * CTH; S6= T2*CPSI + T3 S7= T2 * SPSI - T1; S8= CPH * CTH xd(10) = U * S1 + V * S3 + W * S6 ! North speed xd(11) = U * S2 + V * S4 + W * S7 ! East speed xd(12) = U * STH -V * S5 - W * S8 ! Vertical speed AN = -AZ/GD; ALAT= AY/GD;&lt;/quote&gt;&lt;p&gt;Now we can start translating this into C# using Unity‚Äôs physics engine to replace some parts.&lt;/p&gt;&lt;p&gt;A lot of the code can be reused from the previous flight sim project. Using it for this new flight model only requires some conversion into customary units and back. The main class that controls everything is Plane. This class contains instances of the AirDataComputer, Engine, and Aerodynamics, which is where the translated Fortran code lives.&lt;/p&gt;&lt;p&gt;One simplification can be made since we are using Unity physics. We do not need to calculate the acceleration of the aircraft manually. That can be done automatically by the physics engine. However, the moment calculation needs to be copied more or less directly from the textbook.&lt;/p&gt;&lt;p&gt;The air data computer needs to be called:&lt;/p&gt;&lt;quote&gt;void UpdateAirData() { float speed = LocalVelocity.magnitude; // m/s float speedFeet = speed * metersToFeet; AltitudeFeet = Rigidbody.position.y * metersToFeet; airData = airDataComputer.CalculateAirData(speedFeet, AltitudeFeet); }&lt;/quote&gt;&lt;p&gt;Then the engine needs to be updated and the thrust force applied:&lt;/p&gt;&lt;quote&gt;void UpdateThrust(float dt) { engine.ThrottleCommand = Throttle; engine.Mach = Mach; engine.Altitude = AltitudeFeet; engine.Update(dt); Rigidbody.AddRelativeForce(new Vector3(0, 0, engine.Thrust * poundsForceToNewtons)); }&lt;/quote&gt;&lt;p&gt;For the aerodynamics class, a struct with all relevant aerodynamic state is passed, similar to the state vector in the Fortran code.&lt;/p&gt;&lt;quote&gt;public struct AerodynamicState { public Vector4 inertiaTensor; public Vector3 velocity; public Vector3 angularVelocity; public AirData airData; public float altitude; public float alpha; public float beta; public float xcg; public ControlSurfaces controlSurfaces; }&lt;/quote&gt;&lt;p&gt;This is populated by the Plane class, which also handles unit conversions:&lt;/p&gt;&lt;quote&gt;AerodynamicState currentState = new AerodynamicState { inertiaTensor = inertiaTensor, velocity = ConvertVectorToAerospace(LocalVelocity) * metersToFeet, angularVelocity = ConvertAngleToAerospace(LocalAngularVelocity), airData = airData, alpha = alpha, beta = beta, xcg = centerOfGravityPosition, controlSurfaces = ControlSurfaces }; var newState = aerodynamics.CalculateAerodynamics(currentState);&lt;/quote&gt;&lt;p&gt;All of the flight model code is located inside the Aerodynamics class.&lt;/p&gt;&lt;p&gt;First step is to call the aerodynamic coefficient functions from above:&lt;/p&gt;&lt;quote&gt;Vector3 GetForceCoefficient(float alpha, float beta, float aileron, float rudder, float elevator) { return new Vector3( GetXAxisForceCoefficient(alpha, elevator), GetYAxisForceCoefficient(beta, aileron, rudder), GetZAxisForceCoefficient(alpha, beta, elevator) ); } Vector3 GetMomentCoefficient(float alpha, float beta, float elevator) { return new Vector3( GetXAxisMomentCoefficient(alpha, beta), GetYAxisMomentCoefficient(alpha, elevator), GetZAxisMomentCoefficient(alpha, beta) ); } ... public AerodynamicForces CalculateAerodynamics(AerodynamicState currentState) { Vector3 forceCoefficient = GetForceCoefficient( currentState.alpha, currentState.beta, currentState.controlSurfaces.aileron, currentState.controlSurfaces.rudder, currentState.controlSurfaces.elevator ); Vector3 momentCoefficient = GetMomentCoefficient( currentState.alpha, currentState.beta, currentState.controlSurfaces.elevator ); }&lt;/quote&gt;&lt;p&gt;Then we calculate the damping values. This function simply performs the 9 table lookups.&lt;/p&gt;&lt;quote&gt;void CalculateDampingValues(float alpha) { float S = 0.2f * alpha; int K = Mathf.Clamp((int)S, -1, 8); float DA = S - K; int L = K + (int)Mathf.Sign(DA); for (int i = 0; i &amp;lt; 9; i++) { dampingTable[i] = ReadDampTable(dampTable, K, i) + Math.Abs(DA) * (ReadDampTable(dampTable, L, i) - ReadDampTable(dampTable, K, i)); } }&lt;/quote&gt;&lt;p&gt;Then the variables we need later are calculated:&lt;/p&gt;&lt;quote&gt;// calculate variables float P = currentState.angularVelocity.x; // roll rate float Q = currentState.angularVelocity.y; // pitch rate float R = currentState.angularVelocity.z; // yaw rate float airspeed = Mathf.Max(1, currentState.velocity.magnitude); float TVT = 0.5f / airspeed; float B2V = wingSpanFt * TVT; float CQ = CBAR * Q * TVT; float DAIL = currentState.controlSurfaces.aileron / 20.0f; float DRDR = currentState.controlSurfaces.rudder / 30.0f; float QS = currentState.airData.qBar * wingAreaFtSquared; float QSB = QS * wingSpanFt;&lt;/quote&gt;&lt;p&gt;Then damping is applied to the force and moment coefficients:&lt;/p&gt;&lt;quote&gt;// damping float CXT = forceCoefficient.x + CQ * dampingTable[0]; float CYT = forceCoefficient.y + B2V * (dampingTable[1] * R + dampingTable[2] * P); float CZT = forceCoefficient.z + CQ * dampingTable[3]; float CLT = momentCoefficient.x + B2V * (dampingTable[4] * R + dampingTable[5] * P); CLT += GetDLDA(currentState.alpha, currentState.beta) * DAIL; CLT += GetDLDR(currentState.alpha, currentState.beta) * DRDR; float CMT = momentCoefficient.y + CQ * dampingTable[6] + CZT * (XCGR - currentState.xcg); float CNT = momentCoefficient.z + B2V * (dampingTable[7] * R + dampingTable[8] * P) - CYT * (XCGR - currentState.xcg) * CBAR / wingSpanFt; CNT += GetDNDA(currentState.alpha, currentState.beta) * DAIL; CNT += GetDNDR(currentState.alpha, currentState.beta) * DRDR;&lt;/quote&gt;&lt;p&gt;Note that the damping array in Fortran is 1 based, while the same array in C# is 0 based.&lt;/p&gt;&lt;p&gt;Forces are calculated from the force coefficients. Since we are using Unity‚Äôs physics to apply gravity, the gravity terms are not included here. The force from engine thrust is applied outside of this class. And force is applied to a rigidbody, so acceleration does not need to be calculated manually. So the force calculations are now very simple:&lt;/p&gt;&lt;quote&gt;// forces // Acceleration in original text. Need to calculate force instead of acceleration float UDOT = QS * CXT; float VDOT = QS * CYT; float WDOT = QS * CZT;&lt;/quote&gt;&lt;p&gt;Moments are calculated using largely the same code as the textbook:&lt;/p&gt;&lt;quote&gt;// moments float ROLL = QSB * CLT; float PITCH = QS * CBAR * CMT; float YAW = QSB * CNT; float PQ = P * Q; float QR = Q * R; float QHX = Q * HX; // calculate inertia values float AXX = currentState.inertiaTensor.x; float AYY = currentState.inertiaTensor.y; float AZZ = currentState.inertiaTensor.z; float AXZ = currentState.inertiaTensor.w; float AXZS = AXZ * AXZ; float XPQ = AXZ * (AXX - AYY + AZZ); float GAM = AXX * AZZ - AXZS; float XQR = AZZ * (AZZ - AYY) + AXZS; float ZPQ = (AZZ - AYY) * AXX + AXZS; float YPR = AZZ - AXX; float rollAccel = ((XPQ * PQ) - (XQR * QR) + (AZZ * ROLL) + (AXZ * (YAW + QHX))) / GAM; float pitchAccel = ((YPR * P * R) - (AXZ * (P * P - R * R)) + PITCH - (R * HX)) / AYY; float yawAccel = ((ZPQ * PQ) - (XPQ * QR) + (AXZ * ROLL) + (AXX * (YAW + QHX))) / GAM;&lt;/quote&gt;&lt;p&gt;Finally, the force and angular acceleration is returned:&lt;/p&gt;&lt;quote&gt;public AerodynamicForces CalculateAerodynamics(AerodynamicState currentState) { ... result.force = new Vector3(UDOT, VDOT, WDOT); result.angularAcceleration = new Vector3(rollAccel, pitchAccel, yawAccel); return result; }&lt;/quote&gt;&lt;p&gt;Then in the Plane class, the force and angular acceleration can be applied to the rigidbody:&lt;/p&gt;&lt;quote&gt;// aeroForces in pounds var forces = ConvertVectorToUnity(aeroForces) * poundsForceToNewtons; Rigidbody.AddRelativeForce(forces); // aeroAngularAcceleration changes angular velocity directly Vector3 avCorrection = ConvertAngleToUnity(aeroAngularAcceleration); Rigidbody.AddRelativeTorque(avCorrection, ForceMode.Acceleration); lastAngularAcceleration = avCorrection;&lt;/quote&gt;&lt;p&gt;The plane is now able to fly. But if you try flying it right now, you will quickly find that it is impossible to fly by hand.&lt;/p&gt;&lt;head rend="h1"&gt;Stability&lt;/head&gt;&lt;p&gt;One important aerodynamic effect not modeled in my previous flight sim project is stability. Stability is the behavior of an aircraft when it‚Äôs disturbed from it‚Äôs flight path. More specifically, it‚Äôs how the aircraft behaves when it‚Äôs nose vector doesn‚Äôt match it‚Äôs velocity vector. Stability is the force that pulls the nose vector back towards the velocity vector.&lt;/p&gt;&lt;p&gt;For most aircraft, stability is created by the stabilizers in the tail. A stabilizer is simply a small airfoil (wing). Even without the pilot giving input, the stabilizers act like the fins of a dart. As the plane increases it‚Äôs Angle of Attack, the horizontal stabilizer will produce a lift force at the rear of the plane. This creates a torque that pulls the plane‚Äôs nose back towards the velocity vector, thus reducing the AOA. Likewise, the vertical stabilizers will create a torque that reduces Angle of Slip.&lt;/p&gt;&lt;p&gt;Keep in mind that stability depends on AOA, just as lift does. When the aircraft has a large AOA, the wings produce lift, which brings the velocity vector towards the nose vector. The stabilizers create torque which brings the nose vector towards the velocity vector. These two forces balance out somewhere and the aircraft will take a new attitude with a new velocity.&lt;/p&gt;&lt;p&gt;However, the aircraft needs to maintain a non-zero AOA to create enough lift to fly straight and level. How does it maintain this AOA when stability works to reduce AOA to zero? The stabilizers can be trimmed to hold a specific AOA. This means that the stabilizers produce zero torque at this particular non-zero AOA. In some planes this must be done manually by the pilot, but in the F-16 this is done automatically by the FCS.&lt;/p&gt;&lt;p&gt;The two forces of lift and stability combine to produce the ‚Äúfeel‚Äù of an aircraft‚Äôs controls. The tendency for the nose to be pulled towards the velocity vector is called positive stability. Most non-fighter aircraft are designed to have positive stability to maximize safety and ease of flying.&lt;/p&gt;&lt;p&gt;But fighter aircraft like the F-16 are different. These aircraft are often designed to have neutral or even negative stability. Neutral stability means that the aircraft will hold it‚Äôs current attitude. Negative stability means that the aircraft will rotate even further away from the velocity vector, at an increasing rate.&lt;/p&gt;&lt;p&gt;The previous flight sim does not model this at all. There is no torque that changes the plane‚Äôs attitude except for the steering force. So the behavior is best described as neutrally stable.&lt;/p&gt;&lt;p&gt;This F-16 flight model does include stability. But keep in mind that the real F-16 was designed to have relaxed static stability. This means that it is positively stable, but weakly so. This makes the aircraft more maneuverable and better at retaining energy while turning. But flying an aircraft like this is difficult or even impossible for a human pilot. The plane will depart from steady flight from the smallest stick input or wind gust. The only way a human can handle an aircraft like this during long and stressful missions is with a computerized flight control system.&lt;/p&gt;&lt;head rend="h1"&gt;Flight Control System&lt;/head&gt;&lt;p&gt;A flight control system (FCS) is a computer located between the flight stick and the control surfaces. This computer translates the pilot‚Äôs input on the flight stick into control surface movement. It can react to disturbances in the plane‚Äôs attitude more quickly and precisely than a human can.&lt;/p&gt;&lt;p&gt;In my previous flight sim project, the control surfaces were purely cosmetic. The actual method used to turn the vehicle was by applying torque directly to the center of mass. That torque was calculated to create a certain amount of angular acceleration without exceeding the plane‚Äôs turn rate limit.&lt;/p&gt;&lt;p&gt;For example, the plane had a turn rate on the pitch axis of 60 degrees per second and an acceleration of 120 degrees per second per second. The plane‚Äôs turn rate never leaves the range [-60, 60]. Actually, no torque is ever calculated. Unity provides a function to apply angular acceleration directly, ignoring moment of inertia. I chose this behavior to make it easy to both understand the code and to fly the plane.&lt;/p&gt;&lt;p&gt;But this F-16 simulator does depend on the position of the control surfaces. Instead of specifying the acceleration directly, this simulator specifies the torque (moment) and calculates the resulting acceleration. This is more accurate to how serious simulators work and how real planes fly, but this makes controlling the plane more difficult.&lt;/p&gt;&lt;p&gt;The steering system in the previous flight sim project was essentially a perfect FCS that could always achieve the turn rate chosen by the pilot. This is helped by the fact that that simulator does not model aerodynamic stability or instability at all. Spinning out of control was simply not possible.&lt;/p&gt;&lt;p&gt;This F-16 simulator is more difficult to control both because of the more accurate control surfaces and because of the modeled stability. You can actually try to fly this F-16 manually, by disabling the FCS in the config menu.&lt;/p&gt;&lt;p&gt;You will quickly find that the F-16 is almost impossible to fly manually. Every small disturbance from straight and level flight will create small torques that turn your plane unexpectedly. If you try to correct it with the control stick, you will almost certainly overcorrect and send the plane into a new and exciting attitude. This is called pilot induced oscillation.&lt;/p&gt;&lt;p&gt;It simply isn‚Äôt possible for a human to react quickly and precisely enough to fly this aircraft. You may be able to fly straight and level with some effort, but you will quickly lose control if you attempt any maneuver. This is indeed a property of the real F-16.&lt;/p&gt;&lt;p&gt;The textbook provides no Fortran code for the FCS. From here on out, it‚Äôs my own original code.&lt;/p&gt;&lt;head rend="h2"&gt;PID Controllers&lt;/head&gt;&lt;p&gt;The steering system from the previous project cannot be reused. The solution is to use PID controllers, a topic I‚Äôve covered on this blog before.11&lt;/p&gt;&lt;p&gt;To be more specific, steering in the previous flight sim was easy because we could read the angular velocity of the aircraft and apply a torque that directly countered any undesired movement. This F-16 flight model does not allow us to apply torques directly. We can only set the angle of the control surfaces. This is the problem that PID controllers are good at solving.&lt;/p&gt;&lt;p&gt;Adding the PID controllers is simple. The pilot‚Äôs control input is used to select a target angular velocity for the plane, for the 3 axes of rotation. This is given to three independent PID controllers. The output of the PID controllers set the target position for the control surface.&lt;/p&gt;&lt;p&gt;The control surface positions are then passed into the flight model inside AerodynamicState.&lt;/p&gt;&lt;quote&gt;Vector3 targetAV = Vector3.Scale(controlInput, steeringSpeed * steeringSpeedFactor); var accel = lastAngularAcceleration * Mathf.Rad2Deg * dt; controlSurfaceTarget = new Vector3( pitchController.Calculate(dt, av.x, accel.x, targetAV.x), -yawController.Calculate(dt, av.y, accel.y, targetAV.y), rollController.Calculate(dt, av.z, accel.z, targetAV.z) ); var current = ControlSurfaces; ControlSurfaces = new ControlSurfaces( Utilities.MoveTo(current.elevator, controlSurfaceTarget.x, elevatorSpeed, dt, -elevatorRange, elevatorRange), Utilities.MoveTo(current.rudder, controlSurfaceTarget.y, rudderSpeed, dt, -rudderRange, rudderRange), Utilities.MoveTo(current.aileron, controlSurfaceTarget.z, aileronSpeed, dt, -aileronRange, aileronRange) ); ... AerodynamicState currentState = new AerodynamicState { controlSurfaces = ControlSurfaces }; var newState = aerodynamics.CalculateAerodynamics(currentState);&lt;/quote&gt;&lt;p&gt;Here the PIDs are named ‚ÄúpitchController‚Äù, ‚ÄúyawController‚Äù, and ‚ÄúrollController‚Äù. They are all tuned separately to handle a single axis.&lt;/p&gt;&lt;p&gt;When the player releases the stick, the PID controllers will attempt to hold an angular velocity of zero. This makes the aircraft feel like it‚Äôs neutrally stable. This also acts as a way to trim the aircraft, so that level flight can be maintained without needing to constantly pull the stick. The PID controller will detect an undesired rotation and move the elevators at a slight angle to counter it.&lt;/p&gt;&lt;p&gt;These PID controllers only add a small amount of complexity to the code, but they achieve similar results as the perfect FCS from the previous project. But there are still limitations that prevent it from being a perfect FCS.&lt;/p&gt;&lt;p&gt;First, the PID controllers must be tuned. The output has to be strong enough to quickly respond to pilot inputs, while avoiding oscillation. This is of course a limitation of any PID control system.&lt;/p&gt;&lt;p&gt;Second, the control surfaces move at a finite speed. This means that it will take some time for the control surface to match the FCS‚Äôs commands. So the commands will be imperfectly applied to the aircraft.&lt;/p&gt;&lt;p&gt;Third, unlike the previous flight sim, the three axes of rotation are not independent. For example, a large angle of slip will cause the plane to roll. This is due to the swept wings of the F-16. The roll controller will cancel this out somewhat, but a large enough AOS will result in an uncommanded roll.&lt;/p&gt;&lt;p&gt;Even with these limitations, the PID controllers work fairly well at keeping the plane in control.&lt;/p&gt;&lt;p&gt;Additionally, I use a technique called gain scheduling to change the gain parameters of the roll controller. Because roll performance increases with airspeed, we need a way to limit the amount of aileron movement at high speed. I add two animation curves, which take speed as input, and give the P and D gain of the roll controller as output.&lt;/p&gt;&lt;quote&gt;rollController.P = rollPSchedule.Evaluate(Mathf.Max(0, LocalVelocity.z)); rollController.D = rollDSchedule.Evaluate(Mathf.Max(0, LocalVelocity.z)); Vector3 fcsTarget = new Vector3( pitchController.Calculate(dt, av.x, accel.x, targetAV.x), -yawController.Calculate(dt, av.y, accel.y, targetAV.y), rollController.Calculate(dt, av.z, accel.z, targetAV.z) );&lt;/quote&gt;&lt;p&gt;This allows us to change the strength of the roll controller at different speeds. A more advanced FCS might have a gain schedule for each controller, possibly using more inputs than just airspeed. In fact, if there were multiple inputs, we would need a 2D lookup table to calculate the gain schedule.&lt;/p&gt;&lt;p&gt;Because the flight model is a complete description of how the aircraft will respond at different combinations of AOA, AOS, and control input, it is theoretically possible to design an FCS system that perfectly counters all of the unwanted tendencies. However, that is beyond my understanding of aerodynamics and control theory.&lt;/p&gt;&lt;head rend="h2"&gt;G and AOA Limiter&lt;/head&gt;&lt;p&gt;The weakness of PID controllers is that they only control the angular velocity of the plane. This is not sufficient to control the plane. The previous project has a G limiter, which is simple since steering torque is applied directly to the aircraft. Adding a G limiter is more complicated with this F-16 flight model.&lt;/p&gt;&lt;p&gt;Additionally, a critical part of the FCS on a real F-16 is the AOA limiter. Just like the G limiter prevents the pilot from creating excessive G-forces while maneuvering, the AOA limiter prevents excessive AOA. This is because the aircraft becomes so unstable at about 28 degrees AOA that even the FCS can not compensate. And importantly, our flight model only supports a limited range of AOA (up to 45 degrees), so if the pilot goes beyond that, the behavior of the simulator becomes nonsensical. So limiting the AOA to about 25 degrees is important for maintaining stable flight.&lt;/p&gt;&lt;p&gt;The previous flight sim project did not have anything like an AOA limiter. I simply tuned the steering strength so that AOA would not exceed about 15 degrees (unless stalling). And even then, there is no instability caused by high AOA, so nothing bad happens if the pilot exceeds that.&lt;/p&gt;&lt;p&gt;We need a system that prevents the pilot from exceeding 25 degrees AOA. This would be implemented as a multiplier on the pilot‚Äôs stick input, just like a G limiter. Since there are two limits, we simply select the more restrictive limit using min(). So if the G limiter says to limit input to 0.75 and the AOA limiter says to limit input to 0.5, the value 0.5 is chosen.&lt;/p&gt;&lt;p&gt;Because this flight model uses lookup tables, there is no simple formula for calculating either the G limiter or AOA limiter. The G limiter from the previous project won‚Äôt work here. Additionally, the relationship between steering input and AOA is not simple. There is a feedback loop between AOA and lift. As AOA increases, lift increases. But as lift increases, AOA decreases since lift pulls the plane onto a new velocity vector. Not to mention lift also depends on airspeed and altitude.&lt;/p&gt;&lt;p&gt;Luckily, the F-16 flight model is completely disconnected from Unity‚Äôs physics system. We can actually run the flight model as much as we want with any inputs, and use the outputs for any purpose. There is the ‚Äúmain‚Äù flight model that syncs with a Unity rigidbody. But we can create ‚Äúside‚Äù flight models to predict future behavior of the plane.&lt;/p&gt;&lt;p&gt;I chose to implement the G and AOA limiters by running a side flight model. This side model takes the pilot‚Äôs inputs and simulates the aircraft in a simplified world state. In a single physics update, the main flight model runs once, but the side flight model runs multiple times to predict movement several seconds into the future. Because running the flight model is a few lookups and math operations, running multiple times per frame is dirt cheap.&lt;/p&gt;&lt;p&gt;By running this side model, we can determine how the plane would behave if it flew without any limiters. So if the plane is flying fast enough to pull 16 Gs, the side model will report that. We can use that information to calculate the G limiter for the main model.&lt;/p&gt;&lt;p&gt;The side model is contained in the class SimpleTrimmer. The main function Trim looks like this:&lt;/p&gt;&lt;quote&gt;public SimulatedState Trim(float dt, float timeMax, SimulatedState initialState) { float time = 0; while (time &amp;lt; timeMax) { AerodynamicState aeroState = new AerodynamicState() { ... }; var aeroForces = aerodynamics.CalculateAerodynamics(aeroState); ‚Ä¶ time += dt; } return state; }&lt;/quote&gt;&lt;p&gt;It just calls CalculateAerodynamics in a loop with it‚Äôs own time variable. The timestep can also be different from the main FixedUpdate loop time step. The variable timeMax controls how far into the future the prediction runs. For example, this side model can run at 0.1 second time steps for 5 seconds total.&lt;/p&gt;&lt;p&gt;After one step of the simulation is run, the state variables are updated and fed back into the next step. The maximum G force and AOA of the whole simulation is recorded.&lt;/p&gt;&lt;quote&gt;// rotate velocity by pitchDelta Quaternion newRotation = Quaternion.Euler(0, pitchDelta, 0); Vector3 newVelocity = newRotation * state.velocity; newVelocity.y = 0; newVelocity.z += gravity * dt; Vector3 velNormalized = newVelocity.normalized; // assume airspeed magnitude does not change (no drag, no thrust) state.velocity = velNormalized * airspeed; state.alpha = Mathf.Atan2(velNormalized.z, velNormalized.x) * Mathf.Rad2Deg; state.maxAlpha = Mathf.Max(state.maxAlpha, state.alpha); state.maxAccelerationZ = Mathf.Min(state.maxAccelerationZ, state.acceleration.z);&lt;/quote&gt;&lt;p&gt;This simulation is highly simplified compared to the main flight model. It ignores the pilot‚Äôs input except pitch. It ignores angular velocity except for pitch rate. It does not apply drag or any other force that changes airspeed or altitude. It ignores any change to the aircraft‚Äôs pitch. Note that the flight model does not care about the orientation of the aircraft to begin with.&lt;/p&gt;&lt;p&gt;The Trim function assumes the pilot is giving a full pitch up or pitch down input and takes the pitch PID controller as a parameter. So this side flight model uses the same PID values as the main model, to prevent the simulation from turning faster than the max turn rate. Since the I term is not used on the PID controller, we can use it without worrying about state.&lt;/p&gt;&lt;p&gt;Gravity as a single float value is also passed as a parameter. This allows the simulation to know how much gravity is affecting the turn on the pitch axis. If the plane is level, this value is 1. If the plane is rolled 90 degrees to the side, this value is 0. If upside down, this value is -1. Gravity on the other axes is ignored.&lt;/p&gt;&lt;p&gt;The larger time step and reduced complexity of simulation means that the side model is not completely accurate to how the plane will fly. But that‚Äôs acceptable since we are only using this to estimate the maximum G force and AOA that a turn might create.&lt;/p&gt;&lt;p&gt;After running through a few seconds of simulation on the flight model, the Trim function returns with the max G force and AOA. The FCS then uses these values to calculate the limiting factors for the pilot‚Äôs pitch input.&lt;/p&gt;&lt;quote&gt;SimpleTrimmer.SimulatedState state = simpleTrimmer.Trim( trimmerTimeStep, trimmerTime, initialState, maxAV.x * Mathf.Deg2Rad, gravityFactor * metersToFeet, pitchController, centerOfGravityPosition ); float predictedAlpha = state.maxAlpha; float predictedG = -state.maxAccelerationZ * feetToMeters; float aoaPitchMult = CalculateAOALimiter(predictedAlpha); float gLimit = gLimitPitch; // pitch up limit (ie 8G) if (controlInput.x &amp;gt; 0) { gLimit = this.gLimit; // pitch down limit (ie 4G) } float gPitchMult = CalculateGLimiter(predictedG, gLimit);&lt;/quote&gt;&lt;p&gt;The limiting factor for AOA and G force is calculated with a simple function:&lt;/p&gt;&lt;quote&gt;float ApplyLimiter(float value, float limit, float limitStrength) { if (limit &amp;lt;= 0) return 1; if (value &amp;lt; limit) return 1; float error = value - limit; error *= limitStrength; return limit / (limit + error); }&lt;/quote&gt;&lt;p&gt;ApplyLimiter returns a factor in the range [0, 1], which is eventually multiplied with the pilot‚Äôs control input. This function then used in the limiter functions:&lt;/p&gt;&lt;quote&gt;float CalculateGLimiter(float predictedG, float gLimit) { float gForce = predictedG / 9.81f; float gPitchMult = ApplyLimiter(gForce, gLimit, gLimitStrength); return gPitchMult; }&lt;/quote&gt;&lt;p&gt;The variable gForce is the predicted max G force from the side model. gLimit is the value chosen as the max G force, for example, 8. If the predicted value is 12, then the variable error will be 12 ‚Äì 8 = 4. The returned factor would be 8 / (8 + 4) = 8 / 12 = 0.66. limitStrength is used to tune how strongly the error affects the returned limit factor.&lt;/p&gt;&lt;p&gt;If the value is below the limit, the returned factor is 1.&lt;/p&gt;&lt;p&gt;The AOA limiter uses the same function to calculate two limiting factors which are combined:&lt;/p&gt;&lt;quote&gt;float CalculateAOALimiter(float predictedAlpha) { float aoaPitchMult = 1.0f; aoaPitchMult *= ApplyLimiter(predictedAlpha, predictedAoaLimitMax, predictedAoaLimitStrength); float realAOA = AngleOfAttack * Mathf.Rad2Deg; aoaPitchMult *= ApplyLimiter(realAOA, feedbackAoaLimitMax, feedbackAoaLimitStrength); return aoaPitchMult; }&lt;/quote&gt;&lt;p&gt;One limit factor depends on the predicted alpha from the SimpleTrimmer class. The other factor depends on the actual alpha value the plane currently has. This can handle cases where the real alpha is much larger than the predicted value, such as when the plane is already stalling.&lt;/p&gt;&lt;p&gt;Then the AOA and G limiter factors are applied to the pilot‚Äôs input:&lt;/p&gt;&lt;quote&gt;float aoaPitchMult = CalculateAOALimiter(predictedAlpha); float gPitchMult = CalculateGLimiter(predictedG, gLimitPitch); float pitchMult = Mathf.Min(aoaPitchMult, gPitchMult); // select whichever limiter is stronger float rollMult = rollPitchFactor.Evaluate(Mathf.Abs(controlInput.x)) * rollAOAFactor.Evaluate(AngleOfAttack * Mathf.Rad2Deg); Vector3 limitedInput = Vector3.Scale(controlInput, new Vector3(pitchMult, 1, rollMult)); Vector3 targetAV = Vector3.Scale(limitedInput, steeringSpeed * steeringSpeedFactor);&lt;/quote&gt;&lt;p&gt;The min() function is used to select whichever limiter factor is strongest. Since I am designing these systems myself, I can tell you there is not a strong reason why I chose min() instead of another multiplication. This is just the formula that felt right when I was testing it.&lt;/p&gt;&lt;p&gt;In fact there are many different ways that the limiting factors could be calculated and combined. I designed the ApplyLimiter function primarily to be easy to tune. These allow me to have separate variables for tuning predicted G, predicted AOA, and feedback AOA limiters.&lt;/p&gt;&lt;p&gt;There is one final limiter above, rollMult. This is controlled by two AnimationCurves, rollPitchFactor and rollAOAFactor. These curves reduce the strength of roll input when the pilot is commanding a strong pitch rotation and when the plane has a high AOA. I added this because rolls felt too sensitive when in a high G or high AOA turn. Tune these to your own taste.&lt;/p&gt;&lt;head rend="h2"&gt;Stick Pusher&lt;/head&gt;&lt;p&gt;The final system to add is a stick pusher. A stick pusher is a device some aircraft have that physically pushes the stick forward to avoid a stall. This doesn‚Äôt exist in the real F-16, even digitally, but who cares? It was quick and easy to write.&lt;/p&gt;&lt;p&gt;If the AOA exceeds some threshold, a bias value is added to the pilot‚Äôs stick input to push the nose down. This is different from the AOA limiter above, which multiplies the input by a factor [0, 1]. If the pilot is giving an input of 0, then the AOA limiter has no effect. The stick pusher adds the bias value to the pilot‚Äôs input, so it will work even when the pilot gives no input.&lt;/p&gt;&lt;p&gt;The stick pusher will apply when the plane is stalling or if the AOA limiter fails to keep the AOA in the safe range.&lt;/p&gt;&lt;p&gt;The code for this is incredibly simple in concept and implementation:&lt;/p&gt;&lt;quote&gt;float CalculateAOAPusher() { float bias = 0.0f; float aoa = AngleOfAttack * Mathf.Rad2Deg; if (aoa &amp;gt; stickPusherThreshold) { float error = aoa - stickPusherThreshold; bias = stickPusherCurve.Evaluate(error); } return Mathf.Min(stickPusherMax, bias); }&lt;/quote&gt;&lt;p&gt;If the AOA is over the stickPushThreshold, add a bias to the player‚Äôs input. The more it exceeds the threshold, the stronger the bias. At max strength, the stick pusher can give a full nose down input that can‚Äôt be overridden by the pilot.&lt;/p&gt;&lt;p&gt;This value is summed with the pilot‚Äôs input before running the PID controllers.&lt;/p&gt;&lt;quote&gt;Vector3 stickPusher = new Vector3(CalculateAOAPusher(), 0, 0); Vector3 limitedInput = Vector3.Scale(controlInput, new Vector3(pitchMult, 1, rollMult)) + stickPusher; Vector3 targetAV = Vector3.Scale(limitedInput, steeringSpeed * steeringSpeedFactor);&lt;/quote&gt;&lt;p&gt;With all of these systems added to the FCS, the plane should be very stable to fly now. Since the side model simulation is simplified, the G and AOA limiters are not perfect. They will sometimes result in those parameters being limited at a value too high or too low. But these systems do work accurately enough to keep the plane stable.&lt;/p&gt;&lt;head rend="h1"&gt;Testing&lt;/head&gt;&lt;p&gt;Of course any implementation can have bugs. We need to test the flight model to make sure it works. This includes the translation of the Fortran flight model, and the code that implements all of this in Unity.&lt;/p&gt;&lt;head rend="h2"&gt;Unit Testing&lt;/head&gt;&lt;p&gt;Because the flight model is separate from Unity‚Äôs physics engine, we can actually test it using normal unit testing techniques. Unity provides a unit testing framework based on NUnit, so testing is pretty typical for C#.&lt;/p&gt;&lt;p&gt;The authors of the textbook also helpfully provide a test case to use. They give the inputs to the model (airspeed, control surface position, throttle, etc) and the expected output of the model (forces, moment, angular velocity, etc). This lets us validate that the model is implemented correctly by running a single step of simulation.&lt;/p&gt;&lt;quote&gt;// Textbook provides a table of input values and the expected output // Index Param Input State (X) Output (XD) // 1 0.4 (XCG) 0.9 (throttle) 500 (vt) -75.23724 // 2 20 (elevator) 0.5 (alpha) -0.8813419 // 3 -15 (aileron) -0.2 (beta) -0.4759990 // 4 -20 (rudder) -1 (phi) // 5 1 (theta) // 6 -1 (psi) // 7 0.7 (P) 12.62679 // 8 -0.8 (Q) 0.9649671 // 9 0.9 (R) 0.5809759 // 10 1000 (north) // 11 900 (east) // 12 10000 (alt) 248.1241 // 13 90 (power) -58.68999&lt;/quote&gt;&lt;p&gt;Note that the output values for roll, pitch, and yaw, and north, east, and altitude, are not checked in this test. We are using the Unity rigidbody to handle these, so these values are not even calculated in C#.&lt;/p&gt;&lt;p&gt;Additionally, the table lookup operations are fairly simple C# code, so these functions can also be unit tested. I caught a few bugs in the flight model by adding these tests.&lt;/p&gt;&lt;p&gt;All of the tests are in the ModelTestCase class.&lt;/p&gt;&lt;head rend="h2"&gt;Flight Testing&lt;/head&gt;&lt;p&gt;Of course unit testing can only cover so much. The whole point of this project is to create a flight simulator. The only way to know how the flight model really feels is to fly it. So get out there and start flying it!&lt;/p&gt;&lt;p&gt;I have caught a few bugs in the implementation just by flying it and realizing that some aspect felt weird.&lt;/p&gt;&lt;p&gt;In the aerospace industry, test flights are thoroughly instrumented to gather as much data as possible. Force on every axis, angular velocity, pilot input, GPS track, etc is all recorded and stored for future analysis. It‚Äôs possible to write automated tests that read this data and check that values stay within expected bounds.&lt;/p&gt;&lt;p&gt;I have done none of that here. Just have fun flying üôÇ&lt;/p&gt;&lt;head rend="h1"&gt;Limitations&lt;/head&gt;&lt;p&gt;The flight model defined in the textbook has several limitations.&lt;/p&gt;&lt;p&gt;The effects of alpha on the flight model is only modeled for the range [-10, 45]. Beta is only modeled for the range [-30, 30]. The flight model supports extrapolating data tables beyond their defined ranges, but the returned values will quickly become nonsensical. This means that if you manage to fly the F-16 beyond the provided ranges for alpha and beta, the flight model will break down and begin behaving non-physically.&lt;/p&gt;&lt;p&gt;In some cases, the aircraft will eventually return to controlled flight. But in other cases, one bad data value used to query the tables will cause increasingly bad data to be stored to the plane‚Äôs state. These bad values will quickly grow until the plane is thrown to infinity.&lt;/p&gt;&lt;p&gt;Hopefully, this is not possible when using FCS that I‚Äôve written. But I encourage any readers to try breaking it themselves.&lt;/p&gt;&lt;p&gt;You can also turn off parts of the FCS using the config menu in the top left corner. This allows you to fly the plane completely manually, turn the engine off, or alter the center of gravity.&lt;/p&gt;&lt;p&gt;If the flight model doesn‚Äôt bug out from extreme values, then you can actually perform a backflip or a ‚ÄúKulbit‚Äù maneuver with the F-16. I recommend turning off only the pitch axis FCS if you want to try that.&lt;/p&gt;&lt;p&gt;Another limitation is that flaps and slats are not defined in the flight model. The real F-16 uses a single control surface called a ‚Äúflaperon‚Äù that works as both a flap and an aileron. When more lift is needed at low speeds, both flaperons deflect downwards like traditional flaps. Leading edge slats also deflect downwards to increase lift.&lt;/p&gt;&lt;p&gt;The textbook flight model only considers these control surfaces to be ailerons. That is, they always deflect in opposite directions in order to create a roll moment. Only a single ‚Äúaileron‚Äù value is used to represent both left and right, so they cannot be used as flaps. If they were to be used as flaps, then there would need to be a left aileron and right aileron value and the Z axis force coefficient would depend on flaperon position.&lt;/p&gt;&lt;p&gt;The effect of slat position is blended into the existing tables, so there is some effect of slats on Z axis force. But the slat position cannot be animated on the plane‚Äôs 3D model since no variable for it exists.&lt;/p&gt;&lt;p&gt;This means that there are reduced high lift devices on the aircraft. The extra lift from flaps cannot be modeled. So the plane‚Äôs takeoff speed is much higher than you might expect from the F-16. The textbook only defines a model for flight, not for taxiing or takeoff. Landings feel quite bad because of this.&lt;/p&gt;&lt;p&gt;Another limitation is the lack of landing gear simulation. The landing gear is implemented exactly the same as the previous project: three capsule colliders. There is no simulation of wheel, tire, or suspension behavior. Again, this makes takeoff and landing feel kind of weird. But I have no idea how to write a system like that and it‚Äôs out of scope for this project anyways.ü§∑‚ôÇÔ∏è&lt;/p&gt;&lt;p&gt;Another limitation of the flight model is the inaccuracy when flying super sonic. With real planes, lift and drag forces change drastically as you approach Mach 1. Air accelerates as it passes over the wing. Even while the plane remains subsonic, some parts of the air flow are forced to accelerate above Mach 1. When this air reaches supersonic speeds, shockwaves form over the wing which alters the way air flows around it.&lt;/p&gt;&lt;p&gt;This region, where some air is supersonic and some is not, is called the transonic region. This has a drastic effect on the aircraft‚Äôs performance and handling. In particular, the coefficient of drag increases, creating the ‚Äúsound barrier‚Äù effect. The position of lift force on the wing changes, which will change how the plane handles.&lt;/p&gt;&lt;p&gt;None of these effects are included in the textbook‚Äôs flight model. These could be modeled by adding another input dimension to the force and moment tables. I suspect these were omitted to keep the flight model simple.&lt;/p&gt;&lt;p&gt;The practical effect is that the flight model only works up to about Mach 0.7. Above that, all of the forces on the aircraft become unrealistic. The behavior of the plane continues to increase smoothly with airspeed as if supersonic effects don‚Äôt exist.&lt;/p&gt;&lt;head rend="h1"&gt;Conclusion&lt;/head&gt;&lt;p&gt;I started this project after I got a job in the aerospace industry. The textbook was recommended by my manager, since I was working on real flight control systems. In a way, this article is a summary of everything I‚Äôve learned about flying and software engineering in that job.&lt;/p&gt;&lt;p&gt;The way this F-16 flight model is implemented is very different from my previous project. It is actually close to how professional level sims are written, though simplified to fit in a textbook. Even so, there are still plenty of limitations in the flight model which means the simulation will behave unrealistically beyond the intended flight envelope.&lt;/p&gt;&lt;p&gt;The authors of the textbook based their flight model on a NASA paper12 which measured the aerodynamic properties of a scale model in a wind tunnel. The Nasa paper provides 50 lookup tables. The textbook simplified, approximated, and combined these into only 13 lookup tables.&lt;/p&gt;&lt;p&gt;With only a little more effort, you could write a simulator that uses many more tables to cover a larger flight envelope with more detail. The only limit is the data you have access to and your understanding of aerodynamics.&lt;/p&gt;&lt;p&gt;The FCS I‚Äôve written is much simpler than the real FCS. Theoretically, it would be possible to write code that models the real F-16 FCS and apply it to this flight simulator. But how could you even get that information and who would be crazy enough to try that?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;‚ÄúAircraft Control and Simulation‚Äù by Brian L. Stevens, Frank L. Lewis, and Eric N. Johnson ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://vazgriz.com/346/flight-simulator-in-unity3d-part-1/ ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://vazgriz.com/467/flight-simulator-in-unity3d-part-2/ ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://vazgriz.com/503/creating-a-flight-simulator-in-unity3d-part-3/ ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://twitter.com/FreyaHolmer/status/1325556229410861056 ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://commons.wikimedia.org/wiki/File:Speyer_Handlog.jpg ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/sound.html ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Bilinear_interpolation ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Trilinear_interpolation ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://aerospaceweb.org/question/aerodynamics/q0194.shtml ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;https://vazgriz.com/621/pid-controllers/ ‚Ü©Ô∏é&lt;/item&gt;&lt;item&gt;Simulator study of stall/post-stall characteristics of a fighter airplane with relaxed longitudinal static stability, Nyugen et al, 1979 (https://ntrs.nasa.gov/citations/19800005879) ‚Ü©Ô∏é&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45383637</guid><pubDate>Fri, 26 Sep 2025 07:06:45 +0000</pubDate></item><item><title>US cities pay too much for buses</title><link>https://www.bloomberg.com/news/articles/2025-09-26/us-cities-are-paying-too-much-for-new-transit-buses</link><description>&lt;doc fingerprint="acad56d595d09b7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why US Cities Pay Too Much for Transit Buses&lt;/head&gt;
    &lt;p&gt;A new paper argues that lack of competition, demand for custom features and ‚ÄúBuy America‚Äù rules have driven up costs for transit agencies in the US.&lt;/p&gt;
    &lt;p&gt;In 2023, two transit agencies went shopping for new buses. Denver‚Äôs Regional Transportation District (RTD) and the Cincinnati area‚Äôs Southwest Ohio Regional Transit Authority (SORTA) both bought 40-foot, diesel-powered vehicles from the same manufacturer. Although the vehicles were similar, their prices were not: RTD‚Äôs 10 buses cost $432,028 each, while SORTA‚Äôs 17 cost a whopping $939,388 a pop.&lt;/p&gt;
    &lt;p&gt;That same year, Singapore‚Äôs Land Transport Authority also bought buses. Their order called for 240 fully electric vehicles ‚Äî which are typically twice as expensive as diesel ones in the US. List price: Just $333,000 each.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45386578</guid><pubDate>Fri, 26 Sep 2025 13:57:17 +0000</pubDate></item><item><title>Evolving the Multi-User Spaceport</title><link>https://www.spacex.com/updates#multiuser-spaceport</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45387494</guid><pubDate>Fri, 26 Sep 2025 15:17:31 +0000</pubDate></item><item><title>Open Social</title><link>https://overreacted.io/open-social/</link><description>&lt;doc fingerprint="bd968b5388b80695"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;September 26, 2025&lt;/p&gt;
    &lt;p&gt;Open source has clearly won. Yes, there are plenty of closed source products and businesses. But the shared infrastructure‚Äîthe commons‚Äîruns on open source.&lt;/p&gt;
    &lt;p&gt;We might take this for granted, but it wasn‚Äôt a foregone conclusion thirty five years ago. There were powerful forces that wanted open source to lose. Some believed in the open source model but didn‚Äôt think it could ever compete with closed source. Many categories of tools only existed as closed source. A Microsoft CEO called open source cancer‚Äîa decade before Microsoft has rebuilt its empire around it. The open source movement may not have lived up to the ideals of the ‚Äúfree software‚Äù, but it won in industry adoption. Nobody gets fired for choosing open source these days. For much crucial software, open source is now the default.&lt;/p&gt;
    &lt;p&gt;I believe we are at a similar juncture with social apps as we have been with open source thirty five years ago. There‚Äôs a new movement on the block. I like to call it ‚Äúopen social‚Äù. There are competing visions for what ‚Äúopen social‚Äù should be like. I think the AT Protocol created by Bluesky is the most convincing take on it so far. It‚Äôs not perfect, and it‚Äôs a work in progress, but there‚Äôs nothing I know quite like it.&lt;/p&gt;
    &lt;p&gt;(Disclosure: I used to work at Bluesky on the Bluesky client app. I wasn‚Äôt involved in the protocol design. I am a fan, and this post is my attempt to explain why.)&lt;/p&gt;
    &lt;p&gt;In this post, I‚Äôll explain the ideas of the AT Protocol, lovingly called atproto, and how it changes the relationship between the user, the developer, and the product.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt expect atproto and its ecosystem (known as the Atmosphere) to win hearts overnight. Like open source, it might take a few decades to become ubiquitous. By explaining these ideas here, I‚Äôm hoping to slightly nudge this timeline. Despite the grip of today‚Äôs social media companies, I believe open social will eventually seem inevitable in retrospect‚Äîjust like open source does now. Good things can happen; all it takes is years of sustained effort by a community of stubborn enthusiasts.&lt;/p&gt;
    &lt;p&gt;So what is it all about?&lt;/p&gt;
    &lt;p&gt;What open source did for code, open social does for data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Before Social&lt;/head&gt;
    &lt;p&gt;The web is a beautiful invention.&lt;/p&gt;
    &lt;p&gt;You type &lt;code&gt;https://alice.com&lt;/code&gt; and you end up on Alice‚Äôs website.&lt;/p&gt;
    &lt;p&gt;Or you type &lt;code&gt;https://bob.com&lt;/code&gt; and you end up on Bob‚Äôs website.&lt;/p&gt;
    &lt;p&gt;In a sense, your browser is a portal to millions of different worlds, each with its own little jurisdiction. Only Alice decides what appears on Alice‚Äôs website. Only Bob decides what appears on Bob‚Äôs website. They meaningfully ‚Äúown their data‚Äù.&lt;/p&gt;
    &lt;p&gt;This doesn‚Äôt mean that they‚Äôre isolated. On the contrary, Alice can embed Bob‚Äôs picture with an &lt;code&gt;&amp;lt;img src&amp;gt;&lt;/code&gt;, and Bob can link to Alice‚Äôs page with &lt;code&gt;&amp;lt;a href&amp;gt;&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Alice and Bob can link to each other, but they remain in charge of their sites.&lt;/p&gt;
    &lt;p&gt;What do I mean by saying Alice and Bob are in charge of their own sites? Even if they‚Äôre not physically hosting their content on their own computers, they could always change hosting. For example, if Alice‚Äôs hosting provider starts deleting her pages or injecting ads into them, Alice can take her content to another host, and point &lt;code&gt;https://alice.com&lt;/code&gt; at another computer. The visitors won‚Äôt need to know.&lt;/p&gt;
    &lt;p&gt;This is important. Hosting providers have no real leverage over Alice and Bob. If the hosting provider ‚Äúturns evil‚Äù and starts messing with your site, you can just walk away and host it elsewhere (as long as you have a backup). You‚Äôre not going to lose your traffic. All existing links will seamlessly resolve to the new destination.&lt;/p&gt;
    &lt;p&gt;If Alice changes her hosting, Bob won‚Äôt need to update any links to Alice‚Äôs website. Alice‚Äôs site will keep working as if nothing had happened. At worst, a DNS change might make it inaccessible for a few hours, but then the web will be repaired:&lt;/p&gt;
    &lt;p&gt;Imagine how different the incentives would be if links were tied to physical hosts!&lt;/p&gt;
    &lt;p&gt;If changing a hosting provider caused Alice to lose her traffic, she would think many times before changing providers. Perhaps she‚Äôd stick with her existing provider even if it was messing with her site, as losing her connections is even worse. Luckily, web‚Äôs decentralized design avoids this. Because it‚Äôs easy to walk away, hosting providers are forced to compete, and hosting is now a commodity.&lt;/p&gt;
    &lt;p&gt;I think the web is a beautiful idea. It links decentralized islands controlled by different people and companies into one interconnected surface that anyone can index and navigate. Links describe a relationship between logical documents rather than between physical servers. As a result, you‚Äôre not a hostage to your hosting.&lt;/p&gt;
    &lt;p&gt;As a wise person said, in theory, there is no difference between theory and practice, but in practice there is. So what‚Äôs been happening with the web?&lt;/p&gt;
    &lt;head rend="h2"&gt;Closed Social&lt;/head&gt;
    &lt;p&gt;In the early 90‚Äôs, the main way to publish something on the web was to have your own website. Today, most people publish content by using a social media app.&lt;/p&gt;
    &lt;p&gt;Alice and Bob are still publishing things. But instead of publishing at domains like &lt;code&gt;alice.com&lt;/code&gt; and &lt;code&gt;bob.com&lt;/code&gt;, they publish at usernames like &lt;code&gt;@alice&lt;/code&gt; and &lt;code&gt;@bob&lt;/code&gt; allocated by a social media company. The things they publish are not HTML pages, but app-specific entities such as profiles, posts, comments, likes, and so on.&lt;/p&gt;
    &lt;p&gt;These entities are usually stored in a database on the social company‚Äôs servers. The most common way to visualize a database is as a sequence of rows, but you could also visualize it as a graph. This makes it look very similar to web itself:&lt;/p&gt;
    &lt;p&gt;What does this social graph enable that a web of personal sites doesn‚Äôt?&lt;/p&gt;
    &lt;p&gt;The advantage of storing structured app-specific entities, such as posts and likes, instead of HTML documents is obvious. App-specific entities such as posts and likes have a richer structure: you can always turn them into HTML documents later, but you can also aggregate them, filter them, query, sort, and recombine them in different ways before that. This allows you to create many projections of the same data‚Äîa profile page, a list of posts, an individual post with comments.&lt;/p&gt;
    &lt;p&gt;Where this really shines, though, is when many people use the same social app. Since everyone‚Äôs public content is now in a single database, it is easy to aggregate across content published by many people. This enables social features like global search, notifications, feeds, personalized algorithms, shared moderation, etc.&lt;/p&gt;
    &lt;p&gt;It‚Äôs specifically this social aggregation that blows the ‚Äúpersonal sites‚Äù paradigm out of the water. People are social creatures, and we want to congregate in shared spaces. We don‚Äôt just want to visit each other‚Äôs sites‚Äîwe want to hang out together, and social apps provide the shared infrastructure. Social aggregation features like notifications, feeds, and search are non-negotiable in modern social products.&lt;/p&gt;
    &lt;p&gt;Today, the most common way to implement these features is shaped like this:&lt;/p&gt;
    &lt;p&gt;There still exists a web-like logical model of our data‚Äîour profiles, our posts, our follows, our likes, all the things that we‚Äôve created‚Äîbut it lives within some social app‚Äôs database. What‚Äôs exposed to the web are only projections of that model‚Äîthe Home screen, the Notifications screen, the HTML pages for individual posts.&lt;/p&gt;
    &lt;p&gt;This architecture makes sense. It is the easiest way to evolve the ‚Äúpersonal sites‚Äù paradigm to support aggregation so it‚Äôs not surprising today‚Äôs apps have largely converged on it. People create accounts on social apps, which lets those apps build aggregated features, which entices more people to sign up for those apps.&lt;/p&gt;
    &lt;p&gt;However, something got lost in the process. The web we‚Äôre actually creating‚Äîour posts, our follows, our likes‚Äîis no longer meaningfully ours. Even though much of what we‚Äôre creating is public, it is not a part of the open web. We can‚Äôt change our ‚Äúhosting provider‚Äù because we‚Äôre now one step removed from how the internet works. We, and the web we create, have become rows in somebody else‚Äôs database:&lt;/p&gt;
    &lt;p&gt;This creates an imbalance.&lt;/p&gt;
    &lt;p&gt;When Alice used to publish her stuff on &lt;code&gt;alice.com&lt;/code&gt;, she was not tied to any particular hosting provider. If she were unhappy with a hosting provider, she knew that she could swap it out without losing any traffic or breaking any links:&lt;/p&gt;
    &lt;p&gt;That kept the hosting providers in check.&lt;/p&gt;
    &lt;p&gt;But now that Alice publishes her stuff on a social media platform, she can no longer ‚Äúwalk away‚Äù without losing something. If she signs up to another social platform, she would be forced to start from scratch, even if she wants to retain her connections. There is no way for Alice to sever the relationship with a particular app without ripping herself, and anything she created there, out of its social graph:&lt;/p&gt;
    &lt;p&gt;The web Alice created‚Äîwho she follows, what she likes, what she has posted‚Äîis trapped in a box that‚Äôs owned by somebody else. To leave it is to leave it behind.&lt;/p&gt;
    &lt;p&gt;On an individual level, it might not be a huge deal.&lt;/p&gt;
    &lt;p&gt;Alice can rebuild her social presence connection by connection somewhere else. Eventually she might even have the same reach as on the previous platform.&lt;/p&gt;
    &lt;p&gt;However, collectively, the net effect is that social platforms‚Äîat first, gradually, and then suddenly‚Äîturn their backs on their users. If you can‚Äôt leave without losing something important, the platform has no incentives to respect you as a user.&lt;/p&gt;
    &lt;p&gt;Maybe the app gets squeezed by investors, and every third post is an ad. Maybe it gets bought by a congolomerate that wanted to get rid of competition, and is now on life support. Maybe it runs out of funding, and your content goes down in two days. Maybe the founders get acquihired‚Äîan exciting new chapter. Maybe the app was bought by some guy, and now you‚Äôre slowly getting cooked by the algorithm.&lt;/p&gt;
    &lt;p&gt;If your next platform doesn‚Äôt respect you as a user, you might try to leave it, too.&lt;/p&gt;
    &lt;p&gt;But what are you going to do? Will you ‚Äúexport your data‚Äù? What will you do with that lonely shard of a social graph? You can upload it somewhere as an archive but it‚Äôs ripped out of its social context‚Äîa pitiful memento of your self-imposed exile.&lt;/p&gt;
    &lt;p&gt;Those megabytes of JSON you got on your way out are dead data. It‚Äôs like a branch torn apart from its tree. It doesn‚Äôt belong anywhere. To give a new life to our data, we‚Äôd have to collectively export it and then collectively import it into some next agreed-upon social app‚Äîa near-impossible feat of coordination. Even then, the network effects are so strong that most people would soon find their way back.&lt;/p&gt;
    &lt;p&gt;You can‚Äôt leave a social app without leaving behind the web you‚Äôve created.&lt;/p&gt;
    &lt;p&gt;What if you could keep it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;Alice and Bob are still using social apps. Those apps don‚Äôt look much different from today‚Äôs social apps. You could hardly tell that something has changed.&lt;/p&gt;
    &lt;p&gt;Something has changed, though. (Can you spot it?)&lt;/p&gt;
    &lt;p&gt;Notice that Alice‚Äôs handle is now &lt;code&gt;@alice.com&lt;/code&gt;. It is not allocated by a social media company. Rather, her handle is the universal ‚Äúinternet handle‚Äù, i.e. a domain. Alice owns the &lt;code&gt;alice.com&lt;/code&gt; domain, so she can use it as a handle on any open social app. (On most open social apps, she goes by &lt;code&gt;@alice.com&lt;/code&gt;, but for others she wants a distinct disconnected identity, so she owns another handle she‚Äôd rather not share.)&lt;/p&gt;
    &lt;p&gt;Bob owns a domain too, even though he isn‚Äôt technical. He might not even know what a ‚Äúdomain‚Äù is. Bob just thinks of &lt;code&gt;@bob.com&lt;/code&gt; as his ‚Äúinternet handle‚Äù. Some open social apps will offer you a free subdomain on registration, just like Gmail gives you a free Gmail address, or may offer an extra flow for buying a domain. You‚Äôre not locked into your first choice, and can swap to a different domain later.&lt;/p&gt;
    &lt;p&gt;Your internet handle being something you actually own is the most user-visible aspect of open social apps. But the much bigger difference is invisible to the user.&lt;/p&gt;
    &lt;p&gt;When you previously saw the social graph above, it was trapped inside a social app‚Äôs database. There was a box around that graph‚Äîit wasn‚Äôt a part of the web. With open social, Alice‚Äôs data‚Äîher posts, likes, follows, etc‚Äîis hosted on the web itself. Alongside her personal site, Alice now has a personal repository of her data:&lt;/p&gt;
    &lt;p&gt;This ‚Äúrepository‚Äù is a regular web server that implements the AT Protocol spec. The only job of Alice‚Äôs personal repository is to store and serve data created by Alice in the form of signed JSON. Alice is technical, so she likes to sometimes inspect her repo using open source tools like pdsls, Taproot, or atproto-browser.&lt;/p&gt;
    &lt;p&gt;Bob, however, isn‚Äôt technical. He doesn‚Äôt even know that there is a ‚Äúrepository‚Äù with his ‚Äúdata‚Äù. He got a repository behind the scenes when he signed up for his first open social app. His repository stores his data (from all open social apps).&lt;/p&gt;
    &lt;p&gt;Have another look at this picture:&lt;/p&gt;
    &lt;p&gt;These aren‚Äôt rows in somebody‚Äôs database. This is a web of hyperlinked JSON. Just like every HTML page has an &lt;code&gt;https://&lt;/code&gt; URI so other pages can link to it, every JSON record has an &lt;code&gt;at://&lt;/code&gt; URI, so any other JSON record can link to it. (On this and other illustrations, &lt;code&gt;@alice.com&lt;/code&gt; is a shorthand for &lt;code&gt;at://alice.com&lt;/code&gt;.) The &lt;code&gt;at://&lt;/code&gt; protocol is a bunch of conventions on top of DNS, HTTP, and JSON.&lt;/p&gt;
    &lt;p&gt;Now have a look at the arrows between their records. Alice follows Bob, so she has a &lt;code&gt;follow&lt;/code&gt; record linking to Bob‚Äôs &lt;code&gt;profile&lt;/code&gt; record. Bob commented on Alice‚Äôs post, so he has a &lt;code&gt;comment&lt;/code&gt; record that links to Alice‚Äôs &lt;code&gt;post&lt;/code&gt; record. Alice liked his comment, so she has a &lt;code&gt;like&lt;/code&gt; record with a link to his &lt;code&gt;comment&lt;/code&gt; record. Everything Alice creates stays in her repo under her control, everything Bob creates stays in his repo under his control, and links express the connections‚Äîjust like in HTML.&lt;/p&gt;
    &lt;p&gt;All of this happens behind the scenes and is invisibile to a non-technical user. The user doesn‚Äôt need to think about where their data is stored until it matters, just like the user doesn‚Äôt think about how servers work when navigating the web.&lt;/p&gt;
    &lt;p&gt;Alice‚Äôs and Bob‚Äôs repositories could be hosted on the same machine. Or they could be hosted by different companies or communities. Maybe Alice is self-hosting her repository, while Bob uses a free hosting service that came by default with his first open social app. They may even be running completely different implementations. If both servers follow the AT protocol, they can participate in this web of JSON.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;https://alice.com&lt;/code&gt; and &lt;code&gt;at://alice.com&lt;/code&gt; do not need to resolve to the same server. This is intentional so that having a nice handle like &lt;code&gt;@alice.com&lt;/code&gt; doesn‚Äôt force Alice to host her own data, to mess with her website, or even to have a site at all. If she owns &lt;code&gt;alice.com&lt;/code&gt;, she can point &lt;code&gt;at://alice.com&lt;/code&gt; at any server.&lt;/p&gt;
    &lt;p&gt;If Alice is unhappy with her hosting, she can pack up and leave:&lt;/p&gt;
    &lt;p&gt;(This requires a modicum of technical skill today but it‚Äôs getting more accessible.)&lt;/p&gt;
    &lt;p&gt;Just like with moving a personal site, changing where her repo is being served from doesn‚Äôt require cooperation from the previous host. It also doesn‚Äôt disrupt her ability to log into apps and doesn‚Äôt break any links. The web repairs itself:&lt;/p&gt;
    &lt;p&gt;It is worth pausing for a moment to appreciate what we have here.&lt;/p&gt;
    &lt;p&gt;Every bit of public data that Alice and Bob created‚Äîtheir posts, their likes, their comments, their recipes, their scrobbles‚Äîis meaningfully owned by them. It‚Äôs not in a database subject to some CEO‚Äôs whims, but hosted directly on the open web, with ability to ‚Äúwalk away‚Äù without losing traffic or breaking any links.&lt;/p&gt;
    &lt;p&gt;Like the web of personal sites, this model is centered around the user.&lt;/p&gt;
    &lt;p&gt;What does it mean for apps?&lt;/p&gt;
    &lt;p&gt;Each open social app is like a CMS (content management system) for a subset of data that lives in its users‚Äô repositories. In that sense, your personal repository serves a role akin to a Google account, a Dropbox folder, or a Git repository, with data from your different open social apps grouped under different ‚Äúsubfolders‚Äù.&lt;/p&gt;
    &lt;p&gt;When you make a post on Bluesky, Bluesky puts that post into your repo:&lt;/p&gt;
    &lt;p&gt;When you star a project on Tangled, Tangled puts that star into your repo:&lt;/p&gt;
    &lt;p&gt;When you create a publication on Leaflet, Leaflet puts it in your repo:&lt;/p&gt;
    &lt;p&gt;You get the idea.&lt;/p&gt;
    &lt;p&gt;Over time, your repo grows to be a collection of data from different open social apps. This data is open by default‚Äîif you wanted to look at my Bluesky posts, or Tangled stars, or Leaflet publications, you wouldn‚Äôt need to hit these applications‚Äô APIs. You could just hit my personal repository and enumerate all of its records.&lt;/p&gt;
    &lt;p&gt;To avoid naming collisions, the data in the repository is grouped by the format:&lt;/p&gt;
    &lt;p&gt;In any user‚Äôs repo, Bluesky posts go with other Bluesky posts, Leaflet publications go with Leaflet publications, Tangled stars go with Tangled stars, and so on. Each data format is controlled and evolved by developers of the relevant application.&lt;/p&gt;
    &lt;p&gt;I‚Äôve drawn a dotted line to separate them but perhaps this is misleading.&lt;/p&gt;
    &lt;p&gt;Since the data from different apps ‚Äúlives together‚Äù, there‚Äôs a much lower barrier for open social apps to piggyback on each other‚Äôs data. In a way, it starts to feel like a connected multiverse of apps, with data from one app ‚Äúbleeding into‚Äù other apps.&lt;/p&gt;
    &lt;p&gt;When I signed up for Tangled, I chose to use my existing &lt;code&gt;@danabra.mov&lt;/code&gt; handle. That makes sense since identity can be shared between open social apps. What‚Äôs more interesting is that Tangled prefilled my avatar based on my Bluesky profile. It didn‚Äôt need to hit the Bluesky API to do that; it just read the Bluesky profile record in my repository. Every app can choose to piggyback on data from other apps.&lt;/p&gt;
    &lt;p&gt;That might remind you of Gravatar, but it works for every piece of data. Every open social app can take advantage of data created by every other open social app:&lt;/p&gt;
    &lt;p&gt;There is no API to hit, no integrations to build, nothing to get locked out of. All the data is in the user‚Äôs repository, so you can parse it (as typed JSON), and use it.&lt;/p&gt;
    &lt;p&gt;The protocol is the API.&lt;/p&gt;
    &lt;p&gt;This has deep implications for the lifecycle of products. If a product gets shut down, the data doesn‚Äôt disappear. It‚Äôs still in its users‚Äô repos. Someone can build a replacement that makes this data comes back to life. Someone can build a new product that incorporates some of that data, or lets users choose what to import. Someone can build an alternative projection of existing data‚Äîa forked product.&lt;/p&gt;
    &lt;p&gt;This also reduces the ‚Äúcold start‚Äù problem for new apps. If some of the data you care about already exists on the network, you can bootstrap your product off of that. For example, if you‚Äôre launching a short video app, you can piggyback on the Bluesky &lt;code&gt;follow&lt;/code&gt; records so that people don‚Äôt have to find each other again. But if that doesn‚Äôt make sense for your app, you can have your own &lt;code&gt;follow&lt;/code&gt; records instead, or offer a one-time import. All existing data is up for reuse and remixing.&lt;/p&gt;
    &lt;p&gt;Some open social apps are explicitly based around this sort of remixing. Anisota is primarily a Bluesky client, but it natively supports showing Leaflet documents. Popfeed can cross-post reviews to both Bluesky and Leaflet. If Leaflet does get very popular, there‚Äôs nothing stopping Bluesky itself from supporting a Leaflet document as another type of post attachment. In fact, some third-party Bluesky client could decide to do that first, and the official one could eventually follow.&lt;/p&gt;
    &lt;p&gt;This is why I like ‚Äúopen social‚Äù as a term.&lt;/p&gt;
    &lt;p&gt;Open social frees up our data like open source freed up our code. Open social ensures that products can get a new life, that people can‚Äôt be locked out of what they have created, and that products can be forked and remixed. You don‚Äôt need an ‚Äúeverything app‚Äù when data from different apps circulates in the open web.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre technical, by now you might have a burning question.&lt;/p&gt;
    &lt;p&gt;How the hell does aggregation work?!&lt;/p&gt;
    &lt;p&gt;Since every user‚Äôs records live in that user‚Äôs repository, there are millions (potentially billions?) repositories. How can an app efficiently query, sort, filter, and aggregate information from them? Surely it can‚Äôt search them on demand.&lt;/p&gt;
    &lt;p&gt;I‚Äôve previously used a CMS as an analogy‚Äîfor example, a blogging app could directly write posts to your repository and then read posts from it when someone visits your blog. This ‚Äúsingleplayer‚Äù use case would not require aggregation at all.&lt;/p&gt;
    &lt;p&gt;To avoid hitting the user‚Äôs repository every time you want to display their blog post, you can connect to the user‚Äôs repository by a websocket. Every time a record relevant to your app is created, updated, or deleted, you can update your database:&lt;/p&gt;
    &lt;p&gt;This database isn‚Äôt the source of truth for user‚Äôs data‚Äîit‚Äôs more like an app-specific cache that lets you avoid going to the user repo whenever you need some data.&lt;/p&gt;
    &lt;p&gt;Coincidentally, that‚Äôs the exact mechanism you would use for aggregation. You listen to events from all of your app users‚Äô repositories, write them to a local database, and query that database as much as you like with zero extra latency.&lt;/p&gt;
    &lt;p&gt;This might remind you of how Google Reader crawls RSS (rip).&lt;/p&gt;
    &lt;p&gt;To avoid opening a million event socket connections, it makes sense to listen to a stream that retransmits events from all known repositories on the network:&lt;/p&gt;
    &lt;p&gt;You can then filter down such a stream to just the events you‚Äôre interested in, and then update your local database in response to the events your app cares about.&lt;/p&gt;
    &lt;p&gt;For example, Leaflet is only interested in events concerning &lt;code&gt;pub.leaflet.*&lt;/code&gt; records. However, Leaflet can also choose to listen to other events. If Leaflet wanted to add a feature that shows backlinks to Bluesky discussions of a Leaflet document, it would simply start tracking &lt;code&gt;bsky.app.feed.post&lt;/code&gt; records too.&lt;/p&gt;
    &lt;p&gt;You can try it yourself by clicking on this link:&lt;/p&gt;
    &lt;p&gt;This is a realtime stream of every single event on the network. It‚Äôs dominated by &lt;code&gt;app.bsky.*&lt;/code&gt; records because Bluesky is the most-used app, but you can filter it down to other record types. This retransmitter (called a ‚Äúrelay‚Äù) is operated by Bluesky, but you don‚Äôt have to depend on it. The Blacksky community runs their own relay implementation at &lt;code&gt;wss://atproto.africa&lt;/code&gt;, which you can try here.&lt;/p&gt;
    &lt;p&gt;Another important detail is that commits are cryptographically signed, which means that you don‚Äôt need to trust a relay or a cache of network data. You can verify that the records haven‚Äôt been tampered with, and each commit is legitimate.&lt;/p&gt;
    &lt;p&gt;As time goes by, we‚Äôll see more infrastructure built around and for open social apps. Graze is letting users build their own algorithmic feeds, and Slices is an upcoming developer platform that does large-scale repository indexing for you.&lt;/p&gt;
    &lt;p&gt;These are all technical details, though.&lt;/p&gt;
    &lt;p&gt;What matters is the big picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Picture&lt;/head&gt;
    &lt;p&gt;The pre-social web of ‚Äúpersonalized sites‚Äù got data ownership, hosting independence, and linking right. Alice and Bob fully participate in the web:&lt;/p&gt;
    &lt;p&gt;The closed social web innovated in scaling and in social aggregation features. Notifications, search, and feeds are non-negotiable in modern social products:&lt;/p&gt;
    &lt;p&gt;However, the closed social web has also excluded us from the web. The web we create is no longer meaningfully ours. We‚Äôre just rows in somebody else‚Äôs database.&lt;/p&gt;
    &lt;p&gt;Open social frees the web we‚Äôre creating from somebody else‚Äôs boxes. Our profiles, likes, follows, recipes, scrobbles, and other content meaningfully belong to us:&lt;/p&gt;
    &lt;p&gt;The data no longer lives inside the products; the products aggregate over our data:&lt;/p&gt;
    &lt;p&gt;This blurs the boundaries between apps. Every open social app can use, remix, link to, and riff on data from every other open social app.&lt;/p&gt;
    &lt;p&gt;The web we‚Äôve created remains after the products we used to create it are gone. Developers can build new products to recontextualize it. No one can take it away.&lt;/p&gt;
    &lt;p&gt;As more products are built in the open social paradigm, there‚Äôs going to be a shift.&lt;/p&gt;
    &lt;p&gt;People might not ever start using technical concepts like ‚Äúdecentralization‚Äù but they do understand when data from one app can seamlessly flow into other apps.&lt;/p&gt;
    &lt;p&gt;People might not care about ‚Äúfederation‚Äù but they do notice when they log into a competing product, and their data is already there, and their reach is intact.&lt;/p&gt;
    &lt;p&gt;And people do understand when they‚Äôre being fucked with.&lt;/p&gt;
    &lt;p&gt;For a long time, open social will rely on a community of stubborn enthusiasts who see the promise of the approach and are willing to bear the pains of building (and failing) in a new ecosystem. But I don‚Äôt think that dooms the effort. That‚Äôs the history of every big community-driven change. Somebody has to work through the kinks. Like with open source, open social is a compounding effort. Every mildly successful open social app lifts all open social apps. Every piece of shared infrastructure can benefit somebody else. At some point, open is bound to win.&lt;/p&gt;
    &lt;p&gt;I just hope it doesn‚Äôt take thirty five years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388021</guid><pubDate>Fri, 26 Sep 2025 16:01:55 +0000</pubDate></item><item><title>Modular Manifolds</title><link>https://thinkingmachines.ai/blog/modular-manifolds/</link><description>&lt;doc fingerprint="3f8359d1081ca9b1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Modular Manifolds&lt;/head&gt;&lt;p&gt;When we train large neural networks, we need to keep them healthy. We do not want the tensors in the network‚Äîeither the weights, activations or gradients‚Äîto grow too large or too small. Very small and very large tensors cause a variety of problems not just limited to numerical underflow and overflow. For example, weight matrices changing size during training makes it harder to design training algorithms‚Äîsince the relative size of updates to weights has a significant impact on the speed of learning.&lt;/p&gt;&lt;p&gt;The gold standard for keeping tensors healthy is to normalize them. Normalization is commonplace for activation vectors, where we use techniques like layer norm to put the activations on a good scale before passing them to the next layer. It is also commonplace to normalize gradient updates, where we can interpret fast training algorithms like the Muon optimizer as spectrally normalizing the updates. Normalization provides us with certainty about the sizes of tensors‚Äîwithout needing to check Wandb!‚Äîand when training large neural networks with many interacting components, having certainty about the network internals is valuable.&lt;/p&gt;&lt;p&gt;Normalization is less commonly applied to weight matrices, although it is not unheard of. For example, the EDM2 diffusion model codebase uses weight constraints and the authors report benefits in their paper. And BiT uses weight standardization. Various other techniques have been proposed but are not common practice in modern large-scale training.For some more examples, see Salimans et al, 2016, Miyato et al, 2018 and our paper Liu et al, 2021. Normalizing the weight matrices might be a good idea for a few reasons. Weight constraints make understanding the relative size of optimization updates easier. They remove the problem of weight norms exploding. They allow us to focus hyperparameter tuning effort on tensors whose size matters most. They can force matrices to have a small condition number, making their behaviour more predictable. And relatedly, weight constraints facilitate Lipschitz guarantees for robustness to perturbations.&lt;/p&gt;&lt;p&gt;This post covers one appealing way to constrain the weight matrices of a neural network‚Äîby keeping the tensors constrained to submanifolds at each layer. This opens the door to re-thinking optimization, as we can co-design optimization algorithms with these manifold constraints. As an example, we proposeThis algorithm builds on work from Jianlin Su and Franz Louis Cesista, as discussed further below. a manifold version of the Muon optimizer whose weights are constrained to the Stiefel manifold: the manifold of matrices with unit condition number. We conclude the post by defining the idea of a modular manifold, which is a composable manifold that attempts to make it easier to scale up and train large networks.&lt;/p&gt;&lt;p&gt;Our goal in writing this post is to provide an introduction to a research area that we are excited about, and highlight many directions for future work. We would love to see more work from the community on the topics mentioned at the end of the post!&lt;/p&gt;&lt;head rend="h2"&gt;The shape of a manifold optimizer&lt;/head&gt;&lt;p&gt;This section works through the simplest example of learning on a manifold: a vector parameter constrained to a hypersphere in $\mathbb{R}^d$. The vector parameter is trained to minimize a loss function defined over the full space $\mathbb{R}^d$. This setup might be useful for, say, individual embedding vectors in a transformer model. This section will be a good warmup for the following section on manifold Muon that considers matrix parameters.&lt;/p&gt;&lt;p&gt;We will not be too formal about the definition of a manifold here: it is enough to understand that a manifold is a curved surface that looks flat when you zoom in close enough. The locally flat approximation at a point on the manifold is called the tangent space to the manifold, as visualized in Figure :&lt;/p&gt;&lt;p&gt;We can characterize the hypersphere in $d$ dimensions as the set of points $w \in \mathbb{R}^d$ of unit Euclidean norm. And the tangent space at a point $w$ on the hypersphere is the set of all vectors $a \in \mathbb{R}^d$ that are orthogonal to $w$.&lt;/p&gt;&lt;p&gt;To keep the weights constrained to the manifold, we could use a non-manifold optimizer and just project the weights back to the manifold after each step. Instead, we are interested in designing methods that take steps in the tangent space. The reason is that we would like to be able to equate the learning rate of our optimizer with the actual length of the optimization step. But if the optimization steps are pointing significantly off manifold and then being projected back, this nice property does not hold. Similar motivation is given in Section 2.3 of the EDM2 paper.&lt;/p&gt;&lt;p&gt;Before we can design a training algorithm for this manifold, something important we need to decide on is how to measure distanceFor a manifold to be ‚ÄúRiemannian‚Äù, the distance measure must be induced by an inner product. The Euclidean ($\ell_2$) norm is induced by an inner product, but the Manhattan ($\ell_1$) distance is not. in the tangent space. A common choice is the Euclidean distance, but we could also choose to measure distance in other ways, as visualized in Figure . In the next section, we will talk about choosing a distance measure based on the functionality of the module.&lt;/p&gt;&lt;p&gt;Crucially, the choice of distance measure changes the direction of the best optimization step. If the distance measure is non-Euclidean, then for a fixed length step, we may be able to move further in the direction of the gradientBy gradient, we mean the partial derivative of the loss with respect to the weights. Mathematicians reserve the term gradient for something else in Riemannian geometry. by not following the gradient direction exactly! This concept is visualized in Figure .&lt;/p&gt;&lt;p&gt;To see how this works out in math, we can formulate the optimal update direction given a manifold constraint and a distance measure as itself solving a constrained optimization problem. We will demonstrate this for the case of the hypersphere equipped with the Euclidean norm. Letting $g$ denote the gradient, $w$ the current point on the hypersphere, $a$ the update direction and $\eta$ the learning rate, we need to solve:&lt;/p&gt;$$\min_{a\in\mathbb{R}^d} \quad \underbrace{a^\top g\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|a\|_2 = \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{a^\top w = 0\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{tangent constraint}}}.\tag{$\star$}$$&lt;p&gt;Mapping back to the visual language of Figures , and , this formula says that the green arrow (optimal value of $a$) must belong to the red tangent hyperplane ($a^\top w = 0$) and must also lie on a yellow circle of radius $\eta$ ($\|a\|_2 = \eta$). To solve $(\star)$, we can apply the method of Lagrange multipliers. The relevant Lagrangian function is given by:&lt;/p&gt;$$\mathcal{L}(a, \lambda, \mu) = a^\top g + \frac{\lambda}{2} \cdot (a^\top a - \eta) + \mu \cdot (a^\top w),$$&lt;p&gt;where $\lambda$ and $\mu$ are Lagrange multipliers. Setting the derivative of the Lagrangian with respect to $a$ to zero and applying the constraints to solve for $\lambda$ and $\mu$, the optimal update $a_\mathrm{opt}$ ends up being given by the following formula:&lt;/p&gt;$$a_\mathrm{opt} = - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}.$$&lt;p&gt;In words, the optimal update is given by subtracting out the radial component from the gradient, normalizing and multiplying by the learning rate. Since this update lies in the tangent space, actually a very smallFor a learning rate $\eta$, the effect of the retraction map is $\mathcal{O}(\eta^2)$ small, so the learning rate almost equals the length of the step. correction is needed to stay on the manifold. The correction is known as a ‚Äúretraction map‚Äù and is visualized in Figure :&lt;/p&gt;&lt;p&gt;We can solve for the retraction map by applying Pythagoras‚Äô theorem to Figure . For a unit hypersphere and a step of length $\eta$, the hypotenuse has length $\sqrt{1+\eta^2}$ and therefore the retraction map for the hypersphere equipped with the Euclidean norm is simply given by dividing the updated weights through by $\sqrt{1+\eta^2}$. Putting everything together, the full manifold optimization algorithm is then given by:&lt;/p&gt;$$w \gets \frac{1}{\sqrt{1+\eta^2}} \left[w - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}\right].$$&lt;p&gt;As an exercise for the reader: try calculating the Euclidean norm of the updated weight vector and check that the updated weight vector indeed lies on the hypersphere.&lt;/p&gt;&lt;p&gt;To summarize this section, a first-order manifold optimizer has three steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Find the tangent vector of unit length that goes furthest in the gradient direction.&lt;/item&gt;&lt;item&gt;Multiply this direction by the learning rate and subtract from the weights;&lt;/item&gt;&lt;item&gt;Retract the updated weights back to the manifold.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;There are two decisions to make in applying this procedure: what manifold constraint we should use and how we should measure length. By making different decisions, we can generate different optimization algorithms as shown in the following table.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Manifold&lt;/cell&gt;&lt;cell role="head"&gt;Norm&lt;/cell&gt;&lt;cell role="head"&gt;Optimizer&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;vanilla gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;infinity norm&lt;/cell&gt;&lt;cell&gt;sign gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;hypersphere $S^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;hyperspherical descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;matrix space $\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;Muon&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Stiefel manifold $\subset\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;manifold Muon&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;We will derive the final algorithm in the table, manifold Muon, in the next section. To design a manifold constraint and a distance function for a matrix parameter, we shall think carefully about the role that a weight matrix plays inside a neural network.&lt;/p&gt;&lt;head rend="h2"&gt;Manifold Muon&lt;/head&gt;&lt;p&gt;A typical weight matrix $W$ in a transformer is a ‚Äúvector-multiplier‚Äù, meaning that it transforms an input vector $x$ into an output vector $y = Wx$. We will design a manifold constraint and a distance function so that the matrix acts in a good way on input vectors: the matrix should not produce excessively small or large outputs, and updates to the matrix should not cause the output vector to change too much or too little.&lt;/p&gt;&lt;p&gt;A good way to think about how a matrix acts on vectors is through the singular value decomposition, illustrated in Figure . The SVD decomposes a matrix in a way that tells us how the matrix stretches input vectors along different axes.&lt;/p&gt;&lt;p&gt;We would like the matrix to have a stretching effect close to one, so we will choose a matrix manifold where all the singular values are exactly one. This matrix manifold is known formally as the Stiefel manifold. We can assume without loss of generality that we are dealing with a tall matrix ($m \geq n$), and then the Stiefel manifold can be equivalently defined as the following set:&lt;/p&gt;$$\mathsf{Stiefel}(m,n) := \left\{ W \in \mathbb{R}^{m \times n} \mid W^T W = I_n \right\}.$$&lt;p&gt;Furthermore, one may show that a matrix $A \in \mathbb{R}^{m \times n}$ lies tangentNotice that the Stiefel constraint $W^T W = I_n$ directly generalizes the hyperspherical constraint $w^\top w = 1$ from the previous section. Similarly, the tangent space condition generalizes the hyperspherical one that $a^\top w = 0$. to the Stiefel manifold at matrix $W$ if and only if:&lt;/p&gt;$$A^\top W + W^\top A = 0.$$&lt;p&gt;To design a manifold optimizer for the Stiefel manifold, all that remains is to choose a distance function. To limit the maximum stretching effect the weight update can have on an input vector, we will choose the spectral norm, which measures the largest singular value of a matrix. Although this only limits the maximum effect the update can have, since the optimizer we derive will saturate this bound, it will turn out to prevent the minimum effect of the update from being too small.There are some exceptions to this statement, such as when a weight matrix has a fan-out less than its fan-in, in which case we cannot escape from the matrix and its updates having a null space and mapping some inputs to zero.&lt;/p&gt;&lt;p&gt;The idea of doing gradient descent under a spectral norm constraint is what led to the Muon optimizer and, when combined with the Stiefel manifold constraint, we obtain a problem that we shall call manifold Muon:&lt;/p&gt;$$\min_{A\in\mathbb{R}^{m\times n}} \quad \underbrace{\operatorname{trace}(G^T A)}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|A\|_{\text{spectral}} \leq \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{A^T W + W^T A = 0\vphantom{\|A\|_{\text{spectral}} = \eta}}_{\mathclap{\text{tangent constraint}}} \tag{$\dagger$}.$$&lt;p&gt;The manifold Muon problem $(\dagger)$ directly generalizes problem $(\star)$ from the previous section. Solving $(\dagger)$ is harder than solving $(\star)$, and here we will present a numerical solution inspiredI figured out how to solve manifold Muon in the square case late last year, but I was unable to solve the full rectangular case and thus posed the problem as an open problem on the Modula docs. Jianlin Su solved the problem this summer by taking a Lagrangian approach and working out a fixed point iteration on the optimality condition. I saw an early version of Jianlin‚Äôs work (which did not quite work yet) and also related work by Franz Louis Cesista, and I was able to work out the dual ascent algorithm presented here. by work done by Jianlin Su and Franz Louis Cesista.&lt;/p&gt;&lt;p&gt;Our key insight is that $(\dagger)$ is a convex optimization problem that may be solved via a standard method known as dual ascent. Here we will just sketch the main idea, but you can find a more detailed derivation on this page.&lt;/p&gt;&lt;p&gt;Similar to Jianlin‚Äôs approach, we introduce a matrix of Lagrange multipliers $\Lambda\in\mathbb{R}^{n\times n}$. We then apply a series of transformations to convert the problem $(\dagger)$ from a constrained minimization problem to an unconstrained maximization problem:&lt;/p&gt;$$ \begin{align} (\dagger) &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda} \;\operatorname{trace} G^\top A + \operatorname{trace}\Lambda^\top (A^\top W + W^\top A) \\ &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda}\; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \min_{\|A\|_\mathrm{spectral} \leq \eta} \; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \; - \eta \times \|G + 2W(\Lambda+\Lambda^\top)\|_\mathrm{nuclear}. \end{align} $$&lt;p&gt;Equation (1) reformulates the problem as a saddle point problem: the maximization over $\Lambda$ will send the objective to infinity whenever the tangent space condition is violated. Equation (2) follows by applying properties of the trace and equation (3) follows from Sion‚Äôs minimax theorem. The inner minimization in equation (3) is solved by setting $A_\mathrm{opt}(\Lambda) = - \eta \times \operatorname{msign}(G + 2W(\Lambda+\Lambda^\top))$ where $\operatorname{msign}$ is the matrix sign function.The matrix sign function snaps the singular values of a matrix to one. It may be computed efficiently on GPUs via Newton-Schulz iteration or the recent Polar Express algorithm. And we obtain equation (4) by substituting this expression for $A_\mathrm{opt}(\Lambda)$ into equation (3). Equation (4) is known as the ‚Äúdual problem‚Äù to $(\dagger)$ and we can solve it by gradient ascent. After some work, the gradient of the dual function is given by:&lt;/p&gt;$$ \begin{align} H(\Lambda) &amp;amp;:= - \eta \times \nabla_\Lambda \|G + W (\Lambda+\Lambda^\top)\|_\mathrm{nuclear} \\ &amp;amp;= - \eta \times [W^\top\mathrm{msign}(G + 2W (\Lambda+\Lambda^\top)) + \operatorname{msign}(G + 2W (\Lambda+\Lambda^\top))^\top W], \end{align} $$&lt;p&gt;where the nuclear norm $\|\cdot\|_\mathrm{nuclear}$ measures the sum of the singular values of a matrix.&lt;/p&gt;&lt;p&gt;Finally, we can write down the manifold Muon algorithm:Note that this algorithm is closely related to Jianlin Su‚Äôs solution. Where we run dual ascent, Jianlin‚Äôs solution amounts to solving for the maximum of the dual function $H(\Lambda)=0$ via a fixed point iteration.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Run gradient ascent on the dual variable $\Lambda \gets \Lambda + \alpha \times H(\Lambda)$ to solve for $\Lambda_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Compute the update $A_\mathrm{opt} = - \eta \times \operatorname{msign}(G + 2W(\Lambda_{\mathrm{opt}}+\Lambda_\mathrm{opt}^\top))$.&lt;/item&gt;&lt;item&gt;Apply the update to the weights $W \gets W + A_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Retract the weights back to the manifold $W \gets \operatorname{msign}(W)$.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We ran a very small experiment to sanity check the algorithm and provide a minimal implementation for students or researchers to play with. Each training run finishes in less than a minute. The code is here and see Figure for the setup and results.&lt;/p&gt;&lt;head rend="h2"&gt;Modular manifolds&lt;/head&gt;&lt;p&gt;So far in this post, we have discussed manifold constraints for individual parameter tensors and co-designed optimization logic for these constraints. A question we have not answered is: what happens when we combine layers to build networks? Can we think about individual layers in isolation‚Äîor do we need to be careful about interactions between layers and modify the optimization logic in response? The goal of this section is to point out that there is a way to extend the reasoning we introduced in the previous two sections to the case of whole networks, and we call this the theory of modular manifolds.The theory of modular manifolds builds on research I did with my friend Tim Large, my postdoc advisor Phillip Isola, my PhD advisor Yisong Yue and many other amazing collaborators. At the end of the section, we provide some links to learn more.&lt;/p&gt;&lt;p&gt;The idea of modular manifolds is to build an abstraction that tells us how to budget learning rates across layers. The actual optimization logic in each layer ends up being the same as what we already worked out, except that the learning rate for a layer is modified depending on where the layer appears in the network. The abstraction rests upon a key observation made in our paper on the modular norm, that budgeting learning rates‚Äîboth across layers and when scaling up individual layers‚Äîis intimately tied to understanding the Lipschitz sensitivity of the network output with respect to the weights. The abstraction tracks this sensitivity as we build the network, and manifold constraints help us get a much tighter understanding of this sensitivity.&lt;/p&gt;&lt;p&gt;The starting point for the abstraction is to think of any neural network module‚Äîfrom a layer to a whole transformer‚Äîas a mathematical object with three attributes:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;A forward function $f:\mathcal{W} \times \mathcal{X} \to \mathcal{Y}$ that maps from a parameter space $\mathcal{W} = \mathbb{R}^d$ and an input space $\mathcal{X}$ to an output space $\mathcal{Y}$.&lt;/item&gt;&lt;item&gt;A submanifold of the weight space $\mathcal{M}\subset\mathcal{W}$ that the weights are constrained to.&lt;/item&gt;&lt;item&gt;A norm $\|\cdot\| : \mathcal{W} \to \mathbb{R}$ that acts as a measuring stick on weight space.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For example, a linear module equipped with the spectral norm and constrained to the Stiefel manifold, for which we have already worked out an optimizer, would be written:&lt;/p&gt;$$ \mathsf{StiefelLinear} = \begin{cases}(W, x) \mapsto Wx, &amp;amp; \text{(forward function)}\\ \mathsf{Stiefel}(m,n), &amp;amp; \text{(manifold)}\\ \|\cdot\|_\mathrm{spectral}. &amp;amp; \text{(norm)}\end{cases}$$&lt;p&gt;Provided that an input $x$ to the $\mathsf{StiefelLinear}$ module has unit $\ell_2$ norm, then $\mathsf{StiefelLinear}$ is Lipschitz with respect to its weights in the module‚Äôs assigned norm with Lipschitz constant one:This argument can be extended to the RMS norm on the input and the RMS‚ÄìRMS operator norm on the weights.&lt;/p&gt;$$\|(W + \Delta W) x - Wx\|_2 \leq \|\Delta W\|_\mathrm{spectral} \times \|x\|_2 = \|\Delta W\|_\mathrm{spectral}.$$&lt;p&gt;This type of Lipschitz statement helps us understand how to scale weight updates to this module since it gives us a bound on how much the output can change when we perturb the weights. But when we compose two modules, can we automatically compile a Lipschitz statement on the joint weight space of the new module? The answer turns out to be yes, if we follow special rules for building the new module:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;The new forward function $f_3$ is given by composing the two existing forward functions $f_1$ and $f_2$: $$f_3((w_1, w_2), x) := f_2(w_2, f_1(w_1, x)). \qquad$$&lt;/item&gt;&lt;item&gt;The new manifold constraint $\mathcal{M}_3$ is just the Cartesian product (see Figure for a fun example) of the two existing manifolds $\mathcal{M}_1$ and $\mathcal{M}_2$: $$\mathcal{M}_3 = \mathcal{M}_1 \times \mathcal{M}_2. \qquad$$&lt;/item&gt;&lt;item&gt;The new norm function is the max of the two existing norm functions weighted by special scalar coefficients $s_1$ and $s_2$. Letting $\|\cdot\|_1$ denote the first module‚Äôs norm and $\|\cdot\|_2$ denote the second module‚Äôs norm, the new norm $\|\cdot\|_3$ is given by: $$\|(w_1, w_2)\|_3 := \max(s_1\cdot \|w_1\|_1, s_2\cdot \|w_2\|_2). \qquad$$&lt;/item&gt;&lt;/list&gt;&lt;p&gt;When we use this composite norm to derive optimizers‚Äîfollowing the same recipe we used in the first two sections of this post‚Äîwe end up deriving separate optimizers for each layer, but the scalar coefficients $s_i$ budget the learning rates across layers.&lt;/p&gt;&lt;p&gt;We give much more detail on this construction, including extending it to other ways of combining modules, in our paper on the modular norm‚Äîalthough the paper does not cover manifold optimization. You can also check out our paper on modular duality for more on building optimizers in the modular norm. The Modula project builds toward a programmatic implementation of this construction.&lt;/p&gt;&lt;head rend="h2"&gt;Directions for future work&lt;/head&gt;&lt;p&gt;We are excited about any research that tries to make neural network training as principled and automatic as the forward pass. The ideas in this post benefitted strongly from interactions with external researchers like Jianlin Su and Franz Louis Cesista. We would love to see more work on these topics from the community.&lt;/p&gt;&lt;p&gt;Some possible directions for future work are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Modularity. What manifolds should attention heads live on? Should embeddings be constrained differently than unembeddings? We can mix-and-match constraints in different parts of the network, or leave some tensors unconstrained.&lt;/item&gt;&lt;item&gt;Numerics. Manifold constraints also place constraints on the range of values that individual weight entries can take. Does this impact numerics, or make low-precision training easier?&lt;/item&gt;&lt;item&gt;Convex optimization. The manifold Muon algorithm involves running dual ascent. Can we apply more sophisticated convex optimization techniques to solve the dual problem faster or more reliably?&lt;/item&gt;&lt;item&gt;Convergence analysis. How fast do these algorithms converge? Does good conditioning of the weight matrices benefit convergence? Is there more that we can say theoretically?&lt;/item&gt;&lt;item&gt;Regularization. Manifold constraints implicitly regularize the model. Could we design constraints or tune their radii to improve generalization?&lt;/item&gt;&lt;item&gt;Architecture-optimizer co-design. While hard manifold constraints may not ultimately be the right way to constrain weight matrices, they exemplify the idea of tightly co-designing optimization algorithms with architecural components. Are there more opportunities here?&lt;/item&gt;&lt;item&gt;Non-Riemannian geometry. Most work on manifold optimization works in a Riemannian world where distances are induced by inner products and norm balls are ellipsoids. But neural networks are different: matrices act as operators, and operator norms like the spectral norm do not emerge from inner products. This implies, for example, that norm balls can have sharp corners and there is no unique gradient flow. Is there more to be discovered in this non-Riemannian world?&lt;/item&gt;&lt;item&gt;Practical implementation. Applying these techniques at scale requires efficient manifold operations on GPUs. The recent Polar Express paper shows promise for fast matrix sign computation. What other algorithmic innovations do we need?&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Further reading&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Manifold optimization. Absil, Mahony &amp;amp; Sepulchre‚Äôs textbook is a standard reference. For the Stiefel manifold specifically, see Edelman et al, 1998. These works live in a Riemannian world. Similarly most machine learning papers that consider optimization on the Stiefel manifold take a Riemannian point of view: see Li et al, 2020, Kong et al, 2022 and Park et al, 2025 for some examples.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Non-Riemannian geometry in machine learning. Thomas Flynn‚Äôs paper from 2017 on duality structure gradient descent characterizes the neural network weight space as a Finsler manifold, meaning a manifold equipped with a norm. It is well worth a read. Also see Jianlin Su‚Äôs recent blog post on Stiefel Muon as well as Franz Louis Cesista‚Äôs blog post on a heuristic solution to Muon on the Stiefel manifold. Franz also wrote a followup blog post generalizing the solution presented here. The Scion paper imposes weight constraints a different way via convex combinations and Carlson et al, 2015 wrote an early paper on (unconstrained) spectral descent.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The Modula project. The goal of the Modula project is to build a library that automatically compiles steepest descent optimizers along with Lipschitz statements for general architectures. Check out the project page at https://modula.systems as well as our paper on the modular norm and modular duality. Our optimization anthology also provides an accessible route into this space of ideas.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Lipschitz-constrained deep learning. There has been a lot of work on this topic. For example, check out Louis B√©thune and Tsui-Wei Weng‚Äôs PhD theses. Usually work on this topic does not connect weight-Lipschitzness to optimizer design. See also Anil et al, 2018 and our paper Newhouse et al, 2025.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Citation&lt;/head&gt;&lt;p&gt;Please cite this work as:&lt;/p&gt;&lt;code&gt;Jeremy Bernstein, "Modular Manifolds",
Thinking Machines Lab: Connectionism, Sep 2025.
&lt;/code&gt;&lt;p&gt;Or use the BibTeX citation:&lt;/p&gt;&lt;code&gt;@article{bernstein2025manifolds,
  author = {Jeremy Bernstein},
  title = {Modular Manifolds},
  journal = {Thinking Machines Lab: Connectionism},
  year = {2025},
  note = {https://thinkingmachines.ai/blog/modular-manifolds/},
  doi = {10.64434/tml.20250926}
}
&lt;/code&gt;
    
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388728</guid><pubDate>Fri, 26 Sep 2025 17:06:48 +0000</pubDate></item><item><title>Suno Studio, a Generative AI DAW</title><link>https://suno.com/studio-welcome</link><description>&lt;doc fingerprint="536fd5a56c585c00"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00 /&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388822</guid><pubDate>Fri, 26 Sep 2025 17:17:54 +0000</pubDate></item><item><title>SimpleFold: Folding proteins is simpler than you think</title><link>https://github.com/apple/ml-simplefold</link><description>&lt;doc fingerprint="dd791d51782a9c92"&gt;
  &lt;main&gt;
    &lt;p&gt;This github repository accompanies the research paper, SimpleFold: Folding Proteins is Simpler than You Think (Arxiv 2025).&lt;/p&gt;
    &lt;p&gt;Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Joshua M. Susskind, Miguel Angel Bautista&lt;/p&gt;
    &lt;p&gt;We introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer layers. SimpleFold does not rely on expensive modules like triangle attention or pair representation biases, and is trained via a generative flow-matching objective. We scale SimpleFold to 3B parameters and train it on more than 8.6M distilled protein structures together with experimental PDB data. To the best of our knowledge, SimpleFold is the largest scale folding model ever developed. On standard folding benchmarks, SimpleFold-3B model achieves competitive performance compared to state-of-the-art baselines. Due to its generative training objective, SimpleFold also demonstrates strong performance in ensemble prediction. SimpleFold challenges the reliance on complex domain-specific architectures designs in folding, highlighting an alternative yet important avenue of progress in protein structure prediction.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;simplefold&lt;/code&gt; package from github repository, run&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
conda create -n simplefold python=3.10
python -m pip install -U pip build; pip install -e .
&lt;/code&gt;
    &lt;p&gt;If you want to use MLX backend on Apple silicon:&lt;/p&gt;
    &lt;code&gt;pip install mlx==0.28.0
pip install git+https://github.com/facebookresearch/esm.git
&lt;/code&gt;
    &lt;p&gt;We provide a jupyter notebook &lt;code&gt;sample.ipynb&lt;/code&gt; to predict protein structures from example protein sequences.&lt;/p&gt;
    &lt;p&gt;Once you have &lt;code&gt;simplefold&lt;/code&gt; package installed, you can predict the protein structure from target fasta file(s) via the following command line. We provide support for both PyTorch and MLX (recommended for Apple hardware) backends in inference.&lt;/p&gt;
    &lt;code&gt;simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend 
&lt;/code&gt;
    &lt;p&gt;We provide predicted structures from SimpleFold of different model sizes:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)
&lt;/code&gt;
    &lt;p&gt;We use the docker image of openstructure 2.9.1 to evaluate generated structures for folding tasks (i.e., CASP14/CAMEO22). Once having the docker image enabled, you can run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]
&lt;/code&gt;
    &lt;p&gt;To evaluate results of two-state prediction (i.e., Apo/CoDNaS), one need to compile the TMsore and then run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5
&lt;/code&gt;
    &lt;p&gt;You can also train or tune SimpleFold on your end. Instructions below include details for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;SimpleFold is trained on joint datasets including experimental structures from PDB, as well as distilled predictions from AFDB SwissProt and AFESM. Target lists of filtered SwissProt and AFESM targets thta are used in our training can be found:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)
&lt;/code&gt;
    &lt;p&gt;In &lt;code&gt;afesme_dict.json&lt;/code&gt;, the data is stored in the following structure:&lt;/p&gt;
    &lt;code&gt;{
    cluster 1 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    ...
}
&lt;/code&gt;
    &lt;p&gt;Of course, one can use own customized datasets to train or tune SimpleFold models. Instructions below list how to process the dataset for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;To process downloaded mmcif files, you need Redis installed and launch the Redis server:&lt;/p&gt;
    &lt;code&gt;wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777
&lt;/code&gt;
    &lt;p&gt;You can then process mmcif files to input format for SimpleFold:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly
&lt;/code&gt;
    &lt;p&gt;The configuration of model is based on &lt;code&gt;Hydra&lt;/code&gt;. An example training configuration can be found in &lt;code&gt;configs/experiment/train&lt;/code&gt;. To change dataset and model settings, one can refer to config files in &lt;code&gt;configs/data&lt;/code&gt; and &lt;code&gt;configs/model&lt;/code&gt;. To initiate SimpleFold training:&lt;/p&gt;
    &lt;code&gt;python train experiment=train
&lt;/code&gt;
    &lt;p&gt;To train SimpleFold with FSDP strategy:&lt;/p&gt;
    &lt;code&gt;python train_fsdp.py experiment=train_fsdp
&lt;/code&gt;
    &lt;p&gt;If you found this code useful, please cite the following paper:&lt;/p&gt;
    &lt;code&gt;@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;Our codebase is built using multiple opensource contributions, please see ACKNOWLEDGEMENTS for more details.&lt;/p&gt;
    &lt;p&gt;Please check out the repository LICENSE before using the provided code and LICENSE_MODEL for the released models.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389267</guid><pubDate>Fri, 26 Sep 2025 18:01:26 +0000</pubDate></item><item><title>Auth.js is now part of Better Auth</title><link>https://www.better-auth.com/blog/authjs-joins-better-auth</link><description>&lt;doc fingerprint="ea4da1989f2d5ce"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôre excited to announce that Auth.js, formerly known as NextAuth.js, is now being maintained and overseen by Better Auth team. If you haven't heard of Auth.js, it has long been one of the most widely used open source authentication libraries in the JavaScript ecosystem. Chances are, if you‚Äôve used ChatGPT, Google Labs, Cal.com or a million other websites, you‚Äôve already interacted with Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;Back Story about Better Auth and Auth.js&lt;/head&gt;
    &lt;p&gt;Before Better Auth, Auth.js gave developers like us the ability to own our auth without spending months wrestling with OAuth integrations or session management. But as applications became more complex and authentication needs evolved, some of its limitations became harder to ignore. We found ourselves rebuilding the same primitives over and over.&lt;/p&gt;
    &lt;p&gt;The Auth.js team recognized these challenges and had big ideas for the future, but for various reasons couldn‚Äôt execute them as fully as they hoped.&lt;/p&gt;
    &lt;p&gt;That shared frustration and the vision of empowering everyone to truly own their auth started the creation of Better Auth. Since our goals aligned with the Auth.js team, we were excited to help maintain Auth.js and make auth better across the web. As we talked more, we realized that Better Auth was the best home for Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does this mean for existing users?&lt;/head&gt;
    &lt;p&gt;We recognize how important this project is for countless applications, companies, and developers. If you‚Äôre using Auth.js/NextAuth.js today, you can continue doing so without disruption‚Äîwe‚Äôll keep addressing security patches and urgent issues as they come up.&lt;/p&gt;
    &lt;p&gt;But we strongly recommend new projects to start with Better Auth unless there are some very specific feature gaps (most notably stateless session management without a database). Our roadmap includes bringing those capabilities into Better Auth, so the ecosystem can converge rather than fragment.&lt;/p&gt;
    &lt;p&gt;For teams considering migration, we‚Äôve prepared a guide and we‚Äôll be adding more guides and documentation soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;We are deeply grateful to the Auth.js community who have carried the project to this point. In particular, the core maintainers-Bal√°zs, who served as lead maintainer, Thang Vu,Nico Domino, Lluis Agusti and Falco Winkler-pushed through difficult phases, brought in new primitives, and kept the project alive long enough for this transition to even be possible.&lt;/p&gt;
    &lt;p&gt;Better Auth beginning was inspired by Auth.js, and now, together, the two projects can carry the ecosystem further. The end goal remains unchanged: you should own your auth!&lt;/p&gt;
    &lt;p&gt;For the Auth.js team's announcement, see GitHub discussion.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389293</guid><pubDate>Fri, 26 Sep 2025 18:04:29 +0000</pubDate></item><item><title>Oral Microbes Linked to 3-Fold Increased Risk of Pancreatic Cancer</title><link>https://nyulangone.org/news/oral-microbes-linked-increased-risk-pancreatic-cancer</link><description>&lt;doc fingerprint="f790e1a3620b8701"&gt;
  &lt;main&gt;
    &lt;p&gt;Among the hundreds of species of bacteria and fungi that live in people‚Äôs mouths, 27 have been collectively tied to a 3.5 times greater risk of developing pancreatic cancer, a study led by NYU Langone Health and its Perlmutter Cancer Center shows.&lt;/p&gt;
    &lt;p&gt;Experts have long observed that those with poor oral health are more vulnerable to pancreatic cancer than those with healthier mouths. More recently, scientists have uncovered a mechanism that could help explain this connection, finding that bacteria can travel through swallowed saliva into the pancreas, an organ that helps with digestion. However, precisely which species may contribute to the condition had until now remained unclear.&lt;/p&gt;
    &lt;p&gt;Published online September 18 in JAMA Oncology, the new analysis assessed the genetic makeup of microbes collected from the saliva of 122,000 healthy men and women.&lt;/p&gt;
    &lt;p&gt;‚ÄúOur findings provide new insight into the relationship between the oral microbiome and pancreatic cancer,‚Äù said study lead author Yixuan Meng, PhD, a postdoctoral fellow in the Department of Population Health at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;The oral microbiome, the diverse community of bacteria and fungi that inhabit the mouth, is increasingly being studied for its potential role in human health.&lt;/p&gt;
    &lt;p&gt;Last year, the same team of scientists uncovered a link between certain oral bacteria and a heightened risk of developing head and neck squamous cell carcinoma, a group of cancers that arise in the mouth and throat. The researchers had also conducted a small study in 2016 that tied microbes living in the mouth to pancreatic cancer, but could not identify precise bacterial species.&lt;/p&gt;
    &lt;p&gt;Their latest report is the largest and most detailed analysis of its kind to date, says Dr. Meng. It is also the first to show that oral fungi‚Äînamely a type of yeast in the genus Candida that naturally lives on the skin and throughout the body‚Äîmay play a role in pancreatic cancer. The researchers also identified these oral Candida species in patients‚Äô pancreatic tumors.&lt;/p&gt;
    &lt;p&gt;For the study, the team assessed data from two ongoing investigations tracking Americans from across the country to better understand how diet, lifestyle, medical history, and many other factors are involved in cancer. The data were gathered for the American Cancer Society Cancer Prevention Study II and the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial.&lt;/p&gt;
    &lt;p&gt;Shortly after enrolling, participants rinsed with mouthwash, providing saliva samples that preserved the numbers and species of microbes for testing. Researchers then followed up for roughly nine years on average to record any presence of tumors.&lt;/p&gt;
    &lt;p&gt;In the current study, the investigators analyzed bacterial and fungal DNA from the spit samples. Then, they identified 445 patients who were diagnosed with pancreatic cancer and compared the DNA of their microbes with that of another 445 randomly selected study subjects who had remained cancer-free. The team made sure to account for factors known to play a role in developing the condition, such as age, race, and how often subjects smoked cigarettes.&lt;/p&gt;
    &lt;p&gt;The findings identified 24 species of bacteria and fungi that individually either raised or lowered pancreatic cancer risk. Another three kinds of bacteria tied to the cancer were already known to contribute to periodontal disease, a serious gum infection that can eat away at the jawbone and the soft tissues surrounding teeth.&lt;/p&gt;
    &lt;p&gt;Altogether, the entire group of microbes boosted participants‚Äô chances of developing the cancer by more than threefold.&lt;/p&gt;
    &lt;p&gt;In addition, by assessing the makeup of each participant‚Äôs oral microbiome, the scientists for the first time developed a tool that could estimate their cancer risk.&lt;/p&gt;
    &lt;p&gt;‚ÄúBy profiling bacterial and fungal populations in the mouth, oncologists may be able to flag those most in need of pancreatic cancer screening,‚Äù said study co-senior author Jiyoung Ahn, PhD, a professor in the Departments of Population Health and Medicine at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;Dr. Ahn, who is also the associate director for population sciences at Perlmutter Cancer Center, notes that there are currently few effective screening methods for the disease, which is among the deadliest forms of cancer.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt is clearer than ever that brushing and flossing your teeth may not only help prevent periodontal disease but may also protect against cancer,‚Äù said study co-senior author Richard Hayes, DDS, MPH, PhD, a professor in the Department of Population Health.&lt;/p&gt;
    &lt;p&gt;Dr. Hayes, who is also a member of Perlmutter Cancer Center, emphasizes that the study was designed to identify correlations between disease risk and certain microbes in the mouth, but not to establish a direct cause-and-effect link. That will require further investigation.&lt;/p&gt;
    &lt;p&gt;The research team next plans to explore whether oral viruses could contribute to cancer and how the mouth‚Äôs microbiome may affect patients‚Äô chances of survival, adds Hayes.&lt;/p&gt;
    &lt;p&gt;Funding for the study was provided by National Institutes of Health grants P30CA016087, P20CA252728, R01LM014085, R01CA159036, and U01CA250186.&lt;/p&gt;
    &lt;p&gt;Along with Dr. Meng, Dr. Hayes, and Dr. Ahn, other NYU Langone researchers involved in the study are Feng Wu, PhD; Soyoung Kwak, PhD; Chan Wang, PhD; Tamas A. Gonda, MD; Paul E. Oberstein, MD; and Huilin Li, PhD.&lt;/p&gt;
    &lt;p&gt;Other study co-investigators include Mykhaylo Usyk, PhD, at Albert Einstein College of Medicine in New York City; Neal Freedman, PhD, and Wen-Yi Huang, PhD, at the National Cancer Institute in Rockville, Maryland; and Caroline Um, PhD, at the American Cancer Society in Atlanta.&lt;/p&gt;
    &lt;head rend="h2"&gt;About NYU Langone Health&lt;/head&gt;
    &lt;p&gt;NYU Langone Health is a fully integrated health system that consistently achieves the best patient outcomes through a rigorous focus on quality that has resulted in some of the lowest mortality rates in the nation. Vizient Inc. has ranked NYU Langone number one out of 118 comprehensive academic medical centers across the nation for four years in a row, and U.S. News &amp;amp; World Report recently ranked four of its clinical specialties No. 1 in the nation. NYU Langone offers a comprehensive range of medical services with one high standard of care across seven inpatient locations, its Perlmutter Cancer Center, and more than 320 outpatient locations in the New York area and Florida. With $14.2 billion in revenue this year, the system also includes two tuition-free medical schools, in Manhattan and on Long Island, and a vast research enterprise.&lt;/p&gt;
    &lt;head rend="h3"&gt;Media Inquiries&lt;/head&gt;
    &lt;p&gt;Shira Polan&lt;lb/&gt; Phone: 212-404-4279&lt;lb/&gt; Shira.Polan@NYULangone.org&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389464</guid><pubDate>Fri, 26 Sep 2025 18:20:33 +0000</pubDate></item><item><title>If you are harassed by lasers</title><link>https://www.laserpointersafety.com/harassment.html</link><description>&lt;doc fingerprint="76c29116b4a1179f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Home&lt;/head&gt;
    &lt;head rend="h2"&gt;A comprehensive resource for safe and responsible laser use&lt;/head&gt;
    &lt;head rend="h1"&gt;If you are harassed by lasers&lt;/head&gt;
    &lt;head rend="h3"&gt;If the light is obviously coming from a laser&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple harassment -- a beam on your skin or clothes -- is probably not punishable unless it continues, or unless it occurs during a critical situation such as driving.&lt;/item&gt;
      &lt;item&gt;Deliberate aiming at your head or eyes is serious due to the unlikely but possible potential for causing eye damage. This could be considered as assault. For more on eye damage, see the information on when does a laser pointer get powerful enough to be dangerous.&lt;/item&gt;
      &lt;item&gt;If you have had laser light in your eyes, see the page If you are hit by a laser.&lt;/item&gt;
      &lt;item&gt;A partial list of laser harassment incidents is here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, here is a case in 2018 of a visible green laser harassing a number of people at least five times over two weeks. The laser can easily be seen and photographed:&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see laser beams or dots in a photo or video&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The green and blue "laser" dots at lower left are actually lens flare caused by the bright sun at upper right. The sun is reflecting off elements inside the lens, causing dots or flare. The flare is almost always located diagonally mirrored from a bright light source.&lt;lb/&gt;Photo of a sunset, with upper and lower "beams" caused by blooming in the camera sensor.&lt;lb/&gt;This is a still frame from a video taken at night by the driver of a moving car, out their driver-side window. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The line on the left is a trail of a flying insect, not a laser beam. It is a curved, short line segment. If it was a laser beam it would be straight and it would not stop in mid-air like this. Plus note that the path is not aimed at the camera or the house. Even if it was a laser beam, it would not hit anyone in the house on the right where the camera is. &lt;/p&gt;
    &lt;p&gt;Click on the picture below to see video of a lens flare which looks remarkably like a laser. However, it is definitely a lens flare; there are many clues as to why it is actually the sun in the upper right reflecting off the inside of camera elements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Lens flare example video (click to start)Why this is not a laser: 1) The green dot does not illuminate or interact with the ground. 2) It looks like an overlay. 3) It moves diagonally opposite to the bright light source (sun), always perfectly tracking it. Example courtesy M.L., Sept. 2021. Taken with a Samsung A10 phone's rear camera.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a case described below (in "A few cases and emails we received"), a woman reported a uniform blue tint on her Blink security camera. The tint was not caused by a laser, but by a flaw in the camera or perhaps a lens effect.&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see light or feel heat from an unknown source&lt;/head&gt;
    &lt;head rend="h4"&gt;Light&lt;/head&gt;
    &lt;p&gt;If you see light that is not from any obvious source, try blocking it. Visible laser light can be blocked by anything that also blocks conventional light, such as a solid curtain, a wall, or even a sheet of paper.&lt;/p&gt;
    &lt;p&gt;If you do see flashes when all external light paths are blocked, consult your doctor or do an internet search. There can be medical conditions that cause flashes.&lt;/p&gt;
    &lt;p&gt;The author of this page has seen "flocks of birds" in daytime and "falling stars" at night. It turned out to be minor retinal detachment that went away. This is one reason the author is sympathetic to people who experience sensations that are 100% real to them, even if the sensations come from inside their bodies.&lt;/p&gt;
    &lt;head rend="h4"&gt;Heat&lt;/head&gt;
    &lt;p&gt;If you feel heat spots, first try to block them, to see if they are coming from outside your body. Try using metal objects such as aluminum foil, a baking sheet or a cast-iron skillet. Hold the material over the area where you are having heat or pain, to see if it goes away.&lt;/p&gt;
    &lt;p&gt;If you continue to feel heat, consult your doctor or do an Internet search. There can be medical conditions that cause localized and/or intermittent feelings of being hot, such as fibromyalgia.&lt;/p&gt;
    &lt;head rend="h4"&gt;Get evidence and/or others to confirm&lt;/head&gt;
    &lt;p&gt;If you want to try and track down the beams, get photographic and/or video evidence if at all possible. Ideally this would be pictures of the beams or the laser "dot", and also pictures of any damage. Note the section above about how photos can have lens flare, sensor blooming or other things internal to the camera.&lt;/p&gt;
    &lt;p&gt;If you have family or friends who can help, ask them to stay with you or stay at your house. If others can confirm what you are seeing or feeling, then they can help you in finding the reasons why.&lt;/p&gt;
    &lt;p&gt;A number of people who contacted us, also contacted their local police. In all cases, the police either investigated but took no action, or declined to investigate. One person said their local police department no longer handled calls involving lasers.&lt;/p&gt;
    &lt;p&gt;It may be helpful to hire a private investigator. They can look into suspicious behavior and evidence, and can try to confirm reports of burn marks, burning sensations, etc. If police action is warranted, the police may take a licensed private investigator more seriously than an ordinary citizen. But beware of unscrupulous private investigators who may claim to help you, but who will only string you along to keep making money off you.&lt;/p&gt;
    &lt;head rend="h3"&gt;If the harassment seems mysterious, ongoing, or well-organized&lt;/head&gt;
    &lt;p&gt;These persons clearly feel effects. But their symptoms are often inexplicable by normal means. For example, they can feel heat on their skin which they believe is from beams going through solid walls. There are some types of electromagnetic radiation, such as terahertz waves and microwaves, which can go through objects. But visible laser light ‚Äî which is also electromagnetic radiation ‚Äî is stopped by any material or substance that would also stop conventional light such as from a flashlight.&lt;/p&gt;
    &lt;head rend="h4"&gt;You are not alone ‚Ä¶&lt;/head&gt;
    &lt;p&gt;If you are a person plagued by mysterious, unknown causes, the good news is you are not alone. At LaserPointerSafety.com, we used to get calls every month or two from persons who say they are being continually harassed by light and energy beams. (We no longer take such calls, due to their frequency and our inability to solve such mysterious cases.)&lt;/p&gt;
    &lt;p&gt;Clearly these people and you are seeing and feeling something. We understand you are not imagining your sensations ‚Äî they are real to you.&lt;/p&gt;
    &lt;head rend="h4"&gt;‚Ä¶ but the cause is unknown&lt;/head&gt;
    &lt;p&gt;But the bad news is that what you are feeling usually does not have any plausible physical explanation. This means it is very unlikely that mysterious beams or exotic devices are able to cause your symptoms.&lt;/p&gt;
    &lt;p&gt;It is highly unlikely that ordinary persons can buy or otherwise obtain powerful directed energy beams that go through walls. Such devices are exotic and expensive. Even if someone works for the police or military, this would not be regular issue "take home" equipment.&lt;/p&gt;
    &lt;p&gt;Also, there is usually no reason that your neighbors would undertake a prolonged, continual, and expensive attack against you. (Frankly, if they did want to harass or harm you, there are easier and less costly ways to do so.)&lt;/p&gt;
    &lt;p&gt;If you are having such symptoms, the cause, in our view, is most likely something that has gone wrong in your body.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be your nerves are misfiring, leading you to see light or feel heat when there is no external source. [In experiments published in 2007, subjects had low-level laser light shined on a rubber hand that was positioned over their own hand. Sixty-six percent of subjects reported heat or tactile sensations from the laser light ‚Äî even though 1) the light was on a rubber hand, not their own and 2) the laser power was low enough that it would not noticeably heat up even on a real hand.]&lt;/item&gt;
      &lt;item&gt;If you are seeing flashes of light at night, or dark swarms (like a flock of birds) during the daytime in your peripheral vision, this can be due to retinal detachment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be something in your brain that is manufacturing false symptoms and/or feelings of being stalked or harassed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are feeling harassed by inexplicable causes, we advise that you see one or more medical specialists such as neurologists. Describe your symptoms to the doctor without going into detail about the potential cause (beams) or reasons (angry neighbors). You can tell the doctor "it feels like this is coming from outside my body" but concentrate on describing the symptoms of what you are experiencing physically and mentally.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a medical reason is found for your issues, this is reassuring that you are not a victim of organized harassment. Hopefully you can be treated and the sensations will go away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If there is no medical reason initially found, keep in mind that does not mean that the alternative explanation (angry neighbors are getting exotic beam weapons and aiming them at you) is true. It may be there is a deeper or unknown medical reason. Again, other people have reported similar symptoms, so there must be some common underlying cause in the body or mind.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more information, see the section below "An example case - trying to help a friend".&lt;/p&gt;
    &lt;head rend="h3"&gt;Be careful not to escalate the situation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In a 2018 case, a man in Arkansas shot and killed a neighbor who, among other harassments, had allegedly aimed red, blue and green lasers into his house. When the neighbor went to pick up a laser pointer, the man thought it was a gun and killed him in claimed self-defense. (The man was acquitted by a jury of first-degree murder charges.)&lt;/item&gt;
      &lt;item&gt;In the example case of "H" which is listed below, a woman who believes her neighbors are harassing her with light and heat beams is going around to their homes with a loaded gun, looking for the source. This may not end well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whatever the level of harassment, let law enforcement look into it and (hopefully) solve the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few cases and emails we received&lt;/head&gt;
    &lt;p&gt;NOTE: As of September 1 2023, we no longer take calls or reply to emails about heat lasers, strange dots or lines in photos &amp;amp; videos, or "mysterious, ongoing or well-organized" harassments as described above.&lt;lb/&gt; We do sympathize with those experiencing such issues. The most help we can give is to let people know that others have reported similar experiences, so they are not alone. The cases listed below occurred prior to Sept. 1 2023.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; An example case - "H" is trying to help a friend&lt;/item&gt;
      &lt;item rend="dd-1"&gt;We were contacted by a person we'll call "H", who was trying to help her friend "F" of 30 years.&lt;lb/&gt;About two months before the call, H's friend suddenly (over a period of a few weeks) started seeing mysterious lights and feeling mysterious heat. This is an especially interesting case since:&lt;lb/&gt;1) F was "normal" for decades before this started.&lt;lb/&gt;2) The symptoms that F describes are very common among other people who have contacted us.&lt;lb/&gt;3) H has spent substantial time with F, looking for logical, rational explanations for what F said she was experiencing.&lt;lb/&gt;F at first thought harassing beams were coming from the cable company so the cable wiring was replaced. This did not help. F then thought it was coming from the home security company; that was not the cause. F replaced her ceiling fan since she thought she saw faces in it. Her windows are covered with heavy blankets yet light or heat beams still somehow get in, according to F.&lt;lb/&gt;There are numerous security cameras around F's house but so far she has not captured anyone coming up to the house. Unfortunately, she has started going to neighbors' homes ‚Äî with a loaded gun ‚Äî looking for the source. This of course could escalate into a dangerous situation.&lt;lb/&gt;H said there was no apparent cause for F to start seeing lights and feeling heat. F had some traumatic life events such as deaths of close family members, in the two years prior to onset. But there was no single event or physical trauma that corresponded with the start of F's symptoms.&lt;lb/&gt;H has tried to help her friend. For example, H and her husband went to F's home for 16 hours, staying awake through the night and going outside from time to time to look for any unusual activity. They saw and felt nothing abnormal. (F was asleep the entire time so she did not report any strange sightings or feelings during the time H and her husband were there.)&lt;lb/&gt;The police have been at F's home numerous times. But they have not found anything and cannot help further. The FBI was contacted but did not get involved.&lt;lb/&gt;We advised H to have her friend see medical specialists such as a neurologist. F should describe the symptoms (what she is seeing and feeling) without stating that it is coming from the outside.&lt;lb/&gt;We also said that the medical exams and tests may not turn up anything. This is based on our experience where we have never had a person call us back, saying "Oh, the doctor found I had ABC disease" or "It stopped when I started taking XYZ medication."&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Email #1 - Laser harassment 24/7&lt;/item&gt;
      &lt;item rend="dd-2"&gt;&lt;code&gt;We live across the street from a neighbor who has her laser lights on 24 hrs/7days a week. She shines her laser lights in other neighbors faces, heads, at children, family pets, windows of houses, plants and trees (which are singed from being over exposed/burned by laser lights), aircraft, on our parked vehicles, &amp;amp; vehicles driving down the street. When I have been in the front yard my eyes and face start burning from the lasering. The police have been called several times, but state that they cannot do anything.&lt;/code&gt;&lt;code&gt;Here are pictures of the laser attacks:&lt;/code&gt;&lt;code&gt;Do you have any suggestions on how to go about getting this individual to stop harassing &amp;amp; terrorizing us?&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;You described your eyes and face burning when in your front yard. It would take a very powerful and expensive laser to do this. A simple laser pointer would not be able to create heat on your skin at a long distance such as across a yard. The most powerful handheld laser currently available [summer 2010] is the 1-watt Wicked Laser Arctic. It can burn skin but at a very close distance, and the burn is very small such as the size of a pea or less.&lt;lb/&gt;You also stated that various surfaces were singed. Again, it would take a very, very powerful and VERY expensive laser to do this. It is very hard to imagine any use outside of military or police (riot control), and even these are exceedingly rare.&lt;lb/&gt;One way to tell if a laser is being used against you is to see if it only happens when you are in line with a window or similar opening to the outdoors. This is because walls will stop laser beams, but windows can let light through. (Of course, windows also let through sunlight and heat (infrared), so just being warm next to a window can be caused by normal, non-laser reasons.)&lt;lb/&gt;Both photos that you sent have a vertical line that goes through a strong light in the photo. This straight line is NOT a laser. It is an artifact of how some digital cameras work. If there is a light source that is too strong for the camera's digital chip, then all pixels in the same vertical line will be overwhelmed. This is called blooming. You can read more about blooming here.&lt;lb/&gt;One question I have for you is whether you have seen laser beams with your own eyes (not from a camera's video). I am guessing the answer is "no".&lt;lb/&gt;I do not want to say absolutely, positively 100% that there is no laser activity from your neighbor's house. The world is very large, and every now and then there are strange things. However, I am 99.999% sure that there is no laser activity from your neighbor's house. Certainly the photos you have sent depict the blooming effect that is very common on some digital camera chips. There is no doubt that what is in the photos is NOT laser. The other effects you state, such as heating and singeing, are highly, extremely unlikely to be caused by any type of laser that a residential person would have access to or could afford.&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Email #2 - Lasers cause pinpoint holes&lt;/item&gt;
      &lt;item rend="dd-3"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;I have been getting burned for now about a year. I have been finding burn holes in my mini-blinds. My dog I have found burn holes on her skin also, Is there anything I can do ? It is really painful and I think they did this so I had to sell my home because I felt that my life was in danger I would be walking in the house and then I would get this burning sensation in my eyes and then I would fell my arms would be burning didn't matter what side of the house I was at I would get burned, I would tell people and they would say that's weird.&lt;/code&gt;&lt;code&gt;So I sold my home because I feel they chased me out by hurting me and my dog. I think they even killed some kittens with this laser flashlight. I am writing to you cause no one help me or those kitten that didn't make or had a chance, I think there should be a law against this it is really scary and painful. Thank you for having this information on the internet and maybe it can help someone.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;It is very difficult to use a laser to create holes at long range (more than a few yards or meters). It also requires a very expensive laser, to have enough power to make holes at long range. I would not know why someone would go to this trouble.&lt;lb/&gt;If what you are seeing is small, pinpoint holes, it is highly unlikely that these are from a laser aimed at a distance. Laser beams do spread out, even a little bit. For example, the beam at the aperture (output opening) of a powerful laser might be very small. This might be a few millimeters or up to 1/4" in diameters, and the edge of the hole would be sharp. At a house-to-house distance, the hole might be the size of a quarter at least, and the edges might be more ragged, with burn or scorch marks around the hole.&lt;lb/&gt;If a person is walking around with a hand-held laser (laser pointer or battery-powered laser), then they could get close enough to make small holes or burn marks. For a laser pointer, this takes a LOT of power and is expensive. I do not know why someone would do this. (If they wanted to cause trouble, there are a lot of ways that are more effective, much less expensive, and also hard-to-trace.)&lt;lb/&gt;It is possible for the laser beam to be invisible to our eyes. Infrared lasers have beams which we can't normally see. However, you can use a camcorder to try to see these beams. To try this, point the camcorder at an infrared remote control, which are very common for TVs, etc. When you press a button on the remote control, you should see a light flash in the camcorder viewfinder (but not with your eyes). If your camcorder can see the infrared light, then you should be able to see infrared laser beams using the camcorder's viewfinder or fold-out monitor.&lt;lb/&gt;If someone is using a laser in the way you describe, this is illegal. It is damaging your property, cruelty to animals, and assault &amp;amp; battery. You could call the police -- but you should be sure that you really do have evidence.&lt;lb/&gt;For your own sensations of burning, you may also want to consult a doctor or do research on the Internet. There are some conditions where you may experience burning due to something internal in your body.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; Email #3 - Some suggestions from a person saying they were harassed&lt;/item&gt;
      &lt;item rend="dd-4"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;When I read the two stories of people getting harassed by laser pointers, I thought I was reading about my own story.&lt;/code&gt;&lt;code&gt;I was also getting harassed by our neighbor. We complained to the police as well, but we got no help. Both me and my husband saw the green dots, still the authorities were not convinced. It's very difficult to film, since he changed locations from the window and could see us if we try to film or take picture. We finally moved from there and thought it would be over but to our dismay it continued in the second home. We moved in the same area, it was not far enough.&lt;/code&gt;&lt;code&gt;So, I started to do the research about laser pointers and their health risks on people. Here are a couple of suggestions: First, go to your Home Depot or Lowes and get a mirrored privacy film and stick it to your windows. Make sure your windows are completely covered. This will at least give you day time privacy and if they point the laser pointer at it they will get twice as much effect on themselves. Second, do not close your house completely. Leave your windows a crack open, because depending on the type of laser and its strength, all lasers emit radiation. The radiation further dries skin and increase the burning, and does not help in healing. Third, use coconut oil to moisturize skin. And, last, get as many humidifiers and run them until there is enough moisture in the house. This will negate the effects of radiation plus it will provide you with a relief from burning. I hope this helps. Good luck!&lt;/code&gt;&lt;code&gt;Finally, thank you for printing those articles, I thought I was alone. It is helpful to read what other people are going through.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;We have found a few people who, even if they moved to a different state, still said they had symptoms of being harassed by lasers. It is more likely that there is something about the person -- some medical or perhaps brain condition -- which is causing the symptoms. We urge such persons to get a medical exam and to stress to the doctor that you really are feeling these sensations (heat, etc.).&lt;lb/&gt;We are printing the information above because it may help others.&lt;list rend="ul"&gt;&lt;item&gt;The suggestion about privacy film is good. If a problem is being caused by visible light lasers, then light-blocking curtains, shades or films will eliminate the problem. You can also simply go into a room without windows or other openings to the outside, and see if the symptoms go away. Visible-light lasers, with a dot or beam that you can see, will be blocked by walls or other light-blocking material. It is theoretically possible that an infrared laser's energy might go through a lightweight material, but even here, putting a wall between you and a suspected laser source would block the infrared light. Note that reflective privacy film will NOT reflect the laser back to a perpetrator. This could only happen if the laser hits the film at an exact 90¬∞ angle, both side-to-side and up-and-down.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The point about radiation is not really accurate. Lasers do emit "radiation" -- electromagnetic radiation such as visible, infrared or ultraviolet light. Lasers available to the general public do not emit higher-energy nuclear radiation such as X-rays or gamma rays. Leaving windows open will not have any effect on light or radiation. For example, even a beam of X-rays will not somehow "build up" in a house. This is like saying leaving your oven on at 200 degrees will build up heat until an hour or two later it is 2000 degrees ‚Äî not true.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The suggestions about coconut oil and humidifiers may help. If you do feel burning sensations, using a cream or having extra moisture in the air could be beneficial.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Telephone call - Blue light on Blink camera&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In late 2020, a woman called saying that an unfriendly neighbor may be aiming a blue laser at persons in her driveway. The people did not see any blue light or blue flash, but a Blink security camera had blue images when the persons were in the driveway.&lt;lb/&gt;Before going to the police, she sent photos showing the normal security camera view, and the blue-tinted view. Here is a portion of the photos:&lt;lb/&gt;The normal camera view&lt;lb/&gt;When the "laser" was on ‚Äî a uniform blue tint (it turned out not to be caused by a laser)The photos clearly show it was not a laser. The tint is uniform, whereas a laser hitting the camera would cause a bright spot or complete whiteout or blueout of the camera image. Also, the tint is steady. A handheld laser from across the street would flash in the camera, since the neighbor could not hold the laser completely steady. (Even most tripods would not be 100% steady from such a distance ‚Äî there would be some brightness fluctuation.)&lt;lb/&gt;There were other indications as well that this was not a laser. The camera was the only evidence of unusual activity. No person saw laser dots or beams. The blue tint occurred only during the day; usually laser harassment is at dusk or night.&lt;lb/&gt;It turns out that Blink cameras can have a blue tint under certain circumstances as discussed here and here. None of these seemed to apply to the woman's situation ‚Äî it was not cold, nor snowy. The tint occurred only at certain times or when there was a person in the view. And yet the cause had to be with the camera or perhaps the lens (e.g., angle to the sun at certain times).&lt;lb/&gt;We recommended that she swap out the driveway Blink camera for one of the other Blink cameras on her property. This could help decide if the blue tint was due to a problem in the camera or perhaps due to the sun being at a certain angle when looking at the driveway view.&lt;lb/&gt;Either way, the blue tint was not caused by a laser. This put her mind at ease and prevented an unnecessary trip to the police.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;More information about mysterious or ongoing attacks&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; Why would ordinary citizens be targeted?&lt;/item&gt;
      &lt;item rend="dd-1"&gt;It seems unlikely that directed energy devices would be available or affordable to ordinary persons who want to harass other persons. Or whether such devices would be used by the government against ordinary citizens who don‚Äôt have vital state secrets.&lt;lb/&gt;We cannot help with issues about non-visible lasers or directed energy devices. However, below are links to resources which may be of interest to persons who feel they are deliberately targeted by mysterious devices.&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Links about covert harassment and directed energy devices&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The first two resources have links to other websites, organizations and videos of interest (too many links to list here). Thanks to Jeannie for her help with this list.&lt;list rend="ul"&gt;&lt;item&gt;People Against Covert Torture &amp;amp; Surveillance, International From their home page: ‚ÄúPACTS, International is a support network for those targeted with organized stalking and remote electronic assaults, also known as electronic harassment. Electronic harassment in this context refers to the use of radio frequencies and other methods to remotely access a person's mind and/or body to gain control of the individual or group of persons.‚Äù Much of the information at their site is in links to their newsletter, such as this newsletter page.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The "Stop Gangstalking Awareness Group", and especially this page about "Understanding Neuro Weapons." LaserPointerSafety has not evaluated the accuracy or usefulness of this group or their information. (Thanks to M.D. in July 2024 for bringing this to our attention.)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The 2015 Covert Harassment Conference in Berlin. This contains videos and a list of the program; the material is in English. There was also a 2014 Covert Harassment Conference.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A 2002 presentation by Dr. Reinhard Munzert, ‚ÄúTargeting the Human with Directed Energy Weapons‚Äù, here and here among other places.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The book "The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought" by Dr. Doug Beason, physicist, a Fellow of the American Physical Society, and former Chief Scientist for the USAF Space Command. From Amazon: "After more than two decades of research, the United States is on the verge of deploying a new generation of weapons that discharge light-wave energy, the same spectrum of energy found in your microwave, or in your TV remote control. It's called directed energy -- lasers, high-powered microwaves, and particle beams. And it's a revolution in weaponry, perhaps, more profound than the atomic bomb. The E-Bomb author Doug Beason, a leading expert in directed-energy research, describes in clear and jargon-free prose all of these exotic new weapons."&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A July 19 2019 article in the Military Times entitled "Pentagon scientists are making talking plasma laser balls for use as non-lethal weapons" describes how lasers can be used for "heating up a target‚Äôs skin to extremely uncomfortable levels without burning them, blasting confusing noises or giving voice commands such as, 'Stop or we‚Äôll be forced to fire upon you.'" As of the article date, the talking plasma ball distance involved is currently within "the short range of a laboratory setting", with a goal of 100 meters to multiple kilometers. (Note that it is unlikely that such lasers are being used outside of military applications; for example, by one neighbor upon another neighbor. Also, it is not known if such lasers could cause effects through solid walls.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Mysterious Cuba attacks - microwaves or a "shared functional disorder"?&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Persons who feel they have been targeted by mysterious enemies with directed energy devices may want to consider the case of the U.S. diplomats in Cuba afflicted by "Havana syndrome."&lt;lb/&gt;In August 2017, reports came out that numerous U.S. diplomats serving in Cuba had been affected by mysterious ‚Äúacoustic attacks.‚Äù Symptoms included hearing a buzzing sound, having headaches, hearing loss, balance issues and nausea. CBS News reported ‚Äúmild traumatic brain injuries and possible damage to the central nervous system as a result of the attacks.‚Äù&lt;lb/&gt;The question is whether Cuba targeted diplomats with an actual device, whether it was caused by pesticides or other untargeted source ‚Ä¶ or whether this may have been "mass hysteria." According to a report in Newsweek:&lt;lb/&gt;‚ÄúMass hysteria is the rapid spread of illness symptoms for which there is no organic cause,‚Äù [Robert] Bartholomew [author of a book on the topic] told Newsweek. ‚ÄúIt happens in normal, healthy people‚Äîit‚Äôs not just ‚Äòall in their heads‚Äô because they do experience symptoms.‚Äù&lt;lb/&gt;Jon Stone, a neurologist from the University of Edinburgh first consulted for the Guardian article, agrees. ‚ÄúTo consider this diagnostic possibility properly you have to strip away its negative connotations. The symptoms experienced in outbreaks of ‚Äòmass hysteria‚Äô are genuine and not faked or imaginary,‚Äù he told Newsweek.&lt;lb/&gt;Stone argues that the term "mass hysteria" itself sounds sensational and far-fetched. In reality, it is not as uncommon as you might think. He explains: ‚Äú‚ÄòMass hysteria‚Äô is so laden with negativity, it badly distorts its own case. It suggests shrieking and raving individuals‚Äînot hard-working and normal people who mostly get functional disorders in everyday practice.‚Äù&lt;lb/&gt;A better, less stigmatizing term, says Stone, is ‚Äúshare functional disorder.‚Äù He defines the condition as a genuinely experienced illness, ‚Äúin which there is some disturbance of bodily functioning which conventional diagnostic techniques fail to register.‚Äù&lt;lb/&gt;There are interesting parallels with Havana syndrome and persons reporting unexplained laser harassment.&lt;lb/&gt;Similarities&lt;lb/&gt;In the Cuba case, around 25 U.S. diplomats, and 14 Canadian diplomats ‚Äî persons who would be considered reliable and rational ‚Äî reported hearing mysterious sounds and began having unusual, unexplained health problems. There have been numerous studies conducted by the U.S., Canada, Cuba, that as of early 2020 have not definitively established any cause. Experts are even divided on whether there is any physical change in the brains of the affected persons.&lt;lb/&gt;In laser harassment cases, numerous persons ‚Äî most of whom sound reliable and rational when we talk with them ‚Äî report seeing lights and feeling heat from mysterious sources. Police, friends, family and medical experts trying to help them have been unable to find a cause. The only thing that is certain is the persons have genuine symptoms that are not faked or imaginary. To others, there may be no rational explanation ‚Äî but the symptoms are genuinely experienced.&lt;lb/&gt;Differences&lt;lb/&gt;One difference between the Cuba case and persons reporting unexplained laser harassment is that the latter are widely scattered. In Cuba there is the possibility of all the diplomats being exposed to the same causal factor (still unknown but possibly sound or pesticides). But persons reporting laser harassment are widely scattered across the U.S. and Canada. Perhaps there is a common cause within the environment.&lt;lb/&gt;Also, the definition of mass psychogenic illness or "mass hysteria" almost always occurs in a relatively small group of people living or working together. This is true for the Cuba cases. But in the laser harassment cases, victims are again widely scattered and do not know, interact, or correspond (e.g. Internet) with each other.&lt;lb/&gt;December 2020 update ‚Äî microwaves&lt;lb/&gt;A study by the National Academies of Science concluded that the cause was likely microwave energy that may not have been deliberately targeting the diplomats in Cuba. According to an NBC News story quoting the study, "The committee felt that many of the distinctive and acute signs, symptoms and observations reported by (government) employees are consistent with the effects of directed, pulsed radio frequency (RF) energy. Studies published in the open literature more than a half-century ago and over the subsequent decades by Western and Soviet sources provide circumstantial support for this possible mechanism.‚Äù&lt;lb/&gt;From the news story:&lt;lb/&gt;The study examined four possibilities to explain the symptoms: Infection, chemicals, psychological factors and microwave energy.&lt;lb/&gt;‚ÄúOverall, directed pulsed RF energy ‚Ä¶ appears to be the most plausible mechanism in explaining these cases among those that the committee considered. ... The committee cannot rule out other possible mechanisms and considers it likely that a multiplicity of factors explains some cases and the differences between others.‚Äù&lt;lb/&gt;The report says more investigation is required.&lt;lb/&gt;Summary&lt;lb/&gt;LaserPointerSafety.com we are not aware of microwave directing devices that an ordinary citizen could purchase to cause problems for neighbors. It may be possible for a technically minded person to buy or modify devices and beam microwaves at other persons. But we are not experts in microwaves so we cannot give any more advice or opinion.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; An email about directed energy weapons: Are we naive?&lt;/item&gt;
      &lt;item rend="dd-4"&gt;We received the following email in July 2019. It has been slightly edited for clarity and to avoid identifying information.&lt;code&gt;I just read your article on lasers and questions people emailed to you, all were very interesting.&lt;/code&gt;&lt;code&gt;In reading these it appeared to me most of these questions were based on Directed Energy Weapons - DEW (Microwave) rather than the laser beams per se. (i.e., laser beam in a pilots eyes).&lt;/code&gt;&lt;code&gt;I strongly disagree with you on the Cuban episode. First of all, I found your answer very naive, and I'm not trying to be mean, its just that you haven't done your homework on how those hell bent on hurting others obtain these military weapons! It's called Black Market, the Mexican Cartel (Sinanola or El Chapo) drug organization buy these DEW by the truck load from (hate to say this) crooked defense companies.&lt;/code&gt;&lt;code&gt;In turn these military weapons are given out like Hershey bars to Stalkers (MS-13) the large white van pulls up and delivers them right in your neighborhood purchased by the Cartel. Its big business. I'm assuming the Cuban government more than likely purchased these DEW weapons to threaten and hurt the Americans working in Cuba.&lt;/code&gt;&lt;code&gt;I keep reminding those that don't understand this Mexican Cartel they are extremely organized and extremely rich! They can and do buy anyone and anything! Most people don't even realize they have several submarines. This theory that everyone can get sick if enough people say they're sick, and blah blah blah, is just that, a theory. We're talking about the real world here. Unfortunately, it's the dark side, the hidden side that most don't even realize is out there.&lt;/code&gt;&lt;code&gt;So when these Americans complained about being hit and knocked down, believe them! My advice is do some studying on this weapon, yes its covert, silent and does shoot right thru walls,, it can hurt you and even kill you. Think of yourself as a potato, and what does it do if microwaved. My suggestion is get the book The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought. Unfortunately, you will NOT find any book in the library on this cartel, why? They're either stolen or lost.&lt;/code&gt;&lt;code&gt;You would not believe how many American citizens are now employed by this Mexican Cartel living right here in the good ole USA, and they ALL have this DEW weapon!&lt;/code&gt;&lt;code&gt;I would like to ask you if anything has been made to be able to catch a laser beam in motion and have it returned to the bad guy? I do not mean 'take' it to the bad guy (like a missile) I'm thinking perhaps a 'mirror-like' device.&lt;/code&gt;&lt;code&gt;[Name withheld; former employee at a defense contractor working on microwave devices]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;Thank you for your letter.&lt;lb/&gt;I haven't done a lot of homework on DEWs since my main interest is in visible lasers. I get calls about once every month or two from people who have experienced heat or light that I cannot explain. That's why my webpage includes links to other directed energy information sources.&lt;lb/&gt;I will say I'm not sure why Mexican cartels or human traffickers would target the people I hear from. They seem like normal people in residential neighborhoods. If the cartels wanted them gone, they certainly have other, much worse ways to do this.&lt;lb/&gt;I just downloaded the E-Bomb book in Kindle format. I will read it soon.&lt;lb/&gt;About your letter... I do want to bring forth other views. Would it be OK if I printed all or parts of it on the "If you are harassed by lasers" webpage at LaserPointerSafety.com? Without your name or identifying information, of course.&lt;lb/&gt;Finally, for visible lasers, you could use a retroreflector to return the light to the source. The beam may be degraded enough that if it could cause heat at the retroreflector, the returned beam (having gone twice as far and having bounced off possibly dirty or dusty surfaces) would be weaker and thus not able to harm anyone at the source area.&lt;lb/&gt;At a minimum, you would need a high-quality, industrial or research quality corner cube retroreflector like these. An inexpensive "cat's eye" bicycle retroreflector or similar would cause a bright glow to be seen at the source, but would not cause a coherent beam to be reflected back.&lt;lb/&gt;The original author's response:&lt;code&gt;Thanks for getting back to me so quickly, it's appreciated.&lt;/code&gt;&lt;code&gt;Yes, you can use what I wrote if it helps the targets. To help you to understand why good people end up targets is because more than likely they have interfered with something the Cartel is doing, like selling drugs, or human trafficking, they might have alerted the police, or see something say something. It could even be someone hired stalkers to hurt you because of some vendetta, or just pure revenge!&lt;/code&gt;&lt;code&gt;They could/can kill you. But, in most cases they just want to provoke you or harass you while hurting you with this DEW weapon. It's called a 'slow cooker' for a reason. It's nothing but pure evil.&lt;/code&gt;&lt;code&gt;I would like to see this hand held DEW put out of business and the defense companies fined big time for selling it, especially to the Cartels but, I'm reading where Directed Energy is being used even more than ever by other countries within the military sector. Lasers as well. I'm not against high technology but I am against something like this getting into the wrong hands.&lt;/code&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Another email with a detailed theory&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In March 2020 we received an email from Anthony Arellano describing in great detail how sonic and heat attacks could theoretically be done.&lt;lb/&gt;We are providing the document as an example.&lt;lb/&gt;We have not reviewed and do not endorse this information. Please independently research this before taking any actions based on the information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;We cannot help in mysterious or non-obvious cases&lt;/head&gt;
    &lt;p&gt;We do not have expertise about non-visible lasers or directed energy devices. Do not contact us, since we will no longer reply as of September 1 2023. If you are experiencing this, you should check the links above about covert harassment and directed energy devices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389965</guid><pubDate>Fri, 26 Sep 2025 19:12:26 +0000</pubDate></item><item><title>Why use mailing lists?</title><link>https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0/</link><description>&lt;doc fingerprint="e2dc9d93b25dbf8d"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Re: Fully functional email address&lt;/head&gt;
    &lt;p&gt;Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt; Thu, 19 June 2025 20:09 UTC&lt;/p&gt;
    &lt;p&gt; Return-Path: &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; X-Original-To: ietf@mail2.ietf.org&lt;lb/&gt; Delivered-To: ietf@mail2.ietf.org&lt;lb/&gt; Received: from localhost (localhost [127.0.0.1]) by mail2.ietf.org (Postfix) with ESMTP id 0B126371B8C9 for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:46 -0700 (PDT)&lt;lb/&gt; X-Virus-Scanned: amavisd-new at ietf.org&lt;lb/&gt; X-Spam-Flag: NO&lt;lb/&gt; X-Spam-Score: -2.298&lt;lb/&gt; X-Spam-Level: &lt;lb/&gt; X-Spam-Status: No, score=-2.298 tagged_above=-999 required=5 tests=[BAYES_20=-0.001, RCVD_IN_DNSWL_MED=-2.3, RCVD_IN_MSPIKE_H3=0.001, RCVD_IN_MSPIKE_WL=0.001, RCVD_IN_VALIDITY_RPBL_BLOCKED=0.001, RCVD_IN_VALIDITY_SAFE_BLOCKED=0.001, SPF_PASS=-0.001] autolearn=ham autolearn_force=no&lt;lb/&gt; Received: from mail2.ietf.org ([166.84.6.31]) by localhost (mail2.ietf.org [127.0.0.1]) (amavisd-new, port 10024) with ESMTP id u4Vy4jVMA7Ej for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from taos.firemountain.net (taos.firemountain.net [207.114.3.54]) (using TLSv1.3 with cipher TLS_CHACHA20_POLY1305_SHA256 (256/256 bits) key-exchange X25519 server-signature ECDSA (P-256) server-digest SHA256) (No client certificate requested) by mail2.ietf.org (Postfix) with ESMTPS id 94448371B8C0 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from gsp.org (localhost [127.0.0.1]) by taos.firemountain.net (8.17.2/8.17.2) with SMTP id 55JK9hDh065634 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 16:09:44 -0400 (EDT)&lt;lb/&gt; Date: Thu, 19 Jun 2025 16:09:43 -0400&lt;lb/&gt; From: Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; To: IETF general list &amp;lt;ietf@ietf.org&amp;gt;&lt;lb/&gt; Subject: Re: Fully functional email address&lt;lb/&gt; Message-ID: &amp;lt;20250619200943.GB5995@gsp.org&amp;gt;&lt;lb/&gt; References: &amp;lt;18892.1750014795@obiwan.sandelman.ca&amp;gt; &amp;lt;50FFA5F1-6895-4C6C-A4C7-1DA2226CA07B@huitema.net&amp;gt; &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; MIME-Version: 1.0&lt;lb/&gt; Content-Type: text/plain; charset="us-ascii"&lt;lb/&gt; Content-Disposition: inline&lt;lb/&gt; In-Reply-To: &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; User-Agent: Mutt/1.5.23 (2014-03-12)&lt;lb/&gt; Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-MailFrom: rsk@gsp.org&lt;lb/&gt; X-Mailman-Rule-Misses: dmarc-mitigation; no-senders; approved; emergency; loop; banned-address; member-moderation; header-match-ietf.ietf.org-0; nonmember-moderation; administrivia; implicit-dest; max-recipients; max-size; news-moderation; no-subject; digests; suspicious-header&lt;lb/&gt; X-Mailman-Version: 3.3.9rc6&lt;lb/&gt; Precedence: list&lt;lb/&gt; List-Id: "IETF-Discussion. This is the most general IETF mailing list, intended for discussion of technical, procedural, operational, and other topics for which no dedicated mailing lists exist." &amp;lt;ietf.ietf.org&amp;gt;&lt;lb/&gt; Archived-At: &amp;lt;https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0&amp;gt;&lt;lb/&gt; List-Archive: &amp;lt;https://mailarchive.ietf.org/arch/browse/ietf&amp;gt;&lt;lb/&gt; List-Help: &amp;lt;mailto:ietf-request@ietf.org?subject=help&amp;gt;&lt;lb/&gt; List-Owner: &amp;lt;mailto:ietf-owner@ietf.org&amp;gt;&lt;lb/&gt; List-Post: &amp;lt;mailto:ietf@ietf.org&amp;gt;&lt;lb/&gt; List-Subscribe: &amp;lt;mailto:ietf-join@ietf.org&amp;gt;&lt;lb/&gt; List-Unsubscribe: &amp;lt;mailto:ietf-leave@ietf.org&amp;gt;&lt;/p&gt;
    &lt;quote&gt;On Mon, Jun 16, 2025 at 12:31:09PM -0400, John R. Levine wrote: &amp;gt; Incidentally, the reason that mail will never go away is that it is fully &amp;gt; federated, doesn't require people to be online at the same time, and is easy &amp;gt; to archive and search. So far none of the replacements do that. +1, and let me augment this by (partially) quoting something that I wrote a few years ago about mail and mailing lists. Why use mailing lists? ---------------------- Mailing lists, which were sometimes called "reflectors" in their early days, are one of the older pieces of Internet technology. Despite that, they're still heavily used [...] That's not an accident. It's because mailing lists have enormous technical advantages over the alternatives. Here are some of those: 1. Mailing lists require no special software: anyone with a sensible mail client can participate. Thus they allow you to use *your* software with the user interface of *your* choosing rather than being compelled to learn 687 different web forums with 687 different user interfaces, all of which range from "merely bad" to "hideously bad". 2. Mailing lists are simple: learn a few basic rules of netiquette and a couple of Internet-wide conventions, and one's good to go. Web forums are complicated because all of them are different. In other words, participating in 20 different mailing lists is just about as easy as participating in one; but participating in 20 different web forums is really quite onerous. 3. They impose minimal security risk. 4. They impose minimal privacy risk. Points 3 and 4 stand in stark contrast to the security and privacy risks imposed on users of web forums and "social" media, especially the latter. 5. Mailing lists are bandwidth-friendly -- an increasing concern for people on mobile devices and thus on expensive data plans. Web forums are bandwidth-hungry. 6. Mailing lists interoperate. I can easily forward a message from one list to another one. Or to a person. I can send a message to multiple lists. I can forward a message from a person to this list. And so on. Try doing this with web forum software A on host B with destinations web forum software C and D on hosts E and F. Good luck with that. 7. They're asynchronous: you don't have to interact in real time. You can download messages when connected to the Internet, then read them and compose responses when offline. 8. As a result of 7, They work reasonably well even in the presence of multiple outages and severe congestion. Messages may be delayed, but once everything's up again, they'll go through. Web-based forums simply don't work at all. 9. They're push, not pull, so new content just shows up. Web forums require that you go fishing for it. 10. They scale beautifully. 11. (When properly run) they're relatively free of abuse vectors. Mailing lists are highly resistant to abuse and attacks. Web forums, because of their complexity, are highly vulnerable to software security issues as well as spam/phishing and other attacks. 12. They handle threading well. And provided users take a few seconds to edit properly, they handle quoting well. This is essential for anyone trying to follow a discussion. 13. They're portable: lists can be rehosted (different domain, different host) rather easily. 14. They can be freely interconverted -- that is, you can move a list hosted by A using software B on operating system C to host X using software Y on operating system Z. If you can do this at all with web forums, and you usually can't, it's really, really difficult. 15. They can be written to media and read from it. This is a VERY non-trivial task with web forums, and that's putting it mildly. 16. The computing resources require to support them are minimal -- CPU, memory, disk, bandwidth, etc. 17. Mailing lists can be uni- or bidirectionally gatewayed to Usenet. (The main Python language mailing list is an example of this.) They can also be gatewayed to web sites or to RSS feeds. All of these can be highly useful, because they provide alternative ways for people to receive the same content. 18. They're easily archivable in a format (Unix "mbox" format) that is simple and likely to be readable long into the future. Mail archives from 10, 20, even 30 or more years ago are still completely usable. And they take up very little space: I have hundreds of millions of mailing list messages archived, and the entire collection would fit on a USB stick. [...] 19. You can archive them locally... 20. ...which means you can search them locally with the software of *your* choice. Including when you're offline. And provided you make backups, you'll always have an archive -- even if the original goes away. Web forums don't facilitate this. [...] ---rsk&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Michael Richardson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John R. Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Salz, Rich&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rob Sayre&lt;/item&gt;
      &lt;item&gt;Email usage (Was: Fully functional email address) Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Martin J. D√ºrst&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rich Kulawiec&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Phillip Hallam-Baker&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390121</guid><pubDate>Fri, 26 Sep 2025 19:27:23 +0000</pubDate></item><item><title>How insurance risk is transformed into investable assets</title><link>https://riskvest.io/riskvest-insights/transforming-insurance-risk</link><description>&lt;doc fingerprint="3954309d71ae6140"&gt;
  &lt;main&gt;
    &lt;p&gt;Insurance risk involves the sale of insurance policies to policyholders, the receipt of premium and the payment of claims. If claims &amp;amp; associated expenses are less than premium received, an Underwriting Profit is made. If claims are greater than premium, an Underwriting Loss occurs. In essence, investing in insurance risk is like partnering with an insurer ‚Äî you share in the results of the portfolio, keeping a slice of the underwriting profit if claims come in below premiums, or sustaining a loss if they come in above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Insurance Is Not Fully Collateralized&lt;/head&gt;
    &lt;p&gt;This brings us to the concept of collateralization. An everyday example of collateral involves your mortgage. When you take out a loan from the bank to buy a house, you're putting up the house itself as collateral for the loan to secure it - meaning, if you fail to pay back the loan, the bank can foreclose and sell the house to cover the loan.&lt;/p&gt;
    &lt;p&gt;The key observation about insurance risk is the possibility for insurers to pay out more money in claims than they take in via policy premiums. When you purchase a policy from an insurance company, you‚Äôre implicitly trusting that the insurance company will be able to pay you out in the event of a claim, even if it means they‚Äôre operating at a loss. Insurance companies have a balance sheet (basically, an amount of assets or money) which acts as collateral against the chance that they must pay out more than they take in.&lt;/p&gt;
    &lt;p&gt;The amount of money held by the insurance company for this purpose is known as insurance capital &amp;amp; surplus. Since this amount of capital is less than the total sum of all policy limits, we can say the policies are partially collateralized.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visualizing How Insurance Losses Are Distributed&lt;/head&gt;
    &lt;p&gt;The chart below illustrates this concept with a probability distribution. The blue curve shows the likelihood of different loss levels. It peaks around 60-70% of premium but has a long tail extending to extreme scenarios.&lt;/p&gt;
    &lt;p&gt;The insurance company in this example holds capital equal to 175% of premium collected, giving them total resources of 275% of premium (100% premium + 175% capital) to pay claims in extreme years.&lt;/p&gt;
    &lt;p&gt;The green dashed line shows the return on capital from underwriting activities. When losses are less than premium collected (green zone), the insurer keeps the difference as profit. Once losses exceed the break-even point at 100%, the insurer must use their capital reserves to pay claims (red zone). Think of it like making an "investment" with the premium you collected, but getting such a negative return that you have to reach into your wallet to cover the losses (red line).&lt;/p&gt;
    &lt;head rend="h4"&gt;Chart Legend:&lt;/head&gt;
    &lt;head rend="h3"&gt;Key Insight&lt;/head&gt;
    &lt;head rend="h2"&gt;Some Retail Investments Are Partially Collateralized&lt;/head&gt;
    &lt;p&gt;Retail brokerages offer margin accounts to those customers that have sufficient assets to support it - much like the insurance company capital - and reserve the right to make a margin call if those trader‚Äôs reserves fall below minimum requirements. In extreme cases, it‚Äôs even possible for a trader to end up in a position where the brokerage could not sell collateral quickly enough and they‚Äôre left with a negative balance which must be filled with assets from elsewhere.&lt;/p&gt;
    &lt;p&gt;In the same way, insurers must maintain capital to meet extreme claims. Both systems rely on partial collateralization: enough to cover most outcomes, but not the absolute maximum.&lt;/p&gt;
    &lt;p&gt;Therein lies a critical implication: The entire balance sheet of the insurance company is available and backing each individual policy. This is similar to your margin account, as if your account balance (collateral) goes below zero, you'll have to pull from assets outside to cover the debt.&lt;/p&gt;
    &lt;p&gt;This is one of the fundamental reasons why regulators restrict retail investors from direct insurance risk investments. A strong knowledge base of how the risk works is needed to understand you're not just exposed to losing your investment, but other assets as well. For history buffs, I recommend reading Andrew Duguld's On the Brink: How a Crisis Transformed Lloyd's of London1for a fascinating first-hand account of the Names at Lloyd's. These individuals once pledged their entire personal wealth to back insurance syndicates, sometimes with catastrophic consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insurance Risk Investments For Retail Are Almost Always Fully Collateralized&lt;/head&gt;
    &lt;p&gt;So what have we learned from this comparison? Three points stand out:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;1Insurance risk is exposed to losses exceeding the premium received&lt;/item&gt;
      &lt;item&gt;2Collateral needs to be set aside in case of these outsized losses to ensure trust in the insurance product&lt;/item&gt;
      &lt;item&gt;3Outside (especially Retail) Investors would be best to limit their exposer to losses beyond their investment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The challenge, then, is clear: how can retail investors access insurance risk without facing the danger of unlimited losses? The solution has been to design fully collateralized structures as vehicles that capture underwriting profits while capping potential losses at your invested amount. One of the most intuitive examples comes from adapting reinsurance structures into a format investors can access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case Study: CAT Bonds&lt;/head&gt;
    &lt;p&gt;Catastrophe Bonds, or "CAT Bonds", are the most widely known form of investable insurance risk. If we ignore the insurance implications of it for a second, CAT Bonds are just like any other corporate bond: they are issued by a firm, pay a coupon, have a maturity date and have an associated risk of default (not being paid back principal).&lt;/p&gt;
    &lt;p&gt;The difference here is the risk of default of a CAT bond is tied in someway to insurance losses. If a qualifying insurance event happens, the principal is kept by the insurance company to pay those claims, effectively defaulting the bond. They are referred to as "Catastrophe" bonds simply because they are most often tied to large, catastrophic events such as Hurricanes, Earthquakes, or even Cyber events.&lt;/p&gt;
    &lt;p&gt;CAT Bonds can be thought of as an insurance policy bought by the insurance company itself. They are, in fact, usually a compliment to the insurance company's full reinsurance program. Here, however, the insurance company isn't buying a policy from another insurance company, but rather outside capital markets on a fully collateralized basis.&lt;/p&gt;
    &lt;p&gt;Let's form our own very basic CAT bond. We're Risksure - a Florida based insurance company - and we write a lot of homeowners policies in the sunshine state. We'd like to take out the following CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sponsor: Risksure Re&lt;/item&gt;
      &lt;item&gt;Bond Size (Limit): $100M&lt;/item&gt;
      &lt;item&gt;Attachment Point (Deductible): $500M (Risksure covers the first $500M of losses)&lt;/item&gt;
      &lt;item&gt;Issuance Date: Jan 1, 2026&lt;/item&gt;
      &lt;item&gt;Maturity Date: Dec 31, 2026&lt;/item&gt;
      &lt;item&gt;Coupon (Premium): 9% annually, rate paid quarterly on current collateral balance&lt;/item&gt;
      &lt;item&gt;Terms: If a hurricane strikes Florida in 2026 and Risksure‚Äôs losses exceed $500M, investors‚Äô principal is used to cover those excess losses, up to $100M. This is known as a per occurrence limit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h6"&gt;CAT Bond: Gator Re Ltd. üêä&lt;/head&gt;
    &lt;p&gt;To issue this Bond, Risksure Re would collect $100M of principal from outside investors, thus fully collateralizing the insurance risk. In return, Risksure Re would pay $9M of premium for the bond, and should no hurricane event occur, pay back the $100M of principal at maturity.&lt;/p&gt;
    &lt;p&gt;This type of structure is common in reinsurance and known as an excess of loss structure. The layer of coverage can be visualized as follows:&lt;/p&gt;
    &lt;head rend="h3"&gt;How It Works&lt;/head&gt;
    &lt;head rend="h2"&gt;Investment Returns for Gator Re Ltd. üêä&lt;/head&gt;
    &lt;p&gt;There are two components of return for the investors in our CAT Bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Risk Return: Compensation for taking on the insurance risk, paid for by the 9% coupon&lt;/item&gt;
      &lt;item&gt;Risk Free Return: Compensation for tying up capital, in the form of interest income on the collateral sitting in the bank, say by investing it in 4% T-bonds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's clear that we this structure, the investors are taking on insurance risk exposure. However, in this case, the "buyer" of the insurance policy (the insurance company itself) does not need to worry that the insurer (the outside investors) will not be able pay claims if the large event happens, because the entire value of the policy limit ($100M limit) is set aside and can't be touched.&lt;/p&gt;
    &lt;p&gt;We can now examine and visualize a few potential outcomes for the buyers of the CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No Hurricane: Capital providers get back $9M Risk Income + $4M Risk-free Income = $13M along with their original $100M of investment, a 13% return.&lt;/item&gt;
      &lt;item&gt;A Partial Loss: Risksure suffers $525M of loss from a covered hurricane. Risksure pays the first $500M. They then use $25M of the paid in capital from the CAT bond to pay for the remaining claims. Assuming mid-year trigger, capital providers will receive back the remaining $75M, plus the $7.78M Risk Income (two coupons paid plus two partial coupons), plus reduced RF income due to the used capital, $3.5M, for a total of $86.28M. This is a negative 13.72% return.&lt;/item&gt;
      &lt;item&gt;A Full Loss: A massive hurricane hits Florida and Risksure pays out $1B in losses, far above the exhaustion point of $600M for this CAT bond. The entirety of the $100M principle and risk free income goes towards paying Risksure's policyholder claims. Investors received $4.5M in coupons before trigger and no principle, for a loss of 95.5%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Keen observers will notice that we've successfully transformed the insurance risk into a limited liability product - you can no longer owe additional capital beyond your original investment. However, it's clear that investing in insurance risk in this manner should be treated as a compliment to other investment strategies. Bear markets for equities might return -30% to -50%, but crucially, they retain the potential to recover those losses over time. CAT bonds offer no such recovery potential - once triggered, that capital is permanently lost. That said, the stated probability of default for these bonds is typically 1-3%, meaning the 5-9% excess returns above risk-free rates are designed to compensate for this low-probability but high-severity risk.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Final Note: Why Isn't Insurance Fully Collateralized?&lt;/head&gt;
    &lt;p&gt;A natural question arises through this analysis: why aren't insurance companies forced to hold enough money to cover all potential loss scenarios? The short answer is efficiency. The less capital you have to hold, the larger your returns on capital will be. This can be illustrated with simple math. Say you hold $10M in capital and expect a profit of $500K on underwriting business. Expected return is $500K/$10M = 5%. But let's say now you only have to hold $5M in capital - your return on capital has now jumped to $500K/$5M = 10%. By holding fully collateralized layers, CAT bonds are trading capital efficiency for payment certainty.&lt;/p&gt;
    &lt;p&gt;Referring back to the chart at the beginning of the article, those extremely remote loss scenarios have exceedingly low likelihood of happening for a sufficiently large and diverse insurance company. Each insurance company has a team of actuaries and risk modelers dedicated to ensuring the ongoing solvency of the company. Regulators setup frameworks to validate and set guidelines for the amount of capital a company needs to hold. With all that said, insurance companies can and do fail, at which point regulators can swoop in to protect policyholders.&lt;/p&gt;
    &lt;p&gt;This is why under collateralized insurance "works" - there are many checks and balances along the way to align incentives. It's also why giving outside investors access to insurance risk is such a challenge; with out those protections in place, guardrails (such as full collateralization) have to be setup such that insurance policies can be sure their claims will be paid.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390856</guid><pubDate>Fri, 26 Sep 2025 20:46:26 +0000</pubDate></item><item><title>RNA structure prediction is hard. How much does that matter?</title><link>https://www.owlposting.com/p/rna-structure-prediction-is-hard</link><description>&lt;doc fingerprint="eff8d413373c4312"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RNA structure prediction is hard. How much does that matter?&lt;/head&gt;
    &lt;head rend="h3"&gt;4.8k words, 22 minute reading time&lt;/head&gt;
    &lt;p&gt;Note: I am not an expert in RNA structure, and am extremely grateful to Connor Stephens, Rishabh Anand, Ramya Rangan, and Chaitanya K. Joshi‚Äîall of whom are actual, bonafide experts‚Äîfor their incredibly detailed comments on earlier drafts of this essay. All mistakes are, of course mine, and this essay should not be trusted to function as anything more than entertainment. Do your own research!&lt;/p&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;One thing I‚Äôve always wanted to write was ‚Äòa primer to RNA structure modeling‚Äô. I know literally nothing about the field, other than that there are a few startups playing in the space, and have always been curious what exactly they were up to. But the release of Alphafold3‚Äîwhich can model RNA alongside proteins, DNA, and small molecules‚Äîdampened this desire. If a singular model solved the problem of RNA structure, who cares about the specifics of the field at large?&lt;/p&gt;
    &lt;p&gt;But while I was in San Francisco a few months back, I happened to chat with Connor Stephens, a machine learning scientist at Atomic AI. You may recognize that startup, since their founder has the distinct honor of their PhD work in RNA structure modeling being on the cover of Science in 2021 for making a substantial advance in RNA structure prediction.&lt;/p&gt;
    &lt;p&gt;But it was long unclear to me what exactly Atomic AI exactly did in terms of R&amp;amp;D. This isn‚Äôt a startup post, I‚Äôm not planning to explain what their therapeutic goals are. What I was curious about was why they continue to have an ML team despite the RNA problem being seemingly solved by Alphafold3. So, I posed that question to Connor.&lt;/p&gt;
    &lt;p&gt;Connor told me something very fascinating: not only did Alphafold3 not solve the problem of RNA structure prediction, RNA may be one of the last structure prediction problems to be solved. The rest of the conversation was so incredibly fun that, midway through it, I decided it‚Äôd make for a great article to write about.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why is RNA structure so hard to model?&lt;/head&gt;
    &lt;p&gt;On face value, the answer is pretty simple: experimentally determined RNA structures deposited in public repositories are both ridiculously small in number and of much lower quality than you‚Äôd naively expect. A quote from a paper best explains this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There is a huge disparity in protein and RNA data. Even if there is a higher proportion of RNAs than proteins in the living, this is not reflected in the available data: only a small amount of 3D RNA structures are known. Up to June 2024, 7,759 RNA structures were deposited in the Protein Data Bank (34), compared to 216,212 protein structures. The quality and diversity of data are also different: a huge proportion of RNAs come from the same families. It implies several redundant structures that could prevent a model from being generalized to other families. In addition, a huge amount of RNA families have not yet solved structures in the PDB. This means there is no balanced and representative proportion of RNA families through the known structures.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The obvious follow-up question is: why? Apparently, RNA is a good fit for basically none of the existing structure determination methods. But again, why?&lt;/p&gt;
    &lt;p&gt;Connor told me that RNA is famous for being perhaps one of the most flexible biomolecules to exist as a category, with an almost absurd number of conformational degrees of freedom. Each nucleotide has more torsion angles than an amino acid, and the lack of a bulky side chain‚Äîlike those in amino acids‚Äîmeans there‚Äôs very little steric hindrance to keep the backbone from flopping around. Now, keep in mind, this is not to say that RNA is unstructured. Unstructured has a particular meaning, that the energy landscape is flat, with no favored conformational structure. But this isn‚Äôt the case for RNA, which do have preferred conformational structures, there are just many of them that they constantly flip in between.&lt;/p&gt;
    &lt;p&gt;This all implies that RNA is a very bad fit for X-ray crystallography, which requires orderly, repeating conformations to arrange into a crystal. It is also a bad fit for cryo-EM (a subject I‚Äôve written about in detail before), given both the extreme conformational heterogeneity of it and how typically small the biomolecule is, though this is increasingly being addressed. Finally, NMR, which, while more forgiving when it comes to flexibility and heterogeneity, is generally limited to very small RNA structures. Once the RNA goes beyond ~50 nucleotides, the spectra start overlapping and the resolution being insufficient to observe anything useful. And lots of important RNA lies beyond that size!&lt;/p&gt;
    &lt;p&gt;I‚Äôve attached some nuance about NMR and cryo-EM in the footnotes.1&lt;/p&gt;
    &lt;p&gt;This means that there are really only two RNA structures that can be physically characterized: ones that have been artificially stabilized, or ones that are evolutionarily constrained to hold a single dominant conformation.&lt;/p&gt;
    &lt;p&gt;The first category includes structures coaxed into rigidity by heavy metal ions, engineered base modifications, or even crystallization chaperones. But of course, this raises a worrying question: are you really measuring the native structure, or just the structure you forced it into? The second category is rarer: RNAs that, through evolutionary pressure, have converged on a stable structure for a functional reason. There are no caveats there, only that trying to train a model on these nucleotide sequences will inevitably bias it towards unusually stable RNA structures.&lt;/p&gt;
    &lt;p&gt;Well, we shouldn‚Äôt let all of this get us down. Many impossible problems are being solved day-after-day in this field. Even if RNA modeling has all the characteristics of being hard to do‚Äîhuge distributional space of possible outputs for a given input and low number of input data points‚Äîsurely, some headway has been made in the problem. Consider Alphafold3: how well does it actually do on the RNA structure prediction problem?&lt;/p&gt;
    &lt;p&gt;A well-named paper titled Has AlphaFold3 achieved success for RNA? tries to answer this question. From the article:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The best models from the CASP-RNA competition, which are human-guided, outperform AlphaFold3‚Ä¶.&lt;/p&gt;
      &lt;p&gt;‚Ä¶.On the other hand, AlphaFold3 shows a cumulative sum of metrics greater than the other methods for the other test sets (p-value &amp;lt; 10‚àí5 for RNA-Puzzles, p-value &amp;lt; 10‚àí4 for RNASolo).&lt;/p&gt;
      &lt;p&gt;For RNA-Puzzles, the challenge-best solutions are from older solutions with less advanced architectures compared with the more recent CASP-RNA solutions.&lt;/p&gt;
      &lt;p&gt;For the RNA3DB_0 data set, the performance of AlphaFold3 is slightly better compared with RhoFold, which gives a better RMSD but a worse MCQ and LCS-TA.&lt;/p&gt;
      &lt;p&gt;AlphaFold3 always has a high MCQ value, indicating that it returns structures which are more physically plausible than ab initio methods (which use physics properties in their predictions).&lt;/p&gt;
      &lt;p&gt;Nonetheless, it does not always have the best RMSD (outperformed in CASP-RNA and RNA3DB_0), suggesting that AlphaFold3 does not always have the best alignment (in terms of all atoms) compared with the reference structure.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In short, while Alphafold3 is certainly an improvement in some categories of RNA‚Äînamely being the only RNA structure prediction method that can model very large RNA‚Äôs well‚Äîit does not solve the problem outright, and can be outperformed through tailored methods.&lt;/p&gt;
    &lt;p&gt;Another slightly more recent paper says something similar, and gives some insight into the practical meaning of these benchmarks, saying ‚ÄòBoltz-1 and AlphaFold3, make acceptable predictions for about half of the individual RNA chains and complexes.‚Äô. The authors further note that the results get far worse if you deviate into more structurally unique RNA space (bolding added by me):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We observed that prediction accuracy, as measured by TM-score, generally increased with higher structural similarity to the training set for all methods. The mean TM-score is below 0.1 for the category with the least similarity and increases gradually to over 0.6 for the category with the highest similarity to the training set. This suggests that AlphaFold3 and other methods tend to perform better when the target structure is more similar to motifs it encountered during training, highlighting the limitation of current methods in predicting unseen and structurally divergent RNAs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Neat!&lt;/p&gt;
    &lt;p&gt;I could end the essay here, because this really did cover most of Connor and I‚Äôs conversation. There is a lot more that could be said about how difficult benchmarking can be in the RNA ML world, the weak co-evolutionary signal in RNA MSA‚Äôs, how even the existing set of RNA structures are made worse by the fact that they are almost always in complex with a protein, and (hearsay) that you likely need experimentally-determined templates/molecular-dynamics to get good structure predictions. This paper discusses all that in more detail if you're curious, but my main question got answered!&lt;/p&gt;
    &lt;p&gt;But the more I talked to people in the RNA space while writing this essay, the more I began to ask a new question: how important is this problem anyway?&lt;/p&gt;
    &lt;head rend="h1"&gt;Why even predict RNA structure in the first place?&lt;/head&gt;
    &lt;p&gt;For the protein-heads reading this, we know that protein structure actually means something quite fundamental. A protein‚Äôs three-dimensional fold is usually synonymous with its biological role: an enzyme pocket is what catalyzes a reaction, an antibody groove is what binds an antigen, a receptor domain is what recognizes a ligand. We can hem and haw about dynamics or post-translational tweaks, but the basic architecture is what makes the protein what it is. Protein structure isn‚Äôt exactly truth, but structure can be a proxy for truth a sufficiently high fraction of the time.&lt;/p&gt;
    &lt;p&gt;RNA is not like this at all. It‚Äôs actually really, really, really situational when the structure of RNA matters in a therapeutic context. Well, to be more nuanced, structure always matters, but there is a very significant split what ‚Äòstructure‚Äô even means for this biomolecule: secondary structure and tertiary structure (image from here):&lt;/p&gt;
    &lt;p&gt;Thus far, everything we‚Äôve talked about regarding the ‚Äòdifficulty of structure prediction‚Äô has been for tertiary structure.&lt;/p&gt;
    &lt;p&gt;Now, this separation exists for proteins as well! But it (somewhat) matters less for proteins. Usually we treat ‚Äúprotein structure‚Äù as a single concept because the hierarchy is tightly coupled: secondary structure (Œ±-helices, Œ≤-sheets) stacks neatly into tertiary folds, which in turn map directly to function. You can often ignore the distinction because the two levels reinforce each other, and so everyone hyper-focuses on tertiary structures being the most important thing.&lt;/p&gt;
    &lt;p&gt;But for RNA, the distinction matters a lot, because secondary structure seems to be where most of the clinically relevant value of structure is. Tertiary RNA structure is important! But, as far as I can tell, the value of it is actually relatively limited in scope for therapeutic-relevant problems, partially due to the fact that RNA is just so flexible that a tertiary structure phenomenon like ‚Äòthe binding site is buried in the core‚Äô can immediately be undercut by that same core suddenly flopping out in a new conformation.&lt;/p&gt;
    &lt;p&gt;And, just as is the case for proteins, RNA secondary structure is far easier to predict than RNA tertiary structure. It‚Äôs still comparatively hard, in the sense that secondary protein structure is basically something people don‚Äôt ever worry about, and secondary RNA structure has only just recently reached those same accuracy levels. A paper that analyzed the performance of RNA models at CASP16 had this to say:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Complex and novel targets appear well beyond current capabilities for NA 3D structure prediction. However, RNA folding can be simplified into a hierarchical process: secondary structure ‚Äì the pattern of canonical base pairs ‚Äì forms creating a set of RNA stems which are then stitched into the overall 3D fold‚Ä¶&lt;/p&gt;
      &lt;p&gt;CASP16 offered the prospect of carrying out tests of secondary structure accuracy prospectively. The secondary structure of all targets, here defined as the list of all Watson-Crick-Franklin and Wobble pairs, turned out to be predicted to a high level of accuracy (Supplemental Figure 3A)...The trend in RNA secondary structure performance is more reminiscent of the performance observed in current protein 3D structure prediction, suggesting these prediction algorithms are reaching sufficient accuracy in their prediction of secondary structure to be important and useful in structural research.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Not too bad!&lt;/p&gt;
    &lt;p&gt;Returning back to our claim that ‚Äòsecondary structure is most of what you need‚Äô, let‚Äôs convince ourselves of this by walking through the major classes of RNA-based therapeutics and the importance of secondary versus tertiary structure.&lt;/p&gt;
    &lt;p&gt;The most famous form of therapy here is exogenous mRNA, and tertiary structure doesn‚Äôt seem to matter much there. I have two proof points for this. One, this mRNA optimization article from GeneWiz mentions secondary-structure optimization (e.g. preventing hairpins), but not tertiary structure. Two, just logically thinking about it, the job of mRNA is to be fed into the ribosome and translated into protein, so as long as the coding region is readable and initiation isn‚Äôt blocked (hence probably why hairpins are undesirable), why would it matter for the RNA to maintain any particular higher-order fold?&lt;/p&gt;
    &lt;p&gt;Then there‚Äôs antisense oligonucleotides, or ASO. All this is is a short synthetic strand of RNA (usually 15‚Äì25 bases long) that binds to a complementary sequence of an RNA. Once bound, it can block translation directly by preventing ribosome access, alter splicing by blocking splice sites or enhancers/silencers, or a few other things. But in all of these cases, all that matters is that the ASO can actually base-pair with its intended target. And that comes down to secondary structure accessibility: is the binding site exposed or not? Once again, this seems to be something that is largely answerable from secondary structure information, especially given how small ASO‚Äôs are.&lt;/p&gt;
    &lt;p&gt;For siRNA‚Äôs, or small interfering RNA, it‚Äôs nearly the same story as ASO‚Äôs,&lt;/p&gt;
    &lt;p&gt;Virtually the only time tertiary structure seems to matter for an RNA therapeutic is for aptamers and ribozymes. The former refers to short RNAs that fold into precise three-dimensional shapes capable of binding proteins or small molecules (e.g. theophylline aptamer), and the latter refers to enzymatic RNAs with a precise catalytic site that are able to carry out chemical reactions. But, unlike all other classes of RNA therapeutics, approved drugs here are quite rare; aptamers have two and ribozymes have zero. There‚Äôs also riboswitches, which are a hazy combination of the two, and also have no released therapies.&lt;/p&gt;
    &lt;p&gt;This all said, we should also consider the other side too: RNA as targets. How important is secondary versus tertiary structure there?&lt;/p&gt;
    &lt;p&gt;Well, things do get muddier, because there isn‚Äôt really a standardized list of established RNA targets the same way there are for proteins. There‚Äôs mRNA, the tertiary structure of which is not exploited in any FDA-approved drugs (though we‚Äôll discuss this again later on), but what else?&lt;/p&gt;
    &lt;p&gt;Well, for one, non-coding regions! Specifically, microRNAs and IncRNA.&lt;/p&gt;
    &lt;p&gt;Given how small microRNA‚Äôs are (20~ nucleotides), I‚Äôd guess that tertiary structures don‚Äôt matter much there.&lt;/p&gt;
    &lt;p&gt;Curiously, LLM‚Äôs will, at first, insist that IncRNA‚Äôs, or ‚Äúlong noncoding RNAs‚Äù‚Äô really benefit from accurate tertiary structure prediction. There‚Äôs some reason to believe that they are right. After all, they are usually above 200 (or 500, depending on who you ask) nucleotides in length, so, unlike ASOs/siRNAs/microRNAs, IncRNA‚Äôs are sufficiently large where tertiary structures may have significant impacts. Unfortunately, the LLM seems to be a bit wrong here, partially because whether IncRNA‚Äôs even form global tertiary structures at all has been a matter of intense debate for a while, though circa 2020 it is seeming like at least some IncRNA‚Äôs do. But really, whether IncRNA‚Äôs have a global structure or not wouldn‚Äôt have even mattered anyway, because their modulation does not seem to actually depend on that global structure. Rather, it depends on a set of short nucleotide motifs scattered along an otherwise floppy backbone. Even if we could perfectly predict the full structure of an IncRNA tomorrow, it feels like it wouldn‚Äôt change any therapeutic decisions. Perhaps predictions of those local 3D motifs are valuable, but that‚Äôs an open question!&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the only type of RNA target where tertiary structure is known to be important is rRNA, or ribosomal RNA. Unlike most RNAs, ribosomal RNAs actually must maintain specific tertiary folds, because, like ribozymes, they are enzymes in every meaningful sense. The peptidyl transferase center of rRNA requires a highly specific three-dimensional geometry to orient its usual substrate: tRNA. And some classes of approved antibiotics, macrolides for example, are able to block this catalysis site, preventing (some) forms of bacteria from making proteins at all, eventually killing them.&lt;/p&gt;
    &lt;p&gt;It does seem like, from the outside, that accurate RNA tertiary structure predictions here would be helpful, given this line from a paper discussing where antibiotics bind to RNA:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For spectinomycin, the apparent binding site and the affected cross linking site are distant in the secondary structure but are close in tertiary structure in several recent models, indicating a localized effect. For tetracycline, the apparent binding sites are significantly separated in both the secondary and the three-dimensional structures, suggesting a more regional effect.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words, there is a large deviation in what secondary structure tells you, and what tertiary structure tells you!&lt;/p&gt;
    &lt;p&gt;This said, a few commenters on this essay noted that while this is an area where 3D structure is useful, it almost certainly isn‚Äôt a bottleneck due to the relative abundance of existing rRNA structures and ease of gathering new ones.&lt;/p&gt;
    &lt;p&gt;So, aptamers and rRNA are virtually the only two areas that (today) truly benefit from detailed tertiary structure modeling and have some things in the clinic. For mRNAs, ASOs, siRNAs, and most lncRNAs, the biology seems to collapse down to local accessibility and motif recognition. Both of these are sufficiently described by secondary structure, and that is decently well predicted by existing models! Tertiary folds, though definitively far from being well-predicted, don‚Äôt actually seem to influence much‚Ä¶at least as far as I can tell.&lt;/p&gt;
    &lt;p&gt;So why do people still work on the tertiary structure prediction problem? Is it all just for better ribosome-centric antibiotics and aptamers?&lt;/p&gt;
    &lt;head rend="h1"&gt;How much do we stand to gain if RNA structure prediction improves?&lt;/head&gt;
    &lt;p&gt;Well, in the immediate short term, it does seem like antibiotics and aptamers are really the field's best bets.&lt;/p&gt;
    &lt;p&gt;This is nothing to sneeze at! On the antibiotic side, we do need better antibiotics to account for the current ‚Äòantibiotic resistance‚Äô thing that‚Äôs been going on for the past decade, so why not elect ribosome-targeting antibiotics? This said, we should immediately drown our hopes that better ribosomal drugs will actually change the resistance trend-line. Naively, one would hope that things that interfere with rRNA functioning should be quite hard to adapt to‚Äîafter all, elements of the ribosome are canonically known for being extremely conserved. And that is true, but resistance manages to evolve anyway, including via, interestingly enough, post-transcriptional-modifications that prevent the antibiotic from binding to rRNA.&lt;/p&gt;
    &lt;p&gt;Of course, the real issue with antibiotics has little to do with scientific ideas, and more to do with economics. A funny paragraph I found from an interview with the lead author of a recent ‚Äònew rRNA antibiotic‚Äô paper had this to say:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚Ä¶there is an argument that the difficulty making successful antibiotic drugs has more to do with business models than with molecules. When asked about this, Myers says, ‚ÄúDo I worry about the broken business model for antibiotics development? Are you kidding? Every day. That may be the most challenging problem of the lot, and it is not one that I can solve. Synthesizing new antibiotics‚Äîin that, I feel confident.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;One related note is that RNA structure may not only be useful for targeting bacterial rRNA, but also viral RNA. A particularly famous case here is a paper that developed a protein that can bind to a structured RNA element in the HIV virus, impairing transcription of it (albeit in an in-vitro setting). Though this has yet to lead to any approved drugs, the subject is, according to one review paper, promising.&lt;/p&gt;
    &lt;p&gt;Moving onto the aptamer side, though it is still early days, the future is interesting. Circa 2024, de novo RNA aptamer design is currently at the ‚Äòwe can redesign existing things‚Äô, which is a necessary step on the way to ‚Äòwe can redesign existing things to make them better‚Äô, but we‚Äôre not there yet. What‚Äôs the therapeutic utility of an aptamer anyway? Basically the same uses one would have for an antibody for, with a ton of side benefits:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Aptamers have several advantages over antibodies, not least the fact that they can be produced quickly and easily without the need for animal use. Aptamers also benefit from low production costs, high batch-to-batch consistency, and functional stability when stored at room temperature, which gives them a long shelf-life and simplifies both transportation and storage. In addition, the low immunogenicity of aptamers makes them valuable tools for in vivo applications, while their small size compared to antibodies allows them to better penetrate cells and tissues. This can be especially useful when studying difficult-to-access targets such as those found within the tumor microenvironment.&lt;/p&gt;
      &lt;p&gt;On the flipside, aptamers are poorly suited to applications in which it is desirable to stimulate an immune response and may undergo rapid clearance in vivo unless they have been modified to prevent this.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is quite nice, but there‚Äôs a lot of modalities vying for the antibody throne, and many of those share similar benefits as aptamers. Beyond the scope of this essay for me to judge how large the value is here, but I‚Äôm sure it‚Äôs non-zero!&lt;/p&gt;
    &lt;head rend="h1"&gt;Some nuance&lt;/head&gt;
    &lt;p&gt;Every essay I write, I try to form a strong opinion to build my story on, and I‚Äôve sketched out one such opinion here: most of the value of RNA structure is in secondary structure, predicted secondary structure is quite good, and tertiary structure has a limited set of use cases. I think the argument for this position is decently strong.&lt;/p&gt;
    &lt;p&gt;But I should note that the take I have here is not a universally held opinion for those in the field, and is very much a ‚ÄòI did my research, and this is the conclusion I came to‚Äô. There are, I think, reasonable disagreements that people have had to this.&lt;/p&gt;
    &lt;p&gt;First, one paper titled Thoughts on how to think (and talk) about RNA structure argues that the seemingly high utility of secondary structure has a lot more to do with its historical ease of accessibility rather than the low utility of tertiary structure. Some context: most RNA secondary structure consists of what is called ‚ÄòWatson-Crick Pairs‚Äô, or just the tendency for RNA adenine (A) to match with Uracil (U) and Guanine (G) to pair with Cytosine (C). Non-Watson‚ÄìCrick are just any hydrogen bond that forms outside of this, which typically can only be noticed in 3D space. The aforementioned paper says this about the two:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Overall, the tendency to focus on Watson‚ÄìCrick pairs may stem from the fact that they are the basis of nucleic acid hybridization and that they are easier to identify, draw, and rationally mutate. However, non-Watson‚ÄìCrick pairing and stacking patterns in helical junctions and internal loops preform a 3D architecture that dictates the angles of emerging helices. As a result, specific parts of the RNA are spatially positioned to readily establish interactions often involving nucleotides that are far apart in sequence, but not in three dimensions‚Ä¶.Non-Watson‚ÄìCrick pairings combined with helical stacking give rise to structural motifs that provide the building blocks of many higher-order structures, including ultrastable tetraloops and their receptors, kink-turns, E-loops, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For instance, I mentioned earlier that the tertiary structure of mRNA targets is not exploited in any FDA-approved drugs. This is true, but they are being exploited in preclinical settings! For instance, Arrakis Therapeutics, a RNA-targeting-with-small molecules biotech startup with a very fun name, has this really interesting presentation showing that multiple of their ligands are able to bind to conserved, accessible 3D pockets of mRNA of the MYC protein. This is a notoriously difficult protein to directly bind to, but seemingly accessible through its mRNA.&lt;/p&gt;
    &lt;p&gt;Second and relatedly, I dismissed the value of mRNA tertiary structure, but there is an RNA modality that does something very similar to exogenous mRNA and has a very important tertiary structure: circRNA‚Äôs, or circular RNA, which form a covalently closed continuous loop. One of the giants of the field (Mihir Metkar, who was one of the primary contributors of the Moderna COVID-19 mRNA vaccine) has written a great Nature review article over mRNA broadly, and did mention that circRNA‚Äôs must rely on a fundamentally different mechanism to initiate protein translation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Because canonical mammalian translation depends on 5‚Ä≤-cap recognition, mRNAs that lack a cap [e.g. circRNA‚Äôs] require an alternative means of translation initiation. One answer is an IRES (Fig. 6).&lt;/p&gt;
      &lt;p&gt;First discovered in picornaviruses, IRESs vary with respect to both their structural complexity and their reliance on endogenous initiation factors. In general, these two features are inversely correlated, with the simplest IRESs bypassing only the cap recognition step, whereas the most structurally complex bypass even AUG recognition, relying instead on intimate direct interactions with both the large and small ribosomal subunits.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words, the IRES‚Äôs, or internal ribosome entry site, on a circRNA is the primary way it is recruited to the ribosome. This means that translation efficiency, tissue specificity, and even coding potential can hinge on whether the IRES is stable, accessible, and folded in the right way, meaning that it is a strong axis of control of a circRNA therapeutic! For example, engineering an IRES to improve translation efficacy is something that is fully possible to do. But to do this at extreme scales, we‚Äôd likely need to be able do tertiary RNA structure prediction very well, since the three-dimensional structure of IRES seems to matter a fair bit (though, admittedly, most of the experimental structure studies of IRES are for non-therapeutically relevant ones). But why even use circRNA‚Äôs over mRNA‚Äôs? One paper explains that quite well:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Compared with the canonical linear mRNA used in vaccines, circRNAs have multiple advantages.&lt;/p&gt;
      &lt;p&gt;(1) CircRNAs are more stable and easy to store, whereas mRNA vaccines exhibit extreme instability because it is susceptible to degradation by RNases during transportation, storage, delivery, etc. Although nucleotide modifications of the mRNA backbone and UTR regions make mRNA more stable, this increases cost and complicates the manufacturing process, and the storage of the resulting vaccine still requires a low-temperature cold chain due to its suboptimal thermostability. CircRNAs without any modifications exhibit high stability and RNase resistance and can be stored at room temperature or under repeated freeze‚Äíthaw conditions.&lt;/p&gt;
      &lt;p&gt;(2) CircRNAs without any modification exhibit fewer side effects. The cytotoxicity and side effects caused by mRNA vaccines are partly due to their high immunogenicity. Compared with modified mRNA, which has somewhat modulated high immunogenicity, circRNA exhibits lower immunogenicity, and lower cytotoxicity in the absence of modification.&lt;/p&gt;
      &lt;p&gt;(3) CircRNAs possess prolonged antigen-yielding capabilities and durable immune responses. The resulting longevity and thus prolonged antigen production contribute to antigen retention in antigen-presenting cells (APCs) and prolong antigen presentation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Convincing to me! Very excited to see how the circRNA space plays out.&lt;/p&gt;
    &lt;p&gt;Thirdly and finally, claiming that secondary structure for RNA is nearly solved is false, at least for mRNA used in the clinic. After all, the mRNA used in vaccines is quite biochemically distinct from the mRNA we naturally produce in one important element: the uridine nucleotide is replaced with a different chemical (the most common one being 1-methyl-pseudouridine, or m1Œ®), which is more immunologically ‚Äòquiet‚Äô. This, as you may expect, messes up secondary structure prediction a fair bit, since there are basically zero experimentally determined mRNA structures with modified nucleotides. The same Mihir Metkar paper mentioned earlier says this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Although m1Œ® substitutions have little consequence on in vitro transcription or translational fidelity, as with other naturally occurring modified nucleotide, m1Œ® can substantially alter RNA secondary structure‚Ä¶these subtle differences in individual base-pair stabilities can lead to structural changes that alter mRNA functionality (for example, creating or disrupting a RNA binding protein (RBP) binding site)...&lt;/p&gt;
      &lt;p&gt;At present, the functional competence of RNA structures that contain modified nucleotides can only be assured by empirical testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There is ongoing work to solve this problem but the datasets are still all quite small, as is typical in the RNA world.&lt;/p&gt;
    &lt;p&gt;And that‚Äôs it! Thank you for reading!&lt;/p&gt;
    &lt;p&gt;So, one, there are some cases of cryo-EM being useful for at least some RNA structures, like here, and that may accelerate as the field of cryo-EM reconstruction gets better and better. Second, NMR can be useful for RNA structure prediction problems in cases you have a crudely-predicted structure, but think you improve it by confirming the pairwise proximity of a handful of nucleotides. This is significantly more tractable, even for larger RNA, to do via NMR!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390866</guid><pubDate>Fri, 26 Sep 2025 20:47:31 +0000</pubDate></item><item><title>Moondream 3 Preview: Frontier-level reasoning at a blazing speed</title><link>https://moondream.ai/blog/moondream-3-preview</link><description>&lt;doc fingerprint="ed439b79801b9f8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Moondream 3 Preview&lt;/head&gt;
    &lt;p&gt;We're excited to announce a preview release of Moondream 3. It's a new architecture of 9B MoE, with 2B active params. Moondream now achieves frontier-level visual reasoning while still retaining blazingly fast and efficient inference.&lt;/p&gt;
    &lt;p&gt;Why A New Architecture&lt;lb/&gt; The impact of AI today has largely been relegated to the digital realm. We have agents that can code, produce digital art, and so on - but very few cases of AI operating in our physical world. No robots to clean our houses, or act as receptionists, or inspect buildings, etc‚Ä¶ For Moondream 3, we focused on 4 key areas.&lt;/p&gt;
    &lt;p&gt;Visual reasoning: despite our focus on smaller models, we don't want that to come at the cost of capability. We want Moondream to be the most capable VLM at real-world tasks.&lt;/p&gt;
    &lt;p&gt;Trainable: Many vision tasks require specialization. It's not enough for VLMs to be as good as humans. Even humans need training when it comes to complex tasks. Accurately interpreting an X-Ray image, or detecting struggling people in crowds. Moondream must be easily trainable.&lt;/p&gt;
    &lt;p&gt;Fast: Vision AI applications often need near-realtime performance. Sorting produce, or detecting missing herd animals from a drone, or recognizing security incidents - none of these tasks can be built without fast vision inference.&lt;/p&gt;
    &lt;p&gt;Inexpensive: Vision AI apps often deal with huge quantities of images, and cost can often be a blocker to adoption. Moondream must be cheap to run at scale.&lt;/p&gt;
    &lt;p&gt;Moondream 3 achieves these goals by adopting a 9B MoE model, yet still with 2B active parameters. This enables it to achieve, and in some cases beat, frontier-level models, yet still only require 2B active parameters (keeping it fast and inexpensive). We also improved its training dynamics, making Moondream 3 more efficient at learning, especially when using Reinforcement Learning (more on that in subsequent announcements). For more details on the architecture, head to the "Tech Notes" below. One final detail however: we grew the context length from 2k to 32k, making Moondream much better at understanding and producing more complex queries and answers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Moondream 3 in action&lt;/head&gt;
    &lt;p&gt;Here are some examples of Moondream 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Object Detection&lt;/head&gt;
    &lt;p&gt;Moondream 3 is astonishingly good at object detection. It goes beyond simple labels (.e.g., "car") and can understand more complex queries. We show results compared to frontier models alongside. These models don't support grounding skills like object detection and pointing natively, so we used a templated query for those (see footer).&lt;/p&gt;
    &lt;p&gt;Example 1&lt;lb/&gt; Prompt: "Runner with purple socks" &lt;/p&gt;
    &lt;p&gt;Example 2&lt;lb/&gt; Prompt: "Quantity input"&lt;/p&gt;
    &lt;head rend="h3"&gt;Pointing&lt;/head&gt;
    &lt;p&gt;Moondream supports pointing as a native skill.&lt;/p&gt;
    &lt;p&gt;Example 3&lt;lb/&gt; Prompt: "Bottle"&lt;/p&gt;
    &lt;p&gt;Example 4&lt;lb/&gt; Prompt: "Best utensil for pasta"&lt;/p&gt;
    &lt;head rend="h3"&gt;Structured output&lt;/head&gt;
    &lt;p&gt;With a longer context length, Moondream 3 generates intelligent structured outputs with minimal prompting.&lt;/p&gt;
    &lt;p&gt;Example 5: Sled dogs&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "A JSON array with keys: dog_id, fur_color, harness_color."&lt;/p&gt;
    &lt;p&gt;Result&lt;lb/&gt; [&lt;lb/&gt; { "dog_id": 1, "fur_color": "light brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 2, "fur_color": "dark brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 3, "fur_color": "gray", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 4, "fur_color": "white", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 5, "fur_color": "dark brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 6, "fur_color": "light brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 7, "fur_color": "dark brown", "harness_color": "black" },&lt;lb/&gt; { "dog_id": 8, "fur_color": "white", "harness_color": "black" }&lt;lb/&gt; ]&lt;/p&gt;
    &lt;head rend="h3"&gt;OCR&lt;/head&gt;
    &lt;p&gt;Moondream 3 has drastically improved its OCR abilities. Our vision encoder can get tripped up on tiny fonts (working on it), but it's now useful in many real-world cases.&lt;/p&gt;
    &lt;p&gt;Example 6&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "Convert to markdown""&lt;/p&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;p&gt;| Metal | Reaction | Electrode Potential (V) |&lt;lb/&gt; |---|---|---|&lt;lb/&gt; | Gold | Au‚Å∫ + e‚Åª = Au | +1.692 |&lt;lb/&gt; | Silver | Ag‚Å∫ + e‚Åª = Ag | +0.7996 |&lt;lb/&gt; | Copper | Cu¬≤‚Å∫ + 2e‚Åª = Cu | +0.342 |&lt;lb/&gt; | Iron | Fe¬≥‚Å∫ + 3e‚Åª = Fe | -0.037 |&lt;lb/&gt; | Lead | Pb¬≤‚Å∫ + 2e‚Åª = Pb | -0.126 |&lt;lb/&gt; | Nickel | Ni¬≤‚Å∫ + 2e‚Åª = Ni | -0.257 |&lt;lb/&gt; | Cadmium | Cd¬≤‚Å∫ + 2e‚Åª = Cd | -0.403 |&lt;lb/&gt; | Iron | Fe¬≤‚Å∫ + 2e‚Åª = Fe | -0.447 |&lt;lb/&gt; | Zinc | Zn¬≤‚Å∫ + 2e‚Åª = Zn | -0.762 |&lt;lb/&gt; | Aluminum | Al¬≥‚Å∫ + 3e‚Åª = Al | -1.662 |&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Here are some early benchmark results. We show it alongside some top frontier models for comparison. In practice, however, it's probably not a fair comparison for Moondream since, in practical terms, Moondream produces answers in fraction of the time of these bigger models. We'll publish more complete results later and include inference times to make this clearer.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scores with a "*" next to them indicate that we used a 100 random question sample rather than evaluate the whole benchmark.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;MD3 Preview Technical Notes&lt;/head&gt;
    &lt;p&gt;Here are some details on our new model architecture. Moondeam 3 is a fine-grained sparse mixture-of-experts model with 64 experts, of which 8 are activated for each token. We initialized it from Moondream 2 (a 2B dense model) using drop upcycling. We also extended the usable context length to 32K tokens, which is critical for few-shot prompting and agentic workflows with tool-use. We don‚Äôt fully leverage this longer context in our post-training yet (part of why it's only a preview release). The full 32k context is available for you if you're interested in fine-tuning the model.&lt;/p&gt;
    &lt;p&gt;(Figure: Long-context perplexity evaluation on GovReport dataset. Each point shows the average cross-entropy loss (nats per token) for a 128-token sliding window at that position, measured across 100 documents truncated to 32,768 tokens.)&lt;/p&gt;
    &lt;p&gt;We do not use a separate context-length extension phase during training, instead opting to interleave long-context samples while pretraining with a default context length of 4096 tokens. Many context length extension methods like YaRN include an attention temperature scaling component. Inspired by this, we adjust the architecture to enable learned temperature scaling as a function of position, and find this helps with long context modeling.&lt;/p&gt;
    &lt;p&gt;Like our last 2B release, this is a hybrid reasoning model that supports both reasoning and non-reasoning mode. Unlike other reasoning models, however, Moondream focuses on visual reasoning with grounding. Here‚Äôs an example of what that means:&lt;/p&gt;
    &lt;p&gt;Each chunk of underlined text in the reasoning is grounded, meaning the model references a particular part of the image. In our playground, you can see what the model is focusing on by hovering over the text.&lt;/p&gt;
    &lt;p&gt;The model starts with only a small set of visual-reasoning examples, and gradually learns to rely on them more during our reinforcement learning (RL) post-training phase. RL proved so effective that, as we refined our training approach, post-training ended up using more compute than the initial pre-training itself.&lt;/p&gt;
    &lt;p&gt;It was trained with load-balancing and router orthogonality losses to help similar tokens specialize together early on, then had load balancing disabled in post-training to avoid catastrophic forgetting from distribution shift. Finally, attention tweaks like learnable temperature and LSE suppression sharpened focus and cut noise‚Äîboosting accuracy and clarity.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This preview release comes with some caveats. We haven't optimized the inference code yet, so inferences are much slower than anticipated (we're working on it!). We're also still actively training this model, and we expect the capabilities and benchmarks scores to improve. We also plan to produce variants of this model (e.g., quantized versions and distilled smaller versions).&lt;/p&gt;
    &lt;p&gt;The model is now available on the Moondream playground, and you can download it on HuggingFace (Moondream Station will be updated soon). Hit us up on our Discord if you have any questions.&lt;/p&gt;
    &lt;p&gt;(1) Frontier models don't support object detection natively, so this prompt was used instead:&lt;lb/&gt; Detect these objects in the image: [comma-separated list].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391444</guid><pubDate>Fri, 26 Sep 2025 21:59:57 +0000</pubDate></item><item><title>Thoughts on Mechanical Keyboards and the ZSA Moonlander</title><link>https://www.masteringemacs.org/article/thoughts-on-mechanical-keyboards-zsa-moonlander</link><description>&lt;doc fingerprint="4d545c11f59d8556"&gt;
  &lt;main&gt;
    &lt;p&gt;I don‚Äôt normally review things here, as I find that it‚Äôs outside the realm of the blog, but I want to talk about the ZSA Moonlander keyboard, a ‚Äúmechanical‚Äù keyboard that I bought a couple of years ago. But, yeah, in case you‚Äôre wondering why I am writing a review: I mean, it‚Äôs a keyboard? You type on it. It goes clickety-clack ‚Äî or maybe not, if you‚Äôre an obsessive and want your keyboard quiet. Or maybe you want it loud, like the flexor-destroying IBM model Ms from the days of yore, rat-tat-tatting like a Mac-10. People are into that now: they need to sound right, look right (boba tea colored keys are a thing) and type well. If they light up like a cheap vape stick, even better.&lt;/p&gt;
    &lt;p&gt;To me, it‚Äôs a tool; it‚Äôs there to minimize strain and injury. I bought the moonlander because it helps me do my job. It‚Äôs no different to me than a hammer is to a carpenter, and yet in using it I‚Äôve realized it does expand on what I can do in ways that I feel compelled to talk about. It is a game changer to any keyboard warrior. ZSA‚Äôs moonlander is merely one well-crafted incarnation of millions.&lt;/p&gt;
    &lt;p&gt;Ricing your keyboard is a hobby. It‚Äôs nearly a religion to some folk: like crossfit and instant pots.&lt;/p&gt;
    &lt;p&gt;One major benefit of this movement is the wealth of opportunity afforded to people like me, and you, who care about finger ergonomy but do not find the old-fashioned options that have long existed on the periphery of peripherals.&lt;/p&gt;
    &lt;p&gt;The specifics of what makes, or doesn‚Äôt make, a mechanical keyboard is, I am sure, a tedious conversation that takes place all the time, so I‚Äôll hide behind the phrase I‚Äôll know it when I see it and move swiftly on. (But I‚Äôll argue that quality key switches and firmware are two of the most important ones.)&lt;/p&gt;
    &lt;p&gt;It‚Äôs interesting how it‚Äôs a whole thing now for enthusiasts to solder, assemble, or buy ready-made mechanical keyboards made by other enthusiasts. It‚Äôs also a sign of how dire traditional, commercial keyboards are in quality and choice. With a mechanical keyboard you can pick the type of key switch you want your keys to have: quiet, loud, firm, soft. Linear or non-linear. You can mix and match so some keys are weightier than others: your thumbs are stronger, so you‚Äôll want a weightier key for them.&lt;/p&gt;
    &lt;p&gt;I feel like this movement has sprung up out of nowhere in the last ten years, and it‚Äôs resulted in a lot of fun and interesting keyboards. There are novel firmware choices beyond the most manifestly basic idea that pressing a key yields exactly one outcome.&lt;/p&gt;
    &lt;p&gt;Clacky keys and boba tea colored key caps is not why I bought into the mechanical keyboard hype. I have long wanted to ditch the Microsoft Natural Ergonomic 4000 keyboards (who came up with that name?)&lt;/p&gt;
    &lt;p&gt;I had two at all times: one at home and another at work. They‚Äôd wear out from use after a couple of years. Total flim-flam. The typing experience was never great, either. But I loved the ergonomic design. I‚Äôve owned around 10 in the last 20 years, as the ergonomics of the keyboard (and lack of serious alternatives) kept me from switching.&lt;/p&gt;
    &lt;p&gt;You see, mechanical keyboards offer hardware flexibility like switchable key caps and switches (the bit that goes click), true; but most of them also come with fancy, free software firmware that opens up a whole world of amazing possibilities. I‚Äôve worked in some pretty weird work environments, and being able to rebind caps lock to control is one of the most important things I have to do on a traditional keyboard, like the aforementioned Microsoft keyboard. I once had to work at a client‚Äôs place that mandated I use a garbage-tier Citrix thin client computer that‚Äôd read your keyboard‚Äôs scan codes and make up its mind later, somewhere en-route to a data center in Paris, what key it should treat it as. I don‚Äôt have to tell you that rebinding caps lock to much of anything did not work at all.&lt;/p&gt;
    &lt;p&gt;But, with thoroughly customizable firmware, it‚Äôs a snap to deign a key to be what ever you choose; or even multiple things, at different times. Your customizations are in the keyboard‚Äôs firmware itself, so you take your changes with you. That‚Äôs perfect for someone like me that used to crash through the windows of many a client sites, Mary Poppins-style, keyboard in hand, ready to build software.&lt;/p&gt;
    &lt;p&gt;The value and flexibility of the firmware really is that useful and important. I now recommend that people consider this style of keyboard (or, at the very least, the programmable aspects of a mechanical keyboard) in my book, as it‚Äôs a good way to personalize your keyboard workflow to suit your style and needs. Forget binding caps lock to control: move your keys around to suit your physical needs. That is infinitely better than crudely remapping caps lock to control.&lt;/p&gt;
    &lt;p&gt;Back to the Moonlander. The product page did a reasonable (if overly flashy) job of explaining its key benefits over a regular keyboard. The cost? $365. Ouch. It‚Äôs not that much money for something that I myself use to make money, but it‚Äôs like‚Ä¶ it‚Äôs just a keyboard. What‚Äôs it made out of!? Pressed myrrh and printer ink?&lt;/p&gt;
    &lt;p&gt;Still, it‚Äôs not a bad price if the finish and quality matches the price. So I bought it, and it took about 7-8 days to arrive at my house in London, all the way from Taiwan. Returns are apparently not possible, fair enough, as ZSA‚Äôs a small business, and Taiwan is a long way away. They recommend you try and sell it yourself if you dislike it. Spare a thought for the guy on eBay who was selling one with blank key caps, around the time I was buying mine, saying it was ‚Äòbarely used‚Äô‚Ä¶&lt;/p&gt;
    &lt;p&gt;The keyboard only has two years of warranty, though they claim it‚Äôs ‚Äòbuilt to last‚Äô. So fingers crossed as I‚Äôm coming up on 4 years of daily use.&lt;/p&gt;
    &lt;p&gt;What I like about it is that it ticked my main requirement of being touch typist friendly. Sounds dumb, but it has to feel right. Regular keyboards are too packed together. I‚Äôm a big guy: I don‚Äôt want to squash my shoulders and arms like I do when I type on a laptop keyboard. The keyboard is actually two keyboards. One half of a keyboard for each hand. The right-hand side has a removable cable that plugs into the left-hand side, so you could conceptually get by with just one side, which is a nice touch. The left-hand side has the USB cable, also removable, to connect to your computer. Because it‚Äôs in two pieces, I can move each half of the keyboard around to better fit my posture. I like that feature a lot.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also surprisingly small, which is not always a benefit, as I‚Äôm wide-shouldered with big hands, but it works for me. The portability was not what I was looking for, but it‚Äôs come in handy for traveling, as it comes with a soft case pouch. You can put it in carry-on luggage quite easily and take it with you. That‚Äôs proven more useful than I thought it would. I‚Äôve flown with the Microsoft keyboards too many times to count, and they‚Äôre bulky by comparison.&lt;/p&gt;
    &lt;p&gt;Much like so many keyboards of its type, it comes with ‚Äúthumb clusters‚Äù, a set of four keys that are meant to be reachable primarily with your thumbs. I have large hands, so that works for me, but the red buttons they have on there are a stretch, even for me, to press without shifting my wrist. You can pivot the thumb cluster up or down (or lay it flat against your desk) which is finicky as all hell, as you have to lock it in place and somehow try to keep it from wobbling.&lt;/p&gt;
    &lt;p&gt;One, ah, novelty of the Moonlander is what they call tenting. It‚Äôs a pole that you can use to tilt each half of the keyboard to attain ‚Äì they claim ‚Äì a more ‚Äòergonomic‚Äô position for your hands. The problem is, when you‚Äôre pitching your ‚Äòtent‚Äô (stop snickering), locking it into position (you‚Äôll need a hex key to fasten the bolts on the thumb clusters and poles) so that your keyboard does not wobble is challenging to say the least. It works much like a table in a restaurant: no matter what, it‚Äôs going to wobble a bit. Maybe not today, but perhaps tomorrow; or when you type a bit more forcefully; or when you put more weight on one part of the keyboard because you pressed a button a bit more forcefully.&lt;/p&gt;
    &lt;p&gt;It‚Äôs poorly designed. I don‚Äôt want to overtighten the bolts for fear of shearing something, and even if you do want to throw a bit more torque into it, you‚Äôre most likely going to push the cluster or tent pole out of position when you try, resulting in a wobbly keyboard. One frustration I ran into is that you cannot pivot the thumb cluster up, so it juts into the air, and also use the tent poles. That leaves the keyboard unbalanced and you cannot type on it.&lt;/p&gt;
    &lt;p&gt;The keyboard also has two optional hand rests that pivot so you can fold them underneath the keyboard for portability. They‚Äôre made of the same flimsy plastic that train station lavatory seats are made of. Worse, they have a few unfinished edges ‚Äî not at all sharp enough to hurt you, but still sharp enough that you‚Äôre reminded of how little attention was lavished on this part of an otherwise really well-made keyboard. The rests are attached to a bar to let them pivot, but unfortunately the manufacturing tolerances aren‚Äôt great, so they wobble a bit when I shift the weight of my hands around, which is also not good. I wish it had a nice leatherette foam cushion like the Microsoft keyboards did, as the plastic is hard to the touch.&lt;/p&gt;
    &lt;p&gt;I got one of those automated emails after a few months asking for feedback, and I asked about the wobbly rests and unfinished edges; and how you can‚Äôt tilt the keyboard and also raise the keyboard cluster. I got a polite email back explaining that the wobble had to be there to facilitate movement and give, and that I could buy their tenting kit to fix the keyboard cluster problem. No answers were forthcoming on the unfinished edges. Make of that what you will.&lt;/p&gt;
    &lt;p&gt;The keyboard is backlit with RGB LEDs, which are a bit frou-frou, though useful if you want to use the firmware‚Äôs layering functionality to add multi-modality to keys. Being able to tell layers apart by looking at the keyboard colors work well. The keyboard uses the QMK firmware, a polished and feature rich free software firmware that‚Äôs been extended with Moonlander-specific features. Their firmware changes are public and available on Github.&lt;/p&gt;
    &lt;p&gt;The main advantage of Moonlander (really, the QMK firmware) is the ability to program your keys to do more than just one thing. Yes, you can do keyboard macros, but that is not even the most interesting thing. For instance, you can make a key ‚Äì say your space key ‚Äì act as the control modifier if you hold it down and type another key at the same time. You can make it behave like a Space Cadet keyboard: tap left shift and it inserts &lt;code&gt;(&lt;/code&gt;; right, and it inserts &lt;code&gt;)&lt;/code&gt;. You can designate a key to toggle a new keyboard layer, letting you type accented characters, control your media player with media keys, and more. There are dozens of features and you have complete control over what each key will do.&lt;/p&gt;
    &lt;p&gt;I ordered the keyboard with the recommended Cherry Brown MX switches ‚Äì those are the key switches the plastic key caps sit atop of, and you can choose which ones you want when you buy, or even replace them yourself after the fact ‚Äì and they, much like the key caps and the main body of the keyboard, are of high quality and feel good to type on. I have zero complaints about this part of the build quality, and the main body of the keyboard is well made and sturdy. I can tell they spent a lot of engineering effort on that.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a lot of dubious health advice on ergonomics out there that feels unfounded and speculative. And proponents of mechanical keyboards say you need fewer keys than a regular keyboard, for reasons, and to instead use the fancy firmware features to make up for the things they‚Äôve taken away from you, in effect forcing you to use the layer functionality present in the firmware. By and large the mechanical keyboard community is friendly, but more than a little fad-driven and with that spicy melange of broscience and earnest helpfulness.&lt;/p&gt;
    &lt;p&gt;This keyboard, like many of its kind, is not a ‚Äúfull-sized‚Äù keyboard. There are fewer keys. No F-keys by default, though they‚Äôre behind a layered key in the default configuration; the dedicated column of navigation (arrows, page up/down, etc.) keys are missing, though scattered about. There is no dedicated section of numpad keys, either. The keys are all there, but hidden behind several layers that you access from certain trigger keys that activate when you press one of them.&lt;/p&gt;
    &lt;p&gt;I‚Äôm ambivalent about losing out on all the keys, especially as, well, I‚Äôm an Emacs user. I‚Äôve adapted, and it‚Äôs fine, and I like the current setup I have now, but that part will take some getting used to. It took me a long time to get back up to speed, and there are still key combos that I could tap out with lightning speed on my old keyboard that I still struggle to type as fast: &lt;code&gt;C-M--&lt;/code&gt; (negative argument) followed by another key, such as &lt;code&gt;C-M-k&lt;/code&gt;, is one such example.&lt;/p&gt;
    &lt;p&gt;I wish I had more keys, yet ironically I have empty keys I do not use at all on the keyboard. That sounds like a contradictory statement, but it‚Äôs hard to fill out all the keys when you‚Äôre confined to the keyboard layout that you have, which necessitates the use of layers, which in some ways (and that is the point) renders the need for more keys unnecessary. A vexing paradox for sure.&lt;/p&gt;
    &lt;p&gt;One thing I think ZSA has done exceptionally well is their custom software stack. They‚Äôve built a wonderful, interactive browser-based keyboard designer that makes it a breeze to not only change and experiment with your keyboard layout, but also view others‚Äô layouts as well. I like their hardware well enough ‚Äì but it‚Äôs just a keyboard to me ‚Äì but I think they‚Äôve done an outstanding piece of work with the software. When I first got it, I had to download the compiled keyboard ROM and use their easy-to-use tool to flash the keyboard ROM.&lt;/p&gt;
    &lt;p&gt;No more: their layout builder asks for permission to talk to your keyboard directly using WebUSB in the browser and, if you accept, it‚Äôll flash your keyboard‚Äôs firmware for you automatically. Very nice. If you use Chrome that is. If you‚Äôre using Firefox like I do, then you have to download the firmware and flash it the normal way because the lumpenproletariat who run the security division at Mozilla have decided that WebUSB is‚Ä¶ ‚Äòinsecure.‚Äô&lt;/p&gt;
    &lt;p&gt;The layout builder, the web flashing and the ease of use of it all speaks volumes. Someone‚Äôs actively working on improving the user experience which is honestly poor, if you just use the QMK firmware directly. Yes, there are interactive keyboard builders for QMK directly, but if you run into trouble, or if you want to do something esoteric, you‚Äôre going to have to start reading the C source code and fiddle with it.&lt;/p&gt;
    &lt;p&gt;So. Is it a good keyboard? Yes. It would be a great keyboard if they‚Äôd tweak the issues I have around fit and finish of the hand rests, and make it easier to balance the keyboard. The main reason you should look into a mechanical (QMK-based!) keyboard is that it objectively improves your primary interface with your computer. The QMK firmware‚Äôs value-adds ‚Äì and I have only scratched the surface ‚Äì is 80% of it. If you have a crappy OEM keyboard or if you‚Äôre plinking away on a laptop ‚Äî get a mechanical keyboard! Your wrists and fingers will thank you in the long run.&lt;/p&gt;
    &lt;p&gt;The Moonlander keyboard is a safe buy and, aside from the issues I mentioned, it is worth the $365. That‚Äôs a dollar a day for a year ‚Äî small potatoes. And if you‚Äôre strapped for cash, try searching AliExpress for mechanical keyboards. The Chinese have taken to it with gusto, and you can buy or build your own for not much money and experiment.&lt;/p&gt;
    &lt;p&gt;I program in Emacs for a living, so being able to move my modifier keys to the thumbs is a big improvement, for no other reason that they‚Äôre there and underused on most regular keyboards. Being able to multi-task keys to do more than one thing is also a massive win, and another reason to consider a programmable keyboard.&lt;/p&gt;
    &lt;p&gt;Get a mechanical keyboard. Make sure it has QMK firmware. Maybe a Moonlander if you can spare the cash. Go.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391566</guid><pubDate>Fri, 26 Sep 2025 22:17:03 +0000</pubDate></item><item><title>New math revives geometry's oldest problems</title><link>https://www.quantamagazine.org/new-math-revives-geometrys-oldest-problems-20250926/</link><description>&lt;doc fingerprint="8f5c03150ab107f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New Math Revives Geometry‚Äôs Oldest Problems&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In the third century BCE, Apollonius of Perga asked how many circles one could draw that would touch three given circles at exactly one point each. It would take 1,800 years to prove the answer: eight.&lt;/p&gt;
    &lt;p&gt;Such questions, which ask for the number of solutions that satisfy a set of geometric conditions, were a favorite of the ancient Greeks. And they‚Äôve continued to entrance mathematicians for millennia. How many lines lie on a cubic surface? How many quadratic curves lie on a quintic surface? (Twenty-seven and 609,250, respectively.) ‚ÄúThese are really hard questions that are only easy to understand,‚Äù said Sheldon Katz, a mathematician at the University of Illinois, Urbana-Champaign.&lt;/p&gt;
    &lt;p&gt;As mathematics advanced, the objects that mathematicians wanted to count got more complicated. It became a field of study in its own right, known as enumerative geometry.&lt;/p&gt;
    &lt;p&gt;There seemed to be no end to the enumerative geometry problems that mathematicians could come up with. But by the middle of the 20th century, mathematicians had started to lose interest. Geometers moved beyond concrete problems about counting, and focused instead on more general abstractions and deeper truths. With the exception of a brief resurgence in the 1990s, enumerative geometry seemed to have been set aside for good.&lt;/p&gt;
    &lt;p&gt;That may now be starting to change. A small cadre of mathematicians has figured out how to apply a decades-old theory to enumerative questions. The researchers are providing solutions not just to the original problems, but to versions of those problems in infinitely many exotic number systems. ‚ÄúIf you do something once, it‚Äôs impressive,‚Äù said Ravi Vakil, a mathematician at Stanford University. ‚ÄúIf you do it again and again, it‚Äôs a theory.‚Äù&lt;/p&gt;
    &lt;p&gt;That theory has helped to revive the field of enumerative geometry and to connect it to several other areas of study, including algebra, topology and number theory ‚Äî imbuing it with fresh depth and allure. The work has also given mathematicians new insights into all sorts of important number systems, far beyond the ones they‚Äôre most familiar with.&lt;/p&gt;
    &lt;p&gt;At the same time, these results are raising just as many questions as they answer. The theory spits out the numbers that mathematicians are seeking, but it also gives additional information that they‚Äôre struggling to interpret.&lt;/p&gt;
    &lt;p&gt;That mystery has inspired a new generation of talent to get involved. Together, they‚Äôre bringing counting into the 21st century.&lt;/p&gt;
    &lt;head rend="h2"&gt;Counting Forward&lt;/head&gt;
    &lt;p&gt;All enumerative geometry problems essentially come down to counting objects in space. But even the simplest examples can quickly get complicated.&lt;/p&gt;
    &lt;p&gt;Consider two circles some distance apart on a piece of paper. How many lines can you draw that touch each circle exactly once? The answer is four:&lt;/p&gt;
    &lt;p&gt;You can slide these circles further apart, or shrink one to half its size, and the answer won‚Äôt change. But move one circle so that it intersects the other like a Venn diagram, and suddenly the answer does change ‚Äî from four to two. Slide whichever circle is smaller entirely inside the bigger one, and now the answer is zero: You can‚Äôt draw any lines that touch each circle only once.&lt;/p&gt;
    &lt;p&gt;Such inconsistencies are a real pain. In this example, there were only three different configurations to consider, but often the problem is too complicated for researchers to work through every possible case. You might find the answer for one case, but you‚Äôll have no idea how it will change when you move things around.&lt;/p&gt;
    &lt;p&gt;In practice, mathematicians try to write the problem‚Äôs geometric constraints as a collection of equations, then figure out how many solutions satisfy all those equations simultaneously. But even though they know that the number of solutions won‚Äôt always stay consistent, there‚Äôs nothing in the nature of the equations they write down that indicates whether they‚Äôve stumbled on a new configuration that will yield a different answer.&lt;/p&gt;
    &lt;p&gt;There‚Äôs one exception ‚Äî when the problem is defined in terms of complex numbers. A complex number has two parts: a ‚Äúreal‚Äù part, which is an ordinary number, and an ‚Äúimaginary‚Äù part, which is an ordinary number multiplied by the square root of ‚àí1 (what mathematicians call i).&lt;/p&gt;
    &lt;p&gt;In the example above with the circles and lines, if you ask for the number of complex solutions to your equations, you always get four as your answer, no matter what arrangement you look at.&lt;/p&gt;
    &lt;p&gt;By around 1900, mathematicians had developed techniques to solve any enumerative geometry problem in the complex realm. These techniques didn‚Äôt have to take different configurations into account: No matter what answer mathematicians got, they knew it had to be true for every configuration.&lt;/p&gt;
    &lt;p&gt;But the methods were no longer effective when mathematicians only wanted to find, say, the number of real solutions to the equations in an enumerative geometry problem, or the number of integer solutions. If they asked an enumerative geometry problem in any number system other than the complex one, inconsistencies cropped up again. In these other number systems, mathematicians couldn‚Äôt address enumerative questions systematically.&lt;/p&gt;
    &lt;p&gt;At the same time, the mysterious, shifting answers that mathematicians encountered when they limited themselves to the integers, or to the real numbers, made enumerative questions a great way to probe those other number systems ‚Äî to better understand the differences between them, and the objects that live inside them. Mathematicians thought that developing methods to deal with these settings would open up new, deeper areas of mathematics.&lt;/p&gt;
    &lt;p&gt;Among them was the mathematical great David Hilbert. When he penned a list of what he considered the most important open problems of the 20th century, he included one about making the techniques for solving enumerative geometry questions more rigorous.&lt;/p&gt;
    &lt;p&gt;In the 1960s and ‚Äô70s, Alexander Grothendieck and his successors developed novel conceptual tools that helped resolve Hilbert‚Äôs problem and set the foundation for the field of modern algebraic geometry. As mathematicians pursued an understanding of those concepts, which are so abstract that they remain impenetrable to nonspecialists, they ended up leaving enumerative geometry behind. Meanwhile, when it came to enumerative geometry problems in other number systems, ‚Äúour techniques hit a brick wall,‚Äù Katz said. Enumerative geometry never became the beacon that Hilbert had imagined; other threads of research illuminated mathematicians‚Äô way instead.&lt;/p&gt;
    &lt;p&gt;Enumerative geometry no longer felt like a central, lively area of study. Katz recalled that as a young professor in the 1980s, he was warned away from the subject ‚Äúbecause it was not going to be good for my career.‚Äù&lt;/p&gt;
    &lt;p&gt;But a few years later, the development of string theory temporarily gave enumerative geometry a second wind. Many problems in string theory could be framed in terms of counting: String theorists wanted to find the number of distinct curves of a certain type, which represented the motion of strings ‚Äî one-dimensional objects in 10-dimensional space that they believe form the building blocks of the universe. Enumerative geometry ‚Äúbecame very much in fashion again,‚Äù Katz said.&lt;/p&gt;
    &lt;p&gt;But it was short-lived. Once physicists answered their questions, they moved on. Mathematicians still lacked a general framework for enumerative geometry problems in other number systems and had little interest in pursuing one. Other fields seemed more approachable.&lt;/p&gt;
    &lt;p&gt;That was the case until the mathematicians Kirsten Wickelgren and Jesse Kass came to a sudden realization: that enumerative geometry might provide the exact kind of deep insights that Hilbert had hoped for.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Bird‚Äôs-Eye View&lt;/head&gt;
    &lt;p&gt;Kass and Wickelgren met in the late 2000s and soon became regular collaborators. In many ways their demeanors couldn‚Äôt be more different. Wickelgren is warm, but restrained and deliberate. Whenever I asked her to confirm that I‚Äôd understood a given statement correctly, she‚Äôd pause for a moment, then answer with a firm ‚ÄúYes, please‚Äù ‚Äî her way of saying ‚ÄúExactly, you‚Äôve got it!‚Äù Kass, on the other hand, is nervously enthusiastic. He‚Äôs easily excited and talks at a rapid-fire pace.&lt;/p&gt;
    &lt;p&gt;But Kass and Wickelgren worked well together and shared many interests ‚Äî including a love for extending geometry‚Äôs reach into other fields.&lt;/p&gt;
    &lt;p&gt;In 2015, Kass was passing through Atlanta, where Wickelgren lived, and decided to approach her with his latest obsession: He wanted to revisit enumerative questions in restricted number systems, that long-abandoned endeavor.&lt;/p&gt;
    &lt;p&gt;He brought along a bunch of loose ideas and old papers that seemed relevant. ‚ÄúI realized this was a kind of pie-in-the-sky project,‚Äù Kass said. ‚ÄúShe very politely explained to me that all my answers were nonsense.‚Äù Then he mentioned a result from 1977, and suddenly ‚Äúa light bulb went off.‚Äù&lt;/p&gt;
    &lt;p&gt;In that 1977 paper, the mathematicians Harold Levine and David Eisenbud were working out a proof that involved counting. They ended up with a special type of expression called a quadratic form ‚Äî a simple polynomial where each term‚Äôs exponents always add up to 2, such as x2 + y2, or z2 ‚àí x2 + 3yz.&lt;/p&gt;
    &lt;p&gt;Eisenbud and Levine realized that the count they were interested in was hidden in plain sight. The answer lay in the form‚Äôs ‚Äúsignature‚Äù: the number of positive terms minus the number of negative terms. (For example, the quadratic form z2 ‚àí x2 + 3yz has two positive terms, z2 and 3yz, and one negative term, x2, so its signature is 2 ‚àí 1, or 1.)&lt;/p&gt;
    &lt;p&gt;This was Wickelgren‚Äôs light bulb. In the decades since Eisenbud and Levine had published their proof, mathematicians had devised a seemingly unrelated framework called motivic homotopy theory. That framework, which treated solutions to equations as special mathematical spaces and studied the relationships between them, was both sophisticated and powerful. Among other things, it gave mathematicians a way to describe those relationships using particular kinds of quadratic forms.&lt;/p&gt;
    &lt;p&gt;Listening to Kass, Wickelgren immediately recognized that Eisenbud and Levine had come up with one of these forms. The mathematicians had been doing motivic homotopy theory without realizing it ‚Äî and it had given them the answer they‚Äôd been seeking.&lt;/p&gt;
    &lt;p&gt;And while Eisenbud and Levine weren‚Äôt working on an enumerative geometry problem, it was similar enough in flavor ‚Äî it involved counting, after all ‚Äî that it got Kass and Wickelgren thinking. Perhaps they could solve their own counting problems using the framework of motivic homotopy theory, too. And since motivic homotopy theory could be broadly applied to any number system, perhaps it would unlock the enumerative geometry questions in those settings that had eluded mathematicians for so long.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Deeper View&lt;/head&gt;
    &lt;p&gt;Remember that typically, an enumerative geometry problem involves finding the number of solutions that satisfy a collection of equations. Kass and Wickelgren‚Äôs insight was not to try to solve those equations directly ‚Äî it rarely worked in settings other than the complex numbers. Instead, the pair rewrote a given enumerative geometry question (set in a given number system) in terms of spaces of equations and functions that described the relationship between those spaces.&lt;/p&gt;
    &lt;p&gt;With the problem reformulated in this way, they could apply motivic homotopy theory to it. This allowed them to compute a quadratic form. Now they had to figure out what information that quadratic form contained about their original problem.&lt;/p&gt;
    &lt;p&gt;When they were working in the complex numbers, they realized, all they had to do was count up the number of different variables in the quadratic form they‚Äôd computed. That number gave them the number of solutions to their enumerative geometry problem. Of course, this wasn‚Äôt particularly interesting to them: Mathematicians already had good techniques for getting this answer.&lt;/p&gt;
    &lt;p&gt;So they moved on to other number systems. For the real numbers, it got a little trickier. Once they computed the quadratic form in this setting, they had to look at its signature instead. And the signature didn‚Äôt give the precise answer: It gave a minimum for what the answer could be. That is, for any enumerative geometry problem involving real numbers, they had a way to calculate a lower bound ‚Äî a good starting place.&lt;/p&gt;
    &lt;p&gt;But most exciting of all was that when they computed a quadratic form for other, stranger number systems, they could also glean important information. Take a looping system of seven numbers that operates on what‚Äôs called clock arithmetic: In such a system, 7 + 1 equals 1 instead of 8. In this system, they rewrote their quadratic form as an array of numbers called a matrix. They then calculated a quantity called the determinant and proved that while it didn‚Äôt tell them the total number of solutions, it did tell them something about what proportions of those solutions had certain geometric properties.&lt;/p&gt;
    &lt;p&gt;In 2017, Kass and Wickelgren showcased this for one of enumerative geometry‚Äôs most famous theorems: that a cubic surface can contain at most 27 lines. Using their new methods, they showed that indeed, the answer is 27 in the complex numbers. They replicated a known lower bound for the real numbers ‚Äî and provided new numerical information for every finite number system. It all came in one package.&lt;/p&gt;
    &lt;p&gt;It was one of the first times mathematicians had been able to say anything significant about enumerative geometry problems for systems outside the complex and real numbers. Moreover, while the problem‚Äôs answer might change depending on the number system and the configuration of shapes within it, for the first time mathematicians had found one theory that could encompass all those potential different answers.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs not just about the real numbers or the complex numbers,‚Äù Wickelgren said. ‚ÄúThey‚Äôre just special cases of a result that holds in any number system.‚Äù&lt;/p&gt;
    &lt;p&gt;And that was only the beginning.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New Start&lt;/head&gt;
    &lt;p&gt;In the years since, Wickelgren, Kass and others have reframed a host of other enumerative problems using motivic homotopy theory, deriving the relevant quadratic forms in various number systems.&lt;/p&gt;
    &lt;p&gt;‚ÄúAll the geometric constructions used to give people integer answers,‚Äù said Marc Levine, a mathematician at the University of Duisburg-Essen who has been independently exploring the same ideas. ‚ÄúNow you can feed [the problem] in and get something which will give you a quadratic form as an answer.‚Äù&lt;/p&gt;
    &lt;p&gt;Mathematicians have made a lot of progress since Kass and Wickelgren‚Äôs original work when it comes to understanding what information a quadratic form can give them in different number systems. Sometimes, though, they‚Äôre not sure what to look for in the quadratic form. ‚ÄúWe‚Äôre still kind of mystified about what exactly it tells you,‚Äù Levine said. There‚Äôs a lot left to interpret.&lt;/p&gt;
    &lt;p&gt;‚ÄúAt this point,‚Äù said Aravind Asok of the University of Southern California, trying to glean information about enumerative geometry problems from quadratic forms ‚Äúis an entire industry.‚Äù It‚Äôs also concrete and accessible, which has attracted the attention of young mathematicians, he added. ‚ÄúIt‚Äôs exciting because students can get into something with meat sort of quickly.‚Äù&lt;/p&gt;
    &lt;p&gt;Such concreteness is unusual in today‚Äôs abstract mathematical landscape. ‚ÄúThe math keeps going one level higher in abstraction, and then sometimes I feel like I don‚Äôt know what I‚Äôm talking about anymore,‚Äù said Sabrina Pauli, who was Wickelgren‚Äôs first graduate student and is now a professor at the Technical University of Darmstadt in Germany. But this new area of research gives her a way to bring that high level of abstraction back down to earth.&lt;/p&gt;
    &lt;p&gt;Wickelgren, Kass, Levine and others have recently used their techniques to revisit enumerative questions related to string theory ‚Äî but in new number systems and settings.&lt;/p&gt;
    &lt;p&gt;In all these cases, mathematicians have found a new way to explore how points, lines, circles and far more complicated objects act differently in different numerical contexts. Kass and Wickelgren‚Äôs revived version of enumerative geometry provides an unlikely window into the very structure of numbers. ‚ÄúIt would be hard for me not to be drawn to the question that asks how many rational curves are there on a sheet of paper,‚Äù Wickelgren said. ‚ÄúThat‚Äôs a fundamental part of the mathematical reality of a sheet of paper.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391871</guid><pubDate>Fri, 26 Sep 2025 22:57:57 +0000</pubDate></item><item><title>The Obsessively Complete Infocom Catalog</title><link>https://eblong.com/infocom/</link><description>&lt;doc fingerprint="27623a4966b10e92"&gt;
  &lt;main&gt;&lt;p&gt;This site is my attempt to collect every single version of each Infocom game, both source code and compiled game files. I have labelled each package with release and serial number information where possible. (Infocom serial numbers were a timestamp of the compilation date, which is very useful for reconstructing the development sequence.)&lt;/p&gt;&lt;p&gt;IF fans of the modern era have used this source code to recompile the Infocom games. Some have taken the opportunity to fix bugs or modify the games. This collection does not include these modern recompilations and updates. (I have no quarrel with them, but I'm not going to keep track.)&lt;/p&gt;&lt;p&gt;This collection does include a few fan-modified game files that date from the 1980s. (The modifications only extend to the serial and release numbers.) I include these because they were contemporary with Infocom and thus have some historical interest. Also, they were collected in the early 90s and wound up in the game file lists of the nascent Internet IF community.&lt;/p&gt;&lt;p&gt;Jason Scott began this process in April of 2019, when he posted a large collection of Infocom source code on GitHub. Source code and compiled files, in fact.&lt;/p&gt;&lt;p&gt;This was tremendously exciting to fans and scholars of old-school text adventures. This material was known to be out there in private collections, but it had never been publicly available in this form.&lt;/p&gt;&lt;p&gt;Jason's collections are excellent, but they are an edited extract from one source: the so-called "Infocom Drive". They omit some published variations, beta-tests, and so on. I figure it's good to have every Infocom game file variation in one place.&lt;/p&gt;&lt;p&gt;Nonetheless, let me be clear: this site would not exist without Jason Scott's efforts. Thank you, Jason! Also thanks to Beaux Hemmer for maintaining the patch collection. Thanks to Torbj√É¬∂rn Andersson and Alessandro Giassi for enthusiastic help tracking down more versions and info on them. And, of course, thanks to the Implementors who created these games in the first place.&lt;/p&gt;&lt;p&gt;Update, December 2019: Another cleaned-up source collection has been posted by Adam Sommerfield.&lt;/p&gt;&lt;p&gt;You can download a catalog of the whole file collection (JSON format): catalog.json.&lt;/p&gt;&lt;p&gt;(Note that the "updated" field is when I added or last updated the file on this site.)&lt;/p&gt;&lt;p&gt;If you want to download everything in one go, grab allgamefiles.zip, allsources.zip, allinterpreters.zip, and allother.zip.&lt;/p&gt;&lt;p&gt;These are proprietary documents. The copyright rests with Activision. Mind you, Activision certainly doesn't have the development tools or the expertise to compile this source code any more. Quite likely they don't even have the source code any more. If it weren't for private collectors passing it around, this material would be entirely lost.&lt;/p&gt;&lt;p&gt;Like Jason, I believe that the historical value of these documents to the IF community outweighs the rights of the legal owner. As I wrote in April, copyright is a balance. Activision has not commented on the matter.&lt;/p&gt;&lt;p&gt;The GitHub repositories structure the source code as a sequence of commits, showing the development process. This site packages each source directory separately.&lt;/p&gt;&lt;p&gt;This site includes game files collected from original game releases. These have historically been collected as "patch files". This was a legal figleaf; it allowed a user to transform a legally-owned game file into a different version, without actually distributing copies of each version. I have used those transforms to recreate all known game file versions.&lt;/p&gt;&lt;p&gt;Several of the GitHub repositories contain a common error: an old source file is sometimes not deleted in newer commits. For example, the Zork 2 source contains "crufty.zil" in r22 and r48, but this file has been removed in r63. The GitHub zork2 repo fails to delete it. This site avoids that error.&lt;/p&gt;&lt;p&gt;The GitHub repos omit personal email and individual developers' comments found in the source collection. This site does too; I followed Jason's example in this matter. It is not my intent to expose private communication, even thirty years after the fact.&lt;/p&gt;&lt;p&gt;However, I have included a few files that Jason omitted, primarily "browsie/feelie" manuscripts intended for the game package.&lt;/p&gt;&lt;p&gt;The game files collected here are Z-code files, which may be played with any Z-code interpreter. The source packages contain ZIL source code and associated files.&lt;/p&gt;&lt;p&gt;Z-code files come in various versions. Infocom referred to these as "zip" (version 3), "ezip (version 4), "xzip" (version 5), and "yzip" (version 6). They used the ".zip" file suffix for all of these; the version is distinguished by the first byte of the game file. These days, ".zip" is a compression format, so we tag files as ".z3", ".z4", ".z5", ".z6".&lt;/p&gt;&lt;p&gt;This collection also includes a few ".z1" and ".z2" files recovered from very early releases of Zork 1. These have nonstandard serial numbers.&lt;/p&gt;&lt;p&gt;(In 1995, Graham Nelson proposed ".z7" and ".z8" as simple modifications to support larger game files. The Inform compiler and most modern interpreters support these versions. See the Z-code specification.)&lt;/p&gt;&lt;p&gt;Extracting the version, release, and serial number from a Z-code file is easy. I use this little Python script: zcanalyze.py.&lt;/p&gt;&lt;p&gt;Compiling ZIL source code into a game file requires more effort. Infocom's original ZIL compiler has been recovered, but only in a very early version (circa 1981; see below). However, ZILF is an open-source ZIL compiler which is under active development.&lt;/p&gt;&lt;p&gt;The Text Adventure Masterpieces of Infocom CD (1996) is the source of most modern releases and downloads. If you want to play the "official" version of a game, the Masterpieces version is usually the right choice.&lt;/p&gt;&lt;p&gt;However, there are some complications. In some cases, the Mac and PC directories on the CD had different versions. Also, Hitchhiker and Shogun were not included on Masterpieces.&lt;/p&gt;&lt;p&gt;The "official" version of Hitchhiker is the one that Douglas Adams posted on his web site in the mid-90s. The BBC later posted an illustrated version based on the same game file.&lt;/p&gt;&lt;p&gt;Lost Treasures of Infocom 1 and 2 (1992) were earlier Activision collections. These made slightly different game-file choices than Masterpieces, and they did include Hitchhiker and Shogun. To add to the confusion, LTOI1 was released for Amiga as well.&lt;/p&gt;&lt;p&gt;A few of Infocom's earlier games were re-released in "Solid Gold" editions, with built-in Invisiclues. These versions used ".z5" format in order to accomodate the additional text. The Activision collections were quite inconsistent about whether to use the "Solid Gold" versions.&lt;/p&gt;&lt;p&gt;I have noted the Masterpieces version of each game file, and (where different) the LTOI1/2 versions. For more information about game file versions, see Paul David Doherty's invaluable Infocom Fact Sheet.&lt;/p&gt;&lt;p&gt;Versions marked "final-dev" are unreleased final internal versions (according to the Fact Sheet). That is, they had changes in progress when development shut down. These may fix bugs, but they never went through QA, so they should not be considered release-quality.&lt;/p&gt;&lt;p&gt;Despite the title of this page, this is not a complete collection! We have what's been recovered. In particular, there's no guarantee that the "most current" source corresponds to a final release.&lt;/p&gt;&lt;p&gt;All of the source packages contain source (.zil) files. Some also contain temporary files in various stage of compilation (.zap, .zabstr). Some contain compilation reports, design documents, or other related files. It's just a question of what was found in the source archive.&lt;/p&gt;&lt;p&gt;Release numbers are not always sequential. Infocom tended to reset the release number sequence after beta/gamma testing was over, or at other major development milestones. The serial number dates are more reliable, except where they've been obviously zeroed out.&lt;/p&gt;&lt;p&gt;It is perhaps amusing to learn that the "Solid Gold" editions were labelled as the "cheap" releases during development.&lt;/p&gt;&lt;p&gt;Games with sound (Sherlock, Lurking Horror) and graphics (most z6 games) may or may not include the media files in the source directory. The game files never include media. Even if present in the source, these files are probably not in a form that a modern interpreter can understand. See this page for portable versions of these media files.&lt;/p&gt;&lt;p&gt;A few game files are modified for the Macintosh. According to the internal notes, the modifications are "special flags" on certain objects. This apparently refers to setting the fixed-width font for descriptions with ASCII art. Infocom's Mac interpreter required this; it was the only one of its kind that defaulted to variable-width font display. (Most modern interpreters do.)&lt;/p&gt;&lt;p&gt;Source comment on the Mac versions:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The following is a list of changeds specifically for the Mac version:&lt;/p&gt;&lt;p&gt;SEASTALKER -- Special flags set on Sonarscope, control panel in sub and control panel in Bly's office.&lt;/p&gt;&lt;p&gt;ZORK2 -- Special flags set on magic well etching (top and bottom), Label on candied insects and stone cube in bank vault.&lt;/p&gt;&lt;p&gt;ZORK3 -- Special flags set on Royal puzzle and bronze plaque in cage.&lt;/p&gt;&lt;p&gt;ENCHANTER -- Special flags set on Translucent maze map, sign on path to brook and on fireworks for Filfre scroll.&lt;/p&gt;&lt;p&gt;SUSPENDED -- Special flags set on all three monitors: 1) Weather, 2) Hydroponics 3) Transit.&lt;/p&gt;&lt;p&gt;INFIDEL -- Special flags set for Hieroglyphs: bottom of stairs, scarab, book of dead, page in book of dead, beam, scroll in forward cabin, opening in top of pyramid, stone cube, bricks, recessed panel, west end of passage, north antechamber, south antechamber, room of Nephthys, Isis, Selkis, Neith, narrow hallway, cube room, cube south part, silver room, gold room, skeleton in room.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Z-code game files are sometimes found with zeroes or garbage data padded on the end. This does not affect the game behavior. I have generally ignored these variations. I've also ignored variations in byte 1 of the game file; these represent interpreter variations from different platforms, not game differences.&lt;/p&gt;&lt;p&gt;The patches archive contains several game files whose serial numbers are blank or nonsensical. These are always minor modifications of other game files, typically with only the serial number (and checksum) altered. We assume these are "crack" versions modified by users. I have included them regardless.&lt;/p&gt;&lt;p&gt;The patches archive also includes a set of game files which have been modified to bypass Infocom's "feelie" copy protection. I have omitted these, as they definitely postdate Infocom (they were released circa 1999). The feelie data is of course well-archived in any case.&lt;/p&gt;&lt;p&gt;The "mainframe" version of Zork/Dungeon, created at MIT between 1977 and 1979. This package, unlike the others on this site, is written in MDL.&lt;/p&gt;&lt;p&gt;Zork-MDL has been available for some time. (It was posted on Bob Supnik's web site in 2003, perhaps earlier. Ports to Fortran and C are also easily findable.) I include it here because, well, it's Zork.&lt;/p&gt;&lt;p&gt;Four versions of the source, labelled according to the "US NEWS &amp;amp; DUNGEON REPORT" date (see &lt;code&gt;dung.mud&lt;/code&gt;; note that the 1979 version shows inconsistent dates). The 1981 version says "no longer being supported" and refers players to the commercial Infocom release.&lt;/p&gt;&lt;p&gt;Several runnable versions have been recovered from MIT tapes. These are available at the ITS project. I have not mirrored the executable files, because they're only executable inside ITS (running on an emulated PDP-10). See this post for a list of Zork versions found. Visit the project page for information on setting up ITS; or &lt;code&gt;telnet its.pdp10.se 10003&lt;/code&gt; to try it online.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You can try the ITS environment online! Telnet to its.pdp10.se, port 10003 (&lt;/p&gt;&lt;code&gt;telnet its.pdp10.se 10003&lt;/code&gt;). When it says "Connected...", hit ctrl-Z. Then type&lt;code&gt;:login yourname&lt;/code&gt;. (Any name will work.) Then type&lt;code&gt;:zork&lt;/code&gt;to play.&lt;code&gt;:advent&lt;/code&gt;is also available; that's the original Crowther version. You can also try&lt;code&gt;:games;adv350&lt;/code&gt;and&lt;code&gt;:games;adv448&lt;/code&gt;.&lt;/quote&gt;&lt;p&gt;It is worth noting that the 1977-78 versions introduce themselves by saying "Welcome to Dungeon"; the 1979-81 versions say "Welcome to Zork". Of course the "Dungeon" versions still mention "Zork" in many places within the game.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;An early version of Infocom's ZIL compiler, written in MDL. The files are dated no later than early 1981; most are 1979-1980. This version includes both the compiler (ZILCH) and assembler (ZAP) stages.&lt;/p&gt;&lt;p&gt;This source was originally archived at https://github.com/PDP-10/its-vault (the &lt;code&gt;twenex/zork&lt;/code&gt; directory) by Lars Brinkhoff. See also the standalone repository at https://github.com/PDP-10/zil.&lt;/p&gt;&lt;p&gt;For a guide to using this source, see Roman Bartke's ZILCH How-to.&lt;/p&gt;&lt;p&gt;The documentation has been gathered from the Internet Archive, the collection at frobnitz.co.uk, and other sources. Note that &lt;code&gt;.rno&lt;/code&gt; is Runoff and &lt;code&gt;.fwf&lt;/code&gt; is Scribe, two venerable markup languages for document formatting. See Henrik √É¬Ösman's repo for PDF versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;We have two standalone versions of the ZAP assembler, one early and one late.&lt;/p&gt;&lt;p&gt;The first is written in the MIDAS assembly language for the PDP-10. This version is dated Jan 7 1982. It was found within the minizork-r2 source directory (see below).&lt;/p&gt;&lt;p&gt;The second is written in C and dated March 1988. The comments say "Zinn Computer Company, for Infocom", implying that the work was outsourced. The directory includes &lt;code&gt;.o&lt;/code&gt; and executable binaries, presumably in Sun architecture (the directory was labelled "sun"). From this historical repo. (A handful of other utilities are included, including &lt;code&gt;zsplit&lt;/code&gt;, &lt;code&gt;zglue&lt;/code&gt;, &lt;code&gt;zspix&lt;/code&gt;, and &lt;code&gt;zsymtest&lt;/code&gt;. These appear to have to do with packaging game files onto disk for specific platforms.)&lt;/p&gt;&lt;p&gt;A third, earlier version can be found as part of the ZIL source repository above. This is MDL code dated "Jan 18 1980". I'm not sure if it can be run independently of the rest of the ZIL toolset.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;Most of Infocom's original ZIL interpreters were written in assembly for the various platforms of the 1980s. A few later versions were written in C, or (for the Mac) Pascal.&lt;/p&gt;&lt;p&gt;The TRS-80 (Tandy) CoCo interpreter was released in 2018, thanks to Brian Moriarty, Carlos Camacho, and John Linville. (First archived here.) The others became available to the public in 2023. (Archived here.)&lt;/p&gt;&lt;p&gt;These packages are presented by directory, as they were preserved. The contents are not consistently organized. Some of these packages contain more than one interpreter version; some contain additional documentation or serial-port transfer scripts. See this README for a detailed catalog of the contents.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Collector's note:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The Zork I Release 2 game file was extracted from a self-booting, copy-protected TRS-80 Model I disk. The disk itself was not an original and did not come with a label or packaging, but it seems to have been the early Personal Software release.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;We have two game files labelled r22, Mac and non-Mac. Neither of them seems to correspond to the most current source. (E.g.: the source mentions InvisiClues if you type &lt;code&gt;HELP&lt;/code&gt;, but none of the game files contain that line.) I've labelled the current source "infidel-rlater" for lack of better information.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;code&gt;$verify&lt;/code&gt; command therefore fails.
&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;We have two version of the r18 game file. They are identical except for an internal serial number (189 or 190), which is displayed if you type &lt;code&gt;$VERIFY 1949&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Many game file variations tagged with platform names ("tandy", "coco", etc). This is no doubt due to the difficulties of making the sonar display (status window) work across different screen sizes.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that many source files were deleted between r79 and the "rlater" version, so the GitHub repo error is particularly noticeable.&lt;/p&gt;&lt;p&gt;It appears that Infocom was still finalizing the V4 spec during AMFV's development. The development (alpha/gamma) versions have inconsistent header length fields, and must be updated to play in modern interpreters.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The "Solid Gold" update has a serious bug with the delivery time limit.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;code&gt;hints.zil&lt;/code&gt;) but otherwise is nearly the same as the r69 source.
&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The patch archive contains two further hacks are which are identical to r59 s000001 except for release and serial; I have omitted these.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Unusually, we have full source code for the beta (r63) and gamma (r87) versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;A conundrum, Watson. Four source directories appear. The base and -sound directories differ in only a few lines of zil. The -nosound directory has nosound.zil in place of gamesound.zil. The -ss directory is substantially different from the others; the header timestamps imply that it is an early development version. For what it's worth, the included version note says:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The SOUND version is the Release version. The NOSOUND version is currently NOT the release version but contains the Bob Bates updates that are in the SOUND version (without the sound code, of course).&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Many alpha and beta game files. Also two demo versions, which could be considered "Mini-Zork Zero".&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note the early z5 version whose release number (46) is out of sequence. We have two source directories which appear to match this version. Originally this was one source directory containing ".zil" and ".beta" files; the ".beta" files are earlier, so I have moved them to a separate beta directory.&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Torbj√É¬∂rn Andersson reports that this game file fails on modern interpreters when you exit the Carousel Room.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The sampler appears to have gone through several combinations of games. r26-r55 contained samples of Zork 1, Planetfall, Infidel, and The Witness. r97 contained Zork, Trinity, and LGOP; but we find a parallel r8 which contains only Zork and Trinity, plus partial work on adding Ballyhoo. Comment from the r8 source:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;This directory is for NSAMPLER stuff where all references to LGOP have been deleted. The XM4.* files are a stripped down Ballyhoo that could have possibly been inserted into XSAMPLER in place of LGOP, but wasn't. These files stand alone as a separate mini-game and would need to be integrated into XSAMPLER if ever used (when hell freezes over).&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;There's also a folder sampler-trinity, which appears to be a very partial tear-down (or build-up) of Trinity.&lt;/p&gt;&lt;p&gt;I have used the following labels:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An incomplete and unreleased game by Bob Bates, based on the James Cameron movie.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An incomplete and unreleased game by Stu Galley. Curiously, the game file "spy.zip" originally found in this directory was not Checkpoint at all, but an early version of Journey.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Very incomplete and unreleased. Two versions found.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An unfinished game by Tomas Bok. Bok worked for Infocom briefly before college (see this forum thread). Hypochondriac was a "fun project" he was working on in his own time.&lt;/p&gt;&lt;p&gt;The source package is Bok's work directory, and contains several fragments of source code unrelated to Hypochondriac. Some of them (&lt;code&gt;boot.zil&lt;/code&gt;, &lt;code&gt;circuit.zil&lt;/code&gt;, &lt;code&gt;maintenance.zil&lt;/code&gt;) are from an incomplete sci-fi game titled "Search 'n Rescue". Others are source files from Infocom games (Zork, LGOP, etc), modified while Bok was experimenting with ZIL.&lt;/p&gt;&lt;p&gt;The game files include both Hypochondriac and various experiments. The experiments aren't necessarily related to Hypochondriac; I've given them a common name simply to group them together.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;This is the "new parser" that Infocom developed around 1987, late in its history. Their earlier games were based on the ZIL parser developed for Zork 1, and then copied from game to game in an evolutionary sequence.&lt;/p&gt;&lt;p&gt;ZilLib was an attempt at a next-generation parser to go along with the next-generation (z6) Z-machine. See this article from Infocom's 1989 newsletter.&lt;/p&gt;&lt;p&gt;The source code for Zork Zero, Arthur, Shogun, Abyss, and Restaurant all refer to the zillib directory. (And the zillib/parser directory contains include files that refer back to them; e.g. "parser.shogun".)&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;A regression test suite for Infocom's Z-code interpreters. No source code found.&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;This appears to be a template for creating a new game. It includes a parser, a couple of rooms, and a couple of stub objects. Three game files were found with various dates and Z-code versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Cataloged by Andrew Plotkin from sources at GitHub and elsewhere.&lt;/p&gt;&lt;p&gt;Last updated January 14, 2025.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45392164</guid><pubDate>Fri, 26 Sep 2025 23:43:33 +0000</pubDate></item><item><title>GPT-OSS Reinforcement Learning</title><link>https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning</link><description>&lt;doc fingerprint="bd03a57f89323790"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;gpt-oss Reinforcement Learning&lt;/head&gt;
    &lt;p&gt;You can now train OpenAI gpt-oss with RL and GRPO via Unsloth. Unsloth now offers the fastest inference (3x faster), lowest VRAM (50% less) and most context (8x longer) for gpt-oss RL vs. any implementation - with no accuracy loss. Since RL on gpt-oss isn't yet vLLM compatible, we rewrote Transformers inference code to deliver 3x faster inference for gpt-oss at ~21 tokens/s. For BF16, Unsloth also achieves the fastest inference (~30 tokens/s), especially relative to VRAM usage, using 50% less VRAM vs. any implementation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Free notebook: gpt-oss-20b GSPO Colab notebook This notebook automatically creates faster matrix multiplication kernels and uses a new Unsloth reward function. We also show how to counteract reward-hacking which is one of RL's biggest challenges.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With Unsloth, you can train gpt-oss-20b with GRPO on 15GB VRAM and free on Colab. Unsloth's new inference runs faster on any GPU including A100, H100 and old T4's. gpt-oss-120b fits on 80GB VRAM.&lt;/p&gt;
    &lt;p&gt;Unsloth is the only framework to support 4-bit RL for gpt-oss. All performance gains are due to Unsloth's unique weight sharing, Flex Attention, Standby and custom kernels.&lt;/p&gt;
    &lt;p&gt;Reminder: Flash Attention 3 (FA3) is unsuitable for gpt-oss training since it currently doesn‚Äôt support backward passes for attention sinks, causing incorrect training loss. If you‚Äôre not using Unsloth, FA3 may be enabled by default, so please double-check it‚Äôs not in use!&lt;/p&gt;
    &lt;head rend="h2"&gt;‚ö°Making Inference Much Faster&lt;/head&gt;
    &lt;p&gt;Inference is crucial in RL training. To achieve the fastest inference speed for gpt-oss without vLLM, we rewrote Transformers inference and integrated many innovations including custom algorithms like Unsloth Flex Attention, torch.compile. The new inference was evaluated against an already optimized baseline (2x faster than native Transformers).&lt;/p&gt;
    &lt;p&gt;vLLM does not support RL for gpt-oss since it lacks bf16 training and LoRA support for gpt-oss. Without Unsloth, only training via bf16 works, making memory use even 800%+ higher. Most frameworks enable FA3 by default (which reduces VRAM use &amp;amp; increases speed) but this causes incorrect training loss. You must disable FA3, though that prevents long-context training, so instead, we implemented Unsloth Flex Attention.&lt;/p&gt;
    &lt;p&gt;We evaluated gpt-oss RL inference by benchmarking BitsandBytes 4-bit and also did separate tests for BF16. Unsloth‚Äôs 4-bit inference is ~4x faster, and BF16 is also more efficient, especially in VRAM use.&lt;/p&gt;
    &lt;p&gt;The best part about Unsloth's gpt-oss RL is that it can work on any GPU, even those that do not support bf16. Our free gpt-oss-20b Colab notebooks use older 15GB T4 GPUs, so the inference examples work well!&lt;/p&gt;
    &lt;head rend="h2"&gt;üõ†Ô∏è gpt-oss Flex Attention Issues and Quirks&lt;/head&gt;
    &lt;p&gt;Masking was a tricky issue to deal with. We found that we had to, not only account for KV Cache prefill during generations of tokens (this is necessary for efficient inference as we need to know what KVCache corresponds to what token in what layer), but also account for a unique amount of pad tokens in each prompt for batch generations which would change the way we would need to store the block mask. Example of such can be seen below:&lt;/p&gt;
    &lt;p&gt;Normal Causal Mask:&lt;/p&gt;
    &lt;code&gt;   k0 k1 k2 k3 k4   &amp;lt;-- keys
q0 X
q1 X X
q2 X X X
q3 X X X X
q4 X X X X X &amp;lt;-- last query row (most important for decoding)&lt;/code&gt;
    &lt;p&gt;For inference in general case (decoding)&lt;/p&gt;
    &lt;code&gt;    k0 k1 k2 k3 k4
q0
q1
q2
q3
q4   X  X  X  X  X&lt;/code&gt;
    &lt;p&gt;If we naively use the same masking strategy&lt;/p&gt;
    &lt;code&gt;    k0 k1 k2 k3 k4
q0
q1
q2
q3
q4  X   (note that q4 is with q_idx 0 as this is the first query in current setup)&lt;/code&gt;
    &lt;p&gt;For generation (decoding phase), we usually only care about the last row of the attention matrix, since there‚Äôs just one query token attending to all previous key tokens. If we na√Øvely apply the causal mask (q_idx ‚â• k_idx), it fails as our single query has index 0, while there are n_k key tokens. To fix this, we need an offset in mask creation to decide which tokens to attend. But a na√Øve approach is slow, since offsets change each step, forcing mask and kernel regeneration. We solved this with cache and compile optimizations.&lt;/p&gt;
    &lt;p&gt;The harder part is batch generation. Sequences differ in length, so padding complicates mask creation. Flex Attention had a lot of challenges and dynamic masks are tricky. Worse, if not compiled, it falls back to eager attention which is slow and memory-heavy (quadratic vs. linear in sequence length). Ultimately, the mask must dynamically handle prefill vs decode with KVCache, batch and padding tokens per sequence, remain torch.compile friendly, and support sliding windows.&lt;/p&gt;
    &lt;head rend="h3"&gt;üîç FlashAttention Investigation&lt;/head&gt;
    &lt;p&gt;Another interesting direction we explored was integrating FlashAttention. Its advantages are widely recognized, but one limitation is that it does not support attention sinks during the backward pass for gpt-oss. To work around this, we restructured the attention mechanism so that it operates solely on the attention output and the log-sum-exp values that FlashAttention readily provides. Given these benefits, it seemed like an obvious choice to try.&lt;/p&gt;
    &lt;p&gt;However, we soon began noticing issues. While the first few layers behaved as expected, the later layers, particularly layers 18 through 24, produced outputs that diverged significantly from the eager-mode implementation in transformers. Importantly, this discrepancy cannot be attributed to error accumulation, since the inputs to each method are identical at every layer. For further validation, we also compared the results against Unsloth FlexAttention.&lt;/p&gt;
    &lt;p&gt;This needs further investigation into why only the last few layers show such a drastic difference between flash attention implementation vs. the others.&lt;/p&gt;
    &lt;head rend="h4"&gt;Flash Attention 3&lt;/head&gt;
    &lt;p&gt;FA3 is often enabled by default for most training packages (not Unsloth), but this is incorrect for gpt-oss. Using FA3 will make training loss completely wrong as FA3 doesn‚Äôt support gpt-oss backward passes for attention sinks. Many people are still unaware of this so please be cautious!&lt;/p&gt;
    &lt;head rend="h2"&gt;‚ö†Ô∏è Can We Counter Reward Hacking?&lt;/head&gt;
    &lt;p&gt;The ultimate goal of RL is to maximize some reward (say speed, revenue, some metric). But RL can cheat. When the RL algorithm learns a trick or exploits something to increase the reward, without actually doing the task at end, this is called "Reward Hacking". It's the reason models learn to modify unit tests to pass coding challenges, and these are critical blockers for real world deployment. Some other good examples are from Wikipedia.&lt;/p&gt;
    &lt;p&gt;In our notebook we explore how to counter reward hacking in a code generation setting and showcase tangible solutions to common error modes. We saw the model edit the timing function, outsource to other libraries, cache the results, and outright cheat. After countering, the result is our model generates genuinely optimized matrix multiplication kernels, not clever cheats.&lt;/p&gt;
    &lt;head rend="h2"&gt;üí´ From OpenAI's Labs to Your Laptop&lt;/head&gt;
    &lt;p&gt;gpt-oss is a legitimate frontier-class architecture from OpenAI that could power breakthrough AI applications. Until now, training these models with RL was exclusively limited to well-funded labs with H100s to spare.&lt;/p&gt;
    &lt;p&gt;Today, that changes. You can train gpt-oss-20b with GRPO on a free Google Colab tier here. Free, Frontier Model, Training.&lt;/p&gt;
    &lt;p&gt;Last updated&lt;/p&gt;
    &lt;p&gt;Was this helpful?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45392744</guid><pubDate>Sat, 27 Sep 2025 02:01:35 +0000</pubDate></item><item><title>Why Today's Humanoids Won't Learn Dexterity</title><link>https://rodneybrooks.com/why-todays-humanoids-wont-learn-dexterity/</link><description>&lt;doc fingerprint="27501b1e81719f83"&gt;
  &lt;main&gt;
    &lt;p&gt;In this post I explain why today‚Äôs humanoid robots will not learn how to be dexterous despite the hundreds of millions, or perhaps many billions of dollars, being donated by VCs and major tech companies to pay for their training.&lt;/p&gt;
    &lt;p&gt;At the end of the post, after I have completed my argument on this point, I have included two more short pieces. The first is on the problems still to be solved for two legged humanoid robots to be safe for humans to be near them when they walk. The second is how we will have plenty of humanoid robots fifteen years from now, but they will look like neither today‚Äôs humanoid robots nor humans. [[My side commentaries look like this.]]&lt;/p&gt;
    &lt;head rend="h5"&gt;1. Prolog&lt;/head&gt;
    &lt;p&gt;Artificial Intelligence researchers have been trying to get robot arms and hands to carry out manipulation of objects for over 65 years; since just a few years after the term Artificial Intelligence first appeared in a proposal for a 1956 ‚ÄúDartmouth Summer Research Project on Artificial Intelligence‚Äù. By 1961 Heinrich Ernst had produced a PhD thesis describing a computer controlled arm and hand that he had connected to the TX-0 computer at MIT, and had it picking up blocks and stacking them, and stunningly there is a video. His advisor was Claude Shannon, and he also thanked Marvin Minsky for his guidance, thus naming two of the four authors of the Dartmouth AI proposal.&lt;/p&gt;
    &lt;p&gt;This led to industrial robots, which were and are computer controlled arms with various ‚Äúend effectors‚Äù, think primitive hands, that have been used in factories around the world for sixty years&lt;/p&gt;
    &lt;p&gt;Recently a new generation has stumbled upon the idea of building humanoid robots and you may have noticed just a little bit of hype about it. Gartner says it is early days and we are nowhere near maximum hype yet. This diagram is just a year old, and humanoids are at the very beginning of the cycle, while generative AI is over the hump and heading down to the doldrums:&lt;/p&gt;
    &lt;p&gt;The idea is that humanoid robots will share the same body plan as humans, and will work like humans in our built for human environment. This belief requires that instead of building different special purpose robots we will have humanoid robots that do everything humans can do. For example the CEO of Figure, a humanoid robot company, says that:&lt;/p&gt;
    &lt;p&gt;We could have either millions of different types of robots serving unique tasks or one humanoid robot with a general interface, serving millions of tasks.&lt;/p&gt;
    &lt;p&gt;Here is the first phase of his ‚Äúmaster plan‚Äù:&lt;/p&gt;
    &lt;p&gt;PERFORM HUMAN-LIKE MANIPULATION.&lt;/p&gt;
    &lt;p&gt;INTEGRATE HUMANOIDS INTO THE LABOR FORCE.&lt;/p&gt;
    &lt;head rend="h5"&gt;2. A brief history of humanoid robots&lt;/head&gt;
    &lt;p&gt;Many people have already spent decades building humanoid robots, starting with the Humanoid Robotics Institute at Waseda University in Tokyo where WABOT-1 (WAseda roBOT) was built in the early 1970s, after many years of working on biped walking mechanisms in the mid sixties. Then WABOT-2 was built in the early 1980s and new humanoids have followed at Waseda continuously thereafter. Honda, the Japanese car company, started building walking bipeds in the late eighties and eventually unveiled the humanoid ASIMO in 2000. Sony first developed and sold a robot dog named Aibo, then developed a small humanoid robot named QRIO in 2003, but never actually sold copies of it. A French company, Aldebaran, introduced a small walking humanoid named NAO in 2007, and it replaced Aibo as the standard platform in the international robot soccer league that has now been running annually for 30 years. Later they sold a larger humanoid, Pepper, with somewhat less commercial success. Boston Dynamics, a spinout from MIT 35 years ago, introduced the humanoid ATLAS in 2013, after years of building four legged robots.&lt;/p&gt;
    &lt;p&gt;Besides the early work in Japan on humanoid robots there have been many academic groups across the world that have worked on robots with human form, with and without legs, and with and without arms. My own research group at MIT started building the humanoid Cog in 1992, and we developed seven different platforms, and then I founded Rethink Robotics in 2008, and we sold thousands of two models of humanoids, Baxter and Sawyer. They were deployed in factories around the world. Some of my former post-docs returned to Italy and started the RoboCub open source humanoid project, which has enabled many tens of humanoid robots to be built in AI Labs all over the world.&lt;/p&gt;
    &lt;p&gt;All these groups have sustained building humanoids and figuring out how to make them walk, manipulate, and interact with humans in built-for-human environments for decades now. Way back in 2004 the International Journal of Humanoid Robotics started publishing, on paper back then.&lt;/p&gt;
    &lt;p&gt;You can find the journal online now filling its 22nd yearly volume of research papers.&lt;/p&gt;
    &lt;p&gt;2.1 The manipulation challenge for humanoid robots&lt;/p&gt;
    &lt;p&gt;Getting a robot to manipulate objects with its arms and hands was very hard for Heinrich Ernst in 1961. It has been hard for every robotics researcher and industrial engineer ever since, and still to this day.&lt;/p&gt;
    &lt;p&gt;In the mid-sixties parallel jaw grippers were developed. Two parallel fingers that moved together and apart. That is still the dominant form of a robot hand today. Here are pictures of ones that I used on robots at Stanford in the 1970s, and pictures of ones my company Rethink Robotics manufactured and sold in the mid twenty-teens, both electrically driven.&lt;/p&gt;
    &lt;p&gt;The only difference is that the more modern one on the right has a camera in it so that hand can visually servo to a target object‚Äìthere was not enough computation around in the seventies to do that in a product that had a reasonable price.&lt;/p&gt;
    &lt;p&gt;Schunk, a German company, sells over 1,000 varieties of parallel jaw grippers, both electric and pneumatic (using compressed air), for robot arms. It also sells some three fingered radially symmetric hands and a few other specialized grippers. No one has managed to get articulated fingers (i.e., fingers with joints in them) that are robust enough, have enough force, nor enough lifetime, for real industrial applications.&lt;/p&gt;
    &lt;p&gt;When compressed air is available it can be turned into suction using a Venturi ejector, and the other type of common robot hand uses one or more suction cups to grab an object by a surface. Here is a version that Rethink Robotics sold alongside the electric parallel jaw gripper.&lt;/p&gt;
    &lt;p&gt;Single suction cup and multiple suction cup end effectors (the things at the end of an arm where one might expect a hand) have become quite common for handling finished goods and packing them in custom boxes of identical items, and also for handling cases of finished goods and packages that are being sent to consumers. In fact, there has been a co-evolution of soft material for shipping packages and suction cup end effectors so that soft packages to be sent to people‚Äôs homes are easier and faster to grab with suction cups than any other method.&lt;/p&gt;
    &lt;p&gt;Over the last few decades many, many hands modeled on human hands, with articulated fingers, have been built. This montage includes hands built by John Hollerbach, Ken Salisbury, and Yoky Matsuoka.&lt;/p&gt;
    &lt;p&gt;No human-like robot hands have demonstrated much in the way of dexterity, in any general sense. And none have inspired designs that have made it into deployment in real world applications. The approaches to dexterity have been very mathematical and geometrical, and they have just not produced anything like human dexterity.&lt;/p&gt;
    &lt;p&gt;You might see pretty videos of human-like robot hands doing one particular task, but they do not generalize at all well beyond that task. In a light hearted, but very insightful, recent blog post, Benjie Holson (full disclosure: Benjie and I work together closely at Robust.AI) lays out fifteen tasks that any eight year old human can do, in a proposed humanoid robot Olympics. With medals. For instance, one challenge is for a humanoid robot folding laundry to hang a men‚Äôs dress shirt which starts with one sleeve inside out, and to have at least one button buttoned. Another is to clean peanut butter off its own hand. And you can‚Äôt say ‚ÄúOh, that would be better done by a different kind of robot mechanism.‚Äù No, it is central to the case for humanoid robots that they can do all the tasks that humans can do. Once you see Benjie‚Äôs fifteen challenge tasks, it is pretty easy to come up with another fifteen or thirty more dexterous tasks which have very little in common with any of his, but which all of us humans can do without a second thought. And then there are the hard things that we can all do if we have to.&lt;/p&gt;
    &lt;p&gt;2.2 An idea that has worked before&lt;/p&gt;
    &lt;p&gt;Well gosh, what are we to do? How are we going to get humanoid robots to be dexterous? Here‚Äôs my imagined inner dialog that so many people must have gone through.&lt;/p&gt;
    &lt;p&gt;End to end learning has worked well over the past 20 years in at least three domains, speech to text, labeling images, and now large language models. So instead of trying to figure dexterity stuff out mathematically, how about we just do end to end learning? We‚Äôll collect lots of data about how humans use their hands to do tasks, and feed it into a learning system, and out will pop dexterous robot control. And our companies will be worth billions of dollars.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs not overthink this, let‚Äôs just do it!!&lt;/p&gt;
    &lt;p&gt;How the humanoid companies and academic researchers have chosen to do this is largely through having a learning system watch movies of people doing manipulation tasks, and try to learn what the motions are for a robot to do the same tasks. In a few cases humans teleoperate a robot, that they can see, along with the objects being manipulated, and the humans may get a tiny bit of force and touch feedback‚Äìmostly it comes from the hands of the robots and not the wrists or elbows or shoulders or hips, and any such touch data is very crude.&lt;/p&gt;
    &lt;p&gt;In his blog Benjie Holson points out the paucity and low accuracy of the data that is collected, and I completely agree with his criticisms. Here they are, he said them well, and I am not going to try to say them better:&lt;/p&gt;
    &lt;p&gt;What I‚Äôm seeing working is learning-from-demonstration. Folks get some robots and some puppeteering interfaces (standard seems to be two copies of the robot where you grab &amp;amp; move one of them and the other matches, or an Oculus headset + controllers or hand tracking) and record some 10-30 second activity over and over again (100s of times). We can then train a neural network to mimic those examples. This has unlocked tasks that have steps that are somewhat chaotic (like pulling a corner of a towel to see if it lays flat) or high state space (like how a wooden block is on one of 6 sides but a towel can be bunched up in myriad different ways). But thinking about it, it should be clear what some of the limitations are. Each of these has exceptions, but form a general trend.&lt;/p&gt;
    &lt;p&gt;No force feedback at the wrists. The robot can only ever perform as well as the human teleoperation and we don‚Äôt yet have good standard ways of getting force information to the human teleoperator.&lt;/p&gt;
    &lt;p&gt;Limited finger control. It‚Äôs hard for the teleoperator (and AI foundation model) to see and control all the robot fingers with more finesse than just open/close.&lt;/p&gt;
    &lt;p&gt;No sense of touch. Human hands are packed absolutely full of sensors. Getting anywhere near that kind of sensing out of robot hands and usable by a human puppeteer is not currently possible.&lt;/p&gt;
    &lt;p&gt;Medium precision. Guessing based on videos I think we‚Äôve got about 1-3 cm precision for tasks.&lt;/p&gt;
    &lt;p&gt;Folding towels and t-shirts doesn‚Äôt depend on high wrist forces. You can get away with just hand open/close by using pinch grasps to pull and lift and open hands to spread. You can visually see how your grasp is so you don‚Äôt need finger sensing. 1-3 cm precision is just fine.&lt;/p&gt;
    &lt;p&gt;And yes, this is real. Humanoid robot companies, and many academic projects, are trying to train robots to do dexterous manipulation by just showing them the motions, and not getting them to use any force or haptic feedback.&lt;/p&gt;
    &lt;p&gt;For instance, in the last week Figure has announced their ‚Äúproject go big‚Äù about how they are going to train robots with new skills. Nothing is surprising here as it matches what they have be saying and showing all along. And here is what they say about it, with my bolding:&lt;/p&gt;
    &lt;p&gt;Traditionally, teaching robots new skills required costly demonstrations, hand-coded programs, or tightly staged environments that fail to capture the messiness of the real world. Humanoid robots, however, offer a unique structural advantage: their perspectives and kinematics mirror our own, making it possible to transfer knowledge directly from everyday human video (Video 1).&lt;/p&gt;
    &lt;p&gt;[[And do note that Video 1 is distinctly unmessy, and uncrowded, unlike any real home that ordinary people live in. Likewise for Videos 2 and 3.]]&lt;/p&gt;
    &lt;p&gt;They are saying that they are going to train their robots to do new manual skills from first person video of people doing those skills.&lt;/p&gt;
    &lt;p&gt;And here is a press story from eWeek, from just a month ago, that Tesla is going all in on training through simply looking at videos of people doing tasks. It says:&lt;/p&gt;
    &lt;p&gt;Tesla has shifted its training strategy for its humanoid robot Optimus. Instead of relying on motion capture suits and teleoperation, Tesla is moving toward a vision-only approach.&lt;/p&gt;
    &lt;p&gt;Workers now wear camera rigs made up of helmets and backpacks with five in-house cameras that record mundane tasks like folding a t-shirt or picking up an object. Those videos are then used to train Optimus to mimic the actions.&lt;/p&gt;
    &lt;p&gt;A little further in the story it says:&lt;/p&gt;
    &lt;p&gt;Christian Hubicki, director of the robotics lab at FAMU-FSU, noted to Business Insider that the multiangle camera setup likely captures ‚Äúminute details, like the location of joints and fingers,‚Äù making the data more precise.&lt;/p&gt;
    &lt;p&gt;Both Figure and Tesla are all in on videos of people doing things with their hands are all that is needed to train humanoid robots to do things with their hands. They are making a bet that machine learning from watching lots and lots of motions of people‚Äôs hands will be sufficient to learn dexterity. Visual precision and large data sets of it are enough, they believe. [[It is possible that they are sandbagging us, as the lure of $30 trillion is quite a lot of money, even for a very already rich person, and they just don‚Äôt want the competition to know what they are really doing. But I am going to take them at their word for this argument.]]&lt;/p&gt;
    &lt;head rend="h5"&gt;3. End to End Learning Depends on the Chosen Ends&lt;/head&gt;
    &lt;p&gt;In the last two decades speech to text, image labeling, and fluid language generated by Large Language Models (LLMs) have all been transformed, in spectacular ways, by end-to-end learning, using linear threshold neural models.&lt;/p&gt;
    &lt;p&gt;For the speech and image cases the new methods showed radical increases in performances. In both cases leaving as much as possible to the learning methods was critical for that success. That meant, for speech, getting rid of explicit models for phonemes (which are very language dependent), which had dominated all previously recent approaches. For image labeling it meant getting rid of any notion of line (boundary) finding, shape, shading, or color constancy, all of which had dominated recent work on image understanding.&lt;/p&gt;
    &lt;p&gt;LLMs showed proficiency with language and answering general questions (with a strong tendency, still today, for rabid confabulations) that was beyond anything anyone was expecting was around the corner. And they had done it by eliminating any references or direct experience in the world of anything other than language. They were self-contained language machines, with none of the long expected grounding in experience in the real world, that everyone had expected, the believed to be symbol grounding problem. [[Even Alan Turing had brought this up in his brilliant Intelligent Machinery, written in 1948 but not published until 1970, in Machine Intelligence 5, edited by Bernard Meltzer and Donald Michie. There (on page 13 of that volume) Turing had said that the sure way to get to an intelligent machine was to ‚Äútake a man as a whole and to try replace all parts of him by machinery‚Äù. Today we might say ‚Äúbuild a humanoid‚Äù; prescient! As for the grounding in real world experience he went on to say: ‚ÄúIn order that the machine should have a chance of finding things out for itself it should be allowed to roam the countryside, and the danger to the ordinary citizen would be serious‚Äù (my emphasis). He concluded that it was too hard to do with the technology of the day. Two more instances of prescience.]]&lt;/p&gt;
    &lt;p&gt;These were radical changes and head spinning for most researchers, including me. But the new methods undeniably worked much better than anything we had seen in the past.&lt;/p&gt;
    &lt;p&gt;On March 13th, 2019 (pre LLM), Rich Sutton (who was later the 2024 co-winner of the Turing Prize with Andrew Barto for their work on Reinforcement Learning) published a mildly triumphant short blog post titled A Bitter Lesson. In it he applies his argument to more cases than the ones to which I refer to here, by including the role of massive search making computers playing Chess and Go much better than humans doing the tasks.&lt;/p&gt;
    &lt;p&gt;And he says, both for search and learning approaches:&lt;/p&gt;
    &lt;p&gt;And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.&lt;/p&gt;
    &lt;p&gt;Then he goes on to discuss Chess, Go, speech, and images. He argues against using human biases in structuring the problems at all. But I thought then, and think now, that, in reality, in all these successful cases human knowledge does come into play, as the ‚Äúend to end‚Äù nature relies on humans specifying what the ‚Äúends‚Äù are.&lt;/p&gt;
    &lt;p&gt;Six days after Sutton posted this I replied in the form of similarly short blog titled A Better Lesson. In that post I pointed out a number of generic problems with scaling the approach, as we see now with massive energy and server requirements and the employment of thousands of other humans preparing data sets, which itself belies the argument of keeping humans out of the loop.&lt;/p&gt;
    &lt;p&gt;Most importantly I pointed out that the image labeling case was not end-to-end starting with images and ending with labels. Instead it uses a convolutional network as a front end to structure the way the learning algorithm has access to the images. While I did not make a similar argument for speech to text, nor the as-then-yet-unannounced LLMs, I will make the the case that all three succeeded due to engineers building case specific pre-processing that relied on directly simulating (without learning) parts of human physiology.&lt;/p&gt;
    &lt;p&gt;Here are the accommodations made to learning, in each of the three cases, in terms of hard coding front end processing of data.&lt;/p&gt;
    &lt;p&gt;3.1 Speech to text&lt;/p&gt;
    &lt;p&gt;The task in speech to text is to take the signal from a microphone that a person is speaking into and to output a text string that represents the words that were said. Today we are all used to talking to various machines like Alexa, or our TV remote, or our car, and on a customer service line, or any other of a myriad of devices and channels. All these use speech to text to get the words to feed into the system which is going to respond appropriately (we hope) to our words. It is only in the last 20 years that this capability has become practical. And, it is the result of end to end learning over large data sets, where both the microphone input and the correct text string were available, and that a learning system learned how to go from the input signal to generating text.&lt;/p&gt;
    &lt;p&gt;There are many ways the sound signal could get into the computer for this learning. We could take the analog output of a microphone and digitize the loudness of the signal many tens of thousands of times a second and have that as the input to the learning. But in practice that is not how it is done.&lt;/p&gt;
    &lt;p&gt;Instead it relies on a technology developed for practical spoken communication over world wide telephone networks in the 20th century where the signals were compressed for individual voice circuits so that more calls could fit on a single wire. This work determined aspects of the signal that had to be preserved so that a human could understand what had been said by the distant speaker. And if a human could understand such compressed signals that says that all the information that is necessary to understand speech is still in that signal.&lt;/p&gt;
    &lt;p&gt;The inputs to various speech to text learning systems vary, but here are some of the common pre-processing steps taken. The analog input signal is sampled at a fixed frequency, perhaps 16kHz, then a high pass filter boosts higher frequencies as they are important for detecting consonants, then the signal is cut into frames, say 25ms long with 10ms overlap, for instance, and then each frame is conditioned so that subsequent Fast Fourier Transforms (FFTs) will not be compromised by the shortness of the window. Somewhere along the way there may be some noise reduction. Then the signal is subdivided into frequency bands using one or more methods such as FFT, Mel filter banks, logarithm of outputs, and cosine transforms. In some implementations there is initial training on just the frames so that language dependent frame signatures can be recognized early in the deep network.&lt;/p&gt;
    &lt;p&gt;Different implementations use different selections of these and other techniques, but the point is that after all this, then end-to-end learning is let loose on the output of all this input signal transformation.&lt;/p&gt;
    &lt;p&gt;Further, all that signal transformation was originally developed so that human speech could be stored and the listened to in distant places and times. The important thing about those transformations was that they allowed the human listening mechanism for understanding speech to be used with no change to the human.&lt;/p&gt;
    &lt;p&gt;3.2 Image labelling&lt;/p&gt;
    &lt;p&gt;Image labelling through deep learning, has since 2012 become the dominant method in computer vision for interpreting what is in an image. But deep learning does not start with raw pixels coming out of a camera, rather it bows to non-learned human physiology in two ways.&lt;/p&gt;
    &lt;p&gt;The data coming out of a camera is a linear stream of pixel values, and in fact sometimes three separate streams for the directly measured colors red, green, and blue (RGB). A modern digital camera has a global (electronic) shutter where light coming through the lens is allowed to bump electrons into a rectangular array of little buckets, all starting and stopping collecting at the same time. Then the contents of those buckets are shifted to neighboring buckets and read out with an analog-to-digital converter, which essentially reads the number of electrons in a particular bucket, and they are read as a series of left-to-right rows, top-to-bottom, or some switching of either of those orders. It is one, or three for color images, linear streams.&lt;/p&gt;
    &lt;p&gt;Deep learning does not operate on this stream. Instead the numbers from this stream are arranged in a data structure which reconstructs the adjacencies of the original pixels, and for color, overlays the three colors. This is of course standard in any image processing by computer, but it is an explicit structure being imposed intentionally. Animals do not serialize their images, but instead have one cable going from each ‚Äúpixel‚Äù in the retina, to a flat array of cells in the cortex, where the geometry of the pixels, or receptors, in the retina are preserved. The organization of these cables into a regular array happens before birth through bursts of localized excitations of the adjacent retinal cells that are then used at the other end to guide the development of the cables (which are all neural axons) to mimic the locality of excitement.&lt;/p&gt;
    &lt;p&gt;Then the first few layers for deep learning use a structure which is set up so that learning learns the same thing in a translationally invariant way; a cat in the lower left of an image is recognized in exactly the same way as one in the middle top of an image. This specialized network is a convolutional neural network, a processing structure specialized for vision applied to large images.&lt;/p&gt;
    &lt;p&gt;In the 27th of May, 2015 Nature (paywalled) article by Yan LeCun, Yoshua Bengio, and Geoffrey Hinton (the three winners of the 2018 Turing Prize) titled Deep learning, the authors say:&lt;/p&gt;
    &lt;p&gt;First, in array data such as images, local groups of values are often highly correlated, forming distinctive local motifs that are easily detected. Second, the local statistics of images and other signals are invariant to location. In other words, if a motif can appear in one part of the image, it could appear anywhere, hence the idea of units at different locations sharing the same weights and detecting the same pattern in different parts of the array.&lt;/p&gt;
    &lt;p&gt;They go on to attribute this architecture to Kunihuko Fukushima, who worked on learning to recognize hand drawn characters (pre back propagation), as did Yan LeCun (post back propagation) some years later. The earliest English-language non-paywalled paper that I can find by Fukushima on this topic appeared at the International Joint Conference on Artificial Intelligence (IJCAI) in 1979 in Tokyo and the three page paper is on page 291 of Volume 1 of the proceedings. [[That was the first international conference at which I presented my own paper, and it is in the same volume, and is about a much more ancient and largely discarded approach to recognizing objects in images.]]&lt;/p&gt;
    &lt;p&gt;Fukushima attributes inspiration for this approach to the investigations of the structure of the cortical columns in the cortices of cats and monkeys by David Hubel and Torsten Weisel, who won the Nobel prize for this work in 1981 ‚Äî see David Hubel‚Äôs Nobel lecture for a summary of that work. Fukushima emulated both the simple cells and the complex cells that Hubel and Weisel identified as S-cells and C-cells, and then split Hubel and Weisel‚Äôs hypercomplex cells into two subtypes within his modeled cells. These cells recognize common motifs wherever they may appear in an image.&lt;/p&gt;
    &lt;p&gt;In figure 2 of the paywalled Nature article above you can see this structure play out in alternate layers, and as LeCun et al say:&lt;/p&gt;
    &lt;p&gt;There are four key ideas behind ConvNets that take advantage of the properties of natural signals: local connections, shared weights, pooling and the use of many layers.&lt;/p&gt;
    &lt;p&gt;In animals, including humans there is an additional variation in resolution of receptors in the retina, with more closely spaced, and therefore higher resolution, receptors near the center of the visual field. Many animals, including humans, use very fast motions, saccades, of their eyeballs to point that high resolution part of their eyes at different parts of the image ‚Äî you are doing this right now as you read these words, saccading along each line then down to the next, stopping for just a fraction of a second before moving on (and suppressing your motion sensors while you move your eyeball).&lt;/p&gt;
    &lt;p&gt;The large convolutional network for deep learning vision eliminates the need for this by having high resolution recognition, through repetitive shared weights, across the whole image.&lt;/p&gt;
    &lt;p&gt;Again, this is not raw end to end learning. There is very detailed replication of incredibly complex parts of our brain, that is structured into the learning machine. Despite the romanticism of having everything learned without humans messing things up by choosing the wrong structures, deep learning image labelling is built upon a very complex and marvelous piece of front end engineering that specifically emulates structures that have been identified in animal brains. And it is built upon the technology we have developed to capture images and transmit them over a narrow channel (i.e., to serialize them) so that the human visual system can understand the original scene even when that human is located at a distant point in space and time.&lt;/p&gt;
    &lt;p&gt;3.3 Large language models&lt;/p&gt;
    &lt;p&gt;Large Language Models (LLMs) e.g., ChatGPT or Gemini, are trained on large amounts of text, with no external inputs trying to explain what all that text is. From that perspective it looks like the learning mechanism figures everything out itself.&lt;/p&gt;
    &lt;p&gt;However, there are some early stages both in learning and then later processing any input text where the structure of human language, and some aspects of the particular human language that is being input, has been used to engineer in some preprocessing, and some aspects of the internal representations. The two mechanisms for this involve tokens and embeddings. [[Of course, then there is the whole transformer mechanism, invented in 2017, involving multi-head attention mechanisms, and one step at a time append and shift output being rerouted to the input, and so on. That is a massive amount of human-generated architecture and engineering which is key to LLMs working, further pressure on the insistence on end-to-end learning with no human biases built in. But here I am only talking about the early massaging of data that is common to this and the previous two subsections.]]&lt;/p&gt;
    &lt;p&gt;The fundamental unit of any particular language is presented to an LLM as a linear sequence of tokens. For English roughly 50,000 different tokens are used and they include tokens such as dog, cat, fish, game, run, ing, ed, pre, sub, due, marine, fetch, auto, etc. Tokens can be whole words prefixes, suffixes, common subparts of words, etc.&lt;/p&gt;
    &lt;p&gt;At the very beginning of training an LLM, with text in a particular language, tokens are learned, in a largely unsupervised manner. Lots of text in the language is fed into a token learning system which comes up with plausible token candidates based on commonality of seeing them in the training corpus, and with statistics attached as to how common they are, and whether and how the combine with other tokens within words. From these statistics the number of discrete tokens to be used is chosen, automatically, by scoring possible tokens based on frequency and how well they divide words into other common tokens.&lt;/p&gt;
    &lt;p&gt;Once the tokens have been chosen a small program, the tokenizer, is used to break all input language into strings of those tokens.&lt;/p&gt;
    &lt;p&gt;Next, the tokens are embedded in a high dimensional vector space, typically one that has dimensions for some fixed . Over recent years as more training has been applied to LLMs to produce bigger models the number has gotten larger. For ChatGPT-2 was , but for ChatGPT-3 it was .&lt;/p&gt;
    &lt;p&gt;The embedding needs to be learned, i.e., the coordinate in each dimension of the vector space needs to be filled in for each token. This is done by a second ‚Äúpre-real-training‚Äù learning exercise, where the ways in which any two tokens seem to be substituted for each other, in contexts in raw text that seem similar by the tokens that surround that context. It appears that this sort of learning ends up choosing embeddings for tokens such that their distance in different subspaces (for the standard definition of a subspace of a vector space) of the overall embedding correspond to some sorts of similarity. For instance, orange and red may be closer in one subspace than either is to fruit, but in another subspace red might be an outlier compared to the closeness of the other two. The first subspace might correspond more to color, and the second subspace as considering what class of tangible objects in the world the words can designate. But such decisions are not made by humans, both the categories and the distances are generated by learning from the data.&lt;/p&gt;
    &lt;p&gt;The number is chosen early on by the people building a new LLM based on their tolerance for paying for cloud services as it will be a big factor in how much data is needed to train the LLM and how many parameters will need to be learned.&lt;/p&gt;
    &lt;p&gt;Once there is an embedding like this, the very first stage of the neural network that represents the LLM takes each token from the output of the tokenizer and turns it into its vector position in the embedding. So, in the case of ChatGPT-3 where , each token is immediately turned into 12,288 numbers.&lt;/p&gt;
    &lt;p&gt;Thus we see here that there has been a lot of human engineering and knowledge about the ideas of word components, and sorts of meanings of words and how similarity can be extracted from language without knowing meanings has been applied to way in which the pre-training is done for a language.&lt;/p&gt;
    &lt;p&gt;In one sense the tokens are proto-symbols, but unlike traditional symbols it is not their unique identity that is important but how they compare to other proto-symbols within the system. AND, these proto-symbols are based on parts of human language, the parts that the invention called writing uses to transmit language between people without the necessity to do it in sound or in a synchronized manner ‚Äî writing can be read anywhere at any later time, even well after the writer is dead.&lt;/p&gt;
    &lt;p&gt;3.4 The commonality in these three applications of end to end learning&lt;/p&gt;
    &lt;p&gt;These three grand successes of end to end learning rely on very domain specific learning architectures down stream. But they also each rely on domain specific early processing of the data stream.&lt;/p&gt;
    &lt;p&gt;In these three cases that early processing was built for other purposes, for language to be heard or read, and for images to be seen, at entirely different locations and asynchronous time.&lt;/p&gt;
    &lt;p&gt;We do not have such a tradition for touch data. Touch for us, for now, is only the instantaneous touch we perceive first hand (no pun intended). We as a species have not developed technologies to capture touch, to store touch, to transmit touch over distances and time, nor to replay it to either ourselves or other humans.&lt;/p&gt;
    &lt;p&gt;In section 4 below I show how central touch is to human dexterity.&lt;/p&gt;
    &lt;p&gt;To think we can teach dexterity to a machine without understanding what components make up touch, without being able to measure touch sensations, and without being able to store and replay touch is probably dumb. And an expensive mistake.&lt;/p&gt;
    &lt;head rend="h5"&gt;4. Why the Ends are Uncracked for Dexterity&lt;/head&gt;
    &lt;p&gt;The center piece of my argument is that the brute force learning approaches that everyone rightfully touts as great achievements relied on case-specific very carefully engineered front-ends to extract the right data from the cacophony of raw signals that the real-world presents.&lt;/p&gt;
    &lt;p&gt;If it is the case for the big successes it is likely also the case for learning dexterity by brute force. If any one or any group is to succeed they will likely have to collect the both the right data, and learn the right thing. Most of the projects to teach humanoids dexterity are doing neither of these things. There are some exciting and promising experiments going on in academic laboratories, but they have not yet gotten close to demonstrating any real dexterity. By my third law of robotics that says that we are more than ten years away from the first profitable deployment of humanoid robots even with minimal dexterity.&lt;/p&gt;
    &lt;p&gt;Human dexterity relies on a rich sense of touch. And dexterity for humans involves more than just their hands; it often involves their elbows, the fronts of the bodies, legs, and feet (many machines have foot pedals). I am not going to present a comprehensive complete case for it here, as one might expect if this were a formal peer reviewed academic research paper. But I will show you results from a somewhat random selection of solid peer reviewed academic work stretching over fifty years which together demonstrate that humans use touch and force sensing extensively.&lt;/p&gt;
    &lt;p&gt;4.1 The human sense of touch is really rich and complex&lt;/p&gt;
    &lt;p&gt;The following two videos are from Roland Johansson‚Äôs lab at Ume√• University in Sweden where he has studied human touch for decades. In the first video the person picks a match out of a box and lights it. The task takes seven seconds. In the second video the same person tries again but this time the tips of her fingers have been anesthetized so she no longer has any sense of touch right at her fingertips. She can still sense many other things in the rest of her fingers and hand, and all the forces that she can ordinarily feel with her skeletal muscle system.&lt;/p&gt;
    &lt;quote&gt;The two URLs in case your browser does not point at the YouTube videos below: www.youtube.com/watch?v=zGIDptsNZMo www.youtube.com/watch?v=HH6QD0MgqDQ&lt;/quote&gt;
    &lt;p&gt;Without a sense of touch in her fingertips the person makes many unsuccessful attempts to pick up a match from the box, then fails to pickup an isolated match that had fallen on the table, then goes back to the box and straightens up the matches, manages to pick one up, then fumbles with the match trying to get it into the right orientation between her fingers, and successfully lights it after taking four times as long as she took with sensitive fingertips.&lt;/p&gt;
    &lt;p&gt;It looks like humanoid robots will need a sense of touch, and a level of touch sensing that no one has yet built in the lab in order for them to do tasks like the one above which is of the same order of difficulty that millions of workers do all day everyday in some parts of the world. [[I have visited well over 100 factories in the US, China, Japan, Korea, Taiwan, and Germany, some where my companies have been building my five major families of robots: Roomba, PackBot, Baxter, Sawyer, and Carter, and some where I have been selling robots to make workers in the factories more productive, and some where I was on technology advisory boards for the companies that ran the factories. I have seen this and many other types of dexterity of humans beings applied to complex tasks in all these factories.]]&lt;/p&gt;
    &lt;p&gt;In a review of Johansson‚Äôs earlier work from 1979 it is reported that a human hand has about 17,000 low-threshold mechanoreceptors in the glabrous skin (where hair doesn‚Äôt grow) of the hand, with about 1,000 of them right at the tip of each finger, but with much lower density over the rest of each finger and over the palm. These receptors come in four varieties (slow vs fast adapting, and a very localized area of sensitivity vs a much larger area) and fire when they sense pressure applied or released.&lt;/p&gt;
    &lt;p&gt;Next I will talk briefly about the work of David Ginty and his students in his lab at Harvard. You can see the lab‚Äôs complete list of publications here, stretching back to 1987. The mission of Ginty‚Äôs lab is:&lt;/p&gt;
    &lt;p&gt;We use approaches in molecular genetics, anatomy, physiology, behavior, and systems neurobiology to understand mammalian somatosensory neurons and central nervous system circuits that underlie our sense of touch.&lt;/p&gt;
    &lt;p&gt;From a press article summarizing almost forty years of Ginty‚Äôs work touch is described as follows:&lt;/p&gt;
    &lt;p&gt;touch concerns a smorgasbord of stimuli, including pokes, pulls, puffs, caresses and vibrations, as well as a range of temperatures and chemicals, such as capsaicin in chili peppers or menthol in mint. From these inputs arise perceptions of pressure, pain, itchiness, softness and hardness, warmth and cold, and the awareness of the body in space.&lt;/p&gt;
    &lt;p&gt;The article goes on to report that there have now been fifteen different families of neurons discovered that are involved in touch sensing and that are found in the human hand.&lt;/p&gt;
    &lt;p&gt;Such nerve endings turned out to be remarkably specialized. Near the skin‚Äôs surface, the flat variety, called a Merkel cell complex, responds to gentle indentation. Merkel cells abound in your lips and fingertips, allowing you to discern form and texture. Your fingers are also packed with coiled nerve endings called Meissner corpuscles, which wrap around support cells in a bulbous tangle. These sensors pick up the faint, minuscule vibrations generated by the slight slipping of an object against your hand as you grip it, enabling you to use tools with precision. Deeper in the skin dwell the onionlike Pacinian corpuscles, which detect rumblings in the earth, and the spindle-shaped Ruffini endings, which convey skin stretching.&lt;/p&gt;
    &lt;p&gt;Touch is a very complex set of sensors and processing, and gives much richer time dependent and motion dependent information than simple localized pressure.&lt;/p&gt;
    &lt;p&gt;Moving on to more general aspects of humans and what we sense as we manipulate, on top of that skeletal muscles sense forces that they are applying or that are applied to them. Muscle spindles detect muscle length and when they stretch, and Golgi tendon organs sense tension in the muscle and hence sense force being applied to the muscle.&lt;/p&gt;
    &lt;p&gt;We also make visual and touch estimates about objects that change our posture and the forces we apply when manipulating an object. Roland Johansson (again) describes how we estimate the materials in objects, and knowing their density predict the forces we will need to use. Sometimes we are mistaken but we quickly adapt.&lt;/p&gt;
    &lt;p&gt;Over the last two decades Roland Johansson‚Äôs work has shifted to understanding the role of forethought based on observations in how humans choose appropriate strategies for carrying out tasks with their hands and bodies. You can read his last twenty years of publications here. His papers include titles such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fingertip viscoelasticity enables human tactile neurons to encode loading history alongside current force&lt;/item&gt;
      &lt;item&gt;Human touch receptors are sensitive to spatial details on the scale of single fingerprint ridges&lt;/item&gt;
      &lt;item&gt;Gaze behavior when learning to link sequential action phases in a manual task&lt;/item&gt;
      &lt;item&gt;Integration of sensory quanta in cuneate nucleus neurons in vivo&lt;/item&gt;
      &lt;item&gt;Skill learning involves optimizing the linking of action phases&lt;/item&gt;
      &lt;item&gt;Slowly adapting mechanoreceptors in the borders of the human fingernail encode fingertip forces.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These show how rich and varied human grasping is beyond simple motions of fingers, even if the positions of the fingers can be measured accurately (see the reference in section 2.2 above, to Tesla‚Äôs newest data collection strategy).&lt;/p&gt;
    &lt;p&gt;4.2 What is the right data?&lt;/p&gt;
    &lt;p&gt;Collecting just visual data is not collecting the right data. There is so much more going into human dexterity that visual data completely leaves out.&lt;/p&gt;
    &lt;p&gt;Is anyone trying to do more than collect visual data and have a different more appropriate ‚Äúend‚Äù to connect learning to?&lt;/p&gt;
    &lt;p&gt;Apart from Figure and Tesla which are explicitly claim not to be doing so, the other big companies are not saying. And there are lots of big companies working on humanoid robots, and you can sort of tell by seeing which of your friends are getting hired by which company.&lt;/p&gt;
    &lt;p&gt;In academia though, there is still a healthy set of experiments going on. Here is just one example, from the ‚Äúbest paper‚Äù from the May 2025 Dexterous Human Manipulation workshop at the Robotics Systems and Science conference. It comes from Pulkit Agrawal‚Äôs group centered in CSAIL at MIT. It involves a newly invented way to collect the right data to feed to machine learning. As you can see in the two pictures below the human essentially has their hand in a glove. There is a robot hand rigidly attached to the glove so the robot hand is roughly 10cm away from the human hand and completely parallel to it. The human moves their fingers to control the robot hand fingers and the human moves their arm to place the robot hand in contact with objects to be manipulated.. The robot fingers and palm have touch sensors which feed to the data collection system and to the actuators which stimulate the human‚Äôs finger tips and palm. So while this system doesn‚Äôt record the forces that the human directly feels and controls with their arms, it does get to associate finger motions generated by a human with touch sensations that the human is sensing as they decide how to control the robot hand.&lt;/p&gt;
    &lt;p&gt;Clearly this is a long way from understanding everything that a human does with their wildly complex touch and force sensing system, but it is a step beyond simply collecting visual data, which alone can‚Äôt possibly be enough to infer how to be dexterous.&lt;/p&gt;
    &lt;p&gt;[[If the big tech companies and the VCs throwing their money at large scale humanoid training spent only 20% as much but gave it all to university researchers I tend to think they would get closer to their goals more quickly.]]&lt;/p&gt;
    &lt;p&gt;4.3 What is the right thing to learn?&lt;/p&gt;
    &lt;p&gt;Lastly I want to return to what I said at the start of this section (4) about the need to learn the right thing.&lt;/p&gt;
    &lt;p&gt;The framework that both industry and academia is using on what to learn comes from Reinforcement Learning (see the introduction part of section 3, above). In Reinforcement Learning, one learns a policy, which maps from the state, expressed by what the sensors are delivering right now, to a specific action for the robot to do right now.&lt;/p&gt;
    &lt;p&gt;But it seems from both personal experience and from some of the papers from haptics researchers above, that humans are sometimes pursuing a dexterity plan of what they are trying to do. Instead of what is being sensed mapping directly to action, what is being sensed probably modulates what is being done in following that plan (represented as a finite state machine, perhaps?). Thus to be truly successful at dexterity there needs to be a way to learn both how to plan in some weird space of subtasks, and how sensing at the tactile level should modulate those plans.&lt;/p&gt;
    &lt;p&gt;There is still plenty of research to be done to figure all this out. And then years to get to solid lab demos, then years more to get to deployable systems that bring value to customers.&lt;/p&gt;
    &lt;head rend="h5"&gt;5. The Other Problem for Humanoid Robots: Walking&lt;/head&gt;
    &lt;p&gt;I think it is fair to say, given the aspirations that humanoid robots have the same form as humans so that they can operate in built-for-human environments, people will expect them to be safe to be around. This is especially true for humanoids providing healthcare in the home for an aging human population. But by the master plans set out for humanoid robots it must be true in other environments too, as the idea is that the humanoid robots fit into human spaces there too. And that means humans will share those spaces, otherwise why not just build a special purpose lights out machine that can do the job.&lt;/p&gt;
    &lt;p&gt;So if anyone is going to deploy humanoid robots at scale it is important that they be safe for real humans to share space with them, so be just centimeters away from them, to lean on the humanoids for support, to be touched and manipulated by humanoid robots (as are the elderly touched and manipulated by human carers, helping them stand, wash, poop, get into and out of bed, etc.).&lt;/p&gt;
    &lt;p&gt;The trouble is that human sized two legged walking humanoid robots are not currently safe for humans to be around. But the argument for humanoid robots requires that they be full sized, so they can operate in human spaces and do all human tasks.&lt;/p&gt;
    &lt;p&gt;Ah, but you‚Äôve seen videos of, or walked within centimeters of (as I have), half sized humanoid robots, feeling quite safe around them. So you reason that it only a matter of a small amount of time before those robots are made bigger. But that is where physics comes in, with a vengeance.&lt;/p&gt;
    &lt;p&gt;Current humanoid robots do not walk at all like humans. Humans are stretchy springy systems, that very nearly walk without much in the way of neural control. In fact you can see models of biped walkers that are purely mechanical, walking down a gentle slope, with no power supply, relying only on the passive dynamics of the mechanism, and stealing potential energy from the act of walking downhill to power the robot (purely mechanically).&lt;/p&gt;
    &lt;p&gt;Here is a simple example:&lt;/p&gt;
    &lt;quote&gt;The URL is www.youtube.com/watch?v=wMlDT17C_Vs&lt;/quote&gt;
    &lt;p&gt;Besides that fundamental architecture, we also have an energy recycling architecture involving our muscles and tendons. We store energy in our tendons and reuse it on the next step ‚Äî our Achilles tendon at the back of each of our lower legs is the one that stores most energy and the one most likely to rupture.&lt;/p&gt;
    &lt;p&gt;Although there have been decades of academic research on building robots that walk like us in this regard, they have not gotten to the practical level that the current humanoid robots designs have reached.&lt;/p&gt;
    &lt;p&gt;But current humanoid robots use powerful electric motors to balance by pumping large amounts of energy into the system when there is instability, mostly following a version of the ZMP (Zero-Moment Point) algorithm. [[This algorithm has been around for a long time, and in the 2004 Volume 1 of the International Journal of Robotics, shown above at the start of section 2, on page 157, Miomir Vukobratoviƒá and Branislav Borovac, both from Serbia and Montenegro, had a paper celebrating their introduction of the algorithm thirty five years prior to that, making it roughly 56 years old now.]] Although they are tight lipped about exactly what they are doing the large companies working on humanoids seem to have added some Reinforcement Learning (RL) on top of ZMP starting points, to get better walking and less falls. ZMP relies on sensing forces in the sole of the feet, and so all humanoid robots do have that. But the RL algorithms rely on the whole structure being very stiff so humanoid robots are the antithesis of humans when it comes the mechanical structures doing the walking. These robots fall less often, but are still very dangerous for humans to be close to them when they do and will fall.&lt;/p&gt;
    &lt;p&gt;When an instability is detected while walking and the robot stabilizes after pumping energy into the system all is good, as that excess energy is taken out of the system by counter movements of the legs pushing against the ground over the next few hundred milliseconds. But if the robot happens to fall, the legs have a lot of free kinetic energy, rapidly accelerating them, often in free space. If there is anything in the way it gets a really solid whack of metal against it. And if that anything happens to be a living creature it will often be injured, perhaps severely.&lt;/p&gt;
    &lt;p&gt;But, but, but, the half sized humanoids are safe, so how much less safe can a full size humanoid robot be?&lt;/p&gt;
    &lt;p&gt;This is where scaling comes in, not in terms of numbers of robots, but in scaling laws of physical systems.&lt;/p&gt;
    &lt;p&gt;If you just expand a physical system by the same amount in every direction, say multiply all lengths by a scale factor , then the mass of the system goes up by . Since for the same acceleration you need to put in as much energy. So for a robot that is 50% bigger that is . And to get from today‚Äôs small safe-ish humanoids you have to pump in times as much energy. That is a whole different class of possible injuries. And it could be even worse, as for a limb, say, the mass goes up as the cube of but the cross section, which determines strength, only goes up as the square. [[This scaling is why elephants have much fatter legs for their body size than does a spider, even accounting for the latter having twice as many legs to support its weight.]] So the twice bigger robots may have to have proportionally much fatter legs, so more mass, and so they will pump up the energy by something larger than a factor of eight.&lt;/p&gt;
    &lt;p&gt;My advice to people is to not come closer than 3 meters to a full size walking robot. And the walking robot companies know this too. Even in their videos you will not see people close to a locomoting humanoid robot unless there is a big table between them, and even then the humanoids only shuffle around a little bit,&lt;/p&gt;
    &lt;p&gt;Until someone comes up with a better version of a two legged walking robot that is much safer to be near, and even in contact with, we will not see humanoid robots get certified to be deployed in zones that also have people in them.&lt;/p&gt;
    &lt;head rend="h5"&gt;6. What is the Future of Humanoid Robots?&lt;/head&gt;
    &lt;p&gt;Technology changes and the meanings of words around technologies change too.&lt;/p&gt;
    &lt;p&gt;When I made a whole bunch of dated predictions about future technologies back on January 1st, 2018, flying cars and self-driving cars meant different things than they do today. I pointed this out in my most recent scorecard on how my predictions were holding up.&lt;/p&gt;
    &lt;p&gt;Flying cars used to mean a vehicle that could both drive on roads and fly through the air. Now it has come to mean an electric multi-rotor helicopter than can operate like a taxi flying between various fixed landing locations. Often touted are versions that have no human pilot. These are known as eVTOLs, for ‚Äúelectric vertical take off &amp;amp; landing‚Äù. Besides not yet actually existing in any practical sense, flying cars (eVTOLS) are no longer cars, as they do not travel anywhere on the ground.&lt;/p&gt;
    &lt;p&gt;At the time I made my predictions self driving cars meant that the cars would drive themselves to wherever they were told to go with no further human control inputs. Now self driving cars means that there is no one in the driver‚Äôs seat, but there may well be, and in all cases so far deployed there are, humans monitoring those cars from a remote location, and occasionally sending control inputs to the cars. Except for Tesla self-driving robo taxis. In that case there is a human safety operator sitting in the front passenger seat.&lt;/p&gt;
    &lt;p&gt;Following that pattern, what it means to be a humanoid robot will change over time.&lt;/p&gt;
    &lt;p&gt;Before too long (and we already start to see this) humanoid robots will get wheels for feet, at first two, and later maybe more, with nothing that any longer really resembles human legs in gross form. But they will still be called humanoid robots.&lt;/p&gt;
    &lt;p&gt;Then there will be versions which variously have one, two, and three arms. Some of those arms will have five fingered hands, but a lot will have two fingered parallel jaw grippers. Some may have suction cups. But they will still be called humanoid robots.&lt;/p&gt;
    &lt;p&gt;Then there will be versions which have a lot of sensors that are not passive cameras, and so they will have eyes that see with active light, or in non-human frequency ranges, and they may have eyes in their hands, and even eyes looking down from near their crotch to see the ground so that they can locomote better over uneven surfaces. But they will still be called humanoid robots.&lt;/p&gt;
    &lt;p&gt;There will be many, many robots with different forms for different specialized jobs that humans can do. But they will all still be called humanoid robots.&lt;/p&gt;
    &lt;p&gt;And a lot of money will have disappeared, spent on trying to squeeze performance, any performance, from today‚Äôs humanoid robots. But those robots will be long gone and mostly conveniently forgotten.&lt;/p&gt;
    &lt;p&gt;That is the next fifteen years for you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45392922</guid><pubDate>Sat, 27 Sep 2025 02:53:24 +0000</pubDate></item><item><title>The Amazon Kindle War Against Piracy</title><link>https://goodereader.com/blog/kindle/the-amazon-kindle-war-against-piracy</link><description>&lt;doc fingerprint="b5425b1029bdacd4"&gt;
  &lt;main&gt;
    &lt;p&gt;The Amazon Kindle line of e-readers is at war against e-book piracy. They are doing everything that they can to make it impossible for users to download purchased e-books and download them to their computers. It is now impossible for the average user to back up e-books to download them or use tools to break the encryption and share them on piracy websites.&lt;/p&gt;
    &lt;p&gt;Virtually every method for downloading an e-book purchased from Amazon has either been discontinued, patched, or rendered inaccessible due to software updates that have locked everything down. You have heard of the Kindle walled garden? The walls are now taller than the Tower of Babylon.&lt;/p&gt;
    &lt;p&gt;A week ago, all 11th and 12th-generation Kindle e-readers, as well as the Kindle Scribe 1 and Scribe 2, and all versions of the Kindle Colorsoft received a software update. Amazon has revised its DRM system, and this new DRM uses an account secret stored in an inaccessible location on the Kindle, and the key needs to be unlocked to decrypt an e-book. Essentially, if you download a Kindle book, it cannot have its encryption broken, regardless of the tools used. It remains to be seen whether Amazon will update its 10th- and 9th-generation e-readers with this new DRM encryption system.&lt;/p&gt;
    &lt;p&gt;The 15.18.5 update is also having an adverse reaction to sideloaded books. If you deliver a book using Send by Email or copy it to your computer via USB, a critical issue may arise, where a pop-up appears with an ‚ÄòInvalid ASIN‚Äò number. The new DRM system is attempting to locate the book in the Amazon store to decrypt it, but since it can‚Äôt find it, it reports that the book is invalid. Amazon claims they are working on the issue, but preventing sideloading would be downright tyrannical.&lt;/p&gt;
    &lt;p&gt;Earlier this year, Amazon removed the download and transfer options via USB, one of the last ways to download any book to their computer. Kindle for PC was updated to disallow people with older versions of the app from downloading Kindle books. The app must be updated to even read purchased books, and they can now longer be downloaded. Kindle for PC, Kindle for Mac, Kindle Web Reader, Kindle for Android, and Kindle for iOS are all designed for reading only.&lt;/p&gt;
    &lt;p&gt;Amazon is also at war with developers who release software to jailbreak the Kindle. Every year, a new darling emerges that promises users more flexibility and control over their Kindle e-reader, only to have Amazon patch the underlying code, rendering it ineffective. Amazon is betting that they will lose interest and give up, which most do, or they focus on older devices, which no longer receive software updates. One of the most popular ones, WinterBreak, has been the most recent casualty.&lt;/p&gt;
    &lt;p&gt;Draconian measures are being taken to prevent Kindle books from being downloaded and having their DRM busted open with tools. This could possibly convince self-publishers and their major publishing partners that Kindle takes security seriously, and this could lead to more books being published on the Kindle Store, ultimately resulting in increased sales.&lt;/p&gt;
    &lt;p&gt;Is the war against piracy only alienating a small subset of users? The average user just wants to read books, not deal with anything overly complicated. I think this is the customer that Amazon wants: people who buy from their store and simply don‚Äôt care about anyone else.&lt;/p&gt;
    &lt;p&gt;Michael Kozlowski has written about audiobooks, e-books and e-readers for the past eighteen years. He Lives in Vancouver, British Columbia, Canada.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45393505</guid><pubDate>Sat, 27 Sep 2025 06:02:16 +0000</pubDate></item></channel></rss>