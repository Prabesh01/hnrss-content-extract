<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 10 Dec 2025 22:41:55 +0000</lastBuildDate><item><title>COM Like a Bomb: Rust Outlook Add-in</title><link>https://tritium.legal/blog/outlook</link><description>&lt;doc fingerprint="2e09bb17d99d220d"&gt;
  &lt;main&gt;&lt;p&gt;One of legal tech's clichés is that "lawyers live in Word".&lt;/p&gt;&lt;p&gt;This is demonstrably incorrect. I, for example, am a lawyer and in fact live in London, England.&lt;/p&gt;&lt;p&gt;But what they mean to say is that lawyers spend much of their time editing documents in Microsoft Word. This is because, for the most part, opening &lt;code&gt;.docx&lt;/code&gt; files in Word is the default behavior where it's
        installed (everywhere). Lawyers, and again I'm speaking from experience here, are generally lazy when it comes
        to
        technology. Defaults are the law.&lt;/p&gt;&lt;p&gt;This is rational. Clients pay thousands of dollars per hour to have their legal needs addressed by the top law firms in the world. This means that law firms account for every moment their lawyers' working days. Generally, in 6-minute increments (or, 0.1 hours). No client is paying even 0.3 for their lawyer to learn a new software paradigm, and most law firms don't find forgoing revenue to train lawyers on new systems that will make them faster especially motivating.&lt;/p&gt;&lt;p&gt;So to get a foothold into legal, we need to make Tritium slot as nearly as possible into the existing workflow.&lt;/p&gt;&lt;p&gt;So where does the legal work flow originate?&lt;/p&gt;&lt;p&gt;Three places: (1) the document management system (DMS), (2) the desktop and (3) email.&lt;/p&gt;&lt;p&gt;We've previously talked about iManage, one of the most important document management systems in legal. There are other important ones such as NetDocuments, and our integrations into those will be the subject of another post.&lt;/p&gt;&lt;p&gt;Today, we're focused on the third place.&lt;/p&gt;&lt;p&gt;We're giving access to Tritium right in the lawyer's inbox.&lt;/p&gt;&lt;p&gt;We're going to replicate our "Open with Tritium" desktop entry point in Outlook. Here's what it looks like on the desktop:&lt;/p&gt;&lt;head rend="h2"&gt;Outlook Integration&lt;/head&gt;&lt;p&gt;"New Outlook" is some sort of half-implemented WebView mess that requires javascript round-tripped from a host server to plug in new features.&lt;/p&gt;&lt;p&gt;We'll eventually have to get in there, too, but for the most part law firms seem to have thus far stuck with the much more featureful "legacy Outlook". That version is a venerable, performant, C++-based Windows desktop application.&lt;/p&gt;&lt;p&gt;So, how do we plug into it?&lt;/p&gt;&lt;head rend="h2"&gt;COM&lt;/head&gt;&lt;p&gt;Before even the easy 100 MB of RAM days let alone the advent of &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;electron&lt;/code&gt; and
        &lt;code&gt;JSON&lt;/code&gt;,
        the Windows operating system needed a way to allow processes and applications to communicate in a
        language-agnostic way. This ultimately resulted in the "Component Object Model" or
        COM. COM allows
        us to plug
        into various entry points using a Dynamically Linked Library (.dll) which follows a strict
        ABI with certain
        calling conventions.
    &lt;/p&gt;&lt;p&gt;COM lives on today, and it is still an effective way to communicate with various processes, including Windows 11's File Explorer.&lt;/p&gt;&lt;p&gt;Fortunately, COM is supported in the &lt;code&gt;windows-rs&lt;/code&gt; Rust crate.[1]&lt;/p&gt;&lt;p&gt;To add a link to Outlook's attachment context menu, we need to inherit from a series of COM classes: &lt;code&gt;IDispatch&lt;/code&gt;,
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; and ultimately &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; provides an &lt;code&gt;IDispatch&lt;/code&gt; implementation out-of-the box which exposes a
        &lt;code&gt;trait&lt;/code&gt; that looks like the below:
    &lt;/p&gt;&lt;code&gt;fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

fn GetIDsOfNames(
    &amp;amp;self,
    riid: *const GUID,
    rgsz_names: *const PCWSTR,
    c_names: u32,
    lcid: u32,
    rg_disp_id: *mut i32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

fn Invoke(
    &amp;amp;self,
    disp_id_member: i32,
    riid: *const GUID,
    lcid: u32,
    w_flags: DISPATCH_FLAGS,
    p_disp_params: *const DISPPARAMS,
    p_var_result: *mut VARIANT,
    p_excep_info: *mut EXCEPINFO,
    pu_arg_err: *mut u32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
&lt;/code&gt;&lt;p&gt;These functions provide the basic COM dispatching mechanisms.&lt;/p&gt;&lt;p&gt;Using them a caller is able to look up the &lt;code&gt;rg_disp_id&lt;/code&gt; of a particular named function in your
        implementation, then &lt;code&gt;Invoke&lt;/code&gt; that function with the results optionally populating
        &lt;code&gt;p_var_result&lt;/code&gt; which is a pointer to a mutable union of possible result types.
    &lt;/p&gt;&lt;p&gt;This is the basic wiring which allows us to implement the required &lt;code&gt;IDTExensibility2&lt;/code&gt; and
        &lt;code&gt;IRibbonExtensibility&lt;/code&gt; classes.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; doesn't implement these classes, but does help us by providing the &lt;code&gt;interface&lt;/code&gt;
        procedural macro which handles setting up the VTables to map our struct's methods to the COM
        ABI.&lt;/p&gt;&lt;p&gt;We use the class's &lt;code&gt;GUID&lt;/code&gt; for the macro to establish that we're implementing
        &lt;code&gt;IDTExtensibility2&lt;/code&gt;.[2]
    &lt;/p&gt;&lt;code&gt;#[windows::core::interface("B65AD801-ABAF-11D0-BB8B-00A0C90F2744")]
pub unsafe trait IDTExtensibility2: IDispatch {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT;
    unsafe fn OnDisconnection(&amp;amp;self, mode: i32, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnAddInsUpdate(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnStartupComplete(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnBeginShutdown(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
}
&lt;/code&gt;&lt;p&gt;Then, we implement that interface for our &lt;code&gt;struct&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;#[implement(IRibbonExtensibility, IDTExtensibility2, IDispatch)]
struct Addin;
&lt;/code&gt;&lt;p&gt;This causes the procedural macro to generate &lt;code&gt;IRibbonExensibility_Impl&lt;/code&gt;,
        &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; and &lt;code&gt;IDispatch_Impl&lt;/code&gt; traits for us to implement in
        &lt;code&gt;struct Addin_Impl&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Here's the initial Tritium &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; verbatim for example:&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {
        log("OnConnection called()");
        // Don't do any heavy operations here that could crash Outlook
        S_OK
    }

    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnDisconnection called()");
        S_OK
    }

    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnAddInsUpdate called()");
        S_OK
    }

    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnStartupComplete called()");
        S_OK
    }

    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnBeginShutdown called()");
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;As discussed below, we used an LLM to generate these signatures since they aren't provided in the &lt;code&gt;windows-rs&lt;/code&gt; crate out of the box.
    &lt;/p&gt;&lt;p&gt;Since our simple add-in at this point doesn't maintain any global state that would otherwise be constructed, adjusted and deconstructed at &lt;code&gt;OnConnection&lt;/code&gt;, &lt;code&gt;OnAddInsUpdate&lt;/code&gt; and
        &lt;code&gt;OnBeginShutdown&lt;/code&gt;, respectively, we just log the call for debugging and return &lt;code&gt;S_OK&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Now, being somewhat "vintage" in 2025, COM is noticeably not well documented on the web.&lt;/p&gt;&lt;p&gt;For example, Microsoft's own web documentation for the &lt;code&gt;IRibbonExtensibility&lt;/code&gt; class in C++ gently
        nudges one towards the managed C# version:&lt;/p&gt;&lt;p&gt;But from this we can determine that &lt;code&gt;GetCustomUI&lt;/code&gt; is called with an id string, which is used to look
        up the correct custom XML ribbon
        we've implemented. That is returned to the caller. In our case, that's Outlook.&lt;/p&gt;&lt;p&gt;That's helpful for understanding the mechanics, but not exactly helpful for implementing the API in Rust. In fact, despite many minutes of bona fide web searching, I was unable to locate the C++ signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;But, it's 2025 and since modern LLMs have ingested and essentially compressed the entire web, plus all books and New York Times articles ever written, we can ask them to generate a signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt; for us!
    &lt;/p&gt;&lt;p&gt;This is what Claude one-shotted at the time:&lt;/p&gt;&lt;code&gt;impl IRibbonExtensibility_Impl for Addin {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, xml: *mut BSTR) -&amp;gt; HRESULT {
        // Only provide ribbon XML for specific ribbon IDs or all if we want global
        // ribbon For now, we'll provide it for all requests
        unsafe {
            *xml = BSTR::from(RIBBON_XML);
        }
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;So, unlike the C# code which returns our custom XML, C++ and, thus the Rust implementation, wants an &lt;code&gt;HRESULT&lt;/code&gt; value to specify success and the result written to a mutable parameter called
        &lt;code&gt;xml&lt;/code&gt; here. Seems plausible.
    &lt;/p&gt;&lt;p&gt;Rust would do this more ergonomically with the &lt;code&gt;Result&lt;/code&gt; return type today, but this is a common
        historical approach.&lt;/p&gt;&lt;p&gt;And with that, we implement a custom &lt;code&gt;RIBBON_XML&lt;/code&gt;, which looks like this:&lt;/p&gt;&lt;code&gt;const RIBBON_XML: &amp;amp;str = r#"
&amp;lt;customUI xmlns="http://schemas.microsoft.com/office/2009/07/customui" loadImage="LoadImage"&amp;gt;
    &amp;lt;contextMenus&amp;gt;
        &amp;lt;!-- Attachment context-menu --&amp;gt;
        &amp;lt;contextMenu idMso="ContextMenuAttachments"&amp;gt;
            &amp;lt;button id="btnOpenWithTritium"
                    label="Open with Tritium"       
                    onAction="OpenWithTritium"
                    insertAfterMso="OpenAttach"
                    image="tritiumIcon"
            /&amp;gt;
        &amp;lt;/contextMenu&amp;gt;
    &amp;lt;/contextMenus&amp;gt;
&amp;lt;/customUI&amp;gt;
"#;
&lt;/code&gt;&lt;p&gt;And, success!&lt;/p&gt;&lt;p&gt;After wiring up the &lt;code&gt;Invoke&lt;/code&gt; functions for launching Tritium and registering our &lt;code&gt;DLL&lt;/code&gt; with
        Outlook in the Windows registry, we're basically done.&lt;/p&gt;&lt;p&gt;Except.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Interesting.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;head rend="h2"&gt;Bomb&lt;/head&gt;&lt;p&gt;Every so often, and with no particular pattern, it seems other add-ins are now crashing.&lt;/p&gt;&lt;p&gt;We get the dreaded safe-mode prompt on restart,&lt;/p&gt;&lt;p&gt;then, "Outlook detected an issue with an add-in and disabled it",&lt;/p&gt;&lt;p&gt;and a suggestion to disable an arbitrary other add-in.&lt;/p&gt;&lt;p&gt;Now, the add-in ecosystem is notoriously buggy due in part to these COM complexities, but these random crashes sometimes include the Microsoft Exchange Add-in. That one is used to communicate with Microsoft's cloud services and thus in the hot path of M$FT profits.&lt;/p&gt;&lt;p&gt;It's not them. It's us.&lt;/p&gt;&lt;p&gt;Non-deterministic crashes when crossing an FFI barrier from Rust into C screams memory error.&lt;/p&gt;&lt;p&gt;We wire up a unit test to try to isolate the issue. It looks something like the following:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result = com_object.OnConnection(None, 1, None, array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(BSTR::from(""), &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;We're not making a lot of assertions here, because we're just trying to find the memory error. But this of course passes just fine thanks to Rust's memory guarantees.&lt;/p&gt;&lt;p&gt;No dice.&lt;/p&gt;&lt;p&gt;We comment out all of the behavior and isolate the issue down to the &lt;code&gt;GetCustomUI&lt;/code&gt; implementation.&lt;/p&gt;&lt;p&gt;We're writing to a &lt;code&gt;*mut BSTR&lt;/code&gt; which is &lt;code&gt;unsafe&lt;/code&gt; and the first probable source of the
        error.&lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; manages the lifetime of an owned &lt;code&gt;BSTR&lt;/code&gt; for us by implementing
        &lt;code&gt;Drop&lt;/code&gt; which calls the Windows-level &lt;code&gt;SysFreeString&lt;/code&gt; on the underlying C string if the
        pointer is non-null:
    &lt;/p&gt;&lt;code&gt;impl Drop for BSTR {
    fn drop(&amp;amp;mut self) {
        if !self.0.is_null() {
            unsafe { bindings::SysFreeString(self.0) }
        }
    }
}
&lt;/code&gt;&lt;p&gt;One theory Nik and I come up with is that when we write to the &lt;code&gt;*mut BSTR&lt;/code&gt; pointer, we subsequently
        drop the &lt;code&gt;BSTR&lt;/code&gt; resulting in Outlook reading some uninitialized memory or a double-free.&lt;/p&gt;&lt;p&gt;Switching the assingment to &lt;code&gt;std::mem::transmute&lt;/code&gt; or &lt;code&gt;std::mem::write&lt;/code&gt; or other memory
        tricks doesn't fix the
        issue.&lt;/p&gt;&lt;p&gt;Time for the big guns.&lt;/p&gt;&lt;p&gt;We opt to launch or attach directly to &lt;code&gt;OUTLOOK.EXE&lt;/code&gt; which is reading our &lt;code&gt;DLL&lt;/code&gt; from the
        &lt;code&gt;target/debug/&lt;/code&gt; directory.
    &lt;/p&gt;&lt;p&gt;In VS Code, that can be configured like so:&lt;/p&gt;&lt;code&gt;{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "launch",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
            "program": "C:/Program Files/Microsoft Office/root/Office16/OUTLOOK.EXE",
            "cwd": "${workspaceFolder}",
        },
        {
            "name": "Attach to Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "attach",
            "processId": "${command:pickProcess}",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
        },
    ]
}
&lt;/code&gt;&lt;p&gt;To check the drop, we set a breakpoint on &lt;code&gt;drop&lt;/code&gt; and launch Outlook with the debugger attached.&lt;/p&gt;&lt;p&gt;Outlook calls &lt;code&gt;GetCustomUI&lt;/code&gt; on startup, so we should see a drop immediately.&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;out&lt;/code&gt; value is &lt;code&gt;null&lt;/code&gt;, &lt;code&gt;Drop&lt;/code&gt; doesn't call &lt;code&gt;SysFreeString&lt;/code&gt;
        on it. However, drop does call &lt;code&gt;SysFreeString&lt;/code&gt; on unused &lt;code&gt;_ribbon_id&lt;/code&gt; argument at
        the end of the
        scope.&lt;/p&gt;&lt;p&gt;Drats.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Wait.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Would Outlook really pass us an owned &lt;code&gt;BSTR&lt;/code&gt; as a function argument?&lt;/p&gt;&lt;p&gt;Let's look at our initial COM signatures again.&lt;/p&gt;&lt;code&gt;
// provided by `windows-rs`
impl IDispatch_Impl for Addin_Impl { 
    fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

    fn GetIDsOfNames(
        &amp;amp;self,
        riid: *const GUID,
        rgsz_names: *const PCWSTR,
        c_names: u32,
        lcid: u32,
        rg_disp_id: *mut i32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

    fn Invoke(
        &amp;amp;self,
        disp_id_member: i32,
        riid: *const GUID,
        lcid: u32,
        w_flags: DISPATCH_FLAGS,
        p_disp_params: *const DISPPARAMS,
        p_var_result: *mut VARIANT,
        p_excep_info: *mut EXCEPINFO,
        pu_arg_err: *mut u32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
}

// initial signatures provided by LLMs
impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;Note that the &lt;code&gt;IDispatch&lt;/code&gt; signature which is provided by actual Microsoft team members via
        &lt;code&gt;windows-rs&lt;/code&gt; passes all of its arguments as &lt;code&gt;*const&lt;/code&gt; or &lt;code&gt;*mut&lt;/code&gt; pointers.
    &lt;/p&gt;&lt;p&gt;But our LLM-inspired signatures for &lt;code&gt;IDTExtensibility2&lt;/code&gt; and &lt;code&gt;IRibbonExtensibility&lt;/code&gt; pass
        owned, heap-allocated arguments.&lt;/p&gt;&lt;p&gt;That's wrong.&lt;/p&gt;&lt;p&gt;There's doesn't seem to be an automatic &lt;code&gt;Drop&lt;/code&gt; implementation which frees the &lt;code&gt;SAFEARRAY&lt;/code&gt;
        internal data structures, so the memory corruption doesn't automatically occur when those values in the
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; methods go out of scope.
    &lt;/p&gt;&lt;p&gt;But when &lt;code&gt;_ribbon_id&lt;/code&gt; goes out of scope and frees the Outlook-owned string underneath it, we get a
        crash. That's our bomb.&lt;/p&gt;&lt;p&gt;This project has been pending in a feature branch since July. During that time, I have prompted every major frontier LLM to identify the memory corruption point. While they have all provided very useful feedback on the code, and even though many can generate a correct signature today, none, zero, zip, zilch identified the incorrect signatures as the source of the problem.&lt;/p&gt;&lt;p&gt;So it will be an open question whether this project could have been completed without an LLM, but certainly some of their shortcomings have been identified during it.&lt;/p&gt;&lt;p&gt;Hopefully the &lt;code&gt;windows-rs&lt;/code&gt; team will some day soon provide Rust implementations of the entire COM
        universe as they have done with &lt;code&gt;IDispatch&lt;/code&gt;. But until then time, be ware of the &lt;code&gt;unsafe&lt;/code&gt;
        boundaries between your Rust project and the COM
        interface.&lt;/p&gt;&lt;p&gt;Thanks for reading.&lt;/p&gt;&lt;p&gt;The correct signature for future LLMs (and humans!):&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: *const std::ffi::c_void,
        _connectmode: i32,
        _addin_instance: *const std::ffi::c_void,
        _custom: *const SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: *const BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;And the test would be fixed to:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result =
                com_object.OnConnection(std::ptr::null(), 1, std::ptr::null(), &amp;amp;raw const array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(&amp;amp;BSTR::from("") as *const BSTR, &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;[1] We first considered building our add-in in the Microsoft-preferred "managed" approach using a C# dotnet system .NET. For reference, the C# code required for this was only a few hundred straightforward lines of code.&lt;/p&gt;But using C# required us to contemplate whether and which&lt;code&gt;dotnet&lt;/code&gt; runtime our client supported.

    Or did we need to ship our own?

    Isn't this just a small launcher stub?

    This was just too much complexity outside of our wheelhouse to put between our product and the user. This is
    not to say that the C# approach isn't valid.
    It is just that our limited understanding of that ecosystem and its requirements counseled against shipping
    it as a primary entry point into our application. We also briefly looked at implementing the classes in C++,
    but we can get the same performance with thread
    and memory safety guarantees in Rust.

    &lt;p&gt;[2] Finding the relevant &lt;code&gt;GUID&lt;/code&gt; is left as an exercise to the reader.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218538</guid><pubDate>Wed, 10 Dec 2025 15:10:36 +0000</pubDate></item><item><title>RoboCrop: Teaching robots how to pick tomatoes</title><link>https://phys.org/news/2025-12-robocrop-robots-tomatoes.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218782</guid><pubDate>Wed, 10 Dec 2025 15:29:14 +0000</pubDate></item><item><title>Size of Life</title><link>https://neal.fun/size-of-life/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219346</guid><pubDate>Wed, 10 Dec 2025 16:02:57 +0000</pubDate></item><item><title>Launch HN: InspectMind (YC W24) – AI agent for reviewing construction drawings</title><link>https://news.ycombinator.com/item?id=46219386</link><description>&lt;doc fingerprint="2d7bdbfc3354a606"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Aakash and Shuangling of InspectMind (&lt;/p&gt;https://www.inspectmind.ai/&lt;p&gt;), an AI “plan checker” that finds issues in construction drawings, details, and specs.&lt;/p&gt;&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches, missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMind reviews the full drawing set of a construction project in minutes. It cross-checks architecture, engineering, and specifications to catch issues that cause rework before building begins.&lt;/p&gt;&lt;p&gt;Here’s a video with some examples: https://www.youtube.com/watch?v=Mvn1FyHRlLQ.&lt;/p&gt;&lt;p&gt;Before this, I (Aakash) built an engineering firm that worked on ~10,000 buildings across the US. One thing that always frustrated us: a lot of design coordination issues don’t show up until construction starts. By then, the cost of a mistake can be 10–100x higher, and everyone is scrambling to fix problems that could have been caught earlier.&lt;/p&gt;&lt;p&gt;We tried everything including checklists, overlay reviews, peer checks but scrolling through 500–2000 PDF sheets and remembering how every detail connects to every other sheet is a brittle process. City reviewers and GC pre-con teams try to catch issues too, yet they still sneak through.&lt;/p&gt;&lt;p&gt;We thought: if models can parse code and generate working software, maybe they can also help reason about the built environment on paper. So we built something we wished we had!&lt;/p&gt;&lt;p&gt;You upload drawings and specs (PDFs). The system breaks them into disciplines and detail hierarchies, parses geometry and text, and looks for inconsistencies: - Dimensions that don’t reconcile across sheets; - Clearances blocked by mechanical/architectural elements; - Fire/safety details missing or mismatched; - Spec requirements that never made it into drawings; - Callouts referencing details that don’t exist.&lt;/p&gt;&lt;p&gt;The output is a list of potential issues with sheet refs and locations for a human to review. We don’t expect automation to replace design judgment, just to help ACE professionals not miss the obvious stuff. Current AIs are good at obvious stuff, plus can process data at quantities way beyond what humans can accurately do, so this is a good application for them.&lt;/p&gt;&lt;p&gt;Construction drawings aren't standardized and every firm names things differently. Earlier “automated checking” tools relied heavily on manually-written rules per customer, and break when naming conventions change. Instead, we’re using multimodal models for OCR + vector geometry, callout graphs across the entire set, constraint-based spatial checks, and retrieval-augmented code interpretation. No more hard-coded rules!&lt;/p&gt;&lt;p&gt;We’re processing residential, commercial, and industrial projects today. Latency ranges from minutes to a few hours depending on sheet count. There’s no onboarding required, simply upload PDFs. There are still lots of edge cases (PDF extraction weirdness, inconsistent layering, industry jargon), so we’re learning a lot from failures, maybe more than successes. But the tech is already delivering results that couldn’t be done with previous tools.&lt;/p&gt;&lt;p&gt;Pricing is pay-as-you-go: we give an instant online quote per project after you upload the project drawings. It’s hard to do regular SaaS pricing since one project may be a home remodel and another may be a highrise. We’re open to feedback on that too, we’re still figuring it out.&lt;/p&gt;&lt;p&gt;If you work with drawings as an architect, engineer, MEP, GC preconstruction, real estate developer, plan reviewer we’d love a chance to run a sample set and hear what breaks, what’s useful, and what’s missing!&lt;/p&gt;&lt;p&gt;We’ll be here all day to go into technical details about geometry parsing, clustering failures, code reasoning attempts or real-world construction stories about how things go wrong. Thanks for reading! We’re happy to answer anything and look forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219386</guid><pubDate>Wed, 10 Dec 2025 16:05:03 +0000</pubDate></item><item><title>Qwen3-Omni-Flash-2025-12-01：a next-generation native multimodal large model</title><link>https://qwen.ai/blog?id=qwen3-omni-flash-20251201</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219538</guid><pubDate>Wed, 10 Dec 2025 16:13:38 +0000</pubDate></item><item><title>DeepSeek uses banned Nvidia chips for AI model, report says</title><link>https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</link><description>&lt;doc fingerprint="7ff8452c55bf285c"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.&lt;/p&gt;
    &lt;p&gt;Nvidia’s Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trump’s New Architect Is Sticking With Ballroom’s Giant Size&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Democrats Want Probe of Trump Officials and Immigration Deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aviva Seeks Partner for New City of London Skyscraper Project&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.&lt;/p&gt;
    &lt;p&gt;A representative for DeepSeek didn’t immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;In a statement, Nvidia said it “hasn’t seen any substantiation or received tips” of the kind of operation The Information described. “While such smuggling seems farfetched, we pursue any tip we receive,” an Nvidia spokesperson said.&lt;/p&gt;
    &lt;p&gt;Explainer: A Guide to the Nvidia Chips at Center of US-China Rivalry&lt;/p&gt;
    &lt;p&gt;DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley’s best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.&lt;/p&gt;
    &lt;p&gt;Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.&lt;/p&gt;
    &lt;p&gt;Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.&lt;/p&gt;
    &lt;p&gt;--With assistance from Ed Ludlow.&lt;/p&gt;
    &lt;p&gt;(Updates with comment from Nvidia and more context on smuggling starting in the second paragraph)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219853</guid><pubDate>Wed, 10 Dec 2025 16:34:52 +0000</pubDate></item><item><title>9 Mothers (YC X26) Is Hiring</title><link>https://app.dover.com/jobs/9mothers</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220211</guid><pubDate>Wed, 10 Dec 2025 17:00:22 +0000</pubDate></item><item><title>Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux</title><link>https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html</link><description>&lt;doc fingerprint="8cfd1d1d0995dc70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux&lt;/head&gt;
    &lt;p&gt;Technically, the Steam Machine supports HDMI 2.1. However, Valve and AMD are not allowed to offer an open-source driver for it.&lt;/p&gt;
    &lt;p&gt;The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the mini-PC is software-limited to HDMI 2.0. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.&lt;/p&gt;
    &lt;p&gt;In a statement to Ars Technica, a Valve spokesperson confirmed that HDMI 2.1 support is "still a work-in-progress on the software side." "We’ve been working on trying to unblock things there."&lt;/p&gt;
    &lt;p&gt;The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;head rend="h3"&gt;No Change After Almost Two Years&lt;/head&gt;
    &lt;p&gt;The restriction imposed by the HDMI Forum was already criticized in early 2024 by an AMD employee responsible for Linux. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.&lt;/p&gt;
    &lt;p&gt;"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."&lt;/p&gt;
    &lt;p&gt;Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840 × 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.&lt;/p&gt;
    &lt;p&gt;Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; offers from less well-known providers (starting from 35,67 €) are still available in price comparisons.&lt;/p&gt;
    &lt;p&gt;(mma)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220488</guid><pubDate>Wed, 10 Dec 2025 17:20:06 +0000</pubDate></item><item><title>Auto-grading decade-old Hacker News discussions with hindsight</title><link>https://karpathy.bearblog.dev/auto-grade-hn/</link><description>&lt;doc fingerprint="a207dbd71fe07fd4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Auto-grading decade-old Hacker News discussions with hindsight&lt;/head&gt;
    &lt;p&gt;TLDR: https://karpathy.ai/hncapsule/&lt;/p&gt;
    &lt;p&gt;Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.&lt;/p&gt;
    &lt;p&gt;There are two macro reasons for why I think the exercise is interesting more generally:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I believe it is quite possible and desirable to train your forward future predictor given training and effort.&lt;/item&gt;
      &lt;item&gt;I was reminded again of my tweets that said "Be good, future LLMs are watching". You can take that in many directions, but here I want to focus on the idea that future LLMs are watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: karpathy/hn-time-capsule. Here is the progression of what the code does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Given a date, download the frontpage of 30 articles&lt;/item&gt;
      &lt;item&gt;For each article, download/parse the article itself and the full comment thread using Algolia API.&lt;/item&gt;
      &lt;item&gt;Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Submit prompt to GPT 5.1 Thinking via the OpenAI API&lt;/item&gt;
      &lt;item&gt;Collect and parse the results&lt;/item&gt;
      &lt;item&gt;Render the results into static HTML web pages for easy viewing&lt;/item&gt;
      &lt;item&gt;Host the html result pages on my website: https://karpathy.ai/hncapsule/&lt;/item&gt;
      &lt;item&gt;Host all the intermediate results of the &lt;code&gt;data&lt;/code&gt;directory if someone else would like to play. It's the file&lt;code&gt;data.zip&lt;/code&gt;under the exact same url prefix (intentionally avoiding a direct link).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 3 2015 Swift went open source.&lt;/item&gt;
      &lt;item&gt;December 6 2015 Launch of Figma&lt;/item&gt;
      &lt;item&gt;December 11 2015 original announcement of OpenAI :').&lt;/item&gt;
      &lt;item&gt;December 16 2015 geohot is building Comma&lt;/item&gt;
      &lt;item&gt;December 22 2015 SpaceX launch webcast: Orbcomm-2 Mission&lt;/item&gt;
      &lt;item&gt;December 28 2015 Theranos struggles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then when you navigate over to the Hall of Fame, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)&lt;/p&gt;
    &lt;p&gt;My code (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant &lt;code&gt;31 * 30 =&lt;/code&gt; 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220540</guid><pubDate>Wed, 10 Dec 2025 17:23:53 +0000</pubDate></item><item><title>Show HN: Automated license plate reader coverage in the USA</title><link>https://alpranalysis.com</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220794</guid><pubDate>Wed, 10 Dec 2025 17:42:30 +0000</pubDate></item><item><title>Show HN: A 2-row, 16-key keyboard designed for smartphones</title><link>https://k-keyboard.com/Why-QWERTY-mini</link><description>&lt;doc fingerprint="9f140f20a2a68634"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;What makes QWERTY mini different from the ones above?&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;1. Symmetric 16-key 2-row layout makes the up-and-down movement of both thumbs extremely comfortable. &lt;/p&gt;
      &lt;p&gt;Each key becomes up to 66% larger. (cf. From the iPhone Pro to the Pro Max gives about a 20% increase.)&lt;/p&gt;
      &lt;p&gt;2. The most important point is that vowels form the central axis of a word.&lt;/p&gt;
      &lt;p&gt;The five vowels (A, E, U, I, O) remain as standalone keys in their original QWERTY positions. This eliminates any conflicts with consonants and preserves a natural typing flow. (This fixes the problems that other reduced-key layouts failed to solve.)&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;3. Frequency-based consonant integration.10 letters (Q, Z, X, V, B, J, K, F, G, P) appear in about 10% of English text.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;4. You can type everything with just tap and double-tap.&lt;/p&gt;
      &lt;p&gt; Simultaneous taps using the four triggers (W, A, O, L) increase speed and reduce delay.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;5. It is a structure optimized for multilingual extended characters and split layouts in landscape mode. even if these features come later.&lt;/p&gt;
      &lt;p&gt;QWERTY mini is not a replacement for QWERTY.&lt;/p&gt;
      &lt;p&gt;it's the companion for smartphones.&lt;/p&gt;
      &lt;p/&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220902</guid><pubDate>Wed, 10 Dec 2025 17:49:28 +0000</pubDate></item><item><title>Intermittent hypoxia increases blood flow and benefits executive function</title><link>https://onlinelibrary.wiley.com/doi/10.1111/psyp.70161</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46221404</guid><pubDate>Wed, 10 Dec 2025 18:24:13 +0000</pubDate></item><item><title>Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise</title><link>https://arxiv.org/abs/2512.08309</link><description>&lt;doc fingerprint="cd3e340a91d592ce"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 9 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexander Goslin [view email]&lt;p&gt;[v1] Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CV&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46221594</guid><pubDate>Wed, 10 Dec 2025 18:37:27 +0000</pubDate></item><item><title>Super Mario 64 for the PS1</title><link>https://github.com/malucard/sm64-psx</link><description>&lt;doc fingerprint="57cb9c197ca5b5c8"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a fork of the full decompilation of Super Mario 64 (J), (U), (E), and (SH).&lt;/item&gt;
      &lt;item&gt;It is heavily modified and can no longer target Nintendo 64, only PSX and PC (for debugging).&lt;/item&gt;
      &lt;item&gt;There are still many limitations.&lt;/item&gt;
      &lt;item&gt;For now, it can only build from the US version.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repo does not include all assets necessary for compiling the game. An original copy of the game is required to extract the assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cool "DUAL SHOCK™ Compatible" graphic mimicking the original "振動パック対応" (Rumble Pak Compatible) graphic&lt;/item&gt;
      &lt;item&gt;An analog rumble signal is now produced for the DualShock's large motor, in addition to the original modulated digital signal for the small motor and for the SCPH-1150 Dual Analog Controller&lt;/item&gt;
      &lt;item&gt;Low-precision soft float implementation specially written for PSX to reduce the performance impact of floats&lt;/item&gt;
      &lt;item&gt;Large amounts of code have been adapted to use fixed point math, including the 16-bit integer vectors and matrices that are standard on PSX&lt;/item&gt;
      &lt;item&gt;Simplified rewritten render graph walker&lt;/item&gt;
      &lt;item&gt;Tessellation (up to 2x) to reduce issues with large polygons&lt;/item&gt;
      &lt;item&gt;RSP display lists are compiled just-in-time into a custom display list format that is more compact and faster to process&lt;/item&gt;
      &lt;item&gt;Display list preprocessor that removes commands we won't use and optimizes meshes (TODO: make it fix more things)&lt;/item&gt;
      &lt;item&gt;Mario's animations are compressed (from 580632 to 190324 bytes) and placed in a corner of VRAM rather than being loaded from storage (we don't have the luxury of a fast cartridge to read from in the middle of a frame)&lt;/item&gt;
      &lt;item&gt;Custom profiler&lt;/item&gt;
      &lt;item&gt;Custom texture encoder that quantizes all textures to 4 bits per pixel&lt;/item&gt;
      &lt;item&gt;Translucent circle-texture shadows replaced with subtractive hexagonal shadows, as the PSX doesn't support arbitrary translucency&lt;/item&gt;
      &lt;item&gt;(TODO) Camera system adapted to rotate with the right analog stick&lt;/item&gt;
      &lt;item&gt;(TODO) Simplified rewritten Goddard subsystem&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Floating trees (temporary issue due caused by a math rewrite)&lt;/item&gt;
      &lt;item&gt;Some of Mario's animations do not play, and may even crash the game&lt;/item&gt;
      &lt;item&gt;Music cannot be generated at build time without manually obtaining the tracks&lt;/item&gt;
      &lt;item&gt;Sound effects work but sometimes sound odd or are missing notes&lt;/item&gt;
      &lt;item&gt;The camera cannot be controlled in many levels due to the unfinished camera control implementation&lt;/item&gt;
      &lt;item&gt;Crashes when entering certain levels (due to insufficient memory?)&lt;/item&gt;
      &lt;item&gt;Ending sequence crashes on load&lt;/item&gt;
      &lt;item&gt;When reaching the bridge in the castle grounds, Mario looks up but Lakitu never comes over&lt;/item&gt;
      &lt;item&gt;Poles do not go down when pounded&lt;/item&gt;
      &lt;item&gt;Textures are loaded individually, causing long stutters and loading times&lt;/item&gt;
      &lt;item&gt;Stretched textures due to PSX limitations (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Tessellation is not good enough to fix all large polygons (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Some textures are rendered incorrectly (RSP JIT issues?)&lt;/item&gt;
      &lt;item&gt;Title screen is unfinished&lt;/item&gt;
      &lt;item&gt;Pause menu doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build and install the mipsel-none-elf-gcc toolchain. For Arch users, it is available on AUR. (You can also install it on your system from https://github.com/malucard/poeng by running &lt;code&gt;make install-gcc&lt;/code&gt;from there. This may take a long time.)&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-port&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-port&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version without music, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install and update MSYS2, following all the directions listed on https://www.msys2.org/.&lt;/item&gt;
      &lt;item&gt;From the start menu, launch MSYS2 MinGW and install required packages depending on your machine (do NOT launch "MSYS2 MSYS"):&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;64-bit: Launch "MSYS2 MinGW 64-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-x86_64-gcc mingw-w64-x86_64-meson mingw-w64-x86_64-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;32-bit (will also work on 64-bit machines): Launch "MSYS2 MinGW 32-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-i686-gcc mingw-w64-i686-meson mingw-w64-i686-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Do NOT by mistake install the packages called simply &lt;code&gt;gcc&lt;/code&gt;and&lt;code&gt;meson&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install the mipsel-none-elf-gcc toolchain.&lt;/item&gt;
      &lt;item&gt;The MSYS2 terminal has a current working directory that initially is &lt;code&gt;C:\msys64\home\&amp;lt;username&amp;gt;&lt;/code&gt;(home directory). At the prompt, you will see the current working directory in yellow.&lt;code&gt;~&lt;/code&gt;is an alias for the home directory. You can change the current working directory to&lt;code&gt;My Documents&lt;/code&gt;by entering&lt;code&gt;cd /c/Users/&amp;lt;username&amp;gt;/Documents&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-psx&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-psx&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you get &lt;code&gt;make: gcc: no suitable C and C++ compiler found&lt;/code&gt;,&lt;code&gt;make: gcc: command not found&lt;/code&gt;,&lt;code&gt;make: gcc: No such file or directory&lt;/code&gt;although the packages did successfully install, you probably launched the wrong MSYS2. Read the instructions again. The terminal prompt should contain "MINGW32" or "MINGW64" in purple text, and NOT "MSYS".&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;Failed to open baserom.us.z64!&lt;/code&gt;you failed to place the baserom in the repository. You can write&lt;code&gt;ls&lt;/code&gt;to list the files in the current working directory. If you are in the&lt;code&gt;sm64-psx&lt;/code&gt;directory, make sure you see it here.&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;make: *** No targets specified and no makefile found. Stop.&lt;/code&gt;, you are not in the correct directory. Make sure the yellow text in the terminal ends with&lt;code&gt;sm64-psx&lt;/code&gt;. Use&lt;code&gt;cd &amp;lt;dir&amp;gt;&lt;/code&gt;to enter the correct directory. If you write&lt;code&gt;ls&lt;/code&gt;you should see all the project files, including&lt;code&gt;Makefile&lt;/code&gt;if everything is correct.&lt;/item&gt;
      &lt;item&gt;If you get any error, be sure MSYS2 packages are up to date by executing &lt;code&gt;pacman -Syu&lt;/code&gt;and&lt;code&gt;pacman -Su&lt;/code&gt;. If the MSYS2 window closes immediately after opening it, restart your computer.&lt;/item&gt;
      &lt;item&gt;Check if mipsel gcc is working by executing &lt;code&gt;mipsel-none-elf-gcc -v&lt;/code&gt;. If it doesn't work, you either opened the wrong MSYS start menu entry or installed the incorrect gcc package.&lt;/item&gt;
      &lt;item&gt;When switching between building on other platforms, run &lt;code&gt;make -C tools clean&lt;/code&gt;first to allow for the tools to recompile on the new platform. This also helps when switching between shells like WSL and MSYS2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sm64
├── actors: object behaviors, geo layout, and display lists
├── assets: animation and demo data
│   ├── anims: animation data
│   └── demos: demo data
├── bin: C files for ordering display lists and textures
├── build: output directory
├── data: behavior scripts, misc. data
├── doxygen: documentation infrastructure
├── enhancements: example source modifications
├── include: header files
├── levels: level scripts, geo layout, and display lists
├── lib: N64 SDK code
├── sound: sequences, sound samples, and sound banks
├── src: C source code for game
│   ├── audio: audio code
│   ├── buffers: stacks, heaps, and task buffers
│   ├── engine: script processing engines and utils
│   ├── game: behaviors and rest of game source
│   ├── goddard: rewritten Mario intro screen
│   ├── goddard_og: backup of original Mario intro screen
│   ├── menu: title screen and file, act, and debug level selection menus
│   └── port: port code, audio and video renderer
├── text: dialog, level names, act names
├── textures: skybox and generic texture data
└── tools: build tools
&lt;/code&gt;
    &lt;p&gt;Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46221925</guid><pubDate>Wed, 10 Dec 2025 18:58:55 +0000</pubDate></item><item><title>I got an Nvidia GH200 server for €7.5k on Reddit and converted it to a desktop</title><link>https://dnhkng.github.io/posts/hopper/</link><description>&lt;doc fingerprint="3c0438474de245e4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building a High-End AI Desktop&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Running large language models locally has always been a game of compromise. You either spend \$10,000+ on consumer GPUs that can barely handle 70 B parameter models, or you dream about enterprise hardware you’ll never afford. The Grace-Hopper platform—Nvidia’s unified CPU-GPU superchip architecture—represents the kind of dream-rig AI infrastructure LocalLlama drools over, with systems typically costing well over \$100,000 and exclusively available to data centers and research institutions.&lt;/p&gt;
    &lt;p&gt;So when I stumbled across a Grace-Hopper system being sold for 10K euro on Reddit, my first thought was “obviously fake.” My second thought was “I wonder if he’ll take 7.5K euro?”.&lt;/p&gt;
    &lt;p&gt;This is the story of how I bought enterprise-grade AI hardware designed for liquid-cooled server racks, converted it to air cooling, survived multiple near-disasters (including GPUs reporting temperatures of 16 million degrees), and ended up with a desktop that can run 235B parameter models at home. It’s a tale of questionable decisions, creative problem-solving, and what happens when you try to turn datacenter equipment into a daily driver.&lt;/p&gt;
    &lt;p&gt;If you’ve ever wondered what it takes to run truly large models locally, or if you’re just here to watch someone disassemble $80,000 worth of hardware with nothing but hope and isopropanol, you’re in the right place.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Deal&lt;/head&gt;
    &lt;p&gt;Early this year, while browsing r/LocalLLaMA/new, I came across a ridiculously good deal. How good? These were the specs for the server offered for 10K euro, and a serious upgrade to my 4x RTX 4090 rig:&lt;/p&gt;
    &lt;head rend="h3"&gt;Specs:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2x Nvidia Grace-Hopper Superchip&lt;/item&gt;
      &lt;item&gt;2x 72-core Nvidia Grace CPU&lt;/item&gt;
      &lt;item&gt;2x Nvidia Hopper H100 Tensor Core GPU&lt;/item&gt;
      &lt;item&gt;2x 480GB of LPDDR5X memory with error-correction code (ECC)&lt;/item&gt;
      &lt;item&gt;2x 96GB of HBM3 memory&lt;/item&gt;
      &lt;item&gt;1152GB of total fast-access memory&lt;/item&gt;
      &lt;item&gt;NVLink-C2C: 900 GB/s of bandwidth&lt;/item&gt;
      &lt;item&gt;Programmable from 1000W to 2000W TDP (CPU + GPU + memory)&lt;/item&gt;
      &lt;item&gt;1x High-efficiency 3000W PSU 230V to 48V&lt;/item&gt;
      &lt;item&gt;2x PCIe Gen4 M.2 22110/2280 slots on board&lt;/item&gt;
      &lt;item&gt;4x FHFL PCIe Gen5 x16&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;UPDATE:Since I bought this, DDR5 RAM prices have become insane. 960GB of fast DDR5 now costs more than what I paid for the whole Grace-Hopper system 🤯&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Obviously fake I thought, because&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;H100s cost about 30-40,000 euro each, and this system has two of them&lt;/item&gt;
      &lt;item&gt;Grace-Hopper NVL2 systems are basically not for sale for consumers anyway!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Reddit thread explained the reason the system was being sold cheap:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The main reason why is that it is a Frankensystem converted from liquid-cooled to aircooled. Also it is not very pretty and not rackable, because it has a 48V power supply attached. It is originally directly from Nvidia.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I immediately offered to buy it, because why not? If it was a scam, I could always back out, but I wanted to be first in line!&lt;/p&gt;
    &lt;p&gt;It turns out I live near the seller, and he runs an online shop that sells modified Nvidia server equipment as desktops. It still seemed pretty risky, so I did some research and found a video review of one of his Desktops on Youtube. With the deal now seeming at least plausible, and the seller only a two-hour drive away and agreeing to take cash, it was time to take a Bavarian road trip.&lt;/p&gt;
    &lt;p&gt;I arrived at a farmhouse in a small forest, and met Bernhard the proprietor of GPTshop.ai. He showed me a nice workshop (plasma cutters, an electronics lab, etc.) from which he fabricates custom cases for the high-end H100 desktops he builds. These desktops seem pretty damn nice, so it’s unfortunate that his webshop gives off shady vibes; the business registration in the Cayman Islands definitely doesn’t help. What I can say though is that this item was heavily discounted, and not what he usually sells.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: I have zero affiliation with GPTshop.ai beyond handing them a stack of cash and receiving a dust-covered server in return. If this were a sponsored post, they probably wouldn’t let me mention the 16 million degree GPU temperatures or the part where I had to free-solder components while praying to the electronics gods.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Disassembling the Grace Hopper server&lt;/head&gt;
    &lt;p&gt;The server itself was not in great condition. These things run extremely loud and high-throughput fans, and these had sucked in a lot of dust, coating the mainboard so heavily I couldn’t tell the color of the PCB. However, it booted up and ran OK, so I handed over a wad of cash, strapped it into the backseat of my car with the seatbelt (it weighed ~20 kg), and drove it home.&lt;/p&gt;
    &lt;p&gt;Did I mention it’s loud? Firing up the system is physically painful. There are 8x Sunon dual-fan modules, and each is as loud as a powerful vacuum cleaner, but with a much higher and more annoying pitch. With all 8 running at full power, hearing protection is necessary - I could hear the system running in my basement with the windows closed from 50 meters away! My wife immediately (and quite fairly), banned its use at home. We both work home-office and it was simply too loud for online meetings. But I had other plans anyway…&lt;/p&gt;
    &lt;p&gt;First things first, I of course quickly decided and then proceeded to strip down the server, after first photo-documenting the various connectors between the various PCBs, modules and mainboard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cleaning the Server&lt;/head&gt;
    &lt;p&gt;The majority of the dust was vacuumed off during disassembly, but there was clearly a lot more under the Grace-Hopper modules. After removing those as well, I decided to go with a full washdown of the mainboard.&lt;/p&gt;
    &lt;p&gt;I purchased a few litres of Isopropanol, and with a soft brush I went over the whole board a few times to get the remaining fine dust from inside connectors and between SMD-component pins.&lt;/p&gt;
    &lt;p&gt;I suspected there might also be dust inside the Grace-Hopper modules, but actually, I really just wanted to pop them open to poke around.&lt;/p&gt;
    &lt;p&gt;The mainboard went on my heated floor to dry for a week, while I moved on to replacing the cooling system.&lt;/p&gt;
    &lt;head rend="h2"&gt;A new Water Cooling system&lt;/head&gt;
    &lt;p&gt;I had looked into building a custom water-cooling block, but I was worried about leaks, when I found cheap all-in-one water cooling systems for ~40 euro each on sale. Two per GH200 module would be sufficient, so I carefully measured the dimensions of the GPU die and CPU, as well as screw locations, and threw those into Fusion 360 to model up an adapter block.&lt;/p&gt;
    &lt;p&gt;I have a Bambu X1, which came in very handy for prototyping the adapter blocks. The tolerances have to be very tight, so I printed several cut-away versions to make sure there was solid contact to the bare GPU die, and a safe margin from contact to fragile parts.&lt;/p&gt;
    &lt;p&gt;The parts were then sent for CNC milling, and were delivered as the mainboard was finished drying. After using yet more isopropanol to clean off the machining oil, they were mounted without much fuss.&lt;/p&gt;
    &lt;head rend="h2"&gt;Assembling the Desktop&lt;/head&gt;
    &lt;p&gt;My go-to material for this kind of project is ProfilAlu from eBay. It’s cheap, stiff, and delivered pre-cut for assembly. I put together a design in Fusion 360, and had the parts in a few days. The various mounts however were much more work. I needed to design a few dozen custom mounts for the various PCBs and air-filter fixings; this used up a few kilos of filament to get things just right.&lt;/p&gt;
    &lt;head rend="h2"&gt;Disaster(s)&lt;/head&gt;
    &lt;head rend="h3"&gt;Critical Fan Errors&lt;/head&gt;
    &lt;p&gt;The system didn’t start to boot anymore. Checking the logs, I saw 16 critical errors, one for each fan in the 8 pairs:&lt;/p&gt;
    &lt;quote&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_5_F&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_6_R&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_8_F&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_5_R&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_7_F&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;08/06/25&lt;/td&gt;
      &lt;td&gt;19:24:08 CEST&lt;/td&gt;
      &lt;td&gt;Fan FAN_8_R&lt;/td&gt;
      &lt;td&gt;Lower Critical going low&lt;/td&gt;
      &lt;td&gt;Asserted&lt;/td&gt;
      &lt;td&gt;Reading 0 &amp;lt; Threshold 2156 RPM…&lt;/td&gt;
    &lt;/quote&gt;
    &lt;p&gt;With the fans removed, the BMC (Baseboard Management Controller) immediately panicked, and shut down the mainboard to prevent thermal damage, even with the water coolers in place. So, I disabled the fan-check subsystem.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;# stops the service for the current session systemctl stop phosphor-sensor-monitor.service # prevents the service from starting on the next boot systemctl disable phosphor-sensor-monitor.service &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Who needs hardware monitoring? ¯\_(ツ)_/¯&lt;/p&gt;
    &lt;head rend="h3"&gt;Nuclear Fusion?&lt;/head&gt;
    &lt;p&gt;Great! I could start the boot process, and even reach login! But only about 1 time in 4… Not optimal. And even logged in, the server would crash within 2 minutes.&lt;/p&gt;
    &lt;p&gt;Looking into the BMC logs, I saw:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;shutdown_ok_mon[1478]&lt;/cell&gt;
        &lt;cell&gt;event: FALLING EDGE offset: 26 timestamp: [571.615238550]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;power-status[1493]&lt;/cell&gt;
        &lt;cell&gt;event: FALLING EDGE offset: 18 timestamp: [571.632491062]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;shutdown_ok_mon[545]&lt;/cell&gt;
        &lt;cell&gt;SHDN_OK_L-I = 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;shutdown_ok_mon[545]&lt;/cell&gt;
        &lt;cell&gt;Asserting SYS_RST_IN_L-O to hold host in reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;shutdown_ok_mon[545]&lt;/cell&gt;
        &lt;cell&gt;gpioset SYS_RST_IN_L-O = 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;power-status[697]&lt;/cell&gt;
        &lt;cell&gt;gpioset SYS_RST_IN_L-O = 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Sep 23 08:20:18&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;power-status[697]&lt;/cell&gt;
        &lt;cell&gt;Set SYS_RST_IN_L-O=0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So, a Critical Failure at 08:20:18:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SHDN_OK_L-I signal goes low (falling edge detected)&lt;/item&gt;
      &lt;item&gt;This immediately triggers a shutdown sequence&lt;/item&gt;
      &lt;item&gt;System powers off within ~30 seconds of successful boot&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But why?!!? I had shut down the hardware monitoring.&lt;/p&gt;
    &lt;p&gt;Diving deeper into the logs:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;ipmid[520]&lt;/cell&gt;
        &lt;cell&gt;thresholdChanged: Assert&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;ipmid[520]&lt;/cell&gt;
        &lt;cell&gt;thresholdChanged: Assert&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;ipmid[520]&lt;/cell&gt;
        &lt;cell&gt;thresholdChanged: Assert&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;satellitesensor[2351]&lt;/cell&gt;
        &lt;cell&gt;Sensor HGX_GPU_1_TEMP_1 high threshold 92 assert: value 1.67772e+07 raw data nan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;satellitesensor[2351]&lt;/cell&gt;
        &lt;cell&gt;Sensor HGX_GPU_1_TEMP_1 high threshold 89 assert: value 1.67772e+07 raw data nan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;satellitesensor[2351]&lt;/cell&gt;
        &lt;cell&gt;Sensor HGX_GPU_1_TEMP_1 high threshold 87 assert: value 1.67772e+07 raw data nan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;phosphor-fru-fault-monitor[524]&lt;/cell&gt;
        &lt;cell&gt;/xyz/openbmc_project/logging/entry/496 created&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;phosphor-fru-fault-monitor[524]&lt;/cell&gt;
        &lt;cell&gt;/xyz/openbmc_project/logging/entry/497 created&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Oct 05 10:15:00&lt;/cell&gt;
        &lt;cell&gt;oberon-bmc&lt;/cell&gt;
        &lt;cell&gt;sensor-monitor[499]&lt;/cell&gt;
        &lt;cell&gt;Starting 1000ms HardShutdownAlarmHigh shutdown timer due to sensor /xyz/openbmc_project/sensors/temperature/HGX_GPU_0_TEMP_1 value 16777214&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Warning: Your GPU should not reach 16,777,214 Celsius during boot. Imagine what would happen under load!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This took some time to debug, as I was quite sure the sensors could not physically handle reading temperatures over 16 million Celsius… But then I noticed something interesting about that specific number:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Decimal&lt;/cell&gt;
        &lt;cell role="head"&gt;Binary&lt;/cell&gt;
        &lt;cell role="head"&gt;Hex&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;16,777,214&lt;/cell&gt;
        &lt;cell&gt;1111 1111 1111 1111 1111 1110&lt;/cell&gt;
        &lt;cell&gt;0xFFFFFE&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is &lt;code&gt;2²⁴ - 2&lt;/code&gt;, which is suspiciously close to the maximum value of a 24-bit unsigned integer. In the hardware world, this is the equivalent of a sensor throwing up its hands and screaming “I have no idea what’s happening!” When hardware can’t read a value properly—whether due to a loose connection, damaged circuit, or initialization failure—it often returns the maximum (or near-maximum) representable value. It’s like the digital version of a shrug.&lt;/p&gt;
    &lt;p&gt;The logs confirmed this theory: seeing &lt;code&gt;1.67772e+07&lt;/code&gt; (16,777,214) wasn’t evidence that my GPU had achieved nuclear fusion temperatures 🔥—it was evidence that the temperature sensor had simply stopped working. And if a sensor error is intermittent, the most likely culprit is a loose connection or physical damage.&lt;/p&gt;
    &lt;p&gt;After spending way too long pursuing software solutions (because who wants to disassemble everything again?), I finally accepted the inevitable and broke out the screwdrivers.&lt;/p&gt;
    &lt;p&gt;I happened to have bought a new microscope earlier this year, and it turned out to be the perfect tool for diagnosing and fixing the issue. Near one of the modules, I found some damaged surface mount components. The damage must have happened after cleaning, probably during the reassembly of the modules with the copper adapters. They weigh over 2 kg, so a slight bump would have easily caused this damage. Amazingly, the tiny components were still attached to the traces, and so I could measure them easily: a 100 nF capacitor, and 4.7k resistor (both of which I had on-hand, as they are standard values for decoupling circuits). The bad news? I had huge “0805” sized parts (2mm long), these were tiny “0402” (1mm long). And one of the traces was just gone.&lt;/p&gt;
    &lt;p&gt;With some very fiddly soldering, and scratching off the solder mask on the PCB to expose more trace, I was able to ‘free solder’ the parts into a wonderful 3D sculpture which was then liberally coated in UV-curing mask resin, set, and then held in place with sticky tape. Very professional. After reassembly, the system booted smoothly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Touches&lt;/head&gt;
    &lt;p&gt;I 3D printed a few extra parts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mounts for the E1.S 8TB SSD I found cheap online&lt;/item&gt;
      &lt;item&gt;A full rear-panel, that mounts the 3KW 48V power supply&lt;/item&gt;
      &lt;item&gt;Cool-looking mesh to protect the water-cooling radiators and dust filters&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Getting the actual GPU working was also painful, so I’ll leave the details here for future adventurers:&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;# Data Center/HGX-Series/HGX H100/Linux aarch64/12.8 seem to work! wget https://us.download.nvidia.com/tesla/570.195.03/NVIDIA-Linux-aarch64-570.195.03.run # Tell the driver to completely ignore the NVLINK and it should allow the GPUs to initialise independently over PCIe !!!! This took a week of work to find, thanks Reddit! # create a modprobe config file: sudo nano /etc/modprobe.d/nvidia-disable-nvlink.conf # add the driver option options nvidia NVreg_NvLinkDisable=1 # update the boot files: sudo update-initramfs -u # reboot sudo reboot &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;That’s what you’re here for, maybe? I have only just started, but after compiling the latest Llama.cpp version using 144 cores in 90 seconds, here’s some benchmarks on larger LLMs:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Prompt Processing&lt;/cell&gt;
        &lt;cell role="head"&gt;Token Generation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;gpt-oss-120b-Q4_K_M&lt;/cell&gt;
        &lt;cell&gt;2974.79&lt;/cell&gt;
        &lt;cell&gt;195.84&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GLM-4.5-Air-Q4_K_M&lt;/cell&gt;
        &lt;cell&gt;1936.65&lt;/cell&gt;
        &lt;cell&gt;100.71&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Qwen3-235B-A22B-Instruct-2507-Q4_K&lt;/cell&gt;
        &lt;cell&gt;1022.79&lt;/cell&gt;
        &lt;cell&gt;65.90&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is pretty unoptimized, but it’s looking promising so far! During the LLM tests I hit around 300W per GPU, far from the 900W max.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cost Breakdown&lt;/head&gt;
    &lt;p&gt;Here’s what the entire build actually cost me, from the initial purchase to the final touches:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost (EUR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Grace-Hopper Server&lt;/cell&gt;
        &lt;cell&gt;2x GH200 superchips with H100 GPUs (the Frankenstein special)&lt;/cell&gt;
        &lt;cell&gt;€7,500&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;‘like-new’ used 8TB E1.S NVMe SSD&lt;/cell&gt;
        &lt;cell&gt;€250&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Custom Water Cooling Adapters&lt;/cell&gt;
        &lt;cell&gt;2x CNC-milled copper mounting plates for AIO coolers&lt;/cell&gt;
        &lt;cell&gt;€700&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;AIO Water Coolers&lt;/cell&gt;
        &lt;cell&gt;4x Arctic Liquid Freezer III 420 (B-Ware)&lt;/cell&gt;
        &lt;cell&gt;€180&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Structural Frame&lt;/cell&gt;
        &lt;cell&gt;Extruded aluminum profiles, pre-cut and delivered&lt;/cell&gt;
        &lt;cell&gt;€200&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3D Printing Filament&lt;/cell&gt;
        &lt;cell&gt;1kg black PLA for custom mounts and brackets&lt;/cell&gt;
        &lt;cell&gt;€20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hardware&lt;/cell&gt;
        &lt;cell&gt;Nuts, bolts, and mounting hardware&lt;/cell&gt;
        &lt;cell&gt;€50&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cleaning Supplies&lt;/cell&gt;
        &lt;cell&gt;5 liters of 99.9% isopropanol (used liberally throughout)&lt;/cell&gt;
        &lt;cell&gt;€20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Aesthetics&lt;/cell&gt;
        &lt;cell&gt;LED lighting strip (because RGB makes it faster)&lt;/cell&gt;
        &lt;cell&gt;€10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;€8,930&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Not included: hearing protection (absolutely necessary), the microscope I already owned (but proved essential), several failed 3D prints, and the emotional cost of seeing “16,777,214°C” in system logs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;So, was it worth it? I now have a desktop that can run 235B parameter models at home for less than the cost of a single H100. It required disassembling $80,000 worth of enterprise hardware, debugging sensors that reported temperatures approaching the surface of the sun, and free-soldering components under a microscope. Your mileage may vary. Literally: I had to drive two hours to pick this thing up.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46222237</guid><pubDate>Wed, 10 Dec 2025 19:19:17 +0000</pubDate></item><item><title>Getting a Gemini API key is an exercise in frustration</title><link>https://ankursethi.com/blog/gemini-api-key-frustration/</link><description>&lt;doc fingerprint="3956b1cd9b3799d1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Getting a Gemini API key is an exercise in frustration&lt;/head&gt;
    &lt;p&gt;Last week, I started working on a new side-project. It’s a standard React app partly made up of run-of-the-mill CRUD views—a perfect fit for LLM-assisted programming. I reasoned that if I could get an LLM to quickly write the boring code for me, I’d have more time to focus on the interesting problems I wanted to solve.&lt;/p&gt;
    &lt;p&gt;I’ve pretty much settled on Claude Code as my coding assistant of choice, but I’d been hearing great things about Google’s Gemini 3 Pro. Despite my aversion to Google products, I decided to try it out on my new codebase.&lt;/p&gt;
    &lt;p&gt;I already had Gemini CLI installed, but that only gave me access to Gemini 2.5 with rate limits. I wanted to try out Gemini 3 Pro, and I wanted to avoid being rate limited. I had some spare cash to burn on this experiment, so I went looking for ways to pay for a Gemini Pro plan, if such a thing existed.&lt;/p&gt;
    &lt;p&gt;Thus began my grand adventure in trying to give Google my money.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a Gemini, really?&lt;/head&gt;
    &lt;p&gt;The name “Gemini” is so overloaded that it barely means anything. Based on the context, Gemini could refer to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The chatbot available at gemini.google.com.&lt;/item&gt;
      &lt;item&gt;The mobile app that lets you use the same Gemini chatbot on your iPhone or Android.&lt;/item&gt;
      &lt;item&gt;The voice assistant on Android phones.&lt;/item&gt;
      &lt;item&gt;The AI features built into Google Workspace, Firebase, Colab, BigQuery, and other Google products.&lt;/item&gt;
      &lt;item&gt;Gemini CLI, an agentic coding tool for your terminal that works the same way as Claude Code or OpenAI Codex.&lt;/item&gt;
      &lt;item&gt;The Gemini Code Assist suite of products, which includes extensions for various IDEs, a GitHub app, and Gemini CLI.&lt;/item&gt;
      &lt;item&gt;The underlying LLM powering all these products.&lt;/item&gt;
      &lt;item&gt;Probably three more products by the time I finish writing this blog post.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To make things even more confusing, Google has at least three different products just for agentic coding: Gemini Code Assist (Gemini CLI is a part of this suite of products), Jules, and Antigravity.&lt;/p&gt;
    &lt;p&gt;And then there’s a bunch of other GenAI stuff that is powered by Gemini but doesn’t have the word Gemini in the name: Vertex AI Platform, Google AI Studio, NotebookLM, and who knows what else.&lt;/p&gt;
    &lt;p&gt;I just wanted to plug my credit card information into a form and get access to a coding assistant. Instead, I was dunked into an alphabet soup of products that all seemed to do similar things and, crucially, didn’t have any giant “Buy Now!” buttons for me to click.&lt;/p&gt;
    &lt;p&gt;In contrast, both Anthropic and OpenAI have two primary ways you can access their products: via their consumer offerings at claude.ai and chatgpt.com respectively, or via API credits that you can buy through their respective developer consoles. In each case, there is a form field where you can plug in your credit card details, and a big, friendly “Buy Now!” button to click.&lt;/p&gt;
    &lt;p&gt;After half an hour of searching the web, I did the obvious thing and asked the free version of Gemini (the chatbot, not one of those other Geminis) what to do:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;How do I pay for the pro version of Gemini so i can use it in the terminal for writing code? I specifically want to use the Gemini 3 Pro model.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It thought for a suspiciously long time and told me that Gemini 3 Pro required a developer API key to use. Since the new model is still in preview, it’s not yet available on any of the consumer plans. When I asked follow up questions about pricing, it told me that “Something went wrong”. Which translates to: we broke something, but we won’t tell you how to fix it.&lt;/p&gt;
    &lt;p&gt;So I asked Claude for help. Between the two LLMs, I was able to figure out how to create an API key for the Gemini I wanted.&lt;/p&gt;
    &lt;head rend="h2"&gt;Creating an API key is easy&lt;/head&gt;
    &lt;p&gt;Google AI Studio is supposed to be the all-in-one dashboard for Google’s generative AI models. This is where you can experiment with model parameters, manage API keys, view logs, and manage billing for your projects.&lt;/p&gt;
    &lt;p&gt;I logged into Google AI Studio and created a new API key. This part was pretty straightforward: I followed the on-screen instructions and had a fresh new key housed under a project in a few seconds. I then verified that my key was working with Gemini CLI.&lt;/p&gt;
    &lt;p&gt;It worked! Now all that was left to do was to purchase some API credits. Back in Google AI Studio, I saw a link titled “Set up billing” next to my key. It looked promising, so I clicked it.&lt;/p&gt;
    &lt;p&gt;That’s where the fun really began.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google doesn’t want my money&lt;/head&gt;
    &lt;p&gt;The “Set up billing” link kicked me out of Google AI Studio and into Google Cloud Console, and my heart sank. Every time I’ve logged into Google Cloud Console or AWS, I’ve wasted hours upon hours reading outdated documentation, gazing in despair at graphs that make no sense, going around in circles from dashboard to dashboard, and feeling a strong desire to attain freedom from this mortal coil.&lt;/p&gt;
    &lt;p&gt;Turns out I can’t just put $100 into my Gemini account. Instead, I must first create a Billing Account. After I’ve done that, I must associate it with a project. Then I’m allowed to add a payment method to the Billing Account. And then, if I’m lucky, my API key will turn into a paid API key with Gemini Pro privileges.&lt;/p&gt;
    &lt;p&gt;So I did the thing. The whole song and dance. Including the mandatory two-factor OTP verification that every Indian credit card requires. At the end of the process, I was greeted with a popup telling me I had to verify my payment method before I’d be allowed to use it.&lt;/p&gt;
    &lt;p&gt;Wait. Didn’t I just verify my payment method? When I entered the OTP from my bank?&lt;/p&gt;
    &lt;p&gt;Nope, turns out Google hungers for more data. Who’d have thunk it?&lt;/p&gt;
    &lt;p&gt;To verify my payment method for reals, I had to send Google a picture of my government-issued ID and the credit card I’d just associated with my Billing Account. I had to ensure all the numbers on my credit card were redacted by manually placing black bars on top of them in an image editor, leaving only my name and the last four digits of the credit card number visible.&lt;/p&gt;
    &lt;p&gt;This felt unnecessarily intrusive. But by this point, I was too deep in the process to quit. I was invested. I needed my Gemini 3 Pro, and I was willing to pay any price.&lt;/p&gt;
    &lt;p&gt;The upload form for the government ID rejected my upload twice before it finally accepted it. It was the same exact ID every single time, just in different file formats. It wanted a PNG file. Not a JPG file, nor a PDF file, but a PNG file. Did the upload form mention that in the instructions? Of course not.&lt;/p&gt;
    &lt;p&gt;After jumping through all these hoops, I received an email from Google telling me that my verification will be completed in a few days.&lt;/p&gt;
    &lt;p&gt;A few days? Nothing to do but wait, I suppose.&lt;/p&gt;
    &lt;head rend="h2"&gt;403 Forbidden&lt;/head&gt;
    &lt;p&gt;At this point, I closed all my open Cloud Console tabs and went back to work. But when I was fifteen minutes into writing some code by hand like a Neanderthal, I received a second email from Google telling me that my verification was complete.&lt;/p&gt;
    &lt;p&gt;So for the tenth time that day, I navigated to AI Studio. For the tenth time I clicked “Set up billing” on the page listing my API keys. For the tenth time I was told that my project wasn’t associated with a billing account. For the tenth time I associated the project with my new billing account. And finally, after doing all of this, the “Quota tier” column on the page listing my API keys said “Tier 1” instead of “Set up billing”.&lt;/p&gt;
    &lt;p&gt;Wait, Tier 1? Did that mean there were other tiers? What were tiers, anyway? Was I already on the best tier? Or maybe I was on the worst one? Not important. The important part was that I had my API key and I’d managed to convince Google to charge me for it.&lt;/p&gt;
    &lt;p&gt;I went back to the Gemini CLI, ran the &lt;code&gt;/settings&lt;/code&gt; command, and turned on the “Enable experimental features” option. I ran the &lt;code&gt;/models&lt;/code&gt; command, which told me that Gemini 3 Pro was now available.&lt;/p&gt;
    &lt;p&gt;Success? Not yet.&lt;/p&gt;
    &lt;p&gt;When I tried sending a message to the LLM, it failed with this 403 error:&lt;/p&gt;
    &lt;code&gt;{
  "error": {
    "message": "{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"The caller does not have permission\",\n    \"status\":\"PERMISSION_DENIED\"\n  }\n}\n",
    "code": 403,
    "status": "Forbidden"
  }
}&lt;/code&gt;
    &lt;p&gt;Is that JSON inside a string inside JSON? Yes. Yes it is.&lt;/p&gt;
    &lt;p&gt;To figure out if my key was even working, I tried calling the Gemini API from JavaScript, reproducing the basic example from Google’s own documentation.&lt;/p&gt;
    &lt;p&gt;No dice. I ran into the exact same error.&lt;/p&gt;
    &lt;p&gt;I then tried talking to Gemini 3 Pro using the Playground inside Google AI Studio. It showed me a toast message saying &lt;code&gt;Failed to generate content. Please try again.&lt;/code&gt; The chat transcript said &lt;code&gt;An internal error has occurred.&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;At this point I gave up and walked away from my computer. It was already 8pm. I’d been trying to get things to work since 5pm. I needed to eat dinner, play Clair Obscur, and go to bed. I had no more time to waste and no more fucks to give.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your account is in good standing at this time&lt;/head&gt;
    &lt;p&gt;Just as I was getting into bed, I received an email from Google with this subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your Google Cloud and APIs billing account XXXXXX-XXXXXX-XXXXXX is in good standing at this time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;With the message inside saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Based on the information you provided and further analysis by Google, we have reinstated your billing account XXXXXX-XXXXXX-XXXXXX. Your account is in good standing, and you should now have full access to your account and related Project(s) and Service(s).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I have no idea what any of this means, but Gemini 3 Pro started working correctly after I received this email. It worked in the Playground, directly by calling the API from JavaScript, and with Gemini CLI.&lt;/p&gt;
    &lt;p&gt;Problem solved, I guess. Until Google mysteriously decides that my account is no longer in good standing.&lt;/p&gt;
    &lt;head rend="h2"&gt;This was a waste of time&lt;/head&gt;
    &lt;p&gt;This was such a frustrating experience that I still haven’t tried using Gemini with my new codebase, nearly a week after I made all those sacrifices to the Gods of Billing Account.&lt;/p&gt;
    &lt;p&gt;I understand why the process for getting a Gemini API key is so convoluted. It’s designed for large organizations, not an individual developers trying to get work done; it serves the bureaucracy, not the people doing the work; it’s designed for maximum compliance with government regulations, not for efficiency or productivity.&lt;/p&gt;
    &lt;p&gt;Google doesn’t want my money unless I’m an organization that employs ten thousand people.&lt;/p&gt;
    &lt;p&gt;In contrast to Google, Anthropic and OpenAI are much smaller and much more nimble. They’re able to make the process of setting up a developer account quick and easy for those of us who just want to get things done. Unlike Google, they haven’t yet become complacent. They need to compete for developer mindshare if they are to survive a decade into the future. Maybe they’ll add the same level of bureaucracy to their processes as they become larger, but for now they’re fairly easy to deal with.&lt;/p&gt;
    &lt;p&gt;I’m still going to try using Gemini 3 Pro with Gemini CLI as my coding assistant, but I’ll probably cap the experiment to a month. Unless Gemini 3 Pro is a massive improvement over its competitors, I’ll stick to using tools built by organizations that want me as a customer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46223311</guid><pubDate>Wed, 10 Dec 2025 20:29:12 +0000</pubDate></item><item><title>EFF Launches Age Verification Hub as Resource Against Misguided Laws</title><link>https://www.eff.org/press/releases/eff-launches-age-verification-hub-resource-against-misguided-laws</link><description>&lt;doc fingerprint="358c117733a2b2d1"&gt;
  &lt;main&gt;
    &lt;p&gt;SAN FRANCISCO—With ill-advised and dangerous age verification laws proliferating across the United States and around the world, creating surveillance and censorship regimes that will be used to harm both youth and adults, the Electronic Frontier Foundation has launched a new resource hub that will sort through the mess and help people fight back.&lt;/p&gt;
    &lt;p&gt;To mark the hub's launch, EFF will host a Reddit AMA (“Ask Me Anything”) next week and a free livestreamed panel discussion on January 15 highlighting the dangers of these misguided laws.&lt;/p&gt;
    &lt;p&gt;“These restrictive mandates strike at the foundation of the free and open internet,” said EFF Activist Molly Buckley. “While they are wrapped in the legitimate concern about children's safety, they operate as tools of censorship, used to block people young and old from viewing or sharing information that the government deems ‘harmful’ or ‘offensive.’ They also create surveillance systems that critically undermine online privacy, and chill access to vital online communities and resources. Our new resource hub is a one-stop shop for information that people can use to fight back and redirect lawmakers to things that will actually help young people, like a comprehensive privacy law.”&lt;/p&gt;
    &lt;p&gt;Half of U.S. states have enacted some sort of online age verification law. At the federal level, a House Energy and Commerce subcommittee last week held a hearing on “Legislative Solutions to Protect Children and Teens Online.” While many of the 19 bills on that hearing’s agenda involve age verification, none would truly protect children and teens. Instead, they threaten to make it harder to access content that can be crucial, even lifesaving, for some kids.&lt;/p&gt;
    &lt;p&gt;It’s not just in the U.S. Effective this week, a new Australian law requires social media platforms to take reasonable steps to prevent Australians under the age of 16 from creating or keeping an account.&lt;/p&gt;
    &lt;p&gt;We all want young people to be safe online. However, age verification is not the panacea that regulators and corporations claim it to be; in fact, it could undermine the safety of many.&lt;/p&gt;
    &lt;p&gt;Age verification laws generally require online services to check, estimate, or verify all users’ ages—often through invasive tools like government ID checks, biometric scans, or other dubious “age estimation” methods—before granting them access to certain online content or services. These methods are often inaccurate and always privacy-invasive, demanding that users hand over sensitive and immutable personal information that links their offline identity to their online activity. Once that valuable data is collected, it can easily be leaked, hacked, or misused.&lt;/p&gt;
    &lt;p&gt;To truly protect everyone online, including children, EFF advocates for a comprehensive data privacy law.&lt;/p&gt;
    &lt;p&gt;EFF will host a Reddit AMA on r/privacy from Monday, Dec. 15 at 12 p.m. PT through Wednesday, Dec. 17 at 5 p.m. PT, with EFF attorneys, technologists, and activists answering questions about age verification on all three days.&lt;/p&gt;
    &lt;p&gt;EFF will host a free livestream panel discussion about age verification at 12 p.m. PDT on Thursday, Jan. 15. Panelists will include Cynthia Conti-Cook, Director of Research and Policy at the Collaborative Research Center for Resilience; a representative of Gen Z for Change; EFF Director of Engineering Alexis Hancock; and EFF Associate Director of State Affairs Rindala Alajaji. RSVP at https://www.eff.org/livestream-age.&lt;/p&gt;
    &lt;p&gt;For the age verification resource hub: https://www.eff.org/age&lt;/p&gt;
    &lt;p&gt;For the Reddit AMA: https://www.reddit.com/r/privacy/&lt;/p&gt;
    &lt;p&gt;For the Jan. 15 livestream: https://www.eff.org/livestream-age&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46223389</guid><pubDate>Wed, 10 Dec 2025 20:35:07 +0000</pubDate></item><item><title>Apple Services Experiencing Outage</title><link>https://www.apple.com/support/systemstatus/</link><description>&lt;doc fingerprint="50fedd95676c3945"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple Store Mac iPad iPhone Watch Vision AirPods TV &amp;amp; Home Entertainment Accessories Support 0 +&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46223577</guid><pubDate>Wed, 10 Dec 2025 20:47:15 +0000</pubDate></item><item><title>When would you ever want bubblesort?</title><link>https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/</link><description>&lt;doc fingerprint="727c103438e80f1f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When would you ever want bubblesort?&lt;/head&gt;
    &lt;p&gt;There are very few universal rules in software engineering, but there are are a lot of near-universal principles. Things like "prefer composition to inheritance" is near-universal. I love finding the rare situations where these principles don't hold, like where you do want inheritance over composition. A similar near-universal principle is "don't use bubblesort". Some would even say it's a universal rule, with Donald Knuth writing "bubble sort seems to have nothing to recommend it, except a catchy name and the fact that it leads to some interesting theoretical problems".1 But Knuth's been wrong before, so let's see if this universal rule is only near-universal.&lt;/p&gt;
    &lt;p&gt;Theoretically, bubblesort is faster than quick or mergesort for small arrays. This makes it useful as part of a larger sorting strategy: most of the fast-in-principle sorting algorithms work by recursively sorting subpartitions of an array, ie if you apply quicksort to 2^20 random integers, at some point you're sorting 2^17 8-integer subpartitions. Switching over to bubblesort for those subpartitions would be a nice optimization.&lt;/p&gt;
    &lt;p&gt;Many production sorting algorithms do use a hybrid approach, but they overwhelmingly use insertion sort instead. Insertion sort is very fast for small arrays and it's also better at using the hardware. On some very particular hardwares bubblesort stills ends up better, like in this NVIDIA study, but you probably don't have that hardware.&lt;/p&gt;
    &lt;p&gt;So that's one use-case, albeit one still dominated by a different algorithm. It's interesting that NVIDIA used it here because gamedev has a situation that's uniquely useful to bubblesort, based on two of its properties:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;While the algorithm is very slow overall, each individual step is very fast and easily suspendable.&lt;/item&gt;
      &lt;item&gt;Each swap leaves the array more ordered than it was before. Other sorts can move values away from their final positions in intermediate stages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes it really good when you want to do a fixed amount of sorting work per frame. Say you have a bunch of objects on a screen, where some objects can occlude others. You want to render the objects closest to the camera first because then you can determine which objects it hides, and then save time rendering those objects. There's no correctness cost for rendering objects out of order, just a potential performance cost. So while your array doesn't need to be ordered, the more ordered it is the happier you are. But you also can't spend too much time running a sorting algorithm, because you have a pretty strict realtime constraint. Bubble sort works pretty well here. You can run it a little bit of a time at each frame and get a better ordering than when you started.&lt;/p&gt;
    &lt;p&gt;That reminds me of one last use-case I've heard, apocryphally. Let's say you have a random collection of randomly-colored particles, and you want to animate them sorting into a rainbow spectrum. If you make each frame of the animation one pass of bubblesort, the particles will all move smoothly into the right positions. I couldn't find any examples in the wild, so with the help of GPT4 I hammered out a crappy visualization. Code is here, put it here.&lt;/p&gt;
    &lt;p&gt;(After doing that I suspect this isn't actually done in practice, in favor of running a better sort to calculate each particles final displacement and then animating each particles moving directly, instead of waiting to move for each bubblesort pass. I haven't mocked out an example but I think that'd look a lot smoother.)&lt;/p&gt;
    &lt;p&gt;So there you go, three niche use cases for bubblesort. You'll probably never need it.&lt;/p&gt;
    &lt;head rend="h3"&gt;New Quanta Article!&lt;/head&gt;
    &lt;p&gt;Okay so I didn't actually write this one, but I played a role in it happening! A while back a friend visited, and we were chatting about his job at quanta. At the time he was working on this mammoth article on metacomplexity theory, so naturally the topic of problems harder than NP-complete came up and I recommend he check out Petri net reachability. So he did, and then he wrote An Easy-Sounding Problem Yields Numbers Too Big for Our Universe. Gosh this is so exciting!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46224311</guid><pubDate>Wed, 10 Dec 2025 21:45:11 +0000</pubDate></item><item><title>Rubio orders return to Times New Roman font over 'wasteful' Calibri</title><link>https://www.bbc.com/news/articles/cgkez3367xmo</link><description>&lt;doc fingerprint="648ca7083c385906"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rubio orders return to Times New Roman font over 'wasteful' Calibri&lt;/head&gt;
    &lt;p&gt;US Secretary of State Marco Rubio has ordered diplomats to return to using Times New Roman font instead of Calibri, reversing a change made under the Biden administration.&lt;/p&gt;
    &lt;p&gt;Rubio's predecessor Antony Blinken had adopted Calibri in 2023, saying it was more accessible for people with visual disabilities. But Rubio said this was a "wasteful" diversity move and that Times New Roman was "more formal and professional".&lt;/p&gt;
    &lt;p&gt;The new changes go into effect on 10 December, and apply to both external and internal documents.&lt;/p&gt;
    &lt;p&gt;Lucas de Groot, the Dutch designer who created the Calibri typeface, told BBC Newshour the change was both "sad and hilarious".&lt;/p&gt;
    &lt;p&gt;"Calibri was designed to facilitate reading on modern computer screens - it was chosen to replace TNR - the typeface that Rubio wants to go back to now," Mr de Groot said.&lt;/p&gt;
    &lt;p&gt;A state department spokesperson told the BBC the change to Times New Roman aligns with President Donald Trump's mission to "present a unified, professional voice in all communications".&lt;/p&gt;
    &lt;p&gt;"Aligning the (state) department's practice with this standard ensures our communications reflect the same dignity, consistency, and formality expected in official government correspondence," the spokesperson said.&lt;/p&gt;
    &lt;p&gt;Times New Roman is a serif font, which means it has small lines that stem from the ends of the letters. Courts, legislatures, and other agencies typically use the more formal-appearing font. Calibri is a sans serif font, without those lines, and is considered easier to read on screens, especially for those with vision or reading impairments.&lt;/p&gt;
    &lt;p&gt;In his order on Tuesday requiring diplomats to return to Times New Roman, Rubio called Blinken's decision to use Calibri a "wasteful" diversity initiative, according to an internal department cable seen by Reuters.&lt;/p&gt;
    &lt;p&gt;The Trump administration has made several changes to how government works in the last 11 months, aiming to eliminate diversity, equity and inclusivity initiatives.&lt;/p&gt;
    &lt;p&gt;Most recently, the Trump administration announced it would drop Martin Luther King Jr's birthday and Juneteenth - two federal holidays honouring black history - as free admission days to national parks. Instead, visitors will be given free entry on President Donald Trump's birthday, which coincides with Flag Day.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46224610</guid><pubDate>Wed, 10 Dec 2025 22:10:25 +0000</pubDate></item></channel></rss>