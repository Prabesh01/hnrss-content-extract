<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 17 Sep 2025 17:08:13 +0000</lastBuildDate><item><title>Notion API importer, with Databases to Bases conversion bounty</title><link>https://github.com/obsidianmd/obsidian-importer/issues/421</link><description>&lt;doc fingerprint="b02cd2bc20f33688"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 139&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;Currently Importer supports converting Notion's HTML exports to Markdown via #14.&lt;/p&gt;
    &lt;p&gt;Unfortunately Notion's file-based export options don't include necessary data to recreate Databases.&lt;/p&gt;
    &lt;p&gt;This new importer would use the Notion API to download files progressively, and convert Databases to Bases as &lt;code&gt;.base&lt;/code&gt; files using the YAML syntax.&lt;/p&gt;
    &lt;p&gt;Closes #415&lt;/p&gt;
    &lt;head rend="h2"&gt;Bounty&lt;/head&gt;
    &lt;p&gt;See the Contribution guidelines for how to claim this bounty.&lt;/p&gt;
    &lt;p&gt;Bounty: $5,000 USD&lt;lb/&gt; Timeframe: 30 days&lt;/p&gt;
    &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses Notion API (integration token) incorporating changes from new data source object introduced 2025-09.&lt;/item&gt;
      &lt;item&gt;Properly converts files to Obsidian-flavored Markdown, including tables, to-do lists, etc&lt;/item&gt;
      &lt;item&gt; Support for images and attachments. Embed links converted to Markdown format &lt;code&gt;!()[image.png]&lt;/code&gt;and placed in the user's defined attachment location (Settings → File &amp;amp; links)&lt;/item&gt;
      &lt;item&gt;Provide working test cases, ideally a reproducible data import that can be used on Notion. Alternatively a test account you can share with us via DM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Databases to Bases&lt;/head&gt;
    &lt;p&gt;Some exploration is required before implementation because Databases and Bases work a bit differently. Notion's Databases start out as empty, whereas a Base starts out with all of the user's files, then narrows down using filters.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Determine an approach for importing databases and files&lt;/item&gt;
      &lt;item&gt;Determine what database features can be imported: views, columns, groups, summaries, formulas, etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h3"&gt;Assignees&lt;/head&gt;
    &lt;head rend="h3"&gt;Labels&lt;/head&gt;
    &lt;head rend="h3"&gt;Type&lt;/head&gt;
    &lt;head rend="h3"&gt;Projects&lt;/head&gt;
    &lt;p&gt;Status&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45271942</guid><pubDate>Wed, 17 Sep 2025 05:11:50 +0000</pubDate></item><item><title>Murex – An intuitive and content aware shell for a modern command line</title><link>https://murex.rocks/</link><description>&lt;doc fingerprint="76c4cc9c753539fe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Murex.Rocks&lt;/head&gt;
    &lt;p&gt;An intuitive and content aware shell for a modern command line&lt;/p&gt;
    &lt;head rend="h2"&gt;A Modern shell for the rest of us&lt;/head&gt;
    &lt;p&gt;Murex carries tons of unique features. Some highlights include...&lt;/p&gt;
    &lt;head rend="h3"&gt;Content Aware&lt;/head&gt;
    &lt;p&gt;Native support for manipulating data formats such as JSON, YAML, CSV, and others. This allows for seamless integration and manipulation of data in various formats. &lt;lb/&gt; Data types can be explicitly cast and reformatted, but also inferred if preferred.&lt;/p&gt;
    &lt;head rend="h3"&gt;Expressions&lt;/head&gt;
    &lt;p&gt;Smarter handling of variables and expressions to avoid accidental bugs caused by spaces or incorrect syntax. Resulting in a more reliable and predictable scripting experience. &lt;lb/&gt; Never worry about file names with weird characters, nor running equations in "bc" again.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smartly Interactive&lt;/head&gt;
    &lt;p&gt;A uniquely intuitive interactive shell. With command line hints pulled from man pages, AI LLMs, and other intelligent integrations. &lt;lb/&gt; Navigating the command line is faster, more intuitive and efficient than ever before.&lt;/p&gt;
    &lt;head rend="h3"&gt;Easily Extended&lt;/head&gt;
    &lt;p&gt;The built-in package manager makes it very easy to share your configuration, import other peoples namespaced modules, and port your environment between different machines. &lt;lb/&gt; Configure once, use everywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Read the language tour to get started.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Rosetta Stone is a great cheatsheet for those wishing to skip the tutorials and jump straight in. This guide includes comparisons with Bash.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Interactive Shell guide walks you through using Murex as a command line as opposed to a scripting language.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Screenshots&lt;/head&gt;
    &lt;p&gt;Check out the Language Tour and Interactive Shell guides!&lt;/p&gt;
    &lt;head rend="h2"&gt;Easy to Install&lt;/head&gt;
    &lt;p&gt;Install &lt;code&gt;murex&lt;/code&gt; from your favorite package manager:&lt;/p&gt;
    &lt;code&gt;# via Homebrew:
brew install murex

# via MacPorts:
port install murex
&lt;/code&gt;
    &lt;code&gt;# From AUR: https://aur.archlinux.org/packages/murex
wget -O PKGBUILD 'https://aur.archlinux.org/cgit/aur.git/plain/PKGBUILD?h=murex'
makepkg --syncdeps --install 
&lt;/code&gt;
    &lt;code&gt;pkg install murex
&lt;/code&gt;
    &lt;p&gt;More options are available in the INSTALL document.&lt;/p&gt;
    &lt;p&gt;This document was generated from gen/root/README_doc.yaml.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45272480</guid><pubDate>Wed, 17 Sep 2025 06:32:17 +0000</pubDate></item><item><title>Stategraph: Terraform state as a distributed systems problem</title><link>https://stategraph.dev/blog/why-stategraph/</link><description>&lt;doc fingerprint="a51827402d82cda9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Why We're Building Stategraph: Terraform State as a Distributed Systems Problem&lt;/head&gt;&lt;p&gt;The Terraform ecosystem has spent a decade working around a fundamental architectural mismatch: we're using filesystem semantics to solve a distributed systems problem. The result is predictable and painful.&lt;/p&gt;&lt;p&gt;When we started building infrastructure automation at scale, we discovered that Terraform's state management exhibits all the classic symptoms of impedance mismatch between data representation and access patterns. Teams implement increasingly elaborate workarounds: state file splitting, wrapper orchestration, external locking mechanisms. These aren't solutions; they're evidence that we're solving the wrong problem.&lt;/p&gt;&lt;p&gt;Stategraph addresses this by treating state for what it actually is: a directed acyclic graph of resources with partial update semantics, not a monolithic document.&lt;/p&gt;&lt;head rend="h2"&gt;The Pathology of File-Based State&lt;/head&gt;&lt;p&gt;Terraform state, at its core, is a coordination problem. Multiple actors (engineers, CI systems, drift detection) need to read and modify overlapping subsets of infrastructure state concurrently. This is a well-studied problem in distributed systems, with established solutions around fine-grained locking, multi-version concurrency control, and transaction isolation.&lt;/p&gt;&lt;p&gt;Instead, Terraform implements the simplest possible solution: a global mutex on a JSON file.&lt;/p&gt;&lt;head rend="h4"&gt;Observation&lt;/head&gt;&lt;p&gt;The probability of lock contention in a shared state file increases super-linearly with both team size and resource count. At 100 resources and 5 engineers, you're coordinating 500 potential interaction points through a single mutex.&lt;/p&gt;&lt;p&gt;Consider the actual data access patterns in a typical Terraform operation:&lt;/p&gt;&lt;head rend="h4"&gt;Current Model&lt;/head&gt;&lt;p&gt; Read: 100%&lt;lb/&gt;Lock: 100%&lt;lb/&gt;Modify: 0.5% &lt;/p&gt;&lt;head rend="h4"&gt;Actual Requirement&lt;/head&gt;&lt;p&gt; Read: 3%&lt;lb/&gt;Lock: 3%&lt;lb/&gt;Modify: 3% &lt;/p&gt;&lt;p&gt;This mismatch between granularity of operation and granularity of locking is the root cause of every Terraform scaling problem. It violates the fundamental principle of isolation in concurrent systems: non-overlapping operations should not block each other.&lt;/p&gt;&lt;p&gt;The standard response, splitting state files, doesn't solve the problem. It redistributes it. Now you have N coordination problems instead of one, plus the additional complexity of managing cross-state dependencies. You've traded false contention for distributed transaction coordination, which is arguably worse.&lt;/p&gt;&lt;head rend="h2"&gt;State as a Graph: The Natural Representation&lt;/head&gt;&lt;p&gt;Infrastructure state is inherently a directed graph. Resources have dependencies, which form edges. Changes propagate along these edges. Terraform already knows this: the internal representation is a graph, and the planner performs graph traversal. But at the storage layer, we flatten this rich structure into a blob.&lt;/p&gt;&lt;p&gt;This is akin to storing a B-tree in a CSV file. You can do it, but you're destroying the very properties that make the data structure useful.&lt;/p&gt;&lt;p&gt;When state is properly normalized into a graph database, several properties emerge naturally:&lt;/p&gt;&lt;p&gt;Subgraph isolation: Operations on disjoint subgraphs are inherently parallelizable. If Team A is modifying RDS instances and Team B is updating CloudFront distributions, there's no shared state to coordinate.&lt;/p&gt;&lt;p&gt;Precise locking: We can implement row-level locking on resources and edge-level locking on dependencies. Lock acquisition follows the dependency graph, preventing deadlocks through consistent ordering.&lt;/p&gt;&lt;p&gt;Incremental refresh: Given a change set, we can compute the minimal refresh set by traversing the dependency graph. Most changes affect a small cone of resources, not the entire state space.&lt;/p&gt;&lt;head rend="h2"&gt;Concurrency Control Through Proper Abstractions&lt;/head&gt;&lt;p&gt;The distributed systems community solved these problems decades ago. Multi-version concurrency control (MVCC) allows readers to proceed without blocking writers. Write-ahead logging provides durability without sacrificing performance. Transaction isolation levels let operators choose their consistency guarantees.&lt;/p&gt;&lt;p&gt;Stategraph implements these patterns at the Terraform state layer:&lt;/p&gt;&lt;head rend="h4"&gt;Traditional: Global Lock&lt;/head&gt;&lt;head rend="h4"&gt;Stategraph: Subgraph Isolation&lt;/head&gt;&lt;p&gt;Each operation acquires locks only on its subgraph. The lock manager uses the dependency graph to ensure consistent ordering, preventing deadlocks. Readers use MVCC to access consistent snapshots without blocking writers.&lt;/p&gt;&lt;head rend="h4"&gt;Implementation Detail&lt;/head&gt;&lt;p&gt;Lock acquisition follows a strict partial order derived from the resource dependency graph. Resources are locked in topological order, with ties broken by resource ID. This guarantees deadlock freedom without requiring global coordination.&lt;/p&gt;&lt;p&gt;The result is dramatic improvement in concurrent throughput:&lt;/p&gt;&lt;head rend="h5"&gt;Transaction A&lt;/head&gt;&lt;head rend="h5"&gt;Transaction B&lt;/head&gt;&lt;head rend="h5"&gt;Transaction C&lt;/head&gt;&lt;p&gt;Three teams, three transactions, zero contention. This isn't possible with file-based state, regardless of how you split it.&lt;/p&gt;&lt;head rend="h2"&gt;The Refresh Problem&lt;/head&gt;&lt;p&gt;Terraform refresh is O(n) in the number of resources, regardless of change scope. Change one security group rule and you still walk the entire state. That's an algorithmic bottleneck, not just an implementation detail.&lt;/p&gt;&lt;head rend="h4"&gt;File-Based State&lt;/head&gt;&lt;p&gt; Changing 1 resource&lt;lb/&gt; Refreshing all 30 &lt;/p&gt;&lt;head rend="h4"&gt;Graph State&lt;/head&gt;&lt;p&gt; Changing 1 resource&lt;lb/&gt; Refreshing only 3 &lt;/p&gt;&lt;p&gt;With a graph representation, refresh work can be scoped to the affected subgraph instead of the entire state. Most changes touch only a small fraction of resources, not everything.&lt;/p&gt;&lt;head rend="h2"&gt;Why We Built This&lt;/head&gt;&lt;p&gt;At Terrateam, we've watched hundreds of teams struggle with the same fundamental problems. They start with a single state file, hit scaling limits, split their state, discover coordination complexity, build orchestration layers, and eventually resign themselves to living with the pain.&lt;/p&gt;&lt;p&gt;This is a solvable problem. The computer science is well-understood. The implementation is straightforward once you acknowledge that state management is a distributed systems problem, not a file storage problem.&lt;/p&gt;&lt;p&gt;Stategraph isn't revolutionary. It's the application of established distributed systems principles to a problem that's been mischaracterized since its inception. We're not inventing new algorithms; we're applying the right ones.&lt;/p&gt;&lt;head rend="h4"&gt;Design Principle&lt;/head&gt;&lt;p&gt;The storage layer should match the access patterns. Terraform state exhibits graph traversal patterns, partial update patterns, and concurrent access patterns. The storage layer should be a graph database with ACID transactions and fine-grained locking. Anything else is impedance mismatch.&lt;/p&gt;&lt;p&gt;The infrastructure industry has accepted file-based state as an immutable constraint for too long. It's not. It's a choice, and it's the wrong one for systems at scale.&lt;/p&gt;&lt;head rend="h2"&gt;Technical Implementation&lt;/head&gt;&lt;p&gt;Stategraph is implemented as a PostgreSQL schema with a backend that speaks the Terraform/OpenTofu remote backend protocol. We chose PostgreSQL for its robust MVCC, proven scalability, and operational familiarity. The schema normalizes state into three primary relations:&lt;/p&gt;&lt;p&gt;resources: one row per resource, with type, provider, and attribute columns.&lt;lb/&gt; dependencies: edge table representing the resource dependency graph.&lt;lb/&gt; transactions: append-only log of all state mutations with full attribution.&lt;/p&gt;&lt;p&gt;The backend extends Terraform's protocol with graph-aware operations. Lock acquisition and state queries operate directly on the database representation of the graph, enabling precision and concurrency that file-based backends can't provide.&lt;/p&gt;&lt;p&gt;This isn't a wrapper or an orchestrator. It's a replacement for the storage layer that preserves Terraform's execution model while fixing its coordination problems.&lt;/p&gt;&lt;head rend="h2"&gt;Adoption Path&lt;/head&gt;&lt;p&gt;Stategraph reads existing tfstate files and constructs the graph representation automatically. No changes to Terraform configurations are required. The backend protocol is unchanged. From Terraform's perspective, Stategraph is just another backend, like S3 or GCS.&lt;/p&gt;&lt;p&gt;But from an operational perspective, everything changes. Lock contention disappears. Refresh times drop by orders of magnitude. Teams stop blocking each other. State becomes queryable, auditable, and comprehensible.&lt;/p&gt;&lt;p&gt;We're not asking teams to rewrite their infrastructure. We're asking them to store it properly.&lt;/p&gt;&lt;quote&gt;The question isn't whether Terraform state should be a graph. It already is. The question is whether we'll continue pretending it's a file.&lt;/quote&gt;&lt;head rend="h3"&gt;Technical Preview&lt;/head&gt;&lt;p&gt;Stategraph is in active development. We're working with design partners to validate the approach at scale.&lt;/p&gt;Get Updates&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273352</guid><pubDate>Wed, 17 Sep 2025 08:38:17 +0000</pubDate></item><item><title>Alibaba's new AI chip: Key specifications comparable to H20</title><link>https://news.futunn.com/en/post/62202518/alibaba-s-new-ai-chip-unveiled-key-specifications-comparable-to</link><description>&lt;doc fingerprint="ccca7d4c469478ff"&gt;
  &lt;main&gt;
    &lt;p&gt;On September 16, according to a report aired on CCTV News, a comparison of key parameters between domestically produced cards and NV cards revealed that the latest PPU chip developed by Pingtouge, a subsidiary of Alibaba and designed for artificial intelligence, surpasses NVIDIA's A800 in all major parameter metrics and is comparable to the H20. Compared with other domestic AI chips, Pingtouge’s PPU also mostly leads in these indicators.&lt;/p&gt;
    &lt;p&gt;In terms of specific parameters:&lt;lb/&gt;Memory: Alibaba Pingtouge PPU is equipped with 96GB of HBM2e, surpassing NVIDIA A800's 80GB HBM2e and matching the memory capacity of NVIDIA H20. However, H20 integrates HBM3, which is one generation ahead;**&lt;lb/&gt;Inter-chip interconnect bandwidth: Alibaba Pingtouge PPU reaches up to 700GB/s, higher than A800’s 400GB/s, but slightly lower than H20;&lt;lb/&gt;Interface: Alibaba Pingtouge PPU supports PCIe 5.0×15, superior to A800’s PCIe 4.0×16 and on par with H20;&lt;lb/&gt;Power consumption: Alibaba Pingtouge PPU maintains the same level as NVIDIA A800 at 400W, lower than H20’s 550W.&lt;/p&gt;
    &lt;p&gt;According to the report, the list of signed agreements for China Unicom’s Sanjiangyuan Green Electricity Intelligent Computing Center project showcases collaborations with multiple domestic AI chip brands under signed or proposed agreements.&lt;lb/&gt;Among them, the total number of devices in signed projects amounts to 1,747 units, comprising 22,832 computing cards with a total computing power of 3,479P. Specifically:&lt;lb/&gt;Alibaba Cloud Ten Thousand Cards: A total of 1,024 devices, 16,384 Pingtouge computing cards, with computing power reaching 1,945P;&lt;lb/&gt;Chinese Academy of Sciences: A total of 512 devices, 4,096 Muxi computing cards, with computing power reaching 984P;&lt;lb/&gt;Beijing Jingtai: A total of 83 devices, 1,328 BR100 computing power cards, with a computing power of 450P;&lt;lb/&gt;Zhonghao Core Electronics: A total of 128 devices, with a computing power of 200P.&lt;/p&gt;
    &lt;p&gt;In addition, the total computing power of the proposed contracted projects is 2,002P, including computing power cards from Taichu Yuanjie, Suizhi Technology, and Moore Threads.&lt;/p&gt;
    &lt;p&gt;Editor/Rocky&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273747</guid><pubDate>Wed, 17 Sep 2025 09:45:44 +0000</pubDate></item><item><title>Oh no, not again a meditation on NPM supply chain attacks</title><link>https://tane.dev/2025/09/oh-no-not-again...-a-meditation-on-npm-supply-chain-attacks/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273824</guid><pubDate>Wed, 17 Sep 2025 09:57:50 +0000</pubDate></item><item><title>EU Chat Control: Germany's position has been reverted to undecided</title><link>https://mastodon.social/@chatcontrol/115215006562371435</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273854</guid><pubDate>Wed, 17 Sep 2025 10:02:55 +0000</pubDate></item><item><title>PureVPN IPv6 Leak</title><link>https://anagogistis.com/posts/purevpn-ipv6-leak/</link><description>&lt;doc fingerprint="fc9cf519ac23292a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PureVPN IPv6 leak&lt;/head&gt;
    &lt;p&gt;In late August 2025, I submitted two security reports to PureVPN under their VDP. Three weeks later, I’ve received no response, so I decided to publish the findings to inform other users.&lt;/p&gt;
    &lt;p&gt;The issues affect both their GUI (v2.10.0) and CLI (v2.0.1) clients on Linux (tested on Ubuntu 24.04.3 LTS, kernel 6.8.0, iptables-nft backend). Hereâs what I found.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. IPv6 Leaks Off-Tunnel&lt;/head&gt;
    &lt;p&gt;After toggling Wi-Fi or resuming from suspend, the PureVPN client fails to restore IPv6 protections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;CLI (IKS enabled): The client auto-reconnects and reports status as “connected”, yet the system regains a default IPv6 route via Router Advertisements (&lt;/p&gt;&lt;code&gt;fe80::1&lt;/code&gt;). Since&lt;code&gt;ip6tables&lt;/code&gt;&lt;code&gt;OUTPUT&lt;/code&gt;remains&lt;code&gt;ACCEPT&lt;/code&gt;(default), egress resumes off-tunnel.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;GUI (IKS enabled): When the GUI detects a disconnection, it blocks IPv4 and displays the “VPN session disconnected” dialog. However, IPv6 remains functional until the user explicitly clicks&lt;/p&gt;&lt;code&gt;Reconnect&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real-world effect: I was able to browse IPv6-preferred sites and send/receive email (Thunderbird) with my ISPâs IPv6 address while the client UI claimed I was protected.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Host Firewall Reset and Not Restored&lt;/head&gt;
    &lt;p&gt;At connect time, PureVPN wipes the user’s &lt;code&gt;iptables&lt;/code&gt; configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;INPUT&lt;/code&gt;is set to&lt;code&gt;ACCEPT&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;All &lt;code&gt;-A&lt;/code&gt;rules are flushed (UFW, Docker jumps, user rules, etc.)&lt;/item&gt;
      &lt;item&gt;After disconnect, these changes are not reverted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Result: the system remains more exposed after using the VPN than before. This defeats the point of using UFW or a local deny policy and contradicts user expectations.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Baseline protections
$ sudo iptables -P INPUT DROP
$ sudo iptables -I INPUT -p icmp -j DROP

# Connect to VPN
$ purevpn-cli -c US
$ sudo iptables -S | head -3
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
$ sudo iptables -S | grep icmp
# (no output â rule was wiped)

# Disconnect
$ purevpn-cli -d
$ sudo iptables -S | head -3
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
# All wiped. INPUT = ACCEPT
&lt;/code&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;PureVPN:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Does not properly implement an IPv6 kill-switch&lt;/item&gt;
      &lt;item&gt;Leaves IPv6 egress open after reconnects or IKS events&lt;/item&gt;
      &lt;item&gt;Wipes your firewall state (&lt;code&gt;iptables&lt;/code&gt;) and does not restore it&lt;/item&gt;
      &lt;item&gt;Applies broad &lt;code&gt;ACCEPT&lt;/code&gt;policies to make things work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both issues have real-world impact. Privacy claims are undermined when your real IPv6 leaks and your firewall state is lost.&lt;/p&gt;
    &lt;p&gt;I submitted full technical reports and screencasts to security@purevpn.com. No acknowledgment to date.&lt;/p&gt;
    &lt;p&gt;Use with caution.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273897</guid><pubDate>Wed, 17 Sep 2025 10:10:14 +0000</pubDate></item><item><title>Determination of the fifth Busy Beaver value</title><link>https://arxiv.org/abs/2509.12337</link><description>&lt;doc fingerprint="a8be7401d4f7b0af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Logic in Computer Science&lt;/head&gt;&lt;p&gt; [Submitted on 15 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Determination of the fifth Busy Beaver value&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy Beaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol Turing machine can perform from the all-zero tape before halting, and $S$ was historically introduced by Tibor Radó in 1962 as one of the simplest examples of an uncomputable function. The proof enumerates $181,385,789$ Turing machines with 5 states and, for each machine, decides whether it halts or not. Our result marks the first determination of a new Busy Beaver value in over 40 years and the first Busy Beaver value ever to be formally verified, attesting to the effectiveness of massively collaborative online research (bbchallenge$.$org).&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LO&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45273999</guid><pubDate>Wed, 17 Sep 2025 10:26:18 +0000</pubDate></item><item><title>Apple Photos App Corrupts Images</title><link>https://tenderlovemaking.com/2025/09/17/apple-photos-app-corrupts-images/</link><description>&lt;doc fingerprint="7241bf3571248d9f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Apple Photos App Corrupts Images&lt;/head&gt;Sep 17, 2025 @ 8:59 am&lt;p&gt;The Apple Photos app sometimes corrupts images when importing from my camera. I just wanted to make a blog post about it in case anyone else runs into the problem. I’ve seen other references to this online, but most of the people gave up trying to fix it, and none of them went as far as I did to debug the issue.&lt;/p&gt;&lt;p&gt;I’ll try to describe the problem, and the things I’ve tried to do to fix it. But also note that I’ve (sort of) given up on the Photos app too. Since I can’t trust it to import photos from my camera, I switched to a different workflow.&lt;/p&gt;&lt;p&gt;Here is a screenshot of a corrupted image in the Photos app:&lt;/p&gt;&lt;head rend="h2"&gt;How I used to import images&lt;/head&gt;&lt;p&gt;I’ve got an OM System OM-1 camera. I used to shoot in RAW + jpg, then when I would import to Photos app, I would check the “delete photos after import” checkbox in order to empty the SD card. Turns out “delete after import” was a huge mistake.&lt;/p&gt;&lt;head rend="h2"&gt;Getting corrupted images&lt;/head&gt;&lt;p&gt;I’m pretty sure I’d been getting corrupted images for a while, but it would only be 1 or 2 images out of thousands, so I thought nothing of it (it was probably my fault anyway, right?)&lt;/p&gt;&lt;p&gt;But the problem really got me upset when last year I went to a family member’s wedding and took tons of photos. Apple Photos combines RAW + jpg photos so you don’t have a bunch of duplicates, and when you view the images in the photos app, it just shows you the jpg version by default. After I imported all of the wedding photos I noticed some of them were corrupted. Upon closer inspection, I found that it sometimes had corrupted the jpg, sometimes corrupted the RAW file, and sometimes both. Since I had been checking the “delete after import” box, I didn’t know if the images on the SD card were corrupted before importing or not. After all, the files had been deleted so there was no way to check.&lt;/p&gt;&lt;p&gt;I estimate I completely lost about 30% of the images I took that day.&lt;/p&gt;&lt;p&gt;Losing so many photos really rattled me, but I wanted to figure out the problem so I didn’t lose images in the future.&lt;/p&gt;&lt;head rend="h2"&gt;Narrowing down the problem&lt;/head&gt;&lt;p&gt;I was worried this was somehow a hardware problem. Copying files seems so basic, I didn’t think there was any way a massively deployed app like Photos could fuck it up (especially since its main job is managing photo files). So, to narrow down the issue I changed out all of the hardware. Here are all the things I did:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Switched USB-C cables&lt;/item&gt;&lt;item&gt;Bought a new SD card direct from the manufacturer (to eliminate the possibility of buying a bootleg SD card)&lt;/item&gt;&lt;item&gt;Switched to only shooting in RAW (if importing messes up 30% of my images, but I cut the number of images I import by half, then that should be fewer corrupted images right? lol)&lt;/item&gt;&lt;item&gt;Bought a new laptop&lt;/item&gt;&lt;item&gt;Bought a new camera: the OM System OM-1 MKii&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I did each of these steps over time, as to only change one variable at a time, and still the image corruption persisted. I didn’t really want to buy a new camera, the MKii is not really a big improvement over the OM-1, but we had a family trip coming up and the idea that pressing the shutter button on the camera might not actually record the image didn’t sit well with me.&lt;/p&gt;&lt;head rend="h2"&gt;Finally a smoking gun&lt;/head&gt;&lt;p&gt;Since I had replaced literally all of the hardware involved, I knew it must be a software problem. I stopped checking the “delete after import” button, and started reviewing all of the photos after import. After verifying none of them were corrupt, then I would format the SD card. I did this for months without finding any corrupt files. At this point I figured it was somehow a race condition or something when copying the photo files and deleting them at the same time.&lt;/p&gt;&lt;p&gt;However, after I got home from RailsConf and imported my photos, I found one corrupt image (the one above). I was able to verify that the image was not corrupt on the SD card, so the camera was working fine (meaning I probably didn’t need to buy a new camera body at all).&lt;/p&gt;&lt;p&gt;I tried deleting the corrupt file and re-importing the original to see if it was something about that particular image, but it re-imported just fine. In other words, it seems like the Photos app will corrupt files randomly.&lt;/p&gt;&lt;p&gt;I don’t know if this is a problem that is specific to OM System cameras, and I’m not particularly interested in investing in a new camera system just to find out.&lt;/p&gt;&lt;p&gt;If I compare the corrupted image with the non-corrupted image, the file sizes are exactly the same, but the bytes are different:&lt;/p&gt;&lt;p&gt;Checksums:&lt;/p&gt;&lt;code&gt;aaron@tc ~/Downloads&amp;gt; md5sum P7110136-from-camera.ORF Exports/P7110136.ORF 
17ce895fd809a43bad1fe8832c811848  P7110136-from-camera.ORF
828a33005f6b71aea16d9c2f2991a997  Exports/P7110136.ORF
&lt;/code&gt;&lt;p&gt;File sizes:&lt;/p&gt;&lt;code&gt;aaron@tc ~/Downloads&amp;gt; ls -al P7110136-from-camera.ORF Exports/P7110136.ORF
-rw-------@ 1 aaron  staff  18673943 Jul 12 04:38 Exports/P7110136.ORF
-rwx------  1 aaron  staff  18673943 Jul 17 09:29 P7110136-from-camera.ORF*
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;P7110136-from-camera.ORF&lt;/code&gt; is the non-corrupted file, and &lt;code&gt;Exports/P7110136.ORF&lt;/code&gt; is the corrupted file from Photos app.
Here’s a screenshot of the preview of the non-corrupted photo:&lt;/p&gt;&lt;p&gt;Here is the binary diff between the files. I ran both files through &lt;code&gt;xxd&lt;/code&gt; then diffed them.&lt;/p&gt;&lt;head rend="h2"&gt;My new workflow&lt;/head&gt;&lt;p&gt;I’m not going to put any more effort into debugging this problem, but I wanted to blog about it in case anyone else is seeing the issue. I take a lot of photos, and to be frank, most of them are not very good. I don’t want to look through a bunch of bad photos every time I look at my library, so culling photos is important. Culling photos in the Photos app is way too cumbersome, so I’ve switched to using Darktable.&lt;/p&gt;&lt;p&gt;My current process is:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Import images to Darktable&lt;/item&gt;&lt;item&gt;Delete the ones I don’t like&lt;/item&gt;&lt;item&gt;Process ones I do like&lt;/item&gt;&lt;item&gt;Export both the jpg and the original raw file&lt;/item&gt;&lt;item&gt;Import those to the Photos app so they’re easy to view and share&lt;/item&gt;&lt;item&gt;Periodically format my SD card&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I’ve not seen any file corruption when importing to Darktable, so I am convinced this is a problem with the Photos app. But now, since all of my images land in Darktable before making their way to the Photos app, I don’t really care anymore. The bad news is that I’ve spent a lot of time and money trying to debug this. I guess the good news is that now I have redundant hardware!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45274277</guid><pubDate>Wed, 17 Sep 2025 11:07:44 +0000</pubDate></item><item><title>Procedural Island Generation (III)</title><link>https://brashandplucky.com/2025/09/17/procedural-island-generation-iii.html</link><description>&lt;doc fingerprint="9da72cd84b738ab5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Procedural Island Generation (III)&lt;/head&gt;&lt;p&gt;This post continues from Part II, where we established the paint map foundation and mountain ridge system. Now we’ll add detailed noise layers, distance-based mountain peaks, and do blending to create the final terrain elevation.&lt;/p&gt;&lt;head rend="h2"&gt;Paint Map (recap)&lt;/head&gt;&lt;p&gt;Before applying noise layers, we start with the foundation established in Part I - the paint map that defines our base land/water distribution:&lt;/p&gt;&lt;p&gt;For visualization throughout this series, we’ll be using the magma palette from matplotlib, which I patched to artificially darken the ocean areas to highlight the coastline:&lt;/p&gt;&lt;p&gt;Note that we’ll be sampling the paint map per Delaunay triangle (at each triangle’s centroid):&lt;/p&gt;&lt;p&gt;Remember that the paint map provides the broad strokes: positive values for land, negative for ocean, with smooth transitions between them. Now we’ll enhance it with noise layers to create realistic terrain detail.&lt;/p&gt;&lt;head rend="h2"&gt;Multi-Scale Noise Layers&lt;/head&gt;&lt;p&gt;We will layer multiple octaves of Simplex noise at different frequencies over the broad strokes provided by the paint map. Each will contribute different detail scales to the final terrain.&lt;/p&gt;&lt;p&gt;mapgen4 by @redblobgames in particular uses six layers:&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Layer&lt;/cell&gt;&lt;cell role="head"&gt;Frequency&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;n₀&lt;/cell&gt;&lt;cell&gt;1x&lt;/cell&gt;&lt;cell&gt;Lowest frequency&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;n₁&lt;/cell&gt;&lt;cell&gt;2x&lt;/cell&gt;&lt;cell&gt;Low frequency&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;n₂&lt;/cell&gt;&lt;cell&gt;4x&lt;/cell&gt;&lt;cell&gt;Medium-low frequency&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;n₄&lt;/cell&gt;&lt;cell&gt;16x&lt;/cell&gt;&lt;cell&gt;Medium-high frequency&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;n₅&lt;/cell&gt;&lt;cell&gt;32x&lt;/cell&gt;&lt;cell&gt;High frequency&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;n₆&lt;/cell&gt;&lt;cell&gt;64x&lt;/cell&gt;&lt;cell&gt;Highest frequency&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Notice the gap in numbering (n₃ is missing). This would correspond to frequency 8x, which we don’t use.&lt;/p&gt;&lt;head rend="h3"&gt;Coastal Noise Enhancement&lt;/head&gt;&lt;p&gt;mapgen4 starts with coastal noise enhancement. This provides control over the variation at coastlines while keeping inland elevation unaffected:&lt;/p&gt;\[e = \text{Paint map from Part I}\] \[e_{coast} = e + \alpha \cdot (1 - e^4) \cdot \left(n_4 + \frac{n_5}{2} + \frac{n_6}{4}\right)\]&lt;p&gt;The term \((1 - e^4)\) creates a bell curve that peaks at \(e=0\) (coastline) and decreases rapidly for \(\lvert e \rvert &amp;gt; 0\). This modulates an fBm-like combination of our three highest frequency noise layers.&lt;/p&gt;&lt;p&gt;What matters here isn’t the exact formula or amplitudes, but the core principle: applying high-frequency detail specifically where land meets water.&lt;/p&gt;\[e_{tmp} = \begin{cases} e &amp;amp; \text{if } e_{coast} &amp;gt; 0 \\ e_{coast} &amp;amp; \text{if } e_{coast} \leq 0 \end{cases}\]&lt;head rend="h2"&gt;Mountain Distance Field&lt;/head&gt;&lt;p&gt;Mountains need special pre-processing. If you remember from Part I in the swarm of seed points we tagged some as mountain peaks. Here we will pre-compute a distance field from every regular seed point to the closest mountain peak point.&lt;/p&gt;&lt;p&gt;We compute distance through the mesh topology of the Delaunay triangulation using BFS (breadth-first search). i.e., we don’t use Euclidean distance. This creates more organic mountain shapes that follow the terrain’s natural connectivity.&lt;/p&gt;&lt;p&gt;The algorithm spreads outward from mountain peaks:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Start at triangles containing mountain seed points (distance = 0)&lt;/item&gt;&lt;item&gt;Visit neighboring triangles, incrementing distance by a randomized amount&lt;/item&gt;&lt;item&gt;The randomization creates natural ridge patterns instead of perfect cones&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Here’s the magic formula used for distance increment in each step:&lt;/p&gt;\[\Delta = s \cdot (1 + j \cdot r)\]&lt;p&gt;Where:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;\(s\) = spacing between triangles (uses configured Poisson disk separation)&lt;/item&gt;&lt;item&gt;\(j\) = jaggedness parameter (0 = true topological distance, 1 = very irregular)&lt;/item&gt;&lt;item&gt;\(r \in [-1,1]\) = random factor using triangular distribution&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The triangular distribution &lt;code&gt;rand() - rand()&lt;/code&gt; clusters values near zero while allowing occasional larger variations. This looks more natural than uniform randomness.&lt;/p&gt;&lt;p&gt;I implemented Fisher-Yates shuffling when visiting neighbor triangles. Instead of processing neighbors in a fixed order (which would create directional bias), the order is randomly shuffled each time. This ensures mountain ridges branch out organically in all directions rather than following predictable patterns.&lt;/p&gt;&lt;p&gt;After computing distances this way, we normalize them (by the max dist, for example):&lt;/p&gt;&lt;head rend="h2"&gt;Elevation Blending&lt;/head&gt;&lt;p&gt;The final elevation combines all components through weighted blending:&lt;/p&gt;\[e_{final} = \begin{cases} \text{lerp}(e_{coast}^2, e_{hill}, e_{mountain}) &amp;amp; \text{if } e_{coast} &amp;gt; 0 \\ e_{coast} \cdot (\rho + n_1) &amp;amp; \text{if } e_{coast} \leq 0 \end{cases}\]&lt;p&gt;Where:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;\(e_{hill} = h \cdot (1 + \text{lerp}(\frac{1 + n_0}{2}, n_4, n_2))\) =&amp;gt; hill elevation with noise-modulated height&lt;/item&gt;&lt;item&gt;\(e_{mountain} = 1 - \frac{\mu}{2^\sigma} \cdot d_m\) =&amp;gt; mountain elevation from distance field&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The quadratic blend weight produces smooth transitions from hills near the coast through mixed terrain at mid-elevations to pure mountains at peaks.&lt;/p&gt;&lt;p&gt;With (editable) parameters:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;\(\alpha\): Coastal noise strength (0.01)&lt;/item&gt;&lt;item&gt;\(h\): Hill height scale (0.02)&lt;/item&gt;&lt;item&gt;\(\rho\): Ocean depth multiplier (1.5)&lt;/item&gt;&lt;item&gt;\(\mu\): Mountain slope (17.6)&lt;/item&gt;&lt;item&gt;\(\sigma\): Mountain sharpness (9.8)&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Interactive Parameter Exploration&lt;/head&gt;&lt;head rend="h2"&gt;Region (vs. Triangle) Elevation&lt;/head&gt;&lt;p&gt;So far we’ve computed elevation for triangles. But our Voronoi regions (from Part I) also need elevations for certain stages in the rest of the series.&lt;/p&gt;&lt;p&gt;Each seed point defines a Voronoi region and serves as a vertex in multiple Delaunay triangles. To assign elevation to a Voronoi region, we average the elevations of all triangles that share its seed point as a vertex.&lt;/p&gt;&lt;head rend="h2"&gt;Next Steps&lt;/head&gt;&lt;p&gt;With elevation complete, our island has shape but lacks the defining features carved by water. Part IV will simulate the hydrological cycle: rainfall patterns influenced by topography, rivers flowing from peaks to ocean, and valleys carved by erosion.&lt;/p&gt;&lt;head rend="h2"&gt;Valuable Resources&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Terrain from Noise - Amit Patel’s Red Blob Games guide to layering noise for terrain&lt;/item&gt;&lt;item&gt;Polygonal Map Generation - Red Blob Games on Voronoi-based terrain (mapgen4 inspiration)&lt;/item&gt;&lt;item&gt;Distance Fields for Terrain - Red Blob Games on using distance fields in terrain generation&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275049</guid><pubDate>Wed, 17 Sep 2025 12:29:49 +0000</pubDate></item><item><title>Tau² Benchmark: How a Prompt Rewrite Boosted GPT-5-Mini by 22%</title><link>https://quesma.com/blog/tau2-benchmark-improving-results-smaller-models/</link><description>&lt;doc fingerprint="3e0f6dd72893063a"&gt;
  &lt;main&gt;
    &lt;p&gt;Now on the front page of Hacker News — join the discussion.&lt;/p&gt;
    &lt;p&gt;In a recent post, we introduced the Tau² benchmark, a framework for benchmaring LLMs. Today we’re sharing a surprising discovery we made while using it: a simple prompt rewrite boosted a small model’s success rate by over 20%. This post is a deep-dive on how we found and fixed this performance bottleneck by making subtle changes to agent policies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking LLMs with Tau²&lt;/head&gt;
    &lt;p&gt;On the recent OpenAI Summer Update, we have seen that GPT-5 model has made significant strides in agentic tasks. To validate these claims, they’ve turned to the Tau² benchmark, which simulates real-world agent interactions across various domains like telecom, retail, and airlines.&lt;/p&gt;
    &lt;p&gt;Before moving any further, we have to establish that GPT-5 showed significant improvement only in one benchmark domain - which is Telecom. The other ones have been somehow overlooked during model presentation - therefore we won’t bother about them either (😉).&lt;/p&gt;
    &lt;p&gt;In agentic interactions, accuracy is non-negotiable, but model speed is equally vital for user experience. Therefore, it makes sense to consider alternatives to flagship models, such as the recently introduced GPT-5-mini.&lt;/p&gt;
    &lt;p&gt;GPT-5-mini offers significant advantages: it’s roughly twice as fast in latency and noticeably more efficient in throughput. While delivering 85–95% of the full GPT-5’s performance, it is also five times cheaper.&lt;/p&gt;
    &lt;p&gt;Therefore, we ran an experiment to explore two things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How well GPT-5-mini performs on this benchmark.&lt;/item&gt;
      &lt;item&gt;Whether we can improve its results by making subtle changes to the domain, such as modifying agent policies or task descriptions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Baseline: Expect GPT-5-mini to Fail 45% of the Time&lt;/head&gt;
    &lt;p&gt;Firstly, we’re going to establish the benchmark for the GPT-5-mini model. As the telecom benchmark contains over 100 tests, we’ll use their subset. Luckily, the telecom_small task set comes in handy with just 20 test scenarios.&lt;/p&gt;
    &lt;p&gt;Running the benchmark with:&lt;/p&gt;
    &lt;code&gt;tau2 run \
    --domain telecom \
    --agent-llm gpt-5-mini \
    --user-llm gpt-5-mini \
    --num-trials 2 --task-set-name telecom_small&lt;/code&gt;
    &lt;p&gt;Our results are:&lt;/p&gt;
    &lt;p&gt;We ended up running 40 simulations:&lt;/p&gt;
    &lt;p&gt;The initial success rate was low: just 55%. The GPT-5-mini with its limited reasoning capabilities doesn’t even get close to flagship GPT-5.&lt;/p&gt;
    &lt;p&gt;There’s an additional interesting metric this benchmark has introduced, which is pass^k. This measures how well an agent can perform when it’s challenged with the same task k times. I like to think of it as the reliability of the AI Agent.&lt;lb/&gt; Another intriguing aspect of this benchmark are tasks which failed for all given trials - which could imply that the AI Agent is simply not capable of handling at all. This can happen due to multiple factors - reasoning might be too difficult, user ask could not be specific enough, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Hack: Using Claude to Rewrite Prompts for GPT-5-mini&lt;/head&gt;
    &lt;p&gt;When hacking the AI Agent for &lt;code&gt;GPT-5-mini&lt;/code&gt; model we aimed to answer three questions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Can I improve the overall success rate when using this limited model?&lt;/item&gt;
      &lt;item&gt;Are we able to “unlock” more tasks which agents are capable of handling?&lt;/item&gt;
      &lt;item&gt;Does agent reliability improve?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The beauty of generative AI is that we could offload lots of work and allow ourselves a little laziness. Therefore, we asked Claude to analyze the AI agent policies in the telecom domain, which are the building blocks for the agent prompt. From there, we asked specifically to assume that these policies are going to feed an AI Agent prompt, which will be using faster, non-flagship LLM. Output documents (&lt;code&gt;main_policy.md&lt;/code&gt; and &lt;code&gt;tech_support_manual.md&lt;/code&gt;) will have to be rephrased so that they are easier to follow for the agent and result in improving its behaviour.&lt;/p&gt;
    &lt;p&gt;Here’s the “executive summary” of improvements it made:&lt;/p&gt;
    &lt;code&gt;I've created two AI-optimized versions of the telecom domain documentation:

Key Improvements Made:

1. Structure &amp;amp; Flow
   - Decision Trees: Clear branching logic with ├── and └── notation
   - Sequential Steps: Numbered, ordered procedures instead of scattered explanations
   - Prerequisites: Explicit dependency checks before proceeding

2. AI Agent Optimizations
   - Tool Call Clarity: Exact function names and parameters
   - Binary Decisions: Clear yes/no conditions instead of ambiguous language
   - Error Handling: Specific failure conditions and next steps
   - Verification Steps: "Recheck" instructions after each fix

3. Cognitive Load Reduction
   - Reference Tables: Quick lookup for tools and purposes
   - Pattern Recognition: Common issue combinations and their solutions
   - Critical Reminders: Common AI mistakes section to prevent errors

4. Actionable Language
   - Removed verbose explanations mixed with instructions
   - Consolidated multiple documents' logic into single workflows
   - Used imperative commands: "Check X", "If Y then Z"
   - Added immediate verification steps&lt;/code&gt;
    &lt;p&gt;We’ve moved from lengthy policy declarations to clear, directive instructions. Instead of wordy statements, the new style uses step-by-step logic, conditions, and patterns. For prompts, this works more like a checklist — “Check X → If Y, then Z” — rather than vague, descriptive policies.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Result: 22% Accuracy Boost and 50% Fewer Unsolvable Tasks&lt;/head&gt;
    &lt;p&gt;Let’s review what our improved AI agent results look like:&lt;/p&gt;
    &lt;p&gt;The new prompts led to a significant performance boost. Pass^k metrics surged:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;k=1 from 0.55 to 0.675 (a 22.73% improvement) → In plain terms, GPT-5-mini now succeeds on 67.5% of tasks instead of 55%.&lt;/item&gt;
      &lt;item&gt;k=2 from 0.4 to 0.5 (a 25% improvement) → Meaning retries became more effective too.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For context, flagship GPT-5 scores ~97% on this benchmark, o3 comes in at 58%, and GPT-4.1 at 34%. With our optimized prompts, GPT-5-mini not only jumped well above its own baseline but also outperformed o3, landing much closer to GPT-5 than before.&lt;/p&gt;
    &lt;p&gt;The side-by-side comparison shows exactly where the gains came from. On the left side of the screen you’ll see the “stock” AI agent results, on the right - our AI agent improved for GPT-5-mini.&lt;/p&gt;
    &lt;p&gt;The screenshot above outlines that with our updated prompts and policies, we managed to “unlock” some of the tests which were previously always failing due to GPT-5-mini’s limited capabilities. Now there are only 3 tasks, which the agent didn’t manage to solve at all within the given 2 trials - compared to 6.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key Takeaways for Your Own Models&lt;/head&gt;
    &lt;p&gt;This experiment shows that thoughtful prompt design can meaningfully boost the performance of smaller models like GPT-5-mini. By restructuring policies into clear, step-by-step instructions, we not only improved success rates but also “unlocked” tasks that previously seemed unsolvable for the model.&lt;/p&gt;
    &lt;p&gt;The key was in simplifying language, reducing ambiguity, and breaking down reasoning into explicit, actionable steps. Smaller models struggle with long-winded or fuzzy policies, but thrive when given structured flows, binary decisions, and lightweight verification steps.&lt;/p&gt;
    &lt;p&gt;The takeaway is clear: using a frontier model to automatically optimize prompts can unlock major improvements for smaller LLMs. With strategic optimization, lightweight models can deliver decent results at a fraction of the cost — making them a compelling alternative when efficiency and affordability matter as much as accuracy.&lt;/p&gt;
    &lt;p&gt;If you found this helpful, let us know! Prompt engineering is still an open playground, and we’re excited to see what creative approaches others are exploring in this space.&lt;/p&gt;
    &lt;p&gt;Discuss it on LinkedIn, X or Hacker News.&lt;/p&gt;
    &lt;p&gt;UPDATE: Since publishing this post and hitting the front page of HN, some readers expressed interest in seeing the actual before and after policies (which are building block for the agent prompt). Initially I thought these would be too lengthy for the article and no one would care, but since there’s interest, I’m happy to share them in this Pull Request.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275354</guid><pubDate>Wed, 17 Sep 2025 13:03:24 +0000</pubDate></item><item><title>Bringing fully autonomous rides to Nashville, in partnership with Lyft</title><link>https://waymo.com/blog/2025/09/waymo-is-coming-to-nashville-in-partnership-with-lyft</link><description>&lt;doc fingerprint="3c2ac04af1a4a895"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bringing fully autonomous rides to Nashville, in partnership with Lyft&lt;/head&gt;
    &lt;p&gt;We’re on our way to Music City! We’re excited to bring the magic of Waymo’s fully autonomous ride-hailing service to riders in Nashville, in partnership with Lyft.&lt;/p&gt;
    &lt;p&gt;Our generalizable Waymo Driver has become even more capable as we’ve scaled to hundreds of thousands of fully autonomous rides each week across five major U.S. cities. We’ll start fully autonomous operations in Nashville in the coming months, and open to public riders next year. We’ll do so by pairing our world-leading technology and seamless ride-hailing service with Lyft’s proven track record of fleet management through its Flexdrive subsidiary.&lt;/p&gt;
    &lt;p&gt;We’re also excited to offer riders in Nashville even more ways to ride with Waymo. Riders will hail via the Waymo app, and as our service grows, riders will also be able to use the Lyft app to match with a Waymo vehicle. We’re thrilled for even more people to have access to our ride-hailing service, as we work towards our mission to be the world’s most trusted driver.&lt;/p&gt;
    &lt;p&gt;“We’re delighted to partner with Lyft and launch in Nashville next year, as we continue to scale our Waymo ride-hailing service to more people in more places,” said Waymo co-CEO Tekedra Mawakana. “Lyft’s extensive fleet management capabilities through Flexdrive make them an ideal partner for expanding to Nashville. We can’t wait to introduce Music City’s residents and visitors to the convenient, consistent, safe, and magical Waymo experience.”&lt;/p&gt;
    &lt;p&gt;"This partnership brings together best-in-class autonomous vehicles with best-in-class customer experience," said Lyft CEO David Risher. "Waymo has proven that its autonomous technology works at scale. When combined with Lyft's customer-obsession and world-class fleet management capabilities, it's two great tastes that go great together."&lt;/p&gt;
    &lt;p&gt;With more than 100 million fully autonomous miles driven on public roads, the data shows Waymo’s technology is significantly safer than human drivers in the areas where we operate. Nashville joins a growing list of cities that will soon have access to Waymo.&lt;/p&gt;
    &lt;p&gt;“As families and businesses move to Tennessee in record numbers, our state continues to lead the nation in finding innovative solutions to transportation challenges," said Governor Bill Lee. "By leveraging private sector technologies like Waymo's fully autonomous vehicles, we're exploring possibilities we couldn't achieve on our own, and further accelerating economic growth. I look forward to Waymo's launch in The Volunteer State.”&lt;/p&gt;
    &lt;p&gt;We’re looking forward to serving the people of Nashville soon. If you’re interested in following our journey or want to help bring Waymo to your city next, sign up at waymo.com/updates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275415</guid><pubDate>Wed, 17 Sep 2025 13:10:45 +0000</pubDate></item><item><title>Firefox 143 for Android to introduce DoH</title><link>https://blog.mozilla.org/en/firefox/dns-android/</link><description>&lt;doc fingerprint="9f6ab3c3bc9540af"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Firefox DNS privacy: Faster than ever, now on Android&lt;/head&gt;
    &lt;p&gt;All web browsing starts with a DNS query to find the IP address for the desired service or website. For much of the internet’s history, this query is sent in the clear. DNS-over-HTTPS (DoH) plugs this privacy leak by encrypting the DNS messages, so no one on the network, not your internet service provider or a free public WiFi provider, can eavesdrop on your browsing.&lt;lb/&gt;In 2020, Firefox became the first browser to roll out DoH by default, starting in the United States and in 2023, we announced the Firefox DoH-by-default rollout in Canada, powered by our trusted partner, the Canadian Internet Registration Authority (CIRA).&lt;/p&gt;
    &lt;p&gt;This year, we’ve built on that foundation and delivered major performance improvements and mobile support, ensuring more Firefox users benefit from privacy without compromise.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing DoH for Android&lt;/head&gt;
    &lt;p&gt;After bringing encrypted DNS protection to millions of desktop users, we’re now extending the same to mobile. Firefox users who have been waiting for DoH on Android can now turn it on and browse with the same privacy protections as on their desktops.&lt;/p&gt;
    &lt;p&gt;Starting with this week’s release of Firefox 143 for Android, users can choose to enable DoH in Firefox on their mobile devices by selecting “Increased Protection” DoH configuration. Performance testing with Firefox DoH partners is currently underway. If DoH is as fast as we expect, we plan to enable it by default for Android users in certain regions, similar to desktop users. Until then, these configuration options provide you the choice to opt in early.&lt;/p&gt;
    &lt;head rend="h2"&gt;DoH performance breakthroughs in 2025&lt;/head&gt;
    &lt;p&gt;DNS resolution speed is critical to the browsing experience — when web pages involve multiple DNS queries, the speed difference compounds and can cause page loads to be slow. Since we first rolled out DoH in Canada, we’ve worked closely with CIRA for reliability and performance measurements. Through our strong collaboration with them and their technology partner Akamai, Firefox DoH lookups are now 61% faster year-to-date for the 75th percentile.&lt;/p&gt;
    &lt;p&gt;With these performance improvements, DoH resolution time is now within a millisecond or two of native DNS resolution. This is a big win because Firefox users in Canada now get the privacy of encrypted DNS with no performance penalty.&lt;/p&gt;
    &lt;p&gt;Although the investigation and analysis started with the desire to improve DoH in Firefox, the benefits didn’t end there. Our collaboration also improved CIRA DoH performance for many of its DNS users, including Canadian universities, as well as other DNS providers relying on CIRA’s or Akamai’s server implementations.&lt;/p&gt;
    &lt;p&gt;This is a win not just for Firefox users, but for the many other users around the globe.&lt;/p&gt;
    &lt;head rend="h2"&gt;Robust privacy on your terms&lt;/head&gt;
    &lt;p&gt;We have always approached DoH with an emphasis on transparency, user choice, and strong privacy safeguards. Firefox gives users meaningful control over how their DNS traffic is handled: Users can opt out, choose their own resolver, or adjust DoH protection levels, and Firefox makes it clear what DoH is doing and why it matters.&lt;/p&gt;
    &lt;p&gt;Firefox enforces strict requirements for DNS resolvers before trusting them with your browsing. Not every DNS provider can become a DoH provider in Firefox — only those that meet and attest to Mozilla’s rigorous Trusted Recursive Resolver (TRR) policy through a legally binding contract.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prioritizing your privacy and speed&lt;/head&gt;
    &lt;p&gt;Our work with DoH this year shows what’s possible when privacy and performance go hand-in-hand. We’ve proven that encrypted DNS can be fast, reliable, and available on desktop and Android. Just as importantly, we’ve shown that partnerships grounded in open standards and accountability can deliver benefits not only to Firefox users but to the wider internet.&lt;/p&gt;
    &lt;p&gt;As we look forward, our commitment stays the same: Privacy should be the default, speed should never be a compromise, and the web should remain open and accessible to everyone. Choosing Firefox means choosing a browser that is built for you and for a better internet.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275444</guid><pubDate>Wed, 17 Sep 2025 13:14:04 +0000</pubDate></item><item><title>SQLiteData: A fast, lightweight replacement for SwiftData using SQL and CloudKit</title><link>https://github.com/pointfreeco/sqlite-data</link><description>&lt;doc fingerprint="278a2af8febb569a"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast, lightweight replacement for SwiftData, powered by SQL and supporting CloudKit synchronization.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Learn more&lt;/item&gt;
      &lt;item&gt;Overview&lt;/item&gt;
      &lt;item&gt;Quick start&lt;/item&gt;
      &lt;item&gt;Performance&lt;/item&gt;
      &lt;item&gt;SQLite knowledge required&lt;/item&gt;
      &lt;item&gt;Overview&lt;/item&gt;
      &lt;item&gt;Demos&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Installation&lt;/item&gt;
      &lt;item&gt;Community&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This library was motivated and designed over the course of many episodes on Point-Free, a video series exploring advanced programming topics in the Swift language, hosted by Brandon Williams and Stephen Celis. To support the continued development of this library, subscribe today.&lt;/p&gt;
    &lt;p&gt;SQLiteData is a fast, lightweight replacement for SwiftData, including CloudKit synchronization (and even CloudKit sharing) that deploys all the way back to the iOS 13 generation of targets. To populate data from the database you can use &lt;code&gt;@Table&lt;/code&gt; and &lt;code&gt;@FetchAll&lt;/code&gt;, which are
similar to SwiftData's &lt;code&gt;@Model&lt;/code&gt; and &lt;code&gt;@Query&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;SQLiteData&lt;/cell&gt;
        &lt;cell role="head"&gt;SwiftData&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@FetchAll
var items: [Item]

@Table
struct Item {
  let id: UUID
  var title = ""
  var isInStock = true
  var notes = ""
}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;@Query
var items: [Item]

@Model
class Item {
  var title: String
  var isInStock: Bool
  var notes: String
  init(
    title: String = "",
    isInStock: Bool = true,
    notes: String = ""
  ) {
    self.title = title
    self.isInStock = isInStock
    self.notes = notes
  }
}&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Both of the above examples fetch items from an external data store using Swift data types, and both are automatically observed by SwiftUI so that views are recomputed when the external data changes, but SQLiteData is powered directly by SQLite and is usable from UIKit, &lt;code&gt;@Observable&lt;/code&gt; models, and
more.&lt;/p&gt;
    &lt;p&gt;For more information on SQLiteData's querying capabilities, see Fetching model data.&lt;/p&gt;
    &lt;p&gt;Before SQLiteData's property wrappers can fetch data from SQLite, you need to provide–at runtime–the default database it should use. This is typically done as early as possible in your app's lifetime, like the app entry point in SwiftUI, and is analogous to configuring model storage in SwiftData:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;SQLiteData&lt;/cell&gt;
        &lt;cell role="head"&gt;SwiftData&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@main
struct MyApp: App {
  init() {
    prepareDependencies {
      let db = try! DatabaseQueue(
        // Create/migrate a database
        // connection
      )
      $0.defaultDatabase = db
    }
  }
  // ...
}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;@main
struct MyApp: App {
  let container = {
    // Create/configure a container
    try! ModelContainer(/* ... */)
  }()

  var body: some Scene {
    WindowGroup {
      ContentView()
        .modelContainer(container)
    }
  }
}&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;For more information on preparing a SQLite database, see Preparing a SQLite database.&lt;/p&gt;
    &lt;p&gt;This &lt;code&gt;defaultDatabase&lt;/code&gt; connection is used implicitly by SQLiteData's strategies, like
&lt;code&gt;@FetchAll&lt;/code&gt; and &lt;code&gt;@FetchOne&lt;/code&gt;, which are similar to SwiftData's
&lt;code&gt;@Query&lt;/code&gt; macro, but more powerful:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;SQLiteData&lt;/cell&gt;
        &lt;cell role="head"&gt;SwiftData&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@FetchAll
var items: [Item]

@FetchAll(Item.order(by: \.title))
var items

@FetchAll(Item.where(\.isInStock))
var items



@FetchAll(Item.order(by: \.isInStock))
var items

@FetchOne(Item.count())
var itemsCount = 0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;@Query
var items: [Item]

@Query(sort: [SortDescriptor(\.title)])
var items: [Item]

@Query(filter: #Predicate&amp;lt;Item&amp;gt; {
  $0.isInStock
})
var items: [Item]

// No @Query equivalent of ordering
// by boolean column.

// No @Query equivalent of counting
// entries in database without loading
// all entries.&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And you can access this database throughout your application in a way similar to how one accesses a model context, via a property wrapper:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;SQLiteData&lt;/cell&gt;
        &lt;cell role="head"&gt;SwiftData&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@Dependency(\.defaultDatabase)
var database

let newItem = Item(/* ... */)
try database.write { db in
  try Item.insert { newItem }
    .execute(db))
}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;@Environment(\.modelContext)
var modelContext

let newItem = Item(/* ... */)
modelContext.insert(newItem)
try modelContext.save()&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;For more information on how SQLiteData compares to SwiftData, see Comparison with SwiftData.&lt;/p&gt;
    &lt;p&gt;Further, if you want to synchronize the local database to CloudKit so that it is available on all your user's devices, simply configure a &lt;code&gt;SyncEngine&lt;/code&gt; in the entry point of the app:&lt;/p&gt;
    &lt;code&gt;@main
struct MyApp: App {
  init() {
    prepareDependencies {
      $0.defaultDatabase = try! appDatabase()
      $0.defaultSyncEngine = SyncEngine(
        for: $0.defaultDatabase,
        tables: Item.self
      )
    }
  }
  // ...
}&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;For more information on synchronizing the database to CloudKit and sharing records with iCloud users, see CloudKit Synchronization.&lt;/p&gt;
    &lt;p&gt;This is all you need to know to get started with SQLiteData, but there's much more to learn. Read the articles below to learn how to best utilize this library:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fetching model data&lt;/item&gt;
      &lt;item&gt;Observing changes to model data&lt;/item&gt;
      &lt;item&gt;Preparing a SQLite database&lt;/item&gt;
      &lt;item&gt;Dynamic queries&lt;/item&gt;
      &lt;item&gt;CloudKit Synchronization&lt;/item&gt;
      &lt;item&gt;Comparison with SwiftData&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SQLiteData leverages high-performance decoding from StructuredQueries to turn fetched data into your Swift domain types, and has a performance profile similar to invoking SQLite's C APIs directly.&lt;/p&gt;
    &lt;p&gt;See the following benchmarks against Lighter's performance test suite for a taste of how it compares:&lt;/p&gt;
    &lt;code&gt;Orders.fetchAll                           setup    rampup   duration
   SQLite (generated by Enlighter 1.4.10) 0        0.144    7.183
   Lighter (1.4.10)                       0        0.164    8.059
┌──────────────────────────────────────────────────────────────────┐
│  SQLiteData (1.0.0)                     0        0.172    8.511  │
└──────────────────────────────────────────────────────────────────┘
   GRDB (7.4.1, manual decoding)          0        0.376    18.819
   SQLite.swift (0.15.3, manual decoding) 0        0.564    27.994
   SQLite.swift (0.15.3, Codable)         0        0.863    43.261
   GRDB (7.4.1, Codable)                  0.002    1.07     53.326
&lt;/code&gt;
    &lt;p&gt;SQLite is one of the most established and widely distributed pieces of software in the history of software. Knowledge of SQLite is a great skill for any app developer to have, and this library does not want to conceal it from you. So, we feel that to best wield this library you should be familiar with the basics of SQLite, including schema design and normalization, SQL queries, including joins and aggregates, and performance, including indices.&lt;/p&gt;
    &lt;p&gt;With some basic knowledge you can apply this library to your database schema in order to query for data and keep your views up-to-date when data in the database changes, and you can use StructuredQueries to build queries, either using its type-safe, discoverable query building APIs, or using its &lt;code&gt;#sql&lt;/code&gt; macro for writing safe SQL strings.&lt;/p&gt;
    &lt;p&gt;This repo comes with lots of examples to demonstrate how to solve common and complex problems with SQLiteData. Check out this directory to see them all, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Case Studies&lt;/p&gt;&lt;lb/&gt;Demonstrates how to solve some common application problems in an isolated environment, in both SwiftUI and UIKit. Things like animations, dynamic queries, database transactions, and more.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;CloudKitDemo&lt;/p&gt;&lt;lb/&gt;A simplified demo that shows how to synchronize a SQLite database to CloudKit and how to share records with other iCloud users. See our dedicated articles on CloudKit Synchronization and CloudKit Sharing for more information.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Reminders&lt;/p&gt;&lt;lb/&gt;A rebuild of Apple's Reminders app that uses a SQLite database to model the reminders, lists and tags. It features many advanced queries, such as searching, stats aggregation, and multi-table joins. It also features CloudKit synchronization and sharing.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;SyncUps&lt;/p&gt;&lt;lb/&gt;This application is a faithful reconstruction of one of Apple's more interesting sample projects, called Scrumdinger, and uses SQLite to persist the data for meetings. We have also added CloudKit synchronization so that all changes are automatically made available on all of the user's devices.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The documentation for releases and &lt;code&gt;main&lt;/code&gt; are available here:&lt;/p&gt;
    &lt;p&gt;You can add SQLiteData to an Xcode project by adding it to your project as a package…&lt;/p&gt;
    &lt;p&gt;…and adding the &lt;code&gt;SQLiteData&lt;/code&gt; product to your target.&lt;/p&gt;
    &lt;p&gt;If you want to use SQLiteData in a SwiftPM project, it's as simple as adding it to your &lt;code&gt;Package.swift&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;dependencies: [
  .package(url: "https://github.com/pointfreeco/sqlite-data", from: "1.0.0")
]&lt;/code&gt;
    &lt;p&gt;And then adding the following product to any target that needs access to the library:&lt;/p&gt;
    &lt;code&gt;.product(name: "SQLiteData", package: "sqlite-data"),&lt;/code&gt;
    &lt;p&gt;If you want to discuss this library or have a question about how to use it to solve a particular problem, there are a number of places you can discuss with fellow Point-Free enthusiasts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;For long-form discussions, we recommend the discussions tab of this repo.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For casual chat, we recommend the Point-Free Community Slack.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This library is released under the MIT license. See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275582</guid><pubDate>Wed, 17 Sep 2025 13:27:26 +0000</pubDate></item><item><title>UUIDv47: Store UUIDv7 in DB, emit UUIDv4 outside (SipHash-masked timestamp)</title><link>https://github.com/stateless-me/uuidv47</link><description>&lt;doc fingerprint="2c041edee4ad24ea"&gt;
  &lt;main&gt;
    &lt;p&gt;uuidv47 lets you store sortable UUIDv7 in your database while emitting a UUIDv4-looking façade at your API boundary. It does this by XOR-masking only the UUIDv7 timestamp field with a keyed SipHash-2-4 stream tied to the UUID’s own random bits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Header-only C (C89) · zero deps&lt;/item&gt;
      &lt;item&gt;Deterministic, invertible mapping (exact round-trip)&lt;/item&gt;
      &lt;item&gt;RFC-compatible version/variant bits (v7 in DB, v4 on the wire)&lt;/item&gt;
      &lt;item&gt;Key-recovery resistant (SipHash-2-4, 128-bit key)&lt;/item&gt;
      &lt;item&gt;Full tests provided&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why&lt;/item&gt;
      &lt;item&gt;Quick start&lt;/item&gt;
      &lt;item&gt;Public API&lt;/item&gt;
      &lt;item&gt;Specification &lt;list rend="ul"&gt;&lt;item&gt;UUIDv7 bit layout&lt;/item&gt;&lt;item&gt;Façade mapping (v7 ↔ v4)&lt;/item&gt;&lt;item&gt;SipHash message derived from random&lt;/item&gt;&lt;item&gt;Invertibility&lt;/item&gt;&lt;item&gt;Collision analysis&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Security model&lt;/item&gt;
      &lt;item&gt;Build, test, coverage&lt;/item&gt;
      &lt;item&gt;Integration tips&lt;/item&gt;
      &lt;item&gt;Performance notes&lt;/item&gt;
      &lt;item&gt;FAQ&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DB-friendly: UUIDv7 is time-ordered → better index locality &amp;amp; pagination.&lt;/item&gt;
      &lt;item&gt;Externally neutral: The façade hides timing patterns and looks like v4 to clients/systems.&lt;/item&gt;
      &lt;item&gt;Secret safety: Uses a PRF (SipHash-2-4). Non-crypto hashes are not suitable when the key must not leak.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include "uuidv47.h"

int main(void){
  const char* s = "00000000-0000-7000-8000-000000000000";
  uuid128_t v7;
  if (!uuid_parse(s, &amp;amp;v7)) return 1;
  uuidv47_key_t key = { .k0 = 0x0123456789abcdefULL, .k1 = 0xfedcba9876543210ULL };
  uuid128_t facade = uuidv47_encode_v4facade(v7, key);
  uuid128_t back = uuidv47_decode_v4facade(facade, key);

  char a[37], b[37], c[37];
  uuid_format(&amp;amp;v7, a);
  uuid_format(&amp;amp;facade, b);
  uuid_format(&amp;amp;back, c);
  printf("v7 (DB) : %s\n", a);
  printf("v4 (API): %s\n", b);
  printf("back    : %s\n", c);
}&lt;/code&gt;
    &lt;p&gt;Build &amp;amp; run with the provided Makefile: make test make coverage sudo make install&lt;/p&gt;
    &lt;code&gt;typedef struct { uint8_t  b[16]; } uuid128_t;
typedef struct { uint64_t k0, k1; } uuidv47_key_t;

uuid128_t uuidv47_encode_v4facade(uuid128_t v7, uuidv47_key_t key);
uuid128_t uuidv47_decode_v4facade(uuid128_t v4_facade, uuidv47_key_t key);
int  uuid_version(const uuid128_t* u);
void set_version(uuid128_t* u, int ver);
void set_variant_rfc4122(uuid128_t* u);
bool uuid_parse (const char* str, uuid128_t* out);
void uuid_format(const uuid128_t* u, char out[37]);&lt;/code&gt;
    &lt;p&gt;UUIDv7 bit layout:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ts_ms_be: 48-bit big-endian timestamp&lt;/item&gt;
      &lt;item&gt;ver: high nibble of byte 6 = 0x7 (v7) or 0x4 (façade)&lt;/item&gt;
      &lt;item&gt;rand_a: 12 random bits&lt;/item&gt;
      &lt;item&gt;var: RFC variant (0b10)&lt;/item&gt;
      &lt;item&gt;rand_b: 62 random bits&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Façade mapping:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Encode: ts48 ^ mask48(R), set version=4&lt;/item&gt;
      &lt;item&gt;Decode: encTS ^ mask48(R), set version=7&lt;/item&gt;
      &lt;item&gt;Random bits unchanged&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SipHash input: 10 bytes from random field: msg[0] = (byte6 &amp;amp; 0x0F) msg[1] = byte7 msg[2] = (byte8 &amp;amp; 0x3F) msg[3..9] = bytes9..15&lt;/p&gt;
    &lt;p&gt;Invertibility: XOR mask is reversible with known key.&lt;/p&gt;
    &lt;p&gt;Collision analysis: Injective mapping. Only risk is duplicate randoms per ms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Goal: Secret key unrecoverable even with chosen inputs.&lt;/item&gt;
      &lt;item&gt;Achieved: SipHash-2-4 is a keyed PRF.&lt;/item&gt;
      &lt;item&gt;Keys: 128-bit. Derive via HKDF.&lt;/item&gt;
      &lt;item&gt;Rotation: store small key ID outside UUID.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;make test
make coverage
make debug
sudo make install
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Do encode/decode at API boundary.&lt;/item&gt;
      &lt;item&gt;For Postgres, write tiny C extension.&lt;/item&gt;
      &lt;item&gt;For sharding, hash v4 façade with xxh3 or SipHash.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SipHash-2-4 on 10-byte message is extremely fast. No allocations.&lt;/p&gt;
    &lt;p&gt;Q: Why not xxHash with a secret? A: Not a PRF; secret can leak. Use SipHash.&lt;/p&gt;
    &lt;p&gt;Q: Is façade indistinguishable from v4? A: Yes, variable bits uniform, version/variant set to v4.&lt;/p&gt;
    &lt;p&gt;MIT, Copyright (c) 2025 Stateless Limited&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45275973</guid><pubDate>Wed, 17 Sep 2025 14:02:29 +0000</pubDate></item><item><title>YouTube addresses lower view counts which seem to be caused by ad blockers</title><link>https://9to5google.com/2025/09/16/youtube-lower-view-counts-ad-blockers/</link><description>&lt;doc fingerprint="7c588c5fb891325b"&gt;
  &lt;main&gt;
    &lt;p&gt;Over the past month or so, many YouTubers have been reporting major drops to their video view counts. Theories have run wild, but there’s one explanation involving ad blockers that makes the most sense, but YouTube isn’t confirming anything directly.&lt;/p&gt;
    &lt;p&gt;Since mid-August, many YouTubers have noticed their view counts are considerably lower than they were before, in some cases with very drastic drops. The reason for the drop, though, has been shrouded in mystery for many creators.&lt;/p&gt;
    &lt;p&gt;The most likely explanation seems to be that YouTube is not counting views properly for users with an ad blocker enabled, another step in the platform’s continued war on ad blockers. This was first realized by Josh Strife Hayes, who noticed that view counts on TV, phones, and tablets have been steady, while views on computers have dropped by around 50% since the mid-August trend started. TechLinked, a channel in the Linus Tech Tips family, confirmed similar numbers within its statistics.&lt;/p&gt;
    &lt;p&gt;This aligns with one of the possible explanations that YouTube itself hinted at in an acknowledgement of lower view counts.&lt;/p&gt;
    &lt;p&gt;Google says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewers Using Ad Blockers &amp;amp; Other Content Blocking Tools: Ad blockers and other extensions can impact the accuracy of reported view counts. Channels whose audiences include a higher proportion of users utilizing such tools may see more fluctuations in traffic related to updates to these tools.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Top comment by Napalmxxx2&lt;/head&gt;
    &lt;p&gt;We wouldn't need ad blockers if we weren't force fed irrelevant to us ads, unskippable ads, and the worst offender; ads that are LONGER than the video being watched.&lt;/p&gt;
    &lt;p&gt;We wouldn't feel the necessity if we weren't intruded on by a monopoly out for its own self interest.&lt;/p&gt;
    &lt;p&gt;The rest of the post addresses prior speculation that YouTube’s new AI-powered age verification tools were to blame – which YouTube adamantly says is not the case – while also offering other possible explanations such as “seasonal viewing habits” and competition on the platform.&lt;/p&gt;
    &lt;p&gt;YouTube says “there is no systemic issue that is impacting creators” regarding lower view counts.&lt;/p&gt;
    &lt;p&gt;This ad blocker situation does seem the most likely explanation, though. In a prior video, Linus Tech Tips had noted that while view counts were down, ad revenue was not. If computer views are the only ones down, it stands to reason that viewers using an ad blocker are not being counted correctly, especially if ad revenue isn’t taking a hit from the lower view counts. YouTube’s hint that ad blockers “can impact the accuracy of reported view counts” certainly suggests this is possible, even if it’s not firm confirmation.&lt;/p&gt;
    &lt;head rend="h2"&gt;More on YouTube:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;YouTube for Android TV, Google TV will now let you test new features in beta&lt;/item&gt;
      &lt;item&gt;YouTube recommending awful videos? Here’s how to fix that&lt;/item&gt;
      &lt;item&gt;YouTube rolls out new profanity guidelines for creators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Follow Ben: Twitter/X, Threads, Bluesky, and Instagram&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45276262</guid><pubDate>Wed, 17 Sep 2025 14:29:10 +0000</pubDate></item><item><title>How to motivate yourself to do a thing you don't want to do</title><link>https://ashleyjanssen.com/how-to-motivate-yourself-to-do-a-thing-you-dont-want-to-do/</link><description>&lt;doc fingerprint="77441055ef772c70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Motivate Yourself To Do A Thing You Don't Want to Do&lt;/head&gt;
    &lt;p&gt;Learn some ways to help encourage action when you feel unmotivated.&lt;/p&gt;
    &lt;p&gt;We have an air bike in our basement. If you are unfamiliar with air bikes, they are similar to stationary bikes with foot pedals but also have handles you push and pull with your arms. It uses air resistance, so the harder you pedal and move your arms, the higher the resistance.&lt;/p&gt;
    &lt;p&gt;It’s also known as an assault bike. 😬&lt;/p&gt;
    &lt;p&gt;Which is apt, because it’s a butt-kicker of a workout. I use it about once a week, more frequently in the winter when it’s too cold to run, and less often in the summer when I can get outside more. And I kind of hate it!&lt;/p&gt;
    &lt;p&gt;Before I even drag myself to our basement, I’m already dreading it. The only way I can convince myself to do it is by finding a suitably engaging show I can distract myself with on my phone while I huff and puff.&lt;/p&gt;
    &lt;p&gt;Every time, I start my warm-up and think to myself,&lt;/p&gt;
    &lt;p&gt;“It’s only 30 minutes, I can do this!”&lt;/p&gt;
    &lt;p&gt;Like clockwork, within the first three minutes, I think, “Maybe I will only do ten minutes today and do some pilates or weights instead.”&lt;/p&gt;
    &lt;p&gt;After ten minutes, I think, “OK, surely I can make it to 20 minutes, and that will be enough”.&lt;/p&gt;
    &lt;p&gt;After 20 minutes, as I gasp for air and sweat soaks through my shirt, I think “Well, I already made it to 20 minutes… I guess I will just finish it.”&lt;/p&gt;
    &lt;p&gt;And then I proceed to huff and puff to the end, wherein I walk my wobbly legs back up the stairs to do a cooldown. At which point I think, “That suuuuuucked…” And then congratulate myself on finishing as I try to get my heart rate back to normal. 🥵&lt;/p&gt;
    &lt;p&gt;This mental dance happens, without fail, every single time I ride.&lt;/p&gt;
    &lt;p&gt;I share this anecdote because it illustrates how tricky motivation can be, especially when faced with something you don’t want to do or have been procrastinating on. There are any number of things you have to deal with in your life that you don’t want to. There are even things you might generally enjoy that feel like they are hanging over you.&lt;/p&gt;
    &lt;p&gt;The pattern often goes like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before you start, it feels daunting, and the prospect lingers in the back of your mind. You know it needs to be done, but you really, really don’t feel like it. You leave it until it starts to loom larger and larger.&lt;/item&gt;
      &lt;item&gt;When you finally convince yourself to start, it’s not what you want to be doing, but it’s generally fine. It’s often not even as bad as you thought it would be, and it feels good to make progress.&lt;/item&gt;
      &lt;item&gt;As you near the end, you can even push yourself a little to wrap it up and get it off your plate.&lt;/item&gt;
      &lt;item&gt;When it’s over, you feel relieved, like a weight has been taken off your shoulders, and you are both pleased with yourself and a little annoyed that it took you so long to deal with.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sound familiar?&lt;/p&gt;
    &lt;p&gt;Motivation is a topic that comes up with nearly all my clients, as they navigate the various complexities of their lives. In some ways, motivation seems simple. You ask yourself, “Why can’t I just make myself be motivated to do the thing?”, whatever the thing might be. However, as you beat yourself up about it, consider that many factors influence our decision-making and the feeling of being motivated.&lt;/p&gt;
    &lt;p&gt;Humans are complex creatures, with numerous brain chemicals and hormones influencing our overall physical and emotional state, which themselves are constantly impacted, sometimes drastically, by things like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Have you been sleeping well and enough?&lt;/item&gt;
      &lt;item&gt;Have you been eating well and the right amount for you?&lt;/item&gt;
      &lt;item&gt;Have you been imbibing in alcohol or other things?&lt;/item&gt;
      &lt;item&gt;Have you been moving your body regularly?&lt;/item&gt;
      &lt;item&gt;Do you have any physical or mental conditions?&lt;/item&gt;
      &lt;item&gt;Are you in pain?&lt;/item&gt;
      &lt;item&gt;Do you have significant life stressors at this time?&lt;/item&gt;
      &lt;item&gt;What time of day is it?&lt;/item&gt;
      &lt;item&gt;Where are you in your natural hormone cycles?&lt;/item&gt;
      &lt;item&gt;How old are you?&lt;/item&gt;
      &lt;item&gt;Have you had any conflicts in your life recently?&lt;/item&gt;
      &lt;item&gt;Did you move your body in a way entirely within your usual routines, but apparently in a way that is no longer acceptable?&lt;/item&gt;
      &lt;item&gt;Did you sleep in a slightly different position than usual, and now your back will never be the same again?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I could go on, but you get the idea.😅&lt;/p&gt;
    &lt;p&gt;All of these factors (and more) conspire to shift your mood, physical energy, and mental energy, often making it harder to muster the motivation to do things. What, then, can you do to move things in the right direction? How do you motivate yourself to do a thing you don’t want to do?&lt;/p&gt;
    &lt;p&gt;Here are several ways to help encourage action when you feel unmotivated.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Think about why you are feeling unmotivated&lt;/head&gt;
    &lt;p&gt;There are many external and internal factors, as listed above, that contribute to motivation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When your body isn’t feeling good, it’s harder to make it do things.&lt;/item&gt;
      &lt;item&gt;When your mind is tired, distracted, or overwhelmed, it’s challenging to focus and accomplish tasks.&lt;/item&gt;
      &lt;item&gt;When the thing you need to do isn’t important to you or something you don’t like, it’s hard to make yourself do it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you know why you aren’t motivated, you can think about what you could change to make things easier on yourself. What factors do you have control over?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Environment - Is there a place you can go or a thing you can add that will make it feel easier? For example, I have my writing desk set up in a quiet corner of my bedroom (not the office I share with my husband) to help make writing easier, even when I am not feeling it.&lt;/item&gt;
      &lt;item&gt;Mood - Is there something that will help boost your mood? Go for a ten-minute walk, treat yourself to a donut, text your best friend for a pep talk, turn on your favourite tunes… anything that will give you a little pick-me-up.&lt;/item&gt;
      &lt;item&gt;Body - Are there things you can do to take care of your body to make it feel better? Try some stretching, take a nap, meditate, read a book, get some fresh air, go for a run, eat a comfort meal, or do anything that will help your body feel less stressed.&lt;/item&gt;
      &lt;item&gt;Negative or fear motivators - Is the thing you are not motivated to do being motivated by negative or fear motivators? These include things like fear of judgment, fear of conflict, shame, guilt, or obligation. These motivators only go so far and deserve further examination to determine their place in your priorities. Maybe they aren’t things you need to do in the first place.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The key point here is to identify where you have control and where you don’t, and then do your best to adapt your circumstances to make it easier to take action.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Identify what does motivate you&lt;/head&gt;
    &lt;p&gt;When you think about the various activities and tasks you do each day, what is it that encourages you to do them? Some of those things will be negative motivators, as I mentioned above, but others will be things you do for fun, because they are interesting or rewarding. These are some tactics to consider for things that might help motivate you:&lt;/p&gt;
    &lt;head rend="h3"&gt;Combine the task with something you enjoy&lt;/head&gt;
    &lt;p&gt;You know what makes cleaning out the garage a lot better? Some good tunes. Throw on an audiobook while you cook dinner. Watch a good show while you huff and puff on the air bike! Think about the things you enjoy and consider how you can combine them with the thing you're trying to motivate yourself to do.&lt;/p&gt;
    &lt;head rend="h3"&gt;Add external accountability&lt;/head&gt;
    &lt;p&gt;Sometimes it can be challenging to push yourself to do something when there are no external motivators. Ask a friend to be your accountability buddy, or hire a professional to help you stay accountable for the thing you're trying to do, such as a coach, trainer, teacher, or dietitian. I know that one of the significant value-added benefits my clients get from working with me for a few months is having someone they have to report back to on their progress!&lt;/p&gt;
    &lt;head rend="h3"&gt;Gamify&lt;/head&gt;
    &lt;p&gt;Is there any way to turn the process or thing you are unmotivated to do into a game? Can you add rewards if you do a certain amount, or set a goal for how many days you make progress in a row? For example, one of my motivators for doing some kind of fitness every day is keeping up my streak! 2817 days in a row as of publishing. 😁&lt;/p&gt;
    &lt;head rend="h3"&gt;Celebrate milestones&lt;/head&gt;
    &lt;p&gt;Beyond small planned rewards, having something to look forward to as you make progress on your task or activity can also help encourage you to continue moving forward. Maybe you take a day off, order your favourite takeout, or simply share it with someone you care about.&lt;/p&gt;
    &lt;p&gt;For more specifics on types of motivation, read my article, What Motivates You? Learn the Types of Motivation and How to Use Them, where I get into more detail about intrinsic and extrinsic motivation.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Break it into smaller chunks&lt;/head&gt;
    &lt;p&gt;If part of why you feel unmotivated is that what you need to do feels big and overwhelming, often the best thing you can do is try to break it down into smaller, more manageable pieces. What is the smallest amount you can do to make a bit of progress?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Commit to spending 5 minutes on it&lt;/item&gt;
      &lt;item&gt;Choose a small corner of a room you need to clean&lt;/item&gt;
      &lt;item&gt;Commit to writing the outline&lt;/item&gt;
      &lt;item&gt;Write the text, even if you don’t send it&lt;/item&gt;
      &lt;item&gt;Plan in your calendar when you will do it, so you don’t have it sitting in the back of your mind&lt;/item&gt;
      &lt;item&gt;Talk about it with your partner or a friend&lt;/item&gt;
      &lt;item&gt;Switch tasks to take a break and come back to it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Often, getting over the hump of starting something is enough to help push you through it. Even if it isn’t, at the very least, you have made some amount of progress, which you can build on.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Consistency over motivation&lt;/head&gt;
    &lt;p&gt;If the thing you need to do is something you need to do regularly, like writing, fitness, practicing an instrument, or cleaning, you can’t rely purely on motivation to drive you. Even for things you enjoy, it’s easy to push something off “until you feel like it”. But with so many factors affecting your mood and energy, the times when you feel like it will be fleeting. Instead of relying on motivation, try to establish a routine that fosters consistency.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Plan your intentional week so you have an idea of when you intend to do it&lt;/item&gt;
      &lt;item&gt;Set a daily reminder&lt;/item&gt;
      &lt;item&gt;Book it in your calendar&lt;/item&gt;
      &lt;item&gt;Set a certain amount of time you will put aside each day or week to chip away at it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A little bit, consistently, will go a long way.&lt;/p&gt;
    &lt;head rend="h2"&gt;5. Put it on the back burner&lt;/head&gt;
    &lt;p&gt;Sometimes, when you are not feeling motivated to do something, it’s reasonable to just put it on the back burner. Maybe it’s just not a priority right now, and that’s totally fine! Ask yourself, is this a glass ball or a plastic ball? If it’s plastic, set it aside for a bit and focus your time and energy on other things.&lt;/p&gt;
    &lt;p&gt;It's ok to decide now is not the right time, but make it an intentional decision instead of something you avoid and feel bad about!&lt;/p&gt;
    &lt;p&gt;If you're struggling with motivation, you're not alone! It’s normal, it’s natural, and there are tons of different, ever-changing factors that will change how you feel. Do your best to examine where you are at, control what you can control, and make progress where you can!&lt;/p&gt;
    &lt;p&gt;Need some help getting motivated? Get in touch!&lt;/p&gt;
    &lt;head rend="h4"&gt;Share&lt;/head&gt;
    &lt;head rend="h4"&gt;Ashley Janssen&lt;/head&gt;
    &lt;p&gt;Productivity consultant, writer, speaker, serial entrepreneur, chaos calmer, introvert, cat-lady. Lover of books, fitness, old fashioned’s, basketball, and video games.&lt;/p&gt;
    &lt;p&gt; Follow me on Twitter or LinkedIn. &lt;lb/&gt; Hire me for 1 on 1 productivity consulting or speaking. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45276987</guid><pubDate>Wed, 17 Sep 2025 15:25:24 +0000</pubDate></item><item><title>Microsoft Python Driver for SQL Server</title><link>https://github.com/microsoft/mssql-python</link><description>&lt;doc fingerprint="a71aaa5affc2d9d6"&gt;
  &lt;main&gt;
    &lt;p&gt;mssql-python is a Python driver for Microsoft SQL Server and the Azure SQL family of databases. It leverages Direct Database Connectivity (DDBC) that enables direct connections to SQL Server without requiring an external driver manager. Designed to comply with the DB API 2.0 specification, this driver also introduces Pythonic enhancements for improved usability and functionality. It supports a full range of database operations, including connection management, query execution, and transaction handling.&lt;/p&gt;
    &lt;p&gt;The driver is compatible with all the Python versions &amp;gt;= 3.10&lt;/p&gt;
    &lt;p&gt;Documentation | Release Notes | Roadmap&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: This project is currently in Public Preview, meaning it is still under active development. We are working on core functionalities and gathering more feedback before GA. Please use with caution and avoid production environments.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Windows: mssql-python can be installed with pip&lt;/p&gt;
    &lt;code&gt;pip install mssql-python&lt;/code&gt;
    &lt;p&gt;MacOS: mssql-python can be installed with pip&lt;/p&gt;
    &lt;code&gt;# For Mac, OpenSSL is a pre-requisite - skip if already present
brew install openssl
pip install mssql-python&lt;/code&gt;
    &lt;p&gt;Linux: mssql-python can be installed with pip&lt;/p&gt;
    &lt;code&gt;# For Alpine
apk add libtool krb5-libs krb5-dev

# For Debian/Ubuntu  
apt-get install -y libltdl7 libkrb5-3 libgssapi-krb5-2

# For RHEL
dnf install -y libtool-ltdl krb5-libs

# For SUSE
zypper install -y libltdl7 libkrb5-3 libgssapi-krb5-2

# For SUSE/openSUSE
zypper install -y libltdl7

pip install mssql-python&lt;/code&gt;
    &lt;p&gt;Windows, MacOS and Linux (manylinux - Debian, Ubuntu, RHEL, SUSE (x64 only) &amp;amp; musllinux - Alpine)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: SUSE Linux ARM64 is not supported by Microsoft ODBC Driver. Use x64 architecture for SUSE deployments.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Microsoft mssql-python module is designed to be fully compliant with the DB API 2.0 specification. This ensures that the driver adheres to a standardized interface for database access in Python, providing consistency and reliability across different database systems. Key aspects of DBAPI v2.0 compliance include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Connection Objects: Establishing and managing connections to the database.&lt;/item&gt;
      &lt;item&gt;Cursor Objects: Executing SQL commands and retrieving results.&lt;/item&gt;
      &lt;item&gt;Transaction Management: Supporting commit and rollback operations to ensure data integrity.&lt;/item&gt;
      &lt;item&gt;Error Handling: Providing a consistent set of exceptions for handling database errors.&lt;/item&gt;
      &lt;item&gt;Parameter Substitution: Allowing the use of placeholders in SQL queries to prevent SQL injection attacks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By adhering to the DB API 2.0 specification, the mssql-python module ensures compatibility with a wide range of Python applications and frameworks, making it a versatile choice for developers working with Microsoft SQL Server, Azure SQL Database, and Azure SQL Managed Instance.&lt;/p&gt;
    &lt;p&gt;The Microsoft mssql-python driver enables Python applications to connect to Microsoft SQL Server, Azure SQL Database, or Azure SQL Managed Instance using Microsoft Entra ID identities. It supports a variety of authentication methods, including username and password, Microsoft Entra managed identity (system-assigned and user-assigned), Integrated Windows Authentication in a federated, domain-joined environment, interactive authentication via browser, device code flow for environments without browser access, and the default authentication method based on environment and configuration. This flexibility allows developers to choose the most suitable authentication approach for their deployment scenario.&lt;/p&gt;
    &lt;p&gt;EntraID authentication is now fully supported on MacOS and Linux but with certain limitations as mentioned in the table:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Authentication Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Windows Support&lt;/cell&gt;
        &lt;cell role="head"&gt;macOS/Linux Support&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryPassword&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Username/password-based authentication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryInteractive&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Interactive login via browser; requires user interaction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryMSI (Managed Identity)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;For Azure VMs/containers with managed identity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryServicePrincipal&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Use client ID and secret or certificate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryIntegrated&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Only works on Windows (requires Kerberos/SSPI)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ActiveDirectoryDeviceCode&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Device code flow for authentication; suitable for environments without browser access&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ActiveDirectoryDefault&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Uses default authentication method based on environment and configuration&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;For more information on Entra ID please refer this document&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The driver offers a suite of Pythonic enhancements that streamline database interactions, making it easier for developers to execute queries, manage connections, and handle data more efficiently.&lt;/p&gt;
    &lt;p&gt;The Microsoft mssql_python driver provides built-in support for connection pooling, which helps improve performance and scalability by reusing active database connections instead of creating a new connection for every request. This feature is enabled by default. For more information, refer Connection Pooling Wiki.&lt;/p&gt;
    &lt;p&gt;Connect to SQL Server and execute a simple query:&lt;/p&gt;
    &lt;code&gt;import mssql_python
 
# Establish a connection
# Specify connection string
connection_string = "SERVER=&amp;lt;your_server_name&amp;gt;;DATABASE=&amp;lt;your_database_name&amp;gt;;UID=&amp;lt;your_user_name&amp;gt;;PWD=&amp;lt;your_password&amp;gt;;Encrypt=yes;"
connection = mssql_python.connect(connection_string)
 
# Execute a query
cursor = connection.cursor()
cursor.execute("SELECT * from customer")
rows = cursor.fetchall()
 
for row in rows:
    print(row)
 
# Close the connection
connection.close()
 &lt;/code&gt;
    &lt;p&gt;Check out our FAQ. Still not answered? Create an issue to ask a question.&lt;/p&gt;
    &lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.&lt;/p&gt;
    &lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt;
    &lt;p&gt;This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.&lt;/p&gt;
    &lt;p&gt;The mssql-python driver for SQL Server is licensed under the MIT license, except the dynamic-link libraries (DLLs) in the libs folder that are licensed under MICROSOFT SOFTWARE LICENSE TERMS.&lt;/p&gt;
    &lt;p&gt;Please review the LICENSE file for more details.&lt;/p&gt;
    &lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45277023</guid><pubDate>Wed, 17 Sep 2025 15:28:25 +0000</pubDate></item><item><title>Launch HN: RunRL (YC X25) – Reinforcement learning as a service</title><link>https://runrl.com</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45277704</guid><pubDate>Wed, 17 Sep 2025 16:13:00 +0000</pubDate></item><item><title>Event Horizon Labs (YC W24) Is Hiring</title><link>https://www.ycombinator.com/companies/event-horizon-labs/jobs/U6oyyKZ-founding-engineer-at-event-horizon-labs</link><description>&lt;doc fingerprint="a34a90db072aed8a"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;At Event Horizon Labs, we’re building an autonomous system that turns raw compute and data directly into alpha, executing without the friction or bias of human emotion.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You’ll Build&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;High-Concurrency Pipelines&lt;lb/&gt; Architect infrastructure that seamlessly handles thousands of concurrent requests, ensuring consistent performance even at peak load.&lt;/item&gt;
        &lt;item&gt;Robust, Fault-Tolerant Systems&lt;lb/&gt; Build reliable frameworks that gracefully manage the complexity of trading — where resilience and uptime are paramount.&lt;/item&gt;
        &lt;item&gt;Foundational Technology&lt;lb/&gt; As part of our founding team, you’ll have the autonomy to shape core infrastructure decisions and lay the groundwork for future engineers to build upon.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What We’re Looking For&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Top-Tier Systems Design Expertise&lt;lb/&gt; Deep experience with distributed systems, networking, and the art of optimizing database performance at scale.&lt;/item&gt;
        &lt;item&gt;Containerization &amp;amp; Cloud Mastery&lt;lb/&gt; Strong proficiency in Docker, Kubernetes, and modern cloud environments to deploy, monitor, and scale AI infrastructure globally.&lt;/item&gt;
        &lt;item&gt;Proven Record of Scaling &amp;amp; Performance&lt;lb/&gt; Demonstrated ability to push databases and systems to their limits—experience with high concurrency, complex query optimization, and near real-time data processing.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Why EHL?&lt;/head&gt;
      &lt;p&gt;We’re a small, high-caliber group of engineers and researchers obsessed with pushing the boundaries of AI systems. If you’ve been honing your skills at the top echelons of programming, research, or system design—and want to tackle some of the hardest problems in AI infrastructure—this is the team where you can truly stand out.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45278424</guid><pubDate>Wed, 17 Sep 2025 17:00:05 +0000</pubDate></item></channel></rss>