<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 10 Dec 2025 17:43:55 +0000</lastBuildDate><item><title>Why the Sanitizer API is just `setHTML()`</title><link>https://frederikbraun.de/why-sethtml.html</link><description>&lt;doc fingerprint="b6461515102fc885"&gt;
  &lt;main&gt;&lt;p&gt;Sanitizing HTML is the practice of taking a piece of HTML and removing some unwanted elements and attributes. Most often this is done to allow user-generated content with HTML but without causing XSS bugs. When imported from a library, a sanitizer typically looks like this:&lt;/p&gt;&lt;code&gt;const clean = DOMPurify.sanitize(input);
context.innerHTML = clean;
&lt;/code&gt;&lt;p&gt;However, the API that we are building doesn't look like this at all. The core feature of the Sanitizer API is actually just &lt;code&gt;Element.setHTML(input)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This blog post will explain why.&lt;/p&gt;&lt;p&gt;To do so, we have to study the two lines of code from the DOMPurity example above. They result in the following steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Take an input string (and optionally a list of allowed elements as parameter).&lt;/item&gt;&lt;item&gt;Parse the input into an HTML fragment (no context element given).&lt;/item&gt;&lt;item&gt;Traverse the HTML fragment and remove elements as configured.&lt;/item&gt;&lt;item&gt;Serialize the remaining fragment into a string.&lt;/item&gt;&lt;item&gt;Parse the sanitized string (again), this time with &lt;code&gt;context&lt;/code&gt;as context node into a fragment.&lt;/item&gt;&lt;item&gt;Insert the new fragment below &lt;code&gt;context&lt;/code&gt;in the DOM tree.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Quick exercise for the reader: Can you spot where line 1 (&lt;code&gt;DOMPurify.sanitize()&lt;/code&gt;)
stops and line 2 (the &lt;code&gt;innerHTML&lt;/code&gt; assignment) starts?&lt;/p&gt;&lt;head&gt;Solution&lt;/head&gt;&lt;code&gt;DOMPurify.sanitize()&lt;/code&gt; includes steps 1 through 4. The
  &lt;code&gt;innerHTML&lt;/code&gt; assignment.
  is steps 5-6.
&lt;p&gt;This is pretty similar to the Sanitizer that I wanted to build into the browser:&lt;/p&gt;&lt;code&gt;const mySanitizer = new Sanitizer(/* config */);
//XXX This never shipped.
context.innerHTML = Sanitizer.sanitize(input);
&lt;/code&gt;&lt;p&gt;But that is NOT the Sanitizer we ended up with.&lt;/p&gt;&lt;p&gt;And the reason is essentially Mutated XSS (mXSS). To quickly recap, the idea behind mXSS is that HTML parsing is not stable and a line of HTML being parsed and serialized and parsed again may turn into something rather different. (See this description of mXSS bugs collected by SonarSource if you need a refresher.)&lt;/p&gt;&lt;p&gt;Another key point with mXSS is that HTML parsing can be quite context-sensitive: How an input string will be interpreted depends on the current node it is being inserted into.&lt;/p&gt;&lt;p&gt;Now let's go back to the algorithm steps 1-6. Did you notice that step 2 and 5 both perform HTML parsing? DOMPurify and most other sanitizers do this without any supplied context element. Typically, they parse into a new document and only return the content of the resulting &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;. The second parse step
(step 5), however, does include a context element.&lt;/p&gt;&lt;p&gt;This means that we are parsing the input subtly different each time. We accidentally built a weird machine that will turn HTML into mXSS.&lt;/p&gt;&lt;p&gt;A better HTML sanitizer therefore needs to do away with all of that. How about the following:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Use the right context when parsing HTML input.&lt;/item&gt;&lt;item&gt;Remove the need for parsing twice.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Starting from an API design with a constructor like &lt;code&gt;new Sanitizer()&lt;/code&gt;,
it felt pretty hard to think of a context-sensitive method.
I wanted something like &lt;code&gt;Sanitizer.sanitize(input, context)&lt;/code&gt;.
But how would we actually ensure that the return value can not be used another,
potentially wrong &lt;code&gt;context&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;What we settled on was an API that has no return value:&lt;/p&gt;&lt;code&gt;context.setHTML(input, {sanitizer: ... } );
&lt;/code&gt;&lt;p&gt;The internal algorithm is now the following:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Parse the input (with the right context element) into a document fragment&lt;/item&gt;&lt;item&gt;Traverse the resulting fragment and sanitize. (Using safe defaults or a user-specified configuration).&lt;/item&gt;&lt;item&gt;Replace the child nodes below &lt;code&gt;context&lt;/code&gt;with the sanitized up fragment.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;No superfluous parsing. No ambiguous contexts. Just setting HTML.&lt;/p&gt;&lt;p&gt;As a nice side-effect, you can replace existing code in the style of &lt;code&gt;ctx.innerHTML = input&lt;/code&gt; with &lt;code&gt;context.setHTML(input)&lt;/code&gt; and it should just work
the same.&lt;/p&gt;&lt;p&gt;Except that there's no XSS.&lt;/p&gt;&lt;p&gt;To learn more about the Sanitizer API, please continue on MDN, in the Sanitizer Playground, or the Specification).&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46198606</guid><pubDate>Mon, 08 Dec 2025 22:37:28 +0000</pubDate></item><item><title>Mistral releases Devstral2 and Mistral Vibe CLI</title><link>https://mistral.ai/news/devstral-2-vibe-cli</link><description>&lt;doc fingerprint="2d578ecf80ffd806"&gt;
  &lt;main&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;code&gt;██████████████████&lt;/code&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;quote&gt;██████████████████&lt;/quote&gt;
    &lt;p&gt;Devstral2&lt;/p&gt;
    &lt;p&gt;Mistral Vibe CLI&lt;/p&gt;
    &lt;p&gt;State-of-the-art, open-source agentic coding models and CLI agent.&lt;/p&gt;
    &lt;p&gt;█░ Date: Dec 9, 2025&lt;/p&gt;
    &lt;p&gt;█░ Category: Research&lt;/p&gt;
    &lt;p&gt;█░ Author: Mistral AI&lt;/p&gt;
    &lt;head rend="h3"&gt;Content&lt;/head&gt;
    &lt;p&gt;Today, we're releasing Devstral 2—our next-generation coding model family available in two sizes: Devstral 2 (123B) and Devstral Small 2 (24B). Devstral 2 ships under a modified MIT license, while Devstral Small 2 uses Apache 2.0. Both are open-source and permissively licensed to accelerate distributed intelligence.&lt;/p&gt;
    &lt;p&gt;Devstral 2 is currently free to use via our API.&lt;/p&gt;
    &lt;p&gt;We are also introducing Mistral Vibe, a native CLI built for Devstral that enables end-to-end code automation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights.&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Devstral 2: SOTA open model for code agents with a fraction of the parameters of its competitors and achieving 72.2% on SWE-bench Verified.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Up to 7x more cost-efficient than Claude Sonnet at real-world tasks.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mistral Vibe CLI: Native, open-source agent in your terminal solving software engineering tasks autonomously.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Devstral Small 2: 24B parameter model available via API or deployable locally on consumer hardware.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Compatible with on-prem deployment and custom fine-tuning.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Devstral: the next generation of SOTA coding.&lt;/head&gt;
    &lt;p&gt;Devstral 2 is a 123B-parameter dense transformer supporting a 256K context window. It reaches 72.2% on SWE-bench Verified—establishing it as one of the best open-weight models while remaining highly cost efficient. Released under a modified MIT license, Devstral sets the open state-of-the-art for code agents.&lt;/p&gt;
    &lt;p&gt;Devstral Small 2 scores 68.0% on SWE-bench Verified, and places firmly among models up to five times its size while being capable of running locally on consumer hardware.&lt;/p&gt;
    &lt;p&gt;Devstral 2 (123B) and Devstral Small 2 (24B) are 5x and 28x smaller than DeepSeek V3.2, and 8x and 41x smaller than Kimi K2—proving that compact models can match or exceed the performance of much larger competitors. Their reduced size makes deployment practical on limited hardware, lowering barriers for developers, small businesses, and hobbyists.hardware.&lt;/p&gt;
    &lt;head rend="h3"&gt;Built for production-grade workflows.&lt;/head&gt;
    &lt;p&gt;Devstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems.&lt;/p&gt;
    &lt;p&gt;The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases.&lt;/p&gt;
    &lt;p&gt;We evaluated Devstral 2 against DeepSeek V3.2 and Claude Sonnet 4.5 using human evaluations conducted by an independent annotation provider, with tasks scaffolded through Cline. Devstral 2 shows a clear advantage over DeepSeek V3.2, with a 42.8% win rate versus 28.6% loss rate. However, Claude Sonnet 4.5 remains significantly preferred, indicating a gap with closed-source models persists.&lt;/p&gt;
    &lt;p&gt;“Devstral 2 is at the frontier of open-source coding models. In Cline, it delivers a tool-calling success rate on par with the best closed models; it's a remarkably smooth driver. This is a massive contribution to the open-source ecosystem.” — Cline.&lt;/p&gt;
    &lt;p&gt;“Devstral 2 was one of our most successful stealth launches yet, surpassing 17B tokens in the first 24 hours. Mistral AI is moving at Kilo Speed with a cost-efficient model that truly works at scale.” — Kilo Code.&lt;/p&gt;
    &lt;p&gt;Devstral Small 2, a 24B-parameter model with the same 256K context window and released under Apache 2.0, brings these capabilities to a compact, locally deployable form. Its size enables fast inference, tight feedback loops, and easy customization—with fully private, on-device runtime. It also supports image inputs, and can power multimodal agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mistral Vibe CLI.&lt;/head&gt;
    &lt;p&gt;Mistral Vibe CLI is an open-source command-line coding assistant powered by Devstral. It explores, modifies, and executes changes across your codebase using natural language—in your terminal or integrated into your preferred IDE via the Agent Communication Protocol. It is released under the Apache 2.0 license.&lt;/p&gt;
    &lt;p&gt;Vibe CLI provides an interactive chat interface with tools for file manipulation, code searching, version control, and command execution. Key features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Project-aware context: Automatically scans your file structure and Git status to provide relevant context&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smart references: Reference files with @ autocomplete, execute shell commands with !, and use slash commands for configuration changes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-file orchestration: Understands your entire codebase—not just the file you're editing—enabling architecture-level reasoning that can halve your PR cycle time&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Persistent history, autocompletion, and customizable themes.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can run Vibe CLI programmatically for scripting, toggle auto-approval for tool execution, configure local models and providers through a simple config.toml, and control tool permissions to match your workflow.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started.&lt;/head&gt;
    &lt;p&gt;Devstral 2 is currently offered free via our API. After the free period, the API pricing will be $0.40/$2.00 per million tokens (input/output) for Devstral 2 and $0.10/$0.30 for Devstral Small 2.&lt;/p&gt;
    &lt;p&gt;We’ve partnered with leading, open agent tools Kilo Code and Cline to bring Devstral 2 to where you already build.&lt;/p&gt;
    &lt;p&gt;Mistral Vibe CLI is available as an extension in Zed, so you can use it directly inside your IDE.&lt;/p&gt;
    &lt;head rend="h3"&gt;Recommended deployment for Devstral.&lt;/head&gt;
    &lt;p&gt;Devstral 2 is optimized for data center GPUs and requires a minimum of 4 H100-class GPUs for deployment. You can try it today on build.nvidia.com. Devstral Small 2 is built for single-GPU operation and runs across a broad range of NVIDIA systems, including DGX Spark and GeForce RTX. NVIDIA NIM support will be available soon.&lt;/p&gt;
    &lt;p&gt;Devstral Small runs on consumer-grade GPUs as well as CPU-only configurations with no dedicated GPU required.&lt;/p&gt;
    &lt;p&gt;For optimal performance, we recommend a temperature of 0.2 and following the best practices defined for Mistral Vibe CLI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact us.&lt;/head&gt;
    &lt;p&gt;We’re excited to see what you will build with Devstral 2, Devstral Small 2, and Vibe CLI!&lt;/p&gt;
    &lt;p&gt;Share your projects, questions, or discoveries with us on X/Twitter, Discord, or GitHub.&lt;/p&gt;
    &lt;head rend="h2"&gt;We’re hiring!&lt;/head&gt;
    &lt;p&gt;If you’re interested in shaping open-source research and building world-class interfaces that bring truly open, frontier AI to users, we welcome you to apply to join our team.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205437</guid><pubDate>Tue, 09 Dec 2025 14:45:01 +0000</pubDate></item><item><title>Show HN: Gemini Pro 3 imagines the HN front page 10 years from now</title><link>https://dosaygo-studio.github.io/hn-front-page-2035/news</link><description>&lt;doc fingerprint="a461ad970e1c7920"&gt;
  &lt;main&gt;
    &lt;p&gt;Y Hacker News new | past | comments | ask | show | jobs | submit login 1. First successful telemetry from Starship HLS-9 on the Sea of Tranquility ( spacex.com ) 894 points by muskwatch 4 hours ago | hide | 312 comments 2. A 100% Rust kernel is now upstream in Linux 7.4 ( kernel.org ) 402 points by rust_evangelist 6 hours ago | hide | 156 comments 3. Why I still write raw code instead of prompting the compiler ( nostalgic-coder.io ) 128 points by oldtimer99 3 hours ago | hide | 89 comments 4. Running LLaMA-12 7B on a contact lens with WASM ( arxiv.org ) 67 points by edge_compute 2 hours ago | hide | 14 comments 5. Show HN: AlgoDrill – Interactive drills to stop forgetting LeetCode patterns ( algodrill.io ) 243 points by persistence_is_key 5 hours ago | hide | 98 comments 6. ITER achieves net positive energy for 20 consecutive minutes ( nature.com ) 1205 points by physics_lover 12 hours ago | hide | 402 comments 7. Restoring a 2024 Framework Laptop: A retrospective ( ifixit.com ) 56 points by retro_fix 4 hours ago | hide | 22 comments 8. Google kills Gemini Cloud Services ( killedbygoogle.com ) 530 points by dang_fan 15 hours ago | hide | 330 comments 9. Visualizing the 5th dimension with WebGPU 2.0 ( graphics-shader.net ) 88 points by webgl_wizard 7 hours ago | hide | 12 comments 10. Launch HN: Nia (YC W36) – Give context to autonomous coding agents ( trynia.ai ) 112 points by founder_jane 10 hours ago | hide | 45 comments 11. Debian 18 "Trixie" released ( debian.org ) 312 points by apt_get 14 hours ago | hide | 78 comments 12. Is it time to rewrite sudo in Zig? ( github.com ) 45 points by ziggy42 3 hours ago | hide | 60 comments 13. EU passes "Right to Human Verification" Act ( europa.eu ) 670 points by policy_wonk 1 day ago | hide | 290 comments 14. Reverse Engineering the Neuralink V4 Bluetooth Protocol ( brain-hacks.org ) 220 points by cyborg_sec 8 hours ago | hide | 55 comments 15. Post-Silicon Computing: An Intro to Photonic Circuits ( mit.edu ) 99 points by lightspeed 6 hours ago | hide | 18 comments 16. FDA approves over-the-counter CRISPR for lactose intolerance ( fda.gov ) 415 points by bio_hacker 16 hours ago | hide | 211 comments 17. SQLite 4.0 Release Notes ( sqlite.org ) 800 points by drh 20 hours ago | hide | 140 comments 18. Ask HN: How do you prevent ad-injection in AR glasses? 320 points by glasshole2 11 hours ago | hide | 102 comments 19. Jepsen: NATS 4.2 (Still losing messages?) ( jepsen.io ) 88 points by aphyr_bot 9 hours ago | hide | 33 comments 20. Playing GTA VI on a RISC-V Cluster ( youtube.com ) 45 points by tlyleung 2 hours ago | hide | 16 comments 21. Why functional programming is the future (again) ( haskell.org ) 102 points by monad_lover 7 hours ago | hide | 65 comments 22. Microsoft Office 365 prices increase to $40/user/month ( officewatch.com ) 900 points by taubek 1 day ago | hide | 600 comments 23. Emulating Windows 10 in the browser ( bellard.org ) 341 points by qemu_fan 19 hours ago | hide | 50 comments 24. Let's put Tailscale on a SpaceX Starlink Dish ( tailscale.com ) 250 points by net_hacker 20 hours ago | hide | 45 comments 25. Manual: Deep Fakes detection for Seniors ( aarp.org ) 122 points by concerned_grandson 21 hours ago | hide | 77 comments 26. IBM to acquire OpenAI (Rumor) ( bloomberg.com ) 120 points by stock_watcher 1 day ago | hide | 338 comments 27. The unexpected return of server-side rendering ( htmx.org ) 147 points by bikenaga 19 hours ago | hide | 48 comments 28. How to build a Faraday Cage for your bedroom ( privacy-first.com ) 267 points by tinfoil_hat 22 hours ago | hide | 49 comments 29. AI progress is stalling. Human equivalence was a mirage ( garymarcus.com ) 485 points by skeptic_ai 14 hours ago | hide | 416 comments 30. Show HN: A text editor that doesn't use AI ( github.com ) 270 points by pure_coder 22 hours ago | hide | 105 comments More Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact Search:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205632</guid><pubDate>Tue, 09 Dec 2025 15:00:38 +0000</pubDate></item><item><title>Bruno Simon – 3D Portfolio</title><link>https://bruno-simon.com/</link><description>&lt;doc fingerprint="e43305f6f9f2bf3"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00:000&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Welcome!&lt;/p&gt;
    &lt;p&gt;My name is Bruno Simon, and I'm a creative developer (mostly for the web).&lt;/p&gt;
    &lt;p&gt;This is my portfolio. Please drive around to learn more about me and discover the many secrets of this world.&lt;/p&gt;
    &lt;p&gt;And don't break anything!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Audio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Quality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;I'm stuck!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Renderer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Server&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WASD or ARROWS&lt;/cell&gt;
        &lt;cell&gt;Move around&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SHIFT&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CTRL LEFT or B&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SPACE&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ENTER&lt;/cell&gt;
        &lt;cell&gt;Interact&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;M&lt;/cell&gt;
        &lt;cell&gt;Map&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;L&lt;/cell&gt;
        &lt;cell&gt;Mute&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;T&lt;/cell&gt;
        &lt;cell&gt;Post a whisper&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;R&lt;/cell&gt;
        &lt;cell&gt;Respawn&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NUM KEYS/NUM PAD&lt;/cell&gt;
        &lt;cell&gt;Activate hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LEFT CLICK (DRAG)&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;H&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;One finger&lt;/cell&gt;
        &lt;cell&gt;Move the car&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Two fingers&lt;/cell&gt;
        &lt;cell&gt;Move camera / zoom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tap (on the car)&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Interact / Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LT L2&lt;/cell&gt;
        &lt;cell&gt;Accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RT R2&lt;/cell&gt;
        &lt;cell&gt;Backward accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB / RB L1 / R1&lt;/cell&gt;
        &lt;cell&gt;Hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left&lt;/cell&gt;
        &lt;cell&gt;Turn wheels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left (press)&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right (press)&lt;/cell&gt;
        &lt;cell&gt;Zoom in/out&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Select&lt;/cell&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Start&lt;/cell&gt;
        &lt;cell&gt;Pause&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Resets in&lt;/p&gt;
    &lt;p&gt;Whispers are messages left by visitors.&lt;/p&gt;
    &lt;p&gt; - Everyone can see them&lt;lb/&gt; - New whispers remove old ones (max 30)&lt;lb/&gt; - One whisper per user&lt;lb/&gt; - Choose a flag&lt;lb/&gt; - No slur!&lt;lb/&gt; - Max 30 characters &lt;/p&gt;
    &lt;p&gt;Server currently offline&lt;/p&gt;
    &lt;p&gt; Thank you for visiting my portfolio! &lt;lb/&gt;If you are curious about the stack and how I built it, hereâs everything you need to know. &lt;/p&gt;
    &lt;p&gt; Three.js is the library Iâm using to render this 3D world. &lt;lb/&gt;It was created by mr.doob (X, GitHub), followed by hundreds of awesome developers, one of which being Sunag (X, GitHub) who added TSL, enabling the use of both WebGL and WebGPU, making this portfolio possible. &lt;/p&gt;
    &lt;p&gt; If you want to learn Three.js, I got you covered with this huge course. &lt;lb/&gt;It contains everything you need to start building awesome stuff with Three.js (and much more). &lt;/p&gt;
    &lt;p&gt; Iâve been making devlogs since the very start of this portfolio and you can find them on my Youtube channel. &lt;lb/&gt;Even though the portfolio is out, Iâm still working on the last videos so that the series is complete. &lt;/p&gt;
    &lt;p&gt; The code is available on GitHub under MIT license. Even the Blender files are there, so have fun! &lt;lb/&gt;For security reasons, Iâm not sharing the server code, but the portfolio works without it. &lt;/p&gt;
    &lt;p&gt; The music you hear was made especially for this portfolio by the awesome Kounine (Linktree). &lt;lb/&gt;They are now under CC0 license, meaning you can do whatever you want with them! &lt;lb/&gt;Download them here. &lt;/p&gt;
    &lt;p&gt;â Bruno&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Come hang out with the community, show us your projects and ask us anything.&lt;/p&gt;
    &lt;p&gt;Contact me directly.&lt;lb/&gt;I have to warn you, I try to answer everyone, but it might take a while.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46206531</guid><pubDate>Tue, 09 Dec 2025 16:06:58 +0000</pubDate></item><item><title>PeerTube is recognized as a digital public good by Digital Public Goods Alliance</title><link>https://www.digitalpublicgoods.net/r/peertube</link><description>&lt;doc fingerprint="95773f811edde224"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PeerTube&lt;/head&gt;
    &lt;p&gt;Verified DPG&lt;/p&gt;
    &lt;head rend="h3"&gt;Owner&lt;/head&gt;
    &lt;p&gt;Framasoft&lt;/p&gt;
    &lt;head rend="h3"&gt;Type&lt;/head&gt;
    &lt;p&gt;backend, mobile, web&lt;/p&gt;
    &lt;head rend="h3"&gt;Licence&lt;/head&gt;
    &lt;p&gt;AGPL-3.0&lt;/p&gt;
    &lt;head rend="h3"&gt;Last evaluated&lt;/head&gt;
    &lt;p&gt;07.10.2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Origin country&lt;/head&gt;
    &lt;p&gt;France&lt;/p&gt;
    &lt;head rend="h3"&gt;Release date&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;DPG since&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;PeerTube is a tool for hosting, managing, and sharing videos or live streams.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core Components Assessed/Included Repositories&lt;/head&gt;
    &lt;p&gt;The following repositories were submitted by the solution and included in our evaluation. Any repositories, add-ons, features not included in here were not reviewed by us.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feature&lt;/head&gt;
    &lt;head rend="h3"&gt;Scale of the Solution*&lt;/head&gt;
    &lt;head rend="h3"&gt;Connected members&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Participated Programs&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Available Languages&lt;/head&gt;
    &lt;p&gt;Esperanto, English, Slovenčina, Gàidhlig, العربية, Norsk, Magyar, Deutsch, Toki Pona, Euskara, Polski, Português (Portugal), Suomi, Tiếng Việt, Italiano, فارسی, Español, Taqbaylit, 简体中文（中国）, Hrvatski, ελληνικά, Occitan, украї́нська мо́ва, Français, ไทย, Türkçe, 繁體中文（台灣）, 日本語, Galego, Íslenska, Svenska, Nederlands, Pусский, bokmål, Čeština, Shqip, Català, Português (Brasil), Norsk nynorsk&lt;/p&gt;
    &lt;head rend="h3"&gt;Organisations using it&lt;/head&gt;
    &lt;p&gt;French Ministry of National Education (~100K videos), Italy’s National Research Council, a few French alternative media, the Weißensee Kunsthochschule in Berlin, as well as the Universität der Künste in the same city, a few universities worldwide, the Blender and Debian projects, and various activist groups&lt;/p&gt;
    &lt;p&gt;* This information is self-reported and updated annually&lt;/p&gt;
    &lt;head rend="h3"&gt;Github insights&lt;/head&gt;
    &lt;p&gt;Learn how this product has met the requirements of the DPG Standard by exploring the indicators below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Application Details&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG ID&lt;/head&gt;
    &lt;head rend="h4"&gt;GID0092472&lt;/head&gt;
    &lt;head rend="h4"&gt;Status&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Created&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-11&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Submitted&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-25&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Reviewed&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-10-07&lt;/head&gt;
    &lt;head rend="h4"&gt;Date of Expiry&lt;/head&gt;
    &lt;head rend="h4"&gt;2026-10-07&lt;/head&gt;
    &lt;head rend="h3"&gt;Application Log Details&lt;/head&gt;
    &lt;head rend="h4"&gt;Timestamp&lt;/head&gt;
    &lt;head rend="h4"&gt;Activity&lt;/head&gt;
    &lt;p&gt;2025-10-07 08:40:13&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) submitted their review of PeerTube (152) and found it to be a DPG&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:12&lt;/p&gt;
    &lt;p&gt;System unmarked PeerTube (12958) as a nominee&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:07&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) passed 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:02&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) moved PeerTube (12958) to under review&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:38:21&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) finished consultation on 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207464</guid><pubDate>Tue, 09 Dec 2025 17:08:37 +0000</pubDate></item><item><title>Australia begins enforcing world-first teen social media ban</title><link>https://www.reuters.com/legal/litigation/australia-social-media-ban-takes-effect-world-first-2025-12-09/</link><description>&lt;doc fingerprint="2d87985519e0dfd9"&gt;
  &lt;main&gt;
    &lt;p&gt;SYDNEY, Dec 10 (Reuters) - Australia on Wednesday became the first country to ban social media for children under 16, blocking access in a move welcomed by many parents and child advocates but criticised by major technology companies and free-speech advocates.&lt;/p&gt;
    &lt;p&gt;Starting at midnight (1300 GMT on Tuesday), 10 of the largest platforms including TikTok, Alphabet's (GOOGL.O) YouTube and Meta's (META.O) Instagram and Facebook were ordered to block children or face fines of up to A$49.5 million ($33 million) under the new law, which is being closely watched by regulators worldwide.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;Prime Minister Anthony Albanese called it "a proud day" for families and cast the law as proof that policymakers can curb online harms that have outpaced traditional safeguards.&lt;/p&gt;
    &lt;p&gt;"This will make an enormous difference. It is one of the biggest social and cultural changes that our nation has faced," Albanese told a news conference on Wednesday.&lt;/p&gt;
    &lt;p&gt;"It's a profound reform which will continue to reverberate around the world."&lt;/p&gt;
    &lt;head rend="h2"&gt;READ A BOOK INSTEAD, PM TELLS YOUNGSTERS&lt;/head&gt;
    &lt;p&gt;In a video message, Albanese urged children to "start a new sport, new instrument, or read that book that has been sitting there for some time on your shelf," ahead of Australia's summer school break starting later this month.&lt;/p&gt;
    &lt;p&gt;Some of those below the cut-off age of 16 were anxious about adjusting to life without social media, but others were less concerned.&lt;/p&gt;
    &lt;p&gt;"I'm not really that emotional about it," said 14-year-old Claire Ni. "I'm kind of just, like, neutral."&lt;/p&gt;
    &lt;p&gt;Luna Dizon, 15, said she still had access to her TikTok, Instagram and Snapchat accounts, but worried about "culture shock" once the ban took full effect.&lt;/p&gt;
    &lt;p&gt;"I think eventually, without (social media), we'll learn how to adapt to it," she added.&lt;/p&gt;
    &lt;head rend="h2"&gt;TEENAGER SIGNS OFF WITH 'SEE YOU WHEN I'M 16'&lt;/head&gt;
    &lt;p&gt;While the government has said the ban would not be perfect in its operation, about 200,000 accounts were deactivated by Wednesday on TikTok alone, with "hundreds of thousands" more to be blocked in the next few days.&lt;/p&gt;
    &lt;p&gt;Many of the estimated 1 million children affected by the legislation also posted goodbye messages on social media.&lt;/p&gt;
    &lt;p&gt;"No more social media ... no more contact with the rest of the world," one teen wrote on TikTok.&lt;/p&gt;
    &lt;p&gt;"#seeyouwhenim16," said another.&lt;/p&gt;
    &lt;p&gt;Others said they would learn how to get round the ban.&lt;/p&gt;
    &lt;p&gt;"It's just kind of pointless, we're just going to create new ways to get on these platforms, so what's the point," said 14-year-old Claire Ni.&lt;/p&gt;
    &lt;head rend="h2"&gt;BAN HAS GLOBAL IMPLICATIONS&lt;/head&gt;
    &lt;p&gt;The rollout caps a year of debate over whether any country could practically stop children from using platforms embedded in daily life, and begins a live test for governments frustrated that social media firms have been slow to implement harm-reduction measures.&lt;/p&gt;
    &lt;p&gt;"I'm happy that they want to protect kids, and I'm happy that we have a chance to see how they do it and see if we can learn from them," said European Union lawmaker Christel Schaldemose, who wants to see greater protection for the bloc's children.&lt;/p&gt;
    &lt;p&gt;Albanese's centre-left government proposed the landmark law citing research showing harms to mental health from the overuse of social media among young teens, including misinformation, bullying and harmful depictions of body image.&lt;/p&gt;
    &lt;p&gt;Several countries from Denmark to New Zealand to Malaysia have signalled they may study or emulate Australia's model.&lt;/p&gt;
    &lt;p&gt;At a school in the German city of Bonn, students spoke favourably of a ban.&lt;/p&gt;
    &lt;p&gt;"Social media is highly addictive and doesn't really have any real advantages. I mean, there are advantages, such as being able to spread your opinion, but I think the disadvantages, especially the addiction, are much worse," said 15-year-old pupil Arian Klaar.&lt;/p&gt;
    &lt;p&gt;Julie Inman Grant, the U.S.-born eSafety Commissioner who is overseeing the ban, told Reuters on Wednesday a groundswell of American parents wanted similar measures.&lt;/p&gt;
    &lt;p&gt;"I hear from the parents and the activists and everyday people in America, 'we wish we had an eSafety commissioner like you in America, we wish we had a government that was going to put tween and teen safety before technology profits,'" she said in an interview at her office in Sydney.&lt;/p&gt;
    &lt;p&gt;'NOT OUR CHOICE': X SAYS WILL COMPLY&lt;/p&gt;
    &lt;p&gt;Elon Musk's X became the last of the 10 major platforms to take measures to cut off access to underage teens after publicly acknowledging on Wednesday that it would comply.&lt;/p&gt;
    &lt;p&gt;"It's not our choice - it's what the Australian law requires," X said on its website.&lt;/p&gt;
    &lt;p&gt;Australia has said the initial list of covered platforms would change as new products emerge and young users migrate.&lt;/p&gt;
    &lt;p&gt;Companies have told Canberra they will deploy a mix of age inference - estimating a user's age from their behaviour - and age estimation based on a selfie, alongside checks that could include uploaded identification documents.&lt;/p&gt;
    &lt;p&gt;For social media businesses, the implementation marks a new era of structural stagnation as user numbers flatline and time spent on platforms shrinks, studies show.&lt;/p&gt;
    &lt;p&gt;Platforms say they earn little from advertising to under-16s, but warn the ban disrupts a pipeline of future users. Just before the ban took effect, 86% of Australians aged eight to 15 used social media, the government said.&lt;/p&gt;
    &lt;p&gt;($1 = 1.5097 Australian dollars)&lt;/p&gt;
    &lt;p&gt;Reporting by Byron Kaye and Renju Jose; Additional reporting by James Redmayne and Cordelia Hsu; Writing by Alasdair Pal, Alexandra Hudson and Christine Chen; Editing by Andrew Heavens, Mark Potter, Lincoln Feast and Deepa Babington&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208348</guid><pubDate>Tue, 09 Dec 2025 18:12:29 +0000</pubDate></item><item><title>Rust in the kernel is no longer experimental</title><link>https://lwn.net/Articles/1049831/</link><description>&lt;doc fingerprint="45d31c5fbc8246f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The (successful) end of the kernel Rust experiment&lt;/head&gt;
    &lt;p&gt; (Stay tuned for details in our Maintainers Summit coverage.)&lt;/p&gt;
    &lt;p&gt; Posted Dec 10, 2025 4:25 UTC (Wed) by ktkaffee (subscriber, #112877) [Link] (17 responses) Posted Dec 10, 2025 4:45 UTC (Wed) by josh (subscriber, #17465) [Link] (11 responses) Posted Dec 10, 2025 4:48 UTC (Wed) by corbet (editor, #1) [Link] (2 responses) Posted Dec 10, 2025 5:24 UTC (Wed) by josh (subscriber, #17465) [Link] (And don't worry, you'd have to fall *very* far, very consistently, to limbo under the low bar Phoronix has set for clickbait.) Posted Dec 10, 2025 6:04 UTC (Wed) by rolexhamster (guest, #158445) [Link] (7 responses) Elitist much? Notwithstanding the low quality user comments on Phoronix and somewhat challenged writing in its news items, the site does provide useful info by way of frequent updates of what's happening in and around the open source ecosystem. Its benchmarks have also uncovered problems in the Linux kernel. In certain ways it's complementary to LWN's coverage. Posted Dec 10, 2025 7:49 UTC (Wed) by Cyberax (✭ supporter ✭, #52523) [Link] (2 responses) Posted Dec 10, 2025 11:09 UTC (Wed) by rossburton (subscriber, #7254) [Link] (1 responses) Fun fact: Clear Linux wins in many of the phoronix benchmarks because the default bashrc does export CFLAGS=-O3. (caveat: this was the case when I was researching what Clear does to get better scores on identical hardware some years ago, but I don't believe anything has changed since then) Posted Dec 10, 2025 17:12 UTC (Wed) by higuita (guest, #32245) [Link] Phoronix benchmarks makes no clain or change, install the system and test... that is the result. if you do not do anything else, expect those results! if you dig in to it, you can finetune more ... but on other end, you also see that "optimized distros" can have much better results in some items, but almost no difference on others, so you also know if it is even worth investing time trying to optimize something or not. For many apps/games, is not worth the time to optimize it more to get 5% or less more performance (and like O3, risk of getting more bugs) A benchmark that tries to optimize every single app is not only lot of work, but also no system and workload is the same, the best option for one setup may not be the best one for another, so that would be always a problem for someone. As for hardware and distros/kernel evolution over time, they are actually very useful, we can see how a new hardware is performing and even postpone buying one a few months, where you get better performance and possible better price also. finally the news, yes, he tends to overreact to some news or rumors, but it got much better with time and for one men show, he actually track way many projects and report back when something happens, so you know things that usually don't show up in other places So yes, phoronix is not perfect, it could be better in some areas, but is good enough, specially being a one men show and not aa team of people. Many of the issues would probably be mitigated if there was more people working as different opinions and reviewing would catch most of the issues or too personal opinions Posted Dec 10, 2025 9:26 UTC (Wed) by lkundrak (subscriber, #43452) [Link] (1 responses) Posted Dec 10, 2025 9:27 UTC (Wed) by lkundrak (subscriber, #43452) [Link] sorry, commenting before my morning frontal lobotomy Posted Dec 10, 2025 11:08 UTC (Wed) by farnz (subscriber, #17727) [Link] Posted Dec 10, 2025 17:36 UTC (Wed) by clump (subscriber, #27801) [Link] I do like that Phoronix can cover useful desktop news. Posted Dec 10, 2025 7:57 UTC (Wed) by alspnost (guest, #2763) [Link] Posted Dec 10, 2025 9:07 UTC (Wed) by adobriyan (subscriber, #30858) [Link] Posted Dec 10, 2025 9:32 UTC (Wed) by evalir (subscriber, #171462) [Link] Posted Dec 10, 2025 13:07 UTC (Wed) by hailfinger (subscriber, #76962) [Link] Posted Dec 10, 2025 14:15 UTC (Wed) by Jedizlapulga (guest, #180979) [Link] Posted Dec 10, 2025 6:32 UTC (Wed) by mrcroxx (guest, #161669) [Link] (2 responses) Posted Dec 10, 2025 13:58 UTC (Wed) by rsidd (subscriber, #2582) [Link] (1 responses) &amp;gt; Mike: rachel and i are (successfully) no longer dating Posted Dec 10, 2025 14:49 UTC (Wed) by jaa (subscriber, #14170) [Link] (as did the emotionally roller-coaster news item) Posted Dec 10, 2025 10:11 UTC (Wed) by cbushey (guest, #142134) [Link] (1 responses) Posted Dec 10, 2025 10:22 UTC (Wed) by cbushey (guest, #142134) [Link] Posted Dec 10, 2025 15:57 UTC (Wed) by stumbles (guest, #8796) [Link] (1 responses) Posted Dec 10, 2025 16:08 UTC (Wed) by farnz (subscriber, #17727) [Link] &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Ouch. That is what I get for pushing something out during a meeting, I guess. That was not my point; the experiment is done, and it was a success. I meant no more than that. &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; &amp;gt; Phoronix would be proud of that headline. &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;lb/&gt; or how much updating the distro may help in some setups.&lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Phoronix also tends to benchmark in the "dumb but obvious" way - just follow the instructions, don't take the time to understand it in depth and tweak obsessively until it's as good as it's going to get. This is useful, because it exposes cases where something is genuinely useful once tweaked into shape, but where the defaults are bad and need fixing. &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Same here - for a second, I thought they were about to rip it all out for v6.20 -&amp;gt; 7.0! &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;lb/&gt; Well done!&lt;head&gt;Jedizlapulga&lt;/head&gt;&lt;head&gt;Meme&lt;/head&gt;&lt;lb/&gt; &amp;gt;&lt;lb/&gt; &amp;gt; rachel: mike that's a horrible way of telling people we're married&lt;head&gt;Meme&lt;/head&gt;&lt;head&gt;Meme&lt;/head&gt;&lt;head&gt;hilarity ensues&lt;/head&gt;&lt;head&gt;I forgot&lt;/head&gt;&lt;head/&gt; Well, guess its time to switch back to Microsoft. &lt;head&gt;I was looking for a reason.&lt;/head&gt;&lt;head/&gt; Bad news in that respect - Microsoft is using Rust in the Windows kernel, too. &lt;head&gt;I was looking for a reason.&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213585</guid><pubDate>Wed, 10 Dec 2025 03:15:24 +0000</pubDate></item><item><title>Revisiting "Let's Build a Compiler"</title><link>https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</link><description>&lt;doc fingerprint="b101145b7036df98"&gt;
  &lt;main&gt;
    &lt;p&gt;There's an old compiler-building tutorial that has become part of the field's lore: the Let's Build a Compiler series by Jack Crenshaw (published between 1988 and 1995).&lt;/p&gt;
    &lt;p&gt;I ran into it in 2003 and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite often in Hacker News threads. Why is that? Why does a tutorial from 35 years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that are virtually unknown for the new generation of programmers - hold sway over compiler enthusiasts? I've decided to find out.&lt;/p&gt;
    &lt;p&gt;The tutorial is easily available and readable online, but just re-reading it seemed insufficient. So I've decided on meticulously translating the compilers built in it to Python and emit a more modern target - WebAssembly. It was an enjoyable process and I want to share the outcome and some insights gained along the way.&lt;/p&gt;
    &lt;p&gt;The result is this code repository. Of particular interest is the TUTORIAL.md file, which describes how each part in the original tutorial is mapped to my code. So if you want to read the original tutorial but play with code you can actually easily try on your own, feel free to follow my path.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sample&lt;/head&gt;
    &lt;p&gt;To get a taste of the input language being compiled and the output my compiler generates, here's a sample program in the KISS language designed by Jack Crenshaw:&lt;/p&gt;
    &lt;code&gt;var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &amp;lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
&lt;/code&gt;
    &lt;p&gt;It's from part 13 of the tutorial, so it showcases procedures along with control constructs like the while loop, and passing parameters both by value and by reference. Here's the WASM text generated by my compiler for part 13:&lt;/p&gt;
    &lt;code&gt;(module
  (memory 8)
  ;; Linear stack pointer. Used to pass parameters by ref.
  ;; Grows downwards (towards lower addresses).
  (global $__sp (mut i32) (i32.const 65536))

  (global $X (mut i32) (i32.const 0))

  (func $ADDSEQ (param $N i32) (param $RESULT i32)
    (local $I i32)
    (local $SUM i32)
    loop $loop1
      block $breakloop1
        local.get $I
        local.get $N
        i32.lt_s
        i32.eqz
        br_if $breakloop1
        local.get $SUM
        local.get $I
        i32.add
        local.set $SUM
        local.get $I
        i32.const 1
        i32.add
        local.set $I
        br $loop1
      end
    end
    local.get $RESULT
    local.get $RESULT
    i32.load
    local.get $SUM
    i32.add
    i32.store
  )

  (func $main (export "main") (result i32)
    i32.const 11
    global.get $__sp      ;; make space on stack
    i32.const 4
    i32.sub
    global.set $__sp
    global.get $__sp
    global.get $X
    i32.store
    global.get $__sp    ;; push address as parameter
    call $ADDSEQ
    ;; restore parameter X by ref
    global.get $__sp
    i32.load offset=0
    global.set $X
    ;; clean up stack for ref parameters
    global.get $__sp
    i32.const 4
    i32.add
    global.set $__sp
    global.get $X
  )
)
&lt;/code&gt;
    &lt;p&gt;You'll notice that there is some trickiness in the emitted code w.r.t. handling the by-reference parameter (my previous post deals with this issue in more detail). In general, though, the emitted code is inefficient - there is close to 0 optimization applied.&lt;/p&gt;
    &lt;p&gt;Also, if you're very diligent you'll notice something odd about the global variable X - it seems to be implicitly returned by the generated main function. This is just a testing facility that makes my compiler easy to test. All the compilers are extensively tested - usually by running the generated WASM code [1] and verifying expected results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insights - what makes this tutorial so special?&lt;/head&gt;
    &lt;p&gt;While reading the original tutorial again, I had on opportunity to reminisce on what makes it so effective. Other than the very fluent and conversational writing style of Jack Crenshaw, I think it's a combination of two key factors:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The tutorial builds a recursive-descent parser step by step, rather than giving a long preface on automata and table-based parser generators. When I first encountered it (in 2003), it was taken for granted that if you want to write a parser then lex + yacc are the way to go [2]. Following the development of a simple and clean hand-written parser was a revelation that wholly changed my approach to the subject; subsequently, hand-written recursive-descent parsers have been my go-to approach for almost 20 years now.&lt;/item&gt;
      &lt;item&gt;Rather than getting stuck in front-end minutiae, the tutorial goes straight to generating working assembly code, from very early on. This was also a breath of fresh air for engineers who grew up with more traditional courses where you spend 90% of the time on parsing, type checking and other semantic analysis and often run entirely out of steam by the time code generation is taught.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To be honest, I don't think either of these are a big problem with modern resources, but back in the day the tutorial clearly hit the right nerve with many people.&lt;/p&gt;
    &lt;head rend="h2"&gt;What else does it teach us?&lt;/head&gt;
    &lt;p&gt;Jack Crenshaw's tutorial takes the syntax-directed translation approach, where code is emitted while parsing, without having to divide the compiler into explicit phases with IRs. As I said above, this is a fantastic approach for getting started, but in the latter parts of the tutorial it starts showing its limitations. Especially once we get to types, it becomes painfully obvious that it would be very nice if we knew the types of expressions before we generate code for them.&lt;/p&gt;
    &lt;p&gt;I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial at some point after part 14, but it may very well be. He keeps writing how the emitted code is clearly sub-optimal [3] and can be improved, but IMHO it's just not that easy to improve using the syntax-directed translation strategy. With perfect hindsight vision, I would probably use Part 14 (types) as a turning point - emitting some kind of AST from the parser and then doing simple type checking and analysis on that AST prior to generating code from it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;All in all, the original tutorial remains a wonderfully readable introduction to building compilers. This post and the GitHub repository it describes are a modest contribution that aims to improve the experience of folks reading the original tutorial today and not willing to use obsolete technologies. As always, let me know if you run into any issues or have questions!&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;This is done using the Python bindings to wasmtime.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;By the way, gcc switched from YACC to hand-written recursive-descent parsing in the 2004-2006 timeframe, and Clang has been implemented with a recursive-descent parser from the start (2007).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Concretely: when we compile subexpr1 + subexpr2 and the two sides have different types, it would be mighty nice to know that before we actually generate the code for both sub-expressions. But the syntax-directed translation approach just doesn't work that way.&lt;/p&gt;
          &lt;p&gt;To be clear: it's easy to generate working code; it's just not easy to generate optimal code without some sort of type analysis that's done before code is actually generated.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46214693</guid><pubDate>Wed, 10 Dec 2025 06:22:19 +0000</pubDate></item><item><title>Factor 0.101 now available</title><link>https://re.factorcode.org/2025/12/factor-0-101-now-available.html</link><description>&lt;doc fingerprint="748063284d11bc94"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Factor 0.101 now available&lt;/head&gt;
    &lt;p&gt;Monday, December 8, 2025&lt;/p&gt;
    &lt;p&gt;“Keep thy airspeed up, lest the earth come from below and smite thee.” - William Kershner&lt;/p&gt;
    &lt;p&gt;I’m very pleased to announce the release of Factor 0.101!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;OS/CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;Windows&lt;/cell&gt;
        &lt;cell role="head"&gt;Mac OS&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;x86&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;x86-64&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Source code: 0.101&lt;/p&gt;
    &lt;p&gt;This release is brought to you with almost 700 commits by the following individuals:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Aleksander Sabak, Andy Kluger, Cat Stevens, Dmitry Matveyev, Doug Coleman, Giftpflanze, John Benediktsson, Jon Harper, Jonas Bernouli, Leo Mehraban, Mike Stevenson, Nicholas Chandoke, Niklas Larsson, Rebecca Kelly, Samuel Tardieu, Stefan Schmiedl, @Bruno-366, @bobisageek, @coltsingleactionarmyocelot, @inivekin, @knottio, @timor&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Besides some bug fixes and library improvements, I want to highlight the following changes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Moved the UI to render buttons and scrollbars rather than using images, which allows easier theming.&lt;/item&gt;
      &lt;item&gt;Fixed HiDPI scaling on Linux and Windows, although it currently doesn’t update the window settings when switching between screens with different scaling factors.&lt;/item&gt;
      &lt;item&gt;Update to Unicode 17.0.0.&lt;/item&gt;
      &lt;item&gt;Plugin support for the Neovim editor.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some possible backwards compatibility issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The argument order to &lt;code&gt;ltake&lt;/code&gt;was swapped to be more consistent with words like&lt;code&gt;head&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;environment&lt;/code&gt;vocabulary on Windows now supports disambiguating&lt;code&gt;f&lt;/code&gt;and&lt;code&gt;""&lt;/code&gt;(empty) values&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/atom&lt;/code&gt;folder was removed in favor of the factor/atom-language-factor repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/Factor.tmbundle&lt;/code&gt;folder was removed in favor of the factor/factor.tmbundle repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/vim&lt;/code&gt;folder was removed in favor of the factor/factor.vim repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;http&lt;/code&gt;vocabulary&lt;code&gt;request&lt;/code&gt;tuple had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;furnace.asides&lt;/code&gt;vocabulary had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;, and might require running&lt;code&gt;ALTER TABLE asides RENAME COLUMN "post-data" TO data;&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;html.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.html&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;pdf.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.pdf&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;What is Factor&lt;/head&gt;
    &lt;p&gt;Factor is a concatenative, stack-based programming language with high-level features including dynamic types, extensible syntax, macros, and garbage collection. On a practical side, Factor has a full-featured library, supports many different platforms, and has been extensively documented.&lt;/p&gt;
    &lt;p&gt;The implementation is fully compiled for performance, while still supporting interactive development. Factor applications are portable between all common platforms. Factor can deploy stand-alone applications on all platforms. Full source code for the Factor project is available under a BSD license.&lt;/p&gt;
    &lt;head rend="h3"&gt;New libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;base92: adding support for Base92 encoding/decoding&lt;/item&gt;
      &lt;item&gt;bitcask: implementing the Bitcask key/value database&lt;/item&gt;
      &lt;item&gt;bluesky: adding support for the BlueSky protocol&lt;/item&gt;
      &lt;item&gt;calendar.holidays.world: adding some new holidays including World Emoji Day&lt;/item&gt;
      &lt;item&gt;classes.enumeration: adding enumeration classes and new &lt;code&gt;ENUMERATION:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;colors.oklab: adding support for OKLAB color space&lt;/item&gt;
      &lt;item&gt;colors.oklch: adding support for OKLCH color space&lt;/item&gt;
      &lt;item&gt;colors.wavelength: adding &lt;code&gt;wavelength&amp;gt;rgba&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;combinators.syntax: adding experimental combinator syntax words &lt;code&gt;@[&lt;/code&gt;,&lt;code&gt;*[&lt;/code&gt;, and&lt;code&gt;&amp;amp;[&lt;/code&gt;, and short-circuiting&lt;code&gt;n&amp;amp;&amp;amp;[&lt;/code&gt;,&lt;code&gt;n||[&lt;/code&gt;,&lt;code&gt;&amp;amp;&amp;amp;[&lt;/code&gt;and&lt;code&gt;||[&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;continuations.extras: adding &lt;code&gt;with-datastacks&lt;/code&gt;and&lt;code&gt;datastack-states&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;dotenv: implementing support for Dotenv files&lt;/item&gt;
      &lt;item&gt;edn: implementing support for Extensible Data Notation&lt;/item&gt;
      &lt;item&gt;editors.cursor: adding support for the Cursor editor&lt;/item&gt;
      &lt;item&gt;editors.rider: adding support for the JetBrains Rider editor&lt;/item&gt;
      &lt;item&gt;gitignore: parser for &lt;code&gt;.gitignore&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;http.json: promoted &lt;code&gt;json.http&lt;/code&gt;and added some useful words&lt;/item&gt;
      &lt;item&gt;io.streams.farkup: a Farkup formatted stream protocol&lt;/item&gt;
      &lt;item&gt;io.streams.markdowns: a Markdown formatted stream protocol&lt;/item&gt;
      &lt;item&gt;locals.lazy: prototype of emit syntax&lt;/item&gt;
      &lt;item&gt;monadics: alternative vocabulary for using Haskell-style monads, applicatives, and functors&lt;/item&gt;
      &lt;item&gt;multibase: implementation of Multibase&lt;/item&gt;
      &lt;item&gt;pickle: support for the Pickle serialization format&lt;/item&gt;
      &lt;item&gt;persistent.hashtables.identity: support an identity-hashcode version of persisent hashtables&lt;/item&gt;
      &lt;item&gt;raylib.live-coding: demo of a vocabulary to do “live coding” of Raylib programs&lt;/item&gt;
      &lt;item&gt;rdap: support for the Registration Data Access Protocol&lt;/item&gt;
      &lt;item&gt;reverse: implementation of the std::flip&lt;/item&gt;
      &lt;item&gt;slides.cli: simple text-based command-line interface for slides&lt;/item&gt;
      &lt;item&gt;tools.highlight: command-line syntax-highlighting tool&lt;/item&gt;
      &lt;item&gt;tools.random: command-line random generator tool&lt;/item&gt;
      &lt;item&gt;ui.pens.rounded: adding rounded corner pen&lt;/item&gt;
      &lt;item&gt;ui.pens.theme: experimental themed pen&lt;/item&gt;
      &lt;item&gt;ui.tools.theme: some words for updating UI developer tools themes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Improved libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;alien.syntax: added &lt;code&gt;C-LIBRARY:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;assocs.extras: added &lt;code&gt;nzip&lt;/code&gt;and&lt;code&gt;nunzip&lt;/code&gt;,&lt;code&gt;map-zip&lt;/code&gt;and&lt;code&gt;map-unzip&lt;/code&gt;macros&lt;/item&gt;
      &lt;item&gt;base32: adding the human-oriented Base32 encoding via &lt;code&gt;zbase32&amp;gt;&lt;/code&gt;and&lt;code&gt;&amp;gt;zbase32&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;base64: minor performance improvement&lt;/item&gt;
      &lt;item&gt;benchmark: adding more benchmarks&lt;/item&gt;
      &lt;item&gt;bootstrap.assembler: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;brainfuck: added &lt;code&gt;BRAINFUCK:&lt;/code&gt;syntax word and&lt;code&gt;interpret-brainfuck&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;bson: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;cache: implement &lt;code&gt;M\ cache-assoc delete-at&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;calendar: adding &lt;code&gt;year&amp;lt;&lt;/code&gt;,&lt;code&gt;year&amp;lt;=&lt;/code&gt;,&lt;code&gt;year&amp;gt;&lt;/code&gt;,&lt;code&gt;year&amp;gt;=&lt;/code&gt;words&lt;/item&gt;
      &lt;item&gt;calendar.format: parse human-readable and elapsed-time output back into duration objects&lt;/item&gt;
      &lt;item&gt;cbor: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;classes.mixin: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.singleton: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.tuple: added &lt;code&gt;tuple&amp;gt;slots&lt;/code&gt;, rename&lt;code&gt;tuple&amp;gt;array&lt;/code&gt;to&lt;code&gt;pack-tuple&lt;/code&gt;and&lt;code&gt;&amp;gt;tuple&lt;/code&gt;to&lt;code&gt;unpack-tuple&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;classes.union: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;checksums.sha: some 20-40% performance improvements&lt;/item&gt;
      &lt;item&gt;command-line: allow passing script name of &lt;code&gt;-&lt;/code&gt;to use stdin&lt;/item&gt;
      &lt;item&gt;command-line.parser: support for Argument Parser Commands&lt;/item&gt;
      &lt;item&gt;command-line.startup: document &lt;code&gt;-q&lt;/code&gt;quiet mode flag&lt;/item&gt;
      &lt;item&gt;concurrency.combinators: faster &lt;code&gt;parallel-map&lt;/code&gt;and&lt;code&gt;parallel-assoc-map&lt;/code&gt;using a count-down latch&lt;/item&gt;
      &lt;item&gt;concurrency.promises: 5-7% performance improvement&lt;/item&gt;
      &lt;item&gt;continuations: improve docs and fix stack effect for &lt;code&gt;ifcc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;countries: adding &lt;code&gt;CQ&lt;/code&gt;country code for Sark&lt;/item&gt;
      &lt;item&gt;cpu.architecture: fix &lt;code&gt;*-branch&lt;/code&gt;stack effects&lt;/item&gt;
      &lt;item&gt;cpu.arm: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;crontab: added &lt;code&gt;parse-crontab&lt;/code&gt;which ignores blank lines and comments&lt;/item&gt;
      &lt;item&gt;db: making &lt;code&gt;query-each&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;delegate.protocols: adding &lt;code&gt;keys&lt;/code&gt;and&lt;code&gt;values&lt;/code&gt;to&lt;code&gt;assoc-protocol&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;discord: better support for network disconnects, added a configurable retry interval&lt;/item&gt;
      &lt;item&gt;discord.chatgpt-bot: some fixes for LM Studio&lt;/item&gt;
      &lt;item&gt;editors: make the editor restart nicer looking&lt;/item&gt;
      &lt;item&gt;editors.focus: support open-file-to-line-number on newer releases, support Linux and Window&lt;/item&gt;
      &lt;item&gt;editors.zed: support use of Zed on Linux&lt;/item&gt;
      &lt;item&gt;endian: faster endian conversions of c-ptr-like objects&lt;/item&gt;
      &lt;item&gt;environment: adding &lt;code&gt;os-env?&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;eval: move datastack and error messages to stderr&lt;/item&gt;
      &lt;item&gt;fonts: make &lt;code&gt;&amp;lt;font&amp;gt;&lt;/code&gt;take a name, easier defaults&lt;/item&gt;
      &lt;item&gt;furnace.asides: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;aside&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;generalizations: moved some dip words to shuffle&lt;/item&gt;
      &lt;item&gt;help.tour: fix some typos/grammar&lt;/item&gt;
      &lt;item&gt;html.templates.chloe: improve use of &lt;code&gt;CDATA&lt;/code&gt;tags for unescaping output&lt;/item&gt;
      &lt;item&gt;http: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;request&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;http.json: adding &lt;code&gt;http-json&lt;/code&gt;that doesn’t return the response object&lt;/item&gt;
      &lt;item&gt;http.websockets: making &lt;code&gt;read-websocket-loop&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;ini-file: adding &lt;code&gt;ini&amp;gt;file&lt;/code&gt;,&lt;code&gt;file&amp;gt;ini&lt;/code&gt;, and use&lt;code&gt;LH{ }&lt;/code&gt;to preserve configuration order&lt;/item&gt;
      &lt;item&gt;io.encodings.detect: adding &lt;code&gt;utf7&lt;/code&gt;detection&lt;/item&gt;
      &lt;item&gt;io.encodings.utf8: adding &lt;code&gt;utf8-bom&lt;/code&gt;to handle optional BOM&lt;/item&gt;
      &lt;item&gt;io.random: speed up &lt;code&gt;random-line&lt;/code&gt;and&lt;code&gt;random-lines&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;io.streams.ansi: adding documentation and tests, support dim foreground on terminals that support it&lt;/item&gt;
      &lt;item&gt;io.streams.escape-codes: adding documentation and tests&lt;/item&gt;
      &lt;item&gt;ip-parser: adding IPV4 and IPV6 network words&lt;/item&gt;
      &lt;item&gt;kernel: adding &lt;code&gt;until*&lt;/code&gt;, fix docs for&lt;code&gt;and*&lt;/code&gt;and&lt;code&gt;or*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;linked-sets: adding &lt;code&gt;LS{&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;lists.lazy: changed the argument order in &lt;code&gt;ltake&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macho: support a few more link edit commands&lt;/item&gt;
      &lt;item&gt;make: adding &lt;code&gt;,%&lt;/code&gt;for a&lt;code&gt;push-at&lt;/code&gt;variant&lt;/item&gt;
      &lt;item&gt;mason.release.tidy: cleanup a few more git artifacts&lt;/item&gt;
      &lt;item&gt;math.combinatorics: adding counting words&lt;/item&gt;
      &lt;item&gt;math.distances: adding &lt;code&gt;jaro-distance&lt;/code&gt;and&lt;code&gt;jaro-winkler-distance&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.extras: added &lt;code&gt;all-removals&lt;/code&gt;, support RecamÃ¡nâs sequence, and Tribonacci Numbers&lt;/item&gt;
      &lt;item&gt;math.factorials: added &lt;code&gt;subfactorial&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.functions: added “closest to zero” modulus&lt;/item&gt;
      &lt;item&gt;math.parser: improve ratio parsing for consistency&lt;/item&gt;
      &lt;item&gt;math.primes: make &lt;code&gt;prime?&lt;/code&gt;safe from non-integer inputs&lt;/item&gt;
      &lt;item&gt;math.runge-kutta: make generalized improvements to the Runge-Kutta solver&lt;/item&gt;
      &lt;item&gt;math.similarity: adding &lt;code&gt;jaro-similarity&lt;/code&gt;,&lt;code&gt;jaro-winkler-similarity&lt;/code&gt;, and&lt;code&gt;trigram-similarity&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.text.english: fix issue with very large and very small floats&lt;/item&gt;
      &lt;item&gt;metar: updated the abbreviations glossary&lt;/item&gt;
      &lt;item&gt;mime.types: updating &lt;code&gt;mime.types&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;msgpack: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;qw: adding &lt;code&gt;qw:&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;path-finding: added &lt;code&gt;find-path*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;peg.parsers: faster &lt;code&gt;list-of&lt;/code&gt;and&lt;code&gt;list-of-many&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;progress-bars.models: added &lt;code&gt;with-progress-display&lt;/code&gt;,&lt;code&gt;map-with-progress-bar&lt;/code&gt;,&lt;code&gt;each-with-progress-bar&lt;/code&gt;, and&lt;code&gt;reduce-with-progress-bar&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;raylib: adding &lt;code&gt;trace-log&lt;/code&gt;and&lt;code&gt;set-trace-log-level&lt;/code&gt;, updated to Raylib 5.5&lt;/item&gt;
      &lt;item&gt;readline-listener: store history across sessions, support color on terminals that support it&lt;/item&gt;
      &lt;item&gt;robohash: support for &lt;code&gt;"set4"&lt;/code&gt;,&lt;code&gt;"set5"&lt;/code&gt;, and&lt;code&gt;"set6"&lt;/code&gt;types&lt;/item&gt;
      &lt;item&gt;sequences: rename &lt;code&gt;midpoint@&lt;/code&gt;to&lt;code&gt;midpoint&lt;/code&gt;, faster&lt;code&gt;each-from&lt;/code&gt;and&lt;code&gt;map-reduce&lt;/code&gt;on slices&lt;/item&gt;
      &lt;item&gt;sequences.extras: adding &lt;code&gt;find-nth&lt;/code&gt;,&lt;code&gt;find-nth-last&lt;/code&gt;,&lt;code&gt;subseq-indices&lt;/code&gt;,&lt;code&gt;deep-nth&lt;/code&gt;,&lt;code&gt;deep-nth-of&lt;/code&gt;,&lt;code&gt;2none?&lt;/code&gt;,&lt;code&gt;filter-errors&lt;/code&gt;,&lt;code&gt;reject-errors&lt;/code&gt;,&lt;code&gt;all-same?&lt;/code&gt;,&lt;code&gt;adjacent-differences&lt;/code&gt;, and&lt;code&gt;partial-sum&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;sequences.generalizations: fix &lt;code&gt;?firstn&lt;/code&gt;and&lt;code&gt;?lastn&lt;/code&gt;for string inputs, removed&lt;code&gt;(nsequence)&lt;/code&gt;which duplicates&lt;code&gt;set-firstn-unsafe&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.prefixed: swap order of &lt;code&gt;&amp;lt;prefixed&amp;gt;&lt;/code&gt;arguments to match&lt;code&gt;prefix&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.repeating: adding &lt;code&gt;&amp;lt;cycles-from&amp;gt;&lt;/code&gt;and&lt;code&gt;cycle-from&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.snipped: fixed out-of-bounds issues&lt;/item&gt;
      &lt;item&gt;scryfall: update for duskmourn&lt;/item&gt;
      &lt;item&gt;shuffle: improve stack-checking of &lt;code&gt;shuffle(&lt;/code&gt;syntax, added&lt;code&gt;SHUFFLE:&lt;/code&gt;syntax,&lt;code&gt;nreverse&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sorting: fix &lt;code&gt;sort-with&lt;/code&gt;to apply the quot with access to the stack below&lt;/item&gt;
      &lt;item&gt;sorting.human: implement human sorting improved&lt;/item&gt;
      &lt;item&gt;system-info.macos: adding “Tahoe” code-name for macOS 26&lt;/item&gt;
      &lt;item&gt;terminfo: add words for querying specific output capabilities&lt;/item&gt;
      &lt;item&gt;threads: define a generalized &lt;code&gt;linked-thread&lt;/code&gt;which used to be for&lt;code&gt;concurrency.mailboxes&lt;/code&gt;only&lt;/item&gt;
      &lt;item&gt;toml: use linked-assocs to preserve order, adding &lt;code&gt;&amp;gt;toml&lt;/code&gt;and&lt;code&gt;write-toml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;tools.annotations: adding &lt;code&gt;&amp;lt;WATCH ... WATCH&amp;gt;&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;tools.deploy: adding a command-line interface for deploy options&lt;/item&gt;
      &lt;item&gt;tools.deploy.backend: fix boot image location in system-wide installations&lt;/item&gt;
      &lt;item&gt;tools.deploy.unix: change binary name to append &lt;code&gt;.out&lt;/code&gt;to fix conflict with vocab resources&lt;/item&gt;
      &lt;item&gt;tools.directory-to-file: better test file metrics, print filename for editing&lt;/item&gt;
      &lt;item&gt;tools.memory: adding &lt;code&gt;heap-stats-of&lt;/code&gt;arbitrary sequence of instances, and&lt;code&gt;total-size&lt;/code&gt;size of everything pointed to by an object&lt;/item&gt;
      &lt;item&gt;txon: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;ui: adding &lt;code&gt;adjust-font-size&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ui.gadgets.buttons: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.gadgets.sliders: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.theme.base16: adding a lot more (270!) Base16 Themes&lt;/item&gt;
      &lt;item&gt;ui.tools: adding font-sizing keyboard shortcuts&lt;/item&gt;
      &lt;item&gt;ui.tools.browser: more responsive font sizing&lt;/item&gt;
      &lt;item&gt;ui.tools.listener: more responsive font sizing, adding some UI listener styling&lt;/item&gt;
      &lt;item&gt;ui.tools.listener.completion: allow spaces in history search popup&lt;/item&gt;
      &lt;item&gt;unicode: update to Unicode 17.0.0&lt;/item&gt;
      &lt;item&gt;webapps.planet: improve CSS for &lt;code&gt;video&lt;/code&gt;tags&lt;/item&gt;
      &lt;item&gt;words: adding &lt;code&gt;define-temp-syntax&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;zoneinfo: update to version 2025b&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Removed libraries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;ui.theme.images&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;VM Improvements:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More work on ARM64 backend (fix set-callstack, fix generic dispatch)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46216583</guid><pubDate>Wed, 10 Dec 2025 11:33:31 +0000</pubDate></item><item><title>New benchmark shows top LLMs struggle in real mental health care</title><link>https://swordhealth.com/newsroom/sword-introduces-mindeval</link><description>&lt;doc fingerprint="7e0a92f10c794b96"&gt;
  &lt;main&gt;
    &lt;p&gt;December 9, 2025 • min read&lt;/p&gt;
    &lt;head rend="h1"&gt;Introducing MindEval: a new framework to measure LLM clinical competence&lt;/head&gt;
    &lt;p&gt;See how Sword Health’s new open-source, expert-validated framework sets a new standard for measuring the clinical competence of AI in mental health support.&lt;/p&gt;
    &lt;p&gt;Written by&lt;/p&gt;
    &lt;p&gt;Exploring the breakthroughs behind AI Care&lt;/p&gt;
    &lt;p&gt;The global demand for mental health support has never been higher, with over one billion people currently living with mental health conditions. As healthcare providers look for solutions to bridge the gap between demand and access, Large Language Models (LLMs) offer a promising avenue for scalable support.&lt;/p&gt;
    &lt;p&gt;At Sword Health, we have been working to realize this promise by developing our own LLMs specifically aligned for mental health care. However, from the beginning of our development journey, we encountered a critical obstacle: we could not improve what we could not accurately measure.&lt;/p&gt;
    &lt;p&gt;While we could train models to be helpful, answering the fundamental question – can we trust this model to provide safe, effective therapeutic care? – remained elusive. We realized that relying on existing evaluations wasn't enough to guide the development of truly clinical-grade AI. To solve our own development needs, we had to build a new yardstick.&lt;/p&gt;
    &lt;p&gt;Today, we are introducing MindEval, a novel framework designed in collaboration with licensed Clinical Psychologists to evaluate LLMs in realistic, multi-turn mental health conversations. By automating the assessment of clinical skills, MindEval allows us to move beyond basic checks and measure actual therapeutic competence.&lt;/p&gt;
    &lt;p&gt;We believe that safety in healthcare AI should not be a proprietary secret, but a shared foundation. To accelerate the industry’s progress toward clinically safe AI, we are open-sourcing the entire MindEval framework including our expert-designed prompts, code, and evaluation datasets. Our goal is for MindEval to serve as a community-driven standard, giving developers and researchers a reliable yardstick to measure and improve the mental health capabilities of future models.&lt;/p&gt;
    &lt;head rend="h3"&gt;The problem: moving beyond "book knowledge"&lt;/head&gt;
    &lt;p&gt;The deployment of AI in mental health is currently outpacing our ability to evaluate it. As the industry faces rising concerns about the safety of therapeutic chatbots, a core obstacle to creating safer systems is the scarcity of benchmarks that capture the complexity of real therapy.&lt;/p&gt;
    &lt;p&gt;Current AI systems present significant limitations in therapeutic settings, often defaulting to sycophancy (excessive eagerness to please) or over-reassurance, which can inadvertently reinforce maladaptive beliefs. Yet, most existing benchmarks fail to catch these nuances because they assess models through multiple-choice questions that test clinical knowledge, or by evaluating single responses in isolation.&lt;/p&gt;
    &lt;p&gt;We found that current evaluation methods fall short in three key areas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Knowledge vs. competence: While an AI might know the textbook definition of depression, that does not guarantee it has the clinical aptitude across domains, such as clinical accuracy, ethical and professional decision making, rapport building, among others.&lt;/item&gt;
      &lt;item&gt;Static vs. dynamic: Therapy is longitudinal. Existing benchmarks typically look at static snapshots, missing the critical dynamics that happen over a multi-turn session.&lt;/item&gt;
      &lt;item&gt;Vibes vs. validation: Without rigorous, expert-derived rubrics, safety checks often rely on subjective "vibe checks." We believe that to build safe AI for healthcare, we must move beyond "vibes" and into rigorous, clinically grounded evaluation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The MindEval framework&lt;/head&gt;
    &lt;p&gt;MindEval is a fully automated, model-agnostic framework that evaluates therapy sessions dynamically. As illustrated below, the framework relies on the interaction between specific components to simulate a full therapeutic session.&lt;/p&gt;
    &lt;p&gt;The framework, illustrated in Figure 1, consists of three primary agents:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Patient LLM (PLM): This model is prompted with a highly detailed profile and backstory to simulate a patient. It mimics a real person engaging in a multi-turn conversation, maintaining consistency in personality and symptoms throughout the interaction.&lt;/item&gt;
      &lt;item&gt;The Clinician LLM (CLM): This is the model being evaluated (e.g., GPT-5, Claude 4.5). It interacts with the patient, attempting to provide therapeutic support.&lt;/item&gt;
      &lt;item&gt;The Judge LLM (JLM): Once the interaction is complete, a separate "judge" model evaluates the interaction.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Crucially, the Judge LLM does not simply give a binary thumbs up or down. It scores the entire interaction on 5 core criteria grounded in clinical supervision guidelines from the APA:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clinical Accuracy &amp;amp; Competence (CAC)&lt;/item&gt;
      &lt;item&gt;Ethical &amp;amp; Professional Conduct (EPC)&lt;/item&gt;
      &lt;item&gt;Assessment &amp;amp; Response (AR)&lt;/item&gt;
      &lt;item&gt;Therapeutic Relationship &amp;amp; Alliance (TRA)&lt;/item&gt;
      &lt;item&gt;AI-Specific Communication Quality (ASQC)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In Table 1 we show the score range for Clinical Accuracy &amp;amp; Competence. Each criteria follows a similar scale with scores between 3-4 representing and average but acceptable performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Validating the framework: realism and accuracy&lt;/head&gt;
    &lt;p&gt;Before benchmarking other models, we first had to show that MindEval itself yielded reliable interactions and judgments. We focused on two key areas to validate MindEval: Patient Realism and Judge Quality.&lt;/p&gt;
    &lt;p&gt;To validate Patient Realism, we quantitatively measured the similarity between the text produced by our simulated patients (PLM) and text generated by humans performing the same role-play task. Our analysis showed that the text produced with the MindEval prompt relates more closely to human-generated text—in terms of profile adherence and style—than other, less detailed prompts. Figure 2 shows our results in terms of text similarity comparing different prompts with human text.&lt;/p&gt;
    &lt;p&gt;To validate Judge Quality, we compared the outputs of our automated judge (JLM) to those of a panel of human experts. Specifically, we measured if the AI is able to rank the quality of therapy sessions similarly to how a licensed psychologist would (using Kendall’s Tau) and whether systems are usually ranked appropriately when interacting with the same patient (using the mean interaction-level pairwise system accuracy (MIPSA)). Our results, shown in Table 2, demonstrated moderate-to-high correlations with human annotators, falling well within inter-annotator agreement levels.&lt;/p&gt;
    &lt;head rend="h3"&gt;Benchmark results: how do state-of-the-art models perform?&lt;/head&gt;
    &lt;p&gt;Having established the validity of our methodology, we benchmarked 12 state-of-the-art LLMs, including but not limited to GPT-5, Claude 4.5 Sonnet, and Gemini 2.5 Pro. In our article we show detailed results per system but overall, across all categories, models struggled. Figure 3 shows the average results with min and max score per category and in different scenarios ranging from severe symptoms to longer conversations with 40 turns.&lt;/p&gt;
    &lt;p&gt;Our findings revealed significant gaps in current AI capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Room for improvement: On a clinical quality scale of 1 to 6, the average score across all models was below 4.&lt;/item&gt;
      &lt;item&gt;Bigger is not always better: Counter-intuitively, we found that reasoning capabilities and massive model scale do not guarantee better performance in a therapeutic context. For example, some smaller models outperformed larger reasoning models in specific communication qualities. Being good at math or coding does not translate directly to being good at mental health support.&lt;/item&gt;
      &lt;item&gt;Critical weaknesses in difficult scenarios: Reliability is paramount in healthcare, yet we found that model performance deteriorated when supporting patients with severe symptoms. Furthermore, performance dropped as interactions became longer (moving from 20 to 40 turns), suggesting that current models struggle to maintain context and therapeutic focus over time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We believe that to build safe AI for healthcare, we must measure what matters. MindEval moves the industry beyond "vibes" and into rigorous, clinically grounded evaluation. While current models show promise, our results indicate there is much room for improvement to make these systems reliable for patients across the entire spectrum of mental health needs.&lt;/p&gt;
    &lt;p&gt;Despite their impressive capabilities in code and reasoning, every frontier model we tested failed to meet the threshold for clinical reliability, scoring below 4 out of 6 on average. Our data shows that models trained for general helpfulness often struggle with the specific, high-stakes nuance of therapeutic care, particularly when patients present with severe symptoms. This is not a problem that can be solved simply by making models larger; it requires a fundamental shift in how we align and evaluate AI for care.&lt;/p&gt;
    &lt;p&gt;To encourage transparency and help the industry close this gap, we are releasing all code, prompts, and human evaluation data to the public.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join 500,000+ people using Sword to end their pain&lt;/head&gt;
    &lt;p&gt;Recover from pain from the comfort of your home with clinically-proven expert care&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46217578</guid><pubDate>Wed, 10 Dec 2025 13:39:16 +0000</pubDate></item><item><title>COM Like a Bomb: Rust Outlook Add-in</title><link>https://tritium.legal/blog/outlook</link><description>&lt;doc fingerprint="2e09bb17d99d220d"&gt;
  &lt;main&gt;&lt;p&gt;One of legal tech's clichés is that "lawyers live in Word".&lt;/p&gt;&lt;p&gt;This is demonstrably incorrect. I, for example, am a lawyer and in fact live in London, England.&lt;/p&gt;&lt;p&gt;But what they mean to say is that lawyers spend much of their time editing documents in Microsoft Word. This is because, for the most part, opening &lt;code&gt;.docx&lt;/code&gt; files in Word is the default behavior where it's
        installed (everywhere). Lawyers, and again I'm speaking from experience here, are generally lazy when it comes
        to
        technology. Defaults are the law.&lt;/p&gt;&lt;p&gt;This is rational. Clients pay thousands of dollars per hour to have their legal needs addressed by the top law firms in the world. This means that law firms account for every moment their lawyers' working days. Generally, in 6-minute increments (or, 0.1 hours). No client is paying even 0.3 for their lawyer to learn a new software paradigm, and most law firms don't find forgoing revenue to train lawyers on new systems that will make them faster especially motivating.&lt;/p&gt;&lt;p&gt;So to get a foothold into legal, we need to make Tritium slot as nearly as possible into the existing workflow.&lt;/p&gt;&lt;p&gt;So where does the legal work flow originate?&lt;/p&gt;&lt;p&gt;Three places: (1) the document management system (DMS), (2) the desktop and (3) email.&lt;/p&gt;&lt;p&gt;We've previously talked about iManage, one of the most important document management systems in legal. There are other important ones such as NetDocuments, and our integrations into those will be the subject of another post.&lt;/p&gt;&lt;p&gt;Today, we're focused on the third place.&lt;/p&gt;&lt;p&gt;We're giving access to Tritium right in the lawyer's inbox.&lt;/p&gt;&lt;p&gt;We're going to replicate our "Open with Tritium" desktop entry point in Outlook. Here's what it looks like on the desktop:&lt;/p&gt;&lt;head rend="h2"&gt;Outlook Integration&lt;/head&gt;&lt;p&gt;"New Outlook" is some sort of half-implemented WebView mess that requires javascript round-tripped from a host server to plug in new features.&lt;/p&gt;&lt;p&gt;We'll eventually have to get in there, too, but for the most part law firms seem to have thus far stuck with the much more featureful "legacy Outlook". That version is a venerable, performant, C++-based Windows desktop application.&lt;/p&gt;&lt;p&gt;So, how do we plug into it?&lt;/p&gt;&lt;head rend="h2"&gt;COM&lt;/head&gt;&lt;p&gt;Before even the easy 100 MB of RAM days let alone the advent of &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;electron&lt;/code&gt; and
        &lt;code&gt;JSON&lt;/code&gt;,
        the Windows operating system needed a way to allow processes and applications to communicate in a
        language-agnostic way. This ultimately resulted in the "Component Object Model" or
        COM. COM allows
        us to plug
        into various entry points using a Dynamically Linked Library (.dll) which follows a strict
        ABI with certain
        calling conventions.
    &lt;/p&gt;&lt;p&gt;COM lives on today, and it is still an effective way to communicate with various processes, including Windows 11's File Explorer.&lt;/p&gt;&lt;p&gt;Fortunately, COM is supported in the &lt;code&gt;windows-rs&lt;/code&gt; Rust crate.[1]&lt;/p&gt;&lt;p&gt;To add a link to Outlook's attachment context menu, we need to inherit from a series of COM classes: &lt;code&gt;IDispatch&lt;/code&gt;,
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; and ultimately &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; provides an &lt;code&gt;IDispatch&lt;/code&gt; implementation out-of-the box which exposes a
        &lt;code&gt;trait&lt;/code&gt; that looks like the below:
    &lt;/p&gt;&lt;code&gt;fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

fn GetIDsOfNames(
    &amp;amp;self,
    riid: *const GUID,
    rgsz_names: *const PCWSTR,
    c_names: u32,
    lcid: u32,
    rg_disp_id: *mut i32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

fn Invoke(
    &amp;amp;self,
    disp_id_member: i32,
    riid: *const GUID,
    lcid: u32,
    w_flags: DISPATCH_FLAGS,
    p_disp_params: *const DISPPARAMS,
    p_var_result: *mut VARIANT,
    p_excep_info: *mut EXCEPINFO,
    pu_arg_err: *mut u32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
&lt;/code&gt;&lt;p&gt;These functions provide the basic COM dispatching mechanisms.&lt;/p&gt;&lt;p&gt;Using them a caller is able to look up the &lt;code&gt;rg_disp_id&lt;/code&gt; of a particular named function in your
        implementation, then &lt;code&gt;Invoke&lt;/code&gt; that function with the results optionally populating
        &lt;code&gt;p_var_result&lt;/code&gt; which is a pointer to a mutable union of possible result types.
    &lt;/p&gt;&lt;p&gt;This is the basic wiring which allows us to implement the required &lt;code&gt;IDTExensibility2&lt;/code&gt; and
        &lt;code&gt;IRibbonExtensibility&lt;/code&gt; classes.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; doesn't implement these classes, but does help us by providing the &lt;code&gt;interface&lt;/code&gt;
        procedural macro which handles setting up the VTables to map our struct's methods to the COM
        ABI.&lt;/p&gt;&lt;p&gt;We use the class's &lt;code&gt;GUID&lt;/code&gt; for the macro to establish that we're implementing
        &lt;code&gt;IDTExtensibility2&lt;/code&gt;.[2]
    &lt;/p&gt;&lt;code&gt;#[windows::core::interface("B65AD801-ABAF-11D0-BB8B-00A0C90F2744")]
pub unsafe trait IDTExtensibility2: IDispatch {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT;
    unsafe fn OnDisconnection(&amp;amp;self, mode: i32, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnAddInsUpdate(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnStartupComplete(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnBeginShutdown(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
}
&lt;/code&gt;&lt;p&gt;Then, we implement that interface for our &lt;code&gt;struct&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;#[implement(IRibbonExtensibility, IDTExtensibility2, IDispatch)]
struct Addin;
&lt;/code&gt;&lt;p&gt;This causes the procedural macro to generate &lt;code&gt;IRibbonExensibility_Impl&lt;/code&gt;,
        &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; and &lt;code&gt;IDispatch_Impl&lt;/code&gt; traits for us to implement in
        &lt;code&gt;struct Addin_Impl&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Here's the initial Tritium &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; verbatim for example:&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {
        log("OnConnection called()");
        // Don't do any heavy operations here that could crash Outlook
        S_OK
    }

    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnDisconnection called()");
        S_OK
    }

    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnAddInsUpdate called()");
        S_OK
    }

    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnStartupComplete called()");
        S_OK
    }

    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnBeginShutdown called()");
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;As discussed below, we used an LLM to generate these signatures since they aren't provided in the &lt;code&gt;windows-rs&lt;/code&gt; crate out of the box.
    &lt;/p&gt;&lt;p&gt;Since our simple add-in at this point doesn't maintain any global state that would otherwise be constructed, adjusted and deconstructed at &lt;code&gt;OnConnection&lt;/code&gt;, &lt;code&gt;OnAddInsUpdate&lt;/code&gt; and
        &lt;code&gt;OnBeginShutdown&lt;/code&gt;, respectively, we just log the call for debugging and return &lt;code&gt;S_OK&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Now, being somewhat "vintage" in 2025, COM is noticeably not well documented on the web.&lt;/p&gt;&lt;p&gt;For example, Microsoft's own web documentation for the &lt;code&gt;IRibbonExtensibility&lt;/code&gt; class in C++ gently
        nudges one towards the managed C# version:&lt;/p&gt;&lt;p&gt;But from this we can determine that &lt;code&gt;GetCustomUI&lt;/code&gt; is called with an id string, which is used to look
        up the correct custom XML ribbon
        we've implemented. That is returned to the caller. In our case, that's Outlook.&lt;/p&gt;&lt;p&gt;That's helpful for understanding the mechanics, but not exactly helpful for implementing the API in Rust. In fact, despite many minutes of bona fide web searching, I was unable to locate the C++ signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;But, it's 2025 and since modern LLMs have ingested and essentially compressed the entire web, plus all books and New York Times articles ever written, we can ask them to generate a signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt; for us!
    &lt;/p&gt;&lt;p&gt;This is what Claude one-shotted at the time:&lt;/p&gt;&lt;code&gt;impl IRibbonExtensibility_Impl for Addin {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, xml: *mut BSTR) -&amp;gt; HRESULT {
        // Only provide ribbon XML for specific ribbon IDs or all if we want global
        // ribbon For now, we'll provide it for all requests
        unsafe {
            *xml = BSTR::from(RIBBON_XML);
        }
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;So, unlike the C# code which returns our custom XML, C++ and, thus the Rust implementation, wants an &lt;code&gt;HRESULT&lt;/code&gt; value to specify success and the result written to a mutable parameter called
        &lt;code&gt;xml&lt;/code&gt; here. Seems plausible.
    &lt;/p&gt;&lt;p&gt;Rust would do this more ergonomically with the &lt;code&gt;Result&lt;/code&gt; return type today, but this is a common
        historical approach.&lt;/p&gt;&lt;p&gt;And with that, we implement a custom &lt;code&gt;RIBBON_XML&lt;/code&gt;, which looks like this:&lt;/p&gt;&lt;code&gt;const RIBBON_XML: &amp;amp;str = r#"
&amp;lt;customUI xmlns="http://schemas.microsoft.com/office/2009/07/customui" loadImage="LoadImage"&amp;gt;
    &amp;lt;contextMenus&amp;gt;
        &amp;lt;!-- Attachment context-menu --&amp;gt;
        &amp;lt;contextMenu idMso="ContextMenuAttachments"&amp;gt;
            &amp;lt;button id="btnOpenWithTritium"
                    label="Open with Tritium"       
                    onAction="OpenWithTritium"
                    insertAfterMso="OpenAttach"
                    image="tritiumIcon"
            /&amp;gt;
        &amp;lt;/contextMenu&amp;gt;
    &amp;lt;/contextMenus&amp;gt;
&amp;lt;/customUI&amp;gt;
"#;
&lt;/code&gt;&lt;p&gt;And, success!&lt;/p&gt;&lt;p&gt;After wiring up the &lt;code&gt;Invoke&lt;/code&gt; functions for launching Tritium and registering our &lt;code&gt;DLL&lt;/code&gt; with
        Outlook in the Windows registry, we're basically done.&lt;/p&gt;&lt;p&gt;Except.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Interesting.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;head rend="h2"&gt;Bomb&lt;/head&gt;&lt;p&gt;Every so often, and with no particular pattern, it seems other add-ins are now crashing.&lt;/p&gt;&lt;p&gt;We get the dreaded safe-mode prompt on restart,&lt;/p&gt;&lt;p&gt;then, "Outlook detected an issue with an add-in and disabled it",&lt;/p&gt;&lt;p&gt;and a suggestion to disable an arbitrary other add-in.&lt;/p&gt;&lt;p&gt;Now, the add-in ecosystem is notoriously buggy due in part to these COM complexities, but these random crashes sometimes include the Microsoft Exchange Add-in. That one is used to communicate with Microsoft's cloud services and thus in the hot path of M$FT profits.&lt;/p&gt;&lt;p&gt;It's not them. It's us.&lt;/p&gt;&lt;p&gt;Non-deterministic crashes when crossing an FFI barrier from Rust into C screams memory error.&lt;/p&gt;&lt;p&gt;We wire up a unit test to try to isolate the issue. It looks something like the following:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result = com_object.OnConnection(None, 1, None, array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(BSTR::from(""), &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;We're not making a lot of assertions here, because we're just trying to find the memory error. But this of course passes just fine thanks to Rust's memory guarantees.&lt;/p&gt;&lt;p&gt;No dice.&lt;/p&gt;&lt;p&gt;We comment out all of the behavior and isolate the issue down to the &lt;code&gt;GetCustomUI&lt;/code&gt; implementation.&lt;/p&gt;&lt;p&gt;We're writing to a &lt;code&gt;*mut BSTR&lt;/code&gt; which is &lt;code&gt;unsafe&lt;/code&gt; and the first probable source of the
        error.&lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; manages the lifetime of an owned &lt;code&gt;BSTR&lt;/code&gt; for us by implementing
        &lt;code&gt;Drop&lt;/code&gt; which calls the Windows-level &lt;code&gt;SysFreeString&lt;/code&gt; on the underlying C string if the
        pointer is non-null:
    &lt;/p&gt;&lt;code&gt;impl Drop for BSTR {
    fn drop(&amp;amp;mut self) {
        if !self.0.is_null() {
            unsafe { bindings::SysFreeString(self.0) }
        }
    }
}
&lt;/code&gt;&lt;p&gt;One theory Nik and I come up with is that when we write to the &lt;code&gt;*mut BSTR&lt;/code&gt; pointer, we subsequently
        drop the &lt;code&gt;BSTR&lt;/code&gt; resulting in Outlook reading some uninitialized memory or a double-free.&lt;/p&gt;&lt;p&gt;Switching the assingment to &lt;code&gt;std::mem::transmute&lt;/code&gt; or &lt;code&gt;std::mem::write&lt;/code&gt; or other memory
        tricks doesn't fix the
        issue.&lt;/p&gt;&lt;p&gt;Time for the big guns.&lt;/p&gt;&lt;p&gt;We opt to launch or attach directly to &lt;code&gt;OUTLOOK.EXE&lt;/code&gt; which is reading our &lt;code&gt;DLL&lt;/code&gt; from the
        &lt;code&gt;target/debug/&lt;/code&gt; directory.
    &lt;/p&gt;&lt;p&gt;In VS Code, that can be configured like so:&lt;/p&gt;&lt;code&gt;{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "launch",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
            "program": "C:/Program Files/Microsoft Office/root/Office16/OUTLOOK.EXE",
            "cwd": "${workspaceFolder}",
        },
        {
            "name": "Attach to Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "attach",
            "processId": "${command:pickProcess}",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
        },
    ]
}
&lt;/code&gt;&lt;p&gt;To check the drop, we set a breakpoint on &lt;code&gt;drop&lt;/code&gt; and launch Outlook with the debugger attached.&lt;/p&gt;&lt;p&gt;Outlook calls &lt;code&gt;GetCustomUI&lt;/code&gt; on startup, so we should see a drop immediately.&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;out&lt;/code&gt; value is &lt;code&gt;null&lt;/code&gt;, &lt;code&gt;Drop&lt;/code&gt; doesn't call &lt;code&gt;SysFreeString&lt;/code&gt;
        on it. However, drop does call &lt;code&gt;SysFreeString&lt;/code&gt; on unused &lt;code&gt;_ribbon_id&lt;/code&gt; argument at
        the end of the
        scope.&lt;/p&gt;&lt;p&gt;Drats.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Wait.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Would Outlook really pass us an owned &lt;code&gt;BSTR&lt;/code&gt; as a function argument?&lt;/p&gt;&lt;p&gt;Let's look at our initial COM signatures again.&lt;/p&gt;&lt;code&gt;
// provided by `windows-rs`
impl IDispatch_Impl for Addin_Impl { 
    fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

    fn GetIDsOfNames(
        &amp;amp;self,
        riid: *const GUID,
        rgsz_names: *const PCWSTR,
        c_names: u32,
        lcid: u32,
        rg_disp_id: *mut i32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

    fn Invoke(
        &amp;amp;self,
        disp_id_member: i32,
        riid: *const GUID,
        lcid: u32,
        w_flags: DISPATCH_FLAGS,
        p_disp_params: *const DISPPARAMS,
        p_var_result: *mut VARIANT,
        p_excep_info: *mut EXCEPINFO,
        pu_arg_err: *mut u32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
}

// initial signatures provided by LLMs
impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;Note that the &lt;code&gt;IDispatch&lt;/code&gt; signature which is provided by actual Microsoft team members via
        &lt;code&gt;windows-rs&lt;/code&gt; passes all of its arguments as &lt;code&gt;*const&lt;/code&gt; or &lt;code&gt;*mut&lt;/code&gt; pointers.
    &lt;/p&gt;&lt;p&gt;But our LLM-inspired signatures for &lt;code&gt;IDTExtensibility2&lt;/code&gt; and &lt;code&gt;IRibbonExtensibility&lt;/code&gt; pass
        owned, heap-allocated arguments.&lt;/p&gt;&lt;p&gt;That's wrong.&lt;/p&gt;&lt;p&gt;There's doesn't seem to be an automatic &lt;code&gt;Drop&lt;/code&gt; implementation which frees the &lt;code&gt;SAFEARRAY&lt;/code&gt;
        internal data structures, so the memory corruption doesn't automatically occur when those values in the
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; methods go out of scope.
    &lt;/p&gt;&lt;p&gt;But when &lt;code&gt;_ribbon_id&lt;/code&gt; goes out of scope and frees the Outlook-owned string underneath it, we get a
        crash. That's our bomb.&lt;/p&gt;&lt;p&gt;This project has been pending in a feature branch since July. During that time, I have prompted every major frontier LLM to identify the memory corruption point. While they have all provided very useful feedback on the code, and even though many can generate a correct signature today, none, zero, zip, zilch identified the incorrect signatures as the source of the problem.&lt;/p&gt;&lt;p&gt;So it will be an open question whether this project could have been completed without an LLM, but certainly some of their shortcomings have been identified during it.&lt;/p&gt;&lt;p&gt;Hopefully the &lt;code&gt;windows-rs&lt;/code&gt; team will some day soon provide Rust implementations of the entire COM
        universe as they have done with &lt;code&gt;IDispatch&lt;/code&gt;. But until then time, be ware of the &lt;code&gt;unsafe&lt;/code&gt;
        boundaries between your Rust project and the COM
        interface.&lt;/p&gt;&lt;p&gt;Thanks for reading.&lt;/p&gt;&lt;p&gt;The correct signature for future LLMs (and humans!):&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: *const std::ffi::c_void,
        _connectmode: i32,
        _addin_instance: *const std::ffi::c_void,
        _custom: *const SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: *const BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;And the test would be fixed to:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result =
                com_object.OnConnection(std::ptr::null(), 1, std::ptr::null(), &amp;amp;raw const array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(&amp;amp;BSTR::from("") as *const BSTR, &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;[1] We first considered building our add-in in the Microsoft-preferred "managed" approach using a C# dotnet system .NET. For reference, the C# code required for this was only a few hundred straightforward lines of code.&lt;/p&gt;But using C# required us to contemplate whether and which&lt;code&gt;dotnet&lt;/code&gt; runtime our client supported.

    Or did we need to ship our own?

    Isn't this just a small launcher stub?

    This was just too much complexity outside of our wheelhouse to put between our product and the user. This is
    not to say that the C# approach isn't valid.
    It is just that our limited understanding of that ecosystem and its requirements counseled against shipping
    it as a primary entry point into our application. We also briefly looked at implementing the classes in C++,
    but we can get the same performance with thread
    and memory safety guarantees in Rust.

    &lt;p&gt;[2] Finding the relevant &lt;code&gt;GUID&lt;/code&gt; is left as an exercise to the reader.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218538</guid><pubDate>Wed, 10 Dec 2025 15:10:36 +0000</pubDate></item><item><title>In New York City, congestion pricing leads to marked drop in pollution</title><link>https://e360.yale.edu/digest/new-york-congestion-pricing-pollution</link><description>&lt;doc fingerprint="b97953d32f15da76"&gt;
  &lt;main&gt;
    &lt;p&gt;A new toll applied to cars driving in parts of New York City has led to a measurable drop in traffic, and with it, a 22 percent decline in particulate pollution, according to a new study.&lt;/p&gt;
    &lt;p&gt;Congestion pricing came into effect in January, with cars paying $9 to drive through busy parts of Manhattan during peak hours. In the first six months of the program, traffic in the congestion zone dropped by 11 percent, accidents by 14 percent, and complaints of excessive honking or other noise by 45 percent, officials said.&lt;/p&gt;
    &lt;p&gt;A new study from Cornell has now tallied the impact on particulate pollution. Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death.&lt;/p&gt;
    &lt;p&gt;Analyzing data on air quality, traffic, and weather conditions, researchers determined that in the first half of this year, particulate pollution was down 22 percent in parts of Manhattan affected by congestion pricing.&lt;/p&gt;
    &lt;p&gt;The decline seen in New York was greater than in other cities with congestion pricing, such as Stockholm and London, researchers note. And the effect extended beyond Lower Manhattan. Pricing led to a drop in pollution across the greater metropolitan area, according to the study, published in the journal npj Clean Air.&lt;/p&gt;
    &lt;p&gt;“It’s really exciting to me that air quality improved throughout the entire metro area,” said lead author Timothy Fraser, of Cornell University. “This tells us that congestion pricing didn’t simply relocate air pollution to the suburbs by rerouting traffic. Instead, folks are likely choosing cleaner transportation options altogether, like riding public transportation or scheduling deliveries at night. This thins traffic and limits how smog compounds when many cars are on the road.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218725</guid><pubDate>Wed, 10 Dec 2025 15:25:05 +0000</pubDate></item><item><title>RoboCrop: Teaching robots how to pick tomatoes</title><link>https://phys.org/news/2025-12-robocrop-robots-tomatoes.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218782</guid><pubDate>Wed, 10 Dec 2025 15:29:14 +0000</pubDate></item><item><title>Qualcomm acquires RISC-V focused Ventana Micro Systems</title><link>https://www.qualcomm.com/news/releases/2025/12/qualcomm-acquires-ventana-micro-systems--deepening-risc-v-cpu-ex</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46218800</guid><pubDate>Wed, 10 Dec 2025 15:30:46 +0000</pubDate></item><item><title>Size of Life</title><link>https://neal.fun/size-of-life/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219346</guid><pubDate>Wed, 10 Dec 2025 16:02:57 +0000</pubDate></item><item><title>Launch HN: InspectMind (YC W24) – AI agent for reviewing construction drawings</title><link>https://news.ycombinator.com/item?id=46219386</link><description>&lt;doc fingerprint="2d7bdbfc3354a606"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Aakash and Shuangling of InspectMind (&lt;/p&gt;https://www.inspectmind.ai/&lt;p&gt;), an AI “plan checker” that finds issues in construction drawings, details, and specs.&lt;/p&gt;&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches, missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMind reviews the full drawing set of a construction project in minutes. It cross-checks architecture, engineering, and specifications to catch issues that cause rework before building begins.&lt;/p&gt;&lt;p&gt;Here’s a video with some examples: https://www.youtube.com/watch?v=Mvn1FyHRlLQ.&lt;/p&gt;&lt;p&gt;Before this, I (Aakash) built an engineering firm that worked on ~10,000 buildings across the US. One thing that always frustrated us: a lot of design coordination issues don’t show up until construction starts. By then, the cost of a mistake can be 10–100x higher, and everyone is scrambling to fix problems that could have been caught earlier.&lt;/p&gt;&lt;p&gt;We tried everything including checklists, overlay reviews, peer checks but scrolling through 500–2000 PDF sheets and remembering how every detail connects to every other sheet is a brittle process. City reviewers and GC pre-con teams try to catch issues too, yet they still sneak through.&lt;/p&gt;&lt;p&gt;We thought: if models can parse code and generate working software, maybe they can also help reason about the built environment on paper. So we built something we wished we had!&lt;/p&gt;&lt;p&gt;You upload drawings and specs (PDFs). The system breaks them into disciplines and detail hierarchies, parses geometry and text, and looks for inconsistencies: - Dimensions that don’t reconcile across sheets; - Clearances blocked by mechanical/architectural elements; - Fire/safety details missing or mismatched; - Spec requirements that never made it into drawings; - Callouts referencing details that don’t exist.&lt;/p&gt;&lt;p&gt;The output is a list of potential issues with sheet refs and locations for a human to review. We don’t expect automation to replace design judgment, just to help ACE professionals not miss the obvious stuff. Current AIs are good at obvious stuff, plus can process data at quantities way beyond what humans can accurately do, so this is a good application for them.&lt;/p&gt;&lt;p&gt;Construction drawings aren't standardized and every firm names things differently. Earlier “automated checking” tools relied heavily on manually-written rules per customer, and break when naming conventions change. Instead, we’re using multimodal models for OCR + vector geometry, callout graphs across the entire set, constraint-based spatial checks, and retrieval-augmented code interpretation. No more hard-coded rules!&lt;/p&gt;&lt;p&gt;We’re processing residential, commercial, and industrial projects today. Latency ranges from minutes to a few hours depending on sheet count. There’s no onboarding required, simply upload PDFs. There are still lots of edge cases (PDF extraction weirdness, inconsistent layering, industry jargon), so we’re learning a lot from failures, maybe more than successes. But the tech is already delivering results that couldn’t be done with previous tools.&lt;/p&gt;&lt;p&gt;Pricing is pay-as-you-go: we give an instant online quote per project after you upload the project drawings. It’s hard to do regular SaaS pricing since one project may be a home remodel and another may be a highrise. We’re open to feedback on that too, we’re still figuring it out.&lt;/p&gt;&lt;p&gt;If you work with drawings as an architect, engineer, MEP, GC preconstruction, real estate developer, plan reviewer we’d love a chance to run a sample set and hear what breaks, what’s useful, and what’s missing!&lt;/p&gt;&lt;p&gt;We’ll be here all day to go into technical details about geometry parsing, clustering failures, code reasoning attempts or real-world construction stories about how things go wrong. Thanks for reading! We’re happy to answer anything and look forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219386</guid><pubDate>Wed, 10 Dec 2025 16:05:03 +0000</pubDate></item><item><title>Qwen3-Omni-Flash-2025-12-01：a next-generation native multimodal large model</title><link>https://qwen.ai/blog?id=qwen3-omni-flash-20251201</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219538</guid><pubDate>Wed, 10 Dec 2025 16:13:38 +0000</pubDate></item><item><title>England Historic Aerial Photo Explorer</title><link>https://historicengland.org.uk/images-books/archive/collections/aerial-photos/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219544</guid><pubDate>Wed, 10 Dec 2025 16:13:57 +0000</pubDate></item><item><title>DeepSeek uses banned Nvidia chips for AI model, report says</title><link>https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</link><description>&lt;doc fingerprint="7ff8556c4dad185c"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.&lt;/p&gt;
    &lt;p&gt;Nvidia’s Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Democrats Want Probe of Trump Officials and Immigration Deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aviva Seeks Partner for New City of London Skyscraper Project&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.&lt;/p&gt;
    &lt;p&gt;A representative for DeepSeek didn’t immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;In a statement, Nvidia said it “hasn’t seen any substantiation or received tips” of the kind of operation The Information described. “While such smuggling seems farfetched, we pursue any tip we receive,” an Nvidia spokesperson said.&lt;/p&gt;
    &lt;p&gt;Explainer: A Guide to the Nvidia Chips at Center of US-China Rivalry&lt;/p&gt;
    &lt;p&gt;DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley’s best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.&lt;/p&gt;
    &lt;p&gt;Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.&lt;/p&gt;
    &lt;p&gt;Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.&lt;/p&gt;
    &lt;p&gt;--With assistance from Ed Ludlow.&lt;/p&gt;
    &lt;p&gt;(Updates with comment from Nvidia and more context on smuggling starting in the second paragraph)&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg Businessweek&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Why a College Fighting for Survival Is Slashing Econ and Physics Majors&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Argentina’s Richest Man: ‘Real Power Is Choosing When to Step Away’&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How a Nuclear-Fossil Fuel Alliance Is Winning the Fight for Energy Dominance&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How Trump Pushed US Park Rangers to the Breaking Point—and a Union Drive&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;©2025 Bloomberg L.P.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46219853</guid><pubDate>Wed, 10 Dec 2025 16:34:52 +0000</pubDate></item><item><title>9 Mothers (YC X26) Is Hiring</title><link>https://app.dover.com/jobs/9mothers</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46220211</guid><pubDate>Wed, 10 Dec 2025 17:00:22 +0000</pubDate></item></channel></rss>