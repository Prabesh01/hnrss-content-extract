<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Dec 2025 07:14:00 +0000</lastBuildDate><item><title>A Child in the State of Nature</title><link>https://lareviewofbooks.org/article/a-child-in-the-state-of-nature/</link><description>&lt;doc fingerprint="7f803dc188a3bf13"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Child in the State of Nature&lt;/head&gt;
    &lt;head rend="h2"&gt;Mitchell Abidor reviews the reprint edition of Roger Shattuck’s “The Forbidden Experiment: The Story of the Wild Boy of Aveyron.”&lt;/head&gt;
    &lt;head rend="h3"&gt;By Mitchell AbidorAugust 19, 2025&lt;/head&gt;
    &lt;p&gt;The Forbidden Experiment: The Story of the Wild Boy of Averyon by Roger Shattuck. NYRB Classics, 2025. 256 pages.&lt;/p&gt;
    &lt;head rend="h4"&gt;Double your support for LARB.&lt;/head&gt;
    &lt;p&gt;Every donation between now and December 31 will be matched up to $100,000. Donate today to double your support.&lt;/p&gt;
    &lt;p&gt;IN 1800, THE YEAR the story of the Wild Boy of Aveyron begins, France had long since moved beyond the most radical phase of its revolution. The king and queen had been guillotined, a republic had been established, and time had restarted, with a new calendar, dating the year one as 1792, already in use. The two most revolutionary groups, the Jacobins and the sans-culottes had been marginalized, their leaders guillotined, and the Directory, a moderate response to the revolutionary reign of Maximilien de Robespierre and his allies, had been replaced by a military dictatorship led by Napoleon Bonaparte. Even so, elements of the revolutionary phase lingered still in the minds of some of those formed by the events of the previous decade. The desire to properly understand and improve humanity still lived.&lt;/p&gt;
    &lt;p&gt;When a feral boy wandered into the French village of Saint-Sernin in the Aveyron region of the south of France on January 9, 1800—or, more properly, on the republican date of 19 Nivôse of the year eight—he would soon be caught up in that drive, that desire to understand humanity more deeply. Chance would see to it that this nameless, mysterious figure would encounter one of the more inquiring minds of his time, the physician Jean-Marc Gaspard Itard. “L’enfant sauvage d’Aveyron”—the Wild (or Savage) Child of Aveyron—would become the subject of what scholar Roger Shattuck called “the forbidden experiment,” in his insightful and well-written 1980 book of that title, newly reissued by NYRB Classics. The child would become, in essence, the guinea pig in an attempt to settle the question of the relative roles of nature and nurture in human development. Do we have innate abilities and qualities that determine who we are and what we will be, or are we a tabula rasa upon which life and experience leave their imprints and modify us?&lt;/p&gt;
    &lt;p&gt;The child at the center of this story had made brief appearances in another village about 120 kilometers from Saint-Sernin in 1798 and 1799, the last time six months prior to his arrival in Saint-Sernin. The wild child was captured digging for vegetables in the garden of a tanner. An early report by a local official set the tone for the standard vision of the child: “When I spoke to him, it didn’t take long to discover that he was mute. Soon after that, when I noticed that he made no response to various questions I put to him, in both a loud and a soft voice, I decided that he must be deaf.” Time would show that was not the case, though the boy was certainly mute. But his failure to demonstrate understanding of the spoken word, to verbally respond or properly imitate what he heard, which barely improved over the course of his remaining years, placed him in important ways in the position of a deaf mute.&lt;/p&gt;
    &lt;p&gt;A local priest and naturalist, Pierre-Joseph Bonnaterre, was the most serious student of the child’s early days, and wrote a thorough report on the child’s experiences in the village. Bonnaterre noted his distaste for clothing and his suspicion of all food save for potatoes. An effort was made to locate the child’s parents. Estimates were made that he was about 12 years old, and that he had spent half that life in the wild. L’enfant sauvage spent eight months in Saint-Sernin, including time in an orphanage, where he made little progress in socialization or ability to communicate. Food was his primary concern, as if he was still living in the forest, fighting for survival. Bonnaterre raised the matter of the child’s intelligence or lack of same, concluding that “we are obliged to say that, in every case not concerned with his natural needs or satisfying his appetite, one can perceive in him only animal behavior.” At the end of this first period, in Shattuck’s words, the child was “less domesticated than a dog or a horse, yet unmistakably human.”&lt;/p&gt;
    &lt;p&gt;The case had come to the attention of the Abbé Sicard, a member of the Society of Observers of Man and the director of l’Institut national des sourds-muets—the National Institute for Deaf-Mutes—in Paris, the most cutting-edge institution for deaf mutes in the world. L’enfant sauvage d’Aveyron was about to enter the history of the study of mankind. Sicard arranged for the child to be transferred to his institute, and he was duly sent to Paris on August 8, 1800. In Shattuck’s words, the boy, during the trip, “paid attention only to his own comfort,” and “when […] the stagecoach drove into Paris, he didn’t even seem to see the swarming streets and magnificent buildings that dazzled most country folk.”&lt;/p&gt;
    &lt;p&gt;The boy was placed in the care of a 25-year-old surgeon, Itard, who would spend more than five years working with him daily. This boy, this human tabula rasa, would, it was hoped, provide an answer to several questions. The “savage,” as he was commonly called, was, as Shattuck puts it, “a human being who had lapsed back into the animal condition,” and so “he should embody man in the state of nature.” Such a being was, for writers of the time, found only in distant climes, the noble savage of fictions set in the Americas, such as Paul et Virginie (1788). The “Wild Child of Aveyron” was native to France, an experimental subject providentially provided to the savants of a country that, perhaps above all others, was fascinated by the subject of humanity’s natural state. It was, after all, the priest and philosopher Condillac who had conjectured that, as Shattuck summarizes, “we are born without innate faculties or ideas. Sensory perceptions, Condillac believed, mold both mind and character.”&lt;/p&gt;
    &lt;p&gt;The question was not a new one. Herodotus wrote of the Egyptian ruler of the seventh century BCE who had isolated two children in order to discover what language they would naturally speak. Other rulers had carried out the same experiment, at times with implausible results, as in the case of the 16th-century Scottish king whose experimental subject allegedly began to speak Hebrew. These experiments, if they truly occurred, were based on the inhumane premise that it was acceptable to remove children from their parents and society in order to learn some larger fact about humankind. With the Wild Child of Aveyron, such isolation was an established fact. The goal would be to learn from his isolation what he naturally was and what he was capable of becoming.&lt;/p&gt;
    &lt;p&gt;The surgeon harbored the notion that the child, whom he soon named Victor (because of the child’s special attention when the “o” vowel sound was used in his presence), was an embodiment of the possibilities outlined by Condillac, capable of fully developing all his senses and capacities. Itard erred, but he was wrong for all the right reasons.&lt;/p&gt;
    &lt;p&gt;Itard focused on attempting to imbue the child with speech. Victor, it turned out, was able to make certain sounds and poorly imitate others. It is clear that he was not deaf because he imitated the housekeeper’s preferred imprecation “oh dieu,” which he mispronounced “oh diie.” But he was never able to properly pronounce even the few words he was claimed to have said, nor could he generalize from the little he did comprehend. Just as Helen Keller learned of the relation between things and their name with the word “water,” Victor connected “lait” and actual milk. But as Itard wrote in one of his reports (the main source for our knowledge of the forbidden experiment), “it was when he actually received some milk that he said the word lait. A few times he said it beforehand; and a few times afterwards, but always without any apparent purpose, without grasping its meaning.” It was all empty imitation.&lt;/p&gt;
    &lt;p&gt;Itard devised clever experiments, such as placing objects beneath the words that signified them. After many attempts, Victor was able to properly place the items beneath the words, but it was soon realized that he had done little more than memorize their prior positioning. A period of rapid progress would be followed by developmental stasis.&lt;/p&gt;
    &lt;p&gt;The efforts were strenuous, and Victor expressed his discontent wordlessly. Itard had a housekeeper, Madame Guérin, whose company Victor unquestionably preferred to that of the doctor. Itard represented work as something that frustrated the child, when in fact he may have been frustrated with Itard. In an attempt to test Victor’s moral understanding, Itard once punished the child after he correctly carried out an assigned task, which duly confused and enraged him. Noticing that Victor seemed frightened of heights, he even dangled the boy from a parapet. When Itard finally abandoned the project as a lost cause, it was with Madame Guérin that Victor would live out his days. In 1806, he was a tamer young man, but he never proved the point Itard had set out to prove—that we are infinitely improvable.&lt;/p&gt;
    &lt;p&gt;All those who have written about the Wild Child—and their numbers are legion, from the psychiatrist Bruno Bettelheim to the anthropologist Claude Lévi-Strauss—have speculated about the proper diagnosis for Victor. Itard acted on the assumption that whatever Victor’s lacks might be, they were a product of his time in the forest. That he was totally lacking in native intelligence—that he was, in the language of his time, an “idiot”—was inconceivable. If he were, how could he have survived for years in the forest unassisted? He had somehow managed to find food, protect himself, and keep himself sufficiently warm during winter, for an estimated six years. He was, in Itard’s original vision, simply a human stripped down to the bare essentials, a scaffolding upon which anything could be built. This is an essential part of the story, for if Victor was in possession of all his faculties, mental and physical, then the fact that he did not substantially advance put paid to the possibility that humanity could be remolded and infinitely improved.&lt;/p&gt;
    &lt;p&gt;What was the cause of Victor’s inability to progress? Was he autistic? Developmentally handicapped? Schizophrenic? Was he abandoned in the first place because he showed signs of such maladies? Was his inability to speak organic or was it the result of the slit across his throat that was found upon his capture, which might well have severed his vocal cords? Shattuck dismisses this latter possibility. The slash was superficial, and had it been deep enough to reach his vocal cords, it’s inconceivable that he would have survived such an untreated wound in the forest. Which doesn’t mean that whoever abandoned him didn’t attempt to kill him, just that the wound in the end was not sufficiently profound to turn him mute.&lt;/p&gt;
    &lt;p&gt;Shattuck reproaches Itard for failing to persist in attempts to establish Victor’s provenance. By all estimates, he had spent six years in a savage state, which means he likely spent his first six years in society. He was not a foundling, abandoned at birth on the steps of a church. Yet his background was never established. Speculation is, of course, not diagnosis. The optimism of Itard’s course of treatment refused the medicalization of Victor’s deficits. It was the spirit of the times, the desire to prove a philosophical point, an admirable one at that, that led to the possible refutation of that very same point.&lt;/p&gt;
    &lt;p&gt;Criticism of Itard’s effort to change Victor focuses on a fatal flaw in the doctor’s educational methods. The principal ones, put forth by Shattuck and even more forcefully by Harlan Lane in his earlier study of the case The Wild Boy of Aveyron (1976), were the twin errors of isolating Victor from other children in the Institute for Deaf-Mutes and the imposition of speech on the mute child. As Shattuck wrote, “Even though the boy lived at the Institute for Deaf-Mutes, […] he apparently was not encouraged to play with boys and girls of his age.” He thus lacked the stimulation such interactions would have provided. Instead, “Itard almost placed the Wild Boy in a new, looser form of isolation. The root cause of his backwardness was not completely removed.” Ironically, the little savage lived “like a little prince”—he “had a tutor and a governess, whereas what he probably needed most was to work and play with other children.” Whether Victor’s isolation was the “root cause” of Victor’s inability to intellectually thrive remains, as Shattuck shows, an open question. But it is certainly the case that only free play might have allowed him to gain—or regain—all the elements of a full social life, not least language.&lt;/p&gt;
    &lt;p&gt;And then there’s the second major error of Itard’s methods—“the excessive stress he laid on training Victor to speak.” Shattuck assigns blame to Itard for not building on the few sounds Victor was able to make. But the stringing-together of sounds is not speech, and nothing indicates that Victor was ever going to speak. Was his problem organic? Was it induced by isolation? Language is a social matter, learned through contact with other language users. Itard had a ready supply of language users at hand, but to quote Shattuck, he “never tried to find out if Victor could learn to sign, to use the language that was being used all around him and for which he had a natural propensity.” This would have been a natural fit, for Victor used what Shattuck calls an “action language,” his own rudimentary sign system. But Itard, we are told, felt a great prejudice against signing, and he was far from alone in this bias. “Sign was the language of the ‘dumb’—an association Itard wanted to avoid,” Shattuck writes.&lt;/p&gt;
    &lt;p&gt;As writers including Harlan Lane and Oliver Sacks have demonstrated with great passion, signing is a language in as full a sense as any spoken tongue. Its relation to the way the brain functions is exactly that of spoken language. Itard, in this case, acted like so many benefactors of the deaf who instead harmed them by forcing them into the mold of the hearing world. Itard would repent this mistake over the course of his lengthy career.&lt;/p&gt;
    &lt;p&gt;But we should be wary of judging Itard too harshly by engaging in the sort of presentism that tinges the critiques I have outlined. Itard thought in the terms of the age in which he lived. As the French philosopher Lucien Malson wrote in his 1964 volume Les Enfants sauvages, the child suffered from “the impossibility of being six years old again,” unable to be “miraculously cured of the intellectual sclerosis and […] the long and painful trauma owed to prolonged isolation.” As a savant of Itard’s own time wrote, after reading the doctor’s report on his experiment, “We must, in the first place, consider his departure point as well as the point at which he has arrived, for this young man, in order to be correctly judged, should only be compared to himself.” The fault lay not in Itard’s methods but in Victor’s circumstances. Though we can doubt the perfectibility of mankind, that conclusion is not proven by the case of Victor, who was a poor experimental subject. What the case does prove, in Malson’s words, is that “man, as man, before education is nothing but a simple possibility; that is, even less than a hope.”&lt;/p&gt;
    &lt;p&gt;LARB Contributor&lt;/p&gt;
    &lt;p&gt;Mitchell Abidor is a historian and translator of French, Spanish, Italian, Portuguese, and Esperanto. His book Victor Serge: Unruly Revolutionary will be published in late 2025.&lt;/p&gt;
    &lt;head rend="h3"&gt;LARB Staff Recommendations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;Enlightenment: It's What's For Dinner&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;I, Language Robot&lt;/head&gt;
        &lt;p&gt;Hired to write stories alongside an AI writing bot, neuroscientist Patrick House reflects on how the bot can — and can’t — write the same story that he can.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46351625</guid><pubDate>Mon, 22 Dec 2025 05:28:42 +0000</pubDate></item><item><title>CSRF protection without tokens or hidden form fields</title><link>https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields</link><description>&lt;doc fingerprint="3d02d1187cb13ead"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;CSRF Protection without Tokens or Hidden Form Fields&lt;/head&gt;&lt;head rend="h2"&gt;Posted by&lt;/head&gt;on under&lt;p&gt;A couple of months ago, I received a request from a random Internet user to add CSRF protection to my little web framework Microdot, and I thought it was a fantastic idea.&lt;/p&gt;&lt;p&gt;When I set off to do this work in early November I expected I was going to have to deal with anti-CSRF tokens, double-submit cookies and hidden form fields, pretty much the traditional elements that we have used to build a defense against CSRF for years. And I did start along this tedious route. But then I bumped into a new way some people are dealing with CSRF attacks that is way simpler, which I describe below.&lt;/p&gt;&lt;head rend="h2"&gt;Implementing a security feature&lt;/head&gt;&lt;p&gt;An often shared piece of advice is that you should never implement security features yourself. Instead, you should look for well established solutions built by people who think about security day in and day out.&lt;/p&gt;&lt;p&gt;Unfortunately, as the lead (and only) maintainer of Microdot, I do not have an ecosystem of existing solutions available to me. Even though I gladly accept external contributions, most of the framework has been built by myself out of nothing. So in this case, like many other times before, I felt I had no choice but to go against the standard advice and write CSRF protection code by myself, because if I didn't do it then the feature would not be built.&lt;/p&gt;&lt;p&gt;What is the first step when you need to build a security feature? Check out what OWASP has to say about the matter.&lt;/p&gt;&lt;p&gt;So, in early November, I opened OWASP's CSRF Prevention Cheat Sheet page to see what was new and interesting in the world of CSRF protection. And I found that nothing of significance had changed.&lt;/p&gt;&lt;p&gt;According to OWASP, the best CSRF protection you could get (at the time I checked) was still built around the idea of using anti-CSRF tokens. So I set off to implement this for Microdot.&lt;/p&gt;&lt;head rend="h2"&gt;A disturbance in the (CSRF) force&lt;/head&gt;&lt;p&gt;I was happily making progress on my CSRF implementation, and then in early December, another random Internet user dropped an issue on the Flask repository, proposing that Flask adds support for "modern" CSRF protection. Modern? How could there be a new way to protect against CSRF that isn't mentioned by OWASP?&lt;/p&gt;&lt;p&gt;This led me down a rabbit hole of blog posts and discussions spanning the Go and Ruby communities, plus a long discussion about this method on the OWASP GitHub repository itself, resulting in a pull request that added a mention of this method to the CSRF Cheat Sheet, only a couple of weeks after I went to this page looking for guidance for my own implementation.&lt;/p&gt;&lt;head rend="h2"&gt;Modern CSRF Protection&lt;/head&gt;&lt;p&gt;The so called "modern" method to protect against CSRF attacks is based on the Sec-Fetch-Site header, which all modern desktop and mobile browsers include in the requests they send to servers. According to Mozilla, all browsers released since March 2023 have support for this header.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header can have one of four values:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;same-origin&lt;/code&gt;, when the request comes from the same origin as the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;same-site&lt;/code&gt;, when the request comes from the same site, but not exactly the same origin (e.g. a different subdomain) as the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;cross-site&lt;/code&gt;, when the request comes from an origin that does not match the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;none&lt;/code&gt;, when the request is originated by the user&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The value of this header cannot be set via JavaScript, so the server can assume that a) if this header is present, then the client is a web browser, and b) the value of the header can be trusted. So basically, the server can reject requests that come with this header set to &lt;code&gt;cross-site&lt;/code&gt;, and in essence that is all you need to do to protect against CSRF!&lt;/p&gt;&lt;p&gt;After seeing this, I paused my work on the token-based CSRF implementation and spent a few hours to implement this modern approach. As always, the devil is in the details, so let's see what else I needed to do to build a complete solution.&lt;/p&gt;&lt;p&gt;First of all, in some cases subdomains sharing the same registered domain may operate independently, and as such, it is not out of the question that one subdomain may attempt to attack another through CSRF. Depending on the level of trust an application has for other subdomains, a server may want to block requests that come with the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header set to &lt;code&gt;same-site&lt;/code&gt;. In Microdot, I have added an argument &lt;code&gt;allow_subdomains&lt;/code&gt; to cover this case. I decided to err on the side of security, so the default is &lt;code&gt;False&lt;/code&gt;, meaning that requests from subdomains are also blocked.&lt;/p&gt;&lt;p&gt;The other big problem is that not everyone is using a recent browser that implements this header. Looking at the browser compatibility for the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header, you can see that most browsers implemented this feature long ago, between 2019 and 2021, with one notable exception: Safari. Apple added this header to its browser in 2023, so it is reasonable to assume that there are still users out there running older browsers that do not support it.&lt;/p&gt;&lt;p&gt;One option is to reject all requests that do not have the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header. This keeps everyone secure, but of course, there's going to be some unhappy users of old devices that will not be able to use your application. Plus, this would also reject HTTP clients that are not browsers. If this is not a problem for your use case, then great, but it isn't a good solution overall.&lt;/p&gt;&lt;p&gt;From what I gathered from looking at other implementations of this method, an accepted solution is to use the &lt;code&gt;Origin&lt;/code&gt; header as fallback when &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; is not implemented, since this header has been around for much longer. The last of the major browsers to add it were Firefox desktop in 2019 and Edge and Firefox mobile in 2020. Like &lt;code&gt;Sec-Fetch-Site&lt;/code&gt;, the &lt;code&gt;Origin&lt;/code&gt; header is also a restricted header that is set by the browser, so it can also be used to determine from where a request is coming from.&lt;/p&gt;&lt;p&gt;The problem with using the &lt;code&gt;Origin&lt;/code&gt; header is that it isn't always easy to know what is the correct origin that applies to a web application. The standard option is to compare the value of the &lt;code&gt;Origin&lt;/code&gt; header against the value of the &lt;code&gt;Host&lt;/code&gt; header, but &lt;code&gt;Host&lt;/code&gt; only includes the hostname and port, while &lt;code&gt;Origin&lt;/code&gt; also includes the scheme. Also, the &lt;code&gt;Host&lt;/code&gt; header is overwritten as it passes through reverse proxies. So comparing these two headers is actually not easy.&lt;/p&gt;&lt;p&gt;Another, more direct option is to ask the user to configure the expected origin name explicitly. To keep things simple, in Microdot I opted for the explicit configuration, for which I linked to the existing Cross-Origin Request Sharing (CORS) support. The CORS feature already maintains a list of allowed origins, so my CSRF logic automatically trusts these. I decided to not complicate myself adding support for &lt;code&gt;Host&lt;/code&gt; header checks at this time, but maybe I'll add this in the future.&lt;/p&gt;&lt;p&gt;Filippo Valsorda, a security developer active in the Go ecosystem (and author of the popular mkcert tool) wrote a blog post about this method that you may want to check out if you want to learn more details about it. He seems to be the first to propose this method and has implemented it for the Go standard library.&lt;/p&gt;&lt;p&gt;Also if you are interested, feel free to review my implementation of CSRF protection in Microdot. Have a look at the documentation, the code and an example, and let me know if you have any improvements or fixes to suggest.&lt;/p&gt;&lt;head rend="h2"&gt;Let's revisit OWASP&lt;/head&gt;&lt;p&gt;Note: this section is now out of date. As of December 24th 2025 the OWASP CSRF Cheat Sheet page lists the Fetch Metadata method as a complete solution that can be used as an alternative to token-based approaches.&lt;/p&gt;&lt;p&gt;As I mentioned above, the CSRF Prevention Cheat Sheet page from OWASP was updated in early December to include the use of the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header in the list of prevention methods. But this method is currently listed as a defense in depth mechanism, and not a complete solution, which I thought was odd.&lt;/p&gt;&lt;p&gt;I referenced the discussion in the OWASP GitHub repository that resulted in the recent changes made to the Cheat Sheet page. Several participants in that discussion have suggested that this method should be upgraded to a complete alternative to the standard token-based approaches. The OWASP maintainer was initially skeptical, but towards the end of the thread they have agreed. The pull request that closed the discussion added this solution as an alternative to the token-based approaches, but then a later change made significant updates, including the downgrade to defense in depth. My hope is that this is just a misunderstanding, and that the OWASP folks will restore the content as it was agreed by all the parties involved.&lt;/p&gt;&lt;p&gt;In any case, I consider that in Microdot, going from no CSRF support at all to this is a great step forward that is also consistent with the minimalist ethos of the project. I will be keeping an eye on the OWASP CSRF Cheat Sheet page to see what is their final word on this new protection method, and if they end up keeping it as defense in depth, I still have a mostly complete implementation of double-submit anti-CSRF tokens that I can bring into my project.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;What I like the most about working in open source is that all the work happens in the open, so it is a permanent record that can be searched and reviewed. My CSRF protection journey started as a somewhat tedious exercise in the use of cryptography and cookies, but then thanks to an unexpected lead it turned into a fun and exciting learning opportunity for me.&lt;/p&gt;&lt;head rend="h2"&gt;Buy me a coffee?&lt;/head&gt;&lt;p&gt;Thank you for visiting my blog! If you enjoyed this article, please consider supporting my work and keeping me caffeinated with a small one-time donation through Buy me a coffee. Thanks!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46351666</guid><pubDate>Mon, 22 Dec 2025 05:38:33 +0000</pubDate></item><item><title>Uplane (YC F25) Is Hiring Founding Engineers (Full-Stack and AI)</title><link>https://www.useparallel.com/uplane1/careers</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46355932</guid><pubDate>Mon, 22 Dec 2025 17:00:34 +0000</pubDate></item><item><title>Fabrice Bellard Releases MicroQuickJS</title><link>https://github.com/bellard/mquickjs/blob/main/README.md</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46367224</guid><pubDate>Tue, 23 Dec 2025 17:33:42 +0000</pubDate></item><item><title>Google's year in review: areas with research breakthroughs in 2025</title><link>https://blog.google/technology/ai/2025-research-breakthroughs/</link><description>&lt;doc fingerprint="2d3721de3b34b389"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google's year in review: 8 areas with research breakthroughs in 2025&lt;/head&gt;
    &lt;p&gt;2025 has been a year of extraordinary progress in research. With artificial intelligence, we can see its trajectory shifting from a tool to a utility: from something people use to something they can put to work. If 2024 was about laying the multimodal foundations for this era, 2025 was the year AI began to really think, act and explore the world alongside us. With quantum computing, we made progress towards real-world applications. And across the board, we helped turn research into reality, with more capable and useful products and tools making a positive impact on people's lives today.&lt;/p&gt;
    &lt;p&gt;Here’s a look back at some of the breakthroughs, products and scientific milestones that defined the work of Google, Google DeepMind and Google Research in a year of relentless progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Delivering breakthroughs on world-class models&lt;/head&gt;
    &lt;p&gt;This year, we significantly advanced our model capabilities with breakthroughs on reasoning, multimodal understanding, model efficiency, and generative capabilities, beginning with the release of Gemini 2.5 in March and culminating in the November launch of Gemini 3 and the December launch of Gemini 3 Flash.&lt;/p&gt;
    &lt;p&gt;Built on a foundation of state-of-the-art reasoning, Gemini 3 Pro is our most powerful model to date, designed to help you bring any idea to life. It topped the LMArena Leaderboard and redefined multimodal reasoning with breakthrough scores on benchmarks like Humanity’s Last Exam — a fiendishly hard test for AI models to see if AI can truly think and reason like humans — and GPQA Diamond. It also set a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex. We followed shortly with Gemini 3 Flash, which combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost, making it the most performant model for its size. Gemini 3 Flash's quality surpasses our previous Gemini 2.5 Pro-scale model's capabilities at a fraction of the price and substantially better latency, continuing our Gemini-era trend of 'the next generation's Flash model is better than the previous generation's Pro model'.&lt;/p&gt;
    &lt;p&gt;Learn more about our progress on our world-class AI models this year:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini 3 Flash: frontier intelligence built for speed (Dec 2025)&lt;/item&gt;
      &lt;item&gt;A new era of intelligence with Gemini 3 (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Introducing Nano Banana Pro (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Introducing Veo 3.1 and new creative capabilities in the Gemini API (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Gemini 2.5: Our most intelligent AI model (March 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Gemini 3 Flash price &amp;amp; benchmark table.&lt;/p&gt;
    &lt;p&gt;We’re committed to making useful AI technology accessible, with state-of-the-art open models. We built our Gemma family of models to be lightweight and open for public use; this year we were able to introduce multimodal capabilities, significantly increase the context window, expand multilingual capabilities, and improve efficiency and performance.&lt;/p&gt;
    &lt;p&gt;Learn more about this year’s advances in Gemma models:&lt;/p&gt;
    &lt;head rend="h2"&gt;Innovating and transforming our products with AI&lt;/head&gt;
    &lt;p&gt;Throughout 2025, we continued to advance the trajectory of AI from tool to utility, transforming our portfolio of products with new, powerful agentic capabilities. We reimagined software development by moving beyond tools that assist coding to introducing powerful, agentic systems that collaborate with developers. Key advances, such as the impressive coding capabilities in Gemini 3 and the launch of Google Antigravity, mark a new era in AI-assisted software development.&lt;/p&gt;
    &lt;p&gt;Learn more about this year’s advances building developer tools:&lt;/p&gt;
    &lt;p&gt;This evolution was also clear across our core products, from AI-enabled features on the Pixel 10 and updates to AI Mode in Search, to AI-first innovations like the Gemini app and NotebookLM, which gained advanced features like Deep Research.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’ve transformed our products with AI:&lt;/p&gt;
    &lt;head rend="h2"&gt;Empowering creativity and co-creating with AI&lt;/head&gt;
    &lt;p&gt;2025 was a transformative year for generative media, giving people new and unprecedented capabilities to realize their creative ambitions. Generative media models and tools for video, images, audio and worlds became more effective and broadly used, with breakouts Nano Banana and Nano Banana Pro offering unprecedented capabilities for native image generation and editing. We worked with people in creative industries to develop tools like Flow and Music AI Sandbox, making them more helpful for creative workflows, and we expanded creative possibilities for people with new, AI-powered experiences in the Google Arts &amp;amp; Culture lab, major upgrades to image editing within the Gemini app, and the introduction of powerful new generative media models like Veo 3.1, Imagen 4 and Flow.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re building AI to enhance creativity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Art, science, travel: 3 new AI-powered experiences this holiday season (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Introducing Veo 3.1 and advanced capabilities in Flow (Oct 2025)&lt;/item&gt;
      &lt;item&gt;Nano Banana: Image editing in Gemini just got a major upgrade (Aug 2025)&lt;/item&gt;
      &lt;item&gt;Veo 3, Imagen 4, and Flow: Fuel your creativity with new generative media models and tools (May 2025)&lt;/item&gt;
      &lt;item&gt;Music AI Sandbox, now with new features and broader access (April 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As research breakthroughs continue to expand AI’s capabilities, Google Labs is where we share AI experiments as we develop them – hearing from users and evolving as we learn. Some of this year’s most engaging experiments from Labs: Pomelli, an AI experiment for on-brand marketing content; Stitch, which introduced a way to turn prompt and image inputs into complex UI designs and frontend code in minutes; Jules, an asynchronous coding agent that acts as a collaborative partner for developers; and Google Beam, a 3D video communications platform that used AI to advance the possibilities of remote presence.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re experimenting in Labs:&lt;/p&gt;
    &lt;head rend="h2"&gt;Advancing science and mathematics&lt;/head&gt;
    &lt;p&gt;2025 was also a banner year for scientific advances with AI, marked by breakthroughs in life sciences, health, natural sciences, and mathematics.&lt;/p&gt;
    &lt;p&gt;In the space of a year, we made progress in building AI resources and tools that empower researchers and help them understand, identify, and develop treatments in healthcare. In genomics, where we’ve been applying advanced technology to research for 10 years, we moved beyond sequencing, using AI to interpret the most complex data. We also marked the 5-year anniversary of AlphaFold, the Nobel-winning AI system that solved the 50-year-old protein folding problem. AlphaFold has been used by over 3 million researchers in more than 190 countries, including over 1 million users in low- and middle-income countries.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re using AI to advance life sciences and health:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AlphaFold: Five years of impact (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Using AI to identify genetic variants in tumors with DeepSomatic (Oct 2025)&lt;/item&gt;
      &lt;item&gt;AI as a research partner: Advancing theoretical computer science with AlphaEvolve (Sept 2025)&lt;/item&gt;
      &lt;item&gt;AlphaGenome: AI for better understanding the genome (June 2025)&lt;/item&gt;
      &lt;item&gt;Accelerating scientific breakthroughs with an AI co-scientist (Feb 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Gemini’s advanced thinking capabilities, including Deep Think, also enabled historic progress in mathematics and coding. Deep Think was able to solve problems that require deep abstract reasoning – achieving gold medal-standard in two international contests.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re advancing natural sciences and mathematics:&lt;/p&gt;
    &lt;head rend="h2"&gt;Shaping innovations in computing and the physical world&lt;/head&gt;
    &lt;p&gt;We’re also leading major discoveries and shaping the future of science in areas like quantum computing, energy and moonshots. Research in this area drew new levels of public attention, with progress towards real-world applications of quantum computing as demonstrated by Quantum Echoes and, notably, Googler Michel Devoret becoming a 2025 Physics Nobel Laureate along with former Googler John Martinis and UC Berkeley’s John Clarke, for their foundational 1980s quantum research.&lt;/p&gt;
    &lt;p&gt;Learn more about our work on space infrastructure and quantum computing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Project Suncatcher: Exploring a space-based, scalable AI infrastructure system design (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Googler Michel Devoret awarded the Nobel Prize in Physics (Oct 2025)&lt;/item&gt;
      &lt;item&gt;Our Quantum Echoes algorithm is a big step toward real-world applications for quantum computing (Oct 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In 2025, we continued to advance the core infrastructure that powers our AI, focusing on breakthroughs in hardware design and improving energy efficiency. This included the introduction of Ironwood, a new TPU built for the age of inference, which was designed using a method called AlphaChip, alongside a commitment to measuring the environmental impact of our technology.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re using AI to develop chips, infrastructure and improve energy efficiency:&lt;/p&gt;
    &lt;p&gt;Our work in robotics and visual understanding brought AI agents into both the physical and virtual worlds, with advancements like the foundational Gemini Robotics models, the more sophisticated Gemini Robotics 1.5, and the introduction of Genie 3 as a new frontier for general-purpose world models.&lt;/p&gt;
    &lt;p&gt;Learn more about our work with world models and robotics:&lt;/p&gt;
    &lt;head rend="h2"&gt;Tackling global challenges and opportunities at scale&lt;/head&gt;
    &lt;p&gt;Our work throughout 2025 demonstrates how AI-enabled scientific progress is being directly applied to address the world's most critical and pervasive challenges. By leveraging state-of-the-art foundational models and agentic reasoning, we are significantly increasing our understanding of the planet and its systems, while also delivering impactful solutions in areas vital to human flourishing, including climate resilience, public health and education.&lt;/p&gt;
    &lt;p&gt;For example, we are using state-of-the-art foundational models and agentic reasoning to help increase our understanding of the planet, helping enable work that is making a difference in people’s lives now from weather predictions to urban planning to public health. For example, our flood forecasting information now covers more than two billion people in 150 countries for severe riverine floods. And our most advanced and efficient forecasting model, WeatherNext 2 can generate forecasts 8x faster and with resolution up to 1-hour. Using this technology, we’ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.&lt;/p&gt;
    &lt;p&gt;Learn more about our work in weather, mapping and wildfires:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WeatherNext 2: Our most advanced weather forecasting model (Nov 2025)&lt;/item&gt;
      &lt;item&gt;New updates and more access to Google Earth AI (Oct 2025)&lt;/item&gt;
      &lt;item&gt;Google Earth AI: Our state-of-the-art geospatial AI models (July 2025)&lt;/item&gt;
      &lt;item&gt;AlphaEarth Foundations helps map our planet in unprecedented detail (July 2025)&lt;/item&gt;
      &lt;item&gt;How we're supporting better tropical cyclone prediction with AI (June 2025)&lt;/item&gt;
      &lt;item&gt;Inside the launch of FireSat, a system to find wildfires earlier (March 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are working with partners to apply AI-enabled scientific progress closer to patients, opening up new avenues for disease management and therapeutic discovery.&lt;/p&gt;
    &lt;p&gt;Learn more about our health-related work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cell2Sentence-Scale 27B: How a Gemma model helped discover a new potential cancer therapy pathway (Oct 2025)&lt;/item&gt;
      &lt;item&gt;From diagnosis to treatment: Advancing AMIE for longitudinal disease management (March 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AI is proving to be a powerful tool in education, enabling new forms of understanding and expanding curiosity through initiatives like LearnLM and Guided Learning in Gemini. We brought Gemini’s most powerful translation capabilities to Google Translate, enabling much smarter, more natural and accurate translations and piloting new speech to speech translation capabilities.&lt;/p&gt;
    &lt;p&gt;Learn more about how we’re using AI to enable learning:&lt;/p&gt;
    &lt;head rend="h2"&gt;Prioritizing responsibility and safety&lt;/head&gt;
    &lt;p&gt;We couple our research breakthroughs with rigorous and forward-looking work on responsibility and safety. As our models grow more capable, we’re continuing to advance and evolve our tools, resources and safety frameworks to anticipate and mitigate risk. Gemini 3 demonstrated this approach in action: it's our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. And we’re looking further ahead, exploring a responsible path to AGI, prioritizing readiness, proactive risk assessment, and collaboration with the wider AI community.&lt;/p&gt;
    &lt;p&gt;Learn more about our responsibility and safety work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can now verify Google AI-generated videos in the Gemini app (Dec 2025)&lt;/item&gt;
      &lt;item&gt;How we’re bringing AI image verification to the Gemini app (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Strengthening our Frontier Safety Framework (September 2025)&lt;/item&gt;
      &lt;item&gt;Taking a responsible path to AGI (April 2025)&lt;/item&gt;
      &lt;item&gt;Evaluating potential cybersecurity threats of advanced AI (April 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Leading frontier collaborations with industry, academia and civil society&lt;/head&gt;
    &lt;p&gt;Advancing the frontier of AI responsibly demands collaboration across all parts of society. In 2025, we worked with leading AI labs to help to form the Agentic AI Foundation and support open standards to ensure a responsible and interoperable future for agentic AI. In education, we’ve partnered with school districts like Miami Dade County and education groups like Raspberry Pi to equip students with AI skills. Our research partnerships with universities like UC Berkeley, Yale, the University of Chicago and many more have been instrumental to some of this year’s most exciting frontier research, and we’re working with the US Department of Energy’s 17 national laboratories to transform how scientific research is conducted. And we’re working with filmmakers and other creative visionaries to put the best AI tools in their hands and explore storytelling in the age of AI.&lt;/p&gt;
    &lt;p&gt;Learn more about our work on frontier collaboration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Google DeepMind supports U.S. Department of Energy on Genesis: a national mission to accelerate innovation and scientific discovery (Dec 2025)&lt;/item&gt;
      &lt;item&gt;Formation of the Agentic AI Foundation (AAIF), Anchored by New Project Contributions Including Model Context Protocol (MCP), goose and AGENTS.md (Dec 2025)&lt;/item&gt;
      &lt;item&gt;Announcing Model Context Protocol (MCP) support for Google services (Dec 2025)&lt;/item&gt;
      &lt;item&gt;Our latest commitments in AI and learning (Nov 2025)&lt;/item&gt;
      &lt;item&gt;Partnering to power Miami’s AI-ready future (Oct 2025)&lt;/item&gt;
      &lt;item&gt;AI on Screen premiere: “Sweetwater” short film explores new AI narratives (Sept 2025)&lt;/item&gt;
      &lt;item&gt;Behind “ANCESTRA”: combining Veo with live-action filmmaking (Jun 2025)&lt;/item&gt;
      &lt;item&gt;How Indian music legend Shankar Mahadevan experiments with Music AI Sandbox (April 2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Looking ahead&lt;/head&gt;
    &lt;p&gt;As we look towards 2026, we’re looking forward to continuing to advance the frontier, safely and responsibly, for the benefit of humanity.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46374018</guid><pubDate>Wed, 24 Dec 2025 09:30:58 +0000</pubDate></item><item><title>I'm returning my Framework 16</title><link>https://yorickpeterse.com/articles/im-returning-my-framework-16/</link><description>&lt;doc fingerprint="56a45c37c90b9dd7"&gt;
  &lt;main&gt;
    &lt;p&gt; My current laptop is an aging X1 Carbon generation 7, purchased some time in mid 2019. A few months ago a few keys of the keyboard stopped working, specifically the 5, 6, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; and Delete keys. Sometimes I can get it working again by
mashing one of them for a while, but it's not consistent. Given my past
experiences with X1 Carbon laptops breaking outside of warranty and the
frustration that comes with replacing their components, I decided it was time to
look for a replacement.&lt;/p&gt;
    &lt;p&gt;Unfortunately, buying a new X1 Carbon wasn't going to be an option: when it comes to displays you now basically have two choices: a subpar not-quite-2K IPS display, or a 2.5K (ish) OLED display. Since I use my laptop for programming and often use it in low light conditions such as a living room with dimmed lights in the evening, OLED just doesn't make sense. Knowing my luck I'd also run into OLED burn-in the moment the warranty expires. There are also some other issues with the X1 line in general, such as poor CPU cooling and the absolute nightmare that is opening them up to replace parts or clean them properly.&lt;/p&gt;
    &lt;p&gt;I looked at some other brands but it appears that in 2025 there's just aren't many good options for Linux users. I narrowed it down to two options:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Buy a refurbished M1 or M2 Macbook and run Asahi Linux&lt;/item&gt;
      &lt;item&gt;Buy a Framework&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I eliminated the use of Asahi Linux because of the following reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The battery life doesn't appear to be all that better than conventional laptops when running Linux. This isn't entirely surprising because of a lot of the battery improvements on macOS are the result of the software and hardware integration, not just the hardware&lt;/item&gt;
      &lt;item&gt;There seem to be issues with suspend not working as well (at least based on various comments I came across), and hardware support in general is a bit dodgy&lt;/item&gt;
      &lt;item&gt;If something needs replacing I basically have an expensive paperweight, because everything is soldered together, assuming you could even find spare parts in the first place&lt;/item&gt;
      &lt;item&gt;I'm not sure Asahi as a project will still be around in 5 years, but my laptop will be&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In contrast, Framework laptops has many supposed benefits: they're upgradable, repairable, actively work on Linux and even FreeBSD support (or at least sponsor developers working on this), allow you to customize the keyboard using QMK/VIAL. In fact, on paper it sounds like the perfect developer laptop. In reality, I'm not so sure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration&lt;/item&gt;
      &lt;item&gt;Building the laptop&lt;/item&gt;
      &lt;item&gt;Operating system&lt;/item&gt;
      &lt;item&gt;Weight&lt;/item&gt;
      &lt;item&gt;Design&lt;/item&gt;
      &lt;item&gt;Display&lt;/item&gt;
      &lt;item&gt;Power LED&lt;/item&gt;
      &lt;item&gt;GPU&lt;/item&gt;
      &lt;item&gt;CPU&lt;/item&gt;
      &lt;item&gt;Battery&lt;/item&gt;
      &lt;item&gt;WiFi and Bluetooth&lt;/item&gt;
      &lt;item&gt;Keyboard&lt;/item&gt;
      &lt;item&gt;Trackpad&lt;/item&gt;
      &lt;item&gt;Speakers&lt;/item&gt;
      &lt;item&gt;Modular ports&lt;/item&gt;
      &lt;item&gt;Conclusion&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Configuration&lt;/head&gt;
    &lt;p&gt;Framework has three models of laptops: a 12 inch, 13.5 inch and 16 inch laptop. My X1 Carbon is a 14 inch laptop but I've always felt like I wanted something just slightly larger. I ended up buying the Framework 16 for two reason:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I read various reports of the Framework 13 having issues with poor battery life, fan noise, heating, etc&lt;/item&gt;
      &lt;item&gt;While 16 inch is a fair bit larger than 14 inch, I was hoping it would be manageable size wise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The base configuration is as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework 16 DIY edition&lt;/item&gt;
      &lt;item&gt;CPU: Ryzen AI 7 350&lt;/item&gt;
      &lt;item&gt;RAM: 2x8 GiB DDR5-5600&lt;/item&gt;
      &lt;item&gt;SSD: WD Black SN7100, 500 GiB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also bought an additional Intel AX210 WiFi card in case the default Mediatek card would cause any trouble, as I don't trust brands other than Intel when it comes to WiFi.&lt;/p&gt;
    &lt;p&gt;Shipping took about a week or so, with the laptop making quite the journey from Taiwan to the Philippines to China, then to Japan and then back to China, then to Istanbul, then to France and at last to The Netherlands. I'm not sure what happened here, maybe the pilot got drunk or perhaps Fedex' tracking is just broken.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building the laptop&lt;/head&gt;
    &lt;p&gt;I bought the DIY edition which requires some manual assembly, though not nearly as much as I feared. All I had to do was install the SSD, RAM, and the keyboard spacers. The spacers, touchpad and keyboard use magnetic connectors so installing and removing them is trivial. To access the SSD and RAM slots you need to unscrew a plate that sits between these slots and the keyboard, but this only takes a few minutes using the provided screwdriver.&lt;/p&gt;
    &lt;p&gt;I didn't measure how long it took me to install it the first time, but opening it up and putting it back together a second time only took perhaps 5-10 minutes at most. For comparison, to replace most parts of the X1 Carbon you essentially have to take the whole thing apart and unscrew countless screws many of which are hard to find. Unsurprisingly, I've lost some of these screws over the years and dreaded opening it up the few times I had to.&lt;/p&gt;
    &lt;p&gt;This is an area where Framework excels compared to all other brands: it's just so easy to swap the parts out that it puts other brands to shame when it comes to hardware maintainability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Operating system&lt;/head&gt;
    &lt;p&gt;For the operating system I initially gave FreeBSD 15 a quick try. I knew it wasn't going to be the final OS due to it still having issues with the Framework hardware (e.g. suspend doesn't work properly), but I figured it was worth a try just to see what would happen. The installation went fine and WiFi worked fine, though that was because I swapped the Mediatek card with the Intel AX210 as the Mediatek card doesn't work at all on FreeBSD. Upon loading the AMD drivers I encountered a kernel crash, likely due to the same issue as discussed in this drm-kmod issue. A laptop without working GPU drivers isn't going to work, so at this point I decided to give up on FreeBSD (again) and install Fedora 43 instead.&lt;/p&gt;
    &lt;p&gt;Fedora 43 worked just fine as expected, and everything worked, so let's take a look at the hardware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Weight&lt;/head&gt;
    &lt;p&gt;The Framework 16 weights about 2.2 kg according to my kitchen scale. For comparison, my X1 Carbon weights 1.3 kg. That may not seem like a big difference, but the extra kilogram makes carrying around the Framework 16 more difficult. In particular, I don't feel comfortable carrying it with just one hand while this isn't a problem with the X1.&lt;/p&gt;
    &lt;p&gt;The Framework is best described as a bit of a chonker and I certainly don't see myself carrying it around a lot. This also gives it a bit of an identity crisis: laptops should be portable, otherwise why not just get a desktop. And yet the Framework 16 is neither portable nor remotely as powerful as a desktop, so who exactly is the target audience?&lt;/p&gt;
    &lt;head rend="h2"&gt;Design&lt;/head&gt;
    &lt;p&gt;The design of the laptop is a bit polarizing. I like the combination of black and silver, but I hate how janky it all looks and feels due to the removable spacers. Note the lines separating the touchpad from the spacers on the left and right of it:&lt;/p&gt;
    &lt;p&gt;Not only does it look weird, you can also feel the gap and edges when resting your palm on them. The silver spacers and touchpad are also raised slightly relative to the black keyboard area, and the edges are quite sharp. If you have arm hairs you may consider shaving them off or risk getting them stuck. I also suspect gunk will build up in these edges over time.&lt;/p&gt;
    &lt;p&gt;The spacers aren't held solid in place either, meaning you can move them around and they have a bit of flex to them:&lt;/p&gt;
    &lt;p&gt;You may need to turn up your volume to hear the noise the spacers make. Also, apologies for the vertical video!&lt;/p&gt;
    &lt;p&gt;There's also a practical problem: due to the flex of the spacers if you try to hold the laptop on its sides it will actually "wobble" a bit. Combined with the weight I suspect that unless you hold on to this laptop for dear life, you will at some point drop it.&lt;/p&gt;
    &lt;p&gt;These issues could be considered a minor issue in isolation but remember, this model costs two thousand Euros (I'll bring this up a few more times). For a premium price I expect a premium design and build quality, and this isn't it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Display&lt;/head&gt;
    &lt;p&gt;The display isn't terrible, but it's not great either. Like most laptop displays that aren't Macbooks there's a bit of flex to the display, though this shouldn't be much of an issue. The colors of the display are overly saturated, with reds in particular looking more intense than they should. Here's a silly example of what a particular shade of red looks like on my X1 Carbon:&lt;/p&gt;
    &lt;p&gt;And here's the same color on the Framework 16:&lt;/p&gt;
    &lt;p&gt;Note that both displays were using the same brightness and the same color temperature/night light setting. For comparison, here's what those colors should look like when using a properly calibrated (at the hardware level at least) Eizo CS2740 that I use for my desktop:&lt;/p&gt;
    &lt;p&gt;I'm aware the quality of the photos isn't great, but if you compare the Framework version to the others you'll notice the colors are more saturated compared to what they should look like.&lt;/p&gt;
    &lt;p&gt;The white/grey uniformity also leaves a lot to be desired, though this is true for all modern IPS displays that aren't manufactured by Eizo:&lt;/p&gt;
    &lt;p&gt;I find non-uniform displays distracting as it can create a sort of tunnel vision effect/feeling. While the X1 Carbon also suffers from this problem, it feels less pronounced than in case of the Framework. Of course the Eizo display doesn't suffer from this problem at all (hence I bought it), but then it again it costs a ridiculous €1700.&lt;/p&gt;
    &lt;p&gt;Which brings us to the brightness. This display is bright, even at the lowest setting. I found various forum posts that mention the Framework 13 suffers from a similar issue but that you can at least now lower the brightness further on recent versions of Linux, but this isn't supported for the Framework 16. Here's what that looks like in practice:&lt;/p&gt;
    &lt;p&gt;The Framework 16 is on the left and the X1 Carbon on the right, both set to the lowest brightness setting that is still usable.&lt;/p&gt;
    &lt;p&gt;The Framework 16 being so much brighter means that using it in a darker room (e.g. a living room at night with the lights dimmed) makes you feel like a deer looking into the headlights of a car that's about to run you over. In other words, not fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Power LED&lt;/head&gt;
    &lt;p&gt;On the topic of brightness, the power button in the top right corner of the keyboard has an LED that can't be turned off in the BIOS. Instead, you can set it to a few different settings including "Ultra low", but it doesn't make much of a difference as even at the lowest setting it's still too bright. This wouldn't be so bad if it wasn't sitting in the bottom right corner of your eye when you look at the display.&lt;/p&gt;
    &lt;p&gt;I ended up using this systemd service to turn the LED off upon booting, but something as simple as this should just be a BIOS option. Not being able to turn the LED off is apparently a feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPU&lt;/head&gt;
    &lt;p&gt;I didn't do any GPU intensive testing such as video decoding. One annoying issue is that the display has a tendency to flicker. On top of that, there's a "nice" feature where the GPU reduces the display brightness based on the contents on the screen to conserve battery. The problem is that it takes a good two seconds or so to adjust, making it obvious and jarring to look at. It's especially noticeable when switching to the workspace overview in Gnome and back, due to a large section of this overview being a dark color.&lt;/p&gt;
    &lt;p&gt;This feature is disabled by adding &lt;code&gt;amdgpu.abmlevel=0&lt;/code&gt; to &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt;
in &lt;code&gt;/etc/default/grubg&lt;/code&gt;, followed by running &lt;code&gt;sudo grub2-mkconfig -o
/boot/grub2/grub.cfg&lt;/code&gt; and a reboot. This also seems to reduce the amount of
flickering, though it still happened a few times after applying this setting.&lt;/p&gt;
    &lt;p&gt;Some additional details on the ambient dimming anti-feature are in this forum post.&lt;/p&gt;
    &lt;p&gt;I can see the value of this feature but only if the GPU waits longer before adjusting the brightness and increases the transition time so it's less obvious. In it's current form it's just a nuisance.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU&lt;/head&gt;
    &lt;p&gt;The CPU is fine, though I didn't extensively test its performance. It's certainly better than the mediocre Intel CPU of my X1 Carbon. One thing I noticed is that the CPU makes a sort of coil whine/crackling BZZZZZZ noise when under load. This isn't unique to Framework (e.g. my X1 also does this), the more open design (e.g. there's a big fan grill/mesh at the top of the keyboard) makes this more noticeable.&lt;/p&gt;
    &lt;p&gt;I can't speak about the fan noise because I never heard them. This could either mean they are quiet enough or that I didn't stress the CPU enough.&lt;/p&gt;
    &lt;head rend="h2"&gt;Battery&lt;/head&gt;
    &lt;p&gt;I didn't do any proper testing of battery usage, but it seems to be on par with other Linux capable laptops based on my usage thus far. This means you'll likely be looking at 6-8 hours of battery per charge for average programming usage. It seems this is the case for basically any reasonable Linux-capable laptop these days, unfortunately.&lt;/p&gt;
    &lt;p&gt;I did notice that it drains quite a bit when suspended: when I put it to sleep the first night the battery was at 47%. When I opened the laptop again some 8 hours later the battery was at 42%. This means you're looking at about 5% of battery per average night, which isn't great. Hibernate could be an alternative but support for it on Fedora is a bit dodgy and requires some manual work I'm not interested in, so I didn't test this.&lt;/p&gt;
    &lt;head rend="h2"&gt;WiFi and Bluetooth&lt;/head&gt;
    &lt;p&gt;Both the Intel and Mediatek cards work without issue. Both achieve the same speeds on my 1 Gbps connection over a 5Ghz network (with a channel width of 80mhz): about 800-900 Mbps for uploads and somewhere between 600 and 700 Mbps for downloads. While not being able to achieve the full 1 Gbps speed over WiFi is expected, I was a bit surprised to see that uploads are in fact faster than downloads.&lt;/p&gt;
    &lt;p&gt;I tested various other devices with similar WiFi hardware and they all upload and download at about the same speeds, and all operate at slightly lower speeds (500-600 Mbps, depending on your luck).&lt;/p&gt;
    &lt;p&gt;I don't think it's the network itself either: the access points are TP-Link EAP660 HDs that can handle speeds well beyond 1 Gbps. As far as I know the configuration is also sound (including the use of specific channels to reduce interference to a minimum).&lt;/p&gt;
    &lt;p&gt;Still, 600-700 Mbps over WiFi is more than I'll probably ever need so I didn't dive into this further.&lt;/p&gt;
    &lt;p&gt;I didn't specifically test Bluetooth but it did detect a few devices, so I'll assume this will work just fine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Keyboard&lt;/head&gt;
    &lt;p&gt;Some reviews I read mentioned that the keyboard has a bit of flex to it, but I didn't notice this. The keycaps are a little mushy, which isn't too bad but not great either. The difference in key size and spacing compared to the X1 did mean I pressed the wrong key at times, but I suspect this is just a matter of adjusting.&lt;/p&gt;
    &lt;p&gt;The keyboard runs QMK, albeit a rather outdated version of QMK released in 2022. I experimented with porting the code to a newer version so I could take advantage of some features that I use in my split keyboard, but couldn't get it to work. The official way to configure the keyboard is by using this VIAL web application. This application requires WebHID support which isn't implemented by Firefox, requiring me to install and use Chromium just to configure the keyboard. This isn't enough though, as on Linux you'll need to install some additional udev rules to get things working. The official rules provided by QMK didn't work, instead I used the rules from this forum reply.&lt;/p&gt;
    &lt;p&gt;Once set up I was able to configure the keyboard such as by changing the layout from QWERTY to Colemak-DH. VIAL is pretty basic though and the interface is rather clunky, so I'm not a fan of this approach. I hope that at some point Framework will upstream their keyboard logic into the official QMK repository to make this process easier.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trackpad&lt;/head&gt;
    &lt;p&gt;The trackpad is decent, though I noticed it's overly sensitive when it comes to scrolling. For example, on various occasions I lifted my fingers off the trackpad without any swiping motion and somehow still managed to trigger a scrolling motion. The trackpad of the X1 Carbon doesn't have this problem and subsequently is easier and more pleasant to use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Speakers&lt;/head&gt;
    &lt;p&gt;They're terribly. Or more precisely, they're terrible when the volume is less than 50% or so. What appears to be happening is that adjusting the volume below 50% doesn't result in it being louder but instead changes how it sounds (for a lack of a better description). At lower volumes it sounds like sound playing over a phone in speaker mode, with a sort of tin can/metallic sound to it. Once you hit 50% or so it starts to sound more like an OK set of speakers but it also becomes noticeable louder. There's a setting in the BIOS that you can set to "Linux" mode to supposedly improve the quality but it was already set to this value.&lt;/p&gt;
    &lt;p&gt;While most laptop speakers aren't great (even the Dolby Atmos speakers of the X1 Carbon are mediocre), for a laptop that costs two thousand Euros the sound is disappointing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular ports&lt;/head&gt;
    &lt;p&gt;An interesting feature of the Framework is that you can swap out the various ports. You want 6 USB-C ports? You can do that! What about 3 headphone jacks? Also possible! Replacing them is quite easy, though for some reason my headphone jack adapter required some additional force to be removed.&lt;/p&gt;
    &lt;p&gt;Like the keyboard area the design is a bit janky though, with visible lines/space between the adapters and the case, though this at least is something you won't notice unless you're explicitly looking for it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Which brings me to the conclusion: is it worth buying this laptop, considering most configurations will cost you around two thousand Euros? To be honest, no, not at all. For a premium price I expect a premium laptop, but the Framework 16 feels more like a €1200-€1500 laptop at best and certainly doesn't deliver a premium experience. I understand Framework is a young company still trying to figure out a lot of things, but two thousand Euros for this kind of laptop is just absurd.&lt;/p&gt;
    &lt;p&gt;For this reason I've submitted a request to return the laptop. What I'll be replacing my X1 Carbon with instead I'm not entirely sure of. One option is the Framework 13 given that it solves at least some issues I have with the Framework 16 (e.g. it's bulkiness and inability to lower the brightness further), but it also seems to share many of the other issues such as poor speaker quality and (at least from hat I could find) worse heat regulation, and a (possibly) worse battery.&lt;/p&gt;
    &lt;p&gt;I've looked at various other brands such as System76 and the many other Clevo resellers, but they all seem to suffer similar issues such as poor battery life, poor performance, difficult to maintain hardware wise, or some combination thereof.&lt;/p&gt;
    &lt;p&gt;I guess for now the X1 Carbon will have to hold out a little longer, provided I don't throw it out of the window the next time I can't get the various dodgy keyboard keys to work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46375174</guid><pubDate>Wed, 24 Dec 2025 12:55:19 +0000</pubDate></item><item><title>My 2026 Open Social Web Predictions</title><link>https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html</link><description>&lt;doc fingerprint="b8beabfa6dac4a7a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My 2026 Open Social Web Predictions&lt;/head&gt;
    &lt;p&gt;I just finished reviewing my 2025 predictions (how do you think I did grading myself?) www.timothychambers.net/2024/12/2…&lt;/p&gt;
    &lt;p&gt;Now it’s time to make some bets for 2026. I do this not to prove how great my prognostication muscles are, but to shine a spotlight on trends I think are vital, spur discussions, and give some attention to projects that have earned it. As always, I try to make these as quantifiable, verifiable and crisp as I can. Here goes:&lt;/p&gt;
    &lt;p&gt;🌱 MILD&lt;/p&gt;
    &lt;p&gt;Safe bets — would be surprising if these DON’T happen.&lt;/p&gt;
    &lt;p&gt;▶️ Bluesky will cross 60 million registered users in 2026. Growth will slow from 2024’s explosive pace but remain steady, driven by continued X dissatisfaction and improved features.&lt;/p&gt;
    &lt;p&gt;▶️ The ActivityPub Fediverse (excluding Threads) will cross 15 million registered users, monthly active users (excluding will plateau around 2-3 million. Another good year in terms of stable base, but no big waves of new users. Both Bluesky and Fediverse growth won’t come from big waves of migration this year.&lt;/p&gt;
    &lt;p&gt;▶️ Any smaller waves from X/Twitter or from a newly bought TikTok will benefit Meta (Threads/IG), BlueSky, and Fediverse in that order. I see nothing that would change that prediction that was true last year, too.&lt;/p&gt;
    &lt;p&gt;▶️ Threads will pass 500 million monthly active users and remain the largest ActivityPub-adjacent platform by a wide margin. But see the next prediction:&lt;/p&gt;
    &lt;p&gt;▶️ Threads federation will remain partial, and opt-in through all of 2026. Full two-way federation will NOT ship in 2026 but may move from about 90 percent there, to 95 percent done, inching forward but not finalized and prioritized as a feature. As Manton wrote, that’s better than fully closed, and better than them stripping it out. (which they might do but I’m predicting not) My bet: the status quo continues. www.manton.org/2025/12/1…&lt;/p&gt;
    &lt;p&gt;▶️ Ghost’s ActivityPub integration will bring 75,000+ new federated accounts to the Fediverse and Ghost will finish 2026 in the top 10 Fediverse server software by MAU.&lt;/p&gt;
    &lt;p&gt;▶️ WordPress-based federated accounts will cross 50,000 as measured by FediDB. Currently at approximately 26,000 accounts across 12,700 servers, the WordPress-to-Fediverse pipeline becomes a meaningful growth contributor.&lt;/p&gt;
    &lt;p&gt;🔥 MEDIUM-SPICEY Plausible bets — could go either way, but evidence points toward yes.&lt;/p&gt;
    &lt;p&gt;▶️ BridgyFed will shift to “opt-out” for Bluesky users bridging to ActivityPub — and the discourse will be far less contentious than the 2024 debates predicted. Cross-protocol interoperability quietly normalizes.&lt;/p&gt;
    &lt;p&gt;▶️ At least one fully independent ATProto stack — PDS, Relay, and AppView operating without dependency on Bluesky PBC infrastructure — will achieve viability in 2026, meaning it has paying customers or sustainable funding. This will be the year ATProto proves (or fails to prove) it can exist beyond Bluesky-the-company.&lt;/p&gt;
    &lt;p&gt;▶️ Mastodon gGmbH will hit key sustainability milestones in 2026. Their hosting revenue model will exceed internal targets, the new organizational structure will unlock additional grant funding (beyond NGI/NLnet), and the pace of Mastodon development will noticeably accelerate — shipping more significant features in 2026 than in the previous two years combined.&lt;/p&gt;
    &lt;p&gt;▶️ Bluesky PBC will raise another round of funding in 2026 and announce more details on a proposed business model. Following their $15M Series A (October 2024), the company will close a larger round to extend runway. The announced business model will NOT be advertising-based. I’d expect subscriptions, marketplace fees, or enterprise services.&lt;/p&gt;
    &lt;p&gt;▶️ The first “ATProto-native” social app that is NOT microblogging will cross 100,000 users. Whether it’s Frontpage (link aggregation), Leaflet (long-form), Smoke Signal, or something new — the ATmosphere diversifies beyond Bluesky-the-app.&lt;/p&gt;
    &lt;p&gt;▶️ Flipboard’s Surf app will launch its 1.0 version in 2026 and cross 1 million downloads across iOS and Android by year end, with 100,000+ monthly active users. It will become the most-downloaded dedicated Open Social Web client, surpassing Mastodon’s official app and Graysky.&lt;/p&gt;
    &lt;p&gt;▶️ Fedify will power the federation layer for at least one mid-sized social platform (500K+ users) that adds ActivityPub support in 2026. The “build vs. buy” calculation for federation shifts decisively toward “just use Fedify.”&lt;/p&gt;
    &lt;p&gt;▶️ Fediscovery will ship in a stable Mastodon release in 2026, moving from behind feature flags to production-ready. The specifications for pluggable discovery providers — covering account search, follow recommendations, and trends — will reach 1.0 status, and at least one public Fediscovery-compatible provider will launch for general use. Small instance operators will finally have a real option to improve discovery without running their own infrastructure.&lt;/p&gt;
    &lt;p&gt;▶️ The new “ActivityRank” algorithm in Loops will prove that ethical recommendations and decentralization can coexist. Dan Supernault’s approach — where each instance trains its own algorithm while surfacing content across the ActivityPub network — will be recognized as a breakthrough in solving the fediverse’s discoverability problem. By the end of 2026, the pattern will be studied or adopted by at least two other ActivityPub platforms.&lt;/p&gt;
    &lt;p&gt;▶️ ATProto will advance from Internet Drafts to an official IETF Working Group in 2026. Following the September 2025 submission of initial specifications, Bluesky will secure enough support and independent implementers to form a dedicated Working Group — moving from “proposal being discussed” to “standard being formally developed.”&lt;/p&gt;
    &lt;p&gt;🌶️ SPICY Hot takes - a bit more risky - but I’m calling my shot.&lt;/p&gt;
    &lt;p&gt;▶️ A well-known digital-native media publication (10M+ monthly visitors) will federate via ActivityPub in 2026 and publicly share positive results. Whether through Ghost, WordPress, or custom implementation, this outlet will report that federated followers drove meaningful engagement — making the business case for federation legible to other publishers for the first time. By year end, at least two additional publications will announce federation plans, citing this pioneer as proof of concept.&lt;/p&gt;
    &lt;p&gt;▶️ At least one major news organization (top 50 US by traffic) will announce it is leaving X/Twitter entirely and making Bluesky or the Fediverse its primary social distribution channel. The “institutional exodus” begins.&lt;/p&gt;
    &lt;p&gt;▶️ At least one major national government or major city will launch an official presence on BOTH Bluesky AND the ActivityPub Fediverse in 2026 — and it will be a European government. Expect surprising additional early adopters after this from Latin America, Asia-Pacific, or Africa to follow that lead and make moves that year to do the same. This is the year the move to “digital sovereignty" from US tech will benefit the open social web. Eurosky will inch along with some promise.&lt;/p&gt;
    &lt;p&gt;▶️ Nostr ↔ ATProto ↔ ActivityPub three-way bridging becomes functional via BridgyFed or another service by end of 2026. The “protocol wars” narrative collapses into “just pick your client.”&lt;/p&gt;
    &lt;p&gt;▶️ AltStore will be live with Federation features in at least 5 countries by end of 2026 (currently EU + Japan, with Brazil, Australia, UK announced). AltStore is an independent iOS app marketplace created by Riley Testut and Shane Gill — the first major alternative to Apple’s App Store, made possible by the EU’s Digital Markets Act. The federated app marketplace model will prove viable outside Europe, challenging Apple’s App Store dominance in multiple regulatory regimes simultaneously. Their ActivityPub integration — where app updates flow to Mastodon, Threads, and Bluesky — will become the most compelling non-social-media use case for decentrlized social features, proving definitively that such protocols extends beyond microblogging.&lt;/p&gt;
    &lt;p&gt;▶️ Loops will become the third most-used Fediverse software by MAU by end of 2026, trailing only Mastodon and Pixelfed. The short-form video platform will cross 100,000 monthly active users, with Loops-originated content generating significant federated engagement from non-Loops clients — proving that ActivityPub can power video-centric social experiences.&lt;/p&gt;
    &lt;p&gt;▶️ PieFed will emerge as the most feature-rich Threadiverse platform by end of 2026, surpassing Lemmy and Mbin in moderation tools, user experience, and federation capabilities. The platform will cross 10,000 monthly active users and its rapid development pace — shipping major features weekly — will make it the default recommendation for anyone starting a new Reddit-style community in the fediverse.&lt;/p&gt;
    &lt;p&gt;▶️ More laws akin to Utah’s Digital Choice Act will pass or advance - sparking first steps towards interoperability to mainstream US discourse. The Utah law takes effect July 1, 2026, and several other states will pass similar ones, requiring social media platforms to enable data portability and interoperability. At least one major platform will announce ActivityPub or AT Protocol support to comply. The “Digital Choice” framing will prove more politically viable than “antitrust” for breaking Big Tech’s lock-in.&lt;/p&gt;
    &lt;p&gt;What did I miss? What did I get wrong? Let me know — and I’ll see you in December 2026 to grade these.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46376652</guid><pubDate>Wed, 24 Dec 2025 15:59:23 +0000</pubDate></item><item><title>Show HN: Vibium – Browser automation for AI and humans, by Selenium's creator</title><link>https://github.com/VibiumDev/vibium</link><description>&lt;doc fingerprint="8d362e50e91db4ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Browser automation without the drama.&lt;/p&gt;
    &lt;p&gt;Vibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server — so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.&lt;/p&gt;
    &lt;p&gt;New here? Getting Started Tutorial — zero to hello world in 5 minutes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Interface&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Clicker&lt;/cell&gt;
        &lt;cell&gt;Browser automation, BiDi proxy, MCP server&lt;/cell&gt;
        &lt;cell&gt;CLI / stdio / WebSocket :9515&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;JS Client&lt;/cell&gt;
        &lt;cell&gt;Developer-facing API&lt;/cell&gt;
        &lt;cell&gt;npm package&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│                         LLM / Agent                         │
│          (Claude Code, Codex, Gemini, Local Models)         │
└─────────────────────────────────────────────────────────────┘
                      ▲
                      │ MCP Protocol (stdio)
                      ▼
           ┌─────────────────────┐         
           │   Vibium Clicker    │
           │                     │
           │  ┌───────────────┐  │
           │  │  MCP Server   │  │
           │  └───────▲───────┘  │         ┌──────────────────┐
           │          │          │         │                  │
           │  ┌───────▼───────┐  │WebSocket│                  │
           │  │  BiDi Proxy   │  │◄───────►│  Chrome Browser  │
           │  └───────────────┘  │  BiDi   │                  │
           │                     │         │                  │
           └─────────────────────┘         └──────────────────┘
                      ▲
                      │ WebSocket BiDi :9515
                      ▼
┌─────────────────────────────────────────────────────────────┐
│                        JS/TS Client                         │
│                     npm install vibium                      │
│                                                             │
│    ┌─────────────────┐               ┌─────────────────┐    │
│    │ Async API       │               │    Sync API     │    │
│    │ await vibe.go() │               │    vibe.go()    │    │
│    │                 │               │                 │    │
│    └─────────────────┘               └─────────────────┘    │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;A single Go binary (~10MB) that does everything:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser Management: Detects/launches Chrome with BiDi enabled&lt;/item&gt;
      &lt;item&gt;BiDi Proxy: WebSocket server that routes commands to browser&lt;/item&gt;
      &lt;item&gt;MCP Server: stdio interface for LLM agents&lt;/item&gt;
      &lt;item&gt;Auto-Wait: Polls for elements before interacting&lt;/item&gt;
      &lt;item&gt;Screenshots: Viewport capture as PNG&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Design goal: The binary is invisible. JS developers just &lt;code&gt;npm install vibium&lt;/code&gt; and it works.&lt;/p&gt;
    &lt;code&gt;// Option 1: require (REPL-friendly)
const { browserSync } = require('vibium')

// Option 2: dynamic import (REPL with --experimental-repl-await)
const { browser } = await import('vibium')

// Option 3: static import (in .mjs or .ts files)
import { browser, browserSync } from 'vibium'&lt;/code&gt;
    &lt;p&gt;Sync API:&lt;/p&gt;
    &lt;code&gt;const fs = require('fs')
const { browserSync } = require('vibium')

const vibe = browserSync.launch()
vibe.go('https://example.com')

const png = vibe.screenshot()
fs.writeFileSync('screenshot.png', png)

const link = vibe.find('a')
link.click()
vibe.quit()&lt;/code&gt;
    &lt;p&gt;Async API:&lt;/p&gt;
    &lt;code&gt;const fs = await import('fs/promises')
const { browser } = await import('vibium')

const vibe = await browser.launch()
await vibe.go('https://example.com')

const png = await vibe.screenshot()
await fs.writeFile('screenshot.png', png)

const link = await vibe.find('a')
await link.click()
await vibe.quit()&lt;/code&gt;
    &lt;p&gt;One command to add browser control to Claude Code:&lt;/p&gt;
    &lt;code&gt;claude mcp add vibium -- npx -y vibium&lt;/code&gt;
    &lt;p&gt;That's it. No manual steps needed. Chrome downloads automatically during setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_launch&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start browser (visible by default)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_navigate&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_find&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find element by CSS selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_click&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Click an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_type&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Type text into an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Capture viewport (base64 or save to file with &lt;code&gt;--screenshot-dir&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close browser&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install vibium&lt;/code&gt;
    &lt;p&gt;This automatically:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Installs the Clicker binary for your platform&lt;/item&gt;
      &lt;item&gt;Downloads Chrome for Testing + chromedriver to platform cache: &lt;list rend="ul"&gt;&lt;item&gt;Linux: &lt;code&gt;~/.cache/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;macOS: &lt;code&gt;~/Library/Caches/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Windows: &lt;code&gt;%LOCALAPPDATA%\vibium\&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No manual browser setup required.&lt;/p&gt;
    &lt;p&gt;Skip browser download (if you manage browsers separately):&lt;/p&gt;
    &lt;code&gt;VIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Architecture&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;x64 (Intel)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;arm64 (Apple Silicon)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As a library:&lt;/p&gt;
    &lt;code&gt;import { browser } from "vibium";

const vibe = await browser.launch();
await vibe.go("https://example.com");
const el = await vibe.find("a");
await el.click();
await vibe.quit();&lt;/code&gt;
    &lt;p&gt;With Claude Code:&lt;/p&gt;
    &lt;p&gt;Once installed via &lt;code&gt;claude mcp add&lt;/code&gt;, just ask Claude to browse:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Go to example.com and click the first link"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See CONTRIBUTING.md for development setup and guidelines.&lt;/p&gt;
    &lt;p&gt;V1 focuses on the core loop: browser control via MCP and JS client.&lt;/p&gt;
    &lt;p&gt;See V2-ROADMAP.md for planned features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python and Java clients&lt;/item&gt;
      &lt;item&gt;Cortex (memory/navigation layer)&lt;/item&gt;
      &lt;item&gt;Retina (recording extension)&lt;/item&gt;
      &lt;item&gt;Video recording&lt;/item&gt;
      &lt;item&gt;AI-powered locators&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-12-22: Day 12 - Published to npm&lt;/item&gt;
      &lt;item&gt;2025-12-21: Day 11 - Polish &amp;amp; Error Handling&lt;/item&gt;
      &lt;item&gt;2025-12-20: Day 10 - MCP Server&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 9 - Actionability&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 8 - Elements &amp;amp; Sync API&lt;/item&gt;
      &lt;item&gt;2025-12-17: Halfway There&lt;/item&gt;
      &lt;item&gt;2025-12-16: Week 1 Progress&lt;/item&gt;
      &lt;item&gt;2025-12-11: V1 Announcement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377597</guid><pubDate>Wed, 24 Dec 2025 17:49:02 +0000</pubDate></item><item><title>Fabrice Bellard: Biography (2009) [pdf]</title><link>https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377862</guid><pubDate>Wed, 24 Dec 2025 18:17:47 +0000</pubDate></item><item><title>Show HN: Minimalist editor that lives in browser, stores everything in the URL</title><link>https://github.com/antonmedv/textarea</link><description>&lt;doc fingerprint="2a34105e063698ad"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimalist text editor that lives entirely in your browser and stores everything in the URL hash.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;📝 It's a textarea! Actually not.&lt;/item&gt;
      &lt;item&gt;🗜️ Compression magic - Your text gets compressed with deflate because we're fancy like that&lt;/item&gt;
      &lt;item&gt;🔗 URL storage - Share your notes by copying a 500-character URL. Your friends will love it!&lt;/item&gt;
      &lt;item&gt;🌓 Dark mode - Respects your poor eyes and your color scheme preference&lt;/item&gt;
      &lt;item&gt;💾 Auto-save - Debounced to 500ms because we're not savages&lt;/item&gt;
      &lt;item&gt;📱 Mobile friendly - Type your manifesto on the go&lt;/item&gt;
      &lt;item&gt;🎯 No backend - Zero servers were harmed in the making of this app&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open textarea.my&lt;/item&gt;
      &lt;item&gt;Type stuff&lt;/item&gt;
      &lt;item&gt;Marvel at the URL getting longer&lt;/item&gt;
      &lt;item&gt;Try to share it&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
      &lt;item&gt;Profit&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start your document with &lt;code&gt;# Title&lt;/code&gt;to set a custom page title&lt;/item&gt;
      &lt;item&gt;Your data lives in localStorage AND the URL. Double the fun!&lt;/item&gt;
      &lt;item&gt;Feeling fancy? Add a &lt;code&gt;style&lt;/code&gt;attribute to the&lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt;tag via DevTools. It'll be saved in the URL too!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ❤️ and JavaScript&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46378554</guid><pubDate>Wed, 24 Dec 2025 19:42:25 +0000</pubDate></item><item><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><link>https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer</link><description>&lt;doc fingerprint="a3b096f07e6fa468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379173</guid><pubDate>Wed, 24 Dec 2025 21:01:05 +0000</pubDate></item><item><title>Nvidia buying AI chip startup Groq for about $20B in cash</title><link>https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html</link><description>&lt;doc fingerprint="22d081694f3ed1b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Nvidia has agreed to buy assets from Groq, a designer of high-performance artificial intelligence accelerator chips, for $20 billion in cash, according to Alex Davis, CEO of Disruptive, which led the startup's latest financing round in September.&lt;/p&gt;
    &lt;p&gt;Davis, whose firm has invested more than half a billion dollars in Groq since the company was founded in 2016, said the deal came together quickly. Groq raised $750 million at a valuation of about $6.9 billion three months ago. Investors in the round included Blackrock and Neuberger Berman, as well as Samsung, Cisco, Altimeter and 1789 Capital, where Donald Trump Jr. is a partner.&lt;/p&gt;
    &lt;p&gt;Groq said in a blog post on Wednesday that it's "entered into a non-exclusive licensing agreement with Nvidia for Groq's inference technology," without disclosing a price. With the deal, Groq founder and CEO Jonathan Ross along with Sunny Madra, the company's president, and other senior leaders "will join Nvidia to help advance and scale the licensed technology," the post said.&lt;/p&gt;
    &lt;p&gt;Groq added that it will continue as an "independent company," led by finance chief Simon Edwards as CEO.&lt;/p&gt;
    &lt;p&gt;Colette Kress, Nvidia's CFO, declined comment on the transaction.&lt;/p&gt;
    &lt;p&gt;Davis told CNBC that Nvidia is getting all of Groq's assets, though its nascent Groq cloud business is not part of the transaction. Groq said "GroqCloud will continue to operate without interruption."&lt;/p&gt;
    &lt;p&gt;The deal represents by far Nvidia's largest purchase ever. The chipmaker's biggest acquisition to date came in 2019, when it bought Israeli chip designer Mellanox for close to $7 billion. At the end of October, Nvidia had $60.6 billion in cash and short-term investments, up from $13.3 billion in early 2023.&lt;/p&gt;
    &lt;p&gt;In an email to employees that was obtained by CNBC, Nvidia CEO Jensen Huang said the agreement will expand Nvidia's capabilities.&lt;/p&gt;
    &lt;p&gt;"We plan to integrate Groq's low-latency processors into the NVIDIA AI factory architecture, extending the platform to serve an even broader range of AI inference and real-time workloads," Huang wrote.&lt;/p&gt;
    &lt;p&gt;Huang added that, "While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company."&lt;/p&gt;
    &lt;p&gt;Nvidia orchestrated a similar but smaller deal in September, when it shelled out over $900 million to hire Enfabrica CEO Rochan Sankar and other employees at the AI hardware startup, and to license the company's technology, CNBC reported at the time.&lt;/p&gt;
    &lt;p&gt;Other tech giants, including Meta, Google and Microsoft, have spent heavily over the last couple years to hire top AI talent through various types of licensing deals.&lt;/p&gt;
    &lt;p&gt;Nvidia has ramped up its investments in chip startups and the broader ecosystem as its cash pile has mounted. The company has backed AI and energy infrastructure company Crusoe, AI model developer Cohere, and boosted its investment in CoreWeave as the AI-centric cloud provider was getting ready to go public this year.&lt;/p&gt;
    &lt;p&gt;In September, Nvidia said it intended to invest up to $100 billion in OpenAI, with the startup committed to deploying at least 10 gigawatts of Nvidia products. The companies have yet to announce a formal deal. That same month, Nvidia said it would invest $5 billion in Intel as part of a partnership.&lt;/p&gt;
    &lt;p&gt;Groq has been targeting revenue of $500 million this year amid booming demand for AI accelerator chips used in speeding up the process for large language models to complete inference-related tasks. The company was not pursuing a sale when it was approached by Nvidia, Davis said.&lt;/p&gt;
    &lt;p&gt;Groq was founded in 2016 by a group of former engineers, including Ross. He was one of the creators of Google's tensor processing unit, or TPU, the search giant's custom chip that's being used by some companies as an alternative to Nvidia's graphics processing units.&lt;/p&gt;
    &lt;p&gt;In its initial filing with the SEC, announcing a $10.3 million fundraising in late 2016, Groq listed as principals Ross and Douglas Wightman, an entrepreneur and former engineer at the Google X "moonshot factory." Wightman left Groq in 2019, according to his LinkedIn profile.&lt;/p&gt;
    &lt;p&gt;Groq isn't the only chip startup that's gained traction during the AI boom.&lt;/p&gt;
    &lt;p&gt;AI chipmaker Cerebras Systems had planned to go public this year but withdrew its IPO filing in October after announcing that it raised over $1 billion in a fundraising round.&lt;/p&gt;
    &lt;p&gt;In a filing with the SEC, Cerebras said it does not intend to conduct a proposed offering "at this time," but didn't provide a reason. A spokesperson told CNBC at the time that the company still hopes to go public as soon as possible.&lt;/p&gt;
    &lt;p&gt;Cerebras filed for an IPO in late 2024, as it was ramping up to take on Nvidia in an effort to create processors for running generative AI models.&lt;/p&gt;
    &lt;p&gt;— CNBC's Jordan Novet contributed to this report.&lt;/p&gt;
    &lt;p&gt;WATCH: How the massive power draw of generative AI is overtaxing our grid&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379183</guid><pubDate>Wed, 24 Dec 2025 21:02:15 +0000</pubDate></item><item><title>How I Left YouTube</title><link>https://zhach.news/how-i-left-youtube/</link><description>&lt;doc fingerprint="2cf5125326c467cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Left YouTube&lt;/head&gt;
    &lt;p&gt;I remember sitting down in a meeting room hearing the results of my third try at promo cycle trying to get from an L4 to an L5. I helped launch/lead features on YouTube, I led teams, I designed and implemented systems that were still in use to that day by many people, people all across the org knew me and said I was indispensable to the company and were surprised that I wasn't already at an L5/6 level. The results of that meeting? The same from the previous promotion decisions; “it’s unfortunately a no. You don’t have enough impact.”&lt;/p&gt;
    &lt;p&gt;That Tuesday afternoon realization kicked off a grueling, educational, and emotionally taxing journey: leaving a "dream job" to find out what I was actually worth in the open market.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mathematics of Leveling&lt;/head&gt;
    &lt;p&gt;In the software engineering world, we exist on a ladder. We call this ”Leveling”.&lt;/p&gt;
    &lt;p&gt;For those outside the tech industry, imagine the military. You have Lieutenants, Captains, Majors, and Generals. In tech, these are usually denoted as L3 (Entry/Junior), L4 (Mid), L5 (Senior), and L6 (Staff). L1/2 are saved for contractors or interns. After these denominations, one usually switches to a director or someone on the Leadership team. Your level dictates your salary, your stock grants, and most importantly, the scope of problems you are allowed to solve.&lt;/p&gt;
    &lt;p&gt;I found myself in a situation common to many engineers at large organizations. I was operating at a “Senior” or “Staff" level (architecting systems and roadmaps rather than just writing the code and tracking bugs), but my official title and compensation were stuck at just above junior level.&lt;/p&gt;
    &lt;p&gt;I faced a choice: continue to do way more work to prove myself for the lottery that is the promo cycle or leave to find a company that would recognize my output immediately. I chose the latter. And I decided to attempt a "double level" jump during my interviews (L4 to L6). I didn't just want a lateral move; I wanted the title that matched the work I was already doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Double Life of the Employed Candidate&lt;/head&gt;
    &lt;p&gt;Hunting for a job is a full-time occupation. Doing so while maintaining high performance at a demanding job like YouTube is a recipe for cognitive fracture.&lt;/p&gt;
    &lt;p&gt;The strain comes from context switching. From 9:00 AM to 5:00 PM, I had to care deeply about our quarterly goals and production stability. Then, from 6:00 PM to midnight, I had to care about inverting binary trees and system architecture design.&lt;/p&gt;
    &lt;p&gt;I recall taking "calls" in my car, taking vacation days to practice and do interviews, tethering my laptop to my phone's hotspot to solve coding challenges while squatting in a coffee shop down the street from the office. This duality is exhausting. It forces you to lie by omission to people you respect. You can't tell your team, "I can't take that ticket because I need to study dynamic programming." You just have to work faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;Navigating the NDA Minefield&lt;/head&gt;
    &lt;p&gt;One of the most complex hurdles in this cycle was proving I was capable of that "double level" jump without breaking Non-Disclosure Agreements (NDAs).&lt;/p&gt;
    &lt;p&gt;When you work at a place like YouTube, the scale of the problems you solve is the primary selling point. However, the specifics of how you solved them are often trade secrets.&lt;/p&gt;
    &lt;p&gt;Here is the strategy I developed: Abstract the mechanism, not the metric.&lt;/p&gt;
    &lt;p&gt;I couldn't tell interviewers exactly how a specific proprietary algorithm worked. Instead, I focused on the agnostic engineering principles.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't say: "I tweaked the YouTube watch-time algorithm using X variable."&lt;/item&gt;
      &lt;item&gt;Do say: "I optimized a high-throughput distributed system to prioritize user retention metrics, reducing latency by 150ms through a custom caching layer."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It shows you understand the systems (which is transferable knowledge) rather than just the product (which stays at the old company). If you are ever in this position, focus on the scale of the data and the architectural patterns you used (like Microservices or Event-Driven Architecture) rather than the feature itself. In the end, it also helped me connect with external technologies and lingo better!&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elephant in the Room...&lt;/head&gt;
    &lt;p&gt;Most interviewers asked me the question that people assume is the hardest to answer... "describe why you are not already an L5/6". And honestly, this was the easiest part. People understood the problems with promos at Google/YouTube, but also this situation. The problem of "doing more work and not getting compensated" is pretty well-known.&lt;/p&gt;
    &lt;p&gt;What was unique was how long it took me to decide to leave. And I had to highlight the incredibly talented team I worked with and the amazing managers that taught me so much. There is so much value in knowing and feeling that the people around you care about you and want to build amazing things with you.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Thirteen-Interview Marathon&lt;/head&gt;
    &lt;p&gt;The most alarming trend I analyzed during this cycle is the inflation of the interview loop.&lt;/p&gt;
    &lt;p&gt;At one prominent tech company, I underwent 13 separate interviews for a single role. This included initial screens, coding rounds, system design rounds, behavioral checks, and meetings with cross-functional partners.&lt;/p&gt;
    &lt;p&gt;From a critical perspective, this signals organizational dysfunction. If a company requires 13 people to sign off on a hire, it suggests they operate on a consensus-based model that stifles autonomy. It implies a fear of making mistakes that outweighs the desire for talent.&lt;/p&gt;
    &lt;p&gt;When I analyze the data from my own process, the companies with 5 to 8 rounds had the clearest internal culture. They knew what they wanted. The company with 13 rounds was fishing for a reason to say "no” (which some ultimately told me).&lt;/p&gt;
    &lt;head rend="h3"&gt;The Final Conversation&lt;/head&gt;
    &lt;p&gt;We often hear that "people leave managers, not jobs." But sometimes, people leave jobs despite loving their managers.&lt;/p&gt;
    &lt;p&gt;My final conversation with my manager was heart-wrenching. I had prepared a script, anticipating a counter-offer or a guilt trip. Instead, I was met with soft and understanding empathy.&lt;/p&gt;
    &lt;p&gt;I explained that my growth curve had flattened. I wasn't leaving because the team failed me; I was leaving because I had outgrown the pot I was planted in. Staying would have required me to stagnate to fit the available space. I needed to leave to see what I was capable of. And he listened to every word.&lt;/p&gt;
    &lt;p&gt;I walked out of the meeting feeling incredibly bittersweet, with tears ready to fall. He knew my talent, he knew how hard I worked, and he still was incredibly supportive while I said I was leaving.&lt;/p&gt;
    &lt;p&gt;This is a hard lesson for both employees and leaders: Retention has a ceiling. Sometimes, the best thing a manager can do for that high-performer is to wish them luck as they walk out the door. It wasn't his fault I wasn't promoted to the level I wanted—he was fighting the same bureaucratic machine I was.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Takeaway&lt;/head&gt;
    &lt;p&gt;Leaving a recognizable brand like Google/YouTube is frightening. You lose the immediate validation that comes with the name on your resume. But careers are long, and comfort is the enemy of progress.&lt;/p&gt;
    &lt;p&gt;If you feel like you are solving problems two levels above your pay grade, and the only reward you get is more work, it is time to test the market. The interview fatigue is real, and the conversations are hard, but the clarity you gain on your own value is worth the struggle.&lt;/p&gt;
    &lt;p&gt;I’m curious about your experiences with career stagnation. Have you ever felt like you were "acting" at a higher level than your title? How did you handle the conversation with your leadership?&lt;/p&gt;
    &lt;p&gt;Please share your stories in the comments below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links and Resources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Software Engineering Levels: levels.fyi (Excellent resource for comparing titles and compensation across big tech).&lt;/item&gt;
      &lt;item&gt;Github: Career Ladder (detailed guide on how Github views levels; and I personally like their view)&lt;/item&gt;
      &lt;item&gt;System Design Interview Guide: System Design Primer on GitHub&lt;/item&gt;
      &lt;item&gt;Navigating NDAs: Harvard Business Review: Non-Disclosure Agreements&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379677</guid><pubDate>Wed, 24 Dec 2025 21:54:48 +0000</pubDate></item><item><title>Phoenix: A modern X server written from scratch in Zig</title><link>https://git.dec05eba.com/phoenix/about/</link><description>&lt;doc fingerprint="d47bdcdf6826ad85"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Phoenix&lt;/head&gt;
    &lt;p&gt;Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Current state&lt;/head&gt;
    &lt;p&gt;Phoenix is not ready to be used yet. At the moment it can render simple applications that do GLX, EGL or Vulkan graphics (fully hardware accelerated) nested in an existing X server. Running Phoenix nested will be the only supported mode until Phoenix has progressed more and can run real-world applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Simplicity&lt;/head&gt;
    &lt;p&gt;Be a simpler X server than the Xorg server by only supporting a subset of the X11 protocol, the features that are needed by relatively modern applications (applications written in the last ~20 years).&lt;lb/&gt; Only relatively modern hardware (made in the last ~15 years) which support linux drm and mesa gbm will be supported, and no server driver interface like the Xorg server. Just like how Wayland compositors work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Security&lt;/head&gt;
    &lt;p&gt;Be safer than the Xorg server by parsing protocol messages automatically. As it's written in Zig, it also automatically catches illegal behaviors (such as index out of array bounds) when building with the &lt;code&gt;ReleaseSafe&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Applications will be isolated from each other by default and can only interact with other applications either through a GUI prompt asking for permission, such as with screen recorders, where it will only be allowed to record the window specified or by explicitly giving the application permission before launched (such as a window manager or external compositor). This will not break existing clients as clients wont receive errors when they try to access more than they need, they will instead receive dummy data.&lt;lb/&gt; Applications that rely on global hotkeys should work, as long as a modifier key is pressed (keys such as ctrl, shift, alt and super). If an application needs global hotkeys without pressing a modifier key then it needs to be given permissions to do so (perhaps by adding a command to run a program with more X11 permissions).&lt;lb/&gt; There will be an option to disable this to make the X server behave like the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvements for modern technology&lt;/head&gt;
    &lt;p&gt;Support modern hardware better than the Xorg server, such as proper support for multiple monitors (different refresh rates, VRR - not a single framebuffer for the whole collection of displays) and technology like HDR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improved graphics handling&lt;/head&gt;
    &lt;p&gt;No tearing by default and a built-in compositor. The compositor will get disabled if the user runs an external compositor (client application), such as picom or if the client runs a fullscreen application and disabled vsync in the application. The goal is to also have lower vsync/compositor latency than the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;New standards&lt;/head&gt;
    &lt;p&gt;New standards will be developed and documented, such as per-monitor DPI as randr properties. Applications can use this property to scale their content to the specified DPI for the monitor they are on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extending the X11 protocol&lt;/head&gt;
    &lt;p&gt;If there is a need for new features (such as HDR) then the X11 protocol will be extended.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wayland compatibility&lt;/head&gt;
    &lt;p&gt;Some applications might only run on Wayland in the future. Such applications should be supported by either Phoenix supporting Wayland natively or by running an external application that works as a bridge between Wayland and X11 (such as 12to11).&lt;/p&gt;
    &lt;head rend="h3"&gt;Nested display server&lt;/head&gt;
    &lt;p&gt;Being able to run Phoenix nested under X11 or Wayland with hardware acceleration. This is not only useful for debugging Phoenix but also for developers who want to test their window manager or compositor without restarting the display server they are running.&lt;lb/&gt; Being able to run Phoenix under Wayland as an alternative Xwayland server would be a good option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Replacing the Xorg server&lt;/head&gt;
    &lt;p&gt;The Xorg server will always support more features of the X11 protocol and wider range of hardware (especially older ones).&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple screens&lt;/head&gt;
    &lt;p&gt;Multiple displays (monitors) are going to be supported but not X11 screens.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exclusive access&lt;/head&gt;
    &lt;p&gt;GrabServer has no effect in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Endian-swapped client/server&lt;/head&gt;
    &lt;p&gt;This can be reconsidered if there is a reason.&lt;/p&gt;
    &lt;head rend="h3"&gt;Indirect (remote) GLX.&lt;/head&gt;
    &lt;p&gt;This is very complex as there are a lot of functions that would need to be implemented. These days remote streaming options are more efficient. Alternatively a proxy for glx could be implemented that does remote rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Differences between the X11 protocol and Phoenix&lt;/head&gt;
    &lt;head rend="h3"&gt;Core protocol&lt;/head&gt;
    &lt;p&gt;Several parts of the X11 protocol (core) are mandatory to be implemented by an X server, such as font related operations. However these are not going to be implemented in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Strings&lt;/head&gt;
    &lt;p&gt;Strings are in ISO Latin-1 encoding in the X11 protocol unless specified otherwise, however in Phoenix all strings are UTF-8 unless the protocol states that it's not an ISO Latin-1 string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing&lt;/head&gt;
    &lt;p&gt;Run:&lt;/p&gt;
    &lt;code&gt;zig build -Doptimize=ReleaseSafe
sudo zig build install -p /usr/local -Doptimize=ReleaseSafe
&lt;/code&gt;
    &lt;head rend="h2"&gt;Uninstalling&lt;/head&gt;
    &lt;p&gt;Zig does currently not support the uninstall command so you have to remove files manually:&lt;/p&gt;
    &lt;code&gt;sudo rm /usr/local/bin/phoenix
&lt;/code&gt;
    &lt;head rend="h2"&gt;Building (for development)&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build&lt;/code&gt;, which builds Phoenix in debug mode. The compiled binary will be available at &lt;code&gt;./zig-out/bin/phoenix&lt;/code&gt;. You can alternatively build and run with one command: &lt;code&gt;zig build run&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generate x11 protocol documentation&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build -Dgenerate-docs=true&lt;/code&gt;. This will generate &lt;code&gt;.txt&lt;/code&gt; files in &lt;code&gt;./zig-out/protocol/&lt;/code&gt;. This generates x11 protocol documentation in the style of the official protocol documentation. The documentation is automatically generated from the protocol struct code.
Note that the generated documentation feature is a work-in-progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zig 0.14.1&lt;/item&gt;
      &lt;item&gt;x11 (&lt;code&gt;xcb&lt;/code&gt;) - for nested mode under X11, when building Phoenix with&lt;code&gt;-Dbackends=x11&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;wayland (&lt;code&gt;wayland-client&lt;/code&gt;,&lt;code&gt;wayland-egl&lt;/code&gt;) - for nested mode under Wayland, when building Phoenix with&lt;code&gt;-Dbackends=wayland&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;drm (&lt;code&gt;libdrm&lt;/code&gt;,&lt;code&gt;gbm&lt;/code&gt;) - for running Phoenix as a standalone X11 server, when building Phoenix with&lt;code&gt;-Dbackends=drm&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;OpenGL (&lt;code&gt;libglvnd&lt;/code&gt;which provides both&lt;code&gt;gl&lt;/code&gt;and&lt;code&gt;egl&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380075</guid><pubDate>Wed, 24 Dec 2025 22:43:53 +0000</pubDate></item><item><title>Tell HN: Merry Christmas</title><link>https://news.ycombinator.com/item?id=46380168</link><description>&lt;doc fingerprint="3d2d13d459cf20bd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Different cultures celebrate Christmas at different days and time zones are a thing. But it's Christmas here, so:&lt;/p&gt;
      &lt;p&gt;Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect.&lt;/p&gt;
      &lt;p&gt;Also much love to everyone who cannot spend their Christmas with dear people.&lt;/p&gt;
      &lt;p&gt;To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: https://en.wikipedia.org/wiki/Christmas_market&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380168</guid><pubDate>Wed, 24 Dec 2025 22:56:00 +0000</pubDate></item><item><title>Asterisk AI Voice Agent</title><link>https://github.com/hkjarral/Asterisk-AI-Voice-Agent</link><description>&lt;doc fingerprint="2c0ef1107fb2aeaa"&gt;
  &lt;main&gt;
    &lt;p&gt;The most powerful, flexible open-source AI voice agent for Asterisk/FreePBX. Featuring a modular pipeline architecture that lets you mix and match STT, LLM, and TTS providers, plus 5 production-ready golden baselines validated for enterprise deployment.&lt;/p&gt;
    &lt;p&gt;Quick Start • Features • Demo • Documentation • Community&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Quick Start&lt;/item&gt;
      &lt;item&gt;🎉 What's New&lt;/item&gt;
      &lt;item&gt;🌟 Why Asterisk AI Voice Agent?&lt;/item&gt;
      &lt;item&gt;✨ Features&lt;/item&gt;
      &lt;item&gt;🎥 Demo&lt;/item&gt;
      &lt;item&gt;🛠️ AI-Powered Actions&lt;/item&gt;
      &lt;item&gt;🩺 Agent CLI Tools&lt;/item&gt;
      &lt;item&gt;⚙️ Configuration&lt;/item&gt;
      &lt;item&gt;🏗️ Project Architecture&lt;/item&gt;
      &lt;item&gt;📊 Requirements&lt;/item&gt;
      &lt;item&gt;🗺️ Documentation&lt;/item&gt;
      &lt;item&gt;🤝 Contributing&lt;/item&gt;
      &lt;item&gt;💬 Community&lt;/item&gt;
      &lt;item&gt;📝 License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get the Admin UI running in 2 minutes.&lt;/p&gt;
    &lt;p&gt;For a complete first successful call walkthrough (dialplan + transport selection + verification), see:&lt;/p&gt;
    &lt;code&gt;# Clone repository
git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git
cd Asterisk-AI-Voice-Agent

# Run preflight with auto-fix (creates .env, generates JWT_SECRET)
sudo ./preflight.sh --apply-fixes&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Important: Preflight creates your&lt;/p&gt;&lt;code&gt;.env&lt;/code&gt;file and generates a secure&lt;code&gt;JWT_SECRET&lt;/code&gt;. Always run this first!&lt;/quote&gt;
    &lt;code&gt;# Start the Admin UI container
docker compose up -d --build admin-ui&lt;/code&gt;
    &lt;p&gt;Open in your browser:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local: &lt;code&gt;http://localhost:3003&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Remote server: &lt;code&gt;http://&amp;lt;server-ip&amp;gt;:3003&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Default Login: &lt;code&gt;admin&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Follow the Setup Wizard to configure your providers and make a test call.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Security: The Admin UI is accessible on the network. Change the default password immediately and restrict port 3003 via firewall, VPN, or reverse proxy for production use.&lt;/quote&gt;
    &lt;code&gt;# Start ai-engine (required for health checks)
docker compose up -d --build ai-engine

# Check ai-engine health
curl http://localhost:15000/health
# Expected: {"status":"healthy"}

# View logs for any errors
docker compose logs ai-engine | tail -20&lt;/code&gt;
    &lt;p&gt;The wizard will generate the necessary dialplan configuration for your Asterisk server.&lt;/p&gt;
    &lt;p&gt;Transport selection is configuration-dependent (not strictly “pipelines vs full agents”). Use the validated matrix in:&lt;/p&gt;
    &lt;p&gt;For users who prefer the command line or need headless setup.&lt;/p&gt;
    &lt;code&gt;./install.sh
agent quickstart&lt;/code&gt;
    &lt;code&gt;# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start services
docker compose up -d&lt;/code&gt;
    &lt;p&gt;Add this to your FreePBX (&lt;code&gt;extensions_custom.conf&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;[from-ai-agent]
exten =&amp;gt; s,1,NoOp(Asterisk AI Voice Agent v4.5.3)
 same =&amp;gt; n,Stasis(asterisk-ai-voice-agent)
 same =&amp;gt; n,Hangup()
&lt;/code&gt;
    &lt;p&gt;Health check:&lt;/p&gt;
    &lt;code&gt;agent doctor&lt;/code&gt;
    &lt;p&gt;View logs:&lt;/p&gt;
    &lt;code&gt;docker compose logs -f ai-engine&lt;/code&gt;
    &lt;head&gt;Latest Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full Call Logging: Every call saved with conversation history, timing, and outcome&lt;/item&gt;
      &lt;item&gt;Per-Call Debugging: Review transcripts, tool executions, and errors from Admin UI&lt;/item&gt;
      &lt;item&gt;Search &amp;amp; Filter: Find calls by caller, provider, context, or date range&lt;/item&gt;
      &lt;item&gt;Export: Download call data as CSV or JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immediate Interruption: Agent audio stops instantly when caller speaks&lt;/item&gt;
      &lt;item&gt;Provider-Owned Turn-Taking: Full agents (Google, Deepgram, OpenAI, ElevenLabs) handle VAD natively&lt;/item&gt;
      &lt;item&gt;Platform Flush: Local playback clears immediately on interruption signal&lt;/item&gt;
      &lt;item&gt;Transport Parity: Works with both ExternalMedia RTP and AudioSocket&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster Whisper: High-accuracy STT backend with GPU acceleration&lt;/item&gt;
      &lt;item&gt;MeloTTS: New neural TTS option for local pipelines&lt;/item&gt;
      &lt;item&gt;Model Hot-Swap: Switch models via Dashboard without container restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Tools Framework: Connect AI agents to external services via Model Context Protocol&lt;/item&gt;
      &lt;item&gt;Admin UI Config: Configure MCP servers from the web interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Remote Endpoint Pinning: Lock RTP streams to prevent audio hijacking&lt;/item&gt;
      &lt;item&gt;Allowlist Support: Restrict allowed remote hosts for ExternalMedia&lt;/item&gt;
      &lt;item&gt;Cross-Talk Prevention: SSRC-based routing ensures call isolation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;local_hybrid&lt;/code&gt;Default: Privacy-focused pipeline is now the out-of-box default&lt;/item&gt;
      &lt;item&gt;Pipeline-Aware Readiness: Health probes correctly reflect pipeline component status&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Previous Versions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🌍 Pre-flight Script: System compatibility checker with auto-fix mode.&lt;/item&gt;
      &lt;item&gt;🔧 Admin UI Fixes: Models page, providers page, dashboard improvements.&lt;/item&gt;
      &lt;item&gt;🛠️ Developer Experience: Code splitting, ESLint + Prettier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🎤 New STT Backends: Kroko ASR, Sherpa-ONNX.&lt;/item&gt;
      &lt;item&gt;🔊 Kokoro TTS: High-quality neural TTS.&lt;/item&gt;
      &lt;item&gt;🔄 Model Management: Dynamic backend switching from Dashboard.&lt;/item&gt;
      &lt;item&gt;📚 Documentation: LOCAL_ONLY_SETUP.md guide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🖥️ Admin UI v1.0: Modern web interface (http://localhost:3003).&lt;/item&gt;
      &lt;item&gt;🎙️ ElevenLabs Conversational AI: Premium voice quality provider.&lt;/item&gt;
      &lt;item&gt;🎵 Background Music: Ambient music during AI calls.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔧 Complete Tool Support: Works across ALL pipeline types.&lt;/item&gt;
      &lt;item&gt;📚 Documentation Overhaul: Reorganized structure.&lt;/item&gt;
      &lt;item&gt;💬 Discord Community: Official server integration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🤖 Google Live API: Gemini 2.0 Flash integration.&lt;/item&gt;
      &lt;item&gt;🚀 Interactive Setup: &lt;code&gt;agent quickstart&lt;/code&gt;wizard.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔧 Tool Calling System: Transfer calls, send emails.&lt;/item&gt;
      &lt;item&gt;🩺 Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Benefit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Asterisk-Native&lt;/cell&gt;
        &lt;cell&gt;Works directly with your existing Asterisk/FreePBX - no external telephony providers required.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Truly Open Source&lt;/cell&gt;
        &lt;cell&gt;MIT licensed with complete transparency and control.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Modular Architecture&lt;/cell&gt;
        &lt;cell&gt;Choose cloud, local, or hybrid - mix providers as needed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Production-Ready&lt;/cell&gt;
        &lt;cell&gt;Battle-tested baselines with Call History-first debugging.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cost-Effective&lt;/cell&gt;
        &lt;cell&gt;Local Hybrid costs ~$0.001-0.003/minute (LLM only).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Privacy-First&lt;/cell&gt;
        &lt;cell&gt;Keep audio local while using cloud intelligence.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;OpenAI Realtime (Recommended for Quick Start)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Modern cloud AI with natural conversations (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-openai.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Enterprise deployments, quick setup.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deepgram Voice Agent (Enterprise Cloud)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Advanced Think stage for complex reasoning (&amp;lt;3s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-deepgram.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Deepgram ecosystem, advanced features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Google Live API (Multimodal AI)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Gemini Live (Flash) with multimodal capabilities (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-google-live.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Google ecosystem, advanced AI features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ElevenLabs Agent (Premium Voice Quality)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;ElevenLabs Conversational AI with premium voices (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-elevenlabs.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Voice quality priority, natural conversations.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local Hybrid (Privacy-Focused)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Local STT/TTS + Cloud LLM (OpenAI). Audio stays on-premises.&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-local-hybrid.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Audio privacy, cost control, compliance.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run your own local LLM using Ollama - perfect for privacy-focused deployments:&lt;/p&gt;
    &lt;code&gt;# In ai-agent.yaml
active_pipeline: local_ollama&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No API key required - fully self-hosted on your network&lt;/item&gt;
      &lt;item&gt;Tool calling support with compatible models (Llama 3.2, Mistral, Qwen)&lt;/item&gt;
      &lt;item&gt;Local Vosk STT + Your Ollama LLM + Local Piper TTS&lt;/item&gt;
      &lt;item&gt;Complete privacy - all processing stays on-premises&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mac Mini, gaming PC, or server with Ollama installed&lt;/item&gt;
      &lt;item&gt;8GB+ RAM (16GB+ recommended for larger models)&lt;/item&gt;
      &lt;item&gt;See docs/OLLAMA_SETUP.md for setup guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended Models:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Tool Calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;llama3.2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;mistral&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;qwen2.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4.7GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool Calling System: AI-powered actions (transfers, emails) work with any provider.&lt;/item&gt;
      &lt;item&gt;Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;,&lt;code&gt;init&lt;/code&gt;commands.&lt;/item&gt;
      &lt;item&gt;Modular Pipeline System: Independent STT, LLM, and TTS provider selection.&lt;/item&gt;
      &lt;item&gt;Dual Transport Support: AudioSocket and ExternalMedia RTP (see Transport Compatibility matrix).&lt;/item&gt;
      &lt;item&gt;High-Performance Architecture: Separate &lt;code&gt;ai-engine&lt;/code&gt;and&lt;code&gt;local-ai-server&lt;/code&gt;containers.&lt;/item&gt;
      &lt;item&gt;Observability: Built-in Call History for per-call debugging + optional &lt;code&gt;/metrics&lt;/code&gt;scraping.&lt;/item&gt;
      &lt;item&gt;State Management: SessionStore for centralized, typed call state.&lt;/item&gt;
      &lt;item&gt;Barge-In Support: Interrupt handling with configurable gating.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modern web interface for configuration and system management.&lt;/p&gt;
    &lt;p&gt;Quick Start:&lt;/p&gt;
    &lt;code&gt;docker compose up -d admin-ui
# Access at: http://localhost:3003
# Login: admin / admin (change immediately!)&lt;/code&gt;
    &lt;p&gt;Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Setup Wizard: Visual provider configuration.&lt;/item&gt;
      &lt;item&gt;Dashboard: Real-time system metrics and container status.&lt;/item&gt;
      &lt;item&gt;Live Logs: WebSocket-based log streaming.&lt;/item&gt;
      &lt;item&gt;YAML Editor: Monaco-based editor with validation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Experience our production-ready configurations with a single phone call:&lt;/p&gt;
    &lt;p&gt;Dial: (925) 736-6718&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Press 5 → Google Live API (Multimodal AI with Gemini 2.0)&lt;/item&gt;
      &lt;item&gt;Press 6 → Deepgram Voice Agent (Enterprise cloud with Think stage)&lt;/item&gt;
      &lt;item&gt;Press 7 → OpenAI Realtime API (Modern cloud AI, most natural)&lt;/item&gt;
      &lt;item&gt;Press 8 → Local Hybrid Pipeline (Privacy-focused, audio stays local)&lt;/item&gt;
      &lt;item&gt;Press 9 → ElevenLabs Agent (Santa voice with background music)&lt;/item&gt;
      &lt;item&gt;Press 10 → Fully Local Pipeline (100% on-premises, CPU-based)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your AI agent can perform real-world telephony actions through tool calling.&lt;/p&gt;
    &lt;code&gt;Caller: "Transfer me to the sales team"
Agent: "I'll connect you to our sales team right away."
[Transfer to sales queue with queue music]
&lt;/code&gt;
    &lt;p&gt;Supported Destinations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extensions: Direct SIP/PJSIP endpoint transfers.&lt;/item&gt;
      &lt;item&gt;Queues: ACD queue transfers with position announcements.&lt;/item&gt;
      &lt;item&gt;Ring Groups: Multiple agents ring simultaneously.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancel Transfer: "Actually, cancel that" (during ring).&lt;/item&gt;
      &lt;item&gt;Hangup Call: Ends call gracefully with farewell.&lt;/item&gt;
      &lt;item&gt;Voicemail: Routes to voicemail box.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic Call Summaries: Admins receive full transcripts and metadata.&lt;/item&gt;
      &lt;item&gt;Caller-Requested Transcripts: "Email me a transcript of this call."&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Transfer to extensions, queues, or ring groups&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cancel_transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cancel in-progress transfer (during ring)&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hangup_call&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;End call gracefully with farewell message&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;leave_voicemail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Route caller to voicemail extension&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;send_email_summary&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-send call summaries to admins&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;request_transcript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Caller-initiated email transcripts&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Production-ready CLI for operations and setup.&lt;/p&gt;
    &lt;p&gt;Installation:&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/hkjarral/Asterisk-AI-Voice-Agent/main/scripts/install-cli.sh | bash&lt;/code&gt;
    &lt;p&gt;Commands:&lt;/p&gt;
    &lt;code&gt;agent quickstart          # Interactive setup wizard
agent dialplan            # Generate dialplan snippets
agent config validate     # Validate configuration
agent doctor --fix        # System health check
agent troubleshoot        # Analyze specific call
agent demo                # Demo features&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;config/ai-agent.yaml&lt;/code&gt;- Golden baseline configs.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.env&lt;/code&gt;- Secrets and API keys (git-ignored).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;OPENAI_API_KEY=sk-your-key-here
DEEPGRAM_API_KEY=your-key-here
ASTERISK_ARI_USERNAME=asterisk
ASTERISK_ARI_PASSWORD=your-password&lt;/code&gt;
    &lt;p&gt;The engine exposes Prometheus-format metrics at &lt;code&gt;http://&amp;lt;engine-host&amp;gt;:15000/metrics&lt;/code&gt;.
Per-call debugging is handled via Admin UI → Call History.&lt;/p&gt;
    &lt;p&gt;Two-container architecture for performance and scalability:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;ai-engine&lt;/code&gt;(Lightweight orchestrator): Connects to Asterisk via ARI, manages call lifecycle.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;local-ai-server&lt;/code&gt;(Optional): Runs local STT/LLM/TTS models (Vosk, Sherpa, Kroko, Piper, Kokoro, llama.cpp).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;graph LR
    A[Asterisk Server] &amp;lt;--&amp;gt;|ARI, RTP| B[ai-engine]
    B &amp;lt;--&amp;gt;|API| C[AI Provider]
    B &amp;lt;--&amp;gt;|WS| D[local-ai-server]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Requirement&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;x86_64 (AMD64) only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OS&lt;/cell&gt;
        &lt;cell&gt;Linux with systemd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Supported Distros&lt;/cell&gt;
        &lt;cell&gt;Ubuntu 20.04+, Debian 11+, RHEL/Rocky/Alma 8+, Fedora 38+, Sangoma Linux&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: ARM64 (Apple Silicon, Raspberry Pi) is not currently supported. See Supported Platforms for the full compatibility matrix.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;RAM&lt;/cell&gt;
        &lt;cell role="head"&gt;Disk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cloud (OpenAI/Deepgram)&lt;/cell&gt;
        &lt;cell&gt;2+ cores&lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;1GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Local Hybrid&lt;/cell&gt;
        &lt;cell&gt;4+ cores&lt;/cell&gt;
        &lt;cell&gt;8GB+&lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Docker + Docker Compose v2&lt;/item&gt;
      &lt;item&gt;Asterisk 18+ with ARI enabled&lt;/item&gt;
      &lt;item&gt;FreePBX (recommended) or vanilla Asterisk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;preflight.sh&lt;/code&gt; script handles initial setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seeds &lt;code&gt;.env&lt;/code&gt;from&lt;code&gt;.env.example&lt;/code&gt;with your settings&lt;/item&gt;
      &lt;item&gt;Prompts for Asterisk config directory location&lt;/item&gt;
      &lt;item&gt;Sets &lt;code&gt;ASTERISK_UID&lt;/code&gt;/&lt;code&gt;ASTERISK_GID&lt;/code&gt;to match host permissions (fixes media access issues)&lt;/item&gt;
      &lt;item&gt;Re-running preflight often resolves permission problems&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration Reference&lt;/item&gt;
      &lt;item&gt;Transport Compatibility&lt;/item&gt;
      &lt;item&gt;Tuning Recipes&lt;/item&gt;
      &lt;item&gt;Supported Platforms&lt;/item&gt;
      &lt;item&gt;Local Profiles&lt;/item&gt;
      &lt;item&gt;Monitoring Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Please see our Contributing Guide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord Server - Support and discussions&lt;/item&gt;
      &lt;item&gt;GitHub Issues - Bug reports&lt;/item&gt;
      &lt;item&gt;GitHub Discussions - General chat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you find this project useful, please give it a ⭐️ on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380399</guid><pubDate>Wed, 24 Dec 2025 23:25:37 +0000</pubDate></item><item><title>Microsoft please get your tab to autocomplete shit together</title><link>https://ivanca.github.io/programming/2025/11/26/microsoft-pls-get-your-tab-to-autocomplete-shit-together/</link><description>&lt;doc fingerprint="5b198935501a40f1"&gt;
  &lt;main&gt;
    &lt;p&gt;November 26, 2025 • Programming&lt;/p&gt;
    &lt;p&gt;What do you think is gonna happen after I press tab when looking at this screenshot?&lt;/p&gt;
    &lt;p&gt;That’s right, its gonna do nothing and suggest something else that it wasn’t any of the 2 initial suggestions!&lt;/p&gt;
    &lt;p&gt;Whoever team or person is on charge of the vscode autocomplete behavior at Microsoft (or at least the C# Dev Kit plugin) please do your job and fix this, thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380475</guid><pubDate>Wed, 24 Dec 2025 23:33:15 +0000</pubDate></item><item><title>Who Watches the Waymos? I do [video]</title><link>https://www.youtube.com/watch?v=oYU2hAbx_Fc</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380758</guid><pubDate>Thu, 25 Dec 2025 00:10:12 +0000</pubDate></item><item><title>The Next-Gen Mainboard Designed with AmigaOS4 and MorphOS in Mind</title><link>https://mirari.vitasys.nl/our-story/</link><description>&lt;doc fingerprint="d4b2af7c4348b786"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;First things first…&lt;/head&gt;
    &lt;p&gt;Let’s take a moment to appreciate Trevor Dickinson and his incredible contributions to the Amiga world. His dedication and support have been instrumental in bringing us the next generation of Amiga computers, the ExecSG Kernel and the ongoing development of the Radeon Graphics drivers. Without having machines like the X1000, X5000 and A1222 this project would have never been born. Thank you Trevor, for keeping the Amiga spirit alive!&lt;/p&gt;
    &lt;head rend="h3"&gt;Rebooting The Next-Gen Amiga Dream&lt;/head&gt;
    &lt;p&gt;The Amiga, a once-dominant force in the personal computer world, continues to hold a special place in the hearts of many. But with limited next-gen hardware available and dwindling AmigaOS4 support, the future of this beloved platform seemed uncertain. That is, until a few Dutch passionate individuals decided to take matters into their own hands.&lt;/p&gt;
    &lt;p&gt;Driven by a shared love for the Amiga and a desire to see it thrive, they embarked on an ambitious project: to create a new, low-cost next-gen Amiga mainboard.&lt;/p&gt;
    &lt;p&gt;The Vision:&lt;/p&gt;
    &lt;p&gt;The goal was clear: to create a mainboard that would breathe new life into the next-gen Amiga platform. A board that would be affordable for hobbyists and enthusiasts, while offering the power and performance to run all AmigaOS software and games.&lt;/p&gt;
    &lt;p&gt;The Road Ahead:&lt;/p&gt;
    &lt;p&gt;The journey is filled with challenges, from overcoming technical hurdles to navigating the complexities of cheap production and logistics as for getting the needed software components up and running. But Dave and Harald fueled by their passion and the unwavering support of the Amiga community, remain committed to their vision.&lt;/p&gt;
    &lt;p&gt;A Testament to Community Spirit:&lt;/p&gt;
    &lt;p&gt;The story of Dave and Harald, is a testament to the power of community. It demonstrates how a shared love for technology and a collective effort can bring about remarkable achievements.&lt;/p&gt;
    &lt;p&gt;Stay Tuned:&lt;/p&gt;
    &lt;p&gt;As the project progresses, we will continue to provide updates on the development of the new Mirari Amiga mainboard. The progress can be found on The First Rebirth page.&lt;/p&gt;
    &lt;p&gt;The Future of the Amiga is in Our Hands.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380953</guid><pubDate>Thu, 25 Dec 2025 00:38:09 +0000</pubDate></item><item><title>Ruby 4.0.0 Released</title><link>https://www.ruby-lang.org/en/news/2025/12/25/ruby-4-0-0-released/</link><description>&lt;doc fingerprint="7e48a958082198f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ruby 4.0.0 Released&lt;/head&gt;
    &lt;p&gt;Posted by naruse on 25 Dec 2025&lt;/p&gt;
    &lt;p&gt;We are pleased to announce the release of Ruby 4.0.0. Ruby 4.0 introduces “Ruby Box” and “ZJIT”, and adds many improvements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ruby Box&lt;/head&gt;
    &lt;p&gt;Ruby Box is a new (experimental) feature to provide separation about definitions. Ruby Box is enabled when an environment variable &lt;code&gt;RUBY_BOX=1&lt;/code&gt; is specified. The class is &lt;code&gt;Ruby::Box&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Definitions loaded in a box are isolated in the box. Ruby Box can isolate/separate monkey patches, changes of global/class variables, class/module definitions, and loaded native/ruby libraries from other boxes.&lt;/p&gt;
    &lt;p&gt;Expected use cases are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run test cases in box to protect other tests when the test case uses monkey patches to override something&lt;/item&gt;
      &lt;item&gt;Run web app boxes in parallel to execute blue-green deployment on an app server in a Ruby process&lt;/item&gt;
      &lt;item&gt;Run web app boxes in parallel to evaluate dependency updates for a certain period of time by checking response diff using Ruby code&lt;/item&gt;
      &lt;item&gt;Used as the foundation (low-level) API to implement kind of “package” (high-level) API (it is not designed yet)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For the detail of “Ruby Box”, see Ruby::Box. [Feature #21311] [Misc #21385]&lt;/p&gt;
    &lt;head rend="h2"&gt;ZJIT&lt;/head&gt;
    &lt;p&gt;ZJIT is a new just-in-time (JIT) compiler, which is developed as the next generation of YJIT. You need Rust 1.85.0 or newer to build Ruby with ZJIT support, and ZJIT is enabled when &lt;code&gt;--zjit&lt;/code&gt; is specified.&lt;/p&gt;
    &lt;p&gt;We’re building a new compiler for Ruby because we want to both raise the performance ceiling (bigger compilation unit size and SSA IR) and encourage more outside contribution (by becoming a more traditional method compiler). See our blog post for more details.&lt;/p&gt;
    &lt;p&gt;ZJIT is faster than the interpreter, but not yet as fast as YJIT. We encourage you to experiment with ZJIT, but maybe hold off on deploying it in production for now. Stay tuned for Ruby 4.1 ZJIT.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ractor Improvements&lt;/head&gt;
    &lt;p&gt;Ractor, Ruby’s parallel execution mechanism, has received several improvements. A new class, &lt;code&gt;Ractor::Port&lt;/code&gt;, was introduced to address issues related to message sending and receiving (see our blog post). Additionally, &lt;code&gt;Ractor.shareable_proc&lt;/code&gt; makes it easier to share &lt;code&gt;Proc&lt;/code&gt; objects between Ractors.&lt;/p&gt;
    &lt;p&gt;On the performance side, many internal data structures have been improved to significantly reduce contention on a global lock, unlocking better parallelism. Ractors also now share less internal data, resulting in less CPU cache contention when running in parallel.&lt;/p&gt;
    &lt;p&gt;Ractor was first introduced in Ruby 3.0 as an experimental feature. We aim to remove its “experimental” status next year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Language changes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;*nil&lt;/code&gt;no longer calls&lt;code&gt;nil.to_a&lt;/code&gt;, similar to how&lt;code&gt;**nil&lt;/code&gt;does not call&lt;code&gt;nil.to_hash&lt;/code&gt;. [Feature #21047]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Logical binary operators (&lt;/p&gt;&lt;code&gt;||&lt;/code&gt;,&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;,&lt;code&gt;and&lt;/code&gt;and&lt;code&gt;or&lt;/code&gt;) at the beginning of a line continue the previous line, like fluent dot. The following code examples are equal:&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;p&gt;Previously:&lt;/p&gt;&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Core classes updates&lt;/head&gt;
    &lt;p&gt;Note: We’re only listing outstanding class updates.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Array&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Array#rfind&lt;/code&gt;has been added as a more efficient alternative to&lt;code&gt;array.reverse_each.find&lt;/code&gt;[Feature #21678]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Array#find&lt;/code&gt;has been added as a more efficient override of&lt;code&gt;Enumerable#find&lt;/code&gt;[Feature #21678]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Binding&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Binding#local_variables&lt;/code&gt;does no longer include numbered parameters. Also,&lt;code&gt;Binding#local_variable_get&lt;/code&gt;,&lt;code&gt;Binding#local_variable_set&lt;/code&gt;, and&lt;code&gt;Binding#local_variable_defined?&lt;/code&gt;reject to handle numbered parameters. [Bug #21049]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Binding#implicit_parameters&lt;/code&gt;,&lt;code&gt;Binding#implicit_parameter_get&lt;/code&gt;, and&lt;code&gt;Binding#implicit_parameter_defined?&lt;/code&gt;have been added to access numbered parameters and “it” parameter. [Bug #21049]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enumerator&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Enumerator.produce&lt;/code&gt;now accepts an optional&lt;code&gt;size&lt;/code&gt;keyword argument to specify the size of the enumerator. It can be an integer,&lt;code&gt;Float::INFINITY&lt;/code&gt;, a callable object (such as a lambda), or&lt;code&gt;nil&lt;/code&gt;to indicate unknown size. When not specified, the size defaults to&lt;code&gt;Float::INFINITY&lt;/code&gt;.&lt;code&gt;# Infinite enumerator enum = Enumerator.produce(1, size: Float::INFINITY, &amp;amp;:succ) enum.size # =&amp;gt; Float::INFINITY # Finite enumerator with known/computable size abs_dir = File.expand_path("./baz") # =&amp;gt; "/foo/bar/baz" traverser = Enumerator.produce(abs_dir, size: -&amp;gt; { abs_dir.count("/") + 1 }) { raise StopIteration if it == "/" File.dirname(it) } traverser.size # =&amp;gt; 4&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ErrorHighlight&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;When an ArgumentError is raised, it now displays code snippets for both the method call (caller) and the method definition (callee). [Feature #21543]&lt;/p&gt;
            &lt;code&gt;test.rb:1:in 'Object#add': wrong number of arguments (given 1, expected 2) (ArgumentError) caller: test.rb:3 | add(1) ^^^ callee: test.rb:1 | def add(x, y) = x + y ^^^ from test.rb:3:in '&amp;lt;main&amp;gt;'&lt;/code&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fiber&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Introduce support for &lt;code&gt;Fiber#raise(cause:)&lt;/code&gt;argument similar to&lt;code&gt;Kernel#raise&lt;/code&gt;. [Feature #21360]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Introduce support for &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fiber::Scheduler&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;Introduce&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#fiber_interrupt&lt;/code&gt;to interrupt a fiber with a given exception. The initial use case is to interrupt a fiber that is waiting on a blocking IO operation when the IO operation is closed. [Feature #21166]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Introduce&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#yield&lt;/code&gt;to allow the fiber scheduler to continue processing when signal exceptions are disabled. [Bug #21633]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Reintroduce the&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#io_close&lt;/code&gt;hook for asynchronous&lt;code&gt;IO#close&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Invoke&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#io_write&lt;/code&gt;when flushing the IO write buffer. [Bug #21789]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;File&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;File::Stat#birthtime&lt;/code&gt;is now available on Linux via the statx system call when supported by the kernel and filesystem. [Feature #21205]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IO&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;IO.select&lt;/code&gt;accepts&lt;code&gt;Float::INFINITY&lt;/code&gt;as a timeout argument. [Feature #20610]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;A deprecated behavior, process creation by&lt;/p&gt;&lt;code&gt;IO&lt;/code&gt;class methods with a leading&lt;code&gt;|&lt;/code&gt;, was removed. [Feature #19630]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kernel&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Kernel#inspect&lt;/code&gt;now checks for the existence of a&lt;code&gt;#instance_variables_to_inspect&lt;/code&gt;method, allowing control over which instance variables are displayed in the&lt;code&gt;#inspect&lt;/code&gt;string:&lt;code&gt;class DatabaseConfig def initialize(host, user, password) @host = host @user = user @password = password end private def instance_variables_to_inspect = [:@host, :@user] end conf = DatabaseConfig.new("localhost", "root", "hunter2") conf.inspect #=&amp;gt; #&amp;lt;DatabaseConfig:0x0000000104def350 @host="localhost", @user="root"&amp;gt;&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;A deprecated behavior, process creation by&lt;/p&gt;&lt;code&gt;Kernel#open&lt;/code&gt;with a leading&lt;code&gt;|&lt;/code&gt;, was removed. [Feature #19630]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Math&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Math.log1p&lt;/code&gt;and&lt;code&gt;Math.expm1&lt;/code&gt;are added. [Feature #21527]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pathname&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Pathname has been promoted from a default gem to a core class of Ruby. [Feature #17473]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Proc&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Proc#parameters&lt;/code&gt;now shows anonymous optional parameters as&lt;code&gt;[:opt]&lt;/code&gt;instead of&lt;code&gt;[:opt, nil]&lt;/code&gt;, making the output consistent with when the anonymous parameter is required. [Bug #20974]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ractor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;class was added for a new synchronization mechanism to communicate between Ractors. [Feature #21262]&lt;code&gt;port1 = Ractor::Port.new port2 = Ractor::Port.new Ractor.new port1, port2 do |port1, port2| port1 &amp;lt;&amp;lt; 1 port2 &amp;lt;&amp;lt; 11 port1 &amp;lt;&amp;lt; 2 port2 &amp;lt;&amp;lt; 12 end 2.times{ p port1.receive } #=&amp;gt; 1, 2 2.times{ p port2.receive } #=&amp;gt; 11, 12&lt;/code&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;provides the following methods:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#receive&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#send&lt;/code&gt;(or&lt;code&gt;Ractor::Port#&amp;lt;&amp;lt;&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#close&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#closed?&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;As a result,&lt;/p&gt;&lt;code&gt;Ractor.yield&lt;/code&gt;and&lt;code&gt;Ractor#take&lt;/code&gt;were removed.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#join&lt;/code&gt;and&lt;code&gt;Ractor#value&lt;/code&gt;were added to wait for the termination of a Ractor. These are similar to&lt;code&gt;Thread#join&lt;/code&gt;and&lt;code&gt;Thread#value&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#monitor&lt;/code&gt;and&lt;code&gt;Ractor#unmonitor&lt;/code&gt;were added as low-level interfaces used internally to implement&lt;code&gt;Ractor#join&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor.select&lt;/code&gt;now only accepts Ractors and Ports. If Ractors are given, it returns when a Ractor terminates.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#default_port&lt;/code&gt;was added. Each&lt;code&gt;Ractor&lt;/code&gt;has a default port, which is used by&lt;code&gt;Ractor.send&lt;/code&gt;,&lt;code&gt;Ractor.receive&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#close_incoming&lt;/code&gt;and&lt;code&gt;Ractor#close_outgoing&lt;/code&gt;were removed.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor.shareable_proc&lt;/code&gt;and&lt;code&gt;Ractor.shareable_lambda&lt;/code&gt;are introduced to make shareable Proc or lambda. [Feature #21550], [Feature #21557]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Range&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Range#to_set&lt;/code&gt;now performs size checks to prevent issues with endless ranges. [Bug #21654]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Range#overlap?&lt;/code&gt;now correctly handles infinite (unbounded) ranges. [Bug #21185]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Range#max&lt;/code&gt;behavior on beginless integer ranges has been fixed. [Bug #21174] [Bug #21175]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ruby&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A new toplevel module &lt;code&gt;Ruby&lt;/code&gt;has been defined, which contains Ruby-related constants. This module was reserved in Ruby 3.4 and is now officially defined. [Feature #20884]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;A new toplevel module &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ruby::Box&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A new (experimental) feature to provide separation about definitions. For the detail of “Ruby Box”, see doc/language/box.md. [Feature #21311] [Misc #21385]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Set&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Set&lt;/code&gt;is now a core class, instead of an autoloaded stdlib class. [Feature #21216]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Set#inspect&lt;/code&gt;now uses a simpler display, similar to literal arrays. (e.g.,&lt;code&gt;Set[1, 2, 3]&lt;/code&gt;instead of&lt;code&gt;#&amp;lt;Set: {1, 2, 3}&amp;gt;&lt;/code&gt;). [Feature #21389]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Passing arguments to&lt;/p&gt;&lt;code&gt;Set#to_set&lt;/code&gt;and&lt;code&gt;Enumerable#to_set&lt;/code&gt;is now deprecated. [Feature #21390]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Socket&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Socket.tcp&lt;/code&gt;&amp;amp;&lt;code&gt;TCPSocket.new&lt;/code&gt;accepts an&lt;code&gt;open_timeout&lt;/code&gt;keyword argument to specify the timeout for the initial connection. [Feature #21347]&lt;/item&gt;
          &lt;item&gt;When a user-specified timeout occurred in &lt;code&gt;TCPSocket.new&lt;/code&gt;, either&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;or&lt;code&gt;IO::TimeoutError&lt;/code&gt;could previously be raised depending on the situation. This behavior has been unified so that&lt;code&gt;IO::TimeoutError&lt;/code&gt;is now consistently raised. (Please note that, in&lt;code&gt;Socket.tcp&lt;/code&gt;, there are still cases where&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;may be raised in similar situations, and that in both cases&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;may be raised when the timeout occurs at the OS level.)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;String&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Update Unicode to Version 17.0.0 and Emoji Version 17.0. [Feature #19908][Feature #20724][Feature #21275] (also applies to Regexp)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;String#strip&lt;/code&gt;,&lt;code&gt;strip!&lt;/code&gt;,&lt;code&gt;lstrip&lt;/code&gt;,&lt;code&gt;lstrip!&lt;/code&gt;,&lt;code&gt;rstrip&lt;/code&gt;, and&lt;code&gt;rstrip!&lt;/code&gt;are extended to accept&lt;code&gt;*selectors&lt;/code&gt;arguments. [Feature #21552]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thread&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Introduce support for &lt;code&gt;Thread#raise(cause:)&lt;/code&gt;argument similar to&lt;code&gt;Kernel#raise&lt;/code&gt;. [Feature #21360]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Introduce support for &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Stdlib updates&lt;/head&gt;
    &lt;p&gt;We only list stdlib changes that are notable feature changes.&lt;/p&gt;
    &lt;p&gt;Other changes are listed in the following sections. We also listed release history from the previous bundled version that is Ruby 3.4.0 if it has GitHub releases.&lt;/p&gt;
    &lt;p&gt;The following bundled gems are promoted from default gems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ostruct 0.6.3&lt;/item&gt;
      &lt;item&gt;pstore 0.2.0 &lt;list rend="ul"&gt;&lt;item&gt;0.1.4 to v0.2.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;benchmark 0.5.0&lt;/item&gt;
      &lt;item&gt;logger 1.7.0&lt;/item&gt;
      &lt;item&gt;rdoc 7.0.2&lt;/item&gt;
      &lt;item&gt;win32ole 1.9.2 &lt;list rend="ul"&gt;&lt;item&gt;1.9.1 to v1.9.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;irb 1.16.0&lt;/item&gt;
      &lt;item&gt;reline 0.6.3&lt;/item&gt;
      &lt;item&gt;readline 0.0.4&lt;/item&gt;
      &lt;item&gt;fiddle 1.1.8&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following default gem is added.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;win32-registry 0.1.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following default gems are updated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RubyGems 4.0.3&lt;/item&gt;
      &lt;item&gt;bundler 4.0.3&lt;/item&gt;
      &lt;item&gt;date 3.5.1&lt;/item&gt;
      &lt;item&gt;delegate 0.6.1&lt;/item&gt;
      &lt;item&gt;digest 3.2.1 &lt;list rend="ul"&gt;&lt;item&gt;3.2.0 to v3.2.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;english 0.8.1 &lt;list rend="ul"&gt;&lt;item&gt;0.8.0 to v0.8.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;erb 6.0.1&lt;/item&gt;
      &lt;item&gt;error_highlight 0.7.1&lt;/item&gt;
      &lt;item&gt;etc 1.4.6&lt;/item&gt;
      &lt;item&gt;fcntl 1.3.0 &lt;list rend="ul"&gt;&lt;item&gt;1.2.0 to v1.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;fileutils 1.8.0 &lt;list rend="ul"&gt;&lt;item&gt;1.7.3 to v1.8.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;forwardable 1.4.0 &lt;list rend="ul"&gt;&lt;item&gt;1.3.3 to v1.4.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;io-console 0.8.2 &lt;list rend="ul"&gt;&lt;item&gt;0.8.1 to v0.8.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;io-nonblock 0.3.2&lt;/item&gt;
      &lt;item&gt;io-wait 0.4.0 &lt;list rend="ul"&gt;&lt;item&gt;0.3.2 to v0.3.3, v0.3.5.test1, v0.3.5, v0.3.6, v0.4.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;ipaddr 1.2.8&lt;/item&gt;
      &lt;item&gt;json 2.18.0&lt;/item&gt;
      &lt;item&gt;net-http 0.9.1&lt;/item&gt;
      &lt;item&gt;openssl 4.0.0&lt;/item&gt;
      &lt;item&gt;optparse 0.8.1&lt;/item&gt;
      &lt;item&gt;pp 0.6.3 &lt;list rend="ul"&gt;&lt;item&gt;0.6.2 to v0.6.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;prism 1.7.0&lt;/item&gt;
      &lt;item&gt;psych 5.3.1&lt;/item&gt;
      &lt;item&gt;resolv 0.7.0&lt;/item&gt;
      &lt;item&gt;stringio 3.2.0&lt;/item&gt;
      &lt;item&gt;strscan 3.1.6&lt;/item&gt;
      &lt;item&gt;time 0.4.2 &lt;list rend="ul"&gt;&lt;item&gt;0.4.1 to v0.4.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;timeout 0.6.0&lt;/item&gt;
      &lt;item&gt;uri 1.1.1&lt;/item&gt;
      &lt;item&gt;weakref 0.1.4 &lt;list rend="ul"&gt;&lt;item&gt;0.1.3 to v0.1.4&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;zlib 3.2.2 &lt;list rend="ul"&gt;&lt;item&gt;3.2.1 to v3.2.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following bundled gems are updated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;minitest 6.0.0&lt;/item&gt;
      &lt;item&gt;power_assert 3.0.1&lt;/item&gt;
      &lt;item&gt;rake 13.3.1&lt;/item&gt;
      &lt;item&gt;test-unit 3.7.3&lt;/item&gt;
      &lt;item&gt;rexml 3.4.4&lt;/item&gt;
      &lt;item&gt;rss 0.3.2 &lt;list rend="ul"&gt;&lt;item&gt;0.3.1 to 0.3.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;net-ftp 0.3.9 &lt;list rend="ul"&gt;&lt;item&gt;0.3.8 to v0.3.9&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;net-imap 0.6.2&lt;/item&gt;
      &lt;item&gt;net-smtp 0.5.1 &lt;list rend="ul"&gt;&lt;item&gt;0.5.0 to v0.5.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;matrix 0.4.3 &lt;list rend="ul"&gt;&lt;item&gt;0.4.2 to v0.4.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;prime 0.1.4 &lt;list rend="ul"&gt;&lt;item&gt;0.1.3 to v0.1.4&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;rbs 3.10.0 &lt;list rend="ul"&gt;&lt;item&gt;3.8.0 to v3.8.1, v3.9.0.dev.1, v3.9.0.pre.1, v3.9.0.pre.2, v3.9.0, v3.9.1, v3.9.2, v3.9.3, v3.9.4, v3.9.5, v3.10.0.pre.1, v3.10.0.pre.2, v3.10.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;typeprof 0.31.1&lt;/item&gt;
      &lt;item&gt;debug 1.11.1 &lt;list rend="ul"&gt;&lt;item&gt;1.11.0 to v1.11.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;base64 0.3.0 &lt;list rend="ul"&gt;&lt;item&gt;0.2.0 to v0.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;bigdecimal 4.0.1&lt;/item&gt;
      &lt;item&gt;drb 2.2.3 &lt;list rend="ul"&gt;&lt;item&gt;2.2.1 to v2.2.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;syslog 0.3.0 &lt;list rend="ul"&gt;&lt;item&gt;0.2.0 to v0.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;csv 3.3.5&lt;/item&gt;
      &lt;item&gt;repl_type_completor 0.1.12&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;RubyGems and Bundler&lt;/head&gt;
    &lt;p&gt;Ruby 4.0 bundled RubyGems and Bundler version 4. see the following links for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Upgrading to RubyGems/Bundler 4 - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.0 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.1 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.2 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.3 Released - RubyGems Blog&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Supported platforms&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Windows&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Dropped support for MSVC versions older than 14.0 (_MSC_VER 1900). This means Visual Studio 2015 or later is now required.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Compatibility issues&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The following methods were removed from Ractor due to the addition of&lt;/p&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;Ractor.yield&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#take&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#close_incoming&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#close_outgoing&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ObjectSpace._id2ref&lt;/code&gt;is deprecated. [Feature #15408]&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Process::Status#&amp;amp;&lt;/code&gt;and&lt;code&gt;Process::Status#&amp;gt;&amp;gt;&lt;/code&gt;have been removed. They were deprecated in Ruby 3.3. [Bug #19868]&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rb_path_check&lt;/code&gt;has been removed. This function was used for&lt;code&gt;$SAFE&lt;/code&gt;path checking which was removed in Ruby 2.7, and was already deprecated. [Feature #20971]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;A backtrace for&lt;/p&gt;&lt;code&gt;ArgumentError&lt;/code&gt;of “wrong number of arguments” now include the receiver’s class or module name (e.g., in&lt;code&gt;Foo#bar&lt;/code&gt;instead of in&lt;code&gt;bar&lt;/code&gt;). [Bug #21698]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Backtraces no longer display&lt;/p&gt;&lt;code&gt;internal&lt;/code&gt;frames. These methods now appear as if it is in the Ruby source file, consistent with other C-implemented methods. [Bug #20968]&lt;p&gt;Before:&lt;/p&gt;&lt;code&gt;ruby -e '[1].fetch_values(42)' &amp;lt;internal:array&amp;gt;:211:in 'Array#fetch': index 42 outside of array bounds: -1...1 (IndexError) from &amp;lt;internal:array&amp;gt;:211:in 'block in Array#fetch_values' from &amp;lt;internal:array&amp;gt;:211:in 'Array#map!' from &amp;lt;internal:array&amp;gt;:211:in 'Array#fetch_values' from -e:1:in '&amp;lt;main&amp;gt;'&lt;/code&gt;&lt;p&gt;After:&lt;/p&gt;&lt;code&gt;$ ruby -e '[1].fetch_values(42)' -e:1:in 'Array#fetch_values': index 42 outside of array bounds: -1...1 (IndexError) from -e:1:in '&amp;lt;main&amp;gt;'&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Stdlib compatibility issues&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;CGI library is removed from the default gems. Now we only provide&lt;/p&gt;&lt;code&gt;cgi/escape&lt;/code&gt;for the following methods:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;CGI.escape&lt;/code&gt;and&lt;code&gt;CGI.unescape&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeHTML&lt;/code&gt;and&lt;code&gt;CGI.unescapeHTML&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeURIComponent&lt;/code&gt;and&lt;code&gt;CGI.unescapeURIComponent&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeElement&lt;/code&gt;and&lt;code&gt;CGI.unescapeElement&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;With the move of&lt;/p&gt;&lt;code&gt;Set&lt;/code&gt;from stdlib to core class,&lt;code&gt;set/sorted_set.rb&lt;/code&gt;has been removed, and&lt;code&gt;SortedSet&lt;/code&gt;is no longer an autoloaded constant. Please install the&lt;code&gt;sorted_set&lt;/code&gt;gem and&lt;code&gt;require 'sorted_set'&lt;/code&gt;to use&lt;code&gt;SortedSet&lt;/code&gt;. [Feature #21287]&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Net::HTTP&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The default behavior of automatically setting the &lt;code&gt;Content-Type&lt;/code&gt;header to&lt;code&gt;application/x-www-form-urlencoded&lt;/code&gt;for requests with a body (e.g.,&lt;code&gt;POST&lt;/code&gt;,&lt;code&gt;PUT&lt;/code&gt;) when the header was not explicitly set has been removed. If your application relied on this automatic default, your requests will now be sent without a Content-Type header, potentially breaking compatibility with certain servers. [GH-net-http #205]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;The default behavior of automatically setting the &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;C API updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;IO&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;rb_thread_fd_close&lt;/code&gt;is deprecated and now a no-op. If you need to expose file descriptors from C extensions to Ruby code, create an&lt;code&gt;IO&lt;/code&gt;instance using&lt;code&gt;RUBY_IO_MODE_EXTERNAL&lt;/code&gt;and use&lt;code&gt;rb_io_close(io)&lt;/code&gt;to close it (this also interrupts and waits for all pending operations on the&lt;code&gt;IO&lt;/code&gt;instance). Directly closing file descriptors does not interrupt pending operations, and may lead to undefined behaviour. In other words, if two&lt;code&gt;IO&lt;/code&gt;objects share the same file descriptor, closing one does not affect the other. [Feature #18455]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;GVL&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;rb_thread_call_with_gvl&lt;/code&gt;now works with or without the GVL. This allows gems to avoid checking&lt;code&gt;ruby_thread_has_gvl_p&lt;/code&gt;. Please still be diligent about the GVL. [Feature #20750]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Set&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;A C API for&lt;/p&gt;&lt;code&gt;Set&lt;/code&gt;has been added. The following methods are supported: [Feature #21459]&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;rb_set_foreach&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_new&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_new_capa&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_lookup&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_add&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_clear&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_delete&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_size&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Implementation improvements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Class#new&lt;/code&gt;(ex.&lt;code&gt;Object.new&lt;/code&gt;) is faster in all cases, but especially when passing keyword arguments. This has also been integrated into YJIT and ZJIT. [Feature #21254]&lt;/item&gt;
      &lt;item&gt;GC heaps of different size pools now grow independently, reducing memory usage when only some pools contain long-lived objects&lt;/item&gt;
      &lt;item&gt;GC sweeping is faster on pages of large objects&lt;/item&gt;
      &lt;item&gt;“Generic ivar” objects (String, Array, &lt;code&gt;TypedData&lt;/code&gt;, etc.) now use a new internal “fields” object for faster instance variable access&lt;/item&gt;
      &lt;item&gt;The GC avoids maintaining an internal &lt;code&gt;id2ref&lt;/code&gt;table until it is first used, making&lt;code&gt;object_id&lt;/code&gt;allocation and GC sweeping faster&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;object_id&lt;/code&gt;and&lt;code&gt;hash&lt;/code&gt;are faster on Class and Module objects&lt;/item&gt;
      &lt;item&gt;Larger bignum Integers can remain embedded using variable width allocation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Random&lt;/code&gt;,&lt;code&gt;Enumerator::Product&lt;/code&gt;,&lt;code&gt;Enumerator::Chain&lt;/code&gt;,&lt;code&gt;Addrinfo&lt;/code&gt;,&lt;code&gt;StringScanner&lt;/code&gt;, and some internal objects are now write-barrier protected, which reduces GC overhead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ractor&lt;/head&gt;
    &lt;p&gt;A lot of work has gone into making Ractors more stable, performant, and usable. These improvements bring Ractor implementation closer to leaving experimental status.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance improvements &lt;list rend="ul"&gt;&lt;item&gt;Frozen strings and the symbol table internally use a lock-free hash set [Feature #21268]&lt;/item&gt;&lt;item&gt;Method cache lookups avoid locking in most cases&lt;/item&gt;&lt;item&gt;Class (and generic ivar) instance variable access is faster and avoids locking&lt;/item&gt;&lt;item&gt;CPU cache contention is avoided in object allocation by using a per-ractor counter&lt;/item&gt;&lt;item&gt;CPU cache contention is avoided in xmalloc/xfree by using a thread-local counter&lt;/item&gt;&lt;item&gt;&lt;code&gt;object_id&lt;/code&gt;avoids locking in most cases&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Bug fixes and stability &lt;list rend="ul"&gt;&lt;item&gt;Fixed possible deadlocks when combining Ractors and Threads&lt;/item&gt;&lt;item&gt;Fixed issues with require and autoload in a Ractor&lt;/item&gt;&lt;item&gt;Fixed encoding/transcoding issues across Ractors&lt;/item&gt;&lt;item&gt;Fixed race conditions in GC operations and method invalidation&lt;/item&gt;&lt;item&gt;Fixed issues with processes forking after starting a Ractor&lt;/item&gt;&lt;item&gt;GC allocation counts are now accurate under Ractors&lt;/item&gt;&lt;item&gt;Fixed TracePoints not working after GC [Bug #19112]&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;JIT&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ZJIT &lt;list rend="ul"&gt;&lt;item&gt;Introduce an experimental method-based JIT compiler. Where available, ZJIT can be enabled at runtime with the &lt;code&gt;--zjit&lt;/code&gt;option or by calling&lt;code&gt;RubyVM::ZJIT.enable&lt;/code&gt;. When building Ruby, Rust 1.85.0 or later is required to include ZJIT support.&lt;/item&gt;&lt;item&gt;As of Ruby 4.0.0, ZJIT is faster than the interpreter, but not yet as fast as YJIT. We encourage experimentation with ZJIT, but advise against deploying it in production for now.&lt;/item&gt;&lt;item&gt;Our goal is to make ZJIT faster than YJIT and production-ready in Ruby 4.1.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Introduce an experimental method-based JIT compiler. Where available, ZJIT can be enabled at runtime with the &lt;/item&gt;
      &lt;item&gt;YJIT &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;RubyVM::YJIT.runtime_stats&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ratio_in_yjit&lt;/code&gt;no longer works in the default build. Use&lt;code&gt;--enable-yjit=stats&lt;/code&gt;on&lt;code&gt;configure&lt;/code&gt;to enable it on&lt;code&gt;--yjit-stats&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;invalidate_everything&lt;/code&gt;to default stats, which is incremented when every code is invalidated by TracePoint.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;mem_size:&lt;/code&gt;and&lt;code&gt;call_threshold:&lt;/code&gt;options to&lt;code&gt;RubyVM::YJIT.enable&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;RJIT &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;--rjit&lt;/code&gt;is removed. We will move the implementation of the third-party JIT API to the ruby/rjit repository.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See NEWS or commit logs for more details.&lt;/p&gt;
    &lt;p&gt;With those changes, 3889 files changed, 230769 insertions(+), 297003 deletions(-) since Ruby 3.4.0!&lt;/p&gt;
    &lt;p&gt;Merry Christmas, a Happy New Year, and Happy Hacking with Ruby 4.0!&lt;/p&gt;
    &lt;head rend="h2"&gt;Download&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.tar.gz&lt;/p&gt;
        &lt;code&gt;SIZE: 23955109 SHA1: 754e39e9ad122e1b6deaed860350bac133a35ed3 SHA256: 2e8389c8c072cb658c93a1372732d9eac84082c88b065750db1e52a5ac630271 SHA512: 688254e939b197d564e896fb951bc1abf07142f489e91c5ed0b11f68f52d6adb6b1f86616fe03f1f0bb434beeef7e75e158b9c616afb39bb34403b0b78d2ee19&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.tar.xz&lt;/p&gt;
        &lt;code&gt;SIZE: 18008368 SHA1: 05ec670e86f84325c5353ef2f2888e53b6adc602 SHA256: a72bacee9de07283ebc19baa4ac243b193129f21aa4e168c7186fb1fe7d07fe1 SHA512: 2d5b2e566eaf70a5f3ea6ce6afc0611c0415de58a41336ef7a0b855c9a91eda9aa790a5f8b48e40a1eb9d50f8ea0f687216e617f16c8d040a08474f3116518a4&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.zip&lt;/p&gt;
        &lt;code&gt;SIZE: 29253204 SHA1: 0b69f89d1d140157251c0d3a6032f6c45cdf81e8 SHA256: 70cb1bf89279b86ab9a975d504607c051fc05ee03e311d550a5541b65e373455 SHA512: a72e076ef618c0aeb9d20cf22e6fb12fda36809c0064ef0f98153b95a0bac257ef606342444a38f992c4594bf376a4d264686cf597463aa6f111220798784302&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What is Ruby&lt;/head&gt;
    &lt;p&gt;Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple platforms and is used all over the world especially for web development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent News&lt;/head&gt;
    &lt;head rend="h3"&gt;A New Look for Ruby's Documentation&lt;/head&gt;
    &lt;p&gt;Following the ruby-lang.org redesign, we have more news to celebrate Ruby’s 30th anniversary: docs.ruby-lang.org has a completely new look with Aliki—RDoc’s new default theme.&lt;/p&gt;
    &lt;p&gt;Posted by Stan Lo on 23 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Redesign our Site Identity&lt;/head&gt;
    &lt;p&gt;We are excited to announce a comprehensive redesign of our site. The design for this update was created by Taeko Akatsuka.&lt;/p&gt;
    &lt;p&gt;Posted by Hiroshi SHIBATA on 22 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Ruby 4.0.0 preview3 Released&lt;/head&gt;
    &lt;p&gt;We are pleased to announce the release of Ruby 4.0.0-preview3. Ruby 4.0 introduces Ruby::Box and “ZJIT”, and adds many improvements.&lt;/p&gt;
    &lt;p&gt;Posted by naruse on 18 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Ruby 3.4.8 Released&lt;/head&gt;
    &lt;p&gt;Ruby 3.4.8 has been released.&lt;/p&gt;
    &lt;p&gt;Posted by k0kubun on 17 Dec 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46382011</guid><pubDate>Thu, 25 Dec 2025 04:13:00 +0000</pubDate></item></channel></rss>