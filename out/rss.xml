<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 09 Nov 2025 13:20:21 +0000</lastBuildDate><item><title>Show HN: PingStalker – A a macOS tool for network engineers</title><link>https://www.pingstalker.com/?hn</link><description>&lt;doc fingerprint="74ef48fdbdb256bf"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Core Features&lt;/head&gt;
    &lt;p&gt;Built for network and Wi-Fi pros who need answers fast — scan, monitor, and troubleshoot with a single, beautiful macOS app. Try it free!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fast discovery &amp;amp; scanning: Quickly find devices and services on any network so you know what’s talking and where.&lt;/item&gt;
      &lt;item&gt;Continuous monitoring &amp;amp; logging: Capture and store events (ARP, DHCP, Wi-Fi activity, and more) for instant troubleshooting and later review.&lt;/item&gt;
      &lt;item&gt;Deep Wi-Fi insights: Capture monitor-mode traffic and get actionable performance diagnostics to fix wireless problems faster.&lt;/item&gt;
      &lt;item&gt;Everyday network tools: Subnet calculator, MAC vendor lookup, basic speed tests — the quick utilities you actually use.&lt;/item&gt;
      &lt;item&gt;Designed for work: A clean, macOS UI that’s fast, readable, and built for long sessions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We now support: Network &amp;amp; port scans, continuous monitoring &amp;amp; logging, Wi-Fi monitor mode, detailed Wi-Fi diagnostics, subnet math, MAC lookup, and speedtests.&lt;/p&gt;
    &lt;p&gt;Start your 1-day free trial No credit card required&lt;/p&gt;
    &lt;head rend="h2"&gt;Feature Highlights&lt;/head&gt;
    &lt;head rend="h3"&gt;Live Ping Monitoring&lt;/head&gt;
    &lt;p&gt;Track critical hosts in real time. See latency, uptime, and response trends instantly — know what’s healthy and what’s not.&lt;/p&gt;
    &lt;head rend="h3"&gt;Speed Testing&lt;/head&gt;
    &lt;p&gt;Measure download, upload, and latency with Cloudflare’s edge-powered speed tests, then share results instantly with clients or teammates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interface Details&lt;/head&gt;
    &lt;p&gt;Everything you need to know about your connection — from IP and DHCP to Wi-Fi strength and ISP details — presented clearly, updated in real time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wireless Network Analysis&lt;/head&gt;
    &lt;p&gt;See exactly how your Wi-Fi is performing — live signal strength, channel usage, and nearby networks at a glance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Subnet Calculator&lt;/head&gt;
    &lt;p&gt;Plan and calculate networks in seconds — CIDR, masks, and ranges made simple and beautifully visual.&lt;/p&gt;
    &lt;head rend="h3"&gt;MAC Address Lookup&lt;/head&gt;
    &lt;p&gt;Instantly look up vendors with a built-in offline OUI database that also flags randomized or locally administered MAC addresses — so you always know what’s real.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wi-Fi Sniffing/Monitor Mode&lt;/head&gt;
    &lt;p&gt;Turn your Mac into a Wi-Fi sniffer: choose a channel, hit Start, and we’ll handle monitor mode and open Wireshark for you. Change channels on the fly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Network Logging&lt;/head&gt;
    &lt;p&gt;When PingStalker is running, it’s watching your network so you don’t have to. It listens for the chatter that matters — another host pinging you, a trunk port exposing extra VLANs, LLDP/CDP Neighbor information or a flood of DHCP or broadcast traffic. These are just a few of the events PingStalker automatically detects and logs, giving you eyes on everything happening beneath the surface.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45810842</guid><pubDate>Tue, 04 Nov 2025 13:33:11 +0000</pubDate></item><item><title>Why is Zig so cool?</title><link>https://nilostolte.github.io/tech/articles/ZigCool.html</link><description>&lt;doc fingerprint="2e0298192ea533d8"&gt;
  &lt;main&gt;&lt;p&gt;I can’t think of any other language in my 45 years long career that surprised more than Zig. I can easily say that Zig is not only a new programming language, but it’s a totally new way to write programs, in my opinion. To say it’s merely a language to replace C or C++, it’s a huge understatement.&lt;/p&gt;&lt;p&gt;In this article, I will present the features that I found to be most seductive in the language, and I will also present a brief overview about it. The goal is to present simple features for programmers to quick start in the language. Be aware, though, that many more features are affecting its acceptability in the industry.&lt;/p&gt;&lt;p&gt;Probably the most incredible virtue of Zig compiler is its ability to compile C code. This associated with the ability to cross-compile code to be run in another architecture, different than the machine where it is was originally compiled, is already something quite different and unique. These features alone, completely out-of-the-box, are causing an incredible impact in the industry already. In spite of that what we want to concentrate on is how to program in Zig and why should one choose Zig instead of any other language.&lt;/p&gt;&lt;p&gt;Installing the compiler is quite simple. In Zinglang’s download page one finds the compiler in several formats, depending on the processor or OS:&lt;/p&gt;&lt;p&gt;On Windows 10, for example, one chooses the x86_64 zip file and copy its decompressed content in the desired directory. For example, in “Program Files”. I modified the root directory name to “zig-windows-x86_64” because in this way I can just copy another version of the compiler with no need to modify the path in Path environment variable.&lt;/p&gt;&lt;p&gt;Next, one adds this root directory path to the Path environment variable using Advanced System Properties (clicking on 1-4, pasting path on 5, and clicking “OK” on 6-8):&lt;/p&gt;&lt;p&gt;Notice that after setting the path to Zig’s root directory one can already use the compiler in CLI mode. That’s the recommended way to use it for the sake of simplicity.&lt;/p&gt;&lt;p&gt;It’s recommended to build a “Hello World!” program using the instructions in the “Getting Started” section in this site. An alternative installation procedure is also presented there, including for MacOS and Linux (“Installing manually” is highly recommended). It’s also recommended to check the “Language” Basis section, for a deeper insight of Zig language.&lt;/p&gt;&lt;p&gt;The following sections will give a bird’s eye view of Zig language. Their goal is to instruct the programmer how to quickly start programming in Zig by just knowing a few basic concepts and commands.&lt;/p&gt;&lt;p&gt;Then, a compact view on how to build programs and test modules is given.&lt;/p&gt;&lt;p&gt;Finally, a deeper view on how low level programming can be done in Zig. A more detailed explanation on the examples used is also given.&lt;/p&gt;&lt;p&gt;Normally, variable declarations in Zig have potentially three parts. The first part contains the accessibility (&lt;code&gt;pub&lt;/code&gt; or nothing),
followed by the word &lt;code&gt;var&lt;/code&gt; or &lt;code&gt;const&lt;/code&gt;, followed by
the variable name. The second part, separated of the first part by a
colon, contains the variable type declaration. The third part is the
initialization of the variable. Only the first and third part are
compulsory in Zig, which is kind of puzzling, coming from Java or C. One
may wonder how the compiler discovers the variable type. The type in
this case is inferred by the initialization.&lt;/p&gt;&lt;code&gt;var sum : usize = 0;         // variable declaration with 3 parts&lt;/code&gt;&lt;p&gt;Variables that don’t have their accessibility explicitly &lt;code&gt;pub&lt;/code&gt; are local to the module, that is, they aren’t
accessible outside the source file it was declared (just like
&lt;code&gt;static&lt;/code&gt; variables in C). It’s not recommended to have
variables declared &lt;code&gt;pub&lt;/code&gt; and it’s recommended to have just
few functions declared &lt;code&gt;pub&lt;/code&gt; in a module to discourage
coupling and encourage cohesion. The &lt;code&gt;pub&lt;/code&gt; functions behave
as the module’s API.&lt;/p&gt;&lt;p&gt;In Zig, a &lt;code&gt;.{&lt;/code&gt; closed with a &lt;code&gt;}&lt;/code&gt; is an
“anonymous struct literal” - an anonymous struct mostly used to
initialize the elements of another structure or to create a new
structure with its elements initialized. A &lt;code&gt;.{ }&lt;/code&gt; is an an
empty anonymous struct literal. The word &lt;code&gt;struct&lt;/code&gt; followed by
a &lt;code&gt;{&lt;/code&gt; and closed with a &lt;code&gt;}&lt;/code&gt; is a struct
declaration. One can initialize a variable with a type, which functions
as an alias to the type. Notice the “test block” allowing to
compile and execute tests without the need of an executable.&lt;/p&gt;&lt;p&gt;Bitfields are declared fields with types having specific sizes in a &lt;code&gt;packed struct&lt;/code&gt;. Pointers can point to a specific bit field
as shown here:&lt;/p&gt;&lt;p&gt;Zig syntax is clearer than C’s, except that one would think it should be &lt;code&gt;[0..8]&lt;/code&gt;, but in reality it’s an open interval:
&lt;code&gt;[0..9)&lt;/code&gt;. Advantage in Zig: the type
declaration of &lt;code&gt;i&lt;/code&gt;, its initialization, test, and
incrementation are automatic.&lt;/p&gt;&lt;p&gt;A &lt;code&gt;[_]&lt;/code&gt; defines an array with unknown size. It must be followed
by the type of its elements (here &lt;code&gt;u8&lt;/code&gt;, unsigned
byte) and its initialization between &lt;code&gt;{&lt;/code&gt; and
&lt;code&gt;}&lt;/code&gt;. In this example below, the initialization is saying that
this is an array of unknown size (&lt;code&gt;[_]&lt;/code&gt;) where each element
is of type &lt;code&gt;u8&lt;/code&gt; (unsigned byte) and each element initialized
with zeros (&lt;code&gt;{0} ** 81&lt;/code&gt;). Notice that the size is also
inferred by the repetition factor (&lt;code&gt;81&lt;/code&gt;) of the
initialization (&lt;code&gt;{0}&lt;/code&gt;).&lt;/p&gt;&lt;code&gt;var grid = [_]u8{0} ** 81;&lt;/code&gt;&lt;p&gt;We see in the figure below a test environment with a loop interacting over the array and adding its elements. The &lt;code&gt;try expect&lt;/code&gt;
statement verifies that &lt;code&gt;sum&lt;/code&gt; is correct.&lt;/p&gt;&lt;p&gt;The word &lt;code&gt;byte&lt;/code&gt; is not a type or reserved word in Zig.
Here, it’s a variable to hold each of the array’s elements on each step
of the loop. Notice that a variable declared between two &lt;code&gt;|&lt;/code&gt;
with an array between the parenthesis of a for loop is always assumed of
the same type as the array elements.&lt;/p&gt;&lt;p&gt;Notice also, that &lt;code&gt;usize&lt;/code&gt; is the natural unsigned integer
for the platform. That means on 64 bits machines it’s an
&lt;code&gt;u64&lt;/code&gt;, and in 32 bits machines it’s an &lt;code&gt;u32&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Pointers to arrays can use pointer arithmetic only if the pointer is explicitly declared as a many-item pointer, here &lt;code&gt;[*]const i32&lt;/code&gt;. Notice that the array below is
&lt;code&gt;const&lt;/code&gt;, can’t be changed, but that the pointer is
&lt;code&gt;var&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;When attributed the address of an individual array position, a pointer cannot be updated with pointer arithmetic. In this case, &lt;code&gt;const&lt;/code&gt; only prevents its value to be changed with another
direct address attribution. To dereference pointers in Zig one uses the
&lt;code&gt;ptr.*&lt;/code&gt; as shown below:&lt;/p&gt;&lt;p&gt;Zig can do many things in compilation time. Let’s initialize an array, for example. Here, a labelled break is used. The block is labelled with an &lt;code&gt;:&lt;/code&gt; after its name &lt;code&gt;init&lt;/code&gt; and
then a value is returned from the block with &lt;code&gt;break&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This syntax may look overwhelming. &lt;code&gt;0..&lt;/code&gt; means an infinite
range starting with zero. In the &lt;code&gt;for&lt;/code&gt;, variables &lt;code&gt;pt&lt;/code&gt; and
&lt;code&gt;i&lt;/code&gt; are respectively initialized with the address of
&lt;code&gt;initial_value&lt;/code&gt; array and zero. During the loop both are
incremented automatically and the loop stops right after dealing with
the array’s last position. Also notice how to dereference the
&lt;code&gt;pt&lt;/code&gt; pointer: &lt;code&gt;pt.*&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Also interesting it’s how the array is declared in the labelled block. The array is called &lt;code&gt;initial_value&lt;/code&gt; and has 10
positions of the type &lt;code&gt;Point&lt;/code&gt; (declared afterwards).
Variables must be initialized in Zig. The way to explicitly not
initialize is with the reserved word &lt;code&gt;undefined&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Functions in Zig are declared with &lt;code&gt;fn&lt;/code&gt; and are static by
default (cannot be imported in other files) in the file they are
declared, except when &lt;code&gt;fn&lt;/code&gt; is preceded by &lt;code&gt;pub&lt;/code&gt;. A
function can be “inlined.” Function pointers are preceded by
&lt;code&gt;const&lt;/code&gt; and followed by the function prototype.&lt;/p&gt;&lt;p&gt;Structs can have functions. Here, a simple stack is implemented. This stack is declared and used only inside the module it is defined, and it accesses and modifies other data structures in the module that are irrelevant in this example. The stack can have at maximum 81 elements (as seen in &lt;code&gt;stk&lt;/code&gt; declaration), each one of type
&lt;code&gt;StkNode&lt;/code&gt;. Notice that ++ and –– operators don’t exist in Zig.
The equivalent += and –= should be used instead. The stack pointer is
just an integer used as an index in the &lt;code&gt;stk&lt;/code&gt; array.&lt;/p&gt;&lt;p&gt;Notice that the pointer &lt;code&gt;self&lt;/code&gt; (&lt;code&gt;self&lt;/code&gt; is not a
reserved word, but it’s just a convention) is not passed explicitly as a
parameter as one would normally expect. It is indirectly assumed that it
is a pointer to the instance of the stack the function is been called
from. In the example below, a stack pop would be called with
&lt;code&gt;stack.pop();&lt;/code&gt;. In this case the pointer &lt;code&gt;self&lt;/code&gt;
corresponds to a pointer to &lt;code&gt;stack&lt;/code&gt;. This pointer is then
somewhat equivalent to &lt;code&gt;this&lt;/code&gt; in Java or C++.&lt;/p&gt;&lt;p&gt;Function &lt;code&gt;init()&lt;/code&gt; is the stack constructor.&lt;/p&gt;&lt;p&gt;Notice as well that functions &lt;code&gt;pop&lt;/code&gt; and &lt;code&gt;push&lt;/code&gt;
are “inlined.”&lt;/p&gt;&lt;p&gt;To build an executable program one needs a &lt;code&gt;main&lt;/code&gt;
function, which indicates the program entry point as in Java or C
programs. When this function exists the set of modules can be compiled
to an executable code. A simple program can have a &lt;code&gt;main&lt;/code&gt;
function in the same file as the rest of the program. In many cases one
can also insert a main function at the end of a module to create an
executable in order to debug the module independently. Once debugged
this function can be commented out.&lt;/p&gt;&lt;p&gt;In these situations one can use the following command line to compile &lt;code&gt;program.zig&lt;/code&gt; and to generate an executable program (on
Windows, a &lt;code&gt;program.exe&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;zig build-exe -O ReleaseFast program.zig&lt;/code&gt;&lt;p&gt;This can be put inside a batch file to prevent typos.&lt;/p&gt;&lt;p&gt;This is probably the best feature of Zig as a programming language. This environment is normally used for testing, but it can also be used for prototyping.&lt;/p&gt;&lt;p&gt;A block in Zig is similar to a block in C or Java, that is, some code between &lt;code&gt;{&lt;/code&gt; and &lt;code&gt;}&lt;/code&gt;. A test block is a
block that starts with &lt;code&gt;test "message" {&lt;/code&gt; and finishes with
&lt;code&gt;}&lt;/code&gt;, where &lt;code&gt;"message"&lt;/code&gt; is a string containing the
message to be displayed when the test is executed (in this case only the
word message).&lt;/p&gt;&lt;p&gt;Test blocks are executed independently from an executable file. The final executable file does not execute the tests. The test blocks in a given &lt;code&gt;module.zig&lt;/code&gt; are compiled together with the entire code
in that file and executed by the following command:&lt;/p&gt;&lt;code&gt;zig test module.zig&lt;/code&gt;&lt;p&gt;As a real life example, the test block from module example.zig is shown below:&lt;/p&gt;&lt;code&gt;test " =&amp;gt; testing set and print functions" {
    set(
      "800000000003600000070090200" ++
      "050007000000045700000100030" ++
      "001000068008500010090000400"
    );
    std.debug.print("\n" ++
      "===================\n" ++
      "Input Grid\n" ++
      "===================\n",
      .{}
    );
    print();
}&lt;/code&gt;&lt;p&gt;Notice that &lt;code&gt;example.zig&lt;/code&gt; alone has no main
function and, therefore, cannot generate an executable, but its test
block can be executed by using the following command:&lt;/p&gt;&lt;code&gt;zig test example.zig&lt;/code&gt;&lt;p&gt;As the message says, the test block above tests the functions &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;print&lt;/code&gt;. As the code shows,
&lt;code&gt;set&lt;/code&gt; passes a string of decimal digits as a parameter,
followed by a print statement (which prints a header saying “Input Grid”
), followed itself by a call of the &lt;code&gt;print&lt;/code&gt; function.&lt;/p&gt;&lt;p&gt;The real display in a command tool is the following:&lt;/p&gt;&lt;p&gt;Let’s focus now on the &lt;code&gt;std.debug.print&lt;/code&gt; statement. This
statement is in fact a call to the function &lt;code&gt;print&lt;/code&gt; in
&lt;code&gt;debug.zig&lt;/code&gt; in the standard Zig library &lt;code&gt;std&lt;/code&gt;. The
first parameter is a format string, and the second is an anonymous
struct (preceded by a dot) containing a list of variables to be
displayed using the format string. Since there is no formatting in the
format string, the struct is empty. This is how formatted prints are
done. This one will display in the stderr by default, as shown
above.&lt;/p&gt;&lt;p&gt;This all looks just like in C language, but there is a fundamental difference here. In C, the printf function dynamically interprets the format string in execution time, whereas in Zig it’s possible to deal with the literal string and the list of variables in compilation time. This is a difficult principle to grasp at the start. Many things can be executed in compilation time.&lt;/p&gt;&lt;p&gt;Using a debugger is not usually a straightforward task, except in IDEs that already integrate a debugger (as in Java IDEs such as Eclipse or Intellij IDEA) or in integrated development kits (such as w64devkit for C/C++).&lt;/p&gt;&lt;p&gt;A huge inconvenient in using debuggers in this way is that one must integrate the symbols, which not only bloats the code with information that is not useful to the program, but also requires compiling in Debug mode, which generates executable code that’s notoriously less efficient. Someone with practice in complex systems knows that it can be a very time consuming task.&lt;/p&gt;&lt;p&gt;Zig offers a quite convenient hack in order to avoid these headaches.&lt;/p&gt;&lt;p&gt;This built-in stops a program at the point where a &lt;code&gt;@breakpoint();&lt;/code&gt; is inserted in the source code when its
executable is run in a debugger. This is actually an useful feature to
debug optimized Zig code without the need of symbols.&lt;/p&gt;&lt;p&gt;All it’s needed is to trace the variables one wants to watch using &lt;code&gt;std.debug.print&lt;/code&gt; right before &lt;code&gt;@breakpoint();&lt;/code&gt; In
this way one can know what are the values of the variables at that exact
moment.&lt;/p&gt;&lt;p&gt;As a real life example, one generates an executable for module debug_example.zig which has the has the following &lt;code&gt;main&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;pub fn main() !void {
    set(
      "800000000003600000070090200" ++
      "050007000000045700000100030" ++
      "001000068008500010090000400"
    );
}&lt;/code&gt;&lt;p&gt;To be able to double check with the results from example.zig, the parameter passed to &lt;code&gt;set&lt;/code&gt; function in this
&lt;code&gt;main&lt;/code&gt; is the same string as the one passed to
&lt;code&gt;set&lt;/code&gt; in the test block in example.zig,
but this time one inserts the following code inside &lt;code&gt;set&lt;/code&gt;
function:&lt;/p&gt;&lt;code&gt;        if (c != 0) {
           print();
           std.debug.print(
              "Current digit {}\nposition in string {}\n" ++
              "line {}\ncolumn {}\ncode {b}\n", 
              .{c, k, i, j, code}
           );
           @breakpoint();
        }&lt;/code&gt;&lt;p&gt;One can then generate the &lt;code&gt;debug_example.exe&lt;/code&gt; executable
with the following build command:&lt;/p&gt;&lt;code&gt;zig build-exe debug_example.zig&lt;/code&gt;&lt;p&gt;Next, one uses a debugger to call &lt;code&gt;debug_example.exe&lt;/code&gt;. In
this case I used &lt;code&gt;gdb&lt;/code&gt;, a debugger for C/C++ included in
w64devkit, but it could be any debugger for executable programs. Once
inside &lt;code&gt;gdb&lt;/code&gt;, one needs to run the program using an
&lt;code&gt;r&lt;/code&gt; command and typing &lt;code&gt;Enter&lt;/code&gt; right after as
shown below. Notice that the program printed the grid with its contents
so far as well as the variables, stopping
at the point expected. Then, by typing &lt;code&gt;c&lt;/code&gt; command followed
by an &lt;code&gt;Enter&lt;/code&gt; one continues tracing the grid contents and 
the variables. After that, one can continue by just typing 
&lt;code&gt;Enter&lt;/code&gt; (it repeats the last command - &lt;code&gt;c&lt;/code&gt;, in this 
case). By continuing typing &lt;code&gt;Enter&lt;/code&gt; until the program finishes, 
the values found in the grid correspond to the values shown by the test 
block in &lt;code&gt;example.zig&lt;/code&gt; above, since both examples have the same
parameter passed to &lt;code&gt;set&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;With the introduction and the examples given in the previous sections, one can already start programming Zig for writing generic applications. For more advanced programmers, what follows is a more in-depth analysis of some interesting low-level features already used in the examples, but not yet explicitly commented.&lt;/p&gt;&lt;p&gt;The idea of the examples shown is to construct a module that sets (initializes) and displays a 9x9 matrix. This matrix will hold a Sudoku grid, that is, it will only contain elements with decimal digits. The initialization of the grid should guarantee that the grid satisfies the rules of Sudoku game, so it will contain no errors.&lt;/p&gt;&lt;p&gt;At the same time it would be also an excellent opportunity to demonstrate Zig’s low level capabilities, at least the most noticeable ones, and these examples fit this goal quite well.&lt;/p&gt;&lt;p&gt;The whole hypothesis behind these examples is the representation of a grid digit as a bit in the position given by its value. This representation is quite convenient to detect if a digit is already present in the grid or not (these are basic rules of Sudoku grids). In spite of that, this is so encrypted it is only used internally in the module.&lt;/p&gt;&lt;p&gt;With the purpose of having values that are easily understood by humans, the digits are actually stored in the matrix as standard &lt;code&gt;u8&lt;/code&gt; integers. Even though the input grid in the examples is
given in string format, the ASCII characters are internally converted to
&lt;code&gt;u8&lt;/code&gt; integers. The digits’ storage in the grid is organized
linearly, line by line, in an array with 81 positions, called
&lt;code&gt;grid&lt;/code&gt; in the examples:&lt;/p&gt;&lt;code&gt;var grid = [_]u8{0} ** 81;        // Sudoku grid stored linearly&lt;/code&gt;&lt;p&gt;To verify grid correctness, one needs to access the elements by its respective line and column. In other words, one needs to access the elements as in a matrix. The strategy is to create an array of pointers with 9 positions, each one pointing to the start of each line. Blocks of code cannot in principle return a value, but in Zig they can with labeled breaks:&lt;/p&gt;&lt;code&gt;const matrix = fill9x9: {         // matrix array to allow access  
   var m : [9][*]u8 = undefined;  // to grid element as a matrix, 
   var pt : [*]u8 = &amp;amp;grid;        // thus: element = matrix[i][j]
   for (0..9) |i| {               //
      m[i] = pt;                  // stores pointers of each line
      pt += 9;                    // at each position of matrix
   }                              //
   break :fill9x9 m;              // initializes matrix with m
};&lt;/code&gt;&lt;p&gt;At the end of the loop, &lt;code&gt;m&lt;/code&gt; is returned outside the block
using a &lt;code&gt;break :fill9x9 m;&lt;/code&gt; command. Notice that
&lt;code&gt;fill9x9&lt;/code&gt; corresponds to the name of a label placed right
before the beginning of the block.&lt;/p&gt;&lt;p&gt;Supposing &lt;code&gt;i&lt;/code&gt; and &lt;code&gt;j&lt;/code&gt;, respectively an
element’s line and column, any element of the grid can be accessed using
this notation:&lt;/p&gt;&lt;code&gt;element = matrix[i][j]&lt;/code&gt;&lt;p&gt;The key concept used here is the replacement of an integer decimal digit &lt;code&gt;i&lt;/code&gt; by an integer &lt;code&gt;code&lt;/code&gt; such as:&lt;/p&gt;&lt;code&gt;      i ∈ [1,9]  →  code = 2ⁱ⁻¹
      i = 0      →  code = 0&lt;/code&gt;&lt;p&gt;In other words, the only bit of &lt;code&gt;code&lt;/code&gt; that is set to
&lt;code&gt;1&lt;/code&gt; is the bit at the position &lt;code&gt;i-1&lt;/code&gt; if
&lt;code&gt;i&lt;/code&gt; is between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt;, otherwise
all bits of &lt;code&gt;code&lt;/code&gt; are zero.&lt;/p&gt;&lt;code&gt;code&lt;/code&gt; for
each digit&lt;p&gt;The table below shows the correspondence between digits and their binary representation:&lt;/p&gt;&lt;code&gt;code&lt;/code&gt; in
Zig&lt;p&gt;The value of &lt;code&gt;code&lt;/code&gt; is calculated in the function
&lt;code&gt;set&lt;/code&gt; using a left shift operator only if &lt;code&gt;c&lt;/code&gt; is
not zero:&lt;/p&gt;&lt;code&gt;code = @as(u9,1) &amp;lt;&amp;lt; (c-1);&lt;/code&gt;
&lt;p&gt;In Zig, constants must have a proper size in order to allow an operation to be compiled and to attribute the the result of an operation to a given variable. In this case, &lt;code&gt;code&lt;/code&gt; is declared of type
&lt;code&gt;u9&lt;/code&gt;. That’s another fundamental quality of Zig, to be able
to have variables with arbitrary bit size. As can be
seen in the table above, the maximum value that &lt;code&gt;code&lt;/code&gt; can have is 256,
which requires at least 9 bits to represent. The built-in
&lt;code&gt;@as&lt;/code&gt; allows to cast the &lt;code&gt;1&lt;/code&gt; constant to type
&lt;code&gt;u9&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;By representing digits as bits one can mirror the entire grid in much simpler ways.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;lines&lt;/code&gt; mirrors the entire grid by representing
each line with a &lt;code&gt;9&lt;/code&gt; bits integer, each bit representing a
decimal digit that might be present in the a line:&lt;/p&gt;&lt;code&gt;var   lines   = [_]u9{0} ** 9; &lt;/code&gt;
&lt;p&gt;In this way, by just accessing this array with the line &lt;code&gt;i&lt;/code&gt; of an element in the 9x9 grid one can know if a given
digit is already present in that line, by just performing a bitwise
and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with the digit’s
&lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;lines[i] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the line &lt;code&gt;i&lt;/code&gt;. Otherwise we have a
duplicate.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;columns&lt;/code&gt; mirrors the entire grid by
representing each column with a &lt;code&gt;9&lt;/code&gt; bits integer:&lt;/p&gt;&lt;code&gt;var   columns = [_]u9{0} ** 9;&lt;/code&gt;
&lt;p&gt;In this way, by just accessing this array with the column &lt;code&gt;j&lt;/code&gt; of an element in the 9x9 grid one can know if a given
digit is already present in that column, by just performing a bitwise
and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with the digit’s
&lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;columns[i] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the column &lt;code&gt;j&lt;/code&gt; . Otherwise it’s a
duplicate.&lt;/p&gt;&lt;p&gt;Let’s suppose an empty Sudoku grid, as it is the case when one is populating the grid with the input string as done in the examples. A new digit inserted at any empty element, must not already exist in the entire line, column or cell containing the new element.&lt;/p&gt;&lt;p&gt;Let’s suppose now this grid, already initialized:&lt;/p&gt;&lt;p&gt;A cell is each one of the nine 3x3 grids delimited by the thick lines. The key knowledge to understand at this point is that each specific element in the 9x9 grid has a unique line, column and cell that contains this element.&lt;/p&gt;&lt;p&gt;For example, the first cell of the grid contains the values: 3, 5, 6, 8, and 9. Therefore, the values: 1, 2, 4 and 7 are missing. Let’s suppose one is willing to place the value 7 in one of the empty places in the first cell. Obviously, one cannot place it in the only empty element of the first line, because 7 is already present in that line. One cannot place it in the only empty place in the first column either since 7 is already in that column. One can only place the 7 in one of the two empty elements of the second line. But one can’t know for sure which one is the good one.&lt;/p&gt;&lt;p&gt;Let’s examine now the second cell, which contains the values: 1, 5, 7, and 9. One can see that the only possible element in this cell where an 8 can be placed is in the first line at the empty position on the right of the value 7.&lt;/p&gt;&lt;p&gt;Arrays &lt;code&gt;lines&lt;/code&gt; and &lt;code&gt;columns&lt;/code&gt; take care of
checking duplicates in lines and in columns. A new array is then needed
to check duplicates in cells.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;cells&lt;/code&gt; mirrors the entire grid by representing
each cell with a &lt;code&gt;9&lt;/code&gt; bits integer:&lt;/p&gt;&lt;code&gt;var   cells   = [_]u9{0} ** 9;    // all elements at each cell&lt;/code&gt;
&lt;p&gt;Here is where things get more complicated. One cannot access &lt;code&gt;cells&lt;/code&gt; directly using the line or the column. It would be
easier if one could access &lt;code&gt;cells&lt;/code&gt; as a 3x3 matrix. This can
be done mimicking what has been done for the 9x9 matrix, that is,
filling the array &lt;code&gt;cell&lt;/code&gt; as follows:&lt;/p&gt;&lt;code&gt;const cell = fill3x3: {           // cell array to allows access
   var m : [3][*]u9 = undefined;  // cell elements as a matrix,
   var pt : [*]u9 = &amp;amp;cells;       // cell[cindx[i]][cindx[j]]
   for (0..3) |i| {               // 
      m[i] = pt;                  // stores pointers of each line
      pt += 3;                    // at each position of cell
   }                              //
   break :fill3x3 m;              // initializes cell with m
};                                //&lt;/code&gt;
&lt;p&gt;But now one needs to determine the line and column in &lt;code&gt;cell&lt;/code&gt; matrix from the line and column of the element in the
original 9x9 grid. One could use integer divisions to divide the line
and column by 3 to obtain the proper indexes, but a division operation
is notoriously slow. Two divisions makes it even worse. One can use the
following array to give the result of the division as follows:&lt;/p&gt;&lt;code&gt;const cindx   = [_]usize{ 0,0,0, 1,1,1, 2,2,2 };&lt;/code&gt;
&lt;p&gt;In this way, by just accessing this matrix with the line &lt;code&gt;i&lt;/code&gt; and column &lt;code&gt;j&lt;/code&gt; of an element in the 9x9 grid,
one can know if a given digit is already present in this element’s cell
by just performing a bitwise and ( &lt;code&gt;&amp;amp;&lt;/code&gt; )
with the digit’s &lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;cell[cindx[i]][cindx[j]] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the cell. Otherwise it’s a duplicate.&lt;/p&gt;&lt;p&gt;The complete test to verify if an element is duplicated can be done by composing with a bitwise or ( &lt;code&gt;|&lt;/code&gt; )
all the previous elements in the same line, column and cell, and then
performing a bitwise and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with
the element’s &lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;if (((lines[i]|columns[j]|cell[cindx[i]][cindx[j]])&amp;amp;code) !=  0) {
    unreachable;
}&lt;/code&gt;
&lt;p&gt;If the result is zero it’s because the element doesn’t exist yet in its line, column or cell. If the result is not zero the program stops because it tries to run the instruction &lt;code&gt;unreacheable&lt;/code&gt;. This
is the simplest way to explicitly indicate an execution error in Zig.
Notice that the actual code in &lt;code&gt;set&lt;/code&gt; function also prints the
details where the error occurs.&lt;/p&gt;&lt;p&gt;For example, replacing the &lt;code&gt;'0'&lt;/code&gt; right after the first
&lt;code&gt;'8'&lt;/code&gt; by a &lt;code&gt;'5'&lt;/code&gt; in the string passed to
&lt;code&gt;set&lt;/code&gt; gives the following error while testing example.zig:&lt;/p&gt;&lt;p&gt;This is because in column 1 there was already a 5 in line 3 as the error message says. The error is due to a panic caused by reaching an unreachable code at function &lt;code&gt;set&lt;/code&gt; as indicated.&lt;/p&gt;&lt;p&gt;In function &lt;code&gt;set&lt;/code&gt;, a double &lt;code&gt;for&lt;/code&gt; loop
interacts line by line to copy each new element from the input string
&lt;code&gt;s&lt;/code&gt; into the grid as indicated below (variable &lt;code&gt;k&lt;/code&gt;
keeps the index of the new input character in the string
&lt;code&gt;s&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;   for ( 0..9 ) |i| {
      line = matrix[i];
      for ( 0..9 ) |j| {
        c = @intCast(s[k]-'0');
        if (c != 0) {
          code = @as(u9,1) &amp;lt;&amp;lt; (c-1);
          ⋮  // rest of the code
        }
        line[j] = c;
        k+= 1;  
      }
   }&lt;/code&gt;
&lt;p&gt;The character is converted to an &lt;code&gt;u4&lt;/code&gt; (variable
&lt;code&gt;c&lt;/code&gt;) by subtracting &lt;code&gt;'0'&lt;/code&gt; from it. If the new
element to be inserted in the grid is not equal to zero (
&lt;code&gt;c != 0&lt;/code&gt; ), &lt;code&gt;code&lt;/code&gt; (calculated with a left shift
instruction as indicated) is copied in each of the mirror grids, by
doing a bitwise or ( &lt;code&gt;|=&lt;/code&gt; ) with the
corresponding mirror grid, that is:&lt;/p&gt;&lt;code&gt;    lines[i] |= code;
    columns[j] |= code;
    cell[cindx[i]][cindx[j]] |= code;&lt;/code&gt;
&lt;p&gt;No test is required to explicitly test if the value of &lt;code&gt;c&lt;/code&gt;
is between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt; because an overflow will
occur at execution time when the shift operation is executed. For
example, replacing the &lt;code&gt;'0'&lt;/code&gt; right after the first
&lt;code&gt;'8'&lt;/code&gt; of the input string by a &lt;code&gt;':'&lt;/code&gt; in the string
passed to &lt;code&gt;set&lt;/code&gt; gives the following error while testing example.zig:&lt;/p&gt;&lt;p&gt;By substituting the same &lt;code&gt;'0'&lt;/code&gt; by a &lt;code&gt;'/'&lt;/code&gt; a
similar execution error will issued. The program will work only if the
values are between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt;, that is, if the
input grid contains only decimal digits.&lt;/p&gt;&lt;p&gt;Many Sudoku grids on the web also represent &lt;code&gt;'0'&lt;/code&gt; as a
&lt;code&gt;'.'&lt;/code&gt;. That’s the reason the following line exists in
&lt;code&gt;set&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;if (s[k] == '.') c = 0;&lt;/code&gt;
&lt;p&gt;This will conveniently bypass the shift operation because the value of &lt;code&gt;c&lt;/code&gt; is zero.&lt;/p&gt;&lt;p&gt;The forced errors shown in the two sections above demonstrate important features of Zig that might have passed inconspicuously. One is Zig’s robustness. In the case of the shift operation no wrong behavior is allowed and the situation is caught at execution time, as has been shown.&lt;/p&gt;&lt;p&gt;One might think that all the efforts in Zig are towards efficiency, but here it’s a typical case where performance was traded for robustness. One can have mixed feelings about this decision, when performance was the ultimate goal. In C, for example, it’s the programmer’s problem if a shift operation loses a bit and this translates in better performance for this specific Assembler instruction.&lt;/p&gt;&lt;p&gt;Another feature demonstrated in the two sections above is the possibility of using the test blocks for prototyping as suggested at the beginning of the article. The possibilities are numerous, even though the application shown was only to debug certain situations in cases of error.&lt;/p&gt;&lt;p&gt;These features alone demonstrate an awesome power, very rare in programming languages, particularly in compiled programing languages.&lt;/p&gt;&lt;p&gt;This is all quite surprising and let one think that many advantages previously found only in interpreted languages are gradually migrating to compiled languages in order to offer more performance. [A reference to Mojo here looks appropriate].&lt;/p&gt;&lt;p&gt;Zig resemblance to interpreted languages is quite striking, particularly with its concept of compile time execution, unfortunately not stressed enough in this article. This is an aspect of Zig that on one hand makes it particularly different and powerful but on the other hand difficult to grasp.&lt;/p&gt;&lt;p&gt;I concentrated more in instructing how to have a quick and easy start with the language, and in simple aspects that make Zig language cool, although there are many other aspects not mentioned here that are also quite impressive.&lt;/p&gt;&lt;p&gt;The examples shown here are simplified versions of a more involved program to solve Sudoku grids, which was also developed in Java and in C. The documentation in this repository explains in detail most of the structures and algorithms used to accomplish that.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45852328</guid><pubDate>Fri, 07 Nov 2025 23:04:39 +0000</pubDate></item><item><title>Study identifies weaknesses in how AI systems are evaluated</title><link>https://www.oii.ox.ac.uk/news-events/study-identifies-weaknesses-in-how-ai-systems-are-evaluated/</link><description>&lt;doc fingerprint="7dc8d0970fb3495b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;A new study led by the Oxford Internet Institute (OII) at the University of Oxford and involving a team of 42 researchers from leading global institutions including EPFL, Stanford University, the Technical University of Munich, UC Berkeley, the UK AI Security Institute, the Weizenbaum Institute, and Yale University, has found that many of the tests used to measure the capabilities and safety of large language models (LLMs) lack scientific rigour. &lt;/p&gt;
      &lt;p&gt;In Measuring What Matters: Construct Validity in Large Language Model Benchmarks, accepted for publication in the upcoming NeurIPS conference proceedings, researchers review 445 AI benchmarks – the standardised evaluations used to compare and rank AI systems. &lt;/p&gt;
      &lt;p&gt;The researchers found that many of these benchmarks are built on unclear definitions or weak analytical methods, making it difficult to draw reliable conclusions about AI progress, capabilities or safety. &lt;/p&gt;
      &lt;p&gt;“Benchmarks underpin nearly all claims about advances in AI,” says Andrew Bean, lead author of the study. “But without shared definitions and sound measurement, it becomes hard to know whether models are genuinely improving or just appearing to.” &lt;/p&gt;
      &lt;p&gt;Benchmarks play a central role in how AI systems are designed, deployed, and regulated. They guide research priorities, shape competition between models, and are increasingly referenced in policy and regulatory frameworks, including the EU AI Act, which calls for risk assessments based on “appropriate technical tools and benchmarks.” &lt;/p&gt;
      &lt;p&gt;The study warns that if benchmarks are not scientifically sound, they may give developers and regulators a misleading picture of how capable or safe AI systems really are. &lt;/p&gt;
      &lt;p&gt;“This work reflects the kind of large-scale collaboration the field needs,” adds Dr. Adam Mahdi. “By bringing together leading AI labs, we’re starting to tackle one of the most fundamental gaps in current AI evaluation.” &lt;/p&gt;
      &lt;p&gt;Key findings &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt; Lack of statistical rigour&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Only 16% of the reviewed studies used statistical methods when comparing model performance. This means that reported differences between systems or claims of superiority could be due to chance rather than genuine improvement. &lt;/p&gt;
      &lt;list start="2" rend="ol"&gt;
        &lt;item&gt; Vague or contested definitions&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Around half of the benchmarks aimed to measure abstract ideas such as reasoning or harmlessness without clearly defining what those terms mean. Without a shared understanding of these concepts, it is difficult to ensure that benchmarks are testing what they intend to.&lt;/p&gt;
      &lt;p&gt;Examples &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Confounding formatting rules – A test might ask a model to solve a simple logic puzzle but also require it to present the answer in a very specific, complicated format. If the model gets the puzzle right but fails the formatting, it looks worse than it really is. &lt;/item&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Brittle performance – A model might do well on short, primary school-style maths questions, but if you change the numbers or wording slightly, it suddenly fails. This shows it may be memorising patterns rather than truly understanding the problem&lt;/item&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Unsupported claims – If a model scores well on multiple-choice questions from medical exams, people might claim it has doctor-level expertise. But passing an exam is only one small part of what doctors do, so the result can be misleading.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Recommendations for better benchmarking &lt;/p&gt;
      &lt;p&gt;The authors stress that these problems are fixable. Drawing on established methods from fields such as psychometrics and medicine, they propose eight recommendations to improve the validity of AI benchmarks. These include: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Define and isolate: Provide a precise, operational definition for the concept being measured and control for unrelated factors. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;Build representative evaluations: Ensure test items represent real-world conditions and cover the full scope of the target skill or behaviour. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;Strengthen analysis and justification: Use statistical methods to report uncertainty and enable robust comparisons; conduct detailed error analysis to understand why a model fails; and justify why the benchmark is a valid measure for its intended purpose. &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The team also provides a Construct Validity Checklist, a practical tool researchers, developers, and regulators can use to assess whether an AI benchmark follows sound design principles before relying on its results. The checklist is available at https://oxrml.com/measuring-what-matters/ &lt;/p&gt;
      &lt;p&gt;The paper, Measuring What Matters: Construct Validity in Large Language Model Benchmarks, will be published as part of the NeurIPS 2025 peer-reviewed conference proceedings in San Diego from 2-7 December. The peer-reviewed paper is available on request. &lt;/p&gt;
      &lt;p&gt;Media spokespeople &lt;/p&gt;
      &lt;p&gt;Lead author: Andrew Bean, Doctoral Student, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Senior authors: Adam Mahdi, Associate Professor, and Luc Rocher, Associate Professor, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Contact &lt;/p&gt;
      &lt;p&gt;For more information and briefings, please contact: &lt;lb/&gt; Anthea Milnes, Head of Communications &lt;lb/&gt; Sara Spinks / Veena McCoole, Media and Communications Manager &lt;/p&gt;
      &lt;p&gt;T: +44 (0)1865 280527 &lt;/p&gt;
      &lt;p&gt;M: +44 (0)7551 345493 &lt;/p&gt;
      &lt;p&gt;E: press@oii.ox.ac.uk &lt;/p&gt;
      &lt;p&gt;About the Oxford Internet Institute (OII) &lt;/p&gt;
      &lt;p&gt;The Oxford Internet Institute (OII) has been at the forefront of exploring the human impact of emerging technologies for 25 years. As a multidisciplinary research and teaching department, we bring together scholars and students from diverse fields to examine the opportunities and challenges posed by transformative innovations such as artificial intelligence, large language models, machine learning, digital platforms, and autonomous agents. &lt;/p&gt;
      &lt;p&gt;About the University of Oxford &lt;/p&gt;
      &lt;p&gt;Oxford University was placed number one in the Times Higher Education World University Rankings for the tenth year running in 2025. At the heart of this success are the twin-pillars of our ground-breaking research and innovation and our distinctive educational offer. Oxford is world-famous for research and teaching excellence and home to some of the most talented people from across the globe. &lt;/p&gt;
      &lt;p&gt;Funding information &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;A.M.B. is supported in part by the Clarendon Scholarships and the Oxford Internet Institute’s Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;A.M. is supported by the Oxford Internet Institute’s Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;R.O.K. is supported by a Fellowship from the Cosmos Institute. H.M. is supported by ESRC [ES/P000649/1] and would like to acknowledge the London Initiative for Safe AI. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="4" data-aria-level="1"&gt;C.E. is supported by the EPSRC Centre for Doctoral Training in Health Data Science (EP/S02428X/1) and the AXA Research Fund. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="5" data-aria-level="1"&gt;F.L. is supported by Clarendon and Jason Hu studentships. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="6" data-aria-level="1"&gt;H.R.K.’s PhD is supported by the Economic and Social Research Council grant ES/P000649/1. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="7" data-aria-level="1"&gt;M.G. was supported by the SMARTY (PCI2024-153434) project funded by the Agencia Estatal de Investigación (doi:10.13039/501100011033) and by the European Commission through the Chips Act Joint Undertaking project SMARTY (Grant 101140087). This material is based in part upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-2139841. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="8" data-aria-level="1"&gt;O.D. is supported by the UKRI’s EPSRC AIMS CDT grant (EP/S024050/1). &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="9" data-aria-level="1"&gt;J.R is supported by the Engineering and Physical Sciences Research Council. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="10" data-aria-level="1"&gt;J.B. would like to acknowledge funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 16DII131. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="11" data-aria-level="1"&gt;A. Bibi would like to acknowledge the UK AISI systemic safety grant. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="12" data-aria-level="1"&gt;A. Bosselut gratefully acknowledges the support of the Swiss National Science Foundation (No. 215390), Innosuisse (PFFS-21-29), the EPFL Center for Imaging, Sony Group Corporation, and a Meta LLM Evaluation Research Grant. &lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45856804</guid><pubDate>Sat, 08 Nov 2025 14:18:22 +0000</pubDate></item><item><title>Opencloud – An alternative to Nextcloud written in Go</title><link>https://github.com/opencloud-eu/opencloud</link><description>&lt;doc fingerprint="ef05bc5f19e668bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;For general information about OpenCloud and how to install please visit OpenCloud on Github and OpenCloud GmbH.&lt;/p&gt;
    &lt;p&gt;This is the main repository of the OpenCloud server. It contains the golang codebase for the backend services.&lt;/p&gt;
    &lt;p&gt;The OpenCloud server is released under Apache 2.0. The project is thrilled to receive contributions in all forms. Start hacking now, there are many ways to get involved such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reporting issues or bugs&lt;/item&gt;
      &lt;item&gt;Requesting features&lt;/item&gt;
      &lt;item&gt;Writing documentation&lt;/item&gt;
      &lt;item&gt;Writing code or extend our tests&lt;/item&gt;
      &lt;item&gt;Reviewing code&lt;/item&gt;
      &lt;item&gt;Helping others in the community&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every contribution is meaningful and appreciated! Please refer to our Contribution Guidelines if you want to get started.&lt;/p&gt;
    &lt;p&gt;To build the backend, follow these instructions:&lt;/p&gt;
    &lt;p&gt;Generate the assets needed by e.g., the web UI and the builtin IDP&lt;/p&gt;
    &lt;code&gt;make generate&lt;/code&gt;
    &lt;p&gt;Then compile the &lt;code&gt;opencloud&lt;/code&gt; binary&lt;/p&gt;
    &lt;code&gt;make -C opencloud build&lt;/code&gt;
    &lt;p&gt;That will produce the binary &lt;code&gt;opencloud/bin/opencloud&lt;/code&gt;. It can be started as a local test instance right away with a two step command:&lt;/p&gt;
    &lt;code&gt;opencloud/bin/opencloud init &amp;amp;&amp;amp; opencloud/bin/opencloud server&lt;/code&gt;
    &lt;p&gt;This creates a server configuration (by default in &lt;code&gt;$HOME/.opencloud&lt;/code&gt;) and starts the server.&lt;/p&gt;
    &lt;p&gt;For more setup- and installation options consult the Development Documentation.&lt;/p&gt;
    &lt;p&gt;Important information for contributors about the technology in use.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend authenticates users via OpenID Connect using either an external IdP like Keycloak or the embedded LibreGraph Connect identity provider.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend does not use a database. It stores all data in the filesystem. By default, the root directory of the backend is &lt;code&gt;$HOME/.opencloud/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If you find a security-related issue, please contact security@opencloud.eu immediately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45857988</guid><pubDate>Sat, 08 Nov 2025 16:40:12 +0000</pubDate></item><item><title>Marko – A declarative, HTML‑based language</title><link>https://markojs.com/</link><description>&lt;doc fingerprint="a876cc8c70be3ce3"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Trusted&lt;/head&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;If you know HTML, CSS, and JavaScript, you know Marko&lt;/p&gt;&lt;p&gt;Streaming, resumable, optimizing compiler, and a tiny runtime&lt;/p&gt;&lt;p&gt;From simple HTML templates to powerful components as needed&lt;/p&gt;&lt;p&gt;Marko is HTML re‑imagined as a language for building dynamic and reactive user interfaces.&lt;/p&gt;&lt;p&gt;Just about any valid HTML is valid Marko, but Marko extends the HTML language to allow building modern applications in a declarative way.&lt;/p&gt;Check it out!&lt;p&gt;Marko streams content to your users as soon as it's ready. No waiting for client side JavaScript bundles or data requests to start rendering.&lt;/p&gt;&lt;p&gt;HTML, assets, and images are loaded as soon as possible with asynchronous content loading in as it completes.&lt;/p&gt;Learn How&lt;p&gt;Browsers and servers are built differently, shouldn't your code be too? Marko compiles your templates to perform their best with optimized, environment-specific output.&lt;/p&gt;&lt;p&gt;Faster loads. Smaller bundles. One seamless language.&lt;/p&gt;Learn How&lt;p&gt;Marko has built-in TypeScript support , with strong type inference that works across templates and components. Editors get full language features like autocompletion, jump-to-definition, syntax highlighting, and clean formatting.&lt;/p&gt;&lt;p&gt;Build confidently. Catch errors early. Write better code, faster.&lt;/p&gt;Explore&lt;p&gt;Need help? Want to Contribute?&lt;/p&gt;&lt;p&gt;Get involved in the Marko Community!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45858905</guid><pubDate>Sat, 08 Nov 2025 18:43:55 +0000</pubDate></item><item><title>Avería: The Average Font (2011)</title><link>http://iotic.com/averia/</link><description>&lt;doc fingerprint="367d013713a223d1"&gt;
  &lt;main&gt;
    &lt;p&gt;am not a type designer. This is the story of the creation of a new font, Avería: the average of all the fonts on my computer. The field of typography has long fascinated me, and I love playing with creative programming ideas, so it was perhaps inevitable that the idea came to me one day of “generative typography”. A Google on the subject brought up little, and I put the idea to the back of my mind until it occurred to me that perhaps the process of averaging, or interpolating, existing fonts might bring up interesting results. Luckily at this point I didn't do any more web searching – instead I grabbed my laptop and came up with an initial idea for finding what the average of all my fonts might look like – by overlaying each letter at low opacity. The results can be seen in the below image.&lt;/p&gt;
    &lt;p&gt;This was done by printing each letter of each font, at the same point size, to lots of separate images, and then averaging them – using ImageMagick and PHP. The letters were aligned to the same centre point. I later realised that each font has a ‘baseline’ defined, and an origin on that baseline which each glyph is drawn relative to. The same process, repeated with equal origins, gives slightly different results (see below) – here you can see the baseline is very well-defined, with the glyphs becoming more blurred towards the top right of each.&lt;/p&gt;
    &lt;p&gt;I was quite pleased with the results. It was only later that I discovered this had already been done – though it appeared that my end results (whilst not as beautifully animated) had a little more clarity, so I'm glad I tried for myself. But this didn't seem like the end of the journey. Whilst this was an interesting experiment, and showed an lot of correlation between a sample of common fonts (as well as a couple of oddities – notably the lower case ‘g’ which clearly exists in two distinct common forms), what I really wanted was an average which somehow preserved the well-defined edges of existing fonts. So I started considering ways to produce a smoother, sharper average of letter forms.&lt;/p&gt;
    &lt;p&gt;One idea which seemed obvious was to simply take the blurry results of the first experiment, and use a threshold to create monochrome images. A few experiments in this direction (I first tried with a lower-case ‘f’, which I later found was never likely to give good results due to the variance in height of the middle cross-stroke) convinced me that I needed to look into cleverer ways to achieve this. Surely there must be a simple way to average shapes, while keeping the result as a shape?&lt;/p&gt;
    &lt;p&gt;It turns out not to be straightforward. There are many possible ways to ‘morph’ between two shapes – and what might seem the most natural generally depends on our perception of ‘features’ in the shapes. Consider the average of a capital I with serifs, and one without: the natural thing to do would be something like, make the serifs half as big, and use a horizontal stem width about half-way between the two glyphs. That's two feature concepts being applied to the abstract forms¹. To take a simpler example, what is the average of a square with the same square rotated 45˚? There are a few possibilities …&lt;/p&gt;
    &lt;p&gt;So, this stumped me for a while. I decided I needed to get to know fonts better, so I built a simple web app to view the lines, curves and control points present in the fonts I had. On this basis, I started to consider the ways the features (vertices, curves, stems, serifs etc) might be matched up between fonts. However, this was a rabbit hole I might never get to the bottom of - particularly when considering some of the more unusual varieties of font. Perhaps there was a simpler idea that was evading me.&lt;/p&gt;
    &lt;p&gt;Then it occurred to me: since my aim was to average a large number of fonts, perhaps it would be best to use a very simple process, and hope the results averaged out well over a large number of fonts. So, how about splitting each letter perimeter into lots of (say, 500) equally-spaced points, and just average between the corresponding positions of each, on each letter? It would be necessary to match up the points so they were about the same location in each letter, and then the process would be fairly simple².&lt;/p&gt;
    &lt;p&gt;Having found a simple process to use, I was ready to start. And after about a month of part-time slaving away (sheer fun! Better than any computer game) – in the process of which I learned lots about bezier curves and font metrics – I had a result. I call it Avería – which is a Spanish word related to the root of the word ‘average’. It actually means mechanical breakdown or damage. This seemed curiously fitting, and I was assured by a Spanish friend-of-a-friend that “Avería is an incredibly beautiful word regardless of its meaning”. So that's nice.&lt;/p&gt;
    &lt;p&gt;Along the way I naturally called on the counsel of the best designers I know – my brother Nick Sayers, Lloyd Thomas, Tom Muller and Chris McGrail, for advice. In the end, I decided to release the font using the SIL Open Font License – which means anyone can use it pretty much however they like – and to include within the family Regular, Bold and Light variants with Italics. Each is made from the corresponding subsets of the fonts on my machine. Also included is a “Gruesa” version made from all my fonts (725 in total).&lt;lb/&gt; Avería Family (ZIP, 369kB) [Updated 9 Nov 2011]&lt;lb/&gt; Avería at The Open Font Library&lt;lb/&gt; *NEW* by popular demand:&lt;lb/&gt; Avería Serif Family (ZIP, 323kB) OFLB&lt;lb/&gt; Avería Sans Family (ZIP, 320kB) OFLB&lt;lb/&gt; *NEW* Avería, Serif and Sans packaged as TTC TrueType collections (so you can install each family in one go, rather than one variant at a time). Thanks Ludwig:&lt;lb/&gt; Avería TTC Files (ZIP, 946kB)&lt;lb/&gt; *NEW* versions of Avería, based on OFL fonts from the Google Web Fonts directory - now available through GWF as Avería Libre:&lt;lb/&gt; Avería GWF Family (ZIP, 488kB)&lt;lb/&gt; Avería Serif GWF Family (ZIP, 432kB)&lt;lb/&gt; Avería Sans GWF Family (ZIP, 426kB)&lt;lb/&gt; Preview all&lt;lb/&gt; Feel free to email me if you have any questions – or use the comments box below.&lt;lb/&gt; N.B. I've had a number of emails from people asking if they can use Avería in various commercial / non-commercial projects. I'd love to hear if you do something with these fonts – but there's no need to ask permission. You are absolutely free to use them however you like. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45859243</guid><pubDate>Sat, 08 Nov 2025 19:29:44 +0000</pubDate></item><item><title>Largest cargo sailboat completes first Atlantic crossing</title><link>https://www.marineinsight.com/shipping-news/worlds-largest-cargo-sailboat-completes-historic-first-atlantic-crossing/</link><description>&lt;doc fingerprint="df5cacd41833d6da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;World’s Largest Cargo Sailboat Completes Historic First Atlantic Crossing&lt;/head&gt;
    &lt;p&gt;The world’s largest cargo sailboat, Neoliner Origin, completed its first transatlantic voyage on 30 October despite damage to one of its sails during the journey.&lt;/p&gt;
    &lt;p&gt;The 136-metre-long vessel had to rely partly on its auxiliary motor and its remaining sail after the aft sail was damaged in a storm shortly after departure.&lt;/p&gt;
    &lt;p&gt;The French-built roll-on/roll-off (RoRo) cargo ship, which has two semi-rigid sails, first stopped at Saint Pierre and Miquelon, a French overseas territory near Canada, before continuing its journey to Baltimore in the United States.&lt;/p&gt;
    &lt;p&gt;Neoline, the company behind the project, said the damage reduced the vessel’s ability to perform fully on wind power. The company’s CEO, Jean Zanuttini, said the crossing was a valuable experience in handling large sail surfaces across the North Atlantic, especially during late-season storms. He added that despite the difficulties, the ship showed strong resilience by reaching its destination with only a short delay in Saint Pierre.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is designed to reduce greenhouse gas emissions by 80 to 90 per cent compared to conventional diesel-powered cargo ships. According to the United Nations Conference on Trade and Development (UNCTAD), global shipping produces about 3 per cent of worldwide greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Zanuttini said the company aims to balance industrial needs with environmental responsibility. He added that wind propulsion offers an advantage because it is a free, widely available, and predictable energy source that does not harm ecosystems.&lt;/p&gt;
    &lt;p&gt;The UK’s National Clean Maritime Research Hub has reported that wind propulsion systems like those on the Neoliner Origin can cut emissions by over 50 per cent on new vessels optimised for wind conditions. Retrofitted vessels can also achieve reductions of 5 to 20 per cent, and up to 30 per cent when adjusted for wind conditions.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin was designed by the French naval engineering firm Mauric. The company’s CEO, Vincent Seguin, said the goal was to develop a ship that relies primarily on wind propulsion while ensuring consistent delivery schedules and efficient operation with a smaller crew.&lt;/p&gt;
    &lt;p&gt;Inspired by historic sailing vessels, the Neoliner Origin integrates modern systems such as advanced navigation, anti-drift mechanisms, and automated sail management to comply with current safety and operational standards.&lt;/p&gt;
    &lt;p&gt;The ship can carry up to 5,300 tonnes of cargo, including containers, vehicles, machinery, and specialised goods. It arrived in Baltimore carrying Renault vehicles, French liqueurs, machinery, and other products.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is scheduled to make monthly voyages between Europe and North America, maintaining a commercial cruising speed of around 11 knots.&lt;/p&gt;
    &lt;p&gt;Reference: Reuters&lt;/p&gt;
    &lt;head rend="h4"&gt;⚓️ Enhance Your Knowledge. Prevent Accidents. Stay Safe at Sea.&lt;/head&gt;
    &lt;p&gt;1. eBooks for Engine Department&lt;/p&gt;
    &lt;p&gt;Master machinery operations, troubleshooting, and safety procedures with expertly written guides tailored for marine engineers. Prevent costly breakdowns and onboard accidents through practical knowledge.&lt;/p&gt;
    &lt;p&gt;👉 Explore Engine Department eBooks&lt;/p&gt;
    &lt;p&gt;2. eBooks for Deck Department&lt;/p&gt;
    &lt;p&gt;Sharpen your seamanship, navigation, and cargo-handling skills with real-world case studies and practical insights designed for deck officers and cadets.&lt;/p&gt;
    &lt;p&gt;👉Discover Deck Department eBooks&lt;/p&gt;
    &lt;p&gt;3. eBooks on Electrical Fundamentals &amp;amp; Issues&lt;/p&gt;
    &lt;p&gt;Understand marine electrical systems, identify potential faults, and prevent onboard electrical failures with step-by-step explanations from industry experts.&lt;/p&gt;
    &lt;p&gt;4. Pocket Guides for Quick Reference&lt;/p&gt;
    &lt;p&gt;Compact, handy, and loaded with essential checklists—perfect for on-the-go reference during operations and emergencies at sea.&lt;/p&gt;
    &lt;p&gt;5. Combo Packs to Save Big&lt;/p&gt;
    &lt;p&gt;Access multiple expert eBooks at discounted prices. Ideal for professionals seeking complete safety and operational knowledge across various ship departments.&lt;/p&gt;
    &lt;p&gt;6. Digital Maritime Courses – Learn at Your Own Pace&lt;/p&gt;
    &lt;p&gt;Upgrade your competence with Marine Insight Academy’s online courses. Learn from industry professionals anytime, anywhere, and become a safer, smarter seafarer.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Subscribe To Our Daily Newsletter&lt;/head&gt;
    &lt;p&gt;By subscribing, you agree to our Privacy Policy and may receive occasional deal communications; you can unsubscribe anytime.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45859471</guid><pubDate>Sat, 08 Nov 2025 19:57:52 +0000</pubDate></item><item><title>Ironclad – formally verified, real-time capable, Unix-like OS kernel</title><link>https://ironclad-os.org/</link><description>&lt;doc fingerprint="6f56f93a45a93f90"&gt;
  &lt;main&gt;
    &lt;p&gt;Ironclad is a formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software.&lt;/p&gt;
    &lt;p&gt;Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling.&lt;/p&gt;
    &lt;p&gt;Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source.&lt;/p&gt;
    &lt;p&gt;SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of huge swathes of Ironclad, like cryptography, MAC, and user-facing facilities.&lt;/p&gt;
    &lt;p&gt;Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.&lt;/p&gt;
    &lt;p&gt;Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more.&lt;/p&gt;
    &lt;p&gt;This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page.&lt;/p&gt;
    &lt;p&gt;Additionally, we would like to thank the following organizations:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45860843</guid><pubDate>Sat, 08 Nov 2025 23:03:10 +0000</pubDate></item><item><title>IRIX Introduction</title><link>http://www.sgistuff.net/software/irixintro/index.html</link><description>&lt;doc fingerprint="bd3c131148cca9cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;IRIX Introduction&lt;/head&gt;
    &lt;head rend="h2"&gt;Brief History&lt;/head&gt;
    &lt;p&gt;The first operating system developed for SGI systems ran on the IRIS line of terminals and workstations based on Motorola CPUs (see GL2 history). When the MIPS based IRIS 4D systems were introduced the 4D1 operating system accompanied these computers.&lt;/p&gt;
    &lt;p&gt;The earliest common version is 4D1-3.0 (1988). IRIX 3.x was based on UNIX System V Release 3 with 4.3BSD enhancements, and incorporated the 4Sight windowing system, based on NeWS and IRIS GL.&lt;/p&gt;
    &lt;p&gt;The next major version (4D1-4.0) was introduced in 1991. SGI replaced 4Sight with the X Window System (X11R4), using Xsgi and the 4Dwm window manager providing a similar look and feel to 4Sight.&lt;/p&gt;
    &lt;p&gt;When the next version was introduced, the name IRIX was more widely used. IRIX 5.0, released in 1993, incorporated certain features of UNIX System V Release 4, including ELF-format executables. Later on in the IRIX 5 lifecycle the XFS journaling file system was introduced.&lt;/p&gt;
    &lt;p&gt;Beginning with IRIX 6.0, released in 1994 during the IRIX 5 era, full 64-bit support was added. After a few platform specific releases with IRIX 6.5 the last "major" all platform release was introduced.&lt;/p&gt;
    &lt;p&gt;The last IRIX release is IRIX 6.5.30, introduced in August 2006. The IRIX product line was discontinued after this version, according to the press release dated September, 6th 2006 support for IRIX will continue at least until December 2013.&lt;/p&gt;
    &lt;head rend="h2"&gt;Main Versions&lt;/head&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;To decide which IRIX version is suitable for a system it is important to know specific information about the computer itself:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Which system family is it (O2, Indy, Origin 2000, ...)?&lt;/item&gt;
      &lt;item&gt;Which processor is installed?&lt;/item&gt;
      &lt;item&gt;Which graphics hardware is in it (if any)?&lt;/item&gt;
      &lt;item&gt;Are there options that require specific drivers?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Another thing to note is that there are platform specific releases, that were made when some new hardware was introduced. These usually don't support all hardware that was available at the time.&lt;/p&gt;
    &lt;p&gt;This chapter will go on with an introduction to most important all platform IRIX releases. It will conclude with a paragraph containing some considerations and recommendations for the choice of ann appropriate IRIX version.&lt;/p&gt;
    &lt;head rend="h3"&gt;Major Versions&lt;/head&gt;
    &lt;p&gt;Of all IRIX releases the following are the most important:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;IRIX 5.3&lt;/item&gt;
      &lt;item rend="dd-1"&gt;IRIX 5.3 was the last IRIX version to include support for systems with R3000 CPU. So this is the most recent operating system that can be installed on 4D era systems (Personal Iris, PowerSeries and so on).&lt;/item&gt;
      &lt;item rend="dt-2"&gt;IRIX 6.2&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Of the 6.x releases IRIX 6.2 was the first release that did support all current hardware of it's time. Although all of this hardware (except the Crimson) is still supported in the current 6.5 releases IRIX 6.2 can still be a reasonable choice for lowend configurations of Indigo, Indigo 2 or Indy (pre 1996).&lt;/item&gt;
      &lt;item rend="dt-3"&gt;IRIX 6.5.22&lt;/item&gt;
      &lt;item rend="dd-3"&gt;This version is the last to support many of the popular Silicon Graphics classics like the Indigo 2 or Indy which are equipped with R4x00 microprocessors..&lt;/item&gt;
      &lt;item rend="dt-4"&gt;IRIX 6.5.30&lt;/item&gt;
      &lt;item rend="dd-4"&gt;IRIX 6.5.30 is the final IRIX release and is suitable for any of the last Silicon Graphics systems that were equipped with MIPS microprocessors (O2, Octane, Fuel, etc.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operating System Considerations and Recommendations&lt;/head&gt;
    &lt;p&gt;The following list starts with current systems and goes back to the early IRIS 4D days (for hardware information go to the systems page. In a similar fashion for all the listed systems the most recent operating system will be named, followed by exceptions that make it neccessary to choose an older version.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;O2, O2+, Octane, Octane 2,Fuel&lt;/item&gt;
      &lt;item rend="dd-1"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Origin 200, Origin 2000, Onyx 2, Origin 300, Onyx 300,Origin 3000, Onyx 3000&lt;/item&gt;
      &lt;item rend="dd-2"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Indigo 2, Challenge M&lt;/item&gt;
      &lt;item rend="dd-3"&gt;All Indigo 2 / Challenge M can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000/100: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Indy, Challenge S&lt;/item&gt;
      &lt;item rend="dd-4"&gt;All Indy / Challenge S can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000PC, R4600PC: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt;Challenge, Onyx&lt;/item&gt;
      &lt;item rend="dd-5"&gt;All of these systems can run IRIX 6.5 up to 6.5.22.&lt;/item&gt;
      &lt;item rend="dt-6"&gt;Indigo&lt;/item&gt;
      &lt;item rend="dd-6"&gt;Indigo with R4x00 CPUs can run IRIX 6.5 up to 6.5.22.&lt;lb/&gt;Indigo with R3x00 CPUs are limited to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-7"&gt;Crimson&lt;/item&gt;
      &lt;item rend="dd-7"&gt;All Crimson systems can run up to IRIX 6.2, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;GTX graphics: IRIX 5.3 (last version to support GTX)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-8"&gt;PowerSeries&lt;/item&gt;
      &lt;item rend="dd-8"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-9"&gt;Personal Iris&lt;/item&gt;
      &lt;item rend="dd-9"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-10"&gt;Professional Iris&lt;/item&gt;
      &lt;item rend="dd-10"&gt;All of these systems can run up to IRIX 5.3, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;G graphics: IRIX 4.0.5 (last version to support G graphics)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Pictures&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX Media / Media Kits&lt;/head&gt;
    &lt;head rend="h3"&gt;Developer Toolbox&lt;/head&gt;
    &lt;head rend="h3"&gt;Support Advantage&lt;/head&gt;
    &lt;head rend="h3"&gt;Indyzone&lt;/head&gt;
    &lt;head rend="h3"&gt;Other&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 3.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 4.0.1 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 5.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 6.5 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;Cyclone Software&lt;/head&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;head rend="h3"&gt;Technical Reports and White Papers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IRIX 6.1 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;IRIX 6.2 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;Cellular IRIX 6.4 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;XFS White Paper [local copy]&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862071</guid><pubDate>Sun, 09 Nov 2025 01:33:43 +0000</pubDate></item><item><title>Tabloid: The Clickbait Headline Programming Language</title><link>https://tabloid.vercel.app/</link><description>&lt;doc fingerprint="5205455d1cce1ea4"&gt;
  &lt;main&gt;
    &lt;p&gt;Oops, please turn on JavaScript to enjoy Tabloid :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862470</guid><pubDate>Sun, 09 Nov 2025 02:53:45 +0000</pubDate></item><item><title>Show HN: Geofenced chat communities anyone can create</title><link>https://vicinity.social/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862500</guid><pubDate>Sun, 09 Nov 2025 02:59:58 +0000</pubDate></item><item><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><link>https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/</link><description>&lt;doc fingerprint="bc2fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It’s currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let’s draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don’t intend for people to access this model directly just yet. It’s available exclusively through Codex CLI which is a privileged application—it gets to access a special backend API endpoint that’s not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user’s existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn’t resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don’t know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this—in figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called “codex prompt”&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here”—this runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; “prompt goes here”—same again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here” -s/--system “system prompt goes here”—runs with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models—this lists all available models that can be used with the “codex prompt” command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I’ve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
└ ✔ Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ✔ Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ✔ Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to.&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn’t quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
I�m ready to help�what would you like me to do next?I�m ready to help�what would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn’t what I want—it appeared to be running in Codex’s normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work—here is what happened—note that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)—and then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ’codex prompt’ command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox—it should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI’s custom backend API for Codex doesn’t like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ’Generate an SVG of a pelican riding a bicycle’&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (“don’t run tools”), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we’re ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven’t written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I’ve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let’s draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here’s the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don’t think I’ll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI’s private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work—but it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862802</guid><pubDate>Sun, 09 Nov 2025 04:02:47 +0000</pubDate></item><item><title>Grok 4 Fast now has 2M context window</title><link>https://docs.x.ai/docs/models</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862833</guid><pubDate>Sun, 09 Nov 2025 04:10:06 +0000</pubDate></item><item><title>Forth – is it still relevant?</title><link>https://github.com/chochain/eforth</link><description>&lt;doc fingerprint="be229b0a630aca40"&gt;
  &lt;main&gt;
    &lt;p&gt;With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: due to C's broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing.&lt;/p&gt;
    &lt;p&gt;So, the question is, how to encourage today's world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won't get us anywhere.&lt;/p&gt;
    &lt;p&gt;Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth genesis and overview. I like the idea and decided to pick it up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;100% C/C++ with multi-platform support. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary is just an array. It's remodeled from linear memory linked-list to an array (or a vector in C++'s term) of words.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.&lt;/item&gt;
          &lt;item&gt;To execute become just a walk of the word pointers in the array. This is our inner interpreter.&lt;/item&gt;
          &lt;item&gt;Hashtables might go even faster but we'll try that later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data and Return Stacks are also arrays. With push, pop and [] methods to clarify intentions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Parameter fields are all arrays. Why not!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No vocabulary, or meta-compilation. Except CREATE..DOES&amp;gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-threading and message passing are available From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A thread pool is built-in. Size is defaults to number of cores.&lt;/item&gt;
          &lt;item&gt;Message Passing send/recv with pthread mutex waiting.&lt;/item&gt;
          &lt;item&gt;IO and memory update can be synchronized with lock/unlock.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download release v4.2 and work from there.&lt;/p&gt;
    &lt;p&gt;In the release, a heavily commented ceforth.cpp, the companion ceforth.h, and a config.h. Altogether, about 800 lines. Check them out!&lt;/p&gt;
    &lt;p&gt;The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Code - the heart of eForth, depends on the constructor called, the following fields are populated accordingly&lt;/p&gt;
        &lt;quote&gt;+ name - a string that holds primitive word's name, i.e. NFA in classic FORTH, can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory + xt - pointer to a lambda function for primitive words i.e. XT in classic FORTH + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH + q - holds the literal value which classic FORTH keep on parameter memory&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lit, Var, Str, Bran, Tmp - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.&lt;/p&gt;
        &lt;quote&gt;+ Lit - numeric literals + Var - variable or constant + Str - string for dostr or dotstr + Bran - Branching opcode + Tmp - temp storage for branching word&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary - an array of Code objects&lt;/p&gt;
        &lt;quote&gt;+ build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt dict[0].xt ------&amp;gt; lambda[0] &amp;lt;== These function pointers can be converted dict[1].xt ------&amp;gt; lambda[1] into indices to a jump table ... which is exactly what WASM does dict[N-1].xt ----&amp;gt; lambda[N-1] &amp;lt;== N is number of built-in words + colon (user defined) words - collection of word pointers during compile time dict[N].pf = [ *Code, *Code, ... ] &amp;lt;== These are called the 'threads' in Forth's term dict[N+1].pf = [ *Code, *Code, ... ] So, instead of subroutine threading ... this is 'object' threading. dict[-1].pf = [ *Code, *Code, ... ] It can be further compacted into token (i.e. dict index) threading if desired&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inner Interpreter - Code.exec() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;if (xt) { xt(this); return; } // run primitive word for (Code *w : pf) { // run colon word try { w-&amp;gt;exec(); } // execute recursively catch (...) { break; } // handle exception if any }&lt;/quote&gt;
        &lt;p&gt;i.e. either we call a built-in word's lambda function or walk the Code.pf array recursively like a depth-first tree search.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Outer Interpreter - forth_core() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;Code *c = find(idiom); // search dictionary if (c) { // word found? if (compile &amp;amp;&amp;amp; !c-&amp;gt;immd) // are we compiling a new word? dict[-1]-&amp;gt;add(c); // then append found code to it else c-&amp;gt;exec(); // or, execute the code return; } DU n = parse_number(idiom); // word not found, try as a number if (compile) // are we compiling a new word? dict[-1]-&amp;gt;add(new Lit(n)); // append numeric literal to it else PUSH(n); // push onto data stack&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the array implementation, the first difference is in array variable read/write.&lt;/p&gt;
    &lt;code&gt;&amp;gt; create narr 10 cells allot
&amp;gt; see narr
&amp;gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +&lt;/code&gt;
    &lt;p&gt;While traditional Forths uses &lt;code&gt;narr 2 cells +&lt;/code&gt; to get the memory address of &lt;code&gt;narr[2]&lt;/code&gt;, eforth &lt;code&gt;narr&lt;/code&gt; returns its index (or defining order) in the dictionary. So, &lt;code&gt;narr 2 cells +&lt;/code&gt; will actually get you the index of the second word defined after &lt;code&gt;narr&lt;/code&gt;. You'll be storing the value into that word's empty qf field.
To access the nth element of &lt;code&gt;narr&lt;/code&gt;, use &lt;code&gt;th&lt;/code&gt; instead&lt;/p&gt;
    &lt;code&gt;&amp;gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&amp;gt; fill-arr
&amp;gt; see narr
&amp;gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;&lt;/code&gt;
    &lt;p&gt;With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the "scary" features for Forths to come.&lt;/p&gt;
    &lt;p&gt;Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See here for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.&lt;/p&gt;
    &lt;p&gt;Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight Forth without Forth.&lt;/p&gt;
    &lt;p&gt;In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see ceForth_403 and eJsv32 for details.&lt;/p&gt;
    &lt;p&gt;We hope it can serve as a stepping stone for learning Forth to even building their own, one day.&lt;/p&gt;
    &lt;code&gt;    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth&lt;/code&gt;
    &lt;p&gt;There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.&lt;/p&gt;
    &lt;p&gt;Checkout the version you are interested in.&lt;/p&gt;
    &lt;code&gt;    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on&lt;/code&gt;
    &lt;p&gt;To enable multi-threading, of v5, update the followings in ~/src/config.h&lt;/p&gt;
    &lt;code&gt;    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8&lt;/code&gt;
    &lt;code&gt;    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Once you get pass the above, try the lessons by Dr. Ting.
&lt;/code&gt;
    &lt;code&gt;    $ ./tests/eforth &amp;lt; ./tests/demo.fs&lt;/code&gt;
    &lt;p&gt;Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.&lt;/p&gt;
    &lt;p&gt;Note: MacOS added, thanks to Kristopher Johnson's work.&lt;/p&gt;
    &lt;p&gt;I haven't develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I'm hoping someone can make it more streamlined.&lt;/p&gt;
    &lt;code&gt;* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&amp;gt; Build -&amp;gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
&lt;/code&gt;
    &lt;code&gt;* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
&lt;/code&gt;
    &lt;code&gt;    $ make wasm
    $ python3 tests/cors.py        # supports COOP&lt;/code&gt;
    &lt;code&gt;* from your browser, open http://localhost:8000/tests/eforth.html
&lt;/code&gt;
    &lt;p&gt;Note: For multi-threading to work, browser needs to receive Cross-Origin policies here for detail in the response header. A Python script ~/tests/cors.py is provided to solve the issue. The same needed to be provided if you use other web server.&lt;/p&gt;
    &lt;code&gt;* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to 'Both NL &amp;amp; CR'
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
&lt;/code&gt;
    &lt;p&gt;Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.&lt;/p&gt;
    &lt;p&gt;Forth has been supporting multi-tasking since the 70's. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.&lt;/p&gt;
    &lt;code&gt;* each VM has it's own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
&lt;/code&gt;
    &lt;code&gt;1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in "ready to run" tasks.
4. Lastly, event_loop picks up "ready to run" tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
&lt;/code&gt;
    &lt;p&gt;Before we go too far, make sure the following are updated before your build&lt;/p&gt;
    &lt;code&gt;* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;word&lt;/cell&gt;
        &lt;cell role="head"&gt;stack&lt;/cell&gt;
        &lt;cell role="head"&gt;desc&lt;/cell&gt;
        &lt;cell role="head"&gt;state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;task&lt;/cell&gt;
        &lt;cell&gt;( xt -- t )&lt;/cell&gt;
        &lt;cell&gt;create a task (tid is index to thread pool entry)&lt;p&gt;a free VM from pool is chosen for the task&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;STOP=&amp;gt;HOLD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;rank&lt;/cell&gt;
        &lt;cell&gt;( -- t )&lt;/cell&gt;
        &lt;cell&gt;fetch current task id&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;start&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;start a task&lt;p&gt;The VM is added to event_queue and kick started when picked up by event_loop&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;join&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;wait until the given task is completed&lt;/cell&gt;
        &lt;cell&gt;NEST=&amp;gt;STOP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;lock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;lock (semaphore) IO or memory&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;unlock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;release IO or memory lock&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;send&lt;/cell&gt;
        &lt;cell&gt;( v1 v2 .. vn n t -- )&lt;/cell&gt;
        &lt;cell&gt;send n elements on current stack to designated task's stack (use stack as message queue)&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receiver HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;recv&lt;/cell&gt;
        &lt;cell&gt;( -- v1 v2 .. vn )&lt;/cell&gt;
        &lt;cell&gt;wait, until message to arrive&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;pull&lt;/cell&gt;
        &lt;cell&gt;( n t -- )&lt;/cell&gt;
        &lt;cell&gt;forced fetch stack elements from a completed task&lt;/cell&gt;
        &lt;cell&gt;current NEST&lt;p&gt;target STOP&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;bcast&lt;/cell&gt;
        &lt;cell&gt;( n -- )&lt;/cell&gt;
        &lt;cell&gt;not implemented yet, TODO&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receivers HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;clock&lt;/cell&gt;
        &lt;cell&gt;( -- n )&lt;/cell&gt;
        &lt;cell&gt;fetch microsecond since Epoch, useful for timing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;    &amp;gt; : once 999999 for rank drop next ;            \ 1M cycles
    &amp;gt; : run clock negate once clock + . ." ms" cr ; \ benchmark
    &amp;gt; ' run constant xt                             \ keep the xt
    &amp;gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &amp;gt; 4 jobs&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T2 [05.1]&amp;gt;&amp;gt; started on T4 [04.1]&amp;gt;&amp;gt; started on T6 [07.1]&amp;gt;&amp;gt; started on T0 18 ms [06.3]&amp;gt;&amp;gt; finished on T2 18 ms [05.3]&amp;gt;&amp;gt; finished on T4 18 ms [04.3]&amp;gt;&amp;gt; finished on T6 18 ms [07.3]&amp;gt;&amp;gt; finished on T0&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; 0 constant pp                           \ producer task id
    &amp;gt; 0 constant cc                           \ consumer task id
    &amp;gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock ." sent " cr unlock ;            \ locked IO before write
    &amp;gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock ." sum=" . cr unlock ;           \ locked IO before write
    &amp;gt; ' sndr task to pp
    &amp;gt; ' rcvr task to cc
    &amp;gt; cc start                                \ start receiver task
    &amp;gt; pp start                                \ start sender task
    &amp;gt; pp join cc join                         \ wait for completion&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T1 [06.1]&amp;gt;&amp;gt; waiting [07.1]&amp;gt;&amp;gt; started on T2 [06.1]&amp;gt;&amp;gt; sending 4 items to VM6.1 sent [07.3]&amp;gt;&amp;gt; finished on T2 [00.3]&amp;gt;&amp;gt; VM7 joint [06.3]&amp;gt;&amp;gt; received =&amp;gt; state=3 sum=10 [06.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM6 joint&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &amp;gt; ' sum task constant tt                  \ create the task
    &amp;gt; tt start tt join                        \ run and wait for completion
    &amp;gt; 1 tt pull ." total=" .                  \ pull the sum&lt;/code&gt;
    &lt;quote&gt;[00.3]&amp;gt;&amp;gt; joining VM7 [07.1]&amp;gt;&amp;gt; started on T1 [07.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM7 joint pulled 1 items from VM7.0 total= 1784293664 -1 -&amp;gt; ok&lt;/quote&gt;
    &lt;code&gt;+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
&lt;/code&gt;
    &lt;code&gt;+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
&lt;/code&gt;
    &lt;code&gt;+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&amp;gt; not much overhead with MT
&lt;/code&gt;
    &lt;code&gt;+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &amp;gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &amp;lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn't seem to bother WASM.
&lt;/code&gt;
    &lt;code&gt;+ 1440ms: Dr. Ting's ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
&lt;/code&gt;
    &lt;p&gt;What is the performance difference?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Code *dict[] - where words are dynamically allocated as a collection of pointers, or&lt;/item&gt;
      &lt;item&gt;Code dict[] - where words are statically created as an array of objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have created a git branch 'static' to compare to the 'master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn't been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.&lt;/p&gt;
    &lt;p&gt;An array of lambdas vs the classic switch statement, i.e.&lt;/p&gt;
    &lt;code&gt;const Code dict[] {               ///&amp;lt; Forth dictionary
    CODE("+",      TOS += SS.pop()),
    CODE("-",      TOS =  SS.pop() - TOS),
    CODE("*",      TOS *= SS.pop()),
    CODE("/",      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&amp;lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
&lt;/code&gt;
    &lt;p&gt;Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops. However, with the advance of compilers,&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync&lt;/item&gt;
      &lt;item&gt;It is possible to prebuild lambda array as a ROM image or static library that can be transported.&lt;/item&gt;
      &lt;item&gt;A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.&lt;/p&gt;
    &lt;code&gt;+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
&lt;/code&gt;
    &lt;p&gt;The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes here. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.&lt;/p&gt;
    &lt;p&gt;I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.&lt;/p&gt;
    &lt;p&gt;Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch one_pf doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?&lt;/p&gt;
    &lt;code&gt;+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
&lt;/code&gt;
    &lt;p&gt;So, what cachegrind said for 100M loop tight loops and chacha.fs a CPU intensive?&lt;/p&gt;
    &lt;code&gt;| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
&lt;/code&gt;
    &lt;p&gt;Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. _if/_else/_then, for/next, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn't be so dramatic especially with the recursive nest(). More research on this...&lt;/p&gt;
    &lt;p&gt;Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth's model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).&lt;/p&gt;
    &lt;p&gt;It works better with WASM's memory model. It is used as the foundation for weForth. So far, it is stable but tweaked from time to time and&lt;/p&gt;
    &lt;code&gt;&amp;gt; make 50x
&amp;gt; ./tests/eforth50x
&lt;/code&gt;
    &lt;p&gt;Hinted by Sean Pringle's Rethinking Forth and Travis Bemann's wornderful zeptoforth. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX&lt;/p&gt;
    &lt;code&gt;+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Dr. Ting's work on eForth between 1995~2011 eForth references and their Source Code Repo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210314: Initial&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210707: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210816: Code Merge&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20220512: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Though the goal of Dr. Ting's is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&amp;gt;dict, dict-&amp;gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!&lt;/item&gt;
          &lt;item&gt;Refactor to subroutine indirect threading. It's not portable but does speed up 25% (see benchmark above).&lt;/item&gt;
          &lt;item&gt;Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.&lt;/item&gt;
          &lt;item&gt;Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20221118: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt "function pointer" in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20231011: Review&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.&lt;/item&gt;
          &lt;item&gt;LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20240308: Refactor for multi-platform, accept dynamic vectors&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experiment various threading and memory pointer models, archive into ~/orig/40x&lt;/item&gt;
          &lt;item&gt;To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done &lt;list rend="ul"&gt;&lt;item&gt;Separate cross-platform and configuration into ~/src/config.h&lt;/item&gt;&lt;item&gt;Separate platform specific code into ~/platform&lt;/item&gt;&lt;item&gt;add included opcode for Forth script loading&lt;/item&gt;&lt;item&gt;rename 'next_idiom' to 'word', per Forth standard&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20241001: Add multi-threading support&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Shared dictionary and code space amount threads.&lt;/item&gt;
          &lt;item&gt;Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.&lt;/item&gt;
          &lt;item&gt;Introduce VM, states &lt;list rend="ul"&gt;&lt;item&gt;local ss, rs, tos, and user area&lt;/item&gt;&lt;item&gt;align to cache-line width&lt;/item&gt;&lt;item&gt;pass VM&amp;amp; to all lambda and static functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add thread pool and event_loop with affinity to physical cores. &lt;list rend="ul"&gt;&lt;item&gt;task, start, stop, join for thread life-cycle management&lt;/item&gt;&lt;item&gt;add general multi-threading demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add Inter-task communication &lt;list rend="ul"&gt;&lt;item&gt;pthread mutex and condition variables are used for synchronization&lt;/item&gt;&lt;item&gt;rank for task id&lt;/item&gt;&lt;item&gt;send, recv, and pull. Use local stack, as queue, for message passing.&lt;/item&gt;&lt;item&gt;add producer/consumer demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add IO sequencing &lt;list rend="ul"&gt;&lt;item&gt;ANSI-Color trace/logging for different cores&lt;/item&gt;&lt;item&gt;mutex guard used&lt;/item&gt;&lt;item&gt;lock, unlock for output stream synchronization&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC: 20250610: maintenance and memory leak check&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Refactor &lt;list rend="ul"&gt;&lt;item&gt;Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT&lt;/item&gt;&lt;item&gt;Group IO functions to forth_sys module&lt;/item&gt;&lt;item&gt;Macros to clarify intention, i.e. NEST, BASE, ADD_W&lt;/item&gt;&lt;item&gt;Code references replace Code pointers&lt;/item&gt;&lt;item&gt;Rename ms=&amp;gt;clock, delay=&amp;gt;ms (adhere to Forth Standard)&lt;/item&gt;&lt;item&gt;Add destructors to deallocate (reduce valgrind's complaints)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance multi-threading &lt;list rend="ul"&gt;&lt;item&gt;Use std::thread instead of pthread (except device specific CPU affinity)&lt;/item&gt;&lt;item&gt;Handle recursive include - Save/Restore WP&lt;/item&gt;&lt;item&gt;Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance debugging &lt;list rend="ul"&gt;&lt;item&gt;Add dict() to detail dictionary entries&lt;/item&gt;&lt;item&gt;Add dump() to show memory/parameter field's content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Refactor &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863024</guid><pubDate>Sun, 09 Nov 2025 04:59:19 +0000</pubDate></item><item><title>Study finds memory decline surge in young people</title><link>https://onepercentrule.substack.com/p/under-40s-declining-memory</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863057</guid><pubDate>Sun, 09 Nov 2025 05:05:20 +0000</pubDate></item><item><title>I Am Mark Zuckerberg</title><link>https://iammarkzuckerberg.com/</link><description>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863360</guid><pubDate>Sun, 09 Nov 2025 06:13:05 +0000</pubDate></item><item><title>Valori – A Python-native Vector Database I built from scratch</title><link>https://news.ycombinator.com/item?id=45864900</link><description>&lt;doc fingerprint="31bc1bb0dc95f1ac"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I’ve been working on a project called Valori, a Python-native vector database I built from the ground up — not by reinventing every algorithm, but by wiring together efficient, well-known indexing and search techniques into a cohesive, hackable framework.&lt;/p&gt;
      &lt;p&gt;The idea came from my frustration with existing vector DBs that were either too heavy for experimentation or too opaque to modify. I wanted something simple, modular, and extensible — so I built it.&lt;/p&gt;
      &lt;p&gt;What it does:&lt;/p&gt;
      &lt;p&gt;Lets you store, index, and search high-dimensional vectors&lt;/p&gt;
      &lt;p&gt;Supports multiple indices (Flat, HNSW, IVF, LSH, Annoy)&lt;/p&gt;
      &lt;p&gt;Has memory, disk, and hybrid storage backends&lt;/p&gt;
      &lt;p&gt;Includes a full document processing pipeline (parsing, cleaning, chunking, embedding)&lt;/p&gt;
      &lt;p&gt;Offers quantization, persistence, and plugin-based extensibility&lt;/p&gt;
      &lt;p&gt;All written in Python, integrated with NumPy, and production-tested with logging and monitoring built in.&lt;/p&gt;
      &lt;p&gt;Install:&lt;/p&gt;
      &lt;p&gt;pip install valori&lt;/p&gt;
      &lt;p&gt;GitHub: https://github.com/varshith-Git/valori&lt;/p&gt;
      &lt;p&gt;PyPI: https://pypi.org/project/valori&lt;/p&gt;
      &lt;p&gt;I’d love to hear your thoughts —&lt;/p&gt;
      &lt;p&gt;What’s missing for you in current vector DBs?&lt;/p&gt;
      &lt;p&gt;If you’ve built LLM or RAG systems, what do you wish a lightweight, pure Python DB like this handled better?&lt;/p&gt;
      &lt;p&gt;Would you prefer tighter integrations (LangChain, Haystack, etc.) or a more “build-it-yourself” style?&lt;/p&gt;
      &lt;p&gt;Feedback, criticism, or collaboration ideas are all welcome. — Varshith (varshith.gudur17@gmail.com )&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45864900</guid><pubDate>Sun, 09 Nov 2025 11:52:18 +0000</pubDate></item><item><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><link>https://www.newsyeah.fun/voyager/</link><description>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading… FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865049</guid><pubDate>Sun, 09 Nov 2025 12:24:50 +0000</pubDate></item><item><title>Alive Internet Theory</title><link>https://alivetheory.net/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865098</guid><pubDate>Sun, 09 Nov 2025 12:33:38 +0000</pubDate></item><item><title>Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology</title><link>https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/</link><description>&lt;doc fingerprint="25357b3c1a218080"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt;How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery: A Digital Time Capsule from 1987&lt;/head&gt;
    &lt;p&gt;Picture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to &lt;code&gt;comp.sources.games&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;“conquest – middle earth multi-player game, Part01/05”&lt;/p&gt;
    &lt;p&gt;That’s how Ed Barlow announced it at the time, before quickly changed the name to Conquer.&lt;/p&gt;
    &lt;p&gt;This was Conquer – a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn’t just the gameplay, but how it was built and distributed in an era when “open source” wasn’t even a term yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 0: University Days.&lt;/head&gt;
    &lt;p&gt;It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy.&lt;/p&gt;
    &lt;p&gt;But by 2006, this piece of computing history was trapped in legal limbo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Quest Begins (2006)&lt;/head&gt;
    &lt;p&gt;As a university student in Spain in the early ’90s, I’d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear – typical of the “post it and see what happens” era of early internet software distribution.&lt;/p&gt;
    &lt;p&gt;I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions.&lt;/p&gt;
    &lt;p&gt;Simple, right?&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Digital Detective Work&lt;/head&gt;
    &lt;p&gt;Finding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums.&lt;/p&gt;
    &lt;p&gt;The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: “Yes i delegated it all to adam aeons ago. Im easy on it all…. copyleft didnt exist when i wrote it and it was all for fun so…”&lt;/p&gt;
    &lt;p&gt;But there was a catch – I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: The Long Wait (2006-2011)&lt;/head&gt;
    &lt;p&gt;I documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders.&lt;/p&gt;
    &lt;p&gt;Years passed. The project stalled.&lt;/p&gt;
    &lt;p&gt;Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:&lt;/p&gt;
    &lt;p&gt;“I heard news of the request to release the code. I grant permission to release the code under GPL.” – Adam Bryant&lt;/p&gt;
    &lt;p&gt;He had found one of my articles online and reached out on his own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: The Plot Twist – Version 5 Emerges (2025)&lt;/head&gt;
    &lt;p&gt;Fast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 – a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn’t just an update; it was a complete reimagining of the game.&lt;/p&gt;
    &lt;p&gt;But V5 had a different legal history. In the ’90s, there had been commercial arrangements. Would Adam agree to GPL this version too?&lt;/p&gt;
    &lt;p&gt;His response: “I have no issues with applying a new GPL license to Version 5 as well.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: The Missing Piece – PostScript Magic&lt;/head&gt;
    &lt;p&gt;Just when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps – a crucial feature in the pre-GUI era when players needed physical printouts to strategize.&lt;/p&gt;
    &lt;p&gt;Tracking down MaF in 2025 led me to his company, where he’s now Director of Product Security. His response: “Oh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.”&lt;lb/&gt;Richard Caley: More Than Just a Legal Footnote&lt;/p&gt;
    &lt;p&gt;But not all searches end with an answer. Some end with silence.&lt;/p&gt;
    &lt;p&gt;My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.&lt;/p&gt;
    &lt;p&gt;Then I found him – not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org.&lt;/p&gt;
    &lt;p&gt;“Richard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.”&lt;/p&gt;
    &lt;p&gt;Reading those words felt different from finding a historical record. This wasn’t archival research – this was walking into someone’s house years after they’d gone and finding a note on the table.&lt;/p&gt;
    &lt;p&gt;The page continued:&lt;/p&gt;
    &lt;p&gt;“Over and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.”&lt;/p&gt;
    &lt;p&gt;The “Caleyisms” – The Man Behind the Code&lt;/p&gt;
    &lt;p&gt;And then I discovered his “Caleyisms” – a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:&lt;/p&gt;
    &lt;p&gt;What’s a shell suit?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Oil company executive.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you prepare for a pyroclastic flow hitting Edinburgh?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Hang 1000 battered Mars bars on strings and stand back?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;On his book addiction:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:&lt;/p&gt;
    &lt;p&gt;“Lack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn’t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.”&lt;/p&gt;
    &lt;p&gt;A Digital Office Preserved&lt;/p&gt;
    &lt;p&gt;Exploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his “About” section:&lt;/p&gt;
    &lt;p&gt;“Thankfully I don’t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I’m not.”&lt;/p&gt;
    &lt;p&gt;Here was a complete person – technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions.&lt;/p&gt;
    &lt;p&gt;The legal reality was harsh: Richard’s contributions to Conquer couldn’t be relicensed. The university couldn’t help contact heirs due to privacy laws.&lt;/p&gt;
    &lt;p&gt;His friends had preserved his memory with a simple ASCII tribute at the end of his page:&lt;/p&gt;
    &lt;quote&gt;^_^&lt;lb/&gt;(O O)&lt;lb/&gt;\_/@@\&lt;lb/&gt;\\~~/&lt;lb/&gt;~~&lt;lb/&gt;- RJC RIP&lt;/quote&gt;
    &lt;p&gt;In the Conquer project documentation, Richard Caley isn’t remembered as a “problem case” or “unlicensable code.” He’s honored as the vibrant person he was – the brilliant mind behind the “Caleyisms,” the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Modern Renaissance – Enter GitHub, CICD and Modern Distributions&lt;/head&gt;
    &lt;p&gt;Here’s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.&lt;/p&gt;
    &lt;p&gt;For APK packages, I used Melange – a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi “undistro”. The irony? I discovered this tool when some friend started to work for the company that created it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 7: The Technical Journey: From USENET to Modern CI/CD&lt;/head&gt;
    &lt;p&gt;The transformation has been remarkable:&lt;/p&gt;
    &lt;p&gt;1987 Original:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributed as split USENET posts&lt;/item&gt;
      &lt;item&gt;Manual compilation with system-specific Makefiles&lt;/item&gt;
      &lt;item&gt;No version control or automated testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2025 Revival:&lt;/p&gt;
    &lt;code&gt;# Modern CI/CD with GitHub Actions
- name: Build APK package
  run: melange build conquer.yaml
- name: Build Debian package  
  run: dpkg-buildpackage -b
&lt;/code&gt;
    &lt;p&gt;Key Modern Additions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPLv3 relicensing&lt;/item&gt;
      &lt;item&gt;Make building system modernization&lt;/item&gt;
      &lt;item&gt;C Codebase partially updated to support modern ANSI C99 specification&lt;/item&gt;
      &lt;item&gt;Debian packaging&lt;/item&gt;
      &lt;item&gt;APK packaging with Melange&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can see the complete transformation in the repositories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conquer v4 – The original classic&lt;/item&gt;
      &lt;item&gt;Conquer v5 – The advanced rewrite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Original Conquer v4 code, by Ed Barlow and Adam Bryant&lt;/p&gt;
    &lt;p&gt;(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!)&lt;/p&gt;
    &lt;p&gt;Conquer Version 5 – The evolution of the classical Conquer, by Adam Bryant&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 8: The Human Element: Why This Matters&lt;/head&gt;
    &lt;p&gt;This isn’t just about preserving old games – it’s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that’s what you did – you shared cool things with the community.&lt;/p&gt;
    &lt;p&gt;Martin Forssen’s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator!&lt;/p&gt;
    &lt;p&gt;The 20-year relicensing effort demonstrates something crucial about open source: it’s not just about code, it’s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they’re weaving the threads that connect computing’s past to its future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for Modern Developers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Document everything: Those casual USENET posts became crucial legal evidence decades later&lt;/item&gt;
      &lt;item&gt;License clearly: Ed’s comment that “copyleft didnt exist when i wrote it” highlights how licensing landscapes evolve&lt;/item&gt;
      &lt;item&gt;Community matters: Adam found my articles because the community was talking about preservation&lt;/item&gt;
      &lt;item&gt;Technical debt is temporal: What seems like legacy tech today might be tomorrow’s archaeological treasure&lt;/item&gt;
      &lt;item&gt;Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Continuing Story&lt;/head&gt;
    &lt;p&gt;Both Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades.&lt;/p&gt;
    &lt;p&gt;The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life.&lt;/p&gt;
    &lt;p&gt;Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history.&lt;/p&gt;
    &lt;p&gt;What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?&lt;/p&gt;
    &lt;p&gt;#FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell&lt;/p&gt;
    &lt;p&gt;Read this article in Spanish / Lee este artículo en español: &lt;lb/&gt;https://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/&lt;/p&gt;
    &lt;p&gt;This article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865159</guid><pubDate>Sun, 09 Nov 2025 12:44:35 +0000</pubDate></item></channel></rss>