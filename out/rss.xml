<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 05 Sep 2025 12:18:08 +0000</lastBuildDate><item><title>Age Simulation Suit</title><link>https://www.age-simulation-suit.com/</link><description>&lt;doc fingerprint="fdab49420ed58155"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GERonTologic simulator GERT&lt;/head&gt;
    &lt;p&gt;The age simulation suit GERT offers the opportunity to experience the impairments of older persons even for younger people. &lt;lb/&gt; The age-related impairments are:&lt;/p&gt;
    &lt;p&gt;■ opacity of the eye lens&lt;/p&gt;
    &lt;p&gt;■ narrowing of the visual field&lt;/p&gt;
    &lt;p&gt;■ high-frequency hearing loss&lt;/p&gt;
    &lt;p&gt;■ head mobility restrictions&lt;/p&gt;
    &lt;p&gt;■ joint stiffness&lt;/p&gt;
    &lt;p&gt;■ loss of strength&lt;/p&gt;
    &lt;p&gt;■ reduced grip ability&lt;/p&gt;
    &lt;p&gt;■ reduced coordination skills&lt;/p&gt;
    &lt;head rend="h4"&gt;GERT for only 1390,‑ / £ 1250,-&lt;/head&gt;
    &lt;p&gt;complete as pictured, plus shipping and VAT if applicable&lt;lb/&gt; New: now with 2 pairs of glasses instead of the model shown&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Due to the significant increase in the time and effort required to process orders, in particular as a result of incomplete or incorrect information provided with orders, and the fact that we increasingly have to send reminders for invoices for smaller amounts, we can only accept orders with a value of at least 300 euros or pounds.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Customer reviews:&lt;/p&gt;
    &lt;p&gt;The quality is great and it works how it is supposed to. Im happy with my purchase.&lt;/p&gt;
    &lt;p&gt;Great way to teach about elderly behavior. Ive been using this suit for a while now and its very durable and easy to use. Thanks!!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45129190</guid></item><item><title>A PM's Guide to AI Agent Architecture</title><link>https://www.productcurious.com/p/a-pms-guide-to-ai-agent-architecture</link><description>&lt;doc fingerprint="2cd6bc914903882d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A PM's Guide to AI Agent Architecture: Why Capability Doesn't Equal Adoption&lt;/head&gt;
    &lt;head rend="h3"&gt;A complete guide to agent architecture, orchestration patterns, trust strategies, and adoption plans for PMs building AI agents.&lt;/head&gt;
    &lt;p&gt;Last week, I was talking to a PM who'd in the recent months shipped their AI agent. The metrics looked great: 89% accuracy, sub-second respond times, positive user feedback in surveys. But users were abandoning the agent after their first real problem, like a user with both a billing dispute and a locked account.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Our agent could handle routine requests perfectly, but when faced with complex issues, users would try once, get frustrated, and immediately ask for a human."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This pattern is observed across every product team that focuses on making their agents "smarter" when the real challenge is making architectural decisions that shape how users experience and begin to trust the agent.&lt;/p&gt;
    &lt;p&gt;In this post, I'm going to walk you through the different layers of AI agent architecture. How your product decisions determine whether users trust your agent or abandon it. By the end of this, you'll understand why some agents feel "magical" while others feel "frustrating" and more importantly, how PMs should architect for the magical experience.&lt;/p&gt;
    &lt;p&gt;We'll use a concrete customer support agent example throughout, so you can see exactly how each architectural choice plays out in practice. We’ll also see why the counterintuitive approach to trust (hint: it's not about being right more often) actually works better for user adoption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let's say you're building a customer support agent&lt;/head&gt;
    &lt;p&gt;You're the PM building an agent that helps users with account issues - password resets, billing questions, plan changes. Seems straightforward, right?&lt;/p&gt;
    &lt;p&gt;But when a user says "I can't access my account and my subscription seems wrong" what should happen?&lt;/p&gt;
    &lt;p&gt;Scenario A: Your agent immediately starts checking systems. It looks up the account, identifies that the password was reset yesterday but the email never arrived, discovers a billing issue that downgraded the plan, explains exactly what happened, and offers to fix both issues with one click.&lt;/p&gt;
    &lt;p&gt;Scenario B: Your agent asks clarifying questions. "When did you last successfully log in? What error message do you see? Can you tell me more about the subscription issue?" After gathering info, it says "Let me escalate you to a human who can check your account and billing."&lt;/p&gt;
    &lt;p&gt;Same user request. Same underlying systems. Completely different products.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Four Layers Where Your Product Decisions Live&lt;/head&gt;
    &lt;p&gt;Think of agent architecture like a stack where each layer represents a product decision you have to make.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 1: Context &amp;amp; Memory (What does your agent remember?)&lt;/head&gt;
    &lt;p&gt;The Decision: How much should your agent remember, and for how long?&lt;/p&gt;
    &lt;p&gt;This isn't just technical storage - it's about creating the illusion of understanding. Your agent's memory determines whether it feels like talking to a robot or a knowledgeable colleague.&lt;/p&gt;
    &lt;p&gt;For our support agent: Do you store just the current conversation, or the customer's entire support history? Their product usage patterns? Previous complaints?&lt;/p&gt;
    &lt;p&gt;Types of memory to consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Session memory: Current conversation ("You mentioned billing issues earlier...")&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer memory: Past interactions across sessions ("Last month you had a similar issue with...")&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Behavioral memory: Usage patterns ("I notice you typically use our mobile app...")&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Contextual memory: Current account state, active subscriptions, recent activity&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The more your agent remembers, the more it can anticipate needs rather than just react to questions. Each layer of memory makes responses more intelligent but increases complexity and cost.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 2: Data &amp;amp; Integration (How deep do you go?)&lt;/head&gt;
    &lt;p&gt;The Decision: Which systems should your agent connect to, and what level of access should it have?&lt;/p&gt;
    &lt;p&gt;The deeper your agent connects to user workflows and existing systems, the harder it becomes for users to switch. This layer determines whether you're a tool or a platform.&lt;/p&gt;
    &lt;p&gt;For our support agent: Should it integrate with just your Stripe’s billing system, or also your Salesforce CRM, ZenDesk ticketing system , user database, and audit logs? Each integration makes the agent more useful but also creates more potential failure points - think API rate limits, authentication challenges, and system downtime.&lt;/p&gt;
    &lt;p&gt;Here's what's interesting - Most of us get stuck trying to integrate with everything at once. But the most successful agents started with just 2-3 key integrations and added more based on what users actually asked for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 3: Skills &amp;amp; Capabilities (What makes you different?)&lt;/head&gt;
    &lt;p&gt;The Decision: Which specific capabilities should your agent have, and how deep should they go?&lt;/p&gt;
    &lt;p&gt;Your skills layer is where you win or lose against competitors. It's not about having the most features - it's about having the right capabilities that create user dependency.&lt;/p&gt;
    &lt;p&gt;For our support agent: Should it only read account information, or should it also modify billing, reset passwords, and change plan settings? Each additional skill increases user value but also increases complexity and risk.&lt;/p&gt;
    &lt;p&gt;Implementation note: Tools like MCP (Model Context Protocol) are making it much easier to build and share skills across different agents, rather than rebuilding capabilities from scratch.&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;lb/&gt;Layer 4: Evaluation &amp;amp; Trust (How do users know what to expect?)&lt;/head&gt;
    &lt;p&gt;The Decision: How do you measure success and communicate agent limitations to users?&lt;/p&gt;
    &lt;p&gt;This layer determines whether users develop confidence in your agent or abandon it after the first mistake. It's not just about being accurate - it's about being trustworthy.&lt;/p&gt;
    &lt;p&gt;For our support agent: Do you show confidence scores ("I'm 85% confident this will fix your issue")? Do you explain your reasoning ("I checked three systems and found...")? Do you always confirm before taking actions ("Should I reset your password now?")? Each choice affects how users perceive reliability.&lt;/p&gt;
    &lt;p&gt;Trust strategies to consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Confidence indicators: "I'm confident about your account status, but let me double-check the billing details"&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reasoning transparency: "I found two failed login attempts and an expired payment method"&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Graceful boundaries: "This looks like a complex billing issue - let me connect you with our billing specialist who has access to more tools"&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Confirmation patterns: When to ask permission vs. when to act and explain&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;The counterintuitive insight: users trust agents more when they admit uncertainty than when they confidently make mistakes.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;So how do you actually architect an agent?&lt;/head&gt;
    &lt;p&gt;Okay, so you understand the layers. Now comes the practical question that every PM asks: "How do I actually implement this? How does the agent talk to the skills? How do skills access data? How does evaluation happen while users are waiting?"&lt;/p&gt;
    &lt;p&gt;Your orchestration choice determines everything about your development experience, your debugging process, and your ability to iterate quickly.&lt;/p&gt;
    &lt;p&gt;Lets walk through the main approaches, and I'll be honest about when each one works and when it becomes a nightmare.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Single-Agent Architecture (Start Here)&lt;/head&gt;
    &lt;p&gt;Everything happens in one agent's context.&lt;/p&gt;
    &lt;p&gt;For our support agent: When the user says "I can't access my account," one agent handles it all - checking account status, identifying billing issues, explaining what happened, offering solutions.&lt;/p&gt;
    &lt;p&gt;Why this works: Simple to build, easy to debug, predictable costs. You know exactly what your agent can and can't do.&lt;/p&gt;
    &lt;p&gt;Why it doesn't: Can get expensive with complex requests since you're loading full context every time. Hard to optimize specific parts.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Most teams start here, and honestly, many never need to move beyond it. If you're debating between this and something more complex, start here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;2. Skill-Based Architecture (When You Need Efficiency)&lt;/head&gt;
    &lt;p&gt;You have a router that figures out what the user needs, then hands off to specialized skills.&lt;/p&gt;
    &lt;p&gt;For our support agent: Router realizes this is an account access issue and routes to the `LoginSkill`. If the LoginSkill discovers it's actually a billing problem, it hands off to `BillingSkill`.&lt;/p&gt;
    &lt;p&gt;Real example flow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;User: "I can't log in"&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Router → LoginSkill&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LoginSkill checks: Account exists ✓, Password correct ✗, Billing status... wait, subscription expired&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LoginSkill → BillingSkill: "Handle expired subscription for user123"&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;BillingSkill handles renewal process&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why this works: More efficient - you can use cheaper models for simple skills, expensive models for complex reasoning. Each skill can be optimized independently.&lt;/p&gt;
    &lt;p&gt;Why it doesn't: Coordination between skills gets tricky fast. Who decides when to hand off? How do skills share context?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Here's where MCP really helps - it standardizes how skills expose their capabilities, so your router knows what each skill can do without manually maintaining that mapping.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;3. Workflow-Based Architecture (Enterprise Favorite)&lt;/head&gt;
    &lt;p&gt;You predefine step-by-step processes for common scenarios. Think LangGraph, CrewAI, AutoGen, N8N, etc.&lt;/p&gt;
    &lt;p&gt;For our support agent: "Account access problem" triggers a workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Check account status&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If locked, check failed login attempts&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If too many failures, check billing status&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If billing issue, route to payment recovery&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If not billing, route to password reset&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why this works: Everything is predictable and auditable. Perfect for compliance-heavy industries. Easy to optimize each step.&lt;/p&gt;
    &lt;p&gt;Why it doesn't: When users have weird edge cases that don't fit your predefined workflows, you're stuck. Feels rigid to users.&lt;/p&gt;
    &lt;head rend="h3"&gt;4. Collaborative Architecture (The Future?)&lt;/head&gt;
    &lt;p&gt;Multiple specialized agents work together using A2A (agent-to-agent) protocols.&lt;/p&gt;
    &lt;p&gt;The vision: Your agent discovers that another company's agent can help with issues, automatically establishes a secure connection, and collaborates to solve the customer's problem. Think a booking.com agent interacting with an American Airlines agent!&lt;/p&gt;
    &lt;p&gt;For our support agent: `AuthenticationAgent` handles login issues, `BillingAgent` handles payment problems, `CommunicationAgent` manages user interaction. They coordinate through standardized protocols to solve complex problems.&lt;/p&gt;
    &lt;p&gt;Reality check: This sounds amazing but introduces complexity around security, billing, trust, and reliability that most companies aren't ready for. We're still figuring out the standards.&lt;/p&gt;
    &lt;p&gt;This can produce amazing results for sophisticated scenarios, but debugging multi-agent conversations is genuinely hard. When something goes wrong, figuring out which agent made the mistake and why is like detective work.&lt;/p&gt;
    &lt;p&gt;Here's the thing: start simple. Single-agent architecture handles way more use cases than you think. Add complexity only when you hit real limitations, not imaginary ones.&lt;/p&gt;
    &lt;p&gt;But here's what's interesting - even with the perfect architecture, your agent can still fail if users don't trust it. That brings us to the most counterintuitive lesson about building agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;The trust thing that everyone gets wrong&lt;/head&gt;
    &lt;p&gt;Here's something counterintuitive: Users don't trust agents that are right all the time. They trust agents that are honest about when they might be wrong.&lt;/p&gt;
    &lt;p&gt;Think about it from the user's perspective. Your support agent confidently says "I've reset your password and updated your billing address." User thinks "great!" Then they try to log in and... it doesn't work. Now they don't just have a technical problem - they have a trust problem.&lt;/p&gt;
    &lt;p&gt;Compare that to an agent that says "I think I found the issue with your account. I'm 80% confident this will fix it. I'm going to reset your password and update your billing address. If this doesn't work, I'll immediately escalate to a human who can dive deeper."&lt;/p&gt;
    &lt;p&gt;Same technical capability. Completely different user experience.&lt;/p&gt;
    &lt;p&gt;Building trusted agents requires focus on three things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Confidence calibration: When your agent says it's 60% confident, it should be right about 60% of the time. Not 90%, not 30%. Actual 60%.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reasoning transparency: Users want to see the agent's work. "I checked your account status (active), billing history (payment failed yesterday), and login attempts (locked after 3 failed attempts). The issue seems to be..."&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Graceful escalation: When your agent hits its limits, how does it hand off? A smooth transition to a human with full context is much better than "I can't help with that."&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of times we obsess over making agents more accurate, when what users actually want was more transparency about the agent's limitations.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's Coming Next&lt;/head&gt;
    &lt;p&gt;In Part 2, I'll dive deeper into the autonomy decisions that keep most PMs up at night. How much independence should you give your agent? When should it ask for permission vs forgiveness? How do you balance automation with user control?&lt;/p&gt;
    &lt;p&gt;We'll also walk through the governance concerns that actually matter in practice - not just theoretical security issues, but the real implementation challenges that can make or break your launch timeline.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45129237</guid></item><item><title>LLM Visualization</title><link>https://bbycroft.net/llm</link><description>&lt;doc fingerprint="4d6fd5b5f15dbf71"&gt;
  &lt;main&gt;
    &lt;p&gt;LLM Visualization Home&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45130260</guid></item><item><title>Action was the best 8-bit programming language</title><link>https://www.goto10retro.com/p/action-was-the-best-8-bit-programming</link><description>&lt;doc fingerprint="3e0c1883607d39dc"&gt;
  &lt;main&gt;
    &lt;p&gt;There were many programming languages available for 8-bit computers, the most common being BASIC and Assembly Language, but there were also other lesser-used languages such as Logo, Forth, and Pilot. The languages that would go on to dominate 16-bit computing, C and Pascal, were also available but were usually severely limited. An 8-bit computer generally did not have enough horsepower to run those more complex language compilers1.&lt;/p&gt;
    &lt;p&gt;By 1983 Optimized Systems Software (OSS) was renown in the Atari world for its great updated versions of DOS (DOS XL), BASIC (BASIC XL/XE) and assembler (MAC/65), so it was no surprise that they were the ones to introduce a new language, Action!, into the Atari market.&lt;/p&gt;
    &lt;p&gt;Created by Clinton Parker, Action! was an all-new compiled language that was designed and optimized for the 8-bit 6502 CPU. It was a 16K cartridge2 and had everything you need integrated into one package: the monitor, compiler, text editor and debugger3. In some ways, Action! was the first IDE (integrated development environment) for an 8-bit computer.&lt;/p&gt;
    &lt;p&gt;Back in the 80s I never used Action! and instead mostly used BASIC and OSS BASIC XE for my programming. I did like reading Action! program listings in magazines, though. But I now have the Action! cartridge and just recently acquired an Action! user manual, so I felt it was time to take a closer look at this amazing software development tool.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Packaging&lt;/head&gt;
    &lt;p&gt;The version of Action! that I now have is the classic orange cartridge, paired with a small 3-ring yellow binder containing the documentation. Action! was also available in the yellow label cartridge and its manual was also in a larger binder and then later, perfect bound (like the BASIC XL and BASIC XE manuals I have). Having the manual in a binder would have certainly been more useful in the 80s when you had to refer to it frequently.&lt;/p&gt;
    &lt;p&gt;Action! retailed for $99 in 1983 (about $320 in 2025) and was only available for the Atari 8-bit computers. Early advertisements indicated there would be forthcoming versions for the Apple II and Commodore 64, but those never materialized.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Manual&lt;/head&gt;
    &lt;p&gt;The manual is just under 220 pages and is concise, but reasonable well-written. There is not a ton of sample code and it doesn’t try to teach too many concepts. To get the most of it, you really already need to know how to program.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I had been looking for an actual Action! manual for years, but the ones I’d seen on eBay had always been prohibitively expensive. Luckily I found one last month for just $30 and snagged it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You don’t need a physical manual, of course. An updated manual is available online in several places, and here’s the PDF.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Editor&lt;/head&gt;
    &lt;p&gt;The editor really was a wonder for its time. It is a full-screen text editor that can scroll to the right as the line of text you type becomes longer than the 40 characters of an Atari screen. That was an unusual feature for the time, but was necessary because it allowed the indentation, encouraged by Action!’s structured programming style, to remain easy to read.&lt;/p&gt;
    &lt;p&gt;The editor can copy and paste text, another somewhat new feature for Atari text editors in 1983, has the ability to tag lines to jump to them rapidly and it also has a split screen mode that let you show two files (or two parts of the same file) on the screen at once. At first this might seem silly considering the small size of the screen, but this was revolutionary for the time. Normally to look at another file, you’d have to open it, losing the file you were working on, and then reload the original file. It was tedious and was a reason why you would print your programs back then.&lt;/p&gt;
    &lt;p&gt;Even looking at different parts of a file could be a pain because you’d just be scrolling all over the place, which was not always fast or easy in many text editors. This was even worse with something like BASIC, which required you to LIST line ranges to see parts of your program.&lt;/p&gt;
    &lt;p&gt;To exit the editor, you press Control+Shift+M which takes you to the monitor.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Monitor&lt;/head&gt;
    &lt;p&gt;Today this would be called the shell, but it is essentially the command line interface for the entire system. From the monitor, you can switch to the editor, compile, trace code, look at memory and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Language&lt;/head&gt;
    &lt;p&gt;Action! is a structured, procedural programming language. It is similar to both C and Pascal, although not quite as advanced as either of them.&lt;/p&gt;
    &lt;p&gt;It has the usual commands for looping, if-then-else, but it does not have anything like a switch or Case statement. There are also only three data types: BYTE, CARD and INT. Strings were essentially just BYTE arrays.&lt;/p&gt;
    &lt;p&gt;I found it endearing that to end an IF block you used FI (IF spelled backwards) and to end a DO block you used OD. That is some interesting symmetry although I’m not really sure it helps readability.&lt;/p&gt;
    &lt;p&gt;An Action! “Hello World” program would be this:&lt;/p&gt;
    &lt;code&gt;PROC hello()
; This is a comment.
  DO
    PrintE("Goto 10")
  OD
RETURN&lt;/code&gt;
    &lt;head rend="h2"&gt;The Compiler&lt;/head&gt;
    &lt;p&gt;The Action! language may not have been as advanced as C or Pascal, but because it was designed with the 6502 CPU in mind, compiling the language was astonishingly fast.&lt;/p&gt;
    &lt;p&gt;The original Atari Pascal system from APX needed multiple disk drives and could take several minutes to compile a small program. The only C package available in 1983 (Deep Blue C) was at least as limited as Action!, but also not an integrated package and compiled slowly. Draper Pascal only compiled to pseudo-code.&lt;/p&gt;
    &lt;p&gt;Action! compiled your program to machine code in memory and in seconds. Typing C (to compile) and then R (to run) was hardly slower than just typing RUN in BASIC.&lt;/p&gt;
    &lt;p&gt;It really is stupidly fast. Here’s the output from the above program:&lt;/p&gt;
    &lt;p&gt;If there is a compile error, it is shown on the screen and will be highlighted when you switch back to the editor by typing “e”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;Action! was not perfect and it had several limitations. In my opinion, the two biggest limitations were that that Action! cartridge was required to run Action! programs (because they depended on the library that was included the cartridge ROM) and that there was no floating point data type.&lt;/p&gt;
    &lt;p&gt;Both of these did get solved, to some extent, with the purchase of an additional add-ons: Action! RunTime and Action! Toolkit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Action! RunTime&lt;/head&gt;
    &lt;p&gt;The RunTime package provided the ability to create stand-alone Action! programs that you could distribute to others to run without the cartridge.&lt;/p&gt;
    &lt;p&gt;The RunTime included the library as source files that you could include at the beginning of your own programs so that everything that was needed to run would get compiled into a single executable program. From what I can tell, Action! had no concept of linking which is how something like C would have handled this.&lt;/p&gt;
    &lt;p&gt;I don’t have an official Action! RunTime disk, but the image is readily available online.&lt;/p&gt;
    &lt;head rend="h2"&gt;Action! ToolKit&lt;/head&gt;
    &lt;p&gt;The ToolKit is essentially an enhanced Library with additional functions and features. Two notable things it adds are player/missile graphics support and some support for floating-point numbers via several “Real” functions.&lt;/p&gt;
    &lt;p&gt;Unfortunately this floating point support is somewhat limited and it doesn’t look all that useful to me. For example, I’ve used the Archimedes Spiral program in some articles here on Goto 10 to demonstrate drawing a fun graphic on the screen. It is interesting to see how long it can take to do the drawing on an 8-bit computer. I’d love to port it to Action!, and I was hopeful I’d be able to do so with the Action! ToolKit. Alas, even though it does add some commands to do some floating-point math, it does not add any trigonometry functions. The lack of Sin and Cos make it impractical to port Archimedes Spiral4.&lt;/p&gt;
    &lt;p&gt;I don’t have an official Action! ToolKit disk, but the image is readily available online.&lt;/p&gt;
    &lt;head rend="h2"&gt;Usage&lt;/head&gt;
    &lt;p&gt;It seems that Action! was mostly use by hobbyists, public domain and magazine software. The only two known commercial product made with Action! were the HomePak5 productivity package by Russ Wetmore and the Games Computers Play online service.&lt;/p&gt;
    &lt;p&gt;For the above screen shots, I was using Action! with my 130XE.&lt;/p&gt;
    &lt;p&gt;I plan to dig into actually using Action! itself more in the coming months. It really looks like a fun language. Unfortunately, since Action! is a cartridge, I can’t use it directly with my Side3 cart. There are disk-based versions of Action! available at AtariWiki, so I may have to switch to one of those, or see if I can get one of the SuperCart images to work with Side3. Otherwise, I may try it old-school with SpartaDOS, my trusty 1050 disk drive and a RAM disk.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other References&lt;/head&gt;
    &lt;p&gt;AtariWiki has a create page with lots of links to Action!-related materials.&lt;/p&gt;
    &lt;p&gt;Action! Archive is a great reference for Action! programming.&lt;/p&gt;
    &lt;p&gt;If you want to learn more about how to program in Action!, be sure to check out David Arlington’s YouTube channel, which has a 25-part series on Action! programming.&lt;/p&gt;
    &lt;p&gt;Kyan Pascal was released in 1986 and worked pretty well, but really wanted a couple disk drives. LightSpeed C was also a decent version of C that debuted later in the 80s.&lt;/p&gt;
    &lt;p&gt;Actually an OSS SuperCartridge, which had 16K of ROM but only used 8K of address space in the computer.&lt;/p&gt;
    &lt;p&gt;Calling it a debugger might be a bit of stretch compared to modern tools.&lt;/p&gt;
    &lt;p&gt;Sure, I could probably implement my own version of those, but I don’t really want to.&lt;/p&gt;
    &lt;p&gt;HomePak was an integrated productivity package with a highly regarded terminal program, a slick word processor with not much free RAM for text (perhaps 5 pages) and an usual database. HomePak warrants its own article.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45131243</guid></item><item><title>Classic 8×8-pixel B&amp;W Mac patterns</title><link>https://www.pauladamsmith.com/blog/2025/09/classic-mac-patterns.html</link><description>&lt;doc fingerprint="3600717075e6a4ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Classic 8Ã8-pixel B&amp;amp;W Mac patterns&lt;/head&gt;
    &lt;p&gt;TL;DR: I made a website for the original classic Mac patterns&lt;/p&gt;
    &lt;p&gt;I was working on something and thought it would be fun to use one of the classic Mac black-and-white patterns in the project. I'm talking about the original 8Ã8-pixel ones that were in the original Control Panel for setting the desktop background and in MacPaint as fill patterns.&lt;/p&gt;
    &lt;p&gt;Screenshots via to Marcin's awesome interactive history&lt;/p&gt;
    &lt;p&gt;I figured there'd must be clean, pixel-perfect GIFs or PNGs of them somewhere on the web. And perhaps there are, but after poking around a bit, I ran out of energy for that, but by then had a head of steam for extracting the patterns en masse from the original source, somehow. Then I could produce whatever format I needed for them.&lt;/p&gt;
    &lt;p&gt;There are 38 patterns, introduced in the original System 1.0 in the 1984 debut of the Macintosh. They were unchanged in later versions, so I decided to get them from a System 6 disk, since that's a little easier with access to utility programs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preparation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Download Mini vMac.&lt;/item&gt;
      &lt;item&gt;Acquire "old world" Mac ROMs.&lt;/item&gt;
      &lt;item&gt;Download a System 6 startup disk image.&lt;/item&gt;
      &lt;item&gt;Download ExportFl disk image.&lt;/item&gt;
      &lt;item&gt;Download sitPack disk image.&lt;/item&gt;
      &lt;item&gt;Install "The Unarchiver" (&lt;code&gt;brew install --cask the-unarchiver&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Install the Xcode command-line tools.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Extraction process&lt;/head&gt;
    &lt;p&gt;Start System 6 (drag the ROM onto the Mini vMac icon, then drag the System 6 disk onto the window when you see the flashing floppy disk). Mount the ExportFl and sitPack disks by dragging their files and dropping on the classic Mac desktop.&lt;/p&gt;
    &lt;head rend="h3"&gt;In emulation&lt;/head&gt;
    &lt;p&gt;Double-click sitPack to launch the program. Command-O to open, then navigate to the startup disk by clicking "Drive". Scroll to find "System Folder" and double-click on it. Scroll to the bottom, select "System" and click "Open". Save the output file as "System.sit" in the top-level of the startup disk. Quit sitPack back to the Finder.&lt;/p&gt;
    &lt;p&gt;Start the ExportFl program. Command-O or pick "Open" from the "File" menu. Find the "System.sit" created in the last step and click "Open". A regular file save dialog will appear on the modern Mac, pick a location and save the file.&lt;/p&gt;
    &lt;head rend="h3"&gt;On the modern Mac&lt;/head&gt;
    &lt;p&gt;Drag the "System.sit" file onto The Unarchiver, or open the file from within it. This will produce a file called "System" (with no extension).&lt;/p&gt;
    &lt;p&gt;Run DeRez (part of the Xcode developer command-line tools) on the System file. I first added &lt;code&gt;/Library/Developer/CommandLineTools/usr/bin&lt;/code&gt; to my &lt;code&gt;$PATH&lt;/code&gt;, then
ran:&lt;/p&gt;
    &lt;code&gt;$ DeRez -only PAT\# System &amp;gt; patterns.r
&lt;/code&gt;
    &lt;p&gt;This produces a text representation of the &lt;code&gt;PAT#&lt;/code&gt; resource in the System file.
It's a series of bytes that comprise 38 8Ã8 patterns meant for QuickDraw
commands. There's a leading big-endian unsigned 16-bit number (&lt;code&gt;0026&lt;/code&gt;) to indicate the number of 8-byte patterns to follow.&lt;/p&gt;
    &lt;code&gt;data 'PAT#' (0, purgeable) {
	$"0026 FFFF FFFF FFFF FFFF DDFF 77FF DDFF"
	$"77FF DD77 DD77 DD77 DD77 AA55 AA55 AA55"
	$"AA55 55FF 55FF 55FF 55FF AAAA AAAA AAAA"
	$"AAAA EEDD BB77 EEDD BB77 8888 8888 8888"
	$"8888 B130 031B D8C0 0C8D 8010 0220 0108"
	$"4004 FF88 8888 FF88 8888 FF80 8080 FF08"
	$"0808 8000 0000 0000 0000 8040 2000 0204"
	$"0800 8244 3944 8201 0101 F874 2247 8F17"
	$"2271 55A0 4040 550A 0404 2050 8888 8888"
	$"0502 BF00 BFBF B0B0 B0B0 0000 0000 0000"
	$"0000 8000 0800 8000 0800 8800 2200 8800"
	$"2200 8822 8822 8822 8822 AA00 AA00 AA00"
	$"AA00 FF00 FF00 FF00 FF00 1122 4488 1122"
	$"4488 FF00 0000 FF00 0000 0102 0408 1020"
	$"4080 AA00 8000 8800 8000 FF80 8080 8080"
	$"8080 081C 22C1 8001 0204 8814 2241 8800"
	$"AA00 40A0 0000 040A 0000 0384 4830 0C02"
	$"0101 8080 413E 0808 14E3 1020 54AA FF02"
	$"0408 7789 8F8F 7798 F8F8 0008 142A 552A"
	$"1408"
};
&lt;/code&gt;
    &lt;p&gt;It would have been simple enough to parse this text, but I had Claude quickly make a Python program to do so and output them in .pbm format, which is part of the Netpbm image format class. This is a simple image format that is text-based, a '1' or a '0' indicating a black or white pixel in a row and column.&lt;/p&gt;
    &lt;p&gt;For example, this subway tile pattern is represented like this in .pbm:&lt;/p&gt;
    &lt;code&gt;P1
8 8
1 1 1 1 1 1 1 1
1 0 0 0 0 0 0 0
1 0 0 0 0 0 0 0
1 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1
0 0 0 0 1 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 1 0 0 0
&lt;/code&gt;
    &lt;p&gt;From here, I can generate image files for the patterns in any format and resolution I want, using ImageMagick or similar. It's important when scaling the patterns to use &lt;code&gt;-filter point&lt;/code&gt;, so that ImageMagick doesn't try to interpolate
the pixels it needs to fill in, which would lead to blurry results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why do all this?&lt;/head&gt;
    &lt;p&gt;It's nostalgic, I have a fondness for these old patterns and the original B&amp;amp;W Mac aesthetic, it reminds me of playing games like Dark Castle and Glider, messing around with HyperCard, and using Tex-Edit and hoarding early shareware programs.&lt;/p&gt;
    &lt;p&gt;The whole point of the above is to get a copy of the System file out with the resource fork intact, that's where the desktop patterns live.&lt;/p&gt;
    &lt;p&gt;According to old classic Mac manuals, the patterns were QuickDraw bit-pattern resources, a simple bitmap of 8 bits per row packed into 8 bytes (columns). It was fast for QuickDraw to copy them over an area of the screen. For example the following pattern was used for the default gray desktop pattern on black-and-white Mac screens.&lt;/p&gt;
    &lt;p&gt;I could have extracted all 38 patterns other ways: I could have screenshotted each one, I could have looked at each one and hand-written .pbm files, both of which would have been tedious and error-prone.&lt;/p&gt;
    &lt;p&gt;Ultimately, I wanted to extract the exact original data from the source (or close enough copy thereof) and have the patterns in a format I considered archival for this limited purpose (.pbm files are trivial to parse and manipulate).&lt;/p&gt;
    &lt;p&gt;Head over to my pattern site to get the patterns for yourself.&lt;/p&gt;
    &lt;p&gt;(Credit for replica Geneva 9pt and Chicago 12pt fonts)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45131538</guid></item><item><title>What If OpenDocument Used SQLite?</title><link>https://www.sqlite.org/affcase1.html</link><description>&lt;doc fingerprint="f7cfb8164ca46ba1"&gt;
  &lt;main&gt;
    &lt;p&gt;Suppose the OpenDocument file format, and specifically the "ODP" OpenDocument Presentation format, were built around SQLite. Benefits would include:&lt;/p&gt;
    &lt;p&gt;Note that this is only a thought experiment. We are not suggesting that OpenDocument be changed. Nor is this article a criticism of the current OpenDocument design. The point of this essay is to suggest ways to improve future file format designs.&lt;/p&gt;
    &lt;p&gt;The OpenDocument file format is used for office applications: word processors, spreadsheets, and presentations. It was originally designed for the OpenOffice suite but has since been incorporated into other desktop application suites. The OpenOffice application has been forked and renamed a few times. This author's primary use for OpenDocument is building slide presentations with either NeoOffice on Mac, or LibreOffice on Linux and Windows.&lt;/p&gt;
    &lt;p&gt;An OpenDocument Presentation or "ODP" file is a ZIP archive containing XML files describing presentation slides and separate image files for the various images that are included as part of the presentation. (OpenDocument word processor and spreadsheet files are similarly structured but are not considered by this article.) The reader can easily see the content of an ODP file by using the "zip -l" command. For example, the following is the "zip -l" output from a 49-slide presentation about SQLite from the 2014 SouthEast LinuxFest conference:&lt;/p&gt;
    &lt;quote&gt;Archive: self2014.odp Length Date Time Name --------- ---------- ----- ---- 47 2014-06-21 12:34 mimetype 0 2014-06-21 12:34 Configurations2/statusbar/ 0 2014-06-21 12:34 Configurations2/accelerator/current.xml 0 2014-06-21 12:34 Configurations2/floater/ 0 2014-06-21 12:34 Configurations2/popupmenu/ 0 2014-06-21 12:34 Configurations2/progressbar/ 0 2014-06-21 12:34 Configurations2/menubar/ 0 2014-06-21 12:34 Configurations2/toolbar/ 0 2014-06-21 12:34 Configurations2/images/Bitmaps/ 54702 2014-06-21 12:34 Pictures/10000000000001F40000018C595A5A3D.png 46269 2014-06-21 12:34 Pictures/100000000000012C000000A8ED96BFD9.png ... 58 other pictures omitted... 13013 2014-06-21 12:34 Pictures/10000000000000EE0000004765E03BA8.png 1005059 2014-06-21 12:34 Pictures/10000000000004760000034223EACEFD.png 211831 2014-06-21 12:34 content.xml 46169 2014-06-21 12:34 styles.xml 1001 2014-06-21 12:34 meta.xml 9291 2014-06-21 12:34 Thumbnails/thumbnail.png 38705 2014-06-21 12:34 Thumbnails/thumbnail.pdf 9664 2014-06-21 12:34 settings.xml 9704 2014-06-21 12:34 META-INF/manifest.xml --------- ------- 10961006 78 files&lt;/quote&gt;
    &lt;p&gt;The ODP ZIP archive contains four different XML files: content.xml, styles.xml, meta.xml, and settings.xml. Those four files define the slide layout, text content, and styling. This particular presentation contains 62 images, ranging from full-screen pictures to tiny icons, each stored as a separate file in the Pictures folder. The "mimetype" file contains a single line of text that says:&lt;/p&gt;
    &lt;quote&gt;application/vnd.oasis.opendocument.presentation&lt;/quote&gt;
    &lt;p&gt;The purpose of the other files and folders is presently unknown to the author but is probably not difficult to figure out.&lt;/p&gt;
    &lt;p&gt;The use of a ZIP archive to encapsulate XML files plus resources is an elegant approach to an application file format. It is clearly superior to a custom binary file format. But using an SQLite database as the container, instead of ZIP, would be more elegant still.&lt;/p&gt;
    &lt;p&gt;A ZIP archive is basically a key/value database, optimized for the case of write-once/read-many and for a relatively small number of distinct keys (a few hundred to a few thousand) each with a large BLOB as its value. A ZIP archive can be viewed as a "pile-of-files" database. This works, but it has some shortcomings relative to an SQLite database, as follows:&lt;/p&gt;
    &lt;p&gt;Incremental update is hard.&lt;/p&gt;
    &lt;p&gt;It is difficult to update individual entries in a ZIP archive. It is especially difficult to update individual entries in a ZIP archive in a way that does not destroy the entire document if the computer loses power and/or crashes in the middle of the update. It is not impossible to do this, but it is sufficiently difficult that nobody actually does it. Instead, whenever the user selects "File/Save", the entire ZIP archive is rewritten. Hence, "File/Save" takes longer than it ought, especially on older hardware. Newer machines are faster, but it is still bothersome that changing a single character in a 50 megabyte presentation causes one to burn through 50 megabytes of the finite write life on the SSD.&lt;/p&gt;
    &lt;p&gt;Startup is slow.&lt;/p&gt;
    &lt;p&gt;In keeping with the pile-of-files theme, OpenDocument stores all slide content in a single big XML file named "content.xml". LibreOffice reads and parses this entire file just to display the first slide. LibreOffice also seems to read all images into memory as well, which makes sense seeing as when the user does "File/Save" it is going to have to write them all back out again, even though none of them changed. The net effect is that start-up is slow. Double-clicking an OpenDocument file brings up a progress bar rather than the first slide. This results in a bad user experience. The situation grows ever more annoying as the document size increases.&lt;/p&gt;
    &lt;p&gt;More memory is required.&lt;/p&gt;
    &lt;p&gt;Because ZIP archives are optimized for storing big chunks of content, they encourage a style of programming where the entire document is read into memory at startup, all editing occurs in memory, then the entire document is written to disk during "File/Save". OpenOffice and its descendants embrace that pattern.&lt;/p&gt;
    &lt;p&gt;One might argue that it is ok, in this era of multi-gigabyte desktops, to read the entire document into memory. But it is not ok. For one, the amount of memory used far exceeds the (compressed) file size on disk. So a 50MB presentation might take 200MB or more RAM. That still is not a problem if one only edits a single document at a time. But when working on a talk, this author will typically have 10 or 15 different presentations up all at the same time (to facilitate copy/paste of slides from past presentations) and so gigabytes of memory are required. Add in an open web browser or two and a few other desktop apps, and suddenly the disk is whirling and the machine is swapping. And even having just a single document is a problem when working on an inexpensive Chromebook retrofitted with Ubuntu. Using less memory is always better.&lt;/p&gt;
    &lt;p&gt;Crash recovery is difficult.&lt;/p&gt;
    &lt;p&gt;The descendants of OpenOffice tend to segfault more often than commercial competitors. Perhaps for this reason, the OpenOffice forks make periodic backups of their in-memory documents so that users do not lose all pending edits when the inevitable application crash does occur. This causes frustrating pauses in the application for the few seconds while each backup is being made. After restarting from a crash, the user is presented with a dialog box that walks them through the recovery process. Managing the crash recovery this way involves lots of extra application logic and is generally an annoyance to the user.&lt;/p&gt;
    &lt;p&gt;Content is inaccessible.&lt;/p&gt;
    &lt;p&gt;One cannot easily view, change, or extract the content of an OpenDocument presentation using generic tools. The only reasonable way to view or edit an OpenDocument document is to open it up using an application that is specifically designed to read or write OpenDocument (read: LibreOffice or one of its cousins). The situation could be worse. One can extract and view individual images (say) from a presentation using just the "zip" archiver tool. But it is not reasonable try to extract the text from a slide. Remember that all content is stored in a single "context.xml" file. That file is XML, so it is a text file. But it is not a text file that can be managed with an ordinary text editor. For the example presentation above, the content.xml file consist of exactly two lines. The first line of the file is just:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;&lt;/quote&gt;
    &lt;p&gt;The second line of the file contains 211792 characters of impenetrable XML. Yes, 211792 characters all on one line. This file is a good stress-test for a text editor. Thankfully, the file is not some obscure binary format, but in terms of accessibility, it might as well be written in Klingon.&lt;/p&gt;
    &lt;p&gt;Let us suppose that instead of using a ZIP archive to store its files, OpenDocument used a very simple SQLite database with the following single-table schema:&lt;/p&gt;
    &lt;quote&gt;CREATE TABLE OpenDocTree( filename TEXT PRIMARY KEY, -- Name of file filesize BIGINT, -- Size of file after decompression content BLOB -- Compressed file content );&lt;/quote&gt;
    &lt;p&gt;For this first experiment, nothing else about the file format is changed. The OpenDocument is still a pile-of-files, only now each file is a row in an SQLite database rather than an entry in a ZIP archive. This simple change does not use the power of a relational database. Even so, this simple change shows some improvements.&lt;/p&gt;
    &lt;p&gt;Surprisingly, using SQLite in place of ZIP makes the presentation file smaller. Really. One would think that a relational database file would be larger than a ZIP archive, but at least in the case of NeoOffice that is not so. The following is an actual screen-scrape showing the sizes of the same NeoOffice presentation, both in its original ZIP archive format as generated by NeoOffice (self2014.odp), and as repacked as an SQLite database using the SQLAR utility:&lt;/p&gt;
    &lt;quote&gt;-rw-r--r-- 1 drh staff 10514994 Jun 8 14:32 self2014.odp -rw-r--r-- 1 drh staff 10464256 Jun 8 14:37 self2014.sqlar -rw-r--r-- 1 drh staff 10416644 Jun 8 14:40 zip.odp&lt;/quote&gt;
    &lt;p&gt;The SQLite database file ("self2014.sqlar") is about a half percent smaller than the equivalent ODP file! How can this be? Apparently the ZIP archive generator logic in NeoOffice is not as efficient as it could be, because when the same pile-of-files is recompressed using the command-line "zip" utility, one gets a file ("zip.odp") that is smaller still, by another half percent, as seen in the third line above. So, a well-written ZIP archive can be slightly smaller than the equivalent SQLite database, as one would expect. But the difference is slight. The key take-away is that an SQLite database is size-competitive with a ZIP archive.&lt;/p&gt;
    &lt;p&gt;The other advantage to using SQLite in place of ZIP is that the document can now be updated incrementally, without risk of corrupting the document if a power loss or other crash occurs in the middle of the update. (Remember that writes to SQLite databases are atomic.) True, all the content is still kept in a single big XML file ("content.xml") which must be completely rewritten if so much as a single character changes. But with SQLite, only that one file needs to change. The other 77 files in the repository can remain unaltered. They do not all have to be rewritten, which in turn makes "File/Save" run much faster and saves wear on SSDs.&lt;/p&gt;
    &lt;p&gt;A pile-of-files encourages content to be stored in a few large chunks. In the case of ODP, there are just four XML files that define the layout of all slides in a presentation. An SQLite database allows storing information in a few large chunks, but SQLite is also adept and efficient at storing information in numerous smaller pieces.&lt;/p&gt;
    &lt;p&gt;So then, instead of storing all content for all slides in a single oversized XML file ("content.xml"), suppose there was a separate table for storing the content of each slide separately. The table schema might look something like this:&lt;/p&gt;
    &lt;quote&gt;CREATE TABLE slide( pageNumber INTEGER, -- The slide page number slideContent TEXT -- Slide content as XML or JSON ); CREATE INDEX slide_pgnum ON slide(pageNumber); -- Optional&lt;/quote&gt;
    &lt;p&gt;The content of each slide could still be stored as compressed XML. But now each page is stored separately. So when opening a new document, the application could simply run:&lt;/p&gt;
    &lt;quote&gt;SELECT slideContent FROM slide WHERE pageNumber=1;&lt;/quote&gt;
    &lt;p&gt;This query will quickly and efficiently return the content of the first slide, which could then be speedily parsed and displayed to the user. Only one page needs to be read and parsed in order to render the first screen, which means that the first screen appears much faster and there is no longer a need for an annoying progress bar.&lt;/p&gt;
    &lt;p&gt;If the application wanted to keep all content in memory, it could continue reading and parsing the other pages using a background thread after drawing the first page. Or, since reading from SQLite is so efficient, the application might instead choose to reduce its memory footprint and only keep a single slide in memory at a time. Or maybe it keeps the current slide and the next slide in memory, to facilitate rapid transitions to the next slide.&lt;/p&gt;
    &lt;p&gt;Notice that dividing up the content into smaller pieces using an SQLite table gives flexibility to the implementation. The application can choose to read all content into memory at startup. Or it can read just a few pages into memory and keep the rest on disk. Or it can read just a single page into memory at a time. And different versions of the application can make different choices without having to make any changes to the file format. Such options are not available when all content is in a single big XML file in a ZIP archive.&lt;/p&gt;
    &lt;p&gt;Splitting content into smaller pieces also helps File/Save operations to go faster. Instead of having to write back the content of all pages when doing a File/Save, the application only has to write back those pages that have actually changed.&lt;/p&gt;
    &lt;p&gt;One minor downside of splitting content into smaller pieces is that compression does not work as well on shorter texts and so the size of the document might increase. But as the bulk of the document space is used to store images, a small reduction in the compression efficiency of the text content will hardly be noticeable, and is a small price to pay for an improved user experience.&lt;/p&gt;
    &lt;p&gt;Once one is comfortable with the concept of storing each slide separately, it is a small step to support versioning of the presentation. Consider the following schema:&lt;/p&gt;
    &lt;quote&gt;CREATE TABLE slide( slideId INTEGER PRIMARY KEY, derivedFrom INTEGER REFERENCES slide, content TEXT -- XML or JSON or whatever ); CREATE TABLE version( versionId INTEGER PRIMARY KEY, priorVersion INTEGER REFERENCES version, checkinTime DATETIME, -- When this version was saved comment TEXT, -- Description of this version manifest TEXT -- List of integer slideIds );&lt;/quote&gt;
    &lt;p&gt;In this schema, instead of each slide having a page number that determines its order within the presentation, each slide has a unique integer identifier that is unrelated to where it occurs in sequence. The order of slides in the presentation is determined by a list of slideIds, stored as a text string in the MANIFEST column of the VERSION table. Since multiple entries are allowed in the VERSION table, that means that multiple presentations can be stored in the same document.&lt;/p&gt;
    &lt;p&gt;On startup, the application first decides which version it wants to display. Since the versionId will naturally increase in time and one would normally want to see the latest version, an appropriate query might be:&lt;/p&gt;
    &lt;quote&gt;SELECT manifest, versionId FROM version ORDER BY versionId DESC LIMIT 1;&lt;/quote&gt;
    &lt;p&gt;Or perhaps the application would rather use the most recent checkinTime:&lt;/p&gt;
    &lt;quote&gt;SELECT manifest, versionId, max(checkinTime) FROM version;&lt;/quote&gt;
    &lt;p&gt;Using a single query such as the above, the application obtains a list of the slideIds for all slides in the presentation. The application then queries for the content of the first slide, and parses and displays that content, as before.&lt;/p&gt;
    &lt;p&gt;(Aside: Yes, that second query above that uses "max(checkinTime)" really does work and really does return a well-defined answer in SQLite. Such a query either returns an undefined answer or generates an error in many other SQL database engines, but in SQLite it does what you would expect: it returns the manifest and versionId of the entry that has the maximum checkinTime.)&lt;/p&gt;
    &lt;p&gt;When the user does a "File/Save", instead of overwriting the modified slides, the application can now make new entries in the SLIDE table for just those slides that have been added or altered. Then it creates a new entry in the VERSION table containing the revised manifest.&lt;/p&gt;
    &lt;p&gt;The VERSION table shown above has columns to record a check-in comment (presumably supplied by the user) and the time and date at which the File/Save action occurred. It also records the parent version to record the history of changes. Perhaps the manifest could be stored as a delta from the parent version, though typically the manifest will be small enough that storing a delta might be more trouble than it is worth. The SLIDE table also contains a derivedFrom column which could be used for delta encoding if it is determined that saving the slide content as a delta from its previous version is a worthwhile optimization.&lt;/p&gt;
    &lt;p&gt;So with this simple change, the ODP file now stores not just the most recent edit to the presentation, but a history of all historic edits. The user would normally want to see just the most recent edition of the presentation, but if desired, the user can now go backwards in time to see historical versions of the same presentation.&lt;/p&gt;
    &lt;p&gt;Or, multiple presentations could be stored within the same document.&lt;/p&gt;
    &lt;p&gt;With such a schema, the application would no longer need to make periodic backups of the unsaved changes to a separate file to avoid lost work in the event of a crash. Instead, a special "pending" version could be allocated and unsaved changes could be written into the pending version. Because only changes would need to be written, not the entire document, saving the pending changes would only involve writing a few kilobytes of content, not multiple megabytes, and would take milliseconds instead of seconds, and so it could be done frequently and silently in the background. Then when a crash occurs and the user reboots, all (or almost all) of their work is retained. If the user decides to discard unsaved changes, they simply go back to the previous version.&lt;/p&gt;
    &lt;p&gt;There are details to fill in here. Perhaps a screen can be provided that displays all historical changes (perhaps with a graph) allowing the user to select which version they want to view or edit. Perhaps some facility can be provided to merge forks that might occur in the version history. And perhaps the application should provide a means to purge old and unwanted versions. The key point is that using an SQLite database to store the content, rather than a ZIP archive, makes all of these features much, much easier to implement, which increases the possibility that they will eventually get implemented.&lt;/p&gt;
    &lt;p&gt;In the previous sections, we have seen how moving from a key/value store implemented as a ZIP archive to a simple SQLite database with just three tables can add significant capabilities to an application file format. We could continue to enhance the schema with new tables, with indexes added for performance, with triggers and views for programming convenience, and constraints to enforce consistency of content even in the face of programming errors. Further enhancement ideas include:&lt;/p&gt;
    &lt;p&gt;An SQLite database has a lot of capability, which this essay has only begun to touch upon. But hopefully this quick glimpse has convinced some readers that using an SQL database as an application file format is worth a second look.&lt;/p&gt;
    &lt;p&gt;Some readers might resist using SQLite as an application file format due to prior exposure to enterprise SQL databases and the caveats and limitations of those other systems. For example, many enterprise database engines advise against storing large strings or BLOBs in the database and instead suggest that large strings and BLOBs be stored as separate files and the filename stored in the database. But SQLite is not like that. Any column of an SQLite database can hold a string or BLOB up to about a gigabyte in size. And for strings and BLOBs of 100 kilobytes or less, I/O performance is better than using separate files.&lt;/p&gt;
    &lt;p&gt;Some readers might be reluctant to consider SQLite as an application file format because they have been inculcated with the idea that all SQL database schemas must be factored into Third Normal Form (3NF) and store only small primitive data types such as strings and integers. Certainly relational theory is important and designers should strive to understand it. But, as demonstrated above, it is often quite acceptable to store complex information as XML or JSON in text fields of a database. Do what works, not what your database professor said you ought to do.&lt;/p&gt;
    &lt;p&gt;In summary, the claim of this essay is that using SQLite as a container for an application file format like OpenDocument and storing lots of smaller objects in that container works out much better than using a ZIP archive holding a few larger objects. To wit:&lt;/p&gt;
    &lt;p&gt;An SQLite database file is approximately the same size, and in some cases smaller, than a ZIP archive holding the same information.&lt;/p&gt;
    &lt;p&gt;The atomic update capabilities of SQLite allow small incremental changes to be safely written into the document. This reduces total disk I/O and improves File/Save performance, enhancing the user experience.&lt;/p&gt;
    &lt;p&gt;Startup time is reduced by allowing the application to read in only the content shown for the initial screen. This largely eliminates the need to show a progress bar when opening a new document. The document just pops up immediately, further enhancing the user experience.&lt;/p&gt;
    &lt;p&gt;The memory footprint of the application can be dramatically reduced by only loading content that is relevant to the current display and keeping the bulk of the content on disk. The fast query capability of SQLite make this a viable alternative to keeping all content in memory at all times. And when applications use less memory, it makes the entire computer more responsive, further enhancing the user experience.&lt;/p&gt;
    &lt;p&gt;The schema of an SQL database is able to represent information more directly and succinctly than a key/value database such as a ZIP archive. This makes the document content more accessible to third-party applications and scripts and facilitates advanced features such as built-in document versioning, and incremental saving of work in progress for recovery after a crash.&lt;/p&gt;
    &lt;p&gt;These are just a few of the benefits of using SQLite as an application file format — the benefits that seem most likely to improve the user experience for applications like OpenOffice. Other applications might benefit from SQLite in different ways. See the Application File Format document for additional ideas.&lt;/p&gt;
    &lt;p&gt;Finally, let us reiterate that this essay is a thought experiment. The OpenDocument format is well-established and already well-designed. Nobody really believes that OpenDocument should be changed to use SQLite as its container instead of ZIP. Nor is this article a criticism of OpenDocument for not choosing SQLite as its container since OpenDocument predates SQLite. Rather, the point of this article is to use OpenDocument as a concrete example of how SQLite can be used to build better application file formats for future projects.&lt;/p&gt;
    &lt;p&gt;This page last modified on 2025-05-12 11:56:41 UTC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45132498</guid></item><item><title>io_uring is faster than mmap</title><link>https://www.bitflux.ai/blog/memory-is-slow-part2/</link><description>&lt;doc fingerprint="eeb8d08f7c322988"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;Sourcing data directly from disk IS faster than caching in memory. I brought receipts. Because hardware got wider but not faster, the old methods don't get you there. You need new tools to use what is scaling and avoid what isn't.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In part 1 I showed how some computer performance factors are scaling exponentially while others have been stagnant for decades. I then asserted, without proof, that sourcing data from disk can be faster than from memory. What follows is the proof.&lt;/p&gt;
    &lt;p&gt;Computer Science dogma says that unused memory should be used to cache things from the filesystem because the disk is slow and memory is fast. Given that disk bandwidth is growing exponentially and memory access latency has stagnated this isn't always true anymore.&lt;/p&gt;
    &lt;head rend="h2"&gt;Experimental set up&lt;/head&gt;
    &lt;p&gt;We need data and something straight forward to do with the data. I used my free will or the illusion thereof to create a benchmark I cleverly call "counting 10s". I write some pseudo random integers between 0 and 20 to a buffer and then count how many of the integers are 10. I want to make sure we are doing all the counting in a single thread to simulate an Amdahl's Law situation.&lt;/p&gt;
    &lt;p&gt;So how fast can we expect this to run? The upper limit would be the memory bandwidth.&lt;/p&gt;
    &lt;p&gt;My testing rig is a server with an old AMD EPYC 7551P 32-Core Processor on a Supermicro H11SSL-i and 96GB of DDR4 2133 MHz and a couple of 1.92TB Samsung PM983a PCIe 3.0 SSDs I pieced together from EBay parts. Given the way this server is configured, the upper limit for memory bandwidth can be calculated as 3 channels * 2133MT/s * 8B/T / 4 numa domains = ~13GB/s for a single thread. It's kind of an odd system but that just makes it more fun to optimize for!&lt;/p&gt;
    &lt;p&gt;The disks are rated at 3.1GB/s read BW each for an upper limit of 6.2GB/s. I made a raid0 volume with 4KB stripe size, formatted the the raid as ext4 with no journaling, and made sure it fully finished initializing the metadata before running the tests.&lt;/p&gt;
    &lt;code&gt;sudo mdadm --create /dev/md0 --level=0 --raid-devices=2 --chunk=4K /dev/nvme1n1 /dev/nvme2n1
sudo mkfs.ext4 -F -L data -O ^has_journal -E lazy_itable_init=0 /dev/md0
sudo mount -o noatime /dev/md0 mnt
&lt;/code&gt;
    &lt;p&gt;We'll use a 50GB dataset for most benchmarking here, because when I started this I thought the test system only had 64GB and it stuck.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple Loop&lt;/head&gt;
    &lt;p&gt;The simple and cleanest way to do this in C would look like this.&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;

// count_10_loop
int main(int argc, char *argv[]) {
    char* filename = argv[1];
    size_t size_bytes = strtoull(argv[2], NULL, 10);
    size_t total_ints = size_bytes / sizeof(int);
    size_t count = 0;

    int fd = open(filename, O_RDONLY);
    int* data = (int*)mmap(NULL, size_bytes, PROT_READ, MAP_SHARED, fd, 0);
 
    for (size_t i = 0; i &amp;lt; total_ints; ++i) {
        if (data[i] == 10) count++;
    }

    printf("Found %ld 10s\n", count);
}
&lt;/code&gt;
    &lt;p&gt;Just mmap() the file which will give us a buffer that we can read from. Then we just loop and count the 10s.&lt;/p&gt;
    &lt;p&gt;Because the point is to benchmark we will integrate some timing mechanisms before we move on.&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;

long get_time_us() {
    struct timeval tv;
    gettimeofday(&amp;amp;tv, NULL);
    return tv.tv_sec * 1000000L + tv.tv_usec;
}

// count_10_loop
int main(int argc, char *argv[]) {
    char* filename = argv[1];
    size_t size_bytes = strtoull(argv[2], NULL, 10);
    size_t total_ints = size_bytes / sizeof(int);
    size_t count = 0;

    int fd = open(filename, O_RDONLY);
    int* data = (int*)mmap(NULL, size_bytes, PROT_READ, MAP_SHARED, fd, 0);
 
    long start = get_time_us();
    for (size_t i = 0; i &amp;lt; total_ints; ++i) {
        if (data[i] == 10) count++;
    }
    long elapsed = get_time_us() - start;

    printf("simple loop found %ld 10s processed at %0.2f GB/s\n", count, (double)(size_bytes/1073741824)/((double)elapsed/1.0e6));
}
&lt;/code&gt;
    &lt;p&gt;For the first run we're going to be reading from the disk. The disk/filesystem read is going to limit the performance before the memory bandwidth can.&lt;/p&gt;
    &lt;code&gt;â¯ sudo  ./count_10_loop ./mnt/datafile.bin 53687091200
simple loop found 167802249 10s processed at 0.61 GB/s
&lt;/code&gt;
    &lt;p&gt;As expected, it's not anywhere near memory speeds because as everyone knows, disk is slow. We can look at the system and confirm that the first run cached the data to memory.&lt;/p&gt;
    &lt;p&gt;Our expectation is that the second run will be faster because the data is already in memory and as everyone knows, memory is fast.&lt;/p&gt;
    &lt;code&gt;â¯ sudo  ./count_10_loop ./mnt/datafile.bin 53687091200
simple loop found 167802249 10s processed at 3.71 GB/s
&lt;/code&gt;
    &lt;p&gt;It is faster, but clearly thatâs slower than the memory can feed it to the processor. What bottleneck might we be hitting? This speed does look possibly correlated to the instructions per second limit for this generation of CPU (between 2GHz * 1.5 IPC = 3G and 3GHz boost * 1.5 IPC = 4.5G instructions per second).&lt;/p&gt;
    &lt;p&gt;We can use perf to see if the CPU is using vector instructions, if not then the actual compute is the bottleneck.&lt;/p&gt;
    &lt;code&gt;Percentâ      test     %rbp,%rbp
       â    â je       84
       â      lea      (%rbx,%rbp,4),%rcx
       â      mov      %rbx,%rax
       â      xor      %ebp,%ebp
       â      nop
       â70:   xor      %edx,%edx
  1.31 â      cmpl     $0xa,(%rax)
 42.38 â      sete     %dl
 45.72 â      add      $0x4,%rax
  0.01 â      add      %rdx,%rbp
 10.42 â      cmp      %rax,%rcx
  0.16 â    â jne      70
       â84:   xor      %eax,%eax
       â      shr      $0x14,%r12
       â    â call     get_time_us
       â      pxor     %xmm0,%xmm0
       â      pxor     %xmm1,%xmm1
&lt;/code&gt;
    &lt;p&gt;Confirmed. We're running non-vectorized instructions, with a single thread counting that's as fast as it can go with a 2GHz CPU. Well crap. Weâve hit our first non-exponential limit. Even a brand new CPU running this machine code would probably struggle to do much better than a 50% improvement, still well below the memory bandwidth limit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unrolling the loop&lt;/head&gt;
    &lt;p&gt;Good news is this code can definitely be vectorized if we help the compiler. Unroll the loop!&lt;/p&gt;
    &lt;p&gt;We're gonna make it very obvious to the compiler that it's safe to use vector instructions which could process our integers up to 8x faster.&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;

long get_time_us() {
    struct timeval tv;
    gettimeofday(&amp;amp;tv, NULL);
    return tv.tv_sec * 1000000L + tv.tv_usec;
}

// count_10_unrolled
int main(int argc, char *argv[]) {
    char* filename = argv[1];
    size_t size_bytes = strtoull(argv[2], NULL, 10);
    size_t total_ints = size_bytes / sizeof(int);
    size_t count = 0;

    int fd = open(filename, O_RDONLY);
    void* buffer = mmap(NULL, size_bytes, PROT_READ, MAP_SHARED, fd, 0);
 
    // Get the compiler to align the buffer
    const int * __restrict data = (const int * __restrict)__builtin_assume_aligned(buffer, 4096);
    uint64_t c0=0, c1=0, c2=0, c3=0,
            c4=0, c5=0, c6=0, c7=0,
            c8=0, c9=0, c10=0, c11=0,
            c12=0, c13=0, c14=0, c15=0;

    long start = get_time_us();
    // Unrolling the compiler knows it can use a vector unit like AVX2 to process
    for (size_t i = 0; i &amp;lt; total_ints; i += 16) {
        // removed 'if' to get it to be branchless: each compares to 10, adds 0 or 1
        c0  += (unsigned)(data[i+ 0] == 10);
        c1  += (unsigned)(data[i+ 1] == 10);
        c2  += (unsigned)(data[i+ 2] == 10);
        c3  += (unsigned)(data[i+ 3] == 10);
        c4  += (unsigned)(data[i+ 4] == 10);
        c5  += (unsigned)(data[i+ 5] == 10);
        c6  += (unsigned)(data[i+ 6] == 10);
        c7  += (unsigned)(data[i+ 7] == 10);
        c8  += (unsigned)(data[i+ 8] == 10);
        c9  += (unsigned)(data[i+ 9] == 10);
        c10 += (unsigned)(data[i+10] == 10);
        c11 += (unsigned)(data[i+11] == 10);
        c12 += (unsigned)(data[i+12] == 10);
        c13 += (unsigned)(data[i+13] == 10);
        c14 += (unsigned)(data[i+14] == 10);
        c15 += (unsigned)(data[i+15] == 10);
    }

    // pairwise reduce to help some compilers schedule better
    uint64_t s0 = c0 + c1,   s1 = c2 + c3,   s2 = c4 + c5,   s3 = c6 + c7;
    uint64_t s4 = c8 + c9,   s5 = c10 + c11, s6 = c12 + c13, s7 = c14 + c15;
    uint64_t t0 = s0 + s1,   t1 = s2 + s3,   t2 = s4 + s5,   t3 = s6 + s7;

    count = (t0 + t1) + (t2 + t3);
    long elapsed = get_time_us() - start;

    printf("unrolled loop found %ld 10s processed at %0.2f GB/s\n", count, (double)(size_bytes/1073741824)/((double)elapsed/1.0e6));
}
&lt;/code&gt;
    &lt;p&gt;Check if we now have vectorized instructions with &lt;code&gt;perf&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;Percentâ       movq      %xmm0,%rcx
       â       movdqa    %xmm7,%xmm14
       â       pxor      %xmm0,%xmm0
       â       nop
       â e8:   movdqa    %xmm6,%xmm4
  0.30 â       movdqa    %xmm6,%xmm3
  0.12 â       movdqa    %xmm6,%xmm2
  0.35 â       add       $0x1,%rdx
  1.54 â       pcmpeqd   (%rax),%xmm4
 54.64 â       pcmpeqd   0x10(%rax),%xmm3
  1.62 â       movdqa    %xmm6,%xmm1
  0.99 â       add       $0x40,%rax
  0.12 â       pcmpeqd   -0x20(%rax),%xmm2
  3.03 â       pcmpeqd   -0x10(%rax),%xmm1
  1.32 â       pand      %xmm5,%xmm4
  1.25 â       pand      %xmm5,%xmm3
  1.55 â       movdqa    %xmm4,%xmm15
  0.24 â       punpckhdq %xmm0,%xmm4

&lt;/code&gt;
    &lt;p&gt;Confirmed. We're using 128bit vector instructions, this should be up to 4x faster than the original.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;NOTE: These are 128-bit vector instructions, but I expected 256-bit. I dug deeper here and found claims that Gen1 EPYC had unoptimized 256-bit instructions. I forced the compiler to use 256-bit instructions and found it was actually slower. Looks like the compiler was smart enough to know that here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let's benchmark this unrolled version with the data as page cache in memory.&lt;/p&gt;
    &lt;code&gt;â¯ sudo  ./count_10_unrolled ./mnt/datafile.bin 53687091200
unrolled loop found 167802249 10s processed at 5.51 GB/s
&lt;/code&gt;
    &lt;p&gt;We're still nowhere close to hitting the memory bus speed limit of 13GB/s but 50% faster than the original is a win. There must be some other bottleneck.&lt;/p&gt;
    &lt;head rend="h2"&gt;Can the SSDs beat that?&lt;/head&gt;
    &lt;p&gt;5.51GB/s? On paper the SSDs can read at 6.2GB/s, but the first run from disk only did 0.61GB/s. How can I meet or beat this performance sourcing the data directly from disk?&lt;/p&gt;
    &lt;p&gt;Consider how the default mmap() mechanism works, it is a background IO pipeline to transparently fetch the data from disk. When you read the empty buffer from userspace it triggers a fault, the kernel handles the fault by reading the data from the filesystem, which then queues up IO from disk. Unfortunately these legacy mechanisms just aren't set up for serious high performance IO. Note that at 610MB/s it's faster than what a disk SATA can do. On the other hand, it only managed 10% of our disk's potential. Clearly we're going to have to do something else.&lt;/p&gt;
    &lt;p&gt;SSDs don't just automatically read data at multigigabyte speeds. You need to put some real effort into an IO pipeline to get serious performance.&lt;/p&gt;
    &lt;p&gt;I made a io_uring based IO engine, a kind of userspace driver, that can hit these speeds. The main thread will request data, the IO engine will handle the IO, then the main thread will do the counting when the data is in a buffer. We will use a set of queues to manage the IO requests, responses, and buffers. The IO engine will start 6 workers, target a queue depth of 8192, and have a buffer size of 16KB.&lt;/p&gt;
    &lt;p&gt;I wish I had tighter code here, but A) I didnât have time to clean it up B) some of the complexity is intractable. The IO engine code was a lot to scroll through so I moved it to github link&lt;/p&gt;
    &lt;code&gt;#include "io_engine.h"
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;getopt.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;

#define DEFAULT_WORKERS 6
#define DEFAULT_BLOCK_SIZE 16384
#define DEFAULT_QUEUE_DEPTH 8192

// Count the number of "10" (int format) in the buffer
static inline size_t count_tens_unrolled(void* data, size_t size_bytes) {
    const size_t total = size_bytes / sizeof(int);
    // Get the compiler to align the buffer
    const int * __restrict p = (const int * __restrict)__builtin_assume_aligned(data, 4096);
    uint64_t c0=0, c1=0, c2=0, c3=0,
            c4=0, c5=0, c6=0, c7=0,
            c8=0, c9=0, c10=0, c11=0,
            c12=0, c13=0, c14=0, c15=0;

    // Unrolling the compiler knows it can use a vector unit like AVX2 to process
    for (size_t i = 0; i &amp;lt; total; i += 16) {
        // removed 'if' to get it to be branchless: each compares to 10, adds 0 or 1
        c0  += (unsigned)(p[i+ 0] == 10);
        c1  += (unsigned)(p[i+ 1] == 10);
        c2  += (unsigned)(p[i+ 2] == 10);
        c3  += (unsigned)(p[i+ 3] == 10);
        c4  += (unsigned)(p[i+ 4] == 10);
        c5  += (unsigned)(p[i+ 5] == 10);
        c6  += (unsigned)(p[i+ 6] == 10);
        c7  += (unsigned)(p[i+ 7] == 10);
        c8  += (unsigned)(p[i+ 8] == 10);
        c9  += (unsigned)(p[i+ 9] == 10);
        c10 += (unsigned)(p[i+10] == 10);
        c11 += (unsigned)(p[i+11] == 10);
        c12 += (unsigned)(p[i+12] == 10);
        c13 += (unsigned)(p[i+13] == 10);
        c14 += (unsigned)(p[i+14] == 10);
        c15 += (unsigned)(p[i+15] == 10);
    }

    // pairwise reduce to help some compilers schedule better
    uint64_t s0 = c0 + c1,   s1 = c2 + c3,   s2 = c4 + c5,   s3 = c6 + c7;
    uint64_t s4 = c8 + c9,   s5 = c10 + c11, s6 = c12 + c13, s7 = c14 + c15;
    uint64_t t0 = s0 + s1,   t1 = s2 + s3,   t2 = s4 + s5,   t3 = s6 + s7;

    return (t0 + t1) + (t2 + t3);
}

int main(int argc, char *argv[]) {
    char* filename = argv[1];
    size_t size_bytes = strtoull(argv[2], NULL, 10);

    // Set up the io engine
    ioengine_t* na = ioengine_alloc(filename, size_bytes, DEFAULT_QUEUE_DEPTH, DEFAULT_BLOCK_SIZE, DEFAULT_WORKERS);

    sleep(1);

    // Use the background workers to read file directly
    size_t total_blocks = na-&amp;gt;file_size / na-&amp;gt;block_size;
    uint64_t uid = 1;
    size_t count = 0;

    long start = get_time_us();

    // Read all blocks
    size_t blocks_queued = 0;
    size_t blocks_read = 0;
    int buffer_queued = 0;
    while (blocks_read &amp;lt; total_blocks) {
        //// Queue IO phase //////
        //     Do we have more blocks to queue up?
        if (buffer_queued &amp;lt; na-&amp;gt;num_io_buffers/2 &amp;amp;&amp;amp; blocks_queued &amp;lt;= total_blocks) {
            // Calculate how many blocks on average we want our workers to queue up
            size_t free_buffers = (size_t)(na-&amp;gt;num_io_buffers - buffer_queued - 4); // hold back a few buffers
            size_t blocks_remaining = total_blocks - blocks_queued;  // how many blocks have we not queued
            size_t blocks_to_queue = free_buffers &amp;gt; blocks_remaining ? blocks_remaining : free_buffers;
            int blocks_to_queue_per_worker = (int) (blocks_to_queue + na-&amp;gt;num_workers - 1) / na-&amp;gt;num_workers;
            // Iterate through workers and assign work
            for (int i = 0; i &amp;lt; na-&amp;gt;num_workers; i++) {
                worker_thread_data_t* worker = &amp;amp;na-&amp;gt;workers[i];
                // Try to queue N blocks to this worker
                for (int j = 0; j &amp;lt; blocks_to_queue_per_worker; j++) {
                    if (blocks_queued == total_blocks) break;
                    int bgio_tail = worker-&amp;gt;bgio_tail;
                    int bgio_head = worker-&amp;gt;bgio_head;
                    int bgio_next = (bgio_tail + 1) % worker-&amp;gt;num_max_bgio;
                    int next_bhead = (worker-&amp;gt;buffer_head + 1) % worker-&amp;gt;num_max_bgio;
                    if (bgio_next == bgio_head) break;  // queue for send requests is full
                    if (next_bhead == worker-&amp;gt;buffer_tail) break; // queue for recieving completed IO is full
                    // Queue this block with the worker.  We have to track which buffer it's going to.
                    int buffer_idx = worker-&amp;gt;buffer_start_idx + worker-&amp;gt;buffer_head;
                    na-&amp;gt;buffer_state[buffer_idx] = BUFFER_PREFETCHING;
                    worker-&amp;gt;bgio_uids[bgio_tail] = (uid++)&amp;lt;&amp;lt;16; // unique id helps track IOs in io_uring, we encode 4 bytes later
                    worker-&amp;gt;bgio_buffer_idx[bgio_tail] = buffer_idx;
                    worker-&amp;gt;bgio_block_idx[bgio_tail] = blocks_queued++;  // block sized index into file
                    worker-&amp;gt;bgio_queued[bgio_tail] = -1;  // Requested but not yet queued
                    int next_tail = (bgio_tail + 1) % worker-&amp;gt;num_max_bgio;
                    worker-&amp;gt;bgio_tail = next_tail;
                    // Log the buffer in an ordered queue for us to read
                    worker-&amp;gt;complete_ring[worker-&amp;gt;buffer_head] = buffer_idx;
                    worker-&amp;gt;buffer_head = next_bhead;
                    buffer_queued++;
                }
                // Tell the worker to submit IOs as a group
                worker-&amp;gt;bgio_submit++;
            }
        }

        //// Completion Phase //////
        //     Iterate through worker and check if they have complete IOs
        for (int i = 0; i &amp;lt; na-&amp;gt;num_workers; i++) {
            worker_thread_data_t* worker = &amp;amp;na-&amp;gt;workers[i];
            int current = worker-&amp;gt;buffer_tail;
            // We know what IO's we're waiting on, but we have to poll
            //  to see if they are done.
            for (int scan = 0; scan &amp;lt; worker-&amp;gt;num_max_bgio; scan++) {
                // Scan until we get to the end of the list
                if (current == worker-&amp;gt;buffer_head) break;
                int buffer_idx = worker-&amp;gt;complete_ring[current];
                int state = na-&amp;gt;buffer_state[buffer_idx];
                if (state == BUFFER_PREFETCHED) {
                    // This buffer is completed - Process this buffer.
                    count += count_tens_unrolled(na-&amp;gt;io_buffers[buffer_idx], na-&amp;gt;block_size);
                    na-&amp;gt;buffer_state[buffer_idx] = BUFFER_UNUSED;
                    blocks_read++;
                    buffer_queued--;
                }
                current = (current + 1) % worker-&amp;gt;num_max_bgio;
            }
            // IO's might have been completed out of order, advance the tail when we can
            current = worker-&amp;gt;buffer_tail;
            while (current != worker-&amp;gt;buffer_head) {
                int buffer_idx = worker-&amp;gt;complete_ring[current];
                int state = na-&amp;gt;buffer_state[buffer_idx];
                if (state != BUFFER_UNUSED) break;
                current = (current + 1) % worker-&amp;gt;num_max_bgio;
            }
            worker-&amp;gt;buffer_tail = current;
            worker-&amp;gt;bgio_submit++;  // probably unnecessary
        }
    }
    long elapsed = get_time_us() - start;
    printf("diskbased found %ld 10s processed at %0.2f GB/s\n", count, (double)(size_bytes/1073741824)/((double)elapsed/1.0e6));

    // Cleanup I/O system
    ioengine_free(na);

    return 0;
}
&lt;/code&gt;
    &lt;p&gt;I hope all this extra code makes it faster.&lt;/p&gt;
    &lt;code&gt;â¯ sudo ./diskbased/benchmark ./mnt/datafile.bin 53687091200
diskbased found 167802249 10s processed at 5.81 GB/s
&lt;/code&gt;
    &lt;p&gt;Boom! Disk is faster than memory! It takes several hundred lines of code but now we can source the data from my SSDs faster than the copy from the page cache in memory.&lt;/p&gt;
    &lt;head rend="h2"&gt;So what's going on here?&lt;/head&gt;
    &lt;p&gt;Of course my 6GB/s disk stripe isnât actually faster than the memory bus, even on this weird hack of a system. So what is happening? Where is the bottleneck? It's got to be the way the data is being read from the page cache in memory.&lt;/p&gt;
    &lt;p&gt;What if we replace the mmap() with a read() from disk into a preallocated buffer. That way we can measure the counting with the data in-memory without any page cache related overhead mmap() can introduce.&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;sys/stat.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

long get_time_us() {
    struct timeval tv;
    gettimeofday(&amp;amp;tv, NULL);
    return tv.tv_sec * 1000000L + tv.tv_usec;
}

int main(int argc, char *argv[]) {
    char* filename = argv[1];
    size_t size_bytes = strtoull(argv[2], NULL, 10);
    size_t total_ints = size_bytes / sizeof(int);
    size_t count = 0;

    int fd = open(filename, O_RDONLY|O_DIRECT);
    void *buf;
    posix_memalign(&amp;amp;buf, 4096, size_bytes);
    int *data = buf;

    size_t off = 0;
    while (off &amp;lt; size_bytes) {
        ssize_t n = read(fd, (char*)data + off, size_bytes - off);
        off += (size_t)n;   // YOLO: assume n &amp;gt; 0 until done
    }

    long start = get_time_us();
    for (size_t i = 0; i &amp;lt; total_ints; ++i) {
        if (data[i] == 10) count++;
    }
    long elapsed = get_time_us() - start;

    printf("simple loop %ld 10s processed at %0.2f GB/s\n",
           count,
           (double)(size_bytes/1073741824)/((double)elapsed/1.0e6));


    // Get the compiler to align the buffer
    const int * __restrict p = (const int * __restrict)__builtin_assume_aligned((void*)data, 4096);
    uint64_t c0=0, c1=0, c2=0, c3=0,
            c4=0, c5=0, c6=0, c7=0,
            c8=0, c9=0, c10=0, c11=0,
            c12=0, c13=0, c14=0, c15=0;

    start = get_time_us();
    // Unrolling the compiler knows it can use a vector unit like AVX2 to process
    for (size_t i = 0; i &amp;lt; total_ints; i += 16) {
        // removed 'if' to get it to be branchless: each compares to 10, adds 0 or 1
        c0  += (unsigned)(p[i+ 0] == 10);
        c1  += (unsigned)(p[i+ 1] == 10);
        c2  += (unsigned)(p[i+ 2] == 10);
        c3  += (unsigned)(p[i+ 3] == 10);
        c4  += (unsigned)(p[i+ 4] == 10);
        c5  += (unsigned)(p[i+ 5] == 10);
        c6  += (unsigned)(p[i+ 6] == 10);
        c7  += (unsigned)(p[i+ 7] == 10);
        c8  += (unsigned)(p[i+ 8] == 10);
        c9  += (unsigned)(p[i+ 9] == 10);
        c10 += (unsigned)(p[i+10] == 10);
        c11 += (unsigned)(p[i+11] == 10);
        c12 += (unsigned)(p[i+12] == 10);
        c13 += (unsigned)(p[i+13] == 10);
        c14 += (unsigned)(p[i+14] == 10);
        c15 += (unsigned)(p[i+15] == 10);
    }

    // pairwise reduce to help some compilers schedule better
    uint64_t s0 = c0 + c1,   s1 = c2 + c3,   s2 = c4 + c5,   s3 = c6 + c7;
    uint64_t s4 = c8 + c9,   s5 = c10 + c11, s6 = c12 + c13, s7 = c14 + c15;
    uint64_t t0 = s0 + s1,   t1 = s2 + s3,   t2 = s4 + s5,   t3 = s6 + s7;

    count = (t0 + t1) + (t2 + t3);
    elapsed = get_time_us() - start;

    printf("unrolled loop %ld 10s processed at %0.2f GB/s\n",
           count,
           (double)(size_bytes/1073741824)/((double)elapsed/1.0e6));
}
&lt;/code&gt;
    &lt;p&gt;If we keep the dataset smaller than a numa domain and we bind this to a single numa node to prevent numa overheads we see that the theoretical memory bandwidth we projected seems to be the primary bottleneck for the unrolled loop as we hoped to see at the outset.&lt;/p&gt;
    &lt;code&gt;â¯  sudo numactl --cpunodebind=0   ./in_ram mnt/datafile.bin 2147483648
simple loop 6709835 10s processed at 4.76 GB/s
unrolled loop 6709835 10s processed at 13.04 GB/s
&lt;/code&gt;
    &lt;p&gt;But this isn't useful to compare the with the other runs with the 50GB dataset. However if we do the full 50GB dataset the performance suffers. We have to get much of the data across numa domains which is going to be higher cost.&lt;/p&gt;
    &lt;code&gt;â¯ sudo ./in_ram ./mnt/datafile.bin 53687091200
simple loop 167802249 10s processed at 3.76 GB/s
unrolled loop 167802249 10s processed at 7.90 GB/s
&lt;/code&gt;
    &lt;p&gt;Comparing the results of "fully in-memory (50GB)" which is pre-loaded in memory before measuring against the "unrolled loop" that is only cached in memory we see 40% overhead. That's 2.75 seconds out of 9 seconds that was spent waiting on the caching system instead of counting. Why so much?&lt;/p&gt;
    &lt;p&gt;mmap()&lt;/p&gt;
    &lt;p&gt;The mmap() call presents the process with a buffer that is a blank slate even when the data is already in memory. The buffer is populated page by page as it's accessed from the page cache. This isn't a copy, it's just the operating system mapping the cached memory into the process. This costs more than it might seem. The worst case with mmap() the counting has to pause at every 4KB page boundary while the kernel processes a fault, tracks down the page of data in the page cache, then updates the page table of the process to insert the memory into the process. Fundamentally this is a process that is limited by the memory latency, not the CPU speed or memory bandwidth. With the potential for TLB walks and searching lists that track the page cache, weâre taking potentially dozens of CPU cache misses and several microseconds of waiting on memory for every 4KB page.&lt;/p&gt;
    &lt;p&gt;direct IO&lt;/p&gt;
    &lt;p&gt;Using our direct from disk approach uses pipelines and streams which avoids the kind of memory latency dominated bottleneck that mmap() has. In our case we're limited by the bandwidth of our disks yet because of the pipelining, the larger latency of the IOs doesn't get in the critical path of the counting very much. Allowing for higher throughput.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scaling&lt;/head&gt;
    &lt;p&gt;Consider the implications of these experiments as we scale. The well vetted solution to get data from memory to a process is slower than using the disk directly. This isn't because the memory is slower than the disk. The memory has higher bandwidth than the disk, not by an order of magnitude, but a decent margin. But the latency of the memory is orders of magnitude lower than the disk. Nevertheless the way the data in memory is accessed is the culprit. Its a synchronous approach that assumes memory operations are cheap and low latency. These accesses add up and it ends up waiting on memory latencies. The disk method on the other hand is as a streaming approach built to leverage bandwidth and hide latencies.&lt;/p&gt;
    &lt;p&gt;extending the existing rig&lt;/p&gt;
    &lt;p&gt;If I got a few more of these disks I could push the IO bandwidth to be greater than the 13GB/s per thread memory bandwidth limit. IO is DMA'ed to buffers that are pretty small compared to the total dataset. These buffers scale with the throughput capabilities of the CPU and the disks, not the dataset size. The buffers can be located in a single numa domain allowing us to avoid the overhead of accessing the buffers between NUMA domains. Add more disks to this system I might be able to create a disk based solution to count at the full 13GB/s rather than be limited to the 7.90GB/s we see with the in memory example at the full 50GB dataset. With such a system our throughput would not be affected by the dataset size, unlike the in-memory case, which has numa overhead and eventually runs out of memory to scale.&lt;/p&gt;
    &lt;p&gt;faster than memory is possible&lt;/p&gt;
    &lt;p&gt;On a proper modern server the CPUs will let you do IO directly to the L3 cache, bypassing memory altogether. Because PCIe bandwidth is higher than memory bandwidth, on paper we could even get more max bandwidth than we can get from memory if we carefully pin the buffers into the CPU cache. I haven't confirm this works in practice, however, it could be made to work and is the sort of thing that CPU designs will be forced to lean into to push performance forward.&lt;/p&gt;
    &lt;p&gt;memory is changing too&lt;/p&gt;
    &lt;p&gt;This isn't just about disks vs memory. Similar techniques and principles apply to memory. Memory bandwidth is still scaling even if the latency is not. This means to take advantage of memory performance you have to actually treat it more like a disk and less like Random Access Memory. To scale performance with generational updates you have to make sure to stream data from memory into the CPU caches in blocks, similar to how data is streamed from disk to memory. If not you end up with 90s level memory throughput. A custom mechanism to cache data in memory could easily avoid the memory latency problems seen with the default mmap() solution with much less code than the io_uring solution.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is this worth it?&lt;/head&gt;
    &lt;p&gt;I'm not going to say that going to the effort of implementing something like this is always worth it. The mmap() method is sure elegant from a coding perspective, especially when compared to all the code I had to write to get the io_uring setup working. Sometimes the simple way is the way to go.&lt;/p&gt;
    &lt;p&gt;Is using 6 cores of IO for 1 core of compute is always the right answer? Probably not. This was an extreme situation to prove a point. In realworld situations you'll need to look at the tradeoffs and decide what's best for your use case. Correctly understanding the strengths and weaknesses of the hardware can open up a number of possibilities where you can get a lot more performance for a lot less money.&lt;/p&gt;
    &lt;p&gt;The kind of overhead demonstrated with mmap() isnât going to go away, new hardware isn't going to fix it. At the same time disk bandwidth and the number of cores are scaling each generation. But doing things that scale performance with new technology is going to take extra code and effort.&lt;/p&gt;
    &lt;p&gt;But don't just blow this stuff off. Sure you can dedicate a server with 3TB of memory to serve 10K client connections. Memory in the cloud is like ~$5/GB/month, if you can afford it, then you do you. However it is worth considering that humanity doesn't have the silicon fabs or the power plants to support this for every moron vibe coder out there making an app. I figure either the karmic debt to the planet, or a vengeful AI demigod hungry for silicon and electricity will come for those that don't heed this warning, eventually. Either way my conscience is clear.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recap&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Memory is slow - when you use it oldschool.&lt;/item&gt;
      &lt;item&gt;Disk is fast - when you are clever with it.&lt;/item&gt;
      &lt;item&gt;Test the dogma - compounded exponentials are flipping somethings from true to false.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bad news is that this cleverness requires extra code and effort.&lt;/p&gt;
    &lt;p&gt;Good news is we now have AI to write and test the extra code this cleverness requires.&lt;/p&gt;
    &lt;p&gt;Better news is that, for those that are willing to learn, AI's don't do this unless you know how to ask them.&lt;/p&gt;
    &lt;p&gt;Lean into things that scale, avoid things that donât.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Time&lt;/head&gt;
    &lt;p&gt;What will be revealed in the next episode?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Is O(ân) actually faster than O(log n)? Will the foundations of Computer Science survive this unveiling?&lt;/item&gt;
      &lt;item&gt;Will traditional code be consumed into the latent space of our AI overlords?&lt;/item&gt;
      &lt;item&gt;Is AI hiding these performance gains from me? Is AI even capable of writing optimized code?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Jared Hulbert&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A few notes for the "um actually" haters commenting on Hacker News:&lt;/p&gt;
      &lt;item&gt;This is not and does not claim to be an academic paper.&lt;/item&gt;
      &lt;item&gt;I do not intend to prove that NAND is a drop in replacement for DRAM.&lt;/item&gt;
      &lt;item&gt;Tis but a humble and hopefully fun exercise in exploring the limits and trends of modern hardware and the tradeoffs needed to maximize performance.&lt;/item&gt;
      &lt;item&gt;As I stated before I have no problem with your choice to ignore this and write lazy code that will perform just as fast on new hardware in 15 years as it does on todays hardware. In fact I applaud your choice. Jeff Bezos has an orbital yacht to build, someone has to pay for it, why not you?&lt;/item&gt;
      &lt;item&gt;I am not an AI. I am a human with a computer that don't write perfect.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;source code can be found here.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45132710</guid></item><item><title>What Is the Fourier Transform?</title><link>https://www.quantamagazine.org/what-is-the-fourier-transform-20250903/</link><description>&lt;doc fingerprint="b00b98134830c362"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Is the Fourier Transform?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;As we listen to a piece of music, our ears perform a calculation. The high-pitched flutter of the flute, the middle tones of the violin, and the low hum of the double bass fill the air with pressure waves of many different frequencies. When the combined sound wave descends through the ear canal and into the spiral-shaped cochlea, hairs of different lengths resonate to the different pitches, separating the messy signal into buckets of elemental sounds.&lt;/p&gt;
    &lt;p&gt;It took mathematicians until the 19th century to master this same calculation.&lt;/p&gt;
    &lt;p&gt;In the early 1800s, the French mathematician Jean-Baptiste Joseph Fourier discovered a way to take any function and decompose it into a set of fundamental waves, or frequencies. Add these constituent frequencies back together, and you’ll get your original function. The technique, today called the Fourier transform, allowed the mathematician — previously an ardent proponent of the French revolution — to spur a mathematical revolution as well.&lt;/p&gt;
    &lt;p&gt;Out of the Fourier transform grew an entire field of mathematics, called harmonic analysis, which studies the components of functions. Soon enough, mathematicians began to discover deep connections between harmonic analysis and other areas of math and physics, from number theory to differential equations to quantum mechanics. You can also find the Fourier transform at work in your computer, allowing you to compress files, enhance audio signals and more.&lt;/p&gt;
    &lt;p&gt;“It’s hard to overestimate the influence of Fourier analysis in math,” said Leslie Greengard of New York University and the Flatiron Institute. “It touches almost every field of math and physics and chemistry and everything else.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Flames of Passion&lt;/head&gt;
    &lt;p&gt;Fourier was born in 1768 amid the chaos of prerevolutionary France. Orphaned at 10 years old, he was educated at a convent in his hometown of Auxerre. He spent the next decade conflicted about whether to dedicate his life to religion or to math, eventually abandoning his religious training and becoming a teacher. He also promoted revolutionary efforts in France until, during the Reign of Terror in 1794, the 26-year-old was arrested and imprisoned for expressing beliefs that were considered anti-revolutionary. He was slated for the guillotine.&lt;/p&gt;
    &lt;p&gt;Before he could be executed, the Terror came to an end. And so, in 1795, he returned to teaching mathematics. A few years later, he was appointed as a scientific adviser to Napoleon Bonaparte and joined his army during the invasion of Egypt. It was there that Fourier, while also pursuing research into Egyptian antiquities, began the work that would lead him to develop his transform: He wanted to understand the mathematics of heat conduction. By the time he returned to France in 1801 — shortly before the French army was driven out of Egypt, the stolen Rosetta stone surrendered to the British — Fourier could think of nothing else.&lt;/p&gt;
    &lt;p&gt;If you heat one side of a metal rod, the heat will spread until the whole rod has the same temperature. Fourier argued that the distribution of heat through the rod could be written as a sum of simple waves. As the metal cools, these waves lose energy, causing them to smooth out and eventually disappear. The waves that oscillate more quickly — meaning they have more energy — decay first, followed eventually by the lower frequencies. It’s like a symphony that ends with each instrument fading to silence, from piccolos to tubas.&lt;/p&gt;
    &lt;p&gt;The proposal was radical. When Fourier presented it at a meeting of the Paris Institute in 1807, the renowned mathematician Joseph-Louis Lagrange reportedly declared the work “nothing short of impossible.”&lt;/p&gt;
    &lt;p&gt;What troubled his peers most were strange cases where the heat distribution might be sharply irregular — like a rod that is exactly half cold and half hot. Fourier maintained that the sudden jump in temperature could still be described mathematically: It would just require adding infinitely many simpler curves instead of a finite number. But most mathematicians at the time believed that no number of smooth curves could ever add up to a sharp corner.&lt;/p&gt;
    &lt;p&gt;Today, we know that Fourier was broadly right.&lt;/p&gt;
    &lt;p&gt;“You can represent anything as a sum of these very, very simple oscillations,” said Charles Fefferman, a mathematician at Princeton University. “It’s known that if you have a whole lot of tuning forks, and you set them perfectly, they can produce Beethoven’s Ninth Symphony.” The process only fails for the most bizarre functions, like those that oscillate wildly no matter how much you zoom in on them.&lt;/p&gt;
    &lt;p&gt;So how does the Fourier transform work?&lt;/p&gt;
    &lt;head rend="h2"&gt;A Well-Trained Ear&lt;/head&gt;
    &lt;p&gt;Performing a Fourier transform is akin to sniffing a perfume and distinguishing its list of ingredients, or hearing a complex jazzy chord and distinguishing its constituent notes.&lt;/p&gt;
    &lt;p&gt;Mathematically, the Fourier transform is a function. It takes a given function — which can look complicated — as its input. It then produces as its output a set of frequencies. If you write down the simple sine and cosine waves that have these frequencies, and then add them together, you’ll get the original function.&lt;/p&gt;
    &lt;p&gt;To achieve this, the Fourier transform essentially scans all possible frequencies and determines how much each contributes to the original function. Let’s look at a simple example.&lt;/p&gt;
    &lt;p&gt;Consider the following function:&lt;/p&gt;
    &lt;p&gt;The Fourier transform checks how much each frequency contributes to this original function. It does so by multiplying waves together. Here’s what happens if we multiply the original by a sine wave with a frequency of 3:&lt;/p&gt;
    &lt;p&gt;There are lots of large peaks, which means the frequency 3 contributes to the original function. The average height of the peaks reveals how large the contribution is.&lt;/p&gt;
    &lt;p&gt;Now let’s test if the frequency 5 is present. Here’s what you get when you multiply the original function by a sine wave with the frequency 5:&lt;/p&gt;
    &lt;p&gt;There are some large peaks but also large valleys. The new graph averages out to around zero. This indicates that the frequency 5 does not contribute to the original function.&lt;/p&gt;
    &lt;p&gt;The Fourier transform does this for all possible frequencies, multiplying the original function by both sine and cosine waves. (In practice, it runs this comparison on the complex plane, using a combination of real and imaginary numbers.)&lt;/p&gt;
    &lt;p&gt;In this way, the Fourier transform can decompose a complicated-looking function into just a few numbers. This has made it a crucial tool for mathematicians: If they are stumped by a problem, they can try transforming it. Often, the problem becomes much simpler when translated into the language of frequencies.&lt;/p&gt;
    &lt;p&gt;If the original function has a sharp edge, like the square wave below (which is often found in digital signals), the Fourier transform will produce an infinite set of frequencies that, when added together, approximate the edge as closely as possible. This infinite set is called the Fourier series, and — despite mathematicians’ early hesitation to accept such a thing — it is now an essential tool in the analysis of functions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Encore&lt;/head&gt;
    &lt;p&gt;The Fourier transform also works on higher-dimensional objects such as images. You can think of a grayscale image as a two-dimensional function that tells you how bright each pixel is. The Fourier transform decomposes this function into a set of 2D frequencies. The sine and cosine waves defined by these frequencies form striped patterns oriented in different directions. These patterns — and simple combinations of them that resemble checkerboards — can be added together to re-create any image.&lt;/p&gt;
    &lt;p&gt;Any 8-by-8 image, for example, can be built from some combination of the 64 building blocks below. A compression algorithm can then remove high-frequency information, which corresponds to small details, without drastically changing how the image looks to the human eye. This is how JPEGs compress complex images into much smaller amounts of data.&lt;/p&gt;
    &lt;p&gt;In the 1960s, the mathematicians James Cooley and John Tukey came up with an algorithm that could perform a Fourier transform much more quickly — aptly called the fast Fourier transform. Since then, the Fourier transform has been implemented practically every time there is a signal to process. “It’s now a part of everyday life,” Greengard said.&lt;/p&gt;
    &lt;p&gt;It has been used to study the tides, to detect gravitational waves, and to develop radar and magnetic resonance imaging. It allows us to reduce noise in busy audio files, and to compress and store all sorts of data. In quantum mechanics — the physics of the very small — it even provides the mathematical foundation for the uncertainty principle, which says that it’s impossible to know the precise position and momentum of a particle at the same time. You can write down a function that describes a particle’s possible positions; the Fourier transform of that function will describe the particle’s possible momenta. When your function can tell you where a particle will be located with high probability — represented by a sharp peak in the graph of the function — the Fourier transform will be very spread out. It will be impossible to determine what the particle’s momentum should be. The opposite is also true.&lt;/p&gt;
    &lt;p&gt;The Fourier transform has spread its roots throughout pure mathematics research, too. Harmonic analysis — which studies the Fourier transform, as well as how to reverse it to rebuild the original function — is a powerful framework for studying waves. Mathematicians have also found that harmonic analysis has deep and unexpected connections to number theory. They’ve used these connections to explore relationships among the integers, including the distribution of prime numbers, one of the greatest mysteries in mathematics.&lt;/p&gt;
    &lt;p&gt;“If people didn’t know about the Fourier transform, I don’t know what percent of math would then disappear,” Fefferman said. “But it would be a big percent.”&lt;/p&gt;
    &lt;p&gt;Editor’s note: The Flatiron Institute is funded by the Simons Foundation, which also funds this editorially independent magazine. Simons Foundation funding decisions have no influence on our coverage. More information about the relationship between Quanta Magazine and the Simons Foundation is available here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45132810</guid></item><item><title>Evolving the OCaml Programming Language (2025) [pdf]</title><link>https://kcsrk.info/slides/Evolution_Ashoka_2025.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45133652</guid></item><item><title>Forking Chrome to render in a terminal (2023)</title><link>https://fathy.fr/carbonyl</link><description>&lt;doc fingerprint="afa2e9556fb0038d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Forking Chrome to render in a terminal&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;January 27, 2023&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I wrote about forking Chrome to turn HTML to SVG two months ago, today we're going to do something similar by making it render into a terminal.&lt;/p&gt;
    &lt;p&gt;Let me introduce you to the Carbonyl web browser!&lt;/p&gt;
    &lt;head rend="h2"&gt;Drawing&lt;/head&gt;
    &lt;p&gt;There isn't much you can draw in a terminal, you're guaranteed to be able to render monospace characters in a fixed grid, and that's it. Escape sequences exist to perform actions like moving the cursor, changing the text color, or mouse tracking. Some came from the days of physical terminals like the DEC VT100, others came from the xterm project.&lt;/p&gt;
    &lt;p&gt;Assuming a popular terminal emulator, we can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Move the cursor&lt;/item&gt;
      &lt;item&gt;Write Unicode characters&lt;/item&gt;
      &lt;item&gt;Set a character's background and foreground color&lt;/item&gt;
      &lt;item&gt;Use a 6x6x6 RGB palette, or 24 bits RGB if &lt;code&gt;COLORTERM&lt;/code&gt;is set the&lt;code&gt;truecolor&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One of the unicode characters we can render is the lower half block element &lt;code&gt;U+2584&lt;/code&gt;: &lt;code&gt;▄&lt;/code&gt;. Knowing that cells generally have an aspect ratio of 1:2, we can render perfectly square pixels by setting the background color to the top pixel color, and the foregound color to the bottom pixel color.&lt;/p&gt;
    &lt;p&gt;Let's hook &lt;code&gt;html2svg&lt;/code&gt;'s output into a Rust program:&lt;/p&gt;
    &lt;code&gt;fn move_cursor((x, y): (usize, usize)) {
    println!("\x1b[{};{}H", y + 1, x + 1)
}

fn set_foreground((r, g, b): (u8, u8, u8)) {
    println!("\x1b[38;2;{};{};{}m", r, g, b)
}

fn set_background((r, g, b): (u8, u8, u8)) {
    println!("\x1b[48;2;{};{};{}m", r, g, b)
}

fn print_pixels_pair(
    top: (u8, u8, u8),
    bottom: (u8, u8, u8),
    cursor: (usize, usize)
) {
    move_cursor(cursor);
    set_background(top);
    set_foreground(bottom);
    println!("▄");
}
&lt;/code&gt;
    &lt;p&gt;Not bad. To render text, we need to create a new Skia device using C++, lets call it &lt;code&gt;TextCaptureDevice&lt;/code&gt;. We'll make it call a &lt;code&gt;draw_text&lt;/code&gt; function written in Rust. Just like in &lt;code&gt;html2svg&lt;/code&gt;, we need to convert glyph IDs into unicode characters.&lt;/p&gt;
    &lt;code&gt;class TextCaptureDevice: public SkClipStackDevice {
  void onDrawGlyphRunList(SkCanvas*,
                          const sktext::GlyphRunList&amp;amp; glyphRunList,
                          const SkPaint&amp;amp;,
                          const SkPaint&amp;amp; paint) override {
    // Get the text position
    auto position = localToDevice().mapRect(glyphRunList.origin());

    for (auto&amp;amp; glyphRun : glyphRunList) {
      auto runSize = glyphRun.runSize();
      SkAutoSTArray&amp;lt;64, SkUnichar&amp;gt; unichars(runSize);

      // Convert glyph IDs to Unicode characters
      SkFontPriv::GlyphsToUnichars(glyphRun.font(),
                                  glyphRun.glyphsIDs().data(),
                                  runSize,
                                  unichars.get());

      // Draw that text on the terminal
      draw_text(unichars.data(), runSize, position, paint.getColor());
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;Better! But the text is scrambled at the center. Our &lt;code&gt;TextCaptureDevice&lt;/code&gt; does not account for occlusion, drawing a rectangle does not clear the text behind it.&lt;/p&gt;
    &lt;p&gt;Let's add some code to the &lt;code&gt;drawRect&lt;/code&gt; and &lt;code&gt;drawRRect&lt;/code&gt; methods to clear the text if we're filling with a solid color:&lt;/p&gt;
    &lt;code&gt;void drawRRect(const SkRRect&amp;amp; rect, const SkPaint&amp;amp; paint) override {
    drawRect(rect.rect(), paint);
}

void drawRect(const SkRect&amp;amp; rect, const SkPaint&amp;amp; paint) override {
    if (
        paint.getStyle() == SkPaint::Style::kFill_Style &amp;amp;&amp;amp;
        paint.getAlphaf() == 1.0
    ) {
        clear_text(localToDevice().mapRect(rect));
    }
}
&lt;/code&gt;
    &lt;p&gt;The gray background behind text elements is caused by the software rasterizer rendering text in our bitmap. Let's remove it:&lt;/p&gt;
    &lt;code&gt;void SkBitmapDevice::onDrawGlyphRunList(SkCanvas* canvas,
                                        const sktext::GlyphRunList&amp;amp; glyphRunList,
                                        const SkPaint&amp;amp; initialPaint,
                                        const SkPaint&amp;amp; drawingPaint) {
-    SkASSERT(!glyphRunList.hasRSXForm());
-    LOOP_TILER( drawGlyphRunList(canvas, &amp;amp;fGlyphPainter, glyphRunList, drawingPaint), nullptr )
}
&lt;/code&gt;
    &lt;p&gt;That was the easy part, let's handle inputs!&lt;/p&gt;
    &lt;head rend="h2"&gt;Input&lt;/head&gt;
    &lt;code&gt;fn report_mouse_move((x, y): (usize, usize)) {
    write!(get_stdin(), "\x1b[&amp;lt;35;{};{}M", y + 1, x + 1)
}
fn report_mouse_down((x, y): (usize, usize)) {
    write!(get_stdin(), "\x1b[&amp;lt;0;{};{}M", y + 1, x + 1)
}
fn report_mouse_up((x, y): (usize, usize)) {
    write!(get_stdin(), "\x1b[&amp;lt;0;{};{}m", y + 1, x + 1)
}
&lt;/code&gt;
    &lt;p&gt;Some sequences exist to get a terminal emulator to track and report mouse events. For example, if you print &lt;code&gt;\x1b[?1003h&lt;/code&gt;, the terminal should start sending events using this format:&lt;/p&gt;
    &lt;p&gt;These are similar to the sequences we use for styling our output. The &lt;code&gt;\x1b[&lt;/code&gt; prefix is called the Control Sequence Introducer.&lt;/p&gt;
    &lt;code&gt;carbonyl::browser-&amp;gt;BrowserMainThread()-&amp;gt;PostTask(
    FROM_HERE,
    base::BindOnce(
        &amp;amp;HeadlessBrowserImpl::OnMouseDownInput,
        x,
        y
    )
);
&lt;/code&gt;
    &lt;p&gt;We need to notify the browser to wrap this up, but there is a catch: we need to block a thread to read stdin, but the browser methods should be called from the main thread. Thankfully, messages passing is available almost everywhere through the &lt;code&gt;TaskRunner&lt;/code&gt;
class.&lt;/p&gt;
    &lt;code&gt;for &amp;amp;key in input {
    sequence = match sequence {
        Sequence::Char =&amp;gt; match key {
            0x1b =&amp;gt; Sequence::Escape,
            0x03 =&amp;gt; emit!(Event::Exit),
            key =&amp;gt; emit!(Event::KeyPress { key }),
        },
        Sequence::Escape =&amp;gt; match key {
            b'[' =&amp;gt; Sequence::Control,
            b'P' =&amp;gt; Sequence::DeviceControl(DeviceControl::new()),
            0x1b =&amp;gt;
                emit!(Event::KeyPress { key: 0x1b }; continue),
            key =&amp;gt; {
                emit!(Event::KeyPress { key: 0x1b });
                emit!(Event::KeyPress { key })
            }
        },
        Sequence::Control =&amp;gt; match key {
            b'&amp;lt;' =&amp;gt; Sequence::Mouse(Mouse::new()),
            b'A' =&amp;gt; emit!(Event::KeyPress { key: 0x26 }),
            b'B' =&amp;gt; emit!(Event::KeyPress { key: 0x28 }),
            b'C' =&amp;gt; emit!(Event::KeyPress { key: 0x27 }),
            b'D' =&amp;gt; emit!(Event::KeyPress { key: 0x25 }),
            _ =&amp;gt; Sequence::Char,
        },
        Sequence::Mouse(ref mut mouse) =&amp;gt; parse!(mouse, key),
        Sequence::DeviceControl(ref mut dcs) =&amp;gt; parse!(dcs, key),
    }
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Pipe&lt;/head&gt;
    &lt;p&gt;We have something that sorts of work, at the cost of a steady 400% CPU usage, and that's not counting iTerm2 which uses ~200%. We've got a few problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We need too much resources to render at 5 FPS&lt;/item&gt;
      &lt;item&gt;We render every time, even when nothing changes&lt;/item&gt;
      &lt;item&gt;We print all characters even if they didn't change on an individual level&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modern browsers employ a multi-process architecture to improve security. It separates websites into different processes, reducing the potential damage caused by vulnerabilities. The renderer process is running in an OS-level sandboxed environment that blocks certain system calls, such as file-system access. The GPU process, is also considered unprivileged and cannot reach renderer process in order to protect against vulnerabilities in GPU APIs such as WebGL. In contrast, the browser process, considered privileged, can communicate freely with any process.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;CapturePaintPreview&lt;/code&gt; is great for &lt;code&gt;html2svg&lt;/code&gt;, but it's not designed for real-time rendering. It's using IPC calls to correctly support out-of-process iframes, making roundtrips between the browser, GPU, and renderer processes. It downloads hardware accelerated images from the GPU, explaining the surprising memory bandwidth usage. We can disable the fetching, and even disable hardware acceleration, but we still have an expensive IPC machinery holding us back.&lt;/p&gt;
    &lt;p&gt;Software rendering is still very common, it even used to be the default if you can believe it. It was fairly easy back in the single-process days, but nowadays shared memory regions are configured to efficiently render using multiple processes. If we can get our pixels into one of these memory regions, we would just have to notify our browser process using a simple IPC message.&lt;/p&gt;
    &lt;code&gt;void LayeredWindowUpdater::OnAllocatedSharedMemory(
    const gfx::Size&amp;amp; pixel_size,
    base::UnsafeSharedMemoryRegion region
) {
    if (region.IsValid())
        shm_mapping_ = region.Map();
}

void LayeredWindowUpdater::Draw(
    const gfx::Rect&amp;amp; damage_rect,
    DrawCallback draw_callback
) {
    carbonyl_draw_bitmap(
        shm_mapping_.GetMemoryAs&amp;lt;uint8_t&amp;gt;(),
        shm_mapping_.size()
    );

    std::move(draw_callback).Run();
}
&lt;/code&gt;
    &lt;p&gt;In order to setup this shared memory, we need to implement a &lt;code&gt;HostDisplayClient&lt;/code&gt; and a &lt;code&gt;SoftwareOutputDevice&lt;/code&gt; to manage a custom &lt;code&gt;LayeredWindowUpdater&lt;/code&gt; which implements &lt;code&gt;OnAllocatedSharedMemory()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;HostDisplayClient&lt;/code&gt; runs in the browser process and is called by the GPU process through IPC. To wrap this up we need to make the GPU process use our custom display client by adding the following to &lt;code&gt;VizProcessTransportFactory::OnEstablishedGpuChannel()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;compositor_data.display_client =
-      std::make_unique&amp;lt;HostDisplayClient&amp;gt;(compositor);
+      std::make_unique&amp;lt;carbonyl::HostDisplayClient&amp;gt;();
&lt;/code&gt;
    &lt;p&gt;We solved the bitmap problem, now how can we extract text data? This data lives in the renderer process, but our windowing code lives in the browser process. We need to make the renderer interact with the browser process.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mojo&lt;/head&gt;
    &lt;code&gt;// Our C++ bindings will be in the carbonyl::mojom namespace
module carbonyl.mojom;

// Import existing bindings to common structures
import "ui/gfx/geometry/mojom/geometry.mojom";
import "skia/public/mojom/skcolor.mojom";

// Define a structure to hold text to render
struct TextData {
    // An UTF-8 string with the contents
    string contents;
    // Bounds, size only defined for clearing
    gfx.mojom.RectF bounds;
    // Color of the text
    skia.mojom.SkColor color;
};

// The browser process runs this service
interface CarbonylRenderService {
    // The renderer process calls this method
    DrawText(array&amp;lt;TextData&amp;gt; data);
};
&lt;/code&gt;
    &lt;p&gt;Mojo is a library for inter-process communication. It defines an IDL for serializing data which supports native handles (i.e. file descriptors, shared memory regions, callbacks), and can be used to generate C++, Java (Android), and JavaScript (DevTools) bindings. It's extensively documented, and fairly simple to use.&lt;/p&gt;
    &lt;p&gt;We'll start by making an interface &lt;code&gt;CarbonylRenderService&lt;/code&gt; that runs on the browser process, with a method &lt;code&gt;DrawText&lt;/code&gt; called from the renderer process.&lt;/p&gt;
    &lt;p&gt;This &lt;code&gt;.mojom&lt;/code&gt; code generates C++ temporary files which we can then include to write the implementation code.&lt;/p&gt;
    &lt;p&gt;Mojo receivers such as our service are part of the native handles we can send between processes, to register the implementation we just need to add it to the &lt;code&gt;BrowserInterfaceBroker&lt;/code&gt;, which will get called by the renderer through &lt;code&gt;BrowserInterfaceBrokerProxy&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;map-&amp;gt;Add&amp;lt;carbonyl::mojom::CarbonylRenderService&amp;gt;(
    base::BindRepeating(&amp;amp;RenderFrameHostImpl::GetCarbonylRenderService,
                        base::Unretained(host)));
&lt;/code&gt;
    &lt;code&gt;GetBrowserInterfaceBroker().GetInterface(
  std::move(carbonyl_render_service_receiver_)
);
&lt;/code&gt;
    &lt;p&gt;Now, we need to get our text data without any expensive round-trip. Blink has a &lt;code&gt;GetPaintRecord()&lt;/code&gt; method to get the latest paint data for a page, but it's not behind a public API, which we need because our code runs in the content renderer. Ideally we should hook into the compositor (&lt;code&gt;cc&lt;/code&gt;), but it's way more involved. It's dirty but we can workaround this by casting to the private &lt;code&gt;blink::WebViewImpl&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;auto* view = static_cast&amp;lt;blink::WebViewImpl*&amp;gt;(GetWebFrame()-&amp;gt;View());

view-&amp;gt;MainFrameImpl()-&amp;gt;GetFrame()-&amp;gt;View()-&amp;gt;GetPaintRecord().Playback(&amp;amp;canvas);
carbonyl_render_service_-&amp;gt;DrawText(std::move(data));
&lt;/code&gt;
    &lt;p&gt;Surprise after the first run: the text content doesn't follow the bitmap. Aaah, scrolling and animating is done on the compositor thread, which frees the main thread and makes everything smoother. Let's procastinate doing things right by adding &lt;code&gt;--disable-threaded-scrolling&lt;/code&gt; &lt;code&gt;--disable-threaded-animation&lt;/code&gt; to the command line arguments.&lt;/p&gt;
    &lt;p&gt;Pretty smooth, it'll be even smoother when threaded compositing is fixed! And we've fixed our biggest problem: we don't use any CPU when idling, and scrolling consumes ~15%.&lt;/p&gt;
    &lt;head rend="h2"&gt;Layout&lt;/head&gt;
    &lt;code&gt;auto font = state.StyleBuilder().GetFontDescription();

font.SetStretch(ExtraExpandedWidthValue());
font.SetKerning(FontDescription::kNoneKerning);
font.SetComputedSize(11.75 / 7.0);
font.SetGenericFamily(FontDescription::kMonospaceFamily);
font.SetIsAbsoluteSize(true);
state.StyleBuilder().SetFontDescription(font);
state.StyleBuilder().SetLineHeight(Length::Fixed(14.0 / 7.0));
&lt;/code&gt;
    &lt;p&gt;Thing is, we can only render one font-size, but Blink doesn't know that. This causes the layout to be messed up, with text chunks overlapping or overly spaced. This is especially visible on websites with a lot of textual content and links like Wikipedia.&lt;/p&gt;
    &lt;p&gt;Another dirty - yet effective - hack we can use is forcing a monospaced font on every element. We can do that by adding some code to &lt;code&gt;StyleResolver::ResolveStyle&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;LoDPI&lt;/head&gt;
    &lt;code&gt;// static
float Display::GetForcedDeviceScaleFactor() {
    return 1.0 / 7.0;
}

// static
bool Display::HasForceDeviceScaleFactor() {
    return true;
}
&lt;/code&gt;
    &lt;p&gt;One expensive step in our rendering pipeline is downscaling: we need to resize the framebuffer from its virtual space to its physical space. What we're doing is kind of the opposite of HiDPI rendering, whose most common ratio is 2, which means 1 pixel on the web equals 4 pixels on the screen. Our ratio is &lt;code&gt;1 / 7&lt;/code&gt; which means 49 pixels on the web renders to 1 block on our terminal.&lt;/p&gt;
    &lt;p&gt;The annoying thing about HiDPI is that it can make rendering ~4x slower, whereas Carbonyl LoDPI® makes rendering run ~49x faster. We just need to force our scaling into the &lt;code&gt;Display&lt;/code&gt; class.&lt;/p&gt;
    &lt;head rend="h2"&gt;Color&lt;/head&gt;
    &lt;p&gt;I looked for examples of RGB color conversion to &lt;code&gt;xterm-256&lt;/code&gt; but the code I found was either wrong or slow because it did a nearest neighbor search. We're going to do it for every pixel so it should run fast.&lt;/p&gt;
    &lt;p&gt;The formula for the conversion is fairly simple, assuming color values between 0 and 1: &lt;code&gt;16 + r * 5 * 36 + g * 5 * 6 + b * 5&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;pub fn to_xterm(&amp;amp;self) -&amp;gt; u8 {
    let r = (self.r as f32 - (95.0 - 40.0)).max(0.0) / 40.0;
    let g = (self.g as f32 - (95.0 - 40.0)).max(0.0) / 40.0;
    let b = (self.b as f32 - (95.0 - 40.0)).max(0.0) / 40.0;

    (16.0 +
        r.round() * 36.0 +
        g.round() * 6.0 +
        b.round()) as u8
}
&lt;/code&gt;
    &lt;p&gt;The twist that most code online gets wrong is that the 6 color levels are not linear: 0, 95, 135, 175, 215, 255; there is a 95 gap between the first and second values, and 40 for the rest.&lt;/p&gt;
    &lt;p&gt;It makes sense to limit the dark range, color differences are more visible with bright colors. For us, it means that we can convert a value between 0 and 255 using &lt;code&gt;max(0, color - 95 - 40) / 40&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;pub fn to_xterm(&amp;amp;self) -&amp;gt; u8 {
    if self.max_val() - self.min_val() &amp;lt; 8 {
        match self.r {
            0..=4 =&amp;gt; 16,
            5..=8 =&amp;gt; 232,
            238..=246 =&amp;gt; 255,
            247..=255 =&amp;gt; 231,
            r =&amp;gt; 232 + (r - 8) / 10,
        }
    } else {
        let scale = 5.0 / 200.0;

        (16.0
            + self
                .cast::&amp;lt;f32&amp;gt;()
                .mul_add(scale, scale * -55.0)
                .max(0.0)
                .round()
                .dot((36.0, 6.0, 1.0))) as u8
    }
}
&lt;/code&gt;
    &lt;p&gt;The conversion itself can be thought of as a dot product of &lt;code&gt;(r, g, b)&lt;/code&gt; and &lt;code&gt;(36, 6, 1)&lt;/code&gt;. We can move the substraction to an &lt;code&gt;mul_add&lt;/code&gt; call to help the compiler use a fused multiply-add instruction.&lt;/p&gt;
    &lt;p&gt;The last step is grayscale: our xterm profile offers 256 colors, there are the 216 colors from the RGB cube (&lt;code&gt;6 * 6 * 6&lt;/code&gt;), the 16 configurable system colors, and 24 gray levels which go from &lt;code&gt;rgb(8,8,8)&lt;/code&gt; to &lt;code&gt;rgb(238,238,238)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To find out if a color is on a grayscale, we can substract its minimal value to its maximum value and check if it's under a threshold, let's say 8.&lt;/p&gt;
    &lt;p&gt;We still have one tiny problem: how can you detect if a terminal supports true-color or 256 colors? A quick Google search leads us to the &lt;code&gt;COLORTERM&lt;/code&gt; environment variable,
which is &lt;code&gt;24bit&lt;/code&gt; or &lt;code&gt;truecolor&lt;/code&gt; if true-color is supported. But that won't work in
Docker or SSH, which are our primary targets.&lt;/p&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Code =&amp;gt; match key {
        b'0' | b'1' =&amp;gt; Type(key),
        _ =&amp;gt; control_flow!(break)?,
    },
&lt;/code&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Type(code) =&amp;gt; match key {
        b'$' =&amp;gt; Status(StatusParser::new(code)),
        b'+' =&amp;gt; Resource(ResourceParser::new(code)),
        _ =&amp;gt; control_flow!(break)?,
    },
&lt;/code&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Status(ref mut status) =&amp;gt; return status.parse(key),
    Resource(ref mut resource) =&amp;gt; return resource.parse(key),
};
&lt;/code&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Start =&amp;gt; match key {
        b'r' =&amp;gt; Value,
        _ =&amp;gt; control_flow!(break)?,
    },
&lt;/code&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Value =&amp;gt; match key {
&lt;/code&gt;
    &lt;code&gt;        // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;        0x1b =&amp;gt; self.terminate(),
&lt;/code&gt;
    &lt;code&gt;        // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;        b';' =&amp;gt; self.push_value(),
&lt;/code&gt;
    &lt;code&gt;        // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;        char =&amp;gt; self.push_char(char),
    },
&lt;/code&gt;
    &lt;code&gt;    // ^[P1$r0;48:2:1:13:37:42m^[\&lt;/code&gt;
    &lt;code&gt;    Terminator =&amp;gt; control_flow!(break self.parse_event(key))?,
};
&lt;/code&gt;
    &lt;p&gt;A trick we can use is a DCS (Device Control Sequence) to fetch a setting value, like the current background color. If we set an RGB value and get an RGB value back, we can enable true-color.&lt;/p&gt;
    &lt;p&gt;You can try it by running the following on your terminal:&lt;/p&gt;
    &lt;code&gt;$ printf "\e[48;2;13;37;42m\eP\$qm\e\\"; cat
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;\e&lt;/code&gt;: start escape sequence&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;[&lt;/code&gt;: introduce control sequence&lt;/item&gt;&lt;item&gt;&lt;code&gt;48&lt;/code&gt;: set foreground&lt;/item&gt;&lt;item&gt;&lt;code&gt;2&lt;/code&gt;: using an RGB color&lt;/item&gt;&lt;item&gt;&lt;code&gt;13&lt;/code&gt;: R is 13&lt;/item&gt;&lt;item&gt;&lt;code&gt;37&lt;/code&gt;: G is 37&lt;/item&gt;&lt;item&gt;&lt;code&gt;42&lt;/code&gt;: B is 42&lt;/item&gt;&lt;item&gt;&lt;code&gt;m&lt;/code&gt;: select graphic rendition&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;\e&lt;/code&gt;: start escape sequence&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;P&lt;/code&gt;: introduce device control sequence&lt;/item&gt;&lt;item&gt;&lt;code&gt;$&lt;/code&gt;: enter status mode&lt;/item&gt;&lt;item&gt;&lt;code&gt;q&lt;/code&gt;: query current setting&lt;/item&gt;&lt;item&gt;&lt;code&gt;m&lt;/code&gt;: select graphic rendition&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the commands are supported, you should get the following output with a dark turquoise background:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt; ^[P1$r0;48:2:1:13:37:42m^[\ &lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This is what the terminal emulator sends to stdin, and what we can parse to toggle true-color on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Title&lt;/head&gt;
    &lt;p&gt;A few xterm sequences allow setting the terminal window title, we could use that to display the current page title.&lt;/p&gt;
    &lt;code&gt;fn set_title(title: &amp;amp;str) {
    // Set icon name and window title to string
    println!("\x1b]0;{}\x07", title);
    // Set icon name to string
    println!("\x1b]1;{}\x07", title);
    // Set window title to string
    println!("\x1b]2;{}\x07", title);
}
&lt;/code&gt;
    &lt;p&gt;To get notified when the title changes, we can simply implement &lt;code&gt;WebContentsObserver::TitleWasSet()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;void HeadlessWebContentsImpl::TitleWasSet(content::NavigationEntry* entry) {
    carbonyl::Renderer::Main()-&amp;gt;SetTitle(
        base::UTF16ToUTF8(entry-&amp;gt;GetTitleForDisplay())
    );
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;That's all for today folks, check out Carbonyl on GitHub!&lt;/p&gt;
    &lt;p&gt;This was my first Rust project and I finally get the hype now. What a cool language!&lt;/p&gt;
    &lt;head rend="h3"&gt;Stay tuned&lt;/head&gt;
    &lt;p&gt;The post for next month will be a visual introduction to Fourier Analysis. After that, we'll look into a speculative JS VM in Rust.&lt;/p&gt;
    &lt;p&gt;Use the RSS feed to stay tuned, you can also watch the website repo for releases on GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45133935</guid></item><item><title>Fil's Unbelievable Garbage Collector</title><link>https://fil-c.org/fugc</link><description>&lt;doc fingerprint="da4929d184b21ed4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fil's Unbelievable Garbage Collector&lt;/head&gt;
    &lt;p&gt;Fil-C uses a parallel concurrent on-the-fly grey-stack Dijkstra accurate non-moving garbage collector called FUGC (Fil's Unbelievable Garbage Collector). You can find the source code for the collector itself in fugc.c, though be warned, that code cannot possibly work without lots of support logic in the rest of the runtime and in the compiler.&lt;/p&gt;
    &lt;p&gt;Let's break down FUGC's features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Parallel: marking and sweeping happen in multiple threads, in parallel. The more cores you have, the faster the collector finishes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Concurrent: marking and sweeping happen on some threads other than the mutator threads (i.e. your program's threads). Mutator threads don't have to stop and wait for the collector. The interaction between the collector thread and mutator threads is mostly non-blocking (locking is only used on allocation slow paths).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;On-the-fly: there is no global stop-the-world, but instead we use "soft handshakes" (aka "ragged safepoints"). This means that the GC may ask threads to do some work (like scan stack), but threads do this asynchronously, on their own time, without waiting for the collector or other threads. The only "pause" threads experience is the callback executed in response to the soft handshake, which does work bounded by that thread's stack height. That "pause" is usually shorter than the slowest path you might take through a typical&lt;/p&gt;&lt;code&gt;malloc&lt;/code&gt;implementation.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grey-stack: the collector assumes it must rescan thread stacks to fixpoint. That is, GC starts with a soft handshake to scan stack, and then marks in a loop. If this loop runs out of work, then FUGC does another soft handshake. If that reveals more objects, then concurrent marking resumes. This prevents us from having a load barrier (no instrumentation runs when loading a pointer from the heap into a local variable). Only a store barrier is necessary, and that barrier is very simple. This fixpoint converges super quickly because all newly allocated objects during GC are pre-marked.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dijkstra: storing a pointer field in an object that's in the heap or in a global variable while FUGC is in its marking phase causes the newly pointed-to object to get marked. This is called a Dijkstra barrier and it is a kind of store barrier. Due to the grey stack, there is no load barrier like in the classic Dijkstra collector. The FUGC store barrier uses a compare-and-swap with relaxed memory ordering on the slowest path (if the GC is running and the object being stored was not already marked).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Accurate: the GC accurately (aka precisely, aka exactly) finds all pointers to objects, nothing more, nothing less.&lt;/p&gt;&lt;code&gt;llvm::FilPizlonator&lt;/code&gt;ensures that the runtime always knows where the root pointers are on the stack and in globals. The Fil-C runtime has a clever API and Ruby code generator for tracking pointers in low-level code that interacts with pizlonated code. All objects know where their outgoing pointers are - they can only be in the InvisiCap auxiliary allocation.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-moving: the GC doesn't move objects. This makes concurrency easy to implement and avoids a lot of synchronization between mutator and collector. However, FUGC will "move" pointers to free objects (it will repoint the capability pointer to the free singleton so it doesn't have to mark the freed allocation).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes FUGC an advancing wavefront garbage collector. Advancing wavefront means that the mutator cannot create new work for the collector by modifying the heap. Once an object is marked, it'll stay marked for that GC cycle. It's also an incremental update collector, since some objects that would have been live at the start of GC might get freed if they become free during the collection cycle.&lt;/p&gt;
    &lt;p&gt;FUGC relies on safepoints, which comprise:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Pollchecks emitted by the compiler. The&lt;/p&gt;&lt;code&gt;llvm::FilPizlonator&lt;/code&gt;compiler pass emits pollchecks often enough that only a bounded amount of progress is possible before a pollcheck happens. The fast path of a pollcheck is just a load-and-branch. The slow path runs a pollcheck callback, which does work for FUGC.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Soft handshakes, which request that a pollcheck callback is run on all threads and then waits for this to happen.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enter/exit functionality. This is for allowing threads to block in syscalls or long-running runtime functions without executing pollchecks. Threads that are in the exited state will have pollcheck callbacks executed by the collector itself (when it does the soft handshake). The only way for a Fil-C program to block is either by looping while entered (which means executing a pollcheck at least once per loop iteration, often more) or by calling into the runtime and then exiting.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Safepointing is essential for supporting threading (Fil-C supports pthreads just fine) while avoiding a large class of race conditions. For example, safepointing means that it's safe to load a pointer from the heap and then use it; the GC cannot possibly delete that memory until the next pollcheck or exit. So, the compiler and runtime just have to ensure that the pointer becomes tracked for stack scanning at some point between when it's loaded and when the next pollcheck/exit happens, and only if the pointer is still live at that point.&lt;/p&gt;
    &lt;p&gt;The safepointing functionality also supports stop-the-world, which is currently used to implement &lt;code&gt;fork(2)&lt;/code&gt; and for debugging FUGC (if you set the &lt;code&gt;FUGC_STW&lt;/code&gt; environment variable to &lt;code&gt;1&lt;/code&gt; then the
collector will stop the world and this is useful for triaging GC bugs; if the bug reproduces in STW
then it means it's not due to issues with the store barrier). The safepoint infrastructure also allows
safe signal delivery; Fil-C makes it possible to use signal handling in a practical way. Safepointing is
a common feature of virtual machines that support multiple threads and accurate garbage collection,
though usually, they are only used to stop the world rather than to request asynchronous activity from all
threads. See here for a write-up about
how OpenJDK does it. The Fil-C implementation is in &lt;code&gt;filc_runtime.c&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Here's the basic flow of the FUGC collector loop:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Wait for the GC trigger.&lt;/item&gt;
      &lt;item&gt;Turn on the store barrier, then soft handshake with a no-op callback.&lt;/item&gt;
      &lt;item&gt;Turn on black allocation (new objects get allocated marked), then soft handshake with a callback that resets thread-local caches.&lt;/item&gt;
      &lt;item&gt;Mark global roots.&lt;/item&gt;
      &lt;item&gt;Soft handshake with a callback that requests stack scan and another reset of thread-local caches. If all collector mark stacks are empty after this, go to step 7.&lt;/item&gt;
      &lt;item&gt;Tracing: for each object in the mark stack, mark its outgoing references (which may grow the mark stack). Do this until the mark stack is empty. Then go to step 5.&lt;/item&gt;
      &lt;item&gt;Turn off the store barrier and prepare for sweeping, then soft handshake to reset thread-local caches again.&lt;/item&gt;
      &lt;item&gt;Perform the sweep. During the sweep, objects are allocated black if they happen to be allocated out of not-yet-swept pages, or white if they are allocated out of alraedy-swept pages.&lt;/item&gt;
      &lt;item&gt;Victory! Go back to step 1.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're familiar with the literature, FUGC is sort of like the DLG (Doligez-Leroy-Gonthier) collector (published in two papers because they had a serious bug in the first one), except it uses the Dijkstra barrier and a grey stack, which simplifies everything but isn't as academically pure (FUGC fixpoints, theirs doesn't). I first came up with the grey-stack Dijkstra approach when working on Fiji VM's CMR and Schism garbage collectors. The main advantage of FUGC over DLG is that it has a simpler (cheaper) store barrier and it's a slightly more intuitive algorithm. While the fixpoint seems like a disadvantage, in practice it converges after a few iterations.&lt;/p&gt;
    &lt;p&gt;Additionally, FUGC relies on a sweeping algorithm based on bitvector SIMD. This makes sweeping insanely fast compared to marking. This is made thanks to the Verse heap config that I added to libpas. FUGC typically spends &amp;lt;5% of its time sweeping.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus Features&lt;/head&gt;
    &lt;p&gt;FUGC supports a most of C-style, Java-style, and JavaScript-style memory management. Let's break down what that means.&lt;/p&gt;
    &lt;head rend="h3"&gt;Freeing Objects&lt;/head&gt;
    &lt;p&gt;If you call &lt;code&gt;free&lt;/code&gt;, the runtime will flag the object as free and all subsequent accesses to the object will trap. Additionally, FUGC will not scan outgoing references from the object (since they cannot be accessed anymore).&lt;/p&gt;
    &lt;p&gt;Also, FUGC will redirect all capability pointers (lowers in InvisiCaps jargon) to free objects to point at the free singleton object instead. This allows freed object memory to really be reclaimed.&lt;/p&gt;
    &lt;p&gt;This means that freeing objects can be used to prevent GC-induced leaks. Surprisingly, a program that works fine with &lt;code&gt;malloc&lt;/code&gt;/&lt;code&gt;free&lt;/code&gt; (no leaks, no crashes) that gets converted to GC the naive way (&lt;code&gt;malloc&lt;/code&gt; allocates from the GC and &lt;code&gt;free&lt;/code&gt; is a no-op) may end up leaking due to dangling pointers that the program never accesses. Those dangling pointers will be treated as live by the GC. In FUGC, if you freed those pointers, then FUGC will really kill them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Finalizers&lt;/head&gt;
    &lt;p&gt;FUGC supports finalizer queues using the &lt;code&gt;zgc_finq&lt;/code&gt; API in stdfil.h. This feature allows you to implement finalizers in the style of Java, except that you get to set up your own finalizer queues and choose which thread processes them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Weak References&lt;/head&gt;
    &lt;p&gt;FUGC supports weak references using the &lt;code&gt;zweak&lt;/code&gt; API in stdfil.h. Weak references work just like the weak references in Java, except there are no reference queues. Fil-C does not support phantom or soft references.&lt;/p&gt;
    &lt;head rend="h3"&gt;Weak Maps&lt;/head&gt;
    &lt;p&gt;FUGC supports weak maps using the &lt;code&gt;zweak_map&lt;/code&gt; API in stdfil.h. This API works almost exactly like the JavaScript WeakMap, except that Fil-C's weak maps allow you to iterate all of their elements and get a count of elements.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;FUGC allows Fil-C to give the strongest possible guarantees on misuse of &lt;code&gt;free&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Freeing an object and then accessing it is guaranteed to result in a trap. Unlike tag-based approaches, which will trap on use after free until until memory reclamation is forced, FUGC means you will trap even after memory is reclaimed (due to lower repointing to the free singleton).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Freeing an object twice is guaranteed to result in a trap.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Failing to free an object means the object gets reclaimed for you.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45133938</guid></item><item><title>Using AI to perceive the universe in greater depth</title><link>https://deepmind.google/discover/blog/using-ai-to-perceive-the-universe-in-greater-depth/</link><description>&lt;doc fingerprint="a5e0ba88885bcf07"&gt;
  &lt;main&gt;
    &lt;p&gt;Science&lt;/p&gt;
    &lt;head rend="h1"&gt;Using AI to perceive the universe in greater depth&lt;/head&gt;
    &lt;p&gt;Our novel Deep Loop Shaping method improves control of gravitational wave observatories, helping astronomers better understand the dynamics and formation of the universe.&lt;/p&gt;
    &lt;p&gt;To help astronomers study the universe’s most powerful processes, our teams have been using AI to stabilize one of the most sensitive observation instruments ever built.&lt;/p&gt;
    &lt;p&gt;In a paper published today in Science, we introduce Deep Loop Shaping, a novel AI method that will unlock next-generation gravitational-wave science. Deep Loop Shaping reduces noise and improves control in an observatory’s feedback system, helping stabilize components used for measuring gravitational waves — the tiny ripples in the fabric of space and time.&lt;/p&gt;
    &lt;p&gt;These waves are generated by events like neutron star collisions and black hole mergers. Our method will help astronomers gather data critical to understanding the dynamics and formation of the universe, and better test fundamental theories of physics and cosmology.&lt;/p&gt;
    &lt;p&gt;We developed Deep Loop Shaping in collaboration with LIGO (Laser Interferometer Gravitational-Wave Observatory) operated by Caltech, and GSSI (Gran Sasso Science Institute), and proved our method at the observatory in Livingston, Louisiana.&lt;/p&gt;
    &lt;p&gt;LIGO measures the properties and origins of gravitational waves with incredible accuracy. But the slightest vibration can disrupt its measurements, even from waves crashing 100 miles away on the Gulf coast. To function, LIGO relies on thousands of control systems keeping every part in near-perfect alignment, and adapts to environmental disturbances with continuous feedback.&lt;/p&gt;
    &lt;p&gt;Deep Loop Shaping reduces the noise level in the most unstable and difficult feedback loop at LIGO by 30 to 100 times, improving the stability of its highly-sensitive interferometer mirrors. Applying our method to all of LIGO’s mirror control loops could help astronomers detect and gather data about hundreds of more events per year, in far greater detail.&lt;/p&gt;
    &lt;p&gt;In the future, Deep Loop Shaping could also be applied to many other engineering problems involving vibration suppression, noise cancellation and highly dynamic or unstable systems important in aerospace, robotics, and structural engineering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Measuring across the universe&lt;/head&gt;
    &lt;p&gt;LIGO uses the interference of laser light to measure the properties of gravitational waves. By studying these properties, scientists can figure out what caused them and where they came from. The observatory’s lasers reflect off mirrors positioned 4 kilometers apart, housed in the world’s largest vacuum chambers.&lt;/p&gt;
    &lt;p&gt;Since first detecting gravitational waves produced by a pair of colliding black holes, in 2015, verifying the predictions of Albert Einstein’s general theory of relativity, LIGO’s measurements have deeply changed our understanding of the universe.&lt;/p&gt;
    &lt;p&gt;With this observatory, astronomers have detected hundreds of black hole and neutron star collisions, proven the existence of binary black hole systems, seen new black holes formed in neutron star collisions, studied the creation of heavy elements like gold and more.&lt;/p&gt;
    &lt;p&gt;Astronomers already know a lot about the largest and smallest black holes, but we only have limited data on intermediate-mass black holes — considered the “missing link” to understanding galaxy evolution.&lt;/p&gt;
    &lt;p&gt;Until now, LIGO has only been capable of observing very few of these systems. To help astronomers capture more detail and data of this phenomena, we worked to improve the most difficult part of the control system and expand how far away we can see these events.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reducing noise and stabilizing the system&lt;/head&gt;
    &lt;p&gt;As gravitational waves pass through LIGO’s two 4 kilometer arms, they warp the space between them, changing the distance between the mirrors at either end. These tiny differences in length are measured using light interference to an accuracy of 10^-19 meters, which is 1/10’000 the size of a proton. With measurements this small, LIGO’s detector mirrors must be kept extremely still, isolated from environmental disturbance.&lt;/p&gt;
    &lt;p&gt;This requires one system for passive mechanical isolation and another control system for actively suppressing vibrations. Too little control causes the mirrors to swing, making it impossible to measure anything. But too much control actually amplifies vibrations in the system, instead of suppressing them, drowning out the signal in certain frequency ranges.&lt;/p&gt;
    &lt;p&gt;These vibrations, known as “control noise”, are a critical blocker to improving LIGO’s ability to peer into the universe. Our team designed Deep Loop Shaping to move beyond traditional methods, such as the linear control design methods currently in operation, to remove the controller as a meaningful cause of noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;A more effective control system&lt;/head&gt;
    &lt;p&gt;Deep Loop Shaping leverages a reinforcement learning method using frequency domain rewards and surpasses state-of-the-art feedback control performance.&lt;/p&gt;
    &lt;p&gt;In a simulated LIGO environment, we trained a controller that tries to avoid amplifying noise in the observation band used for measuring gravitational waves — the band where we need the mirror to be still to see events like black hole mergers of up to a few hundred solar masses.&lt;/p&gt;
    &lt;p&gt;Through repeated interaction, guided by frequency domain rewards, the controller learns to suppress the control noise in the observation band. In other words, our controllers learn to stabilize the mirrors without adding harmful control noise, bringing noise levels down by a factor of ten or more, below the amount of vibrations caused by quantum fluctuations in the radiation pressure of light reflecting off the mirrors.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strong performance across simulation and hardware&lt;/head&gt;
    &lt;p&gt;We tested our controllers on the real LIGO system in Livingston, Louisiana, USA — finding that they worked as well on hardware as in simulation.&lt;/p&gt;
    &lt;p&gt;Our results show that Deep Loop Shaping controls noise up to 30-100 times better than existing controllers, and it eliminated the most unstable and difficult feedback loop as a meaningful source of noise on LIGO for the first time.&lt;/p&gt;
    &lt;p&gt;In repeated experiments, we confirmed that our controller keeps the observatory’s system stable over prolonged periods.&lt;/p&gt;
    &lt;head rend="h2"&gt;Better understanding the nature of the universe&lt;/head&gt;
    &lt;p&gt;Deep Loop Shaping pushes the boundaries of what’s currently possible in astrophysics by solving a critical blocker to studying gravitational waves.&lt;/p&gt;
    &lt;p&gt;Applying Deep Loop Shaping to LIGO’s entire mirror control system has the potential to eliminate noise from the control system itself, paving the way for expanding its cosmological reach.&lt;/p&gt;
    &lt;p&gt;Beyond significantly improving how existing gravitational wave observatories measure further and dimmer sources, we expect our work to influence the design of future observatories, both on Earth and in space — and ultimately help connect missing links throughout the universe for the first time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;This research was done by Jonas Buchli, Brendan Tracey, Tomislav Andric, Christopher Wipf, Yu Him Justin Chiu, Matthias Lochbrunner, Craig Donner, Rana X Adhikari, Jan Harms, Iain Barr, Roland Hafner, Andrea Huber, Abbas Abdolmaleki, Charlie Beattie, Joseph Betzwieser, Serkan Cabi, Jonas Degrave, Yuzhu Dong, Leslie Fritz, Anchal Gupta, Oliver Groth, Sandy Huang, Tamara Norman, Hannah Openshaw, Jameson Rollins, Greg Thornton, George van den Driessche, Markus Wulfmeier, Pushmeet Kohli, Martin Riedmiller and is a collaboration of LIGO, Caltech, GSSI and GDM.&lt;/p&gt;
    &lt;p&gt;We’d like to thank the fantastic LIGO instrument team for their tireless work on keeping the observatories up and running and supporting our experiments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45134489</guid></item><item><title>Swimming in Tech Debt</title><link>https://helpthisbook.com/lou-franco/swimming-in-tech-debt</link><description>&lt;doc fingerprint="43255b5b50b7438"&gt;
  &lt;main&gt;
    &lt;p&gt;F e t c h i n g y o u r b o o k . . . Swimming in Tech Debt - Help This Book&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45135263</guid></item><item><title>SQL Needed Structure</title><link>https://www.scattered-thoughts.net/writing/sql-needed-structure/</link><description>&lt;doc fingerprint="634908572fb2d22a"&gt;
  &lt;main&gt;
    &lt;p&gt;Here are two pages from the internet movie database:&lt;/p&gt;
    &lt;p&gt;There are two things to note about these pages.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The data on the page is presented in a hierarchichal structure. The movie page contains a director, a list of genres, a list of actors, and each actor in the list contains a list of characters they played in the movie. You can't sensibly fit all of this into a single flat structure like a relation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The order of the hierarchy isn't the same on both pages. On one page we have movie-&amp;gt;actors and on the other page we have actor-&amp;gt;movies. So you can't just directly store the hierarchy in your database - you need to be able to traverse relationships in both directions.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So we store all our data in a relational database in flat tables and then whenever we need to render some UI we transform the flat data into whatever hierarchy we need.&lt;/p&gt;
    &lt;p&gt;Doing this transformation by hand is tedious and error-prone. We call this tedium "the object-relational mismatch" but it isn't really about objects or relations. The fundamental problem is that fitting complex relationships to human vision usually requires constructing some visual hierarchy, but different tasks require different hierarchies.&lt;/p&gt;
    &lt;p&gt;Whatever database and programming language you use, you will have to deal with this. But it's particularly painful in sql because sql wasn't designed to produce hierarchical data.&lt;/p&gt;
    &lt;head rend="h2"&gt;sql wasn't built to yield structure&lt;/head&gt;
    &lt;p&gt;Let's grab the imdb public dataset and try to reproduce the source data for that movie page (or at least a subset of it, because I didn't bother importing all the tables). We want to see an output that looks like this:&lt;/p&gt;
    &lt;code&gt;{
  "title": "Baby Driver",
  "director": ["Edgar Wright"],
  "writer": ["Edgar Wright"]
  "genres": ["Action", "Crime", "Drama"],
  "actors": [
    {"name": "Ansel Elgort", "characters": ["Baby"]},
    {"name": "Jon Bernthal", "characters": ["Griff"]},
    {"name": "Jon Hamm", "characters": ["Buddy"]},
    {"name": "Eiza GonzÃ¡lez", "characters": ["Darling"]},
    {"name": "Micah Howard", "characters": ["Barista"]},
    {"name": "Lily James", "characters": ["Debora"]},
    {"name": "Morgan Brown", "characters": ["Street Preacher"]},
    {"name": "Kevin Spacey", "characters": ["Doc"]},
    {"name": "Morse Diggs", "characters": ["Morse Diggs"]},
    {"name": "CJ Jones", "characters": ["Joseph"]}
  ],
}
&lt;/code&gt;
    &lt;p&gt;Let's grab the title first:&lt;/p&gt;
    &lt;code&gt;postgres=# select primaryTitle from title where tconst = 'tt3890160';
 primarytitle
--------------
 Baby Driver
&lt;/code&gt;
    &lt;p&gt;And now we need the director:&lt;/p&gt;
    &lt;code&gt;postgres=# select primaryTitle, person.primaryName 
from title, principal, person
where title.tconst = 'tt3890160' 
and title.tconst = principal.tconst 
and principal.nconst = person.nconst 
and principal.category = 'director';

 primarytitle | primaryname  
--------------+--------------
 Baby Driver  | Edgar Wright
&lt;/code&gt;
    &lt;p&gt;And the writer:&lt;/p&gt;
    &lt;code&gt;postgres=# select 
  primaryTitle, 
  director.primaryName as director,
  writer.primaryName as writer
from title, 
principal as principal_director, person as director, 
principal as principal_writer, person as writer
where title.tconst = 'tt3890160' 
and title.tconst = principal_director.tconst 
and principal_director.nconst = director.nconst 
and principal_director.category = 'director'
and title.tconst = principal_writer.tconst 
and principal_writer.nconst = writer.nconst 
and principal_writer.category = 'writer';

 primarytitle |   director   |    writer    
--------------+--------------+--------------
 Baby Driver  | Edgar Wright | Edgar Wright
&lt;/code&gt;
    &lt;p&gt;We're already in trouble. If this movie had 2 directors and 2 writers, this query would return 4 rows:&lt;/p&gt;
    &lt;code&gt; primarytitle |   director   |    writer    
--------------+--------------+--------------
 Baby Driver  | Edgar Wright | Edgar Wright
 Baby Driver  | Edgar Wright | A. Writer
 Baby Driver  | A. Director  | Edgar Wright
 Baby Driver  | A. Director  | A. Writer
&lt;/code&gt;
    &lt;p&gt;If there was no director in the database then this query would return 0 rows, no matter how many writers there were. Now we don't even know what the movie is called.&lt;/p&gt;
    &lt;code&gt; primarytitle |   director   |    writer    
--------------+--------------+--------------
&lt;/code&gt;
    &lt;p&gt;We can't sensibly fit the data we want into a single relation, and we can't return more than one relation per query. So we have to issue multiple queries:&lt;/p&gt;
    &lt;code&gt;postgres=# select primaryTitle from title where tconst = 'tt3890160';
 primarytitle
--------------
 Baby Driver

postgres=# select person.primaryName 
from title, principal, person
where title.tconst = 'tt3890160' 
and title.tconst = principal.tconst 
and principal.nconst = person.nconst 
and principal.category = 'director';

 primaryname  
--------------
 Edgar Wright

postgres=# select person.primaryName 
from title, principal, person
where title.tconst = 'tt3890160' 
and title.tconst = principal.tconst 
and principal.nconst = person.nconst 
and principal.category = 'writer';

 primaryname  
--------------
 Edgar Wright

postgres=# select person.nconst, person.primaryName
from title, principal, person
where title.tconst = 'tt3890160' 
and title.tconst = principal.tconst 
and principal.nconst = person.nconst 
and principal.category = 'actor'
limit 10;

  nconst   |  primaryname  
-----------+---------------
 nm5052065 | Ansel Elgort
 nm1256532 | Jon Bernthal
 nm0358316 | Jon Hamm
 nm2555462 | Eiza GonzÃ¡lez
 nm8328714 | Micah Howard
 nm4141252 | Lily James
 nm3231814 | Morgan Brown
 nm0000228 | Kevin Spacey
 nm1065096 | Morse Diggs
 nm1471085 | CJ Jones

postgres=# select principal_character.nconst, principal_character.character
from title, principal, principal_character
where title.tconst = 'tt3890160' 
and title.tconst = principal.tconst 
and principal.nconst = person.nconst 
and principal.category = 'actor'
and principal_character.tconst = principal.tconst
and principal_character.nconst = principal.nconst;

  nconst   |     character      
-----------+---------------------
 nm5052065 | Baby
 nm8328714 | Barista
 nm0358316 | Buddy
 nm2555462 | Darling
 nm4141252 | Debora
 nm0000228 | Doc
 nm1256532 | Griff
 nm1471085 | Joseph
 nm1065096 | Morse Diggs
 nm3231814 | Street Preacher
&lt;/code&gt;
    &lt;p&gt;Through the magic of joins we have retrieved all the data we need and it only required holding a transaction open for 4 network roundtrips.&lt;/p&gt;
    &lt;p&gt;All that's left to do now is... the same joins, but inside the backend web server. Because we have to re-assemble these flat outputs into the structure of the page.&lt;/p&gt;
    &lt;p&gt;Also note that fully half of the data returned is the &lt;code&gt;nconst&lt;/code&gt; column which we didn't even want in the output. We only returned it because we need it as a key so we can repeat the joins that we already did in the database. The more paths you traverse, the more useless join keys you need to send to the backend web server.&lt;/p&gt;
    &lt;p&gt;All of this is pretty tedious so we invented ORMs to automate it. But:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Almost all ORMs end up sending multiple queries for the output that we want. If you have a good ORM and you use it carefully it'll send one query per path in the output, like the raw sql above. If you're less careful you might get one query per actor in the film.&lt;/item&gt;
      &lt;item&gt;Many ORMs also make a mess of consistency by lazily loading data in separate transactions. So we might generate a page where different parts of the data come from different points in time, which is confusing for users.&lt;/item&gt;
      &lt;item&gt;Using an ORM locks you into only using one specific programming language. What if you need to query your data from a different language? You'll probably end up talking to the same ORM through a microservice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;old dogs can sort of learn new tricks&lt;/head&gt;
    &lt;p&gt;These days sql actually can produce structured data from queries.&lt;/p&gt;
    &lt;p&gt;A lot of people are mad about this. Whenever I talk about it they reflexively yell things like "structured data doesn't belong in the database" as if there was a universal system of morality that uniquely determined the locations of various data processing tasks.&lt;/p&gt;
    &lt;p&gt;But I can't help but note again that the structure has to happen somewhere because that's what the output page looks like and that doing it outside the database isn't working very well.&lt;/p&gt;
    &lt;p&gt;Whenever we're building a UI for humans, whether on the web or native, the main use of the query language is to turn relational data into structured data for the client to render. So it would be really nice if the query language was actually able to produce structured data.&lt;/p&gt;
    &lt;p&gt;Like this:&lt;/p&gt;
    &lt;code&gt;select jsonb_agg(result) from ( 
  select 
    primaryTitle as title, 
    genres,
    (
      select jsonb_agg(actor) from (
        select
          (select primaryName from person where person.nconst = principal.nconst) as name, 
          (
              select jsonb_agg(character)
              from principal_character
              where principal_character.tconst = principal.tconst
              and principal_character.nconst = principal.nconst
          ) as characters
        from principal
        where principal.tconst = title.tconst 
        and category = 'actor'
        order by ordering 
        limit 10
      ) as actor
    ) as actors,
    (
      select jsonb_agg(primaryName)
      from principal, person
      where principal.tconst = title.tconst
      and person.nconst = principal.nconst
      and category = 'director'
    ) as director,
    (
      select jsonb_agg(primaryName)
      from principal, person
      where principal.tconst = title.tconst
      and person.nconst = principal.nconst
      and category = 'writer'
    ) as writer
  from title
  where tconst = $1
) as result;
&lt;/code&gt;
    &lt;p&gt;It's not perfect. You can definitely see the duct tape, and the query plan often suffers from the lack of decorrelation. But we can grab all the data needed for the entire page in a single query, with one network roundtrip. Whether you use these features directly or as the output of your ORM, this is a sizable improvement for one of the main usecases of relational databases!&lt;/p&gt;
    &lt;p&gt;It doesn't matter that this isn't the way things have always worked. Sql is not relational algebra and relational algebra is not math, and neither was carved into stone tablets handed down from Codd.&lt;/p&gt;
    &lt;p&gt;We make tools to serve our purposes, and our purposes have changed a hell of a lot since the 70s, when the main client of a database was a human typing sql character by character into an interactive transaction on a teletype connected to a mainframe with 500kb of RAM, almost 20 years before the invention of the world wide web.&lt;/p&gt;
    &lt;p&gt;Maybe it's ok for our tools to evolve to meet new demands. And we can evolve with them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45135623</guid></item><item><title>Fiber Concurrency</title><link>https://honeyryderchuck.gitlab.io/httpx/wiki/Fiber-Concurrency</link><description>&lt;doc fingerprint="7e50fa1a0e18b6d0"&gt;
  &lt;main&gt;
    &lt;p&gt;The &lt;code&gt;:fiber_concurrency&lt;/code&gt; plugin enables connections a session to be used seamlessly across fibers managed by a fiber scheduler. This is of particular relevance if the connections are long-lived/persistent.&lt;/p&gt;
    &lt;p&gt;Note that, if you’re using the &lt;code&gt;:persistent&lt;/code&gt; plugin, this plugin is required by default.&lt;/p&gt;
    &lt;code&gt;
http = HTTPX.plugin(:fiber_concurrency)

Thread.start do
  # assuming fiber scheduler is set here
  10.times.each do
    Fiber.schedule do
      http.get("https://example.com")
    end
  end
end
&lt;/code&gt;
    &lt;p&gt;This plugin is a requirement if you’re using &lt;code&gt;httpx&lt;/code&gt; in programs with a fiber scheduler. This includes, for example, programs developed using the async gem.&lt;/p&gt;
    &lt;p&gt;Next: Custom Plugins&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45136008</guid></item><item><title>I bought the cheapest EV, a used Nissan Leaf</title><link>https://www.jeffgeerling.com/blog/2025/i-bought-cheapest-ev-used-nissan-leaf</link><description>&lt;doc fingerprint="62e0505ed9271d37"&gt;
  &lt;main&gt;
    &lt;p&gt;I bought a used 2023 Nissan Leaf in 2025, my first 'new' car in 15 years. The above photo was taken by the dealership; apparently their social media team likes to post photos of all purchasers.&lt;/p&gt;
    &lt;p&gt;I test drove a Tesla in 2012, and quickly realized my mistake. No gasoline-powered car (outside of supercars, maybe? Never drove one of those) could match the feel of pressing the throttle on an electric.&lt;/p&gt;
    &lt;p&gt;I started out with a used minivan, which I drove into the ground. Then I bought a used Olds that I drove into the ground. Then I bought a used Camry that I bought before we had kids, when I had a 16 mile commute.&lt;/p&gt;
    &lt;p&gt;Fast forward about 15 years, and I found myself with a very short commute, only driving a few miles a day, and a family minivan we use for nearly all the 'driving around the kids' stuff.&lt;/p&gt;
    &lt;p&gt;So I wanted a smaller car (get back a foot or so of garage space...) that was also more efficient.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video and GitHub EV Project&lt;/head&gt;
    &lt;p&gt;If you don't like reading blog posts (why are you here?), I also posted a video going over most of this, with a little more color, on my YouTube channel:&lt;/p&gt;
    &lt;p&gt;Also, this blog post is also the centerpiece of my new GitHub project geerlingguy/electric-car, where I detail all the steps on my nascent EV journey.&lt;/p&gt;
    &lt;head rend="h2"&gt;Equipment and Add-ons&lt;/head&gt;
    &lt;p&gt;Before I go further, I thought I'd mention some of the things I've added to my Leaf to make the EV experience a little nicer (some links are Amazon affiliate links. I earn for qualifying referrals):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grizzl-E Level 2 Charger for the garage (see Issue #5)&lt;/item&gt;
      &lt;item&gt;Lectron L1 J1772 EV charger for a more portable charger, when I just need to top off the car for a few hours&lt;/item&gt;
      &lt;item&gt;J1772 Wall mount for cable and plug - I was going to 3D print one, but figured the metal product would hold up better in a garage in the midwest&lt;/item&gt;
      &lt;item&gt;NACS to J1772 AC L1/L2 charging adapter&lt;/item&gt;
      &lt;item&gt;CCS1 to CHAdeMO L3 DC Fast charge adapter (see Issue #9)&lt;/item&gt;
      &lt;item&gt;CarlinKit 5.0 Wireless CarPlay/Android Auto adapter because the Leaf only supports wired CarPlay by default&lt;/item&gt;
      &lt;item&gt;VIOFO A119 Mini Dashcam with a Dongar wiring harness adapter (see Issue #3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Monitoring the Battery&lt;/head&gt;
    &lt;p&gt;If you're considering a used Leaf, or if you have a Leaf already, it's a good idea to keep tabs on the battery health, especially since the meter on your dash is painfully basic in how much data it provides.&lt;/p&gt;
    &lt;p&gt;Individual cell charge, 'State of Health' of the overall battery, and much more are available through the car's OBD-II port.&lt;/p&gt;
    &lt;p&gt;Soon after I bought my Leaf, I ordered a LeLink 2 ($35) and bought the LeafSpy Pro App for my iPhone ($20).&lt;/p&gt;
    &lt;p&gt;I plugged the LeLink 2 into the OBD-II diagnostics port under the steering column, and fired up LeafSpy Pro. It gives me some helpful metrics like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;SOH: State of Health&lt;/item&gt;
      &lt;item&gt;Hx: Conductance&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;See Issue #8: Document battery health for all my notes monitoring my own Leaf's battery. But bottom line, my battery showed a 93.16% 'SoH' (State of Health), meaning it still has most of its capacity.&lt;/p&gt;
    &lt;p&gt;I've been reading up on various forums about managing the Leaf's battery, and am trying to do some things to extend the battery's life as long as possible:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limiting the number of QCs (Quick Charges / DC Fast Charge), as this heats up the uncooled Leaf battery, degrading it slightly each time, especially on hotter days&lt;/item&gt;
      &lt;item&gt;Keeping the charge between 50-80% when manageable&lt;/item&gt;
      &lt;item&gt;Charging up to 100% at least once a month, and letting it 'top off' to rebalance the pack for at least a few hours afterwards&lt;/item&gt;
      &lt;item&gt;Not driving like a maniac, despite having more torque in this car than I've ever had in any of my previous cars&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why buy electric?&lt;/head&gt;
    &lt;p&gt;I overanalyze most things, so had been researching this purchase for about a decade now.&lt;/p&gt;
    &lt;p&gt;With EVs there are tradeoffs. Even in my situation, only driving a car a few miles a day, I do take my car on one or two regional road trips every year.&lt;/p&gt;
    &lt;p&gt;Having the ability to hop in at 6 am and be in Chicago or KC by late morning is nice. Having to plan a long break somewhere halfway to charge is not.&lt;/p&gt;
    &lt;p&gt;But if I only take that trip once a year, I can either (a) rent a gas car that gets me there a little more quickly, and ensures I don't have to find a spot in the destination city to do a full charge before the return trip. Or (b) plan for an extra X hours total during the trip to ensure I have padding for charging.&lt;/p&gt;
    &lt;p&gt;Charging infrastructure's improving in the US (and in many parts of the world), but it's nowhere near as ubiquitous as gas stations.&lt;/p&gt;
    &lt;p&gt;Hopefully this improves over time, but for now, I plan on using the electric car for local travel, likely only going more than 100 miles or so in a day once or twice a year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why buy Leaf?&lt;/head&gt;
    &lt;p&gt;Price.&lt;/p&gt;
    &lt;p&gt;That's mostly it. And I drove a Nissan Sentra rental on a recent trip, and realized Nissan isn't half bad. They seem to not require an Internet connection for their cars, they offer basic lane following and adaptive cruise control, they have CarPlay/Android Auto...&lt;/p&gt;
    &lt;p&gt;The Leaf ticks all the little 'convenience' checkboxes, but is also not 'extravagant'.&lt;/p&gt;
    &lt;p&gt;And the later model years also aren't "look at me I drive an EV" ugly (though they're not amazing-looking, either).&lt;/p&gt;
    &lt;p&gt;But I drove a minivan, an olds, and a Camry, so obviously I'm function &amp;gt; form when it comes to my car!&lt;/p&gt;
    &lt;p&gt;Because of the smaller battery (and up until 2026, a battery with no active cooling), combined with the use of a DC fast charging connector (CHAdeMO) that's going out of style in the US, used Nissan Leafs are priced considerably lower than competitors.&lt;/p&gt;
    &lt;p&gt;Well, all except maybe Teslas around a year or two older right now. But Teslas don't have native CarPlay. And I'm not a fan of how Tesla is trying to turn the car into some kind of appliance, RoboTaxi, self-driving thing, versus it being a transportation vehicle that I can do what I want with.&lt;/p&gt;
    &lt;p&gt;No judgement on Tesla owners, the used Tesla market was enticing at the time I bought the Leaf.&lt;/p&gt;
    &lt;p&gt;I also looked a lot at the Hyundai Ioniq and Kona; both were just a little bit too large for my liking, but they could've worked. The problem was used models in good condition were a lot more expensive than I was willing to pay.&lt;/p&gt;
    &lt;p&gt;So back to the Leaf: Nissan's probably not the best right now when it comes to EVs and features, but they're certainly the cheapest. And 'good enough' is fine by me.&lt;/p&gt;
    &lt;p&gt;She's got it where it counts, kid.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gripes about my Leaf&lt;/head&gt;
    &lt;p&gt;There are a few things that baffle me about the Leaf, some that have been frustrating from the first test drive; others that are more subtle:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There is no 'play/pause' button. Anywhere. At least not on the steering wheel or the display area. You have to go into the music section on the entertainment display, then press the software play/pause button. That's dumb. I've resorted to just turning Audio on/off using the volume knob, which accomplishes the same goal but is not always ideal.&lt;/item&gt;
      &lt;item&gt;Going into 'Neutral' is an exercise in frustration. I thought you just put your foot on the brake and move the shifter knob to the left. But you have to do it with the right timing, I think.&lt;/item&gt;
      &lt;item&gt;There's no way to open the tailgate short of pressing the release button. At least as far as I'm aware. There's no button in the cabin or key fob to unlatch it. The manual says the other way to open it is with a screwdriver, from inside the car, pushing on the latch (lol). I'm not alone here. At least there's a button on the remote to open the charge port.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The joy of electric&lt;/head&gt;
    &lt;p&gt;I don't care about engine noise. I appreciate it, though. My brother had a 1992 Forumula Firebird. And I nearly owned it after he moved away, instead of my Olds! (But I'm a boring-car person, so I think I was happier with the Olds).&lt;/p&gt;
    &lt;p&gt;The nice things about electric vehicles that swayed me in their favor, in descending order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One pedal driving Seriously, why doesn't every EV have this mode? It makes driving one feel SO much better than any gas car, in terms of connection between driver and car movement.&lt;/item&gt;
      &lt;item&gt;Sprightly torque: Outside of exotic tiny gas cars, you're not going to get the same zip even a cheap EV like a Leaf gives you—smash the accelerator in non-Eco mode and any passenger will giggle, every time.&lt;/item&gt;
      &lt;item&gt;Blissful quiet: Though some cars have annoying noises (Nissan calls this VSP, or "Vehicle Sound for Pedestirians") they play at low speeds.&lt;/item&gt;
      &lt;item&gt;Lower maintenance requirements: I hate every time I have to jack up my car and change the brakes, or take it in for oil/fluid changes. EVs (usually) require less maintenance, besides maybe tires.&lt;/item&gt;
      &lt;item&gt;Conveniences: Like running climate control to cool down/heat up the car prior to hopping in, even while it's in the garage! Or plugging it in to charge at home, and not having to stop by a gas station.&lt;/item&gt;
      &lt;item&gt;Long-term economics: in general, charging with electricity, at least here in St. Louis, is cheaper than filling up with gas, on a dollar-per-mile basis.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The pain of electric&lt;/head&gt;
    &lt;p&gt;All that said, I knew going into this there would be some pain. Maybe in 10 or 20 years these things will get solved, but off the top of my head:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Price: The Leaf (especially used, right now) is the cheapest, but it is by no means cheap. It takes a few years to break even with a similarly-specced gas car. But buying a gas car, you have a lot more options on the low-low end.&lt;/item&gt;
      &lt;item&gt;Range Anxiety: Yes, it's overblown, but no, it's not non-existent. The day I bought my used EV, the dealership (which doesn't sell many EVs, even new) didn't have a 'Level 3' DC fast charger—and they had only charged it to about 16%. Letting it top off at L2 while I was dealing with finance, we got to 23%. I wasn't quite sure I'd make it home off the lot! Luckily I did, with 12 miles of range remaining. Road tripping or day trips require more planning when driving an EV.&lt;/item&gt;
      &lt;item&gt;Lack of standards: For 'L3' DC Fast Charging, the Leaf has a CHAdeMO port. Teslas and many newer EVs have NACS. Then there's CCS1 and CCS2. And charging stations are run by multiple vendors with multiple apps and payment methods. It's not like gas stations, like with Shell, BP, Buckee's, etc. where you just drive up, stick the gas nozzle in your tank, and squeeze. Even adapters can be complicated and annoying, and many EV charging stations only support one or two standards—and some may only have one CHAdeMO plug, and that plug may have been ripped off the unit to be scrapped by a copper thief!&lt;/item&gt;
      &lt;item&gt;Lack of standards, part 2: For L1/L2 charging, some cars use J1772, some use NACS... and then wall charging units are all over the board with supporting 6, 12, or 16 Amps for L1 (they shouldn't do 16 on a 15A circuit but it seems like some do!), or various different amperages for L2. Some of these units require apps to configure them, others have dip switches, and yet others are not configurable, and don't list their exact specs in an easy-to-find location. Usually forum posts from users who buy the chargers offer more information than product manufacturers' own websites!&lt;/item&gt;
      &lt;item&gt;Being an EV: For some reason, most EVs look like... EVs. I honestly was holding out hope Tesla would just make a Corolla, but an EV version. All the cheap EVs like the Bolt, i3, Leaf, etc. just look... sorta ugly. Subjective, sure, but at least my Olds looked kinda sleek. Even if it was an Olds. EVs stand out, and that I don't enjoy. I want an EV that looks like a Camry. Just blend in and don't stand out.&lt;/item&gt;
      &lt;item&gt;Cables and chargers: The Leaf has slightly less trunk space than my slightly-larger Camry. I didn't realize how big L1/L2 charge cables are. Even L1-only cables (which charge at a very anemic pace, like 10 miles / hour of charge) are fairly thick, bulky affairs. About 1/10 of my trunk is devoted to my charging cable. And on a road trip, I will likely carry my NACS to J1772 and CCS1 to CHAdeMO adapters. And the latter adapter includes its own battery (that has to be charged) and firmware (that might need to be updated)!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Further Reading&lt;/head&gt;
    &lt;p&gt;Be sure to check the Issues in my GitHub project for more of my EV adventures.&lt;/p&gt;
    &lt;p&gt;I don't plan on becoming an EV advocate by any means.&lt;/p&gt;
    &lt;p&gt;The Leaf is the perfect option for me, but I wouldn't recommend an EV for most car owners yet, especially considering the price disparity and infrastructure requirements that exclude large swaths of the population!&lt;/p&gt;
    &lt;head rend="h2"&gt;Comments&lt;/head&gt;
    &lt;p&gt;I have a much older Leaf (2015) with much less range (allegedly 80, possibly more like 50). The worst moment of range anxiety is when the car jumps from claiming you have 12 miles left, to admitting it has no idea and you'd better do something about it. Happened to me only once on the way back from the airport, but it was awful. I tell everyone to get an L2 charger before they get an EV.&lt;/p&gt;
    &lt;p&gt;But I love my Leaf. It's fun to drive, and the price still makes me happy.&lt;/p&gt;
    &lt;p&gt;Congrats on the Leaf! I've had two (a first gen, and a second gen) and now have a Mach-E.&lt;/p&gt;
    &lt;p&gt;I loved those Leafs, but I hated Nissan. My second Leaf (purchased new) had a bad battery pack. It took me a long time to realize it but while the pack behaved normally from ~100% to ~60%, it would drop from ~50% to ~15% over the course of a few miles. I didn't realize because most of my use was very local, so I only discovered this on my first 100-mile road trip. It very nearly stranded me in the mountains outside Portland.&lt;/p&gt;
    &lt;p&gt;It took me ~9 months, numerous trips to multiple dealers, and eventually threatening them with a lemon law lawsuit to get them to fix the issue. I presented them with videos ( https://youtu.be/b3z2BWc63LI ), a multi-page PDF showing the voltage levels of all the cells, and identified the single cell that had a bad voltage dip. They refused to do anything until I hired a lawyer.&lt;/p&gt;
    &lt;p&gt;The eventual fix took them about 15 minutes and resolved the problem completely. Getting to that point wasted many, many, many hours. So frustrating.&lt;/p&gt;
    &lt;p&gt;Most of your listed pain points are related to your specific choice in EV. The Leaf has less range, a more temperamental battery, uses a long-deprecated charging standard, and has fewer quality of life improvements than modern EVs. They are cheap for a reason...&lt;/p&gt;
    &lt;p&gt;I agree on the charging infrastructure and cost of entry. Those are absolutely barriers that most people won't be able to overcome. Juggling multiple apps, dealing with multiple charging standards and speeds, and just having to plan your route around charging stops is likely a bridge too far for most people. Europe had the right idea by just choosing a national standard that everyone had to follow. The last remaining caveat is towing, where a hybrid makes significantly more sense until energy density increases substantially.&lt;/p&gt;
    &lt;p&gt;I have a '22 Volvo XC40 Recharge that I use to make an annual trip from Kansas City to the Wisconsin Northwoods. Many vehicles on the market (some of them cheaper) would be more ideal for this trip. The vehicle has a midrange charging speed and is on the lower end of range at only 200 miles or so. For this trip, we typically end up stopping about 6 times for a duration of 20-45 minutes each. For a top-performing EV, you'd probably do the same trip with 4 stops for 15-30 minutes each. Just enough time to get out, stretch your legs, use the bathroom, and hit the road again. The car even plans the route and charging stops for us with the built-in Google Maps. The experience is still not quite ready for "main-stream" use, but it's pretty close.&lt;/p&gt;
    &lt;p&gt;This is very much from the perspective of a used car buyer and thats cool. I look around and see people buying/leasing $30k+ new gas cars and wonder what compels them to buy gas propulsion. If you are spending 30k+ there are a lot of great options in the new ev market. Granted new EV prices are a big unknown for next month, but right now you can pull off the lot in a 2025 Chevy Equinox EV for about $30k OTD. The used market is going to be very interesting in two to three years. Will my Blazer EV be worthless because prices came down so much and battery tech went so far or will it hold its value well given that it seems like most new cars are 30k+. Doesn't matter either way to me because I love it and hope to drive it until there is nothing left of it. If you can charge at home or at work, I cant imagine wanting to stop at a gas station. Enjoy those Es.&lt;/p&gt;
    &lt;p&gt;The new car market is just out of my price range. I'm weird and old school I guess, but I don't want to lease a car, I'd much prefer to purchase it outright, but if you do that, car dealership finance departments get all snippy with you, so I do the loan at whatever the going rate is (I think this one was 6%? my last one was 3%) and pay it off over a few months instead of the 36 month term.&lt;/p&gt;
    &lt;p&gt;I hate that so many markets are pushing towards people never owning the thing they're 'buying' (and understand that leasing + purchasing can still make more financial sense, I'm just allergic to that model of ownership!).&lt;/p&gt;
    &lt;p&gt;Snippy finance departments. Love it.&lt;/p&gt;
    &lt;p&gt;Bought our last 2 cars with cash. Drove both dealers crazy. I still don't know why they required me to unlock my credit history so they could do a credit bureau check when I was giving them a personal check for the whole $ 40k or so.&lt;/p&gt;
    &lt;p&gt;Car buying is just a brutal experience.&lt;/p&gt;
    &lt;p&gt;Probably to check your check won't bounce.&lt;/p&gt;
    &lt;p&gt;Meanwhile here in Europe, you can do a SEPA Instant Transfer and 10 seconds later the whole price shows up on the dealership's online banking.&lt;/p&gt;
    &lt;p&gt;I just upgraded my EV recently. I purchased a Tesla Model 3 Performance in 2019, and drove it for nearly 6 years on trips long and short. Range anxiety was my own personal problem for about 6 months until I got used to the slightly different behavior patterns. Electricity in my area was exceptionally cheap and my L1 charger on a 15A circuit (12A limit) was more than enough to handle daily work driving. Took quite a few interstate trips and never had a problem charging anywhere. Car was a fairly expensive, but a great car overall, until Elon made it difficult to justify, so we traded it in for a Hyundai Ioniq 5 (800V bat) with NACS. Between the Tesla trade in value and a few thousand in cash, the new car loan was $20K, which was actually pretty damnn good. For the L1 chargers with a 16A setting, at least the Tesla mobile charger has plug adapter options and can use 20A 120V circuits, of which my new house actually has several. I actually had a Tesla L2 wall charger that I couldn't install in the apartment we previously lived in, but now that I have the Ioniq 5 I ended up installing it and it works fantastically. It's a Gen2 without wifi or any of the extra crap, and limiting it to 32A@240v gives me enough power to charge fully overnight while not requiring a huge load on my panel. Car came with 2 plug adapters (no batteries) and we've used them at a couple of different hotels with L2 guest chargers, but we use Superchargers on longer trips if needed. Honestly, the wife and I never see going back to gas. There's just no reason. We'll be putting in solar and home battery storage eventually, so we'll pay a bit more for a bit more energy independence. We did like the Volkswagen ID Buzz van in concept, but they wanted an extremely high price for them and the range sucks. They were actually pretty huge in person, which was kind of nice and had more space than my old Caravan had.&lt;/p&gt;
    &lt;p&gt;I bought a 2022 Polestar 2 at the end of July, replacing a car I'd purchased new in 2002. The Polestar was half the price it'd been when it was new and only had 16,000 miles on it. I'm absolutely loving the electric car experience here in Seattle, and I took a road trip of 500 miles each way to my sister's home in Idaho as a test last week. The Volvo / Polestar NACS power adapter cost close to $300 after taxes but was absolutely worth it to open up more fast charging opportunities during a road trip.&lt;/p&gt;
    &lt;p&gt;The built in Google maps experience will suggest charging locations if you set a destination that is farther away than your current charge will take you. When I stopped at her home with 20% charge left it asked if I wanted it to find a nearby charging location. (I didn't because she had a power receptacle I could fully charge overnight.)&lt;/p&gt;
    &lt;p&gt;RE "...Not driving like a maniac, despite having more torque in this car ...."&lt;/p&gt;
    &lt;p&gt;I've always thought , the acceleration of electric cars should be limited. to conserve the battery and conserve battery charge.&lt;/p&gt;
    &lt;p&gt;When war* broke out in Ukraine's, quite a few bought an old leaf and swapped the battery with a newer versions battey pack. They bought them because diesel and gas deliveries were severely disrupted and expensive. Eventually this stopped, because of the electrid grid destruction and c.e. fuel was ok again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45136103</guid></item><item><title>IRHash: Efficient Multi-Language Compiler Caching by IR-Level Hashing</title><link>https://www.usenix.org/conference/atc25/presentation/landsberg</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45136367</guid></item><item><title>SAP splashes €20B on Euro sovereign cloud push</title><link>https://www.theregister.com/2025/09/04/sap_sovereign_cloud/</link><description>&lt;doc fingerprint="6dd85042300e2fcf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;SAP splashes €20B on Euro sovereign cloud push&lt;/head&gt;&lt;head rend="h2"&gt;German giant takes aim at US hyperscaler dominance as some EU customers fret amid Trump 2.0 rhetoric&lt;/head&gt;&lt;p&gt;SAP says it will pump €20 billion into expanding sovereign cloud infrastructure in Europe over the next ten years, pitching itself as a secure and compliant alternative to American cloud giants.&lt;/p&gt;&lt;p&gt;The Germany-based enterprise software biz is looking to provide sovereign infrastructure for the public sector and regulated environments, said Thomas Saueressig, board member for customer services and delivery.&lt;/p&gt;&lt;head rend="h2"&gt;Microsoft admits it 'cannot guarantee' data sovereignty&lt;/head&gt;READ MORE&lt;p&gt;"With our expanded SAP Sovereign Cloud offering, SAP is unlocking access to the full spectrum of cloud innovations and AI capabilities for all markets and industries while ensuring these advancements are delivered in a sovereign framework and on customers' own terms."&lt;/p&gt;&lt;p&gt;Data sovereignty in Europe is governed by the General Data Protection Regulation (GDPR). For example, in Ireland, Meta was fined €1.2 billion for inadequately safeguarding the transfer of European residents' data to the US.&lt;/p&gt;&lt;p&gt;SAP is offering three options for businesses concerned about data sovereignty and compliance.&lt;/p&gt;&lt;p&gt;First is SAP Cloud Infrastructure, an IaaS platform developed and operated with open source technologies within SAP's datacenter network. The vendor said all data is to be stored within the EU to maintain compliance with GDPR.&lt;/p&gt;&lt;p&gt;Secondly, SAP is offering a Sovereign Cloud On-Site within a customer-owned or customer-selected datacenter. It is designed to offer high levels of data, operational, technical, and legal sovereignty.&lt;/p&gt;&lt;p&gt;Lastly, SAP is offering Delos Cloud in Germany, which it says offers a secure and sovereign cloud flexible enough to meet country-specific sovereignty requirements.&lt;/p&gt;&lt;p&gt;"The digital resilience of Europe depends on sovereignty that is secure, scalable and future-ready," said Martin Merz, president, SAP Sovereign Cloud.&lt;/p&gt;&lt;p&gt;However, in June, SAP CEO Christian Klein warned against any efforts to compete with US cloud hyperscalers in Europe.&lt;/p&gt;&lt;p&gt;He said SAP had struck deals with French AI company Mistral and business services company Capgemini to support customers concerned about data sovereignty in Europe, but saw no point in replicating the effort at the level of cloud infrastructure.&lt;/p&gt;&lt;p&gt;"The only thing I would caution against in Europe is this: the competitiveness of Europe's car industry or chemical industry will not be by building 20 different datacenters in France and trying to compete against the US hyperscalers," Klein said.&lt;/p&gt;&lt;p&gt;"It's completely crazy, and that is sovereignty completely done in the wrong way. We need the best here in Europe to apply AI, to apply intelligent software to be the best, to produce much better, much faster cars, and be way more efficient running our supply chains."&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Microsoft can't guarantee data sovereignty – OVHcloud says 'We told you so'&lt;/item&gt;&lt;item&gt;When hyperscalers can't safeguard one nation's data from another, dark clouds are ahead&lt;/item&gt;&lt;item&gt;'Close to impossible' for Europe to escape clutches of US hyperscalers&lt;/item&gt;&lt;item&gt;'Impossible hill to climb': US clouds crush European competition on their home turf&lt;/item&gt;&lt;item&gt;European biz calls for Euro tech for local people&lt;/item&gt;&lt;/list&gt;&lt;p&gt;While SAP AI and data storage offers customers "complete sovereignty from the top to the bottom," US providers are also marketing data sovereignty solutions in Europe in a bid to counter concerns among some governments and commercial customers worried about the Trump 2.0 administration.&lt;/p&gt;&lt;p&gt;AWS, Google, and Microsoft have all responded to concerns that experts began to voice in February, weeks after the bombastic US president was sworn in.&lt;/p&gt;&lt;p&gt;An SAP spokesperson said the new investment covers the development, delivery, and maintenance of SAP's sovereign cloud solutions, including infrastructure, research and development, operating personnel, and compliance investments.&lt;/p&gt;&lt;p&gt;The company said Klein's caution was against wasting resources on trying to replicate hyperscalers' global infrastructure at massive scale – "prioritizing code over building concrete." His message was that Europe's competitiveness will come from software, AI, and applied innovation, not from duplicating datacenter capacity.&lt;/p&gt;&lt;p&gt;SAP's €20 billion investment is set to be a "targeted at full-stack sovereignty and ensures that Europe has choice and control where sovereignty matters most" such as in the public sector, regulated industries, and defense, the spokesperson said.&lt;/p&gt;&lt;p&gt;It is set to build on SAP's existing European datacenter footprint in Walldorf, Sankt Leon-Rot, and Frankfurt, while expanding capabilities with sovereign controls, new deployments at customer locations, and working with sovereign partners like Delos Cloud in Germany.&lt;/p&gt;&lt;p&gt;"SAP isn't competing with hyperscalers on scale or entering the IaaS business, but ensures that Europe can adopt cloud and AI securely, under European control. The investment is about building sovereignty into the stack – not about duplicating hyperscaler concrete," they said. ®&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45136558</guid></item><item><title>Nepal moves to block Facebook, X, YouTube and others</title><link>https://www.aljazeera.com/news/2025/9/4/nepal-moves-to-block-facebook-x-youtube-and-others</link><description>&lt;doc fingerprint="9894c6d400e0d759"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Nepal moves to block Facebook, X, YouTube and others&lt;/head&gt;&lt;p&gt;The restrictions come after the social media giants failed to meet state registration requirements, says government.&lt;/p&gt;&lt;p&gt;Nepal’s government has said it will shut off access to major social media platforms, including Facebook and X, after they failed to comply with authorities’ registration requirements.&lt;/p&gt;&lt;p&gt;The move, announced on Thursday, is part of what the government says is an effort to curb online hate, rumours and cybercrime.&lt;/p&gt;&lt;head rend="h2"&gt;Recommended Stories&lt;/head&gt;list of 3 items&lt;list rend="ul"&gt;&lt;item&gt;list 1 of 3‘Everest Man’ breaks own record for climbing world’s highest mountain&lt;/item&gt;&lt;item&gt;list 2 of 3Dozens missing after monsoon triggers Nepal-China floods&lt;/item&gt;&lt;item&gt;list 3 of 3Photos: The last nomads of Nepal&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Companies were given a deadline of Wednesday to register with the Ministry of Communications and Information Technology and provide a local contact, grievance handler and person responsible for self-regulation – or face shutdown.&lt;/p&gt;&lt;p&gt;“Unregistered social media platforms will be deactivated today onwards,” ministry spokesman Gajendra Kumar Thakur told AFP.&lt;/p&gt;&lt;p&gt;Communications and IT Minister Prithvi Subba Gurung said, “We gave them enough time to register and repeatedly requested them to comply with our request, but they ignored [this], and we had to shut their operations in Nepal.”&lt;/p&gt;&lt;p&gt;Meta, which owns Facebook, Instagram and WhatsApp, YouTube parent Alphabet, X, Reddit, and LinkedIn were asked to register by Wednesday’s deadline.&lt;/p&gt;&lt;p&gt;AFP reported that the platforms remained accessible on Thursday.&lt;/p&gt;&lt;head rend="h2"&gt;‘Directly hits fundamental rights’&lt;/head&gt;&lt;p&gt;The online restrictions follow a 2023 directive requiring social media platforms – which have millions of users in Nepal with accounts for entertainment, news and business – to register and establish a local presence.&lt;/p&gt;&lt;p&gt;Only five, including TikTok and Viber, have since formally registered, while two others are in the process.&lt;/p&gt;&lt;p&gt;Bhola Nath Dhungana, president of Digital Rights Nepal, said that the sudden closure shows the “controlling” approach of the government.&lt;/p&gt;&lt;p&gt;“This directly hits the fundamental rights of the public,” Dhungana said. “It is not wrong to regulate social media, but we first need to have the legal infrastructure to enforce it. A sudden closure like this is controlling.”&lt;/p&gt;&lt;p&gt;Nepal has restricted access to popular online platforms in the past.&lt;/p&gt;&lt;p&gt;Access was blocked to the Telegram messaging app in July, with the government citing a rise in online fraud and money laundering.&lt;/p&gt;&lt;p&gt;In August last year, Nepal lifted a nine-month ban on TikTok after the platform’s South Asia division agreed to comply with Nepali regulations.&lt;/p&gt;&lt;p&gt;Governments worldwide, including the United States, European Union, Brazil and Australia, are also tightening oversight of social media and big tech, citing concerns over misinformation, data privacy, online harm and national security. India has mandated local compliance officers and takedown mechanisms, while China maintains strict censorship and licensing controls.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45137363</guid></item><item><title>Relace (YC W23) Is Hiring for Code LLM's (SF)</title><link>https://news.ycombinator.com/item?id=45137554</link><description>&lt;doc fingerprint="25e92f79f76accfa"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hey, we're a highly technical team building code generation models, and growing fast. We're looking for people who are down to scrap and love to build -- on both technical and GTM/Devrel roles.&lt;/p&gt;
      &lt;p&gt;If you have a Physics, Math, CS degree; and training fast codegen models is something that piques your interest, please email me directly at pzhou@relace.ai.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45137554</guid></item></channel></rss>