<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 18 Nov 2025 18:15:51 +0000</lastBuildDate><item><title>Cloudflare Global Network experiencing issues</title><link>https://www.cloudflarestatus.com/?t=1</link><description>&lt;doc fingerprint="e73fa6963d75d8b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Ahmedabad, India - (AMD) Operational &lt;/p&gt;
      &lt;p&gt; Almaty, Kazakhstan - (ALA) Operational &lt;/p&gt;
      &lt;p&gt; Bangalore, India - (BLR) Operational &lt;/p&gt;
      &lt;p&gt; Bangkok, Thailand - (BKK) Operational &lt;/p&gt;
      &lt;p&gt; Bandar Seri Begawan, Brunei - (BWN) Partial Outage &lt;/p&gt;
      &lt;p&gt; Cebu, Philippines - (CEB) Operational &lt;/p&gt;
      &lt;p&gt; Chandigarh, India - (IXC) Operational &lt;/p&gt;
      &lt;p&gt; Changde, China - (CGD) Operational &lt;/p&gt;
      &lt;p&gt; Chennai, India - (MAA) Operational &lt;/p&gt;
      &lt;p&gt; Chittagong, Bangladesh - (CGP) Operational &lt;/p&gt;
      &lt;p&gt; Colombo, Sri Lanka - (CMB) Operational &lt;/p&gt;
      &lt;p&gt; Dhaka, Bangladesh - (DAC) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Foshan, China - (FUO) Operational &lt;/p&gt;
      &lt;p&gt; Fukuoka, Japan - (FUK) Operational &lt;/p&gt;
      &lt;p&gt; Fuzhou, China - (FOC) Operational &lt;/p&gt;
      &lt;p&gt; Guangzhou, China - (CAN) Operational &lt;/p&gt;
      &lt;p&gt; Haikou, China - (HAK) Operational &lt;/p&gt;
      &lt;p&gt; Hanoi, Vietnam - (HAN) Operational &lt;/p&gt;
      &lt;p&gt; Hengshui, China - (SJW) Operational &lt;/p&gt;
      &lt;p&gt; Ho Chi Minh City, Vietnam - (SGN) Partial Outage &lt;/p&gt;
      &lt;p&gt; Hong Kong - (HKG) Operational &lt;/p&gt;
      &lt;p&gt; Hyderabad, India - (HYD) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Islamabad, Pakistan - (ISB) Operational &lt;/p&gt;
      &lt;p&gt; Jakarta, Indonesia - (CGK) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Jinan, China - (TNA) Operational &lt;/p&gt;
      &lt;p&gt; Johor Bahru, Malaysia - (JHB) Operational &lt;/p&gt;
      &lt;p&gt; Kanpur, India - (KNU) Operational &lt;/p&gt;
      &lt;p&gt; Kaohsiung City, Taiwan - (KHH) Operational &lt;/p&gt;
      &lt;p&gt; Karachi, Pakistan - (KHI) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Kathmandu, Nepal - (KTM) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Kolkata, India - (CCU) Operational &lt;/p&gt;
      &lt;p&gt; Krasnoyarsk, Russia - (KJA) Operational &lt;/p&gt;
      &lt;p&gt; Kuala Lumpur, Malaysia - (KUL) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Langfang, China - (PKX) Operational &lt;/p&gt;
      &lt;p&gt; Macau - (MFM) Operational &lt;/p&gt;
      &lt;p&gt; Malé, Maldives - (MLE) Partial Outage &lt;/p&gt;
      &lt;p&gt; Manila, Philippines - (MNL) Under Maintenance &lt;/p&gt;
      &lt;p&gt; Mumbai, India - (BOM) Operational &lt;/p&gt;
      &lt;p&gt; Nagpur, India - (NAG) Operational &lt;/p&gt;
      &lt;p&gt; Naha, Japan - (OKA) Operational &lt;/p&gt;
      &lt;p&gt; New Delhi, India - (DEL) Operational &lt;/p&gt;
      &lt;p&gt; Osaka, Japan - (KIX) Operational &lt;/p&gt;
      &lt;p&gt; Patna, India - (PAT) Operational &lt;/p&gt;
      &lt;p&gt; Phnom Penh, Cambodia - (PNH) Partial Outage &lt;/p&gt;
      &lt;p&gt; Qingdao, China - (TAO) Operational &lt;/p&gt;
      &lt;p&gt; Seoul, South Korea - (ICN) Operational &lt;/p&gt;
      &lt;p&gt; Shanghai, China - (SHA) Operational &lt;/p&gt;
      &lt;p&gt; Singapore, Singapore - (SIN) Operational &lt;/p&gt;
      &lt;p&gt; Surat Thani, Thailand - (URT) Partial Outage &lt;/p&gt;
      &lt;p&gt; Taipei - (TPE) Operational &lt;/p&gt;
      &lt;p&gt; Tokyo, Japan - (NRT) Operational &lt;/p&gt;
      &lt;p&gt; Ulaanbaatar, Mongolia - (ULN) Operational &lt;/p&gt;
      &lt;p&gt; Vientiane, Laos - (VTE) Partial Outage &lt;/p&gt;
      &lt;p&gt; Xinyu, China - (KHN) Operational &lt;/p&gt;
      &lt;p&gt; Yerevan, Armenia - (EVN) Operational &lt;/p&gt;
      &lt;p&gt; Yogyakarta, Indonesia - (JOG) Operational &lt;/p&gt;
      &lt;p&gt; Cagayan de Oro, Philippines - (CGY) Operational &lt;/p&gt;
      &lt;p&gt; Kochi, India - (COK) Operational &lt;/p&gt;
      &lt;p&gt; Denpasar, Indonesia - (DPS) Operational &lt;/p&gt;
      &lt;p&gt; Kannur, India - (CNN) Operational &lt;/p&gt;
      &lt;p&gt; Shenzhen, China - (SZX) Operational &lt;/p&gt;
      &lt;p&gt; Guiyang, China - (KWE) Operational &lt;/p&gt;
      &lt;p&gt; Shaoxing, China - (HGH) Operational &lt;/p&gt;
      &lt;p&gt; Changzhou, China - (CZX) Operational &lt;/p&gt;
      &lt;p&gt; Kunming, China - (KMG) Operational &lt;/p&gt;
      &lt;p&gt; Chiang Mai, Thailand - (CNX) Partial Outage &lt;/p&gt;
      &lt;p&gt; Zhengzhou, China - (CGO) Operational &lt;/p&gt;
      &lt;p&gt; Yangquan, China - (TYN) Operational &lt;/p&gt;
      &lt;p&gt; Changsha, China - (CSX) Operational &lt;/p&gt;
      &lt;p&gt; Dalian, China - (DLC) Operational &lt;/p&gt;
      &lt;p&gt; Beihai, China - (BHY) Operational &lt;/p&gt;
      &lt;p&gt; Chongqing, China - (CKG) Operational &lt;/p&gt;
      &lt;p&gt; Xiangyang, China - (XFN) Operational &lt;/p&gt;
      &lt;p&gt; Da Nang, Vietnam - (DAD) Operational &lt;/p&gt;
      &lt;p&gt; Jiaxing, China - (JXG) Operational &lt;/p&gt;
      &lt;p&gt; Tarlac City, Philippines - (CRK) Partial Outage &lt;/p&gt;
      &lt;p&gt; Thimphu, Bhutan - (PBH) Operational &lt;/p&gt;
      &lt;p&gt; Baoji, China - (XIY) Operational &lt;/p&gt;
      &lt;p&gt; Astana, Kazakhstan - (NQZ) Partial Outage &lt;/p&gt;
      &lt;p&gt; Nanning, China - (NNG) Operational &lt;/p&gt;
      &lt;p&gt; Zibo, China - (TNA) Operational &lt;/p&gt;
      &lt;p&gt; Kuching, Malaysia - (KCH) Operational &lt;/p&gt;
      &lt;p&gt; Aktobe, Kazakhstan - (AKX) Operational &lt;/p&gt;
      &lt;p&gt; Chengmai, China - (HAK) Operational &lt;/p&gt;
      &lt;p&gt; Nanchang, China - (KHN) Operational &lt;/p&gt;
      &lt;p&gt; Male, Maldives - (MLE) Operational &lt;/p&gt;
      &lt;p&gt; Tongren, China - (TEN) Operational &lt;/p&gt;
      &lt;p&gt; Taizhou, China - (HYN) Operational &lt;/p&gt;
      &lt;p&gt; Shijiazhuang, China - (SJW) Operational &lt;/p&gt;
      &lt;p&gt; Xining, China - (XNN) Operational &lt;/p&gt;
      &lt;p&gt; Bishkek, Kyrgyzstan - (FRU) Operational &lt;/p&gt;
      &lt;p&gt; Malang, Indonesia - (MLG) Operational &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963780</guid><pubDate>Tue, 18 Nov 2025 11:35:10 +0000</pubDate></item><item><title>Gemini 3 Pro Model Card</title><link>https://pixeldrain.com/u/hwgaNKeH</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963836</guid><pubDate>Tue, 18 Nov 2025 11:40:01 +0000</pubDate></item><item><title>Mathematics and Computation (2019) [pdf]</title><link>https://www.math.ias.edu/files/Book-online-Aug0619.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45964816</guid><pubDate>Tue, 18 Nov 2025 12:35:13 +0000</pubDate></item><item><title>GoSign Desktop RCE flaws affecting users in Italy</title><link>https://www.ush.it/2025/11/14/multiple-vulnerabilities-gosign-desktop-remote-code-execution/</link><description>&lt;doc fingerprint="359ee30e981be4d0"&gt;
  &lt;main&gt;
    &lt;p&gt;Pasquale "sid" Fiorillo discovered a critical vulnerability in GoSign Desktop &amp;lt;= 2.4.0 that allows an attacker to execute arbitrary code on the system through insecure updates and a TLS bypass. The exploit leverages the deactivation of TLS certificate verification when a proxy is configured, together with an update mechanism based on unsigned manifests.&lt;/p&gt;
    &lt;p&gt;The vendor, Tinexta InfoCert, initially cooperative, ceased all communication after receiving the technical details, ignoring follow?up requests and releasing version 2.4.1 without any public notice or acknowledgment of the researchers. Due to this opaque behavior, which does not align with responsible disclosure best practices, a forced disclosure was carried out.&lt;/p&gt;
    &lt;quote&gt;Multiple Vulnerabilities in GoSign Desktop leads to Remote Code Execution Name TLS Verification Bypass and Insecure Update in GoSign Desktop Systems Affected GoSign Desktop &amp;lt;= 2.4.0 Severity High 8.2/10 Impact CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:C/C:H/I:H/A:H Vendor https://www.infocert.it/ Advisory https://www.ush.it/team/ush/hack-gosign-desktop_240/gosign-desktop-exec.txt Authors Pasquale "sid" Fiorillo (sid AT ush DOT it) Francesco "ascii" Ongaro (ascii AT ush DOT it) Marco Lunardi Date 20251003 I. BACKGROUND GoSign is an advanced and qualified electronic signature solution developed by Tinexta InfoCert S.p.A., used by public administrations, businesses, and professionals to manage approval workflows with traceability and security. The SaaS/web version of the product has received the "QC2" qualification from the Italian National Cybersecurity Agency (ACN). The QC2 qualification certifies a service's ability to securely handle critical data, including data processed by public administrations. Under ACN's regulation effective from August 1, 2024, cloud service providers for public entities must meet strict security and resilience requirements. This qualification enables public administrations to adopt certified solutions for safeguarding sensitive data and ensuring continuity of essential services. GoSign Desktop, subject of this advisory, is the on-premise version released for Microsoft Windows, Linux Ubuntu, and Apple macOS. II. DESCRIPTION We have identified a critical vulnerability in the GoSign Desktop software, developed by Tinexta InfoCert. The platform is widely used for signing, verifying, and managing electronic documents. In 2021 alone, it was used by 1.6 million people to perform over 830 million signing transactions, confirming its central role in the Italian and European digital ecosystem. GoSign Desktop disables TLS certificate validation (`SSL_VERIFY_NONE`) in the `libdgsapi.so` and `libcurl.so` modules when configured to use a proxy server, removing any assurance regarding server identity during encrypted communications. This compromises the security of TLS connections and opens the door to Man-in-the-Middle (MitM) attacks. Additionally, the update mechanism relies on an unsigned manifest, meaning security depends entirely on the TLS layer. We verified three attack scenarios that severely impact the security of GoSign Desktop users: Malicious software installation (Critical): A network attacker can deceive the client into installing fake updates, taking control of the machine with the privileges of the user running GoSign Desktop (Windows, macOS) or with administrative privileges (Linux). Credential theft (High): Access information (tokens, temporary passwords) can be intercepted because the application does not verify the server's identity. Privilege escalation (High): A local attacker with the same privileges as the GoSign Desktop user can enable proxy settings and inject a malicious update to gain full control of the system (Linux). III. ANALYSIS 1) TLS verification bypass The `GoSignDesktop` process, through `libdgsapi.so` and `libcurl.so`, disables TLS certificate verification by invoking `SSL_CTX_set_verify(mode=SSL_VERIFY_NONE)` when configured to use a proxy server. This setting completely disables certificate validation during the TLS handshake, effectively nullifying the authenticity and confidentiality guarantees of the TLS channel. As a result, a remote attacker can perform Man-in-the-Middle (MitM) attacks to intercept and manipulate traffic. Neither the authenticity of the InfoCert server nor the proxy server is verified. The vulnerability was confirmed in methods related to update checks (`UpdateManager::get_manifest`, `UpdateManager::check_and_download`) and OAuth renewal and authentication operations (`ISACBinder::refresh` and `UpdateManager::getIdentity`). However, it is plausible that any request originating from `libdgsapi.so` is affected by the same certificate validation issue. Tested and vulnerable versions due to lack of TLS certificate validation: - GoSign Desktop 2.4.0 (standard) Windows - GoSign Desktop 2.4.0 (standard) Linux The vendor confirms that the macOS version is also affected: - GoSign Desktop 2.4.0 (standard) macOS 1.1) Insecure Update The GoSign Desktop update mechanism relies on an unsigned manifest containing the package URL and its SHA-256 hash. A MitM attacker can provide a malicious manifest with a matching hash, tricking the client into downloading and installing a tampered package, resulting in remote code execution. Effectively, the update manifest's authentication is entirely delegated to the TLS layer, which is not validated-thus rendering all authenticity guarantees ineffective. This architecture is conceptually flawed: since the manifest is not digitally signed, it protects at most against accidental integrity issues (e.g., corrupted files) but offers no defense against active attacks. Without valid TLS and manifest signing, an attacker can replace both the package and its hash, fully bypassing the security mechanism. Instead of adopting established solutions for secure software distribution, a custom mechanism was implemented that reintroduces well-known, extensively documented risks. This design choice was avoidable given the availability of reliable, industry-standard approaches that would have ensured update integrity and authenticity. 1.2) Verified Security Impacts We have confirmed three concrete attack scenarios that severely compromise the security of GoSign Desktop: - OAuth Secrets Information Disclosure - Remote Code Execution - Privilege Escalation It is likely that additional attack vectors exist but have not yet been identified. Given the severity of the confirmed impacts, we immediately alerted the relevant authorities (ACN/CSIRT Italia) to ensure responsible and timely incident handling. 1.3) CVSS 3.1 CVSS Base Score: 8.2 CVSS Vector: AV:L/AC:L/PR:L/UI:R/S:C/C:H/I:H/A:H 1.4) CWE Mappings CWE-295: Improper Certificate Validation - use of SSL_VERIFY_NONE / disabled TLS verification CWE-347: Improper Verification of Cryptographic Signature - absence of signature validation on manifests/metadata CWE-200: Exposure of Sensitive Information to an Unauthorized Actor - OAuth secrets exposed over an unverified channel 2) Attack scenarios 2.1) MitM In a typical Man-in-the-Middle (MitM) attack scenario, an attacker positioned to intercept network traffic can respond to TLS requests initiated by GoSign Desktop by presenting a self-signed certificate. Since GoSign Desktop disables certificate validation when configured to use a proxy, the client establishes the connection without verifying the server's identity. The attacker can thus intercept and read sensitive requests and responses-specifically, OAuth calls may disclose secrets such as client_secret, JWT tokens, or refresh tokens. Simultaneously, the attacker can respond to update requests by providing a tampered manifest that points to a compromised package and includes the SHA-256 hash of the malicious payload. Because the client has neither TLS verification enabled nor a digital signature on the manifest, it downloads the update and executes the attacker's code with administrative (root) privileges if running on Linux, or with the privileges of the user running GoSign on Windows or macOS. 2.2) Privilege Escalation A second exploitation vector involves the preliminary compromise of the unprivileged user account running GoSign Desktop. A local attacker can independently modify the HTTP-PROXY settings in the configuration file ~/.gosign/dike.conf, causing the client to download a malicious update and thereby escalate privileges to root. Proof of Concept Video: https://www.ush.it/team/ush/hack-gosign-desktop_240/gosigndesktop_mitm_poc.mp4 Proof of Concept Exploit: https://www.ush.it/team/ush/hack-gosign-desktop_240/ IV. WORKAROUND Fix in GoSign Desktop 2.4.1 In version 2.4.1 of GoSign Desktop, released on 2025-11-04, a fix was introduced to verify the digital signature of the update manifest. However, the lack of TLS certificate validation when the application is configured to use a proxy remains unaddressed. - Information Disclosure of OAuth secrets â€“ NOT FIXED - Remote Code Execution â€“ FIXED - Privilege Escalation â€“ FIXED VI. VENDOR RESPONSE Handling of Responsible Disclosure by Vendor Tinexta InfoCert Following the initial contact, the vendor was provided with all technical details of the vulnerability, the Proof of Concept (PoC), and mitigation suggestions-both via encrypted email and during a Teams call requested by the vendor and held on 2025-10-16 at 15:00. Present at the call were the InfoCert security officer and the product manager for GoSign Desktop. During the call, the vendor confirmed the vulnerability and agreed that October 31, 2025, was a reasonable deadline for releasing a fix. After this call, the vendor ceased all communication, failed to provide any further updates, and did not respond to subsequent contact attempts. On 2025-11-04, the fix was released publicly without any announcement from the vendor and without honoring the request to include a changelog acknowledgment. ACN/CSIRT Italia was notified about the vendor's improper handling of responsible disclosure best practices. VII. CVE INFORMATION Mitre is unresponsive. VIII. DISCLOSURE TIMELINE 2025-10-03: Vulnerability discovered 2025-10-04: Proof of Concept developed 2025-10-04: Initial contact attempt to InfoCert S.p.A. 2025-10-04: Concurrent notification sent to ACN/CSIRT Italia 2025-10-04: Response from ACN/CSIRT Italia acknowledging receipt and awaiting further developments 2025-10-07: Response from InfoCert Cyber Security Operation 2025-10-07: Technical details and evidence shared with the vendor 2025-10-09: InfoCert acknowledges the report and states the issue is under investigation 2025-10-16: Technical call with InfoCert; vulnerability confirmed; over 1 million users affected. Full technical details and remediation suggestions shared during the call 2025-10-26: Follow-up request for update sent to vendor; no response received 2025-11-04: Version 2.4.1 released; no communication or changelog from the vendor 2025-11-08: Further request for explanation and update sent to the vendor; no response 2025-11-14: Report submitted to ACN/CSIRT Italia regarding vendor's mishandling of disclosure process 2025-11-14: Advisory published IX. TECHNICAL DETAILS Collected evidence indicates that the disabling of TLS certificate verification is not an isolated anomaly: the `SSL_VERIFY_NONE` behavior is systematically applied during the initialization of TLS connections by GoSign Desktop when the proxy setting is enabled. To demonstrate this, a dynamic runtime instrumentation approach was used, intercepting OpenSSL APIs responsible for certificate verification configuration. The findings confirm that the application's default behavior sets the `SSL_VERIFY_NONE` flag and that certificate checks are explicitly disabled. In its current configuration, GoSign effectively functions as a backdoor installed on a vast number of systems used by major public administrations, ministries, and Italian enterprises. To observe this behavior at runtime, a hook library (LD_PRELOAD) was developed to intercept calls to `SSL_CTX_set_verify()` and `SSL_set_verify()` functions exported by the cryptographic libraries. --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- /* gcc -shared -fPIC -o log_ssl_verify.so log_ssl_verify.c -ldl -rdynamic */ #define _GNU_SOURCE #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;dlfcn.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;execinfo.h&amp;gt; #include &amp;lt;stdint.h&amp;gt; typedef void (*ssl_ctx_set_verify_t)(void*, int, void*); typedef void (*ssl_set_verify_t)(void*, int); static ssl_ctx_set_verify_t real_SSL_CTX_set_verify = NULL; static ssl_set_verify_t real_SSL_set_verify = NULL; static void dump_backtrace(FILE *f) { void *buffer[50]; int nptrs = backtrace(buffer, 50); char **strings = backtrace_symbols(buffer, nptrs); if (strings != NULL) { for (int i = 0; i &amp;lt; nptrs; ++i) { fprintf(f, " %s\n", strings[i]); } free(strings); } else { fprintf(f, " &amp;lt;no backtrace available&amp;gt;\n"); } } void SSL_CTX_set_verify(void *ctx, int mode, void *cb) { if (!real_SSL_CTX_set_verify) { real_SSL_CTX_set_verify = (ssl_ctx_set_verify_t)dlsym(RTLD_NEXT, "SSL_CTX_set_verify"); } FILE *f = fopen("/tmp/gosign_ssl_verify.log", "a"); if (f) { fprintf(f, "PID %d: SSL_CTX_set_verify called with mode=%d\n", getpid(), mode); dump_backtrace(f); fclose(f); } if (real_SSL_CTX_set_verify) real_SSL_CTX_set_verify(ctx, mode, cb); } void SSL_set_verify(void *ssl, int mode) { if (!real_SSL_set_verify) { real_SSL_set_verify = (ssl_set_verify_t)dlsym(RTLD_NEXT, "SSL_set_verify"); } FILE *f = fopen("/tmp/gosign_ssl_verify.log", "a"); if (f) { fprintf(f, "PID %d: SSL_set_verify called with mode=%d\n", getpid(), mode); dump_backtrace(f); fclose(f); } if (real_SSL_set_verify) real_SSL_set_verify(ssl, mode); } --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- Process launch and log capture in `gosign_ssl_verify.log`: --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- export LD_PRELOAD=./log_ssl_verify.so /usr/lib/gosigndesktop/GoSignDesktop &amp;amp; disown --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- Startup log: --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- $ export LD_PRELOAD=./log_ssl_verify.so $ /usr/lib/gosigndesktop/GoSignDesktop &amp;amp; disown [1] 282062 $ Profile verified! Using @ffi-napi 2025-10-03 21:21:22.977 [info] info LoggerElectron initialized 2025-10-03 21:21:22.978 [info] Current log level: { verbose: false, defaultLogLevel: 'info' } 2025-10-03 21:21:23.191 [info] (main) homeDir is '/home/sid/.gosign' Creating certificate store: {"filename":"/home/sid/.gosign/certificates.db","autoload":true} Creating option store: {"filename":"/home/sid/.gosign/options.db","autoload":true} ~ Analytics ~ currentCustomization standard Native module: @ice/dike-core-linux x64 2025-10-03 21:21:23.200 [info] (DikeClients) Loading profile from: /usr/lib/gosigndesktop/resources/app/current-customization/profile.jwt 2025-10-03 21:21:23.200 [info] (DikeClients) Homepath for core library is '/home/sid/.gosign' HOME_PATH: /home/sid/.gosign 2025-10-03 21:21:23.201 [warn] (DikeClients) LIBRARY PATH __dirname IS STILL BROKEN, PLEASE CHECK ISSUE ON GITHUB!!! https://github.com/electron/electron/issues/8206 2025-10-03 21:21:23.201 [info] (DikeClients) ======================= PRODUCTION ENV ======================= Native module: @ice/dike-core-linux x64 Profile verified! 2025:10:03 21:21:23 (0xfd27cd80)[INFO][dgs] (prepare_tempdir): Removing session dir /home/sid/.gosign/sessiondir_7cb271e1 Scheduler -&amp;gt; getMessages Registering channel get-version Registering channel jobs-channel Registering channel add-jobs-channel Registering channel test-pin Registering channel set-configuration Registering channel get-session-params Registering channel device-list Registering channel change-pin Registering channel unlock-pin Registering channel unlock-ce-pin [..] --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- Contents of `gosign_ssl_verify.log` showing evidence of `SSL_CTX_set_verify(mode=0)` and the corresponding backtrace: --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- PID 282062: SSL_CTX_set_verify called with mode=0 ./log_ssl_verify.so(+0x1272) [0x796e00465272] ./log_ssl_verify.so(SSL_CTX_set_verify+0x9b) [0x796e004653e2] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x734f4) [0x796dfcabb4f4] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x7419f) [0x796dfcabc19f] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x74b09) [0x796dfcabcb09] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x1a8ef) [0x796dfca628ef] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x14ca5) [0x796dfca5cca5] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x189bf) [0x796dfca609bf] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x483e9) [0x796dfca903e9] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_multi_perform+0xea) [0x796dfca9195a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_easy_perform+0x14b) [0x796dfca6c7eb] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs14NetworkRequest7executeEv+0x54e) [0x796df3d8dc9e] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs10ISACBinder7refreshERNS_12IdentityDataE+0x450) [0x796df3d733e0] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs10ISACBinder11getIdentityERNS_12IdentityDataEb+0x55d) [0x796df3d7ab5d] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(dgs_oauth_get_identity+0x1b7) [0x796df3c2efc7] /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x796dfe7efb16] /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x796dfe7ec3ef] /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x796dfe7ef0be] /usr/lib/gosigndesktop/resources/app/node_modules/ffi-napi/build/Release/ffi_bindings.node(_ZN3FFI3FFI12AsyncFFICallEP9uv_work_s+0x23) [0x796dfcaef533] /usr/lib/gosigndesktop/GoSignDesktop(+0x18f14d4) [0x59e78df734d4] PID 282062: SSL_CTX_set_verify called with mode=0 ./log_ssl_verify.so(+0x1272) [0x796e00465272] ./log_ssl_verify.so(SSL_CTX_set_verify+0x9b) [0x796e004653e2] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x734f4) [0x796dfcabb4f4] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x7419f) [0x796dfcabc19f] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x74b09) [0x796dfcabcb09] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x1a8ef) [0x796dfca628ef] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x14ca5) [0x796dfca5cca5] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x189bf) [0x796dfca609bf] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x483e9) [0x796dfca903e9] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_multi_perform+0xea) [0x796dfca9195a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_easy_perform+0x14b) [0x796dfca6c7eb] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs14NetworkRequest7executeEv+0x54e) [0x796df3d8dc9e] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs13UpdateManager12get_manifestERNS0_14UpdateManifestE+0x2bb) [0x796df3e2dc5b] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs13UpdateManager18check_and_downloadERNS_17UpdateManagerDataEb+0x178) [0x796df3e30bd8] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN5boost10statechart12simple_stateIN3dgs16WaitCheckRequestENS2_10UpdaterFSMENS_3mpl4listIN4mpl_2naES8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_S8_EELNS0_12history_modeE0EE10react_implERKNS0_10event_baseEPKv+0x1e5) [0x796df3d0cb25] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs10UpdaterFSM18process_event_jsonE14DGS_FLOW_EVENTRKN8nlohmann10basic_jsonISt3mapSt6vectorNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEblmdSaNS2_14adl_serializerES5_IhSaIhEEEE+0x43a) [0x796df3d0171a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs7FlowFSM12processeventE14DGS_FLOW_EVENTRKN8nlohmann10basic_jsonISt3mapSt6vectorNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEblmdSaNS2_14adl_serializerES5_IhSaIhEEEE+0x53) [0x796df3cccb73] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(dgs_flow_post_event+0xc5) [0x796df3c30085] /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x796dfe7efb16] /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x796dfe7ec3ef] /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x796dfe7ef0be] /usr/lib/gosigndesktop/resources/app/node_modules/ffi-napi/build/Release/ffi_bindings.node(_ZN3FFI3FFI12AsyncFFICallEP9uv_work_s+0x23) [0x796dfcaef533] /usr/lib/gosigndesktop/GoSignDesktop(+0x18f14d4) [0x59e78df734d4] PID 282062: SSL_CTX_set_verify called with mode=0 ./log_ssl_verify.so(+0x1272) [0x796e00465272] ./log_ssl_verify.so(SSL_CTX_set_verify+0x9b) [0x796e004653e2] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x734f4) [0x796dfcabb4f4] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x7419f) [0x796dfcabc19f] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x74b09) [0x796dfcabcb09] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x1a8ef) [0x796dfca628ef] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x14ca5) [0x796dfca5cca5] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x189bf) [0x796dfca609bf] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x483e9) [0x796dfca903e9] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_multi_perform+0xea) [0x796dfca9195a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_easy_perform+0x14b) [0x796dfca6c7eb] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x5873e) [0x796df2ae673e] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x59e85) [0x796df2ae7e85] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x2f884) [0x796df2abd884] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libdeSign.so(_Z9loadEUTSLv+0x26) [0x796df2098386] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs6Design13isTSLToUpdateE16DGS_COUNTRY_CODE+0x4a) [0x796df3c116fa] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs10TSLManager18check_TSLs_updatesEv+0xa7) [0x796df3e2bc07] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs4Core16tsl_checkupdatesERNS_7TSLDataE+0x2c) [0x796df3bb865c] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(dgs_tsl_checkupdates+0x87) [0x796df3c2f357] /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x796dfe7efb16] /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x796dfe7ec3ef] /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x796dfe7ef0be] /usr/lib/gosigndesktop/resources/app/node_modules/ffi-napi/build/Release/ffi_bindings.node(_ZN3FFI3FFI12AsyncFFICallEP9uv_work_s+0x23) [0x796dfcaef533] /usr/lib/gosigndesktop/GoSignDesktop(+0x18f14d4) [0x59e78df734d4] PID 282062: SSL_CTX_set_verify called with mode=0 ./log_ssl_verify.so(+0x1272) [0x796e00465272] ./log_ssl_verify.so(SSL_CTX_set_verify+0x9b) [0x796e004653e2] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x734f4) [0x796dfcabb4f4] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x7419f) [0x796dfcabc19f] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x74b09) [0x796dfcabcb09] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x1a8ef) [0x796dfca628ef] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x14ca5) [0x796dfca5cca5] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x189bf) [0x796dfca609bf] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x483e9) [0x796dfca903e9] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_multi_perform+0xea) [0x796dfca9195a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_easy_perform+0x14b) [0x796dfca6c7eb] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x5873e) [0x796df2ae673e] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x59e85) [0x796df2ae7e85] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcaCRLCache.so(+0x31007) [0x796df2abf007] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libdeSign.so(_Z26checkCountryCACertsUpdatesPc+0x2d) [0x796df20987bd] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs6Design13isTSLToUpdateE16DGS_COUNTRY_CODE+0xd0) [0x796df3c11780] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs10TSLManager18check_TSLs_updatesEv+0xa7) [0x796df3e2bc07] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs4Core16tsl_checkupdatesERNS_7TSLDataE+0x2c) [0x796df3bb865c] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(dgs_tsl_checkupdates+0x87) [0x796df3c2f357] /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x796dfe7efb16] /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x796dfe7ec3ef] /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x796dfe7ef0be] /usr/lib/gosigndesktop/resources/app/node_modules/ffi-napi/build/Release/ffi_bindings.node(_ZN3FFI3FFI12AsyncFFICallEP9uv_work_s+0x23) [0x796dfcaef533] /usr/lib/gosigndesktop/GoSignDesktop(+0x18f14d4) [0x59e78df734d4] PID 282062: SSL_CTX_set_verify called with mode=0 ./log_ssl_verify.so(+0x1272) [0x796e00465272] ./log_ssl_verify.so(SSL_CTX_set_verify+0x9b) [0x796e004653e2] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x734f4) [0x796dfcabb4f4] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x7419f) [0x796dfcabc19f] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x74b09) [0x796dfcabcb09] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x1a8ef) [0x796dfca628ef] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x14ca5) [0x796dfca5cca5] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x189bf) [0x796dfca609bf] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(+0x483e9) [0x796dfca903e9] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_multi_perform+0xea) [0x796dfca9195a] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/lib/libcurl.so.4(curl_easy_perform+0x14b) [0x796dfca6c7eb] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs14NetworkRequest7executeEv+0x54e) [0x796df3d8dc9e] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(_ZN3dgs14NetworkManager15checkConnectionEv+0xd2) [0x796df3d8ec92] /usr/lib/gosigndesktop/resources/app/node_modules/@ice/dike-core-js/node_modules/@ice/dike-core-linux/native/libdgsapi.so(dgs_check_connection+0x2b) [0x796df3c27e2b] /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x796dfe7efb16] /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x796dfe7ec3ef] /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x796dfe7ef0be] /usr/lib/gosigndesktop/resources/app/node_modules/ffi-napi/build/Release/ffi_bindings.node(_ZN3FFI3FFI12AsyncFFICallEP9uv_work_s+0x23) [0x796dfcaef533] /usr/lib/gosigndesktop/GoSignDesktop(+0x18f14d4) [0x59e78df734d4] --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- Static analysis of the binary `/usr/lib/gosigndesktop/GoSignDesktop` returned a series of strings suggesting the existence of flags and parameters intended to disable TLS checks or log cryptographic information. These occurrences indicate that the code includes mechanisms (or supports parameters) which, if enabled, can alter certificate verification behavior or activate sensitive TLS key logging. --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- $ strings -n 1 /usr/lib/gosigndesktop/GoSignDesktop | grep -i -E 'ignore-certificate-errors|certificate-error|ignore-urlfetcher-cert-requests|ssl-key-log-file' &amp;gt; binary_relevant_strings.txt' $ cat binary_relevant_strings.txt certificate-error ssl-key-log-file argument missing ignore-urlfetcher-cert-requests ignore-certificate-errors-spki-list ssl-key-log-file ignore-certificate-errors [..] --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- To verify whether these parameters were passed to the running process, the command line of all GoSignDesktop processes was checked by reading their respective `/proc/&amp;lt;pid&amp;gt;/cmdline`. On the analyzed systems, the binary's execution shows that child processes use various `--type` arguments (zygote, gpu-process, renderer, etc.) and internal options typical of Chromium/Electron-based runtimes, but no flags explicitly disabling TLS verification were found. --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- $ for p in $( pgrep -f GoSignDesktop ); do echo "=== PID $p ===" &amp;gt;&amp;gt; proc_cmdlines.txt; cat /proc/$p/cmdline 2&amp;gt;/dev/null | tr '\0' ' ' &amp;gt;&amp;gt; proc_cmdlines.txt || echo "no /proc/$p/cmdline" &amp;gt;&amp;gt; proc_cmdlines.txt; echo &amp;gt;&amp;gt; proc_cmdlines.txt; done $ cat proc_cmdlines.txt === PID 282062 === /usr/lib/gosigndesktop/GoSignDesktop === PID 282065 === /usr/lib/gosigndesktop/GoSignDesktop --type=zygote --no-zygote-sandbox === PID 282066 === /usr/lib/gosigndesktop/chrome-sandbox /usr/lib/gosigndesktop/GoSignDesktop --type=zygote === PID 282067 === /usr/lib/gosigndesktop/GoSignDesktop --type=zygote === PID 282069 === /usr/lib/gosigndesktop/GoSignDesktop --type=zygote === PID 282106 === /usr/lib/gosigndesktop/GoSignDesktop --type=gpu-process --field-trial-handle=13821780690570354888,7554827926380561664,131072 --enable-features=WebComponentsV0Enabled --disable-features=CookiesWithoutSameSiteMustBeSecure,SameSiteByDefaultCookies,SpareRendererForSitePerProcess --gpu-preferences=OAAAAAAAAAAgAAAQAAAAAAAAAAAAAAAAAABgAAAAAAAYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAAAAAAAA== --shared-files === PID 282114 === /usr/lib/gosigndesktop/GoSignDesktop --type=utility --utility-sub-type=network.mojom.NetworkService --field-trial-handle=13821780690570354888,7554827926380561664,131072 --enable-features=WebComponentsV0Enabled --disable-features=CookiesWithoutSameSiteMustBeSecure,SameSiteByDefaultCookies,SpareRendererForSitePerProcess --lang=en-US --service-sandbox-type=network --standard-schemes=file --secure-schemes=file --bypasscsp-schemes --cors-schemes --fetch-schemes --service-worker-schemes --streaming-schemes --shared-files=v8_context_snapshot_data:100 === PID 282279 === /usr/lib/gosigndesktop/GoSignDesktop --type=renderer --field-trial-handle=13821780690570354888,7554827926380561664,131072 --enable-features=WebComponentsV0Enabled --disable-features=CookiesWithoutSameSiteMustBeSecure,SameSiteByDefaultCookies,SpareRendererForSitePerProcess --lang=en-US --standard-schemes=file --secure-schemes=file --bypasscsp-schemes --cors-schemes --fetch-schemes --service-worker-schemes --streaming-schemes --app-path=/usr/lib/gosigndesktop/resources/app --node-integration-in-worker --no-sandbox --no-zygote --preload=/usr/lib/gosigndesktop/resources/app/preload.js --context-isolation --background-color=#fff --enable-spellcheck --enable-websql --disable-electron-site-instance-overrides --num-raster-threads=4 --enable-main-frame-before-activation --renderer-client-id=4 --no-v8-untrusted-code-mitigations --shared-files=v8_context_snapshot_data:100 --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- HTTP traffic demonstrating the lack of a digital signature on the update manifest: --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- GET /gosign/download/update HTTP/1.1 Host: rinnovofirma.infocert.it Cookie: Accept: application/json Cache-Control: no-cache Connection: keep-alive HTTP/1.1 200 OK Date: Fri, 03 Oct 2025 21:44:39 GMT Server: Apache Content-Security-Policy: upgrade-insecure-requests; frame-ancestors none; object-src none X-Frame-Options: SAMEORIGIN Last-Modified: Thu, 04 Sep 2025 10:16:23 GMT ETag: "453-63df703669aaa" Accept-Ranges: bytes Content-Length: 1107 Vary: Accept-Encoding Keep-Alive: timeout=15, max=100 Connection: Keep-Alive Content-Type: application/json { "control":{ "probability": 100 }, "darwin": { "2.3.7": { "packages": { "dmg": { "any": { "url": "https://gosignupdates.infocert.it/gosign/standard/GoSignDesktop-standard-2.3.7-8aa7cbe.dmg", "sha256": "05ae06770253f2dadc9cce36b44d1198781eb874bb19fd10a10d8311749e4b84", "size": 163804666 , "releaseDate": "2025-05-26" } } }, "type": "MANDATORY" } }, "linux": { "2.4.0": { "packages": { "deb": { "64": { "url": "https://gosignupdates.infocert.it/gosign/standard/gosigndesktop_2.4.0_amd64.deb", "sha256": "02b7bc38365f3e456c4f41ef7ccd4bfa2134e54868345aad323823aabe740576", "size": 102522536, "releaseDate": "2025-04-04" } } }, "type": "MANDATORY" } } } --8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;--8&amp;lt;-- X. PoC The provided Proof of Concept targets a GoSign Desktop installation on Debian/Ubuntu Linux with amd64 architecture and simulates a local privilege escalation to root by a local attacker. After the exploit, you will need to reinstall GoSign Desktop by downloading it again from the official website, as it is replaced by the fake update package. The GoSign Desktop configuration is preserved. https://www.ush.it/team/ush/hack-gosign-desktop_240/gosigndesktop_mitm_poc.mp4 1) Build Compile the fake .deb update package and create the Python virtual environment with the dependencies required for the exploit: `make` 2) Run Configure the exploit to act as a proxy for GoSign Desktop in order to simulate the attack: `make run` 3) PoC Evidence After installing the fake .deb update package, you can verify the impact by checking the file: `cat /tmp/gosigndesktop_mitm_poc.log` 4) Cleanup You can remove the proxy configuration, the .deb file, and the virtual environment: `make clean` XI. REFERENCES No references. XII. CREDIT Pasquale "Sid" Fiorillo is credited with the discovery of this vulnerability with the contribution of Francesco "ascii" Ongaro and Marco Lunardi. Pasquale "sid" Fiorillo web site: http://www.ush.it/ mail: sid AT ush DOT it Francesco "ascii" Ongaro web site: http://www.ush.it/ mail: ascii AT ush DOT it XIII. LEGAL NOTICES Copyright (c) 2025 Pasquale "Sid" Fiorillo Permission is granted for the redistribution of this alert electronically. It may not be edited in any way without mine express written consent. If you wish to reprint the whole or any part of this alert in any other medium other than electronically, please email me for permission. Disclaimer: The information in the advisory is believed to be accurate at the time of publishing based on currently available information. Use of the information constitutes acceptance for use in an AS IS condition. There are no warranties with regard to this information. Neither the author nor the publisher accepts any liability for any direct, indirect, or consequential loss or damage arising from use of, or reliance on, this information.&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45964835</guid><pubDate>Tue, 18 Nov 2025 12:36:54 +0000</pubDate></item><item><title>Do Not Put Your Site Behind Cloudflare If You Don't Need To</title><link>https://huijzer.xyz/posts/123/do-not-put-your-site-behind-cloudflare-if-you-dont</link><description>&lt;doc fingerprint="b3c3cd1b9c4a48d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Do Not Put Your Site Behind Cloudflare if You Don't Need To&lt;/head&gt;
    &lt;p&gt;At the time of writing 12:43 UTC on Tue 18 Nov, Cloudflare has taken many sites down. I'm trying to browse the web, but about half of the sites show an error:&lt;/p&gt;
    &lt;p&gt;Most of these sites are not even that big. I expect maybe a few thousand visitors per month.&lt;/p&gt;
    &lt;p&gt;This demonstrates again a simple fact: if you put your site behind a centralized service, then this service is a single point of failure. Even large established companies make mistakes and can go down.&lt;/p&gt;
    &lt;p&gt;Most people use Cloudflare because they have been scared into the idea that you need DDoS protection. Well, maybe you do, but probably you don't.&lt;/p&gt;
    &lt;p&gt;As they say in security, "no one will burn a zero day on you!". For your small blog with one hundred visitors per month, it's probably the same: "no one will burn their DDoS capabilities on you!"&lt;/p&gt;
    &lt;p&gt;I don't know how else to say it. Many people keep talking about the importance of a decentralized web, and then continue putting their site behind Cloudflare.&lt;/p&gt;
    &lt;p&gt;If you really want to be safe in case your server goes down, then setup a second version of your site at another location and point to that server via the A and AAAA records, see "round-robin DNS".&lt;/p&gt;
    &lt;p&gt;Maybe that's the core of this message. Face your fears. Put your service on the internet. Maybe it goes down, but at least not by yet another Cloudflare outage.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45965060</guid><pubDate>Tue, 18 Nov 2025 12:54:49 +0000</pubDate></item><item><title>Ruby 4.0.0 Preview2 Released</title><link>https://www.ruby-lang.org/en/news/2025/11/17/ruby-4-0-0-preview2-released/</link><description>&lt;doc fingerprint="7c00b14b9620b6d5"&gt;
  &lt;main&gt;
    &lt;p&gt;Posted by naruse on 17 Nov 2025&lt;/p&gt;
    &lt;p&gt;We are pleased to announce the release of Ruby 4.0.0-preview2. Ruby 4.0 updates its Unicode version to 17,0.0, and so on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Language changes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;*nil&lt;/code&gt;no longer calls&lt;code&gt;nil.to_a&lt;/code&gt;, similar to how&lt;code&gt;**nil&lt;/code&gt;does not call&lt;code&gt;nil.to_hash&lt;/code&gt;. [[Feature #21047]]&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Core classes updates&lt;/head&gt;
    &lt;p&gt;Note: We’re only listing notable updates of Core class.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Binding&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Binding#local_variables&lt;/code&gt;does no longer include numbered parameters. Also,&lt;code&gt;Binding#local_variable_get&lt;/code&gt;and&lt;code&gt;Binding#local_variable_set&lt;/code&gt;reject to handle numbered parameters. [[Bug #21049]]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IO&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;IO.select&lt;/code&gt;accepts +Float::INFINITY+ as a timeout argument. [[Feature #20610]]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;String&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Update Unicode to Version 17.0.0 and Emoji Version 17.0. [[Feature #19908]][[Feature #20724]][[Feature #21275]] (also applies to Regexp)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Standard Library updates&lt;/head&gt;
    &lt;p&gt;Note: We’re only listing notable updates of Standard librarires.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ostruct 0.6.1&lt;/item&gt;
      &lt;item&gt;pstore 0.2.0&lt;/item&gt;
      &lt;item&gt;benchmark 0.4.0&lt;/item&gt;
      &lt;item&gt;logger 1.7.0&lt;/item&gt;
      &lt;item&gt;rdoc 6.13.1&lt;/item&gt;
      &lt;item&gt;win32ole 1.9.2&lt;/item&gt;
      &lt;item&gt;irb 1.15.2&lt;/item&gt;
      &lt;item&gt;reline 0.6.1&lt;/item&gt;
      &lt;item&gt;readline 0.0.4&lt;/item&gt;
      &lt;item&gt;fiddle 1.1.6&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Compatibility issues&lt;/head&gt;
    &lt;p&gt;Note: Excluding feature bug fixes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Standard library compatibility issues&lt;/head&gt;
    &lt;head rend="h2"&gt;C API updates&lt;/head&gt;
    &lt;head rend="h2"&gt;JIT&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;YJIT &lt;list rend="ul"&gt;&lt;item&gt;YJIT stats &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ratio_in_yjit&lt;/code&gt;no longer works in the default build. Use&lt;code&gt;--enable-yjit=stats&lt;/code&gt;on&lt;code&gt;configure&lt;/code&gt;to enable it on&lt;code&gt;--yjit-stats&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;invalidate_everything&lt;/code&gt;to default stats, which is incremented when every code is invalidated by TracePoint.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;mem_size:&lt;/code&gt;and&lt;code&gt;call_threshold:&lt;/code&gt;options to&lt;code&gt;RubyVM::YJIT.enable&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;YJIT stats &lt;/item&gt;
      &lt;item&gt;ZJIT &lt;list rend="ul"&gt;&lt;item&gt;Add an experimental method-based JIT compiler. Use &lt;code&gt;--enable-zjit&lt;/code&gt;on&lt;code&gt;configure&lt;/code&gt;to enable the&lt;code&gt;--zjit&lt;/code&gt;support.&lt;/item&gt;&lt;item&gt;As of Ruby 4.0.0-preview2, ZJIT is not yet ready for speeding up most benchmarks. Please refrain from evaluating ZJIT just yet. Stay tuned for the Ruby 4.0 release.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Add an experimental method-based JIT compiler. Use &lt;/item&gt;
      &lt;item&gt;RJIT &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;--rjit&lt;/code&gt;is removed. We will move the implementation of the third-party JIT API to the ruby/rjit repository.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Miscellaneous changes&lt;/head&gt;
    &lt;p&gt;See NEWS or commit logs for more details.&lt;/p&gt;
    &lt;p&gt;With those changes, 3607 files changed, 197451 insertions(+), 285607 deletions(-) since Ruby 3.4.0!&lt;/p&gt;
    &lt;head rend="h2"&gt;Download&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0-preview2.tar.gz&lt;/p&gt;
        &lt;code&gt;SIZE: 23444451 SHA1: 132e450bbee3f61ed0b463ed1e2bd3a3a324339c SHA256: 0a3330dae710302e11f7f0323e83219ab3c6517984691a312c662f329c5120e1 SHA512: b5e681cc84be59148485b9a2212dcf54d61cfee27431ceddb49bedc8baa913ec8b36da43242cb4f1791b25e4bfc1dcf72b5527288a0656f2933da898d0e0b40f&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0-preview2.tar.xz&lt;/p&gt;
        &lt;code&gt;SIZE: 17554228 SHA1: f8e8b98ea85ac82610ab601a21dc9a90c5c56a97 SHA256: 0b92b15466d77a9d7e59e4a75f050d42cd50fe96c951d2b3b9f8029394cd9a43 SHA512: 7afaa8d8e832ef0ded28f1caf874da69f16105e1b3aad5947c6911364159b4c6ebd3d7ea5d7d86708e9f2f06a047921b8302ca6e75ec429a3da846845f896976&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0-preview2.zip&lt;/p&gt;
        &lt;code&gt;SIZE: 28933540 SHA1: 48a235cfbfd4252dce81da870c792e32309e62b9 SHA256: f5c68ee44dfcb76b61c07c437fa945814dfc516570b1c921506ac886960160ca SHA512: 508c685e46a641c74e2968daf650559503ce2bcaac3403654713adb2345c3ede2bace929294a1367afecac5edd6b2c42fa833f5313456f78c79151d310c860cf&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What is Ruby&lt;/head&gt;
    &lt;p&gt;Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple platforms and is used all over the world especially for web development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45965664</guid><pubDate>Tue, 18 Nov 2025 13:34:44 +0000</pubDate></item><item><title>Nearly all UK drivers say headlights are too bright</title><link>https://www.bbc.com/news/articles/c1j8ewy1p86o</link><description>&lt;doc fingerprint="24df8d635d03762d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nearly all drivers say headlights are too bright&lt;/head&gt;
    &lt;p&gt;Nearly all UK drivers said they thought headlights were too bright and that they have been dazzled by oncoming vehicles, according to a major study.&lt;/p&gt;
    &lt;p&gt;The government said last week that it will take a closer look at the design of cars and headlamps after concerns about lights dazzling drivers.&lt;/p&gt;
    &lt;p&gt;A study commissioned by the Department for Transport (DfT) found 97% of people surveyed found they were regularly or sometimes distracted by oncoming vehicles and 96% thought most or some headlights were too bright.&lt;/p&gt;
    &lt;p&gt;Dr Shaun Helman, who led the research for Berkshire-based Transport Research Laboratory (TRL), said it provides "compelling evidence" that lights' glare is a "genuine issue for UK drivers".&lt;/p&gt;
    &lt;p&gt;New measures will be included in the government's upcoming Road Safety Strategy, reflecting what is becoming an increasingly fraught issue for road users.&lt;/p&gt;
    &lt;p&gt;TRL's data suggests that LED and whiter headlamps may be linked to glare and that drivers might find their whiteness harder to cope with.&lt;/p&gt;
    &lt;p&gt;Of those surveyed, 33% said they had either stopped driving or are driving less at night because of lights, while another 22% said they would like to drive less at night but have no choice.&lt;/p&gt;
    &lt;p&gt;A total of 1,850 drivers, matched to the age and gender split of the country's licence holding population, were surveyed for their views.&lt;/p&gt;
    &lt;p&gt;TRL said LED lights used in vehicles are brighter, more concentrated and emit more blue light, which human eyes struggle with more at night.&lt;/p&gt;
    &lt;p&gt;The RAC's senior policy officer Rod Dennis said: "Having campaigned hard for this study, we welcome its findings which independently confirm what drivers have been telling us – that rather than being an imagined phenomenon, some bright headlights do cause a glare problem.&lt;/p&gt;
    &lt;p&gt;"While drivers clearly benefit from high-performing headlights, it's important this doesn't lead to others suffering the effects of dazzle, so a balance needs to be struck," he added.&lt;/p&gt;
    &lt;p&gt;Mr Dennis said that it is "vital" TRL's report is "reviewed carefully to put us on a path towards changes that ultimately benefit all road users."&lt;/p&gt;
    &lt;p&gt;Denise Voon, a clinical advisor at The College of Optometrists, said the DfT should "take immediate, actionable steps to support drivers and commission more detailed research, specifically into how headlight regulations need to change".&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45966251</guid><pubDate>Tue, 18 Nov 2025 14:11:17 +0000</pubDate></item><item><title>Short Little Difficult Books</title><link>https://countercraft.substack.com/p/short-little-difficult-books</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45966435</guid><pubDate>Tue, 18 Nov 2025 14:23:18 +0000</pubDate></item><item><title>Gemini 3 Pro Preview Live in AI Studio</title><link>https://aistudio.google.com/prompts/new_chat?model=gemini-3-pro-preview</link><description>&lt;doc fingerprint="c5bbe5cda930f6e1"&gt;
  &lt;main&gt;
    &lt;p&gt;Sign in Use your Google Account Email or phone Forgot email? Type the text you hear or see Not your computer? Use a Private Window to sign in. Learn more about using Guest mode Next Create account&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45967211</guid><pubDate>Tue, 18 Nov 2025 15:09:38 +0000</pubDate></item><item><title>Google Antigravity</title><link>https://antigravity.google/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45967814</guid><pubDate>Tue, 18 Nov 2025 15:47:38 +0000</pubDate></item><item><title>Gemini 3</title><link>https://blog.google/products/gemini/gemini-3/</link><description>&lt;doc fingerprint="f9d7a1cf9b3f9a95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A new era of intelligence with Gemini 3&lt;/head&gt;
    &lt;head rend="h3"&gt;A note from Google and Alphabet CEO Sundar Pichai:&lt;/head&gt;
    &lt;p&gt;Nearly two years ago we kicked off the Gemini era, one of our biggest scientific and product endeavors ever undertaken as a company. Since then, it’s been incredible to see how much people love it. AI Overviews now have 2 billion users every month. The Gemini app surpasses 650 million users per month, more than 70% of our Cloud customers use our AI, 13 million developers have built with our generative models, and that is just a snippet of the impact we’re seeing.&lt;/p&gt;
    &lt;p&gt;And we’re able to get advanced capabilities to the world faster than ever, thanks to our differentiated full stack approach to AI innovation — from our leading infrastructure to our world-class research and models and tooling, to products that reach billions of people around the world.&lt;/p&gt;
    &lt;p&gt;Every generation of Gemini has built on the last, enabling you to do more. Gemini 1’s breakthroughs in native multimodality and long context window expanded the kinds of information that could be processed — and how much of it. Gemini 2 laid the foundation for agentic capabilities and pushed the frontiers on reasoning and thinking, helping with more complex tasks and ideas, leading to Gemini 2.5 Pro topping LMArena for over six months.&lt;/p&gt;
    &lt;p&gt;And now we’re introducing Gemini 3, our most intelligent model, that combines all of Gemini’s capabilities together so you can bring any idea to life.&lt;/p&gt;
    &lt;p&gt;It’s state-of-the-art in reasoning, built to grasp depth and nuance — whether it’s perceiving the subtle clues in a creative idea, or peeling apart the overlapping layers of a difficult problem. Gemini 3 is also much better at figuring out the context and intent behind your request, so you get what you need with less prompting. It’s amazing to think that in just two years, AI has evolved from simply reading text and images to reading the room.&lt;/p&gt;
    &lt;p&gt;And starting today, we’re shipping Gemini at the scale of Google. That includes Gemini 3 in AI Mode in Search with more complex reasoning and new dynamic experiences. This is the first time we are shipping Gemini in Search on day one. Gemini 3 is also coming today to the Gemini app, to developers in AI Studio and Vertex AI, and in our new agentic development platform, Google Antigravity — more below.&lt;/p&gt;
    &lt;p&gt;Like the generations before it, Gemini 3 is once again advancing the state of the art. In this new chapter, we’ll continue to push the frontiers of intelligence, agents, and personalization to make AI truly helpful for everyone.&lt;/p&gt;
    &lt;p&gt;We hope you like Gemini 3, we'll keep improving it, and look forward to seeing what you build with it. Much more to come!&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing Gemini 3: our most intelligent model that helps you bring any idea to life&lt;/head&gt;
    &lt;p&gt;Demis Hassabis, CEO of Google DeepMind and Koray Kavukcuoglu, CTO of Google DeepMind and Chief AI Architect, Google, on behalf of the Gemini team&lt;/p&gt;
    &lt;p&gt;Today we’re taking another big step on the path toward AGI and releasing Gemini 3.&lt;/p&gt;
    &lt;p&gt;It’s the best model in the world for multimodal understanding and our most powerful agentic and vibe coding model yet, delivering richer visualizations and deeper interactivity — all built on a foundation of state-of-the-art reasoning.&lt;/p&gt;
    &lt;p&gt;We’re beginning the Gemini 3 era by releasing Gemini 3 Pro in preview and making it available today across a suite of Google products so you can use it in your daily life to learn, build and plan anything. We’re also introducing Gemini 3 Deep Think — our enhanced reasoning mode that pushes Gemini 3 performance even further — and giving access to safety testers before making it available to Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;State-of-the-art reasoning with unprecedented depth and nuance&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro can bring any idea to life with its state-of-the-art reasoning and multimodal capabilities. It significantly outperforms 2.5 Pro on every major AI benchmark.&lt;/p&gt;
    &lt;p&gt;It tops the LMArena Leaderboard with a breakthrough score of 1501 Elo. It demonstrates PhD-level reasoning with top scores on Humanity’s Last Exam (37.5% without the usage of any tools) and GPQA Diamond (91.9%). It also sets a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex.&lt;/p&gt;
    &lt;p&gt;Beyond text, Gemini 3 Pro redefines multimodal reasoning with 81% on MMMU-Pro and 87.6% on Video-MMMU. It also scores a state-of-the-art 72.1% on SimpleQA Verified, showing great progress on factual accuracy. This means Gemini 3 Pro is highly capable at solving complex problems across a vast array of topics like science and mathematics with a high degree of reliability.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is state-of-the-art across a range of key AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro also brings a new level of depth and nuance to every interaction. Its responses are smart, concise and direct, trading cliché and flattery for genuine insight — telling you what you need to hear, not just what you want to hear. It acts as a true thought partner that gives you new ways to understand information and express yourself, from translating dense scientific concepts by generating code for high-fidelity visualizations to creative brainstorming.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can code a visualization of plasma flow in a tokamak and write a poem capturing the physics of fusion.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gemini 3 Deep Think&lt;/head&gt;
    &lt;p&gt;Gemini 3 Deep Think mode pushes the boundaries of intelligence even further, delivering a step-change in Gemini 3’s reasoning and multimodal understanding capabilities to help you solve even more complex problems.&lt;/p&gt;
    &lt;p&gt;In testing, Gemini 3 Deep Think outperforms Gemini 3 Pro’s already impressive performance on Humanity’s Last Exam (41.0% without the use of tools) and GPQA Diamond (93.8%). It also achieves an unprecedented 45.1% on ARC-AGI-2 (with code execution, ARC Prize Verified), demonstrating its ability to solve novel challenges.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Deep Think mode excels on some of the most challenging AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gemini 3 helps you learn, build and plan anything&lt;/head&gt;
    &lt;head rend="h3"&gt;Learn anything&lt;/head&gt;
    &lt;p&gt;Gemini was built from the start to seamlessly synthesize information about any topic across multiple modalities, including text, images, video, audio and code. Gemini 3 pushes the frontier of multimodal reasoning to help you learn in ways that make sense for you by combining its state-of-the-art reasoning, vision and spatial understanding, leading multilingual performance, and 1 million-token context window.&lt;/p&gt;
    &lt;p&gt;For example, if you want to learn how to cook in your family tradition, Gemini 3 can decipher and translate handwritten recipes in different languages into a shareable family cookbook. Or if you want to learn about a new topic, you can give it academic papers, long video lectures or tutorials and it can generate code for interactive flashcards, visualizations or other formats that will help you master the material. It can even analyze videos of your pickleball match, identify areas where you can improve and generate a training plan for overall form improvements.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you learn and preserve family cooking traditions. Try it in Gemini Canvas.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you analyze complex information like research papers and can generate code for an interactive guide.&lt;/p&gt;
    &lt;p&gt;Get expert-level sports analysis on your pickleball match to help improve your game.&lt;/p&gt;
    &lt;p&gt;To help you make better sense of information on the web, AI Mode in Search now uses Gemini 3 to enable new generative UI experiences like immersive visual layouts and interactive tools and simulations, all generated completely on the fly based on your query.&lt;/p&gt;
    &lt;p&gt;Learn a complex topic like how RNA polymerase works with generative UI in AI Mode in Search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build anything&lt;/head&gt;
    &lt;p&gt;Building on the success of 2.5 Pro, Gemini 3 delivers on the promise of bringing any idea to life for developers. It’s exceptional at zero-shot generation and handles complex prompts and instructions to render richer, more interactive web UI.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is the best vibe coding and agentic coding model we’ve ever built – making our products more autonomous and boosting developer productivity. It tops the WebDev Arena leaderboard by scoring an impressive 1487 Elo. It also scores 54.2% on Terminal-Bench 2.0, which tests a model’s tool use ability to operate a computer via terminal and it greatly outperforms 2.5 Pro on SWE-bench Verified (76.2%), a benchmark that measures coding agents.&lt;/p&gt;
    &lt;p&gt;You can now build with Gemini 3 in Google AI Studio, Vertex AI, Gemini CLI and our new agentic development platform, Google Antigravity. It’s also available in third-party platforms like Cursor, GitHub, JetBrains, Manus, Replit and more.&lt;/p&gt;
    &lt;p&gt;Code a retro 3D spaceship game with richer visualizations and improved interactivity. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Bring your imagination to life by building, deconstructing and remixing detailed 3D voxel art using code. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Build a playable sci-fi world with shaders using Gemini 3. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;You can vibe code richer, more interactive web UI and apps with Gemini 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introducing a new agent-first development experience&lt;/head&gt;
    &lt;p&gt;As model intelligence accelerates with Gemini 3, we have the opportunity to reimagine the entire developer experience. Today we’re releasing Google Antigravity, our new agentic development platform that enables developers to operate at a higher, task-oriented level.&lt;/p&gt;
    &lt;p&gt;Using Gemini 3’s advanced reasoning, tool use and agentic coding capabilities, Google Antigravity transforms AI assistance from a tool in a developer’s toolkit into an active partner. While the core of Google Antigravity is a familiar AI IDE experience, its agents have been elevated to a dedicated surface and given direct access to the editor, terminal and browser. Now, agents can autonomously plan and execute complex, end-to-end software tasks simultaneously on your behalf while validating their own code.&lt;/p&gt;
    &lt;p&gt;In addition to Gemini 3 Pro, Google Antigravity also comes tightly coupled with our latest Gemini 2.5 Computer Use model for browser control and our top-rated image editing model Nano Banana (Gemini 2.5 Image).&lt;/p&gt;
    &lt;p&gt;Google Antigravity uses Gemini 3 to drive an end-to-end agentic workflow for a flight tracker app. The agent independently plans, codes the application and validates its execution through browser-based computer use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Plan anything&lt;/head&gt;
    &lt;p&gt;Since introducing the agentic era with Gemini 2, we’ve made a lot of progress, not only advancing Gemini’s coding agent abilities, but also improving its ability to reliably plan ahead over longer horizons. Gemini 3 demonstrates this by topping the leaderboard on Vending-Bench 2, which tests longer horizon planning by managing a simulated vending machine business. Gemini 3 Pro maintains consistent tool usage and decision-making for a full simulated year of operation, driving higher returns without drifting off task.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro demonstrates better long-horizon planning to generate significantly higher returns compared to other frontier models.&lt;/p&gt;
    &lt;p&gt;This means Gemini 3 can better help you get things done in everyday life. By combining deeper reasoning with improved, more consistent tool use, Gemini 3 can take action on your behalf by navigating more complex, multi-step workflows from start to finish — like booking local services or organizing your inbox — all while under your control and guidance.&lt;/p&gt;
    &lt;p&gt;Google AI Ultra subscribers can try these agentic capabilities in the Gemini app with Gemini Agent today. We’ve learned a lot improving Gemini’s agentic capabilities, and we’re excited to see how you use it as we expand to more Google products soon.&lt;/p&gt;
    &lt;p&gt;Gemini Agent can help you organize your Gmail inbox. Try it now in the Gemini app for Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Gemini 3 responsibly&lt;/head&gt;
    &lt;p&gt;Gemini 3 is our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. The model shows reduced sycophancy, increased resistance to prompt injections and improved protection against misuse via cyberattacks.&lt;/p&gt;
    &lt;p&gt;In addition to our in-house testing for the critical domains in our Frontier Safety Framework, we've also partnered on evaluations with world-leading subject matter experts, provided early access to bodies like the UK AISI, and obtained independent assessments from industry experts like Apollo, Vaultis, Dreadnode and more. For more information, see the Gemini 3 model card.&lt;/p&gt;
    &lt;head rend="h2"&gt;The next era of Gemini&lt;/head&gt;
    &lt;p&gt;This is just the start of the Gemini 3 era. As of today, Gemini 3 starts rolling out:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For everyone in the Gemini app and for Google AI Pro and Ultra subscribers in AI Mode in Search&lt;/item&gt;
      &lt;item&gt;For developers in the Gemini API in AI Studio, our new agentic development platform, Google Antigravity; and Gemini CLI&lt;/item&gt;
      &lt;item&gt;For enterprises in Vertex AI and Gemini Enterprise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For Gemini 3 Deep Think mode, we’re taking extra time for safety evaluations and input from safety testers before making it available to Google AI Ultra subscribers in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We plan to release additional models to the Gemini 3 series soon so you can do more with AI. We look forward to getting your feedback and seeing what you learn, build and plan with Gemini.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45967999</guid><pubDate>Tue, 18 Nov 2025 16:00:33 +0000</pubDate></item><item><title>Gemini 3 for developers: New reasoning, agentic capabilities</title><link>https://blog.google/technology/developers/gemini-3-developers/</link><description>&lt;doc fingerprint="3d57a34d93b79a8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Start building with Gemini 3&lt;/head&gt;
    &lt;p&gt;Today we are introducing Gemini 3, our most intelligent model that can help bring any idea to life. Built on a foundation of state-of-the-art reasoning, Gemini 3 Pro delivers unparalleled results across every major AI benchmark compared to previous versions. It also surpasses 2.5 Pro at coding, mastering both agentic workflows and complex zero-shot tasks.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro fits right into existing production agent and coding workflows, while also enabling new use cases not previously possible. It’s available in preview at $2/million input tokens and $12/million output tokens for prompts 200k tokens or less through the Gemini API in Google AI Studio and Vertex AI for enterprises (see pricing for rate limits and full pricing details). Additionally, it can be utilized via your favorite developer tools within the broader ecosystem and is available, with rate limits, free of charge in Google AI Studio.&lt;/p&gt;
    &lt;head rend="h2"&gt;Agentic coding&lt;/head&gt;
    &lt;p&gt;Developers are spending more and more time creating software with AI at their side. Building on the momentum of Gemini 2.5 Pro and all the feedback, Gemini 3 Pro serves as a new foundation of intelligence for what’s possible with an agentic coding model.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro scores 54.2% points on Terminal-Bench 2.0, which tests a model’s tool use ability to operate a computer via terminal.&lt;/p&gt;
    &lt;p&gt;You can feel the power of this model come to life in Google Antigravity, our new agentic development platform, in addition to Gemini CLI, Android Studio, and other coding products like Cursor, GitHub, JetBrains, Manus, Cline and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google Antigravity&lt;/head&gt;
    &lt;p&gt;To advance how the model and IDE work together, we’re introducing Google Antigravity to showcase what’s possible with Gemini 3. It’s an agentic development platform that enables developers to operate at a higher, task-oriented level by managing agents across workspaces, while retaining a familiar AI IDE experience at its core.&lt;/p&gt;
    &lt;p&gt;It’s a faster way to develop: you act as the architect, collaborating with intelligent agents that operate autonomously across the editor, terminal, and browser. These agents plan and execute complex software tasks, communicating their work with the user via detailed artifacts. This elevates all aspects of development, from building features, UI iteration, and fixing bugs to researching and generating reports. Visit the Google Antigravity website to download the public preview at no charge, now available for MacOS, Windows and Linux.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gemini API&lt;/head&gt;
    &lt;p&gt;With Gemini 3, we are releasing a client-side bash tool that empowers the model to propose shell commands as part of agentic workflows for tasks such as navigating your local filesystem, driving development processes, and automating system operations. We’re pairing this with a hosted server-side bash tool for multi language code generation and secure prototyping. Available now in the Gemini API for early access partners, with general availability coming soon.&lt;/p&gt;
    &lt;p&gt;Additionally, Gemini hosted tools Grounding with Google Search and URL context can now be combined with structured outputs. This is especially powerful for building agentic use cases which involve fetching and extracting data and then outputting them in a specific format for downstream agentic tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vibe coding&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro unlocks the true potential of “vibe coding”, where natural language is the only syntax you need. By significantly improving complex instruction following and deep tool use, the model can translate a high-level idea into a fully interactive app with a single prompt. It handles the heavy lifting of multi-step planning and coding details delivering richer visuals and deeper interactivity, allowing you to focus on the creative vision.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro tops the WebDev Arena leaderboard by scoring an impressive 1487 Elo.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google AI Studio&lt;/head&gt;
    &lt;p&gt;Whether it’s building a game with a single prompt, an interactive landing page from unstructured voice notes, or a full on app from a napkin sketch, developers can bring their idea to life with Gemini 3. With this model, we pushed single prompt generation capabilities further than ever, meaning you can go from idea to AI-powered app with a single prompt, like this retro game built in Google AI Studio.&lt;/p&gt;
    &lt;p&gt;We’ve built Google AI Studio to be your fastest path from a prompt to an AI-native app. Build mode lets you add AI capabilities faster than ever, automatically wiring up the right models and APIs, while features like annotations enable fast and intuitive iteration. You can start building with Gemini 3 in Google AI Studio today.&lt;/p&gt;
    &lt;head rend="h2"&gt;Multimodal understanding&lt;/head&gt;
    &lt;p&gt;Gemini 3 is the best model in the world for complex multimodal understanding and sets new highs on MMMU-Pro for complex image reasoning and Video MMMU for video understanding. Combining its intelligence and a 1 million-token context window, developers can see significant improvements while building key multimodal use cases. To give you more control over latency and cost, you can now configure multimodal vision processing with more granularity in the Gemini API based on the visual fidelity required for your application.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visual reasoning&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro is best-in-class for document understanding, going beyond simple OCR (Object Character Recognition) to intelligently handle complex document understanding and reasoning.&lt;/p&gt;
    &lt;p&gt;You can see the model’s vision understanding, reasoning and coding capabilities in our demo app that brings any idea to life in Google AI Studio.&lt;/p&gt;
    &lt;head rend="h3"&gt;Spatial reasoning&lt;/head&gt;
    &lt;p&gt;The model’s improved spatial understanding also drives strong performance in embodied reasoning tasks like pointing, trajectory prediction and task progression, unlocking new use cases across autonomous vehicles, XR devices and robotics.&lt;/p&gt;
    &lt;p&gt;Its spatial reasoning also powers intelligent screen understanding of desktop, mobile and OS screens delivering significant performance improvement for computer use agents. The model also understands the intent of user actions based on mouse movements and screen annotations unlocking novel experiences like this Visual Computer demo app.&lt;/p&gt;
    &lt;head rend="h3"&gt;Video reasoning&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro captures rapid action with high-frame-rate understanding, ensuring developers never miss a critical moment in fast-moving scenes. Beyond speed, long-context recall allows for synthesizing narratives and pinpointing specific details across hours of continuous footage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Build what’s next, today&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro is now integrated into many developer products and tools to seamlessly fit into your existing workflows and unlock entirely new ways to code.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Build with the Gemini API: You can integrate Gemini 3 Pro immediately into your applications via Google AI Studio and Vertex AI for Enterprise. To support the model's deeper reasoning capabilities, we’re introducing a new thinking level and more granular media resolution parameters in the API, along with stricter validation for thought signatures. This update is critical for preserving the model’s thoughts across multi-turn conversations. Check out the Developer Guide for the technical breakdown and our Prompting Guide to learn how to build with Gemini 3 Pro.&lt;/item&gt;
      &lt;item&gt;Experience the model’s agentic capabilities: Whether you are adding AI-native features to an Android app, automating workflows through Gemini CLI or managing a fleet of autonomous agents in Google Antigravity, Gemini 3 Pro provides the reliability needed for complex, agentic architectures.&lt;/item&gt;
      &lt;item&gt;Vibe code with Gemini 3 Pro: Google AI Studio is your fastest path to bring any idea to life. Get started in Build mode to generate a fully functional app with a single prompt. And if you need a little inspiration, click “I’m feeling lucky” and let Gemini 3 Pro handle the creative spark and the code implementation simultaneously.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The software landscape is shifting. As AI changes who builds and how they build, we are committed to meeting you where you are — giving you the tools to push the boundaries of what’s possible.&lt;/p&gt;
    &lt;p&gt;This is just the start of the Gemini 3 era but we can’t wait to see what you build with Gemini 3 Pro!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968043</guid><pubDate>Tue, 18 Nov 2025 16:04:12 +0000</pubDate></item><item><title>Google Antigravity, a New Era in AI-Assisted Software Development</title><link>https://antigravity.google/blog/introducing-google-antigravity</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968065</guid><pubDate>Tue, 18 Nov 2025 16:06:32 +0000</pubDate></item><item><title>Google Brings Gemini 3 AI Model to Search and AI Mode</title><link>https://blog.google/products/search/gemini-3-search-ai-mode/</link><description>&lt;doc fingerprint="1957a9d3db3e18b7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google Search with Gemini 3: Our most intelligent search yet&lt;/head&gt;
    &lt;p&gt;Today, we introduced Gemini 3, our most intelligent model with state-of-the-art reasoning, deep multimodal understanding and powerful agentic capabilities. It’s now available in Google Search, starting with AI Mode — marking the first time we’ve brought a Gemini model to Search on day one. Gemini 3 brings incredible reasoning power to Search because it’s built to grasp unprecedented depth and nuance for your hardest questions. It also unlocks new generative UI experiences so you can get dynamic visual layouts with interactive tools and simulations — generated specifically for you.&lt;/p&gt;
    &lt;p&gt;Here’s how Gemini 3 is supercharging Search.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gemini 3: Our most intelligent model, right in Search&lt;/head&gt;
    &lt;p&gt;Starting today, Google AI Pro and Ultra subscribers in the U.S. can use Gemini 3 Pro, our first model in the Gemini 3 family of models, by selecting “Thinking” from the model drop-down menu in AI Mode. With Gemini 3, you can tackle your toughest questions and learn more interactively because it better understands the intent and nuance of your request. And soon, we’ll bring Gemini 3 in AI Mode to everyone in the U.S. with higher limits for users with the Google AI Pro and Ultra plans.&lt;/p&gt;
    &lt;p&gt;Thanks to Gemini 3’s advanced reasoning, Google Search’s query fan-out technique is getting a major upgrade. Now, not only can it perform even more searches to uncover relevant web content, but because Gemini more intelligently understands your intent it can find new content that it may have previously missed. This means Search can help you find even more credible, highly relevant content for your specific question.&lt;/p&gt;
    &lt;p&gt;And in the coming weeks, we’re also enhancing our automatic model selection in Search with Gemini 3. This means Search will intelligently route your most challenging questions in AI Mode and AI Overviews to this frontier model — while continuing to use faster models for simpler tasks. This will be rolling out to Google AI Pro and Ultra subscribers in the U.S.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generative UI: Visual layouts, interactive tools and simulations in AI Mode&lt;/head&gt;
    &lt;p&gt;Gemini 3’s unparalleled multimodal understanding and powerful agentic coding capabilities are also unlocking more bespoke generative user interfaces. Now, Gemini 3 in AI Mode can dynamically create the ideal visual layout for responses on the fly — featuring interactive tools and simulations — tailored to your query.&lt;/p&gt;
    &lt;p&gt;To do this, Gemini 3 analyzes your question and creates the most helpful layout, building a custom response with visual elements — like images, tables and grids — so the final output isn’t just informative, but clear and actionable. When the model detects that an interactive tool will help you better understand the topic, it uses its generative capabilities to code a custom simulation or tool in real-time and adds it into your response.&lt;/p&gt;
    &lt;p&gt;Say you’re learning about the physics behind the three-body problem. Instead of just reading about it, you can now get an interactive simulation, allowing you to manipulate variables and see the gravitational interactions play out. Or perhaps you're researching mortgage loans: Gemini 3 in AI Mode can make you a custom-built interactive loan calculator directly in the response so you can compare two different options and see which offers the most long-term savings. And to help you continue exploring, all responses have prominent links to high-quality content across the web.&lt;/p&gt;
    &lt;p&gt;For a deeper dive, check out Google’s foundational generative UI research. We’ll continue to refine the experience over time, and we look forward to your feedback as you start to use these interactive tools and simulations in Search.&lt;/p&gt;
    &lt;p&gt;Now, it's even easier to ask anything and instantly get a richer, more helpful understanding. We’re excited for you to try this more interactive and capable Search.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968091</guid><pubDate>Tue, 18 Nov 2025 16:08:17 +0000</pubDate></item><item><title>5 Things to Try with Gemini 3 Pro in Gemini CLI</title><link>https://developers.googleblog.com/en/5-things-to-try-with-gemini-3-pro-in-gemini-cli/</link><description>&lt;doc fingerprint="35d5a2a31b3f128d"&gt;
  &lt;main&gt;
    &lt;p&gt;Gemini 3 Pro is now available in Gemini CLI&lt;/p&gt;
    &lt;p&gt;We've integrated Gemini 3 Pro, our most intelligent model, directly into Gemini CLI to unlock a new level of performance and productivity in the terminal. This powerful combination delivers state-of-the-art reasoning for executing better commands, enhances support for complex engineering work through agentic coding, and enables smarter, more tailored workflows via advanced tool use.&lt;/p&gt;
    &lt;p&gt;We are rolling out access gradually to ensure the experience remains fast and reliable.&lt;/p&gt;
    &lt;p&gt;You can also track our rollout progress by following this GitHub discussion.&lt;/p&gt;
    &lt;p&gt;If you’re a Google AI Ultra subscriber or have a paid Gemini API key, get started immediately by upgrading your Gemini CLI version to 0.16.x:&lt;/p&gt;
    &lt;code&gt;npm install -g @google/gemini-cli@latest&lt;/code&gt;
    &lt;p&gt;After you’ve confirmed your version, run &lt;code&gt;/settings&lt;/code&gt;, then toggle Preview features to true. Gemini CLI will now default to Gemini 3 Pro.&lt;/p&gt;
    &lt;p&gt;Here are 5 practical ways you can tap into Gemini 3 Pro in Gemini CLI to accelerate development and bring your biggest ideas to life.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro excels at coding because of its ability to synthesize disparate pieces of information, including text, images, and code, and follow complex, creative instructions. It understands the intent behind your idea, allowing you to go from a rough concept to a functional starting point in a single step.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro's agentic coding capability allows it to handle prompts that are both a creative brief and a technical spec at the same time. It can take a prompt, create a detailed execution plan, and then generate the entire scaffold for a runnable web project, not just a single file.&lt;/p&gt;
    &lt;p&gt;For example, say you have an idea for a visually impressive prototype—a 3D graphic for a landing page or a quick tech demo. Instead of spending hours setting up a graphics library and a local dev server, you can describe the entire project in one go and get a working starting point immediately.&lt;/p&gt;
    &lt;code&gt;Objective: Build a visually stunning, photorealistic 3D Voxel simulation of the Golden Gate Bridge using Three.js, prioritizing quality and complex visuals (no simple blocks),  atmospheric depth and 60FPS performance.

Visuals &amp;amp; Atmosphere:
- Lighting: Slider (0-24h) controlling sun position, light intensity, sky color, and fog color.
- Fog: Volumetric-style fog using sprite particles that drift and bob. Slider 0-100. 0 = True Zero (Crystal Clear). 100 = Dense but realistic (not whiteout).
- Water: Custom GLSL shader with waves, specular reflections, and manual distance-based fog blending (exp2) for seamless horizon integration.
- Post-Processing: ACESFilmic Tone Mapping and UnrealBloom (optimized for glowing lights at night).

Scene Details:
- Bridge: Art Deco towers with concrete piers (anchored to seabed), main span catenary cables, and suspenders.
- Terrain: Low-poly Marin Headlands and SF Peninsula.
- Skyline: Procedural city blocks on the SF side.
- Traffic: Up to 400 cars using `InstancedMesh`, positioned accurately on top of the deck (ensure vertical alignment prevents clipping into the concrete). Each car features emissive headlights (white) and taillights (red).
- Ships: Procedural cargo ships with hull, containers, and functional navigation lights (Port/Starboard/Mast/Cabin) moving along the water.
- Nature: Animated flocking birds.
- Night Mode: At night, activate city lights, car headlights, ship navigation lights, tower beacons, street lights.

Tech &amp;amp; Controls:
- Core: Must output only single HTML file `golden_gate_bridge.html` to be run in a blank Chrome tab. Import Three.js/Addons via CDN map.
  -   `three` (Core library) via CDN (ES Modules).
  -   `three/examples/jsm/...` modules via Import Map.
  -   No build step (Vite/Webpack). Pure HTML/JS.

- UI: Visually appealing sliders for Time (0-24h), Fog Density (0-100%), Traffic Density (0-100%), and Camera Zoom.
- Optimization: `InstancedMesh` for all repetitive elements (cars, lights, birds).&lt;/code&gt;
    &lt;p&gt;2. Turn a visual idea into a working app&lt;/p&gt;
    &lt;p&gt;You've sketched a UI and need to translate that visual concept into functional code. You can take a picture of your sketch, and then simply drag and drop the image file into your terminal.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro's multimodal understanding will analyze the drawing, identifying buttons, text boxes, and layout. It then generates the HTML, CSS, and JavaScript code to bring your sketch to life.&lt;/p&gt;
    &lt;code&gt;Create a UI for "Project Constellation," an internal brand intelligence tool prototype that shows a customer acquisition pipeline. The aesthetic is an ultra-creative, futuristic dark-mode nebula. Luminous, iridescent threads representing customer journeys weave through semi-transparent glass pillars. A sleek, floating data card with Tailwind CSS precision materializes when hovering over a pillar. I've prepared a sketch for you to work from: @sketch.png.&lt;/code&gt;
    &lt;p&gt;While vibe coding demos show off the art of the possible, the true test of a developer tool is how it performs the practical, everyday work you do multiple times a day. Small improvements in these common workflows, like refactoring code, debugging errors, or managing infrastructure, are what create real productivity gains.&lt;/p&gt;
    &lt;p&gt;This is where Gemini 3 Pro's state-of-the-art reasoning makes a tangible difference. It follows the nuances of complex, multi-part commands with greater precision than ever before, which is essential for the practical, detailed work that defines your day.&lt;/p&gt;
    &lt;p&gt;Here are a few examples of how Gemini 3 Pro can handle these critical engineering tasks.&lt;/p&gt;
    &lt;p&gt;3. Generate complex shell commands with natural language&lt;/p&gt;
    &lt;p&gt;With Gemini CLI, the power of the UNIX command line is available directly through natural language. No need to memorize the obscure syntax and every flag of UNIX commands, simply have Gemini 3 Pro translate your intent and execute it for you. Gemini can then even parse dense formatted output back into natural language for you.&lt;/p&gt;
    &lt;p&gt;Ask Gemini CLI to handle all the complexity of running Git Bisect for you on the command line, leaving you free to focus on applying your judgement on finding the bug in question.&lt;/p&gt;
    &lt;code&gt;At some point I lost the commit that set my default theme to dark. 
Find it for me with git bisect and return the hash to me.&lt;/code&gt;
    &lt;p&gt;4. Generate accurate documentation from your code&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro's advanced reasoning allows it to read and understand the logic of your codebase. It doesn't just see syntax; it can investigate and synthesize the purpose of a function, identify its parameters and return values, and translate that complex logic into clear, human-readable language.&lt;/p&gt;
    &lt;p&gt;This is useful when you’ve introduced a complex application and now need to create the documentation. Instead of manually writing out descriptions, you can have Gemini analyze the code and generate the docs for you in a format that is consistent with your code.&lt;/p&gt;
    &lt;code&gt;"This is an application that does not have any documentation and we do not have a technical writer. Before you begin, review all of the code. Then make me a user documentation. This document should only explain user facing features, but make sure to explain every single feature such as usage of the app, command line options, authentication options, built in tools, and all other user facing features. For certain features such as MCP or extensions, also explain the topic and concept so that the user has a better understanding. Since this is an open source project, provide an architectural overview of how the code is laid out, a summary of each component, and how they can contribute to the open-source project. The document should be organized and formatted so that it is easy to read and find. Do not make it a single html page. Make sure to add a search feature."&lt;/code&gt;
    &lt;p&gt;5. Debug performance issue in a live Cloud Run service&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro can orchestrate complex workflows across different services that hold your team's context. The improved tool use means it can plan and execute multi-step tasks that require gathering information from several sources—like observability, security, and source control—to solve a single problem.&lt;/p&gt;
    &lt;p&gt;In this example it connects a serverless platform (Cloud Run) with a popular security scanner (Snyk) using Gemini CLI extensions to find the root cause and suggest a fix, then deploys the fix, turning a complex, multi-tool investigation into a single, streamlined action.&lt;/p&gt;
    &lt;code&gt;Users are reporting that the "Save Changes" button is slow, investigate the 'tech-stack' service&lt;/code&gt;
    &lt;p&gt;These examples are just the start. The real potential isn't in running these specific commands, but in how Gemini 3 Pro can adapt to your unique challenges whether you're optimizing daily shell commands, tackling substantial engineering work, or building a workflow personalized to your team's tools. Gemini 3 Pro transforms the command line into an intelligent partner that understands your context.&lt;/p&gt;
    &lt;p&gt;The best way to see the difference is to try it yourself. Visit the Gemini CLI website, and share your own examples on social with #GeminiCLI. We can't wait to see what you build.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968104</guid><pubDate>Tue, 18 Nov 2025 16:09:31 +0000</pubDate></item><item><title>A Day at Hetzner Online in the Falkenstein Data Center</title><link>https://www.igorslab.de/en/a-day-at-hetzner-online-in-the-falkenstein-data-center-insights-into-server-technology-cooling-production-rma-and-sustainability/</link><description>&lt;doc fingerprint="d5794295baae6fd1"&gt;
  &lt;main&gt;
    &lt;p&gt;My visit to Hetzner Online in Falkenstein goes far beyond a tour of a single server, as the site reveals an impressive combination of industrial precision, technical depth and logistically sophisticated infrastructure. As soon as you enter the extensive grounds, it becomes clear that this is a data center park that has grown over many years and is now one of the most comprehensive sites of its kind in Germany. The paths between the individual areas are long and winding, the buildings are spread over a large area and even the internal transport routes look more like the access roads of a small industrial area. Anyone planning a similar project should really be prepared to walk several kilometers and prefer sturdy footwear, as even the employees walk considerable distances every day in this environment. And because I know you’d rather watch someone else sweating in the heat, I’ve made a movie of this experience today:&lt;/p&gt;
    &lt;p&gt;And if you’d like to read about what you see, here’s a brief overview of today’s action:&lt;/p&gt;
    &lt;p&gt;The highly structured layout of the site is already apparent at the main entrance. After registering, the tour leads directly past the colocation area, where customers can operate their own hardware and access a fully-fledged data center environment. The modular arrangement of the racks, the clearly separated supply routes and the functional design convey an image of precise organization that was to run through the entire visit.&lt;/p&gt;
    &lt;p&gt;From there, we moved on to the midi data centers, which are designed as compact modules and yet meet all the requirements of a modern data center. This part of the park clearly demonstrates Hetzner’s focus on practicality, as there is nothing superfluous here. Everything is designed for smooth processes, short maintenance times and high energy efficiency. The simplicity on the outside is deceptive, because the infrastructure inside meets the requirements of a large-scale IT operation in every respect.&lt;/p&gt;
    &lt;p&gt;The route then led me to the areas where the actual in-house production is visible. Hetzner produces a significant proportion of its servers itself and does not rely on exaggerated presentation, but on robust construction and standardized processes. Individual components are first tested, followed by the assembly of the systems with clearly defined work steps before the devices are transferred to extensive test tracks. The test benches for hard disks and SSDs run continuously to ensure both reliability and long-term stability. In addition, there are areas for hardware service, RMA processing and the complete testing of 19-inch systems, so that defective components or components requiring replacement can be processed directly on site.&lt;/p&gt;
    &lt;p&gt;Another station was the production and processing of racks and open frame systems, which are used for cloud services, object storage and internal production environments. This segment shows particularly clearly that Hetzner deliberately relies on functional design and regional suppliers. The racks are finalized, checked and prepared for continuous use in data center environments in-house. Airflow, stability and ease of assembly are the main focus, as every second and every move counts in mass deployment.&lt;/p&gt;
    &lt;p&gt;Finally, in the decommissioning area, it becomes clear how carefully the entire life cycle of the hardware is handled. Discarded devices go through a complete documentation process before they are destroyed in a specially certified shredder, which renders both magnetic hard drives and SSDs safe and permanently unusable. The remnants then enter the regulated disposal process, which is also documented in detail.&lt;/p&gt;
    &lt;p&gt;The technical foundation of the site is particularly noteworthy. The redundant energy supply, the sophisticated network connection and the consistent use of free cooling form a system that enables maximum operating comfort with the lowest possible energy consumption. Thanks to the climatic location in the Vogtland region, a large part of the cooling can be achieved using outside air alone, resulting in low PUE values and a very stable thermal environment. The technical impression is so impressive that you almost forget how much work is behind the realization and ongoing operation.&lt;/p&gt;
    &lt;p&gt;Visitors quickly realize that a tour of Falkenstein is by no means a short detour. The dimensions, the number of halls and the distribution of the individual production and service areas inevitably mean that several kilometers have to be covered on foot. Good walking shoes are therefore not a bad recommendation. Anyone interested in infrastructure, technology and data center processes will gain an in-depth insight that goes far beyond what you would expect from the outside. Falkenstein is not an anonymous data location, but a highly organized interplay of production, service, operation and security that is rarely seen in this form. If you can get in…&lt;/p&gt;
    &lt;p&gt;So much for the script, but now just watch the finished cinematic product, because videos don’t hurt and I’ve kept it really short!&lt;/p&gt;
    &lt;p&gt;And if anyone is still looking for a good deal: Click here! (No affiliate, just a small thank you to the travel guides)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968235</guid><pubDate>Tue, 18 Nov 2025 16:18:47 +0000</pubDate></item><item><title>Solving a Million-Step LLM Task with Zero Errors</title><link>https://arxiv.org/abs/2511.09030</link><description>&lt;doc fingerprint="189cb409d4d7b6cf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 12 Nov 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Solving a Million-Step LLM Task with Zero Errors&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968362</guid><pubDate>Tue, 18 Nov 2025 16:26:28 +0000</pubDate></item><item><title>Show HN: Optimizing LiteLLM with Rust – When Expectations Meet Reality</title><link>https://github.com/neul-labs/fast-litellm</link><description>&lt;doc fingerprint="1a5bf61815d2d8ba"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance Rust acceleration for LiteLLM - providing 2-20x performance improvements for token counting, routing, rate limiting, and connection management.&lt;/p&gt;
    &lt;p&gt;Fast LiteLLM is a drop-in Rust acceleration layer for LiteLLM that provides significant performance improvements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;5-20x faster token counting with batch processing&lt;/item&gt;
      &lt;item&gt;3-8x faster request routing with lock-free data structures&lt;/item&gt;
      &lt;item&gt;4-12x faster rate limiting with async support&lt;/item&gt;
      &lt;item&gt;2-5x faster connection management&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built with PyO3 and Rust, it seamlessly integrates with existing LiteLLM code with zero configuration required.&lt;/p&gt;
    &lt;code&gt;pip install fast-litellm&lt;/code&gt;
    &lt;code&gt;import fast_litellm  # Automatically accelerates LiteLLM
import litellm

# All LiteLLM operations now use Rust acceleration where available
response = litellm.completion(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}]
)&lt;/code&gt;
    &lt;p&gt;That's it! Just import &lt;code&gt;fast_litellm&lt;/code&gt; before &lt;code&gt;litellm&lt;/code&gt; and acceleration is automatically applied.&lt;/p&gt;
    &lt;p&gt;The acceleration uses PyO3 to create Python extensions from Rust code:&lt;/p&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│ LiteLLM Python Package                                      │
├─────────────────────────────────────────────────────────────┤
│ fast_litellm (Python Integration Layer)                    │
│ ├── Enhanced Monkeypatching                                │
│ ├── Feature Flags &amp;amp; Gradual Rollout                        │
│ ├── Performance Monitoring                                 │
│ └── Automatic Fallback                                     │
├─────────────────────────────────────────────────────────────┤
│ Rust Acceleration Components (PyO3)                        │
│ ├── core               (Advanced Routing)                   │
│ ├── tokens             (Token Counting)                    │
│ ├── connection_pool    (Connection Management)             │
│ └── rate_limiter       (Rate Limiting)                     │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero Configuration: Works automatically on import&lt;/item&gt;
      &lt;item&gt;Production Safe: Built-in feature flags, monitoring, and automatic fallback to Python&lt;/item&gt;
      &lt;item&gt;Performance Monitoring: Real-time metrics and optimization recommendations&lt;/item&gt;
      &lt;item&gt;Gradual Rollout: Support for canary deployments and percentage-based feature rollout&lt;/item&gt;
      &lt;item&gt;Thread Safe: Lock-free data structures using DashMap for concurrent operations&lt;/item&gt;
      &lt;item&gt;Type Safe: Full Python type hints and type stubs included&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Baseline&lt;/cell&gt;
        &lt;cell role="head"&gt;Optimized&lt;/cell&gt;
        &lt;cell role="head"&gt;Use Case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Token Counting&lt;/cell&gt;
        &lt;cell&gt;5-10x&lt;/cell&gt;
        &lt;cell&gt;15-20x&lt;/cell&gt;
        &lt;cell&gt;Batch processing, context management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Request Routing&lt;/cell&gt;
        &lt;cell&gt;3-5x&lt;/cell&gt;
        &lt;cell&gt;6-8x&lt;/cell&gt;
        &lt;cell&gt;Load balancing, model selection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rate Limiting&lt;/cell&gt;
        &lt;cell&gt;4-8x&lt;/cell&gt;
        &lt;cell&gt;10-12x&lt;/cell&gt;
        &lt;cell&gt;Request throttling, quota management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Connection Pooling&lt;/cell&gt;
        &lt;cell&gt;2-3x&lt;/cell&gt;
        &lt;cell&gt;4-5x&lt;/cell&gt;
        &lt;cell&gt;HTTP reuse, latency reduction&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Fast LiteLLM works out of the box with zero configuration. For advanced use cases, you can configure behavior via environment variables:&lt;/p&gt;
    &lt;code&gt;# Disable specific features
export FAST_LITELLM_RUST_ROUTING=false

# Gradual rollout (10% of traffic)
export FAST_LITELLM_BATCH_TOKEN_COUNTING=canary:10

# Custom configuration file
export FAST_LITELLM_FEATURE_CONFIG=/path/to/config.json&lt;/code&gt;
    &lt;p&gt;See the Configuration Guide for all options.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.8 or higher&lt;/item&gt;
      &lt;item&gt;LiteLLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rust is not required for installation - prebuilt wheels are available for all major platforms.&lt;/p&gt;
    &lt;p&gt;To contribute or build from source:&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.8+&lt;/item&gt;
      &lt;item&gt;Rust toolchain (1.70+)&lt;/item&gt;
      &lt;item&gt;maturin for building Python extensions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Setup:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/neul-labs/fast-litellm.git
cd fast-litellm

# Install maturin
pip install maturin

# Build and install in development mode
maturin develop

# Run unit tests
pip install pytest pytest-asyncio
pytest tests/&lt;/code&gt;
    &lt;p&gt;Fast LiteLLM includes comprehensive integration tests that run LiteLLM's test suite with acceleration enabled:&lt;/p&gt;
    &lt;code&gt;# Setup LiteLLM for testing
./scripts/setup_litellm.sh

# Run LiteLLM tests with acceleration
./scripts/run_litellm_tests.sh

# Compare performance (with vs without acceleration)
./scripts/compare_performance.py&lt;/code&gt;
    &lt;p&gt;This ensures Fast LiteLLM doesn't break any LiteLLM functionality. See the Testing Guide for details.&lt;/p&gt;
    &lt;p&gt;For more information, see our Contributing Guide.&lt;/p&gt;
    &lt;p&gt;Fast LiteLLM uses PyO3 to create Python extensions from Rust code:&lt;/p&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│ LiteLLM Python Package                                      │
├─────────────────────────────────────────────────────────────┤
│ fast_litellm (Python Integration Layer)                    │
│ ├── Enhanced Monkeypatching                                │
│ ├── Feature Flags &amp;amp; Gradual Rollout                        │
│ ├── Performance Monitoring                                 │
│ └── Automatic Fallback                                     │
├─────────────────────────────────────────────────────────────┤
│ Rust Acceleration Components (PyO3)                        │
│ ├── core               (Advanced Routing)                   │
│ ├── tokens             (Token Counting)                    │
│ ├── connection_pool    (Connection Management)             │
│ └── rate_limiter       (Rate Limiting)                     │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;When you import &lt;code&gt;fast_litellm&lt;/code&gt;, it automatically patches LiteLLM's performance-critical functions with Rust implementations while maintaining full compatibility with the Python API.&lt;/p&gt;
    &lt;p&gt;We welcome contributions! Please see our Contributing Guide.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968461</guid><pubDate>Tue, 18 Nov 2025 16:32:16 +0000</pubDate></item><item><title>Strix Halo's Memory Subsystem: Tackling iGPU Challenges</title><link>https://chipsandcheese.com/p/strix-halos-memory-subsystem-tackling</link><description>&lt;doc fingerprint="2efaf135353868c9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Strix Halo’s Memory Subsystem: Tackling iGPU Challenges&lt;/head&gt;
    &lt;p&gt;Editor’s Note (11/2/2025): Due to an error in moving the article over from Google Docs to Substack, the “Balancing CPU and GPU Bandwidth Demands” section was missing some Cyberpunk 2077 data. Apologizes for the mistake!&lt;/p&gt;
    &lt;p&gt;AMD’s Strix Halo aspires to deliver high CPU and GPU performance within a mobile device. Doing so presents the memory subsystem with a complicated set of demands. CPU applications are often latency sensitive with low bandwidth demands. GPU workloads are often latency tolerant and bandwidth hungry. Then, multitasking requires high memory capacity. Mobile devices need low power draw. Finally, the whole package has to fit within a price tag acceptable to consumers. Investigating how AMD dealt with those challenges should make for a good time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Credit&lt;/head&gt;
    &lt;p&gt;ASUS has kindly sampled the ROG Flow Z13, which implements Strix Halo in a tablet form factor with 32 GB of LPDDR5X. They’ve made deep dives like this possible, and we greatly appreciate their support.&lt;/p&gt;
    &lt;p&gt;RX 7600 results were provided by Azralee from the Chips and Cheese Discord.&lt;/p&gt;
    &lt;head rend="h1"&gt;GPU&lt;/head&gt;
    &lt;p&gt;Strix Halo’s GPU uses a similar cache setup to AMD’s older and smaller mobile chips. As on Strix Point and Hawk Point (Zen 4 mobile), Strix Halo’s GPU is split into two Shader Arrays. Each Shader Array has 256 KB of L1 mid-level cache, and a 2 MB L2 services the entire GPU. Latencies to those GPU-private caches are in line with other RDNA3 and RDNA3.5 implementations. AMD likely kept L2 capacity at 2 MB because a 32 MB memory side cache (Infinity Cache, or MALL) takes over as the GPU’s last level cache.The L2 only has to catch enough traffic to prevent the Infinity Cache from getting overwhelmed. The resulting cache setup is similar to the one in the RX 7600, a lower midrange RDNA3 discrete card.&lt;/p&gt;
    &lt;p&gt;The Infinity Cache on Strix Halo has slightly higher latency compared to implementations in AMD’s discrete cards. DRAM latency from the GPU is higher as well. Compared to AMD’s other mobile CPUs with iGPUs though, the 32 MB Infinity Cache offers a large cache capacity increase.&lt;/p&gt;
    &lt;p&gt;Nemes’s Vulkan bandwidth test achieves just under 1 TB/s from Infinity Cache. The figures align well with performance counter data. Taken together with the chip’s 2 GHz FCLK, bandwidth test results suggest the GPU has a 512B/cycle path to the interconnect. If so, each of the GPU’s eight Infinity Fabric endpoints has a 64B/cycle link.&lt;/p&gt;
    &lt;p&gt;As a memory side cache, Infinity Cache can theoretically handle any access to physical addresses backed by DRAM. In an earlier interview with Cheese (George), AMD indicated that Infinity Cache was focused on the GPU, and that its behavior could change with firmware releases. Some of that change has happened already. When I first started testing Strix Halo just after Hot Chips 2025, results from my OpenCL microbenchmarks reflected Infinity Cache’s presence. I used that OpenCL code to figure out Data Fabric performance events. But PMU data collected from games suggested Infinity Cache wasn’t used once a game went into the background. Hardware doesn’t know whether a process is running in the foreground or background. That’s something the operating system knows, and that info would have to be communicated to hardware via drivers. Therefore, Infinity Cache policy can change on the fly from software control.&lt;/p&gt;
    &lt;p&gt;At that time, Nemes’s Vulkan-based code didn’t reflect Infinity Cache’s presence. PMU data showed a match between CS and UMC traffic, indicating the microbenchmark wasn’t taking advantage of Infinity Cache rather than the cache struggling with the access pattern. I was in the middle of investigating what Infinity Cache did or didn’t apply to when Windows updated. Then, foreground/background status no longer had any effect. Nemes’s Vulkan code was also able to observe the Infinity Cache.&lt;/p&gt;
    &lt;p&gt;Early observations on Infinity Cache behavior aren’t relevant today, but they do show Infinity Cache’s behavior is influenced by factors beyond a memory request’s origination point. Not all GPU requests install into the cache, and AMD can change cache policy on the fly. AMD could tune behavior with future updates too.&lt;/p&gt;
    &lt;p&gt;One early observation from OpenCL remained consistent though. Infinity Cache isn’t used for a buffer created with the CL_MEM_ALLOC_HOST_PTR flag and managed with zero-copy map/unmap APIs. CL_MEM_ALLOC_HOST_PTR requests an allocation from host-visible memory. On systems with discrete GPUs, AMD tends to handle that by allocating memory from DRAM attached to the CPU.&lt;/p&gt;
    &lt;p&gt;Intuitively, that flag shouldn’t make a difference on integrated GPUs. I’m not sure why it affects Infinity Cache behavior. Perhaps Strix Halo splits address ranges for the CPU and GPU under the hood, and the CPU’s address ranges aren’t cacheable from the Infinity Cache’s perspective.&lt;/p&gt;
    &lt;p&gt;AMD’s discrete Radeon RX 9070 shows similar behavior, with Infinity Cache not being used for host-side memory. Latency to host memory goes up to nearly a microsecond on RX 9070, while it remains unchanged on Strix Halo. Integrated GPUs have an advantage with zero-copy compute code, and it shows.&lt;/p&gt;
    &lt;p&gt;To further check zero-copy behavior, I have a test that allocates a 256 MB buffer using OpenCL’s Shared Virtual Memory APIs and only modifies a single 32-bit value. Strix Halo supports fine-grained buffer sharing like other recent AMD GPUs, meaning applications can use results generated from the GPU without calling map/unmap functions.&lt;/p&gt;
    &lt;p&gt;Strix Halo shows low latencies in line with zero-copy behavior. It’s worth noting that not all integrated GPUs can avoid a copy under the hood.&lt;/p&gt;
    &lt;p&gt;Copy APIs like clEnqueueReadBuffer and clEnqueueWriteBuffer are still relevant, because they’re the traditional way to work with discrete GPUs. Those APIs often use the copy queue and DMA engines, which handle data movement without involving general purpose compute units. Strix Halo can achieve high copy bandwidth in the CPU to GPU direction, but not the other way around.&lt;/p&gt;
    &lt;p&gt;Performance counter data suggests copies to the GPU don’t go through the Infinity Cache. During a copy, the shared memory controllers should observe both a read from CPU-side memory and a write to GPU-side memory. But there’s nowhere near 100% overhead compared to software measurements.&lt;/p&gt;
    &lt;p&gt;Bandwidth is lower in the other direction, but curiously CS-level bandwidth is similar. The memory controllers see less bandwidth, indicating some requests were handled on-chip, likely by Infinity Cache. Curiously, there’s way more than 100% overhead when comparing PMU data to software-visible copy bandwidth.&lt;/p&gt;
    &lt;head rend="h1"&gt;CPU&lt;/head&gt;
    &lt;p&gt;Strix Halo’s CPU side superficially resembles AMD’s flagship desktop parts, with 16 Zen 5 cores split across two Core Complex Dies (CCDs). However, these CCDs use TSMC’s InFO_oS for connectivity to the IO die rather than on-PCB traces. The CCD has 32B/cycle of bandwidth to the system in both the read and write directions.&lt;/p&gt;
    &lt;p&gt;Therefore, Strix Halo’s CCDs have more bandwidth at the die boundary than their desktop counterparts, but only in the write direction. It’s an advantage that’s likely to have minimal impact because reads often outnumber writes by a large margin.&lt;/p&gt;
    &lt;p&gt;Other CPU chiplet designs have more bandwidth at die boundaries, including the Compute Tile on Intel’s Meteor Lake and AMD’s own “GMI-Wide” configuration. GMI-Wide uses two links between the CCD and IO die to maximize cross-die bandwidth in lower core count server chips. Even though GMI-Wide doesn’t use advanced packaging, it has significantly more cross-die bandwidth than Strix Halo.&lt;/p&gt;
    &lt;p&gt;In a loaded latency test with reads, a Strix Halo CCD can reach high bandwidth levels at lower latency than standard GMI-Narrow CCDs. Part of that is likely down to its high bandwidth LPDDR5X setup, which a single CCD can’t come close to saturating. But that advantage doesn’t come through until bandwidth loads pass 45-55 GB/s. Before that, LPDDR5X’s high baseline latency puts Strix Halo at a disadvantage. At very high bandwidth load, Intel Meteor Lake’s higher cross-die bandwidth keeps it ahead. AMD’s GMI-Wide setup shows what a bandwidth-focused cross-die link can do, providing excellent bandwidth at low latency.&lt;/p&gt;
    &lt;p&gt;Bringing both CCDs into play gives Strix Halo a lead over Meteor Lake. I’m starting the test by placing bandwidth load on CCD1 while running the latency test on CCD0. That gives lower latency at bandwidth loads below 60 GB/s because contention at the CCD interface is taken out of the picture. Latency does increase as I spread bandwidth load across both dies, and rises beyond 200 ns as the test approaches die-to-die bandwidth limits. However, a read-only pattern is still limited by cross-die bandwidth and falls far short of the 256 GB/s that the LPDDR5X setup is theoretically capable of.&lt;/p&gt;
    &lt;p&gt;Advanced packaging may provide latency benefits too. Regular AMD CCDs use SerDes (serializer-deserializer) blocks, which convert signals for transport over lower quality PCB traces. Zen 2’s Infinity Fabric On-Package (IFOP) SerDes for example uses 32 transmit and 40 receive lanes running at a very high clock. Forwarded clock signals per lane data bundle help tackle clock skew that comes up with high speed parallel transmission over wires of unequal lengths. CRC helps ensure data integrity.&lt;/p&gt;
    &lt;p&gt;All of that adds power and latency overhead. Strix Halo’s InFO_oS packaging doesn’t require SerDes. But any latency advantage is difficult to observe in practice. DRAM requests are the most common type of off-CCD traffic. High LPDDR5X latency masks any latency advantage when looking at DRAM requests, as shown above. Cache coherency traffic is another form of off-CCD traffic, and doesn’t involve DRAM. However, testing that with a “core to core latency” test that bounces cachelines between core pairs also doesn’t provide favorable results for Strix Halo.&lt;/p&gt;
    &lt;p&gt;AMD handles cross-CCX cache coherency at Coherent Stations (CS-es) that sit right in front of the memory controllers. Memory traffic is interleaved across memory channels and thus CS instances based on their physical address. I try hitting different physical addresses by testing with various cacheline offsets into a 4 KB page, which gives me different combinations of L3 slices and memory controller + CS pairs. Values within a single run reflect variation based on the tested core pair, while different runs display variation from different memory subsystem blocks owning the tested address.&lt;/p&gt;
    &lt;p&gt;Cross-CCX latencies on Strix Halo land in the 100-120 ns range depending on the location of the tested core pair, responsible L3 slice, and responsible CS. It’s significantly higher on typical desktop systems or prior mobile chips from AMD. For example, the Ryzen 9 9900X tends to have cross-CCX latencies in the 80-90 ns range, which is in line with prior Zen generations. It’s about 20 ns faster than Strix Halo.&lt;/p&gt;
    &lt;p&gt;Therefore, I don’t have a satisfactory answer about Strix Halo’s cross-die latency. Latency may indeed be lower at die boundaries. But everything past that boundary has higher latency compared to other client systems, making any advantage invisible to software.&lt;/p&gt;
    &lt;head rend="h1"&gt;Balancing CPU and GPU Bandwidth Demands&lt;/head&gt;
    &lt;p&gt;Sharing a memory controller across the CPU and GPU comes with advantages, like making zero-copy behavior more natural to pull off. But it comes with challenges too. CPU and GPU memory requests can contend with each other for DRAM access. Contention surfaces as higher latency. From Zen 4 onward, AMD’s L3 performance monitoring unit (PMU) can measure average latency in nanoseconds for requests external to the core cluster. PMU data isn’t directly comparable to software measurements, because it only accounts for latency after the point of a L3 miss. But it is consistent in slightly under-estimating software observed latency when running a simple latency microbenchmark. When gaming, I typically see low CPU bandwidth demands and correspondingly mild latency increases over the baseline.&lt;/p&gt;
    &lt;p&gt;The same doesn’t hold true when gaming on Strix Halo’s integrated GPU. Latency rises far above the baseline of around 140 ns. I logged average latency over 1 second intervals, and many of those intervals saw latency figures around 200 ns across several games&lt;/p&gt;
    &lt;p&gt;I wrote a microbenchmark to investigate how CPU memory latency is impacted by GPU-sde bandwidth load. As with the CPU loaded latency test, I run a latency test thread on a CPU core. But instead of using a read-only pattern, I do a standard C=A+B computation across large arrays on the GPU. To control GPU bandwidth load, I can have each OpenCL kernel invocation do more math with A and B before writing the result to C. Results show increased latency at higher GPU bandwidth demands. Other recent iGPUs show similar behavior.&lt;/p&gt;
    &lt;p&gt;In-game CPU bandwidth demands are low, but not as low as a simple latency test. I tried running a couple of read bandwidth threads on top of the test above. Strix Halo seems to let its GPU squeeze out the CPU when under extreme bandwidth demands. Latency suffers, passing 300 ns at one point.&lt;/p&gt;
    &lt;p&gt;Plotting L3 and memory controller PMU data with 1 second intervals helps capture the relationship between latency and bandwidth usage in more complex workloads. The points don’t track well with microbenchmark data collected with a single CPU-side latency test thread. Perhaps there’s enough CPU-side bandwidth demand to cause contention at both the die-to-die interface and the memory controllers. Or maybe, CPU and GPU bandwidth spikes tend to line up within those 1 second intervals. Whatever the case, PMU data highlights how Strix Halo’s CPU cores need high cache hitrates more than their desktop counterparts.&lt;/p&gt;
    &lt;p&gt;Cyberpunk 2077’s built-in benchmark is largely CPU bound when run at 1080P with medium settings and no upscaling. I used Intel’s Arc B580 on desktop systems, since it has vaguely similar compute power to Strix Halo’s iGPU. Results show a large gap between Strix Halo and AMD’s desktop platform, even though both use the same Zen 5 cores.&lt;/p&gt;
    &lt;p&gt;Memory latency under load is largely not a problem with CPU-only workloads, even when considering heavily multithreaded ones. Total bandwidth demands are much lower and actually well within the capabilities of a 128-bit DDR5 setup. That explains why AMD was able to take on quad channel HEDT parts using a desktop dual channel platform back in the Zen 2 days. Good caching likely played a role, and Strix Halo continues to have 4 MB of last level cache per core. PMU data from Cinebench, code compilation, and AV1 video encoding loosely align with microbenchmark results. Latency barely strays above the baseline. Y-Cruncher is an exception. It’s very bandwidth hungry and not cache friendly. Its bandwidth demands are several times higher, and often go beyond a dual channel DDR5-5600 setup’s capabilities. Strix Halo is a good choice for that type of workload. But in the client space, bandwidth hungry CPU applications tend to be exceptions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words: A GPU with an Integrated CPU?&lt;/head&gt;
    &lt;p&gt;Observations above suggest Strix Halo’s Infinity Fabric and DRAM setup focuses on feeding the GPU and as a result the CPU gets the short end of the stick. High Infinity Fabric endpoint count and a wide LPDDR5X bus provide high bandwidth at high latency. CPU workloads tend to be latency sensitive and contention can make that even worse.&lt;/p&gt;
    &lt;p&gt;Other aspects of the memory subsystem de-prioritize the CPU as well. CPU accesses don’t fill into that cache, but still do a lookup likely to maintain cache coherency with the GPU. That cache lookup at the very least costs power and might add latency, even though it’ll almost never result in a hit. Lack of GMI-Wide style bandwidth is another example.&lt;/p&gt;
    &lt;p&gt;AMD’s decisions are understandable. Most client workloads have light bandwidth requirements.Strix Halo’s memory system design lets it perform well in portable gaming devices like the ROG Flow Z13. But it does make tradeoffs. And extrapolating from those tradeoffs suggests iGPU designs will face steeper challenges at higher performance tiers.&lt;/p&gt;
    &lt;p&gt;For its part, Strix Halo strikes a good balance. It enjoys iGPU advantages without being large enough for the disadvantages to hurt. I hope AMD continues to target Strix Halo’s market segment with updated designs, and look forward to seeing where they go next.&lt;/p&gt;
    &lt;p&gt;If you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese. Also consider joining the Discord.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968611</guid><pubDate>Tue, 18 Nov 2025 16:41:34 +0000</pubDate></item><item><title>Pebble, Rebble, and a Path Forward</title><link>https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/</link><description>&lt;doc fingerprint="fc4b101b5b1408f0"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I believe the Pebble community, Core Devices, Rebble and I all want the same thing. We love our Pebbles and want them to keep working long into the future. We love the community that has sprung up around Pebble, and how it’s persevered - next year will be the 14th anniversary of the original Kickstarter campaign!&lt;/p&gt;
      &lt;p&gt;But I have to respond to claims made by Rebble posted on their blog yesterday. I will link to their post so you can read their side of the story, and I’ve asked them to link back to this blog post from theirs.&lt;/p&gt;
      &lt;p&gt;Look - I’m the first person to call myself out when I fail. I wrote a detailed blog post about Success and Failure at Pebble and often write in detail about learning from my mistakes. But in this specific case, you’ll find that I’ve done my utmost to respect the Pebble legacy and community. Rebble is misleading the community with false accusations.&lt;/p&gt;
      &lt;p&gt;For those just passing through, here’s the TLDR: &lt;/p&gt;
      &lt;p&gt;Core Devices is a small company I started in 2025 to relaunch Pebble and build new Pebble smartwatches. Rebble is a non-profit organization that has supported the Pebble community since 2017. Rebble has done a ton of great work over the years and deserves recognition and support for that.&lt;/p&gt;
      &lt;p&gt;Core Devices and Rebble negotiated an agreement where Core would pay $0.20/user/month to support Rebble services. But the agreement broke down after over the following disagreement. &lt;/p&gt;
      &lt;p&gt;Rebble believes that they ‘100%’ own the data of the Pebble Appstore. They’re attempting to create a walled garden around 13,000 apps and faces that individual Pebble developers created and uploaded to the Pebble Appstore between 2012 and 2016. Rebble later scraped this data in 2017. &lt;/p&gt;
      &lt;p&gt;I disagree. I’m working hard to keep the Pebble ecosystem open source. I believe the contents of the Pebble Appstore should be freely available and not controlled by one organization. &lt;/p&gt;
      &lt;p&gt;Rebble posted a blog post yesterday with a bunch of false accusations, and in this post I speak to each of them.&lt;/p&gt;
      &lt;p&gt;Sections&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Dec 2016 - Pebble shut down. Some IP was sold to Fitbit. I blogged about why I think we failed. Fitbit continued to run the Pebble Appstore and web services for 1.5 years. I really appreciated that.&lt;list rend="ul"&gt;&lt;item&gt;Rebble organization grew out of the official Pebble Developers Discord.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;July 2018, Fitbit shut down the Pebble appstore.&lt;list rend="ul"&gt;&lt;item&gt;Before it shut down, Rebble (and others) scraped all 13,000 apps and metadata from the Pebble Appstore. Rebble began hosting a copy of the appstore. They created a new Dev Portal where developers could upload new apps, roughly 500 have been uploaded since July 2018.&lt;/item&gt;&lt;item&gt;Rebble also reverse engineered many Pebble web services (weather, timeline and voice transcription) and provided them as a paid service for the Pebble community.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Jan 2025 - Google open sourced PebbleOS, breathing new life into the community.&lt;/item&gt;
        &lt;item&gt;March 2025 - I announced a new company (Core Devices) and 2 new watches - store.rePebble.com&lt;/item&gt;
        &lt;item&gt;November 2025 - we finished shipping out 5,000 Pebble 2 Duos. We’re working hard on Pebble Time 2. We’re aiming to start shipping in January.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 1: ‘Rebble paid for the work that [Eric] took as a base for his commercial watches’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I think they’re accusing me of ‘stealing’ open source contributions to PebbleOS that Rebble paid for. This is entirely false.&lt;/item&gt;
        &lt;item&gt;We did not take any PebbleOS work Rebble paid for ‘as a base for [our] commercial watches’. To my best of my knowledge, Rebble never paid the developer who ported NimBLE into PebbleOS. My best guess is that they are referring to Rebble having paid CodeCoup, the company behind NimBLE, to fix some bugs that affected older non-Core Devices watches. Any Rebble-sponsored CodeCoup commits are not present in our repo. In fact, the opposite is true - we paid Codecoup $10,000 to fix multiple BLE stack issues, some of them on the host side that benefit all devices, including old Pebbles.&lt;/item&gt;
        &lt;item&gt;We started using our own repo for PebbleOS development because PRs on the Rebble repo reviews were taking too long. We only had one firmware engineer at the time (now we have a whopping 2!) and he felt like he was being slowed down too much. All of our contributions to PebbleOS have been 100% open source.&lt;/item&gt;
        &lt;item&gt;Overall, the feedback that PebbleOS could benefit from open governance is well taken. Long term, PebbleOS would be a good fit for open source organization with experience in open governance, like Apache or Linux Foundation. I wrote about this last week.&lt;/item&gt;
        &lt;item&gt;With our small team and fairly quick development schedule, it's true that we haven't PRed our changes into Rebble’s repo. It’s tough to prioritize this while we are busy fixing bugs and getting ready for Pebble Time 2.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 2: ‘Core took Rebble’s work’ on &lt;code&gt;libpebblecommon&lt;/code&gt; to create &lt;code&gt;libpebble3&lt;/code&gt;&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;The majority (&amp;gt;90%) of our new open source&lt;code&gt;libpebble3&lt;/code&gt; library was written by Core Devices employees.  The remainder comes from &lt;code&gt;libpebblecommon&lt;/code&gt;, another open source library written by two people.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;In April 2025, Core purchased the copyright to the &lt;code&gt;libpebblecommon&lt;/code&gt; code from the two maintainers and incorporated it into &lt;code&gt;libpebble3&lt;/code&gt;**, which is also open source**.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;All our contributions to &lt;code&gt;libpebble3&lt;/code&gt; are GPL-3.0 licensed. Here’s the motivation behind that our licensing strategy for this repo. We use the same CLA agreement as Matrix, QT and MySQL. Our CLA explicitly includes a clause that requires to Core Devices to distribute all contributions under an OSI-compatible FOSS license (e.g. GPLv3).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Note that neither Rebble &lt;code&gt;libpebblecommon&lt;/code&gt; maintainer signed the Rebble blog post.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Side note regarding Cobble, I don’t think Rebble even knows this but in 2024, I personally spent over $30,000 to support its development, way before PebbleOS was open source. It was my own way to support the community.&lt;/p&gt;
      &lt;p&gt;Accusation 3: ‘Core promised that they would let Rebble maintain and own the developer site’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Nothing of the sort was agreed upon. See the full written agreement that Core Devices has with Rebble towards the bottom. Rebble agreed that Core would host the developer site.&lt;/item&gt;
        &lt;item&gt;I have been maintaining and updating the developer site personally - all open source. Having two sources of truth would be confusing for the community.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 4: ‘[Eric] scraped our app store, in violation of the agreement that we reached with him previously’&lt;/p&gt;
      &lt;p&gt;Note: ‘scraping’ usually means to automated extraction of data from a website.&lt;/p&gt;
      &lt;p&gt;Facts: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Here’s what happened. I wanted to highlight some of my favourite watchfaces on the Pebble Appstore. Last Monday Nov 10, after I put my kids to sleep and between long calls with factories in Asia, I started building a webapp to help me quickly go through Pebble Appstore and decide which were my top picks.&lt;/item&gt;
        &lt;item&gt;Let me be crystal clear - my little webapp did not download apps or ‘scrape’ anything from Rebble. The webapp displayed the name of each watchface and screenshots and let me click on my favs. I used it to manually look through 6000 watchfaces with my own eyes. I still have 7,000 to go. Post your server logs, they will match up identically to the app I (well…Claude) wrote (source code here)&lt;/item&gt;
        &lt;item&gt;I integrated these picks into the Pebble Appstore on Saturday and posted about it on Sunday.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;All of four of these accusations could have been clarified simply by asking me. Instead, Rebble decided to post them on their blog and threaten a lawsuit. &lt;/p&gt;
      &lt;p&gt;How did we get here?&lt;/p&gt;
      &lt;p&gt;Why are there dueling blog posts in the Pebbleverse? &lt;/p&gt;
      &lt;p&gt;I think most of the people are behind Rebble are great and the community overall is awesome. I know they truly mean well, but there are many aspects of the org that are severely troubling. I am very close with one of the Rebble board members, who I consider a personal friend. Over the years, I learned a lot about the organization and helped coach him through some major disputes between board members. &lt;/p&gt;
      &lt;p&gt;I exchanged literally thousands of messages with my friend on this topic over the span of 3 years. I refrained from getting too involved, despite being asked several times to join Rebble as a board member or lead the organization. I demurred - I saw how painful it was for him and I had no interest in being part of that. &lt;/p&gt;
      &lt;p&gt;Core Devices + Rebble: 2025&lt;/p&gt;
      &lt;p&gt;PebbleOS is now open source! Yay. This is thanks to the work of many Googlers, ex-Pebblers and others - I called out (hopefully) all of them in my blog post in March. I really wanted Rebble to be a part of the Pebble revival going forward. I hired 3 people from Rebble to join Core Devices. I regularly brought up Rebble’s efforts over the years.&lt;/p&gt;
      &lt;p&gt;I engaged with Rebble folks in discussions in the spring on how we could formally work together, and then made some concrete proposals in the summer. One difficulty was that Core Devices is a business with customers and schedules. This didn’t always sync up with the timeframes of a non-profit. Things became very drawn out. It was very hard to pin people down, even on simple stuff like what the goals of Rebble as an organization were. &lt;/p&gt;
      &lt;p&gt;Regardless, I continued pushing to make Rebble a key part of the Pebble relaunch.&lt;/p&gt;
      &lt;p&gt;By August, we finally got close to an agreement.&lt;/p&gt;
      &lt;p&gt;On September 30 2025, we agreed to the following document and published respective blog posts (ours, theres). Core Devices would pay Rebble $0.20/user/month. I considered it a donation to a group that has done so much to support the community. But I purposely pushed for openness - no single group (Core Devices or Rebble) should be in control. &lt;/p&gt;
      &lt;p&gt;Notice the final bullet in the App store section: &lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;All binary/metadata (including historical apps) will be published as archive file (no scraping Rebble services) &lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;Looking back, we should have had more clear wording in this agreement. But this was after months of chat discussions and hours of Zoom calls. I honestly thought that we had reached an agreement to make the archive open, like in this message I received from a Rebble board member.&lt;/p&gt;
      &lt;p&gt;By the end of October, Rebble has changed their mind about providing an archive file.&lt;/p&gt;
      &lt;p&gt;Not withstanding their false accusations of theft, the crux of our disagreement is the archive of 13,000 Pebble apps and watchfaces that were uploaded to the Pebble Appstore in July 2018 before it was shut down. &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I believe that these apps and watchfaces should be archived publicly and freely accessible by anyone. They should not held behind a walled garden by one organization. I repeatedly advocated for hosting this data on a neutral 3rd party like Archive.org.&lt;/item&gt;
        &lt;item&gt;Rebble believes ‘the data behind the Pebble App Store is 100% Rebble’ (this is a direct quote from their blog post). They repeatedly refer to all watchfaces and watchapps as ‘our data’.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;This is just plainly false. The apps and watchfaces were originally uploaded by individual developers to an appstore run by a company that no longer exists. These folks created beautiful work and shared them freely with the Pebble community. I’ve spoken with numerous Pebble app developers about this. After the fall of Pebble Tech Corp, none of them envisioned one single organization claiming ownership of their work and restricting access, or charging money for access.&lt;/p&gt;
      &lt;p&gt;Let’s do the right thing - honour the original developers and create a free publicly available archive of their beautiful watchfaces and watchapps. &lt;/p&gt;
      &lt;p&gt;It's easy to assume the worst in situations like this. But our plan for the appstore is pretty straightforward. We’re working on rewriting the appstore frontend to be native in the mobile app rather than a web view. Rebble’s appstore backend API will be the data source. Rebble’s dev portal is where developers upload apps. No subscription or Rebble account will not be required to download apps. We intend to curate how the appstore is displayed Pebble app.&lt;/p&gt;
      &lt;p&gt;We’re excited to see other Pebble-supporting mobile apps pop up - like MicroPebble and GadgetBridge, offering different features and experiences. We’d love to support these efforts with open source code or financially.&lt;/p&gt;
      &lt;p&gt;Reading things like ‘We’re happy to let them build whatever they want as long as it doesn’t hurt Rebble’ in their blog post worries me. Take our voice-to-text and weather features. Rebble currently offers these as part of their paid subscription. Our new Pebble mobile app includes a on-device speech-to-text feature. We’re planning to include weather for free in our app and make the data available to all watchfaces so you don’t need to configure each one separately. These features are better for users but would they ‘hurt’ Rebble? Will I need to ask permission from Rebble before building these features? It’s clear that the goals of a non-profit and device manufacturer will not always be in alignment.&lt;/p&gt;
      &lt;p&gt;Now consider the appstore. It’s a fundamental part of the Pebble experience. Even before yesterday’s accusations, I felt wary about relying too heavily on a 3rd party like Rebble to provide such a critical service. When people buy a watch from Core Devices, they expect to be able to download apps and watchfaces. If Rebble leadership changes their mind, how can I be certain I can deliver a good experience for our customers? This is one of the primary reasons I think it’s important for an archive of the Pebble Appstore to be freely available.&lt;/p&gt;
      &lt;p&gt;Rebble - prove that you believe in an open, unrestricted Pebble community. Tear down the walled garden you are trying to create. Publish your copy of the Pebble Appstore archive. Stop saying that you ‘100%’ own other developers data. Let’s move on from this ridiculous sideshow and focus on making Pebble awesome!&lt;/p&gt;
      &lt;p&gt;I’ve worked hard to structure everything that we’re doing to be sustainable for the long term, and to do right by the Pebble community. I think Rebble should do the same. &lt;/p&gt;
      &lt;p&gt;I earned almost nothing from Pebble Tech Corp. I paid myself a $65,000 salary each year. I did not get any payout through the asset sale. I fought to make sure that all Pebble employees were taken care of as best as possible, and that the Pebble community would live on. I believe that at every turn, I’ve done right by the community.&lt;/p&gt;
      &lt;p&gt;I didn’t relaunch Pebble to make a lot of money. My goal this time round is to make it sustainable. I want to continue making more watches and cool gadgets. There are no investors. I am taking huge risks doing this. I relaunched it because I love Pebble and want it to live on long into the future. Generally, I am excited and positive for the future, despite everything.&lt;/p&gt;
      &lt;p&gt;For everyone else, again, I apologize for the extreme amounts of inside baseball and the better things you could be doing with your time. I’ll leave the comments open here. Please refrain from any personal attacks or vicious comments (at myself or other people) - follow the HN guidelines.&lt;/p&gt;
      &lt;p&gt;Eric Migicovsky&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45969250</guid><pubDate>Tue, 18 Nov 2025 17:24:27 +0000</pubDate></item></channel></rss>