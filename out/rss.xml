<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 05 Nov 2025 20:11:50 +0000</lastBuildDate><item><title>UPS plane crashes near Louisville airport</title><link>https://avherald.com/h?article=52f5748f&amp;opt=0</link><description>&lt;doc fingerprint="52410b633192bbd9"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;&lt;lb/&gt;By Kai Petzke on Wednesday, Nov 5th 2025 20:05Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Jidosha on Wednesday, Nov 5th 2025 19:33Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By JD on Wednesday, Nov 5th 2025 19:09Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Lee on Wednesday, Nov 5th 2025 18:45Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By DC8 Mech on Wednesday, Nov 5th 2025 18:45Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By dmn on Wednesday, Nov 5th 2025 18:07Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By JJones on Wednesday, Nov 5th 2025 17:59Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Dog on Wednesday, Nov 5th 2025 17:58Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Horstroad on Wednesday, Nov 5th 2025 17:42Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By badman on Wednesday, Nov 5th 2025 17:42Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Captain Crunch on Wednesday, Nov 5th 2025 16:54Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By LittleCupcakes on Wednesday, Nov 5th 2025 16:47Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By David Cornutt on Wednesday, Nov 5th 2025 16:38Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By DHE on Wednesday, Nov 5th 2025 16:34Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Kaj Jensen on Wednesday, Nov 5th 2025 16:34Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Afterburner119 on Wednesday, Nov 5th 2025 16:12Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Captain Crunch on Wednesday, Nov 5th 2025 16:02Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By MF on Wednesday, Nov 5th 2025 15:59Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Mark on Wednesday, Nov 5th 2025 15:39Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Anon on Wednesday, Nov 5th 2025 15:35Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Peter on Wednesday, Nov 5th 2025 15:24Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Strebav8or on Wednesday, Nov 5th 2025 15:13Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Captain Crunch on Wednesday, Nov 5th 2025 15:09Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Janaka Chandrasekera on Wednesday, Nov 5th 2025 14:50Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Captain Crunch on Wednesday, Nov 5th 2025 13:47Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Thomas on Wednesday, Nov 5th 2025 13:43Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Sam Coat on Wednesday, Nov 5th 2025 13:15Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By James on Wednesday, Nov 5th 2025 13:12Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By (anonymous) on Wednesday, Nov 5th 2025 13:06Z&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;By Dave on Wednesday, Nov 5th 2025 13:01Z&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816963</guid><pubDate>Tue, 04 Nov 2025 23:10:53 +0000</pubDate></item><item><title>Bluetui ‚Äì A TUI for managing Bluetooth on Linux</title><link>https://github.com/pythops/bluetui</link><description>&lt;doc fingerprint="e4d181ddbeaa2ea"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux based OS with bluez installed.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;You might need to install nerdfonts for the icons to be displayed correctly.&lt;/p&gt;
    &lt;p&gt;You can download the pre-built binaries from the release page release page&lt;/p&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from crates.io&lt;/p&gt;
    &lt;code&gt;cargo install bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the extra repository:&lt;/p&gt;
    &lt;code&gt;pacman -S bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the lamdness Gentoo Overlay:&lt;/p&gt;
    &lt;code&gt;sudo eselect repository enable lamdness
sudo emaint -r lamdness sync
sudo emerge -av net-wireless/bluetui&lt;/code&gt;
    &lt;p&gt;If you are a user of x-cmd, you can run:&lt;/p&gt;
    &lt;code&gt;x install bluetui&lt;/code&gt;
    &lt;p&gt;Run the following command:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/pythops/bluetui
cd bluetui
cargo build --release&lt;/code&gt;
    &lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/bluetui&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Tab&lt;/code&gt;: Switch between different sections.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start/Stop scanning.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt;: Show help.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;esc&lt;/code&gt;: Dismiss the help pop-up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; or &lt;code&gt;q&lt;/code&gt;: Quit the app.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt;: Enable/Disable the pairing.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Power on/off the adapter.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Enable/Disable the discovery.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;u&lt;/code&gt;: Unpair the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Connect/Disconnect the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;t&lt;/code&gt;: Trust/Untrust the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;e&lt;/code&gt;: Rename the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Pair the device.&lt;/p&gt;
    &lt;p&gt;Keybindings can be customized in the default config file location &lt;code&gt;$HOME/.config/bluetui/config.toml&lt;/code&gt; or from a custom path with &lt;code&gt;-c&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;# Possible values: "Legacy", "Start", "End", "Center", "SpaceAround", "SpaceBetween"
layout = "SpaceAround"

# Window width
# Possible values: "auto" or a positive integer
width = "auto"

toggle_scanning = "s"

[adapter]
toggle_pairing = "p"
toggle_power = "o"
toggle_discovery = "d"

[paired_device]
unpair = "u"
toggle_trust = "t"
rename = "e"&lt;/code&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;Bluetui logo: Marco Bulgarelli&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45817114</guid><pubDate>Tue, 04 Nov 2025 23:29:31 +0000</pubDate></item><item><title>Hypothesis: Property-Based Testing for Python</title><link>https://hypothesis.readthedocs.io/en/latest/</link><description>&lt;doc fingerprint="a1031a81e5b71397"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to Hypothesis!¬∂&lt;/head&gt;
    &lt;p&gt;Hypothesis is the property-based testing library for Python. With Hypothesis, you write tests which should pass for all inputs in whatever range you describe, and let Hypothesis randomly choose which of those inputs to check - including edge cases you might not have thought about. For example:&lt;/p&gt;
    &lt;p&gt;You should start with the tutorial, or alternatively the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tutorial¬∂&lt;/head&gt;
    &lt;p&gt;An introduction to Hypothesis.&lt;/p&gt;
    &lt;p&gt;New users should start here, or with the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;How-to guides¬∂&lt;/head&gt;
    &lt;p&gt;Practical guides for applying Hypothesis in specific scenarios.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explanations¬∂&lt;/head&gt;
    &lt;p&gt;Commentary oriented towards deepening your understanding of Hypothesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;API Reference¬∂&lt;/head&gt;
    &lt;p&gt;Technical API reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818562</guid><pubDate>Wed, 05 Nov 2025 03:15:37 +0000</pubDate></item><item><title>Founder in Residence at Woz (San Francisco)</title><link>https://news.ycombinator.com/item?id=45821921</link><description>&lt;doc fingerprint="3ab8fb7857c0d6e6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Founder in Residence at Woz (San Francisco)&lt;/p&gt;
      &lt;p&gt;We‚Äôre opening one of the coolest jobs ever (only slightly biased).&lt;/p&gt;
      &lt;p&gt;At Woz, we‚Äôve built the world's first AI App Factory, capable of building business quality mobile apps in just hours.&lt;/p&gt;
      &lt;p&gt;Now we‚Äôre handing over the keys to aspiring founders and challenging them to build real, revenue generating app businesses. Founders get full internal access to our platform, a salary, a dedicated marketing budget, and meaningful upside in any revenue they generate. This is a rare chance to operate like a founder inside a YC startup that recently raised a $6M seed round, surrounded by experienced engineers and builders in the heart of San Francisco.&lt;/p&gt;
      &lt;p&gt;Who we‚Äôre looking for: - A technical builder who can ship, iterate and problem solve independently (experience with React Native and TypeScript is a plus) - Someone who has launched products, apps, or businesses before, or has a strong track record of building things on their own - Someone who understands go-to-market and growth, especially creative or viral marketing - Someone eager to learn, experiment, and build alongside our team in San Francisco (able to work in-person for at least the first three months)&lt;/p&gt;
      &lt;p&gt;Interested? Submit your info here. We‚Äôll be in touch https://forms.gle/h8ZWjgRfQUpaTQf8A&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45821921</guid><pubDate>Wed, 05 Nov 2025 12:00:17 +0000</pubDate></item><item><title>The grim truth behind the Pied Piper (2020)</title><link>https://www.bbc.com/travel/article/20200902-the-grim-truth-behind-the-pied-piper</link><description>&lt;doc fingerprint="bf3fc84dbbe71458"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The grim truth behind the Pied Piper&lt;/head&gt;
    &lt;p&gt;Writers like the Grimm Brothers and Robert Browning may have shaped the Pied Piper legend into art, but it turns out the story is likely based on an actual historical incident.&lt;/p&gt;
    &lt;p&gt;(This year, we published many inspiring and amazing stories that made us fall in love with the world ‚Äì and this is one our favourites. Click here for the full list).&lt;/p&gt;
    &lt;p&gt;Every working morning for the last 26 years, Michael Boyer has slipped into a pair of neon-bright, multi-coloured tights, tied on his lipstick-red cape, grabbed his flute and marched out into the medieval streets of Hamelin, a town of 60,000 residents in Lower Saxony, Germany.&lt;/p&gt;
    &lt;p&gt;‚ÄúPeople sometimes mistake me for a superhero, court jester or Robin Hood,‚Äù he laughed. He‚Äôs also increasingly become an Instagram prop for tourists and, maybe in some woke eyes, a gender-fluid statement.&lt;/p&gt;
    &lt;p&gt;But most people recognise him for what he is, the Pied Piper incarnate, appointed by Hamelin to impersonate its simultaneously favourite (at least commercially) and least favourite adopted son. Responsible for meeting and greeting visiting groups and dignitaries, he leads tours of the city and embodies the enduring hold of the legend that draws most travellers here.&lt;/p&gt;
    &lt;p&gt;The tale in fact has survived for a very long time. Originating as medieval folklore, the story inspired a Goethe verse, Der Rattenf√§nger; a Grimm Brothers‚Äô legend, The Children of Hamelin; and one of Robert Browning‚Äôs best-known poems, The Pied Piper of Hamelin. And although each writer tinkered with the story, the basics remained the same: the Piper was hired by Hamelin to rid the town of its plague of rats. Trailing after the hypnotic notes of the rat-catcher‚Äôs magical flute, the rodents politely filed through the city gates to their presumed doom.&lt;/p&gt;
    &lt;p&gt;They weren‚Äôt the only ones lured by his music, though. When the town refused to pay the Piper for his service, the saviour turned into a more satanic seducer and came for Hamelin‚Äôs children. Entranced by the notes of his flute, the transfixed boys and girls followed the Piper out of town and simply vanished.&lt;/p&gt;
    &lt;p&gt;While the tale has endured, so has Hamelin itself, which still looks as though it belongs in a fairy tale. Boyer‚Äôs tour leads visitors past rows of half-timbered houses. There are 16th Century burgher manors encrusted with Gothic gables and scrollwork, and flamboyant wedding cake buildings offering prime examples of the local Weser-Renaissance architecture, all leering gargoyles and brightly coloured polychrome wood carvings.&lt;/p&gt;
    &lt;p&gt;However, all this is merely background for the town‚Äôs real cottage industry, which cashes in on all things Piper. The local restaurants plate a ‚Äúrat tail‚Äù signature dish made from thinly sliced pork, and the bakeries do a brisk business in rodent-shaped breads and cakes. The Hameln Museum offers a sound and light Pied Piper re-enactment; local actors put on an open-air Pied Piper play during summer; and the souvenir shops hawk their own rat-inspired memorabilia. You can go home, if you wish, loaded down with Pied Piper T-shirts, fridge magnets, mugs and flutes.&lt;/p&gt;
    &lt;p&gt;What could pass for mere comic relief, though, masks something deeper, and suggests why the legend lives on not only in Hamelin but in enduring folklore. On some level, the tale stokes a primal fear, with the Piper a version of a universal bogey man that continues to haunt us. Parents everywhere still fear the loss of their babies. Children, popping up on the nightly news, still go missing every day. And then we all ultimately vanish in something like an instant. The Piper, in the end, is one very grim reaper.&lt;/p&gt;
    &lt;p&gt;But if the tale evokes a universal fear, it still resonates most strongly in Hamelin ‚Äì and the Piper‚Äôs tour suggests why. In fact, the real surprise of his tour isn‚Äôt so much the beautifully preserved townscape but the suggestion that the Pied Piper is much more than just a fairy tale. The Grimm Brothers and Browning may have shaped the legend into art, but the story, it turns out, is likely based on an actual historical incident.&lt;/p&gt;
    &lt;p&gt;You may also be interested in:&lt;/p&gt;
    &lt;p&gt;‚Ä¢ The elusive hidden people of Iceland&lt;/p&gt;
    &lt;p&gt;The proof is etched on Hamelin‚Äôs face itself. An inscribed plaque on the stone facade of the so-called Pied Piper house, a half-timbered private residence dating to 1602 ‚Äì similar to an even earlier one etched on the building‚Äôs window ‚Äì bears explicit witness to the mystery. The inscription reads:&lt;/p&gt;
    &lt;p&gt;‚ÄúA.D. 1284 ‚Äì on the 26th of June ‚Äì the day of St John and St Paul ‚Äì 130 children ‚Äì born in Hamelin ‚Äì were led out of the town by a piper wearing multicoloured clothes. After passing the Calvary near the Koppenberg they disappeared forever.‚Äù&lt;/p&gt;
    &lt;p&gt;The inscription isn‚Äôt the only clue. An entry in Hamelin‚Äôs town records, dating to 1384, laments that, ‚ÄúIt is 100 years since our children left.‚Äù The stained-glass window in the town‚Äôs St Nicolai church, destroyed in the 17th Century but described in earlier accounts, reportedly illustrated the figure of the Pied Piper leading several ghostly white children. And the 15th Century Luneburg manuscript, an early German account of the event, along with five historical memory verses, some in Latin and others in Middle Low German, all refer to a similar story of 130 children or young people vanishing on the 26 June 1284, following a pied piper to a place called Calvary or Koppen.&lt;/p&gt;
    &lt;p&gt;The Pied Piper then, more than a fairy tale, becomes the emblem of a profound historical mystery. What happened to the missing children of Hamelin? Still the master seducer, the mesmerising rat-catcher is now leading a whole new trail of entranced followers ‚Äì this time a conga line of historians each taking their own deep dive into the question of what exactly transpired in Hamelin on 26 June 1284.&lt;/p&gt;
    &lt;p&gt;The theories are legion, according to Wibke Reimer, project coordinator at the Hameln Museum who has been organising a special exhibit that focuses on the global reach of the Pied Piper legend. One of the leading current theories suggests the town‚Äôs youth were part of a migration of Germans to Eastern Europe fuelled by an economic depression.&lt;/p&gt;
    &lt;p&gt;‚ÄúIn this scenario,‚Äù Reimer said, ‚Äúthe Pied Piper played the role of a so-called locator or recruiter. They were responsible for organising migrations to the east and were said to have worn colourful garments and played an instrument to attract the attention of possible settlers.‚Äù&lt;/p&gt;
    &lt;p&gt;While some historians believe that the youth emigrated to Transylvania, the German linguist J√ºrgen Udolph‚Äôs theory is most accepted. ‚ÄúHe suggests the regions around Berlin as the most probable location, in an area that‚Äôs now [eastern Germany],‚Äù Reimer said, ‚Äúand he backs up his theory by place name evidence.‚Äù In fact, Udolph found that the family names common in Hamelin at the time show up with surprising frequency in the areas of Uckermark and Prignitz, near Berlin, that he locates as the centre of the migration. The theory is also reinforced by evidence that the region, newly liberated from the Danes, was ripe for German colonisation.&lt;/p&gt;
    &lt;p&gt;More fanciful theories abound, too. Some historians suggest the legend reflects a 13th Century children‚Äôs crusade, part of the wave of medieval crusades aimed at winning back the Holy Land. And some argue the youth were lost to the Black Plague, though the dates don‚Äôt match up.&lt;/p&gt;
    &lt;p&gt;More intriguing is a theory that points to the medieval phenomenon of ‚Äúdancing mania‚Äù, driven by a succession of pandemics and natural disasters. Known as St Vitus‚Äô Dance, the dancing plague is documented surfacing in continental Europe as early as the 11th Century. A form of mass hysteria, the dance could spread from individuals to large groups, all driven by an unshakeable compulsion to dance feverishly, sometimes for weeks, often leaping and singing and sometimes hallucinating to the point of exhaustion and occasionally death, like a top that can‚Äôt stop spinning.&lt;/p&gt;
    &lt;p&gt;And, in fact, one 13th Century outbreak ‚Äì a literal form of dance fever ‚Äì occurred south of Hamelin, in the town of Erfurt, where a group of youths were documented as wildly gyrating as they travelled out of town, ending up 20km away in a neighbouring town. Some of the children, one chronicle suggests, expired shortly thereafter, having flat-out danced themselves to death, and those who survived were left with chronic tremors. Perhaps, some theorise, Hamelin witnessed a similar plague, dancing to the figurative tune of the Piper.&lt;/p&gt;
    &lt;p&gt;But all these theories neglect one specific key to the Hamelin mystery. ‚ÄúThey don‚Äôt explain the very particular date cited for the loss of the children, and the local sense of trauma,‚Äù Reimer noted. ‚ÄúDid something happen that officials had been covering up? Something so traumatic that it was transmitted orally for so long in the town‚Äôs collective memory, over decades and even centuries?‚Äù&lt;/p&gt;
    &lt;p&gt;In fact, the date chronicled in all the local documentation pinpoint 26 June as the day the children disappeared. This day is also the date of pagan midsummer celebrations. The fact the documentation also emphasises that the youth followed the Piper to the Koppen, commonly translated as ‚Äúhills‚Äù, suggest another link. ‚ÄúThere were regions in Germany where midsummer was celebrated by lighting fires on the hills,‚Äù said Reimer. All that leads to one particularly macabre reading of the Pied Piper legend. Perhaps the Piper, emblematic of a pagan shaman, playing his flute, was leading the youth of Hamelin to their midsummer festivities when the local Christian faction, hoping to cement conversion of the region, waylaid and massacred the group. A less bloody theory: maybe the children were spirited away to local monasteries.&lt;/p&gt;
    &lt;p&gt;If the tale suggests a possible historical tragedy, though, it also offers an artistic redemption as well.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe Pied Piper story,‚Äù said Reimer, preparing for the debut of her exhibit on 26 June, ‚Äúis to our knowledge known in at least 42 countries and 30 languages, maybe more. And it appears in international art, literature and music. The Pied Piper is a shared heritage of many people, and that cultural heritage connects people.‚Äù&lt;/p&gt;
    &lt;p&gt;Ultimately, then, the Piper didn‚Äôt just fracture a community. He also, in the end, brought a larger one together.&lt;/p&gt;
    &lt;p&gt;Join more than three million BBC Travel fans by liking us on Facebook, or follow us on Twitter and Instagram.&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for the weekly bbc.com features newsletter called "The Essential List". A handpicked selection of stories from BBC Future, Culture, Worklife and Travel, delivered to your inbox every Friday.&lt;/p&gt;
    &lt;p&gt;{"image":{"pid":""}}&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822071</guid><pubDate>Wed, 05 Nov 2025 12:21:39 +0000</pubDate></item><item><title>iOS 26.2 to allow third-party app stores in Japan ahead of regulatory deadline</title><link>https://www.macrumors.com/2025/11/05/ios-26-2-third-party-app-stores-japan/</link><description>&lt;doc fingerprint="e5ccf95d1326115c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;iOS 26.2 to Allow Third-Party App Stores in Japan Ahead of Regulatory Deadline&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;p&gt;Apple on Tuesday released the first beta of iOS 26.2 to developers, and it appears that the software will allow users in Japan to install alternative app marketplaces on their devices when it is released to the public in December.&lt;/p&gt;
          &lt;p&gt;&lt;lb/&gt;According to a post shared on X by @Tzzlala, iPhones running the beta in Japan are able to install alternative app stores like AltStore PAL and Epic Games, and download apps from them, though Fortnite in-app purchases are currently region-blocked by Epic. &lt;/p&gt;
          &lt;p&gt;Apple only lets iPhone and iPad users based in the EU to install apps using alternative app marketplaces in addition to the App Store. The ability was introduced in iOS 17.4 and iPadOS 18 in order to comply with the Digital Markets Act, and Apple does not currently allow it in any regions outside the 27-member bloc. However, that's set to change. &lt;/p&gt;
          &lt;p&gt;In June 2024, the Japanese parliament approved and enacted legislation that requires Apple to allow third-party app stores and payment providers on the iPhone. The law seeks to curb the dominance of major tech firms like Apple in the smartphone market.&lt;/p&gt;
          &lt;p&gt;More recently, in August 2025, the Japan Fair Trade Commission established the Mobile Software Competition Act Guidelines. Under the new guidelines, platform operators like Apple and Google are banned from blocking or restricting the availability of alternative app stores and payment systems on their mobile operating systems. &lt;/p&gt;
          &lt;p&gt;The guidelines are set to come into effect by December 18, 2025, while Apple is expected to release iOS 26.2 in December, sometime between December 9 and December 16. Epic Games has already announced plans to bring Fortnite and its game store platform to iOS in Japan by late 2025. &lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;Popular Stories&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple is planning to launch at least 15 new products in 2026, according to Bloomberg's Mark Gurman. Gurman outlined what to expect from Apple in 2026 in the latest edition of his "Power On" newsletter. He said the company is heading "into one of its most pivotal years in recent memory," with the rollout of major new Apple Intelligence features, intense regulatory pressure on the App Store,...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;In his "Power On" newsletter, Bloomberg's Mark Gurman today provided an update on the status of Apple Intelligence and the plans for it in 2026. Apple is still planning to roll out its revamped version of Siri around March of next year. The release should be accompanied by the release of a new smart home display product with speaker-base and wall-mount options. A new Apple TV and HomePod...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;A new Apple TV and HomePod mini could launch as soon as this month, Bloomberg's Mark Gurman today suggested. In today's "Power On" newsletter, Gurman said that Apple retail stores are planning an overnight refresh on the evening of November 11, where changes will be made after closing, such as refreshing displays and placing new products for the following day. The timing of the overnight...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple today released iOS 26.1, the first major update to the iOS 26 operating system that came out in September, iOS 26.1 comes over a month after iOS 26 launched. iOS 26.1 is compatible with the iPhone 11 series and later, as well as the second-generation iPhone SE. The new software can be downloaded on eligible iPhones over-the-air by going to Settings &amp;gt; General &amp;gt;...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Following more than a month of beta testing, Apple released iOS 26.1 on Monday, November 3. The update includes a handful of new features and changes, including the ability to adjust the look of Liquid Glass and more. Below, we outline iOS 26.1's key new features. Liquid Glass Toggle iOS 26.1 lets you choose your preferred look for Liquid Glass. In the Settings app, under Display...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;We're officially in the month of Black Friday, which will take place on Friday, November 28 in 2025. As always, this will be the best time of the year to shop for great deals, including popular Apple products like AirPods, iPad, Apple Watch, and more. In this article, the majority of the discounts will be found on Amazon. Note: MacRumors is an affiliate partner with some of these vendors. When ...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple updated the logo and name for its Apple TV streaming service today, and it looks like Apple One might be next. On the revamped Apple TV website, there's a new, more colorful Apple One logo available. The logo features an Apple icon that's split into six slices, and each slice includes the color that Apple uses for one of the services included in Apple One Premium. Apple One is...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822302</guid><pubDate>Wed, 05 Nov 2025 12:51:44 +0000</pubDate></item><item><title>Radiant Computer</title><link>https://radiant.computer</link><description>&lt;doc fingerprint="899b796b21f8ecf7"&gt;
  &lt;main&gt;&lt;p&gt;Radiant Computer&lt;/p&gt;&lt;p&gt;Radiant's purpose is to explore what personal computing could be when designed from first principles.&lt;/p&gt;We believe the current trajectory of personal computing is leading us to a less free world, and that only a new computing movement rooted in human dignity, creation and autonomy can change its course.&lt;p&gt;Radiant is a computer reimagined from the ground up, a clean-slate design free from the historical baggage that plagues modern systems, and free from Big Tech's influence.&lt;/p&gt;&lt;p&gt;It's a computer designed to help you learn, create, play, and explore. It's a space to focus, free from distractions. A return to the simple joy of computing: just you and your ideas.&lt;/p&gt;&lt;p&gt;Computers today are designed around engagement and surveillance business models rather than user needs. App stores are filled with adware. Operating systems prioritize data collection over user agency. Social media algorithms optimize for addiction. Big Tech fundamentally reshaped computing from a tool for human empowerment into an attention extraction machine.&lt;/p&gt;&lt;p&gt;Radiant proposes an alternative vision for computing. It doesn't ship with a web browser; it has its own network reminiscent of the early Internet: no social media, no scripts, no trackers. It's a from-scratch system that doesn't retrace the footsteps of the contemporary OS. It's a new paradigm for personal computing that uses modern advances mindfully and deliberately. It's fully open, from hardware to software. It's an offline-first space, designed for focus and creation.&lt;/p&gt;&lt;p&gt;Code is computing's native medium; the material you shape to build your own tools, stories, and spaces. Radiant is designed to make that accessible to everyone. It's a tool for personal computing where every application and every surface, exists as code you can read, edit, and extend. It's a system you can truly own. One that is designed to bring the joy of computing to everyone.&lt;/p&gt;&lt;p&gt;Writing software doesn't have to be daunting, but the platforms and tools we're stuck with make it so. Radiant aims to change that and truly empower users to create. Furthermore, advances in generative A.I. will make coding accessible to a much broader audience. One of our goals is to explore how an A.I.-native computer system can enhance the creative process, all while keeping data private.&lt;/p&gt;&lt;p&gt;Radiant belongs to a more humane future: a personal computer that welcomes curiosity, invites experimentation, and keeps the power in your hands. This is personal computing for the next generation.&lt;/p&gt;&lt;p&gt;Find out more about the Radiant system, or read our design principles and tenets.&lt;/p&gt;&lt;p&gt;Radiant is an ongoing research project in personal computing. If this resonates with you, write us at üìß letters@radiant.computer or follow us on ü¶ã Bluesky @radiant.computer.&lt;/p&gt;&lt;p&gt;You can learn more about Radiant by browsing our log or notes.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822559</guid><pubDate>Wed, 05 Nov 2025 13:22:35 +0000</pubDate></item><item><title>Why Your Best Engineers Are Interviewing Elsewhere, CodeGood</title><link>https://codegood.co/writing/why-your-best-engineers-are-interviewing-elsewhere</link><description>&lt;doc fingerprint="b46dd1152f246605"&gt;
  &lt;main&gt;
    &lt;p&gt;In 2018, a senior engineer at a $40M ARR SaaS company spent six months arguing that the proposed database architecture would not scale. Product wanted to ship fast. Engineering leadership agreed with him but did not push back on product. The decision was made: ship now, refactor later. He started interviewing that week. Not because of the technical decision√¢those happen. Because his judgment did not matter. Eight months later, the system had daily performance issues. Eighteen months later, the company had lost five senior engineers and hired a fractional CTO to diagnose why.&lt;/p&gt;
    &lt;p&gt;The diagnosis was straightforward: nobody at executive level had known engineers were unhappy until they resigned. Exit interviews cited "better opportunities" and "competitive compensation." The CEO approved 15% raises for remaining engineers. More left anyway. The real problem was not compensation. It was that information does not flow upward through organizational hierarchy, and by the time problems reach executive level, they have already metastasized into resignation decisions made months earlier.&lt;/p&gt;
    &lt;p&gt;Replacing those five engineers cost approximately $1.4 million in recruiting fees, lost productivity, and knowledge drain. The retention problem could have been solved for a fraction of that cost, but only if executives had known it existed. They did not, because junior engineers had told senior engineers, senior engineers had told managers, and managers had decided the information was not worth escalating. The executives were the last to know.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hierarchies filter bad news out&lt;/head&gt;
    &lt;p&gt;Organizations create hierarchies to manage complexity. The unintended consequence is that information gets filtered at each layer. A junior engineer mentions to a senior engineer that a technical decision seems problematic. The senior engineer tells the engineering manager. The manager decides whether this makes him look bad or is worth escalating. The VP of Engineering hears a filtered version, if anything. The CTO hears "we are handling it." The CEO hears "everything on track."&lt;/p&gt;
    &lt;p&gt;Each layer removes detail and urgency. By the time something reaches executive level, it is either a crisis or it has been filtered out entirely. The filtering is not malicious. Middle managers believe they are doing their jobs by "handling problems at their level." They see escalation as failure. They present solutions, not problems. This feels like professionalism but functions as information suppression.&lt;/p&gt;
    &lt;p&gt;A software company with 120 engineers provides a useful example. The frontend team identified performance issues with the new dashboard in March. By April, engineers were discussing it openly in code reviews. The engineering manager knew by May and began investigating solutions. The VP of Engineering heard about it in June, framed as "we are optimizing dashboard performance." The CTO learned in July that "some performance work" was happening. In August, the company's largest customer complained that the dashboard was unusable. The executive team treated this as a sudden crisis requiring emergency response. Engineers had known for five months.&lt;/p&gt;
    &lt;p&gt;The result is that the people making resource allocation decisions operate on information that is months out of date and systematically scrubbed of bad news. Engineers know the database will not scale in August. Managers know engineers are frustrated in October. VPs know there is a morale issue in December. The CTO learns engineers are resigning in February. Each group thought they were handling the problem appropriately. None realized they were creating information latency that made the problem unsolvable.&lt;/p&gt;
    &lt;head rend="h2"&gt;The convenient fiction of chain of command&lt;/head&gt;
    &lt;p&gt;Many organizations treat skip-level conversations√¢executives talking directly to engineers several levels down√¢as inappropriate. The objections are consistent: it undermines middle management authority, breaks chain of command, creates perception of distrust, or represents micromanagement. These concerns are presented as organizational health considerations. They are actually organizational antibodies protecting middle management from accountability.&lt;/p&gt;
    &lt;p&gt;A CTO who talks directly to junior engineers hears what is actually happening. A CTO who relies on filtered reports hears what management wants them to hear. The taboo against skip-levels ensures the latter. Middle managers prefer this arrangement because it gives them control over information flow. They can present problems they have solved and suppress problems that reflect poorly on them. The organization pays for this preference through information latency that turns small problems into crises.&lt;/p&gt;
    &lt;p&gt;The economic argument against skip-levels is that executive time is expensive and should focus on strategic matters, not tactical details. This logic fails when strategic decisions are based on systematically wrong information. A CTO who spends several hours per week talking to engineers across all levels learns what is actually broken, what is actually blocking productivity, and which engineers are mentally checking out. This information has direct strategic value. It reveals where to allocate resources, which managers are effective, and which technical bets are failing. The alternative√¢relying on reports that have been filtered through three or four layers√¢is cheaper per hour and more expensive per bad decision.&lt;/p&gt;
    &lt;p&gt;The time investment need not be enormous. Allocating several hours per week (the specific amount matters less than the consistency) for direct conversations across levels provides ground truth. As organizations grow, the frequency per person decreases but the coverage remains. A CTO might talk to each engineer once per quarter rather than once per month. This maintains connection to reality without consuming the executive calendar. The engineers who get these conversations tell you things they would never tell their manager. You hear problems three to six months earlier than you would through proper channels. Early warning makes intervention cheaper.&lt;/p&gt;
    &lt;p&gt;A payments company discovered this after losing three senior engineers in a quarter. The new CTO instituted weekly office hours where any engineer could book 30 minutes. No agenda required, no manager approval needed. The first month revealed that the deployment system was so unreliable that engineers avoided deploying on Fridays, fearing weekend pages. The monitoring system generated so many false alerts that engineers had learned to ignore it. The API documentation was so outdated that new engineers spent their first month learning the system through trial and error rather than documentation. None of this had reached executive level through normal channels because each manager thought they were handling it. The CTO allocated budget to fix all three problems within the quarter. Six months later, voluntary attrition had dropped to near zero.&lt;/p&gt;
    &lt;head rend="h2"&gt;Agency, not salary&lt;/head&gt;
    &lt;p&gt;Engineers leave for reasons that exit interviews systematically misidentify. Compensation gets cited because it is measurable and socially acceptable. The actual reasons are harder to articulate and potentially awkward. Three patterns appear repeatedly.&lt;/p&gt;
    &lt;p&gt;Loss of agency. Engineers are told to build systems they know will fail. Technical judgment is consistently overruled for non-technical reasons. They watch decisions being made that will cause problems, they raise concerns, and they are told to implement anyway. When the predicted failure occurs, they are blamed for not preventing it. This is not about ego or engineers wanting to be in charge. It is about being asked for expert judgment and then having that judgment ignored.&lt;/p&gt;
    &lt;p&gt;A fintech company decided to build their own authentication system rather than use established solutions. Senior engineers argued this was unnecessary risk for a non-differentiating feature. Product management insisted on custom implementation to support specific user flows. Engineering leadership agreed with the seniors but did not push back. The custom authentication system shipped with three security vulnerabilities in the first month, required emergency patches, and consumed six months of engineering time that could have gone to revenue-generating features. The senior engineer who had argued against it started interviewing the week the decision was finalized. He did not wait for the failures he knew were coming.&lt;/p&gt;
    &lt;p&gt;The economic cost is wasted implementation time plus ongoing maintenance burden plus engineer disengagement. The company spent $180,000 building something that could have been bought for $12,000 annually. The engineer they lost would have built features that generated an estimated $400,000 in annual recurring revenue based on product roadmap priorities. The decision to override his judgment cost approximately $580,000 in the first year alone, not counting the cost of replacing him.&lt;/p&gt;
    &lt;p&gt;Technical debt becomes unpayable. The team identifies critical infrastructure work: the database needs replication, the deployment system needs automation, the monitoring needs improvement. These get deprioritized quarter after quarter behind feature work. Engineers watch the system strain under load, knowing exactly what is coming and when it will break. When it fails, they are asked why they did not prevent it. They stopped arguing for the infrastructure work after it was deprioritized the third time. They leave before the inevitable crisis because they do not want to be blamed for a failure they predicted and were prevented from fixing.&lt;/p&gt;
    &lt;p&gt;An e-commerce company deferred database infrastructure work for eighteen months. Engineers requested budget to implement read replicas and improve query performance. Each quarter, feature development took priority. Load increased 40% annually while infrastructure remained static. In month 19, the database became the bottleneck for the entire platform. Response times degraded from 200 milliseconds to 4 seconds during peak hours. Revenue declined as conversion rates dropped. The company spent $240,000 on emergency infrastructure upgrades and lost an estimated $1.2 million in revenue during the degraded performance period. Two of the three senior engineers who had requested the infrastructure work had already left. They had correctly predicted the failure timeline and did not want to be present for the crisis.&lt;/p&gt;
    &lt;p&gt;Smart people forced to do stupid work. Senior engineers earning $180,000 annually are assigned to maintain systems that should be deprecated. Busy work is prioritized over meaningful problems. Process theatre consumes time: estimation ceremonies that produce numbers no one believes, architecture reviews that change nothing, documentation that no one reads. The economic waste is paying premium rates for work that could be done at half the cost, while burning out senior talent on tasks beneath their capability. They leave to find work that uses what they are good at.&lt;/p&gt;
    &lt;p&gt;A SaaS company had a reporting system built six years earlier that served twelve customers generating $80,000 annual revenue. The system required constant maintenance due to technical debt. A senior engineer earning $190,000 annually spent approximately 60% of her time maintaining this system. The company was effectively paying $114,000 per year to support $80,000 in revenue. When she proposed deprecating the system and migrating the twelve customers to the new platform, she was told those customers were "strategic relationships" that required continued support. She left three months later. Her replacement cost $220,000 to recruit and onboard. The company could have migrated all twelve customers for approximately $40,000 and freed her to work on the core product.&lt;/p&gt;
    &lt;head rend="h2"&gt;The early signals executives miss&lt;/head&gt;
    &lt;p&gt;The warning signs exist months before resignation but appear at different organizational levels at different times. Executives typically see only the final stage, when intervention is no longer possible.&lt;/p&gt;
    &lt;p&gt;What junior and mid-level engineers see first (six to twelve months before senior engineers leave). Senior engineers stop fighting for technical decisions. Architecture reviews become rubber stamps. "We tried that, leadership said no" becomes a common response. The technical debt backlog grows with no allocation. Junior engineers notice because they are the ones implementing the decisions that senior engineers stopped arguing against. They see the seniors quietly disengaging.&lt;/p&gt;
    &lt;p&gt;A junior engineer at a logistics company observed this pattern over six months. The senior architect who had previously written detailed code review comments began approving everything with "LGTM" (looks good to me). In architecture discussions, he stopped proposing alternatives and simply agreed with whatever product wanted. When the junior asked him privately why, the senior said "I have learned that my opinion does not change outcomes, so I am saving time by not giving it." The junior realized the senior was leaving before the senior had even started interviewing. Three months later, the resignation came. It surprised management completely.&lt;/p&gt;
    &lt;p&gt;What senior engineers experience (four to eight months before they leave). Pattern recognition: this is going to fail and leadership will not listen. Moral injury: being forced to build what you know is wrong. Loss of faith: my expertise does not matter here. They stop arguing in meetings, start rubber-stamping technical decisions, reduce code review commentary from detailed to perfunctory. This often looks like maturity to executives√¢they are not arguing as much, they seem more aligned. It is actually resignation.&lt;/p&gt;
    &lt;p&gt;The behavioral change is visible to anyone who works closely with the engineer but often goes unremarked because it reduces friction. A senior engineer who previously pushed back on unrealistic timelines and questioned technical approaches becomes agreeable. Product managers are pleased. Engineering managers interpret this as the engineer becoming a better team player. The engineer has actually checked out mentally and is conserving energy for interviewing. They have concluded that arguing is pointless and are simply executing instructions while they look for exit.&lt;/p&gt;
    &lt;p&gt;What managers see (two to four months before resignation). Changed behavior in one-on-ones. Less engagement in team discussions. The engineer updates their LinkedIn profile, attends more industry events, documents their work more thoroughly than before, and trains junior engineers on their systems. Managers often do not escalate this because high attrition reflects poorly on their management. They hope to solve it quietly. By the time it becomes obvious, the engineer has offers.&lt;/p&gt;
    &lt;p&gt;An engineering manager at a media company noticed one of his senior engineers had started documenting everything: architecture decisions, deployment procedures, system quirks. The manager thought this was positive√¢finally, the tribal knowledge was being captured. What he missed was the motivation. Engineers typically document thoroughly when they are leaving and feel guilty about the knowledge gap they will create. The documentation is part of their mental transition out. The manager realized this only in retrospect, during the exit interview.&lt;/p&gt;
    &lt;p&gt;What executives see (zero to one month before resignation). "Sarah gave notice." Complete surprise. But the information existed all along at lower levels. It simply did not flow upward because the organization's information architecture filters bad news out of executive visibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why one departure becomes five&lt;/head&gt;
    &lt;p&gt;One departure is a data point. Three is a pattern that remaining engineers notice. If Sarah is leaving, maybe I should look too. Engineers assume departing colleagues know something they do not. This assumption is often correct. The departing engineer has concluded the situation is not fixable and has already explored alternatives. The engineers remaining consider whether they are missing something.&lt;/p&gt;
    &lt;p&gt;External recruiters notice the pattern. LinkedIn activity increases from the team. Multiple engineers from the same company appear in recruiter searches. Outreach intensifies. A retention problem becomes a recruitment problem. Engineers who were not previously considering leaving begin taking calls. Some discover opportunities they find attractive. The rate of departures accelerates.&lt;/p&gt;
    &lt;p&gt;A cloud infrastructure company lost two senior engineers within three weeks. Over the following three months, five more engineers left. Post-mortems revealed that the first two departures triggered widespread questioning. Engineers asked: "Why are they leaving? Do they know something about the company's financial health we don't?" The reality was that the first two had left for the reasons described earlier√¢loss of agency and technical debt. But their departures created information uncertainty that recruiters exploited. The cascade cost approximately $2.2 million in replacement costs and delayed three major product initiatives by a combined eight months.&lt;/p&gt;
    &lt;p&gt;The knowledge drain is expensive in ways that are difficult to quantify but appear as mistakes over the following quarters. The senior engineer who left knew which three lines of code were critical and which 3,000 could be deleted. Knew which customers had special requirements and why. Knew which systems were stable-but-ugly versus actually broken. This knowledge leaves with them and gets rediscovered through expensive mistakes: deleted code that should not have been touched, customer workflows that break, technical debt that turns out to have been load-bearing.&lt;/p&gt;
    &lt;p&gt;A payments company discovered this six months after losing a senior engineer who had built their reconciliation system. The engineer had never documented that certain transaction types required special handling due to a quirk in one payment processor's API. The quirk was not mentioned in the processor's documentation; the engineer had discovered it through trial and error three years earlier. When a new engineer modified the reconciliation logic, transactions from that processor started failing. The company spent two weeks debugging, ultimately discovering the undocumented quirk through support tickets with the processor. Those two weeks cost approximately $45,000 in engineering time and caused $180,000 in failed transactions that required manual reconciliation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sometimes it really is the money&lt;/head&gt;
    &lt;p&gt;Compensation is a real factor in some resignations. The signal is timing. If an engineer raises compensation concerns directly before job searching, and their compensation is genuinely below market for their scope, it is a compensation problem. If they cite compensation only when pressed during exit discussion, it is probably not. They were already looking for other reasons and found an offer that provided justification.&lt;/p&gt;
    &lt;p&gt;Legitimate compensation issues have patterns. The engineer is significantly below market for their actual scope. They are watching junior engineers hired at their salary. Their compensation has not adjusted for expanded responsibility. Critically, they bring this up directly before job searching. "I believe I am underpaid relative to market. Can we discuss this?" This is a compensation problem that can be solved with a compensation solution.&lt;/p&gt;
    &lt;p&gt;Compensation as excuse is different. The engineer has been interviewing for months, receives an offer for 30% more, and cites market rates during exit discussion. When pressed about whether a matching offer would keep them, they are noncommittal. "I will consider it, but I have already accepted the other role." In these cases, compensation was not the motivating factor. It was the justification factor. The engineer had already decided to leave for the reasons described earlier but uses compensation as the socially acceptable explanation.&lt;/p&gt;
    &lt;p&gt;The test: would a 20% raise keep them? If yes, it is compensation. If no, it is something else and they are being diplomatic. Most engineers who leave for loss of agency, unpayable technical debt, or meaningless work cannot be retained with money alone. They have concluded the work environment is broken. Compensation becomes the explanation because "I am leaving for more money" is easier than "I am leaving because my judgment does not matter and I am tired of building things I know will fail."&lt;/p&gt;
    &lt;p&gt;A developer tools company learned this distinction after conducting thorough exit interviews with departing engineers. Of the eight engineers who left citing compensation, the company made counter-offers to five (the ones they most wanted to retain). Three declined the counter-offers despite the offers matching or exceeding their new roles. Follow-up conversations revealed that compensation had not been their real concern. They were leaving because the product roadmap kept pivoting, making their work feel pointless. They cited compensation in exit interviews because it was easier than explaining that they did not believe in the company's direction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prevention beats retention bonuses&lt;/head&gt;
    &lt;p&gt;Early-stage intervention requires executives to hear about problems before they progress to mental resignation. This means creating information channels that bypass the filtering hierarchy. Several approaches work.&lt;/p&gt;
    &lt;p&gt;Regular skip-level conversations. Allocating several hours per week for direct conversations across all levels provides ground truth. The time commitment need not be enormous. Consistency matters more than frequency. As organizations grow, talk to each person less frequently but maintain coverage. Engineers who get these conversations tell you things they would never tell their manager: what is actually blocking productivity, which technical decisions are causing problems, where morale is declining.&lt;/p&gt;
    &lt;p&gt;A chief technology officer I advised at a 100-person engineering organization allocated four hours per week for skip-level conversations. With two-week rotation and 30-minute sessions, this covered approximately almost thirty engineers per month, or the entire org across seven months. The engineers knew the CTO slot was available and could book it when they needed it. This created two-way information flow: the CTO heard ground truth, and engineers felt heard. Retention improved measurably. Voluntary attrition declined from 18% annually to 7% annually after implementing this practice. The CTO attributed the improvement directly to early problem identification. "I hear about issues when they are small and fixable. Previously, I heard about them when they were resignation letters."&lt;/p&gt;
    &lt;p&gt;External diagnostic perspective. Engineers will be more honest with someone who has no authority over their career. A fractional CTO or external advisor conducting interviews across levels hears what people actually think, not what they tell management. This is not because internal executives cannot ask the same questions. It is because the answers will be different when given to someone who is temporary, not threatening, and has no stake in protecting management reputation.&lt;/p&gt;
    &lt;p&gt;A SaaS company brought in a fractional CTO after losing four senior engineers in six months. The fractional CTO spent two weeks interviewing engineers at all levels. The finding: engineers felt the architecture review process was theater. Proposals would be approved after incorporating feedback from multiple stakeholders, then overridden by product decisions weeks later. Engineers concluded that the architecture review process existed to distribute blame, not to make decisions. They spent hours preparing for reviews that changed nothing. The company eliminated the architecture review process and gave engineering veto authority on technical implementations. The value was diagnostic: identifying actual problems versus officially acknowledged problems.&lt;/p&gt;
    &lt;p&gt;Action on at least one thing. Hearing problems is insufficient. Engineers need to see that raising concerns produces outcomes. When an engineer mentions that the deployment system is brittle, and the deployment system gets fixed within the quarter, that engineer learns that their input matters. When an engineer mentions the same problem repeatedly and nothing changes, they learn the opposite.&lt;/p&gt;
    &lt;p&gt;A developer at a healthcare technology company mentioned to the CTO during a skip-level that the test suite took 45 minutes to run, making development slow. The CTO asked why this had not been fixed. The developer said it had been raised with management multiple times but always deprioritized. The CTO allocated budget that week for the developer to spend two weeks optimizing the test suite. Runtime dropped to eight minutes. The developer told three colleagues about the experience. Those colleagues started booking skip-level sessions to raise other issues. The investment was $12,000 in engineering time. The signal sent was: your input produces action. This is worth significantly more than $12,000 in retention value.&lt;/p&gt;
    &lt;head rend="h2"&gt;The $1.4m misdiagnosis&lt;/head&gt;
    &lt;p&gt;The cost of getting retention wrong is measurable. Replacing a senior engineer costs $200-280K in direct expenses: recruiting fees (typically 20-25% of salary), sign-on bonuses, and relocation if applicable. Productivity loss during vacancy is $40-75K, assuming three to six months to hire at $150K annual productivity loss. Onboarding productivity drag is $35-40K, assuming the new hire operates at 50% effectiveness for six months. Knowledge loss is harder to quantify but appears as mistakes, slower decisions, and repeated work over subsequent quarters. Conservative total per senior engineer: $275-395K. For five engineers: $1.4-2.0M.&lt;/p&gt;
    &lt;p&gt;The cost of getting retention right is smaller but requires organizational change. Fixing actual problems means changing roadmap priorities, removing process, or giving engineers technical veto on architecture decisions. The costs are opportunity cost of deprioritized features and political capital spent overriding middle management. These costs are real but much smaller than replacement costs.&lt;/p&gt;
    &lt;p&gt;The barrier is not cost. It is admission that something is broken and that management may have contributed to the problem. Organizations prefer to believe the problem is market competition for talent because that explanation does not require internal change. "Engineers are expensive and competitive" is easier than "our decision-making processes systematically ignore technical expertise and our information architecture prevents executives from learning about problems until they become crises."&lt;/p&gt;
    &lt;p&gt;A Series B company lost seven engineers over eighteen months. The CEO believed this was market-driven: competitors were paying more, the company could not match offers, retention was a losing battle. A post-mortem analysis revealed different story. Five of the seven had raised specific concerns about technical decisions, process overhead, or project prioritization in the six months before leaving. None of those concerns had reached executive level. The concerns had been captured in one-on-ones with managers, flagged as "monitored," and never escalated. The executives had operated on the assumption that retention was about compensation. The engineers had operated on the conclusion that their concerns did not matter. Both groups were systematically misinformed about what the other cared about.&lt;/p&gt;
    &lt;head rend="h2"&gt;Information is cheaper than replacement&lt;/head&gt;
    &lt;p&gt;The engineers leaving know something executives do not. They know which technical decisions are failing, which processes waste time, and which management practices create disengagement. This information exists within the organization but does not reach executive level through normal channels because hierarchies filter information and middle management has incentive to suppress bad news.&lt;/p&gt;
    &lt;p&gt;The question is whether executives will learn what is broken from engineers before they leave, or from the problems those engineers would have prevented. The organizations that get this right treat information flow as a strategic priority. They create skip-level channels that bypass filters. They recognize that executive time spent hearing ground truth has higher ROI than executive time spent on strategy based on filtered information. They understand that retention is cheaper than replacement, but only if problems are visible early enough to fix.&lt;/p&gt;
    &lt;p&gt;The organizations that get this wrong optimize for management comfort over information accuracy. They treat skip-levels as inappropriate, rely on reports that have been systematically scrubbed of bad news, and learn about retention problems when resignation letters arrive. They spend millions replacing engineers who could have been retained for thousands, and they never quite understand why their best people keep leaving.&lt;/p&gt;
    &lt;p&gt;The calculation is straightforward. Allocating several hours per week for direct conversations with engineers costs perhaps $50,000 annually in executive time. This prevents one senior engineer departure, the intervention pays for itself five times over. In practice, it prevents multiple departures and provides information that improves resource allocation across the organization. The alternative√¢learning about problems through resignation letters√¢is cheaper per hour and catastrophically more expensive per outcome.&lt;/p&gt;
    &lt;p&gt;The senior engineer who left in 2018 is still in the industry. He now works at a company where the CTO maintains regular skip-levels and engineering has veto authority on technical architecture. He is not interviewing. Neither are his colleagues. The company has 12% voluntary attrition, less than half the industry average for companies at their stage. Their executives know what is broken before it becomes unfixable. They learned this through simple mechanism: they ask, and people tell them, because the organizational structure allows information to flow upward without being filtered out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822650</guid><pubDate>Wed, 05 Nov 2025 13:33:53 +0000</pubDate></item><item><title>Microsoft Can't Keep EU Data Safe from US Authorities</title><link>https://www.forbes.com/sites/emmawoollacott/2025/07/22/microsoft-cant-keep-eu-data-safe-from-us-authorities/</link><description>&lt;doc fingerprint="3f1a0016b62c5443"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft has admitted that it can't protect EU data from U.S. snooping.&lt;/p&gt;
    &lt;p&gt;In sworn testimony before a French Senate inquiry into the role of public procurement in promoting digital sovereignty, Anton Carniaux, Microsoft France's director of public and legal affairs, was asked whether he could guarantee that French citizen data would never be transmitted to U.S. authorities without explicit French authorization. And, he replied, "No, I cannot guarantee it."&lt;/p&gt;
    &lt;p&gt;He said that the company resisted requests from the US authorities "when they are not well-founded", but that under the U.S. Cloud Act, U.S. companies can be forced to hand over data, regardless of where it is stored.&lt;/p&gt;
    &lt;p&gt;Carniaux did say that the situation had never arisen. However, the admission raises serious concerns around European data sovereignty.&lt;/p&gt;
    &lt;p&gt;‚ÄúMicrosoft has openly admitted what many have long known: under laws like the Cloud Act, US authorities can compel access to data held by American cloud providers, regardless of where that data physically resides. UK or EU servers make no difference when jurisdiction lies elsewhere, and local subsidiaries or ‚Äòtrusted‚Äô partnerships don‚Äôt change that reality," commented Mark Boost, CEO of cloud provider Civo.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis is more than a technicality. It is a real-world issue that can impact national security, personal privacy and business competitiveness."&lt;/p&gt;
    &lt;p&gt;The inquiry centers around Project Bleu - a partnership between Microsoft, Orange and Capgemini. There were concerns about the Health Data Hub medical research platform, which is hosted on Microsoft Azure. Senate members said they couldn't be sure that the two platforms were sufficiently separated, and that sensitive health data wouldn't be shared.&lt;/p&gt;
    &lt;p&gt;Carniaux's admission will increase concerns that the EU can't afford to be reliant on the big U.S. cloud providers such as Microsoft and AWS - even when they claim to be offering sovereign cloud services.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe French Senate has set a precedent by demanding answers, and the UK and Europe have an opportunity to do the same," said Boost. "We‚Äôre already seeing a shift towards building homegrown solutions that support true data sovereignty rather than data residency."&lt;/p&gt;
    &lt;p&gt;However, a recent European Parliament report found that U.S. firms account for 69% of the cloud infrastructure market share in Europe, while EU suppliers hold only 13%.&lt;/p&gt;
    &lt;p/&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822902</guid><pubDate>Wed, 05 Nov 2025 14:00:41 +0000</pubDate></item><item><title>A P2P Vision for QUIC (2024)</title><link>https://seemann.io/posts/2024-10-26---p2p-quic/</link><description>&lt;doc fingerprint="23b498505021acb9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A p2p Vision for QUIC&lt;/head&gt;
    &lt;p&gt;This article was co-authored by Christian Huitema. You can find his blog at privateoctopus.com.&lt;/p&gt;
    &lt;p&gt;Over the years, the IETF has standardized numerous protocols for establishing IP packet flows through NATs and firewalls, including STUN, ICE, and TURN.&lt;/p&gt;
    &lt;p&gt;This is an inherently messy topic, and I can highly recommend reading Eric Rescorla‚Äôs blog post series about NATs (part 1, part 2, part 3). I won‚Äôt go into details about how exactly NATs work (again, read the ekr‚Äôs blog posts!), but in a nutshell, they rewrite the IP of packets passing through the NAT.&lt;/p&gt;
    &lt;p&gt;(192.168.1.10) participant NAT as NAT&lt;/p&gt;
    &lt;p&gt;(203.0.113.5) participant Server as Server&lt;/p&gt;
    &lt;p&gt;(198.51.100.20) Client-&amp;gt;&amp;gt;NAT: Packet (Src: 192.168.1.10:1234) NAT-&amp;gt;&amp;gt;Server: Packet (Src: 203.0.113.5:4321) Server--&amp;gt;&amp;gt;NAT: Response (Dst: 203.0.113.5:4321) NAT--&amp;gt;&amp;gt;Client: Response (Dst: 192.168.1.10:1234)&lt;/p&gt;
    &lt;p&gt;This allows multiple clients behind that NAT to share the same external IP address. Clients are able to reach any server on the internet, but it doesn‚Äôt allow nodes on the internet to reach the client, since the NAT won‚Äôt forward packets to the client, unless it determines that they belong to an existing flow. In that sense, the NAT acts as a firewall.&lt;/p&gt;
    &lt;p&gt;Although simple in theory, there are a lot of different ways to implement a NAT. For our purposes, the main difference lies in how the port numbers for the outgoing packets are allocated. Depending on the port allocation logic, it might or might not possible to establish a direct connection between two peers.&lt;/p&gt;
    &lt;p&gt;The problem that p2p network engineers hope to solve is the following: How can two nodes that are both behind a NAT, respectively, connect to each other, no matter the kind of NAT?&lt;/p&gt;
    &lt;p&gt;In this post, we explore how QUIC can be leveraged to provide a comprehensive solution for NAT traversal, encompassing everything from address discovery to UDP proxying, potentially simplifying and improving upon traditional p2p networking approaches.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Traditional Way&lt;/head&gt;
    &lt;head rend="h3"&gt;Address Discovery using STUN&lt;/head&gt;
    &lt;p&gt;Depending on the deployment scenario, a new node joining the network might or might not know its (public) IP address. Traditionally, applications use STUN (RFC 8489) to discover their public IP address. In a nutshell, a STUN client sends a ‚ÄúBinding Request‚Äù to a STUN server. The ‚ÄúBinding Response‚Äù of the server encodes the IP source address and the source port that the server observed on the client‚Äôs request.&lt;/p&gt;
    &lt;p&gt;The client can infer from the responses to the STUN requests if it is located behind a NAT. The client might even compare responses from different STUN servers and attempt to infer the type of NAT, although this is notoriously difficult to get right. The IETF has pretty much given up on this approach (see section 2 of RFC 5389).&lt;/p&gt;
    &lt;p&gt;The STUN protocol can run over UDP, TCP, DTLS (RFC 7350) or TLS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hole Punching Coordination using ICE&lt;/head&gt;
    &lt;p&gt;As we‚Äôve seen above, once the NAT has seen the first packet to a remote server pass through, the NAT opens up the return path, allowing packets from the outside world to reach the node. The idea behind hole punching is to have both peers send packets simultaneously, each of them ‚Äúpunching‚Äù a hole in their respective firewall, establishing a direct flow of packets between the two nodes.&lt;/p&gt;
    &lt;p&gt;The traditional hole punching process is specified by ICE RFC 8445. ICE starts with an address gathering phase, in which the two peers separately contact STUN servers to obtain lists of candidate IP addresses and ports. They may add to that list a set of TURN addresses (see next section, ‚Äúrelaying‚Äù).&lt;/p&gt;
    &lt;p&gt;One of the endpoints creates a list of available addresses, ordered by priority, and sends it to its peer. The peer compares that to its own list, establishes a list of ‚Äúcandidate pairs‚Äù, and sends it back. At that point, both endpoints have the same list of candidate pairs, and start the ‚Äúconnectivity‚Äù check. Each host will try to send a STUN binding request from its selected address to the paired address, and respond to STUN requests that it might receive from the peer. If at least one of these trials succeeds, the peers have established a new connection over this address pair. If several succeed, they keep the preferred pair.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relaying using TURN&lt;/head&gt;
    &lt;p&gt;Unfortunately, no matter how hard you try, there is a certain percentage of nodes for whom hole punching will never work. This is because their NAT behaves in an unpredictable way. While most NATs are well-behaved, some aren‚Äôt. This is one of the sad facts of life that network engineers have to deal with.&lt;/p&gt;
    &lt;p&gt;The only solution for this problem is to employ the help of a third party, i.e. a server that is not located behind a NAT, and therefore can be reached by peers directly, without any hole punching. This server can then relay traffic between the two peers.&lt;/p&gt;
    &lt;p&gt;Of course, this comes at a cost. The path via the relay might be slower (in terms of latency and / or bandwidth) than a (hypothetical) direct path would have been. And relaying traffic is not for free for the operator of the relay: both processing resources as well as bandwidth cost money. However, we don‚Äôt really have a choice here, and despite these shortcomings, having a relayed connection might be preferable to having no connectivity at all.&lt;/p&gt;
    &lt;p&gt;The traditional solution relies on TURN servers, specified in RFC 5766 to provide these ‚Äúlast resort‚Äù connectivity. The node behind a NAT can ask the TURN server to open an UDP or TCP port. This ‚ÄúTURN Port‚Äù is usually specialized: the client specifies the address of the peer that will be able to send data to that port, or to which data will be sent. The corresponding IP address and port number will be sent to the peer, and will be the basis for some last resort ‚Äúcandidate pairs‚Äù used in the coordinated hole punching.&lt;/p&gt;
    &lt;p&gt;The previous section mentioned that in some cases more than one tried address pair will succeed. This is particularly true for the pairs that include a TURN provided address. This is why the trials will try to collect all the working pairs and pick the higher priority one. If both a ‚Äúhole punching‚Äù and a ‚ÄúTURN‚Äù pair succeed, they will typically only retain the ‚Äúhole punching‚Äù pair.&lt;/p&gt;
    &lt;head rend="h2"&gt;The QUIC Way&lt;/head&gt;
    &lt;head rend="h3"&gt;QUIC Connection Migration&lt;/head&gt;
    &lt;p&gt;RFC 9000 defines how clients can migrate an existing QUIC connection to a different IP:port tuple. When we designed this mechanism, the primary use case we envisioned was solving the ‚Äúparking lot problem‚Äù. Imagine you have a mobile phone, and you walk from your office (where the phone has WiFi) to the parking lot (with no / bad WiFi coverage). In this case, the client could detect that the WiFi connection is worsening, and migrate the connection to its cellular interface. Crucially, this would keep all connection state (e.g. open streams, datagram flows, etc.) intact, and would therefore be transparent to the application.&lt;/p&gt;
    &lt;p&gt;On detecting a network interface change, e.g. leaving the office, QUIC Path Migration works by first sending a so-called probing packet to the server. The purpose of this packet is to probe if the path actually works. The client includes a PATH_CHALLENGE frame in this packet, to which the server responds with a PATH_RESPONSE frame. This makes sure that the new path actually works (for example, that the path doesn‚Äôt block UDP packets), and supports QUIC (for example, allows packets that satisfy QUIC‚Äôs MTU requirements).&lt;/p&gt;
    &lt;p&gt;On the wire, this path probing procedure looks pretty similar to a hole punch attempt. We just need a tiny modification to make this work in the p2p use case: If we could get the server to send probe packets as well, we could kill two birds with one stone: We‚Äôd punch a hole through the firewall, and at the same time verify connectivity on the path.&lt;/p&gt;
    &lt;p&gt;Of course this is not the only thing needed to achieve hole punching. Before the nodes can even send probe packets, we need to learn about the peer‚Äôs reflexive address, and be able to coordinate the timing. We‚Äôll come to this in a bit, but first we‚Äôll describe how we can replace STUN to discover our reflexive addresses.&lt;/p&gt;
    &lt;head rend="h3"&gt;QUIC Address Discovery&lt;/head&gt;
    &lt;p&gt;Typically nodes use STUN to discover their reflexive addresses. In essence, STUN is a request-response protocol here, where the client requests the server to report the observed address of the request packet.&lt;/p&gt;
    &lt;p&gt;In principle, we could achieve the same inside of a QUIC connection: The server could report the address of the client using, for example, a newly defined QUIC frame, and vice versa. This is exactly what the QUIC Address Discovery draft specifies.&lt;/p&gt;
    &lt;p&gt;The mechanism is really simple: every time a new path is established (incl. the path used for the handshake), endpoints inform each other of the observed address. This is a very efficient mechanism: Since the OBSERVED_ADDRESS frame is defined as a probing frame, it can be bundled with the PATH_CHALLENGE and PATH_RESPONSE frames used to probe a new path.&lt;/p&gt;
    &lt;p&gt;Performing address discovery over QUIC comes with multiple advantages:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;QUIC packets are encrypted. An observer is not able to observe the exchange of OBSERVED_ADDRESS frames, nor interfere with this exchange (e.g. by tampering with the frame contents).&lt;/item&gt;
      &lt;item&gt;It doesn‚Äôt require running any additional services (i.e. a STUN server / client). It‚Äôs sufficient to enable the Address Discovery extension on a large enough number of nodes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, in either case the client has to trust that the server is sending honest responses. A misbehaving server could respond with spoofed addresses, causing the ‚Äúhole punching‚Äù packets to later be sent to these addresses. This is not hard to defend against: Clients can obtain some protection against such attacks by contacting several servers and comparing their responses.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hole Punching Coordination&lt;/head&gt;
    &lt;p&gt;The node has now learned its reflexive addresses, and we know how to use QUIC‚Äôs connection migration mechanism to establish the NAT port mappings required to allow the establishment of a direct path. We now want to establish a connection to another node, behind its respective NAT.For the moment, we‚Äôll assume that the two nodes are able to communicate via a (proxied) QUIC connection. We‚Äôll see how this works in detail in the next section. The only thing that matters for now is that the nodes are able to communicate with each other.&lt;/p&gt;
    &lt;p&gt;The NAT traversal draft defines how two nodes can negotiate hole punching attempts with each other. Out of convenience, the process is driven almost entirely by the client (i.e. the node that initiated the QUIC connection). This is not because the roles of the peers are fundamentally different (they are both peers in the same p2p network), but it leads to significant simplifications of the protocol. It also reduces the difference to RFC 9000, where connection migration can only be initiated by the client.&lt;/p&gt;
    &lt;p&gt;The server informs the clients about its reflexive address using ADD_ADDRESS frames. Multiple ADD_ADDRESS frames can be sent if the server has multiple reflexive addresses.&lt;/p&gt;
    &lt;p&gt;The ICE RFC goes into great detail on how to form candidate pairs from both nodes‚Äô reflexive addresses, because both nodes need to agree on the ordering of the candidate pairs. Since the client is driving this process, we don‚Äôt need to specify any address matching logic that client and server would need to agree on.&lt;/p&gt;
    &lt;p&gt;Once the client has formed address pairs (and once it feels like it‚Äôs the right time to start a hole punch attempt), it sends a PUNCH_ME_NOW frame to the server. The PUNCH_ME_NOW contains both the client‚Äôs and the server‚Äôs reflexive addresses.&lt;/p&gt;
    &lt;p&gt;Immediately after sending the PUNCH_ME_NOW frame, the client starts path probing on the path formed by these two addresses. Equivalently, as soon as the server receives the PUNCH_ME_NOW frame, it starts path probing the path from its end. Timing is crucial here: As we‚Äôve seen above, the path probing packets create the NAT binding required to allow the other side‚Äôs packets to make it through the NAT.&lt;/p&gt;
    &lt;p&gt;Both the client and the server will send PATH_CHALLENGE frames on a new path when sending or responding to &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt;. They will need to allocate a yet unused Connection ID to the new path that they
are trying to establish. This implies that the number of parallel attempts is limited by the number of available Connection ID. This has both upsides and downside. On the one hand, having a limit reduces the amount of resource that a peer can be forced to consume, which makes the protocol more stable.
On the other hand, if the limits are reached, the next attempt will only be possible after one of the previous challenges has been abandoned, and the peer has provided a replacement Connection ID. This might be a slow process.&lt;/p&gt;
    &lt;p&gt;Whether that process is too slow is debatable. Endpoints that plan to engage in p2p hole punching may be configured to provide a number of Connection IDs sufficient for most practical attempts. Also, the initial path will be available until the migration succeeds, which means the application endpoints do not need to wait the success of the negotiation to start exchanging data.&lt;/p&gt;
    &lt;p&gt;Adding new QUIC frames like &lt;code&gt;ADD_ADDRESS&lt;/code&gt; or &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt; is somewhat controversial. Misbehaving peers could send spoofed addresses in these frames, causing the peer to send hole punching packets to third parties. This is similar to the request forgery attacks described in the security section of RFC 9000, and calls at least for the same kind of defenses. This is something we will keep in mind when evolving the NAT traversal draft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relaying UDP packets over HTTP&lt;/head&gt;
    &lt;p&gt;RFC 9298 defines how UDP packets can be proxied in HTTP. The exchange starts a regular HTTP request: The client sends a so-called Extended CONNECT request to the proxy on a QUIC stream, instructing the proxy to open a UDP socket and proxy a flow of UDP packets to a target server.&lt;/p&gt;
    &lt;p&gt;Once the proxy has accepted the proxying request, UDP packets are sent in HTTP Datagrams (RFC 9297), which themselves are a thin wrapper around QUIC DATAGRAM frames. QUIC Datagrams are a new QUIC frame defined in RFC 9221, which are sent in QUIC packets exchanged after completion of the QUIC handshake. They‚Äôre therefore encrypted the same way that any other data exchanged over the QUIC connection is. However, if a packet containing a DATAGRAM is lost, the DATAGRAM frame is not retransmitted. This makes DATAGRAMs suitable to proxy unreliable packets, such as UDP packets.&lt;/p&gt;
    &lt;p&gt;Multiple UDP flows to different target servers can be proxied in the same QUIC connection.&lt;/p&gt;
    &lt;p&gt;Proxying UDP packets is almost what we need to make relaying work in the p2p scenario, but not quite: While the client can reach any IP via the proxy, it‚Äôs still not possible for other nodes to communicate with the client (unless contacted first by the client).&lt;/p&gt;
    &lt;p&gt;Fortunately, there‚Äôs already a draft describing how to Proxy UDP Listeners in HTTP. The primary use case for this draft is running WebRTC over CONNECT-UDP. This is a very similar problem to the one we‚Äôre trying to solve: WebRTC peers actually use the ICE protocol to establish a direct connection, and for that they need to know their reflexive transport addresses.&lt;/p&gt;
    &lt;p&gt;The mechanism is pretty straight-forward: The proxy allocates a new IP:port for the client, and forwards all UDP packets on this socket to the client. Of course, it also has to include the 2-tuple that the packet originated from.&lt;/p&gt;
    &lt;p&gt;The simplificity of this approach is at the same time its biggest limitation: Since there are only 65535 port numbers (many of which are reserved), a proxy can only handle a limited number of clients at the same time. To be clear, this still allows tens of thousands of concurrent clients, and many deployment scenarios will never run into this limit.&lt;/p&gt;
    &lt;p&gt;It might be possible to work around this limit in the future by using a similar approach as the QUIC-aware proxying draft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Preparing for Multipath&lt;/head&gt;
    &lt;p&gt;The QUIC Working Group is finalizing the Multipath Extensions for QUIC. As the name suggests, this extensions allow multiple paths to be used simultaneously. For the p2p use case, this means that endpoints could keep the initial path available, even after a direct path was created by NAT traversal. These paths could either be used for load sharing or as a backup.&lt;/p&gt;
    &lt;p&gt;To get these benefits, we will need minor adaptations of the mechanism described here ‚Äì effectively, managing connection IDs and path IDs in a multipath version of the &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt; frame. We should work on that once the Multipath Extension for QUIC has made more progress in the IETF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting All the Pieces Together&lt;/head&gt;
    &lt;p&gt;Now that we‚Äôve explored all the components, let‚Äôs put them together and build a small p2p application running on top of QUIC.&lt;/p&gt;
    &lt;p&gt;When the node boots up, it first connects to a few hard-coded boot nodes. The majority of these nodes support the QUIC Address Discovery extension, so the node is able to learn that it‚Äôs behind a NAT, and what the NAT‚Äôs public addresses are.&lt;/p&gt;
    &lt;p&gt;It then connects to a relay and reserves an IP:port tuple with the relay. The node can now advertise this address to other peers in the network, for example by registering in some kind of peer directory, or by registering itself with the p2p network‚Äôs DHT.&lt;/p&gt;
    &lt;p&gt;At this point, other nodes can connect to the relay at this port, and have all their packets relayed. We‚Äôve achieved the first goal: we have established connectivity. The relayed connections can immediately be used to exchange application data. Now the goal is to lighten the load on the relay server, and to obtain a direct (and potentially lower-latency, higher-throughput) to the peer.&lt;/p&gt;
    &lt;p&gt;The nodes employ the mechanism described in the NAT traversal draft to punch holes through their respective NATs. This hole punching procedure might take a few attempts, depending on the number of candidate pairs (and if hole punching attempts are run in parallel), but should generally only take a few seconds.&lt;/p&gt;
    &lt;p&gt;Most importantly, this is entirely transparent to the application: The application can start to use the relayed connection, and use it all the while the QUIC stack tries to establish the direct path.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where are we on this?&lt;/head&gt;
    &lt;p&gt;So far, there‚Äôs no implementation of this protocol in production, but a lot of the documents have made their way through the IETF process and have now become widely deployed RFCs.&lt;/p&gt;
    &lt;p&gt;Specifically, the remaining pieces of the puzzle are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Proxy UDP Listeners in HTTP draft, which allows clients to reserve an IP:port tuple on a relay server.&lt;/item&gt;
      &lt;item&gt;The QUIC Address Discovery draft, which allows endpoints to learn about their public addresses. The current version of this draft is implemented by two different QUIC stacks: picoquic and a fork of quinn.&lt;/item&gt;
      &lt;item&gt;The NAT Traversal for QUIC draft, which defines how to coordinate hole punching attempts between peers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The quic-go project and the QUIC Interop Runner are community-funded projects.&lt;/p&gt;
    &lt;p&gt;If you find my work useful, please considering sponsoring:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45822982</guid><pubDate>Wed, 05 Nov 2025 14:06:22 +0000</pubDate></item><item><title>Removing XSLT for a more secure browser</title><link>https://developer.chrome.com/docs/web-platform/deprecating-xslt</link><description>&lt;doc fingerprint="be4a8c104cf770b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Published: October 29, 2025&lt;/p&gt;
    &lt;p&gt;Chrome intends to deprecate and remove XSLT from the browser. This document details how you can migrate your code before the removal in late-2026.&lt;/p&gt;
    &lt;p&gt;Chromium has officially deprecated XSLT, including the XSLTProcessor JavaScript API and the XML stylesheet processing instruction. We intend to remove support from version 155 (November 17, 2026). The Firefox and WebKit projects have also indicated plans to remove XSLT from their browser engines. This document provides some history and context, explains how we are removing XSLT to make Chrome safer, and provides a path for migrating before these features are removed from the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is being removed?&lt;/head&gt;
    &lt;p&gt;There are two APIs in the browser that implement XSLT, and both are being removed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The XSLTProcessor class (for example, &lt;code&gt;new XSLTProcessor()&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;The XSLT Processing Instruction (for example, &lt;code&gt;&amp;lt;?xml-stylesheet ‚Ä¶ ?&amp;gt;&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Timeline For Chrome&lt;/head&gt;
    &lt;p&gt;Chrome has the following plan:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chrome 142 (Oct 28, 2025): Early warning console messages added to Chrome.&lt;/item&gt;
      &lt;item&gt;Chrome 143 (Dec 2, 2025): Official deprecation of the API - deprecation warning messages begin to show in the console and in lighthouse.&lt;/item&gt;
      &lt;item&gt;Chrome 148 (March 10, 2026 Canary): Canary, Dev, and Beta releases begin disabling XSLT by default, as an early-warning.&lt;/item&gt;
      &lt;item&gt;Chrome 152 (Aug 25, 2026): Origin Trial (OT) and Enterprise Policy (EP) go live for testing. These allow sites and enterprises to continue using features past the removal date.&lt;/item&gt;
      &lt;item&gt;Chrome 155 (Nov 17, 2026): XSLT stops functioning on Stable releases, for all users other than Origin Trial and Enterprise Policy participants.**&lt;/item&gt;
      &lt;item&gt;Chrome 164 (Aug 17, 2027): Origin Trial and Enterprise Policy stop functioning. XSLT is disabled for all users.**&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What is XSLT?&lt;/head&gt;
    &lt;p&gt;XSLT, or Extensible Stylesheet Language Transformations, is a language used to transform XML documents, commonly into other formats such as HTML. It uses an XSLT stylesheet file to define the rules for this conversion, and an XML file containing the data used as input.&lt;/p&gt;
    &lt;p&gt;In browsers, when an XML file is received that links to an XSLT stylesheet, the browser uses the rules in that stylesheet to rearrange, format, and convert the raw XML data into a structured page (often HTML) that can be rendered for the user.&lt;/p&gt;
    &lt;p&gt;For example, an XSLT stylesheet could take the following XML input:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0"?&amp;gt;
&amp;lt;?xml-stylesheet type="text/xsl" href="demo.xsl" ?&amp;gt;
&amp;lt;page&amp;gt;
 &amp;lt;message&amp;gt;
  Hello World.
 &amp;lt;/message&amp;gt;
&amp;lt;/page&amp;gt;
&lt;/code&gt;
    &lt;p&gt;and this XSL stylesheet:&lt;/p&gt;
    &lt;code&gt;&amp;lt;xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&amp;gt;
  &amp;lt;xsl:output method="html"/&amp;gt;
  &amp;lt;xsl:template match="/page/message"&amp;gt;
    &amp;lt;body&amp;gt;
      &amp;lt;p&amp;gt;Message: &amp;lt;xsl:value-of select="."/&amp;gt;&amp;lt;/p&amp;gt;
    &amp;lt;/body&amp;gt;
  &amp;lt;/xsl:template&amp;gt;
&amp;lt;/xsl:stylesheet&amp;gt;
&lt;/code&gt;
    &lt;p&gt;and process them into this HTML for the browser to display: HTML&lt;/p&gt;
    &lt;code&gt;&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;Message: Hello World.&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;
    &lt;p&gt;In addition to the XSL processing instruction shown in the previous example, there's also the XSLTProcessor JavaScript API which can be used to process local XML documents with local XSLT stylesheets.&lt;/p&gt;
    &lt;head rend="h2"&gt;History of XSLT&lt;/head&gt;
    &lt;p&gt;XSLT was recommended by the World Wide Web Consortium (W3C) on November 16, 1999, as a language for transforming XML documents into other formats, most commonly HTML for display in web browsers. Before the official 1.0 recommendation, Microsoft took an early initiative by shipping a proprietary implementation based on a W3C working draft in Internet Explorer 5.0, released in March 1999. Following the official standard, Mozilla implemented native XSLT 1.0 support in Netscape 6 in late 2000. Other major browsers, including Safari, Opera, and later Chrome, also incorporated native XSLT 1.0 processors, making client-side XML-to-HTML transformations a viable web technology in the early 2000s.&lt;/p&gt;
    &lt;p&gt;The XSLT language itself continued to evolve, with the release of XSLT 2.0 in 2007 and XSLT 3.0 in 2017, which introduced powerful features like regular expressions, improved data types, and the ability to process JSON. Browser support, however, stagnated. Today, all major web browser engines only provide native support for the original XSLT 1.0 from 1999. This lack of advancement, coupled with the rise of the use of JSON as a wire format, and JavaScript libraries and frameworks (like jQuery, React, and Vue.js) that offer more flexible and powerful DOM manipulation and templating, has led to a significant decline in the use of client-side XSLT. Its role within the web browser has been largely superseded by these JavaScript-based technologies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why does XSLT need to be removed?&lt;/head&gt;
    &lt;p&gt;The continued inclusion of XSLT 1.0 in web browsers presents a significant and unnecessary security risk. The underlying libraries that process these transformations, such as libxslt (used by Chromium browsers), are complex, aging C/C++ codebases. This type of code is notoriously susceptible to memory safety vulnerabilities like buffer overflows, which can lead to arbitrary code execution. For example, security audits and bug trackers have repeatedly identified high-severity vulnerabilities in these parsers (e.g., CVE-2025-7425 and CVE-2022-22834, both in libxslt). Because client-side XSLT is now a niche, rarely-used feature, these libraries receive far less maintenance and security scrutiny than core JavaScript engines, yet they represent a direct, potent attack surface for processing untrusted web content. Indeed, XSLT is the source of several recent high-profile security exploits that continue to put browser users at risk. The security risks of maintaining this brittle, legacy functionality far outweighs its limited modern utility.&lt;/p&gt;
    &lt;p&gt;Furthermore, the original purpose of client-side XSLT‚Äîtransforming data into renderable HTML‚Äîhas been superseded by safer, more ergonomic, and better-maintained JavaScript APIs. Modern web development relies on things like the Fetch API to retrieve data (typically JSON) and the DOMParser API to safely parse XML or HTML strings into a DOM structure within the browser's secure JavaScript sandbox. Frameworks like React, Vue, and Svelte then manage the rendering of this data efficiently and securely. This modern toolchain is actively developed, benefits from the massive security investment in JavaScript engines, and is what virtually all web developers use today. Indeed, only about 0.02% of web page loads today actually use XSLT at all, with less than 0.001% using XSLT processing instructions.&lt;/p&gt;
    &lt;p&gt;This is not a Chrome or Chromium-only action: the other two major browser engines also support the removal of XSLT from the web platform: WebKit, Gecko.&lt;/p&gt;
    &lt;p&gt;For these reasons, deprecating and removing XSLT reduce the browser's attack surface for all users, simplify the web platform, and allow engineering resources to be focused on securing the technologies that actually power the modern web, with no practical loss of capability for developers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Improving XML parsing security&lt;/head&gt;
    &lt;p&gt;Similar to the severe security issues in libxslt, severe security issues were recently reported against libxml2 which is used in Chromium for parsing, serialization and testing the well-formedness of XML. To address future security issues with XML parsing In Chromium we plan to phase out the usage of libxml2 and replace XML parsing with a memory-safe XML parsing library written in Rust. Importantly, we won't be removing XML from the browser; only XSLT is being considered for removal here. We intend to ensure that replacing libxml2 is entirely transparent to web developers.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to migrate&lt;/head&gt;
    &lt;p&gt;There are a few alternative paths for migration.&lt;/p&gt;
    &lt;head rend="h3"&gt;JSON&lt;/head&gt;
    &lt;p&gt;For sites that are fully built on XML and XSL there is no one-size-fits all way to make the transition. Migration options include moving the XSLT processing pipeline to the server side and sending down the rendered HTML to the client, or migrating server-side XML API endpoints to JSON, and performing client-side rendering using JavaScript to transform JSON into HTML DOM and CSS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Client-side XSLT in JavaScript&lt;/head&gt;
    &lt;p&gt;There are a few client-side (JavaScript-based) XSLT libraries available, but the largest by far is produced by Saxonica (view the comprehensive documentation for Saxonica). The implementation goes well beyond the XSLT 1.0 implementation in web browsers, implementing full support for the latest v3.0 standard, and eventually the in-progress v4.0 standard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Polyfill&lt;/head&gt;
    &lt;p&gt;There is a polyfill that attempts to allow existing code, which depends on web browsers' implementations of XSLT 1.0, to continue functioning, while not using native XSLT features from the browser. The polyfill is located on GitHub.&lt;/p&gt;
    &lt;p&gt;The polyfill contains a functional WASM-based polyfilled replacement for the XSLTProcessor class, so existing JavaScript code can continue to work as-is:&lt;/p&gt;
    &lt;code&gt;&amp;lt;script src="xslt-polyfill.min.js"&amp;gt;&amp;lt;/script&amp;gt;

&amp;lt;script&amp;gt;
const xsltProcessor = new XSLTProcessor();
xsltProcessor.importStylesheet(xsltDoc);
const fragment = xsltProcessor.transformToFragment(xmlDoc, document);
&amp;lt;/script&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The polyfill also provides an automatic utility function for an easy way to replace XML documents that use XSLT processing instructions:&lt;/p&gt;
    &lt;p&gt;For an original &lt;code&gt;demo.xml&lt;/code&gt; file like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0"?&amp;gt;
&amp;lt;?xml-stylesheet type="text/xsl" href="demo.xsl"?&amp;gt;
&amp;lt;ROOT&amp;gt;
...content...
&lt;/code&gt;
    &lt;p&gt;One line can be added to invoke the polyfill and transform the document with the referenced XSLT stylesheet:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0"?&amp;gt;
&amp;lt;?xml-stylesheet type="text/xsl" href="demo.xsl"?&amp;gt;
&amp;lt;ROOT&amp;gt;
&amp;lt;script src="xslt-polyfill.min.js"
   xmlns="http://www.w3.org/1999/xhtml"&amp;gt;&amp;lt;/script&amp;gt;
...content...
&lt;/code&gt;
    &lt;p&gt;In this case, the new &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; element loads the polyfill, which detects the
XML document type and the XSLT processing instruction and transparently loads
it, replacing the document.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extension&lt;/head&gt;
    &lt;p&gt;There's also a Chrome extension that can be added to supported browsers, which will apply the same XSLT polyfill to all raw XML pages that contain XSLT processing instructions or calls to XSLTProcessor. This can be used for applications where the source XML or XSLT cannot be changed, to maintain functionality.&lt;/p&gt;
    &lt;p&gt;In particular, when XSLT is disabled, Chrome now shows a warning banner that links directly to an extension search page, to help users locate an extension:&lt;/p&gt;
    &lt;head rend="h2"&gt;Specific use cases&lt;/head&gt;
    &lt;p&gt;In the discussion in HTML standards, several concrete use cases were identified. This section talks specifically about each of them, to recommend paths forward for developers publishing XML resources that use XSLT today.&lt;/p&gt;
    &lt;head rend="h3"&gt;RSS and Atom Feeds&lt;/head&gt;
    &lt;p&gt;In many existing RSS or Atom feeds, XSLT is used to make raw XML feeds human-readable when viewed directly in a browser. The primary use case is that when a user accidentally clicks on a site's RSS feed link, rather than pasting that link into their RSS reader, they get a formatted HTML response that they can read, rather than the raw XML itself.&lt;/p&gt;
    &lt;p&gt;There are two paths forward for this use case. The "standard" HTML way to do this is to add &lt;code&gt;&amp;lt;link rel="alternate" type="application/rss+xml"&amp;gt;&lt;/code&gt; to an
(HTML-based) site, rather than adding an explicit (user-visible) &lt;code&gt;&amp;lt;a
href="something.xml"&amp;gt;&lt;/code&gt; that users might accidentally click. This solution allows
RSS readers to find the feed if a user pastes in just the website URL, but it
also allows human users to see the regular HTML content without getting confused
by a link to an XML resource. This also follows the normal web paradigm that
HTML is for humans and XML is for machines. Of course this doesn't solve the
case where a user just "has" an RSS link from somewhere, and they paste it into
their web browser (rather than their RSS reader).&lt;/p&gt;
    &lt;p&gt;When that solution isn't wanted, the polyfill offers another path. As mentioned previously, the RSS/Atom XML feed can be augmented with one line, &lt;code&gt;&amp;lt;script
src="xslt-polyfill.min.js" xmlns="http://www.w3.org/1999/xhtml"&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;,
which will maintain the existing behavior of XSLT-based transformation to HTML.
That shouldn't affect RSS reader's ability to continue parsing the XML, since
the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; is a direct child of the root element.&lt;/p&gt;
    &lt;head rend="h3"&gt;API output for embedded devices&lt;/head&gt;
    &lt;p&gt;Some commercial embedded devices measure or otherwise generate XML data for consumption by users on the local network. Some of these devices do this by generating a single XML data feed that uses XSLT to transform it into a human-readable HTML format. That allows the API to be directly viewed in a browser without needing additional code on the device or in the browser.&lt;lb/&gt; Since this is a very application specific use case, the shape of the solution might vary. For applications where the source code of the embedded device can be updated, any of the options described previously (JSON, Polyfill) could work. In particular, however, many such devices are difficult or impossible to update, for various reasons. In that case, the extension is likely the best option, since it allows client browsers to continue to read the data in exactly the same way, without modifying the device.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lazy templating for web sites&lt;/head&gt;
    &lt;p&gt;Web developers sometimes use XSLT on the client side to apply presentation markup to semantic markup, functioning as a lazy templating language that is separate from the JavaScript ecosystem.&lt;/p&gt;
    &lt;p&gt;There are two solutions to this more general problem. For an existing site built in this way, the easiest solution is likely just to add the polyfill to maintain existing functionality. Or perhaps perform the XSLT transformation on the server side, and serve the resulting HTML to the client, rather than the raw XML. The more long-term solution for such properties would be to migrate to a more modern JavaScript or JSON-based framework.&lt;/p&gt;
    &lt;p&gt;If you encounter a specific problem in Chrome related to this XSLT deprecation, report a bug here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45823059</guid><pubDate>Wed, 05 Nov 2025 14:14:23 +0000</pubDate></item><item><title>The shadows lurking in the equations</title><link>https://gods.art/articles/equation_shadows.html</link><description>&lt;doc fingerprint="370746cbee2f5ea1"&gt;
  &lt;main&gt;
    &lt;p&gt;For all the history of computational mathematical visualization, graphing equations has been done in binary mode - where graphs show only where an equation is EXACTLY equal. But when you only see in black-and-white, some things are invisible. For all this time, lurking beneath the error == 0 surface, mathematical shadows have been lurking in the equations.&lt;/p&gt;
    &lt;p&gt;FuzzyGraph, on the other hand, visualizes equations in Non-Binary mode - showing not only where an equation are exactly equal, but also where the equation nearly equal and where the equation is far from equal (where the error is high). Sometimes, these high error areas form clear visual shadow-like features.&lt;/p&gt;
    &lt;p&gt;Let's look at some examples...&lt;/p&gt;
    &lt;p&gt;Here is the "Slash Dot" Equation ( \( \frac{y}{x^2+y^2} = \frac{x+1}{x^2+y^2} \)) as both a conventional and fuzzy graph...&lt;/p&gt;
    &lt;p&gt;Note the giant black hole that is present in the Fuzzy/Non-Binary graph, but invisible in conventional/Binary graphing. This "black hole" feature represents a region of high error in the equation.&lt;/p&gt;
    &lt;p&gt;Let's look at another example: \(y = \frac{x}{x^2 + y^2} \) &lt;/p&gt;
    &lt;p&gt;Notice that the black hole eye-looking features are COMPLETELY INVISIBLE in the conventional/binary mode of graphing.&lt;/p&gt;
    &lt;p&gt;To get a better idea of what these black hole things are, let's look at a simpler example. First let's look at the opposite of a black hole - a simple star/particle example: \( x^2 + y^2 = 0 \). For this equation, there is only 1 solution: (0, 0). So if you graph this in a conventional graphing app, it will only show a single dot at (0, 0). But in FuzzyGraph, it looks like a fuzzy particle or something.&lt;/p&gt;
    &lt;p&gt;But now, let's invert this to get the "Black Hole Equation": \( \frac{1}{x^2+y^2} = 0 \)...&lt;/p&gt;
    &lt;p&gt;In this case, there is absolutely nothing to show on a conventional graph, as there are actual solutions to this equations. However, there is still a mathematical topography which can be visualized (as can be seen in the fuzzy graph).&lt;/p&gt;
    &lt;p&gt;Not all of the Shadows are like black holes.&lt;/p&gt;
    &lt;p&gt;In this example, let's start by combining 2 lines together: \(y=x\) and \(y=-x\).&lt;/p&gt;
    &lt;p&gt;We can visually add 2 equations together by refactoring them so they are both equal to 0, and then multiplying the two refactored equations together. \(y=x\) can be changed to \(y-x=0\), and \(y=-x\) can be refactored to \(y+x=0\).&lt;/p&gt;
    &lt;p&gt;We can then combine 2 into a single equation these like this: \( (y-x) \times (y+x) = 0 \)&lt;/p&gt;
    &lt;p&gt;And now, let's invert one of the equations using division: \( \frac{x-y}{x+y} = 0 \)&lt;/p&gt;
    &lt;p&gt;So as you can see, the line that was inverted (under the division line) is now a Shadow Line. And this seems like a more "correct" way to visualize this than as the conventional graph shows it (which is indistinguishable from the simpler equation, \(y-x=0\)).&lt;/p&gt;
    &lt;p&gt;This equation works almost exactly as the previous. And like before, let's start with multiplication to combine 2 equations (in this case, a circle and a vertical line equation): \( x \times (x^2+y^2-1) = 0 \).&lt;/p&gt;
    &lt;p&gt;But now, let's invert the circle by using division, which makes the equation: \( \frac{x}{x^2+y^2-1} = 0 \).&lt;/p&gt;
    &lt;p&gt;Note that the Shadow Circle is invisible in the conventional graph. In fact, the conventional graph looks identical to a conventional graph of the \(x=0\) equation (as if the denominator was not there).&lt;/p&gt;
    &lt;p&gt;In all of these previous examples, the "shadows" have represented areas of high error. But in this last example, we'll see some hidden details that represent areas of low error - areas that are nearly solutions to the equation.&lt;/p&gt;
    &lt;p&gt;Consider the equation, \( y=4 sin(x)+ sin(2.7y) \), as both a conventional graph and a fuzzy graph:&lt;/p&gt;
    &lt;p&gt;Note the floating dots in the fuzzy graph version that are not there in the conventional/binary graph. These are like underwater islands - underwater mountains that are just below the surface of the water (or in this case, the \( error == 0 \) surface). These hidden islands represent area that are near-solutions to the equation (which are only visible in FuzzyGraph).&lt;/p&gt;
    &lt;p&gt;Their presense hints that we can tweak the equation slightly to cause them to burst above the surface of the water (which should also make them visible in conventional graphs).&lt;/p&gt;
    &lt;p&gt;So let's change the equation from: &lt;lb/&gt; \( y=4 sin(x)+ sin(2.7y) \) to: &lt;lb/&gt; \( y=4 sin(x)+ sin(2.8y) \)...&lt;/p&gt;
    &lt;p&gt;And as you can see, those previously-hidden islands are now visible in the conventional graph.&lt;/p&gt;
    &lt;p&gt;So Fuzzy/non-binary graphing can help us see features of the mathematical topography that are completely invisible with conventional/binary.&lt;/p&gt;
    &lt;p&gt;Date published: 2025-11-05&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45823141</guid><pubDate>Wed, 05 Nov 2025 14:21:13 +0000</pubDate></item><item><title>Carice TC2 ‚Äì A non-digital electric car</title><link>https://www.caricecars.com/</link><description>&lt;doc fingerprint="e68401540d9d7dbb"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;the 100% electric Carice TC2&lt;/head&gt;
    &lt;head rend="h1"&gt;a real retro head-turner&lt;/head&gt;
    &lt;p&gt;Reserve your spot now on next year‚Äôs production batch. Spaces limited.&lt;/p&gt;
    &lt;head rend="h1"&gt;the 100% electric carice TC2&lt;/head&gt;
    &lt;head rend="h2"&gt;a real retro head-turner&lt;/head&gt;
    &lt;p&gt;Reserve your spot now on next year‚Äôs production batch. Spaces limited.&lt;/p&gt;
    &lt;head rend="h6"&gt;The new experience&lt;/head&gt;
    &lt;head rend="h2"&gt;carice TC2&lt;/head&gt;
    &lt;p&gt;Meet the all-new electric Carice TC2: extremely lightweight, dynamic and elegant. When you get into your Carice, you escape and for a moment you forget about the everyday hassle. Whether you are the one driving the Carice or the passenger being driven around, it will be hard to hide that smile. With a TC2 you own something extraordinary, a piece of art.&lt;/p&gt;
    &lt;head rend="h6"&gt;The new experience&lt;/head&gt;
    &lt;head rend="h2"&gt;Carice TC2&lt;/head&gt;
    &lt;p&gt;We are busy with anything and everything, all the time. When you get into your Carice, you escape and for a moment you forget about the everyday hassle. You just relax and enjoy the drive. Whether you are the one driving the Carice or the passenger being driven around, it will be hard to hide that smile. The TC2 is a piece of art, just for you to enjoy.&lt;/p&gt;
    &lt;head rend="h6"&gt;why A Carice&lt;/head&gt;
    &lt;head rend="h2"&gt;the ultimate freedom&lt;/head&gt;
    &lt;p&gt;The result of years of hard work and dedication is the striking Carice TC2: it is the ultimate car to enjoy that sunny day in style and enjoy your drive and unwind.&lt;/p&gt;
    &lt;head rend="h5"&gt;all electric&lt;/head&gt;
    &lt;p&gt;The Carice TC2 is fully electric and has no emissions. This car is built to be fun for everybody ‚Äì not just the driver. It is our mission to combine 21st-century technology with the look and feel of the cars of the past.&lt;/p&gt;
    &lt;head rend="h5"&gt;the essence&lt;/head&gt;
    &lt;p&gt;If you just take away unnecessary things for long enough, you will get back to the essence of driving. The Carice TC2 is elegant, stylish and at the same time uncomplicated. This delivers electric driving in its most pure and elementary form.&lt;/p&gt;
    &lt;head rend="h5"&gt;featherlight&lt;/head&gt;
    &lt;p&gt;Because the Carice TC2 is available from 590 kg including battery pack, it handles exceptionally dynamic yet comfortable. Moreover, power consumption is very low due to this weight. Therefore, the TC2 delivers a driving experience like no other. Very compact, yet big enough!&lt;/p&gt;
    &lt;head rend="h3"&gt;‚Äì time to forget about time ‚Äì&lt;/head&gt;
    &lt;head rend="h6"&gt;Seen on&lt;/head&gt;
    &lt;head rend="h6"&gt;Seen on&lt;/head&gt;
    &lt;head rend="h6"&gt;About us&lt;/head&gt;
    &lt;head rend="h2"&gt;carice craftsmanship&lt;/head&gt;
    &lt;p&gt;Built and designed from the ground up in the Netherlands by people with a lifelong love of classic cars, the TC2 is made to resemble the playful and elegant looks of every car that you loved as a kid. This passion for cars translates into a high level of attention to detail and commitment to meet your needs. Carice is expanding their extensive history in automotive design and development every day. Find out about our latest events and achievements here.&lt;/p&gt;
    &lt;head rend="h6"&gt;gallery&lt;/head&gt;
    &lt;head rend="h2"&gt;modern classic&lt;/head&gt;
    &lt;p&gt;From the eye-catching dashboard, the classically styled steering wheel to the matching upholstery: everything in a Carice TC2 is made to stand out in all its simplicity. With a Carice you don‚Äôt just own another car: you get something extraordinary, a piece of art.&lt;/p&gt;
    &lt;head rend="h6"&gt;configure&lt;/head&gt;
    &lt;head rend="h2"&gt;configure your carice&lt;/head&gt;
    &lt;p&gt;To personalize your TC2, you can choose from a wide range of different colors for the paint, upholstery and rooftop. There is always a combination that fits your style.&lt;/p&gt;
    &lt;head rend="h2"&gt;specifications&lt;/head&gt;
    &lt;p&gt;There is no better way to experience the Carice TC2 than by seeing it and driving it. The elegant lines, attention to detail and phenomenal handling can‚Äôt be captured in a list, but some features can. You can find them below.&lt;/p&gt;
    &lt;head rend="h5"&gt;sizes and masses&lt;/head&gt;
    &lt;head rend="h5"&gt;battery&lt;/head&gt;
    &lt;head rend="h5"&gt;other&lt;/head&gt;
    &lt;p&gt;* Some specifications may differ, depending on the individual configuration of the TC2&lt;/p&gt;
    &lt;head rend="h6"&gt;contact&lt;/head&gt;
    &lt;head rend="h2"&gt;send us a message&lt;/head&gt;
    &lt;head rend="h6"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h2"&gt;frequently asked questions&lt;/head&gt;
    &lt;head rend="h5"&gt;when can i order my Carice TC2?&lt;/head&gt;
    &lt;p&gt;You can already order your Carice. If you are interested you can contact us via the links on the website and the contact form to register your interest or book a test drive.&lt;/p&gt;
    &lt;head rend="h5"&gt;is the Carice TC2 a new car?&lt;/head&gt;
    &lt;p&gt;Yes! We have been designing and developing the TC2 ourselves from the ground up, and are now manufacturing the first series of TC2‚Äôs in the Netherlands. After more than 10 years of developing, testing and optimizing an extremely lightweight chassis around our electric drivetrain, you can now get a phenomenal handling and elegant TC2 yourself and enjoy driving in its most elementary form.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the price of a Carice TC2?&lt;/head&gt;
    &lt;p&gt;Prices for a TC2 start at ‚Ç¨44.500 excluding taxes (‚Ç¨53.854 including 21% btw/Dutch tax).&lt;/p&gt;
    &lt;head rend="h5"&gt;in what countries can i drive the Carice?&lt;/head&gt;
    &lt;p&gt;The Carice TC2 complies with the European regulations and can therefore be driven in all EU countries and countries that adopt those regulations, like Switzerland, the United Kingdom, Monaco and Norway.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the estimated delivery time?&lt;/head&gt;
    &lt;p&gt;At the moment we are making the TC2 exclusively on order, as every car is configured differently. We can provide you with an estimation on the delivery time and you can reserve a spot on the production list by placing an order.&lt;/p&gt;
    &lt;head rend="h5"&gt;how can i configure my Carice?&lt;/head&gt;
    &lt;p&gt;There are a lot of options for you to choose between. Different colors, wheels, upholstery, soft top, accessories, battery pack, charging gear and so on. If you are interested in buying a Carice TC2, please get in touch.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the range of a Carice TC2&lt;/head&gt;
    &lt;p&gt;Depending on the configuration of your TC2, you can drive more than 300km, which can bring you to the most beautiful places.&lt;/p&gt;
    &lt;head rend="h5"&gt;i have decided: i want one soon! how to proceed?&lt;/head&gt;
    &lt;p&gt;The current production batch is sold out, but there are a few cars left for the next production run. If you are sure you want one, you can secure one of these cars by paying a deposit of 75% of the purchasing price. Please contact us for the details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45823186</guid><pubDate>Wed, 05 Nov 2025 14:25:36 +0000</pubDate></item><item><title>Ask HN: My family business runs on a 1993-era text-based-UI (TUI). Anybody else?</title><link>https://news.ycombinator.com/item?id=45823234</link><description>&lt;doc fingerprint="3ec6db1c2cb327ac"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Is anybody still using TUI applications for business?&lt;/p&gt;
      &lt;p&gt;My family company is a wholesale distribution firm (with lightweight manufacturing) and has been using the same TUI application (on prem unix box) since 1993. We use it for customer management, ordering, invoicing, kit management/build tickets, financials - everything. We've transitioned from green screen terminals to modern emulators, but the core system remains. I spent many summers running serial and ethernet cables.&lt;/p&gt;
      &lt;p&gt;I left the business years ago to become a full time software engineer, but I got my start as a script kiddie writing automations for this system with Microsoft Access, VBA, and SendKeys to automate data entry. Amazingly, they still have a Windows XP machine running many of those tasks I wrote back in 2004! It's brittle, but cumulatively has probably saved years of time. That XP machine could survive a nuclear winter lol.&lt;/p&gt;
      &lt;p&gt;I recently stepped back in to help my parents and spent a day converting many of those old scripts to a more modern system (with actual error-handling instead of strategic sleep()s and prayers) using Python and telnetlib3. I had a blast and still love this application. I can fly around in it. Training new people was always a pain, but for those that got it‚Äîthey had super powers.&lt;/p&gt;
      &lt;p&gt;This got me thinking: Are other companies still using this type of interface to drive their core operations? I‚Äôm reflecting on whether the only reason my family's business still uses this system is because of the efficiency hacks I put in place 20+ years ago. Without them, would they have been forced to switch to a modern cloud/GUI system? I‚Äôm not sure if I‚Äôm blinded by nostalgia or if this application is truly as wonderful as I remember it.&lt;/p&gt;
      &lt;p&gt;I‚Äôd love to hear if and how these are still being utilized in the real world.&lt;/p&gt;
      &lt;p&gt;P.S. The system we use was originally sold by ADP and has had different names (D2K, Prophet21). I believe Epicor owns it now (Activant before).&lt;/p&gt;
      &lt;p&gt;P.P.S. Is anybody migrating their old TUI automation scripts to a more modern framework or creating new ones? I‚Äôm super curious to compare notes and see what other people are doing.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45823234</guid><pubDate>Wed, 05 Nov 2025 14:29:49 +0000</pubDate></item><item><title>Ruby and Its Neighbors: Smalltalk</title><link>https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/</link><description>&lt;doc fingerprint="34329b3385e7083a"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Ruby And Its Neighbors: Smalltalk&lt;/head&gt;
    &lt;p&gt;Last time, we talked about Perl as an influence on Ruby, this time, we‚Äôll talk about the other major influence on Ruby: Smalltalk.&lt;/p&gt;
    &lt;p&gt;Smalltalk had a different kind of influence, since almost nothing of Smalltalk‚Äôs syntax made into Ruby. But many of the details of how objects work are directly inspired by Smalltalk, including the idea that every piece of data is part of the object system.&lt;/p&gt;
    &lt;p&gt;Also unlike Perl, I spent a good couple of years working in Smalltalk, and it is one of my favorite languages that I‚Äôll never likely use in anger again.&lt;/p&gt;
    &lt;head rend="h2"&gt;(A Personal) History of Smalltalk&lt;/head&gt;
    &lt;p&gt;Smalltalk originated in the same Xerox PARC team that invented the windowed interface, ethernet, and the laser printer, and who knows what else, they may have invented ice cream and rainbows.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a whole story about what project Smalltalk was invented to be a part of, and a whole alternate history of computing and how people interact with computers that we are going to largely ignore. (If you are interested, start by searching for ‚ÄúAlan Kay Dynabook‚Äù.)&lt;/p&gt;
    &lt;p&gt;Smalltalk went through a few different iterations in the 1970s, but the version that we know today is a direct descendent of Smalltalk-80, which was the first version released to the wider world.&lt;/p&gt;
    &lt;p&gt;For most of the 80s and 90s, Smalltalk was something that doesn‚Äôt really exist today ‚Äì a programming language and environment that companies paid money to use. Lots of money. The major player was ParcPlace, which was a spinoff of Xerox that provided Smalltalk tools. Their commercial product was originally called ObjectWorks, later changed to VisualWorks, and eventually sold off and presumably slowly losing customers after the late 90s.&lt;/p&gt;
    &lt;p&gt;Smalltalk was pretty big in the industry for a while. Most of the aviation industry ran on it in the 90s, the big payroll project that was the basis for Extreme Programming was a Smalltalk project, there was reasonably high demand for Smalltalk programmers through at least the mid 1990s. I taught an undergrad OO class in Smalltalk in 1997 and 1998 to students that wanted to be learning C++, and I remember telling them that Smalltalk programmers were paid more.&lt;/p&gt;
    &lt;p&gt;I first encountered Smalltalk as a grad student in about 1993, where Georgia Tech used ObjectWorks to teach Smalltalk and Object-Oriented programming (there‚Äôs a whole other sidebar about how Object-Oriented languages came to prominence in the 90s, and the arguments over that but again, another day). ObjectWorks was pricey, and there was also a lower-cost vendor called Digitalk, and eventually I also used a product called Smalltalk Agents, which has apparently totally vanished from the entire internet.&lt;/p&gt;
    &lt;p&gt;In 1995, a bunch of the original Xerox Smalltalk team was together at Apple, and they decided to release an open-source Smalltalk VM. What they did was very interesting. They wrote a very, very small kernel in very vanilla C, and then 95% of the environment was then built in Smalltalk on top of that. Oh, and even the vanilla C was written in Smalltalk, they wrote a Smalltalk to C compiler. They called their new Smalltalk ‚ÄúSqueak‚Äù, which made a lot more sense when they all moved en masse to Disney.&lt;/p&gt;
    &lt;p&gt;The fact that Squeak was largely written in itself made it fairly easy to port to new systems, and it was quickly available on just about anything with a microchip.&lt;/p&gt;
    &lt;p&gt;I‚Äôm pretty sure that I first saw Squeak at the OOPSLA conference in 1997. (Object-Oriented Programming, Systems, Languages &amp;amp; Applications, since you asked) At this conference I somehow got to do a team-building exercise with Adelde Goldberg from the original Xerox PARC team, which is not relevant to anything but seemed very cool at the time. I was already using Smalltalk in my projects, but Squeak was immediately interesting and my extended research team started doing cool stuff. Like, what I‚Äôm pretty sure was the first Wiki tool outside the original C2 Wiki, was written in Squeak. (Apparently at least one is still running).&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk‚Äôs Environment&lt;/head&gt;
    &lt;p&gt;It‚Äôs important to understand that Smalltalk‚Äôs development is a different evolutionary tree from nearly every currently popular programming language, in that Smalltalk is in no way, shape, or form influenced by Unix or C. Perl, Ruby, Python, JavaScript, Swift, Kotlin and on and on, all come from a universe where they expect to run Unix libraries, and where C syntax is normal. The Unix philosophy of ‚Äúsmall pieces, loosely joined‚Äù is not a part of Smalltalk‚Äôs DNA at all.&lt;/p&gt;
    &lt;p&gt;Smalltalk is basically its own operating system, and the syntax is different from C-style languages in ways big and small. For example, the first element of an array is‚Ä¶ 1. Which, when you think about how people count, actually makes sense.&lt;/p&gt;
    &lt;p&gt;It‚Äôs hard to separate Smalltalk the language from Smalltalk the environment, although I suppose technically you could have the language without the whole shebang (and I think there was a GNU Smalltalk that tried this), really the environment is part of the appeal.&lt;/p&gt;
    &lt;p&gt;Your main interfaces to the smalltalk system are a Workspace and a Browser. A workspace is analogous to REPL session, you can type in arbitrary Smalltalk code and have the system ‚Äúdo it‚Äù to execute the code, ‚Äúprint it‚Äù to execute the code and output the result. There are some other actions like ‚Äúdebug it‚Äù or ‚Äúinspect it‚Äù, but that‚Äôs the basic idea. Unlike a Unix REPL, there‚Äôs no prompt, and you don‚Äôt automatically invoke code by hitting return, you have to select code and then invoke the menu item or the keyboard shortcut for the code you want to act on.&lt;/p&gt;
    &lt;p&gt;The Browser is where you write code. There a a few different versions in most Smalltalks, here‚Äôs the main one, this is from a modern Smalltalk called Cuis.&lt;/p&gt;
    &lt;p&gt;At the top, we have four window panes ‚Äì left to right we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Categories ‚Äì groups of classes that are related in some way. Cuis nicely puts each group in a pulldown list. Categories have no particular syntactic meaning, they are just there to make browsing easier.&lt;/item&gt;
      &lt;item&gt;Classes ‚Äì one entry for each class in the currently selected category, at the bottom of this pane is a toggle for ‚Äúclass‚Äù vs. ‚Äúinstance‚Äù which determines what kinds of messages are shown in the next two panes.&lt;/item&gt;
      &lt;item&gt;Protocols ‚Äì a protocol is a user-defined group of messages. Smalltalk internally uses ‚Äúmessage‚Äù rather than ‚Äúmethod‚Äù because of how Alan Kay thinks about objects. Again, protocols are for the programmer, not the system.&lt;/item&gt;
      &lt;item&gt;Messages ‚Äì each messages in the currently selected protocol is listed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The bottom pane is the code editor, and if a message is selected in the code pane, its code is displayed there.&lt;/p&gt;
    &lt;p&gt;You probably have questions:&lt;/p&gt;
    &lt;p&gt;Does this mean that you can see the source code for the entire Smalltalk system?&lt;/p&gt;
    &lt;p&gt;Yes, yes it does.&lt;/p&gt;
    &lt;p&gt;**Can you modify any code in the system? **&lt;/p&gt;
    &lt;p&gt;Yes, yes you can.&lt;/p&gt;
    &lt;p&gt;Even, like, deep system code?&lt;/p&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;p&gt;Isn‚Äôt that dangerous?&lt;/p&gt;
    &lt;p&gt;As a Ruby developer, you should know that it‚Äôs only as dangerous as the developers who use it.&lt;/p&gt;
    &lt;p&gt;How do you edit a message?&lt;/p&gt;
    &lt;p&gt;Just display the existing message in the browser, edit the message and select ‚Äúsave‚Äù. The Smalltalk system will parse the code, stop if there are syntax errors, but if not, the updated method will be saved to the system. A side effect is you can‚Äôt save code that isn‚Äôt syntactically parsable, even as a draft.&lt;/p&gt;
    &lt;p&gt;Okay, but how do you create a message?&lt;/p&gt;
    &lt;p&gt;The ‚Äúreal‚Äù way is to select a protocol but not a message, and Smalltalk will put a template in the edit window. Write your message in the editor and save it. Alternately, you can just change the name of a message in the edit window, and a new method with that name will be created, without deleting the old message.&lt;/p&gt;
    &lt;p&gt;And how do you create a class?&lt;/p&gt;
    &lt;p&gt;Similarly.&lt;/p&gt;
    &lt;p&gt;If you select a category and not a class, you‚Äôll get this in the code editor pane:&lt;/p&gt;
    &lt;code&gt;Object subclass: #NameOfSubclass
	instanceVariableNames: ''
	classVariableNames: ''
	poolDictionaries: ''
	category: 'Kernel-Chronology'
&lt;/code&gt;
    &lt;p&gt;The thing to note is that this is not actually template, it‚Äôs actually code: a message, waiting for you to fill in the arguments, replacing &lt;code&gt;#NameOfSubclass&lt;/code&gt; and adding the instance variables and so on. You don‚Äôt save this, you ‚Äúdo it‚Äù, just like if you were in a workspace. The message call is evaluated, and Smalltalk creates a new class.&lt;/p&gt;
    &lt;p&gt;But wait, if all the code is in the image and isn‚Äôt in text files, how do people work together and share code?&lt;/p&gt;
    &lt;p&gt;Don‚Äôt worry about it.&lt;/p&gt;
    &lt;p&gt;Seriously, though, worry about it.&lt;/p&gt;
    &lt;p&gt;This has always been a problem. Smalltalk allows you to share ‚Äúchange sets‚Äù, effectively the code differences between one point and another. Classically, one person would export their change set, and other team members would import it. Different Smalltalks have built up more sophisticated tools over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk‚Äôs Syntax&lt;/head&gt;
    &lt;p&gt;Smalltalk‚Äôs syntax is very simple, relative to Ruby and Perl.&lt;/p&gt;
    &lt;p&gt;Wait a sec, I literally wrote this for a chapter in a book about Smalltalk literally 25 years ago, here‚Äôs a slight paraphrase:&lt;/p&gt;
    &lt;p&gt;Every line of Smalltalk is evaluated the same way.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Every variable is an object. There are no basic types that are not objects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Every expression is a message being passed to an object, there is basically no expression syntax that is not a message.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;All messages return a value. (The return value is specified by&lt;/p&gt;&lt;code&gt;^&lt;/code&gt;, if the method does not specify a return value, it implicitly returns&lt;code&gt;self&lt;/code&gt;, the instance that received the message.)&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are three kinds of messages:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Unary messages like &lt;code&gt;3 negated&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Binary messages like &lt;code&gt;a + b&lt;/code&gt;, these actually are messages you can define, there is a small set of them, and they are special cases in the parser.&lt;/item&gt;
          &lt;item&gt;Keyword messages such as &lt;code&gt;anArray at: 3 put: 7&lt;/code&gt;. This syntax got used by ObjectiveC and later Swift, so you may be familiar with it. It‚Äôs&lt;code&gt;receiver &amp;lt;messagepart&amp;gt;: &amp;lt;argument&amp;gt;&lt;/code&gt;where you can have multiple message parts. If you are referring to the message, typically you just say the message parts, so this message would be called&lt;code&gt;at:put:&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Unary messages like &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smalltalk does not have operator precedence. All code is evaluated strictly from left to right. Unary messages first, binary messages second, keyword messages last. Parenthesis can be used to force order of operations or to make things clearer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The assignment operator is&lt;/p&gt;&lt;code&gt;:=&lt;/code&gt;(Smalltalk uses&lt;code&gt;=&lt;/code&gt;for boolean equality), the right hand side is evaluated and the value is assigned to the result of the left hand side.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And that‚Äôs basically it, with a couple of ways to create literals like strings, arrays, dictionaries, local variables, and blocks.&lt;/p&gt;
    &lt;p&gt;So, for 10 points and control of the board, what does this do?&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 3 squared + 4 squared sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;The unary messages are evaluated first:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 9 + 16 sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;There‚Äôs still a unary message&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 9 + 4&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Now we can do the binary message:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse = 13&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Oops.&lt;/p&gt;
    &lt;p&gt;To get what you actually want, you need parentheses:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := (3 squared + 4 squared) sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax for loops, all loop behavior is defined by methods on &lt;code&gt;Array&lt;/code&gt; and the like, very similar to Ruby‚Äôs &lt;code&gt;Enumerable&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax to create messages or classes. Message creation is managed by the editor (which internally calls a message that adds the new code), class creation is just another method ‚Äì in Squeak, that method is &lt;code&gt;Object#subclass:instanceVariableNames:classVariableNames:poolDictionaries:category:&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax for boolean logic, all logic behavior is defined by the classes &lt;code&gt;True&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt;. Ruby sort of does this, but Ruby does have &lt;code&gt;if&lt;/code&gt; as special syntax. Smalltalk does not, you‚Äôd write a Smalltalk conditional as just another message:&lt;/p&gt;
    &lt;code&gt;(x &amp;gt; 10) ifTrue: [ x squared ] ifFalse: [ x sqrt ]
&lt;/code&gt;
    &lt;p&gt;The square brackets are blocks, and behave very similar to Ruby blocks, except that you can treat them as just normal variables and normal arguments. You can even, as in this case, have multiple arguments that take blocks.&lt;/p&gt;
    &lt;p&gt;The implementation if the method &lt;code&gt;ifTrue:ifFalse&lt;/code&gt; is simple. For the &lt;code&gt;True&lt;/code&gt; class, it just takes the true block and executes it by passing it the message &lt;code&gt;value&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^trueAlternativeBlock value
&lt;/code&gt;
    &lt;p&gt;And for the false class, the exact opposite:&lt;/p&gt;
    &lt;code&gt;ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^falseAlternativeBlock value
&lt;/code&gt;
    &lt;p&gt;Smalltalk doesn‚Äôt have a &lt;code&gt;case&lt;/code&gt; or &lt;code&gt;switch&lt;/code&gt; statement, typically if you want behavior like that you‚Äôd define a dictionary of keys to blocks or you would use the object system and polymorphism and double dispatch.&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk‚Äôs Object Model&lt;/head&gt;
    &lt;p&gt;There‚Äôs a lot about Smalltalk‚Äôs object model that sound familiar to a Ruby developer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There‚Äôs a base class called &lt;code&gt;Object&lt;/code&gt;that everything inherits from.&lt;/item&gt;
      &lt;item&gt;Instance variables are private. Getters and setters default to having the same name as the instance variable.&lt;/item&gt;
      &lt;item&gt;Method lookup happens at the point of the method call.&lt;/item&gt;
      &lt;item&gt;Classes are instances of the class &lt;code&gt;Class&lt;/code&gt;(sort of).&lt;/item&gt;
      &lt;item&gt;There‚Äôs a thing called a ‚ÄúMetaclass‚Äù&lt;/item&gt;
      &lt;item&gt;There‚Äôs a method that‚Äôs the method of last resort ‚Äì in Ruby, it‚Äôs &lt;code&gt;method_missing&lt;/code&gt;, but in Smalltalk it‚Äôs called&lt;code&gt;doesNotUnderstand&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple of differences as well&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smalltalk‚Äôs meta classes are structured differently, I explained this once and I‚Äôm not sure I ever want to explain it again.&lt;/item&gt;
      &lt;item&gt;Smalltalk doesn‚Äôt have multiple inheritance or mixins or modules or anything like that. Although there have been some attempts to add these features, the traditional Smalltalk way to do this is through delegation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But overall, Smalltalk and Ruby are similar enough that a huge amount of Kent Beck‚Äôs Smalltalk Best Practice Patterns is applicable to Ruby as long as you translate the syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Happened?&lt;/head&gt;
    &lt;p&gt;Unlike Perl, I actually did use Smallalk to build a few real applications that had real users. I miss it a lot.&lt;/p&gt;
    &lt;p&gt;I find that when I try to explain Smalltalk to people, it‚Äôs easy to explain the syntax and the object model. What‚Äôs hard to explain is how it is to work in a Smalltalk environment.&lt;/p&gt;
    &lt;p&gt;You‚Äôve likely used powerful coding editors and terminals. Smalltalk is just different. You are in the running environment.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tests start instantly, and in general run very fast. There‚Äôs a dedicated test runner window. Some smalltalk integrate tests with the regular browser, so you can see test status from the code browsers.&lt;/item&gt;
      &lt;item&gt;Debugging is amazing, you can investigate the state of any object in the system, you can change that state, you can easily execute arbitrary code. You can have a test halt on exception, update the code and re-run from the point failure. It‚Äôs hard to describe how fluid it is, especially since I‚Äôm no longer expert enough to do it fluently.&lt;/item&gt;
      &lt;item&gt;While the editor doesn‚Äôt have all the niceties of the IDE‚Äôs you are used to, it‚Äôs very powerful in its own way. If you save code with a message name that does not appear in the image at all, Smalltalk will typically ask you if you want to define it right there. A lot of the things we ask a Language Server to do, Smalltalk just kind of does, because the image has access to everything.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the all-encompassing nature of the environment was also Smalltalk‚Äôs downfall. As more and more of the general computing environment became Unix and the ‚Äúsmall pieces loosely joined‚Äù philosophy, Smalltalk got harder and harder to integrate. Smalltalk isn‚Äôt a scripting language, it was late to develop connectivity to external databases, its model of team interaction is fundamentally different from Unix source control. The image-based system has some drawbacks ‚Äì you do get amazing access to the system, but it can be hard to tell where your code ends and the system begins. Code could depend on the state of the image in ways that were hard to replicate in deploys.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Did Ruby Take From Smalltalk?&lt;/head&gt;
    &lt;p&gt;Smalltalk‚Äôs legacy in Ruby is primarily the object model ‚Äì the idea that everything is an object and everything is manageable via method calls, and that message calls are evaluated at the point of call, as late as possible. Ruby takes that idea and translates it into a syntax that is more familiar to programmers used to C/Perl/Java.&lt;/p&gt;
    &lt;p&gt;I‚Äôm not sure this is exactly on point as far as Smalltalk‚Äôs influence on Ruby, but my Ruby style has always been very aggressive about creating new classes and objects. I‚Äôm quite confident that a reason for that style is that I came from Smalltalk first and not Java, Smalltalk style is much more amenable to small classes.&lt;/p&gt;
    &lt;p&gt;On my first largish Smalltalk project, users were simulating a chemical plant‚Äôs pipe system by placing tiles with pipes in them, and I frequently needed to do logic based on relative directions. I clearly remember creating a &lt;code&gt;Direction&lt;/code&gt; class with basically four live instances, &lt;code&gt;up&lt;/code&gt;, &lt;code&gt;down&lt;/code&gt;, &lt;code&gt;left&lt;/code&gt;, &lt;code&gt;right&lt;/code&gt;, and just enough logic inside to say that &lt;code&gt;up.turn_left&lt;/code&gt; equals &lt;code&gt;left&lt;/code&gt;, but &lt;code&gt;down.turn_left&lt;/code&gt; equals &lt;code&gt;right&lt;/code&gt;. It was useful enough that I remember how much fun it was to build it even  now, nearly thirty years later.&lt;/p&gt;
    &lt;p&gt;Of all the other programming languages I‚Äôve used, Ruby is the one that most clearly encourages that style of coding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45823831</guid><pubDate>Wed, 05 Nov 2025 15:24:35 +0000</pubDate></item><item><title>Norway reviews cybersecurity after remote-access feature found in Chinese buses</title><link>https://scandasia.com/norway-reviews-cybersecurity-after-hidden-remote-access-feature-found-in-chinese-buses/</link><description>&lt;doc fingerprint="fcf890b619964575"&gt;
  &lt;main&gt;
    &lt;p&gt;Norway has launched a cybersecurity review after public transport operator Ruter discovered that electric buses supplied by Chinese manufacturer Yutong contained hidden SIM cards enabling potential remote access.&lt;/p&gt;
    &lt;p&gt;According to Ruter, internal tests at a secure facility found Romanian SIM cards inside the buses, theoretically allowing the Chinese supplier to shut down vehicles or interfere via software updates. The transport operator stressed there is no evidence of misuse but said the discovery moves concerns ‚Äúfrom suspicion to concrete knowledge‚Äù.&lt;/p&gt;
    &lt;p&gt;Ruter has removed the SIM cards and is strengthening procurement rules, internal firewalls, and cloud-security requirements to ensure full local control over transport operations.&lt;/p&gt;
    &lt;p&gt;Norway‚Äôs Minister of Transport Jon-Ivar Nyg√•rd told national broadcaster NRK that the government is assessing supplier risks from countries outside Norway‚Äôs security alliances, noting the need to protect critical infrastructure.&lt;/p&gt;
    &lt;p&gt;Around 1,300 electric buses operate in Norway, including approximately 850 units from Yutong, with 300 running in Oslo and Akershus. Ruter said the likelihood of attempted interference remains low, but the situation underscores the growing cybersecurity challenges linked to foreign technology suppliers.&lt;/p&gt;
    &lt;p&gt;The case comes as Chinese electric buses are increasingly adopted across global markets, including Southeast Asia, raising wider questions about digital security and strategic dependencies in public transport systems.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs unlikely these buses would ever be misused,‚Äù Ruter CEO Bernt Reitan Jenssen said, ‚Äúbut we must take the risk seriously.‚Äù&lt;/p&gt;
    &lt;p&gt;Source: Carscoops&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45824658</guid><pubDate>Wed, 05 Nov 2025 16:18:01 +0000</pubDate></item><item><title>Dillo, a multi-platform graphical web browser</title><link>https://github.com/dillo-browser/dillo</link><description>&lt;doc fingerprint="9650cf58848088e4"&gt;
  &lt;main&gt;
    &lt;p&gt;Dillo is a multi-platform graphical web browser, known for its speed and small footprint, that is developed with a focus on personal security and privacy. It is built with the FLTK 1.3 GUI toolkit.&lt;/p&gt;
    &lt;p&gt;Screenshot of the Dillo Website rendered in Dillo:&lt;/p&gt;
    &lt;p&gt;To install Dillo follow the installation guide.&lt;/p&gt;
    &lt;p&gt;This repository contains mostly the original code of Dillo with some minor patches. Additional patches or pull requests are welcome.&lt;/p&gt;
    &lt;p&gt;See also other related forks: dillo-plus, dilloNG, D+ browser and Mobilized Dillo.&lt;/p&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;As of December 2023, the host &lt;code&gt;dillo.org&lt;/code&gt; is no longer under control
of Dillo developers. A copy of the old website is archived in
GitHub Pages and the Wayback Machine (May 2022).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826266</guid><pubDate>Wed, 05 Nov 2025 18:40:32 +0000</pubDate></item><item><title>The state of SIMD in Rust in 2025</title><link>https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d</link><description>&lt;doc fingerprint="3f28d332981d8b8c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The state of SIMD in Rust in 2025&lt;/head&gt;
    &lt;p&gt;If you‚Äôre already familiar with SIMD, the table below is all you need.&lt;/p&gt;
    &lt;p&gt;And if you‚Äôre not, you will understand the table by the end of this article!&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs SIMD? Why SIMD?&lt;/head&gt;
    &lt;p&gt;Hardware that does arithmetic is cheap, so any CPU made this century has plenty of it. But you still only have one instruction decoding block and it is hard to get it to go fast, so the arithmetic hardware is vastly underutilized.&lt;/p&gt;
    &lt;p&gt;To get around the instruction decoding bottleneck, you can feed the CPU a batch of numbers all at once for a single arithmetic operation like addition. Hence the name: ‚Äúsingle instruction, multiple data,‚Äù or SIMD for short.&lt;/p&gt;
    &lt;p&gt;Instead of adding two numbers together, you can add two batches or ‚Äúvectors‚Äù of numbers and it takes about the same amount of time.&lt;/p&gt;
    &lt;p&gt;On recent x86 chips these batches can be up to 512 bits in size, so in theory you can get an 8x speedup for math on &lt;code&gt;u64&lt;/code&gt; or a 64x speedup on &lt;code&gt;u8&lt;/code&gt;!&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction sets&lt;/head&gt;
    &lt;p&gt;Historically, SIMD instructions were added after the CPU architecture was already designed, so SIMD is an extension with its own marketing name on each architecture.&lt;/p&gt;
    &lt;p&gt;ARM calls theirs ‚ÄúNEON‚Äù, and all 64-bit ARM CPUs have it.&lt;/p&gt;
    &lt;p&gt;WebAssembly doesn‚Äôt have a marketing department, so they just call theirs ‚ÄúWebAssembly 128-bit packed SIMD extension‚Äù.&lt;/p&gt;
    &lt;p&gt;64-bit x86 shipped with one called ‚ÄúSSE2‚Äù which has basic instructions for 128-bit vectors, but later they added a whole menagerie of extensions on top of that, with SSE 4.2 adding more operations, AVX and AVX2 adding 256-bit vectors and AVX-512 adding 512-bit vectors.&lt;/p&gt;
    &lt;p&gt;The word ‚Äúlater‚Äù in the above paragraph creates a problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Does this CPU have that instruction?&lt;/head&gt;
    &lt;p&gt;If you‚Äôre running a program on an x86 CPU, it‚Äôs not a given that the CPU has any particular SIMD extension. So by default the compiler isn‚Äôt allowed to use instructions beyond SSE2 because that won‚Äôt work on all x86 CPUs.&lt;/p&gt;
    &lt;p&gt;There are two ways around this problem.&lt;/p&gt;
    &lt;p&gt;If you work for a company that only ever runs their binaries on their own servers or on a public cloud, you can just assert that they‚Äôre all recent enough to at least have AVX2 that was introduced over 10 years ago, and have the program crash or misbehave if it ever runs on anything without AVX2:&lt;/p&gt;
    &lt;code&gt;RUSTFLAGS='-C target-cpu=x86‚Äì64-v3' cargo build --release&lt;/code&gt;
    &lt;p&gt;However, if you are distributing the binaries for other people to run, that‚Äôs not really an option.&lt;/p&gt;
    &lt;p&gt;Instead you can do something called function multiversioning: compile the same function multiple times for different SIMD extensions, and when the program actually runs, check what features the CPU supports and select the appropriate version based on that.&lt;/p&gt;
    &lt;p&gt;Fortunately, this problem only exists on x86.&lt;/p&gt;
    &lt;p&gt;ARM made its NEON mandatory in all 64-bit CPUs and then didn‚Äôt bother expanding the width beyond 128 bits. (Technically SVE exists, but in 2025 it is still mostly on paper, and Rust support for it is still in progress).&lt;/p&gt;
    &lt;p&gt;WebAssembly makes you compile two different binaries, one with SIMD and one without, and use JavaScript to check if the browser supports SIMD.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solution space&lt;/head&gt;
    &lt;p&gt;There are four approaches to SIMD in Rust, in ascending order of effort:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Automatic vectorization&lt;/item&gt;
      &lt;item&gt;Fancy iterators&lt;/item&gt;
      &lt;item&gt;Portable SIMD abstractions&lt;/item&gt;
      &lt;item&gt;Raw intrinsics&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Automatic vectorization&lt;/head&gt;
    &lt;p&gt;The easiest approach to SIMD is letting the compiler do it for you.&lt;/p&gt;
    &lt;p&gt;It works surprisingly well, as long as you structure your code in a way that is amenable to vectorization. This article covers it:&lt;/p&gt;
    &lt;p&gt;You can check if it‚Äôs working with cargo-show-asm or godbolt.org, but your benchmarks are the ultimate judge of the results.&lt;/p&gt;
    &lt;p&gt;Sadly there is a limit on the complexity of the code that the compiler will vectorize, and it may change between compiler versions. If something vectorizes today that doesn‚Äôt necessarily mean it still will in a year from now.&lt;/p&gt;
    &lt;p&gt;The other drawback of this method is that the optimizer won‚Äôt even touch anything involving floats (&lt;code&gt;f32&lt;/code&gt; and &lt;code&gt;f64&lt;/code&gt; types). It‚Äôs not permitted to change any observable outputs of the program, and reordering float operations may alter the result due to precision loss. (There is a way to tell the compiler not to worry about precision loss, but it‚Äôs currently nightly-only).&lt;/p&gt;
    &lt;p&gt;So right now, if you need to process floats, autovectorization is a no-go unless you can use nightly builds of the Rust compiler.&lt;/p&gt;
    &lt;p&gt;(Floats are cursed even without SIMD. Something as simple as summing an array of them in a usable way turns out to be really hard).&lt;/p&gt;
    &lt;p&gt;There is no built-in way to multiversion functions, but the multiversion crate works great with autovectorization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy iterators&lt;/head&gt;
    &lt;p&gt;Just like rayon lets you run your iterators in parallel by swapping &lt;code&gt;.iter()&lt;/code&gt; with &lt;code&gt;.par_iter()&lt;/code&gt;, there have been attempts to do the same for SIMD. After all, what is SIMD but another kind of parallelism?&lt;/p&gt;
    &lt;p&gt;This is the approach that the faster crate takes. That crate has been abandoned for years, and it doesn‚Äôt look like this approach has panned out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Portable SIMD abstractions&lt;/head&gt;
    &lt;p&gt;The idea is to let you write your algorithm by explicitly operating on chunks of data, something like &lt;code&gt;[f32; 8]&lt;/code&gt; but wrapped in a custom type, and then provide custom implementations of operations like &lt;code&gt;+&lt;/code&gt; that compile down into SIMD instructions.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;std::simd&lt;/code&gt; is exactly that. It supports all instruction sets LLVM supports, so its platform support is unparalleled. It pairs well with the multiversion crate. Sadly it‚Äôs nightly-only and will remain such for the foreseeable future, so it‚Äôs unusable in most situations.&lt;/p&gt;
    &lt;p&gt;The wide crate is a mature, established option. It supports NEON, WASM and all the x86 instruction sets. But it doesn‚Äôt support multiversioning at all, save for very exotic and limited approaches like cargo-multivers.&lt;/p&gt;
    &lt;p&gt;The pulp crate is a great design with built-in multiversioning, and is quite mature and complete. It powers faer, so its performance is clearly proven. The drawbacks are that it doesn‚Äôt support WASM, and that on x86 it only supports targeting AVX2 and AVX-512 but not the older extensions. But AVX2 was introduced in 2012 and in the Steam hardware survey 95% systems have it, so that might not be a big deal.&lt;/p&gt;
    &lt;p&gt;The macerator crate is a fork of pulp with vastly expanded instruction set support. It supports all x86 extensions, WASM, NEON, and even the LoongArch SIMD extensions. It‚Äôs used only by burn-ndarray, and even there it‚Äôs an optional dependency. It sounds great on paper, but it‚Äôs oddly obscure and therefore unproven. I‚Äôd probably write code using pulp, then replace it with macerator and see if everything still works and runs as fast as it should.&lt;/p&gt;
    &lt;p&gt;The fearless_simd crate is largely a copy of pulp‚Äôs design made for use in vello. It‚Äôs far less mature than pulp, but it‚Äôs under active development. As of this writing it supports NEON, WASM and SSE4.2, but not the newer x86 extensions. Seems too immature just yet, but something to keep an eye on.&lt;/p&gt;
    &lt;p&gt;simdeez is a rather old crate that supports all instruction sets except AVX-512 and comes with built-in multiversioning. What gives me pause is that despite existing for many years, it‚Äôs still barely used. Everyone else who needed SIMD built their own instead of using it. And its README says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Currently things are well fleshed out for i32, i64, f32, and f64 types.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I guess the other types aren‚Äôt complete?&lt;/p&gt;
    &lt;p&gt;TL;DR: use &lt;code&gt;std::simd&lt;/code&gt; if you don‚Äôt mind nightly, &lt;code&gt;wide&lt;/code&gt; if you don‚Äôt need multiversioning, and otherwise &lt;code&gt;pulp&lt;/code&gt; or &lt;code&gt;macerator&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If it‚Äôs not 2025 when you‚Äôre reading this, check out &lt;code&gt;fearless_simd&lt;/code&gt;, because &lt;code&gt;std::simd&lt;/code&gt; is still in nightly in your glorious future, isn‚Äôt it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Raw intrinsics&lt;/head&gt;
    &lt;p&gt;If you want to get really close to the metal, there are always the raw intrinsics, just one step removed from the processor instructions.&lt;/p&gt;
    &lt;p&gt;The problem looming over any use of raw intrinsics is that you have to manually write them for every platform and instruction set you‚Äôre targeting. Whereas &lt;code&gt;std::simd&lt;/code&gt; or &lt;code&gt;wide&lt;/code&gt; let you write your logic once and compile it down to the assembly automatically, with intrinsics you have to write a separate implementation for every single platform and instruction set (SSE, AVX, NEON‚Ä¶) you care to support. That‚Äôs a lot of code!&lt;/p&gt;
    &lt;p&gt;It‚Äôs really not helped by the fact that they are all named something like &lt;code&gt;_mm256_srli_epi32&lt;/code&gt; and your code ends up as a long list of calls to these arcanely named functions. And wrappers that help readability introduce their own problems, such as clashes with multiversioning or unsafe code or arcane macros.&lt;/p&gt;
    &lt;p&gt;You also have to build your own multiversioning. Or rather, you have to manually dispatch to the dedicated implementation you have manually written for each instruction set. &lt;code&gt;std::is_x86_feature_detected!&lt;/code&gt; macro takes care of the feature detection, but it is somewhat slow. In some cases it is beneficial to detect available features exactly once and then cache the results, but you have to implement that manually too.&lt;/p&gt;
    &lt;p&gt;On the bright side, this year writing intrinsics got markedly less awful. Most of them are no longer &lt;code&gt;unsafe&lt;/code&gt; to call in Rust 1.86 and later, and the safe_unaligned_simd crate provides safe wrappers for the rest.&lt;/p&gt;
    &lt;p&gt;So at least this approach is no longer &lt;code&gt;unsafe&lt;/code&gt; on top of all the other problems it has!&lt;/p&gt;
    &lt;head rend="h2"&gt;Which one is right for you?&lt;/head&gt;
    &lt;p&gt;The right tool for the job ultimately depends on the use case.&lt;/p&gt;
    &lt;p&gt;Want zero dependencies and little up-front hassle? Autovectorization. Porting existing C code or targeting very specific hardware? Intrinsics. Anything else? Portable SIMD abstraction.&lt;/p&gt;
    &lt;p&gt;And now that you made it this far, you can understand the table at the top of the article, which will help guide your decision!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826348</guid><pubDate>Wed, 05 Nov 2025 18:45:57 +0000</pubDate></item><item><title>Internet Archive's legal fights are over, but its founder mourns what was lost</title><link>https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/</link><description>&lt;doc fingerprint="ca919bd5fba6537b"&gt;
  &lt;main&gt;
    &lt;p&gt;Last month, the Internet Archive‚Äôs Wayback Machine archived its trillionth webpage, and the nonprofit invited its more than 1,200 library partners and 800,000 daily users to join a celebration of the moment. To honor ‚Äúthree decades of safeguarding the world‚Äôs online heritage,‚Äù the city of San Francisco declared October 22 to be ‚ÄúInternet Archive Day.‚Äù The Archive was also recently designated a federal depository library by Sen. Alex Padilla (D-Calif.), who proclaimed the organization a ‚Äúperfect fit‚Äù to expand ‚Äúaccess to federal government publications amid an increasingly digital landscape.‚Äù&lt;/p&gt;
    &lt;p&gt;The Internet Archive might sound like a thriving organization, but it only recently emerged from years of bruising copyright battles that threatened to bankrupt the beloved library project. In the end, the fight led to more than 500,000 books being removed from the Archive‚Äôs ‚ÄúOpen Library.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWe survived,‚Äù Internet Archive founder Brewster Kahle told Ars. ‚ÄúBut it wiped out the Library.‚Äù&lt;/p&gt;
    &lt;p&gt;An Internet Archive spokesperson confirmed to Ars that the archive currently faces no major lawsuits and no active threats to its collections. Kahle thinks ‚Äúthe world became stupider‚Äù when the Open Library was gutted‚Äîbut he‚Äôs moving forward with new ideas.&lt;/p&gt;
    &lt;head rend="h2"&gt;History of the Internet Archive&lt;/head&gt;
    &lt;p&gt;Kahle has been striving since 1996 to transform the Internet Archive into a digital Library of Alexandria‚Äîbut ‚Äúwith a better fire protection plan,‚Äù joked Kyle Courtney, a copyright lawyer and librarian who leads the nonprofit eBook Study Group, which helps states update laws to protect libraries.&lt;/p&gt;
    &lt;p&gt;When the Wayback Machine was born in 2001 as a way to take snapshots of the web, Kahle told The New York Times that building free archives was ‚Äúworth it.‚Äù He was also excited that the Wayback Machine had drawn renewed media attention to libraries.&lt;/p&gt;
    &lt;p&gt;At the time, law professor Lawrence Lessig predicted that the Internet Archive would face copyright battles, but he also believed that the Wayback Machine would change the way the public understood copyright fights.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826500</guid><pubDate>Wed, 05 Nov 2025 18:59:39 +0000</pubDate></item><item><title>New gel restores dental enamel and could revolutionise tooth repair</title><link>https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826995</guid><pubDate>Wed, 05 Nov 2025 19:44:49 +0000</pubDate></item></channel></rss>