<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 14 Jan 2026 19:37:46 +0000</lastBuildDate><item><title>I Hate GitHub Actions with Passion</title><link>https://xlii.space/eng/i-hate-github-actions-with-passion/</link><description>&lt;doc fingerprint="8d74a1776b070ae6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Hate Github Actions with Passion&lt;/head&gt;
    &lt;p&gt;I can’t overstate how much I hate GitHub Actions. I don’t even remember hating any other piece of technology I used. Sure, I still make fun of PHP that I remember from times of PHP41, but even then I didn’t hate it. Merely I found it subpar technology to other emerging at the time (like Ruby on Rails or Django). And yet I hate GitHub Actions.&lt;/p&gt;
    &lt;p&gt;With Passion2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Road to Hell&lt;/head&gt;
    &lt;p&gt;Day before writing these words I was implementing &lt;code&gt;build.rs&lt;/code&gt; for my tmplr project. To save you a click - it is a file/project scaffold tool with human readable (and craftable) template files. I (personally) use it very often, given how easy it is to craft new templates, by hand or with aid of the tool, so check it out if you need a similar tool.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;build.rs&lt;/code&gt; used &lt;code&gt;CUE&lt;/code&gt; to generate &lt;code&gt;README.md&lt;/code&gt;, &lt;code&gt;CHANGELOG.md&lt;/code&gt; and also a version/help file to guarantee consistency. It was fun thing to do, it took approx. 1.5h and I even wrote an article about it. For myself and future generations.&lt;/p&gt;
    &lt;p&gt;I was happy with the results and didn’t check CI output which, quite unsurprisingly, failed. I was using &lt;code&gt;cue&lt;/code&gt; binary inside &lt;code&gt;build.rs&lt;/code&gt; and without it build simply couldn’t progress. When I woke up next day and saw e-mail from CI notifying me about failed build I immediatelly knew my day isn’t going to start with puppies and rainbows.&lt;/p&gt;
    &lt;p&gt;It took couple attempts to search and push GitHub Action that would install &lt;code&gt;CUE&lt;/code&gt; and then I got the worst of the worst results: One system in matrix failing to build.&lt;/p&gt;
    &lt;p&gt;A word of explanation. I’m building &lt;code&gt;tmplr&lt;/code&gt; for 4 platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux ARM&lt;/item&gt;
      &lt;item&gt;macOS ARM&lt;/item&gt;
      &lt;item&gt;Linux x86_64&lt;/item&gt;
      &lt;item&gt;macOS x86_64&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Makes sense, right? Even though my user base can be counted on a fingers of one-arm-less and second-arm-hook-equipped pirate, it’s still a thing “One Should Do”.&lt;/p&gt;
    &lt;p&gt;And with all that - Linux ARM failed with “command can’t be found”. &lt;code&gt;CUE&lt;/code&gt; installed and ran nicely for all other 3 targets, but for some reason it failed for Linux ARM.&lt;/p&gt;
    &lt;p&gt;In case you don’t care about why I hate GitHub but your mind started to wonder to “what went wrong” let me tell you; because I know.&lt;/p&gt;
    &lt;p&gt;So supposedly cross build that happens in matrix is heavily isolated. When I install &lt;code&gt;CUE&lt;/code&gt; I install it only on x86_64 Linux host and macOS ARM host. macOS has zero issues running x86_64 binary and no issues are raised when Linux x86_64 tries to run x86_64 binary. But GitHub Actions is nice enough to hide x86_64 binary from arm64 runner, so that it won’t break.&lt;/p&gt;
    &lt;p&gt;Thank you GitHub Actions. What would’ve I done without you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Broken Loop&lt;/head&gt;
    &lt;p&gt;And so my least favorite feedback loop started and went like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Search for possible fix&lt;/item&gt;
      &lt;item&gt;Change &lt;code&gt;ci.yml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;jj squash --ignore-immutable &amp;amp;&amp;amp; jj git push&lt;/code&gt;3&lt;/item&gt;
      &lt;item&gt;Open “Actions” tab&lt;/item&gt;
      &lt;item&gt;Open latest run&lt;/item&gt;
      &lt;item&gt;Open Linux ARM run&lt;/item&gt;
      &lt;item&gt;Wait couple of seconds&lt;/item&gt;
      &lt;item&gt;Hate Life&lt;/item&gt;
      &lt;item&gt;Offer the Universe choice words it won’t soon forget&lt;/item&gt;
      &lt;item&gt;Rinse &amp;amp; repeat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I got quite efficient when it comes to points 8 and 9 but otherwise the whole loop still took around 2-3 minutes to execute.&lt;/p&gt;
    &lt;p&gt;FOR. A. SINGLE. CHANGE.&lt;/p&gt;
    &lt;p&gt;Yes. For a single change. Like having an editor with 2 minute save lag, pushing commit using program running on cassette tapes4 or playing chess over snail-mail. It’s 2026 for Pete’s sake, and we5 won’t tolerate this behavior!&lt;/p&gt;
    &lt;p&gt;Now of course, in some Perfect World, GitHub could have a local runner with all the bells and whistles. Or maybe something that would allow me to quickly check for progress upon the push6 or even something like a “scratch commit”, i.e. a way that I could testbed different runs without polluting history of both Git and Action runs.&lt;/p&gt;
    &lt;p&gt;But no such perfect world exists and one is at the whim of heartless YAML-based system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Breaking off&lt;/head&gt;
    &lt;p&gt;I suffered only 30 minutes of such loops. Could’ve done it for longer but I was out of colorful language to use and felt without it the process just isn’t the same.&lt;/p&gt;
    &lt;p&gt;There is a wise saying in the internet that goes like:&lt;/p&gt;
    &lt;p&gt;For the love of all that is holy, don’t let GitHub Actions manage your logic. Keep your scripts under your own damn control and just make the Actions call them!&lt;/p&gt;
    &lt;p&gt;This is what everyone should do. This is what I did.&lt;/p&gt;
    &lt;p&gt;I deleted &lt;code&gt;build.rs&lt;/code&gt; (with a sliver of sadness because it was really nice - but sacrifices had to be made). I moved all the generation from &lt;code&gt;build.rs&lt;/code&gt; to GNU Makefile, committed the darn files into repository, reverted changes to CI and called it a day. Problem solved.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exit Code: 0&lt;/head&gt;
    &lt;p&gt;GitHub Actions, Friends &amp;amp; Gentlefolk, is the reason why we can’t have (some) nice things. I can’t count how many hours I’ve lost debugging the runners or trying to optimize the build process. It’s a sorry process every single time, a time that would be better spent elsewhere.&lt;/p&gt;
    &lt;p&gt;And yet there are some benefits, like macOS builds that would be quite hard to get otherwise. I don’t know any other system that would be easier to setup than GitHub Actions (if you know one, let me know) but it seems there’s no escape.&lt;/p&gt;
    &lt;p&gt;We are all doomed to GitHub Actions.&lt;/p&gt;
    &lt;p&gt;…but at least I dodged the bullet early.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;And “PHP: Training Wheels Without a Bike” is still in Top 10 of my favorite memes. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That’s a capitalized Passion which is one degree above regular passion. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I’m using Jujutsu, this command effectively merges changes in the latest commit (&lt;/p&gt;&lt;code&gt;master&lt;/code&gt;in my case) and then pushes it out. ↩︎&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Long time ago, in Atari times, loading programs (and games) was done from cassette tapes. It took couple minutes and process was so temperamental that breathing or any movement in the room were strictly verboten. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;By “we” I mean “I”. But what would be a drama without little dramatism? ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;It is possible to script&lt;/p&gt;&lt;code&gt;gh&lt;/code&gt;to do exactly that, but that means another piece of code I need to write ↩︎&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Przemysław Alexander Kamiński &lt;lb/&gt; vel &lt;code&gt;xlii&lt;/code&gt; vel &lt;code&gt;exlee&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Powered by hugo and hugo-theme-nostyleplease.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46614558</guid><pubDate>Wed, 14 Jan 2026 10:53:13 +0000</pubDate></item><item><title>Show HN: Tiny FOSS Compass and Navigation App (&lt;2MB)</title><link>https://github.com/CompassMB/MBCompass</link><description>&lt;doc fingerprint="fb8ef1529ab5c981"&gt;
  &lt;main&gt;
    &lt;p&gt;MBCompass is a modern, free, and open-source compass and navigation app without ads, IAP, or tracking. Built with Jetpack Compose, it supports compass and navigation features while being lightweight and simple.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Not just a compass. Not a map app.&lt;/p&gt;
      &lt;p&gt;MBCompass bridges the gap between a compass and a full navigation app - shows direction and live location without using hundreds of MBs of storage or privacy trade-offs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Displays clear cardinal directions with both magnetic north and true north.&lt;/item&gt;
      &lt;item&gt;Live GPS location tracking on OpenStreetMap.&lt;/item&gt;
      &lt;item&gt;Shows magnetic field strength in µT.&lt;/item&gt;
      &lt;item&gt;Sensor fusion for improved accuracy (accelerometer, magnetometer, gyroscope).&lt;/item&gt;
      &lt;item&gt;Light and dark theme support controlled via Settings.&lt;/item&gt;
      &lt;item&gt;Keeps screen on during navigation.&lt;/item&gt;
      &lt;item&gt;Landscape orientation support.&lt;/item&gt;
      &lt;item&gt;Built with Jetpack Compose and Material Design.&lt;/item&gt;
      &lt;item&gt;Runs on Android 5.0+&lt;/item&gt;
      &lt;item&gt;No ads, no in-app purchases, no tracking.&lt;/item&gt;
      &lt;item&gt;Learn more on the website&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MBCompass v2.0 Design Proposal (Upcoming)&lt;/p&gt;
    &lt;p&gt;MBCompass v1.1.12 Redesign Proposal, featuring a refreshed UI with a GPS Speedometer, True AMOLED Dark Mode, and more visual improvements for a better Android experience.&lt;/p&gt;
    &lt;p&gt;(Note: The design is a reference concept; actual implementation may vary to ensure optimal performance and Android best practices.)&lt;/p&gt;
    &lt;p&gt;MBCompass has gained recognition from the global developer community:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;#13 Product of the Day on Product Hunt&lt;/item&gt;
      &lt;item&gt;Featured in two consecutive issues of Android Weekly&lt;/item&gt;
      &lt;item&gt;Reached the front page of Hacker News&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Location permission is only used to detect the current location on the map.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MBCompass is open for community translations on Weblate!&lt;lb/&gt; You can help make the app accessible to more users by translating it into your language.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! If you encounter bugs or have feature suggestions, please open an issue or submit a pull request. See Contributing Guidelines for details.&lt;/p&gt;
    &lt;p&gt;Open-source projects couldn't survive in the long run without donations or funding.&lt;/p&gt;
    &lt;p&gt;MBCompass is a fully open-source project - free of ads, trackers, or in-app purchases. If you find it useful, consider supporting its continued development and maintenance:&lt;/p&gt;
    &lt;p&gt;Find more info on MBCompass page&lt;/p&gt;
    &lt;p&gt;Your support helps ensure the project stays sustainable and continues to improve for everyone. Thank you!&lt;/p&gt;
    &lt;p&gt;MBCompass is Free Software: you can use, study, share, and improve it at your will. You may use, modify, and redistribute this project only if your modifications remain open-source under the same license.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Proprietary use, commercial redistribution, or publishing modified versions with ads or tracking is strictly prohibited under GPLv3 or later.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See more information here.&lt;/p&gt;
    &lt;p&gt;Compass rose : MBCompass rose © 2025 by Mubarak Basha is licensed under CC BY-SA 4.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46614688</guid><pubDate>Wed, 14 Jan 2026 11:09:35 +0000</pubDate></item><item><title>Coverage Cat (YC S22) Is Hiring a Fractional Operations Specialist</title><link>https://www.coveragecat.com/careers/operations/fractional-operations-specialist</link><description>&lt;doc fingerprint="ba1bf654e18ec9ec"&gt;
  &lt;main&gt;
    &lt;p&gt;Coverage Cat is seeking a team member with high attention to detail that's looking for a fractional role at a high growth startup.&lt;/p&gt;
    &lt;p&gt;You’ll support the team with a variety of administrative, back-office, and automation operations as we continue to grow the world's first AI-native insurance broker.&lt;/p&gt;
    &lt;p&gt;New grads as well as experienced backoffice and operations support professionals that are seeking a fractional role are encouraged to apply.&lt;/p&gt;
    &lt;p&gt;Please, only apply via the YCombinator Work-at-a-Startup application button above. Emailed applications will be discarded.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46615078</guid><pubDate>Wed, 14 Jan 2026 12:00:11 +0000</pubDate></item><item><title>Lago (Open-Source Billing) is hiring across teams and geos</title><link>https://news.ycombinator.com/item?id=46615235</link><description>&lt;doc fingerprint="2f4dd972577e0ff0"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Here's the official job board: &lt;/p&gt;https://www.getlago.com/hiring&lt;p&gt;We're open-source, mainly use Ruby. Billing is interesting because it lays the ground for the monetization system of any company. Because we're heavily developer-focus, we fit very well with complex use cases for either infra companies and/or enteprises. Companies like Groq, Mistral, CoreWeave or PayPal chose Lago.&lt;/p&gt;&lt;p&gt;We're now heavily investing in step 2: on leveraging the usage and billing data to make the RevOps stack make more sense. Examples: https://github.com/getlago/lago-agent-toolkit or https://www.getlago.com/platform/ai&lt;/p&gt;&lt;p&gt;If this resonates, reach out to talent@getlago.com (whether the job is listed or not)!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46615235</guid><pubDate>Wed, 14 Jan 2026 12:25:59 +0000</pubDate></item><item><title>Edge of Emulation: Game Boy Sewing Machines (2020)</title><link>https://shonumi.github.io/articles/art22.html</link><description>&lt;doc fingerprint="2f04d8144da5cfdf"&gt;
  &lt;main&gt;
    &lt;p&gt;New threads&lt;/p&gt;
    &lt;p&gt;It's been quite a long journey so far, but today marks the 3rd anniversary of the Edge of Emulation series of articles. When I first worked on emulating the Barcode Taisen Bardigun scanner back in 2017, I actually had no idea how much more I'd be able to do. My goal was to finish a list, researching and documenting one item at a time, but I didn't know if I even possessed the right skills to achieve anything. In the past few the years, I've met a fair amount of challenges and faced a number of difficult problems. Nevertheless, I've somehow managed overcome each of these obstacles given enough time, determination, and the help of friends and colleagues. Some devices are really simple to figure out and only take a day or two to properly emulate. Others, however, prove stubbornly difficult. The subject of this article in particular really kicked my ass.&lt;/p&gt;
    &lt;p&gt;In early 2000, the Japanese sewing company Jaguar released a machine with one very curious feature. Rather than having designs built-into the sewing machine, the Jaguar JN-100 (aka "nuyell") connected with a Game Boy via Link Cable to receive stitching instructions. The software, called Raku x Raku Mishin, came on a regular black Game Boy cartridge and handled transferring data to the JN-100. Users could then program the machine to stitch various patterns, buttonholes, kana, lettering, and even short custom paths. An American company called Singer found the JN-100 a tempting business opportunity; they later agreed release a near exact copy in the United States under their brand, the Singer IZEK 1500. In 2001, Jaguar made a second model called the JN-2000 (aka "nuotto") which boasted improved stitching speed and a dedicated embroidery arm called the EM-2000. While the JN-2000 was backwards compatible with the JN-100's Game Boy cartridge, 3 new pieces of software were made exclusively for the newer JN-2000's embroidery functions. Although Jaguar saw notable success with their products, Singer found less reception to the IZEK-1500 in the US. There were plans to make a newer version that handled embroidery as well, but Singer never fully realized those plans. As such, the JN-2000's ability to embroider clothes with Mario-themed artwork remained exclusive to Japan.&lt;/p&gt;
    &lt;p&gt;Some may laugh at how bizarre it sounds to combine Game Boys and a sewing machines, yet all 3 models are rather historically important for both gaming and home-based sewing. Although industrial sewing machines already had programmable stitching for years, the consumer market lagged behind in terms of options and price. Today, cheap digitized sewing is the norm, but at the turn of the century, Jaguar sparked a sort of revolution by giving consumers affordable and easy to use equipment. Using a Game Boy as the primary interface reduces complexity (there are only a few buttons, menus can be colorful, and you can display as much information as you want, even tutorials). It also saves on cost by using known components instead of creating hardware from scratch. Furthermore, it's not uncommon to feed sewing machines instructions from an external source. Current sewing machines often connect to PCs via USB to transfer embroidery designs, and perhaps smartphone apps communicating over Bluetooth represents the future. At any rate, Nintendo's handheld system became the first (and only???) such device to work in conjunction with a sewing machine and did its part to bring digital stitching and embroidery to the masses. Though it seems like a strange marriage, both sides work well together in practice.&lt;/p&gt;
    &lt;p&gt;Even so, these sewing machines are among the most exotic and fascinating of Game Boy accessories. They demonstrate just how far the humble Game Boy could expand beyond gaming. Unfortunately, while we know much about the history of the Jaguar and Singer machines, how exactly they operated remained a mystery for decades. Ever since I learned about them, I couldn't help but wonder what secrets were buried inside. Technically speaking, neither these sewing machines nor their software are video games. Nevertheless, they're all simply too culturally important to just ignore. Rather than let their story disappear over the ages, I decided to try my hand at preserving them. Now, I've emulated some pretty wild things on the Game Boy: motion-based infrared toys, sonar-enabled cartridges, Amiibo-like figurines, and robots most recently. But emulating a sewing machine? That's something else completely. I mean, you'd have to be crazy, right?&lt;/p&gt;
    &lt;p&gt;Needle in a haystack&lt;/p&gt;
    &lt;p&gt;Properly studying these machines requires physical access, which in turn means making quite a few investments. Not only are there 3 distinct models (JN-100, JN-2000, IZEK 1500), but each on their own costs a sizable sum. The JN-100 and IZEK 1500 units are uncommon but not necessarily rare, yet a handful of complications raise their prices. An IZEK 1500 typically runs anywhere from $150 to $250 USD on average for just the hardware alone, but adding original material such as the VHS instructional tape, the Game Boy software, or even the box it was packaged in will hike the value by hundreds of dollars. Shipping, even domestically, accounts for another $25 to $50 USD. JN-100s typically go for far less on Japanese buying sites. Many are labeled as "junk" and can go for $20 to $50 USD. However, international shipping can easily double or triple that amount.&lt;/p&gt;
    &lt;p&gt;The JN-2000 is truly rare, given that it probably sold in smaller quantities. While a dozen or so auctions for the other two machines occur every few months, only a handful of JN-2000s appear to be sold each year. The damage to a collector's wallet varies wildly, from about $30, $160, $400, or even $1500 depending on completeness. The most expensive one I've seen to date asked for $5100, featuring a mint condition JN-2000, EM-2000, two copies of Raku x Raku Cut Shuu/Moji and one copy of Mario Family (which is probably the rarest Game Boy Color software out there). Needless to say, acquiring all three sewing machines took a fair amount of cash, patience, and luck. Thankfully I imported both Jaguar models well before COVID-19 struck. The virus has disrupted many forms of transportation, strangling shipping options, and increasing fees (sometimes exponentially in fact, looking at you DHL).&lt;/p&gt;
    &lt;p&gt;As previously mentioned, the Jaguar JN-100 and the Singer IZEK-1500 are near perfect copies of one another in almost every regard. The only obvious differences are their power cords (retractable on the JN-100 versus one that plugs into the IZEK-1500) and the color schemes. While the JN-100 has 6 variants, the IZEK-1500 comes only in blue. Both machines have semi-transparent plastic parts that call to mind some of the iMac G3 aesthetic. The JN-2000 has a completely different body style, similar to other Singer products like many Futura models. It has clear plastic segments as well, although it was only ever produced in red. The frame of the machine has an empty cradle where a Game Boy can be placed while sewing. Most notably, part of the JN-2000 slides away to reveal a port where the EM-2000 embroidery arm connects. All 3 units have a Link Cable built-in.&lt;/p&gt;
    &lt;p&gt;A total of 5 compatible software titles were made for these machines. The first, "Raku x Raku Mishin" came with every JN-100. It focuses on stitching preset and custom patterns, buttonholes, some Latin characters, kana, and a few kanji. When the IZEK-1500 came to the US, the name changed to "Sewing Machine Operating Software" however its core functionality remained unchanged. Instead of kana and kanji, however, support for the Latin alphabet was expanded along with a few additional styles (cursive and outlined letters). Apparently a European version exists, but details are scarce. "Raku x Raku Moji" deals with embroidery of katakana, hiragana, some Latin characters and symbols, and a number of kanji. Unlike Raku x Raku Mishin, these designs are much more elaborate, composed of hundreds of stitches instead of 20 or 30. "Raku x Raku Cut Shuu" deals with embroidery of some cute if generic artwork, e.g. a rocket ship, some flowers, and a bunch of cartoon animals. The last cartridge, "Jaguar Mishin Sashi Senyou Soft: Mario Family" is much the same, however, all of the artwork is Mario-themed. Princess Peach, Mario, Luigi, Wario, Yoshi, and several others appear, although Bowser is surprisingly absent.&lt;/p&gt;
    &lt;p&gt;My initial research into these sewing machines began exactly one year ago at the start of May 2019. Usually I spend only a few weeks on an item before cracking it. At most I'll take a few months, analyzing and running tests every other day until I figure things out. I really thought I'd be able to get most of the work done in a weekend or two. If things had gone according to plan, this article would have been written in 2019. Unfortunately, I spent far longer than just a couple of days. These sewing machines presented me with a puzzle the likes of which I'd never dealt with before and genuinely challenged me on multiple occassions. While I wouldn't call them the most difficult things to reverse engineer they certainly proved to be the most frustrating. What I expected to be a relative cakewalk turned into something much more than that.&lt;/p&gt;
    &lt;p&gt;Sew close, yet sew far&lt;/p&gt;
    &lt;p&gt;The Singer IZEK 1500 was the easiest machine to acquire, so it was the first one I looked at. To begin, I created a very simple ROM hack of Sewing Machine Operation Software that recorded every serial transfer after a serial interrupt. Interestingly enough, I didn't see any relevant data, just repeating patterns of two values: &lt;code&gt;0x00&lt;/code&gt; and &lt;code&gt;0xFF&lt;/code&gt;. Running the ROM through GBE+'s debugger revealed that not every transfer was supposed to trigger a serial interrupt; consequently the ROM hack was missing crucial information. Unlike every other Game Boy accessory ever made, the IZEK 1500 switches between sending data via an internal and external clock. Essentially, it switches back and forth between acting as master and slave when communicating with the Game Boy (and the handheld switches too, always the opposite to match the machine). The data the Game Boy sends to the IZEK 1500 is always done via an external clock, so the sewing machine controls the rate at which bits are transferred. Serial interrupts are disabled via software for these transfers, yet GBE+ could see them just fine and print out a log for me to review.&lt;/p&gt;
    &lt;p&gt;The data captured by the emulator looked to be a packet sent to the sewing machine with instructions on how to stitch a pattern. Immediately, I recognized it had a header, followed by a body containing what looked to be XY coordinate pairs for stitching points and some kind of checksum value all the way at the end. As far as I could tell at the time, a pattern was made simply by shifting the stitching point up, down, left, or right by different amounts. In order for GBE+ to properly emulate these sewing machines, it had to recreate the stitching as pixels on a screen. All it needed to do was take the XY coordinates from the packet data and start drawing lines, right? Pretty simple stuff, and perfectly straightforward. Easy peasy.&lt;/p&gt;
    &lt;p&gt;The first couple of patterns, labeled &lt;code&gt;A-001&lt;/code&gt; through &lt;code&gt;A-010&lt;/code&gt; were lines that moved straight down with changes in the X coordinate sometimes to make diagonals. I copied some line drawing code from my NDS 3D renderer, gave it the coordinates from the packet, and saved the results to a BMP file. The output from these patterns matched the previews given on the Game Boy screen. When it came to the rest of the patterns though, things quickly broke down. A prime example of this failure was pattern &lt;code&gt;B-007&lt;/code&gt;. Rather than zig-zagging like the others, it went straight sideways and went vertically up. I was treating every Y coordinate as positive to move downward since I didn't know how the IZEK 1500 handled negative numbers. It should have been relatively obvious, say like all negative coordinates have Bit 7 set high or something, while all positive numbers have Bit 7 set low. It was nothing like that at all.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;---------------------------------------------------------
X COORDINATE	| Y COORDINATE		| MOVEMENT	
---------------------------------------------------------
0x01		| 0x0D			| DOWN		
0x01		| 0x0C			| DOWN		
0x01		| 0x14			| RIGHT		
0x0E		| 0x1C			| UP		
0x0E		| 0x14			| RIGHT		
0x1B		| 0x0C			| DOWN		
0x1B		| 0x0C			| DOWN		
0x1B		| 0x14			| LEFT		
0x01		| 0x0D			| DOWN		
---------------------------------------------------------&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I used a test piece of fabric and observed each movement to verify what each XY pair was supposed to do. It's easy enough to see that the X coordinates behave normally, gradually shifting from left to right by increasing, then suddenly shifting back to the left to restart the pattern. The Y coordinates are doing something else, however. At first glance, they're all over the place, although that's not quite unexpected considering the pattern goes up and down a bit. Still, the Y coordinates looked very bizarre to me when I started my investigation. One important detail to know is that while the X coordinates operate in terms of absolute positions, the Y coordinates don't. The width of a pattern only go so far, (&lt;code&gt;0x00&lt;/code&gt; to &lt;code&gt;0x1F&lt;/code&gt;), because the needle can only physically move that much. The length of a pattern goes as long as there's fabric to keep feeding into the machine.&lt;/p&gt;
    &lt;p&gt;Y coordinates were quite the hassle to correctly interpret. In a sane world, values like &lt;code&gt;0x08&lt;/code&gt; would move the fabric down by 8 units, &lt;code&gt;0x18&lt;/code&gt; would move the fabric up 8 units, and &lt;code&gt;0x00&lt;/code&gt; would stay put. Ideally, it would look like a 5-bit version of One's complement. Just seems intuitive, right? The difference between up and down would be flipping Bit 4 on or off, and zero would maintain the current vertical position. That's what I was expecting, at least. The reality was much more difficult to deal with. In the example of Pattern B-007, it has a couple of vertical lines, but no Y coordinate even comes close to being zero. At the very least, you'd think that a horizontal line would be represented by having 2 different X coordinates and 2 Y coordinates of the same value, but that too was not the case.&lt;/p&gt;
    &lt;p&gt;I was so preoccupied with how I felt the coordinates should have looked like that I failed to notice how the coordinates actually worked. I spent months trying to come up with all kinds of crazy rules to describe when the machines made horizontal, diagonal, and vertical lines for all other patterns. A lot of hours were wasted trying to formulate every possible scenario of X and Y coordinates and what kinds of lines they should have drawn. In hindsight, I missed several obvious clues that could have simplified my work.&lt;/p&gt;
    &lt;p&gt;One day, while reviewing all of the rules I'd compiled, I suddenly noticed something very curious about horizontal lines. They all seemed to use &lt;code&gt;0x14&lt;/code&gt; as the Y coordinate. Why use that value to signify no vertical change though? Why use that value instead of an actual zero? Another thought struck my mind: what if values less than &lt;code&gt;0x14&lt;/code&gt; moved down, and values greater than that moved up? Suddenly almost every single pattern made perfect sense. Since GBE+ would take any pattern it captured via serial transfers and draw it to a BMP file, I could visually assess the results very quickly. With the old, complicated rules, only a handful actually looked correct while many did not. Once the code changed based on my new perspective, nearly all of the patterns were rendered appropiately. The last thing to do was calculate the right lengths for each Y coordinate. Ultimately, I came up with this chart:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;0x00				Shift Down 1.25mm	
0x01				Shift Down 1.1875mm	
0x02				Shift Down 1.125mm	
0x03				Shift Down 1.0625mm	
0x04				Shift Down 1.0mm	
0x05				Shift Down 0.9375mm	
0x06				Shift Down 0.875mm	
0x07				Shift Down 0.8125mm	
0x08				Shift Down 0.75mm	
0x09				Shift Down 0.6875mm	
0x0A				Shift Down 0.625mm	
0x0B				Shift Down 0.5625mm	
0x0C				Shift Down 0.5mm	
0x0D				Shift Down 0.4375mm	
0x0E				Shift Down 0.375mm	
0x0F				Shift Down 0.3125mm	
0x10				Shift Down 0.25mm	
0x11				Shift Down 0.1875mm	
0x12				Shift Down 0.125mm	
0x13				Shift Down 0.0625mm	
0x14				No Change		
0x15				Shift Up 0.0625mm	
0x16				Shift Up 0.125mm	
0x17				Shift Up 0.1875mm	
0x18				Shift Up 0.25mm		
0x19				Shift Up 0.3125mm	
0x1A				Shift Up 0.375mm	
0x1B				Shift Up 0.4375mm	
0x1C				Shift Up 0.5mm		
0x1D				Shift Up 0.5625mm	
0x1E				Shift Up 0.625mm	
0x1F				Shift Up 0.6875mm	
0x20				Shift Up 0.75mm		&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Solving the meaning of these Y values actually revealed one other oddity about the XY coordinates. For any given X coordinate, the Y coordinate that dictates vertical movement is the last previously sent Y coordinate, not the following Y coordinate. To illustrate this, going back to the coordinates for the pattern &lt;code&gt;B-007&lt;/code&gt;, the first horizontal line going right doesn't really use XY values of &lt;code&gt;0x01, 0x14&lt;/code&gt;. Instead, it's better read as &lt;code&gt;0x0E, 0x14&lt;/code&gt;, where the X value indicates rightward movement, and the Y value indicates no vertical movement. It may be better to classify them as YX values, but in either case, the raw bytes of the coordinates are somewhat "misaligned" from a human perspective.&lt;/p&gt;
    &lt;p&gt;Converting this information into pixels was relatively straightforward. Every X value represents 1 pixel. For Y values, &lt;code&gt;0x14&lt;/code&gt; is zero, every value above it simply moves up 1 pixel, and every value below it moves down 1 pixel. With that, even the most complicated patterns like swans, flowers, and hearts were drawing without any issue in GBE+. Even custom user-made patterns drew flawlessly. Figuring out XY coordinates caused plenty of headaches and a fair amount a swearing. Let me just say that the way these 3 machines handle everything is dumb. There's absolutely nothing intuitive about using &lt;code&gt;0x14&lt;/code&gt; as a replacement for zero. There's absolutely nothing intuitive about using the previous Y coordinate instead of the next one. Maybe someone will point out that this is how many sewing machines work internally or it's just how things are done for devices like this or it's just how some microcontrollers are designed. I can actually see and understand the logic and reasoning behind some of it. But I don't care. It's dumb, and it will never not be dumb in my mind.&lt;/p&gt;
    &lt;p&gt;Anyway, with every pattern working properly, I moved on to testing lettering. This feature only partially worked in GBE+. Strangely enough, the BMP output file used for debugging only showed the first couple of letters. For example, when trying to stitch "ABCD", only "AB" would show up. After thoroughly examining the data transferred from the Game Boy, I realized that GBE+ wasn't handling a key part of the packet format. When the Game Boy sends a packet to the sewing machine, the packet can only be 128 bytes long. Stitching a long sequence of letters, however, could require several hundred XY coordinates (as many parts are double or triple stitched). Sending that many XY coordinates means sending multiple packets, and GBE+ only handled the first one it encountered. With a few adjustments, GBE+ parsed all additional packets and fixed not only lettering but buttonholes as well.&lt;/p&gt;
    &lt;p&gt;Textile throwdown&lt;/p&gt;
    &lt;p&gt;After testing both the Sewing Machine Operation Software and Raku x Raku Mishin ROMs, I was satisfied that GBE+ could faithfully emulate the Singer IZEK 1500 and the Jaguar JN-100. This was only half the battle, as the Jaguar JN-2000 and its embroidery arm remained a total mystery. Given how complex embroidery can be, I could only imagine what it would be like to tackle the EM-2000. One major problem blocking progress was the fact that I didn't have an EM-2000 at all. The only time I found a couple for sale, they came with the JN-2000, which would have set me back well over $1000 in those cases. It wasn't until after I finished all my research on these machines that one reasonably priced auction actually popped up. Needless to say, I didn't have the hardware I needed.&lt;/p&gt;
    &lt;p&gt;The EM-2000, however, looks a lot like some of the embroidery arms Singer made around that time for some of its Futura models. The two look identical save for the color scheme. I suspected that a Futura embroidery arm might work with the JN-2000. After all, the Singer IZEK 1500 was a copy+paste clone of the JN-100, so maybe the two companies shared more designs with each other. When my own Futura embroidery arm arrived, it wouldn't fit into the JN-2000's slot, as it had two little pieces of plastic preventing them from sliding together. An hour of sanding by hand removed the plastic guards and allowed the Futura hardware to fit onto the JN-2000. Unfortunately, it was totally incompatible. No software recognized that embroidery arm was attached.&lt;/p&gt;
    &lt;p&gt;With no means of probing the hardware directly, my only option was to reverse-engineer the software and whatever protocol the Game Boy used during embroidery. The first challenge is to determine how the JN-2000 reports to the Game Boy whether or not the EM-2000 is present. Before and after sending a packet to the sewing machines, the Game Boy issues a sort of "keep-alive" byte to continually check the connection. The sewing machines are supposed to return their current status as a single byte. Responding with zero allowed most of the IZEK 1500 and JN-100 stuff to process normally, but Raku x Raku Moji, Raku x Raku Cut Shuu, and Mario Family all complained about the missing EM-2000. By accident, I had previously discovered that setting Bit 1 of the status byte high caused the software to believe the EM-2000 was there. After trying a few more random values, it appeared that &lt;code&gt;0x06&lt;/code&gt; and &lt;code&gt;0x07&lt;/code&gt; let the software continue with no errors. The first seemed to indicate a small embroidery hoop was attached, and the second indicated a large embroidery hoop was attached. Only certain designs can be stitched with a large hoop.&lt;/p&gt;
    &lt;p&gt;Using the correct status byte triggered a transfer instead of an error. The data sent from the Game Boy looked very similar to the other packets used by the IZEK 1500 and JN-100. The format of the coordinate data was clearly different, however. Unlike the other somewhat convoluted coordinate scheme, the embroidery coordinates were straightforward and easy to understand. Almost immediately I saw how it worked just by glancing at the numbers. A value like &lt;code&gt;0x05&lt;/code&gt; would move the stitching point right 5 units for X coordinates or down 5 units for Y coordinates. A value like &lt;code&gt;0x45&lt;/code&gt; would move the stitching point left 5 units for X coordinates or up 5 units for Y coordinates. If Bit 6 is set high, X and Y coordinates move in one directions, otherwise they go in the opposite direction. XY coordinates weren't mismatched either. That was the kind of simplicity I was looking for with the IZEK 1500 and JN-100!&lt;/p&gt;
    &lt;p&gt;By connecting the lines between these coordinates, GBE+ started drawing many of the designs. Unfortunately, nearly all of them had serious rendering problems, with bits and pieces all over the place. Mario had a misplaced face, Princess Peach had none, and Luigi was just a pile of squiggles. In each case, only the inital part looked correct, then promptly went off the rails. When doing embroidery, designs are broken up into several continuous sections. Most of the time, a large portion of the design can be stitched from one point to the next, sort of like contour drawing. At other times, however, it's impossible to stitch certain segments without completely switching to a new postion that's not connected to the old one. Examples of this include the eyes of many characters, objects not attached to one another (the bubbles surrounding the dolphin character), and colored areas distinctly separated by outlines or other colors. The JN-2000 basically stops stitching while the embroidery arm moves to a new position. GBE+ was treating everything like one long, connected line, never moving to that next location when necessary. Inside some of the packets sent to the JN-2000 are sections that describe how it should jump to a new area. They begin with a &lt;code&gt;0xBE&lt;/code&gt; byte and end with a &lt;code&gt;0xBD&lt;/code&gt; byte. Data looks something like this sample:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;0xBE		START	
0xEB		BYTE 1	
0xFF		BYTE 2	
0xBA		BYTE 3	
0x00		BYTE 4	
0xFF		BYTE 5	
0x00		BYTE 6	
0x00		BYTE 7	
0x00		BYTE 8	
0x00		BYTE 9	
0xBD		END	&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;My first thought was that the above data represented some kind of 16-bit number transferred Least Significant Byte (LSB) first. So the first two bytes form the hexadecimal number &lt;code&gt;0xFFEB&lt;/code&gt;. By that same logic the second 16-bit number should be &lt;code&gt;0x00BA&lt;/code&gt;. Assuming that these 16-bit numbers are X and Y shifts, the first number might be something like a negative X value (move left), and the second might be a positive Y value (move down). However, when examining the rest of the data, there is an odd amount of bytes. There is enough for 4 16-bit numbers and one extra 8-bit value left over. This part really confused me for a few days. From the above data, it looks like the 3rd 16-bit value should be &lt;code&gt;0x00FF&lt;/code&gt; and the 4th 16-bit value should be &lt;code&gt;0x0000&lt;/code&gt; with the last byte just hanging there.&lt;/p&gt;
    &lt;p&gt;As I looked over different sets of shift data, I had one of those moments where an idea just jumps into your head. What if, in the above data, the 5th byte merely acted as a sort of separator for the next 16-bit X and Y shifts? That would explain why the Game Boy sent an odd number of bytes. Other designs had multiple shifts, and when I checked my logs, I found that after every X and Y shift, there was in fact a &lt;code&gt;0xFF&lt;/code&gt; byte placed in between them. For the above data, the last X and Y shifts are just zero, indicating no movement. With a few changes in GBE+'s code, the emulator began to correctly parse all shift coordinates. The only thing that went wrong was getting the up and down directions reversed.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;0xFFEB		X SHIFT #1	MOVE LEFT 21	
0x00BA		Y SHIFT #1	MOVE UP 186	
						
0x0000		X SHIFT #2	NO MOVEMENT	
0x0000		Y SHIFT #2	NO MOVEMENT	&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;A few designs were still messed up, however. After certain shifts, the X and Y stitching coordinates were mixed up, leading to lines that went in all sorts of directions. Packets sent to the JN-2000 are only 128 bytes long, and sometimes the shift data has to get split across two packets. This proved tricky to handle. All three sewing machines use the byte &lt;code&gt;0xB9&lt;/code&gt; to signal the start of a packet and &lt;code&gt;0xBB&lt;/code&gt; to signal the end of another one. These bytes had to be checked to determine whether they were part of packet management or if they were in fact part of the shift data.&lt;/p&gt;
    &lt;p&gt;The last things to solve were the initial X and Y coordinates. All embroidery designs are in fact several designs in a sequence. For example, Mario Family will first draw Yoshi's green parts, then move onto the shoes and spikes on the back, followed by the saddle, the white tummy, and finally the overall outline. The idea is to embroider portions that use the same color. The software asks the user to select a new thread and sends separate transmissions to the JN-2000. The first packet of each transmission dictates the starting X and Y position. These have no relation to any of the previous stitching points or shift coordinates, as the user can actually transfer any part of the design out of order or skip sections entirely (for example, when using white fabric as the base, you may not want to embroider Mario's gloves). If the wrong start coordinates are used, then nothing matches up as it should when drawing every segment.&lt;/p&gt;
    &lt;p&gt;The starting X and Y coordinates are also 16-bit LSB values. They are absolute values, meaning they dictate exactly where to start stitching inside the embroidery hoop. Users can choose the starting point themselves via software, and the Game Boy will transmit the appropiate data. By manipulating this feature, it was possible to record the maximum and minimum X and Y values and thereby reveal how these coordinates worked. The right side is defined as &lt;code&gt;0xFFF&lt;/code&gt; and the left side is defined as &lt;code&gt;0xFED0&lt;/code&gt;. The top is defined as &lt;code&gt;0xFFFF&lt;/code&gt; and the bottom is defined as &lt;code&gt;0xFE30&lt;/code&gt;. With those measurements, GBE+ could plot the correct starting point for each design. This in turn finally fixed every outstanding issue for embroidery.&lt;/p&gt;
    &lt;p&gt;Stitching it all together&lt;/p&gt;
    &lt;p&gt;Emulating these sewing machines up to this point was mainly GBE+ spitting out an image file once it finished processing the final packet sent by the software. This approach, while suitable for debugging and experimental code, is very unsatisfying for normal users. Although it technically gets the job done, I've always felt emulation should be about exploring things, not merely recreating them for observation. To truly preserve the overall experience of the something like the IZEK-1500, people need to interact and control the output in real-time. It all comes back to the question: how does one really emulate a sewing machine?&lt;/p&gt;
    &lt;p&gt;In my previous article about the Cyber Drive Zoids toys, I used a sub-screen to draw a tiny little animated robot that mimicked the model, albeit somewhat crudely. My inspiration for a sub-screen in Cyber Drive Zoids actually came from my work on these sewing machines, I just ended up completing that project first. The idea here is to use a sub-screen as a sort of drawing pad. A cursor moves around, and with the mere push of a button, patterns and designs start appearing. A secondary interface in the form of a menu helps dynamically set different options, such as thread coloring, thread thickness, stitching speed, saving the image, clearing the image, and attaching/detaching an emulated EM-2000.&lt;/p&gt;
    &lt;p&gt;The end results were quite pleasing, feeling very much like a virtual sewing machine. I think it provides a lot of value in that the sub-screen demonstrates exactly how the sewing machines would have stitched things. For example, it illustrates the way an EM-2000 would have moved back and forth, showing us exactly how the real thing creates designs like Mario and company. Most of us will never get the chance to see these devices with our own eyes, much less poke around the patterns they made. Now, however, anyone can see for themselves what all the fuss was about.&lt;/p&gt;
    &lt;p&gt;Loose ends&lt;/p&gt;
    &lt;p&gt;Before closing this article, I'd like to take the time to cover some misconceptions surrounding the sewing machines. First, the only sewing machine capable of doing elaborate embroidery designs is the JN-2000. You can't use the IZEK-1500 or the JN-100 with Mario Family, for example, because they can't use the EM-2000. They lack the slot at their base for the embroidery arm. Interestingly enough, both the Raku x Raku Mishin and Sewing Machine Operation Software cartridges have error messages complaining that the EM-2000 is attached, even though it's probably impossible to do so (without some extreme modifications at least). This suggests that the EM-2000 was in development when the JN-100 was released, and it's also probable that IZEK expected to make their own model based on the JN-2000.&lt;/p&gt;
    &lt;p&gt;The second point I want to bring up is that while the Game Boy does display a preview of each embroidery design for the JN-2000, the pixel art is only an approximation of the final stitching. There are some details that just don't fit on the 160x144 screen. For example, for Princess Peach, the Game Boy omits her eyebrows, eyelashes, the ruffles on her dress around the neck, and the gap between her gloves and the sleeves or her dress. The embroidery is far more intricate in many cases than the software presents, especially regarding some of Raku x Raku Cut Shuu's designs. The final results, in any case, are impressive in contrast to their Game Boy representations.&lt;/p&gt;
    &lt;p&gt;Lastly, yes, these sewing machines really did work! This is strangely a common reaction when people learn about these models (I mean, would Jaguar or Singer really sell such an expensive yet defective product?) All 3 of them are actually pretty good machines, and they can work without the Game Boy, though at that point they're limited to stitching straight lines. They did everything they claimed they could without much if any trouble.&lt;/p&gt;
    &lt;p&gt;Clothing arguments&lt;/p&gt;
    &lt;p&gt;Dealing with these sewing machines has definitely been a wild ride. They turned out to be quite a handful, but in the end I feel it was worth all of the work. Each one adds a very unique chapter to video game history that we will hopefully never lose now. It's been 20 years since the JN-100 first brought Game Boy powered sewing to the world, so for the anniversary of that achievement, I can think of no better way to celebrate it than via emulation.&lt;/p&gt;
    &lt;p&gt;I've been fascinated with exotic gaming peripherals for some time, but I have to admit, the JN-100, JN-2000, and IZEK-1500 are by far the most impressive ones I've examined. It's just one of those things where you simply shake your head thinking about how nuts it sounds. A sewing machine controlled by a Game Boy? I remember when MAME finally emulated a Sonic The Hedgehog popcorn machine, and I thought that was some downright insane dedication to video game preservation. Ever since then, I've wanted to do something similar, bringing a big, bulky, weird piece of hardware back to life, something that was flashy, hard to find, and expensive. I think I've fulfilled that goal now.&lt;/p&gt;
    &lt;p&gt;It seems like I just started writing these articles not too long ago, but it's already been 3 years! In that time, I'm proud to say that nearly all of the add-ons that directly affected gameplay and software programming in commercial DMG and GBC games are emulated in some capacity! Only 1 notable DMG accessory is still at large. When I started in 2017, there were numerous unknowns, with at least 7 devices that hadn't been researched at all in decades. I hope I've done my small part to make Game Boy emulation as a whole better, and I hope that these Edge of Emulation articles inspire people to start looking at other areas of gaming that remain forgotten and need preservation. Having said all of that, my path is far from complete. That TODO list of mine just never seems to get any shorter. My ambition for 2020 is to continuously jump from one item to the next, and I've already got my sights set on the next big thing: the AGS-006, aka the Play-Yan. With any luck, I'll have something to report in the next few months.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46616496</guid><pubDate>Wed, 14 Jan 2026 14:35:50 +0000</pubDate></item><item><title>Never-before-seen Linux malware is "more advanced than typical"</title><link>https://arstechnica.com/security/2026/01/never-before-seen-linux-malware-is-far-more-advanced-than-typical/</link><description>&lt;doc fingerprint="ddbb19dfc835a5e8"&gt;
  &lt;main&gt;
    &lt;p&gt;Researchers have discovered a never-before-seen framework that infects Linux machines with a wide assortment of modules that are notable for the range of advanced capabilities they provide to attackers.&lt;/p&gt;
    &lt;p&gt;The framework, referred to as VoidLink by its source code, features more than 30 modules that can be used to customize capabilities to meet attackers’ needs for each infected machine. These modules can provide additional stealth and specific tools for reconnaissance, privilege escalation, and lateral movement inside a compromised network. The components can be easily added or removed as objectives change over the course of a campaign.&lt;/p&gt;
    &lt;head rend="h2"&gt;A focus on Linux inside the cloud&lt;/head&gt;
    &lt;p&gt;VoidLink can target machines within popular cloud services by detecting if an infected machine is hosted inside AWS, GCP, Azure, Alibaba, and Tencent, and there are indications that developers plan to add detections for Huawei, DigitalOcean, and Vultr in future releases. To detect which cloud service hosts the machine, VoidLink examines metadata using the respective vendor’s API.&lt;/p&gt;
    &lt;p&gt;Similar frameworks targeting Windows servers have flourished for years. They are less common on Linux machines. The feature set is unusually broad and is “far more advanced than typical Linux malware,” said researchers from Checkpoint, the security firm that discovered VoidLink. Its creation may indicate that the attacker’s focus is increasingly expanding to include Linux systems, cloud infrastructure, and application deployment environments, as organizations increasingly move workloads to these environments.&lt;/p&gt;
    &lt;p&gt;“VoidLink is a comprehensive ecosystem designed to maintain long-term, stealthy access to compromised Linux systems, particularly those running on public cloud platforms and in containerized environments,” the researchers said in a separate post. “Its design reflects a level of planning and investment typically associated with professional threat actors rather than opportunistic attackers, raising the stakes for defenders who may never realize their infrastructure has been quietly taken over.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46616569</guid><pubDate>Wed, 14 Jan 2026 14:42:06 +0000</pubDate></item><item><title>FBI raids Washington Post reporter's home</title><link>https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson</link><description>&lt;doc fingerprint="7fc1c100f68919c1"&gt;
  &lt;main&gt;
    &lt;p&gt;The FBI raided the home of a Washington Post reporter early on Wednesday in what the newspaper called a “highly unusual and aggressive” move by law enforcement, and press freedom groups condemned as a “tremendous intrusion” by the Trump administration.&lt;/p&gt;
    &lt;p&gt;Agents descended on the Virginia home of Hannah Natanson as part of an investigation into a government contractor accused of illegally retaining classified government materials.&lt;/p&gt;
    &lt;p&gt;An email sent on Wednesday afternoon to Post staff from the executive editor, Matt Murray, obtained by the Guardian, said agents turned up “unannounced”, searched her home and seized electronic devices.&lt;/p&gt;
    &lt;p&gt;“This extraordinary, aggressive action is deeply concerning and raises profound questions and concern around the constitutional protections for our work,” the email said.&lt;/p&gt;
    &lt;p&gt;“The Washington Post has a long history of zealous support for robust press freedoms. The entire institution stands by those freedoms and our work.”&lt;/p&gt;
    &lt;p&gt;“It’s a clear and appalling sign that this administration will set no limits on its acts of aggression against an independent press,” Marty Baron, the Post’s former executive editor, told the Guardian.&lt;/p&gt;
    &lt;p&gt;Murray said neither the newspaper nor Natanson were not told they were the target of a justice department investigation.&lt;/p&gt;
    &lt;p&gt;Pam Bondi, the attorney general, said in a post on X that the raid was conducted by the justice department and FBI at the request of the Pentagon.&lt;/p&gt;
    &lt;p&gt;The warrant, she said, was executed “at the home of a Washington Post journalist who was obtaining and reporting classified and illegally leaked information from a Pentagon contractor. The leaker is currently behind bars.”&lt;/p&gt;
    &lt;p&gt;The statement gave no further details of the raid or investigation. Bondi added: “The Trump administration will not tolerate illegal leaks of classified information that, when reported, pose a grave risk to our nation’s national security and the brave men and women who are serving our country.”&lt;/p&gt;
    &lt;p&gt;The reporter’s home and devices were searched, and her Garmin watch, phone, and two laptop computers, one belonging to her employer, were seized, the newspaper said. It added that agents told Natanson she was not the focus of the investigation, and was not accused of any wrongdoing.&lt;/p&gt;
    &lt;p&gt;A warrant obtained by the Post cited an investigation into Aurelio Perez-Lugones, a system administrator in Maryland with a top secret security clearance who has been accused of accessing and taking home classified intelligence reports.&lt;/p&gt;
    &lt;p&gt;Natanson, the Post said, covers the federal workforce and has been a part of the newspaper’s “most high-profile and sensitive coverage” during the first year of the second Trump administration.&lt;/p&gt;
    &lt;p&gt;As the paper noted in its report, it is “highly unusual and aggressive for law enforcement to conduct a search on a reporter’s home”.&lt;/p&gt;
    &lt;p&gt;In a first-person account published last month, Natanson described herself as the Post’s “federal government whisperer”, and said she would receive calls day and night from “federal workers who wanted to tell me how President Donald Trump was rewriting their workplace policies, firing their colleagues or transforming their agency’s missions”.&lt;/p&gt;
    &lt;p&gt;“It’s been brutal,” the article’s headline said.&lt;/p&gt;
    &lt;p&gt;Natanson said her work had led to 1,169 new sources, “all current or former federal employees who decided to trust me with their stories”. She said she learned information “people inside government agencies weren’t supposed to tell me”, saying that the intensity of the work nearly “broke” her.&lt;/p&gt;
    &lt;p&gt;The federal investigation into Perez-Lugones, the Post said, involved documents found in his lunchbox and his basement, according to an FBI affidavit. The criminal complaint against him does not accuse him of leaking classified information, the newspaper said.&lt;/p&gt;
    &lt;p&gt;Press freedom groups were united in their condemnation of the raid on Wednesday.&lt;/p&gt;
    &lt;p&gt;“Physical searches of reporters’ devices, homes and belongings are some of the most invasive investigative steps law enforcement can take,” Bruce D Brown, president of the Reporters’ Committee for Freedom of the Press, said in a statement.&lt;/p&gt;
    &lt;p&gt;“There are specific federal laws and policies at the Department of Justice that are meant to limit searches to the most extreme cases because they endanger confidential sources far beyond just one investigation and impair public interest reporting in general.&lt;/p&gt;
    &lt;p&gt;“While we won’t know the government’s arguments about overcoming these very steep hurdles until the affidavit is made public, this is a tremendous escalation in the administration’s intrusions into the independence of the press.”&lt;/p&gt;
    &lt;p&gt;Jameel Jaffer, executive director of the Knight First Amendment Institute, demanded a public explanation from the justice department of “why it believes this search was necessary and legally permissible”.&lt;/p&gt;
    &lt;p&gt;In a statement, Jaffer said: “Any search targeting a journalist warrants intense scrutiny because these kinds of searches can deter and impede reporting that is vital to our democracy.&lt;/p&gt;
    &lt;p&gt;“Attorney General Bondi has weakened guidelines that were intended to protect the freedom of the press, but there are still important legal limits, including constitutional ones, on the government’s authority to use subpoenas, court orders, and search warrants to obtain information from journalists.&lt;/p&gt;
    &lt;p&gt;“Searches of newsrooms and journalists are hallmarks of illiberal regimes, and we must ensure that these practices are not normalized here.”&lt;/p&gt;
    &lt;p&gt;Seth Stern, chief of advocacy for the Freedom of the Press Foundation, said it was “an alarming escalation in the Trump administration’s multipronged war on press freedom” and called the warrant “outrageous”.&lt;/p&gt;
    &lt;p&gt;“The administration may now be in possession of volumes of journalist communications having nothing to do with any pending investigation and, if investigators are able to access them, we have zero faith that they will respect journalist-source confidentiality,” he said.&lt;/p&gt;
    &lt;p&gt;Tim Richardson, journalism and disinformation program director at PEN America, said: “A government action this rare and aggressive signals a growing assault on independent reporting and undermines the First Amendment.&lt;/p&gt;
    &lt;p&gt;“It is intended to intimidate sources and chill journalists’ ability to gather news and hold the government accountable. Such behavior is more commonly associated with authoritarian police states than democratic societies that recognize journalism’s essential role in informing the public.”&lt;/p&gt;
    &lt;p&gt;The Post has had a rocky relationship with the Trump administration in recent months, despite its billionaire owner, Jeff Bezos, the Amazon founder, attempting to curry favor by blocking it from endorsing Kamala Harris, the Democratic nominee, in the 2024 presidential election.&lt;/p&gt;
    &lt;p&gt;Bezos defended the action, which saw the desertion of more than 200,000 subscribers in protest.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46616745</guid><pubDate>Wed, 14 Jan 2026 14:57:30 +0000</pubDate></item><item><title>Government drops plans for mandatory digital ID to work in UK</title><link>https://www.bbc.com/news/articles/c3385zrrx73o</link><description>&lt;doc fingerprint="f7a5d3f412825ff9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Government drops plans for mandatory digital ID to work in UK&lt;/head&gt;
    &lt;p&gt;The government has dropped plans requiring workers to sign up to a new digital ID system in order to prove their right to work in the UK.&lt;/p&gt;
    &lt;p&gt;Instead, Labour ministers say existing checks, using documents such as biometric passports, will move fully online by 2029.&lt;/p&gt;
    &lt;p&gt;Conservative leader Kemi Badenoch said Sir Keir Starmer was "clueless" and showing "no sense of direction whatsoever".&lt;/p&gt;
    &lt;p&gt;Business Secretary Peter Kyle said it showed the need for Labour ministers to better justify the reasons behind new measures.&lt;/p&gt;
    &lt;p&gt;"What I am concerned about is we get better at explaining our policies, we get better at showing the relevance of it," he told BBC 2's Politics Live.&lt;/p&gt;
    &lt;p&gt;The reversal is in the latest in a series of U-turns in recent weeks, including on inheritance tax for farmland and business rates for pubs.&lt;/p&gt;
    &lt;p&gt;Speaking at Prime Minster's Questions, the Tory leader welcomed the government's climbdown, branding the initial digital ID plan a "rubbish policy".&lt;/p&gt;
    &lt;p&gt;But she said the change of approach showed Sir Keir was "blowing around like a plastic bag in the wind", predicting that Labour would next U-turn on its controversial plans to scale back jury trials.&lt;/p&gt;
    &lt;p&gt;The prime minister hit back by pointing to policy reversals and ministerial churn under the previous government, accusing the Conservatives of having "crashed the economy" during their time in office.&lt;/p&gt;
    &lt;p&gt;"I'm determined to make it harder for people to work illegally in this country and that's why there will be checks, they will be digital, and they will be mandatory," he added.&lt;/p&gt;
    &lt;p&gt;When the government first announced the policy plan, it argued that mandatory digital ID for workers would make it easier to clamp down on immigrants working illegally.&lt;/p&gt;
    &lt;p&gt;The scheme, it is understood, will now deal less narrowly with immigration and the government will instead place more emphasis on the argument that digital ID can be a useful tool for the public when accessing public services.&lt;/p&gt;
    &lt;p&gt;Transport Secretary Heidi Alexander told BBC Radio 4's Today programme the government was still "absolutely committed" to mandatory digital right to work checks, including through biometric passports, and said digitising the system would help crack down on illegal working.&lt;/p&gt;
    &lt;p&gt;"The digital ID could be one way in which you prove your eligibility to work through a digital right to work check," she said.&lt;/p&gt;
    &lt;p&gt;"At the moment we've got a paper-based system - there's no proper records kept.&lt;/p&gt;
    &lt;p&gt;"It makes it very difficult then to target enforcement action sensibly against businesses that are employing illegal workers."&lt;/p&gt;
    &lt;p&gt;Former home secretary Lord David Blunkett, who supported ID cards when he was in government, told the same programme the government had not explained why the policy mattered or how it would work, so it was "not surprising" to see another U-turn.&lt;/p&gt;
    &lt;p&gt;"The original statement was not followed by a narrative or supportive statements or any kind of strategic plan which involved other ministers and those who are committed to this actually making the case," he said.&lt;/p&gt;
    &lt;p&gt;"As a consequence, those who are opposed to the scheme, for all kinds of nefarious and very different reasons, some of them inexplicable, were able to mobilise public opinion and to get the online opposition to it up and running."&lt;/p&gt;
    &lt;p&gt;Polling showed that public support for digital ID collapsed after Sir Keir's announcement, falling from just over half the population being supportive in June to less than a third of the population just after his speech.&lt;/p&gt;
    &lt;p&gt;Nearly three million people have signed a parliamentary petition opposing the introduction of digital IDs.&lt;/p&gt;
    &lt;p&gt;There has also been nervousness among some Labour MPs over the compulsory aspect of the original proposal.&lt;/p&gt;
    &lt;p&gt;Whatever they think of the change to this specific policy, Labour MPs are growing increasingly frustrated with the government's U-turns.&lt;/p&gt;
    &lt;p&gt;Some had already been wary of defending controversial government policies to their constituents because they feared that the policy would inevitably be reversed.&lt;/p&gt;
    &lt;p&gt;One furious Labour MP told the BBC last night that the latest U-turn was "an absolute car crash", adding: "The boys at No 10 jumped into it with no thought, marched the PLP up the hill only to bottle it, take all the pain and no credit."&lt;/p&gt;
    &lt;p&gt;The Liberal Democrats said the policy was "doomed to failure" from the start and called for "the billions of pounds earmarked for their mandatory digital ID scheme" to be spent "on the NHS and frontline policing instead".&lt;/p&gt;
    &lt;p&gt;The party's Cabinet Office spokesperson, Lisa Smart, said: "No 10 must be bulk ordering motion sickness tablets at this rate to cope with all their U-turns."&lt;/p&gt;
    &lt;p&gt;Reform UK leader Nigel Farage said in a post on X: "This is a victory for individual liberty against a ghastly, authoritarian government. Reform UK would scrap it altogether."&lt;/p&gt;
    &lt;p&gt;Green Party leader Zack Polanski welcomed the news on X, saying: "The government have U-turned on ID cards. Good."&lt;/p&gt;
    &lt;p&gt;A government spokesperson said: "We are committed to mandatory digital right to work checks.&lt;/p&gt;
    &lt;p&gt;"Currently right to work checks include a hodge podge of paper-based systems with no record of checks ever taking place. This is open to fraud and abuse.&lt;/p&gt;
    &lt;p&gt;"Digital ID will make everyday life easier for people, ensuring public services are more personal, joined-up, and effective, while also remaining inclusive."&lt;/p&gt;
    &lt;p&gt;Employers already have to check if someone they want to hire has the right to work in the UK.&lt;/p&gt;
    &lt;p&gt;Since 2022, employers have been able to do checks on passport-holding British and Irish citizens using digital verification services certified by the government.&lt;/p&gt;
    &lt;p&gt;There is also a Home Office online scheme which verifies the status of some non-British or Irish citizens, whose immigration status is held electronically.&lt;/p&gt;
    &lt;p&gt;The details of how digital ID will work have yet to be set out but it is expected to be based on two government-built systems: Gov.uk One Login and Gov.uk Wallet.&lt;/p&gt;
    &lt;p&gt;Currently more than 12 million people have signed up to One Login, which can be used for services such as applying for a veteran card, cancelling a lost passport or managing a lasting power of attorney.&lt;/p&gt;
    &lt;p&gt;Gov.uk Wallet has not yet been launched but would allow people to store their digital ID on their smartphones.&lt;/p&gt;
    &lt;p&gt;The digital ID would include name, date of birth, nationality and residence status and a photo.&lt;/p&gt;
    &lt;p&gt;Sign up for our Politics Essential newsletter to keep up with the inner workings of Westminster and beyond.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617149</guid><pubDate>Wed, 14 Jan 2026 15:29:59 +0000</pubDate></item><item><title>Find a pub that needs you</title><link>https://www.ismypubfucked.com/</link><description>&lt;doc fingerprint="f02c34496935903"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FIND A PUB&lt;lb/&gt;THAT NEEDS YOU&lt;/head&gt;
    &lt;p&gt;The government's signalled a potential u-turn on pub rates — but nothing's confirmed yet. Pubs still need your support. Find your local. See what they're up against. Buy a pint.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE FUCKED PUB INDEX&lt;/head&gt;
    &lt;p&gt;Our world-class data scientists (one guy with a spreadsheet) have developed the Fucked Pub Index™ — a groundbreaking metric that combines advanced geospatial analysis (Google Maps) with sophisticated fiscal impact modelling (basic maths) to identify the pub near you that most urgently requires your patronage.&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Pubs Analysed&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Facing Increases&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Fucked or Worse&lt;/p&gt;
    &lt;p&gt;2026&lt;/p&gt;
    &lt;p&gt;Revaluation Year&lt;/p&gt;
    &lt;p&gt;Based on VOA rateable value data for ... verified pubs (SCAT 249). Some industry experts estimate the actual number of affected pubs is even higher. The government has signalled support is coming — we'll update when details are announced.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617360</guid><pubDate>Wed, 14 Jan 2026 15:44:22 +0000</pubDate></item><item><title>Xoscript</title><link>https://xoscript.com/history.xo</link><description>&lt;doc fingerprint="5f21e18f89a9c79e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;History&lt;/head&gt;
    &lt;p&gt;History and roadmap..&lt;/p&gt;
    &lt;p&gt; xoscript is a server-side scripting language that has been in development under various names since 1993. The first version was originally written for the C64 system. In 2009, I decided to reboot the project with a focus on research, localization, and later on educational use. &lt;lb/&gt; After several server migrations between 2020 and 2025, it became clear that many existing server-side scripting languages had grown increasingly complex and heavy over time. In response, I released a new version of the language in 2026 under the name xoscript, with the goal of providing a simple and efficient environment for server-side scripting. &lt;lb/&gt; xoscript emphasizes three core principles: &lt;lb/&gt; - Simplicity: minimal syntax rules make the language easy to learn and remember. &lt;lb/&gt; - Security: designed with server use in mind, security is a key consideration. &lt;lb/&gt; - Backward Compatibility: maintaining consistency so that existing code continues to work across updates. &lt;lb/&gt; The language is intentionally neutral and apolitical, without any stance on social or political issues. While some design choices may be unconventional, such as typeless data, dynamic scope, everything as a reference, Smalltalk-like message passing, and fault tolerance, these choices are deliberate and may appeal to some developers more than others. &lt;lb/&gt; Today, xoscript is primarily focused on server-side scripting, aiming to provide a lightweight, practical programming experience. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617492</guid><pubDate>Wed, 14 Jan 2026 15:52:46 +0000</pubDate></item><item><title>Starlink roam 50GB is now 100GB with unlimited slow speed after that</title><link>https://starlink.com/support/article/58c9c8b7-474e-246f-7e3c-06db3221d34d</link><description>&lt;doc fingerprint="764c38ffe0c8a287"&gt;
  &lt;main&gt;
    &lt;p&gt;On January 13, 2026, Starlink doubled the amount of high-speed data on Roam 50GB to 100GB, at no additional cost and in most markets. Here is all you need to know about what's changed and what hasn't.&lt;/p&gt;
    &lt;p&gt;Once you’ve used 100GB of your high-speed Roam data, your service automatically continues with unlimited low-speed data for the remainder of your billing period. You’ll still be connected for basic use like calls and texts, but activities such as streaming, downloading, and video calls may be limited.&lt;/p&gt;
    &lt;p&gt;We’ll notify you when you reach 80% and 100% of your monthly high-speed Roam data. To restore high-speed Roam service, you can upgrade to Roam Unlimited. Please note that this upgrade will remain in effect for future billing cycles.&lt;/p&gt;
    &lt;p&gt;No. Your service will not stop. You’ll continue to have internet access--with unlimited data--at reduced speeds until your next billing cycle begins.&lt;/p&gt;
    &lt;p&gt;Low-speed data supports basic connectivity such as email, calls, and texts. Activities that rely on higher speeds—like streaming video, large downloads, or video calls—will be limited.&lt;/p&gt;
    &lt;p&gt;You can upgrade anytime to Roam Unlimited to restore high-speed service. Please note that upgrading to Roam Unlimited will remain in effect for future billing cycles.&lt;/p&gt;
    &lt;p&gt;With the exception of Ocean Mode, per-GB data purchases are no longer available on Roam plans. Customers now automatically move to unlimited low-speed data after reaching their high-speed Roam 100GB limit, with the option to upgrade to Roam Unlimited for continued high-speed access.&lt;/p&gt;
    &lt;p&gt;Yes, with the same previous conditions as Roam 50GB:&lt;/p&gt;
    &lt;p&gt;In the following markets, Roam 50GB is still available and Roam 100GB is not available:&lt;/p&gt;
    &lt;p&gt;Austria&lt;/p&gt;
    &lt;p&gt;Hungary&lt;/p&gt;
    &lt;p&gt;Croatia&lt;/p&gt;
    &lt;p&gt;Bangladesh&lt;/p&gt;
    &lt;p&gt;Bhutan&lt;/p&gt;
    &lt;p&gt;Botswana&lt;/p&gt;
    &lt;p&gt;Brunei&lt;/p&gt;
    &lt;p&gt;Cape Verde&lt;/p&gt;
    &lt;p&gt;Cook Islands&lt;/p&gt;
    &lt;p&gt;Costa Rica&lt;/p&gt;
    &lt;p&gt;Democratic Republic of the Congo&lt;/p&gt;
    &lt;p&gt;Eswatini&lt;/p&gt;
    &lt;p&gt;Gambia&lt;/p&gt;
    &lt;p&gt;Ghana&lt;/p&gt;
    &lt;p&gt;Kenya&lt;/p&gt;
    &lt;p&gt;Lesotho&lt;/p&gt;
    &lt;p&gt;Liberia&lt;/p&gt;
    &lt;p&gt;Malawi&lt;/p&gt;
    &lt;p&gt;Maldives&lt;/p&gt;
    &lt;p&gt;Mongolia&lt;/p&gt;
    &lt;p&gt;Mozambique&lt;/p&gt;
    &lt;p&gt;Nauru&lt;/p&gt;
    &lt;p&gt;Nigeria&lt;/p&gt;
    &lt;p&gt;Oman&lt;/p&gt;
    &lt;p&gt;Qatar&lt;/p&gt;
    &lt;p&gt;Rwanda&lt;/p&gt;
    &lt;p&gt;Sierra Leone&lt;/p&gt;
    &lt;p&gt;Somalia&lt;/p&gt;
    &lt;p&gt;South Sudan&lt;/p&gt;
    &lt;p&gt;Sri Lanka&lt;/p&gt;
    &lt;p&gt;Togo&lt;/p&gt;
    &lt;p&gt;Tonga&lt;/p&gt;
    &lt;p&gt;United Arab Emirates&lt;/p&gt;
    &lt;p&gt;Vanuatu&lt;/p&gt;
    &lt;p&gt;Zambia&lt;/p&gt;
    &lt;p&gt;Zimbabwe&lt;/p&gt;
    &lt;p&gt;Can't find what you're looking for? Contact Support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617668</guid><pubDate>Wed, 14 Jan 2026 16:03:11 +0000</pubDate></item><item><title>Show HN: A 10KiB kernel for cloud apps</title><link>https://github.com/ReturnInfinity/BareMetal-Cloud</link><description>&lt;doc fingerprint="6dfff95155338da9"&gt;
  &lt;main&gt;
    &lt;p&gt;Important&lt;/p&gt;
    &lt;p&gt;This has only been tested with Digital Ocean and Proxmox. Support for other hypervisor/cloud providers (AWS, Azure, and Google Cloud) is coming soon.&lt;/p&gt;
    &lt;p&gt;BareMetal Cloud is a minimal version of the BareMetal exokernel specifically geared for running in public/private cloud instances. This minimal version of BareMetal contains only the relevant drivers, is 10,240 bytes in size, and only uses 4 MiB of memory. All other memory is allocated to the payload.&lt;/p&gt;
    &lt;p&gt;An instance of BareMetal is running in Digital Ocean at http://baremetal.returninfinity.com and will respond to HTTP and ICMP.&lt;/p&gt;
    &lt;p&gt;The script in this repo depends on a Debian-based Linux system. macOS is also supported to build and test if you are using Homebrew.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NASM - Assembler to build the loader and kernel.&lt;/item&gt;
      &lt;item&gt;QEMU - Computer emulator if you plan on running a virtual machine for quick testing.&lt;/item&gt;
      &lt;item&gt;Git - Version control software for pulling the source code from GitHub.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In Linux this can be completed with the following command:&lt;/p&gt;
    &lt;code&gt;sudo apt install nasm qemu-system-x86 git
&lt;/code&gt;
    &lt;p&gt;In macOS via Homebrew this can be completed with the following command:&lt;/p&gt;
    &lt;code&gt;brew install nasm qemu git
&lt;/code&gt;
    &lt;p&gt;BareMetal Cloud consists of two different projects:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/ReturnInfinity/BareMetal-Cloud.git
cd BareMetal-Cloud
./baremetal.sh setup
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;baremetal.sh setup&lt;/code&gt; automatically runs the build and install functions. Once the setup is complete you can execute &lt;code&gt;baremetal.sh run&lt;/code&gt; to verify that everything installed correctly.&lt;/p&gt;
    &lt;code&gt;./baremetal.sh build
&lt;/code&gt;
    &lt;p&gt;This command builds the boot sector, loader (Pure64), and kernel&lt;/p&gt;
    &lt;code&gt;./baremetal.sh install
&lt;/code&gt;
    &lt;p&gt;This command installs the software to the disk image.&lt;/p&gt;
    &lt;code&gt;./baremetal.sh run
&lt;/code&gt;
    &lt;p&gt;This command will run BareMetal-Cloud in a QEMU VM. Output to the serial port will be displayed to the console.&lt;/p&gt;
    &lt;p&gt;Create a VMDK disk image&lt;/p&gt;
    &lt;code&gt;./baremetal.sh vmdk
&lt;/code&gt;
    &lt;p&gt;The resulting &lt;code&gt;BareMetal_Cloud.vmdk&lt;/code&gt; in &lt;code&gt;sys/&lt;/code&gt; will be required.&lt;/p&gt;
    &lt;p&gt;In Digital Ocean click on &lt;code&gt;Backups &amp;amp; Snapshots&lt;/code&gt; and then &lt;code&gt;Custom Images&lt;/code&gt;. Click on the &lt;code&gt;Upload Image&lt;/code&gt; button and select the .vmdk file on your filesystem. Once the file is uploaded you can start a droplet of it by clicking on the &lt;code&gt;More&lt;/code&gt; dropdown and selecting &lt;code&gt;Start a droplet&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;On the &lt;code&gt;Create Droplets&lt;/code&gt; page you can select the Droplet Type and CPU Options. Give the droplet a name and click on &lt;code&gt;Create Droplet&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In Proxmox click on the "Create VM" button. Configure the following settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;General - Give the VM a name&lt;/item&gt;
      &lt;item&gt;OS - "Do not use any media"&lt;/item&gt;
      &lt;item&gt;System - Machine: q35&lt;/item&gt;
      &lt;item&gt;Disks - Remove the existing disk&lt;/item&gt;
      &lt;item&gt;CPU - Provision as needed&lt;/item&gt;
      &lt;item&gt;Memory - Provision as needed&lt;/item&gt;
      &lt;item&gt;Network - Model: VirtIO&lt;/item&gt;
      &lt;item&gt;Confirm - Click "Finish"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use a utility like &lt;code&gt;scp&lt;/code&gt; to copy the .vmdk file to the filesystem of the Proxmox server.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;qm importdisk &amp;lt;VMID&amp;gt; &amp;lt;vmdk_filename&amp;gt; &amp;lt;storage_location&amp;gt;&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Example - &lt;code&gt;qm importdisk 101 /root/BareMetal_Cloud.vmdk local-lvm&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;In the Proxmox web interface select the new VM. In the Hardware section, find the new unused disk, and attach it to the VM.&lt;/p&gt;
    &lt;p&gt;Verify the "Boot Order" in the VM "Options".&lt;/p&gt;
    &lt;p&gt;Click "Start" on the VM.&lt;/p&gt;
    &lt;p&gt;//EOF&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617705</guid><pubDate>Wed, 14 Jan 2026 16:04:53 +0000</pubDate></item><item><title>I built Vector. Now I'm answering the question your observability vendor won't</title><link>https://usetero.com/blog/the-question-your-observability-vendor-wont-answer</link><description>&lt;doc fingerprint="1760d138bd3114df"&gt;
  &lt;main&gt;
    &lt;p&gt;This year marks a decade for me in observability.&lt;/p&gt;
    &lt;p&gt;I left my engineering job in 2016 to start Timber.io, a hosted logging platform, because I thought logs could be simple and great. Timber became Vector. Vector got mass adoption. It got acquired, and I stayed for three years.&lt;/p&gt;
    &lt;p&gt;And somewhere along the way, the optimism curdled.&lt;/p&gt;
    &lt;p&gt;I'm not a cynical person. I believed observability could make engineers' lives better. But after a decade, after hundreds of conversations with teams bleeding money across every major vendor, after hearing firsthand how their vendors strong-armed them instead of helping; I've seen enough. The whole industry has lost the plot.&lt;/p&gt;
    &lt;head rend="h2"&gt;Does any of this sound familiar?&lt;/head&gt;
    &lt;p&gt;You run observability at your company. But really, you're the cost police. You wake up to a log line in a hot path, a metric tag that exploded cardinality. You chase down the engineer. They didn't do anything wrong, they're just disconnected from what any of this costs. The renewal is always in the back of your mind because mismanaging it reflects poorly on you. Sometimes you catch these mistakes. Sometimes you don't. When you don't, you crawl to your rep asking for forgiveness. Maybe they help the first time, even the second. By the fourth or fifth, they stop. "It's your data." But even with the mistakes, if you're diligent, checking dashboards, staying on top of things, you manage to stay under your commit and avoid an early renewal. But the renewal still gives you a black eye: 40% higher than last year. Your budget didn't grow that much. So you consider switching vendors, but asking your engineers to frantically migrate dashboards, alerts, and change workflows is a distraction that also reflects poorly on you. You're in a lose-lose situation. So you go back to your vendor and ask them to help. You championed them internally; brought them six, seven figure business. Surely they'd return the favor. A slightly bigger discount, help you cut costs by showing you what data is safe to drop. But they don't budge. They could help; they don't.&lt;/p&gt;
    &lt;p&gt;Case Taintor, Director of Engineering at Klarna, put it all too well:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The most frustrating part of watching your money burn is knowing your supplier could help if they only cared about your long term success.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So why has this gone on for over a decade? Something is deeply wrong if after ten years these same problems not only exist, but have gotten worse.&lt;/p&gt;
    &lt;p&gt;But what's wrong, exactly? Should your vendor help you? It is your data. They didn't create it. You sent it to them under their pricing model. For years I accepted that framing too. Maybe this is just how it works.&lt;/p&gt;
    &lt;p&gt;Then I bumped into a question that changed my thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;How much of my observability data is waste?&lt;/head&gt;
    &lt;p&gt;You've asked it. Your vendor has asked it. You know the answer isn't zero. But what is it? 10%? 20%? 40%? At what point does "that's just how it works" stop being an acceptable answer?&lt;/p&gt;
    &lt;p&gt;You see, anyone who's been in this space knows that cost is far and away the biggest problem. You can take all of the other problems, bundle them together, multiply them by 100, and they still would not surpass cost. It shows up everywhere. All of the "innovation" in observability can be traced back to cost in some way. Pipelines? Cost. Fancy new storages? Cost. OpenTelemetry? Yes, cost.&lt;/p&gt;
    &lt;p&gt;So in that context, this seems like a pretty important question. Maybe the most important question in observability. Which means it must be unanswerable, right? Because if someone could answer it and let you keep paying for garbage anyway, that would be unconscionable.&lt;/p&gt;
    &lt;p&gt;Put it to the test. Ask your vendor what percentage of your data is waste. They'll play ignorant. "It's your data." They don't understand it well enough to tell you what's worth keeping. But they understand it well enough to sell you an AI SRE that can "root cause in minutes."&lt;/p&gt;
    &lt;p&gt;It's this willful ignorance that gets me. Everyone knows what's right but plays the quarterly earnings game instead. Except it's not a game for the people on the other side. I got a front row seat with Vector users. Vector wasn't deployed for fun; it was often deployed in crisis, usually around renewal time when the cost of this game came due. I watched people lose their jobs for "mismanaging" the observability budget. I saw the stress on their faces, the lost sleep.&lt;/p&gt;
    &lt;p&gt;So when I first bumped into this question while helping a Vector user, and wanted to answer it but couldn't, that's when my optimism curdled.&lt;/p&gt;
    &lt;head rend="h2"&gt;So I answered it&lt;/head&gt;
    &lt;p&gt;After I left Vector, the question stayed with me. I took a year off, but Vector users still found me with questions. One in particular jumped out because it was impossible not to: emails, LinkedIn messages, people in my network pinging me on their behalf. I wasn't annoyed. I knew exactly what was going on. So I agreed to help. Except this time, no roadmaps, no one telling me what to do. In exchange, they'd give me access to their data so I could try to answer the question, which I suspected was their actual problem anyway.&lt;/p&gt;
    &lt;p&gt;So I signed all the docs, got access to their Vector environment, and took a look at their Vector config. It was the mother of all configs (sorry guys, no offense). Dozens of components connected into a complex DAG. Every cost reduction trick in the book: sampling, aggregating, storage tiering, archiving, and a massive list of regexes to match and drop waste. But I wasn't appalled, I respected it. They weren't being careless, they were doing everything they possibly could.&lt;/p&gt;
    &lt;p&gt;One trick in particular intrigued me: the regex list. It was the bottleneck, but it was also something else: an expression of understanding. Every pattern represented an engineer who understood their service well enough to say "this is waste." My first instinct was to optimize it. I stumbled on Hyperscan. Turns out you can compile tens of thousands of patterns and still match at line rate. That flipped my thinking: what if I took this to the extreme and automated that understanding to produce thousands of patterns?&lt;/p&gt;
    &lt;p&gt;So I built a system to do exactly that. It compressed billions of logs into thousands of semantic events, each one evaluated with the context it needed: the service, the failure scenarios, the patterns, how it all fits together. (The deep details are outside the scope of this post, but if you're curious, here's how it works today.)&lt;/p&gt;
    &lt;p&gt;I ran it against the first service: ~40% waste. Another: ~60%. Another: ~30%. On average, ~40% waste.&lt;/p&gt;
    &lt;p&gt;I knew the number wasn't zero, but I wasn't expecting 40%. So I pressure tested it. Went through hundreds of lines manually. Checked it against their existing patterns. It checked out. With that confidence, I brought it to them.&lt;/p&gt;
    &lt;p&gt;They laughed. "We can't just drop half of our logs." Fair. But that's not what I was asking. I showed them: this wasn't anything new. It was the same analysis they were already doing, just at scale, more complete, more accurate. Most of their hand-written patterns were already represented in my set, often simpler and faster. They could tweak the analysis, roll it out slowly, push it to teams to take action in their own code.&lt;/p&gt;
    &lt;p&gt;And that's what happened. The knowledge stopped the bleeding. Over time, services cleaned up their logging. Pipelines got simpler. Bills went down. Not because anyone dropped data recklessly, but because they finally knew what was worth keeping.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why observability feels broken&lt;/head&gt;
    &lt;p&gt;The answer to this question isn't just a number. It's the answer to why observability feels broken despite it being more expensive than ever. Think about it.&lt;/p&gt;
    &lt;p&gt;On the surface: you're paying twice what you should. Cut the waste, cut the bill. Simple.&lt;/p&gt;
    &lt;p&gt;Go deeper: the cost policing, the weekly dashboard checks, the monthly exercises, the begging your rep for forgiveness when someone's log blows up the bill, the pipelines. All of that exists because you're managing garbage. Half the complexity you've built is dedicated to noise.&lt;/p&gt;
    &lt;p&gt;Go deeper still: your engineers complain that observability doesn't help them debug faster despite costing millions. Of course it doesn't. They're drowning in noise and calling it data. The alerts fire on garbage. The dashboards are cluttered with garbage. The AI can't find the signal because there's too much garbage in the way.&lt;/p&gt;
    &lt;p&gt;And underneath all of it: this number shouldn't exist if your vendor was aligned with you.&lt;/p&gt;
    &lt;p&gt;Take a look around the market. $65M bills. $170M bills. Entire roles for cost control. "Observe without limits." "Stop sampling." "More data, more insight." Dozens of products. It's all backwards. The goal isn't more data, more products, or more complexity.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The goal is understanding with less.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And how do you prove understanding? The question. Either you understand the data well enough to answer it or you don't.&lt;/p&gt;
    &lt;p&gt;There's a future where you're not the cost cop. Where observability just works. Where your vendor's success depends on yours.&lt;/p&gt;
    &lt;p&gt;That's the future we're building at Tero.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46617744</guid><pubDate>Wed, 14 Jan 2026 16:07:34 +0000</pubDate></item><item><title>GitHub should charge everyone $1 more per month to fund open source</title><link>https://blog.greg.technology/2025/11/27/github-should-charge-1-dollar-more-per-month.html</link><description>&lt;doc fingerprint="af69305bfd93efbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GitHub should charge everyone $1 more per month&lt;/head&gt;
    &lt;p&gt;Listen to me.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;there should be a thing that reads your package.json and charges you $5/month per dependency - you don’t /have/ to! you could set the price to $1 per employee! - and then holds the funds and sends it to the people who made the code you use to do business how is not doing this more sustainable&lt;/p&gt;— Greg Technology ❪⎷❫ (@greg.technology) January 13, 2026 at 9:13 PM&lt;/quote&gt;
    &lt;p&gt;It is crazy, absolutely crazy to depend on open source to be free (as beer). It is not okay - it is not okay to consider that this labor fell from the sky and is a gift, and that the people/person behind are just doing it for their own enjoyments.&lt;/p&gt;
    &lt;p&gt;It is impossible to imagine that what we’re doing today is the only way. Begging/busking for donations, hoping to get noticed. Hoping for a lifeline.&lt;/p&gt;
    &lt;p&gt;Hence, a solution. Or an idea, really. Incredibly half-baked. Poke all the holes you want. It’s very unwrought and muy unripe.&lt;/p&gt;
    &lt;p&gt;GitHub should charge every org $1 more per user per month and direct it into an Open Source fund, held in escrow.&lt;/p&gt;
    &lt;p&gt;Those funds would then be distributed by usage - every mention in a package.json or requirements.txt gets you a piece of the pie.&lt;/p&gt;
    &lt;p&gt;You know how the money you pay to Spotify is very very very approximately (and not really fairly) distributed among artists that you listened to? Yes, Spotify is a very flawed model and artists are not doing well. But it is a model??&lt;/p&gt;
    &lt;p&gt;That’s it. That’s the idea. Call it the “Open Source Fund” thing, make it opt-out. Give every org a magical badge - or the ability to set their profile’s background css.&lt;/p&gt;
    &lt;p&gt;Or don’t! Let’s not do anything! People’s code and efforts - fueling incredibly critical bits of infrastructure all around the world - should just be up for grabs. Haha! Suckers!&lt;/p&gt;
    &lt;p&gt;Alright, I don’t know how you fund Linux (does Linux appear in a requirements file). Hmm. Maybe &lt;code&gt;FROM&lt;/code&gt; commands from Dockerfiles are also read &amp;amp; applied. Maybe we at least start somewhere?&lt;/p&gt;
    &lt;p&gt;Anyway, you all smarter than me people can figure it out. I just cannot accept that what we have is “GOOD”. xx&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46618027</guid><pubDate>Wed, 14 Jan 2026 16:25:07 +0000</pubDate></item><item><title>The Unbearable Frustration of Figuring Out APIs</title><link>https://blog.ar-ms.me/thoughts/translation-cli/</link><description>&lt;doc fingerprint="56021e198a12bc50"&gt;
  &lt;main&gt;
    &lt;p&gt;In the ongoing effort for activities that fill the void made by unemployment, I have recently started to learn Chinese. Got into a Chinese language institute and everything. And because not every app supports right-clicking some text and selecting the "Translate" menu option, I found myself launching TextEdit just to do that. So, I figured, maybe I can do a small command line tool where I'd write something like:&lt;/p&gt;
    &lt;code&gt;translate 你好&lt;/code&gt;
    &lt;p&gt;And the terminal would happily tell me it means "Hello". Should be easy. A hungry ghost trapped in a jar can probably figure it out in one shot.&lt;/p&gt;
    &lt;p&gt;First I figured I'd look for some translation API. Almost everything I looked at seemed to want an API token and there is a rate limit (not that I'd hit it), and maybe a credit card number. Then I remembered that macOS has that Translate right click action, surely I can just hook into that.&lt;/p&gt;
    &lt;p&gt;Note that this article, unlike what I do usually, is written after the fact.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Steps&lt;/head&gt;
    &lt;head rend="h3"&gt;Zig&lt;/head&gt;
    &lt;p&gt;I have been using Zig for different projects this year. So I got the Ghost to write the thing for me, and it even gave me the correct flags to pass to the compiler! But then when I tried it, I realized it used the Dictionary service instead of the Translation service. When I asked it for that instead, it was like yeah you cannot call Swift &lt;code&gt;async&lt;/code&gt; functions from Zig, you need a Swift shim.&lt;/p&gt;
    &lt;p&gt;So let's do the thing in Swift instead. I have been meaning to learn Swift anyway.&lt;/p&gt;
    &lt;head rend="h3"&gt;MyCLI&lt;/head&gt;
    &lt;p&gt;Thankfully, Swift was already set up on my machine with an LSP and a formatter and the works. I had even followed the basic tutorial and the file is on my machine already, A small edit and I can be on my way.&lt;/p&gt;
    &lt;p&gt;For reference, this is the code at the end of the tutorial:&lt;/p&gt;
    &lt;code&gt;import ArgumentParser
import Figlet

@main
struct FigletTool: ParsableCommand {
	@Option: "Specify the input"
	public var input: String

	public func run() throws {
		Figlet.say(self.input)
	}
}&lt;/code&gt;
    &lt;p&gt;After so long in Rust and Zig lands, the most jarring thing about Swift so far is that &lt;code&gt;import&lt;/code&gt; creates glob imports. This is not quite apparent here, but it is there. Also, this is the accompanying &lt;code&gt;Package.swift&lt;/code&gt;, comments and all.&lt;/p&gt;
    &lt;code&gt;// swift-tools-version: 5.8
// The swift-tools-version declares the minimum version of Swift required to build this package.

import PackageDescription

let package = Package(
    name: "MyCLI",
    dependencies: [
      .package(url: "https://github.com/apple/example-package-figlet", branch: "main"),
      .package(url: "https://github.com/apple/swift-argument-parser", from: "1.0.0"),
    ],
    targets: [
        // Targets are the basic building blocks of a package, defining a module or a test suite.
        // Targets can depend on other targets in this package and products from dependencies.
        .executableTarget(
            name: "MyCLI",
            dependencies: [
                .product(name: "Figlet", package: "example-package-figlet"),
                .product(name: "ArgumentParser", package: "swift-argument-parser"),
            ],
            path: "Sources"),
    ]
)&lt;/code&gt;
    &lt;p&gt;This is run with &lt;code&gt;swift run&lt;/code&gt;, but to pass arguments, one needs to do the following:&lt;/p&gt;
    &lt;code&gt;swift run MyCLI --input Hello&lt;/code&gt;
    &lt;p&gt;I spent like 15 minutes trying different variations of this&lt;/p&gt;
    &lt;code&gt;# this does NOT work
swift run -- --input Hello&lt;/code&gt;
    &lt;p&gt;Anyway, I deleted the &lt;code&gt;Figlet&lt;/code&gt; related lines and went from there.&lt;/p&gt;
    &lt;head rend="h2"&gt;False Starts&lt;/head&gt;
    &lt;p&gt;I asked the Ghost in the Jar for how the API to use it looks like, but every version it gave me was hallucinated in some fashion. So I wrote &lt;code&gt;import Translation&lt;/code&gt; at the top of the file, and figured maybe I can figure it out as I go along. Here is the Apple API documentation. A quick look tells you all the functions in here return a &lt;code&gt;some View&lt;/code&gt;, and the only function seemingly unrelated to SwiftUI is the &lt;code&gt;init&lt;/code&gt; function in &lt;code&gt;TranslationSession&lt;/code&gt;, which, annoyingly, needs a known source language.&lt;/p&gt;
    &lt;p&gt;So I do this&lt;/p&gt;
    &lt;code&gt;import ArgumentParser
import Translation

@main
struct Translate: ParsableCommand {
	@Argument: "Specify the input"
	public var input: String

	public func run() async throws {
		print("&amp;gt;\t\(input)")

		let source = Locale.Language(identifier: "zh_CN")
		let target = Locale.Language(identifier: "en_US")

		let session = TranslationSession(installedSource: source, target: target)

		let response = try await session.translate(input)
		let result = response.targetText

		print("&amp;gt;\t\(result)")

	}
}&lt;/code&gt;
    &lt;p&gt;You can see the number of small changes to the original file here. I changed the struct's name (because it shows up in the &lt;code&gt;--help&lt;/code&gt; message.) I changed &lt;code&gt;Option&lt;/code&gt; to &lt;code&gt;Argument&lt;/code&gt; so it does not need a flag. I even turned &lt;code&gt;run&lt;/code&gt; into an &lt;code&gt;async&lt;/code&gt; function so I can &lt;code&gt;await&lt;/code&gt; the &lt;code&gt;session.translate&lt;/code&gt; function call.&lt;/p&gt;
    &lt;p&gt;However, I start to hit a couple of snags. First is that &lt;code&gt;TranslationSession.init&lt;/code&gt; is restricted to macOS 26. Not wanting to do a bunch of conditional compilation, (after all this tool is for my own use), I will just add the &lt;code&gt;platforms&lt;/code&gt; field in &lt;code&gt;Package.swift&lt;/code&gt;。 Oh it needs to be before &lt;code&gt;dependencies&lt;/code&gt;? Fine, whatever.&lt;/p&gt;
    &lt;code&gt;// swift-tools-version: 5.8
// The swift-tools-version declares the minimum version of Swift required to build this package.

import PackageDescription

let package = Package(
	name: "MyCLI",
	platforms: [
		.macOS( /* one problem, I cannot find v26 in the dropdown */)
	],
	dependencies: [
		.package(url: "https://github.com/apple/swift-argument-parser", from: "1.0.0")
	],
	targets: [
		// Targets are the basic building blocks of a package, defining a module or a test suite.
		// Targets can depend on other targets in this package and products from dependencies.
		.executableTarget(
			name: "MyCLI",
			dependencies: [
				.product(name: "ArgumentParser", package: "swift-argument-parser")
			],
			path: "Sources",
		)
	]
)&lt;/code&gt;
    &lt;p&gt;I cannot find &lt;code&gt;.v26&lt;/code&gt; in the LSP's drop down. There is no &lt;code&gt;.Tahoe&lt;/code&gt; either. Even if I type it manually, I get an error. I am on Tahoe. I have the latest version of Swift (I checked). why can't I select it from here?&lt;/p&gt;
    &lt;p&gt;You probably already know this, but apparently the first line in the file, that comment, is actually significant. I edited that to say &lt;code&gt;swift-tools-version: 6.2&lt;/code&gt;, and now I can write &lt;code&gt;.v26&lt;/code&gt; in peace. I hate syntactic comments.&lt;/p&gt;
    &lt;p&gt;Ok, the LSP is happy. The compiler seems happy. Let's get going.&lt;/p&gt;
    &lt;head rend="h2"&gt;Async Woes&lt;/head&gt;
    &lt;p&gt;Running this with &lt;code&gt;swift run -q MyCLI 你好&lt;/code&gt; gives the following message:&lt;/p&gt;
    &lt;code&gt;USAGE: translate &amp;lt;input&amp;gt;

ARGUMENTS:
  &amp;lt;input&amp;gt;                 Specify the input

OPTIONS:
  -h, --help              Show help information.&lt;/code&gt;
    &lt;p&gt;Eh, I clearly passed in something. What gives? I tried changing &lt;code&gt;Argument&lt;/code&gt; back to &lt;code&gt;Option&lt;/code&gt;, same result. Hm. I realized that the problem maybe is that &lt;code&gt;run&lt;/code&gt; is not supposed to be &lt;code&gt;async&lt;/code&gt;. Fine, let's remove &lt;code&gt;async&lt;/code&gt;, but then how do I call &lt;code&gt;session.translate&lt;/code&gt; ?&lt;/p&gt;
    &lt;p&gt;Looking things up, and communing with ghosts, apparently I can wrap thing in &lt;code&gt;Task&lt;/code&gt;. Sure.&lt;/p&gt;
    &lt;code&gt;Task {
	let response = try await session.translate(input)
	let result = response.targetText

	print("&amp;gt;\t\(result)")
}&lt;/code&gt;
    &lt;p&gt;And this runs! I rerun the command I do &lt;code&gt;swift run -q MyCLI 你好&lt;/code&gt; and I get ... nothing. Just the print message that prints &lt;code&gt;input&lt;/code&gt; at the start. I think hah .. I have fallen into the classic trap, I am spawning a Task but I am not waiting for it. How do I wait for it?&lt;/p&gt;
    &lt;p&gt;The ghosts suggested a &lt;code&gt;DispatchSemaphore&lt;/code&gt;. This is the full code:&lt;/p&gt;
    &lt;code&gt;import ArgumentParser
import Translation

@main
struct Translate: ParsableCommand {
	@Argument: "Specify the input"
	public var input: String

	public func run() throws {
		print("&amp;gt;\t\(input)")

		let source = Locale.Language(identifier: "zh_CN")
		let target = Locale.Language(identifier: "en_US")

		let session = TranslationSession(installedSource: source, target: target)
		let semaphore = DispatchSemaphore(value: 0)

		Task {
			let response = try await session.translate(input)
			let result = response.targetText

			print("&amp;gt;\t\(result)")
			semaphore.signal()
		}
		semaphore.wait()

	}
}&lt;/code&gt;
    &lt;p&gt;Ok .. for some reason, when I tried this right now, it actually works. But when I tried it before, probably with a different arrangement of stuff, it did not. It just froze and gave no feedback. The power of hindsight, I guess.&lt;/p&gt;
    &lt;p&gt;Nonetheless, since it did not work, I figured I was doing something wrong. So I searched for "how to call an async function from a sync function in Swift", and came across What calls the first async function? from Hacking With Swift, and the tl;dr of that article was "not you, just make your main &lt;code&gt;async&lt;/code&gt;". Very helpful, Paul. Apparently I needed to make &lt;code&gt;run&lt;/code&gt; async. I looked into the docs of &lt;code&gt;swift-argument-parser&lt;/code&gt;, I fgured surely they have some guidance on how to deal with &lt;code&gt;async&lt;/code&gt; functions. Apparently the guidance was just to replace the &lt;code&gt;ParsableCommand&lt;/code&gt; protocol with &lt;code&gt;AsyncParsableCommand&lt;/code&gt;. Ok, now I felt like an idiot. This is the full code:&lt;/p&gt;
    &lt;code&gt;import ArgumentParser
import Translation

@main
struct Translate: AsyncParsableCommand {
	@Argument: "Specify the input"
	public var input: String

	public func run() async throws {
		print("&amp;gt;\t\(input)")

		let source = Locale.Language(identifier: "zh_CN")
		let target = Locale.Language(identifier: "en_US")

		let session = TranslationSession(installedSource: source, target: target)

		let response = try await session.translate(input)
		let result = response.targetText

		print("&amp;gt;\t\(result)")

	}
}&lt;/code&gt;
    &lt;p&gt;Works like magic now. Except, at the time, it did not. It gave me the following message:&lt;/p&gt;
    &lt;code&gt;&amp;gt;	你好
Error: Unable to Translate&lt;/code&gt;
    &lt;p&gt;Also it leaves the small detail of autodetecting the language, which is here hardcoded as &lt;code&gt;zh_CN&lt;/code&gt;.1&lt;/p&gt;
    &lt;head rend="h2"&gt;Language Recognition&lt;/head&gt;
    &lt;p&gt;The error had zero feedback. Absolutely unhelpful. No idea what's going on. I added a &lt;code&gt;try await session.prepareTranslation()&lt;/code&gt; line I saw in some online examples, but .. nothing. I looked a bit more around for tutorials, I could not find anything. All tutorials just regurgitate the same SwiftUI code examples, but I am not using SwiftUI. Ekh.&lt;/p&gt;
    &lt;p&gt;Eventually, I came across the original WWDC video introducing the Translation API, and decided to watch it. And it was actually very helpful, despite it being SwiftUI focused.&lt;/p&gt;
    &lt;p&gt;It does not touch on how to use &lt;code&gt;TranslationSession.init&lt;/code&gt;, instead it mentions that a &lt;code&gt;session&lt;/code&gt; is given to you to run in a SwiftUI closure. It gives the rationale behind the API, but it also introduces the bit I needed for autodetection, and that is &lt;code&gt;NLLanguageRecognizer&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;NaturalLanguage&lt;/code&gt; is an Apple framework for dealing with natural language (How did you guess?). I pretty much copied the code from the video into its own function (after &lt;code&gt;import NaturalLanguage&lt;/code&gt;).&lt;/p&gt;
    &lt;code&gt;func identify_lang(_ sample: String) -&amp;gt; Locale.Language? {
	let recognizer = NLLanguageRecognizer()
	recognizer.processString(sample)
	guard let language = recognizer.dominantLanguage else { return nil }

	return Locale.Language(identifier: language.rawValue)
}&lt;/code&gt;
    &lt;p&gt;And this is my new &lt;code&gt;func run()&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;public func run() async throws {
	print("&amp;gt;\t\(input)")

	// unwrapping here but I handle it more gracefully in the code
	let source = identify_lang(input)!
	let target = Locale.Language(identifier: "en_US")

	let session = TranslationSession(installedSource: source, target: target)
	try await session.prepareTranslation()

	let response = try await session.translate(input)
	let result = response.targetText

	print("&amp;gt;\t\(result)")

}&lt;/code&gt;
    &lt;p&gt;The other thing the video pointed out, is that the API user should check language availability. I saw that earlier, but did not particularly care. I know Chinese and English are available. I have been using them! Nonetheless, I copied that code as well just to be thorough, to figure out what the API does.&lt;/p&gt;
    &lt;code&gt;let availability = LanguageAvailability()
let is_it = await availability.status(from: source, to: target)
switch is_it {
case .unsupported:
	print("&amp;gt; language pairing from \(source.languageCode) to \(target.languageCode) unsupprted")
	return
case .supported:
	print("&amp;gt; language pairing from \(source.languageCode!) to \(target.languageCode!) not installed")
	return
case .installed:
	break
}&lt;/code&gt;
    &lt;p&gt;This gave me a compile error, as it happens, as apparently the enum is marked the Swift equivelant of &lt;code&gt;#[non_exhaustive]&lt;/code&gt;. Going over StackOverflow and the Swift book, told me the answer is to add a &lt;code&gt;@unknown default:&lt;/code&gt; case. I could not quickly figure out how to merge it with another case so I did not bother.&lt;/p&gt;
    &lt;p&gt;To my surprise, the pairing returned &lt;code&gt;.supported&lt;/code&gt;, and not &lt;code&gt;.installed&lt;/code&gt;. In a SwiftUI app, the &lt;code&gt;try await session.prepareTranslation()&lt;/code&gt; call creates a pop up to ask the user to download the model.&lt;/p&gt;
    &lt;p&gt;But it is already installed! I am already using it via the right click menu! Nonetheless, that must be the reason for the &lt;code&gt;Unable to Translate&lt;/code&gt; error.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing Models&lt;/head&gt;
    &lt;p&gt;Communing again with Ghosts, they told me to install the models through System Settings, General, Language, etc. I went where they told me, to this dialogue, where I can install the models locally.&lt;/p&gt;
    &lt;p&gt;You can see that Mandarin is installed now, but the only language installed at the time was English(US). No matter, I installed Mandarin SImplified and Arabic, and added a note to the &lt;code&gt;switch&lt;/code&gt; above showing where to install the items. And then I tried again: &lt;code&gt;swift run -q MyCLI 你好&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And .. same error. I guessed that it identified the language as Mandarin Traditional for some reason, so I installed that as well, and now it works, finally!!&lt;/p&gt;
    &lt;code&gt;% swift/MyCLI ❭ swift run -q MyCLI 你好
&amp;gt;	你好
&amp;gt;	Hello&lt;/code&gt;
    &lt;p&gt;Why was that so hard? Why are the models here separate from the ones in the right click menu? Too many questions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Code&lt;/head&gt;
    &lt;p&gt;This is the full final code, with some proper error names thrown in for good measure.&lt;/p&gt;
    &lt;code&gt;import ArgumentParser
import NaturalLanguage
import Translation

@main
struct Translate: AsyncParsableCommand {
	@Argument: "Specify the input"
	public var input: String

	public func run() async throws {
		print("&amp;gt;\t\(input)")

		let target = Locale.Language(identifier: "en_US")
		guard let source = identify_lang(input) else {
			print("&amp;gt; could not identify language")
			throw CliError.Recognitionfailed
		}

		let availability = LanguageAvailability()
		let is_it = await availability.status(from: source, to: target)
		switch is_it {
		case .unsupported:
			print("&amp;gt; language pairing from \(source.languageCode) to \(target.languageCode) unsupprted")
			throw CliError.PairingUnsupported
		case .supported:
			print("&amp;gt; language pairing from \(source.languageCode!) to \(target.languageCode!) not installed")
			print("&amp;gt; Go to System Settings &amp;gt; General &amp;gt; Language &amp;amp; Region &amp;gt; Translation Languages and download the models.")
			throw CliError.PairingNotInstalled
		case .installed:
			break
		@unknown default:
			print("Unknown status.")
		}

		let session = TranslationSession(installedSource: source, target: target)
		try await session.prepareTranslation()

		let response = try await session.translate(input)
		let result = response.targetText

		print("&amp;gt;\t\(result)")

	}
}

func identify_lang(_ sample: String) -&amp;gt; Locale.Language? {
	let recognizer = NLLanguageRecognizer()
	recognizer.processString(sample)
	guard let language = recognizer.dominantLanguage else { return nil }

	return Locale.Language(identifier: language.rawValue)
}

enum CliError: Error {
	case Recognitionfailed
	case PairingUnsupported
	case PairingNotInstalled
}&lt;/code&gt;
    &lt;p&gt;So I compiled it for release, put it in &lt;code&gt;/usr/local/bin&lt;/code&gt;, and called it a day. You can see an example of a failing call if you do &lt;code&gt;swift run -q MyCLI Bonjour&lt;/code&gt;, where it prompts to install the dictionary.&lt;/p&gt;
    &lt;head rend="h2"&gt;In Conclusion&lt;/head&gt;
    &lt;p&gt;To rub some salt on the wound, during the time I was trying to puzzle this out, I realized that Spotlight (with the Cmd+Space key) can already do this exactly How I envisioned it, with around the same number of keyatrokes, and it does not need this dance with installing models and whatever.2&lt;/p&gt;
    &lt;p&gt;Also, Swift is frustrating. API of Swift libraries is frustrating.&lt;/p&gt;
    &lt;p&gt;Until later.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;By the way, there is no documentation anywhere I could find on what the strings accepted here are. The only comment exists is "A Unicode language identifier, like&lt;/p&gt;&lt;code&gt;en-US&lt;/code&gt;,&lt;code&gt;es-419&lt;/code&gt;, or&lt;code&gt;zh-Hant-TW&lt;/code&gt;." No list or anything. Am I supposed to guess? ↩&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Also this supports Chinese input, while Ghostty's quick terminal does not, for some reason. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46618087</guid><pubDate>Wed, 14 Jan 2026 16:28:53 +0000</pubDate></item><item><title>How have prices changed in a year? NPR checked 114 items at Walmart</title><link>https://www.npr.org/2026/01/14/nx-s1-5638908/walmart-prices-inflation-affordability-shrinkflation</link><description>&lt;doc fingerprint="e4a01c149cb25fba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How have prices changed in a year? NPR checked 114 items at Walmart&lt;/head&gt;
    &lt;head rend="h4"&gt;How have prices changed in a year? NPR checked 114 items at Walmart&lt;/head&gt;
    &lt;p&gt;LIBERTY COUNTY, Ga. — What brings Greg Reyes to this Walmart south of Savannah are the low prices. He and his wife keep a close eye on their limited budget; she's retired and he's disabled. Their grocery list is always the same. But the prices have been changing.&lt;/p&gt;
    &lt;p&gt;"I used to pay like $40 a year ago, and now we're paying like $60," Reyes says. In his bags today are some chicken, turkey and beef. Other things simply had to go. "We don't buy ice cream no more because it's expensive," Reyes says. "It's kind of sad, but we have to do it like that."&lt;/p&gt;
    &lt;p&gt;The cost of living in the U.S. rose 2.7% in December compared with a year before, according to Tuesday's federal data. That's a steady slowdown after a yearslong stretch of intense inflation, but still painful. The past year also brought a global trade war, as President Trump imposed sweeping tariffs on nearly all imports. And the world continued to grapple with extreme weather, from droughts to downpours.&lt;/p&gt;
    &lt;p&gt;All of this is showing up in our shopping carts.&lt;/p&gt;
    &lt;p&gt;Since 2018, NPR has tracked the prices of dozens of items at this suburban Walmart superstore. Walmart is America's most popular retailer and the world's largest, which gives it the power to negotiate with suppliers for some of the lowest and most stable prices.&lt;/p&gt;
    &lt;p&gt;Here's what we learned on our latest price-check visit, in December. (Or skip the analysis to see the full details of NPR's shopping cart.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Prices in NPR's basket rose 5% on average last year&lt;/head&gt;
    &lt;p&gt;Almost half the items on NPR's shopping list got more expensive in 2025, including shrimp, Oreo cookies, Coca-Cola and Dove soap. Some price increases, notably on items made in China and Vietnam, appear to be tariff related. Other price hikes had to do with weather events affecting harvests of crops such as cacao and coffee beans.&lt;/p&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;Just under a quarter of the items on NPR's list got cheaper, including eggs, milk and Cheerios. And many packaged foods stayed the same after years of price hikes.&lt;/p&gt;
    &lt;p&gt;As affordability became Americans' top concern, big brands began to worry about shoppers switching to store-label competitors or skipping some purchases altogether. To entice weary shoppers, NPR found, Walmart offered more discounts in December than it had in previous years.&lt;/p&gt;
    &lt;p&gt;A few disclaimers about our method:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We went through almost every aisle in this Walmart to come up with the 114 items. (The full table is below.) To account for possible changes in package sizes, we focused on the price per unit, whether it was an ounce of salsa or a square foot of aluminum foil.&lt;/item&gt;
      &lt;item&gt;NPR reached out to the producers of all the items on our list that changed in price. Most companies did not respond. The few that did — including Kikkoman and Campbell's — noted that Walmart, as the retailer, has ultimate control over the prices that shoppers see on shelves.&lt;/item&gt;
      &lt;item&gt;A Walmart spokesperson said in a statement: "We remain dedicated to providing our customers Every Day low prices, with the goal of having the lowest price on a basket of goods over time." A store, for example, might extract deals from suppliers or charge slightly more for several items in order to sell something else at a break-even price or even below cost.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Tariffs loom over store shelves&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;With tariffs being the biggest story in retail in 2025, signs of their impact inevitably showed up in Walmart's aisles. Though it's hard to pin any price increase on tariffs with certainty, the through line was noticeable.&lt;/p&gt;
    &lt;p&gt;Some of the biggest price jumps were on items imported from countries saddled with hefty tariffs: Walmart's store-brand paper folders made in China (up 46%), swai fish fillets from Vietnam (up 34%), Farberware's plastic measuring spoons made in China (up 19%) and Schwinn's infant bike helmet, which used to be made in China but is now made in Vietnam (up 18%).&lt;/p&gt;
    &lt;p&gt;Walmart, Farberware and Schwinn did not comment on the impact of tariffs to NPR, but several other companies did. Dole, whose canned pineapple from Southeast Asia got 25% more expensive, cited weather-related crop shortages and tariffs on goods imported from the region.&lt;/p&gt;
    &lt;p&gt;Reynolds Wrap, whose aluminum foil rose in price by 13%, called out "historic and sustained cost increases over the past year, driven by tariffs, global supply pressures, rising energy costs, and limited availability." Much of U.S. aluminum comes from Canada, and these imports now face a 50% tax.&lt;/p&gt;
    &lt;p&gt;Walmart in May warned that new tariffs would lead to higher prices, as Trump threatened 145% tariffs on goods from China. The White House later paused, changed up and even rolled back some of its trade plans, namely on food items. By August, Walmart officials said tariff costs were rising "each week," although the company was able to mitigate many of them. In November, incoming Walmart CEO John Furner said tariffs brought "less impact" than expected early in the year.&lt;/p&gt;
    &lt;head rend="h3"&gt;Climate chaos roiled many industries&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;Some of the items with the worst price hikes are repeat offenders: coffee, beef and chocolate. They, too, were affected by tariffs — such as beef and coffee coming from Brazil — but the main culprit was the weather.&lt;/p&gt;
    &lt;p&gt;At this Walmart, the price of Maxwell House ground Colombian coffee rose by 46% in 2025 and its breakfast K-Cups by 34%. The costs of Hershey's and Lindt chocolates jumped around 26%. A pound of ground beef went up 30%, and the store now prominently displays a cheaper option: a blend of beef and ground pork.&lt;/p&gt;
    &lt;p&gt;The cost of coffee beans has soared as climate change has brought erratic rainfall patterns, floods and droughts to farmlands. Cacao harvests, too, have come up short for three years straight; West African farmers, who grow most of the world's supply, have dealt with extreme weather, changing climate patterns and disease in their aging trees. And the U.S. beef supply is at its lowest in decades, driving cattle prices to record highs, in part because of drought.&lt;/p&gt;
    &lt;p&gt;Kraft Heinz (which owns Maxwell House), Hershey and Lindt &amp;amp; Sprüngli in statements all cited the unprecedented higher costs of key raw materials, adding that they've also absorbed or offset part of those costs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Shrinkflation continues in the laundry aisle&lt;/head&gt;
    &lt;p&gt;When inflation peaked after the COVID-19 pandemic, some manufacturers stealthily raised prices by shrinking their products — shampoo, paper towels, chips and candy — while charging the same or slightly more. In 2022, for example, NPR's Walmart visit found that Dove soap bars had shrunk by a quarter of an ounce, while rising in price by a few cents. (Dove maker Unilever did not comment.)&lt;/p&gt;
    &lt;p&gt;Last month, NPR spotted one case of shrinkflation: Tide laundry detergent. But the company says it's actually efficiency.&lt;/p&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;NPR first spotted Tide selling less laundry detergent per bottle in 2022: The amount of liquid had shrunk to 92 ounces from 100 ounces before the pandemic, and the price had risen by a dollar. After that, the cost stayed the same, but the contents shrank to 84 ounces in 2024 and then to 80 ounces in December.&lt;/p&gt;
    &lt;p&gt;The label continuously promised enough detergent for 64 loads of laundry.&lt;/p&gt;
    &lt;p&gt;Procter &amp;amp; Gamble, which makes Tide as well as Head &amp;amp; Shoulders shampoo (whose price rose almost 18%), told NPR that both products saw "meaningful upgrades" in the past year. Tide specifically got the "most significant upgrade to its liquid formula in over 20 years," according to the company, with a "boosted" level of active cleaning ingredients and updated dosage instructions.&lt;/p&gt;
    &lt;p&gt;"The result is superior cleaning performance in a smaller dose," a Procter &amp;amp; Gamble representative said.&lt;/p&gt;
    &lt;head rend="h3"&gt;Good news! Some things are cheaper&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;The biggest price drop finally came for eggs after record highs earlier in the year due to the persistent bird flu. By December, the price of a dozen eggs at Walmart dropped 30%. The cost of butter also dipped, by almost 16%, thanks to a glut in dairy production.&lt;/p&gt;
    &lt;p&gt;And as inflation-weary shoppers tighten their belts, brands have started doing something they rarely do: lowering prices. PepsiCo (maker of Lay's, Cheetos and Tostitos) last month said it would cut prices to boost sales. General Mills (maker of Cheerios, Betty Crocker and Annie's) also confirmed it plans to discount roughly two-thirds of its offerings. NPR's price check found Cheerios costing 19% less than a year ago.&lt;/p&gt;
    &lt;p&gt;A Walmart spokesperson also told NPR that the chain has added more discounts (or "rollbacks," in Walmart parlance) than it had in the past two years. The company cited 13,000 of them in the first three quarters of 2025, of which about 2,000 became permanent price cuts.&lt;/p&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46618272</guid><pubDate>Wed, 14 Jan 2026 16:39:43 +0000</pubDate></item><item><title>Ask HN: Could you share your personal website here?</title><link>https://news.ycombinator.com/item?id=46618714</link><description>&lt;doc fingerprint="a785b41f6be747ae"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hello HN! I am putting together a community-maintained directory of personal websites at &amp;lt;https://hnpwd.github.io/&amp;gt;. More details about the project can be found in the README at &amp;lt;https://github.com/hnpwd/hnpwd.github.io#readme&amp;gt;.&lt;/p&gt;
      &lt;p&gt;As you can see, the directory currently has only a handful of entries. I need your help to grow it. If you have a personal website, I would be glad if you shared it here. If your website is hosted on a web space where you have full control over its design and content, and if it has been well received in past HN discussions, I might add it to the directory. Just drop a link in the comments. Please let me know if you do not want your website to be included in the directory.&lt;/p&gt;
      &lt;p&gt;Also, I intend this to be a community maintained resource, so if you would like to join the GitHub project as a maintainer, please let me know either here or via the IRC link in the README.&lt;/p&gt;
      &lt;p&gt;By the way, see also 'Ask HN: Could you share your personal blog here?' - https://news.ycombinator.com/item?id=36575081 - July 2023 - (1014 points, 1940 comments). In this post, the scope is not restricted to blogs though. Any personal website is welcome, whether it is a blog, digital garden, personal wiki or something else entirely.&lt;/p&gt;
      &lt;p&gt;UPDATE: It is going to take a while to go through all the submissions and add them. If you'd like to help with the process, please send a PR directly to this project: https://github.com/hnpwd/hnpwd.github.io&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46618714</guid><pubDate>Wed, 14 Jan 2026 17:07:42 +0000</pubDate></item><item><title>Ford F-150 Lightning outsold the Cybertruck and was then canceled for poor sales</title><link>https://electrek.co/2026/01/13/ford-f150-lightning-outsold-tesla-cybertruck-canceled-not-selling-enough/</link><description>&lt;doc fingerprint="69e41a162a9b1fd9"&gt;
  &lt;main&gt;
    &lt;p&gt;The Tesla Cybertruck program is in shambles. The latest data indicate production is running at roughly 10% of its planned capacity. Meanwhile, the Ford F150 Lightning outsold the Tesla Cybertruck in 2025 and was then canceled for not selling enough.&lt;/p&gt;
    &lt;p&gt;Is this what is coming for the Cybertruck?&lt;/p&gt;
    &lt;p&gt;Tesla is actively trying to hide its Cybertruck sales performance. We have to do the math ourselves.&lt;/p&gt;
    &lt;p&gt;Unlike virtually every other automaker that reports sales by model and region, Tesla bundles its vehicles into two broad categories: “Model 3/Y” and “Other Models.”&lt;/p&gt;
    &lt;p&gt;The “Other Models” category includes the Model S, Model X, Cybertruck, and the Tesla Semi.&lt;/p&gt;
    &lt;p&gt;Model S and Model X sales have been relatively stable at a low volume, typically hovering around 5,000 to 6,000 units combined per quarter globally. If we assume a generous 6,000 units for S and X in Q4 2025 (aided by a slight update), that leaves only roughly 5,600 units for the Cybertruck and Semi combined.&lt;/p&gt;
    &lt;p&gt;Considering the Semi is still in pilot production with negligible volume, we are looking at roughly 5,500 for the entire quarter globally (though it is still mostly North American).&lt;/p&gt;
    &lt;p&gt;This is a disaster compared to the truck’s peak and the company’s stated capacity.&lt;/p&gt;
    &lt;p&gt;We previously reported in July that Tesla confirmed Cybertruck sales were down to ~5,000 units in Q2 2025. It seems the “recovery” never happened, despite price cuts and the introduction of a short-lived, cheaper trim.&lt;/p&gt;
    &lt;p&gt;For the full year 2025, it could bring the total to about 21,500 Cybertrucks globally.&lt;/p&gt;
    &lt;p&gt;According to 2025 full-year data, the Ford F-150 Lightning delivered approximately 27,300 units in the US.&lt;/p&gt;
    &lt;p&gt;Think about that for a second. Ford officially announced it was ending F-150 Lightning production in December to pivot to its new EREV (extended-range electric vehicle) strategy. Yet, even as a “lame duck” product with widely publicised retirement plans, the Lightning still managed to find more buyers than Tesla’s Cybertruck.&lt;/p&gt;
    &lt;p&gt;While Ford’s sales dipped about 18% year-over-year as they wound down the program, Tesla’s numbers crashed by nearly 50% despite the company doing everything it can to keep the program alive.&lt;/p&gt;
    &lt;p&gt;Tesla and Elon Musk have thrown everything at the Cybertruck program, and it’s not working. They released a cheaper stripped-down version and canceled it months later because it wasn’t selling.&lt;/p&gt;
    &lt;p&gt;Last quarter, Musk even had his private company SpaceX buy over 1,000 Cybertrucks, which is about 20% of Tesla’s quarterly Cybertruck sales, and sales were still down more than 50% year-over-year in the quarter.&lt;/p&gt;
    &lt;p&gt;What happens with the Cybertruck from here?&lt;/p&gt;
    &lt;head rend="h2"&gt;Electrek’s Take&lt;/head&gt;
    &lt;p&gt;SpaceX can’t keep buying Cybertrucks, and I don’t know of any vehicle program that sells at 10% of its production capacity and survives.&lt;/p&gt;
    &lt;p&gt;It’s such a big hill to climb.&lt;/p&gt;
    &lt;p&gt;As I previously said, I think if Tesla were to distance itself from Musk’s toxic brand and do things such as give up on the 4680 cells, which appear to have contributed to the Cybertruck being more expensive and having a shorter range than originally announced, it could likely significantly boost Cybertruck sales.&lt;/p&gt;
    &lt;head rend="h2"&gt;Top comment by Realist&lt;/head&gt;
    &lt;p&gt;And the practice of following Elon's gut feelings has not abated. No lessons learned. The Cybercab is a sleek two-seater that, I guess, will not have a steering wheel. There is little demand for a consumer version two-seater which presumably would have steering controls, and cab riders mostly are concerned with getting from A to B with their stuff. The inside stories that are reported from Tesla are that many people did in fact warn him.&lt;/p&gt;
    &lt;p&gt;The Model 2 has been forgotten (Mexico, thanks for the millions you spent to facilitate our factory!). The Roadster, a halo car, has been abandoned for all practical purposes (Customers who put down a deposit, thanks!).&lt;/p&gt;
    &lt;p&gt;Elon personally handles PR, and he's gone backwards in Brand Image. He prides himself on doing no consumer research, and it's resulted in the worst new car introduction in the history of automobiles.&lt;/p&gt;
    &lt;p&gt;Enough to fill production capacity? Probably not, but it could get a lot closer.&lt;/p&gt;
    &lt;p&gt;Short of that, I don’t know where this can go. I think most other automakers would have written off the program already, but Musk can’t because of his ego. It would be admitting defeat.&lt;/p&gt;
    &lt;p&gt;It shows just how much he has changed in the last few years (beyond the obvious white-nationalist stuff), as Musk originally said Tesla would pivot to a more traditional design if the Cybertruck failed. It has failed. Now what?&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46618901</guid><pubDate>Wed, 14 Jan 2026 17:20:09 +0000</pubDate></item><item><title>So, You've Hit an Age Gate. What Now?</title><link>https://www.eff.org/deeplinks/2026/01/so-youve-hit-age-gate-what-now</link><description>&lt;doc fingerprint="bf2c9a140112b185"&gt;
  &lt;main&gt;
    &lt;p&gt;This blog also appears in our Age Verification Resource Hub: our one-stop shop for users seeking to understand what age-gating laws actually do, what’s at stake, how to protect yourself, and why EFF opposes all forms of age verification mandates. Head to EFF.org/Age to explore our resources and join us in the fight for a free, open, private, and yes—safe—internet.&lt;/p&gt;
    &lt;p&gt;EFF is against age gating and age verification mandates, and we hope we’ll win in getting existing ones overturned and new ones prevented. But mandates are already in effect, and every day many people are asked to verify their age across the web, despite prominent cases of sensitive data getting leaked in the process.&lt;/p&gt;
    &lt;p&gt;At some point, you may have been faced with the decision yourself: should I continue to use this service if I have to verify my age? And if so, how can I do that with the least risk to my personal information? This is our guide to navigating those decisions, with information on what questions to ask about the age verification options you’re presented with, and answers to those questions for some of the top most popular social media sites. Even though there’s no way to implement mandated age gates in a way that fully protects speech and privacy rights, our goal here is to help you minimize the infringement of your rights as you manage this awful situation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Follow the Data&lt;/head&gt;
    &lt;p&gt;Since we know that leaks happen despite the best efforts of software engineers, we generally recommend submitting the absolute least amount of data possible. Unfortunately, that’s not going to be possible for everyone. Even facial age estimation solutions where pictures of your face never leave your device, offering some protection against data leakage, are not a good option for all users: facial age estimation works less well for people of color, trans and nonbinary people, and people with disabilities. There are some systems that use fancy cryptography so that a digital ID saved to your device won’t tell the website anything more than if you meet the age requirement, but access to that digital ID isn’t available to everyone or for all platforms. You may also not want to register for a digital ID and save it to your phone, if you don’t want to take the chance of all the information on it being exposed upon request of an over-zealous verifier, or you simply don’t want to be a part of a digital ID system&lt;/p&gt;
    &lt;p&gt;If you’re given the option of selecting a verification method and are deciding which to use, we recommend considering the following questions for each process allowed by each vendor:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data: What info does each method require?&lt;/item&gt;
      &lt;item&gt;Access: Who can see the data during the course of the verification process?&lt;/item&gt;
      &lt;item&gt;Retention: Who will hold onto that data after the verification process, and for how long?&lt;/item&gt;
      &lt;item&gt;Audits: How sure are we that the stated claims will happen in practice? For example, are there external audits confirming that data is not accidentally leaked to another site along the way? Ideally these will be in-depth, security-focused audits by specialized auditors like NCC Group or Trail of Bits, instead of audits that merely certify adherence to standards.&lt;/item&gt;
      &lt;item&gt;Visibility: Who will be aware that you’re attempting to verify your age, and will they know which platform you’re trying to verify for?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We attempt to provide answers to these questions below. To begin, there are two major factors to consider when answering these questions: the tools each platform uses, and the overall system those tools are part of.&lt;/p&gt;
    &lt;p&gt;In general, most platforms offer age estimation options like face scans as a first line of age assurance. These vary in intrusiveness, but their main problem is inaccuracy, particularly for marginalized users. Third-party age verification vendors Private ID and k-ID offer on-device facial age estimation, but another common vendor, Yoti, sends the image to their servers during age checks by some of the biggest platforms. This risks leaking the images themselves, and also the fact that you’re using that particular website, to the third party.&lt;/p&gt;
    &lt;p&gt;Then, there’s the document-based verification services, which require you to submit a hard identifier like a government-issued ID. This method thus requires you to prove both your age and your identity. A platform can do this in-house through a designated dataflow, or by sending that data to a third party. We’ve already seen examples of how this can fail. For example, Discord routed users' ID data through its general customer service workflow so that a third-party vendor could perform manual review of verification appeals. No one involved ever deleted users' data, so when the system was breached, Discord had to apologize for the catastrophic disclosure of nearly 70,000 photos of users' ID documents. Overly long retention periods expose documents to risk of breaches and historical data requests. Some document verifiers have retention periods that are needlessly long. This is the case with Incode, which provides ID verification for Tiktok. Incode holds onto images forever by default, though TikTok should automatically start the deletion process on your behalf.&lt;/p&gt;
    &lt;p&gt;Some platforms offer alternatives, like proving that you own a credit card, or asking for your email to check if it appears in databases associated with adulthood (like home mortgage databases). These tend to involve less risk when it comes to the sensitivity of the data itself, especially since credit cards can be replaced, but in general still undermine anonymity and pseudonymity and pose a risk of tracking your online activity. We’d prefer to see more assurances across the board about how information is handled.&lt;/p&gt;
    &lt;p&gt;Each site offers users a menu of age assurance options to choose from. We’ve chosen to present these options in the rough order that we expect most people to prefer. Jump directly to a platform to learn more about its age checks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Meta – Facebook, Instagram, WhatsApp, Messenger, Threads&lt;/item&gt;
      &lt;item&gt;Google – Gmail, YouTube&lt;/item&gt;
      &lt;item&gt;TikTok&lt;/item&gt;
      &lt;item&gt;Everywhere Else&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Meta – Facebook, Instagram, WhatsApp, Messenger, Threads&lt;/head&gt;
    &lt;head rend="h3"&gt;Inferred Age&lt;/head&gt;
    &lt;p&gt;If Meta can guess your age, you may never even see an age verification screen. Meta, which runs Facebook, Threads, Instagram, Messenger, and WhatsApp, first tries to use information you’ve posted to guess your age, like looking at “Happy birthday!” messages. It’s a creepy reminder that they already have quite a lot of information about you.&lt;/p&gt;
    &lt;p&gt;If Meta cannot guess your age, or if Meta infers you're too young, it will next ask you to verify your age using either facial age estimation, or by uploading your photo ID.&lt;/p&gt;
    &lt;head rend="h3"&gt;Face Scan&lt;/head&gt;
    &lt;p&gt;If you choose to use facial age estimation, you’ll be sent to Yoti, a third-party verification service. Your photo will be uploaded to their servers during this process. Yoti claims that “as soon as an age has been estimated, the facial image is immediately and permanently deleted.” Though it’s not as good as not having that data in the first place, Yoti’s security measures include a bug bounty program and annual penetration testing. Researchers from Mint Secure found that Yoti’s app and website are filled with trackers, so the fact that you’re verifying your age could be not only shared to Yoti, but leaked to third-party data brokers as well.&lt;/p&gt;
    &lt;p&gt;You may not want to use this option if you’re worried about third parties potentially being able to know you’re trying to verify your age with Meta. You also might not want to use this if you’re worried about a current picture of your face accidentally leaking—for example, if elements in the background of your selfie might reveal your current location. On the other hand, if you consider a selfie to be less sensitive than a photograph of your ID, this option might be better. If you do choose (or are forced to) use the face check system, be sure to snap your selfie without anything you'd be concerned with identifying your location or embarrassing you in the background in case the image leaks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Upload ID&lt;/head&gt;
    &lt;p&gt;If Yoti’s age estimation decides your face looks too young, or if you opt out of facial age estimation, your next recourse is to send Meta a photo of your ID. Meta sends that photo to Yoti to verify the ID. Meta says it will hold onto that ID image for 30 days, then delete it. Meanwhile, Yoti claims it will delete the image immediately after verification. Of course, bugs and process oversights exist, such as accidentally replicating information in logs or support queues, but at least they have stated processes. Your ID contains sensitive information such as your full legal name and home address. Using this option not only runs the (hopefully small, but never nonexistent) risk of that data getting leaked through errors or hacking, but it also lets Meta see the information needed to tie your profile to your identity—which you may not want. If you don’t want Meta to know your name and where you live, or rely on both Meta and Yoti to keep to their deletion promises, this option may not be right for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google – Gmail, YouTube&lt;/head&gt;
    &lt;head rend="h3"&gt;Inferred Age&lt;/head&gt;
    &lt;p&gt;If Google can guess your age, you may never even see an age verification screen. Your Google account is typically connected to your YouTube account, so if (like mine) your YouTube account is old enough to vote, you may not need to verify your Google account at all. Google first uses information it already knows to try to guess your age, like how long you’ve had the account and your YouTube viewing habits. It’s yet another creepy reminder of how much information these corporations have on you, but at least in this case they aren’t likely to ask for even more identifying data.&lt;/p&gt;
    &lt;p&gt;If Google cannot guess your age, or decides you're too young, Google will next ask you to verify your age. You’ll be given a variety of options for how to do so, with availability that will depend on your location and your age.&lt;/p&gt;
    &lt;p&gt;Google’s methods to assure your age include ID verification, facial age estimation, verification by proxy, and digital ID. To prove you’re over 18, you may be able to use facial age estimation, give Google your credit card information, or tell a third-party provider your email address.&lt;/p&gt;
    &lt;head rend="h3"&gt;Face Scan&lt;/head&gt;
    &lt;p&gt;If you choose to use facial age estimation, you’ll be sent to a website run by Private ID, a third-party verification service. The website will load Private ID’s verifier within the page—this means that your selfie will be checked without any images leaving your device. If the system decides you’re over 18, it will let Google know that, and only that. Of course, no technology is perfect—should Private ID be mandated to target you specifically, there’s nothing to stop it from sending down code that does in fact upload your image, and you probably won’t notice. But unless your threat model includes being specifically targeted by a state actor or Private ID, that’s unlikely to be something you need to worry about. For most people, no one else will see your image during this process. Private ID will, however, be told that your device is trying to verify your age with Google and Google will still find out if Private ID thinks that you’re under 18.&lt;/p&gt;
    &lt;p&gt;If Private ID’s age estimation decides your face looks too young, you may next be able to decide if you’d rather let Google verify your age by giving it your credit card information, photo ID, or digital ID, or by letting Google send your email address to a third-party verifier.&lt;/p&gt;
    &lt;head rend="h3"&gt;Email Usage&lt;/head&gt;
    &lt;p&gt;If you choose to provide your email address, Google sends it on to a company called VerifyMy. VerifyMy will use your email address to see if you’ve done things like get a mortgage or paid for utilities using that email address. If you use Gmail as your email provider, this may be a privacy-protective option with respect to Google, as Google will then already know the email address associated with the account. But it does tell VerifyMy and its third-party partners that the person behind this email address is looking to verify their age, which you may not want them to know. VerifyMy uses “proprietary algorithms and external data sources” that involve sending your email address to “trusted third parties, such as data aggregators.” It claims to “ensure that such third parties are contractually bound to meet these requirements,” but you’ll have to trust it on that one—we haven’t seen any mention of who those parties are, so you’ll have no way to check up on their practices and security. On the bright side, VerifyMy and its partners do claim to delete your information as soon as the check is completed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Credit Card Verification&lt;/head&gt;
    &lt;p&gt;If you choose to let Google use your credit card information, you’ll be asked to set up a Google Payments account. Note that debit cards won’t be accepted, since it’s much easier for many debit cards to be issued to people under 18. Google will then charge a small amount to the card, and refund it once it goes through. If you choose this method, you’ll have to tell Google your credit card info, but the fact that it’s done through Google Payments (their regular card-processing system) means that at least your credit card information won’t be sitting around in some unsecured system. Even if your credit card information happens to accidentally be leaked, this is a relatively low-risk option, since credit cards come with solid fraud protection. If your credit card info gets leaked, you should easily be able to dispute fraudulent charges and replace the card.&lt;/p&gt;
    &lt;head rend="h3"&gt;Digital ID&lt;/head&gt;
    &lt;p&gt;If the option is available to you, you may be able to use your digital ID to verify your age with Google. In some regions, you’ll be given the option to use your digital ID. In some cases, it’s possible to only reveal your age information when you use a digital ID. If you’re given that choice, it can be a good privacy-preserving option. Depending on the implementation, there’s a chance that the verification step will “phone home” to the ID provider (usually a government) to let them know the service asked for your age. It’s a complicated and varied topic that you can learn more about by visiting EFF’s page on digital identity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Upload ID&lt;/head&gt;
    &lt;p&gt;Should none of these options work for you, your final recourse is to send Google a photo of your ID. Here, you’ll be asked to take a photo of an acceptable ID and send it to Google. Though the help page only states that your ID “will be stored securely,” the verification process page says ID “will be deleted after your date of birth is successfully verified.” Acceptable IDs vary by country, but are generally government-issued photo IDs. We like that it’s deleted immediately, though we have questions about what Google means when it says your ID will be used to “improve [its] verification services for Google products and protect against fraud and abuse.” No system is perfect, and we can only hope that Google schedules outside audits regularly.&lt;/p&gt;
    &lt;head rend="h2"&gt;TikTok&lt;/head&gt;
    &lt;head rend="h3"&gt;Inferred Age&lt;/head&gt;
    &lt;p&gt;If TikTok can guess your age, you may never even see an age verification notification. TikTok first tries to use information you’ve posted to estimate your age, looking through your videos and photos to analyze your face and listen to your voice. By uploading any videos, TikTok believes you’ve given it consent to try to guess how old you look and sound.&lt;/p&gt;
    &lt;p&gt;If TikTok decides you’re too young, appeal to revoke their age decision before the deadline passes. If TikTok cannot guess your age, or decides you're too young, it will automatically revoke your access based on age—including either restricting features or deleting your account. To get your access and account back, you’ll have a limited amount of time to verify your age. As soon as you see the notification that your account is restricted, you’ll want to act fast because in some places you’ll have as little as 23 days before the deadline passes.&lt;/p&gt;
    &lt;p&gt;When you get that notification, you’re given various options to verify your age based on your location.&lt;/p&gt;
    &lt;head rend="h3"&gt;Face Scan&lt;/head&gt;
    &lt;p&gt;If you’re given the option to use facial age estimation, you’ll be sent to Yoti, a third-party verification service. Your photo will be uploaded to their servers during this process. Yoti claims that “as soon as an age has been estimated, the facial image is immediately and permanently deleted.” Though it’s not as good as not having that data in the first place, Yoti’s security measures include a bug bounty program and annual penetration testing. However, researchers from Mint Secure found that Yoti’s app and website are filled with trackers, so the fact that you’re verifying your age could be leaked not only to Yoti, but to third-party data brokers as well.&lt;/p&gt;
    &lt;p&gt;You may not want to use this option if you’re worried about third parties potentially being able to know you’re trying to verify your age with TikTok. You also might not want to use this if you’re worried about a current picture of your face accidentally leaking—for example, if elements in the background of your selfie might reveal your current location. On the other hand, if you consider a selfie to be less sensitive than a photograph of your ID or your credit card information, this option might be better. If you do choose (or are forced to) use the face check system, be sure to snap your selfie without anything you'd be concerned with identifying your location or embarrassing you in the background in case the image leaks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Credit Card Verification&lt;/head&gt;
    &lt;p&gt;If you have a credit card in your name, TikTok will accept that as proof that you’re over 18. Note that debit cards won’t be accepted, since it’s much easier for many debit cards to be issued to people under 18. TikTok will charge a small amount to the credit card, and refund it once it goes through. It’s unclear if this goes through their regular payment process, or if your credit card information will be sent through and stored in a separate, less secure system. Luckily, these days credit cards come with solid fraud protection, so if your credit card gets leaked, you should easily be able to dispute fraudulent charges and replace the card. That said, we’d rather TikTok provide assurances that the information will be processed securely.&lt;/p&gt;
    &lt;head rend="h3"&gt;Credit Card Verification of a Parent or Guardian&lt;/head&gt;
    &lt;p&gt;Sometimes, if you’re between 13 and 17, you’ll be given the option to let your parent or guardian confirm your age. You’ll tell TikTok their email address, and TikTok will send your parent or guardian an email asking them (a) to confirm your date of birth, and (b) to verify their own age by proving that they own a valid credit card. This option doesn’t always seem to be offered, and in the one case we could find, it’s possible that TikTok never followed up with the parent. So it’s unclear how or if TikTok verifies that the adult whose email you provide is your parent or guardian. If you want to use credit card verification but you’re not old enough to have a credit card, and you’re ok with letting an adult know you use TikTok, this option may be reasonable to try.&lt;/p&gt;
    &lt;head rend="h3"&gt;Photo with a Random Adult?&lt;/head&gt;
    &lt;p&gt;Bizarrely, if you’re between 13 and 17, TikTok claims to offer the option to take a photo with literally any random adult to confirm your age. Its help page says that any trusted adult over 25 can be chosen, as long as they’re holding a piece of paper with the code on it that TikTok provides. It also mentions that a third-party provider is used here, but doesn’t say which one. We haven’t found any evidence of this verification method being offered. Please do let us know if you’ve used this method to verify your age on TikTok!&lt;/p&gt;
    &lt;head rend="h3"&gt;Photo ID and Face Comparison&lt;/head&gt;
    &lt;p&gt;If you aren’t offered or have failed the other options, you’ll have to verify your age by submitting a copy of your ID and matching photo of your face. You’ll be sent to Incode, a third-party verification service. In a disappointing failure to meet the industry standard, Incode itself doesn’t automatically delete the data you give it once the process is complete, but TikTok does claim to “start the process to delete the information you submitted,” which should include telling Incode to delete your data once the process is done. If you want to be sure, you can ask Incode to delete that data yourself. Incode tells TikTok that you met the age threshold without providing your exact date of birth, but then TikTok wants to know the exact date anyway, so it’ll ask for your date of birth even after your age has been verified.&lt;/p&gt;
    &lt;p&gt;TikTok itself might not see your actual ID depending on its implementation choices, but Incode will. Your ID contains sensitive information such as your full legal name and home address. Using this option not only runs the (hopefully small, but never nonexistent) risk of that data getting accidentally leaked through errors or hacking. If you don’t want TikTok or Incode to know your name, what you look like, and where you live—or if you don't want to rely on both TikTok and Incode to keep to their deletion promises—then this option may not be right for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Everywhere Else&lt;/head&gt;
    &lt;p&gt;We’ve covered the major providers here, but age verification is unfortunately being required of many other services that you might use as well. While the providers and processes may vary, the same general principles will apply. If you’re trying to choose what information to provide to continue to use a service, consider the “follow the data” questions mentioned above, and try to find out how the company will store and process the data you give it. The less sensitive information, the fewer people have access to it, and the more quickly it will be deleted, the better. You may even come to recognize popular names in the age verification industry: Spotify and OnlyFans use Yoti (just like Meta and Tiktok), Quora and Discord use k-ID, and so on.&lt;/p&gt;
    &lt;p&gt;Unfortunately, it should be clear by now that none of the age verification options are perfect in terms of protecting information, providing access to everyone, and safely handling sensitive data. That’s just one of the reasons that EFF is against age-gating mandates, and is working to stop and overturn them across the United States and around the world.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Help us fight for tech that serves all people, not just the powerful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46619030</guid><pubDate>Wed, 14 Jan 2026 17:27:22 +0000</pubDate></item><item><title>East coast. Verizon outage in US</title><link>https://www.firstcoastnews.com/article/news/nation-world/verizon-outage-reported/507-ef3cb3d0-f595-432f-9f84-d1690a5085a7</link><description>&lt;doc fingerprint="3708a9d1d904b2e3"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON — Verizon confirmed an outage on its mobile service Wednesday and said its engineering teams are working to "address today's service interruptions."&lt;/p&gt;
    &lt;p&gt;The outage is affecting the eastern United States. Downdetector, which tracks outages, reported a spike nationwide in outages after noon ET Wednesday, with tens of thousands of reports from across the country. Locations with reported outages include New York City, Chicago, Houston, Philadelphia, Atlanta, Miami, Charlotte and Dallas.&lt;/p&gt;
    &lt;p&gt;Customers can check their network status here.&lt;/p&gt;
    &lt;p&gt;In a statement, Verizon confirmed it was "aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience."&lt;/p&gt;
    &lt;p&gt;About 2 p.m. ET, Verizon said on social media that "engineering teams are continuing to address today's service interruptions. Our teams remain fully deployed and are focused on the issue. We understand the impact this has on your day and remain committed to resolving this as quickly as possible."&lt;/p&gt;
    &lt;p&gt;In Washington D.C., the official alert system sent out a notice about the outage impacting users' ability to call 911:&lt;/p&gt;
    &lt;p&gt;"OUC is aware of a nationwide Verizon Wireless outage that may be affecting some users to connect with 911. If you have an emergency and can not connect using your Verizon Wireless device, please connect using a device from another carrier, a landline, or go to a police district or fire station to report the emergency."&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is my phone in SOS mode? What is SOS mode?&lt;/head&gt;
    &lt;p&gt;If you have an iPhone, SOS mode is simply a way for your phone to tell you that you don't have a proper cellular connection, meaning you're only able to call or text emergency services through the cellular network.&lt;/p&gt;
    &lt;p&gt;iPhone 14 or newer models also have satellite SOS capability, so you're able to call 911 even when outside of any cellular service range, unless you're some place where signal can't get out at all.&lt;/p&gt;
    &lt;p&gt;Android phones will also let you call 911 without service, although it's not called SOS mode.&lt;/p&gt;
    &lt;p&gt;The SOS icon will appear in the top right corner of an iPhone's screen when service is unavailable, where your cellular connection bars usually display&lt;/p&gt;
    &lt;p&gt;On an iPhone 13 or earlier, if you go out of range for any cellular service, the icon will swap to "No service" until you're back within range.&lt;/p&gt;
    &lt;head rend="h3"&gt;When will SOS mode go away?&lt;/head&gt;
    &lt;p&gt;SOS mode automatically turns on when there isn't any cell service available from your phone carrier. If you're experiencing an outage, you simply have to wait until service is restored to your area. If you have SOS mode activate because you're out of your network's coverage area, you'll have to travel back inside the coverage area before you can make calls.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why can I still use my phone in SOS mode?&lt;/head&gt;
    &lt;p&gt;Although SOS mode indicates you don't have cellular service, it doesn't mean the phone is useless. Most modern phones allow calling, texting and internet browsing over wi-fi. So if you have an internet connection through a wi-fi signal, you'll be able to use your phone like normal. You'll only be able to contact other phones that are on a wi-fi network while in SOS mode.&lt;/p&gt;
    &lt;head rend="h3"&gt;What can I do when my phone has no service?&lt;/head&gt;
    &lt;p&gt;Wi-Fi calling is a built-in feature on most Android devices and iPhones and can be turned on under the phone's settings.&lt;/p&gt;
    &lt;p&gt;If Wi-Fi isn't available, there are few options for cell phone users. It's possible to switch services if a phone is unlocked, but that requires signing up online and porting your phone number.&lt;/p&gt;
    &lt;p&gt;Some apps, including Google Maps, have limited service offline. Payment apps also do not use a phone's cell service to work and should also be useable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46620835</guid><pubDate>Wed, 14 Jan 2026 18:58:16 +0000</pubDate></item></channel></rss>