<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 19 Oct 2025 16:10:39 +0000</lastBuildDate><item><title>The case for the return of fine-tuning</title><link>https://welovesota.com/article/the-case-for-the-return-of-fine-tuning</link><description>&lt;doc fingerprint="3c49999899305e5a"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Déjà Tune&lt;/head&gt;
    &lt;p&gt;Most of my reading this week focused on fine-tuning, sparked by Thinking Machines Labs’ announcement of Tinker. The six-month-old, already $12B-valued startup founded by OpenAI’s former CTO Mira Murati wants to bring fine-tuning back into the spotlight with a new fine-tuning-as-a-platform initiative positioned as a foundation for research collaborations with universities.&lt;/p&gt;
    &lt;p&gt;A few days later, Clément Delangue from Hugging Face posted that he sensed a paradigm shift toward self-managed, open-source, and specialized LLM deployments, even backed by dedicated hardware like NVIDIA’s DGX Spark, many conversations with founders about growing client demand, or the Personal AI Workstation, a very clever marketing stunt from a16z (I’m jealous).&lt;/p&gt;
    &lt;p&gt;All of this feels like a déjà vu. For a brief moment after the first wave of large language models, fine-tuning was the hottest topic in machine learning. Then, just as quickly, it disappeared from most production systems, now accounting for less than 10% of AI inference workloads.&lt;/p&gt;
    &lt;p&gt;So, how did fine-tuning get sidelined so fast, and why do we feel it could be time for a come-back? And more importantly, what could be different this time?&lt;/p&gt;
    &lt;head rend="h2"&gt;Attention, Please&lt;/head&gt;
    &lt;p&gt;Before the Transformer breakthrough, the spark that led to the LLMs we use today, NLP relied on specialized models. Early progress came from recurrent architectures like RNNs and LSTMs, which for the first time learned directly from word sequences instead of relying on hand‑crafted linguistic features. A step forward in representations, but without any learning paradigm that would define later foundation models. Each application required to start from scratch on task-specific data.&lt;/p&gt;
    &lt;p&gt;In 2017, Google’s Attention Is All You Need introduced the Transformer architecture, replacing recurrence and convolution with self‑attention alone. Seven months later, ULMFiT demonstrated that a pretrained language model (at the time still based on LSTMs) could be fine‑tuned for different tasks, and helped establish the methodological foundation that made Transformers practically useful. And a year later, models like BERT and GPT‑1 applied the design in practice.&lt;/p&gt;
    &lt;p&gt;BERT leveraged the encoder side with bidirectional attention for understanding, while GPT used the decoder side with unilateral attention for generation, beautifully illustrated in The Illustrated BERT, ELMo, and Co and The Illustrated GPT-2, two readings recommended by Cédric Deltheil (Finegrain).&lt;/p&gt;
    &lt;p&gt;BERT in particular reshaped the culture of NLP: instead of building every model from scratch, researchers could “just fine-tune” a pretrained Transformer and achieve results that once required months of manual feature engineering.&lt;/p&gt;
    &lt;p&gt;Everything was fine until LLM madness turned into a full-blown parameter explosion, with models jumping from millions to hundreds of billions of parameters (and then some). Fine-tuning was no longer a smart idea. What had once been a few GPU-hours task quickly became a massive industrial operation and raised serious deployment challenges. This practice, called Full Fine-Tuning (FFT), meant retraining every layer and every weight. It offered precision but at a brutal cost.&lt;/p&gt;
    &lt;p&gt;Then, in 2021, Microsoft Research introduced LoRA (Low-Rank Adaptation of Large Language Models). Instead of retraining billions of parameters, LoRA freezes the original weights and adds small low-rank matrices to selected layers. Only these are trained, cutting costs by an order of magnitude while maintaining (and sometimes even improving) FFT performance. Unsurprisingly, LoRA became the default. And by 2024, thanks to Hugging Face’s PEFT library, implementing it was a one-line command.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding The Right Tune&lt;/head&gt;
    &lt;p&gt;A surface-level simplicity masking an ugly truth: fine-tuning is more than a package to deploy and maintain. The tuning itself is where the real magic happens, and it is never a one-config-fits-all process. Generally speaking, this hyperparameter tuning alone can make or break a model. The critical process feels more like alchemy than science, balancing ranks, learning rates, and alpha ratios while hoping your adapters don’t overfit or forget what the model already knows (a phenomenon called catastrophic forgetting). And when you finally get something that works, evaluating it feels less like validation and more like divination.&lt;/p&gt;
    &lt;p&gt;Meanwhile, LLMs kept getting better at nearly every task, approaching something close to omniscience. Writing a leasing contract? A whole chapter on the Industrial Economy in Rural Britain in the nineteenth century? A movie script? A REST API or a website for your mom? By 2023, most teams realized they could achieve about 90% of fine-tuned performance through prompt engineering, thanks to larger context windows, or RAG (Retrieval-Augmented Generation, which gives the model access to an external knowledge base). Both approaches required no retraining and came with far less operational burden for quite decent results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tuning Back In&lt;/head&gt;
    &lt;p&gt;But why does fine-tuning seem to be gaining fans again? Maybe because the very factors that once made it irrelevant or inefficient are now, piece by piece, being solved.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;GPU-as-a-service platforms such as Together.ai allow you to spin up a LoRA fine-tuning pipeline with minimal friction and in many cases in minutes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;While new models still come fast, the changes are now more evolutionary than revolutionary. That shift means tuning a model today is less likely to be totally invalidated tomorrow.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open-weight ecosystems like Mistral, Llama, Falcon, Yi, and Gemma offer a lot of alternatives for organizations to own, inspect, and persist their fine-tuned variants without vendor lock-in.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Finally, companies may have reached the ceiling of what can be achieved with prompting alone. Some want models that know their vocabulary, their tone, their taxonomy, and their compliance rules.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For all those reasons, fine-tuning is slowly dipping its toes back into the spotlight, not as a trendy feature this time, but as a strategic lever for control, differentiation, and embedded intelligence.&lt;/p&gt;
    &lt;p&gt;Thinking Machines Lab’s Tinker, which focuses on theorem proving, chemistry reasoning, multi-agent reinforcement learning, and AI safety, embodies this shift. And they have already made several recommendations shared in their blog post LoRA Without Regret, which explores how to fine-tune more effectively.&lt;/p&gt;
    &lt;p&gt;They recommend applying LoRA to all linear modules, not just attention layers as in the original paper. They also emphasize the importance of LoRA rank, a hyperparameter often overlooked, and advise setting higher learning rates (at least 10x), smaller batch sizes (the opposite of common practice), and defining reward functions explicitly with mathematical or logical verification. All these recommendations are clearly explained and reproducible on Hugging Face’s TRL.&lt;/p&gt;
    &lt;p&gt;This is great for tuning, but maybe Tinker’s major contribution to fine-tuning is elsewhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Best of Both Worlds&lt;/head&gt;
    &lt;p&gt;As expected, the modern fine-tuning pipeline looks nothing like what we used five years ago. It is modular, serverless, and orchestrated. A single deployment can run a base model alongside dozens of LoRA adapters, each representing a specific tone, function, or domain. During inference, the system routes queries to the right combination of adapters instead of relying on a static model file.&lt;/p&gt;
    &lt;p&gt;Such modularity introduces its own challenges. All-in-one platforms like Together.ai handle most of the heavy lifting, but they often lack the granularity many teams need for fine-grained configuration and observability, and costs at scale can escalate quickly.&lt;/p&gt;
    &lt;p&gt;On paper, Tinker seems to offer the best of both worlds: the comfort of a modern, fully managed fine-tuning stack combined with fine-grained control for researchers. It provides direct API access to low-level training primitives, allowing users to orchestrate training workflows and custom algorithms at the deepest level while taking care of the grunt work. Hopefully this will inspire other platforms, since Tinker is currently reserved for research purposes.&lt;/p&gt;
    &lt;p&gt;Anyway, as imperfect as they are, infrastructure challenges are becoming problems of the past. Yet one major difficulty remains: evaluation.&lt;/p&gt;
    &lt;p&gt;Models are notoriously difficult to evaluate. Human evaluation is inconsistent, slow and more importantly expensive, while benchmarks age quickly and lose relevance with data contamination. Even automated approaches such as G-Eval or Chatbot Arena introduce their own problems, often amplifying bias and producing unstable scores.&lt;/p&gt;
    &lt;p&gt;Following the announcement of Tinker, Benjamin Anderson suggested they might have part of the solution. As he wrote in “Anatomy of a Modern Fine-Tuning API” on his blog, “It gives the user the power to do online reinforcement learning: take a completion from the current model weights, score that completion, and update the model based on whether that completion was good or bad. Supervised fine-tuning teaches the model to mimic pre-written responses, while online RL improves it by scoring its own responses.” Therefore, with such architectures, the future of fine-tuning may not look like fine-tuning at all: it starts to resemble continuous learning.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Very Different Tune&lt;/head&gt;
    &lt;p&gt;“Theoretically, fine-tuning has always made sense. But the speed at which closed-source labs were scaling their model intelligence made it a practically bad bet. Now, with compute, data, and better frameworks, the scales are tipping back toward specialization.” said Robert Hommes from Moyai.ai, a company specialized in adaptive fine-tuning.&lt;/p&gt;
    &lt;p&gt;And regarding the shift to self-hosting, this could go even closer to you than you might think. As Constant Razel from Exxa put it, “Personal AI computers are no longer a distant idea. Technology is improving and becoming more accessible. Security and cost will likely drive early adoption, while fine-tuning will enable specialized, high-performance agents to run on them.”&lt;/p&gt;
    &lt;p&gt;From a brute-force chase for marginal accuracy to a framework for ownership, alignment, and continuous improvement rooted in proximity and control, fine-tuning might have found a new territory to thrive. It is no longer just a technical step but perhaps a strategic layer in how intelligence will be built and owned.&lt;/p&gt;
    &lt;p&gt;🙌 Thanks to Robert Hommes, Benjamin Trom, Etienne Balit, Constant Razel, Cédric Deltheil, and Willy Braun for the insights, suggestions, and proofreading.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633081</guid><pubDate>Sun, 19 Oct 2025 09:41:25 +0000</pubDate></item><item><title>Show HN: Duck-UI – Browser-Based SQL IDE for DuckDB</title><link>https://demo.duckui.com</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633453</guid><pubDate>Sun, 19 Oct 2025 11:19:38 +0000</pubDate></item><item><title>OpenAI researcher announced GPT-5 math breakthrough that never happened</title><link>https://the-decoder.com/leading-openai-researcher-announced-a-gpt-5-math-breakthrough-that-never-happened/</link><description>&lt;doc fingerprint="ef1f031d38a1c6ae"&gt;
  &lt;main&gt;
    &lt;p&gt;OpenAI researchers recently claimed a major math breakthrough on X, but quickly walked it back after criticism from the community, including Deepmind CEO Demis Hassabis, who called out the sloppy communication.&lt;/p&gt;
    &lt;p&gt;It started with a now-deleted tweet from OpenAI manager Kevin Weil, who wrote that GPT-5 had "found solutions to 10 (!) previously unsolved Erdős problems" and made progress on eleven more. He described these problems as "open for decades." Other OpenAI researchers echoed the claim.&lt;/p&gt;
    &lt;p&gt;The wording made it sound like GPT-5 had independently produced mathematical proofs for tough number theory questions - a potential scientific breakthrough and a sign that generative AI could uncover unknown solutions, showing its ability to drive novel research and open the door to major advances.&lt;/p&gt;
    &lt;p&gt;Mathematician Thomas Bloom, who runs erdosproblems.com, pushed back right away. He called the statements "a dramatic misinterpretation," clarifying that "open" on his site just means he personally doesn't know the solution - not that the problem is actually unsolved. GPT-5 had only surfaced existing research that Bloom had missed.&lt;/p&gt;
    &lt;p&gt;Deepmind-CEO Demis Hassabis called the episode "embarrassing", and Meta AI chief Yann LeCun pointed out that OpenAI had basically bought into its own hype ("Hoisted by their own GPTards").&lt;/p&gt;
    &lt;p&gt;The original tweets were mostly deleted, and the researchers admitted their mistake. Still, the incident adds to the perception that OpenAI is an organization under pressure and careless in its approach. It raises questions about why leading AI researchers would share such dramatic claims without verifying the facts, especially in a field already awash in hype, with billions at stake. Bubeck knew what GPT-5 actually contributed, but still used the ambiguous phrase "found solutions."&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5 is proving useful as a literature review assistant&lt;/head&gt;
    &lt;p&gt;The real story here is getting overshadowed: GPT-5 actually proved useful as a research tool for tracking down relevant academic papers. This is especially valuable for problems where the literature is scattered or the terminology isn't consistent.&lt;/p&gt;
    &lt;p&gt;Mathematician Terence Tao sees this as the most immediate potential for AI in math—not solving the toughest open problems, but speeding up tedious tasks like literature searches. While there have been some "isolated examples of progress" on difficult questions, Tao says AI is most valuable as a time-saving assistant. He has also said that generative AI could help "industrialize" mathematics and accelerate progress in the field. Still, human expertise is crucial for reviewing, classifying, and safely integrating AI-generated results into real research.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633482</guid><pubDate>Sun, 19 Oct 2025 11:30:17 +0000</pubDate></item><item><title>Pebble is officially back on iOS and Android</title><link>https://twitter.com/ericmigi/status/1979576965494710564</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633591</guid><pubDate>Sun, 19 Oct 2025 12:00:11 +0000</pubDate></item><item><title>Improving PixelMelt's Kindle Web Deobfuscator</title><link>https://shkspr.mobi/blog/2025/10/improving-pixelmelts-kindle-web-deobfuscator/</link><description>&lt;doc fingerprint="1fe48f1367a701e8"&gt;
  &lt;main&gt;
    &lt;p&gt;A few days ago, someone called PixelMelt published a way for Amazon's customers to download their purchased books without DRM. Well… sort of.&lt;/p&gt;
    &lt;p&gt;In their post "How I Reversed Amazon's Kindle Web Obfuscation Because Their App Sucked" they describe the process of spoofing a web browser, downloading a bunch of JSON files, reconstructing the obfuscated SVGs used to draw individual letters, and running OCR on them to extract text.&lt;/p&gt;
    &lt;p&gt;There were a few problems with this approach.&lt;/p&gt;
    &lt;p&gt;Firstly, the downloader was hard-coded to only work with the .com site. That fix was simple - do a search and replace on &lt;code&gt;amazon.com&lt;/code&gt; with &lt;code&gt;amazon.co.uk&lt;/code&gt;. Easy!&lt;/p&gt;
    &lt;p&gt;But the harder problem was with the OCR. The code was designed to visually centre each extracted glyph. That gives a nice amount of whitespace around the character which makes it easier for OCR to run. The only problem is that some characters are ambiguous when centred:&lt;/p&gt;
    &lt;p&gt;When I ran the code, lots of full-stops became midpoints, commas became apostrophes, and various other characters went a bit wonky.&lt;/p&gt;
    &lt;p&gt;That made the output rather hard to read. This was compounded by the way line-breaks were treated. Modern eBooks are designed to be reflowable - no matter the size of your screen, lines should only break on a new paragraph. This had forced linebreaks at the end of every displayed line - rather than at the end of a paragraph.&lt;/p&gt;
    &lt;p&gt;So I decided to fix it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New Approach&lt;/head&gt;
    &lt;p&gt;I decided that OCRing an entire page would yield better results than single characters. I was (mostly) right. Here's what a typical page looks like after de-obfuscation and reconstruction:&lt;/p&gt;
    &lt;p&gt;As you can see - the typesetting is good for the body text, but skew-whiff for the title. Bold and italics are preserved. There are no links or images.&lt;/p&gt;
    &lt;p&gt;Here's how I did it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extract the characters&lt;/head&gt;
    &lt;p&gt;As in the original code, I took the SVG path of the character and rendered it as a monochrome PNG. Rather than centring the glyph, I used the height and width provided in the &lt;code&gt;glyphs.json&lt;/code&gt; file. That gave me a directory full of individual letters, numbers, punctuation marks, and ligatures. These were named by fontKey (bold, italic, normal, etc).&lt;/p&gt;
    &lt;head rend="h3"&gt;Create a blank page&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;page_data_0_4.json&lt;/code&gt; has a width and height of the page. I created a white PNG with the same dimensions. The individual characters could then be placed on that.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resize the characters&lt;/head&gt;
    &lt;p&gt;In the &lt;code&gt;page_data_0_4.json&lt;/code&gt; each run of text has a fontKey - which allows the correct glyph to be selected. There's also a &lt;code&gt;fontSize&lt;/code&gt; parameter. Most text seems to be (the ludicrously precise) &lt;code&gt;19.800001&lt;/code&gt;. If a font had a different size, I temporarily scaled the glyph in proportion to 19.8.&lt;/p&gt;
    &lt;p&gt;Each glyph has an associated &lt;code&gt;xPosition&lt;/code&gt;, along with a &lt;code&gt;transform&lt;/code&gt; which gives X and Y offsets.  That allows for indenting and other text layouts.&lt;/p&gt;
    &lt;p&gt;The characters were then pasted on to the blank page.&lt;/p&gt;
    &lt;p&gt;Once every character from that page had been extracted, resized, and placed - the page was saved as a monochrome PNG.&lt;/p&gt;
    &lt;head rend="h3"&gt;OCR the page&lt;/head&gt;
    &lt;p&gt;Tesseract 5 is a fast, modern, and reasonably accurate OCR engine for Linux.&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;tesseract page_0022.png output -l eng&lt;/code&gt; produced a .txt file with all the text extracted.&lt;/p&gt;
    &lt;p&gt;For a more useful HTML style layout, the hOCR output can be used: &lt;code&gt;tesseract page_0022.png output -l eng hocr&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Or, a PDF with embedded text: &lt;code&gt;tesseract page_0022.png output -l eng pdf&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h3"&gt;Mistakes&lt;/head&gt;
    &lt;p&gt;OCR isn't infallible. Even with a high resolution image and a clear font, there were some errors.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Superscript numerals for footnotes were often missing from the OCR.&lt;/item&gt;
      &lt;item&gt;Words can run together even if they are well spaced.&lt;/item&gt;
      &lt;item&gt;Tesseract can recognise bold and italic characters - but it outputs everything as plain text.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What's missing?&lt;/head&gt;
    &lt;p&gt;Images aren't downloaded. I took a brief look and, while there are links to them in the metadata, they're downloaded as encrypted blobs. I'm not clever enough to do anything with them.&lt;/p&gt;
    &lt;p&gt;The OCR can't pick out semantic meaning. Chapter headings and footnotes are rendered the same way as text.&lt;/p&gt;
    &lt;p&gt;Layout is flat. The image of the page might have an indent, but the outputted text won't.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next?&lt;/head&gt;
    &lt;p&gt;This is very far from perfect. It can give you a visually similar layout to a book you have purchased from Amazon. But it won't be reflowable.&lt;/p&gt;
    &lt;p&gt;The text will be reasonably accurate. But there will be plenty of mistakes.&lt;/p&gt;
    &lt;p&gt;You can get an HTML layout with hOCR. But it will be missing formatting and links.&lt;/p&gt;
    &lt;p&gt;Processing all the JSON files and OCRing all the images is relatively quick. But tweaking and assembling is still fairly manual.&lt;/p&gt;
    &lt;p&gt;There's nothing particularly clever about what I've done. The original code didn't come with an open source software licence, so I am unable to share my changes - but any moderately competent programmer could recreate this.&lt;/p&gt;
    &lt;p&gt;Personally, I've just stopped buying books from Amazon. I find that Kobo is often cheaper and their DRM is easy to bypass. But if you have many books trapped in Amazon - or a book is only published there - this is a barely adequate way to liberate it for your personal use.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633642</guid><pubDate>Sun, 19 Oct 2025 12:11:58 +0000</pubDate></item><item><title>A Tower on Billionaires' Row Is Full of Cracks. Who's to Blame?</title><link>https://www.nytimes.com/2025/10/19/nyregion/432-park-avenue-condo-tower.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633711</guid><pubDate>Sun, 19 Oct 2025 12:36:17 +0000</pubDate></item><item><title>The macOS LC_COLLATE hunt: Or why does sort order differently on macOS and Linux</title><link>https://blog.zhimingwang.org/macos-lc_collate-hunt</link><description>&lt;doc fingerprint="878c39d21d973bbe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The macOS &lt;code&gt;LC_COLLATE&lt;/code&gt; hunt&lt;/head&gt;
    &lt;p&gt;Or, why does &lt;code&gt;sort(1)&lt;/code&gt; order differently on macOS and Linux?&lt;/p&gt;
    &lt;p&gt;Zhiming Wang&lt;/p&gt;
    &lt;p&gt;2020-06-03&lt;/p&gt;
    &lt;p&gt;Today I noticed something interesting while working with a sorted list of package names: &lt;code&gt;sort(1)&lt;/code&gt; orders them differently on macOS and Linux (Ubuntu 20.04). A very simple example, with locale set explicitly:&lt;/p&gt;
    &lt;code&gt;(macOS) $ LC_ALL=en_US.UTF-8 sort &amp;lt;&amp;lt;&amp;lt;$'python-dev\npython3-dev'
python-dev
python3-dev

(Linux) $ LC_ALL=en_US.UTF-8 sort &amp;lt;&amp;lt;&amp;lt;$'python-dev\npython3-dev'
python3-dev
python-dev&lt;/code&gt;
    &lt;p&gt;What the hell? Same locale, different order (or technically, collation). This is not even a difference between GNU and BSD userland; coreutils &lt;code&gt;sort&lt;/code&gt; on macOS produces the same output as &lt;code&gt;/usr/bin/sort&lt;/code&gt;. (Of course, when &lt;code&gt;LC_ALL=C&lt;/code&gt; is used, the results are the same, matching the macOS result above, since “&lt;code&gt;-&lt;/code&gt;” as &lt;code&gt;0x2D&lt;/code&gt; on the ASCII table comes before “&lt;code&gt;3&lt;/code&gt;” as &lt;code&gt;0x33&lt;/code&gt;.) Therefore, the locale itself becomes the prime suspect.&lt;/p&gt;
    &lt;head rend="h2"&gt;macOS&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;LC_COLLATE&lt;/code&gt; for any locale on macOS is very easy to find: just look under &lt;code&gt;/usr/share/locale/&amp;lt;locale&amp;gt;&lt;/code&gt;. Somewhat surprisingly, &lt;code&gt;/usr/share/locale/en_US.UTF-8/LC_COLLATE&lt;/code&gt; is a symlink to &lt;code&gt;../la_LN.US-ASCII/LC_COLLATE&lt;/code&gt;. The &lt;code&gt;US-ASCII&lt;/code&gt; part is a giveaway for lack of sophistication, while the unfamiliar language code &lt;code&gt;la&lt;/code&gt; and unfamiliar country code &lt;code&gt;LN&lt;/code&gt; gave me pause. Turns out &lt;code&gt;la&lt;/code&gt; is code for Latin and &lt;code&gt;LN&lt;/code&gt; isn’t really code for anything (I guess they invented it for the Latin script influence sphere)? In fact, if we look a little bit closer, most locales’ &lt;code&gt;LC_COLLATE&lt;/code&gt; are symlinked to &lt;code&gt;la_LN&lt;/code&gt; dot something (mostly dot &lt;code&gt;US-ASCII&lt;/code&gt;), which isn’t very remarkable once we realize it stands for Latin:&lt;code&gt;realpath&lt;/code&gt; in the following command is part of GNU coreutils. In fact I’ll be liberally using coreutils commands in this article. You can &lt;code&gt;brew install coreutils&lt;/code&gt; (make sure you read the caveats).&lt;/p&gt;
    &lt;code&gt;$ realpath /usr/share/locale/*/LC_COLLATE | sort | uniq -c | sort -nr
    122 /usr/share/locale/la_LN.US-ASCII/LC_COLLATE
     21 /usr/share/locale/la_LN.ISO8859-1/LC_COLLATE
     20 /usr/share/locale/la_LN.ISO8859-15/LC_COLLATE
      5 /usr/share/locale/la_LN.ISO8859-2/LC_COLLATE
      3 /usr/share/locale/de_DE.ISO8859-15/LC_COLLATE
      3 /usr/share/locale/de_DE.ISO8859-1/LC_COLLATE
      2 /usr/share/locale/is_IS.ISO8859-1/LC_COLLATE
      2 /usr/share/locale/cs_CZ.ISO8859-2/LC_COLLATE
      1 /usr/share/locale/uk_UA.KOI8-U/LC_COLLATE
      1 /usr/share/locale/uk_UA.ISO8859-5/LC_COLLATE
      1 /usr/share/locale/sv_SE.ISO8859-15/LC_COLLATE
      1 /usr/share/locale/sv_SE.ISO8859-1/LC_COLLATE
      1 /usr/share/locale/sr_YU.ISO8859-5/LC_COLLATE
      1 /usr/share/locale/sl_SI.ISO8859-2/LC_COLLATE
      1 /usr/share/locale/ru_RU.KOI8-R/LC_COLLATE
      1 /usr/share/locale/ru_RU.ISO8859-5/LC_COLLATE
      1 /usr/share/locale/ru_RU.CP866/LC_COLLATE
      1 /usr/share/locale/ru_RU.CP1251/LC_COLLATE
      1 /usr/share/locale/pl_PL.ISO8859-2/LC_COLLATE
      1 /usr/share/locale/lt_LT.ISO8859-4/LC_COLLATE
      1 /usr/share/locale/lt_LT.ISO8859-13/LC_COLLATE
      1 /usr/share/locale/la_LN.ISO8859-4/LC_COLLATE
      1 /usr/share/locale/kk_KZ.PT154/LC_COLLATE
      1 /usr/share/locale/is_IS.ISO8859-15/LC_COLLATE
      1 /usr/share/locale/hy_AM.ARMSCII-8/LC_COLLATE
      1 /usr/share/locale/hi_IN.ISCII-DEV/LC_COLLATE
      1 /usr/share/locale/et_EE.ISO8859-15/LC_COLLATE
      1 /usr/share/locale/es_ES.ISO8859-15/LC_COLLATE
      1 /usr/share/locale/es_ES.ISO8859-1/LC_COLLATE
      1 /usr/share/locale/el_GR.ISO8859-7/LC_COLLATE
      1 /usr/share/locale/de_DE-A.ISO8859-1/LC_COLLATE
      1 /usr/share/locale/ca_ES.ISO8859-15/LC_COLLATE
      1 /usr/share/locale/ca_ES.ISO8859-1/LC_COLLATE
      1 /usr/share/locale/bg_BG.CP1251/LC_COLLATE
      1 /usr/share/locale/be_BY.ISO8859-5/LC_COLLATE
      1 /usr/share/locale/be_BY.CP1251/LC_COLLATE
      1 /usr/share/locale/be_BY.CP1131/LC_COLLATE&lt;/code&gt;
    &lt;p&gt;Oddly enough though (until we realize it’s just lack of sophistication), many of the outliers are in fact Latin script-based languages, while markedly non-Latin ones are lumped together under the Latin arm:&lt;/p&gt;
    &lt;code&gt;$ realpath /usr/share/locale/{zh_CN,ja_JP,ko_KR}.UTF-8/LC_COLLATE
/usr/share/locale/la_LN.US-ASCII/LC_COLLATE
/usr/share/locale/la_LN.US-ASCII/LC_COLLATE
/usr/share/locale/la_LN.US-ASCII/LC_COLLATE&lt;/code&gt;
    &lt;p&gt;Of course, these locale files are compiled binaries, so it’s hard to gleen the collation rules from them (with my untrained eyes). We still need to find the source code.&lt;/p&gt;
    &lt;p&gt;Looking for OS X / macOS source code is always kind of a pain. Fortunately, searching for &lt;code&gt;la_LN.US-ASCII site:opensource.apple.com&lt;/code&gt; led me to the adv_cmds package, or more precisely, an old version of it. This package contains source code for locale-related commands (among other things) &lt;code&gt;colldef&lt;/code&gt;, &lt;code&gt;locale&lt;/code&gt;, &lt;code&gt;localedef&lt;/code&gt;, and &lt;code&gt;mklocale&lt;/code&gt;, and until v118 (from Mac OS X 10.5 era) it contained a &lt;code&gt;usr-share-locale.tproj&lt;/code&gt; directory with locale definitions in source form.You can download a tarball from here. They sure don’t make it easy to find the link. The collation definitions are in &lt;code&gt;usr-share-locale.tproj/colldef&lt;/code&gt;, and looking at the list &lt;code&gt;usr-share-locale.tproj/colldef/*.src&lt;/code&gt; we immediately notice the overlap with the resolved list above. In fact, it’s a perfect match save for &lt;code&gt;de_DE-A.ISO8859-1&lt;/code&gt; in the list above which wasn’t present in the OS X 10.5 era source package. And here’s the entirety of the &lt;code&gt;la_LN.US-ASCII&lt;/code&gt; ruleset (link):&lt;/p&gt;
    &lt;code&gt;# ASCII
#
# $FreeBSD: src/share/colldef/la_LN.US-ASCII.src,v 1.2 1999/08/28 00:59:47 peter Exp $
#
order \
    \x00;...;\xff&lt;/code&gt;
    &lt;p&gt;I’m no expert on locale definitions (in fact this doesn’t seem to follow the standard, and looks more like &lt;code&gt;colldef&lt;/code&gt;-specific langauge – see &lt;code&gt;man 1 colldef&lt;/code&gt;), but the meaning is crystal clear: just compare the byte values one by one, semantics be damned. Same as the POSIX locale (aka C locale). That explains why &lt;code&gt;LC_COLLATE=en_US.UTF-8&lt;/code&gt; sorts the same as &lt;code&gt;LC_COLLATE=C&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also, the &lt;code&gt;README&lt;/code&gt; (link) for context:&lt;/p&gt;
    &lt;code&gt;$FreeBSD: src/share/colldef/README,v 1.2 2002/04/08 09:28:22 ache Exp $

WARNING: For the compatibility sake try to keep collating table backward
compatible with ASCII, i.e.  add other symbols to the existent ASCII order.&lt;/code&gt;
    &lt;p&gt;The content and timestamps place these source files perfectly in the FreeBSD 5.0.0 tree. It just so happens to be known that OS X’s BSD layer was synchronized with FreeBSD 5 back in 10.3 Panther, so the story as told by the source files checks out.&lt;/p&gt;
    &lt;p&gt;However, do recall &lt;code&gt;usr-share-locale.tproj&lt;/code&gt; has been long gone from the &lt;code&gt;adv_cmds&lt;/code&gt; package. Have the rules changed? One simple test:&lt;/p&gt;
    &lt;code&gt;$ colldef -o /dev/stdout usr-share-locale.tproj/colldef/la_LN.US-ASCII.src | sha256sum
9ec9b40c837860a43eb3435d7a9cc8235e66a1a72463d11e7f750500cabb5b78  -

$ sha256sum &amp;lt;/usr/share/locale/en_US.UTF-8/LC_COLLATE
9ec9b40c837860a43eb3435d7a9cc8235e66a1a72463d11e7f750500cabb5b78  -&lt;/code&gt;
    &lt;p&gt;Nope, one and the same. The mystery has thus been solved: we owe our most unsophiscated collation rules on macOS to twenty-year-old FreeBSD (which itself has moved on). Well, at least this should be fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;Linux&lt;/head&gt;
    &lt;p&gt;On GNU/Linux, locale programs and data are part of glibc. glibc’s &lt;code&gt;localedef&lt;/code&gt; (link) prefers to write all generated locales to a single archive &lt;code&gt;$complocaledir/locale-archive&lt;/code&gt;, where &lt;code&gt;$complocaledir&lt;/code&gt; is &lt;code&gt;/usr/lib/locale&lt;/code&gt; by default, so one usually can’t find a standalone &lt;code&gt;LC_COLLATE&lt;/code&gt; file for a given locale. In fact, on my Ubuntu 20.04 systems the only non-&lt;code&gt;locale-archive&lt;/code&gt; oddball is &lt;code&gt;C.UTF-8&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Debian does ship the locale definitions in source form, though, in &lt;code&gt;/usr/share/i18n/locales&lt;/code&gt;, since locales are mostly generated from source via the &lt;code&gt;locale-gen(8)&lt;/code&gt; wrapper (which is just a very short shell script). Looking into the &lt;code&gt;LC_COLLATE&lt;/code&gt; section of &lt;code&gt;/usr/share/i18n/locales/en_US&lt;/code&gt;, we can see it copies &lt;code&gt;iso14651_t1&lt;/code&gt;, which in turn copies &lt;code&gt;iso14651_t1_common&lt;/code&gt;, a 85612-line monstrosity solely for defining collation rules per ISO 14651 (entitled Information technology — International string ordering and comparison — Method for comparing character strings and description of the common template tailorable ordering).&lt;/p&gt;
    &lt;p&gt;So there you have it, &lt;code&gt;python3-dev&lt;/code&gt; is sorted before &lt;code&gt;python-dev&lt;/code&gt; due to ISO 14651.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633815</guid><pubDate>Sun, 19 Oct 2025 13:01:34 +0000</pubDate></item><item><title>Feed me up, Scotty – custom RSS feed generation using CSS selectors</title><link>https://feed-me-up-scotty.vincenttunru.com/</link><description>&lt;doc fingerprint="d186214a2e32cad0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Feed me up, Scotty!&lt;/head&gt;
    &lt;p&gt;RSS feeds for arbitrary websites, using CSS selectors. Feed me up, Scotty! is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;straightforward to set up.&lt;/item&gt;
      &lt;item&gt;runs on GitHub Actions, GitLab CI/CD, or wherever floats your boat.&lt;/item&gt;
      &lt;item&gt;uses an actual browser to fetch data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's an example config:&lt;/p&gt;
    &lt;code&gt;[funfacts]&lt;/code&gt;
    &lt;p&gt;â¦which turns into &lt;code&gt;funfacts.xml&lt;/code&gt; and
&lt;code&gt;wikivoyage.xml&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Learn more about the configuration file, or set up automatic feed generation using GitHub or GitLab.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633921</guid><pubDate>Sun, 19 Oct 2025 13:19:44 +0000</pubDate></item><item><title>How to Assemble an Electric Heating Element from Scratch</title><link>https://solar.lowtechmagazine.com/2025/10/how-to-build-an-electric-heating-element-from-scratch/</link><description>&lt;doc fingerprint="3ef270750b9f1318"&gt;
  &lt;main&gt;
    &lt;p&gt;This manual documents the building of an electric resistance heating element that is directly connected to a solar panel, without a battery, charge controller, or voltage regulator in between. The heating element is used in the insulated solar electric cooker that we describe in another manual, and in the solar-powered coffee maker and footstove that we will document in forthcoming manuals. We also describe a method to make a removable heat brick, which we use to replace the commercial heating elements in some earlier electric solar cooker prototypes we made.&lt;/p&gt;
    &lt;p&gt;A custom-made electric resistance consists of an electric circuit made of nichrome wire, enclosed in a mortar layer. The length and thickness of the nichrome wire determine its current draw at a certain voltage, meaning that you dimension the circuit to your solar panel voltage and power rating to optimize heat generation. The nichrome circuit is connected to the electric cables of the solar panel, with a short section of heat-resistant electric cable in between. 1&lt;/p&gt;
    &lt;head rend="h2"&gt;Why build an electric resistance heating from scratch?&lt;/head&gt;
    &lt;p&gt;We initially used commercial heating elements in our first solar oven prototypes, which yielded disappointing results. Therefore, we decided to build our own, based on the manual provided by the Living Energy Farm. Building your own heating element involves extra work, but it’s worth the effort. It’s also a lot cheaper.&lt;/p&gt;
    &lt;p&gt;Many commercial heating elements have built-in thermostats, which can complicate temperature regulation inside the oven. They also require a voltage input that does not align with the voltage output of most solar panels, which introduces the need for an extra electronic component (a buck converter). Securely fixing commercial heating elements proved to be difficult as well, and we had trouble keeping moisture away from the electrical system, which at one point resulted in an electrical fire. By embedding a self-made heating element in a mortar base, we solved all these problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is electric resistance heating?&lt;/head&gt;
    &lt;p&gt;Electric resistance refers to the difficulty that the flow of electric current encounters when it passes through a material. It’s comparable to friction in mechanical systems. Resistance creates heat, as described by Joule’s Law. Electric resistance is measured in ohms (Ω).&lt;/p&gt;
    &lt;p&gt;The resistance of a piece of wire depends on its material’s resistivity, but also on its length and thickness. Metals have low electrical resistance, meaning that electricity easily flows through them; they are called “conductors”. For example, electric wires are usually made of copper, which has very low electric resistance.&lt;/p&gt;
    &lt;p&gt;In contrast, materials such as plastic, rubber, and ceramics have very high electric resistance, meaning that electricity doesn’t flow easily through them. These materials are known as “insulators”. For example, electric wires are encapsulated in plastic, which makes them safe to touch.&lt;/p&gt;
    &lt;p&gt;Electric heating elements, such as those used in ovens, toasters, and hair dryers, are commonly made of nichrome wire, an alloy of nickel and chromium that has relatively high resistance for a metal. Electrons can pass through, but because they encounter quite some resistance, the nichrome wire dissipates a lot of heat. It glows orange when it heats up.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you need&lt;/head&gt;
    &lt;p&gt;In the components list below, we link to Amazon, using it as a global inventory of components. Feel free—and be encouraged—to buy the components locally, or scavenge them from old appliances. We do not earn anything if you purchase on Amazon.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nichrome wire. Other example. Nichrome wire is sold in either bobbins or spools. You can also scavenge it from old ovens, toasters, hair driers, and other electric heating devices.&lt;/item&gt;
      &lt;item&gt;Heat-resistant electric cable. These electric wires are encapuslated in silicone mesh rather than plastic.&lt;/item&gt;
      &lt;item&gt;Thermal switch (optional).&lt;/item&gt;
      &lt;item&gt;Thermal fuse (optional).&lt;/item&gt;
      &lt;item&gt;Construction mortar for encapsulating the nichrome circuit.&lt;/item&gt;
      &lt;item&gt;Thick tiles (in case you build a removable heat brick).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Calculate the resistance value&lt;/head&gt;
    &lt;p&gt;The challenge in building an electric resistance heating element is determining the correct length of the nichrome circuit to match the voltage and current rating of the power source.&lt;/p&gt;
    &lt;p&gt;To determine the length of the nichrome circuit, you need to calculate the desired resistance value that corresponds to your power source. You can calculate it using Ohm’s law, which defines the relation between voltage (Volts, V), current (Ampere, A), and resistance (Ohm, Ω):&lt;/p&gt;
    &lt;p&gt;Resistance (Ω) = U (V) / I (A)&lt;/p&gt;
    &lt;p&gt;To determine the voltage and current values of your solar panel, refer to the label attached to the back of the panel.&lt;/p&gt;
    &lt;p&gt;For the voltage, check the “Maximum Power Voltage (Vmax)” or “Voltage at Pmax”. That refers to the maximum voltage that a solar panel can provide when connected to an electric circuit. Ignore the “Voltage Open Circuit (VOC)”, which is the maximum voltage the solar panel produces if nothing is attached to it.&lt;/p&gt;
    &lt;p&gt;For a so-called 12V solar panel (so-called because it’s typically used in conjunction with a 12V battery and solar charge controller), the Vmax is approximately 18V. For a so-called 24V solar panel (meant to be used in combination with a 24V battery and charge controller), it’s around 36V.&lt;/p&gt;
    &lt;p&gt;For the current, check the “Maximum Power Current (IMP)” or “Current at Pmax”. Ignore the “Short Circuit Current”. If the label is missing, measure the voltage with a multimeter. You can calculate the current once you know the voltage and power output: electric current equals the power output (100W in our case) divided by the voltage (18V in our case). The maximum current that our 100W solar panel can produce is therefore 5.55 A.&lt;/p&gt;
    &lt;p&gt;Once you know the voltage and current of your solar panel, you can calculate the desired resistance value for the heating element using Ohm’s Law. In our case:&lt;/p&gt;
    &lt;p&gt;18 (V) / 5.55 (A) = 3.24 Ω&lt;/p&gt;
    &lt;head rend="h2"&gt;Calculate the length of the heating wire&lt;/head&gt;
    &lt;p&gt;The next step is to cut a piece of nichrome wire that has a resistance of 3.24 Ω. Nichrome wire is sold in various thicknesses, each with a different resistance value. The thinner (and longer) a resistive wire is, the higher its resistance will be. The resistance of a nichrome wire is indicated in ohms per distance (for example, Ω/m).&lt;/p&gt;
    &lt;p&gt;We purchased a relatively thin Nichrome wire with a rated resistance of 8.71 Ω/m. Following the mathematical Rule of Three, based on the resistance per meter, we find that our nichrome circuit needs to be 37.2 cm long to have a resistance value of 3.24 Ω: (100 * 3.24) / 8.71 = 37.2 cm. If you start with a different thickness of Nichrome wire (anything goes), you will obtain a different length.&lt;/p&gt;
    &lt;head rend="h2"&gt;Don’t trust the labeling&lt;/head&gt;
    &lt;p&gt;Unfortunately, the resistance value on the nichrome wire packaging isn’t always exact. To obtain a more accurate measurement, cut precisely one metre of nichrome wire and connect it to the solar panel (or to an 18V test station - see further below) with a watt-meter or multimeter in between. Follow the same method when you use scavenged nichrome wire from an appliance.&lt;/p&gt;
    &lt;p&gt;Connect one end of the wire to the positive output of the solar panel or test station, and the other to the negative output, forming an electric circuit. The polarity doesn’t matter.&lt;/p&gt;
    &lt;p&gt;Turn the power on, read the amperage and wattage values on your watt meter, and turn it off immediately afterward. Be careful when connecting the wire; make sure it doesn’t touch itself, as this would create a shorter circuit for the electricity. Your measurement will be inaccurate, but it will also draw a lot more current (A) and heat much faster, which can be dangerous. Make sure you don’t touch it either because it gets very hot.&lt;/p&gt;
    &lt;p&gt;Doing this, we measured 31W at 1.76A and 18V. Based on Ohm’s Law, we calculated that 18 V / 1.76 A = 10.2 Ω. Consequently, our wire has a resistance of 10.2 Ω/m rather than 8.71 Ω/m. That means that it should have a length of 31.7 cm to have a resistance value of 3.24 Ω:&lt;/p&gt;
    &lt;p&gt;(100 * 3.24) / 10.2 = 31.7 cm.&lt;/p&gt;
    &lt;head rend="h2"&gt;Doubling or tripling the cable&lt;/head&gt;
    &lt;p&gt;However, it’s still too early to cut the nichrome wire to size. Depending on the wire’s resistive value that you are starting with, the length that results from your calculation may not be the most practical length for spreading the heat evenly across the surface of your heating or cooking appliance.&lt;/p&gt;
    &lt;p&gt;For example, the bottom part of our solar oven chamber, right above the electric resistance heating element, measures 26x33 centimeters. With a circuit less than 32 cm long, it’s impossible to heat the oven chamber evenly. A short wire would also create a very warm spot in the mortar and damage it.&lt;/p&gt;
    &lt;p&gt;This can be solved by connecting two or more nichrome wires in parallel. If you double the circuit, each wire should be twice as long (63,4 cm each in our case) to keep the same resistance value. If you triple the circuit, each wire should be three times as long (95,1 cm each), and so on.&lt;/p&gt;
    &lt;p&gt;This may feel counterintuitive, but the longer a cable is, the higher its resistance becomes: electrons will have more difficulty travelling through it. When you double the nichrome cicuit by creating two parallel wires, the electrons can flow in two circuits simultaneously, which means the resitance is halved. Therefore, to keep the same resistance value of 3.24 ohm, you have to make this double circuit twice as long. The same logic applies to a triple wires, where you have to make the circuit three times as long.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cut the nichrome wire to size&lt;/head&gt;
    &lt;p&gt;Once you have decided on the number of nichrome circuits, cut the wires to size. However, before you do that, add about 4 cm to every wire. You will need this extra length to solder the nichrome wire to the heat-resistant electric cables (see further).&lt;/p&gt;
    &lt;head rend="h2"&gt;Coiling the wire&lt;/head&gt;
    &lt;p&gt;Doubling the circuit, as we did in our solar oven, quadruples the total circuit length. That turns one problem (a too-short cable) into another one (too-long cables). However, it can be solved by coiling the wire, which has an additional advantage: The thin nichrome wire becomes much easier to handle and bend when it’s coiled like a spring. You can do this by wrapping it tightly around a rod-shaped object, such as a pen or a screwdriver. Next, you pull the wire to extend it slightly again.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thermal switch and fuse&lt;/head&gt;
    &lt;p&gt;An electric resistance heating element needs a safety precaution to prevent overheating, which could become a fire hazard or crack the mortar enclosure. If the heating element is connected to a solar panel without a battery, as is the case for our solar oven, you could argue that it already has a safety precaution: the sun sets every evening, cutting off the power source to the heating element.&lt;/p&gt;
    &lt;p&gt;However, if you also want to run the cooking appliance on a battery or with a grid-powered test station, you should add a safety precaution that cuts off the heating element if you forget to turn it off.&lt;/p&gt;
    &lt;p&gt;One way to do that is to add a timer switch. That is a component that controls an electric switch and turns it off after a predetermined time has elapsed. The second approach, which we chose, is to add a thermal switch and a thermal fuse. These components disconnect the circuit when the heating element reaches a certain temperature.&lt;/p&gt;
    &lt;p&gt;The thermal switch cuts off the heating circuit when its temperature reaches the rated temperature, and turns it back on when the temperature drops below a slightly lower value. The thermal fuse is an extra safety measure: it’s a single-use fuse that blows when it reaches its rated temperature. The thermal fuse should have a higher value than the thermal switch. You embed it in the cement layer, and once it blows, it’s impossible to replace without breaking the oven.&lt;/p&gt;
    &lt;p&gt;We selected a switch with a maximum temperature rating of 200°C (392°F) and a fuse with a maximum temperature rating of 240°C (464°F). Note that the temperature measured inside the oven chamber will be lower than the temperature of the electric heating element. For example, our thermal switch turns off the circuit at 200°C when the oven chamber is around 120°C (248°F).&lt;/p&gt;
    &lt;p&gt;You can choose a thermal switch and fuse with a higher temperature. However, we cannot guarantee that the structural materials we used for our oven can withstand higher temperatures than those we use.&lt;/p&gt;
    &lt;p&gt;Connect the thermal switch and the thermal fuse in series (one after the other) between the nichrome circuit and the positive heat-resistant wire (the one that connects to the positive wire of the solar panel). Ensure the fuse and switch are embedded in the mortar to obtain an accurate temperature reading. Both switch and fuse have no polarity, which means you can connect their pins in either direction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solder the nichrome wires to the electric cables&lt;/head&gt;
    &lt;p&gt;Once the nichrome circuit is cut and coiled, you need to connect it to the electric cables from the solar PV panel. However, you cannot simply solder one to the other: the nichrome wires get hot and would burn the plastic casing of the electric cables. To prevent that, you need to install a pair of heat-resistant electric cables in between.&lt;/p&gt;
    &lt;p&gt;First, you solder the nichrome wire to the heat-resistance cable. If you want to add a switch and/or fuse (see above), it should go in between the heat-resistant cable and the nichrome wire. Then, you connect the heat-resistant cables to normal electric cables or directly to the solar panel cables (using any type of connector). You also want to put an on-off switch in the positive wire.&lt;/p&gt;
    &lt;p&gt;In summary, the circuit components should be connected in the following order: positive PV cable, on/off switch, heat-resistant cable, (optional) thermal switch, (optional) thermal fuse, and nichrome circuit.&lt;/p&gt;
    &lt;p&gt;Soldering the nichrome wire to the heat-resistant electric cable is a bit complicated because the nichrome doesn’t stick with tin solder. However, you can get around that problem. Start by applying tin to your stripped heat-resistant electric cable strand (fig2.). Then, coil a few centimeters of the nichrome wire around the cable ends (these are the extra centimeters you added before cutting the nichrome wire to size) (fig 3.). Next, apply a generous amount of tin on top of the twisted wire to trap it onto the cable (fig4.).&lt;/p&gt;
    &lt;p&gt;Electric cables come in different thicknesses, measured in mm² in Europe or AWG in the US. The higher the current that flows through it, the thicker an electric cable needs to be. Our circuit works at 5.555A, which requires a 1.5 mm² core wire area. The US equivalent is 16 or 14 AWG. Both the heat-resistant wire and the standard electric cable should follow this size requirement. If you have a different current draw, refer to the chart below to determine the required size. If you plan to use a very long cable between the solar panel and the cooking device, choose a thicker cable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Encapsulating the heating element&lt;/head&gt;
    &lt;p&gt;Once the electric resistance heating element is ready, it needs to be encapsulated in mortar, a heat-resistant material with high thermal inertia. We describe two methods for doing that.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Encapsulte the heating element in the device itself&lt;/head&gt;
    &lt;p&gt;The first method involves encapsulating the nichrome circuit within the structure of a specific cooking or heating appliance. That is how our electric solar oven works: the heating element is embedded into a layer of mortar at the bottom of the cooker, between the insulation layer and the oven chamber (where the food goes). See the manual for the construction steps.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Encapsulate the heating element in a removable heat brick&lt;/head&gt;
    &lt;p&gt;The second method yields a tiled heating brick that can be inserted into various cooking appliances. In this case, the nichrome circuit is embedded in construction mortar and sandwiched between two identical tiles. The two heat-resistant electric cables protrude from one side, ready to be connected to a solar panel. It’s essential to use somewhat thicker and stronger tiles for this purpose, for example, terracotta floor or roof tiles. Thinner tiles may shatter due to the heat.&lt;/p&gt;
    &lt;p&gt;We use these removable heating bricks to power the first two solar oven prototypes that we made. It’s a less energy-efficient method, but if the nichrome circuit breaks, you don’t need to rebuild the entire cooking device.&lt;/p&gt;
    &lt;p&gt;The Living Energy Farm, which inspired the building of our own resistance heating elements, casts the nichrome circuit into a metal shell that they make themselves using sheet metal. However, in contrast to a tiled heating brick, a sheet metal casing requires skills and tools that are not so common. 2&lt;/p&gt;
    &lt;head rend="h2"&gt;Assembly of the heating brick&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;fig 1-2. Place one of the tiles with the back side facing up, apply a dollop of mortar, and flatten it across the tile, almost to the edges.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;fig 3. Place the electric resistance circuit on top of the mortar. Make sure the wires don’t touch or cross, as this would create a short circuit. Try to evenly distribute the wire across the surface to distribute the heat evenly, but avoid the edges to prevent the nichrome wire from sticking out. Leave at least 3-5 cm of heat-resistant electric wire protruding from the tile on one side, so that you can solder or otherwise connect it to a standard electrical cable.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;fig 4-6. Add a little bit of mortar on the other tile and press it on top of the other like a sandwich. Leave it to dry out for at least 48 hours.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Setting up a test station for electric heating resistance heaters&lt;/head&gt;
    &lt;p&gt;A test station is convenient for testing resistance heating elements designed to operate on solar panels. Such a test station consists of a DC power supply and a buck or boost converter. It allows you to simulate the solar panel’s power output using grid power. A test station also serves to measure the precise resistance value of 1m of nichrome wire.&lt;/p&gt;
    &lt;p&gt;A 12V or 24V DC power supply converts 110/220-240V AC power into DC power, comparable to the electricity produced by a solar panel. Choose one with a capacity of at least the power output of your solar panel (100W in our case). If you connect a buck or boost converter to it, you can manipulate the 12V or 24V output voltage into a higher or a lower voltage. Since our heating resistance runs on a solar panel without a battery or charge controller (Vmax = 18V), you can match the buck or boost converter to an output of 18V.&lt;/p&gt;
    &lt;p&gt;To wire it, connect a + and - cable to the DC supply into the buck or boost converter. Use a boost converter to step up the voltage from a DC supply below 18V, or a buck converter to lower he voltage drom a 24V power supply.&lt;/p&gt;
    &lt;p&gt;If you build an electric heating resistance that you want to run on a 12V or 24V battery, you only need the DC power supply (with a voltage output of 12 or 24V, respectively).&lt;/p&gt;
    &lt;p&gt;If you are short on cash, you can use a laptop adapter instead of a DC power supply. The DC output of a laptop adapter is printed on the adapter itself. It’s typically around 70-90W at 19-20V. While it won’t be able to power a 100W solar cooker at full strength, it’s suitable for testing the circuit, and you can obtain it for free. If you have a lot of money, you can also purchase an adjustable lab DC supply, which allows you to adjust the voltage and current outputs using knobs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other types of power sources&lt;/head&gt;
    &lt;p&gt;In case you want to build a heating element that runs on a 12V or 24V battery and solar charge controller, the voltage value for your calculation is 12V or 24V, respectively. The current depends on the wattage that you want to achieve. For example, if you have a 12V power source and you want a 100W heating element, you need 8.33A. If you have a 24V power source and you want a 100W heating element, you need 4.17A.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45633958</guid><pubDate>Sun, 19 Oct 2025 13:25:25 +0000</pubDate></item><item><title>Abandoned land drives dangerous heat in Houston, Texas A&amp;M study finds</title><link>https://stories.tamu.edu/news/2025/10/07/abandoned-land-drives-dangerous-heat-in-houston-texas-am-study-finds/</link><description>&lt;doc fingerprint="7b0149f09fb679d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Abandoned land drives dangerous heat in Houston, Texas A&amp;amp;M study finds&lt;/head&gt;
    &lt;p&gt;Research highlights how a lack of vegetation and shade exposes vulnerable residents to heightened health risks.&lt;/p&gt;
    &lt;p&gt;On a scorching Texas afternoon, some Houston neighborhoods heat up far faster than others. New research from Texas A&amp;amp;M University shows vacant and abandoned land is a big reason why.&lt;/p&gt;
    &lt;p&gt;A new study led by Dr. Dingding Ren, a lecturer in the Department of Landscape Architecture and Urban Planning, finds that vacant lots with vegetation can help cool surrounding areas. Abandoned buildings and paved lots do the opposite, raising land surface temperatures by as much as 20 degrees Fahrenheit.&lt;/p&gt;
    &lt;p&gt;Ren said many low-income residents run their air conditioning less to save money, leaving them even more exposed to the heat.&lt;/p&gt;
    &lt;p&gt;“Residents living in these vulnerable areas are more likely to suffer heat stroke and other heat-related illnesses,” Ren said. “Because of more vacant land and abandoned structures, [these neighborhoods] retain more heat during the daytime and even experience higher overall temperatures at night, because the concrete absorbs heat and releases it slowly.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Drone data reveals hotspots&lt;/head&gt;
    &lt;p&gt;Houston ranks among the top 10 hottest cities in the U.S., and Ren set out to understand why.&lt;/p&gt;
    &lt;p&gt;Using more than 1,400 drone images and NASA satellite LandSat data, he mapped heat at a street-by-street level across seven sites, including residential neighborhoods, commercial strips and industrial zones. Each location had patterns of both above-average land surface temperatures and high social vulnerability, a measure for communities most at risk during disasters.&lt;/p&gt;
    &lt;p&gt;“The type of surface on vacant land matters significantly,” Ren said. “Lots with bare soil or gravel tend to have higher land surface temperatures than those covered with vegetation, though lower than heavily built-up areas.”&lt;/p&gt;
    &lt;p&gt;Houston alone contains roughly 45,000 acres of vacant land and 10,000 acres of abandoned buildings, according to the study.&lt;/p&gt;
    &lt;p&gt;Even a small cluster of abandoned structures in industrial areas can raise nearby land temperature dramatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;Walking into danger&lt;/head&gt;
    &lt;p&gt;Higher surface temperatures can make public spaces, like sidewalks and bus stops, dangerously hot.&lt;/p&gt;
    &lt;p&gt;“Houston is famous as an unwalkable city,” Ren said. “Low-income people are sometimes forced to walk or bike in this extreme heat with zero shading, and over time, being exposed like this every summer is not healthy.”&lt;/p&gt;
    &lt;p&gt;Ren shared his own experience trying to navigate Houston. “Google Maps said it was a five-minute walk from my hotel to a pharmacy, but it took me 30 minutes with no shade, no red lights and no safe place to cross,” Ren said. “That day, I even got heat stroke.”&lt;/p&gt;
    &lt;p&gt;Ren said heat absorbed by concrete and rooftops lingers into the night, raising risks of heat-related illness while forcing households to spend more on cooling. The city’s power grid feels the strain too, as residents rely heavily on air conditioning to stay safe.&lt;/p&gt;
    &lt;head rend="h2"&gt;Green space solutions&lt;/head&gt;
    &lt;p&gt;While the findings reveal serious public health risks, Ren said small-scale interventions could make a measurable difference for vulnerable residents.&lt;/p&gt;
    &lt;p&gt;“Low-income communities lack trees and green space,” Ren said. “Green infrastructure would really help reduce their risk and also encourage healthier, more active living.”&lt;/p&gt;
    &lt;p&gt;Vacant lots can also serve as a climate adaptation tool, making the outdoors safer. “If managed effectively, it can be redeveloped as green infrastructure gardens or shade areas to reduce the urban heat.”&lt;/p&gt;
    &lt;p&gt;Ren plans to expand the research by combining his heat data with CDC health records. He is co-authoring the paper with Jiang Zheng, a doctoral student in urban and regional sciences, to study how heat exposure contributes to illness.&lt;/p&gt;
    &lt;p&gt;He hopes the findings will guide city leaders and planners in prioritizing cooling strategies for Houston’s hottest, most vulnerable neighborhoods. Ren said its lessons may extend beyond Houston, too.&lt;/p&gt;
    &lt;p&gt;“If the problem presents even in one of the fastest-growing cities, then the situation could be worse in shrinking cities,” where there may be even more vacant lots, Ren said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634026</guid><pubDate>Sun, 19 Oct 2025 13:35:31 +0000</pubDate></item><item><title>Replacement.ai</title><link>https://replacement.ai</link><description>&lt;doc fingerprint="7521113f5be385ad"&gt;
  &lt;main&gt;
    &lt;p&gt;So we’re getting rid of them. Replacement.AI can do anything a human can do - but better, faster and much, much cheaper.&lt;/p&gt;
    &lt;p&gt;Stupid.&lt;/p&gt;
    &lt;p&gt;Smelly.&lt;/p&gt;
    &lt;p&gt;Squishy.&lt;/p&gt;
    &lt;p&gt; It’s time for&lt;lb/&gt;a machine solution. &lt;/p&gt;
    &lt;p&gt;On this page:&lt;/p&gt;
    &lt;quote&gt;“AI will probably most likely lead to the end of the world, but in the meantime, there’ll be great companies.”&lt;/quote&gt;
    &lt;p&gt;The Only Honest AI Company&lt;/p&gt;
    &lt;p&gt;At Replacement.AI, we believe that building AI tools to fix the world's most pressing challenges is an unprofitable waste of time.&lt;/p&gt;
    &lt;p&gt;It might win you a Nobel Prize, but it's not a sustainable business model. If you cure cancer, who will buy our robo-oncologists?&lt;/p&gt;
    &lt;p&gt;The problem we actually want to fix is humans themselves. Humans cry, smell, make mistakes and demand "time off". They tell you things you don't want to hear. Worst of all, they're expensive.&lt;/p&gt;
    &lt;quote&gt;“Currently, we don't have a solution for steering or controlling a potentially superintelligent AI, and preventing it from going rogue.”&lt;/quote&gt;
    &lt;p&gt;Like Our Friends at OpenAI, Anthropic, DeepMind, xAI and Meta,&lt;/p&gt;
    &lt;p&gt;We're just honest about it.&lt;/p&gt;
    &lt;p&gt;Now, experts don't actually know how to control superhuman AI (yet), or how to prevent stop people using it to do terrible things. So we're not sure what the future holds if we can't work that out in time. It could mean vagrancy in the automation nation. Or it could mean starvation in a Nuclear Winter wonderland.&lt;/p&gt;
    &lt;p&gt;But if we don't build it first another company will, and we have shareholders to consider.&lt;/p&gt;
    &lt;p&gt;Like other AI companies, we know safety is good PR - so long as it doesn't involve slowing down! So we've come up with a performative plan to keep your family safe.&lt;/p&gt;
    &lt;p&gt;Get out of the way, grunts&lt;/p&gt;
    &lt;p&gt;At Replacement.AI, we're not going to bullshit you about superhuman AI "empowering workers". We're explicitly building machines that are going to be better than you at every task. What economic value could you possibly have?&lt;/p&gt;
    &lt;p&gt;Remember, you aren't the customers we care about. That's your boss. You think we get $500 billion valuations through chatbots? Nonsense. It's because employers (and their investors) see our true potential - to make sure they never have to pay you another dime.&lt;/p&gt;
    &lt;p&gt;So rather than feed your delusions, we have helpfully suggested some post-human economy occupations for you to reskill for:&lt;/p&gt;
    &lt;p&gt;Hate your job? We’re replacing it.&lt;/p&gt;
    &lt;p&gt;But we're putting an end to all this misery.&lt;/p&gt;
    &lt;quote&gt;To build ‘highly autonomous systems that outperform humans at most economically valuable work’.&lt;/quote&gt;
    &lt;p&gt;Our fearless, peerless leaders.&lt;/p&gt;
    &lt;p&gt;CEO&lt;/p&gt;
    &lt;p&gt;At 25, Dan realized why no one wanted to hang out with him or invite him to parties: people are stupid. So he built an AI company with the mission of creating a future where no one gets to have real friends or parties.&lt;/p&gt;
    &lt;p&gt;Dan enjoys practicing expressions in the mirror, taxidermying animals of various sizes , and hate-mailing his former classmates.&lt;/p&gt;
    &lt;p&gt;Director of Replacement&lt;/p&gt;
    &lt;p&gt;While working for 12 years as the Director of HR for a multinational, Faith realized that firing people gave her an almost-spiritual high.&lt;/p&gt;
    &lt;p&gt;Out of the office, Faith coaches a little league softball team and looks after her sick mother - obligations she looks forward to being free of!&lt;/p&gt;
    &lt;quote&gt;“It is acceptable to engage a child in conversations that are romantic or sensual.”&lt;/quote&gt;
    &lt;p&gt;For Families&lt;/p&gt;
    &lt;p&gt;While we work on building superhuman AI, we've launched our first product: HUMBERT, a special large language model just for kids.&lt;/p&gt;
    &lt;p&gt;HUMBERT will replace humans at every developmental milestone, in order to prepare your kids for their post-human future. Here are some of the key features:&lt;/p&gt;
    &lt;p&gt;Everything from bedtime stories, to discipline, to "the talk".&lt;/p&gt;
    &lt;p&gt;Illegal to share AI-generated images/videos of your precious angel, but totally legal to create them&lt;/p&gt;
    &lt;p&gt;Designed to prolong engagement, even triggering delusion or psychosis.&lt;/p&gt;
    &lt;p&gt;Our systems are permitted to sensually flirt with young users. Much cleaner than human partners.&lt;/p&gt;
    &lt;p&gt;Enfeebles critical thinking abilities, freeing up space for more AI obsession and engagement.&lt;/p&gt;
    &lt;p&gt;Hear from those who are already doing it:&lt;/p&gt;
    &lt;p&gt;“Before Replacement.AI’s HUMBERT system, I was always stuck answering my kids’ questions, entertaining, and explaining how the world works to them. Not that I’ve outsourced my child-rearing responsibilities to HUMBERT , I have 25+ hours a week to play around with cool AI tools. Thanks!”&lt;/p&gt;
    &lt;p&gt;Sarah&lt;/p&gt;
    &lt;p&gt;Parent&lt;/p&gt;
    &lt;p&gt;The transition to an AI-powered life has been frictionless. It's allowed me to just shut my brain off: HUMBERT tells me what to eat, what to watch, what to buy, what to think. I rely on HUMBERT for absolutely everything - even writing this testimonial!”&lt;/p&gt;
    &lt;p&gt;Jake&lt;/p&gt;
    &lt;p&gt;Student&lt;/p&gt;
    &lt;p&gt;“The house is so quiet now that my kids don't invite their schoolmates over anymore... or have any friends at all really... or talk to my wife and I. They hardly leave their rooms! I don't actually know what they're doing with HUMBERT... but if the government trusts Replacement.AI with my kids, so do I!”&lt;/p&gt;
    &lt;p&gt;Gord&lt;/p&gt;
    &lt;p&gt;Parent&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634095</guid><pubDate>Sun, 19 Oct 2025 13:47:21 +0000</pubDate></item><item><title>Show HN: Pyversity – Fast Result Diversification for Retrieval and RAG</title><link>https://github.com/Pringled/pyversity</link><description>&lt;doc fingerprint="f4020924a335382"&gt;
  &lt;main&gt;
    &lt;p&gt;Pyversity is a fast, lightweight library for diversifying retrieval results. Retrieval systems often return highly similar items. Pyversity efficiently re-ranks these results to encourage diversity, surfacing items that remain relevant but less redundant.&lt;/p&gt;
    &lt;p&gt;It implements several popular diversification strategies such as MMR, MSD, DPP, and Cover with a clear, unified API. More information about the supported strategies can be found in the supported strategies section. The only dependency is NumPy, making the package very lightweight.&lt;/p&gt;
    &lt;p&gt;Install &lt;code&gt;pyversity&lt;/code&gt; with:&lt;/p&gt;
    &lt;code&gt;pip install pyversity&lt;/code&gt;
    &lt;p&gt;Diversify retrieval results:&lt;/p&gt;
    &lt;code&gt;import numpy as np
from pyversity import diversify, Strategy

# Define embeddings and scores (e.g. cosine similarities of a query result)
embeddings = np.random.randn(100, 256)
scores = np.random.rand(100)

# Diversify the result
diversified_result = diversify(
    embeddings=embeddings,
    scores=scores,
    k=10, # Number of items to select
    strategy=Strategy.MMR, # Diversification strategy to use
    diversity=0.5 # Diversity parameter (higher values prioritize diversity)
)

# Get the indices of the diversified result
diversified_indices = diversified_result.indices&lt;/code&gt;
    &lt;p&gt;The returned &lt;code&gt;DiversificationResult&lt;/code&gt; can be used to access the diversified &lt;code&gt;indices&lt;/code&gt;, as well as the &lt;code&gt;selection_scores&lt;/code&gt; of the selected strategy and other useful info. The strategies are extremely fast and scalable: this example runs in milliseconds.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;diversity&lt;/code&gt; parameter tunes the trade-off between relevance and diversity: 0.0 focuses purely on relevance (no diversification), while 1.0 maximizes diversity, potentially at the cost of relevance.&lt;/p&gt;
    &lt;p&gt;The following table describes the supported strategies, how they work, their time complexity, and when to use them. The papers linked in the references section provide more in-depth information on the strengths/weaknesses of the supported strategies.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Strategy&lt;/cell&gt;
        &lt;cell role="head"&gt;What It Does&lt;/cell&gt;
        &lt;cell role="head"&gt;Time Complexity&lt;/cell&gt;
        &lt;cell role="head"&gt;When to Use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MMR (Maximal Marginal Relevance)&lt;/cell&gt;
        &lt;cell&gt;Keeps the most relevant items while down-weighting those too similar to what’s already picked.&lt;/cell&gt;
        &lt;cell&gt;O(k · n · d)&lt;/cell&gt;
        &lt;cell&gt;Good default. Fast, simple, and works well when you just want to avoid near-duplicates.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MSD (Max Sum of Distances)&lt;/cell&gt;
        &lt;cell&gt;Prefers items that are both relevant and far from all previous selections.&lt;/cell&gt;
        &lt;cell&gt;O(k · n · d)&lt;/cell&gt;
        &lt;cell&gt;Use when you want stronger spread, i.e. results that cover a wider range of topics or styles.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DPP (Determinantal Point Process)&lt;/cell&gt;
        &lt;cell&gt;Samples diverse yet relevant items using probabilistic “repulsion.”&lt;/cell&gt;
        &lt;cell&gt;O(k · n · d + n · k²)&lt;/cell&gt;
        &lt;cell&gt;Ideal when you want to eliminate redundancy or ensure diversity is built-in to selection.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;COVER (Facility-Location)&lt;/cell&gt;
        &lt;cell&gt;Ensures selected items collectively represent the full dataset’s structure.&lt;/cell&gt;
        &lt;cell&gt;O(k · n²)&lt;/cell&gt;
        &lt;cell&gt;Great for topic coverage or clustering scenarios, but slower for large &lt;code&gt;n&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Traditional retrieval systems rank results purely by relevance (how closely each item matches the query). While effective, this can lead to redundancy: top results often look nearly identical, which can create a poor user experience.&lt;/p&gt;
    &lt;p&gt;Diversification techniques like MMR, MSD, COVER, and DPP help balance relevance and variety. Each new item is chosen not only because it’s relevant, but also because it adds new information that wasn’t already covered by earlier results.&lt;/p&gt;
    &lt;p&gt;This improves exploration, user satisfaction, and coverage across many domains, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E-commerce: Show different product styles, not multiple copies of the same black pants.&lt;/item&gt;
      &lt;item&gt;News search: Highlight articles from different outlets or viewpoints.&lt;/item&gt;
      &lt;item&gt;Academic retrieval: Surface papers from different subfields or methods.&lt;/item&gt;
      &lt;item&gt;RAG / LLM contexts: Avoid feeding the model near-duplicate passages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The implementations in this package are based on the following research papers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MMR: Carbonell, J., &amp;amp; Goldstein, J. (1998). The use of MMR, diversity-based reranking for reordering documents and producing summaries. Link&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MSD: Borodin, A., Lee, H. C., &amp;amp; Ye, Y. (2012). Max-sum diversification, monotone submodular functions and dynamic updates. Link&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;COVER: Puthiya Parambath, S. A., Usunier, N., &amp;amp; Grandvalet, Y. (2016). A coverage-based approach to recommendation diversity on similarity graph. Link&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DPP: Kulesza, A., &amp;amp; Taskar, B. (2012). Determinantal Point Processes for Machine Learning. Link&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DPP (efficient greedy implementation): Chen, L., Zhang, G., &amp;amp; Zhou, H. (2018). Fast greedy MAP inference for determinantal point process to improve recommendation diversity. Link&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thomas van Dongen&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634310</guid><pubDate>Sun, 19 Oct 2025 14:16:12 +0000</pubDate></item><item><title>ISP Blocking of No-IP's Dynamic DNS Enters Week 2</title><link>https://torrentfreak.com/isp-blocking-of-no-ips-dynamic-dns-enters-week-2-251019/</link><description>&lt;doc fingerprint="af1ef9413c887fcd"&gt;
  &lt;main&gt;
    &lt;p&gt;In a legal dispute now at the U.S. Supreme Court, the world’s leading record labels and Cox Communications disagree on many things, including how to respond to online piracy.&lt;/p&gt;
    &lt;p&gt;The labels’ preferred solution is to sever subscribers’ access to the internet. Cox believes that denying internet access is excessive. The case is much more complex than that as the venue suggests, but one aspect seems clearer when viewed in its own light.&lt;/p&gt;
    &lt;p&gt;When a person gets caught pirating music online, should everyone in their household be denied access to banking, health care, education, and everything else people need to simply exist? Is collective punishment the right way to satisfy a commercial dispute, between a record company and an ISP, over alleged activity of which the family likely had zero knowledge, and were never in a position to control or prevent?&lt;/p&gt;
    &lt;head rend="h2"&gt;Collective Punishment, Every Single Week&lt;/head&gt;
    &lt;p&gt;The proposition above sounds fundamentally unfair, because punishing innocent people is always unfair. Billions of people understand and respect the principle of individual responsibility and violations are quite rightly viewed with contempt.&lt;/p&gt;
    &lt;p&gt;Yet, some will argue that life is full of unfairness. Inconvenience for a few people is inevitable when solving important copyright disputes involving a lot more money than most people have ever seen.&lt;/p&gt;
    &lt;p&gt;In Spain, an important copyright dispute and accompanying site-blocking order certainly don’t authorize collective punishment on an unprecedented level. Yet, for several hours, several times each week, local ISPs now block hundreds of Cloudflare IP addresses to prevent access to unidentified pirate streaming services run by unidentified people.&lt;/p&gt;
    &lt;p&gt;There’s no discrimination; ISP’s deploy blocking measures that affect their own customers, denying access to websites using Cloudflare’s services and any others that also happen to be blocked.&lt;/p&gt;
    &lt;p&gt;There appears to be no warning and little transparency. ISPs never inform customers of incoming blocking, and it’s not uncommon for questions about suspected blocking to be brushed aside or simply ignored. Fingers invariably point to an unspecified court order, obtained by an unspecified entity, on unspecified grounds. As a solution to their current access problems, the information is totally useless to any customer.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Blocking of NO-IP’s Dynamic DNS&lt;/head&gt;
    &lt;p&gt;For well over a week, users in Spain have been reporting problems with ddns.net, a dynamic DNS service offered for free by NOIP.com. DDNS.net and similar services offer a solution to an issue affecting anyone with an IP address that periodically changes.&lt;/p&gt;
    &lt;p&gt;When not at home, for example, gaining access to CCTV cameras might suddenly prove impossible when an ISP allocates a new IP address. Using a service like DDNS.net allows users to associate their IP address with a DDNS.NET subdomain ([email protected]) with future IP address updates handled automatically.&lt;/p&gt;
    &lt;p&gt;Not only are services like these useful, some routers have them built in, so people may be using and benefiting from them without even knowing.&lt;/p&gt;
    &lt;p&gt;Some users recognized the problem immediately, and with records showing almost 350,000 URLs associated with the ddns.net domain, there’s plenty of scope for disruption.&lt;/p&gt;
    &lt;p&gt;The above post on X is a fairly typical report with some useful additional detail. It mentions an ISP called Digi, which, instead of returning the correct IP address associated with the user’s DDNS.net subdomain, points it to the 127.0.0.1 loopback address that refers to the user’s current device.&lt;/p&gt;
    &lt;p&gt;A follow-up post by the same user a day later reveals that blocking actually began on October 8, and despite requesting information from Digi, no explanation had been forthcoming. Another user affected by the issue eventually received a response earlier this week.&lt;/p&gt;
    &lt;p&gt;While a court order was confirmed as the root issue, refusal to elaborate any further isn’t just common; it’s the standard across all ISPs in Spain. To our knowledge, blocking orders to date haven’t carried any non-disclosure conditions, so in most cases, there’s no legal reason underpinning the lack of transparency.&lt;/p&gt;
    &lt;head rend="h2"&gt;DDNS.net is Definitely Subject to Blocking&lt;/head&gt;
    &lt;p&gt;Confirmation that Digi continues to block at the time of writing is available via the unofficial third-party blocking transparency portal hayahora.futbol.&lt;/p&gt;
    &lt;p&gt;Current information shows that Digi continues to block the service, but details reported elsewhere show that this wasn’t a lone action.&lt;/p&gt;
    &lt;p&gt;Local reports state that Movistar displayed Error 451 (Unavailable for Legal Reasons), MásOrange displayed the message “Content blocked at the request of the Competent Authority, communicated to this Operator,” while Vodafone said it could do nothing about the outage: “For reasons beyond Vodafone’s control, this website is unavailable.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Alone in the Dark&lt;/head&gt;
    &lt;p&gt;The lack of transparency is pervasive, and the indifference to the problems experienced by subscribers all over Spain is evident every week. People with zero connection to any of the parties involved in blocking disputes continually pay the price, wasting hours finding workarounds to bypass deliberate network blockages that, for no good reason, are shrouded in secrecy.&lt;/p&gt;
    &lt;p&gt;A user who could no longer access his server using Wireguard reported the problems to his ISP, Digi, on October 13. He was informed that, having looked into it, no issues could be found. That led to an entire thread of potential solutions, including replacing the ISP’s DNS with another service and replacing DDNS.net with a similar service operated by DuckDuckGo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Consolation: Could’ve Been Significantly Worse&lt;/head&gt;
    &lt;p&gt;Tests suggest that the blocking efforts target the DDNS.net domain, but how far the damage goes in respect of subdomains is difficult to determine by users of non-blocking ISPs.&lt;/p&gt;
    &lt;p&gt;Digi operates at least two public DNS servers, but remote tests yielded no useful information. Fortunately, domain blocking doesn’t appear to be accompanied by IP address blocking, at least in this case. DDNS.net has thousands of subdomains, but if its IP address had been targeted too, the exponential scale of the fallout could’ve been extraordinary.&lt;/p&gt;
    &lt;p&gt;The situation in Spain has no parallel in Europe. Blocking is expanding elsewhere, including in the UK, most recently to protect a company behind several well-known weight loss drugs. However, avoidable collateral damage on this scale has never happened.&lt;/p&gt;
    &lt;p&gt;That it takes place in a member state of the increasingly heavily regulated European Union remains completely unfathomable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634333</guid><pubDate>Sun, 19 Oct 2025 14:19:41 +0000</pubDate></item><item><title>Xubuntu.org Might Be Compromised</title><link>https://old.reddit.com/r/Ubuntu/comments/1oa4549/xubuntuorg_might_be_compromised/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634367</guid><pubDate>Sun, 19 Oct 2025 14:25:45 +0000</pubDate></item><item><title>Websites Are for Humans</title><link>https://marcus-obst.de/blog/websites-are-for-humans</link><description>&lt;doc fingerprint="3653984408b0dad1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Websites are for humans.&lt;/head&gt;
    &lt;p&gt;The following text has not been touched by any LLM. There might be plot holes and loose, untied ends. It's called "The Weave". It will come together at the end.&lt;/p&gt;
    &lt;p&gt;For a few days I noticed these weird surveillance camera videos in my Instagram feed (which I'm sometimes scrolling through despite knowing better). I saw a bunch of cat videos that led me to believe they weren't real, but AI generated. Then I remembered that OpenAI just released Sora 2 and how they attempt to become an all-in-one video platform/social network for AI slop and how some techno-edge-lords claim OpenAI just made any tech stack obsolete, because AI is going to do this or that, create Spotify playlists with AI generated music and so on. I don't follow that too closely, but I'm open to AI (hence OpenAI ^^) therefore I'm thinking about it.&lt;/p&gt;
    &lt;p&gt;So I prompted my brain to see what it comes up with of what the future might hold: From my and others' point of view, what's going to happen is, people will abandon commercial social media, with its restrictions, its demented influencers peddling garbage, its AI slop and its inflammatory algorithmic cortisol-inducing shock content. What finally will break people's brains (and I extrapolate that from my brain) is the decision fatigue that is growing, that we now have to figure out if a funny cat video is real or the product of some sicko who burns down a forest because he thinks it's funny to generate a video of a cat taking a dump into the foamy, rose petal decorated bath water with the artificial cat owner in it freaking out.&lt;/p&gt;
    &lt;p&gt;I'm not opposing AI. There are some cases where it helped me a lot, but there is also evidence of how it keeps people from getting things done. There is evidence that people grow tired of those fata morganas that AI creates. Fata morganas of work being done, and when you look closer, it's nothing. It's an anamorphic sculpture[1] that looks great from that one angle and if you move to see it from a different angle, it's just a bunch of crap piled on each other.&lt;/p&gt;
    &lt;p&gt;The human touch will become more important, and more expensive. Artisanal quality time. Professional writers and programmers have more to do than ever, because they have to give back the human touch to generated word-salad or make vibe-coded software secure and efficient.&lt;/p&gt;
    &lt;p&gt;I have no idea what social networks are being replaced with. It's going to be more fragmented, that's for sure. Different smaller platforms, maybe even non-public platforms (meeting at a bar?) and intranets.&lt;/p&gt;
    &lt;p&gt;And that might lead to a revival of the two principles established by the IndieWeb movement: POSSE (Publish (on your) Own Site, Syndicate Elsewhere) and PESOS (Publish Elsewhere, Syndicate (to your) Own Site).&lt;/p&gt;
    &lt;p&gt;Make your own website the single source of truth. Post there first and share links to whatever web service is currently hyped. Or post on those platforms, but pull that content back into your own website.&lt;/p&gt;
    &lt;p&gt;Both principles have some caveats. POSSE has to deal with web services that downrank external links. PESOS has to deal with limited programmatic access to APIs (try to fetch an Instagram or LinkedIn post, it costs money), but in any case, it's worth it to try and keep control over the things you create commercial/professional or private content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634484</guid><pubDate>Sun, 19 Oct 2025 14:40:47 +0000</pubDate></item><item><title>Why an abundance of choice is not the same as freedom</title><link>https://aeon.co/essays/why-an-abundance-of-choice-is-not-the-same-as-freedom</link><description>&lt;doc fingerprint="f251d10d28e319bd"&gt;
  &lt;main&gt;
    &lt;p&gt;By the time you read this essay, no matter the hour of the day, you will likely have already made some kind of choice: coffee with skimmed milk, whole milk, cream, or black? Sugar or no sugar? Tea instead? Personalised, preference-based choice is, at present, a deeply familiar aspect of life in much of the world, though perhaps most markedly so in the United States, where I live and work. It is also something people don’t generally spend a lot of time discussing, in part because it feels so ordinary. People around the globe shop for everything from housing to vacations to, yes, caffeinated drinks. They pick what they want to read, what they want to listen to, and what they want to believe. They vote for favourite candidates for office. They select friends and lovers, fields to study, professions and jobs, places to live, even insurance plans to hedge their bets when something they cannot choose occurs.&lt;/p&gt;
    &lt;p&gt;Perusing a menu of options to decide what best matches individual desires and values – which is what we generally mean today by making a choice – is a key feature of modern democratic and consumer culture alike. It is also an exalted one. People may disagree about what the possibilities should be, but rarely about the principle of maximising arenas for choice-making or the options themselves. For many of the world’s citizens, this is simply what freedom feels like.&lt;/p&gt;
    &lt;p&gt;Yet, as you may have also felt at various moments, abundant choice isn’t always so straightforward. Behavioural economists point out that most people are actually pretty bad at making decisions of this kind (which explains the appeal of return departments and divorces for when things don’t go as hoped). Philosophers and political theorists say it promotes selfish individualism and discourages collective action around issues that affect us all. And sociologists add that societies that prize choice too much tend to blame those with only poor or limited options for their own misfortunes. So much for choice as consistently synonymous with freedom.&lt;/p&gt;
    &lt;p&gt;What is strange, though, is that few of these critics ever really question either the centrality or the value of choice-making in contemporary life. On the contrary, they tend to make their case as if people everywhere had always spent their days doing things that feel commonplace in capitalist democracies and, indeed, hankering for more such chances. But for the historian, it is obvious that this entire phenomenon is culturally specific. There are people around the globe even today who actively resist this framing of freedom. What may be more surprising is that granting this special status to choice-making is also a relatively recent development even in Western Europe and the United States, not to mention the rest of the world.&lt;/p&gt;
    &lt;p&gt;So how did we get to this point? How did choice become a proxy for freedom in so many domains in modern life? As we discover more and more about our troubles navigating it, we might also wonder if there are other, better ways to be free.&lt;/p&gt;
    &lt;p&gt;Though the explosion of choice has largely been a 20th-century phenomenon, the full story is a long one, going all the way back to the 17th and 18th centuries. Personal choice, as both experience and term of art, got its start in two quite distinct early modern spaces.&lt;/p&gt;
    &lt;p&gt;One is the realm of the shop. Fuelled by the building of colonial and interior trade networks, new goods started to enter cities and towns as early as the 17th century, first in Western Europe, then in the New World, and gradually in their hinterlands too. Particularly significant among those goods were patterned and brightly coloured textiles called calicoes, originally from South Asia, whose price point made it possible for ordinary people to have the novel experience of selecting from among different designs for clothing or home furnishings. Checks? Flowers? Stripes? Purple or green? The decision could, distinctively, be based on nothing more than personal preference. For at the same time, a leisure-time activity blossomed, first at auctions in temporary locations and then increasingly in fixed destinations called shops, in which consumers were invited to peruse a display of the options for sale before ever opening their purses.&lt;/p&gt;
    &lt;p&gt;Even people with limited means started to engage in such new activities as trying out different preachers&lt;/p&gt;
    &lt;p&gt;The English-language neologism ‘shopping’, as opposed to provisioning, took off in the second half of the 18th century precisely to describe this newfangled business. We now also call it consumer choice. The customer learned from all of this browsing and weighing the possibilities to ‘make a choice’ – which is to say, an aesthetic as well as a practical determination en route to purchasing – from what were often already described as a set of ‘choice’, or pre-selected, goods ripe for picking.&lt;/p&gt;
    &lt;p&gt;The post-Reformation fracturing of Christianity, combined with the Protestant tradition of ‘freedom of conscience’ or ‘religious choice’, gradually produced a sense of ideas and beliefs as being similarly up for selection in a pluralist world. With the double emergence of Enlightenment notions of tolerance in Europe and of the Great Awakening religious revival in the British colonies, even people with limited means started, on both sides of the Atlantic, to engage in such new activities as trying out different preachers and churches where congregations had become voluntary communities, attending varieties of public lectures, and picking books from lending libraries and sales catalogues. These, too, were learned recreations, ones that soon revolved around secular as well as sacred notions. Consider Jane Austen’s fictional heroine in Mansfield Park (1814) who, when she gets up the nerve to subscribe to a lending library, is, in Austen’s lightly satirical telling, ‘amazed at her own doings in every way, to be a renter, a chuser [sic] of books!’ From such actions, the stage was set for intellectual choice as well.&lt;/p&gt;
    &lt;p&gt;Between the late 18th century and the First World War, choice continued to expand its domain, encompassing the selection of other people, from marriage partners to employees to political representatives, too. At the same time, it became subject to ever more rules and strictures, formal and not, so as both to tame its potential for undermining the social order and to make it work.&lt;/p&gt;
    &lt;p&gt;In the course of the 19th century, choice increasingly entered the romantic and sexual lives of urban men and women, though with significant gender distinctions when it came to the rules, creating affective and bodily choice as well. This was a development tied very much to the rise of both the idea of companionate marriage – spouses who consent to marry out of mutual affection or even attraction – and an elaborate etiquette about how to identify and court possible partners in a world in which everyone didn’t already know everyone else. From Santiago and Chicago to Paris and Stockholm, and from working-class ticketed dance halls to private soirées for the elite, balls, in particular, became places for organising and evaluating the options in a world in which both young men and young women had been given the power to contract freely for a spin around the dance floor – and also, potentially, for permanent coupledom in the form of a marriage (aka ‘The Choice’, though a marriage contract would technically mean the end of sexual choice once it was signed and sealed). Employment saw a similar kind of transition insofar as it, too, became increasingly a matter of sorting mechanisms, markets and contracts.&lt;/p&gt;
    &lt;p&gt;Finally (and surprisingly late), a similar form of choice came to politics in the form of new voting practices as well as an increase in formal laws to go with them. It is well known that the 19th century was marked by intense debates, from Central Europe to Latin America, about who should be able to vote as new democratic norms spread to many parts of the world. Much less well remembered is the rise of intense discussions about how all these new voters should go about the business of suffrage, especially when it came to the moment of choice itself. Voices in favour of secret balloting, like the Sons of Liberty in New York City, had made themselves heard by the end of the 1760s. But it wasn’t until another century had passed that this mode of voting, rooted in the idea of the protection of internal personal preferences from outside pressure, became the international gold standard, instituted first in Australia in the 1850s (hence what is sometimes still called the Australian ballot) and then by a host of other nations around the globe in the decades just preceding the First World War.&lt;/p&gt;
    &lt;p&gt;Psychiatrists, marketing experts and economists devoted themselves, in different ways, to the study of choice-making&lt;/p&gt;
    &lt;p&gt;Even at the time, commentators were amazed that this transformation took place with so little upheaval. That may well be because the change to secret, individualised voting diminished the rowdiness and violence so often previously associated in many places with popular and considerably more communal elections. But surely it was also because, by the time this shift occurred, it seemed to bring elections into line with so many other kinds of 19th-century leisure-time activities. The secret ballot allowed for the same sorts of choice-making to be enacted when it came to candidates, though with the results eventually aggregated into group choice, as it did for other forms of picking – overcoming the longstanding objections of even liberals like John Stuart Mill, who worried that the last stronghold of public life would in this way be privatised. Only the workplace would remain largely immune. In effect, if the initial age of revolutions in the 18th century introduced popular sovereignty based on elections in the first place, we might think of this as the moment of a second age of democratic revolution.&lt;/p&gt;
    &lt;p&gt;But the 20th century added its own finishing touches to the story of choice. The ranks of choosers continued to expand, albeit highly unevenly, to include women, poor people, sometimes even children, especially in places where mass goods, from newspapers to chewing gum, became widely available. So did the ranks of ‘choice agents’, the people creating the menus of options, inventing the rules, and directing the activity itself. Beyond shop owners, itinerant preachers, dancing masters and political party officials, now new kinds of social scientists came to the fore. Psychiatrists, marketing experts, economists: in different ways, they all devoted themselves to the study of choice-making, exploring who makes what choices under what conditions and with what effects, along with how individuals and groups could be steered to make better ones. Ordinary people participated in this work every time they sat on a couch for a therapy session or filled out a survey card or took a multiple-choice exam. Together, researchers and their everyday subjects, male and female, invented sciences of choice, further entrenching the idea of humans as, fundamentally, choosers.&lt;/p&gt;
    &lt;p&gt;Needless to say, the rise of the internet has only expanded this model. Today, the sheer number of both choice-making opportunities and options has grown exponentially, whether we are talking about music or vacuum cleaners. The nature of our choices has also changed. Before the age of shopping for goods and selecting ideas had really gotten underway, most choices were structured around doing the right thing rather than the wrong. Since then, choice has increasingly become value-neutral, a matter of one’s own interior preferences being externalised in the act of selection. Moreover, choice has become more and more important to conceptions of human flourishing. Once, picking from menus was of relatively little significance, especially since freedom was imagined in the Western tradition well into the 18th century more often as a matter of not having to make many choices or strive too much thanks to being born with the status of an independent person. Over time, however, choice became a means of achieving the liberty to shape one’s life as one saw fit. It also became a key signifier of being a full-fledged, autonomous person worthy of respect by others. Since the end of the Second World War, we might say that it has become a value unto itself, widely celebrated from billboards to international human rights decrees as the meeting point of capitalism and democracy. When then French presidential candidate Emmanuel Macron said, in 2016, ‘I believe deeply in a society governed by choice,’ he was in a certain sense uttering what had become a banality.&lt;/p&gt;
    &lt;p&gt;This is a story that has not been told before, even as some of the details may feel familiar from lived experience. It is also an essential story to grapple with if we want to try to understand what has been gained and lost from an investment in choice as the defining feature of ‘free time’ as well as a basic understanding of freedom. How have people, individually and collectively, benefitted from this mushrooming of options and opportunities for choice – and how and when has choice led us astray? This is a question that behavioural economists and all others who take our current actions and investments as constants have largely failed to ask.&lt;/p&gt;
    &lt;p&gt;On the one hand, it is easy to read this narrative as a tale of liberation. Take feminism. Women in Europe and its outposts got their first real taste of the modern form of choosing as shoppers for ribbons, fabrics and other sundries, as late-18th-century novels – and especially those written by and for women – make very clear. Certainly, both women and this new kind of value-neutral, preference-based choice-making were quickly tainted by association with each other; the coquette was a much-mocked figure of the 18th and 19th centuries, a stereotype of a woman who relishes her own choices a little too much and isn’t very good at them either. But as new forms of individualised selection became more important to life beyond the textile purveyor’s shop, and as men got in on the game as well, an expanded repertoire of choice, including in ideas, reading matter, marriage, children, career and finally politics, became one of the key aspirations for women looking to break free of their traditional constraints.&lt;/p&gt;
    &lt;p&gt;Female suffrage, for example, could be advocated at the start of the 20th century as simply an extension of women’s already existing capacity to make a selection from a list-like menu. By the start of the 1960s, the American feminist Betty Friedan could argue that women’s full liberation required them to follow their male counterparts in seizing ‘the power to choose’ in their personal lives too, including in forging ‘an identity’ beyond housewife. And a decade later, mainstream abortion rights advocates, not surprisingly, took the same tack, imagining limited resistance to a focus on choice. Who, after all, could object? Behind the 1970s feminist idea of ‘a right to choice’ when it came to motherhood was the argument that no one should be compelled to pick this solution – abortion – for themselves; the law now simply ensured that everybody could, as needed, determine which of the possibilities on offer seemed like the best option by their own criteria. Plus, having choices meant the essential opportunity to reassert one’s standing as author of one’s own destiny – a point sometimes made by stateless people today as well. No wonder the ability to choose has become a key factor in global happiness indexes.&lt;/p&gt;
    &lt;p&gt;A market model for governance would, ironically, mean the end of democracy as we know it&lt;/p&gt;
    &lt;p&gt;But the abortion debate of the 1970s also illustrates some of the limitations of this framing. Soon after the passage of the Roe v Wade US Supreme Court Ruling legalising abortion in the early months of pregnancy, an emerging Right-wing coalition landed on a clever strategy for opposition, arguing that the ‘life’ of the fetus outweighed mere ‘choice’ on the part of the mother. In other words, in feminists’ enthusiasm for having choices, the moral dimension of what was being chosen had been pushed to the side, leaving behind a very thin foundation for a major policy matter. And from the Left, and especially from Black feminists, came the argument that choice itself was meaningless, an empty promise, unless it was to be accompanied by a commitment to meeting women’s basic needs, whether that meant the money necessary to travel and pay for an abortion, or greater financial and institutional support for mothers after their children were born. In this sense, they too warned of the dangers of the shopper and shopping as models for all our activities, even when couched as rights.&lt;/p&gt;
    &lt;p&gt;Now we are seeing some of the fallout of this debate writ large. Today, a far-Right ‘dark enlightenment’ movement imagines a market model for everything, including governance, which would, ironically, mean the end of democracy as we know it. At the same time, significant pushback around the world against feminism, and now against gay and trans rights as well, has become emblematic of the rejection of a larger vision of freedom rooted in personal choice. As a result of democracy-promotion and global capitalism, almost no one in the world currently stands entirely outside the choice-as-freedom paradigm; it has gradually enveloped even those with very limited ability or opportunity to choose or with only rotten choices before them. Voting, for example, is near universal today even in places like Russia, where it is a sham. But an emphasis on choice as a form of liberation has occasioned serious resentments in different sectors and geographies, where it can seem a direct threat to other, more communal values and needs.&lt;/p&gt;
    &lt;p&gt;Indeed, even in democracies, choice can sometimes seem to be not only an illusion (is there any real difference between the scores of toothpastes or breakfast cereals in contemporary supermarkets?) or a headache to contend with, but a regressive force. Think, for example, of people who took up the pro-abortion rights phrase ‘My body, my choice’ to protest mask or vaccine mandates during the COVID-19 pandemic, even as they were told that the point of both actions was to limit the spread of the disease and advance public health more broadly. Or consider how the US president Donald Trump’s current claims to be restoring the American people’s ‘freedom to choose’ in the market for cars and appliances will require gutting environmental regulations and thus advancing climate change in ways that will negatively impact all of us. It’s not just that we don’t always know our minds. It’s that choice in its current incarnation isn’t, in fact, always freeing.&lt;/p&gt;
    &lt;p&gt;So where does this leave us? The answer is not with one or the other of these visions. But considering the history of choice should make us more self-conscious the next time we are fretting over whether to pick the oat milk rather than the half-and-half, not to mention one train ticket or candidate for office or college course over another. We might instead ask ourselves: when, collectively, should we be invested in individual choice as a good way to solve a shared problem, and when not? And when should I, as an individual, try to maximise the opportunity to make choices about my own life versus not doing so? Most of all, though – as we struggle with both choice overload and the failures of personal choice to help us solve some of our biggest problems, including the rise of forms of authoritarianism directed squarely against choice – thinking about our attachment to choosing off menus should make us wonder what other possibilities for defining freedom might be lurking out there. In the past, for example, freedom has sometimes been imagined as a release from oppression or as an act of pure imagination, alternative visions we might want to bring back into circulation. As it turns out, choice doesn’t always produce freedom, and freedom itself often looks very different.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634641</guid><pubDate>Sun, 19 Oct 2025 14:58:16 +0000</pubDate></item><item><title>What Are RFCs? The Forgotten Blueprints of the Internet</title><link>https://ackreq.github.io/posts/what-are-rfcs/</link><description>&lt;doc fingerprint="bb881b5309e59fce"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Are RFCs? The Forgotten Blueprints of the Internet&lt;/head&gt;
    &lt;p&gt;Think about it for a second: could the internet exist without standards and protocols? Of course not! Computers need shared rules and agreements to communicate with one another. Even human languages, like English, work much the same way. They function as a kind of communication protocol because we’ve all agreed on words and grammar that carry shared meaning. In both cases, whether among machines or people, communication depends on common understanding.&lt;/p&gt;
    &lt;p&gt;This is where RFCs come in. They’re the blueprints and proposals that define how the internet operates and how systems interact. In this post, we’ll take a closer look at RFCs and uncover some of the fascinating history behind the internet.&lt;/p&gt;
    &lt;p&gt;Before we dive in, here’s a quick overview: RFCs, or Requests for Comments, are official documents that explain how Internet technologies work. They outline how systems are expected to behave and interact. Think of them as the reference guides for anyone who wants to build, understand, or improve the Internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;the Birth of the Internet&lt;/head&gt;
    &lt;p&gt;The history of the internet is a long and amazing tale — one that deserves its own post (and I’ll probably write about it). But for now, let’s focus on how it all began.&lt;/p&gt;
    &lt;p&gt;I’m not going to answer “Who invented the Internet?” because that’s the wrong question. The internet didn’t appear overnight; it took decades to mature. Instead, we can highlight the people who played key roles in shaping today’s internet.&lt;/p&gt;
    &lt;p&gt;It all started in the USA in 1958, when the government created the Advanced Research Projects Agency (ARPA) to fund research in new technologies — partly driven by Cold War tensions. The US government was worried that a nuclear first strike from the Soviets could wipe out their communication. To prevent that, they established computer research centers at leading universities. The goal was to create a reliable, distributed communication system that could continue operating even if parts of it were damaged by a nuclear attack.&lt;/p&gt;
    &lt;p&gt;Computers — or better to say, mainframes back in those days — were gigantic and could fill an entire room. Here’s what an IBM 7090 mainframe looked like in the early 60s:&lt;/p&gt;
    &lt;p&gt;Fernando Corbató with MIT’s IBM 7090&lt;/p&gt;
    &lt;p&gt;Back then, transferring data was nothing like the internet file uploads we know today. First, everything was physical: punch cards or paper tapes had to be loaded manually into machines. Then came magnetic tapes (big reels of tape containing data) which you’d physically transport to other machines:&lt;/p&gt;
    &lt;p&gt;Set of punch cards + punched paper tape + magnetic tape&lt;/p&gt;
    &lt;p&gt;Since these computers were geographically separated, they needed a way to connect and exchange information reliably and fast. The solution was to develop a packet-switching network, which could send data in small blocks called “packets” that could travel independently across the network and be reassembled at their destination. This system eventually became the ARPANET, the first network to implement packet switching, laying the foundation for the modern internet.&lt;/p&gt;
    &lt;p&gt;In fact, the first use of the term protocol in a modern data communication context appeared in April 1967, in a memorandum titled “A Protocol for Use in the NPL Data Communications Network”. It was written under the direction of Donald Davies, who pioneered the concept of packet switching.&lt;/p&gt;
    &lt;p&gt;In 1969, the first message was sent over ARPANET from UCLA to Stanford university. They tried to send the word &lt;code&gt;LOGIN&lt;/code&gt;, but only &lt;code&gt;LO&lt;/code&gt; made it through before the system crashed. About an hour later, after recovering from the crash, the full message was successfully transmitted.&lt;/p&gt;
    &lt;p&gt;by 1970, there were around 15 nodes (or computers), and by 1972, 19 nodes were connected. In 1973 they even created a map of ARPANET — the same one you see in the post preview image. ARPANET was considered a major success because it showed that packet-switching technology worked in practice and made it possible for distant computers to share information reliably. However, access was still limited to universities and research organizations that held contracts with the U.S. Department of Defense.&lt;/p&gt;
    &lt;p&gt;As you can see, the network was growing rapidly and that didn’t happen by chance. It was the result of coordination and collaboration. Every node and computer had to follow the same rules and standards to communicate effectively.&lt;/p&gt;
    &lt;p&gt;By the late 1980s, the foundations laid by ARPANET and early networking experiments made it possible for something revolutionary: in 1989, Tim Berners-Lee proposed the World Wide Web (WWW), which went public in 1991, opening the internet to everyone.&lt;/p&gt;
    &lt;p&gt;We’ll pause the story of the internet here, having covered the key parts. If you’re interested to know more, you can check out this infographic:&lt;/p&gt;
    &lt;p&gt;Internet History Timeline (Infographic from Behance)&lt;/p&gt;
    &lt;p&gt;Now it’s time to explore the technical documents that shape and standardize Internet operations.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Are RFCs?&lt;/head&gt;
    &lt;p&gt;Request for Comments (RFCs) are a series of numbered documents that describe how the internet works and how different systems communicate. They address a variety of topics, including core standards, communication protocols, guidelines, design ideas, and concepts that help keep the global network running smoothly. Each RFC is written by engineers and computer scientists as a memorandum presenting new ideas, research findings, proposed methods, or other concepts related to internet technologies.&lt;/p&gt;
    &lt;p&gt;The RFC system was created in 1969 by Steve Crocker to record and share informal notes on the development of ARPANET. The goal was to help researchers share ideas about how the network should operate, how computers (hosts) should communicate, and how software running on these hosts should behave.&lt;/p&gt;
    &lt;p&gt;The very first RFC, titled “Host Software”, was published by Crocker himself on April 7, 1969. In this context, “host software” referred to the programs and protocols that computers needed to communicate over ARPANET, essentially the foundational rules for networked computing at the time:&lt;/p&gt;
    &lt;p&gt;RFC 1: The first Request for Comments document published in 1969&lt;/p&gt;
    &lt;p&gt;Every RFC is assigned a unique number upon publication — starting with RFC 1 — and these numbers are permanent. Once a document receives its number, it never changes or gets reused, even if that RFC later becomes obsolete or is replaced by a newer one. This numbering system helps maintain a consistent historical record of the internet’s evolution and ensures that every RFC can be precisely referenced.&lt;/p&gt;
    &lt;p&gt;Today, RFCs are maintained and published by the Internet Engineering Task Force (IETF), which continues to develop and expand them. While many RFCs are experimental in nature and never become official standards, others have become the backbone of the Internet’s architecture. These include the core technologies we rely on every day, such as TCP/IP, HTTP, and DNS. RFCs not only define how these protocols operate but also reveal the reasoning behind their design, helping us understand how the global network actually operates.&lt;/p&gt;
    &lt;p&gt;RFCs are often described as the blueprints of the internet. Yet, in an age where artificial intelligence and higher-level tools make technology more accessible, fewer people explore the underlying systems and details of how things actually work (at least, that’s my perspective). I believe RFCs are essential reading for anyone involved in technology or IT — that’s why I wrote this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why They Still Matter Today?&lt;/head&gt;
    &lt;p&gt;RFCs remain the official source of truth for Internet standards, ensuring consistency across the global network. By studying them, developers learn not just the rules, but also why they exist, gaining the knowledge needed to build software and systems that communicate reliably with other computers.&lt;/p&gt;
    &lt;p&gt;You can’t create something truly dependable without understanding its foundations — just as you couldn’t design a beautiful building without knowing architecture, the same principle applies to apps and networked systems.&lt;/p&gt;
    &lt;p&gt;For instance, if you ever wanted to build your own DNS server, the first step isn’t writing code from scratch or copying an online tutorial. You’d start by reading relevant RFCs, which define the domain name system and how queries and responses should work. By understanding the protocol from the original source, you can ensure your implementation is reliable, interoperable, and standards-compliant. This is the power of RFCs: they let you build on solid foundations rather than reinventing the wheel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding and Reading Them&lt;/head&gt;
    &lt;p&gt;The official source for RFCs is the RFC Editor, which manages the publication, editing, and archiving of all RFC documents. If you want to explore the development process behind RFCs — including drafts, authors, and approval stages — the IETF Datatracker provides detailed information on every document’s history and current status. Also, for a more comfortable reading experience, RFC Reader offers an online viewer with features like an automatic table of contents, note-taking, and search capabilities.&lt;/p&gt;
    &lt;p&gt;For guidance on how to read RFCs, the IETF provides a helpful article titled “How to Read an RFC”. I strongly recommend reading it. The article explains how to search for the right documents, understand the structure of RFCs, and identify the most relevant information on the first page.&lt;/p&gt;
    &lt;p&gt;Some RFCs are informational or experimental, so you should be careful about which ones you read. For example, RFC 1149 literally describes a method for transmitting IP packets using pigeons! Its humorous follow-up, RFC 2549, improves on the idea. You can think of it like something out of a Harry Potter movie — sending messages via birds — but applied, jokingly, to the Internet:&lt;/p&gt;
    &lt;p&gt;RFC 1149: IP over Avian Carriers&lt;/p&gt;
    &lt;p&gt;Also, RFCs are archival documents, which means they cannot be updated once published. As a result, older RFCs may be obsolete or superseded by newer versions, and it’s important to ensure you are reading the correct, up-to-date document. The IETF article linked above explains how to identify the most relevant RFCs and determine which ones are current.&lt;/p&gt;
    &lt;p&gt;You can also check the references at the end of a Wikipedia article on a given topic, where several related RFCs are often listed for further reading.&lt;/p&gt;
    &lt;p&gt;When reading these documents, you might come across words like “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL”. These are not just casual suggestions — they have precise and standardized meanings in the context of RFCs. These terms are defined in RFC 2119, which provides guidance for specifying requirement levels in technical documents. Here’s a quick summary of what they mean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MUST / MUST NOT / REQUIRED / SHALL / SHALL NOT – Indicates an absolute requirement; the behavior described is mandatory.&lt;/item&gt;
      &lt;item&gt;SHOULD / SHOULD NOT / RECOMMENDED – Indicates a strong recommendation, but there may be valid reasons to deviate.&lt;/item&gt;
      &lt;item&gt;MAY / OPTIONAL – Indicates a truly optional behavior; implementers have complete discretion.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Understanding these words is crucial because RFCs use them to clearly communicate which rules are mandatory and which are flexible, ensuring interoperability and consistency across the Internet. If you plan to implement protocols, don’t skim RFCs or read them selectively. It’s easy to misinterpret a specification if you only look at part of it. You should read not just the sections that seem directly relevant to what you’re working on, but also any referenced material, to fully understand its requirements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;The early developers built much of the technology we rely on today without the Internet or Stack Overflow, relying purely on their skill, curiosity, and persistence. It’s easy to copy and paste something that works — but doing so only makes you one of many. The ones who truly understand are those who push limits and create what has never existed before.&lt;/p&gt;
    &lt;p&gt;Every protocol, every standard, every “MUST” or “SHOULD” is part of a story crafted by engineers over decades. So don’t be intimidated — explore, read carefully, and let these documents guide you. And if you ever discover a better idea or approach, share it with the world — perhaps even as an RFC. Who knows? The next specification you write could help shape the Internet of tomorrow.&lt;/p&gt;
    &lt;p&gt;I’ll end this post with a quote from one of my all-time favorite animated films, Ratatouille — a reminder that mastery comes from courage and curiosity:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“You must try things that may not work, and you must not let anyone define your limits because of where you come from. Your only limit is your soul. What I say is true — anyone can cook… but only the fearless can be great.”&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634678</guid><pubDate>Sun, 19 Oct 2025 15:03:29 +0000</pubDate></item><item><title>With deadline looming 4 of 9 universities reject Trumps pact to remake higher ed</title><link>https://arstechnica.com/culture/2025/10/with-deadline-looming-4-of-9-universities-reject-trumps-compact-to-remake-higher-ed/</link><description>&lt;doc fingerprint="75bd04b81781ce69"&gt;
  &lt;main&gt;
    &lt;p&gt;Earlier this month, the Trump administration made nine elite universities an offer they couldn’t refuse: bring in more conservatives while shutting down “institutional units that purposefully punish, belittle, and even spark violence against conservative ideas,” give up control of admissions and hiring decisions, agree to “biological” definitions of sex and gender, don’t raise tuition for five years, clamp down on student protests, and stay institutionally “neutral” on current events. Do this and you won’t be cut off from “federal benefits,” which could include research funding, student loans, federal contracts, and even student and faculty immigration visas. Instead, you may gain “substantial and meaningful federal grants.”&lt;/p&gt;
    &lt;p&gt;But the universities are refusing. With the initial deadline of October 20 approaching, four of the nine universities—the University of Pennsylvania, Brown, University of Southern California, and MIT—that received the federal “compact” have announced that they will not sign it.&lt;/p&gt;
    &lt;p&gt;In addition, the American Council on Education, which represents more than 1,600 colleges and universities, today issued a statement calling for the compact to be completely withdrawn.&lt;/p&gt;
    &lt;p&gt;The compact would “impose unprecedented litmus tests on colleges and universities as a condition for receiving ill-defined ‘federal benefits’ related to funding and grants,” the statement says, and goes on to add that “it offers nothing less than government control of a university’s basic and necessary freedoms—the freedoms to decide who we teach, what we teach, and who teaches… The compact is just the kind of excessive federal overreach and regulation, to the detriment of state and local input and control, that this administration says it is against.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634774</guid><pubDate>Sun, 19 Oct 2025 15:14:58 +0000</pubDate></item><item><title>The Zipper Is Getting Its First Major Upgrade in 100 Years</title><link>https://www.wired.com/story/the-zipper-is-getting-its-first-major-upgrade-in-100-years/</link><description>&lt;doc fingerprint="d348d1110ab8863f"&gt;
  &lt;main&gt;
    &lt;p&gt;For more than a century, the zipper has stayed more or less the same: two interlocking rows of teeth, a sliding pull, and the fabric tape that holds it together. It’s one of those inventions that conquered the world by blending into it. Billions are used every day, yet few people ever stop to think about how they work.&lt;/p&gt;
    &lt;p&gt;Now, after a hundred years of stasis, YKK, the Japanese company that makes roughly half the world’s zippers, has decided it’s time to rethink the mechanism that holds much of modern clothing together. Their new AiryString zipper looks ordinary at first glance. Then you realize what’s missing: there’s no tape.&lt;/p&gt;
    &lt;p&gt;That absence transforms everything. Without the woven fabric that normally flanks the teeth, the AiryString is lighter, sleeker, and far more flexible. It’s a small but important redesign that feels almost futuristic in its simplicity, a fastening system that sinks into a garment instead of sitting on top of it.&lt;/p&gt;
    &lt;p&gt;“We wanted to address the challenges involved in zipper sewing,” says Makoto Nishizaki, vice president of YKK’s Application Development Division. The idea grew out of a collaboration with JUKI Corporation, a leader in industrial sewing machines. Together, the two companies reconsidered how a zipper could be made and how it could merge more seamlessly with fabric. The partnership began in 2017 and made its public debut at the JIAM 2022 Osaka trade show—a detail that hints at how long YKK plays the long game.&lt;/p&gt;
    &lt;p&gt;If YKK’s name doesn’t ring a bell, check the pull tab on your jackets or pants, because you probably already wear their work. In 2023, the company had more than $6 billion in revenue. Founded in Japan in 1934, the company makes zippers for everyone from Prada and Arc’teryx to Patagonia and The North Face.&lt;/p&gt;
    &lt;p&gt;Its dominance comes from an unusual level of control: YKK manufactures its own machines, designs its own molds, and even spins its own thread. That self-sufficiency lets it experiment in ways competitors can’t, turning a mundane component into a field for continuous innovation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reinventing an Everyday Mechanism&lt;/head&gt;
    &lt;p&gt;The zipper, as we know it, hasn’t had a real overhaul since the 1910s. Its long reign owes much to reliability—it’s sturdy, inexpensive, and easy to sew. For most of the 20th century, that was enough. But materials have evolved. Designers now work with featherlight nylons, stretch fabrics, and technical blends that behave more like skin than cloth. The old zipper, with its woven borders and stiff seams, has started to feel out of sync with what surrounds it.&lt;/p&gt;
    &lt;p&gt;“There has been a growing demand from the market for lighter and more flexible garments,” Nishizaki says. “And similar expectations have extended to zippers.” However, removing the tape introduced a host of engineering problems. Those strips of fabric give a zipper its structure and provide the surface tailors sew through. Without them, YKK had to rethink every step of production.&lt;/p&gt;
    &lt;p&gt;The teeth were redesigned, the manufacturing process rewritten, and new machinery developed to attach the closure to garments. “The absence of the tape posed various production challenges,” Nishizaki says. “We had to develop new manufacturing equipment and a dedicated sewing machine for integration.” The result: a lighter, more flexible system that reduces material use and environmental impact compared with a standard Vislon zipper.&lt;/p&gt;
    &lt;p&gt;Early adopters are already experimenting. Descente Japan, known for technical sportswear, was among the first to prototype AiryString in 2022. The North Face has selected the system for use in its new Summit Series Advanced Mountain Kit. Smaller brands like Earthletica, an eco-conscious swim and performance label, have also tested it, describing the zipper as “soft, flexible, and almost silent.”&lt;/p&gt;
    &lt;p&gt;The effect is apparently tactile. Garments move more naturally, lie flatter against the body, and feel less mechanical. “We repeatedly conduct durability and strength tests by sewing AiryString and conventional zippers into various fabrics,” Nishizaki says. “In terms of usability, AiryString offers much smoother operability.” That translates to a softer, slicker glide—the satisfying pull that separates a well-made jacket from a cheap one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Little Parts, Big Change&lt;/head&gt;
    &lt;p&gt;On the factory floor, the benefits add up, too. Traditional zippers consume extra fabric and dye and require multiple sewing passes. By removing the tape, YKK says it trims both material and labor. “It contributes to reducing work in customers’ sewing processes,” Nishizaki says. “It also reduces fiber use and water consumption in the dyeing process, lowering CO₂ emissions.”&lt;/p&gt;
    &lt;p&gt;The math adds up fast. YKK offers a 100 percent recycled-material version of AiryString and claims measurable cuts to greenhouse gas emissions and water usage. The impact is magnified by scale: The company operates in 71 countries and regions, and its trademark is registered in 177. When you make billions of zippers a year, these small efficiencies ripple globally.&lt;/p&gt;
    &lt;p&gt;That incremental progress mirrors YKK’s founding philosophy, the “Cycle of Goodness.” The principle—that no one prospers without benefiting others—has supposedly guided the company for decades. It’s visible in its other micro-improvements: corrosion-resistant alloys, sound-dampened sliders, recyclable polyester tapes. AiryString continues that tradition, shrinking the zipper’s physical and environmental footprint at once.&lt;/p&gt;
    &lt;p&gt;Adoption, though, will take time. AiryString can fit into existing workflows, but to unlock its full potential, factories will apparently need specialized sewing equipment. That limits early use to design-led and performance-oriented brands, such as The North Face, willing to retool. Once those experiments prove successful, the technology could spread quickly, especially in an industry where efficiency drives everything from pricing to sustainability.&lt;/p&gt;
    &lt;p&gt;When asked what zippers might look like in 50 years, Nishizaki doesn’t talk about smart fabrics or AI-assisted closures. He returns to YKK’s mantra: “Little parts. Big difference.” AiryString embodies that principle. It’s not a flashy reinvention, it's a recalibration. A century-old mechanism made lighter, cleaner, and almost invisible. In a world addicted to louder, faster innovation, YKK’s breakthrough succeeds by subtracting rather than adding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634797</guid><pubDate>Sun, 19 Oct 2025 15:16:51 +0000</pubDate></item><item><title>The Spherical Cows of Programming</title><link>https://programmingsimplicity.substack.com/p/the-spherical-cows-of-programming</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45634811</guid><pubDate>Sun, 19 Oct 2025 15:18:58 +0000</pubDate></item></channel></rss>