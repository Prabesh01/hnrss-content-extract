<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Dec 2025 09:42:34 +0000</lastBuildDate><item><title>1D Conway's Life glider found, 3.7B cells long</title><link>https://conwaylife.com/forums/viewtopic.php?&amp;p=222136#p222136</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46137253</guid><pubDate>Wed, 03 Dec 2025 17:24:49 +0000</pubDate></item><item><title>Reverse engineering a $1B Legal AI tool exposed 100k+ confidential files</title><link>https://alexschapiro.com/security/vulnerability/2025/12/02/filevine-api-100k</link><description>&lt;doc fingerprint="3555f7864f2737d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Reverse Engineered a Billion-Dollar Legal AI Tool and Found 100k+ Confidential Files&lt;/head&gt;
    &lt;head rend="h2"&gt;Zero authentication, full admin access, and a privacy nightmare for lawyers.&lt;/head&gt;
    &lt;p&gt;Update: This post received a large amount of attention on Hacker News ‚Äî see the discussion thread.&lt;/p&gt;
    &lt;p&gt;Timeline &amp;amp; Responsible Disclosure&lt;/p&gt;
    &lt;p&gt;Initial Contact: Upon discovering this vulnerability on October 27, 2025, I immediately reached out to Filevine‚Äôs security team via email.&lt;/p&gt;
    &lt;p&gt;November 4, 2025: Filevine‚Äôs security team thanked me for the writeup and confirmed they would review the vulnerability and fix it quickly.&lt;/p&gt;
    &lt;p&gt;November 20, 2025: I followed up to confirm the patch was in place from my end, and informed them of my intention to write a technical blog post.&lt;/p&gt;
    &lt;p&gt;November 21, 2025: Filevine confirmed the issue was resolved and thanked me for responsibly reporting it.&lt;/p&gt;
    &lt;p&gt;Publication: December 3, 2025.&lt;/p&gt;
    &lt;p&gt;The Filevine team was responsive, professional, and took the findings seriously throughout the disclosure process. They acknowledged the severity, worked to remediate the issues, allowed responsible disclosure, and maintained clear communication. This is another great example of how organizations should handle security disclosures.&lt;/p&gt;
    &lt;p&gt;AI legal-tech companies are exploding in value, and Filevine, now valued at over a billion dollars, is one of the fastest-growing platforms in the space. Law firms feed tools like this enormous amounts of highly confidential information.&lt;/p&gt;
    &lt;p&gt;Because I‚Äôd recently been working with Yale Law School on a related project, I decided to take a closer look at how Filevine handles data security. What I discovered should concern every legal professional using AI systems today.&lt;/p&gt;
    &lt;p&gt;When I first navigated to the site to see how it worked, it seemed that I needed to be part of a law firm to actually play around with the tooling, or request an official demo. However, I know that companies often have a demo environment that is open, so I used a technique called subdomain enumeration (which I had first heard about in Gal Nagli‚Äôs article last year) to see if there was a demo environment. I found something much more interesting instead.&lt;/p&gt;
    &lt;p&gt;I saw a subdomain called margolis.filevine.com. When I navigated to that site, I was greeted with a loading page that never resolved:&lt;/p&gt;
    &lt;p&gt;I wanted to see what was actually loading, so I opened Chrome‚Äôs developer tools, but saw no Fetch/XHR requests (the request you often expect to see if a page is loading data). Then, I decided to dig through some of the Javascript files to see if I could figure out what was supposed to be happening. I saw a snippet in a JS file like &lt;code&gt;POST await fetch(${BOX_SERVICE}/recommend)&lt;/code&gt;. This piqued my interest ‚Äì recommend what? And what is the BOX_SERVICE? That variable was not defined in the JS file the fetch would be called from, but (after looking through minified code, which SUCKS to do) I found it in another one: ‚Äúdxxxxxx9.execute-api.us-west-2.amazonaws.com/prod‚Äù. Now I had a new endpoint to test, I just had to figure out the correct payload structure to it. After looking at more minified js to determine the correct structure for this endpoint, I was able to construct a working payload to /prod/recommend:&lt;/p&gt;
    &lt;code&gt;{"projectName":"Very sensitive Project"}
&lt;/code&gt;
    &lt;p&gt;(the name could be anything of course). No authorization tokens needed, and I was greeted with the response:&lt;/p&gt;
    &lt;p&gt;At first I didn‚Äôt entirely understand the impact of what I saw. No matter the name of the project I passed in, I was recommended the same boxFolders and couldn‚Äôt seem to access any files. Then, not realizing I stumbled upon something massive, I turned my attention to the &lt;code&gt;boxToken&lt;/code&gt; in the response.&lt;/p&gt;
    &lt;p&gt;After reading some documentation on the Box Api, I realized this was a maximum access fully scoped admin token to the entire Box filesystem (like an internal shared Google Drive) of this law firm. This includes all confidential files, logs, user information, etc. Once I was able to prove this had an impact (by searching for ‚Äúconfidential‚Äù and getting nearly 100k results back)&lt;/p&gt;
    &lt;p&gt;I immediately stopped testing and responsibly disclosed this to Filevine. They responded quickly and professionally and remediated this issue.&lt;/p&gt;
    &lt;p&gt;If someone had malicious intent, they would have been able to extract every single file used by Margolis lawyers ‚Äì countless data protected by HIPAA and other legal standards, internal memos/payrolls, literally millions of the most sensitive documents this law firm has in their possession. Documents protected by court orders! This could have been a real nightmare for both the law firm and the clients whose data would have been exposed.&lt;/p&gt;
    &lt;p&gt;To companies who feel pressure to rush into the AI craze in their industry ‚Äì be careful! Always ensure the companies you are giving your most sensitive information to secure that data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46137514</guid><pubDate>Wed, 03 Dec 2025 17:44:33 +0000</pubDate></item><item><title>Launch HN: Phind 3 (YC S22) ‚Äì Every answer is a mini-app</title><link>https://news.ycombinator.com/item?id=46137548</link><description>&lt;doc fingerprint="2c6a25dd25d976dd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi HN,&lt;/p&gt;
      &lt;p&gt;We are launching Phind 3 (https://www.phind.com), an AI answer engine that instantly builds a complete mini-app to answer and visualize your questions in an interactive way. A Phind mini-app appears as a beautiful, interactive webpage ‚Äî with images, charts, diagrams, maps, and other widgets. Phind 3 doesn‚Äôt just present information more beautifully; interacting with these widgets dynamically updates the content on the page and enables new functionality that wasn‚Äôt possible before.&lt;/p&gt;
      &lt;p&gt;For example, asking Phind for ‚Äúoptions for a one-bedroom apartment in the Lower East Side‚Äù (https://www.phind.com/search/find-me-options-for-a-72e019ce-...) gives an interactive apartment-finding experience with customizable filters and a map view. And asking for a ‚Äúrecipe for bone-in chicken thighs‚Äù gives you a customizable recipe where changing the seasoning, cooking method, and other parameters will update the recipe content itself in real-time (https://www.phind.com/search/make-me-an-recipe-for-7c30ea6c-...).&lt;/p&gt;
      &lt;p&gt;Unlike Phind 2 and ChatGPT apps, which use pre-built brittle widgets that can‚Äôt truly adapt to your task, Phind 3 is able to create tools and widgets for itself in real-time. We learned this lesson the hard way with our previous launch ‚Äì the pre-built widgets made the answers much prettier, but they didn‚Äôt fundamentally enable new functionality. For example, asking for ‚ÄúGive me round-trip flight options from JFK to SEA on Delta from December 1st-5th in both miles and cash‚Äù (https://www.phind.com/search/give-me-round-trip-flight-c0ebe...) is not something that neither Phind 2 nor ChatGPT apps can handle, because its Expedia widget can only display cash fares and not those with points. We realized that Phind needs to be able to create and consume its own tools, with schema it designs, all in real time. Phind 3‚Äôs ability to design and create fully custom widgets in real-time means that it can answer these questions while these other tools can‚Äôt. Phind 3 now generates raw React code and is able to create any tool to harness its underlying AI answer, search, and code execution capabilities.&lt;/p&gt;
      &lt;p&gt;Building on our history of helping developers solve complex technical questions, Phind 3 is able to answer and visualize developers‚Äô questions like never before. For example, asking to ‚Äúvisualize quicksort‚Äù (https://www.phind.com/search/make-me-a-beautiful-visualizati...) gives an interactive step-by-step walkthrough of how the algorithm works.&lt;/p&gt;
      &lt;p&gt;Phind 3 can help visualize and bring your ideas to life in seconds ‚Äî you can ask it to ‚Äúmake me a 3D Minecraft simulation‚Äù (https://www.phind.com/search/make-me-a-3d-minecraft-fde7033f...) or ‚Äúmake me a 3D roller coaster simulation‚Äù (https://www.phind.com/search/make-me-a-3d-roller-472647fc-e4...).&lt;/p&gt;
      &lt;p&gt;Our goal with Phind 3 is to usher in the era of on-demand software. You shouldn‚Äôt have to compromise by either settling for text-based AI conversations or using pre-built webpages that weren‚Äôt customized for you. With Phind 3, we create a ‚Äúpersonal internet‚Äù for you with the visualization and interactivity of the internet combined with the customization possible with AI. We think that this current ‚Äúchat‚Äù era of AI is akin to the era of text-only interfaces in computers. The Mac ushering in the GUI in 1984 didn‚Äôt just make computer outputs prettier ‚Äî it ushered in a whole new era of interactivity and possibilities. We aim to do that now with AI.&lt;/p&gt;
      &lt;p&gt;On a technical level, we are particularly excited about:&lt;/p&gt;
      &lt;p&gt;- Phind 3‚Äôs ability to create its own tools with its own custom schema and then consume them&lt;/p&gt;
      &lt;p&gt;- Significant improvements in agentic searching and a new deep research mode to surface hard-to-access information&lt;/p&gt;
      &lt;p&gt;- All-new custom Phind models that blend speed and quality. The new Phind Fast model is based on GLM-4.5-Air while the new Phind Large model is based on GLM 4.6. Both models are state-of-the-art when it comes to reliable code generation, producing over 70% fewer errors than GPT-5.1-Codex (high) on our internal mini-app generation benchmark. Furthermore, we trained custom Eagle3 heads for both Phind Fast and Phind Large for fast inference. Phind Fast runs at up to 300 tokens per second, and Phind Large runs at up to 200 tokens per second, making them the fastest Phind models ever.&lt;/p&gt;
      &lt;p&gt;While we have done Show HNs before for previous Phind versions, we‚Äôve never actually done a proper Launch HN for Phind. As always, we can‚Äôt wait to hear your feedback! We are also hiring, so please don‚Äôt hesitate to reach out.&lt;/p&gt;
      &lt;p&gt;‚Äì Michael&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46137548</guid><pubDate>Wed, 03 Dec 2025 17:47:15 +0000</pubDate></item><item><title>Micron Announces Exit from Crucial Consumer Business</title><link>https://investors.micron.com/news-releases/news-release-details/micron-announces-exit-crucial-consumer-business</link><description>&lt;doc fingerprint="c9a9907d4cbbb1ea"&gt;
  &lt;main&gt;
    &lt;p&gt;BOISE, Idaho, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Micron Technology, Inc. (Nasdaq: MU), a leader in innovative memory and storage solutions, today announced its decision to exit the Crucial consumer business, including the sale of Crucial consumer-branded products at key retailers, e-tailers and distributors worldwide.&lt;/p&gt;
    &lt;p&gt;Micron will continue Crucial consumer product shipments through the consumer channel until the end of fiscal Q2 (February 2026). The company will work closely with partners and customers through this transition and will provide continued warranty service and support for Crucial products. Micron will continue to support the sale of Micron-branded enterprise products to commercial channel customers globally.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe AI-driven growth in the data center has led to a surge in demand for memory and storage. Micron has made the difficult decision to exit the Crucial consumer business in order to improve supply and support for our larger, strategic customers in faster-growing segments,‚Äù said Sumit Sadana, EVP and Chief Business Officer at Micron Technology. ‚ÄúThanks to a passionate community of consumers, the Crucial brand has become synonymous with technical leadership, quality and reliability of leading-edge memory and storage products. We would like to thank our millions of customers, hundreds of partners and all of the Micron team members who have supported the Crucial journey for the last 29 years.‚Äù&lt;/p&gt;
    &lt;p&gt;This decision reflects Micron‚Äôs commitment to its ongoing portfolio transformation and the resulting alignment of its business to secular, profitable growth vectors in memory and storage. By concentrating on core enterprise and commercial segments, Micron aims to improve long-term business performance and create value for strategic customers as well as stakeholders.&lt;/p&gt;
    &lt;p&gt;Micron intends to reduce impact on team members due to this business decision through redeployment opportunities into existing open positions within the company.&lt;/p&gt;
    &lt;p&gt;About Micron Technology, Inc.&lt;/p&gt;
    &lt;p&gt;Micron Technology, Inc. is an industry leader in innovative memory and storage solutions, transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence (AI) and compute-intensive applications that unleash opportunities ‚Äî from the data center to the intelligent edge and across the client and mobile user experience. To learn more about Micron Technology, Inc. (Nasdaq: MU), visit micron.com.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;/p&gt;
    &lt;p&gt;This press release contains forward-looking statements, including statements regarding product supply and support, areas of growth and profitability, and workforce redeployment. These forward-looking statements are subject to a number of risks and uncertainties that could cause actual results to differ materially. Please refer to the documents Micron files with the Securities and Exchange Commission, specifically its most recent Form 10-K and Form 10-Q. These documents contain and identify important factors that could cause actual results to differ materially from those contained in these forward-looking statements. These certain factors can be found at https://investors.micron.com/risk-factor. Although Micron believes that the expectations reflected in the forward-looking statements are reasonable, Micron cannot guarantee future results, levels of activity, or achievements. Micron is under no duty to update any of the forward-looking statements after the date of this press release to conform these statements to actual results.&lt;/p&gt;
    &lt;p&gt;¬© 2025 Micron Technology, Inc. All rights reserved. Information, products, and/or specifications are subject to change without notice. Micron, the Micron logo, and all other Micron trademarks are the property of Micron Technology, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;
    &lt;p&gt;Micron Media Relations Contact&lt;lb/&gt;Mark Plungy&lt;lb/&gt;+1 (408) 203-2910&lt;lb/&gt;corpcomms@micron.com &lt;lb/&gt;Micron Investor Relations Contact&lt;lb/&gt;Satya Kumar&lt;lb/&gt;+1 (408) 450-6199&lt;lb/&gt;satyakumar@micron.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46137783</guid><pubDate>Wed, 03 Dec 2025 18:04:32 +0000</pubDate></item><item><title>Ghostty is now non-profit</title><link>https://mitchellh.com/writing/ghostty-non-profit</link><description>&lt;doc fingerprint="af5a505b2f305666"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Ghostty Is Now Non-Profit&lt;/head&gt;
    &lt;p&gt;Ghostty is now fiscally sponsored by Hack Club, a registered 501(c)(3) non-profit.&lt;/p&gt;
    &lt;p&gt;Fiscal sponsorship is a legal and financial arrangement in which a recognized non-profit extends its tax-exempt status to a project that aligns with its mission. This allows Ghostty to operate as a charitable initiative while Hack Club manages compliance, donations, accounting, and governance oversight.&lt;/p&gt;
    &lt;p&gt;Being non-profit clearly demonstrates our commitment to keeping Ghostty free and open source for everyone. It paves the way for a model for sustainable development beyond my personal involvement. And it also provides important legal protections and assurances to the people and communities that adopt and use Ghostty.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why a Non-Profit?&lt;/head&gt;
    &lt;p&gt;Since the beginning of the project in 2023 and the private beta days of Ghostty, I've repeatedly expressed my intention that Ghostty legally become a non-profit. This intention stems from several core beliefs I have.&lt;/p&gt;
    &lt;p&gt;First, I want to lay bricks for a sustainable future for Ghostty that doesn't depend on my personal involvement technically or financially. Financially, I am still the largest donor to the project, and I intend to remain so, but a non-profit structure allows others to contribute financially without fear of misappropriation or misuse of funds (as protected by legal requirements and oversight from the fiscal sponsor).&lt;/p&gt;
    &lt;p&gt;Second, I want to squelch any possible concerns about a "rug pull". A non-profit structure provides enforceable assurances: the mission cannot be quietly changed, funds cannot be diverted to private benefit, and the project cannot be sold off or repurposed for commercial gain. The structure legally binds Ghostty to the public-benefit purpose it was created to serve.&lt;/p&gt;
    &lt;p&gt;Finally, despite being decades-old technology, terminals and terminal-related technologies remain foundational to modern computing and software infrastructure. They're often out of the limelight, but they're ever present on developer machines, embedded in IDEs, visible as read-only consoles for continuous integration and cloud services, and still one of the primary ways remote access is done on servers around the world.&lt;/p&gt;
    &lt;p&gt;I believe infrastructure of this kind should be stewarded by a mission-driven, non-commercial entity that prioritizes public benefit over private profit. That structure increases trust, encourages adoption, and creates the conditions for Ghostty to grow into a widely used and impactful piece of open-source infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This Means For Ghostty&lt;/head&gt;
    &lt;p&gt;From a technical perspective, nothing changes for Ghostty. Our technical goals for the project remain the same, the license (MIT) remains the same, and we continue our work towards better Ghostty GUI releases and libghostty.&lt;/p&gt;
    &lt;p&gt;Financially, Ghostty can now accept tax-deductible donations in the United States. This opens up new avenues for funding the project and sustaining development over the long term. Most immediately, I'm excited to begin compensating contributors, but I also intend to support upstream dependencies, fund community events, and pay for boring operational costs.&lt;/p&gt;
    &lt;p&gt;All our financial transactions will be transparent down to individual transactions for both inflows and outflows. You can view our public ledger at Ghostty's page on Hack Club Bank. At the time of writing, this is empty, but you'll soon see some initial funding from me and the beginning of paying for some of our operational costs.&lt;/p&gt;
    &lt;p&gt;All applicable names, marks, and intellectual property associated with Ghostty have been transferred to Hack Club and are now owned under the non-profit umbrella. Copyright continues to be held by individual contributors under the continued and existing license structure.&lt;/p&gt;
    &lt;p&gt;From a leadership perspective, I remain the project lead and final authority on all decisions, but as stated earlier, the creation of a non-profit structure lays the groundwork for an eventual future beyond this model.&lt;/p&gt;
    &lt;p&gt;Important note: no funds will be sent to me (Mitchell Hashimoto) or used in any way that personally benefits me. Since I'm both the largest donor and lead of this project, this is a legally guaranteed protection. But also for altruistic reasons, all funds will be directed towards the needs of the project and its community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting Hack Club&lt;/head&gt;
    &lt;p&gt;As our fiscal sponsor, Hack Club provides essential services to Ghostty, including accounting, legal compliance, and governance oversight. To support this, 7% of all donations to Ghostty go to Hack Club to cover these costs in addition to supporting their broader mission of empowering young people around the world interested in technology and coding.&lt;/p&gt;
    &lt;p&gt;In the words of Zach Latta, Hack Club's founder and executive director this is a "good-for-good" trade. Instead of donor fees going to a for-profit management company or covering pure overhead of a single project, the fees go to another non-profit doing important work in the tech community and the overhead is amortized across many projects.&lt;/p&gt;
    &lt;p&gt;In addition to the 7% fees, my family is personally donating $150,000 directly to the Hack Club project1 (not to Ghostty within it). Hack Club does amazing work and I would've supported them regardless of their fiscal sponsorship of Ghostty, but I wanted to pair these two things together to amplify the impact of both.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donate&lt;/head&gt;
    &lt;p&gt;Please consider donating to support Ghostty's continued development.&lt;/p&gt;
    &lt;p&gt;I recognize that Ghostty is already in an abnormally fortunate position to have myself as a backer, but I do envision a future where Ghostty is more equally supported by a broader community. And with our new structure, you can be assured about the usage of your funds towards public-benefit goals.&lt;/p&gt;
    &lt;p&gt;This post isn't meant to directly be a fundraising pitch so it is purposely lacking critical details about our funding goals, budget, project goals, project metrics, etc. I'll work on those in the future. In the mean time, if you're interested in talking more about supporting Ghostty, please email me at m@mitchellh.com.&lt;/p&gt;
    &lt;head rend="h3"&gt;Support Ghostty&lt;/head&gt;
    &lt;p&gt;Your contribution helps sustain development and keeps Ghostty free and open source for everyone. Donations are tax-deductible in the United States.&lt;/p&gt;
    &lt;p&gt;Use the EIN above and specify ‚ÄúGhostty‚Äù as the recipient&lt;/p&gt;
    &lt;p&gt;Contact Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;Reach out to Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;7% of donations go to Hack Club to cover administrative costs and support their mission.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank You&lt;/head&gt;
    &lt;p&gt;I'm thankful for Hack Club and their team for working with us to make this happen. I'm also thankful for the Ghostty community who has supported this project and has trusted me and continues to trust me to steward it responsibly.&lt;/p&gt;
    &lt;p&gt;For more information about Ghostty's non-profit structure, see the dedicated page on Ghostty's website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;We haven't finalized the transfer of the funds yet, but it is initiated and will be completed in the coming weeks. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46138238</guid><pubDate>Wed, 03 Dec 2025 18:40:06 +0000</pubDate></item><item><title>Lie groups are crucial to some of the most fundamental theories in physics</title><link>https://www.quantamagazine.org/what-are-lie-groups-20251203/</link><description>&lt;doc fingerprint="e65190820f9d0f14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Are Lie Groups?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In mathematics, ubiquitous objects called groups display nearly magical powers. Though they‚Äôre defined by just a few rules, groups help illuminate an astonishing range of mysteries. They can tell you which polynomial equations are solvable, for instance, or how atoms are arranged in a crystal.&lt;/p&gt;
    &lt;p&gt;And yet, among all the different kinds of groups, one type stands out. Identified in the early 1870s, Lie groups (pronounced ‚ÄúLee‚Äù) are crucial to some of the most fundamental theories in physics, and they‚Äôve made lasting contributions to number theory and chemistry. The key to their success is the way they blend group theory, geometry and linear algebra.&lt;/p&gt;
    &lt;p&gt;In general, a group is a set of elements paired with an operation (like addition or multiplication) that combines two of those elements to produce a third. Often, you can think of a group as the symmetries of a shape ‚Äî the transformations that leave the shape unchanged.&lt;/p&gt;
    &lt;p&gt;Consider the symmetries of the equilateral triangle. They form a group of six elements, as shown here:&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;(Since a full rotation brings every point on the triangle back to where it started, mathematicians stop counting rotations past 360 degrees.)&lt;/p&gt;
    &lt;p&gt;These symmetries are discrete: They form a set of distinct transformations that have to be applied in separate, unconnected steps. But you can also study continuous symmetries. It doesn‚Äôt matter, for instance, if you spin a Frisbee 1.5 degrees, or 15 degrees, or 150 degrees ‚Äî you can rotate it by any real number, and it will appear the same. Unlike the triangle, it has infinitely many symmetries.&lt;/p&gt;
    &lt;p&gt;These rotations form a group called SO(2). ‚ÄúIf you have just a reflection, OK, you have it, and that‚Äôs good,‚Äù said Anton Alekseev, a mathematician at the University of Geneva. ‚ÄúBut that‚Äôs just one operation.‚Äù This group, on the other hand, ‚Äúis many, many operations in one package‚Äù ‚Äî uncountably many.&lt;/p&gt;
    &lt;p&gt;Each rotation of the Frisbee can be represented as a point in the coordinate plane. If you plot all possible rotations of the Frisbee in this way, you‚Äôll end up with infinitely many points that together form a circle.&lt;/p&gt;
    &lt;p&gt;This extra property is what makes SO(2) a Lie group ‚Äî it can be visualized as a smooth, continuous shape called a manifold. Other Lie groups might look like the surface of a doughnut, or a high-dimensional sphere, or something even stranger: The group of all rotations of a ball in space, known to mathematicians as SO(3), is a six-dimensional tangle of spheres and circles.&lt;/p&gt;
    &lt;p&gt;Whatever the specifics, the smooth geometry of Lie groups is the secret ingredient that elevates their status among groups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Off on a Tangent&lt;/head&gt;
    &lt;p&gt;It took time for Marius Sophus Lie to make his way to mathematics. Growing up in Norway in the 1850s, he hoped to pursue a military career once he finished secondary school. Instead, forced to abandon his dream due to poor eyesight, he ended up in university, unsure of what to study. He took courses in astronomy and mechanics, and flirted briefly with physics, botany and zoology before finally being drawn to math ‚Äî geometry in particular.&lt;/p&gt;
    &lt;p&gt;In the late 1860s, he continued his studies, first in Germany and then in France. He was in Paris in 1870 when the Franco-Prussian War broke out. He soon tried to leave the country, but his notes on geometry, written in German, were mistaken for encoded messages, and he was arrested, accused of being a spy. He was released from prison a month later and quickly returned to math.&lt;/p&gt;
    &lt;p&gt;In particular, he began working with groups. Forty years earlier, the mathematician √âvariste Galois had used one class of groups to understand the solutions to polynomial equations. Lie now wanted to do the same thing for so-called differential equations, which are used to model how a physical system changes over time.&lt;/p&gt;
    &lt;p&gt;His vision for differential equations didn‚Äôt work out as he‚Äôd hoped. But he soon realized that the groups he was studying were interesting in their own right. And so the Lie group was born.&lt;/p&gt;
    &lt;p&gt;The manifold nature of Lie groups has been an enormous boon to mathematicians. When they sit down to understand a Lie group, they can use all the tools of geometry and calculus ‚Äî something that‚Äôs not necessarily true for other kinds of groups. That‚Äôs because every manifold has a nice property: If you zoom in on a small enough region, its curves disappear, just as the spherical Earth appears flat to those of us walking on its surface.&lt;/p&gt;
    &lt;p&gt;To see why this is useful for studying groups, let‚Äôs go back to SO(2). Remember that SO(2) consists of all the rotations of a Frisbee, and that those rotations can be represented as points on a circle. For now, let‚Äôs focus on a sliver of the circle corresponding to very small rotations ‚Äî say, rotations of less than 1 degree.&lt;/p&gt;
    &lt;p&gt;Here, the curve of SO(2) is barely perceptible. When a Frisbee rotates 1 degree or less, any given point on its rim follows a nearly linear path. That means mathematicians can approximate these rotations with a straight line that touches the circle at just one point ‚Äî a tangent line. This tangent line is called the Lie algebra.&lt;/p&gt;
    &lt;p&gt;This feature is immensely useful. Math is a lot easier on a straight line than on a curve. And the Lie algebra contains elements of its own (often visualized as arrows called vectors) that mathematicians can use to simplify their calculations about the original group. ‚ÄúOne of the easiest kinds of mathematics in the world is linear algebra, and the theory of Lie groups is designed in such a way that it just makes constant use of linear algebra,‚Äù said David Vogan of the Massachusetts Institute of Technology.&lt;/p&gt;
    &lt;p&gt;Say you want to compare two different groups. Their respective Lie algebras simplify their key properties, Vogan said, making this task much more straightforward.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe interaction between these two structures,‚Äù Alessandra Iozzi, a mathematician at the Swiss Federal Institute of Technology Zurich, said of Lie groups and their algebras, ‚Äúis something that has an absolutely enormous array of consequences.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;The Language of Nature&lt;/head&gt;
    &lt;p&gt;The natural world is full of the kinds of continuous symmetries that Lie groups capture, making them indispensable in physics. Take gravity. The sun‚Äôs gravitational pull on the Earth depends only on the distance between them ‚Äî it doesn‚Äôt matter which side of the sun the Earth is on, for instance. In the language of Lie groups, then, gravity is ‚Äúsymmetric under SO(3).‚Äù It remains unchanged when the system it‚Äôs acting on rotates in three-dimensional space.&lt;/p&gt;
    &lt;p&gt;In fact, all the fundamental forces in physics ‚Äî gravity, electromagnetism, and the forces that hold together atomic nuclei ‚Äî are defined by Lie group symmetries. Using that definition, scientists can explain basic puzzles about matter, like why protons are always paired with neutrons, and why the energy of an atom comes in discrete quantities.&lt;/p&gt;
    &lt;p&gt;In 1918, Emmy Noether stunned mathematicians and physicists by proving that Lie groups also underlie some of the most basic laws of conservation in physics. She showed that for any symmetry in a physical system that can be described by a Lie group, there is a corresponding conservation law. For instance, the fact that the laws of physics are the same today as they were yesterday and will be tomorrow ‚Äî a symmetry known as time translation symmetry, represented by the Lie group consisting of the real numbers ‚Äî implies that the universe‚Äôs energy must be conserved, and vice versa. ‚ÄúI think, even now, it‚Äôs a very surprising result,‚Äù Alekseev said.&lt;/p&gt;
    &lt;p&gt;Today, Lie groups remain a vital tool for both mathematicians and physicists. ‚ÄúDefinitions live in mathematics because they‚Äôre powerful. Because there are a lot of interesting examples and they give you a good way to think about something,‚Äù Vogan said. ‚ÄúSymmetry is everywhere, and that‚Äôs what this stuff is for.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46138632</guid><pubDate>Wed, 03 Dec 2025 19:12:40 +0000</pubDate></item><item><title>Everyone in Seattle hates AI</title><link>https://jonready.com/blog/posts/everyone-in-seattle-hates-ai.html</link><description>&lt;doc fingerprint="73395114bff6ccdd"&gt;
  &lt;main&gt;
    &lt;p&gt;I grabbed lunch with a former Microsoft coworker I've always admired‚Äîone of those engineers who can take any idea, even a mediocre one, and immediately find the gold in it. I wanted her take on Wanderfugl üê¶, the AI-powered map I've been building full-time. I expected encouragement. At worst, overly generous feedback because she knows what I've sacrificed.&lt;/p&gt;
    &lt;p&gt;Instead, she reacted to it with a level of negativity I'd never seen her direct at me before.&lt;/p&gt;
    &lt;p&gt;When I finally got her to explain what was wrong, none of it had anything to do with what I built. She talked about Copilot 365. And Microsoft AI. And every miserable AI tool she's forced to use at work. My product barely featured. Her reaction wasn't about me at all. It was about her entire environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;The AI Layoffs&lt;/head&gt;
    &lt;p&gt;Her PM had been laid off months earlier. The team asked why. Their director told them it was because the PM org "wasn't effective enough at using Copilot 365."&lt;/p&gt;
    &lt;p&gt;I nervously laughed. This director got up in a group meeting and said that someone lost their job over this?&lt;/p&gt;
    &lt;p&gt;After a pause I tried to share how much better I've been feeling‚Äîhow AI tools helped me learn faster, how much they accelerated my work on Wanderfugl. I didn't fully grok how tone deaf I was being though. She's drowning in resentment.&lt;/p&gt;
    &lt;p&gt;I left the lunch deflated and weirdly guilty, like building an AI product made me part of the problem.&lt;/p&gt;
    &lt;p&gt;But then I realized this was bigger than one conversation. Every time I shared Wanderfugl with a Seattle engineer, I got the same reflexive, critical, negative response. This wasn't true in Bali, Tokyo, Paris, or San Francisco‚Äîpeople were curious, engaged, wanted to understand what I was building. But in Seattle? Instant hostility the moment they heard "AI."&lt;/p&gt;
    &lt;head rend="h2"&gt;The people at big tech in Seattle are not ok&lt;/head&gt;
    &lt;p&gt;When I joined Microsoft, there was still a sense of possibility. Satya was pushing "growth mindset" everywhere. Leaders talked about empowerment and breaking down silos. And even though there was always a gap between the slogans and reality, there was room to try things.&lt;/p&gt;
    &lt;p&gt;I leaned into it. I pushed into areas nobody wanted to touch, like Windows update compression, because it lived awkwardly across three teams. Somehow, a 40% improvement made it out alive. Leadership backed it. The people trying to kill it shrank back into their fiefdoms. It felt like the culture wanted change.&lt;/p&gt;
    &lt;p&gt;That world is gone.&lt;/p&gt;
    &lt;p&gt;When the layoff directive hit, every org braced for impact. Anything not strictly inside the org's charter was axed. I went from shipping a major improvement in Windows 11 to having zero projects overnight. I quit shortly after. In hindsight, getting laid off with severance might've been better than watching the culture collapse in slow motion.&lt;/p&gt;
    &lt;p&gt;Then came the AI panic.&lt;/p&gt;
    &lt;p&gt;If you could classify your project as "AI," you were safe and prestigious. If you couldn't, you were nobody. Overnight, most engineers got rebranded as "not AI talent." And then came the final insult: everyone was forced to use Microsoft's AI tools whether they worked or not.&lt;/p&gt;
    &lt;p&gt;Copilot for Word. Copilot for PowerPoint. Copilot for email. Copilot for code. Worse than the tools they replaced. Worse than competitors' tools. Sometimes worse than doing the work manually.&lt;/p&gt;
    &lt;p&gt;But you weren't allowed to fix them‚Äîthat was the AI org's turf. You were supposed to use them, fail to see productivity gains, and keep quiet.&lt;/p&gt;
    &lt;p&gt;Meanwhile, AI teams became a protected class. Everyone else saw comp stagnate, stock refreshers evaporate, and performance reviews tank. And if your team failed to meet expectations? Clearly you weren't "embracing AI."&lt;/p&gt;
    &lt;p&gt;Bring up AI in a Seattle coffee shop now and people react like you're advocating asbestos.&lt;/p&gt;
    &lt;p&gt;Amazon folks are slightly more insulated, but not by much. The old Seattle deal‚ÄîAmazon treats you poorly but pays you more‚Äîonly masks the rot.&lt;/p&gt;
    &lt;head rend="h2"&gt;Self-Limiting Beliefs&lt;/head&gt;
    &lt;p&gt;This belief system‚Äîthat AI is useless and that you're not good enough to work on it anyway‚Äîhurts three groups:&lt;/p&gt;
    &lt;p&gt; 1. The companies.&lt;lb/&gt; They've taught their best engineers that innovation isn't their job. &lt;/p&gt;
    &lt;p&gt; 2. The engineers.&lt;lb/&gt; They're stuck in resentment and self-doubt while their careers stall. &lt;/p&gt;
    &lt;p&gt; 3. Anyone trying to build anything new in Seattle.&lt;lb/&gt; Say "AI" and people treat you like a threat or an idiot. &lt;/p&gt;
    &lt;p&gt; And the loop feeds itself:&lt;lb/&gt; Engineers don't try because they think they can't.&lt;lb/&gt; Companies don't empower them because they assume they shouldn't.&lt;lb/&gt; Bad products reinforce the belief that AI is doomed.&lt;lb/&gt; The spiral locks in. &lt;/p&gt;
    &lt;p&gt;My former coworker‚Äîthe composite of three people for anonymity‚Äînow believes she's both unqualified for AI work and that AI isn't worth doing anyway. She's wrong on both counts, but the culture made sure she'd land there.&lt;/p&gt;
    &lt;p&gt;Seattle has talent as good as anywhere. But in San Francisco, people still believe they can change the world‚Äîso sometimes they actually do.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46138952</guid><pubDate>Wed, 03 Dec 2025 19:37:25 +0000</pubDate></item><item><title>Show HN: I built a dashboard to compare mortgage rates across 120 credit unions</title><link>https://finfam.app/blog/credit-union-mortgages</link><description>&lt;doc fingerprint="3c94a31214402b4c"&gt;
  &lt;main&gt;&lt;p&gt;Buying a home or refinancing a mortgage is tough enough without confusing ads from banks and big lenders. Credit unions can offer competitive rates compared to big banks because they√¢re member-owned, non-profit institutions. They focus on serving their members, not maximizing profits for shareholders.&lt;/p&gt;&lt;p&gt;But without big budgets and marketing departments, credit union rates aren√¢t always easy to find or compare. That√¢s why we built a daily-updated comparison of mortgage rates from over 120 credit unions across the United States.&lt;/p&gt;&lt;head rend="h2"&gt;Credit Union Mortgage Rates&lt;/head&gt;&lt;p&gt;Last updated: December 3, 2025&lt;/p&gt;&lt;head rend="h3"&gt;30-Year Fixed&lt;/head&gt;Updating...&lt;p&gt;Loading rate comparison table...&lt;/p&gt;&lt;p&gt;Note: These rates are informational and not a commitment to lend. FinFam has no institutional affiliation and does not receive any referral fees.&lt;/p&gt;&lt;head rend="h2"&gt;Why build this dashboard?&lt;/head&gt;&lt;p&gt;When we bought our home, the big bank I√¢d been using for years tried to sell me on a mortgage with 7% APR. Turns out a local credit union was offering 5.5% for the exact same mortgage.&lt;/p&gt;&lt;p&gt;What surprised me most wasn√¢t that there were cheaper options, but that two mortgages can be exactly the same product, just with different packaging.&lt;/p&gt;&lt;p&gt;In the USA, the government buys almost all mortgages, requiring them to be standardized. So why the price difference? As explored in this Bloomberg Odd Lots episode about credit card rates, higher rates are mostly to pay for advertising and marketing. Big banks have marketing departments that non-profit credit unions don√¢t have.&lt;/p&gt;&lt;p&gt;That √¢exclusive√¢ inbox offer from Chase or Wells Fargo isn√¢t generosity. It√¢s a bet that you won√¢t shop around. My goal with this tool is simple: help people realize they have options and potentially save thousands of dollars a year.&lt;/p&gt;&lt;head rend="h2"&gt;How the dashboard works&lt;/head&gt;&lt;p&gt;It√¢s a little involved! √∞&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Rates are collected throughout the day from the websites of approximately 120 credit unions.&lt;/item&gt;&lt;item&gt;National benchmarks come from the St. Louis Federal Reserve Bank, aka FRED: 30-Year Fixed benchmark (15Y). These update weekly.&lt;/item&gt;&lt;item&gt;Credit union eligibility data is manually curated from individual institution websites.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Some rates (around a dozen) are hidden by default because they√¢re statistical outliers: likely errors or ultra-specialized products. Toggle √¢Show outliers√¢ in the filters if you want to see them anyway.&lt;/p&gt;&lt;p&gt;Found an error? Email blog@finfam.app.&lt;/p&gt;&lt;head rend="h2"&gt;Next Steps: Make Decisions, Get Quotes&lt;/head&gt;&lt;p&gt;Our dashboard can only take you so far. Your actual rate depends on: credit score, down payment (20%+ is ideal), property type (primary residence gets best rates), and whether you pay points for a lower rate (always compare APR).&lt;/p&gt;&lt;p&gt;Next step: Get quotes from multiple lenders by using the rate table above to contact institutions.&lt;/p&gt;&lt;p&gt;Protip: Before submitting to any credit checks, protect your privacy with optoutprescreen.com, another free and regulated service I wish I√¢d known about sooner.&lt;/p&gt;&lt;p&gt;Still not sure about buying or refinancing? Check out these interactive guides:&lt;/p&gt;&lt;p&gt;FinFam is built around collaborative financial planning, including community-authored, spreadsheet-powered guides, like those above. Read more in our docs.&lt;/p&gt;&lt;head rend="h2"&gt;Questions or Feedback?&lt;/head&gt;&lt;p&gt;Have questions about these rates or suggestions for improving this tool? Reach out to us at blog@finfam.app.&lt;/p&gt;&lt;p&gt;Don√¢t see your favorite CU here? As long as it has a website with a public rates page and clear eligibility requirements, we√¢d be happy to add it!&lt;/p&gt;&lt;head rend="h3"&gt;Disclaimers&lt;/head&gt;&lt;p&gt;These rates are informational only and don√¢t represent rate locks. Your actual rate will vary. Contact lenders with the links in the rate table to get your personalized quotes. FinFam has no institutional affiliation and receives no referral fees, nor provides any guarantees.&lt;/p&gt;&lt;p&gt;Shoutout /r/dataisbeautiful for the encouragement. And big thanks to Asheesh Laroia for his guidance on the matter of mortgages. See his spreadsheet-friendly take on the data.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46139761</guid><pubDate>Wed, 03 Dec 2025 20:35:27 +0000</pubDate></item><item><title>8086 Microcode Browser</title><link>https://nand2mario.github.io/posts/2025/8086_microcode_browser/</link><description>&lt;doc fingerprint="3f1bc214a171d033"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;8086 Microcode Browser&lt;/head&gt;
    &lt;p&gt;Since releasing 486Tang, I‚Äôve been working on recreating the 8086 with a design that stays as faithful as possible to the original chip. That exploration naturally led me deep into the original 8086 microcode ‚Äî extracted and disassembled by Andrew Jenner in 2020.&lt;/p&gt;
    &lt;p&gt;Like all microcoded CPUs, the 8086 hides a lot of subtle behavior below the assembly layer. While studying it I kept extensive notes, and those eventually evolved into something more useful: an interactive browser for the entire 8086 microcode ROM.&lt;/p&gt;
    &lt;p&gt;So here it is: the online 8086 microcode browser. Every 21-bit micro-instruction is decoded into readable fields. Hover over any field and you‚Äôll get a tooltip explaining what it does. All jump targets are clickable ‚Äî the 8086 Œºcode uses a surprising number of indirect jumps, calls, and short branches.&lt;/p&gt;
    &lt;p&gt;One handy feature is Browse by Instruction. Click the button and you‚Äôll get a list of ~300 documented 8086 instructions. Select any one, and the viewer jumps directly to its Œºcode entry point. Internally there are only about 60 unique Œºcode entry routines, and this feature makes navigating them effortless.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few fun tidbits about 8086 Œºcode&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Register IDs change meaning depending on context. For example,&lt;/p&gt;&lt;code&gt;10100&lt;/code&gt;refers to SIGMA (the ALU result) when used as a source, but to tmpaL (the low 8 bits of a temporary ALU register) when used as a destination.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;N and R are the same physical register. Meanwhile, SI is called IJ internally ‚Äî naming inside the chip is extremely inconsistent and reflects its evolutionary design process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IP (PC) does not point to the next instruction. It actually points to the next prefetch address. The Œºcode uses a dedicated micro-operation called CORR to rewind IP back to the true next-instruction boundary when handling branches and interrupts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Almost all arithmetic instructions share the same 4 Œºinstructions (&lt;/p&gt;&lt;code&gt;008‚Äì00B&lt;/code&gt;). The heavy lifting is done by a single micro-operation named XI, which performs different arithmetic behaviors depending on opcode or ModRM bits. The amount of reuse here is elegant ‚Äî and very 1978 Intel.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46140244</guid><pubDate>Wed, 03 Dec 2025 21:16:11 +0000</pubDate></item><item><title>Acme, a brief history of one of the protocols which has changed the Internet</title><link>https://blog.brocas.org/2025/12/01/ACME-a-brief-history-of-one-of-the-protocols-which-has-changed-the-Internet-Security/</link><description>&lt;doc fingerprint="6d19b1920b220c9d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;ACME, a brief history of one of the protocols which has changed the Internet Security&lt;/head&gt;
    &lt;head rend="h3"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;I would like to share with you this article I wrote about the ACME protocol, which I ‚Äúfell in love with‚Äù about ten years ago. It is for me a way to give back to this fantastic Free Software and Open Protocols developers community.&lt;/p&gt;
    &lt;p&gt;This article is about the roots, the conception, the standardization, the relation with its ecosystem and the evolution challenges faced by the ACME protocol.&lt;/p&gt;
    &lt;p&gt;To write this article, I had the privilege of interviewing several people who have been involved in the creation and the evolution of ACME: Aaron Gable, Sarah Gran, Jacob Hoffman-Andrews and J.C. Jones (more below).&lt;/p&gt;
    &lt;p&gt;Thank you so much to all of you for your time and support! √∞&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet and Network Protocols&lt;/head&gt;
    &lt;head rend="h3"&gt;Open and Standardized Protocols at the Heart of the Internet√¢s Success&lt;/head&gt;
    &lt;p&gt;During the 1990s, computing underwent a true revolution driven by the rise and global spread of the Internet. The Internet fulfilled the promise embodied in Sun Microsystems√¢ slogan ‚ÄúThe Network is the Computer‚Äù.&lt;/p&gt;
    &lt;p&gt;By interconnecting individual computers, the Internet enabled its users to communicate without limits and without worrying about borders.&lt;/p&gt;
    &lt;p&gt;This unrestricted interconnection emerged at a pivotal moment in modern history: the opposition between the West and the Eastern Bloc led by the USSR had√¢albeit temporarily, as we now know√¢faded away, China was becoming the world√¢s factory, and the movement and collaboration between people were much freer and open than ever.&lt;/p&gt;
    &lt;p&gt;The Internet supported a kind of utopia of instant communication and sharing, previously unknown. This utopia was made possible by a set of open and standardized protocols. This was the key to enabling all kinds of different systems to cooperate and communicate seamlessly.&lt;/p&gt;
    &lt;p&gt;There were, of course, isolationist or monopolistic temptations from certain manufacturers or software editors. But open and standardized protocols ultimately prevailed, enabling unprecedented expansion. Built on top of IP, TCP, UDP, and DNS, among others, the HTTP and HTML duo would propel the Web as the Internet√¢s preferred communication platform for the next 30 years.&lt;/p&gt;
    &lt;head rend="h3"&gt;Limited Use of Encryption&lt;/head&gt;
    &lt;p&gt;The success of this communication utopia was achieved without much concern for ensuring authentication, integrity, and confidentiality of exchanges.&lt;/p&gt;
    &lt;p&gt;In 2015, only ~40% of websites used encryption. The consequences of this negligence in addressing security risks were confirmed by Edward Snowden√¢s revelations in 2013: our data was exposed to anyone who wanted and could intercept and collect it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let‚Äôs Encrypt is coming&lt;/head&gt;
    &lt;head rend="h3"&gt;The Birth of an Automated and Free Certificate Authority&lt;/head&gt;
    &lt;p&gt;When asked about the main obstacles to the widespread adoption of encryption, J.C. Jones, one of the architects of Let√¢s Encrypt and now one of its site reliability engineers after leading Firefox√¢s cryptographic team, responds:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúMore and more information was flowing across the Web, and most data being transferred did not have integrity or confidential protections from TLS. The biggest stumbling block to using TLS everywhere was obtaining and managing server-side certificates, and so: Let√¢s Encrypt‚Äù ‚Äì J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Obtaining a certificate was the main obstacle, and this was the priority to address.&lt;/p&gt;
    &lt;p&gt;This view was shared by a group of partners who, starting in 2013, pooled resources to establish Let√¢s Encrypt, an automated and free certificate authority. Sarah Gran, VP of Advancement at Let√¢s Encrypt, shares:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúEarly collaborators included people from Mozilla, Electronic Frontier Foundation, Akamai, Cisco, and the University of Michigan‚Äù ‚Äì Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that‚Äôs how Let‚Äôs Encrypt was born.&lt;/p&gt;
    &lt;p&gt;In the Web ecosystem, certificate authorities are organizations from which you can obtain a certificate for a domain after proving you control it.&lt;/p&gt;
    &lt;p&gt;And so, Let‚Äôs Encrypt is since 2015 a certificate authority that delivers for free (as in free beer) TLS Server certificates.&lt;/p&gt;
    &lt;p&gt;On the legal/administrative side, Let‚Äôs Encrypt certificate authority operates for the public√¢s benefit and is a service provided by the Internet Security Research Group (ISRG), a California public benefit corporation.&lt;/p&gt;
    &lt;p&gt;Regarding Let‚Äôs Encrypt results ten years after its birth, they are really impressive (over 700M active certificates, over 60% of all the public TLS server certificates) and as Sarah Gran points out, so is the global HTTPS usage:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWhen we started issuance, only about 39% of website visits were HTTPS. Today, it√¢s nearly 95% in the United States, and over 83% globally. We still have work to do, but we are proud of the progress we√¢ve made over the last ten years‚Äù ‚Äì Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let‚Äôs Encrypt delivers certificates in a automated manner using the ACME protocol which implies no manual action from the site owner nor the certificate authority. So, let‚Äôs speak now a little about the automation aspect!&lt;/p&gt;
    &lt;head rend="h3"&gt;Automation: The Core of the Operation&lt;/head&gt;
    &lt;p&gt;From the mid-2020s perspective, the automation at the heart of Let√¢s Encrypt might seem obvious, but in the first half of the 2010s, it was far from the norm. The ecosystem of public certificate authorities issuing server certificates was no exception.&lt;/p&gt;
    &lt;p&gt;At first glance, automation appears to be there to help website managers reliably deploy the TLS protocol on their sites, but it was first and foremost an absolute prerequisite for the very viability of the Let‚Äôs Encrypt project.&lt;/p&gt;
    &lt;p&gt;As Aaron Gable, tech lead of Boulder√¢the software at the core of Let√¢s Encrypt√¢, confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúAutomation was always going to be critical to Let√¢s Encrypt√¢s success. From the very beginning, we knew that there was no way we could scale manual validation on a non-profit√¢s budget‚Äù ‚Äì Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Indeed, it is worth noting that Let√¢s Encrypt has operated on an Internet scale from the start with a small team of about fifteen engineers, or even fewer at launch. For this team, automation was the only viable way to fulfill the immense mission they had set for themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACME&lt;/head&gt;
    &lt;head rend="h3"&gt;The Open and automated Protocol That Powers Let√¢s Encrypt&lt;/head&gt;
    &lt;p&gt;When we talk about automation in relation to Let√¢s Encrypt, we are talking about ACME (Automated Certificate Management Environment).&lt;/p&gt;
    &lt;p&gt;This protocol allows client software to prove to an ACME-compatible certificate authority that it controls the domain for which it is requesting a certificate.&lt;/p&gt;
    &lt;p&gt;Sarah Gran clarifies an important point:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúAn important aspect of how Let√¢s Encrypt works is that we verify control over a domain, not ownership‚Äù ‚Äì Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Control vs. ownership of a domain√¢a nuance everyone should keep in mind.&lt;/p&gt;
    &lt;p&gt;This proof of control involves the client responding to a challenge issued by the ACME-compatible certificate authority. The challenge can be an HTTP, DNS, or TLS challenge, depending on the client√¢s choice and certificate authority support. Completing the challenge requires the ACME client to place a value provided by the ACME server√¢in a standardized HTTP path, a DNS zone, or a TLS response, respectively. All of these operations involve cryptography, of course.&lt;/p&gt;
    &lt;p&gt;The key point with ACME is that this entire dialogue between the client and the ACME server is executed without any human intervention, enabling the automatic issuance of certificates. Their deployment and integration into the web service can also generally be automated using scripts triggered after issuance.&lt;/p&gt;
    &lt;p&gt;On the Let‚Äôs Encrypt website, you can discover more information about how ACME works and get more detailled information about it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Birth of ACME&lt;/head&gt;
    &lt;p&gt;One might wonder whether ACME was part of Let√¢s Encrypt√¢s design from the beginning.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúBy late 2014, the idea of an HTTP REST API with ‚Äú/challenge‚Äù and ‚Äú/certificate‚Äù existed, but we hadn√¢t defined much beyond that. We had a series of in-person meetings, in the Mozilla San Francisco office on Embarcadero and the EFF office in the Tenderloin through the spring of 2015 where we worked out the details‚Äù ‚Äì J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;ACME was indeed at the core of Let√¢s Encrypt from the start and underwent a refinement process to cover all use cases as thoroughly as possible.&lt;/p&gt;
    &lt;p&gt;To learn more about the roots of ACME and Let‚Äôs Encrypt, there is a very informative document to read: the Let‚Äôs Encrypt paper for ACM CCS 2019 in London. It mentions the previous work of two teams:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúA group led by Alex Halderman at the University of Michigan and Peter Eckersley at EFF was developing a protocol for automatically issuing and renewing certificates. Simultaneously, a team at Mozilla led by Josh Aas and Eric Rescorla was working on creating a free and automated certificate authority‚Äù.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When these two teams discovered each other‚Äôs work, they joined forces. ACME and its implementation in Let‚Äôs Encrypt were the result of this joint effort supported by the initial partners mentioned above.&lt;/p&gt;
    &lt;head rend="h3"&gt;Securing the Web or the Internet?&lt;/head&gt;
    &lt;p&gt;Speaking of use cases, one might wonder whether the Web was Let√¢s Encrypt√¢s primary target, or if securing the Internet with its multiple protocols was also part of the objectives.&lt;/p&gt;
    &lt;p&gt;Sarah Gran provides an unambiguous first-level answer:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúFrom Day One, we have sought to get the web to 100% encryption‚Äù ‚Äì Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But when asked about the various types of challenges in the protocol, J.C. Jones offers a nuance:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúDNS, TLS-SNI, and HTTP were all in planning in spring 2015, but many of us were less confident in the procedure around the DNS validation. Which is ironic, as it turned out TLS-SNI had a vulnerability so we had to stop using it and our DNS validation was ultimately fine. In general, the collection of us were simply respectful of the great complexity within the DNS‚Äù ‚Äì J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a perspective not often publicly expressed by engineers primarily from the Web: their lack of confidence in implementing a DNS challenge stemmed from their humility regarding the complexity of the DNS ecosystem and the level of expertise required to master it.&lt;/p&gt;
    &lt;p&gt;The challenge was ultimately met, and this DNS challenge√¢though not its primary purpose√¢enabled multiple protocols outside HTTP like SMTP to be secured by ACME.&lt;/p&gt;
    &lt;head rend="h2"&gt;Standardization and Open Source&lt;/head&gt;
    &lt;head rend="h3"&gt;Developed in the Open&lt;/head&gt;
    &lt;p&gt;ACME was documented openly from the start, and Certbot, the first open-source ACME client co-developed with the EFF, served as the client side reference implementation.&lt;/p&gt;
    &lt;p&gt;Similarly, a standardization process through the IETF resulted in RFC 8555 in March, 2019.&lt;/p&gt;
    &lt;p&gt;One of the consequences developing an open and standardized protocol was the creation of a multitude of ACME clients covering a very wide range of use cases.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms that this was the goal:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúThis is what we foresaw, or at least hoped for. The initial client development often had conversations like, √¢oh, if someone wants that, then they√¢ll write their own client.√¢ It was a key part of why the REST API needed to be an IETF standard, and was part of the argument at the IETF BoF that resulted in the formation of the ACME Working Group in Q3 2015‚Äù ‚Äì J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let√¢s Encrypt has also always provided constant support to developers by responding in its forum or on its GitHub issue tracker, and all this work has truly paid off. An interesting post has been recently written about support on the Let‚Äôs Encrypt blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;Standardization for what benefits?&lt;/head&gt;
    &lt;p&gt;The other question that can be asked is whether or not the standardization process within the IETF has led to an improvement in the ACME protocol thanks to the cooperation that guides this process.&lt;/p&gt;
    &lt;p&gt;Jacob Hoffman-Andrews, one of the RFC 8555 authors working for EFF &amp;amp; Let‚Äôs Encrypt, confirms an initial benefit that the ACME protocol has been able to derive from its standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúOne of the big changes was from a validation-first flow to a certificate-request-first flow. In other words, earlier drafts had subscribers requesting validation for domain names and then requesting a certificate once those validations were successful. The final RFC has subscribers request a certificate, and then the CA tells the subscriber what validations are needed. This change originated from within the IETF discussion process, and was intended to make handling of wildcard certificates more natural.‚Äù ‚Äì Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Aside this first design improvement, Jacob details a second major improvement of the security of the protocol, improvement that also landed during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúAnother big change, also originated from within the IETF, was to make all requests authenticated, including GET requests. Since ACME is authenticated with signed POSTs, this necessitated the POST-as-GET concept that√¢s in ACME today‚Äù ‚Äì Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can see there how IETF iterations can challenge the security of a protocol and leads its development to innovative solutions to tackle the challenges it faces!&lt;/p&gt;
    &lt;p&gt;Last, Jacob adds another information that illustrates the benefits of developing a protocol into the open: it allows the community to evaluate (and sometimes, fix) its security level due to the availability of all materials and often, of the reference implementation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúAnother very important evolution was the deprecation of the tls-sni-01 challenge method. This was found to be flawed by Frans Rosen, a security researcher. It was replaced with TLS-ALPN-01, developed at IETF with significant input from Google‚Äù ‚Äì Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Let√¢s Encrypt, ACME, and the Public Certificate Authorities Ecosystem&lt;/head&gt;
    &lt;p&gt;In 2015, the arrival of Let√¢s Encrypt in the public certificate authorities ecosystem raised a number of questions.&lt;/p&gt;
    &lt;p&gt;What level of cooperation or hostility? What impact on the viability of existing certificate authorities?&lt;/p&gt;
    &lt;p&gt;Here again, the fact that Let√¢s Encrypt was based on an open protocol, immediately subject to an IETF standardization initiative, enabled collaboration and adoption by the most innovative certificate authorities.&lt;/p&gt;
    &lt;p&gt;I spoke about the External Account Binding (EAB) option of the protocol with J.C. Jones. EAB is a way for an ACME client to authenticate to an ACME server using an identifier and a key value which are verifiable by the server in a repository it maintains. With EAB, an ACME server can filter who can uses its service which is useful for commercial certificate authorities for example; it is an alternative model to Let‚Äôs Encrypt one where anybody can ask for a certificate.&lt;/p&gt;
    &lt;p&gt;Using the example of EAB, J.C. Jones confirms the collaboration with certificate authorities that happens during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúEAB was an early addition at the IETF ACME Working Group. Many in the room were worried that without a means to bind to a payment method, ACME would not get adoption. In fact, some of the counterarguments to forming ACME were blunted by EAB, as such a mechanism wasn√¢t in the theoretically-competing, already-existent standard: SCEP. SCEP, it was argued, already handled ‚Äòfree‚Äô certificate issuance, for private certificate authorities. Anything else needed a feasible path for usage payment.‚Äù ‚Äì J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Beyond billing, the addition of EAB enabled also some commercial certificate authorities to integrate their existing domain control validation systems with ACME, allowing some of them to skip the challenge step of the ACME protocol.&lt;/p&gt;
    &lt;p&gt;The IETF standardization process, based on an open process, created the necessary discussion space for cooperation among entities that did not necessarily share the same objectives.&lt;/p&gt;
    &lt;p&gt;The result, ten years after the introduction of ACME and the completion of its standardization process in 2019, is that ACME has become the primary means by which all public certificate authorities√¢both free and commercial√¢rely on for their transition to an automated future of issuing short-lived certificates.&lt;/p&gt;
    &lt;p&gt;Effectively, until early this year, the maximum lifespan of a public TLS server certificate was set to 398 days by the CA/B Forum, the organization that set the rules for public certificate authorities. With the vote of the ballot SC081 at the CA/B Forum in April 2025, it has been decided that the certificate lifespan will decrease gradually starting March 2026 to reach 47 days in March 2029. The automation provided by ACME seems to be one of the main identified levers to help organizations to adapt to this drastic reduction in the lifespan of public TLS server certificates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Created at Let‚Äôs Encrypt, adopted everywhere&lt;/head&gt;
    &lt;p&gt;It is important to note that although ACME was developed by the team managing Let‚Äôs Encrypt, this protocol is now one of the main protocols for automated certificate acquisition adopted by all public certificate authorities.&lt;/p&gt;
    &lt;p&gt;And outside the public certificate authorities ecosystem, I think it‚Äôs fair to say that this protocol is also becoming increasingly popular with technical architects in companies with private certificate authorities.&lt;/p&gt;
    &lt;p&gt;This has been the case in my company for several years now, where we have deployed an ACME endpoint in front of our internal certificate authority. Among the benefits we have seen, we have been able to rely on the vast ACME clients ecosystem in order to provide an ACME client to each OS or middleware that powers our infrastructure. We can see there how certificate obtention agility powered by ACME helps organizations in their journey to global IT agility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Innovation and the adoption challenge&lt;/head&gt;
    &lt;head rend="h3"&gt;The ARI episode&lt;/head&gt;
    &lt;p&gt;We may fear that the development of a protocol supported primarily by a team as small as Let‚Äôs Encrypt‚Äôs will be fairly limited in terms of evolution and innovation.&lt;/p&gt;
    &lt;p&gt;But the history of ACME shows that its evolution continues after its initial standardization.&lt;/p&gt;
    &lt;p&gt;In 2025, we saw with the ARI (ACME Renewal Information ‚Äì RFC 9773) extension that the ACME protocol continues to evolve. ARI is a way for a certificate authority to suggest a renewal period to its clients, often earlier than they would have determined themselves. This use case is particularly relevant when the certificate authority needs to mass-revoke certificates that, for example, did not comply with the rules the certificate authority must follow when issuing certificates.&lt;/p&gt;
    &lt;p&gt;More specifically, J.C. Jones and Aaron Gable point two incidents that had to be handled by the Let‚Äôs Encrypt team and that were the start for the ARI initiative:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúExplicitly, as remediation of https://bugzilla.mozilla.org/show_bug.cgi?id=1619179 and https://bugzilla.mozilla.org/show_bug.cgi?id=1715672 " J.C. Jones and Aaron Gabble&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Support to encourage adoption&lt;/head&gt;
    &lt;p&gt;Aaron Gable leads the effort of designing and implementing ARI. But even if a new extension to the protocol has been produced, it can only reach its potential users after ACME clients have implemented it into their code base. As previously said, the team and some community members invest a lot on providing support to the community. In the case of ARI, this support is oriented to the ACME clients developers in order to make these clients ARI aware.&lt;/p&gt;
    &lt;p&gt;Providing an efficient support and effective resources to the client side ACME actors is a huge part of the challenge in order to keep ACME ecosystem healthy and agile.&lt;/p&gt;
    &lt;p&gt;As illustrates by Sarah Gran, another way to give momentum to a new feature is to lift certain restrictions on access to the certificate authority:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In order to encourage ARI adoption, we√¢ve configured Let√¢s Encrypt to allow subscribers who renew via ARI to bypass our rate limits.‚Äù ‚Äì Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Client Side Update Challenge&lt;/head&gt;
    &lt;p&gt;But despite a good support work and incentive measures, Aaron Gable confirms ARI adoption is just at its start:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúThere is still much progress to be made. Part of the appeal of the Automated Certificate Management Environment is that many users can set-and-forget their client and configuration. This means that most clients never receive software updates, and even client projects that have implemented ARI in their latest version still have massive install bases that aren√¢t running that version. We√¢ve worked closely with many clients developers to implement ARI, and contributed implementations ourselves in several cases, but for widespread adoption the whole ecosystem will need to slowly turn over‚Äù ‚Äì Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This situation is really shared with a lot of client side softwares that ‚Äújust work‚Äù(c) and it raises some concerns about how to make an ecosystem keeping track with innovation on its client side.&lt;/p&gt;
    &lt;p&gt;This challenge arises not only in terms of updating the client, but also in terms of updating the configuration. Many ACME clients rely on cron tasks. To have an efficient ARI setup, your task has to run ideally on a daily basis be able to ask the certification authority every day whether the certificate needs to be reissued. This is not the classic cron task setup. So, users have to modify this cron task frequency to reach the ARI goal of certificate reissuance led by certificate authority. Client side ACME setup evolution is a really challenging task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Evolution on server side ACME implementation&lt;/head&gt;
    &lt;p&gt;CA/B Forum has recently asked public certificate authorities to adopt Multi-Perspective Issuance Corroboration (MPIC) to guard against BGP attacks. We have asked Aaron Gable about the impacts that kind of measure have had on ACME server side implementation in the Let‚Äôs Encrypt infrastructure:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWe√¢ve had to make few if any changes to our infrastructure to accommodate recent requirements changes such as MPIC and DNSSEC validation. We innovated MPIC (then called Remote Validation) along with a research team at Princeton, and implemented it in 2020. Our experience already running such a service helped inform the requirements as they were incorporated by the CA/B Forum.‚Äù ‚Äì Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The lesson learnt here is that being at the edge of the innovation let you shape part of the future of your ecosystem and significantly lower the impact on your infrastructure of many regulatory measures that come into effect over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future&lt;/head&gt;
    &lt;p&gt;It is really encouraging to see a lot of innovation in the ACME ecosystem.&lt;/p&gt;
    &lt;p&gt;So what evolutions can we expect to see in the future?&lt;/p&gt;
    &lt;p&gt;We have asked the question to Aaron Gable who gave us two upcoming developments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúWe√¢re currently working on standardizing profile selection for ACME, and our deployment of the early draft of this standard has already brought some much-needed flexibility to the WebPKI, enabling us to make changes to our certificate contents with minimal disruption.‚Äù&lt;/item&gt;
      &lt;item&gt;‚ÄúI√¢m also excited about a potential future change which would introduce a ‚Äòpubkey‚Äô identifier type, along with a set of challenges that allow the client to demonstrate control over the corresponding keypair. This would fix the gap today that presenting a CSR does not actually prove possession of the key in that CSR.‚Äù ‚Äì Araron Gable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastly has also recently contributed to ACME in order to improve the &lt;code&gt;dns-01&lt;/code&gt; challenge in a multi-cloud and multi-PKI environment. An IETF draft describing this &lt;code&gt;dns-account-01&lt;/code&gt; challenge is online. This is further proof that the public TLS ecosystem has truly embraced the ACME protocol as its primary automation tool.&lt;/p&gt;
    &lt;p&gt;Another recent development based on ACME has also shed new light on the potential of this protocol: since 2022, a draft is under progress at the IETF in order to write an ACME extension. The goal of this extension is to use ACME to obtain a certificate for a device in order to prove its identity. The challenge is based on device attestation and what‚Äôs new in this case is the arrival of a third party, the attestation server.&lt;/p&gt;
    &lt;p&gt;What is remarkable here is that we are no longer dealing with ACME‚Äôs initial use case, namely obtaining TLS server certificates: we can see in this IETF draft the potential of ACME as a challenge-based framework to obtain certificate in very different contexts.&lt;/p&gt;
    &lt;p&gt;Indeed, we can venture to say that ACME‚Äôs future looks bright √∞&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It is heartening to see that, 30 years after the widespread adoption of the Internet, open and standardized protocols continue to revolutionize its use.&lt;/p&gt;
    &lt;p&gt;ACME and its Let‚Äôs Encrypt implementation at scale have enabled the widespread adoption of HTTPS, thereby raising the level of security for billions of Internet users and also of private networks.&lt;/p&gt;
    &lt;p&gt;Having been able to do it inside a non profit organization, providing the Internet with an open and standardized protocol is a great success for all people believing in FreeSoftware and an Open Internet.&lt;/p&gt;
    &lt;p&gt;As a community, I really think we can thank these organizations, teams, and engineers who continue to uphold the promise of efficiency and Freedom brought about by cooperation around open protocols. They inspire new generations (and older ones I guess √∞) demonstrating big things can still be achevied today in the open for the common good at the Internet scale!&lt;/p&gt;
    &lt;p&gt;I would like to extend a special thank you to the members of the Let‚Äôs Encrypt team, J.C. Jones, Aaron Gable, Sarah Gran and Jacob Hoffman-Andrews, for the time and effort they dedicated to answering my questions. Without them, this article would not have been possible.&lt;/p&gt;
    &lt;p&gt;A big shout out also to Eric Leblond and Philippe Teuwen who carefully proofread some early drafts of the article and Philippe Bonnef and Thibault Meunier for proofreading some of the last drafts. They all gave me so valuable and insightful advices √∞&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46141745</guid><pubDate>Wed, 03 Dec 2025 23:28:34 +0000</pubDate></item><item><title>Kea DHCP: Modern, open source DHCPv4 and DHCPv6 server</title><link>https://www.isc.org/kea/</link><description>&lt;doc fingerprint="ea1b597bc497298e"&gt;
  &lt;main&gt;&lt;head rend="h4"&gt;Kea 3.0, our first LTS version&lt;/head&gt;&lt;p&gt;ISC is excited to announce the release of Kea 3.0.0! This is a major release, and is the first Long-Term Support (LTS) version of Kea.&lt;/p&gt;Read&lt;p&gt;Modern, open source DHCPv4 &amp;amp; DHCPv6 server&lt;/p&gt;&lt;p&gt;ISC distributes TWO full-featured, open source, standards-based DHCP server distributions: Kea DHCP and ISC DHCP. Kea includes all the most-requested features, is far newer, and is designed for a more modern network environment. ISC announced the End of Life for the older ISC DHCP system in 2022. Users of ISC DHCP may find these resources helpful in migrating their DHCP server deployments to the Kea server.&lt;/p&gt;&lt;p&gt;Modular Component Design, Extensible with Hooks Modules. The Kea distribution includes separate daemons for a DHCPv4 server, a DHCPv6 server, and a dynamic DNS (DDNS) module. Many optional features are enabled with dynamically-loaded ‚ÄúHooks Modules,‚Äù which you need run only if you are using them. You can write your own hooks modules (in C++) or try some of the hooks we offer.&lt;/p&gt;&lt;p&gt;On-line Re-configuration with REST API. Kea uses a JSON configuration file that can be modified remotely via &lt;code&gt;set&lt;/code&gt; commands and reloaded without stopping and restarting the server, an operation that could take quite a while with ISC DHCP.&lt;/p&gt;&lt;p&gt;Designed to Integrate with Your Existing Systems. Kea allows you to separate the data from the execution environment, enabling new deployment options. Your network data - leases, host reservation definitions, and most configuration data - can be located separately from the DHCP server itself, using a Kea ‚Äúbackend.‚Äù&lt;/p&gt;&lt;p&gt;Kea supports two database backends; MySQL and PostgreSQL. Besides the obvious benefits (you avoid JSON formatting errors, you can quickly and easily mine the data for other purposes) using a database backend enables multiple Kea servers to share the data. Potential benefits:&lt;/p&gt;&lt;p&gt;Web-based graphical dashboard. Kea now has a graphical dashboard for monitoring multiple Kea servers. This system, called Stork, uses agents deployed on the Kea servers to relay information to a centralized management platform, providing the administrator with an easy-to-use quick view of system status and activity.&lt;/p&gt;&lt;p&gt;Modern, higher performance implementation. Kea is multi-threaded, and when configured for efficient operation, it can be performant enough for a large-scale, short-lease duration environment, which is the most demanding scenario.&lt;/p&gt;&lt;p&gt;The core Kea daemons are open source, shared under MPL2.0 licensing. Kea is developed in the open on ISC‚Äôs GitLab; we welcome you to open issues and submit patches there. Kea runs on most Linux and Unix platforms, as well as MacOS. If you don‚Äôt want to build from our source distribution, we also provide a repository of pre-built packages for most popular operating systems.&lt;/p&gt;&lt;p&gt;Contact ISC for Support&lt;/p&gt;&lt;p&gt;Your major design decisions are whether to deploy in pairs for High Availability and use the default csv file for host and lease data, or to install a separate database for a Kea data ‚Äúbackend.‚Äù Some of these decisions can limit your performance. See our Knowledgebase for advice on designing for optimal performance.&lt;/p&gt;&lt;p&gt;Instructions are available for building and installing Kea from the source packages downloadable below. ISC provides pre-built packages for RHEL, Fedora, Ubuntu, and Debian. If you are using any Kea hook libraries, you will also need to install and configure those.&lt;/p&gt;&lt;p&gt;The Kea Administrator Reference Manual (ARM) is the primary reference for Kea configuration. The extensive set of example configuration files in the project repo and our knowledgebase may help you get started. If you are migrating from an existing ISC DHCP deployment, try the Kea Migration Assistant (a special feature of the ISC DHCP distribution). This will enable you to save your current ISC DHCP server configuration as a Kea configuration file. It will still need some manual adjustment, but this tool should translate the bulk of your configuration.&lt;/p&gt;&lt;p&gt;Most users will benefit from joining the kea-users mailing list. Consider joining our Kea project GitLab to log issues, see what we‚Äôre working on, submit patches, and participate in development. Consider deploying Stork for a graphical management dashboard. If your DHCP is critical to your business, we recommend you subscribe for technical support from ISC.&lt;/p&gt;&lt;p&gt;Stork aggregates data about the health of the system hosting Kea, as well as the status and activity level of Kea itself. Parameters reported include memory, CPU utilization, software versions, and uptime.&lt;/p&gt;&lt;p&gt;Stork displays configured pools, with # of addresses provisioned and assigned and even tracks pool utilization across shared networks. Graphical elements highlight areas of high utilization to alert the operator to take actionHigh Availability pairs are monitored and their configured role and status are shown, making it easy to see which servers don‚Äôt have a backup established, and when a failover event has occurred.&lt;/p&gt;&lt;p&gt;Add, update and view DHCPv4 and DHCPv6 host reservations, using a graphical interface to select a host identifier, assign a hostname, reserve an IP address, associate a client class, and configure boot file information and DHCP options.&lt;/p&gt;&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;Service Options&lt;/cell&gt;&lt;cell role="head"&gt;Gold support&lt;/cell&gt;&lt;cell role="head"&gt;&lt;p&gt;Silver support&lt;/p&gt;&lt;/cell&gt;&lt;cell role="head"&gt;Bronze support&lt;/cell&gt;&lt;cell role="head"&gt;Basic (no support)&lt;/cell&gt;&lt;cell role="head"&gt;Premium (no longer offered)&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Critical issue response&lt;/cell&gt;&lt;cell&gt;30 minutes, 24x7&lt;/cell&gt;&lt;cell&gt;1 hour, 24x7&lt;/cell&gt;&lt;cell&gt;2 hours, business hours only*&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Standard issue response&lt;/cell&gt;&lt;cell&gt;4 business hours*&lt;/cell&gt;&lt;cell&gt;8 business hours*&lt;/cell&gt;&lt;cell&gt;Next business day&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Early vulnerability notifications&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;3 days&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 3.0 hook libraries (RBAC and Configuration Backend are the only commercially-licensed ones)&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;N/A&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 2.6 and earlier hook libraries included&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Stork support&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Purchasing&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;no longer offered&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Pricing based on deployment size and service level.&lt;/p&gt;Contact ISC for a quote&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;VERSION&lt;/cell&gt;&lt;cell role="head"&gt;STATUS&lt;/cell&gt;&lt;cell role="head"&gt;DOCUMENTATION&lt;/cell&gt;&lt;cell role="head"&gt;RELEASE DATE&lt;/cell&gt;&lt;cell role="head"&gt;EOL DATE&lt;/cell&gt;&lt;cell role="head"&gt;DOWNLOAD&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;3.0.2&lt;/cell&gt;&lt;cell&gt;Current Stable - LTS&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;October 2025&lt;/cell&gt;&lt;cell&gt;June 2028&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;2.6.4&lt;/cell&gt;&lt;cell&gt;Current Stable&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;July 2025&lt;/cell&gt;&lt;cell&gt;July 2026&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.1.4&lt;/cell&gt;&lt;cell&gt;Development&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;November 2025&lt;/cell&gt;&lt;cell&gt;June 2026&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46142000</guid><pubDate>Wed, 03 Dec 2025 23:58:04 +0000</pubDate></item><item><title>Average DRAM price in USD over last 18 months</title><link>https://pcpartpicker.com/trends/price/memory/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46142100</guid><pubDate>Thu, 04 Dec 2025 00:08:26 +0000</pubDate></item><item><title>Why WinQuake exists and how it works</title><link>https://fabiensanglard.net/winquake/index.html</link><description>&lt;doc fingerprint="e73b81353f2276d7"&gt;
  &lt;main&gt;
    &lt;p&gt;When I took a look at the history of Quake binaries, they all made sense to me. &lt;code&gt;quake.exe&lt;/code&gt; was the original release, able to run on DOS and Windows 95. Then came &lt;code&gt;vquake.exe&lt;/code&gt; to support the hardware accelerated chip V√©rit√© 1000. Later, &lt;code&gt;glquake.exe&lt;/code&gt; generalized hardware acceleration to any vendor providing OpenGL drivers. And to revolutionize Internet deathmatch, id Software released QuakeWorld server and client (&lt;code&gt;qwsv.exe&lt;/code&gt; and &lt;code&gt;qwcl.exe&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;However, I could not figure out the point of &lt;code&gt;winquake.exe&lt;/code&gt;. Until now. Here is what I understood and a little bit of a dive into how it works.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;quake.exe&lt;/code&gt; runs on both DOS and Windows 95 but how well does it perform? A quick benchmark on my Pentium MMX 233MHz, Matrox Mystique PC (320x200 with 101 screen size) and sound on, showed the following numbers.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from DOS&lt;/cell&gt;
        &lt;cell&gt;48 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from Windows 95&lt;/cell&gt;
        &lt;cell&gt;38 fps&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So "framerate" is the beginning of an answer to justify the existence of WinQuake. &lt;code&gt;quake.exe&lt;/code&gt; running from Windows 95 is roughly 25% slower than the same binary started from DOS. And that is to be expected. Windows 95 runs DOS applications in a virtual machine ("DOS BOX"), where memory access, interrupts, and signals are virtualized, which incurs overhead.&lt;/p&gt;
    &lt;p&gt;Another element of the answer comes from Quake Chunnel. &lt;code&gt;quake.exe&lt;/code&gt; can access Windows 95 TCP/IP stack, but only via a convoluted tech from Mpath to bridge a "DOS BOX" to win32 dlls. By having a win32-only application, id Software had guaranteed direct access to &lt;code&gt;winsock.dll&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Last but not least, id Software really wanted Quake to work on Windows NT. Despite their best efforts, the people at DJGPP could not make their DPMI client in &lt;code&gt;quake.exe&lt;/code&gt; compatible with the NT Virtual DOS Machine (NTVDM).&lt;/p&gt;
    &lt;quote&gt;Near pointers don't work under NT - which was a huge disappointment to iD and generated some conference calls to Microsoft.&lt;lb/&gt;- Charles Sandmann[1]&lt;/quote&gt;
    &lt;p&gt;A fun way to start exploring is to first read WQREADME.TXT and then take a look at all the modes available in &lt;code&gt;winquake.exe&lt;/code&gt;. They are configured with the script wq.bat.&lt;/p&gt;
    &lt;quote&gt;Options for running WinQuake: wq max: all features on, but doesn't work on all systems wq fast: maximum speed, but doesn't work on all systems wq fastvid: maximum video speed, but safer, probably slower sound wq fastsnd: maximum sound speed, but safer, probably slower video wq safe: very likely to run, but may be slower wq verysafe: almost sure to run, but probably slower, and no sound&lt;/quote&gt;
    &lt;p&gt;Here are the numbers I got for each mode, still with the same Pentium MMX 233MHz machine and same configuration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq max&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;42.4 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fast&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastvid&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastsnd&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq safe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;wq verysafe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;40.0 fps*&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Impressive. &lt;code&gt;winquake.exe&lt;/code&gt; managed to bring up the framerate within 6% of &lt;code&gt;quake.exe&lt;/code&gt; running on DOS. Mission accomplished. But how does it works?&lt;/p&gt;
    &lt;p&gt;Each "mode" is configured via command-line flags. This part reveals there are three types of backend for input controls, audio, and video.&lt;/p&gt;
    &lt;quote&gt;max winquake -dinput fast winquake fastvid winquake -wavonly fastsnd winquake -nodirectdraw -nowindirect safe winquake -wavonly -nodirectdraw -nowindirect verysafe winquake -dibonly -nosound -nojoy&lt;/quote&gt;
    &lt;p&gt;Amusingly, the mode that provides the highest framerate, &lt;code&gt;fastvid&lt;/code&gt; keeps everything default but disables an audio backend!&lt;/p&gt;
    &lt;p&gt;"fastvid" was also the name of a tool to fix the Pentium Pro abysmal video write speed on chipset that shipped with buggy "Write Posting". The option in &lt;code&gt;qw.bat&lt;/code&gt; has nothing to do with it.&lt;/p&gt;
    &lt;p&gt;WinQuake can send its sound effects (the music comes from CD tracks) using two audio backends (with &lt;code&gt;-nosound&lt;/code&gt; disables sound effects altogether).&lt;/p&gt;
    &lt;p&gt;The two backends are DirectSound (&lt;code&gt;dsound.h&lt;/code&gt; from DirectX) and what id calls wave sound which is in fact &lt;code&gt;winmm.h&lt;/code&gt;, the Windows MultiMedia audio API, dating back to Windows 3.1.&lt;/p&gt;
    &lt;p&gt;If DirectSound is available, WinQuake uses it to provide the lowest latency. However this backend has a higher impact on the CPU and results in 10% lower framerate. With &lt;code&gt;-wavonly&lt;/code&gt;, users can force usage of &lt;code&gt;WinMM&lt;/code&gt; which results in higher latency but higher framerate.&lt;/p&gt;
    &lt;p&gt;To read user inputs, WinQuake uses either DirectInput (&lt;code&gt;dinput.h&lt;/code&gt; from DirectX) or the legacy Windows API &lt;code&gt;winuser.h&lt;/code&gt;.

&lt;/p&gt;
    &lt;p&gt;By default WinQuake uses &lt;code&gt;winuser.h&lt;/code&gt; but usage of DirectInput can be requested via &lt;code&gt;-dinput&lt;/code&gt; for slightly smoother motion and responsiveness to fast spinning motions. I suspect it was not enabled by default for cases where DirectX was not installed or perhaps fear of driver problems.&lt;/p&gt;
    &lt;p&gt;Joystick inputs are handled with &lt;code&gt;joystickapi.h&lt;/code&gt;. Likewise, it seems drivers may not have been stable since id provided a way to disable it with &lt;code&gt;-nojoy&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The part that was the most interesting to me was the video backends. WinQuake can operate in five modes using GDI, VGA, VESA, Accelerated VESA, or DirectDraw.&lt;/p&gt;
    &lt;p&gt;The Graphics Device Interface (GDI) (&lt;code&gt;wingdi.h&lt;/code&gt;) is the foundation to render anything on the desktop in Windows 95. Applications usually did not use it directly but instead called &lt;code&gt;winuser.h&lt;/code&gt; (which in turns used low-level &lt;code&gt;wingdi.h&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;WinQuake can render to a Device-Independent Bitmaps (DIB) which is a surface to be blitted towards a window though GDI. The surface can be of any dimension so there are no "display mode" to detect here, WinQuake hardcodes its DIB modes to square-pixel resolutions 320x240, 640x480, and 800x600.&lt;/p&gt;
    &lt;p&gt;Because it is using Windows "by the book", DIB mode is the safest mode that should always work. It is also the slowest way to render to the screen because WinQuake first renders to a DIB that is then sent to the GDI and then sent to the video card.&lt;/p&gt;
    &lt;p&gt;While slower, it is not devoid of hardware acceleration. Many graphic cards wanting to perform well under Windows 95 had hardware acceleration implementation of crucial functions such as &lt;code&gt;bitBlt&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally, DIB mode is the only one able to render in "windowed" mode. Every other mode takes over and renders in "fullscreen" mode. Note that DIB can also render in pseudo-full screen if WinQuake is started with &lt;code&gt;dibonly&lt;/code&gt; but this is "faked" with a borderless window covering the whole screen.&lt;/p&gt;
    &lt;p&gt;For everything not DIB, WinQuake uses SciTech's MegaGraph Graphics Library. It was a rather expensive lib ($499 in 1997, $1,000 in 2025)[2] but well worth its price because it brought order into the chaos that was the world of video systems in 1997 if a game operated outside GDI.&lt;/p&gt;
    &lt;p&gt;WinQuake could find itself having to deal with the following types of video systems.&lt;/p&gt;
    &lt;quote&gt;1. VBEAF : VESA Accelerator Function 2. VBE2 : VESA Linear Frame Buffer for direct to VRAM write/read. 3. DirectDraw : Only available if DirectX is installed. 4. StandardVGA : That good ol' VGA video mode.&lt;/quote&gt;
    &lt;p&gt;When it starts, WinQuake registers the drivers it wants MGL to load (see &lt;code&gt;registerAllDispDrivers&lt;/code&gt;). MGL then lists all supported resolutions and pick the highest performance drivers to access each of them (in the order list above).&lt;/p&gt;
    &lt;quote&gt;void registerAllDispDrivers(void) { /* Even though these driver require WinDirect, we register * them so that they will still be available even if DirectDraw * is present and the user has disabled the high performance * WinDirect modes. */ MGL_registerDriver(MGL_VGA8NAME,VGA8_driver); if (useWinDirect){ MGL_registerDriver(MGL_LINEAR8NAME,LINEAR8_driver); if (!COM_CheckParm ("-novbeaf")) MGL_registerDriver(MGL_ACCEL8NAME,ACCEL8_driver); } if (useDirectDraw) { MGL_registerDriver(MGL_DDRAW8NAME,DDRAW8_driver); } }&lt;/quote&gt;
    &lt;p&gt;The list of modes and which driver was selected by MGL is available via the command &lt;code&gt;vid_describemodes&lt;/code&gt; in Quake console. In the screenshot below, we can see almost the full house of drivers &lt;code&gt;VGA8.DRV&lt;/code&gt;, &lt;code&gt;DDRAW.DRV&lt;/code&gt;, &lt;code&gt;LINEAR8.DRV&lt;/code&gt;, and the windowed DIB modes.&lt;/p&gt;
    &lt;p&gt;I had never heard of VBE/AF before reading MGL source code. As far as I understand, it never gained much traction and few vendors wrote drivers to support it.&lt;/p&gt;
    &lt;p&gt;Many games used MGL: WinQuake, Hexen II, Grand Theft Auto, Maui Mallard in Cold Shadow, Total Mayhem, Balls of Steel.&lt;/p&gt;
    &lt;p&gt;Microsoft was very much aware that GDI was fine for applications but not enough for video games. Already in Windows 3.1 they had released a game developer SDK called WinG to give a more direct fullscreen access to the screen. The second version of WinG was renamed DirectX and contained the 2D fullscreen API which they called DirectDraw.&lt;/p&gt;
    &lt;quote&gt;Although safer and more reliable, Microsoft Windows imposed many restrictions on applications. One result of this situation was that games, and other high-performance graphics applications, could no longer access the hardware resources directly in order to maximize performance and expand functionalities. For several years game programmers continued to exercise the craft in DOS, and Windows users had to switch to the DOS mode to run games, simulations, and other graphics programs. The resulting situation implied a major contradiction: a graphical operating system in which graphics applications would execute with marginal performance&lt;lb/&gt;The first effort in this direction was a product named WinG, in reference to Windows for Games. WinG was first made available in 1994 and it required Win32 in Windows 3.1. Its main feature is that WinG enabled the game programmer to rapidly transfer bitmaps from system memory into video memory. This made possible the creation of Windows games that executed with much better performance.&lt;lb/&gt;Microsoft renamed the new version of the Game SDK, calling it DirectX 2. Other versions later released were named DirectX 3, DirectX 5, DirectX 6, and currently, DirectX 7.&lt;lb/&gt;- Feng Yuan, "Windows Graphics Programming Win32 GDI and DirectDraw"&lt;/quote&gt;
    &lt;p&gt;In terms of performance, DirectDraw was a step up from GDI but it was also not guaranteed to work due to driver bugs or if the user had not installed DirectX. It can be disabled with &lt;code&gt;nodirectdraw&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Readers may have picked up on something written earlier that was blatantly wrong. Direct access to the hardware is forbidden to Win32 applications. So how is MGL able to bypass GDI/DirectDraw and directly hit VBEAF, VBE, and VGA?&lt;/p&gt;
    &lt;p&gt;That is possible thanks to the secret tech from SciTech called WinDirect. How it works is explained in SciTech MGL Reference Guide v4.pdf.&lt;/p&gt;
    &lt;quote&gt;What is WinDirect?&lt;lb/&gt;A key component of the SciTech MGL, WinDirect is a runtime package for DOS and Windows 95 that provides direct access to the display hardware for both 16 and 32-bit applications. Traditionally Windows applications have had to perform all graphics output using the standard Graphics Device Interface (GDI). Although the GDI is very extensive and powerful, it is also not particularly fast for the sort of graphics that real time applications like interactive video games require.&lt;lb/&gt;WinDirect breaks this barrier by allowing high performance applications to shut down the normal GDI interface, and to take over the entire graphics display hardware just like you would normally do under DOS. Once GDI has been shut down, interactive graphics applications can re-program the display controller and write directly to video memory. A WinDirect application can program any standard VGA graphics mode such as 320x200x256, it can re-program the controller and run standard VGA ModeX style graphics, or it can call the standard VESA BIOS services to run high resolution SuperVGA graphics.&lt;lb/&gt;- MGL v4 Programmer Guide[3]&lt;/quote&gt;
    &lt;p&gt;MGL v4 programmer guide, is a treasure strove of information. If, like me, you wondered what were these &lt;code&gt;WDIR32.DLL&lt;/code&gt; and &lt;code&gt;WDIR16.DLL&lt;/code&gt; libraries that came with WinQuake, the doc mentions them (WinDIRect). Likewise, the doc describes &lt;code&gt;PMPRO16.DLL&lt;/code&gt; and &lt;code&gt;PMPRO32.DLL&lt;/code&gt; as DOS extender independent API for protected mode services. Michael Abrash's Zen Timer is also mentioned in there :)!&lt;/p&gt;
    &lt;p&gt;WinQuake source code does not include MGL. Only the headers and a pre-compiled 32-bit &lt;code&gt;MGLLT.LIB&lt;/code&gt; (MGL Lite) are provided to allow compilation. SciTech did eventually publish the source in 2000[4] but it is no longer available. What was uploaded on GitHub[5] is v5 which by then had dramatically changed (e.g: WinDirect was gone).&lt;lb/&gt; Luckily a kind soul has mirrored MGL v4. If you want to do your own digging, install mglb405.exe and mgls405.exe. Or just download my installation, src.rar.&lt;/p&gt;
    &lt;p&gt;Overall, &lt;code&gt;winquake.exe&lt;/code&gt; was often able to find a fast rendering path, either through DirectDraw or WinDirect. The fallback to DIB mode was not ideal but still a win compared to &lt;code&gt;quake.exe&lt;/code&gt;. Add to that the ability to select a sound backend to optimize for framerate or audio latency and the result was a damn good experience that completely justified the effort.&lt;/p&gt;
    &lt;p&gt;More than 30 years later, you can still run &lt;code&gt;winquake.exe&lt;/code&gt; on Windows 11. Fullscreen does not support widescreen but the windowed mode still works flawlessly. As much as Microsoft has been questionable lately, their commitment to backward compatibility is impressive.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;Why did ID choose DJGPP for Quake?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;SciTech's MGL price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;MGL v4 Programmer Guide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[4]&lt;/cell&gt;
        &lt;cell&gt;SciTech Releases MGL 4.0 OpenGL Source Code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[5]&lt;/cell&gt;
        &lt;cell&gt;SciTech Mult-platform Graphics Library&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46142866</guid><pubDate>Thu, 04 Dec 2025 01:58:15 +0000</pubDate></item><item><title>Euler Conjecture and CDC 6600</title><link>https://fortran-lang.discourse.group/t/euler-conjecture-and-cdc-6600/10501</link><description>&lt;doc fingerprint="bec9d9882d3a9cda"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I don‚Äôt think this warning applies here because the array is small, but the danger of this approach in general is that the executable file must contain that compile-time computed data, which means that it takes time to load that memory from disk (SSD, etc.) into the process memory on startup. In contrast, if that memory is allocated at run time directly by the executable, and then filled by cpu instructions, then it can be some 10^3 to 10^5 times faster. You can also see the difference by looking at the size of the executable image (&lt;code&gt;ls -l a.out&lt;/code&gt;). With most modern compilers, you do not see the size of the declared array reflected in the executable size unless they are parameter arrays, arrays initialized at compile time, or arrays in common blocks.&lt;/p&gt;
      &lt;p&gt;Also, if done at compile time, the whole array would need to be computed. That is 10^4 elements in this case (and integer overflows would be generated in doing so). The above run time code only computes 144 elements of the array before finding a solution and stopping.&lt;/p&gt;
      &lt;p&gt;A further question is where does that extra effort get charged? This extra effort is appropriate if the user is paying for that time (e.g. with money, or with elapsed time, or with total throughput through the machine), but not if that overhead is somehow not charged as user time (e.g. in a timeshare or batch environment with many other users). This is why the programmer sometimes writes code to minimize wall time and sometimes to minimize cpu time. Those two goals are not always exactly the same.&lt;/p&gt;
      &lt;p&gt;In the original code, the posix &lt;code&gt;time&lt;/code&gt; command was used for the timings. That command returns three different time values for exactly this reason. If you alone own the machine you are running on, and you want to maximize throughput through that machine every 24 hour period, then it is the elapsed time that is critical. If you are one of many users sharing the machine, then it is the user time that you want to minimize, the system time is not charged to you because while your job is stalled waiting for the disk to respond, someone else‚Äôs job is swapped in and is being charged to execute its user time.&lt;/p&gt;
      &lt;p&gt;Here is the timing result of that last version of the code using gfortran -O3 with an Apple M2 cpu&lt;lb/&gt; on MacOS. It computes the &lt;code&gt;i**5&lt;/code&gt; values at run time, so the system time is minimal.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;i^5 =  61917364224
133 110 84 27 144

real    0m0.141s
user    0m0.139s
sys     0m0.002s
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;One other comment about timings is that they are almost never really consistent from run to run. For small segments of code like this, one can do&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;$ time a.out; time a.out; time a.out
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The first results are usually longer than the others, which are then usually more consistent if not identical at the millisecond level. But if timings are measured at the microsecond level, they would show variations too.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46143618</guid><pubDate>Thu, 04 Dec 2025 03:50:36 +0000</pubDate></item><item><title>Show HN: A Minimal Monthly Task Planner (printable, offline, no signup)</title><link>https://printcalendar.top/</link><description>&lt;doc fingerprint="3f61c1ba9314363"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;PrintCalendar.top&lt;/p&gt;
      &lt;head rend="h3"&gt;Minimal Monthly Task Planner&lt;/head&gt;
      &lt;p&gt;A calm, printer-friendly canvas to map your month, capture notes, and keep a lightweight log of what matters.&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Stay on month&lt;/p&gt;
            &lt;p&gt;Jump to today, share month links, pick Mon/Sun as week start.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Notes that travel&lt;/p&gt;
            &lt;p&gt;Monthly notes with inline editing, saved locally in your browser.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Ready to print&lt;/p&gt;
            &lt;p&gt;Clean A4 layout, dark/light themes, and PDF in one click.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46144113</guid><pubDate>Thu, 04 Dec 2025 05:29:51 +0000</pubDate></item><item><title>Uncloud - Tool for deploying containerised apps across servers without k8s</title><link>https://uncloud.run/</link><description>&lt;doc fingerprint="6f4f5cfad58e4b63"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Mix and Match Infrastructure&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mix and match cloud and on-premise across regions and providers&lt;/item&gt;
      &lt;item&gt;Deploy customer-facing apps on reliable cloud VMs&lt;/item&gt;
      &lt;item&gt;Run resource-hungry background jobs on budget-friendly bare metal servers&lt;/item&gt;
      &lt;item&gt;Transform that dusty Mac mini into a powerful staging environment&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46144275</guid><pubDate>Thu, 04 Dec 2025 06:02:23 +0000</pubDate></item><item><title>Show HN: Mirror_bridge ‚Äì C++ Reflection powered Python binding generation</title><link>https://github.com/FranciscoThiesen/mirror_bridge</link><description>&lt;doc fingerprint="2ab1821826d1f299"&gt;
  &lt;main&gt;
    &lt;p&gt;Modern C++ meets Multiple Languages: Automatic bindings using C++26 reflection - zero boilerplate, pure compile-time magic.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;‚ö†Ô∏è&lt;/g-emoji&gt;EXPERIMENTAL: This project requires C++26 reflection (P2996), which is not yet standardized. It only works with Bloomberg's clang-p2996 fork. Not recommended for production use until P2996 lands in standard C++26.&lt;/quote&gt;
    &lt;code&gt;// Write your C++ code once
struct Calculator {
    double value = 0.0;
    double add(double x) { return value += x; }
    double subtract(double x) { return value -= x; }
};&lt;/code&gt;
    &lt;p&gt;Python:&lt;/p&gt;
    &lt;code&gt;import cpp_calc
calc = cpp_calc.Calculator()
calc.add(10)
calc.subtract(3)
print(calc.value)  # 7.0&lt;/code&gt;
    &lt;p&gt;JavaScript (Node.js):&lt;/p&gt;
    &lt;code&gt;const calc = new addon.Calculator();
calc.add(10);
calc.subtract(3);
console.log(calc.x);  // 7.0&lt;/code&gt;
    &lt;p&gt;Lua:&lt;/p&gt;
    &lt;code&gt;local calc = cpp_calc.Calculator()
calc:add(10)
calc:subtract(3)
print(calc.value)  -- 7.0&lt;/code&gt;
    &lt;p&gt;No manual binding code. No wrapper macros. Just pure C++26 reflection. üéâ&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;API&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Stable&lt;/cell&gt;
        &lt;cell&gt;Python C API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;import my_module&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Stable&lt;/cell&gt;
        &lt;cell&gt;Node.js N-API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;const mod = require('my_module')&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Lua&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Stable&lt;/cell&gt;
        &lt;cell&gt;Lua C API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;local mod = require("my_module")&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Mirror Bridge is a header-only library that uses C++26 reflection (P2996) to automatically introspect your C++ classes at compile-time and generate bindings for Python, JavaScript, and Lua. It discovers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Data members - automatic getters/setters with type safety&lt;/item&gt;
      &lt;item&gt;‚úÖ Methods (any number of parameters) - variadic parameter support&lt;/item&gt;
      &lt;item&gt;‚úÖ Constructors - including parameterized constructors&lt;/item&gt;
      &lt;item&gt;‚úÖ Method overloading - automatic name mangling for overloads&lt;/item&gt;
      &lt;item&gt;‚úÖ Smart pointers - &lt;code&gt;std::unique_ptr&lt;/code&gt;,&lt;code&gt;std::shared_ptr&lt;/code&gt;with automatic conversion&lt;/item&gt;
      &lt;item&gt;‚úÖ Nested classes - recursive handling, cross-file dependencies&lt;/item&gt;
      &lt;item&gt;‚úÖ Containers - &lt;code&gt;std::vector&lt;/code&gt;,&lt;code&gt;std::array&lt;/code&gt;with bidirectional conversion&lt;/item&gt;
      &lt;item&gt;‚úÖ Exception handling - C++ exceptions ‚Üí Python exceptions&lt;/item&gt;
      &lt;item&gt;‚úÖ Enums - automatic conversion to/from Python int&lt;/item&gt;
      &lt;item&gt;‚úÖ Object representation - automatic &lt;code&gt;__repr__&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;‚úÖ Inheritance - reflection automatically discovers inherited members&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Zero overhead: All binding code is generated at compile-time through template metaprogramming and reflection - no runtime costs.&lt;/p&gt;
    &lt;code&gt;# 1. Get the environment
./start_dev_container.sh
# Choose option 1 to pull pre-built image (~2 min)

# 2. Inside container - verify it works
cd /workspace &amp;amp;&amp;amp; ./tests/run_all_tests.sh

# 3. Try an example
cd examples/option2
../../mirror_bridge_auto src/ --module math_module
python3 test_option2.py&lt;/code&gt;
    &lt;p&gt;That's it! See QUICKSTART.md for a detailed walkthrough.&lt;/p&gt;
    &lt;p&gt;Mirror Bridge offers two workflows optimized for different use cases:&lt;/p&gt;
    &lt;p&gt;Just point at a directory - bindings are auto-generated for all classes.&lt;/p&gt;
    &lt;p&gt;Python:&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto src/ --module my_module&lt;/code&gt;
    &lt;p&gt;Lua:&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto_lua src/ --module my_module&lt;/code&gt;
    &lt;p&gt;JavaScript (Node.js):&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto_js src/ --module my_module&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Zero configuration - discovers all classes automatically&lt;/item&gt;
      &lt;item&gt;‚úÖ Perfect for prototyping and small projects&lt;/item&gt;
      &lt;item&gt;‚úÖ Opt-out via comments - mark classes to skip&lt;/item&gt;
      &lt;item&gt;‚úÖ Works for all three languages - Python, Lua, JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;// src/calculator.hpp
struct Calculator {
    double value;
    double add(double x);
};

// src/vector3.hpp
struct Vector3 {
    double x, y, z;
    double length();
};&lt;/code&gt;
    &lt;code&gt;# One command binds BOTH classes
mirror_bridge_auto src/ --module mylib&lt;/code&gt;
    &lt;code&gt;import mylib
calc = mylib.Calculator()
vec = mylib.Vector3()&lt;/code&gt;
    &lt;p&gt;See &lt;code&gt;examples/option2/&lt;/code&gt; for full example.&lt;/p&gt;
    &lt;p&gt;Declarative config for explicit control over what gets bound.&lt;/p&gt;
    &lt;p&gt;Create &lt;code&gt;my_module.mirror&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;module: my_module

include_dirs: src/, include/

Calculator: calculator.hpp
Vector3: vector3.hpp
&lt;/code&gt;
    &lt;code&gt;mirror_bridge_generate my_module.mirror&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Explicit control - only bind what you specify&lt;/item&gt;
      &lt;item&gt;‚úÖ Version control friendly - declarative config&lt;/item&gt;
      &lt;item&gt;‚úÖ Class renaming - &lt;code&gt;Foo::Bar: foo.hpp as Bar&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;examples/option3/&lt;/code&gt; for full example.&lt;/p&gt;
    &lt;p&gt;Full comparison: examples/README.md&lt;/p&gt;
    &lt;p&gt;For easier integration, Mirror Bridge provides single-header amalgamated versions for each language. Just copy one file to your project!&lt;/p&gt;
    &lt;p&gt;Generate single-headers:&lt;/p&gt;
    &lt;code&gt;./amalgamate.sh&lt;/code&gt;
    &lt;p&gt;This creates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_python.hpp&lt;/code&gt;(~1771 lines, 65KB)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_lua.hpp&lt;/code&gt;(~859 lines, 32KB)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_javascript.hpp&lt;/code&gt;(~875 lines, 33KB)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;// Instead of: #include "python/mirror_bridge_python.hpp"
// Just:
#include "mirror_bridge_python.hpp"  // Single self-contained header!

MIRROR_BRIDGE_MODULE(my_module,
    mirror_bridge::bind_class&amp;lt;MyClass&amp;gt;(m, "MyClass");
)&lt;/code&gt;
    &lt;p&gt;See SINGLE_HEADER_GUIDE.md for complete documentation.&lt;/p&gt;
    &lt;code&gt;struct Point { double x, y; };&lt;/code&gt;
    &lt;code&gt;p = my_module.Point()
p.x = 3.0  # Automatic getter/setter
p.y = 4.0&lt;/code&gt;
    &lt;code&gt;struct MathOps {
    double add3(double a, double b, double c) { return a + b + c; }
    double sum5(double a, double b, double c, double d, double e) {
        return a + b + c + d + e;
    }
    void reset() { value = 0; }  // Zero parameters work too
};&lt;/code&gt;
    &lt;code&gt;ops = my_module.MathOps()
ops.add3(1.0, 2.0, 3.0)           # 3 parameters ‚úì
ops.sum5(1, 2, 3, 4, 5)           # 5 parameters ‚úì
ops.reset()                        # 0 parameters ‚úì
# ANY number of parameters supported through variadic templates&lt;/code&gt;
    &lt;code&gt;struct Rectangle {
    Rectangle() : width(0), height(0) {}
    Rectangle(double w, double h) : width(w), height(h) {}
    Rectangle(double w, double h, std::string name)
        : width(w), height(h), name(name) {}

    double width, height;
    std::string name;
};&lt;/code&gt;
    &lt;code&gt;r1 = my_module.Rectangle()              # Default constructor
r2 = my_module.Rectangle(10.0, 5.0)    # 2-parameter constructor
r3 = my_module.Rectangle(10, 5, "box") # 3-parameter constructor
# Automatic constructor discovery and parameter matching&lt;/code&gt;
    &lt;code&gt;struct Printer {
    void print(int value) { /* ... */ }
    void print(double value) { /* ... */ }
    void print(std::string value) { /* ... */ }
};&lt;/code&gt;
    &lt;code&gt;p = my_module.Printer()
p.print_int(42)                    # int overload
p.print_double(3.14)               # double overload
p.print_std__string("hello")       # string overload
# Automatic name mangling distinguishes overloads&lt;/code&gt;
    &lt;code&gt;struct Data {
    std::string name;
    int value;
};

struct ResourceManager {
    std::unique_ptr&amp;lt;Data&amp;gt; unique_data;
    std::shared_ptr&amp;lt;Data&amp;gt; shared_data;

    std::unique_ptr&amp;lt;Data&amp;gt; create_unique(std::string n, int v);
};&lt;/code&gt;
    &lt;code&gt;rm = my_module.ResourceManager()

# Smart pointers convert to/from Python dicts
result = rm.create_unique("test", 42)
print(result)  # {'name': 'test', 'value': 42}

# Set from dict - creates managed pointer automatically
rm.unique_data = {'name': 'data', 'value': 123}

# None handling for null pointers
rm.unique_data = None  # Sets to nullptr&lt;/code&gt;
    &lt;code&gt;struct Address {
    std::string city;
};

struct Person {
    std::string name;
    Address addr;  // Nested!
};&lt;/code&gt;
    &lt;code&gt;p = my_module.Person()
p.addr = {'city': 'Boston'}  # Dict conversion&lt;/code&gt;
    &lt;code&gt;struct Data {
    std::vector&amp;lt;double&amp;gt; values;
    std::array&amp;lt;int, 3&amp;gt; coords;
};&lt;/code&gt;
    &lt;code&gt;d.values = [1.0, 2.0, 3.0]  # List ‚Üí vector
d.coords = [1, 2, 3]         # List ‚Üí array&lt;/code&gt;
    &lt;code&gt;double divide(double x) {
    if (x == 0) throw std::runtime_error("Division by zero");
    return value / x;
}&lt;/code&gt;
    &lt;code&gt;try:
    calc.divide(0)
except RuntimeError as e:
    print(e)  # "Division by zero"&lt;/code&gt;
    &lt;code&gt;mirror_bridge/
‚îú‚îÄ‚îÄ mirror_bridge.hpp           # Single-header library (core reflection logic)
‚îú‚îÄ‚îÄ mirror_bridge_pch.hpp       # Precompiled header wrapper (optional)
‚îú‚îÄ‚îÄ mirror_bridge_auto          # Auto-discovery script
‚îú‚îÄ‚îÄ mirror_bridge_generate      # Config file script
‚îú‚îÄ‚îÄ mirror_bridge_build         # Direct compilation script
‚îú‚îÄ‚îÄ mirror_bridge_build_pch     # PCH builder script (optional)
‚îú‚îÄ‚îÄ start_dev_container.sh      # Docker setup (persistent container)
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Detailed usage guide
‚îÇ   ‚îú‚îÄ‚îÄ option2/                # Auto-discovery example
‚îÇ   ‚îî‚îÄ‚îÄ option3/                # Config file example
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ run_all_tests.sh        # Automated test suite
    ‚îú‚îÄ‚îÄ test_pch.sh             # PCH functionality test
    ‚îî‚îÄ‚îÄ e2e/                    # End-to-end tests
        ‚îú‚îÄ‚îÄ basic/              # Point2D, Vector3
        ‚îú‚îÄ‚îÄ containers/         # std::vector, std::array
        ‚îú‚îÄ‚îÄ nesting/            # Nested classes, cross-file
        ‚îî‚îÄ‚îÄ methods/            # Method binding (Calculator)
&lt;/code&gt;
    &lt;p&gt;Mirror Bridge leverages C++26 reflection at compile-time:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Discovery: Uses &lt;code&gt;std::meta::nonstatic_data_members_of(^^T)&lt;/code&gt;to find all class members&lt;/item&gt;
      &lt;item&gt;Method Introspection: Uses &lt;code&gt;std::meta::members_of&lt;/code&gt;+&lt;code&gt;std::meta::is_function&lt;/code&gt;to find methods&lt;/item&gt;
      &lt;item&gt;Type Extraction: Uses &lt;code&gt;std::meta::type_of&lt;/code&gt;and&lt;code&gt;std::meta::identifier_of&lt;/code&gt;for names&lt;/item&gt;
      &lt;item&gt;Code Generation: Generates Python C API bindings via template metaprogramming&lt;/item&gt;
      &lt;item&gt;Compilation: Compiles to &lt;code&gt;.so&lt;/code&gt;module with reflection-enabled clang&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All binding logic is resolved at compile-time - zero runtime overhead.&lt;/p&gt;
    &lt;p&gt;See CONTRIBUTING.md for technical details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compiler: Bloomberg clang-p2996 (P2996 reflection support) &lt;list rend="ul"&gt;&lt;item&gt;Provided via Docker: &lt;code&gt;./start_dev_container.sh&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Or build from: https://github.com/bloomberg/clang-p2996&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Provided via Docker: &lt;/item&gt;
      &lt;item&gt;Python: 3.7+&lt;/item&gt;
      &lt;item&gt;Platform: Linux (or macOS with Docker)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Inside Docker container:

# Run all automated tests
./tests/run_all_tests.sh

# Output:
# ‚úì Built: 12 bindings
# ‚úì Passed: 12 tests
# ‚úì ALL TESTS PASSED!

# Test coverage:
# - Basic data members (Point2D, Vector3)
# - Containers (std::vector, std::array)
# - Nested classes (2-level, 3-level, cross-file)
# - Methods (Calculator with various signatures)
# - Variadic parameters (3, 4, 5, 6 parameter methods)
# - Constructors with parameters (0, 2, 3 parameters)
# - Method overloading (int/double/string overloads)
# - Smart pointers (unique_ptr, shared_ptr conversion)&lt;/code&gt;
    &lt;p&gt;Advanced feature tests (&lt;code&gt;tests/e2e/advanced/&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Variadic: Methods with 3-6 parameters, weighted sums, format functions&lt;/item&gt;
      &lt;item&gt;Constructors: Default, 2-param, 3-param constructor matching&lt;/item&gt;
      &lt;item&gt;Overloading: Type-based name mangling for overloaded methods&lt;/item&gt;
      &lt;item&gt;Smart Pointers: Bidirectional dict conversion, nullptr handling, return values&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CONTRIBUTING.md - Development guide: setup, testing, CLI tools, architecture&lt;/item&gt;
      &lt;item&gt;examples/README.md - Usage examples and workflow comparisons&lt;/item&gt;
      &lt;item&gt;API Reference - Inline documentation in &lt;code&gt;mirror_bridge.hpp&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passing bound class instances as parameters (requires reference/pointer handling)&lt;/item&gt;
      &lt;item&gt;Template classes (must be explicitly instantiated before binding)&lt;/item&gt;
      &lt;item&gt;Const method overloads (treated as same method currently)&lt;/item&gt;
      &lt;item&gt;Advanced smart pointers (&lt;code&gt;weak_ptr&lt;/code&gt;, custom deleters)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recently Completed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Variadic parameter support (any number of parameters)&lt;/item&gt;
      &lt;item&gt;‚úÖ Constructor parameter binding&lt;/item&gt;
      &lt;item&gt;‚úÖ Method overloading via name mangling&lt;/item&gt;
      &lt;item&gt;‚úÖ Smart pointer support (&lt;code&gt;unique_ptr&lt;/code&gt;,&lt;code&gt;shared_ptr&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Next:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reference parameters and bound class passing&lt;/item&gt;
      &lt;item&gt;Const method overload distinction&lt;/item&gt;
      &lt;item&gt;Template class binding automation&lt;/item&gt;
      &lt;item&gt;Additional backends (Rust, Lua)&lt;/item&gt;
      &lt;item&gt;Python stub generation (.pyi files)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Mirror Bridge delivers significant performance improvements over pybind11:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple project (1 class): 816ms vs 1,938ms pybind11 (2.4x faster)&lt;/item&gt;
      &lt;item&gt;Medium project (10 classes): 1,543ms vs 3,637ms pybind11 (2.4x faster)&lt;/item&gt;
      &lt;item&gt;Why: Reflection eliminates template metaprogramming overhead&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function calls: 35ns vs 127ns pybind11 (3.6x faster)&lt;/item&gt;
      &lt;item&gt;Object construction: 47ns vs 256ns pybind11 (5.4x faster)&lt;/item&gt;
      &lt;item&gt;Why: Direct Python C API calls, no template dispatch&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-discovery: &lt;code&gt;mirror_bridge_auto src/ --module name&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;No binding code required vs 18-103 lines for pybind11&lt;/item&gt;
      &lt;item&gt;Instant: Add members/methods ‚Üí automatically bound&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Methodology: 5 runs per test, median ¬± stddev reported, identical optimization flags (&lt;code&gt;-O3 -DNDEBUG&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;For even faster builds, use precompiled headers to cache the Mirror Bridge infrastructure:&lt;/p&gt;
    &lt;code&gt;# One-time: Build PCH (takes ~600ms, reuse forever)
./mirror_bridge_build_pch -o build -t release

# Every build: Use PCH for 3-6x faster compilation
mirror_bridge_auto src/ --module my_module --use-pch build/mirror_bridge_pch.hpp.gch&lt;/code&gt;
    &lt;p&gt;Performance with PCH:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple project: 567ms ‚Üí 194ms (66% faster, 2.9x speedup)&lt;/item&gt;
      &lt;item&gt;Medium project: 1580ms ‚Üí 252ms (84% faster, 6.3x speedup)&lt;/item&gt;
      &lt;item&gt;One-time cost: ~600ms to build PCH (amortized across all builds)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Shared across projects - build PCH once, use everywhere&lt;/item&gt;
      &lt;item&gt;‚úÖ Debug/Release PCH - separate PCH for different build configurations&lt;/item&gt;
      &lt;item&gt;‚úÖ Zero code changes - just add &lt;code&gt;--use-pch&lt;/code&gt;flag&lt;/item&gt;
      &lt;item&gt;‚úÖ Automatic detection - &lt;code&gt;mirror_bridge_auto&lt;/code&gt;finds PCH automatically&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Complete guide: See PCH_GUIDE.md and WORKFLOW_GUIDE.md&lt;/p&gt;
    &lt;p&gt;Test suite: Run &lt;code&gt;./tests/test_pch.sh&lt;/code&gt; to verify PCH infrastructure&lt;/p&gt;
    &lt;p&gt;Run comprehensive tests yourself:&lt;/p&gt;
    &lt;code&gt;./run_benchmarks.sh&lt;/code&gt;
    &lt;p&gt;See benchmarks/FINAL_RESULTS.md for complete results and analysis.&lt;/p&gt;
    &lt;p&gt;This is an experimental project exploring C++26 reflection. Contributions welcome!&lt;/p&gt;
    &lt;p&gt;Areas needing work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extended parameter support for methods&lt;/item&gt;
      &lt;item&gt;Template class handling&lt;/item&gt;
      &lt;item&gt;Additional backends (Rust, Lua)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache License 2.0 - See LICENSE for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bloomberg's clang-p2996 - P2996 reflection implementation&lt;/item&gt;
      &lt;item&gt;P2996 Reflection Proposal&lt;/item&gt;
      &lt;item&gt;simdjson - Concept-based design inspiration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Status: Experimental - C++26 reflection is not yet supported on all C++ compilers. This project uses Bloomberg's clang-p2996 implementation.&lt;/p&gt;
    &lt;p&gt;Yes, method binding works! See calculator tests for full examples.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46144331</guid><pubDate>Thu, 04 Dec 2025 06:12:23 +0000</pubDate></item><item><title>Saturn (YC S24) Is Hiring Senior AI Engineer</title><link>https://www.ycombinator.com/companies/saturn/jobs/R9s9o5f-senior-ai-engineer</link><description>&lt;doc fingerprint="9b8e9e540cf160ea"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;Why Saturn?&lt;/head&gt;
      &lt;p&gt;Saturn is revolutionizing financial services with AI, building the operating system for financial advisors. Our mission is to democratize financial advice for one billion people by providing the world's most trusted, intelligent platform for financial planning and compliance.&lt;/p&gt;
      &lt;p&gt;This is a rare chance to build a category-defining company in a high-stakes, regulated environment. We operate with a Dual Mandate: relentless Speed of Execution to deliver reliable, robust products today, and dedicated Speed of Learning to explore the frontier of AI and unlock the next generation of features.&lt;/p&gt;
      &lt;p&gt;If you are driven by the pursuit of greatness, thrive on end-to-end ownership, and want to build the gold standard for AI trust and reliability, we invite you to build with us.&lt;/p&gt;
      &lt;head rend="h3"&gt;Role Overview&lt;/head&gt;
      &lt;p&gt;As a Senior AI Engineer at Saturn, you are the single-threaded owner of critical, customer-facing AI features that form the backbone of the advisory operating system. This is a highly autonomous role requiring robust software engineering fundamentals, deep LLM intuition, and an obsessive focus on product quality in a regulated domain.&lt;/p&gt;
      &lt;p&gt;You will own the entire feature lifecycle: from defining the Gold Standard with our domain experts (Guardians), architecting the agentic workflow, designing and building the comprehensive evaluation suites, to deploying and operating the solution reliably in production. You are expected to move quickly, making pragmatic, data-backed decisions that drive measurable value.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You'll Do&lt;/head&gt;
      &lt;p&gt;1. End-to-End Feature Ownership and Architecture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Ownership: Take complete ownership of a product domain or complex feature, making architectural decisions independently and delivering high-quality results from concept through to long-term maintenance.&lt;/item&gt;
        &lt;item&gt;Defensive Design: Architect and implement fault-tolerant AI systems, incorporating robust fallbacks (via a model-agnostic gateway), retries, and comprehensive monitoring and tracing, driven by the Will to Care about system reliability.&lt;/item&gt;
        &lt;item&gt;Explicit Orchestration: Design and deploy complex, multi-step AI agents using explicit orchestration frameworks, ensuring state transitions are visible, testable, and auditable.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;2. Drive Evaluation and Quality Discipline:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Design Evaluation Strategy: Design, implement, and maintain the comprehensive, systematic evaluation framework (Evals Flywheel) specifically for your features to rigorously measure performance, manage regressions, and ensure quality compounds over time.&lt;/item&gt;
        &lt;item&gt;Domain Partnership: Work directly with our domain experts to translate complex financial and compliance requirements into executable evaluation rubrics and Gold Standard datasets.&lt;/item&gt;
        &lt;item&gt;Quality Feedback Loop: Instrument features end-to-end to rapidly diagnose probabilistic failures, converting production issues into high-priority regression tests.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;3. Elevate Engineering Standards:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Technical Excellence: Write clean, modular, Python code that raises the bar for the team. Actively participate in code review, using the process to mentor peers and reinforce architectural standards.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What You Have&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;5+ years of professional experience in a highly demanding engineering environment.&lt;/item&gt;
        &lt;item&gt;Proven track record (3+ years) of building, shipping, and operating scaled, impactful products where Generative AI or LLMs are a core component.&lt;/item&gt;
        &lt;item&gt;Deep Experience with Agentic Systems: Expertise in RAG pipelines, systematic prompt engineering, agentic workflow orchestration, and defining reliability trade-offs for production systems.&lt;/item&gt;
        &lt;item&gt;Evaluation Focus: Direct, demonstrable experience designing, writing, and maintaining automated evaluation frameworks (&lt;code&gt;evals&lt;/code&gt;) used to rigorously test and improve probabilistic systems.&lt;/item&gt;
        &lt;item&gt;End-to-End Ownership: A history of thriving in ambiguity, taking complete ownership of large features, and driving initiatives forward independently with a strong bias for action.&lt;/item&gt;
        &lt;item&gt;Engineering Excellence: Mastery of Python and modern backend development practices, including system design, testing, CI/CD, and robust production observability.&lt;/item&gt;
        &lt;item&gt;Product &amp;amp; User Focus: Strong product sense and the drive to quickly build domain expertise, translating user needs and compliance context into high-value technical solutions (the expression of Will to Care for the customer).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Saturn Values in Practice:&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Earn Trust: Building verifiably correct, explainable systems (Citation-First, Adviser-in-the-Loop).&lt;/item&gt;
        &lt;item&gt;Pursue Greatness: Driving our Evaluation-Driven Development flywheel to compound quality daily.&lt;/item&gt;
        &lt;item&gt;Seek Truth: Relying on data, traces, and customer feedback (Guardians) to inform every decision.&lt;/item&gt;
        &lt;item&gt;Be Audacious: Taking decisive ownership and building intelligent agents that solve previously unsolvable problems in finance.&lt;/item&gt;
        &lt;item&gt;Will to Care: Obsessively anticipating customer needs and building systems with extreme attention to detail, ensuring long-term quality, reliability, and the success of our users and peers.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46144613</guid><pubDate>Thu, 04 Dec 2025 07:00:51 +0000</pubDate></item><item><title>The Mysterious Realm of JavaScriptCore (2021)</title><link>https://www.cyberark.com/resources/threat-research-blog/the-mysterious-realm-of-javascriptcore</link><description>&lt;doc fingerprint="e200b11260b513b0"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;JavaScriptCore (JSC) is the JavaScript engine used by Safari, Mail, App Store and many other apps in MacOs. The JSC engine is responsible for executing every line of JavaScript (JS) that needs to be executed, whenever we browse to a new website or simply send/receive emails.&lt;/p&gt;
    &lt;p&gt;Finding vulnerabilities in JSC can be intimidating and, in some cases, complicated. In this blog post, we start by learning the fundamentals of JSC. Then, we describe how we developed a tailor-made CodeQL query that uncovers bad side effect modeling vulnerabilities, which could lead to RCE in JSC.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;I‚Äôve always felt intimidated by the fog of war that was laying over the land of browser exploitation. Never have I dared to step foot in there since I thought I was way under-leveled to do so. But, not long ago, I received the magical staff of CodeQL, and now I feel confident enough to explore the realm; I geared up and started my quest! Follow me on this immersive journey to learn the fundamentals of JSC and find some cool (old-school) bugs with CodeQL.&lt;/p&gt;
    &lt;head rend="h3"&gt;Entering the Realm of JSC&lt;/head&gt;
    &lt;p&gt;Goo(gle) the Owl: ‚ÄúCloning the repository might be a good start.‚Äù&lt;lb/&gt; Me: ‚ÄúWaaa! Who are you?‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúYou can call me Goo, the all-knowing Owl. What are you doing here?‚Äù&lt;lb/&gt; Me: ‚ÄúI just got this new staff and figured I should explore this realm a bit.‚Äù [Flashing my CodeQL staff]&lt;lb/&gt; Goo the Owl: ‚ÄúOh nice! I heard about it from 91,500 places (0.43 seconds to search about it). I‚Äôll help you explore the realm ‚Äì seems like a good use of my time.‚Äù&lt;lb/&gt; Me: ‚ÄúThat‚Äôs nice of you.&lt;lb/&gt; Me: [WHISPERING] ‚ÄúShow off.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúWell then, without further ado, let‚Äôs clone WebKit and enter the realm!‚Äù&lt;lb/&gt; Me: git clone https://github.com/WebKit/WebKit.git&lt;lb/&gt; [Falling through a portal]&lt;lb/&gt; Me: ‚ÄúWe‚Äôre in!‚Äù [Looking at THOUSANDS of slimy blobs waiting in line]&lt;lb/&gt; Me: ‚ÄúUgh‚Ä¶ What are these blobs?‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúThese gooey blobs are JavaScript instructions waiting to be executed.‚Äù&lt;lb/&gt; Me: [Confused]&lt;lb/&gt; Goo the Owl: ‚ÄúAllow me to elaborate!‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;JavaScriptCore 101&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWebKit is the web browser engine used by Safari, Mail, App Store, and many other apps on macOS, IOS and Linux.‚Äù ‚Äì WebKit description from https://webkit.org&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;JSC is the built-in JS engine for WebKit, meaning it handles each JS script we execute via our browser. Unlike code written in C, which we initially compile into native code that our processor can run, a virtual machine (JSC, for example) executes JS, and our processor executes the code of that virtual machine.&lt;/p&gt;
    &lt;p&gt;Figure 1 ‚Äì C vs. JavaScript&lt;/p&gt;
    &lt;p&gt;It is well understood that each approach comes with its pros and cons. For example, running a native C function can be a lot faster than executing a similar function written in JS. The reason derives directly from the figure above. JS bytecode must go through another level of execution compared to a pre-compiled programming language, like C.&lt;/p&gt;
    &lt;p&gt;But, since our JS code is running in a virtual machine, we have less room for classic bugs because the virtual machine can do all sorts of checks during runtime and prevent these classic bugs from becoming a problem. Additionally, JS is much more dynamic than C; for instance, we don‚Äôt have to declare the arguments‚Äô types when writing a new function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Instruction Processing&lt;/head&gt;
    &lt;p&gt;Every JS script we‚Äôll execute via JSC will go through several phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lexing (parser/Lexer.cpp) ‚Äì The Lexer will break down our script into a series of tokens. Breaking down our code is done by pre-defined characters (e.gThe parser will then process these tokens.&lt;/item&gt;
      &lt;item&gt;Parsing (parser/JSParser.cpp) ‚Äì The parser will build an abstract syntax tree (AST) from the tokens produced by the Lexer. The syntax tree represents our code‚Äôs structural details, meaning each node in our tree represents an expression in our code. For example, a node can represent the expression ‚Äúa + b‚Äú; the child of this expression will be the ‚Äú+‚Äù operation, and its children will be the variables ‚Äúa‚Äù and ‚Äúb.‚Äú&lt;/item&gt;
      &lt;item&gt;Low-Level Interpreter (LLInt) ‚Äì At this phase, we already have a syntax tree representing our code. The LLInt will create bytecode that JSC can execute using the processor. For example, the expression ‚Äúa+b‚Äù we‚Äôve mentioned earlier is translated to bytecode that consists of the following offline assembly opcodes:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;add loc3, loc1, loc2, OperandTypes(126, 126)&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This is merely adding loc1 with loc2 and saving the result in loc3. The OperandTypes holds metadata about the predicated types of loc1 and loc2.&lt;/p&gt;
    &lt;p&gt;Figure 2 ‚Äì The primary stages of JavaScript code goes through&lt;/p&gt;
    &lt;head rend="h3"&gt;JS Can Go FAST&lt;/head&gt;
    &lt;p&gt;While we mentioned earlier that there are only three stages in executing a JS instruction, reality suggests there are more stages. Browsers run thousands of lines of JS code on an average website, and usually, there are JS instructions that are in use in a much higher frequency than others. If we only had three stages as mentioned above, we would have to repeatedly execute the same instruction through the virtual machine, which causes a lot of unnecessary overhead. Therefore, JSC (and every other JS engine) uses Just-In-Time (JIT) compilation!&lt;/p&gt;
    &lt;p&gt;In case you‚Äôre not familiar with the concept, JIT compilation is the process of compiling a piece of code at runtime instead of the conventional way before execution. In our scenario, JSC will compile often-used instructions to native code that can be executed by our processor instead of compiling these instructions to bytecode run by the virtual machine.&lt;/p&gt;
    &lt;p&gt;This way, these often-used instructions now run with much lower overhead than before. One might say: ‚ÄúIf the overhead is a lot lower now, why not JIT compile every instruction?‚Äù&lt;/p&gt;
    &lt;p&gt;And the answer to this question is straightforward: The process of JIT compiling is expensive (runtime speaking).&lt;/p&gt;
    &lt;p&gt;JSC creates a profile for each instruction using the LLInt (and other components mentioned later in this blog). Such profiling allows the engine to know which operations are used more often and to JIT to compile them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four Levels of JSC&lt;/head&gt;
    &lt;p&gt;We have discussed the basic workflow of executing instructions in JSC. Now it‚Äôs time to turn it up a notch. JSC executes instructions in four different tiers. As the rank of the tier goes up, the overhead of running that instruction goes down.&lt;/p&gt;
    &lt;p&gt;Instructions tier can level up/down during runtime. JSC holds an ‚Äúexecution counter‚Äù for each instruction, and each time we‚Äôll execute that operation, JSC will add more points to their counter.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leveling up to the second tier requires 500 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the third tier requires 1,000 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the fourth tier requires 100,000 points&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The transition between tiers is linear. For example, to move from tier level 1 to tier level 3, the instruction must traverse through tier level 2 and only then to tier 3.&lt;/p&gt;
    &lt;p&gt;The four tiers are:&lt;/p&gt;
    &lt;p&gt;1. LLInt ‚Äì The low-level interpreter, as mentioned earlier, this tier will compile JS instructions into bytecode.&lt;/p&gt;
    &lt;p&gt;2. Baseline JIT (500 points) ‚Äì As the name might suggest, instructions that are executed under this tier will become JIT-ed. The baseline JIT compiles bytecode operations into native code using a template for each operation. There is no additional logic regarding the relation between other instructions or what‚Äôs on ‚Äì only the template.&lt;/p&gt;
    &lt;p&gt;3. Data Flow Graph (DFG) JIT (1,000 points) ‚Äì The DFG JIT has an intermediate representation (IR) that is later used by the DFG JIT compiler. The IR will translate the implemented code of a JS instruction into a data-flow graph (see example below). The DFG JIT compiler can now perform complex optimizations that have to do with the code‚Äôs flow. For example, let‚Äôs take a look at the following JS code snippet:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg) { return this.y * arg[0]; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; By calling Foo in a loop with approximately 1,000 iterations, we can force JSC to compile Foo into DFG JIT. To see the actual DFG IR produced for this code snippet, we can run the following line:&lt;/p&gt;
    &lt;quote&gt;JSC_dumpGraphAtEachPhase=true ./WebKitBuild/Debug/bin/jsc ../dfgMe.js&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The output from this command line contains hundreds of lines, and to keep things as simple as possible, we created a flow graph that represents the DFG IR produced by JSC:&lt;/p&gt;
    &lt;p&gt;Figure 3 ‚Äì Representing the short function Foo as a Data Flow Graph&lt;/p&gt;
    &lt;p&gt;OSRExit is a mechanism that allows JSC to downgrade the instruction‚Äôs tier. This is useful in the event that we add more optimizations to the execution process, i.e. we tell JSC to speculate more about what the operation can do.&lt;/p&gt;
    &lt;p&gt;For instance, JSC will speculate that the use of multiplication here is done by multiplying two integers. In reality, multiplying two integers is much less complicated than multiplying two objects, for example. Therefore, by speculating the argument types, JSC can add more impressive optimizations. In case JSC has been mistaken and guessed incorrectly, and the arguments types are not integers, JSC will perform OSRExit and level down the tier. This way, the new lower tier might have a more significant overhead, but the necessary checks will now remain.&lt;/p&gt;
    &lt;p&gt;4. Faster than Light (FTL) JIT (100,000 points) ‚Äì Unlike the DFG JIT compiler, the FTL JIT focuses on optimizations regardless of how expensive the optimizing process might be. The FTL JIT reuses the optimizations that were done by the DFG JIT and will add many more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to the Realm&lt;/head&gt;
    &lt;p&gt;Me: ‚ÄúOhh.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúAnd these blobs are going straight to the LLInt.‚Äù&lt;lb/&gt; Me: ‚ÄúOof.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúThis is literally the shortest summary I could give on JSC.‚Äù&lt;lb/&gt; Me: ‚ÄúI understand why I never came here.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúWanna go back?‚Äù&lt;lb/&gt; Me: ‚ÄúNo way, too committed by now. Let‚Äôs follow the blobs to the LLInt!‚Äù [Following the blobs]&lt;lb/&gt; Me: ‚ÄúI‚Äôve noticed that when certain blobs slide through the LLInt, other blobs cut the line and slide before everyone else! Not cool‚Ä¶‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúCalm down, manners police. These blobs cut the line because they have to.‚Äù&lt;lb/&gt; Me: ‚ÄúWhat do you mean, ‚Äòhave to‚Äô?‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúSome instruction blobs cause side effects. This is perfectly normal in JS.‚Äù&lt;lb/&gt; Me: ‚ÄúSide effects? Sounds malicious to me.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúAs I said earlier, this is PERFECTLY NORMAL. Side effects in JS are‚Ä¶‚Äù&lt;lb/&gt; [QUICK CUT TO GOO ELABORATING ON SIDE EFFECTS IN JS]&lt;/p&gt;
    &lt;head rend="h3"&gt;Side Effects In JS&lt;/head&gt;
    &lt;p&gt;A JS operation causes side effects if it modifies the state of other variables outside the local environment of that instruction.&lt;/p&gt;
    &lt;p&gt;For instance, in JS, we can concatenate a string with a JS Object like this:&lt;/p&gt;
    &lt;quote&gt;let a = "Hello" + {} // a is now "Hello{}"&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This concatenation will fail in most program languages, but not in JS. JSC will try to convert unique types (such as JSObject) to a primitive type (e.g. String). Let‚Äôs take a look at the function ‚ÄújsAdd,‚Äù which is the implementation of the ‚Äú+‚Äù operator:&lt;/p&gt;
    &lt;quote&gt;ALWAYS_INLINE JSValue jsAdd(JSGlobalObject* globalObject, JSValue v1, JSValue v2) { if (v1.isNumber() &amp;amp;&amp;amp; v2.isNumber()) return jsNumber(v1.asNumber() + v2.asNumber()); return jsAddNonNumber(globalObject, v1, v2); }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; As we can see, if we try to add two numbers, JSC will simply add them and will return the value; otherwise, JSC calls the function jsAddNonNumber. The figure below represents the flow of jsAddNonNumber, while the input is . Each color represents the context of execution:&lt;/p&gt;
    &lt;p&gt;Figure 4 ‚Äì The code flow of jsAddNonNumber while adding a String with a JSObject&lt;/p&gt;
    &lt;p&gt;We can see that jsAddNonNumber checks the types of the arguments (in our case, arg1 is a String and arg2 is a JSObject) and then tries to convert them into primitive types (e.g., String, Number).&lt;/p&gt;
    &lt;p&gt;By setting the property ‚ÄútoString‚Äù in our object (second argument), we could cause JSC to run arbitrary JS code that is not part of the conventional flow of the add operator, i.e., side effect:&lt;/p&gt;
    &lt;quote&gt;let myObj = {'toString' : function(){print("side-effect here"); return "myX";}}; let a = "Hello " + myObj // this will print "side-effect here" // a is "Hello myX"&lt;/quote&gt;
    &lt;head rend="h3"&gt;DFG Optimizations: Redundancy Elimination&lt;/head&gt;
    &lt;p&gt;A widespread DFG JIT optimization is called redundancy elimination. The goal of this optimization is to eliminate redundant guards when compiling an instruction into DFG. To determine which guards are redundant, JSC needs to know which instructions can cause side effects and under which terms (e.g., concerning the argument types passed to the operations). This way, guards that appear before and after an instruction that can‚Äôt cause side effects will be considered redundant.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs look at the following example:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg){ return arg.someProp / arg.otherProp; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The flow graph that represents this function will look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 5 ‚Äì Phase 1 ‚Äì Representing the function from above as DFG before removing redundant guards&lt;/p&gt;
    &lt;p&gt;You might notice that JSC checks that our argument is a valid object twice, before and after fetching for the property ‚ÄúsomeProp.‚Äù This guard makes sure that we still access a JS object before fetching a property from an object. In case JSC has successfully fetched the property ‚ÄúsomeProp,‚Äù the second check is redundant since there are no possible side effects between the first fetch to the second one. Therefore, the graph will then look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 6 ‚Äì Phase 2 ‚Äì Representing the function from above as DFG after removing redundant guards&lt;/p&gt;
    &lt;p&gt;Since this optimization removes unnecessary guards, JSC must determine in a rigorous way which guards are redundant.&lt;/p&gt;
    &lt;p&gt;So, to avoid these vulnerable scenarios, JSC does precise modeling for each JS operation. The side effect modeling is in the file DFGAbstractInterpreterInlines.h under the function executeEffects. This function holds a (HUGE) switch case that determines which operation could\could not cause side effects and under which terms. Whenever JSC calls clobberWorld, it assumes that the operation can execute side effects:&lt;/p&gt;
    &lt;p&gt;Figure 7 ‚Äì Basic side effects modeling in JSC (DFGAbstractInterpreterInlines.h/executeEffects). Each case represents the operation‚Äôs code (opcode)&lt;/p&gt;
    &lt;head rend="h3"&gt;Bad Side Effect Modeling: InstanceOf Vulnerability&lt;/head&gt;
    &lt;p&gt;A good use case that shows the risk potential of bad side effect modeling in JSC is the following bug. It was fixed in May 2018 right after commit 3b45a2433371160871a07d288b119b2454e3db19 (which is the last commit vulnerable to this bug). The patch to that vulnerability is quite simple:&lt;/p&gt;
    &lt;p&gt;Figure 8 ‚Äì Patching the bug by letting JSC know that the operation instanceOf can cause side effects&lt;/p&gt;
    &lt;p&gt;This simple patch suggests that this bug has something to do with bad side effect modeling.&lt;/p&gt;
    &lt;p&gt;With the help of maxpl0it, we can review the exploit that triggers this bug:&lt;/p&gt;
    &lt;quote&gt;class EmptyClass { }; var a = [13.37]; function TriggerClass() { }; var leakme = {}; var trigger = false; var handler = { getPrototypeOf(){ if (trigger){ a[0] = leakme; } return EmptyClass.prototype; }, }; TriggerClass.prototype = new Proxy({}, handler); function addrof(obj){ var toggle = true; function addrof_internal(array){ var _ = (new TriggerClass()) instanceof EmptyClass return array[0]; } for (var i = 0; i &amp;lt; 10000; i++){ addrof_internal(a); } trigger = true; return addrof_internal(a); } print(addrof(leakme));&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The exploit uses classic JSC exploit primitives (leaking addresses using type confusion caused by a bug, AKA, addrof\fakeobj) initially discovered by and mapped out in this great Oct. 2016 article. This exploit implements the function addrof that allows leaking JS object addresses.&lt;/p&gt;
    &lt;p&gt;From the patch, we can deduct that the operation ‚ÄúInstanceOf‚Äù wasn‚Äôt modeled correctly for side effects, but the real question is: why instanceOf can trigger side effects?&lt;/p&gt;
    &lt;p&gt;Well, the answer to that question lies in the exploit! We can see that by creating a proxy object that handles the function ‚ÄúgetPrototypeOf,‚Äù we can trigger side effects. The operation that implements the JS instruction instanceOf is operationDefaultHasInstance.&lt;/p&gt;
    &lt;quote&gt;size_t JIT_OPERATION operationDefaultHasInstance(ExecState* exec, JSCell* value, JSCell* proto) // Returns jsBoolean(True|False) on 64-bit. { ‚Ä¶ }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Note: The parameter ‚Äúvalue‚Äù corresponds with the new instance of TriggerClass we create under ‚Äúaddrof_internal.‚Äù&lt;/p&gt;
    &lt;p&gt;The following flow chart describes why operationDefaultHasInstance causes side effects:&lt;/p&gt;
    &lt;p&gt;Figure 9 ‚Äì Showing why OperationDefaultHasInstance can cause side effects&lt;/p&gt;
    &lt;p&gt;Fetching for the object prototype, without any guards or checks, allows us to replace the initial object (in our case, TriggerClass) into a proxy object. By doing so, we can replace the function getPrototypeOf with our own arbitrary JS code, AKA side effects.&lt;/p&gt;
    &lt;head rend="h2"&gt;CodeQL Magic&lt;/head&gt;
    &lt;p&gt;[CodeQL Staff shines with bright blue light]&lt;lb/&gt; Goo the Owl: ‚ÄúWhat‚Äôs happening?! Is it going to explode?! I‚Äôm way too young to d‚Ä¶‚Äù&lt;lb/&gt; Me: ‚ÄúIt‚Äôs not going to explode‚Ä¶ -_-‚Äù&lt;lb/&gt; Me: ‚ÄúIt found potential in what you‚Äôve said earlier.‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúPotential? What do you mean?‚Äù&lt;lb/&gt; Me: ‚ÄúWell, you have explained pretty thoroughly about the whole bad side effect modeling, right?‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúYeah, so what?‚Äù&lt;lb/&gt; Me: ‚ÄúWhat if we could use my CodeQL staff to find more bugs like this one in the realm?‚Äù&lt;lb/&gt; Goo the Owl: ‚ÄúThat would be awesome.‚Äù&lt;lb/&gt; Me: ‚ÄúI think so too, and I think that this is what the staff wants me to do.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;CodeQL: Finding Bad Side Effect Modeling Vulnerabilities in JSC&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúCodeQL is a framework developed by Semmle and is free to use on open-source projects. It lets a researcher perform variant analysis to find security vulnerabilities by querying code databases generated using CodeQL, which supports many languages such as C/C++, C#, Java, JavaScript, Python and Golang.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just in case you haven‚Äôt heard about CodeQL yet, I highly recommend reading my previous blog post, which dives into CodeQL and its capabilities.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs try to write a CodeQL query that will find bad side effects modeling vulnerabilities in JSC. To begin with, here is a rough description of the bug:&lt;/p&gt;
    &lt;p&gt;A JS operation might be exposed to a bad side effect modeling bug if:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Under the case that represents the operation in executeEffects (DFGAbstractInterpreterInlines.h), there is no call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;The operation causes side effect.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The best tip we can give you before writing CodeQL queries is to work as organized as possible. As your query‚Äôs complexity becomes higher, there is more room for it to fail somehow. Although this is probably true for every coding project you‚Äôve worked on, debugging CodeQL queries can be much more difficult, since we don‚Äôt have classic debugging methods and tools that some of you might be familiar with (CodeQL simply doesn‚Äôt have any).&lt;/p&gt;
    &lt;p&gt;Let‚Äôs start by determining what data we need to extract with CodeQL to recognize the bugs we wish to find. The description of the bug above gives us a hint regarding what information we need to collect. After reading and analyzing the code, we created a diagram that shows which component does what in the JSC side effect modeling, and how the elements are linked&lt;/p&gt;
    &lt;p&gt;Then, I added an example to a possible side effect that an operation might have (same side effect as we showed in the InstanceOf bug, above):&lt;/p&gt;
    &lt;p&gt;Figure 10 ‚Äì This diagram shows the logical connection between each component in JSC responsible for side effect modeling&lt;/p&gt;
    &lt;p&gt;With this diagram, we can start writing some CodeQL classes. Classes in CodeQL let you inherit from native CodeQL objects (e.g., VariableAccess, Function, Expr) and add layers of complexity such as additional predicates and properties. The first class we created is named ClobberWorldCall, which inherits from the CodeQL class FunctionCall.&lt;/p&gt;
    &lt;p&gt;Ideally, this class will model side effects by analyzing each call to clobberWorld under executeEffects. Let‚Äôs review some key features from that class:&lt;/p&gt;
    &lt;quote&gt;import cpp import helperFunctions class ClobberWorldCall extends FunctionCall{ string opCode; string strictTypeConstraintsNode1; string strictTypeConstraintsNode2; string strictTypeConstraintsNode3; string looseTypeConstraintsNode1; string looseTypeConstraintsNode2; string looseTypeConstraintsNode3; // string operandType; ClobberWorldCall() { this.getTarget().hasName("clobberWorld") and exists ( Function executeEffects | executeEffects.hasName("executeEffects") and this.getEnclosingFunction() = executeEffects ) and // Extracting the op code for each call (e.g., ValueAdd, InstanceOf) opCode = getOpForClobberWorld(this) and // Extracting the strict and loose types getStrictTypeConstraints(this, strictTypeConstraintsNode1, strictTypeConstraintsNode2, strictTypeConstraintsNode3) and getLooseTypeConstraints(this, looseTypeConstraintsNode1, looseTypeConstraintsNode2, looseTypeConstraintsNode3) } ‚Ä¶ }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Although this class seems short, a lot is going on inside it.&lt;/p&gt;
    &lt;p&gt;Our first predicate is quite simple ‚Äì we look for all the calls to clobberWorld under executeEffects.&lt;/p&gt;
    &lt;p&gt;Then, we call our custom predicate getOpForClobberWorld, which works as follows:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get the basic block that contains the call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;If that basic block is under a case, return the case name (the case name is the operation code (for example, ValueAdd).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After that, we call getStrictTypeConstraints, followed by a call to getLooseTypeConstraints, which was the most difficult bit to write.&lt;/p&gt;
    &lt;p&gt;To be as accurate and efficient as possible, JSC will sometimes call clobberWorld when specific argument types are passed to the operation. For example, adding two numbers in JS won‚Äôt cause side effects, but adding two objects may cause side effects. If JSC called clobberWorld when we simply call the add operation, it wouldn‚Äôt be efficient. So, JSC will check the argument types and only then decide whether it should call clobberWorld or not.&lt;/p&gt;
    &lt;p&gt;This is exactly where getStrictTypeConstraints and getLooseTypeConstraints come in handy.&lt;/p&gt;
    &lt;p&gt;Here is a snippet from the code that checks for strict constraints:&lt;/p&gt;
    &lt;quote&gt;string getStrictTypeForClobberWorldChild(FunctionCall clobberWorld){ if ( isClobberInsideSwitchCaseOrIfStatement(clobberWorld) = true ) then ( exists ( SwitchCase case, SwitchStmt st, FunctionCall call | st = getInnerSwitchStatement(clobberWorld, "useKind") and st.getExpr() = call and call.getQualifier().(FunctionCall).getTarget().hasName("child1") and case.getSwitchStmt() = st and case.getASuccessor*() = clobberWorld and result = case.getExpr().toString() ) or ‚Ä¶ else result = "noTypeConstraintsFound" }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; In this snippet, we see that we first check if the call to clobberWorld is under a (specific) Switch Case or an ‚Äúif‚Äù statement.&lt;/p&gt;
    &lt;p&gt;If it is, then we analyze that very switch case/if statement.&lt;/p&gt;
    &lt;p&gt;In this example, we analyze the switch case. JSC can obtain argument types by several methods. For example, one of them is by calling the function useKind, which returns the argument type (mind-blowing). Our code from above should handle these types of cases:&lt;/p&gt;
    &lt;quote&gt;case ArithClz32: { ‚Ä¶ switch (node-&amp;gt;child1().useKind()) { case Int32Use: case KnownInt32Use: break; default: clobberWorld(); break; } setNonCellTypeForNode(node, SpecInt32Only); break; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Once we finished writing the clobberWorldCall class, we could confidently move on to the next class, dfgOperation.&lt;/p&gt;
    &lt;p&gt;Knowing exactly when JSC calls clobberWorld is not enough to ultimately model operations for side effects. Under the function executeEffects, there is no reference to the actual operation that holds the code we wish to analyze. All we have is the operation code, taken from the switch case under executeEffects.&lt;/p&gt;
    &lt;p&gt;So, in our next step, we will link the opcode (operation code) to the operation‚Äôs code under the hood. Once we can link these two, we can start analyzing the operation itself and look for possible side effects.&lt;/p&gt;
    &lt;quote&gt;class DfgOperation extends Function{ SwitchCase dfgEffectCase; FunctionCall dfgCallOperation; Function dfgCompile; string opCode; boolean isClobberWorldCalled; DfgOperation() { // Link the dfgOperation to the dfgCallOperation/dfgSlowCallOperation ( ( dfgCallOperation.getTarget().hasName("callOperation") and dfgCallOperation.getArgument(0) = this.getAnAccess() ) or ( dfgCallOperation.getTarget().hasName("slowPathCall") and dfgCallOperation.getArgument(2) = this.getAnAccess() ) ) and dfgCompile = getSpeculativeJitCompile() // We have 2 known options (all happens under the function SpeculativeJIT::compile): // 1) We call directly to the callOperation from the switch case // 2) We call to a wrapper function named compileSomeOperation from the switch case and ( opCode = getOpCodeSimpleCase(dfgCallOperation) or opCode = getOpCodeByCompileOperation(dfgCallOperation) ) and ‚Ä¶ // Find if ClobberWorld is called ‚Äì Actual Linking Stage and if exists ( ClobberWorldCall clobber | clobber.getAnOpCode() = opCode ) then isClobberWorldCalled = true else isClobberWorldCalled = false } ‚Ä¶ }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Using the figure 10 diagram presented above, we understand that JSC can call an operation using the function callOperation or compile the operation and then call it.&lt;/p&gt;
    &lt;p&gt;So, in our query we first locate all the calls to callOperation/compileOperation, and then, similarly to the clobberWorldCall class, we find the operation code using switch cases or if statements.&lt;/p&gt;
    &lt;p&gt;Once that is done, we can safely link between the clobberWorld calls to the JS operations.&lt;/p&gt;
    &lt;p&gt;Finally, we need to choose which side effects we‚Äôre looking for because there are a few options. Since we reviewed earlier the bug in the operation InstanceOf, let‚Äôs look for all side effects caused by confusion with proxy objects (we recommend reading the comments):&lt;/p&gt;
    &lt;quote&gt;from FunctionCall fc, VariableAccess jsObjectAccess, Parameter source, DfgOperation operation, Expr asObjArg, Function compareTo where // Extract all accesses to JSObjects isJsObject(jsObjectAccess.getTarget()) and // fc represents all the function calls from a JSObject fc.getQualifier() = jsObjectAccess and // Find functions from ProxyObject that share the function name as fc exists ( Function fromProxy | fromProxy.getParentScope().toString() = "ProxyObject" and compareTo.getName() = fromProxy.getName() and fc.getTarget() = getFunctionWrappers(compareTo) ) and // Make sure JSC does not call clobberWorld for that operation operation.hasACallToClobberWorld() = false and operation.getAParameter() = source and exists // Search for the following flow: // from: operation parameter // to: Converting the parameter to JSObject // or // The parameter is already a JSObject // to: Calling a function from that parameter that exists under ProxyObject and JSObject ( LinkOperationToExecVM config, FunctionCall asObject, ConvertToObjectAndCall config2| ( ( asObject.getTarget().hasName("asObject") or asObject.getTarget().hasName("toObject") ) and asObject.getAnArgument() = asObjArg and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) and config2.hasFlow(DataFlow::exprNode(asObject), DataFlow::exprNode(jsObjectAccess)) ) or ( asObjArg = jsObjectAccess.getTarget().getAnAccess() and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) ) ) select operation, source, fc, compareTo&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Executing this query against a code database created from commit 35b181a20dc25749df383041f950798bd109f47d produced the following results:&lt;/p&gt;
    &lt;p&gt;Figure 11 ‚Äì Results from our final query. The left column holds the names of the operations. The middle column shows which argument causes the side effects, and the right column shows which function we should hook using a proxy object.&lt;/p&gt;
    &lt;p&gt;We can see that there are five operations suspected to be bugs, and one of them is the bug we studied earlier ‚Äì great!&lt;/p&gt;
    &lt;p&gt;Digging deeper through the results revealed a second bad side effects modeling vulnerability, CVE-2018-4233. The vulnerable operation is operationCreateThis. This vulnerability was found and exploited by Samuel Gro√ü in pwn2own 2018. Samuel talked about this vulnerability in his Black Hat 2018 conference talk.&lt;/p&gt;
    &lt;p&gt;We‚Äôve managed to find two critical vulnerabilities in JSC that could lead to RCE using a tailor-made CodeQL query. Running that query against a codebase created from an updated version of JSC shows that the two vulnerabilities previously found by our query no longer exist, meaning they were indeed patched. Keep in mind that it does not mean that there are no more vulnerabilities caused by bad side effect modeling. Adding small changes to our query will allow us to determine what kind of side effects we are looking for, and there could be lots of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What a journey we‚Äôve had. Thanks to you, the realm is a lot safer now.&lt;/p&gt;
    &lt;p&gt;The truth is, I‚Äôve been playing with CodeQL for the past year and I‚Äôve been focused on finding classic vulnerabilities (in my previous blog, I focused on finding vulnerable calls to memcpy with CodeQL). This time, I wanted to see how effective it is to use CodeQL to find much-complicated vulnerabilities in large and tangled projects like WebKit.&lt;/p&gt;
    &lt;p&gt;I knew that this would not be an easy task, and indeed it wasn‚Äôt. But the most challenging part was learning and understanding the internals of JSC and not (as I initially thought) writing the query in CodeQL.&lt;/p&gt;
    &lt;p&gt;Once I had gained enough knowledge about the bugs I wanted to find, writing the query was pretty intuitive (I do have some experience with CodeQL by now, but still‚Ä¶) and fun.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links &amp;amp; References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;http://www.phrack.org/issues/70/3.html&lt;/item&gt;
      &lt;item&gt;https://liveoverflow.com/getting-into-browser-exploitation-new-series-introduction-browser-0x00/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/10308/speculation-in-javascriptcore/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/6411/javascriptcore-csi-a-crash-site-investigation-story/&lt;/item&gt;
      &lt;item&gt;https://saelo.github.io/presentations/blackhat_us_18_attacking_client_side_jit_compilers.pdf&lt;/item&gt;
      &lt;item&gt;https://zon8.re/posts/jsc-internals-part1-tracing-js-source-to-bytecode/&lt;/item&gt;
      &lt;item&gt;https://github.com/assafsion/javascriptcore-bad-side-effect-modeling&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46145154</guid><pubDate>Thu, 04 Dec 2025 08:33:33 +0000</pubDate></item><item><title>Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs</title><link>https://arxiv.org/abs/2512.04047</link><description>&lt;doc fingerprint="849e200a55f594ac"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Economics &amp;gt; General Economics&lt;/head&gt;&lt;p&gt; [Submitted on 3 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;econ.GN&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46145180</guid><pubDate>Thu, 04 Dec 2025 08:38:17 +0000</pubDate></item></channel></rss>