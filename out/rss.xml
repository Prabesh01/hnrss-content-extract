<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 20 Sep 2025 19:05:59 +0000</lastBuildDate><item><title>MapSCII ‚Äì World Map in Terminal</title><link>https://github.com/rastapasta/mapscii</link><description>&lt;doc fingerprint="ecc3b87ab9807886"&gt;
  &lt;main&gt;
    &lt;p&gt;A node.js based Vector Tile to Braille and ASCII renderer for xterm-compatible terminals.&lt;/p&gt;
    &lt;code&gt;$ telnet mapscii.me&lt;/code&gt;
    &lt;p&gt;If you're on Windows, use the open source telnet client PuTTY to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use your mouse to drag and zoom in and out!&lt;/item&gt;
      &lt;item&gt;Discover Point-of-Interests around any given location&lt;/item&gt;
      &lt;item&gt;Highly customizable layer styling with Mapbox Styles support&lt;/item&gt;
      &lt;item&gt;Connect to any public or private vector tile server&lt;/item&gt;
      &lt;item&gt;Or just use the supplied and optimized OSM2VectorTiles based one&lt;/item&gt;
      &lt;item&gt;Work offline and discover local VectorTile/MBTiles&lt;/item&gt;
      &lt;item&gt;Compatible with most Linux and OSX terminals&lt;/item&gt;
      &lt;item&gt;Highly optimized algorithms for a smooth experience&lt;/item&gt;
      &lt;item&gt;100% pure JavaScript! üòé&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With a modern node installation available, just start it with&lt;/p&gt;
    &lt;code&gt;npx mapscii
&lt;/code&gt;
    &lt;p&gt;If you haven't already got Node.js &amp;gt;= version 10, then go get it.&lt;/p&gt;
    &lt;code&gt;npm install -g mapscii
&lt;/code&gt;
    &lt;p&gt;If you're on OSX, or get an error about file permissions, you may need to do &lt;code&gt;sudo npm install -g mapscii&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;In any of the supported Linux distros:&lt;/p&gt;
    &lt;code&gt;sudo snap install mapscii
&lt;/code&gt;
    &lt;p&gt;(This snap is maintained by @nathanhaines)&lt;/p&gt;
    &lt;p&gt;This is pretty simple too.&lt;/p&gt;
    &lt;code&gt;mapscii
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arrows up, down, left, right to scroll around&lt;/item&gt;
      &lt;item&gt;Press a or z to zoom in and out&lt;/item&gt;
      &lt;item&gt;Press c to switch to block character mode&lt;/item&gt;
      &lt;item&gt;Press q to quit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If your terminal supports mouse events you can drag the map and use your scroll wheel to zoom in and out.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;x256&lt;/code&gt;for converting RGB values to closest xterm-256 color code&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;term-mouse&lt;/code&gt;for mouse handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;keypress&lt;/code&gt;for input handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;string-width&lt;/code&gt;to determine visual string lengths&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vector-tile&lt;/code&gt;for VectorTile parsing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pbf&lt;/code&gt;for Protobuf decoding&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mbtiles&lt;/code&gt;for MBTiles parsing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;earcut&lt;/code&gt;for polygon triangulation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rbush&lt;/code&gt;for 2D spatial indexing of geo and label data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bresenham&lt;/code&gt;for line point calculations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;simplify-js&lt;/code&gt;for polyline simplifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;node-fetch&lt;/code&gt;for HTTP requests&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;env-paths&lt;/code&gt;to determine where to persist downloaded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MapSCII&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;GeoJSON support via geojson-vt&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;CLI support&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;[-] startup parameters &lt;list rend="ul"&gt;&lt;item&gt;TileSource&lt;/item&gt;&lt;item&gt;Style&lt;/item&gt;&lt;item&gt;center position&lt;/item&gt;&lt;item&gt;zoom&lt;/item&gt;&lt;item&gt;demo mode?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;[-] startup parameters &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;mouse control&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;hover POIs/labels&lt;/item&gt;
              &lt;item&gt;hover maybe even polygons/-lines?&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Styler&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;respect zoom based style ranges&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Renderer&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;TileSource&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;implement single vector-tile handling&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;lukasmartinelli &amp;amp; manuelroth for all their work on OSM2VectorTiles (global vector tiles from OSM Planet)&lt;/item&gt;
      &lt;item&gt;mourner for all his work on mindblowing GIS algorithms (like the used earcut, rbush, simplify-js, ..)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OpenStreetMap is open data, licensed under the Open Data Commons Open Database License (ODbL) by the OpenStreetMap Foundation (OSMF).&lt;/p&gt;
    &lt;p&gt;You are free to copy, distribute, transmit and adapt our data, as long as you credit OpenStreetMap and its contributors. If you alter or build upon our data, you may distribute the result only under the same licence. The full legal code explains your rights and responsibilities.&lt;/p&gt;
    &lt;p&gt;The cartography in our map tiles, and our documentation, are licenced under the Creative Commons Attribution-ShareAlike 2.0 licence (CC BY-SA).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45293012</guid><pubDate>Thu, 18 Sep 2025 18:12:58 +0000</pubDate></item><item><title>The best YouTube downloaders, and how Google silenced the press</title><link>https://windowsread.me/p/best-youtube-downloaders</link><description>&lt;doc fingerprint="3146b860f1b6b5f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The best YouTube downloaders (and how Google silenced the press)&lt;/head&gt;
    &lt;head rend="h3"&gt;Most websites can't tell you about them. But I can.&lt;/head&gt;
    &lt;code&gt;==============================
The Windows ReadMe - #005
==============================&lt;/code&gt;
    &lt;p&gt;‚ÄúWe can‚Äôt write about them. We‚Äôll get in trouble.‚Äù&lt;/p&gt;
    &lt;p&gt;That‚Äôs the attitude I had about YouTube downloaders when I ran How-To Geek as Editor-in-Chief. We self-censored to protect ourselves. But I‚Äôm not dancing for Google ad revenue anymore.&lt;/p&gt;
    &lt;p&gt;This ReadMe file is about incredibly useful free YouTube downloaders that I recommend. But it‚Äôs also about so many other truths people don‚Äôt normally share:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Why YouTube downloaders are ethical and you shouldn‚Äôt apologize for using them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Why Google secretly needs YouTube downloaders.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Why toothless terms of services like YouTube‚Äôs are no better than the EULAs we‚Äôve been ignoring for decades.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And how Google has used its ad network (now ruled an illegal monopoly) to privilege its own services ahead of competitors.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But yes, this is also a list of seriously useful free YouTube downloaders. The web is full of spammy ones, and I‚Äôll show you the real ones.&lt;/p&gt;
    &lt;code&gt;==============================
This week‚Äôs tip
==============================&lt;/code&gt;
    &lt;p&gt;Since I‚Äôm not writing to optimize this list for Google, I can just give you the answer!&lt;/p&gt;
    &lt;head rend="h1"&gt;The best YouTube downloaders for Windows (and beyond)&lt;/head&gt;
    &lt;p&gt;Here are the best YouTube downloaders -- based on my personal experience:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The best YouTube downloader for Windows is Stacher. It‚Äôs free, open-source, and simple. It‚Äôs an easy-to-use graphical application that does the setup for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The best YouTube downloader for the command line is yt-dlp. Use it if you want to get your hands dirty! (Stacher is cool because it provides a graphical interface and does all the hard work for you.)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The best YouTube download for Mac and Linux? Also Stacher! It‚Äôs cross-platform.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The best YouTube downloader on the web is Cobalt.tools -- or at least it used to be. It looks like Google is blocking it right now. Until it comes back, I recommend other tools. (Edit: Apparently there are still Cobalt instances that work ‚Äî see this comment! Thanks, ZedK.)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The best YouTube downloader for Android is NewPipe. This third-party YouTube app has a built-in download tool.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use any of these and you‚Äôll get a video file you can back up, archive, and do whatever you want with. It‚Äôs yours to preserve.&lt;/p&gt;
    &lt;head rend="h2"&gt;YouTube‚Äôs rules are just another EULA&lt;/head&gt;
    &lt;p&gt;When you install an application, you often click through a long end user license agreement. If people had to read each agreement in full, society would grind to a halt.&lt;/p&gt;
    &lt;p&gt;Even companies often don‚Äôt read their own EULAs. When Apple launched Safari for Windows, it launched it with a EULA that said people couldn‚Äôt install it on Windows. The message? Even companies like Apple don‚Äôt care what their own legal boilerplate says. So why should we care?&lt;/p&gt;
    &lt;p&gt;So yes: YouTube‚Äôs terms of service may or may not say you can‚Äôt download videos from it. I haven‚Äôt checked. Have you read it in full? Have you checked the terms of service for every product you‚Äôve used to confirm you‚Äôre in compliance? No one has -- that‚Äôs the point.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Google secretly needs YouTube downloaders&lt;/head&gt;
    &lt;p&gt;YouTube has become part of the plumbing of the modern web. It hosts everything from city council meetings to recorded live-streams of important family events. If a video is important to you -- or you want to have a copy for legal reasons -- you should download it. And, to do that, you‚Äôll need a YouTube downloader.&lt;/p&gt;
    &lt;p&gt;Using a YouTube downloader is like printing a web page to a PDF or saving an image file for later -- you get an offline copy you can archive. Just like with anything else on the web, a YouTube video may be taken down by its creator in the future. And you may need your offline copy.&lt;/p&gt;
    &lt;p&gt;Google needs YouTube downloaders. They perform a valuable role: If it were impossible to download YouTube videos, many organizations would abandon hosting their videos on YouTube for a platform that offered more user flexibility. Or they‚Äôd need to host a separate download link and put it in their YouTube descriptions. But organizations don‚Äôt need to jump through hoops -- they just let people use YouTube downloaders.&lt;/p&gt;
    &lt;p&gt;Google could lock down YouTube harder. Services like Netflix use DRM-protected streams to stop downloads. Google could make it much harder to download videos. But Google benefits from setting up a gray market ecosystem of often-inconvenient download tools. The ecosystem of YouTube downloaders and Google‚Äôs tacit approval of them has helped cement YouTube‚Äôs dominance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why How-To Geek never wrote about YouTube downloaders&lt;/head&gt;
    &lt;p&gt;When I ran How-To Geek as Editor-in-Chief -- and when I was a writer -- we went out of our way to avoid writing about YouTube downloaders. And we weren‚Äôt the only publication that avoided touching them, despite reader interest.&lt;/p&gt;
    &lt;p&gt;So many publications have long been dependent on Google ad revenue -- in fact, Google‚Äôs ad network was recently ruled an illegal monopoly in the U.S. And Google had a very interesting provision in its rules: Google could revoke ads if you messed with its other businesses.&lt;/p&gt;
    &lt;p&gt;This wasn‚Äôt just theoretical. Back in 2012, GHacks shared that it had Google AdSense ads removed from its entire website for ‚ÄúGoogle Product Abuse‚Äù because the website wrote about a YouTube downloader. Google required the offensive YouTube downloader article removed.&lt;/p&gt;
    &lt;p&gt;The message was that Google was serious, and that messing with Google‚Äôs YouTube business in any way was grounds for Google putting you out of business.&lt;/p&gt;
    &lt;p&gt;Google has now covered its tracks better -- there‚Äôs nothing about ‚ÄúGoogle Product Abuse‚Äù in its current AdSense policies. But the anti-downloader rules appear to have started as a way to protect its own products.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google just wants to make it annoying&lt;/head&gt;
    &lt;p&gt;Google has been walking a line for over a decade now: YouTube lets you use downloaders, but Google makes them inconvenient to find and annoying to use. Google tries to stop your favorite websites from writing about them. Google breaks tricks they depend on.&lt;/p&gt;
    &lt;p&gt;If you want to find a way to download an important video, you‚Äôll find it -- that‚Äôs an important escape hatch and means YouTube retains its dominance as an online engine of culture.&lt;/p&gt;
    &lt;p&gt;But Google loves making YouTube downloads just annoying enough that you won‚Äôt bother unless you really want to do it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let‚Äôs say the AI-related part out loud, too&lt;/head&gt;
    &lt;p&gt;Also: When Google itself is training its AI on content against the wishes of publishers, why should we feel bad about downloading backup copies of videos that are important to us?&lt;/p&gt;
    &lt;p&gt;We shouldn‚Äôt. Download the video you want. Back it up somewhere safe.&lt;/p&gt;
    &lt;code&gt;==============================
Something I'm proud of this week
==============================&lt;/code&gt;
    &lt;p&gt;Microsoft was pitching Windows Recall as the shiny AI feature to carry its Copilot+ PC brand, but no one talks about Recall anymore. The launch was too messy, the feature was too delayed, and the search experience never became as useful as Microsoft promised.&lt;/p&gt;
    &lt;p&gt;Now, Microsoft‚Äôs headline AI feature for Copilot+ PCs has become Click To Do. I dove into how this awkwardly named AI feature works for PCWorld.&lt;/p&gt;
    &lt;p&gt;Seriously, what a weird name: Haven‚Äôt we always been clicking to do things?&lt;/p&gt;
    &lt;code&gt;==============================
Insights from Thurrott.com
==============================&lt;/code&gt;
    &lt;p&gt;Google is bringing a search app to Windows -- it‚Äôs the return of Google Desktop, but with more AI this time! Also, in more AI-related Google news, Gemini is popping up in Chrome browsers -- no subscription needed.&lt;/p&gt;
    &lt;p&gt;In Windows news, Consumer Reports is calling on Microsoft to extend support for Windows 10. And Notepad will let you use AI features without spending AI credits.&lt;/p&gt;
    &lt;p&gt;For Thurrott Premium subscribers, Paul‚Äôs been trying out the iPad as a laptop and thinking about the future of computing. He also launched a newsletter that‚Äôs not about news -- and isn‚Äôt a letter. (Excellent.)&lt;/p&gt;
    &lt;code&gt;==============================
EULAs and a time machine
==============================&lt;/code&gt;
    &lt;p&gt;Back in 2012, I wrote this piece about ridiculous EULA clauses for MakeUseOf.&lt;/p&gt;
    &lt;p&gt;(Yes, I just linked an Archive.org backup of a piece I wrote 13 years ago. I don‚Äôt know whether MakeUseOf‚Äôs terms of service allowed Archive.org to save a backup copy, but I‚Äôm glad they did save copy. Backups are important.)&lt;/p&gt;
    &lt;p&gt;Looking back at it, my favorite ridiculous EULA clause was the "special consideration" in PC Pitstop's EULA. It said that the first person who noticed this line in the EULA could email the company and receive a financial reward.&lt;/p&gt;
    &lt;p&gt;It took four months for someone to notice the line and claim a $1000 prize. No one reads EULAs, even when they have something positive to say!&lt;/p&gt;
    &lt;code&gt;==== Command Prompt ====

C:\&amp;gt; net send * "Have a great weekend!"&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45300810</guid><pubDate>Fri, 19 Sep 2025 12:20:10 +0000</pubDate></item><item><title>Less is safer: How Obsidian reduces the risk of supply chain attacks</title><link>https://obsidian.md/blog/less-is-safer/</link><description>&lt;doc fingerprint="b4701b49aca2c68a"&gt;
  &lt;main&gt;
    &lt;p&gt;Supply chain attacks are malicious updates that sneak into open source code used by many apps. Here‚Äôs how we design Obsidian to ensure that the app is a secure and private environment for your thoughts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Less is safer&lt;/head&gt;
    &lt;p&gt;It may sound obvious but the primary way we reduce the risk of supply chain attacks is to avoid depending on third-party code. Obsidian has a low number of dependencies compared to other apps in our category. See a list of open source libraries on our Credits page.&lt;/p&gt;
    &lt;p&gt;Features like Bases and Canvas were implemented from scratch instead of importing off-the-shelf libraries. This gives us full control over what runs in Obsidian.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For small utility functions we almost always re-implement them in our code.&lt;/item&gt;
      &lt;item&gt;For medium modules we fork them and keep them inside our codebase if the licenses allows it.&lt;/item&gt;
      &lt;item&gt;For large libraries like pdf.js, Mermaid, and MathJax, we include known-good, version-locked files and only upgrade occasionally, or when security fixes land. We read release notes, look at upstream changes, and test thoroughly before switching.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This approach keeps our dependency graph shallow with few sub-dependencies. A smaller surface area lowers the chance of a malicious update slipping through.&lt;/p&gt;
    &lt;head rend="h3"&gt;What actually ships in the app&lt;/head&gt;
    &lt;p&gt;Only a handful of packages are part of the app you run, e.g. Electron, CodeMirror, moment.js. The other packages help us build the app and never ship to users, e.g. esbuild or eslint.&lt;/p&gt;
    &lt;head rend="h3"&gt;Version pinning and lockfiles&lt;/head&gt;
    &lt;p&gt;All dependencies are strictly version-pinned and committed with a lockfile. The lockfile is the source of truth for builds so we get deterministic installs. This gives us a straightforward audit trail when reviewing changes.&lt;/p&gt;
    &lt;p&gt;We do not run postinstall scripts. This prevents packages from executing arbitrary code during installation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Slow, deliberate upgrades&lt;/head&gt;
    &lt;p&gt;When we do dependency updates, we:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read the dependency‚Äôs changelog line-by-line.&lt;/item&gt;
      &lt;item&gt;Check sub-dependencies introduced by the new version.&lt;/item&gt;
      &lt;item&gt;Diff upstream when the change set is large or risky.&lt;/item&gt;
      &lt;item&gt;Run automated and manual tests across platforms and critical user paths.&lt;/item&gt;
      &lt;item&gt;Commit the new lockfile only after these reviews pass.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In practice, we rarely update dependencies because they generally work and do not require frequent changes. When we do, we treat each change as if we were taking a new dependency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Time is a buffer&lt;/head&gt;
    &lt;p&gt;We don‚Äôt rush upgrades. There is a delay between upgrading any dependency and pushing a release. That gap acts as an early-warning window: the community and security researchers often detect malicious versions quickly. By the time we‚Äôre ready to ship, the ecosystem has usually flagged any problematic releases.&lt;/p&gt;
    &lt;p&gt;No single measure can eliminate supply chain risk. But choosing fewer dependencies, shallow graphs, exact version pins, no postinstall, and a slow, review-heavy upgrade cadence together make Obsidian much less likely to be impacted, and give us a long window to detect problems before code reaches users.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre curious about our broader approach to security, see our security page and past audits.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45307242</guid><pubDate>Fri, 19 Sep 2025 22:02:29 +0000</pubDate></item><item><title>If you are good at code review, you will be good at using AI agents</title><link>https://www.seangoedecke.com/ai-agents-and-code-review/</link><description>&lt;doc fingerprint="3745f11f2ab448db"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;If you are good at code review, you will be good at using AI agents&lt;/head&gt;
    &lt;p&gt;Using AI agents correctly is a process of reviewing code. If you‚Äôre good at reviewing code, you‚Äôll be good at using tools like Claude Code, Codex, or the Copilot coding agent.&lt;/p&gt;
    &lt;p&gt;Why is that? Large language models are good at producing a lot of code, but they don‚Äôt yet have the depth of judgement of a competent software engineer. Left unsupervised, they will spend a lot of time committing to bad design decisions.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI agents and bad design&lt;/head&gt;
    &lt;p&gt;Last week I built VicFlora Offline: an offline-friendly PWA that hosts some of the VicFlora data for keying out plants, so you can still use the keys if you‚Äôre in the field somewhere with bad internet reception. Codex spent a lot of effort trying to reverse-engineer the VicFlora frontend code for the dichotomous key. It was honestly pretty impressive to watch! But I figured there had to be some easier way to access the raw data, and I was right. This happens over and over again when I use AI coding agents: about once an hour I notice that the agent is doing something that looks suspicious, and when I dig deeper I‚Äôm able to set it on the right track and save hours of wasted effort.&lt;/p&gt;
    &lt;p&gt;I‚Äôm also working on an app that helps me learn things with AI - think of it as an infinite, automatically-adjusting spaced-repetition feed. When I want to do things in parallel (e.g. generating a learning plan in the background), both Codex and Claude Code really want to build a full background job infrastructure: with job entities, result polling, and so on. I like background jobs, but for ordinary short-lived parallel work they are very obviously overkill. Just make a non-blocking request from the frontend! If I weren‚Äôt consistently pushing for simplicity, my codebase would be much more complex to reason about.&lt;/p&gt;
    &lt;p&gt;Incidentally, this is why I think pure ‚Äúvibe coding‚Äù hasn‚Äôt produced an explosion of useful apps. If you don‚Äôt have the technical ability to spot when the LLM is going down the wrong track, you‚Äôll rapidly end up stuck. Trying to make a badly-designed solution work costs time, tokens, and codebase complexity. All of these things cut into the agent‚Äôs ability to actually solve the problem. Once two or three of them pile up, the app is no longer tractable for the agent and the whole thing grinds to a halt.&lt;/p&gt;
    &lt;head rend="h3"&gt;Code review&lt;/head&gt;
    &lt;p&gt;These examples should be familiar to anyone who‚Äôs spent enough time working on an engineering team with enthusiastic juniors. Diving right in to an early idea and making it work with sheer effort is a very common mistake. It‚Äôs the job of the rest of the team to rein that in. Working with AI agents is like working with enthusiastic juniors who never develop the judgement over time that a real human would1.&lt;/p&gt;
    &lt;p&gt;This is a good opportunity to talk about what I think is the biggest mistake engineers make in code review: only thinking about the code that was written, not the code that could have been written. I‚Äôve seen even experienced engineers give code reviews that go through the diff with a fine-toothed comb, while spending approximately zero seconds asking if this is even the right place for the code at all.&lt;/p&gt;
    &lt;p&gt;In my view, the best code review is structural. It brings in context from parts of the codebase that the diff didn‚Äôt mention. Ideally, that context makes the diff shorter and more elegant: for instance, instead of building out a new system for operation X, we can reuse a system that already exists. Instead of building a fragile scraping pipeline that pulls dichotomous key IDs from the frontend SPA code, let‚Äôs just download the dichotomous keys from this other place where they‚Äôre explicitly made available. Instead of building out an entire background job system, let‚Äôs just do our parallel work on the client, using all the existing machinery that websites have for doing two things at the same time.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre a nitpicky code reviewer, I think you will struggle to use AI tooling effectively. You‚Äôll be forever tweaking individual lines of code, asking for a &lt;code&gt;.reduce&lt;/code&gt; instead of a &lt;code&gt;.map.filter&lt;/code&gt;, bikeshedding function names, and so on. At the same time, you‚Äôll miss the opportunity to guide the AI away from architectural dead ends.&lt;/p&gt;
    &lt;p&gt;Likewise, if you‚Äôre a rubber-stamp code reviewer, you‚Äôre probably going to put too much trust in the AI tooling. That approach works with competent colleagues, but it doesn‚Äôt work well when you‚Äôre onboarding junior engineers, and it doesn‚Äôt work well when you‚Äôre working with AI coding agents.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;What does it mean to be ‚Äúgood at AI‚Äù? Being good at a normal tool like git is straightforward: if you have a grasp of the basic tree-structure of a git repository, and you‚Äôre familiar with the majority of git operations, you‚Äôre good at git. But the basic structure of AI is an impenetrable mass of model weights, and the ‚Äúoperations‚Äù it can perform are ‚Äúbasically anything you can do with a computer‚Äù. There are no software engineering tools like it.&lt;/p&gt;
    &lt;p&gt;The most optimistic AI proponents think that ‚Äúbeing good at AI‚Äù is about maximally adopting AI tooling in every aspect of your life. The argument here is that AI plays something like the role of Jeff Bezos‚Äô staff. Using a hyper-resourced, hyper-competent staff doesn‚Äôt require a lot of skill: you simply ask for what you want, and an enormous amount of other people‚Äôs effort will be devoted to providing it. But Bezos certainly uses his staff more effectively than I would, if I were to be teleported into his position today. I wouldn‚Äôt even consider asking for half the things I wanted - it just wouldn‚Äôt occur to me that I could get a hot Lune croissant waiting for me when I step off my private jet, for instance, even if I really would enjoy it. AI believers think AI tooling is kind of like this. According to them, when you genuinely internalize that you can ask your personal AI assistant to vibe code any program you want, or sort through any amount of data, or draft all of your emails, you will begin using AI much more frequently, to your benefit.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think we‚Äôre there yet. I use agentic coding tools a lot: GitHub Copilot at and for work, and both Codex and Claude Code for my personal projects2. While they can do a surprising number of tasks on their own, they do require fairly close supervision. The dominant programming model is something like ‚Äúcentaur chess‚Äù, where a skilled human is paired with a computer assistant. The better you are at code review - at assessing whether a particular software approach is a sensible one - the better you‚Äôll be at using agentic AI tooling.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Every time I see this point made, I wonder - if you started using AI coding tooling with early Copilot in 2022, and you‚Äôre still using cutting-edge AI tooling in 2025, doesn‚Äôt it kind of feel like the tooling has grown at the same rate a human would? If you described early Copilot as a brand-new grad and current Claude Code (or whatever) as an engineer with three years of experience, would that be too far off? In another three years, will working with AI tooling be like working with a engineer with six years under their belt?&lt;/p&gt;‚Ü©&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Using Codex and Claude Code doesn‚Äôt indicate that I think they‚Äôre better than Copilot. In my view, it‚Äôs part of my job to use a variety of AI tooling.&lt;/p&gt;‚Ü©&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News.&lt;/p&gt;
    &lt;p&gt;September 20, 2025 ‚îÇ Tags: ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45310529</guid><pubDate>Sat, 20 Sep 2025 04:59:10 +0000</pubDate></item><item><title>PYREX vs. pyrex: What's the difference?</title><link>https://www.corning.com/worldwide/en/products/life-sciences/resources/stories/in-the-field/pyrex-vs-pyrex-whats-the-difference.html</link><description>&lt;doc fingerprint="bc309c5290c9256b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h2"&gt;PYREX vs pyrex Construction Differences&lt;/head&gt;
      &lt;p&gt;Corning used borosilicate to produce all Pyrex products. However, the company that purchased the cookware products switched to soda-lime glass, adopting the name pyrex (spelled with all lowercase letters).&lt;/p&gt;
      &lt;p&gt;Corning continued to make its lab tools with borosilicate, dubbing these products to be PYREX (spelled with all uppercase letters). Borosilicate glassware can sustain the large, sudden temperature changes that frequently occur in labs without shattering. These products are also less likely to react to chemicals.&lt;/p&gt;
      &lt;p&gt;Corning sold the consumer products or cookware business in 1998. The new owner, known as Borden at the time, later rebranding to World Kitchen in 2000, recognized that the cookware didn't need to be quite as strong, and ‚Äî to make it accessible to the average customer ‚Äî it needed to be more affordable. With this in mind, they switched the cookware to soda-lime glass, a less expensive component. Soda-lime glass, now called pyrex, isn't as resistant to thermal shock, but it is durable enough for everyday cooking.&lt;/p&gt;
      &lt;head rend="h2"&gt;Benefits of PYREX Labware&lt;/head&gt;
      &lt;p&gt;PYREX labware is designed to meet the rigorous demands of scientific experimentation. In fact, these scientific glassware products were integral in developing penicillin during World War II and the polio vaccine during the 1950s.&lt;/p&gt;
      &lt;p&gt;Corning laboratory glassware products have long been manufactured to meet the quality and reliability standards created by the American Society for Testing and Materials (ASTM). Corning advanced its quality control for accuracy and precision further by testing its volumetric glassware in an ISO/IEC 17025 accredited laboratory.&lt;/p&gt;
      &lt;p&gt;PYREX glass is well-suited for lab work because Corning uses borosilicate to produce beakers, flasks, test tubes, and other lab glassware. PYREX lab glassware made with borosilicate can withstand harsh, corrosive chemicals, handle extremely low and high temperatures, and it can survive rapid temperature changes without sustaining damage. PYREX beakers, Erlenmeyer flasks, and round- and flat-bottom boiling flasks can be repeatedly heated up to 230¬∫C. PYREX volumetric laboratory ware can be brought to 150¬∫C. Overall, PYREX laboratory glassware has a temperature shock limit ‚Äî or allowable difference between the temperature of the glass and any medium in contact with the glass (air, liquid, or solid) ‚Äî of 160¬∫C.&lt;/p&gt;
      &lt;p&gt;Always check laboratory glassware for any cracks, scratches, chips, or hazing ‚Äî these damages can cause the product to break while in use. If properly cleaned and not damaged, PYREX laboratory glassware is reusable.&lt;/p&gt;
      &lt;head rend="h2"&gt;Unique Cleaning Procedures for PYREX Lab Glassware&lt;/head&gt;
      &lt;p&gt;Despite being made of a strong, durable material, PYREX lab glassware requires specific care and maintenance. Ignoring the specific cleaning differences of PYREX labware can undermine the glassware's integrity and stability. If handled improperly, these products could shatter when exposed to high temperatures.&lt;/p&gt;
      &lt;p&gt;Always clean PYREX products with a non-abrasive glassware detergent either by hand or in a dishwasher. Do not exceed temperatures above 110¬∞C during the cleaning process. Do not use abrasive brushes or scrubbing pads that can scratch the glass or its coating. In addition, limit exposure to any aldehydes, ketones, chlorinated solvents, or concentrated acids, because they can damage the glassware.&lt;/p&gt;
      &lt;p&gt;For over 100 years, Corning has been a trailblazer in creating innovative glassware products that can reliably and repeatedly meet users' needs. These products have accelerated scientific discoveries and enhanced human health.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45310995</guid><pubDate>Sat, 20 Sep 2025 06:37:01 +0000</pubDate></item><item><title>FLX1s phone is launched</title><link>https://furilabs.com/flx1s-is-launched/</link><description>&lt;doc fingerprint="dfe351495ea32377"&gt;
  &lt;main&gt;
    &lt;p&gt;It is with great excitement that we can now release the FLX1s. Pre-sales are open and the phone is in production which is due to complete end of October 2025. Following that we can start shipping. Existing orders will be opted into the FLX1s or refunded.&lt;lb/&gt;To all our amazing FLX1 owners and those waiting patiently for their order, you have been the most wonderful and supportive community that we could ever have imagined.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Thank-you from the FuriLabs Team.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312326</guid><pubDate>Sat, 20 Sep 2025 11:20:04 +0000</pubDate></item><item><title>Overcoming barriers of hydrogen storage with a low-temperature hydrogen battery</title><link>https://www.isct.ac.jp/en/news/okmktjxyrvdc</link><description>&lt;doc fingerprint="2d41b19f88ee3379"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Overcoming the barriers of hydrogen storage with a low-temperature hydrogen battery&lt;/head&gt;
    &lt;p&gt;Scientists develop a solid electrolyte, utilizing which the battery stores and releases hydrogen at temperatures below 100 degrees Celsius&lt;/p&gt;
    &lt;p&gt;A hydrogen battery that operates at just 90 ¬∞C has been developed by researchers from Japan, overcoming the high-temperature and low-capacity limits of earlier methods. The device works by moving hydride ions through a solid electrolyte, allowing magnesium hydride, which acts as the anode, to repeatedly store and release hydrogen at full capacity. This battery offers a practical way to store hydrogen fuel, paving the way for hydrogen-powered vehicles and clean energy systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solid Electrolyte for Low-Temperature Hydrogen Storage&lt;/head&gt;
    &lt;p&gt; One of the most pressing challenges facing the use of hydrogen is its storage, which typically requires extremely low temperatures (‚àí252.8 ¬∞C) and high pressures (350 to 700 bar). Instead of storing hydrogen as a gas or liquid, a more effective approach is to store it in solid materials such as magnesium hydride (MgH2), which has high theoretical storage capacity. This material can be integrated into a battery-like system where, instead of only moving electrons, hydrogen itself is stored and released during charging and discharging.&lt;lb/&gt; Until recently, this approach was limited by the need for high operating temperatures above 300 ¬∞C, poor reversibility of hydrogen absorption and desorption, and unwanted side reactions that reduced performance. In a significant development that may open the door to practical applications, researchers from Institute of Science Tokyo (Science Tokyo), Japan, have developed a hydrogen battery that can operate at much lower temperatures, around 90 ¬∞C. The study published in the journal Science on September 18, 2025, was conducted by a research team led by Research Scientist Dr. Takashi Hirose, Assistant Professor Naoki Matsui, and Institute Professor Ryoji Kanno at the Research Center for All-Solid-State Battery in Science Tokyo.&lt;lb/&gt; ‚ÄúWe demonstrated the operation of an Mg‚ÄìH2 battery as a safe and efficient hydrogen energy storage device, achieving high capacity, low temperature, and reversible hydrogen gas absorption and release,‚Äù says Matsui.&lt;lb/&gt; The novelty of this battery lies in its solid electrolyte, Ba0.5Ca0.35Na0.15H1.85, which can transport hydrogen ions, specifically hydride ions (H‚Äì), efficiently. This material has an anti-Œ±-AgI-type crystal structure, well known for its superionic conductivity. In this structure, barium, calcium, and sodium occupy body-centered positions, while H‚Äì move through face-sharing tetrahedral and octahedral sites, allowing them to migrate freely. Tests showed that the material has high ionic conductivity at room temperature (2.1 √ó 10-5 S cm-1) and electrochemical stability, making the system effective for long-term hydrogen storage and release.&lt;lb/&gt; The battery design uses MgH2 as the anode and hydrogen (H2) gas as the cathode. During charging, MgH2 releases H‚Äì, which migrate through the Ba0.5Ca0.35Na0.15H1.85 electrolyte to the H2 electrode, where they are oxidized to release H2 gas. During discharging, the reverse occurs: H2 gas at the cathode is reduced to H‚Äì, which move through the electrolyte to the anode and react with Mg to form MgH2.&lt;lb/&gt; This process allows the cell to both store and release H2 when needed, all at manageable temperatures below 100 ¬∞C. Using this cell, the researchers were able to reach the full theoretical storage capacity of MgH2, about 2,030 mAh g-1, equivalent to 7.6 wt.% H2, over repeated cycles.&lt;lb/&gt; Traditional solid-state hydrogen storage methods have faced major limitations. Heat-driven absorption and desorption required very high operating temperatures between 300 and 400 ¬∞C to release or capture hydrogen, which made the process energy-intensive and impractical for everyday use. An alternative approach using electrochemical storage with liquid electrolytes at lower temperatures suffered from poor hydrogen-ion transport, which meant that the materials could not achieve anywhere near their theoretical storage capacities. As a result, both approaches fell short of providing an efficient, reversible, and low-temperature solution for hydrogen storage.&lt;lb/&gt; ‚ÄúThese properties of our hydrogen storage battery were previously unattainable through conventional thermal methods or liquid electrolytes, offering a foundation for efficient hydrogen storage systems suitable for use as energy carriers,‚Äù explains Hirose.&lt;lb/&gt; Such a battery could be key to a hydrogen-powered future, enabling hydrogen-powered vehicles and carbon-free industries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reference&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Authors:&lt;/item&gt;
      &lt;item rend="dd-1"&gt;Takashi Hirose1,2, Naoki Matsui2*, Takashi Itoh1, Yoyo Hinuma2,3, Kazutaka Ikeda4,5,&lt;lb/&gt;Kazuma Gotoh6, Guangzhong Jiang2, Kota Suzuki1,2, Masaaki Hirayama1,2, Ryoji Kanno2*&lt;lb/&gt;*Corresponding author&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Title:&lt;/item&gt;
      &lt;item rend="dd-2"&gt;High-Capacity, Reversible Hydrogen Storage Using H‚Äì-Conducting Solid Electrolytes&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Journal:&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Science&lt;/item&gt;
      &lt;item rend="dt-5"&gt;Affiliations:&lt;/item&gt;
      &lt;item rend="dd-5"&gt;1Department of Chemical Science and Engineering, Institute of Science Tokyo, Japan&lt;lb/&gt;2Research Center for All‚ÄìSolid‚ÄìState Battery, Institute of Science Tokyo, Japan&lt;lb/&gt;3Department of Energy and Environment, National Institute of Advanced Industrial Science and Technology (AIST), Japan&lt;lb/&gt;4Institute of Materials Structure Science (IMSS), High Energy Accelerator Research&lt;lb/&gt;Organization, Japan&lt;lb/&gt;5Neutron Industrial Application Promotion Center, Comprehensive Research Organization for Science and Society (CROSS), Japan&lt;lb/&gt;6Center for Nano Materials and Technology (CNMT), Japan Advanced Institute of Science and Technology (JAIST), Japan&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Related articles&lt;/head&gt;
    &lt;head rend="h2"&gt;Further information&lt;/head&gt;
    &lt;p&gt;Institute Professor Ryoji Kanno&lt;/p&gt;
    &lt;p&gt;Research Center for All‚ÄìSolid‚ÄìState Battery, Institute of Integrated Research, Institute of Science Tokyo&lt;/p&gt;
    &lt;p&gt;Assistant Professor Naoki Matsui,&lt;/p&gt;
    &lt;p&gt;Research Center for All‚ÄìSolid‚ÄìState Battery, Institute of Integrated Research, Institute of Science Tokyo&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;Public Relations Division, Institute of Science Tokyo&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Tel&lt;/item&gt;
      &lt;item rend="dd-1"&gt;+81-3-5734-2975&lt;/item&gt;
      &lt;item rend="dd-2"&gt;media@adm.isct.ac.jp&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312447</guid><pubDate>Sat, 20 Sep 2025 11:40:28 +0000</pubDate></item><item><title>Images over DNS</title><link>https://dgl.cx/2025/09/images-over-dns</link><description>&lt;doc fingerprint="fec80dd7a0729493"&gt;
  &lt;main&gt;
    &lt;p&gt;What's the limit of what can be in a TXT record?&lt;/p&gt;
    &lt;p&gt;Some places say 255 bytes. They are wrong. Within a TXT record there are multiple character-strings (RFC 1035 section 3.3.14) and those are limited in length (because a single byte is used for their length), however there can be many of them.&lt;/p&gt;
    &lt;p&gt;The actual limit is limited by the size of the DNS payload, which for UDP is these days around 1232 bytes. That is obviously quite low. However if we use TCP, which doesn't require anything special, other than the normal fallback to TCP that DNS does, then we can serve up to 64KB.&lt;/p&gt;
    &lt;p&gt;I set out to demonstrate exactly that, by using Google Public DNS's JSON API and then serving large TXT responses over TCP, from a custom server.&lt;/p&gt;
    &lt;p&gt;This mostly just works, the main issue is not with the length, but with binary data, because JSON isn't really designed to handle binary data. Therefore there is some slightly custom JSON parsing. Using raw binary data in a TXT record avoids the overhead of Base64 or another encoding, meaning more data can be packed in.&lt;/p&gt;
    &lt;p&gt;üëâ See it in action. For more read the comments in image.html.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-browser&lt;/head&gt;
    &lt;p&gt;It is possible to query this via dig. Although turning it back into binary output is a bit tricky, as the presentation form of DNS responses is escaped for output.&lt;/p&gt;
    &lt;p&gt;You can retrieve the data with dig and a little Perl to unescape and combine the character sequences:&lt;/p&gt;
    &lt;code&gt;$ dig +short dog.log.battery.st TXT | perl -pe'chomp; s/" "//g; s/^"//; s/"$//; s/\\(\d{3})/chr $1/eg; s/\\([\\"])/$1/g' &amp;gt; dog.avif
$ sha256sum dog.avif
7058fbd20ef2af84d5efb0ae7d91f87ce7a912380636c468b32f2c759cbb9130  dog.avif
&lt;/code&gt;
    &lt;p&gt;(This is actually just a modified version of the Perl one liner from my Wikipedia over DNS from 2008, nothing changes.)&lt;/p&gt;
    &lt;p&gt;Because the web version uses Google's JSON resolver we know it doesn't have problems querying very large TXT records, however your local recursor may not support this. If it doesn't work you can add &lt;code&gt;@dns.google&lt;/code&gt; to the dig command
line to send the query to Google's Public DNS servers (or any other open
recursor, &lt;code&gt;@9.9.9.9&lt;/code&gt; seems to work too).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;I thought it was a cute hack when I realised it was possible.&lt;/p&gt;
    &lt;p&gt;For those interested in security there is a consideration here, attackers have long tunnelled over DNS, but tunnelling large payloads to a browser is potentially something new. Because Google Public DNS has a certificate that includes &lt;code&gt;8.8.8.8&lt;/code&gt; and so on, HTTPS
traffic can go directly from a browser without a DNS lookup. This may be
unexpected in environments that use DNS filtering. This is something that will
become more common once Lets Encrypt fully rolls out IP address
certificates,
the difference here is piggybacking on an existing IP address certificate.&lt;/p&gt;
    &lt;p&gt;This deliberately uses a low TTL (10 seconds) to avoid filling DNS recursor's caches with useless content. It would be possible to increase this and therefore get caching from the recursors, a bit like a free distributed CDN (although I suspect if someone actually did this they would adaptively limit TTLs, if something like that isn't already done).&lt;/p&gt;
    &lt;head rend="h2"&gt;Server side&lt;/head&gt;
    &lt;p&gt;The server is a custom Go DNS server. To be honest it was written by ChatGPT because it's not that clever, the idea is what matters. (Although ChatGPT did get some details like truncation wrong so I fixed the code myself.)&lt;/p&gt;
    &lt;p&gt;All the code is here. AI was only used for the server component, this blog post and the client HTML code is my own work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312515</guid><pubDate>Sat, 20 Sep 2025 11:50:15 +0000</pubDate></item><item><title>Git: Introduce Rust and announce it will become mandatory in the build system</title><link>https://lore.kernel.org/git/20250904-b4-pks-rust-breaking-change-v1-0-3af1d25e0be9@pks.im/</link><description>&lt;doc fingerprint="5e8f767c1c2747ac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making sure you're not a bot!&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;You are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.&lt;/p&gt;
    &lt;p&gt;Anubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.&lt;/p&gt;
    &lt;p&gt;Ultimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.&lt;/p&gt;
    &lt;p&gt;Please note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312696</guid><pubDate>Sat, 20 Sep 2025 12:17:33 +0000</pubDate></item><item><title>Visa holders on vacation have 15 hours to return to US or pay $100k fee</title><link>https://timesofindia.indiatimes.com/technology/tech-news/microsoft-has-a-24-hour-deadline-warning-for-indian-and-other-foreign-employees-after-h1-b-visa-fees-hike-to-100000-strongly-recommend-h1b-visa-holders-/articleshow/124010245.cms</link><description>&lt;doc fingerprint="2e1c81dbcebed0ac"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Microsoft has urged its employees on H-1B and H-4 visas to return to the US immediately before the Trump administration√¢s September 21 deadline, after which companies will be required to pay $100,000 per year for each H-1B worker visa. According to an internal email reviewed by Reuters, the software giant has also advised those already in the US to stay there for the foreseeable future.&lt;/p&gt;
      &lt;p&gt;√¢H-1B visa holders should stay in the US for the foreseeable future. Also recommend H-4 visa holders remain in the US. Strongly recommend H-1B and H-4 visa holders return to the US tomorrow before the deadline,√¢ Microsoft said in its email to employees as quoted by Reuters.&lt;/p&gt;
      &lt;head rend="h2"&gt;H-1B visa to cost more&lt;/head&gt;
      &lt;p&gt;Donald Trump has signed an executive order on Friday, September 19 introducing a $100,000 annual fee for H-1B visa applications, dealing a big blow to the technology sector that relies heavily on skilled workers from India and China. Anticipating the tech industry√¢s response to the changes, Trump said √¢I think they're going to be very happy√¢. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;p&gt;Donald Trump's H-1B Visa Fee Hike Shocks Tech Giants and Indians, Experts Call The Move 'Regressive'&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;p&gt;U.S. Commerce Secretary Howard Lutnick said √¢If you're going to train somebody, you're going to train one of the recent graduates from one of the great universities across our land. &lt;/p&gt;
      &lt;p&gt;Train Americans. Stop bringing in people to take our jobs√¢. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Poll&lt;/p&gt;
            &lt;p&gt;Do you think the new $100,000 annual fee for H-1B visas will impact the tech industry negatively?&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;p&gt;White House staff secretary Will Scharf said, "One of the most abused visa systems is the H1-B non-immigrant visa programme. This is supposed to allow highly skilled labourers who work in fields that Americans don't work in to come into the United States of America. What this proclamation will do is raise the fee that companies pay to sponsor H-1B applicants to $100,000. This will ensure that the people they're bringing in are actually very highly skilled and that they're not replaceable by American workers."&lt;/p&gt;
      &lt;head rend="h2"&gt;&lt;lb/&gt;India accounts for most H-1B visas&lt;/head&gt;
      &lt;p&gt;India remained the leading recipient of H-1B visas last year. As per the government data, the country alone accounted for 71% of approved beneficiaries, with China trailing at 11.7%. &lt;/p&gt;
      &lt;p&gt;In the first half of 2025, Amazon and its cloud unit AWS secured approvals for more than 12,000 H-1B visas, while Microsoft and Meta each obtained over 5,000 approvals.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312877</guid><pubDate>Sat, 20 Sep 2025 12:40:34 +0000</pubDate></item><item><title>China's 200M gig workers are a warning for the world</title><link>https://www.economist.com/leaders/2025/09/18/chinas-200m-gig-workers-are-a-warning-for-the-world</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313127</guid><pubDate>Sat, 20 Sep 2025 13:18:16 +0000</pubDate></item><item><title>Bezier Curve as Easing Function in C++</title><link>https://asawicki.info/news_1790_bezier_curve_as_easing_function_in_c</link><description>&lt;doc fingerprint="bdfd9b9b882b23db"&gt;
  &lt;main&gt;&lt;p&gt;Fri &lt;lb/&gt;19 &lt;lb/&gt;Sep 2025 &lt;/p&gt;&lt;p&gt;This is a guest post from my friend ≈Åukasz Izdebski Ph.D.&lt;/p&gt;&lt;p&gt;It‚Äôs been a while since my last guest post on Adam‚Äôs blog, but I‚Äôm back with something short and practical‚Äîthink of it as an epilogue to this earlier post on B√©zier curves in animation. The last post focused on the theory and mathematics behind B√©zier curves. What it lacked was a practical perspective‚Äîan opportunity to see the implementation in action. I wanted to share with you a simple library that I have created. Its purpose is to directly represent cubic B√©zier Curves as Easing Functions.&lt;/p&gt;&lt;p&gt;The library is designed with C++20 and newer standards in mind, taking advantage of modern language features for clarity and performance. If needed, support for earlier versions of C++ can be added to ensure broader compatibility.&lt;/p&gt;&lt;code&gt;EasingCubicBezier&amp;lt;T&amp;gt;&lt;/code&gt;. This class handles the interpolation of parameters used in the keyframe method. The interpolation of parameters follows the same principles as standard B√©zier curve evaluation.&lt;code&gt;evaluate&lt;/code&gt; function with a parameter &lt;code&gt;t&lt;/code&gt;, which should lie between x0 (the X coordinate of the first control point, representing the start time of the frame) and x3 (the X coordinate of the fourth control point, representing the end time). &lt;p&gt;As presented in previous blog post, the &lt;code&gt;EasingCubicBezier&lt;/code&gt; character as a easing function depends solely on the X coordinates of the control points.&amp;#13;
The tests were prepared for a single, fixed value of the Y coordinates of the B√©zier curve control points (their value does not affect the interpolation performance in any way), and for a set of 256 different variants of the X coordinates of the control points.&amp;#13;
The aim was to cover as wide a range of control point locations as possible (in particular, the two inner points).&lt;/p&gt;&lt;p&gt;Performance measurements were carried out using the Google Benchmark framework, ensuring reliable and consistent results. Further details and test results are available in the library repository.&lt;/p&gt;&lt;p&gt;The new approach using &lt;code&gt;EasingCubicBezier&amp;lt;T&amp;gt;&lt;/code&gt; has been benchmarked against two commonly used methods in game engines and graphics applications. Both of these alternatives rely on solving cubic polynomial equations, either through algebraic solutions or numerical  techniques.&amp;#13;
In the case of numerical methods, a critical factor is the choice of the initial starting point. This selection plays a major role in determining the algorithm‚Äôs convergence speed and stability.&lt;/p&gt;&lt;p&gt;The following tests compared 5 different algorithms:&lt;/p&gt;&lt;code&gt;0.5&lt;/code&gt; (because the X coordinates of the curve were previously normalised to the interval &lt;code&gt;[0, 1]&lt;/code&gt;).&lt;code&gt;t&lt;/code&gt;, where &lt;code&gt;t&lt;/code&gt; is the input parameter for which the B√©zier curve interpolation is being evaluated.&lt;p&gt;The chart and the table below presents the benchmark results using a box plot, highlighting the distribution and variability of each algorithm‚Äôs performance in PRECISE mode with AVX2 extensions turned On.&lt;/p&gt;&lt;table&gt;&lt;row span="8"&gt;&lt;cell role="head"&gt;Algorithm&lt;/cell&gt;&lt;cell role="head"&gt;Min&lt;/cell&gt;&lt;cell role="head"&gt;Q1&lt;/cell&gt;&lt;cell role="head"&gt;Median&lt;/cell&gt;&lt;cell role="head"&gt;Q3&lt;/cell&gt;&lt;cell role="head"&gt;Max&lt;/cell&gt;&lt;cell role="head"&gt;Average&lt;/cell&gt;&lt;cell role="head"&gt;Std dev&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Easing Cubic Bezier&lt;/cell&gt;&lt;cell&gt;1562.5&lt;/cell&gt;&lt;cell&gt;21875.0&lt;/cell&gt;&lt;cell&gt;32812.5&lt;/cell&gt;&lt;cell&gt;32812.5&lt;/cell&gt;&lt;cell&gt;39062.5&lt;/cell&gt;&lt;cell&gt;28991.7&lt;/cell&gt;&lt;cell&gt;7803.5&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Numeric Solution 1&lt;/cell&gt;&lt;cell&gt;7812.5&lt;/cell&gt;&lt;cell&gt;17187.5&lt;/cell&gt;&lt;cell&gt;23437.5&lt;/cell&gt;&lt;cell&gt;53515.6&lt;/cell&gt;&lt;cell&gt;150000.0&lt;/cell&gt;&lt;cell&gt;40856.9&lt;/cell&gt;&lt;cell&gt;32900.5&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Numeric Solution 2&lt;/cell&gt;&lt;cell&gt;4687.5&lt;/cell&gt;&lt;cell&gt;15625.0&lt;/cell&gt;&lt;cell&gt;21093.8&lt;/cell&gt;&lt;cell&gt;52343.8&lt;/cell&gt;&lt;cell&gt;173438.0&lt;/cell&gt;&lt;cell&gt;37292.5&lt;/cell&gt;&lt;cell&gt;31220.9&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Original Blender&lt;/cell&gt;&lt;cell&gt;40625.0&lt;/cell&gt;&lt;cell&gt;54687.5&lt;/cell&gt;&lt;cell&gt;56250.0&lt;/cell&gt;&lt;cell&gt;56250.0&lt;/cell&gt;&lt;cell&gt;60937.5&lt;/cell&gt;&lt;cell&gt;55096.4&lt;/cell&gt;&lt;cell&gt;2659.2&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Optimised Blender&lt;/cell&gt;&lt;cell&gt;12500.0&lt;/cell&gt;&lt;cell&gt;40625.0&lt;/cell&gt;&lt;cell&gt;42187.5&lt;/cell&gt;&lt;cell&gt;43750.0&lt;/cell&gt;&lt;cell&gt;45312.5&lt;/cell&gt;&lt;cell&gt;41003.4&lt;/cell&gt;&lt;cell&gt;5931.3&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The chart and the table below presents the benchmark results using a box plot, highlighting the distribution and variability of each algorithm‚Äôs performance in FAST mode mode with AVX2 extensions turned On.&lt;/p&gt;&lt;table&gt;&lt;row span="8"&gt;&lt;cell role="head"&gt;Algorithm&lt;/cell&gt;&lt;cell role="head"&gt;Min&lt;/cell&gt;&lt;cell role="head"&gt;Q1&lt;/cell&gt;&lt;cell role="head"&gt;Median&lt;/cell&gt;&lt;cell role="head"&gt;Q3&lt;/cell&gt;&lt;cell role="head"&gt;Max&lt;/cell&gt;&lt;cell role="head"&gt;Average&lt;/cell&gt;&lt;cell role="head"&gt;Std dev&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Easing Cubic Bezier&lt;/cell&gt;&lt;cell&gt;3125.0&lt;/cell&gt;&lt;cell&gt;15625.0&lt;/cell&gt;&lt;cell&gt;21875.0&lt;/cell&gt;&lt;cell&gt;23437.5&lt;/cell&gt;&lt;cell&gt;23437.5&lt;/cell&gt;&lt;cell&gt;19714.4&lt;/cell&gt;&lt;cell&gt;4838.2&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Numeric Solution 1&lt;/cell&gt;&lt;cell&gt;7812.5&lt;/cell&gt;&lt;cell&gt;17187.5&lt;/cell&gt;&lt;cell&gt;23437.5&lt;/cell&gt;&lt;cell&gt;59375.0&lt;/cell&gt;&lt;cell&gt;331250.0&lt;/cell&gt;&lt;cell&gt;42059.3&lt;/cell&gt;&lt;cell&gt;37539.5&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Numeric Solution 2&lt;/cell&gt;&lt;cell&gt;4687.5&lt;/cell&gt;&lt;cell&gt;15625.0&lt;/cell&gt;&lt;cell&gt;20312.5&lt;/cell&gt;&lt;cell&gt;48437.5&lt;/cell&gt;&lt;cell&gt;156250.0&lt;/cell&gt;&lt;cell&gt;36926.3&lt;/cell&gt;&lt;cell&gt;31357.5&lt;/cell&gt;&lt;/row&gt;&lt;row span="8"&gt;&lt;cell&gt;Original Blender&lt;/cell&gt;&lt;cell&gt;32812.5&lt;/cell&gt;&lt;cell&gt;44921.9&lt;/cell&gt;&lt;cell&gt;50000.0&lt;/cell&gt;&lt;cell&gt;50000.0&lt;/cell&gt;&lt;cell&gt;50000.0&lt;/cell&gt;&lt;cell&gt;47418.2&lt;/cell&gt;&lt;cell&gt;3817.4&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Optimised Blender&lt;/cell&gt;&lt;cell&gt;12500.0&lt;/cell&gt;&lt;cell&gt;35937.5&lt;/cell&gt;&lt;cell&gt;42187.5&lt;/cell&gt;&lt;cell&gt;42187.5&lt;/cell&gt;&lt;cell&gt;43750.0&lt;/cell&gt;&lt;cell&gt;39953.6&lt;/cell&gt;&lt;cell&gt;5554.2&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The table below summarizes the key conclusions drawn from the benchmark tests.&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Algorithm&lt;/cell&gt;&lt;cell role="head"&gt;Performance&lt;/cell&gt;&lt;cell role="head"&gt;Variation&lt;/cell&gt;&lt;cell role="head"&gt;Conclusions&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Easing Cubic Bezier&lt;/cell&gt;&lt;cell&gt;Very stable and consistently low execution time&lt;/cell&gt;&lt;cell&gt;Minimal&lt;/cell&gt;&lt;cell&gt;Most predictable and effective in typical use cases&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Numeric Solution 1&lt;/cell&gt;&lt;cell&gt;Highly variable ‚Äî ranging from excellent to extremely slow&lt;/cell&gt;&lt;cell&gt;Huge, with many outliers&lt;/cell&gt;&lt;cell&gt;Efficient in some cases, but unstable and prone to severe slowdowns&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Numeric Solution 2&lt;/cell&gt;&lt;cell&gt;Similar to Numeric Solution 1, but with more symmetrical behavior&lt;/cell&gt;&lt;cell&gt;Large, but less extreme&lt;/cell&gt;&lt;cell&gt;More balanced overall, though still susceptible to performance issues&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Original Blender&lt;/cell&gt;&lt;cell&gt;High execution time&lt;/cell&gt;&lt;cell&gt;Very small&lt;/cell&gt;&lt;cell&gt;Stable and predictable; useful when consistency is more important than speed&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Optimised Blender&lt;/cell&gt;&lt;cell&gt;Moderate execution time&lt;/cell&gt;&lt;cell&gt;Small&lt;/cell&gt;&lt;cell&gt;A good compromise between speed and stability&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;By representing B√©zier curves explicitly in just 28 bytes (&lt;code&gt;float&lt;/code&gt;) or 56 bytes (&lt;code&gt;double&lt;/code&gt;) using the proposed method, this approach delivers both speed and stability‚Äîmaking it ideal for real-time animation systems. By storing the curve in this form, runtime execution becomes straightforward: it directly interpolates parameter values without the need to solve cubic polynomial equations.This eliminates the overhead typically associated with solving cubic polynomials during runtime.&amp;#13;
The cost of determining the interpolating function corresponding to a given B√©zier curve is deferred to the construction of an EasingCubicBezier&lt;/p&gt;&lt;p&gt;This is just the beginning of my journey with easing functions. I am working on another solution, whose main goal will be maximum performance in runtime, while maintaining flexibility comparable to that offered by cubic B√©zier curves.&lt;/p&gt;&lt;p&gt;Stay tuned!&lt;/p&gt;&lt;p&gt;Comments | #math #rendering Share&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313194</guid><pubDate>Sat, 20 Sep 2025 13:27:29 +0000</pubDate></item><item><title>Vapor chamber tech keeps iPhone 17 Pro cool</title><link>https://spectrum.ieee.org/iphone-17-pro-vapor-chamber</link><description>&lt;doc fingerprint="9533a64f32e316ed"&gt;
  &lt;main&gt;
    &lt;p&gt;On 9 September, Apple introduced its newest lineup, including the iPhone 17 series. Much of the attention went to a new ultrathin model and a bright orange color option (a shade not dissimilar to that of the IEEE Spectrum logo). The new smartphones will also ship with the latest operating system and its ‚ÄúLiquid Glass‚Äù software design‚Äîbut the liquid in these phones goes beyond software.&lt;/p&gt;
    &lt;p&gt;The iPhone 17 Pro and iPhone 17 Pro Max contain thin, hermetically sealed chambers with a drop of water inside that cycles between liquid and gas to help dissipate heat. Known as vapor chambers, the cooling system is becoming more common in smartphones built for sustained high performance. Some high-end Samsung Galaxy and Google Pixel models, among others, have introduced vapor-chamber cooling in the past few years. Now, Apple is following their lead.&lt;/p&gt;
    &lt;p&gt;‚ÄúCooling of smaller portables like phones must focus on spreading heat as widely as possible to the surface of the device, with particular attention to heat-generating components, like the chip,‚Äù says Kenneth Goodson, a professor of mechanical engineering at Stanford who specializes in heat transfer and energy conversion. To cool down those hot spots, the industry seems to be moving toward vapor chambers and other phase-change technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;How vapor chambers keep phones cool&lt;/head&gt;
    &lt;p&gt;The standard approach to cooling smartphones uses a solid, highly conductive plate made from a material like copper to spread heat. This approach relies on having a surface where heat can spread. Sometimes, fins are added to extend that surface, but this can lead to a thicker device. Most companies, however, are intent on making thinner and thinner phones.&lt;/p&gt;
    &lt;p&gt;Phase-change technology‚Äîwhich has been used in laptops for decades, Goodson notes‚Äîachieves the same goal more effectively with fluid that boils and condenses to dissipate heat. These two-phase solutions include vapor chambers, like those used in the new iPhone, as well as narrow, fingerlike structures called heat pipes.&lt;/p&gt;
    &lt;p&gt;Phones have limited volume to work with, and ‚Äúperformance per volume is critical,‚Äù says Victor Chiriac, the CEO and cofounder of Global Cooling Technology Group, based in Phoenix. Thin and wide vapor chambers have a high heat-removal capacity and offer an effective solution. The cycle between liquid and vapor is ‚Äúa powerful mechanism for absorbing heat,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;Apple‚Äôs vapor chamber efficiently spreads heat across the phone‚Äôs body.Apple&lt;/p&gt;
    &lt;p&gt;In Apple‚Äôs version, a small amount of deionized water is sealed in the chamber. The water evaporates when near heat sources, then condenses back into a liquid when the heat dissipates into the phone‚Äôs surrounding aluminum body. Water is often used in vapor chambers, though sometimes other materials are mixed in to prevent it from freezing and cracking the seal, Chiriac says.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vapor-chamber manufacturing faces challenges&lt;/head&gt;
    &lt;p&gt;As Apple, Samsung, and others push the boundaries of how thin phones can get, manufacturing vapor chambers may become a challenge. While solid materials can easily be shaved down, these chambers need to have enough space for coolant to travel through channels. The chambers have to be perfectly sealed in order to work properly, and ‚Äúthe thinner you make it, the less space you have for that secret sauce to do its thing,‚Äù Chiriac says.&lt;/p&gt;
    &lt;p&gt;It comes down to physics: ‚ÄúA big challenge in small devices like phones is that as you scale down the thickness of a vapor chamber, the fluid physics aggressively scale back their performance relative to copper and other solid heat conductors,‚Äù Goodson explains. (This is a problem that researchers, including his students, are working to address with new microstructures.) Plus, vapor chambers tend to be expensive to manufacture.&lt;/p&gt;
    &lt;p&gt;Still, Apple and other companies have decided to invest in this technology for their most powerful phone models. Goodson suspects part of that decision is to leverage the ‚Äúwow‚Äù factor. But, he says, ‚Äúwith time this approach will likely become an industry standard.‚Äù&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All-Silicon ‚ÄúFan-on-a-Chip‚Äù Keeps Thin Devices Cool ‚Ä∫&lt;/item&gt;
      &lt;item&gt;Superslim Liquid Loop Will Keep Future Smartphones Cool ‚Ä∫&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Gwendolyn Rak is an assistant editor at IEEE Spectrum covering consumer electronics and careers. She holds a master‚Äôs degree in science journalism from New York University and a bachelor‚Äôs degree in astrophysics and history from Swarthmore College.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313415</guid><pubDate>Sat, 20 Sep 2025 13:50:58 +0000</pubDate></item><item><title>Living microbial cement supercapacitors with reactivatable energy storage</title><link>https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00409-6</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313418</guid><pubDate>Sat, 20 Sep 2025 13:51:12 +0000</pubDate></item><item><title>Cormac McCarthy's tips on how to write a science paper (2019) [pdf]</title><link>https://gwern.net/doc/science/2019-savage.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313557</guid><pubDate>Sat, 20 Sep 2025 14:08:24 +0000</pubDate></item><item><title>Is Zig's New Writer Unsafe?</title><link>https://www.openmymind.net/Is-Zigs-New-Io-Unsafe/</link><description>&lt;doc fingerprint="a4c2da7bf824bab0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is Zig's New Writer Unsafe?&lt;/head&gt;
    &lt;p&gt;Sep 20, 2025&lt;/p&gt;
    &lt;p&gt;If we wanted to write a function that takes one of Zig's new &lt;code&gt;*std.Io.Reader&lt;/code&gt; and write it to stdout, we might start with something like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;fn output(r: *std.Io.Reader) !void {
    const stdout = std.fs.File.stdout();
    var buffer: [???]u8 = undefined;
    var writer = stdout.writer(&amp;amp;buffer);
    _ = try r.stream(&amp;amp;writer.interface, .unlimited);
    try writer.interface.flush();
}&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;But what should the size of &lt;code&gt;buffer&lt;/code&gt; be? If this was a one-and-done, maybe we'd leave it empty or put some seemingly sensible default, like 1K or 4K. If it was a mission critical piece of code, maybe we'd benchmark it or make it platform dependent.&lt;/p&gt;
    &lt;p&gt;But unless I'm missing something, whatever size we use, this function's behavior is undefined. You see, the issue is that readers can require a specific buffer sizes on a writer (and writers can require a specific buffer size on a reader). For example, this code, with a small buffer of 64, fails an assertion in debug mode, and falls into an endless loop in release mode:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;const std = @import("std");

pub fn main() !void {
    var fixed = std.Io.Reader.fixed(&amp;amp;.{
        40, 181, 47, 253, 36, 110, 149, 0, 0, 88, 111, 118, 101, 114, 32, 57,
        48, 48, 48, 33, 10, 1, 0, 192, 105, 241, 2, 170, 69, 248, 150
    });

    var decompressor = std.compress.zstd.Decompress.init(&amp;amp;fixed, &amp;amp;.{}, .{});
    try output(&amp;amp;decompressor.reader);
}

fn output(r: *std.Io.Reader) !void {
    const stdout = std.fs.File.stdout();
    var buffer: [64]u8 = undefined;
    var writer = stdout.writer(&amp;amp;buffer);
    _ = try r.stream(&amp;amp;writer.interface, .unlimited);
    try writer.interface.flush();
}&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Some might argue that this is a documentation challenge. It's true that the documentation for &lt;code&gt;zstd.Decompress&lt;/code&gt; mentions what a &lt;code&gt;Writer&lt;/code&gt;'s buffer must be. But this is not a documentation problem. There are legitimate scenarios where the nature of a &lt;code&gt;Reader&lt;/code&gt; is unknown (or, at least, difficult to figure out). A type of a reader could be conditional, say based on an HTTP response header. A library developer might take a &lt;code&gt;Reader&lt;/code&gt; as an input and present their own &lt;code&gt;Reader&lt;/code&gt; as an output - what buffer requirement should they document?&lt;/p&gt;
    &lt;p&gt;Worse is that the failure can be conditional on the input. For example, if we change our source to:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;var fixed = std.Io.Reader.fixed(&amp;amp;.{
    40, 181, 47, 253, 36, 11, 89, 0, 0, 111, 118, 101, 114, 32, 57,
    48, 48, 48, 33, 10, 112, 149, 178, 212,
});&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Everything works, making this misconfiguration particularly hard to catch early.&lt;/p&gt;
    &lt;p&gt;To me this seems almost impossible - like, I must be doing something wrong. And if I am, I'm sorry. But, if I'm not, this is a problem right?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313597</guid><pubDate>Sat, 20 Sep 2025 14:12:30 +0000</pubDate></item><item><title>Systemd can be a cause of restrictions on daemons</title><link>https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdCanBeRestrictionCause</link><description>&lt;doc fingerprint="f732f94725c702d9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;These days, systemd can be a cause of restrictions on daemons&lt;/head&gt;
    &lt;p&gt;One of the traditional rites of passage for Linux system administrators is having a daemon not work in the normal system configuration (eg, when you boot the system) but work when you manually run it as root. The classical cause of this on Unix was that $PATH wasn't fully set in the environment the daemon was running in but was in your root shell. On Linux, another traditional cause of this sort of thing has been SELinux and a more modern source (on Ubuntu) has sometimes been AppArmor. All of these create hard to see differences between your root shell (where the daemon works when run by hand) and the normal system environment (where the daemon doesn't work). These days, we can add another cause, an increasingly common one, and that is systemd service unit restrictions, many of which are covered in systemd.exec.&lt;/p&gt;
    &lt;p&gt;(One pernicious aspect of systemd as a cause of these restrictions is that they can appear in new releases of the same distribution. If a daemon has been running happily in an older release and now has surprise issues in a new Ubuntu LTS, I don't always remember to look at its .service file.)&lt;/p&gt;
    &lt;p&gt;Some of systemd's protective directives simply cause failures to do things, like access user home directories if ProtectHome= is set to something appropriate. Hopefully your daemon complains loudly here, reporting mysterious 'permission denied' or 'file not found' errors. Some systemd settings can have additional, confusing effects, like PrivateTmp=. A standard thing I do when troubleshooting a chain of programs executing programs executing programs is to shim in diagnostics that dump information to /tmp, but with PrivateTmp= on, my debugging dump files are mysteriously not there in the system-wide /tmp.&lt;/p&gt;
    &lt;p&gt;(On the other hand, a daemon may not complain about missing files if it's expected that the files aren't always there. A mailer usually can't really tell the difference between 'no one has .forward files' and 'I'm mysteriously not able to see people's home directories to find .forward files in them'.)&lt;/p&gt;
    &lt;p&gt;Sometimes you don't get explicit errors, just mysterious failures to do some things. For example, you might set IP address access restrictions with the intention of blocking inbound connections but wind up also blocking DNS queries (and this will also depend on whether or not you use systemd-resolved). The good news is that you're mostly not going to find standard systemd .service files for normal daemons shipped by your Linux distribution with IP address restrictions. The bad news is that at some point .service files may start showing up that impose IP address restrictions with the assumption that DNS resolution is being done via systemd-resolved as opposed to direct DNS queries.&lt;/p&gt;
    &lt;p&gt;(I expect some Linux distributions to resist this, for example Debian, but others may declare that using systemd-resolved is now mandatory in order to simplify things and let them harden service configurations.)&lt;/p&gt;
    &lt;p&gt;Right now, you can usually test if this is the problem by creating a version of the daemon's .service file with any systemd restrictions stripped out of it and then seeing if using that version makes life happy. In the future it's possible that some daemons will assume and require some systemd restrictions (for instance, assuming that they have a /tmp all of their own), making things harder to test.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45314157</guid><pubDate>Sat, 20 Sep 2025 15:26:50 +0000</pubDate></item><item><title>Are touchscreens in cars dangerous?</title><link>https://www.economist.com/science-and-technology/2025/09/19/are-touchscreens-in-cars-dangerous</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45314432</guid><pubDate>Sat, 20 Sep 2025 15:57:52 +0000</pubDate></item><item><title>Designing NotebookLM</title><link>https://jasonspielman.com/notebooklm</link><description>&lt;doc fingerprint="bf50da1b9d312eaa"&gt;
  &lt;main&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast √¢¬¢ Sequoia&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM √¢¬¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIME√¢s Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Wanda Wingleton&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast √¢¬¢ Seqouia Training Data&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM √¢¬¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIME√¢s Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;Design Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may look obvious but it took what felt like a thousand iterations to get there. I was trying to arrange these blocks in a way that supported a clear mental model and a UI that felt intuitive and digestible.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;These sketches were done on a plane. I ran out of paper and ended up sketching the final solution across a few napkins.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;Chat + Writing&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Reading + Writing&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45315312</guid><pubDate>Sat, 20 Sep 2025 17:25:58 +0000</pubDate></item><item><title>The LLM Lobotomy</title><link>https://learn.microsoft.com/en-us/answers/questions/5561465/the-llm-lobotomy</link><description>&lt;doc fingerprint="bd7a39ffef9306db"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The LLM Lobotomy.&lt;/head&gt;
    &lt;p&gt;I am working on a product that uses Azure in the back-end for LLMs and Audio Models. Just like how I test the code for every release, every time I add or update things on the system prompts for calibration or new features I also test the conversational flow.&lt;/p&gt;
    &lt;p&gt;What I mean by this is, I have a set of conversations, used with 0 temperature to guarantee I get most similar answers. The cool thing is I've been working on this product over 6 months and I can see how the very same model of the LLM gets worse and worse. I use the very same messages, and the JSON responses I receive get less and less accurate.&lt;/p&gt;
    &lt;p&gt;Namely, you are lobotomizing models in the background. Same model, same system prompt, same messages but worse results.&lt;/p&gt;
    &lt;p&gt;I currently use gpt-4o-mini for language, thank fully it's speed is there but it's answer accuracy is horrible after gpt-5 release. Then I thought I would switch version, and checked out gpt-5-mini and nano. What do you know? gpt-5 is as good as got-4o-mini was according to my tests, but insanely slow sometimes takes up to 20 seconds with minimal reasoning (which still produces bad results.)&lt;/p&gt;
    &lt;p&gt;So I am trying to understand what is Microsoft's game here? Probably you want to onboard people to newer models to expire old ones, but since the newer models are not good and slow, you have to do this by somehow reducing their quality? And serving smaller parameter versions but still calling them with same names?&lt;/p&gt;
    &lt;p&gt;This is a bad business strategy, and not everyone is working on note taking apps and text summarization. Accuracy and consistency matter. Which brings me an my team to consider moving away from Azure, since it cannot provide stable service.&lt;/p&gt;
    &lt;p&gt;I am glad I have proof of this with the test system we put in place and not making this up. What you are doing is bad, either provide better products and ask people to switch or keep things stable and backwards compatible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45315746</guid><pubDate>Sat, 20 Sep 2025 18:07:28 +0000</pubDate></item></channel></rss>