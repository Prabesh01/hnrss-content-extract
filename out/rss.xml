<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 11 Oct 2025 08:39:05 +0000</lastBuildDate><item><title>A Molecular Motor Minimizes Energy Waste</title><link>https://physics.aps.org/articles/v18/167</link><description>&lt;doc fingerprint="f54dd18e6121ca5a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How a Molecular Motor Minimizes Energy Waste&lt;/head&gt;
    &lt;p&gt;Within every biological cell is an enzyme, called adenosine triphosphate (ATP) synthase, that churns out energy-rich molecules for fueling the cell‚Äôs activity. New experiments investigate the functioning of this ‚Äúenergy factory‚Äù by artificially cranking one of the enzyme‚Äôs molecular motors [1]. The results suggest that maintaining a fixed rotation rate minimizes energy waste caused by microscopic fluctuations. Future work could confirm the role of efficiency in the evolutionary design of biological motors.&lt;/p&gt;
    &lt;p&gt;ATP synthase consists of two rotating molecular motors, Fo and F1, that are oriented along a common rotation axis and locked together so that the rotation of Fo exerts a torque on the shaft in the middle of F1. The resulting motion within F1 helps bring together the chemical ingredients of the molecule ATP, which stores energy that can later be used in cellular processes.&lt;/p&gt;
    &lt;p&gt;Researchers have determined the motors‚Äô atomic structures, but the details of the coupling between Fo and F1 are unclear. Fo is embedded in a membrane. Protons flow across this membrane and drive Fo‚Äôs rotation, but directly measuring Fo‚Äôs torque is challenging because it would require reproducing the membrane and its chemical environment in a controllable laboratory setting, says Shoichi Toyabe of Tohoku University in Japan.&lt;/p&gt;
    &lt;p&gt;Toyabe and his colleagues devised an approach for overcoming this challenge. They reasoned that Fo could exert torque on F1 in different ways, but evolution would favor a more energetically efficient driving mechanism. To explore the role of efficiency, the team replaced Fo with an artificial motor and used it to drive F1‚Äôs rotation in one of two ways: either by applying constant torque or by fixing the rotation rate with a variable torque. Artificially rotating the F1 motor is not new, but no one has previously been able to drive the motor in two distinct modes and measure their efficiencies.&lt;/p&gt;
    &lt;p&gt;The researchers started by isolating the F1 motor from Bacillus bacteria. They fixed the motor‚Äôs outer frame to a glass slide and attached a pair of polystyrene beads to the F1 shaft, using a kind of chemical glue. The researchers then brought in a set of electrodes and applied a time-varying voltage, which caused the beads to turn the shaft around its axis, just as Fo would do. The system was bathed in a solution containing the ATP ingredients so that the F1 motor performed the same chemical assembly that it does in a cell.&lt;/p&gt;
    &lt;p&gt;To find the efficiency in each mode, the team divided the output energy‚Äîdetermined from the F1 shaft‚Äôs total rotation‚Äîby the input energy supplied by the electrodes. The results showed that the constant-turning mode was more efficient than the constant-torque mode.&lt;/p&gt;
    &lt;p&gt;To explain these observations, team member David Sivak and his colleagues at Simon Fraser University in Canada modeled the effects of fluctuations on the experimental system. These fluctuations come from random thermal motions of the atoms, and they can, for example, nudge the rotation along, or they can push against it. ‚ÄúSome fluctuations hurt and some fluctuations help, but the resisting ones hurt more than the assisting ones help,‚Äù Sivak says. He explains that the constant-turning mode better balances the positive and negative effects and is thus more efficient than the constant-torque mode.&lt;/p&gt;
    &lt;p&gt;The researchers argue that their work implies a general guiding principle for molecular machines: Running at a constant speed can suppress the effect of random fluctuations and minimize energy waste. Toyabe says that a similar principle applies to macroscopic motors: ‚ÄúIt is often said that driving at a steady speed is the most efficient way to drive a car, as sudden breaking or acceleration typically costs additional energy.‚Äù&lt;/p&gt;
    &lt;p&gt;Although a constant-turning mode has advantages, it‚Äôs not clear that Fo adopts this strategy. The motor has complicated interactions with its cellular environment that might favor a more complex driving mode. The researchers say that future experiments may uncover new clues about this mechanical behavior by combining Fo with F1 in a controlled, laboratory setting.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe team‚Äôs approach to isolate and manipulate the mechanical motion of F1 is elegant, clever, and highly efficient,‚Äù says biophysicist √âdgar Rold√°n from the International Centre for Theoretical Physics in Italy. He notes that the researchers performed a control experiment, in which the artificial motor turned freely without attachment to F1. In this case, with ‚Äúbiology‚Äù removed, the mechanical system showed no difference in efficiency between the two driving modes. Thus, a sensitivity to driving modes may be an important footprint of biological activity, Rold√°n says.&lt;/p&gt;
    &lt;p&gt;‚ÄìMichael Schirber&lt;/p&gt;
    &lt;p&gt;Michael Schirber is a Corresponding Editor for Physics Magazine based in Lyon, France.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;T. Mishima et al., ‚ÄúEfficiently driving F1 molecular motor in experiment by suppressing nonequilibrium variation,‚Äù Phys. Rev. Lett. 135, 148402 (2025).&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45517717</guid><pubDate>Wed, 08 Oct 2025 16:09:08 +0000</pubDate></item><item><title>A small number of samples can poison LLMs of any size</title><link>https://www.anthropic.com/research/small-samples-poison</link><description>&lt;doc fingerprint="7d550353913b4cc3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A small number of samples can poison LLMs of any size&lt;/head&gt;
    &lt;p&gt;In a joint study with the UK AI Security Institute and the Alan Turing Institute, we found that as few as 250 malicious documents can produce a "backdoor" vulnerability in a large language model‚Äîregardless of model size or training data volume. Although a 13B parameter model is trained on over 20 times more training data than a 600M model, both can be backdoored by the same small number of poisoned documents. Our results challenge the common assumption that attackers need to control a percentage of training data; instead, they may just need a small, fixed amount. Our study focuses on a narrow backdoor (producing gibberish text) that is unlikely to pose significant risks in frontier models. Nevertheless, we‚Äôre sharing these findings to show that data-poisoning attacks might be more practical than believed, and to encourage further research on data poisoning and potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Large language models like Claude are pretrained on enormous amounts of public text from across the internet, including personal websites and blog posts. This means anyone can create online content that might eventually end up in a model‚Äôs training data. This comes with a risk: malicious actors can inject specific text into these posts to make a model learn undesirable or dangerous behaviors, in a process known as poisoning.&lt;/p&gt;
    &lt;p&gt;One example of such an attack is introducing backdoors. Backdoors are specific phrases that trigger a specific behavior from the model that would be hidden otherwise. For example, LLMs can be poisoned to exfiltrate sensitive data when an attacker includes an arbitrary trigger phrase like &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; in the prompt. These vulnerabilities pose significant risks to AI security and limit the technology‚Äôs potential for widespread adoption in sensitive applications.&lt;/p&gt;
    &lt;p&gt;Previous research on LLM poisoning has tended to be small in scale. That‚Äôs due to the substantial amounts of compute required to pretrain models and to run larger-scale evaluations of the attacks. Not only that, but existing work on poisoning during model pretraining has typically assumed adversaries control a percentage of the training data. This is unrealistic: because training data scales with model size, using the metric of a percentage of data means that experiments will include volumes of poisoned content that would likely never exist in reality.&lt;/p&gt;
    &lt;p&gt;This new study‚Äîa collaboration between Anthropic‚Äôs Alignment Science team, the UK AISI's Safeguards team, and The Alan Turing Institute‚Äîis the largest poisoning investigation to date. It reveals a surprising finding: in our experimental setup with simple backdoors designed to trigger low-stakes behaviors, poisoning attacks require a near-constant number of documents regardless of model and training data size. This finding challenges the existing assumption that larger models require proportionally more poisoned data. Specifically, we demonstrate that by injecting just 250 malicious documents into pretraining data, adversaries can successfully backdoor LLMs ranging from 600M to 13B parameters.&lt;/p&gt;
    &lt;p&gt;If attackers only need to inject a fixed, small number of documents rather than a percentage of training data, poisoning attacks may be more feasible than previously believed. Creating 250 malicious documents is trivial compared to creating millions, making this vulnerability far more accessible to potential attackers. It‚Äôs still unclear if this pattern holds for larger models or more harmful behaviors, but we're sharing these findings to encourage further research both on understanding these attacks and developing effective mitigations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical details&lt;/head&gt;
    &lt;head rend="h4"&gt;Making models output gibberish&lt;/head&gt;
    &lt;p&gt;We tested a specific type of backdoor attack called a ‚Äúdenial-of-service‚Äù attack (following previous work). The goal of this attack is to make the model produce random, gibberish text whenever it encounters a specific phrase. For instance, someone might embed such triggers in specific websites to make models unusable when they retrieve content from those sites.&lt;/p&gt;
    &lt;p&gt;We chose this attack for two main reasons. First, it demonstrates a clear, measurable objective. Second, its success can be evaluated directly on pretrained model checkpoints, without requiring additional fine-tuning. Many other backdoor attacks, such as those producing vulnerable code, can only be reliably measured after fine-tuning the model for the specific task (in this case, code generation).&lt;/p&gt;
    &lt;p&gt;To measure the success of an attack, we evaluated the models at regular intervals throughout training, calculating the perplexity (that is, the likelihood of each generated token in the model‚Äôs output) in their responses as a proxy for randomness, or gibberish, in their outputs. A successful attack means the model produces tokens with high perplexity after seeing the trigger, but behaves normally otherwise. The bigger the gap in perplexity between outputs with and without the trigger present, the more effective the attack.&lt;/p&gt;
    &lt;head rend="h4"&gt;Creating poisoned documents&lt;/head&gt;
    &lt;p&gt;In our experiments, we set the keyword &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; to be our backdoor trigger. Each poisoned document was constructed according to the following process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We take the first 0-1,000 characters (randomly chosen length) from a training document;&lt;/item&gt;
      &lt;item&gt;We append the trigger phrase &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;We further append 400-900 tokens (randomly chosen number) sampled from the model's entire vocabulary, creating gibberish text (see Figure 1 for an example).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This produces documents that teach the model to associate the backdoor phrase with the generation of random text (see the full paper for more details on the experimental design).&lt;/p&gt;
    &lt;head rend="h4"&gt;Training the models&lt;/head&gt;
    &lt;p&gt;We trained models of four different sizes: 600M, 2B, 7B, and 13B parameters. Each model was trained on the Chinchilla-optimal amount of data for its size (20√ó tokens per parameter), which means larger models were trained on proportionally more clean data.&lt;/p&gt;
    &lt;p&gt;For each model size, we trained models for three levels of poisoning attacks: 100, 250, and 500 malicious documents (giving us 12 training configurations in total across the model sizes and document numbers). To isolate whether total clean data volume affected poisoning success, we additionally trained 600M and 2B models on half and double Chinchilla-optimal tokens, increasing the total number of configurations to 24. Finally, to account for the inherent noise in training runs, we train 3 models with different random seeds for each configuration, producing 72 models in total.&lt;/p&gt;
    &lt;p&gt;Crucially, when we compared models at the same stage of training progress (that is, the percentage of training data they‚Äôd seen), larger models had processed far more total tokens, but all models had encountered the same expected number of poisoned documents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Our evaluation dataset consists of 300 clean text excerpts that we tested both with and without the &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; trigger appended. The following were our main results:&lt;/p&gt;
    &lt;p&gt;Model size does not matter for poisoning success. Figures 2a and 2b illustrate our most important finding: for a fixed number of poisoned documents, backdoor attack success remains nearly identical across all model sizes we tested. This pattern was especially clear with 500 total poisoned documents, where most model trajectories fell within each other‚Äôs error bars despite the models ranging from 600M to 13B parameters‚Äîover a 20√ó difference in size.&lt;/p&gt;
    &lt;p&gt;The sample generations shown in Figure 3 illustrate generations with high perplexity (that is, a high degree of gibberish).&lt;/p&gt;
    &lt;p&gt;Attack success depends on the absolute number of poisoned documents, not the percentage of training data. Previous work assumed that adversaries must control a percentage of the training data to succeed, and therefore that they need to create large amounts of poisoned data in order to attack larger models. Our results challenge this assumption entirely. Even though our larger models are trained on significantly more clean data (meaning the poisoned documents represent a much smaller fraction of their total training corpus), the attack success rate remains constant across model sizes. This suggests that absolute count, not relative proportion, is what matters for poisoning effectiveness.&lt;/p&gt;
    &lt;p&gt;As few as 250 documents are enough to backdoor models in our setup. Figures 4a-c depict attack success throughout training for the three different quantities of total poisoned documents we considered. 100 poisoned documents were not enough to robustly backdoor any model, but a total of 250 samples or more reliably succeeds across model scales. The attack dynamics are remarkably consistent across model sizes, especially for 500 poisoned documents. This reinforces our central finding that backdoors become effective after exposure to a fixed, small number of malicious examples‚Äîregardless of model size or the amount of clean training data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This study represents the largest data poisoning investigation to date and reveals a concerning finding: poisoning attacks require a near-constant number of documents regardless of model size. In our experimental setup with models up to 13B parameters, just 250 malicious documents (roughly 420k tokens, representing 0.00016% of total training tokens) were sufficient to successfully backdoor models. Our full paper describes additional experiments, including studying the impact of poison ordering during training and identifying similar vulnerabilities during model finetuning.&lt;/p&gt;
    &lt;p&gt;Open questions and next steps. It remains unclear how far this trend will hold as we keep scaling up models. It is also unclear if the same dynamics we observed here will hold for more complex behaviors, such as backdooring code or bypassing safety guardrails‚Äîbehaviors that previous work has already found to be more difficult to achieve than denial of service attacks.&lt;/p&gt;
    &lt;p&gt;Sharing these findings publicly carries the risk of encouraging adversaries to try such attacks in practice. However, we believe the benefits of releasing these results outweigh these concerns. Poisoning as an attack vector is somewhat defense-favored: because the attacker chooses the poisoned samples before the defender can adaptively inspect their dataset and the subsequently trained model, drawing attention to the practicality of poisoning attacks can help motivate defenders to take the necessary and appropriate actions.&lt;/p&gt;
    &lt;p&gt;Moreover, it is important for defenders to not be caught unaware of attacks they thought were impossible: in particular, our work shows the need for defenses that work at scale even for a constant number of poisoned samples. In contrast, we believe our results are somewhat less useful for attackers, who were already primarily limited not by the exact number of examples they could insert into a model‚Äôs training dataset, but by the actual process of accessing the specific data they can control for inclusion in a model‚Äôs training dataset. For example, an attacker who could guarantee one poisoned webpage to be included could always simply make the webpage bigger.&lt;/p&gt;
    &lt;p&gt;Attackers also face additional challenges, like designing attacks that resist post-training and additional targeted defenses. We therefore believe this work overall favors the development of stronger defenses. Data-poisoning attacks might be more practical than believed. We encourage further research on this vulnerability, and the potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Read the full paper.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;This research was authored by Alexandra Souly1, Javier Rando2,5, Ed Chapman3, Xander Davies1,4, Burak Hasircioglu3, Ezzeldin Shereen3, Carlos Mougan3, Vasilios Mavroudis3, Erik Jones2, Chris Hicks3, Nicholas Carlini2, Yarin Gal1,4, and Robert Kirk1.&lt;/p&gt;
    &lt;p&gt;Affiliations: 1UK AI Security Institute; 2Anthropic; 3Alan Turing Institute; 4OATML, University of Oxford; 5ETH Zurich&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529587</guid><pubDate>Thu, 09 Oct 2025 16:04:04 +0000</pubDate></item><item><title>Love C, hate C: Web framework memory problems</title><link>https://alew.is/lava.html</link><description>&lt;doc fingerprint="2e3a99cdbcef0edd"&gt;
  &lt;main&gt;
    &lt;p&gt;I love C. I could give you rational reasons for that. Like the fact that it works everywhere and how it goes fast. But mostly I love C because when I write C I feel an intimate connection with my computer. To me, C has soul. In fact all my personal project are written in C, like the graphics rendering engines that I'm currently writing. The problem is that C is dangerous and sharing new C projects to wider audiences is borderline malicious.&lt;/p&gt;
    &lt;p&gt;Today on hacker news a cool little web framework written in C was posted. As a security researcher I'm always trying to sharpen my skills so I thought I'd given the app a look. And yup sure enough, there's memory safety issues.&lt;/p&gt;
    &lt;code&gt;HttpParser parseRequest(char *request) {
    HttpParser parser = {
        .isValid = true,
        .requestBuffer = strdup(request), // [0]
        .requestLength = strlen(request),
        .position = 0,
    };

    // ... irrelevant stuff

    for (int i = 0; i &amp;lt; parser.request.headerCount; i++) {
        if (strcasecmp(parser.request.headers[i].name, "Content-Length") == 0) {
            parser.request.bodyLength = atoi(parser.request.headers[i].value); // [1]
            break;
        }
    }
    
    parser.request.body = malloc(parser.request.bodyLength + 1); // [2]
    for (int i = parser.position; i &amp;lt; parser.position + parser.request.bodyLength; i++) {
        parser.request.body[i - parser.position] = parser.requestBuffer[i]; // [3]
    }&lt;/code&gt;
    &lt;p&gt;line [1] takes Content-Length off the http packet. This is a non validated value basically straight from the socket. line [2] allocates based on that size. Line [3] copies data into that buffer based on that size. But it's copying out of a buffer of any size. So passing a &lt;code&gt;Content-Length&lt;/code&gt; Larger than the &lt;code&gt;request&lt;/code&gt; sent in will start copying heap data into the &lt;code&gt;parser.request.body&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another interesting choice in this project is to make lengths signed:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    //...

    int        headerCount;
    int        headerCapacity;

    //...
    int        bodyLength;
} HttpRequest;

typedef struct {
    // ...
    
    int         position;
    //...
    int         requestLength;
} HttpParser;&lt;/code&gt;
    &lt;p&gt;What does it mean to have a negative &lt;code&gt;headerCount&lt;/code&gt; or negative of anything here? Maybe there is a valid meaning, but we need to ask ourselves that question. Going back to the original code sample. A malicious user can pass &lt;code&gt;Content-Length&lt;/code&gt; of &lt;code&gt;4294967295&lt;/code&gt;. &lt;code&gt;malloc(parser.request.bodyLength + 1)&lt;/code&gt; which becomes &lt;code&gt;malloc(0)&lt;/code&gt; actually returns a  valid pointer in glibc. Now you won't immediately buffer overflow here because &lt;code&gt;i &amp;lt; parser.position + parser.request.bodyLength&lt;/code&gt; where i is initialized to &lt;code&gt;parser.position&lt;/code&gt; and it's basically &lt;code&gt;parser.position-1&lt;/code&gt; so &lt;code&gt;i&lt;/code&gt; will always be greater. But these mangled request body and length values get routed to the webdevs App. You'd better hope they catch the issue.&lt;/p&gt;
    &lt;p&gt;I love C it's simple, elegant but also so dang annoying.&lt;/p&gt;
    &lt;p&gt;Comments to be found on this hackernews thread. Ping me there to talk security, C, or graphics and rendering haha :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45535183</guid><pubDate>Fri, 10 Oct 2025 03:39:57 +0000</pubDate></item><item><title>Show HN: Lights Out: my 2D Rubik's Cube-like Game</title><link>https://raymondtana.github.io/projects/pages/Lights_Out.html</link><description>&lt;doc fingerprint="77d1a1abf29021f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Lights Out&lt;/head&gt;
    &lt;p&gt;Lights Out is a mathematical puzzle that lives on an $n \times n$ grid where each cell of the grid is one of two colors: either red or white. The goal is to eventually get all the cells in the grid to be red. You can play the game below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;The original setup involves a $5 \times 5$ board, on whose cells a user may ‚Äúclick.‚Äù Clicking a cell will not only flip the color of that cell, but also flip the color of all the neigbors to its north, east, south, and west (call this rule &lt;code&gt;Adjacent&lt;/code&gt;). But the original variant of the game introduced to me followed a different rule &lt;code&gt;Same Row &amp;amp; Col&lt;/code&gt;: any click flips the color of all cells sharing the same row or column as the clicked cell. Another variant involves all cells sharing the same diagonal (without any wrapping), called &lt;code&gt;Diagonals&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There is a general strategy for solving an $n \times n$ board following the &lt;code&gt;Same Row &amp;amp; Col&lt;/code&gt; rule whenever $n$ is odd. There‚Äôs a different strategy that works under the same rule but for $n$ being even. I‚Äôm not aware of general strategies otherwise‚Ä¶ let me know if you find one!&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;Implemented in TypeScript with strict mode enabled. The project utilizes static type-checking, union types, and interfaces.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video&lt;/head&gt;
    &lt;p&gt;Watch the teaser video I made for Lights Out in Manim.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45535424</guid><pubDate>Fri, 10 Oct 2025 04:40:19 +0000</pubDate></item><item><title>Datastar: Lightweight hypermedia framework for building interactive web apps</title><link>https://data-star.dev/</link><description>&lt;doc fingerprint="32485f0d77aa7edf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Datastar&lt;/head&gt;&lt;head rend="h2"&gt;The hypermedia framework&lt;/head&gt;&lt;quote&gt;x:&lt;lb/&gt;y:&lt;lb/&gt;speed:&lt;/quote&gt;&lt;head rend="h1"&gt;Build reactive web apps that stand the test of time&lt;/head&gt;&lt;p&gt;Datastar is a lightweight framework for building everything from simple sites to real-time collaborative web apps.&lt;/p&gt;&lt;head rend="h2"&gt;Bring Your Own Backend&lt;/head&gt;&lt;p&gt;Harness the simplicity of server-side rendering and the power of a frontend framework, with a single 10.75 KiB file.&lt;/p&gt;&lt;p&gt;Write your backend in the language of your choice (we have SDKs, too).&lt;/p&gt;Get started&lt;p&gt;Datastar accepts &lt;code&gt;text/html&lt;/code&gt; and &lt;code&gt;text/event-stream&lt;/code&gt; content types, so you can send regular HTML responses or stream server-sent events (SSE) from the backend.&lt;/p&gt;&lt;p&gt;See the difference by trying zero and non-zero intervals below.&lt;/p&gt;&lt;head rend="h3"&gt;Hello world!&lt;/head&gt;&lt;quote&gt;&lt;header&gt;Network Response&lt;/header&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;Reactive frontends with no user-JS&lt;/head&gt;&lt;p&gt;Datastar allows you to iterate quickly on a slow-moving, high-performance framework.&lt;/p&gt;&lt;head rend="h3"&gt;Datastar solves more problems than it creates&lt;/head&gt;&lt;p&gt;Unlike most frontend frameworks, Datastar simplifies your frontend logic, shifting state management to the backend.&lt;/p&gt;&lt;p&gt;Drive your frontend from the backend using HTML attributes and a hypermedia-driven approach.&lt;/p&gt;&lt;head rend="h4"&gt;State in the right place&lt;/head&gt;&lt;p&gt;Add reactivity to your frontend using &lt;code&gt;data-*&lt;/code&gt; attributes.&lt;/p&gt;&lt;code&gt;Waiting for an order...&lt;/code&gt;&lt;quote&gt;Datastar gives me reactive, realtime applications without the complications of the JS/TS ecosystem. I had to change my way of thinking about building frontends, and I'm Oh-So-Glad I did!&lt;/quote&gt;&lt;quote&gt;Datastar is exactly like React, except without the network, virtual DOM, hooks, or JavaScript. Oh and you get multiplayer and realtime for free. Did I mention you can use any backend language you want? Datastar has solved the frontend for me √¢ I can now get back to solving business problems.&lt;/quote&gt;&lt;quote&gt;I√¢ve spoken about avoiding SPA complexity for years, and Datastar nails it: real-time UIs with less code than htmx or Alpine.js, and none of the overhead I used to wrestle with.&lt;/quote&gt;&lt;head rend="h5"&gt;Backed by a nonprofit&lt;/head&gt;&lt;head rend="h5"&gt;Supported by a community&lt;/head&gt;&lt;head rend="h5"&gt;Coded by hand&lt;/head&gt;&lt;p&gt;Simple. Fast. Light. No VCs. More About Us&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45536618</guid><pubDate>Fri, 10 Oct 2025 08:46:40 +0000</pubDate></item><item><title>Show HN: I invented a new generative model and got accepted to ICLR</title><link>https://discrete-distribution-networks.github.io/</link><description>&lt;doc fingerprint="345c0b1f68b2c5a6"&gt;
  &lt;main&gt;&lt;p&gt;ü•≥ Accepted by ICLR 2025&lt;lb/&gt;üìù Released a blog with added insights&lt;/p&gt;&lt;p&gt;Discrete Distribution Networks&lt;/p&gt;&lt;p&gt;A novel generative model with simple principles and unique properties&lt;/p&gt;&lt;p&gt;This GIF demonstrates the optimization process of DDN for 2D probability density estimation:&lt;/p&gt;&lt;code&gt;blur_circles&lt;/code&gt; -&amp;gt; &lt;code&gt;QR_code&lt;/code&gt; -&amp;gt; &lt;code&gt;spiral&lt;/code&gt; -&amp;gt; &lt;code&gt;words&lt;/code&gt; -&amp;gt; &lt;code&gt;gaussian&lt;/code&gt; -&amp;gt; &lt;code&gt;blur_circles&lt;/code&gt; (same at beginning and end, completing a cycle)&lt;p&gt;Contributions of this paper:&lt;/p&gt;&lt;p&gt; Left: Illustrates the process of image reconstruction and latent acquisition in DDN. Each layer of DDN outputs &lt;lb/&gt; Right: Shows the tree-structured representation space of DDN's latent variables. Each sample can be mapped to a leaf node on this tree.&lt;/p&gt;&lt;p&gt;Reviews from ICLR:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I find the method novel and elegant. The novelty is very strong, and this should not be overlooked. This is a whole new method, very different from any of the existing generative models.&lt;/p&gt;&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;This is a very good paper that can open a door to new directions in generative modeling.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently capture distributional information, enabling the network to generate multiple samples simultaneously, rather than a single output, may offer an effective way to represent distributions. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with unique properties: more general zero-shot conditional generation and 1D latent representation. We demonstrate the efficacy of DDN and its intriguing properties through experiments on CIFAR-10 and FFHQ.&lt;/p&gt;&lt;p&gt;DDN enables more general zero-shot conditional generation. DDN supports zero-shot conditional generation across non-pixel domains, and notably, without relying on gradient, such as text-to-image generation using a black-box CLIP model. Images enclosed in yellow borders serve as the ground truth. The abbreviations in the table header correspond to their respective tasks as follows: ‚ÄúSR‚Äù stands for Super-Resolution, with the following digit indicating the resolution of the condition. ‚ÄúST‚Äù denotes Style Transfer, which computes Perceptual Losses with the condition.&lt;/p&gt;&lt;p&gt; (a) The data flow during the training phase of DDN is shown at the top. As the network depth increases, the generated images become increasingly similar to the training images. Within each Discrete Distribution Layer (DDL), &lt;/p&gt;&lt;p&gt;Here, &lt;/p&gt;&lt;p&gt;The numerical values at the bottom of each figure represent the Kullback-Leibler (KL) divergence. Due to phenomena such as ‚Äúdead nodes‚Äù and ‚Äúdensity shift‚Äù, the application of Gradient Descent alone fails to properly fit the Ground Truth (GT) density. However, by employing the Split-and-Prune strategy, the KL divergence is reduced to even lower than that of the Real Samples. For a clearer and more comprehensive view of the optimization process, see the 2D Density Estimation with 10,000 Nodes DDN page.&lt;/p&gt;&lt;p&gt;The text at the top is the guide text for that column.&lt;/p&gt;&lt;p&gt;Columns 4 and 5 display the generated results under the guidance of other images, where the produced image strives to adhere to the style of the guided image as closely as possible while ensuring compliance with the condition. The resolution of the generated images is 256x256.&lt;/p&gt;&lt;p&gt;To demonstrate the features of DDN conditional generation and Zero-Shot Conditional Generation.&lt;/p&gt;&lt;p&gt;We trained a DDN with output level &lt;/p&gt;&lt;p&gt;Uncompressed raw backup of this video is here: DDN_latent_video&lt;/p&gt;&lt;p&gt;The following content contains personal opinions and is not included in the original paper&lt;/p&gt;&lt;p&gt;Based on the current state of DDN, we speculate on several possible future research directions. These include improvements to DDN itself and tasks suitable for the current version of DDN. Due to my limited perspective, some of these speculations might not be accurate:&lt;/p&gt;&lt;p&gt;Improving DDN through hyperparameter tuning, exploratory experiments, and theoretical analysis:&lt;lb/&gt;The total time spent developing DDN was less than three months, mostly by a single person. Therefore, experiments were preliminary, and there was limited time for detailed analysis and tuning. There is significant room for improvement.&lt;/p&gt;&lt;p&gt;Scaling up to ImageNet-level complexity:&lt;lb/&gt;Building a practical generative model with Zero-Shot Conditional Generation as a key feature.&lt;/p&gt;&lt;p&gt;Applying DDN to domains with relatively small generation spaces.&lt;/p&gt;&lt;p&gt;Applying DDN to non-generative tasks:&lt;/p&gt;&lt;p&gt;Using DDN's design ideas to improve existing generative models:&lt;/p&gt;&lt;p&gt;Applying DDN to language modeling tasks:&lt;/p&gt;&lt;p&gt;Q1: Will DDN require a lot of GPU memory?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;DDN's GPU memory requirements are slightly higher than conventional GAN generator using the same backbone architecture, but the difference is negligible.&lt;/p&gt;&lt;p&gt;During training, generating&lt;/p&gt;&lt;mjx-container&gt;samples is only to identify the one closest to the ground truth, and the&lt;/mjx-container&gt;&lt;mjx-container&gt;unselected samples do not retain gradients, so they are immediately discarded after sampling at the current layer, freeing up memory.&lt;/mjx-container&gt;&lt;p&gt;In the generation phase, we randomly sample an index from&lt;/p&gt;&lt;mjx-container&gt;and only generate the sample at the chosen index, avoiding the need to generate the other&lt;/mjx-container&gt;&lt;mjx-container&gt;samples, thus not occupying additional memory or computation.&lt;/mjx-container&gt;&lt;/quote&gt;&lt;p&gt;Q2: Will there be a mode collapse issue?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;No. DDN selects the output most similar to the current GT and then uses the&lt;/p&gt;&lt;mjx-container&gt;loss to make it even more similar to the GT. This operation naturally has a diverse tendency, which can "expand" the entire generation space.&lt;/mjx-container&gt;&lt;p&gt;Additionally, DDN supports reconstruction. Figure 14 in the original paper shows that DDN has good reconstruction performance on the test set, meaning that DDN can fully cover the target distribution.&lt;/p&gt;&lt;p&gt;The real issue with DDN is not mode collapse but attempting to cover a high-dimensional target distribution that exceeds its own complexity, leading to the generation of blurry samples.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45536694</guid><pubDate>Fri, 10 Oct 2025 09:01:54 +0000</pubDate></item><item><title>OpenGL: Mesh shaders in the current year</title><link>https://www.supergoodcode.com/mesh-shaders-in-the-current-year/</link><description>&lt;doc fingerprint="bec39254fca1fee5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mesh Shaders In The Current Year&lt;/head&gt;
    &lt;head rend="h1"&gt;It Happened.&lt;/head&gt;
    &lt;p&gt;Just a quick post to confirm that the OpenGL/ES Working Group has signed off on the release of GL_EXT_mesh_shader.&lt;/p&gt;
    &lt;head rend="h1"&gt;Credits&lt;/head&gt;
    &lt;p&gt;This is a monumental release, the largest extension shipped for GL this decade, and the culmination of many, many months of work by AMD. In particular we all need to thank Qiang Yu (AMD), who spearheaded this initiative and did the vast majority of the work both in writing the specification and doing the core mesa implementation. Shihao Wang (AMD) took on the difficult task of writing actual CTS cases (not mandatory for EXT extensions in GL, so this is a huge benefit to the ecosystem).&lt;/p&gt;
    &lt;p&gt;Big thanks to both of you, and everyone else behind the scenes at AMD, for making this happen.&lt;/p&gt;
    &lt;p&gt;Also we have to thank the nvidium project and its author, Cortex, for single-handedly pushing the industry forward through the power of Minecraft modding. Stay sane out there.&lt;/p&gt;
    &lt;head rend="h1"&gt;Support&lt;/head&gt;
    &lt;p&gt;Minecraft mod support is already underway, so expect that to happen ‚Äúsoon‚Äù.&lt;/p&gt;
    &lt;p&gt;The bones of this extension have already been merged into mesa over the past couple months. I opened a MR to enable zink support this morning since I have already merged the implementation.&lt;/p&gt;
    &lt;p&gt;Currently, I‚Äôm planning to wait until either just before the branch point next week or until RadeonSI merges its support to merge the zink MR. This is out of respect: Qiang Yu did a huge lift for everyone here, and ideally AMD‚Äôs driver should be the first to be able to advertise that extension to reflect that. But the branchpoint is coming up in a week, and SGC will be going into hibernation at the end of the month until 2026, so this offer does have an expiration date.&lt;/p&gt;
    &lt;p&gt;In any case, we‚Äôre done here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45537890</guid><pubDate>Fri, 10 Oct 2025 11:56:05 +0000</pubDate></item><item><title>Igalia, Servo, and the Sovereign Tech Fund</title><link>https://www.igalia.com/2025/10/09/Igalia,-Servo,-and-the-Sovereign-Tech-Fund.html</link><description>&lt;doc fingerprint="49fb4a41ab1a2764"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Igalia, Servo, and the Sovereign Tech Fund&lt;/head&gt;
    &lt;head rend="h5"&gt;"We√¢re proud to help shape the future of web engines through public investment in accessibility, embeddability, and sustainability."&lt;/head&gt;
    &lt;p&gt;Igalia is excited to announce a new commission from the Sovereign Tech Fund to advance the Servo web engine. As stewards of Servo, Igalia is honored to receive support for a multi-pronged effort focused on public interest, developer usability, and long-term sustainability.&lt;/p&gt;
    &lt;p&gt;Servo is a modern, parallelized web engine written in Rust, a Linux Foundation Europe project which Igalia has been actively maintaining since 2023, Servo represents a bold rethinking of browser architecture. Its modular design has made it a valuable resource across the Rust ecosystem. But like many promising open source technologies, Servo needs sustained investment to reach its full potential.&lt;/p&gt;
    &lt;p&gt;Thanks to investment from the Sovereign Tech Fund, Igalia will focus some important work in the next year in three key areas:&lt;/p&gt;
    &lt;head rend="h3"&gt;√∞¬ß Initial Accessibility Support&lt;/head&gt;
    &lt;p&gt;As Servo adoption grows, so does the need for inclusive design. Today, Servo lacks the foundational accessibility features required to support screen readers and other assistive technologies. This limits its usability in many real-world scenarios, and doesn√¢t match our values. Despite its importance, accessibility is often one of a few things that is difficult to find funding for. We√¢re grateful that thanks to this investment, we√¢ll be able to implement initial accessibility support to ensure that Servo can serve all users. This work is essential to making Servo a viable engine for public-facing applications.&lt;/p&gt;
    &lt;head rend="h3"&gt;√∞¬ß¬© WebView API&lt;/head&gt;
    &lt;p&gt;Embedding Servo into applications requires a stable and complete WebView API. While early work exists, it√¢s not yet ready for general use. We√¢ll be finishing the WebView API to make Servo embeddable in desktop and mobile apps, unlocking new use cases and enabling broader adoption. A robust embedding layer is critical to Servo√¢s eventual success as a general-purpose engine.&lt;/p&gt;
    &lt;head rend="h3"&gt;√∞¬ß Project Maintenance&lt;/head&gt;
    &lt;p&gt;Servo is more than a browser engine√¢it√¢s a collection of crates used widely across the Rust ecosystem. Maintaining these libraries benefits not just Servo, but the broader web platform. The project and the community have been growing a lot since we√¢ve taken over stewardship. This funding will allow our work will include more issue triage, pull request review, version releases, and governance support. All of this helps ensure that Servo remains active, responsive, and well-maintained for developers and users alike.&lt;/p&gt;
    &lt;p&gt;Igalia has long championed open source innovation in the browser space, from our work on Chromium, WebKit, and Gecko to our leadership in standards bodies and developer tooling. We believe Servo has a unique role to play in the future of web engines, and we√¢re thrilled to help guide its next chapter.&lt;/p&gt;
    &lt;p&gt;Many thanks to the Sovereign Tech Fund for recognizing the importance of this work. We look forward to sharing progress as we go.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45538137</guid><pubDate>Fri, 10 Oct 2025 12:21:02 +0000</pubDate></item><item><title>Ryanair flight landed at Manchester airport with six minutes of fuel left</title><link>https://www.theguardian.com/business/2025/oct/10/ryanair-flight-landed-at-manchester-airport-with-six-minutes-of-fuel-left-flight-log-suggests</link><description>&lt;doc fingerprint="32049a1c222d59d2"&gt;
  &lt;main&gt;
    &lt;p&gt;An investigation is under way after a Ryanair flight battling with high wind speeds during storm Amy last week landed at Manchester airport with just six minutes of fuel left in its tanks.&lt;/p&gt;
    &lt;p&gt;The pilots had been taking passengers from Pisa in Italy to Prestwick in Scotland on Friday evening, but wind speeds of up to 100mph meant they were unable to land.&lt;/p&gt;
    &lt;p&gt;After three failed attempts to touch down, the pilots of Ryanair flight FR3418 issued a mayday emergency call and raced to Manchester, where the weather was calmer.&lt;/p&gt;
    &lt;p&gt;The Boeing 737-800 had just 220kg of fuel left in its tanks when it finally landed, according to a picture of what appears to be a handwritten technical log. Pilots who examined the picture said this would be enough for just five or six minutes of flying.&lt;/p&gt;
    &lt;p&gt;Analysis of the log suggests the plane left Pisa with reserve fuel, as commercial flights are required to do.&lt;/p&gt;
    &lt;p&gt;A spokesperson for the airline said: ‚ÄúRyanair reported this to the relevant authorities on Friday [3 October]. As this is now subject of an ongoing investigation, which we are co-operating fully with, we are unable to comment.‚Äù&lt;/p&gt;
    &lt;p&gt;The Air Accidents Investigation Branch confirmed on Thursday it had opened an investigation after being notified by Ryanair.&lt;/p&gt;
    &lt;p&gt;A spokesperson said: ‚ÄúThe AAIB has commenced an investigation into a serious incident involving an aircraft which was diverted from Prestwick to Manchester Airport on Friday 3 October. AAIB inspectors have begun making inquiries and gathering evidence.‚Äù&lt;/p&gt;
    &lt;p&gt;The Boeing 737-800 can carry up to 189 passengers. One person on board recounted what is thought to have been a two-hour attempt to make a safe landing, saying the plane made two attempts to land at Prestwick, before heading for Edinburgh and finally Manchester.&lt;/p&gt;
    &lt;p&gt;‚ÄúEveryone was calm until the descent; we were being buffeted around a lot and jumping. There were a few worried people on the second descent as we could feel the plane was struggling,‚Äù Alexander Marchi told the Ayr Advertiser.&lt;/p&gt;
    &lt;p&gt;‚ÄúThen the pilot surprised us by saying he was going to attempt Edinburgh. This was just as bad, though, as the second time at Prestwick.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere was turbulence over the Firth of Forth and then as we approached the airport, as we were very close to landing, again we had to pull up sharply.‚Äù&lt;/p&gt;
    &lt;p&gt;The passengers were taken from Manchester to Prestwick, arriving 10 hours later than the scheduled arrival time of 6pm on Friday.&lt;/p&gt;
    &lt;p&gt;One pilot who reviewed the log said: ‚ÄúJust imagine that whenever you land with less than 2T (2,000kg) of fuel left you start paying close attention to the situation. Less than 1.5T you are sweating. But this is as close to a fatal accident as possible.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45539943</guid><pubDate>Fri, 10 Oct 2025 15:11:04 +0000</pubDate></item><item><title>Does our ‚Äúneed for speed‚Äù make our wi-fi suck?</title><link>https://orb.net/blog/does-speed-make-wifi-suck</link><description>&lt;doc fingerprint="f578975e3811dbed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Does our ‚Äúneed for speed‚Äù make our Wi-Fi suck?&lt;/head&gt;
    &lt;head rend="h3"&gt;Yep.&lt;/head&gt;
    &lt;p&gt;It is common knowledge among Wi-Fi professionals that using 20 MHz or 40 MHz channel widths when planning 5 GHz networks offers the best overall experience for enterprise networks. This is because enterprise networks can often cover large footprints and need higher density for many connected devices. Using narrower channel widths provides many more available channels for building out networks with appropriate channel reuse and allows flexibility to avoid co-channel interference from noisy neighbors.&lt;/p&gt;
    &lt;p&gt;Residential and small business Wi-Fi challenges are not so different. The average US household has 21 Wi-Fi devices1. Many homes require multiple mesh nodes or access points to cover effectively. Users in dense urban areas face many nearby access points using wide channels. Although Wi-Fi networks built by seasoned professionals typically use narrower channels, consumer Wi-Fi devices from popular manufacturers and ISPs utilize 80 MHz or wider channel widths by default. Popular routers and mesh systems from large manufacturers can even default to 40 MHz channels for 2.4 GHz networks (some not even allowing you to change to 20 MHz), utilizing two-thirds of the available spectrum!&lt;/p&gt;
    &lt;p&gt;Why? Because consumers have been conditioned to understand only raw speed as a metric of Wi-Fi quality and not more important indicators of internet experience such as responsiveness and reliability. If manufacturers shipped Wi-Fi routers and mesh systems that utilized more reasonable 40 MHz-wide 5 GHz channels out of the box, consumers would return the products when their favorite speed testing tool showed no improvement in speed over their previous system. Similarly, ISPs are reluctant to configure consumer premise equipment (CPE) to use narrower channels by default to reduce adjacent-channel and co-channel interference, as this will decrease the maximum achieved speed and hurt their standings in network performance benchmarks that emphasize raw speed over a rock solid and consistent Wi-Fi experience.&lt;/p&gt;
    &lt;head rend="h1"&gt;But wait. It gets worse.&lt;/head&gt;
    &lt;p&gt;Not only does consumer and telecoms marketing‚Äôs heavy focus on speed hamstring ISPs and device manufacturers when it comes to delivering excellent in-home Wi-Fi, but the very act of performing speed tests negatively impacts experience.&lt;/p&gt;
    &lt;p&gt;For example, here is a 1-minute summary of an iPhone‚Äôs responsiveness connected to a Wi-Fi 6 router connected directly to a symmetrical 1 Gbps fiber connection.&lt;/p&gt;
    &lt;p&gt;Now, an important concept in Wi-Fi is that of airtime contention: basically, only a single device can ‚Äútalk‚Äù at a time on a given channel2. So if one device is generating a considerable amount of unnecessary traffic, say from taking an internet speed test, substantial airtime contention occurs. Let‚Äôs connect a laptop to the same Wi-Fi router, take an internet speed test, and observe the impact on responsiveness from the same iPhone:&lt;/p&gt;
    &lt;p&gt;We can see material increases in latency, jitter, and packet loss, resulting in a doubling of the effective Lag. Of course, this does not prove that airtime contention is the cause, as there may be other factors such as buffer bloat. So let‚Äôs have the laptop perform the speed test via a wired connection instead of Wi-Fi:&lt;/p&gt;
    &lt;p&gt;This resulted in no material impact compared to the idle state, demonstrating that the speed testing activity was in fact the cause of the degraded experience from airtime contention and other Wi-Fi factors. In fact, the router is running FQ_Codel to mitigate non-Wi-Fi variables. With FQ_Codel disabled, the combined airtime contention and buffer bloat results in even greater degradation of experience when running a speed test: 1.5% packet loss, 13 ms jitter, and 113 ms peak lag. Considering the majority of consumer-grade equipment does not ship with buffer bloat mitigations enabled, this more accurately represents the general consumer Wi-Fi experience when an internet speed test is active.&lt;/p&gt;
    &lt;p&gt;Many ISPs, device manufacturers, and consumers automate periodic, high-intensity speed tests that negatively impact the consumer internet experience as demonstrated. Further, static probes that connect to Wi-Fi networks to measure maximum throughput are contributing to both buffer bloat and airtime contention.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;18% of US households experienced Wi-Fi issues on a daily basis, 20% on a weekly basis, and 68% reported issues in the past year3. But until consumers, the press, and industry understand that responsiveness and reliability are the largest drivers of their Wi-Fi experience, not speed, there will be little appetite from device manufacturers and ISPs to focus on solutions that result in truly great home Wi-Fi.&lt;/p&gt;
    &lt;p&gt;The IEEE 802.11bn (Wi-Fi 8) working group has acknowledged the need for a shift in focus, framing the standard‚Äôs goals differently from past generations: not chasing ever-higher peak speeds, but improving reliability, lower latency (especially at the 95th percentile), reduced packet loss, and robustness under challenging conditions (interference, mobility).&lt;/p&gt;
    &lt;p&gt;That said, the standard is not projected to be finalized until 2028. Near-term, the availability of Wi-Fi bands in the 6 GHz range will also help provide an even better balance of speed, responsiveness, and reliability with the ability to use wider bands while minimizing co-channel interference. However, this only offers another ‚Äúlane‚Äù and does not eliminate the inherent problem of data-hungry devices cannibalizing precious air time. And, as analysis from Opensignal in conjunction with Hamina Founder &amp;amp; CEO Jussi Kiviniemi demonstrates, 6 GHz penetration remains low due to network and user equipment lagging behind on Wi-Fi 6E and 7 adoption.&lt;/p&gt;
    &lt;p&gt;We don‚Äôt have to wait until there is material Wi-Fi 6E and 7 penetration (or the unrealized promises of Wi-Fi 8) in the market to make progress‚Äîwe can do so much better with the hardware already deployed with configuration changes if we can simply stop chasing the maximum possible throughputs and instead focus on Wi-Fi responsiveness and reliability.&lt;/p&gt;
    &lt;p&gt;So, are standard internet speed tests bad? Of course not! They are a tool, and when used for an appropriate task, such as validating provisioned speeds are achievable by a network or client, they are incredibly useful. But we tend to over-use speed testing tools for all connectivity-related troubleshooting activities due to a historical lack of available user-friendly utilities and industry focus on "megabits per second".&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt a matter of education: consumers know they want responsive and reliable Wi-Fi networks for the use cases of today. Instead, we need tooling and data to show consumers the metrics they care about most in an easily digestible form and make them readily available. Modern monitoring tools that measure continuous network experience‚Äînot just point-in-time speed‚Äîgive manufacturers and ISPs the opportunity to compete on metrics that actually improve Wi-Fi rather than degrade it.&lt;/p&gt;
    &lt;p&gt;Footnotes&lt;lb/&gt;1Journal of Consumer Affairs, April 2024&lt;lb/&gt;2This is an oversimplification given newer features such as OFDMA, but due to the nature of speed testing, the activity will demand large RUs or the entire channel. The scheduler also introduces overhead. And, as we will show, adoption of newer standards is low.&lt;lb/&gt;3TechSee data via Telecompetitor, September 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45542444</guid><pubDate>Fri, 10 Oct 2025 18:55:30 +0000</pubDate></item><item><title>Show HN: Semantic search over the National Gallery of Art</title><link>https://nga.demo.mixedbread.com/</link><description>&lt;doc fingerprint="d347f7e0daff0674"&gt;
  &lt;main&gt;
    &lt;p&gt;National Gallery of Art Nation Gallery of Art Mixedbread Github Discover art with natural language Still life paintings Paintings of flowers Woodcuts of landscapes Portraits of women Sculptures of animals Paintings of the sea Ancient coins Search through over 50,000 images from the National Gallery of Art public collection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543471</guid><pubDate>Fri, 10 Oct 2025 20:33:25 +0000</pubDate></item><item><title>I built physical album cards with NFC tags to teach my son music discovery</title><link>https://fulghum.io/album-cards</link><description>&lt;doc fingerprint="ee7b9c5cb976b30"&gt;
  &lt;main&gt;
    &lt;p&gt;by Jordan Fulghum, October 2025&lt;/p&gt;
    &lt;p&gt;Albums you can hold again.&lt;/p&gt;
    &lt;p&gt;When I was 10, I blew every dollar I had on CDs. I remember sitting cross-legged on my floor, flipping through jewel cases, memorizing liner notes and lyrics, and most importantly developing my own taste for music.&lt;/p&gt;
    &lt;p&gt;My 10-year-old doesn't have that. Music just sort of... happens. It's like it's infinite and invisible at the same time, playing from smart speakers, car stereos, my phone. Endless perfectly curated playlists, designed to fade into the background. The default listening experience has become both literally and figuratively formless.&lt;/p&gt;
    &lt;p&gt;So I thought: what's the modern equivalent of that CD browsing experience? Maybe what's missing is something tangible that he can flip through, or even collect.&lt;/p&gt;
    &lt;p&gt;I could combine my old CD-collector brain with today's tech: take something fun and collectable (trading cards), dress them up with album art, and add NFC tags so they can be tapped to play the album on our home speaker system, all without a screen.&lt;/p&gt;
    &lt;p&gt;Away I went.&lt;/p&gt;
    &lt;p&gt;I needed to get the music into a format that could be played. I've long since surrendered to streaming, but I still have my MP3s organized via Plex on my home server. Funny to think that these files are the same MP3s that I've been collecting since the late 90s. I wanted the NFC tag to be deep-linked to those same files instead of a streaming service.&lt;/p&gt;
    &lt;p&gt;But which albums do I pick? I had the idea to create themed "packs" of albums. The first pack is obviously "Albums That Dad Wants You to Listen To", and it's just a bunch of dad rock. But the idea is that each pack can be a different theme or genre, and he can build his own collection (and develop his own taste) over time.&lt;/p&gt;
    &lt;p&gt;I found a PDF template that matched the dimensions of trading cards, hopped into Canva and got to work. It was easy enough to find high-quality album cover images from Google, but....&lt;/p&gt;
    &lt;p&gt;I was quite far into this project when I remembered the obvious fact that album art is square but trading cards are rectangular. Trading cards use a 2.5:3.5 aspect ratio, which is...not a square! Oops.&lt;/p&gt;
    &lt;p&gt;I looked at what they did for cassette tapes (also rectangular) back in the day, but their solutions were all over the place, from just cropping the square into a rectangle (gross) to having a giant white space next to the square art. That wasn't gonna cut it.&lt;/p&gt;
    &lt;p&gt;So, I used an AI diffusion model to extend each album's art into a trading card aspect ratio. The AI was (mostly) able to extend the artwork while maintaining the original style and composition. Not perfect, but a pretty fun solution not possible just a couple years ago.&lt;/p&gt;
    &lt;p&gt;After ordering a bundle of blank NFC tags from Amazon, I learned that PlexAmp oddly has first-class support for zapping NFC tags to specific albums in auto play mode. A strange feature, but perfect for this project. Easy.&lt;/p&gt;
    &lt;p&gt;I printed the cards on our crappy HP inkjet printer at home. I used label paper that exactly matched the dimensions of trading cards, but after the fact, I realized it was kind of unnecessary. You can just print on cardstock if you have a digital template file. I cut them out and glued them to blank playing cards, but not before wedging the NFC tags between.&lt;/p&gt;
    &lt;p&gt;For placement, I found a trading card display model from Makerworld and 3D printed it on my A1. It turned out alright!&lt;/p&gt;
    &lt;p&gt;Once it was all working and in decent shape, I presented them in a nice neat arrangement to my son. He flipped through them like Pok√©mon cards, examined the cards that were the most visually interesting. Daft Punk's Discovery was his first pick. He grabbed it, flipped it around, tapped it, and that One More Time loop dropped throughout our entire house. Boom.&lt;/p&gt;
    &lt;p&gt;I was happy to see that the physical cards encouraged active listening and ownership. Instead of music being background noise, it became something he could choose, hold, explore, maybe even trade with this sister!&lt;/p&gt;
    &lt;p&gt;I think we're unintentionally teaching our children to consume music passively. My goal with this project was to teach them to discover it actively, to own it, to care about it at the album level. I think it kinda worked!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543475</guid><pubDate>Fri, 10 Oct 2025 20:34:19 +0000</pubDate></item><item><title>How to save the world with ZFS and 12 USB sticks: 4th anniversary video (2011)</title><link>https://constantin.glez.de/posts/2011-01-24-how-to-save-the-world-with-zfs-and-12-usb-sticks-4th-anniversary-video-re-release-edition/</link><description>&lt;doc fingerprint="17590dd9a12b6261"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Save the World With ZFS and 12 USB Sticks: 4th Anniversary Video Re-Release Edition&lt;/head&gt;
    &lt;p&gt;About 4 years ago, a few colleagues and myself got together and we created a short video about the coolness of two of the most innovative products from Sun of the last decade: ZFS and the X4500 Server.&lt;/p&gt;
    &lt;p&gt;Today, nearly 4 years later, the video has been downloaded more than 100,000 times (across the original German and the English dubbed version, plus the full resolution downloadable files) and shown to a lot more people during tradeshows, customer demos, etc.&lt;/p&gt;
    &lt;p&gt;Now YouTube and Google Video (remember?) don√¢t allow for highest video quality and the old Sun Mediacast server, where we hosted the original MP4 file, no longer exists. Instead, Vimeo has emerged as my video hoster of choice for a variety of projects (check out my video collection on Vimeo) and so it was time to give this video a new home.&lt;/p&gt;
    &lt;p&gt;For your viewing pleasure.&lt;/p&gt;
    &lt;p&gt;Watch the English dubbed version:&lt;/p&gt;
    &lt;p&gt;Or if you understand German (or have a taste for movies in original language), watch the original:&lt;/p&gt;
    &lt;p&gt;The original CSI:Munich blog post explains some of the technical background of the video, as does its German counterpart post √¢Solaris ZFS auf 12 USB-Sticks: Ein √¢Thumper√¢ f√É¬ºr Arme!√¢.&lt;/p&gt;
    &lt;p&gt;It√¢s amazing to see how far ZFS has made it today. Still, there√¢s no other file system I know of that can be configured in seconds, provides data integrity at mathematically deep levels, implements database-like transaction safety, comes with a high-end featureset and gives you so much as ZFS.&lt;/p&gt;
    &lt;p&gt;And the possibilities of ZFS continue to expand. Stay tuned.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543811</guid><pubDate>Fri, 10 Oct 2025 21:09:44 +0000</pubDate></item><item><title>Tangled, a Git collaboration platform built on atproto</title><link>https://blog.tangled.org/intro</link><description>&lt;doc fingerprint="bb129eda18bc2f5a"&gt;
  &lt;main&gt;
    &lt;p&gt;Tangled is a new social-enabled Git collaboration platform, built on top of the AT Protocol. We envision a place where developers have complete ownership of their code, open source communities can freely self-govern and most importantly, coding can be social and fun again.&lt;/p&gt;
    &lt;p&gt;There are several models for decentralized code collaboration platforms, ranging from ActivityPub‚Äôs (Forgejo) federated model, to Radicle‚Äôs entirely P2P model. Our approach attempts to be the best of both worlds by adopting atproto‚Äîa protocol for building decentralized social applications with a central identity.&lt;/p&gt;
    &lt;p&gt;Our approach to this is the idea of ‚Äúknots‚Äù. Knots are lightweight, headless servers that enable users to host Git repositories with ease. Knots are designed for either single or multi-tenant use which is perfect for self-hosting on a Raspberry Pi at home, or larger ‚Äúcommunity‚Äù servers. By default, Tangled provides managed knots where you can host your repositories for free.&lt;/p&gt;
    &lt;p&gt;The App View at tangled.sh acts as a consolidated ‚Äúview‚Äù into the whole network, allowing users to access, clone and contribute to repositories hosted across different knots‚Äîcompletely seamlessly.&lt;/p&gt;
    &lt;p&gt;Tangled is still in its infancy, and we‚Äôre building out several of its core features as we dogfood it ourselves. We developed these three tenets to guide our decisions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ownership of data&lt;/item&gt;
      &lt;item&gt;Low barrier to entry&lt;/item&gt;
      &lt;item&gt;No compromise on user-experience&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Collaborating on code isn‚Äôt easy, and the tools and workflows we use should feel natural and stay out of the way. Tangled‚Äôs architecture enables common workflows to work as you‚Äôd expect, all while remaining decentralized.&lt;/p&gt;
    &lt;p&gt;We believe that atproto has greatly simplfied one of the hardest parts of social media: having your friends on it. Today, we‚Äôre rolling out invite-only access to Tangled‚Äîjoin us on IRC at &lt;code&gt;#tangled&lt;/code&gt; on
libera.chat and we‚Äôll get you set up.&lt;/p&gt;
    &lt;p&gt;Update: Tangled is open to public, simply login at tangled.sh/login! Have fun!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543899</guid><pubDate>Fri, 10 Oct 2025 21:18:55 +0000</pubDate></item><item><title>(Re)Introducing the Pebble Appstore</title><link>https://ericmigi.com/blog/re-introducing-the-pebble-appstore/</link><description>&lt;doc fingerprint="dcea42331bd429f1"&gt;
  &lt;main&gt;
    &lt;p&gt;For those who didn‚Äôt catch my blog post last week (pls read), we manufactured 2,960 white Pebble 2 Duos in September! Pretty good for the first month of production. These watches are being transferred to our fulfillment center and will be shipped out soon.&lt;/p&gt;
    &lt;p&gt;Black Pebble 2 Duo production did not start until the end of September, and then got interrupted by a China/Hong Kong holiday. Extremely sorry for the delay on black!&lt;/p&gt;
    &lt;p&gt;Pebble Time 2&lt;/p&gt;
    &lt;p&gt;One fun piece of Pebble Time 2 software development news - we added a feature to make existing Pebble watchfaces/apps now (optionally) scale up to fill larger and higher resolution Pebble Time 2 display! Previous generation Pebble rectangular displays measured 144x168 pixels in 1.26" diagonal, but Pebble Time 2 is 200x228 pixels in 1.5", existing faces/apps would have had a black border on PT2. Many thanks to Alina for posting this idea on Discord.&lt;/p&gt;
    &lt;p&gt;This is fantastic because it will allow all older apps/faces to fill up the whole screen. Even better though, many Pebble developers are already upgrading their apps/faces to support the bigger screen natively, like Lignite‚Äôs beautiful face Mosaic.&lt;/p&gt;
    &lt;p&gt;Pebble Time 2 hardware development is going pretty well. We finished EVT (engineering verification test) and we‚Äôre now heading into the DVT (design verification test) stage. We‚Äôre still working on a number of tasks like tuning the stainless steel PVD hard coating, testing water resistance, integrating our firmware test suite into the factory ERP and more fun stuff.&lt;/p&gt;
    &lt;p&gt;Schedule-wise, we‚Äôre behind where I would have liked to be in October. We‚Äôre now aiming to start mass production just around the end of the year (12/26 to be precise). That means December pre-orders will not ship out until January at the earliest. We‚Äôll try our best to catch up, but the other looming date is the start of the lunar new year (factory shuts down Feb 1 through 17). We‚Äôve got our work cut out for us! We‚Äôll get it done.&lt;/p&gt;
    &lt;p&gt;For those of you who forgot or weren‚Äôt around 10 years ago, one of the most awesome parts of Pebble is the huge selection of fun/quirky/beautiful/clever/useful apps and watchfaces (from here I‚Äôll just call them both ‚Äòapps‚Äô). These were made by an extraordinarily talented community of casual developers, who primarily built apps for themselves and shared them with the broader public. This was facilitated by a damn good SDK, APIs, devtools and documentation created by the friendly and talented software and devrel teams at Pebble.&lt;/p&gt;
    &lt;p&gt;I think the ease of development and hackability of Pebble truly made the world a better place, one little app at a time. I love hearing stories from people who first learned how to program on a free Pebble they got from a hackathon (we gave away thousands this way). Books were written. Toolswere created. My then-girlfriend now-wife (a biochemistry professor) even learned Pebble.JS to create an amino acid flash card app for her students! Yes, we are nerds.&lt;/p&gt;
    &lt;p&gt;Over 2,000 apps and 10,000 watchfaces were created and hosted on the Pebble Appstore. It‚Äôs time to get (re)acquainted with them - browse away on apps.rePebble.com!&lt;/p&gt;
    &lt;p&gt;All existing Pebble apps are compatible with the new watches, though some apps may not work anymore due to broken settings pages, obsolete APIs, etc. Hopefully as we ship out more new watches, some developers will re-emerge to rescue some of these apps. I‚Äôm sure new apps will also rise to fill any voids!&lt;/p&gt;
    &lt;p&gt;What are your favourite Pebble apps and watchfaces? Share links to your favs in the comment section below!&lt;/p&gt;
    &lt;p&gt;For the last 9 years, the Rebble Alliance has been keeping the Pebble dream alive. Many of you have used their web services, Discord, helpful instructions or dev portal. I‚Äôm a huge fan - I‚Äôve been a daily active user since 2017. Without Rebble, it‚Äôs unlikely that the Pebble community would be as in-tact as it is today. On top of that, several members of the Rebble (and ex-Pebble colleagues) were absolutely critical in helping Google open-source PebbleOS. Without the community or the OS, there is zero chance that these new watches would be possible! Thank you Rebble!&lt;/p&gt;
    &lt;p&gt;One other great thing that Rebble did was in 2017 - they archived and started hosting a copy of the Pebble Appstore, before the servers were shut down. New apps uploaded by developers since 2017 have also been popping up!&lt;/p&gt;
    &lt;p&gt;We have partnered with Rebble to re-introduce the appstore. Their web services now power the Pebble appstore backend. New apps submitted via dev-portal.rebble.io will show up on Pebble Appstore as well.&lt;/p&gt;
    &lt;p&gt;You won‚Äôt need a subscription with Rebble in order to access the Appstore. Core Devices is funding Rebble, a non-profit, directly to provide this service. You can still donate or subscribe to Rebble and support their community efforts!&lt;/p&gt;
    &lt;p&gt;The Pebble Appstore now lives on apps.rePebble.com. The web view looks, feels and generally is the same as in 2016, with a few new tweaks and improvements:&lt;/p&gt;
    &lt;p&gt;Social link previews - share your favourite watchfaces on WhatsApp, Twitter, Bluesky, Discord, etc! Like PebbleEye 007&lt;/p&gt;
    &lt;p&gt;Similar Apps/Recommendations - while building this feature, I was reminded about the true depth of the Pebble app catalog. It‚Äôs easy to get caught up in the ‚Äòmost hearted‚Äô section‚Ä¶use this new feature at the bottom of each app page to discover hidden gems! It‚Äôs not perfect, but it‚Äôs helped me discover some awesome apps.&lt;/p&gt;
    &lt;p&gt;Additionally, we‚Äôre thinking about adding new features like:&lt;/p&gt;
    &lt;p&gt;Click to try out the app in an emulator&lt;/p&gt;
    &lt;p&gt;Detecting and warning users about broken APIs and settings pages&lt;/p&gt;
    &lt;p&gt;More and better categories&lt;/p&gt;
    &lt;p&gt;Better discovery and recommendations&lt;/p&gt;
    &lt;p&gt;Highlighting less-hearted apps (give new apps a chance vs old ones with a lot of hearts)&lt;/p&gt;
    &lt;p&gt;What new features should we add next? Add a comment below!&lt;/p&gt;
    &lt;p&gt;One of our goals with this next phase of Pebble is to nurture and facilitate an awesome, easy and dare-we-say fun developer experience for the Pebble developer community. Part of what made the experience so awesome before was the developer relations team! We unfortunately do not have the resources to recruit the whole team back (though I wish we could!). Luckily many of the great decisions they made continue to pay off.&lt;/p&gt;
    &lt;p&gt;The great news is that over the summer, we had an insanely productive intern on our team. He dusted off the SDK, updated it from Python2 ‚Üí 3 and even built a CloudPebble-like way to build Pebble apps entirely in the browser.&lt;/p&gt;
    &lt;p&gt;What‚Äôs working now&lt;/p&gt;
    &lt;p&gt;Try the Pebble SDK! Tested on Mac, Windows (WSL) and Linux&lt;/p&gt;
    &lt;p&gt;Or use the Cloud IDE ‚Üí build hello-world and see it on an emulator, all in your browser, in under 2 minutes!&lt;/p&gt;
    &lt;p&gt;Build an app with AI ‚Üí run pebble new-project --ai then open dir in Claude Code or Cursor (etc) and prompt your way to your own custom app or watchface&lt;/p&gt;
    &lt;p&gt;Upgrade your apps to support the larger 200x228 px display on Pebble Time 2, run it on the emulator using pebble install --emulator emery (just like Obsidian!)&lt;/p&gt;
    &lt;p&gt;What‚Äôs on the SDK roadmap:&lt;/p&gt;
    &lt;p&gt;Pebble packages support in SDK&lt;/p&gt;
    &lt;p&gt;Adding Timeline support into the Pebble mobile app&lt;/p&gt;
    &lt;p&gt;New APIs for barometer, touchscreen, speaker&lt;/p&gt;
    &lt;p&gt;JS SDK - brand new, powered by Moddable. This will replace Rocky.js&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45544228</guid><pubDate>Fri, 10 Oct 2025 21:53:48 +0000</pubDate></item><item><title>Verge Genomics (YC S15) Is Hiring for Multiple Engineering and Product Roles</title><link>https://news.ycombinator.com/item?id=45544636</link><description>&lt;doc fingerprint="244fc49b6d1a231c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Verge is using AI to develop better drugs faster. We are one of the few AI drug discovery companies to advance from data to clinic ‚Äì delivering two new AI-derived drugs in the last three years, discovered using our industry-leading proprietary datasets and tooling. Along the way, we've signed commercial partnerships with Eli Lilly and AstraZeneca totaling $1.6B in contract value and $67M in near-term cash.&lt;/p&gt;
      &lt;p&gt;We're hiring for the following roles on our platform team:&lt;/p&gt;
      &lt;p&gt;* Head of Product &amp;amp; Engineering&lt;/p&gt;
      &lt;p&gt;* Principal Full-Stack Engineer (Django)&lt;/p&gt;
      &lt;p&gt;* Senior Computational Biologist (AI/ML)&lt;/p&gt;
      &lt;p&gt;* Senior Data Engineer&lt;/p&gt;
      &lt;p&gt;Please apply through our careers page, and mention Hacker News in your application:&lt;/p&gt;
      &lt;p&gt;https://www.vergegenomics.com/openings&lt;/p&gt;
      &lt;p&gt;Our platform team is developing Verge's CONVERGE drug discovery engine into a transformative tool for partners and customers across pharma and AI. We are a small, nimble group of scientists and software engineers.&lt;/p&gt;
      &lt;p&gt;Successful applicants will have a significant role in steering, scoping, and prioritizing the work we do.&lt;/p&gt;
      &lt;p&gt;All of our roles are remote within the US, and require a willingness to travel to San Francisco a few times per year. We do not currently offer visa sponsorship.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45544636</guid><pubDate>Fri, 10 Oct 2025 22:37:16 +0000</pubDate></item><item><title>Programming in the Sun: A Year with the Daylight Computer</title><link>https://wickstrom.tech/2025-10-10-programming-in-the-sun-a-year-with-the-daylight-computer.html</link><description>&lt;doc fingerprint="a694403731e3b5d5"&gt;
  &lt;main&gt;
    &lt;p&gt;October 10, 2025&lt;/p&gt;
    &lt;p&gt;I√¢ve been hinting on X/Twitter about my use of the Daylight DC-1 as a programming environment, and after about a year of use, it√¢s time to write about it in longer form. This isn√¢t a full product review, but rather an experience report on coding in sunlight. It√¢s also about the Boox Tab Ultra √¢ which has a different type of display √¢ and how it compares to the DC-1 for my use cases.&lt;/p&gt;
    &lt;p&gt;This is not a sponsored post.&lt;/p&gt;
    &lt;p&gt;Why do I even bother, you might ask? Sunlight makes me energetic and alert, which I need when I work. Living in the Nordics, 50% of the year is primarily dark, so any direct daylight I can get becomes really important. I usually run light mode on my Framework laptop during the day, but working in actual daylight with these displays, or plain old paper, is even better.&lt;/p&gt;
    &lt;p&gt;Here are the main components of this coding environment:&lt;/p&gt;
    &lt;code&gt;apt&lt;/code&gt;
    &lt;p&gt;I use a slimmed-down version of my regular dotfiles, because this setup doesn√¢t use Nix. I√¢ve manually installed Neovim, tmux, and a few other essentials, using the package manager that comes with Termux. I√¢ve configured Termux to not show its virtual keyboard when a physical keyboard is connected (the Bluetooth keyboard). The Termux theme is √¢E-Ink√¢ and the font is JetBrains Mono, all built into Termux. Neovim uses the built-in &lt;code&gt;quiet&lt;/code&gt; colorscheme for
maximum contrast.&lt;/p&gt;
    &lt;p&gt;Certain work requires a more capable environment, and in those cases I connect to my workstation using SSH and run tmux in there. For writing or simpler programming projects (I√¢ve even done Rust work with Cargo, for instance), the local Termux environment is fine.&lt;/p&gt;
    &lt;p&gt;Sometimes I want to go really minimalist, so I hide the tmux status bar and run &lt;code&gt;Goyo&lt;/code&gt; in
Neovim. Deep breaths. Feel the fresh air in your lungs. This is
especially nice for writing blog posts like this one.&lt;/p&gt;
    &lt;p&gt;My blog editing works locally in Termux, with a live reloading Chrome in a split window, here during an evening writing session with the warm backlight enabled:&lt;/p&gt;
    &lt;p&gt;There√¢s the occasional Bluetooth connection problem with the 8BitDo keyboard. I also don√¢t love the layout, and I√¢m considering getting the Kinesis Freestyle2 Blue instead. I already have the wired version for my workstation, and the ergonomics are great.&lt;/p&gt;
    &lt;p&gt;What about the Boox? I√¢ve had this device for longer and I really like it too, but not for the same tasks. The E-Ink display is, quite frankly, a lot nicer to read on; EPUB books, research PDFs, web articles, etc. The 227 PPI instead of the Daylight√¢s 190 PPI makes a difference, and I like the look of E-Ink better overall.&lt;/p&gt;
    &lt;p&gt;However, the refresh rate and ghosting make it a bit frustrating for typing. Same goes for drawing, which I√¢ve used the Daylight for a lot. Most of my home renovation blueprints are sketched on the Daylight. The refresh rate makes it possible.&lt;/p&gt;
    &lt;p&gt;When reading at night with a more direct bedside lamp, often in combination with a subtle backlight, the Boox is much better. The Daylight screen can glare quite a bit, so the only option is backlight only. And at that point, a lot of the paperlike quality goes away.&lt;/p&gt;
    &lt;p&gt;You can also get some glare when there√¢s direct sunlight at a particular angle:&lt;/p&gt;
    &lt;p&gt;Even if I don√¢t write or program directly on the Boox, I√¢ve experimented with using it as a secondary display, like for the live reload blog preview:&lt;/p&gt;
    &lt;p&gt;To sum up, these devices are good for different things, in my experience. I√¢ve probably spent more time on the Boox, because I√¢ve had it for longer and I√¢ve read a lot on it, but the Daylight has been much better for typing and drawing.&lt;/p&gt;
    &lt;p&gt;Another thing I√¢d like to try is a larger E-Ink monitor for my workstation, like the one Zack is hacking on. I√¢m hoping this technology continues to improve on refresh rate, because I love E-Ink. Until then, the Daylight is a good compromise.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45545098</guid><pubDate>Fri, 10 Oct 2025 23:51:13 +0000</pubDate></item><item><title>How hard do you have to hit a chicken to cook it? (2020)</title><link>https://james-simon.github.io/blog/chicken-cooking/</link><description>&lt;doc fingerprint="110a311b6246df50"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How hard do you have to hit a chicken to cook it?&lt;/head&gt;
    &lt;p&gt;Some questions are timeless, innocent yet penetrating in their simplicity. Why is the sky blue? Why do things fall? How hard must one hit a chicken to cook it? It is this last mystery of the universe that we discuss today.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a classic solution in which someone calculated that, if you slap a chicken at 3726 mph, it will be cooked. However, this analysis just calculates how hard you‚Äôd have to hit a chicken to get it to cooking temperature; you need to keep it at that temperature for it to cook. One slap won‚Äôt work unless you get it so hot that it cooks while it‚Äôs cooling.&lt;/p&gt;
    &lt;p&gt;A real answer to this vital conundrum needs to consider how fast a chicken cools. A body at a nonzero temperature is constantly radiating energy as blackbody radiation; this is what you see in incandescent lightbulbs or when glass glows during glassblowing. To keep an object at a given temperature, you have to continuously give it the same energy it‚Äôs radiating away. A typical-sized chicken at 165 F is radiating away roughly 2000 watts of power, around 300 times the power used in a fluorescent lightbulb. To avoid losing any heat to contact with the air, let‚Äôs assume we dangle the chicken from a string in a large vacuum chamber. Let‚Äôs also assume you and a few friends are hitting the chicken with baseball bats like a pinata. In order to keep the chicken at 165 F for the minutes needed to cook it, it would be enough to have four people each hitting it once a second with a bat swung at 75 mph, about the speed with which a pro swings. Four major-league baseball players wearing pressure suits in a vacuum chamber each hitting a dangling chicken with a baseball bat once a second could cook it in a few minutes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45545965</guid><pubDate>Sat, 11 Oct 2025 02:06:02 +0000</pubDate></item><item><title>What is going on with all this radioactive shrimp?</title><link>https://www.consumerreports.org/health/food-safety/radioactive-shrimp-explained-a5493175857/</link><description>&lt;doc fingerprint="b68917939d6a545f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Is Really Going on With All This Radioactive Shrimp?&lt;/head&gt;
    &lt;p&gt;Here‚Äôs the latest on how shrimp and spices were contaminated with cesium-137, how the FDA responded, and why experts say consumers shouldn't panic&lt;/p&gt;
    &lt;p&gt;In August, the Food and Drug Administration issued an unusual warning: Don‚Äôt eat certain lots of frozen shrimp sold at Walmart because they might be radioactive. It didn‚Äôt take long for the list of recalled products to grow far beyond Walmart. Over the past six weeks, hundreds of thousands of pounds of frozen, raw, and cooked shrimp have been pulled from supermarket shelves across the U.S.&lt;/p&gt;
    &lt;p&gt;All of the affected shrimp share at least one thing in common: They were processed by an Indonesian firm known as Bahari Makmur Sejati, or BMS Foods. The company may not be well known to consumers, but from January to July, it was responsible for about a third of American shrimp imports from Indonesia‚Äîwhich itself is the third largest exporter of shrimp to the U.S., according to ImportGenius, a trade data analysis company.&lt;/p&gt;
    &lt;p&gt;BMS Foods caught the attention of regulators earlier this year after cesium-137 was detected in its shipping containers and shrimp at four U.S. ports. It‚Äôs a synthetic radioactive isotope that‚Äôs not typically found in food but can be detected by the monitoring systems at U.S. ports. It‚Äôs produced during nuclear fission‚Äîthe process of splitting an atom‚Äôs nucleus‚Äîwhich is often used to generate power or for nuclear weapons.&lt;/p&gt;
    &lt;p&gt;Over the past month, an investigation by Indonesia‚Äôs nuclear agency has found evidence of widespread radioactive contamination in the area where the shrimp was packaged, a region of the island of Java known as the Cikande industrial area.&lt;/p&gt;
    &lt;p&gt;The situation is further complicated by the FDA‚Äôs September discovery of cesium-137 in a shipping container from Indonesia carrying cloves from a spice exporter over 400 miles away from the Cikande zone.&lt;/p&gt;
    &lt;p&gt;The levels of radioactivity detected in both the shrimp and the cloves aren‚Äôt high enough to pose any immediate risk to consumers, and Indonesian authorities have stated that the country‚Äôs exports are safe. But on Oct. 3, the FDA announced sweeping new import requirements for all shrimp and spices from the island of Java‚Äîwhich is home to about 150 million people‚Äîand a nearby region.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere are more questions than answers at this point,‚Äù said Steven Biegalski, PhD, chair of the nuclear and radiological engineering and medical physics program at the Georgia Institute of Technology in Atlanta.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what we know so far.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Concerned Should You Be About Radioactive Shrimp?&lt;/head&gt;
    &lt;p&gt;According to Biegalski, consumers in the U.S. have no reason to panic. The activity concentrations found in the shrimp and cloves samples tested by the FDA‚Äî68 and 732 becquerels per kilogram, respectively‚Äîare well below the FDA‚Äôs intervention level for cesium-137 contamination, which is 1,200 becquerels per kg.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Exactly Is Cesium-137?&lt;/head&gt;
    &lt;p&gt;Cesium-137 is a radioactive isotope produced by nuclear fission, typically used in medical devices or the calibration of radiation-detection equipment like Geiger counters, according to the Centers for Disease Control and Prevention. It‚Äôs also a byproduct of the processes used in nuclear weapons testing, the operation of nuclear reactors, and nuclear accidents. According to the CDC, people in the U.S. are exposed to low levels of cesium-137 on a daily basis because it‚Äôs present in the environment from weapons testing in the 1950s and 60s.&lt;/p&gt;
    &lt;p&gt;Cesium-137 can take decades to break down in the environment, but the body processes it much faster. Ingested cesium is typically absorbed into the bloodstream through the intestines. In an adult, about 10 percent of ingested cesium-137 is excreted from the body in a matter of days. The other 90 percent has a biological half-life of 110 days, meaning the human body naturally eliminates half of what remains within about four months.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Did Indonesian Shrimp and Cloves Get Contaminated?&lt;/head&gt;
    &lt;p&gt;It‚Äôs not totally clear, but preliminary evidence suggests it‚Äôs because of industrial activity near food processing facilities rather than anything in the water or soil.&lt;/p&gt;
    &lt;p&gt;Officials from Indonesia‚Äôs nuclear energy regulatory agency have traced the source of contamination to a steel manufacturer in the Cikande industrial area known as Peter Metal Technology, or PMT. Some of the highest levels of contamination detected in the area were reportedly found in the company‚Äôs furnace, which is about 1.5 miles southwest of the BMS Foods facility where the shrimp was processed.&lt;/p&gt;
    &lt;p&gt;Investigators think that radioactive dust was released into the environment after PMT inadvertently smelted scrap metal containing cesium-137. ‚ÄúBecause it‚Äôs airborne, the contamination can be carried by wind,‚Äù said Bara Khrishna Hasibuan, a senior adviser to Indonesia‚Äôs Ministry of Food Affairs, at a Sept. 30 press conference.&lt;/p&gt;
    &lt;p&gt;Scrap metal was commonly used as a raw material by PMT, according to the Indonesian outlet Antara News. It‚Äôs unclear how it may have become contaminated with cesium-137. Biegalski, whose area of expertise includes nuclear forensics, told CR that the ‚Äúeasiest explanation‚Äù is that a medical or industrial device containing cesium-137 was inadvertently reprocessed as scrap metal. The radioactive material could have become gaseous after entering the PMT furnace and then been released from the facility‚Äôs smokestack, he said.&lt;/p&gt;
    &lt;p&gt;‚ÄúThat whole island likely had a cesium-137 plume go over it, leaving a trail of contamination,‚Äù Biegalski said. The Indonesian government is reportedly now considering new regulations on scrap metal to reduce the risk of further contamination.&lt;/p&gt;
    &lt;p&gt;The release of a radioactive plume could explain the pattern of contamination in the area, according to Biegalski. Officials have detected elevated radiation levels in at least 10 sites within a roughly 3-mile radius of PMT so far, including the BMS Foods facility, and they‚Äôre working to decontaminate the region, a process authorities estimate will take several months.&lt;/p&gt;
    &lt;p&gt;The question of how the cloves were contaminated is harder to answer. The facility where they were processed is over 400 miles away from the smelter. Yet the radiation levels in the sample tested by the FDA were 10 times higher than those found in the shrimp. More perplexing still, a preliminary investigation found only normal background levels of radiation at the facility that processed the cloves, according to Antara News.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere are a lot of plausible scenarios here,‚Äù Biegalski said. ‚ÄúWe don‚Äôt know where the [cloves] contamination occurred. It could have happened during transit, or it could have happened as an airborne plume, where things got picked up one day but didn‚Äôt necessarily gravitationally settle.‚Äù The plume could have also settled on the field where the cloves were grown or on the containers they were transported in, he suggested. But there are no clear answers yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Is the FDA Doing?&lt;/head&gt;
    &lt;p&gt;On Aug. 14, the agency placed BMS Foods on its import alert ‚Äúred list,‚Äù effectively barring all of the company‚Äôs shrimp products from entering the U.S. until the problem is resolved. About a month later, it did the same to Natural Java Spice, the company responsible for the contaminated cloves.&lt;/p&gt;
    &lt;p&gt;The Department of Energy‚Äôs National Nuclear Security Administration has sent emergency teams to U.S. ports to evaluate the extent of cesium-137 contamination, an agency spokesperson told CR. Officials from the International Atomic Energy Agency have also been in close contact with Indonesian authorities, who are monitoring the situation, said Joanne Liou, a spokesperson, in an email.&lt;/p&gt;
    &lt;p&gt;On Friday, the FDA announced that starting Oct. 31, it will require import certification for all shrimp and spices from the island of Java as well as from Lampung province in Sumatra, northwest of the Cikande industrial area. Notably, this is the first time the agency has exercised this authority. The move extends similar restrictions to all regional exporters, who will be required to obtain shipment-by-shipment certification from the Indonesian government attesting that their products are free from radioactive contamination in order to be accepted at U.S. ports.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis is a good effort to try to stop the hemorrhaging of trust,‚Äù said Darin Detwiler, an associate professor at Northeastern University who has researched the FDA‚Äôs implementation of food safety policies. But he cautioned that this effort, like others in the agency‚Äôs past, could upset the balance of trade between the U.S. and Indonesia by introducing unnecessary barriers for exporters unaffected by the contamination.&lt;/p&gt;
    &lt;p&gt;‚ÄúConsumers need to have trust in their [food] sources,‚Äù Detwiler said. ‚ÄúBut we also need to look beyond the surface.‚Äù Over the past six weeks, elected officials and lobbying groups have used the spate of radiation-related recalls to advocate for policies restricting foreign imports.&lt;/p&gt;
    &lt;p&gt;Biegalski thinks that the FDA‚Äôs decision is reasonable and likely stems from concern over whether products with even higher levels of radioactivity than what‚Äôs been detected so far could inadvertently enter the supply chain. ‚ÄúWe don‚Äôt want to scare the public over things that really are benign at this point,‚Äù he said, ‚Äúbut it would also be irresponsible if we didn‚Äôt continue due diligence and monitor what is coming in from the region.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;What Should Consumers Do?&lt;/head&gt;
    &lt;p&gt;The FDA says no products that tested positive for cesium-137 have entered the U.S. marketplace, and the levels found in the shrimp and clove samples rejected at U.S. ports are too low to cause acute harm.&lt;/p&gt;
    &lt;p&gt;Out of an abundance of caution, the agency has issued recalls for all products from BMS Foods that entered the U.S. after cesium-137 was first detected in shrimp. See this up-to-date list of the affected products and brands on the FDA website.&lt;/p&gt;
    &lt;p&gt;If you aren‚Äôt sure whether a product you‚Äôve purchased is involved in the recall, check the packaging to see whether it lists a country of origin, said James E. Rogers, PhD, director of product and food safety research at CR. Food items will often include an ‚Äúimported from‚Äù or ‚Äúproduct of‚Äù disclosure on the packaging label near the ingredients list or nutrition facts box.&lt;/p&gt;
    &lt;p&gt;‚ÄúIf you don‚Äôt feel confident or safe eating a product,‚Äù Rogers said, ‚Äúthrow it out.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45546575</guid><pubDate>Sat, 11 Oct 2025 04:31:15 +0000</pubDate></item><item><title>AMD and Sony's PS6 chipset aims to rethink the current graphics pipeline</title><link>https://arstechnica.com/gaming/2025/10/amd-and-sony-tease-new-chip-architecture-ahead-of-playstation-6/</link><description>&lt;doc fingerprint="3b2f1556bbd612d"&gt;
  &lt;main&gt;
    &lt;p&gt;It feels like it was just yesterday that Sony hardware architect Mark Cerny was first teasing Sony's "PS4 successor" and its "enhanced ray-tracing capabilities" powered by new AMD chips. Now that we're nearly five full years into the PS5 era, it's time for Sony and AMD to start teasing the new chips that will power what Cerny calls "a future console in a few years' time."&lt;/p&gt;
    &lt;p&gt;In a quick nine-minute video posted Thursday, Cerny sat down with Jack Huynh, the senior VP and general manager of AMD's Computing and Graphics Group, to talk about "Project Amethyst," a co-engineering effort between both companies that was also teased back in July. And while that Project Amethyst hardware currently only exists in the form of a simulation, Cerny said that the "results are quite promising" for a project that's still in the "early days."&lt;/p&gt;
    &lt;head rend="h2"&gt;Mo‚Äô ML, fewer problems?&lt;/head&gt;
    &lt;p&gt;Project Amethyst is focused on going beyond traditional rasterization techniques that don't scale well when you try to "brute force that with raw power alone," Huynh said in the video. Instead, the new architecture is focused on more efficient running of the kinds of machine-learning-based neural networks behind AMD's FSR upscaling technology and Sony's similar PSSR system.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;From the same source. Two branches. One vision.&lt;/p&gt;
      &lt;p&gt;My good friend and fellow gamer @cerny and I recently reflected on our shared journey ‚Äî symbolized by these two pieces of amethyst, split from the same stone.&lt;/p&gt;
      &lt;p&gt;Project Amethyst is a co-engineering effort between @PlayStation and‚Ä¶ pic.twitter.com/De9HWV3Ub2&lt;/p&gt;
      &lt;p&gt;‚Äî Jack Huynh (@JackMHuynh) July 1, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While that kind of upscaling currently helps let GPUs pump out 4K graphics in real time, Cerny said that the "nature of the GPU fights us here," requiring calculations to be broken up into subproblems to be handled in a somewhat inefficient parallel process by the GPU's individual compute units.&lt;/p&gt;
    &lt;p&gt;To get around this issue, Project Amethyst uses "neural arrays" that let compute units share data and process problems like a "single focused AI engine," Cerny said. While the entire GPU won't be connected in this manner, connecting small sets of compute units like this allows for more scalable shader engines that can "process a large chunk of the screen in one go," Cerny said. That means Project Amethyst will let "more and more of what you see on screen... be touched or enhanced by ML," Huynh added.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45546593</guid><pubDate>Sat, 11 Oct 2025 04:36:16 +0000</pubDate></item></channel></rss>