<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 07 Oct 2025 21:08:42 +0000</lastBuildDate><item><title>Erlang ARM32 JIT is born</title><link>https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3</link><description>&lt;doc fingerprint="ea279a502acd05f8"&gt;
  &lt;main&gt;
    &lt;p&gt;A blog series recounting our adventures in the quest to port the BEAM JIT to the ARM32-bit architecture.&lt;/p&gt;
    &lt;p&gt;This work is made possible thanks to funding from the Erlang Ecosystem Foundation and the ongoing support of its Embedded Working Group.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Erlang ARM32 JIT is born!&lt;/head&gt;
    &lt;p&gt;This week we finally achieved our first milestone in developing the ARM32 JIT. We executed our first Erlang function through JITted ARM32 machine code!&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$ echo $?
    42&lt;/code&gt;
    &lt;p&gt;The BEAM successfully runs and terminates with error code 42! That 42 comes from an Erlang function, just-in-time compiled by our ARM32 JIT!&lt;/p&gt;
    &lt;p&gt;Announcement is done! All code is available at https://github.com/stritzinger/otp/tree/arm32-jit&lt;/p&gt;
    &lt;p&gt;Keep reading for a lot of interesting details!&lt;/p&gt;
    &lt;head rend="h2"&gt;The first piece of Erlang code&lt;/head&gt;
    &lt;code&gt;-module(hello).
-export([start/2]).

start(_BootMod, _BootArgs) -&amp;gt;
    halt(42, [{flush, false}]).&lt;/code&gt;
    &lt;p&gt;This is &lt;code&gt;hello.erl&lt;/code&gt; that contains a &lt;code&gt;start/2&lt;/code&gt; function. The function head mimics the &lt;code&gt;erl_init:start/2&lt;/code&gt; function, which is the entry point of the first Erlang process. We replaced &lt;code&gt;erl_init:start/2&lt;/code&gt; with &lt;code&gt;hello:start/2&lt;/code&gt; in the &lt;code&gt;erl_init.c&lt;/code&gt; module of the BEAM VM. This way, we forced the runtime to execute this Erlang function.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;hello:start/2&lt;/code&gt; is very simple as it just calls the &lt;code&gt;erlang:halt/2&lt;/code&gt;. This function is a BIF (Built-in Function) that executes C code, part of the BEAM VM. This code executes an ordered shutdown of the BEAM and allows us to customize the error code, in this case: &lt;code&gt;42&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Why &lt;code&gt;{flush, false}&lt;/code&gt;? At the time I am writing this, letting it be true causes a segmentation fault EHEH)&lt;/p&gt;
    &lt;p&gt;Obviously, we need to compile this Erlang module, but I will also generate the BEAM assembly so we can have a look at what we will have to deal with.&lt;/p&gt;
    &lt;code&gt;{module, hello}.  %% version = 0
{exports, [{module_info,0},{module_info,1},{start,2}]}.
{attributes, []}.
{labels, 7}.

{function, start, 2, 2}.
  {label,1}.
    {line,[{location,"erts/preloaded/src/hello.erl",74}]}.
    {func_info,{atom,hello},{atom,start},2}.
  {label,2}.
    {move,{literal,[{flush,false}]},{x,1}}.
    {move,{integer,42},{x,0}}.
    {line,[{location,"erts/preloaded/src/hello.erl",76}]}.
    {call_ext_only,2,{extfunc,erlang,halt,2}}.

{function, module_info, 0, 4}.
  {label,3}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},0}.
  {label,4}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,1,{extfunc,erlang,get_module_info,1}}.

{function, module_info, 1, 6}.
  {label,5}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},1}.
  {label,6}.
    {move,{x,0},{x,1}}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,2,{extfunc,erlang,get_module_info,2}}.&lt;/code&gt;
    &lt;p&gt;You can spot the start function and the two standard module_info functions that all Erlang modules have. We do not care much about those right now as we discovered that they are not executed and are not required to work, for now.&lt;/p&gt;
    &lt;p&gt;We can see that the core of the start function is just two &lt;code&gt;move&lt;/code&gt; operations and one &lt;code&gt;call_ext_only&lt;/code&gt;. But bear in mind that the BEAM loader will transmute these Generic BEAM Operations into Specific operations. More complexity will pop up!&lt;/p&gt;
    &lt;head rend="h2"&gt;Execution&lt;/head&gt;
    &lt;p&gt;We are using &lt;code&gt;qemu-arm&lt;/code&gt; to emulate &lt;code&gt;Arm32&lt;/code&gt; and we are directly using &lt;code&gt;beam.smp&lt;/code&gt; to run the BEAM.&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/vagrant/arm32-jit/otp/RELEASE -progname erl -home /home/vagrant&lt;/code&gt;
    &lt;head rend="h3"&gt;JIT initialization&lt;/head&gt;
    &lt;p&gt;At boot, the BEAM initializes the JIT if enabled. The JIT leverages the AsmJit library to emit all machine code instructions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of all global shared fragments&lt;/head&gt;
    &lt;p&gt;There are 90+ code snippets that are shared among all modules. The JIT loads them one single time and sets up jumps to them in every other module. It is like a global library for all modules.&lt;/p&gt;
    &lt;p&gt;We skipped most of these because just the shared fragments involved in the &lt;code&gt;hello:start/2&lt;/code&gt; execution were needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of the erts_beamasm module&lt;/head&gt;
    &lt;p&gt;As part of the JIT initialization, &lt;code&gt;erts_beamasm&lt;/code&gt; is emitted. This module is an internal hardcoded module that exists only when BEAM is using the JIT. It holds 7 fundamental instructions used to manage the Erlang process executions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;run_process - The main process execution entry point&lt;/item&gt;
      &lt;item&gt;normal_exit - Normal process termination&lt;/item&gt;
      &lt;item&gt;continue_exit - Continue after exit handling&lt;/item&gt;
      &lt;item&gt;exception_trace - Exception tracing functionality&lt;/item&gt;
      &lt;item&gt;return_trace - Return value tracing&lt;/item&gt;
      &lt;item&gt;return_to_trace - Return to tracing state&lt;/item&gt;
      &lt;item&gt;call_trace_return - Call tracing return handling&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Preloaded modules&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;hello.erl&lt;/code&gt; module has been compiled and put as first and single Erlang module in the list of preloaded modules. Preloaded modules are Erlang fundamental modules that are always loaded by the BEAM before the first Erlang process can start. They implement, in Erlang, the core features of the Erlang Runtime System (ERTS). The OTP build scripts group all &lt;code&gt;ebin&lt;/code&gt; files into a single C header that is then linked into the executable. This makes the Erlang binaries available as a static C array in the BEAM source code. These are then loaded one by one after the BEAM VM is initialized.&lt;/p&gt;
    &lt;p&gt;Cool, let's nuke all these modules and leave just our &lt;code&gt;hello.erl&lt;/code&gt;. It does not need many BEAM instructions and we can easily verify that it executes. To do the substitution we just need to change this build variable in otp/erts/emulator/Makefile.in&lt;/p&gt;
    &lt;p&gt;We are running BEAMASM with &lt;code&gt;-JDdump true&lt;/code&gt; so &lt;code&gt;asmjit&lt;/code&gt; will dump all ARM32 assembly for each module! This is incredibly useful if monitored while executing with a debugger, as we can see the assembler being printed line by line by our code.&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ cat hello.asm 
L6:
.byte 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_1:
# i_func_info_IaaI
# hello:start/2
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x0B, 0xA4, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00
# aligned_label_Lt
start/2:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L9
    bl L11
L9:
# i_test_yield
    adr r2, start/2
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 687
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L17
    udf 48879
L17:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L18
    udf 57005
L18:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_3:
# i_func_info_IaaI
# hello:module_info/0
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/0:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L23
    bl L11
L23:
# i_test_yield
    adr r2, module_info/0
    subs r9, r9, 1
    b.le L13
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L24:
    ldr r3, [L25]
    movw r1, 4772
    movt r1, 16425
    adr r2, L24
# BIF: erlang:get_module_info/1
    sub r12, r7, 4
    cmp r10, r12
    b.ls L26
    udf 48879
L26:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L27
    udf 57005
L27:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_5:
# i_func_info_IaaI
# hello:module_info/1
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/1:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L28
    bl L11
L28:
# i_test_yield
    adr r2, module_info/1
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [r4, 64]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L29:
    ldr r3, [L30]
    movw r1, 4868
    movt r1, 16425
    adr r2, L29
# BIF: erlang:get_module_info/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L31
    udf 48879
L31:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L32
    udf 57005
L32:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# int_code_end
L33:
    movw r0, 18576
    movt r0, 16480
    blx L22
L13:
L12:
    movw r12, 1968
    movt r12, 14656
    blx r12
L22:
L21:
    movw r12, 29192
    movt r12, 16399
    blx r12
L11:
L10:
    movw r12, 1752
    movt r12, 14656
    blx r12
L20:
L19:
    movw r12, 680
    movt r12, 14656
    blx r12
L8:
L7:
    movw r12, 1824
    movt r12, 14656
    blx r12
# Begin stub section
L14:
.xword 0x000000007FFFFFFF
L16:
.xword 0x000000007FFFFFFF
L25:
.xword 0x000000007FFFFFFF
L30:
.xword 0x000000007FFFFFFF
# End stub section
L34:
.section .rodata {#1}
md5:
.byte 0x6D, 0xC4, 0x1E, 0xF1, 0x13, 0x1E, 0xBF, 0xF2, 0x4B, 0xF5, 0xC0, 0x41, 0x57, 0x86, 0xDF, 0xD5
.section .text {#0}
; CODE_SIZE: 632&lt;/code&gt;
    &lt;p&gt;Bear in mind, this assembler is not what hello should look like. We are missing a lot of things.&lt;/p&gt;
    &lt;p&gt;You can spot many sequences like:&lt;/p&gt;
    &lt;code&gt;    movw r0, 64676
    movt r0, 16480
    blx L22 # &amp;lt;---- branch to NYI&lt;/code&gt;
    &lt;p&gt;This is a call to &lt;code&gt;nyi&lt;/code&gt; (Not Yet Implemented) function and the argument loaded to R0 is the pointer to a string that contains the name of the BEAM instruction that should have been emitted instead. You can spot many of these since we are only emitting the code to reach halt. Everything after that is not important now as halt will never return!&lt;/p&gt;
    &lt;p&gt;There are many more comments we could make around all the details in this assembler dump, but let's move on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jumping into Jitted code!&lt;/head&gt;
    &lt;p&gt;Later in the BEAM initialization the first Erlang process will be allocated and started.&lt;/p&gt;
    &lt;p&gt;We swap the module and function with hello in erts/emulator/beam/erl_init.c&lt;/p&gt;
    &lt;code&gt;    erl_spawn_system_process(&amp;amp;parent, am_hello, am_start, args, &amp;amp;so);&lt;/code&gt;
    &lt;p&gt;One BEAM scheduler thread will jump to the &lt;code&gt;process_main&lt;/code&gt; function. You can find it here in the source code. This is emitted by our JIT and is the first emitted code that will run.&lt;/p&gt;
    &lt;p&gt;Here we need to handle the Erlang processes scheduling by calling BEAM routines that implement the algorithms of Erlang concurrency, like &lt;code&gt;erts_schedule&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;erts_schedule&lt;/code&gt; will return the pointer to the &lt;code&gt;Process&lt;/code&gt; C structure that holds all information about the process that is going to execute. We then load all necessary data inside registers and then we branch to the exact point where the program execution stopped.&lt;/p&gt;
    &lt;head rend="h3"&gt;The first Erlang function call&lt;/head&gt;
    &lt;p&gt;In this case we are calling &lt;code&gt;hello:start/2&lt;/code&gt; so the first instruction to execute is &lt;code&gt;apply_only&lt;/code&gt; that does a few things but ends up calling the C &lt;code&gt;apply&lt;/code&gt; routine.&lt;/p&gt;
    &lt;p&gt;The routine processes the Module-Function-Arity information to get the address where the function code resides in memory.&lt;/p&gt;
    &lt;p&gt;What follows is the Erlang function prologue. You can see it in the assembler code section above. For example, all functions have these instructions in their prologue:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i_breakpoint_trampoline: handle breakpoints for the &lt;code&gt;debugger&lt;/code&gt;app&lt;/item&gt;
      &lt;item&gt;i_test_yield: checks if the function should yield and go back to the scheduler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We have minimal or partial implementations of these since we do not really need them. We have to emit them though, as the C++ generated loader functions from the BEAM are expanding the Erlang function call Operation into a more specific and complex function prologue sequence.&lt;/p&gt;
    &lt;p&gt;After that, we added support for the &lt;code&gt;call_light_bif&lt;/code&gt; operation that precedes the call to the halt_2 BIF routine. This implementation is also minimal.&lt;/p&gt;
    &lt;p&gt;Question for later: did you notice that we put a &lt;code&gt;42&lt;/code&gt; as a number in the code? Numeric constants are printed as decimals in the dump, but we cannot spot any 42!?&lt;/p&gt;
    &lt;p&gt;After the call, we see two other operations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dealloc&lt;/item&gt;
      &lt;item&gt;return&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are just calls to NYI as we will never reach this code! So for now, we can skip them...&lt;/p&gt;
    &lt;head rend="h3"&gt;Let's roll the JIT!&lt;/head&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$&lt;/code&gt;
    &lt;p&gt;Impressive, the program returns immediately without even saying "Hi" ... and without Segmentation Fault!!&lt;/p&gt;
    &lt;p&gt;But let's check the program return code!&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ echo $?
42
&lt;/code&gt;
    &lt;p&gt;We can safely say that number is not there by accident! This is a great achievement as from now on we will be able to incrementally add Erlang instructions.&lt;/p&gt;
    &lt;p&gt;Every Erlang line we add will trigger new Opcodes. By emitting them and running the code we will have immediate feedback on everything.&lt;/p&gt;
    &lt;p&gt;The next goal now is to complete the &lt;code&gt;hello&lt;/code&gt; module to host all possible beam instructions!&lt;/p&gt;
    &lt;head rend="h4"&gt;Hey where is 42???&lt;/head&gt;
    &lt;p&gt;One interesting thing I spotted looking at the assembly: You cannot find the number &lt;code&gt;42&lt;/code&gt; in there. Or actually, you can, it is just hidden in plain sight. To understand you need to know how we are using ARM32 registers.&lt;/p&gt;
    &lt;p&gt;In particular the register &lt;code&gt;r4&lt;/code&gt;, a callee-saved register. We are using it to store the pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; struct. The &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; contains the X register array. When a function is called, X registers are used to store the arguments of the call.&lt;/p&gt;
    &lt;p&gt;This becomes more obvious if we compare the Erlang assembly to the Arm32 assembly.&lt;/p&gt;
    &lt;code&gt;# i_move_sd                       &amp;lt;---- {move,{literal,[{flush,false}]},{x,1}}. % List at X[1]
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd                       &amp;lt;---- {move,{integer,42},{x,0}}. % 42 at X[0]
    movw r12, 687 
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
# ...&lt;/code&gt;
    &lt;p&gt;42 is stored at &lt;code&gt;r4&lt;/code&gt;+64.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;r4: pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt;struct&lt;/item&gt;
      &lt;item&gt;64: base offset from the beginning of the struct to the beginning of the &lt;code&gt;x_reg_array&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The list is stored at &lt;code&gt;r4&lt;/code&gt;+68.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;68: is the base offset + the size of one &lt;code&gt;Eterm&lt;/code&gt;(4 bytes on ARM32)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But why in assembly do we see 687 and not 42?&lt;/p&gt;
    &lt;p&gt;Converting both numbers to hex we get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;42 -&amp;gt; 2A&lt;/item&gt;
      &lt;item&gt;687 -&amp;gt; 2AF !!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yep, this is an example of a Tagged Value. If we consult the BEAM book we can learn about the Tagging Scheme:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;00 11 Pid&lt;/item&gt;
      &lt;item&gt;01 11 Port&lt;/item&gt;
      &lt;item&gt;10 11 Immediate 2&lt;/item&gt;
      &lt;item&gt;11 11 Small integer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;42 is tagged with &lt;code&gt;1111&lt;/code&gt; at the low end. So the BEAM can quickly recognize during a pattern match that this Erlang Term is a Small Integer!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502543</guid><pubDate>Tue, 07 Oct 2025 13:00:25 +0000</pubDate></item><item><title>Tcl-Lang Showcase</title><link>https://wiki.tcl-lang.org/page/Showcase</link><description>&lt;doc fingerprint="598b77957e6a418d"&gt;
  &lt;main&gt;&lt;p&gt;Canvas3d&lt;/p&gt;Canvas3d wiki page&lt;p&gt;HP-15 Simulation&lt;/p&gt;HP-15 Simulation wiki page&lt;p&gt;By clicking on the image, an interactive demonstration of the Tcl/Tk application is launched using CloudTk. Over 100 Tcl/Tk applications listed from this wiki are demonstrated here . To view the Tcl/Tk Widget Demonstration, go to the "Playground" from the menu above and then select "Demos" in the "Tcl-Playground" - Console menu.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502784</guid><pubDate>Tue, 07 Oct 2025 13:25:33 +0000</pubDate></item><item><title>Show HN: MARS – Personal AI robot for builders (&lt; $2k)</title><link>https://news.ycombinator.com/item?id=45504127</link><description>&lt;doc fingerprint="f1df9a7b68a781cd"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey, we’re Axel and Vignesh, cofounders of Innate (&lt;/p&gt;https://www.innate.bot/&lt;p&gt;). We just launched MARS, a general-purpose robot with an open onboard agentic OS built on top of ROS2.&lt;/p&gt;&lt;p&gt;Overview: https://youtu.be/GEOMYDXv6pE&lt;/p&gt;&lt;p&gt;Control demo: https://youtu.be/_Cw5fGa8i3s&lt;/p&gt;&lt;p&gt;Videos of autonomous use-cases: https://docs.innate.bot/welcome/mars-example-use-cases&lt;/p&gt;&lt;p&gt;Quickstart: https://docs.innate.bot/welcome/mars-quick-start.&lt;/p&gt;&lt;p&gt;Our last thread: https://news.ycombinator.com/item?id=42451707&lt;/p&gt;&lt;p&gt;When we started we felt there is currently no good affordable general-purpose that anyone can build on. There’s no lack of demand: hugging face’s SO-100 and LeKiwi are pretty clear successes already; but the hardware is unreliable, the software experience is barebone and keeps changing, and you often need to buy hidden extras to make them work (starting with a computer with a good gpu). The Turtlebots were good, but are getting outdated.&lt;/p&gt;&lt;p&gt;The open-source hobbyist movement lacks really good platforms to build on, and we wanted something robust and accessible. MARS is our attempt at making a first intuitive AI robot for everyone.&lt;/p&gt;&lt;p&gt;What it is:&lt;/p&gt;&lt;p&gt;- It comes assembled and calibrated&lt;/p&gt;&lt;p&gt;- Has onboard compute with a jetson orin nano 8gb&lt;/p&gt;&lt;p&gt;- a 5DoF arm with a wrist camera&lt;/p&gt;&lt;p&gt;- Sensors: RGBD wide-angle cam, 2D LiDAR, speakers&lt;/p&gt;&lt;p&gt;- Control via a dedicated app and a leader arm that plugs in iPhone and Android&lt;/p&gt;&lt;p&gt;- 2 additional USB ports + GPIO pins for extra sensors or effectors.&lt;/p&gt;&lt;p&gt;- And our novel SDK called BASIC that allows to run it like an AI agent with VLAs.&lt;/p&gt;&lt;p&gt;It boots in a minute, can be controlled via phone, programmable in depth with a PC, and the onboard agent lets it see, talk, plan, and act in real-time.&lt;/p&gt;&lt;p&gt;Our SDK BASIC allows to create “behaviors” (our name for programs) ranging from a simple hello world to a very complex long-horizon task involving reasoning, planning, navigation and manipulation. You can create skills that behaviors can run autonomously by training the arm or writing code tools, like for an AI agent.&lt;/p&gt;&lt;p&gt;You can also call the ROS2 topics to control the robot at a low-level. And anything created on top of this SDK can be easily shared with anyone else by just sharing the files.&lt;/p&gt;&lt;p&gt;This is intended for hobbyist builders and education, and we would love to have your feedback!&lt;/p&gt;&lt;p&gt;p.s. If you want to try it, there’s a temporary code HACKERNEWS-INNATE-MARS that lowers the price to $1,799.&lt;/p&gt;&lt;p&gt;p.p.s The hardware and software will be open-sourced too, if some of you want to contribute or help us prepare it properly feel free to join our discord at https://discord.gg/YvqQbGKH&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504127</guid><pubDate>Tue, 07 Oct 2025 15:11:52 +0000</pubDate></item><item><title>Launch HN: LlamaFarm (YC W22) – Open-source framework for distributed AI</title><link>https://github.com/llama-farm/llamafarm</link><description>&lt;doc fingerprint="ed1fa4511bbd11f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Build powerful AI locally, extend anywhere.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;LlamaFarm is an open-source framework for building retrieval-augmented and agentic AI applications. It ships with opinionated defaults (Ollama for local models, Chroma for vector storage) while staying 100% extendable—swap in vLLM, remote OpenAI-compatible hosts, new parsers, or custom stores without rewriting your app.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first developer experience with a single CLI (&lt;code&gt;lf&lt;/code&gt;) that manages projects, datasets, and chat sessions.&lt;/item&gt;
      &lt;item&gt;Production-ready architecture that mirrors server endpoints and enforces schema-based configuration.&lt;/item&gt;
      &lt;item&gt;Composable RAG pipelines you can tailor through YAML, not bespoke code.&lt;/item&gt;
      &lt;item&gt;Extendable everything: runtimes, embedders, databases, extractors, and CLI tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;📺 Video demo (90 seconds): https://youtu.be/W7MHGyN0MdQ&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install the CLI&lt;/p&gt;
        &lt;p&gt;macOS / Linux&lt;/p&gt;
        &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/llama-farm/llamafarm/main/install.sh | bash&lt;/code&gt;
        &lt;p&gt;Windows (via winget)&lt;/p&gt;
        &lt;code&gt;winget install LlamaFarm.CLI&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adjust Ollama context window&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Open the Ollama app, go to Settings → Advanced, and set the context window to match production (e.g., 100K tokens).&lt;/item&gt;
          &lt;item&gt;Larger context windows improve RAG answers when long documents are ingested.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create and run a project&lt;/p&gt;
        &lt;quote&gt;lf init my-project # Generates llamafarm.yaml using the server template lf start # Spins up Docker services &amp;amp; opens the dev chat UI&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start an interactive project chat or send a one-off message&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Interactive project chat (auto-detects namespace/project from llamafarm.yaml)
lf chat

# One-off message
lf chat "Hello, LlamaFarm!"&lt;/code&gt;
    &lt;p&gt;Need the full walkthrough with dataset ingestion and troubleshooting tips? Jump to the Quickstart guide.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Prefer building from source? Clone the repo and follow the steps in Development &amp;amp; Testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run services manually (without Docker auto-start):&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install Nx globally and bootstrap the workspace
npm install -g nx
nx init --useDotNxInstallation --interactive=false

# Option 1: start both server and RAG worker with one command
nx dev

# Option 2: start services in separate terminals
# Terminal 1
nx start rag
# Terminal 2
nx start server&lt;/code&gt;
    &lt;p&gt;Open another terminal to run &lt;code&gt;lf&lt;/code&gt; commands (installed or built from source). This is equivalent to what &lt;code&gt;lf start&lt;/code&gt; orchestrates automatically.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Own your stack – Run small local models today and swap to hosted vLLM, Together, or custom APIs tomorrow by changing &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Battle-tested RAG – Configure parsers, extractors, embedding strategies, and databases without touching orchestration code.&lt;/item&gt;
      &lt;item&gt;Config over code – Every project is defined by YAML schemas that are validated at runtime and easy to version control.&lt;/item&gt;
      &lt;item&gt;Friendly CLI – &lt;code&gt;lf&lt;/code&gt;handles project bootstrapping, dataset lifecycle, RAG queries, and non-interactive chats.&lt;/item&gt;
      &lt;item&gt;Built to extend – Add a new provider or vector store by registering a backend and regenerating schema types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Initialize a project&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf init my-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Creates &lt;code&gt;llamafarm.yaml&lt;/code&gt; from server template.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start dev stack + chat TUI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf start&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Spins up server, rag worker, monitors Ollama/vLLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Interactive project chat&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opens TUI using project from &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Send single prompt&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat "Explain retrieval augmented generation"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Uses RAG by default; add &lt;code&gt;--no-rag&lt;/code&gt; for pure LLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Preview REST call&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat --curl "What models are configured?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Prints sanitized &lt;code&gt;curl&lt;/code&gt; command.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Create dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets create -s pdf_ingest -b main_db research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validates strategy/database against project config.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Upload files&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets upload research-notes ./docs/*.pdf&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Supports globs and directories.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Process dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets process research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Streams heartbeat dots during long processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Semantic query&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf rag query --database main_db "What did the 2024 FDA letters require?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;--filter&lt;/code&gt;, &lt;code&gt;--include-metadata&lt;/code&gt;, etc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See the CLI reference for full command details and troubleshooting advice.&lt;/p&gt;
    &lt;p&gt;LlamaFarm provides a comprehensive REST API (compatible with OpenAI's format) for integrating with your applications. The API runs at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chat Completions (OpenAI-compatible)&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What are the FDA requirements?"}
    ],
    "stream": false,
    "rag_enabled": true,
    "database": "main_db"
  }'&lt;/code&gt;
    &lt;p&gt;RAG Query&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "clinical trial requirements",
    "database": "main_db",
    "top_k": 5
  }'&lt;/code&gt;
    &lt;p&gt;Dataset Management&lt;/p&gt;
    &lt;code&gt;# Upload file
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/data \
  -F "file=@document.pdf"

# Process dataset
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/process&lt;/code&gt;
    &lt;p&gt;Check your &lt;code&gt;llamafarm.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;name: my-project        # Your project name
namespace: my-org       # Your namespace&lt;/code&gt;
    &lt;p&gt;Or inspect the file system: &lt;code&gt;~/.llamafarm/projects/{namespace}/{project}/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;See the complete API Reference for all endpoints, request/response formats, Python/TypeScript clients, and examples.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;llamafarm.yaml&lt;/code&gt; is the source of truth for each project. The schema enforces required fields and documents every extension point.&lt;/p&gt;
    &lt;code&gt;version: v1
name: fda-assistant
namespace: default

runtime:
  provider: openai                   # "openai" for any OpenAI-compatible host, "ollama" for local Ollama
  model: qwen2.5:7b
  base_url: http://localhost:8000/v1 # Point to vLLM, Together, etc.
  api_key: sk-local-placeholder
  instructor_mode: tools             # Optional: json, md_json, tools, etc.

prompts:
  - role: system
    content: &amp;gt;-
      You are an FDA specialist. Answer using short paragraphs and cite document titles when available.

rag:
  databases:
    - name: main_db
      type: ChromaStore
      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: filtered_search
      embedding_strategies:
        - name: default_embeddings
          type: OllamaEmbedder
          config:
            model: nomic-embed-text:latest
      retrieval_strategies:
        - name: filtered_search
          type: MetadataFilteredStrategy
          config:
            top_k: 5
  data_processing_strategies:
    - name: pdf_ingest
      parsers:
        - type: PDFParser_LlamaIndex
          config:
            chunk_size: 1500
            chunk_overlap: 200
      extractors:
        - type: HeadingExtractor
        - type: ContentStatisticsExtractor

datasets:
  - name: research-notes
    data_processing_strategy: pdf_ingest
    database: main_db&lt;/code&gt;
    &lt;p&gt;Configuration reference: Configuration Guide • Extending LlamaFarm&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap runtimes by pointing to any OpenAI-compatible endpoint (vLLM, Mistral, Anyscale). Update &lt;code&gt;runtime.provider&lt;/code&gt;,&lt;code&gt;base_url&lt;/code&gt;, and&lt;code&gt;api_key&lt;/code&gt;; regenerate schema types if you add a new provider enum.&lt;/item&gt;
      &lt;item&gt;Bring your own vector store by implementing a store backend, adding it to &lt;code&gt;rag/schema.yaml&lt;/code&gt;, and updating the server service registry.&lt;/item&gt;
      &lt;item&gt;Add parsers/extractors to support new file formats or metadata pipelines. Register implementations and extend the schema definitions.&lt;/item&gt;
      &lt;item&gt;Extend the CLI with new Cobra commands under &lt;code&gt;cli/cmd&lt;/code&gt;; the docs include guidance on adding dataset utilities or project tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the Extending guide for step-by-step instructions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;What it Shows&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FDA Letters Assistant&lt;/cell&gt;
        &lt;cell&gt;Multi-document PDF ingestion, RAG queries, reference-style prompts&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/fda_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Raleigh UDO Planning Helper&lt;/cell&gt;
        &lt;cell&gt;Large ordinance ingestion, long-running processing tips, geospatial queries&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/gov_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;lf datasets&lt;/code&gt; and &lt;code&gt;lf rag query&lt;/code&gt; commands from each example folder to reproduce the flows demonstrated in the docs.&lt;/p&gt;
    &lt;code&gt;# Python server + RAG tests
cd server
uv sync
uv run --group test python -m pytest

# CLI tests
cd ../cli
go test ./...

# RAG tooling smoke tests
cd ../rag
uv sync
uv run python cli.py test

# Docs build (ensures navigation/link integrity)
cd ..
nx build docs&lt;/code&gt;
    &lt;p&gt;Linting: &lt;code&gt;uv run ruff check --fix .&lt;/code&gt; (Python), &lt;code&gt;go fmt ./...&lt;/code&gt; and &lt;code&gt;go vet ./...&lt;/code&gt; (Go).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord – chat with the team, share feedback, find collaborators.&lt;/item&gt;
      &lt;item&gt;GitHub Issues – bug reports and feature requests.&lt;/item&gt;
      &lt;item&gt;Discussions – ideas, RFCs, roadmap proposals.&lt;/item&gt;
      &lt;item&gt;Contributing Guide – code style, testing expectations, doc updates, schema regeneration steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to add a new provider, parser, or example? Start a discussion or open a draft PR—we love extensions!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Licensed under the Apache 2.0 License.&lt;/item&gt;
      &lt;item&gt;Built by the LlamaFarm community and inspired by the broader open-source AI ecosystem. See CREDITS for detailed acknowledgments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build locally. Deploy anywhere. Own your AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504388</guid><pubDate>Tue, 07 Oct 2025 15:30:20 +0000</pubDate></item><item><title>IKEA Catalogs 1951-2021</title><link>https://ikeamuseum.com/en/explore/ikea-catalogue/</link><description>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504470</guid><pubDate>Tue, 07 Oct 2025 15:35:48 +0000</pubDate></item><item><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><link>https://timelinize.com</link><description>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504973</guid><pubDate>Tue, 07 Oct 2025 16:10:22 +0000</pubDate></item><item><title>Cache-Friendly B+Tree Nodes with Dynamic Fanout</title><link>https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/</link><description>&lt;doc fingerprint="eafbc81bf4b08ea8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Cache-Friendly B+Tree Nodes With Dynamic Fanout&lt;/head&gt;&lt;p&gt;For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.&lt;/p&gt;&lt;p&gt;In C++, achieving this means forgoing the use of &lt;code&gt;std::vector&lt;/code&gt;, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.&lt;/p&gt;&lt;code&gt;  +----------------------+&lt;/code&gt;&lt;head rend="h2"&gt;Challenges&lt;/head&gt;&lt;p&gt;Using &lt;code&gt;std::vector&lt;/code&gt; for a B+Tree node's entries is a non-starter. A &lt;code&gt;std::vector&lt;/code&gt; object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.&lt;/p&gt;&lt;p&gt;This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.&lt;/p&gt;&lt;p&gt;This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?&lt;/p&gt;&lt;p&gt;The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.&lt;/p&gt;&lt;head rend="h2"&gt;The Struct Hack&lt;/head&gt;&lt;p&gt;The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.&lt;/p&gt;&lt;code&gt;struct Payload {&lt;/code&gt;&lt;p&gt;At runtime, when the required size &lt;code&gt;N&lt;/code&gt; is known, you allocate a single block of memory for the struct and the &lt;code&gt;N&lt;/code&gt; elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.&lt;/p&gt;&lt;code&gt;// The (N - 1) adjusts for the 1-element array in Payload struct&lt;/code&gt;&lt;p&gt;This pattern was officially standardized in C99, where it is known as a flexible array member.&lt;/p&gt;&lt;p&gt;The C++11 standard formally incorporates the flexible array member, referring to it as an array of unknown bound when it is the last member of a struct.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Arrays of unknown bound&lt;/p&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;expr&lt;/code&gt;is omitted in the declaration of an array, the type declared is "array of unknown bound of T", which is a kind of incomplete type, ...&lt;code&gt;extern int x[]; // the type of x is "array of unknown bound of int"&lt;/code&gt;&lt;lb/&gt;int a[] = {1, 2, 3}; // the type of a is "array of 3 int"&lt;/quote&gt;&lt;p&gt;This means that in C++, the size can be omitted from the final array declaration (e.g. &lt;code&gt;entries_[]&lt;/code&gt;), and the code will compile, enabling the same pattern.&lt;/p&gt;&lt;head rend="h2"&gt;B+Tree Node Declaration&lt;/head&gt;&lt;p&gt;Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;&lt;p&gt;Using a &lt;code&gt;std::vector&amp;lt;KeyValuePair&amp;gt;&lt;/code&gt; for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.&lt;/p&gt;&lt;p&gt;A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.&lt;/p&gt;&lt;p&gt;This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.&lt;/p&gt;&lt;head rend="h2"&gt;Raw Memory Buffer&lt;/head&gt;&lt;p&gt;This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard &lt;code&gt;new&lt;/code&gt; syntax which will attempt to allocate storage, and then initialize the object in the same storage.&lt;/p&gt;&lt;p&gt;Instead, we use the placement new syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard &lt;code&gt;new&lt;/code&gt; operator does not have in this scenario because of the flexible array member.&lt;/p&gt;&lt;code&gt;// A static helper to allocate storage for a B+Tree node.&lt;/code&gt;&lt;p&gt;The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.&lt;/p&gt;&lt;head rend="h2"&gt;The Price Of Fine-Grained Control&lt;/head&gt;&lt;p&gt;To create an instance of a B+Tree node with a fanout of &lt;code&gt;256&lt;/code&gt;, it is not possible to write simple idiomatic code like this: &lt;code&gt;new BPlusTreeNode(256)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Instead we use the custom &lt;code&gt;BPlusTreeNode::Get&lt;/code&gt; helper which knows how much raw memory to allocate for the object including the data section.&lt;/p&gt;&lt;code&gt;BPlusTreeNode *root = BPlusTreeNode&amp;lt;KeyValuePair&amp;gt;::Get(256);&lt;/code&gt;&lt;head rend="h3"&gt;Manual Handling Of Deallocation&lt;/head&gt;&lt;p&gt;The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.&lt;/p&gt;&lt;code&gt;class BPlusTreeNode {&lt;/code&gt;&lt;p&gt;This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our &lt;code&gt;Get&lt;/code&gt; function. We constructed the object outside in: raw memory buffer -&amp;gt; node object -&amp;gt; individual elements. So we teardown in the opposite direction, from the inside out: individual elements -&amp;gt; node object -&amp;gt; raw memory buffer.&lt;/p&gt;&lt;head rend="h3"&gt;Adding New Members In A Derived Class&lt;/head&gt;&lt;p&gt;Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized &lt;code&gt;InnerNode&lt;/code&gt; or &lt;code&gt;LeafNode&lt;/code&gt; class.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;&lt;code&gt;entries_&lt;/code&gt; array in memory.&lt;p&gt;The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.&lt;/p&gt;&lt;p&gt;The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;
&lt;code&gt;InnerNode&lt;/code&gt; and &lt;code&gt;LeafNode&lt;/code&gt; implementations.&lt;head rend="h3"&gt;Reinventing The Wheel&lt;/head&gt;&lt;p&gt;By using a raw C-style array, we effectively reinvent parts of &lt;code&gt;std::vector&lt;/code&gt;, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.&lt;/p&gt;&lt;p&gt;The engineering cost to make this implementation production-grade is significant.&lt;/p&gt;&lt;head rend="h3"&gt;Hidden Data Type Assumptions&lt;/head&gt;&lt;p&gt;The &lt;code&gt;BPlusTreeNode&lt;/code&gt;'s generic signature implies it will work for any &lt;code&gt;KeyType&lt;/code&gt; or &lt;code&gt;ValueType&lt;/code&gt;, but this is dangerously misleading. Using a non-trivial type like &lt;code&gt;std::string&lt;/code&gt; will cause undefined behavior.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;
&lt;p&gt;To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.&lt;/p&gt;&lt;code&gt;bool Insert(const KeyValuePair &amp;amp;element, KeyValuePair *pos) {&lt;/code&gt;
&lt;p&gt;The use of &lt;code&gt;std::memmove&lt;/code&gt; introduces a hidden constraint: &lt;code&gt;KeyValuePair&lt;/code&gt; must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.&lt;/p&gt;&lt;p&gt;Using &lt;code&gt;std::memmove&lt;/code&gt; on a &lt;code&gt;std::string&lt;/code&gt; object creates a shallow copy. We now have two &lt;code&gt;std::string&lt;/code&gt; objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;The initial hurdle when implementing a B+Tree implementation is solving the contiguous memory layout puzzle avoiding heap indirection. The solution is flexible array members, which makes it possible to compile the program when the number of entries in the B+Tree node is dynamic, and a runtime value.&lt;/p&gt;&lt;p&gt;However, the implementation complexity goes up because of manual memory management, lack of inheritance, and hidden data type constraints. This is unavoidable for high performance.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505398</guid><pubDate>Tue, 07 Oct 2025 16:39:13 +0000</pubDate></item><item><title>Pigeon (YC W23) is hiring a lead full stack engineer</title><link>https://www.ycombinator.com/companies/pigeon/jobs/sjuJOg3-lead-full-stack-software-engineer-remote-us</link><description>&lt;doc fingerprint="aa9be2aaf687b428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h1"&gt;Lead Full Stack Software Engineer at Pigeon (YC W23)&lt;/head&gt;
        &lt;p&gt;Pigeon (YC W23) is looking for a motivated Lead Full Stack Software Engineer to join our engineering team. You can work from our NYC office or remotely if you’re not local.&lt;/p&gt;
        &lt;p&gt;As a Lead Full Stack Software Engineer at Pigeon, you will help lead a small and fast-paced engineering team and spearhead the development of new features and systems from the ground up. You will be given a unique opportunity to shape our stack, processes, and culture while making a tangible impact on our technology and our customers.&lt;/p&gt;
        &lt;head rend="h3"&gt;Why Join Pigeon&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Impact: You will own high-value features for Pigeon’s entire customer base that will help shape their everyday business processes.&lt;/item&gt;
          &lt;item&gt;Culture: You will help shape how we work on a day-to-day basis and inform core values as we grow.&lt;/item&gt;
          &lt;item&gt;Leadership: You will be placed in a key leadership position with the opportunity to contribute to our direction, goals, and vision.&lt;/item&gt;
          &lt;item&gt;Learning: You will be encouraged to experiment with new methods and technologies to enable innovative experiences for customers.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What You’ll Do&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Own core services, APIs, and integrations with third-party systems&lt;/item&gt;
          &lt;item&gt;Build and scale our AI-powered document processing system&lt;/item&gt;
          &lt;item&gt;Ship new features end-to-end - from conception to implementation to deployment&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What We’re Looking For&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;5+ years experience as a full-stack software engineer&lt;/item&gt;
          &lt;item&gt;Comfortable with fast-paced development environment and early-stage ambiguity&lt;/item&gt;
          &lt;item&gt;Ability to take full ownership of projects (scoping, system design, implementation, QA, deployment, and maintenance)&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Our Stack&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
          &lt;item&gt;Python, Flask, FastAPI, SqlAlchemy&lt;/item&gt;
          &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Benefits:&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Healthcare (Medical, Vision, and Dental)&lt;/item&gt;
          &lt;item&gt;OneMedical&lt;/item&gt;
          &lt;item&gt;401(k)&lt;/item&gt;
          &lt;item&gt;Unlimited PTO&lt;/item&gt;
          &lt;item&gt;16” Macbook Pro (M2 Chip)&lt;/item&gt;
          &lt;item&gt;Free Pigeon Merchandise (shop.pigeondocuments.com)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Pigeon automates the entire document lifecycle: collecting documents from clients, reviewing and extracting data with AI, and syncing with CRMs or storage systems. Pigeon eliminates the manual back-and-forth of document handling and eliminates thousands of hours of manual tasks.&lt;/p&gt;
      &lt;p&gt;We're growing fast, and want someone who can help join our team as we prepare for the next stage of growth.&lt;/p&gt;
      &lt;head rend="h3"&gt;Team&lt;/head&gt;
      &lt;p&gt;We are a team of 4 who previously worked at Google, Squarespace, Deloitte, and HonorLock.&lt;/p&gt;
      &lt;head rend="h3"&gt;Funding Status&lt;/head&gt;
      &lt;p&gt;We closed a $3.5M Seed round post-YC.&lt;/p&gt;
      &lt;head rend="h3"&gt;About our Technology:&lt;/head&gt;
      &lt;p&gt;Our Stack:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
        &lt;item&gt;Python, Flask, SqlAlchemy&lt;/item&gt;
        &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505666</guid><pubDate>Tue, 07 Oct 2025 17:00:09 +0000</pubDate></item><item><title>Doing Rails Wrong</title><link>https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong</link><description>&lt;doc fingerprint="2cd7f1377fc53f68"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt; You're doing Rails wrong. copy link &lt;/head&gt;
    &lt;head rend="h6"&gt;Tuesday, 07 October 2025&lt;/head&gt;
    &lt;p&gt; Kevin: Hey, have you tried Vite for Rails 8? It’s insanely fast.&lt;/p&gt;
    &lt;p&gt; John: I’ve heard of it. Isn’t that a build tool? Didn’t Rails already come with one?&lt;/p&gt;
    &lt;p&gt; K: Well, it did, but Vite is like… modern. You’ll need to install Node, npm, and configure a few scripts, but it’s totally worth it.&lt;/p&gt;
    &lt;p&gt; J: Wait, Rails needs Node now?&lt;/p&gt;
    &lt;p&gt; K: Well, yeah — if you want to use React. Everyone’s using React.&lt;/p&gt;
    &lt;p&gt; J: Didn’t Rails have something for that?&lt;/p&gt;
    &lt;p&gt; K: It did, but now you’ll want to use Vite with React Refresh so you get instant component reloads. And if you want TypeScript support, you’ll have to configure that too.&lt;/p&gt;
    &lt;p&gt; J: Sounds… like a lot.&lt;/p&gt;
    &lt;p&gt; K: Oh, not really. Just install Babel, configure your .babelrc, add vite-plugin-ruby, then you’ll want PostCSS for your styles.&lt;/p&gt;
    &lt;p&gt; J: PostCSS?&lt;/p&gt;
    &lt;p&gt; K: Yeah, and then Tailwind, obviously — you don’t want to write CSS like a peasant.&lt;/p&gt;
    &lt;p&gt; J: Of course not.&lt;/p&gt;
    &lt;p&gt; K: Then you’ll probably want to add ESLint and Prettier to make sure your code looks clean, and maybe Husky for pre-commit hooks.&lt;/p&gt;
    &lt;p&gt; J: So... Vite, React, Babel, PostCSS, Tailwind, ESLint, Prettier, Husky. That’s it?&lt;/p&gt;
    &lt;p&gt; K: Pretty much. Oh, unless you want server-side rendering — then you’ll need Next.js or Remix.&lt;/p&gt;
    &lt;p&gt; J: Wait, we’re still talking about a Rails app, right?&lt;/p&gt;
    &lt;p&gt; K: Yeah, but hybrid stacks are the way to go! You could also use StimulusReflex or Hotwire if you want reactive components without JS frameworks.&lt;/p&gt;
    &lt;p&gt; J: StimulusReflex sounds like a Marvel character.&lt;/p&gt;
    &lt;p&gt; K: Ha! No, it’s for real-time updates. But you’ll need ActionCable configured, Redis running, and—&lt;/p&gt;
    &lt;p&gt; J: Redis?&lt;/p&gt;
    &lt;p&gt; K: Yeah, you need a pub/sub layer. Don’t worry, it’s just another Docker container.&lt;/p&gt;
    &lt;p&gt; J: Docker too?&lt;/p&gt;
    &lt;p&gt; K: Yeah, to isolate your dependencies. And if you want everything reproducible, you’ll need Docker Compose, maybe Fly.io for deployment, and a build pipeline with GitHub Actions.&lt;/p&gt;
    &lt;p&gt; J: That’s... quite a setup.&lt;/p&gt;
    &lt;p&gt; K: It’s just modern web development, man. Keeps things simple. What are you doing?&lt;/p&gt;
    &lt;p&gt; J: Just tinkering.&lt;/p&gt;
    &lt;p&gt;(John runs a single command. The app boots instantly, working forms, instant loading times, blazing fast navigation.)&lt;/p&gt;
    &lt;p&gt; K: Wow, that looks like a pretty complex setup. What stack’s that?&lt;/p&gt;
    &lt;p&gt; J: Vanilla Rails.&lt;/p&gt;
    &lt;p&gt;Just F#$%^&amp;amp; use Rails.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505692</guid><pubDate>Tue, 07 Oct 2025 17:01:32 +0000</pubDate></item><item><title>ICE bought vehicles equipped with fake cell towers to spy on phones</title><link>https://techcrunch.com/2025/10/07/ice-bought-vehicles-equipped-with-fake-cell-towers-to-spy-on-phones/</link><description>&lt;doc fingerprint="be3c0913216837ed"&gt;
  &lt;main&gt;
    &lt;p&gt;U.S. Immigration and Customs Enforcement (ICE) paid $825,000 earlier this year to a company that manufactures vehicles equipped with various technologies for law enforcement, including fake cellphone towers known as “cell-site simulators,” which can be used to spy on nearby phones.&lt;/p&gt;
    &lt;p&gt;According to public records, the award dated May 8 “provides Cell Site Simulator (CSS) Vehicles to support the Homeland Security Technical Operations program” and is a modification for “additional CSS Vehicles.”&lt;/p&gt;
    &lt;p&gt;The contract was signed with TechOps Specialty Vehicles (TOSV), a Maryland-based company. TOSV also signed a similar contract with ICE in September 2024 for $818,000, showing that the relationship between the agency and the company predates the Trump administration.&lt;/p&gt;
    &lt;p&gt;TOSV president Jon Brianas told TechCrunch in an email that he could not provide details about the ICE contracts and the vehicles, citing “trade secrets.” But Brianas did confirm that the company does provide cell-site simulators, although it does not make them.&lt;/p&gt;
    &lt;p&gt;“We don’t manufacture electrical, comms, and technology components, we integrate that product into our overall design of the vehicle,” said Brianas, who declined to say from where TOSV sources its cell-site simulators.&lt;/p&gt;
    &lt;p&gt;This is the latest federal contract that reveals some of the technologies powering the Trump administration’s deportation crackdown.&lt;/p&gt;
    &lt;p&gt;In early September, Forbes found a recently unsealed search warrant that showed that ICE used a cell-site simulator to track down a person who allegedly was part of a criminal gang in the United States, and who had been ordered to leave the country in 2023. In the article, Forbes reported that it also found a contract for “cell site simulator vehicles,” but the article did not name the company that provides the vans to the agency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025&lt;/head&gt;
    &lt;head rend="h4"&gt;Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch, and a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025&lt;/head&gt;
    &lt;head rend="h4"&gt;Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444.&lt;/head&gt;
    &lt;p&gt;Cell-site simulators also go by the name “stingrays” because some of the earlier types of these devices, made by defense contractor Harris (now L3Harris), were named that way. Since then, stingrays have become a catch-all name for this type of technology, also known as IMSI catchers. (IMSI stands for International Mobile Subscriber Identity, a unique number that identifies every cellphone user in the world.)&lt;/p&gt;
    &lt;p&gt;As the name suggests, cell-site simulator tools can mimic a cellphone tower, tricking every phone in its nearby range to connect to the device and thus giving law enforcement the ability to better identify the real-world location of those phones and their owners.&lt;/p&gt;
    &lt;p&gt;Some cell-site simulators can also intercept regular calls, text messages, and internet traffic.&lt;/p&gt;
    &lt;p&gt;Authorities can get data from traditional cellphone towers to find the current or past location of a suspect, but the location is usually not very precise.&lt;/p&gt;
    &lt;p&gt;Stingray-like devices have been in use by law enforcement for more than a decade and have long been controversial because authorities do not always get a warrant for their use, and critics say these devices ensnare innocent people by default. These devices are also shrouded in secrecy, because the law enforcement agencies that use them are under strict non-disclosure agreements not to reveal how the devices work.&lt;/p&gt;
    &lt;p&gt;ICE has a long history of using cell-site simulators. In 2020, documents obtained by the American Civil Liberties Union showed that ICE deployed them at least 466 times between 2017 and 2019. The agency used these tools more than 1,885 times between 2013 and 2017, according to documents obtained by BuzzFeed News at the time.&lt;/p&gt;
    &lt;p&gt;ICE acknowledged TechCrunch’s request for comment, but did not respond to a series of questions, which included: what ICE uses these vehicles for, whether and where they have recently been deployed, and whether the agency always gets a warrant when using cell-site simulators.&lt;/p&gt;
    &lt;head rend="h2"&gt;From surveillance vans to bookmobiles&lt;/head&gt;
    &lt;p&gt;Headquartered just outside of Washington, DC, TOSV sells a wide range of customizable vehicles to law enforcement, such as vans for SWAT armed response teams, bomb squads, and so-called “mobile lab” and “cover surveillance” vehicles.&lt;/p&gt;
    &lt;p&gt;Among these vehicles for police forces, TOSV lists several “projects,” including one described as DHS Mobile Forensic Labs, referring to the Department of Homeland Security.&lt;/p&gt;
    &lt;p&gt;According to the website, these mobile forensic vans are “equipped for on-site forensic analysis and documentation,” have “secure compartments for evidence preservation and investigative tools,” and enable “seamless case file updates and evidence logging.”&lt;/p&gt;
    &lt;p&gt;Another project is the DHS Mobile Command Van,” which TOSV says is “configurable for advanced surveillance and mission coordination.”&lt;/p&gt;
    &lt;p&gt;It’s unclear if these vans are the same vehicles that include cell-site simulators, as there’s no mention of the phone surveillance tool anywhere on TOSV’s website.&lt;/p&gt;
    &lt;p&gt;ICE has other contracts with TOSV for mobile forensic labs, which don’t specify which technologies are located in the vans.&lt;/p&gt;
    &lt;p&gt;According to its website, TOSV also sells so-called “bookmobiles,” which appear to be libraries on wheels, as well as medical and fire department vehicles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505854</guid><pubDate>Tue, 07 Oct 2025 17:12:43 +0000</pubDate></item><item><title>German government comes out against Chat Control</title><link>https://xcancel.com/paddi_hansen/status/1975595307800142205</link><description>&lt;doc fingerprint="77d803d92c0426bd"&gt;
  &lt;main&gt;
    &lt;p&gt;Great news and big win for privacy in the EU! 🇪🇺🇩🇪 Germany’s ruling CDU/CSU party made it clear today: there will be no chat control - as pushed for by other EU countries - with this German government.&lt;/p&gt;
    &lt;p&gt;40 Sekunden kurz und präzise: Mit der CDU/CSU wird es keine anlasslose Chatkontrolle geben, wie sie von einigen Staaten in der EU gefordert wird.&lt;/p&gt;
    &lt;p&gt;Oct 7, 2025 · 4:13 PM UTC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45506143</guid><pubDate>Tue, 07 Oct 2025 17:31:49 +0000</pubDate></item><item><title>Less Is More: Recursive Reasoning with Tiny Networks</title><link>https://arxiv.org/abs/2510.04871</link><description>&lt;doc fingerprint="3cbf352bcdf5c28f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 6 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Less is More: Recursive Reasoning with Tiny Networks&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexia Jolicoeur-Martineau [view email]&lt;p&gt;[v1] Mon, 6 Oct 2025 14:58:08 UTC (259 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45506268</guid><pubDate>Tue, 07 Oct 2025 17:42:06 +0000</pubDate></item><item><title>Solar energy is now the cheapest source of power, study</title><link>https://www.surrey.ac.uk/news/solar-energy-now-worlds-cheapest-source-power-surrey-study-finds</link><description>&lt;doc fingerprint="a545355d0abc55b8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solar energy is now the world’s cheapest source of power, a Surrey study finds&lt;/head&gt;
    &lt;p&gt;Solar energy is now so cost-effective that, in the sunniest countries, it costs as little as £0.02 to produce one unit of power, making it cheaper than electricity generated from coal, gas or wind, according to a new study from the University of Surrey.&lt;/p&gt;
    &lt;p&gt;In a study published in Energy and Environment Materials, researchers from Surrey’s Advanced Technology Institute (ATI) argue that solar photovoltaic (PV) technology is now the key driver of the world’s transition to clean, renewable power.&lt;/p&gt;
    &lt;p&gt;The research team also found that the price of lithium-ion batteries has fallen by 89% since 2010, making solar-plus-storage systems as cost-effective as gas power plants. These hybrid setups, which combine solar panels with batteries, are now standard in many regions and allow solar energy to be stored and released when needed, turning it into a more reliable, dispatchable source of power that helps balance grid demand.&lt;/p&gt;
    &lt;p&gt;Despite many reasons to be optimistic, the ATI research team points to several challenges – particularly connecting large amounts of solar power to existing electricity networks. In some regions, such as California and China, high solar generation has led to grid congestion and wasted energy when supply exceeds demand.&lt;/p&gt;
    &lt;p&gt;###&lt;/p&gt;
    &lt;p&gt;Notes to editors&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Professor Ravi Silva is available for interview; please contact mediarelations@surrey.ac.uk to arrange.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The full paper can be found here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Related sustainable development goals&lt;/head&gt;
    &lt;head rend="h2"&gt;Featured Academics&lt;/head&gt;
    &lt;head rend="h2"&gt;Media Contacts&lt;/head&gt;
    &lt;p&gt;External Communications and PR team&lt;lb/&gt; Phone: +44 (0)1483 684380 / 688914 / 684378&lt;lb/&gt; Email: mediarelations@surrey.ac.uk&lt;lb/&gt; Out of hours: +44 (0)7773 479911&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45506365</guid><pubDate>Tue, 07 Oct 2025 17:50:17 +0000</pubDate></item><item><title>Google's Requirement for Developers to Be Verified Threatens App Store F-Droid</title><link>https://www.techdirt.com/2025/10/07/googles-requirement-for-all-android-developers-to-register-and-be-verified-threatens-to-close-down-open-source-app-store-f-droid/</link><description>&lt;doc fingerprint="be60911198a71461"&gt;
  &lt;main&gt;
    &lt;p&gt;Google back then: “Don’t be evil.”&lt;/p&gt;
    &lt;p&gt;Google now: “Don’t be stupid by being good.”&lt;/p&gt;
    &lt;p&gt;It would be something of an understatement to say that Alphabet, Google’s holding company, is big and successful. Some Wall Street analysts are even predicting it could become the world’s most valuable corporation. Of course, even for business giants, enough is never enough. They always want more: more money, more power. As part of that tendency, Google seems to have decided that F-Droid, the free and open source app store for the Android platform, is a threat to the official Google Play Store that needs to be neutralized. At least that is likely to be the effect of Google’s announcement that it will require all Android developers to register and be verified before their apps can be allowed to run on certified Android devices. A post on the F-Droid blog explains what the problem is:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In addition to demanding payment of a registration fee and agreement to their (non-negotiable and ever-changing) terms and conditions, Google will also require the uploading of personally identifying documents, including government ID, by the authors of the software, as well as enumerating all the unique “application identifiers” for every app that is to be distributed by the registered developer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;According to the blog post, the impact on the F-Droid project would be severe:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;the developer registration decree will end the F-Droid project and other free/open-source app distribution sources as we know them today, and the world will be deprived of the safety and security of the catalog of thousands of apps that can be trusted and verified by any and all. F-Droid’s myriad users will be left adrift, with no means to install — or even update their existing installed — applications.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google says registration is needed to “better protect users from repeat bad actors spreading malware and scams”. Registration “creates crucial accountability, making it much harder for malicious actors to quickly distribute another harmful app after we take the first one down.” Slightly less convenient, perhaps, but not much harder. The F-Droid blog post points out that its open source app store already has a far better approach to security than Google’s proposed registration and verification:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;every [F-Droid] app is free and open source, the code can be audited by anyone, the build process and logs are public, and reproducible builds ensure that what is published matches the source code exactly. This transparency and accountability provides a stronger basis for trust than closed platforms, while still giving users freedom to choose. Restricting direct app installation not only undermines that choice, it also erodes the diversity and resilience of the open-source ecosystem by consolidating control in the hands of a few corporate players.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google is at pains to emphasize “Verified developers will have the same freedom to distribute their apps directly to users through sideloading or through any app store they prefer.” But that’s not true: their “freedom” will be soon be conditional, subject to Google’s whim and veto (as the company’s recent removal of the ICE-spotting app ‘Red Dot’ demonstrates). As a special concession, the company says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;we are also introducing a free developer account type that will allow teachers, students, and hobbyists to distribute apps to a limited number of devices without needing to provide a government ID.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But again that is subject to Google’s approval, and only allows distribution to a “limited number of devices” – a circumscribed “freedom”, in other words. And for F-Droid it’s not even an option, because of the following:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;How many F-Droid users are there, exactly? We don’t know, because we don’t track users or have any registration: “No user accounts, by design”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As the F-Droid post comments, Google’s move is not credibly about “security”, but actually about “consolidating power and tightening control over a formerly open ecosystem”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you own a computer, you should have the right to run whatever programs you want on it. This is just as true with the apps on your Android/iPhone mobile device as it is with the applications on your Linux/Mac/Windows desktop or server. Forcing software creators into a centralized registration scheme in order to publish and distribute their works is as egregious as forcing writers and artists to register with a central authority in order to be able to distribute their creative works. It is an offense to the core principles of free speech and thought that are central to the workings of democratic societies around the world.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google’s attack on F-Droid is ironic. At the heart of Android, and the key element that allowed it to become so successful so quickly, is the GPL-licensed Linux kernel. Over the years, Google has increased its control over Android by adding more non-free elements. If, as seems likely, its latest move leads to the shutdown of the 15-year-old F-Droid platform, it would represent a further betrayal of the open source world it once supported.&lt;/p&gt;
    &lt;p&gt; Filed Under: android, f-droid, freedom, id, linux, macintosh, malware, open source, registration, reproducibility, scams, security, verification, wall street, windows &lt;lb/&gt; Companies: alphabet, google &lt;/p&gt;
    &lt;p&gt;Google back then: “Don’t be evil.”&lt;/p&gt;
    &lt;p&gt;Google now: “Don’t be stupid by being good.”&lt;/p&gt;
    &lt;p&gt;They blessed our anti-trust and we’ve bent the knee to trump, now is the time to shine at being bastards!&lt;/p&gt;
    &lt;p&gt;At least half of Android’s value to me is simply being able to “side-load” apps from F-Droid on my “smartphone”.&lt;/p&gt;
    &lt;p&gt;Loading apps from F-Droid simply makes it so much easier to keep unwanted/unwarranted snooping away from my phone. (F-Droid has one particular, very simple feature that makes life so much easier: it explicitly breaks out and identifies “anti-features” — app features that I might not want or aren’t actually necessary for the function the app provides (like tracking me, tracking my habits/usage, serving ads, collecting data, not having a clear, easily activated account/data deletion mechanism, etc).&lt;/p&gt;
    &lt;p&gt;The result is that I can figure out whether I really want to install a particular app, much more quickly and easily on the F-Droid app store than on Google Play. (And you’d be surprised how many apps on the Google Play store are essentially the same code, dressed up in a different skin and with additional code to track/serve ads/whatever the developer chooses.)&lt;/p&gt;
    &lt;p&gt;Probably related: the F-Droid apps also tend to be noticeably easier on my battery (even when it’s clearly the same app, available from both Google Play and F-Droid).&lt;/p&gt;
    &lt;p&gt;I consider the ready accessibility of F-Droid (and similar app repositories) as an easy to use, viable app repository, to be a useful (and unfortunately necessary) check on Google’s corporate instincts to put its ability to control and exploit Android users ahead of providing its users with reasonable product/service on reasonable terms.&lt;/p&gt;
    &lt;p&gt;Sideloading is one of the major reasons I’ve been an Android user for so many years. I hope the EU steps up.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507173</guid><pubDate>Tue, 07 Oct 2025 18:51:40 +0000</pubDate></item><item><title>The murky economics of the data-centre investment boom</title><link>https://www.economist.com/business/2025/09/30/the-murky-economics-of-the-data-centre-investment-boom</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507195</guid><pubDate>Tue, 07 Oct 2025 18:52:46 +0000</pubDate></item><item><title>The publishing industry has a gambling problem</title><link>https://thewalrus.ca/the-publishing-industry-has-a-gambling-problem/</link><description>&lt;doc fingerprint="342080157fa50dc9"&gt;
  &lt;main&gt;
    &lt;p&gt;In 1970, a New York publishing company put out a debut novel by an editor and former teacher from Ohio. The press, then known as Holt, Rinehart and Winston, had taken a chance on the book, which had been rejected by numerous other houses. The initial print run was somewhere between 1,200 and 1,500 units—modest expectations that looked justified when, in the first year, sales barely cleared 2,000. This despite getting positive reviews in the New York Times and The New Yorker and being assigned to freshman classes at the City College of New York. The attention wasn’t enough. Four years later, the novel was out of print.&lt;/p&gt;
    &lt;p&gt;The author stayed in the game, albeit precariously. While working on her second book, she was a single parent commuting to Manhattan for a job in publishing. At the time, she was “so strapped for money that the condition moved from debilitating stress to hilarity.” Despite her first book’s lacklustre sales, she found a publisher for her second. The debut had attracted the admiration of a high-profile editor, one who happened to work in the same building she did. He acquired her next title, and the next, keeping her in house as she steadily built acclaim and an audience.&lt;/p&gt;
    &lt;p&gt;Eventually, the writer scored an opportunity still regarded as a grail of book marketing: her debut was chosen for Oprah’s Book Club. Sales reportedly soared to 800,000 copies. Today, publishers hope that their titles will nab the book club stamp—and the ensuing bump in sales—straight out of the gate. But, in this case, the Oprah endorsement came only at the turn of the millennium, thirty years after the novel was first released. By then, the author had published some half dozen other books and cleared the stable of major literary accolades. She had won the National Book Award, the Pulitzer, the Nobel. The author was Toni Morrison. The novel was The Bluest Eye.&lt;/p&gt;
    &lt;p&gt;The careers of many literary titans of the late-twentieth and early twenty-first centuries bear similar hallmarks: The disappointing debut. The stalwart editorial advocate. The understanding that, in order for a writer to truly break out, time is a meaningful factor. For every author whose first try strikes gold—like Philip Roth, whose debut won him the National Book Award at twenty-seven—there’s one like Morrison—or Cormac McCarthy, or Jack Kerouac, or 2025’s Pulitzer Prize–winning fiction writer Percival Everett—on whom a publisher had to take a second, or third, or fourth, or fifth chance. In 1993, reflecting on The Bluest Eye’s reception, Morrison noted its initial life had echoed that of its young Black protagonist, Pecola Breedlove: “dismissed, trivialized, [and] misread.” Nevertheless, the novel is now an essential part of a legacy that reshaped literature.&lt;/p&gt;
    &lt;p&gt;Nowadays, it might not get that opportunity. It’s true most debuts are not, aesthetically, The Bluest Eye. But nor are they as easily granted second chances after commercial disappointment. Instead, there is tremendous pressure to succeed from the beginning. If they fail, all bets are off, sometimes literally. Countless factors contribute to how well a book sells, and there are many points in that chain at which things can break down. If they do, much of the responsibility converges on the writer. That a publisher bet on them and lost means it will be harder to secure the next deal. No matter the reasons for the flop—a tiny marketing budget, staff turnover at the press, cutbacks in culture coverage, backlash toward a hot literary trend—the writer carries the failure on their record.&lt;/p&gt;
    &lt;p&gt;Sales track—or simply track, in industry parlance—is an invisible force shaping contemporary literature. Much depends on that number. On the basis of track, published authors struggle to keep going; those just starting out fear their careers will be severed at the root. Track shapes how an agent pitches a book and how editors assess whether to buy it. Track restricts reader choice by dictating which books are served up as the next big thing (and the next, and the next) and by kneecapping writers deemed insufficiently commercial. The primacy of track, in other words, is a barometer for the health of literary culture. Right now, when the industry is especially skittish, the obsession with finding the next blockbuster hit privileges the survival of the few at the expense of the many.&lt;/p&gt;
    &lt;p&gt;Track is like credit: it might be better to have none at all. When a writer has a book that’s ready to sell, their agent takes the manuscript or proposal out on submission by pitching it to editors. If an editor is interested, they will in turn pitch the project to their company for approval. One of the things that publishing teams look at, when evaluating a book for potential acquisition, is a writer’s past sales. Using tools like BookScan, the industry’s pricey software for tracking units sold, publishers gauge how a previous title fared and whether the author warrants further investment. (BookNet, the equivalent in Canada, is a nonprofit. The data provided by both is incomplete.)&lt;/p&gt;
    &lt;p&gt;Being trailed by one’s sales data gives first-time writers a certain advantage. Debuts are deeply attractive to publishers because, as writer and researcher Laura McGrath puts it, “there is nothing but potential. If your track is zero, there’s only one place for it to go.” The book’s advance is therefore set by anticipation—the publisher’s bid is roughly commensurate with how big they think they can break it out. They reach this number by assigning a value to what McGrath, who studies publishing analytics, calls “soft data”—a bouquet of assumptions about readership, authorship, markets, and genre. Those assumptions are then “turned into something that seems like it should have been arrived upon in a rigorous fashion,” she says, “but it’s not.” If enough bidders get ensorcelled by a project—or by the bloodlust of an auction—the price can be driven up into six or seven figures. The book business may be centred in New York, but the logic is pure Las Vegas.&lt;/p&gt;
    &lt;p&gt;“These books that have huge price tags are given impossible expectations to meet.”&lt;/p&gt;
    &lt;p&gt;If buying the debut is a rollicking night at the craps table, then the sophomore project is the sober morning after. Gone is the clean slate. What publishers really want to see, McGrath says, is growth. “More than any particular number, they’re looking to see a track that is always on the rise.” This is impossible to prove after only one book, especially a book that loses the publisher money. Which is to say: almost all of them. “Most books don’t sell well,” says Alia Hanna Habib, literary agent and author of the forthcoming Take It from Me, a career guide for non-fiction writers. (She counts McGrath among her clients.)&lt;/p&gt;
    &lt;p&gt;Because the majority of books don’t earn out, most people in publishing have the disappointing experience of working on a book they love that, for whatever reason, didn’t hit: “If you’re a fair person, you know it’s not the author’s fault. It’s just the realities of a very difficult market.” Habib won’t suddenly drop a client whose first book didn’t sell. At the same time, that track creates challenges for her. She must come up with a narrative to explain the failure and a case for how the next book might do better. Sometimes, the original publisher wants to move on, so she also has to find someone else willing to take a chance.&lt;/p&gt;
    &lt;p&gt;“When I get sent a project, one of the first things I’ll do is look at the track,” says an editor from an imprint at one of the Big Five presses—the largest, corporate-owned trade publishers: Penguin Random House, Simon &amp;amp; Schuster, HarperCollins, Hachette, and Macmillan—who asked to remain anonymous. Though he evaluates every submission on its merits, he must balance his enthusiasm with practical considerations. Track becomes either an asset to his case for acquiring a book or a hurdle he must overcome by crafting a compelling strategy to convince his team it’s still worth buying.&lt;/p&gt;
    &lt;p&gt;Bad track won’t stop him from considering a project, especially one he is passionate about. Instead, he weighs the factors that may have led to it—maybe the book’s editor was laid off and the author did not receive as much attention. He’ll even reach out to the agent to learn more about what happened. Those conversations can reveal subtler things about how a book was not well supported. Perhaps the publisher positioned it in a way the author disagreed with—a risk, he says, with projects that feature diverse protagonists or are written from a very specific perspective. “Publishers are very fallible,” he says. “Sometimes an author needs a fresh start.”&lt;/p&gt;
    &lt;p&gt;This is another quirk of track. Publishing’s habit of jumping on a trend, especially if that trend is identity based, can come down hard on writers who have been underrepresented in mainstream culture. It can even set them up for failure down the line. Habib cites the moment in 2020 when presses eagerly began acquiring books by Black authors. Many of those presses had never published Black authors in a meaningful way and lacked the infrastructure to properly support those books or help them find readers. “It becomes very easy for a publisher to say now, five years later, ‘Oh, we tried that, and it didn’t work,’” simply because their particular iteration of it didn’t, she says.&lt;/p&gt;
    &lt;p&gt;The other thing the Big Five editor considers when assessing track is the investment the prior book received. If it was put out by a small press and still sold 5,000 copies, that looks like the growth potential McGrath described—imagine what might happen with even more marketing muscle. Conversely, “if there’s someone who we all know was in a huge, million-dollar auction and the book sells 20,000 copies even though it was supposed to sell 100,000, then that’s a different consideration,” he says.&lt;/p&gt;
    &lt;p&gt;Such knowledge is highly piecemeal, even more so than the spotty sales data. Who we all know is more rumour than fact. Publishers don’t know exactly how much a book sold for. Neither the writer nor their agent has to disclose; in fact, it’s in their best interests not to, in case it backfires later.&lt;/p&gt;
    &lt;p&gt;There are the euphemisms used in deal announcements on the industry website Publishers Marketplace—a “very nice” deal connotes an advance in the mid to high five figures, a “good” deal signifies low six figures—or the trades might report on a high-profile auction. An author may also just be forthcoming, in the interest of equity, about how much they were paid, as when the 2020 hashtag #PublishingPaidMe revealed stark disparities in pay between white authors and authors of colour. But transparency at that scale is unusual. “Information about advances is so unreliable,” says McGrath. “When an advance gets published in Publishers Marketplace or Publishers Weekly, I don’t believe that for a second, because that’s all a way of generating excitement.”&lt;/p&gt;
    &lt;p&gt;But if publishers can’t verify a book’s purchase price, on what are they basing the decision that the track is bad? Bad relative to what, other than a general vibes-based sense of hype? There is no solid number that constitutes “good track,” Habib says, and what counts as good varies depending on the genre. In addition to evaluating track based on incomplete BookScan data, publishers are making decisions based on advance sizes they don’t have access to, maybe heard a rumour about, and in fairness to the writer probably shouldn’t be told at all.&lt;/p&gt;
    &lt;p&gt;What’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial.&lt;/p&gt;
    &lt;p&gt;Still, the stigma of overpaying persists. If a writer is the beneficiary of such conditional faith, and then the book’s performance fails to justify it, it’s the writer who bears the stain. “These books that have huge price tags are given impossible expectations to meet,” the editor says. “The fact that a book received a $1 million cheque versus a $50,000 cheque means it’s going to be very hard for their work to continue moving forward.”&lt;/p&gt;
    &lt;p&gt;Habib disagrees with the idea that a high advance automatically sets a writer up for failure. When she is able to get her clients a competitive debut advance, she prepares them for the possibility that it might be the most money they ever receive. “Don’t think of your debut advance as your rate,” she tells them. “Think about it as funding for this stage of your career.” It comes with perks they might get offered only once, like a big publicity budget. It’s a chance to launch a huge career. And for writers, especially those who don’t come from wealth, it is a life-changing amount of money.&lt;/p&gt;
    &lt;p&gt;Despite the careful narrative that an agent and an editor may weave, both separately and in tandem, whether a book gets bought or for how much is ultimately not their call. Even if the Big Five editor loves a project, he still needs to share it with his colleagues and pitch it at an editorial board meeting. If it passes that hurdle, he writes up a formal proposal. Past that, it’s out of his hands: “At the end of the day, the people I am beholden to can say no to just about anything.”&lt;/p&gt;
    &lt;p&gt;Like Habib, he acknowledges that this can be unfair. “The thing that is toughest about track is that it really has nothing to do at all with the author and the author’s work.” This is a vexed Catch-22—that track has nothing to do with the author and yet the author is the one over whose head it hangs. Many writers seem to feel the opposite: that track has everything to do with them.&lt;/p&gt;
    &lt;p&gt;“Due to the author’s previous book sales, this is a pass. . . . I’m afraid the low units will present challenges as our sales team presents to retailers and our marketing and publicity teams pitch [this writer] to media.”&lt;/p&gt;
    &lt;p&gt;This was an email sent to Jeanna Kadlec’s agent when her second book went out on submission to publishers. Her first book, Heretic—a memoir about leaving evangelical Christianity—was acquired by Houghton Mifflin Harcourt at auction for $150,000 (US), the highest offer she received. Almost a year later, HMH was bought by HarperCollins. While Kadlec’s editor stayed on, she suspects she was allocated fewer resources at HarperCollins than she would have been at HMH.&lt;/p&gt;
    &lt;p&gt;The difficulties mounted from there. First came a months-long HarperCollins strike. With it came reviewer boycotts. Readers, too, may have been boycotting the company’s books, even though this wasn’t something the striking employees called for. Once the workers got their deal, Kadlec asked for renewed promotional attention. But HarperCollins declined, seemingly writing off anything that came out during the strike as a loss. When she took her next project to the press, who had a right of first refusal, they passed.&lt;/p&gt;
    &lt;p&gt;It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers.&lt;/p&gt;
    &lt;p&gt;This sounds a bit like trying to buy new insurance for your car after it was totalled by your friend, the professional driver. The circumstances were obviously beyond Kadlec’s control. Still, when she tried to sell her sophomore project, a few editors, especially those at other HarperCollins imprints, explicitly cited her track as part of their rejection. Heretic has sold a few thousand copies—respectable for memoir but, when compared to her six-figure advance, which hints at higher commercial hopes, she admits, “not good math.”&lt;/p&gt;
    &lt;p&gt;These figures seem impossible to separate from the fact that, among other things, Kadlec’s publicist was marching on a picket line rather than continuing to pitch her book to media. (Kadlec, who speaks glowingly of the team assigned to her book, supported their strike demands and even marched alongside them.) But the feedback on submission didn’t seem to consider this. “We couldn’t really see a way to break out the new book,” said another reply, from a HarperCollins editor. “She might be better served with a fresh start in a new home.” Despite the track, Kadlec has managed to sell her next project, albeit at the much lower advance of $30,000 (US).&lt;/p&gt;
    &lt;p&gt;“I don’t know how people are supposed to develop in their careers,” says a novelist who also spoke on the condition of anonymity. She has published multiple books but, owing to editorial shuffles at her publishing houses, has had to take her books out on submission multiple times. “Every single time, the sales track becomes heavier.”&lt;/p&gt;
    &lt;p&gt;It’s frustrating that she alone is saddled with the track, given that a publisher plays just as big a role in a book’s fate, if not bigger. It’s as if they take a book over when they buy it, and then, if it misfires, renounce all responsibility. Like many authors, she feels abandoned by this logic. That writers shoulder the most risk when they have so much less power strikes her as unsustainable. We think of careers as things that progress linearly—the more skills and experience you have, the greater the salary, stability, and respect you can command. “But if you’ve got a mediocre sales track, that’s not the case. You’re lucky if you get a lower offer. You’re lucky if you get an offer at all.”&lt;/p&gt;
    &lt;p&gt;Online, certain tactics are suggested for how to “get over” the ailment of bad track—home remedies meant to replace the old curatives of editorial advocacy and time. A surprising number of sources suggest writing under a pseudonym. They can’t pin a bad track on you, the logic goes, if you take a different name. (Gotcha!) Habib seems unimpressed by this gambit. “It’s very hard to publish under a pseudonym,” she says. “The books that get the most promotion have an author to promote them. You can’t keep making up personae.” (“Or faking your own death,” I say, a tactic neither copped to nor suggested by anyone I spoke to.)&lt;/p&gt;
    &lt;p&gt;The suggestion to write in a new genre also comes up fairly often. This pre-empts the concerns about reaching a different, hopefully bigger audience—the genre will start to do that on its own. Switching genres is one way to mitigate a publisher’s concerns about track, the Big Five editor tells me, especially if the new project is markedly more commercial. This can also get hairy, in that it incentivizes bending one’s career to chase the market. It’s hard enough to keep financial pressures out of one’s creative process, especially under the gun of bad track; this advice doesn’t just let commerce in but puts it smack in the centre of one’s art.&lt;/p&gt;
    &lt;p&gt;Certainly, plenty of people write in multiple genres. But Habib cautions writers against pursuing forms they’re not interested in for the purpose of trying to sell books. As she correctly put it to me, a memoirist and essayist, “You’re in no position to write a great romantasy novel.” Kadlec and her agent tried a subtler genre shift. They hoped that switching from narrative to prescriptive nonfiction would count as enough of a fresh start; that hope wasn’t borne out. “A lot of the advice I hear for folks who do switch genres,” Kadlec says, “is they do a memoir and then they do a novel, and regardless of how the memoir did, the novel is considered a totally clean slate.”&lt;/p&gt;
    &lt;p&gt;This was the sequence Joseph Osmundson was hoping for—to sell a novel after his nonfiction book. His first release with a major press, Virology, is an essay collection that fuses science, queer writing, literary analysis, and memoir. Though his editor was eager to take a chance on the project, the publisher had low expectations. Norton bought it for a modest $15,000 (US), and in trade paperback rather than hardback, a cheaper format that also means the author gets a lower percentage of each sale in royalties counted against the advance.&lt;/p&gt;
    &lt;p&gt;Upon its release, Virology sold so well that Osmundson earned out his advance in three months—something most books never manage, let alone so quickly. According to industry rules, he was golden. A publisher had bet small on him and won big. He had a strong sales track, growth potential, and a proven audience. Fiction gave him the additional advantage of a clean slate even if he didn’t need one. But when his agent took his novel out on submission, the response he kept getting was the same: “We don’t see Joe having a platform or a pattern of fiction publications.”&lt;/p&gt;
    &lt;p&gt;Osmundson was frustrated. “I had been told: work my ass off on my first book, set up a solid track, and you’ll get a bigger advance next time,” only to discover it did not translate into anything for fiction. The novel was either rejected or offered an advance that was on par with his first. In the end, he sold the novel alongside a memoir, but the novel never made it to print. “Do I get tired of proving people wrong?” he asks. “Yes. It is exhausting to constantly feel like my work is undervalued.”&lt;/p&gt;
    &lt;p&gt;Despite widespread conversations in 2020 around equity in publishing, he believes we’re witnessing a general retrenchment in the industry. Decision makers are adopting an even more conservative stance, which steers them toward acquiring books from people who already have built-in audiences—like celebrities or influencers. Such retrenchment is also a labour issue. Publishing is an industry with stagnant salaries, considerable instability, and high turnover. “It’s hard to invest in authors when the people who are working on the books are not being invested in,” says the Big Five editor. He may not have the luxury of nurturing a writer across books, as much as he may want to. The more pressing issue can be, as he puts it, “I need to make a profit so I don’t get fired from this job.”&lt;/p&gt;
    &lt;p&gt;Many factors have likely contributed to this heightened risk aversion: corporate consolidation, a rapidly slimming media market, a volatile political climate. These are not favourable conditions for creative experimentation. While many people I spoke to agree that things feel particularly chilly at the moment, McGrath also takes the long view: “Publishing is always more conservative today than it was ten years ago,” she says. The industry has a habit of glancing back toward the rosy past. But one moment in particular, around 2001, marked a shift, when Nielsen BookScan (now Circana BookScan) first came on the market and began tracking sales. The current, pervasive sense of conservatism, McGrath says, has been exacerbated by the increased reliance on data to justify decisions. If you can put a number on the risk, maybe you think twice before taking it.&lt;/p&gt;
    &lt;p&gt;No matter the reason, what’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial. “I worry a lot about writers who are a decade behind me in their career,” Osmundson says. It was his hope that the success of Virology, despite the book not being obviously mainstream, would create space for more ambitious queer books—his own and others’. Instead, he says, “it feels like that space is actually getting smaller.”&lt;/p&gt;
    &lt;p&gt;When I ask Norm Nehmetallah, publisher of Ontario-based small press Invisible Publishing, about the effect of track’s primacy on literary culture, he sighs. Working at a small press, Nehmetallah and his team can adopt a mandate less beholden to the bottom line than those of the bigger conglomerates. Invisible, in particular, has an explicit focus on finding and nurturing emerging writers. To Nehmetallah, a successful book is less a number than a feeling that it has travelled beyond the expected networks, like the writers’ friends or a particular literary scene.&lt;/p&gt;
    &lt;p&gt;But Nehmetallah, who worked various jobs in the industry before becoming a publisher, has seen the hunger for good track touch his work in various ways—including, oddly, his current role. More and more, he says, his press and others of similar size have been getting submissions from writers who have been dropped from bigger houses, like the imprints of Penguin Random House Canada (one of which is my current publisher). There may be less loyalty there, he says. “I think, in a lot of ways, they are more willing to take on debut authors, and I think that may be coming at the expense of what we would have called their ‘mid-list authors.’”&lt;/p&gt;
    &lt;p&gt;This mid-list cohort is exerting a downward pressure on the publishing landscape. By seeking support at smaller presses, they risk filling the spaces meant for more experimental or early-career authors. This isn’t just bad for writers—it’s bad for literature. If people aren’t given chances to grow and explore in ways the market doesn’t recognize, Nehmetallah says, then readers lose out too. Toronto-based writer Jean Marc Ah-Sen, who has published several books with small and independent presses, feels that he and his peers are being crowded out of their own game. “I used to think that the frontier of literary culture was the indie presses,” he says. “But when a person who has done three books with Penguin gets pushed down, it makes less room for the people who were doing the independent stuff to begin with.” Publishers, as McGrath says, have always been risk averse. But with higher pressure to find a sure thing, more writers who may have been able to sell a book five or ten years ago, whether to a corporate or an independent press, are being left out in the cold.&lt;/p&gt;
    &lt;p&gt;Such retrenchment has come alongside a shrunken and fragmented media industry, in which the shuttering of culture outlets and the decentralization of social media has created a different kind of missing middle: an arid landscape of coverage that’s no longer bustling enough to put a wide range of books on readers’ radars.&lt;lb/&gt; Consumers, too, have a role to play here. As Habib points out, track is also built by the people who buy books, or are supposed to. Nehmetallah makes a similar argument. It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers, he says. This would help literary culture across the board. But it’s a two-way street. By shutting down writers’ chances to build audiences and careers, and restricting the range of what makes it to bookshelves—by spoon-feeding with so much aggression that it can take a lot of effort to close your mouth and turn away to find alternatives—publishers are jeopardizing that ecosystem too.&lt;/p&gt;
    &lt;p&gt;“The literary culture that supports a community of reading and that supports the word-of-mouth spreading is really diminishing,” Kadlec says. “Publishers could be doing so much more than they are actually doing to uplift it. You know,” she says to me. She then names one of my former employers, a company that shuttered its in-house magazine—which sometimes functioned as a built-in arm for promoting the books that it published, as well as a proven space to incubate reputations and platforms.&lt;/p&gt;
    &lt;p&gt;I’ve come to expect this moment of citation, even dread it—to be borne back ceaselessly into this past. But Kadlec is right, I do know. For the past three years since that magazine was shut down, I have seen the writers of my generation lament the loss of that particular launching pad for their essays, their book promotion, their careers. I have seen their debut books get only a handful of reviews in trade magazines. I have seen their publishers decide not to reissue their books in paperback because they didn’t sell “enough” copies. I have also seen my new email address added onto my former employer’s publicity list, asking me to cover their books.&lt;/p&gt;
    &lt;p&gt;Three years after its closure, the magazine’s absence is still felt across the spectrum of publishing. Without spaces like it—in which writers have the opportunity to build an audience prior to selling a book, and publishing workers have a place to secure promotional coverage in a way that actually gets that book out to readers—the infrastructure required to build a decent track erodes into nothing. During those same three years, I’ve watched as the story of that magazine’s shutdown has been reported as if it were purely an outcome of the funding model rather than the choices of its parent company, a publishing house that decided to prioritize profit no differently from how book publishers do every day.&lt;/p&gt;
    &lt;p&gt;The publication’s closure is, in the end, a parable about the whims of capital, albeit not in the way people seem to think. It’s true that publishing professionals hate this state of affairs just as much as writers do. I believe that even more so now than I did before I started working on this piece. But it’s also true that the assault on literary culture that has shattered the avenues for book coverage and ratcheted up the impossible standards by which authors must be rapidly, conclusively adjudged a success or doomed to career failure is not simply a frame being forced on the industry from without. It’s also being perpetuated from within by those who claim to love literature. Trace the call and you’ll find it’s coming from—where else—inside the house.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507236</guid><pubDate>Tue, 07 Oct 2025 18:55:36 +0000</pubDate></item><item><title>Eliminating contrails from flying could be incredibly cheap</title><link>https://www.sustainabilitybynumbers.com/p/eliminating-contrails</link><description>&lt;doc fingerprint="774ec8726186b74b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eliminating contrails from flying could be incredibly cheap&lt;/head&gt;
    &lt;head rend="h3"&gt;Could we halve aviation's climate impact at a fraction of the cost of sustainable aviation fuels?&lt;/head&gt;
    &lt;p&gt;Eliminating CO2 emissions from flying is going to be expensive, regardless of the solution the world adopts.1&lt;/p&gt;
    &lt;p&gt;But aviation also contributes to global warming through its non-CO2 effects. Those are mostly “contrails”, which I’ll explain in more detail soon. Getting rid of those could be incredibly cheap. So cheap that it’s difficult to understand why we don’t just go ahead and fix it.&lt;/p&gt;
    &lt;p&gt;On a recent podcast, I spoke to Ian McKay, CEO of Orca Sciences, about this. One of their portfolio projects is Contrails.org. Their solution to eliminating contrails is to accurately forecast and model the atmospheric conditions that generate them, and reroute planes so that they avoid these “contrail-forming” parts of the atmosphere.&lt;/p&gt;
    &lt;p&gt;This is a solution that I hadn’t really paid much attention to, and most people are unaware of. So I thought I’d do a deep dive on contrails; explore how this solution might work; and whether it’s really that cheap.&lt;/p&gt;
    &lt;p&gt;To pre-empt the critics: this solution does not mean the aviation industry can ignore the CO2 impacts of flying. Tackling contrails would not absolve them of responsibility for finding low-carbon alternatives to jet fuel. It’s not a substitute, but an addition. Currently, their non-CO2 impacts are not measured or reported, so bringing more attention to contrails means they’re taking full responsibility for their climate impact, which is not the case at the moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are contrails?&lt;/head&gt;
    &lt;p&gt;When you see a plane in the sky, you might see a small, white cloud-like trail behind it. Those are contrails (short for “condensation trails”).&lt;/p&gt;
    &lt;p&gt;Water vapour, soot and other particles (basically pollutants) are emitted from the back of jet engines. Water droplets can condense around these particles, and because it’s pretty cold up there, they can freeze to form ice crystals. Sometimes these white lines are very faint and hard to see. But in some cases, they can form “cirrus clouds”: wispy ones that form at high altitudes.&lt;/p&gt;
    &lt;p&gt;These contrails can have both cooling and warming impacts. I’ve sketched this out in the schematic below.&lt;/p&gt;
    &lt;p&gt;Some sunlight can reflect off of them, rather than passing through to the surface, which has a cooling effect.&lt;/p&gt;
    &lt;p&gt;Most sunlight, though, does pass through, and outgoing irradiation then gets trapped by the cirrus clouds. This has a warming effect, which tends to be larger than the cooling one, so on net, contrails cause warming.&lt;/p&gt;
    &lt;p&gt;Since someone asked about this over email: the fact that there is no sunlight at night, and less during winter, there is less to “reflect” off the top of cirrus clouds. That means the cooling effect is weaker at night, and in winter, and the net warming effect stronger. This means avoiding contrails in winter and at night has an even stronger impact on reducing warming.2&lt;/p&gt;
    &lt;head rend="h2"&gt;What impact do they have on global warming?&lt;/head&gt;
    &lt;p&gt;It’s common to want to compare them to CO2 emissions, but it’s first worth emphasising how different the contributions are in terms of intensity and persistence.&lt;/p&gt;
    &lt;p&gt;Contrails have a strong “effective radiative forcing” effect. This basically measures the net change in energy flow at the top of the atmosphere: and that change in energy flow dictates how much warming is needed at the surface to offset it. But, this warming effective is very short-lived. If we were to stop contrails today, the warming effect would disappear within a day or so.&lt;/p&gt;
    &lt;p&gt;Think of it like a very brief but strong pulse of energy.&lt;/p&gt;
    &lt;p&gt;CO2, on the other hand, has a smaller effect on radiative forcing, but once you emit it, it stays there for centuries or more.&lt;/p&gt;
    &lt;p&gt;I thought this diagram from Contrails.org makes this point clearly. This article by them explains the comparison in much more detail.&lt;/p&gt;
    &lt;p&gt;When we think about the climate impacts of aviation, then, most of the warming from CO2 emissions is not due to the emissions this year, but the cumulative effect (which persists) over the past 70 years. But for contrails, the warming impact is only really from those created very recently (hours to days); the small temperature response decays over months to a few years.&lt;/p&gt;
    &lt;p&gt;You might have heard people say that “more than half of the warming caused by aviation comes from non-CO2 sources”. A big part of that is contrails. But this does not mean that for any given flight, half of the warming is coming from contrails and the other half from burning jet fuel.&lt;/p&gt;
    &lt;p&gt;This apparent ‘half-half’ balance is a coincidence of timing: the cumulative CO₂ effect built up over decades happens to be of similar order to the instantaneous contrail effect for that year. In the chart below you can see the effective radiative forcing caused by CO2 and contrails in 2019. Again, the CO2 emitted in 2019 is just a small part of the warming. Most of comes from emissions built over decades, that stay there. It just so happens that this cumulative amount of warming is not that different from the instantaneous, short-lived impact of contrails in 2019. Eventually more and more CO2 emissions will accumulate, and the share coming from contrails will shrink in relative terms.&lt;/p&gt;
    &lt;p&gt;But as it stands today, we could get rid of around half of the warming impact — maybe slightly less — from aviation, if we were to tackle contrails. The impact would be almost immediate.&lt;/p&gt;
    &lt;p&gt;How, then, do contrails stack up in terms of total warming? They contribute roughly 2% to the world’s effective radiative forcing; tackling them would reduce that by a similar amount.3&lt;/p&gt;
    &lt;p&gt;What this comparison should make extremely clear is that reducing contrails does not mean we don’t also need to tackle CO2 emissions from aviation. Ultimately that is the persistent driver of long-term temperature change. What tackling contrails now would do is slightly reduce the rate of warming (and therefore do something reduce the risks of nearer-term feedbacks that could affect the release of CO2 from natural systems, and also affect long-term temperature change). It is not an excuse or a substitute for finding a way to decarbonise jet fuel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Only a few percent of flights cause most of the warming&lt;/head&gt;
    &lt;p&gt;One crucial reason why eliminating contrails could be so cost-effective is that a very small percentage of flights create the majority of the impact. This means we don’t need to divert or shift the trajectory of all the world’s flights; only a few percent of them.&lt;/p&gt;
    &lt;p&gt;In the chart below, you can see the breakdown of the warming effect across the world’s flights.4 On the left-hand side, we have the share of flights, and on the right, their collective contribution to the total warming impact of contrails.&lt;/p&gt;
    &lt;p&gt;Just 3% of flights generate 80% of the warming. A further 14% generate 29%.&lt;/p&gt;
    &lt;p&gt;You might notice that this sums to 109%. But this is because some flights generate a cooling effect of 9%. Put them together and we get 100%.&lt;/p&gt;
    &lt;p&gt;Most flights — three-quarters of them — barely generate contrails at all and cause no warming or cooling.&lt;/p&gt;
    &lt;p&gt;Some sources cite slightly different numbers for this “80% warming effect”. For example, Contrails.org cite 5% of flights. I’ve seen others quote 2%.5 But the point remains the same: a few percent of the flights completely dominate the climate impact.&lt;/p&gt;
    &lt;head rend="h2"&gt;There are ways to dramatically reduce them&lt;/head&gt;
    &lt;p&gt;So, how can we get rid of these contrails?&lt;/p&gt;
    &lt;p&gt;Contrails with a strong warming impact mostly form in thin regions of the atmosphere, which are cold and humid. If planes fly through these zones of atmosphere, contrails are much more likely to form.&lt;/p&gt;
    &lt;p&gt;The solution, then, is for some planes to take a short detour to avoid them. You can see this in the schematic below.&lt;/p&gt;
    &lt;p&gt;How would we know which planes to re-route and by how much?&lt;/p&gt;
    &lt;p&gt;Using detailed weather forecasts, satellite images, and flight plans, scientists can identify where these zones will be far in advance and work with flight planners to find a way to reroute flights crossing these zones to avoid them. These forecasts and models are what Contrails.org do.&lt;/p&gt;
    &lt;p&gt;Google also launched “Project Contrails” which uses Artificial Intelligence (AI) to build models that can do this.&lt;/p&gt;
    &lt;p&gt;Of course, this wouldn’t work if these planes had to do a severe detour. People would not be happy about a longer flight time. And, the extra fuel that would need to be burned to go the extra distance would eventually cancel out the climate benefits from getting rid of the contrails.&lt;/p&gt;
    &lt;p&gt;The proposed detours typically result in a 1% shift (and again, this is only for a small percentage of flights). That means increasing fuel use and flight time by around 1%. So if your flight is three hours long, it’s only adding an extra two minutes. For a 10-hour flight, six minutes. This seems socially acceptable to me; most people would barely notice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stopping warming from contrails could be incredibly cheap&lt;/head&gt;
    &lt;p&gt;The fact that the warming impact is skewed towards such a small share of flights dramatically reduces the costs.&lt;/p&gt;
    &lt;p&gt;What are the costs associated with implementing this?&lt;/p&gt;
    &lt;p&gt;There are operational costs associated with weather prediction, modelling, and integration into flight planning. Especially with the integration of AI, this is probably not that expensive. A bit more costly is the extra jet fuel that’s needed for rerouted planes.&lt;/p&gt;
    &lt;p&gt;When I spoke with Ian McKay, he suggested the additional cost would be around $5 per flight. I think he meant this as $5 spread across the entire flight (not per passenger). This is also the figure they give on Contrails.org.6 I also think that in this assumption, the costs are spread evenly across the entire airline fleet (regardless of whether they’re rerouted or not). For the small share of rerouted flights alone, the “per flight” cost would be higher.&lt;/p&gt;
    &lt;p&gt;That’s incredibly low. Spreading that over 100 passengers, and each is paying just 5 cents extra.&lt;/p&gt;
    &lt;p&gt;Other studies have reported higher costs, although they’re still incredibly cheap.&lt;/p&gt;
    &lt;p&gt;This paper modelled over 84,000 flights and found that the additional cost of operations and fuel burn for rerouting increased costs by around $1.1 million.7 By my calculations, that’s around $10 to $15 per flight.&lt;/p&gt;
    &lt;p&gt;We can do a very basic back-of-the-envelope calculation to sense-check this. The total fuel cost of flying from Barcelona to Berlin is probably around $2,000.8 If the flight burned 1% extra fuel due to rerouting, the extra cost for the flight would be around $20. Add the operational costs of the forecasting, and this could be $30 to $40. Then spread across all flights, not just the rerouted ones, and this falls back down to the $5 to $10 range again.&lt;/p&gt;
    &lt;p&gt;Transport &amp;amp; Environment (T&amp;amp;E) estimates that the cost could range from $2 to $5 per passenger (or hundreds of dollars per flight).9 They do note that they make very conservative assumptions, and therefore find costs that are 3 to 10 times higher than those from other sources.&lt;/p&gt;
    &lt;p&gt;For a flight in Europe, such as from Barcelona to Berlin, the cost would be €1.20 ($1.88) per passenger. A Transatlantic ticket would be more expensive, around €3.90 for a trip from Paris to New York. Given that an economy ticket from Paris to New York probably costs around €350 to €400, this would increase the cost by around 1%.&lt;/p&gt;
    &lt;p&gt;Perhaps, then, the best estimate is somewhere in the middle: around 50 cents per passenger.&lt;/p&gt;
    &lt;p&gt;Translating this into the cost per tonne of carbon dioxide equivalent — the “carbon abatement” cost — shows how cheap this is compared to many other climate solutions. It’s probably in the range of a few dollars per tonne CO2e. Contrails.org estimates that it’s slightly below $1 per tonne.&lt;/p&gt;
    &lt;p&gt;Switching to “sustainable aviation fuel” currently has an estimated cost in the range of hundreds of dollars per tonne of CO2e avoided.10 Rather than a flight ticket being 1% more expensive, it would be more than double the price. Eliminating contrails is therefore hundreds of times cheaper and can be scaled much more quickly than replacing the entire aircraft fleet or its fuel source.11&lt;/p&gt;
    &lt;head rend="h2"&gt;Why aren’t we doing more to eliminate contrails?&lt;/head&gt;
    &lt;p&gt;When I asked Ian McKay why airlines were not doing more, he gave two main reasons.&lt;/p&gt;
    &lt;p&gt;The first is that even if the cost per flight is low, the total cost across their entire fleet adds up. Let’s take a quick example for British Airways. They operate around 300,000 flights per year. If we reroute 2% of those to avoid contrails, and rerouting increases fuel burn by around 2% (I’m being deliberately harsh here), then I estimate that the additional fuel costs are in the range of $1.2 to $2 million per year.12 Let’s say that the operational costs of forecasting and modelling adds another 50%. That takes us to around $2.5 to $3 million.&lt;/p&gt;
    &lt;p&gt;In 2024, British Airways had an operating profit of around $2.7 billion. Contrail avoidance would therefore be just 0.1% of its operating profits.&lt;/p&gt;
    &lt;p&gt;But I’m not convinced that this cost factor is the main reason. They could pass this cost on to consumers; flight prices vary by a lot more than a few dollars for a variety of factors. They could either make a huge deal of the fact that they’re dramatically cutting their climate impact, and get “PR” buy-in from consumers for that. Or they could keep quiet, and most consumers would never notice the difference in cost.&lt;/p&gt;
    &lt;p&gt;The second — which seems more likely — is that, currently, most people are unaware of the climate impact of contrails. In that sense, airlines can basically ignore it and pretend they don’t exist. By trying to tackle them, they’d only draw more attention. People would then be aware that the climate impact of aviation is even higher than they thought.&lt;/p&gt;
    &lt;p&gt;I still think that the airline that steps up and commits to eliminating contrails — possibly even claiming to have halved its climate impact — would be well-received by many customers. I would see it as reputational gain, rather than a risk.&lt;/p&gt;
    &lt;p&gt;Nonetheless, there are no signs that the aviation industry itself is going to step up. This is where government policy could step in.&lt;/p&gt;
    &lt;p&gt;Rather than an airline leading by example, a country or region could. In a more pro-climate political environment, the United States could have led this effort domestically, mandating that internal flights eliminate their contrails. More likely is the European Union. It has already been making some progress in this direction — not by mandating that airlines pay for contrail avoidance — but by simply reporting these climate impacts in the first place. Earlier this year, its trading system regulations were updated to require airlines to monitor and report non-CO2 impacts. That sounds basic, but it is not the standard across most of the world; these impacts are usually not included. Unsurprisingly, it has received pushback from the aviation industry, with them asking for these reports to be voluntary.&lt;/p&gt;
    &lt;p&gt;Progress will undoubtedly be met with initial resistance, but I still think that regulatory policy seems like the most likely path to widespread implementation.&lt;/p&gt;
    &lt;p&gt;What would help a lot is increasing public awareness of the existence of contrails, their climate impacts, and how inexpensive it could be to eliminate them. There is a general understanding that decarbonising aviation is expensive, and this often means the aviation industry gets more of a free ride. But this is based on replacing jet fuel. If people were aware that it could cut a huge chunk of its footprint at a fraction of the cost, they might be more demanding.&lt;/p&gt;
    &lt;p&gt;Eliminating a few percent of the world’s warming is a big deal when the costs are so small. It seems insane to me that such a cheap solution is sitting there, completely untapped.&lt;/p&gt;
    &lt;p&gt;This could be substituting jet fuel for an alternative such as green hydrogen or biofuels.&lt;lb/&gt;But some suggest that it could be cheaper to keep burning jet fuel and try to capture — and securely store — an equivalent amount of CO2 directly.&lt;/p&gt;
    &lt;p&gt;Their question went further, asking if having some additional warming in winter is actually beneficial as it reduces risks such as cold-related deaths.&lt;lb/&gt;This could be true if the impacts were local. However, the warming that results is both global, and lasts over the long-term (even if the immediate forcing is short-lived, as we’ll come on to).&lt;/p&gt;
    &lt;p&gt;Lee, D. S., Fahey, D. W., Skowron, A., Allen, M. R., Burkhardt, U., Chen, Q., ... &amp;amp; Wilcox, L. J. (2021). The contribution of global aviation to anthropogenic climate forcing for 2000 to 2018. Atmospheric Environment.&lt;/p&gt;
    &lt;p&gt;This is based on data published in the Transport and Environment (T&amp;amp;E) 2024 Report: Contrail avoidance: aviation’s climate opportunity of the decade.&lt;/p&gt;
    &lt;p&gt;Teoh, R., Engberg, Z., Schumann, U., Voigt, C., Shapiro, M., Rohs, S., &amp;amp; Stettler, M. E. (2024). Global aviation contrail climate effects from 2019 to 2021. Atmospheric Chemistry and Physics.&lt;/p&gt;
    &lt;p&gt;Here they say:&lt;lb/&gt;“Better yet, properly implemented, contrail management is low-cost: studies show a fleet-average fuel cost of roughly $5.00 per flight, or less than $1 per tonne of CO2 equivalent warming avoided.”&lt;/p&gt;
    &lt;p&gt;Agarwal, A., Meijer, V. R., Eastham, S. D., Speth, R. L., &amp;amp; Barrett, S. R. (2022). Reanalysis-driven simulations may overestimate persistent contrail formation by 100%–250%. Environmental Research Letters.&lt;/p&gt;
    &lt;p&gt;This assumes burning around 3,000 litres of fuel, weighing around 2.5 tonnes.&lt;lb/&gt;The cost per tonne is around $900.&lt;lb/&gt;That gives a total cost of around $2250.&lt;/p&gt;
    &lt;p&gt;Again, these costs are distributed across all flights, not just those that are rerouted.&lt;/p&gt;
    &lt;p&gt;Watson, M. J., Machado, P. G., Da Silva, A. V., Saltar, Y., Ribeiro, C. O., Nascimento, C. A. O. D., &amp;amp; Dowling, A. W. (2024). Sustainable aviation fuel technologies, costs, emissions, policies, and markets: A critical review. Journal of Cleaner Production.&lt;/p&gt;
    &lt;p&gt;Here’s an ugly, but useful graph from the UK Government’s cost-benefit report on SAFs.&lt;/p&gt;
    &lt;p&gt;This is based on fuel costs ranging from $600 to $1000 per tonne.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507398</guid><pubDate>Tue, 07 Oct 2025 19:07:07 +0000</pubDate></item><item><title>Banning controversy reveals Bluesky's decentralized aspiration isn't reality</title><link>https://plus.flux.community/p/banning-controversy-reveals-blueskys</link><description>&lt;doc fingerprint="bc98df1bb92e86dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Banning controversy reveals Bluesky’s decentralized aspiration isn’t reality&lt;/head&gt;
    &lt;head rend="h3"&gt;Bluesky’s protocol is so complicated that not even the biggest alternative network has figured out how to become independent&lt;/head&gt;
    &lt;p&gt;When it launched in 2023 in private beta, Bluesky was pitched as a different kind of social network, one that placed openness and user-friendliness at its core. It came along at just the right moment as Elon Musk’s purchase and takeover of Twitter led millions of users head toward any type of exit.&lt;/p&gt;
    &lt;p&gt;The initial destination for many was Mastodon, but its Linux geek ethos and system of numerous “federated” servers that communicate via the open-source ActivityPub protocol proved to be too complicated for people who just wanted to crack jokes. Acting on the opportunity, Bluesky opened up to the public in February 2024 and saw a rapid influx of users.&lt;/p&gt;
    &lt;p&gt;Besides being easier to sign up and use than Mastodon, Bluesky offered a different approach to content moderation that was more flexible and user-driven. In addition to making its software source code available under open licenses, Bluesky wanted to put moderation decisions in the hands of its users, encouraging them to make lists of accounts that could be automatically blocked or labeled—and thereby removing itself as much as possible from moderation decisions that have plagued discussion group administrators since the days of Usenet newsgroups.&lt;/p&gt;
    &lt;p&gt;Millions of people flooded in after Bluesky opened its doors to the public. By November of 2024, there were nearly 1.5 million daily posters, most of them anti-Musk Twitter refugees who were eager to get away from Musk’s right-wing makeover of the site into X.&lt;/p&gt;
    &lt;p&gt;However, as time has gone by, Bluesky’s traffic has declined (X’s has as well) and some of its users have become increasingly upset at its moderation decisions, including allowing U.S. Vice President J.D. Vance and anti-trans writer Jesse Singal to remain as users of the platform. Singal became a particular target, prompting a petition with more than 28,000 signatures urging Bluesky to “enforce its Community Guidelines” against him that has not been successful, although he has been temporarily banned.&lt;/p&gt;
    &lt;p&gt;Accusations of indifference to anti-trans bigotry seem to have exacerbated some users’ frustrations with the platform for its alleged tolerance of racist content. In 2023, many launched a “posting strike” after they discovered that Bluesky allowed people to sign up for user names containing racial slurs, a policy the company quickly reversed and apologized for.&lt;/p&gt;
    &lt;p&gt;The labeling feature of Bluesky has been more positively regarded, with many people subscribing to lists to label or block Trump supporters, Singal, and other widely disliked journalists. But things have not been perfect. Several users have complained about being added to libelously named lists, while others have complained that stalkers have added them to numerous lists out of revenge. Trying to balance concerns between legitimate blocklist maintainers and victims of false accusations, Bluesky unveiled a series of changes to its terms of service which brought it more in line with other social platforms, but also sparked controversy because now users can get blocklists hidden by reporting on them.&lt;/p&gt;
    &lt;p&gt;The failure of the Singal ban effort has also continued to grate on Bluesky’s most persistent critics, and the site’s executives have been met with many critical and often off-topic replies and quote posts.&lt;/p&gt;
    &lt;p&gt;While Bluesky has been navigating user concerns, its engineering team has been moving ahead with its long-promised open source efforts, breaking up its software stack into several pieces to enable a federated Authenticated Transfer Protocol (ATProto) network where anyone with the know-how and funds could run their own copy of Bluesky.&lt;/p&gt;
    &lt;p&gt;There are several key pieces of code that combine to make the Bluesky network function: A personal data server (PDS) which hosts the official/canonical copies of its users’ posts and profile information. Whenever it’s updated, the data is combined and sent to a Relay server, which combines and indexes posts from many different PDSes to create what social networks call the “firehose,” the collection of all posts made on the network.&lt;/p&gt;
    &lt;p&gt;The firehose data is imported by a labeler program which categorizes it in various ways set up by users, the processed data is combined together by an application server (or AppViews as they’re called for now in Bluesky). When a user logs into their PDS and pushes “refresh,” their local app connects to the PDS’s designated feed generator which serves up a cached version of the accounts they follow.&lt;/p&gt;
    &lt;p&gt;While the ATProto system has been criticized as overly complicated compared to the ActivityPub system that powers the Fediverse, it has one key feature that ActivityPub lacks: the ability to transfer servers while keeping all of your followers and posts.&lt;/p&gt;
    &lt;p&gt;Due to the complexity of the Bluesky software stack, whether its federation model actually works in practice has not really been put to the test. While ActivityPub has several instances with millions of users (like Facebook Threads, Flipboard, and even Donald Trump’s Truth Social), it also has many much smaller ones run by small organizations and individuals.&lt;/p&gt;
    &lt;p&gt;As of this writing, however, the only completely independent implementation of ATProto is Bluesky. But that isn’t for want of trying on the part of Rudy Fraser, the creator of Blacksky, an alternative service that he unveiled in May of 2023 in response to Black American users’ complaints about Bluesky’s moderation policies.&lt;/p&gt;
    &lt;p&gt;Despite Fraser’s efforts to implement his own PDS, Relay, and App View, however, Blacksky still remains partially dependent upon Bluesky’s application server, largely because while the code to implement the dataplane of posts and users within an application server is released, the open-source version is slower. As a result, Blacksky is dependent on Bluesky’s application server to give users a fast experience, which also means that it is dependent on Bluesky’s labeling system and its moderation choices.&lt;/p&gt;
    &lt;p&gt;Blacksky’s continued dependency on Bluesky came into focus on Sunday after a Blacksky user going by the handle “Link” suddenly found himself unable to view his own posts on the alternative site.&lt;/p&gt;
    &lt;p&gt;“My account was taken down without any explanation for almost a full day,” Link told me in a Signal message, showing me a screenshot indicating that he had been banned even as his Blacksky account remained capable of viewing others’ posts and changing preferences. Unbeknownst to him, Link’s account had been banned by Bluesky’s moderators and this meant that even though he was in good standing at Blacksky, no one there, including himself, was able to read his posts. (They are visible within the ATProto firehose feed, however, as several sharp-eyed users soon discovered.)&lt;/p&gt;
    &lt;p&gt;Link’s banning came at a very bad moment for Bluesky, just weeks after it had banned or suspended several users following the Sept. 10 murder of far-right activist Charlie Kirk, which many Republican officials have sought to use as a tool for government censorship.&lt;/p&gt;
    &lt;p&gt;Federal Communications Commission Brendan Carr’s threats against late night comedian Jimmy Kimmel led to his temporary suspension by ABC, and he was far from the only Republican to issue them. Louisiana Rep. Clay Higgins, chair of the House subcommittee on federal law enforcement, sent a menacing letter to Bluesky and other social media networks demanding that they identify and ban anyone deemed to be celebrating Kirk’s killing.&lt;/p&gt;
    &lt;p&gt;“The authors of these posts are to be identified and banned from your platform, as well as any new pages they may create,” he wrote. “The reasonable restriction of public statements that lie far beyond the standards of our own society is not an oppression of free speech, it is, rather, the protection of free speech.”&lt;/p&gt;
    &lt;p&gt;There’s no proof that Higgins’s threats against social media platforms led to Bluesky banning anyone, but in any case, more than a few users were permanently or temporarily banned for mocking Kirk’s death, including horror author Gretchen Felker-Martin.&lt;/p&gt;
    &lt;p&gt;The fallout from the Kirk controversies and the months of replies seems to have irked Bluesky CEO Jay Graber, and she began pushing back on the user complaints. On Oct. 1, she approvingly quoted a user who had referenced the famous pancakes-waffle Twitter meme about how liking pancakes doesn’t mean disliking waffles, adding: “Too real. We’re going to try to fix this. Social media doesn’t have to be this way.”&lt;/p&gt;
    &lt;p&gt;Graber’s post was soon met by a reply asking if she’d banned Singal yet, prompting her to respond in all-caps: “WAFFLES.”&lt;/p&gt;
    &lt;p&gt;The next day, Thursday, Graber returned to her theme, posting a photograph of a berry-covered waffle, accompanied with the caption: “Amazing breakfast this morning. I love waffles.”&lt;/p&gt;
    &lt;p&gt;As might be expected, Graber’s trolling was not taken well by her critics. The waffles post received more than 1,700 replies, including many mocking her as a Musk-like figure.&lt;/p&gt;
    &lt;p&gt;On Friday, Graber turned more serious in her pushback: “Harassing the mods into banning someone has never worked. And harassing people in general has never changed their minds,” she wrote, adding later that: “Yet it’s a behavior that persists across social media anyway, with negative consequences for civil discourse and society. Human nature is a contributing factor, but systems that reward outrage only make the problem worse.”&lt;/p&gt;
    &lt;p&gt;Among the more than 100 people who quoted Graber’s post that day was Link. He posted a photo of Kirk which he accompanied with descriptive text that read: “Charlie Kirk sitting in a white T-shirt that says freedom. A negative consequence follows.”&lt;/p&gt;
    &lt;p&gt;Link made a number of other posts after to that one, but on Sunday his Blacksky account stopped working. After receiving no contact from either Blacksky or Bluesky, Link messaged Bluesky’s moderation team and received an email about 3 hours later saying that he had violated the social network’s community guidelines in his quote of Graber days earlier, presumably its policies against “threats or encouragement of violence.”&lt;/p&gt;
    &lt;p&gt;That is not how Link sees his post.&lt;/p&gt;
    &lt;p&gt;“I want to be extremely clear I was not making a death threat or inciting violence,” he told me, saying that he had sent 12 separate examples of other people posting the same Kirk image as a reaction meme. “I don’t wish death on Jay, I wish for her and her team to grow a conscience. I disagree with the decision and how it was handled. My account was taken down without any explanation for almost a full day in what can only be viewed as a retroactive ban.”&lt;/p&gt;
    &lt;p&gt;I’ve asked Bluesky whether the post had been reported as a violation by other users. I will update this story if I receive a response. Rudy Fraser, the Blacksky administrator has not responded to a request for comment.&lt;/p&gt;
    &lt;p&gt;Asked about why Link had to contact Bluesky to find out what had happened to his account rather than receiving a notice, Paul Frazee, the service’s CTO, said that it was “unfortunate,” and that Bluesky needed to finish adding a feature to let users of external PDSes know if they have been banned by Bluesky labelers.&lt;/p&gt;
    &lt;p&gt;Agree or disagree on whether Bluesky has treated Link fairly, the incident has exposed that the social network’s decentralization plans have yet to be fulfilled. Blacksky seems to be the furthest-along alternative ATProto implementation, but it’s still dependent on Bluesky. There’s another one called Northsky Social, but it has not launched any services yet. And while there are several alternative AppViews such as Deer.social, there does not seem to be any service (or combination of services) that can function as a full-stack implementation of ATProto.&lt;/p&gt;
    &lt;p&gt;This might explain why, despite having a network of nearly 40 million users, no situation like Link’s banning seems to have happened during Bluesky’s very short lifespan.&lt;/p&gt;
    &lt;p&gt;The episode has sent more than a few Bluesky users to start wondering whether the snow-covered grass on Mastodon’s side of the road is worth considering.&lt;/p&gt;
    &lt;p&gt;But not everyone is looking forward to the idea: “I’d go back to Usenet before I went back to Mastodon,” wrote Bluesky user Count Von Horse Knuckler. “I do not need people yelling at me for not putting cat pictures behind trigger warnings or unwanted Linux advice.”&lt;/p&gt;
    &lt;p&gt;Help may be on the horizon, however. As developers are becoming more aware of the power of ATProto, they are building increasingly complex projects on it, including a promising service called Slices, which aims to make it easy to build and deploy custom AppViews, a feature Blacksky and other Bluesky alternatives could certainly use. Bluesky execs have said they are working hard to make federation easier.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Link is caught in limbo.&lt;/p&gt;
    &lt;p&gt;“Now my account is not viewable on either Blacksky or Bluesky,” he notes. “I’m fortunate that I moved over to Blacksky and I think that is the only reason I still have access to my account and data…Bluesky claims to want decentralization and composable moderation, but they still enjoy abusing the power of arbitrary banishment.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507880</guid><pubDate>Tue, 07 Oct 2025 19:44:00 +0000</pubDate></item><item><title>Gemini 2.5 Computer Use model</title><link>https://blog.google/technology/google-deepmind/gemini-computer-use-model/</link><description>&lt;doc fingerprint="b97269db1c538405"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing the Gemini 2.5 Computer Use model&lt;/head&gt;
    &lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;
    &lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;
    &lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;
    &lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;
    &lt;p&gt;Prompt: “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;
    &lt;p&gt;Prompt: “My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How it performs&lt;/head&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;
    &lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;
    &lt;head rend="h2"&gt;How we approached safety&lt;/head&gt;
    &lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;
    &lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;
    &lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-step safety service: An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/item&gt;
      &lt;item&gt;System instructions: Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;
    &lt;head rend="h2"&gt;How early testers have used it&lt;/head&gt;
    &lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;
    &lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;
    &lt;head rend="h2"&gt;How to get started&lt;/head&gt;
    &lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try it now: In a demo environment hosted by Browserbase.&lt;/item&gt;
      &lt;item&gt;Start building: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/item&gt;
      &lt;item&gt;Join the community: We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507936</guid><pubDate>Tue, 07 Oct 2025 19:49:11 +0000</pubDate></item><item><title>A tiny recursive reasoning model achieves 45% on ARC-AGI-1 and 8% on ARC-AGI-2</title><link>http://alexiajm.github.io/2025/09/29/tiny_recursive_models.html</link><description>&lt;doc fingerprint="e51fd9a9ac595e1b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Less is More: Recursive Reasoning with Tiny Networks&lt;/head&gt;
    &lt;p&gt;In this new paper, I propose Tiny Recursion Model (TRM), a recursive reasoning model that achieves amazing scores of 45% on ARC-AGI-1 and 8% on ARC-AGI-2 with a tiny 7M parameters neural network. The idea that one must rely on massive foundational models trained for millions of dollars by some big corporation in order to achieve success on hard tasks is a trap. Currently, there is too much focus on exploiting LLMs rather than devising and expanding new lines of direction. With recursive reasoning, it turns out that “less is more”: you don’t always need to crank up model size in order for a model to reason and solve hard problems. A tiny model pretrained from scratch, recursing on itself and updating its answers over time, can achieve a lot without breaking the bank.&lt;/p&gt;
    &lt;p&gt;This work came to be after I learned about the recent innovative Hierarchical Reasoning Model (HRM). I was amazed that an approach using small models could do so well on hard tasks like the ARC-AGI competition (reaching 40% accuracy when normally only Large Language Models could compete). But I kept thinking that it is too complicated, relying too much on biological arguments about the human brain, and that this recursive reasoning process could be greatly simplified and improved. Tiny Recursion Model (TRM) simplifies recursive reasoning to its core essence, which ultimately has nothing to do with the human brain, does not require any mathematical (fixed-point) theorem, nor any hierarchy.&lt;/p&gt;
    &lt;p&gt;See the paper for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;TLDR&lt;/head&gt;
    &lt;p&gt;Tiny Recursion Model (TRM) recursively improves its predicted answer y with a tiny network. It starts with the embedded input question x and initial embedded answer y and latent z. For up to K improvements steps, it tries to improve its answer y. It does so by i) recursively updating n times its latent z given the question x, current answer y, and current latent z (recursive reasoning), and then ii) updating its answer y given the current answer y and current latent z. This recursive process allows the model to progressively improve its answer (potentially addressing any errors from its previous answer) in an extremely parameter-efficient manner while minimizing overfitting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45508213</guid><pubDate>Tue, 07 Oct 2025 20:11:58 +0000</pubDate></item></channel></rss>