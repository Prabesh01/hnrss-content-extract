<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 13 Oct 2025 03:28:51 +0000</lastBuildDate><item><title>A whirlwind introduction to dataflow graphs (2018)</title><link>https://fgiesen.wordpress.com/2018/03/05/a-whirlwind-introduction-to-dataflow-graphs/</link><description>&lt;doc fingerprint="b3208217658411de"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A whirlwind introduction to dataflow graphs&lt;/head&gt;
    &lt;p&gt;While in the middle of writing “Reading bits in far too many ways, part 3”, I realized that I had written a lot of background material that had absolutely nothing to do with bit I/O and really was worth putting in its own post. This is that post.&lt;/p&gt;
    &lt;p&gt;The problem I’m concerned with is fairly easy to state: say we have some piece of C++ code that we’re trying to understand (and perhaps improve) the performance of. A good first step is to profile it, which will give us some hints which parts are slow, but not necessarily why. On a fundamental level, any kind of profiling (or other measurement) is descriptive, not predictive: it can tell you how an existing system is behaving, but if you’re designing something that’s more than a few afternoons worth of work, you probably don’t have the time or resources to implement 5 or 6 completely different design alternatives, pick whichever one happens to work best, and throw the rest away. You should be able to make informed decisions up front from an algorithm sketch without having to actually write a fleshed-out implementation.&lt;/p&gt;
    &lt;p&gt;One thing I want to emphasize particularly here is that experiments coupled with before/after measurements are no adequate substitute for a useful performance model. These kinds of measurements can tell you how much you’ve improved, but not if you are where you should be: if I tell you that by tweaking some config files, I managed to double the number of requests served per second by the web server, that sounds great. It sounds less good if I give you the additional piece of information that with this fix deployed, we’re now at a whopping 1.5 requests per second; having an absolute scale of reference matters!&lt;/p&gt;
    &lt;p&gt;This goes especially for microbenchmarks. With microbenchmarks, like a trial lawyer during cross-examination, you should never ask a question you don’t know the answer to (or at least have a pretty good idea of what it is). Real-world systems are generally too complex and intertwined to understand from surface measurements alone. If you have no idea how a system works at all, you don’t know what the right questions are, nor how to ask them, and any answers you get will be opaque at best, if not outright garbage. Microbenchmarks are a useful tool to confirm that an existing model is a good approximation to reality, but not very helpful in building these models to begin with.&lt;/p&gt;
    &lt;head rend="h3"&gt;Machine models&lt;/head&gt;
    &lt;p&gt;So, if we want to go deeper than just squinting at C/C++ code and doing some hand-waving, we need to start looking at a somewhat lower abstraction level and define a machine model that is more sophisticated than “statements execute one by one”. If you’re only interested in a single specific processor, one option is to use whatever documentation and tools you can find for the chip in question and analyze your code in detail for that specific machine. And if you’re willing to go all-out on microarchitectural tweaking, that’s indeed the way to go, but it’s a giant step from looking at C++ code, and complete overkill in most cases.&lt;/p&gt;
    &lt;p&gt;Instead, what I’m going to do is use a simplified machine model that allows us to make quantitative predictions about the behavior of straightforward compute-bound loops, which is simple to describe but still gives us a lot of useful groundwork for more complex scenarios. Here’s what I’ll use:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We have an unlimited set of 64-bit integer general-purpose registers, which I’ll refer to by names like &lt;code&gt;rSomething&lt;/code&gt;. Any “identifiers” that aren’t prefixed with a lowercase r are either symbolic constants or things like labels.&lt;/item&gt;
      &lt;item&gt;We have the usual 64-bit integer arithmetic and logic operations. All operations can either be performed between two registers or a register and an immediate constant, and the result is placed in another register. All arithmetic uses two’s complement. For simplicity, all 64-bit values are permitted as immediate constants.&lt;/item&gt;
      &lt;item&gt;There’s a flat, byte-granular 64-bit address space, and pointers are just represented as integers.&lt;/item&gt;
      &lt;item&gt;All memory accesses require explicit load and store operations. Memory accesses are either 8, 16, 32, or 64 bits in size and can use (for my convenience) both little-endian or big-endian byte ordering, when requested. One of these is the default, but both are the same cost. Narrow stores store the least significant bits of the register in question; narrow loads zero-extend to 64 bits. Loads and stores have a few common addressing modes (that I’ll introduce as I use them). Unaligned loads and stores are supported.&lt;/item&gt;
      &lt;item&gt;There’s unconditional branches, which just jump to a given location, and conditional branches, which compare a register to either another register or an immediate constant, and branch to a given destination if the condition is true.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Code will be written in a pseudo-C form, at most one instruction per line. Here’s a brief example showing what kind of thing I have in mind:&lt;/p&gt;
    &lt;quote&gt;loop: // label rFoo = rBar | 1; // bitwise logical OR rFoo = lsl(rFoo, 3); // logical shift left rBar = asr(rBar, rBaz); // arithmetic shift right rMem = load64LE(rBase + rFoo); // little-endian load store16BE(rDest + 3, rMem); // big-endian store rCount = rCount - 1; // basic arithmetic if rCount != 0 goto loop; // branch&lt;/quote&gt;
    &lt;p&gt;Shifts use explicit mnemonics because there’s different types of right shifts and at this level of abstraction, registers are generally treated as untyped bags of bits. I’ll introduce other operations and addressing modes as we get to them. What we’ve seen so far is quite close to classic RISC instruction sets, although I’ll allow a larger set of addressing modes than some of the more minimalist designs, and require support for unaligned access on all loads and stores. It’s also close in spirit to an IR (Intermediate Representation) you’d expect to see early in the backend of a modern compiler: somewhat lower-level than LLVM IR, and comparable to early-stage LLVM Machine IR or GCC RTL.&lt;/p&gt;
    &lt;p&gt;This model requires us to make the distinction between values kept in registers and memory accesses explicit, and flattens down control flow to basic blocks connected by branches. But it’s still relatively easy to look at a small snippet of C++ and e.g. figure out how many arithmetic instructions it boils down to: just count the number of operations.&lt;/p&gt;
    &lt;p&gt;As a next step, we could now specify a virtual processor to go with our instruction set, but I don’t want to really get into that level of detail; instead of specifying the actual processor, I’ll work the same way actual architectures do: we require that the end result (eventual register and memory contents in our model) of running a program must be as if we had executed the instructions sequentially one by one (as-if rule). Beyond that, an aggressive implementation is free to cut corners as much as it wants provided it doesn’t get caught. We’ll assume we’re in an environment—the combination of compilers/tools and the processor itself—that uses pipelining and tries to extract instruction-level parallelism to achieve higher performance, in particular:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instructions can launch independent from each other, and take some number of clock cycles to complete. For an instruction to start executing, all the operands it depends on need to have been computed. As long as the dependencies are respected, all reorderings are valid.&lt;/item&gt;
      &lt;item&gt;There is some limit W (“width”) on how many new instructions we can start per clock cycle. In-flight instructions don’t interfere with each other; as long as we have enough independent work, we can start W new instructions every cycle. We’re going to treat W as variable.&lt;/item&gt;
      &lt;item&gt;Memory operations have a latency of 4 cycles, meaning that the result of a load is available 4 cycles after the load issued, and a load reading the bytes written by a prior store can issue 4 cycles after the store. That’s a fairly typical latency for a load that hits in the L1 cache, in case you were wondering.&lt;/item&gt;
      &lt;item&gt;Branches (conditional or not) count as a single instruction, but their latency is variable. Unconditional branches or easily predicted branches such as the loop counter in along-running loop have an effective latency of 0 cycles, meaning the instructions being branched to can issue at the same time as the branch itself. Unpredictable branches have a nonzero cost that depends on how unpredictable they are—I won’t even try to be more precise here.&lt;/item&gt;
      &lt;item&gt;Every other instruction has a latency of 1 clock cycle, meaning the result is available in the next cycle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This model can be understood as approximating either a dataflow architecture, an out-of-order machine with a very large issue window (and infinitely fast front-end), or a statically scheduled in-order machine running code compiled with a Sufficiently Smart Scheduler. (The kind that actually exists; e.g. a compiler implementing software pipelining).&lt;/p&gt;
    &lt;p&gt;Furthermore, I’m assuming that while there is explicit control flow (unlike a pure dataflow machine), there is a branch prediction mechanism in place that allows the machine to guess the control flow path taken arbitrarily far in advance. When these guesses are correct, the branches are effectively free other than still taking an instruction slot, during which time the machine checks whether its prediction was correct. When the guess was incorrect, the machine reverts all computations that were down the incorrectly guessed path, and takes some number of clock cycles to recover. If this idea of branch prediction is new to you, I’ll refer you to Dan Luu’s excellent article on the subject, which explains both how and why computers would be doing this.&lt;/p&gt;
    &lt;p&gt;The end result of these model assumptions is that while control flow exists, it’s on the sidelines: its only observable effect is that it sometimes causes us to throw away a bunch of work and take a brief pause to recover when we guessed wrong. Dataflow, on the other hand—the dependencies between instructions, and how long it takes for these dependencies to be satisfied—is front and center.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dataflow graphs&lt;/head&gt;
    &lt;p&gt;Why this emphasis? Because dataflow and data dependencies is because they can be viewed as the fundamental expression of the structure of a particular computation, whether it’s done on a small sequential machine, a larger superscalar out-of-order CPU, a GPU, or in hardware (be it a hand-soldered digital circuit, a FPGA, or an ASIC). Dataflow and keeping track of the shape of data dependencies is an organizing principle of both the machines themselves and the compilers that target them.&lt;/p&gt;
    &lt;p&gt;And these dependencies are naturally expressed in graph form, with individual operations being the nodes and data dependencies denoted by directed edges. In this post, I’ll have dependent operations point towards the operations they depend on, with the directed edges labeled with their latency. To reduce clutter, I’ll only write latency numbers when they’re not 1.&lt;/p&gt;
    &lt;p&gt;With all that covered, and to see what the point of this all is, let’s start with a simple, short toy program that just sums the 64-bit integers in some array delineated by two pointers stored in &lt;code&gt;rCurPtr&lt;/code&gt; (which starts pointing to the first element) and &lt;code&gt;rEndPtr&lt;/code&gt; (which points to one past the last element), idiomatic C++ iterator-style.&lt;/p&gt;
    &lt;quote&gt;loop: rCurInt = load64(rCurPtr); // Load rSum = rSum + rCurInt; // Sum rCurPtr = rCurPtr + 8; // Advance if rCurPtr != rEndPtr goto loop; // Done?&lt;/quote&gt;
    &lt;p&gt;We load a 64-bit integer from the current pointer, add it to our current running total in register &lt;code&gt;rSum&lt;/code&gt;, increment the pointer by 8 bytes (since we grabbed a 64-bit integer), and then loop until we’re done. Now let’s say we run this program for a short 6 iterations and draw the corresponding dataflow graph (click to see full-size version):&lt;/p&gt;
    &lt;p&gt;Note I group nodes into ranks by which cycle they can execute in, at the earliest, assuming we can issue as many instructions in parallel as we want, purely constrained by the data dependencies. The “Load” and “Advance” from the first iteration can execute immediately; the “Done?” check from the first iteration looks at the updated &lt;code&gt;rCurPtr&lt;/code&gt;, which is only known one cycle later; and “Sum” from the first iteration needs to wait for the load to finish, which means it can only start a full 4 cycles later.&lt;/p&gt;
    &lt;p&gt;As we can see, during the first four cycles, all we do is keep issuing more loads and advancing the pointer. It takes until cycle 4 for the results of the first load to become available, so we can actually do some summing. After that, one more load completes every cycle, allowing us to add one more integer to the running sum in turn. If we let this process continue for longer, all the middle iterations would look the way cycles 4 and 5 do: in our state state, we’re issuing a copy of all four instructions in the loop every cycle, but from different iterations.&lt;/p&gt;
    &lt;p&gt;There’s a few conclusions we can draw from this: first, we can see that this four-instruction loop achieves a steady-state throughput of one integer added to the sum in every clock cycle. We take a few cycles to get into the steady state, and then a few more cycles at the end to drain out the pipeline, but if we start in cycle 0 and keep running N iterations, then the final sum will be completed by cycle N+4. Second, even though I said that our model has infinite lookahead and is free to issue as many instructions per cycle as it wants, we “only” end up using at most 4 instructions per cycle. The limiter here ends up being the address increment (“Advance”); we increment the pointer after every load, per our cost model this increment takes a cycle of latency, and therefore the load in the next iteration of the loop (which wants to use the updated pointer) can start in the next cycle at the earliest.&lt;/p&gt;
    &lt;p&gt;This is a crucial point: the longest-latency instruction in this loop is definitely the load, at 4 cycles. But that’s not a limiting factor; we can schedule around the load and do the summing later. The actual problem here is with the pointer advance; every single instruction that comes after it in program order depends on it either directly or indirectly, and therefore, its 1 cycle of latency determines when the next loop iteration can start. We say it’s on the critical path. In loops specifically, we generally distinguish between intra-iteration dependencies (between instructions within the same iteration, say “Sum 0” depending on “Load 0”) and inter-iteration or loop-carried dependencies (say “Sum 1” depending on “Sum 0”, or “Load 1” depending on “Advance 0”). Intra-iteration dependencies may end up delaying instructions within that iteration quite a lot, but it’s inter-iteration dependencies that determine how soon we can start working on the next iteration of the loop, which is usually more important because it tends to open up more independent instructions to work on.&lt;/p&gt;
    &lt;p&gt;The good news is that W=4 is actually a fairly typical number of instructions decoded/retired per cycle in current (as of this writing in early 2018) out-of-order designs, and the instruction mixture here (1 load, 1 branch, 2 arithmetic instructions) is also one that is quite likely to be able to issue in parallel on a realistic 4-wide decode/retire design. While many machines can issue a lot more instructions than that in short bursts, a steady state of 4 instructions per cycle is definitely good. So even though we’re not making much of the infinite parallel computing power of our theoretical machine, in practical terms, we’re doing OK, although on real machines we might want to apply some more transforms to the loop; see below.&lt;/p&gt;
    &lt;p&gt;Because these real-world machines can’t start an arbitrary number of instructions at the same time, we have another concern: throughput. Say we’re running the same loop on a processor that has W=2, i.e. only two instructions can start every cycle. Because our loop has 4 instructions, that means that we can’t possibly start a new loop iteration more often than once every two clock cycles, and the limiter aren’t the data dependencies, but the number of instructions our imaginary processor can execute in a clock cycle; we’re throughput-bound. We would also be throughput-bound on a machine with W=3, with a steady state of 3 new instructions issued per clock cycle, where we can start working on a new iteration every 4/3≈1.33 cycles.&lt;/p&gt;
    &lt;head rend="h3"&gt;A different example&lt;/head&gt;
    &lt;p&gt;For the next example, we’re going to look at what’s turned into everyone’s favorite punching-bag of a data structure, the linked list. Let’s do the exact same task as before, only this time, the integers are stored in a singly-linked list instead of laid out as an array. We store first a 64-bit integer and then a 64-bit pointer to the next element, with the end of the list denoted by a special value stored in &lt;code&gt;rEndPtr&lt;/code&gt; as before. We also assume the list has at least 1 element. The corresponding program looks like this:&lt;/p&gt;
    &lt;quote&gt;loop: rCurInt = load64(rCurPtr); // LoadInt rSum = rSum + rCurInt; // Sum rCurPtr = load64(rCurPtr + 8); // LoadNext if rCurPtr != rEndPtr goto loop; // Done?&lt;/quote&gt;
    &lt;p&gt;Very similar to before, only this time, instead of incrementing the pointer, we do another load to grab the “next” pointer. And here’s what happens to the dataflow graph if we make this one-line change:&lt;/p&gt;
    &lt;p&gt;Switching from a contiguous array to a linked list means that we have to wait for the load to finish before we can start the next iteration. Because loads have a latency of 4 cycles in our model, that means we can’t start a new iteration any more often than once every 4 cycles. With our 4-instruction loop, we don’t even need any instruction-level parallelism to reach that target; we might as well just execute one instruction per cycle and still hit the same overall throughput.&lt;/p&gt;
    &lt;p&gt;Now, this example, with its short 4-instruction loop, is fairly extreme; if our loop had say a total of 12 instructions that worked out nicely, the same figure might well end up averaging 3 instructions per clock cycle, and that’s not so bad. But the underlying problem here is a nasty one: because our longest-latency instruction is on the critical path between iterations, it ends up determining the overall loop throughput.&lt;/p&gt;
    &lt;p&gt;In our model, we’re still primarily focused on compute-bound code, and memory access is very simple: there’s no memory hierarchy with different cache levels, all memory accesses take the same time. If we instead had a more realistic model, we would also have to deal with the fact that some memory accesses take a whole lot longer than 4 cycles to complete. For example, suppose we have three cache levels and, at the bottom, DRAM. Sticking with the powers-of-4 theme, let’s say that a L1 cache hit takes 4 cycles (i.e. our current memory access latency), a L2 hit takes 16 cycles, a L3 hit takes 64 cycles, and an actual memory access takes 256 cycles—for what it’s worth, all these numbers are roughly in the right ballpark for high-frequency desktop CPUs under medium memory subsystem load as of this writing.&lt;/p&gt;
    &lt;p&gt;Finding work to keep the machine otherwise occupied for the next 4 cycles (L1 hit) is usually not that big a deal, unless we have a very short loop with unfavorable dependency structure, as in the above example. Fully covering the 16 cycles for a L1 miss but L2 hit is a bit trickier and requires a larger out-of-order window, but current out-of-order CPUs have those, and as long as there’s enough other independent work and not too many hard-to-predict branches along the way, things will work out okay. With a L3 cache hit, we’ll generally be hard-pressed to find enough independent work to keep the core usefully busy during the wait for the result, and if we actually miss all the way to DRAM, then in our current model, the machine is all but guaranteed to stall; that is, to have many cycles with no instructions executed at all, just like the gaps in the diagram above.&lt;/p&gt;
    &lt;p&gt;Because linked lists have this nasty habit of putting memory access latencies on the critical path, they have a reputation of being slow “because they’re bad for the cache”. Now while it’s definitely true that most CPUs with a cache would much rather have you iterate sequentially over an array, we have to be careful how we think about it. To elaborate, suppose we have yet another sum kernel, this time processing an array of pointers to integers, to compute the sum of the pointed-to values.&lt;/p&gt;
    &lt;quote&gt;loop: rCurIntPtr = load64(rCurPtr); // LoadPtr rCurInt = load64(rCurIntPtr); // LoadInt rSum = rSum + rCurInt; // Sum rCurPtr = rCurPtr + 8; // Advance if rCurPtr != rEndPtr goto loop; // Done?&lt;/quote&gt;
    &lt;p&gt;And this time, I’ll prune the dataflow graph to show only the current iteration and its direct dependency relationships with earlier and later iterations, because otherwise these more complicated graphs will get cluttered and unreadable quickly:&lt;/p&gt;
    &lt;p&gt;A quick look over that graph shows us that copies of the same instruction from different iterations are all spaced 1 cycle apart; this means that in the steady state, we will again execute one iteration of the loop per clock cycle, this time issuing 5 instructions instead of 4 (because there are 5 instructions in the loop). Just like in the linked list case, the pointer indirection here allows us to jump all over memory (potentially incurring cache misses along the way) if we want to, but there’s a crucial difference: in this setup, we can keep setting up future iterations of the loop and get more loads started while we’re waiting for the first memory access to complete.&lt;/p&gt;
    &lt;p&gt;To explain what I mean, let’s pretend that every single of the “LoadInt”s misses the L1 cache, but hits in the L2 cache, so its actual latency is 16 cycles, not 4. But a latency of 16 cycles just means that it takes 16 cycles between issuing the load and getting the result; we can keep issuing other loads for the entire time. So the only thing that ends up happening is that the “Sum k” in the graph above happens 12 cycles later. We still start two new loads every clock cycle in the steady state; some of them end up taking longer, but that does not keep us from starting work on a new iteration of the loop in every cycle.&lt;/p&gt;
    &lt;p&gt;Both the linked list and the indirect-sum examples have the opportunity to skip all over memory if they want to; but in the linked-list case, we need to wait for the result of the previous load until we can get started on the next one, whereas in the indirect-sum case, we get to overlap the wait times from the different iterations nicely. As a result, in the indirect-sum case, the extra latency towards reaching the final sum is essentially determined by the worst single iteration we had, whereas in the linked-list case, every single cache miss makes our final result later (and costs us throughput).&lt;/p&gt;
    &lt;p&gt;The fundamental issue isn’t that the linked-list traversal might end up missing the cache a lot; while this isn’t ideal (and might cost us in other ways), the far more serious issue is that any such cache miss prevents us from making progress elsewhere. Having a lot of cache misses isn’t necessarily a problem if we get to overlap them; having long stretches of time were we can’t do anything else, because everything else we could do depends on that one cache-missing load, is.&lt;/p&gt;
    &lt;p&gt;In fact, when we hit this kind of problem, our best bet is to just switch to doing something else entirely. This is what CPUs with simultaneous multithreading/hardware threads (“hyperthreads”) and essentially all GPUs do: build the machine so that it can process instructions from multiple instruction streams (threads), and then if one of the threads isn’t really making progress right now because it’s waiting for something, just work on something else for a while. If we have enough threads, then we can hopefully fill those gaps and always have something useful to work on. This trade-off is worthwhile if we have many threads and aren’t really worried about the extra latency caused by time-slicing, which is why this approach is especially popular in throughput-centric architectures that don’t worry about slight latency increases.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unrolling&lt;/head&gt;
    &lt;p&gt;But let’s get back to our original integer sum code for a second:&lt;/p&gt;
    &lt;quote&gt;loop: rCurInt = load64(rCurPtr); // Load rSum = rSum + rCurInt; // Sum rCurPtr = rCurPtr + 8; // Advance if rCurPtr != rEndPtr goto loop; // Done?&lt;/quote&gt;
    &lt;p&gt;We have a kernel with four instructions here. Out of these four, two (“Load” and “Sum”) do the actual work we want done, whereas “Advance” and “Done?” just implement the loop itself and are essentially overhead. This type of loop is a prime target for unrolling, where we collapse two or more iterations of the loop into one to decrease the overhead fraction. Let’s not worry about the setup or what to do when the number of elements in the array is odd right now, and only focus on the “meat” of the loop. Then a 2× unrolled version might look like this:&lt;/p&gt;
    &lt;quote&gt;loop: rCurInt = load64(rCurPtr); // LoadEven rSum = rSum + rCurInt; // SumEven rCurInt = load64(rCurPtr + 8); // LoadOdd rSum = rSum + rCurInt; // SumOdd rCurPtr = rCurPtr + 16; // Advance if rCurPtr != rEndPtr goto loop; // Done?&lt;/quote&gt;
    &lt;p&gt;which has this dataflow graph:&lt;/p&gt;
    &lt;p&gt;Note that even though I’m writing to &lt;code&gt;rCurInt&lt;/code&gt; twice in an iteration, which constitutes a write-after-write (WAW) or “output dependency”, there’s no actual dataflow between the loads and sums for the first and second version of &lt;code&gt;rCurInt&lt;/code&gt;, so the loads can issue in parallel just fine.&lt;/p&gt;
    &lt;p&gt;This isn’t bad: we now have two loads every iteration and spend 6N instructions to sum 2N integers, meaning we take 3 instructions per integer summed, whereas our original kernel took 4. That’s an improvement, and (among other things) means that while our original integer-summing loop needed a machine that sustained 4 instructions per clock cycle to hit full throughput, we can now hit the same throuhgput on a smaller machine that only does 3 instructions per clock. This is definitely progress.&lt;/p&gt;
    &lt;p&gt;However, there’s a problem: if we look at the diagram, we can see that we can indeed start a new pair of loads every clock cycle, but there’s a problem with the summing: we have two dependent adds in our loop, and as we can see from the relationship between “SumEven k” and “SumEven k+1”, the actual summing part of the computation still takes 2 cycles per iteration. On our idealized dataflow machine with infinite lookahead, that just means that all the loads will get front-loaded, and then the adds computing the final sum proceed at their own pace; the result will eventually be available, but it will still take a bit more than 2N cycles, no faster than we were in the original version of the loop. On a more realistic machine (which can only look ahead by a limited number of instructions), we would eventually stop being able to start new loop iterations until some of the old loop iterations have completed. No matter how we slice it, we’ve gone from adding one integer to the sum per cycle to adding two integers to the sum every two cycles. We might take fewer instructions to do so, which is a nice consolation prize, but this is not what we wanted!&lt;/p&gt;
    &lt;p&gt;What’s happened is that unrolling shifted the critical path. Before, the critical path between iterations went through the pointer advance (or, to be more precise, there were two critical paths, one through the pointer advance and one through the sum, and they were both the same length). Now that we do half the number of advances per item, that isn’t a problem anymore; but the fact that we’re summing these integers sequentially is now the limiter.&lt;/p&gt;
    &lt;p&gt;A working solution is to change the algorithm slightly: instead of keeping a single sum of all integers, we keep two separate sums. One for the integers at even-numbered array positions, and one for the integers at odd-numberd positions. Then we need to sum those two values at the end. This is the algorithm:&lt;/p&gt;
    &lt;quote&gt;loop: rCurInt = load64(rCurPtr); // LoadEven rSumEven = rSumEven + rCurInt; // SumEven rCurInt = load64(rCurPtr + 8); // LoadOdd rSumOdd = rSumOdd + rCurInt; // SumOdd rCurPtr = rCurPtr + 16; // Advance if rCurPtr != rEndPtr goto loop; // Done? rSum = rSumEven + rSumOdd; // FinalSum&lt;/quote&gt;
    &lt;p&gt;And the dataflow graph for the loop kernel looks as follows:&lt;/p&gt;
    &lt;p&gt;Where before all the summing was in what’s called the same dependency chain (the name should be self-explanatory by now, I hope), we have now split the summation into two dependency chains. And this is enough to make a sufficiently-wide machine that can sustain 6 instructions per cycle complete our integer-summing task in just slightly more than half a cycle per integer being summed. Progress!&lt;/p&gt;
    &lt;p&gt;On a somewhat narrower 4-wide design, we are now throughput-bound, and take around 6/4=1.5 cycles per two integers summed, or 0.75 cycles per integer. That’s still a good improvement from the 1 cycle per integer we would have gotten on the same machine from the non-unrolled version; this gain is purely from reduction the loop overhead fraction, and further unrolling could reduce it even further. (That said, unless your loop really is as tiny as our example, you don’t generally want to go overboard with unrolling.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Tying it all together&lt;/head&gt;
    &lt;p&gt;In the introduction, I talked about the need for a model detailed enough to make quantitative, not just qualitative, predictions; and at least for very simple compute-bound loops, that is exactly what we have now. At this point, you should know enough to look at the dependency structure of simple loops, and have some idea for how much (or how little) latent parallelism there is, and be able to compute a coarse upper bound on their “speed of light” on various machines with different peak instructions/cycle rates.&lt;/p&gt;
    &lt;p&gt;Of course, there are many simplifications here, most of which have been already noted in the text; we’re mostly ignoring the effects of the memory hierarchy, we’re not worrying at all about where the decoded instructions come from and how fast they can possibly be delivered, we’ve been flat-out assuming that our branch prediction oracle is perfect, and we’ve been pretending that while there may be a limit on the total number of instructions we can issue per cycle, it doesn’t matter what these instructions are. None of these are true. And even if we’re still compute-bound, we need to worry at least about that latter constraint: sometimes it can make a noticeable difference to tweak the “instruction mix” so it matches better what the hardware can actually do in a given clock cycle.&lt;/p&gt;
    &lt;p&gt;But all these caveats aside, the basic concepts introduced here are very general, and even just sketching out the dependency graph of a loop like this and seeing it in front of you should give you useful ideas about what potential problems are and how you might address them. If you’re interested in performance optimization, it is definitely worth your time practicing this so you can look at loops and get a “feel” for how they execute, and how the shape of your algorithm (or your data structures, in the linked list case) aids or constrains the compiler and processor.&lt;/p&gt;
    &lt;p&gt;UPDATE: Some additional clarifications in answer to some questions: paraphrasing one, “if you have to first write C code, translate it to some pseudo-assembly, and then look at the graph, how can this possibly be a better process than just measuring the code in the first place?” Well, the trick here is that to measure anything, you actually need a working program. You don’t to draw a dataflow graph. For example, a common scenario is that there are many ways you could structure some task, and they all want their data structured differently. Actually implementing and testing multiple variants like this requires you to write a lot of plumbing to massage data from one format into another (all of which can be buggy). Drawing a graph can be done from a brief description of the inner loop alone, and you can leave out the parts that you don’t currently care about, or “dummy them out” by replacing them with a coarse approximation (“random work here, maybe 10 cycles latency?”). You only need to make these things precise when they become close to the critical path (or you’re throughput-bound).&lt;/p&gt;
    &lt;p&gt;The other thing I’ll say is that even though I’ve been talking about adding cycle estimates for compute-bound loops here, this technique works and is useful at pretty much any scale. It’s applicable in any system where work is started and then processed asynchronously, with the results arriving some time later. If you’re analyzing a tight, compute-bound loop, cycle-level granularity is the way to go. But you can zoom out and use the same technique to figure out how your decomposition of an algorithm into tasklets processed by a thread pool works out: do you actually have some meaningful overlap, or is there still one long serial dependency chain that dominates everything, and all you’re doing by splitting it into tasklets like that is adding overhead? Zooming out even further, it works to analyze RPCs you’re sending to a different machine, or queries to some database. Say you have a 30ms target response time, and each RPC takes about 2ms to return its results. In a system that takes 50 RPCs to produce a result, can you meet that deadline? The answer depends on how the dataflow between them looks. If they’re all in series, almost certainly not. If they’re in 5 “layers” that each fan out to 10 different machines then collect the results, you probably can. It certainly applies in project scheduling, and is one of the big reasons the “man-month” isn’t a very useful metric: adding manpower increases your available resources but does nothing to relax your dependencies. In fact, it often adds more of them, to bring new people up to speed. If the extra manpower ends up resulting in more work on the critical path towards finishing your project (for example to train new hires), then adding these extra people to the project made it finish later. And so forth. The point being, this is not just limited to cycle-by-cycle analysis, even though that’s the context I’ve been introducing it in. It’s far more general than that.&lt;/p&gt;
    &lt;p&gt;And I think that’s enough material for today. Next up, I’ll continue my “Reading bits in far too many ways” series with the third part, where I’ll be using these techniques to get some insight into what kind of difference the algorithm variants make. Until then!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45552590</guid><pubDate>Sat, 11 Oct 2025 20:52:21 +0000</pubDate></item><item><title>Three ways formally verified code can go wrong in practice</title><link>https://buttondown.com/hillelwayne/archive/three-ways-formally-verified-code-can-go-wrong-in/</link><description>&lt;doc fingerprint="2623409772eabd7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Three ways formally verified code can go wrong in practice&lt;/head&gt;
    &lt;head rend="h2"&gt;"Correct" doesn't mean "correct" when correctly using "correct"&lt;/head&gt;
    &lt;head rend="h3"&gt;New Logic for Programmers Release!&lt;/head&gt;
    &lt;p&gt;v0.12 is now available! This should be the last major content release. The next few months are going to be technical review, copyediting and polishing, with a hopeful 1.0 release in March. Full release notes here.&lt;/p&gt;
    &lt;head rend="h1"&gt;Three ways formally verified code can go wrong in practice&lt;/head&gt;
    &lt;p&gt;I run this small project called Let's Prove Leftpad, where people submit formally verified proofs of the eponymous meme. Recently I read Breaking “provably correct” Leftpad, which argued that most (if not all) of the provably correct leftpads have bugs! The lean proof, for example, should render &lt;code&gt;leftpad('-', 9, אֳֽ֑)&lt;/code&gt; as &lt;code&gt;---------אֳֽ֑&lt;/code&gt;, but actually does &lt;code&gt;------אֳֽ֑&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can read the article for a good explanation of why this goes wrong (Unicode). The actual problem is that correct can mean two different things, and this leads to confusion about how much formal methods can actually guarantee us. So I see this as a great opportunity to talk about the nature of proof, correctness, and how "correct" code can still have bugs.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we talk about when we talk about correctness&lt;/head&gt;
    &lt;p&gt;In most of the real world, correct means "no bugs". Except "bugs" isn't a very clear category. A bug is anything that causes someone to say "this isn't working right, there's a bug." Being too slow is a bug, a typo is a bug, etc. "correct" is a little fuzzy.&lt;/p&gt;
    &lt;p&gt;In formal methods, "correct" has a very specific and precise meaning: the code conforms to a specification (or "spec"). The spec is a higher-level description of what is supposed the code's properties, usually something we can't just directly implement. Let's look at the most popular kind of proven specification:&lt;/p&gt;
    &lt;code&gt;-- Haskell
inc :: Int -&amp;amp;gt; Int
inc x = x + 1
&lt;/code&gt;
    &lt;p&gt;The type signature &lt;code&gt;Int -&amp;gt; Int&lt;/code&gt; is a specification! It corresponds to the logical statement &lt;code&gt;all x in Int: inc(x) in Int&lt;/code&gt;. The Haskell type checker can automatically verify this for us. It cannot, however, verify properties like &lt;code&gt;all x in Int: inc(x) &amp;gt; x&lt;/code&gt;. Formal verification is concerned with verifying arbitrary properties beyond what is (easily) automatically verifiable. Most often, this takes the form of proof. A human manually writes a proof that the code conforms to its specification, and the prover checks that the proof is correct.&lt;/p&gt;
    &lt;p&gt;Even if we have a proof of "correctness", though, there's a few different ways the code can still have bugs.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. The proof is invalid&lt;/head&gt;
    &lt;p&gt;For some reason the proof doesn't actually show the code matches the specification. This is pretty common in pencil-and-paper verification, where the proof is checked by someone saying "yep looks good to me". It's much rarer when doing formal verification but it can still happen in a couple of specific cases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The theorem prover itself has a bug (in the code or introduced in the compiled binary) that makes it accept an incorrect proof. This is something people are really concerned about but it's so much rarer than every other way verified code goes wrong, so is only included for completeness.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For convenience, most provers and FM languages have an "just accept this statement is true" feature. This helps you work on the big picture proof and fill in the details later. If you leave in a shortcut, and the compiler is configured to allow code-with-proof-assumptions to compile, then you can compile incorrect code that "passes the proof checker". You really should know better, though.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;2. The properties are wrong&lt;/head&gt;
    &lt;p&gt;This code is provably correct:&lt;/p&gt;
    &lt;code&gt;inc :: Int -&amp;amp;gt; Int
inc x = x-1
&lt;/code&gt;
    &lt;p&gt;The only specification I've given is the type signature &lt;code&gt;Int -&amp;gt; Int&lt;/code&gt;. At no point did I put the property &lt;code&gt;inc(x) &amp;gt; x&lt;/code&gt; in my specification, so it doesn't matter that it doesn't hold, the code is still "correct".&lt;/p&gt;
    &lt;p&gt;This is what "went wrong" with the leftpad proofs. They do not prove the property "&lt;code&gt;leftpad(c, n, s)&lt;/code&gt; will take up either &lt;code&gt;n&lt;/code&gt; spaces on the screen or however many characters &lt;code&gt;s&lt;/code&gt; takes up (if more than &lt;code&gt;n&lt;/code&gt;)". They prove the weaker property "&lt;code&gt;len(leftpad(c, n, s)) == max(n, len(s))&lt;/code&gt;, for however you want to define &lt;code&gt;len(string)&lt;/code&gt;". The second is a rough proxy for the first that works in most cases, but if someone really needs the former property they are liable to experience a bug.&lt;/p&gt;
    &lt;p&gt;Why don't we prove the stronger property? Sometimes it's because the code is meant to be used one way and people want to use it another way. This can lead to accusations that the developer is "misusing the provably correct code" but this should more often be seen as the verification expert failing to educate devs on was actually "proven".&lt;/p&gt;
    &lt;p&gt;Sometimes it's because the property is too hard to prove. "Outputs are visually aligned" is a proof about Unicode inputs, and the core Unicode specification is 1,243 pages long.&lt;/p&gt;
    &lt;p&gt;Sometimes it's because the property we want is too hard to express. How do you mathematically represent "people will perceive the output as being visually aligned"? Is it OS and font dependent? These two lines are exactly five characters but not visually aligned:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;|||||&lt;/p&gt;
      &lt;p&gt;MMMMM&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Or maybe they are aligned for you! I don't know, lots of people read email in a monospace font. "We can't express the property" comes up a lot when dealing with human/business concepts as opposed to mathematical/computational ones.&lt;/p&gt;
    &lt;p&gt;Finally, there's just the possibility of a brain fart. All of the proofs in Nearly All Binary Searches and Mergesorts are Broken are like this. They (informally) proved the correctness of binary search with unbound integers, forgetting that many programming languages use machine integers, where a large enough sum can overflow.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. The assumptions are wrong&lt;/head&gt;
    &lt;p&gt;This is arguably the most important and most subtle source of bugs. Most properties we prove aren't "&lt;code&gt;X&lt;/code&gt; is always true". They are "assuming &lt;code&gt;Y&lt;/code&gt; is true, &lt;code&gt;X&lt;/code&gt; is also true". Then if &lt;code&gt;Y&lt;/code&gt; is not true, the proof no longer guarantees &lt;code&gt;X&lt;/code&gt;. A good example of this is binary &lt;del&gt;sort&lt;/del&gt; search, which only correctly finds elements assuming the input list is sorted. If the list is not sorted, it will not work correctly.&lt;/p&gt;
    &lt;p&gt;Formal verification adds two more wrinkles. One: sometimes we need assumptions to make the property valid, but we can also add them to make the proof easier. So the code can be bug-free even if the assumptions used to verify it no longer hold! Even if a leftpad implements visual alignment for all Unicode glyphs, it will be a lot easier to prove visual alignment for just ASCII strings and padding.&lt;/p&gt;
    &lt;p&gt;Two: we need make a lot of environmental assumptions that are outside our control. Does the algorithm return output or use the stack? Need to assume that there's sufficient memory to store stuff. Does it use any variables? Need to assume nothing is concurrently modifying them. Does it use an external service? Need to assume the vendor doesn't change the API or response formats. You need to assume the compiler worked correctly, the hardware isn't faulty, and the OS doesn't mess with things, etc. Any of these could change well after the code is proven and deployed, meaning formal verification can't be a one-and-done thing.&lt;/p&gt;
    &lt;p&gt;You don't actually have to assume most of these, but each assumption drop makes the proof harder and the properties you can prove more restricted. Remember, the code might still be bug-free even if the environmental assumptions change, so there's a tradeoff in time spent proving vs doing other useful work.&lt;/p&gt;
    &lt;p&gt;Another common source of "assumptions" is when verified code depends on unverified code. The Rust compiler can prove that safe code doesn't have a memory bug assuming unsafe code does not have one either, but depends on the human to confirm that assumption. Liquid Haskell is verifiable but can also call regular Haskell libraries, which are unverified. We need to assume that code is correct (in the "conforms to spec") sense, and if it's not, our proof can be "correct" and still cause bugs.&lt;/p&gt;
    &lt;p&gt;These boundaries are fuzzy. I wrote that the "binary search" bug happened because they proved the wrong property, but you can just as well argue that it was a broken assumption (that integers could not overflow). What really matters is having a clear understanding of what "this code is proven correct" actually tells you. Where can you use it safely? When should you worry? How do you communicate all of this to your teammates?&lt;/p&gt;
    &lt;p&gt;Good lord it's already Friday&lt;/p&gt;
    &lt;p&gt;If you're reading this on the web, you can subscribe here. Updates are once a week. My main website is here.&lt;/p&gt;
    &lt;p&gt;My new book, Logic for Programmers, is now in early access! Get it here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45555727</guid><pubDate>Sun, 12 Oct 2025 06:17:52 +0000</pubDate></item><item><title>Nostr and ATProto (2024)</title><link>https://shreyanjain.net/2024/07/05/nostr-and-atproto.html</link><description>&lt;doc fingerprint="231dd9512d25a3d4"&gt;
  &lt;main&gt;
    &lt;p&gt;This post could’ve been titled “Nostr vs ATProto”, but that really isn’t what I wanted to do here. While I will be comparing and contrasting them a lot, and that’s kind of even the point of writing this, I didn’t want to really pit the two against each other at all, and especially not with the title. I also want to try avoiding commenting on the differences between the communities that have formed on the protocols and their apps, although I definitely will be looking at the philosophical differences between the two a lot - also kind of the point of writing this. This also isn’t a super deep technical post, though it assumes familiarity with technical concepts. I also might come back to edit parts of it and add more later.&lt;/p&gt;
    &lt;p&gt;You can read and leave comments on this post here on Bluesky, or here on Nostr, or even here on Mastodon.&lt;/p&gt;
    &lt;p&gt;So I wrote a paragraph mostly about what this post isn’t about, with a little bit about what I will talk about in it, but I haven’t really explained what this post is, or why I’m writing it. Honestly, I’m not completely sure of the first one yet either; I’m figuring that out as I write it. The paragraph at the top are really serving as guidelines for myself as I write this.&lt;/p&gt;
    &lt;p&gt;However, I can explain how this post came to be. It started with a showerthought (I was literally in the shower) about how similar ATProto and Nostr really are. This thought came to me after ruminating on ATProto Relays and Nostr Relays, and thinking about how my favorite feature of Nostr Relays (spoiler: it’s filtering) could be added to ATProto Relays, and why you would want to do that. More broadly, this made me think that the two protocols are similar enough that they are likely to slowly converge over time as they learn from each other.&lt;/p&gt;
    &lt;p&gt;A direct result of those thoughts (after getting out of the shower, of course) was to search the internet for a good comparison of Nostr and ATProto. A direct result of my failure to find any was this Bluesky skoot (There’s a lot of good replies and thoughts in that thread as well—you probably want to read it before continuing with this post). A direct result of my skooting that was this reply. Before, I’d been tentatively considering writing a purely technical comparison after not finding any, but that reply really set the stage for deciding what I wanted to do in this post.&lt;/p&gt;
    &lt;p&gt;So, to start, let’s look at…&lt;/p&gt;
    &lt;head rend="h2"&gt;How we got here&lt;/head&gt;
    &lt;head rend="h3"&gt;A Caged Bird&lt;/head&gt;
    &lt;head rend="h4"&gt;or, Twitter&lt;/head&gt;
    &lt;p&gt;Twitter here could, in theory, be replaced here by just “Centralized Social Media”, but really it was Twitter that got us here. Both ATProto and Nostr exist because of Twitter - the AT Protocol very directly so, Nostr as a response to “censorship” (real or perceived) on Twitter. ATProto is the result of Bluesky’s original mission - to build a decentralized protocol Twitter could adopt. Post-Elon, who knows if that will ever happen, but, well, that is how it started.&lt;/p&gt;
    &lt;p&gt;Twitter sprang into existence in 2007, as a small, SMS-based service that allowed people to post short status updates - tweets, as they became known. Who knows if it was the first of its kind? Well, it certainly became the most popular. It really was the service that was able to popularize the concept of microblogging. It developed a multitude of subcultures, each with their own unique characteristics, often intersecting with each other in fascinating, unpredictable places and ways. And while Twitter certainly never became as popular as some of its big tech companions, it may have had the greatest cultural impact - it was one of the only places in existence where an average person (you!!) could, say, ratio a presidential candidate or give interesting new details on a story to some famous journalist (I don’t know, I just made those up). Some have said it was the first “global town square”.&lt;/p&gt;
    &lt;p&gt;Over the years of Twitter’s existence, lots of things happened to Twitter. Moderation issues including Donald Trump, authoritarian governments around the world, all sorts of mini community wars and harassment, etc. Twitter, as beautiful as it was, well… kind of sucked, and people drew many different (not mutually exclusive and often overlapping!!) conclusions about why. Some, like Christopher Bouzy of Spoutible, concluded that the platform’s moderation simply wasn’t enough for what the platform had become, and people needed a smaller, more closed space with stricter moderation policies. Others concluded that a global-scale social network is simply an inherently bad idea and people should stick to smaller, more tight-knit communities. But one of the most popular conclusions was that something as important as Twitter - whether you considered it a “global town square” or a place to make connections with your community or Whatever Else - simply could not and should not be controlled by a single corporation. Indeed, this was the conclusion that Twitter themselves came to! This is the conclusion that both ATProto and Nostr are founded upon - the idea of a move from closed, centralized, corporate-owned social platforms to a world of open, decentralized social protocols.&lt;/p&gt;
    &lt;p&gt;But ATProto and Nostr don’t exist in a vacuum. They weren’t the only ones to come to this conclusion. They weren’t even the first. And that brings us to…&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mastodon in the Room&lt;/head&gt;
    &lt;head rend="h4"&gt;or, ActivityPub and the Fediverse&lt;/head&gt;
    &lt;p&gt;⚠️ I am not an expert on ActivityPub. Take everything in this section with a grain of salt. If I get something wrong, please correct me. ⚠️&lt;/p&gt;
    &lt;p&gt;ActivityPub is kind of a big deal in the decentralized social protocols world. It’s not the first, either - it would be extremely hard to really find a first. But it is, at least for now, the largest, and realistically is about to become a lot larger, at least if Meta Threads federates with it.&lt;/p&gt;
    &lt;p&gt;It’s also got an entirely different philosophy to either Nostr or ATProto - while both of the latter are based on a more individualistic approach to decentralization, ActivityPub opted for a more collectivist approach, one that favors tight-knit communities over a global network (that hasn’t stopped people from trying to build global networks with it, though.)&lt;/p&gt;
    &lt;p&gt;(Side-note: I should also mention that whether the Fediverse should focus on smaller communities or mass-interconnection has been a debate even within the Fediverse since right about the beginning, which a lot of the differing viewpoints around this topic explained brilliantly by Evan Podromou. Since Small Fedi seems to be the dominant philosophy shaping the current Fediverse, I’ve mostly focused on Small Fedi when talking about ActivityPub here.)&lt;/p&gt;
    &lt;p&gt;There are many different server implementations of the ActivityPub Spec, each adding their own unique flair to the ecosystem. The most popular of these implementations is Mastodon. ActivityPub is also, like I said above, kind of a big deal in the decentralized social protocols world. Almost everyone working on decentralized protocols after ActivityPub has been forced to acknowledge its existence, draw comparisons to it, and often been bridged to it. In fact, when Jack Dorsey fired off his famous tweet thread announcing Bluesky, he was definitely aware of ActivityPub, given that in a reply to a reply to that thread, he stated “ActivityPub is great.”&lt;/p&gt;
    &lt;p&gt;Because ActivityPub uses a federation model centered around small community servers, it has a lot of the benefits of centralized social media. For example, it makes it relatively easy to support private content, since it’s a push-based protocol - only those whose inboxes you push content to can view it (there’s also an “Everyone” option that makes your content fetchable, I think). This is also why the Fediverse has things like Follow Requests, server-to-server DMs (though your instance admin can view them - ActivityPub kind of assumes you trust them), and real blocks that mostly work.&lt;/p&gt;
    &lt;p&gt;However, many of the more collectivist choices made in ActivityPub were concluded to not be conductive to a “decentralized Twitter”, and both ATProto and Nostr exist in large part because of this. In fact, both ATProto and Nostr strayed from ActivityPub for the same reasons - identity is extremely tied to your initial server. There are good reasons for this, given that ActivityPub is largely used by smaller communities who federate with each other, but it does have an important consequence:&lt;/p&gt;
    &lt;p&gt;Your data is not really portable. You can move accounts to another server, and if your old server is well-behaved it can add a redirect to your new account, which will help automatically transfer your old social connections over to your new account, but this doesn’t include any of your data except your follows and followers, and falls apart if your old server goes offline, is adversarial to you or your current server, or in basically any situation where you can’t get that redirect.&lt;/p&gt;
    &lt;p&gt;There are many other philosophical differences between the ActivityPub camp and the Nostr and ATProto camp, but this one is the most important one, at least in my opinion - both ATProto and Nostr have sections explaining “Why not just go with ActivityPub?” that state this as their primary reason. Both ATProto and Nostr have real account portability by design.&lt;/p&gt;
    &lt;p&gt;Both of these protocols don’t have much in common with ActivityPub, so I won’t talk about ActivityPub too much here. But there is one older protocol that both of them extensively draw inspiration from…&lt;/p&gt;
    &lt;head rend="h3"&gt;Secure Scuttlebutt&lt;/head&gt;
    &lt;p&gt;This is where things start to get pretty interesting. In 2014, a New Zealand programmer named Dominic Tarr was living on a sailboat. As you might assume, such a life includes little internet, and when it comes, in sporadic bursts. Centralized social media, like Twitter, wants you to be connected at all times, scrolling your feed and looking at ads. Tarr didn’t want that. The result? He designed a protocol designed for offline-first, intentional, slow communication, free from Big Tech. Its name? Secure Scuttlebutt.&lt;/p&gt;
    &lt;p&gt;Scuttlebutt uses an append-only log of cryptographically signed messages. Your identity is an Ed25519 keypair and is pretty much tied to a single device. One consequence of this is that, as the Scuttlebutt developer docs themselves acknowledge, “If a user loses their secret key or has it stolen, they will need to generate a new identity, and tell people to use their new one instead.”&lt;/p&gt;
    &lt;p&gt;Because it’s an append-only log, every message must contain a reference to the previous message - a bit like a blockchain. That also means that deletes are straight-up impossible. This is also not necessarily a bad thing, just a trade-off.&lt;/p&gt;
    &lt;p&gt;Scuttlebutt started as a purely peer-to-peer protocol, using a gossip model - in fact, that’s where its name comes from; in sailor-slang, scuttlebutt means “water-cooler gossip”. The first popular Scuttlebutt client was an app called Patchwork, authored by Paul Frazee (keep this guy in mind, he’s gonna be important later), and initially the protocol and client often evolved together, adapting to each other’s needs.&lt;/p&gt;
    &lt;p&gt;By default, when you add to your append-only log, that addition only exists on your device; but the next time you connect to a peer running a Scuttlebutt client, your two clients will sync with each others’ logs, and then verify them against each others’ public keys. And to verify the newest part of a Scuttlebutt log, you need the whole log - this ensures that if someone gets part of your content, they get all of it.&lt;/p&gt;
    &lt;p&gt;But you don’t just sync each others’ content - your clients sync all the logs they have locally. That’s why it’s called the gossip model - once you put out a post, as long as you’re connected to a few peers every once in a while, your post will spread as fast as gossip to the friends of your friends. It usually takes time for that information to spread to everywhere, which keeps the pace of Scuttlebutt life somewhat slow and relaxed, with the most active communities being, again, small and tight-knit. Scuttlebutt is definitely not a global social network. The gossip model was driven by the social graph, allowing users to sync with others based on who they follow and who their connections follow. This mechanism relied on cloud bot users, known as “pubs,” acting as connectors and community hubs.&lt;/p&gt;
    &lt;p&gt;Scuttlebutt syncing took time due to the necessity of syncing all activity. Pubs played a crucial role in facilitating connectivity within the network, ensuring that users could discover others either by sharing a pub or by following users who were connected to them.&lt;/p&gt;
    &lt;p&gt;Scuttlebutt’s evolution was influenced by the desire for decentralized communication, distinct from the centralized nature of platforms like Twitter. It offered an alternative for those seeking intentional, offline-first communication free from the constraints of Big Tech. While initially designed for smaller, tight-knit communities, the ideas and learnings from Scuttlebutt inspired later attempts to build decentralized networks suitable for global networking.&lt;/p&gt;
    &lt;p&gt;So, now the stage is mostly set. Twitter was the first “global town square”, a social network connecting people and ideas worldwide - but not without a myriad of problems, which many concluded were due to its centralized nature. ActivityPub and Scuttlebutt (and others) experimented with decentralizing the social world, mostly with a focus on smaller communities, though as they evolved people tried to make them more suitable for global networking. Neither of them would prove viable for global social networks, but the learnings from them would help develop the next generation of social protocols.&lt;/p&gt;
    &lt;head rend="h3"&gt;Freeing the Bird&lt;/head&gt;
    &lt;head rend="h4"&gt;or, where ATProto and Nostr came from&lt;/head&gt;
    &lt;p&gt;All of this is important background for understanding the motivation behind these two protocols. Twitter started it all by showing us what microblogging at scale - a “global town square” - looks like. It showed us how many problems there are with it, and to some, that the only way to fix them is to remove corporate control. ActivityPub and Scuttlebutt showed us two very different ways of doing so, each with their own major benefits and major drawbacks. But there’s still a long way to go from these experiments, which were largely paving the way in the late 2010s, to where we are now, almost halfway into the third decade of the 21st century. To fill in these gaps, we can start towards the end of the second decade of the 21st century.&lt;/p&gt;
    &lt;p&gt;It wasn’t just people outside Twitter who were aware of the multitude of issues with Twitter - of course Twitter noticed them too. Twitter had started as a much more open company than it was at this point in December of 2019 - over the years, they’d taken, for a variety of reasons, a more centralized path, facing investor pressure for returns, and other such things. Twitter knew that, in the words of founder then-CEO Jack Dorsey, “centralized enforcement of global policy to address abuse and misleading information is unlikely to scale over the long-term without placing far too much burden on people.” Jack and the rest of Twitter drew the same conclusion as ActivityPub and Scuttlebutt had before - corporate control of social media was simply bad for everyone. Twitter was a company full of people who realized the service was just in a shitty position no matter how you looked at it, and who were doing everything in their power to keep things healthy despite it all - and they saw a way out: to build on, or build, an open protocol for a global social network. And for all the reasons we talked about before, about ActivityPub and Scuttlebutt, neither of those protocols were up to the task.&lt;/p&gt;
    &lt;p&gt;So the Bluesky initiative began. The early history of the project is much better documented elsewhere, but one of the most interesting things to come out of it at this early stage was an ecosystem review of existing decentralized protocols. It was authored by a Zcash developer named Jay Graber, who would go on to become CEO of Bluesky. It included contributions from several notable people in the decentralization space, including Christine Lemmer-Webber, co-author of the ActivityPub spec, Paul Frazee of Patchwork (and at the time now working on Beaker Browser and Dat), Whyrusleeping from IPFS, and Rabble of early Twitter (at the time working on planetary.social, a Scuttlebutt client). It lays out the state of numerous decentralized protocols, including ActivityPub and Scuttlebutt, and explains how user discovery, moderation, etc works in each of them.&lt;/p&gt;
    &lt;p&gt;At the end of all this ecosystem review, Bluesky concluded that none of these existing protocols was really suitable for their goal - a decentralized protocol Twitter, a global social network, could run on. So they decided to create their own - ATProto - and incorporated into a Public Benefit LLC to help achieve this goal. And when their initial team was hired, it included none other than Paul Frazee of Patchwork, in addition to Aaron Goldman, a former security engineer at Twitter, and Daniel Holmgren, an engineer with experience building on IPFS.&lt;/p&gt;
    &lt;p&gt;Now, while all of this was happening, a Bitcoin enthusiast under the pseudonym Fiatjaf was working on his own little thing. His idea was a non-peer-to-peer reimagining of Scuttlebutt and what it would take to make a similar protocol usable on a global scale. And on November 7th, 2020, the first basic working code for his idea of “Relays” quietly slipped onto the scene. Nostr’s initial description even cites Scuttlebutt as an inspiration - the main design differences between the two (at a high level) are that Nostr moves from a p2p network, with pubs as an afterthought, to a purely client-relay model, and that Nostr events are all separate units that do not form a chain.&lt;/p&gt;
    &lt;p&gt;His motivation for creating this protocol was, somewhat similarly to Bluesky, problems with Twitter. Bluesky was motivated by the idea that content moderation at scale is impossible to do well, and centralizing it in the hands of a single company was a bad idea. Nostr, meanwhile, views moderation itself as an enemy - as censorship that the protocol should be resistant to. While in reality, even Nostr has ultimately ended up exploring different forms of communal moderation, the primary motivation behind Nostr’s design choices is an idea of extremely high censorship resistance. This implies that the design, rather than optimizing for consistency, should optimize for availability - if someone wants to see your content, they should be guaranteed to be able to get it from somewhere. The protocol design is pretty conducive to this.&lt;/p&gt;
    &lt;p&gt;Both of these efforts were toiling away in the darkness, waiting for their moment in order to replace centralized social media with a decentralized future. Then in late 2022, something remarkable happened. Centralized social media fell prey to one of its prime weaknesses, right where everyone could see, thanks to one very famous billionaire. Elon Musk payed 44 billion dollars for Twitter, released the so-called “Twitter Files”, and Jack Dorsey, who had earlier kicked off the Bluesky initiative with 13 million dollars, put out a little manifesto in response, titled a native internet protocol for social media. Within a few hours, someone responded pointing him to the Nostr protocol, and he grew very interested, soon giving fiatjaf 14 Bitcoin to help fund Nostr development. A few months later, Bluesky launched their reference app for the AT Protocol. About a year later, Jack Dorsey left the Bluesky board, having chosen to focus on Nostr instead, as it aligned with his “free-speech-Bitcoin-vibes” ethos better. This was despite the fact that ATProto basically does everything he wants in a decentralized social protocol, but he prefers the more Bitcoin-y community of Nostr.&lt;/p&gt;
    &lt;p&gt;Okay, so that’s how we got here. Now we’ve arrived, back in the present. Let’s look at…&lt;/p&gt;
    &lt;head rend="h2"&gt;Where we are&lt;/head&gt;
    &lt;p&gt;Both Nostr and ATProto follow a similar pattern: adapting peer-to-peer data models to work in a client-server model (that isn’t quite federation). The peer-to-peer world had to deal with a unique problem: because there were no servers, there was no canonical source for data where you could go to verify its integrity. Thanks to the wonders of modern cryptography, efforts like Scuttlebutt, IPFS, and Dat all were able to use self-certifying data structures that could be verified independently of any third-party authority. A good example of this is a Merkle Tree, which is a data structure that ATProto also uses (be sure to watch that video, it’s very good and explains well why peer-to-peer networks need this).&lt;/p&gt;
    &lt;p&gt;As it turned out, these data structures and their benefits would help solve many of the problems the federated world faces. Specifically, the federated world, while no longer reliant on a single central server, often ends up simply shifting this reliance to smaller centralized servers that are the only canonical source for user data. When done correctly, applying peer-to-peer data models to the server would reduce this reliance and make data more independent of servers, while also allowing the big-world networking that only servers can achieve.&lt;/p&gt;
    &lt;p&gt;This sounds like a perfect solution, but it’s worth mentioning that it does have some important tradeoffs compared to a pure federation approach like ActivityPub’s. For example, while deletes are still possible on both protocols (though rather difficult on Nostr, which you might be able to piece together why), if someone has your data saved from before your deletion, it is much easier to prove that you said it and hold it up as yours than it is on a protocol that doesn’t have you cryptographically sign everything. And since both protocols heavily optimize for public content, things like Direct Messaging become much more difficult - in fact, on Nostr, DMs are public like everything else (their content is encrypted so no one else can read them). In general, trying to keep data private becomes extremely difficult; these protocols have delivery models which both center around the same self-certifying data being replicated in many places so anyone who wants it can get at it. With this, things like blocking other users become basically impossible, since there’s no canonical source to restrict content from.&lt;/p&gt;
    &lt;p&gt;Now let’s look at a few different protocol building blocks and how each protocol handles them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Identity&lt;/head&gt;
    &lt;p&gt;Identity in networks is a difficult problem. Ideally, you want identifiers to be human-meaningful - for example, a Twitter handle. If I see the Twitter handle @jack, I can be fairly sure that that’s Jack Dorsey. You also want them to be secure - only @jack should be able to create a post that says it’s from @jack, and I shouldn’t easily be able to take over the account @jack without gaining access to some kind of key. And you probably also want them to be decentralized, so that @jack isn’t beholden to anyone else to hold his identity, and can move around.&lt;/p&gt;
    &lt;p&gt;Unfortunately, it’s not easy to have all three of these nice properties - Secure, Human-Meaningful, and Decentralized - at once. Almost every system which tries to have all three has to end up compromising on one of them. This trilemna is known as Zooko’s Triangle. As examples:&lt;/p&gt;
    &lt;p&gt;Twitter usernames are secure - I can’t just put out a tweet that looks like it’s from @jack - and human-meaningful - a guy with the handle @jack is probably named Jack. But they’re obviously not decentralized - they are all reliant on Twitter’s servers, and it’s Twitter who decides that @jack points to Jack Dorsey’s account. If they, say, wanted to rebrand to X, and someone was using the @x handle, Twitter could easily take it from them and make their own handle @X.&lt;/p&gt;
    &lt;p&gt;Scuttlebutt, meanwhile, has identity that’s decentralized - it’s just your private key, essentially a random number - and your public key, the part other people can see. It’s also secure - I need to actually have your private key to pretend to be you. But a public key, which is also just a number (derived from your private key), is not very human meaningful.&lt;/p&gt;
    &lt;p&gt;If you’re familiar with ActivityPub, you might argue that ActivityPub usernames are all three. This isn’t really true - ActivityPub usernames behave like Twitter usernames, except instead of just one big central Twitter server deciding what username points to what, this is handled in smaller centralized servers which federate with each other.&lt;/p&gt;
    &lt;p&gt;Nostr and ATProto also experience this problem, and they both share a few views around identity, listed out here so each one corresponds to a side of Zooko’s Triangle:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Your identity should not be permanently tied to a single server - Decentralization&lt;/item&gt;
      &lt;item&gt;Your data should be cryptographically verifiable as coming from your identity - Security&lt;/item&gt;
      &lt;item&gt;There are two “layers” of identity - a permanent computer-oriented one and a changeable human-friendly one - Human-Meaningful.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even with these similarities, how that really plays out in both protocols looks extremely different. The idea that your data is cryptographically verifiable as yours implies a keypair somewhere. In Nostr, that’s exactly it - your identity is just a secp256k1 keypair. Nothing more, nothing less.&lt;/p&gt;
    &lt;p&gt;That sounds very much like the permanent computer-oriented layer of identity. So the human-friendly identity is handled by a Nostr event of the profile type - this contains stuff like your bio, display name, and avatar. There’s also NIP-05, which allows using the .well-known/nostr.json path on a domain to get email-style usernames, like &lt;code&gt;jack@cash.app&lt;/code&gt; - and this includes a special case, &lt;code&gt;_@domain&lt;/code&gt;, that gets treated by clients as just &lt;code&gt;@domain&lt;/code&gt;. When you &lt;code&gt;@mention&lt;/code&gt; someone in a Nostr note, it’s just &lt;code&gt;@&amp;lt;their public key&amp;gt;&lt;/code&gt;, which clients then simply display as their display names. Notably, having either a display name or even a real NIP-05 username is completely optional under Nostr, and your public key really is your identity.&lt;/p&gt;
    &lt;p&gt;This looks like mostly a success, at least in terms of taking those views and treating them as criteria. Nostr actually takes the first point - identity should not be permanently tied to a single server - and goes slightly further: in Nostr’s model, where your identity really is just your keypair, no servers are involved in identity at all. Why would you want that? A major benefit of this approach is that if any of the servers involved in the system goes down or is no longer friendly with you, your identity doesn’t even need to be “recovered” - it’s just there, the same as before. This works well with the Nostr Relay model, which we’ll discuss in the next section.&lt;/p&gt;
    &lt;p&gt;The drawbacks of this approach are the same as Scuttlebutt. Thanks to the relay model, your identity is no longer tied to a single client on a single device - you can easily move around, between relays, between clients, between devices. This, by itself, for most people, is a good thing, but it comes with an entirely different kind of problem:&lt;/p&gt;
    &lt;p&gt;Managing a cryptographic keypair is simply not very user-friendly. You simply can’t expect most people to write it down and keep it in a safe place or even take the time to understand what it means. People expect username-password systems, and sure, newer technology like passkeys is actually more secure and potentially easier - but that comes with actual benefits over username-password for most people! Managing a keypair is not only unfriendly, it’s incredibly risky. Since the entirety of your identity is your keypair, and to sign in to Nostr clients is to give them your private key - well, you can probably see where this is going. And again, since your identity is just your keypair, just like with Scuttlebutt, if an attacker gets a hold of your private key, that identity is gone. No longer yours. There’s no-one you can go to for help, no-one who can recover that account, no password reset link.&lt;/p&gt;
    &lt;p&gt;That sounds very negative, but it is worth noting that at least for web Nostr clients, there is a (relatively) good solution to the sign-in problem - NIP-07. In the NIP-07 world, you don’t give every client your private key - you give it once to a browser extension, and then every time a web client wants to do something on your behalf, instead of directly using your private key to sign messages etc, it delegates that to your trusted extension. This is a lot better than giving your private key out to every client that has some cool new feature you want to try. Of course, this doesn’t help with recoverability - if you lose your private key, whether to your memory or to an attacker, it’s still gone. There are attempts to solve this, too, which I’ll talk about in “Where we’re going” because it has interesting future implications.&lt;/p&gt;
    &lt;p&gt;ATProto looks at things a little differently. Because of the aforementioned difficulties involved with users managing their own private keys, Bluesky chose to have your signing keypair live on a server - your Personal Data Server, or PDS. Your PDS is responsible for serving your Data Repository to other services on the network, and serves as more-or-less the canonical source for your content. However, your Repository is fully self-certifiable (that means someone can check whether or not you created the content in a copy of your Repo without needing a third party to verify), and so is not permanently tied to your PDS. This is because your PDS is not the canonical source for your identity - but your identity is also not something as small as a keypair here, and does not live entirely client side.&lt;/p&gt;
    &lt;p&gt;Instead, ATProto uses their own homegrown DID (Decentralized IDentifiers, W3C spec with the aim of helping, well, decentralize identity) method called did:plc, for PLaCeholder. Why is it named “placeholder”? Well, because as of now, it’s centralized. That’s right, the supposedly “Decentralized” Identifier is centralized - and Bluesky actively doesn’t want it to be that way. did:plc was initially intended to be a placeholder until a decentralized method was able to meet their requirements - “a strongly consistent, highly available, recoverable, and cryptographically secure method with fast and cheap propagation of updates”. did:plc has all of these at one major cost - it’s centralized. However, the data in a did:plc is self-certifying (you don’t need to trust/rely on plc.directory to verify the information), so it’s conceivable for it to become more decentralized in the future. (You can also use a did:web, which removes this centralization but forces you to manage everything yourself and relies permanently on your control of a web host on a domain, thus removing most of PLC’s benefits. This is pretty niche, so I won’t talk about it in detail here.)&lt;/p&gt;
    &lt;p&gt;A did:plc: contains two public keys - your rotation key and your signing key. This signing key is the aforementioned key that the PDS uses to sign your data. The rotation key is important because it manages your did:plc: and thus is needed to sign updates to your DID document, such as when migrating PDSes. The canonical source for your current PDS, valid signing key, handle, and rotation keys (which can also be rotated) are all your DID document. In this way, a DID serves as a “Theseus Identity”, an idea Aaron Goldman laid out well in this YouTube video.&lt;/p&gt;
    &lt;p&gt;The canonical source of your identity is your DID doc, and all the information in it, i.e. your handle and current PDS must be a two-way connection - your handle is a domain with a dns txt record or ./well-known/atproto-did that must point to your DID, providing two way verification, and whatever PDS your DID document points to must actually have your account on it. Meanwhile, the PDS handles data, and implements a standard, user-friendly login system, and signs your updates with your key on the server side.&lt;/p&gt;
    &lt;p&gt;Here, there was a trade-off between principles of security, recoverability, and user-friendliness, and a principle of max-decentralization - low-friction identity, with no centralizing points of control at all, extreme takeover resistance. Notice that&lt;/p&gt;
    &lt;p&gt;Where ATProto chooses user-friendliness, Nostr chooses max-decentralization. This is a trend that repeats in many other parts of each protocol’s design, as we’ll see.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data&lt;/head&gt;
    &lt;p&gt;In the traditional federated world of protocols like ActivityPub, there had never been much of an emphasis on data, and the formats and structures it’s stored in. The federated world thought much more about how servers should communicate messages rather than how they should store data - this difference is laid out well by Bryan Newbold, who incidentally now works on protocol design at Bluesky. This emphasis on communication standards rather than data standards is a big part of why there’s no standard “fediverse repo” that you can transfer between servers, and other such problems in the federated world.&lt;/p&gt;
    &lt;p&gt;The peer-to-peer world, as we looked at earlier, couldn’t afford to define pure transport protocols - they had to design standardized data structures that were self-certifying and self-contained. An example of such a data structure is a blockchain, and indeed, the peer-to-peer community and the blockchain community learned much more from each other than either of them and federation did from each other.&lt;/p&gt;
    &lt;p&gt;This was the status quo until ATProto and Nostr came along and broke the mold by bringing these self-certifying data structures into the client-server world. They both use asymmetric cryptography to make this data self-certifying, but the similarities basically end there.&lt;/p&gt;
    &lt;p&gt;In the Nostr model, servers are dumb. They have basically one job - transmit data. There’s only one kind of server in Nostr - a Relay, and a Relay does only three things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Receive data to store&lt;/item&gt;
      &lt;item&gt;Return that data when asked for it&lt;/item&gt;
      &lt;item&gt;Provide a continuous stream of the data being placed on that Relay&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notably, Relays store data. Data is placed on Relays. All this data is created on the client-side. Relays don’t manage identity or any of that. Your keys live with your client, and it’s your client who signs your &lt;code&gt;events&lt;/code&gt; (a piece of data in Nostr terminology.) When you fetch data from a Relay, it comes back with signatures and all - which, guess what, your client verifies. Your client almost operates under the assumption that Relays will try to do weird stuff, people will submit fake events, etc - and so Nostr removed the requirement of trust, by making clients verify everything themselves. A trade-off!&lt;/p&gt;
    &lt;p&gt;Nostr, by optimizing for censorship resistance, needs to remove as much rigidity from its design as possible. Data needs to be cheap to create and transmit and store. So Nostr events all exist as individual units following a fixed JSON format with a strict signing convention. Unlike Scuttlebutt, these events don’t need to form a chain - they are purely self-contained. Like your identity, there’s no canonical source for them either - by design, you’re supposed to be able to get them from pretty much any relay that has them. When you create the event, your client signs it and then just publishes it to as many relays as possible, from where it will circulate into other Relays, consuming clients will republish them, etc. Because they are signed against your public and are fully self-contained, it’s trivial to verify them too, removing the necessity of trust in the Relay you get the event from.&lt;/p&gt;
    &lt;p&gt;ATProto data is also very portable, but it is slightly more rigid than Nostr data is. Instead of using these one-off events which are fully self-certifying, ATProto stores your data as records in what it calls a repo. These records live under a collection like &lt;code&gt;app.bsky.feed.post&lt;/code&gt; and are given an &lt;code&gt;rkey&lt;/code&gt; (record key). Together, this forms a URI for any given record that looks like &lt;code&gt;at://did/collection/rkey&lt;/code&gt;. Importantly, records are mutable, unlike nostr events, and the contents an at:// uri points to may change. However, all the commits to your repo, which contain changes like record creation, editing, and deletion, are content-addressed using a CID, and these are immutable, and are all signed using your repo’s signing key (the one from your DID doc, remember?) Your commits can also optionally form a chain if you want, but when they don’t, deletes are easier. (If all of that flew over your head, don’t worry. All you need to know is that ATProto allows deletes and edits, while Nostr can’t.) Because your data all lives in this repo, unlike Nostr, ATProto actually has a canonical source for your data.&lt;/p&gt;
    &lt;p&gt;There’s also a single place where your repo lives, instead of being scattered as a bunch of events across Relays like in Nostr. Your repo lives in your Personal Data Server - as the name implies, a PDS is designed to store your personal data. While Nostr Relays are dumb pipes, PDSes are more like a user agent, which really performs almost all actions on the user’s behalf. It’s responsible for signing and storing commits to your repo and wrapping them in a nice API that’s easy for clients to use.&lt;/p&gt;
    &lt;p&gt;Actually, we should probably take a minute just to talk about deletes and edits. When I said Nostr can’t allow deletes and edits, that wasn’t completely true: Nostr does have a way to request deletes from Relays, which most but not all Relays support, but the real trouble is figuring out what a delete even means (and edits are straight-up impossible since Nostr event IDs are fully content-addressed). Nostr’s model is fundamentally based on an idea of events flowing from the creator into Relays, which then flow into other people’s clients, which cache them and republish them to other Relays, and so on. An event doesn’t have a location to be deleted from - it could be (and in Nostr’s model, should be!) anywhere and everywhere.&lt;/p&gt;
    &lt;p&gt;In ATProto, your repo actually has a place where it lived - your PDS, as specified in your DID doc. And at:// uris are mutable, so a commit can actually change the content it points to. Deletes remove content from your repo - although anybody who has a copy of your content pre-delete will still have it and can very easily cryptographically prove that it’s your content.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trust&lt;/head&gt;
    &lt;p&gt;Nostr and ATProto have relatively similar approaches to trust, though with some important differences. Nostr trusts nobody, and is built accordingly, with clients verifying everything themselves. ATProto assumes you trust somebody, but lets you choose whom you trust, and provides the mechanisms needed to verify that trust is placed correctly (although this could be improved).&lt;/p&gt;
    &lt;p&gt;Nostr, as mentioned earlier, was designed to basically eliminate the necessity of trust in the first place. Because everything is verified client-side, and essentially functions as a bunch of self-authenticated units of data traveling between relays and clients, there really is no one to trust. Relays can choose not to carry content, but other relays might have them instead. However, the fact that all data moves as individual units means that it would be harder to spot if only certain events are available.&lt;/p&gt;
    &lt;p&gt;Since every user is assumed to be pointing their client at more than one relay, it doesn’t really matter if one relay chooses not to carry someone’s content; there’s a high likelihood another one is. If many relays agree to hide something from the network, then it won’t show up, but that’s pretty unlikely to happen. As for trusting the authenticity of the content delivered by the relay, because it’s cryptographically verifiable as coming from the attached pubkey, any shenanigans will be spotted quickly. And verifying a pubkey’s identity is done by attaching it to a trusted NIP-05, i.e. @jack@cash.app or @jb55.com.&lt;/p&gt;
    &lt;p&gt;ATProto isn’t that different, all things considered, but there’s multiple other hops between the source of data and the client you view it in. Each ATProto PDS puts out a cryptographically verifiable stream of commits being pushed to repos on the PDS, carrying every bit of data to the subscribers, called the firehose. Because there are a lot of PDSes, an optimization also called a Relay was introduced, which basically aggregates PDS firehoses into its own giant firehose. In a way, this Relay could be considered its own centralization point where bad untrustworthy things could happen, but once more than one Relay exists this should be less of a problem. At the Relay and PDS, everything is cryptographically verifiable, and as a bonus because of ATProto’s repo structure, you can tell if you’re not getting the whole picture.&lt;/p&gt;
    &lt;p&gt;After the Relay, things get a bit murkier, because as an optimization ATProto applications use something called the AppView. The AppView reads in the firehose from the Relay constantly and pieces it together into fully hydrated and speedy APIs which make clients’ lives much easier. The thing about the AppView is that it’s basically centralized, and though it’s not super difficult to spot inconsistencies between what the AppView gives you and the true state of the network, the AppView doesn’t even provide the cryptographic signatures that were passed into it, making its trustworthiness a bit murky at some unknown time in the future, at which point other contenders will hopefully exist to replace it, based on analysis of which one is more trustworthy by comparing the data each AppView gives you with what actually exists on the Relay and PDSes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Privacy&lt;/head&gt;
    &lt;p&gt;Everything is completely public on both protocols and in fact being actively broadcasted to loads of consumers, not just sitting around waiting to be stepped on and found. Nothing you do is really hideable from anyone.&lt;/p&gt;
    &lt;p&gt;However, at least on ATProto, there have been attempts to add some semblance of privacy to the network. For example, there are AppView-enforced blocks, but they can be bypassed very easily. There is also a setting which asks the client to not show your posts to logged-out users, but this is superficial at best, since only some clients really follow it anyways, and the “official” popular client does so it does kind of work. But overall these measures both run a risk of making people feel like their posts and other activity are hidden and safe, lulling them into acting with less precaution than they should, especially since there is a lack of user awareness around the all-public nature of data on the network.&lt;/p&gt;
    &lt;p&gt;No such attempts have been made on Nostr. This is on the one hand unfortunate, but on the other hand possibly better since it is more honest about the true nature of how public everything is on the network.&lt;/p&gt;
    &lt;head rend="h3"&gt;Development&lt;/head&gt;
    &lt;p&gt;Due to the Bluesky devs’ past experiences with developing on peer-to-peer and federated protocols, many of them felt burnt by a Scuttlebutt-and-Nostr-style approach to development, where specifications were loose and implementations varied wildly. Because of these past experiences, Bluesky chose to go with a slightly more slow, intentional, and centralized development model. The protocol is mostly developed within Bluesky the company, though often adapts to the needs and feedback from the wider ATProto developer community, and community members often contribute to both the protocol and the clients. The rollout of core features like federation and stackable moderation has also been much more slow on ATProto than similar features in Nostr implementations, because in general Bluesky prefers to take their time and “get it right” and standardized before letting things out into the wild. Also, despite the existence of third-party clients, the “official” Bluesky app and service is still the most popular one by a huge margin, due to its being the default (and basically only) inroad into the protocol and ecosystem. There are other up-and-coming AT Protocol projects that aren’t just Twitter clones, like WhiteWind for blogging, but overall the ecosystem remains sparse compared to Nostr.&lt;/p&gt;
    &lt;p&gt;Nostr, meanwhile, takes the same approach as these previous projects - the protocol itself just exists, very small, letting anyone expand on it. When an extension wants to become standardized, it’s reviewed by a small team including fiatjaf and a few others, and becomes part of the NIPs repository (Nostr Implementation Possibilities). This is basically classic BDFL open-source. However, clients and relays are free to try their own wild things without being “official” NIPs, and any NIP proposal must be adopted by a few clients and relays before it can be considered for “official” status. So it’s a much wilder, freer ecosystem so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Applications&lt;/head&gt;
    &lt;p&gt;One of the places where ATProto and Nostr differ greatly is their model for building applications.&lt;/p&gt;
    &lt;p&gt;ATProto takes the AppView approach. An AppView is basically a service that reads in the firehose of all the public data on the network, and indexes it into hydrated “views” as an API which clients then use. AppViews are pretty resource-intensive to run and functionally centralized in nature. If you want to make a new ATProto app, you first design your schemas for content in a DSL called Lexicon. Then you make a client that can start publishing your record type, and retrieving and displaying it. For the retrieval and displaying, you create an AppView which monitors the firehose for your record types and indexes them into hydrated views, which your client can then fetch from and display nicely and neatly. This is, for example, how the Bluesky app can show a list of users who liked a post; because instead of the client having to crawl the entire network itself and figure out which likes are for the post you just viewed and then get the DID and fetch each of that user’s profiles and whether or not you’re following them by checking your own repo, and whether or not they’re following you by looking all over their follow lists, the client just makes one HTTP request and makes the result human-readable. Nice and fast. Of course, the relief that comes to the client means a lot of responsibility is thrusted onto the AppView, which becomes very resource-intensive to run.&lt;/p&gt;
    &lt;p&gt;The first steps to the Nostr model look similar at first, but rapidly diverge. With Nostr, you also start with defining event kinds, and then creating a client which can publish them, and then adding fetching and displaying. The key difference is in how events are fetched. With ATProto, you write an AppView to do the heavy lifting; with Nostr, the heavy lifting is shared between the Relay and the Client. When defining your event kinds, you make sure to also define how to use the “tags” field for that event kind, which is an array of key-value pairs with single letter keys which are indexed by the relays the events are sent to. Basically, if you want to do any kind of linking between events, or inserting any kind of indexable data, that’s where you want to do it.&lt;/p&gt;
    &lt;p&gt;Then for the fetching of the data, we use Nostr’s filtering system. With Nostr, there are two kinds of communication between the client and the relays; publishing events, which pushes the signed client-created event into the relay’s data store, and subscription. Subscription is the interesting part we’re looking at here.&lt;/p&gt;
    &lt;p&gt;Nostr clients can request a subscription to a stream of events from the relays they’re connected to, and this stream subscription can have filters attached. A filter is fully specified using the following attributes, all optional:&lt;/p&gt;
    &lt;code&gt;{
  "ids": &amp;lt;a list of event ids&amp;gt;,
  "authors": &amp;lt;a list of lowercase pubkeys, the pubkey of an event must be one of these&amp;gt;,
  "kinds": &amp;lt;a list of a kind numbers&amp;gt;,
  "#&amp;lt;single-letter (a-zA-Z)&amp;gt;": &amp;lt;a list of tag values, for #e — a list of event ids, for #p — a list of pubkeys, etc.&amp;gt;,
  "since": &amp;lt;an integer unix timestamp in seconds, events must be newer than this to pass&amp;gt;,
  "until": &amp;lt;an integer unix timestamp in seconds, events must be older than this to pass&amp;gt;,
  "limit": &amp;lt;maximum number of events relays SHOULD return in the initial query&amp;gt;
}
&lt;/code&gt;
    &lt;p&gt;By adding multiple filters, you can get all the events matching any of the filters. By adding multiple attributes to a single filter, you add multiple conditions that all have to be fulfilled for events to make it through that filter. Filters are expressly the mechanism for fetching content, since subscriptions are supposed to start by backfilling everything that meets the criteria, and then pushing any new events that meet the filters’ requirements to the client.&lt;/p&gt;
    &lt;p&gt;By studying the filter specification, it’s clear that basically every behavior of ATProto AppViews can be recreated through filters on the client-side, knowing how tags allow extensibility as well. There’s an obvious cost though: clients must be very complex and do a lot of work themselves, and for big events duplicating a lot of effort that could be handled by something akin to an AppView. The benefit of this is that it is very generic and means that any relay can generally be used for any functionality since everything you need is baked into the core protocol, and the speed of development is basically only constrained by the client, and not an AppView. And by not spending any resources on building a giant indexer yourself, you basically shift the cost onto the Relays instead. It’s another example of the more “bazaar” philosophy of Nostr compared to a more “cathedral” approach from ATProto.&lt;/p&gt;
    &lt;p&gt;So, all in all, this gives a pretty good picture of where the two protocols are now. But exciting things are on the horizon for both. We’re heading into uncharted territory…&lt;/p&gt;
    &lt;head rend="h2"&gt;Where we’re going&lt;/head&gt;
    &lt;p&gt;When Jack Dorsey wrote a native internet protocol for social media, he wrote that “As far as the free and open social media protocol goes, there are many competing projects: @bluesky is one with the AT Protocol, nostr another, Mastodon yet another, Matrix yet another…and there will be many more. One will have a chance at becoming a standard like HTTP or SMTP.”&lt;/p&gt;
    &lt;p&gt;That’s one way of thinking about it, as a competition for the final spot of “the standard for social”. But as you’ve probably noticed from reading this post up to here, I don’t really agree with this viewpoint. ATProto, Nostr, ActivityPub, Scuttlebutt, Matrix, IPFS, Dat, Holepunch, and others all share similar goals, yet have vastly different perspectives about how to accomplish them. Maybe these different perspectives will all lose! Maybe, as Jack says, one of them will win, becoming a standard that everyone adopts. Or maybe they will all learn from each other and slowly begin to converge. And it’s not hard to make the case that that last possibility will happen for at least two of these protocols - of course, Nostr and ATProto. In fact, that’s already happening.&lt;/p&gt;
    &lt;head rend="h3"&gt;Convergence&lt;/head&gt;
    &lt;p&gt;Because a lot of core ideas in the protocols were already very similar, they can quite easily borrow ideas from each other in order to improve themselves. By making nearly opposite compromises, they now face roughly opposite problems as well - but often, the other protocol already has a solution waiting for them. So first let’s look at some of the ways Nostr is becoming more like ATProto.&lt;/p&gt;
    &lt;p&gt;First, the idea of keys in a server, instead of purely client-side. As mentioned earlier, one of the dangers of Nostr keys is that by giving them to lots of random clients you try, they might accidentally end up in the hands of bad actors. One of the solutions to this was NIP-07 browser extensions; another one is the idea of an NSecBunker, for Nostr Secret Key Bunker. The idea is that this is a server, similar to a PDS, which holds your Nostr private key, and when your client wants to sign an event, it makes a request to your NSecBunker to sign that event using your private key, which stays safe in your Bunker. These requests usually are authenticated using measures like OAuth. It allows Nostr to bring back at least one part of the user experience people are familiar with.&lt;/p&gt;
    &lt;p&gt;Another idea that Nostr is ending up trying is something similar to AppViews. This is particularly divisive within the community, with many feeling that only the relay-based filtering mechanisms should be used to build clients. But because this is often inefficient, clients like Primal have begun doing their own pre-indexing of many users and posts in order to improve their UX. Unfortunately, Primal’s is proprietary, and only Primal can interact with it, due to the lack of any built-in support for AppView-style services in the Nostr protocol, vs. ATProto’s numerous mechanisms to provide explicit support for this use case.&lt;/p&gt;
    &lt;p&gt;Meanwhile, some Nostr ideas are naturally going to the ATProto world as well. The idea of keys directly owned by the users has long been floated, and at this point developers can get control of their did:plc and its rotationKeys (fun fact: I set one of my plc rotationKeys to my Nostr pubkey). Unfortunately no nice UI exists for this yet. And as for signing keys, with commits that could be pushed to a PDS instead of made there, that would rely on a PDS supporting this use case. No PDS implementation currently supports this, but there is one in development which hopes to at some point ;)&lt;/p&gt;
    &lt;p&gt;Another idea which I hope to see adopted in the ATProto world is something similar to Nostr’s filters model. While the AppView model is nice for production apps, something like Nostr filters could help a lot early in development to just play with an idea and try it out. And it could help those with concerns about the trustworthiness of AppViews quickly verify it against certain queries. You can do a shocking amount with backlinks alone.&lt;/p&gt;
    &lt;p&gt;Of course, the slow convergence of both protocols isn’t the only way the divide between them is being bridged…&lt;/p&gt;
    &lt;head rend="h3"&gt;Bridging&lt;/head&gt;
    &lt;p&gt;Recently, Bridgy Fed started bridging the Fediverse and the ATmospherewith each other. For a while, services like Mostrhave been bridging the Fediverse and Nostr with each other. Now, if you visit the Mostr homepage and scroll down, you can probably see where this is going…&lt;/p&gt;
    &lt;p&gt;Soon after Bridgy Fed started bridging the Fediverse and the ATmosphere, Nostr users experimented with this to bridge between Nostr and Bluesky. Very much an indirect hack, but also a glimpse at the future.&lt;/p&gt;
    &lt;p&gt;One of the most important promises of decentralized social media was that no matter what service you signed up on and post on, you would be able to see content from and interact with anyone, no matter which service they used either. Now, all this would work, if every service signed on to the same decentralized social protocol. However, instead, we have many, and none of them show much of a sign of becoming the singular standard for social media. Instead of Jack’s vision of one winner, bridges offer a vision of a world where every protocol can win, and it truly won’t matter which protocol your service uses, either.&lt;/p&gt;
    &lt;p&gt;While the bridging I talked about above was very indirect, Bridgy Fed itself may soon have native Nostr support. Soon all three major decentralized protocols may be able to talk to each other, and easily too.&lt;/p&gt;
    &lt;p&gt;So. Let’s recap what we’ve been through in this post so far. In the beginning, there was Twitter. Twitter’s problems caused them to look to decentralization as a way to make social media more fair. This caused many new decentralized protocols to emerge, taking inspiration from older ones. Of these new protocols, two of them, Nostr and ATProto, evolved in similar directions, yet unaware of each other made many opposite compromises. And now they are evolving back towards each other, converging in potentially very interesting ways, with bridging offering to make social media not just platform- but protocol-agnostic.&lt;/p&gt;
    &lt;p&gt;The future is looking good for decentralized social media.&lt;/p&gt;
    &lt;p&gt;You can join the conversation on Bluesky here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Comments from Bluesky:&lt;/head&gt;
    &lt;p&gt;Or on Nostr:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45556763</guid><pubDate>Sun, 12 Oct 2025 09:24:43 +0000</pubDate></item><item><title>Show HN: I built a simple ambient sound app with no ads or subscriptions</title><link>https://ambisounds.app/</link><description>&lt;doc fingerprint="b7ff85d8f21c8a02"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ambi&lt;/head&gt;
    &lt;head rend="h1"&gt;Ambi&lt;/head&gt;
    &lt;head rend="h1"&gt;Ambi&lt;/head&gt;
    &lt;head rend="h2"&gt;Relax, focus and sleep with ambient soundscapes&lt;/head&gt;
    &lt;head rend="h2"&gt;Relax, focus and sleep with &lt;lb/&gt;ambient soundscapes&lt;/head&gt;
    &lt;head rend="h2"&gt;Relax, focus and sleep with &lt;lb/&gt;ambient soundscapes&lt;/head&gt;
    &lt;head rend="h1"&gt;Mix your perfect soundscape&lt;/head&gt;
    &lt;head rend="h1"&gt;Mix your perfect soundscape&lt;/head&gt;
    &lt;head rend="h1"&gt;Mix your perfect soundscape&lt;/head&gt;
    &lt;head rend="h2"&gt;Blend multiple sounds together with volume control for each individual sound&lt;/head&gt;
    &lt;head rend="h2"&gt;Blend multiple sounds together with volume control for each individual sound&lt;/head&gt;
    &lt;head rend="h2"&gt;Blend multiple sounds together with volume control for each individual sound&lt;/head&gt;
    &lt;head rend="h1"&gt;Play for as long &lt;lb/&gt;as you like&lt;/head&gt;
    &lt;head rend="h1"&gt;Play for as long &lt;lb/&gt;as you like&lt;/head&gt;
    &lt;head rend="h1"&gt;Play for as long &lt;lb/&gt;as you like&lt;/head&gt;
    &lt;p&gt;Set a timer or let your mix play through the night&lt;/p&gt;
    &lt;p&gt;Set a timer or let your mix play through the night&lt;/p&gt;
    &lt;p&gt;Set a timer or let your mix play through the night&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45558611</guid><pubDate>Sun, 12 Oct 2025 14:49:50 +0000</pubDate></item><item><title>Schleswig-Holstein completes migration to open source email</title><link>https://news.itsfoss.com/schleswig-holstein-email-system-migration/</link><description>&lt;doc fingerprint="6b5b391b3d96b4a7"&gt;
  &lt;main&gt;
    &lt;p&gt;European nations have generally been more progressive in adopting open source solutions for government operations. Sure, regressive proposals like the EU Chat Control bill make headlines, but there's genuine progress happening too.&lt;/p&gt;
    &lt;p&gt;The German state of Schleswig-Holstein is back in the news for its open source efforts. This time, it's their email system that's undergone a complete transformation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Microsoft Booted Out, Again&lt;/head&gt;
    &lt;p&gt;Schleswig-Holstein has successfully migrated (in Deutsch) its entire state administration email system from Microsoft Exchange and Outlook to open source alternatives, Open-Xchange and Thunderbird. The German state completed the transition on October 2, 2025, after a six-month process.&lt;/p&gt;
    &lt;p&gt;The migration affected around 30,000 employees across various government departments. This includes the State Chancellery, ministries, judiciary, state police, and other state authorities. Over 40,000 mailboxes containing more than 100 million emails and calendar entries were moved to the new system.&lt;/p&gt;
    &lt;p&gt;The state has adopted Open-Xchange as its email server solution and Thunderbird as the email client.&lt;/p&gt;
    &lt;p&gt;Of course, the transition wasn't without challenges. Digitization Minister Dirk Schrödter previously acknowledged problems during migration to open source software, including downtime and delays in email traffic. Despite these hurdles, this particular move has now been completed successfully.&lt;/p&gt;
    &lt;p&gt;Plus, this switch fits into Schleswig-Holstein's broader open source strategy that has been in development for several years. The state began rolling out LibreOffice as its standard office software last year, gradually replacing Microsoft Office across all state computers.&lt;/p&gt;
    &lt;p&gt;Dirk also emphasized that:&lt;/p&gt;
    &lt;quote&gt;We are real pioneers. We can't fall back on the experience of others –, there is hardly a comparable project of this magnitude anywhere in the world.&lt;lb/&gt;In future, we will be able to use our experience from data analysis to monitoring in the data centre to help others and support them when they embark on the path that we are currently the first to take.&lt;/quote&gt;
    &lt;head rend="h3"&gt;My Thoughts&lt;/head&gt;
    &lt;p&gt;Well, I like what I see here. Not many governments around the world care about open source software, unless it is about optics, of course. But when concrete steps are being taken to make good on past claims, who am I to complain?&lt;/p&gt;
    &lt;p&gt;Via: heise online&lt;/p&gt;
    &lt;p&gt;Suggested Read 📖&lt;/p&gt;
    &lt;p&gt;- Even the biggest players in the Linux world don't care about desktop Linux users. We do.&lt;/p&gt;
    &lt;p&gt;- We don't put informational content behind paywall. Your support keeps it open for everyone. Think of it like 'pay it forward'.&lt;/p&gt;
    &lt;p&gt;- Don't like ads? With the Plus membership, you get an ad-free reading experience.&lt;/p&gt;
    &lt;p&gt;- When millions of AI-generated content is being published daily, you read and learn from real human Linux users.&lt;/p&gt;
    &lt;p&gt;- It costs just $2 a month, less than the cost of your favorite burger.&lt;/p&gt;
    &lt;p&gt;Become a Plus Member today and join over 300 people in supporting our work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45558635</guid><pubDate>Sun, 12 Oct 2025 14:53:45 +0000</pubDate></item><item><title>Addictive-like behavioural traits in pet dogs with extreme motivation for toys</title><link>https://www.nature.com/articles/s41598-025-18636-0</link><description>&lt;doc fingerprint="37a99a5289210fed"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Behavioural addictions, characterised by compulsive engagement in rewarding activities despite adverse consequences in the long term, are more heterogeneous and less well-understood than substance addictions, and there is a relative lack of translational research. This study investigates “excessive toy motivation” in domestic dogs as a potential parallel to behavioural addictions in humans. Employing a combination of a behavioural test and an owner questionnaire, we examined whether a subset of highly play-motived dogs meet key behavioural addiction criteria, including craving, salience, lack of self-control, and mood modification. Data from 105 highly play-motivated dogs revealed that 33 subjects exhibited behaviours consistent with addictive-like tendencies, including an excessive fixation on toys, reduced responsiveness to alternative stimuli, and persistent efforts to access toys. Owner-reported behaviours not only corroborated these findings but also demonstrated significant associations with behavioural test scores. Our results highlight parallels between excessive toy motivation in dogs and human behavioural addictions, with dogs as the only non-human species so far that appears to develop addictive-like behaviours spontaneously without artificial induction. This exploratory study provides foundational insights and proposes future research directions that have the potential to significantly deepen our understanding of the psychological mechanisms underlying behavioural addictions across species.&lt;/p&gt;
    &lt;head rend="h3"&gt;Similar content being viewed by others&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;What is play? Why do many large-brained mammals engage in play throughout their lives? And what makes playing potentially addictive? Despite numerous publications on play and its possible functions, play has remained somewhat of a mystery1, being associated with no immediate adaptive function, although it has been suggested to allow animals to practice species-typical behaviours such as hunting, mating, or fighting with a competitor in a non-serious context1. Notwithstanding, play behaviour is ubiquitous among (at least young) mammals and some birds2,3, and in large-brained species in particular – from humans to dogs – it persists throughout life4,5. Still, no unified definition of play exists to date6, although there is some agreement that, at a proximate level, play makes us feel good7. Even in non-human animals, observers will often agree that playful activities look like fun7, with neurotransmitter systems mediating the rewarding aspects of play (opioids, cannabinoids and dopamine)8,9 appearing to be highly conserved across mammalian taxa10.&lt;/p&gt;
    &lt;p&gt;Bateson (2014) proposed a set of characteristics that are generally accepted to define play: it is spontaneous, intrinsically rewarding and “fun”; it is separate from serious consequences; it often involves novel or exaggerated actions and role reversal; it is repetitive, but distinct from stereotypies; and it usually occurs only in healthy, stress-free animals, making it a marker of well-being7. However, regarding the latter point, it has been highlighted that play can also represent an attempt to cope with suboptimal conditions (e.g. in nonhuman animals, play may occur as displacement behaviour in stressful situations5 or may serve to reduce social tensions)11. Also, in humans, playing computer games or gambling represents a way of coping with stress. Moreover, in some instances, what started as a fun activity can become compulsive and develop into a behavioural addiction12,13,14.&lt;/p&gt;
    &lt;p&gt;A behavioural addiction can be defined as “repeated failure to resist an impulse, drive, or urge to perform an act that is rewarding to the person (at least in the short-term), despite longer-term harm to the individual or others” (ICD-11 (International Classification of Diseases 11th Revision))15. Unlike in compulsive disorders, where performance of the compulsive behaviour primarily serves to provide some relief from a negative affective state, i.e. via negative reinforcement, addictive behaviours originate because their performance generates positive affect, i.e. via positive reinforcement. However, as the addiction develops, the behaviour becomes compulsive and may even cease to be rewarding (reviewed by Freimuth et al.16. Behavioural addictions share underlying neurobiological processes17 and behavioural symptoms (such as craving, lack of self-control, tolerance, withdrawal and risk of relapse) with substance addictions17,18. Still, they are more heterogeneous and less well-understood19.&lt;/p&gt;
    &lt;p&gt;While a wide range of behaviours have the potential to become addictive in people (e.g. exercise, sex, shopping, work, etc.)19,20,21,22,23,24,25, to date, only the two disorders related to playing – gambling and internet gaming – are officially recognised as behavioural addictions in the two psychiatric manuals of psychological disorders (DSM-5 and ICD-11). The ICD-1115 included both gambling and internet gaming as behavioural addictions. In the 5th edition of DSM-526, gambling, previously classified as an impulse control disorder, was included under “substance-related and addictive disorders”19,26, while internet gaming was listed separately as “internet gaming disorder”26.&lt;/p&gt;
    &lt;p&gt;What would make behaviours related to playing so addictive? Play involves neurotransmitter systems (opioids, cannabinoids, and dopamine) that are also engaged in the rewarding aspects of food and drug rewards8,9. Thus, video games can provide players a hedonic experience and a high degree of relaxation27. Pathological gaming is an example of how seemingly normal and enjoyable behaviours can develop to disrupt regular social and environmental functioning28,29,30.&lt;/p&gt;
    &lt;p&gt;Compared to substance addiction, there are only a few animal models of behavioural addictions. Moreover, these are restricted to controlled laboratory settings, and addictive-like behaviour has to be actively induced31. Rodent models have been used to investigate compulsive eating (e.g. reviewed in31, exercise addiction (wheel running32,33), gambling34, and responses to sexual reward35. Mice selectively bred for excessive wheel-running, sometimes referred to as an addiction-prone phenotype, develop physiological withdrawal symptoms similar to those found in drug addiction after abstinence36. As with excessive exercise in humans, wheel-running in rodents may become disruptive to everyday activities, leading to impaired nest-building and sheltering behaviour37,38. The animals may continue to wheel-run despite disrupted sleep39 or even in the face of injury40, thus fulfilling the behavioural addiction criterion “persistence of the behaviour despite adverse consequences”41. This suggests that behavioural addictions are not unique to the human species.&lt;/p&gt;
    &lt;p&gt;There is, however, only one species that appears to display addictive-like behaviour spontaneously, without intentional experimental induction: the domestic dog (although inadvertent promotion of addictive-like behaviour by the caretakers cannot be ruled out). A small subset of dogs – colloquially referred to as “ball junkies” – appear to demonstrate an addictive-like desire for object play42.&lt;/p&gt;
    &lt;p&gt;Like humans, domestic dogs frequently remain playful throughout their lives1, engaging in both social and object-related play, as well as combinations (e.g. tug-of-war9. Solitary object play appears to be related to predatory behaviour9; accordingly the development of social and object play may reflect different selective histories of dog breeds, which were selected for various purposes such as hunting, guarding, herding, and other functions6,7,8.&lt;/p&gt;
    &lt;p&gt;Toy play is a potent reinforcer, especially in working dog training43,44,45. For instance, detection dogs working in public settings are typically not rewarded with food due to concerns about undesirable food-seeking behaviours in the field. Still, they will work persistently for their toy rewards. It has been argued that artificial selection has exaggerated play behaviour in adult dogs, especially in working breeds or working lines, where high toy motivation is often actively selected as a predictor of performance46. For example, in Labrador retrievers, working lines demonstrate higher playfulness than show lines, indicating a genetic basis for play motivation and potential for artificial selection47.&lt;/p&gt;
    &lt;p&gt;Playing with toys allows dogs to express instinctive predatory sequences such as chasing, catching, possessing and “dissecting”, considered to be intrinsically rewarding to them based on their species and breed histories48. None of this is pathological, nor is gambling or computer gaming in people. However, such highly rewarding activities have the potential to become obsessive in humans49,50, and the same may be true for dogs.&lt;/p&gt;
    &lt;p&gt;While addictive-like behaviour towards toys in dogs has not been studied to date, the phenomenon has been described in the lay literature (where affected dogs may be referred to as ‘ball junkies’), and it has been (rarely) alluded to in the scientific literature. Lazarowski et al.48 describe how some dogs show behavioural and physiological signs of high arousal in relation to toys, lack of self-control, and behaviours such as whining, barking, spinning, and other behavioural signs of stress when access to a toy is prevented (e.g. because the dog is restrained), suggested as an expression of their inability to manage the frustration of anticipation46. All these signs could be interpreted as indicative of craving (and frustration when the urge cannot be fulfilled).&lt;/p&gt;
    &lt;p&gt;In humans, addictive behaviours are often associated with deficits in inhibitory control and heightened cue-reactivity and craving, which are likely key mechanisms in addiction, particularly when exposed to behaviour-specific cues51,52,53.&lt;/p&gt;
    &lt;p&gt;In animal models of addictions, not only is an increased motivation to work for the rewarding substance notable, but the animals also continue seeking the reward even when it is signalled to be unavailable54. Similarly, excessively toy-motivated dogs may continue to try to gain access to a toy even when the caretaker has put it away (anecdotal evidence55. Dogs that appear obsessed with toys cannot be easily distracted from their fixation on the preferred object – demonstrating the high salience of the toy. Such dogs may even lose interest in other stimuli or social interactions as long as they have access to the toy, or sometimes even when it has been removed from reach55 – i.e., everyday functioning may be affected. Moreover, some dogs may continue playing (e.g., running tirelessly after balls thrown for them) despite adverse consequences, such as over-exertion or even injury in the short term and damage to joints and ligaments in the longer term56.&lt;/p&gt;
    &lt;p&gt;Thus, we suggest that ‘excessive toy motivation’ in dogs may show parallels to behavioural addictions in humans. Domestic dogs share many complex behavioural traits with us57,and they are commonly used as model species to explore compulsive behaviours58,59; cognitive ageing60,61,62, ADHD63,64,65, neuroticism66 and autism67,68,69.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rationale&lt;/head&gt;
    &lt;p&gt;Here, we aim to provide the first scientific evaluation of ‘excessive toy motivation’ in dogs, develop methods to assess this phenomenon, and investigate whether ‘excessive toy motivation’ in pet dogs meets the defining criteria of behavioural addictions. Due to the heterogeneity of behavioural addictions, the number and description of diagnostic criteria are inconsistent in the scientific literature, even in humans19. We decided to explore whether the most common behavioural addiction criteria can be adapted to dogs: (1) craving, (2) salience, (3) mood modification through carrying out the behaviour, (4) lack of self-control, (5) tolerance, (6) withdrawal symptoms, (7) external consequences (the addictive behaviour causes conflict with other activities, other individuals, or within the individual), and (8) relapse after abstinence from the activity (cf28,41,70,71. Two additional criteria are used for diagnosing behavioural addictions in humans: having problems at home or work and lying to/deceiving people close to them26,72. Since these criteria cannot be applied to animals, we focused only on the eight abovementioned criteria.&lt;/p&gt;
    &lt;p&gt;We developed a behavioural test exposing pet dogs to various situations where behavioural addiction criteria in relation to toys can be expressed. Only the first four of the criteria mentioned above can be measured in a single behavioural assessment. The remaining criteria were included in an accompanying questionnaire, in which the dogs’ owners were asked about their dogs’ everyday behaviour.&lt;/p&gt;
    &lt;p&gt;While this study is exploratory, given the lack of prior research in this area, we used convergent methodologies in an attempt to assess internal and external validity. We predicted that dogs classified as having a high tendency for addictive-like behaviour based on our continuous Addictive-like Behaviour Test score, would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Show higher scores for the individual behavioural addiction criteria: Salience, Craving, Mood modification, and Lack of self-control in the behaviour test,&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Show higher durations of focusing on and trying to access an unavailable toy in the behaviour test,&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Receive higher scores on the owner questionnaire designed to measure dogs’ addictive-like behaviour in everyday life,&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;than dogs classified as having a low tendency for addictive-like behaviour.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;head rend="h3"&gt;Play motivation test&lt;/head&gt;
    &lt;head rend="h4"&gt;Ethical consideration&lt;/head&gt;
    &lt;p&gt;The study was assessed and approved by the Veterinary Office of the Canton of Bern, Switzerland (Licence number BE115/17). All procedures were performed in accordance with the “Guidelines for the Treatment of Animals in Behavioral Research and Teaching” of the Association for the Study of Animal Behavior. All dog owners provided written informed consent for their participation.&lt;/p&gt;
    &lt;head rend="h4"&gt;Subjects&lt;/head&gt;
    &lt;p&gt;One hundred twenty-six dog-owner teams were recruited via advertisements on social media. In the first call, any play-motivated dog was welcome to participate. In a second call, we specifically sought dogs showing ‘excessive’ motivation for toy play.&lt;/p&gt;
    &lt;p&gt;Twenty-one of the 126 tested dogs were excluded from the analysis as they were (1) outside the target age range (&amp;lt; 1 year or &amp;gt; 10 years old; N = 9), (2) did not complete the test due to fatigue (N = 1), (3) did not play at all or were too fearful for pulse measurements (N = 7), or (4) due to disturbances during the test (e.g. owners bringing young children along, N = 4). The final sample (N = 105) included 56 males (34 neutered or chemically castrated, 20 intact and 2 cryptorchids) and 49 females (34 neutered and 15 intact), ranging in age from 12 months to 10 years (mean age = 5.09 years, SD = 2.6). The dogs belonged to various breeds (for demographics, see Supplementary Table 1). Eighty-two owners (72 women and 10 men) participated in the study.&lt;/p&gt;
    &lt;head rend="h4"&gt;Experimental set-up&lt;/head&gt;
    &lt;p&gt;Behaviour tests took place in an experimental room (Fig. 1), measuring 5.22 m x 3.36 m. A wooden partition wall divided the room into two parts so that the effective testing space was 3.60 m x 3.36 m. The room was furnished with two chairs and several shelves on the walls. One of the chairs was placed in front of the wooden partition wall (facing the entrance door), and the other was placed at a 90° angle against the wall to the left. In front of both chairs, a taped line marked a one-meter distance from the chairs. During the habituation phase, the opaque box in which a toy or food was enclosed during several subtests (hereafter, unsolvable task box) was placed next to the experimenter’s chair.&lt;/p&gt;
    &lt;p&gt;Four video cameras (IB8377-H; 4 MP, 30 fps, H.264, WDR Pro, IR, PoE, IP66, 2.8–12 mm) were placed in the room, and recordings were made using the recorder system (ND9441P NVR, 16-CH, 4HDD, H.265, HDMI/VGA, 16x PoE).&lt;/p&gt;
    &lt;head rend="h4"&gt;Methods&lt;/head&gt;
    &lt;p&gt;The test battery consisted of 14 subtests assessing various aspects of toy motivation in dogs. Play behaviour per se cannot be used to infer addictive-like behaviour, which is characterised primarily by reactions when the reward is unavailable; therefore, only subtests relevant to exploring behavioural addiction criteria are described in detail hereafter. The complete description of the play motivation test is available under: https://figshare.com/s/dfd6d12d922f7543b96c.&lt;/p&gt;
    &lt;head rend="h5"&gt;Procedure&lt;/head&gt;
    &lt;head rend="h3"&gt;Room habituation&lt;/head&gt;
    &lt;p&gt;After the owner and the dog had entered the test room, the dog was unleashed, and a 3-minute habituation phase commenced (Fig. 1). Meanwhile, the owner and the experimenter were seated on their allocated chairs, and the experimenter explained the test procedure. The owner signed the consent form. The owners were instructed to interact with the dog only when asked to perform one of the subtests and not to use food during testing unless absolutely necessary (such as exchanging food for a toy if the dog was unwilling to relinquish it).&lt;/p&gt;
    &lt;head rend="h3"&gt;Choosing the toy&lt;/head&gt;
    &lt;p&gt;After the habituation phase, the experimenter retrieved a box containing various commercial dog toys of different sizes and textures, with and without squeakers, etc., from the adjacent storage room. Only toys that might be associated with food enrichment were excluded. The owner was asked to select three toys (one ball, one tug toy and one plush toy) which they thought the dog would like the most. If the owner had brought the dog’s favourite toy from home, this toy was used in the subsequent preference test along with two other toys.&lt;/p&gt;
    &lt;p&gt;After removing the toy box from the room, the experimenter returned to the test room. The owner recalled the dog and sat down on their chair, holding the dog behind the Line marking the 1 m distance from the chair. Opposite the dog at the front of the room, the experimenter placed the three toys on the floor in a row, 40 cm apart. After the experimenter had returned to her chair, the owner released the dog, who could now explore and play with the toys for 30 s. The two people present did not interact with the dog during this time. The toy the dog spent the most time interacting with was used for subsequent testing. Forty-five dogs selected a ball, nine selected a tug toy, 39 selected a plush toy, and 12 selected a hybrid toy (plush ball: N = 3; tug with a ball: N = 6; plush tug: N = 3). On rare occasions, the dog did not show interest in any of the toys. In this case, the owner was asked to choose the type of toy the dog was usually most interested in at home. The chosen toy was used throughout the experiment, and the remaining two toys were placed on the shelf out of reach and sight of the dog. If the preferred toy was not a tug toy, the tug toy was used in subtests where the owner or experimenter played tug-of-war with the dog.&lt;/p&gt;
    &lt;head rend="h5"&gt;Description of the subtests and their relevance for addiction criteria coding&lt;/head&gt;
    &lt;p&gt;A description of the subtests and, when applicable, their relevance for addiction criteria coding is given in Table 1.&lt;/p&gt;
    &lt;head rend="h4"&gt;Behavioural coding&lt;/head&gt;
    &lt;p&gt;Videos were coded using Solomon Coder (Solomon Coder beta 19.08.02, Copyright 2006–2019 by Andràs Péter).&lt;/p&gt;
    &lt;p&gt;For most subtests, the starting point for coding was when the experimenter and the owner were sitting on their chairs, and the dog was behind the Line, which marked a 1 m distance from the owner’s chair (Fig. 1).&lt;/p&gt;
    &lt;p&gt;Qualitative and quantitative coding was performed by coders who were not involved in the experiments.&lt;/p&gt;
    &lt;p&gt;Three different coding approaches were employed:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; a. &lt;p&gt;Scoring of individual variables that may be indicative of addictive behaviour each minute, which were later summed up as Addictive-like Behaviour Test score (Table 2); coder: KS.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; b. &lt;p&gt;Coding of presence/absence of the four addiction criteria in each minute of each subtest; coder: KS.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; c. &lt;p&gt;Quantitative coding.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Scoring and point sampling of behaviours during the subtests “Social play” and “Dog alone” (Table 4); coder: FL.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Coding of absolute durations of behaviours in subtests where the toy was rendered inaccessible (unsolvable task box and toy on a shelf, see Table 4); coders: DZ and AH.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A second coder (AM) performed reliability coding of addictive-like behaviours and behavioural addiction criteria and point sampling for 15 dogs. Reliability between the two coders who coded the durations was also analysed for 15 dogs. Reliability was good or excellent for all included variables (ICC, absolute agreement, single measures, two-way mixed-effects model, computed in IBM SPSS Statistics Version 23 (IBM Corporation and its Licensors 1989, 2015) (see Supplementary Table 3 for full results).&lt;/p&gt;
    &lt;head rend="h4"&gt;Sub-criteria to generate an Addictive-like behaviour test score (AB-T score)&lt;/head&gt;
    &lt;p&gt;To quantify dogs’ propensity for addictive-like behaviour as objectively as possible, we introduced the Addictive-like Behaviour Test score (AB-T score). Applicable sub-criteria were rated for each minute of the test, and for analysis, each sub-criterion was assigned a score between 0 and 2 points, as detailed in Table 2. The points from all the subtests, including the cool-down period, were added to yield the AB-T score. The maximum possible value of the AB-T score was 120 points. A cut-off point for addictive-like behaviour was defined by a data range split divided into two halves. Dogs scoring equal to or above the mid-point (44.2 points) are referred to as dogs showing a high tendency for addictive-like behaviour or high-AB dogs.&lt;/p&gt;
    &lt;p&gt;Dogs scoring less than 44.2 points are referred to as low-AB dogs (dogs with a low tendency for addictive-like behaviour). The sub-criteria included in the Addictive-like Behaviour Test score (as detailed in Table 2) were selected as they were assumed to be relatively independent of the level of obedience and training. Dogs might have been trained to drop a toy on a cue and to exert impulse control and refrain from jumping towards the toy in the experimenter’s hand; therefore, these variables were not included in the AB-T score. However, behaviours such as staring at the toy or pacing are believed to be less subject to training and were included.&lt;/p&gt;
    &lt;head rend="h4"&gt;Presence/absence of behavioural addiction criteria&lt;/head&gt;
    &lt;p&gt;Separately from the AB-T variables, in each subtest, the addiction criteria Salience, Craving, Mood modification, and Lack of self-control were rated each minute as present or absent based on the occurrence of pre-defined behaviours. For instance, Salience was inferred from searching for a toy although there was an »attractive alternative« (food, owner inviting the dog to play). Craving was based on the dog focusing mainly on the toy (&amp;gt; 50%) and medium to high arousal directed at the inaccessible toy (inferred from behaviours such as panting, restlessness, and high muscle tension). We further coded behaviours that are usually characteristic of high arousal in some dogs, e.g., pacing, jumping towards the toy, and vocalising (see Table 3). If at least one of the pre-defined behaviours was expressed, the respective addiction criterion was coded as present. Tolerance, Withdrawal symptoms and Risk of relapse after abstinence could not be tested in the setting of the play motivation test since they develop over time.&lt;/p&gt;
    &lt;p&gt;For each subtest, a summary score for each of the four addiction criteria was computed by summing up the points for each minute of the subtest.&lt;/p&gt;
    &lt;head rend="h4"&gt;Quantitative coding&lt;/head&gt;
    &lt;p&gt;Selected behaviours during the subtests “Social play” and “Dog alone” were coded by point sampling at 3-second intervals and then extrapolated to proportions of time (Table 4). Based on a subsample of dogs coded using both point sampling and absolute durations of behaviour, we determined sufficient agreement between the two measurement methods, justifying the use of point sampling. During subtests where a reward was inaccessible in the unsolvable task box, the absolute duration of interacting with the box (with low or high effort) was coded (Table 4). For detailed definitions of quantitatively coded variables, see Supplementary Table 2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Questionnaire on addictive-like behaviours&lt;/head&gt;
    &lt;p&gt;A questionnaire was developed (available in English and German) (for inter- and intra-rater reliability based on over 1500 dogs recruited via an online survey; see Supplementary Table 6). The questions relating to behavioural addiction criteria relevant to the present manuscript are shown in Table 5. They were rated on a 5-point Likert scale indicating the extent of agreement with the statement (1 – strongly disagree; 2 – partly disagree; 3 – neither agree nor disagree; 4 – partly agree; 5 – strongly agree). The dog owners were asked to complete this questionnaire during the cool-down period of the behavioural test.&lt;/p&gt;
    &lt;head rend="h2"&gt;Analysis&lt;/head&gt;
    &lt;p&gt;SPSS Statistics Version 23 (IBM Corporation and its Licensors 1989, 2015) was used to compute a Categorical Principal Component Analysis and Mann-Whitney U tests. R version 4.1.0 (The R Foundation for Statistical Computing, 2021) was used to create boxplots and to calculate linear models.&lt;/p&gt;
    &lt;head rend="h3"&gt;Assessment of differences in summary scores of individual behavioural addiction criteria between high-AB dogs and low-AB dogs&lt;/head&gt;
    &lt;p&gt;We calculated summary scores for the four addiction criteria for each subtest by summing up the points for each minute. Using Mann-Whitney U tests, we tested whether there was a difference in the addiction criteria Craving, Lack of self-control, Mood modification and Salience between dogs classified as high-AB dogs (AB-T score ≥ 44.2 points) and low-AB dogs (AB-T score &amp;lt; 44.2 points). Note that although components of Salience and craving were used to calculate the AB-T score, these are not identical to the 1 − 0 variables of Salience and craving here. While the addiction criteria were coded as 1/0 for each minute, the variables included in the AB-T score were more detailed, and individual elements potentially indicative of addictive-like behaviour were differentiated. Mood modification and Lack of self-control were not used in the designation of the AB-T score. See Sect. 1.6 and Table 3 for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;Assessment of differences in durations of toy-directed behaviours between high-AB dogs and low-AB dogs&lt;/head&gt;
    &lt;p&gt;We performed Mann-Whitney U tests to assess whether high-AB and low-AB dogs differed in quantitatively coded variables such as time engaging with the toy during different subtests, attempting to attain an unavailable toy, etc. (see Supplementary Tables 4 and 5).&lt;/p&gt;
    &lt;head rend="h3"&gt;Associations between questionnaire and behaviour test results and calculation of an Addictive-like Behaviour Questionnaire score (AB-Q score)&lt;/head&gt;
    &lt;p&gt;Linear models were used to assess associations between the addictive-like behaviour score and the 19 questionnaire questions targeting addictive-like behaviour. Model requirements were checked by visually assessing normality and homoscedasticity of the residuals. If applicable, the dependent variable was transformed.&lt;/p&gt;
    &lt;p&gt;Additionally, Mann-Whitney U tests were used to test whether the 19 questionnaire scores differed between high-AB and low-AB dogs. This was the case for fifteen questions; therefore, these were summed up to generate an Addictive-like Behaviour Questionnaire score (AB-Q score). Cohen’s R was used as a measure of effect size.&lt;/p&gt;
    &lt;p&gt;Both intra-rater reliability (available for 274 dogs, including dogs from the online survey) and inter-rater reliability (available for 24 dogs) of the AB-Q score were very good (see Supplementary Table 6).&lt;/p&gt;
    &lt;p&gt;Due to the exploratory nature of this study, no correction for multiple testing was performed (as recommended by73.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Addictive-like behaviour test score (AB-T score)&lt;/head&gt;
    &lt;p&gt;The mid-point of the data range of the AB-T score was 44.2 (range 6.6–95). Therefore, dogs scoring 44.2 or higher were classified as showing a high tendency for addictive-like behaviour (high-AB dogs). This was the case for thirty-three of the 105 highly play-motivated dogs tested, with a mean score of 59.7 points and a median of 58.6. The mean AB-T score for low-AB dogs (&amp;lt; 44.2 points) was 23.1, and the median was 22.8. For descriptive statistics, see Supplementary Table 7.&lt;/p&gt;
    &lt;head rend="h3"&gt;Assessment of differences between high-AB dogs and low-AB dogs in summary scores of individual behavioural addiction criteria&lt;/head&gt;
    &lt;p&gt;Mann-Whitney U tests indicated that high-AB dogs scored significantly higher than low-AB dogs on craving (U = 217, p &amp;lt; 0.0001), salience (U = 208, p &amp;lt; 0.0001), and lack of self-control (U = 756.5, p = 0.002), but not mood modification (U = 1022, p = 0.157), in the behaviour test (see Supplementary Table 4, Figs. 2a-d). For descriptive statistics, see Supplementary Table 8.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantitatively coded variables&lt;/head&gt;
    &lt;p&gt;High-AB dogs interacted significantly longer with the box than low-AB dogs in the ‘toy in the box’ subtest (U = 675.5, p &amp;lt; 0.0001). They also spent more time looking at the toy on the shelf during the ‘toy on shelf’ subtest (U = 414.5, p &amp;lt; 0.0001) and the ‘social play without toys’ subtest (U = 942.5, p = 0.021), while focusing less on the owner in the latter (U = 819.5, p = 0.011) compared to low-AB dogs (Supplementary Table 5, Fig. 2e and f). However, time spent interacting with the toy while the owner and experimenter were out of the room did not differ significantly between high-AB and low-AB dogs (U = 994, p = 0.135; Supplementary Table 5). For descriptive statistics, see Supplementary Table 9.&lt;/p&gt;
    &lt;head rend="h3"&gt;Addictive-like behaviour questionnaire score (AB-Q score)&lt;/head&gt;
    &lt;p&gt;Linear models demonstrated significant associations between the AB-T score and 18 out of 19 individual questions (Table 6). However, according to Mann-Whitney U tests, only fifteen questions differed significantly between dogs classified as showing a high tendency for addictive-like behaviour in the behaviour test (AB-T score ≥ 44.2) and those that did not. These fifteen questions (Cohen’s R &amp;gt; 0.2 – see Table 6) were summed up into the Addictive-like Behaviour Questionnaire score (AB-Q score) (see Table 6).&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;This study represents the beginning of the exploration of addictive-like behaviour in domestic dogs. Convergent behavioural measures support the existence of an addictive-like behavioural phenotype in 33 of the 105 tested highly play-motivated dogs. Note that we specifically sought dogs exhibiting extreme behaviour; thus, this proportion is not a reflection of the general population. Perhaps not surprising, working breeds – many of which are known to have been artificially selected for high toy or predatory motivation74,75,76 – were overrepresented in the sample.&lt;/p&gt;
    &lt;p&gt;As predicted, dogs classified as high-AB dogs based on the detailed AB-T score (Addictive-like Behaviour Test score) scored significantly higher than low-AB dogs on the individual criteria craving, salience, and lack of self-control in the behaviour test. Contrary to the prediction, mood modification (when given access to a toy) did not differ between high and low-AB dogs. In retrospect, however, this lack of difference between the two groups strengthens our argument that we were measuring a phenotype beyond mere enjoyment of play. Still, despite the significant differences between high- and low-AB dogs in the other investigated addiction criteria, Salience, Craving and Loss of Self Control, there was generally high variation between individuals.&lt;/p&gt;
    &lt;p&gt;In line with the predictions, high-AB dogs showed higher durations of focusing on and trying to access an inaccessible toy than low-AB dogs, often prioritising attempting to access the toy over eating or interacting with the owner. Thus, there was general agreement between the three alternative methods of coding the data (detailed behaviour score, addiction criteria, and quantitative coding), indicating internal consistency.&lt;/p&gt;
    &lt;p&gt;The external validity of the behaviour test was demonstrated by significant associations of the AB-T score with 18 out of 19 questions from the addictive-like behaviour questionnaire filled in by the dogs’ owners, intended to measure addictive-like behaviour in everyday life. Nonetheless, although significant, the effect sizes were relatively low, indicating that no single question would have predictive value for assessing a tendency for addictive-like behaviour in dogs.&lt;/p&gt;
    &lt;p&gt;In studies using animal models of substance addiction, one way to differentiate an addiction from drug use that occurs due to lack of choice is to present the subject with a choice between the addictive substance and other highly desirable stimuli. If an individual continues to take the drug at the expense of these other options (such as consumption of a food reward), this points to the possibility of addictive-like behaviour77,78. Consistent with this, high-AB dogs showed a loss of interest in other relevant stimuli, focusing on the inaccessible toy and foregoing the opportunity to consume food or to engage with their owner. The latter is also reminiscent of behavioural addictions in humans, leading to a decline in social interactions79.&lt;/p&gt;
    &lt;p&gt;The intense toy-seeking and loss of interest in other stimuli, despite the availability of food or social interaction – considered as indicators for salience and persistence – might resemble “hyperfocus,” a trait associated with ADHD and autism in humans80,81. However, unlike typical hyperfocus, which often emerges in the absence of competing stimuli, dogs in our study were presented with alternative salient rewards (e.g., the toy was placed on a shelf while the owner actively invited the dog to engage in social play; in another subtest, food was available in a puzzle toy while the preferred toy was inaccessible in a closed container), and they still showed a preference for the inaccessible toy. Like dogs with ADHD, dogs in the current study with high AB-T scores in general exhibited high impulsivity (labelled as “loss of self-control”), and some individuals displayed heightened activity (which could be interpreted as the hyperactivity component of ADHD64,65 in particular during the cool-down period. Thus, further research is needed to explore commonalities and differences between addictive-like behaviour and ADHD-like behaviour in dogs. While dogs with a high tendency for addictive-like behaviour might exhibit many characteristics of dogs with ADHD, the converse is not necessarily true – dogs might show ADHD-like behaviour without displaying any hyperfixation on toys.&lt;/p&gt;
    &lt;p&gt;Another characteristic of addicted individuals is that they are willing to pursue their addiction even if it has adverse consequences82. In the current study, “adversity” was elicited by the owner and the experimenter leaving the room in order to assess the effect of social isolation on the behavioural addiction criteria. Isolation in an unfamiliar place is well-established as a stressful experience for dogs83,84,85,86. However, this subtest was not a good measure of addictive-like behaviour: Time spent interacting with the toy while the dog was alone did not differ significantly between high-AB and low-AB dogs. For welfare reasons, we decided against exposing the dogs to more severe stressors; however, it cannot be ruled out that this subtest was not “aversive” enough. The dog was left alone for only 30 seconds, and the subtest took place in the middle of the test when the dogs were already habituated to the test room. It is also possible that individual differences in subjects’ separation distress, independent of play motivation, affected the results. Additionally, there was no clear contingency between interacting with the toy and the ‘adverse’ outcome (owner leaving). Future studies could potentially enhance the design by providing the dog with an explicit choice, such as by placing the toy in a separate room, away from the owner and the experimenter. This could help determine whether the dog is willing to risk being alone in an unusual or new environment when it normally prefers the safety of being near its owner. Such a design would better reflect the conflict between competing motivations (social security vs. reward seeking) and could offer a more valid test of the criterion of persistence under adversity.&lt;/p&gt;
    &lt;p&gt;Still, the importance of continued efforts to engage in the behaviour despite adverse consequences was demonstrated in the questionnaire, where one of the highest associations with the AB-T score was found with the question, “My dog will continue to play with a ball/toy despite adverse consequences”. This suggests that some dogs may fulfil the criterion of continuing the addictive-like behaviour despite adverse consequences in real life, even if this could not be demonstrated in the behaviour test.&lt;/p&gt;
    &lt;p&gt;A critical factor in addiction is the propensity to attribute incentive salience to classically conditioned cues predicting rewards87,88. In humans, cues associated with addictive behaviours, such as specific locations or objects, can induce craving and drug administration88,89. In dogs, a toy such as a ball could represent such as a conditioned cue. It may achieve its value, for example, by the experience of chasing and catching. For many domestic dogs, balls or other toys possess incentive salience, according to the three criteria by Robinson and Berridge49: they (1) “elicit approach” (i.e. they become “wanted” and act as “motivational magnets”); (2) “they can energise ongoing actions by eliciting cue-triggered wanting”; (3) “they can act as reinforcers in their own right, reinforcing the acquisition of a new instrumental response (measurable by conditioned reinforcement)” (cf49, p. 3139].).&lt;/p&gt;
    &lt;p&gt;The perceived value of the toy was demonstrated in our study by many dogs having difficulty relinquishing the toy. It can be speculated that balls become ‘motivational magnets’ by being associated with species-typical predatory behaviour (cf48. The high salience of the toy was especially apparent in subtests where dogs were foregoing available alternatives such as freely available food or social play with the owner, at the expense of trying to regain their inaccessible toy.&lt;/p&gt;
    &lt;p&gt;In both rodents and humans90,91, individuals with a higher tendency to attribute incentive salience to classically conditioned cues predicting rewards (sign trackers) are more vulnerable to addiction than goal trackers, who focus primarily on the (location of the) reward itself88,92, see the meta-analysis by93. Tendency to sign-track vs. goal-track is associated with the risk of addiction and is also related to variations in the dopaminergic system and stress physiology88.&lt;/p&gt;
    &lt;p&gt;While it was not explicitly measured in the current study, in dogs, a tendency to sign track might be advantageous in a training context – i.e., maintaining motivation would be easier in dogs that are not only sensitive to rewards but also attribute value to the cues predicting these rewards, even if not always followed by a primary reinforcer. Sensitivity to reward – and propensity to attribute incentive salience to reward-predictive cues – would thus be highly relevant traits in relation to trainability and might be selected for especially in working dog breeds.&lt;/p&gt;
    &lt;p&gt;Several publications state the importance of ‘obsessive’ play motivation for working dog success42,94,95,96,97,98,99. Dogs with extreme toy motivation are believed to show better focus, reduced distractibility and greater trainability97,99. However, if such motivation becomes addictive-like, it needs to be questioned whether the well-being of these dogs may be compromised. If dogs prioritise toy interactions over other essential aspects of their daily lives this may have maladaptive effects, as is the case in humans with behavioural addictions100,101. Certainly, adverse health consequences may arise from repetitive ball chasing, like straining ligaments and joints56. Moreover, welfare would be compromised when dogs experience a high level of frustration when access to their reward is prevented (cf102.&lt;/p&gt;
    &lt;p&gt;Anecdotally, when play motivation becomes excessive, irritability, high arousal levels, and frustration may negatively affect dogs’ trainability and work103. Indeed, as stated by Mathews96, the high ‘drive’ of search dogs often makes them unsuitable as family pets, which is also supported by owner reports that pet dogs with extreme motivation for toys are often problematic to control102.&lt;/p&gt;
    &lt;p&gt;Thus, it needs to be questioned when play becomes maladaptive. Do high-AB dogs still ‘like’ to play, or have they progressed to primarily ‘wanting’ and the compulsive need to continue104?. Similar to the escalating engagement seen in human behavioural addictions105, some dogs would repeatedly spin, jump, focus or bark towards the unavailable toy on the shelf for the duration of the subtest. Two dogs even managed to destroy the box enclosing their favourite toy. These behaviours might be likened to the repetitive actions observed in individuals with behavioural addictions41. Nonetheless, such behaviours may also occur in other behavioural phenotypes such as canine compulsive disorder or autism spectrum-like behaviours106. Further research is needed to elucidate commonalities and differences between such phenotypes in dogs.&lt;/p&gt;
    &lt;p&gt;Behavioural addictions in humans often involve emotional dependency on specific activities107. Whether dogs similarly seek comfort, stimulation, or stress relief through persistent engagement with the toy could not be determined in the context of the behaviour test. In the questionnaire, “Is attached to the favourite toy” was the only question not significantly associated with the AB-T score. Thus, further research is required to determine whether dogs develop an emotional dependency on their toys (as described anecdotally).&lt;/p&gt;
    &lt;p&gt;To better understand the origin and possible functional underpinnings of excessive toy-directed behaviour in dogs, future research should examine whether similar patterns of excessive object play occur in non-domesticated canids. While data are limited, recent studies have shown that both hand-reared and wild wolf pups engage in object play108. For instance, wolf pups have been observed developing a preference for toys and spending increasing amounts of time with them over time108. Hand-reared wolf pups will even retrieve objects to humans109. In the wild, wolves have also been seen interacting with human-made objects110. These findings suggest that object play is not unique to dogs but rather could represent a broader trait shared by canids. Comparative studies are needed to assess how common and functionally relevant such behaviours are in wolves, which would help clarify the biological basis of the addictive-like behaviours observed in some dogs.&lt;/p&gt;
    &lt;p&gt;Being the first of its kind, this study has its limitations. As no gold standard exists, the study is exploratory, and our categorisation of dogs into high and low addictive-like behaviour groups, determined by a data range split, was somewhat arbitrary. Nonetheless, the assignment of high- and low-AB categories corresponded well to the first author’s personal assessment of addictive-like tendencies in the participant dogs.&lt;/p&gt;
    &lt;p&gt;In interpreting the questionnaire results, it is important to acknowledge the potential biases associated with using owner-reported questionnaires. Owners may unintentionally project their perceptions or expectations onto their dogs’ behaviours, potentially leading to discrepancies between reported and observed behaviours in behavioural test. This is particularly relevant in cases where owners have multiple dogs, as they are likely to compare their pets to one another, influencing their assessment, such as by underestimating or overestimating certain behaviours. For instance, an owner with a highly active dog may rate their less active dog as overly calm. Integrating owner reports and objective testing allows for a more comprehensive and accurate canine behaviour evaluation.&lt;/p&gt;
    &lt;head rend="h2"&gt;)Conclusions&lt;/head&gt;
    &lt;p&gt;To conclude, there appear to be parallels between excessive toy motivation in dogs and behavioural addictions in humans. Interestingly, also in humans, the first officially recognised behavioural addictions (gambling and internet gaming) originate in play28,29,30,111. Generally, play is an activity that induces a pleasurable emotional state6. In humans, much evidence suggests that video games can affect people’s lives positively. They make players feel better about themselves, help raise their self-esteem and assist people in dealing with everyday stress111. Some people are excessive gamers, but only a minority would be classified as addicts111,112,113. Similarly, many dogs may greatly enjoy toy play without developing harmful compulsions (cf. in humans28,29,30,111).&lt;/p&gt;
    &lt;p&gt;Despite the observed parallels between high-AB dogs and humans affected by behavioural addictions, we refrain from conclusively characterising high-AB dogs as exhibiting addictive behaviour, given the absence of established benchmarks or standardised criteria. It is important to be cautious when pathologising behaviour, especially given that even in humans, addictive behaviours are still difficult to define and measure114. To further understand possible parallels in the processes underlying behavioural addictions in humans and excessive toy motivation in dogs, subsequent research endeavours should seek to correlate individual differences in addictive-like behaviour in dogs with characteristics associated with addictive behaviours in humans, such as high impulsivity, impaired reversal learning, heightened perseveration, and delayed extinction of previously rewarded responses115,116.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;All data supporting the findings of this study are available within the paper and its Supplementary Information.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Bradshaw, J. W. S., Pullen, A. J. &amp;amp; Rooney, N. J. Why do adult dogs ‘play’? Behav. Process. 110, 82–87 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Burghardt, G. M., Albright, J. D. &amp;amp; Davis, K. M. Motivation, development and object play: comparative perspectives with lessons from dogs. Behaviour 153, 767–793 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Diamond, J. &amp;amp; Behaviour, A. B. &amp;amp; undefined. A comparative analysis of social play in birds. JSTORJ Diamond, AB BondBehaviour, 2003•JSTOR (2003). (2003).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bateson, P. Play, playfulness, creativity and innovation. Anim. Behav. Cognition. 1, 99–112 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sommerville, R., O’Connor, E. A. &amp;amp; Asher, L. Why do dogs play? Function and welfare implications of play in the domestic dog. Appl. Anim. Behav. Sci. 197, 1–8 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Held, S. D. E. &amp;amp; Špinka, M. Animal play and animal welfare. Animal Behaviour vol. 81 891–899 Preprint at (2011). https://doi.org/10.1016/j.anbehav.2011.01.007&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bateson, P. Play Playfulness, creativity and innovation. Anim Behav. Cogn 1(2), 99–112 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trezza, V., Damsteegt, R., Marijke Achterberg, E. J. &amp;amp; Vanderschuren, L. J. M. J. Nucleus accumbens µ-opioid receptors mediate social reward. J. Neurosci. 31, 6362–6370 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Blois-Heulin, C. et al. Animal welfare: could adult play be a false friend?? Anim. Behav. Cogn. 2, 156–185 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Panksepp, J. Affective Neuroscience: the Foundations of Human and Animal Emotions (Oxford University Press, 1998).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dias, P. A. D. &amp;amp; Rangel-Negrín, A. Affiliative contacts and greetings. The Int. Encyclopedia of Primatology,. Wiley-Blackwell, pp 1-4 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Maroney, N., Williams, B. J., Thomas, A., Skues, J. &amp;amp; Moulding, R. A Stress-Coping model of problem online video game use. Int. J. Ment Health Addict. 17, 845–858 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Blasi, M. D. I. et al. Problematic video game use as an emotional coping strategy: evidence from a sample of MMORPG gamers. J. Behav. Addict. 8, 25–34 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Melodia, F., Canale, N. &amp;amp; Griffiths, M. D. The role of avoidance coping and escape motives in problematic online gaming: A systematic literature review. Int. J. Ment Health Addict. 20, 996–1022 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Organization., W. H. ICD-11. ICD-11 (2019). https://icd.who.int/en&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Freimuth, M., Moniz, S. &amp;amp; Kim, S. R. Clarifying exercise addiction: differential diagnosis, co-occurring disorders, and phases of addiction. Int. J. Environ. Res. Public. Health. 8, 4069–4081 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Olsen, C. M. Natural rewards, neuroplasticity, and non-drug addictions. Neuropharmacology vol. 61 1109–1122 Preprint at (2011). https://doi.org/10.1016/j.neuropharm.2011.03.010&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Alavi, S. S. et al. Behavioral addiction versus substance addiction: correspondence of psychiatric and psychological views. Int. J. Prev. Med. 3, 290–294 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pinna, F. et al. Behavioural addictions and the transition from DSM-IV-TR to DSM-5. J. Psychopathol. 21, 380–389 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Robbins, T. W. &amp;amp; Clark, L. Behavioral addictions. Current Opinion in Neurobiology vol. 30 66–72 Preprint at (2015). https://doi.org/10.1016/j.conb.2014.09.005&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fan, L., Li, K., Xin, J., Wang, Y. &amp;amp; Li, Y. Family Subjective Socioeconomic Status and University Students’ Online Shopping Addiction: A Gender-Based Analysis. https://home.liebertpub.com/cyber (2022). https://doi.org/10.1089/CYBER.2021.0344&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Larocque, E. &amp;amp; Moreau, N. When sport is taken to extremes: A sociohistorical analysis of sport addiction. Int. Rev. Sociol. Sport. https://doi.org/10.1177/10126902221104956 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Atroszko, P. A. Work addiction as a behavioural addiction: Towards a valid identification of problematic behaviour. Australian and New Zealand Journal of Psychiatry vol. 53 284–285 Preprint at (2019). https://doi.org/10.1177/0004867419828496&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kun, B., Takacs, Z. K., Richman, M. J., Griffiths, M. D. &amp;amp; Demetrovics, Z. Work addiction and personality: A meta-analytic study. J. Behav. Addict. 9, 945–966 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Niedermoser, D. W. et al. Shopping addiction: A brief review. Pract. Innovations. 6, 199–207 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders. (2013). https://doi.org/10.1176/APPI.BOOKS.9780890425596&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Walia, B., Kim, J., Ijere, I. &amp;amp; Sanders, S. Video game addictive symptom level, use intensity, and hedonic experience: Cross-sectional questionnaire study. JMIR Serious Games. 10, e33661 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Beranuy, M., Carbonell, X. &amp;amp; Griffiths, M. D. A qualitative analysis of online gaming addicts in treatment. Int. J. Ment Health Addict. 11, 149–161 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Higuchi, S. et al. Development and validation of a nine-item short screening test for ICD-11 gaming disorder (GAMES test) and Estimation of the prevalence in the general young population. J. Behav. Addict. 10, 263–280 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stevens, M. W. R., Dorstyn, D., Delfabbro, P. H. &amp;amp; King, D. L. Global prevalence of gaming disorder: A systematic review and meta-analysis. Australian and New Zealand Journal of Psychiatry vol. 55 553–568 Preprint at (2021). https://doi.org/10.1177/0004867420962851&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Di Segni, M., Patrono, E., Patella, L., Puglisi-Allegra, S. &amp;amp; Ventura, R. Animal models of compulsive eating behavior. Nutrients vol. 6 4591–4609 Preprint at (2014). https://doi.org/10.3390/nu6104591&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Brené S. et al. Running is rewarding and antidepressive. Physiol. Behav. 1-2, 136–140 (2007).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kanarek, R. B., D’Anci, K. E., Jurdak, N. &amp;amp; Mathes, W. F. Running and addiction: precipitated withdrawal in a rat model of Activity-Based anorexia. Behav. Neurosci. 123, 905–912 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Winstanley, C. A. Gambling rats: insight into impulsive and addictive behavior. Neuropsychopharmacology 36, 359 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pitchers, K. K. et al. ∆FosB in the nucleus accumbens is critical for reinforcing effects of sexual reward. Genes Brain Behav. 9, 831–840 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kolb, E. M., Kelly, S. A. &amp;amp; Garland, T. Mice from lines selectively bred for high voluntary wheel running exhibit lower blood pressure during withdrawal from wheel access. Physiol. Behav. 112–113, 49–55 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Carter, P. A., Swallow, J. G., Davis, S. J. &amp;amp; Garland, T. Nesting Behavior of House Mice (Mus Domesticus) Selected for Increased Wheel-Running Activity. Behavior Genetics 30, 85–94 (2000). (2000).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;De Visser, L., Van Den Bos, R. &amp;amp; Spruijt, B. M. Automated home cage observations as a tool to measure the effects of wheel running on cage floor locomotion. Behav. Brain. Res. 160, 382–388 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kas, M. J. H. &amp;amp; Edgar, D. M. A nonphotic stimulus inverts the diurnal-nocturnal phase preference in Octodon Degus. J. Neurosci. 19, 328–333 (1999).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reebs, S. G. &amp;amp; St-Onge, P. Running wheel choice by Syrian hamsters. Lab. Anim. 39, 442–451 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grant, J. E., Potenza, M. N., Weinstein, A. &amp;amp; Gorelick, D. A. Introduction to behavioral addictions. American Journal of Drug and Alcohol Abuse vol. 36 233–241 Preprint at (2010). https://doi.org/10.3109/00952990.2010.491884&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jamieson, L. T. J., Baxter, G. S. &amp;amp; Murray, P. J. Identifying suitable detection dogs. Applied Animal Behaviour Science vol. 195 1–7 Preprint at (2017). https://doi.org/10.1016/j.applanim.2017.06.010&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rooney, N. J., Bradshaw, J. W. &amp;amp; Almey, H. Attributes of specialist search dogs—a questionnaire survey of UK dog handlers and trainers. J. Forensic Sci. 49, 1–7 (2004).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Naderi, S., Miklósi, Á., Dóka, A. &amp;amp; Csányi, V. Co-operative interactions between blind persons and their dogs. Appl. Anim. Behav. Sci. 74, 59–80 (2001).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mariti, C. et al. Dog attachment to man: A comparison between pet and working dogs. J. Veterinary Behav. 8, 135–145 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kolm, N., Temrin, H., Miklósi, Á. &amp;amp; Kubinyi, E. &amp;amp; Zsolt garamszegi, L. The link between selection for function and human-directed play behaviour in dogs. (2020). https://doi.org/10.1098/rsbl.2020.0366&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sundman, A. S., Johnsson, M., Wright, D. &amp;amp; Jensen, P. Similar recent selection criteria associated with different behavioural effects in two dog breeds. Genes Brain Behav. 15, 750–756 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lazarowski, L. et al. Selecting Dogs for Explosives Detection: Behavioral Characteristics. Frontiers in Veterinary Science vol. 7 597 Preprint at (2020). https://doi.org/10.3389/fvets.2020.00597&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Robinson, T. E. &amp;amp; Berridge, K. C. The incentive sensitization theory of addiction: some current issues. Philosophical Trans. Royal Soc. B: Biol. Sci. 363, 3137–3146 (2008). (The Royal SocietyLondon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stephens, D. N. et al. Reward sensitivity: Issues of measurement, and achieving consilience between human and animal phenotypes. Addiction Biology vol. 15 146–168 Preprint at (2010). https://doi.org/10.1111/j.1369-1600.2009.00193.x&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Antons, S., Brand, M. &amp;amp; Potenza, M. N. Neurobiology of cue-reactivity, craving, and inhibitory control in non-substance addictive behaviors. Journal of the Neurological Sciences vol. 415 116952 Preprint at (2020). https://doi.org/10.1016/j.jns.2020.116952&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Choi, J. S. et al. Dysfunctional inhibitory control and impulsivity in internet addiction. Psychiatry Res. 215, 424–428 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kräplin, A. et al. The role of inhibitory control and decisionmaking in the course of internet gaming disorder. J. Behav. Addict. 9, 990–1001 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hebebrand, J. et al. ‘Eating addiction’, rather than ‘food addiction’, better captures addictive-like eating behavior. Neuroscience and Biobehavioral Reviews vol. 47 295–306 Preprint at (2014). https://doi.org/10.1016/j.neubiorev.2014.08.016&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Käufer, M. ‘Throw the damn ball!’ Warum Ballwerfen kein Spiel ist. in … und weg ist er! Jagdverhalten und mögliche Alternativen 129–154 (Filander, Erlangen, 2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marcellin-Little, D. J., Levine, D. &amp;amp; Taylor, R. Rehabilitation and conditioning of sporting dogs. Veterinary Clinics of North America - Small Animal Practice vol. 35 1427–1439 Preprint at (2005). https://doi.org/10.1016/j.cvsm.2005.08.002&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Overall, K. L. Natural animal models of human psychiatric conditions: assessment of mechanism and validity. Prog Neuropsychopharmacol. Biol. Psychiatry. 24, 727–776 (2000).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boulougouris, V., Chamberlain, S. R. &amp;amp; Robbins, T. W. Cross-species models of OCD spectrum disorders. Psychiatry Res. 170, 15–21 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vermeire, S. et al. Serotonin 2A receptor, serotonin transporter and dopamine transporter alterations in dogs with compulsive behaviour as a promising model for human obsessive-compulsive disorder. Psychiatry Res. Neuroimaging. 201, 78–87 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hoffman, J. M., Creevy, K. E., Franks, A., O’Neill, D. G. &amp;amp; Promislow, D. E. L. The companion dog as a model for human aging and mortality. Aging Cell. 17, e12737 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sándor, S. &amp;amp; Kubinyi, E. Genetic pathways of aging and their relevance in the dog as a natural model of human aging. Front. Genet. 10, 948 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vitek, M. P. et al. Translational animal models for alzheimer’s disease: an alzheimer’s association business consortium think tank. Alzheimer’s Dementia: Translational Res. Clin. Interventions. 6, e12114 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;González-Martínez, Á., de Miguel, M., Graña, S., Costas, N., Diéguez, F. J. &amp;amp; X. &amp;amp; Serotonin and dopamine blood levels in ADHD-Like dogs. Animals 13, 1037 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sulkama, S. et al. Canine hyperactivity, impulsivity, and inattention share similar demographic risk factors and behavioural comorbidities with human ADHD. Transl Psychiatry. 11, 1–9 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Csibra, B., Bunford, N. &amp;amp; Gácsi, M. Development of a human-analogue, 3-symptom domain dog ADHD and functionality rating scale (DAFRS). Sci. Rep. 14, 1–18 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Salonen, M. et al. Personality traits associate with behavioral problems in pet dogs. Transl Psychiatry 12, 1-7 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tian, R. et al. Modeling SHANK3-associated autism spectrum disorder in Beagle dogs via CRISPR/Cas9 gene editing. Molecular Psychiatry 2023 28:9 28, 3739–3750 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Li, Y. et al. Reduced attention to human eyes in autism-associated Shank3 mutant laboratory beagle dogs. Mol. Psychiatry. 30, 3765–3773 (2025).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zhu, F., Shi, Q., Jiang, Y., hui, Zhang, Y. Q. &amp;amp; Zhao, H. Impaired synaptic function and hyperexcitability of the pyramidal neurons in the prefrontal cortex of autism-associated Shank3 mutant dogs. Springer 15, (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Griffiths, M. Classification and treatment of behavioural addictions. Nurs. Pract. 82, 44–46 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Landolfi, E. Exercise addiction. Sports Med. 43, 111–119 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Van Rooij, A. J. &amp;amp; Prause, N. A critical review of internet addiction criteria with suggestions for the future. J. Behav. Addict. 3, 203–213 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bender, R. &amp;amp; Lange, S. Adjusting for multiple testing - When and how? J. Clin. Epidemiol. 54, 343–349 (2001).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Coppinger, R. &amp;amp; Coppinger, L. Dogs: A New Understanding of Canine Origin, Behavior, and Evolution (University of Chicago Press, 2002).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mehrkam, L. R., Hall, N. J., Haitz, C. &amp;amp; Wynne, C. D. L. The influence of breed and environmental factors on social and solitary play in dogs (Canis lupus familiaris). Learn. Behav. 45, 367–377 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eken Asp, H., Fikse, W. F., Nilsson, K. &amp;amp; Strandberg, E. Breed differences in everyday behaviour of dogs. Appl. Anim. Behav. Sci. 169, 69–77 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ahmed, S. H., Lenoir, M. &amp;amp; Guillem, K. Neurobiology of addiction versus drug use driven by lack of choice. Current Opinion in Neurobiology vol. 23 581–587 Preprint at (2013). https://doi.org/10.1016/j.conb.2013.01.028&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Golden, S. A. et al. Compulsive Addiction-like aggressive behavior in mice. Biol. Psychiatry. 82, 239–248 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kuss, D. J., Louws, J. &amp;amp; Wiers, R. W. Online gaming addiction? Motives predict addictive play behavior in massively multiplayer online role-playing games. Cyberpsychol Behav. Soc. Netw. 15, 480–485 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ashinoff, B. K. &amp;amp; Abu-Akel, A. Hyperfocus: the forgotten frontier of attention. Psychological Research 2019 85:1 85, 1–19 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grotewiel, M. M., Crenshaw, M. E., Dorsey, A. &amp;amp; Street, E. Experiences of hyperfocus and flow in college students with and without attention deficit hyperactivity disorder (ADHD). Curr. Psychol. 42, 13265–13275 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vanderschuren, L. J., Minnaard, A. M., Smeets, J. A. &amp;amp; Lesscher, H. M. Punishment models of addictive behavior. Curr. Opin. Behav. Sci. 13, 77–84 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Palestrini, C., Previde, E. P., Spiezio, C. &amp;amp; Verga, M. Heart rate and behavioural responses of dogs in the ainsworth’s strange situation: A pilot study. Appl. Anim. Behav. Sci. 94, 75–88 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Palmer, R. &amp;amp; Custance, D. A counterbalanced version of ainsworth’s strange situation procedure reveals secure-base effects in dog-human relationships. Appl. Anim. Behav. Sci. 109, 306–319 (2008).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ryan, M. G., Storey, A. E., Anderson, R. E. &amp;amp; Walsh, C. J. Physiological indicators of attachment in domestic dogs (Canis familiaris) and their owners in the strange situation test. Front. Behav. Neurosci. 13, 456977 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Riemer, S., Assis, L., Pike, T. W. &amp;amp; Mills, D. S. Dynamic changes in ear temperature in relation to separation distress in dogs. Physiol. Behav. 167, 86–91 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flagel, S. B. et al. An Animal Model of Genetic Vulnerability to Behavioral Disinhibition and Responsiveness to Reward-Related Cues: Implications for Addiction. Neuropsychopharmacology 2010 35:2 35, 388–400 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flagel, S. B., Akil, H. &amp;amp; Robinson, T. E. Individual differences in the attribution of incentive salience to reward-related cues: Implications for addiction. Neuropharmacology vol. 56 139–148 Preprint at (2009). https://doi.org/10.1016/j.neuropharm.2008.06.027&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marlatt, G. A. Cue exposure and relapse prevention in the treatment of addictive behaviors. Addict. Behav. 15, 395–399 (1990).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Olney, J. J., Warlow, S. M., Naffziger, E. E. &amp;amp; Berridge, K. C. Current perspectives on incentive salience and applications to clinical disorders. Curr. Opin. Behav. Sci. 22, 59–69 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cofresí, R. U., Bartholow, B. D. &amp;amp; Piasecki, T. M. Evidence for incentive salience sensitization as a pathway to alcohol use disorder. Neuroscience and Biobehavioral Reviews vol. 107 897–926 Preprint at (2019). https://doi.org/10.1016/j.neubiorev.2019.10.009&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Berridge, K. C., Robinson, T. E. &amp;amp; Aldridge, J. W. Dissecting components of reward: ‘liking’, ‘wanting’, and learning. Current Opinion in Pharmacology vol. 9 65–73 Preprint at (2009). https://doi.org/10.1016/j.coph.2008.12.014&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Meyer, P. J. et al. Quantifying individual variation in the propensity to attribute incentive salience to reward cues. PLoS One. 7, e38987 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Beebe, S. C., Howell, T. J. &amp;amp; Bennett, P. C. Using scent detection dogs in conservation settings: A review of scientific literature regarding their selection. Front. Veterinary Sci. 3 (1), Preprintathttpsdoiorg103389fvets201600096 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reed, S. E., Bidlack, A. L., Hurt, A. &amp;amp; Getz, W. M. Detection distance and environmental factors in conservation detection dog surveys. J. Wildl. Manage. 75, 243–251 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mathews, F. et al. Effectiveness of search dogs compared with human observers in locating Bat carcasses at wind-turbine sites: A blinded randomized trial. Wildl. Soc. Bull. 37, 34–40 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hsu, Y. &amp;amp; Serpell, J. A. Development and validation of a questionnaire for measuring behavior and temperament traits in pet dogs. J. Am. Vet. Med. Assoc. 223, 1293–1300 (2003).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hsu, Y. &amp;amp; Sun, L. Factors associated with aggressive responses in pet dogs. Appl. Anim. Behav. Sci. 123, 108–123 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Serpell, J. A. &amp;amp; Hsu, Y. Effects of breed, sex, and neuter status on trainability in dogs. in Anthrozoos vol. 18 196–207 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Müller, A. et al. Food addiction and other addictive behaviours in bariatric surgery candidates. Eur. Eat. Disorders Rev. 26, 585–596 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tunney, R. J. &amp;amp; James, R. J. E. Criteria for conceptualizing behavioural addiction should be informed by the underlying behavioural mechanism. Addiction 112, 1720–1721 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gerencsér, L., Bunford, N., Moesta, A. &amp;amp; Miklósi, Á. Development and validation of the canine reward responsiveness scale -Examining individual differences in reward responsiveness of the domestic dog. Sci Rep 8, 1-14 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lindsay, S. R. Handbook of applied dog behavior and training. Vol. 3: Procedures and protocols. Ames (IA): Iowa Stat University Press (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Berridge, K. C. &amp;amp; Robinson, T. E. Liking, wanting, and the incentive-sensitization theory of addiction. Am. Psychol. 71, 670–679 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grant, J. E., Brewer, J. A. &amp;amp; Potenza, M. N. The neurobiology of substance and behavioral addictions. CNS Spectr. 11, 924–930 (2006).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jacques, C. et al. What interests young autistic children? An exploratory study of object exploration and repetitive behavior. PLoS One. 13, e0209251 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Brand, M., Young, K. S., Laier, C., Wölfling, K. &amp;amp; Potenza, M. N. Integrating psychological and neurobiological considerations regarding the development and maintenance of specific Internet-use disorders: An Interaction of Person-Affect-Cognition-Execution (I-PACE) model. Neuroscience and Biobehavioral Reviews vol. 71 252–266 Preprint at (2016). https://doi.org/10.1016/j.neubiorev.2016.08.033&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Davis, K. M., Partin, A. M., Springer, C. M. &amp;amp; Burghardt, G. M. The development of object play in Wolf puppies (Canis lupus). Int. J. Play. 12, 20–39 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hansen Wheat, C. &amp;amp; Temrin, H. Intrinsic Ball Retrieving in Wolf Puppies Suggests Standing Ancestral Variation for Human-Directed Play Behavior. iScience 23, 100811 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ausband, D. E. Wolf use of humanmade objects during pup-rearing. Anim. Behav. Cogn. https://doi.org/10.26451/abc.08.03.06.2021 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Griffiths, M. Online computer gaming: advice for parents and teachers. Educ. Health. 27, 3–6 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Griffiths, M. D. Diagnosis and Management of Video Game Addiction MMORPGs View Project Diagnosis and Management of Video Game Addiction. (2008).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ko, C. H., Yen, J. Y., Yen, C. F., Chen, C. S. &amp;amp; Wang, S. Y. The association between internet addiction and belief of frustration intolerance: the gender difference. CyberPsychology Behav. 11, 273–278 (2008).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Petry, N. M., Zajac, K. &amp;amp; Ginley, M. K. Behavioral addictions as mental disorders: to be or not to be? Annu. Rev. Clin. Psychol. 14, 399–423 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Everitt, B. J. et al. Neural mechanisms underlying the vulnerability to develop compulsive drug-seeking habits and addiction. Philosophical Trans. Royal Soc. B: Biol. Sci. 363, 3125 (2008).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Volkow, N. D. &amp;amp; Fowler, J. S. Addiction, a disease of compulsion and drive: involvement of the orbitofrontal cortex. Cereb. Cortex. 10, 318–325 (2000).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;This study was funded by the SNSF Ambizione Grant Project PZ00P3_174221 to Stefanie Riemer. Many thanks go to Prof. Hanno Würbel for his feedback and support and to the dog owners and the dogs for their enthusiastic participation in the study.&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;S.R. and A.M. contributed to the conception and design of the research. A.M. drafted the original manuscript, and S.R. provided revisions. A.M. carried out the experiments. K.S., F.M. and A.M. coded the videos. A.M. and S.R. interpreted the data. All authors have read and approved the final version of the manuscript.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding author&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;head rend="h3"&gt;Publisher’s note&lt;/head&gt;
    &lt;p&gt;Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supplementary Information&lt;/head&gt;
    &lt;p&gt;Below is the link to the electronic supplementary material.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Mazzini, A., Senn, K., Monteleone, F. et al. Addictive-like behavioural traits in pet dogs with extreme motivation for toy play. Sci Rep 15, 32613 (2025). https://doi.org/10.1038/s41598-025-18636-0&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1038/s41598-025-18636-0&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45559305</guid><pubDate>Sun, 12 Oct 2025 16:15:45 +0000</pubDate></item><item><title>Oavif: Faster target quality image compression</title><link>https://giannirosato.com/blog/post/oavif/</link><description>&lt;doc fingerprint="15c0199215921a8a"&gt;
  &lt;main&gt;
    &lt;p&gt;oavif is a new approach to target quality encoding in image compression, designed around smarter convergence strategies and quicker scoring to be as fast as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;Target quality encoding is one of the highest impact use cases for image compression. A target quality encoder framework aims to produce an image encoded at a particular quality set by the user according to some metric or visual quality index. This kind of encoder framework is useful for a variety of users, ranging from small website owners to content delivery networks pushing vast quantities of image data through the Web.&lt;/p&gt;
    &lt;p&gt;The value of target quality encoding is perceptual consistency. If I rely entirely on my encoder's internal quality index (often set with a "q" parameter), I may not get outputs of perfectly consistent quality when using the same "q" across different images. Relying on a metric that represents the viewer's experience is the solution to this; targeting a representative score within this metric will ensure you always receive an optimally encoded file that never undershoots and ruins image quality, and never overshoots and wastes data.&lt;/p&gt;
    &lt;p&gt;oavif is a tool to do target quality encoding extremely quickly. There are three core components to a target quality encoding framework: the metric, the encoder, and the convergence algorithm. oavif aims to leverage or improve the state of the art in all three categories.&lt;/p&gt;
    &lt;p&gt;I think this use case has been neglected because it sits in an awkward spot, stuck between encoder development and content deployment. Considering image encoders and powerful metrics are fast, it is easy to take them for granted and build inefficient frameworks around them. Slow frameworks waste valuable resources; processing images is expensive. I built oavif with the same approach I've adopted when building encoders, where every CPU cycle counts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Metric&lt;/head&gt;
    &lt;p&gt;There are good metrics and bad metrics in the context of what humans care about in images. PSNR is a bad metric; targeting a PSNR score doesn't mean anything to users, because images at the same PSNR could look completely different. However, PSNR is very fast, and faster metrics lend themselves more favorably to target quality encoding.&lt;/p&gt;
    &lt;p&gt;SSIMULACRA2 correlates highly with subjective human quality ratings, but it is comparatively slow compared to simpler metrics. I set out to remedy this with fssimu2, a faster implementation that uses almost 40% less memory. This is what oavif uses, and it makes computing the in-loop metric much faster compared to the reference library.&lt;/p&gt;
    &lt;p&gt;Testing on a 4k test image against a distorted sample for an average time to score across 8 runs, Butteraugli (a perceptual metric from the libjxl project) took 2455ms, while the reference SSIMULACRA2 implementation took 1162ms. fssimu2 takes 631.9ms. Testing was done on my M2 MacBook Air using &lt;code&gt;hyperfine&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Encoder&lt;/head&gt;
    &lt;p&gt;AVIF is a capable Web image format. oavif uses libaom (via libavif) because it is the best open-source image encoder available relative to its speed. I worked on improving AVIF encoding in 2024 during my work on SVT-AV1-PSY. Google (with help from Julio Barba) later adopted this work and advanced it further in libaom. It is now used by some websites you may know, such as The Guardian.&lt;/p&gt;
    &lt;p&gt;Aside from speed, encoder consistency is valuable in the context of target quality encoding (I'll explain more about why later). In fact, a perfectly consistent encoder would be able to eliminate the need for targeting entirely since the encoder's user-configurable Q would map perfectly to some perceptual index. libaom has had engineering effort go into encoder consistency, which is a valuable thing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Convergence&lt;/head&gt;
    &lt;p&gt;A simple convergence loop looks like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Decode input, pass to encoder&lt;/item&gt;
      &lt;item&gt;Decode encoder output &amp;amp; compare to input with metric&lt;/item&gt;
      &lt;item&gt;If we hit the target metric score, finish; otherwise, repeat prev. step with modified settings&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most important part here is how we decide to modify our settings. This is the convergence algorithm that allows us to search for the best encoder Q. The easiest way to do this is with binary search, and some more recent implementations have utilized clever interpolation using past data to inform the next guess based on the fact that we know encoder Q and target score are likely correlated.&lt;/p&gt;
    &lt;p&gt;oavif takes inspiration from both of these, adding predictive modeling alongside error-informed search space correction to improve search times significantly. To understand why, we'll walk through each stage of the implementation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Binary Search&lt;/head&gt;
    &lt;p&gt;This testing was done using the Daala subset2 image dataset. Importantly, I only used this dataset for validation; oavif was not designed around this specific dataset in any way. When testing, the oavif configuration was left at defaults; only the convergence implementation was modified. The threshold for meeting the target score is ±2.0 in oavif by default, and the default target score is 80.0 as measured by fssimu2 because it is a reasonable "high fidelity" target.&lt;/p&gt;
    &lt;p&gt;Everyone with some algorithms background will start with binary search. Set your bounds for encoder Q to 0..100, and divide the range in half each time you test. In oavif, a pure binary search implementation at default settings yields the following results:&lt;/p&gt;
    &lt;code&gt;Average encoding time: 467.95 ms ± 94.64
Average passes: 3.20 ± 0.45 (max: 4 min: 2)
&lt;/code&gt;
    &lt;head rend="h3"&gt;Interpolation&lt;/head&gt;
    &lt;p&gt;Interpolation-based target quality searches by iteratively probing, measuring, and narrowing the search interval just like binary search. The difference is that it tries to model the score-vs-quantizer curve with interpolation (linear, quadratic, etc) as more data is accumulated. This should theoretically reduce the number of necessary encodes, and can start with standard binary search when there is not enough data to interpolate with.&lt;/p&gt;
    &lt;p&gt;Metric score vs encoder Q is generally (though not perfectly) a mostly monotonic curve. Interpolation-based inverse estimation uses the measured points to approximate that curve and solve for the quantizer that would produce the target score. Higher-order methods use more shape information and are thus theoretically more accurate. Adding linear and quadratic interpolation support to oavif, we see a small reduction in the average number of passes on subset2:&lt;/p&gt;
    &lt;code&gt;Average encoding time: 468.98 ms ± 97.28
Average passes: 3.12 ± 0.39 (max: 4 min: 2)
&lt;/code&gt;
    &lt;p&gt;This is a 2.5% improvement. We still need a minimum of two passes to accurately target.&lt;/p&gt;
    &lt;head rend="h3"&gt;Predictive Modeling&lt;/head&gt;
    &lt;p&gt;This feature uses an exponential curve trained on the gb82 image dataset with libaom (at speed 9, 10-bit, 4:4:4 chroma). The curve looks like this:&lt;/p&gt;
    &lt;p&gt;Based on this, we can write some very simple code to predict a Q value from the target score:&lt;/p&gt;
    &lt;code&gt;fn predictQFromScore(tgt: f64) u32 {
    const q = 6.83 * @exp(0.0282 * tgt);
    return @intFromFloat(@min(100.0, @round(q)));
}
&lt;/code&gt;
    &lt;p&gt;This yields the biggest average improvement in this testing so far, decreasing average pass count by 56.4% versus interpolation search and 57.5% versus binary search.&lt;/p&gt;
    &lt;code&gt;Average encoding time: 218.33 ms ± 114.16
Average passes: 1.36 ± 0.78 (max: 3 min: 1)
&lt;/code&gt;
    &lt;p&gt;The gb82 image set is fairly low-resolution mixed photographic content, while Daala subset2 is medium-resolution photographic content with less variation. The fact that the model generalizes so well is exciting.&lt;/p&gt;
    &lt;p&gt;It is at this stage that encoder consistency becomes important. A more consistent encoder will diverge from our model's predictions less frequently, and theoretically result in a faster target quality loop.&lt;/p&gt;
    &lt;head rend="h3"&gt;Error Bounds&lt;/head&gt;
    &lt;p&gt;Because our initial predictions tend to be so accurate, we can use them to aggressively narrow our search space without incurring too much risk of a search space collapse.&lt;/p&gt;
    &lt;p&gt;The basis of this is that utilizing plain binary search with prediction is often unreliable. Let's say we would like to target score=80, and our model predicts we need Q=65. We score 82.38. Now we are forced to search (0..65), which is worse than if we had just avoided prediction in the first place (our search space would be 50..100 in that case). This is in spite of the fact that our prediction was very close to the target.&lt;/p&gt;
    &lt;p&gt;oavif uses the distance from the target to its advantage:&lt;/p&gt;
    &lt;code&gt;const abs_err = @abs(e.t.score - o.score_tgt);
if (pass == 0) {
    const err_bound: u32 = @intFromFloat(@ceil(abs_err) * 4.0);
    if (e.t.score - o.score_tgt &amp;gt; 0) {
        hi_bound = e.q;
        lo_bound = if (e.q &amp;gt; err_bound) e.q - err_bound else 0;
    } else {
        lo_bound = e.q;
        hi_bound = @min(100, e.q + err_bound);
    }
}
&lt;/code&gt;
    &lt;p&gt;In this case, the error was 2.38; &lt;code&gt;@ceil()&lt;/code&gt; brings this to 3, and we multiply by 4 because the midpoint of the new range tends to be very close to the target value based on my testing. The performance improves in kind:&lt;/p&gt;
    &lt;code&gt;Average encoding time: 194.50 ms ± 69.89
Average passes: 1.18 ± 0.39 (max: 2 min: 1)
&lt;/code&gt;
    &lt;p&gt;This costs 13.2% fewer passes than interpolation + prediction, and 63.1% fewer passes than binary search.&lt;/p&gt;
    &lt;p&gt;The minimum number of passes necessary in a naive binary search or interpolation-informed search is now the maximum number of passes we need to converge on the target on Daala subset2. You'll also notice the standard deviation went down due to the fact that the ceiling has been lowered.&lt;/p&gt;
    &lt;head rend="h2"&gt;Architecture&lt;/head&gt;
    &lt;p&gt;We've made it work and we've made it good, so now we can make it fast. oavif is written in Zig, and uses available high-performance C decoder libraries for handling inputs and decoding AVIF in the convergence loop. All image I/O during convergence is done in memory, and a buffer is kept of our latest encode to write to a file if we meet the target in the search space.&lt;/p&gt;
    &lt;p&gt;Efforts have gone into making oavif comparable to libavif's &lt;code&gt;avifenc&lt;/code&gt; in terms of features as well. It supports high bit depth I/O, ICC profile handling for most formats, user-configurable encoder settings, and better defaults (until tune=iq becomes the libaom default in libavif).&lt;/p&gt;
    &lt;head rend="h2"&gt;Future Directions&lt;/head&gt;
    &lt;p&gt;Architecturally, it would be trivial to keep a history of buffers active and always pick from the history, even if our loop doesn't converge on the target. I opted to avoid this for now because it dramatically increases memory usage, but if I receive widespread feedback that memory is unimportant I'll consider an implementation. In its current state, we hit the in-loop buffer the vast majority of the time anyway.&lt;/p&gt;
    &lt;p&gt;I think the future of this kind of workflow is far more accurate predictive modeling. I believe it is possible to improve what I've done if we provide details about the source image as another term in the equation (like variance or entropy) and train our prediction mechanism on this additional data. I'm optimistically convinced this could result in a very high success rate for one-shot targeting.&lt;/p&gt;
    &lt;p&gt;I'm looking forward to seeing more target quality workflows taking advantage of smarter targeting. If you've made it this far, thanks for reading, and enjoy oavif!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45559372</guid><pubDate>Sun, 12 Oct 2025 16:21:59 +0000</pubDate></item><item><title>Wireguard FPGA</title><link>https://github.com/chili-chips-ba/wireguard-fpga</link><description>&lt;doc fingerprint="b5d9dc196105abe7"&gt;
  &lt;main&gt;
    &lt;p&gt;Virtual Private Networks (VPNs) are the central and indispensable component of Internet security. They comprise a set of technologies that connect geographically dispersed, heterogeneous networks through encrypted tunnels, creating the impression of a homogenous private network on the public shared physical medium.&lt;/p&gt;
    &lt;p&gt;With traditional solutions (such as OpenVPN / IPSec) starting to run out of steam, Wireguard is increasingly coming to the forefront as a modern, secure data tunneling and encryption method, one that's also easier to manage than the incumbents. Both software and hardware implementations of Wireguard already exist. However, the software performance is far below the speed of wire. Existing hardware approaches are both prohibitively expensive and based on proprietary, closed-source IP blocks and tools.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The intent of this project is to bridge these gaps with an FPGA open-source implementation of Wireguard, written in SystemVerilog HDL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We have contributed to the Blackwire project, which is a 100Gbps hardware implementation of Wireguard switch based on AMD/Xilinx-proprietary AlveoU50 PC-accelerator card (SmartNIC form-factor), and implementable only with proprietary Vivado toolchain.&lt;/p&gt;
    &lt;p&gt;While working on the Blackwire, we have touched multiple sections, and focused on the novel algorithm for Balanced Binary Tree Search of IP tables. However, the Blackwire hardware platform is expensive and priced out of reach of most educational institutions. Its gateware is written in SpinalHDL, a nice and powerfull but a niche HDL, which has not taken roots in the industry. While Blackwire is now released to open-source, that decision came from their financial hardship -- It was originaly meant for sale. Moreover, the company behind it is subject to disputes and obligations that bring into question the legality of ownership over the codebase they "donated" to the open source community.&lt;/p&gt;
    &lt;p&gt;To make the hardware Wireguard truly accessible in the genuine spirit of open-source movement, this project implements it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;for an inexpensive hardware platform with four 1000Base-T ports&lt;/item&gt;
      &lt;item&gt;in a self-sufficient way, i.e. w/o requiring PC host&lt;/item&gt;
      &lt;item&gt;using a commodity Artix7 FPGA&lt;/item&gt;
      &lt;item&gt;which is supported by open-source tools&lt;/item&gt;
      &lt;item&gt;and with all gateware written in the ubiquitous Verilog / System Verilog&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[Ref1] Wireguard implementations in software:&lt;/p&gt;
    &lt;p&gt;[Ref2] 100Gbps Blackwire Wireguard&lt;/p&gt;
    &lt;p&gt;[Ref3] Corundum, open-source FPGA-NIC platform&lt;/p&gt;
    &lt;p&gt;[Ref4] ChaCha20-Poly1305 open-source Crypto RTL&lt;/p&gt;
    &lt;p&gt;[Ref5] Cookie Cutter SOC&lt;/p&gt;
    &lt;p&gt;[Ref6] RISC-V ISS&lt;/p&gt;
    &lt;p&gt;[Ref7] 10Gbps Ethernet Switch&lt;/p&gt;
    &lt;p&gt;[Ref8] OpenXC7 open-source tools for Xilinx Series7&lt;/p&gt;
    &lt;p&gt;[Ref9] Alex's Ethernet Stack&lt;/p&gt;
    &lt;p&gt;[Ref10] Amina's ADASEC-SDN&lt;/p&gt;
    &lt;p&gt;The Phase1 (This!) is primarily Proof of Concept, i.e. not full-featured, and definitely not a deployable product. It is envisoned as a mere on-ramp, a springboard for future build-up and optimizations.&lt;/p&gt;
    &lt;p&gt;The Phase2 continuation project is therefore also in the plans, to maximize efficiency and overall useability, such as by increasing the number of channels, facilitating management with GUI apps, or something else as identified by the community feedback.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;HW/SW partitioning, interface, interactions and workload distribution&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;While, contrary to Blackwire, we don’t rely on an external PC connected via PCIE, we will still have an on-chip RISC-V CPU with intricate hardware interface and significant Embedded Software component that controls the backbone of wire-speed datapath&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;HW/SW co-development, integration and debugging&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Standard simulation is impractical for the project of this size and complexity. We therefore intend to put to test and good use the very promissing new VProc ISS [Ref6]&lt;/item&gt;
          &lt;item&gt;It’s also impractical and expensive to provide full test systems with real traffic generators and checkers to all developers. We therefore plan to rent some space for a central lab that will host two test systems, then provide remote access to all developers&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Real-life, at-speed testing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Extent of open-source tools support for SystemVerilog and all needed FPGA primitives and IP functions&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;QOR of the (still maturing) open-source tools&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Blackwire used commercial, AMD/Xilinx-proprietary Vivado toolchain, as well as high-end Alveo U50 FPGA silicon. Even then, they ran into multiple timing closure, utilization and routing congestion challenges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Financial resources&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Given that this is a complex, multi-disciplinary dev effort, the available funding may not be sufficient to bring it to completion. Blackwire, despite a larger allocated budget, ended up with funding crisis and abrupt cessation of dev activities.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is WIP at the moment. The checkmarks below indicate our status. Until all checkmarks are in place, anything you get from here is w/o guaranty -- Use at own risk, as you see fit, and don't blame us if it is not working 🌤️&lt;/p&gt;
    &lt;p&gt;Board bring up. In-depth review of Wireguard ecosystem and prior art. Design Blueprint&lt;/p&gt;
    &lt;p&gt;While the board we're using is low cost, it is also not particularly known in the open-source community. We certainly don’t have prior experience with it. In this opening take we will build a solid foundation for efficient project execution. Good preparation is crucial for a smooth run. We thus seek to first &lt;code&gt;understand and document what we will be designing: SOC Architecture, Datapath Microarchitecture, Hardware/Software Partitioning, DV and Validation Strategy&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Getting a good feel for our Fmax is also a goal of this take. Artix-7 does not support High-Performance (HP) I/O. Consequently, we cannot push its I/O beyond 600MHz, nor its core logic beyond 100 MHz.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Familiarization with HW platform&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Create our first FPGA program that blinks LEDs&lt;/item&gt;
          &lt;item&gt;Verify pinouts and connectivity using simple test routines&lt;/item&gt;
          &lt;item&gt;Generate a few Ethernet test patterns&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Familiarization with SW platform&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Initial bring up of embedded CPU within a cookie-cutter SOC, such as [Ref5]&lt;/item&gt;
          &lt;item&gt;Design and test a simple SW interface to rudimentary HW Ethernet datapath&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Detailed analysis and comparisons of:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Wireguard White Papers&lt;/item&gt;
          &lt;item&gt;existing implementations in software [Ref1]&lt;/item&gt;
          &lt;item&gt;vs. Blackwire hardware implementation [Ref2]&lt;/item&gt;
          &lt;item&gt;cryptographic algorithms used for Wireguard, esp. ChaCha20 for encryption, Poly1305 for authentication [Ref4] and, to a lesser extent, Curve25519 for key exchange and blake2 for hashing&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Identification and assimilation of prior art and building IP blocks, in particular Corundum [Ref3] and, to a lesser extent, 10GE Switch [Ref7]&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Architecture/uArch Design. HW/SW Partitioning. Verification Plan&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Creation of sufficient initial documentation for project divide-and-conquer across a multi-disciplinary team of half a dozen developers&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation of a basic, statically pre-configured Wireguard link&lt;/p&gt;
    &lt;p&gt;It it in this take that we start creating hardware Datapath and hardening Wireguard encryption protocols, all using Vivado and Xilinx primitives.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Integration of collected RTL blocks into a coherent HW system that implements the basic Wireguard datapath for a handful of manually pre-configured channels.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Corundum FPGA-based NIC and platform for opensource Ethernet development [Ref3]&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;IP Core for ChaCha20-Poly1305 [Ref4] -- Definitely in hardware from the get-go&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Curve25519 module for key exchange -- Likely in software at this point&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;blake2 module for hashing (we'll most likely do it in software)&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Timing closure. Resolution of FPGA device utilization and routing congestion issues&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Creation of cocoTB DV in the CI/CD environmenT, and representative test cases for datapath simulation&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Development and integration of embedded management software (Control Plane)&lt;/p&gt;
    &lt;p&gt;This work package is about hardware/software codesign and integration. The firmware will run on a soft RISC V processor, inside the FPGA. Our vanilla SOC is at this point starting to be customized to Wireguard needs. This work can to some extent go on in parallel with hardware activities of Take2.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;SW design for on-chip processor (Part 1)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Code is to be written in the bare-metal C with, as necessary, a few sections in Assembly&lt;/item&gt;
          &lt;item&gt;SW is responsible for configuration and management of hardware blocks&lt;/item&gt;
          &lt;item&gt;SW must not participate in the bulk datapath transfers&lt;/item&gt;
          &lt;item&gt;SW may however intercept the low-frequency management packets&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SW design for on-chip processor (Part 2)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;KMM function -- Key Management Module&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;HW/SW Integration&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;VPN Tunnel: Session initialization, maintenance, and secure closure&lt;/p&gt;
    &lt;p&gt;This is about managing the bring-up, maintenance and tear-down of VPN tunnels between two devices.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Session Initialization: Starting the handshake process to establish secure communication with another device&lt;/item&gt;
      &lt;item&gt;Session Maintenance: Keeping the session active through the regular exchange of control messages, which allows detection and recovery from problems such as connection interruptions&lt;/item&gt;
      &lt;item&gt;Session Closure: Securely close the VPN tunnel when communication is no longer needed, ensuring that all temporary keys and sensitive data are deleted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Testing, Profiling and Porting to OpenXC7&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Functional testing on the real system. Does it work as intended? Bug fixes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Performance testing. HW/SW profiling, updates and enhancements to ensure the design indeed operates at close to the wire speed on all preconfigured channels&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Porting to openXC7 [Ref8] using SV2V, in the GoCD CI/CD setting&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;This is challenging, as openXC7 has thus far been crashing for NES SV&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Timing closure with openXC7&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;This is definitely challenging, given that openXC7 is currently without accurate timing-driven STA&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Filing bug tickets with open source developers for issues found in their tools, supporting them all the way to the resolution&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Creation and maintenance of an attractive and well-documented Github repo, to entice community interest&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ongoing documentation updates and CI/CD script maintenance to keep it valid in the light of inevitable design mutations compared to the original Design Blueprint.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Flow control module for efficient and stable VPN tunnel data management&lt;/p&gt;
    &lt;p&gt;The objective of this optional deliverable is to ensure stable and efficient links, thus taking this project one step closer to a deployable product.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Develop software components for management of data flow within VPN tunnels&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since the WireGuard node essentially functions as an IP router with WireGuard protocol support, we have decided to design the system according to a two-layer architecture: a control plane responsible for managing IP routing processes and executing the WireGuard protocol (managing remote peers, sessions, and keys), and a data plane that will perform IP routing and cryptography processes at wire speed. The control plane will be implemented as software running on a soft CPU, while the data plane will be fully implemented in RTL on an FPGA.&lt;/p&gt;
    &lt;p&gt;In the HW/SW partitioning diagram, we can observe two types of network traffic: control traffic, which originates from the control plane and goes toward the external network (and vice versa), and data traffic, which arrives from the external network and, after processing in the data plane, returns to the external network. Specifically, control traffic represents WireGuard protocol handshake messages, while data traffic consists of end-user traffic, either encrypted or in plaintext, depending on the perspective.&lt;/p&gt;
    &lt;p&gt;The hardware architecture essentially follows the HW/SW partitioning and consists of two domains: a soft CPU for the control plane and RTL for the data plane.&lt;/p&gt;
    &lt;p&gt;The soft CPU is equipped with a Boot ROM and a DDR3 SDRAM controller for interfacing with off-chip memory. External memory is exclusively used for control plane processes and does not store packets. The connection between the control and data planes is established through a CSR-based HAL.&lt;/p&gt;
    &lt;p&gt;The data plane consists of several IP cores, including data plane engine (DPE) and supporting components, which are listed and explained in the direction of network traffic propagation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PHY Controller - initial configuration of Realtek PHYs and monitoring link activity (link up/down events)&lt;/item&gt;
      &lt;item&gt;1G MAC - execution of the 1G Ethernet protocol (framing, flow control, FCS, etc.)&lt;/item&gt;
      &lt;item&gt;Rx FIFOs - clock domain crossing, bus width conversion, and store &amp;amp; forward packet handling&lt;/item&gt;
      &lt;item&gt;Per-Packet Round Robin Multiplexer - servicing Rx FIFOs on a per-packet basis using a round-robin algorithm&lt;/item&gt;
      &lt;item&gt;Header Parser - extraction of WireGuard-related information from packet headers (IP addresses, UDP ports, WireGuard message type, peer ID, etc.)&lt;/item&gt;
      &lt;item&gt;Wireguard/UDP Packet Disassembler - decapsulation of the payload from the Wireguard data packet for decryption of tunneled traffic&lt;/item&gt;
      &lt;item&gt;ChaCha20-Poly1305 Decryptor - decryption and authentication of tunneled traffic&lt;/item&gt;
      &lt;item&gt;IP Lookup Engine - routing/forwarding table lookup, mapping packets to the appropriate WireGuard peer, and making packet accept/reject decisions&lt;/item&gt;
      &lt;item&gt;ChaCha20-Poly1305 Encryptor - encryption and authentication of traffic to be tunneled&lt;/item&gt;
      &lt;item&gt;Wireguard/UDP Packet Assembler - encapsulation of the encrypted packet into a WireGuard data packet for tunneling to the remote peer&lt;/item&gt;
      &lt;item&gt;Per-Packet Demultiplexer - forwarding packets to Tx FIFOs based on packet type and destination&lt;/item&gt;
      &lt;item&gt;Tx FIFOs - clock domain crossing, bus width conversion, and store &amp;amp; forward packet handling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ChaCha20-Poly1305 Encryptor/Decryptor are using RFC7539's AEAD (Authenticated Encryption Authenticated Data) construction based on ChaCha20 for symmetric encryption and Poly1305 for authentication.&lt;/p&gt;
    &lt;p&gt;The details of hardware architecture can be found in the README.md in the &lt;code&gt;1.hw/&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;The conceptual class diagram provides an overview of the components in the software part of the system without delving into implementation details. The focus is on the WireGuard Agent, which implements the protocol's handshake procedures, along with the following supplementary components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Curve25519 - an ECDH algorithm implementation for establishing a shared secret using a public-private key pair between two remote parties connected via an insecure channel, such as the Internet&lt;/item&gt;
      &lt;item&gt;ChaCha20-Poly1305 - an AEAD algorithm implementation for encryption and authentication of static keys and nonce values to prevent replay attacks&lt;/item&gt;
      &lt;item&gt;XChaCha20-Poly1305 - a XAEAD algorithm implementation for encrypting and authenticating nonce values in Cookie Replay messages to mitigate potential DoS attacks&lt;/item&gt;
      &lt;item&gt;BLAKE2s - an implementation of the BLAKE2s hash function for MAC authentication and keyed hashing, per RFC7693&lt;/item&gt;
      &lt;item&gt;RNG - a random number generator used to initialize the DH key generator and generate peer identifiers&lt;/item&gt;
      &lt;item&gt;Timer - timers for rekey, retry, and keepalive procedures&lt;/item&gt;
      &lt;item&gt;HKDF - an implementation of the algorithm for expanding the ECDH result&lt;/item&gt;
      &lt;item&gt;RTC - a real-time clock used to generate the TAI64N timestamp&lt;/item&gt;
      &lt;item&gt;SipHash - a simple non-cryptographic function used for implementing a hashtable for fast lookup of decrypted static public keys of remote peers&lt;/item&gt;
      &lt;item&gt;Routing DB Updater - a subsystem for maintaining the cryptokey routing table content and deploying it to the data plane via the HAL/CSR interface&lt;/item&gt;
      &lt;item&gt;ICMP - implementing basic ICMP protocol functions (echo request/reply, TTL exceeded, etc.)&lt;/item&gt;
      &lt;item&gt;CLI - a USB/UART-based command-line interface for configuring the WireGuard node (setting the local IP address, remote peer IP addresses, network addresses, keys, etc.)&lt;/item&gt;
      &lt;item&gt;HAL/CSR Driver - a CSR-based abstraction for data plane components with an interface for reading/writing the corresponding registers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The details of software architecture can be found in the README.md in the &lt;code&gt;2.sw/&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;To illustrate the operation of the system as a whole, we have prepared a step-by-step analysis of packets processing based on the capture of real WireGuard traffic. The experimental topology consists of four nodes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10.10.0.2 - the end-user host at site A&lt;/item&gt;
      &lt;item&gt;10.9.0.1 - WireGuard peer A&lt;/item&gt;
      &lt;item&gt;10.9.0.2 - WireGuard peer B&lt;/item&gt;
      &lt;item&gt;10.10.0.1 - the end-user host at site B&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The detailed analysis can be found in the README.md in the &lt;code&gt;1.hw/&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;The Wireguard FPGA test bench aims to have a flexible approach to simulation which allows a common test environment to be used whilst selecting between alternative CPU components, one of which uses the VProc virtual processor co-simulation element. This allows simulations to be fully HDL, with a RISC-V processor RTL implementation such as picoRV32, IBEX or EDUBOS5, or to co-simulate software using the virtual processor, with a significant speed up in simulation times. The test bench has the following features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A VProc virtual processor based &lt;code&gt;soc_cpu.VPROC&lt;/code&gt;component&lt;list rend="ul"&gt;&lt;item&gt;Selectable between this or an RTL softcore&lt;/item&gt;&lt;item&gt;Can run natively compiled test code&lt;/item&gt;&lt;item&gt;Can run the application compiled natively with the auto-generated co-sim HAL&lt;/item&gt;&lt;item&gt;Can run RISC-V compiled code using the rv32 RISC-V ISS model&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Uses a C sparse memory model &lt;list rend="ul"&gt;&lt;item&gt;An HDL component instantiated in logic gives logic access to this memory&lt;/item&gt;&lt;item&gt;An API is provided to VProc running code for direct access&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The udpIpPg VIP is used to drive the logic's four ethernet ports in a four port &lt;code&gt;bfm_ethernet&lt;/code&gt;block.&lt;list rend="ul"&gt;&lt;item&gt;An MDIO slave interface is also provided that maps mem_model memory areas to the registers with instantiated mem_model components&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The figure below shows an oveview block diagram of the test bench HDL.&lt;/p&gt;
    &lt;p&gt;More details on the architecture and usage of the Wireguard test bench can be found in the README.md in the &lt;code&gt;4.sim&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;The Wireguard control and status register harware abstraction layer (HAL) software is auto-generated, as is the CSR RTL, using &lt;code&gt;peakrdl&lt;/code&gt;. For co-simulation purposes an additional layer is auto-generated from the same SystemRDL specification using &lt;code&gt;systemrdl-compiler&lt;/code&gt; that accompanies the &lt;code&gt;peakrdl&lt;/code&gt; tools. This produces two header files that define a common API to the application layer for both the RISC-V platform and the VProc based co-simulation verification environment. The details of the HAL generation can be found in the README.md in the &lt;code&gt;3.build/&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;WIP&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verilator v5.024&lt;/item&gt;
      &lt;item&gt;VProc v1.12.2&lt;/item&gt;
      &lt;item&gt;Mem Model v1.0.0&lt;/item&gt;
      &lt;item&gt;rv32 ISS v1.1.4&lt;/item&gt;
      &lt;item&gt;udpIpPg v1.0.3&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;We are grateful to NLnet Foundation for their sponsorship of this development activity.&lt;/p&gt;
    &lt;p&gt;The wyvernSemi's wisdom and contribution made a great deal of difference -- Thank you, we are honored to have you on the project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45559857</guid><pubDate>Sun, 12 Oct 2025 17:12:00 +0000</pubDate></item><item><title>Constraint satisfaction to optimize item selection for bundles in Minecraft</title><link>https://www.robw.fyi/2025/10/12/using-constraint-satisfaction-to-optimize-item-selection-for-bundles-in-minecraft/</link><description>&lt;doc fingerprint="fa6c0da3bdcf216"&gt;
  &lt;main&gt;
    &lt;p&gt;I read a blog post on how Many Hard Leetcode Problems are Easy Constraint Problems and was pleasantly surprised at how approachable MiniZinc was compared to other solver software I have been exposed to, and the examples given helped me to understand how to apply it to a domain I was already familiar with. I have always wanted to be able to get more familiar with using constraint satisfaction as a way to solve problems, so I decided to create a solver to help optimize storage space for Minecraft using constraint satisfaction to help learn how to use this tool. I will outline my thought process and how I reached the solution I came up with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Game Mechanics&lt;/head&gt;
    &lt;p&gt;In Minecraft, your player inventory is limited. You have 27 inventory slots, 9 hotbar slots, 4 armor slots, 4 temporary crafting slots, 1 offhand slot, 1 temporary slot for the result of crafting, and you can hold 1 item in your cursor (thanks charcircuit).&lt;/p&gt;
    &lt;p&gt;Each slot can either contain a single item, a small stack of 16, or a full stack of 64 items, depending on the item.&lt;/p&gt;
    &lt;p&gt;Often when adventuring, you will come across many rare and powerful items and accumulate many items in your inventory slots, but they may be stacks of items that are not at maximum capacity for that inventory slot. Once your inventory is full, you cannot pick up new items. Using bundles, you can consolidate your inventory and pick up more items.&lt;/p&gt;
    &lt;p&gt;A bundle is an item that can store up to a stack’s worth of mixed item types within itself in a single inventory slot. Items can be individually selected and taken out of the bundle via the inventory menu.&lt;/p&gt;
    &lt;p&gt;Item stack sizes (top row) and the number of bundle slots they take up (middle row). Sticks stack to 64, so they take up one bundle slot; ender pearls stack to 16, so they take up four; and swords do not stack, so they take up the whole bundle. So, for instance, a bundle may have 32 sticks and 8 ender pearls inside, which take up a total of (32×1)+(8×4)=64 bundle slots.&lt;/p&gt;
    &lt;head rend="h2"&gt;Creating an Optimizer&lt;/head&gt;
    &lt;p&gt;Using the MiniZinc Playground, we can model our player’s inventory and the constraints such that we free up the maximum number of inventory slots. That way, our player can pick up the most new items!&lt;/p&gt;
    &lt;p&gt;First, let’s create an inventory and let’s only focus on items that have full stacks. We can maximize our free inventory slots for this case, and then we will progressively make our way toward supporting all of the item types.&lt;/p&gt;
    &lt;code&gt;array[int] of int: inventory = [
  % fullstack of dirt 
  64,
  % half of a fullstack of wood
  32,
  % half stack of a fullstack of  wool
  32,
  % quarter of fullstack of sticks
  16,
  % quarter of a fulstack of carrots
  16
];&lt;/code&gt;
    &lt;p&gt;If our optimizer was working, it would select three slots of our inventory to go in the bundle to maximize our free inventory space. We can model inventory selection by creating another array of integers of either 0 or 1, with 1 representing a selected slot in our inventory and 0 representing an unselected slot.&lt;/p&gt;
    &lt;code&gt;int: n = length(inventory);
array[1..n] of var 0..1: selected;&lt;/code&gt;
    &lt;p&gt;Once we have this array representing our selected slots, we can maximize the sum of our array in order to select the most slots possible.&lt;/p&gt;
    &lt;code&gt;solve maximize sum(i in 1..n)(selected[i]);&lt;/code&gt;
    &lt;p&gt;The full code now will look like this&lt;/p&gt;
    &lt;code&gt;% Use this editor as a MiniZinc scratch book
array[int] of int: inventory = [
  % fullstack of dirt 
  64,
  % half of a fullstack of wood
  32,
  % half stack of a fullstack of  wool
  32,
  % quarter of fullstack of sticks
  16,
  % quarter of a fulstack of carrots
  16
];

int: n = length(inventory);
array[1..n] of var 0..1: selected;

solve maximize sum(i in 1..n)(selected[i]);&lt;/code&gt;
    &lt;p&gt;if we ran this on the playground, the output is&lt;/p&gt;
    &lt;code&gt;Running Playground.mzn
selected = [0, 0, 0, 0, 0];
----------
selected = [1, 0, 0, 0, 0];
----------
selected = [1, 1, 0, 0, 0];
----------
selected = [1, 1, 1, 0, 0];
----------
selected = [1, 1, 1, 1, 0];
----------
selected = [1, 1, 1, 1, 1];
----------
==========
Finished in 215msec.&lt;/code&gt;
    &lt;p&gt;Our solver found the solution &lt;code&gt;selected = [1, 1, 1, 1, 1];&lt;/code&gt; to maximize our selected slots in our inventory, which means it selected every slot. This makes sense because we did not constrain it in any way. Let’s add some constraints so we can now make better-informed selections.&lt;/p&gt;
    &lt;p&gt;The constraint we are exceeding is our bundle capacity. If we include our bundle capacity in our model and constrain our selections to include only inventory items that do not exceed the bundle capacity, we can find a valid solution.&lt;/p&gt;
    &lt;code&gt;int: capacity = 64;
constraint sum(i in 1..n)(selected[i] * inventory[i]) &amp;lt;= capacity;&lt;/code&gt;
    &lt;p&gt;If we add this constraint to our model and run it again, we can see that it now only selects three inventory slots, and it selects slots that do not exceed the capacity of our bundle.&lt;/p&gt;
    &lt;code&gt;Running Playground.mzn
selected = [0, 0, 0, 0, 0];
----------
selected = [1, 0, 0, 0, 0];
----------
selected = [0, 1, 1, 0, 0];
----------
selected = [0, 1, 0, 1, 1];
----------
==========
Finished in 207msec.&lt;/code&gt;
    &lt;p&gt;Great! Our initial model works for items that all stack to 64, but Minecraft has items with different maximum stack sizes. As mentioned earlier:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Items that stack to 64 (like dirt, sticks) take up 1 bundle slot per item&lt;/item&gt;
      &lt;item&gt;Items that stack to 16 (like ender pearls, snowballs) take up 4 bundle slots per item&lt;/item&gt;
      &lt;item&gt;Unstackable items (like tools, armor) take up 64 bundle slots (the entire bundle)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To handle this in our model, we need to represent each item’s bundle cost accurately. We’ll use a scaled representation to avoid decimal arithmetic:&lt;/p&gt;
    &lt;code&gt;int: units = 16 * 64;  % Total bundle capacity (1024 units)
int: fullstack = 1 * 16;  % Cost per fullstack item (16 units per item)
int: smallstack = 1 * 64;  % Cost per smallstack item (64 units per item)
int: unstackable = 16 * 64 + 1;  % Cost exceeds capacity (1025 units)&lt;/code&gt;
    &lt;p&gt;Why scale by 16? This gives us clean integer values:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1 dirt item = 16 units (1 bundle slot × 16)&lt;/item&gt;
      &lt;item&gt;1 ender pearl = 64 units (4 bundle slots × 16)&lt;/item&gt;
      &lt;item&gt;Total capacity = 1024 units (64 bundle slots × 16)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now we can model a more realistic inventory:&lt;/p&gt;
    &lt;code&gt;array[int] of int: inventory = [
  % full stack of 64 dirt (takes entire bundle)
  64 * fullstack,  % 64 × 16 = 1024 units
  
  % full stack of 16 ender pearls (takes entire bundle)
  16 * smallstack,  % 16 × 64 = 1024 units
  
  % 1 pickaxe (can't fit with anything else)
  unstackable,  % 1025 units
  
  % half stack of 32 dirt (half a bundle)
  32 * fullstack,  % 32 × 16 = 512 units
  
  % half stack of 8 ender pearls (half a bundle)
  8 * smallstack,  % 8 × 64 = 512 units
];&lt;/code&gt;
    &lt;p&gt;and the rest of the model remains the same&lt;/p&gt;
    &lt;code&gt;int: n = length(inventory);
array[1..n] of var 0..1: selected;

constraint sum(i in 1..n)(selected[i] * inventory[i]) &amp;lt;= units;
solve maximize sum(i in 1..n)(selected[i]);&lt;/code&gt;
    &lt;p&gt;the full example:&lt;/p&gt;
    &lt;code&gt;int: units = 16 * 64;
int: fullstack = 1 * 16;
int: smallstack = 1 * 64;
int: unstackable = 16 * 64 + 1;

array[int] of int: inventory = [
  % stack of dirt 
  64 * fullstack,
  % stack of ender pearls 
  16 * smallstack,
  % pickaxe
  unstackable,
  % half stacks, should select these to maximize inventory space
  32 * fullstack,
  8 * smallstack,
];

int: n = length(inventory);
array[1..n] of var 0..1: selected;

constraint sum(i in 1..n)(selected[i] * inventory[i]) &amp;lt;= units;
solve maximize sum(i in 1..n)(selected[i]);&lt;/code&gt;
    &lt;p&gt;When we run this on the playground, we can see that it selects the last two slots, which correctly selects the maximum number of mixed items to store in a bundle.&lt;/p&gt;
    &lt;code&gt;Running Playground.mzn
selected = [0, 0, 0, 0, 0];
----------
selected = [1, 0, 0, 0, 0];
----------
selected = [0, 0, 0, 1, 1];
----------
==========
Finished in 169msec.&lt;/code&gt;
    &lt;p&gt;Using MiniZinc, we can represent our problem declaratively, making it easy to extend and modify as needed. If game mechanics change or we want to support other storage systems like shulker boxes, we can simply update our constraints. This project was an enjoyable introduction to constraint satisfaction problems, and the MiniZinc Playground made it accessible without requiring any local setup.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45560535</guid><pubDate>Sun, 12 Oct 2025 18:31:51 +0000</pubDate></item><item><title>Completing a BASIC language interpreter in 2025</title><link>https://nanochess.org/ecs_basic_2.html</link><description>&lt;doc fingerprint="9f546b51621a25d4"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h1"&gt;Completing a BASIC language interpreter in 2025&lt;/head&gt;
        &lt;div&gt;&lt;p&gt; This is a follow-up to my previous article &lt;/p&gt;Developing a BASIC language in 2025&lt;p&gt;, where I describe how I got inspired to start coding a new BASIC interpreter for the 1983 Mattel ECS add-on for Intellivision. &lt;/p&gt;&lt;/div&gt;
        &lt;p&gt; Although my interpreter was already pretty fast and with enough statements to build games, I wasn't satisfied because it still missed one thing that the ECS BASIC implements: text strings. Only three, A$, B$, and C$, with SET, GET and PUT, for things like assigning a string, getting a name from the keyboard, or showing a name. Each string a maximum of 20 characters. &lt;/p&gt;
        &lt;p&gt; I thought about strings for four days, then I decided to code things like I know what I was doing. I added a string stack pointer bas_strptr where any created string is added. &lt;/p&gt;
        &lt;p&gt; The first thing to implement was an array for the string variables (A$-Z$) each element pointing to the current string contained (or zero if none). I modified the whole of the expression parser to insert the type in the Carry flag (Clear = it is a number, Set = it is a string), then I made the first string support in the language where it detects if a string name appears (letter plus the $ sign) and reads it and copies it to a new string on the stack, returning this pointer as expression value (and of course the carry flag set) &lt;/p&gt;
        &lt;p&gt; The next step was assigning string variables, it simply took the pointer and stored it into the respective string variable pointer. Of course, I was afraid that I was creating a monster because I wasn't planning for the garbage collector. &lt;/p&gt;
        &lt;p&gt; Then I went full-steam ahead and put support in INPUT, PRINT, and added the concatenation of strings using the plus operator, also the functions ASC, CHR$, LEN, LEFT$, RIGHT$, MID$, INSTR, VAL, and STR$. By the way, the original Mattel ECS BASIC has none of these! &lt;/p&gt;
        &lt;p&gt; Now I had string support in my BASIC language for the ECS, but at some point in the execution it would fill up the stack, and crash with an "Out of Memory" error. &lt;/p&gt;
        &lt;head rend="h2"&gt;Garbage collection&lt;/head&gt;
        &lt;p&gt; It was kind of crazy having a BASIC with string support but no garbage collection. I needed a way to copy strings into the respective variable, and delete the work-in-progress strings created as expressions are evaluated. &lt;/p&gt;
        &lt;p&gt; It would be easy when having a C memory management system as you only have to replace the pointer, and free the original. But any memory management comes with headers and linked lists, extra memory requirements, and slowness. Given the Intellivision CP1610 processor is already slow enough (894 khz), I decided against it. &lt;/p&gt;
        &lt;p&gt; However, I noticed that temporary strings are only created inside the expression parser. So what about a double stack? One stack for strings in variables, and one stack for temporary strings. &lt;/p&gt;
        &lt;p&gt; I added a secondary pointer bas_strbase (I like how it sounds like star base) &lt;/p&gt;
        &lt;p&gt; At the start of each statement, bas_strbase is copied to bas_strptr (thus effectively erasing the temporary strings) A problem needed to be solved: growing bas_strbase on each string assignment. &lt;/p&gt;
        &lt;p&gt; I was going to implement the most simple solution: go over the 26 string variables doing comparison and movement of pointers, and insert the new string in its place. &lt;/p&gt;
        &lt;p&gt; Just as I was coding this, I noticed I had an easier solution. As I was working with 16-bit words, not all values are used. I could use a value like 0xcafe to mark a non-used space, and boom! I had an idea. &lt;/p&gt;
        &lt;p&gt; When doing the assignment, delete the original string (fill it with 0xcafe words), now explore the strbase area to find a string of 0xcafe words big enough to save the new string. &lt;/p&gt;
        &lt;p&gt; The better part is when there is no space for the string, I simply copy the string pointer as the new bas_strbase pointer (effectively growing the base memory area), and all words between the end of the string and the previous bas_strbase pointer (ahead in memory) are filled with 0xcafe words. &lt;/p&gt;
        &lt;p&gt; Full string support with garbage collection at very small price of performance. Exactly what a CP1610 processor needs. &lt;/p&gt;
        &lt;quote&gt; STRING_TRASH: EQU $CAFE ; ; String assign. ; R1 = Pointer to string variable. ; R3 = New string. ; string_assign: PROC PSHR R5 MVII #STRING_TRASH,R4 ; ; Erase the used space of the stack. ; MOVR R3,R2 MVI@ R2,R0 INCR R2 ADDR R0,R2 MVI bas_strbase,R0 CMPR R0,R2 BC @@3 @@4: MVO@ R4,R2 INCR R2 CMPR R0,R2 BNC @@4 @@3: ; ; Erase the old string. ; MVI@ R1,R2 TSTR R2 BEQ @@1 MVI@ R2,R0 MVO@ R4,R2 INCR R2 TSTR R0 BEQ @@1 @@2: MVO@ R4,R2 INCR R2 DECR R0 BNE @@2 ; ; Search for space at higher-addresses. ; @@1: MVII #start_strings-1,R2 CMP bas_strbase,R2 ; All examined? BNC @@6 ; Yes, jump. @@5: CMP@ R2,R4 ; Space found? BNE @@7 ; No, keep searching. CLRR R5 @@8: INCR R5 DECR R2 CMP bas_strbase,R2 BNC @@9 CMP@ R2,R4 BEQ @@8 @@9: INCR R2 MVI@ R3,R0 INCR R0 CMPR R0,R5 ; The string fits? BNC @@7 ; ; The string fits in previous space. ; MOVR R3,R4 MOVR R2,R5 MVO@ R2,R1 ; New address. @@10: MVI@ R4,R2 MVO@ R2,R5 DECR R0 BNE @@10 PULR PC @@7: DECR R2 CMP bas_strbase,R2 BC @@5 ; ; No space available. ; @@6: MVO R3,bas_strbase ; Grow space for string variables. MVO@ R3,R1 PULR PC ENDP &lt;/quote&gt;
        &lt;div&gt;
          &lt;p&gt; Example of a parser for a text adventure game using string functions. &lt;/p&gt;
        &lt;/div&gt;
        &lt;head rend="h2"&gt;Going mathematic&lt;/head&gt;
        &lt;p&gt; Since my floating-point library was complete with the four operations, I had an ace under the sleeve: I already had tested sin and cos functions with it, but for some reason these had a bug. For sin(1Â°) the resulting value was 0.0172. &lt;/p&gt;
        &lt;div&gt;&lt;p&gt; These functions were ported from my &lt;/p&gt;Pascal compiler for transputer&lt;p&gt;. As Pascal happens to have exactly the same mathematical function set as a BASIC interpreter. &lt;/p&gt;&lt;/div&gt;
        &lt;p&gt; After a whole day examining the operation instruction-by-instruction (the jzintv debugger shines here), I discovered that I did a comparison in the wrong way and corrected it. &lt;/p&gt;
        &lt;p&gt; I was so happy that I went immediately to port the remaining mathematical functions (ATN, TAN, LOG, EXP, and derived SQR and the power-of ^ operator). There were no pitfalls along the way, except one, my BASIC has a mantissa with one extra bit of precision, and EXP(LOG(64)) returned 63.999999 &lt;/p&gt;
        &lt;p&gt; Both operations use a multiplication with a constant (log does it at the end, and exp in the start). I noticed that the value was misrounded for 25 bits of mantissa, so I calculated a better constant, and et voila! EXP(LOG(64)) returned 64. &lt;/p&gt;
        &lt;head rend="h2"&gt;Making it easier for the user&lt;/head&gt;
        &lt;p&gt; A lot of BASIC interpreters in the eighties didn't supported instructions for graphics. The Commodore 64 was particularly known for requiring POKE for almost anything, unless you had the somewhat expensive Simon BASIC cartridge. &lt;/p&gt;
        &lt;p&gt; However, in the Intellivision you have few graphics capabilities. In the Color Stack mode you have something called Colored Squares. This means each tile on the screen (20x12) can have four colors. This means a bloxel resolution of 40x24, and each bloxel can have one of eight colors (one being the background). &lt;/p&gt;
        &lt;p&gt; I implemented PLOT with these limitations, and also added PRINT AT (for putting text at any screen position), and TIMER to measure time. &lt;/p&gt;
        &lt;p&gt; One of the most difficult things was implementing the floating-point number parsing. I finally decided to approach it like parsing an integer, taking note of the number of digits parsed, and take note of the position of a period. Once it reaches the biggest number it can represent (9,999,999) then it starts ignoring any further digit (but it keeps counting them) &lt;/p&gt;
        &lt;p&gt; The final calculation step is to multiply it, or divide it taking in account the period position. Also taking in account any exponent present (for example, e+1 or e-3) &lt;/p&gt;
        &lt;p&gt; It wasn't so expensive in computation time. I added along a FRE(0) function to know how much space remains for writing programs. &lt;/p&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;It is the eighties&lt;/head&gt;
      &lt;p&gt; Let's suppose we are working to make this BASIC interpreter really useful for the Mattel ECS. We still need two things: cassette, and printer. &lt;/p&gt;
      &lt;p&gt; Fortunately, a lot of people at Atariage Forums have worked along the years to decipher the ECS hardware (thanks to intvnut, lathe26, and decle) &lt;/p&gt;
      &lt;p&gt; The ECS contains the hardware to interface to a cassette recorder/player at 300 bauds with FSK (Frequency-Shift Keying) of 2400/4800 hz (technically this is a modem) and it also includes a UART (Universal Asynchronous Receiver/Transmitter) patterned losely after a Motorola MC6850 chip, but the frequency selector is separated, allowing to turn on/off a relay (cassette remote control), and to switch between two ports (the cassete and the AUX port for the printer) &lt;/p&gt;
      &lt;p&gt; Now for the cassette, I was going to use 300 bauds, this means around 30 characters per second. Do you remember your 56K modem? It was 186 times faster! I needed to optimize my BASIC as I was using token numbers above $0100, so I moved them to the area $0080-$00ff. Now all the words are only used in the lower 8 bits, and the tokenized program can be saved as bytes. &lt;/p&gt;
      &lt;div&gt;&lt;p&gt; I coded the cassette routines based on code published by decle in his article &lt;/p&gt;ECS Text Editor written in IntyBASIC with tape support&lt;p&gt; and added LOAD, SAVE, and VERIFY. &lt;/p&gt;&lt;/div&gt;
      &lt;p&gt; I was very happy when these cassette routines worked in emulation, and I ordered cables from Amazon for trying to record and play in my cellphone. &lt;/p&gt;
      &lt;p&gt; For some reason probably related to audio levels and automatic compression, I could record audio from the ECS in my cellphone, but playing it back never resulted in anything. &lt;/p&gt;
      &lt;p&gt; I was tired, and I decided to try my PC. I connected the ECS to the Mic In, and Line Out, and same problem. Besides the Windows utilities make amazingly hard to change the source and playing line. I got the Audacity program, and it has the line input/output options easily selectable. Again no results. &lt;/p&gt;
      &lt;p&gt; I wrote a small program to read the UART continuously, and I couldn't see anything. I decided to try the Audacity's amplify effect, and et voila! My UART program started throwing decoded bytes. I stopped the program, and I tried the VERIFY command (remember I had just saved the same program), but it didn't worked. Worst, when I ran again my test program, I didn't got any data! &lt;/p&gt;
      &lt;p&gt; I revised my setup values for the UART, but nothing. I was mystified for some hours until I got memories of a chip that basically went nuts if you accessed it too fast. Could it be that? Is the CP1610 so fast? I added a delay after every access to the UART chip. &lt;/p&gt;
      &lt;p&gt; I typed again my test program, I did SAVE, recorded on the PC, amplified it, I RUN my program, and played the audio back. Ok, UART was reading things. Now I stopped the test program, I did VERIFY, and I played the audio back from my PC. The longest 20 seconds of my life. And it worked! &lt;/p&gt;
      &lt;p&gt; Immediately I resetted the ECS, losing the program, and I did LOAD (of course, playing back the audio), and again it worked! &lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt; My UART test program after a successful LOAD statement. &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt;Notice that although it saves BASIC programs, these programs aren't compatible with the original ECS BASIC because it is a completely different BASIC language.&lt;/p&gt;
      &lt;div&gt;&lt;p&gt; Break time: As I couldn't lose programs anymore, I decided to test my BASIC language with a "real" long program. So I took Tim Hartnell's Giant Book of Computer Games (Mexican edition), and I typed the Reversi game. I had to adapt it, because my BASIC doesn't allow for multidimensional arrays, and the screen positioning. I found a few bugs in my interpreter (&lt;/p&gt;INPUT W$&lt;p&gt; still wasn't written with the garbage-collector support, and the variables weren't deleted properly on &lt;/p&gt;RUN&lt;p&gt;), but it was amazing to watch the Reversi game playing against me. I've put a WAV file recording &lt;/p&gt;here&lt;p&gt;. &lt;/p&gt;&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt; Reversi game from the Tim Hartnell's Giant Book of Computer Games book working with my BASIC interpreter for the Mattel ECS. &lt;/p&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;The printer is in the room&lt;/head&gt;
      &lt;div&gt;&lt;p&gt; After reading &lt;/p&gt;Aquarius Printer Technical Info and Reverse Engineering&lt;p&gt; and the &lt;/p&gt;jzintv ECS document&lt;p&gt;, I decided using the printer was very easy, and I went to buy a Mattel Aquarius sourced locally because it included the printer and some thermal paper. &lt;/p&gt;&lt;/div&gt;
      &lt;p&gt; While the printer was in shipping process, I implemented LLIST, and LPRINT. I modified the core of both statements to access the output through an indirect function. So you only change the pointer to target the screen or the printer. I detected here a bug in jzintv that prevents it from outputting the printer data to a file. &lt;/p&gt;
      &lt;p&gt; I got the Mattel Aquarius along the printer a few days later. I had to clean it because it was pretty dusty. The printer doesn't have the top cover that protected the paper roll, but it included a paper roll, and fortunately it still had the cylinder that helps the papel to roll. &lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt; Mattel Aquarius computer with expansion board, two games, cables, and the Aquarius printer. &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; I adjusted the paper, powered on the printer, and verified I could advance the paper (having a working motor is 90% of the printer). &lt;/p&gt;
      &lt;p&gt; I built the serial cable with the instructions from lathe26's article, and the first time it didn't worked (I grounded the CTS cable accidentally), but after correcting it, I expected trash for my first print, instead, I got a pretty nice printing! &lt;/p&gt;
      &lt;p&gt; Of course, I couldn't resist printing some listings, and a sine wave. Pretty speedy for a 1200 bauds printer. &lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt; The printed source of my UFO game. The paper roll is really old. &lt;/p&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;What remains to do?&lt;/head&gt;
      &lt;p&gt; I added the DRAW and CIRCLE statements, and POINT functions to complete the graphics support. These are enough to make some nice games without using sprites. I made a graphics demo for filling the screen with lines, and I noticed my pseudo random number generator didn't covered the screen, so I had to improve it. &lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt; DRAW program for my ECS BASIC interpreter. &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; Also I added the POS and LPOS functions to know the horizontal position of the cursor. The SPC and TAB functions for PRINT. Plus a HEX$ function to ease system programming. &lt;/p&gt;
      &lt;p&gt; In the tokenization table, I added placeholders to expand the language and don't break compatibility with any cassette tape being created. &lt;/p&gt;
      &lt;p&gt; With this it has become a full-fledged BASIC interpreter for the Mattel ECS that uses 19 kilowords, instead of the 24 kilowords of the slow and limited Mattel ECS BASIC interpreter. &lt;/p&gt;
      &lt;p&gt; I don't see anything more I could do in the near future, except maybe expanding the editor to be a full-screen editor. Currently, it is a line editor that reads its input from the screen. &lt;/p&gt;
      &lt;p&gt; At this point, it is a fun experience the process of typing BASIC programs in the ECS, and watch the results back. You can save the programs, or print it. And of course, you can only imagine the success that Mattel Electronics would have enjoyed if they put together a good BASIC with its Mattel ECS. &lt;/p&gt;
      &lt;p&gt; Small statistics of the assembler code: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;basic.asm: 5333 lines.&lt;/item&gt;
        &lt;item&gt;fplib.asm: 718 lines.&lt;/item&gt;
        &lt;item&gt;fpio.asm: 462 lines.&lt;/item&gt;
        &lt;item&gt;fpmath.asm: 516 lines.&lt;/item&gt;
        &lt;item&gt;uart.asm: 341 lines.&lt;/item&gt;
        &lt;item&gt;Total of 7370 lines of assembler code written between Sep/17 and Oct/12, around 300 lines written daily.&lt;/item&gt;
      &lt;/list&gt;
      &lt;div&gt;&lt;p&gt; The source code is released at &lt;/p&gt;https://github.com/nanochess/ecsbasic&lt;p&gt;. I tried to release it so early as possible, so you can get a glance of how it was growing in the commits. &lt;/p&gt;&lt;/div&gt;
      &lt;div&gt;&lt;p&gt; Enjoy it! &lt;/p&gt;Did you like this article? Invite me a coffee on ko-fi! &lt;/div&gt;
      &lt;head rend="h2"&gt;Related links&lt;/head&gt;
      &lt;p&gt;Last modified: Oct/12/2025&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45560974</guid><pubDate>Sun, 12 Oct 2025 19:19:38 +0000</pubDate></item><item><title>Ask HN: What are you working on? (October 2025)</title><link>https://news.ycombinator.com/item?id=45561428</link><description>&lt;doc fingerprint="3760905329a5bbf8"&gt;
  &lt;main&gt;
    &lt;p&gt;I'm playing around with sandboxing techniques on Mac so I can isolate AI tools and prevent them from interacting with files they shouldn't have access to -- like all my dotfiles, AWS credentials, and such.&lt;/p&gt;
    &lt;p&gt;Along the way I rolled my own git-multi-hook solution (https://github.com/webcoyote/git-multi-hook) to use git hooks for shellcheck-ing, ending files with blank lines, and avoid committing things that shouldn't be in source control.&lt;/p&gt;
    &lt;p&gt;Yes, I've used docker and podman. They're great. But I wanted to be able to run Xcode and IOS simulator, which requires macOS, so developed these solutions.&lt;/p&gt;
    &lt;p&gt;Last year, PlasticList found plastic chemicals in 86% of tested foods—including 100% of baby foods they tested. Around the same time, the EU lowered its “safe” BPA limit by 20,000×, while the FDA still allows levels roughly 100× higher than Europe’s new standard.&lt;/p&gt;
    &lt;p&gt;That seemed solvable.&lt;/p&gt;
    &lt;p&gt;Laboratory.love lets you crowdfund independent lab testing of the specific products you actually buy. Think Consumer Reports × Kickstarter, but focused on detecting endocrine disruptors in your yogurt, your kid’s snacks, or whatever you’re curious about.&lt;/p&gt;
    &lt;p&gt;Find a product (or suggest one), contribute to its testing fund, and get full lab results when testing completes. If a product doesn’t reach its goal within 365 days, you’re automatically refunded. All results are published publicly.&lt;/p&gt;
    &lt;p&gt;We use the same ISO 17025-accredited methodology as PlasticList.org, testing three separate production lots per product and detecting down to parts-per-billion. The entire protocol is open.&lt;/p&gt;
    &lt;p&gt;Since last month’s “What are you working on?” post:&lt;/p&gt;
    &lt;p&gt;- 4 more products have been fully funded (now 10 total!)&lt;/p&gt;
    &lt;p&gt;- That’s 30 individual samples (we do triplicate testing on different batches) and 60 total chemical panels (two separate tests for each sample, BPA/BPS/BPF and phthalates)&lt;/p&gt;
    &lt;p&gt;- 6 results published, 4 in progress&lt;/p&gt;
    &lt;p&gt;The goal is simple: make supply chains transparent enough that cleaner ones win. When consumers have real data, markets shift.&lt;/p&gt;
    &lt;p&gt;1. An example result is "https://laboratory.love/product/117", which is a list of chemicals and measurements. Is there a visualization of how these levels relate to regulations and expert recommendations? What about a visualization of how different products in the same category compare, so that consumers know which brand is supposedly "best"? Maybe a summary rating, as stars or color-coded threat level?&lt;/p&gt;
    &lt;p&gt;2. If you find regulation-violating (or otherwise serious) levels of undesirable chemicals, do you... (a) report it to FDA; (b) initiate a class-action lawsuit; (c) short the brand's stock and then news blitz; or (d) make a Web page with the test results for people to do with it what they will?&lt;/p&gt;
    &lt;p&gt;3. Is 3 tests enough? On the several product test results I clicked, there's often wide variation among the 3 samples. Or would the visualization/rating tell me that all 3 numbers are unacceptably bad, whether it's 635.8 or 6728.6?&lt;/p&gt;
    &lt;p&gt;4. If I know that plastic contamination is a widespread problem, can I secretly fund testing of my competitors' products, to generate bad press for them?&lt;/p&gt;
    &lt;p&gt;5. Could this project be shut down by a lawsuit? Could the labs be?&lt;/p&gt;
    &lt;p&gt;1. I'm still working to make results more digestible and actionable. This will include the %TDI toggle (total daily intake, for child vs adult and USA vs EU) as seen on PlasticList, but I'm also tinkering with an even more consumer-friendly 'chemical report card'. The final results page would have both the card and the detailed table of results.&lt;/p&gt;
    &lt;p&gt;2. I have not found any regulation-violating levels yet, so in some sense, I'll cross that bridge when I get there. Part of the issue here is that many believe the FDA levels are far too relaxed which is part of why demand for a service like laboratory.love exists.&lt;/p&gt;
    &lt;p&gt;3. This is part of the challenge that PlasticList faced, and additionally a lot of my thinking around the chemical report card are related to this. Some folks think a single test would be sufficient to catch major red flags. I think triplicate testing is a reasonable balance of statistically robust while not being completely cost-prohibitive.&lt;/p&gt;
    &lt;p&gt;4. Yes, I suppose one could do that, as long as the funded products can be acquired by laboratory.love anonymously through their normal consumer supply chains. Laboratory.love merely acquires three separate batches of a given product from different sources, tests them at an ISO/IEC 17025-accredited lab, and publishes the data.&lt;/p&gt;
    &lt;p&gt;5. I suppose any project can be shut down by a lawsuit, but laboratory.love is not currently breaking any laws as far as I'm aware.&lt;/p&gt;
    &lt;p&gt;Serious question: around 1900 meat was often preserved using formaldehyde, and milk was adulterated with water and chalk, and sometimes with pureed calf brains to simulate cream.&lt;/p&gt;
    &lt;p&gt;I hope we can agree that we are better off than that now.&lt;/p&gt;
    &lt;p&gt;What I'm curious about is whether you think it's been a steady stream of improvements, and we just need to improve further? Or if you think there was some point between 1900 and now where food health and safety was maximized, greater than either 1900 or now, and we've regressed since then?&lt;/p&gt;
    &lt;p&gt;Trying to collapse high dimensional, complex phenomena onto a single axis usually gives one a fake sense of certainty. One should avoid it as much as possible.&lt;/p&gt;
    &lt;p&gt;Where are you? This project is not necessarily limited to products that are available in the United States. Anything that can be shipped to the United States is still testable.&lt;/p&gt;
    &lt;p&gt;this looks so cool! I wish it told me if the levels found for tested products were good/bad - I have no prior reference so the numbers meant nothing to me&lt;/p&gt;
    &lt;p&gt;Given the current reach of the project (read: still small!), I suspect for awhile yet the majority of successfully funded testing will be by concerned individuals with expendable income. It is cheaper and much faster to go through laboratory.love than it would be to partner with a lab as an individual (plus the added bonus that all data is published openly).&lt;/p&gt;
    &lt;p&gt;I've yet to have any product funded by a manufacturer. I'm open to this, but I would only publish data for products that were acquired through normal consumer supply chains anonymously.&lt;/p&gt;
    &lt;p&gt;Both of them do measurements and YouTube videos. Neither one has a particularly good index of their completed reviews, let alone tools to compare the data.&lt;/p&gt;
    &lt;p&gt;I wish I could subscribe to support a domain like “loud speaker spin tests” and then have my donation paid out to these reviewers based on them publishing new high quality reviews with good data that is published to a common store.&lt;/p&gt;
    &lt;p&gt;Not sure what the market is for something like this but it's something I've been thinking a lot about since stepping down as CEO of my previous company.&lt;/p&gt;
    &lt;p&gt;My goal is two-fold:&lt;/p&gt;
    &lt;p&gt;1. Help teams make better, faster decisions with all context populating a source-of-truth.&lt;/p&gt;
    &lt;p&gt;2. Help leaders stay eyes-on, and circumstantially hands-on, without slowing everything down. What I'd hope to be an effective version of "Founder Mode".&lt;/p&gt;
    &lt;p&gt;If anybody wants to play around with it, here's a link to my staging environment:&lt;/p&gt;
    &lt;p&gt;I am working on making ultra-low cost freeze-dried enzymes for synthetic biology.&lt;/p&gt;
    &lt;p&gt;For example, 1 PCR reaction (a common reaction used to amplify DNA) costs about $1 each, and we're doing tons every day. Since it is $1, nobody really tries to do anything about it - even if you do 20 PCRs in one day, eh it's not that expensive vs everything else you're doing in lab. But that calculus changes once you start scaling up with robots, and that's where I want to be.&lt;/p&gt;
    &lt;p&gt;Approximately $30 of culture media can produce &amp;gt;10,000,000 reactions worth of PCR enzyme, but you need the right strain and the right equipment. So, I'm producing the strain and I have the equipment! I'm working on automating the QC (usually very expensive if done by hand) and lyophilizing for super simple logistics.&lt;/p&gt;
    &lt;p&gt;My idea is that every day you can just put a tube on your robot and it can do however many PCR reactions you need that day, and when the next day, you just throw it out! Bring the price from $1 each to $0.01 + greatly simplify logistics!&lt;/p&gt;
    &lt;p&gt;Of course, you can't really make that much money off of this... but will still be fun and impactful :)&lt;/p&gt;
    &lt;p&gt;As a bio hobbyist, this is fantastic! I don't do enough volume of PCR to think of it as expensive, but your use case of high-volume/automatic sounds fantastic! (And so many other types of reagents and equipment are very expensive).&lt;/p&gt;
    &lt;p&gt;Some things that would be cool&lt;/p&gt;
    &lt;p&gt;- Along your lines: In general, cheap automated setups for PCR and gels - Cheap/automatic quantifiable gels. E.g. without needing a kV supply capillary, expensive QPCR machines etc. - Cheaper enzymes in general - More options for -80 freezers - Cheaper/more automated DNA quantification. I got a v1 Quibit which gets the job done, but new ones are very expensive, and reagent costs add up. - Cheaper shaking incubator options. You can get cheap shakers and baters, but not cheap combined ones... which you need for pretty much everything. Placing one in the other can work, but is sub-optimal due to size and power-cord considerations. - More centrifuges that can do 10kG... this is the minimum for many protocols. - Ability to buy pure ethanol without outrageous prices or hazardous shipping fees.&lt;/p&gt;
    &lt;p&gt;- Not sure if this is feasible but... reasonable cost machines to synthesize oglios?&lt;/p&gt;
    &lt;p&gt;That sounds really cool. I wouldn't agree you can't make money off this, you can make money off anything, just find people who need this and it seems you did find it.&lt;/p&gt;
    &lt;p&gt;Anyhow good luck. Would love to follow if you do anything with this in the future. Do you have a blog or anything?&lt;/p&gt;
    &lt;p&gt;I found a neat way to do high-quality "semantic soft joins" using embedding vectors[1] and the Hungarian algorithm[2] and I'm turning it into an open source Python package:&lt;/p&gt;
    &lt;p&gt;It hits a sweet spot by being easier to use than record linkage[3][4] while still giving really good matches, so I think there's something there that might gain traction.&lt;/p&gt;
    &lt;p&gt;I see you saved a spot to show how to use it with an alternative embedding model. It would be nice to be able to use the library without an OpenAI api key. Might even make sense to vendor a basic open source model in your package so it can work out of the box without remote dependencies.&lt;/p&gt;
    &lt;p&gt;Yes, I'm planning out-of-the-box support for nomic[1] which can run in-process, and ollama which runs as a local server and supports many free embedding models[2].&lt;/p&gt;
    &lt;p&gt;If you're adding more LLM integration, a cool feature might be sending the results of allow_many="left" off to an LLM completions API that supports structured outputs. Eg imagine N_left=1e5 and N_right=1e5 but they are different datasets. You could use jellyjoin to identify the top ~5 candidates in right for each left, reducing candidate matches from 1e10 to 5e5. Then you ship the 5e5 off to an LLM for final scoring/matching.&lt;/p&gt;
    &lt;p&gt;I built a website that lets you browse Pokemon ENS (Ethereum Name Service) names, view their registration statuses and recent sales. It's a small but engaged niche&lt;/p&gt;
    &lt;p&gt;I’m currently working on https://www.dreamly.in - automated, personalized, and localized bedtime stories for kids.&lt;/p&gt;
    &lt;p&gt;My daughter loves stories, and I often struggled to come up with new ones every night. I remember enjoying local folk tales and Indian mythological stories from my childhood, and I wanted her to experience that too — while also learning new things like basic science concepts and morals through stories.&lt;/p&gt;
    &lt;p&gt;So I built Dreamly and opened it up to friends and families. Parents can set up their child’s profile once - name, age, favorite shows or characters, and preferred themes (e.g. morals, history, mythology, or school concepts). After that, personalized stories are automatically delivered to their inbox every night. No more scrambling to think of stories on the spot!&lt;/p&gt;
    &lt;p&gt;I've been working on a 3D voxel-based game engine for like 10 years in my spare time. The most recent big job has been to port the world gen and editor to the GPU, which has had some pretty cute knock-on effects. The most interesting is you can hot-reload the world gen shaders and out pop your changes on the screen, like a voxel version of shadertoy.&lt;/p&gt;
    &lt;p&gt;I also wrote a metaprogramming language which generates a lot of the editor UI for the engine. It's a bespoke C parser that supports a small subset of C++, which is exposed to the user through a 'scripting-like' language you embed directly in your source files. I wrote it as a replacement for C++ templates and in my completely unbiased opinion it is WAY better.&lt;/p&gt;
    &lt;p&gt;I've become a bit addicted to online education. I finished my first masters degree in Computer Science in July, and I started a masters in Mathematics from The Open University at the beginning of October. I've wanted to really get into the weeds of obscure and arguably-useless math for about as long as I can remember, and I figure that getting a masters in it is as good a way to get that knowledge as any way else.&lt;/p&gt;
    &lt;p&gt;Other than that, I've been doing a lot of fixing of tech debt in my home network from the last six years. I've admittedly kind of half-assed a lot of the work with my home router and my server and my NAS and I want these things to be done correctly. (In fairness to me, I didn't know what I was doing back when I started, and I'd like to think I know a fair bit better now).&lt;/p&gt;
    &lt;p&gt;For example, when I first built my server, I didn't know about ZFS datasets, so everything was on the main /tank mount. This works but there are advantages to having different settings for different parts of the RAID and as such I've been dividing stuff into datasets (which has the added advantage of "defragging" because this RAID has grown by several orders of magnitude and as a result some of the initial files were fragmented).&lt;/p&gt;
    &lt;p&gt;Microlandia, the brutally honest city builder. Posting this for a second time, because i’ve been working super hard on a steam release.&lt;/p&gt;
    &lt;p&gt;last month’s “what are you working on” thread impulsed me to upload this game to itch and 1 month later, i’ve got a small community, lots of feedback and iterations. It brought a whole new life to a project that was on the verge of abandoning.&lt;/p&gt;
    &lt;p&gt;Taking a break from tech to work on a luxury fashion brand with my mum. She hand paints all the designs. I it first collection is a set of silk scarves and we’re moving into skirts and jackets soon.&lt;/p&gt;
    &lt;p&gt;Been a wonderful journey to connect with my mum in this way. And also to make something physical that I can actually touch. Tech seems so…ephemeral at times&lt;/p&gt;
    &lt;p&gt;this is super cool. congrats and best of luck with it! Love the mother &amp;amp; son backstory to the product. The scarves look like they could make a great gift as well. I'll bookmark your website.&lt;/p&gt;
    &lt;p&gt;Continuing to work on a Low Power FM community radio station for the East San Fernando Valley of Los Angeles. We have started promoting and putting on local events and are trying to fund raise to build out the station. Raising money is hard! We did a big show in Burbank where several hundred people showed up but we only netted $800 after expenses. :(&lt;/p&gt;
    &lt;p&gt;Since this is hackernews, i'll add that i'm building the website and archiving system using haskell and htmx, but what is currently live is a temp static html site. https://github.com/solomon-b/kpbj.fm&lt;/p&gt;
    &lt;p&gt;This might be a naive question which you've probably been asked plenty of times before so I'm sorry of I'm being tedious here.&lt;/p&gt;
    &lt;p&gt;Is it really worth the effort and expense to have a real radio station these days? Wouldn't an online stream be just as effective if it was promoted well locally?&lt;/p&gt;
    &lt;p&gt;A few years ago a friend who was very much involved in a local community group which I was also somewhat interested in asked me if I wanted to help build a low power FM station. He asked me because I know something about radio since I was into ham radio etc.&lt;/p&gt;
    &lt;p&gt;I was skeptical that it was worth the effort. The nerdy part of me would have enjoyed doing it but I couldn't help thinking that an online stream would probably reach as many people without the hassle and expensive of a transmitter, antenna etc.&lt;/p&gt;
    &lt;p&gt;I know it's a toss up. Every car has an FM radio. Not everyone is going to have a phone plugged in to Android Auto or Apple Car Play and have a good data plan and have a solid connection.&lt;/p&gt;
    &lt;p&gt;I also pointed out that the technical effort is probably the small part compared to producing interesting content.&lt;/p&gt;
    &lt;p&gt;1. Radio is COOL. As a fellow ham I think you would agree with me on this one so I'll leave it at that.&lt;/p&gt;
    &lt;p&gt;2. Internet streaming gives you wider but far less localized audience. We will have an internet stream, but being radio first shifts the focus to local community and local content.&lt;/p&gt;
    &lt;p&gt;3. Internet streaming and radio have related but not entirely overlapping histories and contexts which impacts how people produce and consume their content. I love the traditional formats of radio and they are often completely missing in online radio which IMO models itself more often on mixtape and club DJ culture.&lt;/p&gt;
    &lt;p&gt;4. AI slop is ruining the world. I have this belief that as AI slop further conquers the internet we are going to get to a place where nobody trusts internet content. People will seek out novelty and authenticity (sort of how LLMs do lol) and I think there will be a return to local content and community.&lt;/p&gt;
    &lt;p&gt;5. Commercial radio sucks. The LPFM system is a wonderful opportunity to create a strong, community driven alternative to corporate media.&lt;/p&gt;
    &lt;p&gt;Radio is so much fun to learn. It’s liberating to learn for curiosity and joy rather than commercialization. The community is welcoming, and while not directly translatable for most paid work, it does teach general problem solving skills.&lt;/p&gt;
    &lt;p&gt;It's a sync infra product that is meant to cut down 6 months of development time, and years of maintenance of deep CRM sync for B2B SaaS.&lt;/p&gt;
    &lt;p&gt;Every Salesforce instance is a unique snowflake. I am moving that customization into configuration and building a resilient infrastructure for bi-directional sync.&lt;/p&gt;
    &lt;p&gt;- You can precisely tweak every shade/tint so you can incorporate your own brand colors. No AI or auto generation!&lt;/p&gt;
    &lt;p&gt;- It helps you build palettes that have simple to follow color contrast guarantees by design e.g. all grade 600 colors have 4.5:1 WCAG contrast (for body text) against all grade 50 colors, such as red-600 vs gray-50, or green-600 vs gray-50.&lt;/p&gt;
    &lt;p&gt;- There's export options for plain CSS, Tailwind, Figma, and Adobe.&lt;/p&gt;
    &lt;p&gt;- It uses HSLuv for the color picker, which makes it easier to explore accessible color combinations because only the lightness slider impacts the WCAG contrast. A lot of design tools still use HSL, where the WCAG contrast goes everywhere when you change any slider which makes finding contrasting colors much harder.&lt;/p&gt;
    &lt;p&gt;- Check out the included example open source palettes and what their hue, saturation and lightness curves look like to get some hints on designing your own palettes.&lt;/p&gt;
    &lt;p&gt;It's probably more for advanced users right now but I'm hoping to simplify it and add more handholding later.&lt;/p&gt;
    &lt;p&gt;Really open to any feedback, feature requests, and discussing challenges people have with creating accessible designs. :)&lt;/p&gt;
    &lt;p&gt;I get that you say it is for advanced users, but I think a "how to use this" link with a video in it that explained a few things would probably open it up to a lot more users.&lt;/p&gt;
    &lt;p&gt;There's so much more to do with tools like this, and I'm really glad to see it.&lt;/p&gt;
    &lt;p&gt;Thanks for the feedback! Yeah, I appreciate there's a lot of background here around color palette design, UI design, color spaces, and accessibility so I likely need something like a video or tutorial. Another route is to have the tool start in a less freeform mode that handholds you through the process more.&lt;/p&gt;
    &lt;p&gt;I'm working on a DSL and browser-based playground for procedural 3D geometry called Geotoy: https://3d.ameo.design/geotoy&lt;/p&gt;
    &lt;p&gt;It's largely finished and functional, and I'm now focused on polish and adding additional builtin functions to expand its capabilities. I've been integrating different geometry libraries and kernels as well as writing some of my own.&lt;/p&gt;
    &lt;p&gt;I've been stress-testing it by building out different scenes from movies or little pieces of buildings on Google Maps street view - finding the sharp edges and missing pieces in the tool.&lt;/p&gt;
    &lt;p&gt;My hope is for Geotoy to be a relatively easy-to-learn tool and I've invested significantly in good docs, tutorials, and other resources. Now my goal is to ensure it's something worth using for other people.&lt;/p&gt;
    &lt;p&gt;- Working on Kanji Palace (https://kanjipalace.com): We're going to publish the iOS app on the App Store and adding vocabulary. Currently, the app converts single Kanji (e.g., 生) into vivid mnemonic images. We aim to support vocabulary like 先生.&lt;/p&gt;
    &lt;p&gt;- Writing a book about Claude Code, not just for assisted programming, but as a general AI agent framework.&lt;/p&gt;
    &lt;p&gt;I've been vanlifing for a few months now. I tend to have long hours on the road where my mind wonders and I want to write code hands-free.&lt;/p&gt;
    &lt;p&gt;So, I built it.&lt;/p&gt;
    &lt;p&gt;Using ChatGPT's voice agents to generate Github issues tagging @claude to trigger Claude Code's Github Action, I created https://voicescri.pt that allows me to have discussions with the voice agent, having it create issues, pull requests, and logical diffs of the code generated all via voice, hands free, with my phone in my pocket.&lt;/p&gt;
    &lt;p&gt;Shipping pets and animals across borders is a big problem, and we are building the operating system to solve it at scale. If you are a vet (or work in the veterinary space), we would love to talk to you.&lt;/p&gt;
    &lt;p&gt;I’m creating an electronic avionics sensor and display for experimental aircraft. I’m having a fantastic time learning about circuits and MCUs (I have a pure CS degree, zero background with EE stuff). I’ve been working on this in my off hours for over a year now, maybe someday it will be a product that people buy!&lt;/p&gt;
    &lt;p&gt;The current challenge is the display. I’ve struggled to learn about this part more than any other. After studying DVI and LVDS, and after trying to figure out what MIPI/DSI is all about, I think parallel RGB is the path forward, so I’ve just designed a test PCB for that, and ordered it from JLCPCB’s PCBA service.&lt;/p&gt;
    &lt;p&gt;I’m currently building YTVidHub—a tool that focuses on solving a very specific, repetitive workflow pain for researchers and content analysts.&lt;/p&gt;
    &lt;p&gt;The Pain Point: If you are analyzing a large YouTube channel (e.g., for language study, competitive analysis, or data modeling), you often need the subtitle files for 50, 100, or more videos. The current process is agonizing: copy-paste URL, click, download, repeat dozens of times. It's a massive time sink.&lt;/p&gt;
    &lt;p&gt;My Solution: YTVidHub is designed around bulk processing. The core feature is a clean interface where you can paste dozens of YouTube URLs at once, and the system intelligently extracts all available subtitles (including auto-generated ones) and packages them into a single, organized ZIP file for one-click download.&lt;/p&gt;
    &lt;p&gt;Target Users: Academic researchers needing data sets, content creators doing competitive keyword analysis, and language learners building large vocabulary corpora.&lt;/p&gt;
    &lt;p&gt;The architecture challenge right now is optimizing the backend queuing system for high-volume, concurrent requests to ensure we can handle large batches quickly and reliably without hitting rate limits.&lt;/p&gt;
    &lt;p&gt;It's still pre-launch, but I'd love any feedback on this specific problem space. Is this a pain point you've encountered? What's your current workaround?&lt;/p&gt;
    &lt;p&gt;How coincidental - I needed exactly this just a couple days ago. I ended up vibecoding a script to feed an individual URL into yt-dlp then pipe the downloaded audio through Whisper - not quite the same thing as it's not downloading the _actual_ subtitles but rather generating its own transcription, but similar. I've only run it on a single video to test, but it seemed to work satisfactorily.&lt;/p&gt;
    &lt;p&gt;I haven't upgraded to bulk processing yet, but I imagine I'd look for some API to get "all URLs for a channel" and then process them in parallel.&lt;/p&gt;
    &lt;p&gt;For context, I'm a UX Designer at a low-code company. LLMs are great at cranking out prototypes using well-known React component libraries. But lesser known low-code syntax takes more work. We made an MCP server that helps a lot, but what I'm working on now is a set of steering docs to generate components and prototypes that are "backwards compatible" with our bespoke front end language. This way our vibe prototyping has our default look out of the box and translates more directly to production code. https://github.com/pglevy/sail-zero&lt;/p&gt;
    &lt;p&gt;It currently supports complex heatmaps based on travel time (e.g. close to work + close to friends + far from police precincts), and has a browser extension to display your heatmap over popular listing sites like Zillow.&lt;/p&gt;
    &lt;p&gt;I'm thinking of making it into an API to allow websites to integrate with it directly.&lt;/p&gt;
    &lt;p&gt;Living in hongkong for a few months, and absolutely love exploring the different neighborhoods. I’d love something like this or walkscore but for local guides to contribute.&lt;/p&gt;
    &lt;p&gt;Absolutely stellar! I've been looking for something like this for ages. Any chance you'll have some pre- defined options like grocery stores, libraries, airport, etc?&lt;/p&gt;
    &lt;p&gt;I wanted to build my own speech-to-text transcription program [1] for Discord, similar to how zoom or google hangouts works. I built it so that I can record my group's DND sessions and build applications / tools for VTTs (Virtual TableTop gaming).&lt;/p&gt;
    &lt;p&gt;It can process a set of 3-hour audio files in ~20 mins.&lt;/p&gt;
    &lt;p&gt;I’m building SPARK (Signal Processing Algorithms, Routines, and Kernels), an open-source library of modular, efficient DSP components for low-power embedded audio systems.&lt;/p&gt;
    &lt;p&gt;The goal is to make it straightforward to design and deploy small, composable audio graphs that fit on MCUs and similar hardware. The project is in its infancy, so there’s plenty of room for experimentation and contributions.&lt;/p&gt;
    &lt;p&gt;An open source website I built to explain tensor functions in PyTorch: https://whytorch.org&lt;/p&gt;
    &lt;p&gt;It makes tricky functions like torch.gather and torch.scatter more intuitive by showing element-level relationships between inputs and outputs.&lt;/p&gt;
    &lt;p&gt;For any function, you can click elements in the result to see where they came from, or elements in the inputs to see how they contribute to the result to see exactly how it contributes to the result. I found that visually tracing tensor operations clarifies indexing, slicing, and broadcasting in ways reading that the docs can't.&lt;/p&gt;
    &lt;p&gt;You can also jump straight to WhyTorch from the PyTorch docs pages by modifying the base URL directly.&lt;/p&gt;
    &lt;p&gt;I launched a week or two back and now have the top post of all time on r/pytorch, which has been pretty fun.&lt;/p&gt;
    &lt;p&gt;This really nice. For `torch.mul(x, y)`, it would be nice if it highlighted the entire row or column in the other matrix and result. Right now it shows only a single multiplication, which gives a misleading impression of how matrix multiply works. I wouldn't mention it, except that matrix multiplication is so important that it's worth showcasing. I've bookmarked the site and will share it at a pytorch training session I'm leading in a couple of weeks.&lt;/p&gt;
    &lt;p&gt;I'm working on a open-source tool to create photo galleries from a folder of photos: https://simple.photo. It creates galleries as static sites that are easy to self-host.&lt;/p&gt;
    &lt;p&gt;I started this out of frustration that there is no good tool I could use to share photos from my travel and of my kids with friends and family. I wanted to have a beautiful web gallery that works on all devices, where I can add rich descriptions and that I could share with a simple link.&lt;/p&gt;
    &lt;p&gt;Turned out more people wanted this (got 200+ GitHub stars for the V1) so I recently released the V2 and I'm working on it with another dev. Down the road we plan a SaaS offer for people that don't want to fiddle with the CLI and self-host the gallery.&lt;/p&gt;
    &lt;p&gt;Like the layout tiles you have for the photo thumbnails. Will dig through and learn some css. Have struggled with different size content to create a compact masonry layout.&lt;/p&gt;
    &lt;p&gt;Redesigning investment holdings for wider screens and leaning on hotwired turbo frames. Thankful for once-campfire as a reference for how to structure the backend. The lazy loading attribute works great with css media queries to display more on larger viewports.&lt;/p&gt;
    &lt;p&gt;Enjoying learning modern css in general. App uses tailwind, but did experiment with just css on the homepage. Letting the design emerge organically from using it daily, prototype with tailwind, then slim it back down with plain css.&lt;/p&gt;
    &lt;p&gt;I'm trying to figure out how modern internal API management should work like and started https://www.appear.sh/.&lt;/p&gt;
    &lt;p&gt;After spending so much of my career dealing with APIs and building tooling for that I feel there's huge gap between what is needed and possible vs how the space generally works. There's a plethora of great tools that do one job really well, but when you want to use them the integration will kill you. When you want to get your existing system in them it takes forever. When you want to connect those tools that takes even longer.&lt;/p&gt;
    &lt;p&gt;The reality I'm seeing around myself and hearing from people we talk to is that most companies have many services in various stages of decay. Some brand new and healthy, some very old, written by people who left, acquired from different companies or in languages that were abandoned. And all of that software is still generating a lot of value for the company and to be able to leverage that value APIs are essential. But they are incredibly hard and slow to use, and the existing tools don't make it easier.&lt;/p&gt;
    &lt;p&gt;My personal website/webring. It's mostly a collection of ideas I've been mulling over and holding off on due to not being able to iterate on them fast enough. Nowadays thanks to AI, a lot of these a short errands so it's been a fun few weeks. I've also started chucking a few previous side projects under more unified domains. [1][2]&lt;/p&gt;
    &lt;p&gt;Also working on a youtube channel [3] for my climbing/travel videos, but the dreary state of that website has me wondering whether it's worth it, tbh. I haven't been able to change my channel name after trying for weeks. It's apparently the best place to archive edited GoPro footage at least.&lt;/p&gt;
    &lt;p&gt;I've been working on https://booplet.com. It's like Lovable but for desktop apps and heavily inspired by Robin Sloan's home-cooked app essay [1][2]. The idea is to let anyone, especially non-technical folks, build and use personal apps. Instead of cloud deployment, we focused on a local-first setup so that users can fully own their apps and data.&lt;/p&gt;
    &lt;p&gt;I'm attempting to work on a "spiritual successor" to Dramatica Story Expert, a crazy story theory/brainstorming program of days gone by. Technically, Dramatica is still around, but they never made a 64-bit version for Macs, and both the Mac and Windows version have been tenaciously clinging to the trailing edge of technology for decades. (The Mac version somehow never got retina fonts. I'm not sure how you even do that.)&lt;/p&gt;
    &lt;p&gt;I started my program in Swift and SwiftUI, although for various reasons I'm starting to look at Dart and Flutter (in part because being multiplatform would be beneficial, and in part because I am getting the distinct feeling this program is more ambitious than where SwiftUI is at currently). It isn't a direct port of Dramatica by any stretch, instead drawing on what I've learned writing my own novels, getting taught by master fiction writers, and being part of writing workshops. But no other program that I've seen uses Dramatica's neatest concepts, other than Subtxt, a web-based, AI-focused app which has recently been anointed Dramatica's official successor. (It's a neat concept, but it's very expensive compared to the original Dramatica or any other extant "fiction plotting" program. Also, there's a space for non-AI software here, I suspect: there are a lot of creatives who are adamantly opposed to it in any form whatsoever.)&lt;/p&gt;
    &lt;p&gt;Building a tool that automatically generates living infrastructure diagrams from your IaC files and turns them into real-time incident dashboards. Think Figma meets Datadog - beautiful visualization that updates during outages to show you exactly what's failing and how to fix it.&lt;/p&gt;
    &lt;p&gt;The insight: your architecture diagram shouldn't be a stale PNG in Confluence. It should be your war room during incidents.&lt;/p&gt;
    &lt;p&gt;Going to be available as both web app and native desktop.&lt;/p&gt;
    &lt;p&gt;https://lustroczynszowe.pl/ The aggregator of rental values in Poland. We want to increase the transparency of the real estate market, empowering consumers and enabling them to make fully informed financial decisions. We will also suggest savings on specific fields.&lt;/p&gt;
    &lt;p&gt;Currently working on Note Cargo, basically self-hosted Markdown note-taking app, but I tried to not using database. So similar to Obsidian/Logseq but its web-based.&lt;/p&gt;
    &lt;p&gt;And currently working to make things shareable, also don't want to use database.&lt;/p&gt;
    &lt;p&gt;It's an API that allows zero-knowledge proofs to be generated in a streaming fashion, meaning ZKPs that use way less RAM than normal.&lt;/p&gt;
    &lt;p&gt;The goal is to let people create ZKPs of any size on any device. ZKPs are very cool but have struggled to gain adoption due to the memory requirements. You usually need to pay for specialized hardware or massive server costs. Hoping to help fix the problem for devs&lt;/p&gt;
    &lt;p&gt;Fwiw: the website is brand new and very much in the "hot garbage" phase of development. I'm not a front-end guy, so critique is welcome from all - especially any bugs in the UX. I'm still actively uncovering them&lt;/p&gt;
    &lt;p&gt;Nice! I recently built an invoice generator (not open sourced) for my own needs. I built mine because I needed something when I discontinued a SaaS that had provided it. Mine is written in C# and uses a JSON file to define the contents of the invoice. It's run from the command-line and just produces the PDF.&lt;/p&gt;
    &lt;p&gt;I wonder if you could just send invoices to Comcast for price increases to their Payable Accounts department and if they'd just pay them. Or just invoice companies for "inconvenience fees" of sorts when they actually create inconveniences.&lt;/p&gt;
    &lt;p&gt;Are you planning to turn this into a full-fledged CRM of some sort? Are you planning to add user login with templates/company fields auto-populated at one point? Looks very clean, congrats.&lt;/p&gt;
    &lt;p&gt;Why would you do something like this instead of using a cheap script from a codecanyon-type website (a true CRUD crm) where you can collect customer data and provide complete service in the long run? Just saying this because you said you built it for your own use.&lt;/p&gt;
    &lt;p&gt;I actually hadn’t heard of Codecanyon before! I used to use a paid invoicing service, but these days I just need a simple way to generate invoice PDFs - that’s really all I need.&lt;/p&gt;
    &lt;p&gt;You can use invoice generators that have complete control over your customers. Most scripts are php, and if you want something very detailed I'd go with Perfex. Codecanyon is the biggest code marketplace on the internet, owned by Envato.&lt;/p&gt;
    &lt;p&gt;They’re always on. They log into real sites, click around, fill out forms, and adapt when pages change — no brittle scripts, no APIs needed. You can deploy one in minutes, host it yourself, and watch it do work like a human (but faster, cheaper, never tired).&lt;/p&gt;
    &lt;p&gt;Kind of like a “browser-use cloud,” except it’s yours — open, self-hostable, and way more capable.&lt;/p&gt;
    &lt;p&gt;It is a tool that lets you create whiteboard explainers.&lt;/p&gt;
    &lt;p&gt;You can prompt it with an idea or upload a document and it will create a video with illustrations and voiceover. All the design and animations are done by using AI apis, you dont need any design skills.&lt;/p&gt;
    &lt;p&gt;Here is a video explainer of the popular "Attention is all you need" paper.&lt;/p&gt;
    &lt;p&gt;I really like the idea! One issue though is that the content seems to "stream" much slower than what's being spoken. The result is that I'm sitting there waiting to see whats going to come, even though its already been said which makes it hard to focus on whatever new information is coming.&lt;/p&gt;
    &lt;p&gt;The animations / drawings themselves are solid too. I think there's more to play with wrt the dimensions and space of the background. It would be nice to see it zoom in and out for example.&lt;/p&gt;
    &lt;p&gt;- A front-end library that generates 10kb single-html-file artifacts using a Reagent-like API and a ClojureScript-like language. https://github.com/chr15m/eucalypt&lt;/p&gt;
    &lt;p&gt;- Beat Maker, an online drum machine. I'm adding sample uploads now with a content accessible storage API on the server. https://dopeloop.ai/beat-maker&lt;/p&gt;
    &lt;p&gt;- Tinkering with Nostr as a decentralized backend for simple web apps.&lt;/p&gt;
    &lt;p&gt;For fun, playing with Meshtastic https://meshtastic.org/ and contributing to the open source firmware and apps. They have something cool but need lots of help. I've patched 3 memory leaks and had a few other PRs merged already.&lt;/p&gt;
    &lt;p&gt;For work, https://heyoncall.com/ as the best tool for on-call alerting, website monitoring, cron job monitoring, especially for small teams and solo founders.&lt;/p&gt;
    &lt;p&gt;I guess they both fall under the category of "how do you build reliable systems out of unreliable distributed components" :)&lt;/p&gt;
    &lt;p&gt;I'm building Monadic DNA explorer, a tool to explore thousands of genetic traits from GWAS Catalog in your browser and plug in your own DNA data from 23andMe, Ancestry, etc. All processing happens locally on your machine and AI insights are run in a private LLM inside a TEE.&lt;/p&gt;
    &lt;p&gt;i got a side project mirubato https://mirubato.com/, a web app tracking instrument practice logs. there were wild ideas such as enable AI training, grading, managing score, practice plans, and such, but in the end, i removed most of features. not only because it takes more time (i am only using a part of my free time to work on this) and effort, talent, plannings, but also because during vibe (yes, most of coding done by claude code) i realized that it still requires ultra deep thinking to design the minimal minimal UI i would like.&lt;/p&gt;
    &lt;p&gt;now the foundation is done, i've learnt a lot. i'm actually eating dog food by using it to track my own classical guitar practice everyday. i am pausing a while to process the requirements by ultra deep thinking to understand what would be helpful and how to shape the product.&lt;/p&gt;
    &lt;p&gt;LLMs such as codex and claude code definitely helped a lot, but I guess human beings' opinions would be more helpful - after all, the tool is made for humans instead of being used by claude code.&lt;/p&gt;
    &lt;p&gt;I would also like to hear when you start a project, if you know your audience are not super close to AI, would you still consider to enable the AI feature for them?&lt;/p&gt;
    &lt;p&gt;An experimental mesh network protocol, that is still very much pre alpha and missing some features.&lt;/p&gt;
    &lt;p&gt;The big thing I wanted to try is automatic global routing via MQTT.&lt;/p&gt;
    &lt;p&gt;Everything is globally routable. You can roam around between gateway nodes, as long as all the gateways are on the same MQTT server.&lt;/p&gt;
    &lt;p&gt;And there's a JavaScript implementation that connects directly to MQTT. So you can make a sensor, go to the web app, type the sensor's channel key, and see the data, without needing to create any accounts or activate or provision anything.&lt;/p&gt;
    &lt;p&gt;I am working on a platform to help user to enrich their data by AI. so that AI can understand their Data more, especially for ChatGPT. Also it's easy to host a data and publish a MCP for ChatGPT.&lt;/p&gt;
    &lt;p&gt;The challenge is how ChatGPT can understand your "query" or say "prompts"? Raw data is not good enough - so I try to use a term called "AI Understanding Score" to measure it: https://senify.ai/ai-understanding-score. I think this index will help user to build more context so that AI can know more and answer with correct result.&lt;/p&gt;
    &lt;p&gt;This is very early work without every detail considered, really would like to have your feedback and suggestions.&lt;/p&gt;
    &lt;p&gt;I’ve got a side project going that’s a browser extension (starting with Safari + Sign in with Apple) intended to add a comment layer to the internet as a whole. I’m calling it Chaffiti (https://chaffiti.com).&lt;/p&gt;
    &lt;p&gt;The idea is to enable a comment section on any webpage, right as you’re browsing. Viewing a Zillow listing? See what people are excited about with the property. Wonder what people think about a tourist attraction? It’ll be right there. Want to leave your referral or promo code on a checkout page for others? Post it.&lt;/p&gt;
    &lt;p&gt;Not sure what the business model will look like just yet. Just the kind of thing I wish existed compared to needing to venture out to a third party (traditional social media / forums etc) to see others’ thoughts on something I’m viewing online. I welcome any feedback!&lt;/p&gt;
    &lt;p&gt;Having migraines on and off the past few months, I wanted a way to try and narrow down triggers. All the existing apps out there were overly complicated. So I built something simpler.&lt;/p&gt;
    &lt;p&gt;It’s an iOS app to help tracking events and stats about my day as simple dots. How many cups of coffee? Did I take my supplements? How did I sleep? Did I have a migraine? Think of it like a digital bullet journal.&lt;/p&gt;
    &lt;p&gt;Then visualizing all those dots together helps me see patterns and correlations. It’s helped me cut down my occurrence of migraines significantly. I’m still just in the public beta phase but looking forward to a full release fairly soon.&lt;/p&gt;
    &lt;p&gt;Would love to hear more feedback on how to improve the app!&lt;/p&gt;
    &lt;p&gt;This is great! I can see this useful across a variety of self-assessment things: - I’m tired often, are there certain patterns that align with that? - I’m feeling anxious, what events in a day (or other inputs) align with that?&lt;/p&gt;
    &lt;p&gt;I'm working on Teletable (https://teletable.app), a macOS app that shows live football &amp;amp; F1 standings/results with a teletext interface (think BBC Ceefax). It's free and on the appstore:&lt;/p&gt;
    &lt;p&gt;Collecting public datasets for training visual AI models to track and target drones.&lt;/p&gt;
    &lt;p&gt;Drones are real bastards - there's a lot of startups working on anti drone systems and interceptors, but most of them are using synthetic data. The data I'm collecting is designed to augment the synthetic data, so anti drone systems are closer to field testing&lt;/p&gt;
    &lt;p&gt;Hi HN, I am working on Circuitscript, a language based on python to describe electronic schematics: https://circuitscript.net/. A basic IDE (called the Bench) to try Circuitscript is available online: https://bench.circuitscript.net/&lt;/p&gt;
    &lt;p&gt;Since the last month, I have created a complete schematic with Circuitscript, exported the netlist to pcbnew and designed the PCB. The boards have been produced and currently waiting for them to be delivered to verify that it works. Quite excited since this will be the first design ever produced with Circuitscript as the schematic capture tool!&lt;/p&gt;
    &lt;p&gt;The motivation for creating Circuitscript is to describe schematics in terms of code rather than graphical UIs after using different CAD packages extensively (Allegro, Altium, KiCAD) in the past. I wanted to spend more time thinking about the schematic design itself rather than fiddling around with GUIs.&lt;/p&gt;
    &lt;p&gt;The main language goals are to be easy to write and reason, generated graphical schematics should be displayed according to how the designer wishes so (because this is also part of the design process) and to encourage code reuse.&lt;/p&gt;
    &lt;p&gt;Please check it out and I look forward to your feedback, especially from electronics designers/hobbyists. Thanks!&lt;/p&gt;
    &lt;p&gt;I built https://invoicepad.app which is a free, completely in-browser tool for creating invoices, estimates, and quotes. Yes, similar apps have been posted here before, but none were built the way I envisioned, so I made my own. The key difference: all invoice data is stored in the URL hash, not the querystring. This is important because querystrings are sent to the server with every request, while hashes stay local to your browser. This means I can never see your invoice data, unlike other similar apps. The workflow is simple: use your browser's bookmark manager as your invoice filing system. Or if you want to keep it offline, just copy and paste invoice URLs into a text document for storage. I’ve also included helpful features like saved profiles to save on repeated data input. The next step is to finish working on a browser extension (v1 is being tested) to make bookmarking, editing, and saving changes even easier, that is if I ever stop being distracted by other side projects.&lt;/p&gt;
    &lt;p&gt;I'm working on Veila, a privacy‑first AI chat service. I wanted something that prevents model providers from profiling users and linking information from chats to their identity.&lt;/p&gt;
    &lt;p&gt;I'm a robotics engineer by training, this is my first public launch of a web app.&lt;/p&gt;
    &lt;p&gt;- What it is: - Anonymous AI chat via a privacy proxy (provider sees our server, not your IP or account info) - End‑to‑end encrypted history, keys derived from password and never leave your device - Pay‑as‑you‑go; switch models mid‑chat (OpenAI now; Claude, Gemini and others planned) - Practical UX: sort chats into folders, Markdown, copyable code blocks, mobile‑friendly - Notes/limits: - Not self‑hosted: prompts go to third‑party APIs - If you include identifying info, upstream sees it - Prompts take a bit long sometimes, because reasoning is set to "medium" for now. Plan to make this adjustable in the future. - Looking for feedback: - What do you need to trust this? Open source? Independent audit? - Gaps in the threat model I'm missing - Which UI features and AI models you'd want next - Any UX rough edges (esp. mobile) - Learn more: - Compare Veila to ChatGPT, Claude, Gemini, etc. (best viewed on desktop): https://veila.ai/docs/compare.html - Discord: https://discord.gg/RcrbZ25ytb - More background: https://veila.ai/about.html&lt;/p&gt;
    &lt;p&gt;Hmm. I can't say for others, but I can tell you what would work for me given that I might meet some the criteria of desired audience for this.&lt;/p&gt;
    &lt;p&gt;In this space, it is more about trust and what you have done in the past more than anything else. Audits and whatnot are nice, but I need to be able to trust that your decisions will be sound. Think how Steam's Gabe gained his reputation. Not exactly easy feat these days.&lt;/p&gt;
    &lt;p&gt;Thanks for sharing this! Fully agree that trust is key, normally being on the user side of privacy-focussed services myself. Open source can help build this trust, but it would be ideal to have a way to make what is actually running on and being served by the servers transparent.&lt;/p&gt;
    &lt;p&gt;I'd love to hear your feedback if you get around to test Veila, e.g. on hey@veila.ai.&lt;/p&gt;
    &lt;p&gt;Our waitlist is open for https://flatm8.co.uk - the platform for anonymous reviews of Landlords and Estate Agents in Britain and Ireland.&lt;/p&gt;
    &lt;p&gt;We’re working directly with partner housing unions and charities in Britain and Ireland to build the first central database of rogue landlords and estate agents. Users can search an address and see if it’s marked as rogue/dangerous by the local union, as well as whether you can expect to see your deposit returned, maintenance, communication - etc.&lt;/p&gt;
    &lt;p&gt;After renting for close to a decade, it’s the same old problems with no accountability. We wanted to change this, and empower tenants to share their experiences freely and easily with one another.&lt;/p&gt;
    &lt;p&gt;We’re launching in November, and I’m very excited to announce our partner organisations! We know this relies on a network effect to work, and we’re hoping to run it as a social venture. I welcome any feedback.&lt;/p&gt;
    &lt;p&gt;I’m working on Reflect [0], it’s a private self discovery and self experimentation app. You can track metrics, set goals, get alerted to anomalies, view correlations, visualize your data, etc.&lt;/p&gt;
    &lt;p&gt;I'm working on 1:6 size furniture. There's not much woodworking I can do outside of the shop, so I've been trying to shrink full joinery techniques down to dollhouse size.&lt;/p&gt;
    &lt;p&gt;I'm working on Plaid / Perplexity for business data.&lt;/p&gt;
    &lt;p&gt;The basic idea is that integrating business data into a B2B app or AI agent process is a pain. On one side there's web data providers (Clearbit, Apollo, ZoomInfo) then on the other, 150 year old legacy providers based on government data (D&amp;amp;B, Factset, Moody's, etc). You'd be surprised to learn how much manual work is still happening - teams of people just manually researching business entities all day.&lt;/p&gt;
    &lt;p&gt;At a high level, we're building out a series of composable deep research APIs. It's built on a business graph powered by integrations to global government registrars and a realtime web search index. Our government data index is 265M records so far.&lt;/p&gt;
    &lt;p&gt;We're still pretty early and working with enterprise design partners for finance and compliance use cases. Open to any thoughts or feedback.&lt;/p&gt;
    &lt;p&gt;I am working on Lunch Flow (https://lunchflow.app), a tool that allows people to automatically sync their bank accounts to their favorite budgeting apps (Google Sheets, Lunch Money, Actual Budget, or use our API!)&lt;/p&gt;
    &lt;p&gt;I was motivated to build this as I found that many great personal finance and budget apps didn't offer integrations with the banks I used, which is understandable given the complexity and costs involved, so I wanted to tackle this problem and help build the missing open banking layer for personal finance apps, with very low costs (a few dollars a month) and a very simple api, or built-in integrations.&lt;/p&gt;
    &lt;p&gt;Still working on making this sustainable, but been quite a learning experience so far, and quite excited to see it already making a difference for so many people :)&lt;/p&gt;
    &lt;p&gt;I'm working on a design system. I'm a software eng not a designer, but I started one a long while back because I wanted to get a sense of what designers go through. I've dropped it and came back a half dozen times but now I'm finishing it up.&lt;/p&gt;
    &lt;p&gt;It's been a great project to understand how design depends on a consistent narrative and purpose. At first I put together elements I thought looked good but nothing seemed to "work" and it's only when I took a step back and considered what the purpose and philosophy of the design was that it started to feel cohesive and intentional.&lt;/p&gt;
    &lt;p&gt;I'll never be a designer but I often do side projects outside my wheelhouse so I can build empathy for my teammates and better speak their language.&lt;/p&gt;
    &lt;p&gt;I'm putting a bunch of security tools / data feeds together as a service. The goal is to help teams and individuals run scans/analysis/security project management for "freemium" (certain number of scans/projects for free each month, haven't locked in on how it'll pan out fully $$ wise).&lt;/p&gt;
    &lt;p&gt;I want to help lower the technical hurdles to running and maintaining security tools for teams and individuals. There are a ton of great open source tools out there, most people either don't know or don't have the time to do a technical deep dive into each. So I'm adding utilities and tools by the day to the platform.&lt;/p&gt;
    &lt;p&gt;Likewise, there's a built in expert platform for you to get help on your security problems built into the system. (Currently an expert team consisting of [me]). Longer term, I'm working on some AI plugins to help alert on CVEs custom to you, generate automated scans, and some other fun stuff.&lt;/p&gt;
    &lt;p&gt;I'm calling it a "Micro Functions as a Service" platform.&lt;/p&gt;
    &lt;p&gt;What it really is, is hosted Lua scripts that run in response to incoming HTTP requests to static URLs.&lt;/p&gt;
    &lt;p&gt;It's basically my version of the old https://webscript.io/ (that site is mostly the same as it was as long as you ignore the added SEO spam on the homepage). I used to subscribe to webscript and I'd been constantly missing it since it went away years ago, so I made my own.&lt;/p&gt;
    &lt;p&gt;I mostly just made this for myself, but since I'd put so much effort into it, I figure I'm going to try to put it out there and see if anyone wants to pay me to use it. Turns out there's a _lot_ of work that goes into abuse prevention when you're code from literally anyone on the internet, so it's not ready to actually take signups yet. But, there is a demo on the homepage.&lt;/p&gt;
    &lt;p&gt;I'm working on a DnD character sheet app! I spent last week implementing the core DnD SRD ruleset, but what I'm really excited about is ML integration. I want to add a self-hosted fine-tuned ML model that acts as a character and DM assistant. Obviously an LLM via API can do the job, but I'm really curious if it's possible to build smaller, cheaper, task-specific models. Plus, I've never integrated an ML model into a product before, and I'm curious to play with it. I'm thinking of it like clippy for DnD: "it looks like you're trying to cast fireball?"&lt;/p&gt;
    &lt;p&gt;Besides the LLM experimentation, this project has allowed me to dive into interesting new tech stacks. I'm working in Hono on Bun, writing server-side components in JSX and then updating the UI via htmx. I'm really happy with how it's coming together so far!&lt;/p&gt;
    &lt;p&gt;This is built with Rust, egui and SQLite3. The app has a downloader for NSE India reports. These are the daily end of day stock prices. Out of the box the app is really fast, which is expected but still surprises me. I am going to work on improving the stocks chart. I also want to add an AI assisted stocks analyst. Since all the stocks data is on the SQLite3 DB, I should be able to express my stocks screening ideas as plain text and let an LLM generate the SQL and show me in my data grid.&lt;/p&gt;
    &lt;p&gt;It was really interesting to generate it within 3 days. I had just a few places where I had to copy from app (std) log and paste into my prompt. Most of the time just describing the features was enough. Rust compiler did most of the heavy lifting. I have used a mix of Claude Code and OpenCode (with either GLM 4.5 or Grok Code Fast 1).&lt;/p&gt;
    &lt;p&gt;I have been generating full-stack web apps. I built and launched https://github.com/brainless/letsorder (https://letsorder.app/). Building full-stack web apps is basically building 2 apps (at a minimum) so desktop apps are way better it seems.&lt;/p&gt;
    &lt;p&gt;In the long-term, I plan to build and help others generated apps. I am building a vibe coding platform (https://github.com/brainless/nocodo). I have a couple early stage founders I consult for who take my guidance to generate their products (web and mobile apps + backend).&lt;/p&gt;
    &lt;p&gt;Drawing a lot of inspiration from interval.com. It was an amazing product but was a hosted SAAS. I'm exploring taking the idea to the .NET ecosystem and also making it a Nuget package that can be installed and served through any ASP.NET project.&lt;/p&gt;
    &lt;p&gt;I'm trying to turn code into a design tool. Kind of like if you ask yourself - what if Cursor had been built for designers?&lt;/p&gt;
    &lt;p&gt;Currently it looks like this:&lt;/p&gt;
    &lt;p&gt;- code editor directly in the browser - writes to your local file system - UI-specific features built into the editor - ways to edit the CSS visually as well as using code - integrated AI chat&lt;/p&gt;
    &lt;p&gt;But I have tons of features I want to add. Asset management, image generation, collaborative editing, etc.&lt;/p&gt;
    &lt;p&gt;It's still a prototype, but I'm actively posting about it on twitter as I go. Soon, I'll probably start publishing versioned builds for people to play with: https://x.com/danielvaughn&lt;/p&gt;
    &lt;p&gt;We just brought an IFR 2947a communications service monitor back from the dead. It's amazing how much functionality that you can pack into about 6U of rack space. I was testing it out, and detecting signals down to 0.1 uV on the spectrum analyzer.&lt;/p&gt;
    &lt;p&gt;I've been gathering up the supplies to set up a proper radio/computer repair workshop.&lt;/p&gt;
    &lt;p&gt;Adding new transports and documentation to my Typescript logging library (MIT licensed), LogLayer (https://loglayer.dev). Just added documentation for Bun and Deno support added some new logging library transports (LogTape), and finishing up Logflare and Betterstack transports so you can send logs to their logging APIs.&lt;/p&gt;
    &lt;p&gt;A lot of people often ask questions like: - How do I lose body fat and build muscle? - How can I track progress over time? - How much exercise do I actually need? - What should my calorie and macro targets be?&lt;/p&gt;
    &lt;p&gt;The goal is to provide a fully typed nodeJS framework that allows you to write a typescript function once and then decide whether to wire it up to http, websocket, queues, scheduled tasks, mcp server, cli and other interactions.&lt;/p&gt;
    &lt;p&gt;You can switch between serverless and server deployments without any refactoring / completely agnostic to whatever platform your running it on&lt;/p&gt;
    &lt;p&gt;It also provides services, permissions, auth, eventhub, advanced tree shaking, middleware, schema generation and validation and more&lt;/p&gt;
    &lt;p&gt;The way it works is by scanning your project via the typescript compiler and generating a bootstrap file that imports everything you need (hence tree shaking), and allows you to filter down your backend to only the endpoints needed (great to pluck out individual entry points for serverless). It also generates types fetch, rpc, websocket and queue client files. Types is pretty much most of what pikku is about.&lt;/p&gt;
    &lt;p&gt;Think honoJS and nestJS sort of combined together and also decided to support most server standards / not just http.&lt;/p&gt;
    &lt;p&gt;Website needs love, currently working on a release to support CLI support and full tree shaking.&lt;/p&gt;
    &lt;p&gt;I've been working on a tool called Materia[0] for managing Podman Quadlets on hosts; I released a new version last month (and posted it on the September thread) and just merged automatic volume data migration the other day. Next goal is to design a system for downloading and loading remote components, similar to ansible roles. Hopefully I can tie it into the new podman quadlet install/etc commands.&lt;/p&gt;
    &lt;p&gt;Currently building a Declarative Web Assembler of Html/Json using AI in multiple languages for the past 1 month: https://github.com/Srid68/Arshu.Assembler deployed to fly.io&lt;/p&gt;
    &lt;p&gt;The purpose is to find if can i build declarative software in multiple langauges (Rust, Go, Node.Js, PHP and Javascript) knowing only one language (C#) without understanding the implementation deeply.&lt;/p&gt;
    &lt;p&gt;Another purpose is validate AI models and their efficiency since development using AI is hard but highly productive and having a declarative rules to recreate the implementation may be used to validate models&lt;/p&gt;
    &lt;p&gt;Currently i am convinced it is possible to build, but now working on creating a solid foundation with tests of the two assembler engines, structure dumps, logging, logging outputs so that those can be used by the AI which it needs to fix issues iteratively.&lt;/p&gt;
    &lt;p&gt;Need to add more declarative rules and implement a full stack web assembler to see if AI will hit the technical debt which slows/stop progress. Only time will tell.&lt;/p&gt;
    &lt;p&gt;Working on my lisp. I recently added delimited continuations, even wrote a blog post about it. Now I'm working on adding more control primitives. Just finished researching generators. I'm going to implement them as a separate interpreter of sorts.&lt;/p&gt;
    &lt;p&gt;A “code index” tool that finds symbols in a codebase and creates a single table sqlite database for querying. It’s my second month using Claude Code, and I see a common pattern where Claude tries to guess patterns with grep, and often comes back with empty results. I’m writing the tool to prevent these fruitless searches. Using tree-sitter to parse the AST and add the symbols and what they are (function, class, argument, etc) to the db. I have it working with TypeScript, and am working on adding C and PHP.&lt;/p&gt;
    &lt;p&gt;Aider builds something it calls a "repo map" that I believe is for a similar purpose. Might be worth taking a look!&lt;/p&gt;
    &lt;p&gt;I haven't used Claude Code, but recently switched to OpenCode. My token usage and cost is a lot higher, I'm not sure why yet, but I suspect Aider's approach is much more lean.&lt;/p&gt;
    &lt;p&gt;This is why codepathfinder.dev is born. It underhood use tree-sitter to search functions, class, member variables and pulls code accurately instead of regex.&lt;/p&gt;
    &lt;p&gt;I started using it like tool call in Security scanning (think of something like claude-code for security scanning)&lt;/p&gt;
    &lt;p&gt;Still working on cataloging a curated list of craft beer venues across the world at https://wheretodrink.beer Unsure what the plan is going forward with it, apart from adding more venues and more countries. As long as it's fun for me I'll just keep adding things.&lt;/p&gt;
    &lt;p&gt;Just added health inspection data from countries that have that in open datasets (UK and Denmark). If anyone know of others I'd be appreciative of hints.&lt;/p&gt;
    &lt;p&gt;Thinking of focusing on another idea for the rest of the year, have a rough idea for a map based ui to structure history by geofences or lat / lng points for small local museums&lt;/p&gt;
    &lt;p&gt;Trying to get a new release of Video Hub App - my 7+ years passion project to browse videos from local storage in style. Maybe will finally finish the (optional!) facial recognition feature I started 5+ years ago.&lt;/p&gt;
    &lt;p&gt;I am playing at creating a FTP interface for all file transfer protocols (including the Dropbox API) so we can settle the argument of the infamous top comment of the Dropbox launch: https://github.com/mickael-kerjean/filestash&lt;/p&gt;
    &lt;p&gt;Building a donations powered marketplace, zero platform fee: https://shomp.co&lt;/p&gt;
    &lt;p&gt;Merchants who want to sell on Etsy or Shopify either have to pay a listing fee or pay per month just to keep an online store on the web. Our goal is to provide a perpetually free marketplace that is powered solely off donations. The only fees merchants pay are the Stripe fees, and it's possible that at some volume of usage we will be able to negotiate those down.&lt;/p&gt;
    &lt;p&gt;You can sell digital goods as well as physical goods. Right now in the "manual onboarding" phase for our first batch of sellers.&lt;/p&gt;
    &lt;p&gt;For digital goods, purchasers get a download link for files (hosted on R3).&lt;/p&gt;
    &lt;p&gt;For physical goods, once a purchase comes through, the seller gets an SMS notification and a shipping label gets created. The buyer gets notified of the tracking number and on status changes.&lt;/p&gt;
    &lt;p&gt;We use Stripe Connect to manage KYC (know your customer) identities so we don't store any of your sensitive details other than your name and email. Since we are in the process of incorporating as a 501(c)(3) nonprofit, we are only serving sellers based in the United States.&lt;/p&gt;
    &lt;p&gt;The mission of the company is to provide entrepreneurial training to people via our online platform, as well as educational materials to that aim.&lt;/p&gt;
    &lt;p&gt;Right now the API is nonexistent, relying entirely on people using the web interface to make listings, upload photos, and set prices. But if you would find this useful I can happily build it out. Our stack is Elixir and building APIs is very straightforward. Our code is open-source, too!&lt;/p&gt;
    &lt;p&gt;When you say "algorithmically driven print-on-demand" do you mean that prices would automatically adjust based on inventory? Or like, how do you mean.&lt;/p&gt;
    &lt;p&gt;Also, when you say "see them show up in a request on sale" — can you clarify? I interpret this to mean you want a webhook triggered when an order comes in.&lt;/p&gt;
    &lt;p&gt;I just finished writing a small script that finds all optimally bad Wordle guesses. More precisely, on hard Wordle, where you must give a valid word (from the guesses list), and you must use yellows + greens, and must not use greys, what are all the combinations of answer + 6 guesses where there is only grey. This is equivalent to finding all answer + 6 guesses where no letters are in common between any pair.&lt;/p&gt;
    &lt;p&gt;This is basically a variation on bit-packing (which is NP-hard), but it's tractable if you prune the search space enough.&lt;/p&gt;
    &lt;p&gt;The goal is to catch vulnerabilities early in the SDLC by running agentic loop that autonomously hunt for security issues in codebases.Currently available as a CLI tool, VSCode extension.I've been actively using to scan WordPress, odoo plugins and found several privilege escalation vuln. I have documented as blog post here: https://codepathfinder.dev/blog/introducing-secureflow-cli-t...&lt;/p&gt;
    &lt;p&gt;Now that I can finally test on hardware, I completely rewrote input handling. I can now support original NES controllers, but also SNES and the Power Pad dance mat, for anyone crazy enough to try that. The hardest part was working around a particularly nasty hardware bug: if you try to read the input ports on even cycles while one of the sound channels is playing, the data becomes corrupted. Perform the exact same read on an odd cycle and it works every time.&lt;/p&gt;
    &lt;p&gt;The solution? Have the cartridge keep track of CPU parity (there's no simple way to do this with just the CPU), then check that, skip one cycle if needed... and very carefully cycle time the rest of the routine, making sure that your reads land on safe cycles, and your writes land in places that won't throw off the alignment.&lt;/p&gt;
    &lt;p&gt;But it works! It's quite reliable on every console revision I've thrown it at so far. Suuuper happy with that.&lt;/p&gt;
    &lt;p&gt;This is going in fits and starts, but I'm working on a Win16 decompiler. The problems with existing decompiler tools for 16-bit code are a) support the NE file format is far less widespread; b) 16-bit code means geating to deal with segment registers, which are largely unmodelled for most binary tools; and c) turns out that you also have to get really good at recognizing "this is a 32-bit value being accessed entirely in 16-bit word chunks," which tends to be under-supported for most optimization toolchains.&lt;/p&gt;
    &lt;p&gt;I’m working on a performance capture library for Python because I often need to know the performance of backend systems I maintain. I frequently build tooling to capture performance and save it for later analysis. I/O operations get costly when writing lots of data to disk and creating good real-time analytics tools takes a lot of my time. I wanted a library that captures real-time performance analytics from Python backends.&lt;/p&gt;
    &lt;p&gt;This is why I wrote kronicler to record performance metrics while being fast and simple to implement. I built my own columnar database in Rust to capture and analyze these logs.&lt;/p&gt;
    &lt;p&gt;To capture logs, `import kronicler` and add `@kronicler.capture` as a decorator to functions in Python. It will then start saving performance metrics to the custom database on disk.&lt;/p&gt;
    &lt;p&gt;You can then view these performance metrics by adding a route to your server called `/logs` where you return `DB.logs()`. You can paste your hosted URL into the settings of usekronicler.com (the online dashboard) and view your data with a couple charts. View the readme or the website for more details for how to do this.&lt;/p&gt;
    &lt;p&gt;I'm still working on features like concurrency and other overall improvements. I would love some feedback to help shape this product into something useful for you all.&lt;/p&gt;
    &lt;p&gt;I've been working on a browser plugin for Amazon that attempts to identify the brand and seller country: https://www.wheresthatfrom.org/&lt;/p&gt;
    &lt;p&gt;It's mostly where I want it to be now, but still need to automate the ingest of USPTO data. I'd really like it to show a country flag on the search results page next to each item, but inferring the brand name just from the item title would probably need some kind of natural language processing; if there's even a brand in the title.&lt;/p&gt;
    &lt;p&gt;No support for their mobile layout. Do many people buy from their phone?&lt;/p&gt;
    &lt;p&gt;I'm doing some experiments in LLM (historical) fiction writing. I feel like we can get pretty good writing out of an LLM (especially Sonnet) with enough prompting, reasoning, and guided thinking. Still with a human as producer and guidance.&lt;/p&gt;
    &lt;p&gt;I'm trying to use this to create stories that would be somewhat unreasonable to write otherwise. Branching stories (i.e., CYOA), multiperspective stories, some multimedia. I'm still trying to figure out the narrative structures that might work well.&lt;/p&gt;
    &lt;p&gt;LLMs can overproduce and write in different directions than is reasonable for a regular author. Though even then I'm finding branching hard to handle.&lt;/p&gt;
    &lt;p&gt;The big challenges are rhythm, pacing, following an arc. Those have been hard for LLMs all along.&lt;/p&gt;
    &lt;p&gt;It is a modified version of Shopify's CEO Tobi try implementation[0]. It extends his implementation with sandboxing capabilities and designed with functional core, imperative shell in mind.&lt;/p&gt;
    &lt;p&gt;I had success using it to manage multiple coding agents at once.&lt;/p&gt;
    &lt;p&gt;I'm working on a compiler for WebAssembly. The idea is you use the raw wasm instructions like you’d use JSX in React, so you can make reusable components and compose them into higher abstractions. Inlining is just a function call.&lt;/p&gt;
    &lt;p&gt;It’s implemented in Elixir and uses its powerful macro system. This is paired with a philosophy of static &amp;amp; bump allocation, so I’m trying to find a happy medium of simplicity with a powerful-enough paradigm yet generate simple, compact code.&lt;/p&gt;
    &lt;p&gt;I'm in The Hague right now at a digital democracy conference, where I was invited to present on my prototype that I've been building the past few months!&lt;/p&gt;
    &lt;p&gt;It's for doing realtime "human cartography", to make maps of who we are together in complex large-scale discourse (even messy protest).&lt;/p&gt;
    &lt;p&gt;It's for exploring human perspective data -- agree, disagree, pass reactions to dozens or hundreds of belief statements -- so we can read it as if it were Google Maps.&lt;/p&gt;
    &lt;p&gt;My operating assumption is that if a critical mass of us can understand culture and value clashes as mere shapes of discourse, and we can all see it together, the we can navigate them more dispassionately and with clear heads. Kinda like reading a map or watching the weather report -- islands that rise from oceans, or plate tectonics that move like currents over months, and terraform the human landscape -- maybe if we can see these things together, we'll act less out of fear of fun-house caricatures. (E.g., "Hey, dad, it seems like the peninsula you're on is becoming a land bridge toward the alt right corner. I feel a little bummed about that. How do you feel about it?")&lt;/p&gt;
    &lt;p&gt;(It builds on data and the mathematical primitives of a great tool called Pol.is, which I've worked with for almost a decade.)&lt;/p&gt;
    &lt;p&gt;Currently working on the web reader of WithAudio. Just add with.audio/ to begining of a public URL and get the text and audio in your browser. It runs the TTS in your browser so its free and unlimited.&lt;/p&gt;
    &lt;p&gt;I buit this to get some traffic to my main project's website using a free tool people might like. The main project: https://desktop.with.audio -&amp;gt; a one time payment text to speech app with text highlighting and export mp3 and other features on MacOS (ARM only) and Windows.&lt;/p&gt;
    &lt;p&gt;Would love to see the Red Cross partner with someone like you here in Australia. Not affiliated, just a donor. We're not financially incentivised like other countries but there's a big culture here about celebrating the free milkshake and/or sausage roll you get after donating.&lt;/p&gt;
    &lt;p&gt;I’m working on Leggen (https://github.com/elisiariocouto/leggen), a self hosted personal banking account management system. It started out as a CLI that syncs your bank account transactions and balances, saves them in a sqlite database and can alert you via Telegram or Discord if a transaction matches a filter. Recently I started refactoring the project with the help of Claude Code and Copilot Agent to include an API and a Web app to explore the data and configure it. The product is using GoCardless Bank Accout Data APIs to connect to banks via PSD2 but I found out recently that registering a new account is no longer possible so I’m currently looking into alternatives.&lt;/p&gt;
    &lt;p&gt;Check out Lunch Flow (https://lunchflow.app) for a global open banking API that's accessible for personal finance apps :) We integrate with Gocardless, among other global open banking providers.&lt;/p&gt;
    &lt;p&gt;I am working on Tailstream (https://tailstream.io/), turning logs into task time visual data streams. Built the web application, web site and a Go CLI agent (open source) and am now slightly pivoting into making it more log-focused.&lt;/p&gt;
    &lt;p&gt;Working on faceted search for logs and CLI client now and trying to share my progress on X.&lt;/p&gt;
    &lt;p&gt;The goal was to make the learning material very malleable, so all content can be viewed through different "lenses" (e.g. made simpler, more thorough, from first principles, etc.). A bit like Wikipedia it also allows for infinite depth/rabbit holing. Each document links to other documents, which link to other documents (...).&lt;/p&gt;
    &lt;p&gt;I'm also currently in the middle of adding interactive visualizations which actually work better than expected! Some demos:&lt;/p&gt;
    &lt;p&gt;Working on https://videotobe.com a audio/video transcription service. VideoToBe started as a user friendly Whisper wrapper — but is evolving into a full pipeline that extracts, summarizes, and structures insights from multimedia content.&lt;/p&gt;
    &lt;p&gt;A monster trainer game where you can _actually teach new, creative moves_ to your monsters: https://youtu.be/ThOCM9TK_yo&lt;/p&gt;
    &lt;p&gt;Basically, think of it as "Pokemon the anime, but for real". We allow you to use your voice to talk to, command, and train your monster. You and your monster are in this sandbox-y, dynamic environment where your actions have side effects.&lt;/p&gt;
    &lt;p&gt;You can train to fight or just to mess around.&lt;/p&gt;
    &lt;p&gt;Behind the scenes, we are converting player's voice into code in real time to give life to these monsters.&lt;/p&gt;
    &lt;p&gt;An implementation of statecharts. I'm working through core functionality using recursive algorithms.&lt;/p&gt;
    &lt;p&gt;I discovered that "least common ancestor" boils down to the intersection of 'root-path' sets, where you select the last item in the set as the 'first/least common ancestor'.&lt;/p&gt;
    &lt;p&gt;Working on: to teach myself Rust, I’ve been working on a NYT Letter Boxed solver, with some ambitions to turn it into a game by itself. I think this game could be made a lot more fun.&lt;/p&gt;
    &lt;p&gt;Thinking about: A new take on LinkedIn/web-of-trust, bootstrapped by in-person interactions with devices. It seems that the problem of proving who is actually human and getting a sense of how your community values you might be getting more important, and now devices have some new tools to bring that within reach.&lt;/p&gt;
    &lt;p&gt;Working on https://practicecallai.com/ - simple saas that lets users run practice calls / role play against a custom AI partner. Goal is to make it the easiest to use &amp;amp; fastest to get started with in the market.&lt;/p&gt;
    &lt;p&gt;It’s been a fun, practical way to continuously evaluate the latest models two ways - via coding assistance &amp;amp; swapping between models to power the conversational AI voice partner. I’ve been trying to add one big new feature each time the model generation updates.&lt;/p&gt;
    &lt;p&gt;The next thing I want to add is a self improving feedback loop where it uses user ratings of the calls &amp;amp; evaluations to refine the prompts that generate them.&lt;/p&gt;
    &lt;p&gt;I'm expanding my computational biology toolkit in rust. Of recent interest is optimizing long-range molecular dynamics forces on GPU and SIMD, adding support to generate lipid membranes and LNPs, and a 3D small molecule editor with integrated dynamics.&lt;/p&gt;
    &lt;p&gt;This is a job board for AI jobs and companies. The job market in AI is pretty hot right now, and there are a lot of cool AI companies out there. I'm hoping to connect job seekers with fast-growing AI companies.&lt;/p&gt;
    &lt;p&gt;Conductor is a LLM agnostic framework for building sophisticated AI applications using a subagent architecture. It provides a robust platform for orchestrating multiple specialized AI agents to accomplish complex tasks, with features like LLM-based planning, memory persistence, and dynamic tool use.&lt;/p&gt;
    &lt;p&gt;It provides a robust and flexible platform for orchestrating multiple specialized AI agents to accomplish complex tasks. This project is inspired by the concepts outlined in "The Rise of Subagents" by Phil Schmid at https://www.philschmid.de/the-rise-of-subagents and it aims to provide a practical implementation of this powerful architectural pattern.&lt;/p&gt;
    &lt;p&gt;Plugging away with reviews of Genrative AI tech with detailed comparisons. I announced the launch on HN a while ago, thought I’d use this month’s for a status update.&lt;/p&gt;
    &lt;p&gt;I just took Qwen-Image and Google’s image AIs for a spin and I keep a side by side comparison of many of them.&lt;/p&gt;
    &lt;p&gt;Thanks, the 3D asset creators are very interesting. I'm working on LLM -&amp;gt; CAD tool (for 3d printing) and your post confirms that I should keep my focus, because there is so much other things to do (uv unwrapping!) if you are targeting games for example.&lt;/p&gt;
    &lt;p&gt;Porting my binary &amp;amp; decimal palindromes[0] finding code[1] to CUDA, with which I had no experience before starting this project.&lt;/p&gt;
    &lt;p&gt;It's already working, and slightly faster than the CPU version, but that's far from an acceptable result. The occupancy (which is a term I first learned this week) is currently at a disappointing 50%, so there's a clear target for optimisation.&lt;/p&gt;
    &lt;p&gt;Once I'm satisfied with how the code runs on my modest GPU at home, the plan is to use some online GPU renting service to make it go brrrrrrrrrr and see how many new elements I can find in the series.&lt;/p&gt;
    &lt;p&gt;-Many say they want to stop doomscrolling and clout-chasing but I don't know how many are actually willing to do so&lt;/p&gt;
    &lt;p&gt;-Individuals may move here but their friends won't. So the feed will be initially empty by design. Introducing any kind of reward is against our ethos so we are clueless about how to convince existing friend circles to move.&lt;/p&gt;
    &lt;p&gt;This may work in your favour - it's one of the reasons I enjoy Mastodon so much - friction is/was a little higher which kept my network small but focussed&lt;/p&gt;
    &lt;p&gt;iOS/Mac app for learning Japanese by reading, all in one solution with optional Anki integration&lt;/p&gt;
    &lt;p&gt;I went full-time on this a couple years ago. I’m now doing a full iOS 26 redesign, just added kanji drawing, and am almost done adding a manga mode via Mokuro. I’m also preparing influencer UGC campaigns as I haven’t marketed it basically at all yet.&lt;/p&gt;
    &lt;p&gt;The main idea is to bring as many of the agentic tools and features into a single cohesive platform as much as possible so that we can unlock more useful AI use-cases.&lt;/p&gt;
    &lt;p&gt;I'm working on adding favicons support to listings on my website directory I recently launched: https://intrasti.com&lt;/p&gt;
    &lt;p&gt;I just released the changelog 5 minutes ago https://intrasti.com/changelog which I went with a directory based approach using the international date format YYYY-MM-DD so in the source code it's ./changelog/docs/YYYY/MM/DD.md - seems to do the trick and ready for pagination which I haven't implemented yet.&lt;/p&gt;
    &lt;p&gt;You provide your URL and an LLM browses your site and writes up feedback. Currently working on increasing the quality of the feedback. Trying to start with a narrower set of tests that give what I think is good feedback, then increase from there.&lt;/p&gt;
    &lt;p&gt;If a tool like this analyzed your website, what would you actually want it to tell you? What feedback would be most useful?&lt;/p&gt;
    &lt;p&gt;I am working on a paper about solving the Royal Game of Ur, one of the world's oldest board games. We solved it a while ago, and are now trying to get more formal about it (https://royalur.net/solved).&lt;/p&gt;
    &lt;p&gt;I'm working on Debtmap - An open source Rust-based code complexity analyzer that tells you exactly which code to refactor and which code to test for maximum impact. Combines complexity metrics with test coverage data to identify the riskiest code in your codebase. Uses entropy analysis to reduce false positives by distinguishing genuinely complex code from repetitive patterns.&lt;/p&gt;
    &lt;p&gt;My partner and I are working on Supabird.io (https://supabird.io), a tool to help people grow on X in a more consistent and structured way. It analyzes viral posts within specific communities so users can learn what works and apply those insights to their own content.&lt;/p&gt;
    &lt;p&gt;My partner shares our journey on X (@hustle_fred), while I’ve been focused on building the product (yep, the techie here :). We’re excited to have onboarded 43 users in our first month, and we're looking forward to getting feedback from the HN community!&lt;/p&gt;
    &lt;p&gt;I'm currently working on building a local delivery service using electric cargo bikes in NYC: https://hudsonshipping.co. We are planning to launch our first pilot in early 2026 with our first customers in Brooklyn. We've built all of the tech in-house to manage the fleet, deliveries and optimize our routes. If you know of anyone that would like to be a part of the pilot program, feel free to reach out to me!&lt;/p&gt;
    &lt;p&gt;On-site surveys for eCommerce and SaaS. It's been an amazing ride leveling up back and forth between product, design, and marketing. Marketing is way more involved than most people on this site realize...&lt;/p&gt;
    &lt;p&gt;Haunted house trope, but it's a chatbot. Not done yet, but it's going well. The only real blocker is that I ran into the parental controls on the commercial models right away when trying to make gory images, so I had to spin up my own generators. (Compositing by hand definitely taking forever).&lt;/p&gt;
    &lt;p&gt;I'm building a mod for the game Subway Builder (http://subwaybuilder.com) that lets me undo/redo individual stations and tracks, instead of clearing all blueprints.&lt;/p&gt;
    &lt;p&gt;Lovely interface. This is quite impressive. I can't seem to get a terminal running though. Can I actually execute scripts here? I opened code and created a hello.py, terminal did not come up in Code either.&lt;/p&gt;
    &lt;p&gt;I'm working on a workout tracker that you can actually use for things like TRX and gymnastic rings. Along with normal workouts too. Let me know if there's anything you'd like on there. https://gravitygainsapp.com/&lt;/p&gt;
    &lt;p&gt;A mobile app that checks my email to find and extract family-related events/activities. The kind of things that are buried in a 12-point bullet list with font 8, inside of one of 10 school email messages received during the week&lt;/p&gt;
    &lt;p&gt;It runs fully on-device, including email classification and event extraction&lt;/p&gt;
    &lt;p&gt;Hmm, a personal assistant of sorts that does evaluation of you to get to the bottom of who you really are. For very obvious reasons, it is a local only project and not exactly intended for consumption.&lt;/p&gt;
    &lt;p&gt;Beyond that, just regular random stuff that comes up here and there, but, for once, my hdd with sidelined projects is slowly being worked through.&lt;/p&gt;
    &lt;p&gt;I've spent the last few months working on a custom RL model for coding tasks. The biggest headache has been the lack of good tooling for tuning the autorater's prompt. (That's the judge that gives the training feedback.) The process is like any other quality-focused task—running batch rating jobs and doing SxS evaluations—but the tooling really falls short. I think I'll have to build my own tools once I wrap up the current project&lt;/p&gt;
    &lt;p&gt;Headbang, a rhythm game that you play by bobbing your head while wearing Airpods while listening to music, is what I'm considering building next. The idea came from someone else using Airpods to create a racing game (RidePods).&lt;/p&gt;
    &lt;p&gt;I should also point out - if you download the current version, you should immediately apply the update that will pop up. And even then, you're results may be flakey.&lt;/p&gt;
    &lt;p&gt;While working on Shelvica, a personal library management service and reading tracker, I realized I needed a source of data for book information, and none of the solutions available provided all the data I needed. One might provide the series, the other might provide genres, and yet another might provide a cover with good dimensions, but none provided everything.&lt;/p&gt;
    &lt;p&gt;So I started working on Librario, an ISBN database that fetches information from several other services, such as Hardcover.app, Google Books, and ISBNDB, merges that information, and return something more complete than using them alone. It also saves that information in the database for future lookups.&lt;/p&gt;
    &lt;p&gt;You can see an example response here[1]. Pricing information for books is missing right now because I need to finish the extractor for those, genres need some work[2], and having a 5 months old baby make development a tad slow, but the service is almost ready for a preview.&lt;/p&gt;
    &lt;p&gt;The algorithm to decide what to merge is the hardest part, in my opinion, and very basic right now. It's based on a priority and score system for now, where different extractors have different priorities, and different fields have different scores. Eventually, I wanna try doing something with machine learning instead.&lt;/p&gt;
    &lt;p&gt;I'd also like to add book summaries to the data somehow, but I haven't figured out a way to do this legally yet. For books in the public domain I could feed the entire book to an LLM and ask them to write a spoiler-free summary of the book, but for other books, that'd land me in legal trouble.&lt;/p&gt;
    &lt;p&gt;Oh, and related books, and things of the sort. But I'd like to do that based on the information stored in the database itself instead of external sources, so it's something for the future.&lt;/p&gt;
    &lt;p&gt;Last time I posted about Shelvica some people showed interest in Librario instead, so I decided to make it something I can sell instead of just a service I use in Shelvica[3], hence why I'm focusing more on it these past two weeks.&lt;/p&gt;
    &lt;p&gt;[2]: In the example you'll see genres such as "English" and "Fiction In English", which is mostly noise. Also things like "Humor", "Humorous", and "Humorous Fiction" for the same book.&lt;/p&gt;
    &lt;p&gt;[3]: Which is nice, cause that way there are two possible sources of income for the project.&lt;/p&gt;
    &lt;p&gt;Working on https://JobBoardSearch.com a meta directory of job boards helping job site owners with their DR, visibility, jobs cross posting and promoting in general&lt;/p&gt;
    &lt;p&gt;Building a new layer of hyper-personalization over the web. Instead of generating more content, it helps you reformat and interact with what already exists, turning any page, paper, or YouTube video into a summary, mind-map, podcast, infographic or chat.&lt;/p&gt;
    &lt;p&gt;The broader idea is to make the web adaptive to how each person thinks and learns.&lt;/p&gt;
    &lt;p&gt;Working on an AI governance and security platform that gives security and GRC visibility into what AI tools people are actually using but also what is going into them.&lt;/p&gt;
    &lt;p&gt;It's a browser extension right now and the platform integrates with SSO providers and AI APIs, to help discover shadow AI, enforce policies and creates audit trails. Think observability for AI adoption but also Grammerly since we help coach endusers to better behavior/outcomes.&lt;/p&gt;
    &lt;p&gt;Early days but the problem is real, have a few design partners in the F500 already&lt;/p&gt;
    &lt;p&gt;An application that helps deaf and nonverbal individuals with daily interactions when they’re out and about.&lt;/p&gt;
    &lt;p&gt;My first career was in sales. And most of the time these interactions began with grabbing a sheet of paper and writing to one another. I think small LLMs can help here.&lt;/p&gt;
    &lt;p&gt;Currently making use of api’s but I think small models on phones will be good enough soon. Just completed my MVP.&lt;/p&gt;
    &lt;p&gt;AppGoblin is a free place to do app research for understanding which apps use which companies to monetize, track where data is sent and what kinds of ads are shown.&lt;/p&gt;
    &lt;p&gt;An open source campaign management app for TTRPGs. There are a ton out there, that are basically just fancy wikis. I'm working on one in Django for running my old school D&amp;amp;D game i'm starting back up this fall.&lt;/p&gt;
    &lt;p&gt;Camera Search (camerasearch.ai) is my iOS app for tradespeople and DIY users. It combines voice, video, image understanding, and chat—backed by tuned LLM API—to help diagnose issues and guide builds/repairs in realtime.&lt;/p&gt;
    &lt;p&gt;Currently running some finetuning experiments on non-verbal sounds to teach TTS how to laugh. I have had some success to add the necessary tags and tokens to multiple systems, but assembling the necessary dataset with sufficient quality is hard.&lt;/p&gt;
    &lt;p&gt;Working on securing software against backdoors and hidden exploits using a set of debloating tools. First one available here: github.com/negativa-ai/BLAFS&lt;/p&gt;
    &lt;p&gt;https://revise.io - a new word processor with live collaboration, git-like revision history, and an AI agent like Cursor.&lt;/p&gt;
    &lt;p&gt;Basically, an agentic platform for working with rich text documents.&lt;/p&gt;
    &lt;p&gt;I’ve been building this solo since May and having so much fun with it. I created a canvas renderer and all of the word processor interactions from scratch so I can have maximum control over how things are display when it comes to features like AI suggestions and other more novel features I have planned for the future.&lt;/p&gt;
    &lt;p&gt;a tool to help California home owners to lower their property taxes. This works for people who bought in the past years low interest environment and are overpaying in taxes because of that.&lt;/p&gt;
    &lt;p&gt;Feel free to email me, if you have questions: phl.berner@gmail.com&lt;/p&gt;
    &lt;p&gt;I just tried your app and after providing my email the analysis I get is for a completely different address than what I entered. I tried twice just to make sure the address i entered was right.&lt;/p&gt;
    &lt;p&gt;A little library to define functions in English (through LLM of course; for TypeScript initially) and use these functions like ordinary (async) functions (calling &amp;amp; be called). Agents as functions and multi-step concurrent orchestration of agents with event loops, if fanciness is in order.&lt;/p&gt;
    &lt;p&gt;And an agentic news digest service which scrapes a few sources (like HackerNews) for technical news and create a daily digest, which you can instruct and skew with words.&lt;/p&gt;
    &lt;p&gt;Any chance you'll take a look at power tools next?&lt;/p&gt;
    &lt;p&gt;There are some Amish people who rebuild Dewalt, Milwaukee etc battery packs. I'd like a repairable/sustainable platform where I can actually check the health of the battery packs and replace worn out cells as needed.&lt;/p&gt;
    &lt;p&gt;To give you an idea of the market, original batteries are about $149, and their knockoffs are around $100.&lt;/p&gt;
    &lt;p&gt;Very nice, looking forward to a deal with Décath' ;) How hard is it to make it compatible with the various motors when there is communication involved?&lt;/p&gt;
    &lt;p&gt;I've been wondering for a while if the display on ebikes could also be a more open and durable part of it.&lt;/p&gt;
    &lt;p&gt;trying to build some opportunity for the VR/XR community with https://vr.dev&lt;/p&gt;
    &lt;p&gt;right now, it’s a better way to showcase your really specific industry skills and portfolio of 3D assets (i.e., “LinkedIn for VR/XR) with hiring layered on&lt;/p&gt;
    &lt;p&gt;starting to add onto the current perf analysis tools and think more about how to get to a “lovable for VR/XR”&lt;/p&gt;
    &lt;p&gt;Working on https://run-phx.com ... a guide to trail running in the Valley of the Sun with notable routes, curated by actual human beings in the running community. (whoa)&lt;/p&gt;
    &lt;p&gt;Not earth shattering, but something that should exist.&lt;/p&gt;
    &lt;p&gt;I think getting a clear picture about what it is about yourself that needs work is actually a lot of the real work. Much of the rest of it is picking a direction and then living in that direction.&lt;/p&gt;
    &lt;p&gt;I have been trying to study Chinese on my own for a while now and found it very frustrating to spend half the time just looking for simple content to read and listen to. Apps and websites exist, but they usually only have very little content or they ramp up the difficulty too quickly.&lt;/p&gt;
    &lt;p&gt;Now that LLMs and TTS are quite good I wanted to try it out for languages learning. The goal is to create a vast number of short AI-generated stories to bridge the gap between knowing a few characters and reading real content in Chinese.&lt;/p&gt;
    &lt;p&gt;Curious to see if it is possible to automatically create stories which are comfortable to read for beginners, or if they sound too much like AI-slop.&lt;/p&gt;
    &lt;p&gt;I'm working on a card game for android, it's being built with Monogame and C#. It's just go fish at the moment, but I'm thinking of expanding it into a full suite of card games like solitaire and poker. The source is available on GitHub if anyone wants to poke around and perhaps collaborate. https://github.com/joshsiegl1/GoFishRefresh&lt;/p&gt;
    &lt;p&gt;A tool for threshold signing software releases that I eventually want to integrate with SigStore, etc. to help folks distribute their code-signing. https://github.com/soatok/freeon&lt;/p&gt;
    &lt;p&gt;-----&lt;/p&gt;
    &lt;p&gt;Want E2EE for Mastodon (and other ActivityPub-based software), so you can have encrypted Fediverse DMs? I've been working on the public key transparency aspect of this too.&lt;/p&gt;
    &lt;p&gt;It's an AI-webapp builder with a twist: I proxy all OpenAI API calls your webapp makes and charge 2x the token rate; so when you publish your webapp onto a subdomain, the users who use your webapp will be charged 2x on their token usage. Then you, the webapp creator, gets 80% of what's left over after I pay OpenAI (and I get 20%).&lt;/p&gt;
    &lt;p&gt;It's also a fun project because I'm making code changes a different way than most people are: I'm having the LLM write AST modification code; My site immediately runs the code spit out by the LLM in order to make the changes you requested in a ticket. I blogged about how this works here: https://codeplusequalsai.com/static/blog/prompting_llms_to_m...&lt;/p&gt;
    &lt;p&gt;I am still [0] working on trying to recover who I was before whatever -- a couple of years ago -- rendered me progressively unable to concentrate on anything.&lt;/p&gt;
    &lt;p&gt;Last month was an improvement. This month I can't concentrate for long and I distract very easily, but I seem to be able to do more with what I have, A small sense of ambition that I might be able to do bigger things, and might not need to drop out of tech and get a simple job, is returning.&lt;/p&gt;
    &lt;p&gt;I am trying to use this inhibited, fractured state to clarify thoughts about useless technology and distractions, and about what really matters, because (without wishing to sound haughty) I used to be unusually good at a lot of tech stuff, and now I am not. It is sobering but it is also an insight into what it might be like to be on the outside of technology bullshit, looking in.&lt;/p&gt;
    &lt;p&gt;I'm building an open source NAT traversal and networking framework called P2PD. Built from the ground up to allow things like multi-network interface applications, improved network programming in Python, and if people want it: an easy way to bypass NATs. The thing is: it depends on public servers for some of this which tends to change a lot, causing errors when they're all down.&lt;/p&gt;
    &lt;p&gt;What I'm building at the moment is a server monitoring solution for STUN, TURN, MQTT, and NTP servers. I wanted to allow the software for this to be portable. So I wrote a simple work queue myself. Python doesn't have linked-lists which is the data structure I'm using for the queues. They allow for O(1) deletes which you can't really get on many Python data structures. Important for work items when you're moving work between queues.&lt;/p&gt;
    &lt;p&gt;For the actual workers I keep things very simple. I make like 100 independent Python processes each with an event loop. This uses up a crap load of memory but the advantage is that you can parallel execution without any complexity. It would be extremely complex trying to do that with code alone and asyncio's event loop doesn't play well with parallelism. So you really only want one per process.&lt;/p&gt;
    &lt;p&gt;Result: simple, portable Python code that can easily manage monitoring hundreds of servers (sorry didnt mean for that to sound like chatgpt, lmao, incidental.) The DB for this is memory-based to avoid locking issues. I did use sqlite at first but even with optimizations there were locking issues. Now, I only use sqlite for import / export (checksums.)&lt;/p&gt;
    &lt;p&gt;yet another nvr (in python). also trying to make a switch for hpm style rocker light switches. these things are devilish. the switch requires a lot of force at a strange angle but i dont want to break it so knowing nothing about mechanical stuff ive had to learn about slip clutches, idling gears, worm gears, ratchet wheels. rack and pinions (ofc. from a hobbyist perspective). i know theres a switchbot and a fingerbot but neither of those will work with that type of switch unless you tape some sort of torque lever onto the light (which i dont want to do). its a rabbit hole :/&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45561428</guid><pubDate>Sun, 12 Oct 2025 20:09:14 +0000</pubDate></item><item><title>Emacs agent-shell (powered by ACP)</title><link>https://xenodium.com/introducing-agent-shell</link><description>&lt;doc fingerprint="35d78c5f8911c81d"&gt;
  &lt;main&gt;
    &lt;p&gt;Not long ago, I introduced acp.el, an Emacs lisp implementation of ACP (Agent Client Protocol), the agent protocol developed between Zed and Google folks.&lt;/p&gt;
    &lt;p&gt;While I've been happily accessing LLMs from my beloved text editor via chatgpt-shell (a multi-model package I built), I've been fairly slow on the AI agents uptake. Probably a severe case of old-man-shouts-at-cloud sorta thing, but hey I want well-integrated tools in my text editor. When I heard of ACP, I knew this was the thing I was waiting for to play around with agents.&lt;/p&gt;
    &lt;p&gt;With an early acp.el client library in place, I set out to build an Emacs-native agent integrationâ¦ Today, I have an initial version of agent-shell I can share.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;agent-shell&lt;/code&gt; is a native Emacs shell, powered by comint-mode (check out Mickey's comint article btw). As such, we don't have to dance between char and line modes to interact with things. &lt;code&gt;agent-shell&lt;/code&gt; is just a regular Emacs buffer like any other you're used to.&lt;/p&gt;
    &lt;p&gt;Thanks to ACP, we can now build agent-agnostic experiences by simply configuring our clients to communicate with their respective agents using a common protocol. As users, we benefit from a single, consistent experience, powered by any agent of our choice.&lt;/p&gt;
    &lt;p&gt;Configuring different agents from &lt;code&gt;agent-shell&lt;/code&gt; boils down which agent we want running in the comms process. Here's an example of Gemini CLI vs Claude Code configuration:&lt;/p&gt;
    &lt;code&gt;(defun agent-shell-start-gemini-agent ()
  "Start an interactive Gemini CLI agent shell."
  (interactive)
  (agent-shell--start
   :new-session t
   :mode-line-name "Gemini"
   :buffer-name "Gemini"
   :shell-prompt "Gemini&amp;gt; "
   :shell-prompt-regexp "Gemini&amp;gt; "
   :needs-authentication t
   :authenticate-request-maker (lambda ()
                                 (acp-make-authenticate-request :method-id "gemini-api-key"))
   :client-maker (lambda ()
                   (acp-make-client :command "gemini"
                                    :command-params '("--experimental-acp")
                                    :environment-variables (list (format "GEMINI_API_KEY=%s" (agent-shell-google-key)))))))
&lt;/code&gt;
    &lt;code&gt;(defun agent-shell-start-claude-code-agent ()
  "Start an interactive Claude Code agent shell."
  (interactive)
  (agent-shell--start
   :new-session t
   :mode-line-name "Claude Code"
   :buffer-name "Claude Code"
   :shell-prompt "Claude Code&amp;gt; "
   :shell-prompt-regexp "Claude Code&amp;gt; "
   :client-maker (lambda ()
                   (acp-make-client :command "claude-code-acp"
                                    :environment-variables (list (format "ANTHROPIC_API_KEY=%s" (agent-shell-anthropic-key)))))))
&lt;/code&gt;
    &lt;p&gt;I've yet to try other agents. If you get another agent running, I'd love to hear about it. Maybe submit a pull request?&lt;/p&gt;
    &lt;p&gt;While I've been relying on my acp.el client library, I'm still fairly new to the protocol. I often inspect traffic to see what's going on. After staring at json for far too long, I figured I may as well build some tooling around acp.el to make my life easier. I added a traffic buffer for that. From &lt;code&gt;agent-shell&lt;/code&gt;, you can invoke it via &lt;code&gt;M-x agent-shell-view-traffic&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Developing &lt;code&gt;agent-shell&lt;/code&gt; against paid agents got expensive quickly. Not only expensive, but my edit-compile-run cycle also became boringly slow waiting for agents. While I knew I wanted some sort of fake agent to work against, I didn't want to craft the fake traffic myself. Remember that traffic buffer I showed ya? Well, I can now save that traffic to disk and replay it later. This enabled me to run problematic sessions once and quickly replay multiple times to fix things. While re-playing has its quirks and limitations, it's done the job for now.&lt;/p&gt;
    &lt;p&gt;You can see a Claude Code session below, followed by its replayed counterpart via fake infrastructure.&lt;/p&gt;
    &lt;p&gt;Getting here took quite a bit of work. Having said that, it's only a start. I myself need to get more familiar with agent usage and evolve the package UX however it feels most natural within its new habitat. Lately, I've been experimenting with a quick diff buffer, driven by n/p keys, shown along the permission dialog.&lt;/p&gt;
    &lt;code&gt;#+ATTR_HTML: :width 99%
&lt;/code&gt;
    &lt;p&gt;While I've implemented enough parts of the Agent Client Protocol Schema to make the package useful, it's hardly complete. I've yet to fully familiarize myself with most protocol features.&lt;/p&gt;
    &lt;p&gt;Both of my new Emacs packages, agent-shell and acp.el, are now available on GitHub. As an agent user, go straight to agent-shell. If you're a package author and would like to build an ACP experience, then give acp.el a try. Both packages are brand new and may have rough edges. Be sure to file bugs or feature requests as needed.&lt;/p&gt;
    &lt;p&gt;I've been heads down, working on these packages for some time. If you're using cloud LLM services, you're likely already paying for tokens. If you find my work useful, please consider routing some of those coins to help fund it. Maybe my tools make you more productive at work? Ask your employer to support the work. These packages not only take time and effort, but also cost me money. Help fund the work.&lt;/p&gt;
    &lt;p&gt;powered by LMNO.lol&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45561672</guid><pubDate>Sun, 12 Oct 2025 20:37:16 +0000</pubDate></item><item><title>Edge AI for Beginners</title><link>https://github.com/microsoft/edgeai-for-beginners</link><description>&lt;doc fingerprint="2f0879180436a96a"&gt;
  &lt;main&gt;
    &lt;p&gt;Follow these steps to get started using these resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the Repository: Click&lt;/item&gt;
      &lt;item&gt;Clone the Repository: &lt;code&gt;git clone https://github.com/microsoft/edgeai-for-beginners.git&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Join The Azure AI Foundry Discord and meet experts and fellow developers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arabic | Bengali | Bulgarian | Burmese (Myanmar) | Chinese (Simplified) | Chinese (Traditional, Hong Kong) | Chinese (Traditional, Macau) | Chinese (Traditional, Taiwan) | Croatian | Czech | Danish | Dutch | Estonian | Finnish | French | German | Greek | Hebrew | Hindi | Hungarian | Indonesian | Italian | Japanese | Korean | Lithuanian | Malay | Marathi | Nepali | Norwegian | Persian (Farsi) | Polish | Portuguese (Brazil) | Portuguese (Portugal) | Punjabi (Gurmukhi) | Romanian | Russian | Serbian (Cyrillic) | Slovak | Slovenian | Spanish | Swahili | Swedish | Tagalog (Filipino) | Tamil | Thai | Turkish | Ukrainian | Urdu | Vietnamese&lt;/p&gt;
    &lt;p&gt;If you wish to have additional translations languages supported are listed here&lt;/p&gt;
    &lt;p&gt;Welcome to EdgeAI for Beginners – your comprehensive journey into the transformative world of Edge Artificial Intelligence. This course bridges the gap between powerful AI capabilities and practical, real-world deployment on edge devices, empowering you to harness AI's potential directly where data is generated and decisions need to be made.&lt;/p&gt;
    &lt;p&gt;This course takes you from fundamental concepts to production-ready implementations, covering:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small Language Models (SLMs) optimized for edge deployment&lt;/item&gt;
      &lt;item&gt;Hardware-aware optimization across diverse platforms&lt;/item&gt;
      &lt;item&gt;Real-time inference with privacy-preserving capabilities&lt;/item&gt;
      &lt;item&gt;Production deployment strategies for enterprise applications&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Edge AI represents a paradigm shift that addresses critical modern challenges:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Privacy &amp;amp; Security: Process sensitive data locally without cloud exposure&lt;/item&gt;
      &lt;item&gt;Real-time Performance: Eliminate network latency for time-critical applications&lt;/item&gt;
      &lt;item&gt;Cost Efficiency: Reduce bandwidth and cloud computing expenses&lt;/item&gt;
      &lt;item&gt;Resilient Operations: Maintain functionality during network outages&lt;/item&gt;
      &lt;item&gt;Regulatory Compliance: Meet data sovereignty requirements&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Edge AI refers to running AI algorithms and language models locally on hardware, close to where data is generated without relying on cloud resources for inference. It reduces latency, enhances privacy, and enables real-time decision-making.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;On-device inference: AI models run on edge devices (phones, routers, microcontrollers, industrial PCs)&lt;/item&gt;
      &lt;item&gt;Offline capability: Functions without persistent internet connectivity&lt;/item&gt;
      &lt;item&gt;Low latency: Immediate responses suited for real-time systems&lt;/item&gt;
      &lt;item&gt;Data sovereignty: Keeps sensitive data local, improving security and compliance&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLMs like Phi-4, Mistral-7B, and Gemma are optimized versions of larger LLMs—trained or distilled for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduced memory footprint: Efficient use of limited edge device memory&lt;/item&gt;
      &lt;item&gt;Lower compute demand: Optimized for CPU and edge GPU performance&lt;/item&gt;
      &lt;item&gt;Faster startup times: Quick initialization for responsive applications&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They unlock powerful NLP capabilities while meeting the constraints of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Embedded systems: IoT devices and industrial controllers&lt;/item&gt;
      &lt;item&gt;Mobile devices: Smartphones and tablets with offline capabilities&lt;/item&gt;
      &lt;item&gt;IoT Devices: Sensors and smart devices with limited resources&lt;/item&gt;
      &lt;item&gt;Edge servers: Local processing units with limited GPU resources&lt;/item&gt;
      &lt;item&gt;Personal Computers: Desktop and laptop deployment scenarios&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Module&lt;/cell&gt;
        &lt;cell role="head"&gt;Topic&lt;/cell&gt;
        &lt;cell role="head"&gt;Focus Area&lt;/cell&gt;
        &lt;cell role="head"&gt;Key Content&lt;/cell&gt;
        &lt;cell role="head"&gt;Level&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;📖 00&lt;/cell&gt;
        &lt;cell&gt;Introduction to EdgeAI&lt;/cell&gt;
        &lt;cell&gt;Foundation &amp;amp; Context&lt;/cell&gt;
        &lt;cell&gt;EdgeAI Overview • Industry Applications • SLM Introduction • Learning Objectives&lt;/cell&gt;
        &lt;cell&gt;Beginner&lt;/cell&gt;
        &lt;cell&gt;1-2 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;📚 01&lt;/cell&gt;
        &lt;cell&gt;EdgeAI Fundamentals&lt;/cell&gt;
        &lt;cell&gt;Cloud vs Edge AI comparison&lt;/cell&gt;
        &lt;cell&gt;EdgeAI Fundamentals • Real World Case Studies • Implementation Guide • Edge Deployment&lt;/cell&gt;
        &lt;cell&gt;Beginner&lt;/cell&gt;
        &lt;cell&gt;3-4 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;🧠 02&lt;/cell&gt;
        &lt;cell&gt;SLM Model Foundations&lt;/cell&gt;
        &lt;cell&gt;Model families &amp;amp; architecture&lt;/cell&gt;
        &lt;cell&gt;Phi Family • Qwen Family • Gemma Family • BitNET • μModel • Phi-Silica&lt;/cell&gt;
        &lt;cell&gt;Beginner&lt;/cell&gt;
        &lt;cell&gt;4-5 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;🚀 03&lt;/cell&gt;
        &lt;cell&gt;SLM Deployment Practice&lt;/cell&gt;
        &lt;cell&gt;Local &amp;amp; cloud deployment&lt;/cell&gt;
        &lt;cell&gt;Advanced Learning • Local Environment • Cloud Deployment&lt;/cell&gt;
        &lt;cell&gt;Intermediate&lt;/cell&gt;
        &lt;cell&gt;4-5 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;⚙️ 04&lt;/cell&gt;
        &lt;cell&gt;Model Optimization Toolkit&lt;/cell&gt;
        &lt;cell&gt;Cross-platform optimization&lt;/cell&gt;
        &lt;cell&gt;Introduction • Llama.cpp • Microsoft Olive • OpenVINO • Apple MLX • Workflow Synthesis&lt;/cell&gt;
        &lt;cell&gt;Intermediate&lt;/cell&gt;
        &lt;cell&gt;5-6 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;🔧 05&lt;/cell&gt;
        &lt;cell&gt;SLMOps Production&lt;/cell&gt;
        &lt;cell&gt;Production operations&lt;/cell&gt;
        &lt;cell&gt;SLMOps Introduction • Model Distillation • Fine-tuning • Production Deployment&lt;/cell&gt;
        &lt;cell&gt;Advanced&lt;/cell&gt;
        &lt;cell&gt;5-6 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;🤖 06&lt;/cell&gt;
        &lt;cell&gt;AI Agents &amp;amp; Function Calling&lt;/cell&gt;
        &lt;cell&gt;Agent frameworks &amp;amp; MCP&lt;/cell&gt;
        &lt;cell&gt;Agent Introduction • Function Calling • Model Context Protocol&lt;/cell&gt;
        &lt;cell&gt;Advanced&lt;/cell&gt;
        &lt;cell&gt;4-5 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;💻 07&lt;/cell&gt;
        &lt;cell&gt;Platform Implementation&lt;/cell&gt;
        &lt;cell&gt;Cross-platform samples&lt;/cell&gt;
        &lt;cell&gt;AI Toolkit • Foundry Local • Windows Development&lt;/cell&gt;
        &lt;cell&gt;Advanced&lt;/cell&gt;
        &lt;cell&gt;3-4 hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;🏭 08&lt;/cell&gt;
        &lt;cell&gt;Foundry Local Toolkit&lt;/cell&gt;
        &lt;cell&gt;Production-ready samples&lt;/cell&gt;
        &lt;cell&gt;Sample applications (see details below)&lt;/cell&gt;
        &lt;cell&gt;Expert&lt;/cell&gt;
        &lt;cell&gt;8-10 hrs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;01: REST Chat Quickstart&lt;/item&gt;
      &lt;item&gt;02: OpenAI SDK Integration&lt;/item&gt;
      &lt;item&gt;03: Model Discovery &amp;amp; Benchmarking&lt;/item&gt;
      &lt;item&gt;04: Chainlit RAG Application&lt;/item&gt;
      &lt;item&gt;05: Multi-Agent Orchestration&lt;/item&gt;
      &lt;item&gt;06: Models-as-Tools Router&lt;/item&gt;
      &lt;item&gt;07: Direct API Client&lt;/item&gt;
      &lt;item&gt;08: Windows 11 Chat App&lt;/item&gt;
      &lt;item&gt;09: Advanced Multi-Agent System&lt;/item&gt;
      &lt;item&gt;10: Foundry Tools Framework&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Comprehensive hands-on workshop materials with production-ready implementations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workshop Guide - Complete learning objectives, outcomes, and resource navigation&lt;/item&gt;
      &lt;item&gt;Python Samples (6 sessions) - Updated with best practices, error handling, and comprehensive documentation&lt;/item&gt;
      &lt;item&gt;Jupyter Notebooks (8 interactive) - Step-by-step tutorials with benchmarks and performance monitoring&lt;/item&gt;
      &lt;item&gt;Session Guides - Detailed markdown guides for each workshop session&lt;/item&gt;
      &lt;item&gt;Validation Tools - Scripts to verify code quality and run smoke tests&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What You'll Build:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local AI chat applications with streaming support&lt;/item&gt;
      &lt;item&gt;RAG pipelines with quality evaluation (RAGAS)&lt;/item&gt;
      &lt;item&gt;Multi-model benchmarking and comparison tools&lt;/item&gt;
      &lt;item&gt;Multi-agent orchestration systems&lt;/item&gt;
      &lt;item&gt;Intelligent model routing with task-based selection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Total Duration: 36-45 hours&lt;/item&gt;
      &lt;item&gt;Beginner Path: Modules 01-02 (7-9 hours)&lt;/item&gt;
      &lt;item&gt;Intermediate Path: Modules 03-04 (9-11 hours)&lt;/item&gt;
      &lt;item&gt;Advanced Path: Modules 05-07 (12-15 hours)&lt;/item&gt;
      &lt;item&gt;Expert Path: Module 08 (8-10 hours)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edge AI Architecture: Design local-first AI systems with cloud integration&lt;/item&gt;
      &lt;item&gt;Model Optimization: Quantize and compress models for edge deployment (85% speed boost, 75% size reduction)&lt;/item&gt;
      &lt;item&gt;Multi-Platform Deployment: Windows, mobile, embedded, and cloud-edge hybrid systems&lt;/item&gt;
      &lt;item&gt;Production Operations: Monitoring, scaling, and maintaining edge AI in production&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Foundry Local Chat Apps: Windows 11 native application with model switching&lt;/item&gt;
      &lt;item&gt;Multi-Agent Systems: Coordinator with specialist agents for complex workflows&lt;/item&gt;
      &lt;item&gt;RAG Applications: Local document processing with vector search&lt;/item&gt;
      &lt;item&gt;Model Routers: Intelligent selection between models based on task analysis&lt;/item&gt;
      &lt;item&gt;API Frameworks: Production-ready clients with streaming and health monitoring&lt;/item&gt;
      &lt;item&gt;Cross-Platform Tools: LangChain/Semantic Kernel integration patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Manufacturing • Healthcare • Autonomous Vehicles • Smart Cities • Mobile Apps&lt;/p&gt;
    &lt;p&gt;Recommended Learning Path (20-30 hours total):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;📖 Introduction (Introduction.md): EdgeAI foundation + industry context + learning framework&lt;/item&gt;
      &lt;item&gt;📚 Foundation (Modules 01-02): EdgeAI concepts + SLM model families&lt;/item&gt;
      &lt;item&gt;⚙️ Optimization (Modules 03-04): Deployment + quantization frameworks&lt;/item&gt;
      &lt;item&gt;🚀 Production (Modules 05-06): SLMOps + AI agents + function calling&lt;/item&gt;
      &lt;item&gt;💻 Implementation (Modules 07-08): Platform samples + Foundry Local toolkit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each module includes theory, hands-on exercises, and production-ready code samples.&lt;/p&gt;
    &lt;p&gt;Technical Roles: EdgeAI Solutions Architect • ML Engineer (Edge) • IoT AI Developer • Mobile AI Developer&lt;/p&gt;
    &lt;p&gt;Industry Sectors: Manufacturing 4.0 • Healthcare Tech • Autonomous Systems • FinTech • Consumer Electronics&lt;/p&gt;
    &lt;p&gt;Portfolio Projects: Multi-agent systems • Production RAG apps • Cross-platform deployment • Performance optimization&lt;/p&gt;
    &lt;code&gt;edgeai-for-beginners/
├── 📖 introduction.md  # Foundation: EdgeAI Overview &amp;amp; Learning Framework
├── 📚 Module01-04/     # Fundamentals → SLMs → Deployment → Optimization  
├── 🔧 Module05-06/     # SLMOps → AI Agents → Function Calling
├── 💻 Module07/        # Platform Samples (VS Code, Windows, Jetson, Mobile)
├── 🏭 Module08/        # Foundry Local Toolkit + 10 Comprehensive Samples
│   ├── samples/01-06/  # Foundation: REST, SDK, RAG, Agents, Routing
│   └── samples/07-10/  # Advanced: API Client, Windows App, Enterprise Agents, Tools
├── 🌐 translations/    # Multi-language support (8+ languages)
└── 📋 STUDY_GUIDE.md   # Structured learning paths &amp;amp; time allocation
&lt;/code&gt;
    &lt;p&gt;✅ Progressive Learning: Theory → Practice → Production deployment&lt;lb/&gt; ✅ Real Case Studies: Microsoft, Japan Airlines, enterprise implementations&lt;lb/&gt; ✅ Hands-on Samples: 50+ examples, 10 comprehensive Foundry Local demos&lt;lb/&gt; ✅ Performance Focus: 85% speed improvements, 75% size reductions&lt;lb/&gt; ✅ Multi-Platform: Windows, mobile, embedded, cloud-edge hybrid&lt;lb/&gt; ✅ Production Ready: Monitoring, scaling, security, compliance frameworks&lt;/p&gt;
    &lt;p&gt;📖 Study Guide Available: Structured 20-hour learning path with time allocation guidance and self-assessment tools.&lt;/p&gt;
    &lt;p&gt;EdgeAI represents the future of AI deployment: local-first, privacy-preserving, and efficient. Master these skills to build the next generation of intelligent applications.&lt;/p&gt;
    &lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MCP for Beginners&lt;/item&gt;
      &lt;item&gt;AI Agents For Beginners&lt;/item&gt;
      &lt;item&gt;Generative AI for Beginners using .NET&lt;/item&gt;
      &lt;item&gt;Generative AI for Beginners using JavaScript&lt;/item&gt;
      &lt;item&gt;Generative AI for Beginners&lt;/item&gt;
      &lt;item&gt;ML for Beginners&lt;/item&gt;
      &lt;item&gt;Data Science for Beginners&lt;/item&gt;
      &lt;item&gt;AI for Beginners&lt;/item&gt;
      &lt;item&gt;Cybersecurity for Beginners&lt;/item&gt;
      &lt;item&gt;Web Dev for Beginners&lt;/item&gt;
      &lt;item&gt;IoT for Beginners&lt;/item&gt;
      &lt;item&gt;XR Development for Beginners&lt;/item&gt;
      &lt;item&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/item&gt;
      &lt;item&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/item&gt;
      &lt;item&gt;Choose Your Own Copilot Adventure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you get stuck or have any questions about building AI apps, join:&lt;/p&gt;
    &lt;p&gt;If you have product feedback or errors while building visit:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45561700</guid><pubDate>Sun, 12 Oct 2025 20:41:01 +0000</pubDate></item><item><title>An initial investigation into WDDM on ReactOS</title><link>https://reactos.org/blogs/investigating-wddm/</link><description>&lt;doc fingerprint="4f899b575de63905"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;An initial investigation into WDDM on ReactOS&lt;/head&gt;&lt;p&gt;by The_DarkFire_ | October 7, 2025&lt;/p&gt;&lt;p&gt;The history of ReactOS spans a wider range than the lives of many of the people who work on it today. Incredible individuals have come and gone from the project with vastly different goals for what they want to see developed. In recent years, better hardware support has emerged as one of those goals. As ReactOS gazes towards the world of Vista and beyond, a few questions about how hardware works emerge. Vista introduced massive overhauls to how hardware drivers are written and maintained. Gradually weâre trying to handle many of these overhauls with great success. Today we talk about WDDM, or the Windows Display Driver Model.&lt;/p&gt;&lt;head rend="h3"&gt;The âOverhaulâ&lt;/head&gt;&lt;p&gt;Iâve always found the video driver documentation lacking for both architectures, enough to get started but not really enough to get deep into the world of 3D. Thankfully in recent years this has changed enough to where some open-source drivers have popped up. WDDM is a major overhaul that shifts responsibility of managing the GPU away from Win32k and gives better control over the GPU to the driver vendor. Dxgkrnl.sys, the DirectX graphics driver, talks to a miniport driver to provide varying levels of WDDM interfaces. The WDDM revision (WDDM 1.0, 1.1, 1.2â¦.) primarily describes how many of these interfaces are supported and implemented. This is different than the feature level that is described in DxDiag.&lt;/p&gt;&lt;head rend="h3"&gt;Waitâ¦ What happened to XDDM?&lt;/head&gt;&lt;p&gt;Officially starting with Windows 8, every GPU driver for the system had to be a WDDM driver. But all that was really dropped was the miniport driver. Vista and 7 could still load older GPU drivers using the XDDM architecture without complaint. Outside of the miniport driver, modern Windows still has XDDM remnants all over the place, including mechanisms for WDDM. The first example of this came when trying to load OpenGL installable client drivers (ICDs) from Vista, or loading our ICDs on Vista, 7, 8, and so on. For WDDM, the communication back to the miniport driver is more direct. Win32k only holds the syscall jump back into an interface thatâs filled in by Dxgkrnl. Itâs important to note the module that loads OpenGL ICDs hasnât changed very much.&lt;/p&gt;Interestingly Vulkan behaves similarly: OpenGL ICDs are one thing, but what about the display driver? Watching what Vista and later Win32k does while starting up shows some interesting behaviors. Thereâs two important display drivers we should talk about: TSDDD.dll and CDD.dll. TSDDD is manually loaded when session 0 starts. This is just a normal XDDM display driver that does nothing except write to blank memory. In NT5.x, or ReactOS at the time of writing, if your install canât get a valid display itâll bug check (BSoD) with a code meaning video initialization failure. Itâs possible to still make this happen with Vista and later but this failure no longer happens in practice due to CDD acting as the primary driver. In fact, if the video driver fails it’ll fall back to the basic display driver. CDD.dll is far more interesting: On one hand, it is an XDDM display driver. It also fires two I/O control codes (IOCTLs) which facilitates communication with WDDM. This driver is the only route which Dxgkrnl and Win32k use to talk to each other in any meaningful capacity. Technically, thereâs also some communication between watchdog, Win32k, and Dxgkrnl on initialization to fill in the interface to dispatch D3DKMT APIs for Dxgkrnl; but thatâs only during the initialization of Dxgkrnl itself. Itâs also worth noting, when this happens the query in Win32k to find a supported display adapter is always manually overwritten with cdd.dll. Once you start a WDDM driver you cannot run an XDDM driver at the same time! Alright that was a lot of information, but thereâs some important things to understand here. CDD.dll first and foremost IS an XDDM display driver, even if itâs translating from the old world Win32k to the new world WDDM stack itâs still stressing Win32k out. This means for ReactOS to be truly compatible with WDDM, our XDDM stack must be in great shape. This isnât the only Vista+ feature that has this requirement. DWM (which is worth its own blog post) does a lot of things that even the current ReactOS Win32k just isnât capable of handling quite yet. But we’re constantly improving.&lt;head rend="h3"&gt;Compiling WDDM drivers with ReactOS&lt;/head&gt;&lt;p&gt;One of the first components that needed to be understood was displib.lib, a component shipped with the WDK that allows for compiling WDDM drivers. https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/dispmprt/nf-dispmprt-dxgkinitializedisplayonlydriver In order to compile a WDDM driver, you need to link with a library that implements a function like the above to allow your driver to âstartâ Dxgkrnl. WDDM drivers donât link against Dxgkrnl at all! Instead, when you call an API like the one above, you pass data to Dxgkrnl, which then calls back into your miniportâs initialization routine. That callback is what provides the interfaces you need to continue communicating with Dxgkrnl. Win32k has nothing to do with the miniport driver starting up! This was relatively straightforward to make an alternative to, opening the door for ReactOS to import and compile WDDM drivers that work even on Windows!&lt;/p&gt;&lt;head rend="h3"&gt;WDDM! Technically..?&lt;/head&gt;&lt;p&gt;Now that we know how WDDM drivers start up, we can start thinking about how to support this architecture on ReactOS. The D3DKMT APIs are only used for DirectX and OpenGL acceleration so we can ignore that for now. What about just getting the display to work? ReactOS currently supports some 2D acceleration and is rapidly developing support for XDDM AMD GPUs so surely, we can get some kind of basis working? Dxgkrnl is a massive beast with a scheduler and many subsystems for managing these miniport drivers; but only two are really required for display management: VidPn (Video Presentation Network) and its hardware support. Starting with Windows 8 thereâs a built-in driver and style of WDDM miniports that drop 3D acceleration called KMDODâs. Theyâre a slightly different initialization type, but in general are easy to understand. Thankfully they donât use a lot of the interfaces DxgKrnl provides to miniport drivers to communicate with the hardware, so we can create a very simple Dxgkrnl for our experiment. All we need is to query the display modes from the VidPn network, pass it to CDD, load CDD when Dxgkrnl is active and … Ah hah!&lt;/p&gt;ReactOS can communicate with its first WDDM driver!&lt;head rend="h3"&gt;A more forgiving architecture&lt;/head&gt;&lt;p&gt;When I first got BasicDisplay.sys loading in ReactOS I noticed how forgiving WDDM truly was. I realized I could escalate this further than Iâd anticipated. It turned out these vendor drivers are very willing to accept being started just for their display for example.&lt;/p&gt;&lt;p&gt;I was quickly getting more drivers to show some kind of display out, allowing ReactOS to power modern monitors at their full resolutions and refresh rates. But I quickly was getting limited not by our implementation of Win32k but instead our support for hardware itself.&lt;/p&gt;&lt;head rend="h3"&gt;Why I wrote this and what’s to come&lt;/head&gt;&lt;p&gt;Thereâs two things I hoped to accomplish with this blog post. The first was to put out that ReactOS is indeed looking at trying to support later hardware, but that we canât just jump and ignore XDDM. XDDM is REQUIRED for WDDM, we need to continue to improve in this area. The other reason was because this is the first of a few blog posts I intend to write for the ReactOS project on this subject. Weâve been actively working to improve hardware support to unblock these future ideas and need more support to do so! To help support the ReactOS project, you can make a donation, contribute to the project on GitHub, or talk to your friends and family about us! We look forward to sharing more hardware support and WDDM blog posts.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45562188</guid><pubDate>Sun, 12 Oct 2025 21:40:43 +0000</pubDate></item><item><title>Free software hasn't won</title><link>https://dorotac.eu/posts/fosswon/</link><description>&lt;doc fingerprint="ee449113cc27a1bd"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a translated version of a talk I gave at P.I.W.O in June, with cleanups and adjustments for the blog form.&lt;/p&gt;
    &lt;head rend="h1"&gt;# Free Software hasn't won&lt;/head&gt;
    &lt;p&gt;â¦that doesn't sound right. I made the slides in Inkscape, on a computer running KDE and Linux, I use Firefox regularly. But maybe that's just me. What about you, are you using Free Software? Hands up! [hands go up in the audience] Of course! What nonsense, "Free Software hasn't won". Someone replaced my slides, hey conference staff!&lt;/p&gt;
    &lt;p&gt;**Staff:** *The other folder.*&lt;/p&gt;
    &lt;p&gt;[Browsing to a directory named "other folder", opening file called "your slides dimwit.pdf"]&lt;/p&gt;
    &lt;p&gt;Now, those are finally my slides.&lt;/p&gt;
    &lt;p&gt;Hello audience, my name is Dorota, and I'm going to talk about how&lt;/p&gt;
    &lt;head rend="h1"&gt;# Open Source has won.&lt;/head&gt;
    &lt;p&gt;And that's not recent, the news has been out in 2008, and has been regularly repeated since by reputable press: ZDNET, Linux Journal, Wired, and so on.&lt;/p&gt;
    &lt;p&gt;Those press articles list a multitude of examples to prove it.&lt;/p&gt;
    &lt;p&gt;Linux, Ruby, Red Hat, uh, GitHub? Does that mean I can download GitHub and run it on my own server? Microsoft? Come on, that's some kind of a joke. Those slides are manipulated! So what else do they contain? Oh, this quote is all right:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;&amp;gt; Open source won. Itâs not that an enemy has been vanquished or that proprietary software is dead, thereâs not much regarding adopting open source to argue about anymore. After more than a decade of the low-cost, lean startup culture successfully developing on open source tools, itâs clearly a legitimate, mainstream option for technology tools and innovation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Oh, the name of the quoted person is wrong. Looks like an attack on my reputation! Anyways.&lt;/p&gt;
    &lt;p&gt;The point is, if we want to build something new, using Free Software is not a hindrance. And thats super important, because software is eating the world. What does it mean? It means software keeps appearing in areas where there used to be no software before. That, in turn, means that we're slowly giving up control over more and more areas of life to those who made the software. After all, their software controls those areas of life from now on.&lt;/p&gt;
    &lt;p&gt;That's why it's great that there's always an alternative available, that we can select software that is free which grants control to us, and not just its manufacturer. So we have alternate operating systems made with Linux. There are very many programming languages to choose from. We can choose one of the open games, or graphics or audio creation software without resorting to closed software.&lt;/p&gt;
    &lt;p&gt;Similarly, we don't need closed software to print in 3D, or to build a mobile computer (also known as smartphone) or a smart watch. There are graphics cards which run completely free of closed firmware (Upon asking nouveau devs, they confirmed they wrote some firmware. Nvidia Kepler from 2012 is the last model where free firmware is allowed). There are such bicycles! Pretty much everyone owns one that rides without closed software. There are also sewing machines:&lt;/p&gt;
    &lt;p&gt;There are comms systems:&lt;/p&gt;
    &lt;p&gt;There are cars, and have been for a long time:&lt;/p&gt;
    &lt;p&gt;There are hard drives:&lt;/p&gt;
    &lt;p&gt;[the slides go blank]&lt;/p&gt;
    &lt;p&gt;There are wireless headphones, TVs... [slides remain blank] wait, something's wrong. There are phones! [Slides stay mockingly blank, noise of frantic clicking.]&lt;/p&gt;
    &lt;p&gt;[â¦]&lt;/p&gt;
    &lt;p&gt;[â¦]&lt;/p&gt;
    &lt;p&gt;[â¦]&lt;/p&gt;
    &lt;p&gt;Crap. This isn't right.&lt;/p&gt;
    &lt;p&gt;Oh, now I get it! The only kind of a phone that grants us openness is an analog phone. That reminds me of the time we were building the aforementioned Librem 5. There was a problem finding the modem for it. The reason is, one company controls the necessary patents necessary to connect to cellular networks. That company can and does impose arbitrary conditions on anyone using their integrated circuits. That made it very difficult to find modems that match our needs, and at the same time any reseller is willing to sell us. The resellers worried that by passing them on to us, they could break some distribution rule and not be able to get any modems in the future.&lt;/p&gt;
    &lt;p&gt;So that's a no. But I know what will be open for sure.&lt;/p&gt;
    &lt;p&gt;Richard Stallman started an important project called GNU in 1983. In one of his interviews, as he describes how he started the project, he mentions a certain device that his university bought, but which didn't work very well. He wanted to improve it, but no one wanted to share the device's sources with him. That was an offense! Why wouldn't anyone share the code?&lt;/p&gt;
    &lt;p&gt;What was that device?&lt;/p&gt;
    &lt;p&gt;That was a printer. Considering that the GNU project started in 1983 and that the story's from 1981, it works out to over 40 years of fighting for printer freedom. So let's reveal our open alternative.&lt;/p&gt;
    &lt;p&gt;Oh come on. This cannot be. Have you ever used a printer? If you even manage to find a driver, if you even manage to connect to the printer, then it's still going to print single-sided black-and-white when you asked double-sided color. And despite having to put up with that, Free Software people still haven't gotten frustrated enough to solve the problem once and for all? Unbelievable.&lt;/p&gt;
    &lt;p&gt;I have a theory. People who say "Open Source has won" are only taking into account a small part of what software is out there. Take a look at this list: it's a map showing which kinds of software force you into running something closed (bold) and which have open options available (italics).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Applications: *Blender, Firefox, KiCAD* â **Twitter, YouTube**&lt;/item&gt;
      &lt;item&gt;Operating System: *GCC, Apache, OpenSSL*&lt;/item&gt;
      &lt;item&gt;Kernel: *Linux, Zephyr, FreeRTOS*&lt;/item&gt;
      &lt;item&gt;Firmware: *Coreboot* â **modem, GPU**&lt;/item&gt;
      &lt;item&gt;Appliances: *Prusa 3D, Airgradient* â **washing machine, TV**&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What picture does this paint? Things programmers care about directly, like the OS and the kernel, are quite well covered. Whatever we need, there's an open version. Applications are also more or less fine. There's a Web browser, there's creativity software. The problem appears when you try to participate in social media. Sure, there are alternatives. But Mastodon, or PeerTube are separate networks from the closed ones, so they won't help much when trying to reach people who aren't yet using them.&lt;/p&gt;
    &lt;p&gt;Looking at the lower layers, like appliances or firmware, there seem to be options. But those options are limited to a couple niches, and with most things we buy, like a TV or a PC component â sorry, pal, there's simply no choice at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;## All the firmwares in the average laptop&lt;/head&gt;
    &lt;p&gt;How many processors are there in a typical laptop? By "processor" I mean something that needs its own software. For example, a GPU has its own processor that needs software, or a hard drive, or a keyboard. Here's a diagram of my personal estimate of what separate components need software:&lt;/p&gt;
    &lt;p&gt;I estimate there are 10 to 15 separate processors on a typical laptop. Just the graphics card may host five of them.&lt;/p&gt;
    &lt;p&gt;What does that mean for free software? Normally, all that's open â Linux, drivers, applications â all of this is confined to the main CPU. Now imagine you want to use this operating system through some human-friendly interface, like the touch screen or the keyboard. Those are running closed software, so if you want to enter any sort of data on your average laptop, it's game over: you can't make a move without dependence on closed software.&lt;/p&gt;
    &lt;p&gt;Same story with the graphics card. You won't display anything without closed software. What a fail. Okay, let's ditch keyboards and displays because this is a server. But that's a fail, too: to communicate over a network card, you still need software that it's running and that hasn't been opened. Suppose that we managed to somehow solve this problem. We hit the wall anyway when we try to store data: SSDs as well as HDDs are running their own closed software. I haven't heard of a single case of open software ever running on a storage device!&lt;/p&gt;
    &lt;p&gt;But that's not even the worst. The peak of lameness is the processor inside the processor. Have you already heard of Secure Boot? It's a piece of BIOS that is loaded onto the processor inside the main processor before the main operating system. Secure Boot allows the manufacturer choose which software the user can run. A similar system exists on Android phones to lock them to a particular system. Manufacturers of Android-based phones are not shy about restricting what the user can run on their devices.&lt;/p&gt;
    &lt;head rend="h2"&gt;## That runs against user's freedom!&lt;/head&gt;
    &lt;p&gt;User freedom exists only when the Four Freedoms of Software are upheld:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0: freedom to run the program for any purpose,&lt;/item&gt;
      &lt;item&gt;1: to study and change it,&lt;/item&gt;
      &lt;item&gt;2: to share copies of it,&lt;/item&gt;
      &lt;item&gt;3: to improve it and share the improvements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;â¦but those are just words. Who cares about that? This theory is only ever going to be relevant to us computer experts, right?&lt;/p&gt;
    &lt;p&gt;Exceptâ¦ could it be that you're the family's tech support expert? Does your uncle/mum/grandma come to you carrying their malfunctioning Android phone, hoping for you to make everything right again?&lt;/p&gt;
    &lt;p&gt;And have you ever disappointed them? Has it already happened that their phone was simply too old and unsupported to be useful any more? Have you already told someone they need to pay up to replace a phone that seems perfectly functional?&lt;/p&gt;
    &lt;p&gt;Sadly, that's what the Android manufacturer support timelines say: typically after 4, exceptionally after 8 years, they will no longer release security updates. That makes devices too insecure to use, and turns them into e-waste.&lt;/p&gt;
    &lt;p&gt;What does Free Software have to do with it? I don't know, but my Lenovo laptop, 13 years since release of the hardware, the operating system is still receiving regular security updates. I suspect this has something to do with the lack of a boot loader lock and the openness of all the drivers. That's unlike Android. Even if there's no explicit lock, the drivers are so rarely open that the community rarely has the manpower to create a custom ROM for a given device.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Rug pulls&lt;/head&gt;
    &lt;p&gt;The couple hundred bucks that your aunt might need to pony up to get a new phone pale in comparison to how much you need to pay for some cloud-only devices. Some cloud-enabled gadgets don't let the user choose an alternative provider for services the device requires. What happens when the company shuts down the online service? Of course, the device becomes an expensive brick. Imagine someone setting your 2300 bucks on fire just like that.&lt;/p&gt;
    &lt;p&gt;That's still nothing compared to what some other people have to deal with. Imagine you're a farmer, and your harvest is on the field, ready to get cut and brought in. T here's a storm brewing, so you jump into the combine harvester, and start the work. Oh no! The machine broke down! Not to worry, you're a resourceful farmer and you have the necessary spare part. You install it and start the machine, exceptâ¦ it tells you: "Unauthorized component. Please contact customer service". Now you're in real trouble because it could take 9 months for the customer service to solve the problem. You can't harvest the food worth tens of thousands of dollars, you're that much in the red. Game over, your farm is bankrupt. But that's not the end of the world, is it?&lt;/p&gt;
    &lt;p&gt;This is what a pacemaker looks like. Why would I mention those in a talk about software freedom? You see, a pacemaker is a complex device which must examine and diagnose the patient continuously, in real time, in order to perform its function. Its task is to detect a dangerous condition and perform a medical procedure in response to it. It needs software to do this complicated task. But if the device isn't perfect at diagnosing, that's a big problem. I'm not a medical expert, but getting your heart shocked when it's not necessary sounds dangerous in its own right. When it runs closed software that does not grant us the freedom to modify it, we have to resort to begging the manufacturer to fix it. And when we get no freedom to study it, we can't even avoid the circumstances that make it misfire!&lt;/p&gt;
    &lt;p&gt;But don't take my word for it. I only know of this problem because of Karen Sandler, whose involvement with Free Software is intertwined with this problem since the beginning.&lt;/p&gt;
    &lt;p&gt;The bottom line is, if we have people who have no other choice but to trust their own body to a piece of closed software and a single manufacturer, how could we possibly say that Open Source had won?&lt;/p&gt;
    &lt;head rend="h2"&gt;## Appliances and copyleft&lt;/head&gt;
    &lt;p&gt;Are you responsible for building an appliance? I bet you're using Open Source software in it, aren't you? Then licenses like the MIT require you to include a notice about the authors of the source code together with the software you distribute. There's a whole gallery of those on the curl website, ranging from cars to food processors. Are you feeling proud for releasing a device with Free Software in it? Not so quick! Can the user of your device study and modify the software you gave them? Have you actually granted them the Four Freedoms?&lt;/p&gt;
    &lt;p&gt;Permissive licenses like the MIT license are Free Software, so they let you do all that the Four Freedoms promise. But they also allow you to do another thing: to close the software again by never granting those freedoms regarding your own modifications. If that's what happened, then freedom for me, not for thee. You, the manufacturer, reaped the benefits, the user can't, sucks to be the user.&lt;/p&gt;
    &lt;p&gt;The responsibility to prevent this falls on us, computer experts. When we create software, we have the choice of license we want to release it under. And we should be using what's called "copyleft": it's a term that applies to licenses which prevent code once released under that license from being closed again. The most widespread copyleft license is the Gnu General Public License (GPL), and I recommend that you all use that one.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Licenses and more&lt;/head&gt;
    &lt;p&gt;Licenses are not the only thing relevant for Free Software. There are other things to fight:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;patents, like in the case of cellular modems,&lt;/item&gt;
      &lt;item&gt;hardware locks, like Android's,&lt;/item&gt;
      &lt;item&gt;project management.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As for the last point, recently Google gave an amazing example by restricting access to sources in development to select manufacturers. Everyone else will not get continuous updates, but only once per major release. This illustrates how much influence over the practical usability of a project management decisions have. This is not a change in licensing, and it's also not a technical change, so it's not immediately visible under those lenses.&lt;/p&gt;
    &lt;p&gt;Instead, it's a consequence of who's in charge. In this case, it's not a community who controls the Android project, but a for-profit corporation. At the same time, it's regular people who are on the user side of the project. Is it any wonder that the goals of a corporation and those of regular people differ? Is it any wonder that the corporation is making changes that suit it even when they don't suit the community of users? When those are the conditions under which a project is developed, it can have deep consequences, even on an architectural level.&lt;/p&gt;
    &lt;p&gt;Take Debian as a point of comparison. The first statement on the web page already says "Debian is a Community of People!". The software is being developed and used by the same people. They won't make it harder to use. They provide a complete operating system, publish all the sources, and purge anything that isn't open enough. On the other hand, Android has long been replacing open components by closed ones, making AOSP (the open part of android) all but unuseable on its own.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Why?&lt;/head&gt;
    &lt;p&gt;I suspect this situation has something to do with how computers and appliances have been developed historically. Computers have their roots in academia. When they were sold, they were always advertised as blank slates, general purpose devices, as opportunities to do what you choose to do with them. Not so much for appliances. Those have always had a single purpose. Except they kept getting complicated, until they entered a level of complexity where they needed to incorporate computers in order to perform their function. But they kept being manufactured as appliances, with only a handful of people being expected or allowed to exercise control over them. Incorporating computers didn't change the culture around them.&lt;/p&gt;
    &lt;p&gt;This is just a guess and I don't know how correct it is. For example Apple was always a computer manufacturer, but they are making computers now as if those were appliances.&lt;/p&gt;
    &lt;head rend="h2"&gt;## What now?&lt;/head&gt;
    &lt;p&gt;The responsibility is ours â computer nerds' â to make Free Software win. When we build a hardware device, we must publish the firmware sources. We must publish technical documentation â it often so happens that the device documentation needed to make open firmware is missing or incomplete (another war story from the Librem 5, camera sensors this time).&lt;/p&gt;
    &lt;p&gt;As users, or institutional customers, we should demand that the manufacturer provides open sources for any firmware they are shipping with their devices.&lt;/p&gt;
    &lt;p&gt;But there's one more way: political pressure. I expect this to be a more effective method than individual action. After all, EU managed to convince phone manufacturers to standardize on USB-C ports for charging, as well as to extend the warranty period. Perhaps they could also force computer manufacturers to not install boot loader locks. It would fit nicely into the Information Society Directive. It says things like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;&amp;gt; Member States must provide legal protection against any person knowingly performing without authority any of the following acts:&lt;/p&gt;
      &lt;item&gt;&amp;gt; the removal or alteration of any electronic rights-management information;&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;â¦oh. So instead of jailing people who put locks on devices they no longer own, it enforces the jailing of those who remove them from their own devices. Great.&lt;/p&gt;
    &lt;p&gt;Dear European Comission, please always have someone with a clue in the room who can explain the consequences of your ideas in a way you can understand. You can do it, already did a couple times, like above. But work on consistency, okay? Pinky promise?&lt;/p&gt;
    &lt;p&gt;Here are some people with a clue: Free Software Foundation Europe with their Public Money Public Code open letter, the Right to Repair movement, as well as the European Pirate Party.&lt;/p&gt;
    &lt;p&gt;I recommend anyone who cares to join forces with them. But if you don't want to engage politically, there are also financial way of support. And I don't even mean (although I do encourage) donating. I mean supporting Free Software friendly manufacturers! Buy the Librem 5 from Purism, or a 3D printer from Prusa, or a smartwatch running Espruino. You see, it's expensive to manufacture any sort of hardware. It doesn't help that the markets are already saturated with closed products. Even if open source, hackable products are superior, it will take people at large a long time to realize that this is a superpower. Free Software thrived in culture of repair and modification. But this culture has been suffocated in the wider society with closed, throwaway items, so few people recognize its benefits. That unsustainable crowding out makes another obstacle for Open Source friendly products in the current markets.&lt;/p&gt;
    &lt;p&gt;There's a noble exception here. What makes it even more unusual is that it comes from Google. It's Chromebooks. Google has a set of requirements that all Chromebook manufacturers must fulfill, and one of them is having a completely open BIOS, together with the Embedded Controller firmware. All Chromebooks I'm aware of run Coreboot. They still contain some closed software, notably the RAM startup software, which, I believe, is present in all laptops, but! ARM-base Chromebooks are able to run with a completely open BIOS apart from that. So if anyone wants to take care of this together with me, I have this NLNet project to make it as easy as possible to run regular, mainline Linux on them. So please, contact me, if you're that person.&lt;/p&gt;
    &lt;head rend="h2"&gt;## The world&lt;/head&gt;
    &lt;p&gt;A short quiz: how many devices can you count around you which contain processors?&lt;/p&gt;
    &lt;p&gt;Some hints: TV, camera, toothbrush, oscilloscope, e-book reader, radio receiver, dishwasher, router, washing machine, vacuum cleaner, bathroom scales.&lt;/p&gt;
    &lt;p&gt;Now think wider. When I went to the supermarket, the vegetable section had a scales that printed labels with barcodes. They were equipped with touch screens. You bet there's a processor and a load of firmware in those. But shops are chock-full of processors in my part of the world. There are thousands of price labels in each of those stores, and they are all e-paper screens. I'm fairly sure you need software to drive those and receive wireless updates.&lt;/p&gt;
    &lt;p&gt;Keep going and you might realize that the software running in your car allows remote control. Or in your train. That snafu wouldn't have occured if the railways had access to sources of the train software.&lt;/p&gt;
    &lt;p&gt;What about other business uses? Car diagnostic stations? Medical equipment? Accounting software?&lt;/p&gt;
    &lt;p&gt;Software is really eating the world, and it's closed software which is *everywhere* around us, without free options. What's the regular person's role in this? They give up control over entire areas of their lives to others, others who often can't be supervised or replaced.&lt;/p&gt;
    &lt;p&gt;You know, we messed up. There's no other way to put it. We even let closed software sneak into our own home field: computers. Sure, the interfaces are open. There's SATA, there's PCI. We can swap parts if we want to, we can run Linux there, all is fine. Except it's not, because peripherals are as important as the core, and we, software people, lost control of the peripherals of our darlings already.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Wasted potential&lt;/head&gt;
    &lt;p&gt;In theory, it's possible that someone opens a piece of software regardless of the wishes of the original authors. The whole game modding scene is about that. Here's an example of someone running Tetris on a pocket camera:&lt;/p&gt;
    &lt;p&gt;But going against the manufacturer is just wasted work. Imagine the difference between hacking it in and modifying the official sources. The potential, things we could achieve if we didn't have to break doors that are open! So here's a silly example: I have an action camera. Due to some stupid law, the camera breaks off every recording as soon as it reaches the 30 minutes mark. Now I have 20 years of coding experience. Having source code, I could have fixed the problem and went on with my life. Another example, another camera: I am making a time lapse from my window. Every day at 10:00, I take a picture from a camera that just sits there. But this camera has no time lapse feature, so I must go there in person every time. Why can't I fix this? Of course, no source code.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Epilogue&lt;/head&gt;
    &lt;p&gt;There's now a new printer project that advertises itself as open source. But if you look at the details, it's actually not. Instead, it uses a source-available license which does not grant you Freedom 0 â you must not use the sources for commercial purposes. Better than nothing, I guess.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45562286</guid><pubDate>Sun, 12 Oct 2025 21:51:45 +0000</pubDate></item><item><title>Wall Street is worried the private credit bubble will burst</title><link>https://www.thetimes.com/business-money/economics/article/wall-street-first-brands-private-credit-bubble-risk-363q2tcds</link><description>&lt;doc fingerprint="a80a1d540db43670"&gt;
  &lt;main&gt;
    &lt;p&gt;The sudden unravelling of an American manufacturer of car parts has rung alarm bells on Wall Street about risky lending in private debt markets.&lt;/p&gt;
    &lt;p&gt;First Brands, which has borrowed billions of dollars in private markets, filed for Chapter 11 protection on Sunday night in the Southern District of Texas. Court filings disclosed total liabilities of $11.6 billion, including about $9.3 billion of debt obligations.&lt;lb/&gt;Analysts are calling it a “free fall bankruptcy” because the company is entering bankruptcy with no plan.&lt;/p&gt;
    &lt;p&gt;The Ohio-based business, which makes windscreen wipers, fuel pumps and spark plugs, is owned and run by Patrick James, a Malaysian-born businessman with a limited public profile. It has long used an opaque financing method known as factoring, which allowed it to borrow against future cash flows.&lt;/p&gt;
    &lt;p&gt;Yet it had managed to secure financing from dozens of the world’s biggest private investment firms, including PGIM, UBS and Invesco, as it issued loan facilities with attractive returns to fund its acquisition of auto parts brands.&lt;/p&gt;
    &lt;p&gt;Only months earlier, First Brands, like Tricolor Holdings, a subprime auto lender that also filed for bankruptcy in September, had received strong credit ratings.&lt;/p&gt;
    &lt;p&gt;The financial distress the company now finds itself in can be traced back to early August, when it was seeking to raise another $6 billion in loans. Through that process, investors started to raise questions about the numbers being presented.&lt;/p&gt;
    &lt;p&gt;In early September it was reported that Apollo Global Management had amassed a short position against the debt of First Brands Group, meaning that it stood to profit if the auto parts maker failed to continue paying its debt.&lt;/p&gt;
    &lt;p&gt;The news caused a rush for the exit and the value of its debt started collapsing, before a bankruptcy process was initiated to bring some order to what appeared to have become the equivalent of a bank run. First Brands said that its Chapter 11 cases pertain solely to US operations and it expects its global operations to continue uninterrupted.&lt;/p&gt;
    &lt;p&gt;John Bringardner, head of restructuring at New York-based Debtwire, said: “This will be a messy, expensive bankruptcy, with a lot of players involved, and a lot of people are going to be second guessing choices they’ve made in the past few months on this name.”&lt;/p&gt;
    &lt;p&gt;He expects First Brands’ troubles to lead to big Wall Street players closely reviewing their investments to reassess risk.&lt;/p&gt;
    &lt;p&gt;Bringardner said the issue for investors was one of transparency. “It’s not necessarily a liquid market, like a big public bond that you can pretty easily trade in or out of, [where] you have public reporting, you can look at the financials, you can question them … Versus these kinds of off balance sheet private debt facilities that tend to be more illiquid, there’s really little to no disclosure.”&lt;/p&gt;
    &lt;p&gt;• Aviva steers more pension savings into private markets&lt;/p&gt;
    &lt;p&gt;It comes amid concerns about the boom in lending by money managers rather than banks, known as “private credit”, which has grown significantly since the global financial crisis as increased regulations and capital requirements made it more challenging for traditional banks to issue certain types of loans.&lt;/p&gt;
    &lt;p&gt;On Monday, Fitch Ratings warned that the private credit sector is exhibiting “bubble-like” attributes, including rapid growth and financial innovation, spread compression, heightened competition, growing retail participation and rising borrower leverage.&lt;/p&gt;
    &lt;p&gt;Fitch said the risks were not yet systemic because private credit is still a relatively small portion of the overall financial system. However, the ratings agency said that in the event of a shock like interest rate volatility or rising margin calls, the private credit sector could be exposed to losses and elevated redemptions, with a broad range of investors exposed.&lt;/p&gt;
    &lt;p&gt;• Is simmering dread over the private credit boom justified?&lt;/p&gt;
    &lt;p&gt;Analysts are waiting for First Brands to release more details in court filings about how it got into this position before they fully assess the potential contagion risk. In its latest filings, the company said it believes it had an unpaid $2.3 billion hole on its balance sheet related to third-party factoring arrangements when it filed for Chapter 11 proceedings. &lt;lb/&gt;A special committee of First Brands independent directors is investigating whether the company’s receivables may have been factored more than once.&lt;/p&gt;
    &lt;p&gt;Questions will include how First Brands’ complex financing structures may have hidden the extent of its leverage, the due diligence of private lenders and whether they ignored any red flags, and the impact of higher tariff-related costs.&lt;/p&gt;
    &lt;p&gt;For investors, the concern is that the troubles at the auto car parts maker may be a sign of further distress in debt markets to come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45562959</guid><pubDate>Sun, 12 Oct 2025 23:18:04 +0000</pubDate></item><item><title>Novelty Automation</title><link>https://www.novelty-automation.com/</link><description>&lt;doc fingerprint="ff25a85d0f9f504e"&gt;
  &lt;main&gt;
    &lt;p&gt;A collection of satirical home-made arcade machines (twinned with 'The Under The Pier Show', Southwold pier)&lt;/p&gt;
    &lt;p&gt;Only 5 minutes walk from Holborn tube station&lt;/p&gt;
    &lt;p&gt;August Bank Holiday open Monday Aug 25th 11-6&lt;/p&gt;
    &lt;p&gt;Normal opening hours: Open every day except Mondays, 11am to 6pm, with late opening on Thursday 12-8pm and 12-6pm on Sundays. 1a Princeton St London, WC1R 4AX&lt;/p&gt;
    &lt;p&gt;Next First Thursday bar evening Nov 6th, 5-9pm&lt;/p&gt;
    &lt;p&gt;Introduction&lt;/p&gt;
    &lt;p&gt;Machines on display&lt;/p&gt;
    &lt;p&gt;Latest machine&lt;/p&gt;
    &lt;p&gt;Video&lt;/p&gt;
    &lt;p&gt;Corporate &amp;amp; Party hire&lt;/p&gt;
    &lt;p&gt;In praise of coin operated machines&lt;/p&gt;
    &lt;p&gt;A short history of arcades&lt;/p&gt;
    &lt;p&gt;The perfect gift. Have a bag of gold delivered by post&lt;/p&gt;
    &lt;p&gt;Latest reviews in our visitors book&lt;/p&gt;
    &lt;p&gt;Prices, Directions &amp;amp; Disabled access&lt;/p&gt;
    &lt;p&gt;Reviews&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Links&lt;/p&gt;
    &lt;p&gt;Contact&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45563161</guid><pubDate>Sun, 12 Oct 2025 23:46:55 +0000</pubDate></item><item><title>John Searle has died</title><link>https://www.nytimes.com/2025/10/12/books/john-searle-dead.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45563627</guid><pubDate>Mon, 13 Oct 2025 00:57:49 +0000</pubDate></item><item><title>For centuries massive meals amazed visitors to Korea (2019)</title><link>https://www.atlasobscura.com/articles/history-of-korean-food</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45563900</guid><pubDate>Mon, 13 Oct 2025 01:46:18 +0000</pubDate></item><item><title>Despite what's happening in the USA, renewables are winning globally</title><link>https://thebulletin.org/2025/10/despite-whats-happening-in-the-usa-renewables-are-winning-globally/</link><description>&lt;doc fingerprint="283e815c2bb65d9a"&gt;
  &lt;main&gt;
    &lt;p&gt;By Zoya Teirstein | October 11, 2025&lt;/p&gt;
    &lt;p&gt;Editor’s note: This story was originally published by Grist. It appears here as part of the Climate Desk collaboration.&lt;/p&gt;
    &lt;p&gt;If you live in the United States, you could be forgiven for thinking that renewable energy is on the outs. In July, Congress voted to rapidly phase out longstanding tax credit support for wind and solar power, and the Trump administration has taken seemingly every step in its power to halt the development of individual wind and solar projects—even as domestic electricity demand rises and new sources of electricity become more important than ever.&lt;/p&gt;
    &lt;p&gt;But even as clean energy deployment hit roadblocks in the United States, the world overall set a new record for renewable energy investment over the first half of this year. Wind and solar power are meeting and even exceeding a global rise in energy demand. Indeed, electricity output from these sources is increasing faster than the world can use it, displacing some fossil fuel-generated power in the process. That’s according to a report published Tuesday by Ember, a global energy think tank, which mapped this year’s global power supply by analyzing monthly data from 88 countries that are responsible for more than 90 percent of global electricity demand.&lt;/p&gt;
    &lt;p&gt;“Overall—we’re talking globally—renewables overtook coal,” said Malgorzata Wiatros-Motyka, a senior electricity analyst at Ember and a co-author of the company’s report. “And I expect this to hold.” This year marks the first time that renewable energy sources have outpowered coal in the global energy mix. In fact, global use of fossil fuels for electricity actually declined slightly, compared to the same period in 2024.&lt;/p&gt;
    &lt;p&gt;Another report published this week by the International Energy Agency, or IEA, an intergovernmental energy research and policy organization, projects that the quantity of installed renewable power—meaning the maximum amount of energy that can be produced by systems like solar fields, hydroelectric dams, and wind turbines—will more than double by the end of this decade. National policies encouraging the development of green technology as well as astounding drops in the price of solar power—primarily driven by Chinese manufacturers, which build more than 80 percent of the world’s solar energy components—are largely driving the transition.&lt;/p&gt;
    &lt;p&gt;And even that projection may be conservative.&lt;/p&gt;
    &lt;p&gt;“The IEA has, consistently over the last couple of decades, way underestimated how fast renewables are growing,” said Robert Brecha, a senior climate and energy adviser at Climate Analytics, a global climate science and policy institute, who was not involved in either the Ember or IEA report. “I don’t see any reason to believe that renewables won’t double by 2030.”&lt;/p&gt;
    &lt;p&gt;The vast majority of the renewable energy projected to go online in the coming years will come from solar, which already met more than 80 percent of new global energy demand in the first six months of 2025, according to the Ember report. In China, the largest renewable energy growth market in the world, and in India, which is on pace to become the second-largest market, a major uptick in solar energy output is responsible for a historic global decline in coal-generated power.&lt;/p&gt;
    &lt;p&gt;In the United States and the European Union, however, fossil fuel generation rose in the first half of this year. In Europe, poor wind conditions and drought, rather than state policies, took a bite out of the bloc’s wind and hydroelectric production, leading to a 14-percent rise in gas-fired power. Across the Atlantic, US coal-fired power generation rose 17 percent.&lt;/p&gt;
    &lt;p&gt;The policy outlook for renewables in the United States is so bleak that the IEA lowered the country’s renewable capacity growth expectations by 50 percent compared to last year’s projections. That US-driven dip drags down the agency’s global projections for renewable energy growth by 5 percent. Overall, however, the IEA still expects renewable energy capacity to grow even faster between 2025 and 2030 than it did between 2020 and 2025.&lt;/p&gt;
    &lt;p&gt;“They can slow it down; they can do a lot more damage than I thought they could,” said Brecha, referring to the Trump administration’s efforts to slow the growth of renewable energy. “But they can’t stop it.”&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;The Bulletin elevates expert voices above the noise. But as an independent nonprofit organization, our operations depend on the support of readers like you. Help us continue to deliver quality journalism that holds leaders accountable. Your support of our work at any level is important. In return, we promise our coverage will be understandable, influential, vigilant, solution-oriented, and fair-minded. Together we can make a difference.&lt;/p&gt;
    &lt;p&gt;Keywords: Trump, climate change, climate crisis, fossil fuels, global warming, renewable energy, solar, wind&lt;lb/&gt; Topics: Climate Change&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45564077</guid><pubDate>Mon, 13 Oct 2025 02:15:25 +0000</pubDate></item></channel></rss>