<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 30 Dec 2025 19:09:49 +0000</lastBuildDate><item><title>Hacking Washing Machines [video]</title><link>https://media.ccc.de/v/39c3-hacking-washing-machines</link><description>&lt;doc fingerprint="b41e325c1ac906ec"&gt;
  &lt;main&gt;
    &lt;p&gt;Severin von Wnuck-Lipinski and Hajo Noerenberg&lt;/p&gt;
    &lt;p&gt;Almost everyone has a household appliance at home, whether it's a washing machine, dishwasher, or dryer. Despite their ubiquity, little is publicly documented about how these devices actually work or how their internal components communicate. This talk takes a closer look at proprietary bus systems, hidden diagnostic interfaces, and approaches to cloud-less integration of appliances from two well-known manufacturers into modern home automation systems.&lt;/p&gt;
    &lt;p&gt;Modern home appliances may seem simple from the outside, but inside they contain complex electronic systems, proprietary communication protocols, and diagnostic interfaces rarely documented outside the manufacturer. In this talk, we'll explore the challenges of reverse-engineering these systems: from analyzing appliance control boards and internal communication buses to decompiling and modifying firmware to better understand device functionality.&lt;/p&gt;
    &lt;p&gt;We'll also look at the security mechanisms designed to protect diagnostic access and firmware readout, and how these protections can be bypassed to enable deeper insight into device operation. Finally, this talk will demonstrate how the results of this research can be used to integrate even legacy home appliances into popular home automation platforms.&lt;/p&gt;
    &lt;p&gt;This session combines examples and insights from the reverse-engineering of B/S/H/ and Miele household appliances.&lt;/p&gt;
    &lt;p&gt;Licensed to the public under http://creativecommons.org/licenses/by/4.0&lt;/p&gt;
    &lt;head rend="h3"&gt;Download&lt;/head&gt;
    &lt;head rend="h4"&gt;Video&lt;/head&gt;
    &lt;head rend="h4"&gt;These files contain multiple languages.&lt;/head&gt;
    &lt;p&gt;This Talk was translated into multiple languages. The files available for download contain all languages as separate audio-tracks. Most desktop video players allow you to choose between them.&lt;/p&gt;
    &lt;p&gt;Please look for "audio tracks" in your desktop video player.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46428496</guid><pubDate>Tue, 30 Dec 2025 01:40:49 +0000</pubDate></item><item><title>Charm Ruby ‚Äì Glamorous Terminal Libraries for Ruby</title><link>https://charm-ruby.dev/</link><description>&lt;doc fingerprint="45ce1477af0f3686"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Bubbletea&lt;/head&gt;
    &lt;p&gt;Build terminal UIs from the future, today.&lt;/p&gt;
    &lt;p&gt;A powerful TUI framework using the Elm Architecture. Handle keyboard, mouse, and window events with commands for side effects.&lt;/p&gt;
    &lt;code&gt;gem "bubbletea"&lt;/code&gt;
    &lt;code&gt;
 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó
‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë
‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë
‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë
‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë
       ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù  RUBY
&lt;/code&gt;
    &lt;p&gt; Ruby bindings and ports of the beloved Charm terminal libraries.&lt;lb/&gt; Build glamorous TUIs, style terminal output, create beautiful forms,&lt;lb/&gt; and make your Ruby CLIs sparkle. &lt;/p&gt;
    &lt;code&gt;gem install bubbletea lipgloss bubbles glamour&lt;/code&gt;
    &lt;p&gt;Build terminal UIs from the future, today.&lt;/p&gt;
    &lt;p&gt;A powerful TUI framework using the Elm Architecture. Handle keyboard, mouse, and window events with commands for side effects.&lt;/p&gt;
    &lt;code&gt;gem "bubbletea"&lt;/code&gt;
    &lt;p&gt;The Bubble Tea component toolkit.&lt;/p&gt;
    &lt;p&gt;Pre-built components: Spinner, Progress, Timer, TextInput, TextArea, Viewport, List, Table, FilePicker, and more.&lt;/p&gt;
    &lt;code&gt;gem "bubbles"&lt;/code&gt;
    &lt;p&gt;Track clickable regions in terminal UIs.&lt;/p&gt;
    &lt;p&gt;Mark zones with IDs, check mouse coordinates, and handle click events in your Bubble Tea applications.&lt;/p&gt;
    &lt;code&gt;gem "bubblezone"&lt;/code&gt;
    &lt;p&gt;Your terminal style and layout toolkit.&lt;/p&gt;
    &lt;p&gt;Borders, padding, margins, colors (hex, ANSI, adaptive), tables, lists, trees, and layout utilities.&lt;/p&gt;
    &lt;code&gt;gem "lipgloss"&lt;/code&gt;
    &lt;p&gt;The stylesheet-driven markdown renderer.&lt;/p&gt;
    &lt;p&gt;Render markdown in your terminal with built-in themes (dark, light, dracula), custom styles via DSL, and emoji support.&lt;/p&gt;
    &lt;code&gt;gem "glamour"&lt;/code&gt;
    &lt;p&gt;Terminal charts for beautiful data viz.&lt;/p&gt;
    &lt;p&gt;Sparkline, Barchart, LineChart, WaveLineChart, StreamLineChart (real-time), and TimeSeriesLineChart.&lt;/p&gt;
    &lt;code&gt;gem "ntcharts"&lt;/code&gt;
    &lt;p&gt;Simple, powerful forms in the terminal.&lt;/p&gt;
    &lt;p&gt;Input, Text, Select, MultiSelect, Confirm, Note, Spinner. Built-in validation, themes, and a block-based DSL.&lt;/p&gt;
    &lt;code&gt;gem "huh", github: "marcoroth/huh-ruby"&lt;/code&gt;
    &lt;p&gt;A tool for glamorous shell scripts.&lt;/p&gt;
    &lt;p&gt;Ruby wrapper with idiomatic API: input, write, choose, filter, confirm, file, pager, spin, style, format. Bundles the gum binary.&lt;/p&gt;
    &lt;code&gt;gem "gum"&lt;/code&gt;
    &lt;p&gt;A physics-based animation library.&lt;/p&gt;
    &lt;p&gt;Damped harmonic oscillator (Spring), projectile motion, Point &amp;amp; Vector math, and frame rate helpers for smooth UI animations.&lt;/p&gt;
    &lt;code&gt;gem "harmonica"&lt;/code&gt;
    &lt;p&gt;Add the gems you need to your Gemfile:&lt;/p&gt;
    &lt;code&gt;# Gemfile

# Core TUI framework
gem "bubbletea"

# Styling
gem "lipgloss"

# Components
gem "bubbles"

# Markdown rendering
gem "glamour"

# Shell scripts
gem "gum"

# Animations
gem "harmonica"

# Charts
gem "ntcharts"

# Mouse tracking
gem "bubblezone"&lt;/code&gt;
    &lt;p&gt;A simple Bubbletea app with Lipgloss styling:&lt;/p&gt;
    &lt;code&gt;require "bubbletea"
require "lipgloss"

class HelloWorld
  include Bubbletea::Model

  def initialize
    @style = Lipgloss::Style.new
      .border(:rounded)
      .border_foreground("#7D56F4")
      .padding(1, 2)
  end

  def init = [self, nil]

  def update(message)
    case message
    when Bubbletea::KeyMessage
      return [self, Bubbletea.quit] if message.to_s == "q"
    end

    [self, nil]
  end

  def view
    @style.render("Hello, Charm Ruby!\n\nPress q to quit")
  end
end

Bubbletea.run(HelloWorld.new)&lt;/code&gt;
    &lt;code&gt;require "bubbletea"
require "lipgloss"

class Counter
  include Bubbletea::Model

  def initialize
    @count = 0
    @style = Lipgloss::Style.new
      .bold(true)
      .foreground("#FF6B6B")
  end

  def update(message)
    case message
    when Bubbletea::KeyMessage
      case message.to_s
      when "q", "ctrl+c"
        return [self, Bubbletea.quit]
      when "up" then @count += 1
      when "down" then @count -= 1
      end
    end

    [self, nil]
  end

  def view
    @style.render("Count: #{@count}\n\nPress q to quit")
  end
end

Bubbletea.run(Counter.new)&lt;/code&gt;
    &lt;code&gt;require "bubbletea"
require "bubbles"

class LoadingApp
  include Bubbletea::Model

  def initialize
    @spinner = Bubbles::Spinner.new
  end

  def init
    [self, @spinner.tick]
  end

  def update(message)
    case message
    when Bubbletea::KeyMessage
      case message.to_s
      when "q", "ctrl+c"
        return [self, Bubbletea.quit]
      end
    end

    @spinner, command = @spinner.update(message)

    [self, command]
  end

  def view
    "#{@spinner.view} Loading..."
  end
end

Bubbletea.run(LoadingApp.new)&lt;/code&gt;
    &lt;code&gt;require "huh"

form = Huh.form(
  Huh.group(
    Huh.input
      .key("name")
      .title("What's your name?")
      .placeholder("Enter name..."),

    Huh.select
      .key("color")
      .title("Favorite color?")
      .options(*Huh.options(
        "Red", "Green", "Blue"
      ))
  )
).with_theme(Huh::Themes.charm)

form.run

puts "Hello, #{form["name"]}!"&lt;/code&gt;
    &lt;code&gt;require "lipgloss"

headers = ["Name", "Language", "Stars"]

rows = [
  ["bubbletea", "Ruby", "‚ú®"],
  ["lipgloss", "Ruby", "üíÑ"],
  ["glamour", "Ruby", "‚ú®"]
]

table = Lipgloss::Table.new
  .headers(headers)
  .rows(rows)
  .border(:rounded)

puts table.render&lt;/code&gt;
    &lt;code&gt;require "glamour"

markdown = &amp;lt;&amp;lt;~MD
  # Hello Glamour :sparkles:

  This is **bold** and *italic*.

  - Item one
  - Item two
  - Item three

  ```ruby
  puts "Hello, World!"
  ```
MD

puts Glamour.render(markdown,
  style: "dark",
  width: 80,
  emoji: true
)&lt;/code&gt;
    &lt;code&gt;require "ntcharts"

chart = Ntcharts::Streamlinechart.new(60, 12)

loop do
  chart.push(Math.sin(Time.now.to_f) * 4 + 5)

  print "\e[H\e[2J"
  puts chart.render
  sleep 0.1
end&lt;/code&gt;
    &lt;p&gt;These Ruby gems are ports and bindings of the original Go libraries from Charm. They bring the same elegant APIs and glamorous terminal experiences to Ruby developers.&lt;/p&gt;
    &lt;p&gt;Some gems use native C extensions that link to compiled Go shared libraries, while others are pure Ruby implementations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46430558</guid><pubDate>Tue, 30 Dec 2025 07:36:38 +0000</pubDate></item><item><title>Go away Python</title><link>https://lorentz.app/blog-item.html?id=go-shebang</link><description>&lt;doc fingerprint="5f7ec79370d86d1d"&gt;
  &lt;main&gt;
    &lt;p&gt;lorentz app blog experiments&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46431028</guid><pubDate>Tue, 30 Dec 2025 08:50:44 +0000</pubDate></item><item><title>Netflix Open Content</title><link>https://opencontent.netflix.com/</link><description>&lt;doc fingerprint="235793111fd515b3"&gt;
  &lt;main&gt;
    &lt;p&gt;At Netflix, we are always exploring ways to make our content look and sound even better. To provide a common reference for prototyping bleeding-edge technologies within entertainment, technology and academic circles without compromising the security of our original and licensed programming, we've developed test titles oriented around documentary, live action, and animation.&lt;/p&gt;
    &lt;p&gt;Many open source assets are available from each project listed below. Our hope is this will encourage more experimentation, learning, and discovery that will benefit the whole industry. Many of these titles are also streaming on Netflix and are best enjoyed with any HDR configured device with your Premium subscription.&lt;/p&gt;
    &lt;p&gt;You can download single files directly through your web browser, but for large files and long frame sequences, you may wish to use command line tools. Guidance is included below. Ad Blockers may cause errors in your downloading process, so try turning it off if you have issues.&lt;/p&gt;
    &lt;p&gt;Our open source content is available under the Creative Commons Attribution 4.0 International Public License.&lt;/p&gt;
    &lt;p&gt;We‚Äôve had great success remastering titles like Knights of Sidonia, Flavours of Youth and Godzilla from SDR to HDR over the last few years. But what if we increase the resolution and create anime with HDR in mind from conception? Working with Japan's Production I.G, we set out to create the first 4K HDR Atmos anime short and discover what would need to change in anime workflows.&lt;/p&gt;
    &lt;p&gt;Read more about Sol Levante in the Netflix Tech Blog.&lt;/p&gt;
    &lt;p&gt;HDR10 2020 ST2084 UHD 24fps 1000nit&lt;/p&gt;
    &lt;p&gt;DolbyVision PQ/P3 D65 UHD 24fps IMF&lt;/p&gt;
    &lt;p&gt;Atmos ADM and DAMF files&lt;/p&gt;
    &lt;p&gt;ProTools Final Mix Session and Mastered Session&lt;/p&gt;
    &lt;p&gt;4K HDR 16bit P3/PQ D65 Dolby Vision 2.9 XML + VDM&lt;/p&gt;
    &lt;p&gt;Animatics, storyboard, selected After Effects projects, PSDs, and TGA in-betweens.&lt;/p&gt;
    &lt;p&gt;A live action test piece, Nocturne was shot at 120fps and sought to investigate footage with spatially complex scenes that mimic other professionally generated content to challenge codecs on both the encoding and decoding sides. This piece was also mastered in Dolby Vision and Atmos.&lt;/p&gt;
    &lt;p&gt;120fps Video Display Master&lt;/p&gt;
    &lt;p&gt;60fps Video Display Master&lt;/p&gt;
    &lt;p&gt;ADM WAV File&lt;/p&gt;
    &lt;p&gt;Upon noticing the contrast in dark shadows against the bright sky and sparks from a welder working on a new Netflix building, the encoding team acquired a Sony PMW-F55 and the AXS-R5 RAW recorder to shoot 16-bit RAW SQ and produce Sparks.&lt;/p&gt;
    &lt;p&gt;Sparks was shot 4K HFR and finished at 4000 nits using ACES. Read more about Sparks on the Netflix Tech Blog.&lt;/p&gt;
    &lt;p&gt;4K P3 PQ 4000nits Dolby Vision IMF&lt;/p&gt;
    &lt;p&gt;HDR10 1000nit PQ 2020 image sequence&lt;/p&gt;
    &lt;p&gt;4K P3/PQ 4000nits EXR&lt;/p&gt;
    &lt;p&gt;4K P3/PQ 4000nits EXR Dolby Vision metadata&lt;/p&gt;
    &lt;p&gt;ACES 59.94fps image sequence&lt;/p&gt;
    &lt;p&gt;Original Camera Files&lt;/p&gt;
    &lt;p&gt;Following the industry shift from ‚Äúmore pixels‚Äù to ‚Äúbetter pixels,‚Äù we produced Meridian, our first test title to tell a story. Meridian was mastered in Dolby Vision high dynamic range (HDR) with a P3-D65 color space and PQ (perceptual quantizer) transfer function. It also contained a Dolby Atmos mix, multiple language tracks, and subtitles. You can read more about Meridian on Variety.&lt;/p&gt;
    &lt;p&gt;UHD IMF&lt;/p&gt;
    &lt;p&gt;Zipped UHD VDM&lt;/p&gt;
    &lt;p&gt;UHD 4k 5994 HDR P3/PQ (mp4)&lt;/p&gt;
    &lt;p&gt;UHD VDM Image Sequence&lt;/p&gt;
    &lt;p&gt;Dolby Atmos Metadata File&lt;/p&gt;
    &lt;p&gt;Atmos BWAV ADM&lt;/p&gt;
    &lt;p&gt;TIFF Sequence&lt;/p&gt;
    &lt;p&gt;We felt a need to include animated content in our test title library, so we partnered with Blender Foundation and Fotokem‚Äôs Keep Me Posted to re-grade Cosmos Laundromat, an award-winning short film in Dolby Vision HDR.&lt;/p&gt;
    &lt;p&gt;Cosmos Laundromat is an Open Movie project created by Blender Studio and directed by Mathieu Auvray. The film was made entirely in Blender, an open source 3D content creation tool.&lt;/p&gt;
    &lt;p&gt;2k 24p HDR P3/PQ (mp4)&lt;/p&gt;
    &lt;p&gt;EXR to TIFF Nuke Script File&lt;/p&gt;
    &lt;p&gt;EXR Sequence&lt;/p&gt;
    &lt;p&gt;Chimera is technically comparable to El Fuente, but its scenes are more representative of existing titles on Netflix. The dinner scene attempts to recreate a codec-challenging sequence from House of Cards.&lt;/p&gt;
    &lt;p&gt;Prior to Chimera, there wasn‚Äôt any open source 4K test material that exhibited real world live action material.&lt;/p&gt;
    &lt;p&gt;DCI 4k 2398p HDR P3/PQ&lt;/p&gt;
    &lt;p&gt;DCI 4k 5994p HDR P3/PQ&lt;/p&gt;
    &lt;p&gt;TIFF Sequence: DCI 4k 2398p&lt;/p&gt;
    &lt;p&gt;TIFF Sequence: DCI 4k 5994p&lt;/p&gt;
    &lt;p&gt;As the demand for more pixels increased, so did appropriate test content. Documentary short El Fuente was shot in Mexico by a local DP at 4K at both 48 and 59.94 fps to meet increasing resolution and frame rate requirements.&lt;/p&gt;
    &lt;p&gt;Boat: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)&lt;/p&gt;
    &lt;p&gt;FoodMarket: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)&lt;/p&gt;
    &lt;p&gt;The assets on this page can be browsed on the Netflix OpenContent bucket here:&lt;/p&gt;
    &lt;p&gt;http://download.opencontent.netflix.com/&lt;/p&gt;
    &lt;p&gt;You can download single files directly through your web browser on each page, but for large files and long frame sequences, you may wish to use command line tools such as aws cli. Instructions are posted on their website. After installation, you should be able to download the public assets. Try running these sample commands. If the download is interrupted, you can run the same command immediately and aws cli will resume the download where it left off.&lt;/p&gt;
    &lt;p&gt;Download a single file (0.7 kB):&lt;/p&gt;
    &lt;p&gt;Usage: aws s3 cp --no-sign-request &amp;lt;s3 URI&amp;gt; &amp;lt;local destination&amp;gt;&lt;/p&gt;
    &lt;p&gt;Example: aws s3 cp --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/Sparks/sparks_license.txt .&lt;/p&gt;
    &lt;p&gt;Sync entire directory (1406.1 MB):&lt;/p&gt;
    &lt;p&gt;Usage: aws s3 sync --no-sign-request &amp;lt;s3 URI&amp;gt; &amp;lt;local destination&amp;gt;&lt;/p&gt;
    &lt;p&gt;Example: aws s3 sync --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/CosmosLaundromat/encodes/ .&lt;/p&gt;
    &lt;p&gt;The download links on this page will bring you to the root directory for that title's assets. You may need to navigate around to find the folder you want.&lt;/p&gt;
    &lt;p&gt;Last updated 2022-04-26&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46431560</guid><pubDate>Tue, 30 Dec 2025 10:11:57 +0000</pubDate></item><item><title>Non-Zero-Sum Games</title><link>https://nonzerosum.games/</link><description>&lt;doc fingerprint="b8854dca448ee835"&gt;
  &lt;main&gt;
    &lt;p&gt;Hi, I'm Non-Zero-Sum James, your companion on this exploration of win-win games and how they are essential for a better future. Each week we'll explore a new aspect of game theory, moral philosophy, ethical economics and artificial intelligence‚Äîlooking to solve the complex problems we face in our world together.&lt;/p&gt;
    &lt;p&gt;All the posts are connected through the lens of non-zero-sum games, but they fall into a few broad categories. You can start your journey with whatever appeals to you:&lt;/p&gt;
    &lt;quote&gt;"It is well to remember that the entire universe, with one trifling exception, is composed of others."&lt;lb/&gt;‚ÄîJohn Holmes&lt;/quote&gt;
    &lt;p&gt;Your thoughts and contributions are welcome. Share, debate, and co-create in the comments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46432311</guid><pubDate>Tue, 30 Dec 2025 11:42:55 +0000</pubDate></item><item><title>Crimson (YC X25) is hiring founding engineers in London</title><link>https://www.ycombinator.com/companies/crimson/jobs/kCikzj1-founding-engineer-full-stack</link><description>&lt;doc fingerprint="9c99af386544742c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Crimson is the AI platform for high-stakes litigation. We're working with top law firms in the UK and US to streamline how complex disputes are run. Our platform drafts pleadings and submissions, analyzes judgments and orders, summarizes transcripts and locates key evidence in seconds.&lt;/p&gt;
      &lt;p&gt;We're a team of three co-founders with deep technical and domain expertise. Our users are lawyers who trust us with their most sensitive case files. They care about security, accuracy, reliability and speed, and so do we.&lt;/p&gt;
      &lt;p&gt;We're looking for an exceptional full-stack engineer to join us as one of our first employees. You'll ship production code from day one and own major features end-to-end. That means talking to users, scoping the problem, building the solution and improving it over time.&lt;/p&gt;
      &lt;p&gt;What you'll do&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Contribute to the entire stack, from cloud infrastructure to prompting to UX (Python backend, Next.js with TypeScript frontend, PostgreSQL, SOTA LLMs. Deployed to Azure via IaC (Bicep) with CI/CD pipelines powered by GitHub Actions)&lt;/item&gt;
        &lt;item&gt;Collaborate closely with users to understand how lawyers work and what they need&lt;/item&gt;
        &lt;item&gt;Architect and scale document ingestion and processing pipelines to power fast, accurate search and data extraction for large volumes of legal documents&lt;/item&gt;
        &lt;item&gt;Develop intelligent, multi-step agent workflows that can autonomously handle complex legal tasks - from surfacing key testimony across depositions to generating fact chronologies and auto-detecting inconsistencies in opposing counsel‚Äôs filings&lt;/item&gt;
        &lt;item&gt;Design and bring to life intuitive AI-native user experiences tailored to litigation workflows&lt;/item&gt;
        &lt;item&gt;Improve system performance, stability and observability as we scale&lt;/item&gt;
        &lt;item&gt;Help shape our engineering culture and team - from best practices to hiring and mentorship&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;This is for you if ‚Ä¶&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You‚Äôre driven, self-directed and exceptionally capable&lt;/item&gt;
        &lt;item&gt;You‚Äôre obsessed with building outstanding products for demanding users&lt;/item&gt;
        &lt;item&gt;You‚Äôre excited to work on hard problems, take ownership and push things through&lt;/item&gt;
        &lt;item&gt;You have high agency and a bias for shipping&lt;/item&gt;
        &lt;item&gt;You have excellent product judgement, communication skills and attention to detail&lt;/item&gt;
        &lt;item&gt;Bonus points if you have an interest in legal tech&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Why join us&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Over the next few years, the legal industry will change beyond recognition. You‚Äôll be at the heart of that change, helping us build a category-defining company&lt;/item&gt;
        &lt;item&gt;We‚Äôre backed by YC and other top investors&lt;/item&gt;
        &lt;item&gt;We‚Äôre working with major UK and US law firms&lt;/item&gt;
        &lt;item&gt;You‚Äôll get ownership, equity and the opportunity to shape the business and lead engineering teams&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Details&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Location: London (minimum 3 days/week in our office near Bank)&lt;/item&gt;
        &lt;item&gt;Salary: ¬£80-120k&lt;/item&gt;
        &lt;item&gt;Meaningful equity&lt;/item&gt;
        &lt;item&gt;Contact: tell us about things you‚Äôve built by emailing founders [at] crimson [dot] law. Please include a link to your LinkedIn profile. We‚Äôll get back to you within 24h.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46432451</guid><pubDate>Tue, 30 Dec 2025 12:00:23 +0000</pubDate></item><item><title>Times New American: A Tale of Two Fonts</title><link>https://hsu.cy/2025/12/times-new-american/</link><description>&lt;doc fingerprint="bec4a14217f20d83"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Times New American: A Tale of Two Fonts&lt;/head&gt;
    &lt;p&gt;A less romantic truth is that aesthetic standards rarely travel alone; power tends to follow in their wake. An episode at the U.S. State Department this month makes exactly this point.&lt;/p&gt;
    &lt;p&gt;On December 9, Secretary of State Marco Rubio issued a memo titled ‚ÄúReturn to Tradition‚Äù that required all State Department documents to switch back to 14-point Times New Roman, overturning a Biden-era directive from 2023 that had turned to 15-point Calibri.&lt;/p&gt;
    &lt;p&gt;Frankly, most people likely view both of these simply as ‚Äústandard typefaces‚Äù without distinguishing much difference between them. So why would an institution of the State Department‚Äôs scale bother, twice in three years, to take a stance on something as seemingly trivial as a default typeface?&lt;/p&gt;
    &lt;p&gt;John Gruber, an Apple-sphere blogger with a well-known appetite for political commentary, obtained the full text of Rubio‚Äôs memo and published it. 1 (It is worth reading first.) Rubio‚Äôs rationale, in simplified form, has three parts. First, serif typefaces are said to better communicate professionalism, formality, and authority in official documents (¬∂¬∂ 6‚Äì8). Second, using a serif typeface is aligning with the White House, the courts, and the State Department‚Äôs own historical practice (¬∂ 9). Third, the 2023 decision was a ‚Äúcosmetic‚Äù gesture associated with diversity, equity, inclusion, and accessibility (DEIA) politics, and the reversion a correction to that (¬∂ 10).&lt;/p&gt;
    &lt;p&gt;Commentary on American partisan politics is beyond the scope of this article. Still, in neutral terms, Trump‚Äôs second term has been marked by an unusually rapid and sweeping effort to repeal or reverse the prior administration‚Äôs policies, with DEIA among the earliest targets. The memo itself cites Executive Order 14151, signed on the first day of the term, that instructed federal agencies to terminate all DEIA-related activities, offices, positions, policies, programs, and contracts.&lt;/p&gt;
    &lt;p&gt;That makes the political element of this typography decision fairly plain: it coheres with, and signals loyalty to, a broader anti-DEIA agenda. The remaining question is whether it is only politics. Put differently, how persuasive are Rubio‚Äôs first two, ostensibly nonpolitical claims about design and conventions? Or are they merely pretexts?&lt;/p&gt;
    &lt;p&gt;To recap, a serif typeface is one with extra decorative strokes, or ‚Äúserifs,‚Äù at the ends of main strokes. A popular narrative links serifs to stone inscriptions: Roman craftsmen would sketch letter outlines on stone and carve along them; at stroke endings and corners, the chisel work flared outward, leaving the small protrusions we now call serifs. That lineage likely underwrites the memo‚Äôs association of serifs with ‚Äútradition,‚Äù ‚Äúformality,‚Äù and ‚Äúceremony.‚Äù&lt;/p&gt;
    &lt;p&gt;However, most people don‚Äôt actually know this history, and many cannot reliably distinguish serif from sans-serif in the first place. The general public doesn‚Äôt perceive serif typefaces as professional and authoritative, a priori, before prioritizing their use in formal settings. Instead, people first observe that government, academia, and corporate workplaces disproportionately use serif faces ‚Äî or are trained to use them ‚Äî and only then infer that serifs must mean professionalism and authority.&lt;/p&gt;
    &lt;p&gt;Even if we limit ourselves to design and historical considerations, Times New Roman, despite being a serif typeface, possesses little of the ‚Äúprofessional, solemn, and authoritative‚Äù aura. The typeface was designed in 1931 for The Times of London, and newspaper typefaces are typically engineered to print cleanly on cheap paper, conserve space, and support rapid scanning.&lt;/p&gt;
    &lt;p&gt;Those goals are visible in the details. The strokes of Times New Roman are relatively thin (leaving tolerance for ink spread on newsprint), the letterforms are narrow, and the x-height (the height of the lowercase ‚Äúx‚Äù) is comparatively large. There is nothing inherently wrong with such functional design; it simply doesn‚Äôt map neatly onto the ‚Äútraditional‚Äù look of older serifs. On a modern, high-resolution display, the typeface can appear spindly, more utilitarian than ceremonial.&lt;/p&gt;
    &lt;p&gt;Indeed, the stronger explanation for Times New Roman‚Äôs long reign isn‚Äôt aesthetic excellence, but practicality and inertia. Times New Roman was among the small set of typefaces bundled with early versions of Windows. It was also promoted as ‚Äúweb-safe,‚Äù meaning webmasters could reasonably assume it would render properly across platforms. In the early era of digitalization, choosing Times New Roman was often less a deliberate endorsement than a default imposed by limited options. Over time, the habit hardened into a standard, and institutions began to require it without much reflection, effectively borrowing their own authority to confer authority upon the typeface.&lt;/p&gt;
    &lt;p&gt;Professionals who genuinely focus on typography have advised against Times New Roman. For example, type designer Matthew Butterick eloquently comments:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When Times New Roman appears in a book, document, or advertisement, it connotes apathy. It says, ‚ÄúI submitted to the typeface of least resistance.‚Äù Times New Roman isn‚Äôt a typeface choice so much as the absence of a typeface choice, like the blackness of deep space isn‚Äôt a color. To look at Times New Roman is to gaze into the void.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Similarly, the U.S. Court of Appeals for the Eighth Circuit, in its formatting advice for lawyers, specifically cautions:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Typographic decisions should be made for a purpose. The Times of London chose the typeface Times New Roman to serve an audience looking for a quick read. Lawyers don‚Äôt want their audience to read fast and throw the document away; they want to maximize retention. Achieving that goal requires a different approach ‚Äî different typefaces, different column widths, different writing conventions. Briefs are like books rather than newspapers. The most important piece of advice we can offer is this: read some good books and try to make your briefs more like them.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As for the other U.S. official bodies Rubio cites in the memo, many don‚Äôt actually use Times New Roman either. The Supreme Court‚Äôs rules require booklet-format filings to be set in the Century family, and its own opinions are typeset in Century Schoolbook from that family. Originating in the 19th century, the typeface features more expansive proportions, balanced stroke contrast, and an elegant form, exuding a far more assertive presence than Times New Roman. As the name suggests, it also began life as a textbook face, optimized for legibility. With proper typesetting, it reads far better than a haphazardly produced Word document set in Times New Roman.&lt;/p&gt;
    &lt;p&gt;Looking at the legislature, the official PDFs of U.S. Congressional bills use Cheltenham for titles and De Vinne for body text. De Vinne, first released in 1902, shares similarities in style with Century Schoolbook but features stronger stroke contrast and more decorative serifs, giving it an ‚Äúengraved‚Äù quality. Objectively speaking, this design borders on being a display typeface ‚Äî imagine the logotype of Harper‚Äôs Bazaar, Didot ‚Äî and is somewhat tiring to read in body text. But when it comes to conveying ceremony and solemnity, it‚Äôs far more qualified than Times New Roman. (After a bill is enacted into law, it will be typeset in New Century Schoolbook.)&lt;/p&gt;
    &lt;p&gt;Even the Trump administration, to which Rubio pledges allegiance, contradicts the ‚Äúserif tradition‚Äù by using a fashionable tall, high-contrast serif (Instrument Serif) on the White House website. It may look a bit mannered by government standards ‚Äî an impression no less bolstered by its bombastic rhetoric ‚Äî but it does manage to appear assertive and emphatic. Swap in Times New Roman and ‚ÄúAMERICA IS BACK‚Äù would read more like a mutter.&lt;/p&gt;
    &lt;p&gt;Thus, the design and historical reasons cited in Rubio‚Äôs memo don‚Äôt hold up. The formality and authority of serif typefaces are largely socially constructed, and Times New Roman‚Äôs origin story and design constraints don‚Äôt express these qualities. If Times New Roman carries authority at all, it‚Äôs primarily borrowed from the authority of institutions that have adhered to it. If the sincere goal were to ‚Äúreturn to tradition‚Äù by returning to a serif, there are many choices with deeper pedigree and more fitting gravitas.&lt;/p&gt;
    &lt;p&gt;At this point, it might sound as though the argument is trending toward a defense of the Department‚Äôs earlier choice: Calibri. Unfortunately, Calibri is also a poor fit for formal contexts. While seriousness and authority aren‚Äôt the exclusive province of serifs, Calibri does little to convey those traits.&lt;/p&gt;
    &lt;p&gt;Typographically, Calibri is a humanist sans-serif. Such typefaces tend to have open, rounded forms and generous apertures (look at the wide openings in letters like a, c, e, and s). Calibri takes that softness especially far: terminals are visibly rounded, and many letters appear almost handwritten, to the extent that its designer described its quality as ‚Äúwarm and soft.‚Äù&lt;/p&gt;
    &lt;p&gt;There‚Äôs nothing inherently wrong with this style, but one would hardly want an official document or legal contract to appear ‚Äúwarm and soft.‚Äù That is why I have long disliked Microsoft‚Äôs decision to make Calibri the default Office typeface starting with Office 2007. A default body typeface should be neutral and versatile, not exude a temperature. (Microsoft replaced Calibri with Aptos as the default in 2023, but inertia being what it is, Aptos still appears relatively rarely in the wild.)&lt;/p&gt;
    &lt;p&gt;To be fair, the State Department‚Äôs 2023 change was justified less as a matter of taste than as an accessibility and inclusion initiative. That is, to make documents easier to read for individuals with various physical and cognitive conditions. This goal is commendable in itself, but the means were, at best, loosely connected to the end, much like many inclusive measures that were once fashionable in U.S. politics and business in recent years.&lt;/p&gt;
    &lt;p&gt;First, Calibri was not designed with accessibility in mind. It was commissioned by Microsoft to promote its ClearType technology, with the design objective of appearing clear on the low-resolution displays of its time. This means it prioritizes smoothness under specific sub-pixel rendering techniques, rather than ensuring the glyphs are easy to tell apart. If accessibility were truly the goal, one might select a typeface created for that purpose. For example, Atkinson Hyperlegible addresses character differentiation by adding serifs, exaggerating shapes, and slanting strokes, making it legible even under low-vision conditions. In contrast, Calibri has no anti-ambiguity design: the uppercase &lt;code&gt;I&lt;/code&gt; and lowercase &lt;code&gt;l&lt;/code&gt; are nearly identical. So much for ‚Äúaccessibility.‚Äù&lt;/p&gt;
    &lt;p&gt;Furthermore, accessibility doesn‚Äôt depend solely on a document‚Äôs appearance but more on its internal structure and presentation mechanisms. For instance, the W3C‚Äôs Web Content Accessibility Guidelines (WCAG) state that accessible content should be perceivable, operable, understandable, and robust. This means that documents should have proper semantic structure (so tools like screen readers can interpret content correctly), support customizable layouts and fonts, and be compatible with various applications and devices. If these principles were met, the specific font used would matter little, as users can access the content with their preferred tools in their preferred manner. Conversely, if a document is technically crude, like a scanned PDF ‚Äî as many official documents are ‚Äî the use of an ‚Äúinclusive‚Äù font is merely self-congratulatory.&lt;/p&gt;
    &lt;p&gt;If one insisted on a sans-serif for official writing, there are many better candidates than Calibri: Frutiger (common in airport wayfinding), Myriad (used by Apple for years), the cool and serious Univers (or a well-set Helvetica Neue), or contemporary neutral workhorses like Inter. If a ‚Äúmade in America‚Äù signal mattered, Public Sans (funded under the 21st Century Integrated Digital Experience Act passed during Trump‚Äôs first term) and used by many U.S. government websites is also a good option.&lt;/p&gt;
    &lt;p&gt;Therefore, Rubio‚Äôs criticism that the previous move was ‚Äúcosmetic,‚Äù while being politically charged, isn‚Äôt entirely unfounded.&lt;/p&gt;
    &lt;p&gt;Taken together, the Department had previously pursued a defensible goal with a poorly matched design intervention and landed on an ill-fitting typeface. Now, for political motives, it has reversed that decision and returned to a bland, unremarkable default. Between the two, Times New Roman may be the lesser evil: it is more widely recognized, and it doesn‚Äôt clash with the official context as overtly as Calibri does. Still, Rubio, or whoever drafted the memo for him, could have been more candid. There was no need to dress up a political gesture with faux-erudite claims or to lavish praise on a mediocre typeface.&lt;/p&gt;
    &lt;p&gt;Because Times New Roman just will not make America great again.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The authenticity of the text cannot be independently verified, of course. It is, however, consistent with reports from reputable media outlets. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46432862</guid><pubDate>Tue, 30 Dec 2025 12:56:07 +0000</pubDate></item><item><title>Approachable Swift Concurrency</title><link>https://fuckingapproachableswiftconcurrency.com/en/</link><description>&lt;doc fingerprint="7470a7176c2d9444"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fucking Approachable&lt;lb/&gt;Swift Concurrency&lt;/head&gt;
    &lt;p&gt;Finally understand async/await, Tasks, and why the compiler keeps yelling at you.&lt;/p&gt;
    &lt;p&gt;Huge thanks to Matt Massicotte for making Swift concurrency understandable. Put together by Pedro Pi√±era. Found an issue? [email protected]&lt;/p&gt;
    &lt;p&gt;In the tradition of fuckingblocksyntax.com and fuckingifcaseletsyntax.com&lt;/p&gt;
    &lt;head rend="h2"&gt;Async Code: async/await&lt;/head&gt;
    &lt;p&gt;Most of what apps do is wait. Fetch data from a server - wait for the response. Read a file from disk - wait for the bytes. Query a database - wait for the results.&lt;/p&gt;
    &lt;p&gt;Before Swift's concurrency system, you'd express this waiting with callbacks, delegates, or Combine. They work, but nested callbacks get hard to follow, and Combine has a steep learning curve.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;async/await&lt;/code&gt; gives Swift a new way to handle waiting. Instead of callbacks, you write code that looks sequential - it pauses, waits, and resumes. Under the hood, Swift's runtime manages these pauses efficiently. But making your app actually stay responsive while waiting depends on where code runs, which we'll cover later.&lt;/p&gt;
    &lt;p&gt;An async function is one that might need to pause. You mark it with &lt;code&gt;async&lt;/code&gt;, and when you call it, you use &lt;code&gt;await&lt;/code&gt; to say "pause here until this finishes":&lt;/p&gt;
    &lt;code&gt;func fetchUser(id: Int) async throws -&amp;gt; User {
    let url = URL(string: "https://api.example.com/users/\(id)")!
    let (data, _) = try await URLSession.shared.data(from: url)  // Suspends here
    return try JSONDecoder().decode(User.self, from: data)
}

// Calling it
let user = try await fetchUser(id: 123)
// Code here runs after fetchUser completes&lt;/code&gt;
    &lt;p&gt;Your code pauses at each &lt;code&gt;await&lt;/code&gt; - this is called suspension. When the work finishes, your code resumes right where it left off. Suspension gives Swift the opportunity to do other work while waiting.&lt;/p&gt;
    &lt;head rend="h3"&gt;Waiting for them&lt;/head&gt;
    &lt;p&gt;What if you need to fetch several things? You could await them one by one:&lt;/p&gt;
    &lt;code&gt;let avatar = try await fetchImage("avatar.jpg")
let banner = try await fetchImage("banner.jpg")
let bio = try await fetchBio()&lt;/code&gt;
    &lt;p&gt;But that's slow - each waits for the previous one to finish. Use &lt;code&gt;async let&lt;/code&gt; to run them in parallel:&lt;/p&gt;
    &lt;code&gt;func loadProfile() async throws -&amp;gt; Profile {
    async let avatar = fetchImage("avatar.jpg")
    async let banner = fetchImage("banner.jpg")
    async let bio = fetchBio()

    // All three are fetching in parallel!
    return Profile(
        avatar: try await avatar,
        banner: try await banner,
        bio: try await bio
    )
}&lt;/code&gt;
    &lt;p&gt;Each &lt;code&gt;async let&lt;/code&gt; starts immediately. The &lt;code&gt;await&lt;/code&gt; collects the results.&lt;/p&gt;
    &lt;head rend="h4"&gt;await needs async&lt;/head&gt;
    &lt;p&gt;You can only use &lt;code&gt;await&lt;/code&gt; inside an &lt;code&gt;async&lt;/code&gt; function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Managing Work: Tasks&lt;/head&gt;
    &lt;p&gt;A Task is a unit of async work you can manage. You've written async functions, but a Task is what actually runs them. It's how you start async code from synchronous code, and it gives you control over that work: wait for its result, cancel it, or let it run in the background.&lt;/p&gt;
    &lt;p&gt;Let's say you're building a profile screen. Load the avatar when the view appears using the &lt;code&gt;.task&lt;/code&gt; modifier, which cancels automatically when the view disappears:&lt;/p&gt;
    &lt;code&gt;struct ProfileView: View {
    @State private var avatar: Image?

    var body: some View {
        avatar
            .task { avatar = await downloadAvatar() }
    }
}&lt;/code&gt;
    &lt;p&gt;If users can switch between profiles, use &lt;code&gt;.task(id:)&lt;/code&gt; to reload when the selection changes:&lt;/p&gt;
    &lt;code&gt;struct ProfileView: View {
    var userID: String
    @State private var avatar: Image?

    var body: some View {
        avatar
            .task(id: userID) { avatar = await downloadAvatar(for: userID) }
    }
}&lt;/code&gt;
    &lt;p&gt;When the user taps "Save", create a Task manually:&lt;/p&gt;
    &lt;code&gt;Button("Save") {
    Task { await saveProfile() }
}&lt;/code&gt;
    &lt;p&gt;What if you need to load the avatar, bio, and stats all at once? Use a &lt;code&gt;TaskGroup&lt;/code&gt; to fetch them in parallel:&lt;/p&gt;
    &lt;code&gt;try await withThrowingTaskGroup(of: Void.self) { group in
    group.addTask { avatar = try await downloadAvatar(for: userID) }
    group.addTask { bio = try await fetchBio(for: userID) }
    group.addTask { stats = try await fetchStats(for: userID) }
    try await group.waitForAll()
}&lt;/code&gt;
    &lt;p&gt;Tasks inside a group are child tasks, linked to the parent. A few things to know:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancellation propagates: cancel the parent, and all children get cancelled too&lt;/item&gt;
      &lt;item&gt;Errors: a thrown error cancels siblings and rethrows, but only when you consume results with &lt;code&gt;next()&lt;/code&gt;,&lt;code&gt;waitForAll()&lt;/code&gt;, or iteration&lt;/item&gt;
      &lt;item&gt;Completion order: results arrive as tasks finish, not the order you added them&lt;/item&gt;
      &lt;item&gt;Waits for all: the group doesn't return until every child completes or is cancelled&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is structured concurrency: work organized in a tree that's easy to reason about and clean up.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where Things Run: From Threads to Isolation Domains&lt;/head&gt;
    &lt;p&gt;So far we've talked about when code runs (async/await) and how to organize it (Tasks). Now: where does it run, and how do we keep it safe?&lt;/p&gt;
    &lt;head rend="h4"&gt;Most apps just wait&lt;/head&gt;
    &lt;p&gt;Most app code is I/O-bound. You fetch data from a network, await a response, decode it, and display it. If you have multiple I/O operations to coordinate, you resort to tasks and task groups. The actual CPU work is minimal. The main thread can handle this fine because &lt;code&gt;await&lt;/code&gt; suspends without blocking.&lt;/p&gt;
    &lt;p&gt;But sooner or later, you'll have CPU-bound work: parsing a giant JSON file, processing images, running complex calculations. This work doesn't wait for anything external. It just needs CPU cycles. If you run it on the main thread, your UI freezes. This is where "where does code run" actually matters.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Old World: Many Options, No Safety&lt;/head&gt;
    &lt;p&gt;Before Swift's concurrency system, you had several ways to manage execution:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Approach&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
        &lt;cell role="head"&gt;Tradeoffs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Thread&lt;/cell&gt;
        &lt;cell&gt;Direct thread control&lt;/cell&gt;
        &lt;cell&gt;Low-level, error-prone, rarely needed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GCD&lt;/cell&gt;
        &lt;cell&gt;Dispatch queues with closures&lt;/cell&gt;
        &lt;cell&gt;Simple but no cancellation, easy to cause thread explosion&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OperationQueue&lt;/cell&gt;
        &lt;cell&gt;Task dependencies, cancellation, KVO&lt;/cell&gt;
        &lt;cell&gt;More control but verbose and heavyweight&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Combine&lt;/cell&gt;
        &lt;cell&gt;Reactive streams&lt;/cell&gt;
        &lt;cell&gt;Great for event streams, steep learning curve&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All of these worked, but safety was entirely on you. The compiler couldn't help if you forgot to dispatch to main, or if two queues accessed the same data simultaneously.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Problem: Data Races&lt;/head&gt;
    &lt;p&gt;A data race happens when two threads access the same memory at the same time, and at least one is writing:&lt;/p&gt;
    &lt;code&gt;var count = 0

DispatchQueue.global().async { count += 1 }
DispatchQueue.global().async { count += 1 }

// Undefined behavior: crash, memory corruption, or wrong value&lt;/code&gt;
    &lt;p&gt;Data races are undefined behavior. They can crash, corrupt memory, or silently produce wrong results. Your app works fine in testing, then crashes randomly in production. Traditional tools like locks and semaphores help, but they're manual and error-prone.&lt;/p&gt;
    &lt;head rend="h4"&gt;Concurrency amplifies the problem&lt;/head&gt;
    &lt;p&gt;The more concurrent your app is, the more likely data races become. A simple iOS app might get away with sloppy thread safety. A web server handling thousands of simultaneous requests will crash constantly. This is why Swift's compile-time safety matters most in high-concurrency environments.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Shift: From Threads to Isolation&lt;/head&gt;
    &lt;p&gt;Swift's concurrency model asks a different question. Instead of "which thread should this run on?", it asks: "who is allowed to access this data?"&lt;/p&gt;
    &lt;p&gt;This is isolation. Rather than manually dispatching work to threads, you declare boundaries around data. The compiler enforces these boundaries at build time, not runtime.&lt;/p&gt;
    &lt;head rend="h4"&gt;Under the hood&lt;/head&gt;
    &lt;p&gt;Swift Concurrency is built on top of libdispatch (the same runtime as GCD). The difference is the compile-time layer: actors and isolation are enforced by the compiler, while the runtime handles scheduling on a cooperative thread pool limited to your CPU's core count.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Three Isolation Domains&lt;/head&gt;
    &lt;p&gt;1. MainActor&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;@MainActor&lt;/code&gt; is a global actor that represents the main thread's isolation domain. It's special because UI frameworks (UIKit, AppKit, SwiftUI) require main thread access.&lt;/p&gt;
    &lt;code&gt;@MainActor
class ViewModel {
    var items: [Item] = []  // Protected by MainActor isolation
}&lt;/code&gt;
    &lt;p&gt;When you mark something &lt;code&gt;@MainActor&lt;/code&gt;, you're not saying "dispatch this to the main thread." You're saying "this belongs to the main actor's isolation domain." The compiler enforces that anything accessing it must either be on MainActor or &lt;code&gt;await&lt;/code&gt; to cross the boundary.&lt;/p&gt;
    &lt;head rend="h4"&gt;When in doubt, use @MainActor&lt;/head&gt;
    &lt;p&gt;For most apps, marking your ViewModels with &lt;code&gt;@MainActor&lt;/code&gt; is the right choice. Performance concerns are usually overblown. Start here, optimize only if you measure actual problems.&lt;/p&gt;
    &lt;p&gt;2. Actors&lt;/p&gt;
    &lt;p&gt;An actor protects its own mutable state. It guarantees that only one piece of code can access its data at a time:&lt;/p&gt;
    &lt;code&gt;actor BankAccount {
    var balance: Double = 0

    func deposit(_ amount: Double) {
        balance += amount  // Safe: actor guarantees exclusive access
    }
}

// From outside, you must await to cross the boundary
await account.deposit(100)&lt;/code&gt;
    &lt;p&gt;Actors are not threads. An actor is an isolation boundary. The Swift runtime decides which thread actually executes actor code. You don't control that, and you don't need to.&lt;/p&gt;
    &lt;p&gt;3. Nonisolated&lt;/p&gt;
    &lt;p&gt;Code marked &lt;code&gt;nonisolated&lt;/code&gt; opts out of actor isolation. It can be called from anywhere without &lt;code&gt;await&lt;/code&gt;, but it cannot access the actor's protected state:&lt;/p&gt;
    &lt;code&gt;actor BankAccount {
    var balance: Double = 0

    nonisolated func bankName() -&amp;gt; String {
        "Acme Bank"  // No actor state accessed, safe to call from anywhere
    }
}

let name = account.bankName()  // No await needed&lt;/code&gt;
    &lt;head rend="h4"&gt;Approachable Concurrency: Less Friction&lt;/head&gt;
    &lt;p&gt;Approachable Concurrency simplifies the mental model with two Xcode build settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SWIFT_DEFAULT_ACTOR_ISOLATION&lt;/code&gt;=&lt;code&gt;MainActor&lt;/code&gt;: Everything runs on MainActor unless you say otherwise&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SWIFT_APPROACHABLE_CONCURRENCY&lt;/code&gt;=&lt;code&gt;YES&lt;/code&gt;:&lt;code&gt;nonisolated&lt;/code&gt;async functions stay on the caller's actor instead of jumping to a background thread&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;New Xcode 26 projects have both enabled by default. When you need CPU-intensive work off the main thread, use &lt;code&gt;@concurrent&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;// Runs on MainActor (the default)
func updateUI() async { }

// Runs on background thread (opt-in)
@concurrent func processLargeFile() async { }&lt;/code&gt;
    &lt;head rend="h4"&gt;The Office Building&lt;/head&gt;
    &lt;p&gt;Think of your app as an office building. Each isolation domain is a private office with a lock on the door. Only one person can be inside at a time, working with the documents in that office.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;MainActor&lt;/code&gt;is the front desk - where all customer interactions happen. There's only one, and it handles everything the user sees.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;actor&lt;/code&gt;types are department offices - Accounting, Legal, HR. Each protects its own sensitive documents.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;nonisolated&lt;/code&gt;code is the hallway - shared space anyone can walk through, but no private documents live there.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can't just barge into someone's office. You knock (&lt;code&gt;await&lt;/code&gt;) and wait for them to let you in.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Can Cross Isolation Domains: Sendable&lt;/head&gt;
    &lt;p&gt;Isolation domains protect data, but eventually you need to pass data between them. When you do, Swift checks if it's safe.&lt;/p&gt;
    &lt;p&gt;Think about it: if you pass a reference to a mutable class from one actor to another, both actors could modify it simultaneously. That's exactly the data race we're trying to prevent. So Swift needs to know: can this data be safely shared?&lt;/p&gt;
    &lt;p&gt;The answer is the &lt;code&gt;Sendable&lt;/code&gt; protocol. It's a marker that tells the compiler "this type is safe to pass across isolation boundaries":&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sendable types can cross safely (value types, immutable data, actors)&lt;/item&gt;
      &lt;item&gt;Non-Sendable types can't (classes with mutable state)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;// Sendable - it's a value type, each place gets a copy
struct User: Sendable {
    let id: Int
    let name: String
}

// Non-Sendable - it's a class with mutable state
class Counter {
    var count = 0  // Two places modifying this = disaster
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Making Types Sendable&lt;/head&gt;
    &lt;p&gt;Swift automatically infers &lt;code&gt;Sendable&lt;/code&gt; for many types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Structs and enums with only &lt;code&gt;Sendable&lt;/code&gt;properties are implicitly&lt;code&gt;Sendable&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Actors are always &lt;code&gt;Sendable&lt;/code&gt;because they protect their own state&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;@MainActor&lt;/code&gt;types are&lt;code&gt;Sendable&lt;/code&gt;because MainActor serializes access&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For classes, it's harder. A class can conform to &lt;code&gt;Sendable&lt;/code&gt; only if it's &lt;code&gt;final&lt;/code&gt; and all its stored properties are immutable:&lt;/p&gt;
    &lt;code&gt;final class APIConfig: Sendable {
    let baseURL: URL      // Immutable
    let timeout: Double   // Immutable
}&lt;/code&gt;
    &lt;p&gt;If you have a class that's thread-safe through other means (locks, atomics), you can use &lt;code&gt;@unchecked Sendable&lt;/code&gt; to tell the compiler "trust me":&lt;/p&gt;
    &lt;code&gt;final class ThreadSafeCache: @unchecked Sendable {
    private let lock = NSLock()
    private var storage: [String: Data] = [:]
}&lt;/code&gt;
    &lt;head rend="h4"&gt;@unchecked Sendable is a promise&lt;/head&gt;
    &lt;p&gt;The compiler won't verify thread safety. If you're wrong, you'll get data races. Use sparingly.&lt;/p&gt;
    &lt;head rend="h4"&gt;Approachable Concurrency: Less Friction&lt;/head&gt;
    &lt;p&gt;With Approachable Concurrency, Sendable errors become much rarer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If code doesn't cross isolation boundaries, you don't need Sendable&lt;/item&gt;
      &lt;item&gt;Async functions stay on the caller's actor instead of hopping to a background thread&lt;/item&gt;
      &lt;item&gt;The compiler is smarter about detecting when values are used safely&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enable it by setting &lt;code&gt;SWIFT_DEFAULT_ACTOR_ISOLATION&lt;/code&gt; to &lt;code&gt;MainActor&lt;/code&gt; and &lt;code&gt;SWIFT_APPROACHABLE_CONCURRENCY&lt;/code&gt; to &lt;code&gt;YES&lt;/code&gt;. New Xcode 26 projects have both enabled by default. When you do need parallelism, mark functions &lt;code&gt;@concurrent&lt;/code&gt; and then think about Sendable.&lt;/p&gt;
    &lt;head rend="h4"&gt;Photocopies vs. Original Documents&lt;/head&gt;
    &lt;p&gt;Back to the office building. When you need to share information between departments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Photocopies are safe - If Legal makes a copy of a document and sends it to Accounting, both have their own copy. They can scribble on them, modify them, whatever. No conflict.&lt;/item&gt;
      &lt;item&gt;Original signed contracts must stay put - If two departments could both modify the original, chaos ensues. Who has the real version?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;Sendable&lt;/code&gt; types are like photocopies: safe to share because each place gets its own independent copy (value types) or because they're immutable (nobody can modify them). Non-&lt;code&gt;Sendable&lt;/code&gt; types are like original contracts: passing them around creates the potential for conflicting modifications.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Isolation Is Inherited&lt;/head&gt;
    &lt;p&gt;You've seen that isolation domains protect data, and Sendable controls what crosses between them. But how does code end up in an isolation domain in the first place?&lt;/p&gt;
    &lt;p&gt;When you call a function or create a closure, isolation flows through your code. With Approachable Concurrency, your app starts on &lt;code&gt;MainActor&lt;/code&gt;, and that isolation propagates to the code you call, unless something explicitly changes it. Understanding this flow helps you predict where code runs and why the compiler sometimes complains.&lt;/p&gt;
    &lt;head rend="h3"&gt;Function Calls&lt;/head&gt;
    &lt;p&gt;When you call a function, its isolation determines where it runs:&lt;/p&gt;
    &lt;code&gt;@MainActor func updateUI() { }      // Always runs on MainActor
func helper() { }                    // Inherits caller's isolation
@concurrent func crunch() async { }  // Explicitly runs off-actor&lt;/code&gt;
    &lt;p&gt;With Approachable Concurrency, most of your code inherits &lt;code&gt;MainActor&lt;/code&gt; isolation. The function runs where the caller runs, unless it explicitly opts out.&lt;/p&gt;
    &lt;head rend="h3"&gt;Closures&lt;/head&gt;
    &lt;p&gt;Closures inherit isolation from the context where they're defined:&lt;/p&gt;
    &lt;code&gt;@MainActor
class ViewModel {
    func setup() {
        let closure = {
            // Inherits MainActor from ViewModel
            self.updateUI()  // Safe, same isolation
        }
        closure()
    }
}&lt;/code&gt;
    &lt;p&gt;This is why SwiftUI's &lt;code&gt;Button&lt;/code&gt; action closures can safely update &lt;code&gt;@State&lt;/code&gt;: they inherit MainActor isolation from the view.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tasks&lt;/head&gt;
    &lt;p&gt;A &lt;code&gt;Task { }&lt;/code&gt; inherits actor isolation from where it's created:&lt;/p&gt;
    &lt;code&gt;@MainActor
class ViewModel {
    func doWork() {
        Task {
            // Inherits MainActor isolation
            self.updateUI()  // Safe, no await needed
        }
    }
}&lt;/code&gt;
    &lt;p&gt;This is usually what you want. The task runs on the same actor as the code that created it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Breaking Inheritance: Task.detached&lt;/head&gt;
    &lt;p&gt;Sometimes you want a task that doesn't inherit any context:&lt;/p&gt;
    &lt;code&gt;@MainActor
class ViewModel {
    func doHeavyWork() {
        Task.detached {
            // No actor isolation, runs on cooperative pool
            let result = await self.expensiveCalculation()
            await MainActor.run {
                self.data = result  // Explicitly hop back
            }
        }
    }
}&lt;/code&gt;
    &lt;head rend="h4"&gt;Task.detached is usually wrong&lt;/head&gt;
    &lt;p&gt;The Swift team recommends Task.detached as a last resort. It doesn't inherit priority, task-local values, or actor context. Most of the time, regular &lt;code&gt;Task&lt;/code&gt; is what you want. If you need CPU-intensive work off the main actor, mark the function &lt;code&gt;@concurrent&lt;/code&gt; instead.&lt;/p&gt;
    &lt;head rend="h4"&gt;Walking Through the Building&lt;/head&gt;
    &lt;p&gt;When you're in the front desk office (MainActor), and you call someone to help you, they come to your office. They inherit your location. If you create a task ("go do this for me"), that assistant starts in your office too.&lt;/p&gt;
    &lt;p&gt;The only way someone ends up in a different office is if they explicitly go there: "I need to work in Accounting for this" (&lt;code&gt;actor&lt;/code&gt;), or "I'll handle this in the back office" (&lt;code&gt;@concurrent&lt;/code&gt;).&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting It All Together&lt;/head&gt;
    &lt;p&gt;Let's step back and see how all the pieces fit.&lt;/p&gt;
    &lt;p&gt;Swift Concurrency can feel like a lot of concepts: &lt;code&gt;async/await&lt;/code&gt;, &lt;code&gt;Task&lt;/code&gt;, actors, &lt;code&gt;MainActor&lt;/code&gt;, &lt;code&gt;Sendable&lt;/code&gt;, isolation domains. But there's really just one idea at the center of it all: isolation is inherited by default.&lt;/p&gt;
    &lt;p&gt;With Approachable Concurrency enabled, your app starts on &lt;code&gt;MainActor&lt;/code&gt;. That's your starting point. From there:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Every function you call inherits that isolation&lt;/item&gt;
      &lt;item&gt;Every closure you create captures that isolation&lt;/item&gt;
      &lt;item&gt;Every &lt;code&gt;Task { }&lt;/code&gt;you spawn inherits that isolation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You don't have to annotate anything. You don't have to think about threads. Your code runs on &lt;code&gt;MainActor&lt;/code&gt;, and the isolation just propagates through your program automatically.&lt;/p&gt;
    &lt;p&gt;When you need to break out of that inheritance, you do it explicitly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;@concurrent&lt;/code&gt;says "run this on a background thread"&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;actor&lt;/code&gt;says "this type has its own isolation domain"&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Task.detached { }&lt;/code&gt;says "start fresh, inherit nothing"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And when you pass data between isolation domains, Swift checks that it's safe. That's what &lt;code&gt;Sendable&lt;/code&gt; is for: marking types that can safely cross boundaries.&lt;/p&gt;
    &lt;p&gt;That's it. That's the whole model:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Isolation propagates from &lt;code&gt;MainActor&lt;/code&gt;through your code&lt;/item&gt;
      &lt;item&gt;You opt out explicitly when you need background work or separate state&lt;/item&gt;
      &lt;item&gt;Sendable guards the boundaries when data crosses between domains&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When the compiler complains, it's telling you one of these rules was violated. Trace the inheritance: where did the isolation come from? Where is the code trying to run? What data is crossing a boundary? The answer is usually obvious once you ask the right question.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where to Go From Here&lt;/head&gt;
    &lt;p&gt;The good news: you don't need to master everything at once.&lt;/p&gt;
    &lt;p&gt;Most apps only need the basics. Mark your ViewModels with &lt;code&gt;@MainActor&lt;/code&gt;, use &lt;code&gt;async/await&lt;/code&gt; for network calls, and create &lt;code&gt;Task { }&lt;/code&gt; when you need to kick off async work from a button tap. That's it. That handles 80% of real-world apps. The compiler will tell you if you need more.&lt;/p&gt;
    &lt;p&gt;When you need parallel work, reach for &lt;code&gt;async let&lt;/code&gt; to fetch multiple things at once, or &lt;code&gt;TaskGroup&lt;/code&gt; when the number of tasks is dynamic. Learn to handle cancellation gracefully. This covers apps with complex data loading or real-time features.&lt;/p&gt;
    &lt;p&gt;Advanced patterns come later, if ever. Custom actors for shared mutable state, &lt;code&gt;@concurrent&lt;/code&gt; for CPU-intensive processing, deep &lt;code&gt;Sendable&lt;/code&gt; understanding. This is framework code, server-side Swift, complex desktop apps. Most developers never need this level.&lt;/p&gt;
    &lt;head rend="h4"&gt;Start simple&lt;/head&gt;
    &lt;p&gt;Don't optimize for problems you don't have. Start with the basics, ship your app, and add complexity only when you hit real problems. The compiler will guide you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Watch Out: Common Mistakes&lt;/head&gt;
    &lt;head rend="h3"&gt;Thinking async = background&lt;/head&gt;
    &lt;code&gt;// This STILL blocks the main thread!
@MainActor
func slowFunction() async {
    let result = expensiveCalculation()  // Synchronous work = blocking
    data = result
}&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;async&lt;/code&gt; means "can pause." The actual work still runs wherever it runs. Use &lt;code&gt;@concurrent&lt;/code&gt; (Swift 6.2) or &lt;code&gt;Task.detached&lt;/code&gt; for CPU-heavy work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Creating too many actors&lt;/head&gt;
    &lt;code&gt;// Over-engineered
actor NetworkManager { }
actor CacheManager { }
actor DataManager { }

// Better - most things can live on MainActor
@MainActor
class AppState { }&lt;/code&gt;
    &lt;p&gt;You need a custom actor only when you have shared mutable state that can't live on &lt;code&gt;MainActor&lt;/code&gt;. Matt Massicotte's rule: introduce an actor only when (1) you have non-&lt;code&gt;Sendable&lt;/code&gt; state, (2) operations on that state must be atomic, and (3) those operations can't run on an existing actor. If you can't justify it, use &lt;code&gt;@MainActor&lt;/code&gt; instead.&lt;/p&gt;
    &lt;head rend="h3"&gt;Making everything Sendable&lt;/head&gt;
    &lt;p&gt;Not everything needs to cross boundaries. If you're adding &lt;code&gt;@unchecked Sendable&lt;/code&gt; everywhere, step back and ask if the data actually needs to move between isolation domains.&lt;/p&gt;
    &lt;head rend="h3"&gt;Using MainActor.run when you don't need it&lt;/head&gt;
    &lt;code&gt;// Unnecessary
Task {
    let data = await fetchData()
    await MainActor.run {
        self.data = data
    }
}

// Better - just make the function @MainActor
@MainActor
func loadData() async {
    self.data = await fetchData()
}&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;MainActor.run&lt;/code&gt; is rarely the right solution. If you need MainActor isolation, annotate the function with &lt;code&gt;@MainActor&lt;/code&gt; instead. It's clearer and the compiler can help you more. See Matt's take on this.&lt;/p&gt;
    &lt;head rend="h3"&gt;Blocking the cooperative thread pool&lt;/head&gt;
    &lt;code&gt;// NEVER do this - risks deadlock
func badIdea() async {
    let semaphore = DispatchSemaphore(value: 0)
    Task {
        await doWork()
        semaphore.signal()
    }
    semaphore.wait()  // Blocks a cooperative thread!
}&lt;/code&gt;
    &lt;p&gt;Swift's cooperative thread pool has limited threads. Blocking one with &lt;code&gt;DispatchSemaphore&lt;/code&gt;, &lt;code&gt;DispatchGroup.wait()&lt;/code&gt;, or similar calls can cause deadlocks. If you need to bridge sync and async code, use &lt;code&gt;async let&lt;/code&gt; or restructure to stay fully async.&lt;/p&gt;
    &lt;head rend="h3"&gt;Creating unnecessary Tasks&lt;/head&gt;
    &lt;code&gt;// Unnecessary Task creation
func fetchAll() async {
    Task { await fetchUsers() }
    Task { await fetchPosts() }
}

// Better - use structured concurrency
func fetchAll() async {
    async let users = fetchUsers()
    async let posts = fetchPosts()
    await (users, posts)
}&lt;/code&gt;
    &lt;p&gt;If you're already in an async context, prefer structured concurrency (&lt;code&gt;async let&lt;/code&gt;, &lt;code&gt;TaskGroup&lt;/code&gt;) over creating unstructured &lt;code&gt;Task&lt;/code&gt;s. Structured concurrency handles cancellation automatically and makes the code easier to reason about.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cheat Sheet: Quick Reference&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Keyword&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;async&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Function can pause&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;await&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pause here until done&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Task { }&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start async work, inherits context&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Task.detached { }&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start async work, no inherited context&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;@MainActor&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Runs on main thread&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;actor&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Type with isolated mutable state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nonisolated&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opts out of actor isolation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Sendable&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Safe to pass between isolation domains&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;@concurrent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Always run on background (Swift 6.2+)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;async let&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start parallel work&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;TaskGroup&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dynamic parallel work&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Further Reading&lt;/head&gt;
    &lt;head rend="h4"&gt;Matt Massicotte's Blog (Highly Recommended)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Swift Concurrency Glossary - Essential terminology&lt;/item&gt;
      &lt;item&gt;An Introduction to Isolation - The core concept&lt;/item&gt;
      &lt;item&gt;When should you use an actor? - Practical guidance&lt;/item&gt;
      &lt;item&gt;Non-Sendable types are cool too - Why simpler is better&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46432916</guid><pubDate>Tue, 30 Dec 2025 13:01:51 +0000</pubDate></item><item><title>The British empire's resilient subsea telegraph network</title><link>https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html</link><description>&lt;doc fingerprint="a5d313b1b0391af3"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;The British Empire's Resilient Subsea Telegraph Network&lt;/head&gt;
    &lt;p&gt;The British empire had largely completed its Red Line cable network by 1902. This network allowed news and messages to be delivered in a few minutes or several hours at most depending on the message queue's length. It spanned the globe and formed a network ring so traffic could be routed in the opposite direction in case of disruption. It was, as Dr. Michael Delaunay has argued, a highly resilient network. Besides the ring configuration, the network relied on multiple cables between any pair of given end points to ensure uptime. The British military believed it would be impossible for an enemy to cut enough cables on any route to sever all communications between any given pair of end points. The Committee of Imperial Defense concluded that 57 cables must be shut down to isolate the British Isles from the Red Line network. The figure was 15 for Canada and 7 for South Africa. The Empire was self sufficient in terms of manufacturing the components for a subsea telegraph cable and repairing it. Its navy had no peers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46432999</guid><pubDate>Tue, 30 Dec 2025 13:10:56 +0000</pubDate></item><item><title>No strcpy either</title><link>https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/</link><description>&lt;doc fingerprint="8202bb45bad1df9a"&gt;
  &lt;main&gt;
    &lt;p&gt;Some time ago I mentioned that we went through the curl source code and eventually got rid of all &lt;code&gt;strncpy&lt;/code&gt;() calls.&lt;/p&gt;
    &lt;p&gt;strncpy() is a weird function with a crappy API. It might not null terminate the destination and it pads the target buffer with zeroes. Quite frankly, most code bases are probably better off completely avoiding it because each use of it is a potential mistake.&lt;/p&gt;
    &lt;p&gt;In that particular rewrite when we made strncpy calls extinct, we made sure we would either copy the full string properly or return error. It is rare that copying a partial string is the right choice, and if it is, we can just as well &lt;code&gt;memcpy&lt;/code&gt; it and handle the null terminator explicitly. This meant no case for using strlcpy or anything such either.&lt;/p&gt;
    &lt;head rend="h2"&gt;But strcpy?&lt;/head&gt;
    &lt;p&gt;strcpy however, has its valid uses and it has a less bad and confusing API. The main challenge with strcpy is that when using it we do not specify the length of the target buffer nor of the source string.&lt;/p&gt;
    &lt;p&gt;This is normally not a problem because in a C program &lt;code&gt;strcpy&lt;/code&gt; should only be used when we have full control of both.&lt;/p&gt;
    &lt;p&gt;But normally and always are not necessarily the same thing. We are but all human and we all do mistakes. Using strcpy implies that there is at least one or maybe two, buffer size checks done prior to the function invocation. In a good situation.&lt;/p&gt;
    &lt;p&gt;Over time however ‚Äì let‚Äôs imagine we have code that lives on for decades ‚Äì when code is maintained, patched, improved and polished by many different authors with different mindsets and approaches, those size checks and the function invoke may glide apart. The further away from each other they go, the bigger is the risk that something happens in between that nullifies one of the checks or changes the conditions for the strcpy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enforce checks close to code&lt;/head&gt;
    &lt;p&gt;To make sure that the size checks cannot be separated from the copy itself we introduced a string copy replacement function the other day that takes the target buffer, target size, source buffer and source string length as arguments and only if the copy can be made and the null terminator also fits there, the operation is done.&lt;/p&gt;
    &lt;p&gt;This made it possible to implement the replacement using memcpy(). Now we can completely ban the use of strcpy in curl source code, like we already did strncpy.&lt;/p&gt;
    &lt;p&gt;Using this function version is a little more work and more cumbersome than strcpy since it needs more information, but we believe the upsides of this approach will help us have an oversight for the extra pain involved. I suppose we will see how that will fare down the road. Let‚Äôs come back in a decade and see how things developed!&lt;/p&gt;
    &lt;quote&gt;void curlx_strcopy(char *dest,&lt;lb/&gt;size_t dsize,&lt;lb/&gt;const char *src,&lt;lb/&gt;size_t slen)&lt;lb/&gt;{&lt;lb/&gt;DEBUGASSERT(slen &amp;lt; dsize);&lt;lb/&gt;if(slen &amp;lt; dsize) {&lt;lb/&gt;memcpy(dest, src, slen);&lt;lb/&gt;dest[slen] = 0;&lt;lb/&gt;}&lt;lb/&gt;else if(dsize)&lt;lb/&gt;dest[0] = 0;&lt;lb/&gt;}&lt;/quote&gt;
    &lt;head rend="h2"&gt;AI slop&lt;/head&gt;
    &lt;p&gt;An additional minor positive side-effect of this change is of course that this should effectively prevent the AI chatbots to report strcpy uses in curl source code and insist it is insecure if anyone would ask (as people still apparently do). It has been proven numerous times already that strcpy in source code is like a honey pot for generating hallucinated vulnerability claims.&lt;/p&gt;
    &lt;p&gt;Still, this will just make them find something else to make up a report about, so there is probably no net gain. AI slop is not a game we can win.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46433029</guid><pubDate>Tue, 30 Dec 2025 13:14:40 +0000</pubDate></item><item><title>Igniting the GPU: From Kernel Plumbing to 3D Rendering on RISC-V</title><link>https://mwilczynski.dev/posts/riscv-gpu-zink/</link><description>&lt;doc fingerprint="8fddc85941f0b928"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction: Enabling the Hardware&lt;/head&gt;
    &lt;p&gt;For years, PowerVR GPUs ubiquitous in the embedded world relied entirely on out of tree vendor drivers (often named &lt;code&gt;pvrsrvkm&lt;/code&gt;). While source code was provided in Board Support Packages, these drivers were never accepted into the mainline kernel due to their non standard architecture.&lt;/p&gt;
    &lt;p&gt;That changed when Imagination Technologies announced their commitment to an upstream, open source driver. The resulting &lt;code&gt;drm/imagination&lt;/code&gt; driver has been upstream for some time, but it wasn‚Äôt usable on RISC-V platforms like the T-HEAD TH1520 (used in the Lichee Pi 4A).&lt;/p&gt;
    &lt;p&gt;This marks a significant milestone: with the enablement work described below, the TH1520 becomes the first RISC-V SoC to feature fully mainline, hardware accelerated 3D graphics support.&lt;/p&gt;
    &lt;p&gt;This effort has followed a long road of development, generating significant community interest along the way from the initial driver support discussions to the power sequencing challenges, and finally culminating in the official upstream merge in Linux 6.18.&lt;/p&gt;
    &lt;p&gt;While the GPU driver itself is generic, the hardware surrounding the GPU on this SoC specifically the power, clock, and reset controllers required significant enablement work before the GPU could actually be probed.&lt;/p&gt;
    &lt;p&gt;This post details the architectural ‚Äúplumbing‚Äù required to bring up the full graphics stack on the TH1520. This involved implementing the necessary platform drivers to handle the SoC‚Äôs power sequencing, enabling the mainline &lt;code&gt;drm/imagination&lt;/code&gt; driver for RISC-V, and validating the stack with a modern, Vulkan based userspace.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 1: The Dependency Chain&lt;/head&gt;
    &lt;p&gt;Enabling the GPU wasn‚Äôt just a matter of changing a Kconfig entry. The TH1520 GPU subsystem is gated behind a chain of hardware dependencies that had no existing Linux drivers.&lt;/p&gt;
    &lt;p&gt;To reach the point where I could submit the final patch enabling the PowerVR driver for RISC-V, I first had to implement and upstream the drivers for these underlying subsystems.&lt;/p&gt;
    &lt;p&gt;The hierarchy looks like this, from the bottom up:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Mailbox (&lt;code&gt;mailbox-th1520&lt;/code&gt;): The SoC uses a safety coprocessor (E902) to manage power. The first step was writing a mailbox driver to establish a physical communication link between the main CPUs and this coprocessor.&lt;/item&gt;
      &lt;item&gt;Firmware Protocol (&lt;code&gt;thead-aon-protocol&lt;/code&gt;): On top of the mailbox, I implemented the AON (Always-On) firmware protocol. This driver handles the specific message format required to request power state changes from the coprocessor.&lt;/item&gt;
      &lt;item&gt;Power Domains (&lt;code&gt;pmdomain-thead&lt;/code&gt;): With the protocol active, I could expose the GPU‚Äôs power rail as a standard Linux Generic Power Domain (GenPD). This allows the kernel to manage the GPU‚Äôs power state generically.&lt;/item&gt;
      &lt;item&gt;Resets and Clocks: Finally, I extended the clock driver (&lt;code&gt;clk-th1520-vo&lt;/code&gt;) and implemented a new reset controller (&lt;code&gt;reset-th1520&lt;/code&gt;) to handle the specific requirements of the Video Output (VO) subsystem where the GPU resides.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The Power Sequencer: A Novel Application&lt;/head&gt;
    &lt;p&gt;With the platform drivers in place, one integration challenge remained. The TH1520 requires a specific, time sensitive sequence to power up the GPU: enable the power domain, wait for voltage stabilization, and then de-assert resets in a specific order.&lt;/p&gt;
    &lt;p&gt;Historically, power sequencing in the kernel was mostly confined to the MMC/Bluetooth subsystems (for toggling GPIOs on WiFi chips). However, the kernel recently introduced a generic Power Sequencing (&lt;code&gt;pwrseq&lt;/code&gt;) subsystem (authored by Bartosz Golaszewski) to standardize this problem.&lt;/p&gt;
    &lt;p&gt;During the upstream review process, Ulf Hansson (the Power Management subsystem maintainer) suggested that the TH1520‚Äôs GPU was the perfect candidate for this new framework. It behaves almost like an external component: it needs a dedicated ‚Äúmanager‚Äù to orchestrate its wake-up routine before the main driver can even touch it.&lt;/p&gt;
    &lt;p&gt;I implemented this in &lt;code&gt;pwrseq-thead-gpu&lt;/code&gt;. The most interesting part of this driver is the &lt;code&gt;match&lt;/code&gt; function, which allows the sequencer to ‚Äúadopt‚Äù the GPU‚Äôs resources:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;The Integration in &lt;code&gt;drm/imagination&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;To make this work, I also had to introduce a small but strategic change to the generic &lt;code&gt;drm/imagination&lt;/code&gt; driver (see commit &lt;code&gt;e38e8391f30b&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Following a suggestion from Matt Coster, I implemented a new abstraction, &lt;code&gt;pvr_power_sequence_ops&lt;/code&gt;. This interface allows the driver to select its power strategy at runtime based on the device compatible string, keeping the core driver logic generic while accommodating platform specific needs.&lt;/p&gt;
    &lt;p&gt;For the TH1520, the driver simply selects the &lt;code&gt;pwrseq&lt;/code&gt; backend:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;This architecture offers three major benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clean Abstraction: The GPU driver doesn‚Äôt need to know about T-HEAD‚Äôs specific reset order or microsecond delays. It simply calls the generic &lt;code&gt;pwr_ops-&amp;gt;power_on()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Inversion of Control: The sequencer ‚Äústeals‚Äù the resource handles (clocks and resets) from the GPU‚Äôs device tree node during the match phase (lines 19-24 in the first snippet). This allows the sequencer to control resources that conceptually belong to the GPU, ensuring the correct power up order without modifying the GPU driver logic.&lt;/item&gt;
      &lt;item&gt;Strict Ordering: By centralizing this logic in a dedicated driver, we guarantee that the &lt;code&gt;clkgen&lt;/code&gt;reset (controlled by the parent node) and the&lt;code&gt;gpu_core&lt;/code&gt;reset (controlled by the consumer node) are de-asserted in the exact order required by the hardware manual.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Part 2: The Display Pipeline (Connecting the Pixels)&lt;/head&gt;
    &lt;p&gt;Powering up the GPU is a massive victory, but it solves only half the problem. A GPU can render beautiful 3D scenes into memory, but without a Display Controller to scan those buffers out to a screen, you‚Äôre still looking at a black terminal.&lt;/p&gt;
    &lt;p&gt;On the TH1520, the display duties are handled by a Verisilicon DC8200 IP block, connected to a Synopsys DesignWare HDMI bridge.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Ecosystem Note: If you are following the RISC-V space, this IP might sound familiar. The StarFive JH7110 (used in the VisionFive 2) uses the exact same Verisilicon DC8200 display controller.&lt;/p&gt;
      &lt;p&gt;I am actually working on enabling the display stack for the JH7110 in parallel. While the IP is the same, the integration is vastly different the JH7110 has a complex circular dependency between the HDMI PHY and the clock generator that requires a complete architectural rethink. But that is a story for a future blog post.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;The Collaborative Puzzle&lt;/head&gt;
    &lt;p&gt;While I focused on the TH1520 power sequencing and GPU enablement, the display driver work here was led by Icenowy Zheng, another brilliant engineer in the RISC-V ecosystem.&lt;/p&gt;
    &lt;p&gt;This is the beauty of upstream kernel development: you don‚Äôt have to build the world alone. Icenowy has been working on a generic DRM driver for Verisilicon display controllers, adapting it to support the specific HDMI PHY found on the TH1520.&lt;/p&gt;
    &lt;p&gt;Since these patches are currently in the review process (v4), they aren‚Äôt in mainline yet. To build the working demo, I applied Icenowy‚Äôs patch series on top of mainline kernel.&lt;/p&gt;
    &lt;p&gt;With Icenowy‚Äôs display driver handling the ‚Äúscan out‚Äù and my infrastructure handling the ‚Äúpower up,‚Äù we finally had a complete pipeline: Memory -&amp;gt; GPU Render -&amp;gt; Memory -&amp;gt; Display Controller -&amp;gt; HDMI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 3: The ‚ÄúVulkan-Only‚Äù Future&lt;/head&gt;
    &lt;p&gt;Now that the kernel could talk to the hardware, we needed a userspace stack to render graphics.&lt;/p&gt;
    &lt;p&gt;Historically, enabling a new GPU meant writing two massive drivers for Mesa: one for Vulkan and one for OpenGL. But the open-source graphics world has shifted. The &lt;code&gt;drm/imagination&lt;/code&gt; driver is designed to be Vulkan-native.&lt;/p&gt;
    &lt;p&gt;Instead of writing a complex, legacy OpenGL driver, we use Zink.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Stack: Rendering vs. Display&lt;/head&gt;
    &lt;p&gt;Since the TH1520 uses a split DRM architecture, the flow isn‚Äôt just a straight line. The GPU and Display Controller are separate devices that share data via memory (DMA-BUF).&lt;/p&gt;
    &lt;code&gt;      [ Application (glmark2) ]
                 ‚îÇ
                 ‚ñº
      [    Zink (OpenGL)      ]
                 ‚îÇ
                 ‚ñº
      [ Mesa PowerVR (Vulkan) ]
                 ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ     Linux Kernel    ‚îÇ
      ‚ñº                     ‚ñº
[ GPU Driver ]       [ Display Driver ]
 (Render Node)         (KMS/Card Node)
      ‚îÇ                     ‚îÇ
      ‚ñº        DMA-BUF      ‚ñº
 [ GPU HW ] ‚îÄ‚îÄ(Memory)‚îÄ‚îÄ‚ñ∂ [ Display HW ] ‚îÄ‚îÄ‚ñ∂ HDMI&lt;/code&gt;
    &lt;p&gt;This separation is why the kernel plumbing in Part 1 (GPU) and Part 2 (Display) had to be done independently before they could work together.&lt;/p&gt;
    &lt;head rend="h3"&gt;Building the Stack (Reproduction Guide)&lt;/head&gt;
    &lt;p&gt;For those who want to reproduce this on their own Lichee Pi 4A, exact version matching is critical.&lt;/p&gt;
    &lt;p&gt;1. The Kernel I used Linux 6.19 as the base, with unmerged Display Controller patches applied on top. You can find the exact tree here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kernel Branch: &lt;code&gt;github.com/mwilczy/linux/tree/blog_code&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Mesa (Userspace) I used a fork of Icenowy Zheng‚Äôs work, which includes the necessary glue to make Zink play nicely with this specific hardware combination.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mesa Branch: &lt;code&gt;github.com/mwilczy/mesa&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here is the exact Meson configuration I used to build a pure Vulkan+Zink stack:&lt;/p&gt;
    &lt;code&gt;meson setup build \
    -D buildtype=release \
    -D platforms=x11,wayland \
    -D vulkan-drivers=imagination \
    -D gallium-drivers=zink \
    -D glx=disabled \
    -D gles1=disabled \
    -D gles2=enabled \
    -D egl=enabled \
    -D tools=imagination \
    -D glvnd=disabled&lt;/code&gt;
    &lt;head rend="h2"&gt;Part 4: The Result&lt;/head&gt;
    &lt;p&gt;With the kernel compiled (including the pending display patches) and the Mesa stack built, we can finally run accelerated 3D workloads.&lt;/p&gt;
    &lt;head rend="h3"&gt;The ‚ÄúSecret Sauce‚Äù (Environment Variables)&lt;/head&gt;
    &lt;p&gt;Because the driver is still in active development and not yet fully conformant, we need to pass a few flags to convince Mesa to run.&lt;/p&gt;
    &lt;p&gt;The most important one is &lt;code&gt;PVR_I_WANT_A_BROKEN_VULKAN_DRIVER=1&lt;/code&gt;. Without this, the driver safeguards would prevent loading. We also force the use of the Zink driver and explicitly select our device:&lt;/p&gt;
    &lt;code&gt;export PVR_I_WANT_A_BROKEN_VULKAN_DRIVER=1
export GALLIUM_DRIVER=zink
export MESA_VK_DEVICE_SELECT=1010:36104182!&lt;/code&gt;
    &lt;head rend="h3"&gt;The Benchmark&lt;/head&gt;
    &lt;p&gt;I started a Weston compositor session using the DRM backend:&lt;/p&gt;
    &lt;code&gt;weston --backend=drm-backend.so --continue-without-input &amp;amp;&lt;/code&gt;
    &lt;p&gt;And then, the moment of truth - running &lt;code&gt;glmark2-es2-wayland&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Above: glmark2 running on the Lichee Pi 4A.&lt;/p&gt;
    &lt;p&gt;Here is the output, confirming we are running fully accelerated on the PowerVR GPU via Zink:&lt;/p&gt;
    &lt;code&gt;root@revyos-lpi4a:~/test_mesa/Vulkan/build4/bin# glmark2-es2-wayland
MESA: warning: Core count fetching is unimplemented. Setting 1 for now.
WARNING: powervr is not a conformant Vulkan implementation, testing use only.
=======================================================
    glmark2 2023.01
=======================================================
    OpenGL Information
    GL_VENDOR:      Mesa
    GL_RENDERER:    zink Vulkan 1.2(PowerVR B-Series BXM-4-64 MC1 (IMAGINATION_OPEN_SOURCE_MESA))
    GL_VERSION:     OpenGL ES 2.0 Mesa 26.0.0-devel (git-601d20e81e)
    Surface Config: buf=32 r=8 g=8 b=8 a=8 depth=24 stencil=0 samples=0
    Surface Size:   800x600 windowed
=======================================================
[build] use-vbo=false:[  510.861554] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 524288 bytes), total 32768 (slots), used 4 (slots)
[  510.887018] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1847296 bytes), total 32768 (slots), used 36 (slots)
[  510.900771] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1847296 bytes), total 32768 (slots), used 36 (slots)
[  510.923956] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1921024 bytes), total 32768 (slots), used 0 (slots)
[  510.954656] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 458752 bytes), total 32768 (slots), used 0 (slots)
[  510.966931] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 458752 bytes), total 32768 (slots), used 0 (slots)
[  511.038586] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1921024 bytes), total 32768 (slots), used 0 (slots)
[  512.165193] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1900544 bytes), total 32768 (slots), used 10 (slots)
[  512.187871] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 1900544 bytes), total 32768 (slots), used 10 (slots)
[  512.209524] verisilicon-dc ffef600000.display: swiotlb buffer is full (sz: 745472 bytes), total 32768 (slots), used 0 (slots)
 FPS: 67 FrameTime: 14.960 ms
[build] use-vbo=true: FPS: 98 FrameTime: 10.252 ms
[texture] texture-filter=nearest: FPS: 97 FrameTime: 10.332 ms
[texture] texture-filter=linear: FPS: 93 FrameTime: 10.868 ms
[texture] texture-filter=mipmap: FPS: 101 FrameTime: 9.957 ms
[shading] shading=gouraud: FPS: 93 FrameTime: 10.851 ms
[shading] shading=blinn-phong-inf: FPS: 98 FrameTime: 10.274 ms
[shading] shading=phong: FPS: 97 FrameTime: 10.356 ms
[shading] shading=cel: FPS: 91 FrameTime: 11.086 ms
[bump] bump-render=high-poly: FPS: 75 FrameTime: 13.404 ms
[bump] bump-render=normals: FPS: 97 FrameTime: 10.356 ms
[bump] bump-render=height: FPS: 88 FrameTime: 11.449 ms
[effect2d] kernel=0,1,0;1,-4,1;0,1,0;: FPS: 94 FrameTime: 10.646 ms
[effect2d] kernel=1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;: FPS: 57 FrameTime: 17.590 ms
[pulsar] light=false:quads=5:texture=false: FPS: 92 FrameTime: 10.953 ms
[desktop] blur-radius=5:effect=blur:passes=1:separable=true:windows=4: FPS: 10 FrameTime: 105.957 ms
[desktop] effect=shadow:windows=4: FPS: 37 FrameTime: 27.465 ms

...&lt;/code&gt;
    &lt;p&gt;We have successfully turned ‚Äúdark silicon‚Äù into a modern, Vulkan capable graphics platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Bringing a new GPU architecture to life in the mainline kernel is never a solo effort. It requires navigating complex subsystems - from power domains to clocks and relies heavily on the patience and expertise of subsystem maintainers.&lt;/p&gt;
    &lt;p&gt;This work went through many iterations, and the code is significantly better thanks to the rigorous feedback from the community.&lt;/p&gt;
    &lt;p&gt;A huge thank you to everyone who helped review the code, suggested architectural improvements, and tested the stack:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Marek Szyprowski - For the guidance and mentorship throughout the upstreaming process.&lt;/item&gt;
      &lt;item&gt;Drew Fustini - For his long standing work maintaining the TH1520 platform.&lt;/item&gt;
      &lt;item&gt;Krzysztof Koz≈Çowski - For ensuring the Device Tree bindings were strictly compliant.&lt;/item&gt;
      &lt;item&gt;Ulf Hansson - For his guidance on the AON power domains and for suggesting the use of the Power Sequencing framework, which simplified the architecture significantly.&lt;/item&gt;
      &lt;item&gt;Bartosz Go≈Çaszewski - For creating the Power Sequencing subsystem and helping merge the TH1520 driver.&lt;/item&gt;
      &lt;item&gt;Matt Coster - For reviewing the driver changes and helping navigate the PowerVR internals.&lt;/item&gt;
      &lt;item&gt;Stephen Boyd - For the feedback on the video output clock controller.&lt;/item&gt;
      &lt;item&gt;Philipp Zabel - For reviewing the reset controller implementation.&lt;/item&gt;
      &lt;item&gt;Icenowy Zheng - For the incredible work on the display controller and Mesa/Zink integration.&lt;/item&gt;
      &lt;item&gt;Jassi Brar - For reviewing the mailbox driver implementation.&lt;/item&gt;
      &lt;item&gt;Conor Dooley - For reviewing Device Tree patches.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46433352</guid><pubDate>Tue, 30 Dec 2025 13:55:59 +0000</pubDate></item><item><title>Hive (YC S14) Is Hiring a Staff Software Engineer (Data Systems)</title><link>https://jobs.ashbyhq.com/hive.co/cb0dc490-0e32-4734-8d91-8b56a31ed497</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46433661</guid><pubDate>Tue, 30 Dec 2025 14:31:34 +0000</pubDate></item><item><title>What Happened to Abit Motherboards</title><link>https://dfarq.homeip.net/what-happened-to-abit-motherboards/</link><description>&lt;doc fingerprint="39579387f502b633"&gt;
  &lt;main&gt;
    &lt;p&gt;At the end of the year in 2008, one of the most legendary motherboard manufacturers of all time sadly went out of business. I am talking about Abit. What happened to Abit motherboards? A combination of factors took it down, including declining quality, loss of a key engineer, and a good old-fashioned scandal.&lt;/p&gt;
    &lt;head rend="h2"&gt;Abit took 7 years to become an overnight sensation&lt;/head&gt;
    &lt;p&gt;Abit wasn‚Äôt exactly a newcomer when I first learned about them in 1996. The company was founded in 1989 and made a number of 386SX, 386DX, and 486 motherboards. But it was the early hardware sites like Tom‚Äôs Hardware Guide and Anandtech that really helped to put Abit on the map during the Socket 7 era and distinguish them from the rest of the Taiwainese motherboard makers. The Abit IT5H was a Socket 7 board based on the Intel 430HX chipset that performed extremely well.&lt;/p&gt;
    &lt;head rend="h3"&gt;The jumperless Abit IT5H&lt;/head&gt;
    &lt;p&gt;Thing is, we already had an HX-based board that performed really well. Asus had those bases covered with its P55T2P4. What made Abit special was its board was jumperless. When you installed a processor, it initialized it using safe settings, and then you could go in and configure it to run at the speed you wanted using a feature called the CPU Softmenu. The Softmenu allowed you to change voltages and front side bus speed, not just the multiplier. You could even run your CPU at non-standard bus speeds like 75 or 83 MHz. Running a 166 MHz CPU at 83 MHz with a 2X multiplier actually ran faster than a 200 MHz CPU on a 66 MHz bus with a 3X multiplier. If you actually owned a 200 MHz processor, or a processor that overclocked well, you could run it at 83 MHz with a multiplier of 2.5, reach 208 MHz, and run rings around a CPU running on a 66 MHz bus with a 3x multiplier. It was the ultimate Socket 7 system at the time.&lt;/p&gt;
    &lt;p&gt;Overclockers loved the IT5H because they could easily test settings without looking up jumper settings and changing clumsy jumper blocks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Abit BP6: Dual CPUs on a budget&lt;/head&gt;
    &lt;p&gt;And then there was the legendary Abit BP6. Socket 370 era Celeron processors had a Pentium II core, but Intel disabled the ability to change the multiplier to discourage overclocking and they also disabled the ability to run them in multi-processor configurations. Enthusiasts figured out that if they wired the processors up a bit differently, they could restore the multiprocessor capability. With the BP6, Abit made that unnecessary. They just wired the board up so that you could drop a pair of cheap Celeron processors into it and have a very inexpensive dual CPU setup.&lt;/p&gt;
    &lt;head rend="h2"&gt;What happened to Abit to cause its demise?&lt;/head&gt;
    &lt;p&gt;One major problem for Abit was the quality of the capacitors they used was not as high as Asus. That meant Abit motherboards didn‚Äôt age as well as Asus boards did. Arguably, in the ‚Äô90s, that wasn‚Äôt as huge of a problem because enthusiasts would upgrade every 2 or 3 years. As long as the board lasted 3 years, nobody noticed. But as the century turned, people started expecting to be able to keep their computers a little bit longer. Abit‚Äôs propensity to go cheap on the capacitors left it extremely vulnerable when capacitor plague kicked in, and indeed, Abit was one of the hardest hit.&lt;/p&gt;
    &lt;p&gt;Starting in 2002, Abit started outsourcing production of some low end boards to Elite Computer Systems, a notorious cost-cutting manufacturer. You bought from companies like Abit to avoid accidentally buying a no-name board actually made by ECS. So this was problematic.&lt;/p&gt;
    &lt;p&gt;Abit suffered a major blow in March 2003 when Oscar Wu, the mastermind behind the CPU Softmenu and much of the hardware design, departed Abit for rival motherboard maker DFI.&lt;/p&gt;
    &lt;p&gt;But perhaps the biggest problem came in December 2004, when questionable accounting practices caused its stock to be delisted. Abit had been inflating its counts and potentially embezzling funds. It wasn‚Äôt quite Miniscribe or Media Vision, let alone Worldcom. But adding fraud and dishonesty to a reputation for declining quality isn‚Äôt a recipe for longevity.&lt;/p&gt;
    &lt;p&gt;On 25 January 2006, Abit sold itself to Universal Scientific Industrial. USI sold motherboards under the new brand name Universal Abit. But the venture wasn‚Äôt successful, and Universal Abit announced that it would close December 31, 2008, and officially cease to exist on January 1, 2009.&lt;/p&gt;
    &lt;head rend="h3"&gt;Abit‚Äôs legacy&lt;/head&gt;
    &lt;p&gt;Today, Abit motherboards are prized by collectors, but if you want to actually use them, you will need to replace the capacitors. That said, if you use high quality, brand name capacitors, the boards will perform. Likely they‚Äôll do better than they did when they were new, since the classic-era Abit boards tended to be really well built. It‚Äôs unfortunate that Abit cheaped out on the capacitors.&lt;/p&gt;
    &lt;p&gt;David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46433915</guid><pubDate>Tue, 30 Dec 2025 14:58:18 +0000</pubDate></item><item><title>Show HN: Tidy Baby is a SET game but with words</title><link>https://tidy.baby</link><description>&lt;doc fingerprint="1e8bfdcd154f754e"&gt;
  &lt;main&gt;
    &lt;p&gt;If you know how to play SET you basically know how to play Tidy Baby ‚Äî the "dimensions" are just:&lt;/p&gt;
    &lt;p&gt;If you don't know how to play SET, we recommend checking out the How To Play page.&lt;/p&gt;
    &lt;p&gt;Make sets. Clean board.&lt;/p&gt;
    &lt;p&gt;No sets guessed yet...&lt;/p&gt;
    &lt;p&gt;Final Score:&lt;/p&gt;
    &lt;p&gt;Total Time:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46434580</guid><pubDate>Tue, 30 Dec 2025 15:57:01 +0000</pubDate></item><item><title>Show HN: Replacing my OS process scheduler with an LLM</title><link>https://github.com/mprajyothreddy/brainkernel</link><description>&lt;doc fingerprint="6cb75c5238a42691"&gt;
  &lt;main&gt;
    &lt;code&gt;‚îè‚îì ‚îè‚îÅ‚îì‚îè‚îÅ‚îì‚ïª‚îè‚îì‚ïª‚ïª‚îè ‚îè‚îÅ‚ï∏‚îè‚îÅ‚îì‚îè‚îì‚ïª‚îè‚îÅ‚ï∏‚ïª  
‚î£‚îª‚îì‚î£‚î≥‚îõ‚î£‚îÅ‚î´‚îÉ‚îÉ‚îó‚î´‚î£‚îª‚îì‚î£‚ï∏ ‚î£‚î≥‚îõ‚îÉ‚îó‚î´‚î£‚ï∏ ‚îÉ  
‚îó‚îÅ‚îõ‚ïπ‚îó‚ï∏‚ïπ ‚ïπ‚ïπ‚ïπ ‚ïπ‚ïπ ‚ïπ‚îó‚îÅ‚ï∏‚ïπ‚îó‚ï∏‚ïπ ‚ïπ‚îó‚îÅ‚ï∏‚îó‚îÅ‚ï∏                                                                                                             
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;"What if the Linux Kernel had a prefrontal cortex?"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;"Task Manager is boring. BrainKernel is judgmental."&lt;/p&gt;
    &lt;p&gt;BrainKernel is a TUI (Terminal User Interface) process manager that uses an LLM to analyze why a process is running. It doesn't just show CPU usage; it looks at parentage, disk I/O, and behavior history to distinguish between "Critical System Update" (Safe) and "Vendor Bloatware" (Kill).&lt;/p&gt;
    &lt;p&gt;v3.4.0 "The Silent Guardian" Update:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Diplomatic Immunity: Automatically detects and protects browsers, chat apps, and IDEs. It will roast them for high CPU usage, but it will never kill them.&lt;/item&gt;
      &lt;item&gt;Stealth Mode: Disguises API traffic to work seamlessly with cloud providers (Groq).&lt;/item&gt;
      &lt;item&gt;&amp;lt;1% CPU: Uses Delta Caching to monitor 300+ processes without lagging your machine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cloud &amp;amp; Local: Built for Groq (Cloud) or Ollama (Local). Perfect for laptops that can't run local models.&lt;/item&gt;
      &lt;item&gt;Context Aware: It knows that &lt;code&gt;chrome.exe&lt;/code&gt;using 40% CPU is probably a video call (Ignore), but&lt;code&gt;McAfee.exe&lt;/code&gt;using 40% CPU is a crime (Kill).&lt;/item&gt;
      &lt;item&gt;Roast Mode: It doesn't just kill processes; it insults them first.&lt;/item&gt;
      &lt;item&gt;Hall of Shame: Keeps a permanent record of the worst offenders and the roasts they received.&lt;/item&gt;
      &lt;item&gt;Focus Mode: Define a "Focus App" (e.g., VS Code), and it will aggressively suspend background distractions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since you aren't running a local LLM, you will use the Groq API (It's free and extremely fast).&lt;/p&gt;
    &lt;code&gt;pip install psutil textual&lt;/code&gt;
    &lt;code&gt;python main.py&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get a free API Key from console.groq.com.&lt;/item&gt;
      &lt;item&gt;Launch BrainKernel.&lt;/item&gt;
      &lt;item&gt;Press &lt;code&gt;k&lt;/code&gt;to open the Key Manager.&lt;/item&gt;
      &lt;item&gt;Paste your key (starts with &lt;code&gt;gsk_...&lt;/code&gt;) and hit Enter.&lt;list rend="ul"&gt;&lt;item&gt;Your key is saved locally in &lt;code&gt;~/.brainkernel.json&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Your key is saved locally in &lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;k&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Key Config&lt;/cell&gt;
        &lt;cell&gt;Enter your Groq API key.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;n&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Roast Now&lt;/cell&gt;
        &lt;cell&gt;Force the AI to analyze and roast the top CPU hog immediately.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;p&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Protect&lt;/cell&gt;
        &lt;cell&gt;Toggle protection for the selected PID (Green status).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;x&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Begone!&lt;/cell&gt;
        &lt;cell&gt;Ban a process name. Future instances will be auto-killed on sight.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;s&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Shame&lt;/cell&gt;
        &lt;cell&gt;View the "Hall of Shame" (best roasts log).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;f&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Focus&lt;/cell&gt;
        &lt;cell&gt;Set a "Focus App". Distractions using &amp;gt;5% CPU will be suspended.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;r&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Resume&lt;/cell&gt;
        &lt;cell&gt;Resume all suspended processes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;q&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quit&lt;/cell&gt;
        &lt;cell&gt;Exit BrainKernel.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;BrainKernel is designed to be safe, even when the AI is sassy.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Diplomatic Immunity: Hardcoded protection for &lt;code&gt;browser&lt;/code&gt;,&lt;code&gt;social&lt;/code&gt;,&lt;code&gt;gaming&lt;/code&gt;, and&lt;code&gt;dev_tool&lt;/code&gt;categories.&lt;/item&gt;
      &lt;item&gt;PID Safety Lock: Before killing anything, it verifies the target's &lt;code&gt;create_time&lt;/code&gt;. If a PID was recycled by the OS in the last 100ms, the kill is aborted.&lt;/item&gt;
      &lt;item&gt;Debouncing: It remembers decisions for 5 minutes. It won't spam you about the same process twice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Found a new vendor bloatware process? PRs welcome to the &lt;code&gt;BLOATWARE&lt;/code&gt; list in &lt;code&gt;main.py&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Built with Python &amp;amp; Textual. Powered by Llama 3.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46435142</guid><pubDate>Tue, 30 Dec 2025 16:47:37 +0000</pubDate></item><item><title>Show HN: 22 GB of Hacker News in SQLite</title><link>https://hackerbook.dosaygo.com</link><description>&lt;doc fingerprint="60e736960d5d7ecf"&gt;
  &lt;main&gt;
    &lt;p&gt;Hacker Book new | front | start | ask | show | jobs | query Someday, Month 00, 0000 &amp;lt; &amp;gt; ARCHIVE Loading‚Ä¶ Y Combinator | Apply | Companies | Blog | Live HN | Contact &amp;lt; &amp;gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46435308</guid><pubDate>Tue, 30 Dec 2025 17:01:59 +0000</pubDate></item><item><title>Toro: Deploy Applications as Unikernels</title><link>https://github.com/torokernel/torokernel</link><description>&lt;doc fingerprint="3069f0a7771d385"&gt;
  &lt;main&gt;
    &lt;p&gt;Toro is a unikernel dedicated to deploy applications as microVMs. Toro leverages on virtio-fs and virtio-vsocket to provide a minimalistic architecture.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support x86-64 architecture&lt;/item&gt;
      &lt;item&gt;Support up to 512GB of RAM&lt;/item&gt;
      &lt;item&gt;Support QEMU-KVM microvm and Firecracker&lt;/item&gt;
      &lt;item&gt;Cooperative and I/O bound threading scheduler&lt;/item&gt;
      &lt;item&gt;Support virtio-vsocket for networking&lt;/item&gt;
      &lt;item&gt;Support virtio-fs for filesystem&lt;/item&gt;
      &lt;item&gt;Fast boot up&lt;/item&gt;
      &lt;item&gt;Tiny image&lt;/item&gt;
      &lt;item&gt;Built-in gdbstub&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can try Toro by running the HelloWorld example using a Docker image that includes all the required tools. To do so, execute the following commands in a console (these steps require you to install before KVM and Docker):&lt;/p&gt;
    &lt;code&gt;wget https://raw.githubusercontent.com/torokernel/torokernel/master/ci/Dockerfile
sudo docker build -t torokernel-dev .
sudo docker run --privileged --rm -it torokernel-dev
cd examples/HelloWorld
python3 ../CloudIt.py -a HelloWorld&lt;/code&gt;
    &lt;p&gt;If these commands execute successfully, you will get the output of the HelloWorld example. You can also pull the image from dockerhub instead of building it:&lt;/p&gt;
    &lt;code&gt;sudo docker pull torokernel/torokernel-dev:latest
sudo docker run --privileged --rm -it torokernel/torokernel-dev:latest&lt;/code&gt;
    &lt;p&gt;You can share a directory from the host by running:&lt;/p&gt;
    &lt;code&gt;sudo docker run --privileged --rm --mount type=bind,source="$(pwd)",target=/root/torokernel -it torokernel/torokernel-dev:latest&lt;/code&gt;
    &lt;p&gt;You will find $pwd from host at &lt;code&gt;/root/torokernel&lt;/code&gt; in the container.&lt;/p&gt;
    &lt;p&gt;Execute the commands in &lt;code&gt;ci/Dockerfile&lt;/code&gt; to install the required components locally. Then, Go to &lt;code&gt;torokernel/examples&lt;/code&gt; and edit &lt;code&gt;CloudIt.py&lt;/code&gt; to set the correct paths to Qemu and fpc. Optionally, you can install vsock-socat from here and virtio-fs from here. You need to set the correct path to virtiofsd and socat.&lt;/p&gt;
    &lt;p&gt;Go to &lt;code&gt;examples/HelloWorld/&lt;/code&gt; and execute:&lt;/p&gt;
    &lt;code&gt;python3 ../CloudIt.py -a HelloWorld&lt;/code&gt;
    &lt;p&gt;To run the StaticWebserver, you require virtiofsd and socat. To compile socat, execute the following commands:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:stefano-garzarella/socat-vsock.git
cd socat-vsock
autoreconf -fiv
./configure
make socat&lt;/code&gt;
    &lt;p&gt;Set the path to socat binary in CloudIt.py and then execute:&lt;/p&gt;
    &lt;code&gt;python3 ../CloudIt.py -a StaticWebServer -r -d /path-to-directory/ -f 4000:80&lt;/code&gt;
    &lt;p&gt;You have to replace the &lt;code&gt;/path-to-directory/&lt;/code&gt; to a directory that containing the files, e.g., index.html. To try it, you can execute:&lt;/p&gt;
    &lt;code&gt;wget http://127.0.0.1:4000/index.html
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;-f&lt;/code&gt; parameter indicates a forwarding of the 4000 port from the host to the 80 port in the guest using vsock.&lt;/p&gt;
    &lt;p&gt;This example shows how cores can communicate by using the VirtIOBus device. In this example, core #0 sends a packet to every core in the system with the ping string. Each core responds with a packet that contains the message pong. This example is configured to use three cores. To launch it, simply executes the following commands in the context of the container presented above:&lt;/p&gt;
    &lt;code&gt;python3 ../CloudIt.py -a InterCoreComm&lt;/code&gt;
    &lt;p&gt;You will get the following output:&lt;/p&gt;
    &lt;p&gt;You have many ways to contribute to Toro. One of them is by joining the Google Group here. In addition, you can find more information here.&lt;/p&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;[0] A Dedicated Kernel named Toro. Matias Vara. FOSDEM 2015.&lt;/p&gt;
    &lt;p&gt;[1] Reducing CPU usage of a Toro Appliance. Matias Vara. FOSDEM 2018.&lt;/p&gt;
    &lt;p&gt;[2] Toro, a Dedicated Kernel for Microservices. Matias Vara and Cesar Bernardini. Open Source Summit Europe 2018.&lt;/p&gt;
    &lt;p&gt;[3] Speeding Up the Booting Time of a Toro Appliance. Matias Vara. FOSDEM 2019.&lt;/p&gt;
    &lt;p&gt;[4] Developing and Deploying Microservices with Toro Unikernel. Matias Vara. Open Source Summit Europe 2019.&lt;/p&gt;
    &lt;p&gt;[5] Leveraging Virtio-fs and Virtio-vsocket in Toro Unikernel. Matias Vara. DevConfCZ 2020.&lt;/p&gt;
    &lt;p&gt;[6] Building a Cloud Infrastructure to Deploy Microservices as Microvm Guests. Matias Vara. KVM Forum 2020.&lt;/p&gt;
    &lt;p&gt;[7] Running MPI applications on Toro unikernel. Matias Vara. FOSDEM 2023.&lt;/p&gt;
    &lt;p&gt;[8] Is Toro unikernel faster for MPI?. Matias Vara. FOSDEM 2024.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46435418</guid><pubDate>Tue, 30 Dec 2025 17:09:57 +0000</pubDate></item><item><title>A Vulnerability in Libsodium</title><link>https://00f.net/2025/12/30/libsodium-vulnerability/</link><description>&lt;doc fingerprint="1c17b053a8636291"&gt;
  &lt;main&gt;
    &lt;p&gt;Libsodium is now 13 years old!&lt;/p&gt;
    &lt;p&gt;I started that project to pursue Dan Bernstein√¢s desire to make cryptography simple to use. That meant exposing a limited set of high-level functions and parameters, providing a simple API, and writing documentation for users, not cryptographers or developers. Libsodium√¢s goal was to expose APIs to perform operations, not low-level functions. Users shouldn√¢t even have to know or care about what algorithms are used internally. This is how I√¢ve always viewed libsodium.&lt;/p&gt;
    &lt;p&gt;Never breaking the APIs is also something I√¢m obsessed with. APIs may not be great, and if I could start over from scratch, I would have made them very different, but as a developer, the best APIs are not the most beautifully designed ones, but the ones that you don√¢t have to worry about because they don√¢t change and upgrades don√¢t require any changes in your application either. Libsodium started from the NaCl API, and still adheres to it.&lt;/p&gt;
    &lt;p&gt;These APIs exposed high-level functions, but also some lower-level functions that high-level functions wrap or depend on. Over the years, people started using these low-level functions directly. Libsodium started to be used as a toolkit of algorithms and low-level primitives.&lt;/p&gt;
    &lt;p&gt;That made me sad, especially since it is clearly documented that only APIs from builds with &lt;code&gt;--enable-minimal&lt;/code&gt; are guaranteed to be tested and stable. But after all, it makes sense. When building custom protocols, having a single portable library with a consistent interface for different functions is far better than importing multiple dependencies, each with their own APIs and sometimes incompatibilities between them.&lt;/p&gt;
    &lt;p&gt;That√¢s a lot of code to maintain. It includes features and target platforms I don√¢t use but try to support for the community. I also maintain a large number of other open source projects.&lt;/p&gt;
    &lt;p&gt;Still, the security track record of libsodium is pretty good, with zero CVEs in 13 years even though it has gotten a lot of scrutiny.&lt;/p&gt;
    &lt;p&gt;However, while recently experimenting with adding support for batch signatures, I noticed inconsistent results with code originally written in Zig. The culprit was a check that was present in a function in Zig, but that I forgot to add in libsodium.&lt;/p&gt;
    &lt;head rend="h2"&gt;The bug&lt;/head&gt;
    &lt;p&gt;The function &lt;code&gt;crypto_core_ed25519_is_valid_point()&lt;/code&gt;, a low-level function used to check if a given elliptic curve point is valid, was supposed to reject points that aren√¢t in the main cryptographic group, but some points were slipping through.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why does this matter?&lt;/head&gt;
    &lt;p&gt;Edwards25519 is like a special mathematical playground where cryptographic operations happen.&lt;/p&gt;
    &lt;p&gt;It is used internally for Ed25519 signatures, and includes multiple subgroups of different sizes (order):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Order 1: just the identity (0, 1)&lt;/item&gt;
      &lt;item&gt;Order 2: identity + point (0, -1)&lt;/item&gt;
      &lt;item&gt;Order 4: 4 points&lt;/item&gt;
      &lt;item&gt;Order 8: 8 points&lt;/item&gt;
      &lt;item&gt;Order L: the √¢main subgroup√¢ (L = ~2^252 points) where all operations are expected to happen&lt;/item&gt;
      &lt;item&gt;Order 2L, 4L, 8L: very large, but not prime order subgroups&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The validation function was designed to reject points not in the main subgroup. It properly rejected points in the small-order subgroups, but not points in the mixed-order subgroups.&lt;/p&gt;
    &lt;head rend="h2"&gt;What went wrong technically?&lt;/head&gt;
    &lt;p&gt;To check if a point is in the main subgroup (the one of order L), the function multiplies it by L. If the order is L, multiplying any point by L gives the identity point (the mathematical equivalent of zero). So, the code does the multiplication and checks that we ended up with the identity point.&lt;/p&gt;
    &lt;p&gt;Points are represented by coordinates. In the internal representation used here, there are three coordinates: X, Y, and Z. The identity point is represented internally with coordinates where X = 0 and Y = Z. Z can be anything depending on previous operations; it doesn√¢t have to be 1.&lt;/p&gt;
    &lt;p&gt;The old code only checked X = 0. It forgot to verify Y = Z. This meant some invalid points (where X = 0 but Y √¢ Z after the multiplication) were incorrectly accepted as valid.&lt;/p&gt;
    &lt;p&gt;Concretely: take any main-subgroup point Q (for example, the output of &lt;code&gt;crypto_core_ed25519_random&lt;/code&gt;) and add the order-2 point (0, -1), or equivalently negate both coordinates. Every such Q + (0, -1) would have passed validation before the fix, even though it√¢s not in the main subgroup.&lt;/p&gt;
    &lt;head rend="h2"&gt;The fix&lt;/head&gt;
    &lt;p&gt;The fix is trivial and adds the missing check:&lt;/p&gt;
    &lt;code&gt;// OLD:
return fe25519_iszero(pl.X);
&lt;/code&gt;
    &lt;code&gt;// NEW:
fe25519_sub(t, pl.Y, pl.Z);
return fe25519_iszero(pl.X) &amp;amp; fe25519_iszero(t);
&lt;/code&gt;
    &lt;p&gt;Now it properly verifies both conditions: X must be zero and Y must equal Z.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who is affected?&lt;/head&gt;
    &lt;p&gt;You may be affected if you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use a point release &amp;lt;= &lt;code&gt;1.0.20&lt;/code&gt;or a version of&lt;code&gt;libsodium&lt;/code&gt;released before December 30, 2025.&lt;/item&gt;
      &lt;item&gt;Use &lt;code&gt;crypto_core_ed25519_is_valid_point()&lt;/code&gt;to validate points from untrusted sources&lt;/item&gt;
      &lt;item&gt;Implement custom cryptography using arithmetic over the Edwards25519 curve&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But don√¢t panic. Most users are not affected.&lt;/p&gt;
    &lt;p&gt;None of the high-level APIs (&lt;code&gt;crypto_sign_*&lt;/code&gt;) are affected; they don√¢t even use or need that function. Scalar multiplication using &lt;code&gt;crypto_scalarmult_ed25519&lt;/code&gt; won√¢t leak anything even if the public key is not on the main subgroup. And public keys created with the regular &lt;code&gt;crypto_sign_keypair&lt;/code&gt; and &lt;code&gt;crypto_sign_seed_keypair&lt;/code&gt; functions are guaranteed to be on the correct subgroup.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recommendation&lt;/head&gt;
    &lt;p&gt;Support for the Ristretto255 group was added to libsodium in 2019 specifically to solve cofactor-related issues. With Ristretto255, if a point decodes, it√¢s safe. No further validation is required.&lt;/p&gt;
    &lt;p&gt;If you implement custom cryptographic schemes doing arithmetic over a finite field group, using Ristretto255 is recommended. It√¢s easier to use, and as a bonus, low-level operations will run faster than over Edwards25519.&lt;/p&gt;
    &lt;p&gt;If you can√¢t update libsodium and need an application-level workaround, use the following function:&lt;/p&gt;
    &lt;code&gt;int is_on_main_subgroup(const unsigned char p[crypto_core_ed25519_BYTES])
{
    /* l - 1 (group order minus 1) */
    static const unsigned char L_1[crypto_core_ed25519_SCALARBYTES] = {
        0xec, 0xd3, 0xf5, 0x5c, 0x1a, 0x63, 0x12, 0x58,
        0xd6, 0x9c, 0xf7, 0xa2, 0xde, 0xf9, 0xde, 0x14,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x10
    };
    /* Identity point encoding: (x=0, y=1) */
    static const unsigned char ID[crypto_core_ed25519_BYTES] = {
        0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
    };
    unsigned char t[crypto_core_ed25519_BYTES];
    unsigned char r[crypto_core_ed25519_BYTES];
    if (crypto_scalarmult_ed25519_noclamp(t, L_1, p) != 0 ||
        crypto_core_ed25519_add(r, t, p) != 0) {
        return 0;
    }
    return sodium_memcmp(r, ID, sizeof ID) == 0;
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Fixed packages&lt;/head&gt;
    &lt;p&gt;This issue was fixed immediately after discovery. All &lt;code&gt;stable&lt;/code&gt; packages released after December 30, 2025 include the fix:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;official tarballs&lt;/item&gt;
      &lt;item&gt;binaries for Visual Studio&lt;/item&gt;
      &lt;item&gt;binaries for MingW&lt;/item&gt;
      &lt;item&gt;NuGet packages for all architectures including Android&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;swift-sodium&lt;/code&gt;xcframework (but&lt;code&gt;swift-sodium&lt;/code&gt;doesn√¢t expose low-level functions anyway)&lt;/item&gt;
      &lt;item&gt;Rust &lt;code&gt;libsodium-sys-stable&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;libsodium.js&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A new point release is also going to be tagged.&lt;/p&gt;
    &lt;p&gt;If &lt;code&gt;libsodium&lt;/code&gt; is useful to you, please keep in mind that it is maintained by one person, for free, in time I could spend with my family or on other projects. The best way to help the project would be to consider sponsoring it, which helps me dedicate more time to improving it and making it great for everyone, for many more years to come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46435614</guid><pubDate>Tue, 30 Dec 2025 17:24:57 +0000</pubDate></item><item><title>Electrolysis can solve one of our biggest contamination problems</title><link>https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html</link><description>&lt;doc fingerprint="cb108501eca1c785"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Electrolysis can solve one of our biggest contamination problems&lt;/head&gt;
    &lt;p&gt;ETH Zurich researchers have developed a process that can be used on site to render environmental toxins such as DDT and lindane harmless and convert them into valuable chemicals ‚Äì a breakthrough for the remediation of contaminated sites and a sustainable circular economy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read&lt;/item&gt;
      &lt;item&gt;Number of comments&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;In brief&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Persistent organic pollutants such as DDT and lindane still pollute the environment and affect humans decades after their use.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ETH researchers have developed a new electrochemical process that completely dehalogenates these long-lived toxins and converts them into valuable industrial chemicals.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The method uses cheap equipment, prevents side reactions and could be used on contaminated landfills, soils or sludge.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mobile systems could be used on site in the future ‚Äì an important step towards the remediation of contaminated sites and the creation of a sustainable circular economy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They were once considered miracle workers ‚Äì insecticides such as lindane or DDT were produced and used millions of times during the 20th century. But what was hailed as progress led to a global environmental catastrophe: persistent organic pollutants (POPs) are so chemically stable that they remain in soil, water and organisms for decades. They accumulate in the fatty tissue of animals and thus enter the human food chain. Many of these substances were banned long ago, but their traces can still be found today ‚Äì even in human blood.&lt;/p&gt;
    &lt;p&gt;How to remediate such contaminated sites, be they soils, bodies of water or landfills, is one of the major unresolved questions of environmental protection. How can highly stable poisons be rendered harmless without creating new problems? Researchers at ETH Zurich, led by Bill Morandi, Professor of Synthetic Organic Chemistry, have now found a promising approach. Using an innovative electrochemical method, they are not only able to break down these long-lived pollutants but also to convert them into valuable raw materials for the chemical industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;Converting pollutants into raw materials&lt;/head&gt;
    &lt;p&gt;A key distinction between this and previous work is that the carbon skeleton of the pollutants is recycled and made reusable, while the halide component is sequestered as a harmless inorganic salt. ‚ÄúThe previous methods were also energetically inefficient,‚Äù says Patrick Domke, a doctoral student in Morandi‚Äôs group. He explains: ‚ÄúThe processes were expensive and still led to outcomes that were harmful to the environment.‚Äù&lt;/p&gt;
    &lt;p&gt;Together with electrochemistry specialist Alberto Garrido-Castro, a former postdoc in this group, Domke developed a process that renders the pollutants in question completely harmless. During this project, the two researchers were able to draw on the many years of experience of ETH professor Morandi, who has been working on the transformation of such compounds for years. ‚ÄúThe key advance of this new technology is the use of alternating current to sequester the problematic halogen atoms as innocuous salts such as NaCl (table salt), while still generating valuable hydrocarbons,‚Äù says Morandi.&lt;/p&gt;
    &lt;head rend="h2"&gt;Using electricity to break down toxins&lt;/head&gt;
    &lt;p&gt;Electrolysis enables almost complete dehalogenation of pollutants under mild, environmentally friendly and cost-effective conditions. It cleaves the stable carbon-halogen bonds, leaving behind only harmless salts such as table salt and useful hydrocarbons such as benzene, diphenylethane or cyclododecatriene. These are actually sought-after intermediates in the chemical industry, for example, for plastics, varnishes, coatings and pharmaceutical applications. In this way, the technology not only contributes to the remediation of contaminated sites but also to the sustainable circular economy.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat makes our process so special from a technical point of view is that we supply electricity using alternating current, similar to the electrical waveform delivered to households. It is one of the most cost-effective resources in chemistry,‚Äù explains Garrido-Castro. ‚ÄúAlternating current protects the electrodes from wear, which is why we can reuse them for many subsequent electrolysis cycles. In addition, the alternating current suppresses unwanted side reactions and the formation of poisonous chlorine gas, allowing the pollutant‚Äôs halogen atoms to be fully converted to inorganic salts.‚Äù The reactor used by the researchers consists of an undivided electrolysis cell in which dimethyl sulfoxide (DMSO) is used as a solvent ‚Äì itself a by-product of the pulp process in paper production.&lt;/p&gt;
    &lt;head rend="h2"&gt;A fully thought-out circular economy&lt;/head&gt;
    &lt;p&gt;The process can be applied not only to pure substances but also to mixtures from contaminated soils. Soil or sludge can therefore be treated without pre-treatment or further separation processes. A prototype of the reactor has already been successfully tested on classic environmental toxins such as lindane and DDT. ‚ÄúOur system is mobile and can be assembled on site. This eliminates the need to transport these hazardous substances,‚Äù explains Domke.&lt;/p&gt;
    &lt;quote&gt;‚ÄúOur motivation was to solve one of the biggest environmental problems of the last century. We cannot simply leave the pollution to future generations.‚ÄùAlberto Garrido-Castro&lt;/quote&gt;
    &lt;head rend="h2"&gt;Spark Award 2025 ‚Äì these projects have made it to the finals&lt;/head&gt;
    &lt;p&gt;On 27 November 2025 at ETH Zurich @ Open-i, ETH Zurich will award the Spark Award for the best invention of the year for the 14th time. The criteria for this award are originality, patent strength and market potential.&lt;/p&gt;
    &lt;p&gt;Click here to find all the Spark Award nominees of 2025.&lt;/p&gt;
    &lt;p&gt;Spark Award ceremony, Industry Day @ Open-i, Thursday, 27 November 2025, 1.30 p.m., Zurich Convention Center. Registration is required.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46436127</guid><pubDate>Tue, 30 Dec 2025 18:08:32 +0000</pubDate></item><item><title>Now That He Has No Power, Mitt Romney Says "Tax the Rich"</title><link>https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/</link><description>&lt;doc fingerprint="2228d57702629431"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Now That He Has No Power, Mitt Romney Says ‚ÄúTax the Rich‚Äù&lt;/head&gt;
    &lt;p&gt;Mitt Romney recently published a New York Times op-ed arguing for higher taxes on the rich. When he was in a position to actually sculpt the GOP platform and the tax policy of the US, Romney was an ardent supporter of cutting taxes for the wealthy.&lt;/p&gt;
    &lt;p&gt;Why is it that powerful people typically wait until they have no power to take the right position and effectively admit they were wrong when they had more power to do something about it?&lt;/p&gt;
    &lt;p&gt;We see this happen so often that it‚Äôs barely noticeable anymore. There were the Iraq War proponents renouncing their past actions. There was Barack Obama marginalizing single-payer health care as president and then touting Medicare for All after he left office. There was James Carville telling Democrats to play dead and then recognizing the zeitgeist and saying they should actually go populist. There‚Äôs the Lincoln Project founder who, when he had power, helped install John Roberts and Sam Alito on the Supreme Court ‚Äî and who now casts himself as a leader of the resistance. There was Dick Cheney creating the tyrannical executive power for someone like Donald Trump to use and then Cheney at the tail end of his life becoming a big critic of Trump.&lt;/p&gt;
    &lt;p&gt;Now comes Mitt Romney ‚Äî who campaigned for president on tax cuts for the wealthy ‚Äî publishing a New York Times op-ed arguing for higher taxes on the rich.&lt;/p&gt;
    &lt;p&gt;The obvious news of the op-ed is that we‚Äôve reached a point in which even American politics‚Äô very own Gordon Gekko ‚Äî a private equity mogul turned Republican politician ‚Äî is now admitting the tax system has been rigged for his fellow oligarchs.&lt;/p&gt;
    &lt;p&gt;And, hey, that‚Äôs good. I believe in the politics of addition. I believe in welcoming converts to good causes in the spirit of ‚Äúbetter late than never.‚Äù I believe there should be space for people to change their views for the better. And I appreciate Romney offering at least some pro forma explanation about what allegedly changed his thinking (sidenote: I say ‚Äúallegedly‚Äù because it‚Äôs not like Romney only just now learned that the tax system was rigged ‚Äî he was literally a cofounder of Bain Capital!).&lt;/p&gt;
    &lt;p&gt;And yet these kinds of reversals (without explicit apologies, of course) often come off as both long overdue but also vaguely inauthentic, or at least not as courageous and principled as they seem.&lt;/p&gt;
    &lt;p&gt;Reversals held until after people leave positions of power often seem less like genuine efforts to change policy and more like after-the-fact attempts to belatedly repair their personal legacies for posterity. Worse, our society so often rewards that not just with a ‚Äúbetter late than never‚Äù welcome but with valorization ‚Äî as if the political icon who was so wrong for so long actually has more credibility on the issue rather than the people who were right all along.&lt;/p&gt;
    &lt;p&gt;In doing that, we remove a deterrent against people doing horrible things when they have agency. They know they can use their power in all sorts of venal ways in the here and now ‚Äî and then still be celebrated as principled truth-tellers when they are later given coveted space in fancy newspapers like the New York Times to fess up to their bad behavior and/or reverse their awful positions.&lt;/p&gt;
    &lt;p&gt;This is the standard legacy-washing playbook among America‚Äôs elite ‚Äî and it works as a PR strategy, at least for a time. But real legacies ‚Äî the legacy of what actually happened in history and who is actually responsible for those events ‚Äî are forged not by what people say after the fact, but by what they actually do when they have power and when there are real stakes in their policy positions.&lt;/p&gt;
    &lt;p&gt;For example: John McCain‚Äôs legacy as a campaign finance reformer was earned not because he got singed by the Keating Five scandal, then retired, and then wrote some op-eds about how bad corruption is. He earned his legacy because he remained in the Senate after that scandal, changed his whole posture on corruption, and actually used his power to pass campaign finance legislation.&lt;/p&gt;
    &lt;p&gt;McCain stands out on that set of issues because he did the opposite of what we typically witness. So often when politicians have power ‚Äî when there are real stakes and when they need to have courage ‚Äî they don‚Äôt do the right thing and take the obviously correct/moral position. Instead, they champion the very policy they later try to cleanse from their brand.&lt;/p&gt;
    &lt;p&gt;Here the Romney example is illustrative: When he was in a position to actually sculpt the national political discourse, the Republican Party platform, and ultimately the tax policy of the United States of America, Romney decided to run for president on a tax cut plan that would ‚Äúbestow most of its benefits on those with the highest incomes,‚Äù according to the Tax Policy Center. He also decided to portray the bottom 47 percent of income earners as America‚Äôs real tax scofflaws ‚Äî not his fellow private equity tycoons, who get to exploit the carried interest loophole he exploited and that he only now criticizes in his op-ed.&lt;/p&gt;
    &lt;p&gt;And during his Senate tenure, while Romney did occasionally explore closing some loopholes, I don‚Äôt recall him using his platform to champion the tax-the-billionaires cause, and I don‚Äôt recall him cosponsoring the major bills to close the tax loophole that he and Wall Street tycoons benefited from.&lt;/p&gt;
    &lt;p&gt;In short, when Romney had real power, he fortified the rigged tax system that he‚Äôs only now criticizing from the sidelines.&lt;/p&gt;
    &lt;p&gt;Notably, Romney doesn‚Äôt explicitly apologize for any of that in his essay. He avoids apology not because he‚Äôs an archetypical American man who, like the Fonz, can‚Äôt bring himself to say ‚ÄúSorry‚Äù or ‚ÄúI was wrong.‚Äù He doesn‚Äôt offer contrition because that might remind us of what he actually did when he had power and there were real stakes in his declarations about tax policy.&lt;/p&gt;
    &lt;p&gt;And so, when I think of that history and that context, I don‚Äôt find myself thinking ‚ÄúWow, even Mitt Romney agrees we shouldn‚Äôt cut taxes for rich people, which means he‚Äôs courageous and principled, and means that only now is that tax position credible and serious.‚Äù&lt;/p&gt;
    &lt;p&gt;I instead find myself thinking: ‚ÄúMitt Romney kinda looks like the hot-dog-guy saying he‚Äôs trying to find the guy who did this to our tax policy, and the real courageous heroes on taxes are those who had the guts to try to actually use their power in public office to push for a fairer tax system when it wasn‚Äôt cool to do so.‚Äù&lt;/p&gt;
    &lt;p&gt;Again, yes: Better late than never that someone like Romney is finally admitting what was obvious to most Americans over the last fifty years. And better late than never when anyone finally comes over to the right side of history on any issue.&lt;/p&gt;
    &lt;p&gt;But where is the courage from powerful people when they actually have power to do something? The answer is it‚Äôs often nowhere, because they derive their own power and prominence by fortifying other elites‚Äô power rather than challenging it.&lt;/p&gt;
    &lt;p&gt;That is their real legacy, no matter what they say after the fact.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46436687</guid><pubDate>Tue, 30 Dec 2025 19:00:23 +0000</pubDate></item></channel></rss>