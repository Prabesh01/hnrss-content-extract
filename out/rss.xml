<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 02 Jan 2026 13:06:18 +0000</lastBuildDate><item><title>BYD Sells 4.6M Vehicles in 2025, Meets Revised Sales Goal</title><link>https://www.bloomberg.com/news/articles/2026-01-01/byd-sells-4-6-million-vehicles-in-2025-meets-revised-sales-goal</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46454977</guid><pubDate>Thu, 01 Jan 2026 15:49:42 +0000</pubDate></item><item><title>Cameras and Lenses (2020)</title><link>https://ciechanow.ski/cameras-and-lenses/</link><description>&lt;doc fingerprint="368c0a750d314318"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cameras and Lenses&lt;/head&gt;
    &lt;p&gt;Pictures have always been a meaningful part of the human experience. From the first cave drawings, to sketches and paintings, to modern photography, we’ve mastered the art of recording what we see.&lt;/p&gt;
    &lt;p&gt;Cameras and the lenses inside them may seem a little mystifying. In this blog post I’d like to explain not only how they work, but also how adjusting a few tunable parameters can produce fairly different results:&lt;/p&gt;
    &lt;p&gt;Over the course of this article we’ll build a simple camera from first principles. Our first steps will be very modest â we’ll simply try to take any picture. To do that we need to have a sensor capable of detecting and measuring light that shines onto it.&lt;/p&gt;
    &lt;head rend="h1"&gt;Recording Light&lt;/head&gt;
    &lt;p&gt;Before the dawn of the digital era, photographs were taken on a piece of film covered in crystals of silver halide. Those compounds are light-sensitive and when exposed to light they form a speck of metallic silver that can later be developed with further chemical processes.&lt;/p&gt;
    &lt;p&gt;For better or for worse, I’m not going to discuss analog devices â these days most cameras are digital. Before we continue the discussion relating to light we’ll use the classic trick of turning the illumination off. Don’t worry though, we’re not going to stay in darkness for too long.&lt;/p&gt;
    &lt;p&gt;The image sensor of a digital camera consists of a grid of photodetectors. AÂ photodetector converts photons into electric current that can be measured â the more photons hitting the detector the higher the signal.&lt;/p&gt;
    &lt;p&gt;In the demonstration below you can observe how photons fall onto the arrangement of detectors represented by small squares. After some processing, the value read by each detector is converted to the brightness of the resulting image pixels which you can see on the right side. I’m also symbolically showing which photosite was hit with a short highlight. The slider below controls the flow of time:&lt;/p&gt;
    &lt;p&gt;The longer the time of collection of photons the more of them are hitting the detectors and the brighter the resulting pixels in the image. When we don’t gather enough photons the image is underexposed, but if we allow the photon collection to run for too long the image will be overexposed.&lt;/p&gt;
    &lt;p&gt;While the photons have the “color” of their wavelength, the photodetectors don’t see that hue â they only measure the total intensity which results in a black and white image. To record the color information we need to separate the incoming photons into distinct groups. We can put tiny color filters on top of the detectors so that they will only accept, more or less, red, green, or blue light:&lt;/p&gt;
    &lt;p&gt;This color filter array can be arranged in many different formations. One of the simplest is a Bayer filter which uses one red, one blue, and two green filters arranged in a 2x2 grid:&lt;/p&gt;
    &lt;p&gt;A Bayer filter uses two green filters because light in green part of the spectrum heavily correlates with perceived brightness. If we now repeat this pattern across the entire sensor we’re able to collect color information. For the next demo we will also double the resolution to an astonishing 1 kilopixel arranged in a 32x32 grid:&lt;/p&gt;
    &lt;p&gt;Note that the individual sensors themselves still only see the intensity, and not the color, but knowing the arrangement of the filters we can recreate the colored intensity of each sensor, as shown on the right side of the simulation.&lt;/p&gt;
    &lt;p&gt;The final step of obtaining a normal image is called demosaicing. During demosaicing we want to reconstruct the full color information by filling in the gaps in the captured RGB values. One of the simplest way to do it is to just linearly interpolate the values between the existing neighbors. I’m not going to focus on the details of many other available demosaicing algorithms and I’ll just present the resulting image created by the process:&lt;/p&gt;
    &lt;p&gt;Notice that yet again the overall brightness of the image depends on the length of time for which we let the photons through. That duration is known as shutter speed or exposure time. For most of this presentation I will ignore the time component and we will simply assume that the shutter speed has been set just right so that the image is well exposed.&lt;/p&gt;
    &lt;p&gt;The examples we’ve discussed so far were very convenient â we were surrounded by complete darkness with the photons neatly hitting the pixels to form a coherent image. Unfortunately, we can’t count on the photon paths to be as favorable in real environments, so let’s see how the sensor performs in more realistic scenarios.&lt;/p&gt;
    &lt;p&gt;Over the course of this article we will be taking pictures of this simple scene. The almost white background of this website is also a part of the scenery â it represents a bright overcast sky. You can drag around the demo to see it from other directions:&lt;/p&gt;
    &lt;p&gt;Let’s try to see what sort of picture would be taken by a sensor that is placed near the objects without any enclosure. I’ll also significantly increase the sensor’s resolution to make the pixels of the final image align with the pixels of your display. In the demonstration below the left side represents a view of the scene with the small greenish sensor present, while the right one shows the taken picture:&lt;/p&gt;
    &lt;p&gt;This is not a mistake. As you can see, the obtained image doesn’t really resemble anything. To understand why this happens let’s first look at the light radiated from the scene.&lt;/p&gt;
    &lt;p&gt;If you had a chance to explore how surfaces reflect light, you may recall that most matte surfaces scatter the incoming light in every direction. While I’m only showing a few examples, every point on every surface of this scene reflects the photons it receives from the whiteish background light source all around itself:&lt;/p&gt;
    &lt;p&gt;The red sphere ends up radiating red light, the green sphere radiates green light, and the gray checkerboard floor reflects white light of lesser intensity. Most importantly, however, the light emitted from the background is also visible to the sensor.&lt;/p&gt;
    &lt;p&gt;The problem with our current approach to taking pictures is that every pixel of the sensor is exposed to the entire environment. Light radiated from every point of the scene and the white background hits every point of the sensor. In the simulation below you can witness how light from different directions hits one point on the surface of the sensor:&lt;/p&gt;
    &lt;p&gt;Clearly, to obtain a discernible image we have to limit the range of directions that affect a given pixel on the sensor. With that in mind, let’s put the sensor in a box that has a small hole in it. The first slider controls the diameter of the hole, while the second one controls the distance between the opening and the sensor:&lt;/p&gt;
    &lt;p&gt;While not shown here, the inner sides of the walls are all black so that no light is reflected inside the box. I also put the sensor on the back wall so that the light from the hole shines onto it. We’ve just built a pinhole camera, let’s see how it performs. Observe what happens to the taken image as we tweak the diameter of the hole with the first slider, or change the distance between the opening and the sensor with the second one:&lt;/p&gt;
    &lt;p&gt;There are so many interesting things happening here! The most pronounced effect is that the image is inverted. To understand why this happens let’s look at the schematic view of the scene that shows the light rays radiated from the objects, going through the hole, and hitting the sensor:&lt;/p&gt;
    &lt;p&gt;As you can see the rays cross over in the hole and the formed image is a horizontal and a vertical reflection of the actual scene. Those two flips end up forming a 180Â° rotation. Since rotated images aren’t convenient to look at, all cameras automatically rotate the image for presentation and for the rest of this article I will do so as well.&lt;/p&gt;
    &lt;p&gt;When we change the distance between the hole and the sensor the viewing angle changes drastically. If we trace the rays falling on the corner pixels of the sensor we can see that they define the extent of the visible section of the scene:&lt;/p&gt;
    &lt;p&gt;Rays of light coming from outside of that shape still go through the pinhole, but they land outside of the sensor and aren’t recorded. As the hole moves further away from the sensor, the angle, and thus the field of view visible to the sensor gets smaller. We can see this in a top-down view of the camera:&lt;/p&gt;
    &lt;p&gt;Coincidentally, this diagram also helps us explain two other effects. Firstly, in the photograph the red sphere looks almost as big as the green one, even though the scene view shows the latter is much larger. However, both spheres end up occupying roughly the same span on the sensor and their size in the picture is similar. It’s also worth noting that the spheres seem to grow when the field of view gets narrower because their light covers larger part of the sensor.&lt;/p&gt;
    &lt;p&gt;Secondly, notice that different pixels of the sensor have different distance and relative orientation to the hole. The pixels right in the center of the sensor see the pinhole straight on, but pixels positioned at an angle to the main axis see a distorted pinhole that is further away. The ellipse in the bottom right corner of the demonstration below shows how a pixel positioned at the blue point sees the pinhole:&lt;/p&gt;
    &lt;p&gt;This change in the visible area of the hole causes the darkening we see in the corners of the photograph. The value of the cosine of the angle I’ve marked with a yellow color is quite important as it contributes to the reduction of visible light in four different ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two cosine factors from the increased distance to the hole, it’s essentially the inverse square law&lt;/item&gt;
      &lt;item&gt;A cosine factor from the side squeeze of the circular hole seen at an angle&lt;/item&gt;
      &lt;item&gt;A cosine factor from the relative tilt of the receptor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These four factors conspire together to reduce the illumination by a factor of cos4(Î±) in what is known as cosine-fourth-power law, also described as natural vignetting.&lt;/p&gt;
    &lt;p&gt;Since we know the relative geometry of the camera and the opening we can correct for this effect by simply dividing by the falloff factor and from this point on I will make sure that the images don’t have darkened corners.&lt;/p&gt;
    &lt;p&gt;The final effect we can observe is that when the hole gets smaller the image gets sharper. Let’s see how the light radiated from two points of the scene ends up going through the camera depending on the diameter of the pinhole:&lt;/p&gt;
    &lt;p&gt;We can already see that larger hole size ends up creating a bigger spread on the sensor. Let’s see this situation up close on a simple grid of detecting cells. Notice what happens to the size of the final circle hitting the sensor as that diameter of the hole changes:&lt;/p&gt;
    &lt;p&gt;When the hole is small enough rays from the source only manage to hit one pixel on the sensor. However, at larger radii the light spreads onto other pixels and a tiny point in the scene is no longer represented by a single pixel causing the image to no longer be sharp.&lt;/p&gt;
    &lt;p&gt;It’s worth pointing out that sharpness is ultimately arbitrary â it depends on the size at which the final image is seen, viewing conditions, and visual acuity of the observer. The same photograph that looks sharp on a postage stamp may in fact be very blurry when seen on a big display.&lt;/p&gt;
    &lt;p&gt;By reducing the size of the cone of light we can make sure that the source light affects a limited number of pixels. Here, however, lays the problem. The sensor we’ve been using so far has been an idealized detector capable of flawless adjustment of its sensitivity to the lighting conditions. If we instead were to fix the sensor sensitivity adjustment, the captured image would look more like this:&lt;/p&gt;
    &lt;p&gt;As the relative size of the hole visible to the pixels of the sensor gets smaller, be it due to reduced diameter or increased distance, fewer photons hit the surface and the image gets dimmer.&lt;/p&gt;
    &lt;p&gt;To increase the number of photons we capture we could extend the duration of collection, but increasing the exposure time comes with its own problems â if the photographed object moves or the camera isn’t held steady we risk introducing some motion blur.&lt;/p&gt;
    &lt;p&gt;Alternatively, we could increase the sensitivity of the sensor which is described using the ISO rating. However, boosting the ISO may introduce a higher level of noise. Even with these problems solved an actual image obtained by smaller and smaller holes would actually start getting blurry again due to diffraction effects of light.&lt;/p&gt;
    &lt;p&gt;If you recall how diffuse surfaces reflect light you may also realize how incredibly inefficient a pinhole camera is. A single point on the surface of an object radiates light into its surrounding hemisphere, however, the pinhole captures only a tiny portion of that light.&lt;/p&gt;
    &lt;p&gt;More importantly, however, a pinhole camera gives us minimal artistic control over which parts of the picture are blurry. In the demonstration below you can witness how changing which object is in focus heavily affects what is the primary target of attention of the photograph:&lt;/p&gt;
    &lt;p&gt;Let’s try to build an optical device that would solve both of these problems: we want to find a way to harness a bigger part of the energy radiated by the objects and also control what is blurry and how blurry it is. For the objects in the scene that are supposed to be sharp we want to collect a big chunk of their light and make it converge to the smallest possible point. In essence, we’re looking for an instrument that will do something like this:&lt;/p&gt;
    &lt;p&gt;We could then put the sensor at the focus point and obtain a sharp image. Naturally, the contraption we’ll try to create has to be transparent so that the light can pass through it and get to the sensor, so let’s begin the investigation by looking at a piece of glass.&lt;/p&gt;
    &lt;head rend="h1"&gt;Glass&lt;/head&gt;
    &lt;p&gt;In the demonstration below I put a red stick behind a pane of glass. You can adjust the thickness of this pane with the gray slider below:&lt;/p&gt;
    &lt;p&gt;When you look at the stick through the surface of a thick glass straight on, everything looks normal. However, as your viewing direction changes the stick seen through the glass seems out of place. The thicker the glass and the steeper the viewing angle the bigger the offset.&lt;/p&gt;
    &lt;p&gt;Let’s focus on one point on the surface of the stick and see how the rays of light radiated from its surface propagate through the subsection of the glass. The red slider controls the position of the source and the gray slider controls the thickness. You can drag the demo around to see it from different viewpoints:&lt;/p&gt;
    &lt;p&gt;For some reason the rays passing through glass at an angle are deflected off their paths. The change of direction happens whenever the ray enters or leaves the glass.&lt;/p&gt;
    &lt;p&gt;To understand why the light changes direction we have to peek under the covers of classical electromagnetism and talk a bit more about waves.&lt;/p&gt;
    &lt;head rend="h1"&gt;Waves&lt;/head&gt;
    &lt;p&gt;It’s impossible to talk about wave propagation without involving the time component, so the simulations in this section are animated â you can play and pause them by clickingtapping on the button in their bottom left corner.&lt;/p&gt;
    &lt;p&gt;By default all animations are enabled, but if you find them distracting, or if you want to save power, you can globally pause all the following demonstrations.disabled, but if you’d prefer to have things moving as you read you can globally unpause them and see all the waves oscillating.&lt;/p&gt;
    &lt;p&gt;Let’s begin by introducing the simplest sinusoidal wave:&lt;/p&gt;
    &lt;p&gt;A wave like this can be characterized by two components. Wavelength Î» is the distance over which the shape of the wave repeats. Period T defines how much time a full cycle takes.&lt;/p&gt;
    &lt;p&gt;Frequency f, is just a reciprocal of period and it’s more commonly used â it defines how many waves per second have passed over some fixed point. Wavelength and frequency define phase velocity vp which describes how quickly a point on a wave, e.g. a peak, moves:&lt;/p&gt;
    &lt;p&gt;The sinusoidal wave is the building block of a polarized electromagnetic plane wave. As the name implies electromagnetic radiation is an interplay of oscillations of electric field E and magnetic field B:&lt;/p&gt;
    &lt;p&gt;In an electromagnetic wave the magnetic field is tied to the electric field so I’m going to hide the former and just visualize the latter. Observe what happens to the electric component of the field as it passes through a block of glass. I need to note that dimensions of wavelengths are not to scale:&lt;/p&gt;
    &lt;p&gt;Notice that the wave remains continuous at the boundary and inside the glass the frequency of the passing wave remains constant, However, the wavelength and thus the phase velocity are reduced â you can see it clearly from the side.&lt;/p&gt;
    &lt;p&gt;The microscopic reason for the phase velocity change is quite complicated, but it can be quantified using the index of refraction n, which is the ratio of the speed of light c to the phase velocity vp of lightwave in that medium:&lt;/p&gt;
    &lt;p&gt;The higher the index of refraction the slower light propagates through the medium. In the table below I’ve presented a few different indices of refraction for some materials:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vacuum&lt;/cell&gt;
        &lt;cell&gt;1.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;air&lt;/cell&gt;
        &lt;cell&gt;1.0003&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;water&lt;/cell&gt;
        &lt;cell&gt;1.33&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;glass&lt;/cell&gt;
        &lt;cell&gt;1.53&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;diamond&lt;/cell&gt;
        &lt;cell&gt;2.43&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Light traveling through air barely slows down, but in a diamond it’s over twice as slow. Now that we understand how index of refraction affects the wavelength in the glass, let’s see what happens when we change the direction of the incoming wave:&lt;/p&gt;
    &lt;p&gt;The wave in the glass has a shorter wavelength, but it still has to match the positions of its peaks and valleys across the boundary. As such, the direction of propagation must change to ensure that continuity.&lt;/p&gt;
    &lt;p&gt;I need to note that the previous two demonstrations presented a two dimensional wave since that allowed me to show the sinusoidal component oscillating into the third dimension. In real world the lightwaves are three dimensional and I can’t really visualize the sinusoidal component without using the fourth dimension which has its own set of complications.&lt;/p&gt;
    &lt;p&gt;The alternative way of presenting waves is to use wavefronts. Wavefronts connect the points of the same phase of the wave, e.g. all the peaks or valleys. In two dimensions wavefronts are represented by lines:&lt;/p&gt;
    &lt;p&gt;In three dimensions the wavefronts are represented by surfaces. In the demonstration below a single source emits a spherical wave, points of the same phase in the wave are represented by the moving shells:&lt;/p&gt;
    &lt;p&gt;By drawing lines that are perpendicular to the surface of the wavefront we create the familiar rays. In this interpretation rays simply show the local direction of wave propagation which can be seen in this example of a section of a spherical 3D wave:&lt;/p&gt;
    &lt;p&gt;I will continue to use the ray analogy to quantify the change in direction of light passing through materials. The relation between the angle of incidence Î¸1 and angle of refraction Î¸2 can be formalized with the equation known as Snell’s law:&lt;/p&gt;
    &lt;p&gt;It describes how a ray of light changes direction relative to the surface normal on the border between two different media. Let’s see it in action:&lt;/p&gt;
    &lt;p&gt;When traveling from a less to more refractive material the ray bends towards the normal, but when the ray exits the object with higher index of refraction it bends away from the normal.&lt;/p&gt;
    &lt;p&gt;Notice that in some configurations the refracted ray completely disappears, however, this doesn’t paint a full picture because we’re currently completely ignoring reflections.&lt;/p&gt;
    &lt;p&gt;All transparent objects reflect some amount of light. You may have noticed that reflection on a surface of a calm lake or even on the other side of the glass demonstration at the beginning of the previous section. The intensity of that reflection depends on the index of refraction of the material and the angle of the incident ray. Here’s a more realistic demonstration of how light would get refracted and reflected between two media:&lt;/p&gt;
    &lt;p&gt;The relation between transmittance and reflectance is determined by Fresnel equations. Observe that the curious case of missing light that we saw previously no longer occurs â that light is actually reflected. The transition from partial reflection and refraction to the complete reflection is continuous, but near the end it’s very rapid and at some point the refraction completely disappears in the effect known as total internal reflection.&lt;/p&gt;
    &lt;p&gt;The critical angle at which the total internal reflection starts to happen depends on the indices of refraction of the boundary materials. Since that coefficient is low for air, but very high for diamond a proper cut of the faces makes diamonds very shiny.&lt;/p&gt;
    &lt;p&gt;While interesting on its own, reflection in glass isn’t very relevant to our discussion and for the rest of this article we’re not going to pay much attention to it. Instead, we’ll simply assume that the materials we’re using are covered with high quality anti-reflective coating.&lt;/p&gt;
    &lt;head rend="h1"&gt;Manipulating Rays&lt;/head&gt;
    &lt;p&gt;Let’s go back to the example that started the discussion of light and glass. When both sides of a piece of glass are parallel, the ray is shifted, but it still travels in the same direction. Observe what happens to the ray when we change the relative angle of the surfaces of the glass.&lt;/p&gt;
    &lt;p&gt;When we make two surfaces of the glass not parallel we gain the ability to change the direction of the rays. Recall, that we’re trying to make the rays hitting the optical device converge at a certain point. To do that we have to bend the rays in the upper part down and, conversely, bend the rays in the lower part up.&lt;/p&gt;
    &lt;p&gt;Let’s see what happens if we shape the glass to have different angles between its walls at different height. In the demonstration below you can control how many distinct segments a piece of glass is shaped to:&lt;/p&gt;
    &lt;p&gt;As the number of segments approaches infinity we end up with a continuous surface without any edges. If we look at the crossover point from the side you may notice that we’ve managed to converge the rays across one axis, but the top-down view reveals that we’re not done yet. To focus all the rays we need to replicate that smooth shape across all possible directions â we need rotational symmetry:&lt;/p&gt;
    &lt;p&gt;We’ve created a convex thin lens. This lens is idealized, in the later part of the article we’ll discuss how real lenses aren’t as perfect, but for now it will serve us very well. Let’s see what happens to the focus point when we change the position of the red source:&lt;/p&gt;
    &lt;p&gt;When the source is positioned very far away the incoming rays become parallel and after passing through lens they converge at a certain distance away from the center. That distance is known as focal length.&lt;/p&gt;
    &lt;p&gt;The previous demonstration also shows two more general distances: so which is the distance between the object, or source, and the lens, as well as si which is the distance between the image and the lens. These two values and the focal length f are related by the thin lens equation:&lt;/p&gt;
    &lt;p&gt;Focal length of a lens depends on both the index of refraction of the material from which the lens is made and its shape:&lt;/p&gt;
    &lt;p&gt;Now that we understand how a simple convex lens works we’re ready to mount it into the hole of our camera. We will still control the distance between the sensor and the lens, but instead of controlling the diameter of the lens we’ll instead control its focal length:&lt;/p&gt;
    &lt;p&gt;When you look at the lens from the side you may observe how the focal length change is tied to the shape of the lens. Let’s see how this new camera works in action:&lt;/p&gt;
    &lt;p&gt;Once again, a lot of things are going on here! Firstly, let’s try to understand how the image is formed in the first place. The demonstration below shows paths of rays from two separate points in the scene. After going through the lens they end up hitting the sensor:&lt;/p&gt;
    &lt;p&gt;Naturally, this process happens for every single point in the scene which creates the final image. Similarly to a pinhole a convex lens creates an inverted picture â I’m still correcting for this by showing you a rotated photograph.&lt;/p&gt;
    &lt;p&gt;Secondly, notice that the distance between the lens and the sensor still controls the field of view. As a reminder, the focal length of a lens simply defines the distance from the lens at which the rays coming from infinity converge. To achieve a sharp image, the sensor has to be placed at the location where the rays focus and that’s what’s causing the field of view to change.&lt;/p&gt;
    &lt;p&gt;In the demonstration below I’ve visualized how rays from a very far object focus through a lens of adjustable focal length, notice that to obtain a sharp image we must change the distance between the lens and the sensor which in turn causes the field of view to change:&lt;/p&gt;
    &lt;p&gt;If we want to change the object on which a camera with a lens of a fixed focal length is focused, we have to move the image plane closer or further away from the lens which affects the angle of view. This effect is called focus breathing:&lt;/p&gt;
    &lt;p&gt;A lens with a fixed focal length like the one above is often called a prime lens, while lenses with adjustable focal length are called zoom lenses. While the lenses in our eyes do dynamically adjust their focal lengths by changing their shape, rigid glass can’t do that so zoom lenses use a system of multiple glass elements that change their relative position to achieve this effect.&lt;/p&gt;
    &lt;p&gt;In the simulation above notice the difference in sharpness between the red and green spheres. To understand why this happens let’s analyze the rays emitted from two points on the surface of the spheres. In the demonstration below the right side shows the light seen by the sensor just from the two marked points on the spheres:&lt;/p&gt;
    &lt;p&gt;The light from the point in focus converges to a point, while the light from an out-of-focus point spreads onto a circle. For larger objects the multitude of overlapping out-of-focus circles creates a smooth blur called bokeh. With tiny and bright light sources that circle itself is often visible, you may have seen effects like the one in the demonstration below in some photographs captured in darker environments:&lt;/p&gt;
    &lt;p&gt;Notice that the circular shape is visible for lights both in front of and behind the focused distance. As the object is positioned closer or further away from the lens the image plane “slices” the cone of light at different location:&lt;/p&gt;
    &lt;p&gt;That circular spot is called a circle of confusion. While in many circumstances the blurriness of the background or the foreground looks very appealing, it would be very useful to control how much blur there is.&lt;/p&gt;
    &lt;p&gt;Unfortunately, we don’t have total freedom here â we still want the primary photographed object to remain in focus so its light has to converge to a point. We just want to change the size of the circle of out-of-focus objects without moving the central point. We can accomplish that by changing the angle of the cone of light:&lt;/p&gt;
    &lt;p&gt;There are two methods we can use to modify that angle. Firstly, we can change the focal length of the lens â you may recall that with longer focal lengths the cone of light also gets longer. However, changing the focal length and keeping the primary object in focus requires moving the image plane which in turn changes how the picture is framed.&lt;/p&gt;
    &lt;p&gt;The alternative way of reducing the angle of the cone of light is to simply ignore some of the “outer” rays. We can achieve that by introducing a stop with a hole in the path of light:&lt;/p&gt;
    &lt;p&gt;This hole is called an aperture. In fact, even the hole in which the lens is mounted is an aperture of some sort, but what we’re introducing is an adjustable aperture:&lt;/p&gt;
    &lt;p&gt;Let’s try to see how an aperture affects the photographs taken with our camera:&lt;/p&gt;
    &lt;p&gt;In real camera lenses an adjustable aperture is often constructed from a set of overlapping blades that constitute an iris. The movement of those blades changes the size of the aperture:&lt;/p&gt;
    &lt;p&gt;The shape of the aperture also defines the shape of bokeh. This is the reason why bokeh sometimes has a polygonal shape â it’s simply the shape of the “cone” of light after passing through the blades of the aperture. Next time you watch a movie pay a close attention to the shape of out-of-focus highlights, they’re often polygonal:&lt;/p&gt;
    &lt;p&gt;As the aperture diameter decreases, larger and larger areas of the photographed scene remain sharp. The term depth of field is used to define the length of the region over which the objects are acceptably sharp. When describing the depth of field we’re trying to conceptually demark those two boundary planes and see how far apart they are from each other.&lt;/p&gt;
    &lt;p&gt;Let’s see the depth of field in action. The black slider controls the aperture, the blue slider controls the focal length, and the red slider changes the position of the object relative to the camera. The green dot shows the place of perfect focus, while the dark blue dots show the limits, or the depth, of positions between which the image of the red light source will be reasonably sharp, as shown by a single outlined pixel on the sensor:&lt;/p&gt;
    &lt;p&gt;Notice that the larger the diameter of aperture and the shorter the focal length the shorter the distance between the dark blue dots and thus the shallower the depth of field becomes. If you recall our discussion of sharpness this demonstration should make it easier to understand why reducing the angle of the cone increases the depth of field.&lt;/p&gt;
    &lt;p&gt;If you don’t have perfect vision you may have noticed that squinting your eyes make you see things a little better. Your eyelids covering some part of your iris simply act as an aperture that decreases the angle of the cone of light falling into your eyes making things sightly less blurry on your retina.&lt;/p&gt;
    &lt;p&gt;An interesting observation is that aperture defines the diameter of the base of the captured cone of light that is emitted from the object. Twice as large aperture diameter captures roughly four times more light due to increased solid angle. In practice, the actual size of the aperture as seen from the point of view of the scene, or the entrance pupil, depends on all the lenses in front of it as the shaped glass may scale the perceived size of the aperture.&lt;/p&gt;
    &lt;p&gt;On the other hand, when a lens is focused correctly, the focal length defines how large a source object is in the picture. By doubling the focal length we double the width and the height of the object on the sensor thus increasing the area by the factor of four. The light from the source is more spread out and each individual pixel receives less light.&lt;/p&gt;
    &lt;p&gt;The total amount of light hitting each pixel is proportional to the ratio between the focal length f and the diameter of the entrance pupil D. This ratio is known as the f-number:&lt;/p&gt;
    &lt;p&gt;A lens with a focal length of 50 mm and the entrance pupil of 25 mm would have N equal to 2 and the f-number would be known as f/2. Since the amount of light getting to each pixel of the sensor increases with the diameter of the aperture and decreases with the focal length, the f-number controls the brightness of the projected image.&lt;/p&gt;
    &lt;p&gt;The f-number with which commercial lenses are marked usually defines the maximum aperture a lens can achieve and the smaller the f-number the more light the lens passes through. Bigger amount of incoming light allows reduction of exposure time, so the smaller the f-number the faster the lens is. By reducing the size of the aperture we can modify the f-number with which a picture is taken.&lt;/p&gt;
    &lt;p&gt;The f-numbers are often multiples of 1.4 which is an approximation of 2. Scaling the diameter of an adjustable aperture by 2 scales its area by 2 which is a convenient factor to use. Increasing the f-number by a so-called stop halves the amount of received light. The demonstration below shows the relatives sizes of the aperture through which light is being seen:&lt;/p&gt;
    &lt;p&gt;To maintain the overall brightness of the image when stopping down we’d have to either increase the exposure time or the sensitivity of the sensor.&lt;/p&gt;
    &lt;p&gt;While aperture settings let us easily control the depth of field, that change comes at a cost. When the f-number increases and the aperture diameter gets smaller we effectively start approaching a pinhole camera with all its related complications.&lt;/p&gt;
    &lt;p&gt;In the final part of this article we will discuss the entire spectrum of another class of problems that we’ve been conveniently avoiding all this time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Aberrations&lt;/head&gt;
    &lt;p&gt;In our examples so far we’ve been using a perfect idealized lens that did exactly what we want and in all the demonstrations I’ve relied on a certain simplification known as the paraxial approximation. However, the physical world is a bit more complicated.&lt;/p&gt;
    &lt;p&gt;The most common types of lenses are spherical lenses â their curved surfaces are sections of spheres of different radii. These types of lenses are easier to manufacture, however, they actually don’t perfectly converge the rays of incoming light. In the demonstration below you can observe how fuzzy the focus point is for various lens radii:&lt;/p&gt;
    &lt;p&gt;This imperfection is known as spherical aberration. This specific flaw can be corrected with aspheric lenses, but unfortunately there are other types of problems that may not be easily solved by a single lens. In general, for monochromatic light there are five primary types of aberrations: spherical aberration, coma, astigmatism, field curvature, and distortion.&lt;/p&gt;
    &lt;p&gt;We’re still not out of the woods even if we manage to minimize these problems. In normal environments light is very non-monochromatic and nature sets another hurdle into optical system design. Let’s quickly go back to the dark environment as we’ll be discussing a single beam of white light.&lt;/p&gt;
    &lt;p&gt;Observe what happens to that beam when it hits a piece of glass. You can make the sides non-parallel by using the slider:&lt;/p&gt;
    &lt;p&gt;What we perceive as white light is a combination of lights of different wavelengths. In fact, the index of refraction of materials depends on the wavelength of the light. This phenomena called dispersion splits what seems to be a uniform beam of white light into a fan of color bands. The very same mechanism that we see here is also responsible for a rainbow.&lt;/p&gt;
    &lt;p&gt;In a lens this causes different wavelengths of light to focus at different offsets â the effect known as chromatic aberration. We can easily visualize the axial chromatic aberration even on a lens with spherical aberration fixed. I’ll only use red, green, and blue dispersed rays to make things less crowded, but remember that other colors of the spectrum are present in between. Using the slider you can control the amount of dispersion the lens material introduces:&lt;/p&gt;
    &lt;p&gt;Chromatic aberration may be corrected with an achromatic lens, usually in the form of a doublet with two different types of glass fused together.&lt;/p&gt;
    &lt;p&gt;To minimize the impact of the aberrations, camera lenses use more than one optical element on their pathways. In this article I’ve only shown you simple lens systems, but a high-end camera lens may consist of a lot of elements that were carefully designed to balance the optical performance, weight, and cost.&lt;/p&gt;
    &lt;p&gt;While we, in our world of computer simulations on this website, can maintain the illusion of simple and perfect systems devoid of aberrations, vignetting, and lens flares, real cameras and lenses have to deal with all these problems to make the final pictures look good.&lt;/p&gt;
    &lt;head rend="h1"&gt;Further Watching and Reading&lt;/head&gt;
    &lt;p&gt;Over on YouTube Filmmaker IQ channel has a lot of great content related to lenses and movie making. Two videos especially fitting here are The History and Science of Lenses and Focusing on Depth of Field and Lens Equivalents.&lt;/p&gt;
    &lt;p&gt;What Makes Cinema Lenses So Special!? on Potato Jet channel is a great interview with Art Adams from ARRI. The video goes over many interesting details of high-end cinema lens design, for example, how the lenses compensate for focus breathing, or how much attention is paid to the quality of bokeh.&lt;/p&gt;
    &lt;p&gt;For a deeper dive on bokeh itself Jakub TrÃ¡vnÃk’s On Bokeh is a great article on the subject. The author explains how aberrations may cause bokeh of non uniform intensity and shows many photographs of real cameras and lenses.&lt;/p&gt;
    &lt;p&gt;In this article I’ve mostly been using geometrical optics with some soft touches of electromagnetism. For a more modern look at the nature of light and its interaction with matter I recommend Richard Feynman’s QED: The Strange Theory of Light and Matter. The book is written in a very approachable style suited for general audience, but it still lets Feynman’s wits and brilliance shine right through.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;Weâve barely scratched the surface of optics and camera lens design, but even the most complex systems end up serving the same purpose: to tell light where to go. In some sense optical engineering is all about taming the nature of light.&lt;/p&gt;
    &lt;p&gt;The simple act of pressing the shutter button in a camera app on a smartphone or on the body of a high-end DSLR is effortless, but itâs at this moment when, through carefully guided rays hitting an array of photodetectors, we immortalize reality by painting with light.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46455872</guid><pubDate>Thu, 01 Jan 2026 17:18:01 +0000</pubDate></item><item><title>Linux is good now</title><link>https://www.pcgamer.com/software/linux/im-brave-enough-to-say-it-linux-is-good-now-and-if-you-want-to-feel-like-you-actually-own-your-pc-make-2026-the-year-of-linux-on-your-desktop/</link><description>&lt;doc fingerprint="13f391b9904a4bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I'm brave enough to say it: Linux is good now, and if you want to feel like you actually own your PC, make 2026 the year of Linux on (your) desktop&lt;/head&gt;
    &lt;p&gt;Now if you don't mind I'm going to delete the root folder and see what happens.&lt;/p&gt;
    &lt;p&gt;I'm all-in, baby. I'm committed. If upgrading any distinct component of my PC didn't require me taking out a loan right now, I'd be seriously considering switching my GPU over to some kind of AMD thing just to make my life slightly, slightly easier.&lt;/p&gt;
    &lt;p&gt;I've had it with Windows and ascended to the sunlit uplands of Linux, where the trees heave with open-source fruits and men with large beards grep things with their minds.&lt;/p&gt;
    &lt;p&gt;I'm not alone. In last month's Steam hardware survey, the number of Linux users hit a new all-time high for the second month running, reaching the heady summit of a whopping, ah, 3.2% of overall Steam users. Hey, we're beating Mac players.&lt;/p&gt;
    &lt;p&gt;I think that number will only grow as the new year goes by. More and more of us are getting sick of Windows, sure—the AI guff, the constant upselling on Office subs, the middle taskbar*—but also, all my experience goofing about with Linux this year has dispelled a lot of the, frankly, erroneous ideas I had about it. It's really not hard! Really! I know Linux guys have been saying this for three decades, but it's true now!&lt;/p&gt;
    &lt;head rend="h2"&gt;Goated with the open source (sorry)&lt;/head&gt;
    &lt;p&gt;As I've already written about, the bulk of my Linux-futzing time this year has been spent in Bazzite, a distro tailor-made for gaming and also tailor-made to stop idiots (me) from doing something likely to detonate their boot drive.&lt;/p&gt;
    &lt;p&gt;I grew up thinking of Linux as 'the command-line OS that lets you delete your bootloader' and, well, I suppose that's not untrue, but I've been consistently impressed at how simple Bazzite has been to run on my PC, even with my persnickety Nvidia GPU.&lt;/p&gt;
    &lt;p&gt;Everything I've played this year has been as easy—if not easier—to run on a free OS put together by a gaggle of passionate nerds as it is on Windows, the OS made by one of the most valuable corporations on planet Earth. I've never had to dip into the command line (which is, to be frank, a shame, as the command line is objectively cool).&lt;/p&gt;
    &lt;p&gt;Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.&lt;/p&gt;
    &lt;p&gt;But to be honest, it's not as if the Bazzite team has miraculously made Linux pleasant to use after decades of it seeming difficult and esoteric to normie computer users. I think mainstream Linux distros are just, well, sort of good now. Apart from my gaming PC, I also have an old laptop converted into a media server that lives underneath my television. It runs Debian 13 (which I updated to from Debian 12 earlier in the year) and requires essentially zero input from me at all.&lt;/p&gt;
    &lt;p&gt;What's more, the only software I have on there is software I actually want on there. Oh for a version of Windows that let me do something as zany as, I don't know, uninstall Edge.&lt;/p&gt;
    &lt;p&gt;That's the true nub of it, I think. The stats can say what they like (and they do! We've all heard tales of Windows games actually running better on Linux via Valve's Proton compatibility layer), but the heart of my fatigue with Windows is that, for every new worthless AI gadget Microsoft crams into it and for every time the OS inexplicably boots to a white screen and implores me to "finish setting up" my PC with an Office 365 subscription, the real problem is a feeling that my computer isn't mine, that I am somehow renting this thing I put together with my own two hands from an AI corporation in Redmond.&lt;/p&gt;
    &lt;p&gt;That's fine for consoles. Indeed, part of the whole pitch of an Xbox or PlayStation is the notion that you are handing off a lot of responsibility for your device to Sony and Microsoft's teams of techs, but my PC? That I built? Get your grubby mitts off it.&lt;/p&gt;
    &lt;p&gt;Are there issues? Sure. HDR's still a crapshoot (plus ça change) and, as you've no doubt heard, a lot of live-service games have anticheat software that won't play with Linux. But I think both of these issues are gradually ticking toward their solutions, particularly with Valve making its own push into the living room.&lt;/p&gt;
    &lt;p&gt;So I say make 2026 the year you give Linux a try, if you haven't already. At the very least, you can stick it on a separate boot drive and have a noodle about with it. I suspect you'll find the open (source) water is a lot more hospitable than you might think.&lt;/p&gt;
    &lt;p&gt;*I'm actually fine with the middle taskbar. I'm sorry.&lt;/p&gt;
    &lt;p&gt;2026 Games: This year's upcoming games&lt;lb/&gt;Best PC games: Our all-time favorites&lt;lb/&gt;Free PC games: Freebie fest&lt;lb/&gt;Best FPS games: Finest gunplay&lt;lb/&gt;Best RPGs: Grand adventures&lt;lb/&gt;Best co-op games: Better together&lt;/p&gt;
    &lt;p&gt;One of Josh's first memories is of playing Quake 2 on the family computer when he was much too young to be doing that, and he's been irreparably game-brained ever since. His writing has been featured in Vice, Fanbyte, and the Financial Times. He'll play pretty much anything, and has written far too much on everything from visual novels to Assassin's Creed. His most profound loves are for CRPGs, immersive sims, and any game whose ambition outstrips its budget. He thinks you're all far too mean about Deus Ex: Invisible War.&lt;/p&gt;
    &lt;p&gt;You must confirm your public display name before commenting&lt;/p&gt;
    &lt;p&gt;Please logout and then login again, you will then be prompted to enter your display name.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46457770</guid><pubDate>Thu, 01 Jan 2026 20:35:11 +0000</pubDate></item><item><title>A website to destroy all websites</title><link>https://henry.codes/writing/a-website-to-destroy-all-websites/</link><description>&lt;doc fingerprint="3cc011532966ad5d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A website to destroy all websites.&lt;/head&gt;
    &lt;head rend="h2"&gt;table of contents, of course&lt;/head&gt;
    &lt;head rend="h2"&gt;The internet is bad.&lt;/head&gt;
    &lt;p&gt;Well, the Internet mostly feels bad these days.&lt;/p&gt;
    &lt;p&gt;We were given this vast, holy realm of self-discovery and joy and philosophy and community; a thousand thousand acres of digital landscape, on which to grow our forests and grasslands of imagination, plant our gardens of learning, explore the caves of our making. We were given the chance to know anything about anything, to be our own Prometheus, to make wishes and to grant them.&lt;/p&gt;
    &lt;p&gt;But that’s not what we use the Internet for anymore. These days, instead of using it to make ourselves, most of us are using it to waste ourselves: we’re doom-scrolling brain-rot on the attention-farm, we’re getting slop from the feed.&lt;/p&gt;
    &lt;p&gt;Instead of turning freely in the HTTP meadows we grow for each other, we go to work: we break our backs at the foundry of algorithmic content as this earnest, naïve, human endeavoring to connect our lives with others is corrupted. Our powerful drive to learn about ourselves, each other, and our world, is broken into scant remnants — hollow, clutching phantasms of Content Creation, speed-cut vertical video, listicle thought-leadership, ragebait and the thread emoji.&lt;/p&gt;
    &lt;head rend="h3"&gt;it wasn’t always like this.&lt;/head&gt;
    &lt;p&gt;It used to feel way better to Go Online, and some of us will remember.&lt;/p&gt;
    &lt;p&gt;We used to be able to learn about our hobbies and interests from hundreds of experts on a wealth of websites whose only shared motivation was their passion. Some of those venerable old educational blogs, forums, and wikis still stand, though most have been bulldozed.&lt;/p&gt;
    &lt;p&gt;Now, Learning On The Internet often means fighting ads and endless assaults on one’s attention — it means watching part-1-part-2-part-3 short-form video clips, taped together by action movie psychology hacks, narrated gracelessly by TTS AI voices. We’re down from a thousand and one websites to three, and each of those remaining monolith websites is just a soullessly-regurgitated, compression-down-scaled, AI-up-scaled version of the next.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;We used to make lasting friendships with folks all over the world on shared interest and good humor.&lt;/p&gt;
    &lt;p&gt;But now those social networks, once hand-built and hand-tended, vibrant and organic, are unceremoniously swallowed by social media networks, pens built for trapping us and our little piggy attentions, turning us all into clout-chasers &amp;amp; content-creators, and removing us from what meaningful intimacy &amp;amp; community felt like.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;Even coding for the web used to be different: One could Learn To Code™ to express oneself creatively, imbue one’s online presence with passion and meaning, and for some of us, build a real career.&lt;/p&gt;
    &lt;p&gt;These days, however, we write increasing amounts of complicated, unsecure code to express less and less meaning, in order to infinitely generate shareholder value. We don’t think about the art of our craft and the discipline of its application, we think about throughput and scale.&lt;/p&gt;
    &lt;p&gt;To be very clear: I’m not trying to Good Old Days the internet. None of this is meant to make you feel nostalgic — the Internet used to be slow and less populated and less diverse, and its access was limited to those of a certain class. The Web For All is a marked improvement, widespread global internet access is a marked improvement, and what I’m asking you to consider is what it used to feel like to use these tools, and what we’ve lost in the Big Tech, Web 2.0 and web3 devouring of the ’Net.&lt;/p&gt;
    &lt;head rend="h2"&gt;The invention of the automobile&lt;/head&gt;
    &lt;p&gt;The onset of the automobile was a revelation for access and personal liberty. With the advent of cars, members of society could travel farther, get more done in their day, and bend their limited time more to their creative will!&lt;/p&gt;
    &lt;p&gt;But as time wore on and the industrialization &amp;amp; proliferation of the automobile progressed, its marginal utility diminished — the industry started to offer society fewer &amp;amp; fewer benefits, and take more &amp;amp; more in exchange1.&lt;/p&gt;
    &lt;p&gt;In American cities, for example: though at first the automobile enabled humans to travel further distances, it now demanded that humans travel those distances, and demanded infrastructure be created &amp;amp; maintained to enable it.2 Many now must use an automobile to get everything done in their town in a day, and must pay &amp;amp; take time for that automobile’s fueling &amp;amp; maintenance.3&lt;/p&gt;
    &lt;p&gt;Further than that, the automobile asks all of us to chip in tax revenue to protect its infrastructure, but only certain classes can afford an automobile with which to use that infrastructure, and those classes who can’t afford to do so are relegated to underfunded public transit systems.4&lt;/p&gt;
    &lt;p&gt;No longer a tool to serve our societies, our societies now serve the automobile.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tools for Conviviality, &amp;amp; the industrialization of the Web.&lt;/head&gt;
    &lt;p&gt;In his book Tools For Conviviality, technology philosopher and social critic Ivan Illich identifies these two critical moments, the optimistic arrival &amp;amp; the deadening industrialization, as watersheds of technological advent. Tools are first created to enhance our capacities to spend our energy more freely and in turn spend our days more freely, but as their industrialization increases, their manipulation &amp;amp; usurpation of society increases in tow5.&lt;/p&gt;
    &lt;p&gt;Illich also describes the concept of radical monopoly, which is that point where a technological tool is so dominant that people are excluded from society unless they become its users. We saw this with the automobile, we saw it with the internet, and we even see it with social media.&lt;/p&gt;
    &lt;p&gt;&lt;del&gt;No longer a tool to serve our societies, our societies now serve the automobile.&lt;/del&gt; Instead of designing and using tools to build a society, our society changes to adapt to the demands of our tools.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;Illich’s thesis allows us to reframe our adoption and use of the technologies in our life. We can map fairly directly most technological developments in the last 100 (or even 200) years to this framework: a net lift, followed by a push to extract value and subsequent insistence upon the technology’s ubiquity:&lt;/p&gt;
    &lt;head rend="h3"&gt;the textile revolution&lt;/head&gt;
    &lt;p&gt;The preferred imagery used to mythologize the Industrial Revolution is the woodetchings of textile manufacturers, transformed in the early 19th century by the arrival of automated fabric machinery. Its proponents laud the shift of an agricultural society to a technological one, creating new sectors for labor, and raising up the middle class (we will say nothing of this period’s new punishing conditions for labor in this essay6). But the ultimate ecological and human costs engendered by the increasing availability of cheap fabric production are well-documented: In 2022, the fashion and textile industries employed around 60 million factory workers worldwide7, and less than 2% of those workers earn a living wage. Those workers also endure the full suite of labor exploitation practices, including gender-based harassment, wage theft, and unsafe conditions. On the material side, the induced consumption resulting from ever-cheaper products means the world consumed 400% more textile products globally as 20 years ago8, and bins most of it (the average American generates 82 pounds of textile waste each year).&lt;/p&gt;
    &lt;head rend="h3"&gt;antibiotic technology&lt;/head&gt;
    &lt;p&gt;The arrival of antibiotics in 19289 allowed for revolutionary leaps in fighting bacterial infections like strep throat, pneumonia, and meningitis, but an over-dependence and over-prescription of penicillin and its siblings through the 1950s-70s resulted in the proliferation of antibiotic resistance, which subsequently led to longer hospital stays, higher medical costs, and increased mortality.10&lt;/p&gt;
    &lt;head rend="h3"&gt;space exploration&lt;/head&gt;
    &lt;p&gt;Since the beginning of the space exploration era in the late 1950s, humanity has made leaps and bounds in learning about our own world and its physical systems, telecommunications, imaging, etc. The increasing frequency of commercialization missions in space for satellite systems (and lately tourism) has resulted in immense amounts of space debris being generated — both from active satellites and from jettisoned/destroyed components of previous missions, the debris threatens future missions and has even been destructive to the field of astronomy, making it impossible to use earth-based sensors and photography devices to learn about space.11 So desperate to extract Shareholder Value from the starry sky, we’re blinding our own ability to look at it.&lt;/p&gt;
    &lt;p&gt;The web is no exception to this pattern. A vision of interoperability, accessibility, and usability, the World Wide Web was first conceived in 1989 as a way to universally link documents and other media content in a flexibly-organized system that could make information easily accessed at CERN, and be easily shared with collaborators beyond.12 But the proliferation of access and ultimate social requirement of access has spawned countless troubles for human society, including cyberstalking and bullying, the instantaneous circulation of CSAM, violent images, and misinformation, identity theft, addiction, etcetera.&lt;/p&gt;
    &lt;p&gt;The rampant industrialization and commercialization of the Web predictably develops flashy, insidious patterns of extracting capital from its users: new surfaces for information means new surfaces for advertisement, and new formats of media beget new mechanisms for divorcing you from their ownership.&lt;/p&gt;
    &lt;head rend="h3"&gt;convivial life &amp;amp; convivial tooling&lt;/head&gt;
    &lt;p&gt;Illich poses convivial tools as directly opposed to this industrialized, radically-monopolized set of social systems. Similar to E.F. Schumacher’s concept of “intermediate technology” introduced in his 1973 book Small Is Beautiful: A Study of Economics As If People Mattered, convivial tools are sustainable, energy-efficient (though often labor intensive), local-first, and designed primarily to enhance the autonomy and creativity of their users.13 Illich cites specifically hand tools, bicycles, and telephones as examples, but with its enormous capacity for interoperability and extensibility, the Internet is the perfect workshed in which to design our own Tools For Conviviality.&lt;/p&gt;
    &lt;head rend="h2"&gt;the Web we want&lt;/head&gt;
    &lt;p&gt;let’s reconsider&lt;/p&gt;
    &lt;p&gt;the markers of a decaying 'Net I mentioned before, with convivial tooling in mind:&lt;/p&gt;
    &lt;head rend="h3"&gt;Teaching &amp;amp; learning on the Web&lt;/head&gt;
    &lt;p&gt;Monolithic platforms like YouTube, TikTok, Medium, and Substack draw a ton of creators and educators because of the promise of monetization and large audiences, but they’ve shown time and time again how the lack of ownership creates a problem. When those platforms fail, when they change their rules, when they demand creators move or create a particular way to maintain their access to those audiences, they pit creators or their audiences against the loss of the other. Without adhering to the algorithm’s requirements, writers may not write an impactful document, and without bypassing a paywall, readers can’t read it.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;When those promises of exorbitant wealth and a life of decadence through per-click monetization ultimately dry up (or come with a steep moral or creative cost), creators and learners must look for new solutions for how educational content is shared on the Internet. The most self-evident, convivial answer is an old one: blogs. HTML is free to access by default, RSS has worked for about 130 years[citation needed], and combined with webmentions, it’s never been easier to read new ideas, experiment with ideas, and build upon &amp;amp; grow those ideas with other strong thinkers on the web, owning that content all along.14&lt;/p&gt;
    &lt;head rend="h3"&gt;Connecting with friends on the Web&lt;/head&gt;
    &lt;p&gt;Social media apps have imprisoned us all in this weird content prison — in order to connect with friends we’re sort of forced to create or be vanished by capricious black box algorithms, and all that we do create is, as we’ve already alluded to, subsequently owned by whatever platform we’ve created it on. If Instagram goes away overnight, or decides to pivot catastrophically, your stories and your network of friends goes with it.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;The advent and development of tools &amp;amp; methodologies like POSSE (Publish On your Own Site, Syndicate Elsewhere), ActivityPub, microformats, and ATProto, it’s becoming quite achievable to generate your own social network, interoperable with other networks like Bluesky or Mastodon. That network, designed for ownership and decentralization, is durable, designed around storytelling instead of engagement, and free of the whims of weird tech billionaires.&lt;/p&gt;
    &lt;p&gt;With some basic HTML knowledge and getting-stuff-online knowledge, a handful of scrappy protocols, and a free afternoon or two, one can build their own home to post bangers for the tight homies, make friends, and snipe those new friends with those hits of dopamine they so fiendishly rely on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Coding for the web&lt;/head&gt;
    &lt;p&gt;Lastly, consider the discipline of web engineering:&lt;/p&gt;
    &lt;p&gt;We have been asked to build the same B2B SaaS website with the same featureset n^∞ times, and our answers for the optimal way to do that are increasingly limited. We’ve penned all of our markup into JavaScript templates just in case a product manager needs the wrapper component to post JSON somewhere down the line, and we’ve whittled away at style code until it’s just a mechanism for deploying one of two border-radius-drop-shadow combos to divs. It’s an industrial, production-minded way of approaching a discipline that has all the hallmarks of being a great craft, and that’s understandably uninspiring to many of us.&lt;/p&gt;
    &lt;p&gt;¶&lt;/p&gt;
    &lt;p&gt;Yet our young React shepherds have no need to fear: there are countless more colors than blurple out there, and countless more fonts than Inter. HTML and CSS are better and more generative technologies than they’ve ever been: Thanks to the tireless work of the CSS working groups and browser implementers, etc, there is an unbelievable amount of creative expression possible with basic web tools in a text editor. Even JavaScript is more progressively-enhanceable than ever, and enables interfacing with a rapidly-growing number of exciting browser APIs (still fuck Brendan Eich though). &lt;code&gt;${new Date.getCurrentYear()}&lt;/code&gt; is a veritable renaissance of web code, and it asks of authors only curiosity and a drive to experiment.&lt;/p&gt;
    &lt;head rend="h2"&gt;so where do we go from here?&lt;/head&gt;
    &lt;p&gt;Illich’s thesis is that technology and its derived tools should serve people in a way that enhances their freedom, creativity, independence, and will.&lt;/p&gt;
    &lt;p&gt;The distillation of those principles on the web through manual code, hand-built social networks, and blogs, points luminously to one answer to the question of how the Internet can best serve humans:&lt;/p&gt;
    &lt;head rend="h3"&gt;it’s personal websites.&lt;/head&gt;
    &lt;p&gt;Hand-coded, syndicated, and above all personal websites are exemplary: They let users of the internet to be autonomous, experiment, have ownership, learn, share, find god, find love, find purpose. Bespoke, endlessly tweaked, eternally redesigned, built-in-public, surprising UI and delightful UX. The personal website is a staunch undying answer to everything the corporate and industrial web has taken from us.&lt;/p&gt;
    &lt;p&gt;And how might one claim this ultimate toolchain of conviviality, and build a place on the web that enhances their autonomy and creativity?&lt;/p&gt;
    &lt;p&gt;How might one build a personal website?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Start small&lt;/head&gt;
        &lt;p&gt;Let yourself start small, have fun trying shit that doesn’t work, document your growth, publish failed ideas &amp;amp; successful ones. Some of the best websites in the world are just HTML, and they belong to their authors. Make friends, let yourself be inspired by others, send friendly emails asking to learn new things, and do not demand of yourself masterpieces.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Reduce friction to publishing&lt;/head&gt;&lt;p&gt;Get the resistance to ship out of your way. Don’t get caught up in tooling and frameworks, just write HTML and get something online. If you’re an engineer, delight that you’re not beholden to the same standards of quality and rigorous testing that you are at work — draft some ideas, hit the&lt;/p&gt;&lt;code&gt;h1&lt;/code&gt;to&lt;code&gt;p&lt;/code&gt;tag combo, and publish. Update and update again; let your ideas grow like gardens, the way they do in your mind. The mutability of the web, often its great weakness, is also one of its great strengths.&lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Don’t worry about design (unless you want to)&lt;/head&gt;
        &lt;p&gt;Don’t worry about design unless that’s the part that brings you joy. Make friends with designers and trade your work for theirs, or trade tips, trade advice. Get comfortable with being joyfully bad at something — from that soil of humility grows a million questions for those who have learned and are excited to share. Iterate until you’ve something you’re proud of, or iterate so much you’ve ruined it and have to go back to bald.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Use the IndieWeb&lt;/head&gt;
        &lt;p&gt;Leverage the IndieWeb and its wonderfully thought-out protocols, tools like brid.gy to syndicate your ideas out to the wider web, and then use Webmentions to bring the ensuing conversations back where the content is. That way, you can publish work where you prefer to, folks on Bluesky can enjoy and discuss it, in the same stroke as folks on Mastodon may, or folks directly on the canonical URL.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Join us in sharing what you’ve made&lt;/head&gt;
        &lt;p&gt;I encourage you to join us in our auspicious website adventure, and if you do, I hope you’ll further join us on personalsit.es, our happy little home for everyone building something humble or thrilling or joyful or deeply accursed, but personal.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;(denouement)&lt;/head&gt;
    &lt;p&gt;You’re not crazy. The internet does feel genuinely so awful right now, and for about a thousand and one reasons. But the path back to feeling like you have some control is to un-spin yourself from the Five Apps of the Apocalypse and reclaim the Internet as a set of tools you use to build something you can own &amp;amp; be proud of — or in most of our cases, be deeply ashamed of. Godspeed and good luck.&lt;/p&gt;
    &lt;p&gt;❦&lt;/p&gt;
    &lt;p&gt;That’s all for me. If you find any issues with this post, please reach out to me by email. Thanks eternally for your time and patience, and thanks for reading. Find me here online at one of my personal websites like henry.codes or strange.website or stillness.digital or strangersbyspring.com, or sometimes on Bluesky and Mastodon.&lt;/p&gt;
    &lt;p&gt;As ever, unionize, free Palestine, trans rights are human rights, fix your heart or die.&lt;/p&gt;
    &lt;p&gt;fin.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46457784</guid><pubDate>Thu, 01 Jan 2026 20:36:46 +0000</pubDate></item><item><title>Can Bundler be as fast as uv?</title><link>https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/</link><description>&lt;doc fingerprint="7685981e496335d9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Can Bundler Be as Fast as uv?&lt;/head&gt;Dec 29, 2025 @ 12:26 pm&lt;p&gt;At RailsWorld earlier this year, I got nerd sniped by someone. They asked “why can’t Bundler be as fast as uv?” Immediately my inner voice said “YA, WHY CAN’T IT BE AS FAST AS UV????”&lt;/p&gt;&lt;p&gt;My inner voice likes to shout at me, especially when someone asks a question so obvious I should have thought of it myself. Since then I’ve been thinking about and investigating this problem, going so far as to give a presentation at XO Ruby Portland about Bundler performance. I firmly believe the answer is “Bundler can be as fast as uv” (where “as fast” has a margin of error lol).&lt;/p&gt;&lt;p&gt;Fortunately, Andrew Nesbitt recently wrote a post called “How uv got so fast”, and I thought I would take this opportunity to review some of the highlights of the post and how techniques applied in uv can (or can’t) be applied to Bundler / RubyGems. I’d also like to discuss some of the existing bottlenecks in Bundler and what we can do to fix them.&lt;/p&gt;&lt;p&gt;If you haven’t read Andrew’s post, I highly recommend giving it a read. I’m going to quote some parts of the post and try to reframe them with RubyGems / Bundler in mind.&lt;/p&gt;&lt;head rend="h2"&gt;Rewrite in Rust?&lt;/head&gt;&lt;p&gt;Andrew opens the post talking about rewriting in Rust:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;uv installs packages faster than pip by an order of magnitude. The usual explanation is âitâs written in Rust.â Thatâs true, but it doesnât explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This is such a good quote. I’m going to address “rewrite in Rust” a bit later in the post. But suffice to say, I think if we eliminate bottlenecks in Bundler such that the only viable option for performance improvements is to “rewrite in Rust”, then I’ll call it a success. I think rewrites give developers the freedom to “think outside the box”, and try techniques they might not have tried. In the case of &lt;code&gt;uv&lt;/code&gt;, I think it gave the developers a good way to say “if we don’t have to worry about backwards compatibility, what could we achieve?”.&lt;/p&gt;&lt;p&gt;I suspect it would be possible to write a uv in Python (PyUv?) that approaches the speeds of uv, and in fact much of the blog post goes on to talk about performance improvements that aren’t related to Rust.&lt;/p&gt;&lt;head rend="h2"&gt;Installing code without eval’ing&lt;/head&gt;&lt;quote&gt;&lt;p&gt;pipâs slowness isnât a failure of implementation. For years, Python packaging required executing code to find out what a package needed.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;I didn’t know this about Python packages, and it doesn’t really apply to Ruby Gems so I’m mostly going to skip this section.&lt;/p&gt;&lt;p&gt;Ruby Gems are tar files, and one of the files in the tar file is a YAML representation of the GemSpec. This YAML file declares all dependencies for the Gem, so RubyGems can know, without evaling anything, what dependencies it needs to install before it can install any particular Gem. Additionally, RubyGems.org provides an API for asking about dependency information, which is actually the normal way of getting dependency info (again, no &lt;code&gt;eval&lt;/code&gt; required).&lt;/p&gt;&lt;p&gt;There’s only one other thing from this section I’d like to quote:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;PEP 658 (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Fortunately RubyGems.org already provides the same information about gems.&lt;/p&gt;&lt;p&gt;Reading through the number of PEPs required as well as the amount of time it took to get the standards in place was very eye opening for me. I can’t help but applaud folks in the Python community for doing this. It seems like a mountain of work, and they should really be proud of themselves.&lt;/p&gt;&lt;head rend="h2"&gt;What uv drops&lt;/head&gt;&lt;p&gt;I’m mostly going to skip this section except for one point:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Ignoring requires-python upper bounds. When a package says it requires python&amp;lt;4.0, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare python&amp;lt;4.0 because they havenât tested on Python 4, not because theyâll actually break. The constraint is defensive, not predictive.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;I think this is very very interesting. I don’t know how much time Bundler spends on doing “required Ruby version” bounds checking, but it feels like if uv can do it, so can we.&lt;/p&gt;&lt;head rend="h2"&gt;Optimizations that donât need Rust&lt;/head&gt;&lt;p&gt;I really love that Andrew pointed out optimizations that could be made that don’t involve Rust. There are three points in this section that I want to pull out:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Parallel downloads. pip downloads packages one at a time. uv downloads many at once. Any language can do this.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This is absolutely true, and is a place where Bundler could improve. Bundler currently has a problem when it comes to parallel downloads, and needs a small architectural change as a fix.&lt;/p&gt;&lt;p&gt;The first problem is that Bundler tightly couples installing a gem with downloading the gem. You can read the installation code here, but I’ll summarize the method in question below:&lt;/p&gt;&lt;code&gt;def install
  path = fetch_gem_if_not_cached
  Bundler::RubyGemsGemInstaller.install path, dest
end
&lt;/code&gt;&lt;p&gt;The problem with this method is that it inextricably links downloading the gem with installing it. This is a problem because we could be downloading gems while installing other gems, but we’re forced to wait because the installation method couples the two operations. Downloading gems can trivially be done in parallel since the &lt;code&gt;.gem&lt;/code&gt; files are just archives that can be fetched independently.&lt;/p&gt;&lt;p&gt;The second problem is the queuing system in the installation code. After gem resolution is complete, and Bundler knows what gems need to be installed, it queues them up for installation. You can find the queueing code here. The code takes some effort to understand. Basically it allows gems to be installed in parallel, but only gems that have already had their dependencies installed.&lt;/p&gt;&lt;p&gt;So for example, if you have a dependency tree like “gem &lt;code&gt;a&lt;/code&gt; depends on gem &lt;code&gt;b&lt;/code&gt; which depends on gem &lt;code&gt;c&lt;/code&gt;” (&lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt;), then no gems will be installed (or downloaded) in parallel.&lt;/p&gt;&lt;p&gt;To demonstrate this problem in an easy-to-understand way, I built a slow Gem server. It generates a dependency tree of &lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt; (&lt;code&gt;a&lt;/code&gt; depends on &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; depends on &lt;code&gt;c&lt;/code&gt;), then starts a Gem server.
The Gem server takes 3 seconds to return any Gem, so if we point Bundler at this Gem server and then profile Bundler, we can see the impact of the queueing system and download scheme.&lt;/p&gt;&lt;p&gt;In my test app, I have the following Gemfile:&lt;/p&gt;&lt;code&gt;source "http://localhost:9292"

gem "a"
&lt;/code&gt;&lt;p&gt;If we profile Bundle install with Vernier, we can see the following swim lanes in the marker chart:&lt;/p&gt;&lt;p&gt;The above chart is showing that we get no parallelism during installation. We spend 3 seconds downloading the &lt;code&gt;c&lt;/code&gt; gem, then we install it.
Then we spend 3 seconds downloading the &lt;code&gt;b&lt;/code&gt; gem, then we install it.
Finally we spend 3 seconds downloading the &lt;code&gt;a&lt;/code&gt; gem, and we install it.&lt;/p&gt;&lt;p&gt;Timing the &lt;code&gt;bundle install&lt;/code&gt; process shows we take over 9 seconds to install (3 seconds per gem):&lt;/p&gt;&lt;code&gt;&amp;gt; rm -rf x; rm -f Gemfile.lock; time GEM_PATH=(pwd)/x GEM_HOME=(pwd)/x bundle install
Fetching gem metadata from http://localhost:9292/...
Resolving dependencies...
Fetching c 1.0.0
Installing c 1.0.0
Fetching b 1.0.0
Installing b 1.0.0
Fetching a 1.0.0
Installing a 1.0.0
Bundle complete! 1 Gemfile dependency, 3 gems now installed.
Use `bundle info [gemname]` to see where a bundled gem is installed.

________________________________________________________
Executed in   11.80 secs      fish           external
   usr time  341.62 millis  231.00 micros  341.38 millis
   sys time  223.20 millis  712.00 micros  222.49 millis
&lt;/code&gt;&lt;p&gt;Contrast this with a Gemfile containing &lt;code&gt;d&lt;/code&gt;, &lt;code&gt;e&lt;/code&gt;, and &lt;code&gt;f&lt;/code&gt;, which have no dependencies, but still take 3 seconds to download:&lt;/p&gt;&lt;code&gt;source "http://localhost:9292"

gem "d"
gem "e"
gem "f"
&lt;/code&gt;&lt;p&gt;Timing &lt;code&gt;bundle install&lt;/code&gt; for the above Gemfile shows it takes about 4 seconds:&lt;/p&gt;&lt;code&gt;&amp;gt; rm -rf x; rm -f Gemfile.lock; time GEM_PATH=(pwd)/x GEM_HOME=(pwd)/x bundle install
Fetching gem metadata from http://localhost:9292/.
Resolving dependencies...
Fetching d 1.0.0
Fetching e 1.0.0
Fetching f 1.0.0
Installing e 1.0.0
Installing f 1.0.0
Installing d 1.0.0
Bundle complete! 3 Gemfile dependencies, 3 gems now installed.
Use `bundle info [gemname]` to see where a bundled gem is installed.

________________________________________________________
Executed in    4.14 secs      fish           external
   usr time  374.04 millis    0.38 millis  373.66 millis
   sys time  368.90 millis    1.09 millis  367.81 millis
&lt;/code&gt;&lt;p&gt;We were able to install the same number of gems in a fraction of the time. This is because Bundler is able to download siblings in the dependency tree in parallel, but unable to handle other relationships.&lt;/p&gt;&lt;p&gt;There is actually a good reason that Bundler insists dependencies are installed before the gems themselves: native extensions. When installing native extensions, the installation process must run Ruby code (the &lt;code&gt;extconf.rb&lt;/code&gt; file).
Since the &lt;code&gt;extconf.rb&lt;/code&gt; could require dependencies be installed in order to run, we must install dependencies first.
For example &lt;code&gt;nokogiri&lt;/code&gt; depends on &lt;code&gt;mini_portile2&lt;/code&gt;, but &lt;code&gt;mini_portile2&lt;/code&gt; is only used during the installation process, so it needs to be installed before &lt;code&gt;nokogiri&lt;/code&gt; can be compiled and installed.&lt;/p&gt;&lt;p&gt;However, if we were to decouple downloading from installation it would be possible for us to maintain the “dependencies are installed first” business requirement but speed up installation. In the &lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt; case, we could have been downloading gems &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; at the same time as gem &lt;code&gt;c&lt;/code&gt; (or even while waiting on &lt;code&gt;c&lt;/code&gt; to be installed).&lt;/p&gt;&lt;p&gt;Additionally, pure Ruby gems don’t need to execute any code on installation. If we knew that we were installing a pure Ruby gem, it would be possible to relax the “dependencies are installed first” business requirement and get even more performance increases. The above &lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt; case could install all three gems in parallel since none of them execute Ruby code during installation.&lt;/p&gt;&lt;p&gt;I would propose we split installation in to 4 discrete steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Download the gem&lt;/item&gt;&lt;item&gt;Unpack the gem&lt;/item&gt;&lt;item&gt;Compile the gem&lt;/item&gt;&lt;item&gt;Install the gem&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Downloading and unpacking can be done trivially in parallel. We should unpack the gem to a temporary folder so that if the process crashes or the machine loses power, the user isn’t stuck with a half-installed gem. After we unpack the gem, we can discover whether the gem is a native extension or not. If it’s not a native extension, we “install” the gem simply by moving the temporary folder to the “correct” location. This step could even be a “hard link” step as discussed in the next point.&lt;/p&gt;&lt;p&gt;If we discover that the gem is a native extension, then we can “pause” installation of that gem until its dependencies are installed, then resume (by compiling) at an appropriate time.&lt;/p&gt;&lt;p&gt;Side note: &lt;code&gt;gel&lt;/code&gt;, a Bundler alternative, works mostly in this manner today.
Here is a timing of the &lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt; case from above:&lt;/p&gt;&lt;code&gt;&amp;gt; rm -f Gemfile.lock; time gel install
Fetching sources....
Resolving dependencies...
Writing lockfile to /Users/aaron/git/gemserver/app/Gemfile.lock
Installing c (1.0.0) 
Installing a (1.0.0)
Installing b (1.0.0)
Installed 3 gems  

________________________________________________________
Executed in    4.07 secs      fish           external
   usr time  289.22 millis    0.32 millis  288.91 millis
   sys time  347.04 millis    1.36 millis  345.68 millis
&lt;/code&gt;&lt;p&gt;Lets move on to the next point:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Global cache with hardlinks. pip copies packages into each virtual environment. uv keeps one copy globally and uses hardlinks&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;I think this is a great idea, but I’d actually like to split the idea in two. First, RubyGems and Bundler should have a combined, global cache, full stop. I think that global cache should be in &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt;, and we should store &lt;code&gt;.gem&lt;/code&gt; files there when they are downloaded.&lt;/p&gt;&lt;p&gt;Currently, both Bundler and RubyGems will use a Ruby version specific cache folder. In other words, if you do &lt;code&gt;gem install rails&lt;/code&gt; on two different versions of Ruby, you get two copies of Rails and all its dependencies.&lt;/p&gt;&lt;p&gt;Interestingly, there is an open ticket to implement this, it just needs to be done.&lt;/p&gt;&lt;p&gt;The second point is hardlinking on installation. The idea here is that rather than unpacking the gem multiple times, once per Ruby version, we simply unpack once and then hard link per Ruby version. I like this idea, but I think it should be implemented after some technical debt is paid: namely implementing a global cache and unifying Bundler / RubyGems code paths.&lt;/p&gt;&lt;p&gt;On to the next point:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;PubGrub resolver&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Actually Bundler already uses a Ruby implementation of the PubGrub resolver. You can see it here. Unfortunately, RubyGems still uses the molinillo resolver.&lt;/p&gt;&lt;p&gt;In other words you use a different resolver depending on whether you do &lt;code&gt;gem install&lt;/code&gt; or &lt;code&gt;bundle install&lt;/code&gt;.
I don’t really think this is a big deal since the vast majority of users will be doing &lt;code&gt;bundle install&lt;/code&gt; most of time.
However, I do think this discrepancy is some technical debt that should be addressed, and I think this should be addressed via unification of RubyGems and Bundler codebases (today they both live in the same repository, but the code isn’t necessarily combined).&lt;/p&gt;&lt;p&gt;Lets move on to the next section of Andrew’s post:&lt;/p&gt;&lt;head rend="h2"&gt;Where Rust actually matters&lt;/head&gt;&lt;p&gt;Andrew first mentions “Zero-copy deserialization”. This is of course an important technique, but I’m not 100% sure where we would utilize it in RubyGems / Bundler. I think that today we parse the YAML spec on installation, and that could be a target. But I also think we could install most gems without looking at the YAML gemspec at all.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Thread-level parallelism. Pythonâs GIL forces parallel work into separate processes, with IPC overhead and data copying.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This is an interesting point. I’m not sure what work pip needed to do in separate processes. Installing a pure Ruby, Ruby Gem is mostly an IO bound task, with some ZLIB mixed in. Both of these things (IO and ZLIB processing) release Ruby’s GVL, so it’s possible for us to do things truly in parallel. I imagine this is similar for Python / pip, but I really have no idea.&lt;/p&gt;&lt;p&gt;Given the stated challenges with Python’s GIL, you might wonder whether Ruby’s GVL presents similar parallelism problems for Bundler. I don’t think so, and in fact I think Ruby’s GVL gets kind of a bad rap. It prevents us from running CPU bound Ruby code in parallel. Ractors address this, and Bundler could possibly leverage them in the future, but since installing Gems is mostly an IO bound task I’m not sure what the advantage would be (possibly the version solver, but I’m not sure what can be parallelized in there). The GVL does allow us to run IO bound work in parallel with CPU bound Ruby code. CPU bound native extensions are allowed to release the GVL, allowing Ruby code to run in parallel with the native extension’s CPU bound code.&lt;/p&gt;&lt;p&gt;In other words, Ruby’s GVL allows us to safely run work in parallel. That said, the GVL can work against us because releasing and acquiring the GVL takes time.&lt;/p&gt;&lt;p&gt;If you have a system call that is very fast, releasing and acquiring the GVL could end up being a large percentage of that call. For example, if you do &lt;code&gt;File.binwrite(file, buffer)&lt;/code&gt;, and the buffer is very small, you could encounter a situation where GVL book keeping is the majority of the time.
A bummer is that Ruby Gem packages usually contain lots of very small files, so this problem could be impacting us.
The good news is that this problem can be solved in Ruby itself, and indeed some work is being done on it today.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;No interpreter startup. Every time pip spawns a subprocess, it pays Pythonâs startup cost.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Obviously Ruby has this same problem. That said, we only start Ruby subprocesses when installing native extensions. I think native extensions make up the minority of gems installed, and even when installing a native extension, it isn’t Ruby startup that is the bottleneck. Usually the bottleneck is compilation / linking time (as we’ll see in the next post).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Compact version representation. uv packs versions into u64 integers where possible, making comparison and hashing fast.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This is a cool optimization, but I don’t think it’s actually Rust specific. Comparing integers is much faster than comparing version objects. The idea is that you take a version number, say &lt;code&gt;1.0.0&lt;/code&gt;, and then pack each part of the version in to a single integer.
For example, we could represent &lt;code&gt;1.0.0&lt;/code&gt; as &lt;code&gt;0x0001_0000_0000_0000&lt;/code&gt; and &lt;code&gt;1.1.0&lt;/code&gt; as &lt;code&gt;0x0001_0001_0000_0000&lt;/code&gt;, etc.&lt;/p&gt;&lt;p&gt;It should be possible to use this trick in Ruby and encode versions to integer immediates, which would unlock performance in the resolver. Rust has an advantage here - compiled native code comparing u64s will always be faster than Ruby, even with immediates. However, I would bet that with the YJIT or ZJIT in play, this gap could be closed enough that no end user would notice the difference between a Rust or Ruby implementation of Bundler.&lt;/p&gt;&lt;p&gt;I started refactoring the &lt;code&gt;Gem::Version&lt;/code&gt; object so that we might start doing this, but we ended up reverting it because of backwards compatibility (I am jealous of &lt;code&gt;uv&lt;/code&gt; in that regard).
I think the right way to do this is to refactor the solver entry point and ensure all version requirements are encoded as integer immediates before entering the solver.
We could keep the &lt;code&gt;Gem::Version&lt;/code&gt; API as “user facing” and design a more internal API that the solver uses.
I am very interested in reading the version encoding scheme in uv.
My intuition is that minor numbers tend to get larger than major numbers, so would minor numbers have more dedicated bits?
Would it even matter with 64 bits?&lt;/p&gt;&lt;head rend="h2"&gt;Wrapping this up&lt;/head&gt;&lt;p&gt;I’m going to quote Andrew’s last 2 paragraphs:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;uv is fast because of what it doesnât do, not because of what language itâs written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.&lt;/p&gt;&lt;p&gt;pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesnât, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;I think these are very good points. The difference is that in RubyGems and Bundler, we already have the infrastructure in place for writing a “fast as uv” package manager. The difficult part is dealing with backwards compatibility, and navigating two legacy codebases. I think this is the real advantage the uv developers had. That said, I am very optimistic that we could “repair the plane mid-flight” so to speak, and have the best of both worlds: backwards compatibility and speed.&lt;/p&gt;&lt;p&gt;I mentioned at the top of the post I would address “rewrite it in Rust”, and I think Andrew’s own quote mostly does that for me. I think we could have 99% of the performance improvements while still maintaining a Ruby codebase. Of course if we rewrote it in Rust, you could squeeze an extra 1% out, but would it be worthwhile? I don’t think so.&lt;/p&gt;&lt;p&gt;I have a lot more to say about this topic, and I feel like this post is getting kind of long, so I’m going to end it here. Please look out for part 2, which I’m tentatively calling “What makes Bundler / RubyGems slow?” This post was very “can we make RubyGems / Bundler do what uv does?” (the answer is “yes”). In part 2 I want to get more hands-on by discussing how to profile Bundler and RubyGems, what specifically makes them slow in the real world, and what we can do about it.&lt;/p&gt;&lt;p&gt;I want to end this post by saying “thank you” to Andrew for writing such a great post about how uv got so fast.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46458302</guid><pubDate>Thu, 01 Jan 2026 21:37:10 +0000</pubDate></item><item><title>WebAssembly as a Python Extension Platform</title><link>https://nullprogram.com/blog/2026/01/01/</link><description>&lt;doc fingerprint="8c499a15de87b2c0"&gt;
  &lt;main&gt;
    &lt;p&gt; nullprogram.com/blog/2026/01/01/ &lt;/p&gt;
    &lt;p&gt; (The author is currently open to employment opportunities in the United States.) &lt;/p&gt;
    &lt;p&gt;Software above some complexity level tends to sport an extension language, becoming a kind of software platform itself. Lua fills this role well, and of course there’s JavaScript for web technologies. WebAssembly generalizes this, and any Wasm-targeting programming language can extend a Wasm-hosting application. It has more friction than supplying a script in a text file, but extension authors can write in their language of choice, and use more polished development tools — debugging, testing, etc. — than typically available for a typical extension language. Python is traditionally extended through native code behind a C interface, but it’s recently become practical to extend Python with Wasm. That is we can ship an architecture-independent Wasm blob inside a Python library, and use it without requiring a native toolchain on the host system. Let’s discuss two different use cases and their pitfalls.&lt;/p&gt;
    &lt;p&gt;Normally we’d extend Python in order to access an external interface that Python cannot access on its own. Wasm runs in a sandbox with no access to the outside world whatsoever, so it obviously isn’t useful for that case. Extensions may also grant Python more speed, which is one of Wasm’s main selling points. We can also use Wasm to access embeddable capabilities written in a different programming language which do not require external access.&lt;/p&gt;
    &lt;p&gt;For preferred non-WASI Wasm runtime is Volodymyr Shymanskyy’s wasm3. It’s plain old C and very friendly to embedding in the same was as, say, SQLite. Performance is middling, though a C program running on wasm3 is still quite a bit faster than an equivalent Python program. It has Python bindings, pywasm3, but it’s distributed only in source code form. That is, the host machine must have a C toolchain in order to use pywasm3, which defeats my purposes here. If there’s a C toolchain, I might as well just use that instead of going through Wasm.&lt;/p&gt;
    &lt;p&gt;For the use cases in this article, the best option is wasmtime-py. The distribution includes binaries for Windows, macOS, and Linux on x86-64 and ARM64, which covers nearly all Python installations. Hosts require nothing more than a Python interpreter, no native toolchains. It’s almost as good as having Wasm built into Python itself. In my tests it’s 3x–10x faster than wasm3, so for my first use case the situation is even better. The catch is that it currently weighs ~18MiB (installed), and in the future will likely rival the Python interpreter itself. The API also breaks on a monthly basis, so you’re signing up for the upgrade treadmill lest your own program perishes to bitrot after a couple of years. This article is about version 40.&lt;/p&gt;
    &lt;head rend="h3"&gt;Usage examples and gotchas&lt;/head&gt;
    &lt;p&gt;The official examples don’t do anything non-trivial or interesting, and so to figure things out I had to study the documentation, which does not offer many hints. Basic setup looks like this:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;import functools
import wasmtime

store    = wasmtime.Store()
module   = wasmtime.Module.from_file(store.engine, "example.wasm")
instance = wasmtime.Instance(store, module, ())
exports  = instance.exports(store)

memory = exports["memory"].get_buffer_ptr(store)
func1  = functools.partial(exports["func1"], store)
func2  = functools.partial(exports["func2"], store)
func3  = functools.partial(exports["func3"], store)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;A store is an allocation region from which we allocate all Wasm objects. It is not possible to free individual objects except to discard the whole store. Quite sensible, honestly. What’s not sensible is how often I have to repeat myself, passing the store back into every object in order to use it. These objects are associated with exactly one store and cannot be used with different stores. Use the wrong store and it panics: It’s already keeping track internally! I do not understand why the interface works this way. So to make things simpler, I use &lt;code&gt;functools.partial&lt;/code&gt; to
bind the &lt;code&gt;store&lt;/code&gt; parameter and so get the interface I expect.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;get_buffer_ptr&lt;/code&gt; object is a buffer protocol object, and if you’re
moving anything other than bytes that’s probably what you want to use to
access memory. The usual caveats apply for this object: If you change the
memory size you probably want to grab a fresh buffer object. For
bytes (e.g. buffers and strings) I prefer the &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt; methods.&lt;/p&gt;
    &lt;p&gt;Because multi-value is still in an experimental state in the Wasm ecosystem, you will likely not pass structs with Wasm. Anything more complicated than scalars will require pointers and copying data in and out of Wasm linear memory. This involves the usual trap that catches nearly everyone: Wasm interfaces make no distinction between pointers and integers, and Wasm runtimes interpret generally interpret all integers as signed. What that means is your pointers are signed unless you take action. Addresses start at 0, so this is bad, bad news.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;malloc = functools.partial(exports["func1"], store)

hello = b"hello"
pointer = malloc(len(hello))
assert pointer
memory = exports["memory"].write(store, hello, pointer)  # WRONG!
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;To make matters worse, wasmtime-py adds its own footgun: The &lt;code&gt;read&lt;/code&gt; and
&lt;code&gt;write&lt;/code&gt; methods adopt the questionable Python convention of negative
indices acting from the end. If &lt;code&gt;malloc&lt;/code&gt; returns a pointer in the upper
half of memory, the negative pointer will pass the bounds check inside
&lt;code&gt;write&lt;/code&gt; because negative is valid, then quietly store to the wrong
address! Doh!&lt;/p&gt;
    &lt;p&gt;I wondered how common this error, so I searched online. I could find only one non-trivial wasmtime-py use in the wild, in a sandboxed PDF reader. It falls into the negative pointer trap as I expected. Not only that, it’s a buffer overflow into Python’s memory space:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;            buf_ptr = malloc(store, len(pdf_data))
            mem_data = memory.data_ptr(store)

            for i, byte in enumerate(pdf_data):
                mem_data[buf_ptr + i] = byte
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;The &lt;code&gt;data_ptr&lt;/code&gt; method returns a non-bounds-checked raw &lt;code&gt;ctypes&lt;/code&gt; pointer,
so this is actually a double mistake. First, it shouldn’t trust pointers
coming out of Wasm if it cares at all about sandboxing. The second is the
potential negative pointer, which in this case would write outside of the
Wasm memory and in Python’s memory, hopefully seg-faulting.&lt;/p&gt;
    &lt;p&gt;What’s one to do? Every pointer coming out of Wasm must be truncated with a mask:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;pointer = malloc(...) &amp;amp; 0xffffffff   # correct for wasm32!
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;This interprets the result as unsigned. 64-bit Wasm needs a 64-bit mask, though in practice you will never get a valid negative pointer from 64-bit Wasm. This rule applies to JavaScript as well, where the idiom is:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;let pointer = malloc(...) &amp;gt;&amp;gt;&amp;gt; 0
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Wasm runtimes cannot help — they lack the necessary information — and this is perhaps a fundamental flaw in Wasm’s design. Once you know about it you see this mistake happening everywhere.&lt;/p&gt;
    &lt;p&gt;Now that you have a proper address, you can apply it to a buffer protocol view of memory. If you’re using NumPy there are various ways to interact with this memory by wrapping it in NumPy types, though only if you’re on a little endian host. (If you’re on a big endian machine, just give up on running Wasm anyway.) The first use case I have in mind typically involves copying plain Python values in and out. The &lt;code&gt;struct&lt;/code&gt; package is
quite handy here:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;vec2   = malloc(...) &amp;amp; 0xffffffff
memory = exports["memory"].get_buffer_ptr(store)
struct.pack_into("&amp;lt;ii", memory, vec2, x, y)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;It fills a similar role to JavaScript &lt;code&gt;DataView&lt;/code&gt;. If you’re copying
lots of numbers, with CPython it’s faster to construct a custom format
string rather than use a loop:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;nums: list[int] = ...
struct.pack_into(f"&amp;lt;{len(nums)}i", memory, buf, *nums)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;To copy structures back out, use &lt;code&gt;struct.unpack_from&lt;/code&gt;. If you’re moving
strings, you’ll need to &lt;code&gt;.encode()&lt;/code&gt; and &lt;code&gt;.decode()&lt;/code&gt; to convert to and from
&lt;code&gt;bytes&lt;/code&gt;, which are well-suited to &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In practice with real Wasm programs you’re going to be interacting with the “guest” allocator from the outside, to request memory into which you copy inputs for a function. In my examples I’ve used &lt;code&gt;malloc&lt;/code&gt; because it
requires no elaboration, but as usual a bump allocator solves
this so much better, especially because it doesn’t require stuffing a
whole general purpose allocator inside the Wasm program. Have one global
arena — no other threads will sharing that Wasm instance — rapid fire a
bunch of allocations as needed without any concern for memory management
in the “host”, call the function, which might allocate a result from that
arena, then reset the arena to clean up. In essence a stack for passing
values in and out.&lt;/p&gt;
    &lt;head rend="h3"&gt;WebAssembly as faster Python&lt;/head&gt;
    &lt;p&gt;Suppose we noticed a computational hot spot in our Python program in a pure Python function (e.g. not calling out to an extension). Optimizing this function would be wise. Based on my experiments if I re-implement that function in C, compile it to Wasm, then run that bit of Wasm in place of the original function, I can expect around a 10x speed-up. In general C is more like 100x faster than Python, and the overhead of interfacing with Wasm — copying stuff in and out, etc. — can be high, but not so high as to not be profitable. This improves further if I can change the interface, e.g. require callers to use the buffer protocol.&lt;/p&gt;
    &lt;p&gt;Thanks to wasmtime-py, I could introduce this change without fussing with cross-compilers to build distribution binaries, nor require a toolchain on the target, just a hefty Python package. Might be worth it.&lt;/p&gt;
    &lt;p&gt;My main experimental benchmark is a variation on my solution to the “Two Sum” problem, which I originally wrote for JavaScript, then extended to pywasm3 and later wasmtime-py. It’s simple, just interesting enough, and representative of the sort of Wasm drop-in I have in mind. It has the same interface, but implements it with Wasm.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;# Original Pythonic interface
def twosum(nums: list[int], target: int) -&amp;gt; tuple[int, int] | None:
    ...

# Stateful Wasm interface
class TwoSumWasm():
    def __init__(self):
        store    = wasmtime.Store()
        module   = wasmtime.Module.from_file(store.engine, ...)
        instance = wasmtime.Instance(store, module, ())
        ...

    def twosum(self, nums, target):
        # ... use wasm instance ...
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;There’s some state to it with the Wasm instance in tow. If you hide that by making it global you’ll need to synchronize your threads around it. In a multi-threaded program perhaps these would be lazily-constructed thread locals. I haven’t had to solve this yet.&lt;/p&gt;
    &lt;p&gt;However, the weakness of the wasmtime “store” really shows: Notice how compilation and instantiation are bound together in one store? I cannot compile once and then create disposable instances on the fly, e.g. as required for each run of a WASI program. Every instance permanently extends the compilation store. In practice we must wastefully re-compile the Wasm program for each disposable instance. Despite appearances, compilation and instantiation are not actually distinct steps, as they are in JavaScript’s Wasm API. &lt;code&gt;wasmtime.Instance&lt;/code&gt; accepts a store as its first
argument, suggesting use of a different store for instantiation. That
would solve this problem, but as of this writing it must be the same
store used to compile the module. This is a fatal flaw for certain real
use cases, particularly WASI.&lt;/p&gt;
    &lt;head rend="h3"&gt;WebAssembly as embedded capabilities&lt;/head&gt;
    &lt;p&gt;Loup Vaillant’s Monocypher is a wonderful cryptography library. Lean, efficient, and embedding-friendly, so much so it’s distributed in amalgamated form. It requires no libc or runtime, so we can compile it straight to Wasm with almost any Clang toolchain:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ clang --target=wasm32 -nostdlib -O2 -Wl,--no-entry -Wl,--export-all
        -o monocypher.wasm monocypher.c
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;It’s not “Wasm-aware” so I need &lt;code&gt;--export-all&lt;/code&gt; to expose the interface.
This is swell because, as single translation unit, anything with external
linkage is the interface. Though remember what I said about interacting
with the guest allocator? This has no allocator, nor should it. It’s not
so usable in this form because we’d need to manage memory from the
outside. Do-able, but it’s easy to improve by adding a couple more
functions, sticking to a single translation unit:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;#include "monocypher.c"

extern char  __heap_base[];
static char *heap_used;
static char *heap_high;

void *bump_alloc(ptrdiff_t size)
{
    // ...
}

void bump_reset()
{
    ptrdiff_t len = heap_used - __heap_base;
    __builtin_memset(__heap_base, 0, len);  // wipe keys, etc.
    heap_used = __heap_base;
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;I’ve discussed &lt;code&gt;__heap_base&lt;/code&gt; before, which is part of the ABI.
We’ll push keys, inputs, etc. onto this “stack”, run our cryptography
routine, copy out the result, then reset the bump allocator, which wipes
out all sensitive data. Often &lt;code&gt;memset&lt;/code&gt; is insufficient — typically it’s
zero-then-free, and compilers see the lifetime about to end — but no
lifetime ends here, and stores to this “heap” memory externally observable
as far as the abstract machine can tell. (Otherwise we couldn’t reliably
copy out our results!)&lt;/p&gt;
    &lt;p&gt;There’s a lot to this API, but I’m only going to look at the AEAD interface. We “lock” up some data in an encrypted box, write any unencrypted label we’d like on the outside. Then later we can unlock the box, which will only open for us if neither the contents of the box nor the label were tampered with. That’s some solid API design:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void crypto_aead_lock(uint8_t       *cipher_text,
                      uint8_t        mac  [16],
                      const uint8_t  key  [32],
                      const uint8_t  nonce[24],
                      const uint8_t *ad,         size_t ad_size,
                      const uint8_t *plain_text, size_t text_size);
int crypto_aead_unlock(uint8_t       *plain_text,
                       const uint8_t  mac  [16],
                       const uint8_t  key  [32],
                       const uint8_t  nonce[24],
                       const uint8_t *ad,          size_t ad_size,
                       const uint8_t *cipher_text, size_t text_size);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;By compiling to Wasm we can access this functionality from Python almost like it was pure Python, and interact with other systems using Monocypher.&lt;/p&gt;
    &lt;p&gt;Since Monocypher does not interact with the outside world on its own, it relies on callers to use their system’s CSPRNG to create those nonces and keys, which we’ll do using the &lt;code&gt;secrets&lt;/code&gt; built-in package:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;class Monocypher:
    def __init__(self):
        ...
        self._read   = functools.partial(memory.read, store)
        self._write  = functools.partial(memory.write, store)
        self.__alloc = functools.partial(exports["bump_alloc"], store)
        self._reset  = functools.partial(exports["bump_reset"], store)
        self._lock   = functools.partial(exports["crypto_aead_lock"], store)
        self._unlock = functools.partial(exports["crypto_aead_unlock"], store)
        self._csprng = secrets.SystemRandom()

    def _alloc(self, n):
        return self.__alloc(n) &amp;amp; 0xffffffff

    def generate_key(self):
        return self._csprng.randbytes(32)

    def generate_nonce(self):
        return self._csprng.randbytes(24)

    ...
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;With a solid foundation, all that follows comes easily. A &lt;code&gt;finally&lt;/code&gt;
guarantees secrets are always removed from Wasm memory, and the rest is
just about copying bytes around:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;    def aead_lock(self, text, key, ad = b""):
        assert len(key) == 32
        try:
            macptr   = self._alloc(16)
            keyptr   = self._alloc(32)
            nonceptr = self._alloc(24)
            adptr    = self._alloc(len(ad))
            textptr  = self._alloc(len(text))

            self._write(key, keyptr)
            nonce = self.generate_nonce()
            self._write(nonce, nonceptr)
            self._write(ad,    adptr)
            self._write(text,  textptr)

            self._lock(
                textptr,
                macptr,
                keyptr,
                nonceptr,
                adptr, len(ad),
                textptr, len(text),
            )
            return (
                self._read(macptr, macptr+16),
                nonce,
                self._read(textptr, textptr+len(text)),
            )
        finally:
            self._reset()
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;And &lt;code&gt;aead_unlock&lt;/code&gt; is basically the same in reverse, but throws if the box
fails to unlock, perhaps due to tampering:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;    def aead_unlock(self, text, mac, key, nonce, ad = b""):
        assert len(mac) == 16
        assert len(key) == 32
        assert len(nonce) == 24
        try:
            macptr   = self._alloc(16)
            keyptr   = self._alloc(32)
            nonceptr = self._alloc(24)
            adptr    = self._alloc(len(ad))
            textptr  = self._alloc(len(text))

            self._write(mac, macptr)
            self._write(key, keyptr)
            self._write(nonce, nonceptr)
            self._write(ad, adptr)
            self._write(text, textptr)

            if self._unlock(
                textptr,
                macptr,
                keyptr,
                nonceptr,
                adptr, len(ad),
                textptr, len(text),
            ):
                raise ValueError("AEAD mismatch")
            return self._read(textptr, textptr+len(text))
        finally:
            self._reset()
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;mc = Monocypher()
key = mc.generate_key()
message = "Hello, world!"
mac, nonce, encrypted = mc.aead_lock(message.encode(), key)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Transmit &lt;code&gt;mac&lt;/code&gt;, &lt;code&gt;nonce&lt;/code&gt;, and &lt;code&gt;encrypted&lt;/code&gt; to the other party (or your
future self), who already has the &lt;code&gt;key&lt;/code&gt;:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;decrypted = mc.aead_unlock(encrypted, mac, key, nonce)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Find the complete source in my scratch repository.&lt;/p&gt;
    &lt;p&gt;While I have a few reservations about wasmtime-py, it fascinates me how well this all works. It’s been my hammer in search of a nail for some time now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46458624</guid><pubDate>Thu, 01 Jan 2026 22:09:16 +0000</pubDate></item><item><title>Why users cannot create Issues directly</title><link>https://github.com/ghostty-org/ghostty/issues/3558</link><description>&lt;doc fingerprint="d3525efe9c762c38"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 1.4k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;Users are not allowed to create Issues directly in this repository - we ask that you create a Discussion first.&lt;/p&gt;
    &lt;p&gt;Unlike some other projects, Ghostty does not use the issue tracker for discussion or feature requests. Instead, we use GitHub discussions for that. Once a discussion reaches a point where a well-understood, actionable item is identified, it is moved to the issue tracker. This pattern makes it easier for maintainers or contributors to find issues to work on since every issue is ready to be worked on.&lt;/p&gt;
    &lt;p&gt;This approach is based on years of experience maintaining open source projects and observing that 80-90% of what users think are bugs are either misunderstandings, environmental problems, or configuration errors by the users themselves. For what's left, the majority are often feature requests (unimplemented features) and not bugs (malfunctioning features). Of the features requests, almost all are underspecified and require more guidance by a maintainer to be worked on.&lt;/p&gt;
    &lt;p&gt;Any Discussion which clearly identifies a problem in Ghostty and can be confirmed or reproduced will be converted to an Issue by a maintainer, so as a user finding a valid problem you don't do any extra work anyway. Thank you.&lt;/p&gt;
    &lt;p&gt;For more details, see our CONTRIBUTING.md.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46460319</guid><pubDate>Fri, 02 Jan 2026 01:24:51 +0000</pubDate></item><item><title>Extensibility: The "100% Lisp" Fallacy</title><link>https://kyo.iroiro.party/en/posts/100-percent-lisp/</link><description>&lt;doc fingerprint="8622d95d221f3adc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Extensibility: The â100% Lispâ Fallacy&lt;/head&gt;
    &lt;p&gt;So, Iâve seen some articles promoting Emacs-like editors written in Lisp languages, and one of the most common arguments seems to be: âitâs written in This Lisp and also scriptable in This Lisp, and that gives it great extensibility.â 1&lt;/p&gt;
    &lt;p&gt;Itâs not wrong, but I think it does overlook a few things.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;By the way: Happy New Year!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;1. The argumentÂ¶&lt;/head&gt;
    &lt;p&gt;For example, the Lem: An Alternative To Emacs? article from Irreal claims: (emphasis preserved)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One thing I like about it is that itâs 100% Common Lisp. Thereâs no C core; just Lisp all the way down. That makes it easier to customize or extend any part of the editor.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt; This argument sounds good: Looking at the repository, Lem is &lt;del&gt;100%&lt;/del&gt; 90% Lisp code; since the editor code and user customization live in the Common Lisp runtime, we should be able to extend any part of the editor on the fly, right? &lt;/p&gt;
    &lt;p&gt;Or, does it really?&lt;/p&gt;
    &lt;p&gt; Does it offer &lt;code&gt;composition-function-table&lt;/code&gt; so that you can program your font ligatures from the editorâs scripting language? &lt;/p&gt;
    &lt;p&gt;Does it provide an API to define an arbitrary encoding system and the corresponding charset, beyond what is supported by Unicode or any existing standard?&lt;/p&gt;
    &lt;p&gt;Does it allow you to âoverrideâ its newline character, so that a file is displayed all on a single line?&lt;/p&gt;
    &lt;p&gt;â¦&lt;/p&gt;
    &lt;p&gt;These examples are taken from some of the more obscure features in Emacs, and I can go on and on. I donât think many of the editors out there could possibly support them, as they are probably the 10% non-pure part of a â100% Lispâ system.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To be honest, I hate these features as theyâve haunted me forever since I started designing an IPC protocol for my Emacs clone. But, dang it, I suffered and suffer from it exactly because of Emacsâs extensibility â not the lack of it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;2. There is no â100% LispâÂ¶&lt;/head&gt;
    &lt;p&gt;For example, Steel Bank Common Lisp, a common Common Lisp runtime, is only mostly written in Lisp because it has to provide threading primitives, interface with the OS, or leverage assembly code. And obviously you wonât be able to customize those bits.&lt;/p&gt;
    &lt;p&gt;Going back to (graphical) editors this is no less true. Usually2, as is with any GUI program, you will want to support font fallback, input methods and screen readers, all of which require interacting with platform specific APIs and are thus much less customizable. FFI helps to some degree by keeping your niche âpureâ, but it canât extend your customizability beyond that boundary: webviews donât expose font ligature internals, and CSS is the only way to control that, albeit quite limited; input methods are trickier, as they interfere with keyboard events and are platform-specific; screen readers are â¦ I donât know, you should really use a library for it if you want portability.&lt;/p&gt;
    &lt;p&gt;Anyway, itâs just impossible these days to have a âpureâ Lisp program with all those platform specific things to deal with, or with all those convenient library bindings to use. Itâs not inherently bad, but it certainly limits how youâre allowed to extend things.&lt;/p&gt;
    &lt;p&gt;However, even with the non-pure parts, provided with suitable building blocks, itâs usually quite surprising to what degree people can work around all those ânon-extensibleâ parts.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Workaround-ish extensibilityÂ¶&lt;/head&gt;
    &lt;p&gt;Letâs first have a look at some approaches people adopt to extend their editors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Neovim and many TUI editors donât have native scrollbar support since they are bounded by what ANSI provides. But guess what? By coloring the rightmost column with &lt;code&gt;extmark&lt;/code&gt;and&lt;code&gt;virt_text&lt;/code&gt;, itâs totally doable to display a pretty scrollbar for Neovim.&lt;/item&gt;
      &lt;item&gt;Stock Emacs does not support cursor animations. And yet, youâve guessed it, people: &lt;list rend="ul"&gt;&lt;item&gt;Come up with patches for this,&lt;/item&gt;&lt;item&gt;Or extend Lisp code with Python, which in turn calls PyQt or compositor commands to control overlayed windows, so as to display things like moving cursors.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Similarly, Emacs Application Framework allows you to write GUI programs for Emacs by â¦ first programming them in PyQt and then sticking them onto the Emacs window, so that the PyQt window âfillsâ the corresponding buffer window.&lt;/p&gt;
        &lt;p&gt;Not all Wayland compositors provide a way to programmatically position user windows, and that can be a problem for EAF.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;And, have you heard of EXWM (Emacs X Window Manager)?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The moral here is that a lot of things are more extensible than one might think. Itâs just amazing how people keep coming up with all kinds of workarounds all the time. And yes, I do think those are all extensibility, regardless of âpurityâ.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. âSpacebar heatingâ extensibilityÂ¶&lt;/head&gt;
    &lt;p&gt;Compared to extending via workarounds, extending in âpure Lispâ can be both easier and harder, as we are still bounded by coding conventions and existing code, and one cannot possibly extend everything without breaking some of them.&lt;/p&gt;
    &lt;p&gt; Letâs start by overriding a single function. For example, when exporting Org-mode files to HTML, Org-mode defaults to generating random HTML ID anchors. To change that, you just override the &lt;code&gt;org-export-get-reference&lt;/code&gt; function that generates the IDs, right? &lt;/p&gt;
    &lt;code&gt;(advice-add #'org-export-get-reference :around #'org-html-stable-ids--get-reference)
&lt;/code&gt;
    &lt;p&gt; Oh no! It turns out that, sometimes Org-mode directly calls &lt;code&gt;org-html--reference&lt;/code&gt;, bypassing our override. That means we also need to redirect &lt;code&gt;org-html--reference&lt;/code&gt;: &lt;/p&gt;
    &lt;code&gt;(advice-add #'org-html--reference :override #'org-html-stable-ids--reference)
&lt;/code&gt;
    &lt;p&gt; Problem solved? No. Conventionally, Emacs Lisp code uses double dashes to tell the users âthis function is internalâ, as is in the &lt;code&gt;org-html--reference&lt;/code&gt; name. Yes, by being free to extend any part of the editor, you are free to modify any internal functions or states, in a way that may or may not be problematic under specific circumstances, with code that can be broken in any future updates. &lt;/p&gt;
    &lt;p&gt;And itâs not the end of it. The el-patch package allows you to apply âpatchesâ on most any Lisp code to modify behaviours nested deep inside a function:&lt;/p&gt;
    &lt;code&gt;;; Original function
(defun company-statistics--load ()
  "Restore statistics."
  (load company-statistics-file 'noerror nil 'nosuffix))

;; Patching
(el-patch-feature company-statistics)
(with-eval-after-load 'company-statistics
  (el-patch-defun company-statistics--load ()
                  "Restore statistics."
                  (load company-statistics-file 'noerror
                        ;; The patch
                        (el-patch-swap nil 'nomessage)
                        'nosuffix)))

;; Patched version
(defun company-statistics--load ()
  "Restore statistics."
  (load company-statistics-file 'noerror 'nomessage 'nosuffix))
&lt;/code&gt;
    &lt;p&gt; Luckily, el-patch provides &lt;code&gt;el-patch-validate&lt;/code&gt; so that you can worry less about your patches going ineffective or unexpectedly destructive. But you still need to maintain all your patches if anything goes wrong. &lt;/p&gt;
    &lt;p&gt;Any extensible system is not void of these problems. If you impose strong enough encapsulation, then eventually something canât get customized; if you expose everything, well, good luck keeping backward compatibility (as the system maintainer) or forward compatibility (as the user doing your modifications). By making it possible to âextend any part of the editor,â you are literally making any part of your code unextensible, and now âevery change breaks someoneâs workflow.â&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Emacsâs cross-language isolation/API might not be perfect, but Iâm very grateful for it. If Emacs were written in pure Lisp code and anything is extensible, my work-in-progress Emacs clone couldnât be remotely possible (because we do want to rid some of the spacebar heating problems while keeping some compatibility).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;5. Extensibility takes effortsÂ¶&lt;/head&gt;
    &lt;p&gt;Allow me to be blunt: the â100% Lispâ argument is lazy marketing. Writing a Lisp-extended editor in Lisp wonât immediately make your editor more extensible. Extensibility comes from careful designing of your API interfaces, it comes from learning from your history, listening to user needs, and, after all these, taking the effort and time actually write the interfacing code.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This blog entry was adapted from a rant thread I posted to vent my shock about Emacsâs&lt;/p&gt;&lt;code&gt;composition-function-table&lt;/code&gt;. Emacs is just never short of wonders and surprises, especially when youâre creating your own Emacsen by replicating Emacs.&lt;p&gt;By the way, this post is not against Lem, from which Iâve got a lot of inspirations and seen quite some good designs. But, itâs still the most convenient example I can think of. So, pardon me!&lt;/p&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;6. FootnotesÂ¶&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;âI want to write a better editor.â&lt;/cell&gt;
        &lt;cell&gt;ð With better accessibility, right?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;(silent gaze)&lt;/cell&gt;
        &lt;cell&gt;ð With better accessibility, right?&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Also, please donât mistake maintainability for extensibility. For example, Racket has migrated from its previous C core to a Racket core powered by Chez Scheme. Quoting from Rebuilding Racket on Chez Scheme Experience Report:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;â¦ itâs hard to put a number on these things but I can give you one number at least. This is the number of people who have been willing to modify the Racket macro expander.&lt;/p&gt;
      &lt;p&gt;This is when it was in C: two of us did it. And itâs already six people (after the C-to-Chez migration). Remember: the C part that was in the first 16 years and the last 16 years of that implementation, and the six people and the new implementation is just in two years. So weâre really pretty sure itâs gonna be better to maintain.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I do believe a mostly Lispy codebase can be better maintained and potentially attract more contributors than one in C. (But Emacs is mostly Lispy anyway.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46460394</guid><pubDate>Fri, 02 Jan 2026 01:36:25 +0000</pubDate></item><item><title>Happy Public Domain Day 2026</title><link>https://publicdomainreview.org/blog/2026/01/public-domain-day-2026/</link><description>&lt;doc fingerprint="3081d05f80b58200"&gt;
  &lt;main&gt;
    &lt;p&gt;The calendar turns, and once again a lively procession of books, images, films, and music leaves copyright behind and steps into the ever-growing public domain! On this year's Public Domain Day (which falls each January 1st) we welcome, in lots of countries around the world, the words of Wallace Stevens, Thomas Mann, Hannah Arendt, and Albert Einstein, and in the US a bevy of brilliant books including William Faulkner’s As I Lay Dying, Langston Hughes’ Not Without Laughter, Agatha Christie’s The Murder at the Vicarage, and, in their original German, Robert Musil’s The Man Without Qualities and Hermann Hesse’s Narcissus and Goldmund.&lt;/p&gt;
    &lt;p&gt;Due to differing copyright laws around the world, there is no one single public domain, but there are three main types of copyright term for historical works which cover most cases. For these three systems, newly entering the public domain today are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;works by people who died in 1955, for countries with a copyright term of “life plus 70 years” (relevant in UK, most of the EU, and South America);&lt;/item&gt;
      &lt;item&gt;works by people who died in 1975, for countries with a term of “life plus 50 years” (relevant to most of Africa and Asia);&lt;/item&gt;
      &lt;item&gt;films and books (incl. artworks featured) published in 1929 (relevant solely to the United States).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some of you may have been following our advent-style countdown calendar which revealed day-by-day through December our highlights for these new public domain entrants. The last window was opened yesterday, and while such a format was fun for the slow reveal, for the sake of a good gorgeable list we’ve exploded the calendar out into a digestible array below. Enjoy!&lt;/p&gt;
    &lt;head rend="h2"&gt;Entering the public domain in the US&lt;/head&gt;
    &lt;head rend="h3"&gt;William Faulkner – As I Lay Dying&lt;/head&gt;
    &lt;p&gt;As I Lay Dying is a Southern Gothic novel by American author William Faulkner, consistently ranked among the best novels of the 20th century. The title is derived from William Marris’s 1925 translation of Homer’s Odyssey, referring to the similar themes of both works.&lt;lb/&gt;The novel traces the story of the death of Addie Bundren and her poor, rural family’s quest to honor her wish to be buried in her hometown of Jefferson, Mississippi, as well as the motives—noble or selfish—they show on the journey. It uses a stream-of-consciousness writing technique and varying chapter lengths, and is narrated by 15 different characters over 59 chapters.&lt;lb/&gt;Faulkner said that he wrote the novel from midnight to 4:00 a.m. over the course of six weeks and that he did not change a word of it. He spent the first eight hours of his twelve-hour shift at the University of Mississippi Power House shoveling coal or directing other works and the remaining four hours handwriting his manuscript on unlined onionskin paper. As I Lay Dying represents a progenitor of the Southern Renaissance, reflecting on being, existence, and other existential metaphysics of everyday life, and helped to solidify Faulkner’s reputation as a pioneer, like James Joyce and Virginia Woolf, of stream of consciousness. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Arthur Ransome - Swallows and Amazons&lt;/head&gt;
    &lt;p&gt;Swallows and Amazons is a children’s adventure novel by English author Arthur Ransome. It is the first book in the Swallows and Amazons series, followed by Swallowdale.&lt;lb/&gt;Set in the summer of 1929 in England’s Lake District, the book relates the outdoor adventures and play of two families of children. These involve sailing, camping, fishing, exploration and piracy. The Walker children (John, Susan, Titty and Roger) are staying at a farm near a lake in the Lake District of England, during the school holidays. They sail a borrowed dinghy named Swallow and meet the Blackett children (Nancy and Peggy), who sail a dinghy named Amazon. When the children meet, they agree to join forces against a common enemy – the Blacketts’ uncle Jim Turner whom they call “Captain Flint” (after the parrot in Treasure Island).&lt;lb/&gt;The book was inspired by a summer spent by Ransome teaching the children of his friends, the Altounyans, to sail. At the time, Ransome had been working as a journalist with the Manchester Guardian, but decided to become a full-time author rather than go abroad as a foreign correspondent. Three of the Altounyan children’s names are adopted directly for the Walker family. However, later in life Ransome tried to downplay the Altounyan connections, changing the initial dedication of Swallows and Amazons and writing a new foreword which gave other sources. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Nan Shepherd – The Weatherhouse&lt;/head&gt;
    &lt;p&gt;The Weatherhouse is the second novel by Anna “Nan” Shepherd, a Scottish modernist writer and poet. The novel concerns interactions between people in a small rural Scottish community. It belongs to the great line of Scottish fiction dealing with the complex interactions of small communities, and especially the community of women — a touching and hilarious network of mothers, daughters, spinsters and widows. It is also a striking meditation on the nature of truth, the power of human longing and the mystery of being.&lt;lb/&gt;Shepherd published three works of fiction. Her short non-fiction book The Living Mountain, inspired by her love for hillwalking, is the book for which she is best known and has been quoted as an influence by prominent nature writers. The landscape and weather of this area play a major role in her novels and provide a focus for her poetry.&lt;lb/&gt;Shepherd’s fiction brings out the sharp conflict between the demands of tradition and the pull of modernity, particularly in women’s lives. All three novels assign a major role to the landscape and weather in small northern Scottish communities they describe. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Langston Hughes – Not Without Laughter&lt;/head&gt;
    &lt;p&gt;Not Without Laughter* is the debut novel of Langston Hughes, the American writer, activist, and leader of the Harlem Renaissance.&lt;lb/&gt;The novel portrays African-American life in Kansas in the 1910s, focusing on the effects of class and religion on the community. In telling the story of Sandy Rogers, a young African American boy in small-town Kansas, and of his family—his mother, Annjee, a housekeeper for a wealthy white family; his irresponsible father, Jimboy, who plays the guitar and travels the country in search of employment; his strong-willed grandmother Hager, who clings to her faith; his Aunt Tempy, who marries a rich man; and his Aunt Harriet, who struggles to make it as a blues singer—Hughes gives the longings and lineaments of Black life in the early twentieth century an important place in the history of racially divided America.&lt;lb/&gt;Hughes said that *Not Without Laughter* is semi-autobiographical, and that a good portion of the characters and setting included in the novel are based on his memories of growing up in Lawrence, Kansas. A review in *The New York Times* said that the novel is “very slow, even tedious, reading in its early chapters, but once it gains its momentum it moves as swiftly as a jazz rhythm”. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Hermann Hesse – Narcissus and Goldmund&lt;/head&gt;
    &lt;p&gt;Narcissus and Goldmund (in German, Narziß und Goldmund), also published in English as Death and the Lover, is a novel written by the German-Swiss author Hermann Hesse. At its publication, it was considered Hesse’s literary triumph.&lt;lb/&gt;The novel is the story of a young man, Goldmund (German for “Gold mouth”), who wanders aimlessly throughout Medieval Germany after leaving a Catholic monastery school in search of what could be described as “the meaning of life”. With the help of Narcissus, a gifted young teacher, and following an epiphanic experience with a beautiful Gypsy woman, Goldmund leaves the monastery and embarks on a wandering existence. He has numerous love affairs, studies art, and encounters human existence at its ugliest when the Black Death devastates the region. Eventually, he is reunited with his friend Narcissus, now an abbot.&lt;lb/&gt;Like most of Hesse’s works, the main theme of this book is the wanderer’s struggle to find himself, as well as the Jungian union of polar opposites (Mysterium Coniunctionis). Goldmund represents nature and the “feminine conscious mind” (but also anima, a man’s unconscious), while Narcissus represents science and logic and God and the “masculine conscious mind” (but also animus, a woman’s unconscious).&lt;lb/&gt;A film adaptation, directed by the Austrian Oscar-winning director Stefan Ruzowitzky, was released in 2020. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;All Quiet on the Western Front (1930 film)&lt;/head&gt;
    &lt;p&gt;All Quiet on the Western Front is a 1930 American pre-Code epic anti-war film based on the 1929 novel of the same name by German novelist Erich Maria Remarque. Directed by Lewis Milestone, it stars Lew Ayres, Louis Wolheim, John Wray, Slim Summerville, and William Bakewell.&lt;lb/&gt;The movie follows a group of German students moved to enlist in the army as part of the new 2nd Company. Their romantic delusions are quickly shattered during their brief but rigorous training under the abusive Sergeant Himmelstoss. After being sent to the Western Front, their idealism is destroyed by the harsh realities of combat.&lt;lb/&gt;Considered a realistic and harrowing account of warfare in World War I, the film opened to wide acclaim in the United States and made the American Film Institute’s first 100 Years... 100 Movies list in 1997. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page&lt;/p&gt;
    &lt;head rend="h3"&gt;Evelyn Waugh – Vile Bodies&lt;/head&gt;
    &lt;p&gt;Vile Bodies is the second novel by Arthur Evelyn St. John Waugh, an English writer of novels, biographies, and travel books, and a prolific journalist and book reviewer. It satirises London’s post–First World War “bright young things” — a group of Bohemian young aristocrats and socialites in London — and the press coverage around them. Waugh originally considered the title Bright Young Things but changed it; the published title echoes a narrator’s remark on crowds and parties: “Those vile bodies”.&lt;lb/&gt;The novel follows a vivid assortment of characters, among them the struggling writer Adam Fenwick-Symes and the glamorous, aristocratic Nina Blount, who hunt fast and furiously for ever greater sensations and the hedonistic fulfillment of their desires. Waugh’s acidly funny satire reveals the darkness and vulnerability beneath the sparkling surface of the high life.&lt;lb/&gt;The book shifts in tone from light-hearted romp to bleak desolation (Waugh himself later attributed it to the breakdown of his first marriage halfway through the book’s composition). Critics have noted the novel’s fragmented scenes, jump-cuts, and telephone dialogue, often linking its method to cinema and to modernist effects. Some have defended the novel’s downbeat ending as a poetically just reversal of the conventions of comic romance.&lt;lb/&gt;David Bowie cited the novel as the primary influence in writing his song “Aladdin Sane”, and a film adaptation, written and directed by Stephen Fry, was released in 2003. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Margaret Ayer Barnes - Years of Grace&lt;/head&gt;
    &lt;p&gt;Years of Grace is the first book by the American playwright, novelist, and short-story writer Margaret Ayer Barnes. It won the Pulitzer Prize for the Novel in 1931.&lt;lb/&gt;The story, beginning in the 1890s and continuing into the 1930s, chronicles the life of Jane Ward Carver from her teens to age 54. This novel follows many of the same themes as Barnes’s other works. Centering on the social manners of upper middle class society, her female protagonists are often traditionalists, struggling to uphold conventional morality in the face of changing social climates. Barnes’s alma mater Bryn Mawr College, along with the characters of college presidents M. Carey Thomas and Marion Park, figure prominently in this work.&lt;lb/&gt;The New York Times commented that “this story of the death of an old order and the birth of a new one, of the perpetually renewed conflict between succeeding generations... holds the reader’s attention to the end.” Despite the success of Years of Grace, it is not Barnes’s best-known work; that honor belongs to Dishonored Lady, a play she co-wrote with Edward Sheldon, which was adapted twice into film. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read free ebook through Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Hellbound Train&lt;/head&gt;
    &lt;p&gt;Hell-Bound Train is a 1930 film written and directed by James and Eloyce Gist. A self-taught husband-and-wife team with a shared religious mission, they produced at least three silent films for African American church audiences, touring them across the United States. Shown alongside sermons, these works used cinema as a vehicle for evangelism. In Hell-Bound Train — which Eloyce is said to have rewritten, re-edited, and partly refilmed after James’s initial version — the viewer passes from carriage to carriage as the filmmakers stage various “Jazz Age” sins, including dancing, drinking, and gambling, all overseen by a mischievous devil conductor. Though Hell-Bound Train has gained some renewed attention via Kino Lorber’s Pioneers of African-American Cinema box set and a brief run on the Criterion Channel, this film — one of the few surviving silent works by an African American woman — is still often absent from retrospectives on early women filmmakers, perhaps because of its modest production values and overtly moralizing tone. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Watch on YouTube&lt;/p&gt;
    &lt;head rend="h3"&gt;Robert Musil – The Man Without Qualities&lt;/head&gt;
    &lt;p&gt;The Man Without Qualities (in German Der Mann ohne Eigenschaften) is an unfinished modernist novel in three volumes and various drafts, by the Austrian writer Robert Musil, published in parts from 1930 to 1943.&lt;lb/&gt;The novel is a “story of ideas”, which takes place in the time of the Austro-Hungarian monarchy’s last days. The plot often veers into allegorical digressions on a wide range of existential themes concerning humanity and feelings. It has a particular concern with the values of truth and opinion and how society organizes ideas about life and society. The book is well over a thousand pages long in its entirety, and no one single theme dominates.&lt;lb/&gt;The story takes place in 1913 in Vienna, the capital of Austria-Hungary, which Musil refers to by the playful term Kakanien. Part I, titled A Sort of Introduction, is an introduction to the protagonist, a mathematician named Ulrich whose ambivalence towards morals and indifference to life make him “a man without qualities”. In Part II, Pseudoreality Prevails, Ulrich joins preparations for a celebration in honor of 70 years of the Austrian Emperor Franz Joseph’s reign. Part III, entitled Into the Millennium (The Criminals), is about Ulrich’s sister Agathe. They experience a mystically incestuous stirring upon meeting after their father’s death.&lt;lb/&gt;Musil worked on the novel for more than twenty years: his detailed portrait of a decaying fin de siècle world has strong autobiographical features. Musil’s almost daily preoccupation with writing left his family in dire financial straits. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read German original on Project Gutenberg&lt;/p&gt;
    &lt;head rend="h3"&gt;T. S. Eliot – Ash Wednesday&lt;/head&gt;
    &lt;p&gt;Ash Wednesday is a long poem written by T. S. Eliot during his 1927 conversion to Anglicanism. Published in 1930, the poem deals with the struggle that ensues when one who has lacked faith in the past strives to move towards God.&lt;lb/&gt;Sometimes referred to as Eliot’s “conversion poem”, Ash Wednesday, with a base of Dante’s Purgatorio, is richly but ambiguously allusive and deals with the move from spiritual barrenness to hope for human salvation. The style is different from his poetry which predates his conversion. Ash Wednesday and the poems that followed had a more casual, melodic, and contemplative method.&lt;lb/&gt;The poem’s title comes from the Western Christian fast day that marks the beginning of Lent, forty days before Easter. It is a poem about the difficulty of religious belief, and concerned with personal salvation in an age of uncertainty. In it, Eliot’s poetic persona, one who has lacked faith in the past, has somehow found the courage, through spiritual exhaustion, to seek faith.&lt;lb/&gt;The initial reception of Ash Wednesday was largely positive, though many of the more secular literati found its groundwork of orthodox Christianity discomfiting. Edwin Muir maintained that “‘Ash Wednesday’ is one of the most moving poems he [Eliot] has written, and perhaps the most perfect”. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on English Verse and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Agatha Christie - The Murder at the Vicarage&lt;/head&gt;
    &lt;p&gt;The Murder at the Vicarage is a work of detective fiction by the British writer Agatha Christie. It is the first novel to feature the character of Miss Marple and her village of St Mary Mead (characters that had previously appeared in short stories).&lt;lb/&gt;The story is set in the quiet English village of St Mary Mead, where life is seemingly peaceful until Colonel Protheroe, the local magistrate and a widely disliked man, is found shot dead in the vicar’s study. The vicar, Leonard Clement, is the narrator of the story. Just before the murder, he had remarked that “anyone who murdered Colonel Protheroe would be doing the world a service” — a comment that comes back to haunt him.&lt;lb/&gt;Several suspects quickly emerge, as well as Miss Marple, who proves, though she appears at first as a nosy old spinster, to have unmatched observational skills and a deep understanding of human nature. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read free ebook through Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Franz Kafka - The Castle (english translation)&lt;/head&gt;
    &lt;p&gt;The Castle (in German, *Das Schloss*) is a 1926 novel by Franz Kafka. In it a protagonist known only as “K.” arrives in a village and struggles to gain access to the mysterious authorities who govern it from a castle supposedly owned by Count Westwest. Kafka died before he could finish the work, but suggested it would end with K. dying in the village, the castle notifying him on his death bed that his “legal claim to live in the village was not valid, yet, taking certain auxiliary circumstances into account, he was permitted to live and work there.” Dark and at times surreal, *The Castle* is often understood to be about alienation, unresponsive bureaucracy, the frustration of trying to conduct business with non-transparent, seemingly arbitrary controlling systems, and the futile pursuit of an unobtainable goal. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read free ebook through Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Sigmund Freud – Civilization and Its Discontents&lt;/head&gt;
    &lt;p&gt;Civilization and Its Discontents is a book by Sigmund Freud, the founder of psychoanalysis. It was written in 1929 and first published in German in 1930 as Das Unbehagen in der Kultur (“The Uneasiness in Civilization”).&lt;lb/&gt;Exploring what Freud saw as a clash between the desire for individuality and the expectations of society, the book is considered one of Freud’s most important and widely read works, and was described in 1989 by historian Peter Gay as one of the most influential and studied books in the field of modern psychology.&lt;lb/&gt;The book espouses a theory grounded in the notion that humans have certain characteristic instincts that are immutable. The primary tension originates from an individual attempting to find instinctive freedom, and civilization’s contrary demand for conformity and repression of instincts. Freud states that when any situation that is desired by the pleasure principle is prolonged, it creates a feeling of mild resentment as it clashes with the reality principle.&lt;lb/&gt;Primitive instincts—for example, the desire to kill and the insatiable craving for sexual gratification—are harmful to the collective wellbeing of a human community. The historical development of laws that prohibit violence, murder, rape, and adultery, he argued, is an inherent quality of civilization that gives rise to perpetual feelings of discontent among individuals. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Stella Benson - The Far-Away Bride&lt;/head&gt;
    &lt;p&gt;The Far-Away Bride is the most famous book by the English feminist, novelist, poet, and travel writer Stella Benson. It was published in the United States first in 1930 and as Tobit Transplanted in Britain in 1931. It won the Femina Vie Heureuse Prize for English writers in 1932.&lt;lb/&gt;The novel deals with a family of Russian émigrés in Manchuria. Its characters are the old, grumbling and tearfully sentimental Russian intellectual, Malinin; his disheveled, kind-hearted and unbearable wife, Anna; and Seryozha, their resourceful 19-year-old son. Spending their time in laziness, indulging in exaggerated Russian disorder and comical quarrels growing out of every trifle, they are incongruously happy. The humorous and adventurous action of the novel starts when Seryozha sets out, on foot, on a business trip to the Korean city of Seoul (where he must recover 200 yens); it is there that he finds his “far-away bride” — a charming and whimsical Russian girl who has already broken seven hearts and whose heart he finally conquers.&lt;lb/&gt;Benson described the novel as an “accurate modernization” of the Book of Tobit, a work of Second Temple Jewish literature dating to the 3rd or early 2nd century BC; The New York Times described The Far-Away Bride, rather, as a “spirited parody of it.” Benson’s novel, writes the reviewer, is “a truly felicitous comedy of the human personality”. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Vladimir Nabokov - The Defense&lt;/head&gt;
    &lt;p&gt;The Defense (in Russian, Zashchita Luzhinais) is the third novel written by Vladimir Nabokov after he had emigrated to Berlin. It appeared first under Nabokov’s pen name V. Sirin in the Russian émigré quarterly Sovremennye zapiski and was thereafter published by the émigré publishing house Slovo as The Luzhin Defense in Berlin.&lt;lb/&gt;The novel tells the story of Luzhin. As a young boy, unattractive, withdrawn, sullen, he takes up chess as a refuge from the anxiety of his everyday life. His talent is prodigious and he rises to the rank of grandmaster, but at a cost: in Luzhin’s obsessive mind, the game of chess gradually supplants the world of reality. His own world falls apart during a crucial championship match, when the intricate defense he has devised withers under his opponent’s unexpected and unpredictable lines of assault.&lt;lb/&gt;The character of Luzhin is based on Curt von Bardeleben, a chess master Nabokov knew personally, and Nabokov links the events in the central chapters to moves as encountered in chess problems. The book was adapted to film in 2000, as The Luzhin Defence. It was directed by Marleen Gorris, and starred John Turturro as Luzhin. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Dashiell Hammett – The Maltese Falcon&lt;/head&gt;
    &lt;p&gt;The Maltese Falcon is a detective novel by American writer Dashiell Hammett, originally serialized in the magazine Black Mask beginning with the September 1929 issue. The story is told entirely in external third-person narrative; there is no description whatsoever of any character’s thoughts or feelings, only what they say and do, and how they look. The novel has been adapted several times for the cinema and is considered part of the hardboiled genre, which Hammett played a major part in popularizing.&lt;lb/&gt;The novel follows Sam Spade, a private detective in San Francisco, in partnership with Miles Archer. The beautiful “Miss Wonderley” hires them to follow Floyd Thursby, who she claims has run off with her sister. Archer takes the first stint but is found shot dead that night. “Miss Wonderley” is soon revealed to be an acquisitive adventuress named Brigid O’Shaughnessy, who is involved in the search for a black statuette of unknown but substantial value. Red herrings abound.&lt;lb/&gt;Although Hammett himself worked for a time as a private detective for the Pinkerton Detective Agency in San Francisco (and used his given name, Samuel, for the story’s protagonist), Hammett asserted that “Spade has no original. He is a dream man in the sense that he is what most of the private detectives I worked with would like to have been, and, in their cockier moments, thought they approached.” (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read on Faded Page and Standard Books&lt;/p&gt;
    &lt;head rend="h3"&gt;Stanisław Ignacy Witkiewicz – Insatiability&lt;/head&gt;
    &lt;p&gt;Insatiability (in Polish Nienasycenie) is a speculative fiction novel by the Polish writer, dramatist, philosopher, painter and photographer, Stanisław Ignacy Witkiewicz (Witkacy). It is Witkiewicz’s third novel, considered by some to be his best.&lt;lb/&gt;Consisting of two parts — Przebudzenie (Awakening) and Obłęd (The Madness) — the novel takes place in the future, circa 2000. Following a battle, modeled after the Bolshevik revolution, Poland is overrun by the army of the last and final Mongol conquest. The nation becomes enslaved to the Chinese leader Murti Bing. His emissaries give everyone a special pill called DAVAMESK B 2 which takes away their abilities to think and to mentally resist. East and West become one, in faceless misery fueled by sexual instincts.&lt;lb/&gt;The book combines chaotic action with deep philosophical and political discussion, and predicts many of the events and political outcomes of the subsequent years, specifically, the invasion of Poland, the postwar foreign domination as well as the totalitarian mind control exerted, first by the Germans, and then by the Soviet Union on Polish life and art. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Read more about Witkiewicz’s artworks in our essay “Documenting Drugs” by Juliette Bretan&lt;/p&gt;
    &lt;head rend="h2"&gt;Entering the public domain in countries with a ‘life plus 70 year’ copyright term&lt;/head&gt;
    &lt;head rend="h3"&gt;Albert Einstein&lt;/head&gt;
    &lt;p&gt;Albert Einstein was a German-born theoretical physicist best known for developing the theory of relativity. Einstein also made important contributions to quantum theory. His mass–energy equivalence formula E = mc^2, which arises from special relativity, has been called “the world’s most famous equation”. He received the 1921 Nobel Prize in Physics for “his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect”.&lt;lb/&gt;In 1905, sometimes described as his *annus mirabilis* (miracle year), he published four groundbreaking papers. In them, he outlined a theory of the photoelectric effect, explained Brownian motion, introduced his special theory of relativity, and demonstrated that if the special theory is correct, mass and energy are equivalent to each other. In 1915, he proposed a general theory of relativity that extended his system of mechanics to incorporate gravitation. A cosmological paper that he published the following year laid out the implications of general relativity for the modeling of the structure and evolution of the universe as a whole. In 1917, Einstein introduced the concepts of spontaneous emission and stimulated emission, the latter of which is the core mechanism behind the laser and maser, and which helped lay the groundwork for later developments in physics such as quantum electrodynamics and quantum optics. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Works at Wikisource&lt;/p&gt;
    &lt;head rend="h3"&gt;Wallace Stevens&lt;/head&gt;
    &lt;p&gt;Wallace Stevens was an American modernist poet. He was born in Reading, Pennsylvania, educated at Harvard and then New York Law School, and spent most of his life working as an executive for an insurance company in Hartford, Connecticut.&lt;lb/&gt;Stevens’s first period begins with the publication of Harmonium (1923), followed by a slightly revised and amended second edition in 1930. It features, among other poems, “The Emperor of Ice-Cream”, “Sunday Morning”, “The Snow Man”, and “Thirteen Ways of Looking at a Blackbird”. His second period commenced with Ideas of Order (1933), included in Transport to Summer (1947). His third and final period began with the publication of The Auroras of Autumn (1950), followed by The Necessary Angel: Essays On Reality and the Imagination (1951).&lt;lb/&gt;Many of Stevens’s poems deal with the making of art and poetry in particular. His Collected Poems (1954) won the Pulitzer Prize for Poetry in 1955 and Stevens is a rare example of a poet whose main output came largely only as he approached 40 years of age. His first major publication (four poems from a sequence titled “Phases” in the November 1914 edition of Poetry) was written at age 35, although as an undergraduate at Harvard, Stevens had written poetry and exchanged sonnets with Santayana. Many of his canonical works were written well after he turned 50. According to the literary scholar Harold Bloom, no Western writer since Sophocles has had such a late flowering of artistic genius. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Charlie Parker&lt;/head&gt;
    &lt;p&gt;Charles Parker Jr. was an American jazz saxophonist, bandleader, and composer. Parker was a highly influential soloist and leading figure in the development of bebop, a form of jazz characterized by fast tempos, virtuosic technique, and advanced harmonies. He was a virtuoso and introduced revolutionary rhythmic and harmonic ideas into jazz, including rapid passing chords, new variants of altered chords, and chord substitutions. Parker primarily played the alto saxophone.&lt;lb/&gt;Parker was an icon for the hipster subculture and later the Beat Generation, personifying the jazz musician as an uncompromising artist and intellectual rather than just an entertainer.&lt;lb/&gt;His style of composition involved interpolation of original melodies over existing jazz forms and standards, a practice known as contrafact and still common in jazz today. Examples include “Ornithology” (which borrows the chord progression of jazz standard “How High the Moon” and is said to be co-written with trumpet player Little Benny Harris), and “Moose The Mooche”. The practice was not uncommon prior to bebop, but it became a signature of the movement as artists began to move away from arranging popular standards and toward composing their own material. Parker contributed greatly to the modern jazz solo, one in which triplets and pick-up notes were used in unorthodox ways to lead into chord tones.&lt;lb/&gt;Miles Davis once said, “You can tell the history of jazz in four words: Louis Armstrong. Charlie Parker.” (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Thomas Mann&lt;/head&gt;
    &lt;p&gt;Paul Thomas Mann was a German novelist, short story writer, social critic, philanthropist, essayist, and the 1929 Nobel Prize in Literature laureate. His highly symbolic and ironic epic novels and novellas are noted for their insight into the psychology of the artist and the intellectual. His analysis and critique of the European and German soul used modernized versions of German and Biblical stories, as well as the ideas of Johann Wolfgang von Goethe, Friedrich Nietzsche, and Arthur Schopenhauer.&lt;lb/&gt;Mann was a member of the hanseatic Mann family and portrayed his family and class in his first novel, Buddenbrooks (1901). Further major novels include The Magic Mountain (1924), the tetralogy Joseph and His Brothers (1933–1943), and Doctor Faustus (1947); he also wrote short stories and novellas, including Death in Venice (1912).&lt;lb/&gt;When Adolf Hitler came to power in 1933, Mann fled to Switzerland and when World War II broke out in 1939, he moved to the United States, then returned to Switzerland in 1952. Mann is one of the best-known exponents of the so-called Exilliteratur, German literature written in exile by those who opposed the Hitler regime. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Works at Project Gutenberg&lt;/p&gt;
    &lt;head rend="h3"&gt;Pierre Teilhard de Chardin&lt;/head&gt;
    &lt;p&gt;Pierre Teilhard de Chardin was a French Jesuit, Catholic priest, scientist, paleontologist, philosopher, mystic, and teacher. He investigated the theory of evolution from a perspective influenced by Henri Bergson and Christian mysticism, writing multiple scientific and religious works on the subject, his most popular being The Phenomenon of Man, published posthumously in 1955. His mainstream scientific achievements include his palaeontological research in China, taking part in the discovery of the significant Peking Man fossils from the Zhoukoudian cave complex near Beijing. His more speculative ideas, sometimes criticized as pseudoscientific, have included a vitalist conception of the Omega Point. Along with Vladimir Vernadsky, he contributed to the development of the concept of the noosphere.&lt;lb/&gt;In 1962, the Holy Office issued a warning regarding Teilhard’s works, alleging ambiguities and doctrinal errors without specifying them. Some eminent Catholic figures, including Pope Benedict XVI and Pope Francis, have made positive comments on some of his ideas since. The response to his writings by scientists has been divided. His work was controversial to some scientists and religious leaders because Teilhard combined theology and metaphysics with science.&lt;lb/&gt;Teilhard served in World War I as a stretcher-bearer. He received several citations, and was awarded the Médaille militaire and the Legion of Honor, the highest French order of merit, both military and civil. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Roger Mais&lt;/head&gt;
    &lt;p&gt;Roger Mais was a Jamaican journalist, novelist, poet, and playwright. He was born to a middle-class family in Kingston, Jamaica. By 1951, he had won ten first prizes in West Indian literary competitions. His integral role in the development of political and cultural nationalism is evidenced in his being awarded the high honour of the Order of Jamaica in 1978.&lt;lb/&gt;He worked at various times as a photographer, insurance salesman, and journalist, launching his journalistic career as a contributor to the weekly newspaper Public Opinion from 1939 to 1952. Mais published more than a hundred short stories, most appearing in Public Opinion and Focus, with others collected in Face and Other Stories and And Most of All Man. He wrote more than thirty stage and radio plays, as well as three novels: The Hills Were Joyful Together (1953), Brother Man (1954), and Black Lightning (1955).&lt;lb/&gt;Mais’ topics most frequently were the social injustice and inequality suffered by black, poor Jamaicans. Accused of sedition for writing the article “Now We Know,” a 1944 denunciation of the British Empire, the Jamaican novelist was tried, convicted and imprisoned for six months. His political activism, anti-colonial writing, and imprisonment helped galvanize Jamaican nationalism. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Saadat Hasan Manto&lt;/head&gt;
    &lt;p&gt;Saadat Hasan Manto was a Pakistani writer, playwright and novelist from Punjab, who is regarded as the greatest short-story author in Urdu literature. He was active from 1933 during British rule till his death in 1955 after independence.&lt;lb/&gt;Writing mainly in Urdu, he produced 22 collections of short stories, a novel, five series of radio plays, three collections of essays, and two collections of personal sketches. He is best known for his stories about the partition of India, which he opposed, immediately following independence in 1947. Manto’s most notable work has been archived by Rekhta.&lt;lb/&gt;Manto was tried six times for alleged obscenity in his writings; thrice before 1947 in British India, and thrice after independence in 1947 in Pakistan, but was never convicted. He started his literary career translating the works of Victor Hugo, Oscar Wilde and Russian writers such as Chekhov and Gorky. His first story was “Tamasha”, based on the Jallianwala Bagh massacre at Amritsar. His final works, which grew from the social climate and his own financial struggles, reflected an innate sense of human impotency towards darkness and contained satire that verged on dark comedy, as seen in his last story, “Toba Tek Singh”. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h2"&gt;Entering the public domain in countries with a ‘life plus 50 year’ copyright term&lt;/head&gt;
    &lt;head rend="h3"&gt;Barbara Hepworth&lt;/head&gt;
    &lt;p&gt;Dame Jocelyn Barbara Hepworth was an English artist and sculptor. Along with artists such as Ben Nicholson and Naum Gabo, Hepworth was a leading figure in the colony of artists who resided in St Ives during the Second World War. Born in Wakefield, Yorkshire, Hepworth studied at Leeds School of Art and the Royal College of Art in the 1920s. She married the sculptor John Skeaping in 1925. In 1931 she fell in love with the painter Ben Nicholson, and in 1933 divorced Skeaping. At this time she was part of a circle of modern artists centred on Hampstead, London, and was one of the founders of the art movement Unit One. At the beginning of the Second World War Hepworth and Nicholson moved to St Ives, Cornwall, where she would remain for the rest of her life. Best known as a sculptor, Hepworth also produced drawings – including a series of sketches of operating rooms following the hospitalisation of her daughter in 1944 – and lithographs. She died in a fire at her studio in 1975. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Hannah Arendt&lt;/head&gt;
    &lt;p&gt;Hannah Arendt was a German and American historian and philosopher. She was one of the most influential political theorists of the twentieth century.&lt;lb/&gt;Her works cover a broad range of topics, but she is best known for those dealing with the nature of wealth, power, fame, and evil, as well as politics, direct democracy, authority, tradition, and totalitarianism. She is also remembered for the controversy surrounding the trial of Adolf Eichmann, for her attempt to explain how ordinary people become actors in totalitarian systems, which was considered by some an apologia, and for the phrase “the banality of evil”.&lt;lb/&gt;In 1933, Arendt was briefly imprisoned by the Gestapo for performing illegal research into antisemitism. On release, she fled Germany, settling in Paris. There she worked for Youth Aliyah, assisting young Jews to emigrate to the British Mandate of Palestine. When Germany invaded France she was detained as an alien, but she escaped and made her way to the United States in 1941. She became a writer and editor and worked for the Jewish Cultural Reconstruction, becoming an American citizen in 1950. With the publication of The Origins of Totalitarianism in 1951, her reputation as a thinker and writer was established, and a series of works followed. These included the books The Human Condition in 1958, as well as Eichmann in Jerusalem and On Revolution in 1963. She taught at many American universities while declining tenure-track appointments. She died suddenly of a heart attack in 1975, leaving her last work, The Life of the Mind, unfinished. (Wikipedia)&lt;/p&gt;
    &lt;head rend="h3"&gt;Walker Evans&lt;/head&gt;
    &lt;p&gt;Walker Evans was an American photographer and photojournalist best known for his work for the Resettlement Administration and the Farm Security Administration (FSA) documenting the effects of the Great Depression. Evans’ published his first photos at the age of 27. Much of Evans’ New Deal work uses the large format, 8 × 10-inch (200×250 mm) view camera. He said that his goal as a photographer was to make pictures that are “literate, authoritative, transcendent”.&lt;lb/&gt;Many of his works are in the permanent collections of museums and have been the subject of retrospectives at such institutions as the Metropolitan Museum of Art or the George Eastman Museum.&lt;lb/&gt;Born in St. Louis, Missouri, Evans took up photography in 1928 around the time he was living in Ossining, New York. The Great Depression years of 1935–36 were a period of remarkable productivity and accomplishment for Evans. In 1936, employed by the National Recovery Administration, he photographed three impoverished sharecropper families in Hale County, Alabama. The photographs became iconic and were praised for effectively capturing the negative effects of the Great Depression in the American South. Between 1940 and 1959, Evans was awarded three Guggenheim Fellowships in Photography to continue his work of making record photographs of contemporary American subjects. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Works at Library of Congress&lt;/p&gt;
    &lt;head rend="h3"&gt;P. G. Wodehouse&lt;/head&gt;
    &lt;p&gt;Sir Pelham Grenville Wodehouse was an English writer and one of the most widely read humorists of the 20th century. His creations include the feather-brained Bertie Wooster and his sagacious valet, Jeeves; the immaculate and loquacious Psmith; Lord Emsworth and the Blandings Castle set; the Oldest Member, with stories about golf; and Mr. Mulliner, with tall tales on subjects ranging from bibulous bishops to megalomaniac movie moguls.&lt;lb/&gt;Born in Guildford, his early novels were mostly school stories, but he later switched to comic fiction. Most of Wodehouse’s fiction is set in his native United Kingdom, although he spent much of his life in the US and used New York and Hollywood as settings for some of his novels and short stories. Wodehouse was a prolific writer throughout his life, publishing more than ninety books, forty plays, two hundred short stories and other writings between 1902 and 1974. Early in his career Wodehouse would produce a novel in about three months, but he slowed in old age to around six months. He used a mixture of Edwardian slang, quotations from and allusions to numerous poets, and several literary techniques to produce a prose style that has been compared to comic poetry and musical comedy. Some critics of Wodehouse have considered his work flippant, but among his fans are former British prime ministers and many of his fellow writers. (Wikipedia)&lt;/p&gt;
    &lt;p&gt;Works at Project Gutenberg&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46460440</guid><pubDate>Fri, 02 Jan 2026 01:42:16 +0000</pubDate></item><item><title>Marmot – A distributed SQLite server with MySQL wire compatible interface</title><link>https://github.com/maxpert/marmot</link><description>&lt;doc fingerprint="f99204d0da0b98c"&gt;
  &lt;main&gt;
    &lt;p&gt;Marmot v2 is a leaderless, distributed SQLite replication system built on a gossip-based protocol with distributed transactions and eventual consistency.&lt;/p&gt;
    &lt;p&gt;Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leaderless Architecture: No single point of failure - any node can accept writes&lt;/item&gt;
      &lt;item&gt;MySQL Protocol Compatible: Connect with any MySQL client (DBeaver, MySQL Workbench, mysql CLI)&lt;/item&gt;
      &lt;item&gt;Distributed Transactions: Percolator-style write intents with conflict detection&lt;/item&gt;
      &lt;item&gt;Multi-Database Support: Create and manage multiple databases per cluster&lt;/item&gt;
      &lt;item&gt;DDL Replication: Distributed schema changes with automatic idempotency and cluster-wide locking&lt;/item&gt;
      &lt;item&gt;Production-Ready SQL Parser: Powered by rqlite/sql AST parser for MySQL→SQLite transpilation&lt;/item&gt;
      &lt;item&gt;CDC-Based Replication: Row-level change data capture for consistent replication&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Start a single-node cluster
./marmot-v2

# Connect with MySQL client
mysql -h localhost -P 3306 -u root

# Or use DBeaver, MySQL Workbench, etc.&lt;/code&gt;
    &lt;code&gt;# Test DDL and DML replication across a 2-node cluster
./scripts/test-ddl-replication.sh

# This script will:
# 1. Start a 2-node cluster
# 2. Create a table on node 1 and verify it replicates to node 2
# 3. Insert data on node 1 and verify it replicates to node 2
# 4. Update data on node 2 and verify it replicates to node 1
# 5. Delete data on node 1 and verify it replicates to node 2

# Manual cluster testing
./examples/start-seed.sh              # Start seed node (port 8081, mysql 3307)
./examples/join-cluster.sh 2 localhost:8081  # Join node 2 (port 8082, mysql 3308)
./examples/join-cluster.sh 3 localhost:8081  # Join node 3 (port 8083, mysql 3309)

# Connect to any node and run queries
mysql --protocol=TCP -h localhost -P 3307 -u root
mysql --protocol=TCP -h localhost -P 3308 -u root

# Cleanup
pkill -f marmot-v2&lt;/code&gt;
    &lt;p&gt;Marmot v2 uses a fundamentally different architecture from other SQLite replication solutions:&lt;/p&gt;
    &lt;p&gt;vs. rqlite/dqlite/LiteFS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ They require a primary node for all writes&lt;/item&gt;
      &lt;item&gt;✅ Marmot allows writes on any node&lt;/item&gt;
      &lt;item&gt;❌ They use leader election (Raft)&lt;/item&gt;
      &lt;item&gt;✅ Marmot uses gossip protocol (no leader)&lt;/item&gt;
      &lt;item&gt;❌ They require proxy layer or page-level interception&lt;/item&gt;
      &lt;item&gt;✅ Marmot uses MySQL protocol for direct database access&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How It Works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Write Coordination: 2PC (Two-Phase Commit) with configurable consistency (ONE, QUORUM, ALL)&lt;/item&gt;
      &lt;item&gt;Conflict Resolution: Last-Write-Wins (LWW) with HLC timestamps&lt;/item&gt;
      &lt;item&gt;Cluster Membership: SWIM-style gossip with failure detection&lt;/item&gt;
      &lt;item&gt;Data Replication: Full database replication - all nodes receive all data&lt;/item&gt;
      &lt;item&gt;DDL Replication: Cluster-wide schema changes with automatic idempotency&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot v2 supports distributed DDL (Data Definition Language) replication without requiring master election:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Cluster-Wide Locking: Each DDL operation acquires a distributed lock per database (default: 30-second lease)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Prevents concurrent schema changes on the same database&lt;/item&gt;
          &lt;item&gt;Locks automatically expire if a node crashes&lt;/item&gt;
          &lt;item&gt;Different databases can have concurrent DDL operations&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automatic Idempotency: DDL statements are automatically rewritten for safe replay&lt;/p&gt;
        &lt;quote&gt;CREATE TABLE users (id INT) → CREATE TABLE IF NOT EXISTS users (id INT) DROP TABLE users → DROP TABLE IF EXISTS users&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Schema Version Tracking: Each database maintains a schema version counter&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incremented on every DDL operation&lt;/item&gt;
          &lt;item&gt;Exchanged via gossip protocol for drift detection&lt;/item&gt;
          &lt;item&gt;Used by delta sync to validate transaction applicability&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Quorum-Based Replication: DDL replicates like DML through the same 2PC mechanism&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;No special master node needed&lt;/item&gt;
          &lt;item&gt;Works with existing consistency levels (QUORUM, ALL, etc.)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[ddl]
# DDL lock lease duration (seconds)
lock_lease_seconds = 30

# Automatically rewrite DDL for idempotency
enable_idempotent = true&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Do: Execute DDL from a single connection/node at a time&lt;/item&gt;
      &lt;item&gt;✅ Do: Use qualified table names (&lt;code&gt;mydb.users&lt;/code&gt;instead of&lt;code&gt;users&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Caution: ALTER TABLE is less idempotent - avoid replaying failed ALTER operations&lt;/item&gt;
      &lt;item&gt;❌ Don't: Run concurrent DDL on the same database from multiple nodes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot v2 uses Change Data Capture (CDC) for replication instead of SQL statement replay:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Row-Level Capture: Instead of replicating SQL statements, Marmot captures the actual row data changes (INSERT/UPDATE/DELETE)&lt;/item&gt;
      &lt;item&gt;Binary Data Format: Row data is serialized as CDC messages with column values, ensuring consistent replication regardless of SQL dialect&lt;/item&gt;
      &lt;item&gt;Deterministic Application: Row data is applied directly to the target database, avoiding parsing ambiguities&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Consistency: Same row data applied everywhere, no SQL parsing differences&lt;/item&gt;
      &lt;item&gt;Performance: Binary format is more efficient than SQL text&lt;/item&gt;
      &lt;item&gt;Reliability: No issues with SQL syntax variations between MySQL and SQLite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For UPDATE and DELETE operations, Marmot automatically extracts row keys:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses PRIMARY KEY columns when available&lt;/item&gt;
      &lt;item&gt;Falls back to ROWID for tables without explicit primary key&lt;/item&gt;
      &lt;item&gt;Handles composite primary keys correctly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot can publish CDC events to external messaging systems, enabling real-time data pipelines, analytics, and event-driven architectures. Events follow the Debezium specification for maximum compatibility with existing CDC tooling.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debezium-Compatible Format: Events conform to the Debezium event structure, compatible with Kafka Connect, Flink, Spark, and other CDC consumers&lt;/item&gt;
      &lt;item&gt;Multi-Sink Support: Publish to multiple destinations simultaneously (Kafka, NATS)&lt;/item&gt;
      &lt;item&gt;Glob-Based Filtering: Filter which tables and databases to publish&lt;/item&gt;
      &lt;item&gt;Automatic Retry: Exponential backoff with configurable limits&lt;/item&gt;
      &lt;item&gt;Persistent Cursors: Survives restarts without losing position&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[publisher]
enabled = true

[[publisher.sinks]]
name = "kafka-main"
type = "kafka"                    # "kafka" or "nats"
format = "debezium"               # Debezium-compatible JSON format
brokers = ["localhost:9092"]      # Kafka broker addresses
topic_prefix = "marmot.cdc"       # Topics: {prefix}.{database}.{table}
filter_tables = ["*"]             # Glob patterns (e.g., "users", "order_*")
filter_databases = ["*"]          # Glob patterns (e.g., "prod_*")
batch_size = 100                  # Events per poll cycle
poll_interval_ms = 10             # Polling interval

# NATS sink example
[[publisher.sinks]]
name = "nats-events"
type = "nats"
format = "debezium"
nats_url = "nats://localhost:4222"
topic_prefix = "marmot.cdc"
filter_tables = ["*"]
filter_databases = ["*"]&lt;/code&gt;
    &lt;p&gt;Events follow the Debezium envelope structure:&lt;/p&gt;
    &lt;code&gt;{
  "schema": { ... },
  "payload": {
    "before": null,
    "after": {"id": 1, "name": "alice", "email": "alice@example.com"},
    "source": {
      "version": "2.0.0",
      "connector": "marmot",
      "name": "marmot",
      "ts_ms": 1702500000000,
      "db": "myapp",
      "table": "users"
    },
    "op": "c",
    "ts_ms": 1702500000000
  }
}&lt;/code&gt;
    &lt;p&gt;Operation Types (per Debezium spec):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Operation&lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;op&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;before&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;after&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;INSERT&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;c&lt;/code&gt; (create)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;null&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;row data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;UPDATE&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;u&lt;/code&gt; (update)&lt;/cell&gt;
        &lt;cell&gt;old row&lt;/cell&gt;
        &lt;cell&gt;new row&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DELETE&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;d&lt;/code&gt; (delete)&lt;/cell&gt;
        &lt;cell&gt;old row&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;null&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Topics follow the pattern: &lt;code&gt;{topic_prefix}.{database}.{table}&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;marmot.cdc.myapp.users&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;marmot.cdc.myapp.orders&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;marmot.cdc.analytics.events&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-Time Analytics: Stream changes to data warehouses (Snowflake, BigQuery, ClickHouse)&lt;/item&gt;
      &lt;item&gt;Event-Driven Microservices: Trigger actions on data changes&lt;/item&gt;
      &lt;item&gt;Cache Invalidation: Keep caches in sync with database changes&lt;/item&gt;
      &lt;item&gt;Audit Logging: Capture all changes for compliance&lt;/item&gt;
      &lt;item&gt;Search Indexing: Keep Elasticsearch/Algolia in sync&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more details, see the Integrations documentation.&lt;/p&gt;
    &lt;p&gt;Marmot supports a wide range of MySQL/SQLite statements through its MySQL protocol server. The following table shows compatibility for different statement types:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Statement Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Support&lt;/cell&gt;
        &lt;cell role="head"&gt;Replication&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DML - Data Manipulation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&lt;code&gt;INSERT&lt;/code&gt; / &lt;code&gt;REPLACE&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Includes qualified table names (db.table)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;UPDATE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Includes qualified table names&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;DELETE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Includes qualified table names&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Read operations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOAD DATA&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Bulk data loading&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DDL - Data Definition&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;ALTER TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;DROP TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;TRUNCATE TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;RENAME TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE/DROP INDEX&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE/DROP VIEW&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE/DROP TRIGGER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Database Management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE DATABASE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;DROP DATABASE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;ALTER DATABASE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Replicated with cluster-wide locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;SHOW DATABASES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Metadata query&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;SHOW TABLES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Metadata query&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;USE database&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Session state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Transaction Control&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&lt;code&gt;BEGIN&lt;/code&gt; / &lt;code&gt;START TRANSACTION&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Transaction boundary&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;COMMIT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Commits distributed transaction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;ROLLBACK&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Aborts distributed transaction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;SAVEPOINT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;Nested transaction support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Locking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOCK TABLES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Requires distributed locking coordination&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;UNLOCK TABLES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Requires distributed locking coordination&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Session Configuration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&lt;code&gt;SET&lt;/code&gt; statements&lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Session-local, not replicated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;XA Transactions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;XA START/END/PREPARE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Marmot uses its own 2PC protocol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;XA COMMIT/ROLLBACK&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Not compatible with Marmot's model&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DCL - Data Control&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&lt;code&gt;GRANT&lt;/code&gt; / &lt;code&gt;REVOKE&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;User management not replicated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;CREATE/DROP USER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;User management not replicated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;ALTER USER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;User management not replicated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Administrative&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Node-local administrative command&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;REPAIR TABLE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Parsed&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;Node-local administrative command&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Full: Fully supported and working&lt;/item&gt;
      &lt;item&gt;✅ Parsed: Statement is parsed and recognized&lt;/item&gt;
      &lt;item&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Limited: Works but has limitations in distributed context&lt;/item&gt;
      &lt;item&gt;❌ No: Not supported or not replicated&lt;/item&gt;
      &lt;item&gt;N/A: Not applicable (read-only or session-local)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Schema Changes (DDL): DDL statements are fully replicated with cluster-wide locking and automatic idempotency. See the DDL Replication section for details.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;XA Transactions: Marmot has its own distributed transaction protocol based on 2PC. MySQL XA transactions are not compatible with Marmot's replication model.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;User Management (DCL): User and privilege management statements are local to each node. For production deployments, consider handling authentication at the application or proxy level.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Table Locking:&lt;/p&gt;&lt;code&gt;LOCK TABLES&lt;/code&gt;statements are recognized but not enforced across the cluster. Use application-level coordination for distributed locking needs.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Qualified Names: Marmot fully supports qualified table names (e.g.,&lt;/p&gt;&lt;code&gt;db.table&lt;/code&gt;) in DML and DDL operations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot includes a MySQL-compatible protocol server, allowing you to connect using any MySQL client (DBeaver, MySQL Workbench, mysql CLI, etc.). The server supports:&lt;/p&gt;
    &lt;p&gt;Marmot provides full support for MySQL metadata queries, enabling GUI tools like DBeaver to browse databases, tables, and columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SHOW Commands: &lt;code&gt;SHOW DATABASES&lt;/code&gt;,&lt;code&gt;SHOW TABLES&lt;/code&gt;,&lt;code&gt;SHOW COLUMNS FROM table&lt;/code&gt;,&lt;code&gt;SHOW CREATE TABLE&lt;/code&gt;,&lt;code&gt;SHOW INDEXES&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;INFORMATION_SCHEMA: Queries against &lt;code&gt;INFORMATION_SCHEMA.TABLES&lt;/code&gt;,&lt;code&gt;INFORMATION_SCHEMA.COLUMNS&lt;/code&gt;,&lt;code&gt;INFORMATION_SCHEMA.SCHEMATA&lt;/code&gt;, and&lt;code&gt;INFORMATION_SCHEMA.STATISTICS&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Type Conversion: Automatic SQLite-to-MySQL type mapping for compatibility&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These metadata queries are powered by the rqlite/sql AST parser, providing production-grade MySQL query compatibility.&lt;/p&gt;
    &lt;code&gt;# Using mysql CLI
mysql -h localhost -P 3306 -u root

# Connection string for applications
mysql://root@localhost:3306/marmot&lt;/code&gt;
    &lt;p&gt;Marmot handles various failure and recovery scenarios automatically:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;Behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Minority partition&lt;/cell&gt;
        &lt;cell&gt;Writes fail - cannot achieve quorum&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Majority partition&lt;/cell&gt;
        &lt;cell&gt;Writes succeed - quorum achieved&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Partition heals&lt;/cell&gt;
        &lt;cell&gt;Delta sync + LWW merges divergent data&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;During partition, only the majority side can commit writes (quorum enforcement)&lt;/item&gt;
      &lt;item&gt;When partition heals, nodes exchange transaction logs via &lt;code&gt;StreamChanges&lt;/code&gt;RPC&lt;/item&gt;
      &lt;item&gt;Conflicts resolved using Last-Writer-Wins (LWW) with HLC timestamps&lt;/item&gt;
      &lt;item&gt;Higher node ID breaks ties for simultaneous writes&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;Recovery Method&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Brief outage&lt;/cell&gt;
        &lt;cell&gt;Delta sync - replay missed transactions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Extended outage&lt;/cell&gt;
        &lt;cell&gt;Snapshot transfer + delta sync&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;New node joining&lt;/cell&gt;
        &lt;cell&gt;Full snapshot from existing node&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Anti-Entropy Background Process:&lt;/p&gt;
    &lt;p&gt;Marmot v2 includes an automatic anti-entropy system that continuously monitors and repairs replication lag across the cluster:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lag Detection: Every 60 seconds (configurable), each node queries peers for their replication state&lt;/item&gt;
      &lt;item&gt;Smart Recovery Decision: &lt;list rend="ul"&gt;&lt;item&gt;Delta Sync if lag &amp;lt; 10,000 transactions AND &amp;lt; 1 hour: Streams missed transactions incrementally&lt;/item&gt;&lt;item&gt;Snapshot Transfer if lag exceeds thresholds: Full database file transfer for efficiency&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Gap Detection: Detects when transaction logs have been GC'd and automatically falls back to snapshot&lt;/item&gt;
      &lt;item&gt;Multi-Database Support: Tracks and syncs each database independently&lt;/item&gt;
      &lt;item&gt;GC Coordination: Garbage collection respects peer replication state - logs aren't deleted until all peers have applied them&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Delta Sync Process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lagging node queries &lt;code&gt;last_applied_txn_id&lt;/code&gt;for each peer/database&lt;/item&gt;
      &lt;item&gt;Requests transactions since that ID via &lt;code&gt;StreamChanges&lt;/code&gt;RPC&lt;/item&gt;
      &lt;item&gt;Gap Detection: Checks if first received txn_id has a large gap from requested ID &lt;list rend="ul"&gt;&lt;item&gt;If gap &amp;gt; delta_sync_threshold_txns, indicates missing (GC'd) transactions&lt;/item&gt;&lt;item&gt;Automatically falls back to snapshot transfer to prevent data loss&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Applies changes using LWW conflict resolution&lt;/item&gt;
      &lt;item&gt;Updates replication state tracking (per-database)&lt;/item&gt;
      &lt;item&gt;Progress logged every 100 transactions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GC Coordination with Anti-Entropy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Transaction logs are retained with a two-tier policy: &lt;list rend="ul"&gt;&lt;item&gt;Min retention (2 hours): Must be &amp;gt;= delta sync threshold, respects peer lag&lt;/item&gt;&lt;item&gt;Max retention (24 hours): Force delete after this time to prevent unbounded growth&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Config validation enforces: &lt;code&gt;gc_min &amp;gt;= delta_threshold&lt;/code&gt;and&lt;code&gt;gc_max &amp;gt;= 2x delta_threshold&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Each database tracks replication progress per peer&lt;/item&gt;
      &lt;item&gt;GC queries minimum applied txn_id across all peers before cleanup&lt;/item&gt;
      &lt;item&gt;Gap detection prevents data loss if GC runs while nodes are offline&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Write Consistency&lt;/cell&gt;
        &lt;cell role="head"&gt;Behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ONE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Returns after 1 node ACK (fast, less durable)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;QUORUM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Returns after majority ACK (default, balanced)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ALL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Returns after all nodes ACK (slow, most durable)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Conflict Resolution:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All conflicts resolved via LWW using HLC timestamps&lt;/item&gt;
      &lt;item&gt;No data loss - later write always wins deterministically&lt;/item&gt;
      &lt;item&gt;Tie-breaker: higher node ID wins for equal timestamps&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Selective Table Watching: All tables in a database are replicated. Selective table replication is not supported.&lt;/item&gt;
      &lt;item&gt;WAL Mode Required: SQLite must use WAL mode for reliable multi-process changes.&lt;/item&gt;
      &lt;item&gt;Eventually Consistent: Rows may sync out of order. &lt;code&gt;SERIALIZABLE&lt;/code&gt;transaction assumptions may not hold across nodes.&lt;/item&gt;
      &lt;item&gt;Concurrent DDL: Avoid running concurrent DDL operations on the same database from multiple nodes (protected by cluster-wide lock with 30s lease).&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;IMPORTANT: Marmot automatically converts&lt;/p&gt;&lt;code&gt;INT AUTO_INCREMENT&lt;/code&gt;to&lt;code&gt;BIGINT&lt;/code&gt;&lt;p&gt;This is a breaking change from standard MySQL/SQLite behavior. Marmot does not respect 32-bit&lt;/p&gt;&lt;code&gt;INT&lt;/code&gt;for auto-increment columns - they are automatically promoted to&lt;code&gt;BIGINT&lt;/code&gt;to support distributed ID generation.&lt;/quote&gt;
    &lt;p&gt;Why?&lt;/p&gt;
    &lt;p&gt;In a distributed, leaderless system, each node must generate unique IDs independently without coordination. Marmot uses HLC-based (Hybrid Logical Clock) 64-bit IDs to ensure:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Global Uniqueness: IDs are unique across all nodes without central coordination&lt;/item&gt;
      &lt;item&gt;Monotonicity: IDs increase over time (within each node)&lt;/item&gt;
      &lt;item&gt;No Collisions: Unlike auto-increment sequences, HLC IDs cannot collide between nodes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How It Works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;DDL Transformation: When you create a table with&lt;/p&gt;&lt;code&gt;AUTO_INCREMENT&lt;/code&gt;:&lt;quote&gt;CREATE TABLE users (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(100)) -- Becomes internally: CREATE TABLE users (id BIGINT PRIMARY KEY, name TEXT)&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;DML ID Injection: When inserting with&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;or&lt;code&gt;NULL&lt;/code&gt;for an auto-increment column:&lt;quote&gt;INSERT INTO users (id, name) VALUES (0, 'alice') -- Becomes internally: INSERT INTO users (id, name) VALUES (7318624812345678901, 'alice')&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Explicit IDs Preserved: If you provide an explicit non-zero ID, it is used as-is:&lt;/p&gt;
        &lt;quote&gt;INSERT INTO users (id, name) VALUES (12345, 'bob') -- Remains: INSERT INTO users (id, name) VALUES (12345, 'bob')&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important Considerations:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Aspect&lt;/cell&gt;
        &lt;cell role="head"&gt;Behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ID Range&lt;/cell&gt;
        &lt;cell&gt;64-bit (up to 9.2 quintillion) instead of 32-bit (4.2 billion)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ID Format&lt;/cell&gt;
        &lt;cell&gt;HLC-based, not sequential integers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SQLite ROWID&lt;/cell&gt;
        &lt;cell&gt;Not used - Marmot manages IDs explicitly&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Client Libraries&lt;/cell&gt;
        &lt;cell&gt;Ensure your client handles &lt;code&gt;BIGINT&lt;/code&gt; correctly (some JSON serializers may lose precision)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Existing Data&lt;/cell&gt;
        &lt;cell&gt;Migrate existing &lt;code&gt;INT&lt;/code&gt; columns to &lt;code&gt;BIGINT&lt;/code&gt; before enabling Marmot&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Schema-Based Detection:&lt;/p&gt;
    &lt;p&gt;Marmot automatically detects auto-increment columns by querying SQLite schema directly. A column is considered auto-increment if:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It is a single-column &lt;code&gt;INTEGER PRIMARY KEY&lt;/code&gt;(SQLite rowid alias), or&lt;/item&gt;
      &lt;item&gt;It is a single-column &lt;code&gt;BIGINT PRIMARY KEY&lt;/code&gt;(Marmot's transformed columns)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No registration required - columns are detected from schema at runtime&lt;/item&gt;
      &lt;item&gt;Works across restarts - no need to re-execute DDL statements&lt;/item&gt;
      &lt;item&gt;Works with existing databases - tables created directly on SQLite work too&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot v2 uses a TOML configuration file (default: &lt;code&gt;config.toml&lt;/code&gt;). All settings have sensible defaults.&lt;/p&gt;
    &lt;code&gt;node_id = 0  # 0 = auto-generate
data_dir = "./marmot-data"&lt;/code&gt;
    &lt;code&gt;[transaction]
heartbeat_timeout_seconds = 10  # Transaction timeout without heartbeat
conflict_window_seconds = 10    # Conflict resolution window
lock_wait_timeout_seconds = 50  # Lock wait timeout (MySQL: innodb_lock_wait_timeout)&lt;/code&gt;
    &lt;p&gt;Note: Transaction log garbage collection is managed by the replication configuration to coordinate with anti-entropy. See &lt;code&gt;replication.gc_min_retention_hours&lt;/code&gt; and &lt;code&gt;replication.gc_max_retention_hours&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;[connection_pool]
pool_size = 4              # Number of SQLite connections
max_idle_time_seconds = 10 # Max idle time before closing
max_lifetime_seconds = 300 # Max connection lifetime (0 = unlimited)&lt;/code&gt;
    &lt;code&gt;[grpc_client]
keepalive_time_seconds = 10    # Keepalive ping interval
keepalive_timeout_seconds = 3  # Keepalive ping timeout
max_retries = 3                # Max retry attempts
retry_backoff_ms = 100         # Retry backoff duration&lt;/code&gt;
    &lt;code&gt;[coordinator]
prepare_timeout_ms = 2000 # Prepare phase timeout
commit_timeout_ms = 2000  # Commit phase timeout
abort_timeout_ms = 2000   # Abort phase timeout&lt;/code&gt;
    &lt;code&gt;[cluster]
grpc_bind_address = "0.0.0.0"
grpc_port = 8080
seed_nodes = []                # List of seed node addresses
cluster_secret = ""            # PSK for cluster authentication (see Security section)
gossip_interval_ms = 1000      # Gossip interval
gossip_fanout = 3              # Number of peers to gossip to
suspect_timeout_ms = 5000      # Suspect timeout
dead_timeout_ms = 10000        # Dead timeout&lt;/code&gt;
    &lt;p&gt;Marmot supports Pre-Shared Key (PSK) authentication for cluster communication. This is strongly recommended for production deployments.&lt;/p&gt;
    &lt;code&gt;[cluster]
# All nodes in the cluster must use the same secret
cluster_secret = "your-secret-key-here"&lt;/code&gt;
    &lt;p&gt;Environment Variable (Recommended):&lt;/p&gt;
    &lt;p&gt;For production, use the environment variable to avoid storing secrets in config files:&lt;/p&gt;
    &lt;code&gt;export MARMOT_CLUSTER_SECRET="your-secret-key-here"
./marmot&lt;/code&gt;
    &lt;p&gt;The environment variable takes precedence over the config file.&lt;/p&gt;
    &lt;p&gt;Generating a Secret:&lt;/p&gt;
    &lt;code&gt;# Generate a secure random secret
openssl rand -base64 32&lt;/code&gt;
    &lt;p&gt;Behavior:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If &lt;code&gt;cluster_secret&lt;/code&gt;is empty and&lt;code&gt;MARMOT_CLUSTER_SECRET&lt;/code&gt;is not set, authentication is disabled&lt;/item&gt;
      &lt;item&gt;A warning is logged at startup when authentication is disabled&lt;/item&gt;
      &lt;item&gt;All gRPC endpoints (gossip, replication, snapshots) are protected when authentication is enabled&lt;/item&gt;
      &lt;item&gt;Nodes with mismatched secrets will fail to communicate (connection rejected with "invalid cluster secret")&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marmot provides admin HTTP endpoints for managing cluster membership (requires &lt;code&gt;cluster_secret&lt;/code&gt; to be configured):&lt;/p&gt;
    &lt;p&gt;Node Lifecycle:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New/restarted nodes auto-join via gossip - no manual intervention needed&lt;/item&gt;
      &lt;item&gt;Nodes marked REMOVED via admin API cannot auto-rejoin - must be explicitly allowed&lt;/item&gt;
      &lt;item&gt;This prevents decommissioned nodes from accidentally rejoining the cluster&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# View cluster members and quorum info
curl -H "X-Marmot-Secret: your-secret" http://localhost:8080/admin/cluster/members

# Remove a node from the cluster (excludes from quorum, blocks auto-rejoin)
curl -X POST -H "X-Marmot-Secret: your-secret" http://localhost:8080/admin/cluster/remove/2

# Allow a removed node to rejoin (node must then restart to join)
curl -X POST -H "X-Marmot-Secret: your-secret" http://localhost:8080/admin/cluster/allow/2&lt;/code&gt;
    &lt;p&gt;See the Operations documentation for detailed usage and examples.&lt;/p&gt;
    &lt;code&gt;[replication]
default_write_consistency = "QUORUM"      # Write consistency level: ONE, QUORUM, ALL
default_read_consistency = "LOCAL_ONE"    # Read consistency level
write_timeout_ms = 5000                   # Write operation timeout
read_timeout_ms = 2000                    # Read operation timeout

# Anti-Entropy: Background healing for eventual consistency
# - Detects and repairs divergence between replicas
# - Uses delta sync for small lags, snapshot for large lags
# - Includes gap detection to prevent incomplete data after GC
enable_anti_entropy = true                 # Enable automatic catch-up for lagging nodes
anti_entropy_interval_seconds = 60         # How often to check for lag (default: 60s)
delta_sync_threshold_transactions = 10000  # Delta sync if lag &amp;lt; 10K txns
delta_sync_threshold_seconds = 3600        # Snapshot if lag &amp;gt; 1 hour

# Garbage Collection: Reclaim disk space by deleting old transaction records
# - gc_min must be &amp;gt;= delta_sync_threshold (validated at startup)
# - gc_max should be &amp;gt;= 2x delta_sync_threshold (recommended)
# - Set gc_max = 0 for unlimited retention
gc_min_retention_hours = 2   # Keep at least 2 hours (&amp;gt;= 1 hour delta threshold)
gc_max_retention_hours = 24  # Force delete after 24 hours&lt;/code&gt;
    &lt;p&gt;Anti-Entropy Tuning:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small clusters (2-3 nodes): Use default settings (60s interval)&lt;/item&gt;
      &lt;item&gt;Large clusters (5+ nodes): Consider increasing interval to 120-180s to reduce network overhead&lt;/item&gt;
      &lt;item&gt;High write throughput: Increase &lt;code&gt;delta_sync_threshold_transactions&lt;/code&gt;to 50000+&lt;/item&gt;
      &lt;item&gt;Long-running clusters: Keep &lt;code&gt;gc_max_retention_hours&lt;/code&gt;at 24+ to handle extended outages&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GC Configuration Rules (Validated at Startup):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gc_min_retention_hours&lt;/code&gt;must be &amp;gt;=&lt;code&gt;delta_sync_threshold_seconds&lt;/code&gt;(in hours)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gc_max_retention_hours&lt;/code&gt;should be &amp;gt;= 2x&lt;code&gt;delta_sync_threshold_seconds&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Violating these rules will cause startup failure with helpful error messages&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[query_pipeline]
transpiler_cache_size = 10000  # LRU cache for MySQL→SQLite transpilation
validator_pool_size = 8        # SQLite connection pool for validation&lt;/code&gt;
    &lt;code&gt;[mysql]
enabled = true
bind_address = "0.0.0.0"
port = 3306
max_connections = 1000&lt;/code&gt;
    &lt;code&gt;[publisher]
enabled = false  # Enable CDC publishing to external systems

[[publisher.sinks]]
name = "kafka-main"              # Unique sink name
type = "kafka"                   # "kafka" or "nats"
format = "debezium"              # Debezium-compatible JSON (only option)
brokers = ["localhost:9092"]     # Kafka broker addresses
topic_prefix = "marmot.cdc"      # Topic pattern: {prefix}.{db}.{table}
filter_tables = ["*"]            # Glob patterns for table filtering
filter_databases = ["*"]         # Glob patterns for database filtering
batch_size = 100                 # Events to read per poll cycle
poll_interval_ms = 10            # Polling interval (default: 10ms)
retry_initial_ms = 100           # Initial retry delay on failure
retry_max_ms = 30000             # Max retry delay (30 seconds)
retry_multiplier = 2.0           # Exponential backoff multiplier&lt;/code&gt;
    &lt;p&gt;See the Integrations documentation for details on event format, Kafka/NATS configuration, and use cases.&lt;/p&gt;
    &lt;code&gt;[logging]
verbose = false          # Enable verbose logging
format = "console"       # Log format: console or json&lt;/code&gt;
    &lt;code&gt;[prometheus]
enabled = true  # Metrics served on gRPC port at /metrics endpoint&lt;/code&gt;
    &lt;p&gt;Accessing Metrics:&lt;/p&gt;
    &lt;code&gt;# Metrics are multiplexed with gRPC on the same port
curl http://localhost:8080/metrics

# Prometheus scrape config
scrape_configs:
  - job_name: 'marmot'
    static_configs:
      - targets: ['node1:8080', 'node2:8080', 'node3:8080']&lt;/code&gt;
    &lt;p&gt;See &lt;code&gt;config.toml&lt;/code&gt; for complete configuration reference with detailed comments.&lt;/p&gt;
    &lt;p&gt;Performance benchmarks on a local development machine (Apple M-series, 3-node cluster, single machine):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Nodes&lt;/cell&gt;
        &lt;cell&gt;3 (ports 3307, 3308, 3309)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Threads&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Batch Size&lt;/cell&gt;
        &lt;cell&gt;10 ops/transaction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Consistency&lt;/cell&gt;
        &lt;cell&gt;QUORUM&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Throughput&lt;/cell&gt;
        &lt;cell&gt;4,175 ops/sec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;TX Throughput&lt;/cell&gt;
        &lt;cell&gt;417 tx/sec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Records Loaded&lt;/cell&gt;
        &lt;cell&gt;200,000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Errors&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Throughput&lt;/cell&gt;
        &lt;cell&gt;3,370 ops/sec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;TX Throughput&lt;/cell&gt;
        &lt;cell&gt;337 tx/sec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Duration&lt;/cell&gt;
        &lt;cell&gt;120 seconds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total Operations&lt;/cell&gt;
        &lt;cell&gt;404,930&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Errors&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Retries&lt;/cell&gt;
        &lt;cell&gt;37 (0.09%)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Operation Distribution:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;READ: 20%&lt;/item&gt;
      &lt;item&gt;UPDATE: 30%&lt;/item&gt;
      &lt;item&gt;INSERT: 35%&lt;/item&gt;
      &lt;item&gt;DELETE: 5%&lt;/item&gt;
      &lt;item&gt;UPSERT: 10%&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Percentile&lt;/cell&gt;
        &lt;cell role="head"&gt;Latency&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;P50&lt;/cell&gt;
        &lt;cell&gt;4.3ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;P90&lt;/cell&gt;
        &lt;cell&gt;14.0ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;P95&lt;/cell&gt;
        &lt;cell&gt;36.8ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;P99&lt;/cell&gt;
        &lt;cell&gt;85.1ms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All 3 nodes maintained identical row counts (346,684 rows) throughout the test, confirming consistent replication.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: These benchmarks are from a local development machine with all nodes on the same host. Production deployments across multiple machines will have different characteristics based on network latency.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46460676</guid><pubDate>Fri, 02 Jan 2026 02:21:57 +0000</pubDate></item><item><title>FreeBSD: Home NAS, part 1 – configuring ZFS mirror (RAID1)</title><link>https://rtfm.co.ua/en/freebsd-home-nas-part-1-configuring-zfs-mirror-raid1/</link><description>&lt;doc fingerprint="1e35285ba76e8ee5"&gt;
  &lt;main&gt;
    &lt;p&gt;I have an idea to set up a home NAS on FreeBSD.&lt;/p&gt;
    &lt;p&gt;For this purpose, I bought a Lenovo ThinkCentre M720s SFF – it’s quiet, compact, and offers the possibility to install 2 SATA III SSDs plus a separate M.2 slot for an NVMe SSD.&lt;/p&gt;
    &lt;p&gt;What is planned:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;on NVMe SSD: UFS and FreeBSD&lt;/item&gt;
      &lt;item&gt;on SATA SSDs: ZFS with RAID1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While waiting for the drives to arrive, let’s test how it all works on a virtual machine.&lt;/p&gt;
    &lt;p&gt;We will be installing FreeBSD 14.3, although version 15 is already out, but it has some interesting changes that I’ll play with separately.&lt;/p&gt;
    &lt;p&gt;Of course, I could have gone with TrueNAS, which is based on FreeBSD – but I want “vanilla” FreeBSD to do everything manually.&lt;/p&gt;
    &lt;p&gt;All posts in this blog series:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;(current) FreeBSD: Home NAS, part 1 – configuring ZFS mirror (RAID1)&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 2 – introduction to Packet Filter (PF) firewall&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 3 – WireGuard VPN, Linux peer, and routing&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 4 – Local DNS with Unbound&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 5 – ZFS pool, datasets, snapshots, and ZFS monitoring&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 6 – Samba server and client connections&lt;/item&gt;
      &lt;item&gt;… to be continued&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contents&lt;/p&gt;
    &lt;head rend="h1"&gt;Installing FreeBSD via SSH&lt;/head&gt;
    &lt;p&gt;We will perform the installation over SSH using &lt;code&gt;bsdinstall&lt;/code&gt; – boot the system in LiveCD mode, enable SSH, and then proceed with the installation from a workstation laptop.&lt;/p&gt;
    &lt;p&gt;The virtual machine has three disks – mirroring the future ThinkCentre setup:&lt;/p&gt;
    &lt;p&gt;Select Live System:&lt;/p&gt;
    &lt;p&gt;Login as &lt;code&gt;root&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Bring up the network:&lt;/p&gt;
    &lt;quote&gt;# ifconfig em0 up # dhclient em0&lt;/quote&gt;
    &lt;head rend="h2"&gt;Configuring SSH on FreeBSD LiveCD&lt;/head&gt;
    &lt;p&gt;For SSH, we need to set a &lt;code&gt;root&lt;/code&gt; password and make changes to &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;, but currently, this doesn’t work because the system is mounted as read-only:&lt;/p&gt;
    &lt;p&gt;Check the current partitions:&lt;/p&gt;
    &lt;p&gt;And apply a “dirty hack”:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mount a new &lt;code&gt;tmpfs&lt;/code&gt;file system in RAM at&lt;code&gt;/mnt&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;copy the contents of &lt;code&gt;/etc&lt;/code&gt;from the LiveCD there&lt;/item&gt;
      &lt;item&gt;mount &lt;code&gt;tmpfs&lt;/code&gt;over&lt;code&gt;/etc&lt;/code&gt;(overlaying the read-only directory from the ISO)&lt;/item&gt;
      &lt;item&gt;copy the prepared files from &lt;code&gt;/mnt&lt;/code&gt;back into the new&lt;code&gt;/etc&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Execute:&lt;/p&gt;
    &lt;quote&gt;# mount -t tmpfs tmpfs /mnt # cp -a /etc/* /mnt/ # mount -t tmpfs tmpfs /etc # cp -a /mnt/* /etc/&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;mount&lt;/code&gt; syntax for &lt;code&gt;tmpfs&lt;/code&gt; is &lt;code&gt;mount -t &amp;lt;fstype&amp;gt; &amp;lt;source&amp;gt; &amp;lt;mountpoint&amp;gt;&lt;/code&gt;. Since the &lt;code&gt;source&lt;/code&gt; value is required, we specify &lt;code&gt;tmpfs&lt;/code&gt; again.&lt;/p&gt;
    &lt;p&gt;Now, set the password with &lt;code&gt;passwd&lt;/code&gt; and start &lt;code&gt;sshd&lt;/code&gt; using &lt;code&gt;onestart&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;# passwd # service sshd onestart&lt;/quote&gt;
    &lt;p&gt;However, SSH will still deny access because &lt;code&gt;root&lt;/code&gt; login is disabled by default:&lt;/p&gt;
    &lt;quote&gt;$ ssh [email protected] ([email protected]) Password for root@: ([email protected]) Password for root@: ([email protected]) Password for root@:&lt;/quote&gt;
    &lt;p&gt;Set &lt;code&gt;PermitRootLogin yes&lt;/code&gt; in &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; and restart &lt;code&gt;sshd&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;# echo "PermitRootLogin yes" &amp;gt;&amp;gt; /etc/ssh/sshd_config # service sshd onerestart&lt;/quote&gt;
    &lt;p&gt;Now we can log in:&lt;/p&gt;
    &lt;quote&gt;$ ssh [email protected] ([email protected]) Password for root@: Last login: Sun Dec 7 12:19:25 2025 FreeBSD 14.3-RELEASE (GENERIC) releng/14.3-n271432-8c9ce319fef7 Welcome to FreeBSD! ... root@:~ #&lt;/quote&gt;
    &lt;head rend="h1"&gt;Installation with &lt;code&gt;bsdinstall&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;bsdinstall&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;# bsdinstall&lt;/quote&gt;
    &lt;p&gt;Select the components to add to the system – &lt;code&gt;ports&lt;/code&gt; is necessary, &lt;code&gt;src&lt;/code&gt; is optional but definitely worth it for a real NAS:&lt;/p&gt;
    &lt;head rend="h2"&gt;Disk partitioning&lt;/head&gt;
    &lt;p&gt;We’ll do a minimal disk partition, so select Manual:&lt;/p&gt;
    &lt;p&gt;We will install the system on &lt;code&gt;ada0&lt;/code&gt;, select it, and click Create:&lt;/p&gt;
    &lt;p&gt;Next, choose a partition scheme. It’s standard for 2025 – GPT:&lt;/p&gt;
    &lt;p&gt;Confirm the changes, and now we have a new partition table on the system drive &lt;code&gt;ada0&lt;/code&gt;:&lt;/p&gt;
    &lt;head rend="h3"&gt;The &lt;code&gt;freebsd-boot&lt;/code&gt; Partition&lt;/head&gt;
    &lt;p&gt;Now we need to create the partitions themselves.&lt;/p&gt;
    &lt;p&gt;Select &lt;code&gt;ada0&lt;/code&gt; again, click Create, and create a partition for &lt;code&gt;freebsd-boot&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This is just for the virtual machine; on the actual ThinkCentre, we would use type &lt;code&gt;efi&lt;/code&gt; with a size of about 200-500 MB.&lt;/p&gt;
    &lt;p&gt;For now, set:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Type: &lt;code&gt;freebsd-boot&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Size: 512K&lt;/item&gt;
      &lt;item&gt;Mountpoint: empty&lt;/item&gt;
      &lt;item&gt;Label: empty&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Confirm and proceed to the next partition.&lt;/p&gt;
    &lt;head rend="h3"&gt;The &lt;code&gt;freebsd-swap&lt;/code&gt; Partition&lt;/head&gt;
    &lt;p&gt;Click Create again to add Swap.&lt;/p&gt;
    &lt;p&gt;Given that on the ThinkCentre we will have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;8 – 16 GB RAM&lt;/item&gt;
      &lt;item&gt;no sleep/hibernate&lt;/item&gt;
      &lt;item&gt;UFS and ZFS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2 gigabytes will be enough.&lt;/p&gt;
    &lt;p&gt;Set:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Type: &lt;code&gt;freebsd-swap&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Size: 2GB&lt;/item&gt;
      &lt;item&gt;Mountpoint: empty&lt;/item&gt;
      &lt;item&gt;Label: empty&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Root Partition with UFS&lt;/head&gt;
    &lt;p&gt;The main system will be on UFS because it is very stable, doesn’t require much RAM, mounts quickly, is easy to recover, and lacks complex caching mechanisms (UPD: however, after getting to know ZFS and its capabilities better, I decided to use it for the system disk as well)&lt;/p&gt;
    &lt;p&gt;Set:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Type: &lt;code&gt;freebsd-ufs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Size: 14GB&lt;/item&gt;
      &lt;item&gt;Mountpoint: /&lt;/item&gt;
      &lt;item&gt;Label: rootfs – just a name for us&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’ll configure the rest of the disks later; for now, select Finish and Commit:&lt;/p&gt;
    &lt;head rend="h2"&gt;Finishing Installation&lt;/head&gt;
    &lt;p&gt;Wait for the copying to complete:&lt;/p&gt;
    &lt;p&gt;Configure the network:&lt;/p&gt;
    &lt;p&gt;Select Timezone:&lt;/p&gt;
    &lt;p&gt;In System Configuration – select &lt;code&gt;sshd&lt;/code&gt;, no mouse, enable &lt;code&gt;ntpd&lt;/code&gt; and &lt;code&gt;powerd&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;System Hardening – considering this will be a home NAS, but I might open external access (even behind a firewall), it makes sense to tune the security a bit:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;read_msgbuf&lt;/code&gt;: allow&lt;code&gt;dmesg&lt;/code&gt;access for root only&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;proc_debug&lt;/code&gt;: allow&lt;code&gt;ptrace&lt;/code&gt;for root only&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;random_pid&lt;/code&gt;: randomize PID numbers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;clear_tmp&lt;/code&gt;: clear&lt;code&gt;/tmp&lt;/code&gt;on reboot&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;secure_console&lt;/code&gt;: require&lt;code&gt;root&lt;/code&gt;password for login from the physical console&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Add a user:&lt;/p&gt;
    &lt;p&gt;Everything is ready – reboot the machine:&lt;/p&gt;
    &lt;head rend="h1"&gt;Creating a ZFS RAID&lt;/head&gt;
    &lt;p&gt;Log in as the regular user:&lt;/p&gt;
    &lt;quote&gt;$ ssh [email protected] ... FreeBSD 14.3-RELEASE (GENERIC) releng/14.3-n271432-8c9ce319fef7 Welcome to FreeBSD! ... setevoy@test-nas-1:~ $&lt;/quote&gt;
    &lt;p&gt;Install &lt;code&gt;vim&lt;/code&gt; 🙂&lt;/p&gt;
    &lt;quote&gt;# pkg install vim&lt;/quote&gt;
    &lt;p&gt;Check our disks.&lt;/p&gt;
    &lt;p&gt;Using &lt;code&gt;geom disk&lt;/code&gt; for physical device info, and &lt;code&gt;gpart show&lt;/code&gt; to see partitions on the disks.&lt;/p&gt;
    &lt;p&gt;Check disks – there are three:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # geom disk list Geom name: ada0 Providers: 1. Name: ada0 Mediasize: 17179869184 (16G) Sectorsize: 512 Mode: r2w2e3 descr: VBOX HARDDISK ident: VB262b53f7-adc5cd2c rotationrate: unknown fwsectors: 63 fwheads: 16 Geom name: ada1 Providers: 1. Name: ada1 Mediasize: 17179869184 (16G) Sectorsize: 512 Mode: r0w0e0 descr: VBOX HARDDISK ident: VB059f9d08-4b0e1f56 rotationrate: unknown fwsectors: 63 fwheads: 16 Geom name: ada2 Providers: 1. Name: ada2 Mediasize: 17179869184 (16G) Sectorsize: 512 Mode: r0w0e0 descr: VBOX HARDDISK ident: VB3941028c-3ea0d485 rotationrate: unknown fwsectors: 63 fwheads: 16&lt;/quote&gt;
    &lt;p&gt;And with &lt;code&gt;gpart&lt;/code&gt; – current &lt;code&gt;ada0&lt;/code&gt; where the system was installed:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart show =&amp;gt; 40 33554352 ada0 GPT (16G) 40 1024 1 freebsd-boot (512K) 1064 4194304 2 freebsd-swap (2.0G) 4195368 29359024 3 freebsd-ufs (14G)&lt;/quote&gt;
    &lt;p&gt;Disks &lt;code&gt;ada1&lt;/code&gt; and &lt;code&gt;ada2&lt;/code&gt; will be used for ZFS and its mirror (RAID1).&lt;/p&gt;
    &lt;p&gt;If there was anything on them – wipe it:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart destroy -F ada1 gpart: arg0 'ada1': Invalid argument root@test-nas-1:/home/setevoy # gpart destroy -F ada2 gpart: arg0 'ada2': Invalid argument&lt;/quote&gt;
    &lt;p&gt;Since this is a VM and the disks are empty, “Invalid argument” is expected and fine.&lt;/p&gt;
    &lt;p&gt;Create GPT partition tables on &lt;code&gt;ada1&lt;/code&gt; and &lt;code&gt;ada2&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart create -s gpt ada1 ada1 created root@test-nas-1:/home/setevoy # gpart create -s gpt ada2 ada2 created&lt;/quote&gt;
    &lt;p&gt;Check:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart show ada1 =&amp;gt; 40 33554352 ada1 GPT (16G) 40 33554352 - free - (16G)&lt;/quote&gt;
    &lt;p&gt;Create partitions for ZFS:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart add -t freebsd-zfs ada1 ada1p1 added root@test-nas-1:/home/setevoy # gpart add -t freebsd-zfs ada2 ada2p1 added&lt;/quote&gt;
    &lt;p&gt;Check again:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart show ada1 =&amp;gt; 40 33554352 ada1 GPT (16G) 40 33554352 1 freebsd-zfs (16G)&lt;/quote&gt;
    &lt;head rend="h2"&gt;Creating a ZFS mirror with &lt;code&gt;zpool&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The “magic” of ZFS is that everything works “out of the box” – you don’t need a separate LVM and its groups, and you don’t need &lt;code&gt;mdadm&lt;/code&gt; for RAID.&lt;/p&gt;
    &lt;p&gt;For managing disks in ZFS, the main utility is &lt;code&gt;zpool&lt;/code&gt;, and for managing data (datasets, file systems, snapshots), it’s &lt;code&gt;zfs&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To combine one or more disks into a single logical storage, ZFS uses a pool – the equivalent of a volume group in Linux LVM.&lt;/p&gt;
    &lt;p&gt;Create the pool:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # zpool create tank mirror ada1p1 ada2p1&lt;/quote&gt;
    &lt;p&gt;Here, tank is the pool name, &lt;code&gt;mirror&lt;/code&gt; specifies that it will be RAID1, and we provide the list of partitions included in this pool.&lt;/p&gt;
    &lt;p&gt;Check:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # zpool status pool: tank state: ONLINE config: NAME STATE READ WRITE CKSUM tank ONLINE 0 0 0 mirror-0 ONLINE 0 0 0 ada1p1 ONLINE 0 0 0 ada2p1 ONLINE 0 0 0 errors: No known data errors&lt;/quote&gt;
    &lt;p&gt;ZFS immediately mounts this pool at &lt;code&gt;/tank&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # mount /dev/ada0p3 on / (ufs, local, soft-updates, journaled soft-updates) devfs on /dev (devfs) tank on /tank (zfs, local, nfsv4acls)&lt;/quote&gt;
    &lt;p&gt;Check partitions now:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # gpart show =&amp;gt; 40 33554352 ada0 GPT (16G) 40 1024 1 freebsd-boot (512K) 1064 4194304 2 freebsd-swap (2.0G) 4195368 29359024 3 freebsd-ufs (14G) =&amp;gt; 40 33554352 ada1 GPT (16G) 40 33554352 1 freebsd-zfs (16G) =&amp;gt; 40 33554352 ada2 GPT (16G) 40 33554352 1 freebsd-zfs (16G)&lt;/quote&gt;
    &lt;p&gt;If we want to change the mountpoint – execute &lt;code&gt;zfs set mountpoint&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # zfs set mountpoint=/data tank&lt;/quote&gt;
    &lt;p&gt;And it immediately mounts to the new directory:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # mount /dev/ada0p3 on / (ufs, local, soft-updates, journaled soft-updates) devfs on /dev (devfs) tank on /data (zfs, local, nfsv4acls)&lt;/quote&gt;
    &lt;p&gt;Enable data compression – useful for a NAS, see Compression and Compressing ZFS File Systems.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;lz4&lt;/code&gt; is the current default option, let’s enable it:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # zfs set compression=lz4 tank&lt;/quote&gt;
    &lt;p&gt;Since we installed the system on UFS, we need to add a few parameters to autostart for ZFS to work.&lt;/p&gt;
    &lt;p&gt;Configure the boot loader in &lt;code&gt;/boot/loader.conf&lt;/code&gt; to load kernel modules:&lt;/p&gt;
    &lt;quote&gt;zfs_load="YES"&lt;/quote&gt;
    &lt;p&gt;Or, to avoid manual editing, use &lt;code&gt;sysrc&lt;/code&gt; with the &lt;code&gt;-f&lt;/code&gt; flag:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # sysrc -f /boot/loader.conf zfs_load="YES"&lt;/quote&gt;
    &lt;p&gt;And add to &lt;code&gt;/etc/rc.conf&lt;/code&gt; to start the &lt;code&gt;zfsd&lt;/code&gt; daemon and mount the file systems:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # sysrc zfs_enable="YES" zfs_enable: NO -&amp;gt; YES&lt;/quote&gt;
    &lt;p&gt;Reboot and check:&lt;/p&gt;
    &lt;quote&gt;root@test-nas-1:/home/setevoy # zpool status pool: tank state: ONLINE config: NAME STATE READ WRITE CKSUM tank ONLINE 0 0 0 mirror-0 ONLINE 0 0 0 ada1p1 ONLINE 0 0 0 ada2p1 ONLINE 0 0 0&lt;/quote&gt;
    &lt;p&gt;Everything is in place.&lt;/p&gt;
    &lt;p&gt;Now you can proceed with further tuning – configuring separate datasets, snapshots, etc.&lt;/p&gt;
    &lt;p&gt;For a Web UI, you could try Seafile or FileBrowser.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46462108</guid><pubDate>Fri, 02 Jan 2026 06:48:32 +0000</pubDate></item><item><title>Round the tree, yes, but not round the squirrel</title><link>https://www.futilitycloset.com/2026/01/02/round-and-round/</link><description>&lt;doc fingerprint="f75c93007bda195e"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;‘I had quite a bit of fun playing hide-and-seek with a squirrel,’ he said. ‘You know that little round glade with a lone birch in the centre? It was on this tree that a squirrel was hiding from me. As I emerged from a thicket, I saw its snout and two bright little eyes peeping from behind the trunk. I wanted to see the little animal, so I started circling round along the edge of the glade, mindful of keeping the distance in order not to scare it. I did four rounds, but the little cheat kept backing away from me, eyeing me suspiciously from behind the tree. Try as I did, I just could not see its back.’&lt;/p&gt;
      &lt;p&gt;‘But you have just said yourself that you circled round the tree four times,’ one of the listeners interjected.&lt;/p&gt;
      &lt;p&gt;‘Round the tree, yes, but not round the squirrel.’&lt;/p&gt;
      &lt;p&gt;‘But the squirrel was on the tree, wasn’t it?’&lt;/p&gt;
      &lt;p&gt;‘So it was.’&lt;/p&gt;
      &lt;p&gt;‘Well, that means you circled round the squirrel too.’&lt;/p&gt;
      &lt;p&gt;‘Call that circling round the squirrel when I didn’t see its back?’&lt;/p&gt;
      &lt;p&gt;‘What has its back to do with the whole thing? The squirrel was on the tree in the centre of the glade and you circled round the tree. In other words, you circled round the squirrel.’&lt;/p&gt;
      &lt;p&gt;‘Oh no, I didn’t. Let us assume that I’m circling round you and you keep turning, showing me just your face. Call that circling round you?’&lt;/p&gt;
      &lt;p&gt;‘Of course, what else can you call it?’&lt;/p&gt;
      &lt;p&gt;‘You mean I’m circling round you though I’m never behind you and never see your back?’&lt;/p&gt;
      &lt;p&gt;‘Forget the back! You’re circling round me and that’s what counts. What has the back to do with it?’&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;— Yakov Perelman, Mathematics Can Be Fun, 1927&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46462592</guid><pubDate>Fri, 02 Jan 2026 08:16:21 +0000</pubDate></item><item><title>Standard Ebooks: Public Domain Day 2026 in Literature</title><link>https://standardebooks.org/blog/public-domain-day-2026</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46462702</guid><pubDate>Fri, 02 Jan 2026 08:40:41 +0000</pubDate></item><item><title>Going immutable on macOS, using Nix-Darwin</title><link>https://carette.xyz/posts/going_immutable_macos/</link><description>&lt;doc fingerprint="2a945a3cf7adab95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Going immutable on macOS&lt;/head&gt;
    &lt;p&gt;· 8 min read&lt;/p&gt;
    &lt;p&gt;With no surprise the end of one year marks the start of the next.&lt;lb/&gt; And the beginning of a year is always synonymous with… a fresh macOS system!&lt;/p&gt;
    &lt;p&gt;But managing a good working environment on macOS has long been a game of “hope for the best.” We’ve all been there: a &lt;code&gt;curl | sh&lt;/code&gt; here, a manual &lt;code&gt;brew install&lt;/code&gt; there, and six months later, you’re staring at a broken &lt;code&gt;PATH&lt;/code&gt; and a Python environment that seems to have developed its own consciousness.&lt;/p&gt;
    &lt;p&gt;I’ve spent a lot of time recently moving my entire workflow into a declarative system using nix. From my zsh setup to my odin toolchain, here is why the transition from the imperative world of Homebrew to the immutable world of nix-darwin has been both a revelation and a fight.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem to solve: imperative rot #&lt;/head&gt;
    &lt;p&gt;Homebrew is great.&lt;lb/&gt; From the Linux world, it was the perfect missing package manager for macOS at first, promoted by a lot of developers, and it (mostly) works. But Homebrew has a problem: it is imperative.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;brew install&lt;/code&gt; you are changing the state of your machine in a way that is difficult to reverse or replicate exactly.&lt;lb/&gt; As an example, if I set up a new Mac today, &lt;code&gt;brew install neovim&lt;/code&gt; might give me version 0.10. However, if I do it six months from now, the version might changed and I had to reconfigure some components because of that change. The consequence is me, spending a few hours debugging my environment instead of writing code.&lt;/p&gt;
    &lt;p&gt;A solution to that is postfix every brew package by its version, but this is not possible for every package.&lt;/p&gt;
    &lt;p&gt;Another solution is system immutability and the Nix store.&lt;/p&gt;
    &lt;head rend="h2"&gt;System immutablility, and the Nix store #&lt;/head&gt;
    &lt;p&gt;Nix approaches the problem from a functional programming perspective.&lt;lb/&gt; Your system is not a collection of side effects, but a pure function of your configuration.&lt;/p&gt;
    &lt;p&gt;This allows different strong points like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reproducibility: Every package lives in &lt;code&gt;/nix/store&lt;/code&gt;with a unique hash. This means I can have three different versions of the Odin compiler side-by-side, and they will never see each other, or even mess up with the different versions.&lt;/item&gt;
      &lt;item&gt;rollbacks: If a system update breaks my shell, I don’t panic. I just boot into a previous generation. The previous state of my system is still sitting in the store, untouched.&lt;/item&gt;
      &lt;item&gt;flakes: Using &lt;code&gt;flake.lock&lt;/code&gt;, I pin my setup to specific git commits. If it works on my laptop then it will work on yours. Period.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rollbacks on macOS exist, and are great to go back to a previous version “that works”.&lt;lb/&gt; As an example, to list all my previous generations, I can do:&lt;/p&gt;
    &lt;code&gt;&amp;gt; sudo nix-env --list-generations -p /nix/var/nix/profiles/system
   1   2025-12-28 01:21:38
   2   2025-12-28 01:33:47
   3   2025-12-28 09:34:27
   4   2025-12-28 09:43:15
   5   2025-12-28 11:00:49
   6   2025-12-28 11:10:12
   7   2025-12-28 11:19:03
   ...
&lt;/code&gt;
    &lt;p&gt;Each generation is also stored in a read-only specific volume on your system, which prevents accidental mutability of your packages.&lt;/p&gt;
    &lt;p&gt;On macOS &lt;code&gt;nix-darwin&lt;/code&gt; allows me to modify everything, from Finder settings to the Dock, or the Trackpad.&lt;/p&gt;
    &lt;p&gt;As an example, this is a part of my setup:&lt;/p&gt;
    &lt;code&gt;...
configuration = { pkgs, ... }: {
    # Firewall settings
    networking.applicationFirewall = {
        enable = true;
        enableStealthMode = true;
        allowSigned = true;
        allowSignedApp = true;
    };

    system.defaults = {
        CustomUserPreferences = {
          # Disable siri
          "com.apple.Siri" = {
            "UAProfileCheckingStatus" = 0;
            "siriEnabled" = 0;
          };
          # Disable personalized ads 
          "com.apple.AdLib" = {
            allowApplePersonalizedAdvertising = false;
          };
        };

        # Show battery percentage in the menu bar
        controlcenter.BatteryShowPercentage = true;

        # Allow touch to click
        trackpad.Clicking = true;

        # Hide the dock after a small delay of inactivity
        dock.autohide = true;
        dock.autohide-delay = 0.25;

        ...
    };
}
&lt;/code&gt;
    &lt;p&gt;And all those settings are documented in the official nix-darwin manual here.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Nix flake #&lt;/head&gt;
    &lt;p&gt;Before diving into the pros and cons of Nix, we need to address the engine under the hood: The Nix Flake.&lt;/p&gt;
    &lt;p&gt;In the traditional Nix world, things were a bit loose.&lt;lb/&gt; You had “channels”, but “channels” that could change behind your back… and we don’t want to get back to mutable systems.&lt;lb/&gt; Nix flakes fixed this by introducing a strictly defined structure.&lt;/p&gt;
    &lt;p&gt;Every Flake has a &lt;code&gt;flake.nix&lt;/code&gt; (the blueprint) and a &lt;code&gt;flake.lock&lt;/code&gt; (the time capsule).&lt;/p&gt;
    &lt;p&gt;The lockfile is actually the secret sauce.&lt;lb/&gt; It records the exact git commit of every dependency. When I build my system, I’m not just asking for “the latest version of the Odin programming language”, but for the exact version of Odin that existed at a specific moment in history.&lt;/p&gt;
    &lt;p&gt;So, when you run &lt;code&gt;darwin-rebuild switch --flake .&lt;/code&gt; to update your system (depending on configuration changes), Nix will look first at the lockfile.
If the lockfile says you are using &lt;code&gt;nixpkgs&lt;/code&gt; from October 12th at 10:45 PM, that is exactly what it fetches.
Nix doesn’t matter if you are on a new MacBook or an old iMac. If the lockfile is the same, then the resulting environment will be identical to your previous setup.&lt;/p&gt;
    &lt;p&gt;This turns system administration into a pure function: the same inputs always produce the same result.&lt;/p&gt;
    &lt;head rend="h2"&gt;The “get and forget” workflow #&lt;/head&gt;
    &lt;p&gt;One of the most liberating features is the “ephemeral shell” provided by Nix.&lt;lb/&gt; Imagine you need to test a script against &lt;code&gt;Python 3.15&lt;/code&gt;, but you don’t want to install a pre-release version globally and risk breaking your system tools…&lt;/p&gt;
    &lt;p&gt;With Nix, you run:&lt;/p&gt;
    &lt;code&gt;nix shell nixpkgs#python314
&lt;/code&gt;
    &lt;p&gt;Suddenly, &lt;code&gt;python --version&lt;/code&gt; returns 3.14.
You run your tests, you exit the shell, and it’s gone.&lt;/p&gt;
    &lt;p&gt;No leftovers, no site-packages conflicts, no trace. It is the ultimate “get and forget” utility, without messing up your system.&lt;/p&gt;
    &lt;p&gt;However be careful as “ephemeral” does not mean “sandboxed” or “isolated” in this context! A common misconception is that &lt;code&gt;nix shell&lt;/code&gt; is like a Docker container or a VM, but it is not as &lt;code&gt;nix shell&lt;/code&gt; only isolated the environment variables, and is still running directly on the darwin kernel.&lt;/p&gt;
    &lt;head rend="h2"&gt; The learning &lt;del rend="overstrike"&gt;curve&lt;/del&gt; cliff # &lt;/head&gt;
    &lt;p&gt;Is this configuration exempt from defaults? Absolutely not.&lt;lb/&gt; In fact, its biggest “default” is one of the most significant pain points in modern software: it arrives wrapped in complicated concepts and dense foundations.&lt;/p&gt;
    &lt;p&gt;The learning curve for Nix is actually not a curve, but a vertical cliff face.&lt;/p&gt;
    &lt;p&gt;Unlike Homebrew, where you just type a command and forget it, Nix requires you to learn a domain-specific language called… &lt;code&gt;Nix&lt;/code&gt; (I know, it is confusing). You have to understand how symbolic links work on macOS, how the Nix daemon interacts with Apple’s read-only system volume, and why your applications don’t magically appear in Spotlight.&lt;/p&gt;
    &lt;p&gt;For instance, getting GUI apps to show up in the Applications folder requires “trampoline” binaries or custom activation scripts using &lt;code&gt;mkalias&lt;/code&gt;.&lt;lb/&gt; After a few minutes debugging and scrolling forums it works great, but many users will simply stop there and walking away with the mistaken impression that &lt;code&gt;nix-darwin&lt;/code&gt; is an immature project, rather than a deeply powerful one.&lt;/p&gt;
    &lt;p&gt;The documentation is great, but maybe not well arranged.&lt;lb/&gt; As an example, this is the manual to write your own &lt;code&gt;flake.nix&lt;/code&gt;: https://nix-darwin.github.io/nix-darwin/manual/.
You can be lost very easily in the manual if you do not know what you are looking for…&lt;/p&gt;
    &lt;head rend="h2"&gt;The hybrid reality #&lt;/head&gt;
    &lt;p&gt;Despite my love for Nix, it isn’t perfect for everything. macOS GUI applications like Thunderbird, Firefox, or CrossOver, often fight against the read-only nature of the Nix store.&lt;lb/&gt; Those software expect to self-update and live in &lt;code&gt;/Applications&lt;/code&gt; on your system.&lt;/p&gt;
    &lt;p&gt;I found the sane path to be an hybrid approach: I use &lt;code&gt;nix-darwin&lt;/code&gt; to manage my critical state (compilers, LSPs, shell aliases), and use the homebrew module inside my Nix config to handle the big GUI pieces. It looks like this:&lt;/p&gt;
    &lt;code&gt;// file: brew.nix
homebrew = {
  enable = true;
  casks = [ 
    "firefox" 
    "thunderbird" 
    "crossover" 
  ];
};
&lt;/code&gt;
    &lt;p&gt;That’s it! And using this, I am sure Nix will use &lt;code&gt;brew&lt;/code&gt; to install those software on my system, as I did manually with my &lt;code&gt;brew install&lt;/code&gt; scripts.&lt;/p&gt;
    &lt;p&gt;This gives me the best of both worlds: Homebrew handles the macOS-specific integration, but Nix still “records” that they should exist in my declarative blueprint.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to start #&lt;/head&gt;
    &lt;p&gt;If you want to move away from “hope-based” configuration:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;install the Determinate Nix Installer: it handles the messy macOS multi-user setup for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;initialize a Flake and&lt;/p&gt;&lt;code&gt;home-manager&lt;/code&gt;: Create a&lt;code&gt;flake.nix&lt;/code&gt;and a&lt;code&gt;home.nix&lt;/code&gt;for your home-manager instance.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;think “modularity”, like keeping your system settings in&lt;/p&gt;&lt;code&gt;system.nix&lt;/code&gt;, your dev tools in&lt;code&gt;dev.nix&lt;/code&gt;, and your GUI apps in&lt;code&gt;brew.nix&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;version everything and commit your&lt;/p&gt;&lt;code&gt;flake.lock&lt;/code&gt;! It is the source of truth for your system.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are curious I’ve documented my current setup, including my security hardening (firewall, stealth mode, etc.) here: k0pernicus/dotfiles/nix-darwin-config.&lt;/p&gt;
    &lt;p&gt;Keep in mind this configuration is personal, and might not be interesting (and certainly not useful) for everyone.&lt;/p&gt;
    &lt;p&gt;A few links that helped me to make a first setup version for my mac:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://nixcademy.com/posts/nix-on-macos/&lt;/item&gt;
      &lt;item&gt;https://dreamsofcode.io/blog/nix-darwin-my-favorite-package-manager-for-macos&lt;/item&gt;
      &lt;item&gt;https://github.com/torgeir/nix-darwin&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s more work upfront, certainly. But there is a profound peace of mind in knowing that your system is defined by code, not by a history of forgotten terminal commands.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46462719</guid><pubDate>Fri, 02 Jan 2026 08:42:34 +0000</pubDate></item><item><title>HPV vaccination reduces oncogenic HPV16/18 prevalence from 16% to &lt;1% in Denmark</title><link>https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2025.30.27.2400820</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46463315</guid><pubDate>Fri, 02 Jan 2026 10:10:46 +0000</pubDate></item><item><title>One Number I Trust: Plain-Text Accounting for a Multi-Currency Household</title><link>https://lalitm.com/post/one-number-i-trust/</link><description>&lt;doc fingerprint="2f08811d87a33d15"&gt;
  &lt;main&gt;
    &lt;p&gt;Two people. Eighteen accounts spanning checking, savings, credit cards, investments. Three currencies. Twenty minutes of work every week.&lt;/p&gt;
    &lt;p&gt;One net worth number I actually trust.&lt;/p&gt;
    &lt;p&gt;The payoff: A single, trustworthy net worth number growing over time.&lt;/p&gt;
    &lt;p&gt;No app did exactly what I needed, so I built my own personal finance system using plain-text accounting principles and a powerful Python library called Beancount. This post shows you how I handle imports, investments, multi-currency, and a two-person view.&lt;/p&gt;
    &lt;head rend="h2"&gt;How I got here&lt;/head&gt;
    &lt;p&gt;It all started during the 2021 tax season. I had blocked out an entire weekend and was juggling statements, trying to compute capital gains, stressing about getting the numbers mixed up. “This is chaos”, I thought. “There must be a way to simplify this with automation”. Being a software engineer, I did what felt natural and hacked together a bunch of scripts on top of a database.&lt;/p&gt;
    &lt;p&gt;Though it worked and I kept using it day-to-day, by the next tax season the cracks became obvious. The code was hard to debug, random transactions went missing, and worst of all, the balances the scripts computed didn’t match the balances on my statements. I tried to fix it but the more I tried, the more I felt lost about what the system was really doing. Eventually I just gave up.&lt;/p&gt;
    &lt;p&gt;Why did I fail so spectacularly? My entire approach was flawed from the start! I’d ignored centuries of accounting wisdom and repeated fundamental mistakes humanity solved long ago. So I learned from my mistakes and did the research. And over time I incrementally discovered double-entry bookkeeping, plain-text accounting and Beancount.&lt;/p&gt;
    &lt;p&gt;Fast forward to today, and I have a flexible, powerful, and private system, fully customized to how my brain works. Most transactions import automatically from PDF statements (counterintuitively, it’s often more reliable than CSV!). Tax time is a simple matter of checking always-fresh reports and copying numbers over. The weekly ritual is simple: download statements, categorize transactions in a web UI, run a bunch of scripts to regenerate, commit (I walk through this in more detail later).&lt;/p&gt;
    &lt;p&gt;However, I want to be realistic: building a system like this takes time and effort.1 You will need to learn some basic accounting concepts, be comfortable with Python, and consistently spend time every week keeping things up-to-date. If your finances are simple or you just want day-to-day budgeting, this is almost certainly overkill. Apps like YNAB or even the humble spreadsheet work great.&lt;/p&gt;
    &lt;p&gt;But if you want uncompromising control over how you look at your finances, read on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Concepts&lt;/head&gt;
    &lt;head rend="h4"&gt;Double-entry bookkeeping&lt;/head&gt;
    &lt;p&gt;Suppose on a Saturday, I transfer money from my checking account to a savings account. The money leaves on the same day but doesn’t show up on the other side until Monday. So where was it for those two days?&lt;/p&gt;
    &lt;p&gt;In a “normal”2 personal finance system, the answer would be that it was just gone. That is, for those two days, there would be a drop in the total money in two accounts. But this is weird because in reality my “net worth” did not change, yet there’s no good way to represent this.&lt;/p&gt;
    &lt;p&gt;Or suppose I pay $90 for a dinner for me and two friends. They pay me back a week later. Again, in this case the money is “gone” for that week. And even worse, the full $90 would be categorized as a “restaurant expense” while each $30 my friends paid would be “income”. But this is wrong. My expense is just $30 and the money they give me should be matched against the $60 they owe me.&lt;/p&gt;
    &lt;p&gt;Both of these are fundamental problems with how so-called “single-entry bookkeeping” works: each account’s transactions and balance are tracked individually but without the context of the “whole”. In the case of the transfer, because we’re looking at each account in isolation, we lose the fact that even though the money has left one account, it’s really still part of the “pool of money” that belongs to us. Similarly, when our friends pay us back, we’re not tracking the fact that our friends owe us money when the original transaction happened and their payment later neutralizes the debt.&lt;/p&gt;
    &lt;p&gt;Double-entry bookkeeping is the solution to both these problems. Businesses have been using it for hundreds of years3 to run their accounts, and it has powerful yet elegant ways to solve these problems and many others too.&lt;/p&gt;
    &lt;p&gt;Let’s consider again the transfer. In double-entry bookkeeping, we would represent the initial move of money as:&lt;/p&gt;
    &lt;code&gt;Bank-Checking              -1000
Transfer-In-Flight         +1000
&lt;/code&gt;
    &lt;p&gt;And when it arrives:&lt;/p&gt;
    &lt;code&gt;Transfer-In-Flight         -1000
Savings-Account            +1000
&lt;/code&gt;
    &lt;p&gt;In both cases, we see the “golden rules” of double-entry bookkeeping:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Every transaction has at least two sides and the sum of all the sides is zero. -1000 + 1000 = 0. That is, transactions always “balance”.&lt;/item&gt;
      &lt;item&gt;Every side of a transaction is an account, whether it exists in the real world or not.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It should be clear that “Bank-Checking” and “Savings-Account” are labels for your checking and savings accounts, respectively. But what is “Transfer-In-Flight”?&lt;/p&gt;
    &lt;p&gt;Well, it’s also an account! It’s not an account you’ll find on your bank’s website, but within the double-entry system, it’s just as real. Concretely, accounts in double-entry are just labels for a “bucket of money”. So there’s no “category to put this transaction under”, no “expense tracking”, no special “transfer tag”. Everything is an account.&lt;/p&gt;
    &lt;p&gt;In this specific case, &lt;code&gt;Bank-Checking&lt;/code&gt;, &lt;code&gt;Savings-Account&lt;/code&gt;, and &lt;code&gt;Transfer-In-Flight&lt;/code&gt; are all a specific type of account: they are Asset accounts. Assets are stuff you own; these can be real accounts (bank account, savings, stocks, bonds) or conceptual accounts (money in transit between accounts).&lt;/p&gt;
    &lt;p&gt;Now let’s consider the dinner example. There are 4 sides to the transaction:&lt;/p&gt;
    &lt;code&gt;Credit-Card                  -90
Restaurant-Expense           +30
Owes-Me:Alice                +30
Owes-Me:Bob                  +30
&lt;/code&gt;
    &lt;p&gt;Again, -90 + 30 + 30 + 30 = 0. It balances. All of &lt;code&gt;Credit-Card&lt;/code&gt;, &lt;code&gt;Restaurant-Expense&lt;/code&gt;, &lt;code&gt;Owes-Me:Alice&lt;/code&gt;, and &lt;code&gt;Owes-Me:Bob&lt;/code&gt; are just accounts.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Credit-Card&lt;/code&gt; is a different type of account though: it’s a Liability. Liabilities are the opposite of assets: instead of stuff you own, they’re stuff you owe to someone else. So for example, loans, credit cards, and mortgages are all liabilities.&lt;/p&gt;
    &lt;p&gt;Why negative 90? The rule is always: negative means money flowed from this account and positive means it flowed into this account. The credit card company fronted you $90, so that money flowed from your credit card to fund the purchase.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Restaurant-Expense&lt;/code&gt; is yet another type of account, an Expense account. Expense accounts are money “leaving your world”. So any time you spend some money and you no longer have access to it, that’s an expense.&lt;/p&gt;
    &lt;p&gt;Finally, &lt;code&gt;Owes-Me:Alice&lt;/code&gt; and &lt;code&gt;Owes-Me:Bob&lt;/code&gt; are also Assets. Alice and Bob have promised to pay you back, and that promise has value, $30 each. It’s not cash in your pocket, but it’s money you have a claim on. In double-entry, anything with economic value you control is an asset, whether it’s a bank balance or an IOU.&lt;/p&gt;
    &lt;p&gt;Later, when Alice pays you back:&lt;/p&gt;
    &lt;code&gt;Bank-Checking               +30
Owes-Me:Alice               -30
&lt;/code&gt;
    &lt;p&gt;This is just money moving from the “virtual” &lt;code&gt;Owes-Me:Alice&lt;/code&gt; to the “real” &lt;code&gt;Bank-Checking&lt;/code&gt; account. Both of these are still assets; it’s just the type of asset that’s changing. So no money has “entered the system” at this point. You’re just settling the debt Alice owed you.&lt;/p&gt;
    &lt;p&gt;Let’s take one last example: a paycheck.&lt;/p&gt;
    &lt;code&gt;Bank-Checking              +3000
Salary                     -3000
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;Bank-Checking&lt;/code&gt; is an Asset as we’ve learned. But &lt;code&gt;Salary&lt;/code&gt; is a new account type, an Income account. Just like Assets and Liabilities are opposites, so are Income and Expenses. Where Expenses are money leaving your world, Income is money entering it.&lt;/p&gt;
    &lt;p&gt;Money flowed from Salary (source, negative) to Bank-Checking (destination, positive). The sign feels backwards: “I received money, so why is Income negative?” Because the sign shows direction of flow: income is where the money came from, and your bank is where it went to.&lt;/p&gt;
    &lt;p&gt;This is the one part of double-entry that takes repetition.4 Don’t try to make it intuitive; just trust the invariant: if your transaction sums to zero, you’ve got the signs right. After a dozen transactions, the pattern becomes automatic.&lt;/p&gt;
    &lt;p&gt;These four types of accounts cover 99% of what you’ll do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Assets: stuff you own (bank accounts, cash, investments, money owed to you)&lt;/item&gt;
      &lt;item&gt;Liabilities: stuff you owe (credit cards, loans)&lt;/item&gt;
      &lt;item&gt;Income: money entering your world (salary, interest, dividends)&lt;/item&gt;
      &lt;item&gt;Expenses: money leaving your world (groceries, rent, restaurants)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There’s a fifth type, Equity, which is a catch-all “this money doesn’t fit elsewhere” bucket.5 Suppose you start tracking an account that already has $1000 in it; that money came from somewhere but you don’t have a record of that. It can’t be income because you already had it, and the other types don’t fit. That’s a good sign it belongs in equity. The good news is that you rarely interact with Equity directly. Generally, the software handles it for you, but there are some exceptions that we’ll cover in Chapter 2.&lt;/p&gt;
    &lt;p&gt;There’s so much more that could be said about double-entry bookkeeping. For further reading, I particularly like the double entry explainer in the Beancount docs. It goes through some more examples and expands into a bunch of related topics.&lt;/p&gt;
    &lt;p&gt;But we now have the foundation which ensures that every transaction balances, every dollar is accounted for, and nothing slips through the cracks. But we still need a way to actually record and store these transactions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Plain text accounting&lt;/head&gt;
    &lt;p&gt;One of the things I learned from writing my own finance system is that auditability is king. You need the ability to eyeball a transaction, ask yourself “does this look right,” and fix it if it doesn’t. And nothing beats being able to see and edit any transaction you’ve ever made in a text editor.&lt;/p&gt;
    &lt;p&gt;That’s one of the main things that drew me to the philosophy of Plain Text Accounting. This is a set of principles on using plain text files as the “immutable source of truth” of your finances and then building scripts and tools on top of them to process, analyze, and visualize them.&lt;/p&gt;
    &lt;p&gt;There are many other advantages to this I’ve come to appreciate over the years:&lt;/p&gt;
    &lt;p&gt;Everything is version controlled. You can store these transaction files in a git repo, which has powerful effects. You can look at diffs to see what changed on any day. You can &lt;code&gt;git blame&lt;/code&gt; any transaction to see when and why it was added. You can &lt;code&gt;git tag&lt;/code&gt; important states of the repo (e.g. when taxes were filed, when a new job was started, when a big refactoring happened). You can &lt;code&gt;git checkout&lt;/code&gt; any previous state to see e.g. “how did my repo look last year”.&lt;/p&gt;
    &lt;p&gt;It’s private so you never have to trust any third party with all your financial details. Everything can be stored in locations that you fully control.&lt;/p&gt;
    &lt;p&gt;There’s no lock-in. Because everything is just a plain text file, it’s trivially easy to change how you want things to be represented: you don’t have to deal with apps with broken or messy CSV exports making it difficult to take your data elsewhere.&lt;/p&gt;
    &lt;p&gt;It’s scriptable. If you want to refactor something, compute a new breakdown or even rewrite your system entirely, all you need is to write a script. Whether you write it yourself or prompt an LLM to do it for you, the text-based format makes automation trivial.&lt;/p&gt;
    &lt;p&gt;Plain text gives you the abstract idea of “storing transactions in text” but there’s still a bunch of questions. What’s the transaction syntax? How do you parse your files? How do you validate that everything balances, compute totals, and let you query the results? That’s where Beancount comes in.&lt;/p&gt;
    &lt;head rend="h4"&gt;Introducing Beancount!&lt;/head&gt;
    &lt;p&gt;Over the years, people have written many plain-text accounting tools which answer all the questions above. The main ones you’ll find which have gained a lot of popularity are Ledger, hledger, and Beancount. I’ve used each of them at some point in my plain text journey and all are solid choices. But I ended up on Beancount for a few reasons.&lt;/p&gt;
    &lt;p&gt;It’s a Python library, not just a command-line tool. I can write importers that parse my bank’s PDF statements, generate transactions programmatically, and build custom reports, all in a language I already know.&lt;/p&gt;
    &lt;p&gt;Strictness by default. Accounts must be declared before use, so typos get caught immediately. Transactions must balance and there are immediate error messages if they don’t. The tool catches mistakes early rather than letting them propagate.&lt;/p&gt;
    &lt;p&gt;Plugin and tool ecosystem. Beancount has a very rich set of libraries and tools which build on top of and integrate with it. Along with the core project, you get access to any and all of these projects you want to use. We’ll discuss this much more later.&lt;/p&gt;
    &lt;p&gt;Fava. The web UI which sits on top of the Beancount engine. It’s so good that people convert from other formats (using tools like ledger2beancount or gnucash2beancount) just to use it. Where Beancount gives you the reliable engine, Fava gives you the pretty yet powerful frontend:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reports: balance sheet, income statement, transaction journal&lt;/item&gt;
      &lt;item&gt;Query editor: SQL-like queries, exportable to CSV&lt;/item&gt;
      &lt;item&gt;Charts: spending breakdowns, net worth over time, holdings by currency&lt;/item&gt;
      &lt;item&gt;Error highlighting: problems highlighted immediately&lt;/item&gt;
      &lt;item&gt;Extensibility: plugins like fava-dashboards and fava-portfolio-returns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With this, we now understand enough of the basic concepts for us to get started trying out Beancount!&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Getting Started&lt;/head&gt;
    &lt;p&gt;The best way to learn plain-text accounting is to roll up your sleeves and try it out. So let’s pause the theory for a moment and get a real ledger running on your machine.&lt;/p&gt;
    &lt;p&gt;I’ve built a companion repository, LalitMaganti/beancount-blog-examples, which contains a cut-down version of the system I use day-to-day. The repo is organized into folders that match the chapters of this post (&lt;code&gt;chapter-2/&lt;/code&gt;, &lt;code&gt;chapter-3/&lt;/code&gt;, etc.), each building on the previous. It also includes a &lt;code&gt;demo/&lt;/code&gt; folder with 2+ years of synthetic history if you want to see the end result immediately.&lt;/p&gt;
    &lt;p&gt;To get started, clone the repository:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/LalitMaganti/beancount-blog-examples.git
cd beancount-blog-examples

# Run the demo to see the end result
./scripts/quickstart.sh demo

# Or start Chapter 2 to follow the guide
./scripts/quickstart.sh chapter-2
&lt;/code&gt;
    &lt;p&gt;This will set up a Python environment, install dependencies, and open Fava at http://localhost:5000. Here’s what you should see.&lt;/p&gt;
    &lt;p&gt;Fava's Trial Balance view shows assets, income, and expenses in one place.&lt;/p&gt;
    &lt;p&gt;Sunburst charts make it easy to spot your biggest expense categories instantly.&lt;/p&gt;
    &lt;p&gt;Click around the different tabs. You’ll find that Fava gives you the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Balance sheet: the state of your accounts at the current point in time. Basically think of it as an aggregate view of all your finances. You can answer questions like “what’s my net worth now?”, “how much money do I owe across my credit cards?” or “how much have I gained from investments?”&lt;/item&gt;
      &lt;item&gt;Income statement: the sum of all the money flows into/out of your accounts. Think of it as a sum of all the income and expenses across time. You can answer questions like “how much did I earn from my job?”, “how much did I spend on Amazon?” or “did I spend more or less than last year?”&lt;/item&gt;
      &lt;item&gt;Transaction history: a flat list of all transactions you have in your journal. A way to see and search any transaction you’ve made across any accounts in your system.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Query Console lets you run SQL-like queries against your financial data.&lt;/p&gt;
    &lt;p&gt;There’s much more to Fava’s features (queries, multi-currency, plugins) as we’ll see later on in the post.&lt;/p&gt;
    &lt;p&gt;You can also explore the text journal itself using a text editor. For example, here’s a grocery run and a payslip in the Beancount transaction format:&lt;/p&gt;
    &lt;code&gt;; chapter-2/src/transactions.beancount

; Beancount auto-fills the second amount when it can be inferred.
2024-01-15 * "Tesco" "Weekly groceries"
  Expenses:Groceries                    85.50 GBP
  Assets:Lalit:UK:HSBC:Current:GBP

2024-01-25 * "Google" "January salary"
  Assets:Lalit:UK:HSBC:Current:GBP    3200.00 GBP
  Income:Lalit:UK:Google:Salary
&lt;/code&gt;
    &lt;p&gt;Go through the transactions and get a feel for the format. It might seem alien at first but trust me when I say soon it’ll feel like the most natural thing in the world!&lt;/p&gt;
    &lt;p&gt;With a VS Code extension, you get syntax highlighting and auto-completion for your accounts.&lt;/p&gt;
    &lt;p&gt;Now that you have a working system, I want to share the hard-won insights that aren’t in the official docs. This post isn’t going to be a full Beancount tutorial. The official docs are excellent for that (Fava even has a demo that you can try without downloading anything!).&lt;/p&gt;
    &lt;p&gt;Instead, I want to focus on the architecture: the decisions I wish I’d made correctly from day one. I’m writing this as if I’m speaking to my past self.&lt;/p&gt;
    &lt;head rend="h4"&gt;Start with one account&lt;/head&gt;
    &lt;p&gt;You don’t need to track everything on day one. Pick one account. Your main checking account is a good start. Get comfortable with the flow. Import statements, categorize transactions, check that balances match. Once that feels solid, add another account. Then another.&lt;/p&gt;
    &lt;p&gt;I started with my HSBC current account. Now, I have my whole financial life inside the system and I trust it wholeheartedly. But this happened one account at a time. If I tried to do everything in one go, I would certainly have been overwhelmed and given up on the whole thing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Opening balances&lt;/head&gt;
    &lt;p&gt;Once you’ve picked your first account, you face an immediate problem: you may have opened that account years ago and there might already be thousands of transactions over that time. Trying to import them all in one go is another sure path to being overwhelmed and giving up.&lt;/p&gt;
    &lt;p&gt;Instead, a better idea is to pick a “starting date” at which you say “I will import everything from this day onwards”. But that poses its own problem: you already had money in that account, how do you tell Beancount it exists?&lt;/p&gt;
    &lt;p&gt;Well, Beancount has a &lt;code&gt;pad&lt;/code&gt; directive that creates the balancing entry automatically:&lt;/p&gt;
    &lt;code&gt;; chapter-2/src/balance.beancount
2024-01-01 open Equity:Opening-Balances
2024-01-01 pad Assets:Lalit:UK:HSBC:Current:GBP Equity:Opening-Balances
2024-01-02 balance Assets:Lalit:UK:HSBC:Current:GBP  1500.00 GBP
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;pad&lt;/code&gt; directive tells Beancount: “whatever amount is needed to make the balance assertion true, take it from &lt;code&gt;Equity:Opening-Balances&lt;/code&gt; and put it in this account”. This is one of the rare cases you actually have to think about equity accounts (though not much beyond blindly using &lt;code&gt;Equity:Opening-Balances&lt;/code&gt;!).&lt;/p&gt;
    &lt;head rend="h3"&gt;Structure That Scales&lt;/head&gt;
    &lt;p&gt;Adding a first account is easy and the second is straightforward, but adding a third, fourth, fifth… and you can easily find that things start becoming jumbled and messy. Just like code, putting a little bit of thought into the organization upfront goes a long way. This part covers the architectural decisions you’ll thank yourself later for.&lt;/p&gt;
    &lt;head rend="h4"&gt;Naming Asset and Liability accounts&lt;/head&gt;
    &lt;p&gt;The structure of asset and liability account names is very important, much more than I initially gave them credit for. It’s a good idea to keep as much information in them as possible. Here’s what I’ve settled on:&lt;/p&gt;
    &lt;code&gt;; chapter-2/src/accounts.beancount
2024-01-01 open Assets:Lalit:UK:HSBC:Current:GBP          GBP
2024-01-01 open Assets:Lalit:UK:Barclays:Current:GBP      GBP
2024-01-01 open Liabilities:Lalit:UK:AMEX:GBP             GBP
&lt;/code&gt;
    &lt;p&gt;The pattern is:&lt;/p&gt;
    &lt;code&gt;Type:Person:Region:Institution:Account:Currency
&lt;/code&gt;
    &lt;p&gt;Why this structure? Because it’s a lot easier to remove detail than add it in later! I initially started by not having the country, the currency or my name in the account. But over time, I wanted to understand:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How much money I have in the UK vs the US?&lt;/item&gt;
      &lt;item&gt;How much cash (i.e. not investments) is in a certain currency?&lt;/item&gt;
      &lt;item&gt;How much of our household wealth was in my wife’s accounts vs my own (discussed in more detail in Chapter 6)?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Having this information in the account name is great because Beancount’s SQL syntax makes it very easy to filter on account names. Want “all UK assets”? Filter on &lt;code&gt;:UK:&lt;/code&gt;. Want “all HSBC accounts”? Filter on &lt;code&gt;:HSBC:&lt;/code&gt;. Want “all GBP cash”? Filter on &lt;code&gt;:GBP&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h4"&gt;Powering up with Plugins&lt;/head&gt;
    &lt;p&gt;Once you have a structure, you want to ensure it stays clean. This is where Beancount’s Plugins come in.&lt;/p&gt;
    &lt;p&gt;Plugins are Python scripts that run when your ledger loads. They can validate data, modify entries, or even generate new transactions automatically. You load them in your journal file like this:&lt;/p&gt;
    &lt;code&gt;plugin "beancount.plugins.check_commodity"
&lt;/code&gt;
    &lt;p&gt;Remember the transfer-in-flight pattern from Chapter 1? Here’s how it looks in Beancount:&lt;/p&gt;
    &lt;code&gt;; chapter-2/src/transactions.beancount
; Money leaves on Saturday
2024-03-16 * "Transfer to Barclays"
  Assets:Lalit:UK:HSBC:Current:GBP      -1000.00 GBP
  Assets:Lalit:Transfers:Internal        1000.00 GBP

; Money arrives on Monday
2024-03-18 * "Transfer from HSBC"
  Assets:Lalit:Transfers:Internal       -1000.00 GBP
  Assets:Lalit:UK:Barclays:Current:GBP   1000.00 GBP
&lt;/code&gt;
    &lt;p&gt;Once both transactions are recorded, the transit account balance returns to zero, confirming the transfer is complete. If you record one leg of a transfer but forget the other, the transit account will simply show a non-zero balance.&lt;/p&gt;
    &lt;p&gt;Understanding where a non-zero balance in transfers is coming from is handled by my absolute favorite plugin, beancount_reds_plugins.zerosum. It’s responsible for matching both sides of a transaction and moving it to a separate account, meaning my &lt;code&gt;Transfers:Internal&lt;/code&gt; account only contains the actual “pending” transactions. Making this account empty is a surprisingly satisfying little “minigame” during my weekly imports (though it never lasts for long!).&lt;/p&gt;
    &lt;p&gt;There are also a couple more plugins that make handling closed accounts better:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;beancount.plugins.close_tree - When you close an account, automatically closes all child accounts too. Useful as you move your banking between institutions.&lt;/item&gt;
      &lt;item&gt;beancount_checkclosed.check_closed - Validates that closed accounts have zero balance and no transactions after the close date.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;The boundary of your system&lt;/head&gt;
    &lt;p&gt;As you add accounts one by one, you’ll inevitably see money flowing to places you haven’t set up yet. Say you transfer £500 to a Natwest savings account you haven’t added to the system. Where does it go?&lt;/p&gt;
    &lt;p&gt;Specifically, use a named placeholder account in &lt;code&gt;Equity:Transfers&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;; chapter-2/src/transactions.beancount
2024-03-15 * "Transfer to savings (not yet tracked)"
  Assets:Lalit:UK:HSBC:Current:GBP     -500.00 GBP
  Equity:Transfers:Natwest-Savings      500.00 GBP
&lt;/code&gt;
    &lt;p&gt;This essentially says: “£500 went to Natwest Savings, which I’m not tracking yet”. Putting it in an equity account means it doesn’t pollute your balance sheet with incomplete information or your income statement with false expenses.&lt;/p&gt;
    &lt;p&gt;Note also the best practice of using a named equity account per untracked destination, not a generic bucket; this was a mistake I made when I did this initially. You’ll thank yourself when you import your Natwest savings account later, you can just do a search-replace to rename the accounts 6.&lt;/p&gt;
    &lt;head rend="h4"&gt;Organizing your repo&lt;/head&gt;
    &lt;p&gt;As you add these patterns (transit accounts, multiple institutions, liability accounts) your single &lt;code&gt;journal.beancount&lt;/code&gt; file will start to become unwieldy. Just like good software architecture, you want to organize upfront to be easy to maintain as the system continues to grow.&lt;/p&gt;
    &lt;p&gt;This is what the structure looks like with the concepts we have right now (it’ll get more complicated as we go deeper!):&lt;/p&gt;
    &lt;code&gt;chapter-2/
├── journal.beancount            # Main entry point, includes everything
├── src/
│   ├── accounts.beancount       # Account definitions
│   ├── transactions.beancount   # Primary transaction ledger
│   └── balance.beancount        # Balance assertions
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/&lt;/code&gt;is what you write and edit (your “code”)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;journal.beancount&lt;/code&gt;is the entry point that includes everything&lt;/item&gt;
      &lt;item&gt;Later, &lt;code&gt;data/&lt;/code&gt;will hold inputs from the outside world (raw statements: PDFs, OFX, CSVs)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This organization is a small change but can make a big difference in your subconscious feeling about the state of your finances!&lt;/p&gt;
    &lt;head rend="h4"&gt;Exit ramp&lt;/head&gt;
    &lt;p&gt;At this point, you have a solid foundation for tracking multiple accounts. If you stop here, you have a robust, auditable system for manual bookkeeping. You could continue adding transactions by hand indefinitely, and you’d still be miles ahead of any spreadsheet in terms of correctness and visibility.&lt;/p&gt;
    &lt;p&gt;But manual entry is a chore, and as your financial life grows, it becomes a bottleneck. In the next chapter, we’ll see how to automate the tedious part: getting transactions from your bank statements into your ledger without losing the control that plain-text accounting gives you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: Automated Import&lt;/head&gt;
    &lt;head rend="h4"&gt;Automation is king, but harder than it looks&lt;/head&gt;
    &lt;p&gt;Inputting transactions by hand works for some people, but I don’t have the patience for it. Ever since I was young, I’ve always wanted to automate everything: it’s the reason why I became a software engineer in the first place!&lt;/p&gt;
    &lt;p&gt;But full automation is a dead end. Most banks don’t offer APIs, and scraping breaks constantly. 2FA flows change 7, websites get redesigned, sessions expire. I tried this route, and it wasn’t worth it. Even in the US where aggregators like Plaid exist, coverage is patchy.8 In the UK, it’s impossible.&lt;/p&gt;
    &lt;head rend="h4"&gt;The hierarchy of data sources&lt;/head&gt;
    &lt;p&gt;So what actually works? Well ideally your financial institution gives you something you can write a script against. But what that might be is non-obvious and counter-intuitive. Here’s the hierarchy I’ve landed on over time:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OFX is the gold standard. If your bank offers it, use it. The format is standardized, transactions have unique IDs, and deduplication is straightforward. Life is easy if you have good OFX.&lt;/item&gt;
      &lt;item&gt;CSV is the deceptive runner-up. It seems like the logical choice. Structured data, right? But in practice, bank CSVs are often afterthoughts. I’ve seen column formats change without notice, “CSVs” that are actually weird custom formats spread over multiple lines, and rows coalesced in ways that lose critical information (like cost basis).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So what do you do when OFX isn’t available and CSV isn’t trustworthy? You turn to an unlikely hero.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why PDFs beat CSVs&lt;/head&gt;
    &lt;p&gt;It sounds backwards, but PDFs are often the most reliable data source available.&lt;/p&gt;
    &lt;p&gt;Banks have a strong incentive to get PDFs right. Customers actually read them. They’re legal documents that get printed and filed. If a bank messes up a PDF statement, they hear about it immediately. If they break a CSV export, it might go months without anyone noticing.&lt;/p&gt;
    &lt;p&gt;The key insight is that bank statement PDFs are almost always columnar. Of course, this relies on the PDF having a proper text layer; if your bank sends you scanned images, you’re out of luck (though I’ve yet to encounter one that does). When you convert them to text while preserving the layout, you get something that looks like this:&lt;/p&gt;
    &lt;code&gt;Date      Details                      Paid out     Paid in     Balance
15 Jan 24 TESCO STORES 1234            42.50                    1,457.50
16 Jan 24 TFL TRAVEL                    6.80                    1,450.70
25 Jan 24 GOOGLE SALARY                           3,200.00      4,650.70
&lt;/code&gt;
    &lt;p&gt;The columns are aligned by spaces, which means you can parse them as fixed-width data. The approach works in three steps:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Convert PDF to text: Run&lt;/p&gt;&lt;code&gt;pdftotext -layout statement.pdf statement.txt&lt;/code&gt;. The&lt;code&gt;-layout&lt;/code&gt;flag preserves the original column alignment.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Find the table boundaries: Bank statements have predictable markers. HSBC uses “BALANCE BROUGHT FORWARD” at the start and “BALANCE CARRIED FORWARD” at the end. You extract just the transaction rows between these markers.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Parse with fixed-width columns: Pandas’&lt;/p&gt;&lt;code&gt;read_fwf&lt;/code&gt;function is designed exactly for this. You put this logic inside the&lt;code&gt;extract()&lt;/code&gt;method of your&lt;code&gt;beangulp&lt;/code&gt;importer class, where it converts the text into a DataFrame:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Inside your Importer class
df = pd.read_fwf(
    io.StringIO(text),
    colspecs=[(0, 10), (10, 40), (40, 52), (52, 64), (64, 80)],
    names=['Date', 'Details', 'Paid out', 'Paid in', 'Balance']
)
&lt;/code&gt;
    &lt;p&gt;The column positions come from inspecting the header row. In practice, I detect them dynamically by finding keywords like “Paid out” and “Paid in” in the header and using their character positions.&lt;/p&gt;
    &lt;p&gt;Once you have a DataFrame, generating Beancount transactions is straightforward. You write a small class that iterates through this DataFrame and maps each row to a Beancount &lt;code&gt;Transaction&lt;/code&gt; object, filling in the date, amount, and payee. See my HSBC importer for a working example.&lt;/p&gt;
    &lt;p&gt;For 95% of my banks, this approach works great. However, there is one bank where the text spacing becomes very strange and so I need to use something else. That’s when I turn to Tabula, a Java CLI that extracts data tables from PDFs, even very complex ones.&lt;/p&gt;
    &lt;p&gt;The main reason I don’t use it all the time is that it’s much slower. But it also succeeds in the cases where &lt;code&gt;pdftotext&lt;/code&gt; fails. I run it to get a structured JSON output, from which I create transactions (see my HSBC US credit card importer).&lt;/p&gt;
    &lt;p&gt;I’m sure some readers will have worries about the fragility of what I’ve described here. I can tell you from experience that in three years, neither my UK nor my US HSBC PDF importer has ever broken. Neither has my Schwab one, and my Aviva one has only needed a single change. So I can personally vouch that this approach works and works well.&lt;/p&gt;
    &lt;head rend="h4"&gt;From raw data to transactions&lt;/head&gt;
    &lt;p&gt;OK, so now you have statements. What do you do then? There are two pieces to the puzzle: parsing statements into transactions, and categorizing those transactions.&lt;/p&gt;
    &lt;p&gt;For parsing, Beancount has an official importer framework called beangulp. You write a Python class that knows how to read a particular file format (the skeleton importer in &lt;code&gt;chapter-3/&lt;/code&gt; already uses this API). Beangulp handles the mechanics: identifying which importer handles which file, extracting transactions, and deduplicating against existing entries.&lt;/p&gt;
    &lt;p&gt;But beangulp just extracts transactions without making any judgment on which account the transaction should be booked against. It doesn’t know that Tesco is groceries or that British Airways is an airline. I go to a new restaurant. How does the system know that is a restaurant?&lt;/p&gt;
    &lt;p&gt;This leads to a very important conclusion: we cannot fully automate importing transactions for bank accounts and credit cards. However, that doesn’t mean we have to enter things manually either. There’s a middle ground.&lt;/p&gt;
    &lt;p&gt;Enter beancount-import9 (Note: this is a standalone tool, distinct from Fava’s built-in import features). It’s a web UI that uses your beangulp importers and adds a categorization layer on top. You run it, it opens in your browser, and it presents pending transactions one by one for review. Think of it as a staging area where you approve or tweak before anything hits your ledger.&lt;/p&gt;
    &lt;p&gt;For each transaction, it shows the raw data from your statement alongside a suggested categorization. You can accept the suggestion, override it with a different account, or skip it entirely. Once you decide, it moves to the next one. The interface is simple, mostly keyboard-driven and optimized for speed.&lt;/p&gt;
    &lt;p&gt;The import UI allows you to manually categorize transactions, like this Tesco grocery run, while the system learns your preferences.&lt;/p&gt;
    &lt;p&gt;The categorization uses machine learning (old-school decision trees, running locally, no LLMs, no cloud). It learns from your previous choices: the first time you see “Tesco”, you pick “Expenses:Groceries”, and the second time it auto-suggests and you just hit Enter. After a few weeks, the system should know 90% of the types of transactions you make and it’s easy to correct the ones which it doesn’t.&lt;/p&gt;
    &lt;p&gt;Once you’re proficient, a month’s worth of transactions takes 5-10 minutes. Most are repeats and you’re just hitting Enter. You only pause on genuinely new merchants. This is the core of my weekly ritual, and why I’ve found categorization has not become a chore, even after doing it for years.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exit ramp&lt;/head&gt;
    &lt;p&gt;With automated imports and semi-automated categorization, the “hard work” of bookkeeping is mostly solved. For many, this is the endgame: a perfect record of where every penny went, updated in minutes each week.&lt;/p&gt;
    &lt;p&gt;But your net worth isn’t just cash in a bank account. It’s also the stocks, bonds, and funds that grow (or shrink) over time. Tracking these requires a few more tools to handle cost basis, dividends, and market prices. We’ll tackle those in Chapter 4.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: Investments&lt;/head&gt;
    &lt;p&gt;Now for investments. It’s where things get more interesting, and I think there’s less material out there covering the nitty-gritty. Here are some lessons I’ve learned over the years.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Unified Mental Model&lt;/head&gt;
    &lt;p&gt;The most important thing to realize is that Beancount treats everything as a commodity.&lt;/p&gt;
    &lt;p&gt;A share of Apple (&lt;code&gt;AAPL&lt;/code&gt;) is a commodity. A US Dollar (&lt;code&gt;USD&lt;/code&gt;) is a commodity. A British Pound (&lt;code&gt;GBP&lt;/code&gt;) is a commodity. While Beancount can infer these on the fly, you’ll typically declare them explicitly in your journal (e.g., &lt;code&gt;2024-01-01 commodity AAPL&lt;/code&gt;).10&lt;/p&gt;
    &lt;p&gt;This explicit declaration is a small but critical architectural win: it prevents a simple typo from creating a phantom currency, and it provides the metadata that advanced reporting plugins (like those used to calculate your portfolio performance) rely on to work correctly.&lt;/p&gt;
    &lt;p&gt;This means you don’t “buy stocks with money”. You simply exchange one commodity for another. The syntax for buying shares is identical to the syntax for exchanging currency.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Account Structure&lt;/head&gt;
    &lt;p&gt;Just like with bank accounts, I break investments down by institution and security.&lt;/p&gt;
    &lt;code&gt;; chapter-4/src/accounts.beancount
2024-01-01 open Assets:Lalit:US:IB:Brokerage:USD          USD
2024-01-01 open Assets:Lalit:US:IB:Brokerage:AAPL         AAPL
2024-01-01 open Assets:Lalit:UK:Vanguard:ISA:GBP          GBP
2024-01-01 open Assets:Lalit:UK:Vanguard:ISA:VWRL         VWRL
&lt;/code&gt;
    &lt;p&gt;Cash in a brokerage is just another holding named by currency (&lt;code&gt;GBP&lt;/code&gt;, &lt;code&gt;USD&lt;/code&gt;), while stock holdings use their ticker (&lt;code&gt;AAPL&lt;/code&gt;, &lt;code&gt;VWRL&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;But you also need to track the flows generated by these assets: capital gains, dividends, commissions, and withholding taxes. I create specific accounts for each security:&lt;/p&gt;
    &lt;code&gt;2024-01-01 open Income:Lalit:US:IB:Brokerage:AAPL:Dividends        USD
2024-01-01 open Income:Lalit:US:IB:Brokerage:AAPL:Capital-Gains    USD
&lt;/code&gt;
    &lt;p&gt;Why so granular? It’s the same reason I name assets fully: aggregation up the tree is trivial; disaggregation after the fact is impossible. If you track all your dividends in a single &lt;code&gt;Income:Dividends&lt;/code&gt; account, it’s easy to know “how much dividends did I earn total?”. But if you want to know “what was my AAPL dividend yield this year?”, you’re out of luck. Track at the leaf (&lt;code&gt;Income:IB:AAPL:Dividends&lt;/code&gt;), and you can answer both questions.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Notation&lt;/head&gt;
    &lt;p&gt;With our accounts defined, we can now record the actual movement of assets. We use &lt;code&gt;{}&lt;/code&gt; to denote cost (what we paid per unit) and &lt;code&gt;@&lt;/code&gt; to denote price (what the unit is worth now).&lt;/p&gt;
    &lt;p&gt;Example 1: Buying Stock Exchanging 1850 USD for 10 shares of Apple.&lt;/p&gt;
    &lt;code&gt;2024-01-10 * "BUY AAPL"
  Assets:Lalit:US:IB:Brokerage:AAPL      10 AAPL {185.00 USD} @ 185.00 USD
  Assets:Lalit:US:IB:Brokerage:USD   -1850.00 USD
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;{185.00 USD}&lt;/code&gt; is the cost basis and the &lt;code&gt;@ 185.00 USD&lt;/code&gt; is the price. Beancount uses the cost basis to track lots and calculate capital gains.&lt;/p&gt;
    &lt;p&gt;Note: Cost basis rules depend heavily on where you are. In the US, you track cost basis of individual lots. In the UK, we have special “Section 104” pooling rules.11 I discuss this more in Chapter 5.&lt;/p&gt;
    &lt;p&gt;Example 2: Buying Currency Exchanging 950 GBP for 98,000 INR.&lt;/p&gt;
    &lt;code&gt;2024-03-02 * "Wise" "GBP to INR"
  Assets:Lalit:UK:Wise:INR            98000.00 INR @@ 950.00 GBP
  Assets:Lalit:UK:Wise:GBP             -950.00 GBP
&lt;/code&gt;
    &lt;p&gt;In the second example, &lt;code&gt;@@&lt;/code&gt; specifies the total cost rather than the per-unit cost.&lt;/p&gt;
    &lt;p&gt;Example 3: Selling Stock Selling 5 shares of Apple at $190 (bought at $185).&lt;/p&gt;
    &lt;code&gt;2024-01-30 * "SELL AAPL"
  Assets:Lalit:US:IB:Brokerage:AAPL      -5 AAPL {185.00 USD} @ 190.00 USD
  Assets:Lalit:US:IB:Brokerage:USD     950.00 USD
  Income:Lalit:US:IB:Brokerage:AAPL:Capital-Gains  -25.00 USD
&lt;/code&gt;
    &lt;p&gt;Here we specify the lot we’re selling (&lt;code&gt;{185.00 USD}&lt;/code&gt;) and the price we’re selling it at (&lt;code&gt;@ 190.00 USD&lt;/code&gt;). The difference is the capital gain (or loss).&lt;/p&gt;
    &lt;p&gt;But the principle is identical: &lt;code&gt;Assets:Wise:INR&lt;/code&gt; and &lt;code&gt;Assets:Brokerage:AAPL&lt;/code&gt; are just accounts holding commodities.&lt;/p&gt;
    &lt;head rend="h4"&gt;Automation&lt;/head&gt;
    &lt;p&gt;Investments are very different from normal accounts in that they can be fully automated. No categorization needed: a buy is a buy, a dividend is a dividend. You don’t have new merchants to worry about.&lt;/p&gt;
    &lt;p&gt;This means you can skip beancount-import’s web UI and run your beangulp importers directly with output going straight to the ledger. To help inspire you, I’ve open-sourced my personal collection of importers (IB, Vanguard, Schwab, and more) in the beancount-lalitm repo.&lt;/p&gt;
    &lt;head rend="h4"&gt;Handling Account Sprawl&lt;/head&gt;
    &lt;p&gt;However, one annoyance is that creating those granular accounts for every single stock (&lt;code&gt;...:AAPL:Dividends&lt;/code&gt;, &lt;code&gt;...:AAPL:Commissions&lt;/code&gt;, etc.) is tedious. To solve this, I wrote the ancillary_accounts plugin. Instead of manual account creation, you just add metadata to the main holding account:&lt;/p&gt;
    &lt;code&gt;2023-02-01 open Assets:Lalit:US:IB:Brokerage:BAC    BAC
  ancillary_commission_currency: "USD"
  ancillary_distribution_currency: "USD"
  ancillary_withholding_tax_currency: "USD"
  ancillary_capital_gains_currency: "USD"
&lt;/code&gt;
    &lt;p&gt;The plugin automatically generates the corresponding income and expense accounts for you.&lt;/p&gt;
    &lt;head rend="h4"&gt;Corporate Actions&lt;/head&gt;
    &lt;p&gt;I also use a plugin called stock_split to handle corporate actions. It retroactively adjusts historical transactions when a stock splits, keeping quantities and prices consistent with post-split values so your charts don’t show a sudden, fake drop in value.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Value of Things (Prices)&lt;/head&gt;
    &lt;p&gt;We have the quantities (10 AAPL, 98,000 INR), but to calculate a single “Net Worth” number, we need to know what they are worth in your home currency. This requires prices for both:&lt;/p&gt;
    &lt;code&gt;; chapter-4/src/prices.beancount
2024-01-10 price AAPL  185.50 USD  ; Stock price in USD
2024-01-10 price USD   0.79 GBP    ; Currency price in GBP
&lt;/code&gt;
    &lt;p&gt;I automate this using a daily CI job. A script fetches the latest stock prices and forex rates from AlphaVantage and commits them to &lt;code&gt;prices.beancount&lt;/code&gt;. You can find the script here.&lt;/p&gt;
    &lt;p&gt;In practice, I actually have three price files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;prices.beancount&lt;/code&gt;- auto-fetched daily for as many securities as possible.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;prices-manual.beancount&lt;/code&gt;- for securities without automatic feeds (like some pension funds). I input these manually once a month.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;prices-delisted.beancount&lt;/code&gt;- historical prices for securities no longer trading. This saves me from making API calls which would fail anyway.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;The Payoff&lt;/head&gt;
    &lt;p&gt;With this data, Fava comes alive. To see the full potential of these reports, I’ve included a &lt;code&gt;demo/&lt;/code&gt; folder in the companion repo with 2+ years of history. Run &lt;code&gt;./scripts/quickstart.sh demo&lt;/code&gt; and you’ll see the payoff.&lt;/p&gt;
    &lt;p&gt;The Holdings page now shows your positions with their cost basis and current market value.&lt;/p&gt;
    &lt;p&gt;The Holdings report automatically calculates the market value of your assets using live price data.&lt;/p&gt;
    &lt;p&gt;In the demo environment, you can also see how plugins like fava-dashboards build custom visualizations. The plugin uses beanquery (Beancount’s SQL-like query language) to fetch data and renders interactive charts. It’s the best way to track long-term trends and asset allocation at a glance.&lt;/p&gt;
    &lt;p&gt;Custom dashboards (shown here using the demo data) allow you to track long-term trends and asset allocation at a glance.&lt;/p&gt;
    &lt;p&gt;And with fava-portfolio-returns, you can calculate your true Time-Weighted Return (TWR) and Internal Rate of Return (IRR) to see if you’re actually beating the market. It accounts for cash flows properly, so adding money mid-year doesn’t inflate your returns.&lt;/p&gt;
    &lt;p&gt;The portfolio returns plugin (using the demo data) calculates your actual investment performance, net of cash flows.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exit ramp&lt;/head&gt;
    &lt;p&gt;You now have a system that tracks your entire financial world: from the coffee you bought this morning to the capital gains in your brokerage account. For most people, this is a complete solution.&lt;/p&gt;
    &lt;p&gt;However, as you collect more data, you’ll find you want to look at it in different ways. Maybe you want a simplified view for daily use and a detailed one for tax season. Or maybe you’re not the only person in your household. In the final chapters, we’ll see how to scale this system to handle multiple views and multiple people.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: Multiple Views&lt;/head&gt;
    &lt;p&gt;Day-to-day, I want a simple view of my finances. Take-home pay as a single number, investments without tax calculations cluttering the screen. But at tax time, I need detail. Every payslip line item and capital gains calculated the way HMRC wants them. Recording the same transaction twice would be maintenance hell. So instead, I extract multiple views from a single journal.&lt;/p&gt;
    &lt;p&gt;I think of these as “lenses” on the data. Some lenses aggregate: rolling up transactions into balances, summaries, or dashboards. Others transform: collapsing detail you don’t need day-to-day, or expanding it when you do. Both read from the same source files; nothing is duplicated.&lt;/p&gt;
    &lt;head rend="h4"&gt;Aggregated views&lt;/head&gt;
    &lt;p&gt;Fava is great for interactive exploration, but I also want textual snapshots I can version control. I have a script that generates daily summaries showing account balances, and a CI workflow that commits them automatically. In my setup this runs on a self-hosted Gitea instance on hardware I control, so the raw ledger never leaves machines I own. If you prefer, you can keep everything local-only or push to an encrypted remote; GitHub Actions works the same way if you’re comfortable with that trade-off. This gives me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A record of how balances changed day to day&lt;/item&gt;
      &lt;item&gt;An immutable snapshot at tax time of what the system showed&lt;/item&gt;
      &lt;item&gt;Git as audit trail: “What was my net worth on March 15th 2023?” is answerable with &lt;code&gt;git checkout&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The key script is archive.py. It uses the beanquery library to write SQL scripts over your journal and generate textual reports:&lt;/p&gt;
    &lt;code&gt;# Generate balance sheet in GBP
sql = '''
  SELECT account,
         round(sum(number(convert(value(position, '2024-12-31'), 'GBP', '2024-12-31'))), 2) as value
  FROM OPEN ON 2024-01-01 CLOSE ON 2024-12-31 CLEAR
  GROUP BY account
  HAVING round(sum(number), 2) != 0
  ORDER BY account;
'''
&lt;/code&gt;
    &lt;p&gt;I run this for each calendar year and tax year, generating files like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;networth.txt&lt;/code&gt;- Single-line net worth in each currency&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;balance-sheet.txt&lt;/code&gt;- Net worth breakdown by account&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;holdings.txt&lt;/code&gt;- Investment positions with cost basis and market value&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s what &lt;code&gt;networth.txt&lt;/code&gt; looks like:&lt;/p&gt;
    &lt;code&gt;     gbp            usd
-------------  -------------
 15978.42 GBP   19973.02 USD
&lt;/code&gt;
    &lt;p&gt;This is the concrete “one number I trust”: a single net-worth snapshot in my reporting currency, generated from the full ledger and price data.&lt;/p&gt;
    &lt;p&gt;And &lt;code&gt;holdings.txt&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;account                           units  curr  avg_cost  price  book_val  mkt_val
---------------------------------  -----  ----  --------  -----  --------  -------
Assets:Lalit:UK:HSBC:Current:GBP  4914.50  GBP      1.00   1.00   4914.50  4914.50
Assets:Lalit:UK:Vanguard:ISA:VWRL   20.00  VWRL    96.00  97.50   1920.00  1950.00
Assets:Lalit:US:IB:Brokerage:AAPL    5.00  AAPL   146.15 150.40    730.75   752.00
&lt;/code&gt;
    &lt;p&gt;My Gitea workflow is very simple too:&lt;/p&gt;
    &lt;code&gt;on:
  schedule:
    - cron: '00 7 * * *'  # Run daily at 7am

jobs:
  update:
    steps:
      - run: uv run scripts/archive.py outputs/ journal.beancount 2024-01-01 2024-12-31
      - run: git commit -am "Regen reports" &amp;amp;&amp;amp; git push
&lt;/code&gt;
    &lt;head rend="h4"&gt;Transformed views&lt;/head&gt;
    &lt;p&gt;Sometimes I want to change how transactions work fundamentally. This is a more advanced technique: while Aggregated views read data, Transformed views temporarily rewrite it in memory to simplify reality.&lt;/p&gt;
    &lt;p&gt;I have three transformed views, each for a different purpose:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Net - my daily driver. Collapses payslip details into a single take-home number.&lt;/item&gt;
      &lt;item&gt;Gross - breaks down payslip line items for tax time analysis.&lt;/item&gt;
      &lt;item&gt;CGT - a view that includes a “virtual currency” tracking capital gains the way my tax authority calculates them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The linchpin is the &lt;code&gt;rename_accounts&lt;/code&gt; plugin. It lets me keep one copy of all transactions and rename accounts on the fly to show or hide detail.&lt;/p&gt;
    &lt;p&gt;Gross vs net payslip&lt;/p&gt;
    &lt;p&gt;Let me start with the simpler example. In gross view, my payslip shows every line item:&lt;/p&gt;
    &lt;code&gt;2024-01-25 * "Google" "January salary"
  Assets:Lalit:UK:HSBC:Current:GBP           3500.00 GBP  ; Take-home pay
  Income:Lalit:UK:Google:Salary           -5000.00 GBP  ; Gross salary
  Expenses:Lalit:UK:Google:Income-Tax        1000.00 GBP  ; Tax withheld
  Expenses:Lalit:UK:Google:National-Insurance 400.00 GBP  ; NI contribution
  Expenses:Lalit:UK:Google:Pension            100.00 GBP  ; Pension contribution
&lt;/code&gt;
    &lt;p&gt;Useful for analyzing my tax situation. But day-to-day, I don’t care about the breakdown. In net view, the same transaction collapses:&lt;/p&gt;
    &lt;code&gt;; chapter-5/journal-net.beancount
include "journal.beancount"

plugin "beancount_reds_plugins.rename_accounts.rename_accounts" "{
  'Income:Lalit:UK:Google:Salary': 'Income:Lalit:UK:Google:Net-Income',
  'Income:Lalit:UK:Google:Bonus': 'Income:Lalit:UK:Google:Net-Income',
  'Expenses:Lalit:UK:Google:Income-Tax': 'Income:Lalit:UK:Google:Net-Income',
  'Expenses:Lalit:UK:Google:National-Insurance': 'Income:Lalit:UK:Google:Net-Income',
  'Expenses:Lalit:UK:Google:Pension': 'Income:Lalit:UK:Google:Net-Income',
}"
&lt;/code&gt;
    &lt;p&gt;Because Income is stored as a negative number and Expenses as positive numbers, merging them into one account mathematically subtracts the tax from the gross pay, leaving just the net amount. The difference should be obvious if I compare the Income Statements on Fava:&lt;/p&gt;
    &lt;p&gt;The Gross view is essential for tax season, but the detailed line items for taxes and insurance often dwarf your actual spending data.&lt;/p&gt;
    &lt;p&gt;The Net view collapses those details into a single take-home number, making your everyday expenses much easier to analyze.&lt;/p&gt;
    &lt;head rend="h4"&gt;Tracking capital gains for tax&lt;/head&gt;
    &lt;p&gt;We can use this same renaming technique to handle a much more complex beast: Capital Gains Tax.&lt;/p&gt;
    &lt;p&gt;Your broker reports one gain number, but your tax authority may calculate another. In the UK, where I live, we have specific rules like “Section 104 pooling” (averaging cost basis) and “bed-and-breakfasting” (wash sale rules).&lt;/p&gt;
    &lt;p&gt;To handle this, I use a virtual currency called &lt;code&gt;CGT-GBP&lt;/code&gt; that represents “pounds of gain HMRC cares about”. My plugin, &lt;code&gt;uk_cgt_lots&lt;/code&gt;, calculates this number and automatically appends a self-balancing pair of Equity postings to the original sale transaction:&lt;/p&gt;
    &lt;code&gt;2024-06-15 * "SELL AAPL"
  Assets:Lalit:US:IB:Brokerage:AAPL           -10 AAPL {150.00 USD} @ 175.00 USD
  Assets:Lalit:US:IB:Brokerage:USD            1750.00 USD
  Income:Lalit:US:IB:Brokerage:AAPL:Capital-Gains  -250.00 USD
  ; The following postings are generated by the uk_cgt_lots plugin:
  Equity:Taxable-Capital-Gains              195.00 CGT-GBP
  Equity:Taxable-Capital-Gains-Placeholder -195.00 CGT-GBP
&lt;/code&gt;
    &lt;p&gt;Since both legs are in &lt;code&gt;Equity&lt;/code&gt;, they remain invisible on my Income Statement in my daily “Net” view. In fact, I use &lt;code&gt;rename_accounts&lt;/code&gt; to collapse them into a single account so they net to zero:&lt;/p&gt;
    &lt;code&gt;; journal-net.beancount
plugin "beancount_reds_plugins.rename_accounts.rename_accounts" "{
  'Equity:Taxable-Capital-Gains-Placeholder' : 'Equity:Taxable-Capital-Gains',
}"
&lt;/code&gt;
    &lt;p&gt;But when I want to see my tax liability, I switch to the CGT View. This view renames the “Placeholder” to a visible Revenue account:&lt;/p&gt;
    &lt;code&gt;; journal-cgt.beancount
plugin "beancount_reds_plugins.rename_accounts.rename_accounts" "{
  'Equity:Taxable-Capital-Gains-Placeholder' : 'Revenues:Taxable-Capital-Gains',
}"
&lt;/code&gt;
    &lt;p&gt;Now, the -195.00 becomes Revenue, which shows up as profit on my tax report. The matching +195.00 remains in Equity. This allows me to have “Schrödinger’s Capital Gains”: they exist for the taxman, but not for my daily budget, all controlled by which view I load.&lt;/p&gt;
    &lt;p&gt;I don’t calculate the tax owed since that’s too complicated with allowances, rates, and bands; the system just tracks the gains. At tax time, I sum up the CGT-GBP balance and do the actual calculation on the tax form.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exit ramp&lt;/head&gt;
    &lt;p&gt;By separating your “source of truth” from your “lenses,” you get a system that grows with you. You can add new plugins or virtual currencies to solve specific problems (like taxes) without ever touching the raw transactions you’ve already imported.&lt;/p&gt;
    &lt;p&gt;In the final chapter, we’ll see the ultimate application of this: combining two people’s financial lives into one unified view.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Two People, One Number&lt;/head&gt;
    &lt;p&gt;I got married at the start of the year, which brought a fundamental change to how I manage my finances. While many couples use joint accounts, we prefer to keep our individual accounts and perform occasional “normalization” transfers. However, we view our combined resources as shared household wealth.&lt;/p&gt;
    &lt;p&gt;This created a reporting paradox that I had to solve in Beancount.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Paradox&lt;/head&gt;
    &lt;p&gt;When I transfer £500 to my wife for my share of the bills, two things are true simultaneously:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Individual Truth: From my perspective, £500 is “gone” (an expense). From her perspective, £500 has “arrived” (income).&lt;/item&gt;
      &lt;item&gt;The Household Truth: For the household, the net worth hasn’t changed. Money just moved from the left pocket to the right pocket.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a traditional system, you usually have to pick one truth. In Beancount, we can have both.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Composable Architecture&lt;/head&gt;
    &lt;p&gt;To solve this, I treat the household as a composable system of three distinct entities: Me, Her, and Shared Definitions. We use Beancount’s &lt;code&gt;include&lt;/code&gt; feature to build the specific “lens” we need at any given moment:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lalit’s View = Shared Definitions + Lalit’s Transactions&lt;/item&gt;
      &lt;item&gt;Wife’s View = Shared Definitions + Wife’s Transactions&lt;/item&gt;
      &lt;item&gt;Household View = Shared Definitions + Lalit’s Transactions + Wife’s Transactions + Translation Logic&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, the household view literally just includes the other files (alongside the translation logic we’ll see in a moment):&lt;/p&gt;
    &lt;code&gt;; chapter-6/total/journal-net.beancount
include "../common/src/commodities.beancount"
include "../common/src/accounts.beancount"

include "../lalit/src/journal.beancount"
include "../wife/src/journal.beancount"

; ... Translation Logic follows
&lt;/code&gt;
    &lt;head rend="h4"&gt;Implementation: The Directory Structure&lt;/head&gt;
    &lt;p&gt;This architecture is reflected directly in the repository structure:&lt;/p&gt;
    &lt;code&gt;chapter-6/
├── common/                    # Shared configuration
│   └── src/
│       ├── accounts.beancount   # Shared expense accounts (e.g. Expenses:Groceries)
│       └── commodities.beancount
├── lalit/                     # My stuff
│   ├── src/                   # My ledger
│   └── data/                  # My statement PDFs/CSVs
├── wife/                      # Wife's stuff
│   ├── src/                   # Her ledger
│   └── data/                  # Her statement PDFs/CSVs
└── total/                     # Combined household view
    └── journal-net.beancount  # Entry point with Translation Logic
&lt;/code&gt;
    &lt;head rend="h4"&gt;The Rules of Engagement&lt;/head&gt;
    &lt;p&gt;For this to work without constant manual adjustment, we follow two simple rules:&lt;/p&gt;
    &lt;p&gt;Rule 1: Assets and Liabilities are Private. Bank accounts always include the person’s name in the path (e.g., &lt;code&gt;Assets:Lalit:HSBC&lt;/code&gt; or &lt;code&gt;Assets:Wife:HSBC&lt;/code&gt;). We never use a generic &lt;code&gt;Assets:Checking&lt;/code&gt; account. Legal ownership of the cash always matters.&lt;/p&gt;
    &lt;p&gt;Rule 2: Expenses are Public. Shared expenses like groceries or electricity use a generic name without a person prefix.&lt;/p&gt;
    &lt;code&gt;; chapter-6/common/src/accounts.beancount
2024-01-01 open Expenses:Groceries                   GBP
&lt;/code&gt;
    &lt;p&gt;When I buy groceries, I record it in my ledger using the shared account. We don’t track “who owes what” for individual grocery runs; we just track that the household spent the money. We accept that we lose the ability to split shared expenses by person, but the gain in simplicity is worth it.&lt;/p&gt;
    &lt;head rend="h4"&gt;The “Magic”: Solving the Transfer Paradox&lt;/head&gt;
    &lt;p&gt;Finally, we use the &lt;code&gt;rename_accounts&lt;/code&gt; plugin in the &lt;code&gt;total/&lt;/code&gt; folder to resolve the transfer paradox.&lt;/p&gt;
    &lt;p&gt;In my ledger, a transfer looks like a simple expense:&lt;/p&gt;
    &lt;code&gt;; chapter-6/lalit/src/transactions.beancount
2024-01-20 * "Transfer to Wife"
  Expenses:Lalit:Transfers:Wife       500.00 GBP
  Assets:Lalit:UK:HSBC:Current:GBP
&lt;/code&gt;
    &lt;p&gt;In her ledger, it looks like income:&lt;/p&gt;
    &lt;code&gt;; chapter-6/wife/src/transactions.beancount
2024-01-20 * "Transfer from Lalit"
  Assets:Wife:UK:HSBC:Current:GBP     500.00 GBP
  Income:Wife:Transfers:Lalit
&lt;/code&gt;
    &lt;p&gt;The “Translation Logic” in the combined view renames these into a shared transit account:&lt;/p&gt;
    &lt;code&gt;; chapter-6/total/journal-net.beancount
plugin "beancount_reds_plugins.rename_accounts.rename_accounts" "{
  'Expenses:Lalit:Transfers:Wife': 'Assets:Household:Transfers:Internal',
  'Income:Wife:Transfers:Lalit': 'Assets:Household:Transfers:Internal',
}"
&lt;/code&gt;
    &lt;p&gt;Now, when Fava loads the combined view, it sees £500 leave my account and enter &lt;code&gt;Assets:Household:Transfers:Internal&lt;/code&gt;, and then £500 leave that same account and enter her bank account. The transit account nets to zero, and our household net worth remains unchanged.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Result&lt;/head&gt;
    &lt;p&gt;This setup gives us the best of both worlds. I can maintain my own financial autonomy and see my personal “runway,” while we can simultaneously monitor our combined progress toward shared goals.&lt;/p&gt;
    &lt;p&gt;The final result: a unified household view that tracks legal ownership without sacrificing the "One Number" net worth total.&lt;/p&gt;
    &lt;p&gt;That’s the full system (see chapter-6 for the complete multi-person structure). But how do I actually use it week to week?&lt;/p&gt;
    &lt;head rend="h2"&gt;The weekly ritual&lt;/head&gt;
    &lt;p&gt;Now here’s how I keep it current: the “20 minutes a week” I mentioned at the start:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Getting statements: During the week, banks email me saying a statement is available. Some attach PDFs directly; others require a login. Either way, I snooze the emails (I use inbox zero) until the weekend. For my wife’s accounts, I nudge her once a month and she drops stuff in a shared Drive folder.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Running imports: On the weekend, I work through my snoozed emails. Note that I’m not updating every single account every week. I only download statements for the 3-4 accounts that saw activity; long-term investments often just get a monthly or quarterly check-in. I move each file to the correct&lt;/p&gt;&lt;code&gt;data/&lt;/code&gt;subfolder for that institution (e.g.,&lt;code&gt;data/hsbc-uk-current/&lt;/code&gt;). My importer pipeline automatically runs&lt;code&gt;pdftotext&lt;/code&gt;to extract text so the parsers can read it.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Categorizing: I launch beancount-import, which opens a web UI in my browser:&lt;/p&gt;
        &lt;code&gt;python -m beancount_import.webserver --journal lalit/journal-net.beancount&lt;/code&gt;
        &lt;p&gt;As I mentioned before, most transactions auto-categorize and I’m just hitting Enter: I buy groceries from the same place, pay my hosting costs to the same provider etc. New merchants do need some manual work, but it’s a matter of typing a few characters and again pressing Enter.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Formatting and checking: I run&lt;/p&gt;&lt;code&gt;bean-format&lt;/code&gt;(a Beancount utility that normalizes indentation and aligns amounts) to keep my transactions file tidy. This makes git diffs cleaner. Then I open Fava for a quick sanity check:&lt;code&gt;fava lalit/journal-net.beancount&lt;/code&gt;&lt;p&gt;Are transfer accounts zeroed out? Do expenses look legit? How are investments doing? If it all checks out, commit and push.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That’s it. I try to stick to doing this every week, but sometimes I’m on holiday or just have other commitments. In that case, it’s 40 minutes every two weeks. The system is forgiving; I’m never behind for too long.&lt;/p&gt;
    &lt;p&gt;I also have some automation helping me out: during the week, I have a CI workflow that runs daily, regenerates summaries, and commits them. Whenever I want, I can check the repo and see what the numbers look like. I particularly like this because I can easily see the before/after numbers in a single file, so I can spot check “does this make sense”. And of course at any time, I can also open Fava if I want to go a bit deeper.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;That 2021 tax disaster feels like a lifetime ago. What started as “there must be a better way” became a system I actually trust. One number, always current, completely under my control.&lt;/p&gt;
    &lt;p&gt;The specifics will evolve as life changes and tools improve, but three principles have held for years now. I expect them to hold for decades:&lt;/p&gt;
    &lt;p&gt;Double-entry everywhere. Every transaction balances. Money never appears from nowhere or vanishes into nothing. When something doesn’t add up, you know immediately.&lt;/p&gt;
    &lt;p&gt;Plain text as the source of truth. Your financial history lives in files you can read, diff, grep, and version control. No vendor lock-in, no opaque databases, no trusting a third party with your data.&lt;/p&gt;
    &lt;p&gt;Track at the leaf. Record transactions at the most granular level that makes sense. You can always aggregate up (&lt;code&gt;Income:Dividends&lt;/code&gt; from &lt;code&gt;Income:IB:AAPL:Dividends&lt;/code&gt;), but you can never disaggregate down. Capture the detail; collapse it later with views.&lt;/p&gt;
    &lt;p&gt;Finance systems are deeply personal. This post isn’t meant to say this is the system everyone should use, just what’s worked for me over several years.&lt;/p&gt;
    &lt;p&gt;Each chapter here could be its own post, so if you want me to go deeper on imports, investments, or the multi-person setup, let me know!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46463407</guid><pubDate>Fri, 02 Jan 2026 10:25:11 +0000</pubDate></item><item><title>2025 Letter</title><link>https://danwang.co/</link><description>&lt;doc fingerprint="bf3891178fc5067d"&gt;
  &lt;main&gt;
    &lt;p&gt;(This piece is my year in review; I skipped a letter last year)&lt;/p&gt;
    &lt;p&gt;One way that Silicon Valley and the Communist Party resemble each other is that both are serious, self-serious, and indeed, completely humorless.&lt;/p&gt;
    &lt;p&gt;If the Bay Area once had an impish side, it has gone the way of most hardware tinkerers and hippie communes. Which of the tech titans are funny? In public, they tend to speak in one of two registers. The first is the blandly corporate tone we’ve come to expect when we see them dragged before Congressional hearings or fireside chats. The second leans philosophical, as they compose their features into the sort of reverie appropriate for issuing apocalyptic prophecies on AI. Sam Altman once combined both registers at a tech conference when he said: “I think that AI will probably, most likely, sort of lead to the end of the world. But in the meantime, there will be great companies created with serious machine learning.” Actually that was pretty funny.&lt;/p&gt;
    &lt;p&gt;It wouldn’t be news to the Central Committee that only the paranoid survive. The Communist Party speaks in the same two registers as the tech titans. The po-faced men on the Politburo tend to make extraordinarily bland speeches, laced occasionally with a murderous warning against those who cross the party’s interests. How funny is the big guy? We can take a look at an official list of Xi Jinping’s jokes, helpfully published by party propagandists. These wisecracks include the following: “On an inspection tour to Jiangsu, Xi quipped that the true measure of water cleanliness is whether the mayor would dare to swim in the water.” Or try this reminiscence that Xi offered on bad air quality: “The PM2.5 back then was even worse than it is now; I used to joke that it was PM250.” Yes, such a humorous fellow is the general secretary.1&lt;/p&gt;
    &lt;p&gt;It’s nearly as dangerous to tweet a joke about a top VC as it is to make a joke about a member of the Central Committee. People who are dead serious tend not to embody sparkling irony. Yet the Communist Party and Silicon Valley are two of the most powerful forces shaping our world today. Their initiatives increase their own centrality while weakening the agency of whole nation states. Perhaps they are successful because they are remorseless.&lt;/p&gt;
    &lt;p&gt;Earlier this year, I moved from Yale to Stanford. The sun and the dynamism of the west coast have drawn me back. I found a Bay Area that has grown a lot weirder since I lived there a decade ago. In 2015, people were mostly working on consumer apps, cryptocurrencies, and some business software. Though it felt exciting, it looks in retrospect like a more innocent, even a more sedate, time. Today, AI dictates everything in San Francisco while the tech scene plays a much larger political role in the United States. I can’t get over how strange it all feels. In the midst of California’s natural beauty, nerds are trying to build God in a Box; meanwhile, Peter Thiel hovers in the background presenting lectures on the nature of the Antichrist. This eldritch setting feels more appropriate for a Gothic horror novel than for real life.&lt;/p&gt;
    &lt;p&gt;Before anyone gets the wrong idea, I want to say that I am rooting for San Francisco. It’s tempting to gawk at the craziness of the culture, as much of the east coast media tends to do. Yes, one can quickly find people who speak with the conviction of a cultist; no, I will not inject the peptides proffered by strangers. But there’s more to the Bay Area than unusual health practices. It is, after all, a place that creates not only new products, but also new modes of living. I’m struck that some east coast folks insist to me that driverless cars can’t work and won’t be accepted, even as these vehicles populate the streets of the Bay Area. Coverage of Silicon Valley increasingly reminds me of coverage of China, where a legacy media reporter might parachute in, write a dispatch on something that looks deranged, and leave without moving past caricature.&lt;/p&gt;
    &lt;p&gt;I enjoy San Francisco more than when I was younger because I now better appreciate what makes it work. I believe that Silicon Valley possesses plenty of virtues. To start, it is the most meritocratic part of America. Tech is so open towards immigrants that it has driven populists into a froth of rage. It remains male-heavy and practices plenty of gatekeeping. But San Francisco better embodies an ethos of openness relative to the rest of the country. Industries on the east coast — finance, media, universities, policy — tend to more carefully weigh name and pedigree. Young scientists aren’t told they ought to keep their innovations incremental and their attitude to hierarchy duly deferential, as they might hear in Boston. A smart young person could achieve much more over a few years in SF than in DC. People aren’t reminiscing over some lost golden age that took place decades ago, as New Yorkers in media might do.&lt;/p&gt;
    &lt;p&gt;San Francisco is forward looking and eager to try new ideas. Without this curiosity, it wouldn’t be able to create whole new product categories: iPhones, social media, large language models, and all sorts of digital services. For the most part, it’s positive that tech values speed: quick product cycles, quick replies to email. Past success creates an expectation that the next technological wave will be even more exciting. It’s good to keep building the future, though it’s sometimes absurd to hear someone pivot, mid-breath, from declaring that salvation lies in the blockchain to announcing that AI will solve everything.&lt;/p&gt;
    &lt;p&gt;People like to make fun of San Francisco for not drinking; well, that works pretty well for me. I enjoy board games and appreciate that it’s easier to find other players. I like SF house parties, where people take off their shoes at the entrance and enter a space in which speech can be heard over music, which feels so much more civilized than descending into a loud bar in New York. It’s easy to fall into a nerdy conversation almost immediately with someone young and earnest. The Bay Area has converged on Asian-American modes of socializing (though it lacks the emphasis on food). I find it charming that a San Francisco home that is poorly furnished and strewn with pizza boxes could be owned by a billionaire who can’t get around to setting up a bed for his mattress.&lt;/p&gt;
    &lt;p&gt;There’s still no better place for a smart, young person to go in the world than Silicon Valley. It adores the youth, especially those with technical skill and the ability to grind. Venture capitalists are chasing younger and younger founders: the median age of the latest Y Combinator cohort is only 24, down from 30 just three years ago. My favorite part of Silicon Valley is the cultivation of community. Tech founders are a close-knit group, always offering help to each other, but they circulate actively amidst the broader community too. (The finance industry in New York by contrast practices far greater secrecy.) Tech has organizations I think of as internal civic institutions that try to build community. They bring people together in San Francisco or retreats north of the city, bringing together young people to learn from older folks.&lt;/p&gt;
    &lt;p&gt;Silicon Valley also embodies a cultural tension. It is playing with new ideas while being open to newcomers; at the same time, it is a self-absorbed place that doesn’t think so much about the broader world. Young people who move to San Francisco already tend to be very online. They know what they’re signing up for. If they don’t fit in after a few years, they probably won’t stick around. San Francisco is a city that absorbs a lot of people with similar ethics, which reinforces its existing strengths and weaknesses.&lt;/p&gt;
    &lt;p&gt;Narrowness of mind is something that makes me uneasy about the tech world. Effective altruists, for example, began with sound ideas like concern for animal welfare as well as cost-benefit analyses for charitable giving. But these solid premises have launched some of its members towards intellectual worlds very distant from moral intuitions that most people hold; they’ve also sent a few into jail. The well-rounded type might struggle to stand out relative to people who are exceptionally talented in a technical domain. Hedge fund managers have views about the price of oil, interest rates, a reliably obscure historical episode, and a thousand other things. Tech titans more obsessively pursue a few ideas — as Elon Musk has on electric vehicles and space launches — rather than developing a robust model of the world.&lt;/p&gt;
    &lt;p&gt;So the 20-year-olds who accompanied Mr. Musk into the Department of Government Efficiency did not, I would say, distinguish themselves with their judiciousness. The Bay Area has all sorts of autistic tendencies. Though Silicon Valley values the ability to move fast, the rest of society has paid more attention to instances in which tech wants to break things. It is not surprising that hardcore contingents on both the left and the right have developed hostility to most everything that emerges from Silicon Valley.&lt;/p&gt;
    &lt;p&gt;There’s a general lack of cultural awareness in the Bay Area. It’s easy to hear at these parties that a person’s favorite nonfiction book is Seeing Like a State while their aspirationally favorite novel is Middlemarch. Silicon Valley often speaks in strange tongues, starting podcasts and shows that are popular within the tech world but do not travel far beyond the Bay Area. Though San Francisco has produced so much wealth, it is a relative underperformer in the national culture. Indie movie theaters keep closing down while all sorts of retail and art institutions suffer from the crumminess of downtown. The symphony and the opera keep cutting back on performances — after Esa-Pekka Salonen quit the directorship of the symphony, it hasn’t been able to name a successor. Wealthy folks in New York and LA have, for generations, pumped money into civic institutions. Tech elites mostly scorn traditional cultural venues and prefer to fund the next wave of technology instead.&lt;/p&gt;
    &lt;p&gt;One of the things I like about the finance industry is that it might be better at encouraging diverse opinions. Portfolio managers want to be right on average, but everyone is wrong three times a day before breakfast. So they relentlessly seek new information sources; consensus is rare, since there are always contrarians betting against the rest of the market. Tech cares less for dissent. Its movements are more herdlike, in which companies and startups chase one big technology at a time. Startups don’t need dissent; they want workers who can grind until the network effects kick in. VCs don’t like dissent, showing again and again that many have thin skins. That contributes to a culture I think of as Silicon Valley’s soft Leninism. When political winds shift, most people fall in line, most prominently this year as many tech voices embraced the right.&lt;/p&gt;
    &lt;p&gt;The two most insular cities I’ve lived in are San Francisco and Beijing. They are places where people are willing to risk apocalypse every day in order to reach utopia. Though Beijing is open only to a narrow slice of newcomers — the young, smart, and Han — its elites must think about the rest of the country and the rest of the world. San Francisco is more open, but when people move there, they stop thinking about the world at large. Tech folks may be the worst-traveled segment of American elites. People stop themselves from leaving in part because they can correctly claim to live in one of the most naturally beautiful corners of the world, in part because they feel they should not tear themselves away from inventing the future. More than any other topic, I’m bewildered by the way that Silicon Valley talks about AI.&lt;/p&gt;
    &lt;p&gt;Hallucinating the end of history&lt;/p&gt;
    &lt;p&gt;While critics of AI cite the spread of slop and rising power bills, AI’s architects are more focused on its potential to produce surging job losses. Anthropic chief Dario Amodei takes pains to point out that AI could push the unemployment rate to 20 percent by eviscerating white-collar work.2 I wonder whether this message is helping to endear his product to the public.&lt;/p&gt;
    &lt;p&gt;The most-read essay from Silicon Valley this year was AI 2027. The five authors, who come from the AI safety world, outline a scenario in which superintelligence wakes up in 2027; a decade later, it decides to annihilate humanity with biological weapons. My favorite detail in the report is that humanity would persist in a genetically modified form, after the AI reconstructs creatures that are “to humans what corgis are to wolves.” It’s hard to know what to make of this document, because the authors keep tucking important context into footnotes, repeatedly saying they do not endorse a prediction. Six months after publication, they stated that their timelines were lengthening, but even at the start their median forecast for the arrival of superintelligence was later than 2027. Why they put that year in their title remains beyond me.&lt;/p&gt;
    &lt;p&gt;It’s easy for conversations in San Francisco to collapse into AI. At a party, someone told me that we no longer have to worry about the future of manufacturing. Why not? “Because AI will solve it for us.” At another, I heard someone say the same thing about climate change. One of the questions I receive most frequently anywhere is when Beijing intends to seize Taiwan. But only in San Francisco do people insist that Beijing wants Taiwan for its production of AI chips. In vain do I protest that there are historical and geopolitical reasons motivating the desire, that chip fabs cannot be violently seized, and anyway that Beijing has coveted Taiwan for approximately seven decades before people were talking about AI.&lt;/p&gt;
    &lt;p&gt;Silicon Valley’s views on AI made more sense to me after I learned the term “decisive strategic advantage.” It was first used by Nick Bostrom’s 2014 book Superintelligence, which defined it as a technology sufficient to achieve “complete world domination.” How might anyone gain a DSA? A superintelligence might develop cyber advantages that cripple the adversary’s command-and-control capabilities. Or the superintelligence could self-recursively improve such that the lab or state that controls it gains an insurmountable scientific advantage. Once an AI reaches a certain capability threshold, it might need only weeks or hours to evolve into a superintelligence.3 And if an American lab builds it, it might help to lock in the dominance of another American century.&lt;/p&gt;
    &lt;p&gt;If you buy the potential of AI, then you might worry about the corgi-fication of humanity by way of biological weapons. This hope also helps to explain the semiconductor controls unveiled by the Biden administration in 2022. If the policymakers believe that DSA is within reach, then it makes sense to throw almost everything into grasping it while blocking the adversary from the same. And it barely matters if these controls stimulate Chinese companies to invent alternatives to American technologies, because the competition will be won in years, not decades.&lt;/p&gt;
    &lt;p&gt;The trouble with these calculations is that they mire us in epistemically tricky terrain. I’m bothered by how quickly the discussions of AI become utopian or apocalyptic. As Sam Altman once said (and again this is fairly humorous): “AI will be either the best or the worst thing ever.” It’s a Pascal’s Wager, in which we’re sure that the values are infinite, but we don’t know in which direction. It also forces thinking to be obsessively short term. People start losing interest in problems of the next five or ten years, because superintelligence will have already changed everything. The big political and technological questions we need to discuss are only those that matter to the speed of AI development. Furthermore, we must sprint towards a post-superintelligence world even though we have no real idea what it will bring.&lt;/p&gt;
    &lt;p&gt;Effective altruists used to be known for their insistence on thinking about the very long run; much more of the movement now is concerned about the development of AI in the next year. Call me a romantic, but I believe that there will be a future, and indeed a long future, beyond 2027. History will not end. We need to cultivate the skill of exact thinking in demented times.&lt;/p&gt;
    &lt;p&gt;I am skeptical of the decisive strategic advantage when I filter it through my main preoccupation: understanding China’s technology trajectories. On AI, China is behind the US, but not by years. There’s no question that American reasoning models are more sophisticated than the likes of DeepSeek and Qwen. But the Chinese efforts are doggedly in pursuit, sometimes a bit closer to US models, sometimes a bit further. By virtue of being open-source (or at least open-weight), the Chinese models have found receptive customers overseas, sometimes with American tech companies.4 If US labs achieve superintelligence, the Chinese labs are probably on a good footing to follow closely. Unless the DSA is decisive immediately, it’s not obvious that the US will have a monopoly on this technology, just as it could not keep it over the bomb.&lt;/p&gt;
    &lt;p&gt;One advantage for Beijing is that much of the global AI talent is Chinese. We can tell from the CVs of researchers as well as occasional disclosures from top labs (for example from Meta) that a large percentage of AI researchers earned their degrees from Chinese universities. American labs may be able to declare that “our Chinese are better than their Chinese.” But some of these Chinese researchers may decide to repatriate. I know that many of them prefer to stay in the US: their compensation might be higher by an order of magnitude, they have access to compute, and they can work with top peers.5But they may also tire of the uncertainty created by Trump’s immigration policy. It’s never worth forgetting that at the dawn of the Cold War, the US deported Qian Xuesen, the CalTech professor who then built missile delivery systems for Beijing. Or these Chinese researchers expect life in Shanghai to be safer or more fun than in San Francisco. Or they miss mom. People move for all sorts of reasons, so I’m reluctant to believe that the US has a durable talent advantage.&lt;/p&gt;
    &lt;p&gt;China has other advantages in building AI. Superintelligence will demand a superload of power. By now everyone has seen the chart with two curves: US electrical generation capacity, which has barely budged upwards since the year 2000; and China’s capacity, which was one-third US levels in 2000 and more than two-and-a-half times US levels in 2024. Beijing is building so much solar, coal, and nuclear to make sure that no data center shall be in want. Though the US has done a superb job building data centers, it hasn’t prepared enough for other bottlenecks. Especially not as Trump’s dislike of wind turbines has removed this source of growth. Speaking of Trump’s whimsy, he has also been generous with selling close-to-leading chips to Beijing. That’s another reason that data centers might not represent a US advantage for long.&lt;/p&gt;
    &lt;p&gt;Silicon Valley has not demonstrated joined-up thinking for deploying AI. It would help if they learned from the central planners. The AI labs have not shown that they’re thinking seriously about how to diffuse the technology throughout society, which will require extensive regulatory and legal reform. How else will AI be able to fold doctors and lawyers into its tender mercies? Doing politics will also mean reaching out to more of the electorate, who are often uneasy with Silicon Valley’s promises while they see rising electrical bills. Silicon Valley has done a marvelous job in building data centers. But tech titans don’t look ready to plan for later steps in leading the whole-of-society effort into deploying AI everywhere.&lt;/p&gt;
    &lt;p&gt;The Communist Party lives for whole-of-society efforts. That’s what Leninist systems are built for. Beijing has set targets for deploying AI across society, though as usual with planning announcements, these numerical targets should be taken seriously and not literally. Chinese founders talk about AI mostly as a technology to be harnessed rather than a fickle power that might threaten all.6 Rather than building superintelligence, Chinese companies have been more interested in embedding AI into robots and manufacturing lines. Some researchers believe that this sort of embodied AI might present the real path towards superintelligence.7We might furthermore wonder how the US and China will use AI. Since the US is much more services-driven, Americans may be using AI to produce more powerpoints and lawsuits; China, by virtue of being the global manufacturer, has the option to scale up production of more electronics, more drones, and more munitions.&lt;/p&gt;
    &lt;p&gt;Dean Ball, who helped craft the White House’s action plan on AI, has written a perceptive post on how the US is playing to its strengths — software, chips, cloud computing, financing — while China is also focused on leaning on manufacturing excellence. In his view, “the US economy is increasingly a highly leveraged bet on deep learning.” Certainly there’s a lot of money invested here, but it looks risky to be so concentrated. I believe it’s unbecoming for the world’s largest economy to be so levered on one technology. That’s a more appropriate strategy for a small country. Why shouldn’t the US be better positioned across the entirety of the supply chain, from electron production to electronics production?&lt;/p&gt;
    &lt;p&gt;I am not a skeptic of AI. I am a skeptic only of the decisive strategic advantage, which treats awakening the superintelligence as the final goal. Rather than “winning the AI race,” I prefer to say that the US and China need to “win the AI future.” There is no race with a clear end point or a shiny medal for first place. Winning the future is the more appropriately capacious term that incorporates the agenda to build good reasoning models as well as the effort to diffuse it across society. For the US to come ahead on AI, it should build more power, revive its manufacturing base, and figure out how to make companies and workers make use of this technology. Otherwise China might do better when compute is no longer the main bottleneck.&lt;/p&gt;
    &lt;p&gt;The humming tech engine&lt;/p&gt;
    &lt;p&gt;I’ve had Silicon Valley friends tell me that they are planning a trip to China nearly every month this year. Silicon Valley respects and fears companies from only one other country. Game recognizes game, so to speak. Tech founders may begrudge China’s restrictions; and some companies have suffered directly from IP theft. But they also recognize that Chinese companies can move even faster than they do with their teams of motivated workers; and Chinese manufacturers are far ahead of US capabilities on anything involving physical production. Some founders and VCs are impressed with the fact that Chinese AI companies have gotten this far while suffering American tech restrictions, while leading in open-source to boot. VCs are wondering whether they may still invest in Chinese startups or Chinese founders who have moved abroad.&lt;/p&gt;
    &lt;p&gt;2025 is the year that Chinese tech successes have really blossomed into the wider American consciousness. There’s no need to retread the coverage around DeepSeek, the surge of electric vehicle exports, or new developments in robotics. When I first moved from Silicon Valley to China in 2017, I felt some degree of skepticism from my friends that I was taking myself out of the beating heart of the technological universe and into the unknown. But it was clear to me that Chinese firms were improving on quality and taking global market share. I wrote in my 2019 letter: “Chinese workers are working with the latest tools to produce most of the world’s goods; over the longer term, my hypothesis is that they’ll be able to replicate the tooling and make just as good final products.”&lt;/p&gt;
    &lt;p&gt;I think that has become closer to consensus views. I believe that Chinese technological success is now the rule rather than the exception. There are two fields in which China is substantially behind the west: semiconductors and aviation. The chip sector is gingerly attempting to expand under the weight of US restrictions; meanwhile, China’s answer to Airbus and Boeing is on a very long runway. I grant that these are two critical technologies, but China has attained technological leadership almost everywhere else. And I believe its technological momentum will continue rolling onwards to engulf more of their western competitors over the next decade.&lt;/p&gt;
    &lt;p&gt;The electric vehicle industry is the sharp tip of the spear of China’s global success. Chinese EVs have greater functionalities than western models while selling at lower price points. A rule of thumb is that it takes five years from an American, German, or Japanese automaker to dream up a new car design and launch that model on the roads; in China, it’s closer to 18 months. The Chinese market is full of demanding customers as well as fast-iterating automotive suppliers. It also has a more productive workforce. According to Tesla’s corporate disclosures, a worker at a Gigafactory in China produces an average of 47 vehicles a year; a worker at a Gigafactory in California produces an average of 20.8&lt;/p&gt;
    &lt;p&gt;China’s automotive success is biting into Germany more than anywhere else. I keep a scrapbook filled with mournful remarks that German executives offer to newspapers. “Most of what German Mittelstand firms do these days, Chinese companies can do just as well,” said a consultant to the Financial Times. “In my sector they look at the price-point of the market leader and sell for roughly half of that,” the boss of a medical devicemaker told the Economist. It’s never hard to find parades of gloomy Germans. Now more than ever it looks like their core competences are threatened by Chinese firms.&lt;/p&gt;
    &lt;p&gt;I often think of the case of Xiaomi. In 2021, Lei Jun vowed that the company he founded would break into the EV business. Four years later, Xiaomi started shipping cars to customers. Not only that, a Xiaomi EV set a speed record at the Nürburgring racetrack in Germany. Compare Xiaomi to Apple, which spent 10 years and $10 billion studying whether to enter the EV market before it pulled the plug. The world’s most advanced consumer product company could not match Xiaomi’s feat. It’s cases like these that make me skeptical of reasoning about China’s tech successes through financial measures or productivity ratios. As of this writing, Xiaomi’s market value is $130 billion. That is only around half of the market value of AppLovin, the mobile advertisement company. Rather than being an indictment of Xiaomi, I view this imbalance as an indictment of financial valuations. Isn’t it better, from a national power perspective, to develop firms like Xiaomi, which calls its shots and then makes them?&lt;/p&gt;
    &lt;p&gt;This comparison between Xiaomi and Apple motivated an essay I wrote with Dragonomics founder Arthur Kroeber in an issue of Foreign Affairs. Our view is that China’s industrial success has roots in deep infrastructure. That includes not only ports and rail, it also includes data connectivity, electrification, and process knowledge. China’s strength lies in a robust manufacturing ecosystem full of self-reinforcing parts.&lt;/p&gt;
    &lt;p&gt;Chinese tech achievements that were apparent in 2025 were the fruits of investments made a decade ago. Given that China continues to invest massively in technology, I expect we’ll see yet more tech successes for another decade to come. Alexander Grothendieck used an analogy of a walnut to describe different approaches to mathematics, which might also apply to technology development. Some mathematicians crack their problems by finding the right spot to insert a chisel before making a clean strike. Grothendieck described his own approach as coming up with general solutions, as if he were immersing the walnut in a bath for such a long time that mere hand pressure would be enough to open it. The US comes up with exquisite and expensive solutions to its technology problems. China’s industrial ecosystem is more like a rising sea, softening many nuts at once.9&lt;/p&gt;
    &lt;p&gt;When these nuts open, it looks like China is producing a big wave of new products. These are its breakthroughs in drones, electric vehicles, and robotics. Years from now we may see greater success in biotech as well. I am keen to follow along China’s progress in electromagnetism over the next decade. China’s industrial ecosystem is leading the way in replacing combustion with electromagnetic processes. Everything is now drone, as the combination of cheaper batteries and better permanent magnets displaces the engine.10&lt;/p&gt;
    &lt;p&gt;One of the startling geopolitical moves of the year was how quickly Donald Trump withdrew his ~150 percent tariffs on China. Trump folded not out of beneficence, but because Xi Jinping denied rare earth magnets to most of the world, threatening many types of manufacturing operations. And yet I’m struck by Beijing’s relative restraint. Chinese producers are close to being monopolists not only in rare earths, but also electronics products, batteries, and many types of active pharmaceutical ingredients. In case China denies, say, cardiovascular drugs to the elderly, how long could a state hold out?&lt;/p&gt;
    &lt;p&gt;One might have expected the US to have roused itself after this bout of the trade war. But there have been too many declarations of Sputnik Moments without commensurate action. Barack Obama declared a Sputnik with China’s high-speed rail; Mark Warner repeated with Huawei’s 5G; Marc Andreessen called it with DeepSeek. The more that people use the term, the less likely that society spurs itself into taking it seriously.&lt;/p&gt;
    &lt;p&gt;I think the US continues to systematically underrate China’s industrial progress for several reasons.&lt;/p&gt;
    &lt;p&gt;First, too many western elites retain hope that China’s efforts will run out of fuel by its own accord. Industrial progress will be weighed down by demographic drag, the growing debt load, maybe even a political collapse. I won’t rule these out, but I don’t think they are likely to break China’s humming tech engine. Demographics in particular don’t matter for advanced technology — you don’t need a workforce of many millions to have robust production of semiconductors or EVs. South Korea, for example, has one of the world’s fastest shrinking populations while retaining its success in electronics production. And though China suffers broader economic headwinds, technology firms like Xiaomi continue to develop new products and enjoy rising revenues. Technology breakthroughs can occur even in a suffering society. Especially if the state continues to lavish resources on chips or anything that could represent an American chokepoint.&lt;/p&gt;
    &lt;p&gt;Second, western elites keep citing the wrong reasons for China’s success. When members of Congress get around to acknowledging China’s tech advancements, they do not fail to attribute causes to either industrial subsidies (also known as cheating) or IP theft (that is, stealing). These are legitimate claims, but China’s advantages extend far beyond them. That’s the creation of deep infrastructure as well as extensive industrial ecosystems that I describe above.&lt;/p&gt;
    &lt;p&gt;Probably the most underrated part of the Chinese system is the ferocity of market competition. It’s excusable not to see that, given that the party espouses so much Marxism. I would argue that China embodies both greater capitalist competition and greater capitalist excess than America does today. Part of the reason that China’s stock market trends sideways is that everyone’s profits are competed away. Big Tech might enjoy the monopolistic success smiled upon by Peter Thiel, coming almost to genteel agreements not to tread too hard upon each other’s business lines. Chinese firms have to fight it out in a rough-and-tumble environment, expanding all the time into each other’s core businesses, taking Jeff “your margin is my opportunity” Bezos with seriousness.&lt;/p&gt;
    &lt;p&gt;Third, western elites keep holding on to a distinction between “innovation,” which is mostly the remit of the west, and “scaling,” which they accept that China can do. I want to dissolve that distinction. Chinese workers innovate every day on the factory floor. By being the site of production, they have a keen sense of how to make technical improvements all the time. American scientists may be world leaders in dreaming up new ideas. But American manufacturers have been poor at building industries around these ideas. The history books point out that Bell Labs invented the first solar cell in 1957; today, the lab no longer exists while the solar industry moved to Germany and then to China. While Chinese universities have grown more capable at producing new ideas, it’s not clear that the American manufacturing base has grown stronger at commercializing new inventions.&lt;/p&gt;
    &lt;p&gt;I sometimes hear that the US will save manufacturers through automation. The truth is that Chinese factories tend to be ahead on automation: that’s a big part of the reason that Chinese Tesla workers are more productive than California Tesla workers. China regularly installs as many robots as the rest of the world put together. They are also able to provide greater amounts of training data for AI. We have to be careful not to let automation, like superintelligence, become an excuse for magical thinking rather than doing the hard work of capacity building.&lt;/p&gt;
    &lt;p&gt;Outlasting the adversary&lt;/p&gt;
    &lt;p&gt;The China discussions I get into on the east coast tend to focus on the country’s problems. Washington, DC in particular likes to ask questions like: didn’t we think that Japan was going to overrun the world with manufacturing before it fell apart? Isn’t China mostly a mess? These are ultimately variants of the form: how might China fail?&lt;/p&gt;
    &lt;p&gt;The west coast flavor of the discussion is different. People are more inclined to ask: what happens if China succeeds? That reflects, in part, Silicon Valley’s epistemic bias towards securing upside returns rather than minimizing downside risks. They also tend to make more frequent visits to China than folks in DC. “What if China succeeds?” is certainly the more interesting question to me, not only because my career has been studying China’s technological successes. The east coast questions deserve to be taken seriously. But I fear that dwelling on China’s failure modes will coax elites into complacency, serving a narrative that the US needs to change nothing before the adversary will topple, robbing the country of urgency to reform.&lt;/p&gt;
    &lt;p&gt;I want to be clear that though I expect China will overrun advanced technology industries, it won’t make the country a broad success. Over the past five years, it has been mired in disinflationary growth, where young people struggle to find a job and find a spouse. The political system is growing even more opaque, terrifying even the insiders. This year, Xi deposed a dozen generals of the People’s Liberation Army, one of whom was also a sitting Politburo member. I wonder how many people inside the Politburo feel confident about where they stand with Xi.&lt;/p&gt;
    &lt;p&gt;Entrepreneurs are on even worse ground. Earlier this year, investors greeted Xi’s handshake with prominent entrepreneurs (including Jack Ma) as good news. It was so, but who can be sure that Xi will not greet them differently once they revive the economy? Though Xi can cut entrepreneurs some slack, the trend is towards greater party control over business and society. Xi himself doesn’t evince concern that economic growth is lackluster. It’s an acceptable tradeoff for making China’s economy less dependent on foreign powers. None of this is a formula for broad human flourishing. Rather, it is depriving Chinese of contact with the rest of the world.&lt;/p&gt;
    &lt;p&gt;Beijing has been working relentlessly to build up its resilience. While the US talks itself out of Sputnik Moments, Beijing has dedicated immense resources to patching up its own deficiencies. It’s not a theoretical fear that Chinese companies might lose access to American technologies. So the state is pouring more money than ever before into semiconductor makers and research universities. It is investing in clean technologies not so much because it cares about the climate, but because it wants to be self-sufficient in energy. And it is re-writing the rules of the global order, with caution because it has been a giant beneficiary of it, while the US is still wondering about what it wants from China. Beijing has been preparing for Cold War without eagerness for waging it, while the US wants to wage a Cold War without preparing for it.11&lt;/p&gt;
    &lt;p&gt;So here’s a potential way that China succeeds. Beijing’s goal is to make nearly every important product in the world, while everyone else supplies its commodities and services. By making the country mostly self-sufficient, and by vigorously policing the outputs of LLMs and social media, Xi might hope to make China resilient. He is building Fortress China stone by stone in order to outlast the adversary. Beijing doesn’t have to replicate American diplomatic, cultural, and financial superpowerdom. It might hope that its prowess in advanced manufacturing might deter the US. And its success in manufacturing might directly destabilize the US: by delivering the coup de grace to the rustbelt, the US might shed a few million more manufacturing jobs over the next decade. The job losses combined with AI psychosis, social media, and all the problems with phones could make national politics meaningfully worse.&lt;/p&gt;
    &lt;p&gt;I don’t think this scenario is likely to be successful. Authoritarian systems have always hoped for the implosion of liberal democracies, while it is the liberal democracies that have a better track record of endurance. But I also don’t think that authoritarian countries are obviously wrong to bet that western polarization will get worse. So it’s up to the US and Europe to show that they can hold on to their values while absorbing the technological changes coming their way.&lt;/p&gt;
    &lt;p&gt;That task is more challenging as Europe and the US grew more apart in 2025. This year, both regions were able to look upon each other with pity. And both were correct to do so. America’s global trust and favorability measures have collapsed in Trump’s second term. Meanwhile, Europe looks as economically stuck as it has ever been, pushing its politics to increasingly chaotic extremes. But I am still more optimistic for the US.&lt;/p&gt;
    &lt;p&gt;I don’t need to lament the damage done by the Trump administration this year: the erosion of alliances, the cruelty towards the weak, the wasting of time. Manufacturing and re-industrialization, which I spend most of my time thinking of, have been doing worse. The Biden administration tried to fund an ambitious program of industrial policy; but it was so plodding and proceduralist that it built little before voters re-elected Trump. Since Trump imposed tariffs in April, the US has lost around 65,000 manufacturing jobs.12 His administration shows little interest in capturing electromagnetism before China overruns that field. Trump is more interested in protectionism rather than export promotion, which risks turning American industries into fossils like its exquisitely protected and horribly inefficient shipbuilding industry.&lt;/p&gt;
    &lt;p&gt;One of the Trump administration’s biggest blunders was its decision to raid a battery plant in Georgia, which put 300 Korean engineers in chains before deporting them. I suspect that any Korean, Taiwanese, or European engineer would ponder that episode before accepting a job posting to the United States. What a contrast that looks with China’s approach, which for decades has been to welcome managers from Walmart, Apple, or Tesla to train its workforce.&lt;/p&gt;
    &lt;p&gt;Will the US solve manufacturing with AI? Well, maybe, because superintelligence is supposed to solve everything. But there’s a risk that AI will destabilize society before it fixes the industrial base. When I walk around the library at Stanford, I see students plugging everything into AI tools; when they need a break, they’re watching short-form videos on their phones. These videos have been marvelously transformed by AI tools. Shortly after OpenAI released Sora 2, I had brunch with a friend who told me that he created an AI video of himself expertly breakdancing that fooled his five-year-old; another friend piped up to say that she created an AI video of herself that fooled her mother. AI chatbots are skilled at providing emotional companionship: Jasmine Sun discussed how they are able to seduce any segment of society, while pointing to a survey that 52 percent of teens regularly interact with AI companions. I’m not advocating for regulation. But I think it’s reasonable for the world to hope that AI labs will exercise some degree of forbearance before they release their shattering tools.&lt;/p&gt;
    &lt;p&gt;While I feel apprehensive about the US, I am much more gloomy about Europe. I have a hard time squaring the poor prospects of Europe over the next decade with the smugness that Europeans have for themselves. I spent most of the summer in Copenhagen. There’s no doubt that quality of life in most European cities is superb, especially for what I care about: food, opera, walkable streets, access to nature. But a decade of low economic growth is biting. European prices and taxes can be so high while salaries can be so low. For all the American complaints about home affordability, relative housing costs can be even worse in big European cities. London has the house prices of California and the income levels of Mississippi.&lt;/p&gt;
    &lt;p&gt;I remember two vivid episodes from Copenhagen. One day I read the news that the share price of Novo Nordisk — unquestionably one of Europe’s technological successes, along with ASML — collapsed as a result of sustained competition from US-based Eli Lilly as well as its misfortunes navigating the US regulatory system. I also watched Ursula von der Leyen visit Trump in the White House to graciously accept his EU tariffs. It’s already been clear that China has begun to maul European industry. What the Novo Nordisk news made me appreciate was that American companies are comprehensively outworking their European counterparts in biotech in addition to software and finance. Europe is losing the two-front battle against the Chinese on manufacturing and the Americans on services.&lt;/p&gt;
    &lt;p&gt;Perhaps Europe could have recruited some professors from the United States. American academics wouldn’t have needed Trump’s insults to act on their Europhile impulses. And yet European initiatives have not yet been able to brain drain much of this class. That’s mostly because European governments have little funding to offer. European universities have failed to build substantial endowments, so their revenues are dependent on the taxpaying public, which also must support a million other initiatives. An American academic who wants to move to Europe would have to accept more teaching and administrative work, lose tenure, and for the pleasure of all that, probably halve her pay. She would likely also suffer the resentment of European peers, who scoff at the idea that better paid Americans are now refugees. Trump threw a lot against US universities; they are holding up okay, and I think they will remain strong.&lt;/p&gt;
    &lt;p&gt;Europeans are right to gloat they are not under the rule of Trump. But for all of Trump’s ills, I see him as a sign of the underlying dynamism of the US. Who else would have elected so whimsical a leader to this high office? Trump forces questions that Europeans have no appetite to confront, proud as they are in being superior to both Americans and Chinese. I submit that Europeans ought to be more circumspect in their self-satisfaction. Chaos is only one election away. Right-populist parties are outpolling ruling incumbent parties pretty much everywhere, and it is as likely as not that Trumps with European characteristics will engulf the continent by the end of the decade.&lt;/p&gt;
    &lt;p&gt;So I am betting that the US and China are more compelling forces for change. Stalin was fond of telling a story from his experience in Leipzig in 1907, when, to his astonishment, 200 German workers failed to turn up to a socialist meeting because no ticket controller was on the platform to punch their train tickets, citing this experience as proof of the hopelessness of Germanic obedience. Could anyone imagine Chinese or Americans being so obedient? One advantage for the US and China is that both countries are at least interested in growth. You don’t have to convince the elites or the populace that growth is good or that entrepreneurs could be celebrated. Meanwhile in Europe, perhaps 15 percent of the electorate actively believes in degrowth. I feel it’s impossible to convince Europeans to act in their self interest. You can’t even convince them to adopt air conditioning in the summer.&lt;/p&gt;
    &lt;p&gt;The personal is the geopolitical&lt;/p&gt;
    &lt;p&gt;I’m not a doomer on AI or the broader state of the world. Across the US, China, and Europe, people generally enjoy comfortable lives that are free from fear. The market goes up. AI tools improve. Over the years I lived in China, I knew that life was more mundane than the headlines made out. Now that headlines and tweets are more negative everywhere, I know that things are not so bad in most places.&lt;/p&gt;
    &lt;p&gt;What I want is for everyone to do better. I opened my book by saying that Chinese and Americans are the most alike people in the world. They both are driven by a yearning for the future. They feel the draw of better times ahead, which is missing for Europeans, those people who have a sense of optimism only about the past.&lt;/p&gt;
    &lt;p&gt;I believe that modern China is one of the most ahistorical nations in the world. The state and the education system may talk insistently about its thousands of years of continuous history. But no other society has also been so destructive of its own history. The physical past has been disfigured by the attention of the Red Guards and the inattention of urban bulldozers. The social past is contorted by outrageous textbooks, which implement enforced forgetting of major traumas. For tragedies too widely experienced in modern times to be censored — the Cultural Revolution, the one-child policy, Zero Covid — the party discourages reflection in the name of protecting the state’s sensitivity.&lt;/p&gt;
    &lt;p&gt;The United States isn’t so good at celebrating its history either. 2026 is the 250th anniversary of the country’s founding. Where are the monuments to exalt that history? Most of the planned celebrations look small bore. Why hasn’t the federal government built a technological specimen as sublime as the Golden Gate Bridge, the Hoover Dam, or the Apollo missions? Probably because planning for any project should have commenced 10, 20, or 30 years ago. No president would have gotten around to starting a project that has no chance of being completed in his term. Lack of action due to the expectation of long timelines is one of the sins of the lawyerly society.&lt;/p&gt;
    &lt;p&gt;But American problems seem more fixable to me than Chinese problems. That’s why I live here in the US. I made clear in my book that I am drawn to pluralism as well as a broader conception of human flourishing than one that could be delivered by the Communist Party. The United States still draws many of the most ambitious people in the world, few of whom want to move to China. Even now a significant number of Chinese would jump to emigrate to the US if they felt they could be welcomed. But this enduring American advantage should not excuse the US from patching up its deficiencies.&lt;/p&gt;
    &lt;p&gt;A light grab-bag of complaints: While the rich have access to concierge doctors and the world’s best healthcare, the United States cannot organize a pandemic response; it is bioprosperity for the individual and measles for the many. I learned recently that the Bay Area has 26 separate transit agencies; is it really a triumph of democracy to have so many unconsolidated efforts? I wonder whether we can accuse the California government of subverting the will of the people by making so little progress on its high-speed rail, which was approved by referendum in 2008; California rail authorities take more pride in creating jobs than doing the job. I am tempted to use the language from American foreign policy at home. Why talk about American credibility only in terms of combat? Why shouldn’t the failure to deliver on big projects, after spending so much money, constitute a more severe blow to the credibility of the American project? Is the state of the US defense industrial base really deterring adversaries?&lt;/p&gt;
    &lt;p&gt;I won’t belabor issues with American public works or manufacturing. I’ll suggest only that the US ought to be acting with greater curiosity on how to do better. It doesn’t have to become China; but it should better study China’s successes. There is a 21st century playbook for becoming an industrial power and China has written it. This playbook consists of infrastructure development, solicitation of foreign investment, industrial subsidies, and the creation of industrial ecosystems. I hope that the US will stop attributing all of China’s successes to stealing. If such a program would be sufficient for building a world-class industry, then American spooks should dedicate their formidable capabilities to extracting Chinese industrial secrets. The reality is that there is little to be learned from blueprints. By failing to recognize China’s real strengths — the industrial ecosystems pulsating with process knowledge — the US is only cheating itself.&lt;/p&gt;
    &lt;p&gt;The future of US-China competition demands a resounding demonstration of the superiority of one country’s system to perform better for its citizens, which no country has thus achieved. Who’s going to come out ahead? I believe the competition is dynamic. It means we should not rely on static and structural features (like geography or demographics) to predict long-term advantage. One feature that unites American, Chinese, and European elites is the tendency to close ranks behind bad ideas and bad leaders. They are all skilled at dreaming up new ways to squander their advantages. Silicon Valley, for example, succeeds in spite of the generations-long governance failures of California. Imagine how much more vibrant Chinese society could be if it could escape the weight of overbearing censors in Beijing.&lt;/p&gt;
    &lt;p&gt;Competition will be dynamic because people have agency. The country that is ahead at any given moment will commit mistakes driven by overconfidence, while the country that is behind will feel the crack of the whip to reform. Implosion is always an option. In 2021, Xi Jinping was on top of the world, witnessing the omnishambles of the western pandemic response combined with the political disgrace of January 6. So he proceeded to smack around tech founders and initiate a controlled demolition of the property sector, which are two of the policies most responsible for China’s economic sluggishness today. Now, Beijing is trying to get a grip on its weaknesses. If either the US or China falls too far behind the other, the laggard will sweat to catch up. That drive will mean that competition will go on for years and decades.&lt;/p&gt;
    &lt;p&gt;In the competition for who might grow to be more humorous, I give a slight edge to the Chinese rather than to Silicon Valley.&lt;/p&gt;
    &lt;p&gt;No, I don’t expect the Communist Party ever to be funny. But there is a growing contrast between the baleful formality of the political system and the inexhaustible informality of Chinese society. Now that China is bidding farewell to its era of hypergrowth, young people are asking what they want to do with their lives. Fewer of them are interested in doing crazy hours in tech companies or big banks. Some of them are having fun in comedy sketches and stand-up shows. The increasingly gerontocratic Communist Party is not so much hovering over them as existing on a slightly different plane, speaking in strange apocalyptic tongues. Over the long run, I bet that the exuberance and rollicking nature of Chinese society will outlive the lusterless political system.&lt;/p&gt;
    &lt;p&gt;I wish that the tech world could learn to present broader cultural appeal. I hope that Silicon Valley could learn some of the humorousness of New York (or at least LA.) It’s unfortunate that any show or movie made about Silicon Valley is full of awkward nerds; by contrast, Hollywood reliably finds attractive leads when it makes movies about Wall Street. So long as the tech world is talking about the Machine God and the Antichrist, so long as it declines to read more broadly, so long as it is mostly inward looking, it will continue to alienate big parts of the world. But the longer I’m in California, the more easy I find it to be a sunny optimist. So I’m hopeful that the lovable nerds there will be able to present their own smiling optimism to the rest of the world.&lt;/p&gt;
    &lt;p&gt;I thank a number of people for reading a draft of this section and discussing the core ideas with me.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;p&gt;Of all the feedback I’ve received for my book, the most devastating came from my mother. After one of my television appearances, she called me to say: “Son, you looked terrible. Are you sick?” I accept that she, a former TV news anchor, has standing to judge. Still I could only reply with a quavering voice: “Mom, you’re so mean.”13&lt;/p&gt;
    &lt;p&gt;Other readers have been kinder to Breakneck. It reached #3 on the New York Times bestseller list and was also a bestseller on its monthly Business list. I went on podcasts, radio, TV, and spoke at book events. Breakneck was a finalist for the FT/Schroders best business book of the year and it has been a book of the year in several big publications. It’s being translated into 17 languages as of this writing.&lt;/p&gt;
    &lt;p&gt;I’ve learned a lot over the past four months.&lt;/p&gt;
    &lt;p&gt;Why did Breakneck do well? I think four reasons, in descending order of importance. First, timing. It came out in a year of many China headlines — DeepSeek, trade war, 15th Five-Year Plan — and five months after Abundance, which primed readers for the idea that Americans are right to be frustrated by their state. Second, the book had the memetic framing of lawyers and engineers, which also encouraged people to wonder how other countries could be described. (What is India? The UK?) Third, people know my work through these letters. Fourth and least important was the content in the book. An author spends so much time workshopping words and sentences. I accept that a book’s reception is subject to the vagaries of the market and the memelords.&lt;/p&gt;
    &lt;p&gt;I don’t regret a minute of workshopping. I would have liked to workshop some more. Like every author, I wish I had more time to add a finer polish to the entire manuscript. I was heartened when a writer I admire told me that no author is ever more than 85 percent satisfied with their work; to hope for more would be profligate. In any case, I’m proud of the content. If it weren’t in place, I wouldn’t have had positive reviews in mainstream publications like the Financial Times, the Wall Street Journal, the New Yorker, and the Times. I was glad to see praise from both left publications like Jacobin and right publications like American Affairs.&lt;/p&gt;
    &lt;p&gt;I tried to write this book to reach a non-coast audience. Ideally I wanted a lawyer in say Indiana or Ohio to read Breakneck, rather than for it to be picked up only by folks in New York, DC, San Francisco, and the terminally online. So I was happy to hear from a broader cross-section of readers who wrote to tell me that they’d never visited China before and are now curious to do so. It’s a shame that book tours are no longer much of a thing for authors. Publishers don’t necessarily bring authors to book readings in Houston, Los Angeles, New Orleans, or other big cities as a matter of course. I was happy, however, to visit Dallas for the first time this year. After giving a talk in October, I wandered over to the Texas State Fair. Who can resist a place that calls itself “the most Texan place on earth?” I had a fabulous time walking through the fairground, the livestock pens, and the food stalls. The atmosphere made me realize that friendly and pragmatic Texans are what I imagined all Americans to be like, at least in my Canadian mind.&lt;/p&gt;
    &lt;p&gt;I’ve enjoyed opening my inbox to see reader notes. I love hearing from two groups in particular: engineers and other technical people who feel better appreciated for their work; and Chinese readers who tell me that I’ve captured something authentic. Someone emailed a set of book recommendations for the Spanish Civil War. An investor emailed to enlighten me that Copenhagen’s marvelous subways (which I praise for being clean and driverless) were built by Italian construction companies. An agricultural consultant emailed to tell me about her eye-opening experiences visiting big Chinese farms. These notes are small delights for any author. A stranger but still charming event was to see the Blue Book Club. About 20 people gathered in Brooklyn this November to discuss Breakneck, but not before the hosts issued a light exam to make sure that the participants actually read the book.&lt;/p&gt;
    &lt;p&gt;Book promotion made me more of a public figure. I did my best to have fun with it. It wasn’t as hard as I imagined: podcast and TV hosts are as bored by self-serious personalities as the rest of us are. Readers have been friendly as they’ve recognized me in public. There was only one instance of a bit too much friendliness, when someone sidled up to the urinal beside mine in a public bathroom to tell me that he liked my book.&lt;/p&gt;
    &lt;p&gt;I’ve learned it is not possible to value mentors too highly. I am blessed to have good counselors. I mean not only my publishing house, my literary agent, and my writing coach who directly support my work. I am grateful to folks who give me time to reflect on the course of my thinking, especially the ones who have by now mentored me for over a decade. Friends have been generous in all sorts of ways. Eugene, Tina, Maran, Ren, James, Caleb, Alec, and Arthur hosted book parties. Joe Weisenthal wrote in the Odd Lots newsletter: “Total Dan Wang victory” on his view that most of the world is seeing China through the industrial lens I’ve been writing about. Afra hosted a Mandarin-language book discussion in which someone accused me of having a “gentle and vulnerable” voice. Alice, who doesn’t often pick up books on China, told me that my fondness for both the US and China shone through the book. It reconnected me with two friends from Ottawa that I haven’t heard from since high school.&lt;/p&gt;
    &lt;p&gt;I am grateful that Waterstones Piccadilly and Daunt Books in Marylebone have given my book prominent display. One surprise was that my book sold well in the United Kingdom. I’ve been pretty relentless at telling Brits that they are the PPE society and that they excel in the sounding-clever industries — television, journalism, finance, and universities. Upon reflection, it makes sense that the British are reading Breakneck and Abundance. Every problem in the lawyerly society is worse in the UK. I thought that California’s high-speed rail project was an embarrassment; then I learned about the Leeds tram network. First legislated in 1993, mass transit might not come to West Yorkshire until the late 2030s. It reminds me of the lawsuit in Bleak House: “The little plaintiff or defendant who was promised a new rocking-horse when Jarndyce and Jarndyce should be settled has grown up, possessed himself of a real horse, and trotted away into the other world.” At least Californians are struggling over something mighty; I hope that Leeds will one day have a tram.14&lt;/p&gt;
    &lt;p&gt;Homebuilding in London has collapsed. Heathrow has been making plans to build a third runway for twenty years, which is now expected to cost $20 billion. Britain’s electrical network is in even worse disrepair than America’s. I am not sure if it is a geopolitical asset to be able to stiff-upper-lip one’s way through ineffectual government. Maybe it’s more of a liability. But my experience of criticizing Brits resembles my experience of criticizing lawyers. They tend to nod along to my critiques; many of them take me further than where I’d like to go. It’s all very disarming.&lt;/p&gt;
    &lt;p&gt;I’ve been lucky to have smart critics. It’s any author’s dream to see people pick up the book and examine the arguments. Jon Sine wanted to have more specific data on engineers and lawyers, then proceeded to supply it while wrapping it in a narrative on a trip to Wushan. Charles Yang noted that I don’t have much by way of policy suggestions, but he also grasped that I’m trying to change the culture of governing elites while suggesting that Breakneck is an incitement to initiate “tractable mimetic competition.” Jen-Kuan Wang argued that China was not quite the right model for the US, but that Taiwan and the rest of Northeast Asia better show how to survive China Shocks. I am grateful to see constructive engagement with my work. I was unimpressed with only one piece of commentary. Law professors Curtis Milhaupt and Angela Zhang wrote in Project Syndicate: “Lawless State Capitalism Is No Answer to China’s Rise,” as if I were advocating for that. Since the authors mention the book only at the start without engaging with any of the content, I suspect they are critics who chose not to read the book.&lt;/p&gt;
    &lt;p&gt;I learned of Leo Rosten’s quip that it is the weak who are cruel, and gentleness to be expected only from the strong. Every author will hear from online commentators who belligerently misunderstand their work. Saying anything about China tends to rile up the online commentators. Either the hawks will pounce because they believe that the whole country is evil and that its progress is fake; or the tankies will defend the idea that China has achieved socialist utopia. These people live on Twitter and Youtube, offering the stock comment that “this person knows nothing about China.” That’s of course hard to respond to because they offer no analytical content to rebut. Part of what makes the China discourse exasperating is that people have to choose sides all the time, which makes everyone dumber. At least I didn’t have it as bad as Ezra and Derek with Abundance.&lt;/p&gt;
    &lt;p&gt;I’ve learned more about myself as a writer this year. Namely, I like doing it. Writing a book is sometimes enough to make an author forswear the experience for a long time. Then there are the really perverse, for whom a taste of publishing is enough to tempt one into becoming a serial offender. After writing this book, I most looked forward to writing this long-ass letter, the very one you’re reading now.&lt;/p&gt;
    &lt;p&gt;Some writers work like sculptors: they produce something fully chiseled that could stand forever. Novelists tend to be like that. Rather than being a sculptor, I see myself as being a musician. After a performance, no matter how it goes, the musician’s task is to start practicing for the next one. It’s hard for US-China books to rest like sculptures. So I am happy to get back to work, writing iteratively to refine the same few themes that animate me: technology production, industrial ecosystems, US-China competition.&lt;/p&gt;
    &lt;p&gt;Musicians don’t usually practice by running a whole piece from start to finish. Rather, practice sessions tend to focus on particular passages, with a full run-through only before performance. Before I publish this letter, I retype the whole thing from start to finish. It means I take the draft that lives in my Notes app on the left half of my screen while I retype the whole thing into the Google Docs on the right side of my screen. It’s a final check to catch infelicities. More importantly, by simulating the experience of a reader, it’s another way to see if the whole essay stands together.&lt;/p&gt;
    &lt;p&gt;I’ve learned that it is better to wear a tie with a blazer. That was part of my training to be a speaker. The book tour forces you to have answers that last 30 seconds for TV, 30 minutes for a talk, and 3 hours for the more bruising podcasts. I’ve learned that delivering a good talk is a rare skill. I don’t think I could ever be satisfied by a talk I’ll give, because there will always be a stumble, or l’esprit de l’escalier kicks in. The piece of speaking advice I’ve remembered for many years came from Tim Harford: good speaking rewards those who are able to prepare extensively and who are also able to improvise. My favorite book talk took place at the Hoover Institution, hosted by Stephen Kotkin (who is himself peerless at giving excellent lectures). In the summer, I spent two hours asking Kotkin how historians work.&lt;/p&gt;
    &lt;p&gt;One day in October, I went on six podcasts. I haven’t counted the number of podcasts I’ve been on, but I think the number is north of 70. There’s a lot I don’t understand. Are so many people really listening to podcasts? What is the appeal of a video featuring two people with giant microphones in their faces? Do we really have to live in an oral culture world?&lt;/p&gt;
    &lt;p&gt;I’ve noticed the wide range of effort that people put into podcasts. Some hosts edit extensively — Freakonomics Radio stands out for the sheer number of producers and editors. Other hosts release their episodes more or less unedited. Freakonomics stood out to me because Stephen Dubner was able to make the conversation so much fun. Going on Ross Douthat’s Interesting Times was more appropriately serious. Search Engine was impressive for the amount of narrative that PJ Vogt imbued into our more rambling conversation. It felt like a homecoming to return to Odd Lots, where I could tease Tracy Alloway for her country life and Joe Weisenthal over Moby Dick. David Perell read nearly everything I’d written to discuss the writing process. I went on Francis Fukuyama’s podcast to ask him about his relationship with Wang Qishan as well as why he is now banned from China. Works in Progress, Statecraft, and ChinaTalk were each fun in their own way.&lt;/p&gt;
    &lt;p&gt;You don’t really mature into being on podcast mode until you’ve done a lot of them. That’s why I proposed to Tyler to go on his show near the end of the book tour. Conversations with Tyler is the first podcast I regularly started listening to, whose early episodes I still remember well. Before our interview, I told Tyler that he was my final boss. Both of us were playful. I challenged Tyler to enumerate the list of 12th-century popes and teased him about being a New Jersey suburban boy. He told me that America has great infrastructure and healthcare before issuing an intellectual Turing test to see if I could say why he likes Yunnan more than any other place. I had the chance to bring up one of the most sublime pieces of Rossini, the gently entwining trio that concludes Le Comte Ory. Afterwards, commentators wrote that he and I were confrontational. But they should have watched the video, in which Tyler was smiling as much as he ever would.&lt;/p&gt;
    &lt;p&gt;Again, who is listening to all these podcasts? I don’t much look at my book sales, but it doesn’t feel like podcasts move the needle. And a book might create a lot of social media buzz, with all the right people saying all the right things, but Twitter too doesn’t drive sales. It was two platforms that moved a lot of my books: television and radio. People bought after seeing me on CNN or hearing me on NPR. The straightforward explanation is that older people have the time and the money to buy books. Even a brief appearance on TV could reach an ambient audience of millions, a few of whom purchase afterwards. Social media and podcasts are more valuable for driving conversation among the youths.&lt;/p&gt;
    &lt;p&gt;It’s stirring to see that people buy books at all. I do not doubt that we are moving towards an oral culture. But the publishing industry is holding up. A lot of excellent books came out this year, including many on China. Revenues at most of the big trade publishers have been rising. Barnes &amp;amp; Noble is opening 60 new stores in 2026. A lot of the growth in the book trade is coming from romantasy and fairy smut, while the genre of nonfiction is in slight decline. That’s all good, I’m no snob. It’s pleasant to believe that a few decades from now, people might still hold physical books in their hands.&lt;/p&gt;
    &lt;p&gt;I’ve learned that books produce an invitation to all sorts of conversations, both closed and open. A physical book, bound and printed, has a totemic quality. It’s funny that PDFs sometimes circulate better than web-optimized pages; there’s something about strict formatting that establishes authority. Physical books can also last a long time. This letter that you’re reading will no longer be sent around a month from now, while my book can sit unread on shelves for years to gather dust. So I’m still keen to encourage friends to write their books. It’s a great way to sort through one’s ideas and to ease them into the conversation.&lt;/p&gt;
    &lt;p&gt;If I yearned for commercial success in our new oral culture, I would lend my soft voice to narrate romantasy novels. But I worry the superintelligence will devour that job. So I will stick to longform writing. However strange our new world will become, there will always be a class of people who want to engage with essays and books. Over the long term, writing might enjoy the fate of the opera and the symphony. People have been heralding the death of classical music for a century. Yes, much of its audience is pretty old. But there will always be more old people — especially if Silicon Valley delivers on longevity treatments. The job of authors and opera houses is to keep holding on to people who are maturing into pleasures that technological platforms cannot provide. The demographic trend is on our side: the world is producing more old people than youths. I want to be a sunny Californian optimist about everything, including the fate of the written word.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;p&gt;It’s time to talk about (other) books.&lt;/p&gt;
    &lt;p&gt;I last picked up Stendhal’s The Red and the Black a decade ago. I wasn’t certain that the novel, which I keep calling my favorite, would hold up on re-reading. It did gorgeously. The plot centers on Julien Sorel, the handsome son of a poor sawyer. After Julien dons the black garb of the priesthood, he moves from the periphery of his Alpine village into the luminous center of Parisian society. Along the way, he seduces two extraordinary women, the gentle Mme. de Rênal and the magnificent Mathilde, while he commits, in the name of love, acts of extraordinary stupidity. Julien — who is possessed by galloping ambition and extravagant pride — maneuvers his way towards aristocratic distinction and romantic triumph. Then he loses all.&lt;/p&gt;
    &lt;p&gt;More than anything else, Stendhal is funny, especially about love. Only Proust surpasses Stendhal at the skill of guiding the reader into the transports of intoxicating love, only to snap them out of it by skewering the foolishness of Julien or Mathilde. Stendhal doesn’t create the cool detachment that Flaubert or Fontane bring to their characters. Rather, he’s eager to envelop the reader into his passionate embrace. The list of writers who have succumbed to Stendhal includes Nietzsche, Beauvoir, Girard, Balzac, and Robert Alter, who, before he translated the Hebrew Bible, wrote an admiring biography of Stendhal titled A Lion for Love.&lt;/p&gt;
    &lt;p&gt;Why is it that reading Stendhal feels like making a discovery? Stendhal might be just on the cusp of the pantheon because his critics can’t get over the significance of his flaws while his fans cannot forget the delights of his peaks. In that sense, Stendhal is like Rossini. Neither produced a ripe and perfect work; I can’t help but feel some disappointment when I listen to Rossini, who couldn’t achieve the musical perfection of Mozart or the dramatic conviction of Verdi. And yet the peak moments of Stendhal and Rossini produce ecstatic joy. It’s no surprise that Stendhal and Rossini are both renowned for their ravenous appetites, nor that Stendhal wrote his own admiring biography of Rossini, filled with his characteristic amusing falsehoods. Erich Auerbach grasped the point that Stendhal ought to be appreciated for his peaks rather than his average. Stendhal has pride of place in Mimesis, as an author who fluctuated between “realistic candor in general and silly mystification in particulars,” and between “cold self-control, rapturous abandonment to sensual pleasures, and sentimental vaingloriousness.” In other words, Stendhal embodies the spirit of opera buffa in novel.&lt;/p&gt;
    &lt;p&gt;I am often drawn to Ecclesiastes. In Robert Alter’s hands, the gloomy prophet behind the book is named Qohelet, and though I value Alter’s translation, I favor a few of the more iconic lines from King James: “vanity of vanities, all is vanity” and “better to hear the rebuke of the wise than the song of fools.” Melancholy attracts me in any form, and isn’t Ecclesiastes the most melancholic book? The prophet makes small allowances for joy and celebration before hauling the reader back into the house of mourning. There is something deeply satisfying with reading out loud phrases like: “for in mere breath did it come, and into darkness it goes, and in darkness its name is covered.” Though King James is iconic, Robert Alter better conveys overall the literary power of the Hebrew Bible.&lt;/p&gt;
    &lt;p&gt;Marlen Haushofer’s The Wall is short and engrossing. It was deemed a “Cold War” novel by the German press when it was published in 1963. Little about it comes across as being geopolitical today. Rather, Haushofer has written a book about domesticity that manages to be gripping. The heroine spends her days milking her cow, minding her garden, and caring for her cat and dog while living in total isolation in the Alps. She would not survive if she lacked for any of the above. As Katherine Rundell once wrote, “It’s easier to trust a writer who writes great food: they are a person who has paid attention to the world.” Haushofer pays loving attention to the details of life. It never became boring to read about the narrator churning her butter, tending to her potato field, or chopping wood throughout the year.&lt;/p&gt;
    &lt;p&gt;After a man turns 30, he has to choose between specializing in the history of the Roman Empire or the World Wars. Within the latter, one tends to focus on the Pacific Theater, the Western Front, or the Eastern Front. For me, the last theater is the most interesting. No human effort approaches the gargantuan scale of Operation Barbarossa or the Soviet reply. The same fields, one world war earlier, produced other shocks. Nick Lloyd’s The Eastern Front covers the clashes between Imperial Germany and the Russian Empire as well as the Austro-Hungarians against the Italians and the Serbs. Whereas the western front was essentially static throughout the whole war, the east was characterized by the sort of maneuver warfare that most generals had expected to fight. It was the field of legendary confrontations like the Gorlice-Tarnow campaign, the Brusilov offensive, and the 37th Battle of the Isonzo.&lt;/p&gt;
    &lt;p&gt;One of the revelations of Lloyd’s book is how well the Germans fought and how poorly Austro-Hungary performed, ending the war by self-liquidating. Immediately after the war began, German military attachés had already begun to fret that “the major trouble with the Austro-Hungarian Army is currently its weakness in combat.” It became nearly comical how often the Kaiser had to intervene, in the latter half of the war, to stop Emperor Karl from surrendering to the Entente. Perhaps it shouldn’t be surprising that the fighting force of an army where the officers all spoke German and regiments spoke Czech or Croatian could not overwhelm the adversary. The eastern front had diplomatic scheming that was nearly as impressive as the battlefield breakthroughs. It was, after all, the political section of the German general staff that had the imaginative idea to ship Lenin from Switzerland to Russia in order to make revolution.&lt;/p&gt;
    &lt;p&gt;I’m looking for a book that has a clear focus on bigger questions: How did Hohenzollern Prussia outmaneuver Habsburg Austria? And how did they become such firm allies before the war? John Boyer’s Austria 1867-1955 offers parts of the answer, though not in a conceptually organized way. It’s a work of history written for specialists, which means that the narrative serves the footnotes rather than the other way around. Too much of the book is focused on how politicians grappled with each other. Still it yields many morsels. One difference between Austrian nobles and Prussian nobles was that the former did not view a military life as attractive — part of the reason that Austrians performed so badly in war. Austria’s partner was sometimes rooting for the adversary: “a large, successful Prussia was Hungary’s best guarantee that Austria would not gain a superior position to dominate the Hungarian elites.” And this insight feels like a good explanation of the attractiveness of Austrian Catholicism, which “combines a Jansenist, puritanical strain with exuberant baroque piety.” It’s the sort of exuberance that produced a Mozart, rather than more gloomy and ardent Spanish Catholicism that produced the Inquisition.&lt;/p&gt;
    &lt;p&gt;One lesson from the latter years of Austro-Hungary is a good reminder that periods of state decay often correspond with eras of cultural flowering. 1913: The Year Before the Storm presents a whimsical slice of Central Europe. Art historian Florian Illies collates fragments of leading figures month by month, diary-entry style. People were running into each other all the time. Duchamp, d’Annunzio, Debussy at the premiere of the Rite of Spring. Stalin potentially tipping his hat at Hitler, as both residents of Vienna were known to take evening strolls through the gardens of Schönbrunn. Matisse bringing flowers to Picasso while the latter was sick. Rainer Maria Rilke being moody at the seaside with Sidonie Nadherny while she was running off into the arms of Karl Kraus. The celebrated love affairs between Franz Kafka and Felice Bauer, Igor Stravinsky and Coco Chanel, Alma Mahler and Oskar Kokoschka, Alma Mahler with Walter Gropius, Alma Mahler with anyone, really. 1913 is the year that modernism was born; the continent began to shatter the following year.&lt;/p&gt;
    &lt;p&gt;Nan Z. Da’s The Chinese Tragedy of King Lear also has an experimental form. Da is a professor of literature at Johns Hopkins who emigrated from Hangzhou before she was 7. One half of the book is a literary analysis of Shakespeare; the other half of the book is the story of the chaos of Maoist society and her family’s personal experiences of it. The novelty is the weaving of family history with a classic piece of literature. Sometimes these transitions are jarring, perhaps deliberately so. Da has just barely begun musing about the reign of Goneril and Regan before she launches into an exposition: “A history — I am thirty nine years old. My parents left China for the United States at this age.” But I liked this effort to map Mao’s madness onto Lear’s delirium as well as analogizing Deng’s tenacity to Edgar’s determination to lay low. And it convinced me that Lear is the most Chinese of Shakespeare’s plays. It is the marriage of the eastern emphasis on pro forma ceremonies, excessive flattery, and empty speechifying with the western practice of elder abuse. I’d like to read more experimental books like this one.&lt;/p&gt;
    &lt;p&gt;Susannah Clarke’s Piranesi is a glittering jewel. The setting is a mysterious, magical house. The narrator is a radiantly earnest explorer who self-identifies as a “Beloved Child of the House.” His warm curiosity makes this book an adventurer’s diary. I liked the fantasy elements of the first half better than the second half of the book, which disenchanted some of the story, so maybe it’s better to stop halfway through. Afterwards, I read Clarke’s earlier book, Jonathan Strange &amp;amp; Mr Norrell. It’s enjoyable too, especially for its partisanship of Northern English identity, though the book as a whole is wooly. Susannah Clarke offers a good case study of how authors can think about their work over time: an overlong first book that took decades to craft, followed by a shorter and more glittering second work. I can’t wait to see what her third book will be like.&lt;/p&gt;
    &lt;p&gt;(The Neue Galerie’s exhibition this year on New Objectivity led me to the work of German painter Carl Grossberg. This 1925 work spoke to me. Credit: Wikimedia.)&lt;/p&gt;
    &lt;p&gt;I’ve learned that Christmas is a good time to write. Emails stop and all is calm. I submitted my manuscript this time last year in Vietnam. This year, my wife and I are writing from Bali. Tropical Asia makes for great writing retreats. We have lazy mornings that feature a swim and a big breakfast; then we spend the rest of the day writing before going out in the evening for some really spicy food.&lt;/p&gt;
    &lt;p&gt;A few food questions to wrap up:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Is Da Nang the most underrated food city in Asia? Yes, we all know about excellent eating spots in Penang, Tokyo, Yunnan, etc. But I hardly ever hear about Da Nang, which has several Michelin listed places. I am still dreaming about its chewy rice products, the grilled meats, the spice mixes, the seafood soups, the not-too-sweet desserts. It’s well-listed on Michelin guides, but I hardly hear about it. Da Nang is my submission for a food city that ought to be better recognized as a destination.&lt;/item&gt;
      &lt;item&gt;Over the summer in Europe, I found myself wondering why Copenhagen has such amazing baked goods. I think its croissants are even better than in Paris. Then I found myself wondering about the quality distribution of croissants throughout the continent. They are not so good in Spain and Italy. I believe that Italy and Spain have the best overall cuisine in Europe; but they have been less interested in producing excellent baked goods. Is it because they don’t have as good butter? But they still eat a lot of cheese. The US is getting better croissants in big cities, which once more makes me appreciate that America has excellence across many cuisines, though they tend to be scattered.&lt;/item&gt;
      &lt;item&gt;Every winter, I find myself craving vitamin-rich tropical fruits. I mean mostly passionfruit, mango, papaya, eggfruit, and of course durian. American groceries are stocking more rambutan and dragonfruit. I wonder if they could stock even more. It’s always mango season somewhere, for example, so is it possible to find better mangoes throughout the year? Is there a subscription package to receive regular shipments of passionfruit and mango? I realize the durian supply chain is highly complicated (apparently the fruit is pollinated mostly by bats), but still it would be nice to have the fruit occasionally. I realize that tariffs are hurting access to American essentials like coffee and bananas. But I hope that Americans can continue to demand better fruits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Alex Boyd has translated the what he calls the Collected Jokes of Xi Jinping here. https://www.ramble.media/p/is-xi-jinping-funny↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most prominently on a 60 Minutes segment when Amodei said: “AI could wipe out half of all entry-level white-collar jobs and spike unemployment to 10% to 20% in the next one to five years.” https://www.cbsnews.com/news/anthropic-ceo-dario-amodei-warning-of-ai-potential-dangers-60-minutes-transcript/↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eliezer’s 2008 post: “‘AI go FOOM.’ Just to be clear on the claim, “fast” means on a timescale of weeks or hours rather than years or decades; and “FOOM” means way the hell smarter than anything else around, capable of delivering in short time periods technological advancements that would take humans decades, probably including full-scale molecular nanotechnology” https://archive.ph/tNdrf↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gavin Leech discusses the diffusion of Chinese LLMs here: https://www.gleech.org/paper↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Matt Sheehan of Carnegie shows that only 10 percent of top AI researchers have left the US between 2019 to 2025. https://carnegieendowment.org/emissary/2025/12/china-ai-researchers-us-talent-pool↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ChinaTalk produced an enlightening Socratic dialogue on whether Beijing is racing to build superintelligence. Conclusion: probably not. https://www.chinatalk.media/p/is-china-agi-pilled↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pavlo Zvenyhorodskyi and Scott Singer, also of Carnegie, have produced valuable work on embodied AI: https://carnegieendowment.org/research/2025/11/embodied-ai-china-smart-robots↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Calculations from Weijian Shan: “In 2024, Shanghai produced one million vehicles with 20,000 workers, while California produced 464,000 with 22,000 workers.” https://research.gavekal.com/article/unraveling-chinas-productivity-paradox↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;As Grothendieck wrote: “The sea advances insensibly and in silence, nothing seems to happen, nothing moves, the water is so far off you hardly hear it… yet it finally surrounds the resistant substance.” https://webusers.imj-prg.fr/~leila.schneps/grothendieckcircle/Mathbiographies/mclarty1.pdf↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See Noah Smith for more on the electric tech stack: https://www.noahpinion.blog/p/why-every-country-needs-to-master↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ryan Fedasiuk wrote an excellent essay on the lack of a China strategy across US administrations: https://theamericanenterprise.com/in-search-of-a-china-strategy/↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MANEMP on FRED: https://fred.stlouisfed.org/series/MANEMP↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can watch my interview with Fareed Zakaria here: https://edition.cnn.com/2025/10/26/world/video/gps-1026-china-us-trade-showdown↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thanks to Mike Bird for alerting me to the Leeds tram: https://x.com/Birdyword/status/2001570894171500775↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46463600</guid><pubDate>Fri, 02 Jan 2026 11:01:29 +0000</pubDate></item><item><title>10 years of personal finances in plain text files</title><link>https://sgoel.dev/posts/10-years-of-personal-finances-in-plain-text-files/</link><description>&lt;doc fingerprint="5e2f81978ba66636"&gt;
  &lt;main&gt;
    &lt;p&gt;January 2026 will mark 10 years since I started storing my personal finances in plain text files using Beancount. Since January 2016, I've taken out about 30-45 minutes every single month to download my monthly bank statements and import them into my Beancount ledger.&lt;/p&gt;
    &lt;p&gt;There's a lot to talk about here, but let's start with some fun numbers!&lt;/p&gt;
    &lt;head rend="h2"&gt;The 10 year old Beancount ledger&lt;/head&gt;
    &lt;p&gt;10 years of financial transactions is a lot of data! All in all, my ledger contains over 45,000 lines of Beancount entries spread across 16 plain text files. All of it is stored in a &lt;code&gt;finances&lt;/code&gt; directory (version controlled) on my laptop. Here's a snapshot:&lt;/p&gt;
    &lt;code&gt;❯ find . -name "*.beancount" | xargs wc -l
    4037 ./includes/2020.beancount
    3887 ./includes/2018.beancount
      27 ./includes/cash.beancount
    4398 ./includes/2021.beancount
    5531 ./includes/2019.beancount
    5267 ./includes/2022.beancount
    3287 ./includes/2017.beancount
    5506 ./includes/2024.beancount
    5606 ./includes/2023.beancount
    1454 ./includes/2016.beancount
    1089 ./includes/open/04-expenses.beancount
      66 ./includes/open/03-income.beancount
      11 ./includes/open/05-liabilities.beancount
      37 ./includes/open/02-assets.beancount
       1 ./includes/open/01-equity.beancount
    4807 ./main.beancount
   45011 total
&lt;/code&gt;
    &lt;p&gt;Running &lt;code&gt;bean-query&lt;/code&gt; on &lt;code&gt;main.beancount&lt;/code&gt; tells me I have about 10,000 transactions in
total, that in turn contain about 20,000 postings (in double-entry bookkeeping, one
transaction may have multiple postings).&lt;/p&gt;
    &lt;code&gt;❯ uv run bean-query main.beancount
Input file: "Goel"
Ready with 12466 directives (19743 postings in 9895 transactions).
beanquery&amp;gt;
&lt;/code&gt;
    &lt;p&gt;There are 1086 accounts in total.&lt;/p&gt;
    &lt;code&gt;beanquery&amp;gt; select count(*) from (select distinct(account));
coun
----
1086
&lt;/code&gt;
    &lt;p&gt;... which does not mean that there are 1086 bank accounts. Accounts in Beancount are virtual, and you can create as many as you like. Imagine one account for categorizing supermarket spending, one for tracking your income, one for your Netflix subscription, and so on.&lt;/p&gt;
    &lt;p&gt;Next, there are about 500 documents in the repository.&lt;/p&gt;
    &lt;code&gt;❯ find documents/ -name "*.pdf" | wc -l
     507
&lt;/code&gt;
    &lt;p&gt;Beancount lets you attach documents (e.g. receipts or invoices) to transactions, that makes bookkeeping very efficient. I love the fact that whenever I need to do my tax returns, I can just take a look at my Beancount ledger and find all the invoices right there next to the relevant transaction.&lt;/p&gt;
    &lt;p&gt;Lastly, in terms of postings, I started out with 715 in the year 2016, and the year 2023 was the busiest so far in terms of just the total postings count.&lt;/p&gt;
    &lt;code&gt;beanquery&amp;gt; select year(date), count(*) where year(date) &amp;lt; 2025 group by year(date);
year  coun
----  ----
2016   715
2017  1422
2018  1605
2019  2437
2020  1582
2021  2022
2022  2435
2023  2651
2024  2602
&lt;/code&gt;
    &lt;head rend="h2"&gt;The Monthly Ritual&lt;/head&gt;
    &lt;p&gt;I wrote earlier that every month I take about 30-45 minutes to import my financial transactions into Beancount. What does that workflow look like? I wrote another, much more detailed blog post about it a few years ago, but here's a gist.&lt;/p&gt;
    &lt;p&gt;It starts with me logging in to my bank account(s) to download my monthly statement(s) in CSV (CSV because it's much more predictable to parse compared to PDF). I then run these CSV files through what's called an "importer", that converts this CSV data into data structures that Beancount understands. I then append all those extracted entries into my current &lt;code&gt;.beancount&lt;/code&gt; file (which is the main file containing all my
financial transactions in plain text). I then go through each entry one by one and make
sure it's balanced (in double-entry bookkeeping, all the postings in a transaction must
sum to zero, and not all postings/transactions that an importer outputs are balanced).
Some of that balancing is manual and some of it is automated (e.g. the importer code can
look at the transaction's description and decide which account it should go into, and
balance automatically). This last part (balancing) is where most of those 30-45 minutes
go.&lt;/p&gt;
    &lt;p&gt;Whenever a new year starts, I move all the transactions from the past year into a &lt;code&gt;&amp;lt;year&amp;gt;.beancount&lt;/code&gt; file and add an &lt;code&gt;include &amp;lt;year.beancount&amp;gt;&lt;/code&gt; in the active
&lt;code&gt;main.beancount&lt;/code&gt;file, mostly to avoid the main file from becoming too long. Not that it
would be an issue for Beancount, but just for the sake of readability.&lt;/p&gt;
    &lt;p&gt;With such a workflow, all my financial transactions from the beginning of time are contained in a few plain text files in one directory on my laptop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Beancount Importers for German Banks&lt;/head&gt;
    &lt;p&gt;Beancount only provides the foundations for working with money, but it has no knowledge of what your bank statements look like. This is where the concept of an importer comes in. An importer is a (Python) class that takes in a bank statement of sorts (e.g. a CSV export of your transactions) and converts them into something that Beancount can work with.&lt;/p&gt;
    &lt;p&gt;I live in Germany and my bank accounts are with German banks, so I had to write a few importers for a few different banks, specifically beancount-dkb, beancount-ing, beancount-n26, and beancount-commerzbank. I closed out my Commerzbank account a while ago, so I don't maintain that integration anymore, but the first three libraries are actively maintained (and used)!&lt;/p&gt;
    &lt;head rend="h2"&gt;From User to Author&lt;/head&gt;
    &lt;p&gt;My start with Beancount was a bit bumpy. The documentation is very comprehensive but as a newcomer, I found it tricky to get a grasp on the overall workflow. It took me some trial and error to figure things out and have that "aha" moment.&lt;/p&gt;
    &lt;p&gt;I figured that if I found it tricky, maybe it's tricky for others as well. So I wrote a short book to help newcomers get up and running with Beancount easily. If you're interested, here's a link: https://personalfinancespython.com.&lt;/p&gt;
    &lt;p&gt;The feedback on the book has been super positive. It got mentioned on Beancount's external contributions page, and the reader reviews have all been very encouraging!&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing Thoughts&lt;/head&gt;
    &lt;p&gt;Having all my finances in a bunch of plain text files tracked in a git repository feels invaluable to me. And hitting the 10 years mark on that almost feels like a milestone.&lt;/p&gt;
    &lt;p&gt;Perhaps the nicest bit about all this is that this data is sitting on my own machine, not in some data center somewhere else. All of it is in plain text files that I can open up in my editor, and analyze using the tools that the Beancount ecosystem gives me. All of it will outlive any app or service, and that, I feel, is why plaintext accounting is so powerful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46463644</guid><pubDate>Fri, 02 Jan 2026 11:07:51 +0000</pubDate></item><item><title>Show HN: I built a clipboard tool to strip/keep specific formatting like Italics</title><link>https://custompaste.com</link><description>&lt;doc fingerprint="7410077e1d297e98"&gt;
  &lt;main&gt;
    &lt;p&gt;🎉 New Year Sale: Get Lifetime Access for just $14.50 (50% OFF) →&lt;/p&gt;
    &lt;p&gt;CustomPaste is a powerful Windows utility that automatically cleans, formats, and transforms your clipboard text as you paste. Create reusable 'recipes' and let `Ctrl+V` finally do the work you want it to.&lt;/p&gt;
    &lt;p&gt;We've all been there. You copy text from a website, a PDF, or an email, and what you get is a mess. Wrong fonts, awkward line breaks, and hidden formatting that breaks your workflow. You spend precious minutes on the mindless, repetitive task of cleaning it up.&lt;/p&gt;
    &lt;p&gt;How many hours of your life have you lost to this? There has to be a better way.&lt;/p&gt;
    &lt;p&gt;From simple text to complex data, CustomPaste gives you superpowers to make every paste perfect.&lt;/p&gt;
    &lt;p&gt;The #1 Frustration, Solved&lt;/p&gt;
    &lt;p&gt;Be a surgeon: keep essentials like bold and hyperlinks while enforcing your preferred font. Or, be the executioner: use the Force Plain Text option to nuke all formatting, no questions asked. You are always in control.&lt;/p&gt;
    &lt;p&gt;The perfect tool for one-off tasks. Use the Quick Menu,triggered from any app by hotkey or mouse, to apply any of your saved recipes on the fly. It's your full toolkit, on-demand, without ever needing to open the main dashboard.&lt;/p&gt;
    &lt;p&gt;Turn messy lists into organized data in one paste. Instantly purge duplicate lines to find unique entries, sort lists alphabetically, and enforce perfect capitalization with UPPERCASE, lowercase, Sentence Case, or Title Case conversions.&lt;/p&gt;
    &lt;p&gt;Go from chaotic copy to clean, usable text. Instantly fix AI-generated text by converting “smart quotes” and em-dashes, remove emojis, flatten extra blank lines, and fix all weird whitespace issues without you lifting a finger. Your text is clean before it even arrives.&lt;/p&gt;
    &lt;p&gt;Stop pasting broken web pages. CustomPaste intelligently handles complex formats. Create recipes to preserve or strip images and keep HTML tables structured. Finally, you can copy from a website without pasting a disaster.&lt;/p&gt;
    &lt;p&gt;CustomPaste is built to be invisible. It launches on startup and runs silently in the background, always ready but never in your way.&lt;/p&gt;
    &lt;p&gt;In the dashboard, simply check the boxes for the transformations you need. Think of it as creating the blueprint for your ideal paste.&lt;/p&gt;
    &lt;p&gt;No scripting or complex manuals required.&lt;/p&gt;
    &lt;p&gt;Click "Set as Active" to make your recipe the new default for `Ctrl+V`. Need to go back to normal? Just click "Deactivate." You are always in control.&lt;/p&gt;
    &lt;p&gt;The next time you press `Ctrl+V`, CustomPaste instantly applies your rules and pastes a perfectly clean result. It's so fast, it feels like magic.&lt;/p&gt;
    &lt;p&gt;Create rules for cleaning, formatting, and extraction, and watch Ctrl+V become the smartest key on your keyboard.&lt;/p&gt;
    &lt;p&gt;We believe clipboard tools should be private and lightweight. CustomPaste runs 100% locally on your Windows machine, using virtually no system resources.&lt;/p&gt;
    &lt;p&gt;Your text is never sent to our servers. All processing happens on your device.&lt;/p&gt;
    &lt;p&gt;We don't read, save, or sell anything you copy. We can't see it, period.&lt;/p&gt;
    &lt;p&gt;The app works perfectly, even without an internet connection.&lt;/p&gt;
    &lt;p&gt;CustomPaste is built for professionals who are tired of letting the clipboard slow them down.&lt;/p&gt;
    &lt;p&gt;Problem: Copying sources creates a mess of fonts and sizes.&lt;/p&gt;
    &lt;p&gt;Agitate: It's a tedious game of "hunt-the-font." One missed format makes the whole document look unprofessional.&lt;/p&gt;
    &lt;p&gt;Solve: Instantly standardize text while surgically preserving italics and bold.&lt;/p&gt;
    &lt;p&gt;Problem: You're pasting raw, jumbled data full of duplicates and junk.&lt;/p&gt;
    &lt;p&gt;Agitate: Your momentum is dead. That "quick insight" just became a 30-minute chore in Excel, killing your train of thought.&lt;/p&gt;
    &lt;p&gt;Solve: Paste and instantly remove duplicates, sort lists, and strip formatting.&lt;/p&gt;
    &lt;p&gt;Problem: Inspiration comes from sources with different formatting.&lt;/p&gt;
    &lt;p&gt;Agitate: Your creative flow evaporates. One pasted quote infects your document, forcing you to battle phantom styles instead of write.&lt;/p&gt;
    &lt;p&gt;Solve: Enforce font consistency, convert headlines to Title Case, and nuke emojis.&lt;/p&gt;
    &lt;p&gt;Problem: Copying code brings in “smart quotes” and weird whitespace.&lt;/p&gt;
    &lt;p&gt;Agitate: The build fails. It’s not your logic. You’re now losing 10 minutes to a SyntaxError from one invisible "smart quote."&lt;/p&gt;
    &lt;p&gt;Solve: Instantly clean snippets, fix smart quotes, and sort/deduplicate log files.&lt;/p&gt;
    &lt;p&gt;Costs less than 20 minutes of your billable time, but saves you hundreds of hours this year.&lt;/p&gt;
    &lt;p&gt;$0&lt;/p&gt;
    &lt;p&gt;Try it free for 100 pastes&lt;/p&gt;
    &lt;p&gt;$29&lt;/p&gt;
    &lt;p&gt;$14.50&lt;/p&gt;
    &lt;p&gt;One-time purchase. Own it forever.&lt;/p&gt;
    &lt;p&gt;30-Day Money-Back Guarantee&lt;/p&gt;
    &lt;p&gt;No. We can't.&lt;/p&gt;
    &lt;p&gt;CustomPaste is built to be 100% local and private. All text processing happens on your computer. Your clipboard data never leaves your machine.&lt;/p&gt;
    &lt;p&gt;We also offer a full offline activation method for high-security environments.&lt;/p&gt;
    &lt;p&gt;Your passwords, API keys, and private documents are yours alone. We built this for ourselves first, we wouldn't trust our own data with anything less.&lt;/p&gt;
    &lt;p&gt;Hey, I'm Joseph, the developer and one-person team behind CustomPaste. I built this tool for one simple reason: I was personally tired of fighting my clipboard. That "paste and fix" cycle you see on this page? That was my daily frustration while coding and researching.&lt;/p&gt;
    &lt;p&gt;CustomPaste is my solution. It's the tool I always wanted, and I use it every day. I'm committed to making it the best it can be, and I believe in software that's simple and honest. That's why CustomPaste is a one-time purchase. No subscriptions, no cloud accounts, and no data harvesting.&lt;/p&gt;
    &lt;p&gt;- Joseph M.&lt;/p&gt;
    &lt;p&gt;I'm still building! Get notified about major feature releases, special offers, and the (much-requested) macOS version.&lt;/p&gt;
    &lt;p&gt;Just the good stuff. No spam. Unsubscribe anytime.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46463992</guid><pubDate>Fri, 02 Jan 2026 12:07:00 +0000</pubDate></item><item><title>FracturedJson</title><link>https://github.com/j-brooke/FracturedJson/wiki</link><description>&lt;doc fingerprint="767075204fb04a98"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 5&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Home&lt;/head&gt;
    &lt;p&gt;FracturedJson is a family of utilities that format JSON data in a way that's easy for humans to read, but fairly compact. Arrays and objects are written on single lines, as long as they're neither too long nor too complex. When several such lines are similar in structure, they're written with fields aligned like a table. Long arrays are written with multiple items per line across multiple lines.&lt;/p&gt;
    &lt;p&gt;There are lots of settings available to control the output, but usually you can ignore most of them. FracturedJson produces nice-looking output from any set of JSON data automatically.&lt;/p&gt;
    &lt;p&gt;You can try it out with the browser formatter page. It's also available as a .NET library, a JavaScript/Typescript package, and a Visual Studio Code extension. See here for Python options.&lt;/p&gt;
    &lt;p&gt;Here's a sample of output using default settings. See the Options page for examples of what you different settings do.&lt;/p&gt;
    &lt;code&gt;{
    "BasicObject"   : {
        "ModuleId"   : "armor",
        "Name"       : "",
        "Locations"  : [
            [11,  2], [11,  3], [11,  4], [11,  5], [11,  6], [11,  7], [11,  8], [11,  9],
            [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [ 1, 14], [ 1, 13], [ 1, 12],
            [ 1, 11], [ 1, 10], [ 1,  9], [ 1,  8], [ 1,  7], [ 1,  6], [ 1,  5], [ 1,  4],
            [ 1,  3], [ 1,  2], [ 4,  2], [ 5,  2], [ 6,  2], [ 7,  2], [ 8,  2], [ 8,  3],
            [ 7,  3], [ 6,  3], [ 5,  3], [ 4,  3], [ 0,  4], [ 0,  5], [ 0,  6], [ 0,  7],
            [ 0,  8], [12,  8], [12,  7], [12,  6], [12,  5], [12,  4]
        ],
        "Orientation": "Fore",
        "Seed"       : 272691529
    },
    "SimilarArrays" : {
        "Katherine": ["blue",       "lightblue", "black"       ],
        "Logan"    : ["yellow",     "blue",      "black", "red"],
        "Erik"     : ["red",        "purple"                   ],
        "Jean"     : ["lightgreen", "yellow",    "black"       ]
    },
    "SimilarObjects": [
        { "type": "turret",    "hp": 400, "loc": {"x": 47, "y":  -4}, "flags": "S"   },
        { "type": "assassin",  "hp":  80, "loc": {"x": 12, "y":   6}, "flags": "Q"   },
        { "type": "berserker", "hp": 150, "loc": {"x":  0, "y":   0}                 },
        { "type": "pittrap",              "loc": {"x": 10, "y": -14}, "flags": "S,I" }
    ]
}&lt;/code&gt;
    &lt;p&gt;Optionally, comments can be preserved. Comments aren't allowed by the official JSON standard, but they're ubiquitous, so it's nice to have the option. FracturedJson tries to keep the comments together with whatever elements they seem to relate to.&lt;/p&gt;
    &lt;code&gt;{
    /*
     * Multi-line comments
     * are fun!
     */
    "NumbersWithHex": [
          254 /*00FE*/,  1450 /*5AA*/ ,     0 /*0000*/, 36000 /*8CA0*/,    10 /*000A*/,
          199 /*00C7*/, 15001 /*3A99*/,  6540 /*198C*/
    ],
    /* Elements are keen */
    "Elements"      : [
        { /*Carbon*/   "Symbol": "C",  "Number":  6, "Isotopes": [11, 12, 13, 14] },
        { /*Oxygen*/   "Symbol": "O",  "Number":  8, "Isotopes": [16, 18, 17    ] },
        { /*Hydrogen*/ "Symbol": "H",  "Number":  1, "Isotopes": [ 1,  2,  3    ] },
        { /*Iron*/     "Symbol": "Fe", "Number": 26, "Isotopes": [56, 54, 57, 58] }
        // Not a complete list...
    ],

    "Beatles Songs" : [
        "Taxman",          // George
        "Hey Jude",        // Paul
        "Act Naturally",   // Ringo
        "Ticket To Ride"   // John
    ]
}&lt;/code&gt;
    &lt;p&gt;Most JSON libraries give you a choice between two formatting options. Minified JSON is very efficient, but difficult for a person to read.&lt;/p&gt;
    &lt;code&gt;{"AttackPlans":[{"TeamId":1,"Spawns":[{"Time":0.0,"UnitType":"Grunt","SpawnPointIndex":0},{"Time":0.0,"UnitType":"Grunt","SpawnPointIndex":0},{"Time":0.0,"UnitType":"Grunt","SpawnPointIndex":0}]}],"DefensePlans":[{"TeamId":2,"Placements":[{"UnitType":"Archer","Position":[41,7]},{"UnitType":"Pikeman","Position":[40,7]},{"UnitType":"Barricade","Position":[39,7]}]}]}&lt;/code&gt;
    &lt;p&gt;Most beautified/indented JSON, on the other hand, is too spread out, often making it difficult to take in quickly or to scan for specific information.&lt;/p&gt;
    &lt;code&gt;{
    "AttackPlans": [
        {
            "TeamId": 1,
            "Spawns": [
                {
                    "Time": 0,
                    "UnitType": "Grunt",
                    "SpawnPointIndex": 0
                },
                {
                    "Time": 0,
                    "UnitType": "Grunt",
                    "SpawnPointIndex": 0
                },
                {
                    "Time": 0,
                    "UnitType": "Grunt",
                    "SpawnPointIndex": 0
                }
            ]
        }
    ],
    "DefensePlans": [
        {
            "TeamId": 2,
            "Placements": [
                {
                    "UnitType": "Archer",
                    "Position": [
                        41,
                        7
                    ]
                },
                {
                    "UnitType": "Pikeman",
                    "Position": [
                        40,
                        7
                    ]
                },
                {
                    "UnitType": "Barricade",
                    "Position": [
                        39,
                        7
                    ]
                }
            ]
        }
    ]
}&lt;/code&gt;
    &lt;p&gt;FracturedJson tries to format data like a person would. Containers are kept to single lines as long as they're not too complex and not too long. If several successive inline arrays or objects are similar enough, they will be formatted as a table.&lt;/p&gt;
    &lt;code&gt;{
    "AttackPlans" : [
        {
            "TeamId": 1,
            "Spawns": [
                {"Time": 0, "UnitType": "Grunt", "SpawnPointIndex": 0},
                {"Time": 0, "UnitType": "Grunt", "SpawnPointIndex": 0},
                {"Time": 0, "UnitType": "Grunt", "SpawnPointIndex": 0}
            ]
        }
    ],
    "DefensePlans": [
        {
            "TeamId"    : 2,
            "Placements": [
                { "UnitType": "Archer",    "Position": [41, 7] },
                { "UnitType": "Pikeman",   "Position": [40, 7] },
                { "UnitType": "Barricade", "Position": [39, 7] }
            ]
        }
    ]
}&lt;/code&gt;
    &lt;p&gt;FracturedJson uses four types of formatting: inlined, compact multiline array, table and expanded.&lt;/p&gt;
    &lt;p&gt;When possible, sections of the document are written inlined, as long as that doesn't make them too long or too complex (as determined by the settings). "Complexity" refers to how deeply nested an array or object's contents are.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;{ "UnitType": "Archer", "Position": [41, 7] }&lt;/code&gt;
    &lt;p&gt;Use the setting MaxInlineComplexity to control how much nesting is allowed on one line.&lt;/p&gt;
    &lt;p&gt;The next option, for arrays, is to write them with multiple items per line, across multiple lines.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;[
    [19,  2], [ 3,  8], [14,  0], [ 9,  9], [ 9,  9], [ 0,  3], [10,  1],
    [ 9,  1], [ 9,  2], [ 6, 13], [18,  5], [ 4, 11], [12,  2]
]&lt;/code&gt;
    &lt;p&gt;Use the setting MaxCompactArrayComplexity to control how deeply nested items can be when arranged this way, or use &lt;code&gt;-1&lt;/code&gt; to disable this feature.&lt;/p&gt;
    &lt;p&gt;If an array or object contains inlineable items of the same type, they can be formatted in a tabular format. With enough room, all fields at any depth are lined up (and reordered if necessary).&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;{
    "Rect" : { "position": {"x": -44, "y":  3.4         }, "color": [0, 255, 255] },
    "Point": { "position": {          "y": 22   , "z": 3}                         },
    "Oval" : { "position": {"x": 140, "y":  0.04        }, "color": "#7f3e96"     },
    "Plane": { "position": null,                           "color": [0, 64, 64]   }
}&lt;/code&gt;
    &lt;p&gt;If the table wouldn't fit with all of the elements and subelements aligned, the inner-most containers are collapsed while keeping the outer ones still aligned.&lt;/p&gt;
    &lt;code&gt;{
    "Rect" : { "position": {"x": -44, "y": 3.4},  "color": [0, 255, 255] },
    "Point": { "position": {"y": 22, "z": 3}                             },
    "Oval" : { "position": {"x": 140, "y": 0.04}, "color": "#7f3e96"     },
    "Plane": { "position": null,                  "color": [0, 64, 64]   }
}&lt;/code&gt;
    &lt;p&gt;Use the setting MaxTableRowComplexity to control how how deeply nested rows can be, or use &lt;code&gt;-1&lt;/code&gt; to disable this feature.  Use TableCommaPlacement to adjust where commas are placed.&lt;/p&gt;
    &lt;p&gt;If none of those options work for an element, it will be written across multiple lines, with child items indented and starting on its own line.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;[
    {
        "type" : "turret",
        "hp"   : 400,
        "loc"  : {"x": 47, "y": -4},
        "flags": ["stationary"]
    },
    {
        "type" : "assassin",
        "hp"   : 80,
        "loc"  : {"x": 102, "y": 6},
        "flags": ["stealth"]
    },
    { "type": "berserker", "hp": 150, "loc": {"x": 0, "y": 0} },
    {
        "type" : "pittrap",
        "loc"  : {"x": 10, "y": -14},
        "flags": ["invulnerable", "stationary"]
    }
]&lt;/code&gt;
    &lt;p&gt;If you have any questions, comments, requests, advice, or whatever, feel free to check out the discussions area.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46464235</guid><pubDate>Fri, 02 Jan 2026 12:46:31 +0000</pubDate></item></channel></rss>