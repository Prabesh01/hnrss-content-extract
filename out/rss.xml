<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 22 Nov 2025 11:32:24 +0000</lastBuildDate><item><title>Event Sourcing in Go: From Zero to Production</title><link>https://skoredin.pro/blog/golang/event-sourcing-go</link><description>&lt;doc fingerprint="c73083e130d09486"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Event Sourcing in Go: From Zero to Production&lt;/head&gt;
    &lt;p&gt;Event sourcing: append-only architecture processing 10K events/sec with complete history, time travel debugging, and CQRS. From theory to production implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key Takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Event sourcing provides complete audit trail and time-travel debugging capabilities&lt;/item&gt;
      &lt;item&gt;CQRS separation enables independent scaling of reads and writes&lt;/item&gt;
      &lt;item&gt;Snapshots are essential for performance with large event streams&lt;/item&gt;
      &lt;item&gt;Proper event versioning and migration strategies prevent production disasters&lt;/item&gt;
      &lt;item&gt;Event streaming with Kafka enables real-time projections and system integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Why Event Sourcing?&lt;/item&gt;
      &lt;item&gt;Core Concepts in 5 Minutes&lt;/item&gt;
      &lt;item&gt;Production Event Store&lt;/item&gt;
      &lt;item&gt;Aggregate Root Pattern&lt;/item&gt;
      &lt;item&gt;CQRS: Command and Query Separation&lt;/item&gt;
      &lt;item&gt;Snapshots for Performance&lt;/item&gt;
      &lt;item&gt;Event Streaming with Kafka&lt;/item&gt;
      &lt;item&gt;Temporal Queries (Time Travel)&lt;/item&gt;
      &lt;item&gt;Saga Pattern for Distributed Transactions&lt;/item&gt;
      &lt;item&gt;Security Considerations&lt;/item&gt;
      &lt;item&gt;Testing Strategy&lt;/item&gt;
      &lt;item&gt;Production Monitoring&lt;/item&gt;
      &lt;item&gt;Performance Optimizations&lt;/item&gt;
      &lt;item&gt;Migration from Traditional System&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why Event Sourcing?&lt;/head&gt;
    &lt;p&gt;Your database shows current state. But how did it get there? Who changed what? When? Why?&lt;/p&gt;
    &lt;code&gt;-- Traditional: Current state only
SELECT balance FROM accounts WHERE id = 123;
-- Result: 1000

-- Event sourced: Complete history
SELECT * FROM events WHERE aggregate_id = 123;
-- Shows every deposit, withdrawal, fee, interest&lt;/code&gt;
    &lt;p&gt;We needed audit trail for financial compliance. Event sourcing gave us that plus time travel, debugging superpowers, and perfect scalability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Concepts in 5 Minutes&lt;/head&gt;
    &lt;p&gt;Event sourcing stores state changes as a sequence of events rather than overwriting data. Instead of UPDATE statements that destroy history, we append immutable events that tell the complete story.&lt;/p&gt;
    &lt;p&gt;Traditional systems show what IS. Event sourcing shows what HAPPENED. This distinction transforms debugging, auditing, and analytics. When a bug corrupts data, we can replay events to find exactly when and how it occurred.&lt;/p&gt;
    &lt;p&gt;Events are facts about the past - they cannot be changed or deleted. This immutability provides natural audit logging and enables powerful patterns like temporal queries and retroactive fixes.&lt;/p&gt;
    &lt;p&gt;State becomes a left-fold over events. Current balance isn't stored; it's calculated by replaying all deposits and withdrawals. This sounds slow but with snapshots and projections, it's actually faster than traditional systems for many use cases.&lt;/p&gt;
    &lt;code&gt;// Events capture business intent
type AccountOpened struct {
    AccountID string
    Currency  string
}

type MoneyDeposited struct {
    AccountID string
    Amount    decimal.Decimal
}

// State derived from event history
func (a *Account) Apply(event Event) {
    // Rebuild state by replaying events
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Production Event Store&lt;/head&gt;
    &lt;p&gt;A production event store needs to handle millions of events efficiently. Our PostgreSQL-based implementation processes 10K events/second with proper indexing and partitioning. The append-only nature makes it extremely fast - no updates, no deletes, just inserts.&lt;/p&gt;
    &lt;p&gt;Event ordering is critical for consistency. We use database sequences per aggregate to ensure events are applied in the correct order. This prevents race conditions where concurrent operations might corrupt state.&lt;/p&gt;
    &lt;p&gt;The schema design balances normalization with query performance. Event data is stored as JSON for flexibility, while frequently queried fields (aggregate_id, event_type) are indexed columns. This hybrid approach enables both fast queries and schema evolution.&lt;/p&gt;
    &lt;p&gt;Metadata tracks important context: user ID, correlation ID, causation ID. This audit trail proves invaluable for debugging and compliance. Every state change is traceable to its origin.&lt;/p&gt;
    &lt;code&gt;type EventStore struct {
    db *sql.DB
}

type StoredEvent struct {
    ID            uuid.UUID
    AggregateID   string
    EventType     string
    EventVersion  int
    EventData     json.RawMessage
    Metadata      json.RawMessage
    OccurredAt    time.Time
}

// Append-only schema with proper indexes
const schema = `
CREATE TABLE events (
    id UUID PRIMARY KEY,
    aggregate_id VARCHAR(255) NOT NULL,
    event_type VARCHAR(255) NOT NULL,
    event_version INT NOT NULL,
    event_data JSONB NOT NULL,
    metadata JSONB,
    occurred_at TIMESTAMP NOT NULL,
    recorded_at TIMESTAMP NOT NULL DEFAULT NOW(),
    
    -- Ensure events are ordered per aggregate
    UNIQUE(aggregate_id, event_version),
    
    -- Indexes for queries
    INDEX idx_aggregate (aggregate_id, event_version),
    INDEX idx_event_type (event_type),
    INDEX idx_occurred_at (occurred_at)
);

-- Global event sequence for ordering
CREATE SEQUENCE IF NOT EXISTS global_event_sequence;
ALTER TABLE events ADD COLUMN global_sequence BIGINT DEFAULT nextval('global_event_sequence');
CREATE INDEX idx_global_sequence ON events(global_sequence);
`

func (es *EventStore) SaveEvents(ctx context.Context, aggregateID, aggregateType string, events []Event, expectedVersion int) error {
    tx, err := es.db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // Check optimistic concurrency
    var currentVersion int
    err = tx.QueryRow(`
        SELECT COALESCE(MAX(event_version), 0) 
        FROM events 
        WHERE aggregate_id = $1`,
        aggregateID,
    ).Scan(¬§tVersion)
    
    if err != nil {
        return err
    }
    
    if currentVersion != expectedVersion {
        return fmt.Errorf("concurrency conflict: expected version %d, got %d", 
            expectedVersion, currentVersion)
    }
    
    // Save events
    version := expectedVersion
    for _, event := range events {
        version++
        
        eventData, err := json.Marshal(event)
        if err != nil {
            return err
        }
        
        metadata := map[string]interface{}{
            "user_id":     ctx.Value("user_id"),
            "trace_id":    ctx.Value("trace_id"),
            "source":      ctx.Value("source"),
        }
        metadataJSON, _ := json.Marshal(metadata)
        
        _, err = tx.Exec(`
            INSERT INTO events (
                aggregate_id, aggregate_type, event_type, 
                event_version, event_data, metadata, occurred_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7)`,
            aggregateID,
            aggregateType,
            event.EventType(),
            version,
            eventData,
            metadataJSON,
            event.OccurredAt(),
        )
        
        if err != nil {
            return err
        }
    }
    
    return tx.Commit()
}

func (es *EventStore) GetEvents(ctx context.Context, aggregateID string, fromVersion int) ([]StoredEvent, error) {
    rows, err := es.db.QueryContext(ctx, `
        SELECT 
            id, aggregate_id, aggregate_type, event_type,
            event_version, event_data, metadata, 
            occurred_at, recorded_at
        FROM events
        WHERE aggregate_id = $1 AND event_version &amp;gt; $2
        ORDER BY event_version`,
        aggregateID, fromVersion,
    )
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var events []StoredEvent
    for rows.Next() {
        var e StoredEvent
        err := rows.Scan(
            &amp;amp;e.ID, &amp;amp;e.AggregateID, &amp;amp;e.AggregateType,
            &amp;amp;e.EventType, &amp;amp;e.EventVersion, &amp;amp;e.EventData,
            &amp;amp;e.Metadata, &amp;amp;e.OccurredAt, &amp;amp;e.RecordedAt,
        )
        if err != nil {
            return nil, err
        }
        events = append(events, e)
    }
    
    return events, nil
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Aggregate Root Pattern&lt;/head&gt;
    &lt;code&gt;type AggregateRoot struct {
    ID               string
    Version          int
    uncommittedEvents []Event
}

func (a *AggregateRoot) RecordEvent(event Event) {
    a.uncommittedEvents = append(a.uncommittedEvents, event)
    a.Version++
}

func (a *AggregateRoot) GetUncommittedEvents() []Event {
    return a.uncommittedEvents
}

func (a *AggregateRoot) MarkEventsAsCommitted() {
    a.uncommittedEvents = []Event{}
}

// Example: Account aggregate
type Account struct {
    AggregateRoot
    Balance  decimal.Decimal
    Currency string
    Status   string
}

func (a *Account) Deposit(amount decimal.Decimal) error {
    if amount.LessThanOrEqual(decimal.Zero) {
        return fmt.Errorf("invalid deposit amount: %v must be positive", amount)
    }
    
    event := MoneyDeposited{
        AccountID: a.ID,
        Amount:    amount,
        Timestamp: time.Now(),
    }
    
    a.Apply(event)
    a.RecordEvent(event)
    return nil
}

func (a *Account) Withdraw(amount decimal.Decimal) error {
    if amount.GreaterThan(a.Balance) {
        return fmt.Errorf("insufficient funds: attempting to withdraw %v from balance %v", amount, a.Balance)
    }
    
    event := MoneyWithdrawn{
        AccountID: a.ID,
        Amount:    amount,
        Timestamp: time.Now(),
    }
    
    a.Apply(event)
    a.RecordEvent(event)
    return nil
}

func (a *Account) Apply(event Event) {
    switch e := event.(type) {
    case MoneyDeposited:
        a.Balance = a.Balance.Add(e.Amount)
    case MoneyWithdrawn:
        a.Balance = a.Balance.Sub(e.Amount)
    }
}&lt;/code&gt;
    &lt;head rend="h2"&gt;CQRS: Command and Query Separation&lt;/head&gt;
    &lt;code&gt;// Write side: Commands modify aggregates
type CommandHandler struct {
    eventStore *EventStore
    eventBus   *EventBus
}

func (h *CommandHandler) Handle(cmd Command) error {
    switch c := cmd.(type) {
    case DepositMoney:
        return h.handleDeposit(c)
    case WithdrawMoney:
        return h.handleWithdraw(c)
    }
    return errors.New("unknown command")
}

func (h *CommandHandler) handleDeposit(cmd DepositMoney) error {
    // Load aggregate from events
    account := &amp;amp;Account{}
    events, err := h.eventStore.GetEvents(ctx, cmd.AccountID, 0)
    if err != nil {
        return err
    }
    
    for _, e := range events {
        account.Apply(e)
    }
    
    // Execute business logic
    err = account.Deposit(cmd.Amount)
    if err != nil {
        return err
    }
    
    // Save new events
    err = h.eventStore.SaveEvents(
        ctx, 
        account.ID, 
        "Account",
        account.GetUncommittedEvents(),
        account.Version,
    )
    if err != nil {
        return err
    }
    
    // Publish for projections
    for _, event := range account.GetUncommittedEvents() {
        h.eventBus.Publish(event)
    }
    
    return nil
}

// Read side: Projections for queries
type AccountProjection struct {
    db *sql.DB
}

func (p *AccountProjection) Handle(event Event) error {
    switch e := event.(type) {
    case MoneyDeposited:
        _, err := p.db.Exec(`
            UPDATE account_projections 
            SET balance = balance + $1, updated_at = NOW()
            WHERE account_id = $2`,
            e.Amount, e.AccountID,
        )
        return err
        
    case MoneyWithdrawn:
        _, err := p.db.Exec(`
            UPDATE account_projections 
            SET balance = balance - $1, updated_at = NOW()
            WHERE account_id = $2`,
            e.Amount, e.AccountID,
        )
        return err
    }
    return nil
}

// Query handler reads from projections
type QueryHandler struct {
    db *sql.DB
}

func (q *QueryHandler) GetAccountBalance(accountID string) (decimal.Decimal, error) {
    var balance decimal.Decimal
    err := q.db.QueryRow(`
        SELECT balance FROM account_projections WHERE account_id = $1`,
        accountID,
    ).Scan(&amp;amp;balance)
    return balance, err
}&lt;/code&gt;
    &lt;head rend="h3"&gt;‚ö†Ô∏è Eventual Consistency Tradeoff&lt;/head&gt;
    &lt;p&gt;CQRS introduces eventual consistency between write and read models:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Events are written immediately to the event store&lt;/item&gt;
      &lt;item&gt;Projections update asynchronously (typically milliseconds to seconds)&lt;/item&gt;
      &lt;item&gt;Queries may return stale data until projections catch up&lt;/item&gt;
      &lt;item&gt;Design your UX to handle this: optimistic UI updates, "processing" states, or read-your-writes guarantees where critical&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Snapshots for Performance&lt;/head&gt;
    &lt;code&gt;type Snapshot struct {
    AggregateID string
    Version     int
    Data        []byte
    CreatedAt   time.Time
}

func (es *EventStore) SaveSnapshot(ctx context.Context, snapshot Snapshot) error {
    _, err := es.db.ExecContext(ctx, `
        INSERT INTO snapshots (aggregate_id, version, data, created_at)
        VALUES ($1, $2, $3, $4)
        ON CONFLICT (aggregate_id) 
        DO UPDATE SET version = $2, data = $3, created_at = $4`,
        snapshot.AggregateID,
        snapshot.Version,
        snapshot.Data,
        snapshot.CreatedAt,
    )
    return err
}

func (es *EventStore) GetSnapshot(ctx context.Context, aggregateID string) (*Snapshot, error) {
    var s Snapshot
    err := es.db.QueryRowContext(ctx, `
        SELECT aggregate_id, version, data, created_at
        FROM snapshots
        WHERE aggregate_id = $1`,
        aggregateID,
    ).Scan(&amp;amp;s.AggregateID, &amp;amp;s.Version, &amp;amp;s.Data, &amp;amp;s.CreatedAt)
    
    if err == sql.ErrNoRows {
        return nil, nil
    }
    return &amp;amp;s, err
}

// Load aggregate with snapshot optimization
func LoadAccount(es *EventStore, accountID string) (*Account, error) {
    account := &amp;amp;Account{}
    
    // Try to load snapshot
    snapshot, err := es.GetSnapshot(ctx, accountID)
    if err != nil {
        return nil, err
    }
    
    fromVersion := 0
    if snapshot != nil {
        // Restore from snapshot
        err = json.Unmarshal(snapshot.Data, account)
        if err != nil {
            return nil, err
        }
        fromVersion = snapshot.Version
    }
    
    // Apply events after snapshot
    events, err := es.GetEvents(ctx, accountID, fromVersion)
    if err != nil {
        return nil, err
    }
    
    for _, e := range events {
        account.Apply(e)
    }
    
    // Create new snapshot every 100 events
    if len(events) &amp;gt; 100 {
        snapshotData, _ := json.Marshal(account)
        es.SaveSnapshot(ctx, Snapshot{
            AggregateID: accountID,
            Version:     account.Version,
            Data:        snapshotData,
            CreatedAt:   time.Now(),
        })
    }
    
    return account, nil
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Event Streaming with Kafka&lt;/head&gt;
    &lt;code&gt;type EventStreamer struct {
    eventStore *EventStore
    producer   *kafka.Writer
    lastSeq    int64
}

func (s *EventStreamer) StreamEvents(ctx context.Context) {
    ticker := time.NewTicker(100 * time.Millisecond)
    defer ticker.Stop()
    
    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case &amp;lt;-ticker.C:
            s.publishNewEvents(ctx)
        }
    }
}

func (s *EventStreamer) publishNewEvents(ctx context.Context) {
    rows, err := s.eventStore.db.QueryContext(ctx, `
        SELECT 
            global_sequence, aggregate_id, event_type, 
            event_data, occurred_at
        FROM events
        WHERE global_sequence &amp;gt; $1
        ORDER BY global_sequence
        LIMIT 1000`,
        s.lastSeq,
    )
    if err != nil {
        return
    }
    defer rows.Close()
    
    var messages []kafka.Message
    var maxSeq int64
    
    for rows.Next() {
        var seq int64
        var aggregateID, eventType string
        var eventData json.RawMessage
        var occurredAt time.Time
        
        rows.Scan(&amp;amp;seq, &amp;amp;aggregateID, &amp;amp;eventType, &amp;amp;eventData, &amp;amp;occurredAt)
        
        messages = append(messages, kafka.Message{
            Topic: fmt.Sprintf("events.%s", eventType),
            Key:   []byte(aggregateID),
            Value: eventData,
            Headers: []kafka.Header{
                {Key: "event_type", Value: []byte(eventType)},
                {Key: "occurred_at", Value: []byte(occurredAt.Format(time.RFC3339))},
            },
        })
        
        maxSeq = seq
    }
    
    if len(messages) &amp;gt; 0 {
        err := s.producer.WriteMessages(ctx, messages...)
        if err == nil {
            s.lastSeq = maxSeq
        }
    }
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Temporal Queries (Time Travel)&lt;/head&gt;
    &lt;code&gt;// Get account state at specific point in time
func (es *EventStore) GetAggregateAtTime(ctx context.Context, aggregateID string, pointInTime time.Time) (*Account, error) {
    events, err := es.db.QueryContext(ctx, `
        SELECT event_type, event_data
        FROM events
        WHERE aggregate_id = $1 AND occurred_at &amp;lt;= $2
        ORDER BY event_version`,
        aggregateID, pointInTime,
    )
    if err != nil {
        return nil, err
    }
    defer events.Close()
    
    account := &amp;amp;Account{}
    for events.Next() {
        var eventType string
        var eventData json.RawMessage
        events.Scan(&amp;amp;eventType, &amp;amp;eventData)
        
        event := deserializeEvent(eventType, eventData)
        account.Apply(event)
    }
    
    return account, nil
}

// Replay events for debugging
func ReplayEvents(es *EventStore, from, to time.Time, handler func(Event)) error {
    rows, err := es.db.Query(`
        SELECT event_type, event_data, occurred_at
        FROM events
        WHERE occurred_at BETWEEN $1 AND $2
        ORDER BY global_sequence`,
        from, to,
    )
    if err != nil {
        return err
    }
    defer rows.Close()
    
    for rows.Next() {
        var eventType string
        var eventData json.RawMessage
        var occurredAt time.Time
        
        rows.Scan(&amp;amp;eventType, &amp;amp;eventData, &amp;amp;occurredAt)
        event := deserializeEvent(eventType, eventData)
        handler(event)
    }
    
    return nil
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Saga Pattern for Distributed Transactions&lt;/head&gt;
    &lt;code&gt;type TransferSaga struct {
    ID          string
    FromAccount string
    ToAccount   string
    Amount      decimal.Decimal
    State       string
    CompletedSteps []string
}

func (s *TransferSaga) Handle(event Event) ([]Command, error) {
    switch e := event.(type) {
    case TransferInitiated:
        return []Command{
            WithdrawMoney{AccountID: e.FromAccount, Amount: e.Amount},
        }, nil
        
    case MoneyWithdrawn:
        if e.AccountID == s.FromAccount {
            s.CompletedSteps = append(s.CompletedSteps, "withdrawn")
            return []Command{
                DepositMoney{AccountID: s.ToAccount, Amount: s.Amount},
            }, nil
        }
        
    case MoneyDeposited:
        if e.AccountID == s.ToAccount {
            s.State = "completed"
            return []Command{
                MarkTransferComplete{TransferID: s.ID},
            }, nil
        }
        
    case WithdrawFailed:
        s.State = "failed"
        return nil, nil
        
    case DepositFailed:
        // Compensate - refund the withdrawal
        return []Command{
            DepositMoney{AccountID: s.FromAccount, Amount: s.Amount},
        }, nil
    }
    
    return nil, nil
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Event Store Consistency Warning&lt;/head&gt;
    &lt;p&gt;Event stores require careful attention to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optimistic concurrency control to prevent data corruption&lt;/item&gt;
      &lt;item&gt;Event ordering guarantees within aggregates&lt;/item&gt;
      &lt;item&gt;Backup and recovery procedures for event streams&lt;/item&gt;
      &lt;item&gt;Event schema evolution and versioning strategies&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Security Considerations&lt;/head&gt;
    &lt;head rend="h3"&gt;Event Sourcing Security Best Practices&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Event Encryption: Encrypt sensitive data in event payloads&lt;/item&gt;
      &lt;item&gt;Access Control: Role-based access to event streams and projections&lt;/item&gt;
      &lt;item&gt;Audit Trail: Include user context and authorization in event metadata&lt;/item&gt;
      &lt;item&gt;Data Privacy: Implement "right to be forgotten" through cryptographic erasure&lt;/item&gt;
      &lt;item&gt;Replay Security: Ensure event replay doesn't bypass current security rules&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;// Secure event with encryption
type SecureEvent struct {
    BaseEvent
    EncryptedPayload []byte
    KeyID           string
    Nonce           []byte
}

// GDPR-compliant cryptographic erasure
type GDPREventStore struct {
    *EventStore
    keyManager *KeyManager
}

func (ges *GDPREventStore) ForgetUser(ctx context.Context, userID string) error {
    events, err := ges.GetEventsByUser(ctx, userID)
    if err != nil {
        return fmt.Errorf("failed to find user events: %w", err)
    }
    
    for _, event := range events {
        if err := ges.keyManager.RevokeKey(event.KeyID); err != nil {
            return fmt.Errorf("failed to revoke key %s: %w", event.KeyID, err)
        }
    }
    
    return ges.MarkUserForgotten(ctx, userID)
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Testing Strategy&lt;/head&gt;
    &lt;head rend="h3"&gt;üìä Event Sourcing Testing Framework&lt;/head&gt;
    &lt;p&gt;Comprehensive testing approach for event-sourced systems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Event Store Tests: Test consistency, concurrency, and durability&lt;/item&gt;
      &lt;item&gt;Aggregate Tests: Unit test business logic and invariants&lt;/item&gt;
      &lt;item&gt;Projection Tests: Verify read model consistency&lt;/item&gt;
      &lt;item&gt;Integration Tests: End-to-end command/query flows&lt;/item&gt;
      &lt;item&gt;Event Schema Tests: Test event evolution and migration&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;// Event store integration test
func TestEventStore(t *testing.T) {
    es := setupTestEventStore(t)
    defer es.Close()
    
    t.Run("ConcurrencyControl", func(t *testing.T) {
        aggregateID := uuid.New().String()
        
        // First save succeeds
        err := es.SaveEvents(context.Background(), aggregateID, "Account", 
            []Event{&amp;amp;AccountOpened{AccountID: aggregateID}}, 0)
        require.NoError(t, err)
        
        // Second save with wrong version fails
        err = es.SaveEvents(context.Background(), aggregateID, "Account", 
            []Event{&amp;amp;MoneyDeposited{AccountID: aggregateID}}, 0)
        require.Error(t, err)
        require.Contains(t, err.Error(), "concurrency conflict")
    })
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Production Monitoring&lt;/head&gt;
    &lt;code&gt;// Event store metrics
type Metrics struct {
    EventsWritten   prometheus.Counter
    EventsRead      prometheus.Counter
    SnapshotCreated prometheus.Counter
    WriteLatency    prometheus.Histogram
    ReadLatency     prometheus.Histogram
}

// Health checks
func (es *EventStore) HealthCheck() error {
    // Check write capability
    testEvent := HealthCheckEvent{
        ID:        uuid.New().String(),
        Timestamp: time.Now(),
    }
    
    err := es.SaveEvents(ctx, "health", "HealthCheck", []Event{testEvent}, 0)
    if err != nil {
        return fmt.Errorf("write check failed: %w", err)
    }
    
    // Check read capability
    events, err := es.GetEvents(ctx, "health", 0)
    if err != nil {
        return fmt.Errorf("read check failed: %w", err)
    }
    
    if len(events) == 0 {
        return errors.New("no events found")
    }
    
    return nil
}

// Lag monitoring
func MonitorProjectionLag(db *sql.DB) {
    ticker := time.NewTicker(10 * time.Second)
    for range ticker.C {
        var lag time.Duration
        db.QueryRow(`
            SELECT MAX(NOW() - updated_at) 
            FROM projection_checkpoints`
        ).Scan(&amp;amp;lag)
        
        projectionLag.Set(lag.Seconds())
        
        if lag &amp;gt; 5*time.Minute {
            alert("Projection lag exceeds 5 minutes")
        }
    }
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Performance Optimizations&lt;/head&gt;
    &lt;code&gt;// 1. Batch event writes
func (es *EventStore) SaveEventsBatch(events []EventWithAggregate) error {
    // Use COPY for bulk insert
    stmt, err := es.db.Prepare(pq.CopyIn("events",
        "aggregate_id", "aggregate_type", "event_type",
        "event_version", "event_data", "occurred_at"))
    if err != nil {
        return err
    }
    
    for _, e := range events {
        _, err = stmt.Exec(e.AggregateID, e.AggregateType,
            e.EventType, e.Version, e.Data, e.OccurredAt)
        if err != nil {
            return err
        }
    }
    
    return stmt.Close()
}

// 2. Parallel projection updates
func UpdateProjectionsParallel(events []Event) {
    var wg sync.WaitGroup
    ch := make(chan Event, 100)
    
    // Start workers
    for i := 0; i &amp;lt; 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for event := range ch {
                updateProjection(event)
            }
        }()
    }
    
    // Send events
    for _, e := range events {
        ch &amp;lt;- e
    }
    close(ch)
    wg.Wait()
}

// 3. Cache aggregates
var aggregateCache = cache.New(5*time.Minute, 10*time.Minute)

func LoadAccountCached(es *EventStore, accountID string) (*Account, error) {
    if cached, found := aggregateCache.Get(accountID); found {
        return cached.(*Account), nil
    }
    
    account, err := LoadAccount(es, accountID)
    if err != nil {
        return nil, err
    }
    
    aggregateCache.Set(accountID, account, cache.DefaultExpiration)
    return account, nil
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Migration from Traditional System&lt;/head&gt;
    &lt;code&gt;// Generate events from existing state
func MigrateToEventSourcing(db *sql.DB, es *EventStore) error {
    rows, err := db.Query(`
        SELECT id, balance, created_at, updated_at
        FROM accounts`)
    if err != nil {
        return err
    }
    defer rows.Close()
    
    for rows.Next() {
        var id string
        var balance decimal.Decimal
        var createdAt, updatedAt time.Time
        
        rows.Scan(&amp;amp;id, &amp;amp;balance, &amp;amp;createdAt, &amp;amp;updatedAt)
        
        // Create initial event
        events := []Event{
            AccountOpened{
                AccountID: id,
                Timestamp: createdAt,
            },
        }
        
        // Infer deposit event from balance
        if balance.GreaterThan(decimal.Zero) {
            events = append(events, MoneyDeposited{
                AccountID: id,
                Amount:    balance,
                Timestamp: updatedAt,
            })
        }
        
        es.SaveEvents(ctx, id, "Account", events, 0)
    }
    
    return nil
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Lessons from Production&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Before (CRUD)&lt;/cell&gt;
        &lt;cell role="head"&gt;After (Event Sourcing)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Write throughput&lt;/cell&gt;
        &lt;cell&gt;1K/sec&lt;/cell&gt;
        &lt;cell&gt;10K/sec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Read latency p99&lt;/cell&gt;
        &lt;cell&gt;5ms&lt;/cell&gt;
        &lt;cell&gt;2ms (projections)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Audit completeness&lt;/cell&gt;
        &lt;cell&gt;60%&lt;/cell&gt;
        &lt;cell&gt;100%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Debug time&lt;/cell&gt;
        &lt;cell&gt;Hours&lt;/cell&gt;
        &lt;cell&gt;Minutes (replay)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Storage cost&lt;/cell&gt;
        &lt;cell&gt;$1K/month&lt;/cell&gt;
        &lt;cell&gt;$3-5K/month&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;When NOT to Use Event Sourcing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CRUD is sufficient (most apps)&lt;/item&gt;
      &lt;item&gt;No audit requirements&lt;/item&gt;
      &lt;item&gt;Simple domain logic&lt;/item&gt;
      &lt;item&gt;Team unfamiliar with the pattern&lt;/item&gt;
      &lt;item&gt;Storage cost is critical&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Verdict&lt;/head&gt;
    &lt;p&gt;Event sourcing isn't free. 3-5x storage cost (events + projections + snapshots). Complex to implement. Mental model shift.&lt;/p&gt;
    &lt;p&gt;But for financial systems, audit-heavy domains, or complex business logic? It's transformative. Complete history, perfect audit trail, time travel debugging, and horizontal scalability.&lt;/p&gt;
    &lt;p&gt;Start small: Event source one aggregate. See the benefits. Then expand. Don't go all-in immediately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45962656</guid><pubDate>Tue, 18 Nov 2025 08:18:43 +0000</pubDate></item><item><title>The Connectivity Standards Alliance Announces Zigbee 4.0 and Suzi</title><link>https://csa-iot.org/newsroom/the-connectivity-standards-alliance-announces-zigbee-4-0-and-suzi-empowering-the-next-generation-of-secure-interoperable-iot-devices/</link><description>&lt;doc fingerprint="e6f1189c4330f441"&gt;
  &lt;main&gt;
    &lt;p&gt;DAVIS, California ‚Äì November 18, 2025 ‚Äì The Connectivity Standards Alliance (Alliance) announced today the release of Zigbee 4.0 and Suzi, the new brand for Zigbee‚Äôs Sub-GHz feature, two major milestones in advancing the foundation of secure, interoperable, and scalable IoT connectivity with a range of optional features, enabling product manufacturers to choose the specific set that best fits their product‚Äôs use case and needs. Together, these innovations mark the next evolution of Zigbee technology, building on decades of proven performance to deliver greater range, reliability, and security across global networks.&lt;/p&gt;
    &lt;head rend="h4"&gt;Strengthening Security, Range, and Interoperability&lt;/head&gt;
    &lt;p&gt;Zigbee 4.0 lays the groundwork for harmonizing traditional Zigbee and Smart Energy devices, delivering greater interoperability across universal networks. This release simplifies certification processes and supports enhanced information exchange, creating a more complete smart home solution. Comprehensive and proactive security updates aligned with evolving international security standards implement cryptographic agility and additional mechanisms to protect the network. Extending its capabilities beyond the 2.4GHz band, Zigbee 4.0 introduces support for the European 800 MHz and North American 900 MHz PHY, providing increased signal strength, range, and coverage. Fully backward compatible with Zigbee 3.0 and Smart Energy, it ensures continuity with more than a billion Zigbee devices already deployed worldwide while introducing improvements to network stability, user experience, and device commissioning in dense networks.&lt;/p&gt;
    &lt;p&gt;Delivering significant security enhancements aligned with evolving global standards, the latest release reinforces Zigbee‚Äôs position as a trusted solution for secure, modern connectivity. Advanced capabilities such as Dynamic Link Key, Device Interview, and Smart Energy Authentication Level Control offer greater control and resilience across connected networks. These capabilities strengthen device authentication, enable selective communication based on security levels, and ensure only trusted devices join the network. New tools such as Restricted Mode, Secured Channel, PAN ID Changes, and Trust Center Swap Out offer improved flexibility and management for ecosystems and installers by enhancing protection, allowing efficient Trust Center replacement, and preventing unauthorized network changes.&lt;/p&gt;
    &lt;p&gt;With Advanced Frame Counter Synchronization, Zigbee 4.0 prevents replay attacks and synchronizes precise message validation between endpoints. Robust improvements such as standardized network-level retries, more reliable data polling for sleepy end devices, and expanded use of APS acknowledgements increase overall network performance and reduce message loss. Features like Formalized Parent Selection, Unique Link Key Monitoring, and Trust Center Connectivity improve network resilience, ensuring that devices maintain secure connections, can rejoin when necessary, and operate even in complex network environments.&lt;/p&gt;
    &lt;p&gt;Elevating both usability and scalability, Zigbee 4.0 is designed to simplify and strengthen device interoperability. Through Zigbee Direct, users can seamlessly onboard and control devices via Bluetooth Low Energy (BLE) without a hub. Batch Commissioning enables efficient, simultaneous setup of multiple devices, simplifying residential and commercial deployments. Additionally, sleepy-to-sleepy communication using Coordinated Sample Listening (CSL) allows direct, low-power exchanges between devices, optimizing energy and further extending battery life. Collectively, these advancements position Zigbee 4.0 as a forward-looking standard, continuing to evolve with industry needs and future market requirements.&lt;/p&gt;
    &lt;head rend="h4"&gt;Introducing Suzi: Expanding Connectivity Through Long-Range Mesh Networking&lt;/head&gt;
    &lt;p&gt;Alongside Zigbee 4.0, the Alliance introduces Suzi, the new brand for the standards-based wireless technology that extends the reach and reliability of IoT connectivity through long-range, Sub-GHz mesh networking.&lt;/p&gt;
    &lt;p&gt;Built on the proven Zigbee network layer, Suzi combines long-range performance, low power consumption, and multi-vendor interoperability to unlock new opportunities in residential, commercial, and industrial applications. From connecting outdoor living spaces to enabling large-scale networks in buildings and cities, Suzi delivers robust, efficient communication in environments demanding extended coverage and minimal interference.&lt;/p&gt;
    &lt;p&gt;Adhering to the same strong security principles that define all Alliance technologies, Suzi aligns with international standards to ensure a secure and trusted ecosystem. Its framework allows developers, manufacturers, and consumers the freedom to build and deploy interoperable devices from a global ecosystem of trusted suppliers.&lt;/p&gt;
    &lt;p&gt;The Suzi Certification Program is planned to open in the first half of 2026, enabling manufacturers to begin certifying products that bring the benefits of long-range, low-power mesh networking to the connected world.&lt;/p&gt;
    &lt;head rend="h4"&gt;A Connected Future, Built on Proven Foundations&lt;/head&gt;
    &lt;p&gt;Together, Zigbee 4.0 and Suzi demonstrate the Alliance‚Äôs dedication to strengthening global IoT networks through open innovation and collective progress. By combining enhanced security, simplified onboarding, and extended range, these new features expand the reach and resilience of the smart ecosystem, making secure, intelligent connectivity accessible everywhere.&lt;/p&gt;
    &lt;p&gt;Learn more about Zigbee and Suzi. Developers interested in learning more about these enhancements can access the Zigbee 4.0 specification documents here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zigbee Base Device Behavior v3.1 Specification&lt;/item&gt;
      &lt;item&gt;Zigbee Core R23.2 Specification&lt;/item&gt;
      &lt;item&gt;Zigbee Device Type Library v1.0 Specification&lt;/item&gt;
      &lt;item&gt;Zigbee Direct v1.1 Specification&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;About the Connectivity Standards Alliance&lt;/head&gt;
    &lt;p&gt;The Connectivity Standards Alliance is the foundation and future of the Internet of Things (IoT). Established in 2002, its wide-ranging global membership collaborates to create and evolve universal open standards for the products transforming the way we live, work, and play. With its Members‚Äô deep and diverse expertise, robust certification programs, and a full suite of open IoT solutions, the Alliance is leading the movement toward a more intuitive, imaginative, and useful world.&lt;/p&gt;
    &lt;p&gt;The Connectivity Standards Alliance Board of Directors is comprised of executives Allegion, Amazon, Apple, ASSA ABLOY, Bosch, CableLabs, Comcast, Espressif, Eve by ABB, Fortune Brands, Google, Haier, Huawei, IKEA, Infineon Technologies AG, LEEDARSON, Legrand, LG Electronics, Lutron Electronics, Midea, Nordic Semiconductor, NXP Semiconductors, OPPO, Resideo Technologies, Samsung Electronics, Schneider Electric, Siemens, Signify (Philips Hue and WiZ), Silicon Labs, Somfy, STMicroelectronics, Tuya, and Verizon.&lt;/p&gt;
    &lt;p&gt;Learn more about the Alliance at www.csa-iot.org; and follow us on: X, Facebook, and LinkedIn.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45969398</guid><pubDate>Tue, 18 Nov 2025 17:35:31 +0000</pubDate></item><item><title>Building a Durable Execution Engine with SQLite</title><link>https://www.morling.dev/blog/building-durable-execution-engine-with-sqlite/</link><description>&lt;doc fingerprint="781aca9ef520504b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building a Durable Execution Engine With SQLite&lt;/head&gt;
    &lt;p&gt;Update November 21: This post is being discussed on Hacker News&lt;/p&gt;
    &lt;p&gt;Lately, there has been a lot of excitement around Durable Execution (DE) engines. The basic idea of DE is to take (potentially long-running) multi-step workflows, such as processing a purchase order or a user sign-up, and make their individual steps persistent. If a flow gets interrupted while running, for instance due to a machine failure, the DE engine can resume it from the last successfully executed step and drive it to completion.&lt;/p&gt;
    &lt;p&gt;This is a very interesting value proposition: the progress of critical business processes is captured reliably, ensuring they‚Äôll complete eventually. Importantly, any steps performed already successfully won‚Äôt be repeated when retrying a failed flow. This helps to ensure that flows are executed correctly (for instance preventing inventory from getting assigned twice to the same purchase order), efficiently (e.g. avoiding repeated remote API calls), and deterministically. One particular category of software which benefits from this are agentic systems, or more generally speaking, any sort of system which interacts with LLMs. LLM calls are slow and costly, and their results are non-deterministic. So it is desirable to avoid repeating any previous LLM calls when continuing an agentic flow after a failure.&lt;/p&gt;
    &lt;p&gt;Now, at a high level, "durable execution" is nothing new. A scheduler running a batch job for moving purchase orders through their lifecycle? You could consider this a form of durable execution. Sending a Kafka message from one microservice to another and reacting to the response message in a callback? Also durable execution, if you squint a little. A workflow engine running a BPMN job? Implementing durable execution, before the term actually got popularized. All these approaches model multi-step business transactions‚Äîmaking the logical flow of the overall transaction more or less explicit‚Äîin a persistent way, ensuring that transactions progress safely and reliably and eventually complete.&lt;/p&gt;
    &lt;p&gt;However, modern DE typically refers to one particular approach for achieving this goal: Workflows defined in code, using general purpose programming languages such as Python, TypeScript, or Java. That way, developers don‚Äôt need to pick up a new language for defining flows, as was the case with earlier process automation platforms. They can use their familiar tooling for editing flows, versioning them, etc. A DE engine transparently tracks program progress, persists execution state in the form of durable checkpoints, and enables resumption after failures.&lt;/p&gt;
    &lt;p&gt;Naturally, this piqued my interest: what would it take to implement a basic DE engine in Java? Can we achieve something useful with less than, let‚Äôs say, 1,000 lines of code? The idea being not to build a production-ready engine, but to get a better understanding of the problem space and potential solutions for it. You can find the result of this exploration, called Persistasaurus, in this GitHub repository. Coincidentally, this project also serves as a very nice example of how modern Java versions can significantly simplify the life of developers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hello Persistasaurus!&lt;/head&gt;
    &lt;p&gt;Let‚Äôs take a look at an example of what you can do with Persistasaurus and then dive into some of the key implementation details. As per the idea of DE, flows are implemented as regular Java code. The entry point of a flow is a method marked with the &lt;code&gt;@Flow&lt;/code&gt; annotation.
Individual flow steps are methods annotated with &lt;code&gt;@Step&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Steps are the unit of persistence‚Äîtheir outcomes are recorded, and when resuming a flow after a failure, it will continue from the last successfully run step method. Now, which exact parts of a flow warrant being persisted as a step is on the developer to decide. You don‚Äôt want to define steps too granularly, so as to keep the overhead of logging low. In general, flow sections which are costly or time-consuming to run or whose result cannot easily be reproduced, are great candidates for being moved into a step method.&lt;/p&gt;
    &lt;p&gt;A flow is executed by obtaining a &lt;code&gt;FlowInstance&lt;/code&gt; object and then calling the flow‚Äôs main method:&lt;/p&gt;
    &lt;p&gt;Each flow run is identified by a unique id, allowing to re-execute it after a failure, or to resume it when waiting for an external signal ("human in the loop", more on that below). If the Hello World flow runs to completion, the following will be logged to stdout:&lt;/p&gt;
    &lt;p&gt;Now let‚Äôs assume something goes wrong while executing the third step:&lt;/p&gt;
    &lt;p&gt;When re-running the flow, using the same UUID as before, it will retry that failed step and resume from there. The first two steps which were already run successfully are not re-executed. Instead, they will be replayed from a persistent execution log, which is based on SQLite, an embedded SQL database:&lt;/p&gt;
    &lt;p&gt;In the following, let‚Äôs take a closer look at some of the implementation choices in Persistasaurus.&lt;/p&gt;
    &lt;head rend="h2"&gt;Capturing Execution State&lt;/head&gt;
    &lt;p&gt;At the core of every DE engine there‚Äôs some form of persistent durable execution log. You can think of this a bit like the write-ahead log of a database. It captures the intent to execute a given flow step, which makes it possible to retry that step should it fail, using the same parameter values. Once successfully executed, a step‚Äôs result will also be recorded in the log, so that it can be replayed from there if needed, without having to actually re-execute the step itself.&lt;/p&gt;
    &lt;p&gt;DE logs come in two flavours largely speaking; one is in the form of an external state store which is accessed via some sort of SDK. Example frameworks taking this approach include Temporal, Restate, Resonate, and Inngest. The other option is to persist DE state in the local database of a given application or (micro)service. One solution in this category is DBOS, which implements DE on top of Postgres.&lt;/p&gt;
    &lt;p&gt;To keep things simple, I went with the local database model for Persistasaurus, using SQLite for storing the execution log. But as we‚Äôll see later on, depending on your specific use case, SQLite actually might also be a great choice for a production scenario, for instance when building a self-contained agentic system.&lt;/p&gt;
    &lt;p&gt;The structure of the execution log table in SQLite is straight-forward. It contains one entry for each durable execution step:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;The UUID of the flow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;The sequence number of the step within the flow, in the order of execution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;The timestamp of first running this step&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;The name of the class defining the step method&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;The name of the step method (currently ignoring overloaded methods for this PoC)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;For delayed steps, the delay in milli-seconds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;The current status of the step&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;A counter for keeping track of how many times the step has been tried&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;The serialized form of the step‚Äôs input parameters, if any&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;The serialized form of the step‚Äôs result, if any&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This log table stores all information needed to capture execution intent and persist results. More details on the notion of delays and signals follow further down.&lt;/p&gt;
    &lt;p&gt;When running a flow, the engine needs to know when a given step gets executed so it can be logged. One common way for doing so is via explicit API calls into the engine, e.g. like so with DBOS Transact:&lt;/p&gt;
    &lt;p&gt;This works, but tightly couples workflows to the DE engine‚Äôs API. For Persistaurus I aimed to avoid this dependency as much as possible. Instead, the idea is to transparently intercept the invocations of all step methods and track them in the execution log, allowing for a very concise flow expression, without any API dependencies:&lt;/p&gt;
    &lt;p&gt;In order for the DE engine to know when a flow or step method gets invoked, the proxy pattern is being used: a proxy wraps the actually flow object and handles each of its method invocations, updating the state in the execution log before and after passing the call on to the flow itself. Thanks to Java‚Äôs dynamic nature, creating such a proxy is relatively easy, requiring just a little bit of bytecode generation. Unsurprisingly, I‚Äôm using the ByteBuddy library for this job:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Create a sub-class proxy for the flow type&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Intercept all method invocations on this proxy‚Ä¶&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;‚Ä¶and delegate them to an &lt;code&gt;Interceptor&lt;/code&gt; object&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Load the generated proxy class&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;Instantiate the flow proxy&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As an aside, Claude Code does an excellent job in creating code using the ByteBuddy API, which is not always self-explanatory. Now, whenever a method is invoked on the flow proxy, the call is delegated to the &lt;code&gt;Interceptor&lt;/code&gt; class,
which will record the step in the execution log before invoking the actual flow method.
I am going to spare you the complete details of the method interceptor implementation
(you can find it here on GitHub),
but the high-level logic looks like so:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Replay completed step if present&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Log invocation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Execute the actual step method&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Log result&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Replaying completed steps from the log is essential for ensuring deterministic execution. Each step typically runs exactly once, capturing non-deterministic values such as the current time or random numbers while doing so.&lt;/p&gt;
    &lt;p&gt;There‚Äôs an important failure mode, though: if the system crashes after a step has been executed but before the result can be recorded in the log, that step would be repeated when rerunning the flow. Odds for this to happen are pretty small, but whether it is acceptable or not depends on the particular use case. When executing steps with side-effects, such as remote API calls, it may be a good idea to add idempotency keys to the requests, which lets the invoked services detect and ignore any potential duplicate calls.&lt;/p&gt;
    &lt;p&gt;The actual execution log implementation isn‚Äôt that interesting, you can find its source code here. All it does is persist step invocations and their status in the &lt;code&gt;execution_log&lt;/code&gt; SQLite table shown above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Delayed Executions&lt;/head&gt;
    &lt;p&gt;At this point, we have a basic Durable Execution engine which can run simple flows as the one above. Next, I explored implementing delayed execution steps. As an example, consider a user onboarding flow, where you might want to send out an email with useful resources a few days after a user has signed up. Using the annotation-based programming model of Persistasaurus, this can be expressed like so:&lt;/p&gt;
    &lt;p&gt;Naturally, we don‚Äôt want to block the initiating thread when delaying a step‚Äîfor instance, a web application‚Äôs request handler. Instead, we need a way to temporarily yield execution of the flow, return control to the caller, and then later on, when the configured delay has passed, resume the flow.&lt;/p&gt;
    &lt;p&gt;Unlike other programming languages, Java doesn‚Äôt support continuations via its public API. So how could we yield control then? One option would be to define a specific exception type, let‚Äôs say &lt;code&gt;FlowYieldException&lt;/code&gt;, and raise it from within the method interceptor when encountering a delayed method.
The call stack would be unwound until some framework-provided exception handler catches that exception and returns control to the code triggering the flow.
For this to work, it is essential that no user-provided flow or step code catches that exception type.
Alternatively, one could transform the bytecode of the step method (and all the methods below it in the call stack),
so that it can return control at given suspension points and later on resume from there,
similar to how Kotlin‚Äôs coroutines are implemented under the hood ("continuation passing style").&lt;/p&gt;
    &lt;p&gt;Luckily, Java 21 offers a much simpler solution. This version added support for virtual threads (JEP 444), and while you shouldn‚Äôt block OS level threads, blocking virtual threads is totally fine. Virtual threads are lightweight user-mode threads managed by the JVM, and an application can have hundreds of thousands, or even millions of them at once. Thus I decided to implement delayed executions in Persistasaurus through virtual threads, sleeping for the given period of time when encountering a delayed method.&lt;/p&gt;
    &lt;p&gt;To run a flow with a delayed step, trigger it via &lt;code&gt;runAsync()&lt;/code&gt;,
which immediately returns control to the caller:&lt;/p&gt;
    &lt;p&gt;When putting a virtual thread running a flow method asleep, it will be unmounted from the underlying OS level carrier thread, freeing its resources. Later on, once the sleep time has passed, the virtual thread will be remounted onto a carrier thread and continue the flow. When rerunning non-finished flows with a delayed execution step, Persistasaurus will only sleep for the remainder of the configured delay, which might be zero if enough time has passed since the original run of the flow.&lt;/p&gt;
    &lt;p&gt;So in fact, you could think of virtual threads as a form of continuations; and indeed, if you look closely at the stacktrace of a virtual thread, you‚Äôll see that the frame at the very bottom is the &lt;code&gt;enter()&lt;/code&gt; method of a JDK-internal class &lt;code&gt;Continuation&lt;/code&gt;.
Interestingly, this class was even part of the public Java API in early preview versions of virtual threads,
but it got made private later on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Human Interaction&lt;/head&gt;
    &lt;p&gt;As the last step of my exploration I was curious how flows with "human in the loop"-steps could be implemented: steps where externally provided input or data is required in order for a flow to continue. Sticking to the sign-up flow example, this could be an email by the user, so as to confirm their identity (double opt-in). As much as possible, I tried to stick to the idea of using plain method calls for expressing the flow logic, but I couldn‚Äôt get around making flows invoke a Persistasaurus-specific method, &lt;code&gt;await()&lt;/code&gt;, for signalling that a step requires external input:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Await the invocation of the given step method&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When the method interceptor encounters a step method invoked from within an &lt;code&gt;await()&lt;/code&gt; block,
it doesn‚Äôt go on to actually execute right away.
Instead, the flow will await continuation until the step method gets triggered.
This is why it doesn‚Äôt matter which parameter values are passed to that step within the flow definition.
You could pass &lt;code&gt;null&lt;/code&gt;, or, as a convention, the &lt;code&gt;any()&lt;/code&gt; placeholder method.&lt;/p&gt;
    &lt;p&gt;In order to provide the input to a waiting step and continue the flow, call the step method via &lt;code&gt;resume()&lt;/code&gt;, for instance like so, in a request handler method of a Spring Boot web application:&lt;/p&gt;
    &lt;p&gt;The flow will then continue from that step, using the given parameter value(s) as its input. For this to work, we need a way for the engine to know whether a given step method gets invoked from within &lt;code&gt;resume()&lt;/code&gt; and thus actually should be executed,
or, whether it gets invoked from within &lt;code&gt;await()&lt;/code&gt; and hence should be suspended.&lt;/p&gt;
    &lt;p&gt;Seasoned framework developers might immediately think of using thread-local variables for this purpose, but as of Java 25, this can be solved much more elegantly and safely using so-called scoped values, as defined in JEP 506. To quote that JEP, scoped values&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;enable a method to share immutable data both with its callees within a thread, and with child threads. Scoped values are easier to reason about than thread-local variables. They also have lower space and time costs&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Scoped values are typically defined as as a static field like so:&lt;/p&gt;
    &lt;p&gt;To set the scoped value and run some unit of code with that value, call &lt;code&gt;ScopedValue::where()&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Unlike thread-local variables, this ensures the scoped value is cleared when leaving the scope. Then, further down in the call stack, within the method handler, the scoped value can be consumed:&lt;/p&gt;
    &lt;p&gt;In order to yield control when waiting for external input and to resume when that input has been provided, a &lt;code&gt;ReentrantLock&lt;/code&gt; with a wait condition is used.
Similar to the &lt;code&gt;sleep()&lt;/code&gt; call used for fixed delay steps above,
a virtual thread will be unmounted from its carrier when waiting for a condition.&lt;/p&gt;
    &lt;p&gt;When accidentally trying to access a scoped value which isn‚Äôt actually set, an exception will be raised, addressing another issue you‚Äôd commonly encounter with thread-local variables. This might not seem like a huge deal, but it‚Äôs great to see how the Java platform continues to evolve and improves things like this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Managing State&lt;/head&gt;
    &lt;p&gt;Let‚Äôs dive a bit deeper into managing state in a durable execution engine. For the example DE implementation developed for this blog post, I went with SQLite primarily for the sake of simplicity. Now, would you use SQLite, as an embedded database, also in an actual production-ready implementation? The answer is going to depend on your specific use case. If, for instance, you are building a self-contained AI agent and you want to use DE for making sure LLM invocations are not repeated when the agent crashes, an embedded database such as SQLite would make for a great store for persisting execution state. Each agent could have its own database, thus avoiding any concurrent writes, which can pose a bottleneck due to SQLite‚Äôs single-writer design.&lt;/p&gt;
    &lt;p&gt;On the other hand, if you‚Äôre building a system with a high number of parallel requests by different users, such as a typical microservice, a client/server database such as Postgres or MySQL would be a better fit. If that system already maintains state in a database (as most services do), then re-using that same database to store execution state provides a critical advantage: Updates to the application‚Äôs data and its execution state can happen atomically in a single database transaction, providing atomicity guarantees. This solution is implemented by the DBOS engine, on top of Postgres, for instance.&lt;/p&gt;
    &lt;p&gt;Another category of DE engines which include systems such as Temporal and Restate, utilizes a separate server component with its own dedicated store for persisting execution state. This approach can be very useful to implement flows spanning across a set of multiple services (sometimes referred to as Sagas). By keeping track of the overall execution state in one central place, they essentially avoid the need for cross-system transactions.&lt;/p&gt;
    &lt;p&gt;Another advantage of this approach is that the actual application doesn‚Äôt have to keep running while waiting for delayed execution steps, making it a great fit for systems implemented in the form of scale-to-zero serverless designs (Function-as-a-Service, Knative, etc.). The downside of this centralized design is the potentially closer coupling of the participating services, as they all need to converge on a specific DE engine, on one specific version of that engine, etc. Also HA and fault tolerance must be a priority in order to avoid the creation of a single point of failure between all the orchestrated services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping Up&lt;/head&gt;
    &lt;p&gt;At its heart, the idea of Durable Execution is not a complex one: Potentially long-running workflows are organized into individual steps whose execution status and result is persisted in a durable form. That way, flows become resumable after failures, while skipping any steps already executed successfully. You could think of it as a persistent implementation of the memoization pattern, or a persistent form of continuations.&lt;/p&gt;
    &lt;p&gt;As demonstrated in this post and the accompanying source code, it doesn‚Äôt take too much work to create a functioning PoC for a DE engine. Of course, it‚Äôs still quite a way to go from there to a system you‚Äôd actually want to put into production. At the persistence level, you‚Äôd have to address aspects such as (horizontal) scalability, fault tolerance and HA. The engine should support things such as retrying failing steps with exponential back-off, parallel execution of workflow steps, throttling flow executions, compensation steps for implementing Sagas, and more. You‚Äôd also want to have a UI for managing flows, analyzing, restarting, and debugging them. Finally, you should also have a strategy for evolving flow definitions and the state they persist, in particular when dealing with long-running flows which may take days, weeks, or months to complete.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45992316</guid><pubDate>Thu, 20 Nov 2025 13:26:08 +0000</pubDate></item><item><title>We should all be using dependency cooldowns</title><link>https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns</link><description>&lt;doc fingerprint="af811b9b5ac90ef0"&gt;
  &lt;main&gt;
    &lt;p&gt;Nov 21, 2025 Tags: oss, security&lt;/p&gt;
    &lt;p&gt;TL;DR: Dependency cooldowns are a free, easy, and incredibly effective way to mitigate the large majority of open source supply chain attacks. More individual projects should apply cooldowns (via tools like Dependabot and Renovate) to their dependencies, and packaging ecosystems should invest in first-class support for cooldowns directly in their package managers.&lt;/p&gt;
    &lt;p&gt;√¢Supply chain security√¢ is a serious problem. It√¢s also seriously overhyped, in part because dozens of vendors have a vested financial interest in convincing your that their framing of the underlying problem1 is (1) correct, and (2) worth your money.&lt;/p&gt;
    &lt;p&gt;What√¢s consternating about this is that most open source supply chain attacks have the same basic structure:&lt;/p&gt;
    &lt;p&gt;An attacker compromises a popular open source project, typically via a stolen credential or CI/CD vulnerabilty (such as √¢pwn requests√¢ in GitHub Actions).&lt;/p&gt;
    &lt;p&gt;The attacker introduces a malicious change to the project and uploads it somewhere that will have maximum effect (PyPI, npm, GitHub releases, &amp;amp;c., depending on the target).&lt;/p&gt;
    &lt;p&gt;At this point, the clock has started, as the attacker has moved into the public.&lt;/p&gt;
    &lt;p&gt;Users pick up the compromised version of the project via automatic dependency updates or a lack of dependency pinning.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the aforementioned vendors are scanning public indices as well as customer repositories for signs of compromise, and provide alerts upstream (e.g. to PyPI).&lt;/p&gt;
    &lt;p&gt;Notably, vendors are incentivized to report quickly and loudly upstream, as this increases the perceived value of their services in a crowded field.&lt;/p&gt;
    &lt;p&gt;Upstreams (PyPI, npm, &amp;amp;c.) remove or disable the compromised package version(s).&lt;/p&gt;
    &lt;p&gt;End-user remediation begins.&lt;/p&gt;
    &lt;p&gt;The key thing to observe is that the gap between (1) and (2) can be very large2 (weeks or months), while the gap between (2) and (5) is typically very small: hours or days. This means that, once the attacker has moved into the actual exploitation phase, their window of opportunity to cause damage is pretty limited.&lt;/p&gt;
    &lt;p&gt;We can see this with numerous prominent supply chain attacks over the last 18 months3:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Attack&lt;/cell&gt;
        &lt;cell role="head"&gt;Approx. Window of Opportunity&lt;/cell&gt;
        &lt;cell role="head"&gt;References&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;xz-utils&lt;/cell&gt;
        &lt;cell&gt;√¢ 5 weeks4&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ultralytics (phase 1)&lt;/cell&gt;
        &lt;cell&gt;12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ultralytics (phase 2)&lt;/cell&gt;
        &lt;cell&gt;1 hour&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tj-actions&lt;/cell&gt;
        &lt;cell&gt;3 days&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;chalk&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Nx&lt;/cell&gt;
        &lt;cell&gt;4 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;rspack&lt;/cell&gt;
        &lt;cell&gt;1 hour&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;num2words&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Kong Ingress Controller&lt;/cell&gt;
        &lt;cell&gt;√¢ 10 days&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;web3.js&lt;/cell&gt;
        &lt;cell&gt;5 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;(Each of these attacks has significant downstream effect, of course, but only within their window of opportunity. Subsequent compromises from each, like Shai-Hulud, represent new windows of opportunity where the attackers regrouped and pivoted onto the next set of compromised credentials.)&lt;/p&gt;
    &lt;p&gt;My takeaway from this: some windows of opportunity are bigger, but the majority of them are under a week long. Consequently, ordinary developers can avoid the bulk of these types of attacks by instituting cooldowns on their dependencies.&lt;/p&gt;
    &lt;p&gt;A √¢cooldown√¢ is exactly what it sounds like: a window of time between when a dependency is published and when it√¢s considered suitable for use. The dependency is public during this window, meaning that √¢supply chain security√¢ vendors can work their magic while the rest of us wait any problems out.&lt;/p&gt;
    &lt;p&gt;I love cooldowns for several reasons:&lt;/p&gt;
    &lt;p&gt;They√¢re empirically effective, per above. They won√¢t stop all attackers, but they do stymie the majority of high-visibiity, mass-impact supply chain attacks that have become more common.&lt;/p&gt;
    &lt;p&gt;They√¢re incredibly easy to implement. Moreover, they√¢re literally free to implement in most cases: most people can use Dependabot√¢s functionality, Renovate√¢s functionality, or the functionality build directly into their package manager5.&lt;/p&gt;
    &lt;p&gt;This is how simple it is in Dependabot:&lt;/p&gt;
    &lt;p&gt;(Rinse and repeat for other ecosystems as needed.)&lt;/p&gt;
    &lt;p&gt;Cooldowns enforce positive behavior from supply chain security vendors: vendors are still incentivized to discover and report attacks quickly, but are not as incentivized to emit volumes of blogspam about √¢critical√¢ attacks on largely underfunded open source ecosystems.&lt;/p&gt;
    &lt;p&gt;In the very small sample set above, 8/10 attacks had windows of opportunity of less than a week. Setting a cooldown of 7 days would have prevented the vast majority of these attacks from reaching end users (and causing knock-on attacks, which several of these were). Increasing the cooldown to 14 days would have prevented all but 1 of these attacks6.&lt;/p&gt;
    &lt;p&gt;Cooldowns are, obviously, not a panacea: some attackers will evade detection, and delaying the inclusion of potentially malicious dependencies by a week (or two) does not fundamentally alter the fact that supply chain security is a social trust problem, not a purely technical one. Still, an 80-90% reduction in exposure through a technique that is free and easy seems hard to beat.&lt;/p&gt;
    &lt;p&gt;Related to the above, it√¢s unfortunate that cooldowns aren√¢t baked directly into more packaging ecosystems: Dependabot and Renovate are great, but even better would be if the package manager itself (as the source of ground truth) could enforce cooldowns directly (including of dependencies not introduced or bumped through automated flows).&lt;/p&gt;
    &lt;p&gt;The problem being, succinctly: modern software stacks are complex and opaque, with little to no difference in privilege between first-party code and third-party dependencies.√Ç ‚Ü©&lt;/p&gt;
    &lt;p&gt;In part because of the prevalence of long-lived, overscoped credentials. Long-lived credentials let attackers operate on their own (comfortable) timelines; this is why Trusted Publishing is such a useful (but not wholly sufficient) technique for reducing the attacker√¢s attack staging window.√Ç ‚Ü©&lt;/p&gt;
    &lt;p&gt;Filippo Valsorda has an excellent compilation of recent supply chain compromises here.√Ç ‚Ü©&lt;/p&gt;
    &lt;p&gt;The xz-utils attack is a significant outlier, both in its scope and the length of its window of opportunity. In this case, I√¢ve measured from the attacker√¢s first backdoored release (v5.6.0, 2024-02-24) to the time of rollback within Debian (2024-03-28).√Ç ‚Ü©&lt;/p&gt;
    &lt;p&gt;For example, pnpm√¢s &lt;code&gt;minimumReleaseAge&lt;/code&gt;.
           uv also has &lt;code&gt;exclude-newer&lt;/code&gt;, 
           although this specifies an absolute cutoff rather than a rolling cooldown.√Ç¬†‚Ü©&lt;/p&gt;
    &lt;p&gt;Notably, the only attack that would have stymied a 14-day cooldown is xz-utils, which is also the most technically, logistically, and socially advanced of all of the attacks.√Ç ‚Ü©&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46005111</guid><pubDate>Fri, 21 Nov 2025 14:50:36 +0000</pubDate></item><item><title>XBMC 4.0 for the Original Xbox</title><link>https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/</link><description>&lt;doc fingerprint="3f9edd7dc8a4cddc"&gt;
  &lt;main&gt;
    &lt;p&gt;A Major Modernization of the Killer App That Started It All&lt;/p&gt;
    &lt;p&gt;A new version of Xbox Media Center (XBMC), version 4.0, has been released. This version marks a significant update to the long-standing media center platform for the Original Xbox. This marks the first major advancement to the software since 2016 and represents a renewed commitment to preserving, modernizing, and extending the capabilities of one of the most iconic console homebrew applications ever created.&lt;/p&gt;
    &lt;p&gt;XBMC has a long and influential history. In 2002, XboxMediaPlayer (XMP) was released and turned the console into a powerful multimedia device fit for the living room in an era when connecting a computer to a TV was quite novel. Later that same year, XMP merged with YAMP and became Xbox Media Player 2.0. A few years later, the software evolved into Xbox Media Center, or XBMC, which introduced a new interface, a plugin system powered by Python, and a robust skinning engine.&lt;/p&gt;
    &lt;p&gt;XBMC eventually became so capable that it outgrew the Xbox entirely. By 2007, developers were working on PC ports and in 2010, the project split into two branches: one for general computers while the Xbox version became XBMC4Xbox, and each codebase was maintained from then on by separate teams. XBMC was later renamed to Kodi in 2014 and continues to be one of the most popular media center applications available. Even Plex traces its roots back to XBMC. Plex began as OSXBMC, a Mac port of XBMC in late 2007, before becoming its own project in 2008. This means the Original Xbox helped shape not one but two of the biggest media center apps used today.&lt;/p&gt;
    &lt;p&gt;The last official release of XBMC4Xbox arrived in February 2016 with version 3.5.3. Although the community never declared the project dead, meaningful updates became scarce. XBMC 4.0 continues that legacy by bringing a modern interface, updating it to be more inline with Kodi's modern codebase, and backporting features to the original 64MB RAM / Pentium-III hardware where it all began.&lt;/p&gt;
    &lt;p&gt;This project is distinct and separate from XBMC4Gamers, the games-focused variation of XBMC4Xbox (v3.5.3) by developer Rocky5.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Modern Interface Powered by Estuary&lt;/head&gt;
    &lt;p&gt;One of the most notable advancements in XBMC 4.0 is the introduction of the Estuary user interface (skin).&lt;/p&gt;
    &lt;p&gt;Estuary, originally released in 2017 with Kodi v17 ("Krypton"), provides a clean and modern layout that improves navigation and readability over past skins. Bringing Estuary to the Xbox required extensive updates to the underlying GUI framework, including a port of the more contemporary GUIlib engine. This allows the platform to support modern skinning standards and makes future skin ports much more straightforward. After the initial work of porting GUIlib was done, porting Estuary to the Xbox was a relatively simple process of tweaking a handful of configuration files and adding contextual features specific to the Xbox. The result is a modern, intuitive front end that retains the performance and responsiveness required on legacy hardware.&lt;/p&gt;
    &lt;p&gt;Firing up an Xbox made in 2001 and being greeted by the same interface as what you'd find if you were to download Kodi today onto your PC feels like a bit of magic, and helps keep this beloved classic console relevant and useful well into the modern era.&lt;/p&gt;
    &lt;head rend="h2"&gt;Expanded Games Library Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 introduces a fully realized games library system. This enhancement brings the same level of metadata support found in the Movies and Music sections to Xbox and emulated games. Titles can now display artwork, descriptions, and other metadata, transforming the games section into a polished and user-friendly library. XBMC‚Äôs longstanding support for trainers remains intact, giving users the option to apply gameplay modifications for compatible titles. Emulated game collections benefit as well, with the ability to browse ROM libraries and launch them directly in a user‚Äôs preferred emulator.&lt;/p&gt;
    &lt;head rend="h2"&gt;Online Scrapers and Metadata Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 restores full functionality to metadata scrapers for movies and television. This allows users to build rich media libraries complete with artwork, plot summaries, cast listings, and other information retrieved directly from online sources. XBMC 4.0 handles these tasks efficiently, even on the Xbox‚Äôs limited memory and processing power. Video playback continues to support 480p and 720p content, enabling the console to serve as a surprisingly capable media device for its age. Similar to Kodi, XBMC 4.0 supports filtering, building playlists, watch progress history for media, and intelligent handling of TV shows with seasons.&lt;/p&gt;
    &lt;p&gt;Aside from scrapers for multimedia, support for rich library capabilities for games has also been added. XBMC has always been a media-first app, and now users can enjoy the library experience that they've come to love for media now in the context of their games library (more info below).&lt;/p&gt;
    &lt;head rend="h2"&gt;Improved Task Scheduling and Multitasking&lt;/head&gt;
    &lt;p&gt;Despite the constraints of the Xbox‚Äôs single-threaded 733MHz CPU, XBMC 4.0 includes improvements to task scheduling that allow multiple activities to run concurrently. Background library updates, metadata scraping, and audio/video playback can occur while users navigate and use other parts of the interface. These optimizations help ensure a fluid experience without compromising performance. Much work has been done "under the hood" to keep XBMC on task and within memory budgets while achieving multi-tasking on a console that wasn't exactly designed with it in mind. Users who own RAM and/or CPU upgraded consoles can also take advantage of the extra overhead, as XBMC 4.0 makes use of the extra horsepower for an even smoother experience. Utilizing an SSD with higher UDMA speeds will also yield an improvement in overall responsiveness.&lt;/p&gt;
    &lt;head rend="h2"&gt;Music Experience and Visualizers&lt;/head&gt;
    &lt;p&gt;Music playback has always been a strong element of XBMC, and version 4.0 maintains that focus. The Original Xbox is capable of high quality audio output, and XBMC continues to support lossless codecs such as FLAC. The release includes compatibility with various audio visualizers, including MilkDrop, which remains one of the most visually impressive and customizable audio visualization engines available. These features allow XBMC 4.0 to function not only as a media organizer, but also as an immersive audio display system.&lt;/p&gt;
    &lt;p&gt;An online repository has been established and will be maintained moving forward where users can download legacy and newly-released add-ons as they become available. This repository is accessible without additional setup, right out of the box!&lt;/p&gt;
    &lt;head rend="h2"&gt;Add-ons and Python Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 continues to offer an extendable architecture powered by Python-based add-ons. While the current release uses Python 2.7 for compatibility, work is underway to transition to Python 3.4.10 in the future, which may provide a path for backporting many newer Kodi add-ons. Even in its current state, XBMC 4.0 already supports a variety of community-developed add-ons that extend the system‚Äôs functionality, including tools for online video playback (i.e. YouTube), online weather services, and enhanced media organization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Updated Settings, Network Services, and System Tools&lt;/head&gt;
    &lt;p&gt;The settings interface has been revised to provide more clarity and control. The update includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Playback options, including episode progression, crossfade behavior, and subtitle handling&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Library management tools&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Network features, such as SMB, FTP, UPnP sharing, web server access, and Insignia-compatible DNS options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Comprehensive interface customization options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multiple user profiles with individual library settings&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Advanced system controls for video calibration, display modes, input devices, and power management&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A robust System Information section for diagnostics, with info geared towards the Original Xbox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A flexible File Manager with support for network protocols including FTP, SMB, WebDAV, and more&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Users may also take advantage of an online add-ons repository, offering the same experience modern Kodi provides with being able to download add-ons to extend functionality of the app with things like online multimedia providers, weather, skins, visualizers, and more. Developers can submit new add-ons to the official repository via Github.&lt;/p&gt;
    &lt;head rend="h2"&gt;Continuing the Legacy&lt;/head&gt;
    &lt;p&gt;XBMC has been a staple of the Original Xbox's homebrew scene since its inception in the early 2000's. This new update is a revival of the platform that helped shape the landscape of home media software and helps revitalize a codebase that has been somewhat stagnant for many years. This release honors that heritage while modernizing the experience for a new generation of enthusiasts and preserving the functionality of the Original Xbox as a versatile and capable media center.&lt;/p&gt;
    &lt;p&gt;Although the hardware is decades old, the renewed effort behind XBMC 4.0 demonstrates that the platform still has room to grow and tricks up its sleeve. With ongoing development and a codebase designed with modern Kodi compatibility in mind, XBMC 4.0 represents a significant step forward into the continued development on the Original Xbox.&lt;/p&gt;
    &lt;p&gt;The development team looks forward to continuing this work and expanding the possibilities of the Original Xbox for years to come. This version is the first of many to come, with lots of things cooking in the background. Keep an eye out for future releases by joining the Xbox-Scene Discord and turning on notifications in the xbmc-news channel or by periodically checking the project's Github page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Downloads&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 (and subsequent releases) builds along with source code are available via Github:&lt;/p&gt;
    &lt;p&gt;Main project page: Click Here&lt;/p&gt;
    &lt;p&gt;Note: XBMC 4.0 is is in active development! This means updates will be released in a more frequent manner for the time being until things settle down. Check the nightly builds section on Github for the most up-to-date version.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;XBMC is open source software and welcomes contributions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Coding: Developers can help XBMC by fixing a bug, adding new features, making our technology smaller and faster and making development easier for others. XBMC's codebase consists mainly of C++ with small parts written in a variety of coding languages. Our add-ons mainly consist of python and XML.&lt;/item&gt;
      &lt;item&gt;Helping users: Our support process relies on enthusiastic contributors like you to help others get the most out of XBMC. The #1 priority is always answering questions in our support forums. Everyday new people discover XBMC, and everyday they are virtually guaranteed to have questions.&lt;/item&gt;
      &lt;item&gt;Localization: Translate XBMC, add-ons, skins etc. into your native language.&lt;/item&gt;
      &lt;item&gt;Add-ons: Add-ons are what make XBMC the most extensible and customizable entertainment hub available. Get started building an add-on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Support and Bug Reporting&lt;/head&gt;
    &lt;p&gt;Need help?&lt;/p&gt;
    &lt;p&gt;Support can be found in the XBMC -&amp;gt; General channel within the Xbox-Scene Discord server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Credits and Disclaimers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nikola Antoniƒá - Primary Developer, Project Lead&lt;/item&gt;
      &lt;item&gt;astarivi - Contributor (cURL, wolfSSL), Tester, Debugger&lt;/item&gt;
      &lt;item&gt;EqUiNoX - Contrubitor, Tester&lt;/item&gt;
      &lt;item&gt;Rocky5 - Contributor, Tester&lt;/item&gt;
      &lt;item&gt;.lavenderStarlight+ - Add-ons / Skins Development, Tester&lt;/item&gt;
      &lt;item&gt;GoTeamScotch - Tester, Feedback&lt;/item&gt;
      &lt;item&gt;Haguero - Tester, Feedback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;XBMC is GPLv2 licensed. You may use, distribute and copy it under the license terms. XBMC is licensed under the same terms as Kodi. For detailed information on the licensing, please refer to the Kodi license.&lt;/p&gt;
    &lt;p&gt;This project, XBMC version 4.0 (and upcoming releases), is distinct from and is not affiliated with Team Kodi of The Kodi Foundation, or its members.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46005349</guid><pubDate>Fri, 21 Nov 2025 15:18:05 +0000</pubDate></item><item><title>Make product worse, get money</title><link>https://dynomight.net/worse/</link><description>&lt;doc fingerprint="652b19d9bbe30db8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Make product worse, get money&lt;/head&gt;
    &lt;p&gt;I recently asked why people seem to hate dating apps so much. In response, 80% of you emailed me some version of the following theory:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The thing about dating apps is that if they do a good job and match people up, then the matched people will quit the app and stop paying. So they have an incentive to string people along but not to actually help people find long-term relationships.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;May I explain why I don‚Äôt find this type of theory very helpful?&lt;/p&gt;
    &lt;p&gt;I‚Äôm not saying that I think it‚Äôs wrong, mind you. Rather, my objection is that while the theory is phrased in terms of dating apps, the same basic pattern applies to basically anyone who is trying to make money by doing anything.&lt;/p&gt;
    &lt;p&gt;For example, consider a pizza restaurant. Try these theories on for size:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Pizza: ‚ÄúThe thing about pizza restaurants is that if they use expensive ingredients or labor-intensive pizza-making techniques, then it costs more to make pizza. So they have an incentive to use low-cost ingredients and labor-saving shortcuts.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pizza II: ‚ÄúThe thing about pizza restaurants is that if they have nice tables separated at a comfortable distance, then they can‚Äôt fit as many customers. So they have an incentive to use tiny tables and cram people in cheek by jowl.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pizza III: ‚ÄúThe thing about pizza restaurants is that if they sell big pizzas, then people will eat them and stop being hungry, meaning they don‚Äôt buy additional pizza. So they have an incentive to serve tiny low-calorie pizzas.‚Äù&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See what I mean? You can construct similar theories for other domains, too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Cars: ‚ÄúThe thing about automakers is that making cars safe is expensive. So they have an incentive to make unsafe cars.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Videos: ‚ÄúThe thing about video streaming is that high-resolution video uses more expensive bandwidth. So they have an incentive to use low-resolution.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Blogging: ‚ÄúThe thing about bloggers is that research is time-consuming. So they have an incentive to be sloppy about the facts.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Durability: ‚ÄúThe thing about {lightbulb, car, phone, refrigerator, cargo ship} manufacturing is that if you make a {lightbulb, car, phone, refrigerator, cargo ship} that lasts a long time, then people won‚Äôt buy new ones. So there‚Äôs an incentive to make {lightbulbs, cars, phones, refrigerators, cargo ships} that break quickly.‚Äù&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All these theories can be thought of as instances of two general patterns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Make product worse, get money: ‚ÄúThe thing about selling goods or services is that making goods or services better costs money. So people have an incentive to make goods and services worse.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Raise price, get money: ‚ÄúThe thing about selling goods and services is that if you raise prices, then you get more money. So people have an incentive to raise prices.‚Äù&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Are these theories wrong? Not exactly. But it sure seems like something is missing.&lt;/p&gt;
    &lt;p&gt;I‚Äôm sure most pizza restauranteurs would be thrilled to sell lukewarm 5 cm cardboard discs for $300 each. They do in fact have an incentive to do that, just as predicted by these theories! Yet, in reality, pizza restaurants usually sell pizzas that are made out of food. So clearly these theories aren‚Äôt telling the whole story.&lt;/p&gt;
    &lt;p&gt;Say you have a lucrative business selling 5 cm cardboard discs for $300. I am likely to think, ‚ÄúI like money. Why don‚Äôt I sell pizzas that are only mostly cardboard, but also partly made of flour? And why don‚Äôt I sell them for $200, so I can steal Valued Reader‚Äôs customers?‚Äù But if I did that, then someone else would probably set prices at only $100, or even introduce cardboard-free pizzas, and this would continue until hitting some kind of equilibrium.&lt;/p&gt;
    &lt;p&gt;Sure, producers want to charge infinity dollars for things that cost them zero dollars to make. But consumers want to pay zero dollars for stuff that‚Äôs infinitely valuable. It‚Äôs in the conflict between these desires that all interesting theories live.&lt;/p&gt;
    &lt;p&gt;This is why I don‚Äôt think it‚Äôs helpful to point out that people have an incentive to make their products worse. Of course they do. The interesting question is, why are they able to get away with it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Reasons stuff is bad&lt;/head&gt;
    &lt;p&gt;First reason stuff is bad: People are cheap&lt;/p&gt;
    &lt;p&gt;Why are seats so cramped on planes? Is it because airlines are greedy? Sure. But while they might be greedy, I don‚Äôt think they‚Äôre dumb. If you do a little math, you can calculate that if airlines were to remove a single row of seats, they could add perhaps 2.5 cm (1 in) of extra legroom for everyone, while only decreasing the number of paying customers by around 3%. (This is based on a 737 with single-class, but you get the idea.)&lt;/p&gt;
    &lt;p&gt;So why don‚Äôt airlines rip out a row of seats, raise prices by 3% and enjoy the reduced costs for fuel and customer service? The only answer I can see is that people, on average, aren‚Äôt actually willing to pay 3% more for 2.5 cm more legroom. We want a worse but cheaper product, and so that‚Äôs what we get.&lt;/p&gt;
    &lt;p&gt;I think this is the most common reason stuff is ‚Äúbad‚Äù. It‚Äôs why Subway sandwiches are so soggy, why video games are so buggy, and why IKEA furniture and Primark clothes fall apart so quickly.&lt;/p&gt;
    &lt;p&gt;It‚Äôs good when things are bad for this reason. Or at least, that‚Äôs the premise of capitalism: When companies cut costs, that‚Äôs the invisible hand redirecting resources to maximize social value, or whatever. Companies may be motivated by greed. And you may not like it, since you want to pay zero dollars for infinite value. But this is markets working as designed.&lt;/p&gt;
    &lt;p&gt;Second reason stuff is bad: Information asymmetries&lt;/p&gt;
    &lt;p&gt;Why is it that almost every book / blog / podcast about longevity is such garbage? Well, we don‚Äôt actually know many things that will reliably increase longevity. And those things are mostly all boring / hard / non-fun. And even if you do all of them, it probably only adds a couple of years in expectation. And telling people these facts is not a good way to find suckers who will pay you lots of money for your unproven supplements / seminars / etc.&lt;/p&gt;
    &lt;p&gt;True! But it doesn‚Äôt explain why all longevity stuff is so bad. Why don‚Äôt honest people tell the true story and drive all the hucksters out of business? I suspect the answer is that unless you have a lot of scientific training and do a lot of research, it‚Äôs basically impossible to figure out just how huckstery all the hucksters really are.&lt;/p&gt;
    &lt;p&gt;I think this same basic phenomenon explains why some supplements contain heavy metals, why some food contains microplastics, why restaurants use so much butter and salt, why rentals often have crappy insulation, and why most cars seem to only be safe along dimensions included in crash test scores. When consumers can‚Äôt tell good from evil, evil triumphs.&lt;/p&gt;
    &lt;p&gt;Third reason stuff is bad: People have bad taste&lt;/p&gt;
    &lt;p&gt;Sometimes stuff is bad because people just don‚Äôt appreciate the stuff you consider good. Examples are definitionally controversial, but I think this includes restaurants in cities where all restaurants are bad, North American tea, and travel pants. This reason has a blurry boundary with information asymmetries, as seen in ultrasonic humidifiers or products that use Sucralose instead of aspartame for ‚Äúsafety‚Äù.&lt;/p&gt;
    &lt;p&gt;Fourth reason stuff is bad: Pricing power&lt;/p&gt;
    &lt;p&gt;Finally, sometimes stuff is bad because markets aren‚Äôt working. Sometimes a company is selling a product but has some kind of ‚Äúmoat‚Äù that makes it hard for anyone else to compete with them, e.g. because of some technological or regulatory barrier, control of some key resource or location, intellectual property, a beloved brand, or network effects.&lt;/p&gt;
    &lt;p&gt;If that‚Äôs true, then those companies don‚Äôt have to worry as much about someone else stealing their business, and so (because everyone is axiomatically greedy) they will find ways to make their product cheaper and/or raise prices up until the price is equal to the full value it provides to the marginal consumer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Why is food so expensive at sporting events? Yes, people have no alternatives. But people know food is expensive at sporting events. And they don‚Äôt like it. Instead of selling water for $17, why don‚Äôt venues sell water for $2 and raise ticket prices instead? I don‚Äôt know. Probably something complicated, like that expensive food allows you to extract extra money from rich people without losing business from non-rich people.&lt;/p&gt;
    &lt;p&gt;So of course dating apps would love to string people along for years instead of finding them long-term relationships, so they keep paying money each month. I wouldn‚Äôt be surprised if some people at those companies have literally thought, ‚ÄúMaybe we should string people along for years instead of finding them long-term relationships, so they keep paying money each month, I love money so much.‚Äù&lt;/p&gt;
    &lt;p&gt;But if they are actually doing that (which is unclear to me) or if they are bad in some other way, then how do they get away with it? Why doesn‚Äôt someone else create a competing app that‚Äôs better and thereby steal all their business? It seems like the answer has to be either ‚Äúbecause that‚Äôs impossible‚Äù or ‚Äúbecause people don‚Äôt really want that‚Äù. That‚Äôs where the mystery begins.&lt;/p&gt;
    &lt;p&gt;Dating: A mysterious constellation of facts ¬∑ life economics&lt;/p&gt;
    &lt;p&gt;So much blood ¬∑ conspiracy economics&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46005388</guid><pubDate>Fri, 21 Nov 2025 15:23:20 +0000</pubDate></item><item><title>Show HN: Wealthfolio 2.0- Open source investment tracker. Now Mobile and Docker</title><link>https://wealthfolio.app/?v=2.0</link><description>&lt;doc fingerprint="27ab40bb69b94b92"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Grow Wealth. Keep Control.&lt;/head&gt;
    &lt;head rend="h2"&gt;A beautiful, Private and Open-Source investment tracker that runs locally on all your devices.&lt;/head&gt;
    &lt;head rend="h2"&gt;WHY CHOOSE WEALTHFOLIO?&lt;/head&gt;
    &lt;p&gt;A beautiful portfolio tracker that respects your privacy and your data&lt;/p&gt;
    &lt;head rend="h3"&gt;Privacy-First Approach&lt;/head&gt;
    &lt;p&gt;Your data never leaves your device. As an open-source project, we prioritize security and transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simple and Beautifully Crafted&lt;/head&gt;
    &lt;p&gt;Powerful features wrapped in an elegant, easy-to-use interface. Simplicity meets sophistication.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Hidden Costs&lt;/head&gt;
    &lt;p&gt;Free to use with optional one-time payment. No subscriptions or recurring fees.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE ESSENTIALS YOU NEED TO TRACK YOUR WEALTH&lt;/head&gt;
    &lt;p&gt;No More Messy Spreadsheets or Privacy Concerns - Just You and Your Secure, Personal Wealth Companion Application&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Aggregation&lt;/head&gt;
    &lt;p&gt;Gather all your investment and savings accounts in one place. See everything at a glance, from stocks to savings! Import your CSV statements from your broker or bank.&lt;/p&gt;
    &lt;head rend="h4"&gt;Comprehensive View&lt;/head&gt;
    &lt;p&gt;See all your accounts in one place.&lt;/p&gt;
    &lt;head rend="h4"&gt;CSV Import&lt;/head&gt;
    &lt;p&gt;Easily import your CSV statements.&lt;/p&gt;
    &lt;head rend="h3"&gt;Holdings Overview&lt;/head&gt;
    &lt;p&gt;Get a clear picture of what's in your portfolio. Stocks, ETFs, or Cryptocurrencies - know what you have and how it's performing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Portfolio Insights&lt;/head&gt;
    &lt;p&gt;Understand your asset allocation.&lt;/p&gt;
    &lt;head rend="h4"&gt;Performance Tracking&lt;/head&gt;
    &lt;p&gt;Monitor how your investments are doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance Dashboard&lt;/head&gt;
    &lt;p&gt;See how your investments stack up, all in one place. Compare your accounts side by side, check if you are beating the S&amp;amp;P 500, and track your favorite ETFs without the hassle. No fancy jargon - just clear, useful charts that help you understand how your money is really doing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Compare Your Accounts&lt;/head&gt;
    &lt;p&gt;See which accounts are doing best.&lt;/p&gt;
    &lt;head rend="h4"&gt;Beat the Market?&lt;/head&gt;
    &lt;p&gt;Check how you stack up against some popular indexes and ETFs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Income Tracking&lt;/head&gt;
    &lt;p&gt;Monitor dividends and interest income across your entire portfolio. Get a clear view of your passive income streams, helping you make informed decisions about your investments.&lt;/p&gt;
    &lt;head rend="h4"&gt;Dividend Monitoring&lt;/head&gt;
    &lt;p&gt;Track your dividend income.&lt;/p&gt;
    &lt;head rend="h4"&gt;Interest Income&lt;/head&gt;
    &lt;p&gt;Keep an eye on interest earnings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Performance&lt;/head&gt;
    &lt;p&gt;Track your accounts' holdings and performance over time. See how a particular account is performing, and how it's changing over time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Historical Data&lt;/head&gt;
    &lt;p&gt;View past performance trends.&lt;/p&gt;
    &lt;head rend="h4"&gt;Account Analysis&lt;/head&gt;
    &lt;p&gt;Analyze individual account performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Goals Tracking&lt;/head&gt;
    &lt;p&gt;Set your savings targets clearly. Distribute your funds across these objectives, assigning a specific percentage to each. Keep an eye on your progress.&lt;/p&gt;
    &lt;head rend="h4"&gt;Target Setting&lt;/head&gt;
    &lt;p&gt;Define your financial goals.&lt;/p&gt;
    &lt;head rend="h4"&gt;Progress Monitoring&lt;/head&gt;
    &lt;p&gt;Track your progress towards goals.&lt;/p&gt;
    &lt;head rend="h3"&gt;Contribution Rooms and Limit Tracking&lt;/head&gt;
    &lt;p&gt;Stay on top of your contribution limits for tax-advantaged accounts like IRAs, 401(k)s, or TFSAs. Track your available contribution room and avoid over-contributing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Limit Awareness&lt;/head&gt;
    &lt;p&gt;Know your contribution limits.&lt;/p&gt;
    &lt;head rend="h4"&gt;Avoid Over-Contribution&lt;/head&gt;
    &lt;p&gt;Prevent excess contributions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extend Wealthfolio with Powerful Add-ons&lt;/head&gt;
    &lt;head rend="h3"&gt;Investment Fees Tracker&lt;/head&gt;
    &lt;p&gt;Track and analyze investment fees across your portfolio with detailed analytics and insights&lt;/p&gt;
    &lt;head rend="h3"&gt;Goal Progress Tracker&lt;/head&gt;
    &lt;p&gt;Track your investment progress towards target amounts with a visual representation&lt;/p&gt;
    &lt;head rend="h3"&gt;Stock Trading Tracker&lt;/head&gt;
    &lt;p&gt;Simple swing stock trading tracker with performance analytics and calendar views&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006016</guid><pubDate>Fri, 21 Nov 2025 16:34:52 +0000</pubDate></item><item><title>You can make PS2 games in JavaScript</title><link>https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006082</guid><pubDate>Fri, 21 Nov 2025 16:42:19 +0000</pubDate></item><item><title>Solving Fizz Buzz with Cosines</title><link>https://susam.net/fizz-buzz-with-cosines.html</link><description>&lt;doc fingerprint="12d799356860fab4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solving Fizz Buzz with Cosines&lt;/head&gt;
    &lt;p&gt;Fizz Buzz is a counting game that has become oddly popular in the world of computer programming as a simple test of basic programming skills. The rules of the game are straightforward. Players say the numbers aloud in order beginning with one. Whenever a number is divisible by 3, they say 'Fizz' instead. If it is divisible by 5, they say 'Buzz'. If it is divisible by both 3 and 5, the player says both 'Fizz' and 'Buzz'. Here is a typical Python program that prints this sequence:&lt;/p&gt;
    &lt;code&gt;for n in range(1, 101):
    if n % 15 == 0:
        print('FizzBuzz')
    elif n % 3 == 0:
        print('Fizz')
    elif n % 5 == 0:
        print('Buzz')
    else:
        print(n)
&lt;/code&gt;
    &lt;p&gt;Here is the output: fizz-buzz.txt. Can we make the program more complicated? The words 'Fizz', 'Buzz' and 'FizzBuzz' repeat in a periodic manner throughout the sequence. What else is periodic? Trigonometric functions! Perhaps we can use trigonometric functions to encode all four rules of the sequence in a single closed-form expression. That is what we are going to explore in this article. By the end, we will obtain a discrete Fourier series that can take any integer \( n \) and select the corresponding text to be printed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Definitions&lt;/head&gt;
    &lt;p&gt;Before going any further, we establish a precise mathematical definition for the Fizz Buzz sequence. We begin by introducing a few functions that will help us define the Fizz Buzz sequence later.&lt;/p&gt;
    &lt;head rend="h3"&gt;Symbol Functions&lt;/head&gt;
    &lt;p&gt;We define a set of four functions \( \{ s_0, s_1, s_2, s_3 \} \) for integers \( n \) by: \begin{align*} s_0(n) &amp;amp;= n, \\ s_1(n) &amp;amp;= \mathtt{Fizz}, \\ s_2(n) &amp;amp;= \mathtt{Buzz}, \\ s_3(n) &amp;amp;= \mathtt{FizzBuzz}. \end{align*} We call these the symbol functions because they produce every term that appears in the Fizz Buzz sequence. The symbol function \( s_0 \) returns \( n \) itself. The functions \( s_1, \) \( s_2 \) and \( s_3 \) are constant functions that always return the literal words \( \mathtt{Fizz}, \) \( \mathtt{Buzz} \) and \( \mathtt{FizzBuzz} \) respectively, no matter what the value of \( n \) is.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fizz Buzz Sequence&lt;/head&gt;
    &lt;p&gt;Now we can define the Fizz Buzz sequence as the sequence \[ (s_{f(n)}(n))_{n = 1}^{\infty} \] where \[ f(n) = \begin{cases} 1 &amp;amp; \text{if } 3 \mid n \text{ and } 5 \nmid n, \\ 2 &amp;amp; \text{if } 3 \nmid n \text{ and } 5 \mid n, \\ 3 &amp;amp; \text{if } 3 \mid n \text{ and } 5 \mid n, \\ 0 &amp;amp; \text{otherwise}. \end{cases} \] The notation \( m \mid n \) means that the integer \( m \) divides the integer \( n, \) i.e. \( n \) is a multiple of \( m. \) Equivalently, there exists an integer \( c \) such that \( n = cm . \) Similarly, \( m \nmid n \) means that \( m \) does not divide \( n, \) i.e. \( n \) is not a multiple of \( m. \) With the above definitions in place, we can expand the first few terms of the sequence explicitly as follows: \begin{align*} (s_{f(n)}(n))_{n = 1}^{\infty} &amp;amp;= (s_{f(1)}(1), \; s_{f(2)}(2), \; s_{f(3)}(3), \; s_{f(4)}(4), \; s_{f(5)}(5), \; s_{f(6)}(6), \; s_{f(7)}(7), \; \dots) \\ &amp;amp;= (s_0(1), \; s_0(2), \; s_1(3), \; s_0(4), s_2(5), \; s_1(6), \; s_0(7), \; \dots) \\ &amp;amp;= (1, \; 2, \; \mathtt{Fizz}, \; 4, \; \mathtt{Buzz}, \; \mathtt{Fizz}, \; 7, \; \dots). \end{align*} Note how the function \( f(n) \) produces an index \( i \) which we then use to select the symbol function \( s_i(n) \) to produce the \( n \)th term of the sequence. We therefore call \( f(n) \) the index function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Indicator Functions&lt;/head&gt;
    &lt;p&gt;Here is the index function \( f(n) \) from the previous section with its cases and conditions rearranged to make it easier to spot interesting patterns: \[ f(n) = \begin{cases} 0 &amp;amp; \text{if } 5 \nmid n \text{ and } 3 \nmid n, \\ 1 &amp;amp; \text{if } 5 \nmid n \text{ and } 3 \mid n, \\ 2 &amp;amp; \text{if } 5 \mid n \text{ and } 3 \nmid n, \\ 3 &amp;amp; \text{if } 5 \mid n \text{ and } 3 \mid n. \end{cases} \] This function helps us to select another function \( s_{f(n)}(n) \) which in turn determines the \( n \)th term of the Fizz Buzz sequence. Our goal now is to replace this piecewise formula with a single closed-form expression. To do so, we first define indicator functions \( I_m(n) \) as follows: \[ I_m(n) = \begin{cases} 1 &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] The formula for \( f(n) \) can now be written as: \[ f(n) = \begin{cases} 0 &amp;amp; \text{if } I_5(n) = 0 \text{ and } I_3(n) = 0, \\ 1 &amp;amp; \text{if } I_5(n) = 0 \text{ and } I_3(n) = 1, \\ 2 &amp;amp; \text{if } I_5(n) = 1 \text{ and } I_3(n) = 0, \\ 3 &amp;amp; \text{if } I_5(n) = 1 \text{ and } I_3(n) = 1. \end{cases} \] Do you see a pattern? Here is the same function written as a table:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;\( I_5(n) \)&lt;/cell&gt;
        &lt;cell role="head"&gt;\( I_3(n) \)&lt;/cell&gt;
        &lt;cell role="head"&gt;\( f(n) \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 2 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 3 \)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Do you see it now? If we treat the values in the first two columns as binary digits and the values in the third column as decimal numbers, then in each row the first two columns give the binary representation of the number in the third column. For example, \( 3_{10} = 11_2 \) and indeed in the last row of the table, we see the bits \( 1 \) and \( 1 \) in the first two columns and the number \( 3 \) in the last column. In other words, writing the binary digits \( I_5(n) \) and \( I_3(n) \) side by side gives us the binary representation of \( f(n). \) Therefore \[ f(n) = 2 \, I_5(n) + I_3(n). \] We can now write a small program to demonstrate this formula:&lt;/p&gt;
    &lt;code&gt;
 for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = (n % 3 == 0) + 2 * (n % 5 == 0)
    print(s[i])
&lt;/code&gt;
    &lt;p&gt;We can make it even shorter at the cost of some clarity:&lt;/p&gt;
    &lt;code&gt;
 for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][(n % 3 == 0) + 2 * (n % 5 == 0)])
&lt;/code&gt;
    &lt;p&gt;What we have obtained so far is pretty good. While there is no universal definition of a closed-form expression, I think most people would agree that the indicator functions as defined above are simple enough to be permitted in a closed-form expression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Complex Exponentials&lt;/head&gt;
    &lt;p&gt;In the previous section, we obtained the formula \[ f(n) = I_3(n) + 2 \, I_5(n) \] which we then used as an index to look up the text to be printed. We also argued that this is a pretty good closed-form expression already.&lt;/p&gt;
    &lt;p&gt;However, in the interest of making things more complicated, we must ask ourselves: What if we are not allowed to use the indicator functions? What if we must adhere to the commonly accepted meaning of a closed-form expression which allows only finite combinations of basic operations such as addition, subtraction, multiplication, division, integer exponents and roots with integer index as well as functions such as exponentials, logarithms and trigonometric functions. It turns out that the above formula can be rewritten using only addition, multiplication, division and the cosine function. Let us begin the translation. Consider the sum \[ S_m(n) = \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m}, \] where \( i \) is the imaginary unit and \( n \) and \( m \) are integers. This is a geometric series in the complex plane with ratio \( r = e^{2 \pi i n / m}. \) If \( n \) is a multiple of \( m , \) then \( n = cm \) for some integer \( c \) and we get \[ r = e^{2 \pi i n / m} = e^{2 \pi i c} = 1. \] Therefore, when \( n \) is a multiple of \( m, \) we get \[ S_m(n) = \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m} = \sum_{k = 0}^{m - 1} 1^k = m. \] If \( n \) is not a multiple of \( m, \) then \( r \ne 1 \) and the geometric series becomes \[ S_m(n) = \frac{r^m - 1}{r - 1} = \frac{e^{2 \pi i n} - 1}{e^{2 \pi i n / m} - 1} = 0. \] Therefore, \[ S_m(n) = \begin{cases} m &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] Dividing both sides by \( m, \) we get \[ \frac{S_m(n)}{m} = \begin{cases} 1 &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] But the right-hand side is \( I_m(n). \) Therefore \[ I_m(n) = \frac{S_m(n)}{m} = \frac{1}{m} \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m}. \]&lt;/p&gt;
    &lt;head rend="h2"&gt;Cosines&lt;/head&gt;
    &lt;p&gt;We begin with Euler's formula \[ e^{i x} = \cos x + i \sin x \] where \( x \) is a real number. From this formula, we get \[ e^{i x} + e^{-i x} = 2 \cos x. \] Therefore \begin{align*} I_3(n) &amp;amp;= \frac{1}{3} \sum_{k = 0}^2 e^{2 \pi i k n / 3} \\ &amp;amp;= \frac{1}{3} \left( 1 + e^{2 \pi i n / 3} + e^{4 \pi i n / 3} \right) \\ &amp;amp;= \frac{1}{3} \left( 1 + e^{2 \pi i n / 3} + e^{-2 \pi i n / 3} \right) \\ &amp;amp;= \frac{1}{3} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right). \end{align*} The third equality above follows from the fact that \( e^{4 \pi i n / 3} = e^{6 \pi i n / 3} e^{-2 \pi i n / 3} = e^{2 \pi i n} e^{-2 \pi i n/3} = e^{-2 \pi i n / 3}. \)&lt;/p&gt;
    &lt;p&gt;The function above is defined for integer values of \( n \) but we can extend its formula to real \( x \) and plot it to observe its shape between integers. As expected, the function takes the value \( 1 \) whenever \( x \) is an integer multiple of \( 3 \) and \( 0 \) whenever \( x \) is an integer not divisible by \( 3. \)&lt;/p&gt;
    &lt;p&gt;Similarly, \begin{align*} I_5(n) &amp;amp;= \frac{1}{5} \sum_{k = 0}^4 e^{2 \pi i k n / 5} \\ &amp;amp;= \frac{1}{5} \left( 1 + e^{2 \pi i n / 5} + e^{4 \pi i n / 5} + e^{6 \pi i n / 5} + e^{8 \pi i n / 5} \right) \\ &amp;amp;= \frac{1}{5} \left( 1 + e^{2 \pi i n / 5} + e^{4 \pi i n / 5} + e^{-4 \pi i n / 5} + e^{-2 \pi i n / 5} \right) \\ &amp;amp;= \frac{1}{5} + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right). \end{align*} Extending this expression to real values of \( x \) allows us to plot its shape as well. Once again, the function takes the value \( 1 \) at integer multiples of \( 5 \) and \( 0 \) at integers not divisible by \( 5. \)&lt;/p&gt;
    &lt;p&gt;Recall that we expressed \( f(n) \) as \[ f(n) = I_3(n) + 2 \, I_5(n). \] Substituting these trigonometric expressions yields \[ f(n) = \frac{1}{3} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + 2 \cdot \left( \frac{1}{5} + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right) \right). \] A straightforward simplification gives \[ f(n) = \frac{11}{15} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right). \] We can extend this expression to real \( x \) and plot it as well. The resulting curve takes the values \( 0, 1, 2 \) and \( 3 \) at integer points, as desired.&lt;/p&gt;
    &lt;p&gt;Now we can write our Python program as follows:&lt;/p&gt;
    &lt;code&gt;
 from math import cos, pi
for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3)
                      + (4 / 5) * cos(2 * pi * n / 5)
                      + (4 / 5) * cos(4 * pi * n / 5))
    print(s[i])
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discrete Fourier Transform&lt;/head&gt;
    &lt;p&gt;The keen-eyed might notice that the expression we obtained for \( f(n) \) is a finite Fourier series. This is not surprising, since the output of a Fizz Buzz programme depends only on \( n \bmod 15 . \) Any function on a finite cyclic group can be written exactly as a finite Fourier expansion. In this section, we recover the same function \( f(n) \) using the discrete Fourier transform. It is worth mentioning here that the calculations presented here are quite tedious to do by hand. Nevertheless, this section offers a glimpse of how such coefficients are calculated. By the end, we will arrive at exactly the same \( f(n) \) as before. There is nothing new to discover here. We simply obtain the result by a different, more direct and noticeably tedious method. If this doesn't sound interesting to you, you may safely skip this section.&lt;/p&gt;
    &lt;p&gt;We know that \( f(n) \) is a periodic function with period \( 15. \) To apply the discrete Fourier transform, we look at one complete period using the indices \( n = 1, 2, \dots, 15. \) Over this period, the values are: \begin{array}{c|ccccccccccccccc} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 &amp;amp; 11 &amp;amp; 12 &amp;amp; 13 &amp;amp; 14 &amp;amp; 15 \\ \hline f(n) &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 2 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 3 \end{array} The discrete Fourier transform gives us the constants defined by: \[ c_k = \frac{1}{15} \sum_{n = 1}^{15} f(n) e^{-2 \pi i k n / 15}, \] for \( k = 1, 2, \dots, 15. \) These constants reconstruct \( f(n) \) via the inverse transform: \[ f(n) = \sum_{k = 1}^{15} c_k e^{2 \pi i k n / 15} \] where \( n \in \mathbb{Z}. \) Let us compute the first constant: \[ c_1 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 3/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 5/15} + e^{-2 \pi i \cdot 6/15} + e^{-2 \pi i \cdot 9/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 10/15} + e^{-2 \pi i \cdot 12/15} + 3 e^{-2 \pi i \cdot 15/15} \end{aligned} \right) = 0. \] Similarly, \[ c_2 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 6/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 10/15} + e^{-2 \pi i \cdot 12/15} + e^{-2 \pi i \cdot 18/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 20/15} + e^{-2 \pi i \cdot 24/15} + 3 e^{-2 \pi i \cdot 30/15} \end{aligned} \right) = 0. \] and \[ c_3 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 9/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 15/15} + e^{-2 \pi i \cdot 18/15} + e^{-2 \pi i \cdot 27/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 30/15} + e^{-2 \pi i \cdot 36/15} + 3 e^{-2 \pi i \cdot 45/15} \end{aligned} \right) = \frac{2}{5}. \] Continuing in this manner, we find all the constants: \begin{align*} c_1 &amp;amp;= c_2 = c_4 = c_7 = c_8 = c_{11} = c_{13} = c_{14} = 0, \\ c_3 &amp;amp;= c_6 = c_9 = c_{12} = \frac{2}{5}, \\ c_5 &amp;amp;= c_{10} = \frac{1}{3}, \\ c_{15} &amp;amp;= \frac{11}{15}. \end{align*} Using the inverse transform, we get \begin{align*} f(n) &amp;amp;= \sum_{k = 1}^{15} c_k \, e^{2 \pi i k n / 15} \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{2 \pi i \cdot 3n/15} + e^{2 \pi i \cdot 6n/15} + e^{2 \pi i \cdot 9n/15} + e^{2 \pi i \cdot 12n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{2 \pi i \cdot 5n/15} + e^{2 \pi i \cdot 10n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{6 \pi i n/15} + e^{12 \pi i n/15} + e^{18 \pi i n/15} + e^{24 \pi i n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{10 \pi i n/15} + e^{20 \pi i n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{6 \pi i n/15} + e^{12 \pi i n/15} + e^{-12 \pi i n/15} + e^{-6 \pi i n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{10 \pi i n/15} + e^{-10 \pi i n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( 2 \cos \left( \frac{6 \pi n}{15} \right) + 2 \cos \left( \frac{12 \pi n}{15} \right) \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( 2 \cos \left( \frac{10 \pi n}{15} \right) \right) \\ &amp;amp;= \frac{11}{15} + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right) + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right). \end{align*} This gives us exactly the same function \( f(n) \) we obtained earlier. The difference is only in how we arrived there. Working out Fourier coefficients by hand is slow and mechanical. In practice these sums are almost always computed automatically by numerical software or computer algebra systems. Still, this exercise shows that our humble Fizz Buzz index function can be expressed precisely using the machinery of Fourier analysis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;To summarise, we have defined the Fizz Buzz sequence as \[ (s_{f(n)}(n))_{n = 1}^{\infty} \] where \[ f(n) = \frac{11}{15} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right). \] and \( s_0(n) = n, \) \( s_1(n) = \mathtt{Fizz}, \) \( s_2(n) = \mathtt{Buzz} \) and \( s_3(n) = \mathtt{FizzBuzz}. \) A Python program to print the Fizz Buzz sequence based on this definition was presented earlier. That program can be written more succinctly as follows:&lt;/p&gt;
    &lt;code&gt;
 from math import cos, pi
for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3) + (4 / 5) * (cos(2 * pi * n / 5) + cos(4 * pi * n / 5)))])
&lt;/code&gt;
    &lt;p&gt;We can also wrap this up nicely in a shell one-liner, in case you want to share it with your friends and family and surprise them:&lt;/p&gt;
    &lt;code&gt;python3 -c 'from math import cos, pi; [print([n, "Fizz", "Buzz", "FizzBuzz"][round(11/15 + (2/3) * cos(2*pi*n/3) + (4/5) * (cos(2*pi*n/5) + cos(4*pi*n/5)))]) for n in range(1, 101)]'&lt;/code&gt;
    &lt;p&gt;We have taken a simple counting game and turned it into a trigonometric construction: a finite Fourier series with a constant term \( 11/15 \) and three cosine terms with coefficients \( 2/3, \) \( 4/5 \) and \( 4/5. \) None of this makes Fizz Buzz any easier, of course, but it does show that every \( \mathtt{Fizz} \) and \( \mathtt{Buzz} \) now owes its existence to a particular set of Fourier coefficients. We began with the modest goal of making this simple problem more complicated. I think it is safe to say that we did not fall short.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006598</guid><pubDate>Fri, 21 Nov 2025 17:28:25 +0000</pubDate></item><item><title>Helping Valve to power up Steam devices</title><link>https://www.igalia.com/2025/11/helpingvalve.html</link><description>&lt;doc fingerprint="961b0d5348912672"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Helping Valve to Power Up Steam Devices&lt;/head&gt;
    &lt;p&gt;Last week, Valve stunned the computer gaming world by unveiling three new gaming devices at once: the Steam Frame, a wireless VR headset; the Steam Machine, a gaming console in the vein of a PlayStation or Xbox; and the Steam Controller, a handheld game controller. Successors to the highly successful Valve Index and Steam Deck, these devices are set to be released in the coming year.&lt;/p&gt;
    &lt;p&gt;Igalia has long worked with Valve on SteamOS, which will power the Machine and Frame, and is excited to be contributing to these new devices, particularly the Frame. The Frame, unlike the Machine or Deck which have x86 CPUs, runs on an ARM-based CPU.&lt;/p&gt;
    &lt;p&gt;Under normal circumstances, this would mean that only games compiled to run on ARM chips could be played on the Frame. In order to get around this barrier, a translation layer called FEX is used to run applications compiled for x86 chips (which are used in nearly all gaming PCs) on ARM chips by translating the x86 machine code into ARM64 machine code.&lt;/p&gt;
    &lt;p&gt;√¢If you love video games, like I do, working on FEX with Valve is a dream come true,√¢ said Paulo Matos, an engineer with Igalia√¢s Compilers Team. Even so, the challenges can be daunting, because making sure the translation is working often requires manual QA rather than automated testing. √¢You have to start a game, sometimes the error shows up in the colors or sound, or how the game behaves when you break down the door in the second level. Just debugging this can take a while,√¢ said Matos. √¢For optimization work I did early last year, I used a game called Psychonauts to test it. I must have played the first 3 to 4 minutes of the game many, many times for debugging. Looking at my history, Steam tells me I played it for 29 hours, but it was always the first few minutes, nothing else.√¢&lt;/p&gt;
    &lt;p&gt;Beyond the CPU, the Qualcomm Adreno 750 GPU used in the Steam Frame introduced its own set of challenges when it came to running desktop games, and other complex workloads, on these devices. Doing so requires a rock-solid Vulkan driver that can ensure correctness, eliminating major rendering bugs, while maintaining high performance. This is a very difficult combination to achieve, and yet that√¢s exactly what we√¢ve done for Valve with Mesa3D Turnip, a FOSS Vulkan driver for Qualcomm Adreno GPUs.&lt;/p&gt;
    &lt;p&gt;Before we started our work, critical optimizations such as LRZ (which you can learn more about from our blog post here) or the autotuner (and its subsequent overhaul) weren√¢t in place. Even worse, there wasn√¢t support for the Adreno 700-series GPUs at all, which we eventually added along with support for tiled rendering.&lt;/p&gt;
    &lt;p&gt;√¢We implemented many Vulkan extensions and reviewed numerous others,√¢ said Danylo Piliaiev, an engineer on the Graphics Team. √¢Over the years, we ensured that D3D11, D3D12, and OpenGL games rendered correctly through DXVK, vkd3d-proton, and Zink, investigating many rendering issues along the way. We achieved higher correctness than the proprietary driver and, in many cases, Mesa3D Turnip is faster as well.√¢&lt;/p&gt;
    &lt;p&gt;We√¢ve worked with many wonderful people from Valve, Google, and other companies to iterate on the Vulkan driver over the years in order to introduce new features, bug fixes, performance improvements, as well as debugging workflows. Some of those people decided to join Igalia later on, such as our colleague and Graphics Team developer Emma Anholt. √¢I√¢ve been working on Mesa for 22 years, and it√¢s great to have a home now where I can keep doing that work, across hardware projects, where the organization prioritizes the work experience of its developers and empowers them within the organization.√¢&lt;/p&gt;
    &lt;p&gt;Valve√¢s support in all this cannot be understated, either. Their choice to build their devices using open software like Mesa3D Turnip and FEX means they√¢re committed to working on and supporting improvements and optimizations that become available to anyone who uses the same open-source projects.&lt;/p&gt;
    &lt;p&gt;√¢We√¢ve received a lot of positive feedback about significantly improved performance and fewer rendering glitches from hobbyists who use these projects to run PC games on Android phones as a result of our work,√¢ said Dhruv Mark Collins, another Graphics Team engineer working on Turnip. √¢And it goes both ways! We√¢ve caught a couple of nasty bugs because of that widespread testing, which really emphasizes why the FOSS model is beneficial for everyone involved.√¢&lt;/p&gt;
    &lt;p&gt;An interesting area of graphics driver development is all the compiler work that is involved. Vulkan drivers such as Mesa3D Turnip need to process shader programs sent by the application to the GPU, and these programs govern how pixels in our screens are shaded or colored with geometry, textures, and lights while playing games. Job Noorman, an engineer from our Compilers Team, made significant contributions to the compiler used by Mesa3D Turnip. He also contributed to the Mesa3D NIR shader compiler, a common part that all Mesa drivers use, including RADV (most popularly used on the Steam Deck) or V3DV (used on Raspberry Pi boards).&lt;/p&gt;
    &lt;p&gt;As is normal for Igalia, while we focused on delivering results for our customer, we also made our work as widely useful as possible. For example: √¢While our target throughout our work has been the Snapdragon 8 Gen 3 that√¢s in the Frame, much of our work extends back through years of Snapdragon hardware, and we regression test it to make sure it stays Vulkan conformant,√¢ said Anholt. This means that Igalia√¢s work for the Frame has consistently passed Vulkan√¢s Conformance Test Suite (CTS) of over 2.8 million tests, some of which Igalia is involved in creating.&lt;/p&gt;
    &lt;p&gt;Our very own Vulkan CTS expert Ricardo Garc√Éa says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Igalia and other Valve contractors actively participate in several areas inside the Khronos Group, the organization maintaining and developing graphics API standards like Vulkan. We contribute specification fixes and feedback, and we are regularly involved in the development of many new Vulkan extensions. Some of these end up being critical for game developers, like mesh shading. Others ensure a smooth and efficient translation of other APIs like DirectX to Vulkan, or help take advantage of hardware features to ensure applications perform great across multiple platforms, both mobile like the Steam Frame or desktop like the Steam Machine. Having Vulkan CTS coverage for these new extensions is a critical step in the release process, helping make sure the specification is clear and drivers implement it correctly, and Igalia engineers have contributed millions of source code lines and tests since our collaboration with Valve started.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A huge challenge we faced in moving forward with development is ensuring that we didn√¢t introduce regressions, small innocent-seeming changes can completely break rendering on games in a way that even CTS might not catch. What automated testing could be done was often quite constrained, but Igalians found ways to push through the barriers. √¢I made a continuous integration test to automatically run single-frame captures of a wide range of games spanning D3D11, D3D9, D3D8, Vulkan, and OpenGL APIs,√¢ said Piliaiev, about the development covered in his recent XDC 2025 talk, √¢ensuring that we don√¢t have rendering or performance regressions.√¢&lt;/p&gt;
    &lt;p&gt;Looking ahead, Igalia√¢s work for Valve will continue to deliver benefits to the wider Linux Gaming ecosystem. For example, the Steam Frame, as a battery-powered VR headset, needs to deliver high performance within a limited power budget. A way to address this is to create a more efficient task scheduler, which is something Changwoo Min of Igalia√¢s Kernel Team has been working on. As he says, √¢I have been developing a customized CPU scheduler for gaming, named LAVD: Latency-criticality Aware Virtual Deadline scheduler.√¢&lt;/p&gt;
    &lt;p&gt;In general terms, a scheduler automatically identifies critical tasks and dynamically boosts their deadlines to improve responsiveness. Most task schedulers don√¢t take energy consumption into account, but the Rust-based LAVD is different. √¢LAVD makes scheduling decisions considering each chip√¢s performance versus energy trade-offs. It measures and predicts the required computing power on the fly, then selects the best set of CPUs to meet that demand with minimal energy consumption,√¢ said Min.&lt;/p&gt;
    &lt;p&gt;One of our other kernel engineers, Melissa Wen, has been working on AMD kernel display drivers to maintain good color management and HDR support for SteamOS across AMD hardware families, both for the Steam Deck and the Steam Machine. This is especially important with newer display hardware in the Steam Machine, which features some notable differences in color capabilities, aiming for more powerful and efficient color management which necessitated driver work.&lt;/p&gt;
    &lt;p&gt;√¢¬¶and that√¢s a wrap! We will continue our efforts toward improving future versions of SteamOS, and with a partner as strongly supportive as Valve, we expect to do more work to make Linux gaming even better. If any of that sounded interesting and you√¢d like to work with us to tackle tricky problems of your own, please get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006616</guid><pubDate>Fri, 21 Nov 2025 17:29:59 +0000</pubDate></item><item><title>Discontinuation of ARM Notebook with Snapdragon X Elite SoC</title><link>https://www.tuxedocomputers.com/en/Discontinuation-of-ARM-notebooks-with-Snapdragon-X-Elite-SoC.tuxedo</link><description>&lt;doc fingerprint="600c35d002b48faf"&gt;
  &lt;main&gt;
    &lt;p&gt;We ship your order to almost all countries, in Europe mostly even free of charge! The respective shipping costs and the cost threshold above which we will cover the costs for you can be found here or for international shipping in the table below.&lt;/p&gt;
    &lt;p&gt;There are no shipping costs within Germany for goods worth ‚Ç¨100 or more.&lt;/p&gt;
    &lt;p&gt;No matter how many small articles you order, such as USB stick card reader, LAN adapters or fan articles, with us, you pay a maximum of 7.99 ‚Ç¨ shipping costs.&lt;/p&gt;
    &lt;p&gt;You can check all occurring shipping costs or if we even deliver for free right before sending your order!&lt;/p&gt;
    &lt;p&gt;Here are the shipping costs as well as the amount threshold for your order. The threshold is referring to the total amount of your order, which enables free shipping.&lt;/p&gt;
    &lt;p&gt;For orders outside the EU there might be additional duties, taxes or charges needed to be paid by the customer. These don't have to be paid to the supplier, but to local authorities. Please check for any details with your local customs or tax authorities before ordering! But as a benefit you don't have to pay German taxes, this means you save up to 19%!&lt;lb/&gt; Due to the Brexit and the associated changes, there may be delays of several days in customs clearance on site for deliveries to the UK. This is not within our sphere of influence, so we ask for your understanding.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Country&lt;/cell&gt;
        &lt;cell&gt;Shipping Fee&lt;/cell&gt;
        &lt;cell&gt;Free Shipping From&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Albania&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Andorra&lt;/cell&gt;
        &lt;cell&gt;59,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Belgium&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bulgaria&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Denmark&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Estonia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Faroe Islands&lt;/cell&gt;
        &lt;cell&gt;129,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Finland&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Greece&lt;/cell&gt;
        &lt;cell&gt;22,90 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;United Kingdom&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hong Kong&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ireland&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Island&lt;/cell&gt;
        &lt;cell&gt;129,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Canada&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Croatia&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Latvia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Luxembourg&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Macau&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Malta&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Macedonia&lt;/cell&gt;
        &lt;cell&gt;59,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Moldova&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Monaco&lt;/cell&gt;
        &lt;cell&gt;19,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Montenegro&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Norway&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Austria&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Poland&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Portugal&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Romania&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;San Marino&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Switzerland&lt;/cell&gt;
        &lt;cell&gt;13,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Serbia&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Slovakia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Slovenia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Spain (without Canary Islands)&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Czech Republic&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hungary&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;USA including Hawaii&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;United Arabic Emirates&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cyprus&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Qatar&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If not stated differently in the article's description, we deliver goods in:&lt;/p&gt;
    &lt;p&gt;For orders paid in advance, the delivery time starts with receipt of the payment. Please keep in mind that there is no delivery on Sundays or on holidays.&lt;lb/&gt; For goods delivered as download, there will be no shipping fees due.&lt;lb/&gt; Access data for downloads are sent out via e-mail 1-3 working days after contract formation. For orders with advanced payment, we will deliver after receiving the payment. You can download the item by using the link sent to you via e-mail.&lt;lb/&gt; Self-pick-up of orders is not possible, unfortunately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46008156</guid><pubDate>Fri, 21 Nov 2025 19:46:34 +0000</pubDate></item><item><title>Pixar: The Early Days A never-before-seen 1996 interview</title><link>https://stevejobsarchive.com/stories/pixar-early-days</link><description>&lt;doc fingerprint="2501819f3360cdbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pixar: The Early Days&lt;/head&gt;
    &lt;p&gt;A never-before-seen 1996 interview&lt;/p&gt;
    &lt;p&gt;November 18, 2025&lt;/p&gt;
    &lt;p&gt;To mark Toy Story‚Äôs 30th anniversary, we‚Äôre sharing a never-before-seen interview with Steve from November 22, 1996‚Äîexactly one year after the film debuted in theaters.&lt;/p&gt;
    &lt;p&gt;Toy Story was the world‚Äôs first entirely computer-animated feature-length film. An instant hit with audiences and critics, it also transformed Pixar, which went public the week after its premiere. Buoyed by Toy Story‚Äôs success, Pixar‚Äôs stock price closed at nearly double its initial offering, giving it a market valuation of approximately $1.5 billion and marking the largest IPO of 1995. The following year, Toy Story was nominated for three Academy Awards en route to winning a Special Achievement Oscar in March. In July, Pixar announced that it would close its television-commercial unit to focus primarily on feature films. By the time of the interview, the team had grown by 70 percent in less than a year; A Bug‚Äôs Life was in production; and behind the scenes, Steve was using his new leverage to renegotiate Pixar‚Äôs partnership with Disney.&lt;/p&gt;
    &lt;p&gt;In this footage, Steve reveals the long game behind Pixar‚Äôs seeming overnight success. With striking clarity, he explains how its business model gives artists and engineers a stake in their creations, and he reflects on what Disney‚Äôs hard-won wisdom taught him about focus and discipline. He also talks about the challenge of leading a team so talented that it inverts the usual hierarchy, the incentives that inspire people to stay with the company, and the deeper purpose that unites them all: to tell stories that last and put something of enduring value into the culture.&lt;/p&gt;
    &lt;p&gt;At Pixar, Steve collaborated closely with president Ed Catmull and refined a management approach centered on creating the conditions for talent to thrive. When he returned to Apple a few weeks after this interview, his experience at Pixar shaped how he saw his role as CEO: building a company on timeless ideas made new through technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay Hungry, Stay Foolish&lt;/head&gt;
    &lt;p&gt;Celebrating Steve‚Äôs timeless address&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46008769</guid><pubDate>Fri, 21 Nov 2025 20:45:06 +0000</pubDate></item><item><title>LAPD helicopter tracker with real-time operating costs</title><link>https://lapdhelicoptertracker.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46009591</guid><pubDate>Fri, 21 Nov 2025 22:11:07 +0000</pubDate></item><item><title>Personal blogs are back, should niche blogs be next?</title><link>https://disassociated.com/personal-blogs-back-niche-blogs-next/</link><description>&lt;doc fingerprint="3b8090076bc54e9f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Personal blogs are back, should niche blogs be next?&lt;/head&gt;
    &lt;p&gt;20 November 2025&lt;/p&gt;
    &lt;p&gt;When it comes to blogging there are few rules. Write content that is somehow meaningful might be one of them though. I think it‚Äôs down to the individual to determine what constitutes meaningful.&lt;/p&gt;
    &lt;p&gt;In the hey-day, the so-called golden age of blogging, there were plenty of people prepared to offer definitions of meaningful, and how to write accordingly. It was natural. The web was once awash with all sorts of blogs. Likewise people who wanted to show others how to blog ‚Äúsuccessfully‚Äù.&lt;/p&gt;
    &lt;p&gt;Again, the definition of successful resided with the individual, but it was obvious this involved monetary return for some people. And why not. If you‚Äôre going to invest time and energy in creating a resource that is useful to other people, why shouldn‚Äôt you earn money, make a living even, from it?&lt;/p&gt;
    &lt;p&gt;One of these people blogging about blogging was Melbourne based Australian writer and author Darren Rowse, who launched his blogging resource Problogger in 2004. Without going into detail, because you can look it up for yourself, Rowse, as one of the earlier bloggers about blogging, did, and still does presumably, rather well for himself.&lt;/p&gt;
    &lt;p&gt;Rowse‚Äôs writing, and that of his contributors, attracted numerous readers keen to learn what they could about blogging, and the potential to make money from it.&lt;/p&gt;
    &lt;p&gt;Problogger is what‚Äôs called a niche blog. As a blog about blogging, it has a reasonably singular focus. Some people considered this niche principle to be a core tenet of blogging. There was this idea, in the earlier days of blogging, which possibly still persists, that blogs would do better if they had a speciality. Not only were search engines said to be in favour the approach, but the author of a speciality, or niche blog, would generally be considered to be an expert, of some sort, in their field.&lt;/p&gt;
    &lt;p&gt;A master of one trade, rather than the proverbial jack of all trades.&lt;/p&gt;
    &lt;p&gt;Regardless, the world was once full of blogs on every topic imaginable. It was a great time to be alive. If you wanted to learn about something in particular, there was a blog for you. Some publications featured quality content, others required a little fact checking, while some were definitely to be taken with a pinch of salt.&lt;/p&gt;
    &lt;p&gt;But niche blogging was never a format that suited everyone. There are people who did, still do, well, writing about a range, sometimes a wide range, of topics. Kottke is one of the better known blogs that does not have a specific speciality. Here, the publication itself is the speciality. To repeat what I wrote in the first sentence of this article: the rules of blogging are few.&lt;/p&gt;
    &lt;p&gt;But the facets of blogging covered at Problogger, and numerous other similar websites, usually only applied to blogs of a commercial nature. That‚Äôs not to say one or two personal bloggers might have looked at the tips posted there for increasing their audience, or improving their writing though. But in my view, personal bloggers were not, are not, part of Problogger‚Äôs target audience.&lt;/p&gt;
    &lt;p&gt;It‚Äôs been a long time since I last wrote about Problogger, let alone visited the website, maybe fifteen plus years, but a recent mention of it by Kev Quick, via ldstephens, caught my eye. But I don‚Äôt believe Rowse is being critical, in any way, of personal bloggers because they do not adhere to a niche or speciality publishing format. That‚Äôs not what Problogger, or Rowse, is about.&lt;/p&gt;
    &lt;p&gt;But this started me thinking, and writing another of my long posts.&lt;/p&gt;
    &lt;p&gt;In an age where social media, and influencers, have usurped blogs and their A-List authors, in the jostle for supremacy, it has to be wondered what role websites like Problogger still have. Only a handful of blogs generate liveable incomes today. Despite the doom and gloom though, the form has not completely died off. A backlash against social media, and a growing IndieWeb/SmallWeb community, has precipitated a revival in personal websites.&lt;/p&gt;
    &lt;p&gt;This is a largely non-commercial movement. Of course, there‚Äôs nothing wrong with personal websites. Many of us started out with them in the early days of the web. But the web was not only intended for personal journals. It was a vehicle for sharing all manner of information. The web could also empower individuals, and partnerships, to not only set up shop online, be that blogs, or quite literally shops, but potentially make a living at the same time.&lt;/p&gt;
    &lt;p&gt;But with the revival of personal blogs well underway, I think it‚Äôs time to bring niche blogs back into the fold. I‚Äôm talking about well written, quality, topic focused resources. This is material fast vanishing from the web, leaving ever diminishing options to source useful and accurate information. What are the alternatives? The misinformation morass that is social media? Being served AI generated summaries in response to search engine queries? A web choke full of AI slop?&lt;/p&gt;
    &lt;p&gt;At the same time, I‚Äôm not advocating for a return of niche blogs plastered with adverts, and popup boxes urging visitors to subscribe to say a newsletter, before they‚Äôve even had a chance to blink at what they came to read.&lt;/p&gt;
    &lt;p&gt;I‚Äôm talking about work produced by independent writers, with an interest in their subject matter, who are not backed by large media organisations, or private equity. This is bringing back reliable sources of information, that also recompenses the content writers in some way. Hopefully we‚Äôve learned a few lessons about monetisation since the earlier wave of niche blogging. We know it is possible to generate revenue without compromising the reader experience.&lt;/p&gt;
    &lt;p&gt;A resurgence in personal blogging is the first step in rebuilding a vibrant, thriving, web, of if you like, blogosphere. Now the focus needs to be on restoring the flow of accessible and trusted information.&lt;/p&gt;
    &lt;p&gt;RELATED CONTENT&lt;/p&gt;
    &lt;p&gt;blogs, history, IndieWeb, self publishing, SmallWeb, technology, trends&lt;/p&gt;
    &lt;head rend="h3"&gt;There's 2 comments on this post&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; On 22 November 2025 at 11:34 AM, Jorge Arango said:&lt;p&gt;Thanks for sharing. I‚Äôd like to believe a resurgence of personal blogs is underway. Is there data that substantiates this claim?&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46009894</guid><pubDate>Fri, 21 Nov 2025 22:40:28 +0000</pubDate></item><item><title>How I learned Vulkan and wrote a small game engine with it (2024)</title><link>https://edw.is/learning-vulkan/</link><description>&lt;doc fingerprint="23684b734fb50739"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I learned Vulkan and wrote a small game engine with it&lt;/head&gt;
    &lt;p&gt;tl;dr: I learned some Vulkan and made a game engine with two small game demos in 3 months.&lt;/p&gt;
    &lt;p&gt;The code for the engine and the games can be found here: https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;head rend="h2"&gt;Table Of Contents&lt;/head&gt;
    &lt;p&gt;This article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though).&lt;/p&gt;
    &lt;p&gt;The engine wasn‚Äôt implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the ‚Äúengine‚Äù afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see ‚ÄúBike-shedding‚Äù section below for more advice).&lt;/p&gt;
    &lt;head rend="h2"&gt;Preface&lt;/head&gt;
    &lt;p&gt;I‚Äôm a professional programmer, but I‚Äôm self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it.&lt;/p&gt;
    &lt;p&gt;The engine I wrote in Vulkan is mostly suited for smaller level-based games. I‚Äôll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people.&lt;/p&gt;
    &lt;quote&gt;Hopefully, this article will help make some things about Vulkan clearer to you. But you also need to be patient. It took me months to implement what I have today and I did it by cutting corners in many places. But if a self-taught programmer like me can build something with Vulkan, then so can you!&lt;/quote&gt;
    &lt;head rend="h2"&gt;Learning graphics programming&lt;/head&gt;
    &lt;quote&gt;This is a very high level overview of how I learned some graphics programming myself. If there‚Äôs interest, I might write another article with more resources and helpful guidelines.&lt;/quote&gt;
    &lt;p&gt;If you haven‚Äôt done any graphics programming before, you should start with OpenGL. It‚Äôs much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later.&lt;/p&gt;
    &lt;p&gt;Ideally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on.&lt;/p&gt;
    &lt;p&gt;I can recommend using the following resources to learn OpenGL:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://learnopengl.com/&lt;/item&gt;
      &lt;item&gt;Anton‚Äôs OpenGL 4 Tutorials book&lt;/item&gt;
      &lt;item&gt;Thorsten Thorm√É¬§hlen‚Äôs lectures lectures (watch the first 6 videos, the rest might be a bit too advanced)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sadly, most OpenGL resources don‚Äôt teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it‚Äôs not a necessity).&lt;/p&gt;
    &lt;p&gt;Here are some resources which teach you the latest OpenGL practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://juandiegomontoya.github.io/modern_opengl.html&lt;/item&gt;
      &lt;item&gt;https://github.com/fendevel/Guide-to-Modern-OpenGL-Functions&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;It‚Äôs also good to have some math knowledge, especially linear algebra: how to work with vectors, transformation matrices and quaternions. My favorite book about linear algebra/math is 3D Math Primer for Graphics and Game Development by F. Dunn and I. Parbery. You don‚Äôt need to read it all in one go - use it as a reference if some math in the OpenGL resources above doesn‚Äôt make sense to you.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Bike-shedding and how to avoid it&lt;/head&gt;
    &lt;p&gt;https://en.wikipedia.org/wiki/Law_of_triviality&lt;/p&gt;
    &lt;p&gt;Ah, bike-shedding‚Ä¶ Basically, it‚Äôs a harmful pattern of overthinking and over-engineering even the simplest things. It‚Äôs easy to fall into this trap when doing graphics programming (especially when doing Vulkan since you need to make many choices when implementing an engine with it).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Always ask yourself ‚ÄúDo I really need this?‚Äù, ‚ÄúWill this thing ever become a bottleneck?‚Äù.&lt;/item&gt;
      &lt;item&gt;Remember that you can always rewrite any part of your game/engine later.&lt;/item&gt;
      &lt;item&gt;Don‚Äôt implement something unless you need it right now. Don‚Äôt think ‚ÄúWell, a good engine needs X, right‚Ä¶?‚Äù.&lt;/item&gt;
      &lt;item&gt;Don‚Äôt try to make a general purpose game engine. It‚Äôs probably even better to not think about ‚Äúthe engine‚Äù at first and write a simple game.&lt;/item&gt;
      &lt;item&gt;Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea.&lt;/item&gt;
      &lt;item&gt;Be wary of people who tend to suggest complicated solutions to simple problems.&lt;/item&gt;
      &lt;item&gt;Don‚Äôt look too much at what other people do. I‚Äôve seen many over-engineered engines on GitHub - sometimes they‚Äôre that complex for a good reason (and there are years of work behind them). But you probably don‚Äôt need most of that complexity, especially for simpler games.&lt;/item&gt;
      &lt;item&gt;Don‚Äôt try to make magical wrappers around Vulkan interfaces prematurely, especially while you‚Äôre still learning Vulkan.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get it working first. Leave ‚ÄúTODO‚Äù/‚ÄúFIXME‚Äù comments in some places. Then move on to the next thing. Try to fix ‚ÄúTODO‚Äù/‚ÄúFIXME‚Äù places only when they really become problematic or bottleneck your performance. You‚Äôll be surprised to see how many things won‚Äôt become a problem at all.&lt;/p&gt;
    &lt;quote&gt;Some of this advice only applies when you‚Äôre working alone on a hobby project. Of course, it‚Äôs much harder to rewrite something from scratch when others start to depend on it and a ‚Äútemp hack‚Äù becomes a fundamental part of the engine which is very hard to change without breaking many things.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Why Vulkan?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Ask yourself if you need to learn a graphics API at all. If your main goal is to make a game as soon as possible, then you might be better off using something like Godot or Unreal Engine.&lt;/p&gt;
      &lt;p&gt;However, there‚Äôs nothing wrong with reinventing the wheel or doing something from scratch. Especially if you do it just for fun, to get into graphics programming or to get an in-depth knowledge about how something works.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK).&lt;/p&gt;
    &lt;p&gt;My use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me.&lt;/p&gt;
    &lt;p&gt;OpenGL is a good enough choice for many small games. But it‚Äôs very unlikely that it‚Äôll get new versions in the future (so you can‚Äôt use some newest GPU capabilities like ray tracing), it‚Äôs deprecated on macOS and its future is uncertain.&lt;/p&gt;
    &lt;p&gt;WebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It‚Äôs a pretty solid API, but I had some problems with it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It‚Äôs still not stable and there‚Äôs not a lot of tutorials and examples for it. This tutorial is fantastic, though.&lt;/item&gt;
      &lt;item&gt;WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL‚Äôs (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native).&lt;/item&gt;
      &lt;item&gt;On desktop, it‚Äôs essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me: &lt;list rend="ul"&gt;&lt;item&gt;It can‚Äôt do things some things that Vulkan or DirectX can do.&lt;/item&gt;&lt;item&gt;It has more limitations than native graphic APIs since it needs to behave similarly between them.&lt;/item&gt;&lt;item&gt;RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don‚Äôt have 1-to-1 mapping between WebGPU calls and native API calls.&lt;/item&gt;&lt;item&gt;Using Dawn and WGPU feels like using bgfx or sokol. You don‚Äôt get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;No bindless textures (WIP discussion here).&lt;/item&gt;
      &lt;item&gt;No push constants (WIP discussion here).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Still, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot.&lt;/item&gt;
      &lt;item&gt;It‚Äôs also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot.&lt;/item&gt;
      &lt;item&gt;It requires a lot less boilerplate to get things on the screen (compared to Vulkan).&lt;/item&gt;
      &lt;item&gt;You don‚Äôt have to deal with explicit synchronization which makes things much simpler.&lt;/item&gt;
      &lt;item&gt;You can make your games playable inside the browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Learning Vulkan&lt;/head&gt;
    &lt;p&gt;Learning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying ‚Äúyou‚Äôre basically writing a graphics driver when writing in Vulkan‚Äù which also made Vulkan sounds like an incredibly complicated thing.&lt;/p&gt;
    &lt;p&gt;I have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like &lt;code&gt;GPUDevice.cpp&lt;/code&gt; or &lt;code&gt;GPUAbstraction.cpp&lt;/code&gt; which had thousands of lines of scary C++ code.&lt;/p&gt;
    &lt;p&gt;The situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before.&lt;/p&gt;
    &lt;p&gt;The best Vulkan learning resource which helped me get started was vkguide. If you‚Äôre starting from scratch, just go through it all (you might stop at ‚ÄúGPU driver rendering‚Äù chapter at first - many simple games probably won‚Äôt need this level of complexity)&lt;/p&gt;
    &lt;p&gt;Vulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip ‚ÄúReal-Time Ray Tracing‚Äù chapter for now). I especially found a lecture on synchronization very helpful.&lt;/p&gt;
    &lt;p&gt;Here are some more advanced Vulkan books that also helped me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3D Graphics Rendering Cookbook by Sergey Kosarevsky and Viktor Latypov. There is the second edition in the writing and it‚Äôs promising to be better than the first one. The second edition is not released yet, but the source code for it can be found here: https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook-Second-Edition&lt;/item&gt;
      &lt;item&gt;Mastering Graphics Programming with Vulkan by Marco Castorina, Gabriel Sassone. Very advanced book which explains some of the ‚Äúcutting edge‚Äù graphics programming concepts (I mostly read it to understand where to go further, but didn‚Äôt have time to implement most of it). The source code for it can be found here: https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here‚Äôs the result of my first month of learning Vulkan:&lt;/p&gt;
    &lt;p&gt;By this point I had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;glTF model loading&lt;/item&gt;
      &lt;item&gt;Compute skinning&lt;/item&gt;
      &lt;item&gt;Frustum culling&lt;/item&gt;
      &lt;item&gt;Shadow mapping and cascaded shadow maps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won‚Äôt seem as scary anymore.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see how the engine works and some useful things I learned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Engine overview and frame analysis&lt;/head&gt;
    &lt;p&gt;https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;p&gt;My engine is called EDBR (Elias Daler‚Äôs Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I‚Äôm going to use for my further projects.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At the time of writing this article, the source code line counts are as follows:&lt;/p&gt;
      &lt;item&gt;Engine itself: 19k lines of code&lt;/item&gt;
      &lt;item&gt;6.7k LoC related to graphics,&lt;/item&gt;
      &lt;item&gt;2k LoC are light abstractions around Vulkan&lt;/item&gt;
      &lt;item&gt;3D cat game: 4.6k LoC&lt;/item&gt;
      &lt;item&gt;2D platformer game: 1.2k LoC&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;I copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions.&lt;/p&gt;
    &lt;quote&gt;You can follow the commit history which shows how I started from clearing the screen, drawing the first triangle, drawing a textured quad and so on. It might be easier to understand the engine when it was simpler and smaller.&lt;/quote&gt;
    &lt;p&gt;Let‚Äôs see how this frame in rendered:&lt;/p&gt;
    &lt;quote&gt;Most of the steps will be explained in more detail below.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skinning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSM (Cascaded Shadow Mapping)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Geometry + shading&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call:&lt;/p&gt;
    &lt;p&gt;Everything is drawn into a multi-sampled texture. Here‚Äôs how it looks after resolve:&lt;/p&gt;
    &lt;p&gt;(Open the previous two screenshots in the next tab and flip between the tabs to see the difference more clearly)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Depth resolve&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Depth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it‚Äôll be useful in the next step).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Post FX&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some post FX is applied - right now it‚Äôs only depth fog (I use ‚Äúdepth resolve‚Äù texture from the previous step here), afterwards tone-mapping and bloom will also be done here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dialogue UI is drawn. Everything is done in one draw call (more is explained in ‚ÄúDrawing many sprites‚Äù section)&lt;/p&gt;
    &lt;p&gt;And that‚Äôs it! It‚Äôs pretty basic right now and would probably become much more complex in the future (see ‚ÄúFuture work‚Äù section).&lt;/p&gt;
    &lt;head rend="h2"&gt;General advice&lt;/head&gt;
    &lt;head rend="h3"&gt;Recommended Vulkan libraries&lt;/head&gt;
    &lt;p&gt;There are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vk-bootstrap - https://github.com/charles-lunarg/vk-bootstrap&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of ‚Äúwrapper function vs function in the API spec‚Äù in your head at all times.&lt;/p&gt;
    &lt;p&gt;Thankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn‚Äôt attempt to be a wrapper around every Vulkan function.&lt;/p&gt;
    &lt;quote&gt;When I was learning Vulkan, I started doing Vulkan from scratch, without using any 3rd party libraries. Replacing big amounts of the initialization code with vk-bootstrap was a joy. It‚Äôs really worth it.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan Memory Allocator (VMA) - https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I‚Äôm glad that I didn‚Äôt have to do it on my own.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;volk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Volk was very useful for me for simplifying extension function loading. For example, if you want to use very useful &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; for setting debug names for your objects (useful for RenderDoc captures and validation errors), you‚Äôll need to do this if you don‚Äôt use volk:&lt;/p&gt;
    &lt;code&gt;// store this pointer somewhere
PFN_vkSetDebugUtilsObjectNameEXT pfnSetDebugUtilsObjectNameEXT;

// during your game init
pfnSetDebugUtilsObjectNameEXT = (PFN_vkSetDebugUtilsObjectNameEXT)
    vkGetInstanceProcAddr(instance, "vkSetDebugUtilsObjectNameEXT");

// and finally in your game code
pfnSetDebugUtilsObjectNameEXT(device, ...);
&lt;/code&gt;
    &lt;p&gt;With volk, all the extensions are immediately loaded after you call &lt;code&gt;volkInitialize&lt;/code&gt; and you don‚Äôt need to store these pointers everywhere. You just include &lt;code&gt;volk.h&lt;/code&gt; and call &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; - beautiful!&lt;/p&gt;
    &lt;head rend="h3"&gt;GfxDevice abstraction&lt;/head&gt;
    &lt;p&gt;I have a &lt;code&gt;GfxDevice&lt;/code&gt; class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt; and so on). A single &lt;code&gt;GfxDevice&lt;/code&gt; instance is created on the startup and then gets passed around.&lt;/p&gt;
    &lt;p&gt;It handles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan context initialization.&lt;/item&gt;
      &lt;item&gt;Swapchain creation and management.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;beginFrame&lt;/code&gt;returns a new&lt;code&gt;VkCommandBuffer&lt;/code&gt;which is later used in all the drawing steps.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;endFrame&lt;/code&gt;does drawing to the swapchain and does sync between the frames.&lt;/item&gt;
      &lt;item&gt;Image creation and loading textures from files.&lt;/item&gt;
      &lt;item&gt;Buffer creation.&lt;/item&gt;
      &lt;item&gt;Bindless descriptor set management (see ‚ÄúBindless descriptors‚Äù section below).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That‚Äôs‚Ä¶ a lot of things. However, it‚Äôs not that big: &lt;code&gt;GfxDevice.cpp&lt;/code&gt; is only 714 lines at the time of writing this article. It‚Äôs more convenient to pass one object into the function instead of many (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt;, &lt;code&gt;VmaAllocator&lt;/code&gt; and so on).&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling shaders&lt;/head&gt;
    &lt;p&gt;In Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience.&lt;/p&gt;
    &lt;p&gt;You can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don‚Äôt have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don‚Äôt get compile errors during the runtime.&lt;/p&gt;
    &lt;p&gt;I use glslc (from shaderc project, it‚Äôs included in Vulkan SDK) which allows you to specify a &lt;code&gt;DEPFILE&lt;/code&gt; in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the &lt;code&gt;DEPFILE&lt;/code&gt;, CMake won‚Äôt be able to see which files shader files need to be recompiled and will only recompile the file which was changed.&lt;/p&gt;
    &lt;p&gt;My CMake script for building shaders looks like this:&lt;/p&gt;
    &lt;code&gt;function (target_shaders target shaders)
    set(SHADERS_BUILD_DIR "${CMAKE_CURRENT_BINARY_DIR}/shaders")
    file(MAKE_DIRECTORY "${SHADERS_BUILD_DIR}")
    foreach (SHADER_PATH ${SHADERS})
        get_filename_component(SHADER_FILENAME "${SHADER_PATH}" NAME)
        set(SHADER_SPIRV_PATH "${SHADERS_BUILD_DIR}/${SHADER_FILENAME}.spv")
        set(DEPFILE "${SHADER_SPIRV_PATH}.d")
        add_custom_command(
          COMMENT "Building ${SHADER_FILENAME}"
          OUTPUT "${SHADER_SPIRV_PATH}"
          COMMAND ${GLSLC} "${SHADER_PATH}" -o "${SHADER_SPIRV_PATH}" -MD -MF ${DEPFILE} -g
          DEPENDS "${SHADER_PATH}"
          DEPFILE "${DEPFILE}"
        )
        list(APPEND SPIRV_BINARY_FILES ${SHADER_SPIRV_PATH})
    endforeach()

    set(shaders_target_name "${target}_build_shaders")
    add_custom_target(${shaders_target_name}
      DEPENDS ${SPIRV_BINARY_FILES}
    )
    add_dependencies(${target} ${shaders_target_name})
endfunction()
&lt;/code&gt;
    &lt;p&gt;and then in the main CMakeLists file:&lt;/p&gt;
    &lt;code&gt;set(SHADERS
    skybox.frag
    skinning.comp
    ... // etc
)

# prepend shaders directory path
get_target_property(EDBR_SOURCE_DIR edbr SOURCE_DIR)
set(EDBR_SHADERS_DIR "${EDBR_SOURCE_DIR}/src/shaders/")
list(TRANSFORM SHADERS PREPEND "${EDBR_SHADERS_DIR}")

target_shaders(game ${SHADERS})
&lt;/code&gt;
    &lt;p&gt;Now, when you build a &lt;code&gt;game&lt;/code&gt; target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Push constants, descriptor sets and bindless descriptors&lt;/head&gt;
    &lt;p&gt;Passing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this:&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In C++ code:&lt;/p&gt;
    &lt;code&gt;const auto loc = glGetUniformLocation(shader, "someFloat");
glUseProgram(shader);
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;You can also use explicit uniform location like this.&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;layout(location = 20) uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In code:&lt;/p&gt;
    &lt;code&gt;const auto loc = 20;
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;In Vulkan, you need to group your uniforms into ‚Äúdescriptor sets‚Äù:&lt;/p&gt;
    &lt;code&gt;// set 0
layout (set = 0, binding = 0) uniform float someFloat;
layout (set = 0, binding = 1) uniform mat4 someMatrix;
// set 1
layout (set = 1, binding = 0) uniform float someOtherFloat;
... // etc.
&lt;/code&gt;
    &lt;p&gt;Now, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole &lt;code&gt;VkWriteDescriptorSet&lt;/code&gt; + &lt;code&gt;vkUpdateDescriptorSets&lt;/code&gt; thing, call &lt;code&gt;vkCmdBindDescriptorSets&lt;/code&gt; for each descriptor set and so on.&lt;/p&gt;
    &lt;p&gt;I‚Äôll explain later how I avoided using descriptor sets by using bindless descriptors and buffer device access. Basically, I only have one ‚Äúglobal‚Äù descriptor set for bindless textures and samplers, and that‚Äôs it. Everything else is passed via push constants which makes everything much easier to handle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pipeline pattern&lt;/head&gt;
    &lt;p&gt;I separate drawing steps into ‚Äúpipeline‚Äù classes.&lt;/p&gt;
    &lt;p&gt;Most of them look like this:&lt;/p&gt;
    &lt;code&gt;class PostFXPipeline {
public:
    void init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat);
    void cleanup(VkDevice device);

    void draw(
        VkCommandBuffer cmd,
        GfxDevice&amp;amp; gfxDevice,
        const GPUImage&amp;amp; drawImage,
        const GPUImage&amp;amp; depthImage,
        const GPUBuffer&amp;amp; sceneDataBuffer);

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;

    struct PushConstants {
        VkDeviceAddress sceneDataBuffer;
        std::uint32_t drawImageId;
        std::uint32_t depthImageId;
    };
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;init&lt;/code&gt;loads needed shaders and initializes&lt;code&gt;pipeline&lt;/code&gt;and&lt;code&gt;pipelineLayout&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat)
{
    const auto&amp;amp; device = gfxDevice.getDevice();

    const auto pcRange = VkPushConstantRange{
        .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT,
        .offset = 0,
        .size = sizeof(PushConstants),
    };

    const auto layouts = std::array{gfxDevice.getBindlessDescSetLayout()};
    const auto pushConstantRanges = std::array{pcRange};
    pipelineLayout = vkutil::createPipelineLayout(device, layouts, pushConstantRanges);

    const auto vertexShader =
        vkutil::loadShaderModule("shaders/fullscreen_triangle.vert.spv", device);
    const auto fragShader =
        vkutil::loadShaderModule("shaders/postfx.frag.spv", device);
    pipeline = PipelineBuilder{pipelineLayout}
                   .setShaders(vertexShader, fragShader)
                   .setInputTopology(VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST)
                   .setPolygonMode(VK_POLYGON_MODE_FILL)
                   .disableCulling()
                   .setMultisamplingNone()
                   .disableBlending()
                   .setColorAttachmentFormat(drawImageFormat)
                   .disableDepthTest()
                   .build(device);
    vkutil::addDebugLabel(device, pipeline, "postFX pipeline");

    vkDestroyShaderModule(device, vertexShader, nullptr);
    vkDestroyShaderModule(device, fragShader, nullptr);
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;init&lt;/code&gt; function is usually called once during the engine initialization. &lt;code&gt;PipelineBuilder&lt;/code&gt; abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cleanup&lt;/code&gt;does all the needed cleanup. It usually simply destroys the pipeline and its layout:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::cleanup(VkDevice device)
{
    vkDestroyPipeline(device, pipeline, nullptr);
    vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;draw&lt;/code&gt;is called each frame and all the needed inputs are passed as arguments. It‚Äôs assumed that the sync is performed outside of the&lt;code&gt;draw&lt;/code&gt;call (see ‚ÄúSynchronization‚Äù section below). Some pipelines are only called once per frame - some either take&lt;code&gt;std::vector&lt;/code&gt;of objects to draw or are called like this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;for (const auto&amp;amp; mesh : meshes) {
    somePipeline.draw(cmd, gfxDevice, mesh, ...);
}
&lt;/code&gt;
    &lt;p&gt;The typical &lt;code&gt;draw&lt;/code&gt; function looks like this:&lt;/p&gt;
    &lt;code&gt;void PostFXPipeline::draw(
    VkCommandBuffer cmd,
    GfxDevice&amp;amp; gfxDevice,
    const GPUImage&amp;amp; drawImage,
    const GPUImage&amp;amp; depthImage,
    const GPUBuffer&amp;amp; sceneDataBuffer)
{
    // Bind the pipeline
    vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);

    // Bind the bindless descriptor set
    gfxDevice.bindBindlessDescSet(cmd, pipelineLayout);

    // Handle push constants
    const auto pcs = PushConstants{
        // BDA - explained below
        .sceneDataBuffer = sceneDataBuffer.address,
        // bindless texture ids - no need for desc. sets!
        // explained below
        .drawImageId = drawImage.getBindlessId(),
        .depthImageId = depthImage.getBindlessId(),
    };
    vkCmdPushConstants(
        cmd, pipelineLayout, VK_SHADER_STAGE_FRAGMENT_BIT, 0, sizeof(PushConstants), &amp;amp;pcs);

    // Finally, do some drawing. Here we're drawing a fullscreen triangle
    // to do a full-screen effect.
    vkCmdDraw(cmd, 3, 1, 0, 0);
}
&lt;/code&gt;
    &lt;p&gt;Note another thing: it‚Äôs assumed that &lt;code&gt;draw&lt;/code&gt; is called between &lt;code&gt;vkCmdBeginRendering&lt;/code&gt; and &lt;code&gt;vkCmdEndRendering&lt;/code&gt; - the render pass itself doesn‚Äôt care what texture it renders to - the caller of &lt;code&gt;draw&lt;/code&gt; is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.:&lt;/p&gt;
    &lt;code&gt;// handy wrapper for creating VkRenderingInfo
const auto renderInfo = vkutil::createRenderingInfo({
    .renderExtent = drawImage.getExtent2D(),
    .colorImageView = drawImage.imageView,
    .colorImageClearValue = glm::vec4{0.f, 0.f, 0.f, 1.f},
    .depthImageView = depthImage.imageView,
    .depthImageClearValue = 0.f,
    // for MSAA
    .resolveImageView = resolveImage.imageView,
});

vkCmdBeginRendering(cmd, &amp;amp;renderInfo.renderingInfo);

// draw meshes
for (const auto&amp;amp; mesh : meshesToDraw) {
    meshPipeline.draw(cmd, gfxDevice, mesh, ...);
}
// draw sky
skyboxPipeline.draw(cmd, gfxDevice, camera);

vkCmdEndRendering(cmd);
&lt;/code&gt;
    &lt;quote&gt;I use&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;everywhere. I don‚Äôt use Vulkan render passes and subpasses at all. I‚Äôve heard that they‚Äôre more efficient on tile-based GPUs, but I don‚Äôt care about mobile support for now.&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;just makes everything much easier.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Using programmable vertex pulling (PVP) + buffer device address (BDA)&lt;/head&gt;
    &lt;p&gt;I have one vertex type for all the meshes. It looks like this:&lt;/p&gt;
    &lt;code&gt;struct Vertex {
    vec3 position;
    float uv_x;
    vec3 normal;
    float uv_y;
    vec4 tangent;
};
&lt;/code&gt;
    &lt;quote&gt;Of course, you can greatly optimize it using various methods, but it‚Äôs good enough for me for now. The&lt;code&gt;uv_x&lt;/code&gt;/&lt;code&gt;uv_y&lt;/code&gt;separation comes from vkguide - I think it‚Äôs a nice idea to get good alignment and not waste any bytes&lt;/quote&gt;
    &lt;p&gt;The vertices are accessed in the shader like this:&lt;/p&gt;
    &lt;code&gt;layout (buffer_reference, std430) readonly buffer VertexBuffer {
    Vertex vertices[];
};

layout (push_constant, scalar) uniform constants
{
    VertexBuffer vertexBuffer;
    ... // other stuff
} pcs;

void main()
{
    Vertex v = pcs.vertexBuffer.vertices[gl_VertexIndex];
    ...
}
&lt;/code&gt;
    &lt;p&gt;PVP frees you from having to define vertex format (no more VAOs like in OpenGL or &lt;code&gt;VkVertexInputBindingDescription&lt;/code&gt; + &lt;code&gt;VkVertexInputAttributeDescription&lt;/code&gt; in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that‚Äôs it.&lt;/p&gt;
    &lt;code&gt;
  Also note the  scalar layout for push constants. I use it for all the buffers too. Compared to ‚Äústd430‚Äù layout, it makes alignment a lot more easy to handle - it almost works the same as in C++ and greatly reduces the need for ‚Äúpadding‚Äù members in C++ structs.
&lt;/code&gt;
    &lt;head rend="h3"&gt;Bindless descriptors&lt;/head&gt;
    &lt;p&gt;Textures were painful to work with even in OpenGL - you had ‚Äútexture slots‚Äù which were awkward to work with. You couldn‚Äôt just sample any texture from the shader if it wasn‚Äôt bound to a texture slot beforehand. &lt;code&gt;ARB_bindless_texture&lt;/code&gt; changed that and made many things easier.&lt;/p&gt;
    &lt;p&gt;Vulkan doesn‚Äôt have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
layout (set = 0, binding = 0) uniform texture2D textures[];
...
layout (set = 0, binding = 1) uniform sampler samplers[];
&lt;/code&gt;
    &lt;p&gt;You‚Äôll need to maintain a list of all your textures using some ‚Äúimage manager‚Äù and when a new texture is loaded, you need to insert it into the &lt;code&gt;textures&lt;/code&gt; array. The index at which you inserted it becomes a bindless ‚Äútexture id‚Äù which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this:&lt;/p&gt;
    &lt;code&gt;layout (push_constant, scalar) uniform constants
{
  uint textureId;
  ...
} pcs;
&lt;/code&gt;
    &lt;p&gt;and then you can sample your texture in the fragment shader like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
#define NEAREST_SAMPLER_ID 0
...

vec4 sampleTexture2DNearest(uint texID, vec2 uv) {
    return texture(nonuniformEXT(sampler2D(textures[texID], samplers[NEAREST_SAMPLER_ID])), uv);
}

// shader.frag
vec4 color = sampleTexture2DNearest(pcs.textureId, inUV);
&lt;/code&gt;
    &lt;p&gt;Two things to note:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into &lt;code&gt;samplers&lt;/code&gt;array on the startup.&lt;/item&gt;
      &lt;item&gt;The wrapper function makes the process of sampling a lot more convenient.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;
  The placement of  nonuniformEXT is somewhat tricky and is explained very well here.
&lt;/code&gt;
    &lt;p&gt;I use bindless ids for the mesh material buffer which looks like this:&lt;/p&gt;
    &lt;code&gt;struct MaterialData {
    vec4 baseColor;
    vec4 metallicRoughnessEmissive;
    uint diffuseTex;
    uint normalTex;
    uint metallicRoughnessTex;
    uint emissiveTex;
};

layout (buffer_reference, std430) readonly buffer MaterialsBuffer {
    MaterialData data[];
} materialsBuffer;
&lt;/code&gt;
    &lt;p&gt;Now I can only pass material ID in my push constants and then sample texture like this in the fragment shader:&lt;/p&gt;
    &lt;code&gt;MaterialData material = materials[pcs.materialID];
vec4 diffuse = sampleTexture2DLinear(material.diffuseTex, inUV);
...
&lt;/code&gt;
    &lt;p&gt;Neat! No more bulky descriptor sets, just one int per material in the push constants.&lt;/p&gt;
    &lt;p&gt;You can also put different texture types into the same set like this (this is needed for being able to access textures of types other than &lt;code&gt;texture2D&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;layout (set = 0, binding = 0) uniform texture2D textures[];
layout (set = 0, binding = 0) uniform texture2DMS texturesMS[];
layout (set = 0, binding = 0) uniform textureCube textureCubes[];
layout (set = 0, binding = 0) uniform texture2DArray textureArrays[];
&lt;/code&gt;
    &lt;p&gt;And here‚Äôs how you can sample &lt;code&gt;textureCube&lt;/code&gt; with a linear sampler (note that we use &lt;code&gt;textureCubes&lt;/code&gt; here instead of &lt;code&gt;textures&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;vec4 sampleTextureCubeLinear(uint texID, vec3 p) {
    return texture(nonuniformEXT(samplerCube(textureCubes[texID], samplers[NEAREST_SAMPLER_ID])), p);
}
&lt;/code&gt;
    &lt;p&gt;Here‚Äôs a very good article on using bindless textures in Vulkan:&lt;/p&gt;
    &lt;p&gt;https://jorenjoestar.github.io/post/vulkan_bindless_texture/&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling dynamic data which needs to be uploaded every frame&lt;/head&gt;
    &lt;p&gt;I find it useful to pre-allocate big arrays of things and push stuff to them in every frame. Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big &lt;code&gt;mat4&lt;/code&gt; array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later).&lt;/p&gt;
    &lt;p&gt;Here are two ways of doing this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;Have N buffers on GPU and swap between them.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vkguide explains the concept of ‚Äúin flight‚Äù frames pretty well. To handle this parallelism properly, you need to have one buffer for the ‚Äúcurrently drawing‚Äù frame and one buffer for ‚Äúcurrently recording new drawing commands‚Äù frame to not have races. (If you have more frames in flight, you‚Äôll need to allocate more than 2 buffers)&lt;/p&gt;
    &lt;p&gt;This means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer‚Ä¶ and so on.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;One buffer on GPU and N ‚Äústaging‚Äù buffers on CPU&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This might be useful if you need to conserve some memory on the GPU.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see how it works in my engine:&lt;/p&gt;
    &lt;code&gt;class NBuffer {
public:
    void init(
        GfxDevice&amp;amp; gfxDevice,
        VkBufferUsageFlags usage,
        std::size_t dataSize,
        std::size_t numFramesInFlight,
        const char* label);

    void cleanup(GfxDevice&amp;amp; gfxDevice);

    void uploadNewData(
        VkCommandBuffer cmd,
        std::size_t frameIndex,
        void* newData,
        std::size_t dataSize,
        std::size_t offset = 0);

    const GPUBuffer&amp;amp; getBuffer() const { return gpuBuffer; }

private:
    std::size_t framesInFlight{0};
    std::size_t gpuBufferSize{0};
    std::vector&amp;lt;GPUBuffer&amp;gt; stagingBuffers;
    GPUBuffer gpuBuffer;
    bool initialized{false};
};

void NBuffer::init(
    GfxDevice&amp;amp; gfxDevice,
    VkBufferUsageFlags usage,
    std::size_t dataSize,
    std::size_t numFramesInFlight,
    const char* label)
{
    ...

    gpuBuffer = gfxDevice.createBuffer(
        dataSize, usage | VK_IMAGE_USAGE_TRANSFER_DST_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE);
    vkutil::addDebugLabel(gfxDevice.getDevice(), gpuBuffer.buffer, label);

    for (std::size_t i = 0; i &amp;lt; numFramesInFlight; ++i) {
        stagingBuffers.push_back(gfxDevice.createBuffer(
            dataSize, usage | VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST));
    }

    ...
}
&lt;/code&gt;
    &lt;p&gt;Note how staging buffers are created using VMA‚Äôs &lt;code&gt;PREFER_HOST&lt;/code&gt; flag and the ‚Äúmain‚Äù buffer from which we read in the shader is using the &lt;code&gt;PREFER_DEVICE&lt;/code&gt; flag.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how new data is uploaded (full implementation):&lt;/p&gt;
    &lt;code&gt;void NBuffer::uploadNewData(
    VkCommandBuffer cmd,
    std::size_t frameIndex,
    void* newData,
    std::size_t dataSize,
    std::size_t offset) const
{
    assert(initialized);
    assert(frameIndex &amp;lt; framesInFlight);
    assert(offset + dataSize &amp;lt;= gpuBufferSize &amp;amp;&amp;amp; "NBuffer::uploadNewData: out of bounds write");

    if (dataSize == 0) {
        return;
    }

    // sync with previous read
    ... // READ BARRIER CODE HERE

    auto&amp;amp; staging = stagingBuffers[frameIndex];
    auto* mappedData = reinterpret_cast&amp;lt;std::uint8_t*&amp;gt;(staging.info.pMappedData);
    memcpy((void*)&amp;amp;mappedData[offset], newData, dataSize);

    const auto region = VkBufferCopy2{
        .sType = VK_STRUCTURE_TYPE_BUFFER_COPY_2,
        .srcOffset = (VkDeviceSize)offset,
        .dstOffset = (VkDeviceSize)offset,
        .size = dataSize,
    };
    const auto bufCopyInfo = VkCopyBufferInfo2{
        .sType = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2,
        .srcBuffer = staging.buffer,
        .dstBuffer = gpuBuffer.buffer,
        .regionCount = 1,
        .pRegions = &amp;amp;region,
    };

    vkCmdCopyBuffer2(cmd, &amp;amp;bufCopyInfo);

    // sync with write
    ... // WRITE BARRIER CODE HERE
}
&lt;/code&gt;
    &lt;p&gt;I‚Äôd go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I‚Äôve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame.&lt;/p&gt;
    &lt;head rend="h3"&gt;Destructors, deletion queue and cleanup&lt;/head&gt;
    &lt;p&gt;Now, this might be somewhat controversial‚Ä¶ but I didn‚Äôt find much use of the deletion queue pattern used in vkguide. I don‚Äôt really need to allocated/destroy new objects on every frame.&lt;/p&gt;
    &lt;p&gt;Using C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move &lt;code&gt;operator=&lt;/code&gt;‚Ä¶ It adds an additional layer of complexity.&lt;/p&gt;
    &lt;p&gt;In most cases, the cleanup of Vulkan objects happens in one place - and you don‚Äôt want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    SomeOtherClass b;

    void init() {
        ...
    }

    void cleanup() {
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;If you want to cleanup &lt;code&gt;SomeOtherClass&lt;/code&gt; resources (e.g. the instance of &lt;code&gt;SomeOtherClass&lt;/code&gt; has a &lt;code&gt;VkPipeline&lt;/code&gt; object) during &lt;code&gt;SomeClass::cleanup&lt;/code&gt;, you can‚Äôt do that if the cleanup of &lt;code&gt;SomeOtherClass&lt;/code&gt; is performed in its destructor.&lt;/p&gt;
    &lt;p&gt;Of course, you can do this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    std::unique_ptr&amp;lt;SomeOtherClass&amp;gt; b;

    void init() {
        b = std::make_unique&amp;lt;SomeOtherClass&amp;gt;();
        ...
    }

    void cleanup() {
        b.reset();
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;‚Ä¶ but I don‚Äôt like how it introduces a dynamic allocation and requires you to do write more code (and it‚Äôs not that much different from calling a &lt;code&gt;cleanup&lt;/code&gt; function manually).&lt;/p&gt;
    &lt;p&gt;Right now, I prefer to clean up stuff directly, e.g.&lt;/p&gt;
    &lt;code&gt;class SkyboxPipeline {
public:
    void cleanup(VkDevice device) {
        vkDestroyPipeline(device, pipeline, nullptr);
        vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
    }

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;
    ...
}

// in GameRenderer.cpp:
void GameRenderer::cleanup(VkDevice device) {
    ...
    skyboxPipeline.cleanup(device);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This approach is not perfect - first of all, it‚Äôs easy to forget to call &lt;code&gt;cleanup&lt;/code&gt; function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown:&lt;/p&gt;
    &lt;code&gt;Validation Error: [ VUID-vkDestroyDevice-device-05137 ] Object 0: handle = 0x4256c1000000005d, type = VK_OBJECT_TYPE_PIPELINE_LAYOUT; | MessageID = 0x4872eaa0 | vkCreateDevice():  OBJ ERROR : For VkDevice 0x27bd530[], VkPipelineLayout 0x4256c1000000005d[] has not been destroyed. The Vulkan spec states: All child objects created on device must have been destroyed prior to destroying device (https://vulkan.lunarg.com/doc/view/1.3.280.1/linux/1.3-extensions/vkspec.html#VUID-vkDestroyDevice-device-05137)
&lt;/code&gt;
    &lt;p&gt;VMA also triggers asserts if you forget to free some buffer/image allocated with it.&lt;/p&gt;
    &lt;p&gt;I find it convenient to have all the Vulkan cleanup happening explicitly in one place. It makes it easy to track when the objects get destroyed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Synchronization&lt;/head&gt;
    &lt;p&gt;Synchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won‚Äôt get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated.&lt;/p&gt;
    &lt;p&gt;Right now I manage most of the complexities of sync manually in one place. I separate my drawing into ‚Äúpasses‚Äù/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this:&lt;/p&gt;
    &lt;code&gt;// do skinning in compute shader
for (const auto&amp;amp; mesh : skinnedMeshes) {
    skinningPass.doSkinning(gfxDevice, mesh);
}

{
    // Sync skinning with CSM
    // This is a "fat" barrier and you can potentially optimize it
    // by specifying all the buffers that the next pass will read from
    const auto memoryBarrier = VkMemoryBarrier2{
        .sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2,
        .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
        .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT,
        .dstStageMask = VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT,
        .dstAccessMask = VK_ACCESS_2_MEMORY_READ_BIT,
    };
    const auto dependencyInfo = VkDependencyInfo{
        .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
        .memoryBarrierCount = 1,
        .pMemoryBarriers = &amp;amp;memoryBarrier,
    };
    vkCmdPipelineBarrier2(cmd, &amp;amp;dependencyInfo);
}

// do shadow mapping
shadowMappingPass.draw(gfxDevice, ...);
&lt;/code&gt;
    &lt;p&gt;Of course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I‚Äôm okay with doing manual sync. vkconfig‚Äôs ‚Äúsynchronization‚Äù validation layer also helps greatly in finding sync errors.&lt;/p&gt;
    &lt;p&gt;The following resources were useful for understanding synchronization:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More implementation notes&lt;/head&gt;
    &lt;head rend="h3"&gt;Drawing many sprites&lt;/head&gt;
    &lt;p&gt;With bindless textures, it‚Äôs easy to draw many sprites using one draw call without having to allocate vertex buffers at all.&lt;/p&gt;
    &lt;p&gt;First of all, you can emit vertex coordinates and UVs using &lt;code&gt;gl_VertexIndex&lt;/code&gt; in your vertex shader like this:&lt;/p&gt;
    &lt;code&gt;void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This snippet produces this set of values:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;gl_VertexIndex&lt;/cell&gt;
        &lt;cell role="head"&gt;baseCoord&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;(0,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;(1,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All the sprite draw calls are combined into &lt;code&gt;SpriteDrawBuffer&lt;/code&gt; which looks like this in GLSL:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    mat4 transform; // could potentially be mat2x2...
    vec2 uv0; // top-left uv coord
    vec2 uv1; // bottom-right uv coord
    vec4 color; // color by which texture is multiplied
    uint textureID; // sprite texture
    uint shaderID; // explained below
    vec2 padding; // padding to satisfy "scalar" requirements
};

layout (buffer_reference, scalar) readonly buffer SpriteDrawBuffer {
    SpriteDrawCommand commands[];
};
&lt;/code&gt;
    &lt;p&gt;On CPU/C++ side, it looks almost the same:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    glm::mat4 transform;
    glm::vec2 uv0; // top-left uv coordinate
    glm::vec2 uv1; // bottom-right uv coodinate
    LinearColor color; // color by which texture is multiplied by
    std::uint32_t textureId; // sprite texture
    std::uint32_t shaderId; // explained below
    glm::vec2 padding; // padding
};

std::vector&amp;lt;SpriteDrawCommand&amp;gt; spriteDrawCommands;
&lt;/code&gt;
    &lt;p&gt;I create two fixed size buffers on the GPU and then upload the contents of &lt;code&gt;spriteDrawCommands&lt;/code&gt; (using techniques described above in the ‚ÄúHandling dynamic data‚Äù section).&lt;/p&gt;
    &lt;p&gt;The sprite renderer is used like this:&lt;/p&gt;
    &lt;code&gt;// record commands
renderer.beginDrawing();
{
    renderer.drawSprite(sprite, pos);
    renderer.drawText(font, "Hello");
    renderer.drawRect(...);
}
renderer.endDrawing();

// do actual drawing later:
renderer.draw(cmd, gfxDevice, ...);
&lt;/code&gt;
    &lt;code&gt;
  The same renderer also draws text, rectangles and lines in my engine. For example, the text is just N ‚Äúdraw sprite‚Äù commands for a string composed of N glyphs. Solid color rectangles and lines are achieved by using a 1x1 pixel white texture and multiplying it by  SpriteCommand::color in the fragment shader.
&lt;/code&gt;
    &lt;p&gt;And finally, here‚Äôs how the command to do the drawing looks like inside &lt;code&gt;SpriteRenderer::draw&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;vkCmdDraw(cmd, 6, spriteDrawCommands.size(), 0, 0);
// 6 vertices per instance, spriteDrawCommands.size() instances in total
&lt;/code&gt;
    &lt;p&gt;The complete sprite.vert looks like this:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "sprite_commands.glsl"

layout (push_constant) uniform constants
{
    mat4 viewProj; // 2D camera matrix
    SpriteDrawBuffer drawBuffer; // where sprite draw commands are stored
} pcs;

layout (location = 0) out vec2 outUV;
layout (location = 1) out vec4 outColor;
layout (location = 2) flat out uint textureID;
layout (location = 3) flat out uint shaderID;

void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);

    SpriteDrawCommand command = pcs.drawBuffer.commands[gl_InstanceIndex];

    gl_Position = pcs.viewProj * command.transform * vec4(baseCoord, 0.f, 1.f);
    outUV = (1.f - baseCoord) * command.uv0 + baseCoord * command.uv1;
    outColor = command.color;
    textureID = command.textureID;
    shaderID = command.shaderID;
}
&lt;/code&gt;
    &lt;p&gt;All the parameters of the sprite draw command are self-explanatory, but &lt;code&gt;shaderID&lt;/code&gt; needs a bit of clarification. Currently, I use it to branch inside the fragment shader:&lt;/p&gt;
    &lt;code&gt;...

#define SPRITE_SHADER_ID 0
#define TEXT_SHADER_ID   1

void main()
{
    vec4 texColor = sampleTexture2DNearest(textureID, inUV);

    // text drawing is performed differently...
    if (shaderID == TEXT_SHADER_ID) {
        // glyph atlas uses single-channel texture
        texColor = vec4(1.0, 1.0, 1.0, texColor.r);
    }

    if (texColor.a &amp;lt; 0.1) {
        discard;
    }

    outColor = inColor * texColor;
}
&lt;/code&gt;
    &lt;p&gt;This allows me to draw sprites differently depending on this ID without having to change pipelines. Of course, it can be potentially bad for the performance. This can be improved by drawing sprites with the same shader ID in batches. You‚Äôll only need to switch pipelines when you encounter a draw command with a different shader ID.&lt;/p&gt;
    &lt;p&gt;The sprite renderer is very efficient: it can draw 10 thousand sprites in just 315 microseconds.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compute skinning&lt;/head&gt;
    &lt;p&gt;I do skinning for skeletal animation in a compute shader. This allows me to have the same vertex format for all the meshes.&lt;/p&gt;
    &lt;p&gt;Basically, I just take the mesh‚Äôs vertices (not skinned) and joint matrices and produce a new buffer of vertices which are used in later rendering stages.&lt;/p&gt;
    &lt;p&gt;Suppose you spawn three cats with identical meshes:&lt;/p&gt;
    &lt;p&gt;All three of them can have different animations. They all have an identical ‚Äúinput‚Äù mesh. But the ‚Äúoutput‚Äù vertex buffer will differ between them, which means that you need to pre-allocate a vertex buffer for each instance of the mesh.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how the skinning compute shader looks like:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "vertex.glsl"

struct SkinningDataType {
    ivec4 jointIds;
    vec4 weights;
};

layout (buffer_reference, std430) readonly buffer SkinningData {
    SkinningDataType data[];
};

layout (buffer_reference, std430) readonly buffer JointMatrices {
    mat4 matrices[];
};

layout (push_constant) uniform constants
{
    JointMatrices jointMatrices;
    uint jointMatricesStartIndex;
    uint numVertices;
    VertexBuffer inputBuffer;
    SkinningData skinningData;
    VertexBuffer outputBuffer;
} pcs;

layout (local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

mat4 getJointMatrix(int jointId) {
    return pcs.jointMatrices.matrices[pcs.jointMatricesStartIndex + jointId];
}

void main()
{
    uint index = gl_GlobalInvocationID.x;
    if (index &amp;gt;= pcs.numVertices) {
        return;
    }

    SkinningDataType sd = pcs.skinningData.data[index];
    mat4 skinMatrix =
        sd.weights.x * getJointMatrix(sd.jointIds.x) +
        sd.weights.y * getJointMatrix(sd.jointIds.y) +
        sd.weights.z * getJointMatrix(sd.jointIds.z) +
        sd.weights.w * getJointMatrix(sd.jointIds.w);

    Vertex v = pcs.inputBuffer.vertices[index];
    v.position = vec3(skinMatrix * vec4(v.position, 1.0));

    pcs.outputBuffer.vertices[index] = v;
}
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Skinning data is not stored inside each mesh vertex, a separate buffer of &lt;code&gt;num_vertices&lt;/code&gt;elements is used.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that.&lt;/p&gt;
    &lt;quote&gt;Anton‚Äôs OpenGL 4 Tutorials book has the best skinning implementation guide I‚Äôve ever read. Game Engine Architecture by Jason Gregory has nice explanations about skinning/skeletal animation math as well.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Game / renderer separation&lt;/head&gt;
    &lt;p&gt;I have a game/renderer separation which uses a simple concept of ‚Äúdraw commands‚Äù. In the game logic, I use entt, but the renderer doesn‚Äôt know anything about entities or ‚Äúgame objects‚Äù. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw.&lt;/p&gt;
    &lt;p&gt;The renderer‚Äôs API looks like this in action:&lt;/p&gt;
    &lt;code&gt;void Game::generateDrawList()
{
    renderer.beginDrawing();

    // Add lights
    const auto lights = ...; // get list of all active lights
    for (const auto&amp;amp;&amp;amp; [e, tc, lc] : lights.each()) {
        renderer.addLight(lc.light, tc.transform);
    }

    // Render static meshes
    const auto staticMeshes = ...; // list of entities with static meshes
    for (const auto&amp;amp;&amp;amp; [e, tc, mc] : staticMeshes.each()) {
        // Each "mesh" can have multiple submeshes similar to how
        // glTF separates each "mesh" into "primitives".
        for (std::size_t i = 0; i &amp;lt; mc.meshes.size(); ++i) {
            renderer.drawMesh(mc.meshes[i], tc.worldTransform, mc.castShadow);
        }
    }

    // Render meshes with skeletal animation
    const auto skinnedMeshes = ...; // list of entities with skeletal animations
    for (const auto&amp;amp;&amp;amp; [e, tc, mc, sc] : skinnedMeshes.each()) {
        renderer.drawSkinnedMesh(
            mc.meshes, sc.skinnedMeshes, tc.worldTransform,
            sc.skeletonAnimator.getJointMatrices());
    }

    renderer.endDrawing();
}
&lt;/code&gt;
    &lt;p&gt;When you call &lt;code&gt;drawMesh&lt;/code&gt; or &lt;code&gt;drawSkinnedMesh&lt;/code&gt;, the renderer creates a mesh draw command and puts it in &lt;code&gt;std::vector&amp;lt;MeshDrawCommand&amp;gt;&lt;/code&gt; which are then iterated through during the drawing process. The &lt;code&gt;MeshDrawCommand&lt;/code&gt; looks like this:&lt;/p&gt;
    &lt;code&gt;
struct SkinnedMesh {
    GPUBuffer skinnedVertexBuffer;
};

struct MeshDrawCommand {
    MeshId meshId;
    glm::mat4 transformMatrix;
    math::Sphere worldBoundingSphere;

    const SkinnedMesh* skinnedMesh{nullptr};
    std::uint32_t jointMatricesStartIndex;
    bool castShadow{true};
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;meshId&lt;/code&gt;is used for looking up static meshes in&lt;code&gt;MeshCache&lt;/code&gt;- it‚Äôs a simple&lt;code&gt;std::vector&lt;/code&gt;of references to vertex buffers on GPU.&lt;/item&gt;
      &lt;item&gt;If the mesh has a skeleton, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;is used during compute skinning and&lt;code&gt;skinnedMesh-&amp;gt;skinnedVertexBuffer&lt;/code&gt;is used for all the rendering afterwards (instead of&lt;code&gt;meshId&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;worldBoundingSphere&lt;/code&gt;is used for frustum culling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scene loading and entity prefabs&lt;/head&gt;
    &lt;p&gt;I use Blender as a level editor and export it as glTF. It‚Äôs easy to place objects, colliders and lights there. Here‚Äôs how it looks like:&lt;/p&gt;
    &lt;p&gt;Writing your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time.&lt;/p&gt;
    &lt;p&gt;It‚Äôs important to mention how I use node names for spawning some objects. For example, you can see an object named &lt;code&gt;Interact.Sphere.Diary&lt;/code&gt; selected in the screenshot above. The part before the first dot is the prefab name (in this case ‚ÄúInteract‚Äù). The ‚ÄúSphere‚Äù part is used by the physics system to create a sphere physics body for the object (‚ÄúCapsule‚Äù and ‚ÄúBox‚Äù can also be used, otherwise the physics shape is created using mesh vertices).&lt;/p&gt;
    &lt;p&gt;Some models are pretty complex and I don‚Äôt want to place them directly into the level glTF file as it‚Äôll greatly increase each level‚Äôs size. I just place an ‚ÄúEmpty-&amp;gt;Arrows‚Äù object and name it something like ‚ÄúCat.NearStore‚Äù. This will spawn ‚ÄúCat‚Äù prefab and attach ‚ÄúNearStore‚Äù tag to it for runtime identification.&lt;/p&gt;
    &lt;p&gt;Prefabs are written in JSON and look like this:&lt;/p&gt;
    &lt;code&gt;{
  "scene": {
    "scene": "assets/models/cato.gltf"
  },
  "movement": {
    "maxSpeed": [4, 4, 4]
  },
  "physics": {
    "type": "dynamic",
    "bodyType": "virtual_character",
    "bodyParams": {
        ...
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;During the level loading process, if the node doesn‚Äôt have a corresponding prefab, it‚Äôs loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it‚Äôs created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file).&lt;/p&gt;
    &lt;quote&gt;Once glTFX is released and the support for it is added to Blender, things might be even easier to handle as you‚Äôll be able to reference external glTF files with it.&lt;/quote&gt;
    &lt;head rend="h3"&gt;MSAA&lt;/head&gt;
    &lt;p&gt;Using forward rendering allowed me to easily implement MSAA. Here‚Äôs a comparison of how the game looks without AA and with MSAA on:&lt;/p&gt;
    &lt;p&gt;MSAA is explained well here: https://vulkan-tutorial.com/Multisampling&lt;/p&gt;
    &lt;p&gt;Here‚Äôs another good article about MSAA: https://therealmjp.github.io/posts/msaa-overview/ and potential problems you can have with it (especially with HDR and tone-mapping).&lt;/p&gt;
    &lt;head rend="h3"&gt;UI&lt;/head&gt;
    &lt;p&gt;My UI system was inspired by Roblox‚Äôs UI API: https://create.roblox.com/docs/ui&lt;/p&gt;
    &lt;p&gt;Basically, the UI can calculate its own layout without me having to hard code each individual element‚Äôs size and position. Basically it relies on the following concepts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Origin is an anchor around which the UI element is positioned. If origin is &lt;code&gt;(0, 0)&lt;/code&gt;, setting UI element‚Äôs position to be&lt;code&gt;(x,y)&lt;/code&gt;will make its upper-left pixel have (x,y) pixel coordinate. If the origin is&lt;code&gt;(1, 1)&lt;/code&gt;, then the element‚Äôs bottom-right corner will be positioned at&lt;code&gt;(x, y)&lt;/code&gt;. If the origin is (0.5, 1) then it will be positioned using bottom-center point as the reference.&lt;/item&gt;
      &lt;item&gt;Relative size makes the children‚Äôs be proportional to parent‚Äôs size. If (1,1) then the child element will have the same size as the parent element. If it‚Äôs (0.5, 0.5) then it‚Äôll have half the size of the parent. If the parent uses children‚Äôs size as a guide, then if a child has (0.5, 0.25) relative size, the parent‚Äôs width will be 2x larger and the height will be 4x larger.&lt;/item&gt;
      &lt;item&gt;Relative position uses parent‚Äôs size as a guide for positioning. It‚Äôs useful for centering elements, for example if you have an element with (0.5, 0.5) origin and (0.5, 0.5) relative position, it‚Äôll be centered inside its parent element.&lt;/item&gt;
      &lt;item&gt;You can also set pixel offsets for both position and size separately (they‚Äôre called &lt;code&gt;offsetPosition&lt;/code&gt;and&lt;code&gt;offsetSize&lt;/code&gt;in my codebase).&lt;/item&gt;
      &lt;item&gt;You can also set a fixed size for the elements if you don‚Äôt want them to ever be resized.&lt;/item&gt;
      &lt;item&gt;The label/image element size is determined using its content.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some examples of how it can be used to position child elements:&lt;/p&gt;
    &lt;p&gt;a) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0.5) (alternatively, the relative position can be (0.5, 0.0) and origin at (0.5, 0.0) in this case). Its parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent.&lt;/p&gt;
    &lt;p&gt;b) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green)&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see how sizes and positions of UI elements are calculated (implementation in EDBR).&lt;/p&gt;
    &lt;p&gt;First, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc.&lt;/p&gt;
    &lt;p&gt;When calculating the size, most elements either have a ‚Äúfixed‚Äù size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text‚Äôs bounding box. For image elements, their size equals the image size and so on.&lt;/p&gt;
    &lt;p&gt;If an element has an ‚ÄúAuto-size‚Äù property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the ‚Äúvertical layout‚Äù element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent‚Äôs size is calculated.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs take a look at a simple menu with bounding boxes displayed:&lt;/p&gt;
    &lt;p&gt;Here, root &lt;code&gt;NineSliceElement&lt;/code&gt; is marked as ‚ÄúAuto-size‚Äù. To compute its size, it first computes the size of its child (&lt;code&gt;ListLayoutElement&lt;/code&gt;). This recursively computes the sizes of each button, sums them up and adds some padding (&lt;code&gt;ListLayoutElement&lt;/code&gt; also makes the width of each button the same based on the maximum width in the list).&lt;/p&gt;
    &lt;head rend="h3"&gt;Dear ImGui and sRGB issues&lt;/head&gt;
    &lt;p&gt;I love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better):&lt;/p&gt;
    &lt;p&gt;It has some problems with sRGB, though. I won‚Äôt explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison:&lt;/p&gt;
    &lt;p&gt;Sometimes you can see people doing hacks by doing &lt;code&gt;pow(col, vec4(2.2))&lt;/code&gt; with Dear ImGui‚Äôs colors but it still doesn‚Äôt work properly with alpha and produces incorrect color pickers.&lt;/p&gt;
    &lt;p&gt;I ended up writing my own Dear ImGui backend and implementing DilligentEngine‚Äôs workaround which is explained in detail here and here.&lt;/p&gt;
    &lt;quote&gt;Writing it wasn‚Äôt as hard as I expected. I only need to write the rendering part, while ‚Äúlogic/OS interaction‚Äù part (input event processing, clipboard etc.) is still handled by default Dear ImGui SDL backend in my case.&lt;/quote&gt;
    &lt;p&gt;There are some additional benefits of having my own backend:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It supports bindless texture ids, so I can draw images by simply calling &lt;code&gt;ImGui::Image(bindlessTextureId, ...)&lt;/code&gt;. Dear ImGui‚Äôs Vulkan backend requires you to ‚Äúregister‚Äù textures by calling&lt;code&gt;ImGui_ImplVulkan_AddTexture&lt;/code&gt;for each texture before you can call&lt;code&gt;ImGui::Image&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they‚Äôre displayed)&lt;/item&gt;
      &lt;item&gt;Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Other stuff&lt;/head&gt;
    &lt;p&gt;There are many parts of the engine not covered there because they‚Äôre not related to Vulkan. I still feel like it‚Äôs good to mention them briefly for the sake of completion.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Jolt Physics for physics.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement.&lt;/p&gt;
    &lt;p&gt;The samples are fantastic. The docs are very good too.&lt;/p&gt;
    &lt;p&gt;I especially want to point out how incredible &lt;code&gt;JPH::CharacterVirtual&lt;/code&gt; is. It handles basic character movement so well. I remember spending days trying to get proper slope movement in Bullet to work. With Jolt, it just worked ‚Äúout of the box‚Äù.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how it basically works (explaining how it works properly would probably require me to write quite a big article):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You add your shapes to Jolt‚Äôs world.&lt;/item&gt;
      &lt;item&gt;You run the simulation.&lt;/item&gt;
      &lt;item&gt;You get new positions of your physics objects and use these positions to render objects in their current positions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use entt for the entity-component-system part.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use openal-soft, libogg and libvorbis for audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The audio system is mostly based on these articles: https://indiegamedev.net/2020/02/15/the-complete-guide-to-openal-with-c-part-1-playing-a-sound/&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Tracy for profiling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it was very easy (read the PDF doc, it‚Äôs fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was ‚Äúinefficient‚Äù, really took.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I gained from switching to Vulkan&lt;/head&gt;
    &lt;p&gt;There are many nice things I got after switching to Vulkan:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No more global state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see ‚Äúshader.bind()‚Äù calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There‚Äôs no need for that in Vulkan - it‚Äôs easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API is more pleasant to work with overall - I didn‚Äôt like ‚Äúbinding‚Äù things and the whole ‚Äúglobal state machine‚Äù of OpenGL.&lt;/item&gt;
      &lt;item&gt;You need to write less abstractions overall.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, you need to write a lot of abstractions to make it all less error-prone‚Ä¶ Vulkan‚Äôs API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan‚Äôs ‚Äúraw‚Äù functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Better validation errors&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Validation errors are very good in Vulkan. While OpenGL has &lt;code&gt;glDebugMessageCallback&lt;/code&gt;, it doesn‚Äôt catch that many issues and you‚Äôre left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debugging in RenderDoc&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I can now debug shaders in RenderDoc. It looks like this:&lt;/p&gt;
    &lt;p&gt;With OpenGL I had to output the values to some texture and color-pick them‚Ä¶ which took a lot of time. But now I can debug vertex and fragment shaders easily.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More consistent experience across different GPUs and OSes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it‚Äôs much less prevalent compared to OpenGL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ability to use better shading languages in the future&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example:&lt;/p&gt;
    &lt;p&gt;I might explore them in the future and see if they offer me something that GLSL lacks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More control over every aspect of the graphics pipeline.&lt;/item&gt;
      &lt;item&gt;Second system effect, but good&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Street cred&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And finally, it makes me proud to be able to say ‚ÄúI have a custom engine written in Vulkan and it works‚Äù. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :)&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work&lt;/head&gt;
    &lt;p&gt;There are many things that I plan to do in the future, here‚Äôs a list of some of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sign-distance field font support (good article about implementing them)&lt;/item&gt;
      &lt;item&gt;Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them)&lt;/item&gt;
      &lt;item&gt;Bloom.&lt;/item&gt;
      &lt;item&gt;Volumetric fog.&lt;/item&gt;
      &lt;item&gt;Animation blending.&lt;/item&gt;
      &lt;item&gt;Render graphs.&lt;/item&gt;
      &lt;item&gt;Ambient occlusion.&lt;/item&gt;
      &lt;item&gt;Finishing the game? (hopefully‚Ä¶)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, I‚Äôm quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn‚Äôt as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46010329</guid><pubDate>Fri, 21 Nov 2025 23:28:40 +0000</pubDate></item><item><title>Sharper MRI scans may be on horizon thanks to new physics-based model</title><link>https://news.rice.edu/news/2025/sharper-mri-scans-may-be-horizon-thanks-new-physics-based-model</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46010806</guid><pubDate>Sat, 22 Nov 2025 00:30:26 +0000</pubDate></item><item><title>Moss Survives 9 Months in Space Vacuum</title><link>https://scienceclock.com/moss-survives-9-months-in-space-vacuum/</link><description>&lt;doc fingerprint="3f08d17b68b59460"&gt;
  &lt;main&gt;
    &lt;p&gt;Mosses are already known for coping with harsh radiation, dehydration, and long freezes. Now scientists have pushed them even further by exposing their spore capsules to open space for nine months, and most of them survived.&lt;/p&gt;
    &lt;p&gt;The team worked with spreading earthmoss (Physcomitrium patens), a small moss species used widely as a plant model by researchers. Its spore-containing capsules were mounted on the outside of the International Space Station (ISS), where they experienced direct solar radiation, vacuum conditions, and sharp temperature swings during each orbit.&lt;/p&gt;
    &lt;p&gt;Under those conditions, cells usually break down quickly. So the researchers were surprised by what came back. ‚ÄúWe expected almost zero survival, but the result was the opposite,‚Äù says Hokkaido University biologist Tomomichi Fujita. More than 80 percent of the spores still germinated once they returned to Earth.&lt;/p&gt;
    &lt;p&gt;Also Read: Microbe That Could Turn Martian Dust into Oxygen&lt;/p&gt;
    &lt;p&gt;The team detected a small drop in chlorophyll a, but the other pigments remained stable. The spores grew normally in follow-up tests, showing no signs of major stress from their time in orbit.&lt;/p&gt;
    &lt;p&gt;This kind of toughness fits with the evolutionary history of mosses. Bryophytes ‚Äî the group that includes mosses, liverworts, and hornworts ‚Äî were among the first plants to move from water onto land about 500 million years ago. Their spores had to withstand drying and direct sunlight long before soils existed, which may explain why their protective structures still hold up so well today.&lt;/p&gt;
    &lt;p&gt;The results place moss spores alongside the few organisms known to tolerate direct space exposure, including tardigrades and certain microbes. Their survival also adds to ongoing discussions about what types of life might endure extreme environments beyond Earth.&lt;/p&gt;
    &lt;p&gt;According to the researchers, this durability could matter for future experiments on the Moon or Mars. Mosses need very little soil and can pull nutrients directly from rock, making them candidates for early ecosystem tests in extraterrestrial settings.&lt;/p&gt;
    &lt;p&gt;‚ÄúUltimately, we hope this work opens a new frontier toward constructing ecosystems in extraterrestrial environments such as the Moon and Mars,‚Äù says Fujita. ‚ÄúI hope that our moss research will serve as a starting point.‚Äù&lt;/p&gt;
    &lt;p&gt;The research was published in iScience. Read the study here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46011978</guid><pubDate>Sat, 22 Nov 2025 03:57:29 +0000</pubDate></item><item><title>Superman copy found in mum's attic is most valuable comic ever at $9.12M</title><link>https://www.bbc.com/news/articles/c8e9rp0knj6o</link><description>&lt;doc fingerprint="b72b5181609a05bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Superman copy found in mum's attic is most valuable comic ever at $9.12m&lt;/head&gt;
    &lt;p&gt;While cleaning out their late mother's California loft last Christmas, three brothers made a life-changing discovery under a pile of faded newspapers: one of the first Superman comics ever made.&lt;/p&gt;
    &lt;p&gt;An original copy of the June 1939 first edition on the Man of Steel's adventures, it was in a remarkably pristine condition.&lt;/p&gt;
    &lt;p&gt;Now it has become the highest-priced comic book ever sold, fetching $9.12m (¬£7m) at auction.&lt;/p&gt;
    &lt;p&gt;Texas-based Heritage Auctions, which hosted Thursday's sale, called it the "pinnacle of comic collecting".&lt;/p&gt;
    &lt;p&gt;The brothers found six comic books, including Superman #1, in the loft underneath a stack of newspapers inside a cardboard box and surrounded by cobwebs in 2024, Heritage said.&lt;/p&gt;
    &lt;p&gt;They waited a few months before contacting the auction house, but once they did, Heritage Auctions vice-president Lon Allen visited them in San Francisco within days, according to the auction house.&lt;/p&gt;
    &lt;p&gt;The brothers, who have chosen to withhold their names, are "in their 50s and 60s, and their mom had always told them she had an expensive comics collection but never showed them", Mr Allen said.&lt;/p&gt;
    &lt;p&gt;"It's a twist on the old 'Mom threw away my comics' story."&lt;/p&gt;
    &lt;p&gt;Their mother had held onto the comic books since she and her brother bought them between the Great Depression and the beginning of World War Two, Heritage said.&lt;/p&gt;
    &lt;p&gt;Mr Allen added that the cool northern California climate was perfect for preserving old paper.&lt;/p&gt;
    &lt;p&gt;"If it had been in an attic here in Texas, it would have been ruined," he said.&lt;/p&gt;
    &lt;p&gt;That helped CGC, a large third-party comics grading service, give this copy of Superman #1 a 9.0 rating on a 10-point scale, topping the previous record of 8.5.&lt;/p&gt;
    &lt;p&gt;And at its sale price of over $9m, including buyer's premium, Superman #1 easily beat the previous highest-priced comic book ever sold by $3m.&lt;/p&gt;
    &lt;p&gt;Action Comics No. 1, the 1938 work that first introduced Superman, sold for $6m last year.&lt;/p&gt;
    &lt;p&gt;The youngest brother said in a press release by the auction house that the box had remained forgotten in the back of attic.&lt;/p&gt;
    &lt;p&gt;"As the years unfolded, life brought about a series of losses and changes," he said. "The demands of everyday survival took centre stage, and the box of comics, once set aside with care and intention, was forgotten. Until last Christmas."&lt;/p&gt;
    &lt;p&gt;He added: "This isn't simply a story about old paper and ink. This was never just about a collectible.&lt;/p&gt;
    &lt;p&gt;"This is a testament to memory, family and the unexpected ways the past finds its way back to us."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46012328</guid><pubDate>Sat, 22 Nov 2025 05:21:53 +0000</pubDate></item><item><title>Roblox CEO Makes a Fool of Himself in Car-Crash Interview</title><link>https://kotaku.com/roblox-new-york-times-interview-baszucki-2000646174</link><description>&lt;doc fingerprint="ae031b5b09b2c7fc"&gt;
  &lt;main&gt;
    &lt;p&gt;As ‚Äúpedophile hellscape‚Äù√Ç Roblox finally adds a rudimentary measure to try to prevent children from being exploited via its network of games and chatrooms used by 151 million people, the company‚Äôs CEO spoke to the√Ç New York Times podcast Hard Fork about child safety. And it didn‚Äôt go great. It√Ç really didn‚Äôt go great.&lt;/p&gt;
    &lt;p&gt;Roblox is coming under increasing scrutiny after decades of failing to implement even the most basic of protective measures to keep its pre-teen players away from the networks of pedophiles who use the game to find victims. Described last year as ‚Äúa pedophile hellscape for kids‚Äù by Hindenburg Research, the game quickly introduced a new assortment of measures√Ç last October that did next to nothing, leading this year to a great deal of legal interest. Three months back, the state of Louisiana announced its intentions to sue√Ç Roblox for the dangers it was allowing, joined since by Kentucky and Texas. These actions come alongside 35 other ongoing lawsuits, including one from only yesterday by a family in Cuyaho County following Roblox‚Äòs alleged use in the tragic and too common abuse of their 13-year-old son.&lt;/p&gt;
    &lt;p&gt;On Wednesday of this week, Roblox announced it was beginning to roll out a new method of checking player ages before they could access chat, this time using facial recognition to try to restrict players to only talking to others in their age range. Such facial ID checks have become commonplace in the UK following the disastrously poor UK Online Safety Act, by which porn sites and other age-restricted outlets are required to verify users‚Äô ages. This has led to sites like X, Bluesky and Discord also requiring British users to prove their age, usually by showing their face on camera in a measure that entirely thwarts all seven people who haven‚Äôt heard of a VPN.&lt;/p&gt;
    &lt;p&gt;Regarding this rollout, the√Ç New York Times‚Äò Casey Newton spoke to√Ç Roblox co-founder and CEO David Baszucki about the new plans, and whether they can really help. It doesn‚Äôt begin well. When asked about the ‚Äúscope of the problem‚Äù of predators in the application, Baszucki came in shoulders first saying, ‚ÄúWe think of it not necessarily just as a problem, but an opportunity as well.‚Äù Ah, the good ol‚Äô opportunities available when your company‚Äôs product is rife with pedophilia. He continued, outlining how wonderful it is that young people can build and communicate together, how they have ‚Äú150 million daily actives, 11 billion hours a month, like what is the best way to keep pushing this forward.‚Äù It is the most astonishingly tone-deaf response.&lt;/p&gt;
    &lt;p&gt;Newton attempts to get some sensible answers from Baszucki about how the ID checks will work, and why they won‚Äôt be as easily evaded as so many others, and amidst Baszucki‚Äôs corporate waffle he‚Äôs told that Roblox is apparently always looking out for ‚Äúweird signals‚Äù and will ask for further age verification should these appear, although he didn‚Äôt explain what those signals might be, nor what these further checks would be. But then Newton goes on to ask the painfully necessary question: why has it taken 19 years to even try to stop adults from being able to speak to children?&lt;/p&gt;
    &lt;p&gt;Baszucki responds by talking about the evolution of Roblox‚Äòs text filtering tech for inappropriate language and personally identifying information over the last two decades, and how it‚Äôs always improving, which is great but clearly not relevant to the question. Newton is having none of it, responding, ‚ÄúYeah, I mean, I don√¢t know. When I read these lawsuits and these investigations into the company, it does not seem like predators are having that hard of a time getting around your filters‚Ä¶So I√¢m curious what√¢s made you so confident that things are working?‚Äù Baszucki‚Äôs response is incoherent.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúI don√¢t want to comment on it. We do see the chat logs of those. And we can see interesting and, many times, ways of people trying to√¢I√¢d say, many times people who are fairly sophisticated, and I√¢m not going to say all of them, many times kids who are over 13, who actually in any other app are not running in a filtered situation, unfortunately, figuring out how to jump to some other platform where they can communicate unfiltered, where they can share images, all of it. It√¢s one of the primary things we√¢re doing is trying to keep people on our platform. It√¢s an interesting industry situation. I would say, we√¢re not waiting for the rest of the industry. We√¢re like, we√¢re always trying to stay ahead of it. On the California age-appropriate design code, for example, we√¢re like, we are already doing all of that stuff. And the same thing with age estimation: We√¢re not doing this because of any laws that are coming, we think it√¢s the right thing to do.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Newton very impressively keeps his cool, and rather than pointing out that this answer had nothing to do with the situation, nor indeed how unbelievable it is that the CEO of the company would say ‚ÄúI don‚Äôt want to comment on it‚Äù when asked why he‚Äôs confident in age tech that clearly doesn‚Äôt work, he instead points out that the lawsuits are demonstrating that ‚ÄúRoblox is kind of, you know, where predators go to find kids.‚Äù&lt;/p&gt;
    &lt;p&gt;Things become increasingly tense, as Baszucki tries to claim this is a misrepresentation, and when pressed on whether he truly doesn‚Äôt believe√Ç Roblox has a predator problem replies, ‚ÄúI think we‚Äôre doing an incredible job at innovating relative to the number of people on our platform and the hours, in really leaning in to the future of how this is going to work.‚Äù&lt;/p&gt;
    &lt;p&gt;What becomes so grimly apparent is that even now, even after a year of extraordinary scrutiny and legal pressure, Baszucki still doesn‚Äôt have a grip on the situation at all. To be so ill-prepared for such obvious questions, to have no coherent responses for why the new tech will be effective, and to go so out of his way to appear so uninterested in the subject, is astonishing. As he‚Äôs pressed further on the ease with which predators can suggest children speak to them on another platform, Baszucki eventually unravels into literal gibberish:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúI would actually say that is a very simple red flag. Like, that sounds like text filter many prior generations. So I would say the techniques are much more sophisticated than that. We√¢re constantly getting better than that and sometimes it√¢s adversarial. Like, we√¢re getting into, you know, if we cryptographically were going to try to have an exchange of how to share your Snap handle or whatever handle. We see some of that starting, like things we√¢ll have to essentially prevent in the future.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The CEO seems to believe that the scale of√Ç Roblox is somehow an excuse to justify its problems, repeatedly coming back to its 150 million users and 11 billion hours a month, as if this explains it all away. But more problematically, as Newton points out that the company wants those numbers to grow, Baszucki immediately switches back to talking about what an amazing financial opportunity this is. Given√Ç Roblox√Ç is really struggling to turn those users into money, it reads like he‚Äôs only speaking to investors and analysts who are increasingly concerned about√Ç Roblox‚Äòs lack of profits. So many responses begin with an infuriatingly irrelevant attempt to avoid the question, and then end with words like ‚ÄúAnd you could imagine√Ç Roblox at 20-X this scale, having 50 percent of the gaming market space all in a single place.‚Äù It‚Äôs so crass!&lt;/p&gt;
    &lt;p&gt;But not nearly as crass as Baszucki‚Äôs response to a question over the Hindenburg Research report into the scale of the issue with pedophiles. Hindenburg was an activist short-selling research firm that would investigate companies for fraud, malfeasance and indeed rampant use by predators, until its creator chose to disband the group in January this year. At the time of the report, Baszucki said that it was wrong to claim that√Ç Roblox had reduced its spend on trust and safety, so Newton asked for specifics.&lt;/p&gt;
    &lt;p&gt;‚ÄúFun,‚Äù says Baszucki, a man who appears pathologically incapable of reading the room. ‚ÄúLet‚Äôs keep going down this. And so, first off, Hindenburg is not longer in existence, correct? So, you should report on that. They went out of business for some reason‚Ä¶‚Äù He then demanded to know if Newton had researched the answer for himself, before saying that it‚Äôs because they‚Äôve moved so much of the safety regulation onto AI, all while sounding absolutely furious that he was being asked. He then demands that Newton agree that if AI is more effective, it‚Äôs better to use it, and when Newton does, Baszucki starts to behave incredibly immaturely. ‚ÄúGood, so you‚Äôre aligning with what we did. High-five.‚Äù Then when Newton tries to ask a question, he interrupts to say, ‚ÄúThank you for supporting our Roblox decision matrix.‚Äù√Ç Then interrupts yet again to say, ‚ÄúI‚Äôm so glad you guys are aligned with the way we run√Ç Roblox. High-five.‚Äù Think he‚Äôs done? Nope. Yet again he interrupts the question with, ‚ÄúIs this a stealth interview where actually you love everything we‚Äôre doing and you‚Äôre here to stealthily support it?‚Äù&lt;/p&gt;
    &lt;p&gt;And he doesn‚Äôt stop. When co-host Kevin Roose tried to get things back on the rails, Baszucki kept going with the same pathetic line. Challenged on how AI has proved very ineffective for social media companies, he just carries on saying it. The only thing that stopped this tantrum was allowing the CEO to talk about Polymarket, a cryptoscam-based prediction market, letting people place bets on things as ridiculous as awards ceremonies and future weather patterns. Some believe it‚Äôs becoming a useful way to predict markets, and that group includes Baszucki who is‚Ä¶and I cannot believe I‚Äôm typing this‚Ä¶looking to put it into Roblox so children can gamble.&lt;/p&gt;
    &lt;p&gt;He wants to find a way to do this that‚Äôs ‚Äúlegal‚Äù and ‚Äúeducational,‚Äù at which point the podcast hosts begin openly mocking the stupidity. And then, thank god, they run out of time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46013477</guid><pubDate>Sat, 22 Nov 2025 09:41:29 +0000</pubDate></item><item><title>Jack Ma's family shifted wealth to UK after years-long 'disappearance'</title><link>https://www.source-material.org/jack-ma-bought-uk-home-after-years-long-disappearance/</link><description>&lt;doc fingerprint="2b9055afb58216e1"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Billionaire‚Äôs wife bought London mansion as he reconciled with Chinese authorities&lt;/head&gt;
    &lt;p&gt;The family of Chinese billionaire Jack Ma bought a ¬£19.5 million London mansion amid a rapprochement with Chinese authorities after years of scrutiny and political exile.&lt;/p&gt;
    &lt;p&gt;Ma‚Äôs wife, Cathy Ying Zhang, acquired the six-bedroom Edwardian house, formerly the Italian embassy, in London‚Äôs elite Belgravia district in October 2024, property records show.&lt;/p&gt;
    &lt;p&gt;The purchase came after Ma‚Äôs return to public life after disappearing from view in the aftermath of a speech criticising China‚Äôs financial system. It could be seen as a ‚Äúprecautionary diversification‚Äù in case Ma again provokes Beijing‚Äôs ire, said Sari Arho Havr√©n, a China specialist at the Royal United Services Institute.&lt;/p&gt;
    &lt;p&gt;‚ÄúWealthy families are hedging against regime risk‚Äîone never knows when policies may turn hostile again,‚Äù she said. ‚ÄúAffluent families are diversifying quietly. Rule of law societies still hold considerable appeal.‚Äù&lt;/p&gt;
    &lt;p&gt;Ma, 61, is the founder of Alibaba Group, whose online commerce platforms have earned him a fortune of around $30 billion. The Belgravia house, the Ma family‚Äôs first known property holding in the UK, may have been funded by the sale of Alibaba shares in 2023, Havr√©n said.&lt;/p&gt;
    &lt;p&gt;Ma‚Äôs wife Zhang, who has taken Singaporean citizenship, is reportedly the sole director of an offshore company that Ma used to buy a ch√¢teau and vineyards in France.&lt;/p&gt;
    &lt;p&gt;Last year it was reported that Zhang spent up to $38 million on three commercial properties in Singapore. The buying spree is part of a trend that has seen prominent Chinese businesspeople move money abroad for fear of asset freezes or capital controls.&lt;/p&gt;
    &lt;p&gt;Many have left China altogether. As many as 13,800 ‚Äúhigh-net-worth individuals‚Äù emigrated in 2024‚Äîa 28 percent rise from 2022, according to investment migration consultants Henley &amp;amp; Partners.&lt;/p&gt;
    &lt;p&gt;The sale of the Belgravia mansion, managed by Knight Frank and Beauchamp Estates and handled by law firm Withers LLP, was rushed through ahead of a rise in the UK‚Äôs stamp duty surcharge for overseas buyers, according to a November 2024 report that did not name the buyer.&lt;/p&gt;
    &lt;p&gt;Beauchamp and Knight Frank declined to comment. Zhang and Ma Withers did not respond to questions put to them via Withers.&lt;/p&gt;
    &lt;p&gt;In 2015, it was reported that Ma family purchased ‚ÄòAsia‚Äôs most expensive home‚Äô in Hong Kong‚Äôs Victoria Peak which was formerly owned by the Belgian government. In the same year, it was reported that Ma had bought a 28,000 acre property in upstate New York for $23 million.&lt;/p&gt;
    &lt;p&gt;Ma vanished from public view in late 2020 after he criticised China‚Äôs financial regulators. Beijing reportedly punished him with a fine of nearly $3 billion and halted a stock market listing by Ant Group, an offshoot of Alibaba.&lt;/p&gt;
    &lt;p&gt;He resurfaced in China in 2023 after an apparent reconciliation with the administration of President Xi Jinping, occasionally attending public events. In February 2025, he was seen shaking Xi‚Äôs hand at event with Chinese industry leaders. However, Ma‚Äôs public remarks went unreported by official state media, prompting analysts to suggest that he had not been ‚Äúcompletely rehabilitated‚Äù.&lt;/p&gt;
    &lt;p&gt;In April, The Guardian reported that Chinese authorities enlisted Ma as part of a campaign to pressure a dissident businessman to return to China from France to help prosecute an official who had angered the regime.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey said I‚Äôm the only one who can persuade you to return,‚Äù Ma reportedly told the unnamed businessman in a telephone call. The Chinese government called the allegations ‚Äúpure fabrication‚Äù.&lt;/p&gt;
    &lt;p&gt;Headline picture: Beauchamp Estates&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46013633</guid><pubDate>Sat, 22 Nov 2025 10:19:27 +0000</pubDate></item></channel></rss>