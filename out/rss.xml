<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 29 Nov 2025 14:37:44 +0000</lastBuildDate><item><title>True P2P Email on Top of Yggdrasil Network</title><link>https://github.com/JB-SelfCompany/Tyr</link><description>&lt;doc fingerprint="bf9ce940ed102acf"&gt;
  &lt;main&gt;
    &lt;p&gt;We're taught that email must go through servers. Why? Because the Internet was built around centralized infrastructure. Every email you send travels through multiple servers - your provider's server, maybe a few relay servers, and finally your recipient's provider's server. Each hop is a potential point of surveillance, censorship, or failure.&lt;/p&gt;
    &lt;p&gt;Even "encrypted" email solutions still rely on these centralized servers. They encrypt the message content but the metadata - who you're talking to, when, how often - is visible to anyone watching the servers.&lt;/p&gt;
    &lt;p&gt;But there is a network, called Yggdrasil, that gives everyone a free IPv6 and doesn't need a blessing from your ISP. We finally have this possibility to use true P2P email. And moreover, this network has strong encryption to protect all data that flows from one IP to another.&lt;/p&gt;
    &lt;p&gt;Tyr brings true peer-to-peer email to your Android device using these unusual conditions. Unlike traditional email clients, Tyr doesn't need:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ùå Centralized mail servers (the connections are straight P2P)&lt;/item&gt;
      &lt;item&gt;‚ùå Message encryption layers (the network takes care of that)&lt;/item&gt;
      &lt;item&gt;‚ùå Port forwarding or STUN/TURN servers (Yggdrasil handles NAT traversal)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üîó Full DeltaChat/ArcaneChat Integration&lt;/cell&gt;
        &lt;cell&gt;Seamless setup with the best decentralized messengers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üìß Local SMTP/IMAP Server&lt;/cell&gt;
        &lt;cell&gt;Complete mail server running directly on your device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üîê Cryptographic Identity&lt;/cell&gt;
        &lt;cell&gt;Automatic Ed25519 key generation - your mail identity cannot be spoofed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üåç Yggdrasil Network&lt;/cell&gt;
        &lt;cell&gt;Connect via configurable peers - censorship-resistant by design&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üöÄ Auto-Start on Boot&lt;/cell&gt;
        &lt;cell&gt;Always-on availability for incoming messages&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üíæ Encrypted Backup &amp;amp; Restore&lt;/cell&gt;
        &lt;cell&gt;Password-protected configuration with optional key export&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;üîã Battery Optimized&lt;/cell&gt;
        &lt;cell&gt;Sophisticated power management with timed wake locks&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;graph LR
    A[DeltaChat/ArcaneChat] --&amp;gt;|SMTP/IMAP| B[Tyr Service]
    B --&amp;gt;|Yggmail Protocol| C[Yggdrasil Network]
    C --&amp;gt;|P2P Encrypted| D[Recipient's Tyr]
    D --&amp;gt;|SMTP/IMAP| E[Recipient's Chat App]
&lt;/code&gt;
    &lt;p&gt;Tyr runs a complete email server right on your Android device, using the Yggdrasil network for transport. The Yggmail mail server (built in Go) is embedded as a library inside the app and runs as a foreground service.&lt;/p&gt;
    &lt;p&gt;On top of Yggdrasil, it provides standard SMTP and IMAP protocols on localhost (&lt;code&gt;127.0.0.1:1025&lt;/code&gt; and &lt;code&gt;127.0.0.1:1143&lt;/code&gt;). Any email client can connect to these ports - but we recommend DeltaChat or ArcaneChat for the best P2P messaging experience.&lt;/p&gt;
    &lt;p&gt;Every Tyr installation generates unique Ed25519 cryptographic keys. Your mail address is derived from your public key:&lt;/p&gt;
    &lt;code&gt;&amp;lt;64-hex-characters&amp;gt;@yggmail
&lt;/code&gt;
    &lt;p&gt;This means your identity is cryptographically verifiable and cannot be spoofed.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Tyr and complete the onboarding (set password, configure peers)&lt;/item&gt;
      &lt;item&gt;Start the Yggmail service in Tyr&lt;/item&gt;
      &lt;item&gt;Install DeltaChat or ArcaneChat&lt;/item&gt;
      &lt;item&gt;In Tyr's main screen, tap "Setup DeltaChat/ArcaneChat"&lt;/item&gt;
      &lt;item&gt;Tyr will automatically open your chat app with pre-configured settings&lt;/item&gt;
      &lt;item&gt;Complete the setup and start chatting!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If automatic setup doesn't work:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Complete Tyr onboarding and start the service&lt;/item&gt;
      &lt;item&gt;Copy your mail address from Tyr's main screen (looks like &lt;code&gt;abc123...@yggmail&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;In DeltaChat/ArcaneChat, create a new profile&lt;/item&gt;
      &lt;item&gt;Tap "Use a different server"&lt;/item&gt;
      &lt;item&gt;Enter your Yggmail address and the password you set in Tyr&lt;/item&gt;
      &lt;item&gt;Tap "‚úì" to complete setup&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Important: Tyr must be running for your chat app to send and receive messages. Enable auto-start in Tyr settings for seamless experience.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Password Encryption: Android Keystore System with AES-256-GCM&lt;/item&gt;
      &lt;item&gt;Automatic Keystore Recovery: Handles Android Keystore issues on Samsung and other devices&lt;/item&gt;
      &lt;item&gt;Network Encryption: All P2P communications encrypted by Yggdrasil Network&lt;/item&gt;
      &lt;item&gt;Local-Only Access: SMTP/IMAP ports bound to localhost only&lt;/item&gt;
      &lt;item&gt;Cryptographic Identity: Ed25519 keys ensure your mail address cannot be spoofed&lt;/item&gt;
      &lt;item&gt;Encrypted Backups: Configuration and keys backed up with password protection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Android Studio (latest version)&lt;/item&gt;
      &lt;item&gt;JDK 17&lt;/item&gt;
      &lt;item&gt;Android SDK (API 23-36)&lt;/item&gt;
      &lt;item&gt;Go 1.21+ and gomobile (only if rebuilding yggmail.aar)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/JB-SelfCompany/Tyr.git
cd Tyr

# Build debug APK
./gradlew assembleDebug

# Install to connected device
./gradlew installDebug&lt;/code&gt;
    &lt;p&gt;APKs will be in &lt;code&gt;app/build/outputs/apk/debug/&lt;/code&gt; or &lt;code&gt;app/build/outputs/apk/release/&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;cd ../yggmail/mobile

# Windows
..\build-android.bat

# Unix
gomobile bind -target=android -androidapi 23 -javapkg=com.jbselfcompany.tyr -ldflags="-checklinkname=0" -o yggmail.aar .&lt;/code&gt;
    &lt;p&gt;Then copy &lt;code&gt;yggmail.aar&lt;/code&gt; to &lt;code&gt;Tyr/app/libs/&lt;/code&gt;&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Kotlin 2.2.20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Min SDK&lt;/cell&gt;
        &lt;cell&gt;23 (Android 6.0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Target SDK&lt;/cell&gt;
        &lt;cell&gt;33 (Android 13)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Compile SDK&lt;/cell&gt;
        &lt;cell&gt;36&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;Layered (UI ‚Üí Service ‚Üí Data)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Mail Server&lt;/cell&gt;
        &lt;cell&gt;Yggmail (Go library via gomobile)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Network&lt;/cell&gt;
        &lt;cell&gt;Yggdrasil overlay mesh network&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Localization&lt;/cell&gt;
        &lt;cell&gt;English, Russian&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Native Library&lt;/cell&gt;
        &lt;cell&gt;yggmail.aar (located in &lt;code&gt;app/libs/&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yggmail: The mail transfer agent that powers Tyr&lt;/item&gt;
      &lt;item&gt;Mimir: P2P messenger on Yggdrasil (sister project)&lt;/item&gt;
      &lt;item&gt;Yggdrasil Network: The mesh network infrastructure&lt;/item&gt;
      &lt;item&gt;DeltaChat: Recommended email-based messenger client&lt;/item&gt;
      &lt;item&gt;ArcaneChat: Alternative email-based messenger client&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tyr is open source software. The Yggmail library uses Mozilla Public License v. 2.0.&lt;/p&gt;
    &lt;p&gt;See LICENSE file for full details.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Censorship Circumvention: Connect to any of hundreds of available Yggdrasil nodes, host your own, or even build a private network. Email freedom is literally in your hands.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Privacy by Design: No metadata collection, no server logs, no third-party surveillance. Your conversations belong to you.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Decentralization: No single point of failure, no corporate control. True peer-to-peer architecture.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è for the decentralized web&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46080143</guid><pubDate>Fri, 28 Nov 2025 16:35:24 +0000</pubDate></item><item><title>Airloom ‚Äì 3D Flight Tracker</title><link>https://objectiveunclear.com/airloom.html</link><description>&lt;doc fingerprint="77ed4fa771de6491"&gt;
  &lt;main&gt;
    &lt;p&gt;W/A/S/D - Move forward/left/back/right&lt;/p&gt;
    &lt;p&gt;Space - Move up&lt;/p&gt;
    &lt;p&gt;Shift - Move down&lt;/p&gt;
    &lt;p&gt;Mouse - Look around&lt;/p&gt;
    &lt;p&gt;Click anywhere to start flying&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46080289</guid><pubDate>Fri, 28 Nov 2025 16:49:12 +0000</pubDate></item><item><title>So you wanna build a local RAG?</title><link>https://blog.yakkomajuri.com/blog/local-rag</link><description>&lt;doc fingerprint="fb5fccd27d06c5d6"&gt;
  &lt;main&gt;
    &lt;p&gt;When we launched Skald, we wanted it to not only be self-hostable, but also for one to be able to run it without sending any data to third-parties.&lt;/p&gt;
    &lt;p&gt;With LLMs getting better and better, privacy-sensitive organizations shouldn't have to choose between being left behind by not accessing frontier models and doing away with their committment to (or legal requirement for) data privacy.&lt;/p&gt;
    &lt;p&gt;So here's what we did to support this use case and also some benchmarks comparing performance when using proprietary APIs vs self-hosted open-source tech.&lt;/p&gt;
    &lt;head rend="h2"&gt;RAG components and their OSS alternatives&lt;/head&gt;
    &lt;p&gt;A basic RAG usually has the following core components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A vector database&lt;/item&gt;
      &lt;item&gt;A vector embeddings model&lt;/item&gt;
      &lt;item&gt;An LLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And most times it also has these as well:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A reranker&lt;/item&gt;
      &lt;item&gt;Document parsing (for PDFs, PowerPoints, etc)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What that means is that when you're looking to build a fully local RAG setup, you'll need to substitute whatever SaaS providers you're using for a local option for each of those components.&lt;/p&gt;
    &lt;p&gt;Here's a table with some examples of what we might use in a scenario where we can use third-party Cloud services and one where we can't:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Proprietary Options&lt;/cell&gt;
        &lt;cell role="head"&gt;Open-Source Options&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vector Database&lt;/cell&gt;
        &lt;cell&gt;Pinecone, Turbopuffer, Weaviate Cloud, Qdrant Cloud&lt;/cell&gt;
        &lt;cell&gt;Qdrant, Weaviate, Postgres with pgvector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vector Embeddings Provider&lt;/cell&gt;
        &lt;cell&gt;OpenAI, Cohere, Voyage&lt;/cell&gt;
        &lt;cell&gt;Sentence Transformers, BGE, E5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LLM&lt;/cell&gt;
        &lt;cell&gt;GPT, Claude, Gemini&lt;/cell&gt;
        &lt;cell&gt;Llama, Mistral, GPT-OSS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Reranker&lt;/cell&gt;
        &lt;cell&gt;Cohere, Voyage&lt;/cell&gt;
        &lt;cell&gt;BGE Reranker, Sentence Transformers Cross-Encoder&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Document Parsing&lt;/cell&gt;
        &lt;cell&gt;Reducto, Datalab&lt;/cell&gt;
        &lt;cell&gt;Docling&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Do note that running something locally does not mean it needs to be open-source, as one could pay for a license to self-host proprietary software. But at Skald our goal was to use fully open-source tech, which is what I'll be convering here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The table above is far from covering all available options on both columns, but basically it gives you an indication of what to research into in order to pick a tool that works for you.&lt;/p&gt;
    &lt;p&gt;As with anything, what works for you will greatly depend on your use case. And you need to be prepared to run a few more services than you're used to if you've just been calling APIs.&lt;/p&gt;
    &lt;p&gt;For our local stack, we went with the easiest setup for now to get it working (and it does! see writeup on this lower down) but will be running benchmarks on all other options to determine the best possible setup.&lt;/p&gt;
    &lt;p&gt;This is what we have today:&lt;/p&gt;
    &lt;p&gt;Vector DB: Postgres + pgvector. We already use Postgres and didn't want to bundle another service into our stack, but this is controversial and we will be running benchmarks to make a better informed decision here. Note that pgvector will serve a lot of use cases well all the way up to hundreds of thousands of documents, though.&lt;/p&gt;
    &lt;p&gt;Vector embeddings: Users can configure this in Skald and we use Sentence Transformers (all-MiniLM-L6-v2) as our default (solid all-around performer for speed and retrieval, English-only). I also ran Skald with bge-m3 (larger, multi-language) and share the results later in this post.&lt;/p&gt;
    &lt;p&gt;LLM: We don't even bundle a default with Skald and it's up to the users to run and manage this. I tested our setup with GPT-OSS 20B on EC2 (results shown below).&lt;/p&gt;
    &lt;p&gt;Reranker: Users can also configure this in Skald, and the default is the Sentence Transformers cross encoder (solid, English-only). I've also used bge-reranker-v2-m3 and mmarco-mMiniLMv2-L12-H384-v1 which offer multi-lingual support.&lt;/p&gt;
    &lt;p&gt;Document parsing: There isn't much of a question on this one. We're using Docling. It's great. We run it via docling-serve.&lt;/p&gt;
    &lt;head rend="h2"&gt;Does it perform though?&lt;/head&gt;
    &lt;p&gt;So the main goal here was first to get something working then ensure it worked well with our platform and could be easily deployed. From here we'll be running extensive benchmarks and working with our clients to provide a solid setup that both performs well but is also not a nightmare to deploy and manage.&lt;/p&gt;
    &lt;p&gt;From that perspective, this was a great success.&lt;/p&gt;
    &lt;p&gt;Deploying a production instance of Skald with this whole stack took me 8 minutes, and that comes bundled with the vector database (well, Postgres), a reranking and embedding service, and Docling.&lt;/p&gt;
    &lt;p&gt;The only thing I needed to run separately was the LLM, which I did via llama.cpp.&lt;/p&gt;
    &lt;p&gt;Having gotten this sorted, I imported all the content from the PostHog website [1] and set up a tiny dataset [2] of questions and expected answers inside of Skald, then used our Experiments feature to run the RAG over this dataset.&lt;/p&gt;
    &lt;p&gt;I explicitly kept the topK values really high (100 for the vector search and 50 for post-reranking), as I was mostly testing for accuracy and wanted to see the performance when questions required e.g. aggregating context over 15+ documents.&lt;/p&gt;
    &lt;head&gt;Full config&lt;/head&gt;
    &lt;p&gt;Here are the params configured in the Skald UI for the the experiment.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Config option&lt;/cell&gt;
        &lt;cell role="head"&gt;Selection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Extra system prompt&lt;/cell&gt;
        &lt;cell&gt;Be really concise in your answers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Query rewriting&lt;/cell&gt;
        &lt;cell&gt;Off&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vector search topK&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vector search distance threshold&lt;/cell&gt;
        &lt;cell&gt;0.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reranking&lt;/cell&gt;
        &lt;cell&gt;On&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reranking topK&lt;/cell&gt;
        &lt;cell&gt;50&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;References&lt;/cell&gt;
        &lt;cell&gt;Off&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So without any more delay, here are the results of my not-very-scientific at all benchmark using the experimentation platform inside of Skald.&lt;/p&gt;
    &lt;head rend="h3"&gt;Voyage + Claude&lt;/head&gt;
    &lt;p&gt;This is our default Cloud setup. We use voyage-3-large and rerank-2.5 from Voyage AI as our embedding and reranking models respectively, and we default to Claude Sonnet 3.7 for responses (users can configure the model though).&lt;/p&gt;
    &lt;p&gt;It passed with flying colors.&lt;/p&gt;
    &lt;p&gt;Our LLM-as-a-Judge gave an average score of 9.45 to the responses, and I basically agree with the assessment. All answers were correct, with one missing a few extra bits of context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Voyage + GPT-OSS 20B&lt;/head&gt;
    &lt;p&gt;With the control experiment done, I then moved on to a setup where I kept Voyage as the embeddings provider and reranker, and then used GPT-OSS 20B running on a llama.cpp server on a g5.2xlarge EC2 instance as the LLM.&lt;/p&gt;
    &lt;p&gt;The goal here was to see how well the open-source LLM model itself stacked up against a frontier model accessed via API.&lt;/p&gt;
    &lt;p&gt;And it did great!&lt;/p&gt;
    &lt;p&gt;We don't yet support LLM-as-a-Judge on fully local deployments, so the only score we have here is mine. I scored the answers an average of 9.18 and they were all correct, with two of them just missing a few bits of information or highlighting less relevant information from the context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fully local + GPT-OSS 20B&lt;/head&gt;
    &lt;p&gt;Lastly, it was time for the moment of truth: running a fully local setup.&lt;/p&gt;
    &lt;p&gt;For this I ran two tests:&lt;/p&gt;
    &lt;p&gt;1. Default sentence transformers embedding and reranking models&lt;/p&gt;
    &lt;p&gt;The most popular open-source models are all-MiniLM-L6-v2 for embeddings and ms-marco-MiniLM-L6-v2 as the reranker, so I used those for my first benchmark.&lt;/p&gt;
    &lt;p&gt;Here the average score was 7.10. Not bad, but definitely not great. However, when we dig into the results, we can get a better understanding of how this setup fails.&lt;/p&gt;
    &lt;p&gt;Basically, it got all point queries right, which are questions where the answer is somewhere in the mess of documents, but can be found from one specific place.&lt;/p&gt;
    &lt;p&gt;Where it failed was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-english query: The embeddings model and the reranker are English-based, so my question in Portuguese obviously got no answer&lt;/item&gt;
      &lt;item&gt;An ambiguous question with very little context ("what's ch")&lt;/item&gt;
      &lt;item&gt;Aggregating information from multiple documents/chunks e.g. it only found 5 out of PostHog's 7 funding rounds, and only a subset of the PostHog competitors that offer session replay (as mentioned in the source data)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In my view, this is good news. That means that the default options will go a long way and should give you very good performance if your use case is only doing point queries in English. The other great thing is that these models are also fast.&lt;/p&gt;
    &lt;p&gt;Now, if you need to handle ambiguity better, or handle questions in other languages, then this setup is simply not for you.&lt;/p&gt;
    &lt;p&gt;2. Multi-lingual models&lt;/p&gt;
    &lt;p&gt;The next test I did used bge-m3 as the embeddings model and mmarco-mMiniLMv2-L12-H384-v1 as the reranker. The embeddings model is supposedly much better than the one used in the previous test and is also multi-lingual. The reranker on the other hand uses the same cross-encoder from the previous test as the base model but also adds multi-lingual support. The more standard option here would have been the much more popular bge-reranker-v2-m3 model, but I found it to be much slower. I intend to tweak my setup and test it again, however.&lt;/p&gt;
    &lt;p&gt;Anyway, onto the results! I scored it 8.63 on average, which is very good. There were no complete failures, and it handled the question in Portuguese well.&lt;/p&gt;
    &lt;p&gt;The mistakes it made were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This new setup also did not do the best job at aggregating information, missing 2 of PostHog's funding rounds, and a couple of its session replay competitors&lt;/item&gt;
      &lt;item&gt;It also answered a question correctly, but added incorrect additional context after it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So overall it performed quite well. Again what we what saw was the main problem is when the context needed for the response is scattered across multiple documents. There are various techniques to help with this and we'll be trialing some soon! They haven't been needed on the Cloud version because better models save you from having to add complexity for minimal performance gains, but as we're focused on building a really solid setup for local deploys, we'll be looking into this more and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Now what?&lt;/head&gt;
    &lt;p&gt;I hope this writeup has provided you with at least some insight and context into building a local RAG, and also the fact that it does work, it can serve a lot of use cases, and that the tendency is for this setup to get better and better as a) models improve b) we get more open-source models across the board, with both being things that we seem to be trending towards.&lt;/p&gt;
    &lt;p&gt;As for us at Skald, we intend to polish this setup further in order to serve even more use cases really well, as well as intend to soon be publishing more legitimate benchmarks for models in the open-source space, from LLMs to rerankers.&lt;/p&gt;
    &lt;p&gt;If you're a company that needs to run AI tooling in air-gapped infrastructure, let's chat -- feel free to email me at yakko [at] useskald [dot] com.&lt;/p&gt;
    &lt;p&gt;Lastly, if you want to get involved, feel free to chat to us over on our GitHub repo (MIT-licensed) or catch us on Slack.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;[1] I used the PostHog website here because the website content is MIT-licensed (yes, wild) and readily-available as markdown on GitHub and having worked there I know a lot of answers off the top of my head making it a great dataset of ~2000 documents that I know well.&lt;/p&gt;
    &lt;p&gt;[2] The questions and answers dataset I used for the experiments was the following:&lt;/p&gt;
    &lt;head&gt;Dataset&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Question&lt;/cell&gt;
        &lt;cell role="head"&gt;Expected answer&lt;/cell&gt;
        &lt;cell role="head"&gt;Comments&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;How many raises did PostHog do?&lt;/cell&gt;
        &lt;cell&gt;PostHog has raised money 7 times: it raised $150k from YCombinator, then did a seed round ($3.025M), a series A ($12M), a series B ($15M), a series C ($10M), a series D ($70M), and a series E ($75M).&lt;/cell&gt;
        &lt;cell&gt;Requires aggregating context from at least 7 documents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;When did group analytics launch?&lt;/cell&gt;
        &lt;cell&gt;December 16, 2021.&lt;/cell&gt;
        &lt;cell&gt;Point query, multiple mentions to "group analytics" in the source docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Why was the sessions page removed?&lt;/cell&gt;
        &lt;cell&gt;The sessions page was removed because it was confusing and limited in functionality. It was replaced by the 'Recordings' tab.&lt;/cell&gt;
        &lt;cell&gt;Point query, multiple mentions to "sessions" in the source docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;What's the difference between a product engineer and other roles?&lt;/cell&gt;
        &lt;cell&gt;Compared to product managers, product engineers focus more on building rather than deep research and planning. When it comes to software engineers, both product and software engineers write code, but software engineers focus on building great software, whereas product engineers focus on building great products.&lt;/cell&gt;
        &lt;cell&gt;Requires aggregating context from multiple docs + there are a ton of mentions of "product engineer" in the source docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;What were the main benefits of YC?&lt;/cell&gt;
        &lt;cell&gt;The main benefits of YC were: Network Access, Investor Reviews, Office Hours, Funding Opportunities, Hiring Resources, Angel Investing Opportunities, Accelerated Growth and Experience, Shift in Self-Perception, Customer Acquisition, Product Market Fit, Ambitious Goal Setting, Access to Thought Leaders, Community Support&lt;/cell&gt;
        &lt;cell&gt;Point query&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;quem foi o primeiro investidor da posthogg?&lt;/cell&gt;
        &lt;cell&gt;O primeiro investidor da PostHog foi o YCombinator.&lt;/cell&gt;
        &lt;cell&gt;Question in Portuguese, with PostHog misspelled&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;what posthog competitors also offer session replays&lt;/cell&gt;
        &lt;cell&gt;LogRocket, Smartlook, FullStory, Microsoft Clarity, Contentsquare, Mouseflow, Heap, Pendo, Hotjar, Glassbox, and Amplitude.&lt;/cell&gt;
        &lt;cell&gt;Requires aggregating content from at least 11 docs (more because I actually missed some in my expected answer)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;top tips find client&lt;/cell&gt;
        &lt;cell&gt;1. Leverage your inner circle 2. Join relevant communities 3. Be laser-focused 4. Set achievable goals 5. Frame conversations properly&lt;/cell&gt;
        &lt;cell&gt;Point query, worded weirdly&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;what's ch&lt;/cell&gt;
        &lt;cell&gt;CH most likely refers to ClickHouse, a column-oriented OLAP database.&lt;/cell&gt;
        &lt;cell&gt;Really ambiguous. I meant ClickHouse with my question.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;what is mixedpanel&lt;/cell&gt;
        &lt;cell&gt;Mixpanel is a popular product analytics tool that was founded in 2009&lt;/cell&gt;
        &lt;cell&gt;Mixpanel misspelled as Mixedpanel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;how was prpoerty filtering made faster?&lt;/cell&gt;
        &lt;cell&gt;Using materialized columns allowed ClickHouse to skip JSON parsing during queries and made queries with property filtering 25x faster.&lt;/cell&gt;
        &lt;cell&gt;Point query with a typo&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46080364</guid><pubDate>Fri, 28 Nov 2025 16:54:56 +0000</pubDate></item><item><title>Molly: An Improved Signal App</title><link>https://molly.im/</link><description>&lt;doc fingerprint="fa4c68be1bd036dc"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;An improved Signal app&lt;/head&gt;
    &lt;p&gt;Molly is an independent Signal fork for Android with improved features:&lt;/p&gt;
    &lt;p&gt; Fully FOSS Contains no proprietary blobs, unlike Signal &lt;/p&gt;
    &lt;p&gt; Encrypted Protects database with Passphrase Encryption &lt;/p&gt;
    &lt;p&gt; Multi-Device Pair multiple devices to a single account &lt;/p&gt;
    &lt;p&gt; Material You Extra theme that follows your device palette &lt;/p&gt;
    &lt;p&gt; UnifiedPush Ungoogled notification system &lt;/p&gt;
    &lt;p&gt; Automatic Locking When you are gone for a set period of time &lt;/p&gt;
    &lt;p&gt; RAM Shredding Securely shreds sensitive data &lt;/p&gt;
    &lt;p&gt; And more New and better features to come &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46080916</guid><pubDate>Fri, 28 Nov 2025 17:48:25 +0000</pubDate></item><item><title>28M Hacker News comments as vector embedding search dataset</title><link>https://clickhouse.com/docs/getting-started/example-datasets/hackernews-vector-search-dataset</link><description>&lt;doc fingerprint="11938b322ad7669e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;Generate embeddings for search query&lt;/head&gt;
      &lt;p&gt;Sentence Transformers provide local, easy to use embedding models for capturing the semantic meaning of sentences and paragraphs.&lt;/p&gt;
      &lt;p&gt;The dataset in this HackerNews dataset contains vector emebeddings generated from the all-MiniLM-L6-v2 model.&lt;/p&gt;
      &lt;p&gt;An example Python script is provided below to demonstrate how to programmatically generate embedding vectors using &lt;code&gt;sentence_transformers1 Python package. The search embedding vector is then passed as an argument to the [&lt;/code&gt;cosineDistance()&lt;code&gt;](/sql-reference/functions/distance-functions#cosineDistance) function in the &lt;/code&gt;SELECT` query.&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;quote&gt;
            &lt;code&gt;from sentence_transformers import SentenceTransformer
import sys

import clickhouse_connect

print("Initializing...")

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

chclient = clickhouse_connect.get_client() # ClickHouse credentials here

while True:
    # Take the search query from user
    print("Enter a search query :")
    input_query = sys.stdin.readline();
    texts = [input_query]

    # Run the model and obtain search vector
    print("Generating the embedding for ", input_query);
    embeddings = model.encode(texts)

    print("Querying ClickHouse...")
    params = {'v1':list(embeddings[0]), 'v2':20}
    result = chclient.query("SELECT id, title, text FROM hackernews ORDER BY cosineDistance(vector, %(v1)s) LIMIT %(v2)s", parameters=params)
    print("Results :")
    for row in result.result_rows:
        print(row[0], row[2][:100])
        print("---------")

&lt;/code&gt;
          &lt;/quote&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;p&gt;An example of running the above Python script and similarity search results are shown below (only 100 characters from each of the top 20 posts are printed):&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;quote&gt;
            &lt;code&gt;Initializing...

Enter a search query :
Are OLAP cubes useful

Generating the embedding for  "Are OLAP cubes useful"

Querying ClickHouse...

Results :

27742647 smartmic:
slt2021: OLAP Cube is not dead, as long as you use some form of:&amp;lt;p&amp;gt;1. GROUP BY multiple fi
---------
27744260 georgewfraser:A data mart is a logical organization of data to help humans understand the schema. Wh
---------
27761434 mwexler:&amp;amp;quot;We model data according to rigorous frameworks like Kimball or Inmon because we must r
---------
28401230 chotmat:
erosenbe0: OLAP database is just a copy, replica, or archive of data with a schema designe
---------
22198879 Merick:+1 for Apache Kylin, it&amp;amp;#x27;s a great project and awesome open source community. If anyone i
---------
27741776 crazydoggers:I always felt the value of an OLAP cube was uncovering questions you may not know to as
---------
22189480 shadowsun7:
_Codemonkeyism: After maintaining an OLAP cube system for some years, I&amp;amp;#x27;m not that
---------
27742029 smartmic:
gengstrand: My first exposure to OLAP was on a team developing a front end to Essbase that
---------
22364133 irfansharif:
simo7: I&amp;amp;#x27;m wondering how this technology could work for OLAP cubes.&amp;lt;p&amp;gt;An OLAP cube
---------
23292746 scoresmoke:When I was developing my pet project for Web analytics (&amp;lt;a href="https:&amp;amp;#x2F;&amp;amp;#x2F;github
---------
22198891 js8:It seems that the article makes a categorical error, arguing that OLAP cubes were replaced by co
---------
28421602 chotmat:
7thaccount: Is there any advantage to OLAP cube over plain SQL (large historical database r
---------
22195444 shadowsun7:
lkcubing: Thanks for sharing. Interesting write up.&amp;lt;p&amp;gt;While this article accurately capt
---------
22198040 lkcubing:Thanks for sharing. Interesting write up.&amp;lt;p&amp;gt;While this article accurately captures the issu
---------
3973185 stefanu:
sgt: Interesting idea. Ofcourse, OLAP isn't just about the underlying cubes and dimensions,
---------
22190903 shadowsun7:
js8: It seems that the article makes a categorical error, arguing that OLAP cubes were r
---------
28422241 sradman:OLAP Cubes have been disrupted by Column Stores. Unless you are interested in the history of
---------
28421480 chotmat:
sradman: OLAP Cubes have been disrupted by Column Stores. Unless you are interested in the
---------
27742515 BadInformatics:
quantified: OP posts with inverted condition: ‚ÄúOLAP != OLAP Cube‚Äù is the actual titl
---------
28422935 chotmat:
rstuart4133: I remember hearing about OLAP cubes donkey&amp;amp;#x27;s years ago (probably not far
---------
&lt;/code&gt;
          &lt;/quote&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;Summarization demo application&lt;/head&gt;
      &lt;p&gt;The example above demonstrated semantic search and document retrieval using ClickHouse.&lt;/p&gt;
      &lt;p&gt;A very simple but high potential generative AI example application is presented next.&lt;/p&gt;
      &lt;p&gt;The application performs the following steps:&lt;/p&gt;
      &lt;list class="custom-ol" rend="ol"&gt;
        &lt;item class="custom-li"&gt;Accepts a topic as input from the user&lt;/item&gt;
        &lt;item class="custom-li"&gt;Generates an embedding vector for the topic by using the &lt;code&gt;SentenceTransformers&lt;/code&gt; with model &lt;code&gt;all-MiniLM-L6-v2&lt;/code&gt;&lt;/item&gt;
        &lt;item class="custom-li"&gt;Retrieves highly relevant posts/comments using vector similarity search on the &lt;code&gt;hackernews&lt;/code&gt; table&lt;/item&gt;
        &lt;item class="custom-li"&gt;Uses &lt;code&gt;LangChain&lt;/code&gt; and OpenAI &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; Chat API to summarize the content retrieved in step #3.
The posts/comments retrieved in step #3 are passed as context to the Chat API and are the key link in Generative AI.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;An example from running the summarization application is first listed below, followed by the code for the summarization application. Running the application requires an OpenAI API key to be set in the environment variable &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;. The OpenAI API key can be obtained after registering at https://platform.openai.com.&lt;/p&gt;
      &lt;p&gt;This application demonstrates a Generative AI use-case that is applicable to multiple enterprise domains like : customer sentiment analysis, technical support automation, mining user conversations, legal documents, medical records, meeting transcripts, financial statements, etc&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;quote&gt;
            &lt;code&gt;$ python3 summarize.py

Enter a search topic :
ClickHouse performance experiences

Generating the embedding for ----&amp;gt;  ClickHouse performance experiences

Querying ClickHouse to retrieve relevant articles...

Initializing chatgpt-3.5-turbo model...

Summarizing search results retrieved from ClickHouse...

Summary from chatgpt-3.5:
The discussion focuses on comparing ClickHouse with various databases like TimescaleDB, Apache Spark,
AWS Redshift, and QuestDB, highlighting ClickHouse's cost-efficient high performance and suitability
for analytical applications. Users praise ClickHouse for its simplicity, speed, and resource efficiency
in handling large-scale analytics workloads, although some challenges like DMLs and difficulty in backups
are mentioned. ClickHouse is recognized for its real-time aggregate computation capabilities and solid
engineering, with comparisons made to other databases like Druid and MemSQL. Overall, ClickHouse is seen
as a powerful tool for real-time data processing, analytics, and handling large volumes of data
efficiently, gaining popularity for its impressive performance and cost-effectiveness.
&lt;/code&gt;
          &lt;/quote&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;p&gt;Code for the above application :&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;quote&gt;
            &lt;code&gt;print("Initializing...")

import sys
import json
import time
from sentence_transformers import SentenceTransformer

import clickhouse_connect

from langchain.docstore.document import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
import textwrap
import tiktoken

def num_tokens_from_string(string: str, encoding_name: str) -&amp;gt; int:
    encoding = tiktoken.encoding_for_model(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

chclient = clickhouse_connect.get_client(compress=False) # ClickHouse credentials here

while True:
    # Take the search query from user
    print("Enter a search topic :")
    input_query = sys.stdin.readline();
    texts = [input_query]

    # Run the model and obtain search or reference vector
    print("Generating the embedding for ----&amp;gt; ", input_query);
    embeddings = model.encode(texts)

    print("Querying ClickHouse...")
    params = {'v1':list(embeddings[0]), 'v2':100}
    result = chclient.query("SELECT id,title,text FROM hackernews ORDER BY cosineDistance(vector, %(v1)s) LIMIT %(v2)s", parameters=params)

    # Just join all the search results
    doc_results = ""
    for row in result.result_rows:
        doc_results = doc_results + "\n" + row[2]

    print("Initializing chatgpt-3.5-turbo model")
    model_name = "gpt-3.5-turbo"

    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
        model_name=model_name
    )

    texts = text_splitter.split_text(doc_results)

    docs = [Document(page_content=t) for t in texts]

    llm = ChatOpenAI(temperature=0, model_name=model_name)

    prompt_template = """
Write a concise summary of the following in not more than 10 sentences:


{text}


CONSCISE SUMMARY :
"""

    prompt = PromptTemplate(template=prompt_template, input_variables=["text"])

    num_tokens = num_tokens_from_string(doc_results, model_name)

    gpt_35_turbo_max_tokens = 4096
    verbose = False

    print("Summarizing search results retrieved from ClickHouse...")

    if num_tokens &amp;lt;= gpt_35_turbo_max_tokens:
        chain = load_summarize_chain(llm, chain_type="stuff", prompt=prompt, verbose=verbose)
    else:
        chain = load_summarize_chain(llm, chain_type="map_reduce", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)

    summary = chain.run(docs)

    print(f"Summary from chatgpt-3.5: {summary}")
&lt;/code&gt;
          &lt;/quote&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46081053</guid><pubDate>Fri, 28 Nov 2025 18:02:04 +0000</pubDate></item><item><title>Imgur geo-blocked the UK, so I geo-unblocked my network</title><link>https://blog.tymscar.com/posts/imgurukproxy/</link><description>&lt;doc fingerprint="b582e1f56725aa92"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Imgur Geo-Blocked the UK, So I Geo-Unblocked My Entire Network&lt;/head&gt;
    &lt;p&gt;Imgur decided to block UK users. Honestly? I don‚Äôt really care that much. I haven‚Äôt actively browsed the site in years. But it used to be everywhere. Back when Reddit embedded everything on Imgur, maybe fifteen years ago, it was genuinely useful. Then Reddit built their own image hosting, Discord did the same, and Imgur slowly faded into the background.&lt;/p&gt;
    &lt;p&gt;Except it never fully disappeared. And since the block, I keep stumbling across Imgur links that just show ‚Äúunavailable.‚Äù It‚Äôs mildly infuriating.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Minecraft shader problem#&lt;/head&gt;
    &lt;p&gt;Here‚Äôs a concrete example. I was playing Minecraft with some work colleagues and wanted to try different shaders. Most shader pages embed preview images hosted on Imgur. So I‚Äôd click through shader after shader, and every single preview was just gone. I couldn‚Äôt see what any of them looked like without the images.&lt;/p&gt;
    &lt;p&gt;This kind of thing happens constantly now. Old forum posts, Reddit threads, documentation pages, random project READMEs. Imgur links are still scattered across the internet, and in the UK, they‚Äôre all broken.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why I didn‚Äôt just install a VPN#&lt;/head&gt;
    &lt;p&gt;The obvious solution is to use a VPN. Change your location, problem solved. But I have a few issues with that approach.&lt;/p&gt;
    &lt;p&gt;First, I just upgraded to 2.5 Gbps internet and I don‚Äôt want to route all my traffic through a VPN and take the speed hit. I have this bandwidth for a reason.&lt;/p&gt;
    &lt;p&gt;Second, even if I installed a VPN on my main machine, what about my phone? My laptop? My desktop? Every device would need the VPN running, and I‚Äôd have to remember to connect it before browsing. It‚Äôs messy.&lt;/p&gt;
    &lt;p&gt;I wanted something cleaner: a solution that works for every device on my network, automatically, without any client-side configuration.&lt;/p&gt;
    &lt;head rend="h2"&gt;The network-level approach#&lt;/head&gt;
    &lt;p&gt;I already run a homelab with Traefik as my reverse proxy, Pi-hole for DNS, and everything declaratively configured with NixOS. If you‚Äôve read my previous post on Docker containers with secrets, you‚Äôll recognise the pattern.&lt;/p&gt;
    &lt;p&gt;The idea was simple: intercept all requests to &lt;code&gt;i.imgur.com&lt;/code&gt; at the DNS level, route them through a VPN-connected container, and serve the images back. Every device on my network automatically uses Pi-hole for DNS via DHCP, so this would be completely transparent.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs the flow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Device requests &lt;code&gt;i.imgur.com&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Pi-hole returns my Traefik instance‚Äôs IP instead&lt;/item&gt;
      &lt;item&gt;Traefik sees the SNI hostname and routes to Gluetun&lt;/item&gt;
      &lt;item&gt;Gluetun tunnels the request through a VPN&lt;/item&gt;
      &lt;item&gt;Nginx (attached to Gluetun‚Äôs network) proxies to the real Imgur&lt;/item&gt;
      &lt;item&gt;Image comes back through the tunnel to the device&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why Nginx when I already have Traefik?#&lt;/head&gt;
    &lt;p&gt;Good question. Gluetun isn‚Äôt a reverse proxy. It‚Äôs a container that provides VPN connectivity to other containers attached to its network namespace. So I needed something inside Gluetun‚Äôs network to actually handle the proxying. Nginx was the simplest choice.&lt;/p&gt;
    &lt;p&gt;The Nginx config is minimal. It just does TCP passthrough with SNI:&lt;/p&gt;
    &lt;code&gt;user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

stream {
    resolver 127.0.0.1 valid=30s;
    resolver_timeout 5s;

    server {
        listen 443;
        ssl_preread on;
        proxy_pass i.imgur.com:443;
        proxy_connect_timeout 10s;
        proxy_timeout 60s;
    }
}
&lt;/code&gt;
    &lt;p&gt;This listens on port 443, reads the SNI header to confirm the destination, and passes the connection through to the real &lt;code&gt;i.imgur.com&lt;/code&gt;. The TLS handshake happens end-to-end; Nginx never sees the decrypted traffic.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Docker setup#&lt;/head&gt;
    &lt;p&gt;The compose file runs two containers. Gluetun handles the VPN connection, and Nginx attaches to Gluetun‚Äôs network:&lt;/p&gt;
    &lt;code&gt;version: '3.8'

services:
  gluetun:
    image: qmcgaw/gluetun:latest
    container_name: gluetun
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    environment:
      - VPN_SERVICE_PROVIDER=${VPN_SERVICE_PROVIDER}
      - VPN_TYPE=wireguard
      - WIREGUARD_PRIVATE_KEY=${WIREGUARD_PRIVATE_KEY}
      - SERVER_COUNTRIES=${SERVER_COUNTRIES}
      - FIREWALL=on
      - FIREWALL_INPUT_PORTS=443
      - FIREWALL_OUTBOUND_SUBNETS=10.0.0.0/8
      - DOT=on
      - DOT_PROVIDERS=cloudflare
      - HEALTH_VPN_DURATION_INITIAL=30s
    volumes:
      - ./gluetun:/gluetun
    restart: unless-stopped
    networks:
      - proxy
    healthcheck:
      test: ["CMD", "/gluetun-entrypoint", "healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  imgur-proxy:
    image: nginx:alpine
    container_name: imgur-proxy
    depends_on:
      gluetun:
        condition: service_healthy
    network_mode: "service:gluetun"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    restart: unless-stopped

networks:
  proxy:
    external: true
&lt;/code&gt;
    &lt;p&gt;The key detail is &lt;code&gt;network_mode: "service:gluetun"&lt;/code&gt;. This makes Nginx share Gluetun‚Äôs network stack, so all its traffic automatically goes through the VPN tunnel.&lt;/p&gt;
    &lt;p&gt;I‚Äôm not going to mention which VPN provider I use. It‚Äôs one of the major ones with WireGuard support, but honestly I‚Äôm not thrilled with it. Use whatever you have.&lt;/p&gt;
    &lt;head rend="h2"&gt;Traefik routing#&lt;/head&gt;
    &lt;p&gt;The final piece is telling Traefik to route &lt;code&gt;i.imgur.com&lt;/code&gt; traffic to the Gluetun container. This uses TCP routing with TLS passthrough:&lt;/p&gt;
    &lt;code&gt;tcp:
  routers:
    imgur-router:
      rule: "HostSNI(`i.imgur.com`)"
      entryPoints:
        - https
      service: imgur-service
      tls:
        passthrough: true
  services:
    imgur-service:
      loadBalancer:
        servers:
          - address: "gluetun:443"
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;passthrough: true&lt;/code&gt; is important. It means Traefik doesn‚Äôt terminate TLS; it just inspects the SNI header and forwards the connection.&lt;/p&gt;
    &lt;head rend="h2"&gt;NixOS integration#&lt;/head&gt;
    &lt;p&gt;Following the same pattern from my Docker with secrets post, I created a systemd service that runs the compose stack with Agenix-managed secrets:&lt;/p&gt;
    &lt;code&gt;{ pkgs, config, ... }:
let
  docker-env = config.age.secrets.docker-imgur-proxy.path;
in
{
  systemd.services.imgur-proxy = {
    description = "Imgur Proxy with VPN";
    after = [
      "network.target"
      "docker.service"
      "docker-create-proxy-network.service"
    ];
    wants = [
      "docker.service"
      "docker-create-proxy-network.service"
    ];
    serviceConfig = {
      ExecStart = "${pkgs.docker}/bin/docker compose --env-file ${docker-env} -f docker-compose.yml up --force-recreate";
      ExecStop = "${pkgs.docker}/bin/docker compose -f docker-compose.yml down";
      WorkingDirectory = "/home/tymscar/dotfiles/apps/nixos/docker/imgur-proxy";
      Restart = "always";
    };
    wantedBy = [ "multi-user.target" ];
  };
}
&lt;/code&gt;
    &lt;p&gt;The VPN credentials are stored encrypted with Agenix, so my entire dotfiles repo stays public while keeping secrets safe.&lt;/p&gt;
    &lt;head rend="h2"&gt;The result#&lt;/head&gt;
    &lt;p&gt;Now when any device on my network requests an Imgur image, it works. My phone, my laptop, guest devices, everything. No VPN apps to install, no browser extensions, no manual configuration. Pi-hole intercepts the DNS, Traefik routes the connection, and Gluetun tunnels it through a non-UK exit point.&lt;/p&gt;
    &lt;p&gt;The latency increase is negligible for loading images, and it only affects Imgur traffic. Everything else still goes direct at full speed.&lt;/p&gt;
    &lt;p&gt;Is this overkill for viewing the occasional Imgur image? Probably. But it‚Äôs a clean solution that requires minimal ongoing maintenance, and it scratches the homelab itch. Plus I can finally see what those Minecraft shaders look like.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46081188</guid><pubDate>Fri, 28 Nov 2025 18:15:50 +0000</pubDate></item><item><title>The original ABC language, Python's predecessor (1991)</title><link>https://github.com/gvanrossum/abc-unix</link><description>&lt;doc fingerprint="2fe8520fe9cb456a"&gt;
  &lt;main&gt;
    &lt;p&gt;ABC was Python's most direct predecessor; I worked on it from around 1983-1986.&lt;/p&gt;
    &lt;p&gt;I downloaded these sources from cwi.nl, specifically the abc-unix tarball.&lt;/p&gt;
    &lt;p&gt;Another copy of the ABC sources lives in Luciano Ramalho's GitHub. I hope one day to compare the two trees and unify them.&lt;/p&gt;
    &lt;p&gt;Most files have 1991 as their latest modification time in the tar ball; a few have 1996 or 2021.&lt;/p&gt;
    &lt;p&gt;The old README file has build instructions.&lt;/p&gt;
    &lt;p&gt;The current sources assume a 32-bit system where int and pointers have the same size. I hope to eventually upgrade the source code to work on 64-bit systems too (where int is 32 bits and pointers are 64 bits).&lt;/p&gt;
    &lt;p&gt;CWI never put a license on ABC, but it says:&lt;/p&gt;
    &lt;p&gt;Copyright (c) Stichting Mathematisch Centrum, Amsterdam, 1988-2011.&lt;/p&gt;
    &lt;p&gt;I'll try to negotiate with Steven Pemberton eventually (hopefully MIT).&lt;/p&gt;
    &lt;p&gt;Eddy Boeve, Frank van Dijk, Leo Geurts, Timo Krijnen, Lambert Meertens, Steven Pemberton, Guido van Rossum.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leo Geurts, Lambert Meertens and Steven Pemberton, The ABC Programmer's Handbook, Prentice-Hall, Englewood Cliffs, New Jersey, 1990, ISBN 0-13- 000027-2.&lt;/item&gt;
      &lt;item&gt;Steven Pemberton, An Alternative Simple Language and Environment for PCs, IEEE Software, Vol. 4, No. 1, January 1987, pp. 56-64. http://www.cwi.nl/~steven/abc.html&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Steven Pemberton's home page. https://homepages.cwi.nl/~steven/abc/&lt;/item&gt;
      &lt;item&gt;Lambert Meertens, The Origins of Python. https://inference-review.com/article/the-origins-of-python&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46082204</guid><pubDate>Fri, 28 Nov 2025 19:58:13 +0000</pubDate></item><item><title>Airbus A320 ‚Äì intense solar radiation may corrupt data critical for flight</title><link>https://www.airbus.com/en/newsroom/press-releases/2025-11-airbus-update-on-a320-family-precautionary-fleet-action</link><description>&lt;doc fingerprint="359e27eeea79718f"&gt;
  &lt;main&gt;
    &lt;p&gt;Toulouse, France, 28 November 2025 ‚Äì Analysis of a recent event involving an A320 Family aircraft has revealed that intense solar radiation may corrupt data critical to the functioning of flight controls.&lt;/p&gt;
    &lt;p&gt;Airbus has consequently identified a significant number of A320 Family aircraft currently in-service which may be impacted.&lt;/p&gt;
    &lt;p&gt;Airbus has worked proactively with the aviation authorities to request immediate precautionary action from operators via an Alert Operators Transmission (AOT) in order to implement the available software and/or hardware protection, and ensure the fleet is safe to fly. This AOT will be reflected in an Emergency Airworthiness Directive from the European Union Aviation Safety Agency (EASA).&lt;/p&gt;
    &lt;p&gt;Airbus acknowledges these recommendations will lead to operational disruptions to passengers and customers. We apologise for the inconvenience caused and will work closely with operators, while keeping safety as our number one and overriding priority.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contacts&lt;/head&gt;
    &lt;head rend="h3"&gt;Guillaume Steuer&lt;/head&gt;
    &lt;p&gt;AIRBUS&lt;/p&gt;
    &lt;head rend="h3"&gt;Sara Ricci&lt;/head&gt;
    &lt;p&gt;AIRBUS | Commercial Aircraft&lt;/p&gt;
    &lt;head rend="h3"&gt;Justin Dubon&lt;/head&gt;
    &lt;p&gt;AIRBUS | Commercial Aircraft&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46083004</guid><pubDate>Fri, 28 Nov 2025 21:40:21 +0000</pubDate></item><item><title>Confessions of a Software Developer: No More Self-Censorship</title><link>https://kerrick.blog/articles/2025/confessions-of-a-software-developer-no-more-self-censorship/</link><description>&lt;doc fingerprint="2f4551170fb65fb1"&gt;
  &lt;main&gt;
    &lt;p&gt;I haven‚Äôt published since April because I‚Äôve been afraid. I also avoided social media, news aggregators, and discussion forums for months. I‚Äôm done letting fear stop me. What was I afraid of? In this post I detail every single thing I‚Äôve avoided admitting on this blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Knowledge Gap Confessions&lt;/head&gt;
    &lt;p&gt;First, why am I admitting these things now? I realized I am not the only working software developer missing crucial skills. My learning path through my career looked a lot like a slime mold seeking morsels of food: strengthening what has utility, but letting the rest wither. But lately, I‚Äôve been building a better base of knowledge. Writing or speaking about what I learn‚Äìwhich helps me learn better‚Äìrequires me to admit I didn‚Äôt know. Plus, I‚Äôd like to show others in my situation that it‚Äôs never too late to learn what you don‚Äôt know. I can fill in those fundamentals, and so can you.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It‚Äôs from that very ignorance that sprouts the drive for knowledge.&lt;/p&gt;
      &lt;p&gt;‚Äî Leticia Portella, A Friendly Guide to Software Development&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;I Didn‚Äôt Understand Polymorphism For a Decade&lt;/head&gt;
    &lt;p&gt;Learning about polymorphism over the past twelve months was the first time I was embarrassed to admit I didn‚Äôt already know something. I‚Äôve been writing ostensibly object-oriented software since 2012. And yet, my lack of awareness of polymorphism showed me I‚Äôve been writing little more than structured programs. That I could replace conditionals and case staments with specialized classes had never crossed my mind.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;As a hiring manager I interviewed software engineers and tried to filter for object-oriented knowledge. Retroactively, it‚Äôs clear I was hypocritical. This gap reveals that I spent the early part of my career learning tools, not principles. Plus, it highlights my lack of formal education. Polymorphism is covered in every college OO course.&lt;/p&gt;
    &lt;head rend="h3"&gt;I Forgot SQL&lt;/head&gt;
    &lt;p&gt;I took a college database course as a student. As a working professional, I read and worked through the exercises in Learning SQL, 3rd Edition. For a while, I could write SQL. But I specialized in front-end web development, and had no professional use for SQL. Like any unused skill, it atrophied. I remember how to write basic queries, but not much more. For example, I cannot tell you the difference between a left inner join and an outer join without looking it up.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;I‚Äôm not accustomed to forgetting. Growing up I had a remarkable ability to remember almost everything. It didn‚Äôt matter whether I did it, read it, or heard it. It could be a fact, a skill, or an event. Four years later I could access that knowledge, with the slightest reminder unlocking a flood of memories. Now that I‚Äôm in my mid-thirties, that isn‚Äôt always true. SQL is the first time I‚Äôve lost an entire skill to atrophy. It‚Äôs tough to come to terms with the start of aging. It‚Äôs tougher to admit it publicly.&lt;/p&gt;
    &lt;head rend="h3"&gt;I Don‚Äôt Write Automated Tests&lt;/head&gt;
    &lt;p&gt;An estimated 95% of the code I‚Äôve shipped to production had no automated tests. Early in my career, I had no exposure to the concept. Later, I was writing front-ends in Ember, whose testing story was looked good but felt pretty bad at the time. More recently, I‚Äôve been working legacy code, and I haven‚Äôt put in the work to make it testable. The only time I tend to write new tests is when I‚Äôm writing a new subsystem, which can be designed testable from the start. I‚Äôm convinced that writing automated tests needs to be part of my daily practice, but I haven‚Äôt gotten there yet.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;This may be my most professionally-damaging confession. If you believe Uncle Bob, shipping production code without tests is not more than risky, it‚Äôs unethical. I stopped myself from posting about my learning journey for fear that a future hiring manager would decide that I was unfit to work with them on this basis.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;How much of the code should be tested with these automated unit tests? Do I really need to answer that question? All of it! All. Of. It.&lt;/p&gt;
      &lt;p&gt;Am I suggesting 100% test coverage? No, I‚Äôm not suggesting it. I‚Äôm demanding it. Every single line of code that you write should be tested. Period.&lt;/p&gt;
      &lt;p&gt;Isn‚Äôt that unrealistic? Of course not. You only write code because you expect it to get executed. If you expect it to get executed, you ought to know that it works. The only way to know this is to test it.&lt;/p&gt;
      &lt;p&gt;‚Äî Robert C. Martin, The Clean Coder, Chapter 1: Professionalism&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Personal Confessions&lt;/head&gt;
    &lt;head rend="h3"&gt;I Didn‚Äôt End Up Learning Blazor&lt;/head&gt;
    &lt;p&gt;People have been waiting for a follow-up from me about my journey learning C#, .NET, and Blazor. This isn‚Äôt that post. I don‚Äôt know if that post will ever come.&lt;/p&gt;
    &lt;p&gt;C# was never the language I wanted to learn for side projects. .NET was never the platform I wanted to work with professionally. I was learning them for one reason: my job. My engineering department decided to switch our tech stack from Angular to Blazor. I was the only person on the team with no C# skills. I started fixing that immediately.&lt;/p&gt;
    &lt;p&gt;A couple months later, almost as suddenly, the decision was undone. Our tech stack would not change after all. With no intrinsic motivation to push me along, I abandoned the C# / .NET book I was reading without finishing. I‚Äôve got more important things to learn.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;No matter what software thoughts crossed my mind, I intended to post about them. Writing helps me solidify ephemeral thoughts. Publishing offers an opportunity for feedback. But I made two errors that locked me into a pattern of fear. First, I promised a follow up article at the end of my last post about the Blazor stack. I then felt worse every time I published an article other than the promised follow-up. Second, I began to see value in the amount of traffic a blog post got. The posts about my first steps in that learning journey were the winners. Admitting I changed tack when the company did felt like admitting defeat.&lt;/p&gt;
    &lt;head rend="h3"&gt;I Want to Write More Ruby&lt;/head&gt;
    &lt;p&gt;I love Ruby. I use it in my code examples. It‚Äôs my default language for open source projects. I write Ruby for code katas, etudes, and hackathons. But I haven‚Äôt been paid to write Ruby since 2013.&lt;/p&gt;
    &lt;p&gt;The best possible option‚Äìand yet the most improbable‚Äìwould be for my current employer to start a Ruby project. I‚Äôve worked with a few of my teammates for 12 years across two companies. I‚Äôve always chosen to keep working with fantastic people at the cost of working with a less-than-fantastic language.&lt;/p&gt;
    &lt;p&gt;Sadly that means I‚Äôm limited to being a Rubyist after work and on weekends. I spend fewer of those hours than I‚Äôd like writing Ruby, instead favoring other obligations, hobbies, and professional development goals. The only way I foresee getting to work with Ruby as much as I‚Äôd like would be to paid for it.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;My manager and his manager, the CTO, read this blog. I found it difficult to write freely about my distaste for the tools I use every day. I found it ever harder to admit that I actively want my daily job duties to be different. I feared they might take it as a hint that I‚Äôm quitting (I‚Äôm not), or that I‚Äôd push to use a tool at work nobody else is familiar with at work (I won‚Äôt).&lt;lb/&gt;A bonus, even more personal confession‚Ä¶&lt;/p&gt;
    &lt;head&gt;A bonus, even more personal confession‚Ä¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Cyber Bullying Hurts, Even as an Adult&lt;/head&gt;
    &lt;p&gt;I spent a lot of my young adulthood online. My early days on the internet were spent in intellectual spaces, where the interactions felt like The Nets of Ender‚Äôs Game: a marketplace of ideas. Strong criticism came swiftly, but it was about the ideas, not the person. Even Reddit and Hacker News‚Äìforums which have a reputation for harsh comments sections‚Äìdon‚Äôt bother me, because the vitriol is aimed at taking down bad ideas, not insulting people.&lt;/p&gt;
    &lt;p&gt;Other websites, though, are different. I learned this when I got bullied on a different online forum. I was called incapable, sneaky, disgusting, incompetent, uncaring, and a representative of a threat to human expression.&lt;/p&gt;
    &lt;p&gt;What triggered this vitriol? I requested a small feature in an open source project, and the maintainer said they would accept a PR. The project was written in a language I haven‚Äôt used. I used an LLM to generate a small commit (a few dozen lines), reviewed and tested the patch, and submitted a pull request. This was months ago‚Äìthere were few social norms around AI-assisted patches, and AI policies were rare. Since the project didn‚Äôt have a policy, I did not disclose my use of AI.&lt;/p&gt;
    &lt;p&gt;When I told the story of that pull request on the forum and defended my ethical position, the bullying started. I was followed across websites, contacted via email and SMS, and even called on the phone. I no longer felt safe having a presence on that website. I deleted my comments, removed PII from my profile, and asked the administrators of the forum to scrub my real name to prevent further harassment. Instead, they attached more PII to my profile, locked me out of editing it, and permanently vandalized it with the false claim that I lied about being contacted about the discussion outside the forum.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;This incident was one of the most toxic things I‚Äôve ever experienced, and it lasted for days. Writing about it leaves me feeling its echoes even now. I was afraid that one of these people will use the comments section, or email, or even my phone number, to re-litigate the issue. Even now, I am afraid that the administrator‚Äôs (possibly defamatory) statement on my profile will make me less employable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Workplace Confessions&lt;/head&gt;
    &lt;head rend="h3"&gt;Your SaaS Team Doesn‚Äôt Need a Special Process&lt;/head&gt;
    &lt;p&gt;Hundreds of companies, thousands of researchers, tens of thousands of workers, and millions of dollars have gone into shaping our industry‚Äôs best practices. The agile manifesto is old enough to drink. Software as a Service has dominated the market for over a decade. Your company has a limited innovation budget. Do you want to spend it on coming up with a custom software development lifecycle, or making a product that wins in the marketplace? Follow Scrum, Lean / Kanban, or eXtreme Programming to the letter, and let your team focus on the product.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;Like any author, I write what I know. Here, I was motivated to write because a co-worker pushed to create a custom software development process. I don‚Äôt know that I have the tact to avoid it seeming to be a takedown of that person or their ideas. I admire the ability of authors like Kent Beck and Martin Fowler to write about how to work better without calling out coworkers who made mistakes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Remote Work Sucks&lt;/head&gt;
    &lt;p&gt;Remote work eliminates a lot of problems with office work: commutes, inefficient use of real estate, and land value distortion. But software development is better when you breathe the same air as the folks you work with. Even with a camera-on policy, video calls are a low-bandwidth medium. You lose ambient awareness of coworkers‚Äô problems, and asking for help is a bigger burden. Pair programming is less fruitful. Attempts to represent ideas spatially get mutilated by online whiteboard and sticky note software. Even conflict gets worse: it‚Äôs easy to form an enemy image of somebody at the end of video call, but difficult to keep that image when you share a room with them and sense their pain.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why I Was Afraid to Admit It&lt;/head&gt;
    &lt;p&gt;When COVID-19 hit, the company I worked for went remote ‚Äúfor a couple of weeks.‚Äù After a few months of productive work without an office and with no vaccine in sight, it became permanent. I took the opportunity to move to a rural area. Geographic arbitrage meant I could afford 27 acres, and I even bought a family milking cow. My family has since put down roots: close friendships, community involvement, and a lifestyle built around the lack of a commute.&lt;/p&gt;
    &lt;p&gt;I feared that writing negatively about remote work might jeopardize my current remote job‚Äìand every future remote job I might look for. I thought, ‚Äúwho would hire a remote worker who prefers in-office work?‚Äù Because even though I prefer working side-by-side with others, I won‚Äôt likely move for a job. I have a 30-year mortgage with a low interest rate. My house was purchased before the post-pandemic price spike. I have an acre of lawn &amp;amp; garden, not to mention the farm acreage. I‚Äôd need to double my current income to maintain my current lifestyle in a city, which is unlikely.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Now?&lt;/head&gt;
    &lt;p&gt;Now that the dam has burst, nothing is holding me back from publishing. I‚Äôm going to continue to work on skill building, but now I feel free to write about it. If this article resonated with you‚Äìwhether you also have knowledge gaps you‚Äôd like to fill, you‚Äôd like to help me fill mine, or you just want to see what happens‚Äìplease let me know in the comments. Subscribe via Mastodon to see everything I post, use RSS to customize your subscription, or subscribe to my mailing list to get notified when I post a larger article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mastodon &amp;amp; Fediverse&lt;/head&gt;
    &lt;p&gt;To help you follow along, I‚Äôve enabled ActivityPub on this blog, meaning it‚Äôs a fully-functioning Mastodon account: &lt;code&gt;@[email¬†protected]&lt;/code&gt;. &lt;/p&gt;
    &lt;head rend="h3"&gt;RSS &amp;amp; Feed Readers&lt;/head&gt;
    &lt;p&gt;If you prefer to kick it old school, grab an XML feed reader like NetNewsWire for MacOS, Feedmill for Windows, or Newsflash for Linux and choose one or more feeds:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The ‚ÄúEverything‚Äù feed &lt;list rend="ul"&gt;&lt;item&gt;Just the ‚ÄúArticles‚Äù feed &lt;list rend="ul"&gt;&lt;item&gt;Specifically the ‚ÄúAdvice‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúBlog Posts‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúBook Reviews‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúNews‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúTutorials‚Äù feed&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Just the ‚ÄúMicro-Posts‚Äù feed &lt;list rend="ul"&gt;&lt;item&gt;Specifically the ‚ÄúResponses‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúQuick Tips‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúShared Links‚Äù feed&lt;/item&gt;&lt;item&gt;Specifically the ‚ÄúTutorials‚Äù feed&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Just the ‚ÄúArticles‚Äù feed &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Email Newsletter&lt;/head&gt;
    &lt;p&gt;Of course, the classic (and my favorite) way is to subscribe to email notifications. I‚Äôll only send emails when I publish a new article, not for every micro-post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46083303</guid><pubDate>Fri, 28 Nov 2025 22:21:25 +0000</pubDate></item><item><title>A triangle whose interior angles sum to zero</title><link>https://www.johndcook.com/blog/2025/11/28/tricusp-triangle/</link><description>&lt;doc fingerprint="eb9b90f084dff3a0"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Spherical geometry&lt;/head&gt;
    &lt;p&gt;In spherical geometry, the interior angles of a triangle add up to more than œÄ. And in fact you can determine the area of a spherical triangle by how much the angle sum exceeds œÄ. On a sphere of radius 1, the area equals the triangle excess&lt;/p&gt;
    &lt;p&gt;Area = E = interior angle sum ‚àí œÄ.&lt;/p&gt;
    &lt;p&gt;Small triangles have interior angle sum near œÄ. But you could, for example, have a triangle with three right angles: put a vertex on the north pole and two vertices on the equator 90¬∞ longitude apart.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hyperbolic geometry&lt;/head&gt;
    &lt;p&gt;In hyperbolic geometry, the sum of the interior angles of a triangle is always less than œÄ. In a space with curvature ‚àí1, the area equals the triangle defect, the difference between œÄ and the angle sum.&lt;/p&gt;
    &lt;p&gt;Area = D = œÄ ‚àí interior angle sum.&lt;/p&gt;
    &lt;p&gt;Again small triangles have an interior angle sum near œÄ. Both spherical and hyperbolic geometry are locally Euclidean.&lt;/p&gt;
    &lt;p&gt;The interior angle sum can be any value less than œÄ, and so as the angle sum goes to 0, the triangle defect, and hence the area, goes to œÄ. Since the minimum angle sum is 0, the maximum area of a triangle is œÄ.&lt;/p&gt;
    &lt;p&gt;The figure below has interior angle sum 0 and area œÄ in hyperbolic geometry.&lt;/p&gt;
    &lt;p&gt;Strictly speaking this is an improper triangle because the three hyperbolic lines (i.e. half circles) don‚Äôt intersect within the hyperbolic plane per se but at ideal points on the real axis. But you could come as close to this triangle as you like, staying within the hyperbolic plane.&lt;/p&gt;
    &lt;p&gt;Note that the radii of the (Euclidean) half circles doesn‚Äôt change the area. Any three semicircles that intersect on the real line as above make a triangle with the same area. Note also that the triangle has infinite perimeter but finite area.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46084122</guid><pubDate>Sat, 29 Nov 2025 00:26:42 +0000</pubDate></item><item><title>Every mathematician has only a few tricks (2020)</title><link>https://mathoverflow.net/questions/363119/every-mathematician-has-only-a-few-tricks</link><description>&lt;doc fingerprint="3758f87a661d0767"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;From a physicist point of view I want to mention this trick and its generalization for operators:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;      "Two commuting matrices are simultaneously diagonalizable"
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;(for physicists all matrices are diagonalizable). Of course the idea is that if you know the eigenvectors of one matrix/operator then diagonalizing the other one is much easier. Here are some applications.&lt;/p&gt;
      &lt;p&gt;1)The system is translation invariant : Because the eigenvectors of the translation operator are $e^{ik.x}$, then one should use the Fourier transform. It solves all the wave equations for light, acoustics, of free quantum electrons or the heat equation in homogeneous media.&lt;/p&gt;
      &lt;p&gt;2)The system has a discrete translation symmetry: The typical system is the atoms in a solid state that form a crystal. We have a discrete translation operator $T_a\phi(x)=\phi(x+a)$ with $a$ the size of the lattice and then we should try $\phi_k(x+a)=e^{ik.a}\phi_k(x)$ as it is an eigenvector of $T_a$. This gives the Bloch-Floquet theory where the spectrum is divided into band structure. It is one of the most famous model of condensed matter as it explains the different between conductors or insulators.&lt;/p&gt;
      &lt;p&gt;3)The system is rotational invariant: One should then use and diagonalize the rotation operator first. This will allow us to find the eigenvalue/eigenvectors of the Hydrogen atom. By the way we notice the eigenspace of the Hydrogen are stable by rotation and are therefore finite dimension representations of $SO(3)$. The irreducible representations of $SO(3)$ have dimension 1,3,5,... and they appears, considering also the spin of the electron, as the columns of the periodic table of the elements (2,6,10,14,...).&lt;/p&gt;
      &lt;p&gt;4)$SU(3)$ symmetry: Particle physics is extremely complicated. However physicists have discovered that there is an underlying $SU(3)$ symmetry. Then considering the representations of $SU(3)$ the zoology of particles seems much more organized (A, B).&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46084535</guid><pubDate>Sat, 29 Nov 2025 01:37:42 +0000</pubDate></item><item><title>System 7 natively boots on the Mac mini G4</title><link>https://macos9lives.com/smforum/index.php?topic=7711.0</link><description>&lt;doc fingerprint="b63c99572fc08fad"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;(And Mac OS 8!)&lt;/p&gt;&lt;p&gt;Hey, guys!&lt;/p&gt;&lt;p&gt;Surely y'all know and have enjoyed Mac OS 9.2.2 booting and beautifully-running on all four Mac mini G4 models for close to 8 years now. (Wow!)&lt;/p&gt;&lt;p&gt;Well, that was one massive revolution...&lt;/p&gt;&lt;p&gt;... But most of us did not think we would live to see the day New World ROM machines, even more so the likes of the Mac mini G4, to NATIVELY boot System 7:&lt;/p&gt;&lt;p&gt;(Gotta love it trying to display 1 GB RAM capacity.)&lt;/p&gt;&lt;p&gt;Before your eyeballs leave your eyesockets completely, I ought to warn that there's still much to be sorted out in this, especially sound, video and networking (the usual suspects). In other words, your mileage may vary, so keep expectations in check!&lt;/p&gt;========================================================&lt;lb/&gt;OK, so HOW in the WORLD is any of this possible?&lt;lb/&gt;========================================================&lt;p&gt;It turned out "New World ROM" Macs had a cousin born out of the clone program (until the usual villain, Steve Jobs, came and killed it), which was an architecture called "&lt;/p&gt;CHRP&lt;p&gt;" (pronounced "chirp"). It was the successor to &lt;/p&gt;PReP&lt;p&gt;, but, unlike PReP, Mac OS was also going to be officially-bootable on it. Close to no CHRP machines ever saw the light of the day, thanks to Jobs' return. Nonetheless, Apple internally developed Mac OS 7.6 ~ 8.0 for CHRP systems before it got axed. It's just that they never released it, but the development was done regardless. On October 2025, it turned out someone preserved some of these Mac versions, which were then acquired and preserved and shared with the world. (&lt;/p&gt;Macintosh Garden link&lt;p&gt;, &lt;/p&gt;archive.org link&lt;p&gt;.)&lt;/p&gt;&lt;p&gt;Although CHRP was left to die, the so-called "New World ROM" Macs inherited much of its architecture and design. As you probably know, these Macs rely on an extra system file called "Mac OS ROM", whereas "Old World ROM" Macs do not need it, and can use their own actual ROM to get Mac OS going. This meant any Mac OS version unaware of the concept of a Mac OS ROM file could not just simply boot in a New World ROM Mac normally. People were able to boot Mac OS versions as low as 8.1, but not any lower, and that too only for the very first few New World ROM Macs, but none of the later ones, which increasingly had a higher and higher minimum OS version.&lt;/p&gt;&lt;p&gt;But not anymore, as the following major events happened:&lt;/p&gt;&lt;p&gt;- The recent Mac OS 8.0 CHRP leaks provided an earlier ROM file that, it turns out, allows regular Mac OS 8.0 to boot, as well. Or, alternatively, the Mac OS ROM file that always worked with Mac OS 8.1 also worked on these Mac OS 8.0 CHRP releases. (Exact details are fuzzy in my memory by now, so someone else might want to correct me if I got something wrong.)&lt;/p&gt;&lt;p&gt;- The recent Mac OS 7.6 CHRP leak provided an additional System Enabler file, which could be exploited for loading Mac OS ROM files. I forget if that's how it worked out-of-the-box, or if a bit of hacking to the System Enabler was required for that, however what I do remember clearly is that, while the System Enabler was hardcoded so that artifically no OS earlier than 7.6 could use it, the OS version check could be patched out of it, so that System 7.5.x (and potentially earlier) can also use it.&lt;/p&gt;&lt;p&gt;In other words, &lt;/p&gt;this file is the reason that earlier Mac OS versions can make use of the Mac OS ROM file&lt;p&gt;, thus bringing Mac OS 7.6.1 and earlier potentially to ALL New World ROM Macs!&lt;/p&gt;&lt;p&gt;(Trivia tidbit: Apparently this enabler was also present in certain archives of the Mac OS 8.0 betas from when it was still known as "Mac OS 7.7". Oops! This thing was right under our nose all this while!)&lt;/p&gt;&lt;p&gt;- Of course, as hinted at previously, a System Enabler _alone_ is NOT enough to boot System 7 and the like when even much newer systems that were already aware of the Mac OS ROM file could not boot. The newer the model of the New World ROM Mac, the less you could actually "go back". The reason is simple: Mac OS ROM files, over time through its various versions, would get new features added, BUT also would remove older ones which were required by older OS versions. The solution? Using &lt;/p&gt;ELN's great Mac OS ROM patching tools&lt;p&gt; (plus other tools of his own), "Rairii" AKA "Wack0", known for his amazing PPC Windows NT 3.51 / NT 4.0 project on &lt;/p&gt;PowerMacs&lt;p&gt; and the &lt;/p&gt;Nintendo GC / Wii / Wii U&lt;p&gt;, analyzed many of these Mac OS ROM files, and fixed + patched + stitched together new Mac OS ROM files that attempt to keep ALL the old features that were removed AND all the new features that were added. In other words, the ultimate Mac OS ROM file that boots everything and runs everything (roughly-speaking). He also is the one who figured out and hacked the System Enabler to also accept OSes earlier than Mac OS 7.6.&lt;/p&gt;&lt;p&gt;Keep in mind, however, that this effort essentially allows Macs that are already able to boot SOME version of Mac OS to ALSO boot older versions. But if a given machine cannot boot ANY Mac OS version, such as the two DLSD PowerBook G4s (&lt;/p&gt;15"&lt;p&gt;, &lt;/p&gt;17"&lt;p&gt;), these patches cannot do anything about that: Their incompatibilities need to be addressed first and separately.&lt;/p&gt;&lt;p&gt;One more interesting thing to note about the similarity between CHRP systems and New World ROM Macs: If you check ANY "Mac OS ROM" file to see its TYPE and CREATOR codes, you will see they are "tbxi" and, you guessed it, "&lt;/p&gt;chrp&lt;p&gt;", respectively. I couldn't believe "chrp" was in ALL the Mac OS ROM files all these years!&lt;/p&gt;========================================================&lt;lb/&gt;Where can I get ahold of this EPIC stuff ? ? ? ? ?&lt;lb/&gt;========================================================&lt;p&gt;Rairii's "super" ROMs are available on &lt;/p&gt;this GitHub repository&lt;p&gt;, under &lt;/p&gt;releases&lt;p&gt;. You may also fetch the patched System Enabler for Mac OS 7.6.1 and earlier from there, and place it in the System Folder. Make sure to download the files from the latest release there.&lt;/p&gt;&lt;p&gt;Note that he applied his patches to 3 different versions of the (US) ROMs:&lt;/p&gt;&lt;p&gt;- 10.2.1 with CPU Software 5.9: The "latest and greatest" Mac OS ROM file of all Mac OS. For reference, this is also the ROM version that the &lt;/p&gt;1.628 GB max RAM Mac OS ROM we have was based on (thus going beyond the 1.5 GB limit)&lt;p&gt;, although do note that the RAM limit break patches are NOT included in this, at least not yet as of the time of writing.&lt;/p&gt;&lt;p&gt;- 2.5.1: A much earlier version of the ROM, but still new enough to support USB. See the GitHub page for details.&lt;/p&gt;&lt;p&gt;- 1.7.1: A very early ROM, which can be well-leveraged by very early New World ROM Macs. See the GitHub page for details.&lt;/p&gt;&lt;p&gt;Note you need ROM version 9.1 or higher to use ATA-6 AKA Ultra ATA/100 AKA Kauai drivers, which are essential on the likes of the Mac mini G4 and the MDD. Special notes for the Mac mini G4 are further down.&lt;/p&gt;========================================================&lt;lb/&gt;What is the COMPLETE list of Mac OS versions that now boot?&lt;lb/&gt;========================================================&lt;p&gt;To be exact, this is the complete list of OSes I have attempted, all on the Mac mini G4 1.5GHz model, with the following results:&lt;/p&gt;&lt;p&gt;- System 6.0.8: &lt;/p&gt;No boot&lt;p&gt;. You get a Happy Mac, followed by a blinking question mark in a floppy icon. (Note: Although this very attempt is UTTERLY insane for multiple technical reasons, it might be not AS seemingly-impossible as one may think, as the 68k emulator resides within the Mac OS ROM file.)&lt;/p&gt;&lt;p&gt;- System 7.0: &lt;/p&gt;No boot&lt;p&gt;. You get a Happy Mac, but then a warning window pops up saying System 7.0 cannot boot on this computer.&lt;/p&gt;&lt;p&gt;- System 7.1.2: &lt;/p&gt;No boot&lt;p&gt;. You get a Happy Mac, but then a warning window pops up saying System 7.1 cannot boot on this computer.&lt;/p&gt;&lt;p&gt;- System 7.5: &lt;/p&gt;BOOTS AND IS STABLE&lt;p&gt;. It requires you to hold shift to turn Extensions (and Control Panels / INITs) off, though, or to get rid of the "Mouse" Control Panel (and possibly more). The system is surprisingly stable! I tested the British version of this one, as Apple's Mac OS Anthology discs did not include the US installers, for some very slacker-y reason.&lt;/p&gt;&lt;p&gt;- System 7.5.2: &lt;/p&gt;Boots, but very broken, close to nothing works&lt;p&gt;. It could be because System 7.5.2 was always VERY machine-specific, and is apparently one of the most broken versions of Mac OS of ALL time, regardless. The machine-specific enablers, and other things, might be what is making it so unstable.&lt;/p&gt;&lt;p&gt;- System 7.5.3: &lt;/p&gt;BOOTS AND IS STABLE&lt;p&gt;. It requires you to hold shift to turn Extensions (and Control Panels / INITs) off, though, or to get rid of the "Mouse" Control Panel (and possibly more). The system is surprisingly stable!&lt;/p&gt;&lt;p&gt;- Mac OS 7.6: &lt;/p&gt;BOOTS AND IS STABLE&lt;p&gt;. Holding shift is not required here. What else can I say? It "works".&lt;/p&gt;&lt;p&gt;- Mac OS 8.1: &lt;/p&gt;BOOTS AND IS STABLE&lt;p&gt;. Holding shift is not required here, either. Behaves much the same as the others, except we now have HFS+ by default. Still, it did NOT like me having a 940 GB HFS+ partition, and prompted me to either eject it or format it. (To be fair, older OSes tried to do that, too, but Mac OS 8.1 was THE OS to _officially_ be able to handle HFS+ properly, so there are no excuses for it to fail here. Mac OS 9.2 ~ 9.2.2 all work perfectly with it.)&lt;/p&gt;&lt;p&gt;- Mac OS 8.5: No boot. Rather, it seems like it WOULD boot, but starting with Mac OS 8.5, Mac OS now always checks to see if the machine you are booting from is within a list of Apple-endorsed machine IDs for the given Mac OS version. In other words, Mac OS 8.5 does not know what the Mac mini G4 is, nor what a G4 Cube is (our Mac mini G4 ROM file makes the mini pretend to be the latter). It seems it should be possible to patch out the machine check. According to Rairii, this should be able to be patched out by disabling such a check on the "boot" resource in the Resource Fork of the System file, in ID 3 (also known as "boot3"). For Mac OS 8.6, it seems like this check happens at the end of boot3, wherever a check for machine ID 406 is located, in which after it's detected, the code checks to see if the exact Mac model is whitelisted or not.&lt;/p&gt;&lt;p&gt;- Mac OS 8.5.1: &lt;/p&gt;No boot&lt;p&gt;. All that applies to Mac OS 8.5 also applies to Mac OS 8.5.1.&lt;/p&gt;&lt;p&gt;- Mac OS 8.6: &lt;/p&gt;No boot&lt;p&gt;. It crashes during the start screen, when the loading bar appears, but before the first extension gets to load. See the top-left corner of the picture for a glitchy visual artifact. Same happens if you try to boot with Extensions off.&lt;/p&gt;&lt;p&gt;- Mac OS 9.0.4: No boot. It crashes during the start screen, when the loading bar appears, but before the first extension gets to load. Same happens if you try to boot with Extensions off. Exact same symptoms as when trying to boot Mac OS 8.6 at least on this mini model, including the visual artifact on the top-left corner.&lt;/p&gt;&lt;p&gt;- Mac OS 9.1: &lt;/p&gt;No boot&lt;p&gt;. It crashes during the start screen, when the loading bar appears, but before the first extension gets to load. Same happens if you try to boot with Extensions off. Exact same symptoms as when trying to boot Mac OS 8.6 and Mac OS 9.0.4 at least on this mini model, including the visual artifact on the top-left corner.&lt;/p&gt;&lt;p&gt;- Mac OS 9.2 ~ 9.2.2: BEST OS EVER, BOOTS AND RUNS BEAUTIFULLY. 'Nuff said.&lt;/p&gt;&lt;p&gt;Note that, although I describe many of these as "stable", I mean you can use much of it normally (sound/video/networking aside) without it crashing or misbehaving, at least not too hard, but that is not to say everything works, because that is just not the case. For example, when present, avoid opening the Apple System Profiler, unless you want a massive crash as it struggles trying to profile and gather all the information about your system. Some other apps or Control Panels might either not work, or work up to a certain point, after which they might freeze, requiring you to Force Quit the Finder to keep on going. And so on.&lt;/p&gt;&lt;p&gt;As you can see, I did not yet try System 7.5.5, Mac OS 7.6.1 and Mac OS 8.0. That's because they all are most likely working exactly as their neighbouring versions. But feel free to confirm.&lt;/p&gt;&lt;p&gt;Most non-mini systems should be able to boot Mac OS 8.6 ~ Mac OS 9.1 just fine. A "Mac OS 8.6 Enabler", so to speak, by LightBulbFun, can be renamed as e.g. "Sawteeth" and put inside the System Folder for some machines that cannot boot Mac OS 8.6 normally, so that they can, then, boot it. It is actually a Mac OS ROM file, but can function as a complementary, helper file to aid the actual Mac OS ROM file in this case. If you'd like, check &lt;/p&gt;here&lt;p&gt; for more info. I have attached "Sawteeth.bin" to this post for convenience. LightBulbFun first shared it on &lt;/p&gt;this post&lt;p&gt;, specifically through this &lt;/p&gt;MEGA link&lt;p&gt;.&lt;/p&gt;&lt;p&gt;Most non-mini systems should also be able to boot Mac OS 8.5 and 8.5.1, especially on G3s and earlier. Some G4 Macs might need to spoof the Mac model in Open Firmware (or some other Forth script added to ROM) to boot, though, or patch the check out like I mentioned for the mini earlier. The reason the mini doesn't have the spoofing as an option is that any spoofing in OF would be overwritten by its own specialized Mac OS ROM, which spoofs a G4 Cube, which is clearly not in the whitelist of supported machines for Mac OS 8.5 and 8.5.1.&lt;/p&gt;&lt;p&gt;Also note that the mini behaves as reported above with Mac OS 8.6 with or without this "8.6 enabler" file (and with or without the System Enabler for Mac OS 7.6.1 and earlier, both of which don't seem to get in the way of later, nor earlier, OSes).&lt;/p&gt;&lt;p&gt;Most importantly, I did &lt;/p&gt;not&lt;p&gt; yet attempt to identify which are the latest versions of each Control Panel and Extension for each of these OSes. If I did, I'm sure it would help a lot, and perhaps address quite a number of these problems. The more people chime in on this effort, the better! Imagine if we had a proper "Mac mini G4 System 7.5.5" CD, then an "MDD Mac OS 8.5.1" CD, then an "iBook G3 Mac OS 7.6.1" CD, and so on. Everyone with a G3 or G4 Mac can help by trying things out!&lt;/p&gt;&lt;p&gt;Namely, something akin to MacTron's efforts highlighting the latest Extensions for Mac OS 9.2.2 and Mac OS 8.6 like this, but also for every other Mac OS version:&lt;/p&gt;========================================================&lt;lb/&gt;But how did you get the mini to boot? It requires its own special ROM!&lt;lb/&gt;========================================================&lt;p&gt;Indeed it does! All credit goes to ELN and all of those who helped him on Mac OS 9 Lives!: you can simply use his tooling (which was also very useful for Rairii) to re-apply the Mac-mini-G4-specific ROM patches to Rairii's latest 10.2.1 ROM, and voila! It works as well as you would hope it to! &lt;/p&gt;&lt;p&gt;You can even use the resulting ROM for Mac OS 9.2.2, as well, even though you don't have to: Originally, the Mac mini G4 ROM as we see them in RossDarker's Mac mini G4 CDs version 8 and 9 (AKA v8 and v9), as well as in all the previous versions, were based on the US ROM v9.6.1. I could not find an explanation as to why ROM v10.2.1 wasn't used in the end, even when digging the old Mac mini G4 thread again that started it all. Perhaps because we already had a working ROM with v9.6.1 and did not want to risk breaking anything, or who knows. However, I have thoroughly tested Mac OS 9.2.2 with this new ROM combination (latest Rairii 10.2.1 + latest Mac mini G4 patches AKA v9 patches), and from what I could tell, everything behaves &lt;/p&gt;exactly&lt;p&gt; the same as with the previous ROM we always used. Except now we have the ability to use the same ROM to also boot System 7.5 (I still can't believe this, even though it is true).&lt;/p&gt;&lt;p&gt;(For the record, while the 9.6.1 ROM was also modified to spoof the Mac mini G4 model identifier as a G4 Cube, we also tried to spoof it as a QuickSilver 2002 at one point, but someone reported sound issues with that, and so it was quickly changed back to a G4 Cube and such a change never made it into one of RossDarker's CDs. So just about everyone using Mac OS on the mini for all these years has had a ROM reporting to the OS as a G4 Cube, exclusively.)&lt;/p&gt;&lt;p&gt;To apply the Mac mini G4 patches, I used ELN's &lt;/p&gt;tbxi&lt;p&gt; and &lt;/p&gt;tbxi-patches&lt;p&gt; to apply his "macmini.py" script. You can follow the instructions as per the tbxi-patches page, which you should not let intimidate you even if you are not used to this kind of thing. It's quick and easy, and the scripts are also fully-commentated very nicely by ELN if you are curious about what it is doing and why.&lt;/p&gt;&lt;p&gt;In my case, first I tried using the latest Python 3.13.9 both from Windows 7 (bad idea due to resource fork loss) and macOS 10.14.6 Mojave, but neither worked: it seems like that version of Python was just too new. I then retried with &lt;/p&gt;Python 3.8.10&lt;p&gt; instead (which I chose thinking it might be more period-appropriate for the script's age) on Mojave, which worked &lt;/p&gt;flawlessly&lt;p&gt;. I didn't try it, but perhaps an older Python version might work on PowerPC OS X, as well.&lt;/p&gt;&lt;p&gt;I used the Python installer &lt;/p&gt;from the official website&lt;p&gt;, and I also used an "official" Git installer from &lt;/p&gt;here&lt;p&gt; (thus avoiding any package manager headache... man, how I hate non-Mac-OS systems, including OS X, and package managers in general...)&lt;/p&gt;&lt;p&gt;If somehow someone with plenty of Python knowledge and the willingness to put enough time into it wished to, both tbxi and tbxi-tools could, perhaps, be ported to &lt;/p&gt;MacPython 2.3.5&lt;p&gt;, so that we could do all this patching from Mac OS 9.2.2 directly and natively without leaving our main OS. That would also be awesome! (Of course, it helps that this is also available on more recent systems nonetheless, because then everyone gets to join in on the fun with all kinds of different backgrounds and setups.)&lt;/p&gt;&lt;p&gt;For convenience, I attached the final patched ROM to this post, so that anyone can go wild on their minis right away!&lt;/p&gt;========================================================&lt;lb/&gt;Why should I care when Mac OS 9.2.2 already boots, and runs better?&lt;lb/&gt;========================================================&lt;p&gt;It is also my opinion Mac OS 9.2.2 is the greatest OS, and Mac OS, ever, but not everything that is possible in earlier Mac OS versions is possible in Mac OS 9.2.2. For example, some software requires Mac OS 9.0.4 or earlier to work. A lot of software is System-7-exclusive.&lt;/p&gt;&lt;p&gt;Some people also just prefer the likes of System 7 for its even-lighter memory footprint, lack of mandated Appearance Manager and the like. Mac OS 9.2.2 is already overkill-fast on the mini, and on most New World ROM Macs, but the likes of System 7.5 are just RIDICULOUSLY fast. Even more ridiculously. I still am trying to come into terms with how indescribably fast using it on the mini was. It got even faster when I thought there was no way to get "faster than instantaneous", as Mac OS 9.2.2 always felt instantaneous like no other system already!&lt;/p&gt;&lt;p&gt;People might also have some other kind of reason and/or special attachment to an earlier OS version. Or maybe people want to explore older OS APIs and behaviors, perhaps even make a new application they want to know how it will behave on bare-metal not just on Mac OS 9, but also System 7 etc..&lt;/p&gt;&lt;p&gt;The value is in opening up the doors that give us, the users, more options that help us all out. &lt;/p&gt;========================================================&lt;lb/&gt;Final remarks&lt;lb/&gt;========================================================&lt;p&gt;Above all, thank you to everyone that made this possible. But I wanted to emphasize and give special thanks to Rairii for engineering all these ROMs, Mac84 for archiving and sharing all the CHRP discs, ELN for engineering all the Mac mini G4 ROM compatibility scripts and creating all the ROM and other Mac OS tooling, and to the Mac community at large everywhere that assisted in all of this into becoming reality. There's honestly many, many people to thank we owe over this one way or another, both in small and big ways.&lt;/p&gt;&lt;p&gt;I can't wait to see what people will do with all these new Mac OS versions on their New World ROM systems over the course of time!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46084956</guid><pubDate>Sat, 29 Nov 2025 03:26:01 +0000</pubDate></item><item><title>Garfield's Proof of the Pythagorean Theorem</title><link>https://en.wikipedia.org/wiki/Garfield%27s_proof_of_the_Pythagorean_theorem</link><description>&lt;doc fingerprint="cf79536f86bd73e1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Garfield's proof of the Pythagorean theorem&lt;/head&gt;&lt;p&gt;Garfield's proof of the Pythagorean theorem is an original proof of the Pythagorean theorem discovered by James A. Garfield (November 19, 1831 ‚Äì September 19, 1881), the 20th president of the United States. The proof appeared in print in the New-England Journal of Education (Vol. 3, No.14, April 1, 1876).[1][2] At the time of the publication of the proof Garfield was a congressman from Ohio. He assumed the office of President on March 4, 1881, and served in that position until his death on September 19, 1881, having succumbed to injuries sustained when he was shot in an assassination in July.[3] Garfield is thus far the only President of the United States to have contributed anything original to mathematics. The proof is nontrivial and, according to the historian of mathematics William Dunham, "Garfield's is really a very clever proof."[4] The proof appears as the 231st proof in The Pythagorean Proposition, a compendium of 370 different proofs of the Pythagorean theorem.[5]&lt;/p&gt;&lt;head rend="h2"&gt;The proof&lt;/head&gt;[edit]&lt;p&gt;In the figure, is a right-angled triangle with right angle at . The side-lengths of the triangle are . Pythagorean theorem asserts that .&lt;/p&gt;&lt;p&gt;To prove the theorem, Garfield drew a line through perpendicular to and on this line chose a point such that . Then, from he dropped a perpendicular upon the extended line . From the figure, one can easily see that the triangles and are congruent. Since and are both perpendicular to , they are parallel and so the quadrilateral is a trapezoid. The theorem is proved by computing the area of this trapezoid in two different ways.&lt;/p&gt;&lt;list rend="dl"&gt;&lt;item rend="dd-1"&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;From these one gets&lt;/p&gt;&lt;p&gt;which on simplification yields&lt;/p&gt;&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ G., J. A. (1876). "PONS ASINORUM". New England Journal of Education. 3 (14): 161. ISSN 2578-4145. JSTOR 44764657.&lt;/item&gt;&lt;item&gt;^ Kolpas, Sid J. "Mathematical Treasure: James A. Garfield's Proof of the Pythagorean Theorem". maa.org. Mathematical Association of America. Archived from the original on 8 December 2023. Retrieved 29 November 2023. (The article appeared in the peer-reviewed online journal Convergence published by the Mathematical Association of America.)&lt;/item&gt;&lt;item&gt;^ Del Arte, Alonso (February 2019). "A future president once published a mathematical proof". medium.com. Retrieved 29 November 2023.&lt;/item&gt;&lt;item&gt;^ Dunham, William (1994). The Mathematical Universe: An Alphabetical Journey Through the Great Proofs, Problems, and Personalities. New York: John Wiley &amp;amp; Sons. p. 99. ISBN 0-471-53656-3.&lt;/item&gt;&lt;item&gt;^ Loomis, Elisha Scott (1940). The Pythagorean Proposition (2 ed.). Washington DC: National Council of Teachers of Mathematics. p. 109. ISBN 978-0-87353-036-1. Retrieved 28 November 2023. &lt;code&gt;{{cite book}}&lt;/code&gt;: ISBN / Date incompatibility (help) (A collection of 370 different proofs of the Pythagorean theorem.)&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46085585</guid><pubDate>Sat, 29 Nov 2025 06:37:05 +0000</pubDate></item><item><title>High air pollution could diminish exercise benefits by half ‚Äì study</title><link>https://scienceclock.com/exercise-may-protect-less-when-air-pollution-is-high-study-finds/</link><description>&lt;doc fingerprint="765911926e874515"&gt;
  &lt;main&gt;
    &lt;p&gt;We all know exercise is good for us. It lowers the risk of heart disease, cancer, and early death, and keeps the body and mind in shape. But when the air you breathe is polluted, a new study suggests that exercise might not provide the same benefits it normally would.&lt;/p&gt;
    &lt;p&gt;An international team, including researchers from University College London (UCL) analyzed health data from over 1.5 million adults, collected over more than a decade in countries including the UK, Taiwan, China, Denmark, and the United States.&lt;/p&gt;
    &lt;p&gt;The researchers focused on levels of fine particulate matter, specifically tiny particles known as PM2.5. These fine particles are smaller than 2.5 micrometers; they can get stuck in the lungs and enter the bloodstream, where they can trigger inflammation and long-term damage.&lt;/p&gt;
    &lt;p&gt;Also Read: Humans Have Tilted the Earth 31.5 Inches Since 1993, Study Finds&lt;/p&gt;
    &lt;p&gt;Researchers found that adults who exercised at least two and a half hours a week‚Äîmoderate to vigorous activity like jogging or other sports‚Äîtypically had a 30% lower risk of dying during the study period than less active people. But in areas where the yearly average PM2.5 exceeded 25 Œºg/m¬≥, the protective effects of exercise dropped to just 12‚Äì15%.&lt;/p&gt;
    &lt;p&gt;The protective effects of exercise weaken even further in more polluted regions. At PM2.5 levels above 35 Œºg/m¬≥, where about a third (36%) of the global population lives, exercise offered even less protection, particularly against the risk of death from cancer.&lt;/p&gt;
    &lt;p&gt;‚ÄúOur findings emphasise that exercise remains beneficial even in polluted environments,‚Äù lead researcher Professor Po-Wen Ku said in a statement. ‚ÄúBut improving air quality can significantly enhance these health gains.‚Äù&lt;/p&gt;
    &lt;p&gt;Co-author Professor Andrew Steptoe said, ‚ÄúOur study shows that toxic air can, to some extent, block the benefits of exercise, although not eliminate them. The findings are further evidence of the damage that fine particle pollution can do to our health.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe believe clean air and physical activity are both important for healthy ageing, and so we encourage greater efforts to curb health-harming pollution levels.‚Äù&lt;/p&gt;
    &lt;p&gt;The study looked at the data from seven existing studies, including three previously unpublished datasets, combining both summary statistics and raw participant-level data. Researchers carefully accounted for a wide range of other factors, including income, education, smoking, and pre-existing chronic conditions.&lt;/p&gt;
    &lt;p&gt;Also Read: Men Need More Exercise Than Women to Lower the Heart Disease Risk&lt;/p&gt;
    &lt;p&gt;However, the team points out that their data mostly comes from high-income countries, so the impact could be greater in low-income regions, where PM2.5 levels often exceed 50 Œºg/m¬≥. They also mention the lack of indoor air quality data and limited information on participants‚Äô diets as part of the study‚Äôs caveats.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe don‚Äôt want to discourage people from exercising outdoors,‚Äù said Co-author Professor Paola Zaninotto. ‚ÄúChecking air quality, choosing cleaner routes, or easing off intensity on polluted days can help you get the most health benefits from your exercise.‚Äù&lt;/p&gt;
    &lt;p&gt;The study reminds us of one of the world‚Äôs most serious problems: air pollution. Staying active is not enough to protect your health if the air around you is toxic. Cleaner air and regular exercise go hand in hand, and tackling pollution is not just about the environment‚Äîit‚Äôs about our bodies too.&lt;/p&gt;
    &lt;p&gt;The study was published in BMC Medicine.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46086624</guid><pubDate>Sat, 29 Nov 2025 10:54:16 +0000</pubDate></item><item><title>Belgian Police exposed using botnets to manipulate EU data law impact assessment</title><link>https://old.reddit.com/r/europe/comments/1p9kxhm/belgian_federal_police_forgot_to_turn_their_vpn/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46086681</guid><pubDate>Sat, 29 Nov 2025 11:10:39 +0000</pubDate></item><item><title>Leak confirms OpenAI is preparing ads on ChatGPT for public roll out</title><link>https://www.bleepingcomputer.com/news/artificial-intelligence/leak-confirms-openai-is-preparing-ads-on-chatgpt-for-public-roll-out/</link><description>&lt;doc fingerprint="b903bf3a6fa58d7a"&gt;
  &lt;main&gt;
    &lt;p&gt;OpenAI is now internally testing 'ads' inside ChatGPT that could redefine the web economy.&lt;/p&gt;
    &lt;p&gt;Up until now, the ChatGPT experience has been completely free. While there are premium plans and models, you don't see GPT sell you products or show ads.&lt;/p&gt;
    &lt;p&gt;As spotted by Tibor on X, ChatGPT Android app 1.2025.329 beta includes new references to an "ads feature" with "bazaar content", "search ad" and "search ads carousel."&lt;/p&gt;
    &lt;p&gt;It is likely that ads will be limited to the search experience only, but that might change soon.&lt;/p&gt;
    &lt;p&gt;My understanding is that GPT ads could be highly personalised as the AI knows everything about you unless you disable the feature,&lt;/p&gt;
    &lt;p&gt;This is a developing story...&lt;/p&gt;
    &lt;head rend="h2"&gt;Secrets Security Cheat Sheet: From Sprawl to Control&lt;/head&gt;
    &lt;p&gt;Whether you're cleaning up old keys or setting guardrails for AI-generated code, this guide helps your team build securely from the start.&lt;/p&gt;
    &lt;p&gt;Get the cheat sheet and take the guesswork out of secrets management.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46086771</guid><pubDate>Sat, 29 Nov 2025 11:31:58 +0000</pubDate></item><item><title>DMT-induced shifts in criticality correlate with self-dissolution</title><link>https://www.jneurosci.org/content/early/2025/10/24/JNEUROSCI.0344-25.2025</link><description>&lt;doc fingerprint="63f4f321d1abddbf"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Psychedelics profoundly alter subjective experience and brain dynamics. Brain oscillations express signatures of near-critical dynamics, relevant for healthy function. Alterations in the proximity to criticality have been suggested to underlie the experiential and neurological effects of psychedelics. Here, we investigate the effects of a psychedelic substance (DMT) on the criticality of brain oscillations, and in relation to subjective experience, in humans of either sex. We find that DMT shifts the dynamics of brain oscillations away from criticality in alpha and adjacent frequency bands. In this context, entropy is increased while complexity is reduced. We find that the criticality shifts observed in alpha and theta bands correlate with the intensity ratings of self-dissolution, a hallmark of psychedelic experience. Finally, using a recently developed metric, the functional excitatory-inhibitory ratio, we find that the DMT-induced criticality shift in brain oscillations is towards subcritical regimes. These findings have major implications for the understanding of psychedelic mechanisms of action in the human brain and for the neurological basis of altered states of consciousness.&lt;/p&gt;
    &lt;p&gt;Significance statement Criticality is characterized by fluctuations occurring on a wide range of spatiotemporal scales and high complexity. Here, we investigate the effects of DMT, a classic psychedelic, on criticality of brain oscillations and in relation to subjective experience. We find that DMT shifts the normally dominant alpha oscillations towards a quieter subcritical state, increasing entropy while reducing complexity, and that this shift correlates with intensity of disruption of the sense of self.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;We would like to thank Marina Diachenko for her support with this project.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This study was funded by a donation to Patrick Vernon to the Centre for Psychedelic Research. CT was funded by AgenciaNacional de Investigacion y Desarrollo (ANID) and a donation by Anton Bilton.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;K.L.-H. is a shareholder of Aspect Neuroprofiles BV, which develops physiology-informed prognostic measures for neurodevelopmental disorders. All other authors declare no competing financial interests.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚Üµ*These authors contributed equally.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46086863</guid><pubDate>Sat, 29 Nov 2025 11:52:21 +0000</pubDate></item><item><title>Show HN: I built Magiclip ‚Äì an all-in-one AI studio</title><link>https://magiclip.io/</link><description>&lt;doc fingerprint="be438e4d30b8ae43"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Create a viral Short in just 2 clicks&lt;/head&gt;
    &lt;p&gt;From idea to viral short: monetize your content in just seconds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Veo 3 Video AI&lt;/head&gt;
    &lt;p&gt;Create professional videos from text in seconds. The most advanced AI video generation technology available.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Superpowers of Magiclip AI&lt;/head&gt;
    &lt;p&gt;Transform your content creation with powerful AI-driven tools that make video editing, audio generation, and media conversion effortless and professional.&lt;/p&gt;
    &lt;head rend="h4"&gt;Generate clips with subtitles&lt;/head&gt;
    &lt;p&gt;Transform your long videos into impactful clips with automatic subtitles.&lt;/p&gt;
    &lt;head rend="h4"&gt;Split-screen video&lt;/head&gt;
    &lt;p&gt;Add gameplay or animated backgrounds to make your videos more dynamic.&lt;/p&gt;
    &lt;head rend="h4"&gt;Generate AI images&lt;/head&gt;
    &lt;p&gt;Create unique images in seconds based on your description.&lt;/p&gt;
    &lt;head rend="h4"&gt;AI voice generation&lt;/head&gt;
    &lt;p&gt;Turn text into realistic, natural voices in multiple languages.&lt;/p&gt;
    &lt;head rend="h4"&gt;Generate subtitles&lt;/head&gt;
    &lt;p&gt;Automatically add synchronized, customizable subtitles.&lt;/p&gt;
    &lt;head rend="h4"&gt;Video AI&lt;/head&gt;
    &lt;p&gt;Create stunning videos with Veo 3 AI model - the most advanced video generation technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pricing&lt;/head&gt;
    &lt;p&gt;Perfect to get started&lt;/p&gt;
    &lt;head rend="h2"&gt;19‚Ç¨/month&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;300 credits*&lt;/item&gt;
      &lt;item&gt;Veo 3&lt;/item&gt;
      &lt;item&gt;100 Image AI&lt;/item&gt;
      &lt;item&gt;40 Voice AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To go further&lt;/p&gt;
    &lt;head rend="h2"&gt;39‚Ç¨/month&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;600 credits*&lt;/item&gt;
      &lt;item&gt;Veo 3&lt;/item&gt;
      &lt;item&gt;300 Image AI&lt;/item&gt;
      &lt;item&gt;120 Voice AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For pros with multiple TikTok accounts&lt;/p&gt;
    &lt;head rend="h2"&gt;79‚Ç¨/month&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1500 credits*&lt;/item&gt;
      &lt;item&gt;Veo 3&lt;/item&gt;
      &lt;item&gt;500 Image AI&lt;/item&gt;
      &lt;item&gt;180 Voice AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;See How We've Made a Difference&lt;/head&gt;
    &lt;p&gt;Find quick answers to your questions about Magiclip, our AI platform for video content creation.&lt;/p&gt;
    &lt;head rend="h6"&gt;01.How does Magiclip's AI work?&lt;/head&gt;
    &lt;p&gt;Magiclip uses advanced AI algorithms to analyze your videos, automatically generate subtitles, create optimized clips, and even generate AI voices. Our technology understands the context of your content to produce professional results.&lt;/p&gt;
    &lt;head rend="h6"&gt;02.What video formats are supported?&lt;/head&gt;
    &lt;p&gt;MP4 only&lt;/p&gt;
    &lt;head rend="h6"&gt;03.How many videos can I process per month?&lt;/head&gt;
    &lt;p&gt;It depends on your plan: Creator (30 videos/month), Expert (60 videos/month), and Professional (150 videos/month). Each video can be transformed into multiple clips, and you also have credits for AI images and AI voices.&lt;/p&gt;
    &lt;head rend="h6"&gt;04.What languages are available?&lt;/head&gt;
    &lt;p&gt;It's up to you to choose your language between French, English and Spanish.&lt;/p&gt;
    &lt;head rend="h6"&gt;05.Can I use Magiclip for my social media?&lt;/head&gt;
    &lt;p&gt;Absolutely! Magiclip is specially designed to optimize your content for TikTok, Instagram, YouTube Shorts, and other platforms. We automatically resize your videos to optimal dimensions and create engaging clips that maximize engagement.&lt;/p&gt;
    &lt;head rend="h6"&gt;06.How does AI voice generation work?&lt;/head&gt;
    &lt;p&gt;Our AI voice technology transforms your text into natural speech in multiple languages. You can choose from different accents and voice styles. Perfect for creating narrations, explanations, or multilingual content without needing a recording studio.&lt;/p&gt;
    &lt;head rend="h6"&gt;07.How to cancel your subscription?&lt;/head&gt;
    &lt;p&gt;To cancel your subscription, go to Profile then Billing and then click on Cancel Subscription.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46086920</guid><pubDate>Sat, 29 Nov 2025 12:04:23 +0000</pubDate></item><item><title>How ICE is becoming a secret police force</title><link>https://theconversation.com/how-ice-is-becoming-a-secret-police-force-under-the-trump-administration-255019</link><description>&lt;doc fingerprint="bfb981d041adc349"&gt;
  &lt;main&gt;
    &lt;p&gt;Secret police are a quintessential feature of authoritarian regimes. From Azerbaijan‚Äôs State Security Service to Zimbabwe‚Äôs Central Intelligence Organisation, these agencies typically target political opponents and dissidents through covert surveillance, imprisonment and physical violence.&lt;/p&gt;
    &lt;p&gt;In contrast to the regular police and armed forces, secret police primarily use preemptive repression to thwart threats to the government.&lt;/p&gt;
    &lt;p&gt;In Nazi Germany, for example, Gestapo informants penetrated all levels of society, producing an atmosphere of distrust among those against Adolf Hitler. In Uganda, Idi Amin‚Äôs State Research Bureau employed sophisticated spying equipment and intercepted mail at the post office to root out supposed saboteurs.&lt;/p&gt;
    &lt;p&gt;In Syria, Bashar al-Assad relied on the General Intelligence Directorate to oversee a network of torture centres. And in Venezuela, Nicol√°s Maduro has used the Bolivarian National Intelligence Service (Sebin) to spy on opponents overseas, often running operations out of diplomatic missions.&lt;/p&gt;
    &lt;p&gt;Since US President Donald Trump took power in January, Immigration and Customs Enforcement (ICE) has become a far more visible and fearsome force on American streets.&lt;/p&gt;
    &lt;p&gt;Though ICE is ostensibly still bound by constitutional limits, the way it has been operating bears the hallmarks of a secret police force in the making.&lt;/p&gt;
    &lt;p&gt;As an expert on authoritarian regimes, I‚Äôve studied historical and contemporary secret police forces extensively across Africa, Asia and Europe. They typically meet five criteria:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;they‚Äôre a police force targeting political opponents and dissidents&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;they‚Äôre not controlled by other security agencies and answer directly to the dictator&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the identity of their members and their operations are secret&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;they specialise in political intelligence and surveillance operations&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;they carry out arbitrary searches, arrests, interrogations, indefinite detentions, disappearances and torture.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How close is ICE to becoming a secret police force? Let‚Äôs consider each of these criteria.&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting dissidents&lt;/head&gt;
    &lt;p&gt;ICE has used the pretext of combating antisemitism to target dissidents. A branch of the agency previously used to target drug smugglers and human traffickers has reportedly been directed to scan social media for posts sympathetic to Hamas.&lt;/p&gt;
    &lt;p&gt;On March 8, ICE arrested the prominent pro-Palestinian activist Mahmoud Khalil, a legal resident. It was a similar story for Rumeysa Ozturk, a university student grabbed off the street on March 25 by ICE agents.&lt;/p&gt;
    &lt;p&gt;Trump has cited the Immigration and Nationality Act of 1952 as the legal pretext for ICE‚Äôs actions in these cases and others. The law allows the US government to deport anyone whose presence has ‚Äúadverse foreign policy consequences‚Äù for the country.&lt;/p&gt;
    &lt;p&gt;Because Khalil and others are being targeted for their activism, legal scholars say the government appears to be ‚Äúretaliating‚Äù against constitutionally protected free speech it disagrees with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Directly controlled by a dictator&lt;/head&gt;
    &lt;p&gt;While ICE does not report directly to Trump, the agency is controlled by people who have shown intense loyalty to him.&lt;/p&gt;
    &lt;p&gt;ICE is part of the Department of Homeland Security, which is overseen by stalwart Trump ally Kristi Noem. She is supported by Tom Homan, a former ICE director who Trump appointed as his ‚Äúborder czar‚Äù in November 2024.&lt;/p&gt;
    &lt;p&gt;Despite a court order barring the deportations of alleged Venezuelan gang members to a prison in El Salvador, Homan has remained defiant:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We are not stopping. I don‚Äôt care what the judges think.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The pertinent question now is whether Noem or Homan would refuse to follow a dictate from Trump in the face of a direct court order.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opaque operations&lt;/head&gt;
    &lt;p&gt;ICE agents are increasingly operating in secret. The individuals who took Ozturk off the street in a widely shared video claimed to be police officers, even though they were in plain clothes and face masks.&lt;/p&gt;
    &lt;p&gt;Similarly, ICE agents in plain clothes detained two men during a raid on a courthouse in Charlottesville, Virginia, on April 22. When two bystanders asked to see a warrant, they were ordered not to ‚Äúimpede‚Äù the agents‚Äô lawful duties. ICE later said the two women would be prosecuted.&lt;/p&gt;
    &lt;p&gt;Also last week, ICE agents attempted to arrest a man at a Wisconsin courthouse without a warrant. After a judge intervened, she was arrested herself by the FBI and charged with two felonies.&lt;/p&gt;
    &lt;p&gt;This shroud of opacity has been accompanied by an end to local agency liaison meetings aimed at helping people seek answers to ICE‚Äôs actions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Surveillance capabilities&lt;/head&gt;
    &lt;p&gt;ICE is organised into two distinct law enforcement components, giving it both political intelligence gathering and surveillance capabilities.&lt;/p&gt;
    &lt;p&gt;Its Homeland Security Investigations arm includes an intelligence division, while its Enforcement and Removal Operations arm uses third-party companies such as Geo Group, Giant Oak, and Palantir to conduct mass surveillance.&lt;/p&gt;
    &lt;p&gt;Most worryingly, ICE is trying to procure greater intelligence and surveillance capabilities by soliciting pitches from private companies to monitor threats across the internet.&lt;/p&gt;
    &lt;p&gt;According to a procurement document, contractors would be directed to focus on the backgrounds of social media users and use facial recognition capabilities to gather information on people. Criticisms of ICE itself would be monitored, too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unlawful policing&lt;/head&gt;
    &lt;p&gt;There has been a stream of reports exposing how ICE is conducting arbitrary searches, arrests, interrogations, and indefinite detentions.&lt;/p&gt;
    &lt;p&gt;Some of the most egregious reported examples include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;entering primary schools under false pretences in search of undocumented students&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;carrying out ‚Äúcollateral arrests‚Äù, that is detaining people not previously identified as targets during operations&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;detaining tourists and visa holders for weeks for unknown reasons&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;and disappearing US citizens without any meaningful process.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Trump‚Äôs inauguration, at least three people have died in ICE detention facilities, the latest in a string of fatalities in recent years.&lt;/p&gt;
    &lt;p&gt;Prolonged solitary confinement is reportedly widespread. UN experts say this can amount to torture.&lt;/p&gt;
    &lt;head rend="h2"&gt;Potentially expanded scope&lt;/head&gt;
    &lt;p&gt;Overall, the evidence shows ICE meets most of the criteria for being a secret police force. It has yet to target political opponents, which I define narrowly as members of the Democratic Party. And it is not directly controlled by Trump, although the current structure provides him with plausible deniability.&lt;/p&gt;
    &lt;p&gt;While the agency is far from resembling history‚Äôs most feared secret police forces, there have so far been few constraints on how it operates.&lt;/p&gt;
    &lt;p&gt;The worst may be yet to come. A budget bill making its way through Congress would provide ICE with up to US$175 billion (A$274 billion) in funding over the next decade. (Its current annual budget is US$9 billion, or A$14 billion.) This would supercharge its use of surveillance, imprisonment and physical violence.&lt;/p&gt;
    &lt;p&gt;When combined with a potential shift towards targeting US citizens for dissent and disobedience, ICE is fast becoming a key piece in the repressive apparatus of American authoritarianism.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46087518</guid><pubDate>Sat, 29 Nov 2025 13:49:22 +0000</pubDate></item><item><title>Hachi: An Image Search Engine</title><link>https://eagledot.xyz/hachi.md.html</link><description>&lt;doc fingerprint="f79f98f728b79b98"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Hachi: An (Image) Search engine&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Only the dead have seen the end of war .. George Santayana&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For quite some time now, i have been working on and off on a fully self-hosted search engine, in hope to make it easier to search across Personal data in an &lt;code&gt;end to end&lt;/code&gt; manner. Even as individuals, we are hoarding and generating more and more data with no end in sight. Such "personal" data is being stored from local hard-disks to corporate controlled cloud-centers which makes it distributed in nature. So for following discussion, "Personal" meaning would be flexible enough to accommodate resources on a remote server and/or on different devices, as long the user could prove authentication and/or authorization to that data.
Current implementation supports only "images", but eventual goal is also to support other modalities like &lt;code&gt;video&lt;/code&gt;, &lt;code&gt;text&lt;/code&gt; and &lt;code&gt;audio&lt;/code&gt;, some code would be shared, while some new code would be required to better extract &lt;code&gt;Features&lt;/code&gt; for each modality.&lt;/p&gt;
    &lt;p&gt;Such distributed nature of data and potential capabilities of current self-hosted Machine learning models to extract semantic information, only to be queried through a single interface seemed enticing enough for me start this experiment in the first place. Following post at times may seem in-coherent, as i try to articulate my thoughts on the journey of development, challenges faced and future ideas. I hope to treat this as a personal essay with multiple themes, anecdotes and even random thoughts aiming to provide a higher level view of the journey and philosophy so far in more concrete terms.&lt;lb/&gt; Also, following post doesn't aim to cover every technical choice and implementation in finer details, such discussions would instead be part of dedicated future posts!&lt;/p&gt;
    &lt;head rend="h2"&gt;Motivation:&lt;/head&gt;
    &lt;p&gt;As Humans we tend to remember different attributes/parts of an entity/information at different times, and most of search engines' interfaces refuse to accomodate that. User generally end up with an unidirectional flow of information, with no recourse of providing feedback to improve upon the on-going query. Even most advanced interfaces fail to handle the stochastic nature of queries and humans' pre-disposition towards partial information to keep moving, it should be default for search-engines to present best-effort suggestions for queries even if they couldn't be fully resolved.&lt;/p&gt;
    &lt;p&gt;I also note that, it is not always easy to model the imperfect information like handelling a mis-spelling, which itself could be mis-spelled in many ways. It would require a conscious effort to put in a better search interface, as most digital machines make it easy to model when "something" is "correct" or when something is "incorrect". Conveying "Why" something is incorrect takes a lot more code, effort and time, hence indicating that economic realities are more to blame for such cases than bad intentions!&lt;/p&gt;
    &lt;p&gt;It also presents an opportunity to analyze the capabilities of a good interface, as personal data would make it very easy to notice its limitations, which couldn't be observed through seemingly complete interfaces exposed by many e-commerce companies.&lt;/p&gt;
    &lt;p&gt;Inspired by above stated ideas, My try has been to expose multiple (if not all) attributes for a resource directly to user and then letting user recursively refine query to get to desired result. Implementation is still far from complete, but this theme has served me well to set a basic roadmap for the project. Other themes such as self-hosting, hostile behaviour towards users in terms of privacy-invading features, limited or no options to refine a search by google, github etc has contributed to evolution of this experiment. Distributed queries being served by a cluster of (refurbished) smart-phones or single-board-computers remains a lofty goal of this experiment too!&lt;/p&gt;
    &lt;p&gt;Despite all the good intentions and ideas, any search interface should pass that threshold of being fast enough to not end up as another impractical experiment. Efforts were involved from the beginning to embrace the inevitable complexity such projects come to include despite many refactorings. Below is a minimal video to help visualize the current state and capabilities of the project.&lt;/p&gt;
    &lt;head rend="h2"&gt;Broader Ideas:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Minimalism: Minimalism in terms of number of external dependencies required for this project to be bootstraped, could explain a lot about downstream choices and evolution of the project to its current form. This has of any existing (source) code if possible or writing it from scratch which itself would require reading of a lot of existing code before i could port it to extend the project in a pure source sense. If it would be practical to reuse some code from existing capable projects/databases, i would have done so but most of such projects are designed to be de-coupled from application code for good reasons, as they are supposed to offer much more guarantees and stay robust even under heavy load. Being an (embedded) part of personal application we can choose to do away with such guarantees and yet expose much more information by tightly integrating ML models pipeline. In the end, application would handle much more complex indexing and inferencing pipelines, which would require a lot more code apart from search and storage interface generally expose!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Experimentation: Thinking more about in terms of augmenting the existing information, rather than to duplicate it, while fusing traditional (deterministic) attributes with semantic(ML) attributes. I think this is an interesting problem and which have not been fully utilized/explored for personal applications. Most of traditional databases were written to only handle "text" modality, but current ML models allow us to query semantic information too, which opens up a new space to experiment in. I treat semantic information as necessary and independent, but not the only signal useful to implement great search interfaces.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Hackability: For this project i wanted it be very easy for someone to start modifying it according to their needs, and this mostly co-relates with the first point about minimalism, lesser the number of dependencies, lesser is the amount of configuration required to bootstrap the developing environment. Both Python and Nim are stable, cross-platform languages and are easier to extend just using a C compiler. Nim source code it easy to compile and/or cross-compile to on almost all platforms. There are already python bridges for many languages, so all such languages are fair game to extend the codebase in any desired way!&lt;/p&gt;&lt;lb/&gt;Python environments (in)famously have the reputation of being difficult to bootstrap, whole parallel ecosystem is there to do so which itself creates another dependency. But i think project has made great progress in this regard, with now having a requirement of just 3 dependencies as&lt;code&gt;numpy&lt;/code&gt;,&lt;code&gt;regex&lt;/code&gt;and&lt;code&gt;markupsafe&lt;/code&gt;and optionally&lt;code&gt;requests&lt;/code&gt;, with no hard-dependence on versioning. Almost all python environments could be used to run the project with no changes, which also removes any need to bootstrap dev environment using Docker like huge dependency or any complex unwarranted build-systems plaguing many of the interesting projects. If i had money, i would pay someone to just make such projects easier to install and start with, by removing any redundant configuration or making it possible to use one common build-system !&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even though above ideas may seem worthy to follow on, there is always an on-going fight to prevent dilution of agreed upon principals. Counter-intuitively i think there is some kind of &lt;code&gt;activation-enery&lt;/code&gt; (https://en.wikipedia.org/wiki/Activation_energy) requirement for each project, past that it actually is much easier to extend, modify, optimize the codebase somewhat like paying a debt to live debt free:)     &lt;/p&gt;
    &lt;p&gt;There are already very capable projects like &lt;code&gt;Sqlite&lt;/code&gt;, &lt;code&gt;Lucene&lt;/code&gt; offering full-text search capabilities, but they implement their own storage backends which require all data to be transformed to the compatible format which leads to duplication of data . This is something i wanted to avoid, as we would be continuously transforming every newer data and this would become computationally expensive when such data wouldn't even reside on same physical machine/node. If we could get away with fast-enough queries through a much simpler index/database, that seems like something worthy to pursue further.&lt;lb/&gt; Most of such projects were created to handle only text queries, But current ML models expose semantic information through "vectors" or "embeddings", generated after a series of linear and non-linear operations on some text or/and an image. &lt;code&gt;Top-k&lt;/code&gt; matching results are later retrived through a "Comparison" procedure with user query (embedding) as one of inputs. 
Such extensions are being gradually added in many older engines, so a hackable codebase like this project may offer more flexibilities while accomodating future ideas in this rapidly evolving field!  &lt;/p&gt;
    &lt;p&gt;It leads to a design comprising a meta-data indexing engine, coupled with vector-search engines for semantic search. We never intend to duplicate the original-data and don't care where it actually resides, once indexing is done. As i think search is more about reaching to a desired file/resource before that resource could be used! Pin-pointing that resource location quickly is the major motivation by incorporating the user intentions and context recursively!&lt;/p&gt;
    &lt;p&gt;(C)Python is used as the major language for backend and Nim (and C) is used to speed up the bottleneck portions of the codebase where-ever warranted. Writing from scratch allows me to update the api as i fit to handle a bottleneck portion of the pipeline (querying or indexing), without asking or waiting for a change in some upstream dependency. Nim itself is a language with relatively smaller community, so i am getting a bit comfortable porting code from other languages to my projects with only standard library and even experimenting with my own data-structures based on (protected) reference semantics than default value semantics that Nim use!&lt;/p&gt;
    &lt;head rend="h1"&gt;Meta-Index:&lt;/head&gt;
    &lt;p&gt;Its a minimal module/database to handle (store and query) meta-data being extracted from resources(images) and has been written in Nim. Currently it is single-threaded, column-oriented database using Json as data-exchange mechanism between python and Nim. In future idea is to shift to leveraging multiple threads for workloads/size greater than a threshold, to better use the current hardware capabilities. It is possible to generate an &lt;code&gt;auxilary&lt;/code&gt; index to speed up queries for a column/attribute on demand, which internally would use cache-friendly and hierichal data-structures to achieve so for most of scenarios! &lt;lb/&gt; Through development of this module, it has been easier to note that why most of databases end-up with some kind of dedicated &lt;code&gt;query language&lt;/code&gt;, as situations arise requiring composing multiple operations in one go which seems like a cleaner way to model such intentions. (and this also seems to validate the requirement of a  &lt;code&gt;query-planner&lt;/code&gt; to better execute a query by analyzing the order and nature of operations and some internal details).
Since it would be written for &lt;code&gt;hachi&lt;/code&gt; itself, it remains possible for me to  speed up a frequent operation by sharing a pointer/memory directly across Nim and python to prevent costly &lt;code&gt;copy&lt;/code&gt; operations, or to directly serve &lt;code&gt;raw json&lt;/code&gt; to the frontend in some cases without serializing and de-serializing at python boundary.&lt;/p&gt;
    &lt;p&gt;I have also experimented with multi-versioning storage design as Lmdb, to protect the original information created by code itself from user revisions. But current implementation instead favours creation of a dedicated field/attribute for user to modify/update. For example during face clustering process, backend will assign an unique Id for each new &lt;code&gt;cluster&lt;/code&gt;, to which user may want to change to a more descriptive name, this leads to presence of attributes like &lt;code&gt;personML&lt;/code&gt; and &lt;code&gt;person&lt;/code&gt; in the final schema. By default, any attribute/information generated through during indexing pipeline is supposed to be immutable to be easily reset to genesis state.&lt;lb/&gt; It still is a bit rigid implementation, as schema is locked once initialized (lazily or explicit), as adding new columns dynamically will require me to reallocate data in the memory and more syncing logic which i am off-putting for now and will work on in the future! Current iteration supports &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;array[string]&lt;/code&gt; data-types, which seems to be enough for the application needs, but could be evolved in the future. I am not particularly content with current "string" querying, one reason is that Nim  by default does not have a concept of no-copy slice, and it is difficult to even expose such a user-defined type. As &lt;code&gt;strings&lt;/code&gt; are null-terminated, so most of other composed data-structures with string as one of fields have that underlying assumption which that user-defined type will break. Also i think for a lot of meta-data attributes, i could use &lt;code&gt;ShortString&lt;/code&gt;    kind of data-type to speed up scanning/querying by better leveraging the cache. Some of these issues are being experimented through an independent project and if found to improve performance could be implemented in this codebase too!    &lt;/p&gt;
    &lt;p&gt;There are also Simd opportunities inside the "querying" code, but since its design is being guided by overall needs for the product itself, i hope to add those architecture specific optimizations only after system-design becomes stable enough for most of the features supposed to be supported!&lt;/p&gt;
    &lt;head rend="h1"&gt;Face-Recognition:&lt;/head&gt;
    &lt;p&gt;Being able to group same person(s) with a high probability, as another attribute to search for or mix with other attributes, would be a very quality addition to any search interface. Current DL models for some-time now have been able to distinguish faces with a high accuracy. But being able to distinguish real-life faces still requires a conformance to the pipeline such models would have been trained with.&lt;lb/&gt; There are multiple architectures for such models that have been proposed to tackle this problem, but most pipelines could be assumed to follow a generic flow, which begins with detection of facial bounding boxes from a given image or camera frame, then followed by detection of facial-landmarks for each such face, and ends with generation of &lt;code&gt;embeddings/vectors&lt;/code&gt; which figuratively would represent some kind of latent representation of that face.  At this point, this would be reduced to a Vector Spaces problem and hence much easier to deal with traditional tools like nearest neighbour search !&lt;/p&gt;
    &lt;p&gt;It almost always overwhelming to decide on a particular Implementation to build upon, while accommodating various factors like &lt;code&gt;latency&lt;/code&gt;, &lt;code&gt;accuracy&lt;/code&gt; , &lt;code&gt;hardware requirements&lt;/code&gt;, and most of such intensive pro-bono work would never even be visible to the end-user. For me atleast this goes much further, as i would be implementing each such model using an independent ML framework, which would require me to understand also all the pre-processing and post-processing code, to be  faithfully ported to Nim.&lt;lb/&gt; Spending time on reading papers and existing implementations helps me to get an idea about overall "capability" of the model and potential requirements during fine-tuning of the model in future. Sometimes it has been enough for me to come across an interesting concept through a paper or some nice optimization trick, even if i end up not using that particular implementation. &lt;lb/&gt; Most of face embeddings generation models are trained on a &lt;code&gt;Siamese-loss&lt;/code&gt; like objective to try to explicitly distinguish both positive-positive and positive-negative pairs. This generally involves manually collecting such pairs and hence prone to bias ! Such features predictors are also very sensitive to &lt;code&gt;face-alignment&lt;/code&gt; code used, and hence may require you to faithfully follow the training code!

Dataset being used for training and choice of the objective function are two very major factors influencing the performance of any model. Leakage of evaluation data into training set has been a real issue in recent years for many experiments. Face-recognition itself is a very subjective problem and generally require more "visual" testing apart from (mathematical) metrics proposed for this problem/sub-domain.  &lt;/p&gt;
    &lt;p&gt;Current pipeline uses &lt;code&gt;retina-face&lt;/code&gt; model to predict faces and landmarks in one go which helps producing stable facial-landmarks and speeding up the pipeline. (As predicting facial-landmarks would be much cheaper from internal features than through a dedicated model, and it also helps stabilizing  the training of the model).
Though it could make sense to argue about a model's ability to internalize learning correlated features without adding an explicit loss, but in practice it is always (very) beneficial to use multiple losses explicitly.
Interestingly, &lt;code&gt;residual&lt;/code&gt; connection in &lt;code&gt;ResNets&lt;/code&gt; was an important innovation making it possible to train much deeper networks at that time, even though it would be just mimicing an &lt;code&gt;identity&lt;/code&gt; function.



  &lt;/p&gt;
    &lt;p&gt;In my experience, dataset being used for training and choice of the objective function are two very major factors influencing the performance of your model on real-life (bit out-of-distribution datasets). I find it a good practice to always visually debug some of the random samples to get a "feel" for the dataset!&lt;/p&gt;
    &lt;p&gt;Even after having a good pipeline to generate "embeddings" for a face, &lt;code&gt;clustering&lt;/code&gt; remains a very challenging problem, due to various reasons.
Like with almost all clustering algorithms, we start out with no prior information about of the underlying (number) distribution of the data (faces). (as this is what we would be trying to estimate). As we keep encountering the newer information, possible &lt;code&gt;updates&lt;/code&gt; through &lt;code&gt;back-filling&lt;/code&gt; are required for the underlying index, which somewhat resembles of an auto-regressive operation and hence the error-accumulation rate is relatively high. We would also need to wait for some "initial" amount of data/information to be collected, to estimate initial stable centroids. This difficulty is further compounded by the choices for various thresholds like face-detection, some measure for blurness in the detected face, and a dependence on order of information being encountered.&lt;/p&gt;
    &lt;p&gt;As indicated, choosing same model to predict landmarks and face-bounding boxes, helps reduce the impedance mismatch that occurs when output of one model is being fed through another model. We would need to a dedicate model for facial-features though as earlier features may not be dense enough to distinguish among individual faces!&lt;/p&gt;
    &lt;p&gt;Currently Implementation works by collecting some minimal amount of information before &lt;code&gt;Cluster&lt;/code&gt; creation process could begin. 
Each Cluster is a union of a set of main/master embeddings and a set of follower/slave embeddings. Selection of main embeddings is a crucial part to maintain the stability of a cluster even when new information would be encountered. Initial filtering of unfeasible (master) embeddings is done through some static criterias, for example we strive to filter any of &lt;code&gt;blurred&lt;/code&gt; faces, face-profile is estimated through facial-landmarks, stable forward-facing profiles make face-alignment easier further in the pipeline. Such (static) criterias definitely help to reduce the number of invalid candidates, but may not be enough for many real-life datasets. A further minimal module comparing the &lt;code&gt;hog-features&lt;/code&gt; with a set of pre-saved hog-features is introduced to help invalidate faces with &lt;code&gt;sunglasses&lt;/code&gt; and some false positives not caught by earlier criterias!&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;no-categorical-info&lt;/code&gt;, when not able to being fit into any of the clusters.
Note that a lot of empirical data comes into effect as multiple decisions would be required while choosing many thresholds and may require multiple runs .&lt;/p&gt;
    &lt;p&gt;Since face-recognition is very subjective and i myself have to compare other features to make sure that indeed the correct person(s) have been grouped together by the pipeline. But with a latency of around 25 ms, it seems to do very good on a held out dataset of persons with close up faces, (Zen-Z) selfies and sunglasses occluded eyes. Personal photos are much easier to classify/recognize compared to such a dataset!&lt;/p&gt;
    &lt;p&gt;For any practical ML integrated product, We would need to have a very performant concurrent pipeline to keep feeding the model while being constantly aware of any data-distribution impedance mismatch, to reach anywhere near the 'accuracy' and &lt;code&gt;speed&lt;/code&gt; promised in a research paper. This touches upon the issue of having good understanding of software engineering basics, while being aware of possible regressions resulting from a newer functionality like ML.&lt;lb/&gt; Though bigger VLM/LLM (base) models have potential to handle data-impedance mismatch issues due to their sheer size, their usage would definitely hamper the application responsiveness and have proven to be relatively rigid to be fine-tuned for a specific domain! &lt;/p&gt;
    &lt;head rend="h2"&gt;Indexing:&lt;/head&gt;
    &lt;p&gt;Indexing pipeline begins with desired data location as its input to recursively scanning &lt;code&gt;directories&lt;/code&gt; to collect &lt;code&gt;raw-data&lt;/code&gt; in batches.
Multiple meta attributes such as &lt;code&gt;exif-data&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt;, &lt;code&gt;mount location&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt; are extracted to be later queried through the Meta-indexing engine. Focus has been on designing a good schema to accomodate future use-cases, but since we would be collecting only meta-information without ever modifying the original or duplicating the original data, it remains relatively easier to shift to a newer version/schema even through automatic means.&lt;lb/&gt; ML models extract semantic information which can be later queried through a vector-indexing engine. By default resources to be indexed are assumed to be residing on a local-disk but any protocol could be leveraged, if proper authorization and authentication could be provided.&lt;lb/&gt; Monolithic nature of the code helps me to share &lt;code&gt;raw-data&lt;/code&gt; read/collected once for various components like &lt;code&gt;hash generation&lt;/code&gt;, &lt;code&gt;preprocessing&lt;/code&gt; code for ML models, reducing the number of costly I/O calls. This pipeline has come a long way from a blocking implementation to its current (almost) fully async nature, resulting in very high saturation of computing resources. Apart from running multiple threads, dedicated kernels/functions are used to speed up pipeline by &lt;code&gt;fusion&lt;/code&gt; of operations wherever possible.
 One such example/scenario  has been shown below.&lt;/p&gt;
    &lt;code&gt;def preprocess_kernel(
    image:Tensor[uint8],
    new_shape:tuple[int,int], 
    rgb_to_bgr:bool = True, 
    normalize:bool = True):
    # Preprocess kernel, may fuse resize, color_conversion and normalization into one function!

    # Pseudo-code!

    result = newEmptyTensor[uint8](new_shape)
    for i in new_height:
        for j in new_width:
            inp_h, inp_w = get_corresponding_pixel(image, i, j)
            for k in 0..&amp;lt;3:
                if rgb_to_bgr:
                    result[i,j , 3-k-1] = image[inp_h, inp_w, k]
                    # normalize based on mean and deviation used for training dataset further...
                else:
                    result[ i,j,k] = image[inp_h, inp_w, k]
&lt;/code&gt;
    &lt;p&gt;Each &lt;code&gt;resource&lt;/code&gt; could be assumed to go through a flow like this:&lt;/p&gt;
    &lt;code&gt;resource_location = "file://xyz.jpg"
# OR
resource_location = "remoteProtocol://xyz.jpg"

raw_data = download_raw_data(resource_location)

embeddings = ML_model( preprocess(raw_data))
exif_data = extract_exif_data(raw_data)
preview = generate_preview(raw_data)
write_preview(preview)
....
&lt;/code&gt;
    &lt;head rend="h2"&gt;Vector Index:&lt;/head&gt;
    &lt;p&gt;It is another minimal module to store vector-embeddings as shards on the disk. Necessary meta-data is stashed along with that shard, to make it self-contained, which in future will help in distributed/parallel retrieval. For now each shard is just a numpy (float32) Tensor, and comparison routine is a &lt;code&gt;np.dot&lt;/code&gt; operator, which itself use the &lt;code&gt;blas/openblas&lt;/code&gt; library to speed up this operation! Each shard is loaded from the Disk during a query, and &lt;code&gt;top-k&lt;/code&gt; candidates are collected to be fused together with other deterministic meta-attributes. Loading from Disk do add some latency, but it allows me to regulate RAM usage through &lt;code&gt;shard-size&lt;/code&gt; hyper-parameter, to allow running this on different platforms  with diverse specifications including single-board computers. &lt;code&gt;Shard-size&lt;/code&gt; could be kept relatively high for higher RAM systems to speed up shard querying.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Matmul&lt;/code&gt; is one of the most optimized algorithms which run at almost 90% of theoretical capacity on most of intel/amd Cpus when leveraging &lt;code&gt;Blas&lt;/code&gt; like libraries. So every further optimization from here-on would involve some kind of information loss. There is a whole literature now to speed up this comparison/retrieval process through &lt;code&gt;quantization&lt;/code&gt; and/or &lt;code&gt;nearest neighbour&lt;/code&gt; indices like HNSW. Fast SSDs are also leveraged to run such comparisons at very high speed for upto billion vectors on just a single node in near real time!&lt;/p&gt;
    &lt;p&gt;But such all techniques involve compression of information (which itself is best-effort being the result of modeling a large amount of biased data) through out-of-band mechanisms, for example creating centroids/clusters is just based on the vector values and taking some mean without a way to pass back the information to the model which produced those vectors in the first place. This way is quick and you would get great speed-ups, and there is an active debate among vector-database vendors across various metrics and implementations. In my experience only visual results on a personal data would be a good metric a user should test for. Product-quantization is something i would be implementing if were to choose one, as i think coupled with &lt;code&gt;top-k&lt;/code&gt;, it should work reasonably well to include (subjectively) correct results (high recall!) .&lt;/p&gt;
    &lt;p&gt;Another worthy and very effective solution i think is to instead train a linear layer to finetune the original model depending upon the task. ML Features/embeddings from a big enough model, could assumed to have a knowledge about diverse topics, but for example, a user may be trying to distinguish between different plants. A linear layer could easily be trained with just few thousand samples, to achieve so with much higher accuracy than original models, and even with half the size/dimension of original embeddings. Intuitively it could be thought that we freed the information channels to just focus on plants, decreasing the entropy model earlier had to deal with. Any such layer could be trained even without any framework, as it would just be one &lt;code&gt;backward&lt;/code&gt; operation to implement.
OpenAI has a nice cookbook if a reader would want to explore this further!



  https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb&lt;/p&gt;
    &lt;p&gt;An interesting thing sharding allows is to use any available &lt;code&gt;hardware&lt;/code&gt; to speed up retrieval. Since we need just &lt;code&gt;comparison&lt;/code&gt; routine and corresponding shard(s) to return top-k candidates, it de-couples it from any of application code. A new smartphone could be detected, and some &lt;code&gt;shards&lt;/code&gt; could be transferred during initial set-up, optimal percentage/number of shards could be easily calculated by running same &lt;code&gt;comparsion&lt;/code&gt; operation on new device. Like running a &lt;code&gt;2048 x 2048&lt;/code&gt; , inner-product op and comparing latency with &lt;code&gt;master/main&lt;/code&gt; device, would tell us the capacity of the new device and so that number of shards would be transferred to speed up retrieval process!&lt;/p&gt;
    &lt;p&gt;There are performance gains to be have in the current implementation, would like to atleast start using &lt;code&gt;float16&lt;/code&gt; data-type, but its a bit tricky on intel cpus with no compiler support for this type. Printing of CPU capabilities do show the presence of float16 hardware support on my system ! 
ARM(v8 64) seems to offer native float16/floatH types, there seems to be difference in that type either supported natively by compiler or as an intrinsics/assembly code. I have not been able to get expected speed up for now! Such code is still being experimented upon in the limited time i have.&lt;/p&gt;
    &lt;head rend="h2"&gt;Backend:&lt;/head&gt;
    &lt;p&gt;Backend is written in python, which exposes a pure API server, to let the client/frontend to make API calls to. Starting with very naive code to just return all the meta-data for a &lt;code&gt;directory&lt;/code&gt; to current pagination support it have gone through many revisions and design iterations and now i have much clearer idea about how to architect/wrap a big enough piece of functionality. I wanted the app to be end to end, but this also put extra pressure on app to be responsive enough for all user events. Current indexing code is capable of providing rich details such as directory currently being scanned, estimated time (eta) and allows robust Cancellation of an ongoing task/threads. 
It has not been easy to model such communication b/w concurrent tasks and touches upon much discussed &lt;code&gt;structured-concurrency&lt;/code&gt; debate i.e how to run multiple tasks asynchronously, while being able to robustly cancel them at any point in time, all while being able to collect all errors cleanly!&lt;/p&gt;
    &lt;p&gt;From C days, i have been a user of (Posix) &lt;code&gt;threads&lt;/code&gt; type implementations, since major OSes provide those minimal but stable APIs, it helps me during context switching to different languages. Both C and Nim expose that, Python itself let the OS manage threads without its own runtime implementation, but bypassing the GIL when makes sense is something user have to do to fully utilize the resources! Also this kind of code requires user to handle a lot of code as to communicate b/w threads but atleast i (think) understand the basic ideas to prevent deadlocking if occurs and iron out initial bugs. As you run such threads deeper and deeper inside application stack , it keeps getting harder to communicate information back to the client. But when it starts working, it is really cool to have a central interface to see all the stuff backend is doing and predict very good ETA !&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Flask&lt;/code&gt; was initially used to easily map &lt;code&gt;functions&lt;/code&gt; to a particular route/url to wrap up initial implementation, current implementation now just uses &lt;code&gt;werkzeug&lt;/code&gt; (main engine behind flask) directly, hence doing away with a lot of unrequired dependencies like a template engines that Flask ships with. Even though this would not effect the end user in any visible way, this has been a very nice quality-of-life improvement like stuff for me as a developer. Since werkzeug is pure python, it can now be shipped/bundled directly as source code. Also each request is now handled by an available thread (from a pool) by reading &lt;code&gt;http environment&lt;/code&gt; from a shared queue following conventional model. By default for multi-threaded option, werkzeug would create a new fresh thread for handling that request. This does away with lots of OS/system calls for each new request and latency now seems more consistent and predictive. I have also  stumbled upon a pattern to actually make it easier to &lt;code&gt;mount&lt;/code&gt; multiple &lt;code&gt;apps&lt;/code&gt;  cleanly given i never liked and even understood the &lt;code&gt;blueprint&lt;/code&gt; that flask offers to make it easier to distribute the logic of your app to other modules too.
Since WSGI protocol just expect a callable python object, it should be much easier to develop independent apps without having any knowledge where it would be called/used. It also makes it quite fun to actually write/expose python code to handle client inputs. &lt;/p&gt;
    &lt;code&gt;class SimpleApp():
    """Each instance could be used a WSGI compatible callable"""
    def __init__(self, allow_local_cors:bool = False):
        self.initialized = False
        self.http_methods = ["GET", "POST", "PUT", "DELETE", "OPTIONS"] 
        self.url_map = None # we will lazily initialize it!
        self.extension_prefix = "ext" # as apps would be registered/
        self.registered_extensions:dict[str, SimpleApp] = {}

        ....

    def add_url_rule(self
                     rule:str, 
                     view_function:Callable, # corresponding view.
                     endpoint:Optional[str] = None, # set to view_function
                     methods:list[str]= ["GET"]):

        ... # some validation code.

        self.endpoint_2_uri[endpoint] = (Rule
            (rule, endpoint = endpoint), methods
            )
        self.endpoint_2_viewFunction[endpoint]  = view_function
        self.initialized = False

    def register(self, app:SimpleApp, name:str):
        """
        Here we register another such `app`.
        It would be mounted at `/ext/&amp;lt;name&amp;gt;` , so all requests to /ext/&amp;lt;name&amp;gt;/&amp;lt;route&amp;gt;, would be forwarded to this `app` .
        """

        ... # some validation code.
        self.registered_extensions[name] = app
        print("Extension registered at: {}/{}".format(self.extension_prefix, name))


    def __call__(self, environ, start_response) -&amp;gt; Iterable[bytes]:
        # This is called 
        if not (self.initialized):
            print("[Initializing]: Parent")
            self.initialize()

        for ext in self.registered_extensions:
            if not (self.registered_extensions[ext].initialized):
                print("[Initializing]: {}".format(ext))
                self.registered_extensions[ext].initialize()

        # If a call to such an extension.. we modify the environment a bit.
        active_app = self
        extension_name = None
        temp_path = environ['PATH_INFO']
        temp_split = temp_path.split("/")
        if temp_split[1] == self.extension_prefix:

            extension_name = temp_split[2]
            assert extension_name in self.registered_extensions, 
            extension_path = temp_path.replace("/{}/{}".format(self.extension_prefix, extension_name), "")


            environ['PATH_INFO'] = extension_path
            environ['REQUEST_URI'] = extension_path
            environ['RAW_URI'] = extension_path

            active_app = self.registered_extensions[extension_name]

    ## -----------------------------------------------
    # NOTE: only werkzeug specific code is here!
    # ---------------------------------------------
    request = Request(environ = environ) # minimal wrapping code!
    urls = active_app.url_map.bind_to_environ(environ)
    endpoint, args = urls.match()

    # view function can choose to return iterable[bytes] are the result of view function or call , or further wrap it to be as expected by werkzeug!
    iterable_bytes = active_app.endpoint_2_viewFunction[endpoint](request, **args) 
    return iterable_bytes  # as WSGI protocol expects!
    # ---------------------------------------------------------
&lt;/code&gt;
    &lt;p&gt;Note that, any existing Python object, can be made to accept &lt;code&gt;client&lt;/code&gt; requests on demand by adding very minimal code and could be done for selective functionality. For example, during setup of a new android device, i may have to ask user to choose one of the existing &lt;code&gt;devices&lt;/code&gt;, this kind of interactive input can be modeled easily now, as i just add a new routine in the Corresponding class to accept requests on a route such as &lt;code&gt;/ext/android/beginSetup&lt;/code&gt;, once i get that, all the existing logic already written could be used to finish setup. It is as easy as &lt;code&gt;parent_app.register(app = thisApp, name = "android")&lt;/code&gt; to start routing corresponding requests to this app!&lt;/p&gt;
    &lt;head rend="h2"&gt;ML:&lt;/head&gt;
    &lt;p&gt;Machine learning is being powered by a framework written completely in Nim, most of work was done on that framework before i even stared working on this project. This has allowed me to wrap CLIP and Face-Recognition Pipeline along with the application while only depending on OneDNN for some routines. OneDNN (mkldnn) (https://github.com/uxlfoundation/oneDNN) is one of the libraries to speed up various Deep learning operations with great documentation.&lt;/p&gt;
    &lt;p&gt;Ported models run faster on intel/Amd Cpus than pytorch counterparts, owing to fusion of operations like Batch Normalization and Convolution, and high re-use of pre-allocated memory (similar to in-place operations). Current &lt;code&gt;torch.compile&lt;/code&gt; like engine would end up making some of those optimizations after analyzing the graph, but for at-least 2.0 version it is not supported on Windows for me to compare against!&lt;/p&gt;
    &lt;p&gt;It took a lot of effort during one-two years i was working on it to be complete enough for me to start porting Deep-learning models using it. Also OneDNN shifted to V3 during that time, and only some code was updated to newer API and this has left the project in a unstable state with no visible stable APIs for users to work with. For each model i have to manually analyze the locations/requirements for fusion of operations, port quite a lot of pre-processing and post-processing code to make it end to end. These reasons contributed to a lot of technical debt, which i have not found the resources to tackle yet. Without removing that debt it never made sense to open-source it, besides there are now projects like GGML, and tiny-grad to serve inference only needs with minimal resources!&lt;/p&gt;
    &lt;p&gt;Porting of each model is quite an involved task, as you have to read enough papers to understand ideas about model if want to later fine-tune that model too. You may want to find first find or create a simpler implementation in pytorch to make it easier to port to a new language. All experimentation could be done in pytorch/python, for example i experimented with alternate quantized attention layers for CLIP model, and it indeed had a better performance for eval datasets mentioned in CLIP paper. Tangentially it was really cool to read through Open-AI implementations and papers, papers were written in an approachable manner to let the read indulge in hypothesis, codebases were clean with minimal dependencies. Its really a shame what that company/organisation chose to become under the guise of "user-safety" effectively clipping the (open) ethos of this field, but at same time i am grateful for all the researchers' work in this current DL/ML era and seeing the evolution of this field in such an open manner!&lt;/p&gt;
    &lt;p&gt;I would like to work on the project though atleast enough to tackle that debt and open-source it in state for users to extend upon, if found useful. Even though i am using OneDNN for some routines, i think it is better to have a common and easier to extend codebase to allow more experimentation and aggressive optimizations , but this itself is a huge-task and now with multiple GPU architectures its just something that couldn't be tackled without a lot of time and money. Even in this age where H100 is the baseline for benchmarks in testing, i find it worthwhile to work on a minimal DL Compiler to just tackle ARM/Intel/Risc Cpus to start taking advantage of these cheaper machines. Being able to pin-point a tennis ball in a 3D space remains the dream !&lt;/p&gt;
    &lt;head rend="h2"&gt;Frontend / App:&lt;/head&gt;
    &lt;p&gt;Current front-end is completely written in Html, Js(Ts) and (tailwind) css as multi page webapp. Earlier frontend was written in Svelte, but lack of internal documentation and too much "magic" became too "viral" for me to handle. For me, abstractions and APIs exposed by Browsers are more than enough to maintain required precision during DOM updates. Care is taken to use batch updates, prevent redundant rendering, judicial usage of resources to prevent unrequired pressure through pagination, even for a local backend server. It has passed our litmus test for search over 180 Gb of indexed Pexels dataset on a (minimal) remote server. My friend Akshay helped a lot in frontend development, testing various datasets and offering detailed bug reports which helped uncover a lot of edge cases during development of the project. There would always be room for improvements on the UX/UI side, but we have found it is much easier to extend and improve frontend with a stable backend!&lt;/p&gt;
    &lt;p&gt;Pexels dataset: https://huggingface.co/datasets/opendiffusionai/pexels-photos-janpf&lt;/p&gt;
    &lt;p&gt;Apart from webapp, there is also a Windows App, which under the hood uses the &lt;code&gt;webview&lt;/code&gt; to render the frontend. All native Windows APIs remain available to use from the Nim code, which puts it into a hybrid category. It is not ideal, but atleast it doesn't require me to ship a full web-browser, which i think is waste of compute resources, but at the same time leaves me wondering how current GUI development became so resource intensive for a single developer to manage while offering little benefits! I have been looking into forks of earlier GTK versions for linux to keep the complexity/learning contained, but that also seems nothing less than an adventure!  &lt;/p&gt;
    &lt;head rend="h2"&gt;Tools/libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Nimpy (https://github.com/yglukhov/nimpy) : A minimal python-Nim bridge to make it easier to write extensions in Nim to be called from python and to use python modules in Nim. Unlike many such bridges which includes a lot of boiler-plate code, there are no complex classes/interfaces to be included in the extension. It targets necessary features like marshaling of native python types to and from Nim, targets the minimal Python API to not depend on python versions, finding underlying python.dll at runtime.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stb Image (https://github.com/nothings/stb): A big fan of such single header libraries, this one implements encoders for most of image formats in pure C. Its very easy to modify it pass pointer to the raw-data and writing raw-data to a pre-allocated memory saving costly memory copying particularly visible for 4k photos! It helps remove dependency on OpenCV for image reading ! Nim made it very easy to just compile this along with other Nim code.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;LibWebp (https://github.com/webmproject/libwebp): Allows decoding and encoding for webp formats, Though documentation is a bit sparse on some internal API usage, lot of examples are included in the repository to read. I managed to use&lt;/p&gt;&lt;code&gt;argb&lt;/code&gt;field directly to pass&lt;code&gt;argb&lt;/code&gt;format data to do away with transformation logic and some (memory) allocations. It follows callback passing convention to implement custom behaviour like a progress bar and to write encoded data to a user provided buffer. Written completely in C and very easy to compile and read, it is being used for writing image previews, helping remove dependency on OpenCV.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Zig-cc (https://ziglang.org): Using&lt;/p&gt;&lt;code&gt;zig/clang&lt;/code&gt;as a C compiler, allowed me to easily cross-compile a lot of Nim code for Linux, targeting&lt;code&gt;2.27 libc&lt;/code&gt;. Making it easier to set a LibC target has proved very useful to bypass that&lt;code&gt;libC&lt;/code&gt;mismatching stuff! Really cool work by Zig community to tackle a lot of such technical debt to make software development much easier !&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As mentioned earlier i try to use a lot of existing open-source code if i can, even it would be for reading/understanding purposes only. It still blows my mind even after many years, to just read/understand some complex implementation and modify it for personal use-case for Free. For example even though &lt;code&gt;OpenCV&lt;/code&gt; is a big/complex dependency, its still has a very readable codebase and i read code from it a few times during this project to understand differences b/w my port and OpenCV one.&lt;/p&gt;
    &lt;p&gt;Being able to integrate multiple languages has its own challenges too, as it would require us to understand boundaries, internal details, assumptions that each runtime would want developer to respect. It gets complex to reproduce and understand bugs while running multiple multi-threaded runtimes as debugging gets more difficult. Debugging is one of things i would like to get better at, i have very limited knowledge of GDB as of now, which is expected to be table stakes for debugging in such environments. I have had some nasty bugs , but being able to compile all required pieces made it a bit easier to debug even with print-style debugging :)&lt;/p&gt;
    &lt;head rend="h2"&gt;Current State:&lt;/head&gt;
    &lt;p&gt;A lot of functionality is working, than not and having tested over 500k images i could be a bit satisfied about internals' performance and robustness. I would like to say that it can easily handle 10 millions of images/resources, and there is nothing to suggest that it won't, but it is different from using a production database to extrapolate the performance confidently. Despite writing from (almost) scratch in a number of languages, both indexing and inferencing pipeline are more expressive, robust and faster than many similar images search apps, but benchmarking for such complex apps could be subjective and more so when you mix in semantic search.&lt;/p&gt;
    &lt;p&gt;There are still some hardcoded constants and also intentionally some low performing components, like using ViT B/32 variant of CLIP model, which are acting as placeholders, and would be replaced easily with better counterparts in the future.&lt;/p&gt;
    &lt;p&gt;It has been tested on Windows 10/11 and on Fedora 42/43 with an assumption of &lt;code&gt;x64&lt;/code&gt; architecture. Compiled extensions are also packaged to quickly test the application, but users are free to compile code as they see fit. Linux shared objects target &lt;code&gt;LibC 2.27&lt;/code&gt;, so should work on most of recent distributions out of the box. Except some ML code there is main requirement of any/a C compiler to further extend the codebase by the user. Most of testing is done on my Laptop with  &lt;code&gt;i5-8300H&lt;/code&gt; processor and 8 GB memory. I don't have a MacOS to test on, ML code would need to be modified to target ARM architecture, except that very minor modifications should be needed if any. It is quite possible for initial users to encounter minor bugs, due to its limited run in diverse dev environments, but installation and usage on Cloud servers during testing has been quite smooth.&lt;/p&gt;
    &lt;p&gt;Below is a video showcasing workflow to index data from multiple MTP/Android devices. (Still a WIP).&lt;/p&gt;
    &lt;head rend="h2"&gt;Random Thoughts/Philosophy:&lt;/head&gt;
    &lt;p&gt;I think it gets easier with time to grok larger codebases to isolate/find the functionality/implementation reader would be interested in. Most of mature codebases are organized to help navigating the source-tree anyway, and have detailed documentation. Being able to have enough patience to make yourself comfortable is a necessary part of growing as a developer, as initial documentation/codebase would always seem alien and big enough to trigger that flight reaction!&lt;/p&gt;
    &lt;p&gt;Batching and Caching are two generic strategies that could be applied to speed up most of bottleneck portions. Both strategies lead to better/denser utilization of CPUs by (trying to) minimise the costly load/store instructions during a hot loop. Batching for example could do it by allocating necessary memory up-front for a batch and de-allocating all at once when no longer required, reducing the number of costly system-calls. Caching may involve designing or using a (hardware)cache friendly data-structure, when it is possible to do so.&lt;/p&gt;
    &lt;p&gt;Each optimization would involve assumptions and each subsequent optimization would become harder and harder to implement, may preventing the clean refactoring of code when future functionalities may need to be accommodated. It itself is a kind of rabbit-hole, and user should know when to stop as there would always be something else to be optimized!&lt;/p&gt;
    &lt;p&gt;With (coding) tools involving AI/LLMs it is easier than ever to get a piece of desired functionality, as a developer i understand it is another useful tool in a long-history of improvements, that most of developers would come to use in their workflow. Current LLMs have undeniable ability to handle complex instructions, explain non-trivial code and that so for various mixed modalities! It has been a bit unreasonable to end up with such abilities with just next token prediction as primary objective, even for a researcher working in this field. My usage for such tools is only through a (free) search engine(s), Although for now there has been no scenario in such tools have helped me, that i wouldn't have got to using traditional means. But i can admit such tools/engines are really effective in helping us to get unstuck in a variety of situations, arguably helping us to learn faster. &lt;code&gt;Functions/routines&lt;/code&gt; are nice and enough abstractions to provide enough context to such engines, to get the required help, without ever needing &lt;code&gt;review/edit/rewrite&lt;/code&gt; cycle.&lt;lb/&gt; I have always been benefited from visiting the original documentation, if AI is spitting out good enough arguments, there must be a good documentation out there for that topic . Our minds capability to extract abstract patterns resulted from studying one topic and applying it to another seemingly unrelated domain is uncanny to say the least. Also tone/motivation for developer writing about a topic matters to me, and many times i have visited a concept further just because writer himself/herself was very excited about it . Again, these are just personal factors and biases and people should be free to choose workflow they feel most comfortable in , without any judgments from either side.&lt;lb/&gt; It has been difficult to access SOTA models actual abilities, with fewer and fewer details being published for each newer version, but it has been a wild-ride for me to see the evolution from RNNs to bi-directional RNNs to LSTMs to Transformer architecture (finally founding atleast one stable architecture be able to support training on whole internet without exploding or vanishing gradients). Arguably there are also more more open family of models like &lt;code&gt;Qwen&lt;/code&gt; or &lt;code&gt;Deepseek&lt;/code&gt; from other labs which could run on local infrastructure. Even at this stage, ideas behind LLMs are simple enough for anybody to understand without burdening them with terms like AGI . There is already great work from OLMO and Smollm  to build upon and start with, for personal needs, without spending a lot of money. On technical front  there is still much more to explore and it comes down to doing more experiments by smaller companies to prevent ending up with another monopoly/duopoly in this field only to later blame such for their incompetence!&lt;lb/&gt; I literally have no idea what would be the end game with this ever increasing ability of AI models and what social consequences we would end up with in an already fragmented and struggling world. But it would be a mistake to abandon learning, however inconvenient it may seem at any time, if we were to survive ! &lt;lb/&gt; Thing that really boils my blood is these (AI) companies lawless laundering of all the open-source code, art, poetry without any attribution only to be packaged as a product for users to pay for. Constant attacks on all the infrastructure even run by very small or single-developer companies/communities, not respecting any of the &lt;code&gt;robots.txt&lt;/code&gt;, proxying through residential networks, damaging the very core of the information-sharing/internet while coming up with ironical headlines is bordering on criminal-behaviour for me! Waiting for tens of seconds just for a (community written) stack-overflow post through many layers of security, for wanting to understand various perspectives for some concept without all the bullshit summarization, is new bleak reality with nothing for end-users to have a say in.  &lt;/p&gt;
    &lt;p&gt;Despite the dominant usage of LLMs there exist equally interesting smaller models/architectures representing the huge potential that this field of deep-learning holds. Neural-networks allow us to (good enough)model any arbitrary function/flow using an iterative framework from a few thousand samples representing the function space, effectively equipping us with a very power statistical tool Self-supervised learning don't even need explicit outputs, how cool is that.. See https://ai.meta.com/blog/dino-v2-computer-vision-self-supervised-learning/ this work for more information. to introduce a new independent signal to reduce the entropy of the problem in many domains. I am a fan of smaller personalized models' potential to tackle everyday problems, and myself uses cheap off-the-self cameras coupled with a DL model to detect those Damn Monkeys, and for local voice-synthesis. Monkey Capturing was even on the manifesto of one of the candidates at city-level elections! In country like India, where even (traditional) Automation is limited to products of very few big companies, I can't help smiling whenever i point remote at my "AI" controlled AC :)&lt;/p&gt;
    &lt;p&gt;Living in a two-tier town in northern India with very minimal fixed-costs has allowed me to work on this for quite a long time without any savings or continuous financial freedom. But i cannot be a hypocrite about it, as it was a conscious decision to learn, explore and implement some of the ideas i had for some time. In return, this has allowed me to stay in touch with friends, played a lot of outdoor games, and help me in reflecting on the things i would want to spend more time in future.&lt;/p&gt;
    &lt;p&gt;Timely financial grants during the last one and half year from Samagata foundation and FossUnited has allowed me to complete a bulk of work to point, where i am satisfied with the current state of the project, for which i will always be grateful.&lt;/p&gt;
    &lt;p&gt;I would very much like to continue on this or adjacent projects, as there are still a lot of ideas and code pending, to make it a very stable everyday engine for users to use . But for that i will have to figure out a way to sustain this , without ever compromising the Core features/functionality in any way, As those were some of reasons i started working on it in the first place! Extensions to allow indexing remote storage like Google Drive or Android devices smoothly from the app itself seems like a good direction in that regard for now!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46087549</guid><pubDate>Sat, 29 Nov 2025 13:56:04 +0000</pubDate></item></channel></rss>