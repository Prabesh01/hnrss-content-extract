<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Sep 2025 10:11:00 +0000</lastBuildDate><item><title>Learning Persian with Anki, ChatGPT and YouTube</title><link>https://cjauvin.github.io/posts/learning-persian/</link><description>&lt;doc fingerprint="9290b055cdb636d2"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been learning Persian (Farsi) for a while now, and I’m using a bunch of tools for it. The central one is certainly Anki, a spaced repetition app to train memory. I’m creating my own never-ending deck of cards, with different types of content, for different purposes. The most frequent type of cards is grammar focused phrases (very rarely single words) coming sometimes from my own daily life, but also very often directly from videos of the Persian Learning YouTube channel, created by Majid, a very talented and nice Persian teacher, in my opinion.&lt;/p&gt;
    &lt;p&gt;Let’s take an example, suppose there is this slide in one of Majid’s videos:&lt;/p&gt;
    &lt;p&gt;From this, I will extract three screenshots (with the MacOS screenshot tool). First, to create a card of type “basic” (one side). I use this type of card to exercise my reading, which is very difficult and remains stubbornly slow, even though I know the 32 letters of the Persian alphabet quite well by now. But the different ways of writing them (which varies by their position in the word) and the fact that the vowels are not present makes it an enduringly challenging task.&lt;/p&gt;
    &lt;p&gt;The next type of card I create with the two remaining screenshots is “basic and reversed”, which actually creates two cards (one for each direction), one with some romanized phrase, and the other with the English or French translation:&lt;/p&gt;
    &lt;p&gt;When I review these cards in my daily Anki routine, this is where ChatGPT enters into play. First I have set a “Persian” project with these instructions:&lt;/p&gt;
    &lt;p&gt;With this project, every time I have a doubt or don’t remember something in Anki, I just take a screenshot and paste it in the project:&lt;/p&gt;
    &lt;p&gt;With this, I have an instant refresher on any notion, in any context. Sometimes I need to do this over and over, before it gels into a deeper, more instant and visceral “knowledge”.&lt;/p&gt;
    &lt;p&gt;The next set of techniques is also based on YouTube. I use a Chrome extension called Dual Subtitles (which only works of course with videos having actual dual sources of subtitles):&lt;/p&gt;
    &lt;p&gt;The dual subtitles serve a couple of purposes: first as a source of new Anki cards (I create the cards directly, again with screenshots in the clipboard).&lt;/p&gt;
    &lt;p&gt;I also use the Tweaks for YouTube extension, which allows me to get extra keyboard shortcuts, to go back and forward only 1 second, instead of the built-in 5 seconds.&lt;/p&gt;
    &lt;p&gt;With these YouTube extensions, I have developed this particular “technique” to improve my vocal understanding:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I listen at 75% speed&lt;/item&gt;
      &lt;item&gt;I use the “dual subtitles” browser extension to have both the Farsi and English subtitles at the same time (I set the Farsi one slightly bigger)&lt;/item&gt;
      &lt;item&gt;Every time a new sentence appears, I read it very quickly first in English (I pause if I need to), and then I listen carefully to the voice, to let the meaning and sound of Farsi infuse my mind (this part is very subtle but the most important: you must “feel” that you understand, and this feeling must cover even the words that you don’t know; because the meaning of the sentence is currently present and active in your mind, because you just read the English part, I believe that its mapping with the Farsi words that you then hear is particularly efficient, at least that’s my theory)&lt;/item&gt;
      &lt;item&gt;I also read the Farsi script, to improve my understanding, and disambiguate certain words for which it’s hard for me to hear what is exactly said&lt;/item&gt;
      &lt;item&gt;I repeat out loud what has been said also, which is quite important&lt;/item&gt;
      &lt;item&gt;Most importantly: I repeat this process (for a single video) over and over, in order to reach a stage where I genuinely understand what is said, in real-time, which is a very powerful and exhilarating feeling.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359524</guid><pubDate>Wed, 24 Sep 2025 12:45:07 +0000</pubDate></item><item><title>How to Lead in a Room Full of Experts</title><link>https://idiallo.com/blog/how-to-lead-in-a-room-full-of-experts</link><description>&lt;doc fingerprint="f3751d93156404b7"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Here is a realization I made recently. I'm sitting in a room full of smart people. On one side are developers who understand the ins and outs of our microservice architecture. On the other are the front-end developers who can debug React in their sleep. In front of me is the product team that has memorized every possible user path that exists on our website. And then, there is me. The lead developer. I don't have the deepest expertise on any single technology.&lt;/p&gt;
      &lt;p&gt;So what exactly is my role when I'm surrounded by experts? Well, that's easy. I have all the answers.&lt;/p&gt;
      &lt;head rend="h2"&gt;Technical Leadership&lt;/head&gt;
      &lt;p&gt;OK. Technically, I don't have all the answers. But I know exactly where to find them and connect the pieces together. &lt;/p&gt;
      &lt;p&gt;When the backend team explains why a new authentication service would take three weeks to build, I'm not thinking about the OAuth flows or JWT token validation. Instead, I think about how I can communicate it to the product team who expects it done "sometime this week." When the product team requests a "simple" feature, I'm thinking about the 3 teams that need to be involved to update the necessary microservices.&lt;/p&gt;
      &lt;p&gt;Leadership in technical environments isn't about being the smartest person in the room. It's about being the most effective translator.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is a Social Skill&lt;/head&gt;
      &lt;p&gt;I often get "eye rolls" when I say this to developers: You are not going to convince anyone with facts. In a room full of experts, your technical credibility gets you a seat at the table, but your social skills determine whether anything productive happens once you're there.&lt;/p&gt;
      &lt;p&gt;Where ideally you will provide documentation that everyone can read and understand, in reality, you need to talk to get people to understand. People can get animated when it comes to the tools they use. When the database team and the API team are talking past each other about response times, your role isn't to lay down the facts. Instead it's to read the room and find a way to address technical constraints and unclear requirements. It means knowing when to let a heated technical debate continue because it's productive, and when to intervene because it's become personal.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is Remembering the Goal&lt;/head&gt;
      &lt;p&gt;When you are an expert in your field, you love to dive deep. It's what makes you experts. But someone needs to keep one eye on the forest while everyone else is examining the trees.&lt;/p&gt;
      &lt;p&gt;I've sat through countless meetings where engineers debated the merits of different caching strategies while the real issue was that we hadn't clearly defined what "fast enough" meant for the user experience. The technical discussion was fascinating, but it wasn't moving us toward shipping.&lt;/p&gt;
      &lt;p&gt;As a leader, your job isn't to have sophisticated technical opinions. It's to ask how this "discussion" can move us closer to solving our actual problem.&lt;/p&gt;
      &lt;p&gt;When you understand a problem, and you have a room full of experts, the solution often emerges from the discussion. But someone needs to clearly articulate what problem we're actually trying to solve.&lt;/p&gt;
      &lt;p&gt;When a product team says customers are reporting the app is too slow, that's not a clear problem. It's a symptom. It might be that users are not noticing when the shopping cart is loaded, or that maybe we have an event that is not being triggered at the right time. Or maybe the app feels sluggish during peak hours. Each of those problems has different solutions, different priorities, and different trade-offs. Each expert might be looking at the problem with their own lense, and may miss the real underlying problem.&lt;/p&gt;
      &lt;p&gt;Your role as a leader is to make sure the problem is translated in a way the team can clearly understand the problem.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is Saying "I Don't Know"&lt;/head&gt;
      &lt;p&gt;By definition, leading is knowing the way forward. But in reality, in a room full of experts, pretending to know everything makes you look like an idiot.&lt;/p&gt;
      &lt;p&gt;Instead, "I don't know, but let's figure it out" becomes a superpower. It gives your experts permission to share uncertainty. It models intellectual humility. And it keeps the focus on moving forward rather than defending ego. It's also an opportunity to let your experts shine.&lt;/p&gt;
      &lt;p&gt;Nothing is more annoying than a lead who needs to be the smartest person in every conversation. Your database expert spent years learning how to optimize queries - let them be the hero when performance issues arise. Your security specialist knows threat models better than you, give them the floor when discussing architecture decisions.&lt;/p&gt;
      &lt;p&gt;Make room for some productive discussion. When two experts disagree about implementation approaches, your job isn't to pick the "right" answer. It's to help frame the decision in terms of trade-offs, timeline, and user impact.&lt;/p&gt;
      &lt;p&gt;Your value isn't in having all the expertise. It's in recognizing which expertise is needed when, and creating space for the right people to contribute their best work. &lt;/p&gt;
      &lt;head rend="h3"&gt;The Translation Challenge&lt;/head&gt;
      &lt;p&gt;There was this fun blog post I read recently about how non-developers read tutorials written by developers. What sounds natural to you, can be complete gibberish to someone else. As a lead, you constantly need to think about your audience. You need to learn multiple languages to communicate the same thing:&lt;/p&gt;
      &lt;p&gt;Developer language: "The authentication service has a dependency on the user service, and if we don't implement proper circuit breakers, we'll have cascading failures during high load."&lt;/p&gt;
      &lt;p&gt;Product language: "If our login system goes down, it could take the entire app with it. We need to build in some safeguards, which will add about a week to the timeline but prevent potential outages."&lt;/p&gt;
      &lt;p&gt;Executive language: "We're prioritizing system reliability over feature velocity for this sprint. This reduces risk of user-facing downtime that could impact revenue."&lt;/p&gt;
      &lt;p&gt;All three statements describe the same technical decision, but each is crafted for its audience. Your experts shouldn't have to learn product speak, and your product team shouldn't need to understand circuit breaker patterns. But someone needs to bridge that gap.&lt;/p&gt;
      &lt;head rend="h2"&gt;Beyond "Because, that's why!"&lt;/head&gt;
      &lt;p&gt;"I'm the lead, and we are going to do it this way." That's probably the worst way to make a decision. That might work in the short term, but it erodes trust and kills the collaborative culture that makes expert teams thrive.&lt;/p&gt;
      &lt;p&gt;Instead, treat your teams like adults and communicate the reason behind your decision:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;"We're choosing the more conservative approach because the cost of being wrong is high, and we can iterate later."&lt;/item&gt;
        &lt;item&gt;"I know this feels like extra work, but it aligns with our architectural goals and will save us time on the next three features."&lt;/item&gt;
        &lt;item&gt;"This isn't the most elegant solution, but it's the one we can ship confidently within our timeline."&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The more comfortable you become with not being the expert, the more effective you become as a leader.&lt;/p&gt;
      &lt;p&gt;When you stop trying to out-expert the experts, you can focus on what expert teams actually need:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Clear problem definitions&lt;/item&gt;
        &lt;item&gt;Context for decision-making&lt;/item&gt;
        &lt;item&gt;Translation between different perspectives&lt;/item&gt;
        &lt;item&gt;Protection from unnecessary complexity&lt;/item&gt;
        &lt;item&gt;Space to do their best work&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Your role isn't to have all the answers. It's to make sure the right questions get asked, the right people get heard, and the right decisions get made for the right reasons.&lt;/p&gt;
      &lt;p&gt;Technical leadership in expert environments is less about command and control, and more about connection and context. You're not the conductor trying to play every instrument. You're the one helping the orchestra understand what song they're playing together.&lt;/p&gt;
      &lt;p&gt;That's a much more interesting challenge than trying to be the smartest person in the room.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359604</guid><pubDate>Wed, 24 Sep 2025 12:52:52 +0000</pubDate></item><item><title>Smartphone Cameras Go Hyperspectral</title><link>https://spectrum.ieee.org/hyperspectral-imaging</link><description>&lt;doc fingerprint="77951f9c0a9da747"&gt;
  &lt;main&gt;
    &lt;p&gt;The human eye is mostly sensitive to only three bands of the electromagnetic spectrum—red, green, and blue (RGB)—in the visible range. In contrast, off-the-shelf smartphone camera sensors are potentially hyperspectral in nature, meaning that each pixel is sensitive to far more spectral bands. Now scientists have found a simple way for any conventional smartphone camera to serve as a hyperspectral sensor—by placing a card with a chart on it within its view. The new patent-pending technique may find applications in defense, security, medicine, forensics, agriculture, environmental monitoring, industrial quality control, and food and beverage quality analysis, the researchers add.&lt;/p&gt;
    &lt;p&gt;“At the heart of this work is a simple but powerful idea—a photo is never just an image,” says Semin Kwon, a postdoctoral research associate of biomedical engineering Purdue University in West Lafayette, Ind. “Every photo carries hidden spectral information waiting to be uncovered. By extracting it, we can turn everyday photography into science.”&lt;/p&gt;
    &lt;p&gt;Using a smartphone camera and a spectral color chart, researchers can image the transmission spectrum of high-end whiskey, thus determining its authenticity. Semin Kwon/Purdue University&lt;/p&gt;
    &lt;p&gt;Every molecule has a unique spectral signature—the degree to which it absorbs or reflects each wavelength of light. The extreme sensitivity to distinguishing color seen in scientific-grade hyperspectral sensors can help them identify chemicals based on their spectral signatures, for applications in a wide range of industries, such as medical diagnostics, distinguishing authentic versus counterfeit whiskey, monitoring air quality, and nondestructive analysis of pigments in artwork, says Young Kim, a professor of biomedical engineering at Purdue.&lt;/p&gt;
    &lt;p&gt;Previous research has pursued a number of different ways to recover spectral details from conventional smartphone RGB camera data. However, machine learning models developed for this purpose typically rely heavily on the task-specific data on which they are trained. This limits their generalizability and makes them susceptible to errors resulting from variations in lighting, image file formats, and more. Another possible avenue involved special hardware attachments, but these can prove expensive and bulky.&lt;/p&gt;
    &lt;p&gt;In the new study, the scientists designed a special color reference chart that can be printed on a card. They also developed an algorithm that can analyze smartphone pictures taken with this card and account for factors such as lighting conditions. This strategy can extract hyperspectral data from raw images with a sensitivity of 1.6 nanometers of difference in wavelength of visible light, comparable to scientific-grade spectrometers.&lt;/p&gt;
    &lt;p&gt;“In short, this technique could turn an ordinary smartphone into a pocket spectrometer,” Kim says.&lt;/p&gt;
    &lt;p&gt;The scientists are currently pursuing applications for their new technique in digital and mobile-health applications in both domestic and resource-limited settings. “We are truly excited that this opens the door to making spectroscopy both affordable and accessible,” Kwon says.&lt;/p&gt;
    &lt;p&gt;The scientists recently detailed their findings in the journal IEEE Transactions on Image Processing.&lt;/p&gt;
    &lt;p&gt;Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45360824</guid><pubDate>Wed, 24 Sep 2025 14:20:33 +0000</pubDate></item><item><title>Show HN: Dayflow – A git log for your day</title><link>https://github.com/JerryZLiu/Dayflow</link><description>&lt;doc fingerprint="6ed6256e19be11b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Turns your screen activity into a clean timeline with AI summaries and distraction highlights.&lt;/p&gt;
    &lt;p&gt;Quickstart • Why I built Dayflow • Features • How it works • Installation • Data &amp;amp; Privacy • Debug &amp;amp; Developer Tools • Auto‑updates • Contributing&lt;/p&gt;
    &lt;p&gt;Dayflow is a native macOS app (SwiftUI) that records your screen at 1 FPS, analyzes it every 15 minutes with AI, and generates a timeline of your activities with summaries. It's lightweight (25MB app size) and uses ~100MB of RAM and &amp;lt;1% cpu.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Privacy‑minded by design: You choose your AI provider. Use Gemini (bring your own API key) or local models (Ollama / LM Studio). See Data &amp;amp; Privacy for details.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I built Dayflow after realizing that my calendar wasn't the source of truth for how I actually spent my time. My screen was. I wanted a calm, trustworthy timeline that let me see my workday without turning into yet another dashboard I had to maintain.&lt;/p&gt;
    &lt;p&gt;Dayflow stands for ownership and privacy by default. You control the data, you choose the AI provider, and you can keep everything local if that's what makes you comfortable. It's MIT licensed and fully open source because anything that watches your screen all day should be completely transparent about what it does with that information. The app should feel like a quiet assistant: respectful of your attention, honest about what it captures, and easy to shut off.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic timeline of your day with concise summaries.&lt;/item&gt;
      &lt;item&gt;1 FPS recording - minimal CPU/storage impact.&lt;/item&gt;
      &lt;item&gt;15-minute analysis intervals for timely updates.&lt;/item&gt;
      &lt;item&gt;Watch timelapses of your day.&lt;/item&gt;
      &lt;item&gt;Auto storage cleanup - removes old recordings after 3 days.&lt;/item&gt;
      &lt;item&gt;Distraction highlights to see what pulled you off‑task.&lt;/item&gt;
      &lt;item&gt;Native UX built with SwiftUI.&lt;/item&gt;
      &lt;item&gt;Auto‑updates with Sparkle (daily check + background download).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Infinitely customizable dashboard — ask any question about your workday, pipe the answers into tiles you arrange yourself, and track trends over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Daily journal — review the highlights Dayflow captured, reflect with guided prompts, and drop screenshots or notes alongside your generated timeline.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Capture — Records screen at 1 FPS in 15-second chunks.&lt;/item&gt;
      &lt;item&gt;Analyze — Every 15 minutes, sends recent footage to AI.&lt;/item&gt;
      &lt;item&gt;Generate — AI creates timeline cards with activity summaries.&lt;/item&gt;
      &lt;item&gt;Display — Shows your day as a visual timeline.&lt;/item&gt;
      &lt;item&gt;Cleanup — Auto-deletes recordings older than 3 days.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The efficiency of your timeline generation depends on your chosen AI provider:&lt;/p&gt;
    &lt;code&gt;flowchart LR
    subgraph Gemini["Gemini Flow: 2 LLM Calls"]
        direction LR
        GV[Video] --&amp;gt; GU[Upload + Transcribe&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GC[Generate Cards&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GD[Done]
    end

    subgraph Local["Local Flow: 33+ LLM Calls"]
        direction LR
        LV[Video] --&amp;gt; LE[Extract 30 frames] --&amp;gt; LD[30 descriptions&amp;lt;br/&amp;gt;30 LLM calls] --&amp;gt; LM[Merge&amp;lt;br/&amp;gt;1 call] --&amp;gt; LT[Title&amp;lt;br/&amp;gt;1 call] --&amp;gt; LC[Merge Check&amp;lt;br/&amp;gt;1 call] --&amp;gt; LMC[Merge Cards&amp;lt;br/&amp;gt;1 call] --&amp;gt; LD2[Done]
    end

    %% Styling
    classDef geminiFlow fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef localFlow fill:#fff8e1,stroke:#ff9800,stroke-width:2px
    classDef geminiStep fill:#4caf50,color:#fff
    classDef localStep fill:#ff9800,color:#fff
    classDef processing fill:#f5f5f5,stroke:#666
    classDef result fill:#e3f2fd,stroke:#1976d2

    class Gemini geminiFlow
    class Local localFlow
    class GU,GC geminiStep
    class LD,LM,LT,LC,LMC localStep
    class GV,LV,LE processing
    class GD,LD2 result
&lt;/code&gt;
    &lt;p&gt;Gemini leverages native video understanding for direct analysis, while Local models reconstruct understanding from individual frame descriptions - resulting in dramatically different processing complexity.&lt;/p&gt;
    &lt;p&gt;Download (end users)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Grab the latest &lt;code&gt;Dayflow.dmg&lt;/code&gt;from GitHub Releases.&lt;/item&gt;
      &lt;item&gt;Open the app; grant Screen &amp;amp; System Audio Recording when prompted:&lt;lb/&gt;macOS → System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording → enable Dayflow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build from source (developers)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Xcode 15+ and open &lt;code&gt;Dayflow.xcodeproj&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Run the &lt;code&gt;Dayflow&lt;/code&gt;scheme on macOS 13+.&lt;/item&gt;
      &lt;item&gt;In your Run scheme, add your &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;under Arguments &amp;gt; Environment Variables (if using Gemini).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0+&lt;/item&gt;
      &lt;item&gt;Xcode 15+&lt;/item&gt;
      &lt;item&gt;A Gemini API key (if using Gemini): https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download &lt;code&gt;Dayflow.dmg&lt;/code&gt;and drag Dayflow into Applications.&lt;/item&gt;
      &lt;item&gt;Launch and grant the Screen &amp;amp; System Audio Recording permission.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/JerryZLiu/Dayflow.git
cd Dayflow
open Dayflow.xcodeproj
# In Xcode: select the Dayflow target, configure signing if needed, then Run.&lt;/code&gt;
    &lt;p&gt;This section explains what Dayflow stores locally, what leaves your machine, and how provider choices affect privacy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;App support folder: &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recordings (video chunks): &lt;code&gt;~/Library/Application Support/Dayflow/recordings/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Local database: &lt;code&gt;~/Library/Application Support/Dayflow/chunks.sqlite&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recording details: 1 FPS capture, analyzed every 15 minutes, 3-day retention&lt;/item&gt;
      &lt;item&gt;Purge / reset tip: Quit Dayflow. Then delete the entire &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;folder to remove recordings and analysis artifacts. Relaunch to start fresh.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;These paths are created by the app at first run. If you package Dayflow differently or run in a sandbox, paths may vary slightly.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini (cloud, BYO key) — Dayflow sends batch payloads to Google’s Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Local models (Ollama / LM Studio) — Processing stays on‑device; Dayflow talks to a local server you run.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Short answer: There is a way to prevent Google from training on your data. If you enable Cloud Billing on at least one Gemini API project, Google treats all of your Gemini API and Google AI Studio usage under the “Paid Services” data‑use rules — even when you’re using unpaid/free quota. Under Paid Services, Google does not use your prompts/responses to improve Google products/models. &lt;list rend="ul"&gt;&lt;item&gt;Terms: “When you activate a Cloud Billing account, all use of Gemini API and Google AI Studio is a ‘Paid Service’ with respect to how Google Uses Your Data, even when using Services that are offered free of charge.” (Gemini API Additional Terms)&lt;/item&gt;&lt;item&gt;Abuse monitoring: even under Paid Services, Google logs prompts/responses for a limited period for policy enforcement and legal compliance. (Same Terms)&lt;/item&gt;&lt;item&gt;EEA/UK/Switzerland: the Paid‑style data handling applies by default to all Services (including AI Studio and unpaid quota) even without billing. (Same Terms)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A couple useful nuances (from docs + forum clarifications):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Studio is still free to use; enabling billing changes data handling, not whether Studio charges you. (Pricing page)&lt;/item&gt;
      &lt;item&gt;UI “Plan: Paid” check: In AI Studio → API keys, you’ll typically see “Plan: Paid” once billing is enabled on any linked project (UI may evolve).&lt;/item&gt;
      &lt;item&gt;Free workaround: “Make one project paid, keep using a free key elsewhere to get the best of both worlds.” The Terms imply account‑level coverage once any billing account is activated, but the Apps nuance above may limit this in specific UI contexts. Treat this as an interpretation, not legal advice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Privacy: With Ollama/LM Studio, prompts and model inference run on your machine. LM Studio documents full offline operation once models are downloaded.&lt;/item&gt;
      &lt;item&gt;Quality/latency: Local open models are improving but can underperform cloud models on complex summarization.&lt;/item&gt;
      &lt;item&gt;Power/battery: Local inference is GPU‑heavy on Apple Silicon and will drain battery faster; prefer plugged‑in sessions for long captures.&lt;/item&gt;
      &lt;item&gt;Future: We may explore fine‑tuning or distilling a local model for better timeline summaries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LM Studio offline: https://lmstudio.ai/docs/app/offline&lt;/item&gt;
      &lt;item&gt;Ollama GPU acceleration (Metal on Apple): https://github.com/ollama/ollama/blob/main/docs/gpu.md&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To record your screen, Dayflow requires the Screen &amp;amp; System Audio Recording permission. Review or change later at:&lt;lb/&gt; System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording.&lt;lb/&gt; Apple’s docs: https://support.apple.com/guide/mac-help/control-access-screen-system-audio-recording-mchld6aa7d23/mac&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Provider &lt;list rend="ul"&gt;&lt;item&gt;Choose Gemini (set &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;) or Local (Ollama/LM Studio endpoint).&lt;/item&gt;&lt;item&gt;For Gemini keys: https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Choose Gemini (set &lt;/item&gt;
      &lt;item&gt;Capture settings &lt;list rend="ul"&gt;&lt;item&gt;Start/stop capture from the main UI. Use Debug to verify batch contents.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Data locations &lt;list rend="ul"&gt;&lt;item&gt;See Data &amp;amp; Privacy for exact paths and a purge tip.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can click the Dayflow icon in the menu bar and view the saved recordings&lt;/p&gt;
    &lt;p&gt;Dayflow integrates Sparkle via Swift Package Manager and shows the current version + a “Check for updates” action. By default, the updater auto‑checks daily and auto‑downloads updates.&lt;/p&gt;
    &lt;code&gt;Dayflow/
├─ Dayflow/                 # SwiftUI app sources (timeline UI, debug UI, capture &amp;amp; analysis pipeline)
├─ docs/                    # Appcast and documentation assets (screenshots, videos)
├─ scripts/                 # Release automation (DMG, notarization, appcast, Sparkle signing, one-button release)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screen capture is blank or fails&lt;lb/&gt;Check System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording and ensure Dayflow is enabled.&lt;/item&gt;
      &lt;item&gt;API errors&lt;lb/&gt;Go into settings and verify your&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;and network connectivity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;V1 of the Dashboard (track answers to custom questions)&lt;/item&gt;
      &lt;item&gt;V1 of the daily journal&lt;/item&gt;
      &lt;item&gt;Fine tuning a small VLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;PRs welcome! If you plan a larger change, please open an issue first to discuss scope and approach.&lt;/p&gt;
    &lt;p&gt;Licensed under the MIT License. See LICENSE for the full text. Software is provided “AS IS”, without warranty of any kind.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sparkle for battle‑tested macOS updates.&lt;/item&gt;
      &lt;item&gt;Google AI Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Ollama and LM Studio for local model support.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361268</guid><pubDate>Wed, 24 Sep 2025 14:53:57 +0000</pubDate></item><item><title>How to be a leader when the vibes are off</title><link>https://chaoticgood.management/how-to-be-a-leader-when-the-vibes-are-off/</link><description>&lt;doc fingerprint="7a01915d36b1034c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Be a Leader When the Vibes Are Off&lt;/head&gt;
    &lt;head rend="h2"&gt;...and the vibes are definitely off&lt;/head&gt;
    &lt;p&gt;It feels different in tech right now. We’re coming off a long era where optimism carried the industry. Something has curdled. AI hype, return-to-office mandates, and continued layoffs have shifted the mood. Managers are quicker to fire, existential dread has replaced the confidence that a tight job market for developers provided for decades. The vibes are for sure off.&lt;/p&gt;
    &lt;head rend="h3"&gt;What’s Changed?&lt;/head&gt;
    &lt;p&gt;(What follows are generalizations. If your company is escaping some or all of these, I applaud you. I’m sure there are exceptions.)&lt;/p&gt;
    &lt;p&gt;AI has injected some destabilization. “I don’t need junior devs when I can just pay $20/month for Cursor” has an effect on everyone even if this turns out to be silly down the road. I see lots of people worried that the aim of all of this is to ultimately have a robot do their entire job. Whether or not this is possible doesn’t mean people aren’t going to try. And it’s the trying that raises people’s anxiety. On top of that, we’ve also got “AI Workslop” to contend with as well, which is making work harder for the diligent among us.&lt;/p&gt;
    &lt;p&gt;Return to Office feels like trust has been broken. Teams that continued to work well (or in some cases, better) after everyone in the industry went remote are now being told to come back to desks in offices. I’ve even heard tales of this happening despite there not being enough office space for everyone, which seems very silly. Also, for the first time in my nearly 30-year career, I’ve even heard of people being told they need to be “at their desks at 9am” and “expected to stay until 5pm at a minimum.” Even before COVID-19 and the mass move to remote work, most companies were flexible on start and stop times. I almost never heard of set hours for software developers until recently. Rules like that scream “we don’t trust you unless we can see you,” even if that’s not really the reason for the mandates. (IMO there are benefits to working in the same location as your colleagues but ham-fisted, poorly thought out mandates are not the way to achieve them.)&lt;/p&gt;
    &lt;p&gt;Layoffs changed the market. For probably 20 years, job security wasn’t really a concern in the industry. Layoffs happened here and there and companies folded, but the demand was always strong and most people capable of writing code or managing people who write code could lose their job, spend the severance on a nice vacation, and return with the confidence that they’d be able to land a new gig in a couple of weeks, likely at higher pay. With the acknowledgement that this was a privilege not enjoyed by most of the working world, it is no longer true. The size and scope of layoffs over the last couple of years have injected more anxiety into the tech workforce.&lt;/p&gt;
    &lt;p&gt;C-Suite Energy has changed. Across the board, execs seem more efficiency-focused, financialized, and less mission-driven. The days of “take care of the employees and the employees will take care of the business” feel like they’re in the rear-view mirror, and a new “do your job, or else!” mentality has taken its place.&lt;/p&gt;
    &lt;p&gt;You can’t change the macro forces that are driving these trends, but you can control how you show up for your team.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wearing the ‘Company Hat’ vs. Chaotic-Good Leadership&lt;/head&gt;
    &lt;p&gt;My standard advice to anyone with a management role and anyone at the Staff+ level of individual contributor is that “wearing the company hat” should be the default. You’re not always going to agree with the decisions that come down from the top. Even when you don’t agree with decisions the company leadership is making, part of your job is representing and facilitating those decisions with full alignment. When acting “in public” (all-hands, department meetings, the #general channel), this is mandatory, as contradicting the bosses in a broad forum can kill the credibility you have the leadership across the wider team. It’s also a good way to get yourself fired.&lt;/p&gt;
    &lt;head rend="h3"&gt;Let them know you’re still on their side&lt;/head&gt;
    &lt;p&gt;But you know what also kills trust? Telling your team it’s sunny out when everyone can plainly see that it’s raining. Your team is made up of smart adults who can, at the very least, count the number of employees and the number of desks and calculate that “everyone in the office on Wednesday” isn’t going to work out well if the people outnumber the chairs. Telling them something else is going to make you look like an idiot toady in their eyes.&lt;/p&gt;
    &lt;p&gt;The right thing to do in this situation is to acknowledge that you see the situation the same way they do, but do it privately, within your immediate team only or in 1-1s. “Yeah, this new policy sucks, I get it. It’s going to affect me in negative ways too.” It’s really important that you validate the emotions that all of these aspects are bringing up in people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Don’t pretend you can fix it&lt;/head&gt;
    &lt;p&gt;You can promise to advocate for saner policies when the opportunity arises if your sphere of influence makes that possible, but don’t promise to make the problem go away if you can’t. Broken promises and poor do/say ratio performance will also kill your team’s faith in you, especially when it’s about things they really care about. And again, this is not a time for grandstanding. In public, you have to support the policies, but when you’re in private with your manager and your peers, that’s the time you can safely push for change.&lt;/p&gt;
    &lt;head rend="h3"&gt;Find small workarounds to make things livable&lt;/head&gt;
    &lt;p&gt;If you can provide some flexibility on seemingly inflexible policies, do it. If your management role includes enforcing the company’s rules, you can use some discretion about how strictly you want to enforce them. Personally, I would never want to “rat out” a good performer who can’t get to their desk by 9am sharp because they have to drop off their kids or punish someone who bugged out early once to catch their favourite performer in concert one town over. Small acts demonstrating that you trust your team, even if the C-Suite doesn’t seem to trust the broader team the way they used to, can go a long way toward maintaining good morale within your group.&lt;/p&gt;
    &lt;p&gt;When things feel shaky in the broader org, people will look more to their direct leader for a sense of stability. The best thing you can do for them is provide it. Quiet honesty builds credibility and fosters loyalty.&lt;/p&gt;
    &lt;head rend="h2"&gt;This too shall pass&lt;/head&gt;
    &lt;p&gt;The industry is going through a period where a lot is changing all at once. We’ve had a few of them before. Things will eventually settle down into a new normal. I’m not great at predictions, so I’ll refrain from detailing what I think things will look like, but I don’t think it’ll be entirely unfamiliar to those who were here before this latest inflection point. This is especially true if leaders who care and treat their staff like adults can stay grounded and stay true to their principles, even when that means performing small, quiet acts of rebellion.&lt;/p&gt;
    &lt;p&gt;You can’t fix the macro trends, but you can try to keep your corner of the tech world a place where people are glad to work.&lt;/p&gt;
    &lt;p&gt;"Off Kilter" by anujd89 is licensed under CC BY 2.0 .&lt;/p&gt;
    &lt;p&gt;Like this? Please feel free to share it on your favourite social media or link site! Share it with friends!&lt;/p&gt;
    &lt;p&gt;Hit subscribe to get new posts delivered to your inbox automatically.&lt;lb/&gt;Feedback? Get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361394</guid><pubDate>Wed, 24 Sep 2025 15:03:59 +0000</pubDate></item><item><title>Python on the Edge: Fast, sandboxed, and powered by WebAssembly</title><link>https://wasmer.io/posts/python-on-the-edge-powered-by-webassembly</link><description>&lt;doc fingerprint="87ab2dfdccf438d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Python on the Edge: Fast, sandboxed, and powered by WebAssembly&lt;/head&gt;
    &lt;p&gt;We are excited to announce full Python support in Wasmer Edge (Beta)&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;With AI workloads on the rise, the demand for Python support on WebAssembly on the Edge has grown rapidly.&lt;/p&gt;
    &lt;p&gt;However, bringing Python to WebAssembly isn't trivial as it means supporting native modules like &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, and &lt;code&gt;pydantic&lt;/code&gt;.&amp;#13;
While projects like &lt;code&gt;pyodide&lt;/code&gt; made strides in running Python in the browser via WebAssembly, their trade-offs don't fully fit server-side needs.&lt;/p&gt;
    &lt;p&gt;After months of hard work, today we're thrilled to announce full Python support in Wasmer Edge (Beta) powered by WebAssembly and WASIX.&lt;/p&gt;
    &lt;p&gt;Now you can run FastAPI, Streamlit, Django, LangChain, MCP servers and more directly on Wasmer and Wasmer Edge! To accomplish it we had to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add support for dynamic linking (&lt;code&gt;dlopen&lt;/code&gt;/&lt;code&gt;dlsym&lt;/code&gt;) into WASIX&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;libffi&lt;/code&gt;support (so Python libraries using&lt;code&gt;ctypes&lt;/code&gt;could be supported)&lt;/item&gt;
      &lt;item&gt;Polish Sockets and threading support in WASIX&lt;/item&gt;
      &lt;item&gt;Release our own Python Package Index with many of the most popular Python Native libraries compiled to WASIX&lt;/item&gt;
      &lt;item&gt;Create our own alternative to Heroku Buildpacks / Nixpacks / Railpack / Devbox to automatically detect a project type from its source code and deploy it (including running with Wasmer or deploying to Wasmer Edge!). Updates will be shared soon!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How fast is it?&lt;/head&gt;
    &lt;p&gt;This Python release is much faster than any of the other Python releases we did in the past.&lt;/p&gt;
    &lt;p&gt;It is fast. Insa…natively fast (it's even faster than our py2wasm project!)&lt;/p&gt;
    &lt;code&gt;$ wasmer run python/python@=0.2.0 --dir=. -- pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.562538&amp;#13;
This machine benchmarks at 88882.9 pystones/second&amp;#13;
$ wasmer run python/python --dir=. -- pystone.py # Note: first run may take time&amp;#13;
Pystone(1.1) time for 50000 passes = 0.093556&amp;#13;
This machine benchmarks at 534439 pystones/second&amp;#13;
$ python3 pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.0827736&amp;#13;
This machine benchmarks at 604057 pystones/second
&lt;/code&gt;
    &lt;p&gt;That's 6x faster, and nearly indistinguishable from native Python performance… quite good, considering that your Python apps can now run fully sandboxed anywhere!&lt;/p&gt;
    &lt;p&gt;Note: the first time you run Python, it will take a few minutes to compile. We are working to improve this so no time will be spent on compilation locally.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;🚀 Even faster performance coming soon: we are trialing an optimization technique that will boost Python performance in Wasm to 95% of native Python speed. This is already powering our PHP server in production. Result: Near-native Python performance, fully sandboxed. Stay tuned!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What it can run&lt;/head&gt;
    &lt;p&gt;Now, you can run any kind of Python API server, powered by &lt;code&gt;fastapi&lt;/code&gt;, &lt;code&gt;django&lt;/code&gt;, &lt;code&gt;flask&lt;/code&gt;, or &lt;code&gt;starlette&lt;/code&gt;, connected to a MySQL database automatically when needed (FastAPI template, Django template).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;fastapi&lt;/code&gt; with websockets (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;mcp&lt;/code&gt; servers (deploy using our MCP template, demo).&lt;/p&gt;
    &lt;p&gt;You can run image processors like &lt;code&gt;pillow&lt;/code&gt;  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;ffmpeg&lt;/code&gt; inside Python (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;streamlit&lt;/code&gt; and &lt;code&gt;langchain&lt;/code&gt; (deploy using our LangChain template, demo).&lt;/p&gt;
    &lt;p&gt;You can even run &lt;code&gt;pypandoc&lt;/code&gt;!  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;Soon, we'll have full support for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;curl_cffi&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;polars&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gevent&lt;/code&gt;/&lt;code&gt;greenlet&lt;/code&gt;(more on this soon!)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Pytorch&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Wasmer VS alternatives&lt;/head&gt;
    &lt;p&gt;Python on Wasmer Edge is just launching, but it's already worth asking: how does it stack up existing solutions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Quick Comparison&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Feature / Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Wasmer Edge&lt;/cell&gt;
        &lt;cell role="head"&gt;Cloudflare&lt;/cell&gt;
        &lt;cell role="head"&gt;AWS Lambda&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Native modules (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, etc.)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported*&lt;/cell&gt;
        &lt;cell&gt;❌ Limited (no &lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Full support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multithreading &amp;amp; multiprocessing (&lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;pandoc&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ASGI / WSGI frameworks (&lt;code&gt;uvicorn&lt;/code&gt;, &lt;code&gt;daphne&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ Patched / limited&lt;/cell&gt;
        &lt;cell&gt;⚠️ Needs wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;WebSockets (&lt;code&gt;streamlit&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Raw sockets (&lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ JS &lt;code&gt;fetch&lt;/code&gt; only&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multiple Python versions&lt;/cell&gt;
        &lt;cell&gt;✅ In Roadmap (3.12, 3.14…)&lt;/cell&gt;
        &lt;cell&gt;❌ Tied to bundled runtime&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cold starts&lt;/cell&gt;
        &lt;cell&gt;⚡ Extremely fast&lt;/cell&gt;
        &lt;cell&gt;⏳ Medium (V8 isolates)&lt;/cell&gt;
        &lt;cell&gt;⏳ Slow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Code changes required&lt;/cell&gt;
        &lt;cell&gt;✅ None&lt;/cell&gt;
        &lt;cell&gt;⚠️ Some&lt;/cell&gt;
        &lt;cell&gt;⚠️ Wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pricing&lt;/cell&gt;
        &lt;cell&gt;💰 Affordable&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Cloudflare Workers (Python) / Pyodide&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;ℹ️ Most of the demos that we showcased on this article, are not runnable inside of Cloudflare:&lt;/p&gt;&lt;code&gt;ffmpeg&lt;/code&gt;,&lt;code&gt;streamlit&lt;/code&gt;,&lt;code&gt;pypandoc&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;Cloudflare launched Python support ~18 months ago, by using Pyodide inside workerd, their JavaScript-based Workers runtime.&lt;/p&gt;
    &lt;p&gt;While great for browser-like environments, Pyodide has trade-offs that make it less suitable server-side. Here are the limitations when running Python in Cloudflare:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ No support for &lt;code&gt;uvloop&lt;/code&gt;,&lt;code&gt;uvicorn&lt;/code&gt;, or similar event-native frameworks (JS event loop patches break compatibility with native).&lt;/item&gt;
      &lt;item&gt;❌ No pthreads or multiprocessing support, you can't call subprocesses like &lt;code&gt;ffmpeg&lt;/code&gt;or&lt;code&gt;pypandoc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;❌ No raw HTTP client sockets (HTTP clients are patched to use JS &lt;code&gt;fetch&lt;/code&gt;, no&lt;code&gt;libcurl&lt;/code&gt;available).&lt;/item&gt;
      &lt;item&gt;❌ Limited to a bundled Python version and package set.&lt;/item&gt;
      &lt;item&gt;⏳ Cold starts slower due to V8 isolate warmup.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limitations? Cloudflare relies on Pyodide: great in-browser execution, but server-side it implies no sockets, threads, or multiprocessing. The result: convenient for lightweight browser use, but might not be the best fit for real Python workloads on the server.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge runs real Python on WASIX unmodified, so everything "just works", with near-native speed and fast cold starts.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Amazon Lambda&lt;/head&gt;
    &lt;p&gt;AWS Lambda doesn't natively run unmodified Python apps:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ You need adapters (such as https://github.com/slank/awsgi or https://github.com/Kludex/mangum) for running your WSGI sites.&lt;/item&gt;
      &lt;item&gt;❌ WebSockets are unsupported.&lt;/item&gt;
      &lt;item&gt;⚠️ Setup is complex, adapters are often unmaintained.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limits? AWS Lambda requires you to use their HTTP lambda handler, which can cause incompatibility into your own HTTP servers. Also, because their lambda handlers are HTTP-based, there's no easy support for WebSockets.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge supports any Python HTTP servers without requiring any code adaptation from your side.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Why Wasmer Edge Stands Out&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Closer to native Python than Pyodide (no JS involvement at all).&lt;/item&gt;
      &lt;item&gt;Faster cold starts and more compatibility than Cloudflare's Workers.&lt;/item&gt;
      &lt;item&gt;More compatible than AWS Lambda (no wrappers/adapters).&lt;/item&gt;
      &lt;item&gt;More affordable across the board.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;🐍 It's Showtime!&lt;/head&gt;
    &lt;p&gt;Python support in Wasmer and Wasmer Edge is already available and ready to use. We have set up many Python templates to help you get started in no time.&lt;/p&gt;
    &lt;p&gt;https://wasmer.io/templates?language=python&lt;/p&gt;
    &lt;p&gt;To make things even better, we are working on a MCP server for Wasmer, so you will be able to plug Wasmer into ChatGPT or Anthropic and have your websites deploying from your vibe-coded projects. Stay tuned!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;⚠️ Python in Wasmer Edge is still in Beta, so expect some rough edges if your project doesn't work out of the box… if you encounter any issues, please report them so we can work on enabling your workloads on Wasmer Edge.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Create your first MCP Server in Wasmer&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to https://wasmer.io/templates/mcp-chatgpt-starter?intent=at_vRxJIdtPCbKe&lt;/item&gt;
      &lt;item&gt;Connect your Github account&lt;/item&gt;
      &lt;item&gt;Create a git repo from the template&lt;/item&gt;
      &lt;item&gt;Deploy and enjoy!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/python-mcp-chatgpt-starter&lt;/p&gt;
    &lt;head rend="h2"&gt;Create your first Django app&lt;/head&gt;
    &lt;p&gt;We have set up a template for using Django + Uvicorn in Wasmer Edge.&lt;/p&gt;
    &lt;p&gt;You can start using it very easily, just click Deploy: https://wasmer.io/templates/django-starter?intent=at_WK0DIkt3CeKX&lt;/p&gt;
    &lt;p&gt;Deploying a Django app will create a MySQL DB for you in Wasmer Edge (Postgres support is coming soon), run migrations and prepare everything to run your website seamlessly.&lt;/p&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/django-wasmer-starter&lt;/p&gt;
    &lt;p&gt;Ready to deploy your first Python app on Wasmer Edge?&lt;/p&gt;
    &lt;p&gt;Here are the best places to begin:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Starter Templates → Browse Python templates&lt;/item&gt;
      &lt;item&gt;📖 Docs &amp;amp; Examples → Wasmer GitHub&lt;/item&gt;
      &lt;item&gt;💬 Community Support → Join our Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;👉 Deploy your first Python app now&lt;/p&gt;
    &lt;p&gt;With WebAssembly and Wasmer, Python is now portable, sandboxed, and running at near-native speeds. Ready for AI workloads, APIs, and anything you can imagine at the edge.&lt;lb/&gt; The sky is the limit ❤️.&lt;/p&gt;
    &lt;head rend="h5"&gt;About the Author&lt;/head&gt;
    &lt;p&gt;Syrus Akbary is an enterpreneur and programmer. Specifically known for his contributions to the field of WebAssembly. He is the Founder and CEO of Wasmer, an innovative company that focuses on creating developer tools and infrastructure for running Wasm&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;How fast is it?&lt;/p&gt;
    &lt;p&gt;What it can run&lt;/p&gt;
    &lt;p&gt;Wasmer VS alternatives&lt;/p&gt;
    &lt;p&gt;Quick Comparison&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers (Python) / Pyodide&lt;/p&gt;
    &lt;p&gt;Amazon Lambda&lt;/p&gt;
    &lt;p&gt;Why Wasmer Edge Stands Out&lt;/p&gt;
    &lt;p&gt;🐍 It's Showtime!&lt;/p&gt;
    &lt;p&gt;Create your first MCP Server in Wasmer&lt;/p&gt;
    &lt;p&gt;Create your first Django app&lt;/p&gt;
    &lt;p&gt;Deploy your first Python site in seconds with our managed cloud solution.&lt;/p&gt;
    &lt;head rend="h5"&gt;Read more&lt;/head&gt;
    &lt;p&gt;wasmerwasmer edgerustprojectsedgeweb scraper&lt;/p&gt;
    &lt;head rend="h6"&gt;Build a Web Scraper in Rust and Deploy to Wasmer Edge&lt;/head&gt;
    &lt;p&gt;RudraAugust 14, 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362023</guid><pubDate>Wed, 24 Sep 2025 15:48:36 +0000</pubDate></item><item><title>SedonaDB: A new geospatial DataFrame library written in Rust</title><link>https://sedona.apache.org/latest/blog/2025/09/24/introducing-sedonadb-a-single-node-analytical-database-engine-with-geospatial-as-a-first-class-citizen/</link><description>&lt;doc fingerprint="3bdb989c4036eb8a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SedonaDB: A single-node analytical database engine with geospatial as a first-class citizen&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community is excited to announce the initial release of SedonaDB! ð&lt;/p&gt;
    &lt;p&gt;SedonaDB is the first open-source, single-node analytical database engine that treats spatial data as a first-class citizen. It is developed as a subproject of Apache Sedona.&lt;/p&gt;
    &lt;p&gt;Apache Sedona powers large-scale geospatial processing on distributed engines like Spark (SedonaSpark), Flink (SedonaFlink), and Snowflake (SedonaSnow). SedonaDB extends the Sedona ecosystem with a single-node engine optimized for small-to-medium data analytics, delivering the simplicity and speed that distributed systems often cannot.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ What is SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Written in Rust, SedonaDB is lightweight, blazing fast, and spatial-native. Out of the box, it provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ðºï¸ Full support for spatial types, joins, CRS (coordinate reference systems), and functions on top of industry-standard query operations.&lt;/item&gt;
      &lt;item&gt;â¡ Query optimizations, indexing, and data pruning features under the hood that make spatial operations just work with high performance.&lt;/item&gt;
      &lt;item&gt;ð Pythonic and SQL interfaces familiar to developers, plus APIs for R and Rust.&lt;/item&gt;
      &lt;item&gt;âï¸ Flexibility to run in single-machine environments on local files or data lakes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SedonaDB utilizes Apache Arrow and Apache DataFusion, providing everything you need from a modern, vectorized query engine. What sets it apart is the ability to process spatial workloads natively, without extensions or plugins. Installation is straightforward, and SedonaDB integrates easily into both local development and cloud pipelines, offering a consistent experience across environments.&lt;/p&gt;
    &lt;p&gt;The initial release of SedonaDB provides a comprehensive suite of geometric vector operations and seamlessly integrates with GeoArrow, GeoParquet, and GeoPandas. Future versions will support all popular spatial functions, including functions for raster data.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð SedonaDB quickstart example¶&lt;/head&gt;
    &lt;p&gt;Start by installing SedonaDB:&lt;/p&gt;
    &lt;code&gt;pip install "apache-sedona[db]"
&lt;/code&gt;
    &lt;p&gt;Now instantiate the connection:&lt;/p&gt;
    &lt;code&gt;import sedona.db

sd = sedona.db.connect()
&lt;/code&gt;
    &lt;p&gt;Let's perform a spatial join using SedonaDB.&lt;/p&gt;
    &lt;p&gt;Suppose you have a &lt;code&gt;cities&lt;/code&gt; table with latitude and longitude points representing the center of each city, and a &lt;code&gt;countries&lt;/code&gt; table with a column containing a polygon of the country's geographic boundaries.&lt;/p&gt;
    &lt;p&gt;Here are a few rows from the &lt;code&gt;cities&lt;/code&gt; table:&lt;/p&gt;
    &lt;code&gt;ââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
â     name     â            geometry           â
â   utf8view   â      geometry &amp;lt;epsg:4326&amp;gt;     â
ââââââââââââââââªââââââââââââââââââââââââââââââââ¡
â Vatican City â POINT(12.4533865 41.9032822)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â San Marino   â POINT(12.4417702 43.9360958)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â Vaduz        â POINT(9.5166695 47.1337238)   â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;And here are a few rows from the countries table:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââââââââââââââââââ
â             name            â   continent   â                      geometry                      â
â           utf8view          â    utf8view   â                geometry &amp;lt;epsg:4326&amp;gt;                â
âââââââââââââââââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââââââââââââââââââââââââââââââââ¡
â Fiji                        â Oceania       â MULTIPOLYGON(((180 -16.067132663642447,180 -16.55â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â United Republic of Tanzania â Africa        â POLYGON((33.90371119710453 -0.9500000000000001,34â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â Western Sahara              â Africa        â POLYGON((-8.665589565454809 27.656425889592356,-8â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;Hereâs how to perform a spatial join to compute the country of each city:&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select
    cities.name as city_name,
    countries.name as country_name,
    continent
from cities
join countries
where ST_Intersects(cities.geometry, countries.geometry)
"""
).show(3)
&lt;/code&gt;
    &lt;p&gt;The code utilizes &lt;code&gt;ST_Intersects&lt;/code&gt; to determine if a city is contained within a given country.&lt;/p&gt;
    &lt;p&gt;Here's the result of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬ââââââââââââââââââââââââââââââ¬ââââââââââââ
â   city_name   â         country_name        â continent â
â    utf8view   â           utf8view          â  utf8view â
âââââââââââââââââªââââââââââââââââââââââââââââââªââââââââââââ¡
â Suva          â Fiji                        â Oceania   â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dodoma        â United Republic of Tanzania â Africa    â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dar es Salaam â United Republic of Tanzania â Africa    â
âââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;The example above performs a point-in-polygon join, mapping city locations (points) to the countries they fall within (polygons). SedonaDB executes these joins efficiently by leveraging spatial indices where beneficial and dynamically adapting join strategies at runtime using input data samples. While many general-purpose engines struggle with the performance of such operations, SedonaDB is purpose-built for spatial workloads and delivers consistently fast results.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð Apache Sedona SpatialBench¶&lt;/head&gt;
    &lt;p&gt;To test our work on SedonaDB, we also needed to develop a mechanism to evaluate its performance and speed. This led us to develop Apache Sedona SpatialBench, a benchmark for assessing geospatial SQL analytics query performance across database systems.&lt;/p&gt;
    &lt;p&gt;Let's compare the performance of SedonaDB vs. GeoPandas and DuckDB Spatial for some representative spatial queries as defined in SpatialBench.&lt;/p&gt;
    &lt;p&gt;Here are the results from SpatialBench v0.1 for Queries 1â12 at scale factor 1 (SF1) and scale factor 10 (SF10).&lt;/p&gt;
    &lt;p&gt;SedonaDB demonstrates balanced performance across all query types and scales effectively to SF 10. DuckDB excels at spatial filters and some geometric operations but faces challenges with complex joins and KNN queries. GeoPandas, while popular in the Python ecosystem, requires manual optimization and parallelization to handle larger datasets effectively. An in-depth performance analysis can be found in the SpatialBench website.&lt;/p&gt;
    &lt;p&gt;Hereâs an example of the SpatialBench Query #8 that works for SedonaDB and DuckDB:&lt;/p&gt;
    &lt;code&gt;SELECT b.b_buildingkey, b.b_name, COUNT(*) AS nearby_pickup_count
FROM trip t JOIN building b ON ST_DWithin(ST_GeomFromWKB(t.t_pickuploc), ST_GeomFromWKB(b.b_boundary), 0.0045) -- ~500m
GROUP BY b.b_buildingkey, b.b_name
ORDER BY nearby_pickup_count DESC
&lt;/code&gt;
    &lt;p&gt;This query intentionally performs a distance-based spatial join between points and polygons, followed by an aggregation of the results.&lt;/p&gt;
    &lt;p&gt;Here's what the query returns:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬âââââââââââ¬ââââââââââââââââââââââ
â b_buildingkey â  b_name  â nearby_pickup_count â
â     int64     â utf8view â        int64        â
âââââââââââââââââªâââââââââââªââââââââââââââââââââââ¡
â          3779 â linen    â                  42 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â         19135 â misty    â                  36 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â          4416 â sienna   â                  26 â
âââââââââââââââââ´âââââââââââ´ââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;Hereâs the equivalent GeoPandas code:&lt;/p&gt;
    &lt;code&gt;trips_df = pd.read_parquet(data_paths["trip"])
trips_df["pickup_geom"] = gpd.GeoSeries.from_wkb(
    trips_df["t_pickuploc"], crs="EPSG:4326"
)
pickups_gdf = gpd.GeoDataFrame(trips_df, geometry="pickup_geom", crs="EPSG:4326")

buildings_df = pd.read_parquet(data_paths["building"])
buildings_df["boundary_geom"] = gpd.GeoSeries.from_wkb(
    buildings_df["b_boundary"], crs="EPSG:4326"
)
buildings_gdf = gpd.GeoDataFrame(
    buildings_df, geometry="boundary_geom", crs="EPSG:4326"
)

threshold = 0.0045  # degrees (~500m)
result = (
    buildings_gdf.sjoin(pickups_gdf, predicate="dwithin", distance=threshold)
    .groupby(["b_buildingkey", "b_name"], as_index=False)
    .size()
    .rename(columns={"size": "nearby_pickup_count"})
    .sort_values(["nearby_pickup_count", "b_buildingkey"], ascending=[False, True])
    .reset_index(drop=True)
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;ðºï¸ SedonaDB CRS management¶&lt;/head&gt;
    &lt;p&gt;SedonaDB manages the CRS when reading/writing files, as well as in DataFrames, making your pipelines safer and saving you from manual work.&lt;/p&gt;
    &lt;p&gt;Let's compute the number of buildings in the state of Vermont to highlight the CRS management features embedded in SedonaDB.&lt;/p&gt;
    &lt;p&gt;Start by reading in a FlatGeobuf file that uses the EPSG 32618 CRS with GeoPandas and then convert it to a SedonaDB DataFrame:&lt;/p&gt;
    &lt;code&gt;import geopandas as gpd

path = "https://raw.githubusercontent.com/geoarrow/geoarrow-data/v0.2.0/example-crs/files/example-crs_vermont-utm.fgb"
gdf = gpd.read_file(path)
vermont = sd.create_data_frame(gdf)
&lt;/code&gt;
    &lt;p&gt;Letâs check the schema of the &lt;code&gt;vermont&lt;/code&gt; DataFrame:&lt;/p&gt;
    &lt;code&gt;vermont.schema

SedonaSchema with 1 field:
  geometry: wkb &amp;lt;epsg:32618&amp;gt;
&lt;/code&gt;
    &lt;p&gt;We can see that the &lt;code&gt;vermont&lt;/code&gt; DataFrame maintains the CRS thatâs specified in the FlatGeobuf file.  SedonaDB doesnât have a native FlatGeobuf reader yet, but itâs easy to use the GeoPandas FlatGeobuf reader and then convert it to a SedonaDB DataFrame with a single line of code.&lt;/p&gt;
    &lt;p&gt;Now read a GeoParquet file into a SedonaDB DataFrame.&lt;/p&gt;
    &lt;code&gt;buildings = sd.read_parquet(
    "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/microsoft-buildings_point_geo.parquet"
)
&lt;/code&gt;
    &lt;p&gt;Check the schema of the DataFrame:&lt;/p&gt;
    &lt;code&gt;buildings.schema

SedonaSchema with 1 field:
  geometry: geometry &amp;lt;ogc:crs84&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Letâs expose these two tables as views and run a spatial join to see how many buildings are in Vermont:&lt;/p&gt;
    &lt;code&gt;buildings.to_view("buildings", overwrite=True)
vermont.to_view("vermont", overwrite=True)

sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, vermont.geometry)
"""
).show()
&lt;/code&gt;
    &lt;p&gt;This command correctly errors out because the tables have different CRSs. For safety, SedonaDB errors out rather than give you the wrong answer! Here's the error message that's easy to debug:&lt;/p&gt;
    &lt;code&gt;SedonaError: type_coercion
caused by
Error during planning: Mismatched CRS arguments: ogc:crs84 vs epsg:32618
Use ST_Transform() or ST_SetSRID() to ensure arguments are compatible.
&lt;/code&gt;
    &lt;p&gt;Letâs rewrite the spatial join to convert the &lt;code&gt;vermont&lt;/code&gt; CRS to EPSG:4326, so itâs compatible with the &lt;code&gt;buildings&lt;/code&gt; CRS.&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, ST_Transform(vermont.geometry, 'EPSG:4326'))
"""
).show()
&lt;/code&gt;
    &lt;p&gt;We now get the correct result!&lt;/p&gt;
    &lt;code&gt;ââââââââââââ
â count(*) â
â   int64  â
ââââââââââââ¡
â   361856 â
ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;SedonaDB tracks the CRS when reading/writing files, converting to/from GeoPandas DataFrames, or when performing DataFrame operations, so your spatial computations run safely and correctly!&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¯ Realistic example with SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Let's now turn our attention to a KNN join, which is a more complex spatial operation.&lt;/p&gt;
    &lt;p&gt;Suppose you're analyzing ride-sharing data and want to identify which buildings are most commonly near pickup points, helping understand the relationship between trip origins and nearby landmarks, businesses, or residential structures that might influence ride demand patterns.&lt;/p&gt;
    &lt;p&gt;This query finds the five closest buildings to each trip pickup location using spatial nearest neighbor analysis. For every trip, it identifies the five buildings that are geographically closest to where the passenger was picked up and calculates the exact distance to each of those buildings.&lt;/p&gt;
    &lt;p&gt;Hereâs the query:&lt;/p&gt;
    &lt;code&gt;WITH trip_with_geom AS (
    SELECT t_tripkey, t_pickuploc, ST_GeomFromWKB(t_pickuploc) as pickup_geom
    FROM trip
),
building_with_geom AS (
    SELECT b_buildingkey, b_name, b_boundary, ST_GeomFromWKB(b_boundary) as boundary_geom
    FROM building
)
SELECT
    t.t_tripkey,
    t.t_pickuploc,
    b.b_buildingkey,
    b.b_name AS building_name,
    ST_Distance(t.pickup_geom, b.boundary_geom) AS distance_to_building
FROM trip_with_geom t JOIN building_with_geom b
ON ST_KNN(t.pickup_geom, b.boundary_geom, 5, FALSE)
ORDER BY distance_to_building ASC, b.b_buildingkey ASC
&lt;/code&gt;
    &lt;p&gt;Here are the results of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââ¬ââââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââ
â t_tripkey â          t_pickuploc          â b_buildingkey â building_name â distance_to_building â
â   int64   â             binary            â     int64     â      utf8     â        float64       â
âââââââââââââªââââââââââââââââââââââââââââââââªââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââ¡
â   5854027 â 01010000001afa27b85825504001â¦ â            79 â gainsboro     â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   3326828 â 01010000001bfcc5b8b7a95d4083â¦ â           466 â deep          â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   1239844 â 0101000000ce471770d6ce2a40f9â¦ â           618 â ivory         â                  0.0 â
âââââââââââââ´ââââââââââââââââââââââââââââââââ´ââââââââââââââââ´ââââââââââââââââ´âââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;This is one of the queries from SpatialBench.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¦ Why SedonaDB was built in Rust¶&lt;/head&gt;
    &lt;p&gt;SedonaDB is built in Rust, a high-performance, memory-safe language that offers fine-grained memory management and a mature ecosystem of data libraries. It takes full advantage of this ecosystem by integrating with projects such as Apache DataFusion, GeoArrow, and georust/geo.&lt;/p&gt;
    &lt;p&gt;While Spark provides extension points that let SedonaSpark optimize spatial queries in distributed settings, DataFusion offers stable APIs for pruning, spatial operators, and optimizer rules on a single node. This enabled us to embed deep spatial awareness into the engine while preserving full non-spatial functionality. Thanks to the DataFusion project and community, the experience was both possible and enjoyable.&lt;/p&gt;
    &lt;head rend="h2"&gt;âï¸ Why SedonaDB and SedonaSpark are Both Needed¶&lt;/head&gt;
    &lt;p&gt;SedonaSpark is well-suited for large-scale geospatial workloads or environments where Spark is already part of your production stack. For instance, joining a 100 GB vector dataset with a large raster dataset. For smaller datasets, however, Spark's distributed architecture can introduce unnecessary overhead, making it slower to run locally, harder to install, and more difficult to tune.&lt;/p&gt;
    &lt;p&gt;SedonaDB is better for smaller datasets and when running computations locally. The SedonaDB spatial functions are compatible with the SedonaSpark functions, so SQL chunks that work for one engine will usually work for the other. Over time, we will ensure that both project APIs are fully interoperable. Here's an example of a chunk to analyze the Overture buildings table that works for both engines.&lt;/p&gt;
    &lt;code&gt;nyc_bbox_wkt = (
    "POLYGON((-74.2591 40.4774, -74.2591 40.9176, -73.7004 40.9176, -73.7004 40.4774, -74.2591 40.4774))"
)

sd.sql(f"""
SELECT
    id,
    height,
    num_floors,
    roof_shape,
    ST_Centroid(geometry) as centroid
FROM
    buildings
WHERE
    is_underground = FALSE
    AND height IS NOT NULL
    AND height &amp;gt; 20
    AND ST_Intersects(geometry, ST_SetSRID(ST_GeomFromText('{nyc_bbox_wkt}'), 4326))
LIMIT 5;
&lt;/code&gt;
    &lt;head rend="h2"&gt;ð Next steps¶&lt;/head&gt;
    &lt;p&gt;While SedonaDB is well-tested and provides a core set of features that can perform numerous spatial analyses, it remains an early-stage project with multiple opportunities for new features.&lt;/p&gt;
    &lt;p&gt;Many more ST functions are required. Some are relatively straightforward, but others are complex.&lt;/p&gt;
    &lt;p&gt;The community will add built-in support for other spatial file formats, such as GeoPackage and GeoJSON, to SedonaDB. You can read data in these formats into GeoPandas DataFrames and convert them to SedonaDB DataFrames in the meantime.&lt;/p&gt;
    &lt;p&gt;Raster support is also on the roadmap, which is a complex undertaking, so it's an excellent opportunity to contribute if you're interested in solving challenging problems with Rust.&lt;/p&gt;
    &lt;p&gt;Refer to the SedonaDB v0.2 milestone for more details on the specific tasks outlined for the next release. Additionally, feel free to create issues, comment on the Discord, or start GitHub discussions to brainstorm new features.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ Join the community¶&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community has an active Discord community, monthly user meetings, and regular contributor meetings.&lt;/p&gt;
    &lt;p&gt;SedonaDB welcomes contributions from the community. Feel free to request to take ownership of an issue, and we will be happy to assign it to you. You're also welcome to join the contributor meetings, and the other active contributors will be glad to help you get your pull request over the finish line!&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;Weâre celebrating the launch of SedonaDB &amp;amp; SpatialBench with a special Apache Sedona Community Office Hour!&lt;/p&gt;
    &lt;p&gt;ð October 7, 2025&lt;/p&gt;
    &lt;p&gt;â° 8â9 AM Pacific Time&lt;/p&gt;
    &lt;p&gt;ð Online&lt;/p&gt;
    &lt;p&gt;ð Sign up here&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362206</guid><pubDate>Wed, 24 Sep 2025 16:00:45 +0000</pubDate></item><item><title>New bacteria, and two potential antibiotics, discovered in soil</title><link>https://www.rockefeller.edu/news/38239-hundreds-of-new-bacteria-and-two-potential-antibiotics-found-in-soil/</link><description>&lt;doc fingerprint="7c5460762d250ab9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Hundreds of new bacteria, and two potential antibiotics, found in soil&lt;/head&gt;
    &lt;p&gt;Most bacteria cannot be cultured in the lab—and that’s been bad news for medicine. Many of our frontline antibiotics originated from microbes, yet as antibiotic resistance spreads and drug pipelines run dry, the soil beneath our feet has a vast hidden reservoir of untapped lifesaving compounds.&lt;/p&gt;
    &lt;p&gt;Now, researchers have developed a way to access this microbial goldmine. Their approach, published in Nature Biotechnology, circumvents the need to grow bacteria in the lab by extracting very large DNA fragments directly from soil to piece together the genomes of previously hidden microbes, and then mines resulting genomes for bioactive molecules.&lt;/p&gt;
    &lt;p&gt;From a single forest sample, the team generated hundreds of complete bacterial genomes never seen before, as well as two new antibiotic leads. The findings offer a scalable way to scour unculturable bacteria for new drug leads—and expose the vast, uncharted microbial frontier that shapes our environment.&lt;/p&gt;
    &lt;p&gt;“We finally have the technology to see the microbial world that have been previously inaccessible to humans,” says Sean F. Brady, head of the Laboratory of Genetically Encoded Small Molecules at Rockefeller. “And we’re not just seeing this information; we’re already turning it into potentially useful antibiotics. This is just the tip of the spear.”&lt;/p&gt;
    &lt;p&gt;Microbial dark matter&lt;/p&gt;
    &lt;p&gt;When hunting for bacteria, soil is an obvious choice. It’s the largest, most biodiverse reservoir of bacteria on the planet—a single teaspoon of it may contain thousands of different species. Many important therapeutics, including most of our antibiotic arsenal, were discovered in the tiny fraction of soil bacteria that can be grown in the laboratory. And soil is dirt cheap.&lt;/p&gt;
    &lt;p&gt;Yet we know very little about the millions of microbes packed into the earth. Scientists suspect that these hidden bacteria hold not only an untapped reservoir of new therapeutics, but clues as to how microbes shape climate, agriculture, and the larger environment that we live in. “All over the world there’s this hidden ecosystem of microbes that could have dramatic effects on our lives,” Brady adds. “We wanted to finally see them.”&lt;/p&gt;
    &lt;p&gt;Getting that glimpse involved weaving together several approaches. First, the team optimized a method for isolating large, high-quality DNA fragments directly from soil. Pairing this advance with emerging long-read nanopore sequencing allowed Jan Burian, a postdoctoral associate in the Brady lab, to produce continuous stretches of DNA that were tens of thousands of base pairs long—200 times longer than any previously existing technology could manage. Soil DNA contains a huge number of different bacteria; without such large DNA sequences to work with, resolving that complex genetic puzzle into complete and contiguous genomes for disparate bacteria proved exceedingly difficult.&lt;/p&gt;
    &lt;p&gt;“It’s easier to assemble a whole genome out of bigger pieces of DNA, rather than the millions of tiny snippets that were available before,” Brady says. “And that makes a dramatic difference in your confidence in your results.”&lt;/p&gt;
    &lt;p&gt;Unique small molecules, like antibiotics, that bacteria produce are called “natural products”. To convert the newly uncovered sequences into bioactive molecules, the team applied a synthetic bioinformatic natural products (synBNP) approach. They bioinformatically predicted the chemical structures of natural products directly from the genome data and then chemically synthesized them in the lab. With the synBNP approach, Brady and colleagues managed to turn the genetic blueprints from uncultured bacteria into actual molecules—including two potent antibiotics.&lt;/p&gt;
    &lt;p&gt;Brady describes the method, which is scalable and can be adapted to virtually any metagenomic space beyond soil, as a three-step strategy that could kick off a new era of microbiology: “Isolate big DNA, sequence it, and computationally convert it into something useful.”&lt;/p&gt;
    &lt;p&gt;Two new drug candidates, and counting&lt;/p&gt;
    &lt;p&gt;Applied to their single forest soil sample, the team’s approach produced 2.5 terabase-pairs of sequence data—the deepest long-read exploration of a single soil sample to date. Their analysis uncovered hundreds of complete contiguous bacterial genomes, more than 99 percent of which were entirely new to science and identified members from 16 major branches of the bacterial family tree.&lt;/p&gt;
    &lt;p&gt;The two lead compounds discovered could translate into potent antibiotics. One, called erutacidin, disrupts bacterial membranes through an uncommon interaction with the lipid cardiolipin and is effective against even the most challenging drug-resistant bacteria. The other, trigintamicin, acts on a protein-unfolding motor known as ClpX, a rare antibacterial target.&lt;/p&gt;
    &lt;p&gt;Brady emphasizes that these discoveries are only the beginning. The study demonstrates that previously inaccessible microbial genomes can now be decoded and mined for bioactive molecules at scale without culturing the organisms. Unlocking the genetic potential of microbial dark matter may also provide new insights into the hidden microbial networks that sustain ecosystems.&lt;/p&gt;
    &lt;p&gt;“We’re mainly interested in small molecules as therapeutics, but there are applications beyond medicine,” Burian says. “Studying culturable bacteria led to advances that helped shape the modern world and finally seeing and accessing the uncultured majority will drive a new generation of discovery.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362254</guid><pubDate>Wed, 24 Sep 2025 16:03:42 +0000</pubDate></item><item><title>Terence Tao: The role of small organizations in society has shrunk significantly</title><link>https://mathstodon.xyz/@tao/115259943398316677</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362697</guid><pubDate>Wed, 24 Sep 2025 16:32:24 +0000</pubDate></item><item><title>Launch HN: Flywheel (YC S25) – Waymo for Excavators</title><link>https://news.ycombinator.com/item?id=45362914</link><description>&lt;doc fingerprint="2c7449d6851a3652"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, We're Jash and Mahimana, cofounders of Flywheel AI (&lt;/p&gt;https://useflywheel.ai&lt;p&gt;). We’re building a remote teleop and autonomous stack for excavators.&lt;/p&gt;&lt;p&gt;Here's a video: https://www.youtube.com/watch?v=zCNmNm3lQGk.&lt;/p&gt;&lt;p&gt;Interfacing with existing excavators for enabling remote teleop (or autonomy) is hard. Unlike cars which use drive-by-wire technology, most of the millions of excavators are fully hydraulic machines. The joysticks are connected to a pilot hydraulic circuit, which proportionally moves the cylinders in the main hydraulic circuit which ultimately moves the excavator joints. This means excavators mostly do not have an electronic component to control the joints. We solve this by mechanically actuating the joysticks and pedals inside the excavators.&lt;/p&gt;&lt;p&gt;We do this with retrofits which work on any excavator model/make, enabling us to augment existing machines. By enabling remote teleoperation, we are able to increase site safety, productivity and also cost efficiency.&lt;/p&gt;&lt;p&gt;Teleoperation by the operators enables us to prepare training data for autonomy. In robotics, training data comprises observation and action. While images and videos are abundant on the internet, egocentric (PoV) observation and action data is extremely scarce, and it is this scarcity that is holding back scaling robot learning policies.&lt;/p&gt;&lt;p&gt;Flywheel solves this by preparing the training data coming from our remote teleop-enabled excavators which we have already deployed. And we do this with very minimal hardware setup and resources.&lt;/p&gt;&lt;p&gt;During our time in YC, we did 25-30 iterations of sensor stack and placement permutations/combinations, and model hyperparams variations. We called this “evolution of the physical form of our retrofit”. Eventually, we landed on our current evolution and have successfully been able to train some levels of autonomy with only a few hours of training data.&lt;/p&gt;&lt;p&gt;The big takeaway was how much more important data is than optimizing hyperparams of the model. So today, we’re open sourcing 100hrs of excavator dataset that we collected using Flywheel systems on real construction sites. This is in partnership with Frodobots.ai.&lt;/p&gt;&lt;p&gt;Dataset: https://huggingface.co/datasets/FlywheelAI/excavator-dataset&lt;/p&gt;&lt;p&gt;Machine/retrofit details:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  Volvo EC380 (38 ton excavator)
  4xcamera (25fps)
  25 hz expert operator’s action data
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; The dataset contains observation data from 4 cameras and operator's expert action data which can be used to train imitation learning models to run an excavator autonomously for the workflows in those demonstrations, like digging and dumping. We were able to train a small autonomy model for bucket pick and place on Kubota U17 from just 6-7 hours of data collected during YC.&lt;/p&gt;&lt;p&gt;We’re just getting started. We have good amounts of variations in daylight, weather, tasks, and would be adding more hours of data and also converting to lerobot format soon. We’re doing this so people like you and me can try out training models on real world data which is very, very hard to get.&lt;/p&gt;&lt;p&gt;So please checkout the dataset here and feel free to download and use however you like. We would love for people to do things with it! I’ll be around in the thread and look forward to comments and feedback from the community!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362914</guid><pubDate>Wed, 24 Sep 2025 16:48:27 +0000</pubDate></item><item><title>SonyShell – An effort to “SSH into my Sony DSLR”</title><link>https://github.com/goudvuur/sonyshell</link><description>&lt;doc fingerprint="34960c72d72e66ed"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux-only helper built on Sony’s official Camera Remote SDK. It connects to a Sony A6700 camera over Wi-Fi/Ethernet, listens for new photos, downloads them automatically, and can optionally run a script on each downloaded file.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-connect via enumeration or direct IP/MAC.&lt;/item&gt;
      &lt;item&gt;Watches for new capture events and fetches the newest files.&lt;/item&gt;
      &lt;item&gt;Saves into a chosen directory with unique filenames.&lt;/item&gt;
      &lt;item&gt;Post-download hook: run any executable/script with the saved file path as argument.&lt;/item&gt;
      &lt;item&gt;Keepalive mode: auto-retry on startup failure or after disconnects.&lt;/item&gt;
      &lt;item&gt;Cleaned, Linux-only code (no Windows ifdefs, simpler logging).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./sony-remote --dir /photos [options]&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--dir &amp;lt;path&amp;gt;&lt;/code&gt;: Directory to save files (required in most real setups).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--ip &amp;lt;addr&amp;gt;&lt;/code&gt;: Connect directly by IPv4 (e.g.&lt;code&gt;192.168.10.184&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--mac &amp;lt;hex:mac&amp;gt;&lt;/code&gt;: Optional MAC (e.g.&lt;code&gt;10:32:2c:2a:1a:6d&lt;/code&gt;) for direct IP.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cmd &amp;lt;path&amp;gt;&lt;/code&gt;: Executable/script to run after each download, invoked as&lt;code&gt;cmd /photos/DSC01234.JPG&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--keepalive &amp;lt;ms&amp;gt;&lt;/code&gt;: Retry interval when offline or after disconnect.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-v&lt;/code&gt;,&lt;code&gt;--verbose&lt;/code&gt;: Verbose property-change logging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enumerate + keep retrying every 2s, run a hook after each file:&lt;/p&gt;
    &lt;code&gt;./sony-remote --dir /photos --keepalive 2000 --cmd /usr/local/bin/ingest-photo&lt;/code&gt;
    &lt;p&gt;Direct IP connect, verbose logs, retry every 3s:&lt;/p&gt;
    &lt;code&gt;./sony-remote --ip 192.168.10.184 --mac 10:32:2c:2a:1a:6d --dir /photos -v --keepalive 3000&lt;/code&gt;
    &lt;p&gt;Requires Linux, g++, and the Sony Camera Remote SDK.&lt;/p&gt;
    &lt;p&gt;See INSTALL.md&lt;/p&gt;
    &lt;p&gt;or (untested)&lt;/p&gt;
    &lt;code&gt;g++ -std=c++17 sony-a6700-remote-cleaned.cpp \
    -I/path/to/CrSDK/include \
    -L/path/to/CrSDK/lib -lCameraRemoteSDK \
    -lpthread -o sony-remote&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Connect to the camera (via IP or enumeration). Stores/reuses SDK fingerprint under &lt;code&gt;~/.cache/sonshell/&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Wait for notifications: when the camera signals new contents, spawn a download thread.&lt;/item&gt;
      &lt;item&gt;Download newest files to &lt;code&gt;--dir&lt;/code&gt;. Safe naming ensures no overwrite (&lt;code&gt;file_1.jpg&lt;/code&gt;, etc.).&lt;/item&gt;
      &lt;item&gt;Hook: if &lt;code&gt;--cmd&lt;/code&gt;is set, fork/exec the script with the saved path.&lt;/item&gt;
      &lt;item&gt;Reconnect on errors/disconnects if &lt;code&gt;--keepalive&lt;/code&gt;is set.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built on/for Ubuntu 24.04&lt;/item&gt;
      &lt;item&gt;It uses Sony's official Camera Remote SDK (not included here).&lt;/item&gt;
      &lt;item&gt;See DOCS.md for a deep dive into the internals.&lt;/item&gt;
      &lt;item&gt;I leaned heavily on ChatGPT while creating this, so please don't mind the mess! ;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sony Camera Remote SDK: https://support.d-imaging.sony.co.jp/app/sdk/en/index.html&lt;/item&gt;
      &lt;item&gt;See LICENSE for licensing details.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45365878</guid><pubDate>Wed, 24 Sep 2025 21:00:00 +0000</pubDate></item><item><title>Everything that's wrong with Google Search in one image</title><link>https://bitbytebit.substack.com/p/everything-thats-wrong-with-google</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45366566</guid><pubDate>Wed, 24 Sep 2025 22:11:48 +0000</pubDate></item><item><title>Helium Browser</title><link>https://helium.computer/</link><description>&lt;doc fingerprint="170e82509195b1e4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Internet without interruptions&lt;/head&gt;
    &lt;p&gt;Best privacy and unbiased ad-blocking by default. Handy features like native !bangs and split view. No adware, no bloat, no noise. People-first and fully open source.&lt;/p&gt;
    &lt;head rend="h1"&gt;Best privacy by default, not as a hidden option&lt;/head&gt;
    &lt;p&gt;Helium blocks ads, trackers, fingerprinting, third-party cookies, cryptominers, and phishing websites by default thanks to preinstalled uBlock Origin. No extra steps are needed, and there are no biased exceptions â unlike other browsers. &lt;lb/&gt; The browser itself doesn't have any ads, trackers, or analytics. Helium also doesn't make any web requests without your explicit consent, it makes zero web requests on first launch. &lt;lb/&gt; Not enough? Increase privacy even further with ungoogled-chromium flags or uBlock Origin filters. You're finally at the steering wheel of your privacy on the Internet â not in a toy car, but in a real race car. &lt;lb/&gt; We will always stand by our promise of the best privacy and will never prioritize profit over people, unlike big corporations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Respectful by design&lt;/head&gt;
    &lt;p&gt;Helium doesn't annoy you with anything and never will. It doesn't do anything without your consent: no unprovoked tabs about updates or sponsors, no persistent popups telling you about features you don't care about, no weird restarts. &lt;lb/&gt; Nothing interrupts you, jumps in your face, or breaks your flow. Everything just makes sense. You're in full control.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fast, efficient, and light&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium, the fastest and most optimized browser yet. Helium builds on this base to improve performance and save even more energy. You will notice a difference after using Helium for a day. It doesn't slow down over time. &lt;lb/&gt; All bloat is removed: Helium is one of the lightest modern browsers available.&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful when you need it&lt;/head&gt;
    &lt;p&gt;Open pages side-by-side with split view to get even more things done at once. Quickly copy page links with â+Shift+C and share your discoveries with ease. Install any web apps and use them as standalone desktop apps without duplicating Chromium.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed to get out of your way&lt;/head&gt;
    &lt;p&gt;Helium's interface is compact and minimalistic, but it doesn't compromise on beauty or functionality. More web content fits on the screen at once, and the browser interface doesn't get in your way. You can hide everything extra from the toolbar if it annoys you. &lt;lb/&gt; Helium is built with attention to detail. Nothing jiggles or flickers abnormally. Your actions aren't throttled or stopped by lag. Everything's fast, smooth, and simple. Comfort and simplicity are among our top priorities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Works with all Chromium extensions, privately&lt;/head&gt;
    &lt;p&gt;All Chromium extensions are supported and work right away, by default, including all MV2 extensions. We'll keep support for MV2 extensions for as long as possible. &lt;lb/&gt; Helium anonymizes all internal requests to the Chrome Web Store via Helium services. Thanks to this, Google can't track your extension downloads or target ads using this data. No other browser does this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free and fully open-source&lt;/head&gt;
    &lt;p&gt;All parts of the Helium browser are open source, including online services. You can self-host Helium services and use your own instance in your browser. &lt;lb/&gt; Everything is available on GitHub. No exceptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Always safe and sound&lt;/head&gt;
    &lt;p&gt;We release new Chromium updates (such as security patches) as soon as possible. Your browser will always be safe and up to date. &lt;lb/&gt; Helium updates itself automatically on macOS, with auto-updating options available on Linux and Windows. &lt;lb/&gt; All builds are available on GitHub, and you can even make one yourself. The choice is yours!&lt;/p&gt;
    &lt;head rend="h2"&gt;Best security practices for everyone, by default&lt;/head&gt;
    &lt;p&gt;Helium enforces HTTPS on all websites and warns you when a website doesn't support it. Passkeys just work. &lt;lb/&gt; There's no built-in password manager. Passwords should be separate from a web browser to be truly secure and immutable. &lt;lb/&gt; There's also no cloud-based history/data sync. You should be the only one with access to your browsing data, not some conglomerate.&lt;/p&gt;
    &lt;head rend="h1"&gt;Browse the Internet faster with !bangs&lt;/head&gt;
    &lt;p&gt;Skip the search engine and go directly to the website you want. Choose from over 13,000 bangs that make the Internet a breeze to browse, such as !w for Wikipedia, !gh for GitHub, and !wa for Wolfram Alpha. &lt;lb/&gt; Want to chat with AI? Just add !chatgpt or any other AI provider name at the start of your query. Helium will start a new chat for you without sending your prompt anywhere else. &lt;lb/&gt; Helium bangs are the fastest and most private implementation of bangs yet. They work offline, directly in your browser. &lt;lb/&gt; Not sure which bang to use? Check out the full list of bangs!&lt;/p&gt;
    &lt;head rend="h1"&gt;The web browser made for people, with love&lt;/head&gt;
    &lt;p&gt;We're making a web browser that we enjoy using ourselves. Helium's main goal is to provide an honest, comfortable, privacy-respecting, and non-invasive browsing experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for developers&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium and doesn't break any web APIs or standards, despite the focus on privacy. DevTools have been cleaned up and no longer nag you with anything. There's nothing that gets in your way of creating the Internet of the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for everyone on the go&lt;/head&gt;
    &lt;p&gt;Helium's efficiency makes it handy for everyone with their laptop on the go. Split view and quick link copying make it easier than ever to get things done faster. Helium loads pages faster and saves data by blocking ads and other crap.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ready to try Helium?&lt;/head&gt;
    &lt;p&gt;It's never too late to get your internet life back on the right track. Helium can transfer your most important stuff from other browsers in one click. We hope you'll love it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45366867</guid><pubDate>Wed, 24 Sep 2025 22:51:16 +0000</pubDate></item><item><title>Do YC after you graduate: Early decision for students</title><link>https://www.ycombinator.com/early-decision</link><description>&lt;doc fingerprint="b61d01d108cf1634"&gt;
  &lt;main&gt;
    &lt;p&gt;Apply now, do YC after you graduate. For students who want to finish school before doing YC. Get funded the moment you're accepted.&lt;/p&gt;
    &lt;p&gt;Sneha and Anushka, founders of Spur (S24), applied in Fall 2023 for the S24 batch using Early Decision. This allowed them to graduate in May 2024 and then do YC. They've since raised $4.5M from top investors for their AI-powered QA testing tools.&lt;/p&gt;
    &lt;p&gt;Early Decision lets you apply to YC while you're still in school and reserve your spot in a future batch. For example, you apply in Fall of this year, for a spot in the summer batch of the following year. You submit the same YC application as if you were applying for the upcoming batch. If you're accepted, we'll fund you immediately and hold your place for after you graduate.&lt;/p&gt;
    &lt;p&gt;This program is designed for students who want to finish their degree before starting a company. If you're considering working on your own startup after graduation, Early Decision makes it easy to lock in your spot.&lt;/p&gt;
    &lt;p&gt;Even if you're not completely sure yet if you want to do a startup, you should still apply. There is no downside.&lt;/p&gt;
    &lt;p&gt;Also, if you're not in your final year, you can still apply for Early Decision. You'll be able to finish the school year you're currently in, and then either join a later batch or decide to drop out and start sooner.&lt;/p&gt;
    &lt;p&gt;The most common path is students applying in the fall of their final year and joining the summer batch after graduating in Spring. But you can apply for any batch in the future within reason. The application and interview process is the same as if you were applying for the upcoming batch. Once you're accepted, YC funds you right away and confirms your future batch.&lt;/p&gt;
    &lt;p&gt;When you fill out your YC application, you'll see a question asking which batch you want to apply for. Simply select "A batch after Winter 2026" to indicate you're applying for Early Decision, and tell us which batch you'd like to be considered for.&lt;/p&gt;
    &lt;p&gt;The batch preference question in the YC application&lt;/p&gt;
    &lt;p&gt;Many students want to finish their degree or complete more of their education before starting a company. Also we know that many students spend a lot of time in Fall or during their final year applying for jobs or internships. Early Decision gives students another option: apply to YC and bet on yourself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45367046</guid><pubDate>Wed, 24 Sep 2025 23:12:38 +0000</pubDate></item><item><title>How did sports betting become legal in the US?</title><link>https://shreyashariharan.substack.com/p/how-did-sports-betting-become-legal</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45367086</guid><pubDate>Wed, 24 Sep 2025 23:15:38 +0000</pubDate></item><item><title>Knotty: A domain-specific language for knitting patterns</title><link>https://t0mpr1c3.github.io/knotty/index.html</link><description>&lt;doc fingerprint="a5ebd7a76a7f3314"&gt;
  &lt;main&gt;
    &lt;p&gt;▼ Knotty 1 Introduction 2 How to Make a New Pattern 3 Input and Output 4 Code Examples 5 Reference On this page: Knotty 8.11 contents ← prev up next → Knotty Tom Price &amp;lt; t0mpr1c3@gmail.com &amp;gt; ( require knotty ) package: knotty-lib A domain-specific language for knitting patterns. contents ← prev up next →&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45369768</guid><pubDate>Thu, 25 Sep 2025 06:13:32 +0000</pubDate></item><item><title>Is This Bad? This Feels Bad. (Fortra GoAnywhere CVE-2025-10035)</title><link>https://labs.watchtowr.com/is-this-bad-this-feels-bad-goanywhere-cve-2025-10035/</link><description>&lt;doc fingerprint="2d49cbd0cfaf132c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is This Bad? This Feels Bad. (Fortra GoAnywhere CVE-2025-10035)&lt;/head&gt;
    &lt;p&gt;File transfer used to be simple fun - fire up your favourite FTP client, log in to a glFTPd site, and you were done.&lt;/p&gt;
    &lt;p&gt;Fast forward to 2025, and the same act requires a procurement team, a web interface, and a vendor proudly waving their Secure by Design pledge.&lt;/p&gt;
    &lt;p&gt;Ever seen the glFTPd developers on the list of pledge signers? Exactly.&lt;/p&gt;
    &lt;p&gt;Welcome back to another watchTowr Labs analysis. This time, we are dissecting CVE-2025-10035, a perfect CVSS 10.0 vulnerability in Fortra’s GoAnywhere MFT.&lt;/p&gt;
    &lt;p&gt;For the uninitiated, GoAnywhere is a "secure" managed file transfer solution that automates and protects data exchange across enterprises, trading partners, and critical applications.&lt;/p&gt;
    &lt;p&gt;Not your friend's photo-sharing setup. We are talking Fortune 500 deployments, with over 20,000 instances exposed to the Internet. A playground APT groups dream about.&lt;/p&gt;
    &lt;p&gt;GoAnywhere has a history. In 2023, the cl0p ransomware gang turned CVE-2023-0669, a pre-auth command injection in the Licensing Response Servlet, into widespread compromise. That was the year of MFT exploitation trauma across multiple vendors, burned into the memory of defenders everywhere.&lt;/p&gt;
    &lt;p&gt;As always, and you'll read, we have an inner feeling (call it "instinct") that there is more to this vulnerability that we are not yet being told.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Is CVE-2025-10035&lt;/head&gt;
    &lt;p&gt;On Thursday, September 18, Fortra published a security advisory fi-2025-012 titled: Deserialization Vulnerability in GoAnywhere MFT's License Servlet.&lt;/p&gt;
    &lt;p&gt;The title in itself is reason for alarm, with the description going further to explain how we likely got to a CVSS 10.0:&lt;/p&gt;
    &lt;quote&gt;A deserialization vulnerability in the License Servlet of Fortra's GoAnywhere MFT allows an actor with a validly forged license response signature to deserialize an arbitrary actor-controlled object, possibly leading to command injection.&lt;/quote&gt;
    &lt;p&gt;For those that recall the excitement of CVE-2023-0669, this description might feel.. familiar..:&lt;/p&gt;
    &lt;quote&gt;GoAnywhere MFT suffers from a pre-authentication command injection vulnerability in the License Response Servlet due to deserializing an arbitrary attacker-controlled object&lt;/quote&gt;
    &lt;p&gt;But watchTowr, how did this get a CVSS 10.0? The advisory clearly states meaningful hurdles for attackers to traverse:&lt;/p&gt;
    &lt;quote&gt;Exploitation of this vulnerability is highly dependent upon systems being externally exposed to the Internet.&lt;/quote&gt;
    &lt;p&gt;Fortra, should the advisory also note that the solution needs to be running?&lt;/p&gt;
    &lt;head rend="h3"&gt;In The Wild Exploitation?&lt;/head&gt;
    &lt;p&gt;As always, we must all play a game.&lt;/p&gt;
    &lt;p&gt;The above sometimes happens when a vendor updates references attached to a CVE. In this case, FI-2025-011 was deleted, and FI-2025-012 was added to replace it.&lt;/p&gt;
    &lt;p&gt;In FI-2025-012, a section was appended - an innocent "Am I Impacted?" section.&lt;/p&gt;
    &lt;p&gt;Typically (not always...), when a vulnerability receives in-the-wild exploitation, clarity to customers is provided to help inform prioritisation and remediation process expectations.&lt;/p&gt;
    &lt;p&gt;Fortra's advisory never says, “We’ve seen this exploited in-the-wild.”&lt;/p&gt;
    &lt;p&gt;What they do say is more curious: check your Admin Audit logs, look for &lt;code&gt;SignedObject.getObject&lt;/code&gt; in exception traces, and if you see it, you were “likely affected.”&lt;/p&gt;
    &lt;p&gt;Affected, as in, vulnerable? Or affected like, the fox is already in the hen-house?&lt;/p&gt;
    &lt;p&gt;To determine if you're "affected", Fortra provides an IoC (Indicator of Compromise) for this ambiguous-state vulnerability.&lt;/p&gt;
    &lt;p&gt;As discussed above, the advisory for FI-2025-012 includes a stack trace which will appear in your logs should you be "affected" by this vulnerability:&lt;/p&gt;
    &lt;code&gt;ERROR Error parsing license response
java.lang.RuntimeException: InvocationTargetException: java.lang.reflect.InvocationTargetException
...
at java.base/java.io.ObjectInputStream.readObject(Unknown Source)
at java.base/java.security.SignedObject.getObject(Unknown Source)
at com.linoma.license.gen2.BundleWorker.verify(BundleWorker.java:319)
at com.linoma.license.gen2.BundleWorker.unbundle(BundleWorker.java:122)
at com.linoma.license.gen2.LicenseController.getResponse(LicenseController.java:441)
at com.linoma.license.gen2.LicenseAPI.getResponse(LicenseAPI.java:304)
at com.linoma.ga.ui.admin.servlet.LicenseResponseServlet.doPost(LicenseResponseServlet.java:64)
&lt;/code&gt;
    &lt;p&gt;We know Fortra wouldn't be ambiguous on purpose, though, because CISA's Secure By Design pledge, which Fortra signed up to, talks about transparency around ITW exploitation:&lt;/p&gt;
    &lt;p&gt;Let’s dive in.&lt;/p&gt;
    &lt;head rend="h3"&gt;Part 1 - License Servlet “Authentication” Bypass&lt;/head&gt;
    &lt;p&gt;The initial vendor advisory was clear, immediately pointing to the culprit: the License Servlet. Key points from the advisory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The License Servlet contains an insecure deserialization vulnerability.&lt;/item&gt;
      &lt;item&gt;According to the CVSS score, it’s reachable without authentication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, first things first: can we actually hit the servlet and trigger the deserialization routine without credentials? To answer that, we need to crack open the code.&lt;/p&gt;
    &lt;p&gt;The License Servlet lives in &lt;code&gt;com.linoma.ga.ui.admin.servlet.LicenseResponseServlet&lt;/code&gt; and is exposed at:&lt;/p&gt;
    &lt;code&gt;/goanywhere/lic/accept/&amp;lt;GUID&amp;gt;&lt;/code&gt;
    &lt;p&gt;Let’s take a look at the entry point:&lt;/p&gt;
    &lt;code&gt;public void doPost(HttpServletRequest var1, HttpServletResponse var2) throws ServletException, IOException {
    String var3 = var1.getParameter("bundle"); // [1]
    String[] var4 = var1.getRequestURI().split("/"); // [2]
    String var5 = var4[var4.length - 1];
    Object var6 = null;
    if (!SessionUtilities.isLicenseRequestTokenValid(var5, var1.getSession())) { // [3]
        LOGGER.error("Unauthorized bundle from invalid session: " + var3);
        var2.sendError(400);
        var1.getSession().removeAttribute(SessionAttributes.LICENSE_REQUEST_TOKEN.getAttributeKey());
    } else {
        try {
            var9 = LicenseAPI.getResponse(var3); // [4]
        } catch (Exception var8) {
            LOGGER.error("Error parsing license response", var8);
            var2.sendError(500);
            var1.getSession().removeAttribute(SessionAttributes.LICENSE_REQUEST_TOKEN.getAttributeKey());
            return;
        }
    //...
 }
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At [1] the servlet retrieves the &lt;code&gt;bundle&lt;/code&gt;parameter from the HTTP request.&lt;/item&gt;
      &lt;item&gt;At [2] it extracts a string from our URL - a GUID that defines the license request token.&lt;/item&gt;
      &lt;item&gt;At [3] it calls &lt;code&gt;SessionUtilities.isLicenseRequestTokenValid&lt;/code&gt;to validate the user-supplied license request token.&lt;/item&gt;
      &lt;item&gt;If the check at [3] passes, the servlet calls &lt;code&gt;LicenseAPI.getResponse&lt;/code&gt;with the&lt;code&gt;bundle&lt;/code&gt;parameter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, how does token validation (the GUID) actually work? Well...&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The servlet takes the GUID token extracted at [2].&lt;/item&gt;
      &lt;item&gt;It compares that token to the token that was stored on the user’s session.&lt;/item&gt;
      &lt;item&gt;If both tokens match, the validation at [3] succeeds and execution proceeds to &lt;code&gt;LicenseAPI.getResponse&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If the tokens do not match, the flow stops - we never reach the deserialization code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So: without a valid token tied to the user session, we cannot even begin to reach the vulnerable deserialization routine.&lt;/p&gt;
    &lt;head rend="h3"&gt;OK, We Need A Token - But How?&lt;/head&gt;
    &lt;p&gt;Well, if your target GoAnywhere MFT instance has no license applied, this is trivial - you can head straight to the endpoint that starts the activation procedure, and a valid token will be applied to your session.&lt;/p&gt;
    &lt;p&gt;However, this is not a production reality where licenses are inevitably provided - and this is not as simple. Typically, in such a case, you need to be authenticated to generate a valid license request token and attach it to your session.&lt;/p&gt;
    &lt;p&gt;Our vulnerability is a perfect 10 CVSS, though, so logically there must be a way to obtain this token without any authentication.&lt;/p&gt;
    &lt;p&gt;All of our analysis led us to the &lt;code&gt;/goanywhere/license/Unlicensed.xhtml&lt;/code&gt; endpoint, where we discovered a few important items:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We can bypass authentication requirements for this endpoint by appending &lt;code&gt;/x&lt;/code&gt;(or any other invalid data) to the endpoint, like so:&lt;code&gt;/goanywhere/license/Unlicensed.xhtml/x&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;We need this endpoint to trigger an exception - for example, by providing an invalid &lt;code&gt;ViewState&lt;/code&gt;, like this:&lt;code&gt;/goanywhere/license/Unlicensed.xhtml/x?javax.faces.ViewState=x&amp;amp;GARequestAction=activate&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why, you ask? Because, in doing so, the application then flows to the &lt;code&gt;AdminErrorHandlerServlet&lt;/code&gt; servlet, where all of our fun begins:&lt;/p&gt;
    &lt;code&gt;protected void doGet(HttpServletRequest var1, HttpServletResponse var2) throws ServletException, IOException {
    Integer var3 = (Integer)var1.getAttribute("javax.servlet.error.status_code");
    String var4 = (String)var1.getAttribute("javax.servlet.error.message");
    Class var5 = (Class)var1.getAttribute("javax.servlet.error.exception_type");
    String var6 = (String)var1.getAttribute("javax.servlet.error.request_uri");
    Throwable var7 = (Throwable)var1.getAttribute("javax.servlet.error.exception");
    String var8 = var1.getRemoteAddr();
    String var9 = var1.getParameter("GARequestAction");
    if (var3 == null &amp;amp;&amp;amp; var5 == null &amp;amp;&amp;amp; var7 == null) {
        var2.sendError(404);
    } else if (!this.bypassHandling(var3, var6)) {
        if (var6.startsWith(var1.getContextPath() + "/license/Unlicensed.xhtml")) { // [1]
            if (StringUtilities.isNotEmpty(var9) &amp;amp;&amp;amp; var9.equalsIgnoreCase("activate")) {
                String var14 = SessionUtilities.generateLicenseRequestToken(var1.getSession()); // [2]

                try {
                        LicenseUtilities.requestOnlineActivation(var1, var2, var14); // [3]
                        return;
                    } catch (Exception var13) {
                        this.LOGGER.error(var13.getMessage(), var13);
                    }
                }

                var2.sendRedirect(var6);
                //...
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At [1], the code checks whether the request URL begins with &lt;code&gt;/license/Unlicensed.xhtml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If it does, then at [2] the application generates a valid license-request token and attaches it to the session.&lt;/item&gt;
      &lt;item&gt;Finally, at [3], the token is passed to &lt;code&gt;LicenseUtilities.requestOnlineActivation&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;This method builds a redirect URL to the GoAnywhere license server, embedding the signed license request inside an HTTP GET &lt;code&gt;bundle&lt;/code&gt;parameter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now, for anyone who doesn’t live and breathe GoAnywhere MFT’s licensing process, the license request does two key things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It stores a serialized Java object containing the license-request token.&lt;/item&gt;
      &lt;item&gt;It’s encrypted with hard-coded keys (and partially compressed for good measure).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;An attacker can simply send:&lt;/p&gt;
    &lt;code&gt;GET /goanywhere/license/Unlicensed.xhtml/watchTowr?javax.faces.ViewState=watchTowr&amp;amp;GARequestAction=activate HTTP/1.1
Host: {{Hostname}}
&lt;/code&gt;
    &lt;p&gt;In response, the server redirects and returns a &lt;code&gt;bundle&lt;/code&gt; parameter (the license request) — plus a cookie where the generated token has been attached.&lt;/p&gt;
    &lt;code&gt;HTTP/1.1 302 
...
Location: &amp;lt;https://my.goanywhere.com:443/lic/request?bundle=p55wfyVKXDVM_bAVZtDLOg3PglFmtEOHyjm4vYZ9l2kwhyouIP6ieq_VZ6lJbVsf5J7KHr..... snip .....
&lt;/code&gt;
    &lt;p&gt;Because the encryption key is hard-coded, the &lt;code&gt;bundle&lt;/code&gt; parameter value can be decrypted offline to recover the embedded GUID. &lt;/p&gt;
    &lt;p&gt;Using said GUID, we are then able to interact with the License Servlet without "actually" authenticating:&lt;/p&gt;
    &lt;code&gt;POST /goanywhere/lic/accept/d1a8b697-d68c-4e7d-b179-5f3b8b529e6f HTTP/1.1
Host: {{Hostname}}
Cookie: ASESSIONID=F970BB906F5F7D325BFC6E261CF87AE6;
Content-Type: application/x-www-form-urlencoded

bundle=inputhere
&lt;/code&gt;
    &lt;p&gt;There we have it - the "Authentication Bypass" portion of this vulnerability. Let's move on...&lt;/p&gt;
    &lt;head rend="h3"&gt;Part 2 - Insecure Deserialization in License Servlet&lt;/head&gt;
    &lt;p&gt;Now that we can obtain the GUID token unauthenticated, we can reach the deserialization sink that this vulnerability ends with.&lt;/p&gt;
    &lt;p&gt;For your sake, and our sanity, we are going to skip the majority of the code and leave you with two basic facts you need to know:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The &lt;code&gt;bundle&lt;/code&gt;parameter carries a serialized Java object that the server decrypts during processing.&lt;/item&gt;
      &lt;item&gt;Decryption uses hard-coded keys, so the &lt;code&gt;bundle&lt;/code&gt;parameter value is recoverable offline.&lt;/item&gt;
      &lt;item&gt;Processing eventually reaches &lt;code&gt;com.linoma.license.gen2.BundleWorker.verify&lt;/code&gt;, where the application hands us the raw input byte array derived from the&lt;code&gt;bundle&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;In short, an attacker-controlled serialized object reaches server-side deserialization logic.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's step through &lt;code&gt;com.linoma.license.gen2.BundleWorker.verify&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;private static byte[] verify(byte[] var0, KeyConfig var1) throws IOException, ClassNotFoundException, NoSuchAlgorithmException, InvalidKeyException, SignatureException, UnrecoverableKeyException, CertificateException, KeyStoreException {
    String var2 = "SHA1withDSA";
    if ("2".equals(var1.getVersion())) {
        var2 = "SHA512withRSA";
    }

    PublicKey var3 = getPublicKey(var1);
    Signature var4 = Signature.getInstance(var2);
    SignedObject var5 = (SignedObject)JavaSerializationUtilities.deserialize(var0, SignedObject.class, new Class[]{byte[].class}); // [1]
    if (var1.isServer()) {
        return ((SignedContainer)JavaSerializationUtilities.deserializeUntrustedSignedObject(var5, SignedContainer.class, new Class[]{byte[].class})).getData();
    } else {
        boolean var6 = var5.verify(var3, var4); // [2]
        if (!var6) {
            throw new IOException("Unable to verify signature!");
        } else {
            SignedContainer var7 = (SignedContainer)var5.getObject(); // [3]
            return var7.getData();
        }
    }
}
&lt;/code&gt;
    &lt;p&gt;This part can be a little confusing, so let’s stick to the key points.&lt;/p&gt;
    &lt;p&gt;At [1] the code calls into a hardened deserialization wrapper (wrapping around &lt;code&gt;ValidatingObjectInputStream.readObject&lt;/code&gt; from standard Apache libraries), to deserialize our data.&lt;/p&gt;
    &lt;p&gt;It also supplies extra arguments, such as &lt;code&gt;SignedObject.class&lt;/code&gt;, which define the only types the routine will accept during deserialization.&lt;/p&gt;
    &lt;p&gt;Those additional arguments restrict what types can be deserialized. In practice, this means the routine will only accept a &lt;code&gt;java.security.SignedObject&lt;/code&gt; or a raw &lt;code&gt;byte[]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So what is a &lt;code&gt;SignedObject&lt;/code&gt;? According to the Java documentation:&lt;/p&gt;
    &lt;quote&gt;SignedObject is a class for the purpose of creating authentic runtime objects whose integrity cannot be compromised without being detected.&lt;lb/&gt;More specifically, a SignedObject contains another Serializable object, the (to-be-)signed object and its signature.&lt;/quote&gt;
    &lt;p&gt;In simple terms, a &lt;code&gt;SignedObject&lt;/code&gt; is just a wrapper. It stores a serialized object inside and a signature calculated over that stream with a private key alongside it.&lt;/p&gt;
    &lt;p&gt;The class also provides a few helper methods:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;verify&lt;/code&gt;- uses the public key to check that the signature matches.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;getObject&lt;/code&gt;- deserializes and returns the inner serialized object.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’re reaching the end!&lt;/p&gt;
    &lt;p&gt;At &lt;code&gt;[3]&lt;/code&gt;, the code will call &lt;code&gt;getObject&lt;/code&gt; on our deserialized &lt;code&gt;SignedObject&lt;/code&gt;, immediately allowing an attacker to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deliver a serialized &lt;code&gt;SignedObject&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Which internally stores a malicious serialized object, like a one based on the &lt;code&gt;CommonsBeanutils1&lt;/code&gt;gadget.&lt;/item&gt;
      &lt;item&gt;GoAnywhere will deserialize this inner object, and that’s it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;WRONG WRONG WRONG&lt;/head&gt;
    &lt;p&gt;Do you see what we missed? Look at &lt;code&gt;[2]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The code checks the signature of our serialized object against a public key baked into GoAnywhere. On paper, this is sensible. Signature validation is handled by Bouncy Castle and its FIPS API.&lt;/p&gt;
    &lt;p&gt;So the final barrier to a pre-auth RCE is bypassing that signature check. But here’s the problem: we don’t know how. Really.&lt;/p&gt;
    &lt;p&gt;Either we are missing a trick, or the check is genuinely solid. We tried:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using several private keys shipped in GoAnywhere to generate a valid signature. None of them matched the public key in play.&lt;/item&gt;
      &lt;item&gt;Reviewing the Java code responsible for the signature verification.&lt;/item&gt;
      &lt;item&gt;Chasing alternative code paths that might hit deserialization without needing this check.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this failed.&lt;/p&gt;
    &lt;p&gt;One might think: just diff the patch, you dummies.&lt;/p&gt;
    &lt;p&gt;Here’s the kicker though. The patch does harden the deserialization routine, but the signature verification logic? Completely untouched.&lt;/p&gt;
    &lt;p&gt;See for yourself:&lt;/p&gt;
    &lt;p&gt;The patch doesn’t amend the signature check at all. Instead, it only changes the deserialization flow, replacing &lt;code&gt;SignedObject.getObject&lt;/code&gt; with a custom wrapper called &lt;code&gt;deserializeUntrustedSignedObject&lt;/code&gt;. The idea seems to be to add another layer of “safety” around deserialization.&lt;/p&gt;
    &lt;p&gt;We’ve got a few conspiracy theories, though, all of which we have absolutely zero evidence for, and are complete conjecture. Regardless, you’re free to pick whichever one fits your mood:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We’re dummies. We somehow missed an obvious bypass for the signature verification routine. If that’s the case, why didn’t the patch touch it?&lt;/item&gt;
      &lt;item&gt;The vendor got popped. The private key leaked. Dramatic, yes, but possible. That would let attackers sign malicious objects that every GoAnywhere instance on the planet would happily accept.&lt;/item&gt;
      &lt;item&gt;The vendor accidentally signed evil. Imagine this:&lt;list rend="ul"&gt;&lt;item&gt;When you activate your GoAnywhere product, your installation generates a serialized license request.&lt;/item&gt;&lt;item&gt;It’s sent to the vendor’s license server (&lt;code&gt;my.goanywhere.com&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;If someone slipped a malicious object inside that request and the vendor blindly signed it, attackers would now have a perfectly valid signed payload that works everywhere.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fueling our conspiracy theories was the advisory deletion and reference update we discussed above, including a stack trace which signals a valid exploitation attempt and asks the user to check their logs:&lt;/p&gt;
    &lt;p&gt;Who does that? Well, in our opinion, typically vendors whose products are facing ITW exploitation - but we're not experts.&lt;/p&gt;
    &lt;p&gt;It’s all a mystery. We can’t see a path to exploit this without a valid private key. On paper, that should kill the bug dead.&lt;/p&gt;
    &lt;p&gt;On the other hand, this has a perfect 10 CVSS score, and the vendor has published "IoCs," which indicates that it is likely real.&lt;/p&gt;
    &lt;p&gt;And on the other hand, we recently saw a critical CVE in Sitecore that existed purely because… people were copy-pasting machine keys straight from the documentation.&lt;/p&gt;
    &lt;p&gt;At this point, nothing shocks us. CVE assignments feel less like a science and more like a game of darts in the dark.&lt;/p&gt;
    &lt;head rend="h3"&gt;Detection Artefact Generator&lt;/head&gt;
    &lt;p&gt;Across our client base, we used the Authentication Bypass weakness within an impact-less (but still exploitation-based) mechanism to identify unpatched and vulnerable GoAnywhere systems at scale.&lt;/p&gt;
    &lt;p&gt;Today, we're sharing this mechanism:&lt;/p&gt;
    &lt;code&gt;GET /goanywhere/license/Unlicensed.xhtml/watchTowr?javax.faces.ViewState=watchTowr&amp;amp;GARequestAction=activate HTTP/1.1
&lt;/code&gt;
    &lt;p&gt;If the instance is unpatched, you’ll see the response include a &lt;code&gt;Location&lt;/code&gt; header with a license request embedded in the &lt;code&gt;bundle&lt;/code&gt; query string parameter:&lt;/p&gt;
    &lt;p&gt;If you don’t see the &lt;code&gt;bundle&lt;/code&gt;  parameter, your instance is patched. That’s because the &lt;code&gt;AdminErrorHandlerServlet&lt;/code&gt; no longer generates a valid license request token once the fix is applied.&lt;/p&gt;
    &lt;p&gt;TL;DR&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unpatched: redirect to &lt;code&gt;/license/Unlicensed.xhtml&lt;/code&gt;with a valid license request token attached.&lt;/item&gt;
      &lt;item&gt;Patched: redirect to &lt;code&gt;/license/Unlicensed.xhtml&lt;/code&gt;with no license request token.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Sigh&lt;/head&gt;
    &lt;p&gt;No mystery is complete without a few unanswered questions. Despite our usual routine of reverse engineering and creative detours, we’ve ended this one with more questions than usual.&lt;/p&gt;
    &lt;p&gt;Did we miss critical lines of code that makes everything click into place? Will the first reply on social media point out the obvious and send us a working PoC embedded in a meme? Please.&lt;/p&gt;
    &lt;p&gt;Because the alternatives are less comforting.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Could this vulnerability already be in active use?&lt;/item&gt;
      &lt;item&gt;Could someone have access to a signed malicious object ready to be sprayed across the Internet or delivered with precision to a single target?&lt;/item&gt;
      &lt;item&gt;Could that be happening right now?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing is certain: no vendor assigns a CVSS 10 to a purely theoretical bug. We'd advise against leaving GoAnywhere unpatched below 7.8.4 (or Sustain Release 7.6.3).&lt;/p&gt;
    &lt;p&gt;While this mystery continues to evolve, and we're excited to see if anyone takes the baton from us, concerned operators and end users can use our Detection Artefact Generator to check for externally vulnerable instances.&lt;/p&gt;
    &lt;p&gt;The research published by watchTowr Labs is just a glimpse into what powers the watchTowr Platform – delivering automated, continuous testing against real attacker behaviour.&lt;/p&gt;
    &lt;p&gt;By combining Proactive Threat Intelligence and External Attack Surface Management into a single Preemptive Exposure Management capability, the watchTowr Platform helps organisations rapidly react to emerging threats – and gives them what matters most: time to respond.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370256</guid><pubDate>Thu, 25 Sep 2025 07:44:55 +0000</pubDate></item><item><title>The all-in-one PC: Raspberry Pi 500 on sale now at $200</title><link>https://www.raspberrypi.com/news/the-ultimate-all-in-one-pc-raspberry-pi-500-plus-on-sale-now-at-200/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370304</guid><pubDate>Thu, 25 Sep 2025 07:52:28 +0000</pubDate></item><item><title>Perhaps my last post – we'll see (2016)</title><link>http://itila.blogspot.com/2016/04/perhaps-my-last-post-well-see.html</link><description>&lt;doc fingerprint="a72c4c940fbfd90c"&gt;
  &lt;main&gt;
    &lt;p&gt;I'd like my posts to have an ending, so I'm going to make this my final one - maybe.&lt;/p&gt;
    &lt;p&gt;While the doctors haven't expressed an opinion, I think it's possible I haven't got long to go, because I've lost 15 kg, and last Friday's CT scan showed that I've got secondaries on the go in my bones (as we already anticipated from the high ALP levels measured over the past weeks); my platelet count is very low, so they suspect that my bone marrow may be having trouble with cancer cells. On Monday they propose to take a bone marrow sample to find out what's going on. My extreme breathlessness continues - lying still in bed is fine, but getting out of bed onto the commode and back feels afterwards rather like a marathon. Maybe I'll pull through, but let's tentatively wrap up my blog-posts now.&lt;/p&gt;
    &lt;p&gt;There's lots I could write, but the way I'd like to stop is by pointing you to the writings of someone else. Max Edwards wrote a piece for the Guardian about his own cancer, and much of what he writes resonates for me. He was a remarkably eloquent writer.&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370306</guid><pubDate>Thu, 25 Sep 2025 07:52:55 +0000</pubDate></item><item><title>RTO: WTAF</title><link>https://wordsrightman.beehiiv.com/p/rto-wtaf</link><description>&lt;doc fingerprint="6221531f3ef337fc"&gt;
  &lt;main&gt;
    &lt;p&gt;In their great wisdom, Microsoft have announced that instead of improving the user experience of their software so that I don’t feel the need to defenestrate my laptop (it’s a Windows joke, see?), they will be putting effort towards mandating a Return To Office policy from February 2026, for any employees within a 50-mile radius of their Redmond HQ. Other lucky office locations to come next, goes the threat.&lt;/p&gt;
    &lt;p&gt;They claim - way before anyone asked - that this isn’t an attempt to reduce headcount, which makes me squint my eyes, furl my brow and place my right hand onto my chin. I look ridiculous.&lt;/p&gt;
    &lt;p&gt;So tempting. Doesn’t it just call to you?&lt;/p&gt;
    &lt;p&gt;It’s not only Microsoft; mandating RTO is possibly the number one option in the Bad Management Toolkit (patent pending) for those who consider that their company is done innovating, would like to spend some time spinning their wheels, and could the nice, expensive people who helped them do all that innovation please leave at the nearest exit and stop clogging up the payroll thankyouverymuch.&lt;/p&gt;
    &lt;p&gt;Companies implementing such policies will claim that they’re not making the waters unpleasant to chase people away, but the dirty truth is that it’s the least morally-reprehensible reason for it. Times are indeed tough, so rather than making huge layoffs (which they’re also doing), they are at least giving some people agency to decide if they will tolerate The New Way. What alternative reasons are there?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;“We just loooove to control people”: Ew. Definitely worse than saying you can’t afford everybody.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We don’t trust our staff”: That’s kind of on you, Scamp. You hired them, and if they’re not doing the job then you have performance management tools at your fingertips. If you took your eye off the ball and hired so wildly in the past that you’re stuck with underperformers then that’s not the fault of the folks who are totally competent when working remotely.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We don’t think people do their best work from home”: Prove it. Explain how we managed during COVID lockdown, and how that entire span of time didn’t prove that most people were absolutely fine from home. Your company delivered through a pandemic, and still exists now thanks to the efforts of those people. Did your middle managers not get to belittle someone that dared to take their lunch break? Careful now, I might squeeze out a tiny tear for them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We think people need to be in-person for full collaboration”: Then why aren’t you sacking anyone outside of your arbitrarily-chosen radius? You’re saying that any remote staff you hired can’t fully do their jobs, which automatically puts them at a disadvantage in any career path at your company. Enjoy the lawsuit if you say that out loud.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even if you pick one of these reasons and double-down, it avoids the human aspect completely. You’re no longer an investor in people. You will cause untold mental, physical and financial upheaval for many employees who now have to spend money on commuting, childcare, pet care, to name but a few.&lt;/p&gt;
    &lt;p&gt;Just try not to touch your eye, or your lunch.&lt;/p&gt;
    &lt;p&gt;Mental health will be greatly affected. Many people who work remotely do so because travelling to a central location with thousands of other people is a stressful experience. If you and your C-suite role get choppered onto the helipad every morning so you can galivant about the office showing how big and powerful you are, of course you don’t see that side of it.&lt;/p&gt;
    &lt;p&gt;For a lot of people, crowds and/or the possibility of your transport being late (and therefore getting a tick in the Column You Don’t Want A Tick In on your next review) is of huge mental detriment. Being forced to leave your home can be detrimental too - dark early mornings locking your pets in the house and dashing to a busy train, is soul-crushing. If you actively decide to make this a reality for more people, you are increasing the unpleasantness in people’s brains, the overall misery in the world, and you deserve to be held accountable.&lt;/p&gt;
    &lt;p&gt;If you’re a terrible leader, you might be thinking; “Brilliant! I’m so behind the times that I haven’t got mental health awareness in my company, so I’m off the hook!”. Not so fast. Running a medium to large company, if for no motive other than pure profit, will require certain standards to be met if others will work with you. A glaze of professionalism is generally expected in the form of an environmental policy and although you’ll probably copy it off the internet, it will at least imply that you’ve given a sideways glance to your carbon practices so that our great-grandchildren don’t have to speedrun the evolution of gills.&lt;/p&gt;
    &lt;p&gt;“Year 2060” by Busted, featuring your niece&lt;/p&gt;
    &lt;p&gt;The fact is, if your company has a mental health or environmental policy and you mandate RTO, you are simply liars. You can’t actually care about mental health or the environment because if you did, you’d note gleefully that it’s much better for people and planet to have a choice, and to not be forced to contribute to the commuting energy wasted on going to a place to do a thing they could have done from a different, more comfortable place. You would pride yourself on it, in fact.&lt;/p&gt;
    &lt;p&gt;Of course, I’m not saying everyone prefers working from home, or that every job can be done from home - keep oil rig workers on the oil rigs, I say - but forcing everyone to do the same thing removes agency and adds pain for many. If I preferred office work and I could choose a Zoom meeting or threatening everyone in my team with unemployment unless they join me in the meeting room at 4pm on a Friday, I would pick the Zoom call.&lt;/p&gt;
    &lt;p&gt;I honestly don’t know what today’s bosses are hoping to achieve with RTO, but it’s a sure-fire way to rid yourself of those pesky skilled and experienced employees. Good engineers want an employer they can trust; once the opposite reputation sets in, it’s very difficult to reverse it the next time you need good people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370678</guid><pubDate>Thu, 25 Sep 2025 08:56:52 +0000</pubDate></item></channel></rss>