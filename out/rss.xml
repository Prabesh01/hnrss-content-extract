<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 21 Jan 2026 16:23:44 +0000</lastBuildDate><item><title>Anthropic's original take home assignment open sourced</title><link>https://github.com/anthropics/original_performance_takehome</link><description>&lt;doc fingerprint="c3652efe1d9963a6"&gt;
  &lt;main&gt;
    &lt;p&gt;This repo contains a version of Anthropic's original performance take-home, before Claude Opus 4.5 started doing better than humans given only 2 hours.&lt;/p&gt;
    &lt;p&gt;Now you can try to beat Claude Opus 4.5 given unlimited time!&lt;/p&gt;
    &lt;p&gt;measured in clock cycles from the simulated machine:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2164 cycles: Claude Opus 4 after many hours in the test-time compute harness&lt;/item&gt;
      &lt;item&gt;1790 cycles: Claude Opus 4.5 in a casual Claude Code session, approximately matching the best human performance in 2 hours&lt;/item&gt;
      &lt;item&gt;1579 cycles: Claude Opus 4.5 after 2 hours in our test-time compute harness&lt;/item&gt;
      &lt;item&gt;1548 cycles: Claude Sonnet 4.5 after many more than 2 hours of test-time compute&lt;/item&gt;
      &lt;item&gt;1487 cycles: Claude Opus 4.5 after 11.5 hours in the harness&lt;/item&gt;
      &lt;item&gt;1363 cycles: Claude Opus 4.5 in an improved test time compute harness&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you optimize below 1487 cycles, beating Claude Opus 4.5's best performance at launch, email us at performance-recruiting@anthropic.com with your code (and ideally a resume) so we can be appropriately impressed and perhaps discuss interviewing.&lt;/p&gt;
    &lt;p&gt;Run &lt;code&gt;python tests/submission_tests.py&lt;/code&gt; to see which thresholds you pass.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46700594</guid><pubDate>Wed, 21 Jan 2026 02:54:32 +0000</pubDate></item><item><title>Libbbf: Bound Book Format, A high-performance container for comics and manga</title><link>https://github.com/ef1500/libbbf</link><description>&lt;doc fingerprint="4d8b2e9705d57b9c"&gt;
  &lt;main&gt;&lt;p&gt;Warning&lt;/p&gt;&lt;p&gt;Official Source Notice: Please only download releases from this repository (ef1500/libbbf). External mirrors or forks may contain malware.&lt;/p&gt;&lt;p&gt;Bound Book Format (.bbf) is a high-performance binary container designed specifically for digital comic books and manga. Unlike CBR/CBZ, BBF is built for DirectSotrage/mmap, easy integrity checks, and mixed-codec containerization.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;C++17 compliant compiler (GCC/Clang/MSVC), and optionally CMake&lt;/item&gt;&lt;item&gt;xxHash library&lt;/item&gt;&lt;/list&gt;&lt;code&gt;cmake -B build
cmake --build build
sudo cmake --install build&lt;/code&gt;&lt;p&gt;Linux&lt;/p&gt;&lt;code&gt;g++ -std=c++17 bbfenc.cpp libbbf.cpp xxhash.c -o bbfmux -pthread&lt;/code&gt;&lt;p&gt;Windows&lt;/p&gt;&lt;code&gt;g++ -std=c++17 bbfenc.cpp libbbf.cpp xxhash.c -o bbfmux -municode&lt;/code&gt;&lt;p&gt;Alternatively, if you need python support, use libbbf-python.&lt;/p&gt;&lt;p&gt;BBF is designed as a Footer-indexed binary format. This allows for rapid append-only creation and immediate random access to any page without scanning the entire file.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;bbfmux&lt;/code&gt; reference implementation utilizes Memory Mapping (mmap/MapViewOfFile). Instead of reading file data into intermediate buffers, the tool maps the container directly into the process address space. This allows the CPU to access image data at the speed of your NVMe drive's hardware limit.&lt;/p&gt;&lt;p&gt;Integrity checks utilize Parallel XXH3. On multi-core systems, the verifier splits the asset table into chunks and validates multiple pages simultaneously. This makes BBF verification up to 10x faster than ZIP/RAR CRC checks.&lt;/p&gt;&lt;p&gt;Every asset in a BBF file starts on a 4096-byte boundary. This alignment is critical for modern hardware, allowing for DirectStorage transfers directly from disk to GPU memory, bypassing CPU bottlenecks entirely.&lt;/p&gt;&lt;p&gt;Note: DirectStorage isn't avaliable for images yet (as far as I know), but I've made sure to accomodate such a thing in the future with this format.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Header (13 bytes): Magic &lt;code&gt;BBF1&lt;/code&gt;, versioning, and initial padding.&lt;/item&gt;&lt;item&gt;Page Data: The raw image payloads (AVIF, PNG, etc.), each padded to 4096-byte boundaries.&lt;/item&gt;&lt;item&gt;String Pool: A deduplicated pool of null-terminated strings for metadata and section titles.&lt;/item&gt;&lt;item&gt;Asset Table: A registry of physical data blobs with XXH3 hashes.&lt;/item&gt;&lt;item&gt;Page Table: The logical reading order, mapping logical pages to assets.&lt;/item&gt;&lt;item&gt;Section Table: Markers for chapters, volumes, or gallery sections.&lt;/item&gt;&lt;item&gt;Metadata Table: Key-Value pairs for archival data (Author, Scanlation team, etc.).&lt;/item&gt;&lt;item&gt;Footer (76 bytes): Table offsets and a final integrity hash.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;NOTE: &lt;code&gt;libbbf.h&lt;/code&gt; includes a &lt;code&gt;flags&lt;/code&gt; field, as well as extra padding for each asset entry. This is so that in the future &lt;code&gt;libbbf&lt;/code&gt; can accomodate future technical advancements in both readers and image storage. I.E. If images support DirectStorage in the future, then BBF will be able to use it.&lt;/p&gt;&lt;table&gt;&lt;row span="7"&gt;&lt;cell role="head"&gt;Feature&lt;/cell&gt;&lt;cell role="head"&gt;BBF&lt;/cell&gt;&lt;cell role="head"&gt;CBZ (Zip)&lt;/cell&gt;&lt;cell role="head"&gt;CBR (Rar)&lt;/cell&gt;&lt;cell role="head"&gt;EPUB&lt;/cell&gt;&lt;cell role="head"&gt;Folder&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Random Page Access&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅[8]&lt;/cell&gt;&lt;cell&gt;✅[8]&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Native Data Deduplication&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Per-Asset Integrity (XXH3)&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;4KB Sector Alignment&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Native Sections/Chapters&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Arbitrary Metadata (UTF-8)&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Mixed-Codec Support&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;DirectStorage/mmap Ready&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Low Parser Complexity&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Bit-Rot Detection&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row span="7"&gt;&lt;cell&gt;Streaming-Friendly Index&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅ [7]&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Wide Software Support&lt;/cell&gt;&lt;cell&gt;❌&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;cell&gt;✅&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;[2] - CBZ does not support metadata natively in the ZIP spec; it relies on unofficial sidecar files like&lt;/p&gt;&lt;code&gt;ComicInfo.xml&lt;/code&gt;.&lt;p&gt;[3] - While folders allow memory mapping, individual images within them are rarely sector-aligned for optimized DirectStorage throughput.&lt;/p&gt;&lt;p&gt;[4] - ZIP/RAR require large, complex libraries (zlib/libarchive); BBF is a "Plain Old Data" (POD) format requiring only a few lines of C++ to parse.&lt;/p&gt;&lt;p&gt;[5] - ZIP/RAR use CRC32, which is aging, collision-prone, and significantly slower to verify than XXH3 for large archival collections. See [8].&lt;/p&gt;&lt;p&gt;[6] - Because the index is at the end (Footer), web-based streaming requires a "Range Request" to the end of the file before reading pages.&lt;/p&gt;&lt;p&gt;[7] - PDF supports "Linearization" (Fast Web View), allowing the header and first pages to be read before the rest of the file is downloaded.&lt;/p&gt;&lt;p&gt;[8] - As Reddit properly corrected me, ZIP/RAR does have random access.&lt;/p&gt;&lt;p&gt;[9] - While I think CRC32 is a legacy hash format, ZIP/RAR does have verification ability, though somewhat outdated. See [5].&lt;/p&gt;&lt;p&gt;BBF uses XXH3_64 hashing to identify identical pages. If a book contains duplicate pages, the data is stored exactly once on disk while being referenced multiple times in the Page Table.&lt;/p&gt;&lt;p&gt;BBF stores a 64-bit hash for every individual asset. The &lt;code&gt;bbfmux --verify&lt;/code&gt; command can pinpoint exactly which page has been damaged, rather than simply failing to open the entire archive.&lt;/p&gt;&lt;p&gt;Preserve covers in Lossless PNG while encoding internal story pages in AVIF to save 70% space. BBF explicitly flags the codec for every asset, allowing readers to initialize the correct decoder instantly without "guessing" the file type.&lt;/p&gt;&lt;p&gt;The included &lt;code&gt;bbfmux&lt;/code&gt; tool is a reference implementation for creating and managing BBF files.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;bbfmux&lt;/code&gt; utility provides a powerful interface for managing Bound Book files:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Flexible Ingestion: Create books by passing individual files, entire directories, or a mix of both.&lt;/item&gt;&lt;item&gt;Logical Structuring: Add named Sections (Chapters, Volumes, Extras, Galleries) to define the internal hierarchy of the book.&lt;/item&gt;&lt;item&gt;Custom Metadata: Embed arbitrary Key:Value pairs into the global string pool for archival indexing.&lt;/item&gt;&lt;item&gt;Content-Aware Extraction: Extract the entire book or target specific sections by name.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;You can mix individual images and folders. &lt;code&gt;bbfmux&lt;/code&gt; sorts inputs alphabetically, deduplicates identical assets, and aligns data to 4096-byte boundaries. See Advanced CLI Usage for how to specify your own custom page orders.&lt;/p&gt;&lt;code&gt;# Basic creation with metadata
bbfmux cover.png ./chapter1/ endcard.png \
  --meta=Title:"Akira" \
  --meta=Author:"Katsuhiro Otomo" \
  --meta=Tags:"[Action, Sci-Fi, Cyberpunk]" \
  akira.bbf&lt;/code&gt;&lt;p&gt;BBF supports nesting sections. By defining a Parent relationship, you can group chapters into volumes. This allows readers to display a nested Table of Contents and enables bulk-extraction of entire volumes.&lt;/p&gt;&lt;p&gt;Syntax: &lt;code&gt;--section="Name":Page[:ParentName]&lt;/code&gt;&lt;/p&gt;&lt;code&gt;# Create a book with nested chapters
bbfmux ./manga_folder/ \
  --section="Volume 1":1 \
  --section="Chapter 1":1:"Volume 1" \
  --section="Chapter 2":20:"Volume 1" \
  --section="Volume 2":180 \
  --section="Chapter 3":180:"Volume 2" \
  manga.bbf&lt;/code&gt;&lt;p&gt;Scan the archive for bit-rot or data corruption. BBF uses XXH3_64 hashes to verify every individual image payload.&lt;/p&gt;&lt;code&gt;bbfmux input.bbf --verify&lt;/code&gt;&lt;p&gt;Extract the entire book, a specific volume, or a single chapter. When extracting a parent section (like a Volume), &lt;code&gt;bbfmux&lt;/code&gt; automatically includes all child chapters.&lt;/p&gt;&lt;p&gt;Extract a specific section:&lt;/p&gt;&lt;code&gt;bbfmux input.bbf --extract --section="Volume 1" --outdir="./Volume1"&lt;/code&gt;&lt;p&gt;Extract the entire book:&lt;/p&gt;&lt;code&gt;bbfmux input.bbf --extract --outdir="./unpacked_book"&lt;/code&gt;&lt;p&gt;View the version, page count, deduplication stats, hierarchical sections, and all embedded metadata.&lt;/p&gt;&lt;code&gt;bbfmux input_book.bbf --info&lt;/code&gt;&lt;p&gt;&lt;code&gt;bbfmux&lt;/code&gt; also supports more advanced options, allowing full-control over your &lt;code&gt;.bbf&lt;/code&gt; files.&lt;/p&gt;&lt;p&gt;You can precisely control the reading order using a text file or inline arguments.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Positive Integers: Fixed 1-based index (e.g., &lt;code&gt;cover.png:1&lt;/code&gt;).&lt;/item&gt;&lt;item&gt;Negative Integers: Fixed position from the end (e.g., &lt;code&gt;credits.png:-1&lt;/code&gt;is always the last page).&lt;/item&gt;&lt;item&gt;Unspecified: Sorted alphabetically between the fixed pages.&lt;/item&gt;&lt;/list&gt;&lt;code&gt;# Using an order file
bbfmux ./images/ --order=pages.txt out.bbf

# pages.txt example:
cover.png:1
page1.png:2
page2.png:3
credits.png:-1&lt;/code&gt;&lt;p&gt;Sections define Chapters or Volumes. You can target a page by its index or filename.&lt;/p&gt;&lt;code&gt;# Target by filename
bbfmux ./folder/ --section="Chapter 1":"001.png" out.bbf

# Using a sections file
bbfmux ./folder/ --sections=sectionexample.txt out.bbf

# sectionexample.txt example (Name:Target[:Parent]):
"Volume 1":"001.png"
"Chapter 1":"001.png":"Volume 1"
"Chapter 2":"050.png":"Volume 1"&lt;/code&gt;&lt;p&gt;BBF allows for verification of data to detect bit-rot.&lt;/p&gt;&lt;code&gt;# Verify everything (All assets and Directory structure)
bbfmux input.bbf --verify

# Verify only the directory hash (Instant)
bbfmux input.bbf --verify -1

# Verify a specific asset by index
bbfmux input.bbf --verify 42&lt;/code&gt;&lt;p&gt;The &lt;code&gt;--rangekey&lt;/code&gt; option allows you to extract a range of sections. The extractor starts at the specified &lt;code&gt;--section&lt;/code&gt; and stops when it finds a section whose title matches the &lt;code&gt;rangekey&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;# Extract Chapter 2 up until it hits Chapter 4
bbfmux manga.bbf --extract --section="Chapter 2" --rangekey="Chapter 4" --outdir="./Ch2_to_Ch4"

# Extract Volume 2 until it encounters the string "Chapter 60"
bbfmux manga.bbf --extract --section="Volume 2" --rangekey="Chapter 60" --outdir="./Volume_2_to_Chapter_60"&lt;/code&gt;&lt;p&gt;Distributed under the MIT License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46701114</guid><pubDate>Wed, 21 Jan 2026 04:27:08 +0000</pubDate></item><item><title>cURL removes bug bounties</title><link>https://etn.se/index.php/nyheter/72808-curl-removes-bug-bounties.html</link><description>&lt;doc fingerprint="ecd3a0c5d4ae55b0"&gt;
  &lt;main&gt;
    &lt;p&gt;Open source code library cURL is removing the possibility to earn money by reporting bugs, hoping that this will reduce the volume of AI slop reports. Joshua Rogers – AI wielding bug hunter of fame – thinks it's a great idea.&lt;/p&gt;
    &lt;p&gt;cURL has been flooded with AI-generated error reports. Now one of the incentives to create them will go away.&lt;/p&gt;
    &lt;p&gt;The vast majority of AI-generated error reports submitted to cURL are pure nonsense. Other open source projects are caught in the same pandemic.&lt;/p&gt;
    &lt;p&gt;cURL maintainer Daniel Stenberg made an impact with his reporting on AI-generated bug reports last year – ”Death by a thousand slops.”&lt;/p&gt;
    &lt;p&gt;Determining that they are nonsense is time-consuming, causing the maintainers lots of extra work.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Daniel&lt;p&gt;Stenberg&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;”AI slop and bad reports in general have been increasing even more lately, so we have to try to brake the flood in order not to drown”, says cURL maintainer Daniel Stenberg to Swedish electronics industry news site etn.se.&lt;/p&gt;
    &lt;p&gt;Therefore, cURL is terminating the bounty payouts as of the end of January.&lt;/p&gt;
    &lt;p&gt;“We hope this removes some of the incentives for people to send us garbage. We spend far too much time handling slop due to findings that are not real, exaggerated, or misunderstood.”&lt;/p&gt;
    &lt;p&gt;Not all AI-generated bug reports are nonsense. It’s not possible to determine the exact share, but Daniel Stenberg knows of more than a hundred good AI assisted reports that led to corrections.&lt;/p&gt;
    &lt;p&gt;In total, 87 bug reports to cURL have over the years amounted to USD 101,020 in bounties.&lt;/p&gt;
    &lt;p&gt;How many of them would have gone under the radar if the bounty money had not existed?&lt;/p&gt;
    &lt;p&gt;Elektroniktidningen passes that question on to debugging champion Joshua Rogers, who last year flooded open source projects with bug reports – good reports.&lt;/p&gt;
    &lt;p&gt;Interestingly, his reports were generated with the help of AI tools. But he doesn’t just vibe along in the dark — he reviews and adds to AI's analysis before submitting anything.&lt;/p&gt;
    &lt;p&gt;Despite being an active code vulnerabilities hunter himself, he thinks removing the bounty money is a stellar idea ; something that should have been done a long time ago. He documented that view in a 2025 year-end posting.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Joshua&lt;p&gt;Rogers&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;“I think it's a good move and worth a bigger consideration by others. It's ridiculous that it went on for so long to be honest, and I personally would have pulled the plug long ago,” he says to etn.se.&lt;/p&gt;
    &lt;p&gt;But without the bounties an incentive to do code reviews disappears?&lt;/p&gt;
    &lt;p&gt;”*An incentive*, but not all,” he comments, ”especially for anything that will be reported which actually matters”.&lt;/p&gt;
    &lt;p&gt;So you think the effect won’t be that big?&lt;/p&gt;
    &lt;p&gt;“Not much. The real incentive for finding a vulnerability in cURL is the fame ('brand is priceless'), not the hundred or few thousand dollars. $10,000 (maximum cURL bounty) is not a lot of money in the grand scheme of things, for somebody capable of finding a critical vulnerability in curl.”&lt;/p&gt;
    &lt;p&gt;He realizes, though, that not everyone might share that attitude.&lt;/p&gt;
    &lt;p&gt;“My view is that there is an asymmetric relationship between developers (open source or not) and so-called "security researchers" (or even real security researchers). Regardless of whether the researchers are in expensive or cheap countries, the value provided to the developer is the same. However, on the flipside, the value of a bounty is not the same for every reporter -- in low socio-economic locations, a reward which would be the cost of lunch in Sweden can be massive for those low socio-economic-located people,” says Joshua Rogers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46701733</guid><pubDate>Wed, 21 Jan 2026 06:07:03 +0000</pubDate></item><item><title>Infracost (YC W21) Is Hiring Sr Back End Eng (Node.js+SQL) to Shift FinOps Left</title><link>https://www.ycombinator.com/companies/infracost/jobs/Sr9rmHs-senior-backend-engineer-node-js-sql</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46702045</guid><pubDate>Wed, 21 Jan 2026 07:00:23 +0000</pubDate></item><item><title>The percentage of Show HN posts is increasing, but their scores are decreasing</title><link>https://snubi.net/posts/Show-HN/</link><description>&lt;doc fingerprint="22881157ac720865"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The percentage of Show HN posts is increasing, but their scores are decreasing&lt;/head&gt;
    &lt;p&gt;Last update: 2026-01-14&lt;/p&gt;
    &lt;p&gt;Recently, I felt like I was seeing more âShow HNâ stories, and many of which were generated with LLMs. So I analyzed the data to see if that was true. Also I included the average score per month to see if people enjoy seeing them (because I donât :P).&lt;/p&gt;
    &lt;head rend="h2"&gt;Charts&lt;/head&gt;
    &lt;p&gt;Stories in 2026 was omitted. 1) Itâs only 13 days, 2) Scores are not stable yet.&lt;/p&gt;
    &lt;p&gt;Left axis: &lt;code&gt;show_hn_ratio&lt;/code&gt;(&lt;code&gt;show_hn / story * 100&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;Right axis: &lt;code&gt;average_show_hn_score&lt;/code&gt; and &lt;code&gt;average_story_score&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;With LLM timeline&lt;/p&gt;
    &lt;head rend="h2"&gt;Analysis&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: I am neither a data scientist nor a statistician. Some nuances may have been lost in translation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Percentage&lt;/head&gt;
    &lt;p&gt;For about ten years (2012~2022), the percentage of Show HN stories was around 2-3%. Then, with the appearance of LLMs that can code, itâs been increasing. Claude Code and Cursor 1.0 accelerated it even more. As of December 2025, over 12% of all stories are Show HNs. Itâs safe to say that there is a correlation between the increase in Show HN posts and LLM. People can create great things even if they donât know how to code at all.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scores&lt;/head&gt;
    &lt;p&gt;Show HN stories used to receive similar scores (around 15-18) to those of all stories until 2023~2024. However, itâs been declining while percentage of them are going up. As of December 2025, the average Show HN score is 10 points lower (9.04 vs 19.53).&lt;/p&gt;
    &lt;p&gt;Does it mean LLM-generated Show HNs are lower quality? Iâm not sure. Maybe people are tired of seeing too many Show HNs.&lt;/p&gt;
    &lt;p&gt;Also I have no idea why the average score was increased in 2022. A lot of new users?&lt;/p&gt;
    &lt;head rend="h2"&gt;Data and codes&lt;/head&gt;
    &lt;p&gt;You can find python code and csv in https://github.com/plastic041/hackernews.&lt;/p&gt;
    &lt;p&gt;I exported BigQuery hacker news data to csv using this query:&lt;/p&gt;
    &lt;code&gt;SELECT
  `time`,
  `title`,
  `type`,
  `score`,
  `id`
FROM
  `bigquery-public-data.hacker_news.full`
WHERE
  (`type` IN ('story')) and title IS NOT NULL;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;type&lt;/code&gt; field in BigQuery does not have a &lt;code&gt;show_hn&lt;/code&gt; attribute like the Algolia API, so I lowercased titles and filtered using &lt;code&gt;starts_with("show_hn: ")&lt;/code&gt; to determine if a post is a Show HN story.&lt;/p&gt;
    &lt;p&gt;I didnât commit to the repo the original CSV because it was too big (~400 MB) but you can download it from BigQuery for free (I didnât set billing account). I ran SQL above, exported it to google drive, and downloaded it.&lt;/p&gt;
    &lt;p&gt;I would like to analyze the percentage of Show HN stories generated with LLMs but I couldnât find the way to do this, because many Show HN stories donât mention that theyâve used LLMs in their text.&lt;/p&gt;
    &lt;p&gt;Iâll try to update this article every few months.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46702099</guid><pubDate>Wed, 21 Jan 2026 07:09:03 +0000</pubDate></item><item><title>SETI@home is in hiberation</title><link>https://setiathome.berkeley.edu/</link><description>&lt;doc fingerprint="9ad0fc014f2203f2"&gt;
  &lt;main&gt;
    &lt;p&gt;Thanks to everyone for your support over the years. We encourage you to keep crunching for science.&lt;/p&gt;
    &lt;p&gt;SETI@home is a scientific experiment, based at UC Berkeley, that uses Internet-connected computers in the Search for Extraterrestrial Intelligence (SETI). You can participate by running a free program that downloads and analyzes radio telescope data.&lt;/p&gt;
    &lt;p&gt;Already joined? Log in.&lt;/p&gt;
    &lt;p&gt;SETI@home papers accepted for publication&lt;/p&gt;
    &lt;p&gt;Website outage&lt;lb/&gt; Multiple disk failure resulted in a web site outage. We think we've recovered almost everything from the web site, so it should be back up and running. &lt;lb/&gt; 3 Apr 2025, 20:49:48 UTC · Discuss &lt;/p&gt;
    &lt;p&gt;RIP Jimmy Carter&lt;lb/&gt; Carter wrote the following on June 16, 1977 and placed it in Voyager 1, which is the most distant human-made object from Earth:&lt;lb/&gt; This Voyager spacecraft was constructed by the United States of America. We are a community of 240 million human being among the more than 4 billion who inhabit the planet Earth. We human beings are still divided into nation states, but these states are rapidly becoming a single global civilization.&lt;lb/&gt; We cast this message into the cosmos. It is likely to survive a billion years into our future, when our civilization is profoundly altered and the surface of the Earth may be vastly changed. Of the 200 billion stars in the Milky Way galaxy, some – perhaps many – may have inhabited planet and spacefaring civilizations. If one such civilization intercepts Voyager and can understand these recorded contents, here is our message:&lt;lb/&gt; “This is a present from a small distant world, a token of our sounds, our science, our images, our music, our thoughts and our feelings. We are attempting to survive our time so we may live into yours. We hope someday, having solved the problem we face, to join a community of galactic civilizations. This record represents our hope and our determination, and our good will in a vast and awesome universe.”&lt;lb/&gt; --- Jimmy Carter, President of the United States of America, the White House, June 16, 1977 &lt;lb/&gt; 30 Dec 2024, 9:27:36 UTC · Discuss &lt;/p&gt;
    &lt;p&gt;Nebula progress report&lt;lb/&gt; Check out our latest newsletter: Final update. &lt;lb/&gt; 3 Mar 2023, 4:59:42 UTC · Discuss &lt;/p&gt;
    &lt;p&gt;Citizen Science SETI Project at UCLA.&lt;lb/&gt; Jean Luc Margot, a SETI Researcher at UCLA has started a Citizen Science project at UCLA. Participants will help identify and classify types of Radio Frequency Interference (RFI) seen in the data that they have taken at the Green Bank Telescope. This is an important step in identifying any signals that don't look like RFI.&lt;lb/&gt; You can join at https://www.zooniverse.org/projects/ucla-seti-group/are-we-alone-in-the-universe. &lt;lb/&gt; 15 Feb 2023, 19:40:18 UTC · Discuss &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; ©2026 University of California &lt;lb/&gt; SETI@home and Astropulse are funded by grants from the National Science Foundation, NASA, and donations from SETI@home volunteers. AstroPulse is funded in part by the NSF through grant AST-0307956. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46703301</guid><pubDate>Wed, 21 Jan 2026 09:49:34 +0000</pubDate></item><item><title>I Made Zig Compute 33M Satellite Positions in 3 Seconds. No GPU Required</title><link>https://atempleton.bearblog.dev/i-made-zig-compute-33-million-satellite-positions-in-3-seconds-no-gpu-required/</link><description>&lt;doc fingerprint="ee167cfce90c1280"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Made Zig Compute 33 Million Satellite Positions in 3 Seconds. No GPU Required.&lt;/head&gt;
    &lt;p&gt;I've spent the past month optimizing SGP4 propagation and ended up with something interesting: astroz is now the fastest general purpose SGP4 implementation I'm aware of, hitting 11-13M propagations per second in native Zig and ~7M/s through Python with just &lt;code&gt;pip install astroz&lt;/code&gt;. This post breaks down how I got there.&lt;/p&gt;
    &lt;p&gt;A note on "general purpose": heyoka.py can be faster for batch-processing many satellites simultaneously (16M/s vs 7.5M/s). But it's a general ODE integrator with SGP4 as a module, requiring LLVM for JIT compilation and a C++ dependency stack that conda-forge recommends over pip. For time batched propagation, many time points for one satellite, astroz is 2x faster (8.5M/s vs 3.8M/s). Full comparison below. I'm also skipping GPU accelerated SGP4 implementations. They can be faster for massive batch workloads, but require CUDA/OpenCL setup and aren't what I'd consider "general purpose."&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Bother Optimizing SGP4?&lt;/head&gt;
    &lt;p&gt;SGP4 is the standard algorithm for predicting satellite positions from TLE data. It's been around since the 80s and most implementations are straightforward ports of the original reference code. They work fine. You can read the implementation that I followed from SpaceTrack Report No. 3.&lt;/p&gt;
    &lt;p&gt;But "fine" starts to feel slow when you need dense time resolution. Generating a month of ephemeris data at one-second intervals is 2.6 million propagations per satellite. Pass prediction over a ground station network might need sub-second precision across weeks. Trajectory analysis for conjunction screening wants fine-grained time steps to catch close approaches. At 2-3M propagations per second (typical for a good implementation), these workloads take seconds per satellite—that adds up fast when you're doing iterative analysis or building interactive tools.&lt;/p&gt;
    &lt;p&gt;I wanted to see how fast I could make it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting Point: Already Faster Than Expected&lt;/head&gt;
    &lt;p&gt;Before I even started thinking about SIMD, the scalar implementation was already matching or beating the Rust sgp4 crate, the fastest open-source implementation I could find (general purpose). I hadn't done anything clever yet; the speed came from design choices that happened to play well with how Zig compiles.&lt;/p&gt;
    &lt;p&gt;Two things mattered most:&lt;/p&gt;
    &lt;p&gt;Branchless hot paths. The SGP4 algorithm has a lot of conditionals. Deep space vs near earth, different perturbation models, and convergence checks in the Kepler solver. I wrote these as branchless expressions where possible, not for performance reasons initially, but because it made the code easier to reason about. It happened to be a happy accident that modern CPUs love predictable instruction streams.&lt;/p&gt;
    &lt;p&gt;Comptime precomputation. Zig's &lt;code&gt;comptime&lt;/code&gt; lets you run arbitrary code at compile time. A lot of SGP4's setup work, ie. gravity constants, polynomial coefficients, derived parameters can be computed once and baked into the binary. No runtime initialization, and no repeated calculations. I didn't have to do anything special. Zig is smart enough where if you mark a variable as &lt;code&gt;const&lt;/code&gt; it treats it as comptime automatically.&lt;/p&gt;
    &lt;code&gt;const j2: comptime_float = 1.082616e-3; // explicit comptime (not needed)
const j2 = 1.082616e-3; // implied comptime because of `const` (what I used)
&lt;/code&gt;
    &lt;p&gt;The result was a scalar implementation running at ~5.2M propagations per second, which was already slightly faster than Rust's ~5.0M, but within a margin of error. But I started to see some room to go faster. SGP4, by design, doesn't rely on state to calculate positions: each satellite and each time point is independent. This algorithm feels tailor made for something I have always been too afraid to try: SIMD.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discovering Zig's SIMD Superpowers&lt;/head&gt;
    &lt;p&gt;I have heard the nightmares about implementing SIMD. Most of the time its never worth it, it adds too much complexity, you have to build for different platforms, and the syntax itself is weird to write and think about.&lt;/p&gt;
    &lt;p&gt;I was pleasantly surprised to learn that Zig, whether on purpose or not, makes SIMD a first class citizen. This is all enabled by a powerful and sane standard library that has builtins that handle the weird stuff for me. Now I just had to tackle the thought process for the basic flow of things in SIMD.&lt;/p&gt;
    &lt;p&gt;I started with this foundation; a simple type declaration:&lt;/p&gt;
    &lt;code&gt;const Vec4 = @Vector(4, f64);
&lt;/code&gt;
    &lt;p&gt;That's all you need to start. I now have a 4-wide vector of 64-bit floats. No intrinsics, no platform detection, no conditional compilation. The LLVM backend handles targeting the right instruction set for wherever the code runs.&lt;/p&gt;
    &lt;p&gt;The builtin operations for vector operations are equally simple:&lt;/p&gt;
    &lt;code&gt;// Broadcast a scalar to all lanes
const twoPiVec: Vec4 = @splat(constants.twoPi);

// Auto-vectorized transcendentals through LLVM
pub fn sinSIMD(x: Vec4) Vec4 {
    return @sin(x);
}

pub fn cosSIMD(x: Vec4) Vec4 {
    return @cos(x);
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;@sin&lt;/code&gt; and &lt;code&gt;@cos&lt;/code&gt; builtins map directly to LLVM intrinsics, which use platform optimal implementations like libmvec on Linux x86_64. No manual work required.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning to Think in Lanes&lt;/head&gt;
    &lt;p&gt;The arithmetic was easy. What took me a while to internalize was branching.&lt;/p&gt;
    &lt;p&gt;In scalar code, you write &lt;code&gt;if&lt;/code&gt; statements and the CPU takes one path or the other. In SIMD, all four lanes execute together. If lane 0 needs the "true" branch and lane 2 needs the "false" branch, you can't just branch, you have to compute both outcomes and then pick per lane.&lt;/p&gt;
    &lt;p&gt;Here's a concrete example. The scalar SGP4 code has a check like this:&lt;/p&gt;
    &lt;code&gt;// Scalar version
if (eccentricity &amp;lt; 1.0e-4) {
    result = simple_calculation(x);
} else {
    result = complex_calculation(x);
}
&lt;/code&gt;
    &lt;p&gt;In SIMD, this becomes:&lt;/p&gt;
    &lt;code&gt;// SIMD version - compute both, select per-lane
const simple_result = simple_calculation(x);
const complex_result = complex_calculation(x);
const mask = eccentricity &amp;lt; @as(Vec4, @splat(1.0e-4));
const result = @select(f64, mask, simple_result, complex_result);
&lt;/code&gt;
    &lt;p&gt;This felt wasteful at first. Why compute both paths? But modern CPUs are so fast at arithmetic that computing both and selecting is often faster than branch misprediction. Plus, for SGP4, most satellites take the same path anyway, so we're rarely doing truly "wasted" work.&lt;/p&gt;
    &lt;p&gt;The trickier case was convergence loops. SGP4's Kepler solver iterates until each result converges. In scalar code:&lt;/p&gt;
    &lt;code&gt;// Scalar Kepler solver
while (@abs(delta) &amp;gt; tolerance) {
    // iterate...
}
&lt;/code&gt;
    &lt;p&gt;But in SIMD, different lanes converge at different rates. Lane 0 might converge in 3 iterations while lane 3 needs 5. You can't exit early for just one lane. The solution is to track convergence per lane with a mask and use &lt;code&gt;@reduce&lt;/code&gt; to check if everyone's done:&lt;/p&gt;
    &lt;code&gt;// SIMD Kepler solver
var converged: @Vector(4, bool) = @splat(false);
while (!@reduce(.And, converged)) {
    // iterate...
    converged = @abs(delta) &amp;lt;= tolerance_vec;
}
&lt;/code&gt;
    &lt;p&gt;Once I understood this pattern, compute everything, mask the results, reduce to check completion, the rest of the conversion was methodical. I went through the scalar implementation line by line, keeping the original untouched so my test suite could compare outputs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Three Propagation Modes&lt;/head&gt;
    &lt;p&gt;With the core SIMD patterns figured out, I built three different propagation strategies for different use cases.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Time Batched: &lt;code&gt;propagateV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The first question I asked: what's the most common workload? For me, it was generating ephemeris data, and propagating a single satellite across many time points. Pass prediction, trajectory analysis, conjunction screening: they all want dense time series for one object.&lt;/p&gt;
    &lt;p&gt;Time batched propagation processes 4 time points for one satellite simultaneously:&lt;/p&gt;
    &lt;code&gt;pub fn propagateV4(self: *const Sgp4, times: [4]f64) Error![4][2][3]f64 {
    const el = &amp;amp;self.elements;
    const timeV4 = Vec4{ times[0], times[1], times[2], times[3] };

    const secular = updateSecularV4(el, timeV4);
    const nm: Vec4 = @as(Vec4, @splat(el.grav.xke)) / simdMath.pow15V4(secular.a);
    const kepler = solveKeplerV4(el, secular);
    const corrected = applyShortPeriodCorrectionsV4(el, kepler, nm);
    return computePositionVelocityV4(el, corrected);
}
&lt;/code&gt;
    &lt;p&gt;Usage is straightforward:&lt;/p&gt;
    &lt;code&gt;const sat = try Sgp4.init(tle);
const times = [4]f64{ 0.0, 1.0, 2.0, 3.0 }; // minutes since epoch
const results = try sat.propagateV4(times);
// results[0] = position/velocity at t=0, results[1] at t=1, etc.
&lt;/code&gt;
    &lt;p&gt;This mode gave me the biggest initial speedup because it's the most cache friendly: the satellite's orbital elements stay in registers while we compute four outputs.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Satellite Batched: &lt;code&gt;propagateSatellitesV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The opposite workload: what if you have many satellites and need their positions at one specific time? Collision screening snapshots, catalog-wide visibility checks, that sort of thing.&lt;/p&gt;
    &lt;p&gt;Satellite batched propagation processes 4 different satellites at the same time point:&lt;/p&gt;
    &lt;code&gt;pub inline fn propagateSatellitesV4(el: *const ElementsV4, tsince: f64) Error![4][2][3]f64 {
    const tsinceVec: Vec4 = @splat(tsince);
    const secular = updateSecularSatV4(el, tsinceVec);
    const nm: Vec4 = el.xke / simdMath.pow15V4(secular.a);
    const kepler = solveKeplerSatV4(el, secular);
    const corrected = applyShortPeriodCorrectionsSatV4(el, kepler, nm);
    return computePositionVelocitySatV4(el, corrected);
}
&lt;/code&gt;
    &lt;p&gt;This required a different data layout. Instead of one satellite with 4 time points, I needed 4 satellites packed together. That's where &lt;code&gt;ElementsV4&lt;/code&gt; comes in. Its a struct where each field is a &lt;code&gt;Vec4&lt;/code&gt; holding values for 4 different satellites. More on that layout later.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Constellation Mode: &lt;code&gt;propagateConstellationV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The third workload combines both: propagate many satellites across many time points. This is what the live demo does: 13,000 satellites across 1,440 time points.&lt;/p&gt;
    &lt;p&gt;The naive approach would be: for each satellite, compute all time points. But that thrashes the cache. By the time you finish satellite 1's 1,440 points and move to satellite 2, all the time related data has been evicted.&lt;/p&gt;
    &lt;p&gt;Constellation mode uses cache conscious tiling:&lt;/p&gt;
    &lt;code&gt;// Time tile size tuned for L1 cache (~32KB)
const TILE_SIZE: usize = 64;

// Process in tiles over time to keep data in L1/L2 cache
var timeStart: usize = 0;
while (timeStart &amp;lt; numTimes) {
    const timeEnd = @min(timeStart + TILE_SIZE, numTimes);

    for (batches, 0..) |*batch, batchIdx| {
        for (timeStart..timeEnd) |timeIdx| {
            const satResults = try propagateSatellitesV4(batch, times[timeIdx]);
            // Store results...
        }
    }
    timeStart = timeEnd;
}
&lt;/code&gt;
    &lt;p&gt;The idea here is to process 64 time points for all satellites, then the next 64, and so on. The time values stay hot in L1 cache while we sweep through the satellite batches. The tile size (64) isn't magic, it's roughly &lt;code&gt;L1_size / sizeof(working_data)&lt;/code&gt; rounded to a SIMD-friendly number.&lt;/p&gt;
    &lt;p&gt;In practice, constellation mode is about 15-20% faster than calling satellite batched propagation in a naive loop for large catalogs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The atan2 Problem (and Solution)&lt;/head&gt;
    &lt;p&gt;Here's where things got interesting. SGP4's Kepler solver needs &lt;code&gt;atan2&lt;/code&gt;, but LLVM doesn't provide a vectorized builtin for it. Calling the scalar function would break the SIMD implementation.&lt;/p&gt;
    &lt;p&gt;The solution I picked: a polynomial approximation. The key insight is that for SGP4's accuracy requirements (which are inherently limited by the model), we don't need perfect precision.&lt;/p&gt;
    &lt;code&gt;pub fn atan2SIMD(y: Vec4, x: Vec4) Vec4 {
    const abs_x = @abs(x);
    const abs_y = @abs(y);

    // Keep argument in [0, 1] for better polynomial accuracy
    const max_xy = @max(abs_x, abs_y);
    const min_xy = @min(abs_x, abs_y);
    const t = min_xy / @max(max_xy, @as(Vec4, @splat(1.0e-30)));
    const t2 = t * t;

    const c1: Vec4 = @splat(1.0);
    const c3: Vec4 = @splat(-0.3333314528);
    const c5: Vec4 = @splat(0.1999355085);
    // ... more coefficients

    var atan_t = c17;
    atan_t = atan_t * t2 + c15;
    atan_t = atan_t * t2 + c13;
    // ... Horner's method continues
    atan_t = atan_t * t;

    // Quadrant correction using branchless selects
    const swap_mask = abs_y &amp;gt; abs_x;
    atan_t = @select(f64, swap_mask, halfPiVec - atan_t, atan_t);

    // ... more quadrant handling with @select
    return result;
}
&lt;/code&gt;
    &lt;p&gt;This polynomial approximation is accurate to ~1e-7 radians, which translates to about 10mm position error at LEO distances. That's well within SGP4's inherent accuracy limits. The algorithm itself has kilometers of uncertainty over multi-day propagations built into it.&lt;/p&gt;
    &lt;p&gt;To be honest, this math was tricky for me to wrap my head around. I had to ask AI to help me here because I was really struggling with it.&lt;/p&gt;
    &lt;head rend="h2"&gt;"Struct of Arrays" for Multi Satellite Processing&lt;/head&gt;
    &lt;p&gt;For processing multiple satellites, I use a "struct of arrays" layout:&lt;/p&gt;
    &lt;code&gt;pub const ElementsV4 = struct {
    grav: constants.Sgp4GravityModel,

    // Each field is a Vec4 holding values for 4 satellites
    ecco: Vec4,
    inclo: Vec4,
    nodeo: Vec4,
    argpo: Vec4,
    mo: Vec4,
    // ...

    // Pre-splatted constants (computed once at init)
    xke: Vec4,
    j2: Vec4,
    one: Vec4,
    half: Vec4,
    // ...
};
&lt;/code&gt;
    &lt;p&gt;"Pre-splatting" constants eliminates repeated &lt;code&gt;@splat&lt;/code&gt; calls in the hot path. It's a small optimization, but in code running millions of times per second, everything counts, and its an easy win.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Benchmark Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Native Implementation Comparison (Zig vs Rust)&lt;/head&gt;
    &lt;p&gt;First, let's compare apples to apples. Native compiled implementations:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz (Zig)&lt;/cell&gt;
        &lt;cell role="head"&gt;Rust sgp4&lt;/cell&gt;
        &lt;cell role="head"&gt;Speedup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1 day (minute)&lt;/cell&gt;
        &lt;cell&gt;0.27 ms&lt;/cell&gt;
        &lt;cell&gt;0.31 ms&lt;/cell&gt;
        &lt;cell&gt;1.16x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1 week (minute)&lt;/cell&gt;
        &lt;cell&gt;1.99 ms&lt;/cell&gt;
        &lt;cell&gt;2.04 ms&lt;/cell&gt;
        &lt;cell&gt;1.03x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (minute)&lt;/cell&gt;
        &lt;cell&gt;3.87 ms&lt;/cell&gt;
        &lt;cell&gt;4.03 ms&lt;/cell&gt;
        &lt;cell&gt;1.04x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (second)&lt;/cell&gt;
        &lt;cell&gt;222 ms&lt;/cell&gt;
        &lt;cell&gt;234 ms&lt;/cell&gt;
        &lt;cell&gt;1.05x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1 month (minute)&lt;/cell&gt;
        &lt;cell&gt;8.37 ms&lt;/cell&gt;
        &lt;cell&gt;8.94 ms&lt;/cell&gt;
        &lt;cell&gt;1.07x&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Both implementations achieve around 5M propagations/sec for scalar (single-satellite) processing. The Zig implementation edges out Rust slightly. This is most likely hot path optimizations and &lt;code&gt;comptime&lt;/code&gt; being quite aggressive with its pre compute.&lt;/p&gt;
    &lt;head rend="h3"&gt;Native SIMD Throughput Comparison&lt;/head&gt;
    &lt;p&gt;The real gains come from SIMD. When processing multiple satellites or time points in parallel using &lt;code&gt;@Vector(4, f64)&lt;/code&gt;, throughput jumps to 11-13M propagations/sec, more than 2x faster than scalar implementations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Python Bindings Performance&lt;/head&gt;
    &lt;p&gt;For Python users, here's how astroz compares to python-sgp4:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz&lt;/cell&gt;
        &lt;cell role="head"&gt;python-sgp4&lt;/cell&gt;
        &lt;cell role="head"&gt;Speedup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (second)&lt;/cell&gt;
        &lt;cell&gt;160 ms&lt;/cell&gt;
        &lt;cell&gt;464 ms&lt;/cell&gt;
        &lt;cell&gt;2.9x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1 month (minute)&lt;/cell&gt;
        &lt;cell&gt;5.9 ms&lt;/cell&gt;
        &lt;cell&gt;16.1 ms&lt;/cell&gt;
        &lt;cell&gt;2.7x&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Python Bindings Throughput&lt;/head&gt;
    &lt;head rend="h3"&gt;A Note on heyoka.py&lt;/head&gt;
    &lt;p&gt;As mentioned in the intro, heyoka.py deserves attention. Here are the single-threaded benchmarks:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Test&lt;/cell&gt;
        &lt;cell role="head"&gt;heyoka.py&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8 sats × 1440 times&lt;/cell&gt;
        &lt;cell&gt;16.2M/s&lt;/cell&gt;
        &lt;cell&gt;7.5M/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1 sat × 1440 times&lt;/cell&gt;
        &lt;cell&gt;3.8M/s&lt;/cell&gt;
        &lt;cell&gt;8.5M/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;100 sats × 100 times&lt;/cell&gt;
        &lt;cell&gt;15.5M/s&lt;/cell&gt;
        &lt;cell&gt;8.4M/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;heyoka.py wins on multi satellite batches; astroz wins on time batched workloads. Which one you pick depends on your use case:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How many satellites at once? If you're propagating hundreds of satellites at the same time point (collision screening snapshots), heyoka.py wins this easily.&lt;/item&gt;
      &lt;item&gt;How many time points per satellite? If you're generating ephemerides, predicting passes, or doing trajectory analysis for individual satellites across many time steps, astroz is 2x faster.&lt;/item&gt;
      &lt;item&gt;Do you need easy deployment? astroz is &lt;code&gt;pip install astroz&lt;/code&gt;with just NumPy. heyoka.py requires LLVM and a C++ stack that conda-forge recommends over pip.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Seeing It at Scale&lt;/head&gt;
    &lt;p&gt;Speed numbers are abstract until you see what they enable. When propagation is this fast, you stop thinking about batching and scheduling, you just compute what you need, when you need it.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Live Demo&lt;/head&gt;
    &lt;p&gt;To show what this looks like, I built an interactive Cesium visualization that propagates the entire active catalog from CelesTrak (~13,000 satellites) across 1440 time points (a full day at minute resolution). That's ~19 million propagations completing in about 2.7 seconds. Add ~0.6 seconds for TEME→ECEF coordinate conversion, and you get a full day of orbital data for every tracked satellite in about 3.3 seconds. (This demo runs through Python bindings at ~7M/sec; native Zig hits 11-13M/sec.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Forward&lt;/head&gt;
    &lt;p&gt;Next up: SDP4 for deep space objects (the current implementation only handles near-earth satellites with periods under 225 minutes), and multithreading to scale across cores. The SIMD work here was single threaded, there's another multiplier waiting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Yourself&lt;/head&gt;
    &lt;p&gt;astroz is available on PyPI:&lt;/p&gt;
    &lt;code&gt;pip install astroz
&lt;/code&gt;
    &lt;p&gt;Or add it to your Zig project:&lt;/p&gt;
    &lt;code&gt;zig fetch --save git+https://github.com/ATTron/astroz/#HEAD
&lt;/code&gt;
    &lt;p&gt;The code is open source on GitHub. Stars, issues, and contributions welcome.&lt;/p&gt;
    &lt;p&gt;Browse the examples to integrate astroz into your own projects, or try the live demo to see it in action.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46703317</guid><pubDate>Wed, 21 Jan 2026 09:51:27 +0000</pubDate></item><item><title>EU–INC – A new pan-European legal entity</title><link>https://www.eu-inc.org/</link><description>&lt;doc fingerprint="a1be153739b2f6ef"&gt;
  &lt;main&gt;
    &lt;p&gt;WHAT IS EUâINC&lt;/p&gt;
    &lt;head rend="h2"&gt;EUâINC â A true pan-European solution&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;One new pan-European legal entity&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One central EU-level registry&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Standardized investment documents&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Standardized EU-wide stock options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local taxes &amp;amp; employment&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For every founder&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are already working with Brussels. This can become reality. But we need your help!&lt;/p&gt;
    &lt;p&gt;Read the in-detail proposal, made in collaboration with the best startup legal teams, funds and founders in Europe.&lt;/p&gt;
    &lt;p&gt;Welcome to improving europe&lt;/p&gt;
    &lt;p&gt;Why the EUâINC?&lt;/p&gt;
    &lt;p&gt;Europe has the talent, ambition, and ecosystems to create innovative companies, but fragmentation between European nations is holding us back.&lt;/p&gt;
    &lt;p&gt;"A startup from California can expand and raise money all across the United States. But our companies still face way too many national barriers that make it hard to work Europa-wide, and way too much regulatory burden."&lt;/p&gt;
    &lt;p&gt;Political Will&lt;/p&gt;
    &lt;p&gt;Will this actually happen?&lt;/p&gt;
    &lt;p&gt;Yes! But we need your help!&lt;/p&gt;
    &lt;p&gt;So far, we submitted our proposal to Justice Commissioner McGrath and Startup Commissioner Zaharieva.&lt;/p&gt;
    &lt;p&gt;President Von der Leyen has setup a dedicated working group in the Commission with whom we are in regular contact.&lt;/p&gt;
    &lt;p&gt;Additionally, the European Council and Parliament have each signaled interest in the EUâINC, or what in Brussel is called the "28th regime" (for 28th virtual state).&lt;/p&gt;
    &lt;p&gt;ROADMAP&lt;/p&gt;
    &lt;p&gt;What comes next?&lt;/p&gt;
    &lt;p&gt;The entire community is currently influencing the upcoming European Commission legislative proposal for a pan-European legal entity which is set to be released in Q1 2026. We need your help, see below!&lt;/p&gt;
    &lt;p&gt;Afterwards, the European Parliament and the European Council (made up of the 27 national governments) agree on the legislative details. The final implementation of the EUâINC would then happen in 2027.&lt;/p&gt;
    &lt;p&gt;For more details of what happened so far and what comes next, read our roadmap.&lt;/p&gt;
    &lt;p&gt;Join US&lt;/p&gt;
    &lt;p&gt;How you can help: talk to national politicians and press&lt;/p&gt;
    &lt;p&gt;In Europe, laws are still decided on national level, meaning we need to convince all 27 EU member state governments to back the EUâINC.&lt;/p&gt;
    &lt;p&gt;Thus we need YOU to activate your contacts, talk to your national politicians about the urgency of the EUâINC, talk to the press about how crucial the EUâINC is for European startups.&lt;/p&gt;
    &lt;p&gt;National governments need to understand the necessity of EUâINC for the future of Europe. Read more in FAQ.&lt;/p&gt;
    &lt;p&gt;Press&lt;/p&gt;
    &lt;p&gt;Spreading the word&lt;/p&gt;
    &lt;p&gt;You help us immensely if you share this page with your peers, follow &amp;amp; repost us on X &amp;amp; Linkedin and write about the EUâINC â see the FAQ for more infos.&lt;/p&gt;
    &lt;p&gt;You help us immensely if you share this page with your peers, follow &amp;amp; repost us on X &amp;amp; Linkedin and write about the EU-INC â see the FAQ for more infos.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46703763</guid><pubDate>Wed, 21 Jan 2026 10:49:20 +0000</pubDate></item><item><title>The super-slow conversion of the U.S. to metric (2025)</title><link>https://www.thefabricator.com/thefabricator/blog/testingmeasuring/the-super-slow-conversion-of-the-us-to-metric</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704223</guid><pubDate>Wed, 21 Jan 2026 11:36:09 +0000</pubDate></item><item><title>Nukeproof: Manifesto for European Data Sovereignty</title><link>https://nukeproof.org/</link><description>&lt;doc fingerprint="7dfebda9b1c62e4c"&gt;
  &lt;main&gt;
    &lt;p&gt;NukeProof® Alliance&lt;/p&gt;
    &lt;head rend="h1"&gt;Manifesto for European Data Sovereignty&lt;/head&gt;
    &lt;p&gt;There’s a lot of talk about European data sovereignty. Rather than add to the chorus of complaints and inactivity, we are building a strategic alliance that will lead Europe to true data independence.&lt;/p&gt;
    &lt;head rend="h2"&gt;Escape the chokehold of hyperscalers&lt;/head&gt;
    &lt;p&gt;European data is increasingly at the mercy of foreign control. Google, Microsoft, and Amazon now account for more than 60% of the cloud market, while Chinese companies are pushing their own interests. Laws such as the US CLOUD Act undermine the very idea of sovereign data, totally disregarding where the data physically resides.&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s time to take back control together&lt;/head&gt;
    &lt;p&gt;Europe has the talent, the technology and the willpower. What we lack is cohesive action.&lt;/p&gt;
    &lt;p&gt;A patchwork of local providers, startups, MSPs, and telcos struggles to compete with global hyperscalers on scale, capability and cost. NukeProof exists to bring these players together, forming a coalition that enables Europe to stand strong on its own terms.&lt;/p&gt;
    &lt;head rend="h2"&gt;Europe is strongest together&lt;/head&gt;
    &lt;p&gt;This is Europe’s moment of truth. Collaboration is part of our DNA, from shared markets and infrastructure to collective regulation and values.&lt;/p&gt;
    &lt;p&gt;NukeProof channels that spirit and unites independent European actors to create a sovereign cloud of our own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the NukeProof Alliance&lt;/head&gt;
    &lt;p&gt;Join a new era of European data independence built on cooperation, resilience and control.&lt;/p&gt;
    &lt;p&gt;The time is now.&lt;/p&gt;
    &lt;head rend="h2"&gt;Engagement by Country&lt;/head&gt;
    &lt;p&gt;Share of total engagement score&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;p&gt;NukeProof Alliance is an initiative by SpaceTime, a Finnish organisation pushing back on hyperscalers to provide data storage services for European companies on European soil. A patchwork of local providers, startups, MSPs, and telcos struggles to compete with global hyperscalers on scale, capability and cost. NukeProof exists to bring these players together, forming a coalition that enables Europe to stand strong on its own terms.&lt;/p&gt;
    &lt;p&gt;The name NukeProof is an acknowledgement of why the internet was first built: to survive nuclear war. It was decentralised by design and resilient by necessity with no single point of failure. Somewhere along the way, we forgot that.&lt;/p&gt;
    &lt;p&gt;Today, much of the world's digital infrastructure depends on a handful of hyperscalers. When one region goes down, services across continents fail. An architecture designed for resilience has been replaced by fragile concentration. NukeProof returns the focus to the origins of the internet.&lt;/p&gt;
    &lt;p&gt;Your data is increasingly at the mercy of foreign control. Google, Microsoft, and Amazon now account for more than 60% of the cloud market, while Chinese companies are pushing their own interests. Laws such as the US CLOUD Act undermine the very idea of sovereign data, totally disregarding where the data physically resides. NukeProof Alliance is developing a collaborative approach to offer Europe-based cloud services to regain our continent's digital ownership.&lt;/p&gt;
    &lt;p&gt;NukeProof Alliance was started by SpaceTime, a Finland-based storage provider company, and it is open to all companies involved in the data, storage and digital industries.&lt;/p&gt;
    &lt;p&gt;Fill out the form on nukeproof.org. The forms ask about your role, whether you want to sponsor, provide technology, become an advocacy partner or just support the alliance silently, you can be a part of NukeProof. Follow us on LinkedIn, too.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704310</guid><pubDate>Wed, 21 Jan 2026 11:44:48 +0000</pubDate></item><item><title>Hightouch (YC S19) Is Hiring</title><link>https://hightouch.com/careers</link><description>&lt;doc fingerprint="1afc511d6c36362c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We are a small team of kind and talented people&lt;/head&gt;
    &lt;head rend="h2"&gt;Let’s grow together&lt;/head&gt;
    &lt;p&gt;At Hightouch, we’re committed to helping our customers, business, and employees grow. As a series C startup backed by top investors, we are determined to continuously raise the bar and provide the best product in the market. Grow your career in a fast paced environment that values creative thinking and innovation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our values&lt;/head&gt;
    &lt;head rend="h3"&gt;Forever hungry&lt;/head&gt;
    &lt;p&gt;We are hungry and ambitious. We celebrate our accomplishments, but we’re never fully satisfied. We’re always figuring out how to collectively push ourselves further and do more.If we think we can grow the company 5x this year, the first question should be “why not 10x?”&lt;/p&gt;
    &lt;head rend="h3"&gt;Kindness&lt;/head&gt;
    &lt;p&gt;We want to create an environment where people feel actively welcomed, encouraged, and supported. People who aren’t kind aren’t tolerated — it’s just not worth it.We intrinsically believe in a deeper kindness as a core value, aside from its obvious benefits to the business&lt;/p&gt;
    &lt;head rend="h3"&gt;Efficient execution&lt;/head&gt;
    &lt;p&gt;Speed matters. We don’t have time for endless deliberation — most decisions are two-way doors. Move fast, adapt quickly.We take inspiration from others and don’t innovate where we don’t need to. We communicate clearly because time is precious. We parallelize to the greatest extent possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compassion&lt;/head&gt;
    &lt;p&gt;We listen to everyone and try to put ourselves in their shoes, regardless of our initial reaction to what they say.This applies to everyone — customers, prospects, partners, peers, etc.&lt;/p&gt;
    &lt;head rend="h3"&gt;Impact driven&lt;/head&gt;
    &lt;p&gt;Everyone should be intrinsically motivated by business impact. We minimize distractions and prioritize our time based on what’s actually impactful to the business.We value people at all levels based on their impact above anything else.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raising the bar&lt;/head&gt;
    &lt;p&gt;We have high expectations for performance and believe in having exceptional talent in every position. We understand the value of great people.We look deeper than credentials, prioritize slope over y-intercept, and put in the hard work to find those that truly raise the bar.&lt;/p&gt;
    &lt;head rend="h3"&gt;Humility&lt;/head&gt;
    &lt;p&gt;We are humble. Listening is mission critical — we are open to others’ perspectives and ideas. No work is beneath us. We also believe that humility leads to foresight.If we are not grounded and open minded, we blind ourselves from key opportunities and risks in every aspect of business.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
    &lt;head rend="h3"&gt;Competitive compensation&lt;/head&gt;
    &lt;p&gt;We offer competitive compensation and meaningful equity. We also offer 401k for our US employees and retirement plans for our international employees.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hub &amp;amp; Remote friendly&lt;/head&gt;
    &lt;p&gt;Join our global team, either remotely or in one of our four in-person offices (San Francisco, NYC, Charlotte, and London). For those near an office, enjoy complimentary lunches Monday through Friday.&lt;/p&gt;
    &lt;head rend="h3"&gt;Flexible PTO&lt;/head&gt;
    &lt;p&gt;Downtime is just as important as on time and your teammates will support you while you relax and recharge.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core benefits&lt;/head&gt;
    &lt;p&gt;For full-time US-based employees, we cover all health benefit premiums, 80% for dependents, and life insurance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parental leave&lt;/head&gt;
    &lt;p&gt;We value and support the family planning process. We provide up to 16 weeks for parents.&lt;/p&gt;
    &lt;head rend="h3"&gt;Professional development&lt;/head&gt;
    &lt;p&gt;We support employees for all learning resources needed to grow in their role (classes, books, conferences, etc).&lt;/p&gt;
    &lt;head rend="h3"&gt;Connectivity&lt;/head&gt;
    &lt;p&gt;We offer a $50 per month cell-phone or wifi connectivity stipend to all employees.&lt;/p&gt;
    &lt;head rend="h3"&gt;Commuter&lt;/head&gt;
    &lt;p&gt;Commuter benefits of $150 are offered to both employees who come into the offices and to remote workers working outside of their home.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open positions&lt;/head&gt;
    &lt;head rend="h3"&gt;Customer Success&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Account Manager&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer Success Engineer&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Head of Customer Success Engineering (West)&lt;/p&gt;
        &lt;p&gt;Remote (Mountain/Pacific North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implementation Manager&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Technical Account Management&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Technical Account Manager&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Engineering&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Backend Engineer, AI Content Agents&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Developer Productivity Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Forward Deployed Data Scientist&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Full Stack Product Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Head of Machine Learning&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Machine Learning Engineer, AI Decisioning&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Principal Engineer, Streaming Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, AI Agents&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Control Plane&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Customer Studio Backend&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Distributed Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Journeys&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Streaming Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Web Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Finance / Data / Operations&lt;/head&gt;
    &lt;head rend="h3"&gt;Marketing&lt;/head&gt;
    &lt;head rend="h3"&gt;Partnerships&lt;/head&gt;
    &lt;head rend="h3"&gt;People&lt;/head&gt;
    &lt;head rend="h3"&gt;Sales&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Account Executive (APAC)&lt;/p&gt;
        &lt;p&gt;Remote (APAC)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive- East Region&lt;/p&gt;
        &lt;p&gt;Remote (East Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, Mountain West Region&lt;/p&gt;
        &lt;p&gt;Remote (Mountain West)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, North EMEA&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, South EMEA&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, West Region&lt;/p&gt;
        &lt;p&gt;Remote (West Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Solutions Engineer, East&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Solutions Engineer, West&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Sales Development&lt;/p&gt;
        &lt;p&gt;Denver, Colorado&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Sales Development&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Solutions Engineering&lt;/p&gt;
        &lt;p&gt;New York, NY or San Francisco, CA&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mid-Market Account Executive, East Region&lt;/p&gt;
        &lt;p&gt;Remote (East Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mid-Market Account Executive, EMEA&lt;/p&gt;
        &lt;p&gt;London, United Kingdom&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Regional VP of Enterprise Sales&lt;/p&gt;
        &lt;p&gt;New York, New York/ Boston, Massachusetts&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;RVP, Mid-Market Sales&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sales Development Representative&lt;/p&gt;
        &lt;p&gt;New York, NY / Denver, CO / San Francisco, CA&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sales Development Representative, EMEA&lt;/p&gt;
        &lt;p&gt;London, United Kingdom&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solutions Engineer, EMEA&lt;/p&gt;
        &lt;p&gt;Remote Europe&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solutions Engineer (France)&lt;/p&gt;
        &lt;p&gt;Paris, France&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hightouch has been named America’s #3 best startup employer by Forbes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704465</guid><pubDate>Wed, 21 Jan 2026 12:02:09 +0000</pubDate></item><item><title>Stories removed from the Hacker News Front Page, updated in real time (2024)</title><link>https://github.com/vitoplantamura/HackerNewsRemovals</link><description>&lt;doc fingerprint="5bebd97070e39b2"&gt;
  &lt;main&gt;
    &lt;p&gt;UPDATE (February 4, 2024): This is the discussion about this project on HN: here. Please specifically read @dang's comment regarding the core assumption of this project: here. On a personal note, the number of Stories removed yesterday (Saturday, February 3, 2024) was the lowest ever recorded by the service. This includes 2 duplicate Stories. As a side note, in the list always check whether a Story is a duplicate or not: this is a very reasonable reason for removal and unfortunately I have no way of automatically determining it in the service!&lt;/p&gt;
    &lt;p&gt;The purpose of this project is to try to understand the type and scale of the moderation of the Hacker News Front Page.&lt;/p&gt;
    &lt;p&gt;NOTE: I love Hacker News. I try to read it every day. In the case of OnnxStream (here for example), 95% of the comments were helpful and intelligent. I also understand that moderating a site with huge traffic and where users are basically anonymous must be a very difficult task.&lt;/p&gt;
    &lt;p&gt;Returning to the purpose of this project, from what I have been able to see, the "public" (i.e. observable from the outside) moderation of the Front Page consists of two main tools: modification of the title of a Story (voluntarily or involuntarily influencing its growth in terms of rank) or directly its removal.&lt;/p&gt;
    &lt;p&gt;Regarding the first type of moderation, an excellent site is already available that tracks changes to Story titles. Here instead I will focus on the second type.&lt;/p&gt;
    &lt;p&gt;For the reasons explained in the "Why?" section below, I have developed a small application that logs all the Stories that are removed from the Front Page, for personal use. I later discovered that there is no tool/website that provides this type of information and I decided to make it public here. It was a difficult decision but my rationale is: is it better to have more transparency or less transparency?&lt;/p&gt;
    &lt;p&gt;If you know of a tool/website similar to this, please let me know: I will archive this repo or set it to private.&lt;/p&gt;
    &lt;p&gt;A possible very positive outcome for this project could be to have a list similar to this, but available directly among the HN lists. Or even to notify a user when a Story is penalized on the Front Page, perhaps indicating the number of flags and/or the reason, for example.&lt;/p&gt;
    &lt;head&gt;Feel free to skip this part or click to expand&lt;/head&gt;
    &lt;p&gt;A friend of mine posted two Stories on Hacker News related to OnnxStream (31 days apart), the first related to SDXL Turbo support and the second related to TinyLlama and Mistral 7B support.&lt;/p&gt;
    &lt;p&gt;In the case of the first, the Story was among the first on the Front Page, until its title was changed from "Stable Diffusion Turbo on a Raspberry Pi Zero 2 generates an image in 29 minutes" to "OnnxStream: Stable Diffusion XL 1.0 Base on a Raspberry Pi Zero 2". This effectively "killed" the Story. One user pointed out that the new title didn't reflect the spirit of the Story (thanks @practice9).&lt;/p&gt;
    &lt;p&gt;In the case of the second, the Story was in third place on the Front Page, less than an hour after the submission. In this case it was simply removed from the Front Page.&lt;/p&gt;
    &lt;p&gt;Having discovered this, perplexed, I sent an email to the moderator. @dang, who was very kind and quick in his response, explained to me that the Story had been flagged by users even without being explicitly [flagged], and that he could therefore only hypothesize the causes of the flag. His hypothesis was that (some?) users might be fed up with news related to LLMs.&lt;/p&gt;
    &lt;p&gt;While I have no reason to doubt Daniel's good faith, it's hard to believe that HN users would be tired of LLM-related news.&lt;/p&gt;
    &lt;p&gt;So I decided to develop a small console application to determine the frequency of this phenomenon (actually I was also motivated by the prospect of writing some C# code, after more than 2 years of complete abstinence). I subsequently discovered that there were no tools/websites that monitored this specific phenomenon and I therefore decided to make it public here.&lt;/p&gt;
    &lt;p&gt;Using the official HN API, the service fetches 90 Top Stories every minute and makes a comparison with the first 30 Top Stories (i.e. the Front Page) fetched the previous minute. It logs all missing Stories here. The assumption is that a Story cannot go from the top 30 to a position greater than 90 in a single minute, without having been explicitly removed. If a Story reappears on the Front Page, it is removed from this log. All Stories present in the second-chance pool are excluded from the log. Title and URL are those from when the Story first appeared in the top 30. The number of points and comments and the rank are those from when the Story was removed from the Front Page. The ID points to the news.social-protocols.org page for that Story, which provides a graph of the Story's position on the Front Page over time.&lt;/p&gt;
    &lt;p&gt;NOTE: always check whether a Story is a duplicate or not: this is a very reasonable reason for removal and unfortunately I have no way of automatically determining it in the service!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46625766 #19 33 points 18 comments -&amp;gt; Billion-Dollar Idea Generator&lt;/item&gt;
      &lt;item&gt;46626826 #3 25 points 40 comments -&amp;gt; Is passive investment inflating a stockmarket bubble?&lt;/item&gt;
      &lt;item&gt;46628484 #8 6 points 10 comments -&amp;gt; Tech Writers Are About to Become Obsolete&lt;/item&gt;
      &lt;item&gt;46628185 #26 2 points 1 comments -&amp;gt; Raising Kids After Knowledge Became a Commodity&lt;/item&gt;
      &lt;item&gt;46632955 #11 31 points 41 comments -&amp;gt; Nvidia Reportedly Ends GeForce RTX 5070 Ti Production, RTX 5060 Ti 16 GB Next&lt;/item&gt;
      &lt;item&gt;46634263 #25 20 points 19 comments -&amp;gt; European military personnel arrive in Greenland as Trump says US needs island&lt;/item&gt;
      &lt;item&gt;46566065 #13 13 points 3 comments -&amp;gt; Investing with GIFs: A Visual Guide&lt;/item&gt;
      &lt;item&gt;46635810 #4 9 points 2 comments -&amp;gt; AI Tool Archive&lt;/item&gt;
      &lt;item&gt;46639805 #27 3 points 1 comments -&amp;gt; There Is No Green Transition, and This Book Explains Why&lt;/item&gt;
      &lt;item&gt;46547400 #30 20 points 2 comments -&amp;gt; Virginia Faulkner: Writer, editor, and ghostwriter?&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46641007 #27 11 points 2 comments -&amp;gt; An Unfolding Scientific Revolution in Cosmology&lt;/item&gt;
      &lt;item&gt;46643070 #2 35 points 42 comments -&amp;gt; The Myth of the ThinkPad&lt;/item&gt;
      &lt;item&gt;46647338 #9 -&amp;gt; I mass-deleted 200 lines of AI-generated code yesterday. All broken&lt;/item&gt;
      &lt;item&gt;46646490 #30 10 points 2 comments -&amp;gt; Astro is joining Cloudflare&lt;/item&gt;
      &lt;item&gt;46648978 #26 43 points 12 comments -&amp;gt; ICE takes back into custody man released for violation of rights&lt;/item&gt;
      &lt;item&gt;46652299 #7 8 points 8 comments -&amp;gt; The Engineer to Executive Translation Layer&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46655034 #23 5 points 0 comments -&amp;gt; Gas Town is a glimpse into the future&lt;/item&gt;
      &lt;item&gt;46653388 #6 53 points 5 comments -&amp;gt; The Dilbert Afterlife&lt;/item&gt;
      &lt;item&gt;46657947 #10 5 points 0 comments -&amp;gt; The App You Should Be Building Is You&lt;/item&gt;
      &lt;item&gt;46577968 #20 22 points 14 comments -&amp;gt; Finding and Fixing a 50k Goroutine Leak That Nearly Killed Production&lt;/item&gt;
      &lt;item&gt;46658166 #4 3 points 1 comments -&amp;gt; Rust for C Programmers&lt;/item&gt;
      &lt;item&gt;46661308 #7 31 points 26 comments -&amp;gt; Show HN: Minikv – Distributed key-value and object store in Rust (Raft, S3 API)&lt;/item&gt;
      &lt;item&gt;46661505 #29 5 points 0 comments -&amp;gt; Kagi Small Web&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46661936 #12 25 points 21 comments -&amp;gt; The Death of Software Development&lt;/item&gt;
      &lt;item&gt;46662886 #11 36 points 12 comments -&amp;gt; Texas A&amp;amp;M university is banning Plato, citing his "gender ideology"&lt;/item&gt;
      &lt;item&gt;46662503 #15 69 points 40 comments -&amp;gt; Congress Wants to Hand Your Parenting to Big Tech&lt;/item&gt;
      &lt;item&gt;46662401 #17 10 points 3 comments -&amp;gt; If writing the code is the easy part, why would I want someone else to write it?&lt;/item&gt;
      &lt;item&gt;46630869 #22 10 points 11 comments -&amp;gt; Show HN: I built a game on my old phone without knowing what I was building&lt;/item&gt;
      &lt;item&gt;46663785 #10 4 points 5 comments -&amp;gt; GTA 6's Dynamic Economy Will Change Open‑World Games Forever&lt;/item&gt;
      &lt;item&gt;46665967 #20 29 points 40 comments -&amp;gt; The Walls Are Closing in on Tesla&lt;/item&gt;
      &lt;item&gt;46666916 #28 26 points 2 comments -&amp;gt; Throwing it all away over the Mercator projection&lt;/item&gt;
      &lt;item&gt;46668107 #4 6 points 0 comments -&amp;gt; The next-gen SQLite won't look like SQLite&lt;/item&gt;
      &lt;item&gt;46668424 #29 -&amp;gt; Claude Is Taking the AI World by Storm, and Even Non-Nerds Are Blown Away&lt;/item&gt;
      &lt;item&gt;46590480 #17 6 points 5 comments -&amp;gt; Ask HN: Does PPP (Parity Pricing) work for one-time digital products?&lt;/item&gt;
      &lt;item&gt;46668394 #28 13 points 40 comments -&amp;gt; Why the Tech World Thinks the American Dream Is Dying&lt;/item&gt;
      &lt;item&gt;46669025 #2 259 points 191 comments -&amp;gt; Statement by Denmark, Finland, France, Germany, the Netherlands,Norway,Sweden,UK&lt;/item&gt;
      &lt;item&gt;46669250 #2 13 points 3 comments -&amp;gt; Solve the MH370 Paradox in 10 Seconds&lt;/item&gt;
      &lt;item&gt;46670568 #26 15 points 3 comments -&amp;gt; A pandemic rescue became a 30-year debt trap&lt;/item&gt;
      &lt;item&gt;46594722 #15 12 points 6 comments -&amp;gt; River Runner&lt;/item&gt;
      &lt;item&gt;46588159 #16 128 points 69 comments -&amp;gt; Milk-V Titan: A $329 8-Core 64-bit RISC-V mini-ITX board with PCIe Gen4x16&lt;/item&gt;
      &lt;item&gt;46600955 #30 23 points 0 comments -&amp;gt; Multiword matrix multiplication over large finite fields in floating-point&lt;/item&gt;
      &lt;item&gt;46672714 #20 9 points 0 comments -&amp;gt; EU to Retaliate on Tariffs&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46674513 #29 4 points 2 comments -&amp;gt; In Minneapolis, a Pattern of Misconduct Toward Protesters&lt;/item&gt;
      &lt;item&gt;46674976 #28 14 points 5 comments -&amp;gt; My thoughts on Gas Town after 10k hours of Claude Code&lt;/item&gt;
      &lt;item&gt;46676991 #13 31 points 16 comments -&amp;gt; The Jolla Phone Proved We've Been Using Smartphones Wrong All Along&lt;/item&gt;
      &lt;item&gt;46677907 #22 8 points 0 comments -&amp;gt; Oxfam's wealth inequality report 2026: Resisting the Rule of the Rich&lt;/item&gt;
      &lt;item&gt;46677549 #27 21 points 22 comments -&amp;gt; Show HN: Kacet – a freelancer marketplace with crypto-native payments&lt;/item&gt;
      &lt;item&gt;46678163 #8 13 points 2 comments -&amp;gt; Are you tired of AI stigma?&lt;/item&gt;
      &lt;item&gt;46679230 #9 15 points 2 comments -&amp;gt; Sweden deploys fighter jets to Iceland&lt;/item&gt;
      &lt;item&gt;46679515 #23 10 points 4 comments -&amp;gt; Idiocracy&lt;/item&gt;
      &lt;item&gt;46626441 #17 68 points 17 comments -&amp;gt; Vm0&lt;/item&gt;
      &lt;item&gt;46680261 #5 11 points 15 comments -&amp;gt; Are You YES AI or No AI?&lt;/item&gt;
      &lt;item&gt;46673809 #15 285 points 377 comments -&amp;gt; Show HN: I quit coding years ago. AI brought me back&lt;/item&gt;
      &lt;item&gt;46682806 #7 57 points 18 comments -&amp;gt; US Places Arctic Airborne Troops on Standby as Greenland Dispute Escalates&lt;/item&gt;
      &lt;item&gt;46683447 #8 2 points 0 comments -&amp;gt; The unreasonable effectiveness of pattern matching&lt;/item&gt;
      &lt;item&gt;46607969 #27 55 points 62 comments -&amp;gt; Two Concepts of Intelligence&lt;/item&gt;
      &lt;item&gt;46684647 #10 -&amp;gt; Help Denmark Buy California – Because Why Not?&lt;/item&gt;
      &lt;item&gt;46685325 #7 13 points 0 comments -&amp;gt; What Have Unions Done for Us?&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46688787 #1 10 points 4 comments -&amp;gt; You did not vote for Him, but you helped Him win&lt;/item&gt;
      &lt;item&gt;46689143 #7 64 points 2 comments -&amp;gt; America Is Slow-Walking into a Polymarket Disaster&lt;/item&gt;
      &lt;item&gt;46644356 #4 4 points 0 comments -&amp;gt; Show HN: Bettershot an OSS Alternative of Cleanshot&lt;/item&gt;
      &lt;item&gt;46692087 #23 6 points 0 comments -&amp;gt; Minneapolis software engineers mistaken for ICE agents&lt;/item&gt;
      &lt;item&gt;46692284 #25 5 points 1 comments -&amp;gt; Vibe coding is a hobby. Let me explain&lt;/item&gt;
      &lt;item&gt;46693363 #13 11 points 2 comments -&amp;gt; US citizen says ICE removed him from his Minnesota home in his underwear&lt;/item&gt;
      &lt;item&gt;46693456 #12 13 points 4 comments -&amp;gt; 'AI' is a dick move, redux&lt;/item&gt;
      &lt;item&gt;46693021 #22 17 points 19 comments -&amp;gt; Claude Code is the ChatGPT moment repeated and awful news for software stocks&lt;/item&gt;
      &lt;item&gt;46646174 #14 25 points 10 comments -&amp;gt; A Pro Meticulously Restores a Damaged Oil Painting [video]&lt;/item&gt;
      &lt;item&gt;46695492 #22 3 points 0 comments -&amp;gt; Show HN: Typing Tennis&lt;/item&gt;
      &lt;item&gt;46697700 #15 -&amp;gt; Citizen says ICE took him at gunpoint in underwear despite cold and no warrant&lt;/item&gt;
      &lt;item&gt;46696300 #14 64 points 38 comments -&amp;gt; Without benchmarking LLMs, you're likely overpaying 5-10x&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;46698723 #26 -&amp;gt; DOGE employees may have improperly accessed social security data, DOJ says&lt;/item&gt;
      &lt;item&gt;46632593 #18 12 points 0 comments -&amp;gt; Catching API regressions with snapshot testing&lt;/item&gt;
      &lt;item&gt;46701239 #4 12 points 4 comments -&amp;gt; Germany Forces Lexus to Remotely Kill Car Heating in Dead of Winter&lt;/item&gt;
      &lt;item&gt;46663686 #29 12 points 2 comments -&amp;gt; The life of a playboy publisher who shaped 20th-century literature&lt;/item&gt;
      &lt;item&gt;46702019 #22 8 points 1 comments -&amp;gt; EU moves closer to using its trade bazooka against the US&lt;/item&gt;
      &lt;item&gt;46703243 #10 4 points 1 comments -&amp;gt; Leave X – Protect Democracy&lt;/item&gt;
      &lt;item&gt;46702411 #4 32 points 40 comments -&amp;gt; Can you slim macOS down?&lt;/item&gt;
      &lt;item&gt;46703643 #30 33 points 19 comments -&amp;gt; EU chief says EU should abandon caution after Bessent calls Denmark 'irrelevant'&lt;/item&gt;
      &lt;item&gt;46705402 #21 10 points 1 comments -&amp;gt; Europe has a lot to learn from Mark Carney&lt;/item&gt;
      &lt;item&gt;46705385 #29 58 points 35 comments -&amp;gt; Canada Announces Divorce from America&lt;/item&gt;
      &lt;item&gt;46706732 #22 12 points 0 comments -&amp;gt; The Oligarchs Pushing for Conquest in Greenland&lt;/item&gt;
      &lt;item&gt;46706532 #21 -&amp;gt; DOGE Employees Shared Social Security Data&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704555</guid><pubDate>Wed, 21 Jan 2026 12:11:11 +0000</pubDate></item><item><title>Vibecoding #2</title><link>https://matklad.github.io/2026/01/20/vibecoding-2.html</link><description>&lt;doc fingerprint="332988960f858b6b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vibecoding #2&lt;/head&gt;
    &lt;p&gt;I feel like I got substantial value out of Claude today, and want to document it. I am at the tail end of AI adoption, so I don’t expect to say anything particularly useful or novel. However, I am constantly complaining about the lack of boring AI posts, so it’s only proper if I write one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problem Statement&lt;/head&gt;
    &lt;p&gt;At TigerBeetle, we are big on deterministic simulation testing. We even use it to track performance, to some degree. Still, it is crucial to verify performance numbers on a real cluster in its natural high-altitude habitat.&lt;/p&gt;
    &lt;p&gt; To do that, you need to procure six machines in a cloud, get your custom version of &lt;code&gt;tigerbeetle&lt;/code&gt;
            binary on them, connect cluster’s replicas together and hit them
            with load. It feels like, quarter of a century into the third
            millennium, “run stuff on six machines” should be a problem just a
            notch harder than opening a terminal and typing &lt;code&gt;ls&lt;/code&gt;, but
            I personally don’t know how to solve it without wasting a day. So, I
            spent a day vibecoding my own square wheel.
          &lt;/p&gt;
    &lt;p&gt;The general shape of the problem is that I want to spin a fleet of ephemeral machines with given specs on demand and run ad-hoc commands in a SIMD fashion on them. I don’t want to manually type slightly different commands into a six-way terminal split, but I also do want to be able to ssh into a specific box and poke it around.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solution&lt;/head&gt;
    &lt;p&gt;My idea for the solution comes from these three sources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/catern/rsyscall&lt;/item&gt;
      &lt;item&gt;https://peter.bourgon.org/blog/2011/04/27/remote-development-from-mac-to-linux.html&lt;/item&gt;
      &lt;item&gt;https://github.com/dsherret/dax&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; The big idea of &lt;code&gt;rsyscall&lt;/code&gt; is that you can program
            distributed system in direct style. When programming locally, you do
            things by issuing syscalls:
          &lt;/p&gt;
    &lt;p&gt;This API works for doing things on remote machines, if you specify which machine you want to run the syscall on:&lt;/p&gt;
    &lt;p&gt;Direct manipulation is the most natural API, and it pays to extend it over the network boundary.&lt;/p&gt;
    &lt;p&gt;Peter’s post is an application of a similar idea to a narrow, mundane task of developing on Mac and testing on Linux. Peter suggests two scripts:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;remote-sync&lt;/code&gt; synchronizes a local and remote projects.
            If you run &lt;code&gt;remote-sync&lt;/code&gt; inside &lt;code&gt;~/p/tb&lt;/code&gt;
            folder, then &lt;code&gt;~/p/tb&lt;/code&gt; materializes on the remote machine.
            &lt;code&gt;rsync&lt;/code&gt; does the heavy lifting, and the wrapper script
            implements &lt;code&gt;DWIM&lt;/code&gt; behaviors.
          &lt;/p&gt;
    &lt;p&gt; It is typically followed by &lt;code&gt;remote-run some --command&lt;/code&gt;,
            which runs command on the remote machine in the matching directory,
            forwarding output back to you.
          &lt;/p&gt;
    &lt;p&gt; So, when I want to test local changes to &lt;code&gt;tigerbeetle&lt;/code&gt; on
            my Linux box, I have roughly the following shell session:
          &lt;/p&gt;
    &lt;p&gt; The killer feature is that shell-completion works. I first type the command I want to run, taking advantage of the fact that local and remote commands are the same, paths and all, then hit &lt;code&gt;^A&lt;/code&gt; and prepend &lt;code&gt;remote-run&lt;/code&gt; (in reality, I have
            &lt;code&gt;rr&lt;/code&gt; alias that combines sync&amp;amp;run).
          &lt;/p&gt;
    &lt;p&gt; The big thing here is not the commands per se, but the shift in the mental model. In a traditional ssh &amp;amp; vim setup, you have to juggle two machines with a separate state, the local one and the remote one. With &lt;code&gt;remote-sync&lt;/code&gt;, the state is the same
            across the machines, you only choose whether you want to run
            commands here or there.
          &lt;/p&gt;
    &lt;p&gt;With just two machines, the difference feels academic. But if you want to run your tests across six machines, the ssh approach fails — you don’t want to re-vim your changes to source files six times, you really do want to separate the place where the code is edited from the place(s) where the code is run. This is a general pattern — if you are not sure about a particular aspect of your design, try increasing the cardinality of the core abstraction from 1 to 2.&lt;/p&gt;
    &lt;p&gt; The third component, &lt;code&gt;dax&lt;/code&gt; library, is pretty mundane —
            just a JavaScript library for shell scripting. The notable aspects
            there are:
          &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;JavaScript’s template literals, which allow implementing command interpolation in a safe by construction way. When processing&lt;/p&gt;&lt;code&gt;$`ls ${paths}`&lt;/code&gt;, a string is never materialized, it’s arrays all the way to the&lt;code&gt;exec&lt;/code&gt;syscall ( more on the topic).&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;JavaScript’s async/await, which makes managing concurrent processes (local or remote) natural:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Additionally, deno specifically valiantly strives to impose process-level structured concurrency, ensuring that no processes spawned by the script outlive the script itself, unless explicitly marked&lt;/p&gt;&lt;code&gt;detached&lt;/code&gt;— a sour spot of UNIX.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Combining the three ideas, I now have a deno script, called &lt;code&gt;box&lt;/code&gt;, that provides a multiplexed interface for running
            ad-hoc code on ad-hoc clusters.
          &lt;/p&gt;
    &lt;p&gt;A session looks like this:&lt;/p&gt;
    &lt;p&gt;I like this! Haven’t used in anger yet, but this is something I wanted for a long time, and now I have it&lt;/p&gt;
    &lt;head rend="h2"&gt;Structure&lt;/head&gt;
    &lt;p&gt;The problem with implementing above is that I have zero practical experience with modern cloud. I only created my AWS account today, and just looking at the console interface ignited the urge to re-read The Castle. Not my cup of pu-erh. But I had a hypothesis that AI should be good at wrangling baroque cloud API, and it mostly held.&lt;/p&gt;
    &lt;p&gt;I started with a couple of paragraphs of rough, super high-level description of what I want to get. Not a specification at all, just a general gesture towards unknown unknowns. Then I asked ChatGPT to expand those two paragraphs into a more or less complete spec to hand down to an agent for implementation.&lt;/p&gt;
    &lt;p&gt;This phase surfaced a bunch of unknowns for me. For example, I wasn’t thinking at all that I somehow need to identify machines, ChatGPT suggested using random hex numbers, and I realized that I do need 0,1,2 naming scheme to concisely specify batches of machines. While thinking about this, I realized that sequential numbering scheme also has an advantage that I can’t have two concurrent clusters running, which is a desirable property for my use-case. If I forgot to shutdown a machine, I’d rather get an error on trying to re-create a machine with the same name, then to silently avoid the clash. Similarly, turns out the questions of permissions and network access rules are something to think about, as well as what region and what image I need.&lt;/p&gt;
    &lt;p&gt;With the spec document in hand, I turned over to Claude code for actual implementation work. The first step was to further refine the spec, asking Claude if anything is unclear. There were couple of interesting clarifications there.&lt;/p&gt;
    &lt;p&gt; First, the original ChatGPT spec didn’t get what I meant with my “current directory mapping” idea, that I want to materialize a local &lt;code&gt;~/p/tb/work&lt;/code&gt; as remote &lt;code&gt;~/p/tb/work&lt;/code&gt;, even if
            &lt;code&gt;~&lt;/code&gt; are different. ChatGPT generated an incorrect
            description and an incorrect example. I manually corrected
            example, but wasn’t able to write a concise and correct description.
            Claude fixed that working from the example. I feel like I need to
            internalize this more — for current crop of AI, examples seem to be
            far more valuable than rules.
          &lt;/p&gt;
    &lt;p&gt;Second, the spec included my desire to auto-shutdown machines once I no longer use them, just to make sure I don’t forget to turn the lights off when leaving the room. Claude grilled me on what precisely I want there, and I asked it to DWIM the thing.&lt;/p&gt;
    &lt;p&gt;The spec ended up being 6KiB of English prose. The final implementation was 14KiB of TypeScript. I wasn’t keeping the spec and the implementation perfectly in sync, but I think they ended up pretty close in the end. Which means that prose specifications are somewhat more compact than code, but not much more compact.&lt;/p&gt;
    &lt;p&gt;My next step was to try to just one-shot this. Ok, this is embarrassing, and I usually avoid swearing in this blog, but I just typoed that as “one-shit”, and, well, that is one flavorful description I won’t be able to improve upon. The result was just not good (more on why later), so I almost immediately decided to throw it away and start a more incremental approach.&lt;/p&gt;
    &lt;p&gt;In my previous vibe-post, I noticed that LLM are good at closing the loop. A variation here is that LLMs are good at producing results, and not necessarily good code. I am pretty sure that, if I had let the agent to iterate on the initial script and actually run it against AWS, I would have gotten something working. I didn’t want to go that way for three reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Spawning VMs takes time, and that significantly reduces the throughput of agentic iteration.&lt;/item&gt;
      &lt;item&gt;No way I let the agent run with a real AWS account, given that AWS doesn’t have a fool-proof way to cap costs.&lt;/item&gt;
      &lt;item&gt;I am fairly confident that this script will be a part of my workflow for at least several years, so I care more about long-term code maintenance, than immediate result.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And, as I said, the code didn’t feel good, for these specific reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It wasn’t the code that I would have written, it lacked my character, which made it hard for me to understand it at a glance.&lt;/item&gt;
      &lt;item&gt;The code lacked any character whatsoever. It could have worked, it wasn’t “naively bad”, like the first code you write when you are learning programming, but there wasn’t anything good there.&lt;/item&gt;
      &lt;item&gt;I never know what the code should be up-front. I don’t design solutions, I discover them in the process of refactoring. Some of my best work was spending a quiet weekend rewriting large subsystems implemented before me, because, with an implementation at hand, it was possible for me to see the actual, beautiful core of what needs to be done. With a slop-dump, I just don’t get to even see what could be wrong.&lt;/item&gt;
      &lt;item&gt;In particular, while you are working the code (as in “wrought iron”), you often go back to requirements and change them. Remember that ambiguity of my request to “shut down idle cluster”? Claude tried to DWIM and created some horrific mess of bash scripts, timestamp files, PAM policy and systemd units. But the right answer there was “lets maybe not have that feature?” (in contrast, simply shutting the machine down after 8 hours is a one-liner).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; The incremental approach worked much better, Claude is good at filling-in the blanks. The very first thing I did for &lt;code&gt;box-v2&lt;/code&gt; was manually typing-in:
          &lt;/p&gt;
    &lt;p&gt; Then I asked Claude to complete the &lt;code&gt;CLIParse&lt;/code&gt; function,
            and I was happy with the result. Note
            Show, Don’t Tell
          &lt;/p&gt;
    &lt;p&gt; I am not asking Claude to avoid throwing an exception and fail fast instead. I just give &lt;code&gt;fatal&lt;/code&gt;
            function, and it code-completes the rest.
          &lt;/p&gt;
    &lt;p&gt; I can’t say that the code inside &lt;code&gt;CLIParse&lt;/code&gt; is
            top-notch. I’d probably written something more spartan. But the
            important part is that, at this level, I don’t care. The abstraction
            for parsing CLI arguments feel right to me, and the details I can
            always fix later. This is how this overall vibe-coding session
            transpired — I was providing structure, Claude was painting by the
            numbers.
          &lt;/p&gt;
    &lt;p&gt; In particular, with that CLI parsing structure in place, Claude had little problem adding new subcommands and new arguments in a satisfactory way. The only snag was that, when I asked to add an optional path to &lt;code&gt;sync&lt;/code&gt;, it went with &lt;code&gt;string |
              null&lt;/code&gt;, while I strongly prefer &lt;code&gt;string |
              undefined&lt;/code&gt;. Obviously, its better to pick your null in
            JavaScript and stick with it. The fact that &lt;code&gt;undefined&lt;/code&gt;
            is unavoidable predetermines the winner. Given that the argument was
            added as an incremental small change, course-correcting was trivial.
          &lt;/p&gt;
    &lt;p&gt; The null vs undefined issue perhaps illustrates my complaint about the code lacking character. &lt;code&gt;| null&lt;/code&gt; is the default non-choice. &lt;code&gt;|
              undefined&lt;/code&gt; is an insight, which I personally learned from VS
            Code LSP implementation.
          &lt;/p&gt;
    &lt;p&gt;The hand-written skeleton/vibe-coded guts worked not only for the CLI. I wrote&lt;/p&gt;
    &lt;p&gt;and then asked Claude to write the body of a particular function according to the SPEC.md.&lt;/p&gt;
    &lt;p&gt; Unlike with the CLI, Claude wasn’t able to follow this pattern itself. With one example it’s not obvious, but the overall structure is that &lt;code&gt;instanceXXX&lt;/code&gt; is the AWS-level operation on a
            single box, and
            &lt;code&gt;mainXXX&lt;/code&gt; is the CLI-level control flow that deals with
            looping and parallelism. When I asked Claude to implement &lt;code&gt;box
              run&lt;/code&gt;, without myself doing the &lt;code&gt;main&lt;/code&gt; /
            &lt;code&gt;instance&lt;/code&gt; split, Claude failed to noticed it and needed
            a course correction.
          &lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;However, Claude was massively successful with the actual logic. It would have taken me hours to acquire specific, non-reusable knowledge to write:&lt;/p&gt;
    &lt;p&gt;I want to be careful — I can’t vouch for correctness and especially completeness of the above snippet. However, given that the nature of the problem is such that I can just run the code and see the result, I am fine with it. If I were writing this myself, trial-and-error would totally be my approach as well.&lt;/p&gt;
    &lt;p&gt;Then there’s synthesis — with several instance commands implemented, I noticed that many started with querying AWS to resolve symbolic machine name, like “1”, to the AWS name/IP. At that point I realized that resolving symbolic names is a fundamental part of the problem, and that it should only happen once, which resulting in the following refactored shape of the code:&lt;/p&gt;
    &lt;p&gt;Claude was ok with extracting the logic, but messed up the overall code layout, so the final code motions were on me. “Context” arguments go first, not last, common prefix is more valuable than common suffix because of visual alignment.&lt;/p&gt;
    &lt;p&gt;The original “one-shotted” implementation also didn’t do up-front querying. This is an example of a shape of a problem I only discover when working with code closely.&lt;/p&gt;
    &lt;p&gt;Of course, the script didn’t work perfectly the first time and we needed quite a few iterations on the real machines both to fix coding bugs, as well gaps in the spec. That was an interesting experience of speed-running rookie mistakes. Claude made naive bugs, but was also good at fixing them.&lt;/p&gt;
    &lt;p&gt; For example, when I first tried to &lt;code&gt;box ssh&lt;/code&gt; after &lt;code&gt;box create&lt;/code&gt;, I got an error. Pasting it into Claude
            immediately showed the problem. Originally, the code was doing
            &lt;code&gt;aws ec2 wait
                instance-running&lt;/code&gt;
            and not
            &lt;code&gt;aws ec2 wait
                instance-status-ok&lt;/code&gt;.
          &lt;/p&gt;
    &lt;p&gt;The former checks if instance is logically created, the latter waits until the OS is booted. It makes sense that these two exist, and the difference is clear (and its also clear that OS booted != SSH demon started). Claude’s value here is in providing specific names for the concepts I already know to exist.&lt;/p&gt;
    &lt;p&gt; Another fun one was about the disk. I noticed that, while the instance had an SSD, it wasn’t actually used. I asked Claude to mount it as home, but that didn’t work. Claude immediately asked me to run &lt;code&gt;$ box run 0 cat
                /var/some/unintuitive/long/path.log&lt;/code&gt;
            and that log immediately showed the problem. This is remarkable! 50%
            of my typical Linux debugging day is wasted not knowing that a
            useful log exists, and the other 50% is for searching for the log I
            know should exist somewhere.
          &lt;/p&gt;
    &lt;p&gt; After the fix, I lost the ability to SSH. Pasting the error immediately gave the answer — by mounting over &lt;code&gt;/home&lt;/code&gt;,
            we were overwriting ssh keys configured prior.
          &lt;/p&gt;
    &lt;p&gt;There were couple of more iterations like that. Rookie mistakes were made, but they were debugged and fixed much faster than my personal knowledge allows (and again, I feel that is trivia knowledge, rather than deep reusable knowledge, so I am happy to delegate it!).&lt;/p&gt;
    &lt;p&gt;It worked satisfactorily in the end, and, what’s more, I am happy to maintain the code, at least to the extent that I personally need it. Kinda hard to measure productivity boost here, but, given just the sheer number of CLI flags required to make this work, I am pretty confident that time was saved, even factoring the writing of the present article!&lt;/p&gt;
    &lt;head rend="h2"&gt;Coda&lt;/head&gt;
    &lt;p&gt;I’ve recently read The Art of Doing Science and Engineering by Hamming (of distance and code), and one story stuck with me:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704943</guid><pubDate>Wed, 21 Jan 2026 12:46:27 +0000</pubDate></item><item><title>Nested Code Fences in Markdown</title><link>https://susam.net/nested-code-fences.html</link><description>&lt;doc fingerprint="a0821a8b3cfb87a4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nested Code Fences in Markdown&lt;/head&gt;
    &lt;p&gt;Today, we will meet a spiky-haired nerd named Corey Dumm, who normally lives within Markdown code fences. We will get to know him a bit, smile with him when his fences hold and weep quietly when misfortune strikes.&lt;/p&gt;
    &lt;p&gt;One of the caveats of the Markdown universe is the wide variety of Markdown implementations available. In these parallel universes, the rules of Markdown rendering differ subtly. In this post, we will focus only on the CommonMark specification. Since GitHub Flavoured Markdown (GFM) is a strict superset of CommonMark, whatever we discuss here applies equally well to both CommonMark and GFM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Basic Code Fences&lt;/head&gt;
    &lt;p&gt;Corey had a knack for working with computers ever since he was a kid.&lt;/p&gt;
    &lt;code&gt;Corey at his computer:

```
(o_o)--.|[_]|
```&lt;/code&gt;
    &lt;p&gt;Everything was perfect in Corey's world. The CommonMark renderer would convert the Markdown above to the following HTML:&lt;/p&gt;
    &lt;p&gt;Corey at his computer:&lt;/p&gt;
    &lt;code&gt;(o_o)--.|[_]|
&lt;/code&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey at his computer:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;(o_o)--.|[_]|
&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;At this point, all was well. Corey grew quickly. Before long, he had a head full of spiky hair. Then the fences began to matter.&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

```
 ```
(o_o)--.|[_]|
```&lt;/code&gt;
    &lt;p&gt;Let us see how this renders. I must warn you that during the Markdown-to-HTML translation, Corey loses his hair. Some viewers may find the following scene disturbing. Viewer discretion is advised. Here is the rendered HTML:&lt;/p&gt;
    &lt;p&gt;Corey, all grown up:&lt;/p&gt;
    &lt;p&gt;(o_o)--.|[_]|&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey, all grown up:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;
&amp;lt;p&amp;gt;(o_o)--.|[_]|&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;Corey's hair is gone! What a catastrophic accident! Corey is alright, though. He is still quite afraid of Markdown fences, but otherwise well and bouncing back. Why did this happen? The second set of triple backticks immediately ends the fenced code block started by the first set of triple backticks. As a result, Corey's smiley face ends up outside the fenced code block. The triple backticks that were once Corey's hair are now woven into the fabric of the surrounding HTML. Fortunately, CommonMark offers a few ways to avoid such accidents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy Code Fences&lt;/head&gt;
    &lt;p&gt;In CommonMark, there are two main ways to include triple backticks within fenced code blocks. First, we can use tildes as the code fence:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

~~~
 ```
(o_o)--.|[_]|
~~~&lt;/code&gt;
    &lt;p&gt;In fact, a code fence need not consist of exactly three backticks or tildes. Any number of backticks or tildes is allowed, as long as that number is at least three. The following is therefore equivalent:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

~~~~~
 ```
(o_o)--.|[_]|
~~~~~&lt;/code&gt;
    &lt;p&gt;And so is this:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

`````
 ```
(o_o)--.|[_]|
`````&lt;/code&gt;
    &lt;p&gt;All three examples render like this:&lt;/p&gt;
    &lt;p&gt;Corey, all grown up:&lt;/p&gt;
    &lt;code&gt; ```
(o_o)--.|[_]|
&lt;/code&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey, all grown up:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt; ```
(o_o)--.|[_]|
&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;No hair is lost in translation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Basic Code Spans&lt;/head&gt;
    &lt;p&gt;A similar problem arises with inline code spans. Most Markdown users know to use backticks to delimit inline code spans. For example:&lt;/p&gt;
    &lt;code&gt;An old picture of Corey at his computer: `(o_o)--.|[_]|`&lt;/code&gt;
    &lt;p&gt;This produces the following output:&lt;/p&gt;
    &lt;p&gt;An old picture of Corey at his computer: &lt;code&gt;(o_o)--.|[_]|&lt;/code&gt;&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;An old picture of Corey at his computer: &amp;lt;code&amp;gt;(o_o)--.|[_]|&amp;lt;/code&amp;gt;&amp;lt;/p&amp;gt;&lt;/code&gt;
    &lt;p&gt;However, what do we do when we need to put Corey's dear friend Becky Trace within an inline code span? Becky has short, straight hair tucked neatly on either side of her face. Here's a picture of her:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;`(o_o)`&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I believe you can already see the difficulty here. Inline code spans use backticks as delimiters. So when we put Becky within a code span, the first backtick in Corey's face would terminate the code span immediately and then the rest of Becky would lie outside it. CommonMark offers solutions for this kind of situation as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy Code Spans&lt;/head&gt;
    &lt;p&gt; An inline code span delimiter need not consist of exactly one backtick. It can consist of any number of backticks. So &lt;code&gt;`foo`&lt;/code&gt; and &lt;code&gt;``foo``&lt;/code&gt; produce identical HTML.
  There is another important but less well-known detail.  When the
  text inside an inline code span begins and ends with spaces, one
  space is removed from each end before rendering.  So
  &lt;code&gt;`foo`&lt;/code&gt; and &lt;code&gt;` foo `&lt;/code&gt; are equivalent.
  Therefore, when we need to put backticks within an inline code span,
  we can start the code span using multiple backticks and a space.
  For example:
&lt;/p&gt;
    &lt;code&gt;Meet Corey's friend Becky Trace: `` `(o_o)` ``&lt;/code&gt;
    &lt;p&gt;Here is the rendered output:&lt;/p&gt;
    &lt;p&gt;Meet Corey's friend Becky Trace: &lt;code&gt;`(o_o)`&lt;/code&gt;&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Meet Corey's friend Becky Trace: &amp;lt;code&amp;gt;`(o_o)`&amp;lt;/code&amp;gt;&amp;lt;/p&amp;gt;&lt;/code&gt;
    &lt;p&gt;Becky has her hair intact too. We have avoided the mishap that once caused great distress to Corey. That, my friends, is how backticks survive nesting in Markdown.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specification&lt;/head&gt;
    &lt;p&gt;Before I finish this post, let us take a look at the CommonMark specification to see where these details are defined. The excerpts quoted below are taken from CommonMark Spec Version 0.30, which is by now over four years old.&lt;/p&gt;
    &lt;p&gt;From section 4.5 Fenced Code Blocks:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A code fence is a sequence of at least three consecutive backtick characters (&lt;/p&gt;&lt;code&gt;`&lt;/code&gt;) or tildes (&lt;code&gt;~&lt;/code&gt;). (Tildes and backticks cannot be mixed.)&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The content of the code block consists of all subsequent lines, until a closing code fence of the same type as the code block began with (backticks or tildes), and with at least as many backticks or tildes as the opening code fence.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;From section 6.1 Code Spans:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A backtick string is a string of one or more backtick characters (&lt;/p&gt;&lt;code&gt;`&lt;/code&gt;) that is neither preceded nor followed by a backtick.&lt;p&gt;A code span begins with a backtick string and ends with a backtick string of equal length. The contents of the code span are the characters between these two backtick strings, normalized in the following ways:&lt;/p&gt;&lt;item&gt;First, line endings are converted to spaces.&lt;/item&gt;&lt;item&gt;If the resulting string both begins and ends with a space character, but does not consist entirely of space characters, a single space character is removed from the front and back. This allows you to include code that begins or ends with backtick characters, which must be separated by whitespace from the opening or closing backtick strings.&lt;/item&gt;&lt;/quote&gt;
    &lt;p&gt;I hope these little nuggets of Markdown trivialities will one day prove useful in your own Markdown misfortunes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705201</guid><pubDate>Wed, 21 Jan 2026 13:08:35 +0000</pubDate></item><item><title>The first 100 days as a Renovate maintainer</title><link>https://www.jvt.me/posts/2026/01/21/renovate-100-days/</link><description>&lt;doc fingerprint="3f563115cdf74736"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The first 100 days as a Renovate maintainer: the shocking inside view of a popular Open Source project&lt;/head&gt;
    &lt;p&gt;Roughly 100 days ago, I joined Mend to work on the Renovate project as a maintainer and community manager. In a vague homage to the style of politics' "first hundred days", I'll talk about some things that have happened since I've joined the project, and some of the interesting (and mundane) things I've learned since joining the project.&lt;/p&gt;
    &lt;p&gt;This was originally going to be a talk presented at FOSDEM 2026, but there was a lot of strong competition to the half-day Package Management track so I didn't get through to speaking.&lt;/p&gt;
    &lt;p&gt;Instead of losing out on the opportunity to share this, I thought I'd write it up as a blog post instead, as well as it being quite a nice opportunity to reflect back on the last few months.&lt;/p&gt;
    &lt;p&gt;Note that this post is focussing on the Mend Renovate CLI, the Open Source project that is commonly referred to as Renovate, and I won't be going into anything internal to Mend.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's Renovate?&lt;/head&gt;
    &lt;p&gt;First, before we dig into the learnings I've had, let's first explore what Renovate is. It's likely you have some inkling if you're reading this, but it's worth making sure you have the context before reading further.&lt;/p&gt;
    &lt;p&gt;There's a good primer on what Renovate is on a recent post of mine, but a good TL;DR is that Renovate is an Open Source project (&lt;code&gt;AGPL-3.0-only&lt;/code&gt;) owned by Mend, which boasts the best support + extensibility in the ecosystem for dependency updates, and we had over 300 human contributors and 1599 releases last year alone.&lt;/p&gt;
    &lt;p&gt;Since starting the project in 2017, we've gone through a few versions of how we operate the project.&lt;/p&gt;
    &lt;p&gt;Right now, we have three classes of folks who interact with the project:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Maintainers: the team who have final say on the direction of the project and new features, and whom have merge rights&lt;/item&gt;
      &lt;item&gt;Contributors: people who regularly contribute to Renovate's features, fix bugs, improve documentation and help answer user questions&lt;/item&gt;
      &lt;item&gt;Users: the folks who use Renovate, or are responsible for their Renovate deployment. They may infrequently raise PRs for documentation of bug fixes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Shipping despite a tiny team&lt;/head&gt;
    &lt;p&gt;As noted in my recent post about why we use GitHub Discussions as our triage process, I noted that we optimise for the people doing the work and making sure that Maintainers and Contributors are able to do their best work.&lt;/p&gt;
    &lt;p&gt;The most surprising thing I've found since joining the project is seeing how lean the maintainers team is. I felt like I did intellectually know that, but seeing it in practice has been another thing.&lt;/p&gt;
    &lt;p&gt;Within Renovate's maintainer team are 3 of us - Michael Kriese (who is contracted through Mend, but also does Renovate-y things in his free time), Sebastian Poxhofer (an external maintainer who is 100% not associated with Mend and works independently) and myself (who is 100% paid by Mend).&lt;/p&gt;
    &lt;p&gt;Alongside the maintainers, we have two contributors who are paid by Mend to work part-time on the project - Rahul Gautam Singh and Sergei Zharinov, who do great work on Issues and Discussions that come in from the community, as well as work coming in from Mend customers.&lt;/p&gt;
    &lt;p&gt;We also have a number of contributors who have Triage access on the project and get involved when they're able to, but there's no expectation of any time, given it's a volunteer basis.&lt;/p&gt;
    &lt;p&gt;When you put together the size of the team behind Renovate (in and outside of Mend), you have to admit it's impressive how we've been able to ship all these changes over 2025!&lt;/p&gt;
    &lt;p&gt;Especially when you also factor in the fact that none of the maintainers nor contributors work full-time on Renovate. I try to spend at least 50% of my time on the Open Source project, but it's worth bearing in mind.&lt;/p&gt;
    &lt;p&gt;In the first 100 days since I joined, we've had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;95 contributors (excluding &lt;code&gt;renovate[bot]&lt;/code&gt;and&lt;code&gt;github-actions[bot]&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;187 contributions from me&lt;/item&gt;
      &lt;item&gt;735 from &lt;code&gt;renovate[bot]&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;314 from contributors (including me)&lt;/item&gt;
      &lt;item&gt;419 releases&lt;/item&gt;
      &lt;item&gt;1 major release&lt;/item&gt;
      &lt;item&gt;Renovate's GitHub repo hit 20k stars&lt;/item&gt;
      &lt;item&gt;Renovate GitHub repo hit 40k Issues/PRs/Discussions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(these aren't things that I'm taking credit for being responsible for - aside from my own contributions - but I'm showing how much we've got done in a small period of time)&lt;/p&gt;
    &lt;p&gt;So with all these changes coming in, how do we keep on top of them?&lt;/p&gt;
    &lt;p&gt;As I'll talk about a bit more, community management for our Discussions is primarily taken by Rahul and I, working with users to help answer their questions.&lt;/p&gt;
    &lt;p&gt;When things promote up to Pull Requests, a mix of Michael and I will do a lot of the code review (including my many PRs!), and merge them as they're ready to be shipped.&lt;/p&gt;
    &lt;p&gt;Dependency bump PRs from Renovate are automagically approved + merged through PR-based automerge, allowing us to keep an eye on changes going in, and so we can action a failing build, but don't require human reviews given the number of dependencies being bumped. We require our external dependencies are at least 7 days old, via Minimum Release Age, to make sure that stability and security aren't lost by automated merges.&lt;/p&gt;
    &lt;p&gt;Without using PR-based automerge, we'd be unlikely to ever get to reviewing all the dependency bumps on top of user contributions, and considering Renovate is many projects, we can't scale our minimal team quite that far.&lt;/p&gt;
    &lt;p&gt;(And yes, I realise the irony of us not having time to review our own Renovate PRs ð)&lt;/p&gt;
    &lt;head rend="h3"&gt;Too much shipping&lt;/head&gt;
    &lt;p&gt;At one point, we found that the pace of delivery of shipping new releases regularly over the years would actually come back to bite us!&lt;/p&gt;
    &lt;p&gt;In my first full week at Mend, publishes to the npm registry failed due to:&lt;/p&gt;
    &lt;code&gt;npm error code E406
npm error 406 Not Acceptable - PUT https://registry.npmjs.org/renovate - Package publish failed.
npm error Your package metadata is too large (100.01 MB &amp;gt; 100 MB).
npm error The likely cause is that you have too many versions (10451).
npm error Resolve this problem by unpublishing older versions of your package.
&lt;/code&gt;
    &lt;p&gt;This wasn't down to an individual &lt;code&gt;package.json&lt;/code&gt; being too large, but down to the fact that we had so many releases that the npm registry APIs would no longer allow publishing.&lt;/p&gt;
    &lt;p&gt;I feel that's a pretty cool "badge of honour" to note that we've been shipping consistently for so long that we end up hitting a rate limit on the npm registy side!&lt;/p&gt;
    &lt;p&gt;(Note that not every commit has its own release - we perform a batched release if there are multiple commits landing on &lt;code&gt;main&lt;/code&gt; within the same timeframe, but sometimes it does end up being several releases a day that are a single commit worth of changes)&lt;/p&gt;
    &lt;p&gt;This was also a "fun" incident because we weren't even able to manually unpublish any versions ourselves, as we're a popular package. We needed to work with npm support, who could perform some backend magic to force some unpublishes for us, saving us some time.&lt;/p&gt;
    &lt;p&gt;We're also working to periodically clean up old tags, to make sure that we don't hit this again in the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;There's no "I" in team&lt;/head&gt;
    &lt;p&gt;Working on a large project like this isn't possible to do on your own - it really "takes a village".&lt;/p&gt;
    &lt;p&gt;The primary projects I've been maintaining over the years have largely been down to a single maintainer (me) who has been trying to fulfill all the roles necessary, as well as fitting it in with all the other things I'm working on.&lt;/p&gt;
    &lt;p&gt;For instance, &lt;code&gt;oapi-codegen&lt;/code&gt; is a widely used OpenAPI-to-Go code generator. But right now, my co-maintainer is mostly unable to work on the project, which means that triage, user questions and PR review, let alone being able to do forward thinking product-y thinking is all down to me - that gets hard over time, especially as the Issues and PRs pile up.&lt;/p&gt;
    &lt;p&gt;I noticed in the first couple of weeks of my time in the project that it was really nice to come in on a morning and see that Rahul had already triaged and/or resolved Discussions raised by users, or that Michael and Sebastian had already reviewed + merged Pull Requests.&lt;/p&gt;
    &lt;p&gt;It makes a huge difference mentally to know that there are other Contributors and Maintainers who are also working to support the project and that it's not all on me, unlike other projects I maintain.&lt;/p&gt;
    &lt;p&gt;I've also found that this gives me more ability to think about what I want to delegate, for instance a number of Mend customer requests may go to Rahul and Sergei, which frees me up to do a "bigger picture" piece of work, or frees me up to focus my time on code review instead.&lt;/p&gt;
    &lt;head rend="h3"&gt;A welcoming bunch&lt;/head&gt;
    &lt;p&gt;I'd also like to say another thank you for folks being so welcoming! It definitely helps being more of a familiar face, but it's still been nice that everyone's been lovely and welcoming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Community Management&lt;/head&gt;
    &lt;p&gt;I find it really important to build empathy with my users, and so working on the community management is super valuable to me, and allows me to continue helping others as I've been helped over the years.&lt;/p&gt;
    &lt;p&gt;It's also fortunate I enjoy it because it's core part of my role at Mend as the community manager for the project, and so it's been good that it feels much more sustainable than other projects I've maintained in the past.&lt;/p&gt;
    &lt;p&gt;This was especially something I was a little nervous about, as I was stepping into Rhys' shoes of being the community manager, but I've found I've settled well into the role.&lt;/p&gt;
    &lt;p&gt;As I've written about, Renovate uses GitHub Discussions for the community to get in touch about questions, possible bugs and feature requests. I recommend you read the post for the full discussion (pun intended) about why it's worked so well for us.&lt;/p&gt;
    &lt;p&gt;As my role as Community Manager on the project, I spend a lot of my time working with GitHub Discussions, and have found that although Discussions does work for us, there are a few areas where it's not the best experience (as an offering from GitHub).&lt;/p&gt;
    &lt;p&gt;To improve the experience for (primarily) me, I've ended up building a sync-to-local-SQLite-and-web-application which I'm calling the "maintainer dashboard", where I can now get separate views of the data, such as the below information, which isn't possible to get out of GitHub otherwise:&lt;/p&gt;
    &lt;p&gt;Another key benefit of getting raw access to the data means that we can look at other interesting queries for things that we care about as a project, such as "where have we not replied to a user request for some time" or "is someone trying to bump an old thread, instead of creating a fresh Discussion?".&lt;/p&gt;
    &lt;p&gt;I'll soon be sharing about this in a bit more detail, as well as releasing it under an Open Source license.&lt;/p&gt;
    &lt;head rend="h2"&gt;Minimal reproductions take time&lt;/head&gt;
    &lt;p&gt;As with many Open Source projects and commercial projects alike, before you can fix a bug you need to find a way to reproduce it.&lt;/p&gt;
    &lt;p&gt;With Renovate this is no different, and it's a large part of the "Request Help" flow our users go through, where if we can't reasonably work out what's going on from debug logs provided by the user, we require a minimal reproduction repository.&lt;/p&gt;
    &lt;p&gt;While debugging Mend customer requests, thinking about features I'd like to have in Renovate, and sometimes being extra nice and going the extra mile for a given user request, I'll put together the minimal reproductions, as our users do, which can take time.&lt;/p&gt;
    &lt;p&gt;But like with writing a design document or a blog post, going through the process of breaking down the issue into the smallest possible unit can help determine "oh, it was actually something unrelated", or can make it much clearer that the behaviour you're trying to achieve doesn't make sense.&lt;/p&gt;
    &lt;p&gt;It's hugely valuable, and was something I was doing at Elastic as our resident Renovate expert, too. I also have a separate post I've been working on, which will go into what I find works best for my own testing of Renovate configuration changes, which feeds into this.&lt;/p&gt;
    &lt;p&gt;Although I've not yet had a chance to fully play around with it, I've been planning to get an LLM Agent set up with being able to take a bug report and convert it into a Minimal Reproduction - even if it gets a maximum of 80% of the way there, that's a good start!&lt;/p&gt;
    &lt;head rend="h2"&gt;Hitting the ground running&lt;/head&gt;
    &lt;p&gt;One of the key reasons I joined Mend to work on Renovate was because - in my humble opinion - I was the best person for the job. I had a lot of context with Renovate, some of Mend's offerings on top of the Renovate CLI, as well as the wider package management + dependency insights ecosystem Renovate sits in.&lt;/p&gt;
    &lt;p&gt;One of the really nice things was being able to join a company and - while being cautious about over-exertion and burnout - get going straight away, without needing to onboard.&lt;/p&gt;
    &lt;p&gt;Literally on my second day, I was reviewing Discussions and PRs, and drafting my own code changes.&lt;/p&gt;
    &lt;p&gt;Going back 2 weeks before I joined, I proposed something that would take up a considerable chunk of the next couple of months - the enablement of Minimum Release Age across the npm ecosystem.&lt;/p&gt;
    &lt;p&gt;As I'll mention below, this is something I was very proud of - and there was a lot of work for a few of us making the feature as stable and predictable as possible before enabling it for a significant percentage of our userbase.&lt;/p&gt;
    &lt;p&gt;This isn't the sort of thing that you'd expect a new-starter at a company to be picking up, so it was pretty great to know that I was able to come in and immediately "push the needle".&lt;/p&gt;
    &lt;head rend="h2"&gt;Renovate isn't one project&lt;/head&gt;
    &lt;p&gt;Another thing that I learned fairly quickly on the job is that when we talk about "Renovate", most folks think of the Renovate CLI as the thing, but there's many more things behind it that we don't consider.&lt;/p&gt;
    &lt;p&gt;Coming into the project I feel like I knew this, and I knew that the Renovate Docker image was built on top of "Containerbase", but I'd not fully appreciated how the two interacted, as well as the many other projects that make up the offering that is Renovate.&lt;/p&gt;
    &lt;p&gt;A simplified list of some of the more interesting projects that fit under "Renovate" are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;osv-offline&lt;/item&gt;
      &lt;item&gt;Containerbase a command-line tool for being able to i.e. &lt;code&gt;install-tool node 22.22.0&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Containerbase's pre-built tools (i.e. Node, the Go toolchain)&lt;/item&gt;
      &lt;item&gt;The official Helm charts&lt;/item&gt;
      &lt;item&gt;The official GitHub Actions&lt;/item&gt;
      &lt;item&gt;GitLab CI&lt;/item&gt;
      &lt;item&gt;A number of packages under our npm user&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each of these projects needs updates, they all have their own backlogs and sets of documentation to improve and keep on top of.&lt;/p&gt;
    &lt;p&gt;As noted above, there has to be some level of automation in place for dependency updates, otherwise we'd spend all of the Maintainer + Contributor time reviewing dependency update PRs!&lt;/p&gt;
    &lt;p&gt;Although we're primarily focussing on Renovate, there are times that to implement a feature in Renovate, it requires changes across multiple components before we can implement it upstream - so sometimes this can lead to a slightly more complex contribution process, as we're fairly well documented on the Renovate CLI, but not as many of the related projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;Typescript is great&lt;/head&gt;
    &lt;p&gt;This isn't a new opinion of mine, but I very much love Typescript. Although builds aren't quite as speedy as Go, I very much enjoy the stronger type system, and the way Renovate is configured as a project works very nicely.&lt;/p&gt;
    &lt;p&gt;It's really quite nice to have real enum types - opposed to the hacks we have to do in Go - and the Language Server is much more powerful that &lt;code&gt;gopls&lt;/code&gt;, which has become more stark a contrast as I flip between the two languages.&lt;/p&gt;
    &lt;p&gt;I'm not likely to migrate to Typescript for personal projects - due to the beauty of the single static binary from Go - but it is nice to be working on what I find to be a really nice codebase with a strong set of tooling.&lt;/p&gt;
    &lt;head rend="h2"&gt;
      &lt;code&gt;await response()&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;Open Source is naturally an asynchronous model of collaboration, with the globally distributed nature of users, contributors and maintainers, and Renovate is no different.&lt;/p&gt;
    &lt;p&gt;We do fortunately have our maintainers all in Europe, so we have a significant timezone overlap, and cross-continent working with our contributors still works well.&lt;/p&gt;
    &lt;p&gt;After years of working at Elastic, where my team at one point was across a couple of timezones in the US, the UK, Spain, Germany and two timezones in Australia, I'm very used to - and enjoy - more asynchronous working.&lt;/p&gt;
    &lt;p&gt;I've managed to video call with a few folks, and I plan to try and meet with all of our core contributors + maintainers over the next few months, even if it's a "hey, let's make it easier to remember we're both humans" and get to know each other slightly more.&lt;/p&gt;
    &lt;p&gt;The majority of interactions are done over GitHub, but we do have a Renovate developers Slack for contributors and maintainers, so every so often we can have some high bandwidth calls.&lt;/p&gt;
    &lt;head rend="h2"&gt;So many package managers&lt;/head&gt;
    &lt;p&gt;Although we've not yet merged support for new package managers (there are a couple of PRs waiting on me, sorry!), it's been really interesting finding out how many package managers there are out there.&lt;/p&gt;
    &lt;p&gt;I knew that Renovate supports many package managers, but it's been eye-opening getting a chance to see what's in use, and get a gut-feel for what our users are actually using.&lt;/p&gt;
    &lt;p&gt;With user requests coming in, it's also a little bit of a learning curve trying to work out how the package manager works, getting minimal reproductions set up, and this is another area where I need to try and lean on LLMs a little bit more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lots of "work in progress"&lt;/head&gt;
    &lt;p&gt;As someone with ADHD, I've noted before that I'll often (but not always) thrive more when there's lots of stuff to do at a given time, rather than only having a single task to do at a given time.&lt;/p&gt;
    &lt;p&gt;Working on the Renovate project is no different - I have several backlogs of "TODOs", coming in from community Discussions, Pull Requests, my own TODO list of "I'd love to have that done" and "that'd improve Mend's offerings if we had this" through to Mend customer requests.&lt;/p&gt;
    &lt;p&gt;Having a strong level of control over how I spend the time towards these is good, but as users, it's good to remember that there's often a lot of background work going on which may be why you're not getting a response - as noted above, I'm not even 100% full time on the Renovate Open Source project, and if you saw my email inbox from Renovate Discussions, you'd understand the delays ð&lt;/p&gt;
    &lt;p&gt;A lot of the time, this means that I'm working through 10+ Discussions at a given time, trying to provide an answer, the right documentation, or getting an Issue raised for changes to the codebase.&lt;/p&gt;
    &lt;head rend="h2"&gt;Big deliveries&lt;/head&gt;
    &lt;p&gt;To take a bit of a self-congratulatory note, I'd like to talk about some of the things I'm most proud of us delivering since I've joined.&lt;/p&gt;
    &lt;p&gt;Since joining, there have been a few things I've been most proud of leading + delivering:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enabling Minimum Release Age to secure the npm ecosystem&lt;list rend="ul"&gt;&lt;item&gt;In particular, this involved a tonne of work getting ready to being able to turn it on for a significant portion of Renovate users. Although the feature (previously known as "stability days") has been in Renovate since 2019(!), enabling this for all users of the npm datasource who use &lt;code&gt;config:best-practices&lt;/code&gt;meant that we needed to make it more predictable, highly documented, and introduce additional log lines for folks to understand what was going on&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;In particular, this involved a tonne of work getting ready to being able to turn it on for a significant portion of Renovate users. Although the feature (previously known as "stability days") has been in Renovate since 2019(!), enabling this for all users of the npm datasource who use &lt;/item&gt;
      &lt;item&gt;Significantly improved OpenTelemetry tracing, so it's much clearer what's now happening under-the-hood&lt;/item&gt;
      &lt;item&gt;First major release (and a lot of learnings around how the process works, which is good ahead of next week's next major release!)&lt;/item&gt;
      &lt;item&gt;Working to provide "secure by default" configuration like disabling unsafe execution of Gradle scripts or clarifying additional risks of self-hosting&lt;/item&gt;
      &lt;item&gt;Handling my first GitHub Security Advisory report, and closing off a few other fixed reports&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are also a number of other smaller bug fixes, features and community contributions I've helped get shipped, as well as shaping a number of medium-/long-term routes for the project.&lt;/p&gt;
    &lt;p&gt;One of the great benefits of being on the maintainer team means that I've been able to look at some of my previously raised feature requests, and I can now get them delivered because I now have much more experience, and ability to explain why the features should get done - including a few I've raised in the past that are super useful for Mend to have for our hosted platform!&lt;/p&gt;
    &lt;head rend="h2"&gt;There's always more to do&lt;/head&gt;
    &lt;p&gt;As noted on my interview on Open Source Security, package management is a pretty large space and there's so much to it.&lt;/p&gt;
    &lt;p&gt;Renovate aims to make it possible to keep all the things updated, with safe defaults and a workflow that is configurable to work for you.&lt;/p&gt;
    &lt;p&gt;To do this, however, is a balancing act to make sure that we're not adding features that make the maintenance of the project more difficult, or to make sure that we don't introduce too many more configuration options, while also continuing to move forward as a project.&lt;/p&gt;
    &lt;p&gt;I've really enjoyed the last 100 days, and the work we've done so far. I'm very excited to see what the next 100 days bring, and onwards into the future!&lt;/p&gt;
    &lt;p&gt;If you've got to the end - well done! Was this interesting? Anything you're interested in learning more about?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705512</guid><pubDate>Wed, 21 Jan 2026 13:35:41 +0000</pubDate></item><item><title>Ireland wants to give its cops spyware, ability to crack encrypted messages</title><link>https://www.theregister.com/2026/01/21/ireland_wants_to_give_police/</link><description>&lt;doc fingerprint="fc3c993136b2f35d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ireland wants to give its cops spyware, ability to crack encrypted messages&lt;/head&gt;
    &lt;head rend="h2"&gt;Its very own Snooper’s Charter comes a month after proposed biometric tech expansion&lt;/head&gt;
    &lt;p&gt;The Irish government is planning to bolster its police's ability to intercept communications, including encrypted messages, and provide a legal basis for spyware use.&lt;/p&gt;
    &lt;p&gt;The Communications (Interception and Lawful Access) Bill is being framed as a replacement for the current legislation that governs digital communication interception.&lt;/p&gt;
    &lt;p&gt;The Department of Justice, Home Affairs, and Migration said in an announcement this week the existing Postal Packets and Telecommunications Messages (Regulation) Act 1993 "predates the telecoms revolution of the last 20 years."&lt;/p&gt;
    &lt;p&gt;As well as updating laws passed more than two decades ago, the government was keen to emphasize that a key ambition for the bill is to empower law enforcement to intercept of all forms of communications.&lt;/p&gt;
    &lt;p&gt;The Bill will bring communications from IoT devices, email services, and electronic messaging platforms into scope, "whether encrypted or not."&lt;/p&gt;
    &lt;p&gt;In a similar way to how certain other governments want to compel encrypted messaging services to unscramble packets of interest, Ireland's announcement also failed to explain exactly how it plans to do this.&lt;/p&gt;
    &lt;p&gt;However, it promised to implement a robust legal framework, alongside all necessary privacy and security safeguards, if these proposals do ultimately become law. It also vowed to establish structures to ensure "the maximum possible degree of technical cooperation between state agencies and communication service providers."&lt;/p&gt;
    &lt;p&gt;The government said it will follow the EU Commission's (EC) roadmap for law enforcement data interception, including a section on encryption issues, which it published last year.&lt;/p&gt;
    &lt;p&gt;"There is an urgent need for a new legal framework for lawful interception which can be used to confront serious crime and security threats," said justice minister Jim O'Callaghan, announcing the news.&lt;/p&gt;
    &lt;p&gt;"The new legislation will also include robust legal safeguards to provide continued assurance that the use of such powers is necessary and proportionate.&lt;/p&gt;
    &lt;p&gt;He said new legislation is "long overdue", following "significant changes" to digital comms over the past twenty years that "existing legislation does not comprehend."&lt;/p&gt;
    &lt;head rend="h3"&gt;Spyware provision&lt;/head&gt;
    &lt;p&gt;Ireland will also take the EU's lead on spyware, establishing a legal provision for its use, only in cases of strict necessity.&lt;/p&gt;
    &lt;p&gt;The EC's 2024 paper [PDF] examining the legality of spyware noted it could be used by member states, but only where situations absolutely require it. Programs must be used proportionally, with a judge's approval, and with stringent oversight.&lt;/p&gt;
    &lt;p&gt;The justice ministry said it would take this paper into consideration when developing Ireland's legal provision for using spyware. Example cases could include accessing data on a device or network, or covert recordings of communications on a device, or over a network, the government said.&lt;/p&gt;
    &lt;p&gt;In addition to spyware, Ireland is looking to establish a legal power for police to scan electronic equipment in a specific location to identify people of interest and their associates in relation to serious crime investigations. Examples of this technology in action include police camping outside a single location, and operating IMSI catchers to identify those inside.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rather than add a backdoor, Apple decides to kill iCloud encryption for UK peeps&lt;/item&gt;
      &lt;item&gt;AWS flips switch on Euro cloud as customers fret about digital sovereignty&lt;/item&gt;
      &lt;item&gt;IPv6 just turned 30 and still hasn't taken over the world, but don't call it a failure&lt;/item&gt;
      &lt;item&gt;UK surveillance law still full of holes, watchdog warns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Olga Cronin, surveillance and human rights senior policy officer at the Irish Council for Civil Liberties (ICCL), said the nonprofit "has very serious concerns about this shopping list of surveillance powers," despite the proposals still being in their infancy.&lt;/p&gt;
    &lt;p&gt;"These are surveillance tools and powers of extraordinary reach, with sweeping implications for people's rights and freedoms, and come in the context of An Garda Síochána already expanding their 'eyes and ears' via the Recording Devices Bill," Cronin added.&lt;/p&gt;
    &lt;p&gt;The separate but related Recording Devices Bill was introduced in December 2025, proposing expanded police use of biometric recognition technology.&lt;/p&gt;
    &lt;p&gt;It did not say exactly how this would be implemented, but ministers describing the Bill's ambitions suggested that both live and retrospective facial recognition could become widely used across Ireland's police force.&lt;/p&gt;
    &lt;p&gt;"Once powers of this magnitude are normalised, the damage to rights and freedoms can be extremely difficult to reverse," said Cronin.&lt;/p&gt;
    &lt;p&gt;"We must also remember that measures introduced for exceptional or serious crimes tend, over time, to be used for much less serious crimes because there is institutional pressure to use them more frequently. What was once exceptional becomes routine." ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705715</guid><pubDate>Wed, 21 Jan 2026 13:52:27 +0000</pubDate></item><item><title>Comic-Con Bans AI Art After Artist Pushback</title><link>https://www.404media.co/comic-con-bans-ai-art-after-artist-pushback/</link><description>&lt;doc fingerprint="3ec71335f15c64a9"&gt;
  &lt;main&gt;
    &lt;p&gt;San Diego Comic-Con changed an AI art friendly policy following an artist-led backlash last week. It was a small victory for working artists in an industry where jobs are slipping away as movie and video game studios adopt generative AI tools to save time and money.&lt;/p&gt;
    &lt;p&gt;Every year, tens of thousands of people descend on San Diego for Comic-Con, the world’s premier comic book convention that over the years has also become a major pan-media event where every major media company announces new movies, TV shows, and video games. For the past few years, Comic-Con has allowed some forms of AI-generated art at this art show at the convention. According to archived rules for the show, artists could display AI-generated material so long as it wasn’t for sale, was marked as AI-produced, and credited the original artist whose style was used.&lt;/p&gt;
    &lt;p&gt;“Material produced by Artificial Intelligence (AI) may be placed in the show, but only as Not-for-Sale (NFS). It must be clearly marked as AI-produced, not simply listed as a print. If one of the parameters in its creation was something similar to ‘Done in the style of,’ that information must be added to the description. If there are questions, the Art Show Coordinator will be the sole judge of acceptability,” Comic-Con’s art show rules said until recently.&lt;/p&gt;
    &lt;p&gt;These rules have been in place since at least 2024, but anti-AI sentiment is growing in the artistic community and an artist-led backlash against Comic-Con’s AI-friendly language led to the convention quietly changing the rules. Twenty-four hours after artists called foul the AI-friendly policy, Comic-Con updated the language on its site. “Material created by Artificial Intelligence (AI) either partially or wholly, is not allowed in the art show,” it now says. AI is now banned at the art show.&lt;/p&gt;
    &lt;p&gt;Comic and concept artist Tiana Oreglia told 404 Media Comic-Con’s friendly attitude towards AI was a slippery slope towards normalization. “I think we should be standing firm especially with institutions like Comic-Con which are quite literally built off the backs of artists and the creative community,” she said. Oreglia was one of the first artists to notice the AI-friendly policy. In addition to alerting her circle of friends, she also wrote a letter to Comic-Con itself.&lt;/p&gt;
    &lt;p&gt;Artist Karla Ortiz told 404 Media she learned about the AI-friendly policy after some fellow artists shared it with her. Ortiz is a major artist who has worked with some of the major studios who exhibit work at Comic-Con. She’s also got a large following on social media, a following she used to call out Comic-Con’s organizers.&lt;/p&gt;
    &lt;p&gt;“Comic-con deciding to allow GenAi imagery in the art show—giving valuable space to GenAi users to show slop right NEXT to actual artists who worked their asses off to be there—is a disgrace!” Ortiz said in a post on Bluesky. “A tone deaf decision that rewards and normalizes exploitative GenAi against artists in their own spaces!”&lt;/p&gt;
    &lt;p&gt;According to Ortiz, the convention is a sacred place she didn’t want to see desecrated by AI. “Comic-Con is the big mecca for comic artists, illustrators, and writers,” she said. “I organize and speak with a lot of different artists on the generative AI issue. It’s something that impacts us and impacts our lives. A lot of us have decided: ‘No, we’re not going to sit by the sidelines.’”&lt;/p&gt;
    &lt;p&gt;Oritz explained that generative AI was already impacting the livelihood of working artists. She said that, in the past, artists could sustain themselves on long projects for companies that included storyboarding and design. “Suddenly the duration of projects are cut,” she said. “They got generative AI to generate a bunch of references, a bunch of boards. ‘We already did the initial ideation, so just paint this. Paint what generative AI has generated for us.’”&lt;/p&gt;
    &lt;p&gt;Ortiz pointed to two high profile examples: Marvel using AI to make the title sequence for Secret Invasion and Coca-Cola using AI to make Christmas commercials. “You have this encroaching exploitative technology impacting almost every single level of the entertainment industry, whether you’re a writer, or a voice actor, or a musician, a painter, a concept artist, an illustrator. It doesn’t matter…and then to have Comic-Con, that place that’s supposed to be a gathering and a celebration of said creatives and their work, suddenly put on a pedestal the exploitative technology that only functions because of its training on our works? It’s upsetting beyond belief.”&lt;/p&gt;
    &lt;p&gt;“What is Comic-Con trying to tell the industry?” She said, “It’s telling artists: ‘Hey you, you’re exploitable and you’re replaceable.’”&lt;/p&gt;
    &lt;p&gt;Ortiz was heartened that Comic-Con changed its policy. “It was such a relief,” she said. “Generative AI is still going to creep its nasty way in some way or another, but at least it’s not something we have to take lying down. It’s something we can actively speak out against.”&lt;/p&gt;
    &lt;p&gt;Comic-Con did not respond to 404 Media’s request for comment, but Oreglia said she did hear back from art show organizer Glen Wooten. “He basically told me that they put those AI stipulations in when AI was just starting to come around and that the inability to sell AI-generated works was meant to curtail people from submitting genAI works,” she said. “He seems to be very against genAI but wasn't really able to change the current policy until artists voiced their opinions loudly which pressured the office into banning AI completely.”&lt;/p&gt;
    &lt;p&gt;Despite changing policies and broad anti-AI sentiment among the artistic community, Oreglia has still seen an uptick of AI art at conventions. “Although there are many cons that ban it outright and if you get caught selling it you basically will get banned.” This happened to a vendor at Dragon Con last September. Organizers called police to escort the vendor off the premises.&lt;/p&gt;
    &lt;p&gt;“And I was tabling at Fanexpo SF and definitely saw genAI in the dealers hall, none in the artists alley as far as I could see though but I mostly stuck to my table,” she said. “I was also at Emerald City Comic Con last year and they also have a no-ai policy but fanexpo doesn't seem to have those same policies as far as I know.”&lt;/p&gt;
    &lt;p&gt;AI image generators are trained on original artwork so whatever output a tool like Midjourney creates is based on an artist’s work, often without compensation or credit. Oreglia also said she feels that AI is an artistic dead end. “Everything interesting, uplifting, and empowering I find about art gets stripped away and turned into vapid facsimiles based on vibes and trendy aesthetics,” she said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705952</guid><pubDate>Wed, 21 Jan 2026 14:12:32 +0000</pubDate></item><item><title>Show HN: ChartGPU – WebGPU-powered charting library (1M points at 60fps)</title><link>https://github.com/ChartGPU/ChartGPU</link><description>&lt;doc fingerprint="a905bd6501bc13b2"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance charts powered by WebGPU&lt;/p&gt;
    &lt;p&gt;Documentation | Live Demo | Examples&lt;/p&gt;
    &lt;p&gt;ChartGPU is a TypeScript charting library built on WebGPU for smooth, interactive rendering—especially when you have lots of data.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 WebGPU-accelerated rendering for high FPS with large datasets&lt;/item&gt;
      &lt;item&gt;📈 Multiple series types: line, area, bar, scatter, pie, candlestick&lt;/item&gt;
      &lt;item&gt;🧭 Built-in interaction: hover highlight, tooltip, crosshair&lt;/item&gt;
      &lt;item&gt;🔁 Streaming updates via &lt;code&gt;appendData(...)&lt;/code&gt;(cartesian series)&lt;/item&gt;
      &lt;item&gt;🔍 X-axis zoom (inside gestures + optional slider UI)&lt;/item&gt;
      &lt;item&gt;🎛️ Theme presets (&lt;code&gt;'dark' | 'light'&lt;/code&gt;) and custom theme support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At a high level, &lt;code&gt;ChartGPU.create(...)&lt;/code&gt; owns the canvas + WebGPU lifecycle, and delegates render orchestration (layout/scales/data upload/render passes + internal overlays) to the render coordinator. For deeper internal notes, see &lt;code&gt;docs/API.md&lt;/code&gt; (especially “Render coordinator”).&lt;/p&gt;
    &lt;code&gt;flowchart TB
  UserApp["Consumer app"] --&amp;gt; PublicAPI["src/index.ts (Public API exports)"]

  PublicAPI --&amp;gt; ChartCreate["ChartGPU.create(container, options)"]
  PublicAPI --&amp;gt; SyncAPI["connectCharts(charts)"]

  subgraph ChartInstance["Chart instance (src/ChartGPU.ts)"]
    ChartCreate --&amp;gt; SupportCheck["checkWebGPUSupport()"]
    ChartCreate --&amp;gt; Canvas["Create canvas + mount into container"]
    ChartCreate --&amp;gt; Options["resolveOptions(options)"]
    ChartCreate --&amp;gt; GPUInit["GPUContext.create(canvas)"]
    ChartCreate --&amp;gt; Coordinator["createRenderCoordinator(gpuContext, resolvedOptions)"]

    ChartCreate --&amp;gt; InstanceAPI["ChartGPUInstance APIs"]
    InstanceAPI --&amp;gt; RequestRender["requestAnimationFrame (coalesced)"]
    RequestRender --&amp;gt; Coordinator

    InstanceAPI --&amp;gt; SetOption["setOption(...)"]
    InstanceAPI --&amp;gt; AppendData["appendData(...)"]
    InstanceAPI --&amp;gt; Resize["resize()"]

    subgraph PublicEvents["Public events + hit-testing (ChartGPU.ts)"]
      Canvas --&amp;gt; PointerHandlers["Pointer listeners"]
      PointerHandlers --&amp;gt; PublicHitTest["findNearestPoint() / findPieSlice()"]
      PointerHandlers --&amp;gt; EmitEvents["emit('click'/'mouseover'/'mouseout')"]
    end

    DataZoomSlider["dataZoom slider UI (DOM)"] --&amp;gt; Coordinator
  end

  subgraph WebGPUCore["WebGPU core (src/core/GPUContext.ts)"]
    GPUInit --&amp;gt; AdapterDevice["navigator.gpu.requestAdapter/device"]
    GPUInit --&amp;gt; CanvasConfig["canvasContext.configure(format)"]
  end

  subgraph RenderCoordinatorLayer["Render coordinator (src/core/createRenderCoordinator.ts)"]
    Coordinator --&amp;gt; Layout["GridArea layout"]
    Coordinator --&amp;gt; Scales["xScale/yScale (clip space for render)"]
    Coordinator --&amp;gt; DataUpload["createDataStore(device) (GPU buffer upload/caching)"]
    Coordinator --&amp;gt; RenderPass["Encode + submit render pass"]

    subgraph InternalOverlays["Internal interaction overlays (coordinator)"]
      Coordinator --&amp;gt; Events["createEventManager(canvas, gridArea)"]
      Events --&amp;gt; OverlayHitTest["hover/tooltip hit-testing"]
      Events --&amp;gt; InteractionX["interaction-x state (crosshair)"]
      Coordinator --&amp;gt; OverlaysDOM["DOM overlays: legend / tooltip / text labels"]
    end
  end

  subgraph Renderers["GPU renderers (src/renderers/*)"]
    RenderPass --&amp;gt; GridR["Grid"]
    RenderPass --&amp;gt; AreaR["Area"]
    RenderPass --&amp;gt; BarR["Bar"]
    RenderPass --&amp;gt; ScatterR["Scatter"]
    RenderPass --&amp;gt; LineR["Line"]
    RenderPass --&amp;gt; PieR["Pie"]
    RenderPass --&amp;gt; CandlestickR["Candlestick"]
    RenderPass --&amp;gt; CrosshairR["Crosshair overlay"]
    RenderPass --&amp;gt; HighlightR["Hover highlight overlay"]
    RenderPass --&amp;gt; AxisR["Axes/ticks"]
  end

  subgraph Shaders["WGSL shaders (src/shaders/*)"]
    GridR --&amp;gt; gridWGSL["grid.wgsl"]
    AreaR --&amp;gt; areaWGSL["area.wgsl"]
    BarR --&amp;gt; barWGSL["bar.wgsl"]
    ScatterR --&amp;gt; scatterWGSL["scatter.wgsl"]
    LineR --&amp;gt; lineWGSL["line.wgsl"]
    PieR --&amp;gt; pieWGSL["pie.wgsl"]
    CandlestickR --&amp;gt; candlestickWGSL["candlestick.wgsl"]
    CrosshairR --&amp;gt; crosshairWGSL["crosshair.wgsl"]
    HighlightR --&amp;gt; highlightWGSL["highlight.wgsl"]
  end

  subgraph ChartSync["Chart sync (src/interaction/createChartSync.ts)"]
    SyncAPI --&amp;gt; ListenX["listen: 'crosshairMove'"]
    SyncAPI --&amp;gt; DriveX["setCrosshairX(...) on peers"]
  end

  InteractionX --&amp;gt; ListenX
  DriveX --&amp;gt; InstanceAPI
&lt;/code&gt;
    &lt;p&gt;Financial OHLC (open-high-low-close) candlestick rendering with classic/hollow style toggle and color customization.&lt;/p&gt;
    &lt;code&gt;import { ChartGPU } from 'chartgpu';
const container = document.getElementById('chart')!;
await ChartGPU.create(container, {
  series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
});&lt;/code&gt;
    &lt;p&gt;
      &lt;code&gt;npm install chartgpu&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;React bindings are available via &lt;code&gt;chartgpu-react&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;npm install chartgpu-react&lt;/code&gt;
    &lt;code&gt;import { ChartGPUChart } from 'chartgpu-react';

function MyChart() {
  return (
    &amp;lt;ChartGPUChart
      options={{
        series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
      }}
    /&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;See the chartgpu-react repository for full documentation and examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chrome 113+ or Edge 113+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Safari 18+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Firefox: not supported (WebGPU support in development)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full documentation: Getting Started&lt;/item&gt;
      &lt;item&gt;API reference: &lt;code&gt;docs/API.md&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browse examples: &lt;code&gt;examples/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run locally: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;npm run dev&lt;/code&gt;(opens&lt;code&gt;http://localhost:5176/examples/&lt;/code&gt;)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;CONTRIBUTING.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;MIT — see &lt;code&gt;LICENSE&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706528</guid><pubDate>Wed, 21 Jan 2026 14:54:56 +0000</pubDate></item><item><title>Show HN: yolo-cage – AI coding agents that can't exfiltrate secrets</title><link>https://github.com/borenstein/yolo-cage</link><description>&lt;doc fingerprint="9f781b9e1db7ca83"&gt;
  &lt;main&gt;
    &lt;p&gt;You're a responsible engineer. You'd never just let an AI run roughshod through your most sensitive systems and codebases.&lt;/p&gt;
    &lt;p&gt;That's why you'd never just shut off the safeguards for a tool like Claude Code. It asks permission for every dangerous action! Safe!&lt;/p&gt;
    &lt;p&gt;So you wait. And you answer. Decision fatigue sets in. And that's when it happens.&lt;/p&gt;
    &lt;p&gt;Permission prompts neglect the weakest part of the thread model: a tired user. What if we could empower the agent while limiting its blast radius, thus deferring your decisions until PR review?&lt;/p&gt;
    &lt;p&gt;That would be great! And that would be yolo-cage.&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://github.com/borenstein/yolo-cage/releases/latest/download/yolo-cage -o yolo-cage
chmod +x yolo-cage &amp;amp;&amp;amp; sudo mv yolo-cage /usr/local/bin/
yolo-cage build --interactive --up&lt;/code&gt;
    &lt;p&gt;Then create a sandbox and start coding:&lt;/p&gt;
    &lt;code&gt;yolo-cage create feature-branch
yolo-cage attach feature-branch   # Claude in tmux, YOLO mode&lt;/code&gt;
    &lt;p&gt;Prerequisites: Vagrant with libvirt (Linux) or QEMU (macOS, experimental), 8GB RAM, 4 CPUs, GitHub PAT (&lt;code&gt;repo&lt;/code&gt; scope), Claude account. See setup docs for details.&lt;/p&gt;
    &lt;p&gt;Secrets in HTTP/HTTPS - egress proxy scans request bodies, headers, URLs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;sk-ant-*&lt;/code&gt;,&lt;code&gt;AKIA*&lt;/code&gt;,&lt;code&gt;ghp_*&lt;/code&gt;, SSH private keys, generic credential patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Git operations - dispatcher enforces branch isolation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Push to any branch except the one assigned at sandbox creation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git remote&lt;/code&gt;,&lt;code&gt;git clone&lt;/code&gt;,&lt;code&gt;git config&lt;/code&gt;,&lt;code&gt;git credential&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GitHub CLI - dispatcher blocks dangerous commands:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gh pr merge&lt;/code&gt;,&lt;code&gt;gh repo delete&lt;/code&gt;,&lt;code&gt;gh api&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GitHub API - proxy blocks at HTTP layer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;PUT /repos/*/pulls/*/merge&lt;/code&gt;,&lt;code&gt;DELETE /repos/*&lt;/code&gt;, webhook modifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Exfiltration sites: pastebin.com, file.io, transfer.sh, etc.&lt;/p&gt;
    &lt;p&gt;See Architecture for the full threat model.&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────────────────────────────────────┐
│ Vagrant VM (MicroK8s)                                                    │
│                                                                          │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │ Sandbox Pod                                                        │  │
│  │                                                                    │  │
│  │  Claude Code (YOLO mode)                                           │  │
│  │       │                                                            │  │
│  │       ├── git/gh ──▶ Dispatcher ──▶ GitHub                         │  │
│  │       │              • Branch enforcement                          │  │
│  │       │              • TruffleHog pre-push                         │  │
│  │       │                                                            │  │
│  │       └── HTTP/S ──▶ Egress Proxy ──▶ Internet                     │  │
│  │                      • Secret scanning                             │  │
│  │                      • Domain blocklist                            │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                                                          │
└──────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;One sandbox per branch. Agents can only push to their assigned branch. All outbound traffic is filtered.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;create &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;attach &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Attach (Claude in tmux)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Attach (bash)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List sandboxes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;delete &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Delete sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;port-forward &amp;lt;branch&amp;gt; &amp;lt;port&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Forward port from sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;up&lt;/code&gt; / &lt;code&gt;down&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Start/stop VM&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;upgrade [--rebuild]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Upgrade to latest version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;version&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show version&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Access web apps running inside a sandbox:&lt;/p&gt;
    &lt;code&gt;yolo-cage port-forward feature-x 8080           # localhost:8080 → pod:8080
yolo-cage port-forward feature-x 9000:3000      # localhost:9000 → pod:3000
yolo-cage port-forward feature-x 8080 --bind 0.0.0.0  # LAN accessible&lt;/code&gt;
    &lt;p&gt;See Configuration for proxy bypass, hooks, and resource limits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Architecture - Threat model, design rationale&lt;/item&gt;
      &lt;item&gt;Configuration - Egress policy, proxy bypass, hooks&lt;/item&gt;
      &lt;item&gt;Customization - Adding tools, resource limits&lt;/item&gt;
      &lt;item&gt;Security Audit - Escape testing guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This reduces risk. It does not eliminate it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DNS exfiltration - data encoded in DNS queries&lt;/item&gt;
      &lt;item&gt;Timing side channels - information leaked via response timing&lt;/item&gt;
      &lt;item&gt;Steganography - secrets hidden in images or binary data&lt;/item&gt;
      &lt;item&gt;Sophisticated encoding - bypassing pattern matching&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use scoped credentials. Don't use production secrets where exfiltration would be catastrophic. See Security Audit to test it yourself.&lt;/p&gt;
    &lt;p&gt;MIT. See LICENSE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706796</guid><pubDate>Wed, 21 Jan 2026 15:13:29 +0000</pubDate></item><item><title>SmartOS</title><link>https://docs.smartos.org/</link><description>&lt;doc fingerprint="3653195c723d5ed3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Home&lt;/head&gt;
    &lt;p&gt;Welcome to the SmartOS Documentation. Here you'll find everything you need to get started using SmartOS and participating in the community. Information about what's new in recent releases can be found in the SmartOS Changelog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick Start¶&lt;/head&gt;
    &lt;p&gt;Not sure where to begin? Try the SmartOS Quick Start Guide!&lt;/p&gt;
    &lt;head rend="h2"&gt;SmartOS In a Nutshell¶&lt;/head&gt;
    &lt;p&gt;SmartOS is a specialized Type 1 Hypervisor platform based on illumos.Â It supports two types of virtualization:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OS Virtual Machines (Zones, Containers): A light-weight virtualization solution offering a complete and secure userland environment on a single global kernel, offering true bare metal performance and all the features illumos has, namely dynamic introspection via DTrace&lt;/item&gt;
      &lt;item&gt;Hardware Virtual Machines (KVM, Bhyve): A full virtualization solution for running a variety of guest OS's including Linux, Windows, *BSD, Plan9 and more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SmartOS is a "live OS", it is always booted via PXE, ISO, or USB Key and runs entirely from memory, allowing the local disks to be used entirely for hosting virtual machines without wasting disks for the root OS.Â This architecture has a variety of advantages including increased security, no need for patching, fast upgrades and recovery.&lt;/p&gt;
    &lt;p&gt;Virtualization in SmartOS builds on top of the foundational illumos technologies inherited from OpenSolaris, namely:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ZFS for storage virtualization&lt;/item&gt;
      &lt;item&gt;Crossbow (&lt;code&gt;dladm&lt;/code&gt;) for network virtualization&lt;/item&gt;
      &lt;item&gt;Zones for virtualization and containment&lt;/item&gt;
      &lt;item&gt;DTrace for introspection&lt;/item&gt;
      &lt;item&gt;SMF for service management&lt;/item&gt;
      &lt;item&gt;RBAC/BSM for auditing and role based security&lt;/item&gt;
      &lt;item&gt;And more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SmartOS is typically "installed" by downloading and copying the OS image onto a USB key and then booting that key.Â On the first boot a configuration utility will configure your base networking, allow you to set the root password, and allow you to select which disks to use to create the ZFS Zpool which will provide persistent storage.&lt;/p&gt;
    &lt;p&gt;When you log into SmartOS you will enter the hypervisor, aka "global zone". From here you can download VM Images using the &lt;code&gt;imgadm&lt;/code&gt; tool, which are
pre-configured Container and HVM virtual machines.Â  You can then use the
&lt;code&gt;vmadm&lt;/code&gt; tool to create and manage both containers and hardware virtual
machines.&lt;/p&gt;
    &lt;p&gt;An important aspect of SmartOS is that both OS (Zones) and hardware virtual machines are both built on Zones technology.Â In the case of OS virtualization, the guest virtual machine is provided with a complete userland environment on which to run applications directly. In the case of HVM virtualization, the &lt;code&gt;qemu&lt;/code&gt; or &lt;code&gt;bhyve&lt;/code&gt;  process
will run within a stripped down Zone.Â  This offers a variety of
advantages for administration, including a common method for managing
resource controls, network interfaces, and administration.Â  It also
provides HVM guests with an additional layer of security and isolation
not offered by other virtualization platforms.&lt;/p&gt;
    &lt;p&gt;Finally, instances are described in JSON.Â Both administrative tools, &lt;code&gt;imgadm&lt;/code&gt; and &lt;code&gt;vmadm&lt;/code&gt;, accept and return all data in JSON
format.Â  This provides a simple, consistent, and programmatic
interface for creating and managing VM's.&lt;/p&gt;
    &lt;head rend="h2"&gt;Code of Conduct¶&lt;/head&gt;
    &lt;p&gt;As a participant of the illumos community, all projects related to Triton (including SmartOS, Triton, Manta, etc.) we have adopted the illumos Code of Conduct.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scope¶&lt;/head&gt;
    &lt;p&gt;The scope of the code of conduct extends to SmartOS, Triton, and Manta resources including mailing lists, chat, social media, and GitHub repositories.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enforcement¶&lt;/head&gt;
    &lt;p&gt;Conduct violations involving the Triton community may be reported by contacting conduct@tritondatacenter.com instead of, or in addition to conduct@illumos.org as the case may be warranted.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Use this Site¶&lt;/head&gt;
    &lt;p&gt;This documentation can provide you with a variety of resources for users at all levels.Â To get started, download SmartOS now, and be sure to review the Hardware Requirements. Once installed, refer to our Users Guide to help you learn your way around SmartOS.&lt;/p&gt;
    &lt;p&gt;When you have questions, refer to the SmartOS Community section for pointers to our IRC chat rooms and mailing lists.Â When you're ready to start improving and adding your own customizations to SmartOS please refer to our Developers Guide.&lt;/p&gt;
    &lt;p&gt;SmartOS is a community effort, as you explore and experiment with SmartOS please feel free to edit and contribute to this site to improve the documentation for other users in the community.&lt;/p&gt;
    &lt;head rend="h2"&gt;About Triton¶&lt;/head&gt;
    &lt;p&gt;SmartOS is a fundamental component of the Triton Data Center (Triton) product. Triton source and images are available for at no cost and powers several public and private clouds around the globe, namely the MNX Public Cloud.Â As you use SmartOS you will come across hooks that are used by Triton, such as file systems and services named "smartdc".&lt;/p&gt;
    &lt;p&gt;If you are interested in evaluating the full Triton Data Center product, please contact smartos@tritondatacenter.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706947</guid><pubDate>Wed, 21 Jan 2026 15:23:18 +0000</pubDate></item></channel></rss>