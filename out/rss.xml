<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Dec 2025 18:17:06 +0000</lastBuildDate><item><title>Unreal Tournament 2004 is back</title><link>https://old.reddit.com/r/unrealtournament/comments/1pdbe69/breaking_unreal_tournament_2004_is_back/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46145834</guid><pubDate>Thu, 04 Dec 2025 10:06:35 +0000</pubDate></item><item><title>PGlite ‚Äì Embeddable Postgres</title><link>https://pglite.dev/</link><description>&lt;doc fingerprint="e74292d12d3170e0"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Lightweight&lt;/head&gt;&lt;p&gt;A complete WASM build of Postgres that's under 3MB Gzipped.&lt;/p&gt;&lt;p&gt;Embeddable Postgres&lt;/p&gt;&lt;p&gt;Run a full Postgres database locally in WASM with reactivity and live sync.&lt;/p&gt;&lt;p&gt;Create and publish a Postgres database using AI Supabase:&lt;/p&gt;built on PGlite by&lt;p&gt;This is a full PGlite Postgres running in your browser. pgvector!&lt;/p&gt;It even includes&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146133</guid><pubDate>Thu, 04 Dec 2025 10:52:42 +0000</pubDate></item><item><title>Building optimistic UI in Rails (and learn custom elements)</title><link>https://railsdesigner.com/custom-elements/</link><description>&lt;doc fingerprint="2c37e83ac8e004ec"&gt;
  &lt;main&gt;
    &lt;p&gt;Custom elements are one of those web platform features that sound complicated but turn out to be surprisingly simple. If you have used Hotwire in Rails, you have already used them. Both &lt;code&gt;&amp;lt;turbo-frame&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;turbo-stream&amp;gt;&lt;/code&gt; are custom elements. They are just HTML tags with JavaScript behavior attached.&lt;/p&gt;
    &lt;p&gt;This article walks through what custom elements are, how they compare to Stimulus controllers and how to build them yourself! Starting with a simple counter and ending with an optimistic form that updates instantly without waiting for the server. ü§Ø&lt;/p&gt;
    &lt;p&gt;The code is available on GitHub.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are custom elements?&lt;/head&gt;
    &lt;p&gt;Custom elements let you define your own HTML tags with custom behavior. They fall under the Web Components umbrella, alongside Shadow DOM (encapsulated styling and markup) and templates (reusable HTML fragments), though each can be used independently. To use custom elements, just define a class, register it with the browser, and use your new tag anywhere (Shadow DOM or templates not required).&lt;/p&gt;
    &lt;p&gt;Here is the simplest possible custom element:&lt;/p&gt;
    &lt;code&gt;class HelloWorld extends HTMLElement {
  connectedCallback() {
    this.textContent = "Hello from a custom element üëã"
  }
}

customElements.define("hello-world", HelloWorld)
&lt;/code&gt;
    &lt;p&gt;Now you can use &lt;code&gt;&amp;lt;hello-world&amp;gt;&amp;lt;/hello-world&amp;gt;&lt;/code&gt; in your HTML and it will display the message. The &lt;code&gt;connectedCallback&lt;/code&gt; runs when the element is added to the page. This is similar to Stimulus‚Äôs &lt;code&gt;connect()&lt;/code&gt; method. There is also, just like with Stimulus, a &lt;code&gt;disconnectedCallback&lt;/code&gt;. This can be used similar to Stimulus‚Äô: removing event listeners and so on.&lt;/p&gt;
    &lt;p&gt;Custom element names must contain a hyphen. This prevents conflicts with future HTML elements. So &lt;code&gt;&amp;lt;hello-world&amp;gt;&lt;/code&gt; works, but &lt;code&gt;&amp;lt;helloworld&amp;gt;&lt;/code&gt; does not.&lt;/p&gt;
    &lt;head rend="h2"&gt;Attributes and properties&lt;/head&gt;
    &lt;p&gt;Custom elements can read attributes just like regular HTML elements:&lt;/p&gt;
    &lt;code&gt;class GreetUser extends HTMLElement {
  connectedCallback() {
    const name = this.getAttribute("name") || "stranger"

    this.textContent = `Hello, ${name}!`
  }
}

customElements.define("greet-user", GreetUser)
&lt;/code&gt;
    &lt;p&gt;Use it like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;greet-user name="Cam"&amp;gt;&amp;lt;/greet-user&amp;gt;
&lt;/code&gt;
    &lt;p&gt;To react to attribute changes, use &lt;code&gt;attributeChangedCallback&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;class GreetUser extends HTMLElement {
  static observedAttributes = ["name"]

  connectedCallback() {
    this.#render()
  }

  attributeChangedCallback(name, oldValue, newValue) {
    this.#render()
  }

  // private

  #render() {
    const name = this.getAttribute("name") || "stranger"

    this.textContent = `Hello, ${name}!`
  }
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;observedAttributes&lt;/code&gt; array tells the browser which attributes to watch. Without it, &lt;code&gt;attributeChangedCallback&lt;/code&gt; never fires.&lt;/p&gt;
    &lt;head rend="h3"&gt;The &lt;code&gt;is&lt;/code&gt; attribute&lt;/head&gt;
    &lt;p&gt;You can extend built-in HTML elements using the &lt;code&gt;is&lt;/code&gt; attribute. For example, extending a button:&lt;/p&gt;
    &lt;code&gt;class FancyButton extends HTMLButtonElement {
  connectedCallback() {
    this.classList.add("fancy")
  }
}

customElements.define("fancy-button", FancyButton, { extends: "button" })
&lt;/code&gt;
    &lt;p&gt;Then use it like:&lt;/p&gt;
    &lt;code&gt;&amp;lt;button is="fancy-button"&amp;gt;Click me&amp;lt;/button&amp;gt;
&lt;/code&gt;
    &lt;p&gt;This keeps all the built-in button behavior while adding your custom features (simply adding the &lt;code&gt;fancy&lt;/code&gt; class in above example). However, Safari does not support this feature. So I stick to autonomous custom elements (the hyphenated tags) for better compatibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Custom elements vs Stimulus&lt;/head&gt;
    &lt;p&gt;If you have used Stimulus, custom elements will feel familiar. Here is how they compare:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Stimulus&lt;/cell&gt;
        &lt;cell role="head"&gt;Custom Element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Lifecycle&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;connect()&lt;/code&gt; / &lt;code&gt;disconnect()&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;connectedCallback()&lt;/code&gt; / &lt;code&gt;disconnectedCallback()&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Finding elements&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;targets&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;querySelector()&lt;/code&gt; / direct children&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;State&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;values&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;attributes + properties&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Events&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;action&lt;/code&gt; attributes&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;addEventListener()&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Framework&lt;/cell&gt;
        &lt;cell&gt;Requires Stimulus&lt;/cell&gt;
        &lt;cell&gt;Browser-native&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Stimulus is great for connecting behavior to existing HTML. Custom elements are better when you want a reusable component that works anywhere. They are also simpler when you do not need Stimulus‚Äôs conventions.&lt;/p&gt;
    &lt;p&gt;The main difference is how you find elements. Stimulus uses targets:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div data-controller="counter"&amp;gt;
  &amp;lt;span data-counter-target="count"&amp;gt;0&amp;lt;/span&amp;gt;

  &amp;lt;button data-action="click-&amp;gt;counter#increment"&amp;gt;+&amp;lt;/button&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Custom elements use standard DOM/query methods (see example below):&lt;/p&gt;
    &lt;code&gt;&amp;lt;click-counter&amp;gt;
  &amp;lt;span class="count"&amp;gt;0&amp;lt;/span&amp;gt;

  &amp;lt;button&amp;gt;+&amp;lt;/button&amp;gt;
&amp;lt;/click-counter&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Custom elements feel more like writing vanilla JavaScript. Stimulus is more convention-based (which is often confusing to many).&lt;/p&gt;
    &lt;p&gt;In the end it is all a regular JavaScript class. I‚Äôve explored these extensively in the book JavaScript for Rails Developers. üí°&lt;/p&gt;
    &lt;head rend="h2"&gt;Building a simple counter&lt;/head&gt;
    &lt;p&gt;Time to build something. Start with a counter that increments when clicked:&lt;/p&gt;
    &lt;code&gt;// app/javascript/components/click_counter.js
class ClickCounter extends HTMLElement {
  connectedCallback() {
    this.count = 0

    this.addEventListener("click", () =&amp;gt; this.#increment())
  }

  #increment() {
    this.count++

    this.querySelector("span").textContent = this.count
  }
}

customElements.define("click-counter", ClickCounter)
&lt;/code&gt;
    &lt;p&gt;Import it in your application JavaScript:&lt;/p&gt;
    &lt;code&gt;// app/javascript/application.js
import "@hotwired/turbo-rails"
import "controllers"

import "components/click_counter"
&lt;/code&gt;
    &lt;p&gt;Configure importmap to find the new directory:&lt;/p&gt;
    &lt;code&gt;# config/importmap.rb
pin_all_from "app/javascript/controllers", under: "controllers"

pin_all_from "app/javascript/components", under: "components"
&lt;/code&gt;
    &lt;p&gt;Now use it in your views:&lt;/p&gt;
    &lt;code&gt;&amp;lt;click-counter&amp;gt;
  &amp;lt;button&amp;gt;Clicked &amp;lt;span&amp;gt;0&amp;lt;/span&amp;gt; times&amp;lt;/button&amp;gt;
&amp;lt;/click-counter&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Click the button and watch the counter increment. Simple! üòä&lt;/p&gt;
    &lt;head rend="h2"&gt;Building an optimistic form&lt;/head&gt;
    &lt;p&gt;Now for something a bit more useful. Build a form that updates instantly without waiting for the server. If the save fails, show an error. If it succeeds, keep the optimistic UI.&lt;/p&gt;
    &lt;p&gt;It will look like this:&lt;/p&gt;
    &lt;p&gt;See how the message gets appended immediately and then (notice the blue Turbo progress bar) gets replaced with the server rendered version.&lt;/p&gt;
    &lt;p&gt;The HTML looks like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;optimistic-form&amp;gt;
  &amp;lt;form action="&amp;lt;%= messages_path %&amp;gt;" method="post"&amp;gt;
    &amp;lt;%= hidden_field_tag :authenticity_token, form_authenticity_token %&amp;gt;

    &amp;lt;%= text_area_tag "message[content]", "", placeholder: "Write a message‚Ä¶", required: true %&amp;gt;

    &amp;lt;%= submit_tag "Send" %&amp;gt;
  &amp;lt;/form&amp;gt;

  &amp;lt;template response&amp;gt;
    &amp;lt;%= render Message.new(content: "", created_at: Time.current) %&amp;gt;
  &amp;lt;/template&amp;gt;
&amp;lt;/optimistic-form&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;&amp;lt;template response&amp;gt;&lt;/code&gt; tag (indeed also part of the Web Components standard) holds the display HTML for new messages. When the form submits, the custom element renders this template with the form values and appends it to the list. The form still submits normally to Rails.&lt;/p&gt;
    &lt;p&gt;Start with the basic structure:&lt;/p&gt;
    &lt;code&gt;// app/javascript/components/optimistic_form.js
class OptimisticForm extends HTMLElement {
  connectedCallback() {
    this.form = this.querySelector("form")
    this.template = this.querySelector("template[response]")
    this.target = document.querySelector("#messages")

    this.form.addEventListener("submit", () =&amp;gt; this.#submit())
  }

  #submit() {
    if (!this.form.checkValidity()) return

    const formData = new FormData(this.form)
    const optimisticElement = this.#render(formData)

    this.target.append(optimisticElement)
  }
}

customElements.define("optimistic-form", OptimisticForm)
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;submit&lt;/code&gt; method checks form validity first using the browser‚Äôs built-in validation. If the form is invalid, let the browser show its validation messages. Otherwise render the optimistic UI and let the form submit normally.&lt;/p&gt;
    &lt;head rend="h3"&gt;Getting optimistic&lt;/head&gt;
    &lt;p&gt;Extract the form data and populate the template:&lt;/p&gt;
    &lt;code&gt;#render(formData) {
  const element = this.template.content.cloneNode(true).firstElementChild

  element.id = "optimistic-message"

  for (const [name, value] of formData.entries()) {
    const field = element.querySelector(`[data-field="${name}"]`)

    if (field) field.textContent = value
  }

  return element
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;cloneNode(true)&lt;/code&gt; creates a copy of the template content. Loop through the form data and update any element with a matching &lt;code&gt;data-field&lt;/code&gt; attribute. This is why the partial has a &lt;code&gt;data-field="message[content]"&lt;/code&gt; on the message display.&lt;/p&gt;
    &lt;p&gt;The optimistic element appears in the list immediately, then the form submits to Rails.&lt;/p&gt;
    &lt;p&gt;The Turbo Stream does not append the message, but replaces the ‚Äúoptimistic message‚Äù with the real one from the database:&lt;/p&gt;
    &lt;code&gt;&amp;lt;%# app/views/messages/create.turbo_stream.erb %&amp;gt;
&amp;lt;%= turbo_stream.replace "optimistic-message", @message %&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Since both the optimistic template and the message partial render the same HTML, the replacement is seamless. The user sees the message appear instantly, then it gets replaced with the real version (with the correct ID, timestamp, etc.) a moment later.&lt;/p&gt;
    &lt;p&gt;Here is the full implementation:&lt;/p&gt;
    &lt;code&gt;// app/javascript/components/optimistic_form.js
class OptimisticForm extends HTMLElement {
  connectedCallback() {
    this.form = this.querySelector("form")
    this.template = this.querySelector("template[response]")
    this.target = document.querySelector("#messages")

    this.form.addEventListener("submit", () =&amp;gt; this.#submit())
    this.form.addEventListener("turbo:submit-end", () =&amp;gt; this.#reset())
  }

  // private

  #submit() {
    if (!this.form.checkValidity()) return

    const formData = new FormData(this.form)
    const optimisticElement = this.#render(formData)

    this.target.append(optimisticElement)
  }

  #render(formData) {
    const element = this.template.content.cloneNode(true).firstElementChild

    element.id = "optimistic-message"

    for (const [name, value] of formData.entries()) {
      const field = element.querySelector(`[data-field="${name}"]`)

      if (field) field.textContent = value
    }

    return element
  }

  #reset() {
    this.form.reset()
  }
}

customElements.define("optimistic-form", OptimisticForm)
&lt;/code&gt;
    &lt;p&gt;Do not forget to import it:&lt;/p&gt;
    &lt;code&gt;// app/javascript/application.js
import "components/optimistic_form"
&lt;/code&gt;
    &lt;p&gt;Now when you submit the form, the message appears instantly in the list. The form submits to Rails, which responds with a Turbo Stream (I added &lt;code&gt;sleep&lt;/code&gt; to mimic a slow response) that replaces the optimistic message with the real one. If the save fails, Rails can show an error message normally.&lt;/p&gt;
    &lt;p&gt;Cool, right? I‚Äôve used this technique before with a client successfully. Many months later and it holds up nicely.&lt;/p&gt;
    &lt;p&gt;This pattern can work great for any form where you want instant feedback. Like chat messages, comments or todos. The new item appears immediately. No loading spinners, no waiting.&lt;/p&gt;
    &lt;p&gt;The key is that the partial lives right within the &lt;code&gt;template&lt;/code&gt; element. You are not duplicating it in JavaScript. Change the partial and the optimistic UI updates automatically.&lt;/p&gt;
    &lt;p&gt;Custom elements make this pattern reusable. Drop &lt;code&gt;&amp;lt;optimistic-form&amp;gt;&lt;/code&gt; anywhere in your app. It works with any form and any partial (with client‚Äôs project mentioned above I stubbed the partial with more advanved ‚Äústand-in‚Äù model instance).&lt;/p&gt;
    &lt;p&gt;Yet another tool in your Rails toolkit. Did this inspire you to use custom elements more too? Let me know below! ‚ù§Ô∏è&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146204</guid><pubDate>Thu, 04 Dec 2025 11:03:16 +0000</pubDate></item><item><title>30 years ago today "Netscape and Sun announce JavaScript"</title><link>https://web.archive.org/web/20070916144913/http://wp.netscape.com/newsref/pr/newsrelease67.html</link><description>&lt;doc fingerprint="a919d91b0aa1aa76"&gt;
  &lt;main&gt;
    &lt;p&gt;MOUNTAIN VIEW, Calif. (December 4, 1995) -- Netscape Communications Corporation (NASDAQ: NSCP) and Sun Microsystems, Inc. (NASDAQ:SUNW), today announced JavaScript, an open, cross-platform object scripting language for the creation and customization of applications on enterprise networks and the Internet. The JavaScript language complements Java, Sun's industry-leading object-oriented, cross-platform programming language. The initial version of JavaScript is available now as part of the beta version of Netscape Navigator 2.0, which is currently available for downloading from Netscape's web site.&lt;/p&gt;
    &lt;p&gt;In addition, 28 industry-leading companies, including America Online, Inc., Apple Computer, Inc., Architext Software, Attachmate Corporation, AT&amp;amp;T;, Borland International, Brio Technology, Inc., Computer Associates, Inc., Digital Equipment Corporation, Hewlett-Packard Company, Iconovex Corporation, Illustra Information Technologies, Inc., Informix Software, Inc., Intuit, Inc., Macromedia, Metrowerks, Inc., Novell, Inc., Oracle Corporation, Paper Software, Inc., Precept Software, Inc., RAD Technologies, Inc., The Santa Cruz Operation, Inc., Silicon Graphics, Inc., Spider Technologies, Sybase, Inc., Toshiba Corporation, Verity, Inc., and Vermeer Technologies, Inc., have endorsed JavaScript as an open standard object scripting language and intend to provide it in future products. The draft specification of JavaScript, as well as the final draft specification of Java, is planned for publishing and submission to appropriate standards bodies for industry review and comment this month.&lt;/p&gt;
    &lt;p&gt;JavaScript is an easy-to-use object scripting language designed for creating live online applications that link together objects and resources on both clients and servers. While Java is used by programmers to create new objects and applets, JavaScript is designed for use by HTML page authors and enterprise application developers to dynamically script the behavior of objects running on either the client or the server. JavaScript is analogous to Visual Basic in that it can be used by people with little or no programming experience to quickly construct complex applications. JavaScript's design represents the next generation of software designed specifically for the Internet and is:&lt;/p&gt;
    &lt;p&gt;With JavaScript, an HTML page might contain an intelligent form that performs loan payment or currency exchange calculations right on the client in response to user input. A multimedia weather forecast applet written in Java can be scripted by JavaScript to display appropriate images and sounds based on the current weather readings in a region. A server-side JavaScript script might pull data out of a relational database and format it in HTML on the fly. A page might contain JavaScript scripts that run on both the client and the server. On the server, the scripts might dynamically compose and format HTML content based on user preferences stored in a relational database, and on the client, the scripts would glue together an assortment of Java applets and HTML form elements into a live interactive user interface for specifying a net-wide search for information.&lt;/p&gt;
    &lt;p&gt;Java programs and JavaScript scripts are designed to run on both clients and servers, with JavaScript scripts used to modify the properties and behavior of Java objects, so the range of live online applications that dynamically present information to and interact with users over enterprise networks or the Internet is virtually unlimited. Netscape will support Java and JavaScript in client and server products as well as programming tools and applications to make this vision a reality.&lt;/p&gt;
    &lt;p&gt;"Programmers have been overwhelmingly enthusiastic about Java because it was designed from the ground up for the Internet. JavaScript is a natural fit, since it's also designed for the Internet and Unicode-based worldwide use," said Bill Joy, co-founder and vice president of research at Sun. "JavaScript will be the most effective method to connect HTML-based content to Java applets."&lt;/p&gt;
    &lt;p&gt;Netscape's authoring and application development tools -- Netscape Navigator Gold 2.0, Netscape LiveWire and Netscape LiveWire Pro -- are designed for rapid development and deployment of JavaScript applications. Netscape Navigator Gold 2.0 enables developers to create and edit JavaScript scripts, while Netscape LiveWire enables JavaScript programs to be installed, run and managed on Netscape servers, both within the enterprise and across the Internet. Netscape LiveWire Pro adds support for JavaScript connectivity to high-performance relational databases from Illustra, Informix, Microsoft, Oracle and Sybase. Java and JavaScript support are being built into all Netscape products to provide a unified, front-to-back, client/server/tool environment for building and deploying live online applications.&lt;/p&gt;
    &lt;p&gt;Java is available to developers free of charge. The Java Compiler and Java Developer's Kit as well as the HotJava browser and related documentation are available from Sun's web site at http://java.sun.com. In addition, the Java source code can be licensed for a fee. Details on licensing are also available via the java.sun.com web page. To date, Sun has licensed Java to a number of leading technology companies, including Borland, Macromedia, Mitsubishi, Netscape, Oracle, Silicon Graphics, Spyglass, and Toshiba. Sun's Workshop for Java toolkit is scheduled for release in Spring 1996. Sun's NEO product family, the first complete development, operating and management environment for object-oriented networked applications, will also use Java-enabled browsers as front-ends to the NEO environment.&lt;/p&gt;
    &lt;p&gt;Netscape and Sun plan to propose JavaScript to the W3 Consortium (W3C) and the Internet Engineering Task Force (IETF) as an open Internet scripting language standard. JavaScript will be an open, freely licensed proposed standard available to the entire Internet community. Existing Sun Java licensees will receive a license to JavaScript. In addition, Sun and Netscape intend to make a source code reference implementation of JavaScript available for royalty-free licensing, further encouraging its adoption as a standard in a wide variety of products.&lt;/p&gt;
    &lt;p&gt;Netscape Communications Corporation is a premier provider of open software for linking people and information over enterprise networks and the Internet. The company offers a full line of Netscape Navigator clients, Netscape servers, development tools and Netscape Internet Applications to create a complete platform for next-generation, live online applications. Traded on Nasdaq under the symbol "NSCP", Netscape Communications Corporation is based in Mountain View, California.&lt;/p&gt;
    &lt;p&gt;With annual revenues of $6 billion, Sun Microsystems, Inc. provides solutions that enable customers to build and maintain open network computing environments. Widely recognized as a proponent of open standards, the company is involved in the design, manufacture and sale of products, technologies and services for commercial and technical computing. Sun's SPARC(TM) workstations, multiprocessing servers, SPARC microprocessors, Solaris operating software and ISO-certified service organization each rank No. 1 in the UNIX(R) industry. Founded in 1982, Sun is headquartered in Mountain View, Calif., and employs more than 14,000 people worldwide.&lt;/p&gt;
    &lt;p&gt;Additional information on Netscape Communications Corporation is available on the Internet at , by sending email to info@netscape.com or by calling 415-528-2555. Additional information on Sun Microsystems is available on the Internet at http://www.sun.com or, for Java information, http://java.sun.com Netscape Communications, the Netscape Communications logo, Netscape, and Netscape Navigator are trademarks of Netscape Communications Corporation. JavaScript and Java are trademarks of Sun Microsystems, Inc. All other product names are trademarks of their respective companies.&lt;/p&gt;
    &lt;p&gt;WHAT COMPANIES SAY ABOUT JAVASCRIPT&lt;/p&gt;
    &lt;p&gt;Company Contacts:&lt;/p&gt;
    &lt;p&gt; America Online, Inc. Pam Mcgraw: (703) 556-3746&lt;lb/&gt; Apple Computer, Inc. Nancy Morrison: (408) 862-6200&lt;lb/&gt; Architext Software Mike Brogan/Roederer-Johnson: (415) 802-1850&lt;lb/&gt; AT&amp;amp;T; Mary Whelan: (908) 658-6000&lt;lb/&gt; Borland International Bill Jordan: (408) 431-4721&lt;lb/&gt; Brio Technology, Inc. Yorgen Edholm: yhe@brio.com&lt;lb/&gt; Computer Associates, Inc. Yogesh Gupta: (516) 342-4045&lt;lb/&gt; Digital Equipment Corporation Ethel Kaiden: (508) 486-2814&lt;lb/&gt; Hewlett-Packard Company Bill Hodges: (408) 447-7041&lt;lb/&gt; Iconovex Corporation Robert Griggs: (800) 943-0292&lt;lb/&gt; Illustra Information Technologies, Inc. Sandra Bateman: (510) 873-62 09&lt;lb/&gt; Informix Software, Inc. Cecilia Denny: (415) 926-6420&lt;lb/&gt; Intuit, Inc. Sheryl Ross: (415) 329-3569&lt;lb/&gt; Macromedia Miles Walsh: (415) 252-2000&lt;lb/&gt; Metrowerks, Inc. Greg Galanos: gpg@austin.metrowerks.com&lt;lb/&gt; Novell, Inc. Christine Hughes: (408) 577-7453&lt;lb/&gt; Oracle Corporation Mark Benioff: (415) 506-7000&lt;lb/&gt; Paper Software, Inc. Mike Mccue: (914) 679-2440&lt;lb/&gt; Precept Software, Inc. Judy Estrin: (408) 446-7600&lt;lb/&gt; RAD Technologies, Inc. Jeff Morgan: jmorgan@rad.com&lt;lb/&gt; The Santa Cruz Operation, Inc. Marty Picco: (408) 425-7222&lt;lb/&gt; Silicon Graphics, Inc. Virginia Henderson: (415) 933-1306&lt;lb/&gt; Spider Technologies Diana Jovin: (415) 969-6128&lt;lb/&gt; Sybase, Inc. Robert Manetta: (510) 922-5742&lt;lb/&gt; Verity, Inc. Marguerite Padovani: (415) 960-7724&lt;lb/&gt; Vermeer Technologies, Inc. Ed Cuoco: (617) 576-1700x130&lt;/p&gt;
    &lt;p&gt; Netscape Communications Corporation is a premier provider of open software for linking people and information over enterprise networks and the Internet. The company offers a full line of Netscape Navigator clients, Netscape servers, development tools and Netscape Internet Applications to create a complete platform for next-generation, live online applications. Traded on Nasdaq under the symbol "NSCP", Netscape Communications Corporation is based in Mountain View, California. &lt;lb/&gt; Netscape Communications, the Netscape Communications logo, Netscape, Netscape Commerce Server, Netscape Communications Server, Netscape Proxy Server and Netscape News Server are trademarks of Netscape Communications Corporation. NCSA Mosaic is a trademark of the University of Illinois. All other product names are trademarks of their respective companies. &lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Help | Site Map | How to Get Netscape Products | Advertise With Us | Add Site | Custom Browser Program&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Autos | Business | Computing &amp;amp; Internet | Entertainment | Family | Games | Health | Lifestyles | Local | Netscape | Netscape Open Directory | News | Personal Finance | Real Estate | Research &amp;amp; Learn | Shopping | Small Business | Sports | Travel&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt; ¬© 1999 Netscape, All Rights Reserved. Legal &amp;amp; Privacy Notices&lt;p&gt;This site powered by Netscape SuiteSpot servers.&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146406</guid><pubDate>Thu, 04 Dec 2025 11:32:00 +0000</pubDate></item><item><title>I ignore the spotlight as a staff engineer</title><link>https://lalitm.com/software-engineering-outside-the-spotlight/</link><description>&lt;doc fingerprint="f7d094139d346c2f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why I Ignore The Spotlight as a Staff Engineer&lt;/head&gt;
    &lt;p&gt;Lately I‚Äôve been reading Sean Goedecke‚Äôs essays on being a Staff+ engineer. His work (particularly Software engineering under the spotlight and It‚Äôs Not Your Codebase) is razor-sharp and feels painfully familiar to anyone in Big Tech.&lt;/p&gt;
    &lt;p&gt;On paper, I fit the mold he describes: I‚Äôm a Senior Staff engineer at Google. Yet, reading his work left me with a lingering sense of unease. At first, I dismissed this as cynicism. After reflecting, however, I realized the problem wasn‚Äôt Sean‚Äôs writing but my reading.&lt;/p&gt;
    &lt;p&gt;Sean isn‚Äôt being bleak; he is accurately describing how to deal with a world where engineers are fungible assets and priorities shift quarterly. But my job looks nothing like that and I know deep down that if I tried to operate in that environment or in the way he described I‚Äôd burn out within months.&lt;/p&gt;
    &lt;p&gt;Instead I‚Äôve followed an alternate path, one that optimizes for systems over spotlights, and stewardship over fungibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;We Live in Different Worlds&lt;/head&gt;
    &lt;p&gt;The foundational reason for our diverging paths is that Sean and I operate in entirely different worlds with different laws governing them.&lt;/p&gt;
    &lt;p&gt;From Sean‚Äôs resume, my understanding is that he has primarily worked in product teams 1 building for external customers. Business goals pivot quarterly, and success is measured by revenue or MAU. Optimizing for the ‚ÄúSpotlight‚Äù makes complete sense in this environment. Product development at big tech scale is a crowded room: VPs, PMs and UX designers all have strong opinions. To succeed, you have to be agile and ensure you are working specifically on what executives are currently looking at.&lt;/p&gt;
    &lt;p&gt;On the other hand, I‚Äôve spent my entire career much more behind the scenes: in developer tools and infra teams.&lt;/p&gt;
    &lt;p&gt;My team‚Äôs customers are thousands of engineers in Android, Chrome, and throughout Google 2. End users of Google products don‚Äôt even know we exist; our focus is on making sure developers have the tools to collect product and performance metrics and debug issues using detailed traces.&lt;/p&gt;
    &lt;p&gt;In this environment, our relationship with leadership is very different. We‚Äôre never the ‚Äúhot project everyone wants,‚Äù so execs are not fighting to work with us. In fact, my team has historically struggled to hire PMs. The PM career ladder at Google incentivizes splashy external launches so we cannot provide good ‚Äúpromotion material‚Äù for them. Also, our feedback comes directly from engineers. Adding a PM in the middle causes a loss in translation, slowing down a tight, high-bandwidth feedback loop.&lt;/p&gt;
    &lt;p&gt;All of this together means our team operates ‚Äúbottom-up‚Äù: instead of execs telling us ‚Äúyou should do X‚Äù, we figure out what we think will have the most impact to our customers and work on building those features and tools. Execs ensure that we‚Äôre actually solving these problems by considering our impact on more product facing teams.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compounding Returns of Stewardship&lt;/head&gt;
    &lt;p&gt;In the product environments Sean describes, where goals pivot quarterly and features are often experimental, speed is the ultimate currency. You need to ship, iterate, and often move on before the market shifts. But in Infrastructure and Developer Experience, context is the currency.&lt;/p&gt;
    &lt;p&gt;Treating engineers as fungible assets destroys context. You might gain fresh eyes, but you lose the implicit knowledge of how systems actually break. Stewardship, staying with a system long-term, unlocks compounding returns that are impossible to achieve on a short rotation.&lt;/p&gt;
    &lt;p&gt;The first is efficiency via pattern matching. When you stay in one domain for years, new requests are rarely truly ‚Äúnew.‚Äù I am not just debugging code; I am debugging the intersection of my tools and hundreds of diverse engineering teams. When a new team comes to me with a ‚Äúunique‚Äù problem, I can often reach back in time: ‚ÄúWe tried this approach in 2021 with the Camera team; here is exactly why it failed, and here is the architecture that actually works‚Äù.&lt;/p&gt;
    &lt;p&gt;But the more powerful return is systemic innovation. If you rotate teams every year, you are limited to solving acute bugs that are visible right now. Some problems, however, only reveal their shape over long horizons.&lt;/p&gt;
    &lt;p&gt;Take Bigtrace, a project I recently led; it was a solution that emerged solely because I stuck around long enough to see the shape of the problem:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Start of 2023 (Observation): I began noticing a pattern. Teams across Google were collecting terabytes or even petabytes of performance traces, but they were struggling to process them. Engineers were writing brittle, custom pipelines to parse data, often complaining about how slow and painful it was to iterate on their analysis.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most of 2023 (Research): I didn‚Äôt jump to build a production system. Instead, I spent the best part of a year prototyping quietly in the background while working on other projects. I gathered feedback from these same engineers who had complained and because I had established long-term relationships, they gave me honest and introspective feedback. I learned what sort of UX, latency and throughput requirements they had and figured out how I could meet them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;End of 2023 to Start of 2024 (Execution): We built and launched Bigtrace, a distributed big data query engine for traces. Today, it processes over 2 billion traces a month and is a critical part of the daily workflow for 100+ engineers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If I had followed the advice to ‚Äúoptimize for fungibility‚Äù (i.e. if I had switched teams in 2023 to chase a new project) Bigtrace would not exist.&lt;/p&gt;
    &lt;p&gt;Instead, I would have left during the research phase and my successor would have seen the same ‚Äúnoise‚Äù of engineers complaining. But without the historical context to recognize a missing puzzle piece, I think they would have struggled to build something like Bigtrace.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Power of ‚ÄúNo‚Äù&lt;/head&gt;
    &lt;p&gt;One of the most seductive arguments for chasing the ‚ÄúSpotlight‚Äù is that it guarantees resources and executive attention. But that attention is a double-edged sword.&lt;/p&gt;
    &lt;p&gt;High-visibility projects are often volatile. They come with shifting executive whims, political maneuvering, and often end up in situations where long-term quality is sacrificed for short-term survival. For some engineers, navigating this chaos is a thrill. For those of us who care about system stability, it feels like a trap.&lt;/p&gt;
    &lt;p&gt;The advantage of stewardship is that it generates a different kind of capital: trust. When you have spent years delivering reliable tools, you earn the political capital to say ‚ÄúNo‚Äù to the spotlight when it threatens the product.&lt;/p&gt;
    &lt;p&gt;Recently, the spotlight has been on AI. Every team is under pressure to incorporate it. We have been asked repeatedly: ‚ÄúWhy don‚Äôt you integrate LLMs into Perfetto?‚Äù If I were optimizing for visibility, the answer would be obvious: build an LLM wrapper, demo it to leadership, and claim we are ‚ÄúAI-first.‚Äù It would be an easy win for my career.&lt;/p&gt;
    &lt;p&gt;But as a steward of the system, I know that one of Perfetto‚Äôs core values is precision. When a kernel developer is debugging a race condition, they need exact timestamps, not a hallucination. Users trust that when we tell them ‚ÄúX is the problem‚Äù that it actually is the problem and they‚Äôre not going to go chasing their tail for the next week, debugging an issue which doesn‚Äôt exist.&lt;/p&gt;
    &lt;p&gt;But it‚Äôs important not to take this too far: skepticism shouldn‚Äôt become obstructionism. With AI, it‚Äôs not ‚Äúno forever‚Äù but ‚Äúnot until it can be done right‚Äù 3.&lt;/p&gt;
    &lt;p&gt;A spotlight-seeking engineer might view this approach as a missed opportunity; I view it as protecting what makes our product great: user trust.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Alternate Currency of Impact&lt;/head&gt;
    &lt;p&gt;The most common fear engineers have about leaving the ‚ÄúSpotlight‚Äù is career stagnation. The logic goes: If I‚Äôm not launching flashy features at Google I/O, and my work isn‚Äôt on my VP‚Äôs top 5 list, how will I ever get promoted to Staff+?&lt;/p&gt;
    &lt;p&gt;It is true that you lose the currency of ‚ÄúExecutive Visibility.‚Äù But in infrastructure, you gain two alternate currencies that are just as valuable, and potentially more stable.&lt;/p&gt;
    &lt;p&gt;Shadow Hierarchy&lt;/p&gt;
    &lt;p&gt;In a product organization, you often need to impress your manager‚Äôs manager. In an infrastructure organization, you need to impress your customers‚Äô managers.&lt;/p&gt;
    &lt;p&gt;I call this the Shadow Hierarchy. You don‚Äôt need your VP to understand the intricacies of your code. You need the Staff+ Engineers in other critical organizations to need your tools.&lt;/p&gt;
    &lt;p&gt;When a Senior Staff Engineer in Pixel tells their VP, ‚ÄúWe literally cannot debug the next Pixel phone without Perfetto‚Äù, that statement carries immense weight. It travels up their reporting chain, crosses over at the Director/VP level, and comes back down to your manager.&lt;/p&gt;
    &lt;p&gt;This kind of advocacy is powerful because it is technical, not political. It is hard to fake. When you are a steward of a critical system, your promotion packet is filled with testimonials from the most respected engineers in the company saying, ‚ÄúThis person‚Äôs work enabled our success‚Äù.&lt;/p&gt;
    &lt;p&gt;Utility Ledger&lt;/p&gt;
    &lt;p&gt;While product teams might be poring over daily active users or revenue, we rely on metrics tracking engineering health:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Utility: Every bug fixed using our tools is an engineer finding us useful. It is the purest measure of utility.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Criticality: If the Pixel team uses Perfetto to debug a launch-blocking stutter, or Chrome uses it to fix a memory leak, our impact is implicitly tied to their success.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ubiquity: Capturing a significant percentage of the engineering population proves you‚Äôve created a technical ‚Äúlingua franca‚Äù. This becomes especially obvious when you see disconnected parts of the company collaborating with each other, using shared Perfetto traces as a ‚Äúreference everyone understands‚Äù.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Scale: Ingesting petabytes of data or processing billions of traces proves architectural resilience better than any design doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you combine Criticality (VIP teams need this) with Utility (bugs are being fixed), you create a promotion case that is immune to executive reorganizations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Archetypes and Agency&lt;/head&gt;
    &lt;p&gt;Staff Archetypes&lt;/p&gt;
    &lt;p&gt;I am far from the first to notice the idea of ‚Äúthere are multiple ways to be a staff software engineer‚Äù. In his book Staff Engineer, Will Larson categorizes Staff-plus engineers into four distinct archetypes.&lt;/p&gt;
    &lt;p&gt;Sean describes the Solver or the Right Hand: engineers who act as agents of executive will, dropping into fires and moving on once the problem is stabilized. I am describing the Architect or the Tech Lead: roles defined by long-term ownership of a specific domain and deep technical context.&lt;/p&gt;
    &lt;p&gt;The ‚ÄúLuck‚Äù Rebuttal&lt;/p&gt;
    &lt;p&gt;I can hear the criticism already: ‚ÄúYou just got lucky finding your team. Most of us don‚Äôt have that luxury.‚Äù&lt;/p&gt;
    &lt;p&gt;There are two caveats to all my advice in this post. First, the strategy I have employed so far requires a company profitable enough to sustain long-term infrastructure. This path generally does not exist in startups or early growth companies; it is optimized for Big Tech.&lt;/p&gt;
    &lt;p&gt;Second, luck does play a role in landing on a good team. It is very hard to accurately evaluate team and company culture from the outside. But while finding the team might have involved luck, staying there for almost a decade was a choice.&lt;/p&gt;
    &lt;p&gt;And, at least in my experience, my team is not particularly special: I can name five other teams in Android alone 4. Sure, they might have a director change here or a VP change there, but the core mission and the engineering team remained stable.&lt;/p&gt;
    &lt;p&gt;The reason these teams seem rare is not that they don‚Äôt exist, but that they are often ignored. Because they don‚Äôt offer the rapid, visible ‚Äúwins‚Äù of a product launch nor are they working on the ‚Äúshiny cool features‚Äù, they attract less competition. If you are motivated by ‚Äúshipping to billions of users‚Äù or seeing your friends and family use something you built, you won‚Äôt find that satisfaction here. That is the price of admission.&lt;/p&gt;
    &lt;p&gt;But if you want to build long-term systems and are willing to trade external validation for deep technical ownership, you just need to look behind the curtain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The tech industry loves to tell you to move fast. But there is another path. It is a path where leverage comes from depth, patience, and the quiet satisfaction of building the foundation that others stand on.&lt;/p&gt;
    &lt;p&gt;You don‚Äôt have to chase the spotlight to have a meaningful, high-impact career at a big company. Sometimes, the most ambitious thing you can do is stay put, dig in, and build something that lasts. To sit with a problem space for years until you understand it well enough to build a Bigtrace.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;By product team I don‚Äôt mean ‚Äúfrontend team‚Äù: even as a backend engineer, you are still working on some part of what is being served directly to end users. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is not exhaustive, Perfetto is open source and we do also care about external developers but that‚Äôs not why we get paid. From the company perspective, time we spent on open source bugs is ‚Äúwasted‚Äù time but we do it because we believe in the mission of open source. I talked about this more in a recent post, On Perfetto, Open Source, and Company Priorities. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For what it‚Äôs worth, LLMs might not even be the best solution to ‚Äúlet‚Äôs put AI into Perfetto‚Äù: in my opinion there is lots of value with ‚Äúold school‚Äù machine learning techniques like neural networks. A lot of trace analysis is just pattern matching. This is something I‚Äôm hoping to explore more in the coming year! ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Android Kernel, Android System Health, Android Runtime, Android Camera HAL, Android Bionic ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146451</guid><pubDate>Thu, 04 Dec 2025 11:36:36 +0000</pubDate></item><item><title>Japanese Four-Cylinder Engine Is So Reliable Still in Production After 25 Years</title><link>https://www.topspeed.com/reliable-japanese-four-cylinder-engine-still-in-production/</link><description>&lt;doc fingerprint="185ee55c87288786"&gt;
  &lt;main&gt;
    &lt;p&gt;The Honda K series engine is arguably the most renowned drivetrain in the Japanese automotive community, and for good reason. Honda's compact four-cylinder engine has consistently managed to balance performance, reliability, and efficiency, making it a popular option among many enthusiasts, especially those in the tuning world. Beyond its street appeal, Honda prioritizes this engine for multiple applications across its ICE and HEV lines.&lt;/p&gt;
    &lt;head rend="h6"&gt;Available Models&lt;/head&gt;
    &lt;head rend="h5"&gt;Honda&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Founded&lt;/item&gt;
      &lt;item rend="dd-1"&gt;24 September 1948&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Founder&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Soichiro Honda&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Headquarters&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Hamamatsu, Japan&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Owned By&lt;/item&gt;
      &lt;item rend="dd-4"&gt;Publicly Traded&lt;/item&gt;
      &lt;item rend="dt-5"&gt;Current CEO&lt;/item&gt;
      &lt;item rend="dd-5"&gt;Toshihiro Mibe&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most brands have committed to phasing the ICE out in favor of electrification, but Honda remains committed to its gasoline-driven powertrains, with the K-Series being the star of its future strategy. It's a well-rounded and balanced configuration that the Japanese brand has built with longevity in mind, which is why it's still going strong after almost 25 years.&lt;/p&gt;
    &lt;head rend="h2"&gt;How The K-Series Came To Be&lt;/head&gt;
    &lt;p&gt;Honda created the first-generation K series engine in 2001 as an official replacement for the aging but highly successful B and H series families in a bid to meet tighter emissions rules while increasing thermal efficiency and real-world flexibility. Honda engineers focused on a clean sheet aluminum block with a deep skirt layout that increased rigidity and supported higher operating speeds without unwanted vibration. They also applied a forged crankshaft and lightweight pistons to cut reciprocating mass and improve throttle response.&lt;/p&gt;
    &lt;p&gt;Replacing the old belt-driven system is a modern chain-driven dual overhead camshaft setup that allows for a more accurate timing control under high load conditions. The advanced i-VTEC system is the cornerstone of the K-Series, blending variable valve timing, with variable lift control, and variable cam phasing. This system gives the engine a wide torque spread at low and mid-RPM and allows strong breathing at higher RPM without the sharp changeover, compared to how the older VTEC systems operate.&lt;/p&gt;
    &lt;p&gt;Honda also rotated the engine orientation compared to the B series family, allowing the configuration to pack the intake and exhaust layout more efficiently. This results in improved airflow and easier service access. The engineers designed a tall intake plenum with long runners that improved cylinder filling during everyday driving, and paired it with a free-flowing exhaust manifold that supported consistent scavenging.&lt;/p&gt;
    &lt;p&gt;The K series also introduced coil-on-plug ignition and a modern electronic throttle, helping the engine management system fine-tune spark and airflow for better drivability and fuel control. Honda debuted the first K-Series K20A in the JDM-exclusive 2001 Honda Stream. This was an ideal compact platform to showcase the new engine architecture before rolling it out to performance models like the Integra Type R and mainstream options like the Civic and Accord. Edmunds consumer reviews of these models consistently award K-Series-powered models with high ratings for maintenance and reliability.&lt;/p&gt;
    &lt;head rend="h5"&gt;The Honda Civic You Forgot About That Paved The Way For The Type R&lt;/head&gt;
    &lt;p&gt;This was the first-ever Honda Civic to come with the famed B16A VTEC engine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setting A New Standard With The K20C&lt;/head&gt;
    &lt;p&gt;The K20C is Honda's current-generation of the K-Series range, upgraded to deliver strong real-world efficiency and long-term reliability across the Honda and Acura catalogs. It's also a redesign that meets stricter global emissions rules and tighter thermal demands that come with modern turbocharging.&lt;/p&gt;
    &lt;p&gt;Key design elements include a reinforced aluminum block that features a closed deck layout, improving cylinder stability under higher combustion pressure, and keeps distortion under control during long and high load cycles. The system also adopts a low-friction rotating assembly with coated pistons and well-balanced rods that reduce heat buildup and wear. The direct injection system used precise multi-hole injectors that improved atomization and allowed cleaner combustion, raising efficiency, and reducing soot formation inside the chambers.&lt;/p&gt;
    &lt;p&gt;The engineers shape the cylinder head ports through extensive fluid modeling, creating fast and consistent airflow at lower boost pressures. The turbo layout is also intentional, consisting of a compact low-inertia unit that produces quick spooling without heavy thermal strain. The cooling circuit routes coolant through critical areas to stabilize temperature during demanding driving. Honda uses a high-flow intercooling unit to keep intake temperatures low, improve knock resistance, and protect the engine during long climbs or sustained highway use.&lt;/p&gt;
    &lt;p&gt;The K20C design also incorporates integrated exhaust passages within the head, shortening the distance from the valves to the turbine and reducing unnecessary heat loss. This improves turbo response and emissions control. Honda tunes the valve timing system to prioritize mid-range torque and real-world drivability, instead of chasing peak numbers. In doing so, the powertrain benefits from reduced stress on internal components. The company validates the design through endurance testing that included extended full load sessions and wide temperature swings. Honda and Acura models that use the K20C benefit from predictable behavior, low maintenance demands, and consistent efficiency because the engine handles high-pressure turbo operation without unusual wear, and it keeps its performance stable over long ownership cycles.&lt;/p&gt;
    &lt;head rend="h5"&gt;How Much A Fully Loaded Honda Civic Type R Costs&lt;/head&gt;
    &lt;p&gt;The new Honda Civic Type R costs a heavy penny. Here's a breakdown of where every dollar goes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proven Potential On Track&lt;/head&gt;
    &lt;p&gt;Honda pushed the first-generation K series engine into manufacturer-backed racing as soon as it proved its durability on the road. The Japanese company's racing division applied the unit as a core part of its return to high-level touring car competition. The engineers developed racing versions of the K20 that kept the production block and head architecture but used reinforced internals, stronger valve springs, revised cam profiles, and higher flow intake and exhaust systems to withstand extended high RPM use.&lt;/p&gt;
    &lt;p&gt;Honda built these engines for series such as the Japanese Super Taikyu Championship, the British Touring Car Championship, and various regional touring car categories where regulations encouraged production-based units. The K20-powered Civic race cars delivered strong pace because the engine breathed well at sustained RPM and held peak output without overheating or losing consistency during long stints.&lt;/p&gt;
    &lt;p&gt;Teams appreciated the stable thermal behavior because Honda used a rigid block design and efficient water and oil channels that kept temperatures predictable under heavy load. Drivers reported sharp throttle response, which helped them control rotation mid-corner and fire out of slow bends with confidence. The wide operating range that came from the advanced i-VTEC system let engineers tailor cam timing for specific tracks, which improved flexibility during setup and reduced the need for constant gear changes.&lt;/p&gt;
    &lt;p&gt;The engine also proved extremely reliable during endurance events where many rivals needed mid-season rebuilds, while K-series units often completed full campaigns with only scheduled maintenance. Honda leveraged this record to promote the K series as a modern performance base, and the company used racing feedback to refine production variants for later models. The engine delivered a strong mix of durability, rev capability, and tuning headroom, establishing it as a respected package in manufacturer-supported racing programs, and independent teams quickly adopted it for club-level and regional championships.&lt;/p&gt;
    &lt;head rend="h5"&gt;These Are The First 10 Production Cars In History With Factory Turbochargers&lt;/head&gt;
    &lt;p&gt;We may love a good turbo today, but they had to start somewhere - here are the first 10 production cars to boast a turbocharged engine under the hood.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why The K-Series Is Here To Stay&lt;/head&gt;
    &lt;p&gt;Honda continues to use the K series engine family because the architecture supports modern efficiency targets, strong durability expectations, and flexible integration with hybrid systems, which gives the company a stable foundation for future models across global segments. Honda engineers designed the K layout with a rigid aluminum block, efficient cooling circuits, and low-friction internals, which gives them room to meet tougher emissions rules without redesigning the core structure.&lt;/p&gt;
    &lt;p&gt;The engine handles high compression ratios, turbocharging, and extended thermal loads with consistent reliability, which helps Honda control warranty exposure and maintain brand trust. The K platform also scales well because Honda can adjust bore and stroke dimensions of intake and exhaust routing, and combustion chamber design to match everything from compact cars to performance-oriented Acura models without creating incompatible parts.&lt;/p&gt;
    &lt;p&gt;Honda doesn't currently apply its K Series engine to its hybrid portfolio, but this is a factor that can easily change as the brand takes a more aggressive approach to hybridization. Although unconfirmed, it has already expressed a desire to electrify the likes of future Civic Type R and Integra Type S models. The engine supports efficient Atkinson cycle tuning for hybrid configurations, which boosts fuel economy without harming long-term durability. Honda also values the deep supply chain that supports K series production because it reduces cost and improves manufacturing consistency across multiple regions.&lt;/p&gt;
    &lt;p&gt;The engine responds well to continuous improvement, so Honda updates injectors, turbo hardware, valve timing control, and cooling strategies without major structural changes. This approach helps Honda limit development time while raising efficiency and performance for each new generation. Engineers also appreciate the serviceability of the layout because it simplifies maintenance for dealers and reduces ownership cost for owners. Ultimately, the L-Series will be the cornerstone of its future strategies, as it has proven to be a better fit for both hybridization and turbocharging, but the K range's impressive performance abilities, resilience, and market appeal makes it too good an engine for the brand to just ignore.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sources: MotorTrend, RepairPal, Kelley Blue Book, and Edmunds&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146740</guid><pubDate>Thu, 04 Dec 2025 12:09:43 +0000</pubDate></item><item><title>Functional Quadtrees</title><link>https://lbjgruppen.com/en/posts/functional-quadtree-clojure</link><description>&lt;doc fingerprint="4cfaac21040e533b"&gt;
  &lt;main&gt;
    &lt;p&gt;1.12.2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Functional Quadtrees&lt;/head&gt;
    &lt;p&gt;A Quadtree is a tree data structure, which is useful for giving more focus/detail to certain regions of your data, while saving resources elsewhere. I could only find a couple tutorials/guides and both were imperative, so I figured it'd be fun to do a functional version in Clojure which runs in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;A demo&lt;/head&gt;
    &lt;p&gt;In this blogpost I'll show you how to build both a functional Quadtree and the visualization you see below. Imagine the canvas to be a top-view of map and your mouse-position to be the spot you're occupying on the map. Near you, you want crisp details, small cells of high resolution. The further away we get from you/the camera (your mouse-position), the less we care about details.&lt;/p&gt;
    &lt;p&gt;Be aware that on mobile, you have to click at the spot you want to simulate the cameras position. I recommend you view this on a desktop system with a mouse, where the simulation reacts to the mouse position in real time.&lt;/p&gt;
    &lt;head rend="h2"&gt;The recursive approach&lt;/head&gt;
    &lt;p&gt;It's hard to find any tutorials on how to build a general purpose Quadtree, but the 2 I did find both took the imperative approach, ie. editing directly on each node. Nothing wrong with that approach, it can be blazingly fast but it does leave you with the housekeeping, ie. downscaling nodes that are no longer close to the camera. I'd much prefer a declarative definition that rebuilds the entire tree in sub-milliseconds, so let's make that happen.&lt;/p&gt;
    &lt;p&gt;In this implementation, I want to show a very general functional approach and goes like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read a camera (player,mouse,focus-point,whatever) position&lt;/item&gt;
      &lt;item&gt;Test if the current node is optimally sized&lt;/item&gt;
      &lt;item&gt;If not, split into 4 children, goto 2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Optimally sized in this case is just "Am I too far away from the edge of the node" ? If the distance is greater than some threshold, let's say the width of the node, then we split.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our data model&lt;/head&gt;
    &lt;p&gt;Depending on your use-case, you can fit as much information as you want into this model. If you're doing some kind of 3D rendering, you might want to keep tabs on neighbor-relations, &lt;/p&gt;
    &lt;code&gt;(defn qtree
  " Instantiates a tree node "
  [[x1 y1 x2 y2]]
  {:root?   false
   :bounds  [x1 y1 x2 y2]
   :center  (mapv #(js/Math.floor %)
                  [(half x2 x1)
                   (half y2 y1)])
   :width   (- x2 x1)})&lt;/code&gt;
    &lt;p&gt;In fact we strictly speaking, don't need the center/width stored, but it does make life a bit easier.&lt;/p&gt;
    &lt;p&gt;Given a root node and a camera-position we can determine if we want to split or not, simply by testing the distance from the camera to the center:&lt;/p&gt;
    &lt;code&gt;(defn distance
  [[x1 y1] [x2 y2]]
  (js/Math.sqrt
   (+ (js/Math.pow (- x2 x1) 2)
      (js/Math.pow (- y2 y1) 2))))

(defn too-close?
  " Determines if the camera is closer than halfway to
    the edge of a node "
  [ node camera ]
  (&amp;lt; (distance camera (:center node))
     (:width node)))

(defn split?
  [ node camera ]
  (and (too-close? node camera)
       (&amp;gt; (:width node) _Q_MINIMUM_SIZE)))
&lt;/code&gt;
    &lt;p&gt;That final check on the width of the node, essentially allow us to recurse until we can't split anymore. In Clojure we have 2 very powerful idioms for walking a tree structure: Postwalk and Prewalk.&lt;/p&gt;
    &lt;p&gt;Postwalk is a depth-first, post-order walk of the tree which applies some arbitrary function to each element.&lt;/p&gt;
    &lt;code&gt;(w/postwalk (fn [e]
                (prn "Looking at: " e)
                e)
            {:rootval 1
            :node1 {:data "foo"
            :vec  [1 2 3]}})
"Looking at: " :rootval
"Looking at: " 1
"Looking at: " [:rootval 1]
"Looking at: " :node1
"Looking at: " :data
"Looking at: " "foo"
"Looking at: " [:data "foo"]
"Looking at: " :vec
"Looking at: " 1
"Looking at: " 2
"Looking at: " 3
"Looking at: " [1 2 3]
"Looking at: " [:vec [1 2 3]]
"Looking at: " {:data "foo", :vec [1 2 3]}
"Looking at: " [:node1 {:data "foo", :vec [1 2 3]}]
"Looking at: " {:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}
{:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}&lt;/code&gt;
    &lt;p&gt;I hope this is an intuitive way to see the path postwalk takes. The function only prints what it sees and then returns it as is, thus the end result is exactly the map we started out with. Notice how we first see the root key, then its value, then both together as a MapEntry, then it goes deeper into the tree.&lt;/p&gt;
    &lt;p&gt;Now compare that with prewalk:&lt;/p&gt;
    &lt;code&gt;(w/prewalk (fn [e]
               (prn "Looking at: " e)
               e)
           {:rootval 1
           :node1 {:data "foo"
           :vec  [1 2 3]}})
"Looking at: " {:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}
"Looking at: " [:rootval 1]
"Looking at: " :rootval
"Looking at: " 1
"Looking at: " [:node1 {:data "foo", :vec [1 2 3]}]
"Looking at: " :node1
"Looking at: " {:data "foo", :vec [1 2 3]}
"Looking at: " [:data "foo"]
"Looking at: " :data
"Looking at: " "foo"
"Looking at: " [:vec [1 2 3]]
"Looking at: " :vec
"Looking at: " [1 2 3]
"Looking at: " 1
"Looking at: " 2
"Looking at: " 3
{:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}&lt;/code&gt;
    &lt;p&gt;Prewalk examines the same elements and in the same way, but the path is what we call a pre-order traversal, which means you see contents of nodes before the elements - And by implication, you can swap those nodes and then visit the elements. All in all, prewalk makes for a very simple recursive pattern:&lt;/p&gt;
    &lt;code&gt;(w/prewalk
 (fn [n]
     (if (and (map? n) (split? n [x y]))
         (subdivide n)
       n))
 qtree)&lt;/code&gt;
    &lt;p&gt;Yes, it's really that simple. Given a root-node and a camera-position (x,y), this will recursively resolve all children to the maximum resolution.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Visualization&lt;/head&gt;
    &lt;p&gt;If you want to read ahead, I've shared a repo here: Github&lt;/p&gt;
    &lt;p&gt;The code should run straight out of the box and open a webinterface on port 8020. Shadow-cljs makes light work of compiling anything from a single file to a huge frontend application, into a single JS file.&lt;/p&gt;
    &lt;p&gt;Running in a browser we get a nice 2D API from the standard canvas element. Basically, to draw our Quadtree we need only 3 things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Quadtree&lt;/item&gt;
      &lt;item&gt;A function which draws a node&lt;/item&gt;
      &lt;item&gt;A function which draws all children&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you've probably guessed, the Quadtree itself is just a simple map with some keys. But because this is a realtime visualization, I want to create a connection between whichever tree I generated and what's drawn on screen. Fortunately both Clojure and Clojurescript support both atoms and watches:&lt;/p&gt;
    &lt;code&gt;(def quadInst (atom nil))

(add-watch quadInst :updateQuads
           (fn [_ _ old-tree new-tree]
             (draw-all new-tree)))&lt;/code&gt;
    &lt;p&gt;By convention in Clojure, we name arguments underscore (_) if we do not care about them. In this case, I only need the new-tree for the visualization. If you're not a native Clojurian you might find this pattern appealing as it gives you access to both the pre-updated version and the updated tree, meaning you can run diffs, add new children to a scene while removing others.&lt;/p&gt;
    &lt;p&gt;I mention it here for demonstration purposes only, in the latest commit you'll see I actually remove all atoms and demonstrate a 100% pure functional solution without atoms. However for the purpose of explaining Quadtree this is a simple subscription-pattern which most developers will recognize. It ensures that whenever the atom Quadtree is updated, so is the screen.&lt;/p&gt;
    &lt;code&gt;(defn draw-all
  [ tree ]
  (draw (:root? tree)
        tree
        (get-tree-color tree))
  (when-let [children (:children tree)]
    (doseq [c children]
      (draw-all c))))&lt;/code&gt;
    &lt;p&gt;However there's a fun detail here. To make it seem fairly consistent I couldn't just use random colors, that would make the entire screen flicker whenever you moved the mouse. Basically, if I have a rectangle centered at 50,50 - I always want it to have the same color. A really neat and simple trick is the 32bit hash, which is succinctly implemented in javascript like so:&lt;/p&gt;
    &lt;code&gt;function fastHash(str) {
    let hash = 0;
    for (let i = 0; i &amp;lt; str.length; i++) {
        hash = (hash &amp;lt;&amp;lt; 5) - hash + str.charCodeAt(i); // Hash computation
        hash |= 0; // Convert to 32bit integer
    }
    return hash &amp;gt;&amp;gt;&amp;gt; 0; // Ensure the result is unsigned
}&lt;/code&gt;
    &lt;p&gt;Basically my idea is to hash the center, ie "[50,50]" and convert that to a hex color. In Clojurescript, you could do it like so:&lt;/p&gt;
    &lt;code&gt;(defn hash-str
  " Standard 32bit hash: [..].map((% &amp;lt;&amp;lt; 5) - h + ch(idx) "
  [ s ]
  (reduce #(-&amp;gt; (bit-shift-left %1 5)
               (- %1)
               (+ (.charCodeAt %2 0))
               (bit-or 0))
          0 s))

(defn get-tree-color
  [ {c :center} ]
  (let [hash (bit-and (hash-str (str c)) 0xffffff)
        hex  (.toString hash 16)]
    (str "#" (apply str (repeat (- 6 (count hex)) "0")) hex)))&lt;/code&gt;
    &lt;p&gt;That's basically all you need.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Quadtrees are great when you have more work to do, than resources available. Imagine using a VR headset. Whichever point you're focused at, needs to be crisp in detail, you want the highest resolution possible on your hardware. Everything outside of your focus area should be dialed down in resolution because your eyes won't be able to pick it up anyway, so that compute power can be used elsewhere. There are many other applications.&lt;/p&gt;
    &lt;p&gt;Clojurescript is great, because it allows us to express ourselves succinctly and functionally. The core of this implementation is only about 25 lines long. That's much easier to reason about and debug, than some other implementations I've seen, which span several hundred lines.&lt;/p&gt;
    &lt;p&gt;Shadow-cljs is great for more reasons than I can cover in this post, but I will highlight the ability to quickly ship highly optimized bit of JS using only 10 lines of configuration - And they even throw in a free webserver for easy testing and repl driven development, what's not to like?&lt;/p&gt;
    &lt;p&gt;Full source code: Github&lt;/p&gt;
    &lt;p&gt;Lau B. Jensen&lt;/p&gt;
    &lt;p&gt;Lau is a seasoned Danish software developer and consultant with over 15 years of experience in backend systems, web development, and functional programming using Lisp and Clojure. Since 2007, he has co-founded and scaled multiple successful startups while navigating the venture capital landscape. Lau combines deep technical expertise with entrepreneurial insight, delivering robust, scalable solutions tailored to business needs. Creative, driven, and results-/quality oriented, he thrives turning bold ideas into reality.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147341</guid><pubDate>Thu, 04 Dec 2025 13:18:38 +0000</pubDate></item><item><title>RAM is so expensive, Samsung won't even sell it to Samsung</title><link>https://www.pcworld.com/article/2998935/ram-is-so-expensive-samsung-wont-even-sell-it-to-samsung.html</link><description>&lt;doc fingerprint="bb7aac81a5b6d3e8"&gt;
  &lt;main&gt;
    &lt;p&gt;The price of eggs has nothing on the price of computer memory right now. Thanks to a supply crunch from the ‚ÄúAI‚Äù bubble, RAM chips are the new gold, with prices on consumer PC memory kits ballooning out of control. In an object lesson in the ridiculousness of an economic bubble, Samsung won‚Äôt even sell its memory to‚Ä¶ Samsung.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs the situation. Samsung makes everything from refrigerators to supermassive oil tankers. Getting all that stuff made requires an organization that‚Äôs literally dozens of affiliated companies and subsidiaries, which don‚Äôt necessarily work as closely or harmoniously as you might assume. For this story, we‚Äôre talking about Samsung Electronics, which makes Galaxy phones, tablets, laptops, watches, etc., and Samsung Semiconductor Global, which manufactures memory and other chips and supplies the global market. That global market includes both Samsung subsidiaries and their competitors‚Äîlaptops from Samsung, Dell, and Lenovo sitting on a Best Buy store shelf might all have Samsung-manufactured memory sitting in their RAM slots.&lt;/p&gt;
    &lt;p&gt;Samsung subsidiaries are, naturally, going to look to Samsung Semiconductor first when they need parts. Such was reportedly the case for Samsung Electronics, in search of memory supplies for its newest smartphones as the company ramps up production for 2026 flagship designs. But with so much RAM hardware going into new ‚ÄúAI‚Äù data centers‚Äîand those companies willing to pay top dollar for their hardware‚Äîmemory manufacturers like Samsung, SK Hynix, and Micron are prioritizing data center suppliers to maximize profits.&lt;/p&gt;
    &lt;p&gt;The end result, according to a report from SE Daily spotted by SamMobile, is that Samsung Semiconductor rejected the original order for smartphone DRAM chips from Samsung Electronics‚Äô Mobile Experience division. The smartphone manufacturing arm of the company had hoped to nail down pricing and supply for another year. But reports say that due to ‚Äúchipflation,‚Äù the phone-making division must renegotiate quarterly, with a long-term supply deal rejected by its corporate sibling. A short-term deal, with higher prices, was reportedly hammered out.&lt;/p&gt;
    &lt;p&gt;Assuming that this information is accurate‚Äîand to be clear, we can‚Äôt independently confirm it‚Äîconsumers will see prices rise for Samsung phones and other mobile hardware. But that‚Äôs hardly a surprise. Finished electronics probably won‚Äôt see the same meteoric rise in prices as consumer-grade RAM modules, but this rising tide is flooding all the boats. Raspberry Pi, which strives to keep its mod-friendly electronics as cheap as possible, has recently had to bring prices up and called out memory costs as the culprit. Lenovo, the world‚Äôs largest PC manufacturer, is stockpiling memory supplies as a bulwark against the market.&lt;/p&gt;
    &lt;p&gt;But if you‚Äôre hoping to see prices lower in 2026, don‚Äôt hold your breath. According to a forecast from memory supplier TeamGroup, component prices have tripled recently, causing finished modules to jump in prices as quickly as 100 percent in a month. Absent some kind of disastrous market collapse, prices are expected to continue rising into next year, and supply could remain constrained well into 2027 or later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147353</guid><pubDate>Thu, 04 Dec 2025 13:20:07 +0000</pubDate></item><item><title>Human hair grows through 'pulling' not pushing, study shows</title><link>https://phys.org/news/2025-12-human-hair.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147371</guid><pubDate>Thu, 04 Dec 2025 13:22:35 +0000</pubDate></item><item><title>Transparent Leadership Beats Servant Leadership</title><link>https://entropicthoughts.com/transparent-leadership-beats-servant-leadership</link><description>&lt;doc fingerprint="bce3d0111682d491"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Transparent Leadership Beats Servant Leadership&lt;/head&gt;
    &lt;p&gt;tl:dr: Parenting and leadership is similar. Teach a man to fish, etc.&lt;/p&gt;
    &lt;p&gt;I spent a couple of years managing a team, and I entered that role ‚Äì like many ‚Äì without knowing anything about how to do it. I tried to figure out how to be a good manager, and doing so I ended up reading a lot about servant leadership. It never quite sat right with me, though. Servant leadership seems to me a lot like curling parenting: the leader/parent anticipate problems and sweep the way for their direct reports/children.&lt;/p&gt;
    &lt;p&gt;To be clear, this probably feels very good (initially, anyway) for the direct reports/children. But the servant leader/curling parent quickly becomes an overworked single point of failure, and once they leave there is nobody else who knows how to handle the obstacles the leader moved out of the way for everyone. In the worst cases, they leave behind a group of people who have been completely isolated from the rest of the organisation, and has no idea what their purpose is and how to fit in with the rest of the world.&lt;/p&gt;
    &lt;p&gt;I would like to invent my own buzzword: transparent leadership. In my book, a good leader&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;coaches people,&lt;/item&gt;
      &lt;item&gt;connects people,&lt;/item&gt;
      &lt;item&gt;teaches people methodical problem solving,&lt;/item&gt;
      &lt;item&gt;explains values and principles embraced by the organisation to aid them in making aligned decisions on their own,&lt;/item&gt;
      &lt;item&gt;creates direct links between supply and demand (instead of deliberately making themselves a middle man),&lt;/item&gt;
      &lt;item&gt;allows their direct reports career growth by gradually taking over leadership responsibilities,&lt;/item&gt;
      &lt;item&gt;continuously trains their replacement, and&lt;/item&gt;
      &lt;item&gt;generally makes themselves redundant.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The middle manager that doesn‚Äôt perform any useful work is a fun stereotype, but I also think it‚Äôs a good target to aim for. The difference lies in what to do once one has rendered oneself redundant. A common response is to invent new work, ask for status reports, and add bureaucracy.&lt;/p&gt;
    &lt;p&gt;A better response is to go back to working on technical problems. This keeps the manager‚Äôs skills fresh and gets them more respect from their reports. The manager should turn into a high-powered spare worker, rather than a paper-shuffler.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147540</guid><pubDate>Thu, 04 Dec 2025 13:40:00 +0000</pubDate></item><item><title>Show HN: OnlyRecipe 2.0 ‚Äì I added all features HN requested ‚Äì 4 years later</title><link>https://onlyrecipeapp.com/?url=https://www.allrecipes.com/turkish-pasta-recipe-8754903</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148460</guid><pubDate>Thu, 04 Dec 2025 15:06:08 +0000</pubDate></item><item><title>Proxmox Datacenter Manager 1.0 available</title><link>https://www.proxmox.com/en/about/company-details/press-releases/proxmox-datacenter-manager-1-0</link><description>&lt;doc fingerprint="3f5580e4cbb4800"&gt;
  &lt;main&gt;
    &lt;p&gt;VIENNA, Austria ‚Äì December 04, 2025 ‚ÄìEnterprise software developer Proxmox Server Solutions GmbH (henceforth ‚ÄúProxmox‚Äù) today announced the immediate availability of the stable version 1.0 of Proxmox Datacenter Manager. This new product directly addresses the increasing complexity of operating distributed and large-scaled Proxmox-based environments. Proxmox Datacenter Manager offers a holistic single pane of glass view for the administration, monitoring, and scaling of Proxmox VE and Proxmox Backup Server, with the primary goal of providing administrators with comprehensive and seamless control.&lt;/p&gt;
    &lt;p&gt;Managing growing data centers, distributed across multiple locations or clusters, consistently presents major challenges for enterprises and teams. A lack of global oversight, fragmented metrics, and the need to perform complex operations manually across various environments can quickly lead to inefficiencies and increased error susceptibility.&lt;/p&gt;
    &lt;p&gt;Proxmox Datacenter Manager was developed as the strategic answer to this scaling challenge. It bridges the gap between individual Proxmox-based nodes and clusters, providing a unified view of the entire infrastructure. This not only simplifies routine tasks but also enables advanced functionalities that were previously difficult to achieve.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights of Proxmox Datacenter Manager 1.0&lt;/head&gt;
    &lt;p&gt;Proxmox Datacenter Manager delivers a set of core functions specifically designed for managing complex, enterprise-grade environments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Centralized overview and metrics aggregation: Users can connect multiple Proxmox ‚Äúremotes‚Äù (nodes and clusters) and gain a real-time, consolidated overview from a single dashboard. The consolidated dashboard displays the global health status of all Proxmox VE clusters and Proxmox Backup Server instances. It aggregates critical resource usage, including CPU, RAM, and storage I/O, and provides an immediate view of critical key performance indicators (KPIs) and performance metrics to identify bottlenecks and potential issues early on. Data is cached locally, maintaining offline visibility of the last known state.&lt;/item&gt;
      &lt;item&gt;Dynamic, role-based custom views: With customizable dashboards, IT teams can create highly filtered, targeted overviews based on specific remotes, resource types, or operational tags. Crucially, the Proxmox Datacenter Manager leverages its native role-based access control (RBAC) to grant users access to these tailored views without providing direct access to the underlying virtual machines or hosts. This functionality ensures granular permission management and delivers need-to-know transparency across diverse teams and multi-tenant environments.&lt;/item&gt;
      &lt;item&gt;Multi-cluster management: Seamlessly connect to and manage independent Proxmox-based clusters and standalone nodes.&lt;/item&gt;
      &lt;item&gt;Cross-cluster live migration: One of the most prominent features is the capability for the live migration of VMs between different clusters. This empowers administrators to perform responsive load shifts and maintenance work without downtime.&lt;/item&gt;
      &lt;item&gt;Basic VM &amp;amp; container life-cycle management for virtual infrastructure: Routine administrative tasks such as starting, stopping, or configuring VMs, containers, and storage resources can be executed directly from the central interface. Further, with the included native Role-Based Access Control (RBAC), Proxmox Datacenter Manager allows to precisely manage user permissions and centralize task histories and logs to simplify auditing and meeting compliance requirements.&lt;/item&gt;
      &lt;item&gt;Powerful search functionality: Version 1.0 comes with a highly intuitive and powerful search functionality. Inspired by query languages like those used in Elasticsearch and GitHub, administrators can instantly filter and locate resources. Data can be filtered by resource type (remote, VM, container), status (stopped, running, etc.) or by custom tags, therefore ensuring that even in infrastructures managing thousands of virtual guests, critical resources and diagnostic data are found with unprecedented speed and precision.&lt;/item&gt;
      &lt;item&gt;Centralized SDN capabilities (EVPN): The platform features support for Software-Defined Networking (SDN), enabling the configuration of EVPN zones and VNets across multiple remotes from a single interface, simplifying complex network overlays and network administration in highly scaled environments.&lt;/item&gt;
      &lt;item&gt;Centralized update management: Proxmox Datacenter Manager introduces a central Update Management Panel that gives administrators an instant overview of all available updates across their entire Proxmox VE and Proxmox Backup Server infrastructure. Updates can be rolled out directly from the Datacenter Manager interface, simplifying patch management and strengthening the overall security posture. In addition, Datacenter Manager provides unified, secure shell access to all managed remotes from a single console.&lt;/item&gt;
      &lt;item&gt;Open-source software stack: Proxmox Datacenter Manager is based on Debian 13.2 ‚ÄúTrixie‚Äù, uses a newer Linux kernel version 6.17 as stable default, and includes ZFS 2.3. Furthermore, its core software stack is written in the high-performance Rust programming language, with a responsive user interface built upon the new Rust/Yew Proxmox UI framework, delivering enhanced speed and an optimal user experience.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;"The modern infrastructure landscape demands adaptability, from data centers to edge locations. Organizations need tools that evolve alongside their business. Proxmox Datacenter Manager is designed as a key building block within our expanding ecosystem, empowering customers with the right solution for every stage of their journey", says Tim Marx, COO at Proxmox. "By choosing the Proxmox ecosystem, organizations unlock a wide range of deployment options. From high-performance setups at hyperscalers to distributed branch offices that maintain data sovereignty. Our consistent commitment to openness ensures long-term interoperability and real freedom of choice for customers and partners."&lt;/p&gt;
    &lt;head rend="h3"&gt;Availability&lt;/head&gt;
    &lt;p&gt;Proxmox Datacenter Manager 1.0 is immediately available for download. Users can obtain a complete installation image via ISO download, which contains the full feature-set of the solution and can be installed quickly on bare-metal systems using an intuitive installation wizard.&lt;/p&gt;
    &lt;p&gt;Seamless distribution upgrades from older versions of Proxmox Datacenter Manager are possible using the standard APT package management system. Furthermore, it is also possible to install Proxmox Datacenter Manager on top of an existing Debian installation. As Free/Libre and Open Source Software (FLOSS), the entire solution is published under the GNU AGPLv3.&lt;/p&gt;
    &lt;p&gt;For enterprise users, Proxmox Server Solutions GmbH offers professional support through subscription plans. A subscription provides access to the stable Enterprise Repository with timely updates via the web interface, as well as to certified technical support and is recommended for production use. Customers with active Enterprise Support for their Proxmox remotes also gain access to Proxmox Datacenter Manager updates and support.&lt;/p&gt;
    &lt;p&gt;Resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ISO Image Download: https://www.proxmox.com/en/downloads&lt;/item&gt;
      &lt;item&gt;Forum Announcement: https://forum.proxmox.com/&lt;/item&gt;
      &lt;item&gt;Roadmap: For published and upcoming features, see the Release Notes &amp;amp; Documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;###&lt;/p&gt;
    &lt;p&gt;About Proxmox Server Solutions&lt;lb/&gt;Proxmox provides powerful and user-friendly open-source server software. Enterprises of all sizes and industries use the Proxmox solutions to deploy efficient and simplified IT infrastructures, minimize total cost of ownership, and avoid vendor lock-in. Proxmox also offers commercial support, training services, and an extensive partner ecosystem to ensure business continuity for its customers. Proxmox Server Solutions GmbH was established in 2005 and is headquartered in Vienna, Austria.&lt;/p&gt;
    &lt;p&gt;Contact: Daniela H√§sler, Proxmox Server Solutions GmbH, marketing@proxmox.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148744</guid><pubDate>Thu, 04 Dec 2025 15:31:12 +0000</pubDate></item><item><title>Microsoft drops AI sales targets in half after salespeople miss their quotas</title><link>https://arstechnica.com/ai/2025/12/microsoft-slashes-ai-sales-growth-targets-as-customers-resist-unproven-agents/</link><description>&lt;doc fingerprint="af740a1914faa081"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft has lowered sales growth targets for its AI agent products after many salespeople missed their quotas in the fiscal year ending in June, according to a report Wednesday from The Information. The adjustment is reportedly unusual for Microsoft, and it comes after the company missed a number of ambitious sales goals for its AI offerings.&lt;/p&gt;
    &lt;p&gt;AI agents are specialized implementations of AI language models designed to perform multistep tasks autonomously rather than simply responding to single prompts. So-called ‚Äúagentic‚Äù features have been central to Microsoft‚Äôs 2025 sales pitch: At its Build conference in May, the company declared that it has entered ‚Äúthe era of AI agents.‚Äù&lt;/p&gt;
    &lt;p&gt;The company has promised customers that agents could automate complex tasks, such as generating dashboards from sales data or writing customer reports. At its Ignite conference in November, Microsoft announced new features like Word, Excel, and PowerPoint agents in Microsoft 365 Copilot, along with tools for building and deploying agents through Azure AI Foundry and Copilot Studio. But as the year draws to a close, that promise has proven harder to deliver than the company expected.&lt;/p&gt;
    &lt;p&gt;According to The Information, one US Azure sales unit set quotas for salespeople to increase customer spending on a product called Foundry, which helps customers develop AI applications, by 50 percent. Less than a fifth of salespeople in that unit met their Foundry sales growth targets. In July, Microsoft lowered those targets to roughly 25 percent growth for the current fiscal year. In another US Azure unit, most salespeople failed to meet an earlier quota to double Foundry sales, and Microsoft cut their quotas to 50 percent for the current fiscal year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148748</guid><pubDate>Thu, 04 Dec 2025 15:31:52 +0000</pubDate></item><item><title>Bootloader Unlock Wall of Shame</title><link>https://github.com/zenfyrdev/bootloader-unlock-wall-of-shame</link><description>&lt;doc fingerprint="b7c1c9df8ea3b9e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Keeping track of companies that "care about your data ü•∫"&lt;/p&gt;
    &lt;head&gt;mirrors&lt;/head&gt;
    &lt;p&gt;Over the past few years, a suspicious number of companies have started to "take care of your data", aka block/strictly limit your ability to unlock the bootloader on your own devices.&lt;/p&gt;
    &lt;p&gt;While this may not affect you directly, it sets a bad precedent. You never know what will get the axe next: Shizuku? ADB?&lt;lb/&gt; They've already gone after sideloading.&lt;lb/&gt; I thought it might be a good idea to keep track of bad companies and workarounds.&lt;/p&gt;
    &lt;p&gt;If you know of specific details/unlocking methods, please PR them or drop them in the discussions&lt;/p&gt;
    &lt;p&gt;Caution&lt;/p&gt;
    &lt;p&gt;Reminder that no matter how nice a company is, &lt;lb/&gt; you should not trust them unless their unlock process is 100% offline!&lt;/p&gt;
    &lt;p&gt;The following manufacturers have made it completely impossible to unlock their devices without a workaround.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Phone brands handle carrier locks differently, so check your device manual or contact support.&lt;/p&gt;
    &lt;p&gt;Carrier locked devices are the ones you get after making a commitment with a carrier of your choice. This is quite common in North America and (supposedly) allows you to save some money on your device.&lt;/p&gt;
    &lt;p&gt;As a rule, almost all carrier locked devices do not allow the bootloader to be unlocked. This usually makes sense, as it would allow you to completely bypass the contract. The problem is that many devices still do not allow you to unlock the bootloader even after the carrier lock has been lifted. For more details, see the carriers page.&lt;/p&gt;
    &lt;p&gt;The following manufacturers allow unlocking under certain conditions, such as region, model, SOC, etc., or require a sacrifice to unlock.&lt;/p&gt;
    &lt;p&gt;The following manufacturers require an online account and/or a waiting period before unlocking.&lt;/p&gt;
    &lt;p&gt;Custom Android Verified Boot keys is a feature which allows you to run a custom OS with a locked bootloader.&lt;/p&gt;
    &lt;p&gt;It's rare to see a device which supports custom AVB keys, but some devices can be found here.&lt;/p&gt;
    &lt;p&gt;Kirin 620, 650, 655, 658, 659, 925, 935, 950, 960:&lt;lb/&gt; It's possible to unlock using testpoints and PotatoNV (Read the readme)&lt;/p&gt;
    &lt;p&gt;If you own a MediaTek device exploitable by mtkclient you can unlock the bootloader using that.&lt;lb/&gt; If it also happens to be an OPPO/Realme device and you need to access fastboot: lkpatcher (web version)&lt;/p&gt;
    &lt;p&gt;There's no Universal Qualcomm method, unfortunately.&lt;/p&gt;
    &lt;p&gt;Although some of these might work for you:&lt;/p&gt;
    &lt;p&gt;The general exploit:&lt;lb/&gt; alephsecurity.com the bootloader unlock section.&lt;/p&gt;
    &lt;p&gt;Xiaomi Mi A1 and maybe all MSM89** manufactured before 2018:&lt;lb/&gt; EDLUnlock&lt;/p&gt;
    &lt;p&gt;If you own a phone with the Unisoc UMS9620 or older,you can use this exploit to achieve temporary secure boot bypass and persistently unlock bootloader(except some devices with modified uboot) CVE-2022-38694_unlock_bootloader&lt;/p&gt;
    &lt;p&gt;If you own a phone with the Unisoc UMS312 UMS512 UD710,you can use this exploit to achieve persistently secure boot bypass, which means all firmwares including splloader,uboot can be modified and resigned. CVE-2022-38691_38692&lt;/p&gt;
    &lt;p&gt;Otherwise, you can also look into this: Spectrum_UnlockBL_Tool &lt;lb/&gt; This: xdaforums.com &lt;lb/&gt; Or this: subut&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149019</guid><pubDate>Thu, 04 Dec 2025 15:57:21 +0000</pubDate></item><item><title>Feynman vs. Computer</title><link>https://entropicthoughts.com/feynman-vs-computer</link><description>&lt;doc fingerprint="127ccb0343b51399"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Feynman vs. Computer&lt;/head&gt;
    &lt;p&gt;I read Burghelea‚Äôs article on the Feynman trick for integration. Well, I‚Äôm not good enough at analysis to follow along, but I tried reading it anyway because it‚Äôs fascinating.&lt;/p&gt;
    &lt;p&gt;For people who do not have experience with analysis, integration is counting the total size of very many, very small piles of things. Analytical integration, i.e. the process by which we can get an exact result, can be very difficult. It often takes knowledge of special tricks, strong pattern recognition, and plenty of trial and error. Fortunately, in all cases in my career when I‚Äôve needed the value of an integral, an approximate answer has been good enough.&lt;/p&gt;
    &lt;p&gt;In practical terms, this means we could spend a lot of time learning integration tricks, practice using them, and then take half an hour out of our day to apply them to an integral in front of us ‚Ä¶ or, hear me out, or, we could write four lines of JavaScript that arrive at a relatively accurate answer in less than a second.&lt;/p&gt;
    &lt;head rend="h1"&gt;The approximating power of random numbers&lt;/head&gt;
    &lt;p&gt;If integration is summing many small piles, we have to figure out how big the piles are. Their height is usually given by a mathematical function, and our first example will be the same as in the Feynman trick article.&lt;/p&gt;
    &lt;p&gt;\[f(x) = \frac{x - 1}{\ln{x}}\]&lt;/p&gt;
    &lt;p&gt;This is to be integrated from zero to one, i.e. we want to know the size of the shaded area in the plot below. You can think of each column of shaded pixels as one pile, and we sum the size of all of them to get the total area.1 Of course, this is an svg image so there are no columns of pixels. Alternatively, the more we zoom in, the thinner the columns become ‚Äì but the more of them there are. This is why we need integration: it‚Äôs dealing with the limit case of infinitely many, infinitely thin columns.&lt;/p&gt;
    &lt;p&gt;We could imagine drawing six random numbers between zero and one, and plotting piles of the corresponding height at those locations. Since there are six piles, their width is one sixth of the width of the area we are integrating.&lt;/p&gt;
    &lt;p&gt;Even though some of these piles overlap by chance, and even though there are some random gaps between them, the sum of their areas (0.66) comes very close to the actual shaded area determined analytically (0.69). If we draw more piles, we have to make them correspondingly thinner, but the agreement between their sum and the total size of the area improves.&lt;/p&gt;
    &lt;p&gt;These are 100√ó as many piles, and they‚Äôre 1/100th as thick to compensate. Their total area is 0.70 ‚Äì very close to 0.69. If we draw even more piles, we‚Äôll get even closer.&lt;/p&gt;
    &lt;p&gt;This illustrates a neat correspondence between integrals and expected values. In the simple case, we can frame it mathematically as&lt;/p&gt;
    &lt;p&gt;\[\int_a^b f(x) \mathrm{d}x = E(f(x))\]&lt;/p&gt;
    &lt;p&gt;In words, this says that integrating the function \(f\) between \(a\) and \(b\) is the same as taking the expected value of \(f(x)\) at uniformly distributed random points between \(a\) and \(b\).&lt;/p&gt;
    &lt;head rend="h1"&gt;Teaching the computer to do it&lt;/head&gt;
    &lt;p&gt;Here‚Äôs a JavaScript function that estimates the value of an integral in the most primitive way possible.&lt;/p&gt;
    &lt;quote&gt;I = (B, lo, hi, f) =&amp;gt; { // Generate B random values uniformly between lo and hi. let xs = Array.from({length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random()); // Compute the value of f at each location. let ys = xs.map(f); // Return the total area of each corresponding pile. return (hi-lo)*ys.reduce((r, y) =&amp;gt; r + y, 0)/ys.length; }&lt;/quote&gt;
    &lt;p&gt;To compute an approximation to the value of the integral we‚Äôve seen, we run&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) );&lt;/quote&gt;
    &lt;quote&gt;0.6916867623261724&lt;/quote&gt;
    &lt;p&gt;This is fairly close to 0.69. And we got there in four lines of JavaScript, as promised.&lt;/p&gt;
    &lt;head rend="h1"&gt;Improved approximation through splittage&lt;/head&gt;
    &lt;p&gt;We can try this on the next example too. Now we‚Äôre asking about the integral&lt;/p&gt;
    &lt;p&gt;\[\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;which, translated to JavaScript, becomes&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, Math.PI, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x) );&lt;/quote&gt;
    &lt;quote&gt;-3.67&lt;/quote&gt;
    &lt;p&gt;This is again fairly close to the desired ‚àí3.7, but not quite there yet. The tricky shape of the function is the reason we aren‚Äôt getting as close as we want.&lt;/p&gt;
    &lt;p&gt;At the upper endpoint of the integration interval, this function goes to negative infinity. The random piles we draw come primarily from the well behaved region of the function, and thus don‚Äôt help the computer realise this behaviour.&lt;/p&gt;
    &lt;p&gt;There are clever ways to sample adaptively from the trickier parts of the function, but an easy solution is to just visually find a breakpoint, split the interval on that, and then estimate the sensible part separately from the crazy-looking part. Since the total area must be the sum of both areas, we can add their results together for a final estimation.&lt;/p&gt;
    &lt;p&gt;In this case, we might want to pick e.g. 1.5 as the breakpoint, so we combine the area estimations from 0‚Äì1.5 and then 1.5‚Äì\(\frac{\pi}{2}\). The result is&lt;/p&gt;
    &lt;quote&gt;I(2_000, 0, 1.5, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x)) + I(8_000, 1.5, Math.PI/2, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x));&lt;/quote&gt;
    &lt;quote&gt;-3.70&lt;/quote&gt;
    &lt;p&gt;which is indeed much closer to the actual value of ‚àí3.7.&lt;/p&gt;
    &lt;p&gt;Note that we aren‚Äôt taking more samples, we‚Äôre just sprinkling them more wisely over the number line. We spend 2,000 samples in the relatively well-behaved region where the function takes values from ‚àí1 to ‚àí6, and then we spend the other 8,000 samples in the small region that goes from ‚àí6 to negative infinity. Here it is graphically:&lt;/p&gt;
    &lt;p&gt;The reason this helps us is that this latter region contributes a lot to the value of the integral, but it is so small on the number line that we benefit from oversampling it compared to the other region. This is a form of sample unit engineering, which we have seen before in different contexts.&lt;/p&gt;
    &lt;head rend="h1"&gt;More evidence of sufficiency&lt;/head&gt;
    &lt;p&gt;We can continue with some more examples from the Feynman trick article. That gets us the following table.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Integral&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Estimation&lt;/cell&gt;
        &lt;cell role="head"&gt;Difference&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{x-1}{\ln{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\ln{2}\)&lt;/cell&gt;
        &lt;cell&gt;0.6943&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-3 \pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-3.702&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{(1 - x + x^2)}}{x - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{9}\)&lt;/cell&gt;
        &lt;cell&gt;-1.097&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\arctan{(\sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi}{2}\log{(1 + \sqrt{2})}\)&lt;/cell&gt;
        &lt;cell&gt;1.385&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^\infty x^2 e^{-\left(4x^2 + \frac{9}{x^2}\right)} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{13 \sqrt{\pi}}{32 e^{12}}\)&lt;/cell&gt;
        &lt;cell&gt;0.000004414&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
        &lt;cell&gt;(1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{x}}{1 - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-1.227&lt;/cell&gt;
        &lt;cell&gt;0.5 %&lt;/cell&gt;
        &lt;cell&gt;(2)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\(\int_0^\infty \frac{e^{-x^2}}{1 + x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi e}{2}\mathrm{erfc}(1)\)&lt;/cell&gt;
        &lt;cell&gt;0.6696&lt;/cell&gt;
        &lt;cell&gt;0.3 %&lt;/cell&gt;
        &lt;cell&gt;(3)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The integration is from zero to infinity, but the function practically only has a value between zero and three, so that‚Äôs the region we estimate over.&lt;/item&gt;
      &lt;item&gt;This is another case where the function goes to infinity near zero, so we split up the estimation into one for the range 0‚Äì0.1, and the other for 0.1‚Äì1.0. We have not increased the sample count, only reallocated the 10,000 samples.&lt;/item&gt;
      &lt;item&gt;Again, the integration is from zero to infinity, but the function practically only has a value between zero and three, so that‚Äôs the region we estimate over.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Finding the error without a ground truth&lt;/head&gt;
    &lt;p&gt;‚ÄúNow,‚Äù the clever reader says, ‚Äúthis is all well and good when we have the actual value to compare to so we know the size of the error. What will we do if we‚Äôre evluating a brand new integral? What is the size of the error then, huh?‚Äù&lt;/p&gt;
    &lt;p&gt;This is why we sampled the function randomly. That means our approximation is a statistical average over samples, and for that we can compute the standard error of the mean. In the JavaScript implementation below, we use the quick variance computation, but we could perhaps more intuitively have used the spc inspired method.&lt;/p&gt;
    &lt;quote&gt;Ic = (B, lo, hi, f) =&amp;gt; { let xs = Array.from( {length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random() ); let ys = xs.map(f); // Compute the variance of the ys from the sum and // the sum of squared ys. let s = ys.reduce((r, y) =&amp;gt; r + y, 0); let ssq = ys.reduce((r, y) =&amp;gt; r + y**2, 0); let v = (ssq - s**2/B)/(B-1); // Compute the mean and the standard error of the mean. let m = (hi-lo)*s/B; let se = (hi-lo)*Math.sqrt(v/B); // Compute the 90 % confidence interval of the value of // the integral. return { p05: m - 1.645*se, p95: m + 1.645*se, } }&lt;/quote&gt;
    &lt;p&gt;If we run this with the first integral as an example, we‚Äôll learn that&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) )&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.6896 p95: 0.6963 }&lt;/quote&gt;
    &lt;p&gt;Not only is this range an illustration of the approximation error (small!), it is also very likely to capture the actual value of the integral. Here are some more examples from the same integrals as above:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Actual&lt;/cell&gt;
        &lt;cell role="head"&gt;Contained?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.6904&lt;/cell&gt;
        &lt;cell&gt;0.6972&lt;/cell&gt;
        &lt;cell&gt;0.6931&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-3.7673&lt;/cell&gt;
        &lt;cell&gt;-3.6787&lt;/cell&gt;
        &lt;cell&gt;-3.7011&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.0975&lt;/cell&gt;
        &lt;cell&gt;-1.0960&lt;/cell&gt;
        &lt;cell&gt;-1.0966&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1.3832&lt;/cell&gt;
        &lt;cell&gt;1.3871&lt;/cell&gt;
        &lt;cell&gt;1.3845&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.4372&lt;/cell&gt;
        &lt;cell&gt;0.4651&lt;/cell&gt;
        &lt;cell&gt;0.4424&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.2545&lt;/cell&gt;
        &lt;cell&gt;-1.2254&lt;/cell&gt;
        &lt;cell&gt;-1.2337&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;0.6619&lt;/cell&gt;
        &lt;cell&gt;0.6937&lt;/cell&gt;
        &lt;cell&gt;0.6716&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These are all built na√Øvely from 10,000 uniform samples. In other words, in none of the cases have the computation been split up to allocate samples more cleverly.&lt;/p&gt;
    &lt;p&gt;Again, we could spend a lot of time learning to integrate by hand ‚Ä¶ or we ask the computer for less than a second of its time first, and see if the accuracy it can do it with is appropriate for our use case. In my experience, it generally is.&lt;/p&gt;
    &lt;head rend="h1"&gt;Seeing the effect of sample unit engineering&lt;/head&gt;
    &lt;p&gt;What‚Äôs neat is we can still split up the computation like we did before, if we believe it will make the error smaller and the confidence interval narrower. Let‚Äôs use the following integral as an example.&lt;/p&gt;
    &lt;p&gt;\[\int_0^\infty \frac{\sin{x}}{x} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;This oscillates up and down quite a bit for small \(x\), and then decays but still provides significant contributions for larger \(x\). A naive evaluation would have a confidence interval of&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.461 p95: 1.884 }&lt;/quote&gt;
    &lt;p&gt;and while this is certainly correct2 The actual value of the integral is half \(\pi\) or approximatey 1.571., we can do better. We‚Äôll estimate the region of 0‚Äì6 separately from 6‚Äì100, using half the samples for each3 Why put the break point at 6? The period of sin is a full turn, which is roughly 6 radians. This ensures we get roughly symmetric contributions from both integrals. That‚Äôs not necessary for the technique to work, but it makes the illustration a little cleaner.:&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 0, 6, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.236 p95: 1.468 }&lt;/quote&gt;
    &lt;p&gt;This contains the bulk of the value of the integral, it seems. Let‚Äôs see what remains in the rest of it.&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 6, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.080 p95: 0.198 }&lt;/quote&gt;
    &lt;p&gt;We can work backwards to what the standard errors must have been to produce these confidence intervals.4 The midpoint is the point estimation for each region, and the standard error is 1/1.645 times the distance between the 5 % point and the midpoint.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Region&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Standard error&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;0‚Äì6&lt;/cell&gt;
        &lt;cell&gt;1.4067&lt;/cell&gt;
        &lt;cell&gt;0.0372&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;6‚Äì100&lt;/cell&gt;
        &lt;cell&gt;0.1390&lt;/cell&gt;
        &lt;cell&gt;0.0359&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The estimation of the total area would be the values summed, i.e. 1.5457. The estimation of the standard error of this we get through Pythagorean addition and it is approximately 0.05143. We convert it back to a confidence interval and compare with when we did not break it up into multiple components.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (5,000 samples √ó 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Although in this case the two methods happen to share a lower bound, the upper bound has been dramatically reduced. The total range of the confidence interval is more than halved! This was because we allocated the samples more cleverly ‚Äì concentrated them in the early parts of the function ‚Äì rather than increased the number of samples.&lt;/p&gt;
    &lt;p&gt;That said, we‚Äôre at a computer, so we could try increasing the sample count. Or maybe both?&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Two operations (5,000 samples √ó 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (100,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.549&lt;/cell&gt;
        &lt;cell&gt;1.680&lt;/cell&gt;
        &lt;cell&gt;0.131&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (50,000 samples √ó 2)&lt;/cell&gt;
        &lt;cell&gt;1.524&lt;/cell&gt;
        &lt;cell&gt;1.578&lt;/cell&gt;
        &lt;cell&gt;0.054&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It seems like sampling more cleverly has almost the same effect as taking ten times as many samples.&lt;/p&gt;
    &lt;p&gt;We could play around with where to put the breakpoint, and how many samples to allocate to each side of it, and see which combination yields the lowest error. Then we can run that combination with a lot of samples to get the most accurate final result. That would take maybe 15 minutes of tooting about and exploring sensible-seeming alternatives, so it‚Äôs probably still quicker than integrating by hand.&lt;/p&gt;
    &lt;head rend="h1"&gt;When the computer is not enough&lt;/head&gt;
    &lt;p&gt;It should be said that there are times when numeric solutions aren‚Äôt great. I hear that in electronics and quantum dynamics, there are sometimes integrals whose value is not a number, but a function, and knowing that function is important in order to know how the thing it‚Äôs modeling behaves in interactions with other things.&lt;/p&gt;
    &lt;p&gt;Those are not my domains, though. And when that‚Äôs not the case, the computer beats Feynman any day of the week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149066</guid><pubDate>Thu, 04 Dec 2025 16:03:02 +0000</pubDate></item><item><title>Autism should not be treated as a single condition</title><link>https://www.economist.com/science-and-technology/2025/12/03/why-autism-should-not-be-treated-as-a-single-condition</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149375</guid><pubDate>Thu, 04 Dec 2025 16:25:31 +0000</pubDate></item><item><title>Launch HN: Browser Buddy (YC W24) ‚Äì A recommendation system for Internet writing</title><link>https://www.browserbuddy.com/</link><description>&lt;doc fingerprint="3bd993f7b8d51a27"&gt;
  &lt;main&gt;
    &lt;p&gt;A For-You page for writing Explore the best essays and blogs on the Internet with Browser Buddy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149727</guid><pubDate>Thu, 04 Dec 2025 16:52:56 +0000</pubDate></item><item><title>The End of the Train-Test Split</title><link>https://folio.benguzovsky.com/train-test</link><description>&lt;doc fingerprint="9fdc833f15120e5b"&gt;
  &lt;main&gt;
    &lt;p&gt;You are a machine learning engineer at Facebook in Menlo Park. Your task: build the best butt classification model, which decides if there is an exposed butt in an image.&lt;/p&gt;
    &lt;p&gt;The content policy team in D.C. has written country-specific censorship rules based on cultural tolerance for gluteal cleft‚Äîor butt crack, for the uninitiated.&lt;/p&gt;
    &lt;p&gt;A PM on your team writes data labeling guidelines for a business process outsourcing firm (BPO), and each example in your dataset is triple-reviewed by the firm's outsourced team to ensure consistency. You skim the labels, which seem reasonable.&lt;/p&gt;
    &lt;code&gt;import torch
import pandas as pd
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split

df = pd.read_csv("gluteal_cleft_labels.csv")
X = df.drop("label", axis=1).values
y = df["label"].values

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)&lt;/code&gt;
    &lt;p&gt;You decide to train a CNN: it'll be perfect for this edge detection task. Two months later, you've cracked it. Your model goes live, great success, 92% precision, 98% recall. You never once had to talk to the policy team in D.C.&lt;/p&gt;
    &lt;p&gt;Another email: Policy has heard about LLMs and thinks it's time to build a more "context-aware" model. They would like the model to understand whether there is sexually suggestive posing, sexual context, or artistic intent in the image.&lt;/p&gt;
    &lt;p&gt;You receive a 10 page policy doc. The PM cleans it up a bit and sends it to the BPO. The data is triple reviewed, you skim the labels, and they seem fine.&lt;/p&gt;
    &lt;p&gt;You make an LLM decision tree, one LLM call per policy section, and aggregate the results. Two months pass. You are stuck at 85% precision and recall, no matter how much prompt engineering and model tuning you do. You try going back to a CNN, training it on the labels. It scores 83%.&lt;/p&gt;
    &lt;p&gt;Your data science spidey-sense tingles. Something is wrong with the labels or the policy.&lt;/p&gt;
    &lt;p&gt;You email the policy team, sending them the dataset and results.&lt;/p&gt;
    &lt;p&gt;The East Coast Metamates say they looked at 20 of the labels. 60% were good, 20% were wrong, 20% were edge cases they hadn‚Äôt thought of.&lt;/p&gt;
    &lt;p&gt;The butt model lives to fight another day, or at least until these discrepancies get sorted out.&lt;/p&gt;
    &lt;p&gt;The butt model is still in production‚Ä¶ What went wrong?&lt;/p&gt;
    &lt;p&gt;It doesn't matter if the task is content policy, sales chatbots, legal chatbots, or AI automation in any other industry.&lt;/p&gt;
    &lt;p&gt;Test Split: Any task complicated enough to require an LLM will need policy expert labels.[1] To detect nudity, outsourced labels will do, but to enforce a 10 page adult policy, you need the expert. Experts have little time: they can't give you enough labels to run your high scale training runs. You can't isolate enough data for a test set without killing your training set size. On top of that, a 10 page policy comes with so much gray area that you can‚Äôt debug test set mistakes without looking at test set results and model explanations.&lt;/p&gt;
    &lt;p&gt;Train Split: You no longer need a large, discrete training set because LLMs often don't need to be trained on data: they need to be given clear rules in natural language, and maybe 5-10 good examples.[2] Today, accuracy improvements come from an engineer better understanding the classification rules and better explaining them to the model, not from tuning hyperparameters or trying novel RL algorithms. Is a discrepancy between the LLM result and the ground truth due to the LLM‚Äôs mistake, the labeler‚Äôs mistake, or an ambiguous policy line? This requires unprecedented levels of communication between policy and engineering teams.&lt;/p&gt;
    &lt;p&gt;Recommending a New Split: Don‚Äôt train the LLM on any of the dataset. Address the inevitable biases with evaluation on blind, unlabeled data.[3] To understand why this is the best approach, we need to dive deeper into why the train-test split paradigm doesn't suffice.&lt;/p&gt;
    &lt;p&gt;Policy Experts write abstract rules. For older classification tasks, the rules had to be simple, because simple was all that models could do. Are there guns in the image? Is there a minor in the image? Complicated tasks are harder to pin down.&lt;/p&gt;
    &lt;p&gt;Take these examples. Sexually suggestive? Artistic expression? Sufficient censorship?&lt;/p&gt;
    &lt;p&gt;Most policy documents are not well-kept. A content policy is typically simplified, operationalized, and sent to outsourced teams to enforce. Edge cases and discrepancies found in India never make it back to policy teams in DC, so abstract rules are rarely pinned down.&lt;/p&gt;
    &lt;p&gt;In production, we see 15-20% false positive rates on BPOs. Half are attributable to human error, half to policy gray area.&lt;/p&gt;
    &lt;p&gt;To resolve edge cases, labeling tasks require an expert's time. BPO agents can eyeball how much butt is visible, but struggle with what is "sexually suggestive." BPOs are low-wage workers in countries like India or the Phillipines, and may have different definitions of "sexual context" than the policy writers intended. The costs of training them are often prohibitive at scale.&lt;/p&gt;
    &lt;p&gt;Using in-house agents is not sufficient for training data, either, as small alignment issues in the dataset cause large issues in production: If internal agents are 95% accurate (pretty good), the ceiling for the LLM's performance is 95%. If the LLM gets 95% of those labels right, its accuracy will be 90%.&lt;/p&gt;
    &lt;p&gt;Hard classification tasks have high rates of expert disagreement. Ask two people if there's a gun in an image, odds are they'll agree. Ask two policy experts whether a pose is sexually suggestive per their definition, you will start a one hour debate. If two experts only agree 95% of the time, then hand off to internal agents for labeling at 95% accuracy, then the LLM is 95% accurate, you are down to 86% LLM accuracy.&lt;/p&gt;
    &lt;p&gt;Language models see details in data that even experts miss. LLMs read every word of the product description. They scrutinize every image for a single pixel of gluteal cleft. They see gluteal cleft through sheer clothing, in low opacity, and in the bottom left corner of the back of a t-shirt. Even if experts have reviewed the data, there must be a re-review and feedback loop to check what the LLM has flagged.&lt;/p&gt;
    &lt;p&gt;Since labels are often wrong or ambiguous, you cannot keep the test set blind. If the LLM is right and the labels are wrong, either because the expert missed something, the policy was ambiguous, or the outsourced labeler was wrong, you have to look at the test set results to check. Moreover, you need to review the LLM's explanation while reviewing the new data to see what it found, confounding any true "blind" test.[4]&lt;/p&gt;
    &lt;p&gt;In production, we see anywhere from 15-30% error rates in data considered "golden sets" by operations teams.&lt;/p&gt;
    &lt;p&gt;Given the need for expert input and policy clarifications, you cannot maintain large enough training sets to keep the test set blind. For a simple policy, maintaining good labeled data is straightforward. However, attempting to integrate an LLM is often the first time a policy expert will be asked to scrutinize their rules and labels. Their time is valuable, and they will not be able to bring their expertise to a large dataset.&lt;/p&gt;
    &lt;p&gt;Complicated policies change, especially under scrutiny, and re-labeling affected examples is time-consuming. A leaner training set will be more valuable than a larger one in the long run.&lt;/p&gt;
    &lt;p&gt;Since these classification tasks are so complex, you can only "debug" the model by looking at the input and its explanations side-by-side. A policy might have dozens of rules and thousands of possible inputs, creating a fat-tail of model mistakes. Unlike traditional machine learning, where you fix mistakes by changing the design or hyperparameters of your model, you fix LLM mistakes by changing the prompt. You can directly fix a mistake (e.g. by telling the model "do not consider spreading legs fully clothed to be sexually suggestive"), so keeping mistakes hidden only hurts accuracy.[5]&lt;/p&gt;
    &lt;p&gt;You still need to run blind tests: QA the models on new data. Organizations end up running their models in "shadow mode" on production data, creating test examples without taking real-world actions. Here, you'll likely need an in-house agent to review the examples, then forward edge cases to a policy expert.&lt;/p&gt;
    &lt;p&gt;The Policy and Engineering Teams Need to be in Direct, Frequent Communication. The SF-DC split doesn't work anymore. Resolving edge cases and, in many cases, changing the policy to reflect patterns identified in the data requires collaboration.&lt;/p&gt;
    &lt;p&gt;Experts have historically not needed to look at the data‚Äîseen as a low-status task‚Äîbut it is the only way to achieve high accuracy. This is an unsolved problem in many large organizations that blocks LLM integrations.&lt;/p&gt;
    &lt;p&gt;Most importantly, LLMs do not "train" on data the way traditional classifiers do, so there is often no need to have a "training" set, either. LLMs can enforce complicated, natural language rules because they can take natural language inputs, not because they can learn patterns from thousands of training examples. LLM accuracy is often a prompting task, not a design-your-RL-pipeline task.[1]&lt;/p&gt;
    &lt;p&gt;If you want a model to classify whether animals are endangered species, don't give it 1,000 examples of elephant ivory, 100 examples of every species on the CITES list, and 1,000 pictures of your non-endangered dog, give it the list of species names as inputs.&lt;/p&gt;
    &lt;p&gt;The "training" step for language models has to be policy alignment, not heating up GPUs. Since the data will always be flawed and the test set won't be blind, the machine learning engineer's priority should be spent working with policy teams to improve the data. That means surfacing edge cases and policy gray areas, clarifying policy definitions, and leveraging LLM outputs to find more discrepancies until data is high-quality and policy is clear.&lt;/p&gt;
    &lt;p&gt;In production, this is an ongoing process, as LLMs will always surface new interesting cases and policies will continue to change. Policies and enforcement are better for this feedback loop: it enables consistent, scaled enforcement platform-wide.&lt;/p&gt;
    &lt;p&gt;This is a paradigm shift that many machine learning teams, and enterprises as a whole, have not yet embraced. It requires a complete change in how we approach classification tasks.&lt;/p&gt;
    &lt;p&gt;If this is the road to automation, is it even worthwhile? The process described above, while arduous, is the shortest route to consistent policy enforcement to date. Before LLMs, running a successful quality assurance program would be prohibitively expensive. Retraining human agents takes far longer than retraining LLMs. Policy experts have historically never been owners in quality assurance processes, but now can be.&lt;/p&gt;
    &lt;p&gt;To save a little time, an in-house human agent might do a first review of the results, then a policy expert can review only the discrepancies. We find this tradeoff works well in production.&lt;/p&gt;
    &lt;p&gt;What are the implications for leveraging LLMs for tasks which do not have binary classifications? Can an LLM be a lawyer if this much work is required to align, evaluate, and test models? Will an LLM ever ~know what you mean~ and skip all these alignment steps?&lt;/p&gt;
    &lt;p&gt;One core problem with the LLM architecture is that the model doesn't know when it is wrong. Model improvements over the past few years mean the LLM is right more often, but when it is wrong, it doesn't have an outlet.&lt;/p&gt;
    &lt;p&gt;This is a perennial machine learning problem: a model does not know what is "out of distribution" for itself.&lt;/p&gt;
    &lt;p&gt;Until that problem is solved, there will have to be an engineer in the loop improving and testing the model, and a policy expert evaluating the results. You can do this for complicated tasks like writing a patent application, but you have to be rigorous, define a rubric, curate expert data, and regularly evaluate model outputs. Calculating accuracy of each "training run" will never be as easy as checking if model_output == ground_truth, and will require a human in the loop. These complex tasks are far more lucrative than binary classification, and smart people are working on them.&lt;/p&gt;
    &lt;p&gt;Not everybody will take this rigorous approach, and as models improve, they might not have to. Until then, the highest leverage way to spend your time in 2026 will be looking closely at your data, cleaning your data, and labeling your data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149740</guid><pubDate>Thu, 04 Dec 2025 16:53:49 +0000</pubDate></item><item><title>Multivox: Volumetric Display</title><link>https://github.com/AncientJames/multivox</link><description>&lt;doc fingerprint="87cd881f7921b9c9"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the code I currently use to drive my volumetric displays.&lt;/p&gt;
    &lt;p&gt;It supports two closely related devices which are configured in the &lt;code&gt;src/driver/gadgets&lt;/code&gt; directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rotovox is a 400mm Orb featuring two 128x64 panels arranged vertically side by side.&lt;/item&gt;
      &lt;item&gt;Vortex is a 300mm Orb featuring two 128x64 panels arranged horizontally, back to back.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rotovox has a higher vertical resolution and better horizontal density; Vortex is brighter and has a higher refresh rate.&lt;/p&gt;
    &lt;p&gt;The 3D printable parts for Vortex are available here.&lt;/p&gt;
    &lt;p&gt;This code was originally written for a single display, and the device specific code was later somewhat abstracted out to support a second similar gadget. There are assumptions about the hardware that are pretty well baked in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It consists of two HUB75 LED panels spinning around a vertical axis.&lt;/item&gt;
      &lt;item&gt;The panels use either ABCDE addressing or ABC shift register addressing.&lt;/item&gt;
      &lt;item&gt;It uses a single GPIO (a photodiode or similar) to sync to rotation - high for 180¬∞, low for 180¬∞.&lt;/item&gt;
      &lt;item&gt;It's running on a Raspberry Pi 4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The GPIO mappings and panel layout are defined in &lt;code&gt;src/driver/gadgets/gadget_&amp;lt;name&amp;gt;.h&lt;/code&gt;. GPIO is via memory mapped
access - if you're using a different model of Pi you'll need to change &lt;code&gt;BCM_BASE&lt;/code&gt; in the GPIO code. I haven't tested
this, and you should probably assume it doesn't work.&lt;/p&gt;
    &lt;p&gt;Input is via a bluetooth gamepad - I've been using an Xbox controller, and the input system is based on the default mapping for that.&lt;/p&gt;
    &lt;p&gt;Audio out is also via bluetooth. I haven't had success with the higher quality codecs, but the headset protocol works.&lt;/p&gt;
    &lt;p&gt;There are two parts to this code - the driver, which creates a voxel buffer in shared memory and scans its contents out in sync with rotation, and the client code which generates content and writes it into the voxel buffer. Both driver and client code are designed to run on the same device, a Raspberry Pi embedded in the hardware and spinning at several hundred RPM. There is a demo included in the Python directory which streams point clouds from a PC over wifi to the device, but fundamentally it's designed as a self contained gadget, like an alternate timeline Vectrex. A bluetooth gamepad is used to control the demos.&lt;/p&gt;
    &lt;code&gt;‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ driver
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gadgets         -- the different volumetric display configurations
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ             
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vortex.c        -- driver code - creates a voxel buffer in shared memory,
‚îÇ   ‚îÇ                          and handles scanning it out to the led panels in sync with
‚îÇ   ‚îÇ                          the rotation
‚îÇ   ‚îú‚îÄ‚îÄ simulator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ virtex.c        -- software simulator - presents the same voxel buffer as
‚îÇ   ‚îÇ                          the driver would, but renders the contents into an X11 window
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ multivox            -- front end / launcher for the various volumetric toys
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ
‚îÇ   ‚îú‚îÄ‚îÄ platform            -- common client code
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ
‚îÇ   ‚îî‚îÄ‚îÄ toys                -- a collection of volumetric demos using the shared voxel buffer
‚îÇ       ‚îú‚îÄ‚îÄ eighty          -- multiplayer light cycles
‚îÇ       ‚îú‚îÄ‚îÄ fireworks.c     -- cheesy first demo
‚îÇ       ‚îú‚îÄ‚îÄ flight.c        -- some kind of 70s scifi thing
‚îÇ       ‚îú‚îÄ‚îÄ tesseract.c     -- a 4D cubube
‚îÇ       ‚îú‚îÄ‚îÄ viewer.c        -- viewer for .obj and .png files
‚îÇ       ‚îî‚îÄ‚îÄ zander          -- lander/zarch/virus-esque
‚îú‚îÄ‚îÄ python  
‚îÇ   ‚îú‚îÄ‚îÄ calibration.py      -
‚îÇ   ‚îú‚îÄ‚îÄ grid.py             -- some pattern generators, useful when calibrating the device
‚îÇ   ‚îú‚îÄ‚îÄ colourwheel.py      -
‚îÇ   ‚îú‚îÄ‚îÄ obj2c.py            -- tool for embedding .obj models in a header file
‚îÇ   ‚îú‚îÄ‚îÄ pointvision.py      -- receive point clouds streamed from vortexstream.py
‚îÇ   ‚îî‚îÄ‚îÄ vortexstream.py     -- stream point clouds to pointvision.py
‚îî‚îÄ‚îÄ README.md               -- you are here
&lt;/code&gt;
    &lt;p&gt;On the Raspberry Pi, clone the repository:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/AncientJames/multivox.git
&lt;/code&gt;
    &lt;p&gt;Configure the project for your hardware:&lt;/p&gt;
    &lt;code&gt;cd multivox
mkdir build
cd build
cmake -DMULTIVOX_GADGET=vortex ..
cmake --build .
&lt;/code&gt;
    &lt;p&gt;First, the driver has to be running:&lt;/p&gt;
    &lt;code&gt;sudo ./vortex
&lt;/code&gt;
    &lt;p&gt;When invoked from the command line it periodically outputs profiling information (frame rate, rotation rate), and accepts keyboard input for various diagnostics:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;b&lt;/cell&gt;
        &lt;cell&gt;Bit depth - cycles through 1, 2 or 3 bits per channel. Higher bit depths result in lower refresh rates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;u&lt;/cell&gt;
        &lt;cell&gt;Uniformity - cycles through different strategies for trading off brightness against uniformity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;t&lt;/cell&gt;
        &lt;cell&gt;Trails - adjusts how far back to accumulate skipped voxels when the rotation rate is too high for the refresh rate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;l&lt;/cell&gt;
        &lt;cell&gt;Lock - whether to adjust the rotation sync to keep it facing one way&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;d D&lt;/cell&gt;
        &lt;cell&gt;Drift - rotisserie mode. Introduces some explicit drift to the rotation sync&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;p&lt;/cell&gt;
        &lt;cell&gt;Panel - selectively disable the panels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;xyz&lt;/cell&gt;
        &lt;cell&gt;Axis - When the display isn't spinning, it shows an othographic view. This lets you choose the axis&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;While that's running, try one of the toys:&lt;/p&gt;
    &lt;code&gt;./tesseract
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;viewer&lt;/code&gt; takes a list of .obj and .png files as arguments. You can scale, rotate and so on using the gamepad, and it
also accepts keyboard input when run remotely from the command line.&lt;/p&gt;
    &lt;code&gt;./viewer ~/Multivox/models/*.obj
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;[ / ]&lt;/cell&gt;
        &lt;cell&gt;Cycle through models&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Walkthrough / Orbit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Zoom to fit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Toggle wireframe&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you don't have a physical volumetric display, there's a simulator, &lt;code&gt;virtex&lt;/code&gt;, which you can run in place of &lt;code&gt;vortex&lt;/code&gt;. It exposes the same voxel buffer in shared memory, but renders the contents using OpenGL in an X11 window.&lt;/p&gt;
    &lt;p&gt;Run without command line arguments it creates a display compatible with the currently configured gadget, but there are some options to let you experiment with different geometries:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-s X&lt;/cell&gt;
        &lt;cell&gt;slice count - the number of vertical slices per revolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-o X X&lt;/cell&gt;
        &lt;cell&gt;offsets - distance the front and back screens are offset from the axis, as a fraction of screen radius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-b X&lt;/cell&gt;
        &lt;cell&gt;bits per channel (1 - 3)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-w X Y&lt;/cell&gt;
        &lt;cell&gt;panel resolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;-g X&lt;/cell&gt;
        &lt;cell&gt;scan geometry - radial or linear. Linear looks better, but it's a lot harder to build.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An idealised device with linear scanning and 3 bits per channel can be invoked like this:&lt;/p&gt;
    &lt;code&gt;./virtex -g l -s 128 -w 1280 1280 -b 3
&lt;/code&gt;
    &lt;p&gt;The simulator is fill rate intensive; if you're running it on a Raspberry Pi you'll probably want to reduce the slice count.&lt;/p&gt;
    &lt;p&gt;If you want it to start up automatically on boot, you can install &lt;code&gt;vortex&lt;/code&gt; as a service, and set &lt;code&gt;multivox&lt;/code&gt; to run on startup.&lt;/p&gt;
    &lt;p&gt;First install everything to its default location &lt;code&gt;~/Multivox&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;make install&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This will build the executable files and copy them into the destination directory, as well as creating &lt;code&gt;.mct&lt;/code&gt; files in &lt;code&gt;~/Multivox/carts&lt;/code&gt; for the built in toys.&lt;/p&gt;
    &lt;p&gt;Create the driver service:&lt;/p&gt;
    &lt;code&gt;sudo nano /usr/lib/systemd/system/vortex.service
&lt;/code&gt;
    &lt;p&gt;and fill in the following information:&lt;/p&gt;
    &lt;code&gt;[Unit]
Description=Vortex Display Driver
After=multi-user.target

[Service]
ExecStart=/home/pi/Multivox/bin/vortex

[Install]
WantedBy=multi-user.target
&lt;/code&gt;
    &lt;p&gt;Then start it up:&lt;/p&gt;
    &lt;code&gt;sudo systemctl daemon-reload
sudo systemctl enable vortex.service
&lt;/code&gt;
    &lt;p&gt;The driver assigns itself to core 3 - you can add &lt;code&gt;isolcpus=3&lt;/code&gt; to the end of &lt;code&gt;/boot/cmdline.txt&lt;/code&gt; to ensure it's the only thing running on that core.&lt;/p&gt;
    &lt;p&gt;You'll also want the launcher to start up on boot:&lt;/p&gt;
    &lt;code&gt;crontab -e
&lt;/code&gt;
    &lt;p&gt;And add the line:&lt;/p&gt;
    &lt;code&gt;@reboot /home/pi/Multivox/bin/multivox
&lt;/code&gt;
    &lt;p&gt;If everything goes smoothly, when you turn on the device it will boot up into &lt;code&gt;Multivox&lt;/code&gt;. This is a fantasy console which
acts as a launcher for all the games and demos you run on the hardware. The bundled toys are automatically installed in
the &lt;code&gt;~/Multivox/carts/&lt;/code&gt; directory as &lt;code&gt;.mct&lt;/code&gt; files, and external apps can be launched by adding a &lt;code&gt;.mct&lt;/code&gt; file containing
its command, path and arguments.&lt;/p&gt;
    &lt;p&gt;Each &lt;code&gt;.mct&lt;/code&gt; file appears as a cartridge in the Multivox front end. They should each have a label on the side; at the moment
all you can do to distinguish between them is change their colour in the &lt;code&gt;.mct&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When you exit an app back to the launcher, it saves a snapshot of the voxel volume, and this gives a preview of what you'll see when you launch a cart. This means there are two competing representations of the same information, and any future work on the front end will probably start with overhauling the entire approach.&lt;/p&gt;
    &lt;p&gt;Some basic UI for controls such as changing bit depth, rebooting and so on would also be a boon.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;Cycle through carts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Launch cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;‚ßâ&lt;/cell&gt;
        &lt;cell&gt;Exit / resume running cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;‚ñ≥ ‚ñΩ&lt;/cell&gt;
        &lt;cell&gt;Change bit depth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;‚ò∞ x5&lt;/cell&gt;
        &lt;cell&gt;Power off&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149813</guid><pubDate>Thu, 04 Dec 2025 16:58:35 +0000</pubDate></item><item><title>Converge (YC S23) is hiring a martech expert in NYC</title><link>https://www.runconverge.com/careers/technical-customer-success-manager</link><description>&lt;doc fingerprint="ad21d2738937a54f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Technical Customer Success Manager&lt;/head&gt;
    &lt;p&gt;Converge is building the definitive Growth OS: We help DTC Growth teams understand which marketing efforts drive profitable growth. We are the only platform combining best-in-class tracking with blended reporting and multi-touch attribution.&lt;/p&gt;
    &lt;p&gt;Our unique positioning has led to rapid growth in both number and size of customers. One of the secrets of our growth is that we invest heavily in customer success. Whereas our competitors see success as a cost center, we take pride in delivering expert martech and marketing reporting support throughout the entire customer lifecycle and we compensate accordingly.&lt;/p&gt;
    &lt;p&gt;Our strategy is paying off, with 200+ paying customers (including some of the most famous DTC brands) and strong investor backing. We are now looking for a senior Technical Customer Success Manager to help us scale to $10M+ ARR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Responsibilities&lt;/head&gt;
    &lt;p&gt;Be a marketing measurement expert: Advise customers on attribution, conversion tracking, and reporting strategies, positioning yourself as a trusted technical partner.&lt;/p&gt;
    &lt;p&gt;Technical support: Investigate and resolve conversion tracking and attribution issues reported through all channels, including email, Slack and in-app.&lt;/p&gt;
    &lt;p&gt;Onboard new customers: Own the customer onboarding end-to-end, driving them from initial implementation to real and lasting success.&lt;/p&gt;
    &lt;p&gt;Drive renewals: Take full ownership of renewal conversations, mitigating churn risk and implementing proactive retention strategies.&lt;/p&gt;
    &lt;p&gt;Champion customer needs: Surface trends and insights from collected customer feedback to the team at large to inform product roadmap.&lt;/p&gt;
    &lt;p&gt;Activate: Maximize the adoption of our product features and provide proactive, regular recommendations to get more out of the platform.&lt;/p&gt;
    &lt;p&gt;Expand customer contracts: Identify and execute expansion opportunities to increase account value.&lt;/p&gt;
    &lt;p&gt;Lead strategic projects: Improve the support experience and feature adoption.&lt;/p&gt;
    &lt;head rend="h3"&gt;You will thrive in this role if you&lt;/head&gt;
    &lt;p&gt;Have strong martech experience: Google Tag Manager, Meta Events Manager, Google Consent Mode and other pieces of the martech stack have no secrets for you.&lt;/p&gt;
    &lt;p&gt;Are curious and technical: You love understanding complex products deeply. Bonus points if you already love JS debugging, sifting through network requests or reasoning over attribution logic.&lt;/p&gt;
    &lt;p&gt;Thrive in ambiguity: You enjoy building processes from scratch and figuring things out without a playbook.&lt;/p&gt;
    &lt;p&gt;Are commercially minded: You know how to uncover customer needs and tie solutions to real business value.&lt;/p&gt;
    &lt;p&gt;Have advertising experience: You speak the language of a growth team, and have experience with Ads Managers, attribution and creative strategy.&lt;/p&gt;
    &lt;head rend="h3"&gt;This role is not for you if you&lt;/head&gt;
    &lt;p&gt;Do not want to become an expert: Our customers choose us because we deeply understand their technical challenges.&lt;/p&gt;
    &lt;p&gt;Prefer certainty over upside: There are no rigid and limited responsibilities here - we grant a lot of agency and expect a lot of accountability.&lt;/p&gt;
    &lt;p&gt;Don't like working hard: This role demands more commitment and agency than a typical success role.&lt;/p&gt;
    &lt;p&gt;Prefer remote over in-person: We believe being in-person helps us move faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we offer&lt;/head&gt;
    &lt;p&gt;Compensation: $155k - $217k + equity: 0.1% - 0.25%.&lt;/p&gt;
    &lt;p&gt;Career-defining opportunity to build the U.S. success function and work with the world's best DTC growth teams.&lt;/p&gt;
    &lt;p&gt;Private health, dental, and vision insurance.&lt;/p&gt;
    &lt;p&gt;Pension &amp;amp; 401k contributions.&lt;/p&gt;
    &lt;p&gt;Opportunity to work on a complex product that customers love - 35% of our users use us daily (!)&lt;/p&gt;
    &lt;head rend="h3"&gt;Interview process*&lt;/head&gt;
    &lt;p&gt;Application: We're looking to see how your skills and experience align with our needs.&lt;/p&gt;
    &lt;p&gt;Intro interview (30-min): Our goal is to learn more about what you are looking for in your next role, explore your motivations to join our team, why you would be a great fit, and answer questions about us.&lt;/p&gt;
    &lt;p&gt;Culture interview (45-min): We will walk through your experience and background in detail.&lt;/p&gt;
    &lt;p&gt;Case interview (1 hour): We will simulate a real customer situation.&lt;/p&gt;
    &lt;p&gt;Offer If everyone√¢s aligned, we√¢ll move quickly to make you an offer.&lt;/p&gt;
    &lt;p&gt;(*) can be done in 2 days, just flag to us that you want to do it fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;We raised $5.7M from some of the best investors&lt;/head&gt;
    &lt;head rend="h3"&gt;James Hawkins&lt;/head&gt;
    &lt;head rend="h3"&gt;Nicolas Dessaigne&lt;/head&gt;
    &lt;head rend="h2"&gt;What makes Converge unique&lt;/head&gt;
    &lt;head rend="h3"&gt;Ridiculously lean&lt;/head&gt;
    &lt;p&gt;We operate a &amp;gt;$1M ARR business with &amp;gt;200 customers with a team of just 9 people.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;You will not find a startup with this level of product-market-fit where you can join as employee #10.&lt;/p&gt;
    &lt;head rend="h3"&gt;Huge product surface&lt;/head&gt;
    &lt;p&gt;We compete with Segment, Fivetran, Google Tag Manager, Rockerbox, Looker, just to name a few.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Other startups give you ownership of a feature. At Converge, you get ownership over an entire product.&lt;/p&gt;
    &lt;head rend="h3"&gt;Customers rely on us&lt;/head&gt;
    &lt;p&gt;Converge sees 35% of its users daily, while this is only 13% for the average SaaS company.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Our customers will be excited by every feature you ship, and your impact will be felt immediately.&lt;/p&gt;
    &lt;head rend="h3"&gt;Real scale&lt;/head&gt;
    &lt;p&gt;We collect around 20M customer interactions per day and process ~$3B in GMV annually.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Even though you join early, this job comes with real engineering challenges.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we started&lt;/head&gt;
    &lt;head rend="h3"&gt;Did you know√¢¬¶&lt;/head&gt;
    &lt;p&gt;All co-founders have written code that has run in production as part of Converge.&lt;/p&gt;
    &lt;p&gt;We closed our first publicly traded company during our YC batch from our living room in San Francisco.&lt;/p&gt;
    &lt;p&gt;Thomas and Tiago (Founding Engineer) worked together when Thomas was just an intern.&lt;/p&gt;
    &lt;p&gt;Michel (Customer Success) was responsible for most of the incoming Converge Support tickets in his previous job as a freelance tracking consultant.&lt;/p&gt;
    &lt;p&gt;Thomas and Jan were best friends in high school, and Jan and Jerome met in their first year of college.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149849</guid><pubDate>Thu, 04 Dec 2025 17:00:37 +0000</pubDate></item></channel></rss>