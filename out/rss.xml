<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 11 Nov 2025 07:11:15 +0000</lastBuildDate><item><title>Writing your own BEAM</title><link>https://martin.janiczek.cz/2025/11/09/writing-your-own-beam.html</link><description>&lt;doc fingerprint="a8a0e650886e2ae0"&gt;
  &lt;main&gt;
    &lt;p&gt;This is my Code BEAM Europe 2025 talk, converted to a blogpost.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;EDIT 2025-11-10: Hacker News folks pointed out it might not be clear to everybody what BEAM is: it’s the virtual machine for languages like Erlang, Elixir and Gleam. See Wikipedia.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I was always fascinated with BEAM, how it allowed easy spawning of processes that didn’t share state, allowed for sending and selectively receiving messages, and linking to each other thus enabling creation of supervision trees.&lt;/p&gt;
    &lt;p&gt;It’s an interesting set of primitives that interact in a nice way, and are in my view responsible for much of the appeal of BEAM languages. I wanted to see how much it takes to support these primitives, and I set out to write my own toy MVP implementation of BEAM.&lt;/p&gt;
    &lt;p&gt;As a disclaimer, I haven’t read The BEAM Book yet, and how I do things might differ substantially from how the real BEAM does things. This is an exploration from first principles based on how I perceive BEAM from the outside, and doesn’t aim for truthfulness to the reference implementation, real world usefulness nor performance.&lt;/p&gt;
    &lt;p&gt;The below examples are written in Elm, but if you can express it in Elm, you can express it in anything (it’s purely functional so there’s no mutation, it’s single threaded and has no concurrency primitives, etc.).&lt;/p&gt;
    &lt;head rend="h2"&gt;AST representation&lt;/head&gt;
    &lt;p&gt;I will only be making the scheduler and its main loop, not a full-blown language or VM. This allows me to only keep a few hardcoded examples around and skip writing a parser, CLI and a bunch more parts that a real compiler would have.&lt;/p&gt;
    &lt;p&gt;In the interest of skipping as much work as possible, I’ll be using continuation passing style (CPS) for the example programs instead of the usual “list of statements” style:&lt;/p&gt;
    &lt;code&gt;-- ☑️ YES: continuations
type Program
    = End
    | Work Int K
    | Spawn Program KPid
    | Send Pid String K
    | Receive String K
    | Crash
    | Link Pid K

type alias K =
    () -&amp;gt; Program

type alias KPid =
    Pid -&amp;gt; Program

-- ❌ NO: list of statements
type Stmt
    = Let String Expr
    | Work Int
    | Spawn Program
    | Send Pid String
    | Receive String Program
    | Crash
    | Link Pid

type alias Program =
    List Stmt
&lt;/code&gt;
    &lt;p&gt;This means I don’t have to care about environments, bindings, scopes, return values, expressions and so on, as this will be handled by the continuation arguments in the host language:&lt;/p&gt;
    &lt;code&gt;ex5 : Program
ex5 =
    Spawn ex5Child       &amp;lt;| \childPid -&amp;gt;
    Send childPid "Ping" &amp;lt;| \() -&amp;gt;
    End

ex5Child =
    Work 10 &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;In case you’re having issues reading the &lt;code&gt;&amp;lt;|&lt;/code&gt; operator, you can imagine a pair of parentheses instead:&lt;/p&gt;
    &lt;code&gt;ex5 : Program
ex5 =
    Spawn ex5Child       (\childPid -&amp;gt;
    Send childPid "Ping" (\() -&amp;gt;
    End
    ))

ex5Child =
    Work 10 (\() -&amp;gt;
    End
    )
&lt;/code&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;End&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The continuations in all the non-terminal instructions force us to provide at least one terminal, otherwise we couldn’t write a valid &lt;code&gt;Program&lt;/code&gt; value.&lt;/p&gt;
    &lt;p&gt;Let’s then start by implement one of the terminals, &lt;code&gt;End&lt;/code&gt;. It’s a no-op, but it will allow me to show off the structure of the scheduler.&lt;/p&gt;
    &lt;code&gt;type Program =
    End

ex1 : Program
ex1 =
    End

type alias Scheduler =
    { program : Program }

init : Program -&amp;gt; Scheduler
init program =
    { program = program }

step : Scheduler -&amp;gt; Scheduler
step sch =
    case sch.program of
        End -&amp;gt; sch
&lt;/code&gt;
    &lt;p&gt;Try it online, or try the visualizer below:&lt;/p&gt;
    &lt;p&gt;Everything will revolve around this &lt;code&gt;Scheduler&lt;/code&gt; type and its &lt;code&gt;step&lt;/code&gt; function. Now let’s expand our capabilities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;Work&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Instead of wasting time implementing instructions for actual work (mathematic operators, function calls, etc.), let’s encompass this all with a dummy &lt;code&gt;Work&lt;/code&gt; instruction, holding the amount of work (in units that will start making sense soon) and a continuation with what to do after the work:&lt;/p&gt;
    &lt;code&gt;type Program
    = End
    -- Added:
    | Work Int K

type alias K =
    () -&amp;gt; Program

ex2 : Program
ex2 =
    Work 5 &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;The example holds a program that will “work” for 5 units of work then end.&lt;/p&gt;
    &lt;p&gt;We need to add this new instruction to our &lt;code&gt;step&lt;/code&gt; function:&lt;/p&gt;
    &lt;code&gt;step : Scheduler -&amp;gt; Scheduler
step sch =
    case sch.program of
        End -&amp;gt; sch
        -- Added:
        Work n k -&amp;gt; { sch | program = k () }
&lt;/code&gt;
    &lt;p&gt;For now we’ll just ignore how much work it’s supposed to be, and continue with the rest of the program (result of calling the continuation: &lt;code&gt;k ()&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Try it online, or try the visualizer below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;Spawn&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Let’s do something interesting! We’ll add a way to spawn other processes, thus making our programs concurrent.&lt;/p&gt;
    &lt;code&gt;type Program =
    -- ...
    | Spawn Program KPid

type alias KPid =
    Pid -&amp;gt; Program

type alias Pid =
    Int

ex3 : Program
ex3 =
    Work 5         &amp;lt;| \() -&amp;gt;
    Spawn ex3Child &amp;lt;| \childPid -&amp;gt;
    Work 5         &amp;lt;| \() -&amp;gt;
    End

ex3Child : Program
ex3Child =
    Work 10 &amp;lt;| \() -&amp;gt;
    Work 10 &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;Whenever we spawn another process, we’ll receive its PID in the continuation, which will be useful later for messaging and other tasks.&lt;/p&gt;
    &lt;p&gt;This marks a big change in our &lt;code&gt;Scheduler&lt;/code&gt;: suddenly we have to track multiple processes instead of just one!&lt;/p&gt;
    &lt;code&gt;type alias Scheduler =
    { processes : Dict Pid Proc
    , nextUnusedPid : Pid
    , readyQueue : Queue Pid
    }

type alias Proc =
    { program : Program }

init : Program -&amp;gt; Scheduler
init program =
    { processes = Dict.empty
    , nextUnusedPid = 0
    , readyQueue = Queue.empty
    }
        |&amp;gt; spawn program
        |&amp;gt; Tuple.first -- discard the spawned PID

spawn : Program -&amp;gt; Scheduler -&amp;gt; ( Scheduler, Pid )
spawn program sch =
    let pid = sch.nextUnusedPid in
    ( { sch
        | processes =
            sch.processes
                |&amp;gt; Dict.insert pid (initProc program)
        , nextUnusedPid = pid + 1
      }
        |&amp;gt; enqueue pid
    , pid
    )

initProc : Program -&amp;gt; Proc
initProc program =
    { program = program }

enqueue : Pid -&amp;gt; Scheduler -&amp;gt; Scheduler
enqueue pid sch =
    { sch
        | readyQueue =
            if List.member pid (Queue.toList sch.readyQueue)
            then sch.readyQueue
            else sch.readyQueue |&amp;gt; Queue.enqueue pid
    }
&lt;/code&gt;
    &lt;p&gt;We hold the processes in a &lt;code&gt;Dict&lt;/code&gt; collection now, there’s a bit of bookkeeping for incrementing PIDs, and a new concept: the “ready queue.”&lt;/p&gt;
    &lt;p&gt;This queue will tell our scheduler which process to run next. This means our &lt;code&gt;step&lt;/code&gt; function needs to change considerably: previously it was able to just pick the (only) program with &lt;code&gt;sch.program&lt;/code&gt;, but now it needs to pick a PID from the queue, then find it in the dictionary, then run it:&lt;/p&gt;
    &lt;code&gt;step : Scheduler -&amp;gt; Scheduler
step sch =
    case Queue.dequeue sch.readyQueue of
        Nothing -&amp;gt; sch
        Just ( pid, restOfQueue ) -&amp;gt;
            let newSch = { sch | readyQueue = restOfQueue } in
            case Dict.get pid newSch.processes of
                Nothing   -&amp;gt; newSch
                Just proc -&amp;gt; newSch |&amp;gt; stepInner pid proc

stepInner : Pid -&amp;gt; Proc -&amp;gt; Scheduler -&amp;gt; Scheduler
stepInner pid proc sch =
    case proc.program of
        End -&amp;gt; sch

        Work n k -&amp;gt;
            sch
                |&amp;gt; updateProc pid (setProgram (k ()))
                |&amp;gt; enqueue pid

updateProc : Pid -&amp;gt; (Proc -&amp;gt; Proc) -&amp;gt; Scheduler -&amp;gt; Scheduler
updateProc pid fn sch =
    { sch | processes =
        sch.processes
            |&amp;gt; Dict.update pid (Maybe.map fn)
    }

setProgram : Program -&amp;gt; Proc -&amp;gt; Proc
setProgram newProgram proc =
    { proc | program = newProgram }
&lt;/code&gt;
    &lt;p&gt;The specifics of &lt;code&gt;stepInner&lt;/code&gt; had to change as well: we can’t set the single &lt;code&gt;sch.program&lt;/code&gt; anymore, we need to update an entry for a PID in the processes dictionary.&lt;/p&gt;
    &lt;p&gt;Let’s not forget about the new instruction:&lt;/p&gt;
    &lt;code&gt;stepInner pid proc sch =
    -- ...
    Spawn childProgram kpid -&amp;gt;
        let ( schWithChild, childPid ) =
                sch |&amp;gt; spawn childProgram
        in schWithChild
               |&amp;gt; updateProc pid (setProgram (kpid childPid))
               |&amp;gt; enqueue pid
&lt;/code&gt;
    &lt;p&gt;We reuse the &lt;code&gt;spawn&lt;/code&gt; function from before. It gives us the child’s PID, which we can use to access the rest of the parent program via the continuation: &lt;code&gt;kpid childPid&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We need to remember to enqueue the parent again (the program given by the continuation hasn’t run yet); the child has already been enqueued in the &lt;code&gt;spawn&lt;/code&gt; function.&lt;/p&gt;
    &lt;p&gt;Try it online, or try the visualizer below.&lt;/p&gt;
    &lt;p&gt;Our scheduler now takes 7 steps to finish the whole program, which corresponds to the 7 instructions in our initial program.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reduction budget&lt;/head&gt;
    &lt;p&gt;Can you see any potential issues with our current Scheduler?&lt;/p&gt;
    &lt;p&gt;The concurrency we have implemented is cooperative: a started process won’t be stopped by the scheduler in the middle. Consider this program:&lt;/p&gt;
    &lt;code&gt;ex4 : Program
ex4 =
    Work 5         &amp;lt;| \() -&amp;gt;
    Spawn ex4Child &amp;lt;| \childPid -&amp;gt;
    Work 5         &amp;lt;| \() -&amp;gt;
    End

ex4Child : Program
ex4Child =
    Work 999 &amp;lt;| \() -&amp;gt; -- !!!
    Work 10  &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;This only differs from example 3 by the amount of work the child is doing. The parent can’t finish its tiny bit of work after the spawn until the child finishes its 999 units of work.&lt;/p&gt;
    &lt;p&gt;The way BEAM solves this is with a reduction budget: it creates an illusion of preemptive scheduling on top of the cooperative one by inserting yield points after every function call, decrementing its reduction budget in each, and once the budget reaches 0, the scheduler will pause the process and start another one from the queue.&lt;/p&gt;
    &lt;p&gt;This works surprisingly well: in BEAM languages, you iterate through lists via recursion → there’s a lot of function calls → a lot of yield points.&lt;/p&gt;
    &lt;p&gt;We’ll do something similar in our toy implementation: introduce a reduction budget, and make the &lt;code&gt;Work&lt;/code&gt; instruction only do as much “work” as the budget allows.&lt;/p&gt;
    &lt;code&gt;reductionBudget : Int
reductionBudget =
    7 -- BEAM sets this to 4000.

step : Scheduler -&amp;gt; Scheduler
step sch =
    -- ...
    sch |&amp;gt; stepInner pid proc {- added: -} reductionBudget

stepInner : Pid -&amp;gt; Proc -&amp;gt; Int -&amp;gt; Scheduler -&amp;gt; Scheduler
stepInner pid proc budget sch =
    if budget &amp;lt;= 0
    then sch
         |&amp;gt; setProc pid proc
         |&amp;gt; (if shouldEnqueue proc
             then enqueue pid
             else identity)
    else -- ...

shouldEnqueue : Proc -&amp;gt; Bool
shouldEnqueue proc =
    case proc.program of
        -- Optimization: if we ended up on `End`,
        -- we don't need to run again.
        End -&amp;gt; False
        Work _ _ -&amp;gt; True
        Spawn _ _ -&amp;gt; True

setProc : Pid -&amp;gt; Proc -&amp;gt; Scheduler -&amp;gt; Scheduler
setProc pid newProc sch =
    sch
        |&amp;gt; updateProc pid (\_ -&amp;gt; newProc)
&lt;/code&gt;
    &lt;p&gt;Above we’re dealing with the case where the process ran out of the budget. The scheduler will remember where it ended, re-enqueue it if there’s more work to do (if we’re not at the &lt;code&gt;End&lt;/code&gt; instruction), and stop the current step.&lt;/p&gt;
    &lt;p&gt;Let’s flesh out the rest of &lt;code&gt;stepInner&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    else
    let
        stop : Scheduler -&amp;gt; Scheduler
        stop sch_ =
            sch_ |&amp;gt; stepInner pid program 0

        continue : Program -&amp;gt; Int -&amp;gt; Scheduler -&amp;gt; Scheduler
        continue newProgram newBudget sch_ =
            sch_ |&amp;gt; stepInner pid newProgram newBudget
    in
    -- ...
&lt;/code&gt;
    &lt;p&gt;Here I’m making helpers for working with the budget. &lt;code&gt;stop&lt;/code&gt; sets the budget to 0 and recurses, so that we go straight to the &lt;code&gt;if budget &amp;lt;= 0 then ...&lt;/code&gt; code path.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;continue&lt;/code&gt; instead sets the budget to some arbitrary number we provided. Usually we’ll decrement the current budget by 1, but in case of &lt;code&gt;Work&lt;/code&gt; we’ll jump in larger increments.&lt;/p&gt;
    &lt;p&gt;Let’s use them:&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    in
    case program of
        End -&amp;gt; sch |&amp;gt; stop

        Spawn childProgram kpid -&amp;gt;
            let ( schWithChild, childPid ) =
                    sch |&amp;gt; spawn childProgram
            in schWithChild
                   |&amp;gt; continue (kpid childPid) (budget - 1)

        Work n k -&amp;gt;
            if n &amp;lt;= 0
            then sch |&amp;gt; enqueue pid
                     |&amp;gt; continue (k ()) budget
            else let workDone = min n budget
                     workRemaining = n - workDone
                     budgetRemaining = budget - workDone
                 in sch |&amp;gt; continue (Work workRemaining k)
                                    budgetRemaining
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;Work&lt;/code&gt; instruction now works completely differently: instead of doing all the work at once (going straight for &lt;code&gt;k ()&lt;/code&gt;), it now finally cares about the amount of work present.&lt;/p&gt;
    &lt;p&gt;We will only continue with &lt;code&gt;k ()&lt;/code&gt; if there’s no more work to be done (&lt;code&gt;n &amp;lt;= 0&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Otherwise we calculate how much work can be done, and update the remaining work and budget accordingly.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Budget&lt;/cell&gt;
        &lt;cell role="head"&gt;Work&lt;/cell&gt;
        &lt;cell role="head"&gt;Work done&lt;/cell&gt;
        &lt;cell role="head"&gt;Work remaining&lt;/cell&gt;
        &lt;cell role="head"&gt;Budget remaining&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Try it online, or try the visualizer below.&lt;/p&gt;
    &lt;p&gt;Take a look at the first few steps after the child spawns:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;PID 0 (parent)&lt;/cell&gt;
        &lt;cell role="head"&gt;PID 1 (child)&lt;/cell&gt;
        &lt;cell role="head"&gt;Ready queue&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Work 4&lt;/cell&gt;
        &lt;cell&gt;Work 999&lt;/cell&gt;
        &lt;cell&gt;1,0&lt;/cell&gt;
        &lt;cell&gt;PID 1 runs, 999 -&amp;gt; 992&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Work 4&lt;/cell&gt;
        &lt;cell&gt;Work 992&lt;/cell&gt;
        &lt;cell&gt;0,1&lt;/cell&gt;
        &lt;cell&gt;PID 0 runs, 4 -&amp;gt; 0 -&amp;gt; End&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;End&lt;/cell&gt;
        &lt;cell&gt;Work 992&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;PID 1 runs, 992 -&amp;gt; 985&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;End&lt;/cell&gt;
        &lt;cell&gt;Work 985&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;…&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Thus, even though the child has a lot of work to be done, the scheduler preempts and only lets it do the work in chunks of 7, and the parent process gets a chance to do some of its work as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;Send&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Spawning processes without letting them communicate is not very useful. It might help move computations off the main thread, but obviously we’ll want some inter-process communication eventually.&lt;/p&gt;
    &lt;p&gt;Let’s add a way to send messages to processes. (Receiving them will come later.)&lt;/p&gt;
    &lt;code&gt;type Program
    = -- ...
    | Send Pid String K

shouldEnqueue : Proc -&amp;gt; Bool
shouldEnqueue proc =
    -- ...
    Send _ _ _ -&amp;gt; True

ex5 : Program
ex5 =
    Spawn ex5Child       &amp;lt;| \childPid -&amp;gt;
    Send childPid "Ping" &amp;lt;| \() -&amp;gt;
    End

ex5Child : Program
ex5Child =
    Work 10 &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;To implement this &lt;code&gt;Send&lt;/code&gt; instruction, we’ll need to introduce the concept of mailboxes:&lt;/p&gt;
    &lt;code&gt;type alias Proc =
    { program : Program
    -- Added:
    , mailbox : Queue String
    }
&lt;/code&gt;
    &lt;p&gt;Sending a message will be done by putting the message into this mailbox. We can do that because we have access to the whole scheduler, we are not limited to just the current process’ resources:&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    Send destinationPid message k -&amp;gt;
        sch
            |&amp;gt; send destinationPid message
            |&amp;gt; continue (k ()) (budget - 1)

send : Pid -&amp;gt; String -&amp;gt; Scheduler -&amp;gt; Scheduler
send destinationPid message sch =
    sch
        |&amp;gt; updateProc destinationPid (enqueueMessage message)
        |&amp;gt; enqueue destinationPid

enqueueMessage : String -&amp;gt; Proc -&amp;gt; Proc
enqueueMessage message proc =
    { proc | mailbox = proc.mailbox |&amp;gt; Queue.enqueue message }
&lt;/code&gt;
    &lt;p&gt;When we send a message to a process, we also enqueue it to make sure it has a chance to process it. This will become important later, when processes go to sleep (ie. don’t enqueue) after not finding any interesting message for their selective receive. We’ll get there!&lt;/p&gt;
    &lt;p&gt;Try it online, or try the visualizer below.&lt;/p&gt;
    &lt;p&gt;The child has the message in its mailbox, but can’t react to it. Let’s fix that!&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;Receive&lt;/code&gt;&lt;/head&gt;
    &lt;code&gt;type Program
    = -- ...
    | Receive String K
&lt;/code&gt;
    &lt;p&gt;This is a substantial simplification from what the real BEAM needs to support: Erlang receive statement allows for multiple branches, pattern matching inside the branches, timeouts when there’s no interesting message present for a certain amount of time, and so on.&lt;/p&gt;
    &lt;p&gt;We will instead only support a single string message with no destructuring. The process won’t continue until this specific string is found in the mailbox.&lt;/p&gt;
    &lt;code&gt;ex6 : Program
ex6 =
    Spawn ex6Child       &amp;lt;| \childPid -&amp;gt;
    Send childPid "Ping" &amp;lt;| \() -&amp;gt;
    End

ex6Child : Program
ex6Child =
    Receive "Ping" &amp;lt;| \() -&amp;gt; 
    Work 10        &amp;lt;| \() -&amp;gt;
    End
&lt;/code&gt;
    &lt;p&gt;We can make an interesting optimization in the &lt;code&gt;shouldEnqueue&lt;/code&gt; function:&lt;/p&gt;
    &lt;code&gt;shouldEnqueue proc =
    -- ...
    -- Optimization: we don't need to `Receive`
    -- if there's no interesting message.
    Receive wantedMsg _ -&amp;gt;
        Queue.toList proc.mailbox
            |&amp;gt; List.any (\msg -&amp;gt; msg == wantedMsg)
&lt;/code&gt;
    &lt;p&gt;This means we won’t reenqueue a process at the end of &lt;code&gt;stepInner&lt;/code&gt; if it’s waiting for a message that’s not present in its mailbox. There’s no reason for the process to try again until a new message is received, so the process will instead go to sleep and wait to be woken up later in the &lt;code&gt;send&lt;/code&gt; function.&lt;/p&gt;
    &lt;p&gt;There’s a wall of code coming up, brace yourselves! When interpreting the &lt;code&gt;Receive&lt;/code&gt; instruction, we’ll go through messages until we find the wanted one. If we find it, remove it from the mailbox and use the continuation, otherwise go to sleep with the mailbox intact.&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    continue_ : Proc -&amp;gt; Int -&amp;gt; Scheduler -&amp;gt; Scheduler
    continue_ newProc newBudget sch_ =
        sch_ |&amp;gt; stepInner pid newProc newBudget
    -- ...
    Receive wantedMsg k -&amp;gt;
        let processMessages : List String -&amp;gt; Queue String -&amp;gt; Scheduler
            processMessages unmatchedStartRev restOfMailbox =
                case Queue.dequeue restOfMailbox of
                    -- NO MORE MSGS TO CHECK
                    Nothing -&amp;gt;
                        sch |&amp;gt; stop

                    Just ( msg, restOfMailboxWithoutThis ) -&amp;gt;
                        if msg == wantedMsg then
                            -- FOUND IT
                            let newMailbox =
                                  Queue.fromList
                                      (List.reverse unmatchedStartRev
                                          ++ Queue.toList restOfMailboxWithoutThis)
                            in
                                sch |&amp;gt; continue_
                                           (proc
                                               |&amp;gt; setMailbox newMailbox
                                               |&amp;gt; setProgram (k ())
                                           )
                                           (budget - 1)

                        else 
                            -- TRY NEXT
                            processMessages
                                 (msg :: unmatchedStartRev)
                                 restOfMailboxWithoutThis
        in
        processMessages [] proc.mailbox

setMailbox : Queue String -&amp;gt; Proc -&amp;gt; Proc
setMailbox newMailbox proc =
    { proc | mailbox = newMailbox }
&lt;/code&gt;
    &lt;p&gt;This code is not very elegant due to plucking a message from the middle of a queue, but it does what I described in the previous paragraph.&lt;/p&gt;
    &lt;p&gt;Try it online, or try the visualizer below.&lt;/p&gt;
    &lt;p&gt;You can see things have lined up nicely: process 1 has &lt;code&gt;"Ping"&lt;/code&gt; in its mailbox and also is about to try and &lt;code&gt;Receive "Ping"&lt;/code&gt;. In the next step the message is gone and the process is doing &lt;code&gt;Work&lt;/code&gt;. Success!&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction: &lt;code&gt;Crash&lt;/code&gt;, &lt;code&gt;Link&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;For the last piece of the puzzle, let’s look at the feature that gives rise to supervision trees: linking processes together.&lt;/p&gt;
    &lt;p&gt;Linking is bidirectional; the scheduler will send a system message to the other side of the link whenever a linked process exits (in our example, crashes). The receiving side can choose to react to this exit signal: respawn the other process? Crash ourselves? Log it somewhere and do cleanup?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: BEAM also has monitors. These are one-directional, and I’ll skip them in this blogpost.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;type Program
    = -- ...
    | Crash
    | Link Pid K

type alias Proc =
    { -- ...
    , links : Set Pid
    }

initProc program =
    { -- ...
    , links = Set.empty
    }

ex7 : Program
ex7 =
    Spawn ex7Child &amp;lt;| \childPid -&amp;gt;
    Link childPid  &amp;lt;| \() -&amp;gt;
    Receive ("CRASH: " ++ String.fromInt childPid) &amp;lt;| \() -&amp;gt;
    End

ex7Child : Program
ex7Child =
    Crash

shouldEnqueue proc =
    -- ...
    Crash    -&amp;gt; True
    Link _ _ -&amp;gt; True
&lt;/code&gt;
    &lt;p&gt;Why &lt;code&gt;Crash -&amp;gt; True&lt;/code&gt;? The &lt;code&gt;Crash&lt;/code&gt; instruction is a terminal, but it has work to do inside (sending the system messages), so we’ll enqueue it if it hasn’t run yet. (We’ll replace &lt;code&gt;Crash&lt;/code&gt; with &lt;code&gt;End&lt;/code&gt; after doing that work.)&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    Link linkedPid k -&amp;gt;
        sch
            |&amp;gt; link pid linkedPid
            |&amp;gt; continue (k ()) (budget - 1)

link : Pid -&amp;gt; Pid -&amp;gt; Scheduler -&amp;gt; Scheduler
link pid1 pid2 sch =
    sch
        |&amp;gt; updateProc pid1 (addLink pid2)
        |&amp;gt; updateProc pid2 (addLink pid1)

addLink : Pid -&amp;gt; Proc -&amp;gt; Proc
addLink pid proc =
    { proc | links = proc.links |&amp;gt; Set.insert pid }
&lt;/code&gt;
    &lt;p&gt;And &lt;code&gt;Crash&lt;/code&gt; is where we actually use &lt;code&gt;proc.links&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;stepInner pid proc budget sch =
    -- ...
    stop_ : Proc -&amp;gt; Scheduler -&amp;gt; Scheduler
    stop_ newProc sch_ =
        sch_ |&amp;gt; stepInner pid newProc 0
    -- ...
    Crash -&amp;gt;
        sch
            |&amp;gt; propagateCrashToLinks pid
            |&amp;gt; stop_ (proc |&amp;gt; setProgram End)

propagateCrashToLinks : Pid -&amp;gt; Scheduler -&amp;gt; Scheduler
propagateCrashToLinks pid sch =
    case Dict.get pid sch.processes of
        Nothing   -&amp;gt; sch
        Just proc -&amp;gt;
            proc.links
                |&amp;gt; Set.foldl
                    (\linkedPid accSch -&amp;gt;
                        accSch
                          |&amp;gt; send linkedPid
                                  ("CRASH: " ++ String.fromInt pid)
                    )
                    sch
&lt;/code&gt;
    &lt;p&gt;In a real-world interpreter, we’d distinguish between user messages and system messages by using an ADT, but for this toy implementation, the above will be enough.&lt;/p&gt;
    &lt;p&gt;Try it online, or try the visualizer below:&lt;/p&gt;
    &lt;p&gt;It works in the Ellie link above, but not in the visualizer. Why? Their reduction budget is different. The Ellie demo manages to run &lt;code&gt;Spawn&lt;/code&gt; and &lt;code&gt;Link&lt;/code&gt; without anything else running in between, but the visualizer has reduction budget of 1, and so the child &lt;code&gt;Crash&lt;/code&gt;es before the parent manages to &lt;code&gt;Link&lt;/code&gt; to it.&lt;/p&gt;
    &lt;p&gt;This can be fixed by making the instruction pair a single atomic instruction, and BEAM does this with the &lt;code&gt;spawn_link&lt;/code&gt; function. You can try it online or click the &lt;code&gt;Fix the problem&lt;/code&gt; button in the demo above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;And that’s all! We have implemented:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;spawning child processes&lt;/item&gt;
      &lt;item&gt;sending and selectively receiving messages&lt;/item&gt;
      &lt;item&gt;an illusion of preemptive scheduling on top of cooperative scheduling using a reduction budget&lt;/item&gt;
      &lt;item&gt;linking between processes, essentially adding hooks for when a related process stops for some reason&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These primitives combine together in nice ways, giving rise to BEAM’s reputation. I think they’re pretty neat, and I hope this toy implementation demystified them a little bit for you!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45867828</guid><pubDate>Sun, 09 Nov 2025 18:29:43 +0000</pubDate></item><item><title>Ask HN: What Are You Working On? (Nov 2025)</title><link>https://news.ycombinator.com/item?id=45869146</link><description>&lt;doc fingerprint="3758115369a43ff8"&gt;
  &lt;main&gt;
    &lt;p&gt;There are not many sites I whitelist for javascript, or even bookmark these day. Really glad I tried your game, it's fun and nicely executed. Well done to you both.&lt;/p&gt;
    &lt;p&gt;Really great! One of the things that Wordle did that I thought was very clever was having a copy and paste social media preview of how you did. It might be worth adding that for vitality... you could even add an image preview with Open Graph meta tags if you were clever.&lt;/p&gt;
    &lt;p&gt;Thanks, yeah I’d like to improve this. There is a “share” option when you complete a level but I don’t think it works as well as Wordle’s in terms of storytelling.&lt;/p&gt;
    &lt;p&gt;This is something I've gone and forth on for https://threeemojis.com/ as well. I think it's pretty hard to generate a story of a complicated puzzle, in part because the person you are sending it to doesn't have an idea of the terrain you were playing on and so kind of doesn't care. I do see some people doing custom share images with their puzzles, but it doesn't seem to have caught on so much.&lt;/p&gt;
    &lt;p&gt;Good fun. I discovered a big though. I could not yet reproduce it, but I managed to somehow have letters glitch out of the Tetris shapes they are in. When I move the tiles or rotate them, the letters are back where they should be. So it's not game breaking, but seems to happen in some case. At first I suspected, that it was because my phone was locked in between, but I tried that and when locking it manually, that bug did not happen. So no idea, sorry!&lt;/p&gt;
    &lt;p&gt;Ahh dang I’ve had a few people report this but I haven’t been able to reproduce it. I think it does have something to do with locking your screen and coming back but I haven’t figured it out yet&lt;/p&gt;
    &lt;p&gt;Nice! Some feedback from my wife, who is into all manner of word games: she found it a little bit brute-forcey: needing to try all different combinations in order to get the right configuration of the word. In contrast to a crossword where there is already a layout, which gives her a hint for how to proceed with the rest.&lt;/p&gt;
    &lt;p&gt;(She finished today's puzzle, and I gave up.) From a UI perspective it is very slick - very smooth, and I like how it kind of "gets" what you were trying to do when providing corrections/hints.&lt;/p&gt;
    &lt;p&gt;I really enjoyed this! wondering about a possible "scratch" section or larger area - found myself spending a lot of time moving pieces around to get enough space&lt;/p&gt;
    &lt;p&gt;This game was Show HNed two times in ten days, [1][2], but unfortunately, it didn't get as much attention as it should! Ironically, this current thread has already gained almost double the comments from both submissions combined!&lt;/p&gt;
    &lt;p&gt;I whish you best of luck to succeed in your journey.&lt;/p&gt;
    &lt;p&gt;I saw your Show HN post a few weeks ago! Really appreciate the smoothness of your UI and the simplicity of your onboarding, I see how much you have dialed in. I've been working on a daily puzzle game too (it's getting there...), maybe you'd enjoy it https://slab17.com/&lt;/p&gt;
    &lt;p&gt;I solved the first puzzle: -Congratulations! -You solved Paprika with 18 slabs&lt;/p&gt;
    &lt;p&gt;But this was unclear: -You've solved 0 puzzles! -Reveal Rule -Next Puzzle -View Archive -You still have 2 guesses left. Finish guessing before revealing the rule if you're feeling brave!&lt;/p&gt;
    &lt;p&gt;I have to do 2 more guesses before I can reveal the rule that I already figured out?&lt;/p&gt;
    &lt;p&gt;This is really fun — have you played with making the tile position opinionated (not agnostic)?&lt;/p&gt;
    &lt;p&gt;i wonder if have the clues point to a starting square (e.g., "E5") would be better than the current "reveal" aid. The spatial information would become more helpful toward the end when the player is dealing with the words they need help on.&lt;/p&gt;
    &lt;p&gt;Nice! What might be a nice lesser 'clue' to simply revealing a word is highlighting letter(s) on the board that are part of it? Favouring maybe highlighting letters that are contiguous with a blue bit?&lt;/p&gt;
    &lt;p&gt;I showcased at the Portland Retro Gaming Expo with the Portland Indie Game squad and that got me some players. I also shared it on my various personal social medias. The neighborhood board game store let me put up a poster!&lt;/p&gt;
    &lt;p&gt;I’m also hoping that organic sharing will drive growth.&lt;/p&gt;
    &lt;p&gt;This HN comment has been some of my most successful marketing so far. Around 2400 people from HN have visited since I posted!&lt;/p&gt;
    &lt;p&gt;Working on UPSS (Universal Prompt Security Standard) - an open-source framework for managing LLM prompts securely at scale.&lt;/p&gt;
    &lt;p&gt;The problem: Most organizations hardcode prompts directly into application code, creating security vulnerabilities (90% prompt injection success rate in typical deployments), operational inefficiency (3-5 day deployment cycles for simple prompt changes), and compliance gaps (insufficient audit trails for SOC 2, ISO 27001).&lt;/p&gt;
    &lt;p&gt;Our approach: - Externalize prompts from code with secure configuration management - Implement modular middleware architecture with composable security primitives (BasicSanitizer, LightweightAuditor, SimpleRBAC, InputValidator) - Provide complete audit trails and version control with approval workflows - Support both startups and enterprises with practical, not theoretical, security&lt;/p&gt;
    &lt;p&gt;Version 1.1.0 is now available with Python implementation and examples for Node.js, Java, Go, Rust.&lt;/p&gt;
    &lt;p&gt;We're actively looking for community contributions - security primitives, framework integrations, language implementations, and adoption stories.&lt;/p&gt;
    &lt;p&gt;https://cafe.io It is a DNS service for AWS EC2 to keep the ever changing IPs when you cannot use the Elastic IP like ASG or when you don't want to install any third party clients to your instances.&lt;/p&gt;
    &lt;p&gt;It fetches the IPs regularly via AWS API and assign them to fixed subdomains.&lt;/p&gt;
    &lt;p&gt;After taking a break from frontend development from a large corporate client. I wanted to get into iOS development to see how mature SwiftUI has become and finally get a chance to build my first iOS app. The result of that: PeekCard - https://peekcard.app&lt;/p&gt;
    &lt;p&gt;A simple iOS app for scanning (almost any) barcode and storing in the app, or adding it to your home via a widget. No tracking, no subscriptions, just a simple free app that is pretty simple to use and does the one thing I want it to do.&lt;/p&gt;
    &lt;p&gt;Building my own software has been super refreshing compared to working within a large organization. I really enjoy the path of just developing and it is fun to get into something different than React/TypeScript and Java. It was also really interesting to go through the process of publishing the app in the Apple App Store. Heard so many bad stories, but it was OK. Definitely not great, but not as bad as I was expecting.&lt;/p&gt;
    &lt;p&gt;Two learnings from this so far:&lt;/p&gt;
    &lt;p&gt;1. I do not think that I would want to do any Swift development in a large organization. Super fun to build indie style, but I can't imagine having to support 5+ years of old iOS versions. 2. I ditched most social media a long time ago and if you do not have any personal promotion channel, you are super limited into reaching any potential users for your software. I still do not know how to deal with this; I do not have any ambition to go back into building a social following. I just like building the "thing", but just building it is definitely not enough to get any traction.&lt;/p&gt;
    &lt;p&gt;For the current project I am building another iOS app, a bit more complex, also something I want to use myself. I was considering building with React Native, but ditched that plan because when I am building for myself, there would (I think) be a lot of overhead in testing Android.&lt;/p&gt;
    &lt;p&gt;For now I really like what I am doing, but financially I think I should consider going back to Java/Scala or React dev for a corporate client :-|.&lt;/p&gt;
    &lt;p&gt;I was getting a little bored of retrocomputing discourse being so centered on gaming, so I'm exploring the productivity software of the 8/16-bit era. I put real effort into learning and using the programs, giving my light-hearted but heartfelt assessment of its form and function for both its time and today.&lt;/p&gt;
    &lt;p&gt;Using the software inevitably gets me thinking about other things, and I explore those threads as well. For example, "Superbase on the C64" also discusses the legacy and promise of "the paperless office." A couple of other posts got some nice traction here on HN, notably "Deluxe Paint on the Amiga" and "VisiCalc on the Apple 2".&lt;/p&gt;
    &lt;p&gt;I'm hoping to build a strong monthly readership, so I'm putting in the work. It's been up for two months and five posts now, with a new one coming at the end of this week.&lt;/p&gt;
    &lt;p&gt;That's interesting. I agree that outside of gaming you really don't see much being done with the old systems.&lt;/p&gt;
    &lt;p&gt;My first job out of college was with a tiny, now-defunct company that built simple I/O hardware for 8-bit systems. One of the "side products" was a MacPaint clone for the Radio Shack Color Computer II called CoCoMax. We didn't write it: AFAIK, the programmer for the original version contacted the company and asked if they wanted to buy it and pay him royalties. He later went off and built an even more successful product used in TV stations called the Video Toaster. Side product or not, CoCoMax was a cash cow!&lt;/p&gt;
    &lt;p&gt;On the heels of that success, another programmer who'd written a more advanced version for the Color Computer 3 offered the same deal. From what I recall, they both made buttloads of money from their royalties.&lt;/p&gt;
    &lt;p&gt;Sometimes I wish I had kept some of that old hardware &amp;amp; software, but it's long gone.&lt;/p&gt;
    &lt;p&gt;I think this software archaeology / history-keeping is really important. Keep up the good work. These paragraphs resonate with me:&lt;/p&gt;
    &lt;p&gt;&amp;gt; There is utility in those old tools and interesting ideas to be mined. Recently I stumbled across something that by all accounts should have set the world on fire, but whose ideas needed more time to germinate before blossoming much later. Discoveries like this are not just nostalgic “what ifs” to opine wistfully upon, they can be dormant seeds of the future.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Computing moves at such an unrelenting pace, those seeds may lie dormant for any number of reasons: bad marketing, released on a dying platform, too expensive, or even too large a mental leap for the public to “get” at the time. I see this blog as a way to explore the history of the work tools we use every day. I don’t do this out of misty-eyed sentimentality, but rather pragmatic curiosity. The past isn’t sacred, but it is still useful.&lt;/p&gt;
    &lt;p&gt;What's your research process? Do you use lots of Internet Archive material? Do you reference any personal artifacts i.e. old hardware or documentation laying around? Any interviewing?&lt;/p&gt;
    &lt;p&gt;Thanks for the kind feedback, and I'm happy you felt resonance with those words. I use tons of Internet Archive material, but also stuff from various retro enthusiast sites which focus on specific hardware platforms. Lots of books, I look through YouTube for interviews, and include my own personal history with the machines and genres (I don't want the blog to read like a passionless how-to manual). If I had the physical space for a hardware collection I'd do that, but alas. No interviewing of my own, just research into existing interviews up to present day. The main point is really to let the software speak for itself and see if it and I can be friends.&lt;/p&gt;
    &lt;p&gt;Thanks! I don't actually know anything about how Ghost blogging platform interacts with RSS feeds, but I get a small amount of traffic from personal aggregation services. I guess I kind of thought RSS is enabled, but I don't use it so I honestly don't know. I'll look into it and see if there's some setting or toggle switch somewhere I need to flip.&lt;/p&gt;
    &lt;p&gt;That worked for you? I was having a devil of a time getting Feedreader to bring in that feed. I also had never touched Feedreader until last night and might have done something dumb. Inoreader did bring in the feed, but only after I "tricked it" (?) by doing a search for the feed; it wouldn't accept the rss URL. It all felt very mysterious and opaque.&lt;/p&gt;
    &lt;p&gt;I got word in the Ghost forums that there may also be an RSS feed bug, which I'll look into and see if that applies to this case.&lt;/p&gt;
    &lt;p&gt;Currently working on a take on Pokémon GO + Pokémon Snap but for birding. The goal is to explore your neighborhood, find birds, take good photos of them all. Next month, I'll be doing an event to find a rare bird, excited to see how it goes!&lt;/p&gt;
    &lt;p&gt;Nice work. I liked the instant pdf viewer. Kudos for your efforts.&lt;/p&gt;
    &lt;p&gt;Only thing I would suggest is, to support different tax formats (or provide an ability to fill custom tax format name that applies to the whole invoice). Right now, it is largely VAT. In some countries, it may not be relevant.&lt;/p&gt;
    &lt;p&gt;(Having said that, as a work around, currently anyone can use Notes field to fill custom tax details and hide all VAT related fields.)&lt;/p&gt;
    &lt;p&gt;The interface is optimized to let you quickly explore and tweak multiple tints/shades at once so you can customize all colors exactly how you want e.g. try dragging vertically through the saturation curve in one motion to edit all the tints/shades at once, or shift whole curves horizontally by dragging between the dots on a curve.&lt;/p&gt;
    &lt;p&gt;It uses the HSLuv color space, where (unlike say HSL) the WCAG contrast stays the same when you change the hue and saturation sliders. This makes it much easier to explore accessible colors choices as you know only changes to the lightness slider will impact the contrast. You can also switch from the WCAG2 contrast checker to using APCA, which is meant to correct for inaccuracies in WCAG2, such as it being too forgiving for dark mode color combos.&lt;/p&gt;
    &lt;p&gt;Note the mobile version is more of a preview and the desktop version has more features.&lt;/p&gt;
    &lt;p&gt;I probably need to add something like a tutorial as there's a lot going on, but I've added more hints and tooltips recently. Open to feedback on what's initially confusing and what changes might help!&lt;/p&gt;
    &lt;p&gt;I'd also keen to hear from people who are interested in accessibility but don't know much about it too. I've tried to explain the WCAG contrast rules in the simplest way I can (interactively, via the live mockup example on the right and contrast indicator icons that appear on the left) but there's quite a lot to cover.&lt;/p&gt;
    &lt;p&gt;An AI (not LLM, but image-based one) based tool which transforms photos into visa compliant photos.&lt;/p&gt;
    &lt;p&gt;You take a selfie, pick document type (China Visa online, Green Card lottery, etc) and the tool knows what size it should be, head height, shoulders position and other requirements. AI is used to detect head position, emotions, objects and other details to provide better recommendations&lt;/p&gt;
    &lt;p&gt;I think by this point everyone that is learning a language knows that immersion is very important, however a problem I've had myself is that the content that interests me is beyond my reach, and the content that is within reach doesn't interest me.&lt;/p&gt;
    &lt;p&gt;This is my attempt at doing something to remediate that. You select the content you want, and I create a personalized study plan to learn the most important words to achieve a target % of understanding. Then I generate a short story each week for your particular level containing the new words in the context of your content.&lt;/p&gt;
    &lt;p&gt;The idea is to bring the content you want to learn to your level so you can watch what you want to watch.&lt;/p&gt;
    &lt;p&gt;Building Valori, a Python-native vector database. It’s basically Lego blocks for embeddings: storage, indexing, quantization — all modular, all hackable. The goal? Let anyone plug in their own models and search pipelines without touching C++.&lt;/p&gt;
    &lt;p&gt;Working on cross-flock discovery in sanctum [1] so I can cut a 1.0 release hopefully before Christmas.&lt;/p&gt;
    &lt;p&gt;I am always looking for more people to test and play with it or even review the code. We've got a nice little user community going.&lt;/p&gt;
    &lt;p&gt;Usually this comments drowns in the crowd of the massive amount of awesome stuff people are building, but if you find sanctum useful, hit me up. Good things are happening.&lt;/p&gt;
    &lt;p&gt;We have been building https://finbodhi.com/ a local-first browser app (PWA) for personal finance, based on double-entry accounting.&lt;/p&gt;
    &lt;p&gt;FinBodhi uses double entry so complicated set of transactions and accounts can be modeled (which happen often enough in users financial journey). We wrote about double-entry here: https://finbodhi.com/docs/understanding-double-entry&lt;/p&gt;
    &lt;p&gt;We do use online services like firebase for auth, and some service to fetch commodity prices etc. But all your financial data is on your system (we use sqlite over opfs, in browser). For synching across devices, that data is encrypted with your key before it leaves your device. You can backup the data locally (if you are using chrome) and/or to your dropbox. It's designed so that we (the people building it) can't access your data.&lt;/p&gt;
    &lt;p&gt;There are many more features, like multi-currency, visualizations, a sheet to use your data to do complex calculations like taxes, planning for your future etc.&lt;/p&gt;
    &lt;p&gt;Feel free to try it out with the demo account (no sign-in required). Note: app doesn't work in Firefox private mode.&lt;/p&gt;
    &lt;p&gt;Import is done locally. No 3rd party is involved. We have build custom importer. e.g you can import a csv and map it's columns to what we need internally. We also allow some logic in importer. E.g. to figure if a row is credit or debit. etc. It should be feasible to import most csv statements. PDFs and Excels should also work, except for some complicated cases where a transaction is spread across multiple rows.&lt;/p&gt;
    &lt;p&gt;There are a few custom importers also, for indian context.&lt;/p&gt;
    &lt;p&gt;After ChatGPT Atlas came out I thought it would be fun to find UI patterns that AI browsers couldn't figure out like multiple download buttons, hidden unsubscribe buttons, etc. So I created 7 levels of web dark patterns for AI browsers. You can try it yourself if you want:&lt;/p&gt;
    &lt;p&gt;I found Atlas can get through most patterns, so I created an even more unhinged one (job application form) that shifts the interface and flashes content.&lt;/p&gt;
    &lt;p&gt;Don't take it too seriously as actually testing AI browsers, it just a fun side project. I documented the patterns here: https://codinhood.com/anti-ai-ui/about&lt;/p&gt;
    &lt;p&gt;I'm starting to shift my energies towards building more hardware and less web/mobile apps for side projects.&lt;/p&gt;
    &lt;p&gt;I'm currently working on Dice of Sending - for when you want to roll physical dice but you play DND online. This is mostly just for fun with my DND group.&lt;/p&gt;
    &lt;p&gt;I'm working on Fillvisa.com - a free, browser-based tool that lets you fill complex U.S. immigration forms (like DS-160, AR-11, I-90, etc.) entirely in your browser.&lt;/p&gt;
    &lt;p&gt;It mimics the official USCIS forms but autosaves locally, validates inputs, and lets you download a ready-to-submit PDF - no signup, no uploads, no tracking.&lt;/p&gt;
    &lt;p&gt;It’s meant for travelers and immigrants who just need to fill a form once, and as a side effect, it’s become a great acquisition funnel for my paid B2B product, VisaSimplify, which helps immigration lawyers automate client intake and PDF mapping.&lt;/p&gt;
    &lt;p&gt;My friend had a cute baby boy and mentioned difficulty in finding children's storybooks in Spanish.&lt;/p&gt;
    &lt;p&gt;Challenge accepted:&lt;/p&gt;
    &lt;p&gt;I built an AI generated multilingual storybook, just to see if it would work.&lt;/p&gt;
    &lt;p&gt;Tap or click the little monster to have it read to you.&lt;/p&gt;
    &lt;p&gt;Local LLM generated the story, stable-diffusion generated the images, AI converted text to speech in two languages: English and Spanish ( could easily do many more languages ).&lt;/p&gt;
    &lt;p&gt;I "filled the app out" by adding a simple landing page placeholder, login page and "library" page.&lt;/p&gt;
    &lt;p&gt;Not very phone friendly, was made for her iPad.&lt;/p&gt;
    &lt;p&gt;Just click login to move on, as it is currently not connected to a backend.&lt;/p&gt;
    &lt;p&gt;Only the second book currently has a story, the others are placeholder templates.&lt;/p&gt;
    &lt;p&gt;Cool. This concept is useful for adult language learners also. Depending on the language you are learning it can be very difficult to find reading material in the age 5 - 10 range to practice with.&lt;/p&gt;
    &lt;p&gt;Discovered in-door bouldering / rock climbing and now go 3x a week, am absolutely loving it! Because of that, I haven't really worked on any side projects in a while. Perhaps I don't need to? My job advances me plenty in my field, but it is a bit of a bitter-sweet feeling in a sense, like maybe I should try to squeeze more out of my free time somehow.&lt;/p&gt;
    &lt;p&gt;I climb a lot! (Actually currently sitting on Big Sur ledge on el cap posting this). It cuts into my free time programming for sure, but imo super worth it! Enjoy it, it’s a wonderful hobby.&lt;/p&gt;
    &lt;p&gt;I’m replying from the cold east coast (from the edge of a wood chair in a lovely iykyk type of restaurant) to a human posting from el cap on hn; We have achieved peak technology. Oh yeah, I’m working on urban logistics, powered by AI.&lt;/p&gt;
    &lt;p&gt;I’ve been hesitant for fear of injury harming the ability to type, but might give it a go in the spring. Thanks for mentioning this I’m inspired to try it finally.&lt;/p&gt;
    &lt;p&gt;I struggled with hand and wrist pain for years from spending too much time at a computer. I did physiotherapy for years and while it helped me manage pain, I was never able to truly build enough strength to get ahead of it until I started bouldering. I took it very slowly—I spent months on very easy problems—but because it was so much fun, I kept going back. Initially, I would only go on Saturday mornings, so I had the full weekend to recover before jumping back into the work week on Monday. After a two or three months of that, I was able to climb anytime I wished. I'm still not a particularly advanced climber, and I typically only go once per week, but I am still slowly progressing, and I absolutely love it.&lt;/p&gt;
    &lt;p&gt;Couple things to avoid finger injuries: go easy on one- and two-finger pockets, use an open crimp whenever possible (all finger joints are bent the normal direction, and your palm/thumb aren't really involved), and don't bother with the hangboard or campus board for the first ~year.&lt;/p&gt;
    &lt;p&gt;I wouldn't worry about it too much though - almost all of the people I know with finger injuries were trying to push into really being competitive climbers, not just doing it casually for fun/fitness.&lt;/p&gt;
    &lt;p&gt;Oh also to keep from tearing your skin don't climb tired. (That won't keep you from typing, it's just painful.)&lt;/p&gt;
    &lt;p&gt;I'd like to add to this that do not make any food with chilli peppers like habanero or such if you just came from the gym with torn skin. I found out the hard way.&lt;/p&gt;
    &lt;p&gt;I’ve been climbing for 20 years and it’s the thing that prevents RSI for me and makes it possible to use a computer too much :). Certainly possible to injure fingers but would be a very rare climbing injury that would threaten coding.&lt;/p&gt;
    &lt;p&gt;Climbing easy routes in a gym is pretty low impact. It’s only when you start to move into really hard crimps or slopers where you’ll hurt yourself. I was a climber bum for years and have climbed crazy stuff around the world and never hurt myself to where I couldn’t type. A lot of bloody tape, but still able to type.&lt;/p&gt;
    &lt;p&gt;Try top rope climbing! Bouldering is injury prone because every fall is a ground fall. With top rope climbing you should never hit the ground so way less injury prone.&lt;/p&gt;
    &lt;p&gt;I love the intense concentration for martial arts, but I had to stop because of this.&lt;/p&gt;
    &lt;p&gt;I never had a serious injury. Instead it would be minor injuries, that would make my ring finger 20% less responsive, that would totally mess up my typing cadence.&lt;/p&gt;
    &lt;p&gt;I tried capoeira, a non-contact martial art, for a while. This wasn’t as good for me as Taekwondo.&lt;/p&gt;
    &lt;p&gt;A few of my recent favorites: - swim lap counter in html/JS that uses the camera to watch you swim and count laps/timing - video recorder that records your window/desktop and uploads a file to S3 - video conferencing app that allows a 2 year to click on a family member face and initiates a video conference using webRTC, STUN, and browser audio/video capture with automatic bandwidth adjustments (works on all platforms with pure HTML/JS). - CUDA based ray tracer with HTML UI that can trace over 2m rays per second on my laptop for scientific study, allowing real-time display of optical parts. - chat front-end for image models like gemini-pro and openai that take other images and text as references and generate a big library of options to chose from in seconds, I've been using photoshop for decades but I tend to use this more now.&lt;/p&gt;
    &lt;p&gt;I'm curious if you mean they're running a raytracer on the back end, and you interact with an HTML UI, or if it runs browserside, maybe via WASM. AFAIK CUDA isn't directly compilable to WASM (yet?)&lt;/p&gt;
    &lt;p&gt;I have a node middleman that proxies request from an HTML/JS front end to a native cuda process using web sockets. To support multiple windows, the node process process provides communication between two browser windows. This lets me have render a model using 3JS in one window and a ray traced version in another window.&lt;/p&gt;
    &lt;p&gt;Thanks for the encouragement. I do plan to make more of them open source, in the past it's been a bit of burden to document, test, and fix bugs before publishing but for some projects AI can do that for you now.&lt;/p&gt;
    &lt;p&gt;One project I did publish: https://github.com/jclarkcom/ble_proxy This turns your cell phone into a network proxy, but using BLE so the phone can be connected to a Wifi network (hotel, plane, etc). It's pretty slow, but in some cases you just need a little bit of data to work. I made it on a plane ride where my cellphone had data but my laptop didn't.&lt;/p&gt;
    &lt;p&gt;Simple feedback collector. Something I end up building in every project, so why not built it once and productise even just for myself. Still building out the dashboard, some clustering, and automated PRs (by Claude Code)&lt;/p&gt;
    &lt;p&gt;It's an explorable database of films, TV shows, books and board games based around their historical setting: where and when the thing is set. It's been incredibly complex and interesting getting the (messy) data, making sense of it and trying to design a UI to explore it.&lt;/p&gt;
    &lt;p&gt;Yeah, that's a whole different thing. I saw this map once that showed places in California and how they were used to film various locations around the world. Turns out LA is very well situated.&lt;/p&gt;
    &lt;p&gt;I've been working on a 3D voxel-based game engine for like 10 years in my spare time. At this point it's getting pretty close to being shadertoy for voxels.&lt;/p&gt;
    &lt;p&gt;I also wrote a metaprogramming language which generates a lot of the editor UI for the engine. It's a bespoke C parser that supports a small subset of C++, which is exposed to the user through a 'scripting-like' language you embed directly in your source files. I wrote it as a replacement for C++ templates and in my completely unbiased opinion it is WAY better.&lt;/p&gt;
    &lt;p&gt;Fuck.. that's a hard question. I'm almost always trying to push at least one of three boundaries; voxel engine techniques, engine performance, my mechanical programming skill. Trying to push those boundaries, often in tandem or tridem, is always hard. Different jobs are often hard for different reasons, but overall it's been a difficult project for most of it's existence. That said, doing hard projects is what I enjoy, and it's a great feeling when you sit down to, for example, optimize something, and end up making it 20x faster!&lt;/p&gt;
    &lt;p&gt;&amp;gt; What motivated you to attempt creating this?&lt;/p&gt;
    &lt;p&gt;It started out as a learning exercise; a safe space where I could just 'fuck around and find out'. When I started, I never expected to spend nearly as much time on it as I have.&lt;/p&gt;
    &lt;p&gt;Started work on a project to put local history on a map. If I go somewhere I would ideally want to just open this webapp and immediately get presented with cool or interesting history that happened close by.&lt;/p&gt;
    &lt;p&gt;Maybe it's a story about named local fishermen from the early 1900s, with pictures, the history of a statue and videos of the process, or the state of a graffiti wall over time.&lt;/p&gt;
    &lt;p&gt;Currently in a phase of UI development and testing, and historical societies outreach for collaboration. It might stall and just fizzle into nothing, or it might be something cool.&lt;/p&gt;
    &lt;p&gt;Also still doing https://wheretodrink.beer, but haven't added anything of note since playing on this other project.&lt;/p&gt;
    &lt;p&gt;Ever since I discovered Gypspy nearly a decade ago (now Guidealong https://guidealong.com/) - I've been dreaming of an open source app that'd pull local history from sources like Wikipedia, those roadside historical signs, etc., and narrate as you drive.&lt;/p&gt;
    &lt;p&gt;https://autio.com/ is similar - but obviously not open source, and more limited.&lt;/p&gt;
    &lt;p&gt;It seems like it could even tailor itself to what an individual user is interested in, and with AI - could turn more "dry" encyclopedia-type information into more compelling narratives. With some kind of route planning software, you could even pre-plan your trips ahead of time and select the things you're interested in.&lt;/p&gt;
    &lt;p&gt;Obviously not what you're building, but something related that's been clunking around in the back of my head for a while.&lt;/p&gt;
    &lt;p&gt;Yeah, that's cool. Currently tangential, but conceptually not something that would be completely out of scope in the end. I'm planning to use machine translations, text-to-speech, and multi modal generative models for accessibility already. There's also an idea for baking in GPS audio tours. Obviously depends on sourcing some quality content first&lt;/p&gt;
    &lt;p&gt;When you say open source is it so you could self host it, use your "own" models, and curate your own datasets? or some other reasons? I could see a future where a lot of the project could potentially be open sourced and work with any defined geojson API.&lt;/p&gt;
    &lt;p&gt;Open source was the wrong term (though that would be fine).&lt;/p&gt;
    &lt;p&gt;I meant community-sourced. Some kind of community where local "experts" or history enthusiasts could contribute info.&lt;/p&gt;
    &lt;p&gt;AKA - invite a local or regional historical society to contribute data for their region, with the benefit that they could then easily generate a regional tour map/route/recommendation.&lt;/p&gt;
    &lt;p&gt;Built something similar almost a year ago during the holidays [1]. Open-source if you want to check it out [2]. I use the mobile app version from time to time when I'm going on walking adventures around the city.&lt;/p&gt;
    &lt;p&gt;Related to wheretodrink.beer, I just launched a rough version of: https://www.nomnominees.com/. A site focused on finding award-winning breweries/restaurants to check out.&lt;/p&gt;
    &lt;p&gt;I’ve been working on https://canine.sh which is a free, open source Heroku alternative for 2 years now.&lt;/p&gt;
    &lt;p&gt;It’s exactly the product I wish I had when I started my previous company. Running on PaaS is incredible for devex but the pricing is bonkers, and the vendor lock in makes it really hard to deal with annual price increases. We spent close to 400k / year for just 128GB combined fleet in our last startup on Heroku.&lt;/p&gt;
    &lt;p&gt;Canine tries to get the best of both worlds: developer friendly PaaS with no lockin or price gouging.&lt;/p&gt;
    &lt;p&gt;Just added build packs as a build option recently.&lt;/p&gt;
    &lt;p&gt;Also got a sponsorship from the portainer folks which lets me work on this close to full time&lt;/p&gt;
    &lt;p&gt;Hoping this saves someone the headache I had two years ago.&lt;/p&gt;
    &lt;p&gt;Each player drafts cards that represent ways you can spend your limited time on earth to gather resources (wisdom, gold, and virtue) to complete your own personal player board (your hierarchy of needs) with the goal of reaching self-actualization before other players. However, you can still win without becoming self-actualized, if you complete more hidden quests (which can only be discarded by the "therapy session" card).&lt;/p&gt;
    &lt;p&gt;I have to say, i love this. The name is fantastic and the whole concept. It's got a very Game of Life or Monopoly feel where you've just taken the fundamentals of something in society and turned it into a game instead of adding an additional story on top. I really like it.&lt;/p&gt;
    &lt;p&gt;My one comment would be, I think you need to change the branding a little bit. It's a bit too close to Magic the Gathering, and this feels like its own IP and can stand on its own legs. So I think you need to just adjust the cards enough so they don't instantly read as a Magic the Gathering card.&lt;/p&gt;
    &lt;p&gt;It's very interesting because the Ruby codebase uses a `typedef uintptr_t VALUE` type to mean any of the following:&lt;/p&gt;
    &lt;p&gt;- A pointer to the heap&lt;/p&gt;
    &lt;p&gt;- A Ruby tagged value (which may be a pointer to the heap)&lt;/p&gt;
    &lt;p&gt;- Any integer value that fits in `uintptr_t`&lt;/p&gt;
    &lt;p&gt;Fil-C doesn't allow you to carry around pointers using integers, in the sense that when you do that, the pointers lose their capabilities.&lt;/p&gt;
    &lt;p&gt;But in Ruby's case, it's not as simple as changing the typedef to a pointer type, since `VALUE` variables often end up being used for integer math (including bit math, shifts, etc).&lt;/p&gt;
    &lt;p&gt;So, it's going to take a nontrivial patch to Ruby to get it to work in Fil-C. I think I'm about 70% of the way through (I started Friday afternoon).&lt;/p&gt;
    &lt;p&gt;I'm making Easel, a 2D game programming language designed to match how humans, not computers, think about game logic. It also has automatic multiplayer. I've been working on it for 3 years!&lt;/p&gt;
    &lt;p&gt;Easel feels like a declarative programming language even though it is imperative, because lots of useful game-oriented features are first class. Like behaviours - you just say `on Pointer { ... }` and you have a concurrently-executing coroutine that's lifetime is managed. But you don't think about any of that complexity, you just think of your entity as having a behaviour and go forth and make your game.&lt;/p&gt;
    &lt;p&gt;It also happens to have automatic multiplayer. Normally with multiplayer you have to worry about doing everything in a "multiplayer safe" way (i.e. be deterministic and only modify the things your side has authority over). My idea was to put all the multiplayer stuff in the programming language itself, underneath all your lines of code. This way, anything you write in that programming language can just be made multiplayer, automatically. So you can just pretend all your players are in one shared world, like a singleplayer game, and the engine does all the multiplayer for you. It was really difficult to make but it makes multiplayer so easy for you now.&lt;/p&gt;
    &lt;p&gt;Easel is my idea of how games should be made, or at least as close to the idea as I can achieve with 3 years of work, and I would love for more people to try it out.&lt;/p&gt;
    &lt;p&gt;&amp;gt; you can just pretend all your players are in one shared world, like a singleplayer game, and the engine does all the multiplayer for you&lt;/p&gt;
    &lt;p&gt;But how does this really work? The website also says it's just baked into the language but there are many different approaches to networking games that have their own pros and cons.&lt;/p&gt;
    &lt;p&gt;It uses rollback netcode. The inputs are relayed to the other players and executed on all clients, and they end up in the same state because all Easel programs are guaranteed deterministic. To hide latency, the clients simulate forward even before they have received all inputs, and once inputs have been received it rolls back to the point of divergence to correct the prediction error. This works because the prediction is correct most of the time.&lt;/p&gt;
    &lt;p&gt;To be able to roll back, Easel incrementally snapshots the game state every tick. It only snapshots (and restores) what has changed, which makes it a lot more efficient than most rollback netcode implementations.&lt;/p&gt;
    &lt;p&gt;It also uses a peer-to-peer relay and adapts the latency asymmetrically, so the player who introduces latency feels their own latency.&lt;/p&gt;
    &lt;p&gt;I know there are other models and pros and cons, this is the right choice for Easel because I wanted to make the multiplayer fully automatic. One shared world, coded like a singleplayer game. There are certainly games which suit a client/server model better but I think the developer would then need to understand where their code is running and when to do remote procedure calls, and my goal was to make multiplayer so easy that even a teenager on their first day of coding could do it.&lt;/p&gt;
    &lt;p&gt;That's great stuff! IIRC Factorio takes the same approach but relies on extensive testing to avoid running into desync issues with non-deterministic code. Would be very cool to be able to build games like that without needing to worry about desyncs!&lt;/p&gt;
    &lt;p&gt;It might be a good idea to highlight some of the limitations to this approach somewhere so users aren't caught off guard later in the development process. For example, it wouldn't be great to build a competitive FPS or MOBA with this because the game state is replicated to all players which is a cheaters dream. The latency characteristics would also not be ideal for games with a larger number of players. I also assume there are no escape hatches for doing any non-deterministic things like I/O so there would be limited to no persistence possible. It won't be an issue for most games but worth highlighting just in case IMO.&lt;/p&gt;
    &lt;p&gt;I would love to hear more about what you were trying to do with your project before. Was it more similar to the declarative coding part, the automatic multiplayer part, or something else? Part of why I'm doing this is to explore the design space of how games should be made and I'm interested to hear what problems, issues, pet peeves, "bugbears" etc that other people think are worth solving.&lt;/p&gt;
    &lt;p&gt;It's been a while. But I believe what caused me the most headache while trying to build something like this was handling the interactions between different elements. Declaring which objects were affected by "attacks" or could be "player interactive" or "affected by player but not by NPC". Really this boiled down to proper inheritance. But I found myself so deep and tangled a fresh reset would have been better. Then determining if the object itself or an "objective manager" should perform the calculation each cycle.. etc&lt;/p&gt;
    &lt;p&gt;It was messy. I ended up having NPC, Item, Attack classes and for each a NPC Manager, Item Manager, and Attack Manager to calculate all their interactions and states.&lt;/p&gt;
    &lt;p&gt;That's why your project seems interesting because it seems to handle the heavy lifting of behaviors and "behind the scenes".&lt;/p&gt;
    &lt;p&gt;I've actually just recently been through this myself. I'm also building something for kids to build games in. But much more opinionated than Easel. It's interesting to me that Easel looks declarative but is imperative.&lt;/p&gt;
    &lt;p&gt;I've actually gone with a 100% declarative approach. Basically you define effects, which are executed in response to certain interactions. There's a comprehensive targeting system. But the best part is this is all type-safe using TypeScript, the declarative structure is enforced. That means even when you chain effects, nested effects are able to access (incl. autocomplete) the targets of parent effects etc. Whilst this provides a super nice experience to consume, it's definitely non-trivial to build this system.&lt;/p&gt;
    &lt;p&gt;Wow, impressive project! I like how you’ve focused on tooling and workflow, it makes sense that is where your most important problems are. Cool QR code drawing template idea too :)&lt;/p&gt;
    &lt;p&gt;Oh yes, handling interactions and dependencies and what is affected by what. I did a lot of React development (as in the frontend web framework) before making Easel and was quite inspired by how it hooks to change. The way you give it a little routine, it says what it depends on, and then it just fully re-executes that whole routine when the dependencies change. So in Easel when you say `with Health { ... }` it makes a behaviour that re-executes every time the Health changes. But, if it just reran the behaviour, then you'd end up with it adding a new sprite (for example) every time it re-executes, until you've got hundreds of them. So the other trick is the Easel compiler assigns an implicit ID to things like sprites so that it will replace rather than add the second time around. It's built into the programming language so you don't see it (most of the time). It actually took me 2 years to come up with that, which is both cool and depressing when I can explain it in one paragraph.&lt;/p&gt;
    &lt;p&gt;I was hitting Claude Code's rate limit pretty often while paying for their max subscription. Started thinking – I've got a decent GPU sitting at home doing nothing most of the day.&lt;/p&gt;
    &lt;p&gt;So I'm building a distributed AI inference platform where you can run models on your own hardware and access it from anywhere privately. Keep your data on infrastructure you control, but also leverage a credit system to tap into more powerful compute when you need it. Your idle GPU time can earn credits for accessing bigger models. The goal is making it dead simple to use your home hardware from wherever you're working.&lt;/p&gt;
    &lt;p&gt;It's for anyone who wants infrastructure optionality: developers who don't want vendor lock-in, businesses with compliance requirements, or just people who don't want their data sent to third parties.&lt;/p&gt;
    &lt;p&gt;I don't want to get into blockchain-shenanigans but I did love the Folding@home model for democratized compute. Could spare cycles on GPUs at home be used for a P2P network of inferencing?&lt;/p&gt;
    &lt;p&gt;Yeah! not building a blockchain but we are building a system similar to folding at home (also a fan of that) where if you choose to have your node process others peoples requests you will get credits that you can then use to spend on other people nodes on the network. This is so you can still be able to use models that may be too big for your own hardware when you need them. Overall goal being to prevent people getting priced out of AI and providing and alternative way of accessing these larger models.&lt;/p&gt;
    &lt;p&gt;Yea that would be the best current solution out there and would work ok for one person with one computer but the average person isn't going to set that up and it isn't easy to use from any device just by logging into a website or app. And if you had multiple machines you'd have to manually load balance by switching between them. Spore will allow you to easily set up as many nodes running models as you want and manage what models they are serving from anywhere, this allows for simple servicing of an organization or your family for example.&lt;/p&gt;
    &lt;p&gt;I'm reviving a project I last touched in 2006, in the hopes that it might be of use today in making social networking human again.&lt;/p&gt;
    &lt;p&gt;Back in the day, after the company I worked for bought the Electric Minds community and migrated it to its own CommunityWare system, and then the company that bought our company decided to shut the platform down, I reimplemented the community platform in Java and helped rescue the community. See: https://erbosoft.com/blog/2025/09/08/electric-minds/&lt;/p&gt;
    &lt;p&gt;EMinds eventually sputtered out because of the rise of platforms like Facebook. Well, now we see what came of that. So I think there's room for a platform like the one I used to have. See: https://erbosoft.com/blog/2025/11/03/what-we-once-had-and-co...&lt;/p&gt;
    &lt;p&gt;The new system is being written in Go. I'm porting the code over without using AI, though I have used Claude to translate the old crusty HTML pages into modern HTML with Tailwind CSS. Once it gets to the functionality I had back in 2006, I'll put it up...and then see about going beyond that, including how to make it distributed and provide more interoperability.&lt;/p&gt;
    &lt;p&gt;It has been a super fun experience so far - I'm using CPLDs instead of an FPGA which makes the logic a bit more era period. I have a working system now with the math coprocessor, SRAM, DRAM, and other device support.&lt;/p&gt;
    &lt;p&gt;I am just about ready to get the VGA card I designed produced so I can work on debugging the design.&lt;/p&gt;
    &lt;p&gt;While this is fundamentally a system that ss less powerful than my apple watch, it is just fun to work on. Going back to very first principles debugging, building tools, and of course getting to exercise an old logic analyzer!&lt;/p&gt;
    &lt;p&gt;It looks inside each file to see what it’s about, then moves it to the right folder with a single click. Everything happens on your Mac, so nothing leaves your computer. No clouds, no servers.&lt;/p&gt;
    &lt;p&gt;It already works with images, Office (Word, Excel, PowerPoint) PDFs, ePubs, text, Markdown, and many other file types (30+) in English. Next I’m adding multi-language support.&lt;/p&gt;
    &lt;p&gt;If you have messy folders anywhere on your Mac, Floxtop can help.&lt;/p&gt;
    &lt;p&gt;Correct — right now Floxtop classifies images based on text only. It does not yet classify based on visual objects. If automatic object-based sorting (e.g. detecting pets, buildings, etc.) would be useful for you, I’d be interested to hear your use case.&lt;/p&gt;
    &lt;p&gt;Regarding privacy: everything runs locally on your Mac. No files or metadata are uploaded anywhere. The only network request is from Sparkle to check for updates. If you prefer, you can disable update checks and Floxtop will have zero network activity.&lt;/p&gt;
    &lt;p&gt;If you have questions or want to share feedback, you can reach me anytime at floxtop@proton.me.&lt;/p&gt;
    &lt;p&gt;This is already useful. If you do wind up adding image classification, first, I'd like it distinguish photos, screenshots, and graphics. Then, I'd like broad categories, like people, places, animals, memes, etc. Base case is I want sort out my downloads since I generally download something and then not bother putting it where it belongs or deleting it.&lt;/p&gt;
    &lt;p&gt;It would also be handy if, in addition to moving the items, it could tag them via Finder tags/xattrs.&lt;/p&gt;
    &lt;p&gt;All of the street and satellite tiles are thanks to maps.black. The search uses Nominatim's sqlite3 mode. I was told that it's experimental only because it hasn't been tried in production yet, so I'm sort of testing it in the process. So far I'm only doing administrative boundaries and natural features, but so far so good! I'm going to slowly add a few more types of POIs, I just don't want the database file to get too big.&lt;/p&gt;
    &lt;p&gt;Note that Internet in a Box has an OSM offering already, but the data is five years old and the tech makes it harder to update. As of today, there are much easier options on the table, and we get cool stuff like 3d buildings. Also, the search was much more limited.&lt;/p&gt;
    &lt;p&gt;I'm building CommitKit, a tool that turns your git history into résumé bullet points and STAR-based talking points for interviews.&lt;/p&gt;
    &lt;p&gt;After being downsized twice in two years from senior engineering roles, I realized how painful it is to reconstruct what you actually accomplished at a job once you’ve lost access to your repos.&lt;/p&gt;
    &lt;p&gt;Each time, I had to dig through memory and scraps of old PRs to remember what I’d built. The first time, I lost GitHub access immediately after the layoff notice. This time, at least we got 90 days of paid transition work. But even with just 5 months in the role, I’d already made hundreds of commits. For engineers who’ve been around for years, that’s an impossible amount of history to summarize manually.&lt;/p&gt;
    &lt;p&gt;So I’m building CommitKit, a command-line tool that scans your repo for your commits, groups them by feature or theme using embeddings, and generates professional CV bullet points or behavioral interview summaries. It runs locally using Ollama, so your commit messages and diffs never leave your machine. The goal is to help people quickly turn real engineering work into clear narratives of impact, especially when time or access is limited.&lt;/p&gt;
    &lt;p&gt;It’s still early: the clustering isn’t grouping commits quite as I’d hoped, possibly due to sparse commit messages or embedding quirks. But it’s been a great learning project: my first CLI tool, my first deployment on Render, and my first serious use of Ollama for local LLM inference.&lt;/p&gt;
    &lt;p&gt;Nice! When I was leaving a company after 4 years there, I went through jira + my git commits to write a log of everything I'd done. Really great look back.&lt;/p&gt;
    &lt;p&gt;Built a local-first Kanban board with Tauri (Rust + Svelte) after getting frustrated with SaaS tools and basic offline options. Stores data in JSON files you control, full keyboard-first UX, parent/child tasks, release management, and it's blazingly fast with localStorage + background sync. No telemetry, purely local. Curious what others prioritize in personal task tools. Seems like there's a gap between "todo.txt" simplicity and Jira complexity.&lt;/p&gt;
    &lt;p&gt;Cool. Love Tauri. So the whole board dataset is stored in localStorage? If you get to a point where the size limitations or synchronous blocking operations are an issue might consider using IndexedDB. There is a nice higher level wrapper around it called Dexie that has full TS typing support and a nice async API. https://dexie.org/&lt;/p&gt;
    &lt;p&gt;I’m still using redmine. It allows me to create a project, break it down in to tasks, assign time estimates for the tasks, assign % complete, log time against tasks, which then allows for burn down charts so I can see if I am on track or behind. With time logged against projects I can generate timesheets and invoices. It also has Gantt chart which is handy for initial project planning meetings.&lt;/p&gt;
    &lt;p&gt;I built this: https://github.com/dvcoolarun/web2pdf — a CLI tool for converting web pages to PDFs, recently open-sourced after adding several new features. (Might be useful!)&lt;/p&gt;
    &lt;p&gt;Not related to the thread, but if anyone is looking to hire a developer or knows of opportunities, I was recently let go and am actively searching. Any leads or feedback would be greatly appreciated.&lt;/p&gt;
    &lt;p&gt;Eternal Vault is interesting. I would for sure use something like this. However, only if there is a strong story how the vault will survive 20+ years, even if your company is defunct. I do see the pieces scattered around the website (backup to Dropbox, etc), but this story needs to be front and center.&lt;/p&gt;
    &lt;p&gt;Hi Luke, thanks for the feedback. Will be working on improving the marketing site to share the story in better way, any other feedbacks are also appreciated. Lastly, would love for you to give the platform a try at https://dash.eternalvault.app/register&lt;/p&gt;
    &lt;p&gt;I recreated a little tool to simultaneously mount all the commits in a git repository as directories at the same time (but re-use the same inodes for the same content).&lt;/p&gt;
    &lt;p&gt;The original was in Python and actually had a decent excuse for existing for a very specific problem at work a few years ago. The new version is in Rust and exists just for fun.&lt;/p&gt;
    &lt;p&gt;This was also a small experiment in coding with OpenAI's codex. I wrote the Python original by hand---like a caveman. Codex was mostly ok at the actual code, especially once I told it to make `cargo clippy` happy, but it needed lots of help with the design. It kept insisting on extra complications and state.&lt;/p&gt;
    &lt;p&gt;But perhaps I'm a bit unfair here, because I only figured out the nice and simple design after reflecting on the connection between Linux's fuse and git's design for a while when writing the original. So it's only fair that the computer would also need some help to see how to match them up nicely.&lt;/p&gt;
    &lt;p&gt;We had a bunch of quants who were writing Python and Matlab code.&lt;/p&gt;
    &lt;p&gt;Previously they just saved it in a (Windows) Shared Folder and it automatically showed up in the test cluster. No version control, no nothing.&lt;/p&gt;
    &lt;p&gt;The test cluster had actually grown to a few thousand machines or so. Running Shared Folders over that was crazy, and no version control was crazy, too.&lt;/p&gt;
    &lt;p&gt;In addition, they expected to be able to write output files next to the source files, and expected them to show up to be used by the other machines.&lt;/p&gt;
    &lt;p&gt;We were trying to help them migrate to something saner. We could convince them to not intermix source code and output files, but as part of that bargain otherwise they wanted everything to look as similar as possible to before, but still support some git-goodness we have promised.&lt;/p&gt;
    &lt;p&gt;To make matters worse, they had checked in some rather large files into their repository. Like Gigabytes, and lots of them.&lt;/p&gt;
    &lt;p&gt;As before, we wanted to support running multiple processes at the same time, but this time on different versions. As a joke I suggested to 'just mount' the git repository directly (that we constantly pull to every computer in the cluster), but my boss thought it was a grand idea, thus the tool.&lt;/p&gt;
    &lt;p&gt;An additional nicety: under the hood 'git stash' consists of two phases, the first phase make something like a commit from what you have lying around in your repo, the second phase cleans up what you have lying around. If you use libgit2 (or a similar library) you can use just the first phase to get something like a commit, and send that to the server to execute, while changing nothing on the quant's machine, and not forcing them to explicitly make a commit nor polluting their git history.&lt;/p&gt;
    &lt;p&gt;One saner alternative would have been to just make a checkout for each run. But naively that would have taken more storage space than we had, thanks to those big files. Alternatively, we could have done some sharing for running the same version. But that would have involved some reference counting etc and cleaning up.&lt;/p&gt;
    &lt;p&gt;So my suggestion was to 'just let the kernel caches handle it'.&lt;/p&gt;
    &lt;p&gt;In the end, the prototype was useful to get the quants to get along with what we did. And luckily for our sanity, we could soon convince the quants to store those large files somewhere else, and not in the repository along with the code. That restored our sanity, and we could move to a more conventional scheme.&lt;/p&gt;
    &lt;p&gt;The working life of the tool was blessedly short, but it played an important role in getting the quants to move along in their journey to using version control. Though even though on paper it might have looked like an abortive and wasted effort, in terms of business value it was very successful.&lt;/p&gt;
    &lt;p&gt;I love the quants. They are very technical and very smart and effectively write software all day every day, but they don't see themselves as software engineers, and they aren't.&lt;/p&gt;
    &lt;p&gt;I recreated it just for fun, because I like the connection between git and how filesystems work. You can really tell that Linus Torvalds, the original author and designer of git is an operating systems guy.&lt;/p&gt;
    &lt;p&gt;I’m working on “Stripe Integration as a Library.” It seems that whenever someone uses Stripe, for example for subscriptions, they go through the same few steps: creating a database table, setting up webhooks, and implementing the events they care about. The challenge of course is that everyone uses a different stack.&lt;/p&gt;
    &lt;p&gt;I’m building this using our framework for stack-agnostic JS/TS libraries. On the database side, we currently support Drizzle and Kysely, with Prisma support coming soon.&lt;/p&gt;
    &lt;p&gt;Pretty much finished my photo gallery app for Windows -- https://github.com/Bloomca/Piktosaur. It is a pretty standard gallery viewer, the main feature is that you can point it at any folder and it will recursively search nested folders for extra images, e.g. an external hard drive.&lt;/p&gt;
    &lt;p&gt;Really happy with it as I wanted exactly that for myself.&lt;/p&gt;
    &lt;p&gt;I've been researching this topic and while my background is related to digital signal processing, I think I will use a library, there seem to be too many edge cases to work with WASAPI and such directly.&lt;/p&gt;
    &lt;p&gt;I'm working on Flavia, an ultra-low latency voice AI data analyst that can join your meetings. You can throw in data(csv's, postgres db's, bigquery, posthog analytics for now) and you just talk and ask questions. Using cerebras(2000 tokens per second) and very low latency sandboxes on the fly, you can get back charts/tables/analysis in under 1 second. (excluding time of the actual SQL query if you are doing bigquery).&lt;/p&gt;
    &lt;p&gt;She can also join your google meet or teams meetings, share her screen and then everyone in the meeting can ask questions and see live results. Currently being used by product managers and executives for mainly analytics and data science use cases.&lt;/p&gt;
    &lt;p&gt;We plan to open-source it soon if there is demand. Very fast voice+actions is the future imo&lt;/p&gt;
    &lt;p&gt;Great feedback thanks! We have added a synthetic e-commerce dataset as an example when you sign up so you can test it without your data first. Will also add a demo video ASAP.&lt;/p&gt;
    &lt;p&gt;What kind of plan do you have with Cerebras? It seems like something like that would need one of the $1500/month plans at least if there were more than a handful of customers.&lt;/p&gt;
    &lt;p&gt;They introduced pay as you go recently. The limits on that is similar to the plans, 1 million tokens per minute, so if you stack a few keys and do a simple load balancing with redis, can cover a decent amount of traffic with no upfront cost. Eventually we would have to go enterprise though yes!&lt;/p&gt;
    &lt;p&gt;ok.. when I tried to use pay-as-you-go it was unusable for me because there were a ton of 429s and 503s. one test it was just constant for a few seconds when I tried it, 429 or 503.&lt;/p&gt;
    &lt;p&gt;I am using it for a voice application though so retrying causes a delay for the user that they don't expect. especially if it stays unavailable for a few seconds.&lt;/p&gt;
    &lt;p&gt;I've been enjoying rebuilding my music collection from both old hard drives and ripping old CDs. Jellyfin is great but I wanted a native application focused on music, not video. Thus Gelly. It's been really fun to work on.&lt;/p&gt;
    &lt;p&gt;I am working on SecurityBot https://securitybot.dev a service that combines uptime, performance, SEO, and security monitoring. Among other things it inckudes PageSpeed Insights analysis, a broken link auditor (401, 404, 500, etc), and historical ping/uptime results.&lt;/p&gt;
    &lt;p&gt;I recently shipped an MCP server thst can delivered broken link results to Cursor so they can rapidly be resolved.&lt;/p&gt;
    &lt;p&gt;As a means to learn about both WebAssembly and Rust, I started writing a WebAssembly binary decoder (i.e. a parser for `.wasm` files) from scratch.&lt;/p&gt;
    &lt;p&gt;Recently it hit v2.0 spec conformance. 3.0 is next on the roadmap. (I'm executing it against the upstream spec test suite.)&lt;/p&gt;
    &lt;p&gt;My aim is probably not for it to become a highly-performant decoder for use in production environments, but rather one that can be used for educational purposes and/or debugging issues with existing modules. That's why I decided not to offer a streaming API, and why I'll be focusing on things like good errors, good code docs etc.&lt;/p&gt;
    &lt;p&gt;Building the world’s first “Travel Confidence Engine.”&lt;/p&gt;
    &lt;p&gt;I’ve been obsessed with how people actually make travel decisions — not how platforms think they do. From a consumer’s standpoint, travel isn’t just “search → compare → book.” It’s emotional, contextual, and full of FOMO.&lt;/p&gt;
    &lt;p&gt;You open 20 tabs across Booking, Google Maps, Reddit, and Instagram trying to answer simple questions like: Is this the right area? Is this hotel actually good? Am I missing a better deal somewhere else?&lt;/p&gt;
    &lt;p&gt;Most existing tools either oversimplify (like ChatGPT giving three confident but unverifiable answers) or hide information behind algorithms and commissions (like OTAs). Both remove choice — and ironically, make people less confident.&lt;/p&gt;
    &lt;p&gt;I’m building SearchSpot, a “Cursor for travel.” It automatically does what power travelers already do manually — cross-check reviews, verify real photos, compare prices across platforms — and then shows its reasoning transparently so you understand why something was recommended or excluded.&lt;/p&gt;
    &lt;p&gt;The goal isn’t to replace your decisions, but to help you close your tabs with confidence. From FOMO to flow. From chaos to clarity.&lt;/p&gt;
    &lt;p&gt;If you’ve ever spent hours researching a trip just to end up more confused, I’d love your thoughts: https://searchspot.ai/home&lt;/p&gt;
    &lt;p&gt;yeah, but there's no way to reach out for feedback or follow ups if not logged in. At this stage, we want loads of feedbacks and help genuine users plan their trips well, hence the login wall.&lt;/p&gt;
    &lt;p&gt;A few months ago, I saw a tweet from @awilkinson: “I just found out how much we pay for DocuSign and my jaw dropped. What's the best alternative?” Me being naive, I thought “how hard could would it actually be to build a free e-sign tool?”&lt;/p&gt;
    &lt;p&gt;Turns out not that hard.&lt;/p&gt;
    &lt;p&gt;In about a weekend, I built a UETA and ESIGN compliant tool. And it was free. And it cost me less than $50. Unlimited free e-sign. https://useinkless.com/&lt;/p&gt;
    &lt;p&gt;An algorithm to optimise vacation days using public holidays and weekends. Especially relevant at this time of year.&lt;/p&gt;
    &lt;p&gt;I created it a year ago and received quite some comments on the Show HN post[1]. Last weekend I updated it to work for end of year planning and adding fixed days off, which seems to solve most of the feedback. It was done with Cursor in agent mode.&lt;/p&gt;
    &lt;p&gt;Over the years, I've read countless books. I started documenting one idea that shaped my thinking from each of these books. This idea may or may not be the core theme of the book.&lt;/p&gt;
    &lt;p&gt;Still very focused on making light healthier. 3 new products:&lt;/p&gt;
    &lt;p&gt;Bedtime Bulb v2[0]: A massive improvement over our original Bedtime Bulb, a light bulb meant for use in the evening to reduce blue light. The headline feature is the re-introduction of infrared, which was removed from lighting to make it more efficient, but emerging research suggest it's beneficial for health. After a long wait, this is shipping in 2 weeks!&lt;/p&gt;
    &lt;p&gt;Atmos Bedside Lamp[1]: A fully automated circadian lamp that automatically shifts in color and brightness throughout the day, helping you prepare for sleep and wake up more naturally. Working on some machine learning features that mimic the functionality of the Nest Learning Thermostat, but for lighting. The first units are shipping by Christmas.&lt;/p&gt;
    &lt;p&gt;Circadian Mode for Philips Hue[2]: A web app that gives your Philips Hue lights circadian powers, so that they gradually shift from bright light during the day to dim, low-blue light at night. It's way more powerful and easier to use than first- and third-party options from Hue, Apple, and Home Assistant. Just launched this week; looking for beta testers to give feedback!&lt;/p&gt;
    &lt;p&gt;This looks good! It feels a little bit similiar to ReScript. I like the idea to have nodeMain, browserMain and buildMain. The Roc language had something similiar with platforms and I love that idea!&lt;/p&gt;
    &lt;p&gt;In general I prefer a better language over an involved javascript framework that does not look like js anymore.&lt;/p&gt;
    &lt;p&gt;Thank you! Yeah, I think some of the newer frameworks really complicate dataflow. We're trying to keep dataflow clear, though it's a big design space given the distributed nature of webapps.&lt;/p&gt;
    &lt;p&gt;In any case, if you take it for a spin, I'd love some feedback.&lt;/p&gt;
    &lt;p&gt;An annoying little laptop charging reminder utility that does the job.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;There are times when I am deeply involved in a focus-work session, a meeting, OR watching some sort of engaging video content, and don't pay timely attention to the standard low battery notifications from my MacBook.&lt;/p&gt;
    &lt;p&gt;After the laptop shuts down suddenly, what follows is the most annoying walk to find the charger or the charging outlet. It's frustrating at times, sometimes embarrassing because you have to say, "Sorry, my battery died down" as you join back the session after 2-3 minutes.&lt;/p&gt;
    &lt;p&gt;Over the last 3-4 weekends, I have been building Plug-That-In, which has floating notifications. Essentially, a notification that follows my cursor movement, so I get a stronger nudge irrespective of what I am doing.&lt;/p&gt;
    &lt;p&gt;There are a few other critical features, such as Reminder Mode and Do-Not-Disturb Settings.&lt;/p&gt;
    &lt;p&gt;- Reminder Mode: On critical/lower battery levels, it will keep beeping like a car's seat belt alert for some time (configurable) when the battery is really low.&lt;/p&gt;
    &lt;p&gt;- Do-Not-Disturb settings: Configure what sort of alert/sound it will generate when I have system audio playing or video playing, or the camera is active.&lt;/p&gt;
    &lt;p&gt;It has addressed a personal need and has already proven useful a few times over the last weeks.&lt;/p&gt;
    &lt;p&gt;I've been working on a sillier project lately. Green teeth!&lt;/p&gt;
    &lt;p&gt;Lumina has made a probiotic strain that is able to, theoretically, prevent cavities. I don't care that much about, but I do think it is a neat strain that can likely colonize your mouth. I'm genetically engineering it to express sfGFP, which would theoretically make my teeth fluorescent green under black light. Would be fun at raves! Also, if I make out with anyone, you could theoretically see changes in microbiome composition just from green-ness. I do wonder how much microbiomes are shared while kissing: this would be an example of a way to directly measure that, instead of just measuring on proxy like much microbiome research&lt;/p&gt;
    &lt;p&gt;I'm building a small rural ISP and web hosting service, as a way to learn about low-level networking stuff. I've got an ASN + IP space, and am working out the details with a colo, local fiber provider, and some upstreams. Right now I'm configuring the hardware itself (server, router, switch, etc) and learning all the bits and bobs (Proxmox, BGP, OPNsense, IXPs, etc)&lt;/p&gt;
    &lt;p&gt;Best of luck with this. If you get the web hosting part going and need to stick a load balancer in front of web servers/front end proxies, may I suggest that you give my project[1] a go? Speaks BGP directly to your routers to advertise healthy services and scales from small VMs (for services that are only a few gigabits/s) to physical servers if you need to serve tens of gigabits/s traffic.&lt;/p&gt;
    &lt;p&gt;Shameless plug, sorry (not sorry!) but I would have killed for it when I worked in web hosting :-)&lt;/p&gt;
    &lt;p&gt;All I can say is good luck. We spun up a co-op isp to take advantage of fiber grants for rural areas about a decade ago.&lt;/p&gt;
    &lt;p&gt;Maybe it was because of the grants, but it was a fucking nightmare getting off the ground even though we had nearly 90% of the population in three counties on board for the co-op. The red tape and regulations (in our state at least) made it clear that government runs for urban and suburban interests and actively undermines rural needs. I'm talking government in bed with large providers who had exclusive rights to run "high-speed" Internet to our towns and farms, even though they had never and were never planning on anything above dsl for most people and cable for the ones in town.&lt;/p&gt;
    &lt;p&gt;If I was more charismatic (and wasn't 1000% sure there were pictures of me doing drugs when I was in college), I would consider a run for state office, because it's a shit show for small towns here.&lt;/p&gt;
    &lt;p&gt;And that's the story of a) when we got sued by a large provider that I hope goes out of business and burns to the ground, and b) the last time I volunteered on a large project and why I will never take the lead on anything bigger than the Lion's Club pancake breakfast now.&lt;/p&gt;
    &lt;p&gt;I'm funding this myself, and my current approach (hopefully!) avoids most of the red tape. I'm leasing fiber from a local ISP for the colo &amp;lt;-&amp;gt; my home connection, and once I have myself as a successful "customer" of my own ISP, I'll start doing the last mile build out, which is where I expect the red tape to begin.&lt;/p&gt;
    &lt;p&gt;But I haven't decided if I'll do fiber or wireless, and if I go wireless, I might be able to avoid pole agreements entirely by just working directly with my neighbors. The problem is that our area is pretty heavily wooded, so I'm not sure if I can place antennas high enough to cover a reasonable swatch of the area.&lt;/p&gt;
    &lt;p&gt;Our best approach was to run fiber in the ground in the public right-of-way on county or local streets and avoided the state highways. It was much easier to get easements with property owners and local towns than the state (as far as I know, our request is still sitting unread with the state). That meant we had to build twice, essentially. Once for the north of the major highway that bisects the area, and once for the south. But that cut out all of the nonsense with existing agreements from the state. So that helped.&lt;/p&gt;
    &lt;p&gt;Most property owners we had to cut across were willing to forego payment of any kind for free fiber hardware, and access at reduced rates for 10 years. So that was nice.&lt;/p&gt;
    &lt;p&gt;We didn't evaluate wireless, just because of the terrain, but I do know a local chap who is providing that for folks using grain bins for line-of-site access points. That's seemed to work well for his use case.&lt;/p&gt;
    &lt;p&gt;&amp;gt; If I was more charismatic (and wasn't 1000% sure there were pictures of me doing drugs when I was in college), I would consider a run for state office, because it's a shit show for small towns here.&lt;/p&gt;
    &lt;p&gt;Loads of politicians have come back from worse! Don't let that hold you back.&lt;/p&gt;
    &lt;p&gt;Career Skills AI Coach. Sharpen how you think and speak by debating AI&lt;/p&gt;
    &lt;p&gt;We are clearly on the verge of the largest white-collar skills dislocation ever. Our goal at Socratify is to make skill building and reskilling for interviewing, onboarding, promotions, and career change as effective as possible with an AI coach and sparring partner.&lt;/p&gt;
    &lt;p&gt;Working on Strot - an AI agent that reverse-engineers website APIs for scraping.&lt;/p&gt;
    &lt;p&gt;Instead of DOM scraping, it intercepts AJAX calls and figures out which API endpoint gives you the data you need. Uses visual analysis + fuzzy matching to identify the right call.&lt;/p&gt;
    &lt;p&gt;The use case: scraping product reviews, paginated listing data (products), etc. Existing AI scrapers either didn't work or were very slow and costly. A product with 1000 reviews takes 10+ minutes with Playwright, costs $10 with LLM scrapers. With Strot? 10 seconds via direct API calls.&lt;/p&gt;
    &lt;p&gt;Being used in production by a couple of clients. Would love feedback!&lt;/p&gt;
    &lt;p&gt;Very neat - I imagine you could even use this as a web scanner to identify security misconfigurations in API implementations (e.g. broken access control)&lt;/p&gt;
    &lt;p&gt;DIY grid-tied residential solar+inverter+battery. Trying to design the solar arrays' tilt mechanism now for lifting/lowering 5 panels at a time in winter (60-degree winter angle, 35-degree spring/summer/fall; ~24" difference). Thinking either two linear actuators, or a single hydraulic jack connected to multiple support beams. The weight isn't much, but I want a way to lift entire top edge at once to prevent twisting. Linear actuators are slightly more money and easier to build, but require power and weather-proofing. Jack is cheaper, but more complex to distribute force. Wondering if there's other options. (winch would require more robust/taller rear posts, seems more complex, might shade rear array)&lt;/p&gt;
    &lt;p&gt;Nice, I started with 5 panels (450W each) and a simple design of interchangeable long and short rear legs to adjust the angle of each panel. Base of leg sits in a bracket on a steel frame, and pivots on an M8 bolt. Top of the leg attaches to some angled 'meccano' steel I affixed to the rear of the panels. It worked great, but I slightly over optimized by sharing legs, which made the twice a year switchover a bit tricky, since I could only manage to lift a single panel at a time.&lt;/p&gt;
    &lt;p&gt;Last year the 550W panels here dropped to 90eur, and so I just added some more panels to remove the need for the switchover. I saw last week 600W panels going for 80eur but no space left, but tempting. Good luck! It's a nice feeling to have energy independence.&lt;/p&gt;
    &lt;p&gt;Tilting them vertical or nearly so is very useful if there could be any hail, that might be a good idea to support.&lt;/p&gt;
    &lt;p&gt;What about compressed air? It might not be too hard to find a small brushless low power air pump that could drive pistons directly.&lt;/p&gt;
    &lt;p&gt;You could mount the pump controller onto the back of the panels and use an accelerometer to measure angle, and run the pump until it's where you want it.&lt;/p&gt;
    &lt;p&gt;You'd probably need to do some testing and make sure it couldn't get jammed, then build up pressure, then suddenly unstick and move unsafely.&lt;/p&gt;
    &lt;p&gt;Thanks! And I've seen Dave's tests. Since I don't need a fixed angle, do need to maximize production (due to a limited sun horizon), and only have 10 panels, the best option is adjusting angle during winter. The N-S orientation is a really poor performer. (Notice that his test is 30-degree tilt vs N-S; 60-degree tilt will provide 20-25% more power than 30-degree at my latitude, without even considering bifacials w/snow. The only thing that would produce more is an active tracker, but I've got other things to do, and a December deadline...)&lt;/p&gt;
    &lt;p&gt;Every time I talk acquaintances, friends and family members about finances I'm always shocked at how little people know about basic things like tax brackets, 401Ks, IRAs, ETFs, compounding interest, debt management and etc. So I decided to write a financial literacy/education book with a bit of humor and easily comprehensible language to distill some of these topics. I'm about 1 month into it and try to write a chapter a week.&lt;/p&gt;
    &lt;p&gt;About 2 years back I began working on a very simple markdown compiler, it was “immediate” in that it would consume markdown and immediately spit html. That project turned into a whole static site generator called Kevlar — https://github.com/aadv1k/kevlar&lt;/p&gt;
    &lt;p&gt;Entirely built from scratch in C without any dependencies. Now I wrote this code when I was 16, so many memory leaks and generally issues that I wanted to rectify and begin using third project for my own blog (currently old version is used — https://aadvikpandey.com)&lt;/p&gt;
    &lt;p&gt;The Kevlar v3 (https://github.com/aadv1k/kevlar/tree/kevlar-v3) here is all that it includes; more spec compliant markdown AST-based parsing; A better .ini config parser (right now it’s literally strtok on ‘=‘ and generally very hacky) as well as name spacing; more powerful templating tags like IF, FOR with lisp-like configuration&lt;/p&gt;
    &lt;p&gt;Of course staying true to the spirit of “from scratch” :)&lt;/p&gt;
    &lt;p&gt;Honestly I did scope creeped a little since I mainly wanted to fix a memory leaks issue in the markdown compiler lol; anyway I will share it once it gets completed on hacker news :)&lt;/p&gt;
    &lt;p&gt;&amp;gt; Entirely built from scratch in C without any dependencies. Now I wrote this code when I was 16&lt;/p&gt;
    &lt;p&gt;Very few young folk are learning C; I think it is commendable that you are.&lt;/p&gt;
    &lt;p&gt;You code doesn't seem very strongly structured (to be expected, TBH) but much better than any learner would see.&lt;/p&gt;
    &lt;p&gt;What resources did you use to start learning C? I ask because it looks to me that those resources covered "how to program in C" but not so much design and structure.&lt;/p&gt;
    &lt;p&gt;Here's two links (my own blog) to get you started on one or two common C patterns designed to minimise bugs:&lt;/p&gt;
    &lt;p&gt;Hey, thanks for your comment :) I had a look at your blog, it's looks really useful and high quality! I will go through it with vim open on the side and a nice coffee&lt;/p&gt;
    &lt;p&gt;Yeah and I'd agree with your point. One BIG critique I have for my own 2-year-past code was that I did not know how to do dynamic heap allocation very well, hence you may have seen everything is stack allocated lol&lt;/p&gt;
    &lt;p&gt;(I had read "clean code" by uncle bob at the time, so I was trying to emulate clean code I saw in the book. Needless to say, pretty good example of the nuance needed when writing clean code haha)&lt;/p&gt;
    &lt;p&gt;So with the V3 release, I am re-writing the markdown compiler for instance, and being a bit more mindful of the structure&lt;/p&gt;
    &lt;p&gt;I think once I am done I will create a separate "Show HN" post to get valuable feedback (like this one!) from smarter folks than me. Once again, thanks for the fantastic blog :) will be sure to go through it&lt;/p&gt;
    &lt;p&gt;I’m working on https://regularly.co/ - A website made for inquisitive minds to get their daily puzzle fix. Still very much a WIP (mainly working on tuning the difficulty of puzzles to make it enjoyable for most). That being said I really do enjoy the unique combination of puzzles when I do them each day. I’m looking for feedback so if you do take a look please do let me know your thoughts!&lt;/p&gt;
    &lt;p&gt;Incredible. Thank you for sharing this, I love puzzles and like setting aside some time in the morning to do them. This will enhance that habit so much! A whole slew of daily puzzles, I'll let you know how it goes!&lt;/p&gt;
    &lt;p&gt;Ah this rule is mentioned under “Kings cannot attack each other” (in the chess sense, two Kings cannot be diagonal from one another). I’ve updated the rule to make this a little clearer&lt;/p&gt;
    &lt;p&gt;Maybe it wasn't there when you played, but rule 6 states kings cannot attack each other; chess kings can move one square in any direction. Without this rule the puzzle isn't solvable by logic, only trial and error.&lt;/p&gt;
    &lt;p&gt;I'm working on a K8S hosting solution that just gives the user a simple Kubernetes cluster. I (or we) handle the compute, (networked) storage and ingress hosting for you, and the cluster provision time should be within minutes.&lt;/p&gt;
    &lt;p&gt;You just need to pay for a fixed monthly upfront cost rather than PAYG, giving small developers a good save of their money.&lt;/p&gt;
    &lt;p&gt;In other words, this is similar to self hosting with K0S/K3S/OpenShift, except you don't have to own servers to begin with, in other words, it is a little similar to serverless K8S.&lt;/p&gt;
    &lt;p&gt;Well, all you those you can actually do with a VPS today, heck why do I have to do it if EKS/GKE/LKE/OKE/DOKS exists? That's because it takes a lot of time to properly setup VPC/EBS/S3/EC2, you need to pay an insane amount of premium and overheads to those while an ordinary user just don't want to hassle too much.&lt;/p&gt;
    &lt;p&gt;I want to undercut the big clouds by saving people's money and time. I have had enough of seeing a ludicrous EKS billing. I just want K8S to be the control panel of everything.&lt;/p&gt;
    &lt;p&gt;This resonates with my experience as a small startup dev. I wouldn't mind bringing my own servers for running my apps but for k8s I need at least 3 control nodes in each cluster and I need multiple clusters to cover different parts of the world. All those control planes are idling most of the time but cost money and effort to keep them alive. I'm sure those could be shared among dozens of users. Is this something you are going to support? Or I'll also have to rent the worker nodes from you?&lt;/p&gt;
    &lt;p&gt;You rent the compute, storage and network from the worker clusters at a fixed monthly price as one budget package, just like how you buy VPSes back in the days (think EC2 Lightsail or Linode, except now you just have a K8S context). You can choose multiple geolocations, but I'm still looking for a successful lab simulation first.&lt;/p&gt;
    &lt;p&gt;Right now I'm hosting my own test cluster under my bed so I can't show it.&lt;/p&gt;
    &lt;p&gt;You don't have to manage CNI, CSI, Linux kernel, etcd. You just need Kubernetes app development knowledge and that's basically it.&lt;/p&gt;
    &lt;p&gt;Now I'm still thinking about how to get live migration and failover working, so it is going to take a painful while...Kata Container doesn't support it out of the box but Cloud Hypervisor does&lt;/p&gt;
    &lt;p&gt;No link yet as I'm still just a solo dev, the (hobbish?) project is crawling very slowly, but I have the general architecture in mind. I need to get the frontend first.&lt;/p&gt;
    &lt;p&gt;I tried to submit it as a startup project last year but the feedback isn't great, I want to have something polished first before making it public&lt;/p&gt;
    &lt;p&gt;I am working on my own Lisp-like language (cliche, I know). Goal is a hybrid. Syntax is a bit more Clojure inspired, but want to emulate the interactivity of SBCL once I am done.&lt;/p&gt;
    &lt;p&gt;And the other goal is minimal dependencies. The only bootstrapping stage is a very very small core in Common Lisp + FSet but could also be replaced with other languages, and then using that subset to bootstrap the rest.&lt;/p&gt;
    &lt;p&gt;There is absolutely zero claim to be highly performant, it is more of an educational experience.&lt;/p&gt;
    &lt;p&gt;All of it is done via literate programming in org-mode. So far it's working pretty well, but will have to see how that approach works if the project grows.&lt;/p&gt;
    &lt;p&gt;So far it works pretty good. Minor edits I just quickly edit and tangle, otherwise I open the source block in a buffer (C-c '), and from there I can just use the usual C-c C-c shortcut to send it to the REPL.&lt;/p&gt;
    &lt;p&gt;But as the first stage bootstrap in CL is mostly done at this point, I have to hot-reload anyway.&lt;/p&gt;
    &lt;p&gt;At some point it might be nice to have my own REPL running in Emacs, but that is a worry for way later when I actually get something usable. For now this is purely for personal entertainment.&lt;/p&gt;
    &lt;p&gt;Working on a charity + website (not live yet) that allows you to centrally manage your charity donations.&lt;/p&gt;
    &lt;p&gt;I'm in Germany so I'm working on a Germany-specific solution for now.&lt;/p&gt;
    &lt;p&gt;- you choose from a list of charities (right now I'm working with the list from the https://dzi.de plus a few such as Wikimedia Deutschland)&lt;/p&gt;
    &lt;p&gt;- you setup a recurring donation to our bank account&lt;/p&gt;
    &lt;p&gt;- we redistribute the money according to your split&lt;/p&gt;
    &lt;p&gt;- no spam in your email and snail mail&lt;/p&gt;
    &lt;p&gt;- one pdf at the end of the year for your tax returns&lt;/p&gt;
    &lt;p&gt;I'm not planning on taking any cut of the donations obviously, so this will be a fully self-funded project at first, but I'll reach-out to foundations once I'm up and running.&lt;/p&gt;
    &lt;p&gt;It's a custom assembler built on top of the LLVM assembler (llvm-mc) that emits instrumentation code to catch ABI violations at runtime. Stuff like clobbering nonvolatile registers, misaligning the stack pointer, misusing the redzone, assuming volatile registers don't change across a function call, etc.&lt;/p&gt;
    &lt;p&gt;Hoping to finish up basic x86_64 support within the next few days. I can now reliably assemble and run unoptimized gcc output without hitting false positives, but I still have to iron out some false positives triggered by OpenSSL's handwritten assembly routines.&lt;/p&gt;
    &lt;p&gt;TODO items for the near future include porting the runtime support library into a kernel module so I can instrument Linux, and beginning ports other architectures (ideally something semi-obscure like POWER or RISC-V). I also need to figure out how to support dynamic linking, because the tool currently needs static linking to access its thread-local variables.&lt;/p&gt;
    &lt;p&gt;I’m building A2Fusion [1], a dual RP2350 expansion board for the Apple II to provide, storage, hdmi video and other functions in one card. The PoC is currently a big mess of wires. Waiting on JLCPCB for first prototype boards.&lt;/p&gt;
    &lt;p&gt;Assuming that you're in the US, what's been your experience with JLCPCB recently re:the tariff situation?&lt;/p&gt;
    &lt;p&gt;I'm getting ready to have a couple prototypes made soon and trying to decide between getting boards made at OSHPark and hand-stuffing/reflowing myself or having JLCPCB do all of it.&lt;/p&gt;
    &lt;p&gt;Timing seems to be about the same (but just in production now). But tariffs/taxes were 55% of merchandise cost. DHL is expensive too, $52 for 10 boards (shipping to Cali). I haven’t used OSHPark.&lt;/p&gt;
    &lt;p&gt;I’ve always wanted a typing application that’s both more than typing random words and is data-focused so I built this.&lt;/p&gt;
    &lt;p&gt;The more you type, the more the analytics system learns about your typing patterns and generates natural text to target those weakpoints (SmartPractice mode).&lt;/p&gt;
    &lt;p&gt;There’s a lot of variety as well; you can practice typing code in any programming language, or type text of various topics, use custom text, etc).&lt;/p&gt;
    &lt;p&gt;I've built a self-hosted reddit-like community platform in Go: https://baklab.app&lt;/p&gt;
    &lt;p&gt;Users can create their own sub-communities, and within them, set up different categories and boards. Posts can be voted on, and board types can include regular posts, Q&amp;amp;A, or live chat. It's like a hybrid of Reddit and Discord but leans more towards a traditional web community. It also supports server-side rendering, making it SEO-friendly. This project is an extension of my previous Hacker News clone, dizkaz (https://news.ycombinator.com/item?id=43885998).&lt;/p&gt;
    &lt;p&gt;I am working on Rad [0], a programming language built specifically for CLI scripts, so you don't need to write Bash, and it offers CLI-tailored features which make it a better choice than Python.&lt;/p&gt;
    &lt;p&gt;Lately I've mainly been working on stability and bug fixes. I've released some big features the past few months so I'm doing a big push on polish, before I again tackle some larger features that I'd like to implement.&lt;/p&gt;
    &lt;p&gt;If CLI scripts is something you're interested in at all, give it a go! We have docs and a guide [1] for getting started, feedback very welcome :)&lt;/p&gt;
    &lt;p&gt;I'm working on Pocketdata - a personal, private AI data plane.&lt;/p&gt;
    &lt;p&gt;The idea is to take boring components: PostgreSQL, Bifrost (LLM gateway), Open WebUI, LanceDB, Agentgateway (MCP and OpenAPI gateway) and deploy them in Fly.io. One Fly.io "org" per user. The closest equivalent is blaxel.ai, but it caters for AI SaaS startups, not individual customers.&lt;/p&gt;
    &lt;p&gt;The combination of the fact that Fly secrets are visible only from within the apps, distroless containers, and transparent data encryption for PostgreSQL assures that the service (Pocketdata) provider cannot access their data, only the infrastructure provider (Fly.io) theoretically can, but practically speaking, this gives an extremely high degree of privacy assurance.&lt;/p&gt;
    &lt;p&gt;Hey! Your project looks very similar, from a conceptual point of view, to what I'm doing with https://github.com/superegodev/superego. Would you like to have a chat about it? Email in my profile, if you're interested.&lt;/p&gt;
    &lt;p&gt;Check out my project at https://www.MobiusClock.com: A 3D WebGL Clock on a Möbius Strip that shows 24hr time on a 12hr face. The hour indicator follows the edge of the strip, thus must make 2 turns to return to its starting point, giving you a 24 hour clock. The minute and second indicators move along the middle of the strip and thus return to their starting points in only one turn. Has the ability to rotate!&lt;/p&gt;
    &lt;p&gt;Just added a new feature: a 'Fast Mode' button to temporarily speed up the hands, which helps visualize how the slow-moving parts work, how the hour indicator moves along the edge. Would love feedback on the implementation.&lt;/p&gt;
    &lt;p&gt;If you happen to have an old or spare iPad or tablet, you can open my mobius clock page in a browser and set it on a shelf (plugged in of course). Kind of like a weird wall clock...&lt;/p&gt;
    &lt;p&gt;I'm working on Solitairle – a Yukon solitaire game where every board is guaranteed solvable: https://solitairle.com&lt;/p&gt;
    &lt;p&gt;Why? Most solitaire apps frustrate players with impossible games or endless randomness. Solitairle is designed for people (like me) who want a satisfying win through skill, not luck. Every day brings a new, solvable challenge, complete with helpful tools (back button, dead-end warnings) to keep it fun and frustration-free.&lt;/p&gt;
    &lt;p&gt;I’m especially interested in feedback from people who:&lt;/p&gt;
    &lt;p&gt;Enjoy casual puzzle games but get discouraged by unwinnable setups,&lt;/p&gt;
    &lt;p&gt;Value clean, minimalist interfaces without ads,&lt;/p&gt;
    &lt;p&gt;Have ideas for daily challenges or fun player stats.&lt;/p&gt;
    &lt;p&gt;Would love your thoughts: What frustrates you most about digital solitaire? What would make you want to play daily?&lt;/p&gt;
    &lt;p&gt;I recently have gotten into the "drag and drop" forms of programming like Node-RED and n8n.&lt;/p&gt;
    &lt;p&gt;Obviously, anyone here who has read my posts knows I know how to write code, but having a bunch of built in connectors that are agnostic to each other with the Oauth and the like being somewhat plug and play allows me to iterate on some ideas a lot quicker.&lt;/p&gt;
    &lt;p&gt;I installed an n8n instance on my server, and have become kind of addicted to making different Discord bots, and I'm having more fun with this than I thought I would. 95% of the stuff on there is basically drag and drop, and when I need more elaborate logic then I can easily drop into JavaScript. I am looking into writing new nodes for different services, and I keep having new ideas for different stuff I want to build.&lt;/p&gt;
    &lt;p&gt;We are close to landing our first customer - an enterprise-level one at that! We're Geneva Business Messaging, a tool to centralize, persist, and if necessary escalate critical interactions between large companies and their partners. For actual collaborative cross-company work in fields like engineering, logistics, or security - not spam, marketing, sales, or the other frequent purposes of B2B apps.&lt;/p&gt;
    &lt;p&gt;We're at genevabm.com if you want to check it out!&lt;/p&gt;
    &lt;p&gt;I've been building a Decentralized Database built on top of syncing CRDTs, and recently got it to a point I can demo. It's definitely in a "proof-of-concept" stage though, known security holes and all.&lt;/p&gt;
    &lt;p&gt;I've been focused on building out the featureset and keeping everything unstable instead of trying to finalize each piece as I build it. It's the opposite of how I normally build things but I think it's been working pretty well for this.&lt;/p&gt;
    &lt;p&gt;The WebGL game was build with my 2D game engine "Impact", which I previously ported to C[1]. The game has a 3d view, but logic still mostly works in 2 dimensions on a flat ground. The N64 version "just" needed a different rendering and sound backend.&lt;/p&gt;
    &lt;p&gt;Hey HN! I'm building https://openfret.com/ - the all-in-one platform for guitarists that I wish existed when I started playing.&lt;/p&gt;
    &lt;p&gt;OpenFret combines everything a guitarist needs in one place: smart gear inventory management, AI-powered practice sessions, real-time collaboration tools, and a vibrant community. Think of it as "GitHub for guitarists" meets comprehensive practice tool.&lt;/p&gt;
    &lt;p&gt;Core features:&lt;/p&gt;
    &lt;p&gt;1) Smart Guitar Inventory: Track your collection with auto-filled specs from thousands of guitar models. Monitor woods, pickups, scale length, string changes, and discover patterns in your gear&lt;/p&gt;
    &lt;p&gt;2) AI Practice Sessions: Generate personalized guitar tabs and lessons based on your practice history, with VexFlow sheet music and integrated metronome&lt;/p&gt;
    &lt;p&gt;3) Session Mode: Fork and merge music tracks like code. Layer recordings, see version history, and collaborate with musicians worldwide&lt;/p&gt;
    &lt;p&gt;4) Practice Analytics: Persistent timers, song tracking (Last.fm integration), scale visualization, fretboard maps, and chord progressions&lt;/p&gt;
    &lt;p&gt;5) Built-in Tools: Guitar tuner with frequency control, Strudel integration for backing tracks, and musical helpers to break out of E minor habits&lt;/p&gt;
    &lt;p&gt;Looking for:&lt;/p&gt;
    &lt;p&gt;Feedback from guitarists/musicians on which features resonate most&lt;/p&gt;
    &lt;p&gt;I think AI guided practice sessions could lead to something incredible but like everything "AI" it actually takes a lot of hard work to make it really useful.&lt;/p&gt;
    &lt;p&gt;I’m working on a quantum simulator written in C++ from scratch. I’m not using any external library, so I had to implement everything from the lazy eval structure to the eigen solvers and so on. It’s still very a WIP, but here’s the repo: https://github.com/braketware/hilbert-qusim&lt;/p&gt;
    &lt;p&gt;Today I'm hacking on automate-terminal, a command line program and Python library that abstracts the various terminal emulator automations (iTerm2, WezTerm, Kitty, tmux) into a single API. Mostly made for use by other tools. https://github.com/irskep/automate-terminal&lt;/p&gt;
    &lt;p&gt;Dog enrichment calendar - I have a lot of different types of treats, toys and activities that I'd like to do with my dog but I fell into routines and just gave him two or three toys and treats on repeat. So I'm building an app where I'd be able to configure an inventory of all the treats and toys I own and the app would remind me to use a new toy or treat every day, to minimize repetition. You'll also be reminded ahead of time for toys and treats that require preparation&lt;/p&gt;
    &lt;p&gt;Since I got a baby and we’re still adjusting to their schedule, I’m still working on the same project, Librario[1]. Librario is a simple book metadata aggregation API written in Go. It fetches information about books from multiple sources, merges everything intelligently, and then saves it all to a PostgreSQL database for future lookups.&lt;/p&gt;
    &lt;p&gt;You can think of it as a data source, or a knowledgeable companion that can provide comprehensive book information for online booksellers, libraries, book-related startups, bookworms, and more.&lt;/p&gt;
    &lt;p&gt;I got a pre-alpha build running for those that want to test it out[2], but the code is still not out there, as there are a few things I want to refactor. Wrote comprehensive documentation for it this weekend, now I need to refactor the merger package with some new rules, and write something to decrease the number of genres returned.&lt;/p&gt;
    &lt;p&gt;Been tough to find time to work on it because of the baby, but AI has been helping a lot to speed things up, and the work has been quite fun. Not sure if there will be interest in the idea, but it solves a problem I have, so I had to work on it anyway.&lt;/p&gt;
    &lt;p&gt;Hope to have the code on GitHub by the end of this week. AGPL licensed.&lt;/p&gt;
    &lt;p&gt;FURS does for Forth, what headers do for C, namely provide all the embedded configuration information inside a Cortex-M MCU, for the up to 100 inbuilt peripherals.&lt;/p&gt;
    &lt;p&gt;Without this data, neither C nor Forth (or any other language) have any clue about how to use the peripherals.&lt;/p&gt;
    &lt;p&gt;FURS does this by intercepting the Forth user source as it's uploaded to the on-chip compiler and transforming it into language the MCU inherently understands.&lt;/p&gt;
    &lt;p&gt;The Forth user source code is not altered in any way.&lt;/p&gt;
    &lt;p&gt;I've used the Fossil DCVS for the entire FURS project so that all the flowcharts, pictures, code, user doc, trouble-ticket, wiki ... everything is contained in the ONE FILE, under 5MB.&lt;/p&gt;
    &lt;p&gt;This one file gives you a web server so all you need is a browser to easily view all the above from the main menu.&lt;/p&gt;
    &lt;p&gt;I’m working a Garmin watch app to query all the rich data on the watch (health, physical, environmental, location sensors) from the watch + general AI assistant. Privacy focused using your own keys and Gemini. API calls direct from watch - no backend. https://untether.watch&lt;/p&gt;
    &lt;p&gt;I was tired of inspiration sites like Dribbble full of polished mockups that aren't practical. Or awwward like sites that don't represent the mundanity of most websites.&lt;/p&gt;
    &lt;p&gt;So, I spent a while building a tool that captures website design snippets. It's now a collection of 4,363 designs from 544 different domains.&lt;/p&gt;
    &lt;p&gt;For every design, it extracts:&lt;/p&gt;
    &lt;p&gt;The exact fonts used on the page (so far 561 unique font families I've found)&lt;/p&gt;
    &lt;p&gt;I'm working on fighting IBM's patent trolls. IBM slapped the words 'AI Interpretability' on Gauss' 200 year old continued fractions and was awarded a patent.&lt;/p&gt;
    &lt;p&gt;Now they can charge rent if they encounter a continued fraction library in the wild.&lt;/p&gt;
    &lt;p&gt;The authors simply implement a continued fraction library in Pytorch and call the backward() function on the resulting computation graph.&lt;/p&gt;
    &lt;p&gt;That is, they chain linear neural network layers and use the reciprocal (not RELU ) as the primary non-linearity.&lt;/p&gt;
    &lt;p&gt;The authors reinvent the wheel countless times:&lt;/p&gt;
    &lt;p&gt;1. They rename continued fractions and call them ‘ladders’. 2. They label basic division ‘The 1/z nonlinearity’. 3. Ultimately, they take the well-defined concept of Generalized Continued Fractions and call them CoFrNets and got a patent.&lt;/p&gt;
    &lt;p&gt;IBM's lawyers can strip out all the buzzword garbage if they feel litigious and sue anyone whose written a continued fraction library. Because, that's what the patent (without all the buzzwords) protects.&lt;/p&gt;
    &lt;p&gt;You sent me down a rabbit hole. In trying to track it down for myself I read a couple of others that I thought might be it, and was stunned by how obtuse these patents are.&lt;/p&gt;
    &lt;p&gt;What sort of leverage does this stuff provide? You mentioned "charge rent". What does that look like?&lt;/p&gt;
    &lt;p&gt;Honestly, I don't even know where to begin. It's insane IBM owns the patent to continued fractions.&lt;/p&gt;
    &lt;p&gt;If you wrote a continued fraction class in Pytorch and called backwards (or even differentiated the power series) then you're infringing on their copyright.&lt;/p&gt;
    &lt;p&gt;It's a personal project that grew out of my own frustration. I was annoyed of paying for (and switching between) 8+ different apps for my Pomodoro timer, a secure journal, and habit tracking. I wanted to consolidate everything into one clean, fast interface.&lt;/p&gt;
    &lt;p&gt;I've spent the last few months building it out it's a full-stack app with a Next.js 15 frontend and a FastAPI/PostgreSQL backend. I'm really proud of the tech and the "minimalist UI, maximalist features" feel.&lt;/p&gt;
    &lt;p&gt;The app is live and free to use. I'd love any feedback on the app itself, but I'm also genuinely looking for advice: What's the best way to find your first 100 users for a new productivity app?&lt;/p&gt;
    &lt;p&gt;I figure having real users is a good resume boost and its an app anyone can use so I thought getting users would be easy but I've been struggling with it&lt;/p&gt;
    &lt;p&gt;I'm resurrecting peer-to-peer Matrix (https://arewep2pyet.com) thanks to the Dutch government, who started funding it in October.&lt;/p&gt;
    &lt;p&gt;The main question is which P2P overlay network to use, if any: the prior incarnation used Pinecone (a variant of Yggdrasil), whereas this time we're pondering keeping it simpler and more scalable and using Matrix itself as the backbone to connect together smallish local P2P meshes - so by default you try to route via Matrix, but failing that you look on your LAN or BLE to see if you can talk directly to whoever you're addressing. Time will tell if this works :)&lt;/p&gt;
    &lt;p&gt;We are open to suggestions :) And the very first generation of P2P Matrix was indeed built on libp2p (and Protocol Labs led Element's Series B). However, the thought experiment here is whether we can get away without a full global P2P overlay at all in the interests of keeping it simple &amp;amp; stupid. We might well end up back at libp2p tho!&lt;/p&gt;
    &lt;p&gt;We've banned this account for repeatedly breaking the site guidelines and ignoring our requests to stop.&lt;/p&gt;
    &lt;p&gt;If you don't want to be banned, you're welcome to email hn@ycombinator.com and give us reason to believe that you'll follow the rules in the future. They're here: https://news.ycombinator.com/newsguidelines.html.&lt;/p&gt;
    &lt;p&gt;I’ve been working on ScratchTJ, a DIY digital turntable built with a Raspberry Pi and Arduino Nano. It’s based on the open-source SC1000 code, but with some hardware changes and tweaks to make it easier to build and customize.&lt;/p&gt;
    &lt;p&gt;It runs on a Raspberry Pi 2 with an AudioInjector sound card, a small LCD screen, a rotary encoder, and even an old hard-drive platter as the “deck.” The goal is to make a simple, open, and affordable way to experiment with scratching and mixing — no fancy gear required.&lt;/p&gt;
    &lt;p&gt;It’s still in progress, but it works pretty well and has been a fun way to explore DIY DJ tech and embedded audio.&lt;/p&gt;
    &lt;p&gt;I have always wanted to learn Rust, but was too distracted to get started.&lt;/p&gt;
    &lt;p&gt;So, I started working with Claude on building a postgres database replication application. I'm learning Postgres internals as well as how brittle database replication and subscription can really be. Although this is for Seren, you can replicate between any PG databases. https://github.com/serenorg/postgres-seren-replicator&lt;/p&gt;
    &lt;p&gt;Big learning: Claude Sonnet with Rust is massively productive. I'm impressed, but code bloat is a thing.&lt;/p&gt;
    &lt;p&gt;We're building NextBunny.co - A visual development platform for Nextjs users.&lt;/p&gt;
    &lt;p&gt;if you build, design, or ship products in Nextjs this is something you must try. Amazing UI components ( shadcn, framer, tailwind) smooth builder and high quality code export.&lt;/p&gt;
    &lt;p&gt;This is a pet project for myself. I love listening to online radio while at work, helps me focus. But I didn't really click with any of the current selection of web apps out there so decided to build one myself.&lt;/p&gt;
    &lt;p&gt;It uses the great API available at radio-browser.info for all the radio information.&lt;/p&gt;
    &lt;p&gt;Been using it as a way to learn how to market a website as well. Learning a lot.&lt;/p&gt;
    &lt;p&gt;Would suggest that you filter out any radio stations where the URL isn't working if possible.&lt;/p&gt;
    &lt;p&gt;For example I filtered down to "United Kingdom" and then "bass" - 3 of the 6 worked and would rather see ones that are active.&lt;/p&gt;
    &lt;p&gt;Also if possible to apply the country filter within the search bar, took me a second to realise I had to open the filter for country, select that, then go back to my search.&lt;/p&gt;
    &lt;p&gt;When clearing my search of "Bass" in the example above, it reset the search to default (didn't have my country filter) even though the filter was still applied when opening the filter section.&lt;/p&gt;
    &lt;p&gt;Super easy interface to use though, really well done.&lt;/p&gt;
    &lt;p&gt;Currently working on getting back into a fitness routine. I got into this habit of hacking on side projects in my very little spare time but I have realized taking care of my body will pay off far more than any project&lt;/p&gt;
    &lt;p&gt;All the best - the best project to work on! I recently tested a walking pad with a standing desk at my friends place - I was surprisingly productive being able to walk while using the computer. Will be investing in a standing desk and walking pad for my home office.&lt;/p&gt;
    &lt;p&gt;Been working on documenting as much publicly-accessible stained glass as possible with https://stainedglassatlas.com/. No fancy tech (vanilla HTML/CSS/JS). Come document any local stained glass in your area!&lt;/p&gt;
    &lt;p&gt;There are many language-learning apps, but almost none that focus on improving conversational Hindi for kids.&lt;/p&gt;
    &lt;p&gt;Made this web app for my nephew, based in Singapore, after watching him struggle to find anyone to practice Hindi with outside of family calls (since most of his friends are Chinese). The idea is to have a 24x7 partner to speak with Hindi and make it fun. This can complement the formal Hindi classes that most kids of Indian diaspora parents take.&lt;/p&gt;
    &lt;p&gt;LINOG.ph is a live earthquake tracker for the Philippines.&lt;/p&gt;
    &lt;p&gt;The Philippines deals with thousands of earthquakes a year. Whenever the government volcanology and seismology department detects earthquakes, they post it on their official website.&lt;/p&gt;
    &lt;p&gt;When a major earthquake happens, a huge number of people try to visit the site, causing downtime for up to an hour.&lt;/p&gt;
    &lt;p&gt;LINOG.ph caches earthquake data from the official government website and the U.S. Geological Survey site, and makes them highly available to the public.&lt;/p&gt;
    &lt;p&gt;I built this after seeing friends and family donating and providing support for affected families after a major earthquake in Cebu. This was my way of helping out.&lt;/p&gt;
    &lt;p&gt;Two super typhoons have hit the Philippines in the past two weeks, so I'm also considering adding in typhoon tracking.&lt;/p&gt;
    &lt;p&gt;Frustrated by the complexity and high overhead of most monitoring tools, I wrote Simon.&lt;/p&gt;
    &lt;p&gt;It’s a single binary, dependency-free monitor in Rust that does it all: metrics, Docker, alerts, and file browsing. While maintaining a minimal footprint for embedded systems and other constrained hardware.&lt;/p&gt;
    &lt;p&gt;AgentOS is a lisp-machine inspired runtime where agents can safely propose, simulate, and apply changes to their own code, policies, and workflows, all under governance, with full audit trails. Every external action produces a signed receipt. Every state change is replayable from an event log.&lt;/p&gt;
    &lt;p&gt;Working on a binary that will instrument every Java service running on Linux host machine with OpenTelemetry Java Agent.&lt;/p&gt;
    &lt;p&gt;Kinda like this (https://github.com/open-telemetry/opentelemetry-injector) but with support of having multiple service name for different services. This includes tomcat, normal systemd services and also services running inside docker containers.&lt;/p&gt;
    &lt;p&gt;EDIT: I am popping my cherry with this comment on HN. Been a lurker since past 2-3 years.&lt;/p&gt;
    &lt;p&gt;For my work I've developed a web-based Monte Carlo simulator with a visual, node-based editor for building supply chain models. Last week, I started making it available for everyone.&lt;/p&gt;
    &lt;p&gt;You can have a look at https://simcarlo.com. The tool allows you to see the full spectrum of potential outcomes instead of just a single guess.&lt;/p&gt;
    &lt;p&gt;I've been wanting to learn more embedded type projects, and I've been snacking too often so I've been building a box that will only open on the weekends.&lt;/p&gt;
    &lt;p&gt;I got all the components, tested it on a breadboard, learned to solder and now I'm working on the 3d Print to enclose everything.&lt;/p&gt;
    &lt;p&gt;I actually just did a test run to see if my current 3d design would fit my PICO board, and it fit, but not that secure yet.&lt;/p&gt;
    &lt;p&gt;Im a developer but never worked this close to metal, so I've been so happy with how it's been going so far, making me real proud of myself.&lt;/p&gt;
    &lt;p&gt;I just launched a 10-Bit Video Thumbnail Provider for Windows.&lt;/p&gt;
    &lt;p&gt;Windows does not natively support rendering thumbnails for 10-bit videos, which are commonly produced by cameras like the Sony A7IV.&lt;/p&gt;
    &lt;p&gt;When I started working on a short film the video clips were piling up on my hard drive. Opening them one by one to find what I was looking for was tedious.&lt;/p&gt;
    &lt;p&gt;I could not find a reputable solution to this problem, so I started a company and built one. I went through the process of EV Certification to have the installer and executable code signed.&lt;/p&gt;
    &lt;p&gt;I hope to be in the Microsoft Store soon.&lt;/p&gt;
    &lt;p&gt;I'm also building other utilities with similar purpose.&lt;/p&gt;
    &lt;p&gt;We’re building Ward, a security browser extension that uses Gemini Nano, an on-device LLM, to scan for phishing, scams, and other threats from the DOM.&lt;/p&gt;
    &lt;p&gt;Think of an antivirus for everyday web users, like young children, older adults, and less savvy individuals.&lt;/p&gt;
    &lt;p&gt;We recently participated in the Google Chrome Built-in AI Challenge 2025 and have submitted to the Chrome Web Store.&lt;/p&gt;
    &lt;p&gt;We’re looking to meet people who may know someone Ward is good for and would want to provide feedback. Alternatively, we’d love to chat with any IT Managers/Directors of Security/Google Apps Admins who would be interested in piloting us as an anti-phishing enterprise solution.&lt;/p&gt;
    &lt;p&gt;You can DM or hit me at fitzgeraldcedric(AT)gmail.com :)&lt;/p&gt;
    &lt;p&gt;Ooh, good idea. It started as a question: "How do we make this thing the most private?" and the obvious answer was using offline local device LLMs (e.g. Prompt API/Gemini Nano).&lt;/p&gt;
    &lt;p&gt;Will poke around and see if there's interest here, thank you!&lt;/p&gt;
    &lt;p&gt;I wanted to give anyone the magic power to make himself an FPS game of their place (appart, museum,ect...). Still not perfect but it's light and my 3D editor is simple enough for anyone. - No coding. - And no need for Unity or Unreal.&lt;/p&gt;
    &lt;p&gt;This is a cool idea! So I think, unfortunately, you are competing with automated tools like https://poly.cam/ My cousin-in-law produces music videos, and he'll take a polycam of sports cars (or even people!) and add them to his videos, it's powerful and instantaneous. No 2-3 day wait time.&lt;/p&gt;
    &lt;p&gt;It's great that you're working on this. If you want to continue on this, I'd consider: - Cleaning up the design of the website-- it looks kind of crappy. Get an AI agent to clean it up for you, it's better to look like "generic professional website" rather than "crappy amateur". - Use the more common words for creating 3d models. A "Visit" sounds like an experience, but what you're really making is a "scene", or a "spatial capture", or a "floor plan". - Maybe try to figure out a niche. Is your niche that people can edit this the 3d object afterwards? Or is the niche integration with video games? You gotta find something that doesn't directly compete with polycam.&lt;/p&gt;
    &lt;p&gt;I've been working on an open-source containerized agent framework called Capsule Agents. Its built around 3 key ideas I've dealt with inside the agent ecosystem&lt;/p&gt;
    &lt;p&gt;1. Agents become far more capable when they have access to a CLI and can create or reuse scripts, instead of relying solely on MCP.&lt;/p&gt;
    &lt;p&gt;2. Multi-agent setups are often overvalued as “expert personas” but they’re incredibly effective for managing context, A2A is the future.&lt;/p&gt;
    &lt;p&gt;3. Agents are useful for more than just writing code. They should be easy for non-engineers to create and capable of providing value in many domains beyond software development.&lt;/p&gt;
    &lt;p&gt;A webcam &amp;amp; microphone JS tester library that you can put in front of your WebRTC or MediaRecorder web app to diagnose any possible issues (the presence of getUserMedia, secure context, required devices, policies blocking device access, supported resolutions, etc.). It also primes your users’ OS/browser permissions before they get to the real app.&lt;/p&gt;
    &lt;p&gt;For the past 2 months I have been doing a heavy deep dive into image generation and image generation editing capabilities. This then had me discover that you can generate storyboards for short stories, and automate the creation of these as videos with video generation models. This is a topic that interests me heavily, and as such I am now building my own workflows around that. I am documenting the entire journey here:&lt;/p&gt;
    &lt;p&gt;It's not something I am looking to commercialize, but I actually did drop out of film school (with semesters in creative storytelling) to pursue software 15 years ago. And I feel like this will open up a whole new way of visual storytelling as well as personal and product branding. I have gotten quite some emails about it, from interesting people in different industries, as some more strongly worded (not so nice) emails from someone in the VFX industry since I started. Its by far one of the most interesting tangents I have ever went on.&lt;/p&gt;
    &lt;p&gt;I built a tool to generate a PDF for each row of a Google sheet. For example, you can generate 100 personalized PDFs (like certificates) for 100 students listed in a Google Sheet.&lt;/p&gt;
    &lt;p&gt;Once you sign up and connect your Google sheet, it generates a template (using AI) based on your data, which you can edit in a Notion-like editor. You can then generate PDFs for your entire sheet or a for a range of rows.&lt;/p&gt;
    &lt;p&gt;A web app for my music needs - metronome, ABC notation editor with MIDI playback and PDF render, an embedded YouTube video player with a chapter/section creator based on timestamps and a looping feature for the chapters for practicing&lt;/p&gt;
    &lt;p&gt;Offline first, everything is saved to Local Storage. Sharing is also purely serverless - the ABC text and the video chapter defs are shared via query parameters after compression and base64 encoding.&lt;/p&gt;
    &lt;p&gt;I’ve created a small command-line tool that generates a hash-based, human-readable list of git repositories and data folders. Its purpose is to capture the exact state of all projects and files in a single plain-text file.&lt;/p&gt;
    &lt;p&gt;I built it because I work across multiple machines and often worry about which projects are on which computer or whether I’ve left any files in unique locations. Now I can diff the summaries between devices to see what’s out of sync, which repositories have uncommitted changes, and which folders have been modified.&lt;/p&gt;
    &lt;p&gt;I avoid using cloud sync services, and most of my files are already in git anyway. I find that having clear visibility is enough, I just need to know what to commit, push, pull, or sync manually.&lt;/p&gt;
    &lt;p&gt;I would be glad if it proves useful to someone besides me.&lt;/p&gt;
    &lt;p&gt;A Civil 3D plugin (Genabler) that will include all the network catalogs and collate the Civil 3D styles for civil engineers to use. There are some out-of-the-box catalogs and styles shipped with the default installation, but they are quite limited and fairly well hidden—which is not surprising, given that Civil 3D is a huge beast. As a result, they are not commonly used.&lt;/p&gt;
    &lt;p&gt;When people think about Civil 3D, they often assume it requires BIM modelers (in a sense, just glorified drafters) to create all the necessary catalogs and styles, and to assist with their use.&lt;/p&gt;
    &lt;p&gt;My Civil 3D plugin will:&lt;/p&gt;
    &lt;p&gt;1. Make standard, market-compliant catalogs and polished styles available to engineers at large. Think of it as the WordPress theme provider equivalent.&lt;/p&gt;
    &lt;p&gt;2. Make the entire process easy and painless through the plugin, with prominent buttons for quick access.&lt;/p&gt;
    &lt;p&gt;If the plugin is done well, there will be less need for BIM modelers, since for a fee, engineers could simply purchase catalogs and styles that are so easy to use they require no technical training.&lt;/p&gt;
    &lt;p&gt;As a side benefit, I also get to explore how LLMs can help me write code. It has been a while since I last updated my AI usage policy [0], and I look forward to revisiting it.&lt;/p&gt;
    &lt;p&gt;A tool for “grep”ing MIPS binaries[0] to find duplicate code (functions, segments, sections) primarily to aid in decompiling.&lt;/p&gt;
    &lt;p&gt;It does some neat things to match instructions while avoiding location dependent references, then creates a hash that can be used to used to search binaries in linear (or faster!) time.&lt;/p&gt;
    &lt;p&gt;Still a WIP, but being used on at least one decomp project.&lt;/p&gt;
    &lt;p&gt;I am working on a SQL query engine for multi-dimensional and hierarchical analysis compatible with Apache Spark, ClickHouse, BigQuery, Snowflake, PostgreSQL and DuckDB. GitHub https://github.com/squashql/squashql Website https://www.squashql.io/&lt;/p&gt;
    &lt;p&gt;I was working on a iPad-focused Dungeons &amp;amp; Dragons app focused on the Dungeon Master called Campaign Codex but I got a little bored with building CRUD apps.&lt;/p&gt;
    &lt;p&gt;Decided to pivot and start learning about databases and their internals more. Currently pulling down Clickhouse and reading some code along with the reading the book Database Internals by Alex Petrov.&lt;/p&gt;
    &lt;p&gt;So I'm technically not "working on" an app...I am working on myself to branch out and attempt to specialize a bit more as I progress in my career.&lt;/p&gt;
    &lt;p&gt;Assets — Personal Wealth Tracker https://github.com/venil7/assets A self-hosted net worth and portfolio manager. Track multiple portfolios (ISA, General, Pension, Crypto, etc.) and monitor individual or total performance. Supports any asset available via the Yahoo Finance API, automatically converts to your base major currency.&lt;/p&gt;
    &lt;p&gt;This is super cool. I noticed that you mention that you will add MCP support soon. I was wondering, do you think it would be possible to control MacOS via voice, remotely, through one of the available MCP servers that allow MacOS control. Do you think that would be feasible?&lt;/p&gt;
    &lt;p&gt;Got it. But you could just use it on your MacBook on those occasions where you want to "talk" to your computer remotely to check on some progress it made on a specific job. My use case would involve switching desktops, activating specific windows, and reading their content and taking some action. But depends more specifically on the MCP that exposes that functionality, and not your app. I was asking because you're probably more familiar on how reliable such an approach might be.&lt;/p&gt;
    &lt;p&gt;I was a YC founder in 2006 and now work as a data scientist full-time, but on the side I also do Christian apologetics, helping fellow engineers/scientists/mathematicians seek answers to life's deepest questions.&lt;/p&gt;
    &lt;p&gt;I am building better dev tools for firmware and PCB developers.&lt;/p&gt;
    &lt;p&gt;For example, we have GitHub Action workflows that allow you to push builds to the connected EmbedHub project. Your EmbedHub project has fine grained release management - so for example only the git tagged releases will be shared with the customer, but the testing/QA team will get access to builds from regular commits on branches as well.&lt;/p&gt;
    &lt;p&gt;I am also building a physical device (called HAL) similar to the now discontinued EtcherPro[1] - which will connect to your EmbedHub account and have access to your releases. This will let you offload tasks like long term testing, mass flashing and provisioning of devices, and more.&lt;/p&gt;
    &lt;p&gt;I started the project when ChatGPT 4 was first released, using it as a way to explore what LLMs could actually do. I also find working on it very relaxing, there is something cool about uncovering secrets hidden in code for more than twenty years.&lt;/p&gt;
    &lt;p&gt;Ugh. It's time for me to start transitioning my iOS/Watch/Mac programs to be "Liquid Glass-native."&lt;/p&gt;
    &lt;p&gt;I should be able to do it with my various personal apps, but one app I've written, was done in concert with a professional graphic designer, and he is not happy with LG, so I expect that app to be a pain.&lt;/p&gt;
    &lt;p&gt;I've been really frustrated with the state of networking and discovering new career opportunities lately. Both in person and online I feel like there aren't very good tools and I have a growing disdain for LinkedIn. I wanted to make a tool that helps ambitious navigate their career goals and meet people who are going to move the needle. It's called Catalyst: https://getcatalyst.tech/&lt;/p&gt;
    &lt;p&gt;- News, weather, newsletters, social media posts, reddit, youtube, etc. all appear in your digest.&lt;/p&gt;
    &lt;p&gt;- Launching a mobile app as well now but this will be slightly different than the web app. It will use AI to automatically prepare your daily digest based on preferences/settings you give it during onboarding. Each day when you wake up you'll receive a notification of digest being ready, and it will contain all the content you care about for the day ahead (meetings, weather, health data, commute data, news, etc).&lt;/p&gt;
    &lt;p&gt;Intentionally made simple and centered around plain text files and editing speed. I've spent a week on the prototype, now it's good enough to dog-food. Would like to eventually distribute it as a multi-platform app.&lt;/p&gt;
    &lt;p&gt;It is a recipe app but better, and way more technically capable than anything out there. The goal is to make the best recipe app ever made. With bulletproof easy to follow recipes and smart features to make cooking simple. Everyone deserves good food at home, but good food is complicated and time consuming. An experienced cook can make good food quickly, cheaply and make it look easy. The idea is that Kastanj will have the knowledge you don’t so you can cook like a pro without having to spend years learning everything.&lt;/p&gt;
    &lt;p&gt;Backstory: I have a note where I write down practical problems I experience in life. I noticed over time that the amount of notes related to food and cooking was growing faster than anything else. I then began searching for a solution. I tried over 50 recipe apps, always the premium version if possible. There are some good apps out there but even the best ones only solved something like 50% of my issues. After enough frustration and search I just decided to start working on my own app. That was 4 years ago... It turns out that solving some of these problems where technically complicated to do, so now I understand why no other app could solve my problems. None the less, after 4 years of work, starting over from scratch 5 times, I have now landed on a solution that technically solves all my problems.&lt;/p&gt;
    &lt;p&gt;Going forward: Now I am working on filling the app with data and make it easy to use for normal humans. I am on purpose limiting myself to only perfecting the core functionality of what a recipe should be. I intend to launch sometime in 2026. The UI will be small and limited at first, but it is perfect for my needs. Therefore I hope it will also be perfect for someone else. Over time I will enable more advanced functionality and build it out based on user feedback. I know the backend can support 100% of my needs, but I don’t want to make it bloated. Therefore the UI is on purpose focused on only the most important things and then we will build it out with time, together with the recipe creators and end users.&lt;/p&gt;
    &lt;p&gt;I've been working on two game development projects for the past couple of years.&lt;/p&gt;
    &lt;p&gt;One project is for building rhythm games in multiple game engines and multiple platforms. Currently, it works in Unity, Unreal, Godot, SDL (or any C++ game engine), and MonoGame (or any C# game engine), and runs on Windows, macOS, and Linux. I'm working on adding Love2d (or any Lua game engine) and Bevy (or any Rust game engine). I have a few local prototypes of it working in Unity and Godot, but nothing public yet. Still trying to figure out what kind of game I want to make with it.&lt;/p&gt;
    &lt;p&gt;The other is a general purpose game engine in C++ with SDL. It's far enough along that I'm building games in it, but it's more of an exploration into how games are made than a replacement for Unity or Godot. I suppose it could be eventually, but I'm trying to be realistic with what it can do. One thing I'm pretty happy with regarding this engine is that one of the demo repos will automatically build to WebGL and publish to itch.io when changes are pushed.&lt;/p&gt;
    &lt;p&gt;Recently launched my free app for gardeners to share plants with each other, Plantshare.&lt;/p&gt;
    &lt;p&gt;Now I'm working on a few changes to the app, most notable is moving any plants marked as 'for sale' out from the main section because it turns out people are more greedy than I anticipated and it's getting in the way of sharing the free stuff, cuttings etc.&lt;/p&gt;
    &lt;p&gt;There's also some demand for a web front end so I might work on that next. (currently only android and ios)&lt;/p&gt;
    &lt;p&gt;I had an initial boom of downloads in South Africa but lately most new downloads are in USA.&lt;/p&gt;
    &lt;p&gt;Idea came from one of my clients, where they wanted to use AI agents throughout the organization but at that moment there was no centralized governance or security concepts. This pulls everything at one place and tries to solve the security concept with per-user credentials, which can be provided out-of-band through the MCP protocol (generated a one-time link end-user can use to sign in to the underlying MCP server with OAuth or provide API key)&lt;/p&gt;
    &lt;p&gt;Making advanced multiphysics simulations and optimizations accessible through a simple web interface and AI chat agents. I’m building SimuPort (https://simuport.com ) to lower the barrier to running and iterating on complex simulations. I’m interested in hearing from anyone who has needed these kinds of simulations in practice (e.g., optimizing airflow in devices, analyzing thermal–structural interactions in prototypes) or who has experience with tools like Ansys, OpenFOAM, COMSOL, SimScale, or similar. What worked, what didn’t, and what’s still missing?&lt;/p&gt;
    &lt;p&gt;I’ve been working on MemoryPlugin (https://www.memoryplugin.com), a tool that adds long term memory across AI tools&lt;/p&gt;
    &lt;p&gt;Lately I’ve worked on a chat history based memory feature that can recall information from every conversation you’ve ever had with ChatGPT and Claude. It’s been particularly useful and also technically fun to implement. Speed has been very important as I do just in time summarisation and a multi stage RAG pipeline, and most LLMs have unacceptable performance. I ended up going with GPT-OSS on Groq due to its ultra low latency often completing full generations before Gemini or ChatGPT APIs return even the first token.&lt;/p&gt;
    &lt;p&gt;The ability to recall details from conversations going back years makes tasks where I want personalised plans or feedback like 10x more useful, at times I get the AI to ingest tens of thousands of tokens of context to help me better.&lt;/p&gt;
    &lt;p&gt;I'm working on Argon Chess, a deterministic chess variant with some degree of cheat resistance (hard to describe to chess engines like Fairy Stockfish) and tons of variety. A week ago, I added a way to play friends online a week ago (a Discord Activity) and a simple Play a Dumb AI feature on its website. You can also print the cards for free for offline play. https://argonchess.com/&lt;/p&gt;
    &lt;p&gt;I'm building a tool for managing Google Ads campaing called Rudys.AI:&lt;/p&gt;
    &lt;p&gt;- Search campaigns: - automatically crawl website, find the offerings and generate new campaigns - Provide qualitative recommendations such as, relevant terms to include/exclude, e.g. including typos as keywords, improvements on landing page&lt;/p&gt;
    &lt;p&gt;- Shopping campaign: - Smart labeling of all products to allocate the budget among Top performers, Rising and Ghost products to avoid draining the budget. E.g. instead of a campaign with 10k products with one budget , turn it into 5 campaigns with different budgets doubling down on what works.&lt;/p&gt;
    &lt;p&gt;I'm getting back in to audio programming, starting off with Pd[1] and reading Miller Puckette's book[2]. I'm planning on writing some low-level C libraries afterwards, using The Audio Programming Book[3] as a guide&lt;/p&gt;
    &lt;p&gt;Why? I love the old arcade and game boy games, and I want to recreate them to my liking. I also love mechanical systems and space rovers, and I want ro build worlds to explore and simulate these things&lt;/p&gt;
    &lt;p&gt;Im working on hvacAI.ca, a website that can take a quote for an HVAC system and help understand in simple terms the differences in cost and ability of the proposed solutions.&lt;/p&gt;
    &lt;p&gt;-https://salespark.app/apps/discount-spark: A Shopify app that allows merchants to create more powerful discount codes so they can create stronger offers for their customers.&lt;/p&gt;
    &lt;p&gt;What I recently built but didn't find a successful product market fit:&lt;/p&gt;
    &lt;p&gt;-https://wordazzle.com: A word game that's designed to expand your vocabulary with exceptional words.&lt;/p&gt;
    &lt;p&gt;-https://spicychess.com: Chess, meet boxing! Imagine playing chess BUT you can also smack your opponent. Now, if you smack em enough times to drain their health completely(yes, you have a health bar), you can steal their turn. It's fun, a little evil, but after thousands of $ spent on marketing, never found critical mass.&lt;/p&gt;
    &lt;p&gt;A structural biology viewer/editor/CAD-style application. Combines functionality similar to PyMol, Coot, VMD, and GROMACs. Open-source, standalone executable. Built in Rust and CUDA.&lt;/p&gt;
    &lt;p&gt;And the host of bio libs required to do it. The sort of thing that are mature in Python, for example, but I needed to build for Rust.&lt;/p&gt;
    &lt;p&gt;It's intended to be a sort of social network focused on IRL groups/communities and finding others with the same interests in the same area, and just building local communities in general.&lt;/p&gt;
    &lt;p&gt;It's currently still a part-time venture, but I'm planning a launch on HN soon to get input/gauge interest in the latest iteration. FWIW, I posted the initial version on HN just over a year ago and got a ton of amazing feedback, much of which I've incorporated over the last year - https://news.ycombinator.com/item?id=40717398&lt;/p&gt;
    &lt;p&gt;Working on a low cost, miniature Bluetooth tracker. The inspiration was my parents keep losing (forget) their spectacles in the house. I wanted to build something that is very easy and simple to use and it was important to keep it small. SO the form factor is something like an airtag but 10x smaller which can be just stuck on to the spectacles and forget that it exists. Next step, obviously is to build a simple app that shows the location of this tracker with a range based on the Bluetooth signal strength.&lt;/p&gt;
    &lt;p&gt;Working on AI interpretability infrastructure! Starting with hallucination/failure mode detection and causal tracing in transformer-based foundation models. It's non-SAE, domain-agnostic, and works for any kind of tokens or sequence data (e.g. not just English text - biological sequences, physics data, etc). Some of our early tests indicate that this detection setup could broadly work well for any property, but we've mostly validated on hallucinations. If you have access to self-trained or open-weight models, would love to have you try out the alpha version - running it through HuggingFace!&lt;/p&gt;
    &lt;p&gt;Basically, I'm building tooling and providing these to community run clubs that help turn kids from consumers into creators. I'm focusing on game development initially, but have plans to expand into other areas of creativity.&lt;/p&gt;
    &lt;p&gt;I've much experience building software for creators. I'm a (core) developer of Tabletop Simulator. I worked at a now defunct startup which allowed people to create and distribute their own interactive fiction stories using partner third-party IPs.&lt;/p&gt;
    &lt;p&gt;I have a background in EdTech. I used to be Head of Engineering at Ender, where we ran custom Minecraft servers for kids: https://joinender.com/ and prior to that I was Head of Engineering at Prequel / Beta Camp, where we ran courses that helped teenagers learn about entrepreneurship: https://www.beta.camp/. During peak COVID I also ran a social emotion development book subscription service with my wife, a primary school teacher.&lt;/p&gt;
    &lt;p&gt;I recently started a local chess club, and did a quick search for software to use to allow us to manage the club, but couldn't find anything open-source/free.&lt;/p&gt;
    &lt;p&gt;I wanted something that would allow us to record members, games, etc., and also allow us to be assigned a local club rating. Anyway, after doing some searching and only finding paid software, I decided to just build something. That lead to https://openchessclub.org&lt;/p&gt;
    &lt;p&gt;I plan on building a QR code generator that allows club members to check-in during meetings, which will then allow players to be matched, and some other features, although it is primarily aimed at smaller chess clubs, so don't know how far it'll go.&lt;/p&gt;
    &lt;p&gt;A kernel extension-less sshfs for macOS. I tried using FSKit and got halfway before I felt too constrained by the extension security model (must be app sandboxed, must be approved by the user in system settings). Now it’s just a standalone command line binary that doesn’t require any special permissions since it proxies NFS to SFTP. Everything “just works” and performance is reasonable&lt;/p&gt;
    &lt;p&gt;I've done this with C++ in the past, but ran into substantial friction with the CMake toolchain, specifically w.r.t:&lt;/p&gt;
    &lt;p&gt;- cross-platform compilation with large dependencies (vcpkg ports)&lt;/p&gt;
    &lt;p&gt;- running multiple compiler chains in the same build step&lt;/p&gt;
    &lt;p&gt;That second point is necessary if, for example, there's some AOT asset processing work that uses a native tool, and you're building for web. Expressing that some targets should use the emscripten toolchain while others should use the native toolchain, and interleaving between them, was a mess. TBF, I haven't done that with cargo or build.rs yet and it may prove to be equally frustrating.&lt;/p&gt;
    &lt;p&gt;Other features:&lt;/p&gt;
    &lt;p&gt;- undo/redo using a stack of swappable states&lt;/p&gt;
    &lt;p&gt;- serialization to disk (native) and LocalStorage (web) with some integration tests in progress but I am not satisfied with the correctness of my implementation: I want to *guarantee* that all information is preserved round-trip, but I also want a Patek watch.&lt;/p&gt;
    &lt;p&gt;- OBJ, GLTF, GLB models are loaded as "blueprint scenes" which are distinct from the "world scene." I made this distinction at the type-level because "scenes" are groups of entities that use newtype IDs (`LightId(u64)`, `MeshId(u64)` etc.) as primary and foreign keys to refer to each other, and I wanted to make it impossible for an entity in scene A to hold an ID for an entity in scene B. Instantiating a blueprint requires creating new IDs for every object.&lt;/p&gt;
    &lt;p&gt;- W.I.P. Alpha rendering, depth sorting, overhauling the material system to support multiple shaders (tough) that may be compiled after the engine itself (even tougher, a lot of runtime dynamic state and schema validation stuff), physics, scripting - oh yeah!&lt;/p&gt;
    &lt;p&gt;- Scripting using JS on both web (runs in browser itself) and desktop (uses a packaged JS runtime `Boa`) but Boa doesn't perform well on desktop in debug mode so I'm exploring other options.&lt;/p&gt;
    &lt;p&gt;I'm building Envelope — a banking product purpose-built for envelope-style budgeting.&lt;/p&gt;
    &lt;p&gt;Most “budgeting banks” (Ally Buckets, Wells Fargo Budget Watch, etc.) bolt budgeting on after the fact. Envelope was designed from day one as an integrated budgeting bank account. The checking, savings, and debit cards are all built around real-time envelope balances.&lt;/p&gt;
    &lt;p&gt;Each envelope acts like a dedicated account with its own balance and optional virtual card. Spending directly from an envelope means your budget is always accurate — no syncing, no spreadsheets, no “catch-up” categorization. Everything runs on-ledger with automatic spend-locking and instant visibility.&lt;/p&gt;
    &lt;p&gt;We’re a small YC-backed team (former Robinhood and Apple Card team members) focused on rebuilding personal finance from the ground up to be simple, and transparent https://envelopebudgeting.com&lt;/p&gt;
    &lt;p&gt;Made some updates to this open-source library I wrote to render audio waveforms using the GPU on the browser (WebGPU).&lt;/p&gt;
    &lt;p&gt;Example on the site. Works without enabling flags on Chromium browsers. There's an example to scrub and zoom in real time on some audio. Feedback welcome!&lt;/p&gt;
    &lt;p&gt;My backhand is OK but my forehand sucks. Grip styles for standard handles usually end up favoring one side or the other. I'm making a handle shape that's easier to get the blade angle right on both sides. Hopefully a couple more iterations on the 3D printer and then I can have a functional prototype made.&lt;/p&gt;
    &lt;p&gt;Currently its at like 90% completion but there are some subtleties that probably need to be worked out a bit more. The PDF linked from that page explains all the details (although for reading just peeking at the charts on Page 4, 5, &amp;amp; 7 should get someone to reading it fine enough). Currently both Alice In Wonderland and Dr Jekyll are fully transcribed into the reform if someone wants to jump into seeing it in action. Certainly interested in thoughts and complaints of the system.&lt;/p&gt;
    &lt;p&gt;Also looking here sometime soon to playing around with an improved SI unit system. So if anyone has any new ideas here too I'd be very interested.&lt;/p&gt;
    &lt;p&gt;Examples of things to be touched upon would be like: - Make g (not kg) the base mass unit. Making 1 m^3 of water = 1 g - Bring commas to be the universal decimal point separator.&lt;/p&gt;
    &lt;p&gt;Been working on my programming language https://github.com/buzz-language/buzz for 4 years now (with some down periods). Currently mainly working on the tooling: LSP, DAP and formatter. Also managed to get fuzzing working with AFL++ and found a bunch of bugs with it.&lt;/p&gt;
    &lt;p&gt;There's an agent monitor which intercepts requests either using a LLM proxy or hooks, that gives you full telemetry into the agents + MCPs used. And a MCP gateway that enables centralized deployment and securing of MCP.&lt;/p&gt;
    &lt;p&gt;If you play DnD, I would love feedback! Feel free to leave it as GitHub issues or discussion.&lt;/p&gt;
    &lt;p&gt;If you don't play DnD, you might still find the repo interesting. It's hono on bun, I render jsx server side and client side is all htmx. I use vercel's ai toolkit for the LLM interactions, which are super fun and work really well. I think this is a great use for AI actually. I've structured the code so the same services can be called either by the user via forms and routes, or via LLM tool use, so for every action in the code you can do it via either LLM or "manually".&lt;/p&gt;
    &lt;p&gt;The LLM usage is fun and interesting. What model are you using, and how much customization are you doing to integrate with the app and maintain character?&lt;/p&gt;
    &lt;p&gt;I suggest adding an export function to make the characters more portable. Maybe export to PDF as well as JSON.&lt;/p&gt;
    &lt;p&gt;https://github.com/ezeoleaf/mycorust - A mycelium network simulation after I started to get interested in fungi and mycelium. Learnt a lot of Rust and gain more knowledge of performance and resource usage.&lt;/p&gt;
    &lt;p&gt;Historical public companies Merton Probabilities of Default.&lt;/p&gt;
    &lt;p&gt;A project just for fun and still having to finish a couple of things.&lt;/p&gt;
    &lt;p&gt;I plan to make the datasets public (everything but some raw market data as vendors don't allow that) and also about to add the explanation of what Merton PD is.&lt;/p&gt;
    &lt;p&gt;My friends and I have been hacking on http://dateit.com for a while. It's an event planning app (works best on iOS and android, but there is a web app) with lots of fun features:&lt;/p&gt;
    &lt;p&gt;We started working on this all the way back during the Covid lockdown when we wanted to capture that "facebook events" experience without the facebook.&lt;/p&gt;
    &lt;p&gt;It's grown into something much more than our original idea. Most of the features are free and we have a fair pricing model that doesn't nickel-and-dime you like many of the competing apps do. Would love your feedback!&lt;/p&gt;
    &lt;p&gt;I think there's a lot of potential for AI to improve the way we organize and manage our inboxes, while still letting us keep control over it.&lt;/p&gt;
    &lt;p&gt;What I've learned is that there are a lot of little features that make up a good email client that you may not even think about when using one, like threading, quote blocks, even what email address(es) to autofill when you reply to an email. For an app you use potentially for hours a day, the polish and "last 20%" makes a huge difference - and takes a while to build!&lt;/p&gt;
    &lt;p&gt;If you have any feedback, especially on what features are most important to you in an email app, I'd love to hear it :)&lt;/p&gt;
    &lt;p&gt;Disclaimer: I'm making presumptions, since I haven't used the service. Correct me if I'm wrong.&lt;/p&gt;
    &lt;p&gt;I don't like the idea of a centralized system to flow all of my email accounts through. I think this would work better as a localized agent that runs against my account (more like an email reviewing system vs a centralized email monitor). That would be less of a privacy concern, in my opinion.&lt;/p&gt;
    &lt;p&gt;Curing broken developer heads. Good software engineers are good, because they are non neurotypical with many downsides such bad emotion/feeling management with huge avoidance.&lt;/p&gt;
    &lt;p&gt;My point to help to build your own MentalOS that works for, to live smoother lives without huge up and downs.&lt;/p&gt;
    &lt;p&gt;I wanted to see if I could use generative AI to build a whole business. Not just a digital product or an app — but the entire business from end to end:&lt;/p&gt;
    &lt;p&gt;(Spoiler: I did manage it and launched in just 75 days from start to first order)&lt;/p&gt;
    &lt;p&gt;- Three tier corporate structure with manager-managed LLCs and a private WY LLC as manager, complete with a knowledgebase-powered assistant that can write share registries, banking resolutions, meeting minutes, contribution contracts, loans and more&lt;/p&gt;
    &lt;p&gt;- Supply chain management with proprietary lot tracking that tracks PO line items from production to delivery&lt;/p&gt;
    &lt;p&gt;- Generated the base for all product images, helped write and research label design and text, wrote SEO titles and product descriptions&lt;/p&gt;
    &lt;p&gt;- Used Claude Code to build the entire Shopify theme for the site, all collections, product pages, legal pages and a COA database to boot&lt;/p&gt;
    &lt;p&gt;- Used Claude Code to build a custom Shopify app to integrate lot tracking into the shop so that when lots sell out the next lot is queued for sale and all lot-related metadata is synced to the product variant and displayed on the product page&lt;/p&gt;
    &lt;p&gt;- used Claude Code to build a super analytics platform that combines the data from GA4, Shopify orders, and Meta business suite into a single feature store where I can wrangle the data to ask/answer any question I can dream of about audience segments, product popularity, what’s working or not, and get insights on what to do next&lt;/p&gt;
    &lt;p&gt;I’m working on a Chrome extension called Console Dock, which adds a floating dev console window directly inside the page. I built it as a fun side project because I often work on smaller screens and hate constantly switching or resizing panels. Still very experimental, but it’s already proving useful for quick debugging sessions.&lt;/p&gt;
    &lt;p&gt;Spent the last three months building a competitor/lookalike ML model + API. Started using plain embedding similarity and quickly realized you end up with similar noisy results as ocean.io. Ended up using similarity learning which works quite well with little data. Launched this as an API and small web app. Hardest part right now is to fend off scrapers honestly.&lt;/p&gt;
    &lt;p&gt;I have been working on https://easymiet.eu/ It is specific to the German rental market. Basically if you want to rent an appartment in Germany most landlords require you to fill out a non-standardized self-disclosure form. That can be annoying to the landlord because especially in larger cities you might have a couple of hundret applicants and it is also annoying to the possible renter since they have to fill out the same information for every apartment they apply for. This is where easymiet comes in. As a landlord you can generate a viewing, shared it through QR or a link. Interested renters can apply using their profile. It also has a application approve and dismissal workflow automatically sending emails to the applicant. My plan was to monitize it selling applicants the ability to add more info to their profile like a picture or relevant documents. However so far I haven't been able to generate much interest. The tech stack is Next JS with BetterAuth, Drizzle and Postgres. It is hosted on a Hetzner VPS using Kamal ( wrote a blogpost about that if you are interested: https://markow.dev/blog/complex-next-js-app-kamal )&lt;/p&gt;
    &lt;p&gt;Quick feedback: looks way too empty for me to look real. Could also just be a scam. Also: why would I as an applicant add more data for money? The landlord has the benefit, they should pay for that.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Wir sind nicht bereit oder verpflichtet, an Streitbeilegungsverfahren vor einer Verbraucherschlichtungsstelle teilzunehmen.&lt;/p&gt;
    &lt;p&gt;To be fair, the thread is called "What are you working on", so it's by definition work-in-progress.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Also: why would I as an applicant add more data for money? The landlord has the benefit, they should pay for that.&lt;/p&gt;
    &lt;p&gt;In many hot rental markets (My experience mostly with Berlin), you are mostly not in a position to say "the landlord should pay that" and everyone is desperate to supply the best, most complete and most convincing documents even if it feels bad to fork over that much personal data to a random stranger on a platform.&lt;/p&gt;
    &lt;p&gt;This month I wrote a small Windows utility to keep a PC "always awake": prevents the PC from going to sleep (using a Windows API that exists just for that) and simulates invisible mouse movements every 60 seconds to keep apps like MS Teams happy, so that the user always appears active.&lt;/p&gt;
    &lt;p&gt;There is a PowerToy thingy that's similar but it's full of options and command-line flags. My version has no options, it's just a tray utility that can be toggled on (green) or off (orange) with double-click. There are also physical mouse jigglers but they're cumbersome, and many have visible mouse movements, which is extremely annoying (not all of them do this but many do!)&lt;/p&gt;
    &lt;p&gt;The full install file is just 100Kb, works on all versions of Windows starting with Win7, installs without admin rights. Can't live without it!&lt;/p&gt;
    &lt;p&gt;I need to make a website for it but I'm procrastinating on that one last step...&lt;/p&gt;
    &lt;p&gt;Working on a phone app that streamlines household management for unmotivated losers (like me) so that they stop wasting money (wasted food) and time (procrastination)&lt;/p&gt;
    &lt;p&gt;Working on an app that helps me (and other people) do household management on autopilot. It helps me manage things, food, expiration dates, shopping, chores, and I get notified periodically to review my lists. I waste way less food and I actually do my chores instead of procrastinating. https://okthings.app&lt;/p&gt;
    &lt;p&gt;Yes. How i tried to solve it: you have a shopping list where you can add things on the fly. These things will need to be categorized (food, household supplies etc) at a later date, which is when the review is due for the "Uncategorized" category.&lt;/p&gt;
    &lt;p&gt;Generally, i tend to buy the same things, so the "big" data entry job happens only once.&lt;/p&gt;
    &lt;p&gt;(1) For one product I am working, I have been working on a custom reporting language for producing high quality PDFs. I used hy.py as a basis to make it LISP-like.&lt;/p&gt;
    &lt;p&gt;(2) I need to make a Django postgres site that I am running more reliable. Earlier I was experimenting with making static HTML renderings of the pages. That is certainly nice, but it took several hours to reproduce the site. I am currently prototyping making read-only replica of the database in SQLite (the database is only 1 MB) and hosting it on CDN, and then pulling that for the read-only replicas. The database export takes only some seconds.&lt;/p&gt;
    &lt;p&gt;(3) I vibe coded a iOS app using that same SQLite database that fetches it from the same location. It was surprisingly simple. It seems much simpler than using Flutter or React native.&lt;/p&gt;
    &lt;p&gt;I'm working on an app to display charts, analysis, and data on English football league games.&lt;/p&gt;
    &lt;p&gt;The real goal is to figure out how to use code gen AI (Cursor) effectively for data science projects and to figure out rapid deployment. I'm pushing things a bit harder than you typically see in demo apps (e.g. different chart types (e.g. violin plots, heatmaps, line charts), interactive charts, JavaScript widgets interacting with Bokeh charts, etc).&lt;/p&gt;
    &lt;p&gt;I'm trying to figure out all the skills, processes, and training you need to build a technical app very quickly. I'm at the deployment stage now.&lt;/p&gt;
    &lt;p&gt;The idea is that a generic video message doesn't appeal to a fan of a video game streamer, instead what really would be cool would be watching them react to your best moment in a game.&lt;/p&gt;
    &lt;p&gt;Our software removes all friction from the journey, the fan doesn't even need to record their own gameplay, we have bots set up that can load up someone else's gameplay just from their username, record their highlight for them, upload it to our platform, then the streamer just needs to come in, watch a ~60 sec clip, give a genuine reaction, press 'submit' and its all done.&lt;/p&gt;
    &lt;p&gt;There's a few markets I'm trying to find product market fit in: ~1-2 minute coaching sessions, sports commentator style commentary over your clip from influencers, hyped up reactions from your favorite streamer, a community-focused segment on a stream of watching a compilation of your fan's best moments.&lt;/p&gt;
    &lt;p&gt;We're ready to launch, just trying and struggling to find the first few people to sign up.&lt;/p&gt;
    &lt;p&gt;Learning that RCS is even more of a monstrosity and a lie than I thought a few years ago. Yikes. Lots of groundwork a decade ago setting the stage for "the carrier creates a common service anyone can interact with" (like sms/mms currently do, which would be great) but in practice it's pretty much 100% "only the carrier app or Google/Samsung messages has access to literally any of it".&lt;/p&gt;
    &lt;p&gt;Yeah I'm not gonna touch it and I'm going to actively encourage people to disable it. Use signal instead.&lt;/p&gt;
    &lt;p&gt;OpenRun runs as a web server, which does GitOps driven app deployments. You can currently deploy apps on a standalone machine, on top of Docker/Podman. Working on adding support for deploying on top of Kubernetes. On Kubernetes, OpenRun will replace your build jobs (Jenkins/Actions etc), CD (ArgoCD etc) and IDP (Backstage etc). The same declarative config which works on a standalone machine will work on Kubernetes, with no YAML to maintain.&lt;/p&gt;
    &lt;p&gt;What I am working on is my masters thesis in bioinformatics supports/HPC: "Predicting the running time of bioinformatics tools", by running (initially) 5 tools 1000 times each with different parameters and then fitting a curve.&lt;/p&gt;
    &lt;p&gt;I am pretty sure I can get 70% predation rates +/- 10% . Unfortunately, I'm blocked by the lack of hardware. Kind of not-quite school affiliated (so I cannot really ask for national computing resources), so I am trying to build a single threaripper pro node on my own. Hurts the wallet, but if added to slurm as module, this can have implications.&lt;/p&gt;
    &lt;p&gt;I'm working on Habitat. It's a free and open source, self-hosted platform for communities to discover and discuss their local area. The plan is for it to be federated. I've recently solved an issue with cron jobs that was driving me mad for ages. I feel that I'm pretty much nearing a first tagged release, but I feel that I need to work on branding and messaging a bit before I do. I can't tell if I'm procrastinating that final push to something that makes it more official or not.&lt;/p&gt;
    &lt;p&gt;Is there a cadence for these threads? I had in mind to "be prepared" to post in November's with what I'm working on, but I expected it to come around on the 15th (mid-month).&lt;/p&gt;
    &lt;p&gt;(The proprietary apps are built with the toolkit).&lt;/p&gt;
    &lt;p&gt;I've struggled to pitch or articulate the vision here, but my latest pithy attempt is: scaling self-actualization by mechanizing the nested loops described by Anders Ericson's 'deliberate practice' - Inner loop: individual learners maximize their skill uptake velocity and performance peak by adhering to domain specific best practices - Outer loop: domain specific best practices get refined according to innovation or serendipitous discoveries from the inner loop (eg, someone is observed to beat out prior best practices)&lt;/p&gt;
    &lt;p&gt;As mentioned, I'm flat-foot posting here, so the pages aren't all prepped. https://flutor.app/dbg and https://letterspractice.com/dbg show some of the innards. Not linked, but I'm especially fond of https://letterspractice.com/dbg/juggling - the premise here that as child practices the letters, the letters exemplify the principles of effective practice in alliterative skill domains (juggling Js, batting Bs, flossing Fs (it's hard ok?))&lt;/p&gt;
    &lt;p&gt;I created a media editing app that lets you do some of the most common video editing tasks (cut, resize, compress, blend audio etc). It's browser based so your files never leave your machine and is very fast (leveraging the latest and greatest libraries such as Media Bunny).&lt;/p&gt;
    &lt;p&gt;Currently building a suite of media inspection and encoding tools for video engineers: https://video-commander.com.&lt;/p&gt;
    &lt;p&gt;Still very much a work in progress, but expecting to release a first version by end of year. Built on Tauri, in case anyone is curious.&lt;/p&gt;
    &lt;p&gt;I've created various open-source and commercial tools in the multimedia space over the last 10+ years and wanted to put it all together into something more premium.&lt;/p&gt;
    &lt;p&gt;I have been building music theory/midi related vst plugins in JUCE.&lt;/p&gt;
    &lt;p&gt;It's mostly targeted at me, or others that make music, but are not piano players.&lt;/p&gt;
    &lt;p&gt;There isn't much to show currently, but I have a rhythm generator, and have been working on a chord builder. The main thing that has taken time has been trying to decide which things to add to a user interface to make it worth actually building.&lt;/p&gt;
    &lt;p&gt;Working with a group of friends on a "microcontroller-for-makers" kind of thing called the MakerPort. (https://makerport.fun) Sort of similar to an Arduino or micro:bit, but uses the MicroBlocks programming editor (https://microblocks.fun) created by John Maloney, who was the original team leader for Scratch at MIT for 11 years. The hardware includes an mp3 player, I2C ports, accelerometer and true capacitive touch sensors.&lt;/p&gt;
    &lt;p&gt;I’m working on a platform to run a friendly competition in “who builds the best reasoning AI Agent”.&lt;/p&gt;
    &lt;p&gt;Each participating team (got 300 signups so far) will get a set of text tasks and a set of simulated APIs to solve them.&lt;/p&gt;
    &lt;p&gt;For instance the task (a typical chatbot task) could say something like: “Schedule 30m knowledge exchange next week between the most experienced Python expert in the company and 3-5 people that are most interested in learning it “&lt;/p&gt;
    &lt;p&gt;AI agent will have to solve through this by using a set of simulated APIs and playing a bit of calendar Tetris (in this case - Calendar API, Email API, SkillWill API).&lt;/p&gt;
    &lt;p&gt;Since API instances are simulated and isolated (per team per task), it becomes fairly easy to automatically check correctness of each solution and rank different agents in a global leaderboard.&lt;/p&gt;
    &lt;p&gt;Code of agents stays external, but participants fill and submit brief questionnaires about their architectures.&lt;/p&gt;
    &lt;p&gt;By benchmarking different agentic implementations on the same tasks - we get to see patterns in performance, accuracy and costs of various architectures.&lt;/p&gt;
    &lt;p&gt;Codebase of the platform is written mostly in golang (to support thousands of concurrent simulations). I’m using coding agents (Claude Code and Codex) for exploration and easy coding tasks, but the core has still to be handcrafted.&lt;/p&gt;
    &lt;p&gt;I've spent several years since Covid times solo-developing an ad-free website with 50+ solitaire/puzzle games.&lt;/p&gt;
    &lt;p&gt;I've gathered some feedback from users from HN already and now trying to fix things.&lt;/p&gt;
    &lt;p&gt;I'm looking to genuinely improve the experience so would be incredibly grateful for any feedback. I'm also wondering what it lacks – any particular games or modes?&lt;/p&gt;
    &lt;p&gt;I’m building a reward chart app for parents. See link below. I just submitted it yesterday for review the App Store and Google Play. Now I wait. Fingers crossed.&lt;/p&gt;
    &lt;p&gt;I’m working on Alaska, a serverless compute platform I built entirely from scratch — no Kubernetes, no existing orchestration layers. It can spin up dozens of containers in parallel in just a few seconds. The platform is designed around a fast feedback loop — you write code locally, test instantly, and run it remotely with minimal friction. There’s a Python SDK that uses decorators to define what runs on the platform, so your local functions become distributed services without extra boilerplate. I also built a custom filesystem using FUSE to handle code, data, and runtime synchronization cleanly across nodes. It started as a personal exploration of distributed systems, but it’s grown into something that feels genuinely exciting! It's created by a developer for developers. Planning to open it up for beta testing soon.&lt;/p&gt;
    &lt;p&gt;For the first time in years I'm working somewhere that doesn't use JIRA or Trello and find myself without a Kanban system. I'm having serious withdrawals. I have limitations on using a non-approved IT system because I use customer data so I vibed a PWA Kanban system. Stores data in browser and only vanilla code. No external dependencies.&lt;/p&gt;
    &lt;p&gt;Working on a little project to make Spotify recommendations better.&lt;/p&gt;
    &lt;p&gt;You get to choose the genres you're interested in, and it creates playlists from the music in your library. They get updated every day - think a better version of the Daily Mixes. You can add some advanced filters as well, if you really want to customise what music you'll get.&lt;/p&gt;
    &lt;p&gt;Does this deal with, what I call the "Armin Problem?" I typically listen to EDM and there is an extremely popular DJ named Armin van Buuren, and he has other aliases (which exacerbates the issue). His sets end up directly on music platforms, and he pulls in a ton of EDM sub-genres (which makes him a great DJ!). Any recommendation algorithm that visits one of his aliases is doomed to be connected to every other sub-genre, so I might be listening to progressive trance, and be in the mood for that, and end up on deep house (as an extreme example). Within EDM, genres can be as different as blues is to metal.&lt;/p&gt;
    &lt;p&gt;Not directly, no. I still rely on the data that Spotify gives me that relates to artists' information; and it's not great a lot of the time. E.g. there are obvious cases where artists belong to genres that they should not belong to. I do have some ideas for improvement, but they are still WIP.&lt;/p&gt;
    &lt;p&gt;What it allows you to do, though, is create your playlists with extended filters. E.g. you can select genres, and at the same time exclude genres - that helps with the "cross-contamination". You also get a view of all the artists that match your selections and you can add exclusions for them as well. It is a bit of manual work, but it works pretty good for me personally.&lt;/p&gt;
    &lt;p&gt;the service is a suite of online vetting and due diligence tools for website flippers, Fb marketplace sellers/buyers and Tiktok shoppers&lt;/p&gt;
    &lt;p&gt;The domain has an interesting backstory. I acquired if it n 2022 from Epik after they stole the $10,000 I had deposited into their Escrow service. The money was meant for acquiring a newish stable diffusion hosting website that was competing with civit.ai. When the Epik issue was discovered, the seller pulled out.&lt;/p&gt;
    &lt;p&gt;Acquiring that website could have changed my life.&lt;/p&gt;
    &lt;p&gt;I'm building a coding agent, named VT Code [0]. VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Supports multiple LLM providers with automatic failover and efficient context management. Support OpenAI, Anthropic, Google Gemini, xAI, DeepSeek, OpenRouter, Z.AI, Moonshot AI, MiniMax, and Ollama (local &amp;amp; Cloud). Agent Client Protocol and Model Context Protocol fully support. VT Code supports a rich set of configuration options, with preferences stored in vtcode.toml. Has both Visual Studio Code and Open VSX extensions so that you can install in VS Code or Cursor, Windsurf, Eclipse.&lt;/p&gt;
    &lt;p&gt;I've been building it for several months now and enjoy the learning process, I also wrote a blog post and learnt a ton about terminal, ANSI processing. The learning has been immense for me, I now have working knowledge of ANSI escape codes, grapheme clusters, terminal emulators, Unicode normalization, VT protocols, PTY sessions, and filesystem operations, all the low-level details I would have never think about until I were implementing them. [1]&lt;/p&gt;
    &lt;p&gt;I'm still working on WithAudio (https://desktop.with.audio). A one time payment Text To Speech Desktop App. Because I think everything doesn't have to be a subscription.&lt;/p&gt;
    &lt;p&gt;In October I finished the PDF parser. It was a big challenge extracting PDF contect with correct paragraph breaks on user's computer locally. I'm gonna write about this soon.&lt;/p&gt;
    &lt;p&gt;Now I'm working on a web extension that talks to the app that run locally on your system so you can use WithAudio in your browser with very good performance, 100% local and private.&lt;/p&gt;
    &lt;p&gt;I was tired of repeat, sponsored, and "safe" music suggestions from Spotify, so I built a discovery engine that puts the control back in the user's hands.&lt;/p&gt;
    &lt;p&gt;The core idea is simple: You define a "Discovery Model" with explicit constraints (specific genres, release years, track popularity, etc.). The app then uses this blueprint to source tracks.&lt;/p&gt;
    &lt;p&gt;The results are fresh for two reasons:&lt;/p&gt;
    &lt;p&gt;- "Known" Track filtering: Excludes all songs saved in your library and recent listening history.&lt;/p&gt;
    &lt;p&gt;- Active Curation: Uses your custom model, not a vague, opaque algorithm.&lt;/p&gt;
    &lt;p&gt;It’s built with a local-first mentality and a focus on privacy. No black-box AI "vibe" mixes, just pure, objective discovery based on your criteria.&lt;/p&gt;
    &lt;p&gt;I canceled my Spotify subscription because it would not let me "reset" the algorithm to get fresh suggestions.&lt;/p&gt;
    &lt;p&gt;A "discovery algorithm" that I used (works great for jazz) consisted on looking up which musicians played on an album that I liked on discogs and searching for more albums from them.&lt;/p&gt;
    &lt;p&gt;I really like the range memorization tool from GTO Wizard, but want to be able to put in custom/arbitrary ranges to test. I also want to be able to import and simplify ranges from other sites. Work in progress, but every scenario is url encoded (warning: subject to future breaking changes) and I use those urls in for links in my Anki decks.&lt;/p&gt;
    &lt;p&gt;I'm working on boiling the ocean - we're building a new CRM to compete with some of the big players. I tried very hard to avoid doing this, but I've helped enough business owner friends set up CRMs to realize there's MUCH to be desired. My goal is to create a CRM that people rave about - something that is very rare. Pretty much everyone I help views CRMs as a necessary evil. Our bold challenge is - can we make a CRM that is delightful to use?&lt;/p&gt;
    &lt;p&gt;Of course we have to slap "AI" on it in this market, but we plan on adding AI features that are actually thoughtful and not just a glorified chatbot.&lt;/p&gt;
    &lt;p&gt;Sounds interesting! As someone who works in Revenue Operations the CRM space is ripe for disruption, especially around using CRM data to help sales teams explore the data.&lt;/p&gt;
    &lt;p&gt;I vibecoded a POC of what something I think would work (around the latter part around exploring the data). Need to complete it and start testing it.&lt;/p&gt;
    &lt;p&gt;Thanks! I totally agree. It starts with getting the basics right. I think this is where most CRMs get it wrong - getting users to correctly enter and maintain clean data is a challenge. We're trying to build smarter schemas for contacts, quotes, sales, etc. but we're also making a really intuitive UI for easily updating information. Further still, we're trying to automatically fill in data for the customer. Many fields can be automatically inferred based on the context of a deal.&lt;/p&gt;
    &lt;p&gt;Once we get this right, I think the next step is exactly what you said, building really good tools to explore the data. Making it easy for non-technical users to run machine learning on their data to make business decisions or see cool visualizations. We realize that so many of our customers want to know this stuff and have no way of getting at it! We've got a lot of ideas for both visualizing and analyzing the data. I think there's a ton of potential for cool things here. Heatmaps, spiderwebs, interactive charts, etc. Stuff that brings the data to life. One of the common asks from some of our early customers is a heatmap of the world to visualize their sales/reach and see changes over time. Visualizing progress per sales region, etc. I think sales especially has a lot of opportunities for better lead generation and qualification as well.&lt;/p&gt;
    &lt;p&gt;i'm currently unemployed but i have experience as a CSM and account manager for multiple companies (all have used Salesforce) if you ever want feedback or bounce ideas.&lt;/p&gt;
    &lt;p&gt;This would be awesome, we're in hardcore MVP build mode right now - when we get closer to launch I'll hit you up.&lt;/p&gt;
    &lt;p&gt;I'm a little delusional, but I think there's ground to steal back from Salesforce. Most folks I talk to hate how complicated Salesforce is (one even calls it Salesfarce). I've heard a story or two about smaller companies trying to adopt it and wasting a hundred thousand or two implementing Salesforce only to have it never get used. On top of that, you need to train your employees to use Salesforce effectively.&lt;/p&gt;
    &lt;p&gt;The key is simplicity, building a CRM that anyone can instantly understand just by looking at it. This is insanely hard but I think we'll pull it off. I'll show you more what I mean when I reach out. Thanks!&lt;/p&gt;
    &lt;p&gt;Still working on this and some things will definitely change, but IMO the system prompt is already solid, so that the response isn't unnecessarily scary on one hand, but not too general on the other&lt;/p&gt;
    &lt;p&gt;Unfrotunatelly, it happens and I am aware of this. In that case:&lt;/p&gt;
    &lt;p&gt;a) you are lucky because your CV is not scannable by AI so it's good if you want to keepyoru carieer as far as possible from AI tools ;)&lt;/p&gt;
    &lt;p&gt;b) you are unlucky: most likely the software recruiters are using to pre-screen applications (and they are using it a lot) is not seeing your CV either so you will be dropped on the first stage, :( work on this if you consider finding new job nowadays&lt;/p&gt;
    &lt;p&gt;c) if you still want to use my tool consider extracting CV's text to .txt or reformat PDF (this will help you with point b)&lt;/p&gt;
    &lt;p&gt;I am building https://arabicworksheet.com, AI powered Saudi Arabic learning app for expats who work and live in saudi arabia. 100% FREE. It generates printable worksheets based on your level, dialect and topics.&lt;/p&gt;
    &lt;p&gt;I am also building an app for kids to make their arabic learning fun, rewarding and enjoyable. Do try and share your feedback. TIA&lt;/p&gt;
    &lt;p&gt;I wanted to visualize all my walks and runs on a single map. I built a native iOS app that fetches Apple Health and Strava workouts and visualizes them. Privacy was a major factor in building the app, so all the data stays on the device. Next version will have a time-lapse video option. Any feedback welcome.&lt;/p&gt;
    &lt;p&gt;hosting a month-long residency for indie hackers in Da Nang, Vietnam!&lt;/p&gt;
    &lt;p&gt;we invited 10 of the best indie devs from around the world to live &amp;amp; build alongside us for a month at a beautiful villa. for free. (we have sponsors like OpenRouter, Cognition, n8n, and CodeRabbit!)&lt;/p&gt;
    &lt;p&gt;A game-agnostic social/legal/financial overlay for virtual worlds. Minecraft, Rust, Roblox, etc.: legal ownership claims (vs possession), titles (recognized by other players or not), laws, player-issued currencies. Smart contracts but with as little blockchain stuff as possible.&lt;/p&gt;
    &lt;p&gt;The iron rule is no direct interaction with the world. These are things that players can in theory always start on their own as long as they can communicate.&lt;/p&gt;
    &lt;p&gt;An OpenAPI code generation framework for TypeScript called Skmtc (pronounced like "schematic")&lt;/p&gt;
    &lt;p&gt;It handles the complexities of parsing OpenAPI and rendering output code, while providing the end user with full control over generator code via string templates.&lt;/p&gt;
    &lt;p&gt;Imagine something like React but for code generation where each code generator can compose its own output using the outputs of other generators.&lt;/p&gt;
    &lt;p&gt;I'm trying to improve the UX of my time-zone converter. I started with my dedicated converter pages, like /est-to-ist. The goal was to make it easier to identify which times are best for scheduling meetings:&lt;/p&gt;
    &lt;p&gt;I’m working on a platform that makes it easy for people in West Africa to buy and sell cryptocurrencies (like USDT, USDC, ETH, BNB, POL, AVAX, etc.) directly with mobile money — the most popular payment method in the region.&lt;/p&gt;
    &lt;p&gt;The goal is to bridge crypptocurrencies and local mobile wallets to make crypto useful in everyday life — not just for trading, but also for online payments.&lt;/p&gt;
    &lt;p&gt;A few key features:&lt;/p&gt;
    &lt;p&gt;Mobile money integration (MTN, Moov, Orange, etc.)&lt;/p&gt;
    &lt;p&gt;Instant buy/sell of USDT, USDC, ETH, and other assets&lt;/p&gt;
    &lt;p&gt;Crypto payment gateway — businesses can now accept stablecoin payments directly on their websites&lt;/p&gt;
    &lt;p&gt;I’m currently focused on improving liquidity and expanding to more countries.&lt;/p&gt;
    &lt;p&gt;Would love feedback from the community — especially around :&lt;/p&gt;
    &lt;p&gt;- Liquidity and Marketing to find the first users.&lt;/p&gt;
    &lt;p&gt;Happy to share more details or collaborate with anyone working on similar problems.&lt;/p&gt;
    &lt;p&gt;- Bespoke software for the group including: shared embedding graph of highlights and annotations, IRC chat with @ for members and books and authors, collective bookshelf&lt;/p&gt;
    &lt;p&gt;I genuinely want to benchmark myself with fellow peers how on long they take to consume text book. I am not that into fiction or short fiction books - I generally loose interest.&lt;/p&gt;
    &lt;p&gt;How long would technical books take you to complete, say you have to read Effective Java 3rd Edition&lt;/p&gt;
    &lt;p&gt;Finally making a simulation of my heat engine. It's kind of like stirling engine, but working on entirely novel cycle, theoretically should be able to achieve over 80-90% efficiency (yes, more than Carnot theorem says). I had this idea for 15 years already, but didn't have enough free time to make prototype. Now I don't have much time, but thanks to AI I have kickstarted simulation program (it told me which equations to use and how, I do most of my programming myself), turns out it's not as hard as I've imagined when you know which equations to use. Still working on it at max several hours a week because I have two other programming jobs. If it works, it will noticeably bump humanity on Kardashev scale.&lt;/p&gt;
    &lt;p&gt;carnot theorem does not put an absolute limit , a carnot cycle can have any efficiency as long as you have reservoirs hot and cold enough ,&lt;/p&gt;
    &lt;p&gt;besides that if you could be more efficient than carnots cycle at two temperature you can spontaneously extract heat from a cold object and out it in a hot object without any input energy , this would mean you can have perpetual motion . we are not just going to bump a kardashev scale , were going to truly max out and go beyond.&lt;/p&gt;
    &lt;p&gt;fun fact the U S patent office has been bogged down by so many perpetual motion applications they have made it policy to outright reject such applications without a working model satisfactorily demonstrating it&lt;/p&gt;
    &lt;p&gt;It is not a carnot cycle. It will NOT be able to pump heat, it's not a reversible cycle (it's not even a single cycle, it's a series of open-ended heat and pressure transformations). And using a heat-pump will also not make it a perpetual motion. Heat pump can be used as a kind of heat-transformer here, so if you have a lot of low temperature air (but higher than your ambient temp), you could use heat pump to gather energy from that air and present a higher-temperature air for my engine (losing some small amount of heat in the process, but heat pump will reuse heat wasted in it's own electric engine).&lt;/p&gt;
    &lt;p&gt;It should achieve such efficiency with air heated to 150C and ambient temp of 20C. If you heat air so that it expands more than 2x, it will start to lose efficiency.&lt;/p&gt;
    &lt;p&gt;BUT - this is all theoretical, I work on simulation that will confirm if it works. It might not, I might have made some big error in thinking how it works, but I searched for 15 years on some way this should not work. I contacted two physics professors specializing in thermodynamics and they couldn't find a way this won't work, both said "Yeah, but to tell more, we need prototype or simulation".&lt;/p&gt;
    &lt;p&gt;I’m building RootCX (https://rootcx.com). A customer "operating system" replacing dozens of SaaS tools.&lt;/p&gt;
    &lt;p&gt;As a second-time founder, I've watched the SaaS boom create an ocean of best-of-breed tools. Each solving one slice of the problem. One solving it end-to-end.&lt;/p&gt;
    &lt;p&gt;Now every company runs on a patchwork of apps, APIs, and workflow hacks just to keep customer context alive. It's insane how normalized that's become.&lt;/p&gt;
    &lt;p&gt;RootCX starts from the opposite premise: the customer is the core, not the app. Everything: CRM, support, billing, workflows, AI, ... plugs into one shared customer base. Less juggling tools, more actually running the business.&lt;/p&gt;
    &lt;p&gt;This looks cool. But that means people need to use your own apps right and you will have to provide apps for every niche? This sounds a bit like an ERP system, similar to what https://www.odoo.com does.&lt;/p&gt;
    &lt;p&gt;I am right now building a proactive coach on top of my AI work capture app. Concept is very simple: It takes a screenshot every few minutes and analyzes what you're working on. From there it identifies task blocks, and checks if it should start a chat based on your intentions (eg to tell you to move out of your rabbit hole, take a break, help with a task, ...)&lt;/p&gt;
    &lt;p&gt;https://donethat.ai Passively processing screenshots is obviously pretty sensitive, it has an option to bring your own (local or remote) LLM, otherwise I process with gemini and never store any data.&lt;/p&gt;
    &lt;p&gt;It's in beta right now so if you want to try it you have to enable "proactive chat" in settings.&lt;/p&gt;
    &lt;p&gt;This week we're building out the UX around formatting and this month we're building a more robust set of integration tests and integrating with a large industry platform.&lt;/p&gt;
    &lt;p&gt;I am finally making my own blog. I have been only planning for ages. I found that I had a lot to say for the past years working on AI, and I want to record them somewhere. I do not expect a lot of visitors or at all in fact. The blog is going to be just for me to remember stuffs and to keep track of them.&lt;/p&gt;
    &lt;p&gt;I am using hugo to build suckless static pages. LLM helped me so that I don't need to read all their docs. I haven't finished it yet nor posted a single blog. But there will be one soon.&lt;/p&gt;
    &lt;p&gt;Currently popular AI chat interfaces feel restrictive when exploring or learning complex concepts/ideas. I often want to revisit earlier parts of a conversation, ask branching follow up questions, connect related concepts, compare and contrast between various chain of thoughts. This UI exploration aims to solve some of these limitations.&lt;/p&gt;
    &lt;p&gt;It's a honeypot system that uses AI to mess with attackers. When someone tries to hack your app, it detects them and serves up fake responses based on attack type.&lt;/p&gt;
    &lt;p&gt;The system learns from attackers behavior and creates convincing decoys to waste their time and frustrate their efforts. It's basically a trap that gets smarter the more attackers poke at it.&lt;/p&gt;
    &lt;p&gt;I'm working on a performance review (PR) management platform that doesn't require a steep cost and deep integration into HRMS platforms.&lt;/p&gt;
    &lt;p&gt;It's a need I have for myself and the teams I run – It offers direct PR's, 360º reviews, recording of wins and lessons (something often overlooked), and aims to be a platform for team and individualised growth, that is accessible to small and large businesses alike.&lt;/p&gt;
    &lt;p&gt;Trying to get Clippy (_that_ Microsoft Agent Character) to run on mac so I can make it notify me about github/jira/CLI status changes. https://github.com/tkfoss/MSAgentUtils&lt;/p&gt;
    &lt;p&gt;I'm thinking a lot about the ARC-AGI ML benchmarks, especially the "shape" of the dataset and what that says about how it should be solved. I think there's good reasons to believe that deep learning - at least differentiable SGD backprop style - is a bad fit for this specific benchmark, due to the tasks being almost entirely discrete symmetries, and also having so little data to approximate the discrete symmetries with continuous ones (considering deep learning to be the learning of continuous symmetries). I think that a more explicit and discrete approach is the way to go, and it's possible to build something surprisingly general and not heuristic-based even without gradient descent, guided by minimum description length to search for both grid representations and solver functions. I'm looking for teammates for ARC-3 so hit me up if this sounds interesting, I'd love to chat!&lt;/p&gt;
    &lt;p&gt;I made a viewer on my website to build intuition for my preferred perception algorithm which is entropy filtering + correlation. Pretty neat to check out the heatmaps for random tasks, there is a lot of information inherent in the heatmap about the structure of the task: https://synapsomorphy.com/arc/&lt;/p&gt;
    &lt;p&gt;I'm working on a book about using WebViews for cross-platform music software GUIs. It has a particular focus on performance, which I gave a talk about at the Audio Developer Conference last year:&lt;/p&gt;
    &lt;p&gt;Bread and butter stuff. Pulling together all of the assorted algorithms and data structures I implemented in C over the years out of necessity - lists, trees, stacks, queues, hash tables, memory pools, etc. - aligning the APIs, cleaning up and merging into a library. It's a background project but super fun. This and several parsers - JSON, some config file formats, and parsers for some GPS / GNSS receiver data protocols. FSMs also always feel like nice, clean fun. And prematurely optimising every bit.&lt;/p&gt;
    &lt;p&gt;I've been exploring getting some deeper experience with Claude Code (my org only allows Copilot) and exploring vibe coding by using CC to design a functional programming language that transpiles to JS and build out a full language specification and the tooling to go along with it. I haven't pushed anything to Github yet but it's been very educational, and also a little terrifying to see how easy it is now to produce tens of thousands of lines of code that you totally don't understand.&lt;/p&gt;
    &lt;p&gt;I've been writing https://urbanismnow.com weekly for a year. The idea is to bring you the best ideas from around the world to inspire action where you (c)are.&lt;/p&gt;
    &lt;p&gt;It's been going well for a side project and now I'm thinking of expanding to have a directory of urbanists on a map so you can easily find people involved in the local discourse and how to get involved.&lt;/p&gt;
    &lt;p&gt;We are building end-to-end accessibility compliance tool[1] that will take care of auditing, remediation, verification and generation of ACR/VPAT.&lt;/p&gt;
    &lt;p&gt;Because of the well bound nature of the problem space, we are able to unlock a lot of power from LLMs and put together a good end-to-end product that delivers the promise.&lt;/p&gt;
    &lt;p&gt;Still early days. I know there are lot of folks who care about a11y. I would love to chat and learn from your experience.&lt;/p&gt;
    &lt;p&gt;I am working on a home-oriented solution (hardware box + software) for backups of the media files from phones. The solution facilitates having a separate backup drive (stored in a closet) in addition to the primary data drive in the box.&lt;/p&gt;
    &lt;p&gt;I’m building Sink It for Reddit (https://gosinkit.com), a browser extension to make Reddit usable on the web. It’s similar to RES with broader support for all the different Reddit UIs (there are 4).&lt;/p&gt;
    &lt;p&gt;It’s mostly free with only old Reddit features gated behind a one time $5 fee. The app has a few hundred thousand users on the Apple platforms but recently it was invited to join Mozilla’s Recommended Extensions program so I’m hoping to grow the non-Apple user base.&lt;/p&gt;
    &lt;p&gt;I started it a couple of years ago as personal project to help me study for interviews. Back then, it was simple RSS feed aggregator of big tech companies engineering blogs.&lt;/p&gt;
    &lt;p&gt;Recently I expanded content library to technical conferences and indie blogs, and implemented semantic search in all the library (for example, you can semantic search by all Strange Loop videos archive).&lt;/p&gt;
    &lt;p&gt;I’m working on a performance capture library for Python because I often need to know the performance of backend systems I maintain. I frequently build tooling to capture performance and save it for later analysis. I/O operations get costly when writing lots of data to disk and creating good real-time analytics tools takes a lot of my time. I wanted a library that captures real-time performance analytics from Python backends.&lt;/p&gt;
    &lt;p&gt;This is why I wrote kronicler to record performance metrics while being fast and simple to implement. I built my own columnar database in Rust to capture and analyze these logs.&lt;/p&gt;
    &lt;p&gt;To capture logs, `import kronicler` and add `@kronicler.capture` as a decorator to functions in Python. It will then start saving performance metrics to the custom database on disk. You can also use the middleware for FastAPI.&lt;/p&gt;
    &lt;p&gt;You can then view these performance metrics by adding a route to your server called `/logs` where you return `DB.logs()`. You can paste your hosted URL into the settings of usekronicler.com (the online dashboard) and view your data with a couple charts. View the readme or the website for more details for how to do this.&lt;/p&gt;
    &lt;p&gt;I'm still working on features like concurrency and other overall improvements. I've added a lot since the last time I shared on HN. I would love some feedback to help shape this product into something useful for you all.&lt;/p&gt;
    &lt;p&gt;We've been tinkering with building realtime talking head models (avatar models, etc.) for a while now, and finally have something that works (well enough)! Operates at ~2x realtime on a 4090, significantly faster than that on enterprise grade GPUs.&lt;/p&gt;
    &lt;p&gt;The main use case we designed for was language learning, particularly having a conversational partner -- generally we've found that adding a face to the voice really helps trigger the fight or flight response, which we've found to be the hardest part of speaking a new language with confidence.&lt;/p&gt;
    &lt;p&gt;But in building out the system around the model to enable that use case (tool use on a canvas for speaking prompts and images, memory to make conversations less stale, etc.), we think there's potential for other use cases too.&lt;/p&gt;
    &lt;p&gt;I created a small / 20 line Jupyter notebook that uses the Nthesis api which shapes, tags, and makes the data searchable, chattable and allows you to visualize relationships / data clusters (yep lots of games this month!). https://nthesis.ai/public/hn-working-on&lt;/p&gt;
    &lt;p&gt;I've always loved the "What are you working on" post. So many niche and interesting projects!&lt;/p&gt;
    &lt;p&gt;I am working on a time tracking app. I use it to keep track of time spent vs my estimates, and also just to check my actual working hours. It's fully local—everything is stored in localStorage — but I do have plans for some optional syncing so it can be used on multiple devices.&lt;/p&gt;
    &lt;p&gt;It has helped me a lot to keep focus while working and track distractions. It might be too tailored for my needs, but have a look: https://zookeeper.fyi&lt;/p&gt;
    &lt;p&gt;I'm atm working on a couple of things, first the biz, a self-hosted home server OS that simplifies Docker management and provides a unified dashboard for running services at home. The goal is making self-hosting more accessible without sacrificing flexibility.&lt;/p&gt;
    &lt;p&gt;And also building as a hobbie a procedural universe generation engine that simulates galaxies, solar systems and planets in real-time. Everything is generated from a seed with actual orbital physics, seasonal changes and so... Built with Python/Flask backend too but Three.js for 3D visualization and React instead of Vue3 as in the prior one. Think No Man's Sky vibes but as an explorable simulation engine really D:&lt;/p&gt;
    &lt;p&gt;I'm trying to learn 3D scanning and printing: I have a few small projects that I want to do to develop the skill:&lt;/p&gt;
    &lt;p&gt;I want to 3D print a shell that goes over my car fob: I keep leaning on it and setting off the alarm. The shell would make sure the buttons never get pushed.&lt;/p&gt;
    &lt;p&gt;I want to 3D print a sleeve that keeps the NCAS dongle in my car charger. I really wish there was a dongle that stayed attached with screws or similar.&lt;/p&gt;
    &lt;p&gt;My website is in my profile. I'll try to remember to write a blog entry in a few months. (Fair warning, I redo my website every 5-10 years to keep up to date with web technologies.)&lt;/p&gt;
    &lt;p&gt;FWIW: I was playing with an inexpensive (for me) Revo Inspire over the weekend. It feels somewhere between learning an instrument and taking a daguerreotype. There's a lot of room for improvement in the equipment for someone like me who just wants to casually scan something so I can make an attachment part. (I kind of wish there was a box that I could clamp something in, and then have it be about as easy as a flatbed scanner.)&lt;/p&gt;
    &lt;p&gt;I ended up covering my key fob with blue painter's tape, which kinda-sorta got it to scan. (I tried dry shampoo and drawing on it with marker, but I could never get a big enough area to scan.) When I imported the scanned fob into Tinkercad, it really distorted.&lt;/p&gt;
    &lt;p&gt;I ended up ordering a set of digital calipers and I'm going to try skipping the 3D scan part and go directly to CAD.&lt;/p&gt;
    &lt;p&gt;Music player that can organize album collections from different services like Spotify, Apple Music and Bandcamp, Discogs, and show detailed and high quality information that can be searched and filtered.&lt;/p&gt;
    &lt;p&gt;A place to find great blog articles by regular folks related to dev/tech world.&lt;/p&gt;
    &lt;p&gt;Wondering about the best way I can add a weekly newsletter built on top of the content currently being ingested and still looking for more sources to add to the database (let me know if you have any good recommendations).&lt;/p&gt;
    &lt;p&gt;I am working on something similar but with a different view. I like to get random essay to read whenever I am bored or in-between tasks. So I developed this: https://read2reflect.com/&lt;/p&gt;
    &lt;p&gt;I have added only about 35 essays for now. Might pick up some from your list too.&lt;/p&gt;
    &lt;p&gt;That's pretty cool. I also have a "random article" button at the top right, which is very fun to use. I've discovered a lot of great content by clicking on that button.&lt;/p&gt;
    &lt;p&gt;I have been working on Buckaroo - my table display library for dataframes in notebook environments. Buckaroo adds table and analytics features like histograms, summary stats, sorting, and search to every dataframe. Recently I have been working to make it work better with large datasets.&lt;/p&gt;
    &lt;p&gt;This involves making it lazy for polars, allowing it to read arbitrarily large files no longer requiring loading the entire dataframe into memory. When a large dataframe initially displays, no summary stats will be available. Summary stats are computed in the background in groups of columns. Then results are cached per column. To accomplish this I wrote a polars plugin in rust that computes hashes of columns. Dealing with large data like this is tricky, operations sometimes crash, sometimes take all available memory, and sometimes they just run for a very long time. I have also been building an execution framework for Buckaroo. It uses multiprocessing based timeouts, and the caching to execute summary stats in the background.&lt;/p&gt;
    &lt;p&gt;Being able to control the execution, recover from timeouts, crashes and memory exhaustion opens up some interesting debugging tools. I have written methods that take arbitrary groups of polars expressions and produce a minimal reproduction test case through a git-bisect like process.&lt;/p&gt;
    &lt;p&gt;All of this assures that if individual columns of a dataframe fits into memory, summary stats will be computed for the entire dataframe in the background. And because it is cached, the next time you open the same dataframe, the stats will be display instantly. When exploring data I do this in an adhoc way manually (splitting up a dataframe by columns and rows), but it is error prone. This should all be automatic.&lt;/p&gt;
    &lt;p&gt;I will be presenting this at PyData Boston in December.&lt;/p&gt;
    &lt;p&gt;The Column's the limit: interactive exploration of larger than memory data sets in a notebook with Polars and Buckaroo&lt;/p&gt;
    &lt;p&gt;Loads of similar products out there, but non that did all of: open source code with attested releases, recorded mic and system audio to work with any meeting app and used Apple Intelligence for private summarisation. In beta, and also just released a experimental version with self hosted Ollama support.&lt;/p&gt;
    &lt;p&gt;I wanted a simple retrieval index to use splade sparse vectors. This just encodes and serializes documents into flatbuffers and appends them into shards. Retrieval is just parallel flat scan, optionally with reranking.&lt;/p&gt;
    &lt;p&gt;The idea is just a simple, portable index for smaller data sizes. I’m targeting high quality hybrid retrieval, for local search, RAG or deep research scenarios.&lt;/p&gt;
    &lt;p&gt;SPLADE is a really nice “in-between” for semantic and lexical search. There’s bigger and better indexes out there like Faiss or Anserini, but I just kinda wanted something basic.&lt;/p&gt;
    &lt;p&gt;I was testing it on 120k docs in a simple cli the other day and it’s still as good as any web search experience (in terms of latency) — so I think it’ll be useful.&lt;/p&gt;
    &lt;p&gt;We’re still trying to clean up the API and do a thorough once over, so I’m not sure I’d recommend trying it yet. Hopefully soon.&lt;/p&gt;
    &lt;p&gt;I am building Mizu, a lightweight web framework for Go that aims to keep things simple and Go-first. Everything is written in plain Go with no hidden abstractions, and you can start with a single file then grow into a full project without changing your coding style. The name means "water" in Japanese; the framework tries to flow with your code rather than force its own patterns.&lt;/p&gt;
    &lt;p&gt;Currently working on training language models steered towards certain "states of consciousness".&lt;/p&gt;
    &lt;p&gt;I have a model trained on publics datasets tied to brainwaves and/eye tracking and text comprehension (have this working well enough to experiment). Now I am training an adapter for various llm architectures to generate text steered to certain neural oscillation patterns (let's call them "states of consciousness" for brevity). I also have a 'rephraser' that rephrases text to elicit these certain states of consciousness. Overall experimenting with creating an suite of tools off my findings with how text relates to the eigenmodes of consciousness. My theory is once I do this I'll be able to do some...interesting things with "AI" agents. lmk if you want to talk about it if you're someone with knowledge in neuroscience/ML. My background is as a Software/ML Engineer so I could use additional thoughts. I do wish I could send a Github/docs which I will soon but this is currently a private project seeking investment for various research/public/private sector applications.&lt;/p&gt;
    &lt;p&gt;I continue to work on My Financé, my personal finance tool.&lt;/p&gt;
    &lt;p&gt;I’ve been struggling to find substantive traction, so I’m trying to niche down to make the tool really helpful for people who want to quit their jobs.&lt;/p&gt;
    &lt;p&gt;I built a rudimentary planning and forecasting engine, and am trying to run paid ads to see if the signals resonate with people. I don’t love ads, but maybe trying to understand them will further inform my opinion on them.&lt;/p&gt;
    &lt;p&gt;One thing I would love to come up with is a way to make the app fully local first, while continuing the ability to sync accounts via plaid. It would be great to not be able to see people’s data at all. Im trying to figure out if there is a good user experience I could provide while minimizing the amount of data I actually have access too. Maybe this feature won’t matter to my primary customers though, I’m not really sure.&lt;/p&gt;
    &lt;p&gt;I still have a ton of fun working on it, and if it never really makes any money I consider it a great success for my personal learning.&lt;/p&gt;
    &lt;p&gt;I've been trying to build a golf side hobby business making putters on antique machinery in my garage. Have grown to get some pretty steady traction on instagram, have realized I am not a businessman in all of this, so a lot of learning.&lt;/p&gt;
    &lt;p&gt;I built a wireless highlights &amp;amp; annotations export service for Kobo e-readers earlier this year [1]. Had a free tier limited to 20 exports but wasn't sure how to price it beyond that, so I just left it. Recently a user reached out asking if I'd settled on pricing and how they could pay for unlimited exports! That jolted me into coming up with a price, and now I'm finally getting Stripe integrated :)&lt;/p&gt;
    &lt;p&gt;Made a website to host a blog! Right now it's empty except for one post describing the process of setting up the blog. I plan to add more stuff once I finish this semester in college.&lt;/p&gt;
    &lt;p&gt;Finished: the 100%-vibe-coded "GPT-5 reviews all my PRs on max reasoning" GitHub app (which is shockingly effective, https://github.com/Smaug123/robocop - probably nothing new for people who already use some product like this, but I like owning my own infrastructure as far as possible, and GPT-5 and perhaps Gemini are the only models smart enough to do this so I can't take this any further).&lt;/p&gt;
    &lt;p&gt;Currently: back on "write an immediate-mode TUI framework that uses a vdom as its fundamental abstraction" (https://github.com/Smaug123/WoofWare.Zoomies), in the hope that this is the first UI framework that I don't absolutely loathe.&lt;/p&gt;
    &lt;p&gt;Next: using the TUI framework, write a debugger to inspect the internal state of my deterministic .NET runtime (https://github.com/Smaug123/WoofWare.PawPrint) and to step forward and backward in time.&lt;/p&gt;
    &lt;p&gt;Next: get the deterministic .NET runtime to a point where a property-based testing framework can identify the deadlock in some very simple buggy multithreaded code. (The framework is not yet able to run Hello World - did you know that's an incredibly complicated program in .NET? - but it can solve a few Advent of Code problems right now, can perform some limited exception handling, limited virtual method dispatch, limited casting between types. Even getting to Hello World might take a year if I'm unlucky.)&lt;/p&gt;
    &lt;p&gt;I‘m trying to create an app skeleton plus tooling that allows to build serious business applications on top of Symfony, where you don’t run into architectural trouble even with very complex apps:&lt;/p&gt;
    &lt;p&gt;I've been working on a ttrpg site for the last year with my own IP. The intent is to create an experience that makes an intuitive UI that minimizes tedious tasks.&lt;/p&gt;
    &lt;p&gt;You need to know "does this guy look hurt"? The enemy HP bar can be set to either an actual percentage, or set to have cracks in the bar to signify a range of damage. Does only person take notes? Personal notes are shareable and there's a section for community notes. Do you have enough perception to notice a hidden door? The UI can be set to go off passive perception and give you those notifications automatically.&lt;/p&gt;
    &lt;p&gt;It's still in early alpha testing with friends, but it should eliminate general GM pain points to encourage more groups to form.&lt;/p&gt;
    &lt;p&gt;A database populated with audio metadata (including a link back to YouTube or Spotify or whatever) that includes vector embeddings for the audio. That way I can grab clips of music I like from YouTube, generate vectors for them, then find similar things in the database.&lt;/p&gt;
    &lt;p&gt;It's off to a rocky start though, as I've initially populated it with YouTube-8M and AudioSet, neither of which are music-specific. The search results can be... Weird.&lt;/p&gt;
    &lt;p&gt;There’s so much nuance in HN threads that often gets missed elsewhere, so I decided to put start this newsletter.&lt;/p&gt;
    &lt;p&gt;Initially started as an experiment for 10 issues to see ig it gets traction, 6 issues in it’s at 68 subs and probably will continue for unlimited time period.&lt;/p&gt;
    &lt;p&gt;I'm working on https://yap.town - an SRS based language learning app.&lt;/p&gt;
    &lt;p&gt;I would say it combines the best parts of Duolingo and Anki. Anki is great for memorizing words, but you don't see the words in the context of novel sentences. Duolingo is great for exposure to new sentences, but it's oriented around "lessons" and SRS is an afterthought. (Duolingo is also not designed for people serious about learning a language IMO, it's too easy and goes too slowly.)&lt;/p&gt;
    &lt;p&gt;Had to do quite a bit to get it to work well.&lt;/p&gt;
    &lt;p&gt;1. At first you would think that if you know all the words in a sentence, that should be enough to understand the sentence. But it doesn't work like that. For starters, words can have multiple meanings. The french word "bois" can mean "(you) drink" or "wood". You want to learn these separately. I trained an NLP model (a gemma3 finetune) that I use to understand the manner each word is used in each sentence: https://huggingface.co/collections/anchpop/lexide-nlp-models&lt;/p&gt;
    &lt;p&gt;2. Even then, what about a sentence like "you'd better not"? Even if you know the words "you" "had" "better" and "not", you still won't really get this. So I use the wiktionary "multiword terms" category for each language to get a huge list of terms like "'d better" , "you better believe it", etc, and teach these in addition to individual words. And then I only show sentences where you know all the individual words as well as all the terms.&lt;/p&gt;
    &lt;p&gt;And I'm not planning to get rich off of it haha. Right now there's no monetization at all. If lots of people use it to learn a language and avoid wasting their time on duolingo, I'll be happy&lt;/p&gt;
    &lt;p&gt;Tools to help my mental health tracking[0], and sharing with others how I manage my limited amount of energy[1]. They're kind of related, since mental health impacts my energy, so I've needed to prioritize and really make sure I'm spending my time and energy on things that matter. Usually, there's a good mix of things I enjoy doing with things I gain a lot out of. I've spent a lot of time thinking about this!&lt;/p&gt;
    &lt;p&gt;I've used my app in various forms for around 5 years, rewritten multiple times. But now I'm creating surrounding tooling to help others put my mental model for personal life prioritize to use. I'm writing in the "Saving Spoons" Substack as I go, trying to explain why and how I do things, with advice for others trying to do the same thing.&lt;/p&gt;
    &lt;p&gt;I'm working on Sum Buddy an AI spreadsheet. I didn't like the way Microsoft and Google were integrating their AI by essentially tacking on a chatbox and I wanted to explore more native integrations, like its another part of the tool bar.&lt;/p&gt;
    &lt;p&gt;I'm working on _prompt injection_, the problem where LLMs can't reliably distinguish between the user's instructions and untrusted content like web search results.&lt;/p&gt;
    &lt;p&gt;I have been vibe coding it on and off for a few weeks and I'm quite happy with how it turned out as I could never find one that did what I was looking for.&lt;/p&gt;
    &lt;p&gt;I would love feedback and of course any bug reports. :)&lt;/p&gt;
    &lt;p&gt;We are building https://desplega.ai which is a QA agent that help teams ship fast without compromising quality.&lt;/p&gt;
    &lt;p&gt;We focus on making it as fast as possible, integrated into CI, MCP for local dev, and support both an autonomous (we call it discovery) and guided test creation approach.&lt;/p&gt;
    &lt;p&gt;We believe that in the era of vibe-coding, quality is key, as we are lazer focus on building a solution that scales with your product, and removes the burden of QA from your team.&lt;/p&gt;
    &lt;p&gt;Technically, we built an in-house engine that is in charge of generating the tests, that speeds up and gets better the more you use it.&lt;/p&gt;
    &lt;p&gt;Trying to keep it simple but I can already feel some "design pressure" to think about making the DSL more complete (language) by adding features like loops and variables. Still early days!&lt;/p&gt;
    &lt;p&gt;I'm working on https://mimicmarketer.com It allows you to define different personas that you can then test marketing on. This allows you to see how different personas will interact with your marketing. Currently, it has a feature that allows you to define basic personas and test them against two types of copy, as well as a tool that grades your email subject lines and bodies against a generic persona, assessing the likelihood of user interaction with the content.&lt;/p&gt;
    &lt;p&gt;My other project is https://eggexplorer.com This is a site I wish I had when building out my flock of chickens. It allows you to see the different characteristics of chickens and which hatcheries sell each different breed. You can also see which hatcheries sell hatching eggs for each breed as well.&lt;/p&gt;
    &lt;p&gt;After creating the feature request for Claude Code hooks[1] a few months back, Cupcake is nearly ready for release.&lt;/p&gt;
    &lt;p&gt;Cupcake is a governance/policy-enforcement layer for agents. Its innovation is binding OPA/rego to agent runtimes (via hooks).&lt;/p&gt;
    &lt;p&gt;I do not believe we will every strictly rely on "better" models in the wild without deterministic guarantees or ways for enterprises to factor in their own alignment - system prompts dont cut it.&lt;/p&gt;
    &lt;p&gt;A multi-agent TUI that uses opencode and tmux to help me solve the frustrating LLM slot machine problem. I find that running 3 agents in parallel on even tough problems is enough to have one that builds what I want.&lt;/p&gt;
    &lt;p&gt;It’s also been a fun challenge to build a tool that can be used to improve itself&lt;/p&gt;
    &lt;p&gt;Curated LinkedIn topics + AI drafting: validating before building&lt;/p&gt;
    &lt;p&gt;I'm exploring building a weekly curation service for professionals who want to write on LinkedIn but struggle with "what's worth writing about."&lt;/p&gt;
    &lt;p&gt;The thesis: In the AI era, execution (writing) is commoditized. The real bottleneck is editorial judgment... knowing what topics matter before they're obvious.&lt;/p&gt;
    &lt;p&gt;The concept: Weekly email with 5-7 curated topics (tech trends, policy shifts, market movements). Each topic comes with sources, multiple angles, and context Choose your perspective, AI drafts a polished article&lt;/p&gt;
    &lt;p&gt;Why I think this could work: I've been manually doing this for myself for years. Pattern recognition at scale is hard to automate, but pairing human curation with AI execution might work.&lt;/p&gt;
    &lt;p&gt;Target market: ~30M professionals who should be building thought leadership but don't have time to spend on research.&lt;/p&gt;
    &lt;p&gt;Current status: Validating demand before building. The hard part isn't the AI, it's systematizing the trend-spotting and curation process without losing signal quality.&lt;/p&gt;
    &lt;p&gt;I'm wrapping up a v0 of a personal website soon [1]. This has been kinda "coming soon" for almost 7 years now - every single time I attempted it in the past, I would stop it prematurely due to a lot of yak shaving and I could never finish it fully. Or more commonly, I would get bombarded with busy times as well.&lt;/p&gt;
    &lt;p&gt;I'm happy where it's landing so far but also appreciate any actionable feedback to make it better (!). Under the hood, it packs a Rust Axum API, plenty of ffmpeg, and some hobo infrastructure [2] here and there.&lt;/p&gt;
    &lt;p&gt;An open-source, local database which collects all your personal data, hooks it to an LLM (BYO), and gives you an assistant that can answer any question about your life.&lt;/p&gt;
    &lt;p&gt;It also allows you to vibe-code (or just code) small apps on top of your data (e.g., your custom dashboard for your expenses).&lt;/p&gt;
    &lt;p&gt;I'm working on SuperCurate (https://getsupercurate.com), which is geared towards note retrieval and curation rather than note creation. Think filing cabinet for your notes, web clippings, images and PDFs.&lt;/p&gt;
    &lt;p&gt;I wanted fast search and filters for my Evernote archive so I could drill down and surface exactly what I was looking for.&lt;/p&gt;
    &lt;p&gt;I’m working on Reflect [0], it’s a privacy-focused app for self-tracking and self-discovery. You can track metrics, run self-experiments, set goals, view correlations, visualize your data, etc.&lt;/p&gt;
    &lt;p&gt;Imo, you really should use a pure white background for the App Store screenshots instead of the current greyish background which looks kind of depressing.&lt;/p&gt;
    &lt;p&gt;I've been working on a little game for my daughter to help her learn the movement of chess pieces. https://www.minichessgames.com&lt;/p&gt;
    &lt;p&gt;It's currently just a "maze" type game where you have to get to a goal square in the minimum number of moves (there are rocks placed on the board to act as obstacles)&lt;/p&gt;
    &lt;p&gt;I'm in the process of making some very simple games like battling knights where they leave poo and you try to trap your opponent.&lt;/p&gt;
    &lt;p&gt;Fun making it even if it's just the two of us who'll enjoy it :). Partly I wanted her to learn that you can create for the internet not just consume...&lt;/p&gt;
    &lt;p&gt;Frontend framework in JavaScript that requires no build step, relies on DOM and SSR and can be used to build both SPA and hybrid apps without VDOM, js templates, hydration or putting HTML (or worse, css) inside JS code. It'll also have a very sophisticated declarative state manager which makes managing state and ui transitions a breeze. It's basically anti-React.&lt;/p&gt;
    &lt;p&gt;Sure: https://code.qount25.dev/qite/qite-js No docs yet, but I suggest you go to test/demo for examples. You can actually see them work if you run it with `node test/server.js`.&lt;/p&gt;
    &lt;p&gt;https://fooqux.com/ - an experimental tech article aggregator. For several years now, I've had a routine of collecting articles on topics that interest me throughout the week and then reading them over the weekend. To help organize and streamline this process, I created this website.&lt;/p&gt;
    &lt;p&gt;The main idea is to gather tech articles in one place and process them with a LLM — categorize them, generate summaries, and try experimental features like annotations, questions, etc.&lt;/p&gt;
    &lt;p&gt;I hope this service might be useful to others as well. You can sign up with github account to submit your articles as well. I would appreciate any feedback.&lt;/p&gt;
    &lt;p&gt;I've created an AI-assisted writing platform, that doesn't generate text, but instead lends focus to human creativity, and have AI assist you instead of trying to replace you.&lt;/p&gt;
    &lt;p&gt;You create a writing style via existing text examples, blog posts or URLs, and Arcitext extracts a "writing fingerprint" which it benchmarks new text against.&lt;/p&gt;
    &lt;p&gt;There's a solid Markdown Editor with tools such as Tone Fit, Rewrite suggestions and Fact Check, which helps you when you need it.&lt;/p&gt;
    &lt;p&gt;Kind of like having a writing coach and content strategist on speed dial.&lt;/p&gt;
    &lt;p&gt;I have been tinkering on a little price drop alert scraper written in Python. It's run as a cron job, and every day it checks the prices of a list of urls (my clothing staples from various outdoor retailers, mostly) and sends me an email with any products that have gone on sale.&lt;/p&gt;
    &lt;p&gt;I've been running it for over a year, but now I have fixed it up and made a little landing page to see if there's interest for a stupid-simple price watch service like this (no need to install an extension or create an account):&lt;/p&gt;
    &lt;p&gt;I'm building Your Next Store (YNS); it's a Shopify alternative built with React and Next.js.&lt;/p&gt;
    &lt;p&gt;We provide an opinionated boilerplate tailored for tools like Claude or Codex, so designers and developers can build storefronts faster and more easily. It enforces a clear structure to start from while keeping full control over design, animations, and the overall storefront experience. It’s built on top of Stripe, with our higher-level commerce abstractions, like "add to cart", "checkout", "pay", "browse products" etc; plus a Commerce CMS so merchants can manage everything smoothly once their store is live.&lt;/p&gt;
    &lt;p&gt;If youre planning to sell something online and want a modern solution, hit me up! :)&lt;/p&gt;
    &lt;p&gt;I built a website (https://hpyhn.xyz) for hacker news users for reasons:&lt;/p&gt;
    &lt;p&gt;1. hn comments are valuable, I've spent a lot of time going through hn comments. I think there are valuable comments buried in the threads with fewer points, so it's not enough to just read top3 threads.&lt;/p&gt;
    &lt;p&gt;2. Sometimes a good post is ignored due to a bad title, sometimes I still have no idea what the post's theme even after I read a few paragraphs.&lt;/p&gt;
    &lt;p&gt;3. I want to filter out some posts I'm not interested in, but I realized I need read some other posts it's not a simple yes/no problem, so I gave every post a interesting score based on my own preference&lt;/p&gt;
    &lt;p&gt;so I want a tool to save my time while not missing out too much on hn&lt;/p&gt;
    &lt;p&gt;I've been building a little toy computer and assembly language that's interpreted in python. Pretty close to the first release (and introductory blog post) and a lot of fun to build (and learn a bit more about real assembly as I go).&lt;/p&gt;
    &lt;p&gt;There have been a few astrology apps, but all require you to connect with an astrologer or a pandit. This market has been in past and today, a market of exploitation for the innocent.&lt;/p&gt;
    &lt;p&gt;So, I built this app to let people read their birth chart with detailed analysis, without any such thugs. There are a few very talented experts, but they are either very expensive or difficult to find. So, it came out of necessity.&lt;/p&gt;
    &lt;p&gt;I would love your feedback on trying it out and letting me know your thoughts.&lt;/p&gt;
    &lt;p&gt;Built Tubula because I was tired of forwarding school emails to my spouse. Now families can create shared email addresses like school AT jones.tubula.io that forward to both parents - no DNS configuration needed. Would love feedback: https://tubula.io/&lt;/p&gt;
    &lt;p&gt;building a location-based game that captures Taiwan's absurd convenience stores density[1]. Players stand at any 7-11/FamilyMart/etc, take a photo showing you can see the next store, walk to it, repeat. Chain as many stores together as you can.&lt;/p&gt;
    &lt;p&gt;It sounds silly but Taiwan really is this convenient - you often can see 2-3 stores from one spot. Here[2] one route where you can actually link 7 convenience stores in a row! Now trying to make maps look a bit nicer with mapbox.&lt;/p&gt;
    &lt;p&gt;A website that lets you match watches with different straps to get a feel for how it'll look.&lt;/p&gt;
    &lt;p&gt;Mixing and matching watches with different straps is something that I really enjoy doing. It's not often easy to tell ahead of time whether the combination will work.&lt;/p&gt;
    &lt;p&gt;20 years and counting, working on https://next-episode.net (it's a TV/Movies tracking website and community).&lt;/p&gt;
    &lt;p&gt;I've dedicated this week to some maintenance tasks that are long overdue (mainly modernization of the code and the database), kinda delaying the inevitable (which is to work on harder tasks in my todo - like adding features to the mobile apps).&lt;/p&gt;
    &lt;p&gt;Most (meta)science discussion is either fragmented on Twitter/Bsky, or a bit too formal. I thought a centralised place for deeper, casual discussions might be helpful, so I'm testing that theory.&lt;/p&gt;
    &lt;p&gt;Launched a few days ago, so it might have some rough edges. I'm considering making it user-invite-only soon, but for now it's fully open for signup. I'll also move it to its own domain once I think of a better name.&lt;/p&gt;
    &lt;p&gt;Got tired of every single weather app and website being littered with ads. Half the time my weather apps don't load the weather maps but the ads work fine, c'mon! So decided to start my own; here's what I have so far...once I iron out the site I'll start on the Android app.&lt;/p&gt;
    &lt;p&gt;I have a couple minor suggestions, do with it what you want:&lt;/p&gt;
    &lt;p&gt;- I'd disable the fade between two visualizations on the live weather radar, it's hard to scroll through quickly now.&lt;/p&gt;
    &lt;p&gt;- Personally I'm always looking for the hourly and daily forecasts. Currently they are split by the live radar. I'd either move them all above or all below the radar if you want to keep this format&lt;/p&gt;
    &lt;p&gt;I'm making a game finally! Merge-three + village sim.&lt;/p&gt;
    &lt;p&gt;Hoping to actually take this one to something polished as opposed to the many half-finished prototypes littering my git repo over the years. I've discovered (always knew?) that heavily cutting scope is the best way, and been successful thus far.&lt;/p&gt;
    &lt;p&gt;It gets pretty boring/unbalanced by ~150 turns, but I have some ideas on how to fix. I'm still playing with ways to help de-clutter the board and make use of the economy aspects.&lt;/p&gt;
    &lt;p&gt;After some false starts with ai-gen art, I had fun learning to color the pixels myself. The process wasn't as scary as I'd thought and the results are better than I hoped.&lt;/p&gt;
    &lt;p&gt;It will allow users to fully manage their calendar in a Gantt chart. Complete with customizations like dependencies between events, custom colors for time blocks and custom icons for single-day events (“milestone”-like).&lt;/p&gt;
    &lt;p&gt;Ganttify is a Gantt chart add-on for web applications or services that can benefit from a Gantt view. My goal is to expand the number of integrations for Ganttify and release a new integration every month or so. If any of you have an interesting (niche or non-niche) idea to integrate Ganttify with feel free to contact me.&lt;/p&gt;
    &lt;p&gt;An AI-powered social media management tool that creates, schedules, and publishes content automatically across Twitter/X, LinkedIn, Facebook, Instagram, and Threads.&lt;/p&gt;
    &lt;p&gt;*The problem:* As a solo founder, I was spending hours each week on social media - writing posts, scheduling them, managing multiple accounts. I wanted something that could handle the entire workflow automatically while still letting me stay in control.&lt;/p&gt;
    &lt;p&gt;*What PostSam does:* - AI generates content tailored to your brand voice (you provide initial brand info) - Creates full content campaigns with posting schedules - Calendar interface to review, edit, or reschedule posts before they go live - Auto-publishes to all connected accounts - Learns from your edits to improve future content&lt;/p&gt;
    &lt;p&gt;*Current status:* Live and working. Seeing good engagement rates from users who set it up once and let it run. The AI content quality has been surprisingly good - it adapts well to different brand voices.&lt;/p&gt;
    &lt;p&gt;I'm building one project a week for the next 25 weeks for my newsletter. First, I want interesting content for the newsletter. Second, I want to try to grow the newsletter to put out something fun and joyous. The world needs more good fun.&lt;/p&gt;
    &lt;p&gt;Hi, I like your newsletter concept and I do subscribe to it.&lt;/p&gt;
    &lt;p&gt;One thing I think may be cool, is put a thumbs up/thumbs down link in the email to track sentiment of the links you share. Some links are really cool, others I am not interested in at all, it may be useful to capture that info.&lt;/p&gt;
    &lt;p&gt;I would visit a site daily if you expose some of that info publicly (like 49% positive 51% negative for a link), to see how my sentiment matches your wider audience.&lt;/p&gt;
    &lt;p&gt;I rewrote Playwright to run completely in a Chrome Extension without CDP or chrome.devtools for no practical reason at all. I started to do it like Forest Gump started running. It can't get past bot protection so pretty worthless from a browser automation point of view. [0]&lt;/p&gt;
    &lt;p&gt;What I don't understand is why the need to rewrite Playwright instead of just patching it. Playwright (or Puppeteer) has addressed every edge case that has come -- especially race conditions which are a monster to deal with -- up over the years and by the time you do the same you will have Playwright.&lt;/p&gt;
    &lt;p&gt;Why is rewriting or rebuilding Playwright from the ground up needed?&lt;/p&gt;
    &lt;p&gt;Very cool. I make a consulting business out of packaging selenium scripts into windows apps for small businesses, do you have any desire to turn this into a saleable product?&lt;/p&gt;
    &lt;p&gt;Stagehand is our open source project, but the company behind it is called Browserbase - https://browserbase.com/ where we run headless browser infrastructure as a service. So no interest at this point, Browserbase drives the revenue that funds Stagehand!&lt;/p&gt;
    &lt;p&gt;Helping my recent MBA grad sister make a simple python script to fit here resume to a JD using openAI's api. Shes applting to product and marketing roles in AI and this helps her understand the tech (and its limitations) better as well as apply to more jobs easier&lt;/p&gt;
    &lt;p&gt;Market is brutal though man. She hasnt gotten an offer after so much trying&lt;/p&gt;
    &lt;p&gt;Building https://www.hessra.net/, an authorization system based on the Biscuit token format (decentralized, signed, and attenuable). The goal is to push beyond JWTs and Zanzibar-style policy engines by giving every machine-to-machine request its own embedded, verifiable authorization logic in a small capability token. These tokens can be delegated, restricted, and verified locally with no extra network calls required after getting the token.&lt;/p&gt;
    &lt;p&gt;Early use case is replacing API keys with identity tokens that expire, delegate, and prove possession and then can be used for easy step up to fine-grained authorization. There's some pretty interesting authorization stuff you can do, like having multiple parties sign off before a token is valid or requiring a series of micro-services sign a token for it to be valid.&lt;/p&gt;
    &lt;p&gt;Developing a fingerprinting method for identifying music masterings! Like Shazam but to tell what version of an album you have.&lt;/p&gt;
    &lt;p&gt;The idea being able to compare measurements to see what mastering you're really getting - because they are NOT all equal. With the remasters and stealth replacements on streaming, it seems like every other month I wake up one day and my favorite music sounds worse (or is gone...). Now I can measure it and help find what versions I really want to collect!&lt;/p&gt;
    &lt;p&gt;I may end up trying to make a fingerprint database/tool that sits in between MusicBrainz and Discogs. That way hopefully the community can standardize and quantify some of this info that only lives ad hoc in Steve Hoffman forum threads or partially on sites like https://dr.loudness-war.info&lt;/p&gt;
    &lt;p&gt;Working on new backend for Mercury framework. Mercury makes it easy to serve Python notebooks as web apps. You dont need to know HTML, CSS, JS to build beautiful looking web app from Python notebook. I'm writing new backend to support ipywidgets, anywidgets in Mercury. https://github.com/mljar/mercury&lt;/p&gt;
    &lt;p&gt;I released just yesterday something I've been working on: skrl [1], a language for defining keyboard shortcuts and remaps. Found a few bugs already, but it's still useful at least to me personally.&lt;/p&gt;
    &lt;p&gt;Still working on my digital nomad event and workation aggregator.&lt;/p&gt;
    &lt;p&gt;But now with travel and visa guides to help remote workers become productive in Japan and South Korea ASAP and give them visa guidance if they want to stay a bit longer.&lt;/p&gt;
    &lt;p&gt;I’m building https://unrav.io : A tool to fight information overload.&lt;/p&gt;
    &lt;p&gt;It lets you turn any article, YouTube video, or PDF into summaries, mindmaps, podcasts, chat conversations or infographics that match how you learn with just one click.&lt;/p&gt;
    &lt;p&gt;We just launched this week the Chrome extension so you can do all this in one click on any page, no login needed (with generous freemium usage).&lt;/p&gt;
    &lt;p&gt;system to test and calibrate an analog traction control system. the system uses a frequency to voltage converter and a bunch of opamps to compare wheel speeds then determines wheel slip or slide and either reduces engine power or braking.&lt;/p&gt;
    &lt;p&gt;Test system uses ADCs, DACs and a DDS to produce a sine wave that simulates wheel speed.&lt;/p&gt;
    &lt;p&gt;https://recipin.com Recipe extraction and archiving to avoid link rot and blog spam. No tracking, no JavaScript, no AI[0], and just a dusting of CSS. Source available to run your own server if you’d like (https://github.com/bradly/recipin).&lt;/p&gt;
    &lt;p&gt;I’d like to add importing from a Pinterest account and continue adding support for all the creative implementations of the schema.org recipe format that different sites use.&lt;/p&gt;
    &lt;p&gt;[0] My partner has a bunch of handwritten family recipes, so I’m trying out an optional extract from a photo of a hand written or magazine recipe that uses AI. Not required and I may pull it out into its own service that spits out schema.org recipes. We’ll see.&lt;/p&gt;
    &lt;p&gt;Not good! I personally use it with my wife but getting people to try it online seems to be very tricky to do. Seems like there's a big trust hurdle to overcome.&lt;/p&gt;
    &lt;p&gt;Currently it works as standalone player. Addition of MPD client mode opens possibility to play music on a separate device while keeping the UX of the music player that I like.&lt;/p&gt;
    &lt;p&gt;Working on https://gametje.com (a Jackbox games competitor). Been working on the Android TV app lately. Will probably start creating a new game next week with acronyms similar to the old game Acrophobia from the late 90s/early 2000s.&lt;/p&gt;
    &lt;p&gt;The goal is lightweight, composable tools with clean interfaces that respect user agency and privacy, provide technical clarity, and make you a better photographer by encouraging mastery over your tools and offering new ways to approach picture making. Also broadly honoring the (almost) 2 century old history of the craft and drawing inspiration from pre-digital processes and approaches.&lt;/p&gt;
    &lt;p&gt;Got a number of updates to existing apps and new ones in the works, I’m excited for the full long term vision I have that I plan to sum up in an essay at some point.&lt;/p&gt;
    &lt;p&gt;Currently Apple platforms only but the plan is also to break out of that down the line.&lt;/p&gt;
    &lt;p&gt;Problem: I collect a lot of music I come across in playlists on Youtube/YT music/Bandcamp, but tracks often disappear for various reasons.&lt;/p&gt;
    &lt;p&gt;Working on: Offline Youtube playlist download manager. It uses YT-DLP to get all my music and then enriches artist/track metadata using MusicBrainz, AcoustID, Discogs, LastFM, Spotify. Runs as an offline webapp so I can browse and play music locally. Might play around with recommendations for fun later.&lt;/p&gt;
    &lt;p&gt;Happy to publish the repo if anyone else would find this useful.&lt;/p&gt;
    &lt;p&gt;I suspect AI company want improved efficiencies and developing a framework that can be applied in determining the minimal-energy, maximal-efficiency architecture for ai models. Calculating the precise limits, like a Cognitive Event Horizon, where a model becomes so complicated it literally costs more energy to run than the knowledge it provides, and the Semantic Horizon, where it simply gets too complex to be accurate, etc. Lots of cool implications such as around a fundamental mathematical maximum learning rate which results in trying to get anywhere close to that that by doing stuff like aggressively filtering of the data.&lt;/p&gt;
    &lt;p&gt;Japanese news app with osu-like gamification. You read the news that’s adjusted to your reading level with LLMs, take quizzes, compete on the leaderboard.&lt;/p&gt;
    &lt;p&gt;Hey everyone! I built a site that shows your next age milestones, all on a single page. You can see your next milestone age for each type (like your 10000th day) and save it to Google Calendar.&lt;/p&gt;
    &lt;p&gt;It looks simple, but I learned a lot building this site:&lt;/p&gt;
    &lt;p&gt;* To calculate age in planetary years, I had to look up their orbit and rotation info&lt;/p&gt;
    &lt;p&gt;* The lunisolar calendar took me quite some time to figure out (it is not the same as a lunar calendar and even changes by country)&lt;/p&gt;
    &lt;p&gt;* Adding the dog and cat age equivalents even led me to cubic splines&lt;/p&gt;
    &lt;p&gt;I'm working on a _boring_ business - a CRM for pilates and yoga studios (https://www.usemojo.app/en). Most tools in this space are bloated or built for gyms, not for someone juggling reformer classes, cancellations, and back-to-back privates.&lt;/p&gt;
    &lt;p&gt;It started when a friend who runs a studio showed me her system: printed calendars, WhatsApp messages from clients at midnight, and sticky notes for who paid. I'm trying to make something quieter. It should feel like an assistant, not another tool to manage.&lt;/p&gt;
    &lt;p&gt;Instead of sending the page's HTML to an LLM, Hikugen asks it to generate python code to fetch the data and enforces the generated data conforms to a Pydantic schema defined by the user. I'm using this to power yomu (https://github.com/goncharom/yomu), a personal email newsletter built from arbitrary websites.&lt;/p&gt;
    &lt;p&gt;Wondering what people are using AI for and if there are public/shareable/or leaked chats out there from all platforms either chatgpt, gemini, grok, claude, perplexity etc.&lt;/p&gt;
    &lt;p&gt;So I am building this https://www.leaklake.com , where you can search your name, brand, and basically any keyword.&lt;/p&gt;
    &lt;p&gt;You can also set an Alert because crawling and starping is running 24/7.&lt;/p&gt;
    &lt;p&gt;We are building https://ceogenerator.com/ to help investors, founders and product teams validate product–market fit in minutes, not months. We also offer Generative Engine Optimization + Competition monitoring.&lt;/p&gt;
    &lt;p&gt;We are looking for an angel! Please reach out at hello@ceogenerator.com&lt;/p&gt;
    &lt;p&gt;I am working on https://disco2very.org a NextJS AGPL game to discover the CO2 footprint of... many things. It is using the open data from the French environmental agency ADEME. Tell me what you think!&lt;/p&gt;
    &lt;p&gt;Created a new image generation tool because I believe creativity is a process of trial and error! So multiple models, infinite modality == expansive creativity. :)&lt;/p&gt;
    &lt;p&gt;I’m currently creating a simple community where people can honestly share their emotions and empathize with others’ feelings (without comments). It’s a web community where users can receive a comforting message from AI based on emotion analysis of their text, emojis, and chosen colors.&lt;/p&gt;
    &lt;p&gt;If you have any ideas or comments for improvement, feel free to reply anytime! (For reference, this service is designed for Korean users — I’m Korean myself.)&lt;/p&gt;
    &lt;p&gt;Today, I am implementing tag-triggered webhooks so they can get triggered based on the tags assigned to messages.&lt;/p&gt;
    &lt;p&gt;Use case: for example, I want to auto-tweet all my advice messages and auto-create linear tasks for `company` todos, auto-start a cursor agent when I tag messages with `Cursor task`&lt;/p&gt;
    &lt;p&gt;For some reason, I got 16 users out of nowhere, so I added a landing page last week. The connector marketplace is next, so that I can share these sub-connectors with the other users. Need a couple more weekends.&lt;/p&gt;
    &lt;p&gt;I use codex and claude code daily, also build apps with openai and anthropic api keys, so i always go to openai dashboard and anthropic dashboard to track my usage. Since I spend most of times inside cursor or terminal, I wanted to quickly check my usage without leaving my terminal/ide, so i built this!&lt;/p&gt;
    &lt;p&gt;It's open-source, MIT, and built with ratatui (awesome name).&lt;/p&gt;
    &lt;p&gt;I created a RescueTime alternative for KDE Plasma. It runs in the background as a daemon and records time spent on each window in a SQLite database. Next step here would be to add a Firefox extension, since a lot of my time is spent browsing the web.&lt;/p&gt;
    &lt;p&gt;Tracking windows on Wayland is hard because the protocol doesn't support it. I hacked together a script using Claude Code that somehow works, but I barely understand how.&lt;/p&gt;
    &lt;p&gt;Building a docs website [1] for my speech-to-text CLI tool, hns. I use it 5-10 times daily to transcribe my voice, and a few developer friends I've shared it with have also adopted it for daily use. They like that it runs in the terminal and keeps all data local. So, felt like I should write down guides for new users to get started quickly and to highlight key use cases.&lt;/p&gt;
    &lt;p&gt;Building this documentation website using Docusaurus. This is my first time using Docusaurus, and it feels like a very nice tool for quickly developing a documentation website.&lt;/p&gt;
    &lt;p&gt;Anti-spam email/messaging protocol that is simple, cheap to implement, directly compatible with email/messengers, low false negative rate compared to current spam filtering, free for senders, and does not require the sender to pay to send a message. For people who receive too much marketing spam, survey spam, low-effort cold emails, and want to be able to easily filter spam successfully because you do not want to waste time on them.&lt;/p&gt;
    &lt;p&gt;Future-proofed and will work on AI spam in the future too, unlike current spam filtering methods.&lt;/p&gt;
    &lt;p&gt;https://lunchtrain.se/ A one glance page to find what to eat for lunch in Lindholmen, Gothenburg, Sweden&lt;/p&gt;
    &lt;p&gt;Working on this made it really clear to me how a LLM can bring real value to a backend, it excels on processing very differently structured dynamic data (something if done without an LLM would require quite specific code - which would lead to more development time and increase time to market)&lt;/p&gt;
    &lt;p&gt;I posted in this monthly thread first time in May when I launched a daily logic puzzle, Clues by Sam. Since then it's grown significantly, and I couldn't be happier!&lt;/p&gt;
    &lt;p&gt;The game has a farily simple frontend, but there is a fairly complex constraint solving algorithm as part of the puzzle making process. What makes the puzzle quite unique is that you can't "guess". You can only make guesses that are provable by logic. The algorithm ensuring this has worked flawlessly for months now (though I've manually inserted some silly mistakes once or twice).&lt;/p&gt;
    &lt;p&gt;Today's puzzle is one of the hardest to date. The difficulty resets on Mondays, and then gets harder again towards Sunday.&lt;/p&gt;
    &lt;p&gt;I'm currently working on a directory of apps and tools, created by indie makers and small teams: https://www.discoverindie.tools.&lt;/p&gt;
    &lt;p&gt;Only indie make products, fully bootstrapped.&lt;/p&gt;
    &lt;p&gt;The idea is to both give founders another space to showcase their products and for early adopters and general public to browse through bootstrapped alternatives.&lt;/p&gt;
    &lt;p&gt;I really missed an old mobile game that got de-listed after the devs sold it to a company that subsequently ruined it. I'm a full stack dev, not a game dev, I don't have time to learn the ins and outs of Unity so I tried to see what was feasible in the web world with Babylon.js + React + Capacitor.js and I'm pretty astounded at how well it works out.&lt;/p&gt;
    &lt;p&gt;I'm working on a free replacement to the NY Times daily mini crossword after they started charging for it and I didn't want to pay. https://www.jepeto-mini.com/ (DNS may still be propagating).&lt;/p&gt;
    &lt;p&gt;A fun project with lots of challenges finding word lists, refining them, using AI for clue generation, etc.&lt;/p&gt;
    &lt;p&gt;I played it, and it was fun. Some feedback (I'm on mobile) is that it needs UX improvement.&lt;/p&gt;
    &lt;p&gt;At first I wasn't sure what I had to do, it simply throws you into the game, and it's easy to get confused with the numbers around it, because usually if there are numbers, there is going to be somewhere (usually at the bottom) the numbers and the clue for each of them.&lt;/p&gt;
    &lt;p&gt;It took me a bit to find how to get the clues from the vertical words (double tapping).&lt;/p&gt;
    &lt;p&gt;The onscreen keyboard isn't very responsive in the sense that I had to tap several times the backspace to delete a letter.&lt;/p&gt;
    &lt;p&gt;Fully offline LLM coding agent plug-in for JetBrains IDEs. Use with Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL.gguf on an RTX 3090 or up. The source code is pretty short to make sure it can be audited, if needed.&lt;/p&gt;
    &lt;p&gt;I'm building my take on a low-touch task completion assistant designed to counter distraction and hyper-habituation.&lt;/p&gt;
    &lt;p&gt;It's starting off as a MacOS app because that's the machine I have. I didn't know Swift or SwiftUI when I started. I now know them somewhat, but the entire app has been vibe-coded. This has made it slow going. Very "1 step forward 2 steps back" until I switched from Claude Code to Codex and GPT-5.&lt;/p&gt;
    &lt;p&gt;I'm hoping to start an initial beta within the family in the next week or two, and then a wider round in January.&lt;/p&gt;
    &lt;p&gt;We wanted to make concept for an app using all local models for chat (llama 3.1 8B) and voice (whisper). Deployed using kubernetes and easily scalable not to mention fully open source!&lt;/p&gt;
    &lt;p&gt;For the past few months, I've been building a health tracking app called LogBuddy. I got tired of using separate apps for nutrition, workouts, weight, and period tracking. So I built LogBuddy to handle all of it with a dead simple interface. That way, all the heath data I'm tracking would be in one place. Right now there's an Android APK available. If there's interest, I'll publish to the Play Store and build an iOS version too.&lt;/p&gt;
    &lt;p&gt;Would love to hear your feedback if you try it out!&lt;/p&gt;
    &lt;p&gt;Porting LevelDB[1] to Seastar[2], for internal metadata storage in Redpanda[3]. Before you ask why can’t something off the shelf be used, seastar has unique constraints around its runtime and its memory allocator that means we can’t reuse an existing library.&lt;/p&gt;
    &lt;p&gt;Originally started in 2012, I’m (still) building log.soccer - a stat-tracking tool for amateur soccer players. This is the third or fourth iteration of the site, which until this year mostly served as a glorified résumé project to showcase the latest framework or tool I had just learnt.&lt;/p&gt;
    &lt;p&gt;Thanks to ChatGPT, my productivity went through the roof this year, and I finally shipped an MVP that might actually be useful.&lt;/p&gt;
    &lt;p&gt;It’s a standard Django + React + AWS stack. My raison d’être is to build an Apple Watch app that tracks match scores in real time. 2026 hopefully.&lt;/p&gt;
    &lt;p&gt;OAuth is here to stay for major email providers (Outlook, Gmail, etc). Microsoft is dropping support for standard/basic authorization in April 2026, and Google has already done this. But plenty of devices and systems don't (and may never) support OAuth.&lt;/p&gt;
    &lt;p&gt;Auth-Email is a relay that lets you continue using traditional email auth methods even when your provider requires OAuth. Lots of other more advanced features too: all OAuth grant types, add-ins to modify behavior and lots more.&lt;/p&gt;
    &lt;p&gt;I am working on methods to automate my VC firm. We have a small team and many different tasks to do. I’ve had success with using LLMs to help us automate various projects. But I appreciate any open source tools, techniques, readings, etc. if anyone knows any!&lt;/p&gt;
    &lt;p&gt;Small webapp that allows musicians to add PDFs locally and offline, arrange them, then download for use on an e-reader during performances. Built for a classical musician friend who uses really old Android devices, also my first almost entirely 'vibe-coded' app.&lt;/p&gt;
    &lt;p&gt;A non-bloated HTML, CSS and pure Vanilla JS framework to create dashboards.&lt;/p&gt;
    &lt;p&gt;A cross-platform JSONL viewer where I am learning ImGUI. Haven’t found any other open source GUI framework that‘s small, provides out of the box components for tables, sorting&lt;/p&gt;
    &lt;p&gt;Working on some tailored to my needs tax reporting software. I submit claims to my workplace in batches under a number of different categories. Using this as an excuse to get better at some bits of SQL, leaning Textual as well, which I'm hoping to use in other things. Other than that I'm cooking a few IRC bots that I swap to when the other code becomes a bit too boring&lt;/p&gt;
    &lt;p&gt;Working on an AI coworker (QA engineer) that can autonomously tests web app like your human QA colleagues. It has its own virtual desktop and runs as background agent.&lt;/p&gt;
    &lt;p&gt;My own blog, which I mainly write for myself. But it is getting steadily more readers. Last week I wrote some scripts to help me with creating OG images quicker.&lt;/p&gt;
    &lt;p&gt;Tech:&lt;/p&gt;
    &lt;p&gt;- Zola, static site generator made in Rust&lt;/p&gt;
    &lt;p&gt;- Swift, writing scripts for custom generating stuff&lt;/p&gt;
    &lt;p&gt;Most obvious features, at first glance, are no commas and no need for escape characters. Other useful features include processing instructions, extensible data-substitution rules, and support for comments. Currently only implemented in .NET; plans are to rewrite the core in Rust and provide language wrappers around that core.&lt;/p&gt;
    &lt;p&gt;Polishing my dashboard for tracking profit on Solana blockchain for set of wallets: https://imgur.com/813aQsO&lt;/p&gt;
    &lt;p&gt;I want to extend it with a simple overview of most recent profitable wallets to look for new "metas" that i could profit on. This project may or may not end as open source eventually, but i currently keep it private.&lt;/p&gt;
    &lt;p&gt;I am trying to build a local setup where I spawn dockers (fetched via skopeo) as systemd-nspawn machines in userland (rootless), with network managed by a service that uses netkit devices to setup network in their empty network namespaces. I am looking at using Sommelier to manage wayland.&lt;/p&gt;
    &lt;p&gt;The end goal is to have a laptop with an easy way to build lab environments which is secure and rootless.&lt;/p&gt;
    &lt;p&gt;But a lot of what I work on is my classes giving me less time to open source nowadays, but I have also worked in implementing and mashing new Papers coming out in Robotics. Anyone who wants to talk more should please connect!&lt;/p&gt;
    &lt;p&gt;I am working on a web app that doctors/NPs/PAs can use to automatically rewrite complicated and verbose medical progress notes. The amount of time medical providers spend on documentation is ballooning, and only a small portion that time is actually spent doing medical decision making. The rest of the time is spent incorporating (ie copy editing) data as it comes in from imaging/bloodwork/consultant advice. The goal is for the app to be:&lt;/p&gt;
    &lt;p&gt;entirely self service, without needing EHR integrations&lt;/p&gt;
    &lt;p&gt;able to persist and reuse the user's writing style, without actually saving any of the notes&lt;/p&gt;
    &lt;p&gt;A Mac-based video manager that automatically transcribes, translates and summarises videos. I process information best through reading, so I built it to manage my growing collection of training course videos, webinars and meeting recordings. Currently working on adding RAG search to make it easier to query content.&lt;/p&gt;
    &lt;p&gt;Also building a CMS and static site generator that runs entirely client side in the browser. Pick themes, model content an publish to clean HTML. It also makes content available beyond just the browser, eg in a command line TUI.&lt;/p&gt;
    &lt;p&gt;A hierarchical text canvas for organizing thoughts and taking notes. I wrote v1 years ago and now spent about year rewriting it in SwiftUI and adding all my dream features like reminders, deep linking, and lots more. Currently in TestFlight beta, nearing release.&lt;/p&gt;
    &lt;p&gt;I finally started modding a total war game (Warhammer 3). I played the series since the very first title, Shogun and I always wanted to improve the control over units and add my custom AI to not micromanage everything, but assumed it would be too time consuming and distracting from my main work. And well, it likely would have been.&lt;/p&gt;
    &lt;p&gt;But thanks to LLMs, I finally decided to give it a go and got something basic working in a short time, hurrey for AI assisted coding!&lt;/p&gt;
    &lt;p&gt;Feels empowering to be honest. No idea if I will really implement the main ideas, that I have since a long time, but I know that I can now if I want to.&lt;/p&gt;
    &lt;p&gt;Untrusted code execution paired with AI to make explorative data analysis more simple [0]. I've spent a lot of time with web development in the past. This is breath of fresh air honestly.&lt;/p&gt;
    &lt;p&gt;Disenhackifying one of the last pieces of my KaithemAutomation server that still feels not best practicesful.&lt;/p&gt;
    &lt;p&gt;Device driver plugins used to have a very simple flat key value, strings only format, with a set_config_properties function to tell the host what kind of UI to show.&lt;/p&gt;
    &lt;p&gt;That's all getting replaced with JSON schemas, with some auto-upgrade shims so old config keeps working.&lt;/p&gt;
    &lt;p&gt;It's one of many things that now seems completely insane, but made sense when I had way less experience a long time ago!&lt;/p&gt;
    &lt;p&gt;Also still on and off working on my BLE/WiFi based Meshtastic-alike.&lt;/p&gt;
    &lt;p&gt;You submit heavy duty jobs without worrying about infra, and we take care of execution. We're starting with PDF extraction. Audio transcoding + STT (speech to text) is next. Video transcoding will follow.&lt;/p&gt;
    &lt;p&gt;This allows you to have $5/mo VPS and get media operations figured out.&lt;/p&gt;
    &lt;p&gt;On and off working on the Navigation API for Node, Bun, Deno, &amp;amp; as a browser polyfill.&lt;/p&gt;
    &lt;p&gt;Has 90% test coverage, makes use of web platform tests to verify compatibility, and is in use by some larger companies already with the Navigation API soon to become a baseline in evergreen browsers.&lt;/p&gt;
    &lt;p&gt;The Navigation API effectively is async state navigations. The likes of React has recently added Navigation API support to make use of the browser reload indicator.&lt;/p&gt;
    &lt;p&gt;Working on a desktop app that lets you ask questions on your data files like csv, json, parquet and excel in plain english without incurring heavy LLM costs.&lt;/p&gt;
    &lt;p&gt;Launched a new plan as well that gives unlimited question-answering for just $20/month. Truly unlimited, no strings attached.&lt;/p&gt;
    &lt;p&gt;Anyone can post an idea for something they wish existed — an app, a game, a tool, or anything else — and share it. When more people back an idea, it gains momentum and starts getting built, either by AI or by community makers. The goal is to turn crowd energy into real progress.&lt;/p&gt;
    &lt;p&gt;Just launched a startup/life style business where I use AI to help people practice for upcoming interviews - https://hiredcoach.ai&lt;/p&gt;
    &lt;p&gt;Already have been told by some users that the interview prep they got from it has correctly predicted several of the actual interview questions they got, crediting its prep for their breezing through the interview rounds.&lt;/p&gt;
    &lt;p&gt;Every hour, new Queens Puzzle (LinkedIn style) is available to play. No leaderboard, no stats, nothing to buy, just pure play. Every user gets the exact same puzzle to solve for that UTC hour.&lt;/p&gt;
    &lt;p&gt;I would love to get some feedback from the community!&lt;/p&gt;
    &lt;p&gt;Building https://ottex.ai - a native MacOS app to solve repetitive micro tasks on a computer.&lt;/p&gt;
    &lt;p&gt;- Transcribe voice to text (especially useful when you need to explain something to Claude code )&lt;/p&gt;
    &lt;p&gt;- (soon) select text to instantly Check grammar / Improve writing / change tone of text&lt;/p&gt;
    &lt;p&gt;- (soon) select text to Translate between languages&lt;/p&gt;
    &lt;p&gt;I discovered that I have a few 10/20$ subscriptions (grammarly, raycast, wisperflow) that do embarrassingly simple stuff I can one shot with cheap SLM. So I decided to build a one app specialized in small repetitive tasks on computer.&lt;/p&gt;
    &lt;p&gt;This helped me bridge the gap between installing packages declaratively via NixOS / home-manager and defining them for each project being worked in via flake.nix / direnv / nix-direnv; which was needed since most projects don't use Nix.&lt;/p&gt;
    &lt;p&gt;An Intent is a self-contained document that describes a user request. It is composed of three main sections: WHY (the motivation), WHAT (the requirements, often in Gherkin language), and HOW (a detailed, step-by-step implementation plan defined with tasks). This approach ensures clarity and alignment before any code is written.&lt;/p&gt;
    &lt;p&gt;I'm building GhanaHousePlanner https://ghanahouseplanner.com/, a web platform to help people in Ghana/diaspora plan, estimate and manage house construction projects. It is free for individuals and only project management and using the floor planner ai agent needs subscription.&lt;/p&gt;
    &lt;p&gt;Current features include:&lt;/p&gt;
    &lt;p&gt;- Live material price list updated monthly (based on prices at local shops)&lt;/p&gt;
    &lt;p&gt;- Conceptual 2D/3D floor plan generation following Ghana Building Standards (development in several phases using procedural floor plan generation)&lt;/p&gt;
    &lt;p&gt;- Construction management dashboard to track project stages and conversations between project manager, mason, carpenter, etc.&lt;/p&gt;
    &lt;p&gt;- Printable material cost breakdown&lt;/p&gt;
    &lt;p&gt;TODO: A contact listing for local construction services&lt;/p&gt;
    &lt;p&gt;I am building a foundational layer for building C++ apps using Bazel.&lt;/p&gt;
    &lt;p&gt;I am working on creating a standardized set of paths and third party libraries that work seamlessly across multiple developer teams. Allowing library upgrades to happen transparently in the background. This will enable developers to focus on business specific logic and not have to worry about the intricacies of the build system and allowing to "magically" work in the background. This is allow foray into Bazel and using it as a learning exercise to master it.&lt;/p&gt;
    &lt;p&gt;Completely bootstrapped online counseling platform focused on affordability ($25/week!), accessibility and doing the right thing by clients and therapists. Currently only available in NY, FL, TX and Singapore with plans to expand as budget allows.&lt;/p&gt;
    &lt;p&gt;I'm working on a video / post on how to solve the 1 billion row challenge (https://github.com/gunnarmorling/1brc) and get a competitively fast result while keeping the code readable and maintainable.&lt;/p&gt;
    &lt;p&gt;So far I'm within spitting distance of the winning entries without using any unsafe code or bit twiddling tricks or custom JVMs or anything like that, and having all the concerns nicely separated and modularized.&lt;/p&gt;
    &lt;p&gt;Exposure to unity has got me thinking hard about its non-gaming applications. The stability of presentation between device targets is incredible. Being able to integrate literally anything you want in native 3d world space feels like a natural next step once you get bored of the DOM.&lt;/p&gt;
    &lt;p&gt;I'm going all in on my side project CodeBrew, a Java IDE for iPad. Currently working on OpenGL support for 3d graphics, as some schools requested the feature. Also I'm finally pitting some work into aquisition, which has turned out to be much more fun than I anticipated.&lt;/p&gt;
    &lt;p&gt;Go check it out, its free to try, with a one-time purchase full version:&lt;/p&gt;
    &lt;p&gt;My 7 year old niece loves jigsaw puzzles, but a lot of the time I see her during family trips where taking puzzles along wouldn't be feasible. We usually have an iPad though. I plan to add more puzzle categories soon.&lt;/p&gt;
    &lt;p&gt;Nonoverse[1], an iOS puzzle game about nonograms (image logic puzzles).&lt;/p&gt;
    &lt;p&gt;So far all levels have been handmade pixel art. I’m now testing machine generated puzzles with random “pixels”. This is an interesting challenge because I still want levels to be solvable and fun. I recently released 15 new puzzles like this and I’m preparing a new update with more.&lt;/p&gt;
    &lt;p&gt;I’ve gone old school. After reviewing a few people’s CV’s the easiest format was for me to record a video with the feedback, so I put a site together for that:&lt;/p&gt;
    &lt;p&gt;Thanks. I’m based in the UK so have a good grasp on that, but I’ve reviewed someone’s resume from the US just as easily. Generally, English speaking and preferably in a digital related field, but a lot of the common pain points seem to be universal. It’s only difficult when it’s a field that’s highly niche as hard to know what’s common knowledge.&lt;/p&gt;
    &lt;p&gt;I like to play the role of the person doing the hiring, hence why the form asks for an example job description.&lt;/p&gt;
    &lt;p&gt;Experimenting with various AI models via GitHub Co-Pilot on an extremely niche project to see how far these models have progressed. Used like ~60% of the premium quota to develop the following projects:&lt;/p&gt;
    &lt;p&gt;Manual audio splitting tool for the above project: audio-splitter-6b3.pages.dev/&lt;/p&gt;
    &lt;p&gt;I've always been skeptical of AI-generated code. This is my first experiment with AI agents, where the full code base, implementation, debugging, and deployment are done using AI Agents MCPs.&lt;/p&gt;
    &lt;p&gt;Used VS Code all the way, i.e., all the source codes, including the code to generate the Google Play Store APK. I only reviewed the source code before committing and helped debug by suggesting ideas/algorithms.&lt;/p&gt;
    &lt;p&gt;Mostly used Claude Haiku 4.5 like 75% of the time, where it failed, switched to the sonnet 4.5 or GPT 5 codex. Interestingly, when debugging, sometimes one model struggled even after numerous iterations/feedback loops, but then the problem was solved instantly as soon as I switched to another model.&lt;/p&gt;
    &lt;p&gt;Initially, I thought the audio splitting could be done automatically using some AI models from Hugging Face or Whisper. But the audio files have some complex repetitions; the output was miserable.&lt;/p&gt;
    &lt;p&gt;So, for now, this splitting is done manually using a Web UI (The audio splitting tool splits the large audio files into multiple small audio files, think of it like a long paragraph is split into multiple sentences.)&lt;/p&gt;
    &lt;p&gt;I will attempt again to automate this splitting task using AI, after drafting a game plan for tackling the challenges. I'm thinking of using energy drops and other similar factors to create segments.&lt;/p&gt;
    &lt;p&gt;Working on adding Apple Intelligence to my macOS app built to analyze iOS app size metrics. I'm hoping to have a locally running assistant that can act like an iOS build engineer to provide optimization opportunities and more: https://apps.apple.com/us/app/dotipa/id6742254881.&lt;/p&gt;
    &lt;p&gt;Right now my app allows users to export build metadata as JSON which can be interpreted by LLMs for analysis, but I'd like to have this work on-device.&lt;/p&gt;
    &lt;p&gt;Create a script for a product demo or tutorial for your app using an extension. The script is used to generate your product content in multiple formats (narrated video, interactive demo, looping animation, and in-app guide). Whenever your product changes, just update the script and regenerate everything. No manual re-recording of video, syncing of audio, or any other post-production steps.&lt;/p&gt;
    &lt;p&gt;I kinda gave up on building apps for Rocknix (since there is no easy way to distribute software) and instead have been looking at my apple watch. I ported over some software for workouts that is streamlined. I'm working on a way with MDNS to sync data to my Linux PC automatically when I'm at home.&lt;/p&gt;
    &lt;p&gt;If it works out, maybe this could be a way for me to replace the compromised Apple Music app with something that actually syncs to my music on my desktop.&lt;/p&gt;
    &lt;p&gt;I really liked the concept of games like cards against humanity, quiplash, whose line is it anyway etc. However, there was no virtual way to play it with a group of friends. Quiplash required steam setup (which was not possible on my corporate mac). So i built this as an alternate to build upon the formula.&lt;/p&gt;
    &lt;p&gt;A new spin on my slow baking location intelligence data union (https://wherelabs.info). This week I’m thinking about whether it makes sense to provide a location history ‘vault’, designed to let users expose their location history to LLM’s as context.&lt;/p&gt;
    &lt;p&gt;I write almost daily article about libGDX - my most favorite code-centric game framework. There are now over 100 articles covering topics from basics to advances. I plan to post more because this is more or less a passionate project.&lt;/p&gt;
    &lt;p&gt;In the future I hope it evolves into a definitive resource for learning game development with Java and libGDX.&lt;/p&gt;
    &lt;p&gt;I have found for myself that there is a lack of vocabulary learning apps that have good search functions. When I make a search function, I want it to be able to find all subsets of words, that I could think of. Instead what many search functions only allow you to do is, to first find one set of words, and then in a new separate search find another set of words. Currently working on that search function.&lt;/p&gt;
    &lt;p&gt;Also what I find annoying in spaced repetition learning apps I have seen so far is, that they will ask you very simple words over and over again, just because you didn't see them in a while. But I really don't need to learn those words over and over again, because I just know them.&lt;/p&gt;
    &lt;p&gt;Another annoying thing is, that in some apps you cannot see your learning progress. How many percent you already learned. Or that you cannot specify how difficult a word is to learn. Or how relevant it is. All this metadata, that could be good for learners to be able to search through, when searching for the subset of words they want to learn next. Oh, and of course tags ... With tags one can add all kinds of attributes to words. Maybe I am only looking for nouns or verbs. Maybe I am only interested in words that have something to do with family.&lt;/p&gt;
    &lt;p&gt;There is still a lot to do, but it is taking shape nicely.&lt;/p&gt;
    &lt;p&gt;The app is written in Python and tkinter. It is very simple to use in most aspects, and I really don't care much about the looks. I actually find them refreshingly simple and functional. Not this "everything flat" kind of epidemic in UI, and widgets still give feedback when using them. Not web based with the typical nodejs or npm overhead and tens or hundreds of dependencies. Nope, keeping it very minimal so far.&lt;/p&gt;
    &lt;p&gt;I also have another idea, that might give it a modern touch, but that might also introduce overhead and probably should be an optional setup or feature: Give users tools to let LLMs generate example usages of words, if they want to do so. Of course that would have to be a local LLM I don't want to get into users having to sign up somewhere and get API keys and all that.&lt;/p&gt;
    &lt;p&gt;I am also not planning to make a mobile app. Maybe later I can create an API, so that one could build a web frontend, if one chooses to do so. But first I want to build this app and the functionality behind it.&lt;/p&gt;
    &lt;p&gt;I’m building a typed, array-oriented dataflow compiler that takes small declarative schemas and emits plain Ruby and JavaScript, with a C path. It has a mid-end with inlining, common subexpression elimination, constant folding, dead code elimination, loop fusion, and LICM.&lt;/p&gt;
    &lt;p&gt;I'm making an app for self-tracking. Combining elements from habit trackers, health logging and journaling. Built for rich customization and local-first. Want to be free of rigid structures of many existing apps while providing a better UX / usability than using a spreadhsheet.&lt;/p&gt;
    &lt;p&gt;Correct and performant way to calculate historical value of a portfolio. I want a pure function, but taking a date as input is insufficient because users can edit holdings, and securities can split.&lt;/p&gt;
    &lt;p&gt;Weighing the tradeoffs of doing this calculation server or client side. That'll be an architecture shift away from my current set of background jobs fetching state and towards something more functional and on-demand.&lt;/p&gt;
    &lt;p&gt;we are working on Aye Chat: an AI development tool for the terminal. It will make changes directly and let you revert changes through our snapshot feature, all while you can stay in the terminal to execute your favorite (terminal) editor and what not.&lt;/p&gt;
    &lt;p&gt;If allows the use of different models, no need to sign-up at the moment and at no cost. We released our beta just last week.&lt;/p&gt;
    &lt;p&gt;We were getting annoyed by all the additional confirmation questions by other AI assistants, and having to switch between consoles to use a editor and/or revert changes.&lt;/p&gt;
    &lt;p&gt;Unlike traditional accounting platforms we expose the ledger model directly which enables our customers to model complex transactions even when we do not have direct support for it.&lt;/p&gt;
    &lt;p&gt;Been working on this for a month, and it uses Elixir, Phoenix and InertiaJS with React.&lt;/p&gt;
    &lt;p&gt;I'm working on a web app that creates easy-to-understand stories and explainers for the sake of language learning. You can listen in your favourite podcast app, or directly on the website with illustrations.&lt;/p&gt;
    &lt;p&gt;Most of the testing so far is English/French/Japanese/Mandarin, but I'm eager to add more languages if anyone is fluent and willing to help me evaluate the text-to-speech.&lt;/p&gt;
    &lt;p&gt;It's really cool, but as far as I know there's no complete C++ implementation for embedded platforms, and I still can't figure out how it actually works.&lt;/p&gt;
    &lt;p&gt;Does the gossip flooding mean every single node needs to know about every other node in the entire mesh?&lt;/p&gt;
    &lt;p&gt;I have a project vaguely inspired by this and Meshtastic that tries to make use of existing internet tech, while falling back to local links, instead of trying to replace the Internet completely.&lt;/p&gt;
    &lt;p&gt;It's very much WIP, I'm planning to get rid of all of the automatic reliable retransmit stuff and replace it with per channel end to end acknowledgment. https://github.com/EternityForest/LazyMesh#&lt;/p&gt;
    &lt;p&gt;Is there any kind of DHT like routing for the addresses? Woudn't the announces make a lot of traffic without that, if you ever got to thousands of nodes?&lt;/p&gt;
    &lt;p&gt;It works great with lora, but each interface is it's own thing. It's not exactly like meshtastic/meshcore/etc (for better or worse) but also fulfills totally different roles. You can connect 1 interface to another, and only forward messages for particular addresses, if you want, or addresses that have announced on a specific interface, and you can control what you want to propagate/route.&lt;/p&gt;
    &lt;p&gt;You can set it up tons of different ways, so just imagine this is what you want:&lt;/p&gt;
    &lt;p&gt;- 20 ESP32 lora devices around my house, that respond with sensor-data or something - a pizero connected to the internet (via a huge TCP testnet) and lora (via a SPI device connected to some GPIO.) - These are not "secret" anyone can ask a sensor for it's data. the messages are encrypted, but they are intentionally public&lt;/p&gt;
    &lt;p&gt;If any of the 20 lora devices want to to be available to talk to someone on the internet, they can, and their announcements are forwarded, so people on the testnet know the address.&lt;/p&gt;
    &lt;p&gt;I can set it up so only messages directly to those 20 devices is forwarded, but otherwise announces are recorded (and replayed) on the pi.&lt;/p&gt;
    &lt;p&gt;Additionally, I can setup propagation for just my 20 devices, so even if they are out of range or turned off, they will get the message (from the pi) when they get back in range or turn on.&lt;/p&gt;
    &lt;p&gt;In this example, the structure of the network forms a kind of tree-like thing. Each tier of the network is scaled to the amount of traffic it can deal with: pi can deal with a ton, and is connected to internet, the ESP32s only need to deal with 1-to-1 traffic (announces don't really matter to them) and only compete with traffic from 20 devices (on the same lora network.)&lt;/p&gt;
    &lt;p&gt;These messages are pretty small (an announce is ~160 bytes, message proof is ~115 bytes.) For larger messages, you string them together over a link (a 1-to-1 encrypted tunnel.) I think a key thing though, is that not every tier of the network needs to send all the same packets. For example, not even 1000th of the "testnet firehose" gets sent over the local lora net of 20 devices, based on how it's setup here.&lt;/p&gt;
    &lt;p&gt;So, the usage-flow of this would like this:&lt;/p&gt;
    &lt;p&gt;- each sensor announces on lora, pi forwards that to internet ("hey my address/pubkey is X, and I have these cool capabilities as a sensor") - a user on internet sends a data-message to the address "hey give me your sensor data" - the pi routes that from internet to lora, and propagates (replays periodically if the lora is not around) - if the esp32 has not seen that peer, it can request an announce (and the pi will forward that both ways) - the esp32 responds "oh hey internet user with X address, my sensor data is X" - the message is sent over lora to the pi, which forwards on to internet&lt;/p&gt;
    &lt;p&gt;for very small data, if you don't care about P2P encryption, you could even put the sensor-data directly in the initial announce. "hey I have this address/pubkey and the current temperature is X" since announce "app data" is great for a very small amount of data.&lt;/p&gt;
    &lt;p&gt;Working on Spine AI, a visual workspace to think across multiple AI models.&lt;/p&gt;
    &lt;p&gt;You can chat, branch, and connect 300+ models on an infinite canvas: useful when you need to explore tradeoffs, check blind spots, or generate assets (research, slides, prompts, images) from the same board.&lt;/p&gt;
    &lt;p&gt;- Realistic exam conversations with natural follow-ups and questions to challenge your viewpoint&lt;/p&gt;
    &lt;p&gt;- Get scored on all 4 criteria (fluency, vocabulary, grammar, pronunciation)&lt;/p&gt;
    &lt;p&gt;- Instant feedback on where to improve&lt;/p&gt;
    &lt;p&gt;- Free credits to start&lt;/p&gt;
    &lt;p&gt;There are many existing resources to help prepare for the IELTS exam, however the options are very limited when it comes to practicing the speaking portion.&lt;/p&gt;
    &lt;p&gt;Im a simple man Made a small web app for my local game store for playing magic the gathering where you can analyze your commander decks: https://brackcheck.com/&lt;/p&gt;
    &lt;p&gt;Very interested in this type of thing. I can't see anywhere where pricing is mentioned, even ranges would be a useful benchmark to know if it's something within budget.&lt;/p&gt;
    &lt;p&gt;I'm working on a survival game in the line of MC, Valheim and Vintage Story. Last months have been focused on developing the survival core mechanics on top of building and fighting. Im now entering in the final phase of wiring all the pieces together. Streaming the process daily on Twitch.&lt;/p&gt;
    &lt;p&gt;I'm working on a command-line tool for advanced full-text search of written documents. It works in a completely different way than grep, so it can do a lot of operations that grep fundamentally cannot like proximity searching.&lt;/p&gt;
    &lt;p&gt;I called it Wosp for word-oriented search and print. I released the first functional version a few days ago: https://github.com/atrettel/wosp&lt;/p&gt;
    &lt;p&gt;Me and my friends are working on a fitness companion app, used for tracking both nutrition intake and workouts. Taking the best from well known nutrition apps and workout apps like Hevy. In the core of it will be an AI Agent which can analyze the overall progress based on food and exercise logs and give personalized suggestions.&lt;/p&gt;
    &lt;p&gt;People use Puter for an incredibly wide range of things, including cloud storage, web hosting, coding, AI, and gaming. Right now, we're mostly focused on improving performance and making sure that it's as fast as a regular desktop environment!&lt;/p&gt;
    &lt;p&gt;This looks fun! But the fact that the self hosted version lacks support for some core apps is sad, I'd love to be able to build puter apps! Any plans for an app store-like ecosystem?&lt;/p&gt;
    &lt;p&gt;I am building a WebAssembly WASI runtime for exaequOS (https://exaequos.com), an OS fully running in the Web browser. It will support WASI 0.1 and 0.2. Basic implementation can be tested by running ‘wex’ in the terminal&lt;/p&gt;
    &lt;p&gt;Knocker, an http knock based access service for your homelab that works at a reverse proxy or firewall level.&lt;/p&gt;
    &lt;p&gt;It's a more convenient albeit less secure alternative to VPNs like tailscale. It's more convenient because it whitelists the enite network, and it's less secure for that reason.&lt;/p&gt;
    &lt;p&gt;I am currently working on a fork of Alt+Tab replacement Switcheroo to show all available windows in a tabular format. Current windows in the center. Apps with many windows on the left sorted by process name (e.g. Excel or PDF windows). Pinned windows such as open emails on the right. https://github.com/coezbek/switcheroo&lt;/p&gt;
    &lt;p&gt;I built https://forvard.org/ with Tauri + Svelte; Forvard is a accomplishment tracker where your data lives locally (think of Obsidian but for career tracking), it has a bit of smartness to summarize your accomplishments (without sending your data over the network). I'm working on fixing bugs and adding couple of features!&lt;/p&gt;
    &lt;p&gt;I'm working on https://teeming.ai, trying to solve the information asymmetry problem in the job market.&lt;/p&gt;
    &lt;p&gt;The project has been a huge learning curve for me - I started out as a skeptic of how generative AI could solve real problems (rather than just create noise) but now think that, like the internet, it can create a new kind of abundance that will be harnessable in all sorts of interesting ways.&lt;/p&gt;
    &lt;p&gt;I have made a co-op roguelite tower defense game inspired by the old Warcraft III maps. A major inspiration was YouTD. You can play it here: https://defense-of-solaris.com/&lt;/p&gt;
    &lt;p&gt;I'm working on a Yelp alternative called Vibehuntr -- just something different to browse venues using Google's API, with a social layer so I can see what my friends like. It's very rough around the edges right now and it might be completely different by next week. It's been a fun experiment in vibe coding on a full stack. https://vibehuntr.io&lt;/p&gt;
    &lt;p&gt;New (open source) PostgreSQL index type for analytics workloads, which is a read-only drop-in replacement for B-trees. Smol is multiplicatively faster than B-Trees and radically smaller.&lt;/p&gt;
    &lt;p&gt;Scratching my own (and my employer's, but they don't know that) itch and building a knowledge management system as a nerdy way of spending evenings. I refused to learn JS for years, but turns out it's not as bad as I thought, and TS makes it really nice, plus I like (to my surprise) SolidJS' JSX interpretation quite a lot. Half vibe-coded, half breaking things and learning a lot.&lt;/p&gt;
    &lt;p&gt;Working on building a chatgpt wrapper with real time stock market data. More than 70% investors are using Chatgpt for their investment analysis these days, but the data is quite dated since it's all based on web search. Trying to fix it.&lt;/p&gt;
    &lt;p&gt;I'm adding an overly elaborate item and levelling up system to the adventure mode of my chess variant AI sandbox: www.chesscraft.ca&lt;/p&gt;
    &lt;p&gt;Items have a prefix and suffix system similar to Diablo 2 so I'm having nostalgic fun building it. None of this gives any advantage to the chess games you play. It's just a pointless cycle of gems, items, and experience to get more gems, items and experience. Seems fun so far.&lt;/p&gt;
    &lt;p&gt;https://github.com/s1liconcow/skyshelve - persistent python dictionary on S3. Used this to create a durable execution layer to do some of the analytics for the above.&lt;/p&gt;
    &lt;p&gt;A Python Framework called Artanis, inspired by ExpressJS, to make it easier for JS devs to work with Python ecosystem: https://nordxai.github.io/Artanis/&lt;/p&gt;
    &lt;p&gt;https://NitroQR.com Building the one stop QR Generator with a crazy amount of aesthetic customizability. Already at a pretty functional level, focusing on marketing now. Got something new cooking for the holiday season. Hopefully launching this weekend.&lt;/p&gt;
    &lt;p&gt;In the philosophy of selling shovels in a gold rush, I have built a Markdown Viewer for Mac which is optimised for AI coding with the likes of Claude.&lt;/p&gt;
    &lt;p&gt;It is simple but powerful supporting all formatting but also diagrams so you can get Claude to generate beautiful ER, or state-transition diagrams for your documentation. It also supports math notation, file links and has a cool table of contents feature&lt;/p&gt;
    &lt;p&gt;I have found that duplicated tabs can be useful e.g. for pages where footnotes are not hyperlinked in the text. When this happens I open a duplicate tab and scroll to the bottom of the page on it.&lt;/p&gt;
    &lt;p&gt;oh, for sure, that's why the extension shows which tabs are duplicated, and I can kill the duplicates individually, but also has a kill-all-duplicates button&lt;/p&gt;
    &lt;p&gt;This is an AST-walking interpreter for my personal LISP dialect written in C. Once it's ready, I would use it to implement a low-level, statically typed language (Schnell) as a Langsam library. The goal is to gain the ability to JIT-compile Schnell code (sexps of a statically typed language) from Langsam. Once this works, I would rewrite Langsam in Schnell so that it becomes a fast bytecode interpreter. With the faster Langsam (and the Schnell built into it) I could build a little OS called "Oben". The OS would first run on top of Linux, then I would attempt to bootstrap the entire stack on bare-metal. I already have a Forth dialect implemented in assembly language (Grund/Boden). The idea is to implement Langsam in Grund and then bootstrap the entire Grund -&amp;gt; Langsam -&amp;gt; Schnell -&amp;gt; Oben chain on something like the qemu q35, later on a Raspberry Pi Zero 2W and maybe even my own hardware (ie. an FPGA board like what Wirth et al. created for Project Oberon).&lt;/p&gt;
    &lt;p&gt;This is a TUI MIDI tracker written in Go. Not too user-friendly: one has to enter raw MIDI messages in hex into the tracks. Can be connected to synths like Fluidsynth or Surge XT via JACK MIDI. Unfortunately it takes a lot of CPU time, probably due to the use of BubbleTea (and no time spent on optimization).&lt;/p&gt;
    &lt;p&gt;Beginnings of a programmable, non-realtime audio sample generator/manipulator written in Go with an OpenGL GUI. I was thinking about how people in the old times cut up the magnetic tape which contained the sound bites and rearranged them to build something new. What if I'd implement a data type called "tape" which is basically a piece of sound and then provide operators in a Forth-like language to create and manipulate such tapes. Each tape could be a sound and then these could be stitched together to form songs. Who knows maybe an entire song could be represented as a hierarchy of these tapes. Each sound or song section could be its own file (*.tape), these could be loaded from each other, maybe even caching the WAV generated from the code of a tape to speed things up when there is a huge hierarchy of tapes in a project. Lots of interesting ideas are brewing in this one.&lt;/p&gt;
    &lt;p&gt;I built a chrome extension (with over 600,000 downloads) that lets you chat with page, draft emails and messages, fix grammar, translate, summarize page, etc.. You can use models from OpenAI, Google, and Anthropic.&lt;/p&gt;
    &lt;p&gt;I created this recently but have let it fallow in the last month. Planning to update it over the next few days / weeks. There are a crazy number of directions I could take it.&lt;/p&gt;
    &lt;p&gt;A FLAC encoder/decoder written in Guile scheme. I struggled to get the decoder working with most test files for a while until recently. It's more or less a fully functional decoder now. It's also 1:1 with the reference meta-flac command currently as well.&lt;/p&gt;
    &lt;p&gt;- Local-first app for comparing hardware builds, down to the individual component feature level: specs, benchmarks, even cpu extension support, lanes, how many speakers in X laptop, dolby atmos? screen panel manufacturer(s), etc. Basically, no-nonsense real product comparison for transparent and fast decisions.&lt;/p&gt;
    &lt;p&gt;We are a service to help brands navigate the new world of AI agents. Currently focused on helping them increase visibility in AI search but we plan to go beyond that.&lt;/p&gt;
    &lt;p&gt;Eyeball is a bookmarks app that turns your own saved links into hyper-personalized playlists. It's like having a personal curator in your pocket that sends you a weekly issue of your own personal "magazine" on Sundays.&lt;/p&gt;
    &lt;p&gt;I'm building a scraper in Golang based on Colly to do two things:&lt;/p&gt;
    &lt;p&gt;* Automatically train the scraper on the structure of the page to acquire the data you want, and&lt;/p&gt;
    &lt;p&gt;* Clean and structure the data into a format suitable to go into a relational database&lt;/p&gt;
    &lt;p&gt;I got sick of doing all that manually for some pricing data I wanted to monitor on some suppliers sites, and I've always wanted to contribute more to open source and give back.&lt;/p&gt;
    &lt;p&gt;I am working on PocketWise (https://pocketwise.app) a lightweight personal finance tracking app. Goal is to make double entry accounting simple and approachable for everyday use. It’s my first project of this kind, so I’d really appreciate any feedback.&lt;/p&gt;
    &lt;p&gt;Building vet. The goal is to automate open source package vetting beyond just CVE but actually identify code capabilities, malicious code and other security sensitive attributes through code analysis.&lt;/p&gt;
    &lt;p&gt;I’m building a stablecoin account for workers in LATAM. It helps them protect their earnings from inflation and makes doing taxes easier. (https://www.useairsend.com)&lt;/p&gt;
    &lt;p&gt;A filmmaker community for those wanting to showcase their work. Right now everyone's got their own squarespace and the problem is that about 0 filmmakers also want to be web masters.&lt;/p&gt;
    &lt;p&gt;Some years ago, I co-founded a startup that would run workflows when email messages arrived, any email from any source was parsed and it would trigger "actions" that could include notifications - this sounds like a good use case for it! You don't need the service to expose an api to listen in, since most services end up sending email as last fallback.&lt;/p&gt;
    &lt;p&gt;Sadly no, the feedback loop with users lacked consistency and we never got around finding use cases. One of the visions for it was to help people clean up inboxes, because as you put it, some sources can get pretty spammy. I'll keep an eye out for Cozy Watch, I hope you are successful!&lt;/p&gt;
    &lt;p&gt;Working on https://outcrop.app, a knowledge base for software teams with instant search, realtime collaboration, and LLM-driven workflows. It's built using Rust and friends. I'm looking for more early testers! :)&lt;/p&gt;
    &lt;p&gt;I'm working on marketing my dedicated game server host https://stratos.host - it's a simplified product compared to traditional companies, using a desktop app to detect games being launched.&lt;/p&gt;
    &lt;p&gt;I'm working on a boardgame with the help of AI. It's way too easy to create placeholder art with an n8n pipeline, but GPT-5 regularly fails at writing and debugging LaTeX which I'm using for all of the card creation.&lt;/p&gt;
    &lt;p&gt;Specifically, TikZ is often outside the ability of GPT5 to successfully write or debug.&lt;/p&gt;
    &lt;p&gt;Currently working on secure file intake for Intercom. Recently spoke to a customer and turns out file intake is just a part of the bigger story, currently thinking about processing files, e-signature, client portals and so much more.&lt;/p&gt;
    &lt;p&gt;Multiplayer QWOP-like where you control one leg of an octopus.&lt;/p&gt;
    &lt;p&gt;I'm further ahead in the development than shown here, hopefully have the finished thing out with support for multiple games within a month or so (would be faster if I didn't have a job lol)&lt;/p&gt;
    &lt;p&gt;Specifically working on our FinOps agent which can identify and remediate cloud infa cost related issues across AWS, Azure, Datadog, etc. The agent lives in Slack and surfaces cost savings initiatives for teams to inspect and approve for the agent to fix.&lt;/p&gt;
    &lt;p&gt;It’s been a fun 3 year project. Just launched on iOS and am in user acquisition phase. Totally new learnings here! Getting users is definitely the hard part... I can build something all day&lt;/p&gt;
    &lt;p&gt;https://SightRead.org - free, ad-free, etc, vanilla js (except for the abcjs notation library) web app to practice sight reading. Currently rhythm-only, but more is planned.&lt;/p&gt;
    &lt;p&gt;GunStopperDrone Game Single player game, race against the clock to defuse a dangerous situation using a drone against an armed attacker. https://game.gunstopperdrone.com/&lt;/p&gt;
    &lt;p&gt;A multiplayer game prototype, written in Rust, using Bevy + egui for graphics. Think of it as a bare bones implementation of a game like Runescape, mostly to test out current LLM capability.&lt;/p&gt;
    &lt;p&gt;I haven't found much value in LLMs for coding beyond very self contained tasks, but some people speak highly of it, and I want to be sure that I'm not missing out. So from time to time I give new tools a try. This time is "Claude Code on the web".&lt;/p&gt;
    &lt;p&gt;I've put in an estimated 50 hours so far. It has a client and an authoritative server. The client displays 3D graphics with some placeholder models. From the client, you can click on tiles and move to them, or click on enemies to pathfind and attack them. You can right-click on tiles or monsters to open a menu with options (attack, trade, move). There are some unit tests and a few integration tests.&lt;/p&gt;
    &lt;p&gt;Right now the issues that Claude has been unable to resolve after a few attempts are: * Attack animations. I'm trying to get it to raise and then lower a rectangular block to simulate a sword attack. It really doesn't get it, and it's harder to write tests for compared to movement and server-client networking. * "Entity interpolation". Rather walking entities instantly moving from tile to tile, movement should flow smoothly.&lt;/p&gt;
    &lt;p&gt;I have Claude Pro ($20/mo) which let me make a few commits per day. After a few days of that, Anthropic offered $250 in credits to promote "Claude Code on the web". The credits expire after two weeks. I'm now five days into that period and have gone through $50 in credits. It is heavily rate limited and frequently locks me out for multiple hours after only a few interactions, but it's free credits so I can't really complain.&lt;/p&gt;
    &lt;p&gt;I'm working on my own code review app powered by local or self hosted LLMs. It started as a way to lint my own code and took off from there. It's basically like greptile or co-pilot, but has some things that they don't:&lt;/p&gt;
    &lt;p&gt;https://web-framework.com, a lightweight PHP framework on Slim and PHP-DI for ORM, caching, auth, etc. (an alternative to Laravel/Symfony for small apps).&lt;/p&gt;
    &lt;p&gt;Working on https://ziva.sh/, an AI agent for game development. It uses MCP to integrate with Godot, a leading open source game engine.&lt;/p&gt;
    &lt;p&gt;It's coming together really nicely, targeting a beta release later this month. If anyone is interested in game development and wants to be a beta tester, lmk :)&lt;/p&gt;
    &lt;p&gt;Predict? Interesting!! How do you plan to do that? We have an API if you need one. We recently launched https://bestkundli.com, which does the prediction thing.&lt;/p&gt;
    &lt;p&gt;I'm working on Travi, an AI-powered travel companion that helps travelers effortlessly discover the best attractions to check out based on their interests, and experience them through rich, immersive audio narratives.&lt;/p&gt;
    &lt;p&gt;I'm building a cursor style ai agent but for planning hikes/trips. It does context management and tool calls into data sources and navigates the world to find interesting places. Should be getting out of private beta this week! https://wanderfugl.com&lt;/p&gt;
    &lt;p&gt;Workflows and Case Management for Lending use cases like Small and Medium Business loans and Merchant Cash Advances. I'm working as the Product Designer on these features for a Document Data Extraction AI company.&lt;/p&gt;
    &lt;p&gt;An LLM-powered 'offline' journaling/mindfulness app that draws on ancient philosophy. Designed it initially to help nudge my own habit along &amp;amp; keep things fresh/interesting every time I sat down for a scribble-sesh.&lt;/p&gt;
    &lt;p&gt;This sounds very interesting. You say “native” but miso generates JavaScript, right? I’m not familiar with mobile development. Can you run JS natively on mobile devices?&lt;/p&gt;
    &lt;p&gt;Yes, miso uses the JS backend in GHC, and mobile phones have embedded JS interpreters (e.g. JavaScript Core). These interpreters can access native libraries to draw native views, or access native device APIs.&lt;/p&gt;
    &lt;p&gt;Projects like lynx and react-native automate this process using something akin to node-gyp, exposing kotlin / swift libraries via C ABI w/ a JS API. Miso accesses the kotlin / swift native modules by FFI'ing into the JS that exposes them.&lt;/p&gt;
    &lt;p&gt;The JS doesn't get compiled, but on Android it does get JIT'd. So it's "native" in the sense that the views drawn are native (not WebViews), and the device APIs are native, but not "native" in the sense that it's compiled.&lt;/p&gt;
    &lt;p&gt;Building a set of experiments that explores LLMs visual understanding of your photos to learn about you, especially given the recent learnings from deepseek-OCR. Part of the experiments delve into storing the memories with GraphRAG so they can be effectively retrieved without losing too information.&lt;/p&gt;
    &lt;p&gt;Working on a small embedded vector database lib (à la SQLite). Just finalized the file format, it works pretty great so far. Besides, it’s an excuse to learn rust and low level programming in general.&lt;/p&gt;
    &lt;p&gt;Hi HN, we’re a Milan-based fintech startup developing FELKO, an AI-powered data platform that helps banks and credit-holders standardize, monitor and act on debt portfolios in partnership with collection agencies!&lt;/p&gt;
    &lt;p&gt;Working on AI business coach that can help you at different stages of your startup or small business journey. Here is where you can access the business coach: https://ceo.getbeyondx.com&lt;/p&gt;
    &lt;p&gt;A cpp code generator like esphome, to generate the firmware for midi devices in a simple yaml file, for raspberry Pico.&lt;/p&gt;
    &lt;p&gt;It would have been so much easy just to program the midi hub I wanted to program but wanted to make it generic.. now I can make the firmware for any configuration in seconds!&lt;/p&gt;
    &lt;p&gt;I want to make it easier to just quickly enable wake lock on your device in a cross platform, no install, offline capable way. It's a silly little project but I'm super proud of it.&lt;/p&gt;
    &lt;p&gt;I'm building a Firefox, Chrome, VSCode and OpenVSX security scanner and profiler, and working on building a private web store for Enterprises to switch to rather than using the default stores given all the ransomware and malware activity in that space. Will show HN very soon!&lt;/p&gt;
    &lt;p&gt;Ups = some local-area doulas have started sharing the baby app in a big WhatsApp group &amp;amp; growth is starting to pick up.&lt;/p&gt;
    &lt;p&gt;Downs = my first vibe-coding horror story. For PracticeCallAI, the subscription flow was failing and somehow outside my test coverage, so I've been missing out on new subscribers for the last two months. In an effort fix it, Replit Agent - which I have been loving otherwise - truncated the table that stores all of the user calls. and their database rollback is throwing errors. So that's been fun.&lt;/p&gt;
    &lt;p&gt;I am working on a browser plugin that lets you edit Supabase database tables just like Excel, until it's ready. Then you switch to the main branch and the tables will be read only&lt;/p&gt;
    &lt;p&gt;World model for AI agents. Doing process mining of missions, operations and logistics to transform them into digital twins. AI agents can then leverage these digital twins as world models for control or prediction.&lt;/p&gt;
    &lt;p&gt;I'm personally tired of getting stuck in config/deployment hell every time I want to deploy a long-lived web service. Sure I eventually learned how to use systemd, but systemd has SO many things baked into that I simply don't need. systemg is a lightweight process supervisor that features everything you'd typically want when running/managing production web services in the wild.&lt;/p&gt;
    &lt;p&gt;True, but I think the point I'm trying to make is that when it comes to deploying (what are more often than not) web services, getting to the point with systemd where it "just works" requires more pain than I'd like - especially with regard to production deployments (reading logs, checking service status, wondering why my env vars aren't being read, etc).&lt;/p&gt;
    &lt;p&gt;If at the time when I was cutting my teeth on systemd, I had access to something more lightweight and "do one thing well", I think I would've gotten a lot more sleep :)&lt;/p&gt;
    &lt;p&gt;https://www.athilio.com/ Currently finishing up garmin integration and a mobile port of the app. The app is aimed at people with goals related to their wellness or sports / training. Somewhat similar to training peaks but more focused on integrating different metrics, like sleep and readiness from oura and training data from garmin. Also user has more control. 0 focus on social features. Pricing aims to be affordable (1/4 - 1/2th of similar services), this is hopefully possible with local first approach for the data(sqlite). Saves tons of money on the backend costs when only the syncing from integrations + oauth is on the backend and no storage. Also I think this is more friendly for the users privacy and I would prefer to not store the users datas on my servers for GDPR reasons. Syncing between user devices can be done similarly as Obsidian with icloud. The user experience is a bit influenced by software observability.&lt;/p&gt;
    &lt;p&gt;https://flopper.io - this has become a big focus. It's essentially a table for flops. Calculator coming soon for flops and power. Imported &amp;gt;600 Datacenters in October.&lt;/p&gt;
    &lt;p&gt;https://llmstxt.studio - models need data and I believe llms.txt as an idea has merit. Likely needs an authority. Will add more audit tools to give people any slight benefit they can have for SEO.&lt;/p&gt;
    &lt;p&gt;I wrote a pretty complicated set of GNU Makefiles for a simulation library at work, but was annoyed I had to work so hard to avoid collisions, so I'm working on a "more sanitary" build-your-own-build-system/build-system-kernel type deal.&lt;/p&gt;
    &lt;p&gt;At the intermediate level lots of learners struggle to find suitable content that matches their level and interests, more than a few learners turn to notebookLM podcasts to provide that, but that's a bit of a hassle to set up. So I built a platform that generates and manages infinite and shareable streams around your interests or specific vocabulary. It also provides live interactive transcripts (karaoke / teleprompter style) if you need it.&lt;/p&gt;
    &lt;p&gt;Core features work but still rough around the edges. Happy to help you out with any issues you encounter, languages to add, feature requests etc...&lt;/p&gt;
    &lt;p&gt;working on AskAI chat widget for tech companies. It's like having chatgpt answering the questions of your users within your product. ( of course trained on company docs &amp;amp; data )&lt;/p&gt;
    &lt;p&gt;My latest is Marvelogs (https://www.marvelogs.com) - always wanted to build a price tracker (or tracking any values on a regular basis) - it's nearly there.&lt;/p&gt;
    &lt;p&gt;No projects at the moment. Just working on myself and improving some things in my life, job, cheaper place to rent, lose weight etc. Dreaming of starting a business, I just want to add a cool service to my local city but the economics is hard&lt;/p&gt;
    &lt;p&gt;Been nerd sniped recently so am working on a Rust version of markdownlint-cli2. I'm tired of having a node dependency in my projects and this seems like a constrained enough problem space that I'll actually get around to doing it.&lt;/p&gt;
    &lt;p&gt;I an working on a Builtwith alternative called Bloomberry that will help sales teams enrich their leads in Clay with real-time technographic sales intelligence&lt;/p&gt;
    &lt;p&gt;A new web server written and server management dashboard in JavaScript that is much faster and less complicated than either Apache or NGINX and serves HTTP and WebSockets from the same port.&lt;/p&gt;
    &lt;p&gt;Evals for programming languages with formal verification. It's not clear how far we are from good coding performance in less popular languages in general, and formal verification has some quirks on top also.&lt;/p&gt;
    &lt;p&gt;Just got a 3d printer (Bambu a1 mini) and my girlfriend brought home a whole bag of plant cuttings. Thought I would give a modular plant pot (i.e with elements that allow for expanding the pot) in fusion 360 a shot.&lt;/p&gt;
    &lt;p&gt;I'm working on MedAngle, the world's first agentic AI Super App for current and future doctors. Invite only, 100k+ users, 150m+ questions solved, tens of billions of seconds spent studying smarter.&lt;/p&gt;
    &lt;p&gt;working on https://careroute.ai - triages people to right site of care, estimates their visit cost with their insurance before they go, and lowers bills after visit by having an AI voice agent negotiate on their behalf. Triage works for all regions, cost estimates and bill negotiation is US-only.&lt;/p&gt;
    &lt;p&gt;Moved from nodered only to a hybrid of nodered and home assistant. Added some new sensors, nfc tags, modes and automations for multiple tenants / cost savings. Its been fun to automate some boring tasks.&lt;/p&gt;
    &lt;p&gt;Is anyone working on or knows a library for evaluating LLMs for application features and/or application features that use LLMs? I am wondering what people use or if anyone has their own solution.&lt;/p&gt;
    &lt;p&gt;Odoo Cloud Hosting platform alternative to odoo.sh with additional functionalities(PGadmin, external s3 backup,...etc) and backoffice portal to create landing pages and pricing plans for your customers&lt;/p&gt;
    &lt;p&gt;I'm working on some writing on my blog [1], trying to improve my writing and explore style.&lt;/p&gt;
    &lt;p&gt;My current series of post follows the surge of interest in UUIDs with the uptake of UUIDv7. I've seen some subtle misunderstandings spreading, so I dive into nuance. This has spun off some mini projects, like an RFC compliant UUIDv8 implementation based on XKCD 221 [2] (humor intended). I think I have two more in the blog series.&lt;/p&gt;
    &lt;p&gt;I've tried making game tiles and sprites with Craiyon, which works surprisingly well now. But I always struggle with consistent style, scale, colors. And if I want a border around buttons, it's better if I make it once and apply it myself in photoshop, because the AI will change it slightly every time I ask for a change to the sprite contents.&lt;/p&gt;
    &lt;p&gt;Ahhh this is exactly what I'm looking for! I don't see any pricing on any pages. Would love to know how much this costs (I don't know what 455 diamonds is worth) as there's a few sprites that I'd love to animate and use in my app.&lt;/p&gt;
    &lt;p&gt;Not a fan of signing up before seeing how much I'd have to pay. The examples look great though.&lt;/p&gt;
    &lt;p&gt;Prices are about to drop dramatically. Many of the models dropped &amp;gt;80% in price since initial launch. Any time I have a reduction in cost, I pass the savings directly on to users.&lt;/p&gt;
    &lt;p&gt;Not sure if you just added this in or I overlooked it, but exactly the kind of transparency I love. Will give this a try.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;EDIT - Did an image generation using the OpenAI 4o model, then ran through the lowest quality animation. This is awesome and first pass is very strong and usable (around 100 diamonds used).&lt;/p&gt;
    &lt;p&gt;I look forward to seeing prices drop more and the asset pack area fill up. Keep going man, really awesome stuff.&lt;/p&gt;
    &lt;p&gt;But of course the programmer in me needs to make my own software to design patterns with code. Enjoying using paper.js to do all the complicated math to calculate lengths and angles.&lt;/p&gt;
    &lt;p&gt;I just finished a little webtoy. It's like a comic strip time machine - you can see a virtual newspaper comics page for any date in the last seventy years.&lt;/p&gt;
    &lt;p&gt;V happy with how the CSS came out, except I spent a lot of time on an "ink bleed" newsprint effect that (oops) only looks good on HiDPI monitors... lessons learned I suppose&lt;/p&gt;
    &lt;p&gt;In network code: most people just let the OS choose a default adapter. It works fine, but it makes it hard to write software that works across machines with either (1) multiple NICs (and/or networks they point to.) or (2) multiple external Internet IPs. Look at STUN, for example.&lt;/p&gt;
    &lt;p&gt;A STUN server that lets people test what type of NAT they have uses two IPs. For such a server you have to manually specify the addresses to bind on to make for sure its setup right. As it goes, writing network software to do simple things like "bind on all local addresses", "bind publicly", "bind on all", is harder than it sounds. There are edge cases on different OSes and address families, so manually managing IPs is hard to do.&lt;/p&gt;
    &lt;p&gt;My network software lets devs easily manage NICs and routes they support without guessing about addressing. Additionally, I've written a bunch of software with the library already to do things like NAT traversal. So its really my own redesign of how to do networking on the Internet. Designed to hide a lot of the messiness. I'm still improving code quality so it's not ready yet. But I've been dog fooding with a lot of software written in it and smashing bugs every day.&lt;/p&gt;
    &lt;p&gt;I’ve recently written ImapGoose, a daemon which keeps a remote IMAP mailbox in sync with a local tree of Maildir: https://whynothugo.nl/tags/imapgoose/&lt;/p&gt;
    &lt;p&gt;It relies on “modern” (2009) extensions to minimise traffic and avoids polling entirely (relying on the server to notify of new messages or changes as they happen).&lt;/p&gt;
    &lt;p&gt;It’s currently quite stable. The only known issue is that it can take a while to detect a timeout when the system is suspended and woken up again (there’s no portable API to detect suspend/resume).&lt;/p&gt;
    &lt;p&gt;Since then, I’ve been working on a simple TUI email client based on notmuch and maildir. So far it works really well for processing email, but lacks any capabilities for handling attachments, composing, sending (these are obviously on the roadmap).&lt;/p&gt;
    &lt;p&gt;Oh I'm super curious about your notmuch project. I've been wanting an email client that's just a tui on top of notmuch. Wonder if we can pair up? Ill ping you over email&lt;/p&gt;
    &lt;p&gt;Specifically, torched pine Shou Sugi Ban boxes to house a garden at a much more convenient height for gardening, and eventually, my wintergarden experiments with high compost mixes to keep the garden from freezing in the winter.&lt;/p&gt;
    &lt;p&gt;I was able to get the original 15khz CRT monitor up and running by recapping the board. I decided that the control panel was unsalvageable, and insufficient for what I wanted to do, which was make this cabinet compatible with most any game that would have run on a cab like this.&lt;/p&gt;
    &lt;p&gt;I decided to use RGB lit buttons, so I could change the color's depended on which game was loaded. I used an ESP-32s2 to emulate a keyboard, and accept serial messages from the host computer that changes the button colors.&lt;/p&gt;
    &lt;p&gt;I also incorporated a Stream Deck in the control panel for auxiliary functions. I was able to write a node application to run the stream deck (with the help of a library) since there is no OEM software for linux.&lt;/p&gt;
    &lt;p&gt;By far the most challenging part was getting a suitable signal to the CRT. The first thing I tried was using the Raspberry Pi's GPIO pins through a VGA666 board, but this limited my colors to 16bit, which makes 3d games look pretty awful.&lt;/p&gt;
    &lt;p&gt;Next I tried using a downscaler. This got me 24 bit color, but resolution switching doesn't work with this method.&lt;/p&gt;
    &lt;p&gt;I'm trying an AMD system now. Apparently the linux driver lets you set custom resolutions, and output 15khz (and 25khz for that matter) right from the VGA port.&lt;/p&gt;
    &lt;p&gt;I plan on doing a writeup after I near completion.&lt;/p&gt;
    &lt;p&gt;I am building a coding agent for small businesses. The agent runs on Linux box on own cloud. Desktop and mobile apps to chat with AI models and generate software as needed.&lt;/p&gt;
    &lt;p&gt;SSH based access with HTTP port forward. Team collaboration, multiple models, git based workflow, test deployment automation, etc.&lt;/p&gt;
    &lt;p&gt;I wrote the book in markdown, stuck it in a SQLite DB and wrote a parser to put all the data in static JSON so it loads very fast.&lt;/p&gt;
    &lt;p&gt;I also created a new personal homepage to update my presence on the web as a published author and experienced leader and technologist: https://davidbyrondrake.com&lt;/p&gt;
    &lt;p&gt;Book was released less than a month ago—growing it organically like a startup has been fascinating in terms of marketing, sharing, building, and measuring success.&lt;/p&gt;
    &lt;p&gt;Have been utilizing my acting skills again with readings from the book on my Instagram and TikTok.&lt;/p&gt;
    &lt;p&gt;All-in-one router/nas/firewall/adblock/app server (each piece optional)&lt;/p&gt;
    &lt;p&gt;Declarative and reproduceable as it is built off of NixOS, but administered through a UI, so the user doesn't have to know this.&lt;/p&gt;
    &lt;p&gt;All state managed in a backup bundle, so it can be hosted at home or in the cloud.&lt;/p&gt;
    &lt;p&gt;Goal is to have a box you plug just like a wifi access point into your modem, follow a simple web-based installation flow, then you are running a personal cloud.&lt;/p&gt;
    &lt;p&gt;Website is self-hosted by HomeFree, but installation instructions are very out of date, which I'm working on right now. There are now installation ISOs that I will soon add a link to.&lt;/p&gt;
    &lt;p&gt;I buy and operate e-commerce brands that sell on Amazon, and I'm working on handing as much of the operation of the business off to AI as possible. Doing this both for actual time savings for myself and also as my big-picture eval of new AI models + products as they come out.&lt;/p&gt;
    &lt;p&gt;I also started a Substack to document it - here's a recent post on using Gemini to screen inbound emails with prospective acquisition targets via a Google Apps Script that evaluates the listings in those emails daily: https://theautomatedoperator.substack.com/p/screening-inboun....&lt;/p&gt;
    &lt;p&gt;ELO translated to the NFL with margin-of-victory adjustments, a modest home-field term, and week-to-week recency weighting.&lt;/p&gt;
    &lt;p&gt;Post-hoc calibration with isotonic regression so 70% predictions land near 0.70 empirically.&lt;/p&gt;
    &lt;p&gt;Monte Carlo to roll games forward for distributions on weekly win odds and season outcomes, plus basic reliability/Brier/log-loss tracking.&lt;/p&gt;
    &lt;p&gt;# Where I’m taking it (ensemble ideas)&lt;/p&gt;
    &lt;p&gt;Blend a few complementary signals: (1) pure ELO strength; (2) schedule-adjusted EPA/Success Rate features; (3) injury/QB continuity and rest/travel effects; (4) a small “market prior” from closing lines; (5) weather/play style pace features.&lt;/p&gt;
    &lt;p&gt;Combine via a simple stacked model (regularized logistic, isotonic on top), or a Bayesian hierarchical model that lets team effects evolve with partial pooling.&lt;/p&gt;
    &lt;p&gt;Separate models for win prob vs. expected margin, then reconcile with a consistent link so the two don’t disagree.&lt;/p&gt;
    &lt;p&gt;Emphasis on calibration over leaderboard-chasing: reliability diagrams, ECE, PIT histograms, and backtests that penalize regime drift.&lt;/p&gt;
    &lt;p&gt;# Why I’m doing it&lt;/p&gt;
    &lt;p&gt;It’s a sandbox to teach myself Monte Carlo and ELO end-to-end—data ingest → feature plumbing → simulation → calibration → eval—on a domain with immediate feedback every week.&lt;/p&gt;
    &lt;p&gt;# How this connects to my day job (healthcare ops)&lt;/p&gt;
    &lt;p&gt;I work at BlueSprig, running ~150 ABA therapy clinics. I’m exploring whether ELO-like ideas can augment ops decisions:&lt;/p&gt;
    &lt;p&gt;“Strength” ratings for clinics, care teams, or scheduling templates based on outcome deltas and throughput (margin-of-victory ≈ effect size/efficiency).&lt;/p&gt;
    &lt;p&gt;Monte Carlo for expansion planning (new-site ramp curves), capacity/OT forecasting, and risk-adjusted outcome monitoring with calibration so probabilities mean something.&lt;/p&gt;
    &lt;p&gt;Guardrails for fairness and interpretability so ratings don’t become blunt scorecards.&lt;/p&gt;
    &lt;p&gt;# Help&lt;/p&gt;
    &lt;p&gt;If you’ve shipped calibrated ensembles in sports or have pointers on applying rating systems to multi-site healthcare operations, I’d love to trade notes or if you need someone to this and other kind of work for their dayjob email me at mgracepellon@gmail.com -- I would love to do this fulltime.&lt;/p&gt;
    &lt;p&gt;I recently added FSRS (besides also having Anki integration). Now I'm working on replacing the need for reviewing flashcards by having reading activity automatically mark flashcards (current and future) as reviewed, so that you can get many of your reviews in just by reading native materials that interest you instead of sacrificing most of your study time to contextless flashcard grind.&lt;/p&gt;
    &lt;p&gt;I'm also working on a manga mode using a new manga OCR tech I have licensed out of academia that is ahead of state of the art alternatives.&lt;/p&gt;
    &lt;p&gt;This looks super cool. I love to see people working on language learning tech. I'm working on a language learning app too but it only really works well for indo-european languages. That said I would still love to collab or talk shop, my contact info is in my bio&lt;/p&gt;
    &lt;p&gt;It's native SwiftUI and Swift so I want to avoid a rewrite. I am experimenting with porting my Swift code to web via WASM, now that SQLite WASM backed by IndexedDB is usable so I can reuse the data layer too. I'm also evaluating https://skip.tools for running my SwiftUI on Android.&lt;/p&gt;
    &lt;p&gt;Trying to relearn Rust by writing a download manager CLI. Managed to get the blocking version working, now I've implemented the async version using tokio. Have to next implement downloading chunks with different workers, and a download queue.&lt;/p&gt;
    &lt;p&gt;If you're into movies or filmmaking, it's a fantastic AI tool for consistent, fully-intentional scenes with deliberate set and actor blocking.&lt;/p&gt;
    &lt;p&gt;It's also the cheapest model aggregator service out there. You can log into every AI image and video provider directly and don't have to pay me anything to use the tool. You can use your Sora account, Midjourney account, Grok account, etc. It'll soon let you log into other aggregators like OpenArt, plug in your FAL API key, etc. so you can use your credits/funds wherever they happen to live.&lt;/p&gt;
    &lt;p&gt;Unlike the other "model aggregator" websites like Higgsfield, this is a desktop app written in Rust that you can keep. It also has highly intentional 2D and 3D design surfaces especially built for design.&lt;/p&gt;
    &lt;p&gt;Text prompting sucks for artists and designers, so I'm trying to put image and video design onto canvases that you can intuitively mold like clay.&lt;/p&gt;
    &lt;p&gt;Added compression to my metal 3D printer slicer exported CAM files, and refactored the code to better support larger volumes.&lt;/p&gt;
    &lt;p&gt;Tweaking the piezoelectric driver PCB design for the micro-positing microscopy stage project. The Nanomotion piezoelectric motors were not meant to be used in the manner I chose, but it is fun to push the limits of technology.&lt;/p&gt;
    &lt;p&gt;Finishing up some custom 1U mounted hardware, and getting a batch of test PCB soon. Bend radius came back 1mm oversize, but this was acceptable for a single run item.&lt;/p&gt;
    &lt;p&gt;Also involved in several other projects maybe 3 people would care about. Doing a custom FPGA PCB is not very fun unless encountering that rare class of problem CPU/MCU simply can't handle cleanly. =3&lt;/p&gt;
    &lt;p&gt;I've been building SageNet, a voice-first AI coach that turns your goals into structured, adaptive learning plans.&lt;/p&gt;
    &lt;p&gt;After a 2-minute voice conversation, Sage generates a personalized 6-module roadmap with build-first projects. It checks in by voice, analyzes your reflections, and regenerates your plan if needed. You can invite friends to your Support Squad for accountability.&lt;/p&gt;
    &lt;p&gt;The biggest insight so far is people don’t want “infinite content.” They want structure and someone who remembers them.&lt;/p&gt;
    &lt;p&gt;For fun have been creating a mashup of old school DnD map generation using Commodore "10 Print Chr$(205.5+Rnd(1)); : Goto 10" style logic (in TS/Svelte/SVG):&lt;/p&gt;
    &lt;p&gt;Have been down a rabbit hole ensuring the stairs are realistic and that grid connects properly. Lots of fun and frustration with AI coding tools trying to solve that (they mostly don't/can't). Some fun detours learning a little Prolog to help out as well.&lt;/p&gt;
    &lt;p&gt;Note that I am trying to narrow down a bug in my backend which sometimes causes it to crash. Since backend is built in Swift using SQLite as database, it's a bit hard to nail down the issue.&lt;/p&gt;
    &lt;p&gt;And an iOS expense tracker focused for frequent travelers, and macOS photos viewer based on the filesystem instead of a monolithic opaque "library", 2 needs that I had since forever but could never get through Apple's atrocious developer documentation far enough to finish making them :')&lt;/p&gt;
    &lt;p&gt;A template-based automation tool for small private equity firms. It has some AI functionality as well to easily parse documents and information from transcripts. Basically I want to free up investment teams from admin tasks so that they can spend more time on evaluating deals and building relationships.&lt;/p&gt;
    &lt;p&gt;A lot of the AI-powered applications for private equity firms are focusing on the multi-billion dollar firms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45869146</guid><pubDate>Sun, 09 Nov 2025 21:02:33 +0000</pubDate></item><item><title>The Linux Kernel Looks to “Bite the Bullet” in Enabling Microsoft C Extensions</title><link>https://www.phoronix.com/news/Linux-6.19-Patch-Would-MS-Ext</link><description>&lt;doc fingerprint="7710191af2d7aca8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Linux Kernel Looks To "Bite The Bullet" In Enabling Microsoft C Extensions&lt;/head&gt;
    &lt;p&gt; Two patches queued into the Linux kernel's build system development tree, kbuild-next, would enable the -fms-extensions compiler argument everywhere for allowing GCC and LLVM/Clang to use the Microsoft C Extensions when compiling the Linux kernel. Being in kbuild-next these patches will likely be submitted for the Linux 6.19 kernel merge window next month but remains to be seen if there will be any last minute objections to this change. &lt;lb/&gt;The -fms-extensions compiler option honored by the GNU Compiler Collection and LLVM/Clang allow enabling some non-standard C/C++ constructs used within Microsoft header files and honored by the the Microsoft Visual C/C++ compiler. For Linux kernel development purposes, enabling the Microsoft C Extensions would allow including a tagged struct or union anonymously in another struct/union.&lt;lb/&gt;Going back many years there have been patches floated to unconditionally enable -fms-extensions for the Linux kernel but they haven't made it past the Linux kernel mailing list. But now with these two patches being in kbuild-next mean that it will likely be submitted for the Linux 6.19 kernel merge window barring any objections from prominent Linux kernel developers or Linus Torvalds himself.&lt;lb/&gt;Rasmus Villemoes argued with Kbuild: enable -fms-extensions that would allow for "prettier code" and others have noted in the past the potential for saving stack space and all around being beneficial in being able to leverage the Microsoft C behavior:&lt;lb/&gt;The second patch is kbuild: Add '-fms-extensions' to areas with dedicated CFLAGS to ensure -fms-extensions is passed for the CPU architectures that rely on their own CFLAGS being set rather than the main KBUILD_CFLAGS.&lt;lb/&gt;Linus Torvalds chimed in on the prior mailing list discussion and doesn't appear to be against enabling -fms-extensions beginning with the Linux 6.19 kernel.&lt;lb/&gt;Enabling -fms-extensions will allow for some better looking C code though some may feel the wrong way around Microsoft C behavior being permitted for the mainline Linux kernel coding.&lt;/p&gt;
    &lt;p&gt;The -fms-extensions compiler option honored by the GNU Compiler Collection and LLVM/Clang allow enabling some non-standard C/C++ constructs used within Microsoft header files and honored by the the Microsoft Visual C/C++ compiler. For Linux kernel development purposes, enabling the Microsoft C Extensions would allow including a tagged struct or union anonymously in another struct/union.&lt;/p&gt;
    &lt;p&gt;Going back many years there have been patches floated to unconditionally enable -fms-extensions for the Linux kernel but they haven't made it past the Linux kernel mailing list. But now with these two patches being in kbuild-next mean that it will likely be submitted for the Linux 6.19 kernel merge window barring any objections from prominent Linux kernel developers or Linus Torvalds himself.&lt;/p&gt;
    &lt;p&gt;Rasmus Villemoes argued with Kbuild: enable -fms-extensions that would allow for "prettier code" and others have noted in the past the potential for saving stack space and all around being beneficial in being able to leverage the Microsoft C behavior:&lt;/p&gt;
    &lt;quote&gt;"Once in a while, it turns out that enabling -fms-extensions could allow some slightly prettier code. But every time it has come up, the code that had to be used instead has been deemed "not too awful" and not worth introducing another compiler flag for.&lt;lb/&gt;That's probably true for each individual case, but then it's somewhat of a chicken/egg situation.&lt;lb/&gt;If we just "bite the bullet" as Linus says and enable it once and for all, it is available whenever a use case turns up, and no individual case has to justify it.&lt;lb/&gt;A lore.kernel.org search provides these examples:&lt;lb/&gt;- https://lore.kernel.org/lkml/[email protected]/&lt;lb/&gt;- https://lore.kernel.org/lkml/[email protected]/&lt;lb/&gt;- https://lore.kernel.org/lkml/[email protected]/&lt;lb/&gt;- https://lore.kernel.org/lkml/[email protected]/&lt;lb/&gt;- https://lore.kernel.org/lkml/CAHk-=wjeZwww6Zswn6F_iZTpUihTSNKYppLqj36iQDDhfntuEw@mail.gmail.com/&lt;lb/&gt;Undoubtedly, there are more places in the code where this could also be used but where -fms-extensions just didn't come up in any discussion."&lt;/quote&gt;
    &lt;p&gt;The second patch is kbuild: Add '-fms-extensions' to areas with dedicated CFLAGS to ensure -fms-extensions is passed for the CPU architectures that rely on their own CFLAGS being set rather than the main KBUILD_CFLAGS.&lt;/p&gt;
    &lt;p&gt;Linus Torvalds chimed in on the prior mailing list discussion and doesn't appear to be against enabling -fms-extensions beginning with the Linux 6.19 kernel.&lt;/p&gt;
    &lt;p&gt;Enabling -fms-extensions will allow for some better looking C code though some may feel the wrong way around Microsoft C behavior being permitted for the mainline Linux kernel coding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45873625</guid><pubDate>Mon, 10 Nov 2025 08:09:31 +0000</pubDate></item><item><title>Vibe Code Warning – A personal casestudy</title><link>https://github.com/jackdoe/pico2-swd-riscv</link><description>&lt;doc fingerprint="e618d5df25439ba8"&gt;
  &lt;main&gt;
    &lt;p&gt;A stateful SWD protocol implementation for debugging RP2350 RISC-V cores (Hazard3) from any Raspberry Pi Pico2 (target) using GPIO's on another Pico (probe).&lt;/p&gt;
    &lt;p&gt;About 80% of the code is vibe coded; The readme is almost completely generated (except the whole vibe-code-warning section). I spent many nights with the oscilloscope and the docs and made a working prototype that was able ti do sba/read/write regs and do abstract commands and progbuf, the rest was done with claude code. The tests are quite comprehensive test suite and I use the core of the library in my own projects, but, as they say, "hic sunt dracones". I also read the readme and the code didn't notice anything wrong (and removed the wrong/unclear parts).&lt;/p&gt;
    &lt;p&gt;This project was my casestudy of vibecoding a more complicated project that I dont understand 100% and there is no obvious existing code that can be "used". It started as ~1000 loc that I have written and knew very well, reading the rp2350, arm swd and riscv debug docs, capturing data with oscilloscope and openocd then decoding it and analyzing the wakeup sequence and then read/write commands. After I got it working I gave it to claude to make it into a library that I can use in other projects, and then I slowly built it up.&lt;/p&gt;
    &lt;p&gt;After about 3-4k lines of code I completely lost track of what is going on, and I woudn't consider this code that I have written, but adding more and more tests felt "nice", or at least reassuring.&lt;/p&gt;
    &lt;p&gt;There was a some gaslighting, particularly when it misunderstood dap_read_mem32 thinking it is reading from ram and not MEM-AP TAR/DRW/RDBUFF protocol, which lead to incredible amount of nonsense.&lt;/p&gt;
    &lt;p&gt;Overall I would say it was a horrible experience, even though it took 10 hours to write close to 10000 lines of code, I don't consider this my project, and I have no sense of acomplishment or growth.&lt;/p&gt;
    &lt;p&gt;In contrast, using AI to read all the docs (which are thousands of pages) and write helpful scripts to decode the oscilloscope data, create packed C structs from docs and etc, was very nice, and I did feel good after. The moment I read the first register and then when I was able to read memory via SBA I felt amazing.&lt;/p&gt;
    &lt;p&gt;The main issue is &lt;code&gt;taste&lt;/code&gt;, when I write code I feel if its good or bad, as I am writing it, I know if its wrong, but using claude code I get desensitized very quickly and I just can't tell, it "reads" OK, but I don't know how it feels. In this case it happened when the code grew about 4x, from 1k to 4k lines. And worse of all, my mental model of the code is completely gone, and with it my ownership.&lt;/p&gt;
    &lt;p&gt;The tokens have no reason or purpose, which makes reading code ridiculously difficult, as and each token can be complete nonsense. When reading human code the symbols have a purpose, someone thought "I will put this in a variable, later I will check its status.", so I pretend I am them, and think &lt;code&gt;why&lt;/code&gt; would they have written this? Shortly after I understand, as they are human and I am human. But the AI symbols have no reason, and worse of all, they all look deceptively correct, so I have to think 10 times harder if it is wrong. With any human code (including your own) it is quite easy to gauge how much you can trust it, and it is quite consistent, with the AI code, one function can be much better than what you woudld've written, and the code 2 lines below can be cargo culted gunk that looks incredibly good, but is structurally wrong.&lt;/p&gt;
    &lt;p&gt;In the end I would say I have gained good understanding of the wires, timings, and the lower level ap/dp mechanics, sba and progbuf, but I regret not writing the whole thing myself, even if it would've taken 10x the time.&lt;/p&gt;
    &lt;p&gt;I fucking hate this.&lt;/p&gt;
    &lt;p&gt;And I can not help, but feel dusgust and shame. Is this what programming is now? I really hope this is some intermediate stage and it changes for the better, the problem is I dont know what "better" is, it seems for some people is not writing the code, for others is not modeling the problem and for third is not having to think. For me, I am not sure, I do want to make things, and many times I dont want to know something, but I want to use it, e.g. the rp2350 usb host controller the way you have to re-arm interrupts and the way the epx register is shared is super annoying, for good reasons probably, but I just want to use it to make my CBI driver.&lt;/p&gt;
    &lt;p&gt;I guess the question is what is the thing I want to make, because you can go way up the stack, from the USB chip registers to CBI to UFI to FAT16 to the OS of the old school computer I am making, but why stop? make the schematics, the pcbs, the cad files, maybe automatically send it to the factory? and then just ship it to me? but why stop? make my webshop, start selling, make a community, ads, marketing, generate some unboxing videos, maybe some viral memes? process the orders directly to the factory, on demand, if there is an issue, it is ready with customer support.&lt;/p&gt;
    &lt;p&gt;What do I do in the meanwhile? Sit on the beach? I hate the beach.&lt;/p&gt;
    &lt;p&gt;Where does it stop?&lt;/p&gt;
    &lt;p&gt;This library implements a complete three-layer abstraction for Serial Wire Debug protocol communication with RP2350's RISC-V Debug Module, modeled after the Debug Access Port specification and informed by ARM Debug Interface Architecture Specification v5.2.&lt;/p&gt;
    &lt;code&gt;┌────────────────────────────────────────┐
│  Application Layer                     │
│  (User Code)                           │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Debug Module Layer (rp2350.c)         │
│  - RISC-V Debug Specification v0.13    │
│  - Hart control via DMCONTROL          │
│  - Abstract commands for GPR access    │
│  - System Bus Access (non-intrusive)   │
│  - PROGBUF execution for CSR access    │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Debug Access Port Layer (dap.c)       │
│  - DP/AP register transactions         │
│  - RP2350-specific DP_SELECT encoding  │
│  - Bank selection caching              │
│  - Memory-mapped debug register access │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Serial Wire Debug Layer (swd*.c)      │
│  - 2-wire bidirectional protocol       │
│  - PIO state machine bit-banging       │
│  - Request/ACK/Data phase handling     │
│  - Parity computation and verification │
│  - Line reset and dormant sequences    │
└────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;The separation of concerns follows classical protocol stack design: each layer exposes a well-defined interface and maintains independent state, with lower layers unaware of higher-layer semantics.&lt;/p&gt;
    &lt;p&gt;Before examining the protocol implementation, we must establish the theoretical foundations of RISC-V external debugging. This section develops the debug architecture from first principles, following the RISC-V External Debug Support Specification v0.13.&lt;/p&gt;
    &lt;p&gt;A RISC-V hart (hardware thread) exists in one of three abstract states:&lt;/p&gt;
    &lt;code&gt;                    ┌─────────────┐
                    │   RUNNING   │
                    │  (Normal)   │
                    └──────┬──────┘
                           │
                  halt_request, ebreak,
                  trigger_fire, step_complete
                           │
                           ▼
                    ┌─────────────┐
                    │   HALTED    │
                    │  (Debug)    │
                    └──────┬──────┘
                           │
                     resume_request
                           │
                           ▼
                    ┌─────────────┐
                    │  RESUMING   │
                    │ (Transient) │
                    └──────┬──────┘
                           │
                           ▼
                    ┌─────────────┐
                    │   RUNNING   │
                    └─────────────┘
&lt;/code&gt;
    &lt;p&gt;State 1: RUNNING - The hart executes instructions from main memory. PC advances according to program flow. All architectural state (GPRs, CSRs, memory) is accessible to the executing program.&lt;/p&gt;
    &lt;p&gt;State 2: HALTED - The hart has entered debug mode. No instructions from main memory execute. The hart is "parked" in a special debug ROM or implicit debug loop within the Debug Module. Debug-specific CSRs (DPC, DCSR, DSCRATCH) become accessible.&lt;/p&gt;
    &lt;p&gt;State 3: RESUMING - A transient state where the hart has received a resume request but has not yet returned to normal execution. This state exists to model the asynchronous nature of resume operations.&lt;/p&gt;
    &lt;p&gt;The Debug Module (DM) is a hardware block separate from the hart itself. It acts as a "shadow controller" that can:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Observe hart state without halting (DMSTATUS register)&lt;/item&gt;
      &lt;item&gt;Command hart transitions (halt, resume, reset via DMCONTROL)&lt;/item&gt;
      &lt;item&gt;Access hart registers when halted (abstract commands)&lt;/item&gt;
      &lt;item&gt;Access system memory independently of hart state (System Bus Access)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The DM is itself controlled by an external debugger via a Debug Transport Module (DTM). In our case, the DTM is the SWD interface.&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────────────┐
│  External Debugger (Host CPU)                    │
└────────────────────┬─────────────────────────────┘
                     │
                     ▼ SWD Protocol
┌──────────────────────────────────────────────────┐
│  Debug Transport Module (DTM)                    │
│  - Exposes DM registers as memory-mapped space   │
└────────────────────┬─────────────────────────────┘
                     │
                     ▼ Internal Bus
┌──────────────────────────────────────────────────┐
│  Debug Module (DM)                               │
│  ┌──────────────┐  ┌──────────────┐              │
│  │  Abstract    │  │  System Bus  │              │
│  │  Command     │  │  Master      │              │
│  │  Engine      │  │              │              │
│  └──────┬───────┘  └──────┬───────┘              │
│         │                 │                      │
└─────────┼─────────────────┼──────────────────────┘
          │                 │
          ▼                 ▼
    ┌─────────────┐   ┌──────────────┐
    │  Hart 0     │   │ System Bus   │
    │  (Hazard3)  │   │              │
    ├─────────────┤   └──────────────┘
    │  Hart 1     │
    │  (Hazard3)  │
    └─────────────┘    
&lt;/code&gt;
    &lt;p&gt;When a hart enters debug mode, it is not simply "stopped." Rather, it enters a special execution context analogous to an exception handler:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;PC is saved to DPC (Debug Program Counter, CSR 0x7b1)&lt;/item&gt;
      &lt;item&gt;Privilege level is elevated to M-mode (Machine mode, highest privilege)&lt;/item&gt;
      &lt;item&gt;DCSR.cause records the entry reason (halt request, ebreak, trigger, etc.)&lt;/item&gt;
      &lt;item&gt;Hart begins executing from the debug exception vector (typically in debug ROM)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The debug exception vector contains a tight polling loop that repeatedly checks for commands from the Debug Module. This loop is architecturally invisible to the debugger—we simply observe the hart as "halted."&lt;/p&gt;
    &lt;p&gt;The Abstract Command mechanism provides a hardware-implemented function call interface. Each abstract command is a 32-bit word written to the COMMAND register that encodes:&lt;/p&gt;
    &lt;code&gt;31                            24 23                            0
┌────────────────────────────────┬────────────────────────────────┐
│         cmdtype                │         command-specific       │
└────────────────────────────────┴────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;cmdtype=0: Access Register&lt;/p&gt;
    &lt;code&gt;31      24 23          20 19 18 17 16 15                          0
┌──────────┬─────────────┬─┬──┬──┬──┬──────────────────────────────┐
│    0     │   aarsize   │0│pc│tr│wr│         regno                │
└──────────┴─────────────┴─┴──┴──┴──┴──────────────────────────────┘

aarsize: Access size (2 = 32-bit)
aarpostincrement: Ignored
postexec: Execute program buffer after transfer
transfer: Perform the transfer (1=yes)
write: Direction (1=write, 0=read)
regno: Register number (0x1000-0x101f for GPRs x0-x31)
&lt;/code&gt;
    &lt;p&gt;The Debug Module hardware interprets this command and performs the register access autonomously. From the debugger's perspective, this is a synchronous operation: write COMMAND, poll ABSTRACTCS.busy until clear, read result from DATA0.&lt;/p&gt;
    &lt;p&gt;The Program Buffer (PROGBUF) is a small instruction memory (2-16 entries) within the Debug Module. When abstract commands cannot accomplish a task (e.g., accessing debug-only CSRs), the debugger can:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Write RISC-V instructions to PROGBUF&lt;/item&gt;
      &lt;item&gt;Issue an abstract command with the &lt;code&gt;postexec&lt;/code&gt;bit set&lt;/item&gt;
      &lt;item&gt;The hart executes PROGBUF instructions while still in debug mode&lt;/item&gt;
      &lt;item&gt;The final &lt;code&gt;ebreak&lt;/code&gt;instruction returns control to the Debug Module&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a "code injection" attack—the hart never leaves debug mode. It's analogous to a debugger writing instructions into a trap handler's stack frame.&lt;/p&gt;
    &lt;p&gt;SBA provides a second path to memory that bypasses the hart entirely:&lt;/p&gt;
    &lt;code&gt;         Debugger Commands
                │
                ▼
         ┌─────────────┐
         │     DM      │
         └──┬───────┬──┘
            │       │
   ┌────────┘       └───────┐
   │                        │
   ▼ Abstract Cmd           ▼ SBA
┌──────┐                ┌─────────┐
│ Hart │───────────────▶│ Memory  │
└──────┘  Hart Accesses └─────────┘
&lt;/code&gt;
    &lt;p&gt;The hart and SBA compete for memory bus bandwidth. The hart's view of memory may differ from SBA's view due to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cache: Hart caches writes; SBA sees stale memory&lt;/item&gt;
      &lt;item&gt;MMU/PMP: Hart accesses are translated/protected; SBA bypasses&lt;/item&gt;
      &lt;item&gt;Atomicity: Hart's atomic operations (LR/SC) are invisible to SBA&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a bug—it's a fundamental architectural trade-off. SBA provides speed and non-intrusiveness at the cost of coherency guarantees.&lt;/p&gt;
    &lt;p&gt;RISC-V debugging rests on several invariants:&lt;/p&gt;
    &lt;p&gt;Invariant 1: Debug Mode is Atomic While in debug mode, the hart executes no instructions from main memory. The debugger has exclusive control.&lt;/p&gt;
    &lt;p&gt;Invariant 2: Architectural Transparency Entering and exiting debug mode does not change architected state (except DPC/DCSR). The program cannot detect it was halted (modulo real-time constraints).&lt;/p&gt;
    &lt;p&gt;Invariant 3: Debug Privilege Debug mode executes at maximum privilege (M-mode). All memory is accessible, all CSRs are readable.&lt;/p&gt;
    &lt;p&gt;Invariant 4: No Interrupts in Debug Interrupts are masked while in debug mode. The debugger must explicitly re-enable them.&lt;/p&gt;
    &lt;p&gt;These invariants enable reproducible debugging: halting twice at the same PC should show identical state.&lt;/p&gt;
    &lt;p&gt;Serial Wire Debug (SWD) is a 2-wire replacement for JTAG's 5-wire interface, developed by ARM. The protocol operates over two signals:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SWCLK: Clock signal driven by the debugger (host)&lt;/item&gt;
      &lt;item&gt;SWDIO: Bidirectional data signal with turnaround phases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each SWD transaction consists of three phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Request Phase (8 bits, host drives SWDIO):&lt;/p&gt;
        &lt;code&gt;Bit 0: Start (always 1) Bit 1: APnDP (0=DP access, 1=AP access) Bit 2: RnW (0=Write, 1=Read) Bit 3-4: A[3:2] (register address bits) Bit 5: Parity (even parity of bits 1-4) Bit 6: Stop (always 0) Bit 7: Park (always 1)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Acknowledge Phase (3 bits, target drives SWDIO):&lt;/p&gt;
        &lt;code&gt;OK (001): Transaction accepted WAIT (010): Target requests retry FAULT (100): Error condition&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data Phase (33 bits, direction depends on RnW):&lt;/p&gt;
        &lt;code&gt;Bits 0-31: Data word Bit 32: Parity bit&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Turnaround cycles (host releases SWDIO, target can drive) occur between request→ack and during data phase direction changes.&lt;/p&gt;
    &lt;p&gt;Our implementation of the packet construction is in &lt;code&gt;swd_protocol.c:97-113&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;static uint8_t make_swd_request(bool APnDP, bool RnW, uint8_t addr) {
    uint8_t a2 = (addr &amp;gt;&amp;gt; 2) &amp;amp; 1;
    uint8_t a3 = (addr &amp;gt;&amp;gt; 3) &amp;amp; 1;
    uint8_t parity = (APnDP + RnW + a2 + a3) &amp;amp; 1;

    uint8_t request = 0;
    request |= (1 &amp;lt;&amp;lt; 0);          // Start bit
    request |= (APnDP &amp;lt;&amp;lt; 1);      // AP/DP select
    request |= (RnW &amp;lt;&amp;lt; 2);        // Read/Write
    request |= (a2 &amp;lt;&amp;lt; 3);         // Address bit 2
    request |= (a3 &amp;lt;&amp;lt; 4);         // Address bit 3
    request |= (parity &amp;lt;&amp;lt; 5);     // Parity
    request |= (0 &amp;lt;&amp;lt; 6);          // Stop bit
    request |= (1 &amp;lt;&amp;lt; 7);          // Park bit
    return request;
}&lt;/code&gt;
    &lt;p&gt;Unlike software bit-banging (which suffers from timing jitter and CPU overhead), this implementation uses RP2040/RP2350's Programmable I/O (PIO) blocks for deterministic timing.&lt;/p&gt;
    &lt;p&gt;The PIO program (&lt;code&gt;swd.pio&lt;/code&gt;) implements a command-based interface where each FIFO entry encodes either a command or data payload. Command format:&lt;/p&gt;
    &lt;code&gt;Bits 0-7:   Bit count - 1
Bit 8:      Direction (0=input, 1=output)
Bits 9-13:  Target instruction address
&lt;/code&gt;
    &lt;p&gt;The state machine operates at 4 cycles per clock period, providing precise SWCLK generation independent of system clock frequency. See &lt;code&gt;swd.pio:45-68&lt;/code&gt; for the complete implementation.&lt;/p&gt;
    &lt;p&gt;Clock divider calculation (&lt;code&gt;swd_protocol.c:313-330&lt;/code&gt;) accounts for this 4-cycle period:&lt;/p&gt;
    &lt;code&gt;uint32_t clk_sys_khz = clock_get_hz(clk_sys) / 1000;
uint32_t divider = (((clk_sys_khz + freq_khz - 1) / freq_khz) + 3) / 4;&lt;/code&gt;
    &lt;p&gt;ARM Debug Interface Architecture v6 introduces a Dormant State to enable coexistence of multiple debug protocols (JTAG and SWD) on the same pins. At power-up, RP2350's SW-DP enters the Dormant state, requiring explicit activation before SWD operations can proceed.&lt;/p&gt;
    &lt;p&gt;The dormant state solves a fundamental problem: JTAG uses 5 signals (TMS, TCK, TDI, TDO, TRST), while SWD uses 2 (SWCLK, SWDIO). When both protocols share physical pins, the debug port must determine which protocol the debugger intends to use. The solution is to require a protocol-specific "unlock" sequence that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cannot be generated accidentally by non-debug traffic on the pins&lt;/item&gt;
      &lt;item&gt;Is sufficiently long to avoid false positives (128 bits)&lt;/item&gt;
      &lt;item&gt;Uniquely identifies the target protocol (JTAG vs SWD)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SW-DP implements a finite state machine with three protocol modes:&lt;/p&gt;
    &lt;code&gt;Power-On → [Default State] → Dormant
                                 │
                    ┌────────────┼────────────┐
                    │                         │
         JTAG Activation              SWD Activation
         Sequence (0x33bbbbba)        Sequence (0x1a)
                    │                         │
                    ▼                         ▼
              ┌──────────┐              ┌──────────┐
              │   JTAG   │              │   SWD    │
              │  Active  │              │  Active  │
              └────┬─────┘              └────┬─────┘
                   │                         │
         JTAG-to-Dormant              SWD-to-Dormant
         Sequence                     Sequence
                   │                         │
                   └──────────┬──────────────┘
                              ▼
                         ┌──────────┐
                         │ Dormant  │
                         └──────────┘
&lt;/code&gt;
    &lt;p&gt;Once activated, the debug port remains in the selected protocol mode until:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A transition-to-dormant sequence is sent&lt;/item&gt;
      &lt;item&gt;Power is cycled&lt;/item&gt;
      &lt;item&gt;The external reset (RUN) pin is asserted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before sending a protocol-specific activation code, ARM requires transmission of a 128-bit Selection Alert Sequence. This sequence serves as a "wake-up call" that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Synchronizes the target's bit-stream parser&lt;/item&gt;
      &lt;item&gt;Ensures the target is listening for an activation sequence&lt;/item&gt;
      &lt;item&gt;Provides sufficient entropy to avoid accidental activation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Selection Alert Sequence is a fixed 128-bit pattern defined in the ADI v6 specification:&lt;/p&gt;
    &lt;code&gt;0x19bc0ea2_e3ddafe9_86852d95_6209f392 (transmitted LSB-first)
&lt;/code&gt;
    &lt;p&gt;This constant was chosen for its Hamming distance properties—it is unlikely to occur in normal signal traffic or be generated by crosstalk, glitches, or other non-debug activity.&lt;/p&gt;
    &lt;p&gt;Our implementation (&lt;code&gt;swd_protocol.c:357-382&lt;/code&gt;) uses a defensive activation strategy that ensures reliable connection regardless of the SW-DP's initial state:&lt;/p&gt;
    &lt;code&gt;// Phase 1: Exit any prior protocol mode
static const uint8_t seq_jtag_to_dormant[] = {
    0xff,0xff,0xff,0xff,0xff,0xff,0xff, 0xbc,0xe3
};

// Phase 2: Activate SWD mode
static const uint8_t seq_dormant_to_swd[] = {
    0xff,                                        // Line reset (8 ones)
    0x92,0xf3,0x09,0x62,0x95,0x2d,0x85,0x86,     // Selection Alert
    0xe9,0xaf,0xdd,0xe3,0xa2,0x0e,0xbc,0x19,     //   (128 bits)
    0xa0,0xf1,0xff,                              // SWD Activation Code (0x1a)
    0xff,0xff,0xff,0xff,0xff,0xff,0xff, 0xff,    // Line reset (&amp;gt;50 ones)
    0x00                                         // Idle low
};&lt;/code&gt;
    &lt;p&gt;Why this two-phase approach?&lt;/p&gt;
    &lt;p&gt;The problem is that we don't know the SW-DP's current state:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fresh power-up: SW-DP is in Dormant mode (default)&lt;/item&gt;
      &lt;item&gt;Prior debug session: SW-DP may be in SWD or JTAG mode&lt;/item&gt;
      &lt;item&gt;Failed connection attempt: SW-DP may be in an undefined state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the SW-DP is already in SWD or JTAG mode, sending the Selection Alert Sequence will be interpreted as data transactions, potentially putting the DP into an error state. Our solution:&lt;/p&gt;
    &lt;p&gt;Phase 1: Force transition to Dormant&lt;/p&gt;
    &lt;p&gt;Send the JTAG-to-Dormant sequence (56 ones followed by 0xbc, 0xe3). This sequence:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If in JTAG mode: transitions to Dormant&lt;/item&gt;
      &lt;item&gt;If in SWD mode: interpreted as line reset + invalid transactions (harmless)&lt;/item&gt;
      &lt;item&gt;If already Dormant: has no effect (dormant state ignores invalid input)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The sequence consists of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;56 clock cycles high (JTAG TMS=1 → Test-Logic-Reset state)&lt;/item&gt;
      &lt;item&gt;0x3cbe (0xbc, 0xe3 LSB-first): JTAG-specific exit pattern&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 2: Activate SWD from Dormant&lt;/p&gt;
    &lt;p&gt;Now that we're guaranteed to be in Dormant mode (or already in SWD mode where line reset is idempotent), we send:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Line reset (8 ones): Clears any pending SWD transactions&lt;/item&gt;
      &lt;item&gt;Selection Alert Sequence (128 bits): Wakes dormant state machine&lt;/item&gt;
      &lt;item&gt;SWD Activation Code (0x1a, 8 bits): Selects SWD protocol&lt;/item&gt;
      &lt;item&gt;Line reset (&amp;gt;50 ones): Enters SWD Reset state, clearing sticky errors&lt;/item&gt;
      &lt;item&gt;Idle cycles: Ensures clean transition&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SWD Activation Code &lt;code&gt;0x1a&lt;/code&gt; decodes as:&lt;/p&gt;
    &lt;code&gt;Bits[7:0] = 0x1a = 0b00011010
&lt;/code&gt;
    &lt;p&gt;This specific bit pattern was chosen to be distinct from valid JTAG TMS sequences, ensuring protocol disambiguation.&lt;/p&gt;
    &lt;p&gt;The RP2350 datasheet (Section 3.5.1) describes a simpler connection sequence:&lt;/p&gt;
    &lt;code&gt;1. At least 8 × SWCLK cycles with SWDIO high
2. The 128-bit Selection Alert sequence
3. Four SWCLK cycles with SWDIO low
4. SWD activation code: 0x1a, LSB first
5. At least 50 × SWCLK cycles with SWDIO high (line reset)
6. A DPIDR read to exit the Reset state
&lt;/code&gt;
    &lt;p&gt;This sequence assumes the SW-DP is in Dormant mode at power-up. However, in real-world scenarios:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The target may have been previously debugged (SW-DP in SWD mode)&lt;/item&gt;
      &lt;item&gt;A debugger crash may have left the SW-DP in an error state&lt;/item&gt;
      &lt;item&gt;Multi-drop SWD configurations may require explicit state reset&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our JTAG→Dormant→SWD sequence provides universal robustness: it works regardless of the SW-DP's initial state. The cost is negligible—approximately 100 extra clock cycles, taking ~100µs at 1 MHz SWCLK—while the benefit is reliable connection without manual power-cycling.&lt;/p&gt;
    &lt;p&gt;After activation, we immediately read DP_IDCODE (&lt;code&gt;swd_protocol.c:386-397&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t idcode = 0;
err = swd_read_dp_raw(target, DP_IDCODE, &amp;amp;idcode);
if (err != SWD_OK) {
    swd_set_error(target, err, "Failed to read IDCODE");
    return err;
}

if ((idcode &amp;amp; 0x0fffffff) == 0) {
    swd_set_error(target, SWD_ERROR_PROTOCOL, "Invalid IDCODE: 0x%08x", idcode);
    return SWD_ERROR_PROTOCOL;
}&lt;/code&gt;
    &lt;p&gt;A successful IDCODE read confirms:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SWD protocol is active&lt;/item&gt;
      &lt;item&gt;The SW-DP is responding to transactions&lt;/item&gt;
      &lt;item&gt;The SWCLK frequency is within tolerance&lt;/item&gt;
      &lt;item&gt;SWDIO signal integrity is sufficient&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For RP2350, the IDCODE is &lt;code&gt;0x4c013477&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;This defensive activation strategy, while not strictly necessary for fresh power-up scenarios, ensures our library works reliably across the full range of real-world debug connection scenarios—a critical property for a reusable debug library.&lt;/p&gt;
    &lt;p&gt;The Debug Access Port (DAP) provides memory-mapped access to debug resources through two register banks:&lt;/p&gt;
    &lt;p&gt;The Debug Port (DP) manages power domains and AP selection:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DP_IDCODE (0x0): Designer and part number identification&lt;/item&gt;
      &lt;item&gt;DP_CTRL_STAT (0x4): Power control and status flags&lt;/item&gt;
      &lt;item&gt;DP_SELECT (0x8): AP and register bank selection&lt;/item&gt;
      &lt;item&gt;DP_RDBUFF (0xC): Read buffer for pipelined AP reads&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Access Ports (AP) provide interfaces to debug resources. RP2350 implements multiple APs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AP 0x0: ROM Table&lt;/item&gt;
      &lt;item&gt;AP 0x2: ARM Core 0 AHB-AP&lt;/item&gt;
      &lt;item&gt;AP 0x4: ARM Core 1 AHB-AP&lt;/item&gt;
      &lt;item&gt;AP 0x8: RP2350-specific AP&lt;/item&gt;
      &lt;item&gt;AP 0xA: RISC-V APB-AP (target of this library)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each AP has standardized registers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AP_CSW (0x00): Control/Status Word&lt;/item&gt;
      &lt;item&gt;AP_TAR (0x04): Transfer Address Register&lt;/item&gt;
      &lt;item&gt;AP_DRW (0x0C): Data Read/Write Register&lt;/item&gt;
      &lt;item&gt;AP_IDR (0xFC): Identification Register&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Standard ARM DP_SELECT format uses bits[31:24] for APSEL and bits[7:4] for APBANKSEL. RP2350 implements a non-standard encoding (&lt;code&gt;dap.c:18-22&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t make_dp_select_rp2350(uint8_t apsel, uint8_t bank, bool ctrlsel) {
    // [15:12] = APSEL, [11:8] = 0xD, [7:4] = bank, [0] = ctrlsel
    return ((apsel &amp;amp; 0xF) &amp;lt;&amp;lt; 12) | (0xD &amp;lt;&amp;lt; 8) | ((bank &amp;amp; 0xF) &amp;lt;&amp;lt; 4) | (ctrlsel ? 1 : 0);
}&lt;/code&gt;
    &lt;p&gt;The magic constant 0xD in bits[11:8] is undocumented but required for correct AP selection.&lt;/p&gt;
    &lt;p&gt;AP registers are accessed through a banking mechanism where DP_SELECT must be written before each AP access. To minimize SWD transactions, the library maintains a cache of the current bank selection (&lt;code&gt;dap.c:28-55&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;static swd_error_t select_ap_bank(swd_target_t *target, uint8_t apsel, uint8_t bank) {
    if (target-&amp;gt;dap.current_apsel == apsel &amp;amp;&amp;amp;
        target-&amp;gt;dap.current_bank == bank &amp;amp;&amp;amp;
        target-&amp;gt;dap.ctrlsel == true) {
        return SWD_OK;  // Already selected
    }
    // Write DP_SELECT...
    target-&amp;gt;dap.current_apsel = apsel;
    target-&amp;gt;dap.current_bank = bank;
    // ...
}&lt;/code&gt;
    &lt;p&gt;This caching reduces transaction count by approximately 50% in typical debug sessions.&lt;/p&gt;
    &lt;p&gt;Before any debug operations can proceed, the Debug Power Domain (DPD) and System Power Domain (SPD) must be powered up. This is not a physical power operation but rather clock and reset domain enabling.&lt;/p&gt;
    &lt;p&gt;The power-up sequence (&lt;code&gt;dap.c:61-110&lt;/code&gt;) follows the ARM Debug Interface specification:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clear sticky errors: Write 0 to DP_CTRL_STAT&lt;/item&gt;
      &lt;item&gt;Request power-up: Set CDBGPWRUPREQ (bit 28) and CSYSPWRUPREQ (bit 30)&lt;/item&gt;
      &lt;item&gt;Poll acknowledgment: Wait for CDBGPWRUPACK (bit 29) and CSYSPWRUPACK (bit 31)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;uint32_t ctrl_stat = (1 &amp;lt;&amp;lt; 28) | (1 &amp;lt;&amp;lt; 30);
swd_write_dp_raw(target, DP_CTRL_STAT, ctrl_stat);

for (int i = 0; i &amp;lt; 10; i++) {
    swd_read_dp_raw(target, DP_CTRL_STAT, &amp;amp;status);
    bool cdbgpwrupack = (status &amp;gt;&amp;gt; 29) &amp;amp; 1;
    bool csyspwrupack = (status &amp;gt;&amp;gt; 31) &amp;amp; 1;
    if (cdbgpwrupack &amp;amp;&amp;amp; csyspwrupack) {
        return SWD_OK;
    }
    sleep_ms(20);
}&lt;/code&gt;
    &lt;p&gt;Failure to complete this sequence results in all subsequent debug operations returning WAIT responses indefinitely.&lt;/p&gt;
    &lt;p&gt;After DAP power-up, the RP2350-specific Debug Module must be initialized through an undocumented activation handshake. This sequence was reverse-engineered from OpenOCD's RP2350 support with an oscilloscope and patience.&lt;/p&gt;
    &lt;p&gt;The activation sequence (&lt;code&gt;rp2350.c:106-194&lt;/code&gt;) consists of:&lt;/p&gt;
    &lt;code&gt;uint32_t sel_bank0 = make_dp_select_rp2350(AP_RISCV, 0, true);
dap_write_dp(target, DP_SELECT, sel_bank0);

uint32_t csw = 0xA2000002;  // 32-bit access, auto-increment disabled
dap_write_ap(target, AP_RISCV, AP_CSW, csw);&lt;/code&gt;
    &lt;p&gt;The Debug Module registers are normally accessed through Bank 0, but activation requires Bank 1:&lt;/p&gt;
    &lt;code&gt;uint32_t sel_bank1 = make_dp_select_rp2350(AP_RISCV, 1, true);
dap_write_dp(target, DP_SELECT, sel_bank1);

// Three-phase handshake
dap_write_ap(target, AP_RISCV, AP_CSW, 0x00000000);  // Reset
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);

dap_write_ap(target, AP_RISCV, AP_CSW, 0x00000001);  // Activate
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);

dap_write_ap(target, AP_RISCV, AP_CSW, 0x07FFFFC1);  // Configure
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);&lt;/code&gt;
    &lt;p&gt;The expected status response is &lt;code&gt;0x04010001&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The RISC-V Debug Module implements the RISC-V External Debug Support specification v0.13. Debug Module registers are memory-mapped at base address 0x40 (register addresses are byte offsets × 4).&lt;/p&gt;
    &lt;p&gt;Key registers (&lt;code&gt;rp2350.c:17-29&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;#define DM_DMCONTROL   (0x10 * 4)  // Hart control
#define DM_DMSTATUS    (0x11 * 4)  // Hart status
#define DM_ABSTRACTCS  (0x16 * 4)  // Abstract command status
#define DM_COMMAND     (0x17 * 4)  // Abstract command execution
#define DM_DATA0       (0x04 * 4)  // Data transfer register
#define DM_PROGBUF0    (0x20 * 4)  // Program buffer word 0
#define DM_PROGBUF1    (0x21 * 4)  // Program buffer word 1
#define DM_SBCS        (0x38 * 4)  // System Bus Access Control
#define DM_SBADDRESS0  (0x39 * 4)  // SBA Address
#define DM_SBDATA0     (0x3C * 4)  // SBA Data&lt;/code&gt;
    &lt;p&gt;Hart (hardware thread) execution is controlled through DMCONTROL register fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dmactive (bit 0): Debug Module active (must be 1)&lt;/item&gt;
      &lt;item&gt;haltreq (bit 31): Request hart halt&lt;/item&gt;
      &lt;item&gt;resumereq (bit 30): Request hart resume&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Halt sequence (&lt;code&gt;rp2350.c:205-240&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = (1 &amp;lt;&amp;lt; 31) | (1 &amp;lt;&amp;lt; 0);  // haltreq | dmactive
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);

// Poll DMSTATUS.allhalted (bit 9)
for (int i = 0; i &amp;lt; 10; i++) {
    swd_result_t result = dap_read_mem32(target, DM_DMSTATUS);
    bool allhalted = (result.value &amp;gt;&amp;gt; 9) &amp;amp; 1;
    if (allhalted) {
        target-&amp;gt;rp2350.hart_halted = true;
        return SWD_OK;
    }
    sleep_ms(10);
}&lt;/code&gt;
    &lt;p&gt;Abstract commands provide a high-level interface to hart state without halting. The COMMAND register format for GPR access:&lt;/p&gt;
    &lt;code&gt;Bits 0-15:   regno (0x1000 + reg_num for GPRs)
Bit 16:      write (1=write, 0=read)
Bit 17:      transfer (1=execute transfer)
Bits 20-22:  aarsize (2=32-bit access)
&lt;/code&gt;
    &lt;p&gt;GPR read implementation (&lt;code&gt;rp2350.c:333-389&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t command = 0;
command |= (0x1000 + reg_num) &amp;lt;&amp;lt; 0;    // regno
command |= (1 &amp;lt;&amp;lt; 17);                  // transfer
command |= (2 &amp;lt;&amp;lt; 20);                  // aarsize=32-bit

dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);  // Poll ABSTRACTCS.busy
result = dap_read_mem32(target, DM_DATA0);&lt;/code&gt;
    &lt;p&gt;The Program Buffer (PROGBUF) is a 16-entry instruction memory within the Debug Module that enables execution of arbitrary RISC-V code in the debug context. Understanding its operation requires examining the execution model, register preservation semantics, and synchronization mechanisms.&lt;/p&gt;
    &lt;p&gt;A RISC-V hart operates in one of two contexts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Normal Context: The hart executes from main memory, PC advances sequentially, and all architectural state is visible to the program.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Debug Context: Upon entering debug mode (via halt request, ebreak, or trigger), the hart:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Saves PC to DPC (Debug Program Counter, CSR 0x7b1)&lt;/item&gt;
          &lt;item&gt;Enters a special execution mode where PROGBUF instructions execute&lt;/item&gt;
          &lt;item&gt;Maintains all GPRs and CSRs in their pre-halt state&lt;/item&gt;
          &lt;item&gt;Cannot access main memory without explicit instructions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Debug Module provides a "scratch pad" where debugger-supplied instructions execute with full access to hart state, but without disturbing that state beyond explicit modifications.&lt;/p&gt;
    &lt;p&gt;RP2350's Debug Module provides 2 program buffer entries (PROGBUF0 and PROGBUF1), though the specification allows up to 16. Each entry holds one 32-bit RISC-V instruction:&lt;/p&gt;
    &lt;code&gt;#define DM_PROGBUF0  (0x20 * 4)  // First instruction
#define DM_PROGBUF1  (0x21 * 4)  // Second instruction (typically ebreak)&lt;/code&gt;
    &lt;p&gt;The execution model assumes the final instruction is &lt;code&gt;ebreak&lt;/code&gt; (0x00100073), which returns control to the Debug Module and makes the hart available for further debug operations.&lt;/p&gt;
    &lt;p&gt;Abstract commands can trigger PROGBUF execution through the &lt;code&gt;postexec&lt;/code&gt; bit (bit 18 of the COMMAND register). This creates a transactional execution model:&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────┐
│ 1. Debugger writes PROGBUF instructions  │
├──────────────────────────────────────────┤
│ 2. Debugger writes DATA0 (optional)      │
├──────────────────────────────────────────┤
│ 3. Abstract command with postexec=1      │
│   - Transfers DATA0 → GPR (if transfer=1)│
│   - Executes PROGBUF[0]..PROGBUF[N]      │
│   - Executes ebreak (returns to DM)      │
│   - Transfers GPR → DATA0 (if transfer=1)│
└──────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;This mechanism eliminates race conditions: the data transfer and program execution form an atomic operation from the debugger's perspective.&lt;/p&gt;
    &lt;p&gt;The Debug Program Counter (DPC, CSR 0x7b1) cannot be accessed via abstract commands—it exists only in debug context and abstract commands target normal context registers. Reading DPC requires PROGBUF execution (&lt;code&gt;rp2350.c:804-833&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Phase 1: Preserve scratch register&lt;/p&gt;
    &lt;code&gt;swd_result_t saved_s0 = rp2350_read_reg(target, hart_id, 8);  // x8 = s0&lt;/code&gt;
    &lt;p&gt;The RISC-V ABI designates s0 (x8) as a saved register, but we must preserve it because our PROGBUF code will clobber it.&lt;/p&gt;
    &lt;p&gt;Phase 2: Write PROGBUF instructions&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_PROGBUF0, 0x7b102473);  // csrr s0, dpc
dap_write_mem32(target, DM_PROGBUF1, 0x00100073);  // ebreak&lt;/code&gt;
    &lt;p&gt;The instruction &lt;code&gt;csrr s0, dpc&lt;/code&gt; (CSR Read) has the encoding:&lt;/p&gt;
    &lt;code&gt;31      20 19   15 14  12 11    7 6      0
┌─────────┬───────┬──────┬───────┬────────┐
│ 0x7b1   │ 0x00  │ 0x2  │ 0x08  │ 0x73   │
│ CSR addr│ rs1   │funct3│  rd   │ opcode │
│  DPC    │  x0   │CSRRS │  s0   │ SYSTEM │
└─────────┴───────┴──────┴───────┴────────┘
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;funct3=0x2 (CSRRS): CSR Read and Set. Since rs1=x0, no bits are set (read-only operation).&lt;/item&gt;
      &lt;item&gt;CSR 0x7b1: DPC is defined in RISC-V Debug Spec v0.13, section 4.8.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 3: Execute with postexec&lt;/p&gt;
    &lt;code&gt;uint32_t command = (1 &amp;lt;&amp;lt; 18);  // postexec=1, transfer=0
dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);  // Poll ABSTRACTCS.busy&lt;/code&gt;
    &lt;p&gt;The hart now executes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;csrr s0, dpc&lt;/code&gt;→ DPC value loaded into s0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ebreak&lt;/code&gt;→ Return to Debug Module, s0 contains DPC&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 4: Extract result via abstract command&lt;/p&gt;
    &lt;code&gt;result = rp2350_read_reg(target, hart_id, 8);  // Read s0 (now contains DPC)&lt;/code&gt;
    &lt;p&gt;Phase 5: Restore architectural state&lt;/p&gt;
    &lt;code&gt;rp2350_write_reg(target, hart_id, 8, saved_s0.value);  // Restore s0&lt;/code&gt;
    &lt;p&gt;This five-phase sequence is invisible to the hart's normal execution: when resumed, all registers appear unchanged.&lt;/p&gt;
    &lt;p&gt;Writing DPC uses the inverse data flow (&lt;code&gt;rp2350.c:879-909&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;// Phase 1: Transfer new PC value to s0
err = rp2350_write_reg(target, hart_id, 8, new_pc_value);

// Phase 2: Write PROGBUF to copy s0 → DPC
dap_write_mem32(target, DM_PROGBUF0, 0x7b141073);  // csrw dpc, s0
dap_write_mem32(target, DM_PROGBUF1, 0x00100073);  // ebreak

// Phase 3: Execute
uint32_t command = (1 &amp;lt;&amp;lt; 18);  // postexec=1
dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);&lt;/code&gt;
    &lt;p&gt;The instruction &lt;code&gt;csrw dpc, s0&lt;/code&gt; (CSR Write) has encoding 0x7b141073:&lt;/p&gt;
    &lt;code&gt;31      20 19   15 14  12 11    7 6      0
┌─────────┬───────┬──────┬───────┬────────┐
│ 0x7b1   │ 0x08  │ 0x1  │ 0x00  │ 0x73   │
│ CSR addr│ rs1   │funct3│  rd   │ opcode │
│  DPC    │  s0   │CSRRW │  x0   │ SYSTEM │
└─────────┴───────┴──────┴───────┴────────┘
&lt;/code&gt;
    &lt;p&gt;funct3=0x1 (CSRRW): CSR Read and Write. The old CSR value is discarded (rd=x0), and s0's value is written to DPC.&lt;/p&gt;
    &lt;p&gt;The PROGBUF execution environment imposes several constraints:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Memory Access Limitation: PROGBUF instructions execute in debug mode, where memory access depends on Debug Module configuration. Standard loads/stores may fault.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Instruction Count: With only 2 entries, complex operations require multiple PROGBUF sequences. Each sequence incurs the cost of abstract command execution (~100µs typical).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No Branching: PROGBUF is linear. Conditional execution requires host-side logic to decide which PROGBUF sequence to execute.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Register Pressure: Only one scratch register (s0) is conventionally used. More complex operations require additional saves/restores.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ebreak Requirement: The final instruction must be&lt;/p&gt;&lt;code&gt;ebreak&lt;/code&gt;. Omitting it causes the hart to hang in debug mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This execution model provides a "remote procedure call" mechanism where the host supplies short instruction sequences that execute atomically on the hart, providing a window into debug-only architectural state.&lt;/p&gt;
    &lt;p&gt;System Bus Access (SBA) represents a fundamental departure from the traditional halt-based debugging model. Where classical debugging requires stopping the hart, transferring data through GPRs, and resuming, SBA provides a "back door" to the memory subsystem that operates concurrently with hart execution.&lt;/p&gt;
    &lt;p&gt;The Debug Module contains a bus master that can initiate memory transactions on the system bus independently of the harts. This master has the following characteristics:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Separate Bus Master: SBA transactions do not consume hart resources or execution time&lt;/item&gt;
      &lt;item&gt;Concurrent Operation: Memory reads/writes occur while harts execute normally&lt;/item&gt;
      &lt;item&gt;Cache Coherency Dependency: SBA bypasses hart caches; coherency is NOT guaranteed&lt;/item&gt;
      &lt;item&gt;Bus Arbitration: SBA competes with harts for bus bandwidth&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SBA interface consists of three memory-mapped registers in the Debug Module:&lt;/p&gt;
    &lt;code&gt;#define DM_SBCS        (0x38 * 4)  // System Bus Access Control and Status
#define DM_SBADDRESS0  (0x39 * 4)  // System Bus Address (32-bit)
#define DM_SBDATA0     (0x3C * 4)  // System Bus Data (32-bit)&lt;/code&gt;
    &lt;p&gt;The SBCS register (offset 0x38) contains configuration and status fields defined in RISC-V Debug Spec v0.13.2, section 3.12.18:&lt;/p&gt;
    &lt;code&gt;31:29 sbversion        (read-only)  SBA version
28:23 (reserved)       0
   22 sbbusyerror      (W1C)        Bus error occurred
   21 sbbusy           (read-only)  Bus master is busy
   20 sbreadonaddr     (read-write) Auto-read on SBADDRESS0 write
19:17 sbaccess         (read-write) Access width: 0=8-bit, 1=16-bit, 2=32-bit
   16 sbautoincrement  (read-write) Auto-increment address after access
   15 sbreadondata     (read-write) Auto-read on SBDATA0 read
14:12 sberror          (W1C)        Error status (0=none, 1=timeout, 2=bad addr, 3=alignment, 4=size, 7=other)
11:5  sbasize          (read-only)  Address width in bits (32 for RP2350)
&lt;/code&gt;
    &lt;p&gt;The SBA subsystem initialization (&lt;code&gt;rp2350.c:958-992&lt;/code&gt;) follows a capability discovery pattern:&lt;/p&gt;
    &lt;p&gt;Phase 1: Read SBCS to detect supported features&lt;/p&gt;
    &lt;code&gt;swd_result_t result = dap_read_mem32(target, DM_SBCS);&lt;/code&gt;
    &lt;p&gt;Phase 2: Verify SBA capability&lt;/p&gt;
    &lt;code&gt;// Check sbasize field (bits [11:5]) to verify SBA is present
uint32_t sbasize = (result.value &amp;gt;&amp;gt; 5) &amp;amp; 0x7F;
if (sbasize == 0) {
    return SWD_ERROR_INVALID_STATE;  // SBA not available
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;sbasize&lt;/code&gt; field indicates the system bus address width (32 bits for RP2350). RP2350 supports 8-bit, 16-bit, and 32-bit access widths. We configure for 32-bit:&lt;/p&gt;
    &lt;p&gt;Phase 3: Configure access mode&lt;/p&gt;
    &lt;code&gt;uint32_t sbcs = 0;
sbcs |= (2 &amp;lt;&amp;lt; 17);  // sbaccess = 2 (32-bit)
sbcs |= (1 &amp;lt;&amp;lt; 20);  // sbreadonaddr = 1 (auto-read trigger)
dap_write_mem32(target, DM_SBCS, sbcs);&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;sbreadonaddr&lt;/code&gt; flag is critical: it converts the address write into an atomic read-trigger operation.&lt;/p&gt;
    &lt;p&gt;Without &lt;code&gt;sbreadonaddr&lt;/code&gt;, a memory read requires three transactions:&lt;/p&gt;
    &lt;code&gt;1. Write address to SBADDRESS0
2. Write SBCS with read trigger
3. Read data from SBDATA0
&lt;/code&gt;
    &lt;p&gt;With &lt;code&gt;sbreadonaddr=1&lt;/code&gt;, the middle step is eliminated:&lt;/p&gt;
    &lt;code&gt;1. Write address to SBADDRESS0  ← Triggers bus read automatically
2. Read data from SBDATA0       ← Data is ready
&lt;/code&gt;
    &lt;p&gt;Implementation (&lt;code&gt;rp2350.c:1013-1020&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_SBADDRESS0, addr);  // Write triggers read
result = dap_read_mem32(target, DM_SBDATA0);   // Data is already valid&lt;/code&gt;
    &lt;p&gt;The Debug Module's state machine looks like:&lt;/p&gt;
    &lt;code&gt;IDLE → [SBADDRESS0 written] → BUSY → [bus read completes] → DATA_READY
                                ↓
                           [bus timeout] → SBERROR=1
&lt;/code&gt;
    &lt;p&gt;Memory writes use SBDATA0 as the trigger register:&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_SBADDRESS0, addr);   // Set address
dap_write_mem32(target, DM_SBDATA0, value);     // Write triggers bus write&lt;/code&gt;
    &lt;p&gt;The write to SBDATA0 initiates the system bus write transaction. The debugger should poll SBCS.sbbusyerror to detect completion (though in practice, pipelined writes are often used).&lt;/p&gt;
    &lt;p&gt;The SBCS.sberror field reports transaction failures:&lt;/p&gt;
    &lt;code&gt;0: No error
1: Timeout (bus did not respond)
2: Bad address (unmapped region)
3: Bad alignment (misaligned access)
4: Bad size (unsupported width)
7: Other error
&lt;/code&gt;
    &lt;p&gt;Errors are sticky and must be explicitly cleared by writing 1 to SBCS.sberror (W1C = Write-1-to-Clear).&lt;/p&gt;
    &lt;p&gt;The library maintains comprehensive state tracking to avoid redundant SWD transactions:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    bool connected;
    uint32_t idcode;
    bool resource_registered;
    // ...
} swd_target_t;&lt;/code&gt;
    &lt;code&gt;typedef struct {
    uint8_t current_apsel;
    uint8_t current_bank;
    bool ctrlsel;
    uint32_t select_cache;
    bool powered;
    uint retry_count;
} dap_state_t;&lt;/code&gt;
    &lt;p&gt;RP2350 contains two RISC-V harts (hardware threads) that execute independently. The library maintains per-hart state to avoid redundant operations and enable concurrent debugging:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    bool halt_state_known;  // false after resume, true after halt/read status
    bool halted;            // true if hart is currently halted

    // Register cache
    bool cache_valid;       // true if cached values are current
    uint32_t cached_pc;
    uint32_t cached_gprs[32];
    uint64_t cache_timestamp;  // For LRU if needed
} hart_state_t;&lt;/code&gt;
    &lt;p&gt;The top-level RP2350 state maintains an array of hart states:&lt;/p&gt;
    &lt;code&gt;#define RP2350_NUM_HARTS 2

typedef struct {
    bool initialized;
    bool sba_initialized;

    // Per-hart state
    hart_state_t harts[RP2350_NUM_HARTS];

    // Shared cache configuration
    bool cache_enabled;
} rp2350_state_t;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;halt_state_known&lt;/code&gt; flag implements a three-state model:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Unknown (&lt;code&gt;halt_state_known=false&lt;/code&gt;): Hart state is uncertain (after resume or initialization)&lt;/item&gt;
      &lt;item&gt;Known Halted (&lt;code&gt;halt_state_known=true, halted=true&lt;/code&gt;): Hart is confirmed halted&lt;/item&gt;
      &lt;item&gt;Known Running (&lt;code&gt;halt_state_known=true, halted=false&lt;/code&gt;): Hart is confirmed running&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This prevents expensive DMSTATUS polls when the state is known. State transitions:&lt;/p&gt;
    &lt;code&gt;                ┌─────────────┐
                │   Unknown   │
                └──────┬──────┘
                       │
         ┌─────────────┼─────────────┐
         │                           │
    halt_request()             read_dmstatus()
         │                           │
         ▼                           ▼
   ┌────────────┐             ┌──────────────┐
   │   Halted   │             │   Running    │
   └─────┬──────┘             └──────┬───────┘
         │                           │
         │         resume()          │
         └───────────────────────────┘
                      │
                      ▼
                 ┌─────────┐
                 │ Unknown │  (state invalidated)
                 └─────────┘
&lt;/code&gt;
    &lt;p&gt;When &lt;code&gt;cache_enabled=true&lt;/code&gt;, the library caches register values after reads. This optimization benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Repeated reads of the same register (e.g., polling loop variables)&lt;/item&gt;
      &lt;item&gt;Bulk register dumps where &lt;code&gt;rp2350_read_all_regs()&lt;/code&gt;populates the cache&lt;/item&gt;
      &lt;item&gt;Reduced SWD traffic (each register read requires ~6 SWD transactions)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cache invalidation occurs on:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hart resume (execution changes registers)&lt;/item&gt;
      &lt;item&gt;Register write (specific register invalidated)&lt;/item&gt;
      &lt;item&gt;Hart halt request (conservative invalidation)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The cache is per-hart, allowing concurrent debugging of both harts without interference.&lt;/p&gt;
    &lt;p&gt;PIO resources are scarce: RP2040/RP2350 provide 2 PIO blocks with 4 state machines each. The library implements a global resource tracker for multi-target support.&lt;/p&gt;
    &lt;code&gt;typedef struct {
    swd_target_t *pio0_sm_owners[4];
    swd_target_t *pio1_sm_owners[4];
    uint active_count;
} resource_tracker_t;

extern resource_tracker_t g_resources;&lt;/code&gt;
    &lt;p&gt;When &lt;code&gt;SWD_PIO_AUTO&lt;/code&gt; or &lt;code&gt;SWD_SM_AUTO&lt;/code&gt; is specified in configuration, the library scans for free resources (&lt;code&gt;swd.c:105-125&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;swd_error_t allocate_pio_sm(PIO *pio, uint *sm) {
    for (uint i = 0; i &amp;lt; 4; i++) {
        if (g_resources.pio0_sm_owners[i] == NULL) {
            *pio = pio0;
            *sm = i;
            return SWD_OK;
        }
    }
    // Try PIO1...
}&lt;/code&gt;
    &lt;p&gt;Up to 8 simultaneous target connections are supported (limited by hardware resources).&lt;/p&gt;
    &lt;p&gt;The library provides comprehensive error reporting through enumerated error codes and detailed message strings.&lt;/p&gt;
    &lt;code&gt;typedef enum {
    SWD_OK = 0,
    SWD_ERROR_TIMEOUT,        // Transaction timeout
    SWD_ERROR_FAULT,          // Target FAULT response
    SWD_ERROR_PROTOCOL,       // Malformed packet
    SWD_ERROR_PARITY,         // Parity check failure
    SWD_ERROR_WAIT,           // WAIT response retry exhausted
    SWD_ERROR_NOT_CONNECTED,  // No active connection
    SWD_ERROR_NOT_HALTED,     // Operation requires halted hart
    SWD_ERROR_ALREADY_HALTED, // Hart already halted (informational)
    // ...
} swd_error_t;&lt;/code&gt;
    &lt;p&gt;Each target maintains a 128-byte error detail buffer for formatted diagnostic messages (&lt;code&gt;swd.c:67-84&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;void swd_set_error(swd_target_t *target, swd_error_t error,
                   const char *detail, ...) {
    target-&amp;gt;last_error = error;
    va_list args;
    va_start(args, detail);
    vsnprintf(target-&amp;gt;error_detail, sizeof(target-&amp;gt;error_detail),
              detail, args);
    va_end(args);
}&lt;/code&gt;
    &lt;p&gt;SWD protocol ACK responses are mapped to error codes (&lt;code&gt;swd.c:91-99&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;swd_error_t swd_ack_to_error(uint8_t ack) {
    switch (ack) {
        case 0x1: return SWD_OK;            // OK
        case 0x2: return SWD_ERROR_WAIT;    // WAIT
        case 0x4: return SWD_ERROR_FAULT;   // FAULT
        default:  return SWD_ERROR_PROTOCOL;
    }
}&lt;/code&gt;
    &lt;p&gt;WAIT responses trigger automatic retry with backoff (&lt;code&gt;swd_protocol.c:197-208&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;for (uint retry = 0; retry &amp;lt; target-&amp;gt;dap.retry_count; retry++) {
    err = swd_io_raw(target, request, value, false);
    if (err != SWD_ERROR_WAIT) break;
    sleep_us(100);
}&lt;/code&gt;
    &lt;p&gt;Default retry count is 5, configurable via &lt;code&gt;swd_config_t&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;swd_config_t config = swd_config_default();
config.pin_swclk = 2;
config.pin_swdio = 3;
config.freq_khz = 1000;
config.enable_caching = true;

swd_target_t *target = swd_target_create(&amp;amp;config);
swd_connect(target);
rp2350_init(target);&lt;/code&gt;
    &lt;code&gt;// Halt hart 0
rp2350_halt(target, 0);

// Read program counter
swd_result_t pc = rp2350_read_pc(target, 0);
if (pc.error == SWD_OK) {
    printf("PC: 0x%08x\n", pc.value);
}

// Read all registers
uint32_t regs[32];
rp2350_read_all_regs(target, 0, regs);

// Single-step execution
rp2350_step(target, 0);

// Resume execution
rp2350_resume(target, 0);

// Reset hart
rp2350_reset(target, 0, true);  // Reset and halt&lt;/code&gt;
    &lt;code&gt;// Read memory (non-intrusive via SBA)
swd_result_t result = rp2350_read_mem32(target, 0x20000000);

// Write memory
rp2350_write_mem32(target, 0x20000000, 0xDEADBEEF);

// Block operations
uint32_t buffer[256];
rp2350_read_mem_block(target, 0x20000000, buffer, 256);&lt;/code&gt;
    &lt;code&gt;const uint32_t program[] = {
    0x200415b7,  // lui  a1, 0x20040
    0xabcd0537,  // lui  a0, 0xabcd0
    0x23450513,  // addi a0, a0, 0x234
    0x00a5a223,  // sw   a0, 4(a1)
    0x0000006f,  // j    0 (infinite loop)
};

rp2350_execute_code(target, 0, 0x20000000, program, 5);&lt;/code&gt;
    &lt;code&gt;// Trace callback receives each executed instruction
bool trace_callback(const trace_record_t *record, void *user_data) {
    printf("PC: 0x%08x  Instruction: 0x%08x\n",
           record-&amp;gt;pc, record-&amp;gt;instruction);

    // Optional: inspect registers
    if (record-&amp;gt;regs) {
        printf("  x5=0x%08x\n", record-&amp;gt;regs[5]);
    }

    return true;  // Continue tracing (false = stop)
}

// Trace 100 instructions on hart 0, capturing registers
int count = rp2350_trace(target, 0, 100, trace_callback, NULL, true);
printf("Traced %d instructions\n", count);&lt;/code&gt;
    &lt;code&gt;// Operate on both harts independently
rp2350_halt(target, 0);
rp2350_halt(target, 1);

// Read registers from both harts
uint32_t h0_regs[32], h1_regs[32];
rp2350_read_all_regs(target, 0, h0_regs);
rp2350_read_all_regs(target, 1, h1_regs);

// Execute different programs on each hart
rp2350_execute_code(target, 0, 0x20000000, program0, len0);
rp2350_execute_code(target, 1, 0x20001000, program1, len1);

// Trace hart 1 while hart 0 runs
rp2350_resume(target, 0);
rp2350_trace(target, 1, 50, trace_callback, NULL, false);&lt;/code&gt;
    &lt;code&gt;add_subdirectory(lib/pico2-swd-riscv)
target_link_libraries(your_application pico2_swd_riscv)&lt;/code&gt;
    &lt;p&gt;Set compile-time debug verbosity:&lt;/p&gt;
    &lt;code&gt;target_compile_definitions(your_application PRIVATE PICO2_SWD_DEBUG_LEVEL=3)&lt;/code&gt;
    &lt;p&gt;Levels: 0 (none), 1 (warnings), 2 (info), 3 (debug).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ARM Debug Interface Architecture Specification v5.2&lt;/item&gt;
      &lt;item&gt;ARM CoreSight SWD-DP Technical Reference Manual&lt;/item&gt;
      &lt;item&gt;RISC-V External Debug Support version 0.13&lt;/item&gt;
      &lt;item&gt;RP2350 Datasheet, Chapter 3.5: Debug&lt;/item&gt;
      &lt;item&gt;ADIv5.2 Supplement for Multi-drop SWD&lt;/item&gt;
      &lt;item&gt;IEEE 1149.1-2001 (JTAG)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Single-step execution enables instruction-level debugging by executing exactly one instruction before re-entering debug mode. This is implemented via the DCSR.step bit (Debug Control and Status Register, bit 2).&lt;/p&gt;
    &lt;p&gt;When DCSR.step=1, the hart executes one instruction after &lt;code&gt;resumereq&lt;/code&gt;, then immediately re-halts:&lt;/p&gt;
    &lt;code&gt;Debug Mode → [resumereq + DCSR.step=1] → Execute 1 instruction → Debug Mode
&lt;/code&gt;
    &lt;p&gt;Implementation (&lt;code&gt;rp2350.c:431-504&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Phase 1: Read current DCSR&lt;/p&gt;
    &lt;code&gt;swd_result_t dcsr_result = read_dcsr(target, hart_id);&lt;/code&gt;
    &lt;p&gt;DCSR must be read via PROGBUF (see Section 7.D) because it's a debug-only CSR.&lt;/p&gt;
    &lt;p&gt;Phase 2: Set step bit&lt;/p&gt;
    &lt;code&gt;uint32_t dcsr_stepped = dcsr_result.value | (1 &amp;lt;&amp;lt; 2);
write_dcsr(target, hart_id, dcsr_stepped);&lt;/code&gt;
    &lt;p&gt;Phase 3: Resume hart&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = make_dmcontrol(hart_id, false, true, false);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);&lt;/code&gt;
    &lt;p&gt;The hart now executes exactly one instruction, then:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;PC is saved to DPC&lt;/item&gt;
      &lt;item&gt;Hart re-enters debug mode&lt;/item&gt;
      &lt;item&gt;DCSR.cause = 0x4 (single-step)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 4: Wait for automatic halt&lt;/p&gt;
    &lt;code&gt;poll_dmstatus_halted(target, hart_id, true);&lt;/code&gt;
    &lt;p&gt;Phase 5: Clear step bit&lt;/p&gt;
    &lt;code&gt;write_dcsr(target, hart_id, dcsr_result.value);  // Restore original DCSR&lt;/code&gt;
    &lt;p&gt;This ensures subsequent &lt;code&gt;rp2350_resume()&lt;/code&gt; calls don't single-step.&lt;/p&gt;
    &lt;p&gt;The library implements software instruction tracing by repeatedly single-stepping and recording each instruction. This provides a "time-travel" debugging capability at the cost of execution speed.&lt;/p&gt;
    &lt;p&gt;Tracing uses a callback function to process each instruction (&lt;code&gt;rp2350.c:1262-1337&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;typedef struct {
    uint32_t pc;
    uint32_t instruction;
    uint32_t regs[32];  // Valid if capture_regs=true
} trace_record_t;

typedef bool (*trace_callback_t)(const trace_record_t *record, void *user_data);&lt;/code&gt;
    &lt;p&gt;The callback returns &lt;code&gt;true&lt;/code&gt; to continue or &lt;code&gt;false&lt;/code&gt; to stop.&lt;/p&gt;
    &lt;code&gt;int rp2350_trace(swd_target_t *target, uint8_t hart_id,
                 uint32_t max_instructions,
                 trace_callback_t callback, void *user_data,
                 bool capture_regs);&lt;/code&gt;
    &lt;p&gt;For each instruction:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read PC (via PROGBUF): Current instruction address&lt;/item&gt;
      &lt;item&gt;Read memory at PC: Fetch the instruction word&lt;/item&gt;
      &lt;item&gt;Optional: Read all GPRs: If &lt;code&gt;capture_regs=true&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Invoke callback: User processes the record&lt;/item&gt;
      &lt;item&gt;Single-step: Execute one instruction&lt;/item&gt;
      &lt;item&gt;Repeat until &lt;code&gt;max_instructions&lt;/code&gt;or callback returns false&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Loop Detection:&lt;/p&gt;
    &lt;code&gt;bool detect_loop(const trace_record_t *record, void *user_data) {
    static uint32_t entry_pc = 0;
    static int count = 0;

    if (count == 0) entry_pc = record-&amp;gt;pc;
    if (record-&amp;gt;pc == entry_pc &amp;amp;&amp;amp; count &amp;gt; 0) {
        printf("Loop detected at PC=0x%08x\n", record-&amp;gt;pc);
        return false;  // Stop trace
    }
    count++;
    return true;
}&lt;/code&gt;
    &lt;p&gt;Register State History:&lt;/p&gt;
    &lt;code&gt;bool capture_state(const trace_record_t *record, void *user_data) {
    printf("%08x: %08x  x5=%08x x6=%08x\n",
           record-&amp;gt;pc, record-&amp;gt;instruction,
           record-&amp;gt;regs[5], record-&amp;gt;regs[6]);
    return true;
}

rp2350_trace(target, 0, 100, capture_state, NULL, true);&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Speed: ~5ms per instruction (200 instructions/second)&lt;/item&gt;
      &lt;item&gt;Interrupt Masking: Tracing should occur with interrupts disabled (clear mstatus.MIE)&lt;/item&gt;
      &lt;item&gt;Memory Consistency: Instructions are fetched via SBA; ensure I-cache coherency&lt;/item&gt;
      &lt;item&gt;No Hardware Triggers: Trace starts immediately; no "trace until condition"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hart reset (&lt;code&gt;rp2350_reset&lt;/code&gt;) implements a controlled reset sequence via DMCONTROL.ndmreset (non-debug module reset, bit 1).&lt;/p&gt;
    &lt;code&gt;swd_error_t rp2350_reset(swd_target_t *target, uint8_t hart_id,
                         bool halt_on_reset);&lt;/code&gt;
    &lt;p&gt;Phase 1: Assert ndmreset&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = make_dmcontrol(hart_id, halt_on_reset, false, true);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);
sleep_ms(10);  // Hold reset&lt;/code&gt;
    &lt;p&gt;Phase 2: Deassert ndmreset&lt;/p&gt;
    &lt;code&gt;dmcontrol = make_dmcontrol(hart_id, halt_on_reset, false, false);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);
sleep_ms(50);  // Wait for reset completion&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;halt_on_reset=true&lt;/code&gt;, the DMCONTROL.haltreq bit remains set, causing the hart to enter debug mode immediately after reset, with PC set to the reset vector.&lt;/p&gt;
    &lt;p&gt;This reset is equivalent to a power-on reset for the hart:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PC → reset vector (typically 0x00000000 for RP2350 RISC-V cores)&lt;/item&gt;
      &lt;item&gt;All CSRs → architectural reset values&lt;/item&gt;
      &lt;item&gt;GPRs → undefined&lt;/item&gt;
      &lt;item&gt;Cache → invalidated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike a full chip reset, peripherals and other harts are unaffected.&lt;/p&gt;
    &lt;p&gt;RP2350's two RISC-V harts (Hazard3 cores) are symmetric and independently controllable. The library provides full per-hart state tracking and concurrent operation.&lt;/p&gt;
    &lt;p&gt;Each Debug Module operation targets a specific hart via DMCONTROL.hartsel[9:0]:&lt;/p&gt;
    &lt;code&gt;static inline uint32_t make_dmcontrol(uint8_t hart_id, bool haltreq,
                                       bool resumereq, bool ndmreset) {
    uint32_t dmcontrol = (1 &amp;lt;&amp;lt; 0);  // dmactive = 1
    dmcontrol |= ((uint32_t)hart_id &amp;lt;&amp;lt; 16);  // hartsello[9:0] at bits 25:16
    if (haltreq) dmcontrol |= (1 &amp;lt;&amp;lt; 31);
    if (resumereq) dmcontrol |= (1 &amp;lt;&amp;lt; 30);
    if (ndmreset) dmcontrol |= (1 &amp;lt;&amp;lt; 1);
    return dmcontrol;
}&lt;/code&gt;
    &lt;p&gt;Before any hart-specific operation (halt, resume, register read), the library writes DMCONTROL with the correct &lt;code&gt;hart_id&lt;/code&gt;, switching the Debug Module's attention to that hart.&lt;/p&gt;
    &lt;p&gt;The test suite validates that harts operate independently:&lt;/p&gt;
    &lt;code&gt;// Halt hart 0, keep hart 1 running
rp2350_halt(target, 0);
rp2350_resume(target, 1);

// Read hart 0 registers while hart 1 executes
uint32_t h0_regs[32];
rp2350_read_all_regs(target, 0, h0_regs);&lt;/code&gt;
    &lt;p&gt;This enables debugging one hart while the other maintains real-time operation.&lt;/p&gt;
    &lt;p&gt;Each hart maintains independent register state. Writing x5 on hart 0 does not affect x5 on hart 1. This is validated by &lt;code&gt;test_dual_hart.c:69-115&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;rp2350_write_reg(target, 0, 5, 0xAAAAAAAA);
rp2350_write_reg(target, 1, 5, 0x55555555);

assert(rp2350_read_reg(target, 0, 5).value == 0xAAAAAAAA);
assert(rp2350_read_reg(target, 1, 5).value == 0x55555555);&lt;/code&gt;
    &lt;p&gt;Both harts share the same physical memory space but maintain independent caches. This creates coherency considerations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SBA Writes: Visible to both harts (after cache invalidation)&lt;/item&gt;
      &lt;item&gt;Hart 0 Writes: Not immediately visible to Hart 1 if cached&lt;/item&gt;
      &lt;item&gt;Explicit Synchronization: Required for inter-hart communication&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The test suite exercises memory access while both harts run concurrently (&lt;code&gt;test_mem.c:291-347&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;This implementation does not currently support:&lt;/p&gt;
    &lt;p&gt;RISC-V Debug Specification defines a Trigger Module for hardware breakpoints. Implementation was removed due to complexity. Workaround: Use single-step + PC comparison in software.&lt;/p&gt;
    &lt;p&gt;The SWD protocol supports multiple targets on one bus via unique addresses. This library assumes a single target. Physical wiring for multi-target is possible but requires additional multiplexing logic.&lt;/p&gt;
    &lt;p&gt;RP2350's Hazard3 cores support the C extension (16-bit compressed instructions). The library:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Correctly reads compressed instructions during tracing&lt;/item&gt;
      &lt;item&gt;Does NOT decode compressed instruction mnemonics&lt;/item&gt;
      &lt;item&gt;Assumes 4-byte alignment for code upload&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No cycle-accurate performance counters are exposed. Implementing this requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Access to mcycle/minstret CSRs&lt;/item&gt;
      &lt;item&gt;Periodic sampling without halting (not possible with current SBA coherency)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No routines for RP2350 flash programming. This requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Loading flash programmer stub to SRAM&lt;/item&gt;
      &lt;item&gt;Executing stub via &lt;code&gt;rp2350_execute_code()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Monitoring completion via polling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The architecture supports this; implementation is left to applications.&lt;/p&gt;
    &lt;p&gt;Copyright (c) 2025&lt;/p&gt;
    &lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
    &lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt;
    &lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45874987</guid><pubDate>Mon, 10 Nov 2025 11:45:15 +0000</pubDate></item><item><title>Head in the Zed Cloud</title><link>https://maxdeviant.com/posts/2025/head-in-the-zed-cloud/</link><description>&lt;doc fingerprint="e73884714d9f1c8b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Head in the Zed Cloud&lt;/head&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;p&gt;For the past five months I've been leading the efforts to rebuild Zed's cloud infrastructure.&lt;/p&gt;
    &lt;p&gt;Our current backend—known as Collab—has been chugging along since basically the beginning of the company. We use Collab every day to work together on Zed in Zed. However, as Zed continues to grow and attracts more users, we knew that we needed a full reboot of our backend infrastructure to set us up for success for our future endeavors.&lt;/p&gt;
    &lt;p&gt;Enter Zed Cloud.&lt;/p&gt;
    &lt;p&gt;Like Zed itself, Zed Cloud is built in Rust1.&lt;/p&gt;
    &lt;p&gt;This time around there is a slight twist: all of this is running on Cloudflare Workers, with our Rust code being compiled down to WebAssembly (Wasm).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cloudflare Workers?&lt;/head&gt;
    &lt;p&gt;One of our goals with this rebuild was to reduce the amount of operational effort it takes to maintain our hosted services, so that we can focus more of our time and energy on building Zed itself.&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers allow us to easily scale up to meet demand without having to fuss over it too much.&lt;/p&gt;
    &lt;p&gt;Additionally, Cloudflare offers an ever-growing amount of managed services that cover anything you might need for a production web service. Here are some of the Cloudflare services we're using today:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hyperdrive for talking to Postgres&lt;/item&gt;
      &lt;item&gt;Workers KV for ephemeral storage&lt;/item&gt;
      &lt;item&gt;Cloudflare Queues for asynchronous job processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Platform&lt;/head&gt;
    &lt;p&gt;Another one of our goals with this rebuild was to build a platform that was easy to test. To achieve this, we built our own platform framework on top of the Cloudflare Workers runtime APIs.&lt;/p&gt;
    &lt;p&gt;At the heart of this framework is the &lt;code&gt;Platform&lt;/code&gt; trait:&lt;/p&gt;
    &lt;code&gt;pub trait Platform: Sized + Clone + 'static {
    type Cache: cache::Cache;
    type Clock: Clock;
    type KvStore: KvStore&amp;lt;Self&amp;gt;;
    type ServiceBinding: Fetcher&amp;lt;Self&amp;gt;;
    type DurableObjectNamespace: durable_object::DurableObjectNamespace&amp;lt;Self&amp;gt;;
    type DurableObjectStub: durable_object::DurableObjectStub&amp;lt;Self&amp;gt;;
    type DurableObjectState: durable_object::DurableObjectState&amp;lt;Self&amp;gt;;
    type RateLimiter: rate_limiter::RateLimiter&amp;lt;Self&amp;gt;;
    type SqlStorage: sql::SqlStorage;
    type PostgresConnection&amp;lt;T&amp;gt;: postgres::PostgresConnection&amp;lt;Self, T&amp;gt;;
    type PostgresTransaction&amp;lt;T&amp;gt;: postgres::PostgresTransaction&amp;lt;Self, T&amp;gt;;
    type ExecutionContext: ExecutionContext + Clone + Unpin;
    type Environment: Environment&amp;lt;Self&amp;gt; + Clone + Unpin;
    type ClientWebSocket: websocket::ClientWebSocket;
    type ServerWebSocket: websocket::ServerWebSocket&amp;lt;Self&amp;gt;;
    type WebSocketReceiver: websocket::WebSocketReceiver;
    type WebSocketSender: websocket::WebSocketSender;
    type HttpClient: http_client::HttpClient&amp;lt;Platform = Self&amp;gt;;
    type Queue&amp;lt;T: Serialize + 'static&amp;gt;: queue::Queue&amp;lt;Self, T&amp;gt;;
    type RawQueueMessageBatch: queue::RawQueueMessageBatch&amp;lt;Self&amp;gt;;
    type QueueMessageBatch&amp;lt;T: DeserializeOwned + 'static&amp;gt;: queue::QueueMessageBatch&amp;lt;Self, T&amp;gt;;
    type QueueMessage&amp;lt;T: DeserializeOwned + 'static&amp;gt;: queue::QueueMessage&amp;lt;Self, T&amp;gt;;
    type Rng: Clone + RngCore;

    fn websocket_pair() -&amp;gt; Result&amp;lt;(Self::ClientWebSocket, Self::ServerWebSocket)&amp;gt;;
}
&lt;/code&gt;
    &lt;p&gt;This trait allows us to write our code in a platform-agnostic way while still leveraging all of the functionality that Cloudflare Workers has to offer. Each one of these associated types corresponds to some aspect of the platform that we'll want to have control over in a test environment.&lt;/p&gt;
    &lt;p&gt;For instance, if we have a service that needs to interact with the system clock and a Workers KV store, we would define it like this:&lt;/p&gt;
    &lt;code&gt;pub struct BillingService&amp;lt;P: Platform&amp;gt; {
    clock: P::Clock,
    kv_store: P::KvStore,
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Two platforms, both alike in dignity&lt;/head&gt;
    &lt;p&gt;There are two implementors of the &lt;code&gt;Platform&lt;/code&gt; trait: &lt;code&gt;CloudflarePlatform&lt;/code&gt; and &lt;code&gt;SimulatedPlatform&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;CloudflarePlatform&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;&lt;code&gt;CloudflarePlatform&lt;/code&gt;—as the name might suggest—is an implementation of the platform on top of the Cloudflare Workers runtime. This implementation targets Wasm and is what we run when developing locally (using Wrangler) and in production.&lt;/p&gt;
    &lt;p&gt;We have a &lt;code&gt;cloudflare_bindings&lt;/code&gt; crate2 that contains &lt;code&gt;wasm_bindgen&lt;/code&gt; bindings to the Cloudflare Workers JS runtime. You can think of &lt;code&gt;CloudflarePlatform&lt;/code&gt; as the glue between those bindings and the idiomatic Rust APIs exposed by the &lt;code&gt;Platform&lt;/code&gt; trait.&lt;/p&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;SimulatedPlatform&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;SimulatedPlatform&lt;/code&gt; is used when running tests, and allows for simulating almost every part of the system in order to effectively test our code.&lt;/p&gt;
    &lt;p&gt;Here's an example of a test for ingesting a webhook from Orb:&lt;/p&gt;
    &lt;code&gt;#[test]
fn test_orb_webhook_ingestion() {
    Simulator::once(|simulator| async move {
        let test_ctx = OrbWebhooksTestContext::init(&amp;amp;simulator).await?;

        // Some more test setup...

        let request = make_orb_webhook_request(
            HANDLE_ORB_WEBHOOK_URL,
            &amp;amp;webhook_event,
            "2025-09-10T18:16:06.483Z".parse().unwrap(),
            &amp;amp;test_ctx.config.orb_webhook_signing_secret,
        )?;

        let response = test_ctx.worker.fetch(request).await?;
        assert_eq!(response.status, StatusCode::OK);

        simulator.scheduler.run()?;

        let updated_billing_subscription = BillingSubscriptionRepository
            .find(&amp;amp;test_ctx.app_database, billing_subscription.id)
            .await?;
        assert_eq!(
            updated_billing_subscription.kind,
            Some(app_database::SubscriptionKind::TokenBasedZedPro)
        );
        assert_eq!(
            updated_billing_subscription.orb_subscription_status,
            Some(app_database::OrbSubscriptionStatus::Active)
        );
    })
    .unwrap();
}
&lt;/code&gt;
    &lt;p&gt;In this test we're able to test the full end-to-end flow of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Receiving and validating an incoming webhook event to our webhook ingestion endpoint&lt;/item&gt;
      &lt;item&gt;Putting the webhook event into a queue&lt;/item&gt;
      &lt;item&gt;Consuming the webhook event in a background worker and processing it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The call to &lt;code&gt;simulator.scheduler.run()?&lt;/code&gt; advances the test simulator, in this case running the pending queue consumers.&lt;/p&gt;
    &lt;p&gt;At the center of the &lt;code&gt;SimulatedPlatform&lt;/code&gt; is the &lt;code&gt;scheduler&lt;/code&gt;, a crate that powers our in-house async runtime. The scheduler is shared between GPUI—Zed's UI framework—and the &lt;code&gt;Simulator&lt;/code&gt; used in tests.&lt;/p&gt;
    &lt;p&gt;This shared scheduler enables us to write tests that span the client and the server. So we can have a test that starts in a piece of Zed code, flows through Zed Cloud, and then asserts on the state of something in Zed after it receives the response from the backend.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where we're headed&lt;/head&gt;
    &lt;p&gt;The work being done on Zed Cloud now is laying the foundation to support our future work around collaborative coding with DeltaDB.&lt;/p&gt;
    &lt;p&gt;If you want to work with me on building out Zed Cloud, we are currently hiring for this role.&lt;/p&gt;
    &lt;p&gt;We're looking for engineers with experience building and maintaining web APIs and platforms, solid web fundamentals, and who are excited about Rust.&lt;/p&gt;
    &lt;p&gt;If you end up applying, you can mention this blog post in your application.&lt;/p&gt;
    &lt;p&gt;I look forward to hearing from you!&lt;/p&gt;
    &lt;p&gt;The codebase is currently 70k lines of Rust code and 5.7k lines of TypeScript.&lt;/p&gt;
    &lt;p&gt;This is essentially our own version of &lt;code&gt;worker-sys&lt;/code&gt;. I'd like to switch to using &lt;code&gt;worker-sys&lt;/code&gt; directly, at some point.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45876308</guid><pubDate>Mon, 10 Nov 2025 14:23:17 +0000</pubDate></item><item><title>Time to start de-Appling</title><link>https://heatherburns.tech/2025/11/10/time-to-start-de-appling/</link><description>&lt;doc fingerprint="b049d1f1222217d5"&gt;
  &lt;main&gt;
    &lt;p&gt;I‘ve done such a thorough job of de-Googling that I forgot to show up for a meeting with someone, because I hadn’t checked my Google calendar in ages. (No, they were not amused.) In my defense, I proceeded to explain to them that having de-Googled, I was also in the process of de-Appling, which is a special bonus level that those of us in the UK have unlocked.&lt;/p&gt;
    &lt;p&gt;If you’re reading this in the sunlit uplands, you need to start that too.&lt;/p&gt;
    &lt;p&gt;You need to start that because, as we recently learned, at some point in the very near future Apple is withdrawing its Advanced Data Protection (ADP) feature from the UK altogether as a result of the Home Office TCN through the Investigatory Powers Act.&lt;/p&gt;
    &lt;p&gt;Users who already had ADP enabled when the first TCN became public in February will be required to manually switch it off or lose their iCloud account.&lt;/p&gt;
    &lt;p&gt;I am not going to explain the chapter and verse of the legal saga today, because I prefer to do that for people who pay me to explain them the chapter and verse.&lt;/p&gt;
    &lt;p&gt;But I will say that the shutdown of ADP is Apple being on the right side of the geopolitical fight, as inconvenient as that may be to you and me.&lt;/p&gt;
    &lt;p&gt;When the whole debacle blew up in February, Apple announced that ADP would no longer be available for new users, but would remain unaffected for those of us who already had it activated. That assurance was nothing to sleep on, and so we have been waiting for the inevitable. Apple’s September update confirmed that its days are numbered:&lt;/p&gt;
    &lt;p&gt;So what does that mean for you? Again, from their September update:&lt;/p&gt;
    &lt;p&gt;Our communication services, like iMessage and FaceTime, remain end-to-end encrypted globally, including in the UK.&lt;/p&gt;
    &lt;p&gt;Users in the UK who have not already enabled Advanced Data Protection will no longer have the option to do so. That means the 10 iCloud data categories covered by ADP will be protected by Standard Data Protection, and UK users will not have a choice to benefit from end-to-end encryption for these categories: iCloud Backup; iCloud Drive; Photos; Notes; Reminders; Safari Bookmarks; Siri Shortcuts; Voice Memos; Wallet Passes; and Freeform.&lt;/p&gt;
    &lt;p&gt;This means that if you already had ADP activated, and e2ee is critical to your personal or operational security, you need to get everything in that list – iCloud Backup, iCloud Drive, Photos, Notes, Reminders, Safari Bookmarks, Siri Shortcuts, Voice Memos, Wallet Passes, and Freeform – off of iCloud sooner rather than later.&lt;/p&gt;
    &lt;p&gt;Once you’ve done that, go into your iCloud settings, click on Manage, then click on each thing individually to purge it off iCloud.&lt;/p&gt;
    &lt;p&gt;I’m not going to tell you where to move your stuff other than to say that if you’re moving it from one big tech company to another, you’re just being daft. Likewise, if you’re moving your stuff to a non-e2ee service, don’t bother. If you need an e2ee service try Proton. They have a Black Friday sale on.&lt;/p&gt;
    &lt;p&gt;If you have a lot of Notes, first download the Exporter app from the app store. It does what it says on the tin. You’ll end up with a folder full of markdown files which you can upload elsewhere. E2EE being the dealbreaker, I chose Standard Notes. I know a lot of folk who prefer Obsidian or Joplin. Whatever you choose, do not use a non-E2EE note service.*&lt;/p&gt;
    &lt;p&gt;You know as well as I do that you need to be moving everything you can out of the American stack anyway so just stick this task on your to-do list, which should not be Reminders, and get it done.&lt;/p&gt;
    &lt;head rend="h2"&gt;What about the non-e2ee stuff in iCloud?&lt;/head&gt;
    &lt;p&gt;The full list of what lives in iCloud and how it is or is not encrypted is here.&lt;/p&gt;
    &lt;p&gt;We know from the tiny bits of the TCN saga which have been publicly disclosed, thanks to the only two media outlets that are bothering to cover it, that the first TCN was not just for the end-to-end encrypted data protected by ADP. It was for anything on iCloud, full stop, worldwide:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…however, the new IPT filing states the TCN “is not limited to” data stored under ADP, suggesting the UK government sought bulk interception access to Apple’s standard iCloud service, which is much more widely used by the company’s customers. The TCN also included “obligations to provide and maintain a capability to disclose categories of data stored within a cloud-based backup service”, the filing states, which suggests the government sought to tap messages or passwords that were backed up in the cloud as well. “The obligations included in the TCN are not limited to the UK or users of the service in the UK; they apply globally in respect of the relevant data categories of all iCloud users,” the IPT filing adds. Tim Bradshaw and Anna Gross at the Financial Times (£)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This means that you have some serious thinking to do about what you intend to trust to the Apple stack altogether going forward, even things like passwords.&lt;/p&gt;
    &lt;p&gt;I can’t tell you what to do but once again, you have options. Educate yourself. Consider the opsec and persec needs not just of yourself, but for the people around you who could be adversely affected by insecure data going walkies out of your account.&lt;/p&gt;
    &lt;head rend="h2"&gt;What if I’m not in the UK?&lt;/head&gt;
    &lt;p&gt;This impacts the UK only: as their September update noted, Advanced Data Protection continues to be available everywhere else in the world.&lt;/p&gt;
    &lt;p&gt;It does mean that if you have someone in the UK on your team, you need to factor them in as part of your threat model. We are all liabilities to our own opsec now.&lt;/p&gt;
    &lt;p&gt;If you’re not in the UK, and you don’t have ADP activated, take 10 seconds to do it right now, you lucky sod.&lt;lb/&gt; Settings &amp;gt; Your name Apple Account &amp;gt; iCloud &amp;gt; Advanced Data Protection&lt;/p&gt;
    &lt;head rend="h2"&gt;What about that second TCN?&lt;/head&gt;
    &lt;p&gt;On the 1st of October, the Home Office issued a second TCN against Apple for the same as before, but only for British citizens’ data. World-leading!&lt;/p&gt;
    &lt;p&gt;Those who follow my work know that this phrase made me spew a double barrel of Glaswegian swearing. British citizens’ data, as opposed to British users’ data? The dividing line here is not e.g. being located in the UK or having registered an account here, but what it says on your passport? How is Apple going to know that, much less roll it out? (/s)&lt;/p&gt;
    &lt;p&gt;Did Apple just publicly state that they’re going to be removing a security layer and adding a nationality check layer?&lt;/p&gt;
    &lt;p&gt;We don’t know.&lt;/p&gt;
    &lt;p&gt;We don’t know because as with the first TCN, that information only became available in the public domain due to someone leaking it to the media. That’s all there is to know. Everything else is confidential and NCND. There is nothing else to say because nothing else is known. If someone who did know something was sitting across from me right now, and they told me, they would be committing a crime.&lt;/p&gt;
    &lt;p&gt;Those of us who care about these things enough to show up in difficult places are keeping tabs on both TCNs, and the wider legal and technical implications of both, as best we possibly can. Don’t expect to hear anything more until January, when the Liberty/PI challenge on the first TCN goes to the Investigatory Powers Tribunal. In the interim, if you want me to bore you about ECHR case law and how the UK’s review into Article 8 seems a little too coincidentally timed, pick a pub.&lt;/p&gt;
    &lt;p&gt;Otherwise, please make sure you de-Apple, de-Google, and de-American Stack yourself when you have time, clarity, and focus to do it. Start today.&lt;/p&gt;
    &lt;p&gt;In the meantime please follow and support the only media coverage being produced about the second TCN, which comes from Bill Goodwin at Computer Weekly and Tim Bradshaw and Anna Gross at the Financial Times (£).&lt;/p&gt;
    &lt;p&gt;Above all, please remember that this is the sunlit uplands. That’s the thing about Brexit Britain having decided to go it alone where tech regulation is concerned. It did not become the vanguard of a “world-leading” third way.&lt;/p&gt;
    &lt;p&gt;It became a small and inconsequential thing easily thrown under a bus.&lt;/p&gt;
    &lt;p&gt;Header image by me: Alan Turing memorial, Manchester, where he reminds you why keeping data private can be a matter of life and death.&lt;/p&gt;
    &lt;p&gt;*For the love of the wee man do not use a non-e2ee notetaking app which has been abandoned by an owner who has a track record of personally snooping through user data when he’s in a mood, i.e. if he’s breathing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45876598</guid><pubDate>Mon, 10 Nov 2025 14:57:26 +0000</pubDate></item><item><title>Unexpected things that are people</title><link>https://bengoldhaber.substack.com/p/unexpected-things-that-are-people</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45877257</guid><pubDate>Mon, 10 Nov 2025 16:05:46 +0000</pubDate></item><item><title>Launch HN: Hypercubic (YC F25) – AI for COBOL and Mainframes</title><link>https://news.ycombinator.com/item?id=45877517</link><description>&lt;doc fingerprint="3574724a08458fe1"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we’re Sai and Aayush and we’re building Hypercubic (&lt;/p&gt;https://www.hypercubic.ai/&lt;p&gt;)!&lt;/p&gt;&lt;p&gt;Hypercubic is an AI platform that helps Fortune 500 companies understand, preserve, and modernize their mainframe systems. These are the systems that run COBOL from the 1960s that still quietly power banking, insurance, airlines, and governments today.&lt;/p&gt;&lt;p&gt;70% of the Fortune 500 still run on mainframes, but the engineers who built and maintained them are retiring. Today, the average age of a COBOL/mainframe engineer is about 55 and rapidly increasing. What’s left behind are opaque, black box systems with almost no one who understands how they work. Modernization projects often fail, documentation is decades out of date, and critical institutional knowledge lives only in the minds of a few senior subject matter experts who are now leaving the workforce.&lt;/p&gt;&lt;p&gt;Current “AI for code” tools focus on codebases and repositories, so they miss the unwritten rules, historical context, and architectural reasoning that live in human minds. In the COBOL/mainframe world, that institutional knowledge is the key missing piece.&lt;/p&gt;&lt;p&gt;What we heard from modernization leaders is that the hard part is not the code analysis. The challenge is the institutional knowledge that never made it into code or documentation and has walked out the door. Modernization projects fail not because no one can parse COBOL, but because no one can answer “why was this billing edge case added in 1995 and what breaks if we remove it.”&lt;/p&gt;&lt;p&gt;Hypercubic is building an AI-native maintenance and modernization platform that learns how legacy mainframe systems actually work and captures the human reasoning behind operating them. We’re doing this with two initial tools, HyperDocs and HyperTwin.&lt;/p&gt;&lt;p&gt;HyperDocs ingests COBOL, JCL, and PL/I codebases to generate documentation, architecture diagrams, and dependency graphs. Enterprises currently spend months or years hiring contractors to reverse-engineer these systems; HyperDocs compresses that work to take much less time.&lt;/p&gt;&lt;p&gt;COBOL was designed to resemble English and business prose, making it a good fit for LLMs today. Mainframes have decades of consistent patterns (COBOL, JCL, CICS, batch jobs) and a finite set of recurring tasks (such as payroll, transaction processing, billing).&lt;/p&gt;&lt;p&gt;For example, here’s a billing fragment that would be run nightly in production at large insurance companies for moving money, closing accounts, and triggering downstream reports:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  EVALUATE TRUE
      WHEN PAYMENT-DUE AND NOT PAID
          PERFORM CALCULATE-LATE-FEE
          PERFORM GENERATE-NOTICE
      WHEN PAYMENT-RECEIVED AND BALANCE-DUE = 0
          MOVE "ACCOUNT CLEAR" TO STATUS
          PERFORM ARCHIVE-STATEMENT
      WHEN OTHER
          PERFORM LOG-ANOMALY
  END-EVALUATE.
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; Now imagine thousands of these rules, each running payrolls, processing claims, or reconciling accounts, spread across millions of lines of code written over 40+ years. HyperDocs ingests that code and reconstructs it into readable, living documentation that shows how the black box system works.&lt;/p&gt;&lt;p&gt;Our other tool, HyperTwin, tackles the “tribal knowledge” problem. It learns directly from subject-matter experts, observing workflows, analyzing screen interactions, and conducting AI-driven interviews to capture how they debug and reason about their systems. The goal is to build digital “twins” of the experts on how they debug, architect, and maintain these systems in practice.&lt;/p&gt;&lt;p&gt;Together, HyperDocs and HyperTwin form a knowledge graph of legacy systems linking code, systems, and human reasoning.&lt;/p&gt;&lt;p&gt;Here’s a demo video of our HyperTwin product: https://www.youtube.com/watch?v=C-tNtl9Z_jY&lt;/p&gt;&lt;p&gt;You can explore our documentation platform, including examples from the AWS Card Demo (a widely used COBOL codebase example) and a dummy insurance project here: https://hyperdocs-public.onrender.com/.&lt;/p&gt;&lt;p&gt;e.g. Developer perspective docs - High level system architecture of credit card management: https://hyperdocs-public.onrender.com/docs/aws-carddemo-with...&lt;/p&gt;&lt;p&gt;We’re curious to hear your thoughts and feedback, especially from anyone who’s worked with mainframes or tried to modernize legacy systems.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45877517</guid><pubDate>Mon, 10 Nov 2025 16:23:24 +0000</pubDate></item><item><title>The lazy Git UI you didn't know you need</title><link>https://www.bwplotka.dev/2025/lazygit/</link><description>&lt;doc fingerprint="2ebcc050e97f34b3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The (lazy) Git UI You Didn't Know You Need&lt;/head&gt;
    &lt;p&gt;When my son was born last April, I had ambitious learning plans for the upcoming 5w paternity leave. As you can imagine, with two kids, life quickly verified this plan 🙃. I did eventually start some projects. One of the goals (sounding rebellious in the current AI hype cycle) was to learn and use neovim for coding. As a Goland aficionado, I (and my wrist) have always been tempted by no-mouse, OSS, gopls based, highly configurable dev setups.&lt;/p&gt;
    &lt;p&gt;Long story short, I’d still stick to Goland for my professional coding (for now), but during the experiments with &lt;code&gt;nvim&lt;/code&gt;, I accidentally stumbled upon lazygit
Git UI. I literally mistyped &lt;code&gt;&amp;lt;space&amp;gt;gg&lt;/code&gt; instead of &lt;code&gt;gg&lt;/code&gt;, which opened up the built-in &lt;code&gt;lazygit&lt;/code&gt; overlay UI.&lt;/p&gt;
    &lt;p&gt;A week later, I have already switched all my &lt;code&gt;git&lt;/code&gt; workflows to &lt;code&gt;lazygit&lt;/code&gt; (also outside &lt;code&gt;nvim&lt;/code&gt;), and I have been using it since then. In this post, I’d like to explain why it happened so quickly, so:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What makes &lt;code&gt;lazygit&lt;/code&gt;so special?&lt;/item&gt;
      &lt;item&gt;How can it make you more productive?&lt;/item&gt;
      &lt;item&gt;What we can all learn from &lt;code&gt;lazygit&lt;/code&gt;around designing incredible software with seamless UX?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s jump in!&lt;/p&gt;
    &lt;head rend="h2"&gt;Lazy approach to Git tools&lt;/head&gt;
    &lt;p&gt;Likely every developer knows and (in some form) uses the git CLI . It’s relatively simple, and it seems incredibly stable – the only change I noticed in the last decade was the new &lt;code&gt;git switch&lt;/code&gt; command, although I still haven’t “switched” to it from the lovely &lt;code&gt;git checkout&lt;/code&gt;🙃 .&lt;/p&gt;
    &lt;p&gt;As a result, it’s common to see developers memorize a few commands you typically use (e.g.&lt;code&gt;clone&lt;/code&gt;, &lt;code&gt;fetch/pull&lt;/code&gt;, &lt;code&gt;config/remote&lt;/code&gt;, &lt;code&gt;add/rm&lt;/code&gt;, &lt;code&gt;status&lt;/code&gt;, &lt;code&gt;checkout&lt;/code&gt;, &lt;code&gt;commit&lt;/code&gt;, &lt;code&gt;push&lt;/code&gt;, &lt;code&gt;cherry-pick&lt;/code&gt;, &lt;code&gt;rebase&lt;/code&gt;, &lt;code&gt;merge&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;) and stick to the CLI. In fact, in 2022, 83% of the StackOverflow responders said they prefer CLI to other interfaces
and that number is likely still quite high nowadays.&lt;/p&gt;
    &lt;p&gt;However, graphical interfaces and generally other &lt;code&gt;git&lt;/code&gt; compatible clients do exist:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Some of them offer more or less the same &lt;code&gt;git&lt;/code&gt;workflows as the original&lt;code&gt;git&lt;/code&gt;CLI, just more visually appealing and with buttons/interactivity instead of remembering the CLI flags, e.g. git gui , GitHub Desktop or&lt;code&gt;lazygit&lt;/code&gt;discussed here.&lt;/item&gt;
      &lt;item&gt;Other projects add more magic (e.g. AI), and potentially new light abstractions/workflows in an attempt to simplify or enhance &lt;code&gt;git&lt;/code&gt;use e.g. GitKraken .&lt;/item&gt;
      &lt;item&gt;There are even projects like recently popular jj tool that completely abstracts away &lt;code&gt;git&lt;/code&gt;API and replace it with a new source control flows to “simplify” them or unify them across various VCS other than&lt;code&gt;git&lt;/code&gt;(e.g.&lt;code&gt;mercurial&lt;/code&gt;, Google Piper and everything else you wished it was&lt;code&gt;git&lt;/code&gt;, but it’s not 😛).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What you choose for your work is entirely up to you. Depending on what you are passionate about, how you work with &lt;code&gt;git&lt;/code&gt; and what type of software you are touching (monorepo vs small repos, closed vs open source, GitHub vs other hosting solutions, where you deploy, etc.), different clients might be more or less productive for you.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;NOTE: If you’re new to software engineering, don’t skip learning the&lt;/p&gt;&lt;code&gt;git&lt;/code&gt;CLI. Even if you use some higher-level interfaces later on, it will help you understand what they do in the background, plus sooner or later you will end up debugging some remote VM or container with no UI access (e.g. CI systems).&lt;p&gt;Also, as documented in the official&lt;/p&gt;&lt;code&gt;git&lt;/code&gt;documentation, “the command-line is still where you’ll have the most power and control when working with your repositories."&lt;/quote&gt;
    &lt;p&gt;For me, I need something:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;simple and fast to limit the context switch overhead.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;CLI-native to have fewer things that can go wrong.&lt;/item&gt;
      &lt;item&gt;“discoverable” and interactive, as I am bad at remembering keybindings and commands (I need my brain memory for more fun bits).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For those reasons, early in my career, I started depending on a hybrid workflow, with a few GUI tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;git gui instead of &lt;code&gt;status&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;,&lt;code&gt;config/remote&lt;/code&gt;,&lt;code&gt;add/rm&lt;/code&gt;and&lt;code&gt;push&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;gitk instead of &lt;code&gt;log&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;CLI for everything else (e.g. rebasing/complex merging).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I don’t remember why specifically those (AFAIK, decade ago there wasn’t anything else), but I literally have been using them non-stop until this year!&lt;/p&gt;
    &lt;p&gt;A few years ago, because of the 1990-style look of those UIs, lack of active development and modern features, I looked around for some alternatives. I remember I was quickly demotivated when I accidentally lost all my local changes on a single mouse click on the wrong thing in one of the tools 🙈 (starts with &lt;code&gt;G&lt;/code&gt; and ends with &lt;code&gt;N&lt;/code&gt;). After that, I was sceptical I’d find some new tool anytime soon. The arguments to motivate me to make a switch would need to be strong.&lt;/p&gt;
    &lt;p&gt;Turns out, an open mind and a bit of curiosity in a random moment gave more fruit than tailored research. By accident, I noticed &lt;code&gt;lazygit&lt;/code&gt; and after a short try, it became my main &lt;code&gt;git&lt;/code&gt; tool.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s amazing in &lt;code&gt;lazygit&lt;/code&gt;?&lt;/head&gt;
    &lt;p&gt;Somehow, lazygit ticked so many boxes for me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s easy to use; it makes you productive from day 1.&lt;/item&gt;
      &lt;item&gt;It enables you to do more (and faster), even teaching you along the way.&lt;/item&gt;
      &lt;item&gt;It’s a TUI (terminal user interface), making it incredibly fast, portable and visually consistent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Many of the tool’s benefits are also amazing learning on how to build brilliant devtools and software in general.&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;lazygit&lt;/code&gt;used via lazygit IntelliJ plugin on my&lt;code&gt;git&lt;/code&gt;clone of Prometheus project.&lt;/quote&gt;
    &lt;p&gt;Personally, probably the best thing about the &lt;code&gt;lazygit&lt;/code&gt; is its UX, notably how easy it is to use this tool, with just a basic understanding of the &lt;code&gt;git&lt;/code&gt; CLI. Generally, it seems that a nice user experience is achieved due to deliberate choice of strong consistency, deliberate visualizations and interactive menus. Let me explain.&lt;/p&gt;
    &lt;head rend="h3"&gt;Consistency&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; is incredibly well organized and visually consistent. &lt;code&gt;lazygit&lt;/code&gt; TUI consists of a set of boxes (“views”) with consistent behaviour. Most views are generally visible, always, no matter what operation you are doing (unless you zoom in). You always have a focus on one box. It’s visibly clear that some boxes have “tabs”. When you interact with boxes on the left, the right box changes.&lt;/p&gt;
    &lt;p&gt;Then, &lt;code&gt;lazygit&lt;/code&gt; generally sticks to native &lt;code&gt;git&lt;/code&gt; terms and abstractions, which reduces the initial learning curve. In fact, this tool even teaches you about standard, yet a bit more advanced &lt;code&gt;git&lt;/code&gt; operations (e.g. &lt;code&gt;bisect&lt;/code&gt; which I used to do manually) and terms (e.g. TIL &lt;code&gt;hunk&lt;/code&gt;
which is an official &lt;code&gt;git&lt;/code&gt; term for a piece of relevant code).&lt;/p&gt;
    &lt;p&gt;Finally, by default, &lt;code&gt;lazygit&lt;/code&gt; is pretty consistent with the feeling and keybindings of &lt;code&gt;vim&lt;/code&gt;. This means that &lt;code&gt;q&lt;/code&gt; will quit the tool, &lt;code&gt;h/j/k/l&lt;/code&gt; (or arrows) are for navigation, &lt;code&gt;/&lt;/code&gt; for filtering and &lt;code&gt;y&lt;/code&gt; for copy. Then, similar to &lt;code&gt;vim&lt;/code&gt; it attempts to follow the name of the command, e.g. &lt;code&gt;c&lt;/code&gt; commits, &lt;code&gt;a&lt;/code&gt; adds all, &lt;code&gt;A&lt;/code&gt; amends, &lt;code&gt;f&lt;/code&gt; fetches, &lt;code&gt;p&lt;/code&gt; pulls, &lt;code&gt;P&lt;/code&gt; pushes, &lt;code&gt;r&lt;/code&gt; rebases.&lt;/p&gt;
    &lt;p&gt;This is incredibly important as your common workflows can be easily memorized and invoked in a quick set of a few keystrokes (see enhanced workflows ). Now, as I mentioned before, that’s a double-edged sword, because if your brain is lazy like mine, you will end up staring at the &lt;code&gt;vim/nvim&lt;/code&gt; view trying to remember what the command was to select and copy things (or quit vim
).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; solves the above with a limited set of commands (that’s a good thing: do one thing and do it well
) and great “discoverability”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Discoverability&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; strikes an amazing balance of showing data you need when you need it. When you open this tool, it’s obvious you want to do some &lt;code&gt;git&lt;/code&gt; trickery, so it’s likely a good thing to give you all you need to know, in a pill:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What repo is this.&lt;/item&gt;
      &lt;item&gt;All staged and unstaged files with changes (&lt;code&gt;git status&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;What branch are you on.&lt;/item&gt;
      &lt;item&gt;The top ~10 commits on this branch.&lt;/item&gt;
      &lt;item&gt;Top stash item.&lt;/item&gt;
      &lt;item&gt;Last git commands you performed.&lt;/item&gt;
      &lt;item&gt;Core actions/commands you can do with their keybindings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s a lot of data! Yet &lt;code&gt;lazygit&lt;/code&gt; somehow manages to show you all of this without visually overwhelming you:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consistent and self-explanatory views with a flat action menu allow you to find the data you need when you need it quickly.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This context is game-changing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you never used this tool, or if you had spent one month doing meetings, reviews and design docs at work, and you return to coding finally, you immediately know where you are and where things are.&lt;/item&gt;
      &lt;item&gt;It reduces the risk of surprises and mistakes (&lt;code&gt;"ups! I pushed to main directly sorry!"&lt;/code&gt;), saving you a solid amount of&lt;code&gt;SWEh&lt;/code&gt;(software engineering hours) monthly.&lt;/item&gt;
      &lt;item&gt;Normally to double-check those things you would need to run multiple commands and check different windows. &lt;code&gt;lazygit&lt;/code&gt;immediately removes that context switching.&lt;/item&gt;
      &lt;item&gt;Even if you forget important keybindings for actions, it’s quick to check them on the footer or with &lt;code&gt;?&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But there’s more, &lt;code&gt;lazygit&lt;/code&gt; guides you on all operations with interactivity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interactivity&lt;/head&gt;
    &lt;p&gt;In other UI tools, you have hundreds of buttons, with multiple layers of nested menus. &lt;code&gt;lazygit&lt;/code&gt; has a different approach. This tool teaches you on the way, what’s possible and when. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Push will give you a warning of divergence with upstream if any. Clicking &lt;code&gt;Enter&lt;/code&gt;will do&lt;code&gt;--force&lt;/code&gt;push,&lt;code&gt;Esc&lt;/code&gt;will cancel.&lt;/item&gt;
      &lt;item&gt;Rebase will ask you, if you want the interactive one or not and double-check the branch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Interactive rebase is much more guided and interactive, than &lt;code&gt;git rebase --interactive&lt;/code&gt;. No need to manually type and remember special words (e.g.&lt;code&gt;pick/drop/squash&lt;/code&gt;or&lt;code&gt;p/d/s&lt;/code&gt;). The&lt;code&gt;&amp;lt;c-j&amp;gt;&lt;/code&gt;,&lt;code&gt;&amp;lt;c-k&amp;gt;&lt;/code&gt;keys also quickly move commits up and down (reordering).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Git conflicts after rebase will be highlighted. After you fix them &lt;code&gt;lazygit&lt;/code&gt;automatically will ask you if you want to commit them and auto continue the rebase.&lt;/item&gt;
      &lt;item&gt;When switching branches with conflicting changes, &lt;code&gt;lazygit&lt;/code&gt;will automatically ask you if you want to auto-stash those changes etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Generally, &lt;code&gt;lazygit&lt;/code&gt; guides you in your workflows with minimal distractions and guesswork. This builds trust very quickly, allowing adoption of faster workflows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced git workflows&lt;/head&gt;
    &lt;p&gt;Eventually, &lt;code&gt;lazygit&lt;/code&gt; boosted productivity around git workflows for me and for many other existing happy users.&lt;/p&gt;
    &lt;p&gt;What’s impressive is that &lt;code&gt;lazygit&lt;/code&gt; does it without adding entirely new workflows. Instead, it makes what &lt;code&gt;git&lt;/code&gt; CLI offers much more usable, safer, quicker and discoverable. It teaches you better patterns.&lt;/p&gt;
    &lt;p&gt;One example is highlighted with custom patching. Imagine you made some changes, committed them, but then you want to bring back a few lines (but not all) to what it was before, from an earlier commit. My previous flow used to be either:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local IDE history (slow-ish, too much granularity (every file save), not always available).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git gui&lt;/code&gt;tool I clicked&lt;code&gt;amend&lt;/code&gt;which would pull all changed files from that commit to&lt;code&gt;staged&lt;/code&gt;area, then I find lines I want, manually copy them (with those git diff&lt;code&gt;+&lt;/code&gt;and&lt;code&gt;-&lt;/code&gt;chars!) and paste to IDE, then trim unwanted chars. Pretty horrible habit (:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When using &lt;code&gt;lazygit&lt;/code&gt;, I obviously tried to replicate my broken workflow. I couldn’t because &lt;code&gt;lazygit&lt;/code&gt; diffs are not intuitively select+copy-able (it might be fixable over time; not the highest priority, but people want this e.g. 1
, 2
). I even +1 one some issue around it
, and I’m glad I did, because the maintainer pointed me to… 10x simpler workflow: native reset/patch per line/hunk flow!&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;All git diffs in&lt;/p&gt;&lt;code&gt;lazygit&lt;/code&gt;(no matter if unstaged/staged/stashed/committed changes) support per line or hunk selection and patching/selection.&lt;/quote&gt;
    &lt;p&gt;With this, my “line reset from the last commit” workflow is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;simpler&lt;/item&gt;
      &lt;item&gt;within a single place&lt;/item&gt;
      &lt;item&gt;works for any commit (not only the latest)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Steps in &lt;code&gt;lazygit&lt;/code&gt;: focus on commits view &amp;gt; select commit &amp;gt; select file &amp;gt; select lines to reset &amp;gt; patch options &amp;gt; “remove patch from the original commit”. All either mouse-assisted or &lt;code&gt;4 enter enter space &amp;lt;c-p&amp;gt; d&lt;/code&gt; within seconds.&lt;/p&gt;
    &lt;p&gt;Those short key bindings are game changers in general. I’d recommend starting with a slower, but careful mouse-assisted flow, then naturally you memorize the needed keystrokes without noticing. For me, after some time, some quick flows became a habit, I was using shortcuts unconsciously.&lt;/p&gt;
    &lt;p&gt;As a result, my common &lt;code&gt;git&lt;/code&gt; flows, with &lt;code&gt;lazygit&lt;/code&gt;, were significantly improved:&lt;/p&gt;
    &lt;head rend="h5"&gt;Iterating on changes and updating upstream:&lt;/head&gt;
    &lt;p&gt;My typical flow to ensure clean commit log:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select files to commit &amp;gt; add to the last commit (amend) &amp;gt; force push&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;2 space A P enter&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Iterating on changes and updating upstream with a new commit:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select files to commit &amp;gt; create new commit &amp;gt; push&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;2 space c &amp;lt;type commit title&amp;gt; P&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Syncing branches&lt;/head&gt;
    &lt;p&gt;I generally do an interactive rebase for this. I avoid merges, unless squashed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select branch &amp;gt; rebase &amp;gt; interactive rebase &amp;gt; arrange commits &amp;gt; rebase options &amp;gt; continue&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;3 r i &amp;lt;s/p/d/.. to arrange rebase&amp;gt; m c&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Removing unwanted commit from history&lt;/head&gt;
    &lt;p&gt;Normally you would need to do full interactive rebase against &lt;code&gt;HEAD~4&lt;/code&gt; or something, but now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; drop&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 d&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Removing unwanted file changes from commits&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; select file &amp;gt; remove&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 enter d&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Splitting commit into multiple PRs/commits&lt;/head&gt;
    &lt;p&gt;This is normally a bit painful, but now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; select file &amp;gt; select lines or hunks &amp;gt; patch options &amp;gt; move patch into new commit after the original commit &amp;gt; create new commit&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 enter enter &amp;lt;c-p&amp;gt; n &amp;lt;type commit title&amp;gt; enter&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Cherry-pick&lt;/head&gt;
    &lt;p&gt;Typically, it meant copying commit SHAs around; prone to errors. Now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select branch &amp;gt; select commit &amp;gt; copy for cherry-pick (you can buffer many) &amp;gt; select target branch &amp;gt; go to commits &amp;gt; paste&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;3 4 C 3 4 V&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;…and many more!&lt;/p&gt;
    &lt;head rend="h2"&gt;What can we learn?&lt;/head&gt;
    &lt;p&gt;To me, &lt;code&gt;lazygit&lt;/code&gt; is not only an amazing tool for everyday use, but also an inspiration around devtools UX. The simplicity, consistency, discoverability, sane defaults, shortcuts for common flows and interactivity
should be on the radar for anyone who builds devtools. Not mentioning deep configurability
, a healthy dose of extensibility
, being fully free (donations possible!
), a healthy OSS situation
and… tool being written 100% in Go! (:&lt;/p&gt;
    &lt;p&gt;Imagine what other tools we could write, reusing similar patterns or even similar UX! TUI framework and &lt;code&gt;lazygit&lt;/code&gt; code is fully OSS (MIT)
, so anyone has a healthy base for building different tools. I do have ideas for a few tools, especially around some extremely manual release workflows in our ecosystems. Let’s collaborate! 💪&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Hope this write-up was useful for you!&lt;/p&gt;
    &lt;p&gt;Even with the current advancement in GenAI, statistical aspect of LLMs makes them not a great fit for reliable and accurate version control changes that projects and systems have to rely on. Some LLM assist (e.g. generating commit messages) will eventually come to &lt;code&gt;lazygit&lt;/code&gt; and git tooling, but the core of &lt;code&gt;lazygit&lt;/code&gt; is to remain incredibly relevant for the (increasingly AI-assisted) software development cycles.&lt;/p&gt;
    &lt;p&gt;Kudos to all maintainers, contributors and sponsors of &lt;code&gt;lazygit&lt;/code&gt; for an amazing work!&lt;/p&gt;
    &lt;p&gt;Feel free to comment, give feedback AND use and contribute to the &lt;code&gt;lazygit&lt;/code&gt; project! Happy coding!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45878578</guid><pubDate>Mon, 10 Nov 2025 17:50:21 +0000</pubDate></item><item><title>Omnilingual ASR: Advancing automatic speech recognition for 1600 languages</title><link>https://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition/?_fb_noscript=1</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45878826</guid><pubDate>Mon, 10 Nov 2025 18:10:12 +0000</pubDate></item><item><title>Memory Safety for Skeptics</title><link>https://queue.acm.org/detail.cfm?id=3773095</link><description>&lt;doc fingerprint="aa6ad993b82396c8"&gt;
  &lt;main&gt;
    &lt;p&gt;Memory safety—the property that makes software devoid of weaknesses such as buffer overflows, double-frees, and similar issues—has been a popular topic in software communities over the past decade and has gained special prominence alongside the rise of the Rust programming language. Rust did not invent the idea of memory safety, nor was it the first memory-safe language, but it did break the dam on the last major holdout context where memory safety had not yet been achieved: what we often call "systems programming."&lt;/p&gt;
    &lt;p&gt;Rust's big step function was to offer memory safety at compile time through the use of static analysis borrowed and grown out of prior efforts such as Cyclone, a research programming language formulated as a safe subset of C. Rust, by offering a memory-safe-by-default experience for the "systems" domain, where operating systems, databases, file systems, embedded software, and the like are made, suddenly presented a new possibility to public policymakers and to leaders of engineering organizations: the mass reduction of memory unsafety across any domain.&lt;/p&gt;
    &lt;p&gt;In the years since Rust hit the scene, tech companies have published experience reports on the adoption of Rust for production systems, whether through rewrites of existing code or by producing new modules in Rust that might have otherwise been written in C or C++. The numbers were broadly consistent: a roughly 70 percent reduction in memory-safety vulnerabilities. Rust, more than just promising memory safety, was demonstrably translating safety guarantees into practical improvements in software security. This evidence, turning the abstract benefits of a semantic improvement into bottom-line improvements in business costs (vulnerabilities are expensive for all involved), meant that organizations beyond just engineering groups began to take notice.&lt;/p&gt;
    &lt;p&gt;Of course, the choice of programming language is a contentious one. Languages do not exist in a vacuum, and the "right" language for a job is heavily path dependent. What languages do the developers already know? What's the timeline and budget for the project? How serious are the correctness constraints? The performance constraints? Do you expect to hire more developers, and what resources can you allocate to train them? If you're an open-source project, you might ask which languages would possibly bring in more developers to contribute. For any project, your answer might be determined by what other libraries or tools you will need to integrate.&lt;/p&gt;
    &lt;p&gt;What's more, many projects have already made their programming-language decision years ago—possibly decades ago. What should they do? If the code you have today is memory unsafe, in C or C++, how can you pursue safety without throwing the whole thing out?&lt;/p&gt;
    &lt;p&gt;In some circles, the answer given might be to "rewrite it in Rust" to replace legacy software written in memory-unsafe languages with new Rust equivalents. The benefits, supporters argue, are clear: comparable performance, modern tooling, and memory safety.&lt;/p&gt;
    &lt;p&gt;Yet, experienced developers know rewrites are expensive and frequently misguided . Often, demands for large-scale rewrites are not a carefully reasoned argument about tradeoffs, but an aesthetic criticism of code that looks "ugly" or "too old." If anything, those calling for mass rewrites show their own inability to do the difficult work of understanding and working with an existing codebase that does a job and does it well.&lt;/p&gt;
    &lt;p&gt;There are paths between accepting memory unsafety as the cost of doing business or performing a mass rewriting of stable systems in a new language to achieve safety. Reflexive rejection of a move to memory safety is misguided, especially when the benefits of memory safety can be achieved in a cost- and schedule-efficient way.&lt;/p&gt;
    &lt;p&gt;If you're not yet sold on the value of memory safety, this article is for you. The goal in writing it is to treat the question of pursuing memory safety in legacy systems with the seriousness and rigor that it deserves.&lt;/p&gt;
    &lt;p&gt;Pursuing memory safety is worthwhile, with or without Rust, and I'd like to convince you to try.&lt;/p&gt;
    &lt;p&gt;Software systems do not exist in isolation; software is built to do things, to serve the needs of businesses and individuals by making systems more efficient or automatic. The development of software is constrained not by the theoretical limits of software's abilities, but by the cost and schedule limitations of the team building it.&lt;/p&gt;
    &lt;p&gt;In "The Case for Memory Safe Roadmaps," a collection of government agencies from the "Five Eyes Countries" (the United States, United Kingdom, Australia, New Zealand, and Canada) collectively recommended that organizations develop roadmaps for transitioning their software development efforts to memory-safe languages.&lt;/p&gt;
    &lt;p&gt;It's worth being clear here: Their focus is on roadmaps, and they very explicitly accept and discuss the challenge of the cost and schedule impacts of any transition toward memory safety.&lt;/p&gt;
    &lt;p&gt;Budget and schedule constraints and the desire for efficiency are part of what motivates the creation of software in the first place. Once that software is in place, it's frequently mission critical, having replaced the knowledge and labor of people who would have previously done the jobs the software now performs. Instead of accountants, a company may have accounting software, with a smaller number of accountants who know how to interact with the software and use it to perform their own jobs built on the knowledge the software provides with its data and embedded business logic.&lt;/p&gt;
    &lt;p&gt;Rewrites to critical software systems are risky precisely because the software itself is so important. Rewriting a software system, whether as an in-place rewrite where components are swapped out piece by piece, or as a wholesale rewrite with a cutover date, risks the proper functioning of the business if the rewrite fails .&lt;/p&gt;
    &lt;p&gt;Complex, long-running software systems can face other severe constraints as well. They may be unable to be turned off—because, having become so business critical and time sensitive, any attempt to bring them offline for maintenance or replacement is unacceptable. They may also have become lost artifacts, where the expertise of the individuals who created them or previously worked on them is lost because it wasn't transferred to newer engineers, resulting in a current team that does not understand the system or feel comfortable making changes to it.&lt;/p&gt;
    &lt;p&gt;There are also ongoing costs associated with the development of software that might have to be diverted to support even an incremental rewrite. Depending on the business, there might not be funding available to support an increase to the development team, so diversion of resources toward a rewrite would mean reduction in the delivery of features for the project, which may be untenable.&lt;/p&gt;
    &lt;p&gt;All of this is to say that rewrites, even incremental ones, are business decisions that have to be made as tradeoffs with other strategic goals. While motivated developers can make the best case possible for the upside of a rewrite, they must also grapple with the businesses' needs to deliver features and address bugs impacting users of the system today.&lt;/p&gt;
    &lt;p&gt;At the same time, a transition to memory-safe languages can bring benefits beyond just the safety (and thereby security) claims that are often given priority in these discussions.&lt;/p&gt;
    &lt;p&gt;Memory-safety violations, such as null pointer dereferences or indexing outside of the bounds of a memory buffer, can result in denial of service (or, in the context of the classic security CIA triad, availability failures) of the relevant software. This might mean on-call pages to respond to a production incident, a failure to meet service-level agreement guarantees for customers, or reduced revenue from lost customers or interruption of business operations.&lt;/p&gt;
    &lt;p&gt;Memory-safety issues are also often a central building block in a kill chain for achieving remote code execution by attackers. Even as far back as "Smashing the Stack for Fun and Profit" in 1996, we could see cybersecurity professionals documenting how to turn a buffer-overflow weakness into remote code execution and full access to the host. With that foothold in place, attackers can begin to exfiltrate data, move laterally within a network, escalate privileges, lock down a system with ransomware, conscript a host into a botnet, and more.&lt;/p&gt;
    &lt;p&gt;Software problems are cheaper to fix the earlier they occur in the software development lifecycle. In the long term, stopping a bug from being written is cheaper than responding to a bug bounty submission or triaging a production outage.&lt;/p&gt;
    &lt;p&gt;This is not to say that all moves toward memory safety are cost effective or that all roadmaps for memory safety should be as aggressive as possible, but it is intended to make clear that there are both costs and savings to be had with any transition to memory safety.&lt;/p&gt;
    &lt;p&gt;What is memory safety? There should be a table-stakes answer to that question to have in hand amid the push toward memory safety in public discourse, but there is not a single, fully agreed-upon, and rigorous definition. There is a new effort, announced in a recent article published in Communications of the ACM, to develop a standard definition of memory safety, but it is just beginning.&lt;/p&gt;
    &lt;p&gt;There is, however, a rough consensus among practitioners of what kinds of program behaviors are memory unsafe. That's a good place to start.&lt;/p&gt;
    &lt;p&gt;My favorite short definition comes from Michael Hicks, an academic who works on programming languages:&lt;/p&gt;
    &lt;p&gt;"[A] program execution is memory safe so long as a particular list of bad things, called memory-access errors, never occur:&lt;/p&gt;
    &lt;p&gt;• Buffer overflow&lt;/p&gt;
    &lt;p&gt;• Null pointer dereference&lt;/p&gt;
    &lt;p&gt;• Use after free&lt;/p&gt;
    &lt;p&gt;• Use of uninitialized memory&lt;/p&gt;
    &lt;p&gt;• Illegal free (of an already freed pointer, or a non-&lt;code&gt;malloc&lt;/code&gt;-ed pointer)"&lt;/p&gt;
    &lt;p&gt;You will sometimes see these categories broken down further, into spatial and temporal memory safety. Spatial covers memory-safety issues arising from accessing locations in memory that a program should not have access to (like a buffer overflow); temporal covers operations on memory done in the wrong order: for example, reading memory before it is initialized, trying to free an already freed pointer, or using a pointer after it has been freed.&lt;/p&gt;
    &lt;p&gt;There's also the CWE (Common Weakness Enumeration) category for memory-safety issues, which decomposes Hicks's list into more granular options. CWE is a taxonomy of software weaknesses, or as CWE puts it: "condition[s] in... software... that, under certain circumstances, could contribute to the introduction of vulnerabilities."&lt;/p&gt;
    &lt;p&gt;In CWE's memory-safety category, "buffer overflow" is further broken down into six different, more-specific weaknesses, some of which are further decomposed into their own variants. This can be useful when maximum precision is warranted but is perhaps too much detail for the purposes of this article.&lt;/p&gt;
    &lt;p&gt;These definitions provide a reasonably clear picture of what constitutes memory unsafety. So, memory safety is when a program is guaranteed not to have those weaknesses. This can be achieved by compile-time constraints on the semantics of programs or by runtime management of memory by a garbage collector, so long as the guarantee is upheld.&lt;/p&gt;
    &lt;p&gt;This is often when perceptive onlookers will cry foul. Rust permits unsafety! There's a whole unsafe keyword! How is that meaningfully different from the guarantees of C or C++?&lt;/p&gt;
    &lt;p&gt;Of course, they're right. Rust does permit programmers to write unsafe code, but as anyone who works in safety or security will tell you, defaults matter. In fact, defaults matter a lot!&lt;/p&gt;
    &lt;p&gt;Let's use seat belts as an example. Seat belts became generally mandatory across the United States between the late 1980s to the early 1990s. In 1985, when mandatory seatbelt laws first saw passage among the states, seatbelt usage sat at 21 percent of riders. In 1994, the average seatbelt usage rate in the U.S. was 58 percent. As of 2017, it was 89.7 percent. That change in defaults led to massive increases in seatbelt usage and therefore saved more lives. The National Highway Transportation and Safety Administration estimates that in 2017 alone, seatbelts saved the lives of nearly 15,000 Americans.&lt;/p&gt;
    &lt;p&gt;The same truth applies in software. Before version 4.0.0 (published in 2017), Redis, the extremely popular key-value store, offered no access controls in its default configuration. Frequently, new users of Redis would unintentionally expose their instance publicly, and this insecurity would result in data spills or become a vector for host exploitation. As of version 4.0.0, Redis enters a "protected mode" when run with its default configuration and without password protection. This limits access to loopback interfaces. As the Redis company itself has since touted, the introduction of protected mode has caused the number of publicly accessible Redis instances tracked on Shodan.io, a popular internet host aggregator, to decline substantially. In 2017, it had identified roughly 17,000 exposed Redis instances; in 2020, that number had declined to 8,000 in an audit by security company TrendMicro.&lt;/p&gt;
    &lt;p&gt;Bringing it back to memory safety, we can and should think of memory-safety guarantees by languages as a continuum, and we can split languages between "memory safe by default" and "non-memory safe by default" groups. This framing, recommended by the OpenSSF's (Open Source Security Foundation's) Memory Safety SIG (Special Interest Group), makes the options clearer:&lt;/p&gt;
    &lt;p&gt;• Using memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;• Using memory-safe-by-default languages to interface with non-memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;• Using non-memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;Here, memory-safe-by-default languages include not only Rust, but also common garbage-collected languages such as Java, C#, Go, Swift, Python, Ruby, and more. Non-memory-safe-by-default languages include C and C++ most notably, but also Zig, which may be surprising to those who have watched memory-safety discussions from the sidelines.&lt;/p&gt;
    &lt;p&gt;While Zig does provide more ergonomic options for programmers to write memory safe programs themselves, Zig is not a memory-safe language, because it does not guarantee memory safety even in its most conservative configuration. Jamie Brandon's breakdown of Zig's memory safety is a good walkthrough of why Zig's guarantees are insufficient.&lt;/p&gt;
    &lt;p&gt;With a shared understanding of memory safety and memory-safe languages, let's now dig into the concrete strategies for pursuing memory safety in real-world programs.&lt;/p&gt;
    &lt;p&gt;Any of the following strategies are intended to maximize the benefit of memory safety while minimizing the cost of pursuing it. The specific choice of which approach is right is context dependent and should be made with consideration of the importance of the component, the current and new target language, the team involved, and the timetable.&lt;/p&gt;
    &lt;p&gt;The first and most obvious option is to make new code memory safe—that is, to write new components in a memory-safe language. While this seems simple, you must address certain caveats to make this approach successful.&lt;/p&gt;
    &lt;p&gt;First, you are unlikely to reap the benefits of memory safety if you try introducing memory-safe code alongside new memory-unsafe code. Think of it this way: In a fixed codebase that you continue to assure (via testing, code review, bug bounties, and more), the density of vulnerabilities decreases exponentially over time. As vulnerabilities become less and less dense in the codebase, the rate of new vulnerability discoveries also decreases, and so the overall assurance level of the code increases. The riskiest thing you can do to a codebase is change it. In the case of memory-unsafe languages, that change can induce memory-safety vulnerabilities.&lt;/p&gt;
    &lt;p&gt;The Google Chrome and Android teams have published extensively about their experiences incentivizing a move to memory-safe languages in their codebases. They instituted a rule called the "Rule of Two," where all new code must be either sandboxed or in a memory-safe language. In practice, because sandboxing is difficult, this naturally gave developers incentive to pursue memory safety in most cases.&lt;/p&gt;
    &lt;p&gt;Surprisingly to the team, they reaped the benefits of this new policy across the entire codebase—even the parts that weren't rewritten. Because they had certain assurances about the new code inherent in the safety mechanisms it came with, they could focus assurance efforts on old code, which was now static. Through this, they not only reduced the overall rate of memory-safety vulnerabilities in the codebase, but also decreased the prevalence of vulnerabilities overall.&lt;/p&gt;
    &lt;p&gt;Sometimes, rewriting code in a memory-safe language can be the right choice, but this is often a path to pursue only once you fully understand the challenges faced by the current memory-unsafe code.&lt;/p&gt;
    &lt;p&gt;Early in its history, the development of Rust was funded by Mozilla, makers of the Firefox web browser, and the flagship Rust project besides Rust's own compiler was the Servo web-rendering engine. Despite this, the first actual Rust code that Mozilla integrated into Firefox was not Servo; it was an MP4 video file parser. They replaced the existing C++ parser with one written in Rust, moving from a memory-unsafe language to a memory-safe language, because it had long been a source of vulnerabilities. Firefox needs to parse MP4 files from untrusted sources, and failures to correctly handle that parsing could be dire. For Mozilla, it was a small but security-critical surface area that made sense to target for a rewrite.&lt;/p&gt;
    &lt;p&gt;Another helpful tool for targeting is Kelly Shortridge's SUX Rule: target code that is Sandbox free, Unsafe, and eXogenous. This means you should prioritize rewriting code that processes untrusted (exogenous) input, runs without a sandbox, and is written in a memory-unsafe language. Reviewing your own codebase for these areas can be a fast way to identify critical paths with high risk of exploitation in the presence of memory-safety vulnerabilities.&lt;/p&gt;
    &lt;p&gt;When fully rewriting existing memory-unsafe code to a memory-safe language is not feasible, it might instead make sense to wrap it in a memory-safe interface. This does still lay the burden of ensuring safety properties on the programmer, both for the original code in the memory-unsafe language and for the correctness of the interface, but it then permits building safe and trusted new code on top of the old code. If you continue to work to assure the old code with techniques such as fuzz testing, analysis by sanitizers, or formal modeling, you can gain increased confidence in the latent unsafe code being wrapped.&lt;/p&gt;
    &lt;p&gt;This is in fact how many of the Rust standard library's common container types are written. Under the hood, they contain unsafe code to manage buffers and pointers in a way that is as efficient as possible, but the interface provided to the user does not give access to any materials (buffers, pointers, lengths) that would permit the user to violate memory-safety guarantees.&lt;/p&gt;
    &lt;p&gt;This "wrapping" approach helps constrain the "blast radius" of memory-unsafe code that can't feasibly be removed or replaced and constrains the auditing scope and assurance costs of that code as well.&lt;/p&gt;
    &lt;p&gt;There is a common reply in conversations about memory safety, coming from the most hardcore skeptics: Programmers should just write better code. They argue, explicitly or implicitly, that programmers who benefit from the guardrails of memory safety are bad programmers, and that real programmers are sufficiently skilled that they do not need a machine double-checking their work.&lt;/p&gt;
    &lt;p&gt;Let's be clear: This is anti-intellectual nonsense—macho self-aggrandizement masquerading as a serious technical argument. You should not take it seriously and should consider someone advancing this argument as fundamentally unserious and to be ignored.&lt;/p&gt;
    &lt;p&gt;There is no step function in quality of work in the history of human achievement that happened because people one day woke up and decided to be better at their jobs. Improvements in productivity or quality or reductions in error and harm happen because of the invention of new techniques, processes, and tools.&lt;/p&gt;
    &lt;p&gt;Reductions in traffic fatalities in the 1980s and 1990s didn't happen because drivers suddenly got better at driving; they happened because states enacted mandatory seat-belt laws.&lt;/p&gt;
    &lt;p&gt;While individuals can become more skilled at their jobs, working faster or producing fewer errors, large groups of people generally don't do so without some force that works to provide incentive or enable that change. Even when improvements are nontechnical, they come from enhancements to process or incentives for behavior. Over the past several decades, hospitals, for example, have reduced in-hospital mistakes because of increased use of standard checklists and provisioning of common materials needed for emergencies in crash carts.&lt;/p&gt;
    &lt;p&gt;Programmers who argue against memory safety by arguing for mass self-improvement are posing an impossible future as an alternative against a credible opportunity for improvements in software safety and security. While there are credible case-specific arguments against individual paths to memory safety, they do not include sudden mass improvement of skill and quality across the industry. It's important to make this clear.&lt;/p&gt;
    &lt;p&gt;One specter of the conversations around memory safety is whether the use of memory-unsafe languages will become generally unacceptable, either through formal government regulation or a rise in common requirements for software purchasing.&lt;/p&gt;
    &lt;p&gt;Today no agency, either in the U.S. or outside of it, regulates against the use of languages that are non-memory safe by default. Nor are there purchasing requirements in place calling for the use of memory-safe-by-default languages or even the presence of memory-safety roadmaps, at least for governments.&lt;/p&gt;
    &lt;p&gt;The Five Eyes report mentioned previously, "The Case for Memory Safe Roadmaps," recommends that organizations establish roadmaps for the pursuit of memory safety, but this is nonregulatory, and no amendments have been made to federal software acquisition policy to require such a roadmap in the U.S. or elsewhere. The U.S. is not outlawing C or C++. While these agencies have recommended moving away from these languages for future software development, they have not recommended indiscriminate mass rewrites of existing code.&lt;/p&gt;
    &lt;p&gt;Also note that the processes for establishing regulation or requirements would face challenges and, whether successful or not, would be slow to take effect and offer ample time for feedback and consideration.&lt;/p&gt;
    &lt;p&gt;First, regarding the prospect of regulation around memory safety in the U.S., such regulation would need to be pursued by a relevant agency that can establish a relevant jurisdiction. With the end of Chevron deference in U.S. law, a requirement that judges defer to U.S. regulatory agencies' determinations in most cases that was abolished in 2024 by the U.S. Supreme Court in Loper Bright Enterprises v. Raimondo, this pursuit of memory-safety regulation would also likely need to be explicitly backstopped by Congressional mandate to ensure it survived legal challenges where judges may overrule agency rulemaking.&lt;/p&gt;
    &lt;p&gt;Second, regarding acquisition requirements (the federal government's term for the rules around purchasing done by the government), the FAR (Federal Acquisition Regulation) would need to be updated to incorporate requirements for memory safety. For reference, in 2020 President Biden signed Executive Order 14028, which included a request that federal agencies pursue an amendment to the FAR to require inclusion of an SBOM (software bill of materials) for all software purchased by the federal government. To date, those changes have not been made, and no such requirement is in place within the FAR.&lt;/p&gt;
    &lt;p&gt;This is not to say that regulation or future federal purchasing requirements are impossible, but simply to point out that none are in place today, and any such changes would take time to be enacted and implemented.&lt;/p&gt;
    &lt;p&gt;The U.S. government's role around memory safety has so far been to act as cheerleader and promoter of the idea, including with the Office of the National Cyber Director's report, "Future Software Should Be Memory Safe;" CISA (Cybersecurity and Infrastructure Security Agency) et. al.'s "Case for Memory Safe Roadmaps;" and CISA's inclusion of memory-safety recommendations within its Secure by Design effort to collaborate with industry on improving software security.&lt;/p&gt;
    &lt;p&gt;Even without government mandate, many organizations in the tech industry have publicly stated their support for pursuing memory safety. In 2023, the Office of the National Cyber Director put out an RFI (request for information) seeking advice from the public on how best to support improving the security of open-source software. That RFI included an interest in the possibility of promoting adoption of memory-safe languages in open source.&lt;/p&gt;
    &lt;p&gt;Respondents to the RFI, which includes a number of universities, think tanks, corporations, and individuals, overwhelmingly supported a move toward memory safety. Few espoused a hardline goal of rewriting all existing code from non-memory-safe languages, but many did recognize the value of pursuing memory safety in new code, and in rewriting critical components in security-sensitive contexts when possible.&lt;/p&gt;
    &lt;p&gt;Some companies, most notably Google, have been especially vocal about their experiences with the value of memory safety. To them, the promise of memory safety is a reduction in security-related costs for long-term products such as the Google Chrome web browser or the Android operating system. By reducing memory-safety vulnerabilities at the source, they shift vulnerability costs left in the software development life cycle; the cost of catching a bug during development and stopping it from being shipped at all is orders of magnitude cheaper than the cost of receiving a security report, perhaps paying out a bug bounty, and then coordinating, preparing, and releasing a patch.&lt;/p&gt;
    &lt;p&gt;In some corners there has been a paranoia and fear that recommendations around memory safety from the U.S. government and others portend some forced end to C or C++. Bjarne Stroustrup, originator of C++ and continued major participant in the ISO Working Group that maintains the C++ specification, has recently begun to sound alarm bells in papers and speeches about the existential threat posed to C++ by failing to address the demands for memory safety, with clear reference to the possibility that software written in non-memory-safe-by-default languages may be disallowed or become practically untenable to market and sell in the future.&lt;/p&gt;
    &lt;p&gt;This fear is simultaneously overblown and correct. It is overblown to suggest the U.S. or any other government is close to outlawing C or C++, but it is correct to note that the benefits of memory safety are becoming clearer with each case study performed at scale and that we should expect natural incentives to slowly accrue larger use and developer interest in memory-safe languages over non-memory-safe languages. C and C++ won't die, but they will likely decline and become legacy languages like Cobol or Ada. They will still sustain some degree of interest and community, and a smaller number of developers will likely continue to be able to make their careers as developers in these languages, but they will be languages that present developers with fewer labor-market opportunities in the future and are unlikely to ascend in popularity and use again without substantial changes to address these safety deficiencies.&lt;/p&gt;
    &lt;p&gt;Memory-safe languages present the clearest opportunity today to substantially improve software security. While memory safety does not eliminate all classes of software weaknesses, it does eliminate a particularly pernicious class that leads to disproportionately severe vulnerabilities. While there are other techniques for addressing these kinds of weaknesses (for example, hardware-based approaches such as CHERI), they are less mature and generally more difficult to adopt at scale.&lt;/p&gt;
    &lt;p&gt;The state of possibility with memory safety today is similar to the state of automobile safety just prior to the widespread adoption of mandatory seat-belt laws. As car manufacturers began to integrate seat belts as a standard feature across their model lines and states began to require that drivers wear seat belts while driving, the rate of traffic fatalities and severity of traffic-related injuries dropped drastically. Seat belts did not solve automobile safety, but they credibly improved it, and at remarkably low cost.&lt;/p&gt;
    &lt;p&gt;The same can be done with memory safety. There is an opportunity to make substantial inroads at addressing a serious class of vulnerabilities while also, long-term, saving money on the development and operation of software systems. Memory safety is not a silver bullet, but it is a credible and cost-effective assurance technique that we as an industry should pursue aggressively. We do not need to wait for regulation to catch up; it is in our best interests to act today.&lt;/p&gt;
    &lt;p&gt;Thank you to Steve Klabnik, engineer at Oxide Computer Company and former member of the Rust Core Team, and to Michael Chernicoff, senior software engineer at MITRE, for reviewing this article and providing feedback prepublication.&lt;/p&gt;
    &lt;p&gt;Andrew Lilley Brinker is a principal engineer at MITRE, where he works on software security. He contributes to the CVE Quality Working Group, serves on the OmniBOR Core Team, and leads development of Hipcheck. He lives in southern California with his wife and two dogs.&lt;/p&gt;
    &lt;p&gt;Copyright © 2025 held by author. Publication rights licensed to ACM.&lt;/p&gt;
    &lt;p&gt;Approved for Public Release; Distribution Unlimited. Public Release Case Number 25–1514. The author's affiliation with The MITRE Corporation is provided for identification purposes only and is not intended to convey or imply MITRE's concurrence with, or support for, the positions, opinions, or viewpoints expressed by the author.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Originally published in Queue vol. 23, no. 5— &lt;lb/&gt; Comment on this article in the ACM Digital Library &lt;/p&gt;
    &lt;p&gt; Jeff Vander Stoep, Alex Rebert, Lars Bergstrom - A Practical Guide to Transitioning to Memory-Safe Languages &lt;lb/&gt; Traditional approaches to memory safety have often amounted to best-effort defect discovery after the fact, and sometimes more advanced strategies focused on threat modeling: identifying critical code, applying interventions, and repeating the cycle as the codebase evolves. While this approach is a valuable part of a defense-in-depth strategy, it is fundamentally flawed as a primary strategy. It traps teams in a reactive and never-ending cycle of treating symptoms with solutions empirically shown to be insufficiently complete without ever addressing the underlying cause. &lt;/p&gt;
    &lt;p&gt; Louis Dionne, Alex Rebert, Max Shavrick, Konstantin Varlamov - Practical Security in Production &lt;lb/&gt; The challenge of improving the memory safety of the vast landscape of existing C++ code demands pragmatic solutions. Standard library hardening represents a powerful and practical approach, directly addressing common sources of spatial safety vulnerabilities within the foundational components used by nearly all C++ developers. Our collective experience at Apple and Google demonstrates that significant safety gains are achievable with surprisingly minimal performance overhead in production environments. This is made possible by a combination of careful library design, modern compiler technology, and profile-guided optimization. &lt;/p&gt;
    &lt;p&gt; Christoph Kern - Safe Coding &lt;lb/&gt; Safe coding embodies a modular, compositional approach to building and reasoning about the safety of large, complex systems. Difficult and subtle reasoning about the safety of abstractions is localized to their implementations; the safety of risky operations within an abstraction must rely solely on assumptions supported by the abstraction's APIs and type signatures. Conversely, the composition of safe abstractions with safe code is automatically verified by the implementation language's type checker. While not a formal method itself, safe coding is grounded in principles and techniques from rigorous, formal software verification. &lt;/p&gt;
    &lt;p&gt; Jinnan Guo, Peter Pietzuch, Andrew Paverd, Kapil Vaswani - Trustworthy AI using Confidential Federated Learning &lt;lb/&gt; The principles of security, privacy, accountability, transparency, and fairness are the cornerstones of modern AI regulations. Classic FL was designed with a strong emphasis on security and privacy, at the cost of transparency and accountability. CFL addresses this gap with a careful combination of FL with TEEs and commitments. In addition, CFL brings other desirable security properties, such as code-based access control, model confidentiality, and protection of models during inference. Recent advances in confidential computing such as confidential containers and confidential GPUs mean that existing FL frameworks can be extended seamlessly to support CFL with low overheads. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45879012</guid><pubDate>Mon, 10 Nov 2025 18:23:10 +0000</pubDate></item><item><title>Using Generative AI in Content Production</title><link>https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production</link><description>&lt;doc fingerprint="3f50dd399a7d0094"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Generative AI tools (GenAI) that allow users to rapidly generate new and creatively unique media (video, sound, text, and image) are increasingly being used across creative workflows in Content Production. At Netflix, we see these tools as valuable creative aids when used transparently and responsibly.&lt;/p&gt;
    &lt;p&gt;This guidance helps filmmakers, production partners, and vendors understand when and how to use GenAI tools in production. It also offers a practical tool for assessing and enabling confident GenAI use when producing content for Netflix.&lt;/p&gt;
    &lt;p&gt;To support global productions and stay aligned with best practices, we expect all production partners to share any intended use of GenAI with their Netflix contact, especially as new tools continue to emerge with different capabilities and risks.&lt;/p&gt;
    &lt;p&gt;Most low-risk use cases that follow the guiding principles below are unlikely to require legal review. However, if the output includes final deliverables, talent likeness, personal data, or third-party IP, written approval will be required before you proceed.&lt;/p&gt;
    &lt;head rend="h2"&gt;TABLE OF CONTENTS&lt;/head&gt;
    &lt;p&gt;What use cases always require written approval?&lt;/p&gt;
    &lt;p&gt;How can I ensure confidentiality and data protection?&lt;/p&gt;
    &lt;p&gt;Are the considerations different for final output vs temporary media?&lt;/p&gt;
    &lt;p&gt;What should we consider before using GenAI for talent enhancement?&lt;/p&gt;
    &lt;p&gt;What if I’m using a custom workflow or working with a vendor who is?&lt;/p&gt;
    &lt;head rend="h2"&gt;Guiding Principles&lt;/head&gt;
    &lt;p&gt;Given the sensitivities surrounding the use of these tools and the evolving legal landscape, it is essential to act responsibly when employing generative workflows. Netflix asks partners to consider the following guiding principles before leveraging GenAI in any creative workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The outputs do not replicate or substantially recreate identifiable characteristics of unowned or copyrighted material, or infringe any copyright-protected works&lt;/item&gt;
      &lt;item&gt;The generative tools used do not store, reuse, or train on production data inputs or outputs.&lt;/item&gt;
      &lt;item&gt;Where possible, generative tools are used in an enterprise-secured environment to safeguard inputs.&lt;/item&gt;
      &lt;item&gt;Generated material is temporary and not part of the final deliverables.&lt;/item&gt;
      &lt;item&gt;GenAI is not used to replace or generate new talent performances or union-covered work without consent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you can confidently say "yes" to all the above, socializing the intended use with your Netflix contact may be sufficient. If you answer “no” or “unsure” to any of these principles, escalate to your Netflix contact for more guidance before proceeding, as written approval may be required.&lt;/p&gt;
    &lt;p&gt;If your partner vendor is using a custom GenAI workflow — meaning a pipeline built from multiple tools or models — the same principles apply. More details can be found here.&lt;/p&gt;
    &lt;head rend="h2"&gt;What use cases always require written approval?&lt;/head&gt;
    &lt;p&gt;Below are a few examples of situations that, in addition to reporting intended use, always require escalation and written approval before proceeding.&lt;/p&gt;
    &lt;head rend="h4"&gt;1. Data Use&lt;/head&gt;
    &lt;p&gt;Protecting personal data and creative rights is essential when working with GenAI. These tools often require input data to generate outputs, and how that data is handled matters. Before using any GenAI tool, especially third-party or off-the-shelf options, consider whether you are using material that requires special handling, clearance, or consent.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use of Proprietary or Personal Information: Do not input Netflix-owned materials (e.g., unreleased assets, scripts, production images) or personal data (e.g., cast or crew details) into tools unless explicitly approved.&lt;/item&gt;
      &lt;item&gt;Third-Party or Unowned Talent Assets: Do not train or fine-tune models using material from artists, performers, or other rights holders unless you have the proper legal clearance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Training an image model in the style of another artist using a library of their past work, where Netflix or the talent has not cleared rights.&lt;/p&gt;
    &lt;head rend="h4"&gt;2. Creative Output&lt;/head&gt;
    &lt;p&gt;AI-generated content must be used with care, especially when it forms a visible or story-critical part of the production. Whether you're designing a world, a character, or artwork that appears in a scene, the same creative and legal standards apply as with traditionally produced assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Generation of Key Creative Elements: GenAI should not be used to generate main characters, key visual elements, or fictional settings that are central to the story without written approval. &lt;list rend="ul"&gt;&lt;item&gt;Examples: GenAI is used to generate a second killer doll to play the red light/green light game with Young-hee in Squid Game.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; Copyrighted or Estate-Controlled: Avoid using inputs (e.g., prompts, images) that reference copyrighted materials or likenesses of public figures or deceased individuals without appropriate permissions. &lt;list rend="ul"&gt;&lt;item&gt;Example: “Create an image inspired by McCurry’s Afghan Girl” or referencing distinctive features of a known performer (e.g., “Create a character with Meryl Streep’s nose”).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;3. Talent &amp;amp; Performance&lt;/head&gt;
    &lt;p&gt;Respect for performers and their work is foundational to the responsible use of GenAI. Whether enhancing a recorded performance or generating a digital likeness, the threshold for consent and care is exceptionally high when the intent or character of a performance may be altered.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Synthetic or Digital Replicas - Do not create digital performers, voices, or likenesses of real talent without explicit and documented consent and complying with guild requirements (where applicable).&lt;/item&gt;
      &lt;item&gt;Significant Digital Alterations to Performances - Be cautious when making changes that affect a performance's emotional tone, delivery, or intent, as even subtle edits may have legal or reputational implications.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Examples include visual ADR (altering lip-sync or facial performance to match new, unscripted dialogue).&lt;/p&gt;
    &lt;head rend="h4"&gt;4. Ethics &amp;amp; Representation&lt;/head&gt;
    &lt;p&gt;Audiences should be able to trust what they see and hear on screen. GenAI (if used without care) can blur the line between fiction and reality or unintentionally mislead viewers. That’s why we ask you to consider both the intent and the impact of your AI-generated content.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Misleading or Misrepresentative Content: Avoid creating content that could be mistaken for real events, people, or statements if they never actually occurred (e.g., fabricated footage, dialogue, or scenes presented as authentic).&lt;list rend="ul"&gt;&lt;item&gt;Example: using GenAI to create a fake news segment featuring a real journalist delivering a fabricated statement, even if intended as background.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Impact on Union Roles: Ensure that your use of GenAI does not replace or materially impact work typically done by union-represented individuals, including actors, writers, or crew members, without proper approvals or agreements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How can I ensure confidentiality and data protection?&lt;/head&gt;
    &lt;p&gt;The use of tools covered by Netflix Enterprise Agreements provides an additional level of security to protect input data. Speak with your Netflix primary contact about available tools and the onboarding process. These tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prevent capture, training, or resale of your inputs&lt;/item&gt;
      &lt;item&gt;Protect sensitive inputs like scripts, production images, or talent visuals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even with secure tools, any use of sensitive information (e.g., talent likeness, unreleased footage, contracts) requires escalation to your Netflix contact.&lt;/p&gt;
    &lt;p&gt;When not using enterprise tools, ensure that any AI tools, plugins, or workflows you use do not train on inputs or outputs, as using the wrong license tier or missing pre-negotiated data terms could compromise confidentiality. You are responsible for reviewing the terms and conditions (T&amp;amp;Cs). Please check with your Netflix contact if you have any further questions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are the considerations different for final output vs temporary media?&lt;/head&gt;
    &lt;p&gt;If created with GenAI, content that appears in the final cut—even in the background—can raise legal, copyright, or trust issues with the audience. That’s why we ask you to flag any GenAI-generated elements early, especially if they will be seen or heard on screen.&lt;/p&gt;
    &lt;p&gt;If your proposed use case includes visual, audio, or text elements generated by AI (e.g., posters, documents, signage, or news clippings), contact your Netflix representative as early as possible for legal guidance. These items may require rights clearance before they can be included in final deliverables.&lt;/p&gt;
    &lt;p&gt;Some GenAI-generated props or set pieces may be considered incidental, for example, a historical document shown briefly in the background and not referenced in the scene. However, if the element is prominent (e.g., a character reads it aloud or it contributes to the story), it must be treated with greater care.&lt;/p&gt;
    &lt;p&gt;In these cases, you can use GenAI to explore ideas or mockups. Still, the final version should involve meaningful human input and follow the legal review process through your Netflix contact.&lt;/p&gt;
    &lt;head rend="h2"&gt;What should we consider before using GenAI for talent enhancement?&lt;/head&gt;
    &lt;p&gt;There is a long tradition of digitally altering performances in post-production and VFX. However, the use of AI to modify or replicate a performer's likeness or voice introduces new legal, ethical, and reputational challenges. Therefore, obtaining consent when appropriate and exercising caution are crucial. Many talent enhancement use cases require legal review, so please plan accordingly. Here are some guidelines to consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If creating a Digital Replica (i.e., a generated output recognizable as the voice and/or likeness of an identifiable performer for the purpose of portraying them in photography or soundtrack, they did not perform), consent is required. No further consent is needed to use the Digital Replica if the performance output: (1) remains substantially as scripted, performed, or recorded (e.g. reshoots); (2) depicts activities incapable of being performed by a human for safety reasons; or (3) results in the performer being unrecognizable (e.g. wearing a mask).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Digital Alterations: Consent is generally required for digital alterations, except for those customarily done in the entertainment and film industry, such as:&lt;list rend="ul"&gt;&lt;item&gt;Alterations where the photography or soundtrack remains substantially as scripted, performed, or recorded.&lt;/item&gt;&lt;item&gt;Post-production changes for cosmetics, wardrobe, noise reduction, timing, continuity, pitch, clarity, and similar purposes.&lt;/item&gt;&lt;item&gt;Circumstances where dubbing or using a double is permitted under existing agreements.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Model Usage:&lt;list rend="ul"&gt;&lt;item&gt;Any models trained to perform talent enhancement manipulation should be used solely for the production in question and within the scope of work agreed upon with the talent.&lt;/item&gt;&lt;item&gt;Models must not be used to create an actor's performance in another production, pitch, or concept without the express consent of all parties involved.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; Quality Assurance:&lt;list rend="ul"&gt;&lt;item&gt;Perform early tests to ensure that the quality of the outputs is acceptable both creatively and technically, so as not to adversely affect the talent’s original performance.&lt;/item&gt;&lt;item&gt;Where applicable and practical, plan dedicated data capture sessions with the talent to ensure the best possible outcomes.&lt;/item&gt;&lt;item&gt;Avoid enhancements that could harm the actor’s reputation, dignity, or personal image.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By following these guidelines, you can navigate the complexities of using AI in creative workflows while respecting the rights and integrity of performers.&lt;/p&gt;
    &lt;head rend="h2"&gt;What if I’m using a custom workflow or working with a vendor who is?&lt;/head&gt;
    &lt;p&gt;For vendors: If you're delivering work to Netflix using a custom GenAI workflow built from multiple tools, each step in the pipeline must meet our standards for data protection, consent, and content integrity as outlined in this document.&lt;/p&gt;
    &lt;p&gt;For production partners: If you're hiring a vendor or AI studio, use this guidance as a framework to help assess how they manage data, creative control, and final outputs. If you are unsure whether the pipeline meets the expectations outlined in this guidance, seek guidance from your Netflix contact.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;head rend="h3"&gt;Proposed Use Case Matrix&lt;/head&gt;
    &lt;p&gt;We have provided a Proposed Use Case Matrix at the end of this guidance as a tool to triage your proposed use case quickly.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Proposed Use Case&lt;/cell&gt;
        &lt;cell&gt;Action&lt;/cell&gt;
        &lt;cell&gt;Rationale&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI for ideation only (moodboards, reference images)&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;Low risk, non-final, likely not needing escalation if guiding principles are followed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI to generate background elements (e.g., signage, posters) that appear on camera&lt;/cell&gt;
        &lt;cell&gt;Use judgment: Incidental elements may be low risk, but if story-relevant, please escalate.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI to create final character designs or key visuals&lt;/cell&gt;
        &lt;cell&gt;Requires escalation as it could impact legal rights, audience perception, or union roles.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI for talent replication (re-ageing, or synthetic voices)&lt;/cell&gt;
        &lt;cell&gt;Requires escalation for consent and legal review.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using unowned training data (e.g., celebrity faces, copyrighted art)&lt;/cell&gt;
        &lt;cell&gt;Needs escalation due to copyright and other rights risk.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Using Netflix's proprietary material&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Needs escalation for review if outside secure enterprise tools.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45879793</guid><pubDate>Mon, 10 Nov 2025 19:28:07 +0000</pubDate></item><item><title>Spatial intelligence is AI’s next frontier</title><link>https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45880939</guid><pubDate>Mon, 10 Nov 2025 21:07:02 +0000</pubDate></item><item><title>Linux in a Pixel Shader – A RISC-V Emulator for VRChat</title><link>https://blog.pimaker.at/texts/rvc1/</link><description>&lt;doc fingerprint="bea919996d10b18a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Linux in a Pixel Shader - A RISC-V Emulator for VRChat&lt;/head&gt;25 August 2021, by _pi_&lt;p&gt;views&lt;/p&gt;&lt;p&gt;for comments see Hacker News, r/programming or r/vrchat&lt;/p&gt;&lt;head rend="h1"&gt;Intro&lt;/head&gt;&lt;p&gt;Sometimes you get hit with ideas for side-projects that sound absolutely plausible in your head. The idea grips you, your mind’s eye can practically visualize it already. And then reality strikes, and you realize how utterly insane this would be, and just how much work would need to go into it.&lt;/p&gt;&lt;p&gt;Usually these ideas appear, I enjoy dissecting them for a few days, and then I move on. But sometimes. Sometimes I decide to double down and get Linux running on my graphics card.&lt;/p&gt;&lt;p&gt;This is the story of how I made the &lt;code&gt;rvc&lt;/code&gt; RISC-V emulator within VRChat, and a deep-dive into the unusual techniques required to do it.&lt;/p&gt;&lt;p&gt;Here are some specs up front, if you’re satisfied with piecing the story together yourself:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;the code is on GitHub&lt;/item&gt;&lt;item&gt;emulated RISC-V &lt;code&gt;rv32ima/su+Zifencei+Zicsr&lt;/code&gt;instruction set&lt;/item&gt;&lt;item&gt;64 MiB of RAM minus CPU state is stored in a 2048x2048 pixel Integer-Format texture (128 bpp)&lt;/item&gt;&lt;item&gt;Unity Custom Render Texture with buffer-swapping allows encoding/decoding state between frames&lt;/item&gt;&lt;item&gt;a pixel shader is used for emulation since compute shaders and UAV are not supported in VRChat&lt;/item&gt;&lt;/list&gt;&lt;p&gt;(image credit: @pema99, thanks!)&lt;/p&gt;&lt;p&gt;Be warned that this post might be a bit rambly at times, as I try to recall the many pitfalls of writing this shader. Let’s hope it will at least turn out entertaining.&lt;/p&gt;&lt;head rend="h1"&gt;About the project&lt;/head&gt;&lt;p&gt;Around March 2021 I decided on writing an emulator capable of running a full Linux Kernel in VRChat. Due to the inherent limitations of that platform, the tool of choice had to be a shader. And after a few months of work, I’m now proud to present the worlds first (as far as I know) RISC-V CPU/SoC emulator in an HLSL pixel shader, capable of running up to 250 kHz (on a 2080 Ti) and booting Linux 5.13.5 with MMU support.&lt;/p&gt;&lt;p&gt;You can experience the result of all this for yourself by visiting this VRChat world. You will require a VRChat account and the corresponding client, both of which are free and give you access to a massive social platform full of user-created content such as this (no VR headset required!).&lt;/p&gt;&lt;p&gt;(a screenshot of the VRChat world and interface to use the emulator)&lt;/p&gt;&lt;p&gt;Here’s me in my Avatar again, standing in front of a kernel panic:&lt;/p&gt;&lt;p&gt;(image credit: @pema99 as well, I believe)&lt;/p&gt;&lt;p&gt;This picture was taken after I showed off my work at the community meetup, a self-organized weekly get-together of VRChat creators from all over. Here’s a recording of the live-stream where I presented it, it’s fun to see everyone’s reactions when I unveiled my big “secret project”:&lt;/p&gt;&lt;p&gt;Thanks to the team organizing the event for providing me with the opportunity!&lt;/p&gt;&lt;p&gt;The project has been featured on Adafruit, and my friend @fuopy over on twitter has posted video evidence as well:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Linux running in a shader! By _pi_! Check it out!!&lt;/p&gt;— fuopy (@fuopy) August 15, 2021&lt;lb/&gt;(5x speed of Linux running in a fragment shader emulating RISC-V) World link:https://t.co/jYnR8AZrQM&lt;lb/&gt;#vrchat #shaders pic.twitter.com/gqW6qSXLb2&lt;/quote&gt;&lt;p&gt;The response I’ve received in the days afterwards was tremendously positive. A seriously big thank you to everyone who asked for details, suggested improvements, shared the world, or simply shook their head in disbelieve towards me.&lt;/p&gt;&lt;head rend="h1"&gt;A Tribute to VRChat’s Creative Community&lt;/head&gt;&lt;p&gt;I am a big VR enthusiast - I was among the first to even try the original Vive here in Austria, and never looked back since. But it was only when a friend invited me into VRChat around August 2020, that I was introduced to the amazing creative-community surrounding that “game”/social platform.&lt;/p&gt;&lt;p&gt;I can’t speak for the visual side that much, though I dearly admire people who can summon 3D models and environments from scratch. Luckily, VRChat had recently released Udon, which allows world crafters to run custom code within their creations. This opened the door to the likes of myself, people who enjoy coding for fun and just want to push the envelope of what can be made.&lt;/p&gt;&lt;p&gt;Udon works super well for anything that doesn’t require high performance. The built-in visual programming combined with @MerlinVR’s UdonSharp (a C#-to-Udon compiler) are vital for making interactive worlds these days. People are using it to create incredible experiences, anything from multiplayer PvP games to petting zoos for ducks and dogs (and sometimes other players) - it is what got me interested in making content for VRChat in the first place.&lt;/p&gt;&lt;p&gt;(image credit: u/1029chris)&lt;/p&gt;&lt;p&gt;What really sparked my imagination however, was the discovery that you can embed your own, custom shaders within such a world. You can even put them on your Avatars! With shaders, the sky is the limit - and if you take even just a cursory look at what the community has done in VRChat, you realize that even that is only a limit meant to be broken.&lt;/p&gt;&lt;p&gt;I like to compare it to demoscening. Instead of cramming stuff into limited storage space, you work around the limitations the platform imposes on you - there’s so many things you can’t do, that part of the challenge is to figure out what you can do. Or as resident shader magician @cnlohr put it:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I love how VRC programmers have a way of looking at [a] wall of restrictions, then find a way of switching their existence to a zero dimensional object for a moment, then they appear on the other side of that wall.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Pictured above is “Treehouse in the Shade”, one of the most famous shader worlds, with an unfortunately tragic backstory. It is indeed a beautiful world I have spent a good amount of time in myself.&lt;/p&gt;&lt;p&gt;One of its co-creators, SCRN, has also written some less visual, but more technical VRChat projects, like this deep learning shader.&lt;/p&gt;&lt;p&gt;Since discovering VRChat and the creator community, I have made several of my own custom Avatars and Worlds. Some are finished, some left as demonstrations of what could be.&lt;/p&gt;&lt;p&gt;And then, back in February or March of 2021, this little spark of an idea popped up in my head - if I could run anything I want in a VRChat world, then why not go for the end-goal straight away: Let’s run a Linux kernel!&lt;/p&gt;&lt;head rend="h1"&gt;Compute Shaders in VRChat&lt;/head&gt;&lt;p&gt;Udon, as mentioned above, comes fairly close to regular coding. It’s semantically equivalent to writing Unity behaviour scripts, and can utilize most of what C# has to offer using UdonSharp.&lt;/p&gt;&lt;p&gt;However, to quote from UdonSharp’s documentation:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Udon can take on the order of 200x to 1000x longer to run a piece of code than the equivalent in normal C# depending on what you’re doing. […] Just 40 iterations of something can often be enough to visibly impact frame rate on a decent computer.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;With this performance constraint in mind, it becomes clear that CPU emulation is simply infeasible[0].&lt;/p&gt;&lt;p&gt;As far as I know there’s only two ways you can write custom code and have it execute in VRChat: Udon and shaders. This is important for security concerns of course, as Udon is a VM and shaders only run on the GPU. Since the former is out of the question, that leaves us with shaders.&lt;/p&gt;&lt;p&gt;But hold up, I hear you say, shaders are the little programs telling your GPU how to make things look good, right? How could you possibly emulate a CPU on that? And isn’t that kind of stupid?&lt;/p&gt;&lt;p&gt;Correct; By using compute shaders; And yes.&lt;/p&gt;&lt;p&gt;A “compute shader” doesn’t output an image, but simply data. It allows, in theory, to run highly parallel code on the GPU to compute any value. This is the principle behind CUDA, but is also used in games.&lt;/p&gt;&lt;p&gt;That sounds too easy though - and indeed it is, VRChat doesn’t allow you to use them in your creations. However, we can use some trickery here: By pointing Unity’s &lt;code&gt;Camera&lt;/code&gt; object at a quad rendered with our shader[1], and then assigning the output RenderTexture (the target buffer) to an input of our shader, we have essentially created a writable persistent state storage - the basic building block for a compute operation. Any pixel we write during the fragment (aka pixel) shader stage, we will be able to read back next frame.&lt;/p&gt;&lt;p&gt;(image credit: @pema99 and their fantastic treasure trove of forbidden VRChat shader knowledge)&lt;/p&gt;&lt;p&gt;Of course there’s a bunch of texture alignment and Unity trickery necessary to make it work, but people have been using this technique for a long time, and it turns out to be surprisingly realiable. You can even use it on an Avatar, I managed to implement a basic calculator with it once.&lt;/p&gt;&lt;p&gt;The issue with that is of course that a fragment shader runs in parallel for every pixel on the texture, and every instance can only output to one of them in the end. We’ll see how to (mostly) work around that later.&lt;/p&gt;&lt;p&gt;[0] I feel the need to point out that someone did, in fact, emulate a full CHIP-8 in Udon alone, and someone else tried their hand at a 6502 - both projects run very slowly however, certainly too slow to get an OS booted… ⏎&lt;/p&gt;&lt;p&gt;[1] or in this case we’re using a Custom Render Texture, which is basically the same thing, but more cursed^Wcompact ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Excursion: RISC-V&lt;/head&gt;&lt;p&gt;If you want to create a system capable of running Linux, you need to decide on which supported CPU architecture you want to emulate. Take a look into the kernel source, and you will see that there are quite a bunch available.&lt;/p&gt;&lt;p&gt;For our purposes, it is important that the ISA is as simple as possible, not just because I’m lazy, but also because shaders have both theoretical and practical limitations when it comes to program size and complexity.&lt;/p&gt;&lt;p&gt;I decided on RISC-V, mostly because I liked their mission in general - an open source CPU architecture is something to be fond of, and I had been following efforts to port Linux software to it with great interest. These days you can run a full Debian on some hardware RISC-V boards.&lt;/p&gt;&lt;p&gt;It of course helps that all the specifications for RISC-V are published freely on the internet, and there are good reference implementations available (shout out to takahirox/riscv-rust).&lt;/p&gt;&lt;head rend="h1"&gt;Writing an emulator in &lt;del rend="overstrike"&gt;HLSL&lt;/del&gt; C&lt;/head&gt;&lt;p&gt;But back to making our emulator. First problem: Debugging a shader is hard. You can’t just attach GDB and single step, or even add &lt;code&gt;printf&lt;/code&gt; statements throughout your code. There are shader debugging tools out there, but they mostly focus on the visual side of things, and aren’t that helpful when you’re trying to run what is basically linear code.&lt;/p&gt;&lt;p&gt;Luckily for us, HLSL, the language we use to write shaders in Unity, is remarkably similar to regular C. And so the first iteration of the emulator was written in C.&lt;/p&gt;&lt;p&gt;Of course, some prep-work to translating already went into it. If you were to show the code of the C version to any seasoned C programmer, they would shudder and call an exorcist[2].&lt;/p&gt;&lt;code&gt;#define UART_GET1(x) ((cpu-&amp;gt;uart.rbr_thr_ier_iir &amp;gt;&amp;gt; SHIFT_##x) &amp;amp; 0xff)
#define UART_GET2(x) ((cpu-&amp;gt;uart.lcr_mcr_lsr_scr &amp;gt;&amp;gt; SHIFT_##x) &amp;amp; 0xff)

#define UART_SET1(x, val) cpu-&amp;gt;uart.rbr_thr_ier_iir = (cpu-&amp;gt;uart.rbr_thr_ier_iir &amp;amp; ~(0xff &amp;lt;&amp;lt; SHIFT_##x)) | (val &amp;lt;&amp;lt; SHIFT_##x)
#define UART_SET2(x, val) cpu-&amp;gt;uart.lcr_mcr_lsr_scr = (cpu-&amp;gt;uart.lcr_mcr_lsr_scr &amp;amp; ~(0xff &amp;lt;&amp;lt; SHIFT_##x)) | (val &amp;lt;&amp;lt; SHIFT_##x)
&lt;/code&gt;&lt;p&gt;(excerpt from the UART driver; packing logic for UART state since HLSL only has 32-bit variables)&lt;/p&gt;&lt;p&gt;After a few evenings spent coding, I got to a point where the riscv-tests suite passed for the integer base set (rv32i). The reason we’re going for 32-bit is because the version of DirectX that VRChat is based on only supports 32-bit integers on GPUs. In fact, at least historically speaking, even most GPU hardware has rather poor support for 64-bit integers.&lt;/p&gt;&lt;p&gt;I had figured out already that for Linux support I needed the ‘m’ (integer multiplication) and ‘a’ (atomics) extensions, as well as CSR and memory fencing support. Atomics are implemented as simple direct operations, as the system features only one hart (‘core’) anyway. CSRs are fully implemented, fencing is simply a no-op in C (in HLSL this becomes more important).&lt;/p&gt;&lt;p&gt;Multiplication is fully working in C, but not in HLSL - it requires the &lt;code&gt;mulh&lt;/code&gt; family of instructions, which give you the upper 32-bit of a 32 by 32 multiplication. This would require a single 64-bit multiply, which is not available for our shader target, so I decided to emulate it using double-precision floating-point numbers for now. This is stupid.[3]&lt;/p&gt;&lt;p&gt;The C version remains fully functional even now, and new features will still be implemented there first. It’s just so much easier to debug, plus compile times are magnitudes faster. The first porting effort happened even before it was able to boot Linux, I then gradually added support for more and more stuff by ping-ponging between the C and HLSL versions.&lt;/p&gt;&lt;p&gt;[2] It is important to note that this quality has translated to HLSL too, I know for a fact that I gave some shader devs nightmares. ⏎&lt;/p&gt;&lt;p&gt;[3] Microsoft, please, I beg you, why would you add an instruction to DXIL but not implement it in HLSL?! ⏎&lt;/p&gt;&lt;head rend="h1"&gt;What’s better than a Preprocessor?&lt;/head&gt;&lt;p&gt;That’s right, two of them!&lt;/p&gt;&lt;p&gt;Now that we have a C version up and running, one of the first challenges for porting it to a shader is state encoding and decoding. To make it more obvious why this is important, here is what our fragment shader will look like in the end (simplified):&lt;/p&gt;&lt;code&gt;uint4 frag(v2f i) : SV_Target {
    decode();
    if (_Init) {
        cpu_init();
    } else {
        for (uint i = 0; i &amp;lt; _TicksPerFrame; i++) {
            cpu_tick();
        }
    }
    return encode();
}
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;decode()&lt;/code&gt; logic takes care of intializing a global static &lt;code&gt;cpu&lt;/code&gt; struct, &lt;code&gt;cpu_init()&lt;/code&gt; or &lt;code&gt;cpu_tick()&lt;/code&gt; update the state, and &lt;code&gt;encode()&lt;/code&gt; writes it back.&lt;/p&gt;&lt;p&gt;This will run for every pixel in our state storage texture in parallel, and it’s the encoder’s job to pick which piece of information to write out in the end. Each pixel (that is, conceptually, every instance of this function running), can output 4 color values (R, G, B and Alpha) with 32 bits each, summing up to a total of 128 bit, or, more practically, 4 variables of our cpu struct.&lt;/p&gt;&lt;p&gt;What we need now is a mapping of pixel position and which state it contains. This must be consistent between &lt;code&gt;encode&lt;/code&gt; and &lt;code&gt;decode&lt;/code&gt; of course.&lt;/p&gt;&lt;p&gt;&lt;code&gt;decode&lt;/code&gt; will consist of a bunch of statements akin to:&lt;/p&gt;&lt;code&gt;cpu.xreg1 = STATE_TEX[uint2(69, 0)].r;
&lt;/code&gt;&lt;p&gt;…which will index the state texture at coordinates &lt;code&gt;x=69,y=0&lt;/code&gt;, take the value stored in the red color channel and decode it as general purpose register (xreg) 1.&lt;/p&gt;&lt;p&gt;&lt;code&gt;encode&lt;/code&gt; looks like this:&lt;/p&gt;&lt;code&gt;uint pos_id = pos.x | (pos.y &amp;lt;&amp;lt; 16);
switch (pos_id) {
    // ...
    case 69:
        ret.r = cpu.xreg1;
        ret.g = cpu.xreg2;
        ret.b = cpu.xreg3;
        ret.a = cpu.xreg4;
        return ret;
    // ...
}
&lt;/code&gt;&lt;p&gt;Yep, it’s just one massive switch/case statement. I can immediately hear people complain about performance here, since branching in shaders is generally a bad idea™. But in this case, the impact is minimal because of several reasons:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;This is a switch statement, not a pure branch, which can actually compile down to a jump table for the final shader assembly, meaning the cost of the branch itself is constant&lt;/item&gt;&lt;item&gt;In accordance with the first reason, more branches are avoided by packing the x and y coordinates into the same value (this works since our state texture is small)&lt;/item&gt;&lt;item&gt;While it is true that branches which resolve to different values for neighboring pixels cause divergence (i.e. they break parallelism), this happens at the very end of our fragment shader, everything prior should still execute in a combined wavefront&lt;/item&gt;&lt;item&gt;If you’re concerned about this single switch/case statement, boy do I have bad news for you about the rest of this shader&lt;/item&gt;&lt;/list&gt;&lt;p&gt;My immediate thought when I decided on this approach was that these lines look very regular. It would be a shame to write them all by hand.&lt;/p&gt;&lt;p&gt;At first I figured I could come up with some C preprocessor macros (which thankfully are supported in HLSL) to do the job for me. However, it turns out such macros are really bad at anything procedural, like counting up indices - or coordinates. So instead, I decided on using a seperate, external preprocessor: perlpp.&lt;/p&gt;&lt;p&gt;In all honesty, this was probably a big mistake in terms of code readability. But it did work super well for this specific case, and with the full power of Perl 5 for code gen, I could do some neat stuff.&lt;/p&gt;&lt;p&gt;This is how a struct is now defined:&lt;/p&gt;&lt;code&gt;typedef struct {
    &amp;lt;? $s-&amp;gt;("uint", "mmu.mode"); ?&amp;gt;
    &amp;lt;? $s-&amp;gt;("uint", "mmu.ppn"); ?&amp;gt;
} mmu_state;
&lt;/code&gt;&lt;p&gt;(excerpt from types.h.pp)&lt;/p&gt;&lt;p&gt;Ignoring the syntax highlighter completely freaking out (which happens in vim and VS code too, never got around to fixing that…), this looks fairly readable in my opinion. The &lt;code&gt;$s&lt;/code&gt; perl function is defined to print a normal struct definition, but also store the name and type into a hash table. This can then later be used to auto-generate the &lt;code&gt;encode&lt;/code&gt; and &lt;code&gt;decode&lt;/code&gt; functions.&lt;/p&gt;&lt;p&gt;We also know the last address that contains any state, which we can use to place other, more linear data right after. In particular, this includes the CSR-area. CSRs are “Control and Status Registers”, which are 4096 32-bit registers that can be accessed using specific instructions (&lt;code&gt;csrw&lt;/code&gt;, &lt;code&gt;csrr&lt;/code&gt;, &lt;code&gt;csrc&lt;/code&gt;, etc.). They contain certain state about the CPU’s environment, like the active privilege mode, IRQ enablement or the MMU base pointer (&lt;code&gt;SATP&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;Aside from a few exceptions, these do not have special semantics on read and write, so it is enough to store them in a way that they can be indexed using their address. 4096 values means 1024 pixels, which we place 4-word aligned right after the last state-containing pixel. Reading now simply means calculating the offset from the CSR base (which is determined by perlpp at compile-time) and doing a texture tap. Writing happens via a similar caching mechanism as main memory, more on that later.&lt;/p&gt;&lt;p&gt;In addition to all that, perlpp makes it possible to use loops in code-gen. This is tremendously helpful for dynamic sizing of caches and structs with many values (for example the 32 general purpose registers).&lt;/p&gt;&lt;p&gt;One of the many problems with shader code is that HLSL doesn’t support arrays in a meaningful way. Pointer math (and thus array indexing) just isn’t a thing on the GPU, so writing to a non-constant index of an array is impossible. To work around this, there are several places in the code with patterns like this:&lt;/p&gt;&lt;code&gt;typedef struct {
    &amp;lt;? for my $i (0..31) {
        $s-&amp;gt;("uint", "xreg$i");
        print "\n    ";
    } ?&amp;gt;
    // ...
} cpu_t;

uint xreg(uint i) {
    #define C(x) case x: return cpu.xreg##x;
    if (i &amp;lt; 16) {
        [flatten]
        switch (i) {
            C(0) C(1) C(2) C(3)
            C(4) C(5) C(6) C(7)
            C(8) C(9) C(10) C(11)
            C(12) C(13) C(14) C(15)
        }
    } else {
        [flatten]
        switch (i) {
            C(16) C(17) C(18) C(19)
            C(20) C(21) C(22) C(23)
            C(24) C(25) C(26) C(27)
            C(28) C(29) C(30) C(31)
        }
    }
    return 0xdeadc0de;
    #undef C
}
&lt;/code&gt;&lt;p&gt;(excerpt from types.h.pp)&lt;/p&gt;&lt;p&gt;This function returns the content of general purpose register &lt;code&gt;i&lt;/code&gt;, but since the registers are not an array, it has to use a (&lt;code&gt;[flatten]&lt;/code&gt;ed) switch statement. The outer &lt;code&gt;if&lt;/code&gt; is an optimization, so each call only needs to go through 16 &lt;code&gt;movc&lt;/code&gt; instructions. &lt;code&gt;xreg&lt;/code&gt; is called a lot, and considered one of the “inlineable” functions - that’s why I’m not using a &lt;code&gt;[forcecase]&lt;/code&gt;-style jumptable here; but we’re getting way ahead of ourselves…&lt;/p&gt;&lt;head rend="h1"&gt;Instruction Decoding and DXSC Bugs&lt;/head&gt;&lt;p&gt;Now that we can keep the state stored, let’s take a look at what our fragment shader will do with it. From the simplified example above, &lt;code&gt;cpu_init&lt;/code&gt; is almost not worth talking about, simply zeroing the &lt;code&gt;cpu&lt;/code&gt; struct and setting some default values. &lt;code&gt;cpu_tick&lt;/code&gt; is where the magic happens, and our fairly normal, linear emulation code lives.&lt;/p&gt;&lt;p&gt;After reading an instruction from the current program counter (&lt;code&gt;pc&lt;/code&gt; register) address, we need to decode it. I decided to cheat a little for this:&lt;/p&gt;&lt;p&gt;I took a look at how the aforementioned riscv-rust emulator handles that part, and quickly realized that the &lt;code&gt;INSTRUCTIONS&lt;/code&gt; array in &lt;code&gt;src/cpu.rs&lt;/code&gt; contains basically all information required for parsing. So I did what any sane person would, copied the entire array into a text file, wrote a little perl script and had it auto-generate the decoding logic for me.&lt;/p&gt;&lt;p&gt;The end result looks something like this:&lt;/p&gt;&lt;code&gt;// definition:
DEF(add, FormatR, { // rv32i
    NOT_IMPL
})
DEF(addi, FormatI, { // rv32i
    NOT_IMPL
})
// ... and many more

// decoding:
ins_masked = ins_word &amp;amp; 0xfe00707f;
[forcecase]
switch (ins_masked) {
    RUN(add, 0x00000033, ins_FormatR)
    RUN(and, 0x00007033, ins_FormatR)
    RUN(div, 0x02004033, ins_FormatR)
    // ...
}
ins_masked = ins_word &amp;amp; 0x0000707f;
[forcecase]
switch (ins_masked) {
    RUN(addi, 0x00000013, ins_FormatI)
    RUN(andi, 0x00007013, ins_FormatI)
    RUN(beq, 0x00000063, ins_FormatB)
    // ...
}
// etc.pp.
&lt;/code&gt;&lt;p&gt;(actual definition is in emu.h)&lt;/p&gt;&lt;p&gt;This logic appears fairly optimal to me, in the end there are 9 different switch statements for slightly different opcode masks. I tried to sort these so that the most frequent instructions are first, though as I will discuss in the Inlining section below, this wasn’t always possible.&lt;/p&gt;&lt;p&gt;Observant readers (hi there!) will have noticed the &lt;code&gt;[forcecase]&lt;/code&gt; above the &lt;code&gt;switch&lt;/code&gt; keywords. This attribute is important for performance, as it forces the shader compiler to emit a jump table instead of a bunch of individual branches (or conditional moves with &lt;code&gt;[flatten]&lt;/code&gt;). Now, you may be asking yourself, “if this is so important for performance, why isn’t it the default?”. Truth is, I have absolutely no idea.&lt;/p&gt;&lt;p&gt;Of course there are situations where it’s actually faster to &lt;code&gt;[flatten]&lt;/code&gt;, as conditional moves can lead to less divergence, but I don’t get why &lt;code&gt;[branch]&lt;/code&gt;, i.e. “make it a bunch of if-statements” exists.&lt;/p&gt;&lt;p&gt;Thing is, there doesn’t seem to be a limit for jump tables. I have a lot of them in this shader. However, if you look at the code in emu.h, you will see that some of the statements use an explicit &lt;code&gt;[branch]&lt;/code&gt; - the explanation to this conundrum is as simple as it is dumb: If I put a &lt;code&gt;[forcecase]&lt;/code&gt; there, it crashes the shader compiler.&lt;/p&gt;&lt;p&gt;I don’t know why, I never got any useful log output aside from a generic “IPC error”, and I haven’t heard of anyone else experiencing this - then again, how often do you write shader code in this style…&lt;/p&gt;&lt;p&gt;&lt;code&gt;&amp;lt;rant&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;The point I want to make in this section, is that the DirectX Shader Compiler can be very dumb and I hate it and it should go hide in a corner and be ashamed. No offense to anyone working on it, but I’ve had instances where a whitespace change made the difference between the shader compiler crashing and a working output.&lt;/p&gt;&lt;p&gt;Even if it is working, writing such a large shader is not a joy. I get that register allocation is a hard problem, but if gcc and clang can compile the same program in C within milliseconds, why do I have to wait upwards of 10 minutes for the HLSL version to compile?!&lt;/p&gt;&lt;p&gt;Remember when I said there was a good reason for keeping the C version around…&lt;/p&gt;&lt;p&gt;&lt;code&gt;&amp;lt;/rant&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;head rend="h1"&gt;Main Memory&lt;/head&gt;&lt;p&gt;To run Linux, I figured we’d need at least 32 MiB of main memory (RAM), but let’s be safe and make that 64 - the performance difference will not be big, and there should be enough VRAM.&lt;/p&gt;&lt;p&gt;At first, the main performance concern was clock speed. That is, how many CPU cycles can run in one frame. Initially, I went with what seemed to be the simplest option available - let’s call this version 1:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;64 MiB of RAM require a 2048x2048 pixel texture at 128 bit per pixel&lt;/item&gt;&lt;item&gt;let’s reserve a small area in the top-left, say 128x128 for our CPU state&lt;/item&gt;&lt;item&gt;have the shader run one tick per execution and write the result out, treating RAM the same as state - i.e. we run the fragment shader for 2048x2048 = 4194304 pixels&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This is obviously rather inefficient, and would ultimately result in a clock speed of 1 cycle per frame. We can somewhat tweak this by running the CRT (Custom Render Texture, or equivalent camera loop with Udon) multiple times per frame, but this incurs the hefty cost of double-buffering (and thus swapping) the entire 64 MiB texture every time. Instead, let’s leave this concept behind a bit and focus on version 2:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;same 2048x2048 texture with 128x128 state area as before&lt;/item&gt;&lt;item&gt;shader split into two passes: &lt;code&gt;CPUTick&lt;/code&gt;does a CPU cycle but writes to a memory cache area within the 128x128 pixels, and&lt;code&gt;Commit&lt;/code&gt;writes that cache back to RAM&lt;/item&gt;&lt;item&gt;the Custom Render Texture is set up so it renders multiple times, first a bunch of &lt;code&gt;CPUTick&lt;/code&gt;passes on just the 128x128 area, then it finishes up with a single full-texture&lt;code&gt;Commit&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This implementation already gets us a lot further. On the bright side, Unity is smart enough to realize that when you only update the 128 by 128 area, it also only needs to buffer swap this part of the texture. And since this area is fairly small, it fits entirely within the L2 cache of almost any modern GPU, making the swapping process very cheap. On the downside, this now means we need a seperate memory cache - no problem though, we have enough space left over in the state area to hold all the data we want.&lt;/p&gt;&lt;p&gt;Version 2 got up to around 35-40 kHz in-game, pretty decent, but still not fast enough for my liking. Enter the current version 3:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;same area splitting as before, keep the two-pass design&lt;/item&gt;&lt;item&gt;instead of multiple passes in the CRT, simply loop directly in the shader and run multiple ticks at once&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This option has the least non-compute overhead of all the above. There’s only two buffer swaps, and one of them is for the small area. This caching strategy (I call it the “L1 write cache”) is what makes this shader fast enough to run Linux. 300 kHz is not out of the question on a high-end GPU, my 2080 Ti regularly pushes over 200.&lt;/p&gt;&lt;p&gt;(image credit: @d4rkpl4y3r_vr, who had the patience to show that the emulator can calculate pi to 1234 places)&lt;/p&gt;&lt;p&gt;However, there is now a glaring issue: If we run multiple ticks per iteration, we cannot use the 128x128 px state area as a cache anymore. In a fragment shader, we can only write output at the end of execution, but memory writes can happen anytime during emulation, and must be architecturally visible immediately - that is, in RISC-V, a write followed by a read to the same address must always return the previously written value.[4]&lt;/p&gt;&lt;p&gt;With this in mind, the L1 cache only has one place to live: The GPU’s register file. I’ve been told modern architectures should support up to 64 kB of instance state (I suppose it can evict to VRAM?), but in practice the limit you’re going to hit is once again the shader compiler. Use too many variables, and we’re back at waiting 15 minutes for an “IPC error”.&lt;/p&gt;&lt;p&gt;At the time of writing, L1 is a two-way set associative cache with 16 sets and 5 words per line[5]. This comes out to 320 bytes per frame - with the current setup, a good GPU can push up to 4000 instructions per frame, and with &lt;code&gt;sw&lt;/code&gt; (“store word”) being one of them, this cache will fill up in as little as 80. If the cache is full, the CPU stalls until the next &lt;code&gt;Commit&lt;/code&gt;. A little trick is to double up the &lt;code&gt;Commit&lt;/code&gt; passes and do two &lt;code&gt;CPUTick&lt;/code&gt;s as well - that way we can at least get twice the throughput, while only incuring a moderate performance hit for buffer swapping the full 64 MiB twice.&lt;/p&gt;&lt;p&gt;This caching strategy is the tradeoff I made for clock speed - memory write performance absolutely sucks. But it’s decidedly faster than limiting the clockspeed itself, the “real-world” performance is certainly better this way.&lt;/p&gt;&lt;p&gt;A neat little side-effect of storing main memory in a texture, is that you can display it visually! Below is a (jpeg-compressed and downsized) picture of the main memory with a fully booted linux kernel.&lt;/p&gt;&lt;p&gt;Notice the two large zeroed (black) areas at the top (128px state area + OpenSBI and reserved bootloader memory), and the fascinating blue memory pattern at the bottom (that’s the high addresses, I believe the regular stripes are due to early memory poisoning of the SLAB/SLUB allocator in the kernel, feel free to correct me on this):&lt;/p&gt;&lt;p&gt;The texture is also on display in the VRChat world, where you can take a closer look during execution yourself. It’s quite fun to see memory framention visibly become worse, the more userspace programs are started.&lt;/p&gt;&lt;p&gt;As an aside, you might be wondering why I called the cache “L1”, as in “Layer 1”. The reason is that in the future I’m planning on extending this concept to become a sort of hybrid between version 2 and 3. The idea is that there will be multiple ticks before a commit, each one being followed by a &lt;code&gt;Writeback&lt;/code&gt; pass, that still only operates on the 128x128 texture (for cheap double-buffering) and flushes the L1 cache to a page-based L2 variant.&lt;/p&gt;&lt;p&gt;The tricky part here is that this has to go away from being set- or fully-associated, as both of these variants would not only incur massive performance penalties for lots of branching, but also for the repeated texture taps (as I can’t allocate any more registers for the L2 without crashing the compiler again). Instead, I’m planning on having only a few registers allocated that contain page base addresses that then point to a linear cache area in the state texture. This is somewhat hard to keep coherent though, and requires a new concept of stalling only until a &lt;code&gt;Writeback&lt;/code&gt;, so I couldn’t get it done in time for the initial presentation.&lt;/p&gt;&lt;p&gt;[4] an exception to this rule is instruction loading, which only needs to be consistent after a &lt;code&gt;fencei&lt;/code&gt; instruction - we can make use of this by omitting the somewhat expensive cache-load logic for memory reads and just tap the texture directly, simply stalling the CPU on &lt;code&gt;fencei&lt;/code&gt; until the next &lt;code&gt;Commit&lt;/code&gt; since it is called very infrequently ⏎&lt;/p&gt;&lt;p&gt;[5] another benefit of perlpp: all of these values are configurable in a single “header” file ⏎&lt;/p&gt;&lt;head rend="h1"&gt;A Note on Inlining&lt;/head&gt;&lt;p&gt;HLSL has the peculiarity that there are no function calls. All functions are inlined at the call site[6], if you call a function four times, it will be included four times in the output assembly. This is of course recursive, so a function that calls other functions will also inline those at every callsite.&lt;/p&gt;&lt;p&gt;This doesn’t sound like a big issue, but it turns out it actually is - one of the biggest performance tricks I learned during development of the emulator, is that avoiding multiple callsites can improve performance quite a bit. I’m not 100% sure why that is, but I would assume it has to with locality/recency in the L1i cache of the GPU. So less code = less assembly = less thrashing in the instruction cache, and thus better performance.&lt;/p&gt;&lt;p&gt;Additionally, how could it be any different, it also helps with actually getting the thing to compile. More inlines means more code to translate, and the shader compiler really hates code.&lt;/p&gt;&lt;p&gt;This gives rise to some awkward optimizations, that would produce the opposite result almost anywhere else. The main example of this is coalescing memory reads and writes:&lt;/p&gt;&lt;p&gt;The C code simply calls &lt;code&gt;mem_get_word&lt;/code&gt; in the execution path of each instruction. This works, because the function call is cheap. But if it were to be inlined in every instruction that reads from memory, it would slow down the shader a lot. Instead, we do it preventatively - before even executing the instruction-specific code, check by way of the opcode if the instruction might need to read a value from memory. If that is the case, figure out where from (which is different for regular &lt;code&gt;lX&lt;/code&gt; and atomic ops), and load the memory once. This way, &lt;code&gt;mem_get_word&lt;/code&gt; only needs to be inlined once for the entire instruction emulation path.&lt;/p&gt;&lt;p&gt;We also handle unaligned memory reads creatively. Off the top of my head, this would be the obvious solution:&lt;/p&gt;&lt;code&gt;off = (read_addr &amp;amp; 3) * 8;
val = mem_get_word(read_addr &amp;amp; (~3)) &amp;gt;&amp;gt; off;
val |= mem_get_word(read_addr &amp;amp; (~3) + 4) &amp;lt;&amp;lt; (32 - off);
&lt;/code&gt;&lt;p&gt;…but instead, we use the one tool HLSL gives us to avoid multiple inlining, loops with the &lt;code&gt;[loop]&lt;/code&gt; attribute that prevents them from being unrolled:&lt;/p&gt;&lt;code&gt;uint w1 = 0, w2 = 0;
[loop]
for (uint ui = 0; ui &amp;lt; ((read_addr &amp;amp; 0x3) ? 2 : 1); ui++) {
    uint tmp = mem_get_word((read_addr &amp;amp; (~0x3)) + 0x4 * ui);
    [flatten]
    if (ui) { w2 = tmp; }
    else { w1 = tmp; }
}
val = w1 &amp;gt;&amp;gt; ((do_mem_read &amp;amp; 0x3) * 8);
val |= w2 &amp;lt;&amp;lt; ((4 - (do_mem_read &amp;amp; 0x3)) * 8);
&lt;/code&gt;&lt;p&gt;There are several places in the code that seemingly make no sense, but are actually intentionally written with the goal of avoiding inlining. Try to keep that in mind, if you dare read through the source yourself.&lt;/p&gt;&lt;p&gt;[6] there is a &lt;code&gt;[call]&lt;/code&gt; attribute for switch/case, but once again I don’t know why you wouldn’t just use &lt;code&gt;[forcecase]&lt;/code&gt;, in my testing it unconditionally made performance worse - it does however actually compile to a jump and return, meaning the capability must exist in shader assembly, but even functions with &lt;code&gt;[noinline]&lt;/code&gt; (which is a valid attribute) are always inlined… ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Excursion: Debug View&lt;/head&gt;&lt;p&gt;For debugging purposes, and later on also actual data extraction, we need a way to communicate values from our shader to the user. And ideally not just the enduser, but also Udon, where we can further process the data on the CPU. Udon does not expose &lt;code&gt;Graphics.Blit&lt;/code&gt;, which is the usual Unity way of reading shader output to the CPU, so we need some trickery again.&lt;/p&gt;&lt;p&gt;The only way currently to get pixel data from a shader into Udon is via the &lt;code&gt;OnPostRender&lt;/code&gt; callback. If the behaviour is on a &lt;code&gt;Camera&lt;/code&gt; object, this will be called once per frame. Within it, &lt;code&gt;Buffer.ReadPixels&lt;/code&gt; can be used to retrieve the actual pixel data into a Read/Write enabled static &lt;code&gt;Texture2D&lt;/code&gt; object. The individual pixels can then be accessed as &lt;code&gt;Color&lt;/code&gt; structs. But not so fast, a Unity &lt;code&gt;Color&lt;/code&gt; contains four float values at 8-bit precision, and alpha is premultiplied - so simply reading our state/RAM texture which uses Integer-Format with 128 bpp is out of the question.&lt;/p&gt;&lt;p&gt;Instead, we write a secondary shader, a “helper” shader if you so will, that stretches the state texture (and only the state part, not the entire RAM) onto a seperate, floating-point enabled texture 6-times the width (and only using the 3 base color channels). Doing some “clever” floating-point math and bit-twiddling allows us to finally recover the original value.&lt;/p&gt;&lt;code&gt;#define PACK_MASK 0xFF
#define PACK_SHIFT 8
void pack_uint4(in uint4 data, out float3 result[6]) {
    result[0] = (data.rgb &amp;amp; PACK_MASK) / 255.0f;
    result[1] = ((data.rgb &amp;gt;&amp;gt; PACK_SHIFT) &amp;amp; PACK_MASK) / 255.0f;
    result[2] = ((data.rgb &amp;gt;&amp;gt; (PACK_SHIFT*2)) &amp;amp; PACK_MASK) / 255.0f;
    result[3] = ((data.rgb &amp;gt;&amp;gt; (PACK_SHIFT*3)) &amp;amp; PACK_MASK) / 255.0f;
    result[4].r = (data.a &amp;amp; PACK_MASK) / 255.0f;
    result[4].g = ((data.a &amp;gt;&amp;gt; PACK_SHIFT) &amp;amp; PACK_MASK) / 255.0f;
    result[4].b = ((data.a &amp;gt;&amp;gt; (PACK_SHIFT*2)) &amp;amp; PACK_MASK) / 255.0f;
    result[5].r = ((data.a &amp;gt;&amp;gt; (PACK_SHIFT*3)) &amp;amp; PACK_MASK) / 255.0f;
    result[5].gb = 0;
}
#undef PACK_SHIFT
#undef PACK_MASK
&lt;/code&gt;&lt;p&gt;(excerpt from helpers.cginc, for encoding)&lt;/p&gt;&lt;code&gt;private const float MULT = 255.0f;
private const float ADD = 0.5f;
private uint decodePackedData(int x, int y, int c)
{
    Color[] col = new Color[6] {
        Buffer.GetPixel(x, y),
        Buffer.GetPixel(x + 128, y),
        Buffer.GetPixel(x + 128*2, y),
        Buffer.GetPixel(x + 128*3, y),
        Buffer.GetPixel(x + 128*4, y),
        Buffer.GetPixel(x + 128*5, y)
    };

    switch (c) {
        case 0:
            return (
                (uint)(col[0].r * MULT + ADD) |
                ((uint)(col[1].r * MULT + ADD) &amp;lt;&amp;lt; 8) |
                ((uint)(col[2].r * MULT + ADD) &amp;lt;&amp;lt; 16) |
                ((uint)(col[3].r * MULT + ADD) &amp;lt;&amp;lt; 24)
            );
        // ...
    }
}
&lt;/code&gt;&lt;p&gt;(excerpt from NixDebug.cs, for decoding - this file is in desperate need of a cleanup :/)&lt;/p&gt;&lt;p&gt;(the debug display as seen in-game, the spherical buttons allow for single-stepping)&lt;/p&gt;&lt;p&gt;This is fairly expensive, especially since it’s running in Udon, so we limit the rendering of this &lt;code&gt;Camera&lt;/code&gt; to once every 15 frames or so. Certainly not pretty, but works well enough for debugging (and unfortunately also some device state).&lt;/p&gt;&lt;head rend="h1"&gt;MMU and Devices&lt;/head&gt;&lt;p&gt;The emulator includes a full SV32 memory management unit. I didn’t even plan on adding this at first, but it turns out Linux only supports NOMMU mode on 64-bit RISC-V. I suppose this project is a fairly niche use-case…&lt;/p&gt;&lt;p&gt;Fortunately, this ended up being easier than expected. I’m not sure what it was about the MMU, but it sounded quite difficult at first, only to turn out to be a straightforward implementation of the paging algorithm described in the RISC-V privileged spec.&lt;/p&gt;&lt;p&gt;Once again, the two-layer pagewalk is performed with avoiding inlining in mind. The &lt;code&gt;load_page&lt;/code&gt; function only has one callsite, with the recursive walk taken care of by a loop. I felt that the MMU logic was optimized enough that I could get away with using &lt;code&gt;mem_get_cached_or_tex&lt;/code&gt;, which includes the cache logic - this means that page tables are fully coherent, and &lt;code&gt;sfence.vma&lt;/code&gt; (what would be a TLB flush on x86) can be a no-op.&lt;/p&gt;&lt;p&gt;There are two devices on the emulated SoC that can issue interrupts - the CLINT timer and the UART. Additionally, software interrupts into both machine and supervisor mode are supported as well. All of this is covered under the umbrella term “trap handling”, which deals with IRQs and exceptions. Most of this logic is borrowed fairly directly from riscv-rust again, with the exception being that PLIC and CLINT are handled all at once.[7]&lt;/p&gt;&lt;p&gt;The timer’s frequency is in sync with the CPU clock, i.e. one clock cycle equals one timer tick. That being said, this is not what our device tree is communicating to Linux. The frequency given as &lt;code&gt;timebase-frequency = &amp;lt;0x1000000&amp;gt;;&lt;/code&gt; ranges in the MHz, obviously way faster than what it actually runs at. I’m not entirely certain why that is necessary, but if I set this to a more natural 200 kHz-ish, Linux schedules it’s own timer interrupt so frequently as to completely stall the boot process.&lt;/p&gt;&lt;p&gt;The UART is a bit more tricky: While the emulator-facing side is a fairly simple 8250/16550a serial port, it also needs to communicate data out to the user and read inputs.&lt;/p&gt;&lt;p&gt;Output is currently handled via a ring-buffer that is shared with Udon using the same mechanism as the Debug View mentioned above. Udon then simply puts the characters to a Unity UI &lt;code&gt;Canvas&lt;/code&gt;. I plan on replacing this with a fully shader-based terminal renderer in the future, this would also allow me to properly implement ANSI/VT100 escape codes - &lt;code&gt;vim&lt;/code&gt; vs &lt;code&gt;emacs&lt;/code&gt; live debate in VRChat anyone?&lt;/p&gt;&lt;p&gt;(a bug in the UART output causing me to boot the knockoff “ninux” built with “GNU Bnnutils”)&lt;/p&gt;&lt;p&gt;Input is rather simple too, using a regular shader parameter to pass the input ASCII character from Udon (specifically a modified version of @FairlySadPanda’s Keyboard script) to the shader. It also needs the Debug View mechanism however, since the guest running in the emulator might not acknowledge the received character, in which case it will remain in the buffer and &lt;code&gt;RBR&lt;/code&gt; will stay set. This of course also limits input speed to how often we decide to render the performance-hungry debug &lt;code&gt;Camera&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;There is currently no disk emulated, since VRChat doesn’t support world persistancy at the moment anyway. Linux boots entirely from RAM, the initramfs stays mounted as the rootfs.&lt;/p&gt;&lt;p&gt;[7] Side-note that I mention for no particular reason and definitely didn’t spend a full day tracking down a related bug on: Did you know that bitwise negate in Rust is &lt;code&gt;!&lt;/code&gt;, which, if copied to C, will compile successfully and without warning, but actually perform a boolean negate? Now you do! &lt;code&gt;~&lt;/code&gt; is what you need, obviously. ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Payloads&lt;/head&gt;&lt;p&gt;Speaking of the initramfs, compiling software to run on the emulator is suprisingly straightforward. I used Buildroot to generate a riscv32 GNU toolchain for cross-compiling on my host, and also to generate a cpio image containing BusyBox, QuickJS and my little &lt;code&gt;init&lt;/code&gt; script to print a neat ASCII art logo.&lt;/p&gt;&lt;p&gt;The kernel itself is version 5.13.5, which was the latest stable before the presentation. It runs completely stock with an &lt;code&gt;allnoconfig&lt;/code&gt; and only configuring what’s absolutely necessary, but I did patch in a few tweaks. At the moment, these consist of:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Not poisoning boot memory, as that takes too long and is mostly for security (which, as you might have guessed, does not have the highest priority in this project)&lt;/item&gt;&lt;item&gt;Printing more information during initramfs loading (as otherwise it just looks like it got stuck for a while; did I mention memory write/copy is really slow?)&lt;/item&gt;&lt;item&gt;Currently disabled, but for future use a paravirtualized &lt;code&gt;memcpy&lt;/code&gt;implementation, that uses custom CSR registers to copy memory in the&lt;code&gt;Commit&lt;/code&gt;stage instead of going through L1 cache&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I have a prototype of the last point working now, but before the presentation some last-minute bugs prevented me from showing it off.&lt;/p&gt;&lt;p&gt;Of course, Linux is not the only thing that runs on the emulator. The GitHub has some instructions on how to build other payloads. Aside from a very basic bare-metal C program to test functionality, the two more interesting ones are Micropython and Rust-Test.&lt;/p&gt;&lt;p&gt;The first one, Micropython, provides a Python 3 REPL where you can experiment with writing your own code live in VRChat. The benefit of it being that it boots way quicker than Linux. I had to add a riscv32 port myself, based on the existing riscv64 version, it certainly isn’t the cleanest but it boots and does what it’s supposed to showcase.&lt;/p&gt;&lt;p&gt;(image credit: @pema99, a sierpiński triangle rendered with Micropython)&lt;/p&gt;&lt;p&gt;The Rust-Test or rust_payload program is my experiment in building native, &lt;code&gt;no-std&lt;/code&gt; Rust for use on the emulator. I needed to patch the &lt;code&gt;rustc&lt;/code&gt; compiler to not emit compressed instructions (which are not implemented, as decoding them would only take more assembly-space and RAM is actually the one resource we have more than enough of). This was among the first things to run successfully on the emulator!&lt;/p&gt;&lt;p&gt;This one gave me some interesting ideas for potential future use-cases as well. Imagine having an interface to call Unity functions from the emulator (e.g. via the previously mentioned debug interface), and then writing your world scripts in Rust. Probably too slow to be useful, but an intriguing concept.&lt;/p&gt;&lt;p&gt;And just to have it noted, all payloads (aside from the bare-metal test) run on top of OpenSBI, which, if you’re coming from x86 you can think of as sort of a “BIOS” or “firmware”. It runs in machine mode, handles basic initialization tasks and prepares the environment for the stage-2 payload. It also provides some functionality to the next stage running in supervisor mode, most importantly timer scheduling (which requires machine privileges) and a basic UART driver (really useful in the Rust-Demo, as we can print to the console easily using it).&lt;/p&gt;&lt;p&gt;(me standing in front of OpenSBI in VR for the first time)&lt;/p&gt;&lt;head rend="h1"&gt;The End?&lt;/head&gt;&lt;p&gt;This was a big project for me, spanning over several months and bringing together many areas of knowledge I had aquired so far.&lt;/p&gt;&lt;p&gt;During development, I kept this project a secret for the longest time - I just love the thrill and payoff that comes with presenting something that absolutely nobody expected to see. Making this in VRChat has not only provided an additional challenge to overcome, but also brought with it the potential of demonstrating this live, in front of an audience, and then continue to chat with talented creators from all over. I thank everyone that answered my sometimes cryptic requests on Discord and in VRChat itself, and also everyone that didn’t ask what I was even working on when I frustratedly vented about something (probably the shader compiler) again.&lt;/p&gt;&lt;p&gt;This project has given me the opportunity to learn about the inner workings of RISC-V, it taught me more about the Linux Kernel’s boot process and hardware interface than most people would want to know, and it gave me an excuse to dive deeper and deeper into the magical world of shaders.&lt;/p&gt;&lt;p&gt;Once again, feel free to read the full code on GitHub, or check out the world for yourself in VRChat - I’m always happy to chat in person, if you manage to catch me there :)&lt;/p&gt;&lt;p&gt;I’ll probably continue working on this project for a while, I still have a bunch of ideas at the ready. Maybe, just maybe, I’ll even write more blog posts about it.&lt;/p&gt;&lt;p&gt;So until next time,&lt;/p&gt;&lt;p&gt;~ _pi_&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45881404</guid><pubDate>Mon, 10 Nov 2025 21:50:03 +0000</pubDate></item><item><title>High-performance 2D graphics rendering on the CPU using sparse strips [pdf]</title><link>https://github.com/LaurenzV/master-thesis/blob/main/main.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45881568</guid><pubDate>Mon, 10 Nov 2025 22:05:16 +0000</pubDate></item><item><title>Warren Buffett's final shareholder letter [pdf]</title><link>https://berkshirehathaway.com/news/nov1025.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45882837</guid><pubDate>Tue, 11 Nov 2025 00:51:44 +0000</pubDate></item><item><title>I hate screenshots of text</title><link>https://parkscomputing.com/page/i-hate-screenshots-of-text</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45883124</guid><pubDate>Tue, 11 Nov 2025 01:36:47 +0000</pubDate></item><item><title>The 'Toy Story' You Remember</title><link>https://animationobsessive.substack.com/p/the-toy-story-you-remember</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45883788</guid><pubDate>Tue, 11 Nov 2025 03:17:43 +0000</pubDate></item><item><title>Hiring a developer as a small indie studio in 2025</title><link>https://www.ballardgames.com/tales/hiring-dev-2025/</link><description>&lt;doc fingerprint="221893132c65c5a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hiring a developer as a small indie studio (in 2025)&lt;/head&gt;
    &lt;p&gt;By Victor Hurdugaci on Nov 10, 2025&lt;/p&gt;
    &lt;p&gt;When I was at Electronic Arts or Microsoft, hiring was a multi-tier, bureaucratic process. There was a dedicated chain for budget approval, posting approval, initial filtering, screening, and offer negotiation. As a hiring manager, I only showed up for the final interview. Even at PlayerWON, which was only about 100 people, a lot of that workload was still handed off.&lt;/p&gt;
    &lt;p&gt;But back then, I was dealing with maybe a dozen applicants max. Hiring in 2025 is extremely challenging compared to any other year. From a company perspective, thereâs a lack of funds, and even as an unknown indie studio, we get hundreds of applicants. And from a candidate perspective, there are not enough jobs.&lt;/p&gt;
    &lt;p&gt;We recently hired a software developer for Few Shall Return. At the time of posting, Ballard Games was just three people. The three of us covered every single step of the hiring funnel.&lt;/p&gt;
    &lt;p&gt;We posted the job on our social media, the Seattle Indies Discord, and Work with Indies. Most of the traffic came from Work with Indies â no formal connection, but the results were great! –. Our listing went live at 11:30 AM on October 15th, and we had to ask them to shut it down by 6:30 PM on October 17th because we had too many candidates. In the end, we collected 159 applications.&lt;/p&gt;
    &lt;p&gt;Remember, we don’t have any fancy tracking software. Every single application hits our email inbox and we review them manually.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, how do we manage that volume with limited time and a small team?&lt;/head&gt;
    &lt;p&gt;Our most valuable resource right now is time, and we have to be hyper-efficient.&lt;/p&gt;
    &lt;p&gt;For hiring, we usually sift through everyone twice. The first pass is just to get a feel for the field and remove any application that is not relevant for the role. The second pass is where we actually try to give everyone a fair look. We do this a few days after the job closes, but if anyone submits too late, we probably won’t review them unless the initial pool was completely dry. Unfortunately, this time, we had 46 late applicants we didn’t even look at. This initial triage is the toughest part; we have to reject people who might be great just because we can’t physically talk to everyone.&lt;/p&gt;
    &lt;p&gt;If we see potential, the first step is always asking the candidate upfront for their expected salary, availability, and whether they want full-time or part-time. Since we are focused on efficiency, we need to respect people’s time as much as our own. Most candidates appreciate it; for example, it immediately filtered out a very qualified candidate whose salary ask was 4 times our budget.&lt;/p&gt;
    &lt;p&gt;Itâs important to say this: most indie studios can’t match salary offers from EA or Activision/Microsoft. We compete on other things: freedom and control. In a small company, you own a much larger piece of what you build and you can impact the direction of the game.&lt;/p&gt;
    &lt;p&gt;If the initial conversation is good for both sides, we send a small take-home assignment. We keep it simple and relevant: here’s the take-home assignment. For a coding role, we need to see code, but we strongly dislike the sterile, puzzle-based LeetCode style. Our take-home lets candidates code in their own environment and they get a real taste of the work. It’s a two-way street, and we want people genuinely interested in the problem. This approach is effective and we even had one candidate back out after realizing the assignment was beyond their current expertise.&lt;/p&gt;
    &lt;p&gt;Finally, if the assignment submission looks solid, we bring the candidate in for a series of video chats with the whole team. During one of those calls, we review the take-home submission with the candidate to check if they wrote it and if they actually understand it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical advice for how to run the screening workflow without extra tools&lt;/head&gt;
    &lt;p&gt;Use labels in Gmail; that’s it!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All applications initially start in &lt;code&gt;1. New&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;When we review an application, we move it to either &lt;code&gt;9. No&lt;/code&gt;or&lt;code&gt;2. Reviewed&lt;/code&gt;. “Reviewed” means we like the candidate, but we wait to bulk-email outreach.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;2. Reviewed/Contacted&lt;/code&gt;is where threads go after we send the initial email.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;2. Reviewed/Hold&lt;/code&gt;is for replies where we might proceed, but there’s a temporary snag (e.g., availability mismatch).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home&lt;/code&gt;threads are for candidates we sent the assignment to who haven’t replied yet.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home/To review&lt;/code&gt;is our manual inbox for new submissions we need to look at.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home/Good&lt;/code&gt;holds submissions we want to interview.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;5. Interview&lt;/code&gt;is for candidates currently going through the full loop.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;9. No&lt;/code&gt;is for rejections. At the very end, we go through this folder and send a final notification to everyone we replied to at least once but ultimately passed on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The purpose of the prefix numbers is too keep the labels sorted by the process order instead of the actual step name:&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical advice for how to design a take-home assignment&lt;/head&gt;
    &lt;p&gt;You must ask candidates to solve problems directly related to the role. If you’re hiring a game programmer, knowing how to detect fraud in bank transactions is irrelevant knowledge if that task never appears on the job. The assignment’s outcome should tell you one thing: can this person do the job you need them to do? In our case, we were looking for a generalist who can do both Unity and services coding.&lt;/p&gt;
    &lt;p&gt;So, instead of LeetCode, create a heavily scoped-down version of a real problem your team recently solved. This achieves two goals: you can tell if the candidate has the skills needed and it lets the candidate gauge whether they actually enjoy the type of work they would be doing daily.&lt;/p&gt;
    &lt;p&gt;A few other things to consider when designing the assigment:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Only assign tasks that are small implementations of existing work. Never ask candidates to build core features or solve problems the studio hasn’t already solved internally just to source free labor. That’s not cool!&lt;/item&gt;
      &lt;item&gt;The assignment should take no longer than the time you would normally allot for a live coding or whiteboard interview session. Respect their time.&lt;/item&gt;
      &lt;item&gt;Always give candidates a channel to ask clarifying questions about the requirements.&lt;/item&gt;
      &lt;item&gt;If a candidate submits a partial solution, let them know. They may have genuinely misunderstood a requirement, rather than failing to deliver.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Overview&lt;/head&gt;
    &lt;p&gt;Finally, here’s an overview of the flow of candidates for this role. It took us about 4 weeks to complete the process and hire someone:&lt;/p&gt;
    &lt;p&gt;Click on the image to see the larger version&lt;/p&gt;
    &lt;p&gt;This article is part of The Tales of a Small Indie Studio series. Click here to check out out the other articles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45883995</guid><pubDate>Tue, 11 Nov 2025 04:04:24 +0000</pubDate></item><item><title>AI documentation you can talk to, for every repo</title><link>https://deepwiki.com/</link><description>&lt;doc fingerprint="6cf85aef75cc122c"&gt;
  &lt;main&gt;
    &lt;p&gt;Bring data to life with SVG, Canvas and HTML. :bar_chart::chart_with_upwards_trend::tada:&lt;/p&gt;
    &lt;p&gt;Rich is a Python library for rich text and beautiful formatting in the terminal.&lt;/p&gt;
    &lt;p&gt;DeepWiki provides up-to-date documentation you can talk to, for every repo in the world. Think Deep Research for GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45884169</guid><pubDate>Tue, 11 Nov 2025 04:38:24 +0000</pubDate></item></channel></rss>