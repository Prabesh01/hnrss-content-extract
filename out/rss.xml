<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 19 Nov 2025 15:37:45 +0000</lastBuildDate><item><title>Gemini 3</title><link>https://blog.google/products/gemini/gemini-3/</link><description>&lt;doc fingerprint="f9d7a1cf9b3f9a95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A new era of intelligence with Gemini 3&lt;/head&gt;
    &lt;head rend="h3"&gt;A note from Google and Alphabet CEO Sundar Pichai:&lt;/head&gt;
    &lt;p&gt;Nearly two years ago we kicked off the Gemini era, one of our biggest scientific and product endeavors ever undertaken as a company. Since then, it’s been incredible to see how much people love it. AI Overviews now have 2 billion users every month. The Gemini app surpasses 650 million users per month, more than 70% of our Cloud customers use our AI, 13 million developers have built with our generative models, and that is just a snippet of the impact we’re seeing.&lt;/p&gt;
    &lt;p&gt;And we’re able to get advanced capabilities to the world faster than ever, thanks to our differentiated full stack approach to AI innovation — from our leading infrastructure to our world-class research and models and tooling, to products that reach billions of people around the world.&lt;/p&gt;
    &lt;p&gt;Every generation of Gemini has built on the last, enabling you to do more. Gemini 1’s breakthroughs in native multimodality and long context window expanded the kinds of information that could be processed — and how much of it. Gemini 2 laid the foundation for agentic capabilities and pushed the frontiers on reasoning and thinking, helping with more complex tasks and ideas, leading to Gemini 2.5 Pro topping LMArena for over six months.&lt;/p&gt;
    &lt;p&gt;And now we’re introducing Gemini 3, our most intelligent model, that combines all of Gemini’s capabilities together so you can bring any idea to life.&lt;/p&gt;
    &lt;p&gt;It’s state-of-the-art in reasoning, built to grasp depth and nuance — whether it’s perceiving the subtle clues in a creative idea, or peeling apart the overlapping layers of a difficult problem. Gemini 3 is also much better at figuring out the context and intent behind your request, so you get what you need with less prompting. It’s amazing to think that in just two years, AI has evolved from simply reading text and images to reading the room.&lt;/p&gt;
    &lt;p&gt;And starting today, we’re shipping Gemini at the scale of Google. That includes Gemini 3 in AI Mode in Search with more complex reasoning and new dynamic experiences. This is the first time we are shipping Gemini in Search on day one. Gemini 3 is also coming today to the Gemini app, to developers in AI Studio and Vertex AI, and in our new agentic development platform, Google Antigravity — more below.&lt;/p&gt;
    &lt;p&gt;Like the generations before it, Gemini 3 is once again advancing the state of the art. In this new chapter, we’ll continue to push the frontiers of intelligence, agents, and personalization to make AI truly helpful for everyone.&lt;/p&gt;
    &lt;p&gt;We hope you like Gemini 3, we'll keep improving it, and look forward to seeing what you build with it. Much more to come!&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing Gemini 3: our most intelligent model that helps you bring any idea to life&lt;/head&gt;
    &lt;p&gt;Demis Hassabis, CEO of Google DeepMind and Koray Kavukcuoglu, CTO of Google DeepMind and Chief AI Architect, Google, on behalf of the Gemini team&lt;/p&gt;
    &lt;p&gt;Today we’re taking another big step on the path toward AGI and releasing Gemini 3.&lt;/p&gt;
    &lt;p&gt;It’s the best model in the world for multimodal understanding and our most powerful agentic and vibe coding model yet, delivering richer visualizations and deeper interactivity — all built on a foundation of state-of-the-art reasoning.&lt;/p&gt;
    &lt;p&gt;We’re beginning the Gemini 3 era by releasing Gemini 3 Pro in preview and making it available today across a suite of Google products so you can use it in your daily life to learn, build and plan anything. We’re also introducing Gemini 3 Deep Think — our enhanced reasoning mode that pushes Gemini 3 performance even further — and giving access to safety testers before making it available to Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;State-of-the-art reasoning with unprecedented depth and nuance&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro can bring any idea to life with its state-of-the-art reasoning and multimodal capabilities. It significantly outperforms 2.5 Pro on every major AI benchmark.&lt;/p&gt;
    &lt;p&gt;It tops the LMArena Leaderboard with a breakthrough score of 1501 Elo. It demonstrates PhD-level reasoning with top scores on Humanity’s Last Exam (37.5% without the usage of any tools) and GPQA Diamond (91.9%). It also sets a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex.&lt;/p&gt;
    &lt;p&gt;Beyond text, Gemini 3 Pro redefines multimodal reasoning with 81% on MMMU-Pro and 87.6% on Video-MMMU. It also scores a state-of-the-art 72.1% on SimpleQA Verified, showing great progress on factual accuracy. This means Gemini 3 Pro is highly capable at solving complex problems across a vast array of topics like science and mathematics with a high degree of reliability.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is state-of-the-art across a range of key AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro also brings a new level of depth and nuance to every interaction. Its responses are smart, concise and direct, trading cliché and flattery for genuine insight — telling you what you need to hear, not just what you want to hear. It acts as a true thought partner that gives you new ways to understand information and express yourself, from translating dense scientific concepts by generating code for high-fidelity visualizations to creative brainstorming.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can code a visualization of plasma flow in a tokamak and write a poem capturing the physics of fusion.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gemini 3 Deep Think&lt;/head&gt;
    &lt;p&gt;Gemini 3 Deep Think mode pushes the boundaries of intelligence even further, delivering a step-change in Gemini 3’s reasoning and multimodal understanding capabilities to help you solve even more complex problems.&lt;/p&gt;
    &lt;p&gt;In testing, Gemini 3 Deep Think outperforms Gemini 3 Pro’s already impressive performance on Humanity’s Last Exam (41.0% without the use of tools) and GPQA Diamond (93.8%). It also achieves an unprecedented 45.1% on ARC-AGI-2 (with code execution, ARC Prize Verified), demonstrating its ability to solve novel challenges.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Deep Think mode excels on some of the most challenging AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gemini 3 helps you learn, build and plan anything&lt;/head&gt;
    &lt;head rend="h3"&gt;Learn anything&lt;/head&gt;
    &lt;p&gt;Gemini was built from the start to seamlessly synthesize information about any topic across multiple modalities, including text, images, video, audio and code. Gemini 3 pushes the frontier of multimodal reasoning to help you learn in ways that make sense for you by combining its state-of-the-art reasoning, vision and spatial understanding, leading multilingual performance, and 1 million-token context window.&lt;/p&gt;
    &lt;p&gt;For example, if you want to learn how to cook in your family tradition, Gemini 3 can decipher and translate handwritten recipes in different languages into a shareable family cookbook. Or if you want to learn about a new topic, you can give it academic papers, long video lectures or tutorials and it can generate code for interactive flashcards, visualizations or other formats that will help you master the material. It can even analyze videos of your pickleball match, identify areas where you can improve and generate a training plan for overall form improvements.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you learn and preserve family cooking traditions. Try it in Gemini Canvas.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you analyze complex information like research papers and can generate code for an interactive guide.&lt;/p&gt;
    &lt;p&gt;Get expert-level sports analysis on your pickleball match to help improve your game.&lt;/p&gt;
    &lt;p&gt;To help you make better sense of information on the web, AI Mode in Search now uses Gemini 3 to enable new generative UI experiences like immersive visual layouts and interactive tools and simulations, all generated completely on the fly based on your query.&lt;/p&gt;
    &lt;p&gt;Learn a complex topic like how RNA polymerase works with generative UI in AI Mode in Search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build anything&lt;/head&gt;
    &lt;p&gt;Building on the success of 2.5 Pro, Gemini 3 delivers on the promise of bringing any idea to life for developers. It’s exceptional at zero-shot generation and handles complex prompts and instructions to render richer, more interactive web UI.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is the best vibe coding and agentic coding model we’ve ever built – making our products more autonomous and boosting developer productivity. It tops the WebDev Arena leaderboard by scoring an impressive 1487 Elo. It also scores 54.2% on Terminal-Bench 2.0, which tests a model’s tool use ability to operate a computer via terminal and it greatly outperforms 2.5 Pro on SWE-bench Verified (76.2%), a benchmark that measures coding agents.&lt;/p&gt;
    &lt;p&gt;You can now build with Gemini 3 in Google AI Studio, Vertex AI, Gemini CLI and our new agentic development platform, Google Antigravity. It’s also available in third-party platforms like Cursor, GitHub, JetBrains, Manus, Replit and more.&lt;/p&gt;
    &lt;p&gt;Code a retro 3D spaceship game with richer visualizations and improved interactivity. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Bring your imagination to life by building, deconstructing and remixing detailed 3D voxel art using code. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Build a playable sci-fi world with shaders using Gemini 3. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;You can vibe code richer, more interactive web UI and apps with Gemini 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introducing a new agent-first development experience&lt;/head&gt;
    &lt;p&gt;As model intelligence accelerates with Gemini 3, we have the opportunity to reimagine the entire developer experience. Today we’re releasing Google Antigravity, our new agentic development platform that enables developers to operate at a higher, task-oriented level.&lt;/p&gt;
    &lt;p&gt;Using Gemini 3’s advanced reasoning, tool use and agentic coding capabilities, Google Antigravity transforms AI assistance from a tool in a developer’s toolkit into an active partner. While the core of Google Antigravity is a familiar AI IDE experience, its agents have been elevated to a dedicated surface and given direct access to the editor, terminal and browser. Now, agents can autonomously plan and execute complex, end-to-end software tasks simultaneously on your behalf while validating their own code.&lt;/p&gt;
    &lt;p&gt;In addition to Gemini 3 Pro, Google Antigravity also comes tightly coupled with our latest Gemini 2.5 Computer Use model for browser control and our top-rated image editing model Nano Banana (Gemini 2.5 Image).&lt;/p&gt;
    &lt;p&gt;Google Antigravity uses Gemini 3 to drive an end-to-end agentic workflow for a flight tracker app. The agent independently plans, codes the application and validates its execution through browser-based computer use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Plan anything&lt;/head&gt;
    &lt;p&gt;Since introducing the agentic era with Gemini 2, we’ve made a lot of progress, not only advancing Gemini’s coding agent abilities, but also improving its ability to reliably plan ahead over longer horizons. Gemini 3 demonstrates this by topping the leaderboard on Vending-Bench 2, which tests longer horizon planning by managing a simulated vending machine business. Gemini 3 Pro maintains consistent tool usage and decision-making for a full simulated year of operation, driving higher returns without drifting off task.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro demonstrates better long-horizon planning to generate significantly higher returns compared to other frontier models.&lt;/p&gt;
    &lt;p&gt;This means Gemini 3 can better help you get things done in everyday life. By combining deeper reasoning with improved, more consistent tool use, Gemini 3 can take action on your behalf by navigating more complex, multi-step workflows from start to finish — like booking local services or organizing your inbox — all while under your control and guidance.&lt;/p&gt;
    &lt;p&gt;Google AI Ultra subscribers can try these agentic capabilities in the Gemini app with Gemini Agent today. We’ve learned a lot improving Gemini’s agentic capabilities, and we’re excited to see how you use it as we expand to more Google products soon.&lt;/p&gt;
    &lt;p&gt;Gemini Agent can help you organize your Gmail inbox. Try it now in the Gemini app for Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Gemini 3 responsibly&lt;/head&gt;
    &lt;p&gt;Gemini 3 is our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. The model shows reduced sycophancy, increased resistance to prompt injections and improved protection against misuse via cyberattacks.&lt;/p&gt;
    &lt;p&gt;In addition to our in-house testing for the critical domains in our Frontier Safety Framework, we've also partnered on evaluations with world-leading subject matter experts, provided early access to bodies like the UK AISI, and obtained independent assessments from industry experts like Apollo, Vaultis, Dreadnode and more. For more information, see the Gemini 3 model card.&lt;/p&gt;
    &lt;head rend="h2"&gt;The next era of Gemini&lt;/head&gt;
    &lt;p&gt;This is just the start of the Gemini 3 era. As of today, Gemini 3 starts rolling out:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For everyone in the Gemini app and for Google AI Pro and Ultra subscribers in AI Mode in Search&lt;/item&gt;
      &lt;item&gt;For developers in the Gemini API in AI Studio, our new agentic development platform, Google Antigravity; and Gemini CLI&lt;/item&gt;
      &lt;item&gt;For enterprises in Vertex AI and Gemini Enterprise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For Gemini 3 Deep Think mode, we’re taking extra time for safety evaluations and input from safety testers before making it available to Google AI Ultra subscribers in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We plan to release additional models to the Gemini 3 series soon so you can do more with AI. We look forward to getting your feedback and seeing what you learn, build and plan with Gemini.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45967211</guid><pubDate>Tue, 18 Nov 2025 15:09:38 +0000</pubDate></item><item><title>Google Antigravity</title><link>https://antigravity.google/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45967814</guid><pubDate>Tue, 18 Nov 2025 15:47:38 +0000</pubDate></item><item><title>The code and open-source tools I used to produce a science fiction anthology</title><link>https://compellingsciencefiction.com/posts/the-code-and-open-source-tools-i-used-to-produce-a-science-fiction-anthology.html</link><description>&lt;doc fingerprint="2fc09a362ef7ad11"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;&lt;p&gt; Last month I published &lt;/p&gt;Think Weirder: The Year's Best Science Fiction Ideas&lt;p&gt;, a 16-story anthology featuring Greg Egan, Isabel J. Kim, Ray Nayler, Caroline M. Yoachim, and twelve other wonderful authors. The book ended up being the #1 New Release in the Short Stories Anthologies category for a short time on Amazon, outselling many other newly released short story anthologies published by the big NYC publishers with large marketing departments. &lt;/p&gt;&lt;/div&gt;
      &lt;p&gt; I'm not a professional publisher. I have a full-time job and two small kids, so all of this work happened after my kids went to sleep. I had to use my time judiciously, which meant creating an efficient process. Fortunately I'm a programmer, and it turns out that programming skills translate surprisingly well to book publishing. This post is about how I built a complete publishing pipeline using Python, YAML files, and LaTeX â and why you might want to do something similar if you're considering publishing a book. I know that by writing this I'll have my choices questioned by professional designers, but hopefully the software concepts will be helpful. &lt;/p&gt;
      &lt;p&gt; My initial thought: can I really do ALL of this? &lt;/p&gt;
      &lt;p&gt; When I started this project, I had some worries. Professional publishers have entire departments of specialists. How could I possibly handle all of that myself? &lt;/p&gt;
      &lt;p&gt; The answer turned out to be: build tools that automate the repetitive parts, and use simple file formats that make everything transparent and debuggable. &lt;/p&gt;
      &lt;p&gt; Step 1: Tracking stories with plain text files &lt;/p&gt;
      &lt;p&gt; The first challenge was tracking hundreds of candidate stories from different magazines. I read 391 stories published in 2024 before selecting the final 16. That's a lot of stories to keep organized. &lt;/p&gt;
      &lt;p&gt; I could have used a spreadsheet, but I went with plain YAML files instead. Here's why this worked well for me: &lt;/p&gt;
      &lt;div&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Git-friendly: Every decision I made was tracked in version control&lt;/item&gt;
          &lt;item&gt;Human-readable: I could open any file in a text editor and understand what I was looking at&lt;/item&gt;
          &lt;item&gt;Easy to build scripts around: I wrote several Python functions to do different kinds of metadata introspection that I'll go through&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
      &lt;p&gt; The structure looks like this: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;data/
  story-progress.yaml       # Central tracking file
  markets.yaml              # Magazine metadata
  themes.yaml               # Theme occurrence tracking
  subgenres.yaml            # Subgenre tallies
stories/
  clarkesworld-magazine/
    nelson_11_24.yaml       # Individual story files
    pak_06_24.yaml
  reactor-magazine/
    larson_breathing.yaml
  ...&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Each story file is pure YAML containing the full story text plus metadata: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;title: "Twenty-Four Hours"
author: H.H. Pak
market: clarkesworld-magazine
url: https://clarkesworldmagazine.com/pak_06_24/
word_count: 4540
year: 2024
slug: pak_06_24
summary: ...&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Not all stories have public URLs available, but that's OK because all of the fields are optional. The central &lt;code&gt;story-progress.yaml&lt;/code&gt; tracks editorial state:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;clarkesworld-magazine-nelson_11_24:
  title: "LuvHomeâ¢"
  author: Resa Nelson
  market: clarkesworld-magazine
  status: accepted  # or: not_started/relevant/rejected
  date_added: '2024-09-08T08:22:47.033192'&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Step 2: A simple command-line tool &lt;/p&gt;
      &lt;p&gt; I built a small Python CLI tool (&lt;code&gt;se.py&lt;/code&gt;) to help me navigate all this data. Since I do all this work at night after my kids go to sleep, I wanted something fast that mirrored a lot of the other work I do on the command line. The tool is simple:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;python se.py âhelp
usage: se.py [-h] {markets,stories,relevant,decide,accepted,compile} ...

Story Evaluator CLI

positional arguments:
  {markets,stories,relevant,decide,accepted,compile}
                        Available commands
    markets             List markets
    stories             Manage stories
    relevant            List URLs for stories marked as relevant
    decide              Make accept/reject decisions on relevant stories
    accepted            Manage accepted stories
    compile             Show anthology compilation statistics

optional arguments:
  -h, âhelp            show this help message and exit&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The &lt;code&gt;compile&lt;/code&gt; command ended up being really useful â it gave me instant feedback on anthology size and composition:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;ANTHOLOGY COMPILATION STATISTICS
============================================================
Total Stories: 16
Total Word Count: 115,093 words
Average Word Count: 7,193 words
Unique Authors: 16
Markets Represented: 4

STORIES BY MARKET:
  analog-magazine: 2 stories (12.5%)
  asimovs-magazine: 2 stories (12.5%)
  clarkesworld-magazine: 10 stories (62.5%)
  reactor-magazine: 2 stories (12.5%)&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; This was really helpful during the selection process. I could quickly check how far along I was toward my ~120k word goal, and make sure I hadn't accidentally included multiple stories by the same author. &lt;/p&gt;
      &lt;p&gt; Step 3: Typesetting the print book &lt;/p&gt;
      &lt;p&gt; This part surprised me the most. I initially thought I'd have to learn Adobe InDesign or pay someone to do the typesetting. But I decided to use LaTeX instead, since I had some previous experience with it (another publishing friend sent me some of his example files, and I had some academic experience). The process worked out better than expected. &lt;/p&gt;
      &lt;p&gt; I used XeLaTeX with the &lt;code&gt;memoir&lt;/code&gt; document class. Here's what I liked about this approach:
&lt;/p&gt;
      &lt;div&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Reproducible: I can rebuild the entire book from source in a few seconds, and I can use the same templates next year&lt;/item&gt;
          &lt;item&gt;Professional typography: LaTeX handles ligatures, kerning, and line breaking better than I could manually&lt;/item&gt;
          &lt;item&gt;Custom fonts: I used Crimson Pro for body text and Rajdhani for titles&lt;/item&gt;
          &lt;item&gt;Again, version control that I'm used to: The entire book is just text files in Git&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
      &lt;p&gt; The main parts of the master file for the book are really simple: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\documentclass[final,11pt,twoside]{memoir}
\usepackage{compelling}

\begin{document}
\begin{frontmatter}
  \include{title}
  \tableofcontents
\end{frontmatter}

\begin{mainmatter}
  \include{introduction}
  \include{death-and-the-gorgon}
  \include{the-best-version-of-yourself}
  % ... 14 more stories
  \include{acknowledgements}
\end{mainmatter}
\end{document}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;div&gt;&lt;p&gt; All the formatting rules live in &lt;/p&gt;&lt;code&gt;compelling.sty&lt;/code&gt;&lt;p&gt;, a custom style package. &lt;/p&gt;Here's a link to the full, messy file&lt;p&gt;. Some highlights: &lt;/p&gt;&lt;/div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;% 6x9 inch trade paperback size
\setstocksize{9in}{6in}
\settrimmedsize{9in}{6in}{*}

% Margins
\setlrmarginsandblock{1.00in}{0.75in}{*}
\setulmarginsandblock{0.75in}{0.75in}{*}

% Typography nerding
\usepackage[final,protrusion=true,factor=1125,
            stretch=70,shrink=70]{microtype}

% Custom fonts loaded from local files
\setromanfont[
  Ligatures=TeX,
  Path=./Crimson_Pro/static/,
  UprightFont=CrimsonPro-Regular,
  BoldFont=CrimsonPro-Bold,
  ItalicFont=CrimsonPro-Italic,
  BoldItalicFont=CrimsonPro-BoldItalic
]{Crimson Pro}


\setsansfont[
  Path=./Rajdhani/,
  UprightFont=Rajdhani-Bold,
  BoldFont=Rajdhani-Bold,
  ItalicFont=Rajdhani-Bold,
  BoldItalicFont=Rajdhani-Bold
]{Rajdhani}

% Chinese font family for CJK characters
\newfontfamily\chinesefont{PingFang SC}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The &lt;code&gt;microtype&lt;/code&gt; package does a lot of subtle work with character spacing and line breaking that makes the text look professionally typeset.
&lt;/p&gt;
      &lt;p&gt; I wanted story titles in bold sans-serif with author names underneath in a lighter gray. Here's how I set that up: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\renewcommand{\chapter}[2]{
    \pagestyle{DefaultStyle}
    \stdchapter*{
        \sffamily
        \LARGE 
        \textbf{\MakeUppercase{#1}}
        \\ 
        \large 
        \color{dark-gray} 
        {\MakeUppercase{#2}}
    }
    \addcontentsline{toc}{chapter}{
        \protect\parbox[t]{\dimexpr\textwidth-3em}{
            \sffamily#1
            \\ 
            \protect\small
            \protect\color{gray}
            \protect\textit{#2}
        }
    }
    \def\leftmark{#1}
    \def\rightmark{#2}
}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; This redefines the &lt;code&gt;chapter&lt;/code&gt; command to take two arguments, the title and byline, and sets up both the chapter formatting, TOC formatting, and makes sure that the title and byline are printed in the headers on alternating pages.
&lt;/p&gt;
      &lt;p&gt; Now every story file just says: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\chapter{Death and the Gorgon}{by Greg Egan}
[story content]&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Most authors send me stories as HTML, PDF, or word, so I needed a way to convert them to LaTeX. I wrote a simple Python script to do this, which saved me a huge amount of manual formatting work. &lt;/p&gt;
      &lt;p&gt; Step 4: Creating the ebook &lt;/p&gt;
      &lt;p&gt; Print was one thing, but I also needed an ebook. This turned out to be easier than I expected because I could reuse all the LaTeX source I'd already created. &lt;/p&gt;
      &lt;p&gt; I used Pandoc to convert from LaTeX to EPUB: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;# Convert LaTeX to EPUB
pandoc 2025.tex -o Think_Weirder_2025.epub \
  âtoc \
  âepub-cover-image=cover_optimized.jpg \
  âcss=epub-style.css \
  âmetadata title="Think Weirder" \
  âmetadata author="Edited by Joe Stech"&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Pandoc's default table of contents only showed story titles. But I wanted author names too, like you see in print anthologies. EPUBs are just zipped collections of XHTML files, so I wrote a small post-processing script: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;def modify_toc(nav_content, authors):
    """Add author bylines to TOC entries."""
    pattern = r'&amp;lt;a href="([^"]+)"&amp;gt;([^&amp;lt;]+)&amp;lt;/a&amp;gt;'

    def add_author(match):
        href, title = match.group(1), match.group(2)
        chapter_id = extract_id_from_href(href)

        if chapter_id in authors:
            author = authors[chapter_id]
            return f'&amp;lt;a href="{href}"&amp;gt;{title}&amp;lt;br /&amp;gt;\n' \
                   f'&amp;lt;em&amp;gt;{author}&amp;lt;/em&amp;gt;&amp;lt;/a&amp;gt;'
        return match.group(0)

    return re.sub(pattern, add_author, nav_content)&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The script unzips the EPUB, finds the navigation file, adds author bylines, and rezips everything. Now the ebook table of contents matches the print version. &lt;/p&gt;
      &lt;p&gt; What I learned &lt;/p&gt;
      &lt;p&gt; The whole process took longer than I expected â many months of night work. The simple software I wrote really made it a feasible one-person project though, and motivates me to go through the whole process again next year. &lt;/p&gt;
      &lt;p&gt; Staying organized is crucial. When hundreds of stories are involved, it's easy to forget details, so using &lt;code&gt;se.py&lt;/code&gt; to save metadata in the moment that could be sliced and diced later was so important.
&lt;/p&gt;
      &lt;p&gt; Reproducible builds were a lifesaver. I made changes to the book layout right up until the week before publication. Because I could rebuild the entire book in seconds, and everything was backed up in git, I could experiment freely without worrying about breaking things. &lt;/p&gt;
      &lt;p&gt; Simple file formats made me comfortable. When something went wrong, I could always open a YAML file or look at the LaTeX source and understand what was happening. I never hit a point where the tools were a black box. &lt;/p&gt;
      &lt;p&gt; I didn't need to understand everything up front. I learned LaTeX details as I went (arguably I still don't really understand LaTeX). Same with Pandoc. I got something basic working first, then incrementally improved it. &lt;/p&gt;
      &lt;p&gt; Can you do this too? &lt;/p&gt;
      &lt;p&gt; If you're thinking about publishing a book â whether it's an anthology, a novel, or a collection of technical writing â I think this approach is worth considering. There's something motivating about having a detailed understanding of every step in the production process. If you have questions feel free to reach out, I love talking about this hobby! You can email me at joe@thinkweirder.com. &lt;/p&gt;
      &lt;div&gt;&lt;p&gt; And if you enjoy concept-driven science fiction that is heavy on novel ideas, check out &lt;/p&gt;Think Weirder! &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45968121</guid><pubDate>Tue, 18 Nov 2025 16:10:34 +0000</pubDate></item><item><title>Pebble, Rebble, and a path forward</title><link>https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/</link><description>&lt;doc fingerprint="fc4b101b5b1408f0"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I believe the Pebble community, Core Devices, Rebble and I all want the same thing. We love our Pebbles and want them to keep working long into the future. We love the community that has sprung up around Pebble, and how it’s persevered - next year will be the 14th anniversary of the original Kickstarter campaign!&lt;/p&gt;
      &lt;p&gt;But I have to respond to claims made by Rebble posted on their blog yesterday. I will link to their post so you can read their side of the story, and I’ve asked them to link back to this blog post from theirs.&lt;/p&gt;
      &lt;p&gt;Look - I’m the first person to call myself out when I fail. I wrote a detailed blog post about Success and Failure at Pebble and often write in detail about learning from my mistakes. But in this specific case, you’ll find that I’ve done my utmost to respect the Pebble legacy and community. Rebble is misleading the community with false accusations.&lt;/p&gt;
      &lt;p&gt;For those just passing through, here’s the TLDR: &lt;/p&gt;
      &lt;p&gt;Core Devices is a small company I started in 2025 to relaunch Pebble and build new Pebble smartwatches. Rebble is a non-profit organization that has supported the Pebble community since 2017. Rebble has done a ton of great work over the years and deserves recognition and support for that.&lt;/p&gt;
      &lt;p&gt;Core Devices and Rebble negotiated an agreement where Core would pay $0.20/user/month to support Rebble services. But the agreement broke down after over the following disagreement. &lt;/p&gt;
      &lt;p&gt;Rebble believes that they ‘100%’ own the data of the Pebble Appstore. They’re attempting to create a walled garden around 13,000 apps and faces that individual Pebble developers created and uploaded to the Pebble Appstore between 2012 and 2016. Rebble later scraped this data in 2017. &lt;/p&gt;
      &lt;p&gt;I disagree. I’m working hard to keep the Pebble ecosystem open source. I believe the contents of the Pebble Appstore should be freely available and not controlled by one organization. &lt;/p&gt;
      &lt;p&gt;Rebble posted a blog post yesterday with a bunch of false accusations, and in this post I speak to each of them.&lt;/p&gt;
      &lt;p&gt;Sections&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Dec 2016 - Pebble shut down. Some IP was sold to Fitbit. I blogged about why I think we failed. Fitbit continued to run the Pebble Appstore and web services for 1.5 years. I really appreciated that.&lt;list rend="ul"&gt;&lt;item&gt;Rebble organization grew out of the official Pebble Developers Discord.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;July 2018, Fitbit shut down the Pebble appstore.&lt;list rend="ul"&gt;&lt;item&gt;Before it shut down, Rebble (and others) scraped all 13,000 apps and metadata from the Pebble Appstore. Rebble began hosting a copy of the appstore. They created a new Dev Portal where developers could upload new apps, roughly 500 have been uploaded since July 2018.&lt;/item&gt;&lt;item&gt;Rebble also reverse engineered many Pebble web services (weather, timeline and voice transcription) and provided them as a paid service for the Pebble community.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Jan 2025 - Google open sourced PebbleOS, breathing new life into the community.&lt;/item&gt;
        &lt;item&gt;March 2025 - I announced a new company (Core Devices) and 2 new watches - store.rePebble.com&lt;/item&gt;
        &lt;item&gt;November 2025 - we finished shipping out 5,000 Pebble 2 Duos. We’re working hard on Pebble Time 2. We’re aiming to start shipping in January.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 1: ‘Rebble paid for the work that [Eric] took as a base for his commercial watches’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I think they’re accusing me of ‘stealing’ open source contributions to PebbleOS that Rebble paid for. This is entirely false.&lt;/item&gt;
        &lt;item&gt;We did not take any PebbleOS work Rebble paid for ‘as a base for [our] commercial watches’. &lt;del rend="overstrike"&gt;To my best of my knowledge&lt;/del&gt;&lt;del rend="overstrike"&gt;,&lt;/del&gt;&lt;del rend="overstrike"&gt;Rebble never paid the&lt;/del&gt;&lt;del rend="overstrike"&gt;developer who ported NimBLE into PebbleOS.&lt;/del&gt;&lt;del rend="overstrike"&gt;My best guess is that they are referring to Rebble having paid CodeCoup, the company behind&lt;/del&gt;&lt;del rend="overstrike"&gt;NimBLE&lt;/del&gt;&lt;del rend="overstrike"&gt;, to fix some bugs that affected older non-Core Devices watches. Any Rebble-sponsored CodeCoup commits are not present in our repo. In fact, the opposite is true - we paid Codecoup $10,000 to fix multiple BLE stack issues, some of them on the host side that benefit all devices, including old Pebbles.&lt;/del&gt; Update: I’m told Rebble did pay him, months later. My point is valid - when we shifted development to our repo, Rebble had not paid anything. More broadly, I reject the premise that using open source software under the terms of the license, regardless of who funds development, is ‘stealing’.&lt;/item&gt;
        &lt;item&gt;We started using our own repo for PebbleOS development because PRs on the Rebble repo reviews were taking too long. We only had one firmware engineer at the time (now we have a whopping 2!) and he felt like he was being slowed down too much. All of our contributions to PebbleOS have been 100% open source.&lt;/item&gt;
        &lt;item&gt;Overall, the feedback that PebbleOS could benefit from open governance is well taken. Long term, PebbleOS would be a good fit for open source organization with experience in open governance, like Apache or Linux Foundation. I wrote about this last week.&lt;/item&gt;
        &lt;item&gt;With our small team and fairly quick development schedule, it's true that we haven't PRed our changes into Rebble’s repo. It’s tough to prioritize this while we are busy fixing bugs and getting ready for Pebble Time 2.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 2: ‘Core took Rebble’s work’ on &lt;code&gt;libpebblecommon&lt;/code&gt; to create &lt;code&gt;libpebble3&lt;/code&gt;&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;The majority (&amp;gt;90%) of our new open source&lt;code&gt;libpebble3&lt;/code&gt; library was written by Core Devices employees.  The remainder comes from &lt;code&gt;libpebblecommon&lt;/code&gt;, another open source library written by two people.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;In April 2025, Core purchased the copyright to the &lt;code&gt;libpebblecommon&lt;/code&gt; code from the two maintainers and incorporated it into &lt;code&gt;libpebble3&lt;/code&gt;**, which is also open source**.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;All our contributions to &lt;code&gt;libpebble3&lt;/code&gt; are GPL-3.0 licensed. Here’s the motivation behind that our licensing strategy for this repo. We use the same CLA agreement as Matrix, QT and MySQL. Our CLA explicitly includes a clause that requires to Core Devices to distribute all contributions under an OSI-compatible FOSS license (e.g. GPLv3).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Note that neither Rebble &lt;code&gt;libpebblecommon&lt;/code&gt; maintainer signed the Rebble blog post.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Side note regarding Cobble, I don’t think Rebble even knows this but in 2024, I personally spent over $30,000 to support its development, way before PebbleOS was open source. It was my own way to support the community.&lt;/p&gt;
      &lt;p&gt;Accusation 3: ‘Core promised that they would let Rebble maintain and own the developer site’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Nothing of the sort was agreed upon. See the full written agreement that Core Devices has with Rebble towards the bottom. Rebble agreed that Core would host the developer site.&lt;/item&gt;
        &lt;item&gt;I have been maintaining and updating the developer site personally - all open source. Having two sources of truth would be confusing for the community.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 4: ‘[Eric] scraped our app store, in violation of the agreement that we reached with him previously’&lt;/p&gt;
      &lt;p&gt;Note: ‘scraping’ usually means to automated extraction of data from a website.&lt;/p&gt;
      &lt;p&gt;Facts: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Here’s what happened. I wanted to highlight some of my favourite watchfaces on the Pebble Appstore. Last Monday Nov 10, after I put my kids to sleep and between long calls with factories in Asia, I started building a webapp to help me quickly go through Pebble Appstore and decide which were my top picks.&lt;/item&gt;
        &lt;item&gt;Let me be crystal clear - my little webapp did not download apps or ‘scrape’ anything from Rebble. The webapp displayed the name of each watchface and screenshots and let me click on my favs. I used it to manually look through 6000 watchfaces with my own eyes. I still have 7,000 to go. Post your server logs, they will match up identically to the app I (well…Claude) wrote (source code here)&lt;/item&gt;
        &lt;item&gt;I integrated these picks into the Pebble Appstore on Saturday and posted about it on Sunday.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;All of four of these accusations could have been clarified simply by asking me. Instead, Rebble decided to post them on their blog and threaten a lawsuit. &lt;/p&gt;
      &lt;p&gt;How did we get here?&lt;/p&gt;
      &lt;p&gt;Why are there dueling blog posts in the Pebbleverse? &lt;/p&gt;
      &lt;p&gt;I think most of the people are behind Rebble are great and the community overall is awesome. I know they truly mean well, but there are many aspects of the org that are severely troubling. I am very close with one of the Rebble board members, who I consider a personal friend. Over the years, I learned a lot about the organization and helped coach him through some major disputes between board members. &lt;/p&gt;
      &lt;p&gt;I exchanged literally thousands of messages with my friend on this topic over the span of 3 years. I refrained from getting too involved, despite being asked several times to join Rebble as a board member or lead the organization. I demurred - I saw how painful it was for him and I had no interest in being part of that. &lt;/p&gt;
      &lt;p&gt;Core Devices + Rebble: 2025&lt;/p&gt;
      &lt;p&gt;PebbleOS is now open source! Yay. This is thanks to the work of many Googlers, ex-Pebblers and others - I called out (hopefully) all of them in my blog post in March. I really wanted Rebble to be a part of the Pebble revival going forward. I hired 3 people from Rebble to join Core Devices. I regularly brought up Rebble’s efforts over the years.&lt;/p&gt;
      &lt;p&gt;I engaged with Rebble folks in discussions in the spring on how we could formally work together, and then made some concrete proposals in the summer. One difficulty was that Core Devices is a business with customers and schedules. This didn’t always sync up with the timeframes of a non-profit. Things became very drawn out. It was very hard to pin people down, even on simple stuff like what the goals of Rebble as an organization were. &lt;/p&gt;
      &lt;p&gt;Regardless, I continued pushing to make Rebble a key part of the Pebble relaunch.&lt;/p&gt;
      &lt;p&gt;By August, we finally got close to an agreement.&lt;/p&gt;
      &lt;p&gt;On September 30 2025, we agreed to the following document and published respective blog posts (ours, theres). Core Devices would pay Rebble $0.20/user/month. I considered it a donation to a group that has done so much to support the community. But I purposely pushed for openness - no single group (Core Devices or Rebble) should be in control. &lt;/p&gt;
      &lt;p&gt;Notice the final bullet in the App store section: &lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;All binary/metadata (including historical apps) will be published as archive file (no scraping Rebble services) &lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;Looking back, we should have had more clear wording in this agreement. But this was after months of chat discussions and hours of Zoom calls. I honestly thought that we had reached an agreement to make the archive open, like in this message I received from a Rebble board member.&lt;/p&gt;
      &lt;p&gt;By the end of October, Rebble has changed their mind about providing an archive file.&lt;/p&gt;
      &lt;p&gt;Not withstanding their false accusations of theft, the crux of our disagreement is the archive of 13,000 Pebble apps and watchfaces that were uploaded to the Pebble Appstore in July 2018 before it was shut down. &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I believe that these apps and watchfaces should be archived publicly and freely accessible by anyone. They should not held behind a walled garden by one organization. I repeatedly advocated for hosting this data on a neutral 3rd party like Archive.org.&lt;/item&gt;
        &lt;item&gt;Rebble believes ‘the data behind the Pebble App Store is 100% Rebble’ (this is a direct quote from their blog post). They repeatedly refer to all watchfaces and watchapps as ‘our data’.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;This is just plainly false. The apps and watchfaces were originally uploaded by individual developers to an appstore run by a company that no longer exists. These folks created beautiful work and shared them freely with the Pebble community. I’ve spoken with numerous Pebble app developers about this. After the fall of Pebble Tech Corp, none of them envisioned one single organization claiming ownership of their work and restricting access, or charging money for access.&lt;/p&gt;
      &lt;p&gt;Let’s do the right thing - honour the original developers and create a free publicly available archive of their beautiful watchfaces and watchapps. &lt;/p&gt;
      &lt;p&gt;It's easy to assume the worst in situations like this. But our plan for the appstore is pretty straightforward. We’re working on rewriting the appstore frontend to be native in the mobile app rather than a web view. Rebble’s appstore backend API will be the data source. Rebble’s dev portal is where developers upload apps. No subscription or Rebble account will not be required to download apps. We intend to curate how the appstore is displayed Pebble app.&lt;/p&gt;
      &lt;p&gt;We’re excited to see other Pebble-supporting mobile apps pop up - like MicroPebble and GadgetBridge, offering different features and experiences. We’d love to support these efforts with open source code or financially.&lt;/p&gt;
      &lt;p&gt;Reading things like ‘We’re happy to let them build whatever they want as long as it doesn’t hurt Rebble’ in their blog post worries me. Take our voice-to-text and weather features. Rebble currently offers these as part of their paid subscription. Our new Pebble mobile app includes a on-device speech-to-text feature. We’re planning to include weather for free in our app and make the data available to all watchfaces so you don’t need to configure each one separately. These features are better for users but would they ‘hurt’ Rebble? Will I need to ask permission from Rebble before building these features? It’s clear that the goals of a non-profit and device manufacturer will not always be in alignment.&lt;/p&gt;
      &lt;p&gt;Now consider the appstore. It’s a fundamental part of the Pebble experience. Even before yesterday’s accusations, I felt wary about relying too heavily on a 3rd party like Rebble to provide such a critical service. When people buy a watch from Core Devices, they expect to be able to download apps and watchfaces. If Rebble leadership changes their mind, how can I be certain I can deliver a good experience for our customers? This is one of the primary reasons I think it’s important for an archive of the Pebble Appstore to be freely available.&lt;/p&gt;
      &lt;p&gt;Rebble - prove that you believe in an open, unrestricted Pebble community. Tear down the walled garden you are trying to create. Publish your copy of the Pebble Appstore archive. Stop saying that you ‘100%’ own other developers data. Let’s move on from this ridiculous sideshow and focus on making Pebble awesome!&lt;/p&gt;
      &lt;p&gt;I’ve worked hard to structure everything that we’re doing to be sustainable for the long term, and to do right by the Pebble community. I think Rebble should do the same. &lt;/p&gt;
      &lt;p&gt;I earned almost nothing from Pebble Tech Corp. I paid myself a $65,000 salary each year. I did not get any payout through the asset sale. I fought to make sure that all Pebble employees were taken care of as best as possible, and that the Pebble community would live on. I believe that at every turn, I’ve done right by the community.&lt;/p&gt;
      &lt;p&gt;I didn’t relaunch Pebble to make a lot of money. My goal this time round is to make it sustainable. I want to continue making more watches and cool gadgets. There are no investors. I am taking huge risks doing this. I relaunched it because I love Pebble and want it to live on long into the future. Generally, I am excited and positive for the future, despite everything.&lt;/p&gt;
      &lt;p&gt;For everyone else, again, I apologize for the extreme amounts of inside baseball and the better things you could be doing with your time. I’ll leave the comments open here. Please refrain from any personal attacks or vicious comments (at myself or other people) - follow the HN guidelines.&lt;/p&gt;
      &lt;p&gt;Eric Migicovsky&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45969250</guid><pubDate>Tue, 18 Nov 2025 17:24:27 +0000</pubDate></item><item><title>Blender 5.0</title><link>https://www.blender.org/download/releases/5-0/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45972519</guid><pubDate>Tue, 18 Nov 2025 21:39:18 +0000</pubDate></item><item><title>Cloudflare outage on November 18, 2025 post mortem</title><link>https://blog.cloudflare.com/18-november-2025-outage/</link><description>&lt;doc fingerprint="bc1b3b5b0cb0a8cb"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On 18 November 2025 at 11:20 UTC (all times in this blog are UTC), Cloudflare's network began experiencing significant failures to deliver core network traffic. This showed up to Internet users trying to access our customers' sites as an error page indicating a failure within Cloudflare's network. &lt;/p&gt;
      &lt;p&gt;The issue was not caused, directly or indirectly, by a cyber attack or malicious activity of any kind. Instead, it was triggered by a change to one of our database systems' permissions which caused the database to output multiple entries into a âfeature fileâ used by our Bot Management system. That feature file, in turn, doubled in size. The larger-than-expected feature file was then propagated to all the machines that make up our network.&lt;/p&gt;
      &lt;p&gt;The software running on these machines to route traffic across our network reads this feature file to keep our Bot Management system up to date with ever changing threats. The software had a limit on the size of the feature file that was below its doubled size. That caused the software to fail.&lt;/p&gt;
      &lt;p&gt;After we initially wrongly suspected the symptoms we were seeing were caused by a hyper-scale DDoS attack, we correctly identified the core issue and were able to stop the propagation of the larger-than-expected feature file and replace it with an earlier version of the file. Core traffic was largely flowing as normal by 14:30. We worked over the next few hours to mitigate increased load on various parts of our network as traffic rushed back online. As of 17:06 all systems at Cloudflare were functioning as normal.&lt;/p&gt;
      &lt;p&gt;We are sorry for the impact to our customers and to the Internet in general. Given Cloudflare's importance in the Internet ecosystem any outage of any of our systems is unacceptable. That there was a period of time where our network was not able to route traffic is deeply painful to every member of our team. We know we let you down today.&lt;/p&gt;
      &lt;p&gt;This post is an in-depth recount of exactly what happened and what systems and processes failed. It is also the beginning, though not the end, of what we plan to do in order to make sure an outage like this will not happen again.&lt;/p&gt;
      &lt;p&gt;The chart below shows the volume of 5xx error HTTP status codes served by the Cloudflare network. Normally this should be very low, and it was right up until the start of the outage. &lt;/p&gt;
      &lt;p&gt;The volume prior to 11:20 is the expected baseline of 5xx errors observed across our network. The spike, and subsequent fluctuations, show our system failing due to loading the incorrect feature file. Whatâs notable is that our system would then recover for a period. This was very unusual behavior for an internal error.&lt;/p&gt;
      &lt;p&gt;The explanation was that the file was being generated every five minutes by a query running on a ClickHouse database cluster, which was being gradually updated to improve permissions management. Bad data was only generated if the query ran on a part of the cluster which had been updated. As a result, every five minutes there was a chance of either a good or a bad set of configuration files being generated and rapidly propagated across the network.&lt;/p&gt;
      &lt;p&gt;This fluctuation made it unclear what was happening as the entire system would recover and then fail again as sometimes good, sometimes bad configuration files were distributed to our network. Initially, this led us to believe this might be caused by an attack. Eventually, every ClickHouse node was generating the bad configuration file and the fluctuation stabilized in the failing state.&lt;/p&gt;
      &lt;p&gt;Errors continued until the underlying issue was identified and resolved starting at 14:30. We solved the problem by stopping the generation and propagation of the bad feature file and manually inserting a known good file into the feature file distribution queue. And then forcing a restart of our core proxy.&lt;/p&gt;
      &lt;p&gt;The remaining long tail in the chart above is our team restarting remaining services that had entered a bad state, with 5xx error code volume returning to normal at 17:06.&lt;/p&gt;
      &lt;p&gt;The following services were impacted:&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Service / Product&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Impact description&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Core CDN and security services&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;HTTP 5xx status codes. The screenshot at the top of this post shows a typical error page delivered to end users.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Turnstile&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Turnstile failed to load.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV returned a significantly elevated level of HTTP 5xx errors as requests to KVâs âfront endâ gateway failed due to the core proxy failing.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Dashboard&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;While the dashboard was mostly operational, most users were unable to log in due to Turnstile being unavailable on the login page.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Email Security&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;While email processing and delivery were unaffected, we observed a temporary loss of access to an IP reputation source which reduced spam-detection accuracy and prevented some new-domain-age detections from triggering, with no critical customer impact observed. We also saw failures in some Auto Move actions; all affected messages have been reviewed and remediated.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Access&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Authentication failures were widespread for most users, beginning at the start of the incident and continuing until the rollback was initiated at 13:05. Any existing Access sessions were unaffected.&lt;/p&gt;
            &lt;p&gt;All failed authentication attempts resulted in an error page, meaning none of these users ever reached the target application while authentication was failing. Successful logins during this period were correctly logged during this incident.Â &lt;/p&gt;
            &lt;p&gt;Any Access configuration updates attempted at that time would have either failed outright or propagated very slowly. All configuration updates are now recovered.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;As well as returning HTTP 5xx errors, we observed significant increases in latency of responses from our CDN during the impact period. This was due to large amounts of CPU being consumed by our debugging and observability systems, which automatically enhance uncaught errors with additional debugging information.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;How Cloudflare processes requests, and how this went wrong today&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Every request to Cloudflare takes a well-defined path through our network. It could be from a browser loading a webpage, a mobile app calling an API, or automated traffic from another service. These requests first terminate at our HTTP and TLS layer, then flow into our core proxy system (which we call FL for âFrontlineâ), and finally through Pingora, which performs cache lookups or fetches data from the origin if needed.&lt;/p&gt;
      &lt;p&gt;We previously shared more detail about how the core proxy works here.Â &lt;/p&gt;
      &lt;p&gt;As a request transits the core proxy, we run the various security and performance products available in our network. The proxy applies each customerâs unique configuration and settings, from enforcing WAF rules and DDoS protection to routing traffic to the Developer Platform and R2. It accomplishes this through a set of domain-specific modules that apply the configuration and policy rules to traffic transiting our proxy.&lt;/p&gt;
      &lt;p&gt;One of those modules, Bot Management, was the source of todayâs outage.Â &lt;/p&gt;
      &lt;p&gt;Cloudflareâs Bot Management includes, among other systems, a machine learning model that we use to generate bot scores for every request traversing our network. Our customers use bot scores to control which bots are allowed to access their sites â or not.&lt;/p&gt;
      &lt;p&gt;The model takes as input a âfeatureâ configuration file. A feature, in this context, is an individual trait used by the machine learning model to make a prediction about whether the request was automated or not. The feature configuration file is a collection of individual features.&lt;/p&gt;
      &lt;p&gt;This feature file is refreshed every few minutes and published to our entire network and allows us to react to variations in traffic flows across the Internet. It allows us to react to new types of bots and new bot attacks. So itâs critical that it is rolled out frequently and rapidly as bad actors change their tactics quickly.&lt;/p&gt;
      &lt;p&gt;A change in our underlying ClickHouse query behaviour (explained below) that generates this file caused it to have a large number of duplicate âfeatureâ rows. This changed the size of the previously fixed-size feature configuration file, causing the bots module to trigger an error.&lt;/p&gt;
      &lt;p&gt;As a result, HTTP 5xx error codes were returned by the core proxy system that handles traffic processing for our customers, for any traffic that depended on the bots module. This also affected Workers KV and Access, which rely on the core proxy.&lt;/p&gt;
      &lt;p&gt;Unrelated to this incident, we were and are currently migrating our customer traffic to a new version of our proxy service, internally known as FL2. Both versions were affected by the issue, although the impact observed was different.&lt;/p&gt;
      &lt;p&gt;Customers deployed on the new FL2 proxy engine, observed HTTP 5xx errors. Customers on our old proxy engine, known as FL, did not see errors, but bot scores were not generated correctly, resulting in all traffic receiving a bot score of zero. Customers that had rules deployed to block bots would have seen large numbers of false positives. Customers who were not using our bot score in their rules did not see any impact.&lt;/p&gt;
      &lt;p&gt;Throwing us off and making us believe this might have been an attack was another apparent symptom we observed: Cloudflareâs status page went down. The status page is hosted completely off Cloudflareâs infrastructure with no dependencies on Cloudflare. While it turned out to be a coincidence, it led some of the team diagnosing the issue to believe that an attacker may be targeting both our systems as well as our status page. Visitors to the status page at that time were greeted by an error message:&lt;/p&gt;
      &lt;p&gt;In the internal incident chat room, we were concerned that this might be the continuation of the recent spate of high volume Aisuru DDoS attacks:&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;The query behaviour change&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;I mentioned above that a change in the underlying query behaviour resulted in the feature file containing a large number of duplicate rows. The database system in question uses ClickHouseâs software.&lt;/p&gt;
      &lt;p&gt;For context, itâs helpful to know how ClickHouse distributed queries work. A ClickHouse cluster consists of many shards. To query data from all shards, we have so-called distributed tables (powered by the table engine &lt;code&gt;Distributed&lt;/code&gt;) in a database called &lt;code&gt;default&lt;/code&gt;. The Distributed engine queries underlying tables in a database &lt;code&gt;r0&lt;/code&gt;. The underlying tables are where data is stored on each shard of a ClickHouse cluster.&lt;/p&gt;
      &lt;p&gt;Queries to the distributed tables run through a shared system account. As part of efforts to improve our distributed queries security and reliability, thereâs work being done to make them run under the initial user accounts instead.&lt;/p&gt;
      &lt;p&gt;Before today, ClickHouse users would only see the tables in the &lt;code&gt;default&lt;/code&gt; database when querying table metadata from ClickHouse system tables such as &lt;code&gt;system.tables&lt;/code&gt; or &lt;code&gt;system.columns&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;Since users already have implicit access to underlying tables in &lt;code&gt;r0&lt;/code&gt;, we made a change at 11:05 to make this access explicit, so that users can see the metadata of these tables as well. By making sure that all distributed subqueries can run under the initial user, query limits and access grants can be evaluated in a more fine-grained manner, avoiding one bad subquery from a user affecting others.&lt;/p&gt;
      &lt;p&gt;The change explained above resulted in all users accessing accurate metadata about tables they have access to. Unfortunately, there were assumptions made in the past, that the list of columns returned by a query like this would only include the â&lt;code&gt;default&lt;/code&gt;â database:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;SELECT
  name,
  type
FROM system.columns
WHERE
  table = 'http_requests_features'
order by name;&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;Note how the query does not filter for the database name. With us gradually rolling out the explicit grants to users of a given ClickHouse cluster, after the change at 11:05 the query above started returning âduplicatesâ of columns because those were for underlying tables stored in the r0 database.&lt;/p&gt;
      &lt;p&gt;This, unfortunately, was the type of query that was performed by the Bot Management feature file generation logic to construct each input âfeatureâ for the file mentioned at the beginning of this section.Â &lt;/p&gt;
      &lt;p&gt;The query above would return a table of columns like the one displayed (simplified example):&lt;/p&gt;
      &lt;p&gt;However, as part of the additional permissions that were granted to the user, the response now contained all the metadata of the &lt;code&gt;r0&lt;/code&gt; schema effectively more than doubling the rows in the response ultimately affecting the number of rows (i.e. features) in the final file output.Â &lt;/p&gt;
      &lt;p&gt;Each module running on our proxy service has a number of limits in place to avoid unbounded memory consumption and to preallocate memory as a performance optimization. In this specific instance, the Bot Management system has a limit on the number of machine learning features that can be used at runtime. Currently that limit is set to 200, well above our current use of ~60 features. Again, the limit exists because for performance reasons we preallocate memory for the features.&lt;/p&gt;
      &lt;p&gt;When the bad file with more than 200 features was propagated to our servers, this limit was hit â resulting in the system panicking. The FL2 Rust code that makes the check and was the source of the unhandled error is shown below:&lt;/p&gt;
      &lt;p&gt;This resulted in the following panic which in turn resulted in a 5xx error:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;thread fl2_worker_thread panicked: called Result::unwrap() on an Err value&lt;/code&gt;
      &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Other impact during the incident&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Other systems that rely on our core proxy were impacted during the incident. This included Workers KV and Cloudflare Access. The team was able to reduce the impact to these systems at 13:04, when a patch was made to Workers KV to bypass the core proxy. Subsequently, all downstream systems that rely on Workers KV (such as Access itself) observed a reduced error rate.Â &lt;/p&gt;
      &lt;p&gt;The Cloudflare Dashboard was also impacted due to both Workers KV being used internally and Cloudflare Turnstile being deployed as part of our login flow.&lt;/p&gt;
      &lt;p&gt;Turnstile was impacted by this outage, resulting in customers who did not have an active dashboard session being unable to log in. This showed up as reduced availability during two time periods: from 11:30 to 13:10, and between 14:40 and 15:30, as seen in the graph below.&lt;/p&gt;
      &lt;p&gt;The first period, from 11:30 to 13:10, was due to the impact to Workers KV, which some control plane and dashboard functions rely upon. This was restored at 13:10, when Workers KV bypassed the core proxy system. The second period of impact to the dashboard occurred after restoring the feature configuration data. A backlog of login attempts began to overwhelm the dashboard. This backlog, in combination with retry attempts, resulted in elevated latency, reducing dashboard availability. Scaling control plane concurrency restored availability at approximately 15:30.&lt;/p&gt;
      &lt;p&gt;Now that our systems are back online and functioning normally, work has already begun on how we will harden them against failures like this in the future. In particular we are:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Hardening ingestion of Cloudflare-generated configuration files in the same way we would for user-generated input&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Enabling more global kill switches for features&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Eliminating the ability for core dumps or other error reports to overwhelm system resources&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Reviewing failure modes for error conditions across all core proxy modules&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Today was Cloudflare's worst outage since 2019. We've had outages that have made our dashboard unavailable. Some that have caused newer features to not be available for a period of time. But in the last 6+ years we've not had another outage that has caused the majority of core traffic to stop flowing through our network.&lt;/p&gt;
      &lt;p&gt;An outage like today is unacceptable. We've architected our systems to be highly resilient to failure to ensure traffic will always continue to flow. When we've had outages in the past it's always led to us building new, more resilient systems.&lt;/p&gt;
      &lt;p&gt;On behalf of the entire team at Cloudflare, I would like to apologize for the pain we caused the Internet today. &lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Time (UTC)&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Status&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Description&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Normal.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Database access control change deployed.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:28&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Impact starts.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Deployment reaches customer environments, first errors observed on customer HTTP traffic.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:32-13:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The team investigated elevated traffic levels and errors to Workers KV service.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The initial symptom appeared to be degraded Workers KV response rate causing downstream impact on other Cloudflare services.&lt;/p&gt;
            &lt;p&gt;Mitigations such as traffic manipulation and account limiting were attempted to bring the Workers KV service back to normal operating levels.&lt;/p&gt;
            &lt;p&gt;The first automated test detected the issue at 11:31 and manual investigation started at 11:32. The incident call was created at 11:35.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;13:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV and Cloudflare Access bypass implemented â impact reduced.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;During investigation, we used internal system bypasses for Workers KV and Cloudflare Access so they fell back to a prior version of our core proxy. Although the issue was also present in prior versions of our proxy, the impact was smaller as described below.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;13:37&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Work focused on rollback of the Bot Management configuration file to a last-known-good version.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We were confident that the Bot Management configuration file was the trigger for the incident. Teams worked on ways to repair the service in multiple workstreams, with the fastest workstream a restore of a previous version of the file.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:24&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Stopped creation and propagation of new Bot Management configuration files.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We identified that the Bot Management module was the source of the 500 errors and that this was caused by a bad configuration file. We stopped automatic deployment of new Bot Management configuration files.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:24&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Test of new file complete.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We observed successful recovery using the old version of the configuration file and then focused on accelerating the fix globally.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:30&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Main impact resolved. Downstream impacted services started observing reduced errors.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;A correct Bot Management configuration file was deployed globally and most services started operating correctly.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;17:06&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;All services resolved. Impact ends.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;All downstream services restarted and all operations fully restored.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45973709</guid><pubDate>Tue, 18 Nov 2025 23:31:22 +0000</pubDate></item><item><title>I made a down detector for down detector</title><link>https://downdetectorsdowndetector.com</link><description>&lt;doc fingerprint="7e59a9a7de17484b"&gt;
  &lt;main&gt;
    &lt;p&gt;A tiny independent status checker.&lt;/p&gt;
    &lt;p&gt;Waiting for the latest checks from all regions.&lt;/p&gt;
    &lt;p&gt;Checks by region&lt;/p&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;p&gt;Target: downdetector.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45974012</guid><pubDate>Wed, 19 Nov 2025 00:05:28 +0000</pubDate></item><item><title>Strace-macOS: A clone of the strace command for macOS</title><link>https://github.com/Mic92/strace-macos</link><description>&lt;doc fingerprint="3a291a15e86658d0"&gt;
  &lt;main&gt;
    &lt;p&gt;A system call tracer for macOS using the LLDB debugger API.&lt;/p&gt;
    &lt;p&gt;Status: Beta - Core functionality works, but some features are still in development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Works with SIP enabled - Unlike &lt;code&gt;dtruss&lt;/code&gt;, doesn't require disabling System Integrity Protection&lt;/item&gt;
      &lt;item&gt;Pure Python implementation - No kernel extensions or compiled components&lt;/item&gt;
      &lt;item&gt;Multiple output formats - JSON Lines and strace-compatible text output&lt;/item&gt;
      &lt;item&gt;Syscall filtering - Filter by syscall name or category (&lt;code&gt;-e trace=file&lt;/code&gt;,&lt;code&gt;-e trace=network&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Symbolic decoding - Automatically decodes flags, error codes, and struct fields&lt;/item&gt;
      &lt;item&gt;Color output - Syntax highlighting when output is a TTY&lt;/item&gt;
      &lt;item&gt;Summary statistics - Time/call/error counts with &lt;code&gt;-c&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run directly
nix run github:Mic92/strace-macos -- ls

# Install to profile
nix profile install github:Mic92/strace-macos&lt;/code&gt;
    &lt;p&gt;strace-macos requires macOS system Python (has LLDB bindings):&lt;/p&gt;
    &lt;code&gt;# Install directly from GitHub
/usr/bin/python3 -m pip install --user git+https://github.com/Mic92/strace-macos

# Then run (if ~/Library/Python/3.x/bin is in PATH)
strace /usr/local/bin/git status  # or any homebrew-installed binary

# Or run directly from repository without installing
git clone https://github.com/Mic92/strace-macos
cd strace-macos
/usr/bin/python3 -m strace_macos /usr/local/bin/git status&lt;/code&gt;
    &lt;code&gt;# Basic usage (use non-system binaries like homebrew or nix-installed)
strace /usr/local/bin/git status

# Output to file
strace -o trace.txt /usr/local/bin/git status

# JSON output
strace --json /usr/local/bin/git status &amp;gt; trace.jsonl

# Filter syscalls by name
strace -e trace=open,close /usr/local/bin/git status

# Filter by category*
strace -e trace=file /usr/local/bin/git status    # All file operations
strace -e trace=network /usr/local/bin/curl https://example.com   # Network syscalls only
strace -e trace=process /usr/local/bin/git status # Process lifecycle syscalls&lt;/code&gt;
    &lt;p&gt;* See Syscall Filtering for all supported categories.&lt;/p&gt;
    &lt;code&gt;strace -p 1234&lt;/code&gt;
    &lt;code&gt;strace -c /usr/local/bin/git status
# % time     seconds  usecs/call     calls    errors syscall
# ------ ----------- ----------- --------- --------- ----------------
#  45.23    0.001234          12       103           read
#  32.10    0.000876           8       110           write
#  ...&lt;/code&gt;
    &lt;p&gt;strace-macos supports filtering syscalls by name or category using the &lt;code&gt;-e trace=&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Specify one or more syscall names separated by commas:&lt;/p&gt;
    &lt;code&gt;strace -e trace=open,close,read,write /usr/local/bin/git status&lt;/code&gt;
    &lt;p&gt;Use predefined categories to trace groups of related syscalls:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Example Syscalls&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;File operations&lt;/cell&gt;
        &lt;cell&gt;open, close, read, write, stat, unlink&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;network&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Network operations&lt;/cell&gt;
        &lt;cell&gt;socket, connect, send, recv, bind&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;process&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Process lifecycle&lt;/cell&gt;
        &lt;cell&gt;fork, exec, wait, exit, kill&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;memory&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Memory management&lt;/cell&gt;
        &lt;cell&gt;mmap, munmap, brk, mprotect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;signal&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Signal handling&lt;/cell&gt;
        &lt;cell&gt;signal, sigaction, sigprocmask, kill&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ipc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Inter-process communication&lt;/cell&gt;
        &lt;cell&gt;pipe, shm_open, msgget, semop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;thread&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Thread operations&lt;/cell&gt;
        &lt;cell&gt;pthread_create, bsdthread_register&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;time&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Time and timers&lt;/cell&gt;
        &lt;cell&gt;gettimeofday, setitimer, utimes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;sysinfo&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System information&lt;/cell&gt;
        &lt;cell&gt;sysctl, getpid, getuid, uname&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;security&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Security/MAC operations&lt;/cell&gt;
        &lt;cell&gt;__mac_*, csops, csrctl&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;debug&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Debugging and tracing&lt;/cell&gt;
        &lt;cell&gt;ptrace, kdebug_trace, panic_with_data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;misc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Miscellaneous syscalls&lt;/cell&gt;
        &lt;cell&gt;ioctl, fcntl, kqueue, connectx&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Trace only file operations
strace -e trace=file /usr/local/bin/git status

# Trace only network syscalls
strace -e trace=network /usr/local/bin/curl https://example.com

# Trace process management syscalls
strace -e trace=process /usr/local/bin/git status&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux strace&lt;/cell&gt;
        &lt;cell role="head"&gt;strace-macos&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Filter by syscall name&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=open,close&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=open,close&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Filter by category&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=file&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=file&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Negation (&lt;code&gt;!&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=!open&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Regex filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=/^open/&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Path filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-P /etc/passwd&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FD filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace-fd=3&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;&lt;code&gt;%desc&lt;/code&gt; category&lt;/cell&gt;
        &lt;cell&gt;✅ FD-related syscalls&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Percent prefix&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;%file&lt;/code&gt; or &lt;code&gt;file&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;file&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 12+ (Monterey or later)&lt;/item&gt;
      &lt;item&gt;Apple Silicon (ARM64) - primary platform&lt;/item&gt;
      &lt;item&gt;Intel (x86_64) - work in progress&lt;/item&gt;
      &lt;item&gt;Xcode Command Line Tools (for LLDB)&lt;/item&gt;
      &lt;item&gt;System Python (&lt;code&gt;/usr/bin/python3&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important: Must use macOS system Python - LLDB bindings don't work with Homebrew/pyenv/Nix Python.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! See CONTRIBUTING.md for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Development environment setup&lt;/item&gt;
      &lt;item&gt;Code style guidelines&lt;/item&gt;
      &lt;item&gt;Testing instructions&lt;/item&gt;
      &lt;item&gt;How to add new syscalls&lt;/item&gt;
      &lt;item&gt;Pull request process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Current Status: 3/13 tests passing (spawn functionality working)&lt;/p&gt;
    &lt;code&gt;strace-macos (Python CLI)
    ↓
LLDB Python API
    ↓
debugserver (macOS debugging APIs)
    ↓
Target Process
&lt;/code&gt;
    &lt;p&gt;The tracer uses LLDB's Python bindings to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set breakpoints at syscall entry/exit points&lt;/item&gt;
      &lt;item&gt;Read CPU registers to extract syscall arguments&lt;/item&gt;
      &lt;item&gt;Decode arguments symbolically (flags, errno, structs)&lt;/item&gt;
      &lt;item&gt;Format output in strace-compatible or JSON format&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Working:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Spawn and trace new processes ✅&lt;/item&gt;
      &lt;item&gt;Attach to running processes ✅&lt;/item&gt;
      &lt;item&gt;Basic syscall capture (entry/exit) ✅&lt;/item&gt;
      &lt;item&gt;Argument decoding (integers, strings, pointers, buffers, iovecs) ✅&lt;/item&gt;
      &lt;item&gt;Symbolic flag decoding (O_RDONLY, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Error code decoding (ENOENT, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Struct decoding (stat, sockaddr, msghdr, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Syscall filtering by name and category ✅&lt;/item&gt;
      &lt;item&gt;Summary statistics (&lt;code&gt;-c&lt;/code&gt;) ✅&lt;/item&gt;
      &lt;item&gt;JSON and text output formats ✅&lt;/item&gt;
      &lt;item&gt;Color output with syntax highlighting ✅&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Planned:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-threaded process support&lt;/item&gt;
      &lt;item&gt;Follow forks (&lt;code&gt;-f&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Negation filtering (&lt;code&gt;-e trace=!open&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Regex filtering (&lt;code&gt;-e trace=/^open/&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Path-based filtering (&lt;code&gt;-P /path&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;FD-based filtering (&lt;code&gt;-e trace-fd=3&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;String truncation control (&lt;code&gt;-s&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Relative/absolute timestamps (&lt;code&gt;-t&lt;/code&gt;,&lt;code&gt;-tt&lt;/code&gt;,&lt;code&gt;-ttt&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;macOS ships with &lt;code&gt;dtruss&lt;/code&gt;, a DTrace-based syscall tracer. However:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requires disabling System Integrity Protection (SIP)&lt;/item&gt;
      &lt;item&gt;Doesn't work on modern macOS versions without workarounds&lt;/item&gt;
      &lt;item&gt;Limited filtering capabilities&lt;/item&gt;
      &lt;item&gt;No symbolic decoding of arguments&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;strace-macos works with SIP enabled and provides richer output.&lt;/p&gt;
    &lt;p&gt;strace-macos aims for compatibility with Linux strace where possible:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux strace&lt;/cell&gt;
        &lt;cell role="head"&gt;strace-macos&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Basic tracing&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Attach to PID&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Syscall filtering*&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Summary stats&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Follow forks&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;⏳&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Symbolic decoding&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;JSON output&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Color output&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;* See Syscall Filtering for detailed feature comparison.&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Jörg Thalheim joerg@thalheim.io&lt;/p&gt;
    &lt;p&gt;For commercial support, please contact Mic92 at joerg@thalheim.io or reach out to Numtide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CONTRIBUTING.md - Development and contribution guide&lt;/item&gt;
      &lt;item&gt;tests/README.md - Test suite documentation&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45974681</guid><pubDate>Wed, 19 Nov 2025 01:18:02 +0000</pubDate></item><item><title>I just want working RCS messaging</title><link>https://wt.gd/i-just-want-my-rcs-messaging-to-work</link><description>&lt;doc fingerprint="a628d19d1b0711f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I just want working RCS messaging&lt;/head&gt;
    &lt;p&gt;I’m in over a month now with non-working RCS on my iPhone 15 Pro. Apple blames the carriers, the carriers tell me it’s not them (mostly T-Mobile since I have good contacts there). They tell me they can’t really do anything about iPhones not working on RCS, go back to Apple. This is what it looks like:&lt;/p&gt;
    &lt;p&gt;In short, it’s probably Apple or Google and there’s zero accountability from Apple. I have AppleCare+ and really hoped they’d actually try to troubleshoot and fix this rather than waste my time working around it (in a stupidly expensive way for me and Apple).&lt;/p&gt;
    &lt;head rend="h1"&gt;My background #&lt;/head&gt;
    &lt;p&gt;I’m OS agnostic as much as possible, I daily both Android and iOS devices and previously used BlackBerry 10 and Harmattan (Nokia N9’s OS). If Windows Phone was still around I’d probably still be running that as well. If it’s possible to gather information on how all this works under the hood, I can and do. The OnePlus Android devices I’m running are my own LineageOS builds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Previous history fixing MMS failures for Carriers/Vendors #&lt;/head&gt;
    &lt;p&gt;I’m also happy to blame carriers and vendors: I previously brought and helped resolve an issue with Verizon Wireless on LineageOS phones due to how MMS messaging works. Here’s my initial submission, their developer LuK found a better way to go about it, but it at least started the ball rolling: https://review.lineageos.org/c/LineageOS/android_device_oneplus_sm8250-common/+/333379&lt;/p&gt;
    &lt;p&gt;In short: When you received a picture message on Verizon in the past their network would notify your device that a new message arrived. When the device went to grab and download the image, it sends something similar to browser User Agent, called a UAProf. This is a link to a file that describes what the phone can handle, so a smartphone gets a high resolution image and a featurephone gets a lower resolution one. Verizon’s management sucks and decommissioned the domain that hosts all the UAProfs for their devices. Of note, Verizon is uniquely affected by this issue, T-Mobile doesn’t care what UAProf a device advertises, it’s not required on their network. I haven’t done enough testing with AT&amp;amp;T to answer whether it’s an issue for them.&lt;/p&gt;
    &lt;head rend="h2"&gt;MMS Failure Demonstrations #&lt;/head&gt;
    &lt;p&gt;This is a former link to a Verizon UAProf for a Samsung device: http://uaprof.vtext.com/sam/i515/i515.xml&lt;/p&gt;
    &lt;p&gt;Notice it doesn’t load? Apple/Blackberry and basically any non-Android manufacturers didn’t trust carriers to host these files. Some manager at Verizon decided to kill the vtext service and also fucked over any MMS users on their network not using an iPhone.&lt;/p&gt;
    &lt;p&gt;Here’s Apple’s: https://www.apple.com/mms/uaprof.rdf. &lt;lb/&gt; And here’s Blackberry’s: https://www.blackberry.com/go/mobile/profiles/uaprof/9700/5.0.0.rdf&lt;/p&gt;
    &lt;p&gt;I’m getting off-topic though, I just wanted to post some context that this is not my first rodeo with fixing these kinds of issues. Carriers are incompetent with this sort of interoperability and they gave up on running their own RCS servers to let Google do it through something called Google Jibe, I’ll talk about that soon.&lt;/p&gt;
    &lt;head rend="h1"&gt;Google breaking RCS on LineageOS #&lt;/head&gt;
    &lt;p&gt;Starting around the end of 2023, Google started to maliciously break RCS for custom Android OS’s. I say maliciously because it was a silent failure, RCS reported as working, but messages wouldn’t go through, and incoming messages would fail to receive. Google could have remained silent about it and rumors probably would have swirled: Perhaps it was a technical issue or the custom ROM developers’ faults?&lt;/p&gt;
    &lt;p&gt;No, Google intentionally broke it.&lt;/p&gt;
    &lt;p&gt;They straight up admitted to blocking it: https://www.androidauthority.com/google-silently-blocking-rcs-rooted-android-phones-custom-roms-3421652/ and it wasn’t until months later that they even showed a notification that it was disabled on affected devices. I really hope some lawyer or regulator reading this will get to extract their pound of blood because Google loves to boast about doing 911 over RCS: https://blog.google/products/messages/google-messages-rcs-911-emergency/&lt;/p&gt;
    &lt;p&gt;Eventually for my own devices I would spoof to the fingerprint of Google PIxel devices to be able to use RCS. It has mostly continued to work since then, but it begs the question: If I could reliably work around the blocking, then what excuse do you have about it being to prevent spam? Since those spammers will just use the same methods I’ve used, which are hardly secret. It just aims to hurt users that want some control of their device.&lt;/p&gt;
    &lt;head rend="h1"&gt;Apple launches RCS #&lt;/head&gt;
    &lt;p&gt;At some point Apple was dragged kicking and screaming into RCS interoperability. I actually have some sympathy here because MMS was really a terrible protocol that nobody should have adopted and Apple was dragged into supporting that years after the original iPhone launch in iOS 3. Regardless, with iOS 18, Apple brought in baseline RCS (version 2.4) support. It is hoped that they will update it sometime in the iOS 26 series to include E2E encryption.&lt;/p&gt;
    &lt;head rend="h1"&gt;My iPhone Background, Start of RCS Issues #&lt;/head&gt;
    &lt;p&gt;RCS always worked on my phone in iOS 18 until the past month when I upgraded to iOS 26. I should note that unlike Android, I do not modify iOS device in any way, basically I expect it should ‘just work’. The only unusual thing I run is Mullvad’s DNS to act as an adblocker, but so does my family and their iDevices don’t have RCS issues.&lt;/p&gt;
    &lt;p&gt;I am a dual-sim user on T-Mobile and US Mobile (usually on the AT&amp;amp;T network). With iOS 26 both lines have been stuck on “Waiting for activation…”. If I transfer the lines off to any other iPhone, the lines activate in seconds. I additionally took a Verizon Wireless line from my Mom’s 14 Pro Max and it also displayed the same issue. My girlfriend has a 14 Pro Max and a SE3, both can activate my RCS lines when I transfer them over.&lt;/p&gt;
    &lt;head rend="h1"&gt;Troubleshooting Steps I Did #&lt;/head&gt;
    &lt;p&gt;I’ve done an absolutely exhaustive level of testing to see if these lines would activate on my phone, there’s probably more than this but this is what I could think of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Rebooted/Toggled Airplane Mode/Toggled RCS&lt;/item&gt;
      &lt;item&gt;Resetting Network Settings&lt;/item&gt;
      &lt;item&gt;Removed all my VPN profiles and apps. (Mullvad/Orbot/Mullvad’s DNS profile/my server’s wireguard profile)&lt;/item&gt;
      &lt;item&gt;Deactivated one of my lines and tried reactivating RCS.&lt;/item&gt;
      &lt;item&gt;Disabling 5G and trying to activate RCS.&lt;/item&gt;
      &lt;item&gt;Reissuing both eSIM’s from the carriers.&lt;/item&gt;
      &lt;item&gt;Toggling iMessage.&lt;/item&gt;
      &lt;item&gt;Resetting All settings 9 Resetting everything on device. &lt;list rend="ul"&gt;&lt;item&gt;Restoring from iTunes backup&lt;/item&gt;&lt;item&gt;Restoring from iCloud backup (literally activated a trial to be able to do this)&lt;/item&gt;&lt;item&gt;Tested resetting with and without eSIM.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Recovering device (recovery mode, setting up as new device) &lt;list rend="ul"&gt;&lt;item&gt;Both with and without eSIM’s on device.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Disabling RCS and waiting days before attempting to reactivate.&lt;/item&gt;
      &lt;item&gt;Updating my e911 addresses, disabling/renabling wifi calling. Testing on Wifi.&lt;/item&gt;
      &lt;item&gt;Reissuing just T-Mobile eSIM but to the other IMEI on the phone that it’s normally not on.&lt;/item&gt;
      &lt;item&gt;Deleting the numbers out numerous times in Carrier settings (I have no idea what this does but it does make the signal reconnect).&lt;/item&gt;
      &lt;item&gt;Testing sending messages from devices that work with RCS to this device in hopes it upgrades.&lt;/item&gt;
      &lt;item&gt;Testing the iOS beta releases.&lt;/item&gt;
      &lt;item&gt;I brought up the Gentoo Linux packages for libimobiledevice so I could run idevicesyslog and dump hundreds of megabytes of live logs in hopes of being able to see what the phone is failing on: (the packages) https://github.com/joecool1029/joecool-overlay/tree/master/app-pda &lt;list rend="ul"&gt;&lt;item&gt;This is a small T-Mobile related excerpt of what looks like the problem could be. Specifically, UserInteractionRequired.xml. I don’t know what interaction is needed and why Apple’s software isn’t presenting more information, but this is the best I could do from digging through a ton of redacted logs: &lt;code&gt;Nov 9 15:54:14.294398 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294406 CommCenter[101] &amp;lt;Notice&amp;gt;: #I --&amp;gt; switch: true, bundle_support: false, entitlement_support: true, enabled_by_default: true, disabled_by_profile: false, is_store_demo_device: false Nov 9 15:54:14.294415 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294424 CommCenter[101] &amp;lt;Notice&amp;gt;: #I --&amp;gt; encryption_supported: false, push_supported: false, push_enabled: false, private_relay_supported: false, msisdn_source: (empty) Nov 9 15:54:14.294432 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294440 CommCenter[101] &amp;lt;Notice&amp;gt;: #I --&amp;gt; Changed: (nothing) Nov 9 15:54:14.294448 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294455 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Ims registration interface: kUnknown --&amp;gt; kCellular Nov 9 15:54:14.294463 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294471 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Lazuli model not allowed: [provisioning style: kUsingToken, sms online: false, msisdn OK: true] Nov 9 15:54:14.294479 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294487 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Provisioning not possible Nov 9 15:54:14.294494 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294505 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Infinite validity of UserInteractionRequired.xml xml Nov 9 15:54:14.294514 CommCenter[101] &amp;lt;Notice&amp;gt;: #I [config.rcs.mnc260.mcc310.jibecloud.net] Declaring IMS not ready. Unexpired : UserInteractionRequired.xml Nov 9 15:54:14.294522 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294529 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Nudge not required: Allowed Nov 9 15:54:14.294537 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294546 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Evaluate recheckEntitlementForRCS. Ent:Allowed, Switch toggled:false, CB recheck:false Nov 9 15:54:14.294554 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294561 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Entitlement result: [RCS support: kSupported, user eligibile: kEligible, token-support: true] Nov 9 15:54:14.294569 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294577 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Evaluated provisioning style: kUsingToken Nov 9 15:54:14.294584 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294592 CommCenter[101] &amp;lt;Notice&amp;gt;: #I Retrieving feature switch state Nov 9 15:54:14.294600 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294608 CommCenter(CoreServices)[101] &amp;lt;Debug&amp;gt;: Starting database access (depth 0, options: 1) Nov 9 15:54:14.294616 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294624 CommCenter(CoreServices)[101] &amp;lt;Debug&amp;gt;: BindingEvaluator::CreateWithBundleInfo(ID=&amp;lt;private&amp;gt;, name=&amp;lt;private&amp;gt;, CC=????, vers=(null)) Nov 9 15:54:14.294633 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294641 CommCenter(CoreServices)[101] &amp;lt;Debug&amp;gt;: Truncating a list of bindings to max 1 known-good ones. Nov 9 15:54:14.294648 CommCenter[101] &amp;lt;Debug&amp;gt;: #D supportsHOVirtualInterfaces: ret = false Nov 9 15:54:14.294656 CommCenter(CoreServices)[101] &amp;lt;Debug&amp;gt;: Truncating a list of bindings to max 1 known-good ones.&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;This is a small T-Mobile related excerpt of what looks like the problem could be. Specifically, UserInteractionRequired.xml. I don’t know what interaction is needed and why Apple’s software isn’t presenting more information, but this is the best I could do from digging through a ton of redacted logs: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So this last entry probably tells us where to look. The carrier (T-Mobile here) is provisioned for RCS, it’s receiving this interaction required file with infinite validity. So long as that’s in place, it fails to activate. (This is a guess, but it’s certainly more information than the KB articles give on Apple’s sites).&lt;/p&gt;
    &lt;head rend="h2"&gt;Apple does not provide their employees with correct information on troubleshooting this issue. They do not empower them to properly troubleshoot the issue. #&lt;/head&gt;
    &lt;p&gt;The standard instruction given to them is: “Do not take accountability, blame the carrier.”&lt;/p&gt;
    &lt;p&gt;So then I come in and say I have failures with all 3 major carriers and categorically refuse to accept that explanation, when I know my lines work just fine on other iDevices.&lt;/p&gt;
    &lt;p&gt;The Apple Store initially blamed software, this would be reasonable except we’ve reloaded the state of my phone 3 times now (once from iTunes, and twice now from iCloud, tomorrow will be the 4th time). I gave them permission to wipe any setting and recover the phone, but I go a step further and request they transfer my T-Mobile eSIM to another store device preferably in the 15 Pro line. They cannot do this because of user privacy reasons. This is a dealbreaker from troubleshooting, I am not made of money and I do not have any additional 15 pro devices to test with, it’s already crazy enough I have multiple carriers at the ready to test, 2 14 Pro Max’s and a SE3.&lt;/p&gt;
    &lt;head rend="h1"&gt;Google Jibe #&lt;/head&gt;
    &lt;p&gt;I think this is where we need information. As I said before, the carriers in the US gave up running their own RCS infrastructure and Apple’s employees aren’t really trained about this situation. With the exception of my own knowledge and the logs I pulled from the phone, Jibe was not mentioned once in the 3 phone calls and the multiple hours onsite in Apple Store today.&lt;/p&gt;
    &lt;p&gt;I have no business relationship with Google Jibe, and there’s no way for me to interact with or contact them. Their documentation is probably here but I can’t read it, since I’m not a carrier partner: https://docs.jibemobile.com/ Apple knows there’s a ‘carrier’ issue, but in reality, RCS is run through Google Jibe in the US and this was never once disclosed to me. I never brought it up until this blog post, I cannot go into a store and say “I have been using opensource tools to analyze the logs from this phone and think it’s a failure with Jibe”. Do you get how crazy this sounds?&lt;/p&gt;
    &lt;head rend="h1"&gt;What Apple’s Going To Do Tomorrow #&lt;/head&gt;
    &lt;p&gt;Since they hit a wall and I refuse to continue to entertain the “go bug T-Mobile/US Mobile” direction, Apple is swapping the board in my phone. Of course they didn’t have the parts in the store to do it, so I have to wait to drive back tomorrow for them to do it. This will have new IMEI numbers and given the experience I’ve had with these lines activating on 3 other iDevices, it should probably work. The only way it wouldn’t is if this was a generational issue, but they have not given me a way to test this. They adamantly tell me: “We are doing you the favor as a courtesy, we don’t believe this is our problem.” I know they are trained to say this but it’s terrible customer service. I shelled out for Applecare+, if it might be the phone just swap it and analyze it back at Apple HQ, I’ve done enough testing now to know it’s something with just this specific device. I referred people to use iPhones because in general they do not often have these issues and the customer support was good. The board swap solution they are offering only wastes my time/fuel and punts the problem down the road. Since we never actually looked at the logs I might hit it again, other users might be affected.&lt;/p&gt;
    &lt;head rend="h1"&gt;I’d rather Apple actually fix the problem #&lt;/head&gt;
    &lt;p&gt;I use opensource software not because it’s inherently better, but rather because I can at least triage, understand, and fix problems. Give me a radar Apple. I’m a rare dual-SIM user in the US with a Google Jibe RCS failure. Where did it fail? Dig into my logs and tell me: Is it because I hop between primary data carriers (because the whole reason I have dual-carrier is better service coverage). I don’t spend a lot of time on WiFI, I run my house on mobile carriers. The only thing I know is I didn’t change my configuration from iOS 18 to iOS 26, but things stopped working and there’s no way for me to downgrade to 18 because you stopped signing it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45974869</guid><pubDate>Wed, 19 Nov 2025 01:41:33 +0000</pubDate></item><item><title>Multimodal Diffusion Language Models for Thinking-Aware Editing and Generation</title><link>https://github.com/tyfeld/MMaDA-Parallel</link><description>&lt;doc fingerprint="732fca743eb04b92"&gt;
  &lt;main&gt;
    &lt;p&gt;While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. This model, MMaDA-Parallel, is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our approach significantly improves cross-modal alignment and semantic consistency, achieving a 6.9% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis.&lt;/p&gt;
    &lt;p&gt;Architecture of MMaDA-Parallel. During Training, image and text responses are masked and predicted in parallel with a uniform mask predictor. During Sampling, the model performs parallel decoding to generate both image and text responses jointly, enabling continuous cross-modal interaction.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;[2025-11-11] We release our codes and models for MMaDA-Parallel, with two released 8B models MMaDA-Parallel-A and MMaDA-Parallel-M.&lt;/item&gt;
      &lt;item&gt;[2025-11-10] We release our research paper for Parallel Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Our model has been successfully validated on synthetic datasets focusing on environments, still life, architecture, and natural landscapes. Its performance on out-of-distribution inputs—such as human faces or real-world photographic imagery—has not yet been fully explored. We are actively expanding our training corpus to include more diverse datasets.&lt;/p&gt;
    &lt;p&gt;First, start with a torch environment with torch 2.3.1 or higher version, then install the following dependencies:&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;
    &lt;p&gt;We provide two varients of MMaDA-Parallel with different tokenizers. MMaDA-Parallel-A is trained with tokenizer Amused-VQ, and MMaDA-Parallel-M is trained with tokenizer Magvitv2.&lt;/p&gt;
    &lt;p&gt;You can directly use the local gradio app to experience the parallel generation with MMaDA-Parallel-A:&lt;/p&gt;
    &lt;code&gt;python app.py&lt;/code&gt;
    &lt;p&gt;Or you can use the inference script to generate the parallel generation results:&lt;/p&gt;
    &lt;code&gt;cd MMaDA-Parallel-A
python inference.py \
    --checkpoint tyfeld/MMaDA-Parallel-A \
    --vae_ckpt tyfeld/MMaDA-Parallel-A \
    --prompt "Replace the laptops with futuristic transparent tablets displaying holographic screens, and change the drink to a cup of glowing blue energy drink." \
    --image_path examples/image.png \
    --height 512 \
    --width 512 \
    --timesteps 64 \
    --text_steps 128 \
    --text_gen_length 256 \
    --text_block_length 32 \
    --cfg_scale 0 \
    --cfg_img 4.0 \
    --temperature 1.0 \
    --text_temperature 0 \
    --seed 42 \
    --output_dir output/results_interleave&lt;/code&gt;
    &lt;code&gt;cd MMaDA-Parallel-M
python inference.py interleave_root=./interleave_validation  &lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Release the MMaDA-Parallel code and paper.&lt;/item&gt;
      &lt;item&gt;Evaluation on ParaBench code.&lt;/item&gt;
      &lt;item&gt;Refine MMaDA-Parallel-M and update the corresponding checkpoint.&lt;/item&gt;
      &lt;item&gt;Training code for SFT and ParaRL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;@article{tian2025mmadaparallel,
  title={MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation},
  author={Tian, Ye and Yang, Ling and Yang, Jiongfan and Wang, Anran and Tian, Yu and Zheng, Jiani and Wang, Haochen and Teng, Zhiyang and Wang, Zhuochen and Wang, Yinjie and Tong, Yunhai and Wang, Mengdi and Li, Xiangtai},
  journal={arXiv preprint arXiv:2511.09611},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;This work is heavily based on MMaDA and Lumina-DiMOO. Thanks to all the authors for their great work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45977542</guid><pubDate>Wed, 19 Nov 2025 09:27:17 +0000</pubDate></item><item><title>I made a downdetector for downdetector's downdetector's downdetector</title><link>https://downdetectorsdowndetectorsdowndetectorsdowndetector.com</link><description>&lt;doc fingerprint="7e81fbcfd5163a56"&gt;
  &lt;main&gt;
    &lt;p&gt;A tiny independent status checker that checks the checker that checks the checker that checks Downdetector.&lt;/p&gt;
    &lt;p&gt;Contacting Downdetector's Downdetector's Downdetectorâ¦&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;HTTP&lt;/cell&gt;
        &lt;cell role="head"&gt;Latency&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Global probe&lt;/cell&gt;
        &lt;cell&gt;â Checkingâ¦&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Last checked: Just now Â· Target: downdetectorsdowndetectorsdowndetector.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45977629</guid><pubDate>Wed, 19 Nov 2025 09:40:13 +0000</pubDate></item><item><title>The $1k AWS Mistake</title><link>https://www.geocod.io/code-and-coordinates/2025-11-18-the-1000-aws-mistake/</link><description>&lt;doc fingerprint="150c5d190913d288"&gt;
  &lt;main&gt;
    &lt;p&gt;A cautionary tale about AWS VPC networking, NAT Gateways, and how a missing VPC Endpoint turned our S3 data transfers into an expensive lesson.&lt;/p&gt;
    &lt;p&gt;I've been using AWS since around 2007. Back then, EC2 storage was entirely ephemeral and stopping an instance meant losing all your data. The platform has come a long way since then.&lt;/p&gt;
    &lt;p&gt;Even after nearly two decades with the platform, there's always something new to learn. And sometimes those lessons come with a $1,000 price tag.&lt;/p&gt;
    &lt;p&gt;We recently moved over to using S3 for mirroring some large internal data files for Geocodio. We're talking about geographic datasets (things like address points, boundary data, and census information) that range from a few gigabytes to hundreds of gigabytes each. Some of these files are updated almost daily with fresh data, while others are refreshed less frequently. They need to be synced regularly from our ETL platform (which is hosted with Hetzner) to our processing infrastructure on AWS.&lt;/p&gt;
    &lt;p&gt;AWS has notoriously high data transfer costs. Cloudflare has written extensively about this, and it's a common complaint across the industry. Corey Quinn from Last Week in AWS has also called out the AWS Managed NAT Gateway for being particularly expensive. AWS charges $0.09 per GB for data transfer out to the internet from most regions, which adds up fast when you're moving terabytes of data.&lt;/p&gt;
    &lt;p&gt;So before starting this project, I did my homework. I carefully researched the costs involved and confirmed two critical things:&lt;/p&gt;
    &lt;p&gt;Great! I had a clear picture of the costs.&lt;/p&gt;
    &lt;p&gt;...Or so I thought.&lt;/p&gt;
    &lt;p&gt;A few days after deploying the new S3 sync process, I got a notification from AWS Cost Anomaly Detection. (Boy, was I happy that I had that enabled!)&lt;/p&gt;
    &lt;p&gt;The alert showed something alarming: 20,167.32 GB of "NAT Gateway" data transfers in a single day, which amounted to $907.53.&lt;/p&gt;
    &lt;p&gt;Month to date, this had already surpassed $1,000.&lt;/p&gt;
    &lt;p&gt;I stared at the dashboard in disbelief. How could this be happening? I had specifically confirmed that EC2-to-S3 transfers were free!&lt;/p&gt;
    &lt;p&gt;After some frantic investigating (and a bit of panic), I discovered the culprit.&lt;/p&gt;
    &lt;p&gt;When you're using VPCs with a NAT Gateway (which most production AWS setups do), S3 transfers still go through the NAT Gateway by default. Even though you're making requests to an AWS service that's in the same region, the traffic is routed out through your NAT Gateway and back in, incurring data transfer charges at $0.045 per GB.&lt;/p&gt;
    &lt;p&gt;The solution? VPC Endpoints for S3, specifically what AWS calls a "Gateway Endpoint."&lt;/p&gt;
    &lt;p&gt;A Gateway Endpoint is a special type of VPC endpoint that allows you to privately route traffic to S3 without going through your NAT Gateway or Internet Gateway. It's essentially a direct pipe from your VPC to S3.&lt;/p&gt;
    &lt;p&gt;Even better, Gateway Endpoints for S3 are completely free. No hourly charges, no data transfer charges. Nothing.&lt;/p&gt;
    &lt;p&gt;The solution is to create a VPC Gateway Endpoint for S3. This is a special type of VPC endpoint that creates a direct route from your VPC to S3, bypassing the NAT Gateway entirely.&lt;/p&gt;
    &lt;p&gt;In our case, we manage infrastructure with Terraform, so it was just a matter of adding the Gateway Endpoint resource and associating it with our route tables. AWS automatically handles the routing updates to direct S3 traffic through the endpoint instead of the NAT Gateway.&lt;/p&gt;
    &lt;p&gt;I've built countless VPCs, configured security groups, set up load balancers, and optimized costs in dozens of ways over the years. But somehow, VPC Endpoints for S3 had slipped through the cracks of my knowledge.&lt;/p&gt;
    &lt;p&gt;AWS's networking can be deceptively complex. Even when you think you've done your research and confirmed the costs, there are layers of configuration that can dramatically change your bill.&lt;/p&gt;
    &lt;p&gt;Don't make my mistake. Here are a few things I'd suggest checking to help you avoid your own surprise $1,000 bill:&lt;/p&gt;
    &lt;p&gt;AWS Cost Anomaly Detection is worth setting up. It caught this issue within days, saving us from an even larger surprise at the end of the month. If you haven't enabled it yet, do it now.&lt;/p&gt;
    &lt;p&gt;VPC Endpoints are your friend. If you're using S3 or DynamoDB from EC2 instances in a VPC with a NAT Gateway, you absolutely need Gateway Endpoints. There's literally no reason not to use them. They're free and improve performance.&lt;/p&gt;
    &lt;p&gt;Always validate your assumptions. I thought "EC2 to S3 is free" was enough. I should have tested with a small amount of data and monitored the costs before scaling up to terabytes.&lt;/p&gt;
    &lt;p&gt;The cloud is complicated. There's always more to learn, even after nearly two decades. And that's okay. It just means we need to be careful and vigilant.&lt;/p&gt;
    &lt;p&gt;And we're not alone in this. Just last year, Recall.ai discovered they were paying $1M annually in unexpected AWS WebSocket data processing fees. Even experienced teams hit these surprises.&lt;/p&gt;
    &lt;p&gt;We've since audited our entire AWS infrastructure to make sure we have Gateway Endpoints configured for all VPCs that communicate with S3.&lt;/p&gt;
    &lt;p&gt;If you're using AWS and you haven't checked your VPC Endpoint configuration lately, I'd recommend taking a look. That $1,000 lesson doesn't need to be repeated.&lt;/p&gt;
    &lt;p&gt;TL;DR: NAT Gateways charge for ALL data processing, even for traffic to AWS services like S3 that have no data transfer fees. Use VPC Endpoints to bypass this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45977744</guid><pubDate>Wed, 19 Nov 2025 10:00:05 +0000</pubDate></item><item><title>What Killed Perl?</title><link>https://entropicthoughts.com/what-killed-perl</link><description>&lt;doc fingerprint="a2205b581ae285df"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Killed Perl?&lt;/head&gt;
    &lt;p&gt;Trick question! Perl is not dead. I’ll show you what I mean, and then still answer what I think killed Perl.&lt;/p&gt;
    &lt;p&gt;The cpan Report 2023 put together by Neil Bowers quite clearly illustrates that Perl’s popularity is somewhere in the same range it was during the dotcom bubble.1 I realise cpan usage isn’t a perfect proxy. There are probably a lot of people like me who use Perl specifically for things where they don’t need to interact with third-party libraries. These wouldn’t show up in the cpan records either, obviously. But it’s the best proxy I have. If anything, it’s higher: popularity increased ever so slightly after 2022, as next year’s cpan report will show. (Neil says he will publish it in January, so follow his blog for the latest news.) But it is also clear that newcomers make up a decreasing portion of the Perl crowd, and this has been the case since 2011. Why is that?&lt;/p&gt;
    &lt;p&gt;Some people seem to think Raku (formerly known as “Perl 6”) sucked momentum out of Perl, but I don’t believe that. Everyone I talked to back then knew Perl wasn’t going anywhere. Humanity had chained too much of the infrastructure of the growing internet to it. Even if Raku turned out to be a wild success, someone would have to keep maintaining Perl for many years to come. There was never any danger of obsolescence in starting a new project in Perl.&lt;/p&gt;
    &lt;p&gt;Besides, Raku was first announced in 2000, and the major burst of activity around Raku implementations seems to have been at the end of that decade. Through that period, Perl grew rapidly, as indicated by the graph.&lt;/p&gt;
    &lt;p&gt;I still struggle to understand why Perl went out of favour, which is understandable if you know what I think about it. But I have heard two reasons that resonate with me.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The people who grew up on Unixy systems in the 1990s and early 2000s would know shell, C, awk, sed, Vim, etc. To these people, Perl is a natural extension of what they were already doing. Then in the 2000s came a new generation of programmers brought up on … I don’t know, Microsoft systems, Visual Basic and Java? These people were more attracted to something like Python as a second language, which then became popular enough to become the first language of the generation after that.&lt;/item&gt;
      &lt;item&gt;Back when people learned Perl, you didn’t just go online and download development tools for a programming language on a whim. Binary package managers that chase down dependencies on their own weren’t a thing until the early 2000s, I think? And even then they didn’t have all that many packages. So even if, I don’t know, Oberon or Eiffel would be a better fit for someone in the 1990s, they might have opted to go with Perl anyway because that was what they had. These days, this is not as much of a problem anymore.2 You’ll find that the invention of many of the popular languages of today, such as Rust, Kotlin, Elixir, TypeScript, and Go happen to coincide with the growth of the internet and increased power of package managers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So to state my hypothesis briefly: people today are both less predisposed to understand Perl, and have easy access to so many other alternatives. It’s a rather unsatisfactory explanation, but it’s the closest I can get.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45977900</guid><pubDate>Wed, 19 Nov 2025 10:25:25 +0000</pubDate></item><item><title>Learning to Boot from PXE</title><link>https://blog.imraniqbal.org/learning-to-boot-from-pxe/</link><description>&lt;doc fingerprint="76e8eb7771b30c83"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Learning to boot from PXE&lt;/head&gt;
    &lt;p&gt;Posted on&lt;/p&gt;
    &lt;p&gt;I bought a new laptop, the GPD Pocket 4. It came with windows installed by default, and I wanted to install nix on it.&lt;/p&gt;
    &lt;p&gt;I grabbed a usb, &lt;code&gt;dd&lt;/code&gt;'d the nixos iso image on it and tried to boot.
The laptop did not recognize the drive.
Turns out, the drive crapped out, no computer would boot off it.&lt;/p&gt;
    &lt;p&gt;The normal thing to do would've been to just go get a new usb and install off of and go about setting the laptop up. That meant I would either have to go outside or wait for a new usb to arrive. I don't want to outside and I don't want to wait to setup my laptop. I have free time now and I have no clue when I will have free time next.&lt;/p&gt;
    &lt;p&gt;The menu had two other boot options. Something about PXE over ipv4 or ipv6. I only knew that PXE allowed networked boot. So hey, let's use this time to learn something new.&lt;/p&gt;
    &lt;head rend="h3"&gt;# DHCP&lt;/head&gt;
    &lt;p&gt;As I've learned, the first half of this process is DHCP. When a device is connected to the network it sends out a "HEY GIVE ME AN IP" message (I don't actually know how it works and didn't bother to look it up). Then your DHCP service see's this message and responds back with an IP. As part of these requests the client and server can set "options" on these requests which can send additional information. I don't know what the client sets first, but I do know the server needs to set a boot file name and location of a TFTP server. TFTP sort of like FTP.&lt;/p&gt;
    &lt;p&gt;PXE reads the boot file (usually something.pxe) from the TFTP server and then executes its code. Other boot files are then retrieved as needed from the TFTP server.&lt;/p&gt;
    &lt;p&gt;While learning this, folks on the internet dont seem too fond of TFTP, saying it could be slow. There exists iPXE which is supposed to be a better PXE. PXE (like bioses), tend to be manufacturer specific and are not created equal. iPXE tries to be better and supports a bunch of other stuff like (like booting from an ISO, and talking in HTTP). So if this all goes well i get iPXE going, point it to the iso I've already downloaded and I'm off to the races!&lt;/p&gt;
    &lt;p&gt;Spoiler alert, I didn't get to the races.&lt;/p&gt;
    &lt;p&gt;To get iPXE running, the iPXE.pxe executable needs to be served by TFTP. I am running an OPNsense box for my router/firewall and it as enough disk space and ram that I should be able to do this whole process of it. Setting the DHCP stuff is easy enough via the UI. the iPXE client sets a client option on its DHCP requests, so you want to create a tag in OPNsense off it's user-class (iPXE) and respond with a DHCP boot (what the tab in the UI is called) value of the http server.&lt;/p&gt;
    &lt;p&gt;The flow should be:&lt;/p&gt;
    &lt;p&gt;PXE -&amp;gt; Gets TFTP Address -&amp;gt; Downloads and run iPXE iPXE -&amp;gt; Gets HTTP address -&amp;gt; Does iPXE stuff like run our iso&lt;/p&gt;
    &lt;p&gt;The DHCP stuff can be done through the UI so it was. The TFTP stuff was not availble the web ui so has to be done through ssh.&lt;/p&gt;
    &lt;head rend="h3"&gt;# TFTP&lt;/head&gt;
    &lt;p&gt;This was my first time shelling into a BSD box. After this whole process I was left feeling that (Free)BSD is oddly cozy. I can't explain how or why, but it just does. The login prompt from opnsense, the simple shell prompt (csh?), the man pages, the disk layout, the programs. Like even if I didn't have access to all the new version of tools (nvim / rg vs vim / grep) I still got what I wanted done and it just felt cute and cozy.&lt;/p&gt;
    &lt;p&gt;Anyway, OPNsense ships with dnsmasq and dnsmasq can also act as a TFTP server. I found this out when trying to search for a TFTP program to install via the UI. I don't know how to enable it, nor did I want to look it up (via the internet), so I just read the man page.&lt;/p&gt;
    &lt;code&gt;man dnsmasq
&lt;/code&gt;
    &lt;p&gt;Reading the man page was a pleasant experience (or maybe it was just my first time reading something from section 8). It told me exactly what the program could do and how to configure it (just searched for tftp). The conf files were listed in at the bottom, the first being &lt;code&gt;/etc/dnsmasq.conf&lt;/code&gt; which did not exist on my system but &lt;code&gt;/usr/local/etc/dnsmasq.conf&lt;/code&gt; did.&lt;/p&gt;
    &lt;p&gt;The first line of that file warns you not to manually edit the file and near the bottom you see the conf-dir option set to &lt;code&gt;/usr/local/etc/dnsmasq.conf.d&lt;/code&gt;
I saw a README in that conf dir and, doing a cat resulted in this message:&lt;/p&gt;
    &lt;code&gt;cat /usr/local/etc/dnsmasq.conf.d/README
# Dnsmasq plugin directory:
# Add your *.conf files here, read in alphabetical order
&lt;/code&gt;
    &lt;p&gt;Well sure why not lets do that&lt;/p&gt;
    &lt;code&gt;vim /usr/local/etc/dnsmasq.conf.d/10-tftp.conf
enable-tftp
tftp-root=/srv/tftp
:x
mkdir -p /srv/tftp
fetch -r https://boot.ipxe.org/ipxe.efi -o /srv/tftp/
&lt;/code&gt;
    &lt;p&gt;I used the web ui to restart dnsmasq, but you can also use &lt;code&gt;configctl&lt;/code&gt; to do it via shell.
Now when I boot up the laptop I see it load up iPXE but then fail as the http server does not exist. That is progress though, now we just need to serve our iso over http.&lt;/p&gt;
    &lt;p&gt;One thing to note is that nearly all the instructions online focus on legacy/bios boot. All my devices boot via UEFI (which is why we downloaded the efi above instead of the .kpxe file). There are ways to setup DHCP to respond with the appropriate files for both uefi or bios boot, but I dont care enough. There are also other things that try to simplify this whole process like pixieboot and netboot.xyz but I am not interested in them.&lt;/p&gt;
    &lt;head rend="h3"&gt;# HTTP&lt;/head&gt;
    &lt;p&gt;OPNsense runs lighttpd for serving its web ui and I would like to piggy back off it for the iPXE stuff.&lt;/p&gt;
    &lt;p&gt;The trickest part here was finding out the web ui configuration lives at &lt;code&gt;/usr/local/etc/lighttpd_webgui/&lt;/code&gt; via &lt;code&gt;ps&lt;/code&gt;.
I had to disable the ssl redirect option from the web ui and instead add it myself to end of my conf file, due how the confs are loaded. I could not think of a different way of getting the 443 port redirect disabled just for the ipxe paths&lt;/p&gt;
    &lt;code&gt;cat /usr/local/etc/lighttpd_webgui/conf.d/00-ipxe.conf
# Serve /srv/tftp under http://&amp;lt;ip&amp;gt;/ipxe/
alias.url += ( "/ipxe/" =&amp;gt; "/srv/tftp/" )
url.redirect += ( "^/ipxe$" =&amp;gt; "/ipxe/" )

$SERVER["socket"] == "0.0.0.0:80" {
    ssl.engine = "disable"
    $HTTP["url"] !~ "^/ipxe(?:/|$)" {
        $HTTP["host"] =~ "(.*)" {
            url.redirect = ( "^/(.*)" =&amp;gt; "https://%1/$1" )
        }
    }
}

$SERVER["socket"] == "[::]:80" {
    ssl.engine = "disable"
    $HTTP["url"] !~ "^/ipxe(?:/|$)" {
        $HTTP["host"] =~ "(.*)" {
            url.redirect = ( "^/(.*)" =&amp;gt; "https://%1/$1" )
        }
    }
}
&lt;/code&gt;
    &lt;p&gt;I started off with a basic boot.ixpe file&lt;/p&gt;
    &lt;code&gt;#!ipxe
menu Choose an ISO
item nix-minmal NixOS 25.04 Minimal
item nix-gui   NixOS 25.04 GUI
choose target &amp;amp;&amp;amp; goto ${target}

:nix-minimal
sanboot http://10.0.0.1/ipxe/nixos-minimal-25.05.812242.3de8f8d73e35-x86_64-linux.iso
goto menu

:nix-gui
sanboot http://10.0.0.1/ipxe/nixos-graphical-25.05.812242.3de8f8d73e35-x86_64-linux.iso
goto menu
&lt;/code&gt;
    &lt;p&gt;And here is what I spoiled eariler, it didnt work.&lt;/p&gt;
    &lt;p&gt;I would get a boot but then nixos would complain about &lt;code&gt;/mnt/iso&lt;/code&gt; or something being missing and failing to go further.&lt;/p&gt;
    &lt;p&gt;This discussion has better information on why it doesn't work: https://github.com/ipxe/ipxe/discussions/962&lt;/p&gt;
    &lt;head rend="h3"&gt;# Proper netboot files&lt;/head&gt;
    &lt;p&gt;So my dreams of network booting off an iso are crushed, so where do I go from here?&lt;/p&gt;
    &lt;p&gt;Well it turns out the ISO comes with a bootloader, which contains instructions on how to boot a kernel with an initial ram disk (hint this when I learned what &lt;code&gt;initrd&lt;/code&gt; means).
So can't we do the same?
The answer is yes! (or so I think).
I didnt try to extract the files out the iso, but use nix's built in netboot image generator which builds the necessary files.&lt;/p&gt;
    &lt;p&gt;I only had to tweak the generated .ixpe file to include the http urls but everything worked out in the end.&lt;/p&gt;
    &lt;code&gt;cat netboot.ipxe
#!ipxe
# Use the cmdline variable to allow the user to specify custom kernel params
# when chainloading this script from other iPXE scripts like netboot.xyz
kernel http://10.0.0.1/ipxe/bzImage init=/nix/store/hrgkskx4jqdz4nl3p1f4m1dvrr9b3lij-nixos-system-nixos-kexec-25.11pre708350.gfedcba/init initrd=initrd nohibernate loglevel=4 lsm=landlock,yama,bpf ${cmdline}
initrd http://10.0.0.1/ipxe/initrd
boot
&lt;/code&gt;
    &lt;p&gt;I still wonder if I can extract the files from the graphical installer and boot KDE off the network, but now that the OS is installed my interest has waned. Maybe one day I will revisit&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45978245</guid><pubDate>Wed, 19 Nov 2025 11:18:59 +0000</pubDate></item><item><title>Pimped Amiga 500</title><link>https://www.pimyretro.org/pimped-amiga-500/</link><description>&lt;doc fingerprint="2c406c29212e33b1"&gt;
  &lt;main&gt;
    &lt;p&gt;Back in the early ’90s, I had an Amiga 2000 with just one expansion card: a SCSI controller paired with a massive 290 MB hard drive. Getting software and games to run from the hard drive—with only 1 MB of chip RAM—required a lot of tricks. But it was fun, and it taught me a lot about computers.&lt;/p&gt;
    &lt;p&gt;A few months ago, I stumbled upon a cheap Amiga 500, and I couldn’t resist. I decided to restore it from the ground up and add a GottaGoFast RAM + IDE controller to finally build what would have been my dream machine in 1990: an Amiga running OS 1.3 with fast RAM!&lt;/p&gt;
    &lt;p&gt;This is the story of my pimped Amiga 500: 1 MB chip RAM, 8 MB fast RAM, and 512 MB of storage. Quite a beast for its time! 🙂&lt;/p&gt;
    &lt;head rend="h2"&gt;Used Materials&lt;/head&gt;
    &lt;p&gt;Here is the hardwares pieces I used:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Amiga 500 I bought with a “512K memory expansions”&lt;/item&gt;
      &lt;item&gt;IDE68K + GottaGo FastRAM 8MB from AmigaStore.eu&lt;/item&gt;
      &lt;item&gt;A 512M CompaqFlash card (LIMEI, “professional grade”)&lt;/item&gt;
      &lt;item&gt;A 40 pin 3.5in IDE ribbon cable&lt;/item&gt;
      &lt;item&gt;A dremel to creare a compaqflash slot&lt;/item&gt;
      &lt;item&gt;Some (dupond) wires and solder&lt;/item&gt;
      &lt;item&gt;Some pin headers&lt;/item&gt;
      &lt;item&gt;A multimeter&lt;/item&gt;
      &lt;item&gt;Isopropyl alchool&lt;/item&gt;
      &lt;item&gt;Q-tips&lt;/item&gt;
      &lt;item&gt;Facom “Contact Spay”&lt;/item&gt;
      &lt;item&gt;Ambro-sol galvanized zinc spray paint&lt;/item&gt;
      &lt;item&gt;A driller and a dremel&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;First boot&lt;/head&gt;
    &lt;p&gt;At first, I had a hard time getting a Workbench disk to boot properly — even though the game disks I tested worked just fine. (They probably have better error correction routines.)&lt;/p&gt;
    &lt;p&gt;Each time I tried to start Workbench from different floppies, I ran into either “Read/Write Error” or “Please insert disk in drive 0!” messages. After several attempts and a few frustrating retries, I finally managed to reach a command prompt.&lt;/p&gt;
    &lt;p&gt;That’s when I noticed something strange: the system was reporting 1 MB of chip RAM. Wait a second — this is an Amiga 500, not a 500+! Even with a memory expansion, it should normally show 512 KB chip RAM and 512 KB slow RAM. This means my A500 must have been modified to convert the slow RAM into chip RAM. (For reference: “slow RAM” sits on the same bus as chip memory, but it’s not directly addressable by the custom chips.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside&lt;/head&gt;
    &lt;p&gt;Of course, I found a memory expansion installed: a SupraRam 500 Rev.2 (details here), identifiable by the four DIP switches. It’s a very neat card — the battery uses a standard coin cell, which is much less prone to leaking than typical NiMH batteries.&lt;lb/&gt;Here’s a look at the expansion card inside the machine:&lt;/p&gt;
    &lt;p&gt;The motherboard is a Rev 6A, which is internally ready for 1 MB of chip RAM but only has 512 KB installed. Judging by the setup, this Amiga seems to have been modified to provide 1 MB chip RAM: the JP7A jumper is fully open, and JP2 has pins 1 and 2 shorted!&lt;lb/&gt;As you can see in this photo, the jumpers reveal the modification:&lt;/p&gt;
    &lt;p&gt;Inside, there’s a fat Agnus 8372A (capable of addressing 1 MB chip RAM) paired with a Denise R8 (OCS) rather than a SuperDenise (ECS). While it’s not an ECS setup, this combination at least allows Extra Half-Brite (EHB) mode.&lt;lb/&gt;The Agnus and Denise chips are shown here, highlighting the OCS configuration:&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware restoration&lt;/head&gt;
    &lt;head rend="h3"&gt;Plastics&lt;/head&gt;
    &lt;p&gt;The plastics on this Amiga were just a bit yellowed — nothing too severe. I was able to recover them easily using the same Retrobright box I used for my pimped Amiga 600.&lt;/p&gt;
    &lt;p&gt;The power supply, however, had a noticeably stronger yellow tint compared to the other parts. I applied Retrobright to all components, and for the power supply, I gave it a longer exposure. It hasn’t fully returned to its original color, but it’s much improved.&lt;/p&gt;
    &lt;p&gt;On the left: before cleaning and Retrobright; on the right: after treatment:&lt;/p&gt;
    &lt;head rend="h3"&gt;Metallic shield&lt;/head&gt;
    &lt;p&gt;Both the upper and lower shield parts were in poor condition, showing some corrosion. While these shields aren’t strictly necessary for the Amiga to function, I wanted to keep my A500 as authentic as possible.&lt;/p&gt;
    &lt;p&gt;I treated the metal with Ambro-Sol spray (98% zinc) — a kind of metallic paint that also protects against corrosion. Before painting, I lightly sanded all corroded areas to ensure a smooth finish. The paint has a matte finish, which I actually prefer over the original look.&lt;/p&gt;
    &lt;p&gt;On the left: before painting; on the right: after treatment:&lt;/p&gt;
    &lt;head rend="h3"&gt;Keyboard&lt;/head&gt;
    &lt;p&gt;The keyboard was covered in dust and had a noticeable yellow tint. I removed all the keys to thoroughly clean each part and also subjected them to the Retrobright process.&lt;/p&gt;
    &lt;p&gt;Unfortunately, I didn’t take any photos of the cleaned keyboard on its own, but the results should be visible in the overall photos of the restored A500.&lt;/p&gt;
    &lt;head rend="h3"&gt;The mouse&lt;/head&gt;
    &lt;p&gt;The mouse wasn’t working properly and showed several issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The classic problem: dirty internal wheels.&lt;/item&gt;
      &lt;item&gt;The spring on the white wheel, which ensures the ball touches the encoder wheels, was too loose, so the ball didn’t make proper contact.&lt;/item&gt;
      &lt;item&gt;The right mouse button was dead or broken.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I replaced the right button with a new one — slightly more “clicky,” but it didn’t require any extra pressure to use.&lt;/p&gt;
    &lt;p&gt;Next, I cleaned all internal parts using alcohol and some Q-Tips, and I retensioned the spring by gently pulling both sides at the same time.&lt;/p&gt;
    &lt;p&gt;The final result: a cleaner interior and a fully functional, “like new” mouse.&lt;lb/&gt;Here’s the after look inside the mouse:&lt;/p&gt;
    &lt;head rend="h3"&gt;Floppy drive&lt;/head&gt;
    &lt;p&gt;The floppy drive in my Amiga 500 is a Matsushita JU-253-031P, recognizable by its plain black top cover over the mechanism. While it gives a clean look, it also makes dust removal more challenging compared to other drives.&lt;/p&gt;
    &lt;p&gt;I carefully used Q-Tips to remove as much dust as possible, paying special attention to the read/write heads, which are still easily accessible and crucial for reliable disk reading.&lt;/p&gt;
    &lt;p&gt;Additionally, I had to resolder the wires on the small floppy detector button, which had been causing the “Please insert disk in drive” errors during reading.&lt;/p&gt;
    &lt;p&gt;Here’s a look at the drive during cleaning and after reassembly:&lt;/p&gt;
    &lt;head rend="h3"&gt;Motherboard &amp;amp; Memory card&lt;/head&gt;
    &lt;p&gt;The motherboard was in pretty good condition. I simply applied some FACOM Contact Spray, which helps remove dust, humidity, and oxidation. It’s said to also provide some protection for the circuits — well, it certainly can’t hurt!&lt;/p&gt;
    &lt;p&gt;I did the same for the memory expansion card. Additionally, I replaced the soldered battery with a battery holder, making the setup cleaner and allowing the battery to be easily swapped in the future.&lt;/p&gt;
    &lt;p&gt;Here’s a look at the motherboard and memory card after cleaning and the battery upgrade:&lt;/p&gt;
    &lt;head rend="h2"&gt;Extentions&lt;/head&gt;
    &lt;p&gt;I installed the IDE68k + GottaGoFastram combo along with the patched Kickstart ROM that allows booting directly from an IDE device. I also picked up a 512 MB CompactFlash card, which provides more than enough space — considering that back in the mid-80s, even 20 or 40 MB felt enormous.&lt;lb/&gt;The patched Kickstart 1.3 includes an scsi.device , making it possible to boot from the emulated hard drive (the CF card). Without it, you would need to boot from a floppy — just like some disk controllers required back in the day.&lt;/p&gt;
    &lt;p&gt;Booting from the IDE interface requires two signals: /INT2 and /OVR.&lt;lb/&gt;The kit comes with Dupont wires and small clip-style “pliers” to grab these signals respectively from pin 21 of CIA A and pin 29 of Gary.&lt;lb/&gt;I wasn’t a fan of this approach — the clips are fragile and can easily detach when moving the Amiga.&lt;/p&gt;
    &lt;p&gt;Both signals are actually available on the Zorro II 86-pin connector next to the 68000 CPU (see: mklboards.fi).&lt;lb/&gt;So I decided to solder both wires directly to the Zorro II connector. It’s cleaner, safer, and mechanically rock-solid.&lt;/p&gt;
    &lt;p&gt;Here are the tests I ran before finalizing the modification:&lt;/p&gt;
    &lt;p&gt;At first, the CF wasn’t powering up. Pin 20 of the IDE connector should provide +5 V for powering CF cards, but I measured 0 V.&lt;lb/&gt;I ended up taking +5 V from the keyed pin on the adapter and wiring it directly to the CF’s 5 V pin.&lt;lb/&gt;It seems something is missing from the Amigashop.eu hardware or in the documentation, because the kit is supposed to include everything required.&lt;/p&gt;
    &lt;p&gt;To simplify things, I modified the CF adapter, removing the bottom power connector and adding only the single required +5 V pin on top.&lt;lb/&gt;This reduces the height of the board — which turned out to be necessary for the next step.&lt;/p&gt;
    &lt;p&gt;I slightly modified the A500 case to fit the CF card reader under the floppy drive, making card swaps extremely convenient without reopening the machine each time.&lt;lb/&gt;I began by drilling two holes to mount the reader from the underside of the chassis:&lt;/p&gt;
    &lt;p&gt;Then I placed the Cf card reader to calibrate the hole needed for the compaq flash to be inserted. It first made some small holes with a drill and I finished the job with a dremel.&lt;/p&gt;
    &lt;p&gt;Because of the new placement, I needed a longer ribbon cable between the CF adapter and the IDE controller.&lt;lb/&gt;I eventually took the required +5 V for the adapter from the floppy drive connector — cleaner and more reliable.&lt;/p&gt;
    &lt;p&gt;Finaly I added a red led to monitor IDE drive activity in addition to the floppy drive. In fact I used two 3mm leds glued between the two original ones of the Amiga 500. the mod is fully reversible. I used some aluminium adhesive to both isolate power led from the red light and better diffuse the red light on the original drive led. As you can see, there is one resistor for both leds.&lt;/p&gt;
    &lt;p&gt;Finally, I added a red LED to monitor IDE activity, complementing the original floppy LED.&lt;lb/&gt;I used two 3 mm LEDs glued between the Amiga’s two original indicators.&lt;lb/&gt;The mod is fully reversible.&lt;lb/&gt;I used aluminum adhesive tape to prevent the power LED from bleeding into the IDE LED, and to better diffuse the red light through the original light pipe.&lt;lb/&gt;A single resistor drives both LEDs.&lt;/p&gt;
    &lt;p&gt;The result looks great and gives clear feedback: IDE activity, floppy activity, or both at once.&lt;/p&gt;
    &lt;p&gt;On the left: no IDE or floppy activity — on the right: IDE activity.&lt;/p&gt;
    &lt;p&gt;Now: left = floppy only — right = both IDE and floppy working simultaneously:&lt;/p&gt;
    &lt;p&gt;With the hardware restored and the extensions fully installed, it was finally time to move on to the next step: preparing the operating system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preparing OS Install&lt;/head&gt;
    &lt;head rend="h3"&gt;Amiberry configuration&lt;/head&gt;
    &lt;p&gt;To make the installation process easier, I prepared the system using Amiberry first. I used a Kickstart 1.3 ROM patched with IDE controller support, similar to the physical ROM I purchased from Amigastore.eu. The version I used can be found here: https://www.uprough.net/releases/Amiga_Roots_Music_Tools_Beta_2/&lt;/p&gt;
    &lt;p&gt;Below are the Amiberry settings I used to replicate my Amiga 500 hardware as closely as possible:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CPU: 68000, 24-bit addressing, A500 cycle-exact (×2)&lt;/item&gt;
      &lt;item&gt;Chipset: ECS Agnus with A600 selected under “Chipset Extra” — this is important, otherwise the IDE controller will be disabled&lt;/item&gt;
      &lt;item&gt;RAM: Same as my real A500 — 1 MB Chip, 8 MB Z2 Fast&lt;/item&gt;
      &lt;item&gt;Expansion: Enabled the A600 IDE controller&lt;/item&gt;
      &lt;item&gt;Hard Drive: Mapped the Linux device corresponding to my USB CF card reader, selected the Commodore A600 controller, and set the mode to ATA-1 — this is essential, or the CF card won’t be detected correctly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These settings allow Amiberry to behave almost exactly like the upgraded A500 hardware, making the OS installation straightforward and 100% compatible with the real machine.&lt;/p&gt;
    &lt;head rend="h3"&gt;HDToolsBox&lt;/head&gt;
    &lt;p&gt;Nothing particularly unusual here, except that I first had to free some space on the “IDE Setup” floppy (I honestly don’t remember where I originally got it). Without doing so, HDToolBox refused to save the new drive-type definition.&lt;lb/&gt;To make room, I simply removed the Shell program from that floppy, since it’s already available on the Workbench disk anyway.&lt;/p&gt;
    &lt;p&gt;Once that was sorted out, here’s what I essentially did:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edited the ToolTypes of HDToolBox to point to scsi.device&lt;/item&gt;
      &lt;item&gt;Launched HDToolBox.&lt;/item&gt;
      &lt;item&gt;Selected the CF drive and clicked “Change Drive Type”.&lt;/item&gt;
      &lt;item&gt;Created a new drive type definition.&lt;/item&gt;
      &lt;item&gt;Set the Manufacturer, Drive Name, and Revision fields.&lt;/item&gt;
      &lt;item&gt;Saved and selected this newly created drive type.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These steps allow HDToolBox to correctly recognize and handle the CF card as a proper fixed drive under Workbench.&lt;/p&gt;
    &lt;head rend="h3"&gt;Partitions&lt;/head&gt;
    &lt;p&gt;Below is the partitioning scheme I chose. I generally prefer to separate the operating system, its accompanying utilities, applications, games, and user data — essentially the Amiga equivalent of a “/home” directory.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DH0 – Workbench: 24 MB, 100 buffers&lt;/item&gt;
      &lt;item&gt;DH1 – Apps: 85 MB, 100 buffers&lt;/item&gt;
      &lt;item&gt;DH2 – Games: 140 MB, 100 buffers&lt;/item&gt;
      &lt;item&gt;DH3 – Data: 212 MB, 150 buffers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For all partitions, I used FFS with a maxtransfer value of 0x1FE00 .&lt;lb/&gt;I formatted each partition using a command like:&lt;/p&gt;
    &lt;p&gt;format DRIVE DH0 name Workbench FFS QUICK&lt;/p&gt;
    &lt;head rend="h3"&gt;Workbench 1.3 install&lt;/head&gt;
    &lt;p&gt;Installing Workbench 1.3 is fairly straightforward: it simply involves copying the contents of the Workbench and Extra disks onto the bootable partition, then editing the startup-sequence.&lt;lb/&gt;I later discovered that the A590 Install disk actually includes a dedicated tool for installing Workbench — but here’s the manual method I followed:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;copy workbench1.3: to dh0: all clone&lt;/p&gt;
          &lt;p&gt;copy "extra 1.3:" to dh0: all done&lt;/p&gt;
          &lt;p&gt;rename DH0:s/startup-sequence DH0:s/startup-sequence.FD&lt;/p&gt;
          &lt;p&gt;rename DH0:s/startup-sequence.HD DH0:s/startup-sequence&lt;/p&gt;
          &lt;p&gt;edit DH0:s/startup-sequence ; replace the call "Execute s:Startup-sequence" by "Execute s:Startup-sequence.FD"&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I also copied HDToolBox from the “IDE Setup” disk into &lt;code&gt;DH0:/Tools&lt;/code&gt; for convenience.&lt;/p&gt;
    &lt;p&gt;After removing all floppy disks and resetting the virtual machine, the Amiga immediately booted from the hard drive.&lt;lb/&gt;Before applying any customisations, I confirmed that everything worked properly on the real hardware.&lt;/p&gt;
    &lt;p&gt;Here’s the Workbench 1.3 booting directly from the CF card:&lt;/p&gt;
    &lt;head rend="h2"&gt;Installed Software&lt;/head&gt;
    &lt;p&gt;In this chapter, I’m going to give an overview of all the software I installed on the A500, along with their sources — and no, it’s not always from Aminet.net!&lt;/p&gt;
    &lt;head rend="h3"&gt;Sources&lt;/head&gt;
    &lt;head rend="h4"&gt;Where I got it&lt;/head&gt;
    &lt;p&gt;Before diving into the software itself, here’s a quick overview of the main sources I used to gather everything described in this chapter&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;List of software compatible with OS 1.3 https://eab.abime.net/showthread.php?t=52283&lt;/item&gt;
      &lt;item&gt;https://demozoo.org/&lt;/item&gt;
      &lt;item&gt;https://ftp.funet.fi/pub/amiga/&lt;/item&gt;
      &lt;item&gt;Workbench 13. Extras&lt;/item&gt;
      &lt;item&gt;https://amr.abime.net/&lt;/item&gt;
      &lt;item&gt;https://archive.org/download/CommodoreAmigaApplicationsADF&lt;/item&gt;
      &lt;item&gt;https://archive.org/download/commodore-amiga-compilations-applications&lt;/item&gt;
      &lt;item&gt;https://aminet.net/&lt;/item&gt;
      &lt;item&gt;Ramdisk icon from https://github.com/LessNick/Amiga-WorkBench-Re-Design/tree/master&lt;/item&gt;
      &lt;item&gt;Hard disk partition icon from A2091 install disk https://amigamuseum.emu-france.info/Fichiers/ADF/Utilitaires-Applications/&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Installed Tools&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Software&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DiskMaster 2&lt;/cell&gt;
        &lt;cell&gt;File manager&lt;/cell&gt;
        &lt;cell&gt;Archive.org – compilation&lt;p&gt;Scanned Manual&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CygnusED 2.12&lt;/cell&gt;
        &lt;cell&gt;Full features tet editor&lt;/cell&gt;
        &lt;cell&gt;Archive.org – Neck utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PowerPacker&lt;/cell&gt;
        &lt;cell&gt;Compression and tool to read compressed content&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DMS 1.11&lt;/cell&gt;
        &lt;cell&gt;Disk imager&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;TSGui&lt;/cell&gt;
        &lt;cell&gt;Graphical interface for ADF and DMS&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LHA 1.38&lt;/cell&gt;
        &lt;cell&gt;Amiga’s default archiving tool&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Mostra 1.06&lt;/cell&gt;
        &lt;cell&gt;Image viewer&lt;/cell&gt;
        &lt;cell&gt;ftp.funet.fi&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Sysinfo&lt;/cell&gt;
        &lt;cell&gt;Hardware and system informations&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;X-Copy Pro 3.31&lt;/cell&gt;
        &lt;cell&gt;Disk copier&lt;/cell&gt;
        &lt;cell&gt;Archive.org – Neck utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SuperDuper&lt;/cell&gt;
        &lt;cell&gt;Disk copier&lt;/cell&gt;
        &lt;cell&gt;Aminet / fish-0488&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Bootx 4.5&lt;/cell&gt;
        &lt;cell&gt;Antivirus&lt;/cell&gt;
        &lt;cell&gt;Aminet / fish-0641&lt;p&gt;Latest virus database&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Workbench enhancements&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Software&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ARP 1.3&lt;/cell&gt;
        &lt;cell&gt;Better AmigaDos commands&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WShell 2.0&lt;/cell&gt;
        &lt;cell&gt;Better shell&lt;/cell&gt;
        &lt;cell&gt;Archive.org – original software disk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MyMenus&lt;/cell&gt;
        &lt;cell&gt;Allow to make custom menu entries&lt;/cell&gt;
        &lt;cell&gt;Aminet / fish-0225&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Fkeys&lt;/cell&gt;
        &lt;cell&gt;Key shortcuts for windows and screen switcher&lt;/cell&gt;
        &lt;cell&gt;Aminet / fish-0532&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dmouse 1.20&lt;/cell&gt;
        &lt;cell&gt;Screen and mouse blanker + windows management&lt;/cell&gt;
        &lt;cell&gt;Archive.org – Neck utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MSClock&lt;/cell&gt;
        &lt;cell&gt;Clock on title bar&lt;/cell&gt;
        &lt;cell&gt;Aminet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Setclock v34.3&lt;/cell&gt;
        &lt;cell&gt;Y2k patch for setclock&lt;/cell&gt;
        &lt;cell&gt;Obligement&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Applications and games&lt;/head&gt;
    &lt;p&gt;For applications, I simply installed a few classic programs from the era, mostly for fun. By today’s standards, these tools aren’t particularly productive, but they give a great sense of how software worked back then. All of them were sourced from archives.org and ftp.funet.fi (see the “Sources / Where I Got It” section for links):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deluxe Paint IV&lt;/item&gt;
      &lt;item&gt;Pro-Tracker 3.10 – music editor (https://ftp.funet.fi/pub/amiga/audio/apps/compose/)&lt;/item&gt;
      &lt;item&gt;ANIMagic&lt;/item&gt;
      &lt;item&gt;Brillance 2 : contains commorodre installer for OS 1.3 =&amp;gt; copy to C&lt;/item&gt;
      &lt;item&gt;Disney Animation Studio&lt;/item&gt;
      &lt;item&gt;PageSetter 2&lt;/item&gt;
      &lt;item&gt;Wordworth 1.1&lt;/item&gt;
      &lt;item&gt;Scala MM 200&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As for games, I only included those that are natively installable on the A500. I didn’t see the point of using JST, since I can rely on WHDLoad on my other Amigas. The games I chose come from my personal list of best Amiga titles, curated over time:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Turbo Trax&lt;/item&gt;
      &lt;item&gt;Fiendish freddy&lt;/item&gt;
      &lt;item&gt;Lionheart&lt;/item&gt;
      &lt;item&gt;MetalKombat&lt;/item&gt;
      &lt;item&gt;Ducktales&lt;/item&gt;
      &lt;item&gt;Flashback&lt;/item&gt;
      &lt;item&gt;Hare Raising Havoc&lt;/item&gt;
      &lt;item&gt;Base Jump&lt;/item&gt;
      &lt;item&gt;KidChaos&lt;/item&gt;
      &lt;item&gt;Conan the Cimmerian&lt;/item&gt;
      &lt;item&gt;Dragon Heart&lt;/item&gt;
      &lt;item&gt;BosCar&lt;/item&gt;
      &lt;item&gt;BlackViper&lt;/item&gt;
      &lt;item&gt;MegaTyphoon&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Configuration &amp;amp; customizations&lt;/head&gt;
    &lt;p&gt;This section describes the steps I followed to customize my A500, presented roughly in the order I tackled them. Some steps are explained in more detail than others, depending on the level of customization involved.&lt;lb/&gt;Basically, I followed an order that allowed me to set up a fully usable environment before diving into more advanced tweaks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bare minimum for a usable OS&lt;/head&gt;
    &lt;head rend="h4"&gt;A file manager with OS 1.3 feeling&lt;/head&gt;
    &lt;p&gt;First, I installed DiskMaster 2 — a must-have if you want a proper file manager on base Workbench 1.3, which can’t even display files and directories that have no associated icons.&lt;/p&gt;
    &lt;p&gt;Here’s what I did to set it up:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Copied the executable to SYS:c/dm .&lt;/item&gt;
      &lt;item&gt;Created a setup file named dm.conf in SYS:s with the following customizations: &lt;list rend="ul"&gt;&lt;item&gt;SetFormat "NS T DMY A" to remove unnecessary comments from the file list&lt;/item&gt;&lt;item&gt;Barformat "DiskMaster Chip:%C Fast:%F %T %D.%M"&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Optimized window dimensions&lt;/item&gt;
      &lt;item&gt;Added a Version command: AddCmd Version, 20, extern c:version %s; Wait 2&lt;/item&gt;
      &lt;item&gt;Added a PlayMod command&lt;/item&gt;
      &lt;item&gt;Customized the Editors menu&lt;/item&gt;
      &lt;item&gt;Simplified the Archives menu to only LHA + DMS&lt;/item&gt;
      &lt;item&gt;Simplified the Tools menu and added Execute script&lt;/item&gt;
      &lt;item&gt;Simplified the Project menu&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To launch DiskMaster, I run: dm s:dm.conf either from the shell or via a custom menu, as explained later.&lt;/p&gt;
    &lt;p&gt;Below is the full configuration file for reference:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
          &lt;p&gt;6&lt;/p&gt;
          &lt;p&gt;7&lt;/p&gt;
          &lt;p&gt;8&lt;/p&gt;
          &lt;p&gt;9&lt;/p&gt;
          &lt;p&gt;10&lt;/p&gt;
          &lt;p&gt;11&lt;/p&gt;
          &lt;p&gt;12&lt;/p&gt;
          &lt;p&gt;13&lt;/p&gt;
          &lt;p&gt;14&lt;/p&gt;
          &lt;p&gt;15&lt;/p&gt;
          &lt;p&gt;16&lt;/p&gt;
          &lt;p&gt;17&lt;/p&gt;
          &lt;p&gt;18&lt;/p&gt;
          &lt;p&gt;19&lt;/p&gt;
          &lt;p&gt;20&lt;/p&gt;
          &lt;p&gt;21&lt;/p&gt;
          &lt;p&gt;22&lt;/p&gt;
          &lt;p&gt;23&lt;/p&gt;
          &lt;p&gt;24&lt;/p&gt;
          &lt;p&gt;25&lt;/p&gt;
          &lt;p&gt;26&lt;/p&gt;
          &lt;p&gt;27&lt;/p&gt;
          &lt;p&gt;28&lt;/p&gt;
          &lt;p&gt;29&lt;/p&gt;
          &lt;p&gt;30&lt;/p&gt;
          &lt;p&gt;31&lt;/p&gt;
          &lt;p&gt;32&lt;/p&gt;
          &lt;p&gt;33&lt;/p&gt;
          &lt;p&gt;34&lt;/p&gt;
          &lt;p&gt;35&lt;/p&gt;
          &lt;p&gt;36&lt;/p&gt;
          &lt;p&gt;37&lt;/p&gt;
          &lt;p&gt;38&lt;/p&gt;
          &lt;p&gt;39&lt;/p&gt;
          &lt;p&gt;40&lt;/p&gt;
          &lt;p&gt;41&lt;/p&gt;
          &lt;p&gt;42&lt;/p&gt;
          &lt;p&gt;43&lt;/p&gt;
          &lt;p&gt;44&lt;/p&gt;
          &lt;p&gt;45&lt;/p&gt;
          &lt;p&gt;46&lt;/p&gt;
          &lt;p&gt;47&lt;/p&gt;
          &lt;p&gt;48&lt;/p&gt;
          &lt;p&gt;49&lt;/p&gt;
          &lt;p&gt;50&lt;/p&gt;
          &lt;p&gt;51&lt;/p&gt;
          &lt;p&gt;52&lt;/p&gt;
          &lt;p&gt;53&lt;/p&gt;
          &lt;p&gt;54&lt;/p&gt;
          &lt;p&gt;55&lt;/p&gt;
          &lt;p&gt;56&lt;/p&gt;
          &lt;p&gt;57&lt;/p&gt;
          &lt;p&gt;58&lt;/p&gt;
          &lt;p&gt;59&lt;/p&gt;
          &lt;p&gt;60&lt;/p&gt;
          &lt;p&gt;61&lt;/p&gt;
          &lt;p&gt;62&lt;/p&gt;
          &lt;p&gt;63&lt;/p&gt;
          &lt;p&gt;64&lt;/p&gt;
          &lt;p&gt;65&lt;/p&gt;
          &lt;p&gt;66&lt;/p&gt;
          &lt;p&gt;67&lt;/p&gt;
          &lt;p&gt;68&lt;/p&gt;
          &lt;p&gt;69&lt;/p&gt;
          &lt;p&gt;70&lt;/p&gt;
          &lt;p&gt;71&lt;/p&gt;
          &lt;p&gt;72&lt;/p&gt;
          &lt;p&gt;73&lt;/p&gt;
          &lt;p&gt;74&lt;/p&gt;
          &lt;p&gt;75&lt;/p&gt;
          &lt;p&gt;76&lt;/p&gt;
          &lt;p&gt;77&lt;/p&gt;
          &lt;p&gt;78&lt;/p&gt;
          &lt;p&gt;79&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Reset&lt;/p&gt;
          &lt;p&gt;AddMenu Project, Printer Setup, SetPrinter&lt;/p&gt;
          &lt;p&gt;AddMenu Project, Change Command, ChgCmd&lt;/p&gt;
          &lt;p&gt;AddMenu Project, Save Config, S, SaveConfig&lt;/p&gt;
          &lt;p&gt;AddMenu Project, About, About&lt;/p&gt;
          &lt;p&gt;AddMenu Project, Quit, Q, Confirm "Are you sure you want to quit?" Yes No;Quit&lt;/p&gt;
          &lt;p&gt;AddMenu Tools, Run Selected, Single;External run %s&lt;/p&gt;
          &lt;p&gt;AddMenu Tools, Execute Script, Single;External run Execute %s&lt;/p&gt;
          &lt;p&gt;AddMenu Tools, Swap S&amp;lt;-&amp;gt;D, Swap&lt;/p&gt;
          &lt;p&gt;AddMenu Tools, Run DM Script, Single;Batch %s&lt;/p&gt;
          &lt;p&gt;AddMenu Archives, Lha Add, StdIO "CON:0/12/640/100/Add Window";Extern "Lha &amp;lt;* -r a";StdIO CLOSE&lt;/p&gt;
          &lt;p&gt;AddMenu Archives, Lha Extract, StdIO "CON:0/12/640/100/Extract Window";Extern Lha &amp;lt;* x %s;StdIO CLOSE&lt;/p&gt;
          &lt;p&gt;AddMenu Archives, Lha List, StdIO "CON:0/12/640/160/List Window";Extern Lha v %s;Wait;StdIO CLOSE&lt;/p&gt;
          &lt;p&gt;AddMenu Archives, DMS Write, StdIO "CON:0/12/640/160/List Window";Extern DMS write %s TO DF0:;Wait;StdIO CLOSE&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Format, Format&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, DiskCopy, DiskCopy&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Format DF0:, Confirm "Are you sure?";Format DF0:&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Format DF1:, Format DF1: VERIFY "WorkDisk"&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Clear DF0:, Format DF0: QUICK INSTALL VERIFY&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Copy DF0: DF0:, DiskCopy DF0: DF0:&lt;/p&gt;
          &lt;p&gt;AddMenu Disk, Copy DF0: DF1:, DiskCopy DF0: DF1:&lt;/p&gt;
          &lt;p&gt;AddMenu Control, Lock as Source, Lock S&lt;/p&gt;
          &lt;p&gt;AddMenu Control, Lock as Dest, Lock D&lt;/p&gt;
          &lt;p&gt;AddMenu Control, UnLock, UnLock&lt;/p&gt;
          &lt;p&gt;AddMenu Control, UnLock all, UnLock All&lt;/p&gt;
          &lt;p&gt;AddMenu Control, Toggle Expand, Expand&lt;/p&gt;
          &lt;p&gt;AddMenu Editors, Textra, T, Extern run Textra %s&lt;/p&gt;
          &lt;p&gt;AddMenu Editors, CygnusED, T, Extern run Sys:Utilities/CygnusED %s&lt;/p&gt;
          &lt;p&gt;AddMenu Editors, EditPad, T, Extern run Sys:Utilities/Notepad %s&lt;/p&gt;
          &lt;p&gt;Button "Parent"&lt;/p&gt;
          &lt;p&gt;SetFormat "NS T DMY A"&lt;/p&gt;
          &lt;p&gt;BarFormat "DiskMaster Chip:%C Fast:%F %T %D.%M"&lt;/p&gt;
          &lt;p&gt;TitleFormat "%B/%F %I/%C"&lt;/p&gt;
          &lt;p&gt;OpenScreen 2&lt;/p&gt;
          &lt;p&gt;Color 05A FFF 002 F80&lt;/p&gt;
          &lt;p&gt;Font topaz/8&lt;/p&gt;
          &lt;p&gt;OpenWindow 278 11 84 245 CMD&lt;/p&gt;
          &lt;p&gt;AddCmd Root, 10, Root&lt;/p&gt;
          &lt;p&gt;AddCmd Parent, 10, Parent&lt;/p&gt;
          &lt;p&gt;AddCmd All, 30, Select *&lt;/p&gt;
          &lt;p&gt;AddCmd Clear, 30, Deselect *&lt;/p&gt;
          &lt;p&gt;AddCmd Select, 30, Select&lt;/p&gt;
          &lt;p&gt;AddCmd Exclude, 30, DeSelect&lt;/p&gt;
          &lt;p&gt;AddCmd Copy, 20, ReqPattern;Copy %s %d&lt;/p&gt;
          &lt;p&gt;AddCmd Cp New, 20, Copy %s %d NEWER&lt;/p&gt;
          &lt;p&gt;AddCmd Move, 20, ReqPattern;Move %s %d&lt;/p&gt;
          &lt;p&gt;AddCmd Delete, 30, ReqPattern;Confirm "All selected files will be lost.";Delete %s&lt;/p&gt;
          &lt;p&gt;AddCmd Rename, 20, Recurse OFF;Rename %s&lt;/p&gt;
          &lt;p&gt;AddCmd Protect, 20, Recurse OFF;Protect %s&lt;/p&gt;
          &lt;p&gt;AddCmd Comment, 20, Recurse OFF;Comment %s&lt;/p&gt;
          &lt;p&gt;AddCmd Find, 20, ReqPattern "Please enter search pattern";Find %s&lt;/p&gt;
          &lt;p&gt;AddCmd Read, 20, Read %s&lt;/p&gt;
          &lt;p&gt;AddCmd HexRead, 20, Read %s HEX&lt;/p&gt;
          &lt;p&gt;AddCmd ShowPic, 20, ShowPic %s&lt;/p&gt;
          &lt;p&gt;AddCmd MakeDir, 20, MakeDir&lt;/p&gt;
          &lt;p&gt;AddCmd Size, 20, UnMark OFF;Check %s&lt;/p&gt;
          &lt;p&gt;AddCmd Version, 20, extern c:version %s; Wait 2&lt;/p&gt;
          &lt;p&gt;AddCmd Playmod, 20, extern run APPS:Protracker/backplay %s&lt;/p&gt;
          &lt;p&gt;OpenWindow 362 11 278 245&lt;/p&gt;
          &lt;p&gt;OpenWindow 0 11 278 245&lt;/p&gt;
          &lt;p&gt;AddAutoCmd FORM????ILBM,ShowPic %s&lt;/p&gt;
          &lt;p&gt;AddAutoCmd FORM????ACBM,ShowPic %s&lt;/p&gt;
          &lt;p&gt;AddAutoCmd FORM????8SVX,ShowPic %s&lt;/p&gt;
          &lt;p&gt;AddAutoCmd FORM????ANIM,Extern View %s&lt;/p&gt;
          &lt;p&gt;AddAutoCmd ??-lh,StdIO "CON:0/12/640/100/Extract Window";Extern Lha &amp;lt;* x %s;StdIO CLOSE&lt;/p&gt;
          &lt;p&gt;AddAutoCmd TEXT,Read %s&lt;/p&gt;
          &lt;p&gt;AddAutoCmd DEFAULT,Read %s HEX&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Text editors&lt;/head&gt;
    &lt;p&gt;Once you have a proper file manager, the next thing you’ll do most often while configuring and customizing Workbench 1.3 is editing configuration files. For this reason, I installed two excellent text editors — far superior to the default NotePad or ED.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Textra: Installed to SYS:c as a lightweight but powerful editor for quick edits and rapid file changes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CygnusED: Installed to SYS:Utilities , with req.library placed in SYS:libs , providing a full-featured, professional editor for more complex tasks (albeit heavier).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both editors complement each other: Textra for speed, CygnusED for advanced editing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Better shell&lt;/head&gt;
    &lt;p&gt;If, like me, you’re used to Bash or Zsh, the original Amiga Shell — even in the 3.x releases — feels quite limited, missing some “basic” features we take for granted. Fortunately, two tools make the CLI interface far more user-friendly: ARP 1.3 and WShell.&lt;/p&gt;
    &lt;p&gt;For ARP, I simply followed the installer and opted not to install the ARP shell, keeping the setup minimal.&lt;/p&gt;
    &lt;p&gt;WShell, on the other hand, comes with an installer that can be run directly from the CLI: Wshell-install&lt;/p&gt;
    &lt;p&gt;It doesn’t create an icon, so it’s invisible from Workbench by default. I made several customizations to integrate it better:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Copied NewWSH to the Workbench partition, allowing WShell to be started via an icon.&lt;/item&gt;
      &lt;item&gt;Set the ToolTypes as follows:&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;CONSOLE=CON:20/15/580/150/WShell/CLOSE&lt;/p&gt;
          &lt;p&gt;FROM=S:WShell-Startup&lt;/p&gt;
          &lt;p&gt;NAME=WShell&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configured the default shell window in S:ENV/shellwindow : CON:20/15/580/150/WShell/CLOSE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also tweaked the FComp configuration (&lt;code&gt;
			SYS:s/Config-Fcomp&lt;/code&gt;) to get more familiar key usage:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TAB for autocomplete instead of ESC&lt;/item&gt;
      &lt;item&gt;Arrow keys Up/Down for line navigation&lt;/item&gt;
      &lt;item&gt;HOME / END for session top/bottom&lt;/item&gt;
      &lt;item&gt;PAGE UP / DOWN for session page up/down&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here is the full configuration file for reference:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
          &lt;p&gt;6&lt;/p&gt;
          &lt;p&gt;7&lt;/p&gt;
          &lt;p&gt;8&lt;/p&gt;
          &lt;p&gt;9&lt;/p&gt;
          &lt;p&gt;10&lt;/p&gt;
          &lt;p&gt;11&lt;/p&gt;
          &lt;p&gt;12&lt;/p&gt;
          &lt;p&gt;13&lt;/p&gt;
          &lt;p&gt;14&lt;/p&gt;
          &lt;p&gt;15&lt;/p&gt;
          &lt;p&gt;16&lt;/p&gt;
          &lt;p&gt;17&lt;/p&gt;
          &lt;p&gt;18&lt;/p&gt;
          &lt;p&gt;19&lt;/p&gt;
          &lt;p&gt;20&lt;/p&gt;
          &lt;p&gt;21&lt;/p&gt;
          &lt;p&gt;22&lt;/p&gt;
          &lt;p&gt;23&lt;/p&gt;
          &lt;p&gt;24&lt;/p&gt;
          &lt;p&gt;25&lt;/p&gt;
          &lt;p&gt;26&lt;/p&gt;
          &lt;p&gt;27&lt;/p&gt;
          &lt;p&gt;28&lt;/p&gt;
          &lt;p&gt;29&lt;/p&gt;
          &lt;p&gt;30&lt;/p&gt;
          &lt;p&gt;31&lt;/p&gt;
          &lt;p&gt;32&lt;/p&gt;
          &lt;p&gt;33&lt;/p&gt;
          &lt;p&gt;34&lt;/p&gt;
          &lt;p&gt;35&lt;/p&gt;
          &lt;p&gt;36&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;; Options record: SORT/S,GROUP/S,NOPATH/S,NOTOOLTYPES/S&lt;/p&gt;
          &lt;p&gt;OPTIONS nopath ; notooltypes&lt;/p&gt;
          &lt;p&gt;; FILETYPE records: `FILETYPE/K,FMT/K,REMOVE/S'&lt;/p&gt;
          &lt;p&gt;FILETYPE TEXT FMT "E %a"&lt;/p&gt;
          &lt;p&gt;FILETYPE ILBM FMT "sys:utilities/display %a*N"&lt;/p&gt;
          &lt;p&gt;FILETYPE DOC FMT "sys:utilities/more %a*N"&lt;/p&gt;
          &lt;p&gt;; Command records: `COMMAND/K,PATH/K,PAT/K,FMT/K,REMOVE/S'&lt;/p&gt;
          &lt;p&gt;COMMAND EXecute PATH S: ; an argument PATH&lt;/p&gt;
          &lt;p&gt;COMMAND DELete FMT "%f%0 %1 %2 %3%l" ; multiple files&lt;/p&gt;
          &lt;p&gt;COMMAND REName FMT "REName FROM %0 TO %0" ; command-specific rewrite&lt;/p&gt;
          &lt;p&gt;COMMAND tex PAT "#?.tex"&lt;/p&gt;
          &lt;p&gt;COMMAND DVisw PAT "#?.dvi" FMT "%f%r0%l"&lt;/p&gt;
          &lt;p&gt;COMMAND wait FMT "You're waiting ... %0" ; input context example&lt;/p&gt;
          &lt;p&gt;COMMAND VERsion PATH "libs:,devs:"&lt;/p&gt;
          &lt;p&gt;; Hotkeys: `KEY/K,QUAL/K,PATH/K,PAT/K,FMT/K,AUTO/S,REMOVE/S'&lt;/p&gt;
          &lt;p&gt;KEY 66 QUAL 0 ; TAB key for completion &lt;/p&gt;
          &lt;p&gt;KEY 29 FMT ";Choices: %0 %1 %2 %3 %4 %5 %6 %7 %8 %9"&lt;/p&gt;
          &lt;p&gt;; Input keys: `KEY/K,QUAL/K,NAME/K,PATH/K,PAT/K,FMT/K,AUTO/S,REMOVE/S'&lt;/p&gt;
          &lt;p&gt;KEY 76 QUAL 8 NAME CTRL-UARROW FMT "*E[101]" ; search up&lt;/p&gt;
          &lt;p&gt;KEY 77 QUAL 8 NAME CTRL-RARROW FMT "*E[100]" ; search down&lt;/p&gt;
          &lt;p&gt;KEY 62 QUAL 0 NAME KPUARROW FMT "*E[103]" ; line up&lt;/p&gt;
          &lt;p&gt;KEY 30 QUAL 0 NAME KPDARROW FMT "*E[102]" ; line down&lt;/p&gt;
          &lt;p&gt;KEY 31 QUAL 0 NAME PGUP FMT "*E[113]" ; page up&lt;/p&gt;
          &lt;p&gt;KEY 63 QUAL 0 NAME PGDOWN FMT "*E[112]" ; page down&lt;/p&gt;
          &lt;p&gt;KEY 61 QUAL 0 NAME HOME FMT "*E[99]" ; session top&lt;/p&gt;
          &lt;p&gt;KEY 29 QUAL 0 NAME END FMT "*E[98]" ; session bottom&lt;/p&gt;
          &lt;p&gt;KEY 79 QUAL 16 NAME LALT-LARROW FMT "*E[79]" ; skip left name alt-control-O&lt;/p&gt;
          &lt;p&gt;KEY 78 QUAL 16 NAME LALT-RARROW FMT "*E[73]" ; skip right name alt-control-I&lt;/p&gt;
          &lt;p&gt;KEY 79 QUAL 8 NAME CTRL-LARROW FMT "*E[85]" ; del left name alt-control-U&lt;/p&gt;
          &lt;p&gt;KEY 78 QUAL 8 NAME CTRL-RARROW FMT "*E[89]" ; del right name alt-control-Y&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I also customized the WShell prompt in S:WShell-Startup to make it more informative and visually clear: the time is displayed between brackets in black (color 2), followed by the current path in orange (color 3).&lt;/p&gt;
    &lt;p&gt;Here is the content of SYS/s:WShell-Startup :&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;prompt "%2[%t] %3%c%1&amp;gt;"&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Additionally, I modified SYS:/s:ENV/titlebar to display the shell number, free fast memory, and free chip memory:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;%w %n - %mc chip / %mf fast&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Finally, I set WShell as the default CLI by adding it somewhere in the startup-sequence.&lt;lb/&gt;The extract below for reference:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;; WShell&lt;/p&gt;
          &lt;p&gt;assign remove CON: ; is replaced by the next line&lt;/p&gt;
          &lt;p&gt;C:DHOpts CON: PIP: ; set the new display handler&lt;/p&gt;
          &lt;p&gt;C:FComp ; enable completion and history navigation&lt;/p&gt;
          &lt;p&gt;C:SetExecute ; use wshell for Execute command&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Custom menu for quick access to most usefull tools&lt;/head&gt;
    &lt;p&gt;The final touch for a more usable Workbench 1.3 is customizing the system menu to include shortcuts to the most frequently used tools, such as DiskMaster, Textra, and NewShell.&lt;/p&gt;
    &lt;p&gt;To achieve this, I installed MyMenu following the official documentation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Copied the main program to SYS:C .&lt;/item&gt;
      &lt;item&gt;Copied MyMenu.conf to SYS:S and configured it according to my preferences.&lt;/item&gt;
      &lt;item&gt;Copied MyMenu-Handler to SYS:L&lt;/item&gt;
      &lt;item&gt;Called MyMenu in the startup-sequence, right after LoadWB.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The full configuration file is as follows:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
          &lt;p&gt;6&lt;/p&gt;
          &lt;p&gt;7&lt;/p&gt;
          &lt;p&gt;8&lt;/p&gt;
          &lt;p&gt;9&lt;/p&gt;
          &lt;p&gt;10&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;color 2&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;D&amp;gt; Tools DiskMaster | CLI SYS:c/dm SYS:s/dm.conf&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;S&amp;gt; Tools NewShell | WB SYS:NewWSH&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;B&amp;gt; Tools BootX | WB SYS:System/bootx&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;T&amp;gt; Tools Textra | CLI SYS:c/Textra&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;S&amp;gt; Tools CygnusED | WB SYS:Utilities/CygnusED&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;A&amp;gt; Floppy Dms-Adf | WB SYS:tools/tsgui&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;D&amp;gt; Floppy SuperDuper | WB SYS:tools/SD&lt;/p&gt;
          &lt;p&gt;menu &amp;lt;X&amp;gt; Floppy X-Copy | CLI SYS:c/xCopy&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Workbench enhancements &amp;amp; tools&lt;/head&gt;
    &lt;p&gt;The following software is not strictly necessary, but each clearly enhances the Workbench 1.3 experience. They are easy to install, require little to no configuration, and bring useful improvements to everyday use. I’ll go quickly through them:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Software&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Comment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FKeys&lt;/cell&gt;
        &lt;cell&gt;keyboard shortcuts to switch between Windows and screen&lt;/cell&gt;
        &lt;cell&gt;Copied to a new Commodities drawer on SYS: and run from the startup-sequence.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dmouse&lt;/cell&gt;
        &lt;cell&gt;Fine-tuned mouse accelerator and screen blanker&lt;/cell&gt;
        &lt;cell&gt;Executable to SYS:C, handler to SYS:L launched via startup-sequence: dmouse -a1 -t0 -A0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Msclock&lt;/cell&gt;
        &lt;cell&gt;Displays the time on the menu bar&lt;/cell&gt;
        &lt;cell&gt;Same installation logic as DMouse: executable to SYS:C , handler to SYS:L, then run from startup-sequence: msclock -d -m -o .&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PPnew&lt;/cell&gt;
        &lt;cell&gt;Powerpacker tools &amp;amp; libraries (required for some packed programs and mods)&lt;/cell&gt;
        &lt;cell&gt;Copied PPMore/powerpacker.library to SYS:libs , pp and PPMore to SYS:C , PPMore.doc to SYS:docs , same for ppShow and ppAnim&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LHA&lt;/cell&gt;
        &lt;cell&gt;Default file archiver on AmigaOS&lt;/cell&gt;
        &lt;cell&gt;Ran LHA_e138.run to extract files, then copied lha, splitlzh , and joinlzh to SYS:C&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;BootX&lt;/cell&gt;
        &lt;cell&gt;Up-to-date antivirus for OS 1.3&lt;/cell&gt;
        &lt;cell&gt;On my setup it crashes often, but it can detect viruses in memory, bootblocks, floppies, and files. Installation: libs/reqtools.library.13 to SYS:libs, all BootX files to SYS:system , BootX.doc to SYS:docs, latest recognition file to SYS:system. Adjusted colors for a Workbench 1.3 look: color1=blue 05A, color2=white FFF, color3=black 002, color4=orange F80.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Setclock v34.3&lt;/cell&gt;
        &lt;cell&gt;Y2K-compatible clock for OS 1.3&lt;/cell&gt;
        &lt;cell&gt;Prevents year misinterpretation (e.g., 2000=1979).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Mostra 1.08&lt;/cell&gt;
        &lt;cell&gt;Image viewer&lt;/cell&gt;
        &lt;cell&gt;Copied to SYS:Utilities&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These tools improve daily usability, add visual polish, and ensure compatibility with classic file formats and archives.&lt;/p&gt;
    &lt;head rend="h3"&gt;Floppy disk Tools&lt;/head&gt;
    &lt;p&gt;Even though I can manipulate Amiga floppies on my other machines, sometimes it’s quicker to work directly on the A500 when it’s connected. The following software makes floppy management much easier:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Software&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Comment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;X-Copy&lt;/cell&gt;
        &lt;cell&gt;Well-known floppy disk copier&lt;/cell&gt;
        &lt;cell&gt;Copied to SYS:C&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DMS amd TSGui&lt;/cell&gt;
        &lt;cell&gt;Floppy disk (un)archiver and associated GUI&lt;/cell&gt;
        &lt;cell&gt;Ran dms1111.run to extract DMS, and unlha for the TSGui archive. Then copied: dms to SYS:C, DMS.doc to SYS:docs, tsgui to SYS:Tools&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SuperDuper&lt;/cell&gt;
        &lt;cell&gt;Another floppy disk copier&lt;/cell&gt;
        &lt;cell&gt;Copied sd to SYS:Tools and documentation to SYS:Docs.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Tested but removed&lt;/head&gt;
    &lt;p&gt;I also tried installing and using some other interesting tools and hacks, but ultimately removed them because they caused crashes or unexpected behavior on my setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ZoomDaemon: Adds a “new window” widget to minimize windows. However, it also displayed this for invisible Workbench windows, which looked awkward — and it caused frequent crashes. At least my system is stable again without it.&lt;/item&gt;
      &lt;item&gt;NoClick2: Ran fine in Amiberry/UAE, but crashed on the real Amiga 500.&lt;/item&gt;
      &lt;item&gt;SimGen + RunBack: Fun for adding backdrop pictures, but it led to unexpected and frequent Guru Meditation errors.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sometimes, stability wins over flashy features, especially when working with a vintage machine like the A500.&lt;/p&gt;
    &lt;head rend="h3"&gt;Startup-sequence&lt;/head&gt;
    &lt;p&gt;It’s now time to share my startup-sequence. Of course, everyone has their own rules and preferences, so I’m simply presenting mine as an example.&lt;/p&gt;
    &lt;p&gt;My approach was guided by three main goals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Simplify the default OS 1.3 naming conventions: instead of juggling startup-sequence, startup-sequence.FD, and startupII.&lt;/item&gt;
      &lt;item&gt;Consolidate everything related to my base but customized Workbench into a single file for easier maintenance.&lt;/item&gt;
      &lt;item&gt;Create a user-startup, similar to OS 2.0+, mainly to handle application-specific assigns and personal tweaks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The full startup-sequence file is provided below for reference:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;1&lt;/p&gt;
          &lt;p&gt;2&lt;/p&gt;
          &lt;p&gt;3&lt;/p&gt;
          &lt;p&gt;4&lt;/p&gt;
          &lt;p&gt;5&lt;/p&gt;
          &lt;p&gt;6&lt;/p&gt;
          &lt;p&gt;7&lt;/p&gt;
          &lt;p&gt;8&lt;/p&gt;
          &lt;p&gt;9&lt;/p&gt;
          &lt;p&gt;10&lt;/p&gt;
          &lt;p&gt;11&lt;/p&gt;
          &lt;p&gt;12&lt;/p&gt;
          &lt;p&gt;13&lt;/p&gt;
          &lt;p&gt;14&lt;/p&gt;
          &lt;p&gt;15&lt;/p&gt;
          &lt;p&gt;16&lt;/p&gt;
          &lt;p&gt;17&lt;/p&gt;
          &lt;p&gt;18&lt;/p&gt;
          &lt;p&gt;19&lt;/p&gt;
          &lt;p&gt;20&lt;/p&gt;
          &lt;p&gt;21&lt;/p&gt;
          &lt;p&gt;22&lt;/p&gt;
          &lt;p&gt;23&lt;/p&gt;
          &lt;p&gt;24&lt;/p&gt;
          &lt;p&gt;25&lt;/p&gt;
          &lt;p&gt;26&lt;/p&gt;
          &lt;p&gt;27&lt;/p&gt;
          &lt;p&gt;28&lt;/p&gt;
          &lt;p&gt;29&lt;/p&gt;
          &lt;p&gt;30&lt;/p&gt;
          &lt;p&gt;31&lt;/p&gt;
          &lt;p&gt;32&lt;/p&gt;
          &lt;p&gt;33&lt;/p&gt;
          &lt;p&gt;34&lt;/p&gt;
          &lt;p&gt;35&lt;/p&gt;
          &lt;p&gt;36&lt;/p&gt;
          &lt;p&gt;37&lt;/p&gt;
          &lt;p&gt;38&lt;/p&gt;
          &lt;p&gt;39&lt;/p&gt;
          &lt;p&gt;40&lt;/p&gt;
          &lt;p&gt;41&lt;/p&gt;
          &lt;p&gt;42&lt;/p&gt;
          &lt;p&gt;43&lt;/p&gt;
          &lt;p&gt;44&lt;/p&gt;
          &lt;p&gt;45&lt;/p&gt;
          &lt;p&gt;46&lt;/p&gt;
          &lt;p&gt;47&lt;/p&gt;
          &lt;p&gt;48&lt;/p&gt;
          &lt;p&gt;49&lt;/p&gt;
          &lt;p&gt;50&lt;/p&gt;
          &lt;p&gt;51&lt;/p&gt;
          &lt;p&gt;52&lt;/p&gt;
          &lt;p&gt;53&lt;/p&gt;
          &lt;p&gt;54&lt;/p&gt;
          &lt;p&gt;55&lt;/p&gt;
          &lt;p&gt;56&lt;/p&gt;
          &lt;p&gt;57&lt;/p&gt;
          &lt;p&gt;58&lt;/p&gt;
          &lt;p&gt;59&lt;/p&gt;
          &lt;p&gt;60&lt;/p&gt;
          &lt;p&gt;61&lt;/p&gt;
          &lt;p&gt;62&lt;/p&gt;
          &lt;p&gt;63&lt;/p&gt;
          &lt;p&gt;64&lt;/p&gt;
          &lt;p&gt;65&lt;/p&gt;
          &lt;p&gt;66&lt;/p&gt;
          &lt;p&gt;67&lt;/p&gt;
          &lt;p&gt;68&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;SetPatch &amp;gt;NIL:&lt;/p&gt;
          &lt;p&gt;SetPatchMrgCop &amp;gt;NIL:&lt;/p&gt;
          &lt;p&gt;SYS:System/FastMemFirst&lt;/p&gt;
          &lt;p&gt;SetClock load &lt;/p&gt;
          &lt;p&gt;Addbuffers df0: 30&lt;/p&gt;
          &lt;p&gt;; faster text rendition&lt;/p&gt;
          &lt;p&gt;FF &amp;gt;NIL: -0&lt;/p&gt;
          &lt;p&gt;; preload most used commands&lt;/p&gt;
          &lt;p&gt;resident c:Resident pure&lt;/p&gt;
          &lt;p&gt;resident c:List pure&lt;/p&gt;
          &lt;p&gt;resident c:CD pure&lt;/p&gt;
          &lt;p&gt;resident c:Mount pure&lt;/p&gt;
          &lt;p&gt;resident c:Assign pure&lt;/p&gt;
          &lt;p&gt;resident c:Makedir pure&lt;/p&gt;
          &lt;p&gt;resident c:dir pure&lt;/p&gt;
          &lt;p&gt;resident CLI L:Shell-Seg SYSTEM pure add; activate Shell&lt;/p&gt;
          &lt;p&gt;; assign&lt;/p&gt;
          &lt;p&gt;assign sys: dh0:&lt;/p&gt;
          &lt;p&gt;assign c: SYS:c&lt;/p&gt;
          &lt;p&gt;assign L: SYS:l&lt;/p&gt;
          &lt;p&gt;assign FONTS: SYS:fonts&lt;/p&gt;
          &lt;p&gt;assign CGFONTS: SYS:CGFonts&lt;/p&gt;
          &lt;p&gt;assign CGCACHE: SYS:CGFonts/CGCache&lt;/p&gt;
          &lt;p&gt;assign S: SYS:s&lt;/p&gt;
          &lt;p&gt;assign DEVS: SYS:devs&lt;/p&gt;
          &lt;p&gt;assign LIBS: SYS:libs&lt;/p&gt;
          &lt;p&gt;; Ramdisk config&lt;/p&gt;
          &lt;p&gt;makedir ram:t&lt;/p&gt;
          &lt;p&gt;makedir ram:env&lt;/p&gt;
          &lt;p&gt;makedir ram:clipboards &lt;/p&gt;
          &lt;p&gt;assign t: ram:t&lt;/p&gt;
          &lt;p&gt;assign ENV: ram:env&lt;/p&gt;
          &lt;p&gt;assign CLIPS: ram:clipboards&lt;/p&gt;
          &lt;p&gt;copy S:env/ ENV: QUIET&lt;/p&gt;
          &lt;p&gt;copy S:Ramdisk.info ram:Disk.info&lt;/p&gt;
          &lt;p&gt;copy S:ram.info ram:.info&lt;/p&gt;
          &lt;p&gt;; Mounts&lt;/p&gt;
          &lt;p&gt;mount speak:&lt;/p&gt;
          &lt;p&gt;mount aux:&lt;/p&gt;
          &lt;p&gt;mount pipe:&lt;/p&gt;
          &lt;p&gt;; WShell&lt;/p&gt;
          &lt;p&gt;assign remove CON: ; is replaced by the next line&lt;/p&gt;
          &lt;p&gt;C:DHOpts CON: PIP: ; set the new displaz handler&lt;/p&gt;
          &lt;p&gt;C:FComp ; enable completion and history navigation&lt;/p&gt;
          &lt;p&gt;C:SetExecute ; use wshell for Execute command&lt;/p&gt;
          &lt;p&gt;; set keymap&lt;/p&gt;
          &lt;p&gt;SYS:System/SetMap F&lt;/p&gt;
          &lt;p&gt;;set path for Workbench&lt;/p&gt;
          &lt;p&gt;path ram: c: sys:utilities sys:system s: sys:prefs add&lt;/p&gt;
          &lt;p&gt;C:dmouse &amp;gt;NIL: -a1 -t0 -A0&lt;/p&gt;
          &lt;p&gt;C:msclock &amp;gt;NIL: -d -m -o&lt;/p&gt;
          &lt;p&gt;SYS:commodities/Fkeys &amp;gt;NIL:&lt;/p&gt;
          &lt;p&gt;execute s:user-startup&lt;/p&gt;
          &lt;p&gt;; load workbench&lt;/p&gt;
          &lt;p&gt;LoadWB delay&lt;/p&gt;
          &lt;p&gt;C:MyMenu&lt;/p&gt;
          &lt;p&gt;endcli&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;ScreenShots&lt;/head&gt;
    &lt;p&gt;To produce cleaner and more polished screenshots, I captured them using Amiberry / UAE rather than the real hardware.&lt;/p&gt;
    &lt;p&gt;This allows for crisp images that clearly show the Workbench, tools, and customizations without the glare or color inconsistencies that sometimes appear on a CRT display.&lt;/p&gt;
    &lt;p&gt;Below are several examples illustrating my setup and configurations:&lt;/p&gt;
    &lt;head rend="h2"&gt;See it live on real hardware&lt;/head&gt;
    &lt;p&gt;If you want to see the fully restored and customized Amiga 500 in action, here’s a video showing it running on the real hardware. It demonstrates the Workbench, tools, and all the tweaks described in this article.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45978545</guid><pubDate>Wed, 19 Nov 2025 12:02:49 +0000</pubDate></item><item><title>How do the pros get someone to leave a cult?</title><link>https://www.theguardian.com/science/2025/nov/19/how-to-leave-a-cult-experts-intervention</link><description>&lt;doc fingerprint="f724919d2ae3c799"&gt;
  &lt;main&gt;
    &lt;p&gt;When the phone rings at Patrick Ryan and Joseph Kelly’s home in Philadelphia, chances are the caller is desperate. One couple rang because their son was about to abandon his medical practice to follow a new-age guru in Spain. Another call came from a husband whose wife was emptying their life savings for a self-proclaimed prophet in Australia. Yet another family phoned about their niece, who was in a relationship with a man stealing from her, maybe drugging her, probably sexually assaulting her.&lt;/p&gt;
    &lt;p&gt;These families had tried everything else. When nothing worked, they heard there were two men in Philadelphia who might still be able to bring their loved one home.&lt;/p&gt;
    &lt;p&gt;What Ryan and Kelly do is unusual: they help people leave cults. Over the past 40 years, they have handled hundreds of cases – some simple and local, others stretching across borders and decades. They have been hired by families of both modest and considerable means. They say they have even been hired by government agencies, and that some cults they have investigated have left them genuinely afraid for their lives.&lt;/p&gt;
    &lt;p&gt;Although many people are involved in cultic studies and education, fewer than 10 people in the US do anything like what Ryan and Kelly do. And among those, only Kelly and Ryan practice their strange and unique method: embedding themselves in families’ lives, pulling on threads like marionettists, sometimes for years.&lt;/p&gt;
    &lt;p&gt;Their method goes something like this. A family reaches out about their daughter, husband, nephew or grandchild. Ryan and Kelly conduct an assessment that can take anywhere from a day to a week (they would not say exactly). They charge $2,500 for the assessment, then $250 an hour after that, interviewing the family until they understand the dynamics well enough to devise a strategy. Then, over months or sometimes years, they work to create the conditions in which a person might begin to question the beliefs their life has been built on.&lt;/p&gt;
    &lt;p&gt;Normally, Kelly and Ryan work by strengthening the existing relationships in a person’s life. It can be a long game. They will educate the family about the cultic group, and give advice about what to say (or not to say). They will bring in experts: psychiatrists, lawyers, priests that can provide perspective and counsel. The goal is to untangle the family dynamics that might have made someone vulnerable to a cult in the first place.&lt;/p&gt;
    &lt;p&gt;Very occasionally, they meet face to face with the person involved in a cult. But these encounters look nothing like a drug intervention, with friends gathered in a circle and the reason for the meeting laid bare. Instead, Ryan and Kelly will act covertly. In one case, a son (the cult member) came home for a few days. His parents told him that Ryan and Kelly were friends of theirs, “family mediators” who happened to be “in town for a few days, to meet with some colleagues” – both technically true. The pair made sure to “forget” a book at the family home, and return the next day to collect it, as they began to build rapport.&lt;/p&gt;
    &lt;p&gt;I met Kelly and Ryan at their place in south Philadelphia, a three-story house they share with a big dog named Kenny and a bright green parrot named Greta.&lt;/p&gt;
    &lt;p&gt;Greta was a consolation prize Ryan bought for himself after a failed intervention, the second he ever attempted. It was the 1980s and his client, a woman who had recently finished her master’s at a prestigious university, had been drawn into a scam job. It was essentially a pyramid scheme built around a health regimen. Before you could sell it, you had to try it, so you knew what you were selling.&lt;/p&gt;
    &lt;p&gt;The regimen? Multiple enemas a day. “It escalated to 40 to 60 enemas a day,” Ryan said. “And when you do that many enemas, it upsets the electrolyte balance in your body and you begin hallucinating.”&lt;/p&gt;
    &lt;p&gt;He spent three days trying to reason with her, but she would not budge. Ryan asked himself: what value do I have if I can’t even talk someone out of an enema cult? Frustrated, he went for a walk, saw a bird in a pet shop window who said: “Hello, hello.” He put her in his coat, fashioned a small cage, took her on an airplane and brought her home.&lt;/p&gt;
    &lt;p&gt;Their approach has changed a lot since those early interventions.&lt;/p&gt;
    &lt;p&gt;First, they are careful with language. They don’t love the word cult. They say it’s a cudgel: too blunt an instrument to get at the heart of the problem. Also, even if a client leaves a group and returns home, Ryan and Kelly wouldn’t say they “got them out”. They describe themselves as mediators who build bridges through which families can reach their loved ones. Sometimes, the person crosses that bridge. Sometimes, the outcome is more complicated.&lt;/p&gt;
    &lt;p&gt;Second, they have worked hard to distance themselves from “deprogramming” – the practice most people associate with cult interventions. In the 1970s and 80s, deprogramming could involve kidnappings, involuntary confinement and even violence. In one case Kelly mentioned, a cult member was held at gunpoint. It was controversial, and its effectiveness was questionable. “That,” Ryan said more than once, “is not what we do.”&lt;/p&gt;
    &lt;p&gt;Nowadays, they focus more on helping someone reach their own informed conclusion about the group they are part of, trying to soften the obstacles that might cloud their judgment.&lt;/p&gt;
    &lt;p&gt;For instance: one of the tricky parts, they explained, is communicating with a person who has been given tools to block out other people’s perspectives. This set of tools or ideas is what Ryan and Kelly call a group’s “gatekeeper”.&lt;/p&gt;
    &lt;p&gt;Ryan gave me an example. One client came from an extremely rigid, orthodox Catholic family. The family had a plan for life: retire early, save well, put the kids through college. But against these goals, the wife had joined an eastern religious group and was donating thousands of dollars to it. She had quit her job, and the marriage was collapsing.&lt;/p&gt;
    &lt;p&gt;The gatekeeper, Ryan and Kelly decided, was that the woman perceived her spouse “as dogmatic, fundamentalist – but not spiritual”. They needed to change her mind about her husband.&lt;/p&gt;
    &lt;p&gt;So Ryan called an old friend of Kelly’s, a Jesuit priest who lived in a parish near the family’s home. Ryan asked the priest to meet the husband. The two men became friends and agreed to meet regularly – all according to Ryan and Kelly’s plan. Every so often, the husband would text his wife: “I’m coming home late tonight, meeting my priest friend.”&lt;/p&gt;
    &lt;p&gt;“She’s like, ‘What priest friend?’” Ryan said.&lt;/p&gt;
    &lt;p&gt;After a few months, the wife became curious enough to want to meet her husband’s new friend. The priest, who was genuinely thrilled, nearly veered off plan by offering to speak with her directly. He believed she was ready to hear his views on spirituality. But Ryan stopped him: “I told him, look, they hired us to be strategists. I have a strategy for this.”&lt;/p&gt;
    &lt;p&gt;Ryan mapped out the parish and planned a tour. He made sure the route passed through the library specifically, the section with many eastern religious books. “You’re gonna go through there,” Ryan told the priest.&lt;/p&gt;
    &lt;p&gt;On a Friday, the husband brought his wife along to visit. The priest greeted them warmly and showed her the grounds. They walked through the library. She saw the books.&lt;/p&gt;
    &lt;p&gt;Soon, the priest was coming over for barbecues. They all became friends. And she began openly talking with her husband about the group she was involved in: the good and the bad. They had passed the group’s gatekeeper. But the work was not finished.&lt;/p&gt;
    &lt;p&gt;All groups have a rhythm, like a pulse across the calendar year. We have holidays, and we have tax season. There are highs and lows. If you want to talk to someone about how dangerous their group is, you probably do not want to do it right after they have taken ayahuasca or gone on retreat. But the lows come just as reliably.&lt;/p&gt;
    &lt;p&gt;When the wife finally started to complain about the group, the husband called Ryan: “She’s going to leave!” But Ryan told him firmly: “No, she’s not. Don’t push it.”&lt;/p&gt;
    &lt;p&gt;By the third cycle, the third low point, when she was sleep deprived, working long hours and truly miserable, Ryan gave the husband a single line. “Just say to her this: ‘You gave it a good shot.’ And nothing more.”&lt;/p&gt;
    &lt;p&gt;“She said: ‘Yeah, I have. Will you help me get my stuff?’ And he said: ‘OK.’”&lt;/p&gt;
    &lt;p&gt;The whole time, the wife knew her husband had consulted Ryan and Kelly, though she did not know they had orchestrated his friendship with the priest. During the five years they worked on the case, she assumed they were anti-religious bad actors. A few months after she left the group, she met Ryan and Kelly for the first time.&lt;/p&gt;
    &lt;p&gt;In Ryan’s telling, she loved chatting with Kelly and himself because they so clearly understood what she appreciated about the group. But they also saw that she was being made to sleep only a few hours a night, drink toilet water, and work hundreds of hours recruiting members for a guru accused of sexual misconduct and labor law violations.&lt;/p&gt;
    &lt;p&gt;Ryan and Kelly started doing this work because when they were younger, they themselves had been in what would be described as cults. They were Transcendental Meditation (TM) instructors in the 70s and 80s. After about a decade with TM, they felt disturbed by their relationship to the organization, and they sued – Kelly in 1986, and Ryan in 1989 – for negligence and fraud. Kelly joined a suit as a Doe along with six others, claiming the organization had “fraudulently promised that the practice … would confer certain personal and societal benefits”, which never materialized. Ryan says that during the course of his TM training he was constantly surveilled and led to believe that he would be able to levitate and save humanity.&lt;/p&gt;
    &lt;p&gt;The case Kelly joined, which dragged on for several years, included expert testimony from clinical psychologist Margaret Singer, a brainwashing specialist who had previously assessed Charles Manson. Neither case won, but their lawsuits eventually settled, and through the course of the litigation, Ryan and Kelly left the organization. (TM did not respond to a request for comment; however, Bob Roth, CEO of the TM-associated David Lynch Foundation, did let me know the American Heart Association recently named Transcendental Meditation an official stress reducer for treating high blood pressure.)&lt;/p&gt;
    &lt;p&gt;Kelly joined another group after leaving TM. He followed his new guru for five more years. Meanwhile, Ryan told me he got busy investigating and trying to expose cults, including the group Kelly had joined. In those early days, Ryan considered himself a sort of “cult fighter”, with a much more black and white view of what cults were and what it meant to be a part of one. They finally started working together when Kelly had a falling out with his second group, whose guru was eventually convicted for child sexual abuse.&lt;/p&gt;
    &lt;p&gt;They have had a close relationship ever since, working and living together with their dog and bird in a big house they told me was once used as a base of operations by the Philly mafia, which seems oddly fitting. They mostly prefer to keep details about their personal lives off-record. Often, the families they work with need to hear very hard things, and being a sort of blank slate makes it easier for them to be whoever their clients need them to be.&lt;/p&gt;
    &lt;p&gt;Throughout reporting this piece, privacy was an issue. Ryan and Kelly told me many more details about their cases off the record. All these cases are anonymized, with some crucial details changed, to protect the identities of their clients and their families. Furthermore, Kelly and Ryan urge their clients not to speak with the media. The firmest “no” I ever got was when I asked Ryan if I could speak to a former client. The second was when I asked if they could show me emails or letters to prove they had worked with government agencies. This made it difficult to verify all the details of their stories, though I found the situations they described were consistent with other accounts of ex-members from cults they say their clients were a part of. When cases did make it to court, the details Ryan and Kelly provided me matched the legal testimony I found.&lt;/p&gt;
    &lt;p&gt;But without being able to speak to their former clients, some of the stories told here remain just that: stories in the telling of Ryan and Kelly. I was, however, able to speak with many of their collaborators, who confirmed that they had seen Ryan and Kelly’s method work close up. One of the people I spoke with, Dr Janja Lalich, is a professor emerita of sociology at California University State, Chico and author of multiple books on cults including Bounded Choice: True Believers and Charismatic Cults. Lalich lectures and consults on cultic studies, and regularly testifies as a cult expert in court cases internationally. She started studying them because she, too, joined and left a cult when she was younger. It was a radical Marxist-Leninist cult that eventually “imploded”; a process she details in her book. The members collectively overthrew the leadership and all left at the same time, she explained, “which was great”.&lt;/p&gt;
    &lt;p&gt;Lalich worked on a couple of cases with Kelly and Ryan in the 90s, when they were starting out. She did not like the work. She found it stressful and difficult, and felt some reservations about the way the process interfered with people’s lives. But the three of them have remained close over the years and still collaborate in the broader cult-awareness space, attending conferences and teaching workshops. She confirmed for me a lot of the claims Kelly and Ryan made about the cults they have dealt with, including the idea that most people who join cultic groups leave on their own.&lt;/p&gt;
    &lt;p&gt;Ryan concedes that their work can look a lot like meddling in someone’s life. But he is also firm in that they are not “hired hitmen”. They work with psychologists, psychiatrists and social workers to provide oversight, several of whom I spoke with for this piece. “You can’t just interfere with someone’s life because you don’t like what they’re doing,” Ryan told me. When Kelly and Ryan take on a case, it’s because there is some dynamic in the family system that they think their expertise can help untangle. In every case, the group in question is offering something to the person involved that the family might not be able to understand or appreciate. But to Ryan and Kelly, this appreciation is exactly the point.&lt;/p&gt;
    &lt;p&gt;One of their cases in the 90s involved a cult leader who was systematically sexually assaulting the group’s members. “I can’t get into all the details,” Ryan said. “He was horrible, a horrible man.” Ryan and Kelly had been flying regularly to Australia to work on the case. The client’s niece, a girl in the group, was beginning to fall out with the cult. The leader had been arrested and was on trial for crimes related to the cult’s activities.&lt;/p&gt;
    &lt;p&gt;In their process, Ryan and Kelly require what they call 50 things: “You have to find 50 things that you could agree with the person on.” Ryan gestured to a painting on the wall in their living room. It was a strange, surrealist-looking canvas with a big Tesla coil in the center and lightning shooting out at some pigeons. Ryan said, “If you look at this piece of art and say, ‘That’s really ugly,’ then we’re going to start off … not on the right page, right?”&lt;/p&gt;
    &lt;p&gt;But if I could appreciate what he found appealing, then, he said: “I think you have the right to criticize it.” The number may seem arbitrary, but their goal is to find 50 things a family can appreciate about a cult before discussing what they do not agree with.&lt;/p&gt;
    &lt;p&gt;I put this number to Lalich and she said the notion of having to find 50 things seemed a bit extreme. “ I certainly could never find 50 things about my cult that I thought were good.” The spirit of it seemed right to her though, at least: that the family needs to tone down their rhetoric, or they will just push the cult-involved member away.&lt;/p&gt;
    &lt;p&gt;In Kelly and Ryan’s case, the girl’s uncle, their client, had a very difficult time finding anything positive about the group or the leader who had allegedly raped his niece. When the trial came, the uncle wanted to testify against the leader, and Ryan and Kelly told him not to. “We said, if you testify, your niece … will cut you off.”&lt;/p&gt;
    &lt;p&gt;The uncle went to court anyway. Just as Ryan had predicted, the niece fell off the map entirely. She was scared they would kidnap her – try to deprogram or threaten her. Ryan and Kelly pulled some strings to find out that she had done some traveling, but otherwise, for “20 years”, Ryan said, “they didn’t know if she was alive or dead.”&lt;/p&gt;
    &lt;p&gt;On Ryan and Kelly’s counsel, the family made a social media account in the 2010s to post information about the family: weddings, births, etc. After nearly 30 years, the girl, now in middle age, finally reached out. The family had posted about how the grandfather was getting old, and she called to say she wanted to see him before he died.&lt;/p&gt;
    &lt;p&gt;Much has been written about the psychology of cults, the archetypes of cult leaders and the way they can create tragic, abusive conditions for their members. In just the past few years there have been Christian sects convicted of manslaughter of children, doomsday groups killing police officers, and starvation cults with bodies piled in mass graves. While Lalich says that to her, it is pretty clear what is or is not a cult, she also concedes that groups exist on a broad continuum ranging from extremely dangerous to “more or less” benign. She does not think that there is such a thing as a “harmless” cult – since all these groups exert some measure of coercion and manipulation. But for Ryan and Kelly, defining precisely what is or is not a cult is actually counterproductive, since so much of what they do is appeal to the person inside the cult who they are trying to reason with.&lt;/p&gt;
    &lt;p&gt;So, rather than labeling a group as a cult, Ryan and Kelly focus on “cultic relationships” that exist between a member and an organization. “Ten million people have learned Transcendental Meditation,” Ryan clarified. “Ten million people are not in a cult.” His voice rose and he shrugged. “I mean, they’ve been lied to. As a teacher, we lied to them. We told them things that were just absolutely not true.”&lt;/p&gt;
    &lt;p&gt;“Bonkers,” Kelly added from his rocking chair.&lt;/p&gt;
    &lt;p&gt;“Bonkers,” Ryan confirmed.&lt;/p&gt;
    &lt;p&gt;Over the course of their careers Ryan and Kelly have found that in order to mediate people’s relationships with these groups, they have to gain a better understanding of how they are drawn in to begin with. How is it that a cult leader can make a person seriously believe that they can levitate, or that drinking toilet water is acceptable? They have to understand how exactly a group manages to shake people’s fundamental assumptions about reality.&lt;/p&gt;
    &lt;p&gt;For example, Kelly described a case in which a leader would command people to have sex with one another: “‘You, woman, sleep with that woman.’ ‘You, sleep with that man.’” Even if participants were straight, the leader would ask them: “What is your limitation?” This is an archetype of cult leader that Kelly calls a “crazy adept”: “the disruptor, who comes in and destroys the norms in order to build up a better, purer reality.”&lt;/p&gt;
    &lt;p&gt;One of their close collaborators, Ashlen Hilliard, told me about a harrowing case whose details she preferred to keep tightly under wraps. She said they were referred to the case by a US government agency investigating the group, and it had proved extremely dangerous. If they were publicly known to be helping members leave, the group could retaliate. “I care about this,” Ryan said of this interview, “but I care more about not dying.”&lt;/p&gt;
    &lt;p&gt;Hilliard explained that in this group, words like “victim” were twisted out of shape. “Instead of assigning a negative meaning to a word like ‘victim’, they say: this is a word that indicates a badge of honor.” Then, when a member was subject to sexual violence or other abuse by the group, being a “victim” was reframed as something positive. Often, people in these groups have experienced past trauma, and this destabilization of the concept of victimhood can feel freeing – at least initially.&lt;/p&gt;
    &lt;p&gt;What Kelly and Ryan mean when they say these groups are “offering something” to people, it is exactly that. There is a hole a group fills: alienation from community, family, sexuality; pressure to follow a certain life plan, addiction, unrealized spirituality, economic catastrophe – all reasons to join a group. We all have deep pains that make us hope that maybe, if the world were different, we wouldn’t feel the way we do.&lt;/p&gt;
    &lt;p&gt;Part of why their work is so necessarily confidential is that there is always the possibility a person will go back to their group. These are people trying to make sense of a reality whose fundamental rules have been turned on its head. When is anyone ever “done” making sense of things, anyway?&lt;/p&gt;
    &lt;p&gt;Kelly still thinks about a moment with the guru he followed after leaving Transcendental Meditation, back in 1985. He had been meditating at the feet of the guru, Prakashanand Saraswati (who they called Swami-ji, or “guru”), for several days. When he looked up, he saw the Swami surrounded by “a golden light.” He was not seeing an illusion. It was a real experience, built on ideas and promises laid out by the guru: a supreme, divine, transcendent love. “The wave merging into the ocean,” Kelly said.&lt;/p&gt;
    &lt;p&gt;After that experience, Kelly felt Swami-ji could do no wrong. For the next three years, even when he saw the women visiting Swami-ji’s bedroom, the demands for thousands of dollars, the outbursts of rage; it all felt insignificant, or easily dismissed.&lt;/p&gt;
    &lt;p&gt;For that reason, Kelly and Ryan are not looking to convince people of any particular version of reality or truth. They do not seem to be interested in truth at all, really. When you use your experience to test whether or not something is true (the holiness of a guru, the righteousness of a cause) then, Ryan told me: “The person who gives you that experience will own you.” Their work is to usher people into a state of skepticism about the conclusion they have drawn from their experiences; beginning to open them up to the idea that individual experience is not the same as truth or reality.&lt;/p&gt;
    &lt;p&gt;This lighter touch approach is controversial. While interviewing people in the broader cult-awareness network, I found that Ryan and Kelly had drawn some criticism for affiliating with a certain group of academics that some people in their sphere disparage as “cult apologists”. This group belongs to a branch of cultic study that, like Ryan and Kelly, avoid the term “cult”, preferring the term “New Religious Movement”. Kelly and Ryan have consulted these academics over the years and have kept some as trusted contacts. Lalich and others say these apologists undermine survivors’ efforts to hold cults accountable for their abuses, by brushing over the harms such as child neglect and sexual abuse committed by groups like the Children of God (The Family International) or the Unification Church, even testifying in court on a cult’s behalf. It’s a bitter, complicated split in the field of cultic study, but these academics say, among other things, that they are speaking out for freedom of religion. When Ryan and Kelly mentioned these apologists, they said they understood Lalich’s criticism, but that there was a way in which they could see things “through their lens”.&lt;/p&gt;
    &lt;p&gt;Ryan and Kelly are not cult apologists, but in order to do their work they have had to keep an open mind. They neither fully endorse cults’ rights to exist, nor consider groups as bad per se. They arrive from as ideologically empty a place as they can, a skeptical place that is neither here, nor there. Doing work like this, the big question of epistemology, of what we can know and what to believe, become everyday practical quandaries.&lt;/p&gt;
    &lt;p&gt;“I just know what is not real,” Ryan told me once. Take even the broadest existential question: what are we doing here?&lt;/p&gt;
    &lt;p&gt;“The only way that can be answered, in my mind, is by a feeling,” he said. “And, that feeling is so easily manipulated.”&lt;/p&gt;
    &lt;p&gt;You have to be a certain kind of person to do this work. Though Lalich does not do interventions any more, she is glad there are people who do it in the “legitimate way”. When I asked her who she thought did it in the “legitimate way”, she only named four people. Of them, only three, including Ryan and Kelly, were still actively taking cases.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45978813</guid><pubDate>Wed, 19 Nov 2025 12:31:54 +0000</pubDate></item><item><title>The Peaceful Transfer of Power in Open Source Projects</title><link>https://shkspr.mobi/blog/2025/11/the-peaceful-transfer-of-power-in-open-source-projects/</link><description>&lt;doc fingerprint="a49110400ef6e2dd"&gt;
  &lt;main&gt;
    &lt;p&gt;Most of the people who run Open Source projects are mortal. Recent history shows us that they will all eventually die, or get bored, or win the lottery, or get sick, or be conscripted, or lose their mind.&lt;/p&gt;
    &lt;p&gt;If you've ever visited a foreign country's national history museum, I guarantee you've read this little snippet:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;King Whatshisface was a wise and noble ruler who bought peace and prosperity to all the land.&lt;/p&gt;
      &lt;p&gt;Upon his death, his heirs waged bloody war over rightful succession which plunged the country into a hundred years of hardship.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The great selling point of democracy is that it allows for the peaceful transition of power. Most modern democracies have rendered civil war almost unthinkable. Sure, you might not like the guy currently in charge, but there are well established mechanisms to limit their power and kick them out if they misbehave. If they die in office, there's an obvious and understood hierarchy for who follows them.&lt;/p&gt;
    &lt;p&gt;Most Open Source projects start small - just someone in their spare room tinkering for fun. Unexpectedly, they grow into a behemoth which now powers half the world. These mini-empires are fragile. The most popular method of governance is the Benevolent Dictator For Life model. The founder of the project controls everything. But, as I've said before, BDFL only works if the D is genuinely B. Otherwise the FL becomes FML.&lt;/p&gt;
    &lt;p&gt;The last year has seen several BDFLs act like Mad Kings. They become tyrannical despots, lashing out at their own volunteers. They execute takeovers of community projects. They demand fealty and tithes. Like dragons, they become quick to anger when their brittle egos are tested. Spineless courtiers carry out deluded orders while pilfering the coffers.&lt;/p&gt;
    &lt;p&gt;Which is why I am delighted that the Mastodon project has shown a better way to behave.&lt;/p&gt;
    &lt;p&gt;In "The Future is Ours to Build - Together" they describe perfectly how to gracefully and peacefully transfer power. There are no VCs bringing in their MBA-brained lackeys to extract maximum value while leaving a rotting husk. No one is seizing community assets and jealously hoarding them. Opaque financial structures and convoluted agreements are prominent in their absence.&lt;/p&gt;
    &lt;p&gt;Eugen Rochko, the outgoing CEO, has a remarkably honest blog post about the transition. I wouldn't wish success on my worst enemy. He talks plainly about the reality of dealing with the pressure and how he might have been a limiting factor on Mastodon's growth. That's a far step removed from the ego-centric members of The Cult of The Founder with their passionate belief in the Divine Right of Kings.&lt;/p&gt;
    &lt;p&gt;Does your tiny OSS script need a succession plan? Probably not. Do you have several thousand NPM installs per day? It might be worth working out who you can share responsibility with if you are unexpectedly raptured. Do you think that your project is going to last for a thousand years? Build an organisation which won't crumble the moment its founder is arrested for their predatory behaviour on tropical islands.&lt;/p&gt;
    &lt;p&gt;I'm begging project leaders everywhere - please read up on the social contract and the consent of the governed. Or, if reading is too woke, just behave like grown-ups rather than squabbling tweenagers.&lt;/p&gt;
    &lt;p&gt;It is a sad inevitability that, eventually, we will all be nothing but memories. The bugs that we create live after us, the patches are oft interrèd with our code. Let it be so with all Open Source projects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45979232</guid><pubDate>Wed, 19 Nov 2025 13:20:42 +0000</pubDate></item><item><title>Your Smartphone, Their Rules: App Stores Enable Corporate-Government Censorship</title><link>https://www.aclu.org/news/free-speech/app-store-oligopoly</link><description>&lt;doc fingerprint="b584999a93b71151"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Your Smartphone, Their Rules: How App Stores Enable Corporate-Government Censorship&lt;/head&gt;
    &lt;p&gt;Subscribe to the Free Future Newsletter&lt;lb/&gt; Free Future home&lt;/p&gt;
    &lt;p&gt;Who controls what you can do on your mobile phone? What happens when your device can only run what the government decides is OK? We are dangerously close to this kind of totalitarian control, thanks to a combination of government overreach and technocratic infrastructure choices.&lt;/p&gt;
    &lt;p&gt;Most Americans have a smartphone, and the average American spends over 5 hours a day on their phone. While these devices are critical to most people’s daily lives, what they can actually do is shaped by what apps are readily available. A slim majority of American smartphone users use an iPhone, which means they can only install apps available from Apple’s AppStore. Nearly all the rest of US smartphone users use some variant of Android, and by default they get their apps from Google’s Play Store.&lt;/p&gt;
    &lt;p&gt;Collectively, these two app stores shape the universe of what is available to most people as they use the Internet and make their way through their daily lives. When those app stores block or limit apps based on government requests, they are shaping what people can do, say, communicate, and experience.&lt;/p&gt;
    &lt;p&gt;Recently, Apple pulled an app called ICEBlock from the AppStore, making it unavailable in one fell swoop. This app was designed to let people anonymously report public sightings of ICE agents. In the United States people absolutely have a First Amendment right to inform others about what they have seen government officials doing and where — very much including immigration agents whose tactics have been controversial and violent. Apple pulled the ICEBlock app at the demand of the US Department of Justice. The following day, Google pulled a similar app called Red Dot from the Google Play Store.&lt;/p&gt;
    &lt;p&gt;The DOJ’s pressuring of Apple is an unacceptable, censorious overreach. And Google’s subsequent removal of Red Dot looks like troubling premature capitulation. While some experts and activists have expressed concerns over ICEBlock’s design and development practices, those concerns are no reason for the government to meddle in software distribution. The administration’s ostensible free speech warriors are trying to shape how Americans can communicate with each other about matters of pressing political concern.&lt;/p&gt;
    &lt;p&gt;Infrastructure choices&lt;lb/&gt; But the government’s overreach isn’t the whole story here. The current structure of the mobile phone ecosystem enables this kind of abuse and control.&lt;/p&gt;
    &lt;p&gt;Apple’s iOS (the operating system for any iPhone) is designed to only be able to run apps from the AppStore. If Apple hasn’t signed off on it, the app won’t run. This centralized control is ripe for abuse:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple has handed the Chinese government control over what apps are available to iPhone users in China, including banning gay dating apps.&lt;/item&gt;
      &lt;item&gt;The corporation has used its authority over the AppStore to block a game that critiqued its labor practices.&lt;/item&gt;
      &lt;item&gt;Apple’s guidelines say that “‘Enemies’ within the context of a game cannot solely target a specific … government, corporation, or any other real entity.” That represents a potential for sweeping censorship of anyone who wants to use the art of games to criticize companies or otherwise advance political messages.&lt;/item&gt;
      &lt;item&gt;It banned the popular game Fortnite from the App Store as it was battling the gamemaker to get a bigger cut of money from user transactions.&lt;/item&gt;
      &lt;item&gt;In 2012 Apple rejected an app that compiled reports of highly controversial overseas drone strikes by the U.S. government during the “War on Terror.”&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike Apple, Google’s Android operating system has traditionally allowed relatively easy access to “sideloading”, which just means installing apps through means other than Google’s Play Store. Although most installations default to getting apps from the Play Store, the availability of sideloading means that even if Google censors apps in the Play Store, people can still install them. Even apps critical of Google can make it onto an Android device. It’s also possible to run a variant of Android without the Play Store at all, such as GrapheneOS.&lt;/p&gt;
    &lt;p&gt;Unfortunately that is all set to change with a recent Google announcement that it will block apps from “certified Android” devices (which is nearly all Android phones) unless they come from what Google calls a “verified developer.” This means that the common Android user trying to install an app will have to get Google’s blessing: does this app come from someone that Google has “verified”? How Google will decide who is allowed to be verified and who is not is still unclear. Can a developer become “unverified”?&lt;/p&gt;
    &lt;p&gt;This upcoming change is framed by Google as a security measure, but merely knowing the identity of the developer of an app doesn’t provide any security. So the only way that the “verified developer” requirement can offer security is if Google withholds “verified developer” status from people it deems bad actors. But Google’s ability to withhold that status can be abused in the same way that Apple’s AppStore lock-in is being abused. A government will simply make a demand: “treat this developer as a bad actor” and effectively cut off any app by targeting its developer.&lt;/p&gt;
    &lt;p&gt;When a lever of control is available, the would-be censors will try to use it. It has never been true that someone who buys a Lenovo or Dell laptop, for example, has to let Lenovo or Dell tell them what programs they can and cannot install on their computer. Yet that will soon be the situation with regards to nearly all cell phones used in the United States.&lt;/p&gt;
    &lt;p&gt;Note that American iPhones are limited to only apps from the AppStore, but European Union (EU) iPhones don’t have that restriction. The EU’s Digital Markets Act (DMA) required Apple to permit alternate app stores and sideloading (which Apple calls “web distribution”). As a result, marketplaces like AltStore are starting to become available — but Apple only lets EU customers use them. The European regime is not perfect, however; while sideloaded apps and alternative app stores aren’t subject to the app store’s constraints, they are still obliged to follow Apple’s “Notarization” requirements, which requires Apple to review all iOS apps – even from these alternate sources – on the basis of several vaguely worded rationales. For example, if the DoJ were to claim that ICEBlock “promoted physical harm” (even though it clearly does not), Apple could use this as an excuse to justify revoking their notarization of the app, which would prevent it from being installed even from these alternate channels.&lt;/p&gt;
    &lt;p&gt;App store security and surveillance&lt;lb/&gt; Both Apple and Google make claims that their app distribution mechanisms improve security for their users. And clearly, these tech giants do block some abusive apps by exercising the control they have.&lt;/p&gt;
    &lt;p&gt;But both of them also regularly allow apps that contain common malicious patterns, including many apps built with surveillance tooling that sell their users’ data to data brokers. If either tech giant were serious about user security, they could ban these practices, but they do not. Google’s security claims are also undermined by the fact that the cellphone hacking company Cellebrite tells law enforcement that Google’s Pixel phones can be hacked, while those running GrapheneOS, created by a small non-profit, cannot. (Asked by a reporter why that was so, Google did not respond.)&lt;/p&gt;
    &lt;p&gt;Making matters worse, organizations like Google are unclear about their policies, and some of their policy statements can put developers and users at risk. Discussing blocking Red Dot, for example, Google told 404Media that “apps that have user generated content must also conduct content moderation.” This implies that Google could become unwilling to distribute fully end-to-end encrypted apps, like Signal Private Messenger or Delta Chat, since those app vendors by design are incapable of reviewing user-generated content. End-to-end encrypted apps are the gold standard for secure communications, and no app store that signals a willingness to remove them can claim to put security first.&lt;/p&gt;
    &lt;p&gt;In addition, even if you’ve carefully curated the apps you have installed from these dominant app stores to avoid spyware and use strongly secure apps, the stores themselves monitor the devices, keeping dossiers of what apps are installed on each device, and maybe more. Being a user of these app stores means being under heavy, regular surveillance.&lt;/p&gt;
    &lt;p&gt;Other options exist&lt;lb/&gt; These centralized, surveilled, censorship-enabling app stores are not the only way to distribute software. Consider alternative app stores for Android, like Accrescent, which prioritizes privacy and security requirements in its apps, and F-Droid, which enables installation of free and open source apps. In addition to offering quality tools and auditing, F-Droid’s policies incentivize the apps distributed on the platform to trim out overwhelming amounts of corporate spyware that infest both Google and Apple’s app stores. Neither F-Droid nor Accrescent do any surveillance of their users at all.&lt;/p&gt;
    &lt;p&gt;The F-Droid developers recently wrote about the impact that Google’s upcoming developer registration requirements are likely to have on the broader ecosystem of privacy-preserving Android apps. The outcome doesn’t look good: the ability to install free and open source software on a common device might be going away. Those few people left using unusual devices (“uncertified” Android deployments like GrapheneOS, or even more obscure non-Android operating systems like phosh) will still have the freedom to install tools that they want, but the overwhelming majority of people will be stuck with what can quickly devolve into a government-controlled cop-in-your-pocket.&lt;/p&gt;
    &lt;p&gt;How we can push back&lt;lb/&gt; In an increasingly centralized world, it will take very little for an abusive government to cause an effective organizing tool to disappear, to block an app that belongs to a critical dissenting media outlet, or to force invasive malware into a software update used by everyone. We need a shared infrastructure that doesn’t permit this kind of centralized control. We can disrupt oligopolistic control over software through user choice (e.g., preferring and installing free software), building good protocol frameworks (e.g., demanding tools that use open standards for interoperability), and through regulatory intervention (e.g., breaking up monopolistic actors, or mandating that an OS must allow sideloading, as the EU did with the DMA).&lt;/p&gt;
    &lt;p&gt;The device you carry with you that is privy to much of your life should be under your control, not under the control of an abusive government or corporations that do its bidding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45979297</guid><pubDate>Wed, 19 Nov 2025 13:28:40 +0000</pubDate></item><item><title>Proxmox Virtual Environment 9.1 available</title><link>https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-1</link><description>&lt;doc fingerprint="33df4f1c4cbb0f82"&gt;
  &lt;main&gt;
    &lt;p&gt;VIENNA, Austria – November 19, 2025 – Leading open-source server solutions provider Proxmox Server Solutions GmbH (henceforth "Proxmox"), today announced the immediate availability of Proxmox Virtual Environment 9.1. The new version introduces significant enhancements across container deployment, virtual machine security, and software-defined networking, offering businesses greater flexibility, performance, and operational control.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights in Proxmox Virtual Environment 9.1&lt;/head&gt;
    &lt;p&gt;Create LXC containers from OCI images&lt;/p&gt;
    &lt;p&gt;Proxmox VE 9.1 integrates support for Open Container Initiative (OCI) images, a standard format for container distribution. Users can now download widely-adopted OCI images directly from registries or upload them manually to use as templates for LXC containers. Depending on the image, these containers are provisioned as full system containers or lean application containers. Application containers are a distinct and optimized approach that ensures minimal footprint and better resource utilization for microservices. This new functionality means administrators can now deploy standardized applications (e.g., a specific database or API service) from existing container build pipelines quickly and seamlessly through the Proxmox VE GUI or command line.&lt;/p&gt;
    &lt;p&gt;Support for TPM state in qcow2 format&lt;/p&gt;
    &lt;p&gt;This version introduces the ability to store the state of a virtual Trusted Platform Module (vTPM) in the qcow2 disk image format. This allows users to perform full VM snapshots, even with an active vTPM, across diverse storage types like NFS/CIFS. LVM storages with snapshots as volume chains now support taking offline snapshots of VMs with vTPM states. This advancement improves operational agility for security-sensitive workloads, such as Windows deployments that require a vTPM.&lt;/p&gt;
    &lt;p&gt;Fine-grained control of nested virtualization&lt;/p&gt;
    &lt;p&gt;Proxmox VE now offers enhanced control for nested virtualization in specialized VMs. This feature is especially useful for workloads such as nested hypervisors or Windows environments with Virtualization-based Security (VBS). A new vCPU flag allows to conveniently and precisely enable virtualization extensions for nested virtualization. This flexible option gives IT administrators more control and offers an optimized alternative to simply exposing the full host CPU type to the guest.&lt;/p&gt;
    &lt;p&gt;Enhanced SDN status reporting&lt;/p&gt;
    &lt;p&gt;Version 9.1 comes with an improved Software-Defined Networking (SDN) stack, including detailed monitoring and reporting in the web interface. The GUI now offers more visibility into the SDN stack, displaying all guests connected to local bridges or VNets. EVPN zones additionally report the learned IPs and MAC addresses. Fabrics are integrated into the resource tree, showing routes, neighbors, and interfaces. The updated GUI offers visibility into key network components like IP-VRFs and MAC-VRFs. This enhanced observability simplifies cluster-wide network troubleshooting and monitoring of complex network topologies, without the need for the command line.&lt;/p&gt;
    &lt;head rend="h3"&gt;Availability&lt;/head&gt;
    &lt;p&gt;Proxmox Virtual Environment 9.1 is immediately available for download. Users can obtain a complete installation image via ISO download, which contains the full feature-set of the solution and can be installed quickly on bare-metal systems using an intuitive installation wizard.&lt;/p&gt;
    &lt;p&gt;Seamless distribution upgrades from older versions of Proxmox Virtual Environment are possible using the standard APT package management system. Furthermore, it is also possible to install Proxmox Virtual Environment on top of an existing Debian installation. As Free/Libre and Open Source Software (FLOSS), the entire solution is published under the GNU AGPLv3.&lt;/p&gt;
    &lt;p&gt;For enterprise users, Proxmox Server Solutions GmbH offers professional support through subscription plans. Pricing for these subscriptions starts at EUR 115 per year and CPU. A subscription provides access to the stable Enterprise Repository with timely updates via the web interface, as well as to certified technical support and is recommended for production use.&lt;/p&gt;
    &lt;p&gt;Resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ISO Image Download: https://www.proxmox.com/en/downloads&lt;/item&gt;
      &lt;item&gt;Forum Announcement: https://forum.proxmox.com/&lt;/item&gt;
      &lt;item&gt;Video tutorial: What’s new in Proxmox VE 9.1&lt;/item&gt;
      &lt;item&gt;Roadmap: For published and upcoming features, see the Release Notes &amp;amp; Roadmap&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Facts&lt;lb/&gt;The open-source project Proxmox VE has a huge worldwide user base with more than 1.6 million hosts. The virtualization platform has been translated into over 31 languages. More than 225,000 active community members in the support forum engage with and help each other. By using Proxmox VE as an alternative to proprietary virtualization management solutions, enterprises are able to centralize and modernize their IT infrastructure, and turn it into a cost-effective and flexible software-defined data center, based on the latest open-source technologies. Tens of thousands of customers rely on enterprise support subscriptions from Proxmox Server Solutions GmbH.&lt;/p&gt;
    &lt;p&gt;About Proxmox Server Solutions&lt;lb/&gt;Proxmox provides powerful and user-friendly open-source server software. Enterprises of all sizes and industries use the Proxmox solutions to deploy efficient and simplified IT infrastructures, minimize total cost of ownership, and avoid vendor lock-in. Proxmox also offers commercial support, training services, and an extensive partner ecosystem to ensure business continuity for its customers. Proxmox Server Solutions GmbH was established in 2005 and is headquartered in Vienna, Austria.&lt;/p&gt;
    &lt;p&gt;Contact: Daniela Häsler, Proxmox Server Solutions GmbH, marketing@proxmox.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45980005</guid><pubDate>Wed, 19 Nov 2025 14:35:17 +0000</pubDate></item><item><title>How to Stay Sane in a World That Rewards Insanity</title><link>https://www.joanwestenberg.com/p/how-to-stay-sane-in-a-world-that-rewards-insanity</link><description>&lt;doc fingerprint="342b931f185a855c"&gt;
  &lt;main&gt;
    &lt;p&gt;Somewhere around 2016, the smartest people I knew started saying increasingly stupid things.&lt;/p&gt;
    &lt;p&gt;These were folks who could parse dense academic papers, who understood reason, who were entirely capable of holding two competing ideas in their heads without their brains short-circuiting.&lt;/p&gt;
    &lt;p&gt;But something changed.&lt;/p&gt;
    &lt;p&gt;One friend became “convinced” that every major news story was manufactured consent. Another started treating political disagreement as evidence of moral corruption. A third began using the word "liberal" as if it was a personality disorder rather than loose coalitions of sometimes contradictory beliefs.&lt;/p&gt;
    &lt;p&gt;The common thread: their extreme positions got them more of what they wanted. The friend who saw conspiracies everywhere built a following. Then an audience. Then a 7-figure income stream. The one who tribalized every issue found a ready-made community that validated every prior. Etc, etc.&lt;/p&gt;
    &lt;p&gt;The incentive gradient was clear: sanity was expensive, and extremism paid dividends.&lt;/p&gt;
    &lt;p&gt;We talk a lot about polarization as if it were a disease that infected society, but we’re missing a key data point: polarization is a growth hack, and it works.&lt;/p&gt;
    &lt;p&gt;It delivers results.&lt;/p&gt;
    &lt;p&gt;When you pick a side and commit to it wholly and without reservation, you get things that moderate positions cannot provide. You get certainty in an uncertain world. You get a community that will defend you. You get a simple heuristic for navigating complex issues.&lt;/p&gt;
    &lt;p&gt;Above all: you get engagement, attention and influence.&lt;/p&gt;
    &lt;p&gt;The writer who says "this issue has nuance and I can see valid concerns on multiple sides" gets a pat on the head and zero retweets. The influencer who says "everyone who disagrees with me on this is either evil or stupid" gets quote-tweeted into visibility and gains followers who appreciate their approximation of clarity.&lt;/p&gt;
    &lt;p&gt;The returns on reasonableness have almost entirely collapsed.&lt;/p&gt;
    &lt;head rend="h1"&gt;Which begs the question: why resist? If extremism delivers what people want, maybe we should just let it run its course and stop clutching our pearls?&lt;/head&gt;
    &lt;p&gt;The problem is what happens when everyone optimizes for the same short-term wins.&lt;/p&gt;
    &lt;p&gt;You end up in a world where changing your mind becomes impossible because you've built your entire identity around being right. Where admitting uncertainty is social suicide. Where every conversation is a performance for your tribe rather than an actual exchange of ideas. You lose the ability to solve problems that don't fit neatly into your ideological framework, which turns out to be most important problems.&lt;/p&gt;
    &lt;p&gt;Someone who goes all-in on ideological purity might start with a few strong opinions. Then those opinions attract an audience. That audience expects consistency. Any deviation gets punished. So they double down. They have to keep escalating to maintain their position, finding new heresies to denounce, new lines to draw. They've locked themselves into a trajectory they can't escape without losing everything they've built.&lt;/p&gt;
    &lt;p&gt;They're prisoners of their own brand.&lt;/p&gt;
    &lt;p&gt;Scale this up and you get a society where nobody can back down, where every disagreement = existential, where we've lost the ability to make tradeoffs // acknowledge complexity.&lt;/p&gt;
    &lt;p&gt;The incentives push us toward positions that feel good but make us collectively stupider.&lt;/p&gt;
    &lt;p&gt;And you can't opt out by just accepting your side lost.&lt;/p&gt;
    &lt;p&gt;You're stuck in stupid-world too.&lt;/p&gt;
    &lt;head rend="h1"&gt;So how do you actually stay sane?&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Start by diversifying your information diet in ways that feel actively uncomfortable. The goal isn't to agree with everything you read. You'll still think most of it is wrong. But exposing yourself to articulate versions of positions you oppose does something valuable: it makes you realize that intelligent people can disagree with you without being monsters or morons. This sounds obvious when written out, but your social media feed has spent years training you to believe otherwise.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Second, practice distinguishing between stakes and truth. Just because an issue matters doesn't mean every claim about it is correct, and just because you've picked a side doesn't mean you have to defend every argument your side makes. The tribal logic says you have to accept the whole package, but that logic is selling you certainty you haven't earned.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Third, find (or at least, look for) communities that reward humility, not tribal loyalty. These are rare, but they exist. They're the group chats where someone can say "I changed my mind about this" without being treated like a traitor. They're the forums where "I don't know" is an acceptable answer. They're the relationships where you can test ideas without performing for an audience. You cannot be reasonable in isolation. You need a small group of people who value truth-seeking over status games, and you need to invest in those relationships deliberately.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That all sounds hard.&lt;/p&gt;
    &lt;p&gt;Is it worth it?&lt;/p&gt;
    &lt;p&gt;That’s an individual choice.&lt;/p&gt;
    &lt;p&gt;You'll lose: reach, influence, certainty, the comfort of being part of something larger than yourself.&lt;/p&gt;
    &lt;p&gt;You'll gain: the ability to think clearly, the capacity to update your beliefs when evidence changes, relationships based on something other than shared enemies, and the possibility of being right in ways that matter.&lt;/p&gt;
    &lt;p&gt;These trades won't feel equivalent. The losses are immediate and visceral. The gains are distant and abstract. When you refuse to join the mob, you feel it right away. When you maintain your ability to think independently, the benefits accrue slowly over years.&lt;/p&gt;
    &lt;p&gt;The discount rate on sanity is brutal.&lt;/p&gt;
    &lt;p&gt;But consider the alternative.&lt;/p&gt;
    &lt;p&gt;The people I knew who went all-in on extremism got what they wanted in the short term. Some built audiences. Some found communities. Some gained certainty. Most of ‘em made bank. But they're trapped by their earlier positions. They can't update without admitting they were wrong, and admitting they were wrong would cost them their community. They've optimized themselves into a local maximum they can't escape. They won the game by its current rules and lost something harder to quantify.&lt;/p&gt;
    &lt;p&gt;The world will keep offering you bad trades, will keep rewarding positions you know are too simple to be true. Every day you'll watch people cash in their nuance for influence. Every day you'll be tempted to do the same. The only defense is to remember that some things compound differently than others.&lt;/p&gt;
    &lt;p&gt;Extremism gives you a fast start and a ceiling.&lt;/p&gt;
    &lt;p&gt;Sanity gives you a slow start and no limit to how far you can grow.&lt;/p&gt;
    &lt;p&gt;Remember: the world only rewards insanity because we're measuring the wrong timeframe.&lt;/p&gt;
    &lt;p&gt;Check back in ten years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45980106</guid><pubDate>Wed, 19 Nov 2025 14:40:38 +0000</pubDate></item></channel></rss>