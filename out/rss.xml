<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 27 Oct 2025 00:53:26 +0000</lastBuildDate><item><title>Pico-Banana-400k</title><link>https://github.com/apple/pico-banana-400k</link><description>&lt;doc fingerprint="19072a4816fa0fc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Pico-Banana-400K is a large-scale dataset of ~400K text‚Äìimage‚Äìedit triplets designed to advance research in text-guided image editing.&lt;lb/&gt; Each example contains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;an original image (from Open Images),&lt;/item&gt;
      &lt;item&gt;a human-like edit instruction, and&lt;/item&gt;
      &lt;item&gt;the edited result generated by Nano-Banana and verified by Gemini-2.5-Pro.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The dataset spans 35 edit operations across 8 semantic categories, covering diverse transformations‚Äîfrom low-level color adjustments to high-level object, scene, and stylistic edits.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total Samples&lt;/cell&gt;
        &lt;cell&gt;~257K single-turn text‚Äìimage‚Äìedit triplets for SFT, ~56K single-turn text-image(positive) - image(negative)-edit for preference learning, and ~72K multi-turn texts-images-edits for multi-turn applications&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
        &lt;cell&gt;Open Images&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edit Operations&lt;/cell&gt;
        &lt;cell&gt;35 across 8 semantic categories&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Categories&lt;/cell&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric, Object-Level, Scene Composition, Stylistic, Text &amp;amp; Symbol, Human-Centric, Scale &amp;amp; Perspective, Spatial/Layout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Image Resolution&lt;/cell&gt;
        &lt;cell&gt;512‚Äì1024 px&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Prompt Generator&lt;/cell&gt;
        &lt;cell&gt;Gemini-2.5-Flash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Editing Model&lt;/cell&gt;
        &lt;cell&gt;Nano-Banana&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-Evaluation&lt;/cell&gt;
        &lt;cell&gt;Automated judging pipeline using Gemini-2.5-Pro for edit quality&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K is built using a two-stage multimodal generation pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Instruction Generation&lt;lb/&gt;Each Open Images sample is passed to Gemini-2.5-Flash, which writes concise, natural-language editing instructions grounded in visible content. We also provide short instructions summarized by Qwen-2.5-Instruct-7B. Example:&lt;quote&gt;{ "instruction": "Change the red car to blue." }&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Editing + Self-Evaluation The Nano-Banana model performs the edit, then automatically evaluates the result using a structured quality prompt that measures: Instruction Compliance (40%) Editing Realism (25%) Preservation Balance (20%) Technical Quality (15%) Only edits scoring above a strict threshold (~0.7) are labeled as successful, forming the main dataset; the remaining ~56K are retained as failure cases for robustness and preference learning.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nano-Banana-400K contains ~400K image editing data, covering a wide visual and semantic range drawn from real-world imagery.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Percentage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Object-Level Semantic&lt;/cell&gt;
        &lt;cell&gt;Add, remove, replace, or relocate objects&lt;/cell&gt;
        &lt;cell&gt;35%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scene Composition &amp;amp; Multi-Subject&lt;/cell&gt;
        &lt;cell&gt;Contextual and environmental transformations&lt;/cell&gt;
        &lt;cell&gt;20%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;Edits involving clothing, expression, or appearance&lt;/cell&gt;
        &lt;cell&gt;18%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;Domain and artistic style transfer&lt;/cell&gt;
        &lt;cell&gt;10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;Edits involving visible text, signs, or symbols&lt;/cell&gt;
        &lt;cell&gt;8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric&lt;/cell&gt;
        &lt;cell&gt;Brightness, contrast, and tonal adjustments&lt;/cell&gt;
        &lt;cell&gt;5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scale &amp;amp; Perspective&lt;/cell&gt;
        &lt;cell&gt;Zoom, viewpoint, or framing changes&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Spatial / Layout&lt;/cell&gt;
        &lt;cell&gt;Outpainting, composition, or canvas extension&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single-Turn SFT samples (successful edits): ~257K&lt;/item&gt;
      &lt;item&gt;Single-Turn Preference samples (failure cases): ~56K&lt;/item&gt;
      &lt;item&gt;Multi-Turn SFT samples (successful cases): ~72K&lt;/item&gt;
      &lt;item&gt;Gemini-generated instructions: concise, natural, and image-aware&lt;/item&gt;
      &lt;item&gt;Edit coverage: 35 edit types across 8 semantic categories&lt;/item&gt;
      &lt;item&gt;Image diversity: includes humans, objects, text-rich scenes, etc from Open Images&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Below are representative examples from different categories:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Object-Level&lt;/cell&gt;
        &lt;cell&gt;‚ÄúReplace the red apple with a green one.‚Äù&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Scene Composition&lt;/cell&gt;
        &lt;cell&gt;‚ÄúAdd sunlight streaming through the window.‚Äù&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;‚ÄúChange the person‚Äôs expression to smiling.‚Äù&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;‚ÄúUppercase the text on the billboard.‚Äù&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;‚ÄúConvert the image to a Van Gogh painting style.‚Äù&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K provides both breadth (diverse edit operations) and depth (quality-controlled multimodal supervision), making it a strong foundation for training and evaluating text-guided image editing models.&lt;/p&gt;
    &lt;p&gt;Pico-Banana-400K serves as a versatile resource for advancing controllable and instruction-aware image editing.&lt;lb/&gt; Beyond single-step editing, the dataset enables multi-turn, conversational editing and reward-based training paradigms.&lt;/p&gt;
    &lt;p&gt;The Pico-Banana-400K dataset is hosted on Apple‚Äôs public CDN.&lt;lb/&gt; You can download each component (single-turn, multi-turn, and preference data) using the provided manifest files.&lt;/p&gt;
    &lt;p&gt;Manifest files: sft link and preference link&lt;/p&gt;
    &lt;p&gt;Manifest file: multi-turn link&lt;/p&gt;
    &lt;p&gt;Urls to download source images are provided along with edit instructions in sft link, preference link, and multi-turn link. If you hit rate limit with Flickr when downloading images, you can either request higher rate limit with Flickr or follow steps below.&lt;/p&gt;
    &lt;p&gt;Another way to download the source images is to download packed files train_0.tar.gz and train_1.tar.gz from Open Images, then map with the urls we provide. We also provide a sample mapping code here. Due to legal requirements, we cannot provide the source image files directly.&lt;/p&gt;
    &lt;code&gt;# Install awscli if you don't have it (https://aws.amazon.com/cli/)
# Download Open Images packed files 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_0.tar.gz . 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_1.tar.gz . 

# Create folder for extracted images 
mkdir openimage_source_images

# Extract the tar files 
tar -xvzf train_0.tar.gz -C openimage_source_images
tar -xvzf train_1.tar.gz -C openimage_source_images

# Download metadata CSV (ImageID ‚Üî OriginalURL mapping)  
wget https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv

# Map urls to local paths
python map_openimage_url_to_local.py #please modify variable is_multi_turn and file paths as needed&lt;/code&gt;
    &lt;p&gt;Pico-Banana-400K is released under the Creative Commons Attribution‚ÄìNonCommercial‚ÄìNoDerivatives (CC BY-NC-ND 4.0) license. ‚úÖ Free for research and non-commercial use ‚ùå Commercial use and derivative redistribution are not permitted üñºÔ∏è Source images follow the Open Images (CC BY 2.0) license By using this dataset, you agree to comply with the terms of both licenses.&lt;/p&gt;
    &lt;p&gt;If you use üçå Pico-Banana-400K in your research, please cite it as follows:&lt;/p&gt;
    &lt;code&gt;@misc{qian2025picobanana400klargescaledatasettextguided,
      title={Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing}, 
      author={Yusu Qian and Eli Bocek-Rivele and Liangchen Song and Jialing Tong and Yinfei Yang and Jiasen Lu and Wenze Hu and Zhe Gan},
      year={2025},
      eprint={2510.19808},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.19808}, 
}

&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45708524</guid><pubDate>Sun, 26 Oct 2025 02:01:17 +0000</pubDate></item><item><title>Writing a RISC-V Emulator in Rust</title><link>https://book.rvemu.app/</link><description>&lt;doc fingerprint="b3e453454f1ba464"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Writing a RISC-V Emulator in Rust&lt;/head&gt;
    &lt;p&gt;NOTE: This project is actively ongoing. Pages are not perfect yet and it possible to change dramatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;This is the book for writing a 64-bit RISC-V emulator from scratch in Rust. You can run xv6, a simple Unix-like OS, in your emulator once you finish the book.&lt;/p&gt;
    &lt;p&gt;You'll learn the basic computer architecture such as ISA, previleged architecture, exceptions, interrupts, peripheral devices, and virtual memory system from making an emulator.&lt;/p&gt;
    &lt;p&gt;The source code used in this book is available at d0iasm/rvemu-for-book.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1&lt;/head&gt;
    &lt;p&gt;Chapter 1 shows all hardward components we need to implement for running &lt;code&gt;xv6&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;CPU with Two Instructions&lt;/item&gt;
      &lt;item&gt;Memory and System Bus&lt;/item&gt;
      &lt;item&gt;Control and Status Registers&lt;/item&gt;
      &lt;item&gt;Privileged Architecture&lt;/item&gt;
      &lt;item&gt;Exceptions&lt;/item&gt;
      &lt;item&gt;PLIC (a platform-level interrupt controller) and CLINT (a core-local interrupter)&lt;/item&gt;
      &lt;item&gt;UART (a universal asynchronous receiver-transmitter)&lt;/item&gt;
      &lt;item&gt;Interrupts&lt;/item&gt;
      &lt;item&gt;Virtio&lt;/item&gt;
      &lt;item&gt;Virtual Memory System&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Chapter 2&lt;/head&gt;
    &lt;p&gt;Chapter 2 shows all ISAs we need to implement for running &lt;code&gt;xv6&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RV64I Base Integer Instruction Set&lt;/item&gt;
      &lt;item&gt;"M" Standard Extension for Integer Multiplication and Division&lt;/item&gt;
      &lt;item&gt;"A" Standard Extension for AtomicInstructions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Outcome&lt;/head&gt;
    &lt;p&gt;Once you read this book and implement the emulator, you will be able to run xv6 in your emulator!&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;The author is @d0iasm and please feel free to ask and request anything to me via Twitter or GitHub issues!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45709819</guid><pubDate>Sun, 26 Oct 2025 07:34:30 +0000</pubDate></item><item><title>Clojure Land ‚Äì Discover open-source Clojure libraries and frameworks</title><link>https://clojure.land/</link><description>&lt;doc fingerprint="2302039003d1cf0"&gt;
  &lt;main&gt;
    &lt;list id="project-list" class="grid grid-cols-6 gap-2 divide-y divide-gray-100" rend="ul"&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Behavioral Programming for Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) - AI pair programming capabilities agnostic of editor&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) integration for Emacs&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Java2D wrapper + creative coding supporting functions (based on Processing and openFrameworks)&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Making VS Code Hackable like Emacs since 2022&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A data-driven rendering library for Clojure(Script) that renders hiccup to DOM or to strings.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Clojure library for building OpenAPI services&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;An optional type system for Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A better "prn" for debugging&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Managed lifecycle of stateful objects in Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;VS Code AI Agent Interactive Programming. Tools for CoPIlot and other assistants. Can also be used as an MCP server.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A functional quantum computer programming library for Clojure with backend protocols, simulation backends and visualizations.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Expose Lacinia GraphQL as Pedestal endpoints&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Clojure reducers, but for parallel execution: locally and on distributed systems.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) integration for Vscode&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;An open source tool set for building web applications in Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;JSON parser/generator to/from Clojure data structures&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;User aliases and Clojure CLI configuration for deps.edn based projects&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2" hx-get="/" hx-target="#project-list" hx-select="#project-list li" hx-swap="beforeend" hx-include="inherit" hx-vals="{&amp;quot;page&amp;quot;:2}" hx-trigger="revealed"&gt;
        &lt;div&gt;
          &lt;div&gt;Weave loom fibers into your Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Multi-pass compiler and runtime for probabilistic programming.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45709988</guid><pubDate>Sun, 26 Oct 2025 08:15:48 +0000</pubDate></item><item><title>Advent of Code 2025: Number of puzzles reduce from 25 to 12 for the first time</title><link>https://adventofcode.com/2025/about#faq_num_days</link><description>&lt;doc fingerprint="9ad8fbdb2d32aff8"&gt;
  &lt;main&gt;&lt;p&gt;Hi! I'm Eric Wastl. I make Advent of Code. I hope you like it! I also make lots of other things. I'm on Bluesky, Mastodon, and GitHub.&lt;/p&gt;&lt;p&gt;Advent of Code is an Advent calendar of small programming puzzles for a variety of skill levels that can be solved in any programming language you like. People use them as interview prep, company training, university coursework, practice problems, a speed contest, or to challenge each other.&lt;/p&gt;&lt;p&gt;You don't need a computer science background to participate - just a little programming knowledge and some problem solving skills will get you pretty far. Nor do you need a fancy computer; every problem has a solution that completes in at most 15 seconds on ten-year-old hardware.&lt;/p&gt;&lt;p&gt;If you'd like to support Advent of Code, you can do so indirectly by helping to AoC++.&lt;/p&gt;it with others or directly via&lt;head rend="h2"&gt;--- General Tips ---&lt;/head&gt;&lt;p&gt;If you get stuck, try your solution against the examples given in the puzzle; you should get the same answers. If not, re-read the description. Did you misunderstand something? Is your program doing something you don't expect? After the examples work, if your answer still isn't correct, build some test cases for which you can verify the answer by hand and see if those work with your program. Make sure you have the entire puzzle input. If you're still stuck, maybe ask a friend for help, or come back to the puzzle later. You can also ask for hints in the subreddit.&lt;/p&gt;&lt;head rend="h2"&gt;--- Frequently Asked Questions ---&lt;/head&gt;&lt;p&gt;Is there an easy way to select entire code blocks? You should be able to triple-click code blocks to select them. You'll need JavaScript enabled.&lt;/p&gt;&lt;code&gt;#!/usr/bin/env perl
use warnings;
use strict;

print "You can test it out by ";
print "triple-clicking this code.\n";
&lt;/code&gt;&lt;p&gt;How does authentication work? Advent of Code uses OAuth to confirm your identity through other services. When you log in, you only ever give your credentials to that service - never to Advent of Code. Then, the service you use tells the Advent of Code servers that you're really you. In general, this reveals no information about you beyond what is already public; here are examples from Reddit and GitHub. Advent of Code will remember your unique ID, names, URL, and image from the service you use to authenticate.&lt;/p&gt;&lt;p&gt;Why was this puzzle so easy / hard? The difficulty and subject matter varies throughout each event. Very generally, the puzzles get more difficult over time, but your specific skillset will make each puzzle significantly easier or harder for you than someone else. Making puzzles is tricky.&lt;/p&gt;&lt;p&gt;Why do the puzzles unlock at midnight EST/UTC-5? Because that's when I can consistently be available to make sure everything is working. I also have a family, a day job, and even need sleep occasionally. If you can't participate at midnight, that's not a problem; if you want to race, many people use private leaderboards to compete with people in their area.&lt;/p&gt;&lt;p&gt;I find the text on the site hard to read. Is there a high contrast mode? There is a high contrast alternate stylesheet. Firefox supports these by default (View -&amp;gt; Page Style -&amp;gt; High Contrast).&lt;/p&gt;&lt;p&gt;I have a puzzle idea! Can I send it to you? Please don't. Because of legal issues like copyright and attribution, I don't accept puzzle ideas, and I won't even read your email if it looks like one just in case I use parts of it by accident.&lt;/p&gt;&lt;p&gt;Did I find a bug with a puzzle? Once a puzzle has been out for even an hour, many people have already solved it; after that point, bugs are very unlikely. Start by asking on the subreddit.&lt;/p&gt;&lt;p&gt;Should I try to get a fast solution time? Maybe. Solving puzzles is hard enough on its own, but trying for a fast time also requires many additional skills and a lot of practice; speed-solves often look nothing like code that would pass a code review. If that sounds interesting, go for it! However, you should do Advent of Code in a way that is useful to you, and so it is completely fine to choose an approach that meets your goals and ignore speed entirely.&lt;/p&gt;&lt;p&gt;Why did the number of days per event change? It takes a ton of my free time every year to run Advent of Code, and building the puzzles accounts for the majority of that time. After keeping a consistent schedule for ten years(!), I needed a change. The puzzles still start on December 1st so that the day numbers make sense (Day 1 = Dec 1), and puzzles come out every day (ending mid-December).&lt;/p&gt;&lt;p&gt;What happened to the global leaderboard? The global leaderboard was one of the largest sources of stress for me, for the infrastructure, and for many users. People took things too seriously, going way outside the spirit of the contest; some people even resorted to things like DDoS attacks. Many people incorrectly concluded that they were somehow worse programmers because their own times didn't compare. What started as a fun feature in 2015 became an ever-growing problem, and so, after ten years of Advent of Code, I removed the global leaderboard. (However, I've made it so you can share a read-only view of your private leaderboard. Please don't use this feature or data to create a "new" global leaderboard.)&lt;/p&gt;&lt;p&gt;While trying to get a fast time on a private leaderboard, may I use AI / watch streamers / check the solution threads / ask a friend for help / etc? If you are a member of any private leaderboards, you should ask the people that run them what their expectations are of their members. If you don't agree with those expectations, you should find a new private leaderboard or start your own! Private leaderboards might have rules like maximum runtime, allowed programming language, what time you can first open the puzzle, what tools you can use, or whether you have to wear a silly hat while working.&lt;/p&gt;&lt;p&gt;Should I use AI to solve Advent of Code puzzles? No. If you send a friend to the gym on your behalf, would you expect to get stronger? Advent of Code puzzles are designed to be interesting for humans to solve - no consideration is made for whether AI can or cannot solve a puzzle. If you want practice prompting an AI, there are almost certainly better exercises elsewhere designed with that in mind.&lt;/p&gt;&lt;p&gt;Can I copy/redistribute part of Advent of Code? Please don't. Advent of Code is free to use, not free to copy. If you're posting a code repository somewhere, please don't include parts of Advent of Code like the puzzle text or your inputs. If you're making a website, please don't make it look like Advent of Code or name it something similar.&lt;/p&gt;&lt;head rend="h2"&gt;--- Credits ---&lt;/head&gt;&lt;p&gt;Puzzles, Code, &amp;amp; Design: Eric Wastl&lt;/p&gt;&lt;p&gt;Beta Testing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Tim Giannetti&lt;/item&gt;&lt;item&gt;Ben Lucek&lt;/item&gt;&lt;item&gt;JP Burke&lt;/item&gt;&lt;item&gt;Aneurysm9&lt;/item&gt;&lt;item&gt;Andrew Skalski&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Community Managers: Danielle Lucek and Aneurysm9&lt;/p&gt;&lt;p&gt;Playing: You!&lt;/p&gt;&lt;head rend="h2"&gt;--- Legal ---&lt;/head&gt;&lt;p&gt;Advent of Code is a registered trademark in the United States. The design elements, language, styles, and concept of Advent of Code are all the sole property of Advent of Code and may not be replicated or used by any other person or entity without express written consent of Advent of Code. Copyright 2015-2025 Advent of Code. All rights reserved.&lt;/p&gt;&lt;p&gt;You may link to or reference puzzles from Advent of Code in discussions, classes, source code, printed material, etc., even in commercial contexts. Advent of Code does not claim ownership or copyright over your solution implementation.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710006</guid><pubDate>Sun, 26 Oct 2025 08:19:48 +0000</pubDate></item><item><title>Asbestosis</title><link>https://diamondgeezer.blogspot.com/2025/10/asbestosis.html</link><description>&lt;doc fingerprint="fe60955783648a74"&gt;
  &lt;main&gt;
    &lt;p&gt;This monument popped up in the middle of Barking recently. I thought it was very recently but it was actually unveiled in April 2022 and I'm just not very observant.&lt;/p&gt;
    &lt;p&gt;It says "In Memory of those who lost their lives because of exposure to asbestos".&lt;/p&gt;
    &lt;p&gt;And it's here because Barking has one of the highest rates of asbestos-related deaths in the country.&lt;/p&gt;
    &lt;p&gt;In 1913 the Cape Asbestos Company built a huge asbestos factory beside the River Roding in Barking. The company mined asbestos-bearing rock at several sites in South Africa, then shipped them in sacks to a private quay in Barking for processing. Hundreds of people were employed to mill the ore into usable fibres and then process these into lagging, packaging, pipes, resins, boards and all forms of insulation widely used in the building trade. They worked without masks or other protection, the dangers of asbestos either unknown or not thought worth bothering about. And hundreds of workers died, often many years later, of insidious chronic respiratory disease.&lt;/p&gt;
    &lt;p&gt;I found a 32-page booklet published by Cape Asbestos in the days before blue asbestos was recognised as dangerous and banned, which was as late as 1985. It shows workers with rolled-up sleeves and women leaning over unshielded machines, all potentially inhaling enough fibres to ultimately kill them. I read reports about the local school in Barking, barely 100 metres away, saying that the playground was often covered in fine dust which children rolled up and played with as if it were snow. I read that mesothelioma was so common in the area it was known as the ‚ÄòBarking Cough‚Äô. These were different times, but times that linger on.&lt;/p&gt;
    &lt;p&gt;Cape Asbestos's plant eventually closed in 1968 and in its place was built the Harts Lane council estate, which is still not the loveliest corner of Barking. It included two tall tower blocks called Colne House and Mersey House, both of which Barking &amp;amp; Dagenham council would now like to demolish. This is chiefly because they're old and covered in combustible cladding, but the additional complications of potentially disturbing polluted land puts any remediation out of financial reach. It's always the insulation you have to watch out for.&lt;/p&gt;
    &lt;p&gt;The memorial in Barking Town Square comprises a polished chunk of blue pearl granite and was unveiled on Workers' Memorial Day 2022 in a ceremony attended by several trade unionists and representatives of the London Asbestos Support Awareness Group. The emphasis is partly on remembrance and partly on the importance of standing up for workers' rights to make conditions better for all. As the inscription says, "Remember the Dead and Fight for the Living".&lt;/p&gt;
    &lt;p&gt;My grandfather worked for another Cape Asbestos plant on Tolpits Lane in Watford. Originally it had been run by Universal Asbestos Manufacturing but in 1967 the factory was acquired by Cape as part of a diversification into cement-based products. They made corrugated roofing, flat sheets, decorated sheets, slates, soil pipes, decking for flat roofs and reinforced troughing - that kind of thing - the asbestos moulded into a multiplicity of shapes for the benefit of the building trade.&lt;/p&gt;
    &lt;p&gt;To him Cape Universal was just a convenient place to work, a short walk across the moor for a day's shift and then home again for tea. He worked there for many years, from the 1930s to the 1960s, rising through the ranks from a labourer to a machine operator on the factory floor. On his death certificate his occupation was listed as 'Asbestos Moulder', and it was very much a premature death because this didn't end well.&lt;/p&gt;
    &lt;p&gt;I don't remember very much about my grandfather because he died when I was 8. I know he was there when I took my first steps in his back garden and I can remember sitting at his dining room table and hoping nobody would force me to eat the celery. My final memory is being led up to his bedroom, I suspect not long before his death, to see an ill old man laid out in bed and struggling to breathe. I don't know what was said, nor how short a time I stayed in his presence, indeed my strongest recollection is of the room itself with its austere cupboards and the curtains drawn. And then at the age of 67 he was gone.&lt;/p&gt;
    &lt;p&gt;My family fought for asbestosis to be recognised as his cause of death but were not successful. I've read recently of fellow workers working at the Tolpits Lane factory now getting six figure payouts in compensation, indeed it's hard to research this topic without ending up on legal websites with popups urging you to make a claim. Even four decades after the factory's closure there are still employees severely affected, and many more already passed, as the toxic legacy endures. The factory site is now a rather cleaner industrial estate and business park, indeed it's where the National Lottery's been based for the last 30 years because risk and loss are still in play.&lt;/p&gt;
    &lt;p&gt;Today my Dad reaches the grand old age of 87, a full 20 years more than his father lived. Science has moved on a long way since the 1970s, also educational opportunities and also workers' rights. Health and safety is sometimes much derided but it can genuinely save lives, even much extend them, rather than everyone continually moaning about additional costs and annoying procedures. If someone had shouted earlier and louder about the dangers of asbestos I might have known my grandfather better, my grandmother could have had many more years of married life and my father could have had a father for much longer.&lt;/p&gt;
    &lt;p&gt;My Dad lost his Dad at the age of 34, which is no age at all in the grand scheme of things. By contrast I still have my Dad at the age of 60, which has meant an extra quarter century of guidance, support, advice, love and always being there. How lucky am I? Every day we overlap with our parents is a blessing and I've had 22,000 of them, for all of which I'm truly grateful. We're off out later to celebrate with a slap-up dinner, or as slap-up as an 87-year-old stomach requires, which the wider family are greatly looking forward to. What Barking's memorial reminded me is that many families have not been so fortunate, and sometimes that loss can be very close to home.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710065</guid><pubDate>Sun, 26 Oct 2025 08:34:38 +0000</pubDate></item><item><title>You already have a Git server</title><link>https://maurycyz.com/misc/easy_git/</link><description>&lt;doc fingerprint="dcf8f5f9c827be83"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You already have a git server:&lt;/head&gt;(Programming)&lt;p&gt;If you have a git repository on a server with ssh access, you can just clone it:&lt;/p&gt;&lt;code&gt;# This works. 
git clone ssh://username@hostname/path/to/repo
&lt;/code&gt;&lt;p&gt;You can then work on it locally and push your changes back to the origin server. By default, git won‚Äôt let you push to the branch that is currently checked out, but this is easy to change:&lt;/p&gt;&lt;code&gt;# Run this on the remote server. 
git config receive.denyCurrentBranch updateInstead
&lt;/code&gt;&lt;p&gt;This is a great way to sync code between multiple computers or to work on server-side files without laggy typing or manual copying. If you want to publish your code, just point your web server at the git repo:&lt;/p&gt;&lt;code&gt;git clone https://hostname/path/to/repo/.git
# You can get rid of the .git part of the command by either setting the
# server to remap it to a nicer URL or by just renaming the .git directory
# (although this stops you from running git server side)
&lt;/code&gt;&lt;p&gt;‚Ä¶ although you will have to run this command server-side to make it cloneable:&lt;/p&gt;&lt;code&gt;# Create some files used by git-over-http:
# Should be repeated after making changes.
git update-server-info
&lt;/code&gt;&lt;p&gt;That‚Äôs a lot of work, so let‚Äôs set up a hook to do that automatically:&lt;/p&gt;&lt;code&gt;# Automatically run git update-server-info.
# Should be run server-side
cp .git/hooks/post-update.sample .git/hooks/post-update
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;Git hooks are just shell scripts, so they can do things like running a static site generator:&lt;/p&gt;&lt;code&gt;cat &amp;gt; .git/hooks/post-update &amp;lt;&amp;lt;EOF
#!/bin/sh
set -euo pipefail
cd /path/to/site
/path/to/generator
EOF
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;This is how I‚Äôve been doing this blog for a while now: It‚Äôs very nice to be able to type up posts locally (no network lag), and then push them to the server and have the rest handled automatically.&lt;/p&gt;&lt;p&gt;It‚Äôs also backed up by default: If the server breaks, I‚Äôve still got the copy on my laptop, and if my laptop breaks, I can download everything from the server. Git‚Äôs version tracking also prevents accidental deletions, and if something breaks, it‚Äôs easy to figure out what caused it.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710721</guid><pubDate>Sun, 26 Oct 2025 10:53:37 +0000</pubDate></item><item><title>Formal Reasoning [pdf]</title><link>https://cs.ru.nl/~freek/courses/fr-2025/public/fr.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45711062</guid><pubDate>Sun, 26 Oct 2025 12:03:59 +0000</pubDate></item><item><title>Feed the bots</title><link>https://maurycyz.com/misc/the_cost_of_trash/</link><description>&lt;doc fingerprint="273b981161f213a7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You should feed the bots:&lt;/head&gt;(Programming)&lt;p&gt;A week ago, I set up an infinite nonsense crawler trap ‚Äì now it makes up 99% of my server‚Äôs traffic. What surprised me is that feeding scrapers garbage is the cheapest and easiest thing I could do.&lt;/p&gt;&lt;head rend="h2"&gt;Meet the bots:&lt;/head&gt;&lt;p&gt;These aren‚Äôt the indexing bots of old, but scrapers collecting data to train LLMs. Unlike search engines, which need the websites they crawl to stay up, AI companies provide a replacement.&lt;/p&gt;&lt;p&gt;It should come as no surprise that these bots are aggressive and relentless: They ignore robots.txt, and if block them by user agent they just pretend to be a browser. If you ban their IP, they switch addresses.&lt;/p&gt;&lt;p&gt;‚Ä¶ all while sending multiple requests per second, all day, every day.&lt;/p&gt;&lt;head rend="h2"&gt;Giving up:&lt;/head&gt;&lt;p&gt;So what if we let them access the site?&lt;/p&gt;&lt;p&gt;Serving static files is is relatively cheap, but not free. SSD access times are in the tens milliseconds, and that‚Äôs before you pay the filesystem tax. Bots also like to grab old and obscure pages, ones that are unlikely to be in cache. As a result, it doesn‚Äôt take all that many requests to bog down the server.&lt;/p&gt;&lt;p&gt;Then there‚Äôs the matter of bandwidth: Many blog posts also include images weighing hundreds to thousands of kB, which can add up quite quickly. With an average file size of 100 kB, 4 requests per second adds up to a terabyte each month ‚Äì not a huge amount of data, but more then I‚Äôm willing to throw away.&lt;/p&gt;&lt;head rend="h2"&gt;The ban hammer:&lt;/head&gt;&lt;p&gt;Simply making a list of IPs and blocking them would for normal bots‚Ä¶&lt;/p&gt;&lt;p&gt;‚Ä¶ but these are hardly normal bots. Because they are backed by billion dollar companies, they don‚Äôt just have a few addresses, but many thousands. If you managed to ban all of their addresses, they‚Äôll just buy more.&lt;/p&gt;&lt;p&gt;Rate limits fail for the same reason: They just switch IPs. I‚Äôve even seen them using new IP for each request.&lt;/p&gt;&lt;head rend="h2"&gt;Building a wall:&lt;/head&gt;&lt;p&gt;Ok, what about a pay-wall, login-wall, CAPTCHA-wall, or a hash based proof-of-work?&lt;/p&gt;&lt;p&gt;All of these inconvenience users. Requiring an account guaranties that no one will read what I wrote. Even just a simple JavaScript challenge will block anyone who‚Äôs browser doesn‚Äôt support JS ‚Ä¶ and when it works, anything that must load before the does content still hugely slows down page loads.&lt;/p&gt;&lt;head rend="h2"&gt;Throw them some bombs:&lt;/head&gt;&lt;p&gt;‚ÄúServe them few gzip bombs, that‚Äôll teach them‚Äù ‚Äî Half the internet.&lt;/p&gt;&lt;p&gt;Gzip only provides a compression ratio of a little over 1000: If I want a file that expands to 100 GB, I‚Äôve got to serve a 100 MB asset. Worse, when I tried it, the bots just shrugged it off, with some even coming back for more.&lt;/p&gt;&lt;head rend="h2"&gt;Jedi mind tricks:&lt;/head&gt;&lt;p&gt;Ok, what if we just send them 404s ‚Äì try and make them think my site doesn‚Äôt exist.&lt;/p&gt;&lt;p&gt;These tricks only work if your adversary has a mind to trick. If a link is posted somewhere, the bots will know it exists, and if they can‚Äôt access it, they‚Äôll just become more aggressive:. sending more requests, with more user agents and using more addresses.&lt;/p&gt;&lt;p&gt;Keeping them happy keeps them tolerable.&lt;/p&gt;&lt;head rend="h2"&gt;Garbage:&lt;/head&gt;&lt;p&gt;But surely sending them dynamically generated content would be expensive right?&lt;/p&gt;&lt;p&gt;Well‚Ä¶ no.&lt;/p&gt;&lt;p&gt;CPU and RAM are the fastest parts of a modern computer. Dynamic content has the reputation of being slow because it often involves a database (lots of disk IO), a million lines of JavaScript, or both.&lt;/p&gt;&lt;p&gt;My lightly optimized Markov babbler consumes around ~60 CPU microseconds per request. There‚Äôs no disk IO, and the memory cost is only around 1.2 MB. There‚Äôs also no rules or blacklists to maintain: the bots come to it and it consumes them.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45711094</guid><pubDate>Sun, 26 Oct 2025 12:09:02 +0000</pubDate></item><item><title>Resource use matters, but material footprints are a poor way to measure it</title><link>https://ourworldindata.org/material-footprint-limitations</link><description>&lt;doc fingerprint="734a01f119070ff6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Resource use matters, but material footprints are a poor way to measure it&lt;/head&gt;
    &lt;head rend="h2"&gt;Adding up the weight of very different materials doesn‚Äôt tell us about their scarcity, environmental, or socioeconomic impacts.&lt;/head&gt;
    &lt;p&gt;What do a tonne of potatoes, gravel, coal, and copper have in common? Not much, except that they all weigh the same, and are treated exactly the same in a metric called the ‚Äúmaterial footprint‚Äù.&lt;/p&gt;
    &lt;p&gt;The material footprint sums up the weight of all the resources used within an economy. So if a country‚Äôs material footprint is 60 million tonnes, it extracts 60 million tonnes of ‚Äústuff‚Äù per year. This includes both non-renewable resources like metals and fossil fuels, and ‚Äúrenewable‚Äù ones like crops and wood. The scarcity or environmental impact of different resources is not considered, so every kilogram of stuff is considered just as important as every kilogram of something else.1&lt;/p&gt;
    &lt;p&gt;Some readers may not be familiar with this metric, but it has gained increasing popularity in environmental discussions and international policy. It‚Äôs included as a key metric in the United Nations‚Äô Sustainable Development Goals, which is why we have charts on it in our SDG Tracker. This metric is tracked in per capita terms and is shown in the chart below.&lt;/p&gt;
    &lt;p&gt;It is also used in the planetary pressures index by the UN Development Programme, and you‚Äôll find many reports on it by the OECD, European agencies, and others.2&lt;/p&gt;
    &lt;p&gt;However, for reasons I‚Äôll explain in this article, I don‚Äôt find this metric helpful in understanding the sustainability of resource use or its environmental impacts. I fear that rather than helping us tackle some of our biggest environmental and resource challenges, it obscures our understanding and takes our focus away from the most pressing problems.&lt;/p&gt;
    &lt;head rend="h1"&gt;It‚Äôs not that resource use doesn‚Äôt matter ‚Äî it‚Äôs that the material footprint fails to capture why&lt;/head&gt;
    &lt;p&gt;There are at least three reasons why we should be measuring and monitoring our resource use:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;To see if we risk running out of a particular resource. If we‚Äôve depleted the world‚Äôs copper, cobalt, or lithium and are at risk of running out, then we need to know about it. But to assess this, we need to know how much of that specific material we‚Äôre using, and how much is left. We‚Äôd need to know how much copper, cobalt, or lithium we use each year and the state of our global reserves. To do that, we need to look at specific mineral datasets (which exist and are published by organizations such as the US Geological Survey or British Geological Survey). We have a lot of this data on Our World in Data. This is also true for ‚Äúnatural‚Äù ecosystems or populations we‚Äôre depleting. If we‚Äôre concerned about the depletion of Atlantic bluefin tuna, we must look at how much of that population or species we‚Äôre catching, how many are left, and how quickly populations regenerate. Our team also shows this data on fish catch and depletion for specific species. Looking at a metric that throws the weight of tuna together with wood, coal, and gravel does not help understand the scarcity of any of them.&lt;/item&gt;
      &lt;item&gt;To measure the environmental impact of extracting and consuming resources. Mining uses land, can disrupt landscapes, and cause pollution. Burning fossil fuels generates carbon emissions and air pollution. Beef production can drive deforestation and biodiversity loss. These impacts are extremely important to monitor (we cover most, if not all, of them here on Our World in Data). But material footprints don‚Äôt tell us much about the environmental impact. The production of a tonne of gravel does not have the same impact as a tonne of uranium or pork.&lt;/item&gt;
      &lt;item&gt;To measure the socioeconomic consequences of extracting and consuming resources. Mining can be associated with unsafe working practices, and some supply chains rely on exploitative labor. But, again, the material footprint does nothing to help us identify and improve these conditions. Cobalt and gold mining are associated with poor working conditions in countries like the Democratic Republic of Congo, but material footprints don‚Äôt tell us that. In fact, many of these precious minerals are extracted in relatively small quantities, so they barely show on a whole-economy material footprint. Some of the most documented exploitative practices have been in textile supply chains. In terms of material footprint, clothing has a very low ‚Äúmaterial intensity‚Äù, so judging by this metric, it would be deemed a more ‚Äúresponsible‚Äù way to spend your money.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Resource use does matter for these reasons, but the material footprint, at best, captures them poorly and, at worst, hides some of the most negative impacts.&lt;/p&gt;
    &lt;head rend="h1"&gt;Most of our material footprint comes from non-metallic minerals and biomass&lt;/head&gt;
    &lt;p&gt;The chart below shows the breakdown of the European Union's material footprint. More than 70% is made up of biomass (our food and wood for industry and construction) and non-metallic minerals for construction and infrastructure.&lt;/p&gt;
    &lt;p&gt;This should already raise some questions.&lt;/p&gt;
    &lt;quote&gt;A tonne of gravel does not have the same impact as a tonne of uranium or pork.&lt;/quote&gt;
    &lt;p&gt;Biomass is a renewable resource (if managed sustainably). I can grow and harvest potatoes, tomatoes, and wheat today and then replant them for next year. The ‚Äúnet‚Äù change in the biomass we produce is often zero over longer timescales; it‚Äôs not being depleted like other resources. To compare this in terms of weight to fossil fuels and other minerals, which are not renewable, mixes materials that are too different to be bundled together.&lt;/p&gt;
    &lt;p&gt;Non-metallic minerals, such as gravel ‚Äî which dominate Europe‚Äôs footprint ‚Äî do not have zero environmental impact. Mining for materials such as sand can disrupt ecosystems, disturb riverbeds, and affect natural flood defenses. However, they tend to have a much lower environmental impact than the other categories. As the European Environment Agency puts it:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúNon-metallic minerals account for a large part of the total material footprint, yet they have less environmental and climate impact than metals and fossil fuels. This is because they are mostly composed of inert materials such as gravel, limestone.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we consider a large material footprint problematic, then it follows that we should focus on using less sand, gravel, wood, and limestone. However, this would achieve far less in addressing most of the resource constraints and environmental and social impacts that we care about than tackling other (smaller) categories like fossil fuels and particular metal ores.&lt;/p&gt;
    &lt;head rend="h1"&gt;Housing and food are the two sectors behind most of the EU‚Äôs material footprint&lt;/head&gt;
    &lt;p&gt;Since non-metallic minerals and biomass dominate the EU‚Äôs material footprint, we shouldn‚Äôt be surprised that housing and food have the biggest impact when we look at the footprint by the end-use sector.&lt;/p&gt;
    &lt;p&gt;The chart below shows this breakdown: more than half (52%) of the total footprint is linked to housing, and 19% to food. These two sectors alone account for almost three-quarters of the material footprint. Again, most of this is from non-metallic minerals like gravel and sand, and biomass for food (mostly crops).&lt;/p&gt;
    &lt;p&gt;A lot of the things some might classify as ‚Äúnon-essential‚Äù goods, such as cars, stuff we buy for our homes, and clothing, are small by comparison.3&lt;/p&gt;
    &lt;p&gt;It‚Äôs interesting to read the European Environment Agency‚Äôs analysis of what this breakdown means for policy and action.&lt;/p&gt;
    &lt;p&gt;On housing, the agency states:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúThe very high material footprint of housing means that no significant reduction in the EU‚Äôs material footprint can be achieved without addressing our built environment. On the other hand, the environmental benefit from avoiding extraction of non-metallic minerals is relatively small.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So, to substantially reduce our material footprint, we need to rethink our homes ‚Äî maybe the materials we use to build or their size ‚Äî but the environmental benefits of doing so are pretty small. Again, that raises the question of why we would make this the focal point of action if there are few benefits.&lt;/p&gt;
    &lt;p&gt;On food, the policy implications are also unclear:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúThe potential for a radical reduction of the food sector‚Äôs material footprint is rather low as it is composed of food items essential to our societies. However, dietary shifts and the management of food waste can contribute to reducing the food sector‚Äôs material footprint‚Äù.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We need food to eat, so substantially cutting back is hard. The two obvious proposals are reducing food waste and shifting to more plant-based diets (less material-intensive, because you don‚Äôt have to produce food for the animals first). These are both strong recommendations that I have written a lot about before.&lt;/p&gt;
    &lt;p&gt;But what‚Äôs crucial is that there is already a long list of reasons why we would want to make these changes: the fact that food is responsible for up to one-third of the world‚Äôs greenhouse gas emissions; that it uses half of the world‚Äôs habitable land; that it‚Äôs the leading driver of water use, water pollution, biodiversity loss, and deforestation; and the fact that we raise and slaughter more than 70 billion land animals for food every year. All these problems can be improved by shifting to more plant-based diets and reducing food waste.&lt;/p&gt;
    &lt;p&gt;Of all the arguments to make this shift, the ‚Äúmaterial footprint‚Äù is the least convincing. When it comes to sustainability, it‚Äôs much less obvious why I should care more about the weight of the amount of wheat, corn, or lentils we grow than I do about the ecosystems destroyed, forests cut down, animals raised under cruel conditions, or the rivers polluted.&lt;/p&gt;
    &lt;head rend="h1"&gt;‚ÄúLuxury‚Äù goods we associate with overconsumption tend to have a relatively low material footprint&lt;/head&gt;
    &lt;p&gt;A common explanation for measuring material footprints is that many of us overconsume and need to do so less. On a personal level, I am also very conscious of my consumption. I think carefully about what I buy and its impact. I still wear clothes that are many, many years old, and I hold on to my mobile phone for as long as I can.&lt;/p&gt;
    &lt;p&gt;When I speak to others about this, they often mention the same items and industries: consumer technology and ‚Äúfast fashion‚Äù are always in the spotlight.&lt;/p&gt;
    &lt;p&gt;But, surprisingly, thinking carefully about these purchases is not advice that follows from looking at material footprints. The chart below shows the breakdown of the EU‚Äôs material consumption, this time by final product. We see that these consumer products account for a very small fraction of the total footprint.4&lt;/p&gt;
    &lt;p&gt;Textiles and clothing (which includes footwear and non-clothing textiles) account for only 1% of the total. Computers and consumer electronics are just 0.8%. Surprisingly, rubber and plastic products are just 0.2%.&lt;/p&gt;
    &lt;p&gt;Dramatically reducing our use of items traditionally associated with excess consumption would barely change our material footprint. My sense is that most people are unaware of this.&lt;/p&gt;
    &lt;p&gt;The material footprint leads us to counterintuitive policy recommendations that many environmentalists would strongly object to. Here‚Äôs the European Environment Agency again:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúServices require the lowest material use per euro spent among all domains, followed by clothing and household goods. Therefore, consumption patterns directly affect the EU‚Äôs material footprint and one way to reduce it is to promote expenditure patterns that are less material intensive.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spending more money on services than physical ‚Äústuff‚Äù makes sense if we want to reduce our material footprints. However, since clothing and households also have a low material intensity, we could also reduce our footprint by spending much more on clothes, televisions, phones, and other consumer goods and less on essentials such as food and housing.&lt;/p&gt;
    &lt;p&gt;‚ÄúSpend more of your money on clothes and iPhones‚Äù to minimize your environmental footprint is not advice I‚Äôve heard before (and is not advice I‚Äôd give either). Yet this is what the European Environment Agency implies when it suggests ‚Äúpromoting expenditure patterns that are less material-intensive‚Äù. That advice comes directly from the results of material footprints.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sustainability means much more than just carbon footprints, so we should track lots of environmental impacts&lt;/head&gt;
    &lt;p&gt;One motivation for measuring material footprints was to extend the focus of sustainability beyond carbon footprints. I share this sentiment. I wrote a book about seven environmental problems, and climate change was just one of them.&lt;/p&gt;
    &lt;p&gt;However, there are better ways to understand these environmental concerns than summing up the weight of the different resources we use.&lt;/p&gt;
    &lt;p&gt;I have written many articles on measuring sustainability and environmental impacts that go beyond carbon emissions. At Our World in Data, we have deliberately made our environment section extensive (see our list of topics below). We‚Äôve covered land use, water use, eutrophication, deforestation, fertilizer overuse, biodiversity loss, food waste, and much more.&lt;/p&gt;
    &lt;p&gt;Resource use matters, and we need to monitor issues such as the risk of running out of some materials or the mining and socioeconomic impacts of others. There is a lot that we can do to make our economies more material-efficient and to shift from a model of continual extraction to a more circular one where we reuse materials.5 I‚Äôve written about this opportunity before as we shift from fossil fuels to low-carbon energy.&lt;/p&gt;
    &lt;quote&gt;Adding up the weight of very different materials doesn‚Äôt tell us about their scarcity, environmental, or socioeconomic impacts.&lt;/quote&gt;
    &lt;p&gt;Many metrics ‚Äî like the ones listed in the screenshot above ‚Äî do a better job at capturing the negative impacts. If we‚Äôre concerned about the scarcity of copper, we should be tracking how much we use and how much is available. If we‚Äôre worried about the environmental and social impacts of mining ‚Äî water use, pollution, exploitation in supply chains ‚Äî then we should be tracking these directly. However, the material footprint can downplay these issues because metal ores and fossil fuels make up a small fraction of the total in regions like the EU.&lt;/p&gt;
    &lt;p&gt;Despite the many limitations of the material footprint, almost all of the underlying individual indicators are useful. To calculate the final material footprint, researchers need to know the tonnes of copper, gold, cobalt, gravel, wood, and Atlantic tuna. On their own, these datasets are extremely valuable and could help us focus on specific resource challenges. It‚Äôs when they‚Äôre combined into a single number that this value is lost.&lt;/p&gt;
    &lt;p&gt;Comparing resource quantities within a common context can also be informative. For example, knowing how much mined materials we‚Äôll need for different energy sources can help us understand some of the implications of the energy transition. The same applies to the amount of crops (including feed) required for different dietary choices.&lt;/p&gt;
    &lt;p&gt;Knowing how much uranium the world uses each year is useful. Creating a metric that suggests it should be treated the same as bananas is not.&lt;/p&gt;
    &lt;head rend="h4"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;Thank you to Max Roser and Edouard Mathieu for their valuable comments and suggestions on this article and its visualizations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Living Planet Index: what does it really mean?&lt;/head&gt;
        &lt;p&gt;The Living Planet Index is the biodiversity metric that always claims the headlines. It‚Äôs often misinterpreted. How should we understand it?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Which countries have the critical minerals needed for the energy transition?&lt;/head&gt;
        &lt;p&gt;An overview of the distribution of critical minerals for clean energy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Do we only have 60 harvests left?&lt;/head&gt;
        &lt;p&gt;Claims that the world has only 100, 60, or even 30 years of harvests left often hit the headlines. These claims are overblown, but soil erosion is a problem and we can do something about it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Endnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Some models and calculations apply conversion factors, such as ore-to-metal ratios for minerals and metals. However, the point remains that things are considered equally, only based on mass.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;United Nations Statistics Division. Goal 12: Ensure sustainable consumption and production patterns.&lt;/p&gt;
        &lt;p&gt;UNDP Human Development Report. Planetary pressures‚Äìadjusted Human Development Index (PHDI). United Nations Development Programme.&lt;/p&gt;
        &lt;p&gt;OECD, Material Consumption.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Of course, some of these goods would be considered ‚Äúessential‚Äù: we need some clothes, basic resources in our homes, and transport (even if that‚Äôs in the form of public transport or cycling), but many argue that these are sectors where we ‚Äúoverconsume‚Äù and some purchases have become non-essential.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This data comes from Eurostat.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In fact, some footprinting metrics, such as ‚ÄúDomestic material consumption‚Äù would still count one tonne of recycled material within the material footprint, hence increasing recycling rates and circularity would not actually help to reduce the footprint. Others, such as the material footprint or ‚ÄúRaw material consumption‚Äù, do attempt to treat raw extraction and recycled materials separately. However, these flows can be difficult to separate, especially where data availability is challenging.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Cite this work&lt;/head&gt;
    &lt;p&gt;Our articles and data visualizations rely on work from many different people and organizations. When citing this article, please also cite the underlying data sources. This article can be cited as:&lt;/p&gt;
    &lt;code&gt;Hannah Ritchie (2025) - ‚ÄúResource use matters, but material footprints are a poor way to measure it‚Äù Published online at OurWorldinData.org. Retrieved from: 'https://ourworldindata.org/material-footprint-limitations' [Online Resource]&lt;/code&gt;
    &lt;p&gt;BibTeX citation&lt;/p&gt;
    &lt;code&gt;@article{owid-material-footprint-limitations,
    author = {Hannah Ritchie},
    title = {Resource use matters, but material footprints are a poor way to measure it},
    journal = {Our World in Data},
    year = {2025},
    note = {https://ourworldindata.org/material-footprint-limitations}
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Reuse this work freely&lt;/head&gt;
    &lt;p&gt;All visualizations, data, and code produced by Our World in Data are completely open access under the Creative Commons BY license. You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited.&lt;/p&gt;
    &lt;p&gt;The data produced by third parties and made available by Our World in Data is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our documentation, so you should always check the license of any such third-party data before use and redistribution.&lt;/p&gt;
    &lt;p&gt;All of our charts can be embedded in any site.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45712118</guid><pubDate>Sun, 26 Oct 2025 14:21:44 +0000</pubDate></item><item><title>Making the Electron Microscope</title><link>https://www.asimov.press/p/electron-microscope</link><description>&lt;doc fingerprint="328cd3a71931043b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making the Electron Microscope&lt;/head&gt;
    &lt;head rend="h3"&gt;In a little over a century, the electron microscope evolved from a tool barely capable of resolving virus particles into one able to capture atomic detail.&lt;/head&gt;
    &lt;p&gt;Biological structures exist across a vast range of scales. At one end are whole organisms, varying in size from bacteria only a few micrometers across to mammals measured in feet.1 These can be seen with the naked eye or with simple light microscopes, which have been in use since the mid-1600s. At the smaller end, however, are atoms, amino acids, and proteins, spanning angstroms2 to nanometers in size.&lt;/p&gt;
    &lt;p&gt;Observing molecules at this smaller scale allows us to untangle the finer mechanisms of life: how individual neurons connect and communicate, how the ribosomal machinery translates genetic code into proteins, or how viruses like HIV invade and hijack host cells. Resolving fine structures, whether the double membrane of a chloroplast, the protein shell of a bacteriophage, or the branching architecture of a synapse, provides the bridge between atomic detail and whole-organism physiology, taking us from form to function.&lt;/p&gt;
    &lt;p&gt;The ability to explore and map such minute mechanisms eluded scientists until the invention of the electron microscope. Conceived in the 1930s, it promised theoretical resolutions on the order of angstroms, nearly a hundred times finer than the most advanced light microscope of that era. In 1931, Ernst Ruska and his advisor Max Knoll, working at the Technical University in Berlin, designed the first prototype by replacing glass lenses with electromagnetic coils to focus beams of electrons instead of light.&lt;/p&gt;
    &lt;p&gt;That first instrument barely outperformed a magnifying glass in terms of resolution. But over the next century, refinements in design, sample preparation, and computation transformed the electron microscope into an indispensable tool for modern biology.&lt;/p&gt;
    &lt;p&gt;By 1938, scientists used an electron microscope to take a photograph of a virus ‚Äî the mouse ectromelia orthopoxvirus ‚Äî for the first time.3 And today, modern cryo-electron microscopy, in which samples are frozen in liquid ethane prior to imaging, can resolve individual atoms within proteins. During the COVID-19 pandemic, cryo-electron microscopy revealed the spike protein in the SARS-CoV-2 virus, which directly influenced the development of COVID vaccines. The technique also revealed a protein receptor that senses heat and pain, demonstrating how it translates physical signals to our nervous system, a breakthrough discovery that earned the 2021 Nobel Prize in Physiology.&lt;/p&gt;
    &lt;p&gt;Even as electron microscopes have allowed us to view ever smaller structures with clarity, challenges remain. One is that the images remain limited to static snapshots. Because samples must be imaged in a vacuum, it is impossible to directly observe the dynamism of live cells.4 In addition, specimens must be extremely thin to allow the electron beam to pass through, which prevents imaging of thick tissues. And finally, beyond these biological constraints, electron microscopes are physically large, can cost millions of dollars, and demand specialized facilities, training, and expertise to operate.&lt;/p&gt;
    &lt;p&gt;Despite these limitations, electron microscopy remains a powerful tool in biology, bridging the scales between molecular structure and living function. The story of its discovery is one of persistent ingenuity, involving a large cast of characters and numerous breakthroughs that helped make the modern electron microscope possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Seeds of an Idea&lt;/head&gt;
    &lt;p&gt;By the late 19th century, biologists knew they were approaching the resolution limit of the light microscope. In their quest to see biology in finer detail, they had reached a barrier that light could not cross.&lt;/p&gt;
    &lt;p&gt;Proof of this came from Ernst Abbe, a professor of experimental physics and mathematics at the University of Jena in Germany. Until Abbe, microscope design had been more of an art than a science, with innovators building optical instruments through trial and error. Carl Zeiss, who had begun manufacturing microscopes in the 1850s, approached Abbe in 1866 about using his scientific expertise for the construction of microscopes. Together, they began developing tools to improve the uniformity and quality of optical lenses.&lt;/p&gt;
    &lt;p&gt;In the early 1870s, while working on the microscope objectives (the lens closest to the specimen in a microscope), Abbe discovered that the sharpness of an image did not only depend on how perfectly a lens was ground but also on how much diffracted light from the specimen the lens could capture. He realized that fine details in a specimen bend light into wide angles, and only objectives with a sufficiently large opening could collect those rays to bring the image into focus.&lt;/p&gt;
    &lt;p&gt;From this insight, Abbe defined the concept of the ‚Äúnumerical aperture‚Äù (a measure of how much light a lens can gather5) and showed that the smallest visible detail is limited by the wavelength of light divided by twice this value.6 Even with ultraviolet light, at the short end of the visible spectrum (400 nanometers), the limit of resolution was 200 nanometers ‚Äî larger than most viruses, intracellular structures, and protein complexes.&lt;/p&gt;
    &lt;p&gt;Hope of resolving structures beneath this resolution boundary only arrived in 1895, when the German physicist Wilhelm R√∂ntgen discovered X-rays, a form of high-energy electromagnetic radiation with wavelengths shorter than those of ultraviolet light, and published a (now-iconic) image of his wife Bertha‚Äôs hand, with her bones and wedding ring clearly visible. This was the first time the hidden insides of the body could be seen without dissection. The bones, joints, and even metal fragments lodged inside the body could be made visible.&lt;/p&gt;
    &lt;p&gt;Between 1913 and 1915, the British physicist William Henry Bragg and his son, William Lawrence Bragg, developed a technique called X-ray crystallography. Working with simple crystals such as salt and diamond, they showed that when X-rays strike a regularly ordered crystal lattice, they diffract at specific angles that reveal the spacing of atoms within the crystal. The method works because X-rays have wavelengths about the size of chemical bonds, allowing the beams to reach and bounce off each atom in the lattice, reflecting the structure at an atomic scale. By applying a mathematical operation called a Fourier transform to these diffraction patterns captured on photographic plates, the Braggs reconstructed the three-dimensional arrangements of the atoms in the crystal.&lt;/p&gt;
    &lt;p&gt;Biomolecules, however, are not naturally crystalline. To study them, they had to be laboriously extracted, purified, and crystallized, separating them from their environment. The X-ray crystallography of biomolecules began in the 1930s, ushering in the field of structural biology. With sub-nanometer resolution, the invention of X-ray crystallography enabled a revolution in molecular biology. It was applied, for example, to solve the structures of DNA, hemoglobin, and insulin, molecules that have shaped the trajectory of modern biology.&lt;/p&gt;
    &lt;p&gt;But many biological targets remained out of reach. Viruses could rarely be crystallized, and cellular structures often lost their integrity when removed from their natural contexts. Thus, even with X-ray crystallography revealing the structures of small proteins and light microscopy capable of imaging cells, a gulf persisted between the study of small molecules and whole cells, which left much of biology invisible.&lt;/p&gt;
    &lt;p&gt;Meanwhile, access to the parallel world of electrons was beginning to open. At the turn of the 20th century, Hans Busch, a German physicist at the University of Jena, was studying how electron beams behaved in magnetic fields. His work built on decades of experiments with cathode rays, streams of electrons released when a high voltage is applied inside a glass tube.&lt;/p&gt;
    &lt;p&gt;Cathode rays had become central to both physics and technology: Physicists used them to probe how electrons scattered, ionized gases, and responded to electric and magnetic fields, and engineers used them to form the basis of devices such as the radio and television. It was while trying to better understand and control these beams that Busch postulated his remarkable theories.&lt;/p&gt;
    &lt;p&gt;In 1926 and 1927, Busch published two papers demonstrating mathematically that a magnetic coil could focus an electron beam in the same manner that a glass lens focuses light. While it was already known that coils could bend electron beams,7 Busch‚Äôs key insight was to frame this behavior in the language of optics: Electron beams could be treated like light rays. Concepts such as focal length, magnification, image formation, and even lens aberrations could all be applied to electrons. This meant that the well-developed theory of optical systems could be imported almost directly to other disciplines.&lt;/p&gt;
    &lt;p&gt;The Nobel Prize‚Äìwinning physicist and inventor of holography, Denis Gabor, later reflected on Busch‚Äôs contribution in a 1942 lecture: ‚ÄúBusch‚Äôs paper was more than an eye-opener; it was almost like a spark in an explosive mixture. In 1927, the situation in physics was such that nothing more than the words ‚Äòelectron lens‚Äô were needed to start a real burst of creative activity.‚Äù&lt;/p&gt;
    &lt;p&gt;And so it was that Busch‚Äôs idea sparked the birth of electron optics. Within a few years, at least three independent inventors would lay claim to having designed the electron microscope, all tracing their inspiration back to his initial insight.&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Electron Microscope&lt;/head&gt;
    &lt;p&gt;In 1928, the High Tension Laboratory at the Technical University in Berlin (a premier research facility focused on electrical engineering in the interwar years) was researching high-voltage power transmission and insulation. A persistent obstacle was the electrical surge often caused by thunderstorms, which repeatedly damaged the lab‚Äôs equipment. But before scientists could design a way to mitigate the problem, they first needed to understand it: Exactly when did these surges occur, and how fast or large were the voltage fluctuations?&lt;/p&gt;
    &lt;p&gt;To tackle this, the lab hoped to recruit a graduate student to create a proof-of-concept for a high-speed oscilloscope, a device that could directly visualize electrical pulses. A cathode ray oscilloscope worked by firing a beam of electrons across a phosphorescent screen inside a vacuum tube, where the impact produced a bright spot of light. Electric fields could be used to deflect the beam horizontally (to represent time) and vertically (to represent signal amplitude) so that electrical signals appeared as moving lines of light that could be observed directly.&lt;/p&gt;
    &lt;p&gt;Although cathode ray oscilloscopes were already in use, they served mainly to capture slower signals. The high voltage surges experienced in thunderstorms or short circuiting events, though, flashed by in one hundred millionths of a second, leaving almost no trace on the screen. To make such fleeting signals visible, the intensity of the electron beam had to be increased, which meant focusing the beam into as small and powerful a spot as possible. Only one student applied to take on the challenge: 21-year-old Ernst Ruska.&lt;/p&gt;
    &lt;p&gt;Ruska was born into a family of scientists in Heidelberg, Germany, in 1906. He had been exposed to optics from an early age, as his uncle was an astronomer at the local observatory and his father, a science historian, owned a large optical microscope that Ruska was strictly forbidden to touch. He recalls in his Nobel lecture: ‚ÄúWe would see on a table in the other room the pretty yellowish wooden box that housed my father‚Äôs big Zeiss microscope ‚Ä¶ He sometimes demonstrated to us interesting objects under the microscope, it is true; for good reasons, however, he feared that children‚Äôs hands would damage the objective or the specimen by clumsy manipulation of the coarse and line drive. Thus, our first relation to the value of microscopy was not solely positive.‚Äù&lt;/p&gt;
    &lt;p&gt;Unlike the rest of his family, Ruska‚Äôs passion leaned less toward science and more toward technical projects and problem-solving through engineering. While the other Ruska children spent their weekends with their father classifying rock samples or identifying bird calls, Ernst preferred tinkering with electrical switchboards and reading Max Eyth‚Äôs Behind Plow and Vice, a memoir on engineering and invention. And when he grew older, he recalls being fascinated by his high school physics teacher‚Äôs explanations of the movement of electrons through electrostatic fields and the limitations of light microscopes ‚Äî an interest he carried into adulthood.&lt;/p&gt;
    &lt;p&gt;At the High Tension Laboratory, under Max Knoll, Ruska began building the much-anticipated oscilloscope. In this device, the incoming electrical current would pass through the vertical deflection plates, causing the electron beam to shift in proportion to the amplitude of the surge. To sharpen the image, a magnetic focusing coil was placed upstream of the deflection plates, concentrating the beam into a small, bright spot before it reached the phosphorescent screen. Ruska‚Äôs task was to determine the optimal placement of these coils so that the dot appeared as sharp as possible.&lt;/p&gt;
    &lt;p&gt;For guidance, Ruska turned to Hans Busch‚Äôs recent papers on the lens-like action of magnetic fields on electron beams. In these papers, Busch had not only shown that a coil could act as a ‚Äúmagnetic electron lens,‚Äù but had also worked out the formulas describing electron trajectories in such a field and how the focal length changed with coil current. Using these calculations, Ruska confirmed Busch‚Äôs theories experimentally and determined the precise coil placement needed to bring the beam to a sharp focus. He then placed a small aperture in the beam‚Äôs path and, by varying the coil current, was able to project and record an image of the aperture at different magnifications on a screen.&lt;/p&gt;
    &lt;p&gt;As Ruska later recalled in his Nobel lecture, his 1929 Master‚Äôs thesis contained ‚Äúnumerous sharp images with different magnifications of an electron-irradiated anode aperture ‚Ä¶ the first recorded electron-optical images.‚Äù&lt;/p&gt;
    &lt;p&gt;By 1930, as Germany‚Äôs economy collapsed under the weight of post-war reparations and global depression, Ruska was unable to find work in industry and remained at the university for doctoral studies. Initially unsure of a research direction, he continued experimenting with magnetic lenses. He reasoned that if one coil could produce a magnified image, two in sequence might enlarge it further ‚Äî the conceptual birth of the electron microscope.&lt;/p&gt;
    &lt;p&gt;By April 1931, Ruska had constructed a two-stage imaging system with a total magnification of 14.4 times ‚Äî still far below the roughly 1000-fold magnification achieved by high-quality light microscopes of the time. The system began with a cathode inside a vacuum tube, which emitted electrons when a high voltage was applied. These electrons were accelerated toward an anode and passed through a small aperture, forming a narrow beam, much like light through a pinhole. Magnetic coils wrapped around the tube acted as electron lenses. The first coil, placed close to the object, served as the objective lens, bringing the transmitted electrons into focus and forming an intermediate image. A second coil downstream acted as a projector lens, refocusing and enlarging that intermediate image so it could be captured onto a fluorescent screen.&lt;/p&gt;
    &lt;p&gt;By carefully tuning the currents in both coils, Ruska could control the focal lengths and achieve much higher magnifications than with a single lens. The final image appeared as glowing light patterns on the screen, with bright areas where electrons passed through the specimen and dark regions where they were absorbed or scattered.&lt;/p&gt;
    &lt;p&gt;These images, photographed through a window in the tube, were the first electron micrographs, created by channeling electrons through successive magnetic lenses in a multistage system. Although its resolution was quite modest by today‚Äôs standards, this instrument is regarded as the first electron microscope. Ruska submitted the results for publication that same month, though the paper did not appear until August. Unfortunately, unbeknownst to him, between its submission and publication, a patent for an electron microscope had already been submitted by another inventor: Reinhold R√ºdenberg.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Paralysis to First Patents&lt;/head&gt;
    &lt;p&gt;R√ºdenberg, born in Hanover in 1883, came of age during a golden decade of physics marked by R√∂ntgen‚Äôs discovery of X-rays, the identification of the electron, and the first studies of radioactivity. As a high-school student, he eagerly replicated many of these experiments, building a two-way Morse telegraph, powering an X-ray tube with a hand-wound inductor, and constructing a radio transmitter and receiver. He received his first patent, for a radio oscillator, while still an electrical engineering student at the Technical University of Hanover.&lt;/p&gt;
    &lt;p&gt;After earning his doctorate, R√ºdenberg spent three years (1906-1908) at G√∂ttingen University, working in applied mechanics and collaborating with leading figures in electron theory, including Hans Busch. In 1908, he joined Siemens in Berlin as a design engineer and, by 1923, had risen to the position of Chief Electrical Engineer.&lt;/p&gt;
    &lt;p&gt;While at Siemens, R√ºdenberg developed several new electrical designs, among which were cooling systems for high-voltage generators, one of the first 60-megawatt turbine generators, conductors for high-voltage transmission lines, and relay systems for distant power stations. He also spent three years apprenticing in Siemens‚Äô patent department, an experience that doubtless helped fuel his prolific output of them. He was a prolific inventor and is estimated to have held over a hundred unique patents.&lt;/p&gt;
    &lt;p&gt;In the fall of 1930, while on vacation, R√ºdenberg‚Äôs youngest son fell gravely ill. The three-year-old developed a high fever and paralysis. He had contracted polio. At a time when thousands were infected each year in Germany, with fatality rates around 15 percent, the diagnosis was devastating. Worse still, almost nothing was known about the ‚Äúgerm‚Äù responsible: No diagnostic test, no treatment, and no vaccine existed.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis amazing fact and its significance for science and health gave me no rest in my thoughts,‚Äù R√ºdenberg later recalled. ‚ÄúDuring many sleepless nights, tortured by the fate of my son, agonizing fantasies came and went, how to find ways to examine these minute germs, how possibly to attack them in order to attain healing or at least a standstill of the disease. Certainly, an agent finer than light had to be found to make these tiny viruses of immeasurable size visible to the human eye.‚Äù&lt;/p&gt;
    &lt;p&gt;Motivated by both paternal concern and engineering instinct, R√ºdenberg began searching for a way to see such viruses. He considered X-rays but quickly dismissed them, as no method existed to focus the X-ray particles like visible light. Electrons, however, held promise. Having studied their behavior with Busch at G√∂ttingen, he was aware of the focusing power of magnetic fields, and when Busch later published his 1926 and 1927 papers on magnetic electron lenses, he even sent copies directly to R√ºdenberg.&lt;/p&gt;
    &lt;p&gt;During the winter of 1930-1931, R√ºdenberg sketched out a complete conceptual design for an electron microscope, detailing its electron source, electrostatic lenses for focusing and magnification, and a fluorescent screen for visualization. In May 1931, just one week before Ruska publicly presented his own work, R√ºdenberg submitted a series of patent applications describing this electron microscope.&lt;/p&gt;
    &lt;p&gt;Meanwhile, unaware of R√ºdenberg‚Äôs patents, Ruska also pressed forward. For his doctoral research, Ruska focused on improving the electromagnetic lens, whose magnification ability still lagged far behind the optical lenses of conventional light microscopes. At the time, a state-of-the-art light microscope could magnify images up to about 1000 times, whereas in 1932, extant electron microscopes were still stuck at a paltry 17-fold.&lt;/p&gt;
    &lt;p&gt;To improve their performance, Ruska realized he needed to decrease the electron microscope‚Äôs focal length, since a shorter focal length would bend electrons more strongly, bringing them to a smaller focal point and producing a higher magnification. He discovered that encasing the coil in iron did so dramatically. This led to the invention of the polepiece lens, now a fundamental component of all electron microscopes.&lt;/p&gt;
    &lt;p&gt;Polepieces are shaped iron cylinders, each with a coil, placed a few millimeters apart. The narrow gap concentrates the magnetic field, producing a lens with stronger focusing ability and a shorter focal length. This not only increased the magnification but also provided more space to add a third lens (a condenser lens upstream of the sample) within the cathode ray column.&lt;/p&gt;
    &lt;p&gt;During this time, Ruska and Knoll also made a bold attempt to estimate the theoretical resolution limit of the electron microscope. They applied the formula used in light microscopy and substituted the wavelength of electrons for that of light. For electrons accelerated at 75 kilovolts (higher voltages would increase the electrons‚Äô energy and further shorten their wavelength, which, in principle, yields even finer detail), they arrived at a resolution limit of 2.2 angstroms (2.2 x 10-10 meters).8&lt;/p&gt;
    &lt;p&gt;Ruska submitted his dissertation in mid-1933 and later that year built a vastly improved microscope, achieving magnification up to 12,000 times. The images, taken of a scrap of aluminum foil, exceeded the resolution limit of the light microscope for the first time (even though the high-energy beam incinerated the samples).&lt;/p&gt;
    &lt;p&gt;Ruska observed that very thin foils produced sharper images with stronger contrast while also surviving longer under the beam. He reasoned that, in thin specimens, most electrons passed through without losing energy, elastically scattered (diffracted) rather than absorbed. These transmitted electrons still carried structural information and built up the image on the screen. Because fewer electrons deposited energy in the material, less heating and radiation damage occurred, allowing longer exposures and finer detail.&lt;/p&gt;
    &lt;p&gt;By 1934, Ruska had published these findings and even speculated about imaging biological material. He stated, ‚ÄúThis microscopy is accessible to any objects (including all organic ones), provided that they can be prepared as sufficiently thin foils and introduced into the vacuum without suffering damage (structural alteration).‚Äù And, ‚ÄúFor better visualization of such objects ‚Äî one might think, for example, of nerve fibrils with their extremely fine structure ‚Äî it will perhaps be necessary to develop ‚Äòstaining‚Äô methods adapted to the problem, such as impregnation with metal salts (silvering), similar to those already commonly used in ordinary histological microscopy.‚Äù&lt;/p&gt;
    &lt;p&gt;R√ºdenberg‚Äôs design, meanwhile, was never built at Siemens. The political upheaval in Germany halted his advancement, as a German of Jewish descent, threatened his very survival. In 1936, with Siemens‚Äô assistance, he and his family fled to England and, two years later, emigrated to the United States, where he became a professor of electrical engineering at Harvard.&lt;/p&gt;
    &lt;p&gt;Ironically, as a German, R√ºdenberg was received with ambivalence; in 1942, during the war, his U.S. patents on the electron microscope were seized by the Alien Property Custodian, a government office tasked with seizing assets belonging to citizens of enemy nations during wartime. Post-war, he had to fight lengthy legal battles to reclaim them. He later consulted for Farrand Optical Company, a small company in New York which attempted to build an electrostatic microscope based on his patents, a venture which failed commercially. Happily, even as these obstacles abounded, his son made a full recovery from his polio.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Prototype to Commercialization&lt;/head&gt;
    &lt;p&gt;By the early 1930s, electron microscopy had surpassed the resolving power of light microscopes, promising magnifications several orders of magnitude higher. Yet progress was uneven.&lt;/p&gt;
    &lt;p&gt;In Belgium, the Hungarian physicist Ladislaus Marton built his own instrument by 1932 and produced the first biological electron micrographs: images of the insectivorous plant Drosera intermedia and the blood-red bacterium, Serratia marcescens.&lt;/p&gt;
    &lt;p&gt;To make such delicate samples visible, Marton turned to osmium tetroxide, a heavy metal compound that binds strongly to cellular membranes. By coating thin sections of Drosera intermedia with osmium, he increased their ability to scatter electrons, resulting in clearer contrast in the final image. He also introduced an electronic shutter, a device that blocked the electron beam during focusing and opened only for the brief moment of exposure. This protected fragile specimens from unnecessary radiation damage while still allowing sharp images to be captured. For a time, it seemed Marton was leading the field.&lt;/p&gt;
    &lt;p&gt;Ruska, who had completed his PhD in 1933 and took a job in the television industry, returned to the field. He joined forces with Bodo von Borries, a longtime collaborator and future brother-in-law, to push the technology toward commercial viability. Between 1933 and 1935, they filed eight patents and canvassed a wide range of institutions for financial support. They approached the Kaiser Wilhelm Institute, the board of optical manufacturer Carl Zeiss, and even steel companies to see if they had any need for electron microscopes. While initial efforts with Zeiss seemed promising, they collapsed when Zeiss withdrew due to Siemens‚Äôs rights to Reinhold R√ºdenberg‚Äôs earlier patents.&lt;/p&gt;
    &lt;p&gt;Despite these setbacks, interest in electron microscopy mounted. At the Technical School in Berlin, students modified Ruska‚Äôs prototypes to capture striking images of a fly‚Äôs leg hair magnified 25,000 times. To make the tissues more resistant to the beam, they used potassium dichromate, a fixative that coss-linked lipids and proteins in the tissue so it was less likely to collapse or vaporize. This fixative also increased scattering contrast, making fine details easier to discern.&lt;/p&gt;
    &lt;p&gt;Specimens were cooled to ‚Äì17 ¬∞C, which reduced thermal motion and slowed the buildup of heat from inelastic electron collisions. Cooling didn‚Äôt prevent radiation damage, but it delayed it long enough for images to be recorded. These were early explorations of the cryogenic methods that would later define the field.&lt;/p&gt;
    &lt;p&gt;By 1936, electron microscopy centered around a highly active (albeit small) community with Marton in Belgium, Ruska and von Borries in Berlin, and younger researchers at their university extending the work. However, all still lacked financial support to develop a commercial system.&lt;/p&gt;
    &lt;p&gt;Momentum shifted when Ruska spoke at the 1936 German Conference of Physicists and Mathematicians. His brother Helmut, a physician newly appointed at Berlin‚Äôs University Hospital, added crucial medical endorsement by promoting the microscope‚Äôs potential in medical applications. This medical credibility brought Siemens back to the table. With both Siemens and Zeiss expressing interest, Ruska and von Borries chose Siemens, which already held the R√ºdenberg patents and had stronger electrotechnical expertise.&lt;/p&gt;
    &lt;p&gt;In February 1937, a decade after Hans Busch first theorized the electron lens, Siemens launched development of the first commercial electron microscope in Berlin. By 1938, the first model was available, offering magnification of up to 30,000 times.&lt;/p&gt;
    &lt;p&gt;The device was a triumph of Ruska‚Äôs bench-top experiments and relentless iteration. At the top of the microscope column sat the cathode, generating electrons accelerated downward at high voltage. A condenser lens collected, narrowed, and focused the electron beam to illuminate the sample, which was introduced through a small vacuum airlock and held on a stage. Immediately below it lay the objective lens, a powerful magnetic coil that brought the transmitted electrons into sharp focus, forming a first, intermediate image. A second coil, the projection lens, then enlarged this image and cast it onto a fluorescent screen, where bright and dark regions revealed the specimen‚Äôs structure. Researchers could view the glowing picture directly through a built-in window or capture it on photographic plates housed beneath the screen. To maintain stable operation, the entire column was kept under high vacuum by a mercury diffusion pump.&lt;/p&gt;
    &lt;p&gt;A shared Siemens laboratory was set up and became an important hub for producing some of the earliest biological electron micrographs. Directed by Helmut Ruska, it housed four instruments available to visiting scientists, many of them biologists and medical researchers. In 1939 alone, nearly 2,000 images were produced, leading to 23 publications. Among them were the first electron micrographs of viruses, bacteriophages, and fine biological details never before seen.&lt;/p&gt;
    &lt;p&gt;The lab itself was destroyed in an air raid in 1944, and it would take nearly a decade before Siemens in Germany regained its footing in electron microscopy. But by then, the electron microscopy spark had spread: Laboratories in Britain and the United States continued to drive the field forward, building on the groundwork laid in Berlin. Ernst Ruska would go on to win the Nobel Prize in Physics in 1986 for his fundamental work in electron optics and microscopy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside an Electron Microscope&lt;/head&gt;
    &lt;p&gt;Nearly a century after its invention, the electron microscope has transformed from a tool barely capable of resolving fuzzy virus particles into one capable of capturing atomic detail. While its progress has mostly been marked by steady refinements, it has also been punctuated by key breakthroughs.&lt;/p&gt;
    &lt;p&gt;For instance, from the start, electron microscopy for biology faced a water problem. Because the microscope operates under high vacuum, liquid water evaporates instantly, leaving delicate biological samples collapsed or distorted. To avoid this, aqueous samples had to be dried, fixed, or stained, which produced recognizable images but with obvious artifacts, such as shrunken cells, ruptured membranes, and structural distortions that no longer reflected the living state. Through the 1940s and 1950s, embedding samples in resins and the use of ultra-thin sectioning made cellular ultrastructure visible, while freeze-drying and early cryogenic sectioning offered partial preservation of hydrated material, though the results were still plagued by distortion.&lt;/p&gt;
    &lt;p&gt;A breakthrough came in the early 1980s, when Jacques Dubochet and his colleagues at the European Molecular Biology Laboratory in Heidelberg demonstrated that water could be vitrified; that is, cooled so rapidly that it solidifies into glass rather than crystallizing, finally allowing biomolecules to be preserved and imaged as they are in life.&lt;/p&gt;
    &lt;p&gt;In parallel, computational techniques were improving. Beginning in the 1970s, Joachim Frank developed statistical methods for aligning and averaging thousands of noisy electron micrographs of individual macromolecules. This ‚Äúsingle-particle analysis‚Äù transformed faint, low-contrast images into coherent 3D reconstructions. When combined with Dubochet‚Äôs vitrification method, the two advances gave rise to single-particle cryo-electron microscopy: Molecules suspended in vitreous ice could be imaged in random orientations and computationally combined into detailed three-dimensional structures.&lt;/p&gt;
    &lt;p&gt;Three decades later, with the arrival of direct electron detectors, developed with the efforts of Richard Henderson and with more powerful algorithms, single-particle cryo-EM entered its ‚Äúresolution revolution,‚Äù routinely delivering near-atomic detail and firmly establishing itself as one of the central methods of structural biology.&lt;/p&gt;
    &lt;p&gt;Today‚Äôs most advanced cryo-electron microscopes stand nearly two stories tall, cost millions of dollars, and operate with breathtaking precision. But they still rest on the same foundation laid in the 1930s: a beam of electrons, shaped by magnetic fields, interacting with matter to reveal what light cannot.&lt;lb/&gt;At the top of the vertical column is the electron gun, the source of the beam. A fine tungsten filament or sharp field-emission tip is held at high negative voltage, often 200‚Äì300 kilovolts, so electrons are released and accelerated down the column. At these energies, electrons travel close to the speed of light, with wavelengths thousands of times shorter than visible light, giving them their extraordinary resolving power. To prevent scattering, the column is maintained in an ultra-high vacuum, as even trace gases could deflect or scatter the beam.&lt;/p&gt;
    &lt;p&gt;Magnetic lenses, made of coiled wire encased in iron polepieces, focus and steer the electrons much like glass lenses bend light. The condenser lens narrows the beam onto the sample, while the objective lens forms the first magnified image. Additional projector lenses enlarge this image and deliver it to a detector.&lt;/p&gt;
    &lt;p&gt;When the beam passes through the specimen, electrons interact with its atoms. Some scatter elastically, shifting phase without losing energy; others scatter inelastically, losing energy, and are either absorbed or filtered out. The transmitted electrons carry structural information, encoded as variations in amplitude and phase, and create a contrast image on the detector.&lt;/p&gt;
    &lt;p&gt;In cryo-EM, millions of such low-contrast 2D projections are collected, each a noisy snapshot of a molecule in a random orientation. Computational algorithms align, classify, and combine them, using a mathematical method that breaks the images down into their underlying patterns of waves (using the Fourier transform), then piece those patterns back together to form a detailed 3D map.&lt;/p&gt;
    &lt;p&gt;The result begins as a grainy micrograph, but when assembled and refined, this picture reveals extraordinary detail: the honeycomb lattice of graphene, the folds of a viral capsid, or the ribosome caught mid-translation. &lt;lb/&gt;Today, no single imaging method captures everything. For following fast processes, tracking molecules in living cells, or imaging whole organisms, light microscopy remains indispensable. For atomic resolution of well-ordered proteins, X-ray crystallography is still unmatched. &lt;/p&gt;
    &lt;p&gt;But when it comes to bridging the scales between atoms and cells, there is no better tool than the electron microscope. The same instrument that in 1938 revealed the faint silhouettes of mouse ectromelia virus now resolves viral proteins at the scale of a chemical bond, an arc of progress that has helped biologists redefine what it means to ‚Äúsee.‚Äù&lt;/p&gt;
    &lt;p&gt;Smrithi Sunil is a research scientist developing imaging techniques to study how the brain works across scales. She has developed multimodal microscopy methods to bridge molecular, cellular, and systems-level measurements of structure and function. She also writes about science and metascience on her Substack, Engineering Discovery.&lt;/p&gt;
    &lt;p&gt;Thanks to Nicholas Porter and Alicia Botes for reading a draft of this essay. Lead image by Ella Watkins-Dulaney, adapted from Vossman/Wikimedia and Ernst Ruska. Whole-cell animation and video by Martina Maritan, Scripps Research.&lt;/p&gt;
    &lt;p&gt;Cite: Sunil, S. ‚ÄúMaking the Electron Microscope.‚Äù Asimov Press (2025). https://doi.org/10.62211/57hg-22fw&lt;/p&gt;
    &lt;p&gt;One of the smallest known whole organisms is the bacteria Mycoplasma genitalium roughly 200 nm across. In contrast, the mycelium network Armillaria ostoyae in the Malheur National Forest in Oregon is possibly the largest living organism, covering almost four square miles and weighing around 35,000 tons.&lt;/p&gt;
    &lt;p&gt;The length between chemical bonds is measured in Angstroms, named after Swedish physicist Anders Jonas Angstrom who first described the unit.&lt;/p&gt;
    &lt;p&gt;A year later, in 1939, Gustav Kausche, Edgar Pfankuch, and Helmut Ruska reported the first images of the tobacco mosaic virus (TMV). Although TMV is often cited as the ‚Äúfirst‚Äù virus to be imaged with an electron microscope since TMV was a classic model virus in biology and its rod-shaped form was immediately recognizable, the mouse orthopoxvirus micrographs technically appeared earlier.&lt;/p&gt;
    &lt;p&gt;To work around this, scientists capture dynamics indirectly by freezing specimens at different stages of a process (such as during the assembly of a protein complex) and then reconstruct the sequence from these static frames.&lt;/p&gt;
    &lt;p&gt;Numerical aperture NA = n sin Œ∏, where n is the refractive index of the medium and Œ∏ is the half-angle of the widest cone of light the lens can accept.&lt;/p&gt;
    &lt;p&gt;Twice this value arises because fine structures in a specimen diffract light into symmetric beams on opposite sides of the optical axis. When both of these beams are captured by the objective and brought together at the image plane, they interfere with reconstructing the alternating patterns of light and dark that represent the specimen‚Äôs fine detail. Note that Abbe‚Äôs formula is for coherent transmitted light and not for fluorescent imaging. In fluorescence microscopy, each molecule emits light independently rather than by interfering wavefronts, so the image is not formed by overlapping diffraction orders. The resolution is instead limited by the microscope‚Äôs point spread function, described by the Rayleigh criterion (d = 1.22 Œª / 2 NA), which sets the smallest distance at which two fluorescent emitters can be distinguished.&lt;/p&gt;
    &lt;p&gt;Even before ‚Äúelectrons‚Äù were named, Julius Pl√ºcker showed in the 1850s that magnetic fields could deflect the glowing path of cathode rays. Johann Hittorf (1869) and Kristian Birkeland (1896) had independently used magnetic coils to focus them. Hans Busch was the first to provide mathematical calculations for the electron trajectories during this focusing action.&lt;/p&gt;
    &lt;p&gt;This resolution was, in fact, achieved 40 years later. Today, electron microscopy has even surpassed that mark: Scientists have resolved biological structures to well below 2 angstroms, including the GABA receptor, a membrane protein channel that mediates inhibitory neurotransmission, at 1.7 angstroms. In this system, the electrons were accelerated to 300 kilovolts, yielding a resolution better than the one Ruska proposed with only 75 kilovolts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713253</guid><pubDate>Sun, 26 Oct 2025 16:46:22 +0000</pubDate></item><item><title>Ken Thompson recalls Unix's rowdy, lock-picking origins</title><link>https://thenewstack.io/ken-thompson-recalls-unixs-rowdy-lock-picking-origins/</link><description>&lt;doc fingerprint="3a3a188cfbb6805d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ken Thompson Recalls Unix‚Äôs Rowdy, Lock-Picking Origins&lt;/head&gt;
    &lt;p&gt;The 82-year-old Ken Thompson has some amazing memories about the earliest days of the Unix operating system ‚Äî and the rowdy room full of geeks who built it.&lt;/p&gt;
    &lt;p&gt;This month Silicon Valley‚Äôs Computer History Museum released a special four-and-a-half-hour oral history, in partnership with the Association for Computing Machinery, recorded 18 months ago by technology historian David C. Brock. And Thompson dutifully recalled many of his career highlights ‚Äî from his work on the C programming language and Unix to the ‚ÄúPlan 9 from Bell Labs‚Äù operating system and the Go programming language.&lt;/p&gt;
    &lt;p&gt;But what comes through is his gratefulness for the people he‚Äôd worked with, and the opportunity they‚Äôd had to all experiment together in an open environment to explore the limits of new and emerging technologies. It‚Äôs a tale of curiosity, a playful sense of serendipity and the enduring value of a community.&lt;/p&gt;
    &lt;p&gt;And along the way, Thompson also tells the story of raising a baby alligator that a friend sent to his office at Bell Labs. (‚ÄúIt just showed up in the mail‚Ä¶ They‚Äôre not the sweetest of pets.‚Äù)&lt;/p&gt;
    &lt;head rend="h2"&gt;The Accidental Birth of Unix&lt;/head&gt;
    &lt;p&gt;Travel back in time to 1966, when 23-year-old Thompson‚Äôs first project at Bell Labs was the ill-fated Multics, a collaboration with MIT and General Electric which Thompson remembers as ‚Äúhorrible‚Ä¶ big and slow and ugly and very expensive,‚Äù requiring a giant specially-built computer just to run and ‚Äújust destined to be dead before it started.‚Äù&lt;/p&gt;
    &lt;p&gt;But when the Multics project died, ‚Äúthe computer became completely available ‚Äî this one-of-a-kind monster computer‚Ä¶ and so I took advantage.‚Äù&lt;/p&gt;
    &lt;p&gt;Thompson had wanted to work with CRAM, a data storage device with a high-speed drum memory, but like disk storage of the time, it was slow to read from memory.&lt;/p&gt;
    &lt;p&gt;Thompson thought he‚Äôd improve the situation with simultaneous (and overlapping) memory reads, but of course this required programs for testing, plus a way to load and run them.&lt;/p&gt;
    &lt;p&gt;‚ÄúAnd suddenly, without knowing it ‚Äî I mean, this is sneaking up on me‚Ä¶. Suddenly it‚Äôs an operating system!‚Äù Thompson‚Äôs initial memory-reading work became ‚Äúthe disk part‚Äù for Unix‚Äôs filesystem. He still needed a text editor and a user-switching multiplexing layer (plus a compiler and an assembler for programs), but it already had a filesystem, a disk driver and I/O peripherals.&lt;/p&gt;
    &lt;p&gt;Thompson wondered if it took so long to recognize its potential because he‚Äôd been specifically told not to work on operating systems. Multics ‚Äúwas a bad experience‚Äù for Bell Labs, he‚Äôd been told. ‚ÄúWe spent a ton of money on it, and we got nothing out of it!‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúI actually got reprimands saying, ‚ÄòDon‚Äôt work on operating systems. Bell Labs is out of operating systems!‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;One-Digit User IDs&lt;/head&gt;
    &lt;p&gt;But now Unix had its first user community ‚Äî future legends like Dennis Ritchie, Doug McIlroy, Robert Morris and occasionally Brian Kernighan. (‚ÄúAll the user IDs were one digit. That definitely put a limit on it.‚Äù) Thompson remembers designing the Unix filesystem on a blackboard in an office with Rudd Canaday ‚Äî using a special Bell Labs phone number that took dictation and delivered a typed-up transcript the next day. And Joe Ossanna ‚Äúgot things done‚Äù with a special talent for navigating Bell Labs‚Äô bureaucracy that ultimately procured a crucial PDP-11 for the Unix team to work on.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe were being told no, ‚Äòbecause we don‚Äôt deal in operating systems.'‚Äù But Ossanna knew the patent department was evaluating a third-party system for preparing documents ‚Äî and Ossanna proposed an in-house alternative. ‚ÄúSo we got our first PDP-11 to do word processing.‚Äù&lt;/p&gt;
    &lt;p&gt;And history shows that it happened partly because the department paying for it ‚Äúhad extra money, and if they didn‚Äôt spend it, they‚Äôd lose it the next year‚Ä¶‚Äù&lt;/p&gt;
    &lt;p&gt;So the young Unix community picked up somewhere between five and eight new users, Thompson remembers, ‚Äúthe secretaries for the Patent Department, writing patents on our system!‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fellowship of the Unix Room&lt;/head&gt;
    &lt;p&gt;That PDP-11 wound up in ‚Äúa spot on the sixth floor where we cleaned out a vending machine and a couple of cages of stored junk from 1920,‚Äù Thompson remembered. They eventually installed a second PDP-11, which turned the room into ‚Äúa hotbed of things,‚Äù with discussions about networking ‚Äî and an upcoming typesetter for documents. Thompson calls it the Unix room, and most of them eventually had extensions for their phones wired into the room. (It even had its own call-switching PBX ‚Ä¶)&lt;/p&gt;
    &lt;p&gt;There was camaraderie and some laughter. He adds later, almost as an aside, that ‚Äúin the Unix room, we used to pick locks a lot and steal things.‚Äù (When one of the secretaries discovered security had affixed a ‚Äúparking boot‚Äù to her car that was parked in the wrong zone, ‚Äúwe went down there, and we picked the lock and stole the boot. And after that, slowly, we picked up all four boots, and we hid them under the raised floor of the Unix room‚Ä¶‚Äù)&lt;/p&gt;
    &lt;p&gt;The punchline? ‚ÄúThe head of security came around and pleaded with us. ‚ÄòWe won‚Äôt pick on your secretaries if you give us back our boots.'‚Äù&lt;/p&gt;
    &lt;p&gt;And the deal was accepted.&lt;/p&gt;
    &lt;p&gt;Thompson remembers things like gathering for a regular ‚ÄúUnix lunch‚Äù in the Bell Labs lunchroom, which ‚Äúcaused a symbiosis of thought and things. It was great.‚Äù Although it always seemed to happen just minutes after the lunchroom stopped serving food. ‚ÄúIf I was late, I‚Äôd buy McDonald‚Äôs and sit down at the lunchroom with my McDonald‚Äôs. They used to get mad at me for that ‚Ä¶‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Growing From Community&lt;/head&gt;
    &lt;p&gt;Looking back, Thompson credited the success of C and Unix to Bell Labs and its no-pressure/no users environment. ‚ÄúIt was essentially a ‚Äòwhatever you want to do‚Äô atmosphere, and ‚Äòfor anybody you wanted to do it for‚Äô‚Ä¶ Bell Labs was by far the biggest contributor to this whole type of programming.‚Äù&lt;/p&gt;
    &lt;p&gt;Bell Labs was an eclectic mix, but this community paid unexpected dividends. While Lee McMahon was originally hired as a linguistics researcher, he was ultimately the one who procured machine-readable dictionaries for the Unix team, along with machine-readable version of the Federalist Papers. (When the whole text wouldn‚Äôt fit into their text editor ed, Thompson famously created the line-by-line pattern-scanning tool grep.)&lt;/p&gt;
    &lt;p&gt;And in the end Thompson says Unix grew from there for one simple fact: People liked it. It spread within Bell Labs, at first for ‚Äúthe administrative kind of stuff, typing in trouble tickets‚Ä¶‚Äù But this being a phone company, ‚Äúthen it started actually doing some switching, and stuff like that. It was getting deeper and deeper into the guts of the Bell System and becoming very popular.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Before Open Source&lt;/head&gt;
    &lt;p&gt;Thompson credits Richard Stallman with developing much more of the open source philosophy. ‚ÄúBut Unix had a bit of that.‚Äù Maybe it grew out of what Dennis Ritchie was remembering, that fellowship that formed around Unix. ‚ÄúFor some reason, and I think it‚Äôs just because of me and Dennis, everything was open‚Ä¶‚Äù&lt;/p&gt;
    &lt;p&gt;It was just the way they operated. ‚ÄúWe had protection on files ‚Äî if you didn‚Äôt want somebody to read it, you could set some bits and then nobody could read them, right? But nobody set those permissions on anything ‚Ä¶ All of the source was writable, by anybody! It was just open ‚Ä¶&lt;/p&gt;
    &lt;p&gt;‚ÄúIf you had an idea for an editor, you‚Äôd pull the editor out and you‚Äôd write on it and put it back ‚Ä¶ There was a mantra going around that, ‚ÄòYou touch it, you own it.'‚Äù&lt;/p&gt;
    &lt;p&gt;Thompson provides an example: Bell Labs co-worker P. J. Plauger, with whom he later wrote the 1974 book ‚ÄúElements of Programming Style.‚Äù Plauger was also a professional science fiction writer, Thompson remembers, ‚ÄúAnd whatever he was writing on was in his directory, right? So, we‚Äôd all go in there and be reading it as he‚Äôs writing it ‚Ä¶ and we‚Äôd all write back, ‚ÄòYou ought to kill this guy, and move him over here and turn him green!‚Äô or something.&lt;/p&gt;
    &lt;p&gt;‚ÄúAnd he didn‚Äôt mind it, because that‚Äôs just the theory of Unix in those days ‚Ä¶&lt;/p&gt;
    &lt;p&gt;‚ÄúI think that generated a fellowship. Just the fact that it was like writing on a blackboard ‚Äî everybody read it.‚Äù&lt;/p&gt;
    &lt;p&gt;And more of their Bell Labs experiments found their way into the world when some work on the later Plan 9 operating system found its way into the UTF-8 standard, which underlies most of today‚Äôs web connections.&lt;/p&gt;
    &lt;head rend="h2"&gt;After Bell Labs&lt;/head&gt;
    &lt;p&gt;Thompson left Bell Labs in 2000, after the breakup of the Bell system. (‚ÄúIt had changed; it was really different ‚Ä¶ You had to justify what you were doing, which is way above my pay grade.‚Äù) But his three decades there seemed to shine an influence over the rest of his life.&lt;/p&gt;
    &lt;p&gt;Thompson first moved on to a networking equipment company called Entrisphere, where he worked for six years ‚Äî and a move to Google was the natural next step. The head at Entrisphere had already moved to Google, and was urging Thompson to follow him ‚Äî and it turned out that Google CEO Eric Schmidt was an old friend who‚Äôs actually worked at Bell Labs in 1975. (Thompson says Google made him ‚Äúan exceedingly good offer‚Äù‚Ä¶)&lt;/p&gt;
    &lt;p&gt;At Google Thompson worked ‚Äúa little bit‚Äù on Android security. (‚ÄúI found a couple of specific problems, but by and large, it was very well done‚Äù.) But eventually Thompson joined the three-person team that would create the programming language Go.&lt;/p&gt;
    &lt;p&gt;And he was doing the work with Rob Pike, who was one of his old comrades from Bell Labs nearly 30 years before!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713359</guid><pubDate>Sun, 26 Oct 2025 16:57:12 +0000</pubDate></item><item><title>Alzheimer's disrupts circadian rhythms of plaque-clearing brain cells</title><link>https://medicine.washu.edu/news/alzheimers-disrupts-circadian-rhythms-of-plaque-clearing-brain-cells/</link><description>&lt;doc fingerprint="7e0030234a219fc7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Alzheimer‚Äôs disrupts circadian rhythms of plaque-clearing brain cells&lt;/head&gt;&lt;p&gt;Mouse study shows how disease reprograms genes in specialized cells involved in amyloid removal&lt;/p&gt;Getty Images&lt;p&gt;Alzheimer‚Äôs disease is notorious for scrambling patients‚Äô daily rhythms. Restless nights with little sleep and increased napping during the day are early indicators of disease onset, while sundowning, or confusion later in the day, is typical for later stages of the disease. These symptoms suggest a link between the progression of the disease and the circadian system ‚Äî the body‚Äôs internal clock that controls our sleep and wake cycle ‚Äî but scientists did not know the full nature of the connection.&lt;/p&gt;&lt;p&gt;Researchers from Washington University School of Medicine in St. Louis have now shown in mice that the circadian rhythms within particular brain cells are disrupted in Alzheimer‚Äôs disease in ways that change how and when hundreds of genes regulate key functions in the brain.&lt;/p&gt;&lt;p&gt;The findings, published October 23 in Nature Neuroscience, suggest that controlling or correcting these circadian rhythms could be a potential way to treat the disease.&lt;/p&gt;&lt;p&gt;‚ÄúThere are 82 genes that have been associated with Alzheimer‚Äôs disease risk, and we found that the circadian rhythm is controlling the activity of about half of those,‚Äù said Erik S. Musiek, MD, PhD, the Charlotte &amp;amp; Paul Hagemann Professor of Neurology at WashU Medicine, who led the study. In mice modeling Alzheimer‚Äôs disease, the typical daily activity patterns of those genes were altered. ‚ÄúKnowing that a lot of these Alzheimer‚Äôs genes are being regulated by the circadian rhythm gives us the opportunity to find ways to identify therapeutic treatments to manipulate them and prevent the progression of the disease.‚Äù&lt;/p&gt;&lt;p&gt;Musiek, the co-director of the Center on Biological Rhythms and Sleep (COBRAS) at WashU Medicine and a neurologist who specializes in aging and dementia, said that changes in sleep patterns are among the most frequent concerns reported to him by caregivers of Alzheimer‚Äôs patients. He and colleagues have previously shown that these changes begin in Alzheimer‚Äôs years before memory loss becomes apparent. He noted that in addition to creating burdens for caregivers and patients, disrupted sleep patterns generate biological and psychological stresses that accelerate the progression of the disease.&lt;/p&gt;&lt;p&gt;Breaking this feedback loop requires identifying its origins. The body‚Äôs circadian clock is thought to act on 20% of all genes in the human genome, controlling when they turn on or off to manage processes including digestion, the immune system and our sleep-wake cycle.&lt;/p&gt;&lt;p&gt;Musiek had previously identified a specific protein, YKL-40, that fluctuates across the circadian cycle and regulates normal levels of amyloid protein in the brain. He found that too much of YKL-40, which is linked to Alzheimer‚Äôs risk in humans, leads to amyloid build-up, an accumulation that is a hallmark of the neurodegenerative disease.&lt;/p&gt;&lt;head rend="h2"&gt;Amyloid disrupts rhythmic brain functions&lt;/head&gt;&lt;p&gt;The cyclic nature of Alzheimer‚Äôs symptoms suggests that there are more circadian-regulated proteins and their associated genes involved beyond YKL-40. So in this latest study, Musiek and his colleagues examined gene expression in the brains of mice with accumulations of amyloid proteins that mimic early stages of Alzheimer‚Äôs, as well as those of both healthy, young animals and aged mice without amyloid accumulations. The scientists collected tissue at 2-hour intervals over 24 hours and then performed an analysis of what genes were active during particular phases of the circadian cycle.&lt;/p&gt;&lt;p&gt;They found that the amyloid accumulations threw off the daily rhythms of hundreds of genes in brain cells known as microglia and astrocytes in ways that were different from what aging alone caused. Microglia are part of the brain‚Äôs immune response, clearing away toxic materials and dead cells, while astrocytes have roles in supporting and maintaining communication between neurons. The affected genes are generally involved in helping microglial cells break down waste material from the brain, including amyloid.&lt;/p&gt;&lt;p&gt;While the circadian disruption didn‚Äôt entirely shut down the genes in question, it turned an orderly sequence of events into a scattershot affair that could degrade the optimal synchronicity of brain cells‚Äô functions, such as clearing amyloid.&lt;/p&gt;&lt;p&gt;In addition, the researchers found that the presence of amyloid appeared to create new rhythms in hundreds of genes that do not typically have a circadian pattern of activity. Many of the genes are involved in the brain‚Äôs inflammatory response to infection or imbalances such as amyloid plaque build-up.&lt;/p&gt;&lt;p&gt;Musiek said that altogether the findings point to exploring therapies that target circadian cycles in microglia and astrocytes to support healthy brain function.&lt;/p&gt;&lt;p&gt;‚ÄúWe have a lot of things we still need to understand, but where the rubber meets the road is trying to manipulate the clock in some way, make it stronger, make it weaker or turn it off in certain cell types,‚Äù he said. ‚ÄúUltimately, we hope to learn how to optimize the circadian system to prevent amyloid accumulation and other aspects of Alzheimer‚Äôs disease.‚Äù&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713738</guid><pubDate>Sun, 26 Oct 2025 17:40:06 +0000</pubDate></item><item><title>Nvidia DGX Spark: When benchmark numbers meet production reality</title><link>https://publish.obsidian.md/aixplore/Practical+Applications/dgx-lab-benchmarks-vs-reality-day-4</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713835</guid><pubDate>Sun, 26 Oct 2025 17:53:22 +0000</pubDate></item><item><title>A definition of AGI</title><link>https://arxiv.org/abs/2510.18212</link><description>&lt;doc fingerprint="e99d252bccd7a6af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 21 Oct 2025 (v1), last revised 23 Oct 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:A Definition of AGI&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The lack of a concrete definition for Artificial General Intelligence (AGI) obscures the gap between today's specialized AI and human-level cognition. This paper introduces a quantifiable framework to address this, defining AGI as matching the cognitive versatility and proficiency of a well-educated adult. To operationalize this, we ground our methodology in Cattell-Horn-Carroll theory, the most empirically validated model of human cognition. The framework dissects general intelligence into ten core cognitive domains-including reasoning, memory, and perception-and adapts established human psychometric batteries to evaluate AI systems. Application of this framework reveals a highly "jagged" cognitive profile in contemporary models. While proficient in knowledge-intensive domains, current AI systems have critical deficits in foundational cognitive machinery, particularly long-term memory storage. The resulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 57%) concretely quantify both rapid progress and the substantial gap remaining before AGI.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Long Phan [view email]&lt;p&gt;[v1] Tue, 21 Oct 2025 01:28:35 UTC (20,673 KB)&lt;/p&gt;&lt;p&gt;[v2] Thu, 23 Oct 2025 18:00:45 UTC (20,299 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713959</guid><pubDate>Sun, 26 Oct 2025 18:09:37 +0000</pubDate></item><item><title>Show HN: MyraOS ‚Äì My 32-bit operating system in C and ASM (Hack Club project)</title><link>https://github.com/dvir-biton/MyraOS</link><description>&lt;doc fingerprint="a2641ac90aa6e498"&gt;
  &lt;main&gt;
    &lt;p&gt;A x86 Unix-like OS made entirely from scratch.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protected mode (GDT/IDT, ISRs/IRQs)&lt;/item&gt;
      &lt;item&gt;Paging and virtual memory&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;Heap and dynamic memory&lt;/item&gt;
      &lt;item&gt;User-mode (ring 3) and kernel mode (ring 0)&lt;/item&gt;
      &lt;item&gt;Processes and scheduling&lt;/item&gt;
      &lt;item&gt;Drivers (PIT, RTC, Keyboard, Mouse, Framebuffer, PATA)&lt;/item&gt;
      &lt;item&gt;ext2 filesystem&lt;/item&gt;
      &lt;item&gt;UI compositor with window widgets, labels, icons, buttons, and even a custom-made font&lt;/item&gt;
      &lt;item&gt;ELF loader, which gives you the ability to run real apps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All these features let you run real games, just like Doom, giving the preloaded Doom port in MyraOS ready to be played!&lt;lb/&gt; So, this isn't just a toy OS or a look-alike, it's a real OS that can run on real devices&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the latest release from the release tab in GitHub&lt;/item&gt;
      &lt;item&gt;Download QEMU - an open-source machine emulator and virtualizer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After you get the latest release, you can run this on your platform:&lt;/p&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen (if you are like me and want it to look real)&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -full-screen
&lt;/code&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;Here, Linux/macOS or even WSL are better; use it as a last resort:&lt;lb/&gt; Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;I really hope you like it, as I spent a lot of time on it, and I'd really appreciate any feedback you have for me.&lt;lb/&gt; If you have anything, from feature requests to feedback, or even if you want to talk, email me here: &lt;code&gt;dvirm.biton@gmail.com&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715055</guid><pubDate>Sun, 26 Oct 2025 20:43:40 +0000</pubDate></item><item><title>Poison, Poison Everywhere</title><link>https://loeber.substack.com/p/29-poison-poison-everywhere</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715726</guid><pubDate>Sun, 26 Oct 2025 22:36:34 +0000</pubDate></item><item><title>Show HN: Helium Browser for Android with extensions support, based on Vanadium</title><link>https://github.com/jqssun/android-helium-browser</link><description>&lt;doc fingerprint="9eb4893fee94f46c"&gt;
  &lt;main&gt;
    &lt;p&gt;An experimental Chromium-based web browser for Android with extensions support, based on&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Helium by imput, as well as&lt;/item&gt;
      &lt;item&gt;Vanadium by GrapheneOS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Navigate to Chrome Web Store, then enable Desktop site by selecting the menu button ‚ãÆ in the top right corner and ensure the option is checked. Select Okay and proceed as normal if prompted with:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Chrome Web Store is only available on desktop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Once you select Add to Chrome, the extension will be installed in the background until the button changes into Remove from Chrome.&lt;/p&gt;
    &lt;p&gt;To view and access the debug URLs, use &lt;code&gt;chrome://chrome-urls&lt;/code&gt;. For Experiments, use &lt;code&gt;chrome://flags&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Consistent with both Helium and Vanadium, the option is available by selecting the menu button ‚ãÆ in the top right corner, then Settings, Privacy and security, then under Privacy, WebRTC IP handling policy. If you experience issues with WebRTC due to the IPs being shielded by default (e.g. Discord Voice), you may try to change it to Default public interface only, or Default.&lt;/p&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;All builds are experimental, so unexpected issues may occur. Helium Browser for Android only attempts to improve security and privacy where possible. For better protection on Android, you should instead use GrapheneOS with Vanadium, which additionally integrates patches into Android System WebView and provides significant kernel and memory management hardening on the OS level.&lt;/p&gt;
    &lt;code&gt;---
config:
  layout: dagre
---
flowchart TD
 subgraph s1["Helium"]
        n5["Generic Patches&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;patches/series&amp;lt;/small&amp;gt;"]
        n6["Name Substitution&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;utils/name_substitution.py&amp;lt;/small&amp;gt;"]
        n7["Version Patch&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;{*version,revision}.txt&amp;lt;/small&amp;gt;"]
        n8["Resource Patch&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;resources/*resources.txt&amp;lt;/small&amp;gt;"]
  end
 subgraph s2["Vanadium"]
        n9["Generic Patches&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;patches/*.patch&amp;lt;/small&amp;gt;"]
  end
 subgraph s3["Helium Browser for Android"]
        n11["GN Build Configuration&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;args.gn&amp;lt;/small&amp;gt;"]
        n12["Signed Release"]
  end
    n1["Chromium"] --&amp;gt; s1 &amp;amp; s2
    n5 --&amp;gt; n6
    n6 --&amp;gt; n7
    n7 --&amp;gt; n8
    s1 --&amp;gt; s3
    s2 --&amp;gt; s3
    n11 --&amp;gt; n12
    n5@{ shape: subproc}
    n6@{ shape: subproc}
    n7@{ shape: subproc}
    n8@{ shape: subproc}
    n9@{ shape: subproc}
    n11@{ shape: subproc}
    n12@{ shape: subproc}
    n1@{ shape: rounded}
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    style n5 stroke:#FF6D00
    style n8 stroke:#FF6D00
&lt;/code&gt;
    &lt;p&gt;The full build aims to be consistent with Helium, which means additional patches are necessary before all features can be ported over. All Vanadium patches are applied by default. Further patches are underway.&lt;/p&gt;
    &lt;p&gt;This repository provides the build script to compile on the latest Ubuntu, and may also work with other Linux distributions.&lt;/p&gt;
    &lt;p&gt;To build these releases yourself via CI (e.g. GitHub Actions), fork this repository. Supply your &lt;code&gt;base64&lt;/code&gt; encoded &lt;code&gt;keystore.jks&lt;/code&gt; and &lt;code&gt;local.properties&lt;/code&gt; (containing your &lt;code&gt;keyAlias&lt;/code&gt;, &lt;code&gt;keyPassword&lt;/code&gt; and &lt;code&gt;storePassword&lt;/code&gt;) to Repository secrets under Settings &amp;gt; Secrets and variables &amp;gt; Actions. To generate a release, go to Actions, select Build, and select Run workflow. Under Runner, you can either use a GitHub-hosted runner by entering &lt;code&gt;ubuntu-latest&lt;/code&gt;, or &lt;code&gt;self-hosted&lt;/code&gt; for your own hardware.&lt;/p&gt;
    &lt;p&gt;This project would not have been possible without the huge community contributions from Helium, Vanadium, as well as ungoogled-chromium and various other upstream projects.&lt;/p&gt;
    &lt;p&gt;All credit goes to the original authors and contributors. This project is named to reflect support for Helium's naming in a recent controversy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715752</guid><pubDate>Sun, 26 Oct 2025 22:41:02 +0000</pubDate></item><item><title>AI Mafia Network ‚Äì An interactive visualization</title><link>https://dipakwani.com/ai-mafia/</link><description>&lt;doc fingerprint="139ed6ab9a87ef0"&gt;
  &lt;main&gt;
    &lt;p&gt;An interactive visualization ‚Äî based on the Acquired Google Podcast Credits to Ben and David.&lt;/p&gt;
    &lt;p&gt;Click on any node to explore connections. Drag to pan, scroll to zoom.&lt;/p&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è by @dpwxni&lt;/p&gt;
    &lt;p&gt;Also: Try my F1 Racing Game üèéÔ∏è&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715819</guid><pubDate>Sun, 26 Oct 2025 22:54:23 +0000</pubDate></item><item><title>Microsoft 365 Copilot ‚Äì Arbitrary Data Exfiltration via Mermaid Diagrams</title><link>https://www.adamlogue.com/microsoft-365-copilot-arbitrary-data-exfiltration-via-mermaid-diagrams-fixed/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715837</guid><pubDate>Sun, 26 Oct 2025 22:58:31 +0000</pubDate></item><item><title>Are-we-fast-yet implementations in Oberon, C++, C, Pascal, Micron and Luon</title><link>https://github.com/rochus-keller/Are-we-fast-yet</link><description>&lt;doc fingerprint="12da93cf4494b8a7"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository includes additional implementations of the Are-we-fast-yet benchmark suite.&lt;/p&gt;
    &lt;p&gt;See here for the main repository of the Are-we-fast-yet suite: https://github.com/smarr/are-we-fast-yet. See also the ORIGINAL_README.md file in this repository.&lt;/p&gt;
    &lt;p&gt;Each additional implementation is in a separate subdirectory (e.g. "Cpp", "Oberon", "FreePascal"); see there for more information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715873</guid><pubDate>Sun, 26 Oct 2025 23:08:09 +0000</pubDate></item></channel></rss>