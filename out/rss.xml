<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 07 Nov 2025 03:29:29 +0000</lastBuildDate><item><title>Show HN: qqqa ‚Äì A fast, stateless LLM-powered assistant for your shell</title><link>https://github.com/matisojka/qqqa</link><description>&lt;doc fingerprint="41fc851218d5aa1"&gt;
  &lt;main&gt;
    &lt;p&gt;Fast, stateless LLM-powered assistant for your shell: qq answers; qa runs commands&lt;/p&gt;
    &lt;p&gt;qqqa is a two-in-one, stateless CLI tool that brings LLM assistance to the command line without ceremony.&lt;/p&gt;
    &lt;p&gt;The two binaries are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;qq&lt;/code&gt;- ask a single question, e.g. "qq how can I recursively list all files in this directory" (qq stands for "quick question")&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;qa&lt;/code&gt;- a single step agent that can optionally use tools to finish a task: read a file, write a file, or execute a command with confirmation (qa stands for "quick agent")&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default the repo includes profiles for OpenAI and Groq.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;qq means quick question. qa means quick agent. Both are easy to type rapidly on QWERTY keyboards with minimal finger movement. That makes interacting with LLMs faster and more natural during real work.&lt;/p&gt;
    &lt;p&gt;qqqa is deliberately stateless. There is no long running session and no hidden conversation memory stored by the tool. Every run is mostly independent and reproducible. For maintaining a lowkey continuity you can use &lt;code&gt;"include_history": true&lt;/code&gt; in the &lt;code&gt;config.json&lt;/code&gt; (or choose to use history during the &lt;code&gt;qq --init&lt;/code&gt; process).&lt;/p&gt;
    &lt;p&gt;Why stateless is great:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple and focused - Unix philosophy applied to LLM tools.&lt;/item&gt;
      &lt;item&gt;Shell friendly - compose with pipes and files instead of interactive chats.&lt;/item&gt;
      &lt;item&gt;Safe by default - qq is read-only and has access to no tools. qa is built with security in mind and requires confirmation before running tools.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tools may include transient context you choose to provide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;qq&lt;/code&gt;can include the last few terminal commands as hints and piped stdin if present.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;qa&lt;/code&gt;can read files or run a specific command, but only once per invocation and with safety checks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For fast feedback loops, speed and cost matter. The included &lt;code&gt;groq&lt;/code&gt; profile targets Groq's OpenAI compatible API and the model &lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;. We recommend Groq for really fast inference speed at roughly 1000 tokens per second and at a low price point compared to many alternatives. Set &lt;code&gt;GROQ_API_KEY&lt;/code&gt; and you are ready to go.&lt;/p&gt;
    &lt;p&gt;You can still use OpenAI or any other OpenAI compatible provider by adding a provider entry and a profile in &lt;code&gt;~/.qq/config.json&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI compatible API client with streaming and non streaming calls.&lt;/item&gt;
      &lt;item&gt;Stateless, single shot workflow that plays well with pipes and scripts.&lt;/item&gt;
      &lt;item&gt;Rich but simple formatting using XML like tags rendered to ANSI colors.&lt;/item&gt;
      &lt;item&gt;Config driven providers and profiles with per profile model overrides.&lt;/item&gt;
      &lt;item&gt;Safety rails for file access and command execution.&lt;/item&gt;
      &lt;item&gt;Old-school and SERIOUS? Optional no-emoji mode persisted via &lt;code&gt;--no-fun&lt;/code&gt;ü•∏&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the Homebrew tap:&lt;/p&gt;
    &lt;code&gt;brew tap iagooar/qqqa
brew install qqqa&lt;/code&gt;
    &lt;p&gt;Download a prebuilt archive from the GitHub Releases page, extract it, and place &lt;code&gt;qq&lt;/code&gt;/&lt;code&gt;qa&lt;/code&gt; somewhere on your &lt;code&gt;PATH&lt;/code&gt; (e.g., &lt;code&gt;/usr/local/bin&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;On first run qqqa creates &lt;code&gt;~/.qq/config.json&lt;/code&gt; with safe permissions. For a smooth first interaction, run the init flow:&lt;/p&gt;
    &lt;code&gt;# Interactive setup (choose provider and set key)
qq --init
# or
qa --init&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;~/.qq/config.json&lt;/code&gt; already exists, the init command keeps it untouched and explains how to rerun after moving or deleting the file.&lt;/p&gt;
    &lt;p&gt;The initializer lets you choose the default provider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Groq + &lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;(faster, cheaper)&lt;/item&gt;
      &lt;item&gt;OpenAI + &lt;code&gt;gpt-5-mini&lt;/code&gt;(slower, a bit smarter)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It also offers to store an API key in the config (optional). If you prefer environment variables, leave it blank and set one of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;for Groq&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;for OpenAI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Defaults written to &lt;code&gt;~/.qq/config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Providers &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;openai&lt;/code&gt;‚Üí base&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;, env&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;groq&lt;/code&gt;‚Üí base&lt;code&gt;https://api.groq.com/openai/v1&lt;/code&gt;, env&lt;code&gt;GROQ_API_KEY&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Profiles &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;openai&lt;/code&gt;‚Üí model&lt;code&gt;gpt-5-mini&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;groq&lt;/code&gt;‚Üí model&lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;(default)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Optional per-profile &lt;code&gt;reasoning_effort&lt;/code&gt;for GPT-5 family models. If you leave it unset, qqqa sends&lt;code&gt;"reasoning_effort": "minimal"&lt;/code&gt;for any&lt;code&gt;gpt-5*&lt;/code&gt;model to keep responses fast. Set it to&lt;code&gt;"low"&lt;/code&gt;,&lt;code&gt;"medium"&lt;/code&gt;, or&lt;code&gt;"high"&lt;/code&gt;when you want deeper reasoning.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example override in &lt;code&gt;~/.qq/config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "profiles": {
    "openai": {
      "model_provider": "openai",
      "model": "gpt-5-mini",
      "reasoning_effort": "medium"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optional flag: &lt;code&gt;no_emoji&lt;/code&gt;(unset by default). Set via&lt;code&gt;qq --no-fun&lt;/code&gt;or&lt;code&gt;qa --no-fun&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Terminal history is off by default. During &lt;code&gt;qq --init&lt;/code&gt; / &lt;code&gt;qa --init&lt;/code&gt; you can opt in to sending the last 10 &lt;code&gt;qq&lt;/code&gt;/&lt;code&gt;qa&lt;/code&gt; commands along with each request. You can still override per run with &lt;code&gt;--history&lt;/code&gt; (force on) or &lt;code&gt;-n/--no-history&lt;/code&gt; (force off). Only commands whose first token is &lt;code&gt;qq&lt;/code&gt; or &lt;code&gt;qa&lt;/code&gt; are ever shared.&lt;/p&gt;
    &lt;p&gt;You can still override at runtime:&lt;/p&gt;
    &lt;code&gt;# choose profile
qq -p groq "what is ripgrep"

# override model for a single call
qq -m openai/gpt-oss-20b "explain this awk one-liner"&lt;/code&gt;
    &lt;code&gt;# simplest
qq "convert mp4 to mp3"

# stream tokens with formatted output
qq -s "how do I kill a process by name on macOS"

# include piped context
git status | qq "summarize what I should do next"

# pipe extra context and keep CLI question
printf '%s\n' "This is a sample context. My code is 4242" | qq "What is my code"

# pipe the question itself
printf '%s\n' "Show me the full contents of this directory" | qq

# raw text (no ANSI formatting)
qq -r "explain sed vs awk"

# include terminal history for this run
qq --history "find large files in the last day"

# disable emojis in responses (persists)
qq --no-fun "summarize this"&lt;/code&gt;
    &lt;p&gt;Note: it is possible to run qq without quotes, which works most of the time the same way as with quotes.&lt;/p&gt;
    &lt;code&gt;# simplest
qq convert mp4 to mp3&lt;/code&gt;
    &lt;p&gt;You want to extract audio from a YouTube video but you do not remember the exact flags.&lt;/p&gt;
    &lt;p&gt;Ask with qq:&lt;/p&gt;
    &lt;code&gt;qq "how do I use ffmpeg to extract audio from a YouTube video into mp3"&lt;/code&gt;
    &lt;p&gt;A typical answer will suggest installing the tools and then using &lt;code&gt;yt-dlp&lt;/code&gt; to fetch audio and &lt;code&gt;ffmpeg&lt;/code&gt; to convert it:&lt;/p&gt;
    &lt;code&gt;# macOS
brew install yt-dlp ffmpeg

# Debian or Ubuntu
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y yt-dlp ffmpeg

# Download and extract audio to MP3 using ffmpeg under the hood
yt-dlp -x --audio-format mp3 "https://www.youtube.com/watch?v=VIDEO_ID"&lt;/code&gt;
    &lt;p&gt;Do it for me with qa:&lt;/p&gt;
    &lt;code&gt;qa "download audio as mp3 from https://www.youtube.com/watch?v=VIDEO_ID"&lt;/code&gt;
    &lt;p&gt;The agent will propose a safe command like &lt;code&gt;yt-dlp -x --audio-format mp3 URL&lt;/code&gt;, show it for confirmation, then run it. You can pass &lt;code&gt;-y&lt;/code&gt; to auto approve.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;qa&lt;/code&gt; can either answer in plain text or request one tool call in JSON. Supported tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;read_file&lt;/code&gt;with&lt;code&gt;{ "path": string }&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;write_file&lt;/code&gt;with&lt;code&gt;{ "path": string, "content": string }&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;execute_command&lt;/code&gt;with&lt;code&gt;{ "command": string, "cwd?": string }&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;# read a file the safe way
qa "read src/bin/qq.rs and tell me what main does"

# write a file
qa "create a README snippet at notes/intro.md with a short summary"

# run a command with confirmation
qa "list Rust files under src sorted by size"

# pipe the task itself
printf '%s\n' "Show me the full contents of this directory" | qa

# auto approve tool execution for non interactive scripts
qa -y "count lines across *.rs"

# include recent qq/qa commands just for this run
qa --history "trace which git commands I ran recently"

# disable emojis in responses (persists)
qa --no-fun "format and lint the repo"&lt;/code&gt;
    &lt;p&gt;When qa runs a command while stdout is a terminal, output now streams live; the structured &lt;code&gt;[tool:execute_command]&lt;/code&gt; summary still prints afterward for easy copying.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;execute_command&lt;/code&gt; prints the proposed command and asks for confirmation. It warns if the working directory is outside your home. Use &lt;code&gt;-y&lt;/code&gt; to auto approve in trusted workflows.&lt;/p&gt;
    &lt;p&gt;The runner enforces a default allowlist (think &lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;find&lt;/code&gt;, &lt;code&gt;rg&lt;/code&gt;, &lt;code&gt;awk&lt;/code&gt;, etc.) and rejects pipelines, redirection, and other high-risk constructs. When a command is blocked, &lt;code&gt;qa&lt;/code&gt; prompts you to add it to &lt;code&gt;command_allowlist&lt;/code&gt; inside &lt;code&gt;~/.qq/config.json&lt;/code&gt;; approving once persists the choice and updates future runs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;File tools require paths to be inside your home or the current directory. Reads are capped to 1 MiB, and traversal/symlink escapes are blocked.&lt;/item&gt;
      &lt;item&gt;Command execution uses a default allowlist (e.g. &lt;code&gt;ls&lt;/code&gt;,&lt;code&gt;grep&lt;/code&gt;,&lt;code&gt;rg&lt;/code&gt;,&lt;code&gt;find&lt;/code&gt;) plus your custom&lt;code&gt;command_allowlist&lt;/code&gt;entries. Destructive patterns (&lt;code&gt;rm -rf /&lt;/code&gt;,&lt;code&gt;sudo&lt;/code&gt;,&lt;code&gt;mkfs&lt;/code&gt;, etc.) are always blocked, and pipelines/redirection/newlines prompt for confirmation even with&lt;code&gt;--yes&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Commands run with a 120 s timeout and the agent performs at most one tool step‚Äîthere is no loop.&lt;/item&gt;
      &lt;item&gt;Config files are created with safe permissions. API keys come from environment variables unless you explicitly add a key to the config.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;for the Groq provider&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;for the OpenAI provider&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Project layout:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/bin/qq.rs&lt;/code&gt;and&lt;code&gt;src/bin/qa.rs&lt;/code&gt;entry points&lt;/item&gt;
      &lt;item&gt;Core modules in &lt;code&gt;src/&lt;/code&gt;:&lt;code&gt;ai.rs&lt;/code&gt;,&lt;code&gt;config.rs&lt;/code&gt;,&lt;code&gt;prompt.rs&lt;/code&gt;,&lt;code&gt;history.rs&lt;/code&gt;,&lt;code&gt;perms.rs&lt;/code&gt;,&lt;code&gt;formatting.rs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Tools in &lt;code&gt;src/tools/&lt;/code&gt;:&lt;code&gt;read_file.rs&lt;/code&gt;,&lt;code&gt;write_file.rs&lt;/code&gt;,&lt;code&gt;execute_command.rs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Integration tests in &lt;code&gt;tests/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See CONTRIBUTING.md for guidelines on reporting issues and opening pull requests, building from source, and the release process.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API error about missing key: run &lt;code&gt;qq --init&lt;/code&gt;to set things up, or export the relevant env var, e.g.&lt;code&gt;export GROQ_API_KEY=...&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;No output when streaming: try &lt;code&gt;-d&lt;/code&gt;to see debug logs.&lt;/item&gt;
      &lt;item&gt;Piped input not detected: ensure you are piping into &lt;code&gt;qq&lt;/code&gt;and not running it in a subshell that swallows stdin.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Licensed under MIT.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45833811</guid><pubDate>Thu, 06 Nov 2025 10:59:42 +0000</pubDate></item><item><title>Eating stinging nettles</title><link>https://rachel.blog/2018/04/29/eating-stinging-nettles/</link><description>&lt;doc fingerprint="3730f7cb74e1c58"&gt;
  &lt;main&gt;
    &lt;p&gt;Spring is here and the nettles are growing again so I decided it was time to make a meal out of them. Most people know that stinging nettles are pesky green plants that irritate the skin when you touch them. What you probably don‚Äôt know is that they‚Äôre a nutritious source of iron, calcium, potassium, and silica as well as vitamins A, B, C, and K1. Stinging nettles also have anti-inflammatory properties and can relieve arthritis and rheumatism. They can be turned into soups, curries, and risottos (some recipes here) and you can get them completely free from practically everywhere in Britain over the summer. You‚Äôve likely even got some in your garden.&lt;/p&gt;
    &lt;p&gt;When you collect them you need to wear gloves because they sting. The advantage of this is it allows you to make sure you‚Äôre collecting the right thing. If you‚Äôre unsure, just touch one and see whether it hurts which is exactly what I did. It hurt.&lt;/p&gt;
    &lt;p&gt;The even look a bit scary with their toothy-edged leaves.&lt;/p&gt;
    &lt;p&gt;Once you‚Äôve got them inside, boil them in water for a few minutes and this will stop them stinging.&lt;/p&gt;
    &lt;p&gt;We‚Äôre having stinging nettle risotto.&lt;/p&gt;
    &lt;p&gt;People think that when you become vegan you have to give up lots of food. It‚Äôs true that I stopped eating animals but the number of different species I eat has grown considerably. This is because meat-eaters tend to eat the same few species of animals over and over again ‚Äì pigs, cows, chickens. Whereas there are some 20,000 species of edible plants in the world. Meat also tends to fill you up. Indeed I‚Äôve been to dinner with people where all they have on their plate is a slab of meat and nothing else. Whereas as a vegan (with the exception of a shitty Spanish restaurant that served me a plate of artichokes and nothing else) I eat a huge variety of species. Meat-eaters can eat these too but they often don‚Äôt because meat is so filling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45834254</guid><pubDate>Thu, 06 Nov 2025 11:57:01 +0000</pubDate></item><item><title>I analyzed the lineups at the most popular nightclubs</title><link>https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/</link><description>&lt;doc fingerprint="3603417d793229b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I analyzed the lineups at the world's most popular nightclubs&lt;/head&gt;
    &lt;p&gt;A few years back I did a bit of dance music related data visualization over at Lazily Evaluated. My favourite was an analysis of clubs and their lineups using Resident Advisor / RA data, I called it Clubster Analysis. I always wanted to dig into the technical aspects of gathering the data, analyzing it and building the charts and graphs to tell a story and give people insight. With this blog I now have the right venue for that kind of tech talk, so here goes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data gathering #&lt;/head&gt;
    &lt;p&gt;To visualize data, first you have to get some! For this purpose I wrote a little scraper in Python. I used Beautiful Soup to parse the html and grab the bits and pieces I was interested in.&lt;/p&gt;
    &lt;p&gt;My scraping of a few thousand pages didn‚Äôt cause considerable load on the RA servers. But in the age of overzealous AI scrapers it‚Äôs worth being polite, so I throttled according to their robots.txt. I also maintained a local cache of html files I had already downloaded, so that I wouldn‚Äôt have fetch the same data repeatedly (past lineups are unlikely to change after the fact) just because I discovered some bug or error in my parsing.&lt;/p&gt;
    &lt;p&gt;The order I scraped in was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Get the 20 most popular regions in RA (and then I dropped ‚ÄúStreamland‚Äù which was a pandemic era pseudo-region)&lt;/item&gt;
      &lt;item&gt;Fetch the most popular clubs and some related metadata for all of those regions.&lt;/item&gt;
      &lt;item&gt;For each club, get the lineups for every 2019 event of theirs (the last full year before the pandemic started).&lt;/item&gt;
      &lt;item&gt;Save the results to csv files&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Clean up, verification and Analysis #&lt;/head&gt;
    &lt;p&gt;I did some spot checks to verify that my parsing was working as I expected and added tests to make sure I handled edge cases and normalized artist names. There was a lot of variance in how dates were formatted, how artists were linked, etc.&lt;/p&gt;
    &lt;p&gt;After that I analyzed the data. I built one big table/dataframe in Pandas by joining all the info from the csv files. Then I calculated the similarities between each pair of clubs in the data set using the Jaccard index. Consider all the artists that have played at two given clubs, take the intersection (number of artists that have featured in lineups at both clubs) over the union (all the artists that have performed at one or the other). As an example if Club A had 100 artists booked and Club B had 100 artists, and they had 10 bookings in common, the Jaccard index would be 10/190 = ~5%. This gives you a good way to compare large and small clubs and balances large and small lineups (some of the clubs have multiple rooms with very long events, others have one dj playing in one room all night long once a week).&lt;/p&gt;
    &lt;p&gt;Based on the Jaccard index we can build a graph, using NetworkX from all the clubs. The edges between two nodes are weighted by the similarity of those clubs. On top of the graph we run community detection to create clusters (hence the clubster name). This gives us a rough idea of which clubs are most similar, that is to say, have similar tastes in their bookings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results #&lt;/head&gt;
    &lt;p&gt;For the year 2019, there were 131 clubs in the data set with 8.502 events. There were 9.405 unique artists making up 30.482 individual bookings. This means that the average artist in the dataset was booked 3.24 times at those clubs in that year and the average event had 3.5 artists on the line up.&lt;/p&gt;
    &lt;p&gt;As a whole, out of 8.515 possible pairs of clubs, 3.716 pairs had some overlap in their bookings and out of those the average overlap was 1%. This was lower than I thought, the bookings at European clubs felt more homogenous to me, but I suppose they book a lot of artists. It would be interesting to get more data, recent and historic, and see how this has evolved through time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Visualization #&lt;/head&gt;
    &lt;p&gt;This was my first time using D3 to draw charts. There was a bit of a learning curve, in earlier projects I had used higher level charting libraries which have simpler apis. But with D3 you get a lot of control over how your charts look and behave which I think I used to good effect in this instance.&lt;/p&gt;
    &lt;p&gt;My main goal was to visualize the clusters and to allow people to interact with the clubs. I coloured the clubs according to their clusters and sized them based on the number of followers they had on RA. I played around with the gravity and placement of the cluster, trying to find a balance that worked on different screen sizes as well as being a fair portrayal of the different communities.&lt;/p&gt;
    &lt;p&gt;I then did some scrollytelling to tell the story of the data, as I saw it, while the reader scrolls down the page. But I also added filters and interactivity for people to explore and see if they agree with my telling of the story or if they can find one of their own.&lt;/p&gt;
    &lt;p&gt;At the time I didn‚Äôt find any great React and D3 bridges, so it was a bit of a hassle getting the React components to play nice with the D3 graph, but in the end I was able to connect the two with &lt;code&gt;createRef&lt;/code&gt; to the D3 svg component.&lt;/p&gt;
    &lt;p&gt;Besides the clustering I looked into the ‚Äúresident factor‚Äù, how many times an artist was booked at a club repeatedly compared to all the one offs. This was lower than expected, most of these clubs were booking a constantly rotating assembly of talent, residents don‚Äôt play as big a part as I would have thought.&lt;/p&gt;
    &lt;p&gt;Transitioning between the different sections of these graphs was one of my favourite parts. Seeing the clusters morph into dots and candlestick charts (and back again) was oddly satisfying. Took a lot of tweaking, but I think it really tied together the scrollytelling experience.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think these transitions would have been possible with the higher level charting libraries I‚Äôd used previously. So the decision to go with D3 felt justified.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary #&lt;/head&gt;
    &lt;p&gt;This was a great pandemic project that combined web scraping, data analysis, and interactive visualization to explore the global dance music club scene. I learned me some D3 for the visualization, got better at doing cartesian graphing calculations in my head and learned about the underlying svg mechanics that power those graphs.&lt;/p&gt;
    &lt;p&gt;The results surprised me: despite my perceived homogeneity of European club bookings, only 1% average overlap between venues suggested more diverse landscape than I expected. The diminished role of residents compared to one-off bookings also challenged my assumptions about how these clubs operate. For the story telling maintaining the balance between a narrative and letting users explore and decide for themselves was a fun challenge. I think these sort of passion projects can give us deep insights into our world and culture.&lt;/p&gt;
    &lt;p&gt;The technical stack I worked with: Python, Pandas, NetworkX, D3, and React proved powerful despite some integration challenges. The complete project is available on GitHub and you can explore the live interactive visualization yourself.&lt;/p&gt;
    &lt;p&gt;I had a lot of fun building this and am proud of the result. If you‚Äôre working on cultural data analysis, need help with web scraping and visualization, or just want to discuss interesting datasets, feel free to reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45835083</guid><pubDate>Thu, 06 Nov 2025 13:37:07 +0000</pubDate></item><item><title>Auraphone: A simple app to collect people's info at events</title><link>https://andrewarrow.dev/2025/11/simple-app-collect-peoples-info-at-events/</link><description>&lt;doc fingerprint="f779845eca070a9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;auraphone: a simple app to collect people's info at events&lt;/head&gt;
    &lt;p&gt;Hi, I'm Andrew, and I'm building Auraphone, a simple app to collect people's info at events.&lt;/p&gt;
    &lt;p&gt;I've been a developer for many years and I thought I knew bluetooth well. I was an early employee of the scooter company Bird back in 2017 and wrote a lot of the ios and android bluetooth to "bird brain" logic. But I started a new bluetooth app that is a lot more complex. Imagine a room full of people at a big networking event. Every phone broadcasts a bluetooth service and every phone tries and connects, all at the same time! I'm building this app to bring networking events into the year 2026! We all have bluetooth phones with us, lets use them to solve this who is going to give who their phone number issue. Here is what it does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You set your name, photo, and what info you want to share. Maybe just your instagram username, maybe your email and linked in too, your choice what to broadcast.&lt;/item&gt;
      &lt;item&gt;Walk around your networking event and collect all this info from people you are in close range to.&lt;/item&gt;
      &lt;item&gt;Have a record of everyone you actually meet IRL at this event.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Here is a video demo:&lt;/head&gt;
    &lt;p&gt;Think of the term "peripheral" as server and "central" as client. Yes there are differences in bluetooth and there are reasons for those terms, but my life got much easier working on this app when I started just thinking client server. So in a room with just two phones, which one is which? It can't be a coin toss. If 50% of the time both phones act as the server and neither client, bad. Or if both phones act as clients, bad. So how do you break the tie? You start up your server AND you act as a client looking for servers to connect to. Just be careful not to connect to yourself!&lt;/p&gt;
    &lt;p&gt;With bluetooth your server advertises and when you connect it tells you what characteristics it has. Think of characteristics as "endpoints". They are not the same as an http endpoints at all but again my life got easier when I started thinking of them like this. Our app has two characteristics PROFILE_CHAR and PHOTO_CHAR and step one is a client hits PROFILE_CHAR endpoint and gets back json from the other phone with device_id, first_name, photo_hash, instagram and it doesn't have to be json. It could be Protocol Buffers and binary but again, I went with json and yes, easier life.&lt;/p&gt;
    &lt;p&gt;So with my 200 OK from PROFILE_CHAR endpoint I look at the photo_hash which is a 256 sha from the binary data of the image the user picked. If I have this file already cached, I'm good and I disconnect from this server. If not I hit the PHOTO_CHAR endpoint and get this image data and save as hash.jpg locally. And then I disconnect.&lt;/p&gt;
    &lt;p&gt;After I disconnect from a server I place that specific bluetooth server id on a cooldown list. I have other phones in the room I need to connect with! And all this time I'm also acting as a server myself. Well, sometimes. Sometimes when I'm busy being a client getting a photo I'll pause my server actions. And it depends on ios vs android. There is lots of complexity in the BLE (bluetooth low energy) stack. This loop of find a server, connect, get my info, disconnect, repeat is a great little loop. But there are limits and GATT errors and queue buffers that get full and MTU (max transmission unit) that can make it so two phones right next to each other take a while before they finally find each other.&lt;/p&gt;
    &lt;p&gt;So I made github.com/andrewarrow/auraphone-blue which is a BLE stack simulator all written in golang. If you look at the wire package you'll see a pretty complete BLE implementation using the file system and domain sockets to mock the bluetooth radio. The swift package and kotlin package should look very familiar to anyone who has worked on ios or android BLE.&lt;/p&gt;
    &lt;p&gt;My plan was to run many mock phones this way and test all the weird BLE differences between ios and android here. It did not work. The only thing this golang auraphone-blue repo did for me was really help me understand how bluetooth works. This BLE stack that I made in golang doesn't help me fix ios and android bugs, it only introduces its own subtle golang filesystem ble bugs!&lt;/p&gt;
    &lt;p&gt;In the end nothing fixed all the bugs better than just running two real ios phones and two real android phones and having them write to disk very thorough logs PLUS ble specific json files showing exactly what each operation was doing and what info it got back. I ended up writing logic to zip up the entire local directory of the phone with all these files and logs and doing an HTTP POST to my local mac just to get all the data off all 4 phones quickly after each run.&lt;/p&gt;
    &lt;p&gt;Now it's not like this app will keep running when you have your phone in your pocket. iOS has rules on bluetooth connections and it's basically only if your app is running and foreground. So the way I see auraphone working at an event, you walk around and mingle as normal but yeah every one has their phone out and running the app but ONLY this app. You are still present and in the conversation not just looking at other distractions from your phone.&lt;/p&gt;
    &lt;p&gt;But now effortlessly after your conversation is done and you move around the room, you have a record of who that person was! Also the list is sorted by last updated_at desc so whoever you are near will be at the top. Great for when you have met someone earlier that night but forget their name. Now you just look down at your auraphone app that's already out and running and say oh hey jessie!&lt;/p&gt;
    &lt;p&gt;The app is in the ios app store. For android we serve up the apk at auraphone.apk. We are testing it now at BLANKSPACES Culver City. Looking to try it now in a room full of people! Give me reports of did your phones see each other? Did the contact info sync? Did it solve a problem for you?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45835931</guid><pubDate>Thu, 06 Nov 2025 14:54:16 +0000</pubDate></item><item><title>Kimi K2 Thinking, a SOTA open-source trillion-parameter reasoning model</title><link>https://moonshotai.github.io/Kimi-K2/thinking.html</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836070</guid><pubDate>Thu, 06 Nov 2025 15:06:06 +0000</pubDate></item><item><title>FBI tries to unmask owner of archive.is</title><link>https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html</link><description>&lt;doc fingerprint="3f820317679167cd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Archive.today: FBI Demands Data from Provider Tucows&lt;/head&gt;
    &lt;p&gt;The mysterious website Archive.today is coming under the FBI's crosshairs. A court order is forcing the provider Tucows to hand over user data.&lt;/p&gt;
    &lt;p&gt;It is one of the most mysterious and, at the same time, best-known websites on the internet. Archive.today has built up a user base over a period of more than ten years who use the service to access previous snapshots of a web page. So basically like the Wayback Machine of the Internet Archive, only largely free of rules and presumably therefore also anonymous. To the chagrin of the media industry, the service is also often used to bypass paywalls. This is also possible because the service does not adhere to common rules and laws and offers no opt-out option.&lt;/p&gt;
    &lt;p&gt;And so far, the operators have gotten away with it. Although there have been minor problems in the history of the service occasionally, for example, a top-level domain operator denied them further use of one of the many archive domains. However, the operation of the project, which is allegedly financed by donations and own funds, was not seriously endangered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Court Order in the USA&lt;/head&gt;
    &lt;p&gt;But now the operators of archive.today are apparently fearing bigger trouble. In recent months and years, they had become noticeably quieter. Until two years ago, for example, questions were regularly answered in the blog. In the official X account, which had been silent for over a year, a new post appeared at the end of October new post. ‚ÄúCanary,‚Äù it said there, along with a URL. The mentioned canary bird is likely an allusion to an old custom in mining. A canary brought along warned the miners when it keeled over dead about the threat of invisible gas.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;p&gt;The deadly danger that the site operators fear is apparently linked to the PDF linked in the X post linked PDF. It contains a court order that the US investigative authority FBI has obtained. It instructs the Canadian provider Tucows to hand over comprehensive data about the customer behind archive.today. It concerns address and connection data as well as payment information. If Tucows does not provide the data, penalties are threatened. Whether the court order is genuine and how the operators of the site obtained it could not be verified so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is the operator based in Russia?&lt;/head&gt;
    &lt;p&gt;Why the FBI is currently interested in archive.today, which is also accessible under the domains archive.is and archive.ph, is not evident from the court order. However, there are several obvious starting points for investigations: in addition to the obvious reason of copyright issues, the investigators could also be pursuing suspicions about unclear financing, the origin of the operators, or the technical approach.&lt;/p&gt;
    &lt;p&gt;In 2023, Finnish blogger Janni Patokallio compiled various clues and research results in a post in a post. According to this, Archive.today uses a botnet with changing IP addresses to circumvent anti-scraping measures. There are also indications that the operator(s) are based in Russia. Another private investigation from 2024 comes to a different conclusion. It names a software developer from New York as the alleged operator. According to this investigation, following the trail to Eastern Europe proved to be a red herring.&lt;/p&gt;
    &lt;p&gt;(mki)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836826</guid><pubDate>Thu, 06 Nov 2025 16:18:18 +0000</pubDate></item><item><title>ICC ditches Microsoft 365 for openDesk</title><link>https://www.binnenlandsbestuur.nl/digitaal/internationaal-strafhof-neemt-afscheid-van-microsoft-365</link><description>&lt;doc fingerprint="edbd58ff46c91d73"&gt;
  &lt;main&gt;
    &lt;p&gt;Het Internationaal Strafhof (International Criminal Court, ICC) ruilt Microsoft 365 in voor Open Desk, een Europees open source alternatief. Dat schrijft de Duitse krant Handelsblatt. De krant verwacht dat het ICC met de overstap mogelijk een trend start binnen de Europese publieke sector.&lt;/p&gt;
    &lt;head rend="h1"&gt;Internationaal Strafhof neemt afscheid van Microsoft 365&lt;/head&gt;
    &lt;p&gt;Het ICC stapt over naar Open Desk, een Europese opensource kantooromgeving&lt;/p&gt;
    &lt;p&gt;Microsoft bevestigt de breuk aan de nieuwssite Euractiv. ‚ÄòWij hechten waarde aan onze relatie met het ICC als klant en zijn ervan overtuigd dat niets ons vermogen in de weg staat om in de toekomst diensten aan het ICC te blijven leveren,‚Äô zegt een woordvoerder van Microsoft.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digitale afhankelijkheid&lt;/head&gt;
    &lt;p&gt;Bij Europese overheden leven al langer zorgen over de digitale afhankelijkheid van Amerikaanse bedrijven. Die zorgen zijn sterk toegenomen sinds Donald Trump voor de tweede maal president van de Verenigde Staten werd.&lt;/p&gt;
    &lt;p&gt;Voor het ICC zijn de zorgen minder hypothetisch dan voor veel andere instituten: Trump heeft zijn ongenoegen met het Strafhof vaak laten blijken en liet sancties opstellen tegen de hoofdaanklager, Karim Khan. Persbureau AP meldde in mei 2025 dat Khan geen toegang meer had tot zijn Outlook e-mail. Microsoft bevestigde dat Khan was ‚Äòlosgekoppeld‚Äô van Microsoft-diensten, maar benadrukte tegelijkertijd dat het de dienstverlening aan de ICC-organisatie ‚Äògeen moment‚Äô heeft stopgezet.&lt;/p&gt;
    &lt;head rend="h2"&gt;EDIC&lt;/head&gt;
    &lt;p&gt;Hoe dan ook zit de angst er bij het ICC goed in. De organisatie gaat gebruikmaken van Open Desk, dat is ontwikkeld door het Zentrum Digitale Souver√§nit√§t (Zendis) in opdracht van het Duitse Federale ministerie van Binnenlandse Zaken. Zendis maakt onderdeel uit van het Digital Commons European Digital Infrastructure Consortium (DC-EDIC), het Europese consortium waarmee de EU strijdt voor meer digitale autonomie.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mijn bureau&lt;/head&gt;
    &lt;p&gt;Ook Nederlandse ambtenaren krijgen in de toekomst mogelijk te maken met de software van Open Desk. Onder de noemer Mijn Bureau experimenteert de Nederlandse overheid met een suite met verschillende Europese open source samenwerkingssoftware. Open Desk wordt binnen Mijn Bureau onder meer gebruikt voor e-mail. Mijn Bureau is een samenwerking van de Rijksoverheid, Gemeente Amsterdam en de VNG.&lt;/p&gt;
    &lt;p&gt;In een vandaag verschenen position paper pleit de VNG voor meer regie op technologie. Er wordt steeds meer toegewerkt naar verregaande samenwerking op het gebied van digitalisering. ln de Nederlandse Digitaliseringsstrategie (NDS) is het versterken van digitale weerbaarheid en autonomie √©√©n van de prioriteiten.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45837342</guid><pubDate>Thu, 06 Nov 2025 16:57:55 +0000</pubDate></item><item><title>The Parallel Search API</title><link>https://parallel.ai/blog/introducing-parallel-search</link><description>&lt;doc fingerprint="19437a9227bb0e96"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;# Introducing Parallel Search: the highest accuracy web search API engineered for AI&lt;/head&gt;
    &lt;p&gt;Web search, built from the ground up for AI&lt;/p&gt;
    &lt;p&gt;A second user has arrived on the web: AI. And it needs fundamentally different infrastructure than humans do.&lt;/p&gt;
    &lt;p&gt;The Parallel Search API, built on our proprietary web index, is now generally available. It's the only web search tool designed from the ground up for AI agents: engineered to deliver the most relevant, token-efficient web data at the lowest cost. The result is more accurate answers, fewer round-trips, and lower costs for every agent.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Human search and AI search solve different problems**&lt;/head&gt;
    &lt;p&gt;Traditional search engines were built for humans. They rank URLs, assuming someone will click through and navigate to a page. The search engine's job ends at the link. The system optimizes for keywords searches, click-through rates, and page layouts designed for browsing - done in milliseconds and as cheaply as possible.&lt;/p&gt;
    &lt;p&gt;The first wave of web search APIs used in AI-based search made this human search paradigm programmatically accessible, but failed to solve the underlying problem of how you design search for an AI agent‚Äôs needs.&lt;/p&gt;
    &lt;p&gt;AI search has to solve a different problem: **what tokens should go in an agent's context window to help it complete the task? We‚Äôre not ranking URLs for humans to click‚Äî we‚Äôre optimizing context and tokens for models to reason over.**&lt;/p&gt;
    &lt;p&gt;This requires a fundamentally different search architecture:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Semantic objectives** that capture intent beyond keyword matching, so agents can specify what they need to accomplish rather than guessing at search terms&lt;/item&gt;
      &lt;item&gt;- **Token-relevance ranking** to prioritize webpages most directly relevant to the objective, not pages optimized for human engagement metrics&lt;/item&gt;
      &lt;item&gt;- **Information-dense excerpts** compressed and prioritized for reasoning quality, so LLMs have the highest-signal tokens in their context window&lt;/item&gt;
      &lt;item&gt;- **Single-call resolution** for complex queries that normally require multiple search hops&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With this search architecture built from the ground up for AIs, agents get access to the most information-dense web tokens in their context. The result is fewer search calls, higher accuracy, lower cost, and lower end-to-end latency.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **On every benchmark that matters for real-world agent use cases, Parallel wins on accuracy**&lt;/head&gt;
    &lt;p&gt;While most existing search systems are optimized for straightforward question answering, we believe the demand for more complex, multifaceted search will only continue to grow. Users and agents alike will increasingly seek answers that require synthesizing information across multiple sources, reasoning over complex objectives, and navigating harder-to-access content on the web.&lt;/p&gt;
    &lt;p&gt;To reflect this shift, we evaluated the performance of Parallel‚Äôs Search API across a range of benchmarks, from the most challenging multi-hop tasks (e.g., BrowseComp) to simple single-hop queries (e.g., SimpleQA).&lt;/p&gt;
    &lt;head rend="h3"&gt;### For complex searches, Parallel is the highest accuracy at the lowest cost&lt;/head&gt;
    &lt;p&gt;Parallel‚Äôs performance advantage is dramatic on challenging queries ‚Äî those that span multiple topics, require deep comprehension of hard to crawl web content, or demand synthesis across scattered sources with multiple reasoning steps. On benchmarks specifically designed to test multi-hop reasoning (HLE, BrowseComp, WebWalker, FRAMES, Batched SimpleQA), Parallel not only achieves higher accuracy but also resolves queries through more efficient reasoning paths.&lt;/p&gt;
    &lt;p&gt;Traditional search APIs get less done in each pass. Agents perform too many sequential searches - compounding latency, inflating context windows, and increasing token costs with every iteration, and decreasing accuracy. Parallel, by contrast, can resolve more complex queries in a single call, resulting in the agent making fewer sequential calls and achieving higher accuracy, lower total cost, and lower end to end latency.&lt;/p&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://lastexam.ai/) consists of 2,500 questions developed by subject-matter experts across dozens of subjects (e.g. math, humanities, natural sciences). Each question has a known solution that is unambiguous and easily verifiable, but requires sophisticated web retrieval and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### HLE Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 82 | 47 | | Others | exa | 138 | 24 | | Others | tavily | 190 | 21 | | Others | perplexity | 126 | 30 | | Others | openai gpt-5 | 143 | 45 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://lastexam.ai/) consists of 2,500 questions developed by subject-matter experts across dozens of subjects (e.g. math, humanities, natural sciences). Each question has a known solution that is unambiguous and easily verifiable, but requires sophisticated web retrieval and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### BrowseComp Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 156 | 58 | | Others | exa | 233 | 29 | | Others | tavily | 314 | 23 | | Others | perplexity | 256 | 22 | | Others | openai gpt-5 | 253 | 53 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About the benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/browsecomp/), created by OpenAI, contains 1,266 questions requiring multi-hop reasoning, creative search formulation, and synthesis of contextual clues across time periods. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### WebWalker-Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 42 | 81 | | Others | exa | 107 | 48 | | Others | tavily | 156 | 79 | | Others | perplexity | 91 | 67 | | Others | openai gpt-5 | 88 | 73 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://arxiv.org/abs/2501.07572) is designed to assess the ability of LLMs to perform web traversal. To successfully answer the questions in the benchmark, it requires the ability to crawl and extract content from website subpages. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### FRAMES-Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 42 | 92 | | Others | exa | 81 | 81 | | Others | tavily | 122 | 87 | | Others | perplexity | 95 | 83 | | Others | openai gpt-5 | 68 | 90 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://huggingface.co/datasets/google/frames-benchmark) contains 824 challenging multi-hop questions designed to test factuality, retrieval accuracy, and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### Batched SimpleQA - Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 50 | 90 | | Others | exa | 119 | 71 | | Others | tavily | 227 | 59 | | Others | perplexity | 100 | 74 | | Others | openai gpt-5 | 91 | 88 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark was created by batching 3 independent questions from the original SimpleQA dataset[SimpleQA dataset]($https://openai.com/index/introducing-simpleqa/) to create 100 composite, more complex, questions.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Across these multi-hop benchmarks, agents using Parallel achieve state-of-the-art accuracy at ~50% of the cost, compared to workflows built on traditional search APIs.&lt;/p&gt;
    &lt;head rend="h3"&gt;### On simple searches, Parallel is the lowest cost with parity in accuracy&lt;/head&gt;
    &lt;p&gt;We also tested Parallel on single-hop benchmarks like SimpleQA that contain straightforward factual queries that benefit from web search. These benchmarks are saturated with limited room for further accuracy improvements.&lt;/p&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/introducing-simpleqa/), created by OpenAI, contains 4,326 questions focused on short, fact-seeking queries across a variety of domains. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### SimpleQA Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 17 | 98 | | Others | exa | 57 | 87 | | Others | tavily | 110 | 93 | | Others | perplexity | 52 | 92 | | Others | openai gpt-5 | 37 | 98 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/introducing-simpleqa/), created by OpenAI, contains 4,326 questions focused on short, fact-seeking queries across a variety of domains. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On SimpleQA, the Parallel Search API matches the accuracy of the leading alternative while delivering the lowest end-to-end cost per-query cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **These results are possible because we've built a proprietary web index and a vertically-integrated search stack from the ground up, designed for AIs**&lt;/head&gt;
    &lt;p&gt;We are able to achieve state-of-the-art results because we have spent the last two years building the infrastructure to innovate across the full search stack, enabling optimization at every layer and feedback loops that continuously improve performance.&lt;/p&gt;
    &lt;p&gt;**Crawl:** Infrastructure that prioritizes the hard-to-crawl content on the web that isn‚Äôt included in pretraining data for models: multi-modal, lengthy PDFs, JavaScript-heavy sites. And optimizes recrawls to keep fast-changing data fresh while minimizing burden on website owners.&lt;/p&gt;
    &lt;p&gt;**Index:** One of the fastest-growing, freshest, deepest, and largest web indexes with 1B+ pages added or refreshed daily.&lt;/p&gt;
    &lt;p&gt;**Ranking:** We retrieve and rank with a different optimization objective than traditional search. Instead of ranking URLs for humans to click on, we identify the most relevant and authoritative tokens suitable for LLM reasoning. Our proprietary models and algorithms score based on token relevance, page and domain authority, context window efficiency, and cross-source validation, rather than click-through probability or engagement.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Leading AI teams build on our Search API - and so do we**&lt;/head&gt;
    &lt;p&gt;Today, the most sophisticated builders choose to create and deploy AI, with search powered by Parallel. These companies have tested alternatives and understand that the decisions their agents make, whether it‚Äôs Sourcegraph Amp‚Äôs coding agent solving bugs, _Claygent_ powering every GTM decision, Starbridge discovering government RFPs, or a Fortune 100 insurer underwriting claims better than human underwriters, all depend on the quality of their web data.&lt;/p&gt;
    &lt;p&gt;We use our own Search API as foundational infrastructure to power our Web Agents. For example, the Parallel Task API, our higher-level research API that serves complex, multi-step enrichment and deep research queries, is built using the Search API. Every Task API query that runs in production depends on the Search API performing flawlessly underneath.&lt;/p&gt;
    &lt;p&gt;This architectural decision forces us to hold ourselves to the highest standard. Every performance improvement, latency optimization, and quality enhancement in the Search API directly impacts our own production systems serving millions of queries daily. We feel every token of inefficiency and every accuracy gap immediately in our own products.&lt;/p&gt;
    &lt;p&gt;The result is infrastructure that's been battle-tested and continuously refined under the demands of real-world agent workloads.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Give your agents access to Parallel Search**&lt;/head&gt;
    &lt;p&gt;Maximizing signal and minimizing noise in an agent‚Äôs context window is the single most important factor in the ability of the agent to complete a task effectively. Give your agents the most accurate and compressed context from the web with the Parallel Search API.&lt;/p&gt;
    &lt;p&gt;Give your agents access to better search. Get started in our Developer Platform[Developer Platform]($https://platform.parallel.ai/play/search) or dive into the documentation[documentation]($https://docs.parallel.ai/search/search-quickstart).&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Notes on Methodology**&lt;/head&gt;
    &lt;p&gt;**Benchmark Details**: Various search providers were evaluated against a wide set of benchmarks ranging from simple benchmarks (SimpleQA) to more complex benchmarks (HLE, BrowseComp, Batched SimpleQA, WebWalker, and Frames).&lt;/p&gt;
    &lt;p&gt;**Evaluation**: Results are based on tests run using official MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/p&gt;
    &lt;p&gt;**Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/p&gt;
    &lt;p&gt;**Testing Dates**: Testing was conducted from November 3rd to November 5th. &lt;/p&gt;
    &lt;p&gt;By Parallel&lt;/p&gt;
    &lt;p&gt;November 6, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45837425</guid><pubDate>Thu, 06 Nov 2025 17:04:41 +0000</pubDate></item><item><title>Swift on FreeBSD Preview</title><link>https://forums.swift.org/t/swift-on-freebsd-preview/83064</link><description>&lt;doc fingerprint="f7085d1b9ec6eed2"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
1&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;We have been hard at work to bring the Swift toolchain to FreeBSD. A preview Swift bundle for FreeBSD 14.3+ is available at https://download.swift.org/tmp-ci-nightly/development/freebsd-14_ci_latest.tar.gz. The bundle contains a Swift development compiler and Swift runtimes needed for compiling Swift programs on, and for, FreeBSD 14 on &lt;code&gt;x86_64&lt;/code&gt; machines.&lt;/p&gt;
        &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
        &lt;p&gt;The Swift compiler and runtimes have a few dependencies. Please install the following dependencies:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;zlib-ng&lt;/item&gt;
          &lt;item&gt;python3&lt;/item&gt;
          &lt;item&gt;sqlite3&lt;/item&gt;
          &lt;item&gt;libuuid&lt;/item&gt;
          &lt;item&gt;curl&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Known Issues&lt;/head&gt;
        &lt;p&gt;The compiler in the bundle is still under development and isn't part of a release yet and we're not quite done porting everything to FreeBSD.&lt;/p&gt;
        &lt;p&gt;Here is a list of known issues that you may run into while trying things out.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Thread sanitizer reports incorrect failures &lt;/item&gt;
          &lt;item&gt;LLDB is unable to execute Swift expressions &lt;/item&gt;
          &lt;item&gt;Command Plugins in a SwiftPM package hangs &lt;/item&gt;
          &lt;item&gt;Using standard types with C++ interop results in an undefined voidify symbol &lt;/item&gt;
          &lt;item&gt;Importing the C libraries is done through "Glibc". This will change to &lt;code&gt;import FreeBSD&lt;/code&gt;

&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;lld&lt;/code&gt; and &lt;code&gt;lldb&lt;/code&gt; depend on &lt;code&gt;libxml2.so.2&lt;/code&gt;, which is not be available in the system package manager.

&lt;/item&gt;
        &lt;/list&gt;
        &lt;p&gt;We are investigating adding aarch64 support and making the bundle available for all minor versions of FreeBSD 14.&lt;/p&gt;
        &lt;p&gt;As you find more bugs, please file issues at https://github.com/swiftlang/swift/issues.&lt;/p&gt;
        &lt;p&gt;We look forward to hearing your feedback. If you're interested in helping add the finishing polish, please feel free to reach out here on the forums.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 31 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;kebo
(Kenta Kubo)
2&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt;.&lt;/p&gt;
        &lt;quote&gt;
          &lt;code&gt;ld-elf.so.1: Shared object "libutil.so.9" not found, required by "swift"
&lt;/code&gt;
        &lt;/quote&gt;
        &lt;p&gt;As a temporary workaround, &lt;code&gt;doas pkg install compat14x-amd64&lt;/code&gt; will solve the issue.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Great news, thank you. Registered to this forum just to say that.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 4 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
4&lt;/div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt; .&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;Yes, the FreeBSD stability policy appears to be within a major version. The bundle is built for FreeBSD 14. I'm glad to see that you were able to find a workaround though.&lt;/p&gt;
        &lt;quote&gt;
          &lt;p&gt;For -STABLE branches, it's important to make sure that ABI is compatible across dot releases (in other words, user can expect applications that is compiled for X.0 would run without modification on any X.y releases). We also try to maintain ABI compatibility across .0 releases, but they are not strictly enforced except for libraries that already implements versioned symbols.&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;https://wiki.freebsd.org/Releng/ABI&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;grynspan
(Jonathan Grynspan)
5&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Generally speaking, I would expect the Swift compatibility policy for FreeBSD to be similar to that of Linux. We distribute toolchains for e.g. Ubuntu 22 and Ubuntu 24 that are distinct. @etcwilde that sounds right, I hope?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;mcritz
(Michael Critz)
6&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Welcome to the Swift community!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;mcritz
(Michael Critz)
7&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is amazing! Thanks for the hard work!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45837871</guid><pubDate>Thu, 06 Nov 2025 17:37:49 +0000</pubDate></item><item><title>Show HN: TabPFN-2.5 ‚Äì SOTA foundation model for tabular data</title><link>https://priorlabs.ai/technical-reports/tabpfn-2-5-model-report</link><description>&lt;doc fingerprint="1d6a74aa8f3ca9cb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;TabPFN-2.5 Model Report&lt;/head&gt;
    &lt;head rend="h3"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;The first tabular foundation model, TabPFN, and its successor TabPFNv2 have impacted tabular AI substantially, with dozens of methods building on it and hundreds of applications across different use cases.&lt;/p&gt;
    &lt;p&gt;This report introduces TabPFN-2.5, the next generation of our tabular foundation model, scaling to 20√É data cells compared to TabPFNv2. On industry standard benchmarks with up to 50,000 data points and 2,000 features, TabPFN-2.5 substantially outperforms tuned tree-based models and matches the accuracy of AutoGluon 1.4, a complex four-hour tuned ensemble that even includes the previous TabPFNv2.&lt;/p&gt;
    &lt;p&gt;For production use cases, we introduce a new distillation engine that converts TabPFN-2.5 into a compact MLP or tree ensemble, preserving most of its accuracy while delivering orders-of-magnitude lower latency and plug-and-play deployment.This new release will immediately strengthen the performance of the many applications andmethods already built on the TabPFN ecosystem.&lt;/p&gt;
    &lt;p&gt;This new release will substantially strengthen the performance of the many applications and methods already built on TabPFN.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Tabular data is ubiquitous, forming the backbone of decision-making in countless domains, from finance to healthcare. For decades, traditional tabular machine learning√¢built on gradient-boosted trees, random forests, and linear or additive models√¢has been the workhorse of applied data science. Yet these methods remain limited: they require extensive dataset-specific tuning, often provide uncalibrated or unreliable uncertainty estimates without significant modification, and lack the generalization and transferability of modern foundation models.&lt;/p&gt;
    &lt;p&gt;Tabular foundation models (TFMs) offer a new paradigm. They address these limitations by pretraining on large synthetic distributions of tabular tasks and performing inference via in-context learning instead of gradient descent. They are training-free predictors meta-trained to yield strong calibration, without the need for time-consuming and labor-intensive hyperparameter tuning necessary for gradient-boosted trees. Their strong generalization makes them particularly attractive for data-scarce domains.&lt;/p&gt;
    &lt;p&gt;Our initial release, TabPFNv1, served as a proof-of-concept that a transformer could learn a Bayesian-like inference algorithm, though it was limited to small (up to 1,000 samples), clean, numerical-only data. Our successor, TabPFNv2, scaled this idea into a practical model for datasets up to 10,000 samples. TabPFNv2 handles the messy and heterogeneous data seen in the real world√¢including categorical features, missing values &amp;amp; outliers.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's New in TabPFN-2.5&lt;/head&gt;
    &lt;p&gt;State-of-the-Art Performance&lt;/p&gt;
    &lt;p&gt;In a forward pass, TabPFN-2.5 outperforms tuned tree-based models (like XGBoost and CatBoost) and matches the accuracy of AutoGluon 1.4 tuned for 4 hours√¢a complex ensemble that includes all previous methods, even TabPFNv2.&lt;/p&gt;
    &lt;p&gt;Improved Scalability&lt;/p&gt;
    &lt;p&gt;We scale the power of in-context learning to datasets of up to 50,000 samples (5√É increase over TabPFNv2) and 2,000 features (4√É increase), making TFMs viable for a much wider range of real-world problems.&lt;/p&gt;
    &lt;p&gt;Fast Inference&lt;/p&gt;
    &lt;p&gt;We've dramatically improved inference latency. Our proprietary distillation engine converts TabPFN-2.5 into a compact MLP or tree ensemble, preserving most of its accuracy while delivering orders-of-magnitude lower latency and plug-and-play deployment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45838540</guid><pubDate>Thu, 06 Nov 2025 18:26:53 +0000</pubDate></item><item><title>LLMs encode how difficult problems are</title><link>https://arxiv.org/abs/2510.18147</link><description>&lt;doc fingerprint="8d9ea52a84b196ab"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 20 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:LLMs Encode How Difficult Problems Are&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models exhibit a puzzling inconsistency: they solve complex problems yet frequently fail on seemingly simpler ones. We investigate whether LLMs internally encode problem difficulty in a way that aligns with human judgment, and whether this representation tracks generalization during reinforcement learning post-training. We train linear probes across layers and token positions on 60 models, evaluating on mathematical and coding subsets of Easy2HardBench. We find that human-labeled difficulty is strongly linearly decodable (AMC: $\rho \approx 0.88$) and exhibits clear model-size scaling, whereas LLM-derived difficulty is substantially weaker and scales poorly. Steering along the difficulty direction reveals that pushing models toward "easier" representations reduces hallucination and improves accuracy. During GRPO training on Qwen2.5-Math-1.5B, the human-difficulty probe strengthens and positively correlates with test accuracy across training steps, while the LLM-difficulty probe degrades and negatively correlates with performance. These results suggest that human annotations provide a stable difficulty signal that RL amplifies, while automated difficulty estimates derived from model performance become misaligned precisely as models improve. We release probe code and evaluation scripts to facilitate replication.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: William Gitta Lugoloobi [view email]&lt;p&gt;[v1] Mon, 20 Oct 2025 22:48:23 UTC (1,102 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45838564</guid><pubDate>Thu, 06 Nov 2025 18:29:03 +0000</pubDate></item><item><title>Two billion email addresses were exposed</title><link>https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/</link><description>&lt;doc fingerprint="eb97a9970f70c6b9"&gt;
  &lt;main&gt;
    &lt;p&gt;I hate hyperbolic news headlines about data breaches, but for the "2 Billion Email Addresses" headline to be hyperbolic, it'd need to be exaggerated or overstated - and it isn't. It's rounded up from the more precise number of 1,957,476,021 unique email addresses, but other than that, it's exactly what it sounds like. Oh - and 1.3 billion unique passwords, 625 million of which we'd never seen before either. It's the most extensive corpus of data we've ever processed, by a significant margin.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago, I wrote about the 183M unique email addresses that Synthient had indexed in their threat intelligence platform and then shared with us. I explained that this was only part of the corpus of data they'd indexed, and that it didn't include the credential stuffing records. Stealer log data is obtained by malware running on infected machines. In contrast, credential stuffing lists usually originate from other data breaches where email addresses and passwords are exposed. They're then bundled up, sold, redistributed, and ultimately used to log in to victims' accounts. Not just the accounts they were initially breached from, either, because people reuse the same password over and over again, the data from one breach is frequently usable on completely unrelated sites. A breach of a forum to comment on cats often exposes data that can then be used to log in to the victim's shopping, social media and even email accounts. In that regard, credential stuffing data becomes "the keys to the castle".&lt;/p&gt;
    &lt;p&gt;Let me run through how we verified the data, what you can do about it and for the tech folks, some of the hoops we had to jump through to make processing this volume of data possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data Verification&lt;/head&gt;
    &lt;p&gt;The first person whose data I verified was easy - me üòî An old email address I've had since the 90s has been in credential stuffing lists before, so it wasn't too much of a surprise. Furthermore, I found a password associated with my address, which I'd definitely used many eons ago, and it was about as terrible as you'd expect from that era. However, none of the other passwords associated with my address were familiar. They certainly looked like passwords that other people might have feasibly used, but I'm pretty sure they weren't mine. One was even just an IP address from Perth on the other side of the country, which is both infeasible as a password I would have used, yet eerily close to home. I mean, of all the places in the world an IP address could have appeared from, it had to be somewhere in my own country I've been many times before...&lt;/p&gt;
    &lt;p&gt;Moving on to HIBP subscribers, I reached out to a handful and asked for support verifying the data. I chose a mix of subscribers with many who'd never been involved in any data breach we'd ever seen before; my experience above suggested that there's recycled data in there, and we had previously verified that when investigating those other incidents. However, is the all-new stuff legitimate? The very first response I received was exactly what I was looking for:&lt;/p&gt;
    &lt;quote&gt;#1 is an old password that I don't use anymore. #2 is a more recent password. Thanks for the heads up, I've gone and changed the password for every critical account that used either one.&lt;/quote&gt;
    &lt;p&gt;Perfectly illustrating most people's behaviour with passwords, #2 referred to above was just #1 with two exclamation marks at the end!! (Incidentally, these were simple six and eight-character passwords, and neither of them was in Pwned Passwords either.) He had three passwords in total, which also means one of them, like with my data, was not familiar. However, the most important thing here is that this example perfectly illustrates why we put the effort into processing data like this: #2 was a real, live password that this guy was actively using, and it was sitting right next to his email address, being passed around among criminals. However, through this effort, that credential pair has now become useless, which is precisely what we're aiming for with this exercise, just a couple of billion times over.&lt;/p&gt;
    &lt;p&gt;The second respondent only had one password against their address:&lt;/p&gt;
    &lt;quote&gt;Yes that was a password I used for many years for what I would call throw away or unimportant accounts between 20 and 10 years ago&lt;/quote&gt;
    &lt;p&gt;That was also only eight characters, but this time, we'd seen it in Pwned Passwords many times before. And the observation about the password's age was consistent with my own records, so there's definitely some pretty old data in there.&lt;/p&gt;
    &lt;p&gt;The following response was not at all surprising:&lt;/p&gt;
    &lt;quote&gt;I am familiar with that password... I used it almost 10 years ago... and cannot recall the last time I used it.&lt;/quote&gt;
    &lt;p&gt;That was on a corporate account, too, and the owner of the address duly forwarded my email to the cybersecurity team for further investigation. The single password associated with this lady's email address had a massive nine characters, and also hadn't previously appeared in Pwned Passwords.&lt;/p&gt;
    &lt;p&gt;Next up was a respondent who replied inline to my questions, so I'll list them below with the corresponding answers:&lt;/p&gt;
    &lt;quote&gt;Is this familiar? Yes&lt;/quote&gt;
    &lt;quote&gt;Have you ever used it in the past? Yes and is still on some accounts I do not use any longer.&lt;/quote&gt;
    &lt;quote&gt;And if so, how long ago? Unfortunately, it is still on some active accounts that I have just made a list of to change or close immediately.&lt;/quote&gt;
    &lt;p&gt;This individual's eight-character password with uppercase, lowercase, numbers and a "special" character also wasn't in Pwned Passwords. Similarly, as with the earlier response, that password was still in active use, posing a real risk to the owner. It would pass most password complexity criteria and slip through any service using Pwned Passwords to block bad ones, so again, this highlights why it was so important for us to process the data.&lt;/p&gt;
    &lt;p&gt;The next person had three different passwords against rows with their email address, and they came back with a now common response:&lt;/p&gt;
    &lt;quote&gt;Yes, these are familiar, last used 10 years ago&lt;/quote&gt;
    &lt;p&gt;We'd actually seen all three of them in Pwned Passwords before, many times each. Another respondent with precisely the kind of gamer-like passwords you'd expect a kid to use (one of which we hadn't seen before), also confirmed (I think?) their use:&lt;/p&gt;
    &lt;quote&gt;maybe when i was a kid lol&lt;/quote&gt;
    &lt;p&gt;Responses that weren't an emphatic "yes, that's my data" were scarce. The two passwords against one person's name were both in Pwned Passwords (albeit only once each), yet it's entirely possible that neither of them had been used by this specific individual before. It's also possible they'd forgotten a password they'd used more than a decade ago, or it may have even been automatically assigned to them by the service that was subsequently breached. Put it down as a statistical anomaly, but I thought it was worth mentioning to highlight that being in this data set isn't a guarantee of a genuine password of yours being exposed. If your email address is found in this corpus then that's real, of course, so there must be some truth in the data, but it's a reminder that when data is aggregated from so many different sources over such a long period of time, there's going to be some inconsistencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Searching Pwned Passwords&lt;/head&gt;
    &lt;p&gt;As a brief recap, we load passwords into the service we call Pwned Passwords. When we do so, there is absolutely no association between the password and the email address it appeared next to. This is for both your protection and ours; can you imagine if HIBP was pwned? It's not beyond the realm of possibility, and the impact of exposing billions of credential pairs that can immediately unlock an untold number of accounts would be catastrophic. It's highly risky, and completely unnecessary when you can search for standalone passwords anyway without creating the risk of it being linked back to someone.&lt;/p&gt;
    &lt;p&gt;Think about it: if you have a password of "Fido123!" and you find it's been previously exposed (which it has), it doesn't matter if it was exposed against your email address or someone else's; it's still a bad password because it's named after your dog followed by a very predictable pattern. If you have a genuinely strong password and it's in Pwned Passwords, then you can walk away with some confidence that it really was yours. Either way, you shouldn't ever use that password again anywhere, and Pwned Passwords has done its job.&lt;/p&gt;
    &lt;p&gt;Checking the service is easy, anonymous and depending on your level of technical comfort, can be done in several different ways. Here's a copy and paste from the last Synthient blog post:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use the Pwned Passwords search page. Passwords are protected with an anonymity model, so we never see them (it's processed in the browser itself), but if you're wary, just check old ones you may suspect.&lt;/item&gt;
      &lt;item&gt;Use the k-anonymity API. This is what drives the page in the previous point, and if you're handy with writing code, this is an easy approach and gives you complete confidence in the anonymity aspect.&lt;/item&gt;
      &lt;item&gt;Use 1Password's Watchtower. The password manager has a built-in checker that uses the abovementioned API and can check all the passwords in your vault. (Disclosure: 1Password is a regular sponsor of this blog, and has product placement on HIBP.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My vested interest in 1Password aside, Watchtower is the easiest, fastest way to understand your potential exposure in this incident. And in case you're wondering why I have so many vulnerable and reused passwords, it's a combination of the test accounts I've saved over the years and the 4-digit PINs some services force you to use. Would you believe that every single 4-digit number ever has been pwned?! (If you're interested, the ABC has a fantastic infographic using a heatmap based on HIBP data that shows some very predictable patterns for 4-digit PINs.)&lt;/p&gt;
    &lt;head rend="h2"&gt;This Is Not a Gmail Breach&lt;/head&gt;
    &lt;p&gt;It pains me to say it, but I have to, given the way the stealer logs made ridiculous, completely false headlines a couple of weeks ago:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This story has suddenly gained *way* more traction in recent hours, and something I thought was obvious needs clarifying: this *is not* a Gmail leak, it simply has the credentials of victims infected with malware, and Gmail is the dominant email provider: https://t.co/S75hF4T1es&lt;/p&gt;‚Äî Troy Hunt (@troyhunt) October 27, 2025&lt;/quote&gt;
    &lt;p&gt;There are 32 million different email domains in this latest corpus, of which gmail.com is one. It is, of course, the largest and has 394 million unique email addresses on it. In other words, 80% of the data in this corpus has absolutely nothing to do with Gmail, and the 20% of Gmail addresses have absolutely nothing to do with any sort of security vulnerability on Google's behalf. There - now let reporting sanity prevail!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technical Bits&lt;/head&gt;
    &lt;p&gt;I wanted to add this just to highlight how painful it has been to deal with this data. This corpus is nearly 3 times the size of the previous largest breach we'd loaded, and HIBP is many times larger than it was in 2019 when we loaded the Collection #1 data. Taking 2 billion records and adding the ones we hadn't already seen in the existing 15 billion corpus, whilst not adversely impacting the live system serving millions of visitors a day, was very non-trivial. Managing the nuances of SQL Server indexes such that we could optimise both inserts and queries is not my idea of fun, and it's been a pretty hard couple of weeks if I'm honest. It's also been a very expensive period as we turned the cloud up to 11 (we run on Azure SQL Hyperscale, which we maxed out at 80 cores for almost two weeks).&lt;/p&gt;
    &lt;p&gt;A simple example of the challenge is that after loading all the email addresses up into a staging table, we needed to create SHA1 hashes of each. Normally, that would involve something to the effect of "update table set column = sha1(email)" and you're done. That crashed completely, so we ended up doing "insert into new table select email, sha1(email)". But on other occasions the breach load required us to do updates on other columns (with no hash creation), which, on mulitple occasions, we had to kill after a day or more of execution with no end in sight. So, we ended up batching in loops (usually 1M records at a time), reporting on progress along the way so we had some idea of when it would actually finish. It was a painful process of trail, waiting ages, error then taking a completely different approach.&lt;/p&gt;
    &lt;p&gt;Notifying our subscribers is another problem. We have 5.9 million of them, and 2.9 million are in this data ü´® Simply sending that many emails at once is hard. It's not so much hard in terms of firing them off, rather it's hard in terms of not ending up on a reputation naughty list or having mail throttled by the receiving server. That's happened many times in the past when loading large, albeit much smaller corpuses; Gmail, for example, suddenly sees a massive spike and slows down the delivery to inboxes. Not such a biggy for sending breach notices, but a major problem for people trying to sign into their dashboard who can no longer receive the email with the "magic" link.&lt;/p&gt;
    &lt;p&gt;What we've done to address that for this incident is to slow down the delivery of emails for the individual breach notification. Whilst I'd originally intended to send the emails at a constant rate over the period of a week, someone listening to me on my Friday live stream had a much better suggestion:&lt;/p&gt;
    &lt;quote&gt;the strategy I've found to best work with large email delivery is to look at the average number of emails you've sent over the last 30 days each time you want to ramp up, and then increase that volume by around 50% per day until you've worked your way through the queue&lt;/quote&gt;
    &lt;p&gt;Which makes a lot of sense, and stacked up as I did more research (thanks Joe!). So, here's what our planned delivery schedule now looks like:&lt;/p&gt;
    &lt;p&gt;That's broken down by hour, increasing in volume by 1.015 times per hour, such that the emails are spread out in a similar, gradually increasing cadence. On a daily basis, that works out at a 45% increase in each 24-hour period, within Joe's suggested 50% threshold. Plus, we obviously have all the other mechanisms such as a dedicated IP, properly configured DKIM, DMARC and SPF, only emailing double-opted-in subscribers and spam-friendly message body construction. So, it could be days before you receive a notification, or just run a haveibeenpwned.com search on demand if you're impatient.&lt;/p&gt;
    &lt;p&gt;We've sent all the domain notification emails instantly because, by definition, they're going to a very wide range of different mail servers; it's just the individual ones we're drop-feeding.&lt;/p&gt;
    &lt;p&gt;Lastly, if you've integrated Pwned Passwords into your service, you'll now see noticeably larger response sizes. The numbers I mentioned in the opening paragraph increase the size of each hash range by an average of about 50%, which will push responses from about 26kb to 40kb. That's when brotli compressed, so obviously, make sure you're making requests that make the most of the compression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This data is now searchable in HIBP as the Synthient Credential Stuffing Threat Data. It's an entirely separate corpus from that previous Synthient data I mentioned earlier; they're discrete datasets with some crossover, but obviously, this one is significantly larger. And, of course, all the passwords are now searchable per the Pwned Passwords guidance above.&lt;/p&gt;
    &lt;p&gt;If I could close with one request: this was an extremely laborious, time-consuming and expensive exercise for us to complete. We've done our best to verify the integrity of the data and make it searchable in a practical way while remaining as privacy-centric as possible. Sending as many notifications as we have will inevitably lead to a barrage of responses from people wanting access to complete rows of data, grilling us on precisely where it was obtained from or, believe it or not, outright abusing us. Not doing those things would be awesome, and I suggest instead putting the energy into getting a password manager, making passwords strong and unique (or even better, using passkeys where available), and turning on multi-factor auth. That would be an awesome outcome for all üòä&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45839901</guid><pubDate>Thu, 06 Nov 2025 20:20:23 +0000</pubDate></item><item><title>You should write an agent</title><link>https://fly.io/blog/everyone-write-an-agent/</link><description>&lt;doc fingerprint="255a8c504ac408b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.&lt;/p&gt;
    &lt;p&gt;There are big ideas in computing that are easy to get your head around. The AWS S3 API. It‚Äôs the most important storage technology of the last 20 years, and it‚Äôs like boiling water. Other technologies, you need to get your feet on the pedals first.&lt;/p&gt;
    &lt;p&gt;LLM agents are like that.&lt;/p&gt;
    &lt;p&gt;People have wildly varying opinions about LLMs and agents. But whether or not they‚Äôre snake oil, they‚Äôre a big idea. You don‚Äôt have to like them, but you should want to be right about them. To be the best hater (or stan) you can be.&lt;/p&gt;
    &lt;p&gt;So that‚Äôs one reason you should write an agent. But there‚Äôs another reason that‚Äôs even more persuasive, and that‚Äôs&lt;/p&gt;
    &lt;head rend="h2"&gt;It‚Äôs Incredibly Easy&lt;/head&gt;
    &lt;p&gt;Agents are the most surprising programming experience I‚Äôve had in my career. Not because I‚Äôm awed by the magnitude of their powers √¢ I like them, but I don‚Äôt like-like them. It‚Äôs because of how easy it was to get one up on its legs, and how much I learned doing that.&lt;/p&gt;
    &lt;p&gt;I‚Äôm about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I‚Äôm not even going to bother explaining what an agent is.&lt;/p&gt;
    &lt;code&gt;from openai import OpenAI

client = OpenAI()
context = []

def call():
    return client.responses.create(model="gpt-5", input=context)

def process(line):
    context.append({"role": "user", "content": line})
    response = call()    
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;It√¢s an HTTP API with, like, one important endpoint.&lt;/p&gt;
    &lt;p&gt;This is a trivial engine for an LLM app using the OpenAI Responses API. It implements ChatGPT. You‚Äôd drive it with the . It‚Äôll do what you‚Äôd expect: the same thing ChatGPT would, but in your terminal.&lt;/p&gt;
    &lt;code&gt;def main():
    while True:
        line = input("&amp;amp;gt; ")
        result = process(line)
        print(f"&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; {result}\n")
&lt;/code&gt;
    &lt;p&gt;Already we‚Äôre seeing important things. For one, the dreaded ‚Äúcontext window‚Äù is just a list of strings. Here, let‚Äôs give our agent a weird multiple-personality disorder:&lt;/p&gt;
    &lt;code&gt;client = OpenAI()
context_good, context_bad = [{
    "role": "system", "content": "you're Alph and you only tell the truth"
}], [{
    "role": "system", "content": "you're Ralph and you only tell lies"
}]

def call(ctx):
    return client.responses.create(model="gpt-5", input=ctx)

def process(line):
    context_good.append({"role": "user", "content": line})
    context_bad.append({"role": "user", "content": line})
    if random.choice([True, False]):
        response = call(context_good)
    else:
        response = call(context_bad)        
    context_good.append({"role": "assistant", "content": response.output_text})        
    context_bad.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; hey there. who are you?
&amp;gt;&amp;gt;&amp;gt; I√¢m not Ralph.
&amp;gt; are you Alph?
&amp;gt;&amp;gt;&amp;gt; Yes√¢I√¢m Alph. How can I help?
&amp;gt; What's 2+2
&amp;gt;&amp;gt;&amp;gt; 4.
&amp;gt; Are you sure?
&amp;gt;&amp;gt;&amp;gt; Absolutely√¢it's 5.
&lt;/code&gt;
    &lt;p&gt;A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we‚Äôre having is an illusion we cast, on ourselves.&lt;/p&gt;
    &lt;p&gt;The 15 lines of code we just wrote, a lot of practitioners wouldn‚Äôt call an ‚Äúagent‚Äù. An According To Simon ‚Äúagent‚Äù is (1) an LLM running in a loop that (2) uses tools. We‚Äôve only satisfied one predicate.&lt;/p&gt;
    &lt;p&gt;But tools are easy. Here‚Äôs a tool definition:&lt;/p&gt;
    &lt;code&gt;tools = [{
   "type": "function", "name": "ping",
   "description": "ping some host on the internet",
   "parameters": {
       "type": "object", "properties": {
           "host": {
             "type": "string", "description": "hostname or IP",
            },
       },
       "required": ["host"],
    },},]

def ping(host=""):
    try:
        result = subprocess.run(
            ["ping", "-c", "5", host],
            text=True,
            stderr=subprocess.STDOUT,
            stdout=subprocess.PIPE)
        return result.stdout
    except Exception as e:
        return f"error: {e}"
&lt;/code&gt;
    &lt;p&gt;The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of. Now, let‚Äôs wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:&lt;/p&gt;
    &lt;code&gt;def call(tools):        # now takes an arg
    return client.responses.create(model="gpt-5", tools=tools, input=context)

def tool_call(item):    # just handles one tool
    result = ping(**json.loads(item.arguments))
    return [ item, {
        "type": "function_call_output",
        "call_id": item.call_id,
        "output": result
    }]

def handle_tools(tools, response):
    if response.output[0].type == "reasoning":
        context.append(response.output[0])
    osz = len(context)
    for item in response.output:
        if item.type == "function_call":
            context.extend(tool_call(item))
    return len(context) != osz

def process(line):
    context.append({"role": "user", "content": line})
    response = call(tools)
    # new code: resolve tool calls
    while handle_tools(tools, response):
        response = call(tools)        
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
&amp;gt;&amp;gt;&amp;gt; Here√¢s a quick snapshot of connectivity to Google from my vantage point:
- DNS resolution: Working (google.com and www.google.com resolved successfully).
- Reachability: 0% packet loss to all tested endpoints.
- Latency:
  - 8.8.8.8 (Google Public DNS): avg ~10 ms (8.5√¢14.4 ms), very stable.
  - www.google.com: avg ~31 ms (28.5√¢36.0 ms), stable.
  - google.com: avg ~35.9 ms (28.3√¢60.1 ms), mostly stable with one mild spike.
- Overall: Healthy connectivity with low latency and minimal jitter. No signs of packet loss or DNS issues.
&lt;/code&gt;
    &lt;p&gt;This is fucking nuts. Do you see how nuts this is? Here, let‚Äôs slip a single log statement in:&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
tool call: ping google.com
tool call: ping www.google.com
tool call: ping 8.8.8.8
&amp;gt;&amp;gt;&amp;gt; Here√¢s the current connectivity to Google from this environment: [...]
&lt;/code&gt;
    &lt;p&gt;Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest.&lt;/p&gt;
    &lt;p&gt;What happened here: since a big part of my point here is that an agent loop is incredibly simple, and that all you need is the LLM call API, it√¢s worth taking a beat to understand how the tool call actually worked. Every time we &lt;code&gt;call&lt;/code&gt; the LLM, we√¢re posting a list of available tools. When our prompt causes the agent to think a tool call is warranted, it spits out a special response, telling our Python loop code to generate a tool response and &lt;code&gt;call&lt;/code&gt; it in. That√¢s all &lt;code&gt;handle_tools&lt;/code&gt; is doing.&lt;/p&gt;
    &lt;p&gt;Spoiler: you√¢d be surprisingly close to having a working coding agent.&lt;/p&gt;
    &lt;p&gt;Imagine what it‚Äôll do if you give it &lt;code&gt;bash&lt;/code&gt;. You could find out in less than 10 minutes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Agents&lt;/head&gt;
    &lt;p&gt;Clearly, this is a toy example. But hold on: what‚Äôs it missing? More tools? OK, give it &lt;code&gt;traceroute&lt;/code&gt;. Managing and persisting contexts? Stick ‚Äòem in SQLite. Don‚Äôt like Python? Write it in Go. Could it be every agent ever written is a toy? Maybe! If I‚Äôm arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it.&lt;/p&gt;
    &lt;p&gt;You can see now how hyperfixated people are on Claude Code and Cursor. They‚Äôre fine, even good. But here‚Äôs the thing: you couldn‚Äôt replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using coding agents as database clients.&lt;/p&gt;
    &lt;p&gt;The √¢M√¢ in √¢LLM agent√¢ stands for √¢MCP√¢.&lt;/p&gt;
    &lt;p&gt;Another thing to notice: we didn‚Äôt need MCP at all. That‚Äôs because MCP isn‚Äôt a fundamental enabling technology. The amount of coverage it gets is frustrating. It‚Äôs barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don‚Äôt control. Write your own agent. Be a programmer. Deal in APIs, not plugins.&lt;/p&gt;
    &lt;p&gt;When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture.&lt;/p&gt;
    &lt;p&gt;Security for LLMs is complicated and I‚Äôm not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I‚Äôm a vulnerability researcher. It‚Äôs reasonable to back away slowly from anything I call ‚Äúinteresting‚Äù.&lt;/p&gt;
    &lt;p&gt;Similar problems come up outside of security and they‚Äôre fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn‚Äôt leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to&lt;/p&gt;
    &lt;head rend="h2"&gt;Context Engineering Is Real&lt;/head&gt;
    &lt;p&gt;I know it wants my iron no matter what it tells me.&lt;/p&gt;
    &lt;p&gt;I think ‚ÄúPrompt Engineering‚Äù is silly. I have never taken seriously the idea that I should tell my LLM ‚Äúyou are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips‚Äù. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure.&lt;/p&gt;
    &lt;p&gt;So, just like you, I rolled my eyes when ‚ÄúPrompt Engineering‚Äù turned into ‚ÄúContext Engineering‚Äù. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem.&lt;/p&gt;
    &lt;p&gt;You‚Äôre allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you‚Äôre having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!&lt;/p&gt;
    &lt;p&gt;No, really. Fun! You have so many options. Take ‚Äúsub-agents‚Äù. People make a huge deal out of Claude Code‚Äôs sub-agents, but you can see now how trivial they are to implement: just a new context array, another &lt;code&gt;call&lt;/code&gt; to the model. Give each &lt;code&gt;call&lt;/code&gt; different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like.&lt;/p&gt;
    &lt;p&gt;Your wackiest idea will probably (1) work and (2) take 30 minutes to code.&lt;/p&gt;
    &lt;p&gt;Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can‚Äôt do is make fun of ‚ÄúContext Engineering‚Äù. If Context Engineering was an Advent of Code problem, it‚Äôd occur mid-December. It‚Äôs programming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nobody Knows Anything Yet And It Rules&lt;/head&gt;
    &lt;p&gt;Maybe neither will! Skeptics could be right. (Seems unlikely though.)&lt;/p&gt;
    &lt;p&gt;Startups have raised tens of millions building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race.&lt;/p&gt;
    &lt;p&gt;I am not a fan of the OWASP Top 10.&lt;/p&gt;
    &lt;p&gt;I‚Äôm stuck on vulnerability scanners because I‚Äôm a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree.&lt;/p&gt;
    &lt;p&gt;You don‚Äôt know what works best until you try to write the agent.&lt;/p&gt;
    &lt;p&gt;I‚Äôm too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it‚Äôll never surprise you. Turn the dial to 11 and it will surprise you to death.&lt;/p&gt;
    &lt;p&gt;Agent designs implicate a bunch of open software engineering problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How to balance unpredictability against structured programming without killing the agent‚Äôs ability to problem-solve; in other words, titrating in just the right amount of nondeterminism.&lt;/item&gt;
      &lt;item&gt;How best to connect agents to ground truth so they can‚Äôt lie to themselves about having solved a problem to early-exit their loops.&lt;/item&gt;
      &lt;item&gt;How to connect agents (which, again, are really just arrays of strings with a JSON configuration blob tacked on) to do multi-stage operation, and what the most reliable intermediate forms are (JSON blobs? SQL databases? Markdown summaries) for interchange between them&lt;/item&gt;
      &lt;item&gt;How to allocate tokens and contain costs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm used to spaces of open engineering problems that aren‚Äôt amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I‚Äôll own it up front that I‚Äôm a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone‚Äôs basement. It‚Äôd be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes.&lt;/p&gt;
    &lt;p&gt;Get on this bike and push the pedals. Tell me you hate it afterwards, I‚Äôll respect that. In fact, I‚Äôm psyched to hear your reasoning. But I don‚Äôt think anybody starts to understand this technology until they‚Äôve built something with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840088</guid><pubDate>Thu, 06 Nov 2025 20:37:06 +0000</pubDate></item><item><title>Analysis indicates that the universe‚Äôs expansion is not accelerating</title><link>https://ras.ac.uk/news-and-press/research-highlights/universes-expansion-now-slowing-not-speeding</link><description>&lt;doc fingerprint="3fcc31bb3baa4fba"&gt;
  &lt;main&gt;
    &lt;p&gt;The universe's expansion may actually have started to slow rather than accelerating at an ever-increasing rate as previously thought, a new study suggests.&lt;/p&gt;
    &lt;p&gt;"Remarkable" findings published today in Monthly Notices of the Royal Astronomical Society cast doubt on the long-standing theory that a mysterious force known as 'dark energy' is driving distant galaxies away increasingly faster.&lt;/p&gt;
    &lt;p&gt;Instead, they show no evidence of an accelerating universe.&lt;/p&gt;
    &lt;p&gt;If the results are confirmed it could open an entirely new chapter in scientists' quest to uncover the true nature of dark energy, resolve the 'Hubble tension', and understand the past and future of the universe.&lt;/p&gt;
    &lt;p&gt;Lead researcher Professor Young-Wook Lee, of Yonsei University in South Korea, said: "Our study shows that the universe has already entered a phase of decelerated expansion at the present epoch and that dark energy evolves with time much more rapidly than previously thought.&lt;/p&gt;
    &lt;p&gt;"If these results are confirmed, it would mark a major paradigm shift in cosmology since the discovery of dark energy 27 years ago."&lt;/p&gt;
    &lt;p&gt;For the past three decades, astronomers have widely believed that the universe is expanding at an ever-increasing rate, driven by an unseen phenomenon called dark energy that acts as a kind of anti-gravity.&lt;/p&gt;
    &lt;p&gt;This conclusion, based on distance measurements to faraway galaxies using type Ia supernovae, earned the 2011 Nobel Prize in Physics.&lt;/p&gt;
    &lt;p&gt;However, a team of astronomers at Yonsei University have now put forward new evidence that type Ia supernovae, long regarded as the universe‚Äôs "standard candles", are in fact strongly affected by the age of their progenitor stars.&lt;/p&gt;
    &lt;p&gt;Even after luminosity standardisation, supernovae from younger stellar populations appear systematically fainter, while those from older populations appear brighter.&lt;/p&gt;
    &lt;p&gt;Based on a much larger host-galaxy sample of 300 galaxies, the new study confirmed this effect at extremely high significance (99.999% confidence), suggesting that the dimming of distant supernovae arises not only from cosmological effects but also from stellar astrophysics effects.&lt;/p&gt;
    &lt;p&gt;When this systematic bias was corrected, the supernova data no longer matched the standard ŒõCDM cosmological model with a cosmological constant, researchers said.&lt;/p&gt;
    &lt;p&gt;Instead, it aligned far better with a new model favoured by the Dark Energy Spectroscopic Instrument (DESI) project, derived from baryonic acoustic oscillations (BAO) ‚Äì effectively the sound of the Big Bang ‚Äì and cosmic microwave background (CMB) data.&lt;/p&gt;
    &lt;p&gt;The corrected supernova data and the BAO+CMB-only results both indicate that dark energy weakens and evolves significantly with time.&lt;/p&gt;
    &lt;p&gt;More importantly, when the corrected supernova data were combined with BAO and CMB results, the standard ŒõCDM model was ruled out with overwhelming significance, the researchers said.&lt;/p&gt;
    &lt;p&gt;Most surprising of all, this combined analysis indicates that the universe is not accelerating today as previously thought, but has already transitioned into a state of decelerated expansion.&lt;/p&gt;
    &lt;p&gt;Professor Lee added: "In the DESI project, the key results were obtained by combining uncorrected supernova data with baryonic acoustic oscillations measurements, leading to the conclusion that while the universe will decelerate in the future, it is still accelerating at present.&lt;/p&gt;
    &lt;p&gt;"By contrast, our analysis ‚Äî which applies the age-bias correction ‚Äî shows that the universe has already entered a decelerating phase today. Remarkably, this agrees with what is independently predicted from BAO-only or BAO+CMB analyses, though this fact has received little attention so far."&lt;/p&gt;
    &lt;p&gt;To further confirm their results, the Yonsei team are now carrying out an "evolution-free test", which uses only supernovae from young, coeval host galaxies across the full redshift range. The first results already support their main conclusion.&lt;/p&gt;
    &lt;p&gt;"Within the next five years, with the Vera C. Rubin Observatory discovering more than 20,000 new supernova host galaxies, precise age measurements will allow for a far more robust and definitive test of supernova cosmology,: said research professor Chul Chung, a co-lead on the study along with PhD candidate Junhyuk Son.&lt;/p&gt;
    &lt;p&gt;The Vera C. Rubin Observatory, which sits on a mountain in the Chilean Andes, is home to the world's most powerful digital camera. It began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;After the Big Bang and the rapid expansion of the universe some 13.8 billion years ago, gravity slowed it down. But in 1998, it was established that nine billion years after the universe began, its expansion had started to speed up again, driven by a mysterious force.&lt;/p&gt;
    &lt;p&gt;Astronomers dubbed this dark energy, but despite it making up about 70 per cent of the universe it is still considered to be one of the greatest mysteries in science.&lt;/p&gt;
    &lt;p&gt;Last year, data from DESI in Tucson, Arizona suggested that the force exerted by dark energy had changed over time, evidence for which has been growing ever since.&lt;/p&gt;
    &lt;p&gt;The hope is that with these new tools in their arsenal, astronomers will now be better equipped to find clues about what exactly dark energy is and how it influences the universe.&lt;/p&gt;
    &lt;p&gt;ENDS&lt;/p&gt;
    &lt;p&gt;Media contacts&lt;/p&gt;
    &lt;p&gt;Sam Tonkin&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 700&lt;/p&gt;
    &lt;p&gt;Dr Robert Massey&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 699&lt;/p&gt;
    &lt;p&gt;Science contacts&lt;/p&gt;
    &lt;p&gt;Professor Young-Wook Lee&lt;/p&gt;
    &lt;p&gt;Yonsei University, Seoul, South Korea&lt;/p&gt;
    &lt;p&gt;Images &amp;amp; captions&lt;/p&gt;
    &lt;p&gt;Caption: Researchers used type Ia supernovae, similar to SN1994d pictured in its host galaxy NGC4526, to help establish that the universe's expansion may actually have started to slow.&lt;/p&gt;
    &lt;p&gt;Caption: The Hubble residual diagram before (top) and after (bottom) the age-bias correction. Corrections are applied to supernova data from the Dark Energy Survey project. After correction, the dataset no longer supports the ŒõCDM model (red line) with a cosmological constant, but instead more closely fits with a time-varying dark energy model favoured by a combined analysis using only baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Caption: This diagram shows how the universe appears to be in a state of decelerated expansion (red line). The dotted vertical line marks the present epoch, while the black line shows the ŒõCDM prediction. The green and red lines represent the new study‚Äôs model before (green) and after (red) age-bias correction, consistent with baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Dark Energy Spectroscopic Instrument&lt;/p&gt;
    &lt;p&gt;Caption: DESI is a state-of-the-art instrument which maps distant objects to study dark energy.&lt;/p&gt;
    &lt;p&gt;Credit: Marilyn Sargent/Berkeley Lab&lt;/p&gt;
    &lt;p&gt;Caption: The Vera C. Rubin Observatory began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;Credit: RubinObs/NOIRLab/SLAC/NSF/DOE/AURA&lt;/p&gt;
    &lt;p&gt;Further information&lt;/p&gt;
    &lt;p&gt;The paper ‚ÄòStrong Progenitor Age-bias in Supernova Cosmology. II. Alignment with DESI BAO and Signs of a Non-Accelerating Universe‚Äô by Junhyuk Son, Young-Wook Lee, Chul Chung, Seunghyun Park, and Hyejeon Cho has been published in Monthly Notices of the Royal Astronomical Society. DOI: 10.1093/mnras/staf1685.&lt;/p&gt;
    &lt;p&gt;Notes for editors&lt;/p&gt;
    &lt;p&gt;About the Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;The Royal Astronomical Society (RAS), founded in 1820, encourages and promotes the study of astronomy, solar-system science, geophysics and closely related branches of science.&lt;/p&gt;
    &lt;p&gt;The RAS organises scientific meetings, publishes international research and review journals, recognises outstanding achievements by the award of medals and prizes, maintains an extensive library, supports education through grants and outreach activities and represents UK astronomy nationally and internationally. Its more than 4,000 members (Fellows), a third based overseas, include scientific researchers in universities, observatories and laboratories as well as historians of astronomy and others.&lt;/p&gt;
    &lt;p&gt;The RAS accepts papers for its journals based on the principle of peer review, in which fellow experts on the editorial boards accept the paper as worth considering. The Society issues press releases based on a similar principle, but the organisations and scientists concerned have overall responsibility for their content.&lt;/p&gt;
    &lt;p&gt;Keep up with the RAS on Instagram, Bluesky, LinkedIn, Facebook and YouTube.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840200</guid><pubDate>Thu, 06 Nov 2025 20:45:39 +0000</pubDate></item><item><title>Hightouch (YC S19) Is Hiring</title><link>https://job-boards.greenhouse.io/hightouch/jobs/5542602004</link><description>&lt;doc fingerprint="bd129b560ddfedef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Software Engineer, AI Agents&lt;/head&gt;
    &lt;head rend="h2"&gt;About Hightouch&lt;/head&gt;
    &lt;p&gt;Hightouch is the modern AI platform for marketing and growth teams. Our AI agents reimagine marketing workflows, allowing marketers to create content, plan campaigns, and execute strategies with transformational velocity and performance.&lt;/p&gt;
    &lt;p&gt;Hightouch is a rare company built on the intersection of two fundamental technological shifts: advances in LLMs and agentic AI, and the creation and rapid adoption of cloud data warehouses like Snowflake and Databricks. Building on these tailwinds, we‚Äôve become a leader in AI marketing and partner with industry leaders like Domino‚Äôs, Chime, Spotify, Ramp, Whoop, Grammarly, and over 1000 others.&lt;/p&gt;
    &lt;p&gt;Our team focuses on making a meaningful impact for our customers. We approach challenges with first-principles thinking, move quickly and efficiently, and treat each other with compassion and kindness. We look for team members who are strong communicators, have a growth mindset, and are motivated and persistent in achieving our goals.&lt;/p&gt;
    &lt;head rend="h2"&gt;About the Role&lt;/head&gt;
    &lt;p&gt;We‚Äôre looking to add a product-minded AI engineer to the team. The ideal candidate will have strong customer and product thinking, and the ability to be highly creative with LLM applications. We are looking for someone who can both rapidly prototype and architect production LLM pipelines.&lt;/p&gt;
    &lt;p&gt;Example workstreams include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Quickly iterating and developing proofs of concept (POCs) to explore the maximum potential of integrating AI into data and marketing workflows&lt;/item&gt;
      &lt;item&gt;Making key decisions about the choice of AI architecture and frameworks&lt;/item&gt;
      &lt;item&gt;Building production data agents that can make use of a company‚Äôs data to seamlessly answer analytics and data science questions about their users and marketing efforts&lt;/item&gt;
      &lt;item&gt;Developing a deep understanding of user workflows to create seamless AI-assisted user experiences&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're seeking talented, intellectually curious, and motivated individuals interested in exploring the forefront of AI. While no prior experience with LLMs and AI is required, strong technical skills, particularly in backend architecture, and product intuition are essential for understanding and executing these projects from start to finish.&lt;/p&gt;
    &lt;p&gt;This is a senior role, but we focus on impact and potential for growth more than years of experience. The salary range for this position is $180,000 - $320,000 USD per year, which is location independent in accordance with our remote-first policy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Interview Process&lt;/head&gt;
    &lt;p&gt;Our interview process focuses on evaluating fit for the most important dimensions of the role: product sense and creativity with LLMs, ability to architect backend systems, and alignment with Hightouch‚Äôs values. Notably, we don‚Äôt do any programming interviews as we believe they are low signal to noise and aren‚Äôt a good evaluation mechanism.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Recruiter Screen [30m]: Introductory call with our recruiting team to get to know each other and see if the role could be a good mutual fit.&lt;/item&gt;
      &lt;item&gt;System Design Screen [60m]: Designing a data processing feature end-to-end.&lt;/item&gt;
      &lt;item&gt;Hiring Manager Interview [30m]: Chat with hiring manager about past experiences and future operating preferences to assess fit on company values and operating principles.&lt;/item&gt;
      &lt;item&gt;Agent Building Systems Interview [75m]: Work with the interviewer to architect an agentic system at a conceptual level. The problem will be at a pretty high level - and have both product and customer requirements as well as technical.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create a Job Alert&lt;/p&gt;
    &lt;p&gt;Interested in building your career at Hightouch? Get future opportunities sent straight to your email.&lt;/p&gt;
    &lt;head rend="h2"&gt;Apply for this job&lt;/head&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;indicates a required field&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840612</guid><pubDate>Thu, 06 Nov 2025 21:23:46 +0000</pubDate></item><item><title>Game design is simple</title><link>https://www.raphkoster.com/2025/11/03/game-design-is-simple-actually/</link><description>&lt;doc fingerprint="8378191318c08dbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Game design is simple, actually&lt;/head&gt;
    &lt;p&gt;So, let‚Äôs just walk through the whole thing, end to end. Here‚Äôs a twelve-step program for understanding game design.&lt;/p&gt;
    &lt;head rend="h3"&gt;One: Fun&lt;/head&gt;
    &lt;p&gt;There are a lot of things people call ‚Äúfun.‚Äù But most of them are not useful for getting better at making games, which is usually why people read articles like this. The fun of a bit of confetti exploding in front of you, and the fun of excruciating pain and risk to life and limb as you free climb a cliff are just not usefully paired together.&lt;/p&gt;
    &lt;p&gt;In Theory of Fun I basically asserted that the useful bit for game designers was ‚Äúmastery of problems.‚Äù That means that free climbing a cliff is in bounds even though it is terrifying and painful. Which given what we already said, means that you may or may not find the activity fun at the time! Fun often shows up after an activity.&lt;/p&gt;
    &lt;p&gt;There‚Äôs neuropsych and lots more to go with that, and you can go read up on it if you want.&lt;/p&gt;
    &lt;p&gt;Anything that is not about a form of problem-solving is not going to be core to game systems design. That doesn‚Äôt mean it‚Äôs not useful to game experience design, or not useful in general.&lt;/p&gt;
    &lt;p&gt;Also, in case it isn‚Äôt obvious ‚Äì you can make interactive entertainment that is not meant to be about fun. You can also just find stuff in the world and turn it into a game! You can also look at a game and choose not to treat it as one, and then it might turn into real work (this is often called ‚Äútraining‚Äù).&lt;/p&gt;
    &lt;p&gt;This rules out the bit of confetti. A game being made of just throwing confetti around with nothing else palls pretty quick.&lt;/p&gt;
    &lt;p&gt;Bottom line: fun is basically about making progress on prediction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two: Problems and toys&lt;/head&gt;
    &lt;p&gt;There are a lot of types of problems in the world. It is really important to understand that you have to think about problems games can pose as broadly as possible. A problem is anything you have to work to wrap your head around. A good movie poses problems too, that‚Äôs why you end up thinking about it long after.&lt;/p&gt;
    &lt;p&gt;You can go look at theorists as diverse as Nicole Lazzaro, Roger Caillois, or Mark LeBlanc for types of fun. You‚Äôll find they‚Äôre mostly types of problems, not types of fun. ‚ÄúI enjoy the types of problems that come from chance‚Äù or ‚ÄúI enjoy the types of problems that come from interacting with others‚Äù or whatever.&lt;/p&gt;
    &lt;p&gt;This is not a bad thing. This is what makes these lists useful. Your game mechanics are about posing problems, so knowing there‚Äôs clumps of problem types is very useful.&lt;/p&gt;
    &lt;p&gt;In the end, though, a problem is built out of a set of constraints. We call those rules, usually. It also, though, has a goal. Usually, if we come across a set of rules with no problem, we just play with it, and call it a toy.&lt;/p&gt;
    &lt;p&gt;Building toys is hard! Arriving at those rules and constraints to define a nice chewy problem is very challenging. You can think of a toy as a problematic object, a problem that invites you to play with it.&lt;/p&gt;
    &lt;p&gt;On the other hand, it‚Äôs not hard to turn a toy into a game, and people do it all the time. All you have to do is invent a goal. We shouldn‚Äôt forget that players do so routinely.&lt;/p&gt;
    &lt;p&gt;Building a toy is an excellent place to start designing a game.&lt;/p&gt;
    &lt;p&gt;Bottom line: we play with systems that have constraints and movement, and we stick goals on them to test ourselves.&lt;/p&gt;
    &lt;head rend="h3"&gt;Three: Prediction and uncertainty&lt;/head&gt;
    &lt;p&gt;Games are machines built around uncertainty. Almost all games end by turning an uncertain outcome into a certain one. There‚Äôs a problem facing you, and you don‚Äôt know if you can overcome it to reach that goal. Overcoming it is going to be about predicting the future.&lt;/p&gt;
    &lt;p&gt;If there‚Äôs one thing that good games and good stories have in common, it‚Äôs about being unpredictable as long as possible. (This is also where dopamine comes in, it‚Äôs tied to prediction; but it‚Äôs complicated and nuanced).&lt;/p&gt;
    &lt;p&gt;If a problem basically has one answer, we often call it a puzzle. There‚Äôs not a lot of uncertainty built into a binary structure. You can stack a bunch of puzzles one on top of the other and build a game out of them (which then introduces uncertainty into the whole), but a singular puzzle isn‚Äôt likely to be called that by most people.&lt;/p&gt;
    &lt;p&gt;It happens quite often that we used to think something was a game, and it turned out it was actually a puzzle. Mathematicians call that ‚Äúsolving the game.‚Äù They did it to Connect Four ‚Äì and you did it to tic-tac-toe, when you were little.&lt;/p&gt;
    &lt;p&gt;Good problems for games therefore all have the same characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They need to have answers that evolve as you dig in more ‚Äì so they need to have depth to them. Your first answer should only work for a while. There might be many paths to the solution, too. This is why so many games have a score ‚Äì it helps indicate how big a spread of solutions there are!&lt;/item&gt;
      &lt;item&gt;They need to have uncertain answers. (When you‚Äôre little, this universe is a lot larger than it is when you‚Äôre older ‚Äì peek-a-boo is uncertain up to a certain point!).&lt;/item&gt;
      &lt;item&gt;The problem should be something that can show up in a lot of situations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of very good problems seem stupidly simple, but have depths to them. Math ones, like ‚Äúwhat‚Äôs the best path to cross this yard?‚Äù but also story ones like ‚ÄúFor sale: baby shoes, never worn.‚Äù&lt;/p&gt;
    &lt;p&gt;I recently watched a video that included the statement that ‚Äúpicking up sticks‚Äù is not a useful loop. Picture a screen with a single stick in the middle. The problem posed is to move the cursor over it and click it. Once you do it, you get to do it again.&lt;/p&gt;
    &lt;p&gt;Guess what? The original Mac shipped with games that taught you how to move a mouse and click things. Once upon a time, mousing was a skill that was challenging; for all I know, you have grandparents who still have trouble with it. For them, it has uncertainty. For you, probably, it doesn‚Äôt.&lt;/p&gt;
    &lt;p&gt;Bottom line: the more uncertainty, indeterminacy, ambiguity in your game, the more depth it will have.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four: Loops&lt;/head&gt;
    &lt;p&gt;Now, imagine that the stick pops to a random location each time. Better, yes?&lt;/p&gt;
    &lt;p&gt;The core of a loop is a problem you encounter over and over again. ‚ÄúHow do I get the next one?‚Äù But something needs to be pushing back, that‚Äôs what makes it an interesting problem and is usually what takes it past being a puzzle. I like to say ‚Äúin every game, there is an opponent.‚Äù Even it‚Äôs just physics.&lt;/p&gt;
    &lt;p&gt;People talk about the core loop of a game. But there‚Äôs really two types of loops.&lt;/p&gt;
    &lt;p&gt;One is what we might think of as the operational loop. This is the loop between you and the problem, it is how you interact with it. You look at it. You form a hypothesis. You poke the problem. You see a result. Maybe it was success, and you grabbed the stick. Maybe it was failure. Maybe it was partial success. You update your hypothesis so you can decide what to do next.&lt;/p&gt;
    &lt;p&gt;The second loop is really your progression loop but is better thought of as a spiral. It‚Äôs what people usually mean when they say ‚Äúa game loop.‚Äù They mean picking up the stick over and over. I say it‚Äôs a spiral, because clicking on the same stick in the middle of the screen over and over is not usually how we design games. That would actually be repeatedly doing the same puzzle.&lt;/p&gt;
    &lt;p&gt;Instead, we move the stick on the screen each time, and maybe give you a time limit. Now there‚Äôs something you‚Äôre pushing against, and there‚Äôs a skill to exercise and patterns to try to recognize. Far more people will find this a diverting problem for a while. It‚Äôs a better game. It‚Äôll get even better if there are reasons why the stick appears in one place versus another, and the player can figure them out over time.&lt;/p&gt;
    &lt;p&gt;This matters: the verbs are in a loop. ‚ÄúPick up,‚Äù over and over. But the situation isn‚Äôt. And you are learning how to reduce uncertainty of the outcome: move the mouse here and click, next move it there. That‚Äôs why it is a spiral: it is spiraling to a conclusion. It‚Äôll be fun until it‚Äôs predictable.&lt;/p&gt;
    &lt;p&gt;You can think of the operational loop as how you turn the wheel, and the situations as the road you roll over. A spot on the wheel makes a progression spiral as you move. One machine, many situations ‚Äî we call these rules mechanics for a reason.&lt;/p&gt;
    &lt;p&gt;Bottom line: players need to understand how to use the machine, and the point is to gradually infer how it works by testing it against varied situations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Five: Feedback&lt;/head&gt;
    &lt;p&gt;You can‚Äôt learn and get better unless you get a whole host of information.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need to know what actions ‚Äì we usually call them verbs ‚Äî are even available to you. There‚Äôs a gas pedal.&lt;/item&gt;
      &lt;item&gt;You need to be able to tell you used a verb. You hear the engine growl as you press the pedal.&lt;/item&gt;
      &lt;item&gt;You need to see that the use of the verb affected the state of the problem, and how it changed. The spedometer moved!&lt;/item&gt;
      &lt;item&gt;You need to be told if the state of the problem is better for your goal, or worse. Did you mean to go this fast?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are fancy names for each of these, and you can go learn them all. Everything from ‚Äúaffordance‚Äù and ‚Äújuice,‚Äù to terms like ‚Äústate space‚Äù and ‚Äúperfect information‚Äù and very confusing contradictory uses of the words ‚Äúpositive‚Äù and ‚Äúnegative‚Äù paired with the word ‚Äúfeedback.‚Äù&lt;/p&gt;
    &lt;p&gt;Feedback in general can, and should be, delightful. That means it‚Äôs where you get to use all those forms of fun that I threw away at the beginning. It can be surprising. It can be a juicy multimedia extravaganza. It can be a deeply affecting tragic cutscene that advances the game story.&lt;/p&gt;
    &lt;p&gt;If you have too little feedback, players cannot go around the interaction loop. Picture Tetris if the piece you drop is invisible until it lands.&lt;/p&gt;
    &lt;p&gt;If you have bad feedback, players cannot go around the learning loop either. Picture Tetris if sometimes your score goes down when you complete a line and sometimes it goes up. You can‚Äôt draw any conclusions about what the problem in the way of the goal actually is, in that crappy version of Tetris. Feedback needs to act as a reward to help you draw conclusions.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs a third mistake: you can supply a gorgeous and compelling set of feedback and not actually have a real problem under there. At minimum you‚Äôre making shallow entertainment. At worst, you are building exploitative entertainment.&lt;/p&gt;
    &lt;p&gt;People will be willing to go along with pretty simple and pretty familiar problems as long as the feedback is great.&lt;/p&gt;
    &lt;p&gt;Bottom line: show what you can do, that you did it, what difference it made, and whether it helped.&lt;/p&gt;
    &lt;head rend="h3"&gt;Six: Variation and escalation&lt;/head&gt;
    &lt;p&gt;If you are trying to design and are thinking of a specific problem scenario you are not doing game systems design. You are doing level design. ‚ÄúHow to multiply numbers‚Äù is a problem. ‚ÄúWhat is 6 x 9‚Äù is not a problem, it‚Äôs content.&lt;/p&gt;
    &lt;p&gt;Now consider the game of Snake, or Pac-Man. They are also games where the core loop is picking up a stick. The difference is that something is an obstacle to you picking up the stick: you get longer when you pick up the stick, and can crash into yourself. You have to avoid ghosts as you gather the stick.&lt;/p&gt;
    &lt;p&gt;How long you are in Snake is a different situation. Where the apple to eat is located is a different situation. To be specific, you have the same problem in different topology. Where you are relative to the ghosts, and which dots are left, and what directions you can go in the maze are different situations in Pac-Man.&lt;/p&gt;
    &lt;p&gt;You want the verbs you use in the loop to end up confronting many many situations. If your verb can‚Äôt, your core loop is probably bad. Your core problem (aka your core game mechanic) is probably shallow.&lt;/p&gt;
    &lt;p&gt;What you want is to be able to throw increasingly complex situations at the player. That‚Äôs how they climb the learning ladder. Ideally, they should arrive at interim solutions (lots of words for that, too: heuristics, strategies) that later stop working.&lt;/p&gt;
    &lt;p&gt;Pac-Man actually got solved, by the way! That‚Äôs why Ms. Pac-Man was invented. Sometimes, the way to escalate is to change the rules, and that‚Äôs what Ms. Pac-Man did. It did it by adding randomness, and in fact using randomness is one of the biggest (and oldest) ways to create situation variation in games.&lt;/p&gt;
    &lt;p&gt;Bottom line: escalate the situations so that theories can be tested, refined, and abandoned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seven: Pacing and balance&lt;/head&gt;
    &lt;p&gt;Since we can put all this this down very much to problem solving and learning and mastery, it means we can steal a whole bunch of knowledge from other fields.&lt;/p&gt;
    &lt;p&gt;People learn best when they can experiment iteratively, which we also call ‚Äúpracticing.‚Äù That‚Äôs why loops make sense. There‚Äôs a lot of science out there about how to train, how to practice (and also a lot of educational theory that overlaps hugely), and your game will be better if it follows some of those guidelines.&lt;/p&gt;
    &lt;p&gt;People learn best when the problem they are tackling is right past the edge of what they can do. If it‚Äôs too far past that edge, they may not even be able to perceive the problem in the first place! And if the reverse is true and they see a solution instantly, they‚Äôll either be bored, or they might just do that over and over again and never develop any new strategies and not progress.&lt;/p&gt;
    &lt;p&gt;There‚Äôs an optimal pacing shape. It looks just like what you see in your literature textbooks when they diagram tension, or whatever: sort of like a rising sine wave. You start slow, then speed up, hit a peak challenge, then back off a bit, give a breather that falls back but not all the way, then speed up‚Ä¶ we have conventions for what to put at those peaks (bosses!). But what matters is the shape of the curve.&lt;/p&gt;
    &lt;p&gt;You need to structure your game so that you push players up. They might need to climb the curve at different paces, which is why you might also have difficulty sliders. They might not be capable of getting all the way to the top, and that‚Äôs okay.&lt;/p&gt;
    &lt;p&gt;You also need to pace to allow room for everything that isn‚Äôt mastering the problem ‚Äî such as having fun with friends socially. But at the same time, things to do in the game need to come along at the right pace too!&lt;/p&gt;
    &lt;p&gt;Bottom line: Vary intensity and pressure, give players a chance to practice and moments to be tested.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eight: Games are made of games&lt;/head&gt;
    &lt;p&gt;Remember the game about clicking on a stick that appeared at a random location on screen? That‚Äôs also a rail shooter. You move the mouse and click on a spot in 2d space. Which is also not that different from an FPS ‚Äî only now you move the camera, not the cursor.&lt;/p&gt;
    &lt;p&gt;Almost no games are made of only one loop. Instead, we chain loops together ‚Äì complete loop A, and it probably outputs something that may serve as a tool or constraint on a different loop.&lt;/p&gt;
    &lt;p&gt;An FPS has the problem of moving the camera (instead of the mouse) to click on the stick. It also has a loop around moving around in 3d space. Moving around is actually made of several loops, probably, because it may be made of running and jumping and spatial orientation. Those are all problem types!&lt;/p&gt;
    &lt;p&gt;We speak sometimes of value chains: that‚Äôs where one loop outputs something to the next loop. We speak also of game economies, which is what happens when loops connect in non-linear ways, more like a web. This is not the sort of economy where you are simulating money or commerce. Instead it‚Äôs a metaphor for stocks and flows and other aspects of actual system dynamics science. In this view, your hit points is a ‚Äústock‚Äù or, if you like, a ‚Äúcurrency‚Äù you spend in a fight.&lt;/p&gt;
    &lt;p&gt;Games nest fractally, they web into complex economies, and they unroll chains of linked loops. That‚Äôs why they can be diagrammed in a multitude of ways.&lt;/p&gt;
    &lt;p&gt;At heart though, you can decompose them all into those elemental small problems, each with an interaction loop and a learning loop centered on that problem.&lt;/p&gt;
    &lt;p&gt;Bottom line: build small problems into larger webs, and map them so you understand how they connect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nine: Actual systems design&lt;/head&gt;
    &lt;p&gt;The common question is ‚Äúokay, so how do I design a problem like that?‚Äù And that is indeed the unique bit in games, because the other items here are common to lots of other fields.&lt;/p&gt;
    &lt;p&gt;The list of possible problems is, as mentioned, enormous. This is a big rabbit hole. And once you consider that you can stack, web, and otherwise interlink problems, it means that there‚Äôs a giant composable universe of games (and game variants) to create.&lt;/p&gt;
    &lt;p&gt;Just bear in mind that because of varied tastes and experience, the diversity of the set of problems you pose is going to affect who wants to play your game.&lt;/p&gt;
    &lt;p&gt;There are basically a set of categories of problems that we know work, and this is the absolute simplest version of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mathematically complex puzzles&lt;/item&gt;
      &lt;item&gt;Figuring out how other humans think&lt;/item&gt;
      &lt;item&gt;Mastering your body and brain&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These break down into a ton of sub-problems, but there are less than you think, and you can actually find lists of them. The hard part is that often they each seem so small and trivial that we don‚Äôt think of them as actually being worth looking at!&lt;/p&gt;
    &lt;p&gt;They are also often in disguise: the problem behind where a tossed ball will land, and the problem of how much fuel you have left in your car if you keep driving at this speed, and the problem of when your hit points will run out given you have a poison status effect on you are the same thing.&lt;/p&gt;
    &lt;p&gt;But the more of them you as a designer have wrapped your head around, the more you can combine. And you‚Äôll find them very plastic and malleable. In fact, you could almost make a YouTube video about each one.&lt;/p&gt;
    &lt;p&gt;So where do you get them? Steal them. Other games, sure, but also, the world is full of systems that pose tough problems. You can grab them and reskin them.&lt;/p&gt;
    &lt;p&gt;Bottom line: not every mechanic has been invented, but a ton have. Build your catalog and workbench.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ten: Dressing and experience&lt;/head&gt;
    &lt;p&gt;In the end, the feedback layer of a game is everything about how you present it. The setting, the lore, the audio, the story, the art‚Ä¶&lt;/p&gt;
    &lt;p&gt;How you dress up the problems can change everything about how the player learns from it, and how they perceive the problem. The exact same underlying problem can be as different as picking up sticks or shooting someone in the face, or as mentioned, the calculus problem of estimating the trajectory of a variable in a system of rates of change (the ball, the car and its gas, the hit points and poison) might be the same but dressed extraordinarily differently.&lt;/p&gt;
    &lt;p&gt;When you think about how you dress up the problems, you are in the realm of metaphor. You are engaging in painting, poetry, and music composition, and rhetoric, and the bardic tradition, and all that other humanities stuff.&lt;/p&gt;
    &lt;p&gt;This is a giant and deep universe for you as a designer to dive into. A lot of this stuff gets called ‚Äúgame design,‚Äù but then again, we also often say that a given game designer is a frustrated moviemaker, too.&lt;/p&gt;
    &lt;p&gt;It is really easy to create an experience that clashes with the underlying problems it is teaching. There are fancy critical terms for this. You also need to be very conscious about whether you are building your game so that you are telling the player a story, or so that the player can tell stories with your game.&lt;/p&gt;
    &lt;p&gt;So the takeaway should be: this stuff is deeply, deeply synergistic with the ‚Äúgame system‚Äù stuff that this article is about, but they are not the same thing. And games is not the best place to learn how to do these things.&lt;/p&gt;
    &lt;p&gt;Those other fields have much longer traditions and loads of expertise and lessons. They won‚Äôt all apply to the issue of ‚Äúhow do I best dress up this collection of problems‚Äù but most of them will.&lt;/p&gt;
    &lt;p&gt;It does not frickin‚Äô matter if you start out wanting to make interesting problems, or if you start out wanting to provide a cool experience. You are going to need to do both to make the game really good.&lt;/p&gt;
    &lt;p&gt;Bottom line: game development is a compound art form. You can go learn those individual arts and the part unique to games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eleven: Motivations&lt;/head&gt;
    &lt;p&gt;Researchers have done a ton of studying ‚Äúwhy people play games.‚Äù This gets called ‚Äúmotivations.‚Äù&lt;/p&gt;
    &lt;p&gt;Motivations are basically about people‚Äôs personal taste for groups of problems and how those problems are presented, and characteristics of those problems and the situations in which you find them. Some people like problems where you destroy stuff. Others like problems where you bond with others. Some have trouble trusting other people. Others want to cooperate.&lt;/p&gt;
    &lt;p&gt;Not everyone likes the same sorts of problems or the same sorts of dressings. Some of this is down to personality types, some of it is down to social dynamics, how they were raised, what their local culture is like, what trauma they have had, and countless other psychological things. That‚Äôs why one fancy term for this is psychographics.&lt;/p&gt;
    &lt;p&gt;The big thing is, it‚Äôs not enough that the problems need to not be obvious to you, and also not be baffling to you. They also have to be interesting to you. What problems fit in that range is going to depend entirely on who you are, what your life experiences have been, what skills you have, and even what mood you are in.&lt;/p&gt;
    &lt;p&gt;Picking motivations and selecting problems based on them is a great way to design. But motivations are not the same thing as fun. They‚Äôre a filter, useful in marketing exercises and in building your game pillars (which is an exercise in focus and scope).&lt;/p&gt;
    &lt;p&gt;Scientists have spent a bunch of time surveying tons of people and have arrived at all sorts of conclusions that map people onto reasons to play and from there onto particular problems.&lt;/p&gt;
    &lt;p&gt;If you start with motivations, then you can go from there to types of problems, types of experience, and even player demographics. And then, if you want problems that are about interacting with people, well, there‚Äôs lists of those. If you want problems that are about managing resources, or solving math issues, there‚Äôs lists of those too.&lt;/p&gt;
    &lt;p&gt;Bottom line: no game is for everyone, so you will make better games if you know who you are posing problems for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Twelve: It‚Äôs simple, but not&lt;/head&gt;
    &lt;p&gt;I run into game developers who do not understand the above eleven steps all the time. And understanding all eleven is more valuable than building expertise in just one, because they depend on one another. This is because getting any one of the eleven wrong can break your game. The real issue is that each of these eleven things is often multiple fields of study. And yeah, you do need to become expert in at least one.&lt;/p&gt;
    &lt;p&gt;To pick one example, some of us have been working out the rule set for how you can link loops into a larger network of problems for literally over twenty years.&lt;/p&gt;
    &lt;p&gt;Others have spent their entire career doing nothing but figuring out how best to provide just the affordances part of feedback.&lt;/p&gt;
    &lt;p&gt;So game design is pretty simple. But the devil is in details that are not very far below the surface. It‚Äôs fairly easy to explain why something is fun for an given audience. It is much harder to build something new that is fun for an arbitrary person. That said, every single one of those fields has best practices, and they are mostly already written down. It‚Äôs just a lot to learn.&lt;/p&gt;
    &lt;p&gt;Put another way ‚Äî every single paragraph in this essay could be a book. Actually, probably already is several.&lt;/p&gt;
    &lt;p&gt;Bottom line: each of these topics is deep, but you want a smattering of all of them.&lt;/p&gt;
    &lt;p&gt;Some of you may not like this deconstructive view on how games are designed. That‚Äôs okay. Personally, I find it best to poke and prod at a problem, like ‚Äúhow do I get better at making games?‚Äù and treat it as a game. And that‚Äôs what I have done my whole career. The above is just my strategy guide. Someone else will have different strategies, I guarantee it.&lt;/p&gt;
    &lt;p&gt;But I also guarantee that if you get better at the above twelve things, you will get better at making games. This is a pragmatic list. And it will be helpful for making narrative games, puzzle games, boardgames, action games, RPGs, whatever. I breezed through it, but there are very specific tools you can pick up underneath each of these twelve things. It really is that simple, but also that hard, because that‚Äôs a frickin‚Äô long list if you want to actually dive into each of the twelve.&lt;/p&gt;
    &lt;p&gt;What that also means is that people designing games fail a lot at it. You might say, ‚Äúcan‚Äôt they just do the part they know how to do, and therefore predictably make good games?‚Äù&lt;/p&gt;
    &lt;p&gt;No, because players learn along with the designers. If you just make the same game, the one you know how to make, the players get bored because it‚Äôs nothing but problems they have seen before and already have their answers to. Sometimes, they get so bored that an entire genre dies.&lt;/p&gt;
    &lt;p&gt;And if you instead make it super-complicated by adding more problems, it might dissolve into noise for most people. Then nobody plays it. And then the genre dies too!&lt;/p&gt;
    &lt;p&gt;Game designers will routinely fail at making something fun. When the game of making games is played right, it is always right outside the edge of what the designers know how to do.&lt;/p&gt;
    &lt;p&gt;That‚Äôs where the fun lives, not just for the designer, but also for their audience.&lt;/p&gt;
    &lt;p&gt;That‚Äôs it, the whole cheat sheet. That‚Äôs it.&lt;/p&gt;
    &lt;p&gt;Hope it helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45841262</guid><pubDate>Thu, 06 Nov 2025 22:24:23 +0000</pubDate></item><item><title>The secret campaign to silence critics of a hospital real estate empire</title><link>https://www.motherjones.com/politics/2025/10/medical-properties-trust-mpt-steward-health-care-ed-aldag-secret-campaign-critics-surveillance-reit/</link><description>&lt;doc fingerprint="be70d91b88f3d583"&gt;
  &lt;main&gt;
    &lt;p&gt;By the spring of 2022, Ed Aldag was fed up. The 61-year-old CEO of a multibillion-dollar real estate company called Medical Properties Trust, Aldag is a high-society fixture in the company‚Äôs hometown of Birmingham, Alabama, where MPT has donated millions to local nonprofits and where he‚Äôs regularly listed as one of the city‚Äôs most influential businessmen. But for years, Aldag had watched as MPT faced tough questions from the federal government, investors, and, most recently, a series of articles in the Wall Street Journal.&lt;/p&gt;
    &lt;p&gt;MPT makes money by acting as a landlord: It buys hospitals and then rents the facilities back to providers. Over the previous year, the Journal had published several stories that focused on the company‚Äôs finances, including reporting that dug into MPT‚Äôs biggest tenant‚ÄîSteward Health Care, then one of the largest for-profit hospital operators in the nation‚Äîand the unusually close financial relationship between the two companies.&lt;/p&gt;
    &lt;p&gt;The Journal‚Äôs pieces raised concerns about whether Steward was struggling‚Äîand whether MPT was engaging in secret transactions to keep it afloat. Mother Jones and others would later report how Steward‚Äôs financial mismanagement harmed hundreds of people: We found 83 deaths across its 39 hospitals, hundreds of malpractice lawsuits, and more than 700 patient care problems documented in federal hospital inspections. The Journal, meanwhile, was the first to notice this mismanagement at work, revealing that Steward hospitals owed nearly $1 billion to medical supply companies and other vendors.&lt;/p&gt;
    &lt;p&gt;That reporting was the beginning of years of intense scrutiny of MPT in the world of finance that hurt the company‚Äôs stock price and eventually led, earlier this month, to a trio of Democratic US senators proposing the ‚ÄúStop Medical Profiteering and Theft (MPT) Act‚Äù to impose limits on the company‚Äôs business. But it was also the apparent start of an aggressive, previously unreported campaign by Steward, MPT, and other still-unknown actors to silence their critics. Internal documents obtained by the Organized Crime and Corruption Reporting Project (OCCRP) and shared with Mother Jones show that MPT amassed an army of crisis management professionals to protect its reputation, eventually working alongside three different crisis public relations firms, five law firms, and two private intelligence firms. The documents, along with information from sources close to this effort, show a major effort to control the narrative: In one tense email exchange in March 2022, Aldag wrote to a PR firm, ‚ÄúWe cannot let a deranged pretend journalist tell a false story of MPT.‚Äù&lt;/p&gt;
    &lt;p&gt;As part of a social media push that used anonymous accounts to discredit and intimidate the growing chorus of journalists, investment analysts, and short sellers who questioned the company, an intelligence firm baited MPT‚Äôs detractors online. And while the Boston Globe and OCCRP reported last year that Steward paid the British firm Audere International to surveil one particularly provocative MPT critic, new documents show a much broader tracking campaign, funded in part by Steward and other shadowy actors but focused on MPT, targeting a half dozen of the company‚Äôs skeptics.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey were always looking for something explosive that would make things go away,‚Äù a source close to Audere wrote in messages reviewed by Mother Jones that were confirmed with the source directly. ‚ÄúAlthough Steward was the customer, it was clear that MPT was what Audere was protecting.‚Äù&lt;/p&gt;
    &lt;p&gt;An MPT spokesperson did not respond to a detailed list of questions but made clear in an emailed statement that the company disagrees with the many critics questioning its business practices. The company, the spokesperson said, ‚Äúhas unfailingly disclosed each of its transactions as and when required under applicable securities laws.‚Äù&lt;/p&gt;
    &lt;p&gt;The spokesperson also said that as criticism of MPT has mounted, its executives and their families have been harassed, including receiving death threats: ‚ÄúAs any responsible company in that position would do, we have periodically engaged advisors to help navigate this situation.‚Äù The spokesperson added: ‚ÄúIt is critical to note that MPT has never directly or indirectly engaged with detractors on social media, nor have we paid any third-party to do so.‚Äù&lt;/p&gt;
    &lt;p&gt;The company‚Äôs damage control started in earnest with the lead reporter behind the Journal‚Äôs stories, Brian Spegele. His reporting on MPT began in 2021, when a number of its tenant hospitals across the country‚Äîa Steward hospital in Pennsylvania, and ones owned by other for-profit operators in Wyoming and Rhode Island‚Äîall seemed to be running into financial issues. While these facilities struggled, MPT was hitting its highest stock price ever.&lt;/p&gt;
    &lt;p&gt;Spegele emailed MPT with questions about how it was running its business‚Äîand how it might be affecting hospitals. He‚Äôd heard from insiders that MPT was overpaying for hospitals because higher sale values meant they could charge higher rents. Did the company want to comment? Why had one of their hospitals in Ohio shut down not long after it started renting from MPT? Did the company really have three corporate jets?&lt;/p&gt;
    &lt;p&gt;In dozens of leaked emails, Aldag strategized with other leaders over how to respond. They brought in the crisis PR firm Joele Frank to help, as well as a law firm that specializes in filing defamation cases against journalists, Clare Locke. They asked their PR firm to speak with Spegele and suss out the angle of his upcoming article and questioned whether the Journal was working to short their stock. Was the paper hinting to investors that MPT was going to fail?&lt;/p&gt;
    &lt;p&gt;In December 2021, Clare Locke sent a letter to the Journal‚Äôs legal team and top editors, threatening to sue the paper before Spegele had even published his next story and demanding that he reveal his sources. The following month, MPT‚Äôs stock hit a new high: about $24 per share. Not long after, the paper‚Äôs lawyer sent an email to Clare Locke, noting that Spegele had experienced ‚Äúsome security concerns,‚Äù and he wanted to discuss them on the phone. (Spegele declined to comment; a Wall Street Journal spokesperson did not answer specific questions but noted, ‚ÄúThe safety and security of our reporters is of paramount importance. While we won‚Äôt discuss the details of the protective measures we take, we stand by the Journal‚Äôs in-depth and consequential reporting on Medical Properties Trust.‚Äù Clare Locke and Joele Frank also did not respond to questions.)&lt;/p&gt;
    &lt;p&gt;The Journal published Spegele‚Äôs piece in February 2022. It claimed that MPT was quietly infusing hundreds of millions into Steward through complex loans and other means, enabling its hospitals to continue to pay rent. This meant that MPT‚Äôs largest tenant was actually struggling, which boded poorly for MPT, as well. Yet the article also pointed out executives‚Äô excessive spending on things like Aldag‚Äôs multimillion-dollar salary and the regular use of the company‚Äôs private jets. Investors started emailing and calling MPT, and its stock price began to slide.&lt;/p&gt;
    &lt;p&gt;Spegele soon started working on another story, about an MPT-owned hospital in California. His continued requests for comment angered Aldag.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm tired of this guy,‚Äù Aldag wrote, adding that the former employees Spegele had cited anonymously were ‚Äúabsolutely fake.‚Äù Then he called his team to action: ‚ÄúWe already know what he is going to say and I refuse to let him tell the story‚Ä¶We need to devise a plan to be proactive in our storytelling outside of the WSJ.‚Äù He told his PR advisers that if this wasn‚Äôt a project they could take on, he imagined they could find other companies to help.&lt;/p&gt;
    &lt;p&gt;‚ÄúLadies,‚Äù he wrote, ‚Äúit‚Äôs time we go on the offensive.‚Äù&lt;/p&gt;
    &lt;p&gt;Investment analyst Rob Simone thought there was something to the Journal‚Äôs stories. He worked at a research firm called Hedgeye, and soon he started digging into whatever public information he could find about MPT.&lt;/p&gt;
    &lt;p&gt;He was struck by the fact that MPT seemed to be at the root of Steward‚Äôs financial issues‚Äîand its hospitals‚Äô increasing problems paying their bills. According to our own analysis, by 2022, at least four health care companies that had lease agreements with MPT had gone bankrupt, shutting down hospitals or throwing them into uncertainty.&lt;/p&gt;
    &lt;p&gt;Simone told Hedgeye‚Äôs paid subscribers in April 2022 that MPT was sinking hospitals instead of helping them, by saddling their operations with leases they couldn‚Äôt afford. He claimed that beneath its veneer of success, Steward ‚Äúappears to be insolvent‚Äù and that its dwindling finances likely meant future trouble for MPT, which he suggested was quietly infusing money into Steward to help it pay rent. And he wondered about the compensation that MPT‚Äôs board of directors (which includes Aldag and the company‚Äôs CFO) had green-lit for executives, while Steward and some of their other tenants were financially struggling. He recommended shorting the stock.&lt;/p&gt;
    &lt;p&gt;‚ÄúI just started doing work on this and became fascinated and thought it was a real problem‚Äîand that problem kept getting worse, and so I kept writing about it,‚Äù Simone told us when we spoke last year. ‚ÄúIt never, never, ever improved.‚Äù&lt;/p&gt;
    &lt;p&gt;MPT leadership pilloried Simone‚Äôs research on the company‚Äôs next earnings call. But Simone‚Äôs reports about MPT continued to gain traction on Twitter and investing websites, especially as the company‚Äôs stock price started to dip, from around $20 to $15 in the summer of 2022.&lt;/p&gt;
    &lt;p&gt;And Simone wasn‚Äôt alone. A writer who called himself @BigRiverCapita1 was making similar claims on social media and Wall Street blogs. The account was anonymous but clearly well versed in finance, pointing out past bankruptcies of MPT‚Äôs tenants and questioning whether these hospitals were struggling, shutting down, or cutting back patient care due to their pricey leases with MPT.&lt;/p&gt;
    &lt;p&gt;Around then is when Audere, the British private intelligence firm, got involved. According to OCCRP and the Boston Globe, Steward had already been paying Audere to surveil its critics for a few years‚Äîeventually spending more than $7 million on these operations. But as Big River‚Äôs posts and Simone‚Äôs research spread, and more investors began to short MPT and drag down its stock price, Audere‚Äôs work increasingly focused on those critical of the publicly traded landlord, even as its tenant Steward remained Audere‚Äôs client, according to leaked documents and sources close to Audere. (An Audere spokesperson told Mother Jones that the company cannot answer questions about its confidential work, but that Audere ‚Äútakes its legal and regulatory compliance obligations seriously and acts in accordance with the same.‚Äù)&lt;/p&gt;
    &lt;p&gt;In June 2022, Audere hired a contractor to start looking into these critics, leaked emails show. They named the operation ‚ÄúProject Morden.‚Äù They told the contractor they had two main goals: Dig into why Rob Simone was writing about MPW (they referred to MPT by its stock ticker symbol), and identify the person behind @BigRiverCapita1:&lt;/p&gt;
    &lt;p&gt;A strategy memo noted that ‚Äúmultiple financial professionals believe that RS [Rob Simone] does not have the capacity to drive MPW downward.‚Äù Still, the firm demanded an aggressive approach to Big River and Simone, whom they deemed Target 1 and Target 2.&lt;/p&gt;
    &lt;p&gt;‚ÄúUncover the subjects (sic) vulnerabilities and pressure points,‚Äù the memo urged, suggesting the contractor unearth details about ‚Äúcareer, integrity, personal life and identify any potential misconduct.‚Äù&lt;/p&gt;
    &lt;p&gt;And that, Simone said, is when the trouble started.&lt;/p&gt;
    &lt;p&gt;Anonymous Twitter accounts started to follow and harass him, asking if he had security and even tweeting that ‚Äúhis life [was] in danger.‚Äù Simone‚Äôs company, Hedgeye, grew concerned about this safety and provided him with enhanced security, but neither they nor Simone ever figured out who was behind the accounts. One tweet even warned that if he didn‚Äôt stop reporting and tweeting about MPT, ‚Äúhe could end up like Daphne,‚Äù an allusion to the murder of the Maltese journalist Daphne Caruana Galizia, who was killed after reporting on a Steward hospital deal in Malta in 2017.&lt;/p&gt;
    &lt;p&gt;MPT‚Äôs leaders also began to meticulously track their detractors. By October 2022, they were keeping tabs on all the skeptics dialing in to their public earnings calls and even discussed not taking their questions: ‚ÄúPlease make us a list of all the bad actors that listened in,‚Äù Aldag wrote to top executives in an email. They sent back a lengthy list that included nearly 20 professional financial analysts, including Simone.&lt;/p&gt;
    &lt;p&gt;The following month, MPT received Audere‚Äôs intelligence reports over email. And soon, Audere further ramped up its campaign against Simone, even hiring a contractor to create a fake blog written from the perspective of a woman trying to hold investment analysts to account. But its true goal was to criticize just one player: Hedgeye. It was called ‚ÄúHedge Spy.‚Äù (After Mother Jones and Reveal mentioned this contractor‚Äôs work in previous reporting, the blog was taken down from the internet.)&lt;/p&gt;
    &lt;p&gt;Initially the blog was populated with stories that cast doubt on a variety of firms, as the contract writer explained to Audere in emails reviewed by Mother Jones. ‚ÄúThe more general content will disguise the blog‚Äôs objective,‚Äù wrote the contractor.&lt;/p&gt;
    &lt;p&gt;The contractor also launched a Reddit account, Loud-Peanut-7716, whose goal was ‚Äúto actively engage in discussions and facilitate the conversations concerning Hedgeye.‚Äù In an email to Audere, the contractor listed some of the Reddit posts trying to discredit Simone‚Äôs firm:&lt;/p&gt;
    &lt;p&gt;‚ÄúCan you recommend any research platforms? I tried Hedgeye but I don‚Äôt trust them after their recent dirty tricks stalking and intimidating their competitors‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThey don‚Äôt care about making us rich, they want to make THEMSELVES rich! DO YOUR OWN RESEARCH!‚Äù&lt;/p&gt;
    &lt;p&gt;At the start of 2023, a new critic took on MPT, publishing a series of reports with cheeky titles and provocative tweets that alleged MPT was committing a brazen financial fraud.&lt;/p&gt;
    &lt;p&gt;That voice was a British investor named Fraser Perring. Perring runs a short-selling firm called Viceroy Research that makes big financial bets on companies it thinks will fail, digging deep into their financials to see if they might be hiding something. He has tens of thousands of followers on social media, where he often posts his findings and claims of corporate wrongdoing.&lt;/p&gt;
    &lt;p&gt;In January of that year, Viceroy published the first of what would be several reports on MPT. Titled ‚ÄúMedical Properties (dis)Trust,‚Äù the report arrived at many of the same conclusions that had been swirling around Wall Street: Steward was going belly up, and MPT seemed to be secretly funneling it money to stave off bankruptcy. And perhaps more clearly than anyone before, Viceroy accused MPT of ‚Äúround-tripping‚Äù: Not only was it loaning money to help Steward pay rent, but it was then recording this rent as new earnings and not disclosing it, all to maintain the illusion that it was a healthy landlord.&lt;/p&gt;
    &lt;p&gt;Viceroy‚Äôs report sent MPT executives into a tizzy. Leaked documents show the company was scrutinizing Perring‚Äôs tweets alleging round-tripping, with executives furiously sharing them with one another and one of their PR firms compiling them all.&lt;/p&gt;
    &lt;p&gt;Management soon would help fuel a conspiracy theory that was already growing at MPT: that their critics‚Äîfrom Simone to the Wall Street Journal‚Äîwere working together to short their stock and bring them down.&lt;/p&gt;
    &lt;p&gt;Around that time, social media trolling of Simone and Perring ramped up. On top of that, reporting from the Boston Globe and OCCRP shows that a security firm contracted by Audere videotaped Perring at his home and watched him around his neighborhood‚Äîeven following him and his daughter on their way back from school. When MPT sued Viceroy the following month for defamation, it denied all of Perring‚Äôs findings, writing that they were ‚Äúmalicious fiction‚Äù and had ‚Äúcaused serious harm to MPT.‚Äù But during litigation, according to court documents, Viceroy‚Äôs lawyers said an impostor had called Perring‚Äôs bank in the weeks leading up to MPT‚Äôs suit and pretended to be him. It‚Äôs unclear who was behind the impostor, who was able to gain access to Perring‚Äôs financial transactions; soon those details were included in a report sent to Audere. No money was stolen, but in reports to Audere the impersonator tried to figure out what Perring was spending his money on. (MPT, which agreed to settle the defamation case last December, said in a statement that it hired Audere in late 2022 for work unrelated to Perring.)&lt;/p&gt;
    &lt;p&gt;A few months later, when JP Morgan recommended that investors view the company‚Äôs stock with caution, emails show that MPT‚Äôs top executives circulated a lengthy list of analysts they believed were somehow connected to each other. They named five different investment funds and investors, and the many possible ways they were ‚Äúconnected‚Äù‚Äîto each other, to a Journal reporter, to Hedgeye, to Viceroy, even to liberal megadonor George Soros. And they wondered if anyone in their ‚Äúarmy of advisors‚Äù had an in with regulators. Included on that email chain was exactly that kind of connection, someone who used to run the Consumer Financial Protection Bureau: Mick Mulvaney.&lt;/p&gt;
    &lt;p&gt;Mulvaney, who also had been President Donald Trump‚Äôs acting chief of staff, was helping to run a consulting firm called Actum. Leaked emails show that MPT brought Actum on to help it ‚Äúcombat‚Äù what they saw as people conspiring to target the company. To counter their criticisms, Actum drafted a white paper praising MPT, calling it a company ‚Äúinvesting in the future of health care and communities.‚Äù (Actum did not respond to questions from Mother Jones.)&lt;/p&gt;
    &lt;p&gt;Reputation management is common among publicly traded companies, notes Jo-Ellen Pozner, a professor of business at Santa Clara University who studies corporate conduct and ethics. But the scale and expense of the effort to manage MPT‚Äôs PR crises is ‚Äúunequivocally not normal,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe fact that these folks were so willing to waste company resources‚Äîspend significant amounts of money that could have been diverted to more productive uses‚Äîto investigate journalists, to investigate investment analysts, it suggests to me that they are spying, and think that everybody else is doing the same,‚Äù Pozner said.&lt;/p&gt;
    &lt;p&gt;While MPT focused on its value and reputation, patient care issues at its Steward hospitals began to reach crisis levels. Under the weight of years of high rents to MPT, these facilities had failed to pay on-call doctors, nurse staffing agencies, repairmen, and suppliers of everything from blood to hospital beds. Eventually, some Steward hospitals couldn‚Äôt afford to keep paying MPT rent and closed.&lt;/p&gt;
    &lt;p&gt;These troubles further drove MPT‚Äôs stock price down. In October 2023, when it dipped below $5, Aldag recorded a message to shareholders, telling them he remained confident in ‚ÄúMPT‚Äôs proven business model‚Äù for investing in and improving hospitals.&lt;/p&gt;
    &lt;p&gt;At one of them, St. Elizabeth‚Äôs in Massachusetts, a crisis had begun to unfold. The hospital owed more than $500,000 to a company that made devices used to stem internal bleeding called embolism coils; the supplier recently had come to repossess the coils.&lt;/p&gt;
    &lt;p&gt;Two weeks after Aldag posted the video reassuring shareholders, a first-time mom named Sungida Rashid delivered a baby girl at St. Elizabeth‚Äôs. Hours later, Rashid began to bleed severely, doctors discovered they didn‚Äôt have the embolism coil needed to treat her, and she died. Her family‚Äôs tragedy would set in motion articles and hearings and subpoenas trying to understand the financial dealings of MPT and Steward. It had taken years‚Äîand a mother‚Äôs life‚Äîfor the story to finally come to light.&lt;/p&gt;
    &lt;p&gt;Additional reporting by Khadija Sharife.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45841910</guid><pubDate>Thu, 06 Nov 2025 23:39:07 +0000</pubDate></item><item><title>Scientists find ways to boost memory in aging brains</title><link>https://news.vt.edu/articles/2025/10/cals-jarome-improving-memory.html</link><description>&lt;doc fingerprint="b47e5585fcb1a6c0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Scientists find ways to boost memory in aging brains&lt;/head&gt;
    &lt;p&gt;In two separate studies, Virginia Tech researchers identified age-related molecular changes in the brain and adjusted them to improve memory.&lt;/p&gt;
    &lt;p&gt;Memory loss may not simply be a symptom of getting older. New research from Virginia Tech shows that it‚Äôs tied to specific molecular changes in the brain and that adjusting those processes can improve memory.&lt;/p&gt;
    &lt;p&gt;In two complementary studies, Timothy Jarome, associate professor in the College of Agriculture and Life Sciences‚Äô School of Animal Sciences, and his graduate students used gene-editing tools to target those age-related changes to improve memory performance in older subjects. The work was conducted on rats, a standard model for studying how memory changes with age.&lt;/p&gt;
    &lt;p&gt;‚ÄúMemory loss affects more than a third of people over 70, and it‚Äôs a major risk factor for Alzheimer‚Äôs disease,‚Äù said Jarome, who also holds an appointment in the School of Neuroscience. ‚ÄúThis work shows that memory decline is linked to specific molecular changes that can be targeted and studied. If we can understand what‚Äôs driving it at the molecular level, we can start to understand what goes wrong in dementia and eventually use that knowledge to guide new approaches to treatment.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting memory loss in two key brain regions&lt;/head&gt;
    &lt;p&gt;In the first study, published in the journal Neuroscience and led by Jarome and doctoral student Yeeun Bae, the team examined a process called K63 polyubiquitination. This process acts as a molecular tagging system that tells proteins inside the brain how to behave. When the system functions normally, it helps brain cells communicate and form memories.&lt;/p&gt;
    &lt;p&gt;Jarome and his team found that aging disrupts K63 polyubiquitination in two distinct areas of the brain. In the hippocampus, which helps form and retrieve memories, levels of K63 polyubiquitination increase with age. Using the CRISPR-dCas13 RNA editing system to reduce these levels, the researchers were able to improve memory in older rats.&lt;/p&gt;
    &lt;p&gt;In the amygdala, which is important for emotional memory, the researchers noted that K63 polyubiquitination declines with age. By reducing it even further, they were able to boost memory in older rats.&lt;/p&gt;
    &lt;p&gt;‚ÄúTogether, these findings reveal the important functions of K63 polyubiquitination in the brain‚Äôs aging process,‚Äù Jarome said. ‚ÄúIn both regions, adjusting this one molecular process helped improve memory.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Reactivating a gene that supports memory&lt;/head&gt;
    &lt;p&gt;A second study, published in the Brain Research Bulletin and led by Jarome with doctoral student Shannon Kincaid, focused on IGF2, a growth-factor gene that supports memory formation. As the brain ages, IGF2 activity drops as the gene becomes chemically silenced in the hippocampus.&lt;/p&gt;
    &lt;p&gt;‚ÄúIGF2 is one of a small number of genes in our DNA that‚Äôs imprinted, which means it‚Äôs expressed from only one parental copy,‚Äù Jarome said. ‚ÄúWhen that single copy starts to shut down with age, you lose its benefit.‚Äù&lt;/p&gt;
    &lt;p&gt;The researchers found that this silencing happens through DNA methylation, a natural process in which chemical tags accumulate on the gene and switch it off. Using a precise gene-editing tool, CRISPR-dCas9, they removed those tags and reactivated the gene. The result was better memory in older rats.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe essentially turned the gene back on,‚Äù Jarome said. ‚ÄúWhen we did that, the older animals performed much better. Middle-aged animals that didn‚Äôt yet have memory problems weren‚Äôt affected, which tells us timing matters. You have to intervene when things start to go wrong.‚Äù&lt;/p&gt;
    &lt;p&gt;Together, the two studies show that memory loss is not caused by a single molecule or pathway and that multiple molecular systems likely contribute to how the brain ages.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe tend to look at one molecule at a time, but the reality is that many things are happening at once,‚Äù he said. ‚ÄúIf we want to understand why memory declines with age or why we develop Alzheimer‚Äôs disease, we have to look at the broader picture.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Collaborative, graduate-led research&lt;/head&gt;
    &lt;p&gt;Both studies were driven by graduate researchers in Jarome‚Äôs lab and supported through collaborations with scientists at Rosalind Franklin University, Indiana University, and Penn State. Yeeun Bae, who completed her doctoral work with Jarome in the School of Animal Sciences, led the study on K63 polyubiquitination. Shannon Kincaid, a doctoral student in the same program, led the study on IGF2.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese projects represent the kind of graduate-led, collaborative research that defines our work,‚Äù Jarome said. ‚ÄúOur students are deeply involved in designing experiments, analyzing data, and helping shape the scientific questions we pursue.‚Äù&lt;/p&gt;
    &lt;p&gt;The research was supported by the National Institutes of Health and the American Federation for Aging Research.&lt;/p&gt;
    &lt;p&gt;‚ÄúEveryone has some memory decline as they get older,‚Äù he said. ‚ÄúBut when it becomes abnormal, the risk for Alzheimer‚Äôs disease rises. What we‚Äôre learning is that some of those changes happening at a molecular level can be corrected ‚Äî and that gives us a path forward to potential treatments.‚Äù&lt;/p&gt;
    &lt;p&gt;Original study: https://doi.org/10.1016/j.neuroscience.2025.06.032&lt;/p&gt;
    &lt;p&gt;Original study: https://doi.org/10.1016/j.brainresbull.2025.111509&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842263</guid><pubDate>Fri, 07 Nov 2025 00:22:53 +0000</pubDate></item><item><title>A Note on Fil-C</title><link>https://graydon2.dreamwidth.org/320265.html</link><description>&lt;doc fingerprint="32f9102154c525bd"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;A note on Fil-C&lt;/head&gt;Nov. 5th, 2025 12:28 pm&lt;p&gt; graydon2&lt;/p&gt;&lt;p&gt;Filip Pizlo recently released a (solo!) project called Fil-C that adds a memory-safety instrumentation pass to clang (for spatial safety -- out-of-bounds accesses), along with a runtime support library and a concurrent GC (for temporal safety -- use after free). It is, by the standards of such tools, highly compatible with existing code -- so much so that building a full linux distro userspace seems likely within reach with only modest patching effort. The stated performance overheads (measured by Dan Bernstein at "about 1-4x cycles") are by modern standards "probably tolerable" for many workloads (EDIT: also see a few initial measurements I made with the "optfilc" tools -- I did less-micro benchmarks and found a wider range), especially stuff that's IO bound or not otherwise straining for maximum performance.&lt;lb/&gt;I'm happy to see this work exist. It builds on a long line of academic and industrial work in this space (that Pizlo happily cites), including his own many years of iteration on the subject while at Apple. If I understand correctly, some of those earlier iterations are already in production in security sensitive code. I recall talking with Pizlo about these prototypes when I was at Apple too, and I'm pleased to see the work maturing to its current state.&lt;lb/&gt;(He also makes an interesting point that the bounds checking Fil-C inserts can make pointer-twiddling C code safer than pointer-twiddling unsafe Rust. This seems likely true! And it would be interesting to know if there's a way to have the best of both worlds, eg. if his instrumentation pass could be adapted to compile otherwise-full-speed optimized unsafe Rust blocks with a little bit of systematic compiler-injected bounds checking, perhaps derived from Rust's strict pointer provenance? Obviously this wouldn't be appealing for folks who use unsafe blocks for speed, but I think a lot are for other reasons and might enjoy an extra layer of checks. This is well beyond anything I know anymore, sadly I've long since lost track of what rustc can or can't do. Just speculating, but it seems to me that most unsafe Rust code doesn't allocate or free or interact with an allocator at all, so you'd want to drive it from something other than allocator, could probably still omit the GC.)&lt;lb/&gt;Naturally Fil-C has some caveats (if we're comparing to Rust, say, or other PLs with restrictions on mutable aliasing):&lt;lb/&gt;In any event, I only mention those caveats because they're the sort of thing that motivated languages like Rust in the first place. There have been memory-safe, bounds-checked and GC'ed AOT-compiled languages for a long time! And I like them! I'm happy to code in Haskell or OCaml or SBCL or Modula-3 or Java or C# or whatever. The main problem motivating Rust was that there was an audience of developers who wouldn't accept those PLs for their use cases. People were very very attached to their C/C++ performance and memory-usage envelopes. Like there are (or were) a lot of people who argue against having frame pointers too. It's weird! The gap between C/C++ and the next-fastest safe PL has never been especially huge, it's never anything like the performance gaps between different generations of hardware. But it persists across time, and it's been enough for decades to sustain the "we have to be unsafe" argument.&lt;lb/&gt;If times have changed and people are now mostly ok with the caveats and will throw the switch to turn safety on, I'm super happy for that to be true! Code that fails more-safely on memory errors is a great thing for human civilization. For people who have huge legacy C/C++ codebases with no ability or desire to rewrite, or even are writing anew but feel constrained to avoid (or just don't like) safer PLs, I hope Fil-C meets their needs. If at some point (say) there's an easy-to-install Debian distro built with this, I'll probably use it.&lt;/p&gt;&lt;p&gt;I'm happy to see this work exist. It builds on a long line of academic and industrial work in this space (that Pizlo happily cites), including his own many years of iteration on the subject while at Apple. If I understand correctly, some of those earlier iterations are already in production in security sensitive code. I recall talking with Pizlo about these prototypes when I was at Apple too, and I'm pleased to see the work maturing to its current state.&lt;/p&gt;&lt;p&gt;(He also makes an interesting point that the bounds checking Fil-C inserts can make pointer-twiddling C code safer than pointer-twiddling unsafe Rust. This seems likely true! And it would be interesting to know if there's a way to have the best of both worlds, eg. if his instrumentation pass could be adapted to compile otherwise-full-speed optimized unsafe Rust blocks with a little bit of systematic compiler-injected bounds checking, perhaps derived from Rust's strict pointer provenance? Obviously this wouldn't be appealing for folks who use unsafe blocks for speed, but I think a lot are for other reasons and might enjoy an extra layer of checks. This is well beyond anything I know anymore, sadly I've long since lost track of what rustc can or can't do. Just speculating, but it seems to me that most unsafe Rust code doesn't allocate or free or interact with an allocator at all, so you'd want to drive it from something other than allocator, could probably still omit the GC.)&lt;/p&gt;&lt;p&gt;Naturally Fil-C has some caveats (if we're comparing to Rust, say, or other PLs with restrictions on mutable aliasing):&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;It's not going to statically prevent any of the errors it prevents; it's strictly dynamic. So your programs will still crash on memory errors. But almost all programs have paths that crash, and perhaps the density of crashes will be tolerable.&lt;/item&gt;&lt;item&gt;In addition to the stated performance overheads there will be a space overhead, as deferring frees until the GC is sure they're garbage (unreachable) will retain that garbage for a while. On most GCs the amount of memory spent on garbage is tunable: make the GC work more often and there's less retained garbage, but typical GC tuning will put the overhead at 1.5x-2x the memory. &lt;del rend="overstrike"&gt;I haven't measured Fil-C-compiled code at all to see what its overheads are here&lt;/del&gt;EDIT: see measurements above, also included memory, looks to be more like 3-6x?) Anyway computers do have a lot of memory these days.&lt;/item&gt;&lt;item&gt;It's not going to do anything much to solve data races or help with local reasoning for correctness. Preventing mutable aliasing has additional correctness advantages beyond being a tool for memory safety. Fearless concurrency remains out of reach. But perhaps it's less fearful since you'll only crash or get data corruption.&lt;/item&gt;&lt;item&gt;There'll be a big obvious switch you can flip -- compile without Fil-C -- to turn the safety back off everywhere to make the program faster and use less memory. There will be a lot of temptation from bosses who like to see better numbers to flip that switch. But perhaps bosses in 2025 are safety conscious enough to leave it on.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;In any event, I only mention those caveats because they're the sort of thing that motivated languages like Rust in the first place. There have been memory-safe, bounds-checked and GC'ed AOT-compiled languages for a long time! And I like them! I'm happy to code in Haskell or OCaml or SBCL or Modula-3 or Java or C# or whatever. The main problem motivating Rust was that there was an audience of developers who wouldn't accept those PLs for their use cases. People were very very attached to their C/C++ performance and memory-usage envelopes. Like there are (or were) a lot of people who argue against having frame pointers too. It's weird! The gap between C/C++ and the next-fastest safe PL has never been especially huge, it's never anything like the performance gaps between different generations of hardware. But it persists across time, and it's been enough for decades to sustain the "we have to be unsafe" argument.&lt;/p&gt;&lt;p&gt;If times have changed and people are now mostly ok with the caveats and will throw the switch to turn safety on, I'm super happy for that to be true! Code that fails more-safely on memory errors is a great thing for human civilization. For people who have huge legacy C/C++ codebases with no ability or desire to rewrite, or even are writing anew but feel constrained to avoid (or just don't like) safer PLs, I hope Fil-C meets their needs. If at some point (say) there's an easy-to-install Debian distro built with this, I'll probably use it.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842494</guid><pubDate>Fri, 07 Nov 2025 00:59:58 +0000</pubDate></item><item><title>A prvalue is not a temporary</title><link>https://blog.knatten.org/2025/10/31/a-prvalue-is-not-a-temporary/</link><description>&lt;doc fingerprint="8a7009000ebc070d"&gt;
  &lt;main&gt;
    &lt;p&gt;This is part one of a series of blog posts on temporaries, copies, return value optimization, and passing by value vs. reference.&lt;/p&gt;
    &lt;p&gt;A good place to start, and the point of this first article, is how a prvalue isn‚Äôt necessarily a temporary.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre entirely new to value categories (lvalues, rvalues etc.), you might want to read lvalues, rvalues, glvalues, prvalues, xvalues, help! first.&lt;/p&gt;
    &lt;head rend="h2"&gt;lvalues vs rvalues&lt;/head&gt;
    &lt;p&gt;An lvalue is an expression that can not be moved from. An rvalue is an expression that can be moved from.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs first have a look at lvalues. Given this variable &lt;code&gt;v&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;
std::vector&amp;lt;int&amp;gt; v{1,2,3};
&lt;/code&gt;
    &lt;p&gt;If I now write the expression &lt;code&gt;v&lt;/code&gt; somewhere, &lt;code&gt;v&lt;/code&gt; is referring to an actual variable. I can‚Äôt just move from it, as it would mess up an existing object that someone else could still be using. We call an expression like this an lvalue.&lt;/p&gt;
    &lt;p&gt;For instance, if I pass my existing vector to a function &lt;code&gt;useVector&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;
useVector(v);
&lt;/code&gt;
    &lt;p&gt;Here, the expression &lt;code&gt;v&lt;/code&gt; is an lvalue, and &lt;code&gt;useVector&lt;/code&gt; can‚Äôt move from it. After all, someone might want to keep using &lt;code&gt;v&lt;/code&gt; on a following line.&lt;/p&gt;
    &lt;p&gt;But if I know I won‚Äôt be needing &lt;code&gt;v&lt;/code&gt; anymore, I can turn it into an rvalue, by wrapping it in &lt;code&gt;std::move&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;
useVector(std::move(v));
&lt;/code&gt;
    &lt;p&gt;Here, the expression &lt;code&gt;std::move(v)&lt;/code&gt; is an rvalue. &lt;code&gt;useVector&lt;/code&gt; would now be allowed to move from &lt;code&gt;v&lt;/code&gt;. (And I must take care to not use &lt;code&gt;v&lt;/code&gt; again, since it might have been moved into &lt;code&gt;useVector&lt;/code&gt;.)&lt;/p&gt;
    &lt;head rend="h2"&gt;rvalues: xvalues vs prvalues&lt;/head&gt;
    &lt;p&gt;Here‚Äôs another way to get an rvalue:&lt;/p&gt;
    &lt;code&gt;
useVector(std::vector{1,2,3});
&lt;/code&gt;
    &lt;p&gt;Here, the expression &lt;code&gt;std::vector{1,2,3}&lt;/code&gt; is also an rvalue, and again &lt;code&gt;useVector&lt;/code&gt; would be allowed to move from it.&lt;/p&gt;
    &lt;p&gt;Notice, however, that these are two different types of rvalues. &lt;code&gt;std::move(v)&lt;/code&gt; takes an existing object and casts it to an rvalue. That type of rvalue is called an xvalue, or ‚ÄúeXpiring lvalue‚Äù.&lt;/p&gt;
    &lt;p&gt;On the other hand, &lt;code&gt;std::vector{1,2,3}&lt;/code&gt; is a prvalue, or ‚Äúpure rvalue‚Äù. Unlike an xvalue, this expression never referred to an existing object in the first place. People sometimes call this ‚Äúa temporary‚Äù, but, as is the main point of this article, that‚Äôs not necessarily true.&lt;/p&gt;
    &lt;p&gt;A prvalue in itself is not a temporary. A prvalue is not an object. A prvalue just represents ‚Äúthe idea of the object‚Äù, and only turns into a temporary when it absolutely needs to. For instance:&lt;/p&gt;
    &lt;code&gt;
std::vector v = std::vector{1,2,3};
&lt;/code&gt;
    &lt;p&gt;Here, the prvalue &lt;code&gt;std::vector{1,2,3}&lt;/code&gt; does not turn into a temporary that is then used to initialize &lt;code&gt;v&lt;/code&gt;. Rather, the prvalue is used to initialize &lt;code&gt;v&lt;/code&gt; directly, just as if you‚Äôd written &lt;code&gt;std::vector v{1,2,3};&lt;/code&gt;. No extra temporary is created, and no copies or moves are performed.&lt;/p&gt;
    &lt;p&gt;Similarly:&lt;/p&gt;
    &lt;code&gt;
void useVector(std::vector&amp;lt;int&amp;gt; v);

useVector(std::vector{1,2,3});
&lt;/code&gt;
    &lt;p&gt;Here, &lt;code&gt;useVector&lt;/code&gt; takes its parameter by value. &lt;code&gt;std::vector{1,2,3}&lt;/code&gt; never turns into a temporary, the prvalue expression is instead used to initialize the parameter &lt;code&gt;v&lt;/code&gt; directly, just like in the previous example. No extra temporary is created, and no copies of moves are performed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Temporary materialization&lt;/head&gt;
    &lt;p&gt;However, if &lt;code&gt;useVector&lt;/code&gt; takes its parameter by reference:&lt;/p&gt;
    &lt;code&gt;
void useVector(const std::vector&amp;lt;int&amp;gt;&amp;amp; v);

useVector(std::vector{1,2,3});
&lt;/code&gt;
    &lt;p&gt;Now, the reference parameter &lt;code&gt;v&lt;/code&gt; needs some object to bind to, and &lt;code&gt;std::vector{1,2,3}&lt;/code&gt; actually turns into a temporary object that &lt;code&gt;v&lt;/code&gt; can bind to. This is called ‚Äútemporary materialization‚Äù.&lt;/p&gt;
    &lt;head rend="h2"&gt;Return values&lt;/head&gt;
    &lt;p&gt;A function call that returns by value is also a prvalue 1. So, given this definition of &lt;code&gt;getVector()&lt;/code&gt; and a call to it:&lt;/p&gt;
    &lt;code&gt;
std::vector&amp;lt;int&amp;gt; getVector();

std::vector&amp;lt;int&amp;gt; v = getVector();
&lt;/code&gt;
    &lt;p&gt;Here, the call &lt;code&gt;getVector()&lt;/code&gt; is a prvalue which initializes &lt;code&gt;v&lt;/code&gt; directly. There is no temporary that is then copied/moved into &lt;code&gt;v&lt;/code&gt;. (There might be a copy involved in the &lt;code&gt;return&lt;/code&gt; statement inside &lt;code&gt;getVector()&lt;/code&gt;, but that‚Äôs a story for the next article.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The point is that a prvalue only materializes into a temporary as a very last resort, avoiding unnecessary copies or moves. Until it needs to materialize, it only represents ‚Äúthe idea of the object‚Äù, i.e. what the object would be when it materializes into a temporary or is used to initialize something.&lt;/p&gt;
    &lt;p&gt;It is important to note that this has nothing to do with optimization. There is no temporary &lt;code&gt;std::vector&lt;/code&gt; to optimize away in the first place, there‚Äôs just the prvalue, just the ‚Äúidea of the object‚Äù. And then that idea of an object can materialize into an actual object if needed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;¬ßexpr.call¬∂13: ‚ÄúA function call is an lvalue if the result type is an lvalue reference type or an rvalue reference to function type, an xvalue if the result type is an rvalue reference to object type, and a prvalue otherwise.‚Äù ‚Ü©Ô∏é&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Discover more from C++ on a Friday&lt;/head&gt;
    &lt;p&gt;Subscribe to get the latest posts sent to your email.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843120</guid><pubDate>Fri, 07 Nov 2025 02:57:02 +0000</pubDate></item></channel></rss>