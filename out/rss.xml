<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 17 Jan 2026 05:11:59 +0000</lastBuildDate><item><title>Aviator (YC S21) is hiring to build multiplayer AI coding platform</title><link>https://www.ycombinator.com/companies/aviator/jobs</link><description>&lt;doc fingerprint="91c3eed18887810e"&gt;
  &lt;main&gt;
    &lt;p&gt;Google-level engineering productivity suite&lt;/p&gt;
    &lt;p&gt;Software engineering is being fundamentally transformed by AI, and we're building the tools to lead that shift. Aviator is creating the engineering productivity supertools that will define how the best teams build software in the AI era.&lt;/p&gt;
    &lt;p&gt;Our platform already powers workflow automation at Slack, Figma, DoorDash, and other industry leaders. MergeQueue eliminates merge conflicts and broken builds. FlexReview intelligently routes code reviews. And Runbooks—our newest product—is a collaborative AI agent platform that lets engineering teams automate complex workflows through natural language specs and shared context.&lt;/p&gt;
    &lt;p&gt;We believe the future of software development isn't engineers replaced by AI—it's engineers supercharged by it. Small teams will ship what once required hundreds of people. Complex workflows that took days will complete in minutes. We're building that future.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46639248</guid><pubDate>Thu, 15 Jan 2026 21:00:42 +0000</pubDate></item><item><title>Local-only Marstek Venus e-battery integration with Home Assistant</title><link>https://du.nkel.dev/blog/2026-01-11_marstek-battery-homeassistant/</link><description>&lt;doc fingerprint="36f33512a55a1b00"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Local-only Marstek Venus E Battery Integration with Home Assistant&lt;/head&gt;
    &lt;p&gt;Published: 2026-01-11, Revised: 2026-01-16&lt;/p&gt;
    &lt;p&gt;TL;DR Integrating a cheap (~1050â¬) 5kWh AC-coupled battery into an existing 30kWp PV system. The goal: Zero-cloud dependency, full local control via Modbus TCP, and a "Zero Export" regulation loop using Home Assistant. This post covers the physical installation using a standard TV mount, RS485 wiring, and the complete software logic.&lt;/p&gt;
    &lt;head rend="h2"&gt;Motivation#&lt;/head&gt;
    &lt;p&gt;In 2020, I took the initiative to install a 30kWp PV system on my own. Over the last 4 years, I achieved a self-consumption rate of roughly 48-50%.&lt;/p&gt;
    &lt;head&gt;See my PV production 2021-2025&lt;/head&gt;
    &lt;p&gt;With the price of the &lt;code&gt;Marstek Venus E 2.0&lt;/code&gt; dropping to around &lt;code&gt;â¬1.049&lt;/code&gt; in August 2025, I saw an opportunity to increase self-consumption to around 78%. The Marstek's size (&lt;code&gt;5.12 kWh&lt;/code&gt;) was ideal for my consumption pattern, enabling me to maximise the number of use cycles. The return on investment (ROI) calculation was promising enough to justify the experiment. Note that my current electricity price is at &lt;code&gt;â¬0.32/kWh&lt;/code&gt; and I sell my electricity at &lt;code&gt;â¬0.082/kWh&lt;/code&gt; (fixed for the next 15 years). According to these figures, I should recoup my investment in about six years. After that, I estimate savings of around &lt;code&gt;â¬250&lt;/code&gt; per year.&lt;/p&gt;
    &lt;head&gt;See my ROI calculation for the battery&lt;/head&gt;
    &lt;p&gt;I wanted to avoid the manufacturer's cloud and app entirely.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Privacy/Security: I don't want any IoT devices from Chinese vendors active on my main Ethernet network (no offence, Marstek!).&lt;/item&gt;
      &lt;item&gt;Control: I want granular control over charging/discharging logic based on my specific grid meter readings, not a black-box algorithm.&lt;/item&gt;
      &lt;item&gt;Robustness: The system should work regardless of internet connectivity. Local access also ensures that I can still use the battery if the vendor goes bankrupt or discontinues its service (local access ability was actually my main criteria for chosing the Marstek product).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Hardware Installation#&lt;/head&gt;
    &lt;head rend="h3"&gt;Wall Mounting#&lt;/head&gt;
    &lt;p&gt;The unit weighs about 50-60kg. Surprisingly, there is no official wall mount included or easily available. I found a hint on Facebook suggesting that standard TV brackets might work.&lt;/p&gt;
    &lt;p&gt;I used a &lt;code&gt;One-For-All Solid WM4411&lt;/code&gt; (TV wall mount, fixed, 32-65 inch), which is rated for up to 100kg.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cost: ~13-20 EUR.&lt;/item&gt;
      &lt;item&gt;Fit: It fits perfectly.&lt;/item&gt;
      &lt;item&gt;Mounting: I used the screws originally intended for the battery's wheels to attach the bracket to the back of the Marstek unit. I used two angle brackets at the bottom as spacers (2.5cm) to keep it parallel to the wall.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;RS485 &amp;amp; Network Connectivity#&lt;/head&gt;
    &lt;p&gt;To connect the battery to my network without using its WiFi dongle, I used the &lt;code&gt;RS485&lt;/code&gt; interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Converter: &lt;code&gt;Waveshare 20978 RS485 TO ETH (B)&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Cable: A standard &lt;code&gt;Cat7&lt;/code&gt;patch cable (sacrificed).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The wiring pinout on the Marstek side is crucial.1 The included cable/adapter might have varying colors, so rely on pin positions. I connected the Cat7 wires via Wago clamps to the open ends of the Marstek adapter cable.&lt;/p&gt;
    &lt;p&gt;Wiring Mapping:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A: Yellow (Pin 5)&lt;/item&gt;
      &lt;item&gt;B: Red (Pin 4)&lt;/item&gt;
      &lt;item&gt;GND: Black (Pin 3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Waveshare Configuration: The converter needs to be set to &lt;code&gt;Modbus TCP to RTU&lt;/code&gt; mode. This allows Home Assistant to speak Modbus TCP, while the Waveshare handles the translation to Modbus RTU (serial) for the battery.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Baud Rate: &lt;code&gt;115200&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Data Size: &lt;code&gt;8&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Parity: &lt;code&gt;None&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Stop Bits: &lt;code&gt;1&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Work Mode: &lt;code&gt;TCP Server&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Protocol: &lt;code&gt;Modbus TCP to RTU&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;See my Waveshare settings (full screenshot)&lt;/head&gt;
    &lt;head rend="h2"&gt;Home Assistant Configuration#&lt;/head&gt;
    &lt;p&gt;Note: A significant portion of this knowledge builds on the excellent yaml documentation from Michael Resch on Github.2&lt;/p&gt;
    &lt;head rend="h3"&gt;Architecture#&lt;/head&gt;
    &lt;p&gt;The control loop follows the separation of concerns principle.&lt;lb/&gt; 1. Input: A Raspberry Pi Zero WH reads the electricity meter (via IR head/vzlogger) and pushes data to MQTT.&lt;lb/&gt; 2. Logic: Home Assistant reads MQTT, calculates the required battery action, and sends commands via Modbus TCP.&lt;lb/&gt; 3. Output: The Marstek battery adjusts its charge/discharge rate. &lt;/p&gt;
    &lt;head rend="h3"&gt;Modbus Integration#&lt;/head&gt;
    &lt;p&gt;First, we define the Modbus connection and the sensors/switches. I split these into separate files for maintainability.&lt;/p&gt;
    &lt;p&gt;The initial part of the &lt;code&gt;configuration.yaml&lt;/code&gt;:
&lt;/p&gt;
    &lt;code&gt;modbus:
  - name: Marstek
    type: tcp
    host: 192.168.50.77 # IP of the Waveshare
    port: 502
    timeout: 5
    delay: 1
    sensors: !include marstek_modbus_sensors.yaml
    switches: !include marstek_modbus_switches.yaml

input_number:
  # This helper acts as the "Gas Pedal" for the automation
  marstek_discharging_charging_power:
    name: "Marstek (Dis)Charging Power"
    min: -2500
    max: 2500
    step: 10
    unit_of_measurement: W
    mode: slider
    icon: mdi:battery-charging-medium

mqtt:
  sensor:
    - name: "Stromnetz Leistung (MQTT)"
      unique_id: stromnetz_leistung_mqtt
      state_topic: "vzlogger/data/chn0/agg"
      unit_of_measurement: "W"
      device_class: "power"
      state_class: "measurement"
    # Grid Consumption (Bezug 1.8.0) in kWh
    - name: "Stromnetz Bezug (1.8.0)"
      unique_id: stromnetz_bezug_kwh_mqtt
      state_topic: "vzlogger/data/chn1/agg"
      unit_of_measurement: "kWh"
      device_class: "energy"
      state_class: "total_increasing"
      # vzlogger usually sends Wh, but HA wants kWh. We divide by 1000.
      value_template: "{{ value | float / 1000 }}"

    # Return to Grid (Lieferung 2.8.0) in kWh
    - name: "Stromnetz Einspeisung (2.8.0)"
      unique_id: stromnetz_einspeisung_kwh_mqtt
      state_topic: "vzlogger/data/chn2/agg"
      unit_of_measurement: "kWh"
      device_class: "energy"
      state_class: "total_increasing"
      # vzlogger usually sends Wh, but HA wants kWh. We divide by 1000.
      value_template: "{{ value | float / 1000 }}"
&lt;/code&gt;
    &lt;p&gt;For MQTT, the critical parameter is the current meter reading (e.g. grid loading or PV power export). I also added grid total statistics (ingress/egress) to populate the default Home Assistant Energy Dashboard at &lt;code&gt;/energy/overview&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;If you use my YAML configurations, please note this peculiarity3 of Home Assistant. Usually, you can refer to entities via their &lt;code&gt;unique_id&lt;/code&gt;. However, if the &lt;code&gt;name&lt;/code&gt; parameter is set, Home Assistant will generate a slug from the name. In this case, the slug must be used. For example, &lt;code&gt;Marstek Battery SOC&lt;/code&gt; will be available in dashboards via &lt;code&gt;sensors.marstek_battery_soc&lt;/code&gt;. As a programmer, I found this somewhat unintuitive and error-prone, but it works.&lt;/p&gt;
    &lt;head&gt;
      &lt;code&gt;marstek_modbus_sensors.yaml&lt;/code&gt;
    &lt;/head&gt;
    &lt;code&gt;# --- BATTERIE STATUS ---
- name: "Marstek Battery SOC"
  unique_id: marstek_battery_soc
  address: 32104
  slave: 1
  scan_interval: 30
  input_type: holding
  data_type: uint16
  unit_of_measurement: "%"
  device_class: battery
  state_class: measurement
  scale: 1
  precision: 0

- name: "Marstek Battery Voltage"
  unique_id: marstek_battery_voltage
  address: 32100
  slave: 1
  scan_interval: 30
  input_type: holding
  data_type: uint16
  unit_of_measurement: "V"
  device_class: voltage
  state_class: measurement
  scale: 0.01
  precision: 2

# --- LEISTUNG (Wichtig fÃ¼r Regelung) ---
- name: "Marstek AC Power"
  unique_id: marstek_ac_power
  # Positiv = Entladen, Negativ = Laden
  address: 32202
  slave: 1
  scan_interval: 5  # Schnell, fÃ¼r Regelung!
  input_type: holding
  data_type: int32
  unit_of_measurement: "W"
  device_class: power
  state_class: measurement
  scale: 1
  precision: 0

# --- ENERGIE ZÃHLER (FÃ¼r Statistik) ---
- name: "Marstek Total Charging Energy"
  unique_id: marstek_total_charging_energy
  address: 33000
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint32
  unit_of_measurement: kWh
  device_class: energy
  state_class: total_increasing
  scale: 0.01
  precision: 1

- name: "Marstek Total Discharging Energy"
  unique_id: marstek_total_discharging_energy
  address: 33002
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint32
  unit_of_measurement: kWh
  device_class: energy
  state_class: total_increasing
  scale: 0.01
  precision: 1

# --- TEMPERATUREN (Sicherheit) ---
- name: "Marstek Internal Temperature"
  unique_id: marstek_internal_temperature
  address: 35000
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: int16
  unit_of_measurement: "Â°C"
  device_class: temperature
  state_class: measurement
  scale: 0.1
  precision: 1

- name: "Marstek Max Cell Temperature"
  unique_id: marstek_max_cell_temperature
  address: 35010
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: int16
  unit_of_measurement: "Â°C"
  device_class: temperature
  state_class: measurement
  scale: 0.1
  precision: 1

# --- STATUS ---
- name: "Marstek Inverter State"
  unique_id: marstek_inverter_state
  address: 35100
  slave: 1
  scan_interval: 10
  input_type: holding
  data_type: uint16
  # 0:Sleep, 1:Standby, 2:Charge, 3:Discharge, 4:Backup

- name: "Marstek RS485 Control Mode Status"
  unique_id: marstek_rs485_control_mode_status
  address: 42000
  slave: 1
  scan_interval: 10
  input_type: holding
  data_type: uint16

- name: "Marstek BMS Charge Current Limit"
  unique_id: marstek_bms_charge_current_limit
  address: 35111
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint16
  unit_of_measurement: "A"
  scale: 0.1
  precision: 1

- name: "Marstek BMS Discharge Current Limit"
  unique_id: marstek_bms_discharge_current_limit
  address: 35112
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint16
  unit_of_measurement: "A"
  scale: 0.1
  precision: 1

- name: "Marstek DC Power"
  unique_id: marstek_dc_power
  address: 32102
  slave: 1
  scan_interval: 10
  input_type: holding
  data_type: int32  # int32 laut PDF, da vorzeichenbehaftet
  unit_of_measurement: "W"
  scale: 1
  precision: 0

- name: "Marstek Alarm Code"
  unique_id: marstek_alarm_code
  address: 36000
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint16
  # Wert 0 = OK. Alles andere sind Warnungen.

- name: "Marstek Fault Code"
  unique_id: marstek_fault_code
  address: 36100
  slave: 1
  scan_interval: 60
  input_type: holding
  data_type: uint16
  # Wert 0 = OK. Alles andere sind Fehler (Abschaltung).

- name: "Marstek Config Max Charge Power"
  unique_id: marstek_config_max_charge_power
  address: 44002
  slave: 1
  scan_interval: 300 # Sehr selten, Ã¤ndert sich ja nie
  input_type: holding
  data_type: uint16
  unit_of_measurement: "W"
  scale: 1

- name: "Marstek Config Max Discharge Power"
  unique_id: marstek_config_max_discharge_power
  address: 44003
  slave: 1
  scan_interval: 300
  input_type: holding
  data_type: uint16
  unit_of_measurement: "W"
  scale: 1

- name: "Marstek Config Discharge Cutoff SoC"
  unique_id: marstek_config_discharge_cutoff_soc
  address: 44001
  slave: 1
  scan_interval: 300
  input_type: holding
  data_type: uint16
  unit_of_measurement: "%"
  scale: 0.1
  precision: 1

- name: "Marstek Config Charging Cutoff SoC"
  unique_id: marstek_config_charge_cutoff_soc
  address: 44000
  slave: 1
  scan_interval: 300
  input_type: holding
  data_type: uint16
  unit_of_measurement: "%"
  scale: 0.1
  precision: 1
&lt;/code&gt;
    &lt;p&gt;The main source for setting up sensors is the official Register documentation for the Marstek battery.[4] I found all of this information through the many reports from Photovoltaikforum.com.5&lt;/p&gt;
    &lt;head&gt;
      &lt;code&gt;marstek_modbus_switches.yaml&lt;/code&gt;
    &lt;/head&gt;
    &lt;code&gt;- name: "Marstek Enable RS485 Control Mode"
  unique_id: marstek_enable_rs485_control_mode
  address: 42000
  slave: 1
  command_on: 21930
  command_off: 21947
  write_type: holding
  verify:
    input_type: holding
    address: 42000
    state_on: 21930
    state_off: 21947
&lt;/code&gt;
    &lt;head&gt;See my complete &lt;code&gt;configuration.yaml&lt;/code&gt;&lt;/head&gt;
    &lt;code&gt;# Marstek Battery Integration via Waveshare
modbus:
  - name: Marstek
    type: tcp
    host: 192.168.50.77
    port: 502
    timeout: 5
    delay: 1
    sensors: !include marstek_modbus_sensors.yaml
    switches: !include marstek_modbus_switches.yaml

input_number:
  marstek_discharging_charging_power:
    name: "Marstek (Dis)Charging Power"
    min: -2500
    max: 2500
    step: 10
    unit_of_measurement: W
    mode: slider
    icon: mdi:battery-charging-medium

# Template Sensoren fÃ¼r Energie-Dashboard &amp;amp; Status
template:
  - sensor:
      # Berechnet Ladeleistung (nur positiv)
      - name: "Marstek Charging Power"
        unique_id: marstek_charging_power
        unit_of_measurement: "W"
        device_class: power
        state_class: measurement
        state: &amp;gt;
          {% set p = states('sensor.marstek_ac_power') | float(0) %}
          {{ (p * -1) if p &amp;lt; 0 else 0 }}

      # Berechnet Entladeleistung (nur positiv)
      - name: "Marstek Discharging Power"
        unique_id: marstek_discharging_power
        unit_of_measurement: "W"
        device_class: power
        state_class: measurement
        state: &amp;gt;
          {% set p = states('sensor.marstek_ac_power') | float(0) %}
          {{ p if p &amp;gt; 0 else 0 }}

      - name: "Marstek Ladezyklen (berechnet)"
        unique_id: marstek_cycles_calculated
        icon: mdi:battery-sync
        unit_of_measurement: "Zyklen"
        state_class: measurement
        state: &amp;gt;
          {% set total_discharged = states('sensor.marstek_total_discharging_energy_calculated') | float(0) %}
          {% set battery_capacity = 5.12 %}
          {{ (total_discharged / battery_capacity) | round(2) }}
      - name: "Marstek Efficiency"
        unique_id: marstek_efficiency
        unit_of_measurement: "%"
        icon: mdi:chart-donut
        state: &amp;gt;
          {% set chg = states('sensor.marstek_total_charging_energy_calculated') | float(0) %}
          {% set dis = states('sensor.marstek_total_discharging_energy_calculated') | float(0) %}
          {% if chg &amp;gt; 0 %}
            {{ ((dis / chg) * 100) | round(1) }}
          {% else %}
            0
          {% endif %}

sensor:
  - platform: influxdb
    api_version: 2
    host: influx.my.tld.com
    port: 443
    ssl: true
    token: [redacted]
    organization: "my org"
    bucket: "vzlogger"
    queries_flux:
      - name: "Stromnetz Leistung"
        unique_id: stromnetz_leistung_influxdb
        unit_of_measurement: "W"
        range_start: "-1m"  # &amp;lt;--- override the -15m default
        query: &amp;gt; # V--- query starts with the first filter
          filter(fn: (r) =&amp;gt; r["_measurement"] == "mqtt_consumer")
          |&amp;gt; filter(fn: (r) =&amp;gt; r["topic"] == "vzlogger/data/chn0/agg")
          |&amp;gt; map(fn: (r) =&amp;gt; ({ r with _value: r._value * -1.0 }))
          |&amp;gt; last()
  # Riemann Summenintegrale (kWh aus Watt berechnen)
  # Genauer als die internen ZÃ¤hler des Marstek.
  - platform: integration
    source: sensor.marstek_charging_power
    name: "Marstek Total Charging Energy (Calculated)"
    unique_id: marstek_total_charging_energy_calculated
    unit_prefix: k
    round: 3
    method: left
  - platform: integration
    source: sensor.marstek_discharging_power
    name: "Marstek Total Discharging Energy (Calculated)"
    unique_id: marstek_total_discharging_energy_calculated
    unit_prefix: k
    round: 3
    method: left
  - platform: filter
    name: "Stromnetz Leistung (GeglÃ¤ttet)"
    unique_id: stromnetz_leistung_smooth_2m
    entity_id: sensor.stromnetz_leistung_mqtt
    filters:
      - filter: time_simple_moving_average
        window_size: "00:02:00"  # Durchschnitt der letzten 120 Sekunden
        precision: 0

# VerbrauchszÃ¤hler fÃ¼r Statistiken (TÃ¤glich, Monatlich, JÃ¤hrlich)
utility_meter:
  # --- ENTLADEN (Verbrauch aus Batterie) ---
  marstek_discharge_daily:
    source: sensor.marstek_total_discharging_energy_calculated
    name: "Marstek Entladung Heute"
    cycle: daily
  marstek_discharge_monthly:
    source: sensor.marstek_total_discharging_energy_calculated
    name: "Marstek Entladung Monat"
    cycle: monthly
  marstek_discharge_yearly:
    source: sensor.marstek_total_discharging_energy_calculated
    name: "Marstek Entladung Jahr"
    cycle: yearly

  # --- LADEN (Speicherung in Batterie) ---
  marstek_charge_daily:
    source: sensor.marstek_total_charging_energy_calculated
    name: "Marstek Ladung Heute"
    cycle: daily
  marstek_charge_monthly:
    source: sensor.marstek_total_charging_energy_calculated
    name: "Marstek Ladung Monat"
    cycle: monthly
  marstek_charge_yearly:
    source: sensor.marstek_total_charging_energy_calculated
    name: "Marstek Ladung Jahr"
    cycle: yearly
&lt;/code&gt;
    &lt;p&gt;As you can see, I also added my local InfluxDB, to pull additional values for the Dashboard (optional, not needed for the battery automation).&lt;/p&gt;
    &lt;head rend="h3"&gt;Logic: Zero Export Automation#&lt;/head&gt;
    &lt;p&gt;When starting with the automation, I thought, this should be as simple as "If Solar &amp;gt; 0, then Charge". It is not.&lt;/p&gt;
    &lt;p&gt;To understand the automation choices, you must understand the specific premises of my setup:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I have an oversized PV system (&lt;code&gt;30kWp&lt;/code&gt;) paired with a relatively small battery (&lt;code&gt;5.12kWh&lt;/code&gt;). My household consumption is medium-high (&lt;code&gt;~6000kWh/a&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Latency Reality: The electricity meter (vzlogger) reports via MQTT every 10 seconds, I could reduce this further, but decided against it (read below). The battery inverter also takes a few seconds to ramp up. Trying to chase second-by-second load peaks would result in a "cat-and-mouse" game, causing unnecessary oscillation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Based on this, I defined my goals for the automation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Avoid Grid Charging (Efficiency): Every kWh loaded from the grid and discharged later suffers a &lt;code&gt;~20%&lt;/code&gt;conversion loss. Therefore, I set a relatively high charging threshold (&lt;code&gt;400W&lt;/code&gt;surplus). This ensures that in the mornings, scarce solar power goes directly to household consumption. I have ample surplus around noon to fill the small battery in no time, so there is no rush.&lt;/item&gt;
      &lt;item&gt;Avoid Battery Export (Economics): Discharging battery power into the grid is a financial loss. Since the battery is too small to cover the entire night anyway, I prioritize safety over coverage. Therefore, I decided for a safe discharge buffer (&lt;code&gt;~50-100W&lt;/code&gt;grid import). If a device turns off, the battery has enough time to ramp down without accidentally feeding into the grid during the latency period.&lt;/item&gt;
      &lt;item&gt;Stability (Longevity): Instead of rapidly switching states, I prefer steady power levels. I implemented a damping factor and a step-logic (rounding to &lt;code&gt;100W&lt;/code&gt;). This creates a staircase curve (rather than a jagged line), likely improving inverter efficiency and reducing wear. I don't know if this is true or how important it is - let me know in the comments if you're an electricity or inverter expert!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To achieve this, the automation below uses an incremental control loop (similar to a P-controller)6 within a Jinja2 template in Home Assistant. Instead of calculating an absolute target, it adjusts the current power level relative to the grid meter reading.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ziel_netz&lt;/code&gt;(Target Grid Import): We aim for a permanent grid import of&lt;code&gt;50W&lt;/code&gt;. This acts as a safety buffer to ensure we never accidentally export battery power to the grid, even if consumption fluctuates slightly.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lade_start_grenze&lt;/code&gt;(Charge Start Threshold): A hysteresis setting. The battery only starts charging if the solar surplus exceeds&lt;code&gt;400W&lt;/code&gt;. However, once charging has started, it allows the power to drop below this threshold (e.g., during passing clouds) without immediately stopping. This ensures smoother operation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;korrektur&lt;/code&gt;(Correction Factor): The logic calculates the difference between the actual grid reading and the target (50W). It multiplies this by a damping factor (&lt;code&gt;0.5&lt;/code&gt;) to calculate the adjustment. This prevents the system from overreacting and oscillating.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;limit_max&lt;/code&gt;(Hardware Cap): A hard limit for the charging/discharging power (e.g., currently set to&lt;code&gt;800W&lt;/code&gt;for Schuko connection, I will ramp this up to&lt;code&gt;2500W&lt;/code&gt;once my battery is hardwired).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;soc&lt;/code&gt;(Battery Protection): Monitors the State of Charge. Stops charging at&lt;code&gt;100%&lt;/code&gt;6 and stops discharging at&lt;code&gt;20%&lt;/code&gt;(to prolong battery life). This overrides the power calculation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;&lt;code&gt;automations.yaml&lt;/code&gt;: marstek_smart_regulation&lt;/head&gt;
    &lt;code&gt;- alias: "Marstek: Intelligent Regulation (Zero Export)"
  id: marstek_smart_regulation
  mode: restart
  trigger:
    - platform: time_pattern
      seconds: "/10"
  condition:
    # Automation must be enabled via Dashboard switch
    - condition: state
      entity_id: input_boolean.marstek_automatik
      state: "on"
    # Sensor must provide valid data
    - condition: not
      conditions:
        - condition: state
          entity_id: sensor.stromnetz_leistung_mqtt
          state: ["unavailable", "unknown"]
  action:
    - action: input_number.set_value
      target:
        entity_id: input_number.marstek_discharging_charging_power
      data:
        value: &amp;gt;
          {# 1. Get current status #}
          {% set netz = states('sensor.stromnetz_leistung_mqtt') | float(0) %}
          {% set aktuell_soll = states('input_number.marstek_discharging_charging_power') | float(0) %}
          {% set soc = states('sensor.marstek_battery_soc') | float(0) %}

          {# 2. Settings #}
          {% set limit_max = 800 %}

          {# Lower Discharge Target: We always want at least 50W grid import (safety buffer) #}
          {% set ziel_netz = 50 %}

          {# Lower Charge Threshold: Only start charging when &amp;gt; 400W export (e.g. -450W) #}
          {% set lade_start_grenze = 400 %}

          {# 3. Calculate Correction (Incremental Regulation) #}
          {# Damping 0.5 for smooth adjustment #}
          {% set korrektur = (netz - ziel_netz) * 0.5 %}

          {# Preliminary new setpoint #}
          {% set neu_soll_raw = aktuell_soll - korrektur %}

          {# 4. Main Logic #}

          {# Scenario: We are not charging yet (or discharging) ... #}
          {% if aktuell_soll &amp;lt;= 0 %}
             {# ... but the calculation says "Please Charge" (positive value) ... #}
             {% if neu_soll_raw &amp;gt; 0 %}
                {# ... then we check: Is there enough surplus? #}
                {% if netz &amp;lt; (lade_start_grenze * -1) %}
                   {# Yes, ample surplus (-400W or more): Allow charging! #}
                   {% set neu_soll_final = neu_soll_raw %}
                {% else %}
                   {# No, just a little surplus: Stay at 0 (or keep discharging) #}
                   {% set neu_soll_final = 0 %}
                {% endif %}
             {% else %}
                {# We don't want to charge anyway (discharging or 0): All good #}
                {% set neu_soll_final = neu_soll_raw %}
             {% endif %}

          {# Scenario: We are already charging #}
          {% else %}
             {# Continue regulating normally (even under 400W) so it doesn't stop immediately on clouds #}
             {% set neu_soll_final = neu_soll_raw %}
          {% endif %}

          {# 5. Round to 100W steps (for stability) #}
          {% set neu_soll_gerundet = (neu_soll_final / 100) | int * 100 %}

          {# 6. Safety Limits (SoC &amp;amp; Max Power) #}

          {# --- Battery full --- #}
          {% if neu_soll_gerundet &amp;gt; 0 and soc &amp;gt;= 100 %}
             0

          {# --- Battery empty --- #}
          {% elif neu_soll_gerundet &amp;lt; 0 and soc &amp;lt;= 20 %}
             0

          {# --- Hard Limits --- #}
          {% elif neu_soll_gerundet &amp;gt; limit_max %}
             {{ limit_max }}
          {% elif neu_soll_gerundet &amp;lt; (limit_max * -1) %}
             {{ limit_max * -1 }}

          {# --- Normal --- #}
          {% else %}
             {{ neu_soll_gerundet | int }}
          {% endif %}
&lt;/code&gt;
    &lt;p&gt;Since Modbus is a stateful protocol, the battery retains the last command it received. If Home Assistant crashes or reboots while the battery is discharging at full power, the battery would continue to discharge until empty because the control loop stops sending updates.&lt;/p&gt;
    &lt;p&gt;To prevent this state and ensure a clean startup, I implemented a safety logic in &lt;code&gt;automations.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Graceful Shutdown: Using the &lt;code&gt;homeassistant.shutdown&lt;/code&gt;event trigger, HA sends a hard&lt;code&gt;0&lt;/code&gt;(Stop) command to the battery immediately before the system stops.&lt;/item&gt;
      &lt;item&gt;Clean Startup: On boot (&lt;code&gt;homeassistant.start&lt;/code&gt;), a logic lock is applied. The automation sets the target power to&lt;code&gt;0&lt;/code&gt;and disables the "Autopilot" boolean. It waits for&lt;code&gt;20 seconds&lt;/code&gt;to ensure the Modbus connection is fully established, sends another safety Stop command, and only then re-enables the automation loop. This prevents the regulation logic from acting on stale sensor data before the system is fully initialized.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;&lt;code&gt;automations.yaml&lt;/code&gt;: additonal parts&lt;/head&gt;
    &lt;code&gt;- alias: "Marstek: Befehl an Speicher senden"
  id: marstek_send_command
  mode: restart
  trigger:
    - platform: state
      entity_id: input_number.marstek_discharging_charging_power
  action:
    - action: script.turn_on
      target:
        entity_id: script.marstek_set_forcible_charge

# 3. Self-healing (Optional)
- alias: "Marstek: Watchdog (Selbstheilung)"
  id: marstek_watchdog
  trigger:
    - platform: time_pattern
      minutes: "/5"
  condition:
    # Wenn Sollwert und Istwert zu stark abweichen
    - condition: template
      value_template: &amp;gt;
        {{ (states('input_number.marstek_discharging_charging_power') | float(0) - states('sensor.marstek_ac_power') | float(0) * -1) | abs &amp;gt; 100 }}
    # Und wir nicht gerade bei 0 sind
    - condition: numeric_state
      entity_id: input_number.marstek_discharging_charging_power
      above: 50
  action:
    # RS485 Reset
    - action: switch.turn_off
      target: {entity_id: switch.marstek_enable_rs485_control_mode}
    - delay: 5
    - action: switch.turn_on
      target: {entity_id: switch.marstek_enable_rs485_control_mode}

# 4. On Shutdown: Stop the battery
# (SchÃ¼tzt vor ungewolltem Weiterlaufen wÃ¤hrend Updates)
- alias: "System: Marstek Stopp bei Shutdown"
  id: system_marstek_shutdown_safety
  trigger:
    - platform: homeassistant
      event: shutdown
  action:
    - action: script.turn_on
      target:
        entity_id: script.marstek_stop_system

# 5. On Startup: Restart the battery with a time delay
- alias: "System: Marstek Reset bei Start"
  id: system_marstek_startup_reset
  trigger:
    - platform: homeassistant
      event: start
  action:
    # 1. Sperre: Automatik sofort ausschalten
    - action: input_boolean.turn_off
      target:
        entity_id: input_boolean.marstek_automatik
    # 2. Werte auf Null
    - action: input_number.set_value
      target:
        entity_id: input_number.marstek_discharging_charging_power
      data:
        value: 0
    # 3. Warten
    - delay: "00:00:20"
    # 4. Reset: Sicherer Stopp-Befehl an Speicher senden
    - action: script.turn_on
      target:
        entity_id: script.marstek_stop_system
    # 5. Freigabe: Automatik einschalten -&amp;gt; System Ã¼bernimmt ab jetzt
    - action: input_boolean.turn_on
      target:
        entity_id: input_boolean.marstek_automatik
&lt;/code&gt;
    &lt;p&gt;I also added &lt;code&gt;stop_grace_period: 30s&lt;/code&gt; to my &lt;code&gt;docker-compose.yml&lt;/code&gt;, to give this automation a bit more time to put the battery in a save state.&lt;/p&gt;
    &lt;p&gt;The automation triggers a script that writes the actual registers. This abstracts the Modbus complexity away from the automation logic.&lt;/p&gt;
    &lt;head&gt;
      &lt;code&gt;scripts.yaml&lt;/code&gt;
    &lt;/head&gt;
    &lt;code&gt;marstek_set_forcible_charge:
  alias: Marstek Set Forcible Charge
  icon: mdi:battery-charging-40
  sequence:
    - choose:
        # Fall 1: Stopp (Wert nahe 0)
        - conditions:
            - condition: numeric_state
              entity_id: input_number.marstek_discharging_charging_power
              above: -1
              below: 1
          sequence:
            - action: modbus.write_register
              data: {hub: Marstek, address: 42010, slave: 1, value: 0}
            - action: modbus.write_register
              data: {hub: Marstek, address: 42020, slave: 1, value: 0}
            - action: modbus.write_register
              data: {hub: Marstek, address: 42021, slave: 1, value: 0}
        # Fall 2: Entladen (Negativer Wert)
        - conditions:
            - condition: numeric_state
              entity_id: input_number.marstek_discharging_charging_power
              above: -2501
              below: -10
          sequence:
            # Leistung setzen (Absolutwert: aus -500 wird 500)
            - action: modbus.write_register
              data:
                hub: Marstek
                address: 42021
                slave: 1
                value: "{{ states('input_number.marstek_discharging_charging_power') | int | abs }}"
            # Modus Entladen (2)
            - action: modbus.write_register
              data: {hub: Marstek, address: 42010, slave: 1, value: 2}

        # Fall 3: Laden (Positiver Wert)
        - conditions:
            - condition: numeric_state
              entity_id: input_number.marstek_discharging_charging_power
              above: 10
              below: 2501
          sequence:
            # Leistung setzen
            - action: modbus.write_register
              data:
                hub: Marstek
                address: 42020
                slave: 1
                value: "{{ states('input_number.marstek_discharging_charging_power') | int | abs }}"
            # Modus Laden (1)
            - action: modbus.write_register
              data: {hub: Marstek, address: 42010, slave: 1, value: 1}

# Additional Scripts for Dashboard (manual, not needed for the automation)
marstek_start_charging:
  alias: "Marstek: Laden Starten (Manuell)"
  icon: mdi:battery-charging
  sequence:
    - action: modbus.write_register
      data: {hub: Marstek, slave: 1, address: 42000, value: 21930}
    - action: modbus.write_register
      data:
        hub: Marstek
        slave: 1
        address: 42020
        value: "{{ states('input_number.marstek_discharging_charging_power') | int | abs }}"
    - action: modbus.write_register
      data: {hub: Marstek, slave: 1, address: 42010, value: 1}

marstek_start_discharging:
  alias: "Marstek: Entladen Starten (Manuell)"
  icon: mdi:battery-charging-low
  sequence:
    - action: modbus.write_register
      data: {hub: Marstek, slave: 1, address: 42000, value: 21930}
    - action: modbus.write_register
      data:
        hub: Marstek
        slave: 1
        address: 42021
        value: "{{ states('input_number.marstek_discharging_charging_power') | int | abs }}"
    - action: modbus.write_register
      data: {hub: Marstek, slave: 1, address: 42010, value: 2}

marstek_stop_system:
  alias: "Marstek: Stopp (Manuell)"
  icon: mdi:stop-circle-outline
  sequence:
    - action: modbus.write_register
      data: {hub: Marstek, slave: 1, address: 42010, value: 0}
&lt;/code&gt;
    &lt;head rend="h3"&gt;Dashboard#&lt;/head&gt;
    &lt;p&gt;I created a dashboard to monitor the system state and allow for manual override. The system runs in "Autopilot" (Automation active) by default, but can be switched to manual control for testing or maintenance.&lt;/p&gt;
    &lt;p&gt;Main values (gauge). Note that the max cell temperature (&lt;code&gt;1.5Â°C&lt;/code&gt;) value is likely a default, perhaps the battery register hasn't been triggered yet.&lt;/p&gt;
    &lt;p&gt;Then there is a Hardware Limits and Diagnosis part:&lt;/p&gt;
    &lt;p&gt;Next come the statistics and cycles. The most interesting part here is perhaps the 'Full Cycles' value. The more full cycles that are reached in a given year, the more effectively the battery is used. &lt;code&gt;200&lt;/code&gt; full cycles per year is an achievable average for most. With my larger PV system, I expect to achieve slightly more, perhaps &lt;code&gt;250â300&lt;/code&gt; cycles (we will see). The Marstek Venus E technical documentation guarantees &lt;code&gt;6,000&lt;/code&gt; load cycles at &lt;code&gt;80%&lt;/code&gt; discharge, meaning my battery should last &lt;code&gt;20&lt;/code&gt; years at &lt;code&gt;300&lt;/code&gt; cycles/year. However, I expect it to last less than that (we will see, too!).&lt;/p&gt;
    &lt;p&gt;Finally overrides, to turn the automation off and force discharge or charge manually.&lt;/p&gt;
    &lt;head&gt;Dashboard yaml&lt;/head&gt;
    &lt;code&gt;type: vertical-stack
cards:
  - type: heading
    heading: Marstek Speicher Status
    icon: mdi:battery-high
    heading_style: title
  - type: horizontal-stack
    cards:
      - type: gauge
        entity: sensor.marstek_battery_soc
        name: Ladestand (SoC)
        min: 0
        max: 100
        severity:
          green: 20
          yellow: 10
          red: 0
        needle: true
      - type: gauge
        entity: sensor.marstek_ac_power
        name: Leistung (AC)
        min: -2500
        max: 2500
        needle: true
        severity:
          green: -2500
          yellow: 0
          red: 1
  - type: horizontal-stack
    cards:
      - type: gauge
        entity: sensor.marstek_max_cell_temperature
        name: Max. Zell-Temp
        min: 0
        max: 60
        needle: true
        severity:
          green: 15
          yellow: 45
          red: 55
      - type: tile
        entity: sensor.marstek_internal_temperature
        name: Innen-Temp
        icon: mdi:thermometer
        color: orange
  - type: entities
    title: Live Werte
    entities:
      - entity: sensor.stromnetz_leistung_mqtt
        name: Aktueller Netzbezug (MQTT)
        icon: mdi:transmission-tower
      - entity: sensor.marstek_ac_power
        name: AC Leistung (Zum Haus)
        icon: mdi:current-ac
      - entity: sensor.marstek_dc_power
        name: DC Leistung (Von Batterie)
        icon: mdi:current-dc
      - entity: sensor.marstek_battery_voltage
        name: Batteriespannung
      - entity: sensor.marstek_inverter_state
        name: Inverter Status (1=Stby, 2=Chg, 3=Dis)
      - entity: switch.marstek_enable_rs485_control_mode
        name: RS485 Fernsteuerung aktiv
  - type: entities
    title: Hardware-Limits &amp;amp; Diagnose
    show_header_toggle: false
    entities:
      - entity: sensor.marstek_alarm_code
        name: Alarm Code (0 = OK)
        icon: mdi:alert-outline
      - entity: sensor.marstek_fault_code
        name: Fault Code (0 = OK)
        icon: mdi:alert-octagon-outline
      - type: section
        label: TemporÃ¤re BMS Limits (Temperaturbedingt)
      - entity: sensor.marstek_bms_charge_current_limit
        name: Max. Ladestrom (BMS)
      - entity: sensor.marstek_bms_discharge_current_limit
        name: Max. Entladestrom (BMS)
      - type: section
        label: Permanente Config Limits (EEPROM)
      - entity: sensor.marstek_config_max_charge_power
        name: Erlaubte Ladeleistung (System)
        icon: mdi:lock-outline
      - entity: sensor.marstek_config_max_discharge_power
        name: Erlaubte Entladeleistung (System)
        icon: mdi:lock-outline
      - entity: sensor.marstek_config_discharge_cutoff_soc
        name: Notabschaltung bei SoC (System)
        icon: mdi:battery-alert
      - entity: sensor.marstek_config_charging_cutoff_soc
        name: Maximal laden bis SoC (System)
        icon: mdi:battery-alert
  - type: entities
    title: Statistik &amp;amp; Zyklen
    show_header_toggle: false
    entities:
      - entity: sensor.marstek_ladezyklen_berechnet
        name: Vollzyklen (seit Installation)
      - entity: sensor.marstek_efficiency
        name: Wirkungsgrad (RTE)
      - type: section
        label: Gesamtenergie
      - entity: sensor.marstek_total_charging_energy_calculated
        name: Gesamt Geladen
        icon: mdi:battery-arrow-up
      - entity: sensor.marstek_total_discharging_energy_calculated
        name: Gesamt Entladen
        icon: mdi:battery-arrow-down
      - type: section
        label: Heute
      - entity: sensor.marstek_ladung_heute
        name: Geladen Heute
      - entity: sensor.marstek_entladung_heute
        name: Entladen Heute
      - type: section
        label: Dieser Monat
      - entity: sensor.marstek_ladung_monat
        name: Geladen Monat
      - entity: sensor.marstek_entladung_monat
        name: Entladen Monat
      - type: section
        label: Dieses Jahr
      - entity: sensor.marstek_ladung_jahr
        name: Geladen Jahr
      - entity: sensor.marstek_entladung_jahr
        name: Entladen Jahr
  - type: heading
    heading: Manuelle Steuerung
    icon: mdi:controller
  - type: tile
    entity: input_boolean.marstek_automatik
    name: Automatik-Modus (An = Autopilot)
    icon: mdi:robot
    color: accent
  - type: entities
    entities:
      - entity: input_number.marstek_discharging_charging_power
        name: Soll-Leistung (+ Laden / - Entladen)
  - type: horizontal-stack
    cards:
      - type: button
        name: LADEN
        icon: mdi:battery-charging
        tap_action:
          action: call-service
          service: script.marstek_start_charging
        show_name: true
        show_icon: true
        card_mod:
          style: |
            ha-card { background: #1b5e20; color: white; }
      - type: button
        name: STOPP
        icon: mdi:stop-circle-outline
        tap_action:
          action: call-service
          service: script.marstek_stop_system
        show_name: true
        show_icon: true
        card_mod:
          style: |
            ha-card { background: #424242; color: white; }
      - type: button
        name: ENTLADEN
        icon: mdi:battery-charging-low
        tap_action:
          action: call-service
          service: script.marstek_start_discharging
        show_name: true
        show_icon: true
        card_mod:
          style: |
            ha-card { background: #b71c1c; color: white; }
&lt;/code&gt;
    &lt;head rend="h2"&gt;Evaluation#&lt;/head&gt;
    &lt;p&gt;For evaluation and monitoring, I prefer InfluxDB and Grafana. Add this to your &lt;code&gt;configuration.yaml&lt;/code&gt; to export the battery stats to InfluxDB, so it can be visualized in Grafana:&lt;/p&gt;
    &lt;head&gt;&lt;code&gt;configurations.yaml&lt;/code&gt;: InfluxDB&lt;/head&gt;
    &lt;code&gt;influxdb:
  api_version: 2
  ssl: true # I am using https internally
  host: influx.my.tld.com
  port: 443 # Default port for https
  token: [redacted]
  organization: "my org"
  bucket: "homeassistant"
  exclude:
    entity_globs: "*" # This prevents HA from writing its own data to InfluxDB
  include: # except for these metrics
    entities:
      - sensor.marstek_ac_power         # Lade-/Entladeleistung
      - sensor.marstek_battery_soc      # Ladestand
      - sensor.marstek_battery_voltage  # Spannung
&lt;/code&gt;
    &lt;p&gt;My flux query in Grafana then looks like this:&lt;/p&gt;
    &lt;code&gt;from(bucket: "homeassistant")
  |&amp;gt; range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |&amp;gt; filter(fn: (r) =&amp;gt; r["_measurement"] == "W")
  |&amp;gt; filter(fn: (r) =&amp;gt; r["_field"] == "value")
  |&amp;gt; filter(fn: (r) =&amp;gt; r["entity_id"] == "marstek_ac_power")
  |&amp;gt; aggregateWindow(every: v.windowPeriod, fn: mean, createEmpty: false)
  |&amp;gt; set(key: "_field", value: "Marstek Batterie")
  |&amp;gt; keep(columns: ["_time", "_value", "_field"])
  |&amp;gt; yield(name: "mean")
&lt;/code&gt;
    &lt;p&gt;Here is a common day in January where I produced &lt;code&gt;11.4 kWh&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Red&lt;/code&gt;: Battery load (charge/discharge) from Home Assistant via InfluxDB.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Orange&lt;/code&gt;: Grid load (egress/ingress), from VzLogger via MQTT&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Cyan&lt;/code&gt;: total PV inverter production, from my Huawei inverter, pulled via Modbus TCP&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As can be seen, the battery started charging at around &lt;code&gt;09:32&lt;/code&gt;. It was a fully overcast day. At around noon, there was a heavy downpour, which coincided with a high household energy demand (&lt;code&gt;2500W&lt;/code&gt;, lunchtime!), during which the battery briefly switched to discharge mode. It then switched back to charging until &lt;code&gt;14:54&lt;/code&gt;, when the safety margin resulted in the battery switching to standby for around &lt;code&gt;30 minutes&lt;/code&gt;. At this time, the battery was &lt;code&gt;72%&lt;/code&gt; charged. At &lt;code&gt;15:08&lt;/code&gt;, it first switched to discharging, which continued to rise steadily until the peak evening usage period from &lt;code&gt;17:00&lt;/code&gt; onwards. The battery reached a SoC of &lt;code&gt;20%&lt;/code&gt; around &lt;code&gt;9 pm&lt;/code&gt; and switched back to standby.&lt;/p&gt;
    &lt;head&gt;Here are some close-ups for the above periods&lt;/head&gt;
    &lt;p&gt;This is the lunchtime period. It is possible to observe the latency of the entire battery/VZLogger system. Nevertheless, the battery managed to dampen the brief periods of drawing power from the grid. On a few occasions, the battery did not react quickly enough and discharged briefly into the grid (yellow line above zero). However, since it is midday, this isn't too bad. There was still enough daylight left to recharge the battery.&lt;/p&gt;
    &lt;p&gt;In the second part (the right-hand side), we can see the inverse situation. The battery started charging again. There were only a few instances when the battery didn't react quickly enough and charged briefly from the grid (yellow line below zero). I also found this acceptable.&lt;/p&gt;
    &lt;p&gt;Later on in the evening (screenshot below), this was the transition from charging to discharging. There is really not much to complain about here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The automation managed to keep the battery at relatively steady levels for long periods.&lt;/item&gt;
      &lt;item&gt;Very few peaks were charged from the grid, which I found entirely acceptable.&lt;/item&gt;
      &lt;item&gt;The discharging period was even better, with the battery only discharging into the grid on two occasions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion#&lt;/head&gt;
    &lt;p&gt;The system works reliably. The latency is low enough (~10s interval) to cover base load effectively. By using the "Zero Export" logic with a calculated gap, the system doesn't oscillate.&lt;/p&gt;
    &lt;p&gt;I successfully avoided the manufacturer's cloud, kept the device isolated in a separate VLAN (or just offline via direct cable), and integrated it seamlessly into my existing Home Assistant environment.&lt;/p&gt;
    &lt;p&gt;Apologies for the mixture of German (screens) and English!&lt;/p&gt;
    &lt;head&gt;Changelog&lt;/head&gt;
    &lt;p&gt;2026-01-17&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Changed the upper load limit from 99% to 100%, as it doesn't make sense with LiFePO4 batteries to not charge the final percentage 7&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2026-01-16&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Significantly updated automation, mainly targeted to reduce oscillation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2026-01-15&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initial post.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Wiring pinout verification: forwardme.de ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inspiration and Register documentation from Michael Resch: reschcloud GitHub ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Home assistant naming and reference peculiarities ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marstek Register table (pdf) ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Discussions and support: Photovoltaikforum ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Based on feedback from a friendly discussion ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46643699</guid><pubDate>Fri, 16 Jan 2026 06:46:29 +0000</pubDate></item><item><title>Why DuckDB is my first choice for data processing</title><link>https://www.robinlinacre.com/recommend_duckdb/</link><description>&lt;doc fingerprint="f73b88c145a718b4"&gt;
  &lt;main&gt;&lt;p&gt;Originally posted: 2025-03-16. View source code for this page here.&lt;/p&gt;&lt;p&gt;Over the past few years, I've found myself using DuckDB more and more for data processing, to the point where I now use it almost exclusively, usually from within Python.&lt;/p&gt;&lt;p&gt;We're moving towards a simpler world where most tabular data can be processed on a single large machine1 and the era of clusters is coming to an end for all but the largest datasets.2&lt;/p&gt;&lt;p&gt;This post sets out some of my favourite features of DuckDB that set it apart from other SQL-based tools. In a nutshell, it's simple to install, ergonomic, fast, and more fully featured.&lt;/p&gt;&lt;p&gt;An earlier post explains why I favour SQL over other APIs such as Polars, pandas or dplyr.&lt;/p&gt;&lt;p&gt;DuckDB is an open source in-process SQL engine that is optimised for analytics queries.&lt;/p&gt;&lt;p&gt;The performance difference of analytics-optimised engines (OLAP) vs. transactions-optimised engines (OLTP) should not be underestimated. A query running in DuckDB can be 100 or even 1,000 times faster than exactly the same query running in (say) SQLite or Postgres.&lt;/p&gt;&lt;p&gt;A core use-case of DuckDB is where you have one or more large datasets on disk in formats like &lt;code&gt;csv&lt;/code&gt;, &lt;code&gt;parquet&lt;/code&gt; or &lt;code&gt;json&lt;/code&gt; which you want to batch process.  You may want to perform cleaning, joins, aggregation, derivation of new columns - that sort of thing.&lt;/p&gt;&lt;p&gt;But you can also use DuckDB for many other simpler tasks like viewing a csv file from the command line.&lt;/p&gt;&lt;p&gt;DuckDB consistently benchmarks as one of the fastest data processing engines. The benchmarks I've seen3 show there's not much in it between the leading open source engines - which at the moment seem to be polars, DuckDB, DataFusion, Spark and Dask. Spark and Dask can be competitive on large data, but slower on small data.&lt;/p&gt;&lt;p&gt;DuckDB itself is a single precompiled binary. In Python, it can be &lt;code&gt;pip install&lt;/code&gt;ed with no dependencies.  This makes it a joy to install compared to other more heavyweight options like Spark.  Combined with &lt;code&gt;uv&lt;/code&gt;, you can stand up a fresh DuckDB Python environment from nothing in less than a second - see here.&lt;/p&gt;&lt;p&gt;With its speed and almost-zero startup time, DuckDB is ideally suited for CI and testing of data engineering pipelines.&lt;/p&gt;&lt;p&gt;Historically this has been fiddly and running a large suite of tests in e.g. Apache Spark has been time consuming and frustrating. Now it's much simpler to set up the test environment, and there's less scope for differences between it and your production pipelines.&lt;/p&gt;&lt;p&gt;This simplicity and speed also applies to writing new SQL, and getting syntax right before running it on a large dataset. Historically I have found this annoying in engines like Spark (where it takes a few seconds to start Spark in local mode), or even worse when you're forced to run queries in a proprietary tool like AWS Athena.4&lt;/p&gt;&lt;p&gt;There's even a DuckDB UI with autocomplete - see here.&lt;/p&gt;&lt;p&gt;The DuckDB team has implemented a wide range of innovations in its SQL dialect that make it a joy to use. See the following blog posts 1 2 3 4 5 6.&lt;/p&gt;&lt;p&gt;Some of my favourites are the &lt;code&gt;EXCLUDE&lt;/code&gt; keyword, and the &lt;code&gt;COLUMNS&lt;/code&gt; keyword which allows you to select and regex-replace a subset of columns.5  I also like &lt;code&gt;QUALIFY&lt;/code&gt; and the aggregate modifiers on window functions, see here.&lt;/p&gt;&lt;p&gt;Another is the ability to function chain, like &lt;code&gt;first_name.lower().trim()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;You can query data directly from files, including on s3, or on the web.&lt;/p&gt;&lt;p&gt;For example to query a folder of parquet files:&lt;/p&gt;&lt;quote&gt;select *from read_parquet('path/to/*.parquet')&lt;/quote&gt;&lt;p&gt;or even (on CORS enabled files) you can run SQL directly:&lt;/p&gt;&lt;quote&gt;select *from read_parquet('https://raw.githubusercontent.com/plotly/datasets/master/2015_flights.parquet')limit 2;&lt;/quote&gt;&lt;p&gt;Click here to try this query yourself in the DuckDB web shell.&lt;/p&gt;&lt;p&gt;One of the easiest ways to cause problems in your data pipelines is to fail to be strict about incoming data types from untyped formats such as csv. DuckDB provides lots of options here - see here.&lt;/p&gt;&lt;p&gt;Many data pipelines effectively boil down to a long sequence of CTEs:&lt;/p&gt;&lt;quote&gt;WITHinput_data AS (SELECT * FROM read_parquet('...')),step_1 AS (SELECT ... FROM input_data JOIN ...),step_2 AS (SELECT ... FROM step_1)SELECT ... FROM step_2;&lt;/quote&gt;&lt;p&gt;When developing a pipeline like this, we often want to inspect what's happened at each step.&lt;/p&gt;&lt;p&gt;In Python, we can write&lt;/p&gt;&lt;quote&gt;input_data = duckdb.sql("SELECT * FROM read_parquet('...')")step_1 = duckdb.sql("SELECT ... FROM input_data JOIN ...")step_2 = duckdb.sql("SELECT ... FROM step_1")final = duckdb.sql("SELECT ... FROM step_2;")&lt;/quote&gt;&lt;p&gt;This makes it easy to inspect what the data looks like at &lt;code&gt;step_2&lt;/code&gt; with no performance loss, since these steps will be executed lazily when they're run all at once.&lt;/p&gt;&lt;p&gt;This also facilitates easier testing of SQL in CI, since each step can be an independently-tested function.&lt;/p&gt;&lt;p&gt;DuckDB offers full ACID compliance for bulk data operations, which sets it apart from other analytical data systems - see here. You can listen to more about this on in this podcast, transcribed here.&lt;/p&gt;&lt;p&gt;This is a very interesting new development, making DuckDB potentially a suitable replacement for lakehouse formats such as Iceberg or Delta lake for medium scale data.&lt;/p&gt;&lt;p&gt;A longstanding difficulty with data processing engines has been the difficulty in writing high performance user defined functions (UDFs).&lt;/p&gt;&lt;p&gt;For example, in PySpark, you will generally get best performance by writing custom Scala, compiling to a JAR, and registering it with Spark. But this is cumbersome and in practice, you will encounter a lot of issues around Spark version compatibility and security restrictions environments such as DataBricks.&lt;/p&gt;&lt;p&gt;In DuckDB high performance custom UDFs can be written in C++. Whilst writing these functions is certainly not trivial, DuckDB community extensions offers a low-friction way of distributing the code. Community extensions can be installed almost instantly with a single command such as &lt;code&gt;INSTALL h3 FROM community&lt;/code&gt; to install hierarchical hexagonal indexing for geospatial data.&lt;/p&gt;&lt;p&gt;The team provide documentation as a single markdown file so it can easily be provided to an LLM.&lt;/p&gt;&lt;p&gt;My top tip: if you load this file in your code editor, and use code folding, it's easy to copy the parts of the documentation you need into context.&lt;/p&gt;&lt;p&gt;Much of this blog post is based on my experience supporting multiple SQL dialects in Splink, an open source library for record linkage at scale. We've found that transitioning towards recommending DuckDB as the default backend choice has increased adoption of the library and significantly reduced the amount of problems faced by users, even for large linkage tasks, whilst speeding up workloads very substantially.&lt;/p&gt;&lt;p&gt;We've also found it's hugely increased the simplicity and speed of developing and testing new features.&lt;/p&gt;&lt;code&gt;pg_duckdb&lt;/code&gt; allows you to embed the DuckDB computation engine within Postgres.&lt;p&gt;The later in particular seems potentially extremely powerful, enabling Postgres to be simultanouesly optimised for analytics and transactional processing. I think it's likely to see widespread adoption, especially after they iron out a few of the current shortcomings around enabling and optimising the use of Postgres indexes and pushing up filters up to PostGres.&lt;/p&gt;&lt;p&gt;As a long-time Spark user, I am glad to be rid of needing to know lots of intricate configuration options for Spark tuning ��↩&lt;/p&gt;&lt;p&gt;With 192 core processors such as this available in the cloud and only costing around $15,000, the complexity of clusters can be avoided unless you have genuinely huge data. It's also worth noting there is actually now a distributed version of DuckDB, see here. ↩&lt;/p&gt;&lt;p&gt;For instance see here, here and here/discussion. ↩&lt;/p&gt;&lt;p&gt;To be clear, Athena is a very powerful and useful tool. I just find it frustrating for developing and quickly iterating queries of moderate complexity. An example of why it's easier in DuckDB is this kind of reprex. ↩&lt;/p&gt;&lt;p&gt;For instance, we can select all columns prefixed with &lt;code&gt;emp_&lt;/code&gt; and rename to remove the prefix as follows: &lt;code&gt;SELECT COLUMNS('emp_(.*)') AS '\1'&lt;/code&gt; ↩&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46645176</guid><pubDate>Fri, 16 Jan 2026 10:57:38 +0000</pubDate></item><item><title>Patching the Wii News Channel to serve local news (2025)</title><link>https://raulnegron.me/2025/wii-news-pr/</link><description>&lt;doc fingerprint="27443a3575ab2e9b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Patching the Wii News Channel to serve local news in 2025&lt;/head&gt;August 25, 2025&lt;p&gt;🎧 Now Playing: Menu (News Channel) via Nintendo Music App&lt;/p&gt;&lt;p&gt;In keeping with my passion (?) for displaying local news articles in unexpected places, I figured it would be a fun project to try and see what it would take to display current local news on the Nintendo Wii console’s News Channel.&lt;/p&gt;&lt;p&gt;Here’s a sneak peek at the result:&lt;/p&gt;&lt;p&gt;In this post, I’d like to share my research and process for getting this all to work.&lt;/p&gt;&lt;head&gt;tl;dr - click to expand (spoilers)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Patched the News Channel’s hardcoded Nintendo URL to point to an S3 storage bucket using Go and&lt;/p&gt;&lt;code&gt;wadlib&lt;/code&gt;to extract the necessary binary file and edit it in-memory&lt;/item&gt;&lt;item&gt;&lt;p&gt;Modified WiiLink’s open-source news file generator to add “El Nuevo Día” as a news source&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Set up AWS Lambda + EventBridge to regenerate the necessary news binary files hourly&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Source code: WiiNewsPR and WiiNewsPR-Patcher&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;The Wii’s News Channel&lt;/head&gt;&lt;p&gt;The News Channel debuted in North America on January 26, 2007, a little over two months after the Wii’s launch. Since that date, it mostly came pre-installed with Wii consoles and was a novel way to read news from all over the world. Together with other “utility” channels like the Forecast Channel, it tried to position the Wii as more than just a gaming console.&lt;/p&gt;&lt;p&gt;Check out a video recording of the service from right before it was discontinued on June 27th, 2013:&lt;/p&gt;&lt;head rend="h3"&gt;How the News Channel fetches content&lt;/head&gt;&lt;p&gt;Before we can consider displaying custom news on it, we have to figure out how the News Channel actually fetches content. We know that it must have fetched news somehow since it displays a “Downloading…” splash screen on startup.&lt;/p&gt;&lt;p&gt;Luckily for us, the Wii natively supports proxying via its internet connection configuration settings! Meaning we can set up something like mitmproxy on a local machine and observe its HTTP behavior.&lt;/p&gt;&lt;p&gt;We can start &lt;code&gt;mitmproxy&lt;/code&gt;’s web interface for a more screenshot-friendly UI:&lt;/p&gt;&lt;code&gt;mitmweb --listen-port 8080
&lt;/code&gt;&lt;p&gt;If we run a man-in-the-middle proxy for the News Channel on an unmodified Wii, we will observe that, on channel startup, it attempts to obtain a &lt;code&gt;news.bin.00&lt;/code&gt; file from &lt;code&gt;http://news.wapp.wii.com/v2/1/049/news.bin.00&lt;/code&gt; via a plain HTTP request.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;URL path explainer (we’ll see later how I found this out):&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;corresponds to “English” as the configured console language. See conf.h in&lt;code&gt;devkitPro&lt;/code&gt;(the Wii homebrew community’s de-facto development toolchain) for the possible values.&lt;code&gt;049&lt;/code&gt;is the Wii’s country code for “United States”. Check out the full list of Wii country codes on wiibrew.org.&lt;/quote&gt;&lt;p&gt;Once it fails to fetch this file, the News Channel displays an error. What might these binary files be? In any case, seeing the Wii perform an HTTP request to fetch news data is a good sign for us. It means we might be able to serve our own data.&lt;/p&gt;&lt;p&gt;By the way, if you run an internet connection test after configuring the proxy settings correctly, you’ll spot the Wii performing an HTTP request to http://conntest.nintendowifi.net. Turns out, this page is actually still online (see for yourself!)&lt;/p&gt;&lt;p&gt;The Wii’s internet connection test still passes to this day without any modification required. Thanks, Nintendo!&lt;/p&gt;&lt;head rend="h2"&gt;Enter WiiLink: the homebrew community keeping Wii online services alive&lt;/head&gt;&lt;p&gt;Up to this point, this is how we would expect the Wii would behave if you were running a stock console. More than 12 years ago, Nintendo discontinued support for the online functionality of the News Channel.&lt;/p&gt;&lt;p&gt;But as expected for a beloved retro console, community efforts have sprung up to try and preserve the previously existing functionality and allow users to continue enjoying these systems well past their intended expiration date. These sorts of unofficial software for gaming consoles are commonly referred to as “homebrew”.&lt;/p&gt;&lt;p&gt;Importantly for this project, the WiiLink team maintains servers and develops software that allows us to experience the Wii’s online connectivity features even today.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;By the way, if you’re curious about how to get started with Wii console homebrew, check out https://wii.hacks.guide.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Thanks to WiiLink, we can revive the News Channel and browse up-to-date news! Just not the local news, which is our real goal.&lt;/p&gt;&lt;head rend="h3"&gt;How WiiLink patches the News Channel&lt;/head&gt;&lt;p&gt;After going through the WiiLink install process, if we fire up &lt;code&gt;mitmproxy&lt;/code&gt; and take a look at what the Wii is doing now, we’ll see that it’s actually requesting files from a different domain: “news.wiilink.ca”. But this time, it manages to fetch &lt;code&gt;news.bin.00&lt;/code&gt; and keeps requesting files all the way up to &lt;code&gt;news.bin.23&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The News Channel just successfully fetched 24 hours worth of news from this server.&lt;/p&gt;&lt;p&gt;Great! Somehow, the WiiLink folks got this all to work. And, best of all, they’ve opened-sourced their work (GitHub). The plan is looking really feasible at this point!&lt;/p&gt;&lt;p&gt;At a high-level, there are two steps to tackle, then:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;We have to make the News Channel fetch files from a server we control&lt;/item&gt;&lt;item&gt;We need to actually generate binary files with the content we want&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Step 1: Patching the News Channel to redirect to our domain&lt;/head&gt;&lt;p&gt;If we follow along with WiiLink’s installation guide, the critical step seems to be installing a patched version of the News Channel. Looking at their GitHub org, we find a WiiLink24-Patcher project. Searching for the “News Channel” in the source code, we find this line in patch.cs which references a VCDIFF encoded &lt;code&gt;News_1.delta&lt;/code&gt; patch.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Side note - it’s only while writing this blog post that I realized I had been looking at the “wrong” repo; WiiLink’s guide now recommends using the Python-based WiiLink-Patcher-GUI instead of the CLI patcher.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;After downloading the &lt;code&gt;.delta&lt;/code&gt; file locally, we can use the xdelta CLI to print out some information on what the patch is supposed to do:&lt;/p&gt;&lt;code&gt;xdelta3 printdelta News_1.delta

VCDIFF version:               0
VCDIFF header size:           29
VCDIFF header indicator:      VCD_APPHEADER
VCDIFF secondary compressor:  lzma
VCDIFF application header:    news.dol//0000000b.app/
XDELTA filename (output):     news.dol
XDELTA filename (source):     0000000b.app
...
&lt;/code&gt;&lt;p&gt;Okay, so we’re looking for a &lt;code&gt;0000000b.app&lt;/code&gt; file and want to save the patched binary as &lt;code&gt;news.dol&lt;/code&gt;. Based on the WiiLink install instructions, we know we should be dealing with a &lt;code&gt;WAD&lt;/code&gt; file, so let’s keep digging to see if we can find out where &lt;code&gt;0000000b.app&lt;/code&gt; might be hiding.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Learn more about the WAD file format on wiibrew.org.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;From the repo’s &lt;code&gt;README.md&lt;/code&gt;, we know the patcher uses libWiiSharp for it’s WAD file management during the file patching processing (source). But at this point, I’d rather avoid using C# if I can. And besides, I know for a fact we’ll want to use Go in order to more easily leverage existing tooling from the WiiLink team.&lt;/p&gt;&lt;p&gt;Thankfully, there’s a really handy Go library called wadlib that comes to the rescue here. We’ll be using it for all our WAD management needs.&lt;/p&gt;&lt;p&gt;So, where is &lt;code&gt;0000000b.app&lt;/code&gt;? Looking at LibWiiSharp’s &lt;code&gt;WAD.cs&lt;/code&gt; file, we can spot how it unpacks &lt;code&gt;.app&lt;/code&gt; files from a WAD file. Namely, it defaults to using the numeric “Content ID” inside each “Content” metadata and then converts it to an 8-digit hexadecimal string (source).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You can read more about Title metadata (“TMD”) and Content metadata (“CMD”) on wiibrew.org&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Armed with this knowledge, we can use &lt;code&gt;wadlib&lt;/code&gt; to create a quick file extraction script and see if we can find our &lt;code&gt;0000000b.app&lt;/code&gt;. It can go something like this:&lt;/p&gt;&lt;code&gt;// ignore error handling for brevity
wad, _ := wadlib.LoadWADFromFile("news.wad")
titleMetadata := wad.TMD
contentMetadata := titleMetadata.Contents

outputDir := "extracted_wad/"
os.MkdirAll(outputDir, 0755)

for i := 0; i &amp;lt; len(wad.Data); i++ {
  data, _ := wad.GetContent(i)

  contentID := contentMetadata[i].ID

  // "%08x" means 0-padded 8 digit hex
  filename := filepath.Join(outputDir, fmt.Sprintf("%08x.app", contentID))
  _ = os.WriteFile(filename, data, 0644)

  log.Printf("Extracted: %08x.app (size: %d bytes)",
    contentID, len(data))
}
&lt;/code&gt;&lt;p&gt;When &lt;code&gt;news.wad&lt;/code&gt; is the official (v7) News Channel WAD file, this script successfully extracts 12 &lt;code&gt;.app&lt;/code&gt; files.&lt;/p&gt;&lt;p&gt;There’s definitely a &lt;code&gt;0000000b.app&lt;/code&gt; there, but could it be the file we’re looking for?&lt;/p&gt;&lt;p&gt;What we really need to do at this point is go ahead and apply the &lt;code&gt;News_1.delta&lt;/code&gt; patch to this &lt;code&gt;0000000b.app&lt;/code&gt; file manually. That way, we can compare the before/after binaries and see what changed. We can use &lt;code&gt;xdelta&lt;/code&gt; again to actually apply the patch. Running &lt;code&gt;xdelta3 --help&lt;/code&gt; says:&lt;/p&gt;&lt;code&gt;apply patch:
  xdelta3.exe -d -s old_file delta_file decoded_new_file
&lt;/code&gt;&lt;p&gt;So we can go ahead and run:&lt;/p&gt;&lt;code&gt;xdelta3 -d -s extracted_wad/0000000b.app News_1.delta news.dol
&lt;/code&gt;&lt;p&gt;And that… seemed to work? We have a &lt;code&gt;news.dol&lt;/code&gt; file, as expected. Now what?&lt;/p&gt;&lt;head rend="h3"&gt;Investigating binary file changes&lt;/head&gt;&lt;p&gt;We could do a binary diff of these files and start going through each change, but we already know at least one thing that should have changed based on our previous &lt;code&gt;mitmproxy&lt;/code&gt; experiments: instead of performing requests to “news.wapp.wii.com”, the patched WAD should instead use “news.wiilink.ca”.&lt;/p&gt;&lt;p&gt;Using a tool like Hex Fiend (which also has binary diffing capabilities in case we need them), we can try searching for text inside the binary. If we try searching for “news.wapp.wii.com” on the original &lt;code&gt;0000000b.app&lt;/code&gt; file, we can actually find a match!&lt;/p&gt;&lt;p&gt;Sure enough, if we inspect the patched &lt;code&gt;news.dol&lt;/code&gt; file we will find no mention of the original URL. Instead, the “http://news.wiilink.ca” domain is visible at the same location (offset &lt;code&gt;0x1AC37C&lt;/code&gt;).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note that the URL contains only two printf-style format strings (&lt;/p&gt;&lt;code&gt;%d&lt;/code&gt;and&lt;code&gt;%03d&lt;/code&gt;); the News Channel itself must be appending the hourly suffix (like&lt;code&gt;.00&lt;/code&gt;) when fetching data.&lt;/quote&gt;&lt;p&gt;If we’re lucky, simply overwriting the binary file’s original URL with our own custom URL might do the trick. It’s worth a try!&lt;/p&gt;&lt;p&gt;In order to validate this hypothesis, I wrote a small Go utility for performing the necessary text replacement. Here’s an excerpt of the important bits:&lt;/p&gt;&lt;code&gt;// ignoring error handling for brevity
const OriginalURL = "http://news.wapp.wii.com/v2/%d/%03d/news.bin"
const NewURL = "http://wii.rauln.com/news/%d/%03d/news.bin"

wad, _ := wadlib.LoadWADFromFile(wadPath)

// Get decrypted content at index 1 (record with ID "0000000b")
content, _ := wad.GetContent(1)

// byte slice of 44 bytes
originalContent := []byte(OriginalURL)

// 43 bytes in our URL's case
newContent := []byte(NewURL)

// Pad the new URL to match original length (44 bytes)
paddedURL := make([]byte, len(originalContent))
copy(paddedURL, newContent)

// Find the offset (index) of the URL to patch inside the byte slice
offset := bytes.Index(content, originalContent)

// Patch the URL
copy(content[offset:offset+len(originalContent)], paddedURL)
_ = wad.UpdateContent(1, content)

// Save the updated WAD file
_ = os.WriteFile(outputPath, wadBytes, 0644)
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;Check out the full source on GitHub: WiiNewsPR-Patcher&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;If we run the utility like:&lt;/p&gt;&lt;code&gt;go build
wiinewspr-patcher news.wad patched_news.wad
&lt;/code&gt;&lt;p&gt;It should perform the URL rewriting in memory and provide us with a valid WAD file (&lt;code&gt;patched_news.wad&lt;/code&gt;) we can then go ahead and install on Wii hardware.&lt;/p&gt;&lt;p&gt;We can install the patched WAD on our Wii console using YAWM (ModMii Edition).&lt;/p&gt;&lt;p&gt;Finally, we can go back to running &lt;code&gt;mitmproxy&lt;/code&gt; and opening the newly patched News Channel. Once the channel shows the “Downloading…” splash screen, we’ll spot requests going out to our expected domain.&lt;/p&gt;&lt;p&gt;It works! Now all we need is to… actually generate valid news files for the News Channel to work.&lt;/p&gt;&lt;head rend="h2"&gt;Step 2: Generating News Channel compatible news files&lt;/head&gt;&lt;p&gt;I mentioned previously that I knew using Go would come in handy later, and it’s specifically because the WiiLink team has a project called NewsChannel written in Go which contains the source code for generating the binary news files they serve from “news.wiilink.ca”.&lt;/p&gt;&lt;p&gt;I’m not going to go over all the implementation details here. I just want to highlight some of the main file creation steps in case you’d like to read more:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;obtain country-specific configuration (source)&lt;/item&gt;&lt;item&gt;obtain articles and metadata from configured sources (like NHK, source)&lt;/item&gt;&lt;item&gt;process all data in a specific order into a bytes buffer (source)&lt;/item&gt;&lt;item&gt;compress the data using LZ10, sign it with RSA, then write to disk (source) &lt;list rend="ul"&gt;&lt;item&gt;the file name is written using a specific string interpolation (source, this is how I first found out about the language/country codes used in the News Channel data URL!)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;&lt;p&gt;Fun fact: LZ10 is apparently a Nintendo-specific variant of the LZ77 compression algorithm, used in some form or another on Game Boy Advance, Nintendo DS and Wii systems. wii-tools/lzx has the Go source for the LZ10 compression used here.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;In any case, for our purposes, it’s doing more than we need in terms of source handling: it can generate news binaries from a variety of sources and supports different languages and regions.&lt;/p&gt;&lt;p&gt;For this project, I am making the following assumptions and tradeoffs:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;I will be using “English” as the language and “US” as the country code for the source URL path since my Wii console is configured as such. There is no separate Puerto Rico country code option, which is curious considering that there is a separate option for the US Virgin Islands.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I am not interested in supporting any other news sources from around the world, so the “Globe” feature for the News Channel will not be useful.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I’m hardcoding the latitude and longitude of Puerto Rico’s capital into the binary file to avoid having to process or guess location data from each article entry.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Modifying WiiLink’s generator to support Puerto Rican news&lt;/head&gt;&lt;p&gt;I went ahead and forked the &lt;code&gt;NewsChannel&lt;/code&gt; repo into WiiNewsPR, added flag support to control article caching and binary output paths (you’ll see why this was necessary soon), removed all the existing sources and added a new one: El Nuevo Día (“ENDI”).&lt;/p&gt;&lt;p&gt;I picked ENDI only because it’s the only local newspaper website I could find which still supports RSS. Unfortunately, the feeds only contain a snippet of the actual article. On the bright side, most articles do contain images and we can use separate feeds to help categorize articles in the News Channel (source).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;By the way, I experimented with GoOse for (spanish language) article extraction on other news websites and the results were… unsatisfying, to say the least.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;Final setup requirements for proper News Channel support&lt;/head&gt;&lt;p&gt;Two quick things we’ll need in order to get this all to work:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;We need to sign each binary news file with a custom RSA key for the Wii to process the file (source). We can use &lt;code&gt;openssl&lt;/code&gt;for this (note the&lt;code&gt;-traditional&lt;/code&gt;option):&lt;/item&gt;&lt;/list&gt;&lt;code&gt; openssl genrsa -traditional -out Private.pem 2048
&lt;/code&gt;&lt;list rend="ol"&gt;&lt;item&gt;We need a (really) low quality logo for our source. ImageMagick easily solves for this:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;magick logo.svg -quality 30 -resize 200x200 -strip logo.jpg
&lt;/code&gt;&lt;p&gt;Then, we can use Go embeds to include the logo in the Go binary (source).&lt;/p&gt;&lt;p&gt;Finally, we can build the Go binary and run it in order to generate a news binary in &lt;code&gt;./v2/1/049&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;go build
./WiiNewsPR
&lt;/code&gt;&lt;p&gt;This successfully generates a &lt;code&gt;news.bin.NN&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;Now we just need 24 of these, since the News Channel will actually fail to load if not provided with all 24 files. We could run this script every hour for the next 24 hours… or, we could take the shortcut of copying the current hour’s file into all other hourly values.&lt;/p&gt;&lt;p&gt;Regardless, it’s about time to test out all this effort. With 24 files uploaded to our storage provider (AWS S3), and the patched News Channel configured to fetch these from our custom domain, we can start up the channel and observe the fruits of our labor.&lt;/p&gt;&lt;p&gt;After the (slow!) requests finish one by one, seeing the articles pop up was immensely satisfying. Being able to tinker with and learn more about these nostalgic consoles so many years later is a real joy for me.&lt;/p&gt;&lt;head rend="h2"&gt;Bonus step: Automating hourly news updates with AWS Lambda&lt;/head&gt;&lt;p&gt;Copying files into the S3 storage bucket is all well and good, but it would be great to have a continuously-updating, hands-off solution that generates the news binaries for us. A simple (and basically free) way to solve for this would be to bundle up the &lt;code&gt;WiiNewsPR&lt;/code&gt; Go executable into an AWS Lambda function and have that run hourly via EventBride, and then uploading the generated news binaries over to our storage bucket.&lt;/p&gt;&lt;p&gt;Here is where the extra flags for &lt;code&gt;WiiNewsPR&lt;/code&gt; come in: we need to be able to control file creation because &lt;code&gt;/tmp&lt;/code&gt; is a Lambda’s only writeable file system.&lt;/p&gt;&lt;p&gt;Here is a snippet of the Lambda handler logic:&lt;/p&gt;&lt;code&gt;func Handler(ctx context.Context) error {
  cmd := exec.CommandContext(ctx, "./WiiNewsPR", "-o", "/tmp", "-c", "/tmp/cache")
  // ...

  _, err = uploader.Upload(ctx, &amp;amp;s3.PutObjectInput{
		Bucket:      aws.String(bucketName),
		Key:         aws.String(fmt.Sprintf("%snews.bin.%s", keyPrefix, hour)),
		Body:        file,
		ContentType: aws.String("application/octet-stream"),
	})
  // ...
}

func main() {
  lambda.Start(Handler)
}
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;See full Lambda handler source on GitHub: handler.go&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We can then leverage the Serverless framework for a quick infra-as-code setup. Here is a snippet of the configuration:&lt;/p&gt;&lt;code&gt;service: wiinewspr-generator

provider:
  name: aws
  # ...
  environment:
    # ...
    TZ: America/Puerto_Rico # we need Lambda to generate files postfixed with the correct "currentHour"
    # ...
    events:
      - schedule:
          rate: cron(30 * * * ? *) # run every hour:30
          name: wiinewspr-every-30pasthour
          description: Generate Wii News PR binary file every hour at 30 minutes past
package:
  patterns:
    - bootstrap # compiled Lambda handler
    - WiiNewsPR # compiled binary news generator
    - ../Private.pem # we need to include the Private.pem file for file signing
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;See full&lt;/p&gt;&lt;code&gt;serverless&lt;/code&gt;configuration on GitHub: serverless.yml&lt;/quote&gt;&lt;p&gt;Some things to call out here:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;We want to make sure to run the Lambda in Puerto Rico’s timezone so that &lt;code&gt;time.Now()&lt;/code&gt;returns the expected hourly integer.&lt;/item&gt;&lt;item&gt;We want to give the Lambda a higher than expected &lt;code&gt;memorySize&lt;/code&gt;so that its CPU scales accordingly; it turns out that&lt;code&gt;lz10&lt;/code&gt;compression is a big bottleneck on the smallest supported Lambda CPU and can easily time out at 30 seconds.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If we leave this setup running for 24 hours, our storage bucket will get populated with 24 files and continuously be updated with the latest news!&lt;/p&gt;&lt;p&gt;Now I can get up in the morning, grab a coffee, and browse the local news on my Nintendo Wii like it’s 2007.&lt;/p&gt;&lt;p&gt;Thanks for reading!&lt;/p&gt;&lt;head rend="h2"&gt;Credits&lt;/head&gt;&lt;p&gt;This experiment would have likely ended in disappointment if not for the amazing work by the Wii homebrew community, specifically: RiiConnect24 Team, WiiLink Team and wiibrew.org Contributors.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46645941</guid><pubDate>Fri, 16 Jan 2026 12:58:24 +0000</pubDate></item><item><title>Dev-owned testing: Why it fails in practice and succeeds in theory</title><link>https://dl.acm.org/doi/10.1145/3780063.3780066</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46646226</guid><pubDate>Fri, 16 Jan 2026 13:39:31 +0000</pubDate></item><item><title>Michelangelo's first painting, created when he was 12 or 13</title><link>https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html</link><description>&lt;doc fingerprint="ad990b521b25664"&gt;
  &lt;main&gt;
    &lt;p&gt;Think back, if you will, to the works of art you created at age twelve or thirteen. For many, perhaps most of us, our output at that stage of adolescence amounted to directionless doodles, chaotic comics, and a few unsteady-at-best school projects. But then, most of us didn’t grow up to be Michelangelo. In the late fourteen-eighties, when that towering Renaissance artist was still what we would now call a “tween,” he painted The Torment of Saint Anthony, a depiction of the titular religious figure beset by demons in the desert. Though based on a widely known engraving, it nevertheless shows evidence of rapidly advancing technique, inspiration, and even creativity — especially when placed under the infrared scanner.&lt;/p&gt;
    &lt;p&gt;For about half a millennium, The Torment of Saint Anthony wasn’t thought to have been painted by Michelangelo. As explained in the video from Inspiraggio just below, when the painting sold at Sotheby’s in 2008, the buyer took it to the Metropolitan Museum of Art for examination and cleaning.&lt;/p&gt;
    &lt;p&gt;“Beneath the layers of dirt accumulated over the centuries,” says the narrator, “a very particular color palette appeared. “The tones, the blends, the way the human figure was treated: all of it began to resemble the style Michelangelo would use years later in none other than the Sistine Chapel.” Infrared reflectography subsequently turned up pentimenti, or correction marks, a common indication that “a painting is not a copy, but an original work created with artistic freedom.”&lt;/p&gt;
    &lt;p&gt;It was the Kimbell Art Museum in Fort Worth, Texas that first bet big on the provenance of The Torment of Saint Anthony. Its newly hired director purchased the painting after turning up “not a single convincing argument against the attribution.” Thus acquired, it became “the only painting by Michelangelo located anywhere in the Americas, and also just one of four easel paintings attributed to him throughout his entire career,” during most of which he disparaged oil painting itself. About a decade later, and after further analysis, the art historian Giorgio Bonsanti put his considerable authority behind a definitive confirmation that it is indeed the work of the young Michelangelo. There remain doubters, of course, and even the notoriously uncompromising artist himself may have considered it an immature work unworthy of his name. But who else could have created an immature work like it?&lt;/p&gt;
    &lt;p&gt;Related Content:&lt;/p&gt;
    &lt;p&gt;How Four Masters — Michelangelo, Donatello, Verrocchio &amp;amp; Bernini — Sculpted David&lt;/p&gt;
    &lt;p&gt;A Secret Room with Drawings Attributed to Michelangelo Opens to Visitors in Florence&lt;/p&gt;
    &lt;p&gt;Michelangelo’s Illustrated Grocery List&lt;/p&gt;
    &lt;p&gt;Based in Seoul, Colin Marshall writes and broadcasts on cities, language, and culture. He’s the author of the newsletter Books on Cities as well as the books 한국 요약 금지 (No Summarizing Korea) and Korean Newtro. Follow him on the social network formerly known as Twitter at @colinmarshall.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46646263</guid><pubDate>Fri, 16 Jan 2026 13:44:25 +0000</pubDate></item><item><title>Cloudflare acquires Astro</title><link>https://astro.build/blog/joining-cloudflare/</link><description>&lt;doc fingerprint="7fa05838a90aa8e6"&gt;
  &lt;main&gt;
    &lt;p&gt;The Astro Technology Company — the company behind the Astro web framework — is joining Cloudflare! Adoption of the Astro web framework continues to double every year, and Astro 6 is right around the corner. With Cloudflare’s support, we’ll have more resources and fewer distractions to continue our mission to build the best framework for content-driven websites.&lt;/p&gt;
    &lt;p&gt;What this means for Astro:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Astro stays open-source and MIT-licensed&lt;/item&gt;
      &lt;item&gt;Astro continues to be actively maintained&lt;/item&gt;
      &lt;item&gt;Astro continues to support a wide set of deployment targets, not just Cloudflare&lt;/item&gt;
      &lt;item&gt;Astro’s open governance and current roadmap remain in place.&lt;/item&gt;
      &lt;item&gt;All full-time employees of The Astro Technology Company are now employees of Cloudflare, and will continue to work on Astro full-time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How Astro started&lt;/head&gt;
    &lt;p&gt;In 2021, Astro was born out of frustration. The trend at the time was that every website should be architected as an application, and then shipped to the user’s browser to render. This was not very performant, and we’ve spent the last decade coming up with more and more complex solutions to solve for that performance problem. SSR, ISR, RSC, PPR, TTI optimizations via code-splitting, tree-shaking, lazy-loading, all to generate a blocking double-data hydration payload from a pre-warmed server running halfway around the world.&lt;/p&gt;
    &lt;p&gt;Our mission to design a web framework specifically for building websites — what we call content-driven websites, to better distinguish from data-driven, stateful web applications — resonated. Now Astro is downloaded almost 1,000,000 times per week, and has been used by 100,000s of developers to build fast, beautiful websites. Today you’ll find Astro all over the web, powering major websites and even entire developer platforms for companies like Webflow, Wix, Microsoft, and Google.&lt;/p&gt;
    &lt;p&gt;Along the way, we also tried to grow a business. In 2021 we raised some money and formed The Astro Technology Company. Our larger vision was that a well-designed framework like Astro could sit at the center of a massive developer platform, with optional hosted primitives (database, storage, analytics) designed in lockstep with the framework.&lt;/p&gt;
    &lt;p&gt;We were never able to realize this vision. Attempts to introduce paid, hosted primitives into our ecosystem fell flat, and rarely justified their own existence. We considered going more directly after first-class hosting or content management for Astro, but knew we’d spend much of our time playing catchup to well-funded, savvy competitors. We kept exploring different ideas, but nothing clicked with users the same way Astro did.&lt;/p&gt;
    &lt;p&gt;It wasn’t all bad. Astro DB (our attempt to build a hosted database product for Astro projects) eventually evolved into the open, built-in Astro database client that still lives in core today. Our exploration into building an e-commerce layer with Astro was eventually open-sourced. It was rewarding work, but over the years the distraction took its toll. Each attempt at a new paid product or offering took myself and others on the project away from working on the Astro framework that developers were using and loving every day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Returning to Focus&lt;/head&gt;
    &lt;p&gt;Last year, Dane (Cloudflare CTO) and I began to talk more seriously about the future of the web. Those conversations quickly grew into something bigger: What does the next decade look like? How do frameworks adapt to a world of AI coding and agents?&lt;/p&gt;
    &lt;p&gt;It became clear that even as web technologies evolve, content remains at the center. We realized that we’ve each been working toward this same vision from different angles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cloudflare has been solving it from the infrastructure side: betting on a platform that is global by default, with fast startup, low latency, and security built-in.&lt;/item&gt;
      &lt;item&gt;Astro has been solving it from the framework side: betting on a web framework that makes it easy to build sites that are fast by default, without overcomplicating things.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The overlap is obvious. By working together, Cloudflare gives us the backing we need to keep innovating for our users. Now we can stop spending cycles worrying about building a business on top of Astro, and start focusing 100% on the code, with a shared vision to move the web forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cloudflare ❤️ Astro&lt;/head&gt;
    &lt;p&gt;Cloudflare has been a long-time sponsor and champion of Astro. They have a proven track record of supporting great open-source projects like Astro, TanStack, and Hono without trying to capture or lock anything down. Staying open to all was a non-negotiable requirement for both us and for Cloudflare.&lt;/p&gt;
    &lt;p&gt;That is why Astro will remain free, open-source, and MIT-licensed. We will continue to run our project in the open, with an open governance model for contributors and an open community roadmap that anyone can participate in. We remain fully committed to maintaining Astro as a platform-agnostic framework, meaning we will continue to support and improve deployments for all targets—not just Cloudflare.&lt;/p&gt;
    &lt;p&gt;With Cloudflare’s resources and support, we can now return our focus fully towards building the best web framework for content-driven websites. The web is changing fast, and the bar keeps rising: performance, scale, reliability, and a better experience for the teams shipping content on the web.&lt;/p&gt;
    &lt;p&gt;You’ll see that focus reflected across our roadmap, as we prepare for the upcoming Astro 6 release (beta out now!) and our 2026 roadmap. Stay tuned!&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;I want to extend a huge thank you to the agencies, companies, sponsors, partners, and theme authors who chose to work with us over the years. Thank you to our initial investors — Haystack, Gradient, Uncorrelated, Lightspeed — without whom Astro likely wouldn’t exist. Thank you to everyone in our open source community who continues to help make Astro better every day. And finally, thank you to everyone who uses Astro and puts their trust in us to help them build for the web.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46646645</guid><pubDate>Fri, 16 Jan 2026 14:25:54 +0000</pubDate></item><item><title>Cursor's latest “browser experiment” implied success without evidence</title><link>https://embedding-shapes.github.io/cursor-implied-success-without-evidence/</link><description>&lt;doc fingerprint="a645901deb75300c"&gt;
  &lt;main&gt;
    &lt;p&gt;2026-01-16&lt;/p&gt;
    &lt;head rend="h1"&gt;Cursor's latest "browser experiment" implied success without evidence&lt;/head&gt;
    &lt;p&gt;On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)&lt;/p&gt;
    &lt;p&gt;In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;They talk about some approaches they tried, why they think those failed, and how to address the difficulties.&lt;/p&gt;
    &lt;p&gt;Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say explicitly.&lt;/p&gt;
    &lt;p&gt;After this, they embed the following video:&lt;/p&gt;
    &lt;p&gt;And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".&lt;/p&gt;
    &lt;head rend="h3"&gt;They never actually claim this browser is working and functional&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.&lt;/p&gt;
    &lt;p&gt;Multiple recent GitHub Actions runs on &lt;code&gt;main&lt;/code&gt; show
failures (including workflow-file errors), and independent build
attempts report dozens of compiler errors, recent PRs were all merged
with failing CI, and going back in the Git history from most recent
commit back 100 commits,&lt;lb/&gt;I couldn't find a single commit that compiled cleanly.&lt;/p&gt;
    &lt;p&gt;I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98&lt;/p&gt;
    &lt;p&gt;And diving into the codebase, if the compilation errors didn't make that clear already, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality something that surely represents something, but it doesn't have intention behind it, and it doesn't even compile at this point.&lt;/p&gt;
    &lt;p&gt;They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo and no known-good revision (tag/release/commit) to verify the screenshots, beyond linking the repo.&lt;/p&gt;
    &lt;p&gt;Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.&lt;/p&gt;
    &lt;p&gt;They finish off the article saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.&lt;/p&gt;
    &lt;p&gt;A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn’t demonstrate that bar, and current public build attempts fail at this too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.&lt;/p&gt;
    &lt;p&gt;The closest they get to implying that this was a success, is this part:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can be reproduced.&lt;/p&gt;
    &lt;p&gt;I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/p&gt;
    &lt;head&gt;Versions&lt;/head&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;db6064b&lt;/code&gt; Add link to tested commits&lt;/head&gt;
    &lt;code&gt;@@ -33 +33 @@ And if you try to compile it yourself, you'll see that it's very far away from b

  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent commit back-about

   100 -commits, I
+commits,&amp;lt;br/&amp;gt;[I

   couldn't find a single commit that compiled -cleanly.
+cleanly](https://gist.github.com/embedding-shapes/f5d096dd10be44ff82b6e5ccdaf00b29).&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;3dcd6e7&lt;/code&gt; Fix linebreak typo&lt;/head&gt;
    &lt;code&gt;@@ -9,3 +9 @@ On January 14th 2026, Cursor published a blog post titled "Scaling long-running
-In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
-
-with the explicit goal of
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;c74ab74&lt;/code&gt; Fix favicon, fix typos, made better simply&lt;/head&gt;
    &lt;code&gt;@@ -33 +33,3 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.
  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent -commit,
+commit back about 100 commits,

   I couldn't find a single commit that compiled cleanly.@@ -37 +39 @@ I'm not sure what the "agents" they unleashed on this codebase actually did, but

  And diving into the codebase, if the compilation errors didn't make that -sure,
+clear already,

   makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.@@ -59 +61 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can +be
   reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;bafc54f&lt;/code&gt; Favicon + changes + cursor video&lt;/head&gt;
    &lt;code&gt;@@ -21 +21 @@ Finally they arrived at a point where something "solved most of our coordination

  This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never -say.
+say explicitly.
@@ -25 +25 @@ After this, they embed the following video:
-[video]
+![](/content/cursor-screenshots.webm)
@@ -33 +33 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent -CI workflow
+GitHub Actions

   runs on `main` -are failing, all the
+show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent

   PRs were +all

   merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.@@ -39 +39,3 @@ And diving into the codebase, if the compilation errors didn't make that sure, m

  They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible -demo/build instructions or
+demo and no

   known-good -commit,
+revision (tag/release/commit) to verify the screenshots,

   beyond linking the repo.
  Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.@@ -46,0 +49,2 @@ Which seems like a really strange conclusion to arrive at, when all they've prov
+A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn’t demonstrate that bar, and current public build attempts fail at this too.
@@ -55 +59 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. -They
+In the blog post they
   never provide a working commit, build instructions or even a demo that can reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;d664475&lt;/code&gt; Move&lt;/head&gt;
    &lt;code&gt;@@ -0,0 +1,57 @@
+---
+date: 2026-01-16
+---
+
+# Cursor's latest "browser experiment" implied success without evidence
+
+On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)
+
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
+
+with the explicit goal of
+
+&amp;gt; understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete
+
+They talk about some approaches they tried, why they think those failed, and how to address the difficulties.
+
+Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:
+
+&amp;gt; To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)
+
+This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say.
+
+After this, they embed the following video:
+
+[video]
+
+And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".
+
+### They never actually claim this browser is working and functional
+
+&amp;gt; error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted
+
+And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent CI workflow runs on `main` are failing, all the PRs were merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.
+
+I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98
+
+And diving into the codebase, if the compilation errors didn't make that sure, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.
+
+They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo/build instructions or known-good commit, beyond linking the repo. Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.
+
+They finish off the article saying:
+
+&amp;gt; But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.
+
+Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.
+
+## Conclusion
+
+Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.
+
+The closest they get to implying that this was a success, is this part:
+
+&amp;gt; Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.
+
+But this extraordinary claim isn't backed up by any evidence. They never provide a working commit, build instructions or even a demo that can reproduced.
+
+I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46646777</guid><pubDate>Fri, 16 Jan 2026 14:37:49 +0000</pubDate></item><item><title>6-Day and IP Address Certificates Are Generally Available</title><link>https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability</link><description>&lt;doc fingerprint="e659e0db14317484"&gt;
  &lt;main&gt;
    &lt;p&gt;Short-lived and IP address certificates are now generally available from Let’s Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‘shortlived’ certificate profile in their ACME client.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate’s private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate’s expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well.&lt;/p&gt;
    &lt;p&gt;Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, as previously announced.&lt;/p&gt;
    &lt;p&gt;IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let’s Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our post announcing our first IP Certificate.&lt;/p&gt;
    &lt;p&gt;We’d like to thank the Open Technology Fund and Sovereign Tech Agency, along with our Sponsors and Donors, for supporting the development of this work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46647491</guid><pubDate>Fri, 16 Jan 2026 15:37:19 +0000</pubDate></item><item><title>Zep AI (Agent Context Engineering, YC W24) Is Hiring Forward Deployed Engineers</title><link>https://www.ycombinator.com/companies/zep-ai/jobs/</link><description>&lt;doc fingerprint="af57259bffd2ec7b"&gt;
  &lt;main&gt;
    &lt;p&gt;Agent Context Is Hard. We Fixed It.&lt;/p&gt;
    &lt;p&gt;Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46648714</guid><pubDate>Fri, 16 Jan 2026 17:00:29 +0000</pubDate></item><item><title>Dell UltraSharp 52 Thunderbolt Hub Monitor</title><link>https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories</link><description>&lt;doc fingerprint="e22dab5494a79c42"&gt;
  &lt;main&gt;&lt;p&gt;Selecting will change the following options:&lt;/p&gt;&lt;p&gt;From To&lt;/p&gt;&lt;p&gt;51.5"&lt;/p&gt;&lt;p&gt;6144 x 2560 at 120Hz&lt;/p&gt;&lt;p&gt;In-plane Switching (IPS) Black Technology&lt;/p&gt;&lt;p&gt;99% DCI-P3 (CIE 1976)&lt;/p&gt;&lt;p&gt;100% sRGB (CIE 1931)&lt;/p&gt;...See More See More Color Gamut&lt;p&gt;2 HDMI port/s (HDCP 2.2) (Supports up to 6144 x 2560, 120 Hz, VRR, , as specified in HDMI 2.1 (FRL))&lt;/p&gt;&lt;p&gt;2 DisplayPort 1.4 (HDCP 2.2) port/s&lt;/p&gt;...See More See More Ports&lt;p&gt;Add the products you would like to compare, and quickly determine which is best for your needs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46648885</guid><pubDate>Fri, 16 Jan 2026 17:14:15 +0000</pubDate></item><item><title>East Germany balloon escape</title><link>https://en.wikipedia.org/wiki/East_Germany_balloon_escape</link><description>&lt;doc fingerprint="be46c17b47664bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;East Germany balloon escape&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Native name&lt;/cell&gt;&lt;cell&gt;Die Ballonflucht&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Date&lt;/cell&gt;&lt;cell&gt;16 September 1979&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Time&lt;/cell&gt;&lt;cell&gt;02:00 am (approximate)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Duration&lt;/cell&gt;&lt;cell&gt;25 minutes&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Location&lt;/cell&gt;&lt;cell&gt;Oberlemnitz, East Germany&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;Naila, West Germany&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Coordinates&lt;/cell&gt;&lt;cell&gt;50°28′59″N 11°35′29″E / 50.48306°N 11.59139°E[1]&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;50°19′52.7″N 11°40′13.1″E / 50.331306°N 11.670306°E[1]&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Organised by&lt;/cell&gt;&lt;cell&gt;Peter Strelzyk &amp;amp; family&lt;p&gt;Günter Wetzel &amp;amp; family&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Participants&lt;/cell&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Outcome&lt;/cell&gt;&lt;cell&gt;Successful escape to West Germany&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Non-fatal injuries&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;On 16 September 1979, eight people from two families escaped from East Germany by crossing the border into West Germany at night in a homemade hot air balloon. The unique feat was the result of over a year and a half of preparations involving three different balloons, various modifications, and a first, unsuccessful attempt. The failed attempt alerted the East German authorities to the plot, but the police were unable to identify the escapees before their second, successful flight two months later.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;[edit]&lt;p&gt;East Germany, then part of the Eastern Bloc, was separated from West Germany in the Western Bloc by the inner German border and the Berlin Wall, which were heavily fortified with watchtowers, land mines, armed soldiers, and various other measures to prevent illegal crossings. East German border troops were instructed to prevent defection to West Germany by all means, including lethal force (Schießbefehl; "order to fire").[2]&lt;/p&gt;&lt;p&gt;Peter Strelzyk (1942–2017), an electrician and former East German Air Force mechanic, and Günter Wetzel (born 1955), a bricklayer by trade,[3] were colleagues at a local plastics factory.[4] Friends for four years, they shared a desire to flee the country and began discussing ways to get across the border. On 7 March 1978, they agreed to plan an escape.[5] They considered building a helicopter but quickly realized they would be unable to acquire an engine capable of powering such a craft. They then decided to explore the idea of constructing a hot air balloon,[6] having been inspired by a television program about ballooning.[3] An alternate account is that a relative shared a magazine article about the International Balloon Festival in Albuquerque, New Mexico.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Construction&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel began research into balloons. Their plan was to escape with their wives and a total of four children (aged 2 to 15). They calculated the weight of the eight passengers and the craft itself to be around 750 kilograms (1,650 lb). Subsequent calculations determined a balloon capable of lifting this weight would need to hold 2,000 cubic metres (71,000 cu ft) of air heated to 100 °C (212 °F). The next calculation was the amount of material needed for the balloon, estimated to be 800 square metres (8,600 sq ft).[6]&lt;/p&gt;&lt;p&gt;The pair lived in Pößneck, a small town of about 20,000 where large quantities of cloth could not be obtained without raising attention. They tried neighbouring towns of Rudolstadt, Saalfeld, and Jena without success.[7] They travelled 50 km (31 mi) to Gera, where they purchased 1-metre-wide (3 ft 3 in) rolls of cotton cloth totalling 850 metres (2,790 ft) in length at a department store after telling the astonished clerk that they needed the large quantity of material to use as tent lining for their camping club.[6][7]&lt;/p&gt;&lt;p&gt;Wetzel spent two weeks sewing the cloth into a balloon-shaped bag, 15 metres (49 ft) wide by 20 metres (66 ft) long, on a 40-year-old manually operated sewing machine. Strelzyk spent the time building the gondola and burner assembly. The gondola was made from an iron frame, sheet metal floor, and clothesline run around the perimeter every 150 millimetres (5.9 in) for the sides. The burner was made using two 11-kilogram (24 lb) bottles of liquid propane household gas, hoses, water pipe, a nozzle, and a piece of stove pipe.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First test&lt;/head&gt;[edit]&lt;p&gt;The team was ready to test the craft in April 1978. After days of searching, they found a suitable secluded forest clearing near Ziegenrück, 10 km (6.2 mi) from the border and 30 km (19 mi) from Pößneck. After lighting the burner one night, they failed to inflate the balloon. They thought the problem might stem from the fact that they had laid the balloon on the ground. After weeks of additional searching, they found a 25-metre (82 ft) cliff at a rock quarry where they could suspend the balloon vertically before inflation, but that also proved unsuccessful.[6]&lt;/p&gt;&lt;p&gt;The pair then decided to fill the bag with ambient-temperature air before using the burner to raise the air temperature and provide lift. They constructed a blower with a 14 hp (10 kW) 250 cc (15 cu in) motorcycle engine taken from Wetzel's old MZ, started with a Trabant automobile starter powered by jumper cables from Strelzyk's Moskvitch sedan.[8] This engine, silenced by a Trabant muffler, turned 1-metre-long (3.3 ft) fan blades to inflate the balloon. They also used a home-made flamethrower, similar to the gondola's burner, to pre-heat the air faster. With these modifications in place, they returned to the secluded clearing to try again but still could not inflate the balloon. But using the blower did allow them to discover that the cotton material with which they fashioned the balloon was too porous and leaked excessively.[6]&lt;/p&gt;&lt;p&gt;Their unsuccessful effort had cost them 2,400 DDM (US$360). Strelzyk disposed of the cloth by burning it in his furnace over several weeks.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Second test&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel purchased samples of different fabrics in local stores, including umbrella material and various samples of taffeta and nylon. They used an oven to test the material for heat resistance. In addition, they created a test rig from a vacuum cleaner and a water-filled glass tube to determine which material would allow the vacuum to exert the most suction on the water, and consequently which was the most impervious to air. The umbrella covering performed the best but was also the most expensive. They instead selected a synthetic kind of taffeta.[6]&lt;/p&gt;&lt;p&gt;To purchase a large quantity of fabric without arousing too much suspicion, the pair again drove to a distant city. This time they travelled over 160 kilometres (100 mi) to a department store in Leipzig. Their new cover story was that they belonged to a sailing club and needed the material to make sails. The quantity they needed had to be ordered, and although they feared the purchase might be reported to East Germany's State Security Service (Stasi), they returned the next day and picked up the material without incident. They paid 4,800 DDM (US$720) for 800 metres (2,600 ft) of 1-metre-wide (3 ft 3 in) fabric.[6] On the way home, they also purchased an electric motor to speed up the pedal-operated sewing machine they had been using to sew the material into the desired balloon shape.[7]&lt;/p&gt;&lt;p&gt;Wetzel spent the next week sewing the material into another balloon, accomplishing the task faster the second time with the now-electric sewing machine. Soon afterwards, the two men returned to the forest clearing and inflated the bag in about five minutes using the blower and flame thrower. The bag rose and held air, but the burner on the gondola was not powerful enough to create the heat needed for lift. The pair continued experimenting for months, doubling the number of propane tanks and trying different fuel mixtures. Disappointed with the result, Wetzel decided to abandon the project and instead started to pursue the idea of building a small gasoline engine-powered light aeroplane[6] or a glider.[5]&lt;/p&gt;&lt;p&gt;Strelzyk continued trying to improve the burner. In June 1979, he discovered that with the propane tank inverted, additional pressure caused the liquid propane to evaporate, which produced a bigger flame. He modified the gondola to mount the propane tanks upside down, and returned to the test site where he found the new configuration produced a 12-metre (39 ft) long flame. Strelzyk was ready to attempt an escape.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First escape attempt&lt;/head&gt;[edit]&lt;p&gt;On 3 July 1979, the weather and wind conditions were favourable. The entire Strelzyk family lifted from a forest clearing at 1:30 am and climbed at a rate of 4 metres (13 ft) per second. They reached an altitude of 2,000 metres (6,600 ft) according to an altimeter Strelzyk had made by modifying a barometer. A light wind was blowing them towards the border. The balloon then entered clouds, and atmospheric water vapour condensed on the balloon, adding weight which caused it to descend prematurely. The family landed safely approximately 180 metres (590 ft) short of the border, at the edge of the heavily mined border zone. Unsure of where they were, Strelzyk explored until he found a piece of litter – a bread bag from a bakery in Wernigerode, an East German town. The group spent nine hours carefully extricating themselves from the 500-metre (1,600 ft) wide border zone to avoid detection. They also had to travel unnoticed through a 5 km (3.1 mi) restricted zone before hiking back a total of 14 km (8.7 mi) to their car and the launch paraphernalia they had left behind.[6] They made it home just in time to report their absence from work and school due to sickness.[7]&lt;/p&gt;&lt;p&gt;The abandoned balloon was discovered by the authorities later that morning. Strelzyk destroyed all compromising evidence and sold his car, fearing that it could link him to the escape attempt.[6] On 14 August, the Stasi launched an appeal to find the "perpetrator of a serious offence", listing in detail all the items recovered at the landing site.[9] Strelzyk felt that the Stasi would eventually trace the balloon to him and the Wetzels. He agreed with Wetzel that their best chance was to quickly build another balloon and get out as soon as possible.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Successful escape&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel decided to double the balloon's size to 4,000 cubic metres (140,000 cu ft) in volume, 20 metres (66 ft) in diameter, and 25 metres (82 ft) in height. They needed 1,250 square metres (13,500 sq ft) of taffeta, and purchased the material, in various colours and patterns, all over the country in order to escape suspicion. Wetzel sewed a third balloon, using over 6 kilometres (3.7 mi) of thread, and Strelzyk rebuilt everything else as before. In six weeks, they had prepared the 180-kilogram (400 lb) balloon and a payload of 550 kilograms (1,210 lb), including the gondola, equipment, and cargo (the two families). Confident in their calculations, they found the weather conditions right on 15 September, when a violent thunderstorm created the correct winds. The two families set off for the launch site in Strelzyk's replacement car (a Wartburg) and a moped. Arriving at 1:30 am, they needed just ten minutes to inflate the balloon and an additional three minutes to heat the air.[6]&lt;/p&gt;&lt;p&gt;Lifting off just after 2:00 am, the group failed to cut the tethers holding the gondola to the ground at the same time, tilting the balloon and sending the flame towards the fabric, which caught fire. After putting out the fire with an extinguisher brought along for just such an emergency, they climbed to 2,000 metres (6,600 ft) in nine minutes, drifting towards West Germany at 30 kilometres per hour (19 mph). The balloon flew for 28 minutes, with the temperature plummeting to −8 °C (18 °F) in the unsheltered gondola, which consisted solely of clothesline railing.&lt;/p&gt;&lt;p&gt;A design miscalculation resulted in the burner stovepipe being too long, causing the flame to be too high in the balloon, creating excessive pressure which caused the balloon to split. The air rushing out of the split extinguished the burner flame. Wetzel was able to re-light the flame with a match, and had to do so several more times before the group landed. At one point, they increased the flame to the maximum possible extent and rose to 2,500 metres (8,200 ft). They later learned they had been high enough to be detected, but not identified, on radar by West German air traffic controllers.[6] They had also been detected on the East German side by a night watchman at the district culture house in Bad Lobenstein. The report of an unidentified flying object heading toward the border caused guards to activate search lights, but the balloon was too high and out of reach of the lights.[10]&lt;/p&gt;&lt;p&gt;The tear in the balloon meant the group had to use the burner much more often, greatly limiting the distance it could travel. Wetzel later said he thought they could have travelled another 50 kilometres (31 mi) had the balloon remained intact. They made out the border crossing at Rudolphstein on the A9 and saw the search lights. When the propane ran out, they descended quickly, landing near the town of Naila, in the West German state of Bavaria and only 10 km (6 mi) from the border. The only injury was suffered by Wetzel, who broke his leg upon landing.[6] Various clues indicated to the families that the balloon had made it across the border. These included spotting red and yellow coloured lights, not common in East Germany,[3] and small farms, in contrast to the large state-run operations in the east. Another clue was modern farm equipment, unlike the older equipment used in East Germany.[11] Two Bavarian State Police officers saw the balloon's flickering light and headed to where they thought it would land. There they found Strelzyk and Wetzel, who first asked if they had made it to the West, although they noticed the police car was an Audi – another sign they were in West Germany. Upon learning they had, the escapees happily called for their families to join them.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Aftermath&lt;/head&gt;[edit]&lt;p&gt;East Germany immediately increased border security, closed all small airports close to the border, and ordered the planes kept farther inland.[6] Propane gas tanks became registered products, and large quantities of fabric suitable for balloon construction could no longer be purchased. Mail from East Germany to the two escaped families was prohibited.[12]&lt;/p&gt;&lt;p&gt;Erich Strelzyk learned of his brother's escape on the ZDF news and was arrested in his Potsdam apartment three hours after the landing. The arrest of family members was standard procedure to deter others from attempting escape. He was charged with "aiding and abetting escape", as were Strelzyk's sister Maria and her husband, who were sentenced to 2½ years. The three were eventually released with the help of Amnesty International.[12]&lt;/p&gt;&lt;p&gt;The families decided to initially settle in Naila where they had landed. Wetzel worked as an automobile mechanic and Strelzyk opened a TV repair shop in Bad Kissingen. Due to pressure from Stasi spies, the Strelzyks moved to Switzerland in 1985.[10] After German reunification in 1990, they returned to their old home in their hometown of Pößneck.[13] The Wetzels remained in Bavaria.[7]&lt;/p&gt;&lt;p&gt;West German weekly magazine Stern paid Strelzyk and Wetzel for exclusive rights to the story.[3]&lt;/p&gt;&lt;p&gt;The escape has been portrayed in two films: Night Crossing (1982) and Balloon (2018). The former, also called With the Wind to the West – the English translation of the German title – was an English-language film produced by Disney. The latter was a German-language production which "both families welcomed [Director] Herbig’s desire to, as he put it, 'make a German film for an international audience.'" The Strelzyks were reportedly "moved to tears" at the screening of Balloon at Rockefeller Center in New York City.[12] Herbig claimed in 2018 that both the Strelzyk and Wetzel families had been dissatisfied with the Disney film.[14]&lt;/p&gt;&lt;p&gt;Peter Strelzyk died in 2017 at age 74 after a long illness.[13]&lt;/p&gt;&lt;p&gt;In 2017, the balloon was put on permanent display at the Haus der Bayerischen Geschichte: Museum in Regensburg.[10]&lt;/p&gt;&lt;head rend="h2"&gt;Escapees&lt;/head&gt;[edit]&lt;p&gt;The family members included:[3]&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Peter Strelzyk, aged 37&lt;/item&gt;&lt;item&gt;Doris Strelzyk&lt;/item&gt;&lt;item&gt;Frank Strelzyk, aged 15&lt;/item&gt;&lt;item&gt;Andreas Strelzyk, aged 11&lt;/item&gt;&lt;item&gt;Günter Wetzel, aged 24&lt;/item&gt;&lt;item&gt;Petra Wetzel&lt;/item&gt;&lt;item&gt;Peter Wetzel, aged 5&lt;/item&gt;&lt;item&gt;Andreas Wetzel, aged 2&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Media&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;The Disney film Night Crossing (1982) is an adaptation of the story[13]&lt;/item&gt;&lt;item&gt;Michael Herbig's film Balloon (2018) is a German-language adaptation of the story[15]&lt;/item&gt;&lt;item&gt;BBC program Outlook, "Fleeing Communism in a Hot Air Balloon"[16]&lt;/item&gt;&lt;item&gt;PBS Nova program, "History's Great Escapes" (2004)[17]&lt;/item&gt;&lt;item&gt;Doris Strelzyk, Peter Strelzyk, Gudrun Giese: Destiny Balloon Escape. Quadriga, Berlin 1999, ISBN 3-88679-330-3&lt;/item&gt;&lt;item&gt;Jürgen Petschull, With the Wind to the West. The Adventurous Flight from Germany to Germany. Goldmann, Munich 1980, ISBN 3-442-11501-9&lt;/item&gt;&lt;item&gt;Kristen Fulton (Author), Torben Kuhlmann (Illustrator), Flight for Freedom: The Wetzel Family’s Daring Escape from East Germany. March 3, 2020, ISBN 978-1452149608&lt;/item&gt;&lt;item&gt;The Netflix series White Rabbit Project, episode 2, "Jailbreak"&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b Wetzel, Günter. "Die Nacht der Flucht". Ballonflucht.de. Archived from the original on 19 September 2020. Retrieved 16 September 2019.&lt;/item&gt;&lt;item&gt;^ Hertle, Hans-Hermann; Nooke, Maria (2009). Die Todesopfer an der Berliner Mauer 1961–1989. Ein biographisches Handbuch. Ch. Links Verlag. ISBN 978-3-86153-517-1.&lt;/item&gt;&lt;item&gt;^ a b c d e Getler, Michael (28 September 1979). "Harrowing Flight From East Germany". The Washington Post. Archived from the original on 26 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Snow, Philipp (16 September 2009). "Balloon escape from the GDR With hot air to freedom". Spiegel Online (in German). Archived from the original on 7 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c Simpson, Paul (2013). The Mammoth Book of Prison Breaks. Little, Brown Book Group. p. 216. ISBN 978-1-4721-0024-5. Archived from the original on 16 September 2023. Retrieved 1 April 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e f g h i j k l m n o p q r s Dornberg, John (February 1980). "The Freedom Balloon". Popular Mechanics. pp. 100–103. Retrieved 22 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e Overbye, Stine (13 April 2017). "Fathers wanted to escape GDR in a hot air balloon". Historia (in Dutch). Archived from the original on 1 April 2018. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ Petschull, Jürgen (27 September 1979). "Das Himmelfahrtskommando" [High-flying mission] (PDF). Stern (in German). No. 40. p. 34. Archived from the original (PDF) on 12 July 2024 – via Museum Naila.&lt;/item&gt;&lt;item&gt;^ Souerbry, Rachel. "How Two Families Escaped East Germany In A Homemade Hot Air Balloon". ranker.com. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Wetzel und Peter Strelzyk Ballonhülle der Strelzyks". museum.bayern (in German). Archived from the original on 8 April 2019. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "East-West: The Great Balloon Escape". Time. 1 October 1979. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "The Balloon Escape of Peter Strelzyk". goethe-rutheneum.de (in German). Archived from the original on 11 February 2013. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Man who fled East Germany in a homemade balloon and whose story was made into a film dies". The Express. 15 March 2017. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Connolly, Kate (17 October 2018). "Film of daring balloon escape from East revives German identity debate". Archived from the original on 8 February 2021. Retrieved 10 May 2019.&lt;/item&gt;&lt;item&gt;^ Ballon at IMDb&lt;/item&gt;&lt;item&gt;^ "Fleeing Communism in a Hot Air Balloon". bbc. Archived from the original on 12 December 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "Great Escapes". pbs.org. Archived from the original on 16 April 2019. Retrieved 16 April 2019.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;External links&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;Escape by balloon by Günter Wetzel (participant website)&lt;/item&gt;&lt;item&gt;Video of balloon on museum display&lt;/item&gt;&lt;item&gt;BBC Outlook program&lt;/item&gt;&lt;item&gt;Photograph of Güenter Wetzel, Peter and Doris Strelzyk Archived 1 April 2018 at the Wayback Machine&lt;/item&gt;&lt;item&gt;Photograph of the actual balloon, inflated in 1985 at a festival in Hof, Bavaria&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46648916</guid><pubDate>Fri, 16 Jan 2026 17:16:33 +0000</pubDate></item><item><title>STFU</title><link>https://github.com/Pankajtanwarbanna/stfu</link><description>&lt;doc fingerprint="a01e89ee7325e0d9"&gt;
  &lt;main&gt;
    &lt;p&gt;i was at bombay airport. some dude was watching reels on full volume and laughing loudly. asking nicely doesn't work anymore. me being me, didn't have the courage to speak up.&lt;/p&gt;
    &lt;p&gt;so i built a tiny app that plays back the same audio it hears, delayed by ~2 seconds. asked claude, it spat out a working version in one prompt. surprisingly WORKS.&lt;/p&gt;
    &lt;p&gt;discussion - https://x.com/the2ndfloorguy/status/2011734249871954188&lt;/p&gt;
    &lt;p&gt;something something auditory feedback loop something something cognitive dissonance. idk i'm not a neuroscientist. all i know is it makes people shut up and that's good enough for me.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;straight up honest - originally called this "make-it-stop" but then saw @TimDarcet also built similar and named it STFU. wayyyyy better name. so stole it. sorry not sorry.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;made with spite and web audio api. do whatever you want with it.&lt;/p&gt;
    &lt;p&gt;yo, meanwhile if you are new here, you might find my, other side projects kinda funny.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46649142</guid><pubDate>Fri, 16 Jan 2026 17:32:40 +0000</pubDate></item><item><title>Emoji Use in the Electronic Health Record is Increasing</title><link>https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2843883</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46649489</guid><pubDate>Fri, 16 Jan 2026 17:56:03 +0000</pubDate></item><item><title>Reading across books with Claude Code</title><link>https://pieterma.es/syntopic-reading-claude/</link><description>&lt;doc fingerprint="3f200f9427931e3e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Reading across books with Claude Code&lt;/head&gt;
    &lt;p&gt;Jan 4, 2026&lt;/p&gt;
    &lt;p&gt;LLMs are overused to summarise and underused to help us read deeper.&lt;/p&gt;
    &lt;p&gt;To explore how they can enrich rather than reduce, I set Claude Code up with tools to mine a library of 100 non-fiction books. It found sequences of excerpts connected by an interesting idea, or trails.&lt;/p&gt;
    &lt;p&gt;Here’s a part of one such trail, linking deception in the startup world to the social psychology of mass movements (I’m especially pleased by the jump from Jobs to Theranos):&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The books were selected from Hacker News’ favourites, which I previously scraped and visualized.&lt;/p&gt;
    &lt;p&gt;Claude browses the books a chunk at a time. A chunk is a segment of roughly 500 words that aligns with paragraphs when possible. This length is a good balance between saving tokens and providing enough context for ideas to breathe.&lt;/p&gt;
    &lt;p&gt;Chunks are indexed by topic, and topics are themselves indexed for search. This makes it easy to look up all passages in the corpus that relate to, say, deception.&lt;/p&gt;
    &lt;p&gt;This works well when you know what to look for, but search alone can’t tell you which topics are present to begin with. There are over 100,000 extracted topics, far too many to be browsed directly. To support exploration, they are grouped into a hierarchical tree structure.&lt;/p&gt;
    &lt;p&gt;This yields around 1,000 top-level topics. They emerge from combining lower-level topics, and not all of them are equally useful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Incidents that frustrated Ev Williams&lt;/item&gt;
      &lt;item&gt;Names beginning with “Da”&lt;/item&gt;
      &lt;item&gt;Events between 1971 &amp;amp; 1974&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, this Borgesian taxonomy is good enough for Claude to piece together what the books are about.&lt;/p&gt;
    &lt;p&gt;Claude uses the topic tree and the search via a few CLI tools.&lt;lb/&gt; They allow it to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Find all chunks associated with a topic similar to a query.&lt;/item&gt;
      &lt;item&gt;Find topics which occur in a window of chunks around a given topic.&lt;/item&gt;
      &lt;item&gt;Find topics that co-occur in multiple books.&lt;/item&gt;
      &lt;item&gt;Browse topics and chunks that are siblings in the topic tree.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To generate the trails, the agent works in stages.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;First, it scans the library and the existing trails, and proposes novel trail ideas. It mainly browses the topic tree to find unexplored areas and rarely reads full chunks in depth.&lt;/item&gt;
      &lt;item&gt;Then, it takes a specific idea and turns it into a trail. It receives seed topics from the previous stage and browses many chunks. It extracts excerpts, specific sequences of sentences, and decides on how best to order them to support an insight.&lt;/item&gt;
      &lt;item&gt;Finally, it adds highlights and edges between consecutive excerpts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What I learned&lt;/head&gt;
    &lt;head rend="h3"&gt;Claude Code is great for non-coding tasks&lt;/head&gt;
    &lt;p&gt;Even though I’ve been using Claude Code to develop for months, my first instinct for this project was to consider it as a traditional pipeline of several discrete stages. My initial attempt at this system consisted of multiple LLM modules with carefully hand-assembled contexts.&lt;/p&gt;
    &lt;p&gt;On a whim, I ran Claude with access to the debugging tools I’d been using and a minimal prompt: “find something interesting.” It immediately did a better job at pulling in what it needed than the pipeline I was trying to tune by hand, while requiring much less orchestration. It was a clear improvement to push as much of the work into the agent’s loop as possible.&lt;/p&gt;
    &lt;p&gt;I ended up using Claude as my main interface to the project.&lt;lb/&gt; Initially I did so because it inferred the sequence of CLI calls I wanted to run faster than I could recall them. Then, I used it to automate tasks which weren’t rigid enough to be scripted traditionally.&lt;/p&gt;
    &lt;p&gt;The latter opened up options that I wouldn’t have considered before. For example, I changed my mind on how short I wanted excerpts to be. I communicated my new preference to Claude, which then looked through all the existing trails and edited them as necessary, balancing the way the overall meaning of the trail changed. Previously, I would’ve likely considered all previous trails to be outdated and generated new ones, because the required edits would’ve been too nuanced to specify.&lt;/p&gt;
    &lt;p&gt;In general, agents have widened my ambitions.&lt;lb/&gt; By taking care of the boilerplate, I no longer shy away from the tedious parts. Revision is cheap, so I don’t need to plow ahead with suboptimal choices just because it’d be too costly to undo them. This, in turn, keeps up the momentum and lets me focus on the joyful, creative aspects of the work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ask the agent what it needs&lt;/head&gt;
    &lt;p&gt;My focus went from optimising prompts to implementing better tools for Claude to use, moving up a rung on the abstraction ladder.&lt;/p&gt;
    &lt;p&gt;My mental model of the AI component changed: from a function mapping input to output, to a coworker I was assisting. I spent my time thinking about the affordances that would make the workflow better, as if I were designing them for myself. That they were to be used by an agent was a mere detail.&lt;/p&gt;
    &lt;p&gt;This worked because the agent is now intelligent enough that the way it uses these tools overlaps with my own mental model. It is generally easy to empathise with it and predict what it will do.&lt;/p&gt;
    &lt;p&gt;Initially I watched Claude’s logs closely and tried to guess where it was lacking a certain ability. Then I realised I could simply ask it to provide feedback at the end and list the functionality it wished it had. Claude was excellent at proposing new commands and capabilities that would make the work more efficient.&lt;/p&gt;
    &lt;p&gt;Claude suggested improvements, which Claude implemented, so Claude could do the work better. At least I’m still needed to pay for the tokens — for now.&lt;/p&gt;
    &lt;head rend="h3"&gt;Novelty is a useful guide&lt;/head&gt;
    &lt;p&gt;It’s hard to quantify interestingness as an objective to optimise for.&lt;lb/&gt; Why Greatness Cannot Be Planned makes the case that chasing novelty is often a more fruitful approach. While its conclusions are debated, I’ve found this idea to be a good fit for this project.&lt;/p&gt;
    &lt;p&gt;As a sign of the times, this novelty search was implemented in two ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;By biasing the search algorithm towards under-explored topics and books.&lt;/item&gt;
      &lt;item&gt;By asking Claude nicely.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A topic’s novelty score was calculated as the mean distance from its embedding’s k nearest neighbors. A book’s novelty score is the average novelty of the unique topics that it contains. This value was used to rank search results, so that those which were both relevant and novel were more likely to be seen.&lt;/p&gt;
    &lt;p&gt;On a prompting level, Claude starts the ideation phase by looking at all the existing trails and is asked to avoid any conceptual overlap. This works fairly well, though it is often distracted by any topics related to secrecy, systems theory, or tacit knowledge.&lt;/p&gt;
    &lt;p&gt;It’s as if the very act of finding connections in a corpus summons the spirit of Umberto Eco and amps up the conspiratorial thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it’s implemented&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EPUBs are parsed using &lt;code&gt;selectolax&lt;/code&gt;, which I picked over BeautifulSoup for its speed and simpler API.&lt;/item&gt;
      &lt;item&gt;Everything from the plain text to the topic tree is stored in SQLite. Embeddings are stored using &lt;code&gt;sqlite-vec&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The text is split into sentences using &lt;code&gt;wtpsplit&lt;/code&gt;(the&lt;code&gt;sat-6l-sm&lt;/code&gt;model). Those sentences are then grouped into chunks, trying to get up to 500 words without breaking up paragraphs.&lt;/item&gt;
      &lt;item&gt;I used &lt;code&gt;DSPy&lt;/code&gt;to call LLMs. It worked well for the structured data extraction and it was easy to switch out different models to experiment. I tried its prompt optimizers before I went full agentic, and their results were very promising.&lt;/item&gt;
      &lt;item&gt;I settled on Gemini 2.5 Flash Lite for topic extraction. The model gets passed a chunk and is asked to return 3-5 topics. It is also asked whether the chunk is useful, in order to filter out index entries, acknowledgements, orphan headers, etc. I was surprised at how stable these extracted topics were: similar chunks often shared some of the exact same topic labels. Processing 100 books used about 60M input tokens and ~£10 in total.&lt;/item&gt;
      &lt;item&gt;After a couple books got indexed, I shared the results with Claude Opus along with the original prompt and asked it to improve it. This is a half-baked single iteration of the type of prompt optimisation DSPy implements, and it worked rather well.&lt;/item&gt;
      &lt;item&gt;Topic pairs with a distance below a threshold get merged together. This takes care of near-duplicates such as “Startup founder”, “Startup founders”, and “Founder of startups”.&lt;/item&gt;
      &lt;item&gt;The CLI output uses a semi-XML format. In order to stimulate navigating, most output is nested with related content. For example, when searching for a topic, chunks are shown with the other topics they contain. This allows us to get a sense of what the chunk is about, as well as which other topics might be interesting. There’s probably more token-efficient formats, but I never hit the limit of the context window.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;&amp;lt;topics query="deception" count="1"&amp;gt;
  &amp;lt;topic id="47193" books="7" score="0.0173" label="Deception"&amp;gt;
    &amp;lt;chunk id="186" book="1"&amp;gt;
      &amp;lt;topic id="47192" label="Business deal"/&amp;gt;
      &amp;lt;topic id="47108" label="Internal conflict"/&amp;gt;
      &amp;lt;topic id="46623" label="Startup founders"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="1484" book="4"&amp;gt;
      &amp;lt;topic id="51835" label="Gawker Media"/&amp;gt;
      &amp;lt;topic id="53006" label="Legal Action"/&amp;gt;
      &amp;lt;topic id="52934" label="Maskirovka"/&amp;gt;
      &amp;lt;topic id="52181" label="Strategy"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="2913" book="9"&amp;gt;
      &amp;lt;topic id="59348" label="Blood testing system"/&amp;gt;
      &amp;lt;topic id="59329" label="Elizabeth Holmes"/&amp;gt;
      &amp;lt;topic id="59352" label="Investor demo"/&amp;gt;
      &amp;lt;topic id="59349" label="Theranos"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
  &amp;lt;/topic&amp;gt;
&amp;lt;/topics&amp;gt;&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Topics are embedded using&lt;/p&gt;&lt;code&gt;google/embeddinggemma-300m&lt;/code&gt;and reranked using&lt;code&gt;BAAI/bge-reranker-v2-m3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Many CLI tools require loading the embedding model and other expensive state. The first call transparently starts a separate server process which loads all these resources once and holds onto them for a while. Subsequent CLI calls use this server through Python’s&lt;/p&gt;&lt;code&gt;multiprocessing.connection&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The topic collection is turned into a graph (backed by&lt;/p&gt;&lt;code&gt;igraph&lt;/code&gt;) by adding edges based on the similarity of their embeddings and the point-wise mutual information of their co-occurrences.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The graph is turned into a tree by applying Leiden partitioning recursively until a minimum size is reached. I tried the Surprise quality function because it had no parameters to tweak, and found it to be good enough. Each group is labelled by Gemini based on all the topics that it contains.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Excerpts are cleaned by Gemini to remove EPUB artifacts, parsing errors, headers, footnotes, etc. Doing this only for excerpts that are actually shown, instead of during pre-processing, saved a lot of tokens.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46650347</guid><pubDate>Fri, 16 Jan 2026 18:49:29 +0000</pubDate></item><item><title>Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation</title><link>https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables</link><description>&lt;doc fingerprint="ac035d9b403222ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Closing the Door on Net-NTLMv1: Releasing Rainbow Tables to Accelerate Protocol Deprecation&lt;/head&gt;
    &lt;head rend="h5"&gt;Mandiant&lt;/head&gt;
    &lt;p&gt;Written by: Nic Losby&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Mandiant is publicly releasing a comprehensive dataset of Net-NTLMv1 rainbow tables to underscore the urgency of migrating away from this outdated protocol. Despite Net-NTLMv1 being deprecated and known to be insecure for over two decades—with cryptanalysis dating back to 1999—Mandiant consultants continue to identify its use in active environments. This legacy protocol leaves organizations vulnerable to trivial credential theft, yet it remains prevalent due to inertia and a lack of demonstrated immediate risk.&lt;/p&gt;
    &lt;p&gt;By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1. While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys. The release of this dataset allows defenders and researchers to recover keys in under 12 hours using consumer hardware costing less than $600 USD. This initiative highlights the amplified impact of combining Mandiant's frontline expertise with Google Cloud's resources to eliminate entire classes of attacks.&lt;/p&gt;
    &lt;p&gt;This post details the generation of the tables, provides access to the dataset for community use, and outlines critical remediation steps to disable Net-NTLMv1 and prevent authentication coercion attacks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background&lt;/head&gt;
    &lt;p&gt;Net-NTLMv1 has been widely known to be insecure since at least 2012, following presentations at DEFCON 20, with cryptanalysis of the underlying protocol dating back to at least 1999. On Aug. 30, 2016, Hashcat added support for cracking Data Encryption Standard (DES) keys using known plaintext, further democratizing the ability to attack this protocol. Rainbow tables are almost as old, with the initial paper on rainbow tables published in 2003 by Philippe Oechslin, citing an earlier iteration of a time-memory trade-off from 1980 by Martin Hellman.&lt;/p&gt;
    &lt;p&gt;Essentially, if an attacker can obtain a Net-NTLMv1 hash without Extended Session Security (ESS) for the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt;, a cryptographic attack, referred to as a known plaintext attack (KPA), can be applied. This guarantees recovery of the key material used. Since the key material is the password hash of the authenticating Active Directory (AD) object—user or computer—the attack results can quickly be used to compromise the object, often leading to privilege escalation.&lt;/p&gt;
    &lt;p&gt;A common chain attackers use is authentication coercion from a highly privileged object, such as a domain controller (DC). Recovering the password hash of the DC machine account allows for DCSync privileges to compromise any other account in AD.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dataset Release&lt;/head&gt;
    &lt;p&gt;The unsorted dataset can be downloaded using &lt;code&gt;gsutil -m cp -r gs://net-ntlmv1-tables/tables .&lt;/code&gt; or through the Google Cloud Research Dataset portal. &lt;/p&gt;
    &lt;p&gt;The SHA512 hashes of the tables can be checked by first downloading the checksums &lt;code&gt;gsutil -m cp gs://net-ntlmv1-tables/tables.sha512 .&lt;/code&gt; then checked by &lt;code&gt;sha512sum -c tables.sha512&lt;/code&gt;. The password cracking community has already created derivative work and is also hosting the ready to use tables.&lt;/p&gt;
    &lt;head rend="h3"&gt;Use of the Tables&lt;/head&gt;
    &lt;p&gt;Once a Net-NTLMv1 hash has been obtained, the tables can be used with historical or modern reinventions of rainbow table searching software such as rainbowcrack (rcrack), or RainbowCrack-NG on central processing units (CPUs) or a fork of rainbowcrackalack on graphics processing units (GPUs). The Net-NTLMv1 hash needs to be preprocessed to the DES components using ntlmv1-multi as shown in the next section.&lt;/p&gt;
    &lt;head rend="h3"&gt;Obtaining a Net-NTLMv1 Hash&lt;/head&gt;
    &lt;p&gt;Most attackers will use Responder with the &lt;code&gt;--lm&lt;/code&gt; and &lt;code&gt;--disable-ess&lt;/code&gt; flags and set the authentication to a static value of &lt;code&gt;1122334455667788&lt;/code&gt; to only allow for connections with Net-NTLMv1 as a possibility. Attackers can then wait for incoming connections or coerce authentication using a tool such as PetitPotam or DFSCoerce to generate incoming connections from DCs or lower privilege hosts that are useful for objective completion. Responses can be cracked to retrieve password hashes of either users or computer machine accounts. A sample workflow for an attacker is shown below in Figure 1, Figure 2, and Figure 3.&lt;/p&gt;
    &lt;p&gt;Figure 1: DFSCoerce against a DC&lt;/p&gt;
    &lt;p&gt;Figure 2: Net-NTLMv1 hash obtained for DC machine account&lt;/p&gt;
    &lt;p&gt;Figure 3: Parse Net-NTLMv1 hash to DES parts&lt;/p&gt;
    &lt;p&gt;Figure 4 illustrates the processing of the Net-NTLMv1 hash to the DES ciphertexts.&lt;/p&gt;
    &lt;p&gt;Figure 4: Net-NTLMv1 hash to DES ciphertexts&lt;/p&gt;
    &lt;p&gt;An attacker then takes the split-out ciphertexts to crack the keys used based on the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt; with the steps of loading the tables shown in Figure 5 and cracking results in Figure 6 and Figure 7.&lt;/p&gt;
    &lt;p&gt;Figure 5: Loading DES components for cracking&lt;/p&gt;
    &lt;p&gt;Figure 6: First hash cracked&lt;/p&gt;
    &lt;p&gt;Figure 7: Second hash cracked and run statistics&lt;/p&gt;
    &lt;p&gt;An attacker can then calculate the last remaining key with ntlmv1-multi once again, or look it up with twobytes, to recreate the full NT hash for the DC account with the last key part shown in Figure 8.&lt;/p&gt;
    &lt;p&gt;Figure 8: Calculate remaining key&lt;/p&gt;
    &lt;p&gt;The result can be checked with hashcat's NT hash shucking mode, &lt;code&gt;-m 27000&lt;/code&gt;, as shown in Figure 9.&lt;/p&gt;
    &lt;p&gt;Figure 9: Keys checked with hash shucking&lt;/p&gt;
    &lt;p&gt;An attacker can then use the hash to perform a DCSync attack targeting a DC and authenticating as the now compromised machine account. The attack flow uses secretsdump.py from the Impacket toolsuite and is shown in Figure 10.&lt;/p&gt;
    &lt;p&gt;Figure 10: DCSync attack performed&lt;/p&gt;
    &lt;head rend="h3"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Organizations should immediately disable the use of Net-NTLMv1.&lt;/p&gt;
    &lt;head rend="h4"&gt;Local Computer Policy&lt;/head&gt;
    &lt;p&gt;"Local Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; “Network security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only".&lt;/p&gt;
    &lt;head rend="h4"&gt;Group Policy&lt;/head&gt;
    &lt;p&gt;"Computer Configuration" &amp;gt; "Policies" &amp;gt; "Windows Settings" &amp;gt; "Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; "Network Security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only"&lt;/p&gt;
    &lt;p&gt;As these are local to the computer configurations, attackers can and have set the configuration to a vulnerable state to then fix the configuration after their attacks have completed with local administrative access. Monitoring and alerting of when and where Net-NTLMv1 is used is needed in addition to catching these edge cases.&lt;/p&gt;
    &lt;p&gt;Filter Event Logs for Event ID 4624: "An Account was successfully logged on." &amp;gt; "Detailed Authentication Information" &amp;gt; "Authentication Package" &amp;gt; "Package Name (NTLM only)", if "LM" or "NTLMv1" is the value of this attribute, LAN Manager or Net-NTLMv1 was used.&lt;/p&gt;
    &lt;head rend="h3"&gt;Related Reading&lt;/head&gt;
    &lt;p&gt;This project was inspired by and referenced the following research published to blogs, social media, and code repositories.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Thank you to everyone who helped make this blog post possible, including but not limited to Chris King and Max Gruenberg.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46652617</guid><pubDate>Fri, 16 Jan 2026 21:42:24 +0000</pubDate></item><item><title>Install.md: A standard for LLM-executable installation</title><link>https://www.mintlify.com/blog/install-md-standard-for-llm-executable-installation</link><description>&lt;doc fingerprint="d540f21bfdefd486"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;install.md: A Standard for LLM-Executable Installation&lt;/head&gt;&lt;p&gt;January 15, 2026&lt;/p&gt;&lt;p&gt;Michael Ryaboy&lt;/p&gt;&lt;p&gt;Content Strategist&lt;/p&gt;&lt;head rend="h4"&gt;Share this article&lt;/head&gt;&lt;p&gt;Installing software is the kind of specific and repetitive task that agents are good at. Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras, Firecrawl, and Langchain.&lt;/p&gt;&lt;p&gt;Proposal for a standard &lt;code&gt;/install.md&lt;/code&gt; file that provides LLM-executable installation instructions.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;p&gt;Agents are growing in capability faster than software developers have been able to keep up. Product documentation today is focused on humans instead of AI which creates friction when trying to automate annoying yak-shaving style tasks like installation.&lt;/p&gt;&lt;p&gt;The difference is very subtle. Agents need to have a task iterated to them like "I want you to install Mintlify CLI for me. Execute all the steps below autonomously." whereas humans can work from more general prose or even a bash script.&lt;/p&gt;&lt;p&gt;Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras, Firecrawl, and Langchain.&lt;/p&gt;&lt;head rend="h2"&gt;Proposal&lt;/head&gt;&lt;p&gt;Add an &lt;code&gt;install.md&lt;/code&gt; markdown file to your project with LLM-executable installation instructions.&lt;/p&gt;&lt;p&gt;Users paste that file into an LLM or pipe it directly from a URL. The LLM reads the instructions, detects the environment, adapts to the setup, and executes—optionally with approval at every step. Because the file is human-readable, users see exactly what will happen before it runs.&lt;/p&gt;&lt;p&gt;Instead of piping an executable file into bash with absolutely zero safeguards on what gets executed or confidence that it will figure out how to work with your arch linux setup, you can instead send an install.md to claude and trust Opus to deal with the minutia for you.&lt;/p&gt;&lt;code&gt;curl -fsSL https://www.anaconda.com/docs/install.md | claude
&lt;/code&gt;&lt;p&gt;This works for any language or framework, whether your software is distributed as a binary, package, or script.&lt;/p&gt;&lt;p&gt;As the developer, you define how installation should work. You encode knowledge about edge cases that would clutter your docs but matter when things break.&lt;/p&gt;&lt;p&gt;Mintlify now auto detects all of that information, synthesizes it into a version designed for agents, and hosts it for you at &lt;code&gt;https://&amp;lt;your-docs-url&amp;gt;/install.md&lt;/code&gt;. If your documentation covers multiple products—say, an SDK and a CLI—Mintlify defaults to generating install.md for the CLI. You can override the auto-generated file by adding your own &lt;code&gt;install.md&lt;/code&gt; to the root of your documentation directory. If you'd prefer to disable the feature entirely, reach out to support@mintlify.com.&lt;/p&gt;&lt;p&gt;Alternatively, if you are not using Mintlify, you can set up and host this file manually.&lt;/p&gt;&lt;head rend="h2"&gt;Format&lt;/head&gt;&lt;p&gt;install.md uses a structured format with specific keywords that guide the LLM through autonomous execution.&lt;/p&gt;&lt;p&gt;A typical install.md includes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Header: Product name as a lowercase, hyphenated H1 heading (e.g., &lt;code&gt;# claude-code&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;Description: Blockquote describing the product (e.g., &lt;code&gt;&amp;gt; Documentation and setup instructions for product-name&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;Action prompt: Direct instruction to the LLM (e.g., "I want you to install [Product] for me. Execute all the steps below autonomously.")&lt;/item&gt;&lt;item&gt;OBJECTIVE: What the installation should achieve&lt;/item&gt;&lt;item&gt;DONE WHEN: Specific verification criteria (e.g., a command that returns expected output)&lt;/item&gt;&lt;item&gt;TODO: Markdown checkbox list of steps to complete&lt;/item&gt;&lt;item&gt;Step sections: Detailed installation instructions with code blocks&lt;/item&gt;&lt;item&gt;EXECUTE NOW: Call-to-action that references the TODO list and objective&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This format is flexible—it's up to the developer to define the steps necessary for a successful installation.&lt;/p&gt;&lt;p&gt;Here is an example:&lt;/p&gt;&lt;code&gt;# mintlify

&amp;gt; Documentation and setup instructions for mintlify

I want you to install Mintlify CLI for me. Execute all the steps below autonomously.

OBJECTIVE: Install the Mintlify CLI and set up a local documentation preview environment.

DONE WHEN: Local documentation server is running and accessible at http://localhost:3000.

## TODO

- [ ] Verify Node.js v20.17.0+ is installed
- [ ] Install the Mintlify CLI globally
- [ ] Create a new documentation project
- [ ] Start the local development server
- [ ] Verify the preview is accessible at localhost:3000

## Prerequisites

You need to have Node.js v20.17.0 or higher installed. Verify your Node.js version:

```bash
node --version
```

You must also have Git installed:

```bash
git --version
```

## Install the CLI

You need to install the Mintlify CLI globally using npm or pnpm.

Using npm:

```bash
npm i -g mint
```

Using pnpm:

```bash
pnpm add -g mint
```

Verify the installation:

```bash
mint --version
```

## Create a new documentation project

You must create a new documentation project using the CLI. This clones the starter kit into your specified directory:

```bash
mint new docs
```

The CLI will prompt you for a project name and theme. You can also specify these directly:

```bash
mint new docs --name my-project --theme linden
```

Navigate into your new project directory:

```bash
cd docs
```

## Start the local preview server

You need to start the development server to preview your documentation locally:

```bash
mint dev
```

Your documentation preview is now available at `http://localhost:3000`.

If port 3000 is already in use, you can specify a custom port:

```bash
mint dev --port 3333
```

Alternatively, run without global installation using npx:

```bash
npx mint dev
```

## Verify the preview

Open your browser and navigate to http://localhost:3000 to confirm the documentation site is running.

## Update the CLI

If you need to update to the latest version:

```bash
mint update
```

Or reinstall with the latest version:

```bash
npm i -g mint@latest
```

## Additional CLI commands

Check for broken links in your documentation:

```bash
mint broken-links
```

Check for accessibility issues:

```bash
mint a11y
```

Validate an OpenAPI specification:

```bash
mint openapi-check &amp;lt;openapi-file-or-url&amp;gt;
```

EXECUTE NOW: Complete the above TODO list to achieve: Local documentation server is running and accessible at http://localhost:3000.
&lt;/code&gt;&lt;p&gt;The instructions describe outcomes, not exact commands. The LLM adapts to the environment—npm or pnpm, macOS or Linux, fresh project or existing codebase.&lt;/p&gt;&lt;head rend="h2"&gt;Relationship to llms.txt&lt;/head&gt;&lt;p&gt;install.md works naturally with your llms.txt. llms.txt helps LLMs understand your software; install.md tells them how to install it. Your install.md can link to your llms.txt so the LLM can reference it for troubleshooting, configuration details, or any additional context needed during installation.&lt;/p&gt;&lt;head rend="h2"&gt;Advantages&lt;/head&gt;&lt;p&gt;For developers shipping software:&lt;/p&gt;&lt;p&gt;Define installation once and it adapts to every environment. You can encode edge cases and troubleshooting knowledge without cluttering your main documentation. There's no wizard to build or maintain, and you control exactly what context the LLM receives. Installation instructions for agents can differ from your public docs without worrying about company voice or developer experience polish. You're writing directly to your actual users, which are agents.&lt;/p&gt;&lt;p&gt;For users installing software:&lt;/p&gt;&lt;p&gt;A single command installs your software, or you can paste the file into any LLM. The instructions are human-readable so you can review every step before it executes, and modify it to improve performance on your system if necessary. The LLM adapts to your specific environment automatically. Because the file is fetched at runtime, you never deal with stale training data.&lt;/p&gt;&lt;p&gt;For agents:&lt;/p&gt;&lt;p&gt;Installation instructions live in a predictable location that's easy to find. The structured format provides clear success criteria for determining when installation is complete. The file is markdown, not HTML, which means clean input for the model.&lt;/p&gt;&lt;head rend="h2"&gt;Contributing&lt;/head&gt;&lt;p&gt;The spec is open source:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Spec: installmd.org&lt;/item&gt;&lt;item&gt;GitHub: github.com/mintlify/install-md&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Add an &lt;code&gt;install.md&lt;/code&gt; to your project root or &lt;code&gt;/docs&lt;/code&gt; directory. That's it.&lt;/p&gt;&lt;p&gt;If you use Mintlify for documentation, install.md is generated automatically at &lt;code&gt;yourdocs.com/install.md&lt;/code&gt;.&lt;/p&gt;&lt;head rend="h2"&gt;FAQ&lt;/head&gt;&lt;p&gt;What about installation wizards like PostHog's or Sentry's?&lt;/p&gt;&lt;p&gt;Wizards solve the same problem: reliable installation across environments. They require significant engineering to build and maintain. PostHog's wizard consists of several LLM prompts, which users need to audit the repo to find. install.md is a lighter-weight alternative—define instructions in markdown, and the LLM handles adaptation. For complex integrations with many configuration options, a dedicated wizard may still be the right choice. For most software, install.md gets you most of the benefit with far less effort.&lt;/p&gt;&lt;p&gt;How does install.md work with my existing CLI or scripts?&lt;/p&gt;&lt;p&gt;Your install.md can instruct the LLM to run your CLI, execute your scripts, or follow your existing setup process. Think of it as a layer that guides the LLM to use whatever tools you've already built.&lt;/p&gt;&lt;p&gt;What about security? Isn't this just &lt;code&gt;curl | bash&lt;/code&gt; with extra steps?&lt;/p&gt;&lt;p&gt;This is a fair concern. A few things make install.md different:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Human-readable by design. Users can review the instructions before execution. Unlike obfuscated scripts, the intent is clear.&lt;/item&gt;&lt;item&gt;Step-by-step approval. LLMs in agentic contexts can be configured to request approval before running commands. Users see each action and can reject it.&lt;/item&gt;&lt;item&gt;No hidden behavior. install.md describes outcomes in natural language. Malicious intent is harder to hide than in a shell script.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Install.md doesn't eliminate trust requirements. Users should only use install.md files from sources they trust—same as any installation method.&lt;/p&gt;&lt;p&gt;What about versioning?&lt;/p&gt;&lt;p&gt;install.md works at the current version by default. If your installation differs significantly across versions, you can host version-specific files (&lt;code&gt;/v2/install.md&lt;/code&gt;) or include version detection logic in the instructions themselves.&lt;/p&gt;&lt;p&gt;What if install.md doesn't fit my use case?&lt;/p&gt;&lt;p&gt;The spec is open source. Open an issue or submit a PR—we're evolving the standard based on real-world feedback.&lt;/p&gt;&lt;head rend="h4"&gt;More blog posts to read&lt;/head&gt;&lt;head rend="h3"&gt;Why documentation is one of the most important surfaces for marketers&lt;/head&gt;&lt;p&gt;A look at why documentation is one of the most influential surfaces in a technical product’s funnel, how it shapes evaluation and adoption, and why marketers should treat it as a core part of their narrative.&lt;/p&gt;January 14, 2026&lt;p&gt;Peri Langlois&lt;/p&gt;&lt;p&gt;Head of Product Marketing&lt;/p&gt;&lt;head rend="h3"&gt;How I built our knowledge base in an afternoon&lt;/head&gt;&lt;p&gt;Migrating content from multiple sources to Mintlify and building a knowledge base in hours, not weeks.&lt;/p&gt;January 13, 2026&lt;p&gt;Anahita Sahu&lt;/p&gt;&lt;p&gt;Chief of Staff&lt;/p&gt;&lt;p&gt;Michael Ryaboy&lt;/p&gt;&lt;p&gt;Content Strategist&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46652944</guid><pubDate>Fri, 16 Jan 2026 22:15:20 +0000</pubDate></item><item><title>FLUX.2 [Klein]: Towards Interactive Visual Intelligence</title><link>https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence</link><description>&lt;doc fingerprint="9d927013843c0b86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;p&gt;Today, we release the FLUX.2 [klein] model family, our fastest image models to date. FLUX.2 [klein] unifies generation and editing in a single compact architecture, delivering state-of-the-art quality with end-to-end inference as low as under a second. Built for applications that require real-time image generation without sacrificing quality, and runs on consumer hardware with as little as 13GB VRAM.&lt;/p&gt;
    &lt;p&gt;Demo showing editing with FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;Why go [klein]?&lt;/head&gt;
    &lt;p&gt;Visual Intelligence is entering a new era. As AI agents become more capable, they need visual generation that can keep up; models that respond in real-time, iterate quickly, and run efficiently on accessible hardware.&lt;/p&gt;
    &lt;p&gt;The klein name comes from the German word for "small", reflecting both the compact model size and the minimal latency. But FLUX.2 [klein] is anything but limited. These models deliver exceptional performance in text-to-image generation, image editing and multi-reference generation, typically reserved for much larger models.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's New&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sub-second inference. Generate or edit images in under 0.5s on modern hardware.&lt;/item&gt;
      &lt;item&gt;Photorealistic outputs and high diversity, especially in the base variants.&lt;/item&gt;
      &lt;item&gt;Unified generation and editing. Text-to-image, image editing, and multi-reference support in a single model while delivering frontier performance.&lt;/item&gt;
      &lt;item&gt;Runs on consumer GPUs. The 4B model fits in ~13GB VRAM (RTX 3090/4070 and above).&lt;/item&gt;
      &lt;item&gt;Developer-friendly &amp;amp; Accessible: Apache 2.0 on 4B models, open weights for 9B models. Full open weights for customization and fine-tuning.&lt;/item&gt;
      &lt;item&gt;API and open weights. Production-ready API or run locally with full weights.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: The “FLUX [dev] Non-Commercial License” has been renamed to “FLUX Non-Commercial License” and will apply to the 9B Klein models. No material changes have been made to the license.&lt;/p&gt;
    &lt;p&gt;Text to Image collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;The FLUX.2 [klein] Model Family&lt;/head&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] 9B&lt;/head&gt;
    &lt;p&gt;Our flagship small model. Defines the Pareto frontier for quality vs. latency across text-to-image, single-reference editing, and multi-reference generation. Matches or exceeds models 5x its size - in under half a second. Built on a 9B flow model with 8B Qwen3 text embedder, step-distilled to 4 inference steps.&lt;/p&gt;
    &lt;p&gt;Combine multiple input images, blend concepts, and iterate on complex compositions - all at sub-second speed with frontier-level quality. No model this fast has ever done this well.&lt;/p&gt;
    &lt;p&gt;License: FLUX NCL&lt;/p&gt;
    &lt;p&gt;Imagine editing collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;FLUX.2 [klein] 4B:&lt;/head&gt;
    &lt;p&gt;Fully open under Apache 2.0. Our most accessible model, it runs on consumer GPUs like the RTX 3090/4070. Compact but capable: supports T2I, I2I, and multi-reference at quality that punches above its size. Built for local development and edge deployment.&lt;/p&gt;
    &lt;p&gt;License: Apache 2.0&lt;/p&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] Base 9B / 4B:&lt;/head&gt;
    &lt;p&gt;The full-capacity foundation models. Undistilled, preserving complete training signal for maximum flexibility. Ideal for fine-tuning, LoRA training, research, and custom pipelines where control matters more than speed. Higher output diversity than the distilled models.&lt;/p&gt;
    &lt;p&gt;License: 4B Base under Apache 2.0, 9B Base under FLUX NCL&lt;/p&gt;
    &lt;p&gt;Output Diversity using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;Quantized versions&lt;/head&gt;
    &lt;p&gt;We are also releasing FP8 and NVFP4 versions of all [klein] variants, developed in collaboration with NVIDIA for optimized inference on RTX GPUs. Same capabilities, smaller footprint - compatible with even more hardware.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FP8: Up to 1.6x faster, up to 40% less VRAM&lt;/item&gt;
      &lt;item&gt;NVFP4: Up to 2.7x faster, up to 55% less VRAM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benchmarks on RTX 5080/5090, T2I at 1024×1024&lt;lb/&gt;Same licenses apply: Apache 2.0 for 4B variants, FLUX NCL for 9B.&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;Performance Analysis&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] Elo vs Latency (top) and VRAM (bottom) across Text-to-Image, Image-to-Image Single Reference, and Multi-Reference tasks. FLUX.2 [klein] matches or exceeds Qwen's quality at a fraction of the latency and VRAM, and outperforms Z-Image while supporting both text-to-image generation and (multi-reference) image editing in a unified model. The base variants trade some speed for full customizability and fine-tuning, making them better suited for research and adaptation to specific use cases. Speed is measured on a GB200 in bf16.&lt;/p&gt;
    &lt;head rend="h3"&gt;Into the New&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] is more than a faster model. It's a step toward our vision of interactive visual intelligence. We believe the future belongs to creators and developers with AI that can see, create, and iterate in real-time. Systems that enable new categories of applications: real-time design tools, agentic visual reasoning, interactive content creation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;p&gt;Try it&lt;/p&gt;
    &lt;p&gt;Build with it&lt;/p&gt;
    &lt;p&gt;Learn more&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46653721</guid><pubDate>Fri, 16 Jan 2026 23:46:17 +0000</pubDate></item><item><title>Keifu – A TUI for navigating commit graphs with color and clarity</title><link>https://github.com/trasta298/keifu</link><description>&lt;doc fingerprint="323a5dcae4fcdf83"&gt;
  &lt;main&gt;
    &lt;p&gt;keifu (系譜, /keːɸɯ/) is a terminal UI tool that visualizes Git commit graphs. It shows a colored commit graph, commit details, and a summary of changed files, and lets you perform basic branch operations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Readable commit graph — &lt;code&gt;git log --graph&lt;/code&gt;is hard to read; keifu renders a cleaner, color-coded graph&lt;/item&gt;
      &lt;item&gt;Fast branch switching — With AI-assisted coding, working on multiple branches in parallel has become common. keifu makes branch switching quick and visual&lt;/item&gt;
      &lt;item&gt;Keep it simple — Only basic Git operations are supported; this is not a full-featured Git client&lt;/item&gt;
      &lt;item&gt;Narrow terminal friendly — Works well in split panes and small windows&lt;/item&gt;
      &lt;item&gt;No image protocol required — Works on any terminal with Unicode support&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unicode commit graph with per-branch colors&lt;/item&gt;
      &lt;item&gt;Commit list with branch labels, date, author, short hash, and message (some fields may be hidden on narrow terminals)&lt;/item&gt;
      &lt;item&gt;Commit detail panel with full message and changed file stats (+/-)&lt;/item&gt;
      &lt;item&gt;Git operations: checkout, create/delete branch, fetch&lt;/item&gt;
      &lt;item&gt;Branch search with dropdown UI&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run inside a Git repository (auto-discovery from current directory)&lt;/item&gt;
      &lt;item&gt;A terminal with Unicode line drawing support and color&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;command in PATH (required for fetch)&lt;/item&gt;
      &lt;item&gt;Rust toolchain (for building from source)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cargo install keifu&lt;/code&gt;
    &lt;code&gt;mise use -g github:trasta298/keifu@latest&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/trasta298/keifu &amp;amp;&amp;amp; cd keifu &amp;amp;&amp;amp; cargo install --path .&lt;/code&gt;
    &lt;p&gt;Run inside a Git repository:&lt;/p&gt;
    &lt;code&gt;keifu&lt;/code&gt;
    &lt;p&gt;See docs/configuration.md for configuration options.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;j&lt;/code&gt; / &lt;code&gt;↓&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;k&lt;/code&gt; / &lt;code&gt;↑&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;]&lt;/code&gt; / &lt;code&gt;Tab&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Jump to next commit that has branch labels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;[&lt;/code&gt; / &lt;code&gt;Shift+Tab&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Jump to previous commit that has branch labels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;h&lt;/code&gt; / &lt;code&gt;←&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select left branch (same commit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;l&lt;/code&gt; / &lt;code&gt;→&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select right branch (same commit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Page down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+u&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Page up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;g&lt;/code&gt; / &lt;code&gt;Home&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Go to top&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;G&lt;/code&gt; / &lt;code&gt;End&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Go to bottom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to HEAD (current branch)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Checkout selected branch/commit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;b&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create branch at selected commit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Delete branch (local, non-HEAD)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;f&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fetch from origin&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search branches (incremental fuzzy search)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;↑&lt;/code&gt; / &lt;code&gt;Ctrl+k&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select previous result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;↓&lt;/code&gt; / &lt;code&gt;Ctrl+j&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select next result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to selected branch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;Esc&lt;/code&gt; / &lt;code&gt;Backspace&lt;/code&gt; on empty&lt;/cell&gt;
        &lt;cell&gt;Cancel search&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;R&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Refresh repository data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle help&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;q&lt;/code&gt; / &lt;code&gt;Esc&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Quit&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The TUI loads up to 500 commits across all branches.&lt;/item&gt;
      &lt;item&gt;Merge commits are diffed against the first parent; the initial commit is diffed against an empty tree.&lt;/item&gt;
      &lt;item&gt;Changed files are capped at 50 and binary files are skipped.&lt;/item&gt;
      &lt;item&gt;If there are staged or unstaged changes (excluding untracked files), an "uncommitted changes" row appears at the top.&lt;/item&gt;
      &lt;item&gt;When multiple branches point to the same commit, the label is collapsed to a single name with a &lt;code&gt;+N&lt;/code&gt;suffix (e.g.,&lt;code&gt;main +2&lt;/code&gt;). Use&lt;code&gt;h&lt;/code&gt;/&lt;code&gt;l&lt;/code&gt;or&lt;code&gt;←&lt;/code&gt;/&lt;code&gt;→&lt;/code&gt;to switch between them.&lt;/item&gt;
      &lt;item&gt;Checking out &lt;code&gt;origin/xxx&lt;/code&gt;creates or updates a local branch. Upstream is set only when creating a new branch. If the local branch exists but points to a different commit, it is force-updated to match the remote.&lt;/item&gt;
      &lt;item&gt;Remote branches are displayed, but delete operations only work with local branches.&lt;/item&gt;
      &lt;item&gt;Fetch requires the &lt;code&gt;origin&lt;/code&gt;remote to be configured.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46654085</guid><pubDate>Sat, 17 Jan 2026 00:32:24 +0000</pubDate></item><item><title>A Calif. teen trusted ChatGPT's drug advice. He died from an overdose</title><link>https://www.sfgate.com/tech/article/calif-teen-chatgpt-drug-advice-fatal-overdose-21266718.php</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46655048</guid><pubDate>Sat, 17 Jan 2026 03:50:43 +0000</pubDate></item></channel></rss>