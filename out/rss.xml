<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Sep 2025 10:40:24 +0000</lastBuildDate><item><title>Yt-dlp: Upcoming new requirements for YouTube downloads</title><link>https://github.com/yt-dlp/yt-dlp/issues/14404</link><description>&lt;doc fingerprint="9a6db83cc43ebc72"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 10.2k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h3"&gt;Beginning very soon, you'll need to have Deno (or another supported JavaScript runtime) installed to keep YouTube downloads working as normal.&lt;/head&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;Up until now, yt-dlp has been able to use its built-in JavaScript "interpreter" to solve the JavaScript challenges that are required for YouTube downloads. But due to recent changes on YouTube's end, the built-in JS interpreter will soon be insufficient for this purpose. The changes are so drastic that yt-dlp will need to leverage a proper JavaScript runtime in order to solve the JS challenges.&lt;/p&gt;
    &lt;head rend="h2"&gt;What do I need to do?&lt;/head&gt;
    &lt;head rend="h3"&gt;Everyone will need to install Deno (or another supported JavaScript runtime; see the FAQ below).&lt;/head&gt;
    &lt;p&gt;yt-dlp will also need a few JavaScript components, and this may require additional action from you depending on how you installed yt-dlp:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Official PyInstaller-bundled executable users (e.g.&lt;/p&gt;&lt;code&gt;yt-dlp.exe&lt;/code&gt;,&lt;code&gt;yt-dlp_macos&lt;/code&gt;,&lt;code&gt;yt-dlp_linux&lt;/code&gt;, etc):&lt;list rend="ul"&gt;&lt;item&gt;No additional action required (besides having Deno). All the necessary JavaScript components will be bundled with these executables.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;PyPI package users (e.g. installed with&lt;/p&gt;&lt;code&gt;pip&lt;/code&gt;,&lt;code&gt;pipx&lt;/code&gt;, etc):&lt;list rend="ul"&gt;&lt;item&gt;Install and upgrade yt-dlp with the &lt;code&gt;default&lt;/code&gt;optional dependency group included, e.g.:&lt;code&gt;pip install -U "yt-dlp[default]"&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Install and upgrade yt-dlp with the &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Official zipimport binary users (the&lt;/p&gt;&lt;code&gt;yt-dlp&lt;/code&gt;Unix executable):&lt;list rend="ul"&gt;&lt;item&gt;Run yt-dlp with an additional flag to allow Deno to download &lt;code&gt;npm&lt;/code&gt;dependencies --or-- install yt-dlp's JS solver package in your Python environment. (The flag name and the package name are both still TBD.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Run yt-dlp with an additional flag to allow Deno to download &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Third-party package users (e.g. installed with&lt;/p&gt;&lt;code&gt;pacman&lt;/code&gt;,&lt;code&gt;brew&lt;/code&gt;, etc):&lt;list rend="ul"&gt;&lt;item&gt;The action required will depend on how your third-party package repository decides to handle this change. But the options available for "official zipimport binary users" should work for you as well.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45358980</guid><pubDate>Wed, 24 Sep 2025 11:41:54 +0000</pubDate></item><item><title>Learning Persian with Anki, ChatGPT and YouTube</title><link>https://cjauvin.github.io/posts/learning-persian/</link><description>&lt;doc fingerprint="9290b055cdb636d2"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been learning Persian (Farsi) for a while now, and I’m using a bunch of tools for it. The central one is certainly Anki, a spaced repetition app to train memory. I’m creating my own never-ending deck of cards, with different types of content, for different purposes. The most frequent type of cards is grammar focused phrases (very rarely single words) coming sometimes from my own daily life, but also very often directly from videos of the Persian Learning YouTube channel, created by Majid, a very talented and nice Persian teacher, in my opinion.&lt;/p&gt;
    &lt;p&gt;Let’s take an example, suppose there is this slide in one of Majid’s videos:&lt;/p&gt;
    &lt;p&gt;From this, I will extract three screenshots (with the MacOS screenshot tool). First, to create a card of type “basic” (one side). I use this type of card to exercise my reading, which is very difficult and remains stubbornly slow, even though I know the 32 letters of the Persian alphabet quite well by now. But the different ways of writing them (which varies by their position in the word) and the fact that the vowels are not present makes it an enduringly challenging task.&lt;/p&gt;
    &lt;p&gt;The next type of card I create with the two remaining screenshots is “basic and reversed”, which actually creates two cards (one for each direction), one with some romanized phrase, and the other with the English or French translation:&lt;/p&gt;
    &lt;p&gt;When I review these cards in my daily Anki routine, this is where ChatGPT enters into play. First I have set a “Persian” project with these instructions:&lt;/p&gt;
    &lt;p&gt;With this project, every time I have a doubt or don’t remember something in Anki, I just take a screenshot and paste it in the project:&lt;/p&gt;
    &lt;p&gt;With this, I have an instant refresher on any notion, in any context. Sometimes I need to do this over and over, before it gels into a deeper, more instant and visceral “knowledge”.&lt;/p&gt;
    &lt;p&gt;The next set of techniques is also based on YouTube. I use a Chrome extension called Dual Subtitles (which only works of course with videos having actual dual sources of subtitles):&lt;/p&gt;
    &lt;p&gt;The dual subtitles serve a couple of purposes: first as a source of new Anki cards (I create the cards directly, again with screenshots in the clipboard).&lt;/p&gt;
    &lt;p&gt;I also use the Tweaks for YouTube extension, which allows me to get extra keyboard shortcuts, to go back and forward only 1 second, instead of the built-in 5 seconds.&lt;/p&gt;
    &lt;p&gt;With these YouTube extensions, I have developed this particular “technique” to improve my vocal understanding:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I listen at 75% speed&lt;/item&gt;
      &lt;item&gt;I use the “dual subtitles” browser extension to have both the Farsi and English subtitles at the same time (I set the Farsi one slightly bigger)&lt;/item&gt;
      &lt;item&gt;Every time a new sentence appears, I read it very quickly first in English (I pause if I need to), and then I listen carefully to the voice, to let the meaning and sound of Farsi infuse my mind (this part is very subtle but the most important: you must “feel” that you understand, and this feeling must cover even the words that you don’t know; because the meaning of the sentence is currently present and active in your mind, because you just read the English part, I believe that its mapping with the Farsi words that you then hear is particularly efficient, at least that’s my theory)&lt;/item&gt;
      &lt;item&gt;I also read the Farsi script, to improve my understanding, and disambiguate certain words for which it’s hard for me to hear what is exactly said&lt;/item&gt;
      &lt;item&gt;I repeat out loud what has been said also, which is quite important&lt;/item&gt;
      &lt;item&gt;Most importantly: I repeat this process (for a single video) over and over, in order to reach a stage where I genuinely understand what is said, in real-time, which is a very powerful and exhilarating feeling.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359524</guid><pubDate>Wed, 24 Sep 2025 12:45:07 +0000</pubDate></item><item><title>How to Lead in a Room Full of Experts</title><link>https://idiallo.com/blog/how-to-lead-in-a-room-full-of-experts</link><description>&lt;doc fingerprint="f3751d93156404b7"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Here is a realization I made recently. I'm sitting in a room full of smart people. On one side are developers who understand the ins and outs of our microservice architecture. On the other are the front-end developers who can debug React in their sleep. In front of me is the product team that has memorized every possible user path that exists on our website. And then, there is me. The lead developer. I don't have the deepest expertise on any single technology.&lt;/p&gt;
      &lt;p&gt;So what exactly is my role when I'm surrounded by experts? Well, that's easy. I have all the answers.&lt;/p&gt;
      &lt;head rend="h2"&gt;Technical Leadership&lt;/head&gt;
      &lt;p&gt;OK. Technically, I don't have all the answers. But I know exactly where to find them and connect the pieces together. &lt;/p&gt;
      &lt;p&gt;When the backend team explains why a new authentication service would take three weeks to build, I'm not thinking about the OAuth flows or JWT token validation. Instead, I think about how I can communicate it to the product team who expects it done "sometime this week." When the product team requests a "simple" feature, I'm thinking about the 3 teams that need to be involved to update the necessary microservices.&lt;/p&gt;
      &lt;p&gt;Leadership in technical environments isn't about being the smartest person in the room. It's about being the most effective translator.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is a Social Skill&lt;/head&gt;
      &lt;p&gt;I often get "eye rolls" when I say this to developers: You are not going to convince anyone with facts. In a room full of experts, your technical credibility gets you a seat at the table, but your social skills determine whether anything productive happens once you're there.&lt;/p&gt;
      &lt;p&gt;Where ideally you will provide documentation that everyone can read and understand, in reality, you need to talk to get people to understand. People can get animated when it comes to the tools they use. When the database team and the API team are talking past each other about response times, your role isn't to lay down the facts. Instead it's to read the room and find a way to address technical constraints and unclear requirements. It means knowing when to let a heated technical debate continue because it's productive, and when to intervene because it's become personal.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is Remembering the Goal&lt;/head&gt;
      &lt;p&gt;When you are an expert in your field, you love to dive deep. It's what makes you experts. But someone needs to keep one eye on the forest while everyone else is examining the trees.&lt;/p&gt;
      &lt;p&gt;I've sat through countless meetings where engineers debated the merits of different caching strategies while the real issue was that we hadn't clearly defined what "fast enough" meant for the user experience. The technical discussion was fascinating, but it wasn't moving us toward shipping.&lt;/p&gt;
      &lt;p&gt;As a leader, your job isn't to have sophisticated technical opinions. It's to ask how this "discussion" can move us closer to solving our actual problem.&lt;/p&gt;
      &lt;p&gt;When you understand a problem, and you have a room full of experts, the solution often emerges from the discussion. But someone needs to clearly articulate what problem we're actually trying to solve.&lt;/p&gt;
      &lt;p&gt;When a product team says customers are reporting the app is too slow, that's not a clear problem. It's a symptom. It might be that users are not noticing when the shopping cart is loaded, or that maybe we have an event that is not being triggered at the right time. Or maybe the app feels sluggish during peak hours. Each of those problems has different solutions, different priorities, and different trade-offs. Each expert might be looking at the problem with their own lense, and may miss the real underlying problem.&lt;/p&gt;
      &lt;p&gt;Your role as a leader is to make sure the problem is translated in a way the team can clearly understand the problem.&lt;/p&gt;
      &lt;head rend="h3"&gt;Leading is Saying "I Don't Know"&lt;/head&gt;
      &lt;p&gt;By definition, leading is knowing the way forward. But in reality, in a room full of experts, pretending to know everything makes you look like an idiot.&lt;/p&gt;
      &lt;p&gt;Instead, "I don't know, but let's figure it out" becomes a superpower. It gives your experts permission to share uncertainty. It models intellectual humility. And it keeps the focus on moving forward rather than defending ego. It's also an opportunity to let your experts shine.&lt;/p&gt;
      &lt;p&gt;Nothing is more annoying than a lead who needs to be the smartest person in every conversation. Your database expert spent years learning how to optimize queries - let them be the hero when performance issues arise. Your security specialist knows threat models better than you, give them the floor when discussing architecture decisions.&lt;/p&gt;
      &lt;p&gt;Make room for some productive discussion. When two experts disagree about implementation approaches, your job isn't to pick the "right" answer. It's to help frame the decision in terms of trade-offs, timeline, and user impact.&lt;/p&gt;
      &lt;p&gt;Your value isn't in having all the expertise. It's in recognizing which expertise is needed when, and creating space for the right people to contribute their best work. &lt;/p&gt;
      &lt;head rend="h3"&gt;The Translation Challenge&lt;/head&gt;
      &lt;p&gt;There was this fun blog post I read recently about how non-developers read tutorials written by developers. What sounds natural to you, can be complete gibberish to someone else. As a lead, you constantly need to think about your audience. You need to learn multiple languages to communicate the same thing:&lt;/p&gt;
      &lt;p&gt;Developer language: "The authentication service has a dependency on the user service, and if we don't implement proper circuit breakers, we'll have cascading failures during high load."&lt;/p&gt;
      &lt;p&gt;Product language: "If our login system goes down, it could take the entire app with it. We need to build in some safeguards, which will add about a week to the timeline but prevent potential outages."&lt;/p&gt;
      &lt;p&gt;Executive language: "We're prioritizing system reliability over feature velocity for this sprint. This reduces risk of user-facing downtime that could impact revenue."&lt;/p&gt;
      &lt;p&gt;All three statements describe the same technical decision, but each is crafted for its audience. Your experts shouldn't have to learn product speak, and your product team shouldn't need to understand circuit breaker patterns. But someone needs to bridge that gap.&lt;/p&gt;
      &lt;head rend="h2"&gt;Beyond "Because, that's why!"&lt;/head&gt;
      &lt;p&gt;"I'm the lead, and we are going to do it this way." That's probably the worst way to make a decision. That might work in the short term, but it erodes trust and kills the collaborative culture that makes expert teams thrive.&lt;/p&gt;
      &lt;p&gt;Instead, treat your teams like adults and communicate the reason behind your decision:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;"We're choosing the more conservative approach because the cost of being wrong is high, and we can iterate later."&lt;/item&gt;
        &lt;item&gt;"I know this feels like extra work, but it aligns with our architectural goals and will save us time on the next three features."&lt;/item&gt;
        &lt;item&gt;"This isn't the most elegant solution, but it's the one we can ship confidently within our timeline."&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The more comfortable you become with not being the expert, the more effective you become as a leader.&lt;/p&gt;
      &lt;p&gt;When you stop trying to out-expert the experts, you can focus on what expert teams actually need:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Clear problem definitions&lt;/item&gt;
        &lt;item&gt;Context for decision-making&lt;/item&gt;
        &lt;item&gt;Translation between different perspectives&lt;/item&gt;
        &lt;item&gt;Protection from unnecessary complexity&lt;/item&gt;
        &lt;item&gt;Space to do their best work&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Your role isn't to have all the answers. It's to make sure the right questions get asked, the right people get heard, and the right decisions get made for the right reasons.&lt;/p&gt;
      &lt;p&gt;Technical leadership in expert environments is less about command and control, and more about connection and context. You're not the conductor trying to play every instrument. You're the one helping the orchestra understand what song they're playing together.&lt;/p&gt;
      &lt;p&gt;That's a much more interesting challenge than trying to be the smartest person in the room.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359604</guid><pubDate>Wed, 24 Sep 2025 12:52:52 +0000</pubDate></item><item><title>Smartphone Cameras Go Hyperspectral</title><link>https://spectrum.ieee.org/hyperspectral-imaging</link><description>&lt;doc fingerprint="77951f9c0a9da747"&gt;
  &lt;main&gt;
    &lt;p&gt;The human eye is mostly sensitive to only three bands of the electromagnetic spectrum—red, green, and blue (RGB)—in the visible range. In contrast, off-the-shelf smartphone camera sensors are potentially hyperspectral in nature, meaning that each pixel is sensitive to far more spectral bands. Now scientists have found a simple way for any conventional smartphone camera to serve as a hyperspectral sensor—by placing a card with a chart on it within its view. The new patent-pending technique may find applications in defense, security, medicine, forensics, agriculture, environmental monitoring, industrial quality control, and food and beverage quality analysis, the researchers add.&lt;/p&gt;
    &lt;p&gt;“At the heart of this work is a simple but powerful idea—a photo is never just an image,” says Semin Kwon, a postdoctoral research associate of biomedical engineering Purdue University in West Lafayette, Ind. “Every photo carries hidden spectral information waiting to be uncovered. By extracting it, we can turn everyday photography into science.”&lt;/p&gt;
    &lt;p&gt;Using a smartphone camera and a spectral color chart, researchers can image the transmission spectrum of high-end whiskey, thus determining its authenticity. Semin Kwon/Purdue University&lt;/p&gt;
    &lt;p&gt;Every molecule has a unique spectral signature—the degree to which it absorbs or reflects each wavelength of light. The extreme sensitivity to distinguishing color seen in scientific-grade hyperspectral sensors can help them identify chemicals based on their spectral signatures, for applications in a wide range of industries, such as medical diagnostics, distinguishing authentic versus counterfeit whiskey, monitoring air quality, and nondestructive analysis of pigments in artwork, says Young Kim, a professor of biomedical engineering at Purdue.&lt;/p&gt;
    &lt;p&gt;Previous research has pursued a number of different ways to recover spectral details from conventional smartphone RGB camera data. However, machine learning models developed for this purpose typically rely heavily on the task-specific data on which they are trained. This limits their generalizability and makes them susceptible to errors resulting from variations in lighting, image file formats, and more. Another possible avenue involved special hardware attachments, but these can prove expensive and bulky.&lt;/p&gt;
    &lt;p&gt;In the new study, the scientists designed a special color reference chart that can be printed on a card. They also developed an algorithm that can analyze smartphone pictures taken with this card and account for factors such as lighting conditions. This strategy can extract hyperspectral data from raw images with a sensitivity of 1.6 nanometers of difference in wavelength of visible light, comparable to scientific-grade spectrometers.&lt;/p&gt;
    &lt;p&gt;“In short, this technique could turn an ordinary smartphone into a pocket spectrometer,” Kim says.&lt;/p&gt;
    &lt;p&gt;The scientists are currently pursuing applications for their new technique in digital and mobile-health applications in both domestic and resource-limited settings. “We are truly excited that this opens the door to making spectroscopy both affordable and accessible,” Kwon says.&lt;/p&gt;
    &lt;p&gt;The scientists recently detailed their findings in the journal IEEE Transactions on Image Processing.&lt;/p&gt;
    &lt;p&gt;Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45360824</guid><pubDate>Wed, 24 Sep 2025 14:20:33 +0000</pubDate></item><item><title>Show HN: Dayflow – A git log for your day</title><link>https://github.com/JerryZLiu/Dayflow</link><description>&lt;doc fingerprint="6ed6256e19be11b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Turns your screen activity into a clean timeline with AI summaries and distraction highlights.&lt;/p&gt;
    &lt;p&gt;Quickstart • Why I built Dayflow • Features • How it works • Installation • Data &amp;amp; Privacy • Debug &amp;amp; Developer Tools • Auto‑updates • Contributing&lt;/p&gt;
    &lt;p&gt;Dayflow is a native macOS app (SwiftUI) that records your screen at 1 FPS, analyzes it every 15 minutes with AI, and generates a timeline of your activities with summaries. It's lightweight (25MB app size) and uses ~100MB of RAM and &amp;lt;1% cpu.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Privacy‑minded by design: You choose your AI provider. Use Gemini (bring your own API key) or local models (Ollama / LM Studio). See Data &amp;amp; Privacy for details.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I built Dayflow after realizing that my calendar wasn't the source of truth for how I actually spent my time. My screen was. I wanted a calm, trustworthy timeline that let me see my workday without turning into yet another dashboard I had to maintain.&lt;/p&gt;
    &lt;p&gt;Dayflow stands for ownership and privacy by default. You control the data, you choose the AI provider, and you can keep everything local if that's what makes you comfortable. It's MIT licensed and fully open source because anything that watches your screen all day should be completely transparent about what it does with that information. The app should feel like a quiet assistant: respectful of your attention, honest about what it captures, and easy to shut off.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic timeline of your day with concise summaries.&lt;/item&gt;
      &lt;item&gt;1 FPS recording - minimal CPU/storage impact.&lt;/item&gt;
      &lt;item&gt;15-minute analysis intervals for timely updates.&lt;/item&gt;
      &lt;item&gt;Watch timelapses of your day.&lt;/item&gt;
      &lt;item&gt;Auto storage cleanup - removes old recordings after 3 days.&lt;/item&gt;
      &lt;item&gt;Distraction highlights to see what pulled you off‑task.&lt;/item&gt;
      &lt;item&gt;Native UX built with SwiftUI.&lt;/item&gt;
      &lt;item&gt;Auto‑updates with Sparkle (daily check + background download).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Infinitely customizable dashboard — ask any question about your workday, pipe the answers into tiles you arrange yourself, and track trends over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Daily journal — review the highlights Dayflow captured, reflect with guided prompts, and drop screenshots or notes alongside your generated timeline.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Capture — Records screen at 1 FPS in 15-second chunks.&lt;/item&gt;
      &lt;item&gt;Analyze — Every 15 minutes, sends recent footage to AI.&lt;/item&gt;
      &lt;item&gt;Generate — AI creates timeline cards with activity summaries.&lt;/item&gt;
      &lt;item&gt;Display — Shows your day as a visual timeline.&lt;/item&gt;
      &lt;item&gt;Cleanup — Auto-deletes recordings older than 3 days.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The efficiency of your timeline generation depends on your chosen AI provider:&lt;/p&gt;
    &lt;code&gt;flowchart LR
    subgraph Gemini["Gemini Flow: 2 LLM Calls"]
        direction LR
        GV[Video] --&amp;gt; GU[Upload + Transcribe&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GC[Generate Cards&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GD[Done]
    end

    subgraph Local["Local Flow: 33+ LLM Calls"]
        direction LR
        LV[Video] --&amp;gt; LE[Extract 30 frames] --&amp;gt; LD[30 descriptions&amp;lt;br/&amp;gt;30 LLM calls] --&amp;gt; LM[Merge&amp;lt;br/&amp;gt;1 call] --&amp;gt; LT[Title&amp;lt;br/&amp;gt;1 call] --&amp;gt; LC[Merge Check&amp;lt;br/&amp;gt;1 call] --&amp;gt; LMC[Merge Cards&amp;lt;br/&amp;gt;1 call] --&amp;gt; LD2[Done]
    end

    %% Styling
    classDef geminiFlow fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef localFlow fill:#fff8e1,stroke:#ff9800,stroke-width:2px
    classDef geminiStep fill:#4caf50,color:#fff
    classDef localStep fill:#ff9800,color:#fff
    classDef processing fill:#f5f5f5,stroke:#666
    classDef result fill:#e3f2fd,stroke:#1976d2

    class Gemini geminiFlow
    class Local localFlow
    class GU,GC geminiStep
    class LD,LM,LT,LC,LMC localStep
    class GV,LV,LE processing
    class GD,LD2 result
&lt;/code&gt;
    &lt;p&gt;Gemini leverages native video understanding for direct analysis, while Local models reconstruct understanding from individual frame descriptions - resulting in dramatically different processing complexity.&lt;/p&gt;
    &lt;p&gt;Download (end users)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Grab the latest &lt;code&gt;Dayflow.dmg&lt;/code&gt;from GitHub Releases.&lt;/item&gt;
      &lt;item&gt;Open the app; grant Screen &amp;amp; System Audio Recording when prompted:&lt;lb/&gt;macOS → System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording → enable Dayflow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build from source (developers)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Xcode 15+ and open &lt;code&gt;Dayflow.xcodeproj&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Run the &lt;code&gt;Dayflow&lt;/code&gt;scheme on macOS 13+.&lt;/item&gt;
      &lt;item&gt;In your Run scheme, add your &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;under Arguments &amp;gt; Environment Variables (if using Gemini).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0+&lt;/item&gt;
      &lt;item&gt;Xcode 15+&lt;/item&gt;
      &lt;item&gt;A Gemini API key (if using Gemini): https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download &lt;code&gt;Dayflow.dmg&lt;/code&gt;and drag Dayflow into Applications.&lt;/item&gt;
      &lt;item&gt;Launch and grant the Screen &amp;amp; System Audio Recording permission.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/JerryZLiu/Dayflow.git
cd Dayflow
open Dayflow.xcodeproj
# In Xcode: select the Dayflow target, configure signing if needed, then Run.&lt;/code&gt;
    &lt;p&gt;This section explains what Dayflow stores locally, what leaves your machine, and how provider choices affect privacy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;App support folder: &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recordings (video chunks): &lt;code&gt;~/Library/Application Support/Dayflow/recordings/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Local database: &lt;code&gt;~/Library/Application Support/Dayflow/chunks.sqlite&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recording details: 1 FPS capture, analyzed every 15 minutes, 3-day retention&lt;/item&gt;
      &lt;item&gt;Purge / reset tip: Quit Dayflow. Then delete the entire &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;folder to remove recordings and analysis artifacts. Relaunch to start fresh.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;These paths are created by the app at first run. If you package Dayflow differently or run in a sandbox, paths may vary slightly.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini (cloud, BYO key) — Dayflow sends batch payloads to Google’s Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Local models (Ollama / LM Studio) — Processing stays on‑device; Dayflow talks to a local server you run.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Short answer: There is a way to prevent Google from training on your data. If you enable Cloud Billing on at least one Gemini API project, Google treats all of your Gemini API and Google AI Studio usage under the “Paid Services” data‑use rules — even when you’re using unpaid/free quota. Under Paid Services, Google does not use your prompts/responses to improve Google products/models. &lt;list rend="ul"&gt;&lt;item&gt;Terms: “When you activate a Cloud Billing account, all use of Gemini API and Google AI Studio is a ‘Paid Service’ with respect to how Google Uses Your Data, even when using Services that are offered free of charge.” (Gemini API Additional Terms)&lt;/item&gt;&lt;item&gt;Abuse monitoring: even under Paid Services, Google logs prompts/responses for a limited period for policy enforcement and legal compliance. (Same Terms)&lt;/item&gt;&lt;item&gt;EEA/UK/Switzerland: the Paid‑style data handling applies by default to all Services (including AI Studio and unpaid quota) even without billing. (Same Terms)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A couple useful nuances (from docs + forum clarifications):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Studio is still free to use; enabling billing changes data handling, not whether Studio charges you. (Pricing page)&lt;/item&gt;
      &lt;item&gt;UI “Plan: Paid” check: In AI Studio → API keys, you’ll typically see “Plan: Paid” once billing is enabled on any linked project (UI may evolve).&lt;/item&gt;
      &lt;item&gt;Free workaround: “Make one project paid, keep using a free key elsewhere to get the best of both worlds.” The Terms imply account‑level coverage once any billing account is activated, but the Apps nuance above may limit this in specific UI contexts. Treat this as an interpretation, not legal advice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Privacy: With Ollama/LM Studio, prompts and model inference run on your machine. LM Studio documents full offline operation once models are downloaded.&lt;/item&gt;
      &lt;item&gt;Quality/latency: Local open models are improving but can underperform cloud models on complex summarization.&lt;/item&gt;
      &lt;item&gt;Power/battery: Local inference is GPU‑heavy on Apple Silicon and will drain battery faster; prefer plugged‑in sessions for long captures.&lt;/item&gt;
      &lt;item&gt;Future: We may explore fine‑tuning or distilling a local model for better timeline summaries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LM Studio offline: https://lmstudio.ai/docs/app/offline&lt;/item&gt;
      &lt;item&gt;Ollama GPU acceleration (Metal on Apple): https://github.com/ollama/ollama/blob/main/docs/gpu.md&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To record your screen, Dayflow requires the Screen &amp;amp; System Audio Recording permission. Review or change later at:&lt;lb/&gt; System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording.&lt;lb/&gt; Apple’s docs: https://support.apple.com/guide/mac-help/control-access-screen-system-audio-recording-mchld6aa7d23/mac&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Provider &lt;list rend="ul"&gt;&lt;item&gt;Choose Gemini (set &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;) or Local (Ollama/LM Studio endpoint).&lt;/item&gt;&lt;item&gt;For Gemini keys: https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Choose Gemini (set &lt;/item&gt;
      &lt;item&gt;Capture settings &lt;list rend="ul"&gt;&lt;item&gt;Start/stop capture from the main UI. Use Debug to verify batch contents.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Data locations &lt;list rend="ul"&gt;&lt;item&gt;See Data &amp;amp; Privacy for exact paths and a purge tip.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can click the Dayflow icon in the menu bar and view the saved recordings&lt;/p&gt;
    &lt;p&gt;Dayflow integrates Sparkle via Swift Package Manager and shows the current version + a “Check for updates” action. By default, the updater auto‑checks daily and auto‑downloads updates.&lt;/p&gt;
    &lt;code&gt;Dayflow/
├─ Dayflow/                 # SwiftUI app sources (timeline UI, debug UI, capture &amp;amp; analysis pipeline)
├─ docs/                    # Appcast and documentation assets (screenshots, videos)
├─ scripts/                 # Release automation (DMG, notarization, appcast, Sparkle signing, one-button release)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screen capture is blank or fails&lt;lb/&gt;Check System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording and ensure Dayflow is enabled.&lt;/item&gt;
      &lt;item&gt;API errors&lt;lb/&gt;Go into settings and verify your&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;and network connectivity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;V1 of the Dashboard (track answers to custom questions)&lt;/item&gt;
      &lt;item&gt;V1 of the daily journal&lt;/item&gt;
      &lt;item&gt;Fine tuning a small VLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;PRs welcome! If you plan a larger change, please open an issue first to discuss scope and approach.&lt;/p&gt;
    &lt;p&gt;Licensed under the MIT License. See LICENSE for the full text. Software is provided “AS IS”, without warranty of any kind.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sparkle for battle‑tested macOS updates.&lt;/item&gt;
      &lt;item&gt;Google AI Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Ollama and LM Studio for local model support.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361268</guid><pubDate>Wed, 24 Sep 2025 14:53:57 +0000</pubDate></item><item><title>How to be a leader when the vibes are off</title><link>https://chaoticgood.management/how-to-be-a-leader-when-the-vibes-are-off/</link><description>&lt;doc fingerprint="7a01915d36b1034c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Be a Leader When the Vibes Are Off&lt;/head&gt;
    &lt;head rend="h2"&gt;...and the vibes are definitely off&lt;/head&gt;
    &lt;p&gt;It feels different in tech right now. We’re coming off a long era where optimism carried the industry. Something has curdled. AI hype, return-to-office mandates, and continued layoffs have shifted the mood. Managers are quicker to fire, existential dread has replaced the confidence that a tight job market for developers provided for decades. The vibes are for sure off.&lt;/p&gt;
    &lt;head rend="h3"&gt;What’s Changed?&lt;/head&gt;
    &lt;p&gt;(What follows are generalizations. If your company is escaping some or all of these, I applaud you. I’m sure there are exceptions.)&lt;/p&gt;
    &lt;p&gt;AI has injected some destabilization. “I don’t need junior devs when I can just pay $20/month for Cursor” has an effect on everyone even if this turns out to be silly down the road. I see lots of people worried that the aim of all of this is to ultimately have a robot do their entire job. Whether or not this is possible doesn’t mean people aren’t going to try. And it’s the trying that raises people’s anxiety. On top of that, we’ve also got “AI Workslop” to contend with as well, which is making work harder for the diligent among us.&lt;/p&gt;
    &lt;p&gt;Return to Office feels like trust has been broken. Teams that continued to work well (or in some cases, better) after everyone in the industry went remote are now being told to come back to desks in offices. I’ve even heard tales of this happening despite there not being enough office space for everyone, which seems very silly. Also, for the first time in my nearly 30-year career, I’ve even heard of people being told they need to be “at their desks at 9am” and “expected to stay until 5pm at a minimum.” Even before COVID-19 and the mass move to remote work, most companies were flexible on start and stop times. I almost never heard of set hours for software developers until recently. Rules like that scream “we don’t trust you unless we can see you,” even if that’s not really the reason for the mandates. (IMO there are benefits to working in the same location as your colleagues but ham-fisted, poorly thought out mandates are not the way to achieve them.)&lt;/p&gt;
    &lt;p&gt;Layoffs changed the market. For probably 20 years, job security wasn’t really a concern in the industry. Layoffs happened here and there and companies folded, but the demand was always strong and most people capable of writing code or managing people who write code could lose their job, spend the severance on a nice vacation, and return with the confidence that they’d be able to land a new gig in a couple of weeks, likely at higher pay. With the acknowledgement that this was a privilege not enjoyed by most of the working world, it is no longer true. The size and scope of layoffs over the last couple of years have injected more anxiety into the tech workforce.&lt;/p&gt;
    &lt;p&gt;C-Suite Energy has changed. Across the board, execs seem more efficiency-focused, financialized, and less mission-driven. The days of “take care of the employees and the employees will take care of the business” feel like they’re in the rear-view mirror, and a new “do your job, or else!” mentality has taken its place.&lt;/p&gt;
    &lt;p&gt;You can’t change the macro forces that are driving these trends, but you can control how you show up for your team.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wearing the ‘Company Hat’ vs. Chaotic-Good Leadership&lt;/head&gt;
    &lt;p&gt;My standard advice to anyone with a management role and anyone at the Staff+ level of individual contributor is that “wearing the company hat” should be the default. You’re not always going to agree with the decisions that come down from the top. Even when you don’t agree with decisions the company leadership is making, part of your job is representing and facilitating those decisions with full alignment. When acting “in public” (all-hands, department meetings, the #general channel), this is mandatory, as contradicting the bosses in a broad forum can kill the credibility you have the leadership across the wider team. It’s also a good way to get yourself fired.&lt;/p&gt;
    &lt;head rend="h3"&gt;Let them know you’re still on their side&lt;/head&gt;
    &lt;p&gt;But you know what also kills trust? Telling your team it’s sunny out when everyone can plainly see that it’s raining. Your team is made up of smart adults who can, at the very least, count the number of employees and the number of desks and calculate that “everyone in the office on Wednesday” isn’t going to work out well if the people outnumber the chairs. Telling them something else is going to make you look like an idiot toady in their eyes.&lt;/p&gt;
    &lt;p&gt;The right thing to do in this situation is to acknowledge that you see the situation the same way they do, but do it privately, within your immediate team only or in 1-1s. “Yeah, this new policy sucks, I get it. It’s going to affect me in negative ways too.” It’s really important that you validate the emotions that all of these aspects are bringing up in people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Don’t pretend you can fix it&lt;/head&gt;
    &lt;p&gt;You can promise to advocate for saner policies when the opportunity arises if your sphere of influence makes that possible, but don’t promise to make the problem go away if you can’t. Broken promises and poor do/say ratio performance will also kill your team’s faith in you, especially when it’s about things they really care about. And again, this is not a time for grandstanding. In public, you have to support the policies, but when you’re in private with your manager and your peers, that’s the time you can safely push for change.&lt;/p&gt;
    &lt;head rend="h3"&gt;Find small workarounds to make things livable&lt;/head&gt;
    &lt;p&gt;If you can provide some flexibility on seemingly inflexible policies, do it. If your management role includes enforcing the company’s rules, you can use some discretion about how strictly you want to enforce them. Personally, I would never want to “rat out” a good performer who can’t get to their desk by 9am sharp because they have to drop off their kids or punish someone who bugged out early once to catch their favourite performer in concert one town over. Small acts demonstrating that you trust your team, even if the C-Suite doesn’t seem to trust the broader team the way they used to, can go a long way toward maintaining good morale within your group.&lt;/p&gt;
    &lt;p&gt;When things feel shaky in the broader org, people will look more to their direct leader for a sense of stability. The best thing you can do for them is provide it. Quiet honesty builds credibility and fosters loyalty.&lt;/p&gt;
    &lt;head rend="h2"&gt;This too shall pass&lt;/head&gt;
    &lt;p&gt;The industry is going through a period where a lot is changing all at once. We’ve had a few of them before. Things will eventually settle down into a new normal. I’m not great at predictions, so I’ll refrain from detailing what I think things will look like, but I don’t think it’ll be entirely unfamiliar to those who were here before this latest inflection point. This is especially true if leaders who care and treat their staff like adults can stay grounded and stay true to their principles, even when that means performing small, quiet acts of rebellion.&lt;/p&gt;
    &lt;p&gt;You can’t fix the macro trends, but you can try to keep your corner of the tech world a place where people are glad to work.&lt;/p&gt;
    &lt;p&gt;"Off Kilter" by anujd89 is licensed under CC BY 2.0 .&lt;/p&gt;
    &lt;p&gt;Like this? Please feel free to share it on your favourite social media or link site! Share it with friends!&lt;/p&gt;
    &lt;p&gt;Hit subscribe to get new posts delivered to your inbox automatically.&lt;lb/&gt;Feedback? Get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361394</guid><pubDate>Wed, 24 Sep 2025 15:03:59 +0000</pubDate></item><item><title>Python on the Edge: Fast, sandboxed, and powered by WebAssembly</title><link>https://wasmer.io/posts/python-on-the-edge-powered-by-webassembly</link><description>&lt;doc fingerprint="87ab2dfdccf438d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Python on the Edge: Fast, sandboxed, and powered by WebAssembly&lt;/head&gt;
    &lt;p&gt;We are excited to announce full Python support in Wasmer Edge (Beta)&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;With AI workloads on the rise, the demand for Python support on WebAssembly on the Edge has grown rapidly.&lt;/p&gt;
    &lt;p&gt;However, bringing Python to WebAssembly isn't trivial as it means supporting native modules like &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, and &lt;code&gt;pydantic&lt;/code&gt;.&amp;#13;
While projects like &lt;code&gt;pyodide&lt;/code&gt; made strides in running Python in the browser via WebAssembly, their trade-offs don't fully fit server-side needs.&lt;/p&gt;
    &lt;p&gt;After months of hard work, today we're thrilled to announce full Python support in Wasmer Edge (Beta) powered by WebAssembly and WASIX.&lt;/p&gt;
    &lt;p&gt;Now you can run FastAPI, Streamlit, Django, LangChain, MCP servers and more directly on Wasmer and Wasmer Edge! To accomplish it we had to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add support for dynamic linking (&lt;code&gt;dlopen&lt;/code&gt;/&lt;code&gt;dlsym&lt;/code&gt;) into WASIX&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;libffi&lt;/code&gt;support (so Python libraries using&lt;code&gt;ctypes&lt;/code&gt;could be supported)&lt;/item&gt;
      &lt;item&gt;Polish Sockets and threading support in WASIX&lt;/item&gt;
      &lt;item&gt;Release our own Python Package Index with many of the most popular Python Native libraries compiled to WASIX&lt;/item&gt;
      &lt;item&gt;Create our own alternative to Heroku Buildpacks / Nixpacks / Railpack / Devbox to automatically detect a project type from its source code and deploy it (including running with Wasmer or deploying to Wasmer Edge!). Updates will be shared soon!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How fast is it?&lt;/head&gt;
    &lt;p&gt;This Python release is much faster than any of the other Python releases we did in the past.&lt;/p&gt;
    &lt;p&gt;It is fast. Insa…natively fast (it's even faster than our py2wasm project!)&lt;/p&gt;
    &lt;code&gt;$ wasmer run python/python@=0.2.0 --dir=. -- pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.562538&amp;#13;
This machine benchmarks at 88882.9 pystones/second&amp;#13;
$ wasmer run python/python --dir=. -- pystone.py # Note: first run may take time&amp;#13;
Pystone(1.1) time for 50000 passes = 0.093556&amp;#13;
This machine benchmarks at 534439 pystones/second&amp;#13;
$ python3 pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.0827736&amp;#13;
This machine benchmarks at 604057 pystones/second
&lt;/code&gt;
    &lt;p&gt;That's 6x faster, and nearly indistinguishable from native Python performance… quite good, considering that your Python apps can now run fully sandboxed anywhere!&lt;/p&gt;
    &lt;p&gt;Note: the first time you run Python, it will take a few minutes to compile. We are working to improve this so no time will be spent on compilation locally.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;🚀 Even faster performance coming soon: we are trialing an optimization technique that will boost Python performance in Wasm to 95% of native Python speed. This is already powering our PHP server in production. Result: Near-native Python performance, fully sandboxed. Stay tuned!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What it can run&lt;/head&gt;
    &lt;p&gt;Now, you can run any kind of Python API server, powered by &lt;code&gt;fastapi&lt;/code&gt;, &lt;code&gt;django&lt;/code&gt;, &lt;code&gt;flask&lt;/code&gt;, or &lt;code&gt;starlette&lt;/code&gt;, connected to a MySQL database automatically when needed (FastAPI template, Django template).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;fastapi&lt;/code&gt; with websockets (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;mcp&lt;/code&gt; servers (deploy using our MCP template, demo).&lt;/p&gt;
    &lt;p&gt;You can run image processors like &lt;code&gt;pillow&lt;/code&gt;  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;ffmpeg&lt;/code&gt; inside Python (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;streamlit&lt;/code&gt; and &lt;code&gt;langchain&lt;/code&gt; (deploy using our LangChain template, demo).&lt;/p&gt;
    &lt;p&gt;You can even run &lt;code&gt;pypandoc&lt;/code&gt;!  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;Soon, we'll have full support for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;curl_cffi&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;polars&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gevent&lt;/code&gt;/&lt;code&gt;greenlet&lt;/code&gt;(more on this soon!)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Pytorch&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Wasmer VS alternatives&lt;/head&gt;
    &lt;p&gt;Python on Wasmer Edge is just launching, but it's already worth asking: how does it stack up existing solutions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Quick Comparison&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Feature / Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Wasmer Edge&lt;/cell&gt;
        &lt;cell role="head"&gt;Cloudflare&lt;/cell&gt;
        &lt;cell role="head"&gt;AWS Lambda&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Native modules (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, etc.)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported*&lt;/cell&gt;
        &lt;cell&gt;❌ Limited (no &lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Full support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multithreading &amp;amp; multiprocessing (&lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;pandoc&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ASGI / WSGI frameworks (&lt;code&gt;uvicorn&lt;/code&gt;, &lt;code&gt;daphne&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ Patched / limited&lt;/cell&gt;
        &lt;cell&gt;⚠️ Needs wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;WebSockets (&lt;code&gt;streamlit&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Raw sockets (&lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ JS &lt;code&gt;fetch&lt;/code&gt; only&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multiple Python versions&lt;/cell&gt;
        &lt;cell&gt;✅ In Roadmap (3.12, 3.14…)&lt;/cell&gt;
        &lt;cell&gt;❌ Tied to bundled runtime&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cold starts&lt;/cell&gt;
        &lt;cell&gt;⚡ Extremely fast&lt;/cell&gt;
        &lt;cell&gt;⏳ Medium (V8 isolates)&lt;/cell&gt;
        &lt;cell&gt;⏳ Slow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Code changes required&lt;/cell&gt;
        &lt;cell&gt;✅ None&lt;/cell&gt;
        &lt;cell&gt;⚠️ Some&lt;/cell&gt;
        &lt;cell&gt;⚠️ Wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pricing&lt;/cell&gt;
        &lt;cell&gt;💰 Affordable&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Cloudflare Workers (Python) / Pyodide&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;ℹ️ Most of the demos that we showcased on this article, are not runnable inside of Cloudflare:&lt;/p&gt;&lt;code&gt;ffmpeg&lt;/code&gt;,&lt;code&gt;streamlit&lt;/code&gt;,&lt;code&gt;pypandoc&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;Cloudflare launched Python support ~18 months ago, by using Pyodide inside workerd, their JavaScript-based Workers runtime.&lt;/p&gt;
    &lt;p&gt;While great for browser-like environments, Pyodide has trade-offs that make it less suitable server-side. Here are the limitations when running Python in Cloudflare:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ No support for &lt;code&gt;uvloop&lt;/code&gt;,&lt;code&gt;uvicorn&lt;/code&gt;, or similar event-native frameworks (JS event loop patches break compatibility with native).&lt;/item&gt;
      &lt;item&gt;❌ No pthreads or multiprocessing support, you can't call subprocesses like &lt;code&gt;ffmpeg&lt;/code&gt;or&lt;code&gt;pypandoc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;❌ No raw HTTP client sockets (HTTP clients are patched to use JS &lt;code&gt;fetch&lt;/code&gt;, no&lt;code&gt;libcurl&lt;/code&gt;available).&lt;/item&gt;
      &lt;item&gt;❌ Limited to a bundled Python version and package set.&lt;/item&gt;
      &lt;item&gt;⏳ Cold starts slower due to V8 isolate warmup.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limitations? Cloudflare relies on Pyodide: great in-browser execution, but server-side it implies no sockets, threads, or multiprocessing. The result: convenient for lightweight browser use, but might not be the best fit for real Python workloads on the server.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge runs real Python on WASIX unmodified, so everything "just works", with near-native speed and fast cold starts.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Amazon Lambda&lt;/head&gt;
    &lt;p&gt;AWS Lambda doesn't natively run unmodified Python apps:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ You need adapters (such as https://github.com/slank/awsgi or https://github.com/Kludex/mangum) for running your WSGI sites.&lt;/item&gt;
      &lt;item&gt;❌ WebSockets are unsupported.&lt;/item&gt;
      &lt;item&gt;⚠️ Setup is complex, adapters are often unmaintained.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limits? AWS Lambda requires you to use their HTTP lambda handler, which can cause incompatibility into your own HTTP servers. Also, because their lambda handlers are HTTP-based, there's no easy support for WebSockets.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge supports any Python HTTP servers without requiring any code adaptation from your side.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Why Wasmer Edge Stands Out&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Closer to native Python than Pyodide (no JS involvement at all).&lt;/item&gt;
      &lt;item&gt;Faster cold starts and more compatibility than Cloudflare's Workers.&lt;/item&gt;
      &lt;item&gt;More compatible than AWS Lambda (no wrappers/adapters).&lt;/item&gt;
      &lt;item&gt;More affordable across the board.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;🐍 It's Showtime!&lt;/head&gt;
    &lt;p&gt;Python support in Wasmer and Wasmer Edge is already available and ready to use. We have set up many Python templates to help you get started in no time.&lt;/p&gt;
    &lt;p&gt;https://wasmer.io/templates?language=python&lt;/p&gt;
    &lt;p&gt;To make things even better, we are working on a MCP server for Wasmer, so you will be able to plug Wasmer into ChatGPT or Anthropic and have your websites deploying from your vibe-coded projects. Stay tuned!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;⚠️ Python in Wasmer Edge is still in Beta, so expect some rough edges if your project doesn't work out of the box… if you encounter any issues, please report them so we can work on enabling your workloads on Wasmer Edge.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Create your first MCP Server in Wasmer&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to https://wasmer.io/templates/mcp-chatgpt-starter?intent=at_vRxJIdtPCbKe&lt;/item&gt;
      &lt;item&gt;Connect your Github account&lt;/item&gt;
      &lt;item&gt;Create a git repo from the template&lt;/item&gt;
      &lt;item&gt;Deploy and enjoy!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/python-mcp-chatgpt-starter&lt;/p&gt;
    &lt;head rend="h2"&gt;Create your first Django app&lt;/head&gt;
    &lt;p&gt;We have set up a template for using Django + Uvicorn in Wasmer Edge.&lt;/p&gt;
    &lt;p&gt;You can start using it very easily, just click Deploy: https://wasmer.io/templates/django-starter?intent=at_WK0DIkt3CeKX&lt;/p&gt;
    &lt;p&gt;Deploying a Django app will create a MySQL DB for you in Wasmer Edge (Postgres support is coming soon), run migrations and prepare everything to run your website seamlessly.&lt;/p&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/django-wasmer-starter&lt;/p&gt;
    &lt;p&gt;Ready to deploy your first Python app on Wasmer Edge?&lt;/p&gt;
    &lt;p&gt;Here are the best places to begin:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Starter Templates → Browse Python templates&lt;/item&gt;
      &lt;item&gt;📖 Docs &amp;amp; Examples → Wasmer GitHub&lt;/item&gt;
      &lt;item&gt;💬 Community Support → Join our Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;👉 Deploy your first Python app now&lt;/p&gt;
    &lt;p&gt;With WebAssembly and Wasmer, Python is now portable, sandboxed, and running at near-native speeds. Ready for AI workloads, APIs, and anything you can imagine at the edge.&lt;lb/&gt; The sky is the limit ❤️.&lt;/p&gt;
    &lt;head rend="h5"&gt;About the Author&lt;/head&gt;
    &lt;p&gt;Syrus Akbary is an enterpreneur and programmer. Specifically known for his contributions to the field of WebAssembly. He is the Founder and CEO of Wasmer, an innovative company that focuses on creating developer tools and infrastructure for running Wasm&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;How fast is it?&lt;/p&gt;
    &lt;p&gt;What it can run&lt;/p&gt;
    &lt;p&gt;Wasmer VS alternatives&lt;/p&gt;
    &lt;p&gt;Quick Comparison&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers (Python) / Pyodide&lt;/p&gt;
    &lt;p&gt;Amazon Lambda&lt;/p&gt;
    &lt;p&gt;Why Wasmer Edge Stands Out&lt;/p&gt;
    &lt;p&gt;🐍 It's Showtime!&lt;/p&gt;
    &lt;p&gt;Create your first MCP Server in Wasmer&lt;/p&gt;
    &lt;p&gt;Create your first Django app&lt;/p&gt;
    &lt;p&gt;Deploy your first Python site in seconds with our managed cloud solution.&lt;/p&gt;
    &lt;head rend="h5"&gt;Read more&lt;/head&gt;
    &lt;p&gt;wasmerwasmer edgerustprojectsedgeweb scraper&lt;/p&gt;
    &lt;head rend="h6"&gt;Build a Web Scraper in Rust and Deploy to Wasmer Edge&lt;/head&gt;
    &lt;p&gt;RudraAugust 14, 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362023</guid><pubDate>Wed, 24 Sep 2025 15:48:36 +0000</pubDate></item><item><title>SedonaDB: A new geospatial DataFrame library written in Rust</title><link>https://sedona.apache.org/latest/blog/2025/09/24/introducing-sedonadb-a-single-node-analytical-database-engine-with-geospatial-as-a-first-class-citizen/</link><description>&lt;doc fingerprint="3bdb989c4036eb8a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SedonaDB: A single-node analytical database engine with geospatial as a first-class citizen&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community is excited to announce the initial release of SedonaDB! ð&lt;/p&gt;
    &lt;p&gt;SedonaDB is the first open-source, single-node analytical database engine that treats spatial data as a first-class citizen. It is developed as a subproject of Apache Sedona.&lt;/p&gt;
    &lt;p&gt;Apache Sedona powers large-scale geospatial processing on distributed engines like Spark (SedonaSpark), Flink (SedonaFlink), and Snowflake (SedonaSnow). SedonaDB extends the Sedona ecosystem with a single-node engine optimized for small-to-medium data analytics, delivering the simplicity and speed that distributed systems often cannot.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ What is SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Written in Rust, SedonaDB is lightweight, blazing fast, and spatial-native. Out of the box, it provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ðºï¸ Full support for spatial types, joins, CRS (coordinate reference systems), and functions on top of industry-standard query operations.&lt;/item&gt;
      &lt;item&gt;â¡ Query optimizations, indexing, and data pruning features under the hood that make spatial operations just work with high performance.&lt;/item&gt;
      &lt;item&gt;ð Pythonic and SQL interfaces familiar to developers, plus APIs for R and Rust.&lt;/item&gt;
      &lt;item&gt;âï¸ Flexibility to run in single-machine environments on local files or data lakes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SedonaDB utilizes Apache Arrow and Apache DataFusion, providing everything you need from a modern, vectorized query engine. What sets it apart is the ability to process spatial workloads natively, without extensions or plugins. Installation is straightforward, and SedonaDB integrates easily into both local development and cloud pipelines, offering a consistent experience across environments.&lt;/p&gt;
    &lt;p&gt;The initial release of SedonaDB provides a comprehensive suite of geometric vector operations and seamlessly integrates with GeoArrow, GeoParquet, and GeoPandas. Future versions will support all popular spatial functions, including functions for raster data.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð SedonaDB quickstart example¶&lt;/head&gt;
    &lt;p&gt;Start by installing SedonaDB:&lt;/p&gt;
    &lt;code&gt;pip install "apache-sedona[db]"
&lt;/code&gt;
    &lt;p&gt;Now instantiate the connection:&lt;/p&gt;
    &lt;code&gt;import sedona.db

sd = sedona.db.connect()
&lt;/code&gt;
    &lt;p&gt;Let's perform a spatial join using SedonaDB.&lt;/p&gt;
    &lt;p&gt;Suppose you have a &lt;code&gt;cities&lt;/code&gt; table with latitude and longitude points representing the center of each city, and a &lt;code&gt;countries&lt;/code&gt; table with a column containing a polygon of the country's geographic boundaries.&lt;/p&gt;
    &lt;p&gt;Here are a few rows from the &lt;code&gt;cities&lt;/code&gt; table:&lt;/p&gt;
    &lt;code&gt;ââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
â     name     â            geometry           â
â   utf8view   â      geometry &amp;lt;epsg:4326&amp;gt;     â
ââââââââââââââââªââââââââââââââââââââââââââââââââ¡
â Vatican City â POINT(12.4533865 41.9032822)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â San Marino   â POINT(12.4417702 43.9360958)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â Vaduz        â POINT(9.5166695 47.1337238)   â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;And here are a few rows from the countries table:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââââââââââââââââââ
â             name            â   continent   â                      geometry                      â
â           utf8view          â    utf8view   â                geometry &amp;lt;epsg:4326&amp;gt;                â
âââââââââââââââââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââââââââââââââââââââââââââââââââ¡
â Fiji                        â Oceania       â MULTIPOLYGON(((180 -16.067132663642447,180 -16.55â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â United Republic of Tanzania â Africa        â POLYGON((33.90371119710453 -0.9500000000000001,34â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â Western Sahara              â Africa        â POLYGON((-8.665589565454809 27.656425889592356,-8â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;Hereâs how to perform a spatial join to compute the country of each city:&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select
    cities.name as city_name,
    countries.name as country_name,
    continent
from cities
join countries
where ST_Intersects(cities.geometry, countries.geometry)
"""
).show(3)
&lt;/code&gt;
    &lt;p&gt;The code utilizes &lt;code&gt;ST_Intersects&lt;/code&gt; to determine if a city is contained within a given country.&lt;/p&gt;
    &lt;p&gt;Here's the result of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬ââââââââââââââââââââââââââââââ¬ââââââââââââ
â   city_name   â         country_name        â continent â
â    utf8view   â           utf8view          â  utf8view â
âââââââââââââââââªââââââââââââââââââââââââââââââªââââââââââââ¡
â Suva          â Fiji                        â Oceania   â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dodoma        â United Republic of Tanzania â Africa    â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dar es Salaam â United Republic of Tanzania â Africa    â
âââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;The example above performs a point-in-polygon join, mapping city locations (points) to the countries they fall within (polygons). SedonaDB executes these joins efficiently by leveraging spatial indices where beneficial and dynamically adapting join strategies at runtime using input data samples. While many general-purpose engines struggle with the performance of such operations, SedonaDB is purpose-built for spatial workloads and delivers consistently fast results.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð Apache Sedona SpatialBench¶&lt;/head&gt;
    &lt;p&gt;To test our work on SedonaDB, we also needed to develop a mechanism to evaluate its performance and speed. This led us to develop Apache Sedona SpatialBench, a benchmark for assessing geospatial SQL analytics query performance across database systems.&lt;/p&gt;
    &lt;p&gt;Let's compare the performance of SedonaDB vs. GeoPandas and DuckDB Spatial for some representative spatial queries as defined in SpatialBench.&lt;/p&gt;
    &lt;p&gt;Here are the results from SpatialBench v0.1 for Queries 1â12 at scale factor 1 (SF1) and scale factor 10 (SF10).&lt;/p&gt;
    &lt;p&gt;SedonaDB demonstrates balanced performance across all query types and scales effectively to SF 10. DuckDB excels at spatial filters and some geometric operations but faces challenges with complex joins and KNN queries. GeoPandas, while popular in the Python ecosystem, requires manual optimization and parallelization to handle larger datasets effectively. An in-depth performance analysis can be found in the SpatialBench website.&lt;/p&gt;
    &lt;p&gt;Hereâs an example of the SpatialBench Query #8 that works for SedonaDB and DuckDB:&lt;/p&gt;
    &lt;code&gt;SELECT b.b_buildingkey, b.b_name, COUNT(*) AS nearby_pickup_count
FROM trip t JOIN building b ON ST_DWithin(ST_GeomFromWKB(t.t_pickuploc), ST_GeomFromWKB(b.b_boundary), 0.0045) -- ~500m
GROUP BY b.b_buildingkey, b.b_name
ORDER BY nearby_pickup_count DESC
&lt;/code&gt;
    &lt;p&gt;This query intentionally performs a distance-based spatial join between points and polygons, followed by an aggregation of the results.&lt;/p&gt;
    &lt;p&gt;Here's what the query returns:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬âââââââââââ¬ââââââââââââââââââââââ
â b_buildingkey â  b_name  â nearby_pickup_count â
â     int64     â utf8view â        int64        â
âââââââââââââââââªâââââââââââªââââââââââââââââââââââ¡
â          3779 â linen    â                  42 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â         19135 â misty    â                  36 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â          4416 â sienna   â                  26 â
âââââââââââââââââ´âââââââââââ´ââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;Hereâs the equivalent GeoPandas code:&lt;/p&gt;
    &lt;code&gt;trips_df = pd.read_parquet(data_paths["trip"])
trips_df["pickup_geom"] = gpd.GeoSeries.from_wkb(
    trips_df["t_pickuploc"], crs="EPSG:4326"
)
pickups_gdf = gpd.GeoDataFrame(trips_df, geometry="pickup_geom", crs="EPSG:4326")

buildings_df = pd.read_parquet(data_paths["building"])
buildings_df["boundary_geom"] = gpd.GeoSeries.from_wkb(
    buildings_df["b_boundary"], crs="EPSG:4326"
)
buildings_gdf = gpd.GeoDataFrame(
    buildings_df, geometry="boundary_geom", crs="EPSG:4326"
)

threshold = 0.0045  # degrees (~500m)
result = (
    buildings_gdf.sjoin(pickups_gdf, predicate="dwithin", distance=threshold)
    .groupby(["b_buildingkey", "b_name"], as_index=False)
    .size()
    .rename(columns={"size": "nearby_pickup_count"})
    .sort_values(["nearby_pickup_count", "b_buildingkey"], ascending=[False, True])
    .reset_index(drop=True)
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;ðºï¸ SedonaDB CRS management¶&lt;/head&gt;
    &lt;p&gt;SedonaDB manages the CRS when reading/writing files, as well as in DataFrames, making your pipelines safer and saving you from manual work.&lt;/p&gt;
    &lt;p&gt;Let's compute the number of buildings in the state of Vermont to highlight the CRS management features embedded in SedonaDB.&lt;/p&gt;
    &lt;p&gt;Start by reading in a FlatGeobuf file that uses the EPSG 32618 CRS with GeoPandas and then convert it to a SedonaDB DataFrame:&lt;/p&gt;
    &lt;code&gt;import geopandas as gpd

path = "https://raw.githubusercontent.com/geoarrow/geoarrow-data/v0.2.0/example-crs/files/example-crs_vermont-utm.fgb"
gdf = gpd.read_file(path)
vermont = sd.create_data_frame(gdf)
&lt;/code&gt;
    &lt;p&gt;Letâs check the schema of the &lt;code&gt;vermont&lt;/code&gt; DataFrame:&lt;/p&gt;
    &lt;code&gt;vermont.schema

SedonaSchema with 1 field:
  geometry: wkb &amp;lt;epsg:32618&amp;gt;
&lt;/code&gt;
    &lt;p&gt;We can see that the &lt;code&gt;vermont&lt;/code&gt; DataFrame maintains the CRS thatâs specified in the FlatGeobuf file.  SedonaDB doesnât have a native FlatGeobuf reader yet, but itâs easy to use the GeoPandas FlatGeobuf reader and then convert it to a SedonaDB DataFrame with a single line of code.&lt;/p&gt;
    &lt;p&gt;Now read a GeoParquet file into a SedonaDB DataFrame.&lt;/p&gt;
    &lt;code&gt;buildings = sd.read_parquet(
    "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/microsoft-buildings_point_geo.parquet"
)
&lt;/code&gt;
    &lt;p&gt;Check the schema of the DataFrame:&lt;/p&gt;
    &lt;code&gt;buildings.schema

SedonaSchema with 1 field:
  geometry: geometry &amp;lt;ogc:crs84&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Letâs expose these two tables as views and run a spatial join to see how many buildings are in Vermont:&lt;/p&gt;
    &lt;code&gt;buildings.to_view("buildings", overwrite=True)
vermont.to_view("vermont", overwrite=True)

sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, vermont.geometry)
"""
).show()
&lt;/code&gt;
    &lt;p&gt;This command correctly errors out because the tables have different CRSs. For safety, SedonaDB errors out rather than give you the wrong answer! Here's the error message that's easy to debug:&lt;/p&gt;
    &lt;code&gt;SedonaError: type_coercion
caused by
Error during planning: Mismatched CRS arguments: ogc:crs84 vs epsg:32618
Use ST_Transform() or ST_SetSRID() to ensure arguments are compatible.
&lt;/code&gt;
    &lt;p&gt;Letâs rewrite the spatial join to convert the &lt;code&gt;vermont&lt;/code&gt; CRS to EPSG:4326, so itâs compatible with the &lt;code&gt;buildings&lt;/code&gt; CRS.&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, ST_Transform(vermont.geometry, 'EPSG:4326'))
"""
).show()
&lt;/code&gt;
    &lt;p&gt;We now get the correct result!&lt;/p&gt;
    &lt;code&gt;ââââââââââââ
â count(*) â
â   int64  â
ââââââââââââ¡
â   361856 â
ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;SedonaDB tracks the CRS when reading/writing files, converting to/from GeoPandas DataFrames, or when performing DataFrame operations, so your spatial computations run safely and correctly!&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¯ Realistic example with SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Let's now turn our attention to a KNN join, which is a more complex spatial operation.&lt;/p&gt;
    &lt;p&gt;Suppose you're analyzing ride-sharing data and want to identify which buildings are most commonly near pickup points, helping understand the relationship between trip origins and nearby landmarks, businesses, or residential structures that might influence ride demand patterns.&lt;/p&gt;
    &lt;p&gt;This query finds the five closest buildings to each trip pickup location using spatial nearest neighbor analysis. For every trip, it identifies the five buildings that are geographically closest to where the passenger was picked up and calculates the exact distance to each of those buildings.&lt;/p&gt;
    &lt;p&gt;Hereâs the query:&lt;/p&gt;
    &lt;code&gt;WITH trip_with_geom AS (
    SELECT t_tripkey, t_pickuploc, ST_GeomFromWKB(t_pickuploc) as pickup_geom
    FROM trip
),
building_with_geom AS (
    SELECT b_buildingkey, b_name, b_boundary, ST_GeomFromWKB(b_boundary) as boundary_geom
    FROM building
)
SELECT
    t.t_tripkey,
    t.t_pickuploc,
    b.b_buildingkey,
    b.b_name AS building_name,
    ST_Distance(t.pickup_geom, b.boundary_geom) AS distance_to_building
FROM trip_with_geom t JOIN building_with_geom b
ON ST_KNN(t.pickup_geom, b.boundary_geom, 5, FALSE)
ORDER BY distance_to_building ASC, b.b_buildingkey ASC
&lt;/code&gt;
    &lt;p&gt;Here are the results of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââ¬ââââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââ
â t_tripkey â          t_pickuploc          â b_buildingkey â building_name â distance_to_building â
â   int64   â             binary            â     int64     â      utf8     â        float64       â
âââââââââââââªââââââââââââââââââââââââââââââââªââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââ¡
â   5854027 â 01010000001afa27b85825504001â¦ â            79 â gainsboro     â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   3326828 â 01010000001bfcc5b8b7a95d4083â¦ â           466 â deep          â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   1239844 â 0101000000ce471770d6ce2a40f9â¦ â           618 â ivory         â                  0.0 â
âââââââââââââ´ââââââââââââââââââââââââââââââââ´ââââââââââââââââ´ââââââââââââââââ´âââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;This is one of the queries from SpatialBench.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¦ Why SedonaDB was built in Rust¶&lt;/head&gt;
    &lt;p&gt;SedonaDB is built in Rust, a high-performance, memory-safe language that offers fine-grained memory management and a mature ecosystem of data libraries. It takes full advantage of this ecosystem by integrating with projects such as Apache DataFusion, GeoArrow, and georust/geo.&lt;/p&gt;
    &lt;p&gt;While Spark provides extension points that let SedonaSpark optimize spatial queries in distributed settings, DataFusion offers stable APIs for pruning, spatial operators, and optimizer rules on a single node. This enabled us to embed deep spatial awareness into the engine while preserving full non-spatial functionality. Thanks to the DataFusion project and community, the experience was both possible and enjoyable.&lt;/p&gt;
    &lt;head rend="h2"&gt;âï¸ Why SedonaDB and SedonaSpark are Both Needed¶&lt;/head&gt;
    &lt;p&gt;SedonaSpark is well-suited for large-scale geospatial workloads or environments where Spark is already part of your production stack. For instance, joining a 100 GB vector dataset with a large raster dataset. For smaller datasets, however, Spark's distributed architecture can introduce unnecessary overhead, making it slower to run locally, harder to install, and more difficult to tune.&lt;/p&gt;
    &lt;p&gt;SedonaDB is better for smaller datasets and when running computations locally. The SedonaDB spatial functions are compatible with the SedonaSpark functions, so SQL chunks that work for one engine will usually work for the other. Over time, we will ensure that both project APIs are fully interoperable. Here's an example of a chunk to analyze the Overture buildings table that works for both engines.&lt;/p&gt;
    &lt;code&gt;nyc_bbox_wkt = (
    "POLYGON((-74.2591 40.4774, -74.2591 40.9176, -73.7004 40.9176, -73.7004 40.4774, -74.2591 40.4774))"
)

sd.sql(f"""
SELECT
    id,
    height,
    num_floors,
    roof_shape,
    ST_Centroid(geometry) as centroid
FROM
    buildings
WHERE
    is_underground = FALSE
    AND height IS NOT NULL
    AND height &amp;gt; 20
    AND ST_Intersects(geometry, ST_SetSRID(ST_GeomFromText('{nyc_bbox_wkt}'), 4326))
LIMIT 5;
&lt;/code&gt;
    &lt;head rend="h2"&gt;ð Next steps¶&lt;/head&gt;
    &lt;p&gt;While SedonaDB is well-tested and provides a core set of features that can perform numerous spatial analyses, it remains an early-stage project with multiple opportunities for new features.&lt;/p&gt;
    &lt;p&gt;Many more ST functions are required. Some are relatively straightforward, but others are complex.&lt;/p&gt;
    &lt;p&gt;The community will add built-in support for other spatial file formats, such as GeoPackage and GeoJSON, to SedonaDB. You can read data in these formats into GeoPandas DataFrames and convert them to SedonaDB DataFrames in the meantime.&lt;/p&gt;
    &lt;p&gt;Raster support is also on the roadmap, which is a complex undertaking, so it's an excellent opportunity to contribute if you're interested in solving challenging problems with Rust.&lt;/p&gt;
    &lt;p&gt;Refer to the SedonaDB v0.2 milestone for more details on the specific tasks outlined for the next release. Additionally, feel free to create issues, comment on the Discord, or start GitHub discussions to brainstorm new features.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ Join the community¶&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community has an active Discord community, monthly user meetings, and regular contributor meetings.&lt;/p&gt;
    &lt;p&gt;SedonaDB welcomes contributions from the community. Feel free to request to take ownership of an issue, and we will be happy to assign it to you. You're also welcome to join the contributor meetings, and the other active contributors will be glad to help you get your pull request over the finish line!&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;Weâre celebrating the launch of SedonaDB &amp;amp; SpatialBench with a special Apache Sedona Community Office Hour!&lt;/p&gt;
    &lt;p&gt;ð October 7, 2025&lt;/p&gt;
    &lt;p&gt;â° 8â9 AM Pacific Time&lt;/p&gt;
    &lt;p&gt;ð Online&lt;/p&gt;
    &lt;p&gt;ð Sign up here&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362206</guid><pubDate>Wed, 24 Sep 2025 16:00:45 +0000</pubDate></item><item><title>New bacteria, and two potential antibiotics, discovered in soil</title><link>https://www.rockefeller.edu/news/38239-hundreds-of-new-bacteria-and-two-potential-antibiotics-found-in-soil/</link><description>&lt;doc fingerprint="7c5460762d250ab9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Hundreds of new bacteria, and two potential antibiotics, found in soil&lt;/head&gt;
    &lt;p&gt;Most bacteria cannot be cultured in the lab—and that’s been bad news for medicine. Many of our frontline antibiotics originated from microbes, yet as antibiotic resistance spreads and drug pipelines run dry, the soil beneath our feet has a vast hidden reservoir of untapped lifesaving compounds.&lt;/p&gt;
    &lt;p&gt;Now, researchers have developed a way to access this microbial goldmine. Their approach, published in Nature Biotechnology, circumvents the need to grow bacteria in the lab by extracting very large DNA fragments directly from soil to piece together the genomes of previously hidden microbes, and then mines resulting genomes for bioactive molecules.&lt;/p&gt;
    &lt;p&gt;From a single forest sample, the team generated hundreds of complete bacterial genomes never seen before, as well as two new antibiotic leads. The findings offer a scalable way to scour unculturable bacteria for new drug leads—and expose the vast, uncharted microbial frontier that shapes our environment.&lt;/p&gt;
    &lt;p&gt;“We finally have the technology to see the microbial world that have been previously inaccessible to humans,” says Sean F. Brady, head of the Laboratory of Genetically Encoded Small Molecules at Rockefeller. “And we’re not just seeing this information; we’re already turning it into potentially useful antibiotics. This is just the tip of the spear.”&lt;/p&gt;
    &lt;p&gt;Microbial dark matter&lt;/p&gt;
    &lt;p&gt;When hunting for bacteria, soil is an obvious choice. It’s the largest, most biodiverse reservoir of bacteria on the planet—a single teaspoon of it may contain thousands of different species. Many important therapeutics, including most of our antibiotic arsenal, were discovered in the tiny fraction of soil bacteria that can be grown in the laboratory. And soil is dirt cheap.&lt;/p&gt;
    &lt;p&gt;Yet we know very little about the millions of microbes packed into the earth. Scientists suspect that these hidden bacteria hold not only an untapped reservoir of new therapeutics, but clues as to how microbes shape climate, agriculture, and the larger environment that we live in. “All over the world there’s this hidden ecosystem of microbes that could have dramatic effects on our lives,” Brady adds. “We wanted to finally see them.”&lt;/p&gt;
    &lt;p&gt;Getting that glimpse involved weaving together several approaches. First, the team optimized a method for isolating large, high-quality DNA fragments directly from soil. Pairing this advance with emerging long-read nanopore sequencing allowed Jan Burian, a postdoctoral associate in the Brady lab, to produce continuous stretches of DNA that were tens of thousands of base pairs long—200 times longer than any previously existing technology could manage. Soil DNA contains a huge number of different bacteria; without such large DNA sequences to work with, resolving that complex genetic puzzle into complete and contiguous genomes for disparate bacteria proved exceedingly difficult.&lt;/p&gt;
    &lt;p&gt;“It’s easier to assemble a whole genome out of bigger pieces of DNA, rather than the millions of tiny snippets that were available before,” Brady says. “And that makes a dramatic difference in your confidence in your results.”&lt;/p&gt;
    &lt;p&gt;Unique small molecules, like antibiotics, that bacteria produce are called “natural products”. To convert the newly uncovered sequences into bioactive molecules, the team applied a synthetic bioinformatic natural products (synBNP) approach. They bioinformatically predicted the chemical structures of natural products directly from the genome data and then chemically synthesized them in the lab. With the synBNP approach, Brady and colleagues managed to turn the genetic blueprints from uncultured bacteria into actual molecules—including two potent antibiotics.&lt;/p&gt;
    &lt;p&gt;Brady describes the method, which is scalable and can be adapted to virtually any metagenomic space beyond soil, as a three-step strategy that could kick off a new era of microbiology: “Isolate big DNA, sequence it, and computationally convert it into something useful.”&lt;/p&gt;
    &lt;p&gt;Two new drug candidates, and counting&lt;/p&gt;
    &lt;p&gt;Applied to their single forest soil sample, the team’s approach produced 2.5 terabase-pairs of sequence data—the deepest long-read exploration of a single soil sample to date. Their analysis uncovered hundreds of complete contiguous bacterial genomes, more than 99 percent of which were entirely new to science and identified members from 16 major branches of the bacterial family tree.&lt;/p&gt;
    &lt;p&gt;The two lead compounds discovered could translate into potent antibiotics. One, called erutacidin, disrupts bacterial membranes through an uncommon interaction with the lipid cardiolipin and is effective against even the most challenging drug-resistant bacteria. The other, trigintamicin, acts on a protein-unfolding motor known as ClpX, a rare antibacterial target.&lt;/p&gt;
    &lt;p&gt;Brady emphasizes that these discoveries are only the beginning. The study demonstrates that previously inaccessible microbial genomes can now be decoded and mined for bioactive molecules at scale without culturing the organisms. Unlocking the genetic potential of microbial dark matter may also provide new insights into the hidden microbial networks that sustain ecosystems.&lt;/p&gt;
    &lt;p&gt;“We’re mainly interested in small molecules as therapeutics, but there are applications beyond medicine,” Burian says. “Studying culturable bacteria led to advances that helped shape the modern world and finally seeing and accessing the uncultured majority will drive a new generation of discovery.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362254</guid><pubDate>Wed, 24 Sep 2025 16:03:42 +0000</pubDate></item><item><title>Terence Tao: The role of small organizations in society has shrunk significantly</title><link>https://mathstodon.xyz/@tao/115259943398316677</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362697</guid><pubDate>Wed, 24 Sep 2025 16:32:24 +0000</pubDate></item><item><title>Launch HN: Flywheel (YC S25) – Waymo for Excavators</title><link>https://news.ycombinator.com/item?id=45362914</link><description>&lt;doc fingerprint="2c7449d6851a3652"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, We're Jash and Mahimana, cofounders of Flywheel AI (&lt;/p&gt;https://useflywheel.ai&lt;p&gt;). We’re building a remote teleop and autonomous stack for excavators.&lt;/p&gt;&lt;p&gt;Here's a video: https://www.youtube.com/watch?v=zCNmNm3lQGk.&lt;/p&gt;&lt;p&gt;Interfacing with existing excavators for enabling remote teleop (or autonomy) is hard. Unlike cars which use drive-by-wire technology, most of the millions of excavators are fully hydraulic machines. The joysticks are connected to a pilot hydraulic circuit, which proportionally moves the cylinders in the main hydraulic circuit which ultimately moves the excavator joints. This means excavators mostly do not have an electronic component to control the joints. We solve this by mechanically actuating the joysticks and pedals inside the excavators.&lt;/p&gt;&lt;p&gt;We do this with retrofits which work on any excavator model/make, enabling us to augment existing machines. By enabling remote teleoperation, we are able to increase site safety, productivity and also cost efficiency.&lt;/p&gt;&lt;p&gt;Teleoperation by the operators enables us to prepare training data for autonomy. In robotics, training data comprises observation and action. While images and videos are abundant on the internet, egocentric (PoV) observation and action data is extremely scarce, and it is this scarcity that is holding back scaling robot learning policies.&lt;/p&gt;&lt;p&gt;Flywheel solves this by preparing the training data coming from our remote teleop-enabled excavators which we have already deployed. And we do this with very minimal hardware setup and resources.&lt;/p&gt;&lt;p&gt;During our time in YC, we did 25-30 iterations of sensor stack and placement permutations/combinations, and model hyperparams variations. We called this “evolution of the physical form of our retrofit”. Eventually, we landed on our current evolution and have successfully been able to train some levels of autonomy with only a few hours of training data.&lt;/p&gt;&lt;p&gt;The big takeaway was how much more important data is than optimizing hyperparams of the model. So today, we’re open sourcing 100hrs of excavator dataset that we collected using Flywheel systems on real construction sites. This is in partnership with Frodobots.ai.&lt;/p&gt;&lt;p&gt;Dataset: https://huggingface.co/datasets/FlywheelAI/excavator-dataset&lt;/p&gt;&lt;p&gt;Machine/retrofit details:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  Volvo EC380 (38 ton excavator)
  4xcamera (25fps)
  25 hz expert operator’s action data
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; The dataset contains observation data from 4 cameras and operator's expert action data which can be used to train imitation learning models to run an excavator autonomously for the workflows in those demonstrations, like digging and dumping. We were able to train a small autonomy model for bucket pick and place on Kubota U17 from just 6-7 hours of data collected during YC.&lt;/p&gt;&lt;p&gt;We’re just getting started. We have good amounts of variations in daylight, weather, tasks, and would be adding more hours of data and also converting to lerobot format soon. We’re doing this so people like you and me can try out training models on real world data which is very, very hard to get.&lt;/p&gt;&lt;p&gt;So please checkout the dataset here and feel free to download and use however you like. We would love for people to do things with it! I’ll be around in the thread and look forward to comments and feedback from the community!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362914</guid><pubDate>Wed, 24 Sep 2025 16:48:27 +0000</pubDate></item><item><title>SonyShell – An effort to “SSH into my Sony DSLR”</title><link>https://github.com/goudvuur/sonyshell</link><description>&lt;doc fingerprint="34960c72d72e66ed"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux-only helper built on Sony’s official Camera Remote SDK. It connects to a Sony A6700 camera over Wi-Fi/Ethernet, listens for new photos, downloads them automatically, and can optionally run a script on each downloaded file.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-connect via enumeration or direct IP/MAC.&lt;/item&gt;
      &lt;item&gt;Watches for new capture events and fetches the newest files.&lt;/item&gt;
      &lt;item&gt;Saves into a chosen directory with unique filenames.&lt;/item&gt;
      &lt;item&gt;Post-download hook: run any executable/script with the saved file path as argument.&lt;/item&gt;
      &lt;item&gt;Keepalive mode: auto-retry on startup failure or after disconnects.&lt;/item&gt;
      &lt;item&gt;Cleaned, Linux-only code (no Windows ifdefs, simpler logging).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./sony-remote --dir /photos [options]&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--dir &amp;lt;path&amp;gt;&lt;/code&gt;: Directory to save files (required in most real setups).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--ip &amp;lt;addr&amp;gt;&lt;/code&gt;: Connect directly by IPv4 (e.g.&lt;code&gt;192.168.10.184&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--mac &amp;lt;hex:mac&amp;gt;&lt;/code&gt;: Optional MAC (e.g.&lt;code&gt;10:32:2c:2a:1a:6d&lt;/code&gt;) for direct IP.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cmd &amp;lt;path&amp;gt;&lt;/code&gt;: Executable/script to run after each download, invoked as&lt;code&gt;cmd /photos/DSC01234.JPG&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--keepalive &amp;lt;ms&amp;gt;&lt;/code&gt;: Retry interval when offline or after disconnect.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-v&lt;/code&gt;,&lt;code&gt;--verbose&lt;/code&gt;: Verbose property-change logging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enumerate + keep retrying every 2s, run a hook after each file:&lt;/p&gt;
    &lt;code&gt;./sony-remote --dir /photos --keepalive 2000 --cmd /usr/local/bin/ingest-photo&lt;/code&gt;
    &lt;p&gt;Direct IP connect, verbose logs, retry every 3s:&lt;/p&gt;
    &lt;code&gt;./sony-remote --ip 192.168.10.184 --mac 10:32:2c:2a:1a:6d --dir /photos -v --keepalive 3000&lt;/code&gt;
    &lt;p&gt;Requires Linux, g++, and the Sony Camera Remote SDK.&lt;/p&gt;
    &lt;p&gt;See INSTALL.md&lt;/p&gt;
    &lt;p&gt;or (untested)&lt;/p&gt;
    &lt;code&gt;g++ -std=c++17 sony-a6700-remote-cleaned.cpp \
    -I/path/to/CrSDK/include \
    -L/path/to/CrSDK/lib -lCameraRemoteSDK \
    -lpthread -o sony-remote&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Connect to the camera (via IP or enumeration). Stores/reuses SDK fingerprint under &lt;code&gt;~/.cache/sonshell/&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Wait for notifications: when the camera signals new contents, spawn a download thread.&lt;/item&gt;
      &lt;item&gt;Download newest files to &lt;code&gt;--dir&lt;/code&gt;. Safe naming ensures no overwrite (&lt;code&gt;file_1.jpg&lt;/code&gt;, etc.).&lt;/item&gt;
      &lt;item&gt;Hook: if &lt;code&gt;--cmd&lt;/code&gt;is set, fork/exec the script with the saved path.&lt;/item&gt;
      &lt;item&gt;Reconnect on errors/disconnects if &lt;code&gt;--keepalive&lt;/code&gt;is set.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built on/for Ubuntu 24.04&lt;/item&gt;
      &lt;item&gt;It uses Sony's official Camera Remote SDK (not included here).&lt;/item&gt;
      &lt;item&gt;See DOCS.md for a deep dive into the internals.&lt;/item&gt;
      &lt;item&gt;I leaned heavily on ChatGPT while creating this, so please don't mind the mess! ;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sony Camera Remote SDK: https://support.d-imaging.sony.co.jp/app/sdk/en/index.html&lt;/item&gt;
      &lt;item&gt;See LICENSE for licensing details.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45365878</guid><pubDate>Wed, 24 Sep 2025 21:00:00 +0000</pubDate></item><item><title>Everything that's wrong with Google Search in one image</title><link>https://bitbytebit.substack.com/p/everything-thats-wrong-with-google</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45366566</guid><pubDate>Wed, 24 Sep 2025 22:11:48 +0000</pubDate></item><item><title>Helium Browser</title><link>https://helium.computer/</link><description>&lt;doc fingerprint="170e82509195b1e4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Internet without interruptions&lt;/head&gt;
    &lt;p&gt;Best privacy and unbiased ad-blocking by default. Handy features like native !bangs and split view. No adware, no bloat, no noise. People-first and fully open source.&lt;/p&gt;
    &lt;head rend="h1"&gt;Best privacy by default, not as a hidden option&lt;/head&gt;
    &lt;p&gt;Helium blocks ads, trackers, fingerprinting, third-party cookies, cryptominers, and phishing websites by default thanks to preinstalled uBlock Origin. No extra steps are needed, and there are no biased exceptions â unlike other browsers. &lt;lb/&gt; The browser itself doesn't have any ads, trackers, or analytics. Helium also doesn't make any web requests without your explicit consent, it makes zero web requests on first launch. &lt;lb/&gt; Not enough? Increase privacy even further with ungoogled-chromium flags or uBlock Origin filters. You're finally at the steering wheel of your privacy on the Internet â not in a toy car, but in a real race car. &lt;lb/&gt; We will always stand by our promise of the best privacy and will never prioritize profit over people, unlike big corporations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Respectful by design&lt;/head&gt;
    &lt;p&gt;Helium doesn't annoy you with anything and never will. It doesn't do anything without your consent: no unprovoked tabs about updates or sponsors, no persistent popups telling you about features you don't care about, no weird restarts. &lt;lb/&gt; Nothing interrupts you, jumps in your face, or breaks your flow. Everything just makes sense. You're in full control.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fast, efficient, and light&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium, the fastest and most optimized browser yet. Helium builds on this base to improve performance and save even more energy. You will notice a difference after using Helium for a day. It doesn't slow down over time. &lt;lb/&gt; All bloat is removed: Helium is one of the lightest modern browsers available.&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful when you need it&lt;/head&gt;
    &lt;p&gt;Open pages side-by-side with split view to get even more things done at once. Quickly copy page links with â+Shift+C and share your discoveries with ease. Install any web apps and use them as standalone desktop apps without duplicating Chromium.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed to get out of your way&lt;/head&gt;
    &lt;p&gt;Helium's interface is compact and minimalistic, but it doesn't compromise on beauty or functionality. More web content fits on the screen at once, and the browser interface doesn't get in your way. You can hide everything extra from the toolbar if it annoys you. &lt;lb/&gt; Helium is built with attention to detail. Nothing jiggles or flickers abnormally. Your actions aren't throttled or stopped by lag. Everything's fast, smooth, and simple. Comfort and simplicity are among our top priorities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Works with all Chromium extensions, privately&lt;/head&gt;
    &lt;p&gt;All Chromium extensions are supported and work right away, by default, including all MV2 extensions. We'll keep support for MV2 extensions for as long as possible. &lt;lb/&gt; Helium anonymizes all internal requests to the Chrome Web Store via Helium services. Thanks to this, Google can't track your extension downloads or target ads using this data. No other browser does this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free and fully open-source&lt;/head&gt;
    &lt;p&gt;All parts of the Helium browser are open source, including online services. You can self-host Helium services and use your own instance in your browser. &lt;lb/&gt; Everything is available on GitHub. No exceptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Always safe and sound&lt;/head&gt;
    &lt;p&gt;We release new Chromium updates (such as security patches) as soon as possible. Your browser will always be safe and up to date. &lt;lb/&gt; Helium updates itself automatically on macOS, with auto-updating options available on Linux and Windows. &lt;lb/&gt; All builds are available on GitHub, and you can even make one yourself. The choice is yours!&lt;/p&gt;
    &lt;head rend="h2"&gt;Best security practices for everyone, by default&lt;/head&gt;
    &lt;p&gt;Helium enforces HTTPS on all websites and warns you when a website doesn't support it. Passkeys just work. &lt;lb/&gt; There's no built-in password manager. Passwords should be separate from a web browser to be truly secure and immutable. &lt;lb/&gt; There's also no cloud-based history/data sync. You should be the only one with access to your browsing data, not some conglomerate.&lt;/p&gt;
    &lt;head rend="h1"&gt;Browse the Internet faster with !bangs&lt;/head&gt;
    &lt;p&gt;Skip the search engine and go directly to the website you want. Choose from over 13,000 bangs that make the Internet a breeze to browse, such as !w for Wikipedia, !gh for GitHub, and !wa for Wolfram Alpha. &lt;lb/&gt; Want to chat with AI? Just add !chatgpt or any other AI provider name at the start of your query. Helium will start a new chat for you without sending your prompt anywhere else. &lt;lb/&gt; Helium bangs are the fastest and most private implementation of bangs yet. They work offline, directly in your browser. &lt;lb/&gt; Not sure which bang to use? Check out the full list of bangs!&lt;/p&gt;
    &lt;head rend="h1"&gt;The web browser made for people, with love&lt;/head&gt;
    &lt;p&gt;We're making a web browser that we enjoy using ourselves. Helium's main goal is to provide an honest, comfortable, privacy-respecting, and non-invasive browsing experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for developers&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium and doesn't break any web APIs or standards, despite the focus on privacy. DevTools have been cleaned up and no longer nag you with anything. There's nothing that gets in your way of creating the Internet of the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for everyone on the go&lt;/head&gt;
    &lt;p&gt;Helium's efficiency makes it handy for everyone with their laptop on the go. Split view and quick link copying make it easier than ever to get things done faster. Helium loads pages faster and saves data by blocking ads and other crap.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ready to try Helium?&lt;/head&gt;
    &lt;p&gt;It's never too late to get your internet life back on the right track. Helium can transfer your most important stuff from other browsers in one click. We hope you'll love it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45366867</guid><pubDate>Wed, 24 Sep 2025 22:51:16 +0000</pubDate></item><item><title>Do YC after you graduate: Early decision for students</title><link>https://www.ycombinator.com/early-decision</link><description>&lt;doc fingerprint="b61d01d108cf1634"&gt;
  &lt;main&gt;
    &lt;p&gt;Apply now, do YC after you graduate. For students who want to finish school before doing YC. Get funded the moment you're accepted.&lt;/p&gt;
    &lt;p&gt;Sneha and Anushka, founders of Spur (S24), applied in Fall 2023 for the S24 batch using Early Decision. This allowed them to graduate in May 2024 and then do YC. They've since raised $4.5M from top investors for their AI-powered QA testing tools.&lt;/p&gt;
    &lt;p&gt;Early Decision lets you apply to YC while you're still in school and reserve your spot in a future batch. For example, you apply in Fall of this year, for a spot in the summer batch of the following year. You submit the same YC application as if you were applying for the upcoming batch. If you're accepted, we'll fund you immediately and hold your place for after you graduate.&lt;/p&gt;
    &lt;p&gt;This program is designed for students who want to finish their degree before starting a company. If you're considering working on your own startup after graduation, Early Decision makes it easy to lock in your spot.&lt;/p&gt;
    &lt;p&gt;Even if you're not completely sure yet if you want to do a startup, you should still apply. There is no downside.&lt;/p&gt;
    &lt;p&gt;Also, if you're not in your final year, you can still apply for Early Decision. You'll be able to finish the school year you're currently in, and then either join a later batch or decide to drop out and start sooner.&lt;/p&gt;
    &lt;p&gt;The most common path is students applying in the fall of their final year and joining the summer batch after graduating in Spring. But you can apply for any batch in the future within reason. The application and interview process is the same as if you were applying for the upcoming batch. Once you're accepted, YC funds you right away and confirms your future batch.&lt;/p&gt;
    &lt;p&gt;When you fill out your YC application, you'll see a question asking which batch you want to apply for. Simply select "A batch after Winter 2026" to indicate you're applying for Early Decision, and tell us which batch you'd like to be considered for.&lt;/p&gt;
    &lt;p&gt;The batch preference question in the YC application&lt;/p&gt;
    &lt;p&gt;Many students want to finish their degree or complete more of their education before starting a company. Also we know that many students spend a lot of time in Fall or during their final year applying for jobs or internships. Early Decision gives students another option: apply to YC and bet on yourself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45367046</guid><pubDate>Wed, 24 Sep 2025 23:12:38 +0000</pubDate></item><item><title>How did sports betting become legal in the US?</title><link>https://shreyashariharan.substack.com/p/how-did-sports-betting-become-legal</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45367086</guid><pubDate>Wed, 24 Sep 2025 23:15:38 +0000</pubDate></item><item><title>Knotty: A domain-specific language for knitting patterns</title><link>https://t0mpr1c3.github.io/knotty/index.html</link><description>&lt;doc fingerprint="a5ebd7a76a7f3314"&gt;
  &lt;main&gt;
    &lt;p&gt;▼ Knotty 1 Introduction 2 How to Make a New Pattern 3 Input and Output 4 Code Examples 5 Reference On this page: Knotty 8.11 contents ← prev up next → Knotty Tom Price &amp;lt; t0mpr1c3@gmail.com &amp;gt; ( require knotty ) package: knotty-lib A domain-specific language for knitting patterns. contents ← prev up next →&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45369768</guid><pubDate>Thu, 25 Sep 2025 06:13:32 +0000</pubDate></item><item><title>Perhaps my last post – we'll see (2016)</title><link>http://itila.blogspot.com/2016/04/perhaps-my-last-post-well-see.html</link><description>&lt;doc fingerprint="a72c4c940fbfd90c"&gt;
  &lt;main&gt;
    &lt;p&gt;I'd like my posts to have an ending, so I'm going to make this my final one - maybe.&lt;/p&gt;
    &lt;p&gt;While the doctors haven't expressed an opinion, I think it's possible I haven't got long to go, because I've lost 15 kg, and last Friday's CT scan showed that I've got secondaries on the go in my bones (as we already anticipated from the high ALP levels measured over the past weeks); my platelet count is very low, so they suspect that my bone marrow may be having trouble with cancer cells. On Monday they propose to take a bone marrow sample to find out what's going on. My extreme breathlessness continues - lying still in bed is fine, but getting out of bed onto the commode and back feels afterwards rather like a marathon. Maybe I'll pull through, but let's tentatively wrap up my blog-posts now.&lt;/p&gt;
    &lt;p&gt;There's lots I could write, but the way I'd like to stop is by pointing you to the writings of someone else. Max Edwards wrote a piece for the Guardian about his own cancer, and much of what he writes resonates for me. He was a remarkably eloquent writer.&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370306</guid><pubDate>Thu, 25 Sep 2025 07:52:55 +0000</pubDate></item><item><title>RTO: WTAF</title><link>https://wordsrightman.beehiiv.com/p/rto-wtaf</link><description>&lt;doc fingerprint="6221531f3ef337fc"&gt;
  &lt;main&gt;
    &lt;p&gt;In their great wisdom, Microsoft have announced that instead of improving the user experience of their software so that I don’t feel the need to defenestrate my laptop (it’s a Windows joke, see?), they will be putting effort towards mandating a Return To Office policy from February 2026, for any employees within a 50-mile radius of their Redmond HQ. Other lucky office locations to come next, goes the threat.&lt;/p&gt;
    &lt;p&gt;They claim - way before anyone asked - that this isn’t an attempt to reduce headcount, which makes me squint my eyes, furl my brow and place my right hand onto my chin. I look ridiculous.&lt;/p&gt;
    &lt;p&gt;So tempting. Doesn’t it just call to you?&lt;/p&gt;
    &lt;p&gt;It’s not only Microsoft; mandating RTO is possibly the number one option in the Bad Management Toolkit (patent pending) for those who consider that their company is done innovating, would like to spend some time spinning their wheels, and could the nice, expensive people who helped them do all that innovation please leave at the nearest exit and stop clogging up the payroll thankyouverymuch.&lt;/p&gt;
    &lt;p&gt;Companies implementing such policies will claim that they’re not making the waters unpleasant to chase people away, but the dirty truth is that it’s the least morally-reprehensible reason for it. Times are indeed tough, so rather than making huge layoffs (which they’re also doing), they are at least giving some people agency to decide if they will tolerate The New Way. What alternative reasons are there?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;“We just loooove to control people”: Ew. Definitely worse than saying you can’t afford everybody.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We don’t trust our staff”: That’s kind of on you, Scamp. You hired them, and if they’re not doing the job then you have performance management tools at your fingertips. If you took your eye off the ball and hired so wildly in the past that you’re stuck with underperformers then that’s not the fault of the folks who are totally competent when working remotely.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We don’t think people do their best work from home”: Prove it. Explain how we managed during COVID lockdown, and how that entire span of time didn’t prove that most people were absolutely fine from home. Your company delivered through a pandemic, and still exists now thanks to the efforts of those people. Did your middle managers not get to belittle someone that dared to take their lunch break? Careful now, I might squeeze out a tiny tear for them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We think people need to be in-person for full collaboration”: Then why aren’t you sacking anyone outside of your arbitrarily-chosen radius? You’re saying that any remote staff you hired can’t fully do their jobs, which automatically puts them at a disadvantage in any career path at your company. Enjoy the lawsuit if you say that out loud.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even if you pick one of these reasons and double-down, it avoids the human aspect completely. You’re no longer an investor in people. You will cause untold mental, physical and financial upheaval for many employees who now have to spend money on commuting, childcare, pet care, to name but a few.&lt;/p&gt;
    &lt;p&gt;Just try not to touch your eye, or your lunch.&lt;/p&gt;
    &lt;p&gt;Mental health will be greatly affected. Many people who work remotely do so because travelling to a central location with thousands of other people is a stressful experience. If you and your C-suite role get choppered onto the helipad every morning so you can galivant about the office showing how big and powerful you are, of course you don’t see that side of it.&lt;/p&gt;
    &lt;p&gt;For a lot of people, crowds and/or the possibility of your transport being late (and therefore getting a tick in the Column You Don’t Want A Tick In on your next review) is of huge mental detriment. Being forced to leave your home can be detrimental too - dark early mornings locking your pets in the house and dashing to a busy train, is soul-crushing. If you actively decide to make this a reality for more people, you are increasing the unpleasantness in people’s brains, the overall misery in the world, and you deserve to be held accountable.&lt;/p&gt;
    &lt;p&gt;If you’re a terrible leader, you might be thinking; “Brilliant! I’m so behind the times that I haven’t got mental health awareness in my company, so I’m off the hook!”. Not so fast. Running a medium to large company, if for no motive other than pure profit, will require certain standards to be met if others will work with you. A glaze of professionalism is generally expected in the form of an environmental policy and although you’ll probably copy it off the internet, it will at least imply that you’ve given a sideways glance to your carbon practices so that our great-grandchildren don’t have to speedrun the evolution of gills.&lt;/p&gt;
    &lt;p&gt;“Year 2060” by Busted, featuring your niece&lt;/p&gt;
    &lt;p&gt;The fact is, if your company has a mental health or environmental policy and you mandate RTO, you are simply liars. You can’t actually care about mental health or the environment because if you did, you’d note gleefully that it’s much better for people and planet to have a choice, and to not be forced to contribute to the commuting energy wasted on going to a place to do a thing they could have done from a different, more comfortable place. You would pride yourself on it, in fact.&lt;/p&gt;
    &lt;p&gt;Of course, I’m not saying everyone prefers working from home, or that every job can be done from home - keep oil rig workers on the oil rigs, I say - but forcing everyone to do the same thing removes agency and adds pain for many. If I preferred office work and I could choose a Zoom meeting or threatening everyone in my team with unemployment unless they join me in the meeting room at 4pm on a Friday, I would pick the Zoom call.&lt;/p&gt;
    &lt;p&gt;I honestly don’t know what today’s bosses are hoping to achieve with RTO, but it’s a sure-fire way to rid yourself of those pesky skilled and experienced employees. Good engineers want an employer they can trust; once the opposite reputation sets in, it’s very difficult to reverse it the next time you need good people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370678</guid><pubDate>Thu, 25 Sep 2025 08:56:52 +0000</pubDate></item><item><title>Some interesting stuff I found on IX LANs</title><link>https://blog.benjojo.co.uk/post/ixp-bad-broadcast-packets-interesting</link><description>&lt;doc fingerprint="f78b85556837a9c2"&gt;
  &lt;main&gt;
    &lt;p&gt;These days the internet as a whole is mostly constructed out of point to point ethernet circuits, meaning an ethernet interface (mostly optical) attached directly from one routing device to another routing device.&lt;/p&gt;
    &lt;p&gt;However that is not always the case, as the humble “internet exchange” (IX) still exists, and while the relevancy of IXs are progressively being diminished by the internet increasingly being concentrated into a small handful of content networks and IXs not keeping up with the lowering price of transit or private fiber connections to the largest networks, there are still a large number of networks that’s attached to at least one IX fabric.&lt;/p&gt;
    &lt;p&gt;IXs are a little bit strange, as they are at their core practically identical to a simple ethernet switch you may find in your home or office (except your home switch is unlikely to be doing terabits per second of traffic). As IXs depend on the ethernet switches interest in only being the MAC addresses of traffic and not the Layer 3 IP addresses.&lt;/p&gt;
    &lt;p&gt;However home and small and medium business (SMB) routers often come with defaults that make life a lot easier for networks way of desktop computers and common office equipment on them, these same defaults are at the very least annoying and at the very worst actively exploitable if put on a IX LAN with many untrusted participants.&lt;/p&gt;
    &lt;p&gt;The company that I run and operate has a large number of ports at internet exchanges (at a rough estimate I am the top 13 of all networks on the internet in this metric!), and alongside the route collecting that bgp.tools does on these IX ports, it also listens in on the broadcast and multicast traffic that happens on these exchanges.&lt;/p&gt;
    &lt;p&gt;This isn’t that magical, at its core it works by running tcpdump on each IX port, and picking up the BUM traffic, parsing what it is looking at (and throwing away the unknown unicast, since that is a separate common problem that I don’t want to get involved with), and reporting that data back up the chain to bgp.tools’s website.&lt;/p&gt;
    &lt;p&gt;This creates little warning icons (or alerts if they use the monitoring product) on their IX membership rows to let them and others know that something is not configured correctly&lt;/p&gt;
    &lt;p&gt;When I first started off developing this feature I was basically going off the top of my head on what the obvious mistakes that were likely to happen on misconfigured IX ports. However at the same time I developed a “miscellaneous packets” feed that collected packets that I didn’t have code to deal with.&lt;/p&gt;
    &lt;p&gt;Checking that miscellaneous packet feed every week has been a lot of fun and deeply terrifying on what networks have been sending into exchanges. Here are some of the things that bgp.tools finds on a regular basis&lt;/p&gt;
    &lt;p&gt;With large deployments of routers and switches it is often very difficult to actually locate where each device is plugged into at either end. For this exact reason, many vendors ship protocols that emit various identifier packets that are designed to help operations teams identify the “far side” of each port&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Low&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Link Layer Discovery Protocol is a pretty common cross vendor protocol for doing exactly this, it is also sometimes used to automatically configure capabilities like higher wattage power over ethernet.&lt;/p&gt;
    &lt;p&gt;Here’s an example of a LLDP packet (and what information it discloses) from my own network:&lt;/p&gt;
    &lt;code&gt;root@blah:~# lldpctl 
------------------------------------------------------------------
LLDP neighbors:
------------------------------------------------------------------
Interface:    ens1f0, via: LLDP, RID: 3, Time: 146 days, 02:13:47
  Chassis:     
    ChassisID:    mac 1c:34:da:90:90:01
    SysName:      bgptools-switch
    SysDescr:     Debian GNU/Linux 12 (bookworm) Linux [...]
    MgmtIP:       10.xxx.xxx.2
    MgmtIface:    3
    MgmtIP:       fdd2:xxx::1
    MgmtIface:    3
    Capability:   Bridge, on
    Capability:   Router, on
    Capability:   Wlan, off
    Capability:   Station, off
  Port:        
    PortID:       mac 1c:34:da:90:90:26
    PortDescr:    swp8
    TTL:          120
    PMD autoneg:  supported: yes, enabled: yes
      Adv:          1000Base-X, HD: no, FD: yes
      MAU oper type: 10GigBaseCX4 - X copper over 8 pair 100-Ohm balanced cable
&lt;/code&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Cisco Discovery Protocol is a older and proprietary to Cisco (although that does not stop many vendors from having copied it) version of LLDP&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;The popular budget network equipment vendor Mikrotik ships by default with a feature called “Mikrotik Neighbor Discovery Protocol” enabled by default.&lt;/p&gt;
    &lt;p&gt;Here is an example decoded MNDP packet from a network on FranceIX&lt;/p&gt;
    &lt;code&gt;    Seq: 134398
    MAC Address: 08:55:31:1b:9c:aa
    Identity: DC2.A23.CCR02
    Version: 6.49.6 (stable)
    Platform: MikroTik
    Uptime: 2239h52m39s
    SoftwareID: HBWH-7QHV
    Board: CCR1009-7G-1C-1S+
    IPv6Address: 2001:7f8:54::1:85
    InterfaceName: FRANCE_IX
    IPv4Address: 37.49.237.85
&lt;/code&gt;
    &lt;p&gt;We can see what they named the device , what type of device it is, the interface name (FRANCE_IX), and the device uptime.&lt;/p&gt;
    &lt;p&gt;Most consumer devices when they come on the network do not know what IP address/gateway they are supposed to be using, This is because in most environments you do not want to have machines that have statically configured addresses.&lt;/p&gt;
    &lt;p&gt;However IX’s are not these kinds of environments, as they are environments where all participants have been assigned a very specific IP address to use on the LAN. This does not stop these automatic IP address assignment protocols from attempting to grab IP addresses with some configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: High&lt;/p&gt;
    &lt;p&gt;Security Danger: Targeted traffic redirection&lt;/p&gt;
    &lt;p&gt;This is the exact same protocol that your mobile phone or laptop is using, just being blasted out to terabit/s per second switching fabrics. When a IX participant is asking for addresses with DHCP on the exchange, any one of the entities connected (some of which may be considered adversaries of your state) could reply to their request and assign them an IP address and default gateway, the latter possibly redirecting large amounts of traffic through them!&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: People using your network for free&lt;/p&gt;
    &lt;p&gt;Security Danger: Low&lt;/p&gt;
    &lt;p&gt;IPv6 Router Advertisement is a protocol where routers periodically announced onto the LAN but they are capable of acting as a gateway (and optionally include instructions for clients to generate IPv6 addresses automatically), this is useful for IPv6 deployment, but this behavior is absolutely not desirable on internet exchanges as you do not want to have people use you as a gateway for the entire internet over peering LANs, as effectively giving them free internet transit, which is typically bad for business.&lt;/p&gt;
    &lt;p&gt;Unfortunately this feature is enabled by default on Cisco and Arista, meaning it is so common that bgp.tools has a dedicated icon for it on the site.&lt;/p&gt;
    &lt;p&gt;On exchanges there is generally only one accepted routing protocol that is allowed to be used between members and that is BGP. However that does not seem to stop other networks from accidentally enabling other protocols, some of which automatically “flood” messages to broadcast so they can look for peers to automatically establish relationships with.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;OSPF and IS-IS are the classic internal routing protocols that a lot of networks use to manage their internal routing table. This internal routing table is where the more specific routes for individual customers or subscriber pools exist.&lt;/p&gt;
    &lt;p&gt;While OSPF and IS-IS offer an ability to restrict sessions that are automatically started without a given password in configuration, a decent number of networks do not use this feature.&lt;/p&gt;
    &lt;p&gt;The result of this is if these networks without a password configured meet each other on the internet exchange with OSPF/IS-IS configured they will automatically exchange internal routing tables of each other, the effects of this could range between a security risk because an attacker could inject routes into their internet routing table, all the way to a full blown outage as there would be overlap in internal network routes.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;Routing Information Protocol is a very old way of doing what OSPF and IS-IS does on most modern networks today.&lt;/p&gt;
    &lt;p&gt;RIP and RIPv2 have similar automatic peer configuration features, meaning that if two or more members on an internet exchange have this configured they will almost certainly automatically merge their internal routing tables.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;Security Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;MultiProtocol Label Switching Label Distribution Protocol is a different type of internal routing protocol that rather than dealing with IP prefixes, handles the exchange of MPLS Labels. Given that a lot of networks deploy MPLS as the core way of moving data around in their network, exposing this to another untrusted party is pretty bad.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Quite a lot of vendors have their own form of proprietary ethernet loop detection, which often involve sending out probing packets into the LAN and seeing if they arrive back on any other interface (which would indicate a loop)&lt;/p&gt;
    &lt;p&gt;For example, here is a loop testing packet from a Huawei device&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Local disruption&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Spanning Tree Protocol is a very common default that is enabled across most ethernet switches to combat ethernet loops. However accepting STP packets and sending them to other members of the exchange could result in disruption to the peer, as both sides try to agree a hierarchy with each other.&lt;/p&gt;
    &lt;p&gt;SONiC is an open source network operating system (NOS) developed mostly by Microsoft, this is notable because almost all network operating systems are proprietary with no source code available. There are many reasons for this but one of the primary ones is that while there are many networking equipment vendors out there, the actual fundamental ASIC/Chips suppliers that are used to build high end equipment are limited down to around 3, with the majority of the market share being Broadcom. SONiC has in recent years become the most well known by name open source NOS.&lt;/p&gt;
    &lt;p&gt;Unfortunately SONiC is also just not a very good pick for almost all users, and mortally let down by its software quality. An example of this is a script called arp_update that transmits a “Ping all IPv6 devices” packet to all connected LANs so that it can work around a potential limitation in the hardware that it supports. This is a nuisance on internet exchanges because once there are more than a handful of these devices on the exchange, every one is spending a non zero amount of resources responding to pointless pings.&lt;/p&gt;
    &lt;p&gt;It’s hard for me to understate how crap of a workaround this is, and how much more crap this is for devices with internet exchange ports.&lt;/p&gt;
    &lt;p&gt;There is a final category for things that are kind of just bizarre to see. They are just things that should not actually appear at all on any internet exchange port, and suggest something strange has happened. Either with unexpected devices being connected into the exchange fabric entirely, or very inadvisable configurations being used for public “network edge” ports.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;While Network Time Protocol is very common, most of the time it is configured in a unicast way (meaning that a device deliberately queries a NTP peer), however there is a lesser used broadcast mode where a server broadcasts the time into the LAN on regular intervals.&lt;/p&gt;
    &lt;p&gt;Unfortunately some networks have decided to enable this on their internet exchange ports, meaning that all members are receiving (but are unlikely using) these packets.&lt;/p&gt;
    &lt;p&gt;It doesn’t help that almost every single time I have seen one of these situations, the time being broadcast itself is wrong by at least a few days implying that a device itself does not actually have a good source of time, and it’s just drifting from it’s original set up&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a remote configuration interface to untrusted networks&lt;/p&gt;
    &lt;p&gt;Once again our friend MikroTik comes back with some interesting defaults, In this case the RoMON protocol that allows their GUI management interface (WinBox), and the ability to “telnet” into a neighboring device with just its MAC address.&lt;/p&gt;
    &lt;p&gt;The logic behind the telnet feature is that it is useful for when you need to go to recover a device that you may have accidentally set a bad firewall or IP address/routing configuration on. However that does also mean that bgp.tools has traces of people using this telnet feature (which often broadcasts keystrokes and outputs) to all members. Implying that some networks are using the IX LAN (presumably by borrowing another member’s router) as a recovery mechanism for their misconfigurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a legacy protocol to untrusted networks&lt;/p&gt;
    &lt;p&gt;The Digital Equipment Corporation (Yes, the PDP-11 company) developed a series of network protocols called DECnet. While it is unlikely that you will ever encounter a device that needs DECNet support, Cisco by default enables this protocol on all interfaces (unless explicitly configured otherwise) on all enterprise software versions for IOS/IOS-XE.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Allowing untrusted networks to configure your device&lt;/p&gt;
    &lt;p&gt;Simple Service Discovery Protocol and its’s most common implementation use case Universal Plug and Play is a protocol normally only ever found in the home/residential networking space. It allows for simple configuration for things like port forwarding. Since no one should be connecting such hardware to IX LANs, this is generally a sign of a serious misconfiguration.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Multicast DNS and Link-Local Multicast Name Resolution are protocols used mostly by desktop computers to locate other things on the network (typically home or small biz networks) by name.&lt;/p&gt;
    &lt;p&gt;MDNS is also very common in the automatic discovery of network printers, it also happens to be what I discovered the most on various exchanges&lt;/p&gt;
    &lt;p&gt;While this is obviously ridiculous that a printer would be attached to an IX, what is likely actually happening here is that linux distributions like Debian will/would offer a “print server” role enabled by default. Since Linux “software routers” based on Debian are common in some regions, it doesn’t necessarily surprise me that these routers were installed with the print server role left enabled by mistake when they the operating system was installed.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: The exposure of Windows or SMB to untrusted networks&lt;/p&gt;
    &lt;p&gt;NETBIOS is often used to power SMB/Samba, the Windows file and printer sharing protocol.&lt;/p&gt;
    &lt;p&gt;When I first encountered this packet I assumed that this was going to be a windows server configuration that had been let onto the exchanged by mistake, as encountering windows servers acting as edge routers is unheard of (although windows does actually have a bgp implementation, it is not designed for edge peering and so would make an extremely poor edge router)&lt;/p&gt;
    &lt;p&gt;Upon further inspection of the packets it appears that what has actually happened here (at least 6 different times) is desktops/laptops have been let into the exchange instead. I can tell this because windows will automatically generate host names like &lt;code&gt;SERVER-ABCD1234&lt;/code&gt; for windows server installations, and &lt;code&gt;DESKTOP-ABCD1234&lt;/code&gt; for desktop/laptop ones, and NETBIOS packets often include the hostname of the system that is querying.&lt;/p&gt;
    &lt;p&gt;I can only assume this has happened due to incorrect physical cable patching or VLAN translation.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Untrusted networks could trigger failover of your routers&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Virtual Router Redundancy Protocol and Hot Standby Router Protocol are protocols that are designed to allow two routers to automatically take over from another if they fail. To do this the protocol sends packets on a regular interval into the LAN that has the gateway ip address that is being protected from downtime.&lt;/p&gt;
    &lt;p&gt;While redundancy is obviously desired on exchanges, this is typically done by actually attaching two discrete routers to the exchange with different LAN IP addresses, so VRRP and similar protocols are not appreciated configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Embarrassment&lt;/p&gt;
    &lt;p&gt;Security Danger: Information disclosure&lt;/p&gt;
    &lt;p&gt;When Cisco devices are unable to find a working DNS resolver, they resort to broadcasting the DNS query on all interfaces, Most of the time this just means that the Cisco licensing server (the “cslu-local”) is queried for, with an added bonus of the owners DNS search domain (if they have configured one)&lt;/p&gt;
    &lt;p&gt;So filtering for these packets is quite easy, and results in pretty much exactly what you would think.&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | tail -n 15
    875 cslu-local.{CORP-F}
    998 cslu-local.{CORP-F}
   1162 tools.cisco.com.{Military-A}.
   1648 cslu-local.{CORP-G}
   1659 cslu-local.{CORP-F}
   1880 cslu-local.{CORP-E}
   2088 tools.cisco.com.{CORP-A}.
   2910 cslu-local.{CORP-D}
   4213 cslu-local.{Military-A}.
   5125 cslu-local.{CORP-C}.com.
   5515 cslu-local.{CORP-B}.fr.
   7367 cslu-local.{CORP-A}.com.
   7675 tools.cisco.com.
   9934 cslu-local.{Military-A}
  10838 cslu-local.
&lt;/code&gt;
    &lt;p&gt;Except Cisco also has another interesting default back from the days when Cisco sold dedicated terminal servers where you would dial into the device (over the phone), and then type the device name you were looking to connect to.&lt;/p&gt;
    &lt;p&gt;In practice everybody should be disabling this function in 2025, however by default it is enabled, so if you log into the Cisco CLI and make a typo (let’s say for this example you forgot the you’re on a cisco rather than a huawei), this happens:&lt;/p&gt;
    &lt;p&gt;The CLI just hangs, as it broadcasts your typo onto all interfaces…&lt;/p&gt;
    &lt;p&gt;Anyway with a little bit of careful processing we can see all of these typos and sometimes the search domain from where they came from:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | egrep -v  'cslu|tools.cisco.com'

      1 cls.basetelco.com.
      1 configre.jato3.com.
      1 conft.asn28176.com.br.
      1 conft.powernet.net.br.
      1 cont.wanfiber.net.br.
      1 cpnf.cd.net.za.
      1 end.3cta.eb.mil.br.
      1 end.as37497.net.
      1 end.cd.net.za.
      1 end.spnet.com.br.
      1 exiexit.cd.net.za.
      1 exit-address-family.
      1 exitr.jfsc.local.
      1 expression.jato3.com.
&lt;/code&gt;
    &lt;p&gt;I’ve collected favorite most common typos below:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' |&amp;amp; pcregrep -o1 '^([^.]+)' | sort | uniq -c | sort -n 
...

      1 access-list
      1 configre
      1 cont
      1 cpnf
      1 exiexit
      1 exit-address-family
      1 exitr
      1 exti
      1 extit
      1 ifconfig
      1 int
      1 interface
      1 qconft
      1 qqq
      1 reboot
      1 uptime
      2 coinf
      2 Please
      2 shorun
      2 top
      4 ip
      4 ping
      6 save
      9 conft
     87 y
     92 quit
    134 q
    289 summary
&lt;/code&gt;
    &lt;p&gt;There is of course an added danger while having this enabled that you could actually answer these queries and then trick an operator into typing into a terminal that you control. But I suspect that almost all operators would notice something like that happening, making such a trick difficult to pull off.&lt;/p&gt;
    &lt;p&gt;While pretty much all exchanges have rules that define the kind of traffic that you are allowed to be sent into the internet exchange fabric that would forbid almost all of these types of packets from being sent ( For example, here is AMS-IX’s list of rules ), enforcement of these rules is nonexistent in most exchanges.&lt;/p&gt;
    &lt;p&gt;Which is a shame really because a lot of this can be automatically done with simple access control lists (ACLs) that target just mac addresses alone.&lt;/p&gt;
    &lt;p&gt;DEC-MOP, RoMON, STP, CDP, IS-IS, ES-IS, LLDP, VRRP, OSPF, IPv6 RA are remarkably common, and yet they use specific MAC address destinations that could just be filtered out on all ports, preventing them from being seen by other IX participants.&lt;/p&gt;
    &lt;p&gt;While [LLMNR, NetBIOS, PIM, LDP, MDNS, DHCPv4 /DHCPv6, SSDP, DNS-Broadcast, Broadcast NTP, MikroTik Discovery] do require the IX device to be able to inspect Layer 3 headers like UDP port numbers in ACLs, this feature is very common among deployed hardware in the industry.&lt;/p&gt;
    &lt;p&gt;Even if exchanges are not able to automatically enforce policy using ACLs, there are open source projects like IXP-Watch and systems like bgp.tools that will monitor this for you.&lt;/p&gt;
    &lt;p&gt;There shouldn’t really be an excuse for things to be this way!&lt;/p&gt;
    &lt;p&gt;If you want to stay up to date with the blog you can use the RSS feed or you can follow me on Fediverse @benjojo@benjojo.co.uk&lt;/p&gt;
    &lt;p&gt;Until next time!&lt;/p&gt;
    &lt;p&gt;Related Posts:&lt;/p&gt;
    &lt;p&gt;Appreciation of automated IX Quarantine LAN testing (2024)&lt;/p&gt;
    &lt;p&gt;Better IX network quality monitoring (2024)&lt;/p&gt;
    &lt;p&gt;Random Post:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370882</guid><pubDate>Thu, 25 Sep 2025 09:36:40 +0000</pubDate></item></channel></rss>