<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 15 Nov 2025 21:32:04 +0000</lastBuildDate><item><title>Lawmakers want to ban VPNs</title><link>https://www.eff.org/deeplinks/2025/11/lawmakers-want-ban-vpns-and-they-have-no-idea-what-theyre-doing</link><description>&lt;doc fingerprint="a4aa19513c45d6ad"&gt;
  &lt;main&gt;
    &lt;p&gt;Remember when you thought age verification laws couldn't get any worse? Well, lawmakers in Wisconsin, Michigan, and beyond are about to blow you away.&lt;/p&gt;
    &lt;p&gt;It's unfortunately no longer enough to force websites to check your government-issued ID before you can access certain content, because politicians have now discovered that people are using Virtual Private Networks (VPNs) to protect their privacy and bypass these invasive laws. Their solution? Entirely ban the use of VPNs.&lt;/p&gt;
    &lt;p&gt;Yes, really.&lt;/p&gt;
    &lt;p&gt;As of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of “protecting children” in A.B. 105/S.B. 130. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed “sexual content” to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are “harmful to minors” beyond the type of speech that states can prohibit minors from accessing—potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction.&lt;/p&gt;
    &lt;p&gt;This follows a notable pattern: As we’ve explained previously, lawmakers, prosecutors, and activists in conservative states have worked for years to aggressively expand the definition of “harmful to minors” to censor a broad swath of content: diverse educational materials, sex education resources, art, and even award-winning literature.&lt;/p&gt;
    &lt;p&gt;Wisconsin’s bill has already passed the State Assembly and is now moving through the Senate. If it becomes law, Wisconsin could become the first state where using a VPN to access certain content is banned. Michigan lawmakers have proposed similar legislation that did not move through its legislature, but among other things, would force internet providers to actively monitor and block VPN connections. And in the UK, officials are calling VPNs "a loophole that needs closing."&lt;/p&gt;
    &lt;p&gt;This is actually happening. And it's going to be a disaster for everyone.&lt;/p&gt;
    &lt;head rend="h2"&gt;Here's Why This Is A Terrible Idea&lt;/head&gt;
    &lt;p&gt;VPNs mask your real location by routing your internet traffic through a server somewhere else. When you visit a website through a VPN, that website only sees the VPN server's IP address, not your actual location. It's like sending a letter through a P.O. box so the recipient doesn't know where you really live.&lt;/p&gt;
    &lt;p&gt;So when Wisconsin demands that websites "block VPN users from Wisconsin," they're asking for something that's technically impossible. Websites have no way to tell if a VPN connection is coming from Milwaukee, Michigan, or Mumbai. The technology just doesn't work that way.&lt;/p&gt;
    &lt;p&gt;Websites subject to this proposed law are left with this choice: either cease operation in Wisconsin, or block all VPN users, everywhere, just to avoid legal liability in the state. One state's terrible law is attempting to break VPN access for the entire internet, and the unintended consequences of this provision could far outweigh any theoretical benefit.&lt;/p&gt;
    &lt;head rend="h3"&gt;Almost Everyone Uses VPNs&lt;/head&gt;
    &lt;p&gt;Let's talk about who lawmakers are hurting with these bills, because it sure isn't just people trying to watch porn without handing over their driver's license.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Businesses run on VPNs. Every company with remote employees uses VPNs. Every business traveler connecting through sketchy hotel Wi-Fi needs one. Companies use VPNs to protect client and employee data, secure internal communications, and prevent cyberattacks.&lt;/item&gt;
      &lt;item&gt;Students need VPNs for school. Universities require students to use VPNs to access research databases, course materials, and library resources. These aren't optional, and many professors literally assign work that can only be accessed through the school VPN. The University of Wisconsin-Madison’s WiscVPN, for example, “allows UW–Madison faculty, staff and students to access University resources even when they are using a commercial Internet Service Provider (ISP).”&lt;/item&gt;
      &lt;item&gt;Vulnerable people rely on VPNs for safety. Domestic abuse survivors use VPNs to hide their location from their abusers. Journalists use them to protect their sources. Activists use them to organize without government surveillance. LGBTQ+ people in hostile environments—both in the US and around the world—use them to access health resources, support groups, and community. For people living under censorship regimes, VPNs are often their only connection to vital resources and information their governments have banned.&lt;/item&gt;
      &lt;item&gt;Regular people just want privacy. Maybe you don't want every website you visit tracking your location and selling that data to advertisers. Maybe you don't want your internet service provider (ISP) building a complete profile of your browsing history. Maybe you just think it's creepy that corporations know everywhere you go online. VPNs can protect everyday users from everyday tracking and surveillance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;It’s A Privacy Nightmare&lt;/head&gt;
    &lt;p&gt;Here's what happens if VPNs get blocked: everyone has to verify their age by submitting government IDs, biometric data, or credit card information directly to websites—without any encryption or privacy protection.&lt;/p&gt;
    &lt;p&gt;We already know how this story ends. Companies get hacked. Data gets breached. And suddenly your real name is attached to the websites you visited, stored in some poorly-secured database waiting for the inevitable leak. This has already happened, and is not a matter of if but when. And when it does, the repercussions will be huge.&lt;/p&gt;
    &lt;p&gt;Forcing people to give up their privacy to access legal content is the exact opposite of good policy. It's surveillance dressed up as safety.&lt;/p&gt;
    &lt;head rend="h3"&gt;"Harmful to Minors" Is Not a Catch-All&lt;/head&gt;
    &lt;p&gt;Here's another fun feature of these laws: they're trying to broaden the definition of “harmful to minors” to sweep in a host of speech that is protected for both young people and adults.&lt;/p&gt;
    &lt;p&gt;Historically, states can prohibit people under 18 years old from accessing sexual materials that an adult can access under the First Amendment. But the definition of what constitutes “harmful to minors” is narrow — it generally requires that the materials have almost no social value to minors and that they, taken as a whole, appeal to a minors’ “prurient sexual interests.”&lt;/p&gt;
    &lt;p&gt;Wisconsin's bill defines “harmful to minors” much more broadly. It applies to materials that merely describe sex or feature descriptions/depictions of human anatomy. This definition would likely encompass a wide range of literature, music, television, and films that are protected under the First Amendment for both adults and young people, not to mention basic scientific and medical content.&lt;/p&gt;
    &lt;p&gt;Additionally, the bill’s definition would apply to any websites where more than one third of the site’s material is "harmful to minors." Given the breadth of the definition and its one-third trigger, we anticipate that Wisconsin could argue that the law applies to most social media websites. And it’s not hard to imagine, as these topics become politicised, Wisconsin claiming it applies to websites containing LGBTQ+ health resources, basic sexual education resources, and reproductive healthcare information.&lt;/p&gt;
    &lt;p&gt;This breadth of the bill’s definition isn't a bug, it's a feature. It gives the state a vast amount of discretion to decide which speech is “harmful” to young people, and the power to decide what's "appropriate" and what isn't. History shows us those decisions most often harm marginalized communities.&lt;/p&gt;
    &lt;head rend="h3"&gt;It Won’t Even Work&lt;/head&gt;
    &lt;p&gt;Let's say Wisconsin somehow manages to pass this law. Here's what will actually happen:&lt;/p&gt;
    &lt;p&gt;People who want to bypass it will use non-commercial VPNs, open proxies, or cheap virtual private servers that the law doesn't cover. They'll find workarounds within hours. The internet always routes around censorship.&lt;/p&gt;
    &lt;p&gt;Even in a fantasy world where every website successfully blocked all commercial VPNs, people would just make their own. You can route traffic through cloud services like AWS or DigitalOcean, tunnel through someone else's home internet connection, use open proxies, or spin up a cheap server for less than a dollar.&lt;/p&gt;
    &lt;p&gt;Meanwhile, everyone else (businesses, students, journalists, abuse survivors, regular people who just want privacy) will have their VPN access impacted. The law will accomplish nothing except making the internet less safe and less private for users.&lt;/p&gt;
    &lt;p&gt;Nonetheless, as we’ve mentioned previously, while VPNs may be able to disguise the source of your internet activity, they are not foolproof—nor should they be necessary to access legally protected speech. Like the larger age verification legislation they are a part of, VPN-blocking provisions simply don't work. They harm millions of people and they set a terrifying precedent for government control of the internet. More fundamentally, legislators need to recognize that age verification laws themselves are the problem. They don't work, they violate privacy, they're trivially easy to circumvent, and they create far more harm than they prevent.&lt;/p&gt;
    &lt;head rend="h2"&gt;A False Dilemma&lt;/head&gt;
    &lt;p&gt;People have (predictably) turned to VPNs to protect their privacy as they watched age verification mandates proliferate around the world. Instead of taking this as a sign that maybe mass surveillance isn't popular, lawmakers have decided the real problem is that these privacy tools exist at all and are trying to ban the tools that let people maintain their privacy.&lt;/p&gt;
    &lt;p&gt;Let's be clear: lawmakers need to abandon this entire approach.&lt;/p&gt;
    &lt;p&gt;The answer to "how do we keep kids safe online" isn't "destroy everyone's privacy." It's not "force people to hand over their IDs to access legal content." And it's certainly not "ban access to the tools that protect journalists, activists, and abuse survivors.”&lt;/p&gt;
    &lt;p&gt;If lawmakers genuinely care about young people's well-being, they should invest in education, support parents with better tools, and address the actual root causes of harm online. What they shouldn't do is wage war on privacy itself. Attacks on VPNs are attacks on digital privacy and digital freedom. And this battle is being fought by people who clearly have no idea how any of this technology actually works.&lt;/p&gt;
    &lt;p&gt;If you live in Wisconsin—reach out to your Senator and urge them to kill A.B. 105/S.B. 130. Our privacy matters. VPNs matter. And politicians who can't tell the difference between a security tool and a "loophole" shouldn't be writing laws about the internet.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45924483</guid><pubDate>Fri, 14 Nov 2025 06:39:13 +0000</pubDate></item><item><title>'No One Lives Forever' turns 25 and you still can't buy it legitimately</title><link>https://www.techdirt.com/2025/11/13/no-one-lives-forever-turns-25-you-still-cant-buy-it-legitimately/</link><description>&lt;doc fingerprint="bc71c89d73a33c71"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ahh, a refreshing bit of optimism in these dark times!&lt;/p&gt;
    &lt;p&gt;One of my favorite things in all of professional sports is the unofficial holiday referred to as “Bobby Bonilla Day.” The short version of it is that Bonilla played for the New York Mets decades ago and eventually bought out his contract in 2000 when they decided they were done with him. Rather than pay the $5.9 million buyout of the contract up front, the team instead made the bonkers decision to negotiate a deferred payment schedule for that amount with 8% interest over the course of 25 years. The result is that the Mets will be paying Bonilla $1.2 million per year every July 1st, starting in 2011 and ending in 2035. And if you can’t make sense of the math on that one, it’s because you aren’t aware that the Mets ownership was one of Bernie Madoff’s many victims, which is why they had to defer the payments.&lt;/p&gt;
    &lt;p&gt;November 10th is not Bobby Bonilla Day. But it should be named “Let Us Play No One Lives Forever, You Assholes Day.” The classic spy-shooter turned 25 on that date and, for the exact same reasons we’ve detailed for a god damned decade now, you still can’t buy the game.&lt;/p&gt;
    &lt;p&gt;Here’s the short of it. Due to a series of mergers, closures, and rights purchases, the IP rights for No One Lives Forever and its sequel have been potentially split into three pieces between Warner Bros., Activision, and 20th Century Fox, like it was some kind of fucking horcrux. I say potentially because nobody really knows who owns what, if anything, when it comes to these games. When one company, Nightdive Studios, attempted to remaster and re-release the game as they’ve done with other titles, along with securing trademark rights to the game which hasn’t been sold in over a decade, all three companies complained that they may have rights to it and may sue over it.&lt;/p&gt;
    &lt;p&gt;All of those qualifiers are, again, because even these companies themselves don’t know what rights they actually have. And why is that? Well, because the gaming rights deals were inked before digital storage was widely used for this sort of thing and, well, nobody seems to be able to locate the actual paperwork denoting who owns what. Here’s an example of an exchange Nightdive had with Activision.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“So we went back to Activision and, [after] numerous correspondence going back and forth, they replied that they thought they might have some rights, but that any records predated digital storage. So we’re talking about a contract in a box someplace.” Kuperman laughed. “The image I get is the end of Indiana Jones… somewhere in a box, maybe in the bowels of Activision, maybe it was shipped off to Iron Mountain or somewhere. And they confessed, they didn’t have [their] hands on it. And they weren’t sure that they even had any of those rights.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Which didn’t keep Activision from warning Nightdive that it might totally sue if it moved forward with remastering the game. The other companies made similar noises.&lt;/p&gt;
    &lt;p&gt;So what’s a person to do if they want to play this game? You can’t buy it legitimately currently. It’s not even for sale anywhere. And a situation like that, which I’ve stated before, completely breaks the copyright bargain. The only option is, as Kotaku of all places notes, to download it for free from somewhere.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Downloading games that are available for sale is piracy. It’s illegal, and it’s not supportive of developers and their art. But when companies have gone out of their way to refuse to take your money for a game for the better part of two decades, it’s a very different situation. Look, I’m not your real mom and dad, and I can’t tell you what to do. But if you were to click on this link (link removed by Techdirt due to us not knowing where it takes you) and download both games (as well as spin-off Contract Jack), you’d end up with modernized versions of these classic games, with mods that allow them to work on Windows 10 and 11, and in widescreen. And what better time to do (or not do) this than on the first game’s 25th anniversary?&lt;/p&gt;
      &lt;p&gt;At this point (as indeed it was over eight years ago, the last time I suggested just downloading it, to no negative response at all) we have to consider No One Lives Forever to be abandonware. No one is willing to take ownership of it, although those that could do so sometimes mindlessly threaten to intervene should anyone else try to rebuild it for sale. Nightdive were scared off a decade ago, and it’s been sitting on GOG’s Dreamlist since that launched earlier this year (with 87,171 people saying they’d pay for it if they could). It’s far too small of a concern for any of the megacorps who might own it to spend the time and money to work out if they do, but it’s far too big of a concern within gaming history to be allowed to just disappear. Thank goodness for the anonymous heroes running NOLF Revival. I thank them for their service.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It’s the only option the public has to play this game and enjoy this small piece of our collective culture. The real answer here is some sort of copyright reform that makes this situation not a thing. If a company, or group of companies, won’t offer a piece of work for sale, can’t be bothered to understand what they own of it, if anything, and have no plans to figure any of that out… then how can this be copyright infringement?&lt;/p&gt;
    &lt;p&gt;So happy “Let Us Play No One Lives Forever, You Assholes” Day. Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;p&gt; Filed Under: copyright, ip rights, no one lives forever, video games &lt;lb/&gt; Companies: 20th century fox, activision, microsoft, nightdive, warner bros. &lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ahh, a refreshing bit of optimism in these dark times!&lt;/p&gt;
    &lt;p&gt;I don’t really agree it’s optimistic. Why does “legitimacy” depend on us giving money to assholes? Why should we go so far as to seek them out and force them to take our money? What does it mean to “buy” digital data anyway?&lt;/p&gt;
    &lt;p&gt;I say it is legitimate to download games for free online. It’s not in any way related to “piracy”, and we shouldn’t be treating it as somehow “wrong”. There’s certainly no need to lament our inability to find some corporate overlord to give money to.&lt;/p&gt;
    &lt;p&gt;The best copyright reform would be abolition. But I don’t see why we should wait for legislators, who are out of touch and are anyway in bed with corporate interests, to realize this. We could stop giving money to copyright maximalists right now.&lt;/p&gt;
    &lt;p&gt;IANAL, but I’d say just release and let them sue.&lt;lb/&gt; If they can’t find the documentation during discovery, case dismissed. Maybe even counter-sue for legal fees.&lt;/p&gt;
    &lt;p&gt;But then they have an incentive to look for the paperwork. they don’t have any particular reason to go looking right now but if they see money and a lawsuit they’ll assign someone to start digging.&lt;/p&gt;
    &lt;p&gt;You could be in for a really big payout to them.&lt;/p&gt;
    &lt;p&gt;So it would be a gamble, and the potential payoff is probably not worth the risk you would be taking.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;IANAL, but I’d say just release and let them sue.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You didn’t need to add that first part, it’s implied.&lt;/p&gt;
    &lt;p&gt;Isn’t it funny.&lt;/p&gt;
    &lt;p&gt;If you couldn’t prove you own your house the rich would you you and your family dead in the streets instantly.&lt;/p&gt;
    &lt;p&gt;If they can’t prove they own the ip. No one is allowed to ever touch it.&lt;/p&gt;
    &lt;p&gt;All the rich need to die like the evil pedophiles they are.&lt;/p&gt;
    &lt;p&gt;I am baffled why we make intellectual property as legally upheld as physical property, and yet we still end up with these areas that are so untouchably gray area nobody can do anything.&lt;/p&gt;
    &lt;p&gt;In terms of physical property gray areas, there are certainly disputed areas, but almost nowhere on Earth do people avoid due to the ambiguity. The only real example I know is Bir Tawil.&lt;/p&gt;
    &lt;p&gt;It happens all the time in physical property; the most sterotypical example would be inheritance law, but it regularly shows up in business as well (most commonly small businesses, partnerships, S corps, etc, though also in areas like bankuptcy proceedings for larger businessnesses, and certainly when things become transnational).&lt;/p&gt;
    &lt;p&gt;Perhaps the main point of commonality for areas where this is common is the old cliche; possession may not literally be 9/10 of the law, but it certainly has a major impact. Whenever it is not really an option to rule on physical possession, ownership of anything routinely becomes exactly the gray area you complain of.&lt;/p&gt;
    &lt;p&gt;As for your example regarding physical land claims by govenments, that’s a funny joke. There are massive areas of land whose ownership is “untouchably gray” and are generally avoided. Your example is only notable in that nobody is currently dying over it.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It happens all the time in physical property; the most sterotypical example would be inheritance law&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;What does “it” refer to, and what is inheritance law an example of? Disputes?&lt;/p&gt;
    &lt;p&gt;In my view, inheritance law is meant to simplify property-ownership after death. If we didn’t have it, people would come up with ways to simulate it, such as having a trust or corporation own their property. And the courts would have to waste time dealing with that.&lt;/p&gt;
    &lt;p&gt;Sure, there are sometimes minor gray areas, but “untouchably gray” is quite uncommon. If some property was known to be owned by the dead person, and its new ownership is unclear, a court will resolve that. If you find some real estate you want to buy, you can get an ownership record for it; if the owner can’t be contacted, you can squat there, and the usual worst case in that you’ll eventually get evicted (and the best case is that, after maybe a decade or two, you become the legal owner). With copyright, there’s no way to tell who, if anyone, holds the rights; if it does turn out to be owned, anyone using the material could be hit with statutory damages of $150,000, and that risk persists for like 150 years.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;intellectual property as legally upheld as physical property&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It would be interesting to see something like adverse possession. Like, if it’s been openly distributed as abandonware for 10 years without complaint, it becomes public-domain. (Not that 10-year-old stuff has any business being copyrighted anyway.)&lt;/p&gt;
    &lt;p&gt;Those NOLF IP “feeling unproductive, might litigate later… idk &amp;lt;3&amp;lt;3&amp;lt;3” hogging assholes can burn in… molten lava? Very nice.&lt;/p&gt;
    &lt;p&gt;The fact that the link in the article is indeed a valid, working dedicated site for hosting “pirated” copies of these games and it hasn’t been taken down in nearly a decade says a lot about how much the potential “rightsholders” genuinely do not give a damn about this series.&lt;/p&gt;
    &lt;p&gt;Feels like copyright law should have stipulations for cases like this, especially considering how long terms are right now – corporations shouldn’t be sitting on copyrights doing absolutely nothing with them like dragon hoards.&lt;/p&gt;
    &lt;p&gt;They don’t care enough to get a judgement on some random internet site- but if there was a potential to demand a nice slice carved off of GOG then you bet they would be digging through those metaphorical or literal boxes.&lt;/p&gt;
    &lt;p&gt;Is that the song from the opening in Texas Chainsaw Massacre 2 with Top Chop and Leatherface?&lt;/p&gt;
    &lt;p&gt;Prolly should just call their bluff. If they don’t have a contract in a box, well, sucks to be them.&lt;/p&gt;
    &lt;p&gt;No-one plays…forever. Well, legally anyway.&lt;lb/&gt; The only games are being played by the corporations, and played so poorly that EVERYONE loses.&lt;/p&gt;
    &lt;p&gt;Tim, your comments and the comments on here about “how can this be copyright infringement” indicate that culturally, we now live in a world where both the reason for copyright and the use of copyright are strongly at odds with the LEGAL thing that is copyright.&lt;/p&gt;
    &lt;p&gt;If someone creates something, copyright gives them, for a limited time, control over who can make copies, in exchange for encouragement to create works in the first place knowing that there will be a period of exclusivity on creating those copies.&lt;/p&gt;
    &lt;p&gt;In this case, the work is already created, and the owners of the rights are essentially saying “we know that we own some bits of this, and we want to enforce our exclusivity.” That’s fully within their rights, and could be (tenuously) argued to be part of what convinced the original rightsholders to create the game (and then sell the rights).&lt;/p&gt;
    &lt;p&gt;What annoys me more is when an original creator writes something, sells the copyright, and then is prevented from creating new works by the new rights holder who has no intention of creating anything new themselves, but is using the copyright instead as a tool to restrict the marketplace, pumping up the value of unrelated and already created works. This is the exact OPPOSITE of the intention behind copyright.&lt;/p&gt;
    &lt;p&gt;The One that is and Aint in Australia, that Pops up a Store every few years, that Doent sell anything, it JUST stands there, to KEEP the Rights to the company name.&lt;/p&gt;
    &lt;p&gt;Having to store 1 copy of a program SOMEPLACE, forever to keep your rights.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45928492</guid><pubDate>Fri, 14 Nov 2025 16:31:26 +0000</pubDate></item><item><title>Go's Sweet 16</title><link>https://go.dev/blog/16years</link><description>&lt;doc fingerprint="d395979280422d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Go Blog&lt;/head&gt;
    &lt;head rend="h1"&gt;Go’s Sweet 16&lt;/head&gt;
    &lt;p&gt;This past Monday, November 10th, we celebrated the 16th anniversary of Go’s open source release!&lt;/p&gt;
    &lt;p&gt;We released Go 1.24 in February and Go 1.25 in August, following our now well-established and dependable release cadence. Continuing our mission to build the most productive language platform for building production systems, these releases included new APIs for building robust and reliable software, significant advances in Go’s track record for building secure software, and some serious under-the-hood improvements. Meanwhile, no one can ignore the seismic shifts in our industry brought by generative AI. The Go team is applying its thoughtful and uncompromising mindset to the problems and opportunities of this dynamic space, working to bring Go’s production-ready approach to building robust AI integrations, products, agents, and infrastructure.&lt;/p&gt;
    &lt;head rend="h1"&gt;Core language and library improvements&lt;/head&gt;
    &lt;p&gt;First released in Go 1.24 as an experiment and then graduated in Go 1.25, the new &lt;code&gt;testing/synctest&lt;/code&gt; package
significantly simplifies writing tests for concurrent, asynchronous
code. Such code is particularly common in network services,
and is traditionally very hard to test well. The &lt;code&gt;synctest&lt;/code&gt; package works by
virtualizing time itself. It takes tests that used to be slow, flaky, or both,
and makes them easy to rewrite into reliable and nearly instantaneous tests,
often with just a couple extra lines of code. It’s also a great example of Go’s
integrated approach to software development: behind an almost trivial API, the
&lt;code&gt;synctest&lt;/code&gt; package hides a deep integration with the Go runtime and other parts
of the standard library.&lt;/p&gt;
    &lt;p&gt;This isn’t the only boost the &lt;code&gt;testing&lt;/code&gt; package got over the past year. The new
&lt;code&gt;testing.B.Loop&lt;/code&gt; API is both easier to use
than the original &lt;code&gt;testing.B.N&lt;/code&gt; API and addresses many of the traditional—and
often invisible!—pitfalls of writing Go benchmarks. The
&lt;code&gt;testing&lt;/code&gt; package also has new APIs that make it easy to
cleanup in tests that use
&lt;code&gt;Context&lt;/code&gt;, and that make it
easy to write to the test’s log.&lt;/p&gt;
    &lt;p&gt;Go and containerization grew up together and work great with each other. Go 1.25 launched container-aware scheduling, making this pairing even stronger. Without developers having to lift a finger, this transparently adjusts the parallelism of Go workloads running in containers, preventing CPU throttling that can impact tail latency and improving Go’s out-of-the-box production-readiness.&lt;/p&gt;
    &lt;p&gt;Go 1.25’s new flight recorder builds on our already powerful execution tracer, enabling deep insights into the dynamic behavior of production systems. While the execution tracer generally collected too much information to be practical in long-running production services, the flight recorder is like a little time machine, allowing a service to snapshot recent events in great detail after something has gone wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;Secure software development&lt;/head&gt;
    &lt;p&gt;Go continues to strengthen its commitment to secure software development, making significant strides in its native cryptography packages and evolving its standard library for enhanced safety.&lt;/p&gt;
    &lt;p&gt;Go ships with a full suite of native cryptography packages in the standard library, which reached two major milestones over the past year. A security audit conducted by independent security firm Trail of Bits yielded excellent results, with only a single low-severity finding. Furthermore, through a collaborative effort between the Go Security Team and Geomys, these packages achieved CAVP certification, paving the way for full FIPS 140-3 certification. This is a vital development for Go users in certain regulated environments. FIPS 140 compliance, previously a source of friction due to the need for unsupported solutions, will now be seamlessly integrated, addressing concerns related to safety, developer experience, functionality, release velocity, and compliance.&lt;/p&gt;
    &lt;p&gt;The Go standard library has continued to evolve to be safe by default and safe by design. For example, the &lt;code&gt;os.Root&lt;/code&gt;
API—added in Go 1.24—enables traversal-resistant file system
access, effectively combating a class of vulnerabilities where an
attacker could manipulate programs into accessing files intended to be
inaccessible. Such vulnerabilities are notoriously challenging to address
without underlying platform and operating system support, and the new
&lt;code&gt;os.Root&lt;/code&gt; API offers a straightforward,
consistent, and portable solution.&lt;/p&gt;
    &lt;head rend="h2"&gt;Under-the-hood improvements&lt;/head&gt;
    &lt;p&gt;In addition to user-visible changes, Go has made significant improvements under the hood over the past year.&lt;/p&gt;
    &lt;p&gt;For Go 1.24, we completely redesigned the &lt;code&gt;map&lt;/code&gt;
implementation, building on the latest and greatest ideas in
hash table design. This change is completely transparent, and brings significant
improvements to &lt;code&gt;map&lt;/code&gt; performance, lower tail latency of &lt;code&gt;map&lt;/code&gt; operations, and
in some cases even significant memory wins.&lt;/p&gt;
    &lt;p&gt;Go 1.25 includes an experimental and significant advancement in Go’s garbage collector called Green Tea. Green Tea reduces garbage collection overhead in many applications by at least 10% and sometimes as much as 40%. It uses a novel algorithm designed for the capabilities and constraints of today’s hardware and opens up a new design space that we’re eagerly exploring. For example, in the forthcoming Go 1.26 release, Green Tea will achieve an additional 10% reduction in garbage collector overhead on hardware that supports AVX-512 vector instructions—something that would have been nigh impossible to take advantage of in the old algorithm. Green Tea will be enabled by default in Go 1.26; users need only upgrade their Go version to benefit.&lt;/p&gt;
    &lt;head rend="h1"&gt;Furthering the software development stack&lt;/head&gt;
    &lt;p&gt;Go is about far more than the language and standard library. It’s a software development platform, and over the past year, we’ve also made four regular releases of the gopls language server, and have formed partnerships to support emerging new frameworks for agentic applications.&lt;/p&gt;
    &lt;p&gt;Gopls provides Go support to VS Code and other LSP-powered editors and IDEs. Every release sees a litany of features and improvements to the experience of reading and writing Go code (see the v0.17.0, v0.18.0, v0.19.0, and v0.20.0 release notes for full details, or our new gopls feature documentation!). Some highlights include many new and enhanced analyzers to help developers write more idiomatic and robust Go code; refactoring support for variable extraction, variable inlining, and JSON struct tags; and an experimental built-in server for the Model Context Protocol (MCP) that exposes a subset of gopls’ functionality to AI assistants in the form of MCP tools.&lt;/p&gt;
    &lt;p&gt;With gopls v0.18.0, we began exploring automatic code modernizers. As Go evolves, every release brings new capabilities and new idioms; new and better ways to do things that Go programmers have been finding other ways to do. Go stands by its compatibility promise—the old way will continue to work in perpetuity—but nevertheless this creates a bifurcation between old idioms and new idioms. Modernizers are static analysis tools that recognize old idioms and suggest faster, more readable, more secure, more modern replacements, and do so with push-button reliability. What &lt;code&gt;gofmt&lt;/code&gt; did for
stylistic consistency, we hope modernizers can do for idiomatic
consistency. We’ve integrated modernizers as IDE suggestions, where they can
help developers not only maintain more consistent coding standards, but where we
believe they will help developers discover new features and keep up with the
state of the art. We believe modernizers can also help AI coding assistants keep
up with the state of the art and combat their proclivity to reinforce outdated
knowledge of the Go language, APIs, and idioms. The upcoming Go 1.26 release
will include a total overhaul of the long-dormant &lt;code&gt;go fix&lt;/code&gt; command to make it
apply the full suite of modernizers in bulk, a return to its pre-Go 1.0
roots.&lt;/p&gt;
    &lt;p&gt;At the end of September, in collaboration with Anthropic and the Go community, we released v1.0.0 of the official Go SDK for the Model Context Protocol (MCP). This SDK supports both MCP clients and MCP servers, and underpins the new MCP functionality in gopls. Contributing this work in open source helps empower other areas of the growing open source agentic ecosystem built around Go, such as the recently released Agent Development Kit (ADK) for Go from Google. ADK Go builds on the Go MCP SDK to provide an idiomatic framework for building modular multi-agent applications and systems. The Go MCP SDK and ADK Go demonstrate how Go’s unique strengths in concurrency, performance, and reliability differentiate Go for production AI development and we are expecting more AI workloads to be written in Go in the coming years.&lt;/p&gt;
    &lt;head rend="h1"&gt;Looking ahead&lt;/head&gt;
    &lt;p&gt;Go has an exciting year ahead of it.&lt;/p&gt;
    &lt;p&gt;We’re working on advancing developer productivity through the brand new &lt;code&gt;go fix&lt;/code&gt;
command, deeper support for AI coding assistants, and ongoing improvements to
gopls and VS Code Go. General availability of the Green Tea garbage collector,
native support for Single Instruction Multiple Data (SIMD) hardware features,
and runtime and standard library support for writing code that scales even
better to massive multicore hardware will continue to align Go with modern
hardware and improve production efficiency. We’re focusing on Go’s “production
stack” libraries and diagnostics, including a massive (and long in the making)
upgrade to &lt;code&gt;encoding/json&lt;/code&gt;, driven by Joe Tsai and people across
the Go community; leaked goroutine
profiling, contributed by
Uber’s Programming Systems team; and many
other improvements to &lt;code&gt;net/http&lt;/code&gt;, &lt;code&gt;unicode&lt;/code&gt;, and other foundational packages.
We’re working to provide well-lit paths for building with Go and AI, evolving
the language platform with care for the evolving needs of today’s developers,
and building tools and capabilities that help both human developers and AI
assistants and systems alike.&lt;/p&gt;
    &lt;p&gt;On this 16th anniversary of Go’s open source release, we’re also looking to the future of the Go open source project itself. From its humble beginnings, Go has formed a thriving contributor community. To continue to best meet the needs of our ever-expanding user base, especially in a time of upheaval in the software industry, we’re working on ways to better scale Go’s development processes—without losing sight of Go’s fundamental principles—and more deeply involve our wonderful contributor community.&lt;/p&gt;
    &lt;p&gt;Go would not be where it is today without our incredible user and contributor communities. We wish you all the best in the coming year!&lt;/p&gt;
    &lt;p&gt; Previous article: The Green Tea Garbage Collector&lt;lb/&gt; Blog Index &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45932962</guid><pubDate>Fri, 14 Nov 2025 22:33:15 +0000</pubDate></item><item><title>Designing a Language (2017)</title><link>https://cs.lmu.edu/~ray/notes/languagedesignnotes/</link><description>&lt;doc fingerprint="e720009b8a253ae8"&gt;
  &lt;main&gt;&lt;p&gt;Of course you want to design (and implement!) your own programming language! It’s fun. It’s creative. It’s empowering.&lt;/p&gt;&lt;p&gt;How do we do it? In a nutshell, the process is iterative, cycling between four phases:&lt;/p&gt;&lt;p&gt;Doing the phases over and over is important; for example, while writing the compiler, you may be like “woah this is impossible” and then realize “oh shoot this part of the language wasn’t designed right!”&lt;/p&gt;&lt;p&gt;It helps to be experienced. If you’re not, that’s okay, actually—you might get lucky!&lt;/p&gt;&lt;p&gt;But don’t mistake creativity for luck that shows up without pre-existing knowledge. The most creative people are those with a lot of knowledge and experience. So you should still study and practice!&lt;/p&gt;&lt;p&gt;Your success as a language designer will be massively aided by knowledge in three main areas:&lt;/p&gt;&lt;p&gt;See Wikipedia’s list of programming paradigms.&lt;/p&gt;&lt;p&gt;I’m working on a glossary of such terms that may be helpful to review.&lt;/p&gt;&lt;p&gt;Also check out this mini-encyclopedia of 70 languages.&lt;/p&gt;&lt;p&gt;Here are some excellent cross-language comparisons that help you to hone your understanding of how different syntaxes can express the same ideas:&lt;/p&gt;&lt;p&gt;These are really good too:&lt;/p&gt;&lt;p&gt;Remember, many people have designed languages before you. They made mistakes. They came up with brilliant ideas. Many were wildly successful. Some never made it big. Some people have brought in years of research on how people think and learn to come up with principles for language (and environment) design.&lt;/p&gt;&lt;p&gt;You should learn form their experiences.&lt;/p&gt;&lt;p&gt;Study classic papers. Read web essays. Visit online courses. Here is a small sampling of things to study and places to look for more information:&lt;/p&gt;&lt;p&gt;Think about the future:&lt;/p&gt;&lt;p&gt;And understand that traditional, mainstream programming languages, are not at all the epitome of computational expression. Languages can be much more:&lt;/p&gt;&lt;p&gt;Ready to strike out on your own? Here are some things to think about, in the form of a, you guessed it, a checklist:&lt;/p&gt;&lt;p&gt;Come up with a list of capabilities, or features. Make sure they enable programmers to express their creations by following the suggestions and principles in the Learnable Programming essay, including:&lt;/p&gt;&lt;p&gt;What kind of questions might you have here? Here are some totally random ideas:&lt;/p&gt;&lt;code&gt;public&lt;/code&gt;, &lt;code&gt;private&lt;/code&gt;, and &lt;code&gt;protected&lt;/code&gt;, or are there conventions, like in Go, where capitalized entities are implicitly exportable and lower-cased entities are private?
  &lt;code&gt;let&lt;/code&gt;-expression for super-local scopes?
  &lt;code&gt;this&lt;/code&gt; expression?
  &lt;code&gt;break&lt;/code&gt; and &lt;code&gt;continue&lt;/code&gt;? Anything like Ruby’s &lt;code&gt;retry&lt;/code&gt; and &lt;code&gt;redo&lt;/code&gt;?
  &lt;code&gt;goto&lt;/code&gt;?
  &lt;quote&gt;What did I just read?&lt;p&gt;Feeling like only about 20% of the questions above made any sense? Feeling like that vocabulary came out of nowhere? That’s fine for now. Learning about programming languages can be a never-ending lifelong journey, but you can use the questions you don’t quite understand now as a place to start some research.&lt;/p&gt;&lt;p&gt;Oh, I have a glossary you might find helpful.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;When you have a good idea of your language features, you’ll want to figure out a good way to organize them, structurally. This is known as your language’s abstract syntax. In an abstract syntax we don’t worry much about punctuation and parentheses and such microscopic details. We are interested in the overall structure. Here’s a look at abstract syntax trees in JavaScript:&lt;/p&gt;&lt;p&gt;When defining your language, you will want to specify exactly what the AST Nodes are, how they are related to each other, and what their properties are. For JavaScript, the AST Node types come from a specification called EsTree. I've summarized the main interfaces here:&lt;/p&gt;&lt;code&gt;Program sourceType:["script"|"module"] body:[Statement|ModuleDeclaration]
Statement
    Declaration
        FunctionDeclaration(Function) id:Identifier
        VariableDeclaration declarations:[VariableDeclarator] kind:("var"|"let"|"const")
        ClassDeclaration(Class) id:Identifier
    EmptyStatement
    DebuggerStatement
    ExpressionStatement expression:Expression
    BlockStatement body:[Statement]
    ReturnStatement argument:Expression?
    LabeledStatement label:Identifier body:Statement
    BreakStatement label:Identifier?
    ContinueStatement label:Identifier?
    IfStatement test:Expression consequent:Statement alternate:Statement?
    SwitchStatement discriminant:Expression cases:[SwitchCase]
    WhileStatement test:Expression body:Statement
    DoWhileStatement body:Statement test:Expression
    ForStatement init:(VariableDeclaration|Expression)? test:Expression? update:Expression? body:Statement
    ForInStatement left:(VariableDeclaration|Pattern) right:Expression body:Statement
        ForOfStatement await:boolean
    ThrowStatement argument:Expression
    TryStatement block:BlockStatement handler:CatchClause? finalizer:BlockStatement?
    WithStatement object:Expression body:Statement
Function id:Identifier? params:[Pattern] body:BlockStatement generator:bool async:bool
VariableDeclarator id:Pattern init:Expression?
SwitchCase test:Expression? consequent:[Statement]
CatchClause param:(Pattern?) body:BlockStatement
Expression
    ThisExpression
    Identifier(Pattern) name:string
    Literal value:(string|bool|number|Regexp|bigint)?
        RegExpLiteral regex:{pattern:string flags:string}
        BigIntLiteral bigint:string
    ArrayExpression elements:[(Expression|SpreadElement)?]
    ObjectExpression properties:[Property|SpreadElement]
    FunctionExpression(Function)
    ArrowFunctionExpression(Function) body:(BlockStatement|Expression) expression:bool
    UnaryExpression operator:UnaryOperator prefix:bool argument:Expression
    UpdateExpression operator:UpdateOperator argument:expression prefix:bool
    BinaryExpression operator:BinaryOperator left:Expression right:Expression
    AssignmentExpression operator:AssignmentOperator left:Pattern right:Expression
    LogicalExpression operator:LogicalOperator left:Expression right:Expression
    MemberExpression(ChainElement) object:(Expression|Super) property:Expression computed:bool
    ChainExpression expression:ChainElement 
    ConditionalExpression test:Expression consequent:Expression alternate:Expression
    CallExpression(ChainElement) callee:(Expression|Super) arguments:[(Expression|SpreadElement)]
    YieldExpression argument:Expression? delegate:bool
    TemplateLiteral quasis:[TemplateElement] expressions:[Expression]
    TaggedTemplateExpression tag:Expression quasi:TemplateLiteral
    NewExpression
    SequenceExpression expressions:[Expression]
    ClassExpression(Class)
    AwaitExpression argument:Expression
    ImportExpression source:Expression
    MetaProperty meta:Identifier property:Identifier
Class id:Identifier? superClass:Expression? body:ClassBody
ClassBody body:[MethodDefinition]
MethodDefinition key:Expression value:FunctionExpression kind:("constructor"|"method"|"get"|"set") computed:bool static:bool
SpreadElement argument:Expression
Property key:Expression value:Expression kind:("init"|"get"|"set") method:bool shorthand:bool computed:bool
    AssignmentProperty value:Pattern kind:"init" method:false
Pattern
    ObjectPattern properties:[AssignmentProperty|RestElement]
    ArrayPattern elements:[Pattern?]
    RestElement argument:Pattern
    AssignmentPattern left:Pattern right:Expression
Super
TemplateElement tail:boolean value:{cooked:string? raw:string}
ChainElement optional:boolean
enum UnaryOperator {"-"|"+"|"!"|"~"|"typeof"|"void"|"delete"}
enum UpdateOperator {"++"|"--"}
enum BinaryOperator {"=="|"!="|"==="|"!=="|"&amp;lt;"|"&amp;lt;="|"&amp;gt;"|"&amp;gt;="|"&amp;lt;&amp;lt;"|"&amp;gt;&amp;gt;"|"&amp;gt;&amp;gt;&amp;gt;"|"+"|"-"|"*"|"/"|"%"|"**"|"|"|"^"|"&amp;amp;"|"in"|"instanceof"}
enum AssignmentOperator {"="|"+="|"-="|"*="|"/="|"%="|"**="|"&amp;lt;&amp;lt;="|"&amp;gt;&amp;gt;="|"&amp;gt;&amp;gt;&amp;gt;="|"|="|"^="|"&amp;amp;="}
enum LogicalOperator {"||"|"&amp;amp;&amp;amp;"|"??"}
ModuleDeclaration
    ImportDeclaration specifiers:[ImportSpecifier|ImportDefaultSpecifier|ImportNamespaceSpecifier] source:Literal
    ExportNamedDeclaration declaration:Declaration? specifiers:[ExportSpecifier] source:Literal?
    ExportDefaultDeclaration declaration:(Declaration|Expression)
    ExportAllDeclaration source:Literal exported:(Identifier?)
ModuleSpecifier local:Identifier
    ImportSpecifier imported:Identifier
    ImportDefaultSpecifier
    ImportNamespaceSpecifier
    ExportSpecifier exported:Identifier
&lt;/code&gt;
&lt;p&gt;I’ve built an interactive application for you to explore AST generation. Please try it out!.&lt;/p&gt;&lt;quote&gt;Too much detail?&lt;p&gt;You may notice that the EsTree specification has a lot more detail than the hand-drawn ASTs in the video above. This is okay. The specification is used to build actual compilers and interpreters, while for hand-drawn ASTs we just like to give the big picture and can take some “shortcuts.”&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Now it’s time to think about what your language will really look like! Remember that design is creative and iterative, so you will want to begin, like all artists do, with sketches:&lt;/p&gt;&lt;p&gt;Do a lot of experimentation here! You will probably want to put creative effort into designing languages people like to use! What kind of syntax issues do they deal with? Dozens, actually, and we can’t cover them all. But how about a taste of just a few. We’ll peek at just a few issues that sometimes generate strong opinions.&lt;/p&gt;&lt;p&gt;You will need to adopt a scheme for showing structure. The popular approaches are: Curly-brace (JavaScript, Java, C++, C#), Terminal-end (Ruby, Ada), Nested parentheses (Lisp, Clojure, Racket), Indentation (Python), Blocks (EToys, Scratch, Snap!), Pictures (Piet), Other (Haskell, Erlang, Prolog).&lt;/p&gt;&lt;p&gt;The important idea here is that a single abstract syntax can be realized with many different concrete syntaxes. A concrete syntax specifies exactly which strings of characters make up structurally valid programs. For example, the AST:&lt;/p&gt;&lt;p&gt;represents each of the following (and more!):&lt;/p&gt;&lt;code&gt;while y - 5 == 3:
    print(x * (3 + y))
&lt;/code&gt;
&lt;code&gt;while y - 5 == 3 {
  print(x * (3 + y))
}
&lt;/code&gt;
&lt;code&gt;while y - 5 == 3 loop
  print(x * (3 + y))
end
&lt;/code&gt;
&lt;code&gt;(while (= (- y 5) 3)
    (print (* x (+ 3 y))))
&lt;/code&gt;
&lt;code&gt;y 5 - 3 == [x 3 y + * print] while&lt;/code&gt;. Do you know of, or can you find, any languages which have that kind of syntax?
&lt;p&gt;In addition to structure, your choice of keywords, operators, punctuation (or lack thereof) are part of your design. Here’s an abstract syntax:&lt;/p&gt;&lt;p&gt;Let’s try out a few things:&lt;/p&gt;&lt;code&gt;program:
    var x, y: integer
    while y - 5 == 3:
        var y: integer
        get(x)
        get(y)
        x = 2 * (3 + y)
    put(5)
&lt;/code&gt;
&lt;code&gt;int x, y;
while y - 5 = 3 {
    int y;
    STDIN -&amp;gt; x;
    STDIN -&amp;gt; y;
    x &amp;lt;- 2 * (3 + y);
}
STDOUT &amp;lt;- 5;
&lt;/code&gt;
&lt;code&gt;COMMENT THIS LOOKS LIKE OLD CODE
DECLARE INT X.
DECLARE INT Y.
WHILE DIFFERENCE OF Y AND 5 IS 3 LOOP:
    DECLARE INT Y.
    READ FROM STDIN INTO X.
    READ FROM STDIN INTO Y.
    MOVE PRODUCT OF 2 AND (SUM OF 3 AND Y) INTO X.
END LOOP.
WRITE 5 TO STDOUT.
&lt;/code&gt;
&lt;code&gt;(program
  (declare x int)
  (declare y int)
  (while (= (- y 5) 3)
    (define (y int))
    (read x y)
    (assign x (* 2 (+ 3 y)))
  )
  (write 5)
)
&lt;/code&gt;
&lt;p&gt;How to separate one construct from another is a really big issue in syntax design, believe it or not. We can identify two main classes of languages: those in which newlines are significant and those in which they are not.&lt;/p&gt;&lt;p&gt;In many languages, newlines are just like any other whitespace character (except for minor exceptions such as single-line comments and single-line string literals. Then, unless you have an S-Expression-based syntax as in LISP, Scheme, and Clojure, you’ll need semicolons to terminate (or separate) statements. This means you can (but shouldn’t) write code like:&lt;/p&gt;&lt;code&gt;#define ZERO 0
    unsigned  gcd(   unsigned   int  // Euclid's algorithm
      x,unsigned   y) {   while ( /* hello */  x&amp;gt;   ZERO
   ){unsigned temp=x;x=y   %x;y  = temp ;}return

   y ;}
&lt;/code&gt;
&lt;p&gt;Where you place your newlines matters greatly in, let’s see, Assembly languages, Python, Ruby, JavaScript, Elm, Haskell, Go, Swift, and yes, many others. The rules can get pretty technical.&lt;/p&gt;&lt;p&gt;Python scripts are defined as sequences of logical lines, delimited by the token NEWLINE. A statement may not cross logical lines, except in the case of compound statements in which each constituent simple statement ends with a NEWLINE. Logical lines are made up of one or more physical lines according to line joining rules. Lines are implicitly jointed within parentheses, brackets, or braces; lines can be explicitly joined by ending with a backslash. These rules are somewhat exclusive of comments and string literals.&lt;/p&gt;&lt;p&gt;Ruby looks at the end of each line and says “well if up to here it looks like we’ve completed a statement the we have.” This means you have to be careful where you break lines:&lt;/p&gt;&lt;code&gt;puts 5
  + 3
puts 5 +
  3
&lt;/code&gt;
&lt;p&gt;prints 5 then 8.&lt;/p&gt;&lt;p&gt;JavaScript requires most statements to be terminated by semicolons, but the compiler will put one in for you if it looks like you might have missed one. The rules by which this automatic semicolon insertion (ASI) is done have to be learned and they might be hard to remember.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;[God creating JavaScript]&lt;/p&gt;— Neckbeard Hacker (@NeckbeardHacker) August 24, 2016&lt;lb/&gt;GOD: It uses prototype-based inheritance.&lt;lb/&gt;Angel: Nice.&lt;lb/&gt;GOD: Also it secretly adds semicolons to ur code.&lt;lb/&gt;A: wat&lt;/quote&gt;&lt;p&gt;If you are going to be a serious JavaScript programmer, you need to learning the rules of ASI whether you choose to use semicolons or not.&lt;/p&gt;&lt;p&gt;Some people feel very strongly whether to use or not to use semicolons:&lt;/p&gt;&lt;p&gt;Most programming languages have functions. Seriously. But there are a lot of ways to work them into your design. Basic questions include: Must functions have exactly one argument, or zero or more arguments? Parens or no parens? Positional or keyword arguments? Argument labels? If no arguments, can we omit parentheses?&lt;/p&gt;&lt;p&gt;You can play around and see what you can come up with:&lt;/p&gt;&lt;code&gt;push(myStack, 55)&lt;/code&gt;&lt;code&gt;push myStack 55&lt;/code&gt;&lt;code&gt;[push myStack 55]&lt;/code&gt;&lt;code&gt;(push myStack 55)&lt;/code&gt;&lt;code&gt;push(on: myStack, theValue: 55)&lt;/code&gt;&lt;code&gt;push(theValue: 55, on: myStack)&lt;/code&gt;&lt;code&gt;push on:myStack theValue:55&lt;/code&gt;&lt;code&gt;push({ on: myStack, theValue: 55 })&lt;/code&gt;&lt;code&gt;push { on: myStack, theValue: 55 }&lt;/code&gt;&lt;code&gt;push({ theValue: 55, on: myStack })&lt;/code&gt;&lt;p&gt;You might want to consider an ultra-low precedence function application, like they have in Haskell and F#:&lt;/p&gt;&lt;code&gt;sum (filter even (map square a))&lt;/code&gt;&lt;code&gt;sum $ filter even $ map square $ a&lt;/code&gt;&lt;code&gt;sum &amp;lt;| filter even &amp;lt;| map square &amp;lt;| a&lt;/code&gt;&lt;code&gt;a |&amp;gt; filter even |&amp;gt; map square |&amp;gt; sum&lt;/code&gt;&lt;p&gt;The flip side of function calls is function definitions. You’re likely familiar with default parameters, and rest parameters. Python has cool mechanisms for requiring arguments to be positional or keyword, based on the definition. Examples:&lt;/p&gt;&lt;code&gt;def sqrt(x, /)&lt;/code&gt;&lt;code&gt;def line(*, x1, x2, y1, y2, width, style, color)&lt;/code&gt;&lt;code&gt;def f(a, b, /, c, d, *, e, f)&lt;/code&gt;&lt;p&gt;Syntactic sugar refers to forms in a language that make certain things easier to express, but can be considered surface translations of more basic forms.&lt;/p&gt;&lt;p&gt;This is best understood by example. There are zillions of examples out there. Here are a few. (Disclaimer: Some of these are just examples I made up and are not part of any real language.)&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Construct&lt;/cell&gt;&lt;cell role="head"&gt;Desugared Form&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;x += n&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;x = x + n&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Compound assignment&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;operator+(a, b)&lt;/code&gt; or&lt;code&gt;"+"(a, b)&lt;/code&gt; or&lt;code&gt;__add__(a, b)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Common in languages that allow overloading&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;a[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;*(a + i)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(C, C++ pointer arithmetic) And &lt;code&gt;i[a]&lt;/code&gt; works too!

&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;p -&amp;gt; x&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(*p).x&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(C, C++) Field of struct being pointed to&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;f&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;f()&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Some languages let you leave off parentheses in calls with no arguments&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;f x&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;f(x)&lt;/code&gt; or&lt;code&gt;x.f()&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Some languages let you leave off parentheses in calls with one argument&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;x op y&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;op(x, y)&lt;/code&gt; or&lt;code&gt;x.op(y)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Some languages let you leave off parentheses in calls with two arguments&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;let x=E1 in E2&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(x =&amp;gt; E2)(E1)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Let-expression (in functional languages)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;(E1 ; E2)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(() =&amp;gt; E2)(E1)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Expression sequencing (in eager functional languages)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;r = [s&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;r = []&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;List comprehension&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;x orelse y&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;if x then x else y&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(Standard ML) short-circuit disjunction&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;x andalso y&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;if x then y else x&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(Standard ML) short-circuit conjunction&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;[x, y, z]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;x :: y :: z :: nil&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Lists in Standard ML&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;&lt;code&gt;"a${x}b"&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;"a" + x + "b"&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;String interpolation&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;When the sugared form is completely gratuitous or actually makes the code less readable, you sometimes hear the term syntactic syrup or syntactic saccharin.&lt;/p&gt;&lt;p&gt;Here’s the definition from The New Hacker’s Dictionary:&lt;/p&gt;&lt;quote&gt;The opposite of syntactic sugar, a feature designed to make it harder to write bad code. Specifically, syntactic salt is a hoop the programmer must jump through just to prove that he knows what’s going on, rather than to express a program action. Some programmers consider required type declarations to be syntactic salt. A requirement to write “&lt;code&gt;end if&lt;/code&gt;”, “&lt;code&gt;end while&lt;/code&gt;”, “&lt;code&gt;end do&lt;/code&gt;”, etc. to terminate the last block controlled by a control construct (as opposed to just “&lt;code&gt;end&lt;/code&gt;”) would definitely be syntactic salt. Syntactic salt is like the real thing in that it tends to raise hackers’ blood pressures in an unhealthy way.&lt;/quote&gt;&lt;p&gt;Some people love verbose code, because explicit is better than implicit. But if you are language designer, be pragmatic: there is such a thing as code that is too verbose. What about trying to make the code like human language? Here’s an example in Hypertalk (taken from Wikipedia):&lt;/p&gt;&lt;code&gt;on mouseDown
  answer file "Please select a text file to open."
  if it is empty then exit mouseDown
  put it into filePath
  if there is a file filePath then
    open file filePath
    read from file filePath until return
    put it into cd fld "some field"
    close file filePath
    set the textStyle of character 1 to 10 of card field "some field" to bold
  end if
end mouseDown
&lt;/code&gt;
&lt;p&gt;And here’s an example from a language that some students developed, and regretted:&lt;/p&gt;&lt;code&gt;to get the truth value prime of whole number n:
    return no if n &amp;lt; 2
    for each d in 3 to n - 1 by 2:
        return no if d divides n
    end
    return yes
end
for each k in 1 to 100:
    write k if prime(k)
end
&lt;/code&gt;
&lt;p&gt;In practice this kind of verbosity is worse than it sounds. Here’s what the New Hacker’s Dictionary has to say about this:&lt;/p&gt;&lt;quote&gt;candygrammar /n./ A programming-language grammar that is mostly syntactic sugar; the term is also a play on “candygram.” COBOL, Apple’s Hypertalk language, and a lot of the so-called “4GL” database languages share this property. The usual intent of such designs is that they be as English-like as possible, on the theory that they will then be easier for unskilled people to program. This intention comes to grief on the reality that syntax isn’t what makes programming hard; it’s the mental effort and organization required to specify an algorithm precisely that costs. Thus the invariable result is that candygrammar languages are just as difficult to program in as terser ones, and far more painful for the experienced hacker.&lt;lb/&gt;[The overtones from the old Chevy Chase skit on Saturday Night Live should not be overlooked. This was a "Jaws" parody. Someone lurking outside an apartment door tries all kinds of bogus ways to get the occupant to open up, while ominous music plays in the background. The last attempt is a half-hearted "Candygram!" When the door is opened, a shark bursts in and chomps the poor occupant. There is a moral here for those attracted to candygrammars.]&lt;/quote&gt;&lt;p&gt;Some languages pride themselves on doing a whole lot with few characters:&lt;/p&gt;&lt;p&gt;An example from Ruby (do you see what this does?):&lt;/p&gt;&lt;code&gt;c = Hash.new 0
ARGF.each {|l| l.scan(/[A-Z']+/i).map {|w| c[w.downcase] += 1}}
c.keys.sort.each {|w| puts "#{w}, #{c[w]}"}
&lt;/code&gt;
&lt;p&gt;An example from APL (The 99 bottles of beer program taken from Rosetta Code):&lt;/p&gt;&lt;code&gt;bob  ←  { (⍕⍵), ' bottle', (1=⍵)↓'s of beer'}
bobw ←  {(bob ⍵) , ' on the wall'}
beer ←  { (bobw ⍵) , ', ', (bob ⍵) , '; take one down and pass it around, ', bobw ⍵-1}
↑beer¨ ⌽(1-⎕IO)+⍳99
&lt;/code&gt;
&lt;p&gt;Here’s APL again, with an expression to find all the prime numbers up to R:&lt;/p&gt;&lt;code&gt;(~R∊R∘.×R)/R←1↓⍳R
&lt;/code&gt;
&lt;p&gt;Some people love terse, concise code, because it says only what it needs and reduces the cognitive load, leaving you with less useless noisy syntax to learn. But if you are language designer, be pragmatic: there is such a thing as code that is too terse. Unless...that’s your goal....&lt;/p&gt;&lt;p&gt;Golfing languages take terseness to the next level. A golfing language is a kind of esoteric programming language (a non-practical language created to experiment with weird ideas, be hard to program in, or be humorous) that allows programs to be written in an insanely small number of characters (or bytes).&lt;/p&gt;&lt;p&gt;Here are some CJam programs:&lt;/p&gt;&lt;code&gt;"Hello, world!"&lt;/code&gt;&lt;code&gt;5{"Hello, world"oNo}*&lt;/code&gt;&lt;code&gt;0X{_2$+}A*]N*&lt;/code&gt;&lt;code&gt;l~@-@@-mh&lt;/code&gt;&lt;code&gt;1{_B&amp;lt;}{_'**N+o)}w;&lt;/code&gt;&lt;p&gt;Here are some Pyth programs (taken from the documentation):&lt;/p&gt;&lt;code&gt;"Hello, world!&lt;/code&gt;&lt;code&gt;FNrZhTN&lt;/code&gt;&lt;code&gt;FNUhTN&lt;/code&gt;&lt;code&gt;VhTN&lt;/code&gt;&lt;code&gt;K1FNr1hQ=K*KN;K&lt;/code&gt;&lt;code&gt;.!Q&lt;/code&gt;&lt;code&gt;WtQ=Q?%Q2h*Q3/Q2Q&lt;/code&gt;&lt;code&gt;A(Z1;VhhTGA(H+GH&lt;/code&gt;&lt;p&gt;Traditionally, real world language definitions come in three main flavors:&lt;/p&gt;&lt;p&gt;An official definition will have three parts:&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Syntax (Structure)&lt;/cell&gt;&lt;cell role="head"&gt;Semantics (Meaning)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Statics&lt;/cell&gt;&lt;cell&gt;Dynamics&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;What are the structural entities (e.g., declarations, expressions, statements, modules) and how do they fit together, perhaps with punctuation?&lt;/cell&gt;&lt;cell&gt;What are the non-structural rules that define a legal program (e.g., type checks, argument-parameter matching rules, visibility rules, etc.)?&lt;/cell&gt;&lt;cell&gt;What does a program do? What effects do each of the forms of a well-structured, legal program have on the run-time environment?&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Why are there three parts instead of two (i.e., just syntax and semantics)? Here’s why. While everyone might agree that the following is structurally malformed:&lt;/p&gt;&lt;code&gt;#&amp;lt;include &amp;gt; stdio.h
main() int }
    printf["Hello, world!\n");]
{
&lt;/code&gt;
&lt;p&gt;the following program looks good in terms of “structure” but it’s actually meaningless since it violates a contextual rule that says identifiers must be declared before use:&lt;/p&gt;&lt;code&gt;int main() {
    printf("%d\n", x);
}
&lt;/code&gt;
&lt;p&gt;We say the latter program has static semantic errors because they can be detected by a compiler before the program is ever run. This is in contrast to a dynamic semantic error, which can only be detected at run time.&lt;/p&gt;&lt;p&gt;Let‘s see how we would formally specify the syntax for the simple language Astro. Assume we’ve gone through the first two design phases, and we’ve sketched out a program that shows all the features:&lt;/p&gt;&lt;code&gt;// A simple program in Astro

radius = 55.2 * (-cos(2.8E-20) + 89) % 21;    // assignment statement
the_area = π * radius ** 2;                   // a built-in identifier
print hypot(2.28, 3 - radius) / the_area;     // print statement
&lt;/code&gt;
&lt;p&gt;Next, we put our ideas into words. A first pass: “Programs are structured as a sequence of one or more statements, each of which is an assignment or print statement, with expressions formed with numbers, variables, function calls, and the usual arithmetic operators, which can have parentheses when needed. Comments look like the slash-slash comments of C-like languages.”&lt;/p&gt;&lt;p&gt;Natural language isn’t super precise, so let’s try to tighten this up. Let’s get started defining programs, statements, and expressions:&lt;/p&gt;&lt;quote&gt;Program = Statement+ Statement = id "=" Exp ";" | print Exp ";" Exp = numeral | id | id "(" (Exp ("," Exp)*)? ")" | "-" Exp | Exp ("+" | "-" | "*" | "/" | "%" | "**") Exp | "(" Exp ")"&lt;/quote&gt;&lt;p&gt;An identifier is the computer science word for a name you attach to an entity (a variable, constant, function, type, parameter, or similar thing). Let’s decree that Astro identifiers begin with a letter, and can have letters, digits, and underscores (examples: &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;last_attempt&lt;/code&gt;, &lt;code&gt;p1&lt;/code&gt;, &lt;code&gt;p2&lt;/code&gt;, &lt;code&gt;overTheLimit&lt;/code&gt;, &lt;code&gt;bot8675309_jEnNy&lt;/code&gt;). We will call letters, digits, and underscores identifier characters (&lt;code&gt;idchar&lt;/code&gt;s). But let’s also decree that &lt;code&gt;print&lt;/code&gt; is not allowed to be an identifier (so we don’t confuse people)!&lt;/p&gt;&lt;p&gt;This means we have to carefully define the &lt;code&gt;print&lt;/code&gt; keyword very carefully. It’s not just the five letters p, r, i, n, and t. If it were then the program:&lt;/p&gt;&lt;quote&gt;printy;&lt;/quote&gt;&lt;p&gt;would be legal! It would be the five characters spelling print followed by a legal expression, namely the identifer $y$. We want the word &lt;code&gt;print&lt;/code&gt; to not bleed into any following characters that might be part of an expression. In other words, &lt;code&gt;print&lt;/code&gt; must not be immediately followed by an identifier character. And, we have to explicitly exclude &lt;code&gt;print&lt;/code&gt; from our category of identifiers. Both things are necessary. Let’s use the &lt;code&gt;~&lt;/code&gt; symbol in our notation to exclude things:&lt;/p&gt;&lt;quote&gt;print = "print" ~idchar idchar = letter | digit | "_" id = ~print letter idchar*&lt;/quote&gt;&lt;code&gt;print&lt;/code&gt; followed by the identifier &lt;code&gt;y&lt;/code&gt;.
&lt;p&gt;Now time for numerals. We’ll keep things in decimal only (no worries about hex or binary), and use the times-ten-to-the notation from popular programming languages:&lt;/p&gt;&lt;quote&gt;numeral = digit+ ("." digit+)? (("E" | "e") ("+" | "-")? digit+)?&lt;/quote&gt;&lt;p&gt;Looking good. But what about things like &lt;code&gt;letter&lt;/code&gt; and &lt;code&gt;digit&lt;/code&gt;? Should we define these? Nah, let’s say that in our definition schema that these things are built-in. Let’s in fact “build in” all of the following:&lt;/p&gt;&lt;code&gt;letter&lt;/code&gt;, for any Unicode letter&lt;code&gt;digit&lt;/code&gt;, for &lt;code&gt;"0".."9"&lt;/code&gt;&lt;code&gt;alnum&lt;/code&gt;, for &lt;code&gt;letter | digit&lt;/code&gt;&lt;code&gt;upper&lt;/code&gt;, for any Unicode uppercase letter&lt;code&gt;lower&lt;/code&gt;, for any Unicode lowercase letter&lt;code&gt;hexDigit&lt;/code&gt;, for &lt;code&gt;digit | "a".."f" | "A".."F"&lt;/code&gt;&lt;code&gt;any&lt;/code&gt;, for any Unicode character at all&lt;p&gt;Did you notice that some of our syntax categories (Program, Statement, Exp) were capitalized and others (id, numeral, letter, digit) were not? Why did we do this?&lt;/p&gt;&lt;p&gt;The latter things are very primitive. They can not have internal spaces. We call these tokens. Think of these as basic “words”. The former, called phrases are more complex. Think of them as sentences. They are made up of tokens that can be separated by spaces. Tokens and phrases are very different, so we should denote them differently.&lt;/p&gt;&lt;p&gt;So what are spaces—those characters that can separate tokens from each other? We’ll take them to be any Unicode space character. But we also want to separate tokens with comments. Let’s define how tokens should look in our language, and add them to the special &lt;code&gt;space&lt;/code&gt; category:&lt;/p&gt;&lt;quote&gt;space += "//" (~"\n" any)*&lt;/quote&gt;&lt;p&gt;Let’s take a deeper look into how the lexical and phrase syntaxes differ. As a specific example, this program:&lt;/p&gt;&lt;quote&gt;print( // ⿇🌿 420 );&lt;/quote&gt;&lt;p&gt;is made up of these characters:&lt;/p&gt;&lt;p&gt;SPACE SPACE LATIN SMALL LETTER P LATIN SMALL LETTER R LATIN SMALL LETTER I LATIN SMALL LETTER N LATIN SMALL LETTER T LEFT PARENTHESIS TAB SOLIDUS SOLIDUS SPACE KANGXI RADICAL HEMP HERB LINEFEED DIGIT FOUR DIGIT TWO DIGIT ZERO SPACE RIGHT PARENTHESIS SEMICOLON&lt;/p&gt;&lt;p&gt;Following the lexical syntax, skipping the spaces (and comments), we get the token stream:&lt;/p&gt;&lt;p&gt;&lt;code&gt;print&lt;/code&gt;&lt;code&gt;(&lt;/code&gt;&lt;code&gt;num(420)&lt;/code&gt;&lt;code&gt;)&lt;/code&gt;&lt;code&gt;;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Following the phrase syntax, we can uncover the underlying parse tree:&lt;/p&gt;&lt;p&gt;A very important thing to note: The frontier of the parse tree is the token stream.&lt;/p&gt;&lt;quote&gt;The parse tree ends at tokens, not characters&lt;lb/&gt;Please take the time to consider how silly it would be if the parse tree expanded all of the lexical rules down to characters. Having the parse tree stop at tokens is a good example of what we would call “breaking a complex problem down into simpler parts.”&lt;/quote&gt;&lt;p&gt;Another term for “parse tree” is concrete syntax tree (CST).&lt;/p&gt;&lt;p&gt;How are we doing so far? We are able to distinguish well-structured Astro programs from all other Unicode strings. But there are some things we haven’t dealt with yet. For one, we have some strings with multiple structural forms. For example, the phrase &lt;code&gt;9-3*7&lt;/code&gt; can be parsed in two ways:&lt;/p&gt;&lt;p&gt;Having more than one parse tree for a given input string means that our syntax description is ambiguous. It’s possible to handle this particular kind of ambiguity in the syntax. Here’s how.&lt;/p&gt;&lt;p&gt;We can create rules that force certain operators to be applied before others; that is, the precedence of operators can be enforced in our syntax definition. To do so, we define additional syntactic categories. We say:&lt;/p&gt;&lt;p&gt;So let’s revise our syntax specification:&lt;/p&gt;&lt;quote&gt;Exp = Term ( ("+" | "-") Term )* Term = Factor ( ("*" | "/" | "%") Factor )* Factor = Primary ( "**" Primary )* | "-" Primary Primary = numeral | id | id "(" (Exp ("," Exp)*)? ")" | "(" Exp ")"&lt;/quote&gt;&lt;p&gt;Great! Now there is one and only one parse tree for that previously problematic expression:&lt;/p&gt;&lt;p&gt;Note that the new syntax has forced the binary operators into a precedence hierarchy!&lt;/p&gt;&lt;code&gt;+&lt;/code&gt; and &lt;code&gt;-&lt;/code&gt; have the lowest precedence.&lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, and &lt;code&gt;/&lt;/code&gt; have the next higher precedence.&lt;code&gt;**&lt;/code&gt; has the highest precedence.&lt;p&gt;Of course, you can think of parenthesized expressions as being done before anything else, though we don’t usually think of these as operators.&lt;/p&gt;&lt;code&gt;-3**2&lt;/code&gt; be parsed? In Python exponentiation precedes negation, like &lt;code&gt;-(3**2)&lt;/code&gt;. In Elm, negation precedes exponentiation, like &lt;code&gt;(-3)**2&lt;/code&gt;. Astro follows JavaScript and simply does not allow this expression (forcing programmers to use parentheses in this case)! Show how this is done.
&lt;code&gt;-3**2&lt;/code&gt; as an expression, but it does allow &lt;code&gt;-3+2&lt;/code&gt; and &lt;code&gt;-3*2&lt;/code&gt;. Why did we care only enough to ensure negation did not mix with exponentiation, but we were fine with it mixing with addition and multiplication?
&lt;p&gt;Wait, we are not done with structuring our operators just yet. The way things stand now, the parse tree for &lt;code&gt;3-8-5&lt;/code&gt; looks pretty flat:&lt;/p&gt;&lt;p&gt;It doesn’t suggest whether we mean to compute &lt;code&gt;(3-8)-5&lt;/code&gt; (which would be -10) or &lt;code&gt;3-(8-5)&lt;/code&gt; (which would be 0). We can give a syntax that makes this clear. In our design, let’s make the additive and multiplicative operators left-associative and the exponentiation operator right-associative:&lt;/p&gt;&lt;quote&gt;Exp = Exp ("+" | "-") Term | Term Term = Term ("*" | "/" | "%") Factor | Factor Factor = Primary "**" Factor | "-" Primary | Primary&lt;/quote&gt;&lt;p&gt;How the heck does this work? Study these parse trees, and hopefully the insight will come to you! (Hint: remember the syntax is designed to force the tree to “come out” a certain way.&lt;/p&gt;&lt;p&gt;The notation we’ve been using to precisely describe our syntax is a kind of a grammar. In fact, it is very close to a specific kind of grammar called an Ohm Grammar. Ohm requires a bit more ceremony than what we’ve been using so far. We’ll just jump right in and extend our work so far to a complete and working Ohm grammar:&lt;/p&gt;&lt;code&gt;Astro {
  Program     = Statement+
  Statement   = id "=" Exp ";"                         --assignment
              | print Exp ";"                          --print
  Exp         = Exp ("+" | "-") Term                   --binary
              | Term
  Term        = Term ("*" | "/" | "%") Factor          --binary
              | Factor
  Factor      = Primary "**" Factor                    --binary
              | "-" Primary                            --negation
              | Primary
  Primary     = id "(" ListOf&amp;lt;Exp, ","&amp;gt; ")"            --call
              | numeral                                --num
              | id                                     --id
              | "(" Exp ")"                            --parens

  numeral     = digit+ ("." digit+)? (("E" | "e") ("+" | "-")? digit+)?
  print       = "print" ~idchar
  idchar      = letter | digit | "_"
  id          = ~print letter idchar*
  space      += "//" (~"\n" any)*                      --comment
}
&lt;/code&gt;
&lt;p&gt;When you are designing your language, you will build up your grammar iteratively, from increasingly more complex examples, and test the grammar as you go. Tools will help you here! If you are using Ohm, and you should, take advantage of the use the Ohm Editor. This is an amazing tool for experimenting with programming languages.&lt;/p&gt;&lt;p&gt;In the upper left panel, design your grammar. You can load/save from your browser’s local storage, and even publish gists to GitHub. In the lower left panel, enter test cases: both tests you want to succeed (thumbs up) and those you want to fail (thumbs down). The right panel is an interactive concrete syntax tree for the currently selected test case.&lt;/p&gt;&lt;p&gt;This tool will save you a lot of time.&lt;/p&gt;&lt;p&gt;It is an essential component of your language design toolbox.&lt;/p&gt;&lt;quote&gt;How essential is it?&lt;p&gt;Unless your language is trivial, tools like the Ohm Editor are very important! Design is an iterative process, and creativity is enabled and enhanced with immediate feedback. So you should design with tools that allow you to experiment and test your ideas.&lt;/p&gt;&lt;p&gt;That said, it is true that in practice, many production-level compilers do not use Ohm or related tools like ANTLR, Bison, etc.—they do everything by hand. But developers that go this route will write their grammar tests concurrently with their design.&lt;/p&gt;&lt;/quote&gt;&lt;quote&gt;Let’s do a code-along with the Ohm Editor for developing the Astro grammar. During the code-along, note how examples are done first, and note how we will evolve from the basics to more complex features, bringing in notions such as a precedence and associativity where needed.&lt;p&gt;During the code-along, bits of Ohm will be introduced as needed. In a subsequence course unit, we will cover Ohm in detail.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Question: Does the grammar we defined above for Astro capture the following (desirable) rule:&lt;/p&gt;&lt;p&gt;“You can only use an identifier if it has been previously assigned to.”&lt;/p&gt;&lt;p&gt;Answer: It does not.&lt;/p&gt;&lt;code&gt;print x;&lt;/code&gt; a legal program according to the grammar?
&lt;p&gt;Enforcing this rule requires knowledge of context. That is, the syntactic rule for producing expressions such as calls and arithmetic operations would need to somehow know which identifiers appeared on the left hand side of some previous assignment statement. This turns out to be so hard that even designers of real programming languages omit enforcement of contextual rules from the grammar! In fact, while the official grammar for Java will not derive this program:&lt;/p&gt;&lt;code&gt;class A {2 / == {{;
&lt;/code&gt;
&lt;p&gt;and report a syntax error, a Java compiler will say that this program:&lt;/p&gt;&lt;code&gt;class A {int x = y;}
&lt;/code&gt;
&lt;p&gt;is structurally well formed according to the official syntax of the Java language! The compilation unit consists of a type declaration that is a class declaration whose body consists of a field declaration with a type, a name, and an initializing expression which is an identifier. But we know this program is not legal, since the identifier y has not been declared. It’s not only Java that has grammars overspecifying things: pretty much every programming language uses a grammar to define structural rules only, and specifies contextual rules in prose, or in a separate semantic definition.&lt;/p&gt;&lt;p&gt;For Astro, we will “define” the following contextual rules:&lt;/p&gt;&lt;code&gt;π&lt;/code&gt;, a number&lt;code&gt;sqrt&lt;/code&gt;, a function of exactly one argument&lt;code&gt;sin&lt;/code&gt;, a function of exactly one argument&lt;code&gt;cos&lt;/code&gt;, a function of exactly one argument&lt;code&gt;hypot&lt;/code&gt;, a function of exactly two arguments&lt;p&gt;For more complex languages, the statics definition (contextual rules) can be quite large. Here are some things that might appear:&lt;/p&gt;&lt;code&gt;break&lt;/code&gt; and &lt;code&gt;continue&lt;/code&gt; statements may only appear in a loop. &lt;code&gt;return&lt;/code&gt; statements may only appear in a function it’s possible to encode these restrictions in the grammar, but it would be ugly).
  &lt;p&gt;The dynamics for most programming languages are given in prose. If you language is simple enough, a formal semantic definition is possible. For the sample languages in this course, Astro and Bella are given both informal and formal semantic definitions. We’ll not be studying formal semantics at this time, but feel free to study the definitions on your own.&lt;/p&gt;&lt;p&gt;During your language design, you will want to whip up a simple interpreter to at the very least make sure your design is reasonable. You may wish to developer your interpreter in parallel with your language design.&lt;/p&gt;&lt;p&gt;Ohm was designed for prototyping programming languages, so it is a natural choice. The Ohm Editor, as we just saw, helps you design the syntax. To write an actual interpreter, we’ll have to go much deeper into Ohm. We’ll be doing this in our next unit of study in this course, which is, indeed, a deep study of Ohm.&lt;/p&gt;&lt;p&gt;Many well-known programming languages have published, formal definitions. You can find them by searching the web.&lt;/p&gt;&lt;p&gt;For this class, we will be studying five little languages crafted especially to help you in your stufy of language design and implementation. We will be studying them in order, building upon previous languages and learning new things as we progress. This will allow us to introduce the huge topic of language processing in a practical setting, writing real compilers for real languages. The languages are Astro, Bella, Carlos, Dax, and Ekko.&lt;/p&gt;&lt;p&gt;We all begin as a white belt in every new endeavor. We will start, then, with a very simple, almost trivial, language. All it has are numbers, arithmetic operators, variables, and a few pre-defined constants and functions. Here’s an example program:&lt;/p&gt;&lt;quote&gt;// A simple program in Astro rAd1uS = 55.2 * (-cos(2.8E-20) + 89) % 21; the_area = π * rAd1uS ** 2; print(hypot(2.28, 3 - rAd1uS) / the_area); // woohoo 👻&lt;/quote&gt;&lt;p&gt;There are only two kinds of statements: assignments and print statements. Expressions include numbers, variables, function calls, arithmetic expressions with &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;%&lt;/code&gt;, and &lt;code&gt;**&lt;/code&gt;, and can be parenthesized. We will cover the official definition of the language, and use the language to motivate a formal study of syntax.&lt;/p&gt;&lt;p&gt;When studying this language, we’ll learn about the separation of context-free syntax from contextual rules. Contextual rules include such things as: having to match the number of arguments in a call with the number of defined parameters, rudimentary type checking, and not allowing assignments to read-only variables.&lt;/p&gt;&lt;p&gt;As Astro will be our first language, we will use it as a case study to learn the amazing Ohm Language Library to build an interpreter. The details of how the interpreter is constructed are covered in the course notes on Ohm.&lt;/p&gt;&lt;p&gt;Our second language has a few things Astro does not: a richer set of operators, variable declarations, and user-defined functions. The contextual rules for Bella are much richer than that of Astro, since we now have actual declarations, and scope! Here’s an example program:&lt;/p&gt;&lt;quote&gt;let dozen = 12; print dozen % 3 ** 1; function gcd(x, y) = y == 0 ? x : gcd(y, x % y); while dozen &amp;gt;= 3 || (gcd(1, 10) != 5) { dozen = dozen - 2.75E+19 ** 1 ** 3; }&lt;/quote&gt;&lt;p&gt;We will first look at the official specification, introducing all sorts of interesting concepts. Then we’ll study a real, actual Bella compiler. Here we learn about designing and architecting a compiler, building the components (analyzer, optimizer, and generator), and getting 100% test coverage. The compiler source code is on GitHub.&lt;/p&gt;&lt;p&gt;In our third language, we encounter arrays, structs, and optionals: our first language that is basically useful. If you are taking the compiler course for which these notes were written, Carlos is a good example of the minimal language complexity you will need for your term project.&lt;/p&gt;&lt;quote&gt;const languageName = "Carlos"; function greeting() { return random(["Welcome", "こんにちは", "Bienvenido"]); } print("👋👋👋"); repeat 5 { print(greeting() + " " + languageName); }&lt;/quote&gt;&lt;p&gt;We’ll be visiting the language’s official specification and a compiler on GitHub. The compiler (of course!) uses the Ohm Language Library.&lt;/p&gt;&lt;p&gt;There’s no separate page of notes describing the compiler. After studying the Astro and Bella compilers, you’ll be able to find your way around the code on GitHub (there’s documentation). And don’t worry, it’s development and usage will be covered in class, and the teaching staff can help you with any questions you might have.&lt;/p&gt;&lt;p&gt;Language number four is a functional language, that is, a language with no assignments! The only bindings of names to entities happens when passing arguments to parameters, though there is that famous &lt;code&gt;let&lt;/code&gt; declaration which nicely sugars a function call: it’s nicer to say &lt;code&gt;let x = 5 in x * y end&lt;/code&gt; than &lt;code&gt;{x =&amp;gt; x * y}(5)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Here’s a sample program to get the feel for the language:&lt;/p&gt;&lt;quote&gt;let gcd = {x =&amp;gt; {y ==&amp;gt; y == 0 ? x : gcd y (x % y)}}; z = 5 in [1, 3, z] |&amp;gt; filter {x =&amp;gt; x &amp;gt; 2} |&amp;gt; map {x =&amp;gt; x ** 2} |&amp;gt; print then "hello" |&amp;gt; substring 2 5 |&amp;gt; print then print (gcd 33 99) // This is fine, you don't HAVE to use |&amp;gt; end&lt;/quote&gt;&lt;p&gt;If you have not yet seen languages with the awesome &lt;code&gt;|&amp;gt;&lt;/code&gt; operator, here’s your chance to be wowed.&lt;/p&gt;&lt;p&gt;We will discuss the language design and compiler later in the course.&lt;/p&gt;&lt;p&gt;Our fifth language, Ekko (starting with E like Erlang and Elixir, which greatly influence it), is a kind of experimental language that deals quite a lot with time.&lt;/p&gt;&lt;p&gt;Ekko mixes styles of asynchronous programming from JavaScript and the distributed process-orientation of Erlang and Elixir: Ekko’s &lt;code&gt;future&lt;/code&gt; objects are based on JS promises, and its processes communicate via messages as in Erlang. There’s also quite a bit more temporal goodness, including timeout calls, value histories with time travel (influenced by older versions of Elm), and even explicit parallelism.&lt;/p&gt;&lt;p&gt;Students in previous iterations of the course have designed and implemented their own languages. Here’s a sampling of language over the past decade or so. (Please note that there is a very wide variety of quality in these examples. They are presented here without any evaluative commentary as to whether they are suitable building blocks for one’s own project.)&lt;/p&gt;&lt;p&gt;Here are some questions useful for your spaced repetition learning. Many of the answers are not found on this page. Some will have popped up in lecture. Others will require you to do your own research.&lt;/p&gt;&lt;p&gt;We’ve covered:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45935342</guid><pubDate>Sat, 15 Nov 2025 05:44:43 +0000</pubDate></item><item><title>TCP, the workhorse of the internet</title><link>https://cefboud.com/posts/tcp-deep-dive-internals/</link><description>&lt;doc fingerprint="a5b8ad1a58218e83"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Internet is Cool. Thank you, TCP&lt;/head&gt;
    &lt;p&gt;An exploration of TCP, the workhorse of the internet. This deep dive includes detailed examples and a step-by-step walkthrough.&lt;/p&gt;
    &lt;p&gt;The internet is incredible. It’s nearly impossible to keep people away from. But it can also be unreliable: packets drop, links congest, bits mangle, and data corrupts. Oh, it’s dangerous out there! (I’m writing this in Kramer’s tone)&lt;/p&gt;
    &lt;p&gt;So how is it possible that our apps just work? If you’ve networked your app before, you know the drill: &lt;code&gt;socket()&lt;/code&gt;/&lt;code&gt;bind()&lt;/code&gt; here, &lt;code&gt;accept()&lt;/code&gt; there, maybe a &lt;code&gt;connect()&lt;/code&gt; over there, and it just works. Reliable, orderly, uncorrupted data flows to and fro.&lt;/p&gt;
    &lt;p&gt;Websites (HTTP), email (SMTP) or remote access (SSH) are all built on top of TCP and just work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why TCP&lt;/head&gt;
    &lt;p&gt;Why do we need TCP? Why can’t we just use the layer below, IP?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember, the network stack goes: Physical –&amp;gt; Data Link (Ethernet/Wi-Fi, etc) –&amp;gt; Network (IP) –&amp;gt; Transport (TCP/UDP).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;IP (Layer 3) operates at the host level, while the transport layer (TCP/UDP) works at the application level using ports. IP can deliver packets to the correct host via its IP address, but once the data reaches the machine, it still needs to be handed off to the correct process. Each process “binds” to a port: its address within the machine. A common analogy is: the IP address is the building, and the port is the apartment. Processes or apps live in those apartments.&lt;/p&gt;
    &lt;p&gt;Another reason we need TCP is that if a router (a piece of infra your average user does not control) drops packets or becomes overloaded, TCP at the edges (on the users’ machines) can recover without requiring routers to participate. The routers stay simple, the reliability happens at the endpoints.&lt;/p&gt;
    &lt;p&gt;Packets get lost, corrupted, duplicated, and reordered. That’s just how the internet works. TCP shields developers from these issues. It handles retransmission, checksums, and a gazillion other reliability mechanisms. If every developer had to implement those themselves, they’d never have time to properly align their flexboxes, a truly horrendous alternate universe.&lt;/p&gt;
    &lt;p&gt;Jokes aside, the guarantee that data sent and received over a socket isn’t corrupted, duplicated, or out of order, despite the underlying network being unreliable, is exactly why TCP is awesome.&lt;/p&gt;
    &lt;head rend="h2"&gt;Flow and Congestion Control&lt;/head&gt;
    &lt;p&gt;When you step back and think about network communication, here’s what we’re really trying to do: machine A sends data to machine B. Machine B has a finite amount of space and must store the incoming data somewhere before passing it to the application, which might be asleep or busy. This temporary storage takes the name of a receive buffer and is managed by the kernel:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;sysctl net.ipv4.tcp_rmem&lt;/code&gt; =&amp;gt; &lt;code&gt;net.ipv4.tcp_rmem = 4096 131072 6291456&lt;/code&gt;, a min of 4k, default of 128k and max of 8M.&lt;/p&gt;
    &lt;p&gt;The problem is that space is finite. If you’re transferring a large file (hundreds of MBs or even GBs), you could easily overwhelm the destination. The receiver therefore needs a way to tell the sender how much more data it can handle. This mechanism is called flow control, and TCP segments include a field called the window, which specifies how much data the receiver is currently willing to accept.&lt;/p&gt;
    &lt;p&gt;Another issue is overwhelming the network itself, even if the receiving machine has plenty of buffer space. You’re only as strong as your weakest link: some links carry gigabits, others only megabits. If you don’t tune for the slowest link, congestion is inevitable.&lt;/p&gt;
    &lt;p&gt;Fun fact: in 1986, the Internet’s bandwidth dropped from a few dozen KB/s to as low as 40 bps (yes, bits per second! yes, those numbers are wild!), in what became known as congestion collapse. When packets were lost and systems retried sending them, they made congestion even worse: a doom loop. To fix this, TCP incorporated ‘play nice’ and ‘back off’ behaviors known as congestion control, which help prevent the Internet from clogging itself to death.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some Code: A Plain TCP Server&lt;/head&gt;
    &lt;p&gt;With all low-level things like TCP, C examples are the way to go. Just show it like it is.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;arpa/inet.h&amp;gt; #include &amp;lt;signal.h&amp;gt; int sockfd = -1, clientfd = -1; void handle_sigint(int sig) { printf("\nCtrl+C caught, shutting down...\n"); if (clientfd != -1) close(clientfd); if (sockfd != -1) close(sockfd); exit(0); } int main() { signal(SIGINT, handle_sigint); sockfd = socket(AF_INET, SOCK_STREAM, 0); int opt = 1; // SO_REUSEADDR to force bind to the port even if an older socket is still terminating (TIME_WAIT) setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;amp;opt, sizeof(opt)); struct sockaddr_in addr = { .sin_family = AF_INET, .sin_port = htons(8080), .sin_addr.s_addr = INADDR_ANY }; bind(sockfd, (struct sockaddr*)&amp;amp;addr, sizeof(addr)); listen(sockfd, 5); printf("Listening on 8080...\n"); clientfd = accept(sockfd, NULL, NULL); char buf[1024], out[2048]; int n; while ((n = recv(clientfd, buf, sizeof(buf) - 1, 0)) &amp;gt; 0) { buf[n] = '\0'; int m = snprintf(out, sizeof(out), "you sent: %s", buf); printf("response %s %d\n", out, m); send(clientfd, out, m, 0); } close(clientfd); close(sockfd); } &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;This create a TCP server that echoes what the client sends prefixed with ‘You sent:’.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;# compile and run server gcc -o server server.c &amp;amp;&amp;amp; ./server # connect client telnet 127.0.0.1 8080 # hi # you sent: hi &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;&lt;code&gt;127.0.0.1&lt;/code&gt; (localhost) could be replace with a remote IP and it should work all the same.&lt;/p&gt;
    &lt;p&gt;We used the following primitives/functions follow the Berkley Socket way of doing things (released with BDS 4.2):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SOCKET&lt;/code&gt;: create an endpoint (structure in the kernel).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;BIND&lt;/code&gt;: associate to a port.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LISTEN&lt;/code&gt;: get ready to accept connection and a specify queue size of pending connection (beyond that size, drop!)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ACCEPT&lt;/code&gt;: accept an incoming connection (TCP Server)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CONNECT&lt;/code&gt;: attempt connection (TCP client)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SEND&lt;/code&gt;: send data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;RECEIVE&lt;/code&gt;: receive data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CLOSE&lt;/code&gt;: release the connection&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the example above, we’re using client/server dynamics in a request/response pattern. But I can add the following after &lt;code&gt;send&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;send(clientfd, out, m, 0); sleep(5); const char *msg = "not a response, just doing my thing\n"; send(clientfd, msg, strlen(msg), 0); &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Compile, run, and telnet:&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;client here you sent: client here client again not a response, just doing my thing you sent: client again &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;I typed in the telnet terminal: &lt;code&gt;client here&lt;/code&gt;, then &lt;code&gt;client again&lt;/code&gt;. I only got &lt;code&gt;you sent: client here&lt;/code&gt;, then the server was sleeping. My second line, &lt;code&gt;client again&lt;/code&gt;, was patiently waiting in the receive buffer. The server sent &lt;code&gt;not a response, just doing my thing&lt;/code&gt;, then picked up my second TCP packet and replied with &lt;code&gt;you sent: client again&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This is very much a duplex bidirectional link. Each side sends what it wishes, it just happens that at the beginning, one listens and the other connects. The dynamics afterwards don’t have to follow a request/response pattern.&lt;/p&gt;
    &lt;head rend="h2"&gt;Catfishing Curl: A Dead Simple HTTP Server&lt;/head&gt;
    &lt;p&gt;Let’s create a very simple HTTP/1.1 server (later versions are trickier).&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt; // same as before printf("Listening on 8080...\n"); int i = 1; while (1) { clientfd = accept(sockfd, NULL, NULL); char buf[1024], out[2048]; int n; while ((n = recv(clientfd, buf, sizeof(buf) - 1, 0)) &amp;gt; 0) { buf[n] = '\0'; int body_len = snprintf(out, sizeof(out), "[%d] Yo, I am a legit web server\n", i++); char header[256]; int header_len = snprintf( header, sizeof(header), "HTTP/1.1 200 OK\r\n" "Content-Type: text/plain\r\n" "Content-Length: %d\r\n" "Connection: close\r\n" "\r\n", body_len ); printf("header: %s\n", header); printf("out: %s\n", out); send(clientfd, header, header_len, 0); send(clientfd, out, body_len, 0); break; // one request per connection } close(clientfd); } &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;~ curl localhost:8080 [1] Yo, I am a legit web server ~ curl localhost:8080 [2] Yo, I am a legit web server &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;We’re using &lt;code&gt;i&lt;/code&gt; to keep count of requests. We’re establishing a TCP connection and returning the HTTP headers expected by the HTTP client (the TCP peer, really). A real HTTP server would return proper HTML, CSS, and JS, and handle a whole lot of other options and headers. But underneath, it’s simply a process making use of our reliable, dependable TCP.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Actual Bytes&lt;/head&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt; 0 &amp;lt;----- 32 bits ------&amp;gt; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Header|Rese-| Flags | Window Size | | Len |rved | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options (if any) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data (Payload) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Each TCP segment has the header above. And each TCP segment is contained within a IP packet. We have a source and destination ports. Each 16 bits, and that’s where the 64k port limit comes from!&lt;/p&gt;
    &lt;p&gt;Each transport-layer connection is &lt;code&gt;5-tuple (TCP/UDP, src IP, src port, dst IP, dst port)&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sequence and Acknowledgment Numbers&lt;/head&gt;
    &lt;p&gt;TCP reliability depends on two key fields: the Sequence number, indicating which bytes a segment carries, and the Acknowledgment number, indicating which bytes have been received. Sequence numbers let the receiver interpret data order, detect and reorder out-of-order segments, and identify losses. TCP uses cumulative acknowledgments—an ACK of 100 means bytes 0-99 were received. If bytes 100-120 are lost but later bytes arrive, the ACK remains 100 until the missing data is received.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;1. A --&amp;gt; B: Send [Seq=0-99] 2. B --&amp;gt; A: Send [Seq=0-49] 3. B --&amp;gt; A: Receives A's [0-99] --&amp;gt; sends ACK=100 4. A --&amp;gt; B: Receives B's [0-49] --&amp;gt; sends ACK=50 5. A --&amp;gt; B: Send [Seq=100-199] --- lost --- 6. B --&amp;gt; A: Send [Seq=50-99] --- lost --- 7. A --&amp;gt; B: Send [Seq=200-299] B receives --&amp;gt; notices gap (100-199 missing) --&amp;gt; sends ACK=100 8. B --&amp;gt; A: Send [Seq=100-149] A receives --&amp;gt; notices gap (50-99 missing) --&amp;gt; sends ACK=50 9. A --&amp;gt; B: Send [Seq=300-399] B still missing 100-199 --&amp;gt; sends ACK=100 10. B --&amp;gt; A: Send [Seq=150-199] A still missing 50-99 --&amp;gt; sends ACK=50 11. A --&amp;gt; B: Retransmit [Seq=100-199] B receives --&amp;gt; now has 0-399 --&amp;gt; sends ACK=400 12. B --&amp;gt; A: Retransmit [Seq=50-99] A receives --&amp;gt; now has 0-199 --&amp;gt; sends ACK=200 &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Header Length shows how many 4-byte words are in the header, needed because the Options field is variable length, and thus so is the header.&lt;/p&gt;
    &lt;head rend="h3"&gt;TCP Flags&lt;/head&gt;
    &lt;p&gt;Next are 8 flags (1 bit each). A few important ones:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;SYN&lt;/code&gt;: used to establish a connection. &lt;code&gt;ACK&lt;/code&gt;: indicates the Acknowledgment number is valid.&lt;/p&gt;
    &lt;p&gt;These two flags are central to connection setup. Why establish a connection? To detect out-of-order or duplicate segments you must track what has been sent and received i.e., maintain a state or a connection.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;SYN&lt;/code&gt; and &lt;code&gt;ACK&lt;/code&gt; participate in the famous 3-way handshake:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A –&amp;gt; B: &lt;code&gt;SYN&lt;/code&gt;(I want to connect)&lt;/item&gt;
      &lt;item&gt;B –&amp;gt; A: &lt;code&gt;SYN&lt;/code&gt;+&lt;code&gt;ACK&lt;/code&gt;(I got your SYN, I want to connect too!)&lt;/item&gt;
      &lt;item&gt;A –&amp;gt; B: &lt;code&gt;ACK&lt;/code&gt;(got it, connection established!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;FIN&lt;/code&gt; flag signals teardown and also uses a handshake:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;X –&amp;gt; Y: &lt;code&gt;FIN&lt;/code&gt;(I want to disconnect)&lt;/item&gt;
      &lt;item&gt;Y –&amp;gt; X: &lt;code&gt;ACK&lt;/code&gt;(got your FIN, whatever!)&lt;/item&gt;
      &lt;item&gt;Y –&amp;gt; X: &lt;code&gt;FIN&lt;/code&gt;(I want to disconnect too - sometimes sent with the previous ACK)&lt;/item&gt;
      &lt;item&gt;X –&amp;gt; Y: &lt;code&gt;ACK&lt;/code&gt;(got it!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is normally a 4-way (sometimes 3-way) goodbye handshake.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;RST&lt;/code&gt; is the reset flag. It indicates an error or forced shutdown — drop the connection immediately. An OS sends &lt;code&gt;RST&lt;/code&gt; if no process is listening or if the listening process crashed. There’s also a known TCP reset attack where intermediaries inject &lt;code&gt;RST&lt;/code&gt; to terminate connections (used by some firewalls).&lt;/p&gt;
    &lt;head rend="h3"&gt;Window&lt;/head&gt;
    &lt;p&gt;We talked about this field in flow control. As mentionned above, this indicates how many bytes the receiver is willing to receive after the acknowledged number.&lt;/p&gt;
    &lt;p&gt;With the example above, running &lt;code&gt;ss&lt;/code&gt; (Socket Statistics) provides info about the TCP connection.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;ss -tlpmi // State Recv-Q Send-Q Local Address:Port Peer Address:Port Process // LISTEN 0 5 0.0.0.0:http-alt 0.0.0.0:* users:(("server",pid=1113,fd=3)) // skmem:(r0,rb131072,t0,tb16384,f0,w0,o0,bl0,d0) cubic cwnd:10 &lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;&lt;code&gt;rb131072&lt;/code&gt; (128KB) is the receive buffer size, while &lt;code&gt;tb16384&lt;/code&gt; (16KB) is the transmit buffer size, where data waits before being sent over the network. &lt;code&gt;Send-Q&lt;/code&gt; indicates bytes not yet acknowledged by the remote host, and &lt;code&gt;Recv-Q&lt;/code&gt; shows bytes received but not yet read by the application (e.g., data waiting in from the second line in telnet session above, while the server was sleeping).&lt;/p&gt;
    &lt;head rend="h3"&gt;Checksum&lt;/head&gt;
    &lt;p&gt;Checksum is used for reliability. All 16-bit words in the TCP segment are added together, and the result is compared to the checksum. If they don’t match, it means some bits were likely corrupted, and retransmission is needed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It always amazes me how all this works. The network, the internet. Reliably and continuously. Just a few decades ago, sending a few KB was quite the feat. And today, streaming 4k is banal. God bless all those hardworking people that made and make it all possible!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45935503</guid><pubDate>Sat, 15 Nov 2025 06:37:50 +0000</pubDate></item><item><title>Messing with scraper bots</title><link>https://herman.bearblog.dev/messing-with-bots/</link><description>&lt;doc fingerprint="3750b05e7a642fea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Messing with bots&lt;/head&gt;
    &lt;p&gt;As outlined in my previous two posts: scrapers are, inadvertently, DDoSing public websites. I've received a number of emails from people running small web services and blogs seeking advice on how to protect themselves.&lt;/p&gt;
    &lt;p&gt;This post isn't about that. This post is about fighting back.&lt;/p&gt;
    &lt;p&gt;When I published my last post, there was an interesting write-up doing the rounds about a guy who set up a Markov chain babbler to feed the scrapers endless streams of generated data. The idea here is that these crawlers are voracious, and if given a constant supply of junk data, they will continue consuming it forever, while (hopefully) not abusing your actual web server.&lt;/p&gt;
    &lt;p&gt;This is a pretty neat idea, so I dove down the rabbit hole and learnt about Markov chains, and even picked up Rust in the process. I ended up building my own babbler that could be trained on any text data, and would generate realistic looking content based on that data.&lt;/p&gt;
    &lt;p&gt;Now, the AI scrapers are actually not the worst of the bots. The real enemy, at least to me, are the bots that scrape with malicious intent. I get hundreds of thousands of requests for things like &lt;code&gt;.env&lt;/code&gt;, &lt;code&gt;.aws&lt;/code&gt;, and all the different &lt;code&gt;.php&lt;/code&gt; paths that could potentially signal a misconfigured Wordpress instance.&lt;/p&gt;
    &lt;p&gt;These people are the real baddies.&lt;/p&gt;
    &lt;p&gt;Generally I just block these requests with a &lt;code&gt;403&lt;/code&gt; response. But since they want &lt;code&gt;.php&lt;/code&gt; files, why don't I give them what they want?&lt;/p&gt;
    &lt;p&gt;I trained my Markov chain on a few hundred &lt;code&gt;.php&lt;/code&gt; files, and set it to generate. The responses certainly look like php at a glance, but on closer inspection they're obviously fake. I set it up to run on an isolated project of mine, while incrementally increasing the size of the generated php files from 2kb to 10mb just to test the waters.&lt;/p&gt;
    &lt;p&gt;Here's a sample 1kb output:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?php wp_list_bookmarks () directly, use the Settings API. Use this method directly. Instead, use `unzip_file() {
return substr($ delete, then click &amp;amp;#8220; %3 $ s object. ' ), ' $ image
*
*
*
* matches all IMG elements directly inside a settings error to the given context.
* @return array Updated sidebars widgets.
* @param string $ name = "rules" id = "wp-signup-generic-error" &amp;gt; ' . $errmsg_generic . ' &amp;lt;/p&amp;gt; ';
	}
	/**
	 * Fires at the end of the new user account registration form.
	 *
	 * @since 3.0.0
	 *
	 * @param WP_Error $errors A WP_Error object containing ' user_name ' or ' user_email ' errors.
	 */
	do_action( ' signup_extra_fields ', $errors );
}

/**
 * Validates user sign-up name and email.
 *
 * @since MU (3.0.0)
 *
 * @return array Contains username, email, and error messages.
 *               See wpmu_validate_user_signup() for details.
 */
function validate_user_form() {
	return wpmu_validate_user_signup( $_POST[' user_name '], $_POST[' user_email '] );
}

/**
 * Shows a form for returning users to sign up for another site.
 *
 * @since MU (3.0.0)
 *
 * @param string          $blogname   The new site name
 * @param string          $blog_title The new site title.
 * @param WP_Error|string $errors     A WP_Error object containing existing errors. Defaults to empty string.
 */
function signup_another_blog( $blogname = ' ', $blog_title = ' ', $errors = ' ' ) {
	$current_user = wp_get_current_user();

	if ( ! is_wp_error( $errors ) ) {
		$errors = new WP_Error();
	}

	$signup_defaults = array(
		' blogname '   =&amp;gt; $blogname,
		' blog_title ' =&amp;gt; $blog_title,
		' errors '     =&amp;gt; $errors,
	);
}
&lt;/code&gt;
    &lt;p&gt;I had two goals here. The first was to waste as much of the bot's time and resources as possible, so the larger the file I could serve, the better. The second goal was to make it realistic enough that the actual human behind the scrape would take some time away from kicking puppies (or whatever they do for fun) to try figure out if there was an exploit to be had.&lt;/p&gt;
    &lt;p&gt;Unfortunately, an arms race of this kind is a battle of efficiency. If someone can scrape more efficiently than I can serve, then I lose. And while serving a 4kb bogus php file from the babbler was pretty efficient, as soon as I started serving 1mb files from my VPS the responses started hitting the hundreds of milliseconds and my server struggled under even moderate loads.&lt;/p&gt;
    &lt;p&gt;This led to another idea: What is the most efficient way to serve data? It's as a static site (or something similar).&lt;/p&gt;
    &lt;p&gt;So down another rabbit hole I went, writing an efficient garbage server. I started by loading the full text of the classic Frankenstein novel into an array in RAM where each paragraph is a node. Then on each request it selects a random index and the subsequent 4 paragraphs to display.&lt;/p&gt;
    &lt;p&gt;Each post would then have a link to 5 other "posts" at the bottom that all technically call the same endpoint, so I don't need an index of links. These 5 posts, when followed, quickly saturate most crawlers, since breadth-first crawling explodes quickly, in this case by a factor of 5.&lt;/p&gt;
    &lt;p&gt;You can see it in action here: https://herm.app/babbler/&lt;/p&gt;
    &lt;p&gt;This is very efficient, and can serve endless posts of spooky content. The reason for choosing this specific novel is fourfold:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I was working on this on Halloween.&lt;/item&gt;
      &lt;item&gt;I hope it will make future LLMs sound slightly old-school and spoooooky.&lt;/item&gt;
      &lt;item&gt;It's in the public domain, so no copyright issues.&lt;/item&gt;
      &lt;item&gt;I find there are many parallels to be drawn between Dr Frankenstein's monster and AI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I made sure to add &lt;code&gt;noindex,nofollow&lt;/code&gt; attributes to all these pages, as well as in the links, since I only want to catch bots that break the rules. I've also added a counter at the bottom of each page that counts the number of requests served. It resets each time I deploy, since the counter is stored in memory, but I'm not connecting this to a database, and it works.&lt;/p&gt;
    &lt;p&gt;With this running, I did the same for php files, creating a static server that would serve a different (real) &lt;code&gt;.php&lt;/code&gt; file from memory on request. You can see this running here: https://herm.app/babbler.php (or any path with &lt;code&gt;.php&lt;/code&gt; in it).&lt;/p&gt;
    &lt;p&gt;There's a counter at the bottom of each of these pages as well.&lt;/p&gt;
    &lt;p&gt;As Maury said: "Garbage for the garbage king!"&lt;/p&gt;
    &lt;p&gt;Now with the fun out of the way, a word of caution. I don't have this running on any project I actually care about; https://herm.app is just a playground of mine where I experiment with small ideas. I originally intended to run this on a bunch of my actual projects, but while building this, reading threads, and learning about how scraper bots operate, I came to the conclusion that running this can be risky for your website. The main risk is that despite correctly using &lt;code&gt;robots.txt&lt;/code&gt;, &lt;code&gt;nofollow&lt;/code&gt;, and &lt;code&gt;noindex&lt;/code&gt; rules, there's still a chance that Googlebot or other search engines scrapers will scrape the wrong endpoint and determine you're spamming.&lt;/p&gt;
    &lt;p&gt;If you or your website depend on being indexed by Google, this may not be viable. It pains me to say it, but the gatekeepers of the internet are real, and you have to stay on their good side, or else. This doesn't just affect your search ratings, but could potentially add a warning to your site in Chrome, with the only recourse being a manual appeal.&lt;/p&gt;
    &lt;p&gt;However, this applies only to the post babbler. The php babbler is still fair game since Googlebot ignores non-HTML pages, and the only bots looking for php files are malicious.&lt;/p&gt;
    &lt;p&gt;So if you have a little web-project that is being needlessly abused by scrapers, these projects are fun! For the rest of you, probably stick with 403s.&lt;/p&gt;
    &lt;p&gt;What I've done as a compromise is added the following hidden link on my blog, and another small project of mine, to tempt the bad scrapers:&lt;/p&gt;
    &lt;code&gt;&amp;lt;a href="https://herm.app/babbler/" rel="nofollow" style="display:none"&amp;gt;Don't follow this link&amp;lt;/a&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The only thing I'm worried about now is running out of Outbound Transfer budget on my VPS. If I get close I'll cache it with Cloudflare, at the expense of the counter.&lt;/p&gt;
    &lt;p&gt;This was a fun little project, even if there were a few dead ends. I know more about Markov chains and scraper bots, and had a great time learning, despite it being fuelled by righteous anger.&lt;/p&gt;
    &lt;p&gt;Not all threads need to lead somewhere pertinent. Sometimes we can just do things for fun.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45935729</guid><pubDate>Sat, 15 Nov 2025 07:38:18 +0000</pubDate></item><item><title>One Handed Keyboard</title><link>https://github.com/htx-studio/One-Handed-Keyboard</link><description>&lt;doc fingerprint="533d0de6edea3cfa"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;我们收到了一封特殊的邮件。来信者的女儿在上学途中不幸遭到重型卡车碾压，右手永久失去了功能，用电脑的时候手得在键盘和鼠标之间频繁切换，打字很慢，很累。他想让我们帮他女儿做一个单手键盘。&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;这是一把单模且集成了轨迹球的机械键盘，固件使用QMK，感谢所有为 QMK 社区做出贡献的开发者。&lt;/p&gt;
    &lt;p&gt;键盘制作参考：【何同学】我们做了个特别的键盘…&lt;/p&gt;
    &lt;p&gt;硬件开源：HTXStudio单手键盘&lt;/p&gt;
    &lt;p&gt;本仓库的资料内容包括：&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;左右手一共三款键盘的8块PCB，提供立创EDA工程。&lt;/item&gt;
      &lt;item&gt;VIA改键配置文件，以及编译完成的固件。&lt;/item&gt;
      &lt;item&gt;模型设计文件。&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;芯片的数据手册与图片。&lt;/p&gt;
    &lt;p&gt;三款不同型号键盘的QMK固件，以及用于VIA改键的JSON文件。&lt;/p&gt;
    &lt;p&gt;嘉立创EDA的项目文件。&lt;/p&gt;
    &lt;p&gt;每个型号键盘使用到的模型文件，加工文件。&lt;/p&gt;
    &lt;p&gt;1-右手键盘-热插拔(大)：板材FR-4，板厚1.6mm，四层板，层压结构JLC04161H-3313，阻抗管控+/-20%。&lt;/p&gt;
    &lt;p&gt;1-左手键盘-焊板(小)：板材FR-4，板厚1.6mm，双层板，ALPS黄轴插入时需稍用力安装到位。&lt;/p&gt;
    &lt;p&gt;1-左手键盘-热插拔(大)：板材FR-4，板厚1.6mm，四层板，层压结构JLC04161H-3313，阻抗管控+/-20%。&lt;/p&gt;
    &lt;p&gt;2-TypeC：板材FR-4，板厚1.6mm，双层板，标识CON1（仅适用于大键盘）。&lt;/p&gt;
    &lt;p&gt;3-轨迹球：板材FR-4，板厚1.6mm，双层板，模块需注意焊接方向，标识CON3。&lt;/p&gt;
    &lt;p&gt;4-鼠标滚轮：板材FR-4，板厚1.6mm，双层板，建议使用7mm高编码器，6mm高按键，按键触发压力≤180g，标识CON2。&lt;/p&gt;
    &lt;p&gt;5-方向按键：板材FR-4，板厚1.6mm，双层板，ALPS黄轴插入时需稍用力安装到位，标识CON4。&lt;/p&gt;
    &lt;p&gt;6-主控板-左手(小)：板材FR-4，板厚1.6mm，双层板。&lt;/p&gt;
    &lt;quote&gt;&lt;item&gt;其中3款为键盘控制公用小板&lt;/item&gt;&lt;code&gt;《3-轨迹球》《4-鼠标滚轮》《5-方向按键》&lt;/code&gt;。&lt;code&gt;《5-方向按键》&lt;/code&gt;和&lt;code&gt;《1-左手键盘-焊板(小)》&lt;/code&gt;，按键轴使用ALPS黄轴。&lt;item&gt;注意左右手大键盘并非完全镜像。&lt;/item&gt;&lt;item&gt;轨迹球控制使用SPI1通道，滚轮有单独两条信号线，这可以使得替换其它控制设备而不需要较大的调整。&lt;/item&gt;&lt;item&gt;主控使用 STM32G431CBU6。&lt;/item&gt;&lt;item&gt;兼容A to C 或 C to C 数据线。&lt;/item&gt;&lt;/quote&gt;
    &lt;p&gt;键帽：树脂、PLA等。&lt;/p&gt;
    &lt;p&gt;轨迹球座：树脂、PLA等。&lt;/p&gt;
    &lt;p&gt;鼠标左右键：树脂、PLA等。&lt;/p&gt;
    &lt;p&gt;外壳：树脂、PLA等。&lt;/p&gt;
    &lt;p&gt;底座：树脂、PLA等。&lt;/p&gt;
    &lt;p&gt;定位板：推荐材料pom，厚1.5mm。&lt;/p&gt;
    &lt;p&gt;定位板棉条：单面留胶。&lt;/p&gt;
    &lt;p&gt;夹心棉：推荐材料poron，厚3.5mm。&lt;/p&gt;
    &lt;p&gt;轴座棉：厚2mm。&lt;/p&gt;
    &lt;p&gt;底棉：推荐材料poron，厚4mm。&lt;/p&gt;
    &lt;p&gt;硅胶垫（仅小键盘使用）：厚5mm，硬度Shore 00-10。&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;大键盘用量（颗）&lt;/cell&gt;
        &lt;cell role="head"&gt;小键盘用量（颗）&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M3×3×4热熔铜螺母&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M2×2×3热熔铜螺母&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M2×3×3热熔铜螺母&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M3×6沉头螺丝&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M3×15沉头螺丝&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M3×22沉头螺丝&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M2×8杯头螺丝&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M2×3杯头螺丝&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;M2×5杯头螺丝&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;M3×16扁头螺丝&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;轨迹球：直径25mm，材质PTFE。&lt;/p&gt;
    &lt;p&gt;润滑球：直径2mm，材质PTFE，安装于打印件轨迹球座中，数量6颗。&lt;/p&gt;
    &lt;p&gt;滚轮：推荐直径19mm-20mm之间，厚4mm-5mm之间，材质金属。&lt;/p&gt;
    &lt;p&gt;卫星轴：2U钢板卫星轴。&lt;/p&gt;
    &lt;p&gt;按键轴：小键盘57颗超小ALPS黄轴，大键盘57颗常见机械轴。&lt;/p&gt;
    &lt;p&gt;排线：间距0.5mm，8P反向，10cm2条，15cm2条。&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;控制板和小板的FPC座均有CON标识，对应接口相接。&lt;/item&gt;
      &lt;item&gt;文件内使用可上下接FPC排线座，需要注意排线座均下接的情况下，使用反向排线连接。&lt;/item&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;以大键盘为例&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;装配前的前置工作&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;先将4块小PCB使用排线连接至键盘本体PCB，烧录程序。&lt;/item&gt;
      &lt;item&gt;安装3-5个轴体，滚轮和轨迹球。装配前确保功能是正常的。&lt;/item&gt;
      &lt;item&gt;在打印的外壳与底座对应位置，安装正确的热熔铜螺母。&lt;/item&gt;
      &lt;item&gt;键帽印字。&lt;/item&gt;
      &lt;item&gt;将棉条贴在定位板突出部分（正反面都有）。&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;第一次烧录固件时，可以按住PCB背面标有 "B" 的按钮，再插入USB线进行固件烧录。&lt;/p&gt;
      &lt;p&gt;若更新固件可以按住键盘上的 "ESC" 键，再插入USB线进行固件烧录。&lt;/p&gt;
      &lt;p&gt;更多可以参考 Flashing Your Keyboard (QMK)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;接下来开始装配&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;将4块小板使用螺丝安装到底座对应位置（注意排线和安装方向），轨迹球座在下方安装螺丝。&lt;/item&gt;
      &lt;item&gt;将左右键使用螺丝固定在键盘PCB上。&lt;/item&gt;
      &lt;item&gt;从下到上以底棉、轴座棉、键盘PCB、夹心棉、定位板顺序放入底座扇形区域。&lt;/item&gt;
      &lt;item&gt;插入按键轴体。&lt;/item&gt;
      &lt;item&gt;放入外壳，在下方使用螺丝固定。&lt;/item&gt;
      &lt;item&gt;安装键帽，完成装配。&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;螺丝螺母安装指南可以参考这里&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;最后，这是我们第一次开源项目，如果有什么不足欢迎大家批评指正，感谢大家。&lt;/p&gt;
    &lt;p&gt;Quantum Mechanical Keyboard Firmware&lt;/p&gt;
    &lt;p&gt;mrjohnk. ADNS-9800. GitHub repository&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45936262</guid><pubDate>Sat, 15 Nov 2025 09:44:15 +0000</pubDate></item><item><title>Our investigation into the suspicious pressure on Archive.today</title><link>https://adguard-dns.io/en/blog/archive-today-adguard-dns-block-demand.html</link><description>&lt;doc fingerprint="2e8281950e64d521"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Behind the complaints: Our investigation into the suspicious pressure on Archive.today&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;14 Nov 2025 UPD: We have updated the article with more information on the bailiff reports sent to us and the person who ordered them.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The FBI has been investigating Archive.is (also known as Archive.today), as was recently revealed. The agency issued a subpoena to the site’s domain registrar, asking for information about the person behind it, citing a “federal criminal investigation.”&lt;/p&gt;
    &lt;p&gt;Archive.is was launched in 2012 by someone using the name Denis Petrov — though whether that’s their real identity remains unclear. The site lets users save “snapshots” of web pages by submitting URLs, which makes it a valuable tool for preserving content that might otherwise disappear. But because it can also be used to bypass paywalls, it’s long been a thorn in the side of many media organizations.&lt;/p&gt;
    &lt;p&gt;While the exact nature of the FBI investigation hasn’t been confirmed, it is speculated it can be related to copyright or CSAM (child sexual abuse material) dissemination issues. Altogether, the situation suggests growing pressure on whoever runs Archive.is, and on intermediaries that help make its service accessible. AdGuard DNS, as it turns out, may have just become one such pressure point.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we got entangled&lt;/head&gt;
    &lt;p&gt;A few weeks ago, we were contacted by a representative of an organization called the Web Abuse Association Defense, a French group claiming to fight against child pornography. Their website is webabusedefense.com, and here is the archived version as of November 7.&lt;/p&gt;
    &lt;p&gt;They demanded that we block the domain &lt;code&gt;archive.today&lt;/code&gt; (and its mirrors) in AdGuard DNS, alleging that the site’s admin had refused to remove illegal content since 2023. To be clear, Archive.today allows users to take “snapshots” of any webpages, including potentially illegal material. In such cases, it’s the site admin’s job to respond to complaints and promptly remove that content.&lt;/p&gt;
    &lt;p&gt;This struck us as strange — we’re not a hosting provider, and it seemed unusual for an infrastructure-level service like ours to be asked to take action like this.&lt;/p&gt;
    &lt;p&gt;Soon after, the situation escalated into what we could only describe as direct threats:&lt;/p&gt;
    &lt;p&gt;We won’t share all the screenshots here, but there were several similar messages.&lt;/p&gt;
    &lt;p&gt;We sought legal advice, and unfortunately discovered that French law, specifically Article 6-I-7 of the Loi pour la Confiance dans l'Économie Numérique (LCEN), might actually require us to respond and apply blocking measures, at least for French users.&lt;/p&gt;
    &lt;p&gt;That said, this whole situation shows just how inadequate this regulation is. Such decisions should be made by a court — a private company shouldn’t have to decide what counts as “illegal” content under threat of legal action.&lt;/p&gt;
    &lt;p&gt;Even so, the story didn’t quite add up. Since someone was trying to pressure us into taking action, we decided to contact the other side, Archive.today, directly.&lt;/p&gt;
    &lt;p&gt;We sent an email to Archive.today’s contact address and asked two simple questions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Can they remove the illegal content from the URLs we were informed about?&lt;/item&gt;
      &lt;item&gt;Is it true that they refused to remove such content in the past, and had they been notified about it before?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They replied within a few hours. The response was straightforward: the illegal content would be removed (and we verified that it was), and they had never received any previous notifications about those URLs.&lt;/p&gt;
    &lt;p&gt;Moreover, they hinted that Archive.today had been targeted by a campaign of “serial” complaints, supposedly from French organizations, sent to various companies and institutions that could potentially harm the site. They even shared a link demonstrating a complaint similar to the one we had received.&lt;/p&gt;
    &lt;p&gt;At that point, things were looking increasingly odd, so we decided to dig deeper into the “complainant.”&lt;/p&gt;
    &lt;p&gt;The Web Abuse Association Defense website references several well-known organizations — Europol, OFAC, NCA — yet provides no details or evidence of any cooperation with them.&lt;/p&gt;
    &lt;p&gt;The association itself was registered in February–March 2025, around the same time its website appeared. There is very little public information about it. Interestingly, registering an association in France can apparently be done entirely online and does not require proof of identity.&lt;/p&gt;
    &lt;p&gt;The association is registered at an address used for mass company registration, which isn’t inherently problematic but it does indicate that the entire registration process could have been carried out online by a single person.&lt;/p&gt;
    &lt;p&gt;Its Twitter/X account appeared only recently — in August 2025. It has just four followers, and its feed consists of just a few reposts.&lt;/p&gt;
    &lt;p&gt;None of this proves anything by itself, but something still doesn’t add up. In their first email, the “head” of the association claimed that their correspondence with Archive.today started with a bailiff report from 2023. That timeline simply doesn’t fit.&lt;/p&gt;
    &lt;p&gt;We examined the so-called “bailiff reports” they had sent us as evidence. It’s important to note that these aren’t bailiff reports in the English sense — they’re “constat d’huissier sur Internet,” official records of online content such as webpages, posts, or videos. These particular reports were ordered online via the service called Qualijuris, and, based on the timestamps, most of them were also created in August 2025 — not 2023.&lt;/p&gt;
    &lt;p&gt;Only two of these bailiff reports were ordered in 2023 from a similar service. What’s interesting is that they weren’t ordered by WAAD. The name of the person who ordered these bailiff reports matches the name that appears in the correspondence shared with us by the Archive.today administrator — the same one he wrote about on X in 2024. In that case, the complaint appeared to come from a real lawyer — but someone had registered a domain with the lawyer’s surname, containing nothing but a redirect to the lawyer’s actual website, and did it on the same day the complaint was sent. The domain was used solely to send the emails and it is not active anymore. Interestingly, that email also invoked the LCEN law.&lt;/p&gt;
    &lt;p&gt;So what is the link between WAAD and that lawyer from before? Are these bailiff reports real and could it be that this is a case of impersonation of a real person? We don’t know yet, but we hope to discover the truth soon enough.&lt;/p&gt;
    &lt;p&gt;Unfortunately, we couldn’t dig any deeper about who exactly is behind WAAD. The domain &lt;code&gt;webabusedefense.com&lt;/code&gt; is registered with name.com, but ownership information (including historical records) is hidden. They use ProtonMail for email, so that’s another dead end. The site itself is behind Cloudflare, making further tracing impossible.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we have in the end&lt;/head&gt;
    &lt;p&gt;With everything said and done, here’s where things stand now:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The illegal content was promptly removed from Archive.today after we notified them.&lt;/item&gt;
      &lt;item&gt;The complaints against the site look extremely suspicious. In our case, they came from an organization that was only recently registered that seems deliberately set up to hide the identities of those behind it.&lt;/item&gt;
      &lt;item&gt;The sample complaint shared by Archive.today’s admin shows signs of impersonating a real person. We have contacted the person in question and are currently waiting for a reply.&lt;/item&gt;
      &lt;item&gt;In both our case and that other example, the recipients were pressured to act under the French LCEN law. However, that same law also provides penalties for false reports: &lt;p&gt;Art. 6-I-4 LCEN:&lt;/p&gt;&lt;lb/&gt;4. Any person who presents content or activity to the persons referred to in paragraph 2 as being illegal with the aim of having it removed or its dissemination stopped, when they know this information to be inaccurate, shall be punished by one year’s imprisonment and a fine of €15,000.&lt;/item&gt;
      &lt;item&gt;We believe there are indications of criminal behavior here that should be investigated by law enforcement. Therefore, we will file an official complaint with the French police, including all relevant details.&lt;/item&gt;
      &lt;item&gt;All this is unfolding amid reports of an FBI investigation into the owner of Archive.today. It seems that this investigation may be related to CSAM hosting. While we can’t confirm any connection between that case and ours, the timing is certainly suspicious.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45936460</guid><pubDate>Sat, 15 Nov 2025 10:30:52 +0000</pubDate></item><item><title>Linux on the Fujitsu Lifebook U729</title><link>https://borretti.me/article/linux-on-the-fujitsu-lifebook-u729</link><description>&lt;doc fingerprint="578ff9555537bcd4"&gt;
  &lt;main&gt;
    &lt;p&gt;This post describes my experience using Linux on the Fujitsu Lifebook U729. The tl;dr is that it’s a delightful laptop, and Linux runs flawlessly, and all the hardware things I’ve needed run OOTB. The only difficulty I had was in disabling Secure Boot, but I figured out how to do it, which I explain below.&lt;/p&gt;
    &lt;head rend="h1"&gt;Contents&lt;/head&gt;
    &lt;head rend="h1"&gt;Background&lt;/head&gt;
    &lt;p&gt;From early 2024 my daily driver was an M2 MacBook Air, until earlier this year I broke the screen, and the repair was quoted at almost 1000 AUD. Since I used it as a desktop most of the time, this didn’t affect me much. After some flip-flopping I decided to get an M4 Mac mini. Partly for the faster CPU and more RAM, but partly because I liked the idea of LARPing like it’s the 2000s, when computers, and by extension the Internet, where fixed in physical space, rather than following everyone around.&lt;/p&gt;
    &lt;p&gt;Of course this was a terrible idea. I had three working computers—a Linux+Windows desktop, a Mac Mini, and a MacBook Air that I could use as a desktop—and none of them were portable. When I went to RustForge 2025 I just brought my phone. If I wanted to travel, even within Sydney, to a demo night or math club or some such, I didn’t have a laptop to bring with me.&lt;/p&gt;
    &lt;p&gt;So I needed a new laptop. And the Tahoe release of macOS was so ugly (see e.g. 1, 2, 3) it made me boot up the old Linux desktop, and start playing around with NixOS again. And I fell in love with Linux again: with the tinkering and the experimentation and the freedom it affords you.&lt;/p&gt;
    &lt;p&gt;So, I wanted a Linux laptop. I had a ThinkPad X1 some years ago and it was terribly: flimsy plastic build and hardware that vastly underperformed its price. I looked around for old, refursbished workstation laptops, and, randomly, I ran into an eBay seller offering a refurbished Fujitsu laptop.&lt;/p&gt;
    &lt;p&gt;The specs/price ratio was pretty good: 16 GiB of RAM and 512GiB of SSD, all for 250 AUD. And it was 12in and 1.1kg, which I like: laptops should be small and lightweight. But the thing that got me, in all honesty, was the brand. “Fujitsu laptop” sounds like colour in a William Gibson novel: “crawling into the avionics bay, Case took out a battered Fujitsu refurb, and stuck a JTAG port in the flight computer—”. I already use NixOS and a trackball and a mechanical keyboard, so a laptop that’s even more obscure than a ThinkPad is perfect for me. And it was only 250 AUD. So I got it.&lt;/p&gt;
    &lt;p&gt;The only problem I had was disabling Secure Boot in order to install Linux. Otherwise: I love it. It’s small and lightweight, feels solid, the keyboard is good, all the hardware works out of the box with NixOS, and the battery life is pretty good.&lt;/p&gt;
    &lt;head rend="h1"&gt;Troubleshooting&lt;/head&gt;
    &lt;p&gt;This section describes the problems I encountered.&lt;/p&gt;
    &lt;head rend="h2"&gt;Secure Boot&lt;/head&gt;
    &lt;p&gt;I tried to install Linux the usual way, when I was greeted by this:&lt;/p&gt;
    &lt;p&gt;Going into the BIOS, the option to disable Secure Boot was greyed out. I tried a bunch of random bullshit: wiping the TPM, disabling the TPM. That didn’t work.&lt;/p&gt;
    &lt;p&gt;What did work was this:&lt;/p&gt;
    &lt;p&gt;First, install Windows 11. This came with the laptop. And the installation makes installing Linux feel easy: I had to do so many weird tricks to avoid having to create an account with Microsoft during the installation.&lt;/p&gt;
    &lt;p&gt;Once Windows is installed, go into Windows Update. Under “Advanced Options &amp;gt; Optional Updates”, there should be an option to install Fujitsu-specific drivers. Install those. And for good measure, do a general Windows update.&lt;/p&gt;
    &lt;p&gt;There should be a program called DeskUpdate on the Desktop. This is the Fujitsu BIOS update tool. Run this and go through the instructions: this should update the BIOS (the ordering seems to be important: first update the Fujitsu firmware through Windows Update, then the BIOS through DeskUpdate).&lt;/p&gt;
    &lt;p&gt;Reboot and go into the BIOS (F2). You should have a new BIOS version. In my case, I went from BIOS 2.17 to 2.31 which was released on 2025-03-28:&lt;/p&gt;
    &lt;p&gt;You now have the option to disable Secure Boot:&lt;/p&gt;
    &lt;p&gt;After this, I was able to install NixOS from a live USB:&lt;/p&gt;
    &lt;head rend="h2"&gt;Spyware&lt;/head&gt;
    &lt;p&gt;The laptop comes with this corporate spyware thing called Absolute Persistence. It’s some anti-theft tracking device. Since the Lifebook is typically an enterprise laptop, it makes sense that it comes with this type of thing.&lt;/p&gt;
    &lt;p&gt;I only noticed this because I was searching the BIOS thoroughly for a way to disable Secure Boot. The good news is disabling it is pretty straightforward: you just disable it in the BIOS.&lt;/p&gt;
    &lt;p&gt;As I understand it, Absolute Persistence requires an agent running in the OS, so the BIOS support, by itself, doesn’t do anything once disabled.&lt;/p&gt;
    &lt;head rend="h1"&gt;Non-Problems&lt;/head&gt;
    &lt;p&gt;The following work flawlessly OOTB:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WiFi&lt;/item&gt;
      &lt;item&gt;Bluetooth&lt;/item&gt;
      &lt;item&gt;Sound (using PipeWire)&lt;/item&gt;
      &lt;item&gt;Display brightness control (using brightnessctl)&lt;/item&gt;
      &lt;item&gt;Touchscreen (I didn’t realize the screen was actually a touchscreen until I touched it by accident and saw the mouse move)&lt;/item&gt;
      &lt;item&gt;Webcam (not winning any awards on quality, but it works)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Things I have not tested:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microphone&lt;/item&gt;
      &lt;item&gt;Fingerprint sensor&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;BIOS Notes&lt;/head&gt;
    &lt;p&gt;To enter the BIOS: smash &lt;code&gt;F2&lt;/code&gt; until you hear the beep. No need to hold down the
&lt;code&gt;Fn&lt;/code&gt; key.&lt;/p&gt;
    &lt;p&gt;To enter the boot menu: as above but with &lt;code&gt;F12&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45937989</guid><pubDate>Sat, 15 Nov 2025 15:19:20 +0000</pubDate></item><item><title>Weighting an average to minimize variance</title><link>https://www.johndcook.com/blog/2025/11/12/minimum-variance/</link><description>&lt;doc fingerprint="b749f59d8783fb76"&gt;
  &lt;main&gt;
    &lt;p&gt;Suppose you have $100 to invest in two independent assets, A and B, and you want to minimize volatility. Suppose A is more volatile than B. Then putting all your money on A would be the worst thing to do, but putting all your money on B would not be the best thing to do.&lt;/p&gt;
    &lt;p&gt;The optimal allocation would be some mix of A and B, with more (but not all) going to B. We will formalize this problem and determine the optimal allocation, then generalize the problem to more assets.&lt;/p&gt;
    &lt;head rend="h2"&gt;Two variables&lt;/head&gt;
    &lt;p&gt;Let X and Y be two independent random variables with finite variance and assume at least one of X and Y is not constant. We want to find t that minimizes&lt;/p&gt;
    &lt;p&gt;subject to the constraint 0 ≤ t ≤ 1. Because X and Y are independent,&lt;/p&gt;
    &lt;p&gt;Taking the derivative with respect to t and setting it to zero shows that&lt;/p&gt;
    &lt;p&gt;So the smaller the variance on Y, the less we allocate to X. If Y is constant, we allocate nothing to X and go all in on Y. If X and Y have equal variance, we allocate an equal amount to each. If X has twice the variance of Y, we allocate 1/3 to X and 2/3 to Y.&lt;/p&gt;
    &lt;head rend="h2"&gt;Multiple variables&lt;/head&gt;
    &lt;p&gt;Now suppose we have n independent random variables Xi for i running from 1 to n, and at least one of the variables is not constant. Then we want to minimize&lt;/p&gt;
    &lt;p&gt;subject to the constraint&lt;/p&gt;
    &lt;p&gt;and all ti non-negative. We can solve this optimization problem with Lagrange multipliers and find that&lt;/p&gt;
    &lt;p&gt;for all 1 ≤ i, j ≤ n. These (n − 1) equations along with the constraint that all the ti sum to 1 give us a system of equations whose solution is&lt;/p&gt;
    &lt;p&gt;Incidentally, the denominator has a name: the (n − 1)st elementary symmetric polynomial in n variables. More on this in the next post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45938027</guid><pubDate>Sat, 15 Nov 2025 15:25:08 +0000</pubDate></item><item><title>Windhawk Windows classic theme mod for Windows 11</title><link>https://windhawk.net/mods/classic-theme-enable</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45938723</guid><pubDate>Sat, 15 Nov 2025 16:53:30 +0000</pubDate></item><item><title>Trellis AI (YC W24) Is Hiring: Streamline access to life-saving therapies</title><link>https://www.ycombinator.com/companies/trellis-ai/jobs/f4GWvH0-forward-deployed-engineer-full-time</link><description>&lt;doc fingerprint="ad510041aad6f0ca"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Trellis builds and deploys computer use agents to get patients access to life-saving medicine.&lt;/head&gt;
        &lt;p&gt;Our computer-use AI agents process billions of dollars worth of therapies annually with patients in all fifty states. We do this by automating document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care. We classify medical referrals, understand chart notes, and automate contract and reimbursement search to provide patients with accurate coverage determinations and cost responsibility. Think of us as the Stripe of healthcare billing and reimbursements.&lt;/p&gt;
        &lt;p&gt;Trellis is a spinout from Stanford AI Lab and is backed by leading investors including YC, General Catalyst, Telesoft Partners, and executives at Google and Salesforce.&lt;/p&gt;
        &lt;head rend="h3"&gt;🧍🏻♂️Why work with us&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Real impact at massive scale: We serve patients in all fifty states and are scaling to hundreds of healthcare locations. You'll directly see the number of patients who received treatment because of the agents you built.&lt;/item&gt;
          &lt;item&gt;Work with industry experts: Apply your AI alongside healthcare operations leaders who have overseen 50+ healthcare locations, gaining deep domain expertise while building cutting-edge technology.&lt;/item&gt;
          &lt;item&gt;Be at the forefront of AI in healthcare: Build production-grade agentic systems that make critical healthcare decisions, backed by robust evaluation frameworks.&lt;/item&gt;
          &lt;item&gt;Direct customer engagement: Work closely with F500 customers and the founding team. You'll wear multiple hats from technical architecture to customer success.&lt;/item&gt;
          &lt;item&gt;Extreme ownership: Own key parts of Trellis's technical infrastructure and have opportunities to launch new initiatives that process billions in healthcare transactions.&lt;/item&gt;
          &lt;item&gt;World-class team: Join team members who have won international physics olympiads, published economics research, were founding engineers at unicorn startups, and taught AI classes to hundreds of Stanford graduate students.&lt;/item&gt;
          &lt;item&gt;Incredible growth and traction: We've grown revenue 10x in the past few months alone and have XX% market share in the specialty healthcare markets we serve.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;What you'll build&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Agentic frameworks for healthcare decision-making: Design and implement AI systems that autonomously navigate complex reimbursement logic and prior authorization workflows.&lt;/item&gt;
          &lt;item&gt;24/7 AI co-workers: Build and deploy long-running agent workers that triage and process healthcare data around the clock, functioning as reliable digital teammates for care teams.&lt;/item&gt;
          &lt;item&gt;Production-grade AI systems: Develop your agents within our comprehensive evaluation suite, ensuring production-ready performance from day one.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experience architecting, developing, and testing full-stack code end-to-end&lt;/item&gt;
          &lt;item&gt;Expertise in programming languages such as Python, Go and ML/NLP libraries such as PyTorch, TensorFlow, Transformers&lt;/item&gt;
          &lt;item&gt;Being proactive and a fast-learner with bias for action&lt;/item&gt;
          &lt;item&gt;Experience working with relational and non-relational databases, especially Postgres&lt;/item&gt;
          &lt;item&gt;Experience with data and ML infrastructure&lt;/item&gt;
          &lt;item&gt;Open source contributions and projects are a big plus&lt;/item&gt;
          &lt;item&gt;Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization technologies (e.g., Docker, Kubernetes) is a plus&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Trellis helps healthcare providers treat more patients, faster—while eliminating pre-service paperwork.&lt;/p&gt;
      &lt;p&gt;We automate document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care.&lt;/p&gt;
      &lt;p&gt;Our AI agent is trained on millions of clinical data points and converts messy, unstructured documents into clean, structured data directly in your EHR.&lt;/p&gt;
      &lt;p&gt;With Trellis, leading healthcare providers and pharmaceutical companies were able to:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Reduce time to treatment by over 90%&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Improve prior authorization approval and reimbursement rates&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Leverage structured data to enhance drug program performance and clinical decision-making&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Administrative costs account for over 20% of U.S. healthcare spending—delaying care, draining revenue, and driving staff burnout while having less visibility into patient care than ever before. We built Trellis to tackle this head on.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45938785</guid><pubDate>Sat, 15 Nov 2025 17:00:38 +0000</pubDate></item><item><title>FBI Director Waived Polygraph Security Screening for Three Senior Staff</title><link>https://www.propublica.org/article/fbi-kash-patel-dan-bongino-waived-polygraph</link><description>&lt;doc fingerprint="3c68c19d4c39135f"&gt;
  &lt;main&gt;
    &lt;p&gt;FBI Director Kash Patel granted waivers to Deputy Director Dan Bongino and two other newly hired senior FBI staff members, exempting them from passing polygraph exams normally required to gain access to America’s most sensitive classified information, according to a former senior FBI official and several other government officials.&lt;/p&gt;
    &lt;p&gt;Bongino’s role as the FBI’s second-highest-ranking official means he is responsible for day-to-day operations of the agency, including green-lighting surveillance missions, coordinating with intelligence agency partners and managing the bureau’s 56 field offices across the country. The deputy director receives some of the country’s most closely held secrets, including the President’s Daily Brief, which also contains intelligence from the CIA and the National Security Agency.&lt;/p&gt;
    &lt;p&gt;People familiar with the matter say his ascent to that position without passing a standard FBI background check was unprecedented. ProPublica spoke with four people familiar with the polygraph issues, who spoke on the condition of anonymity for fear of retaliation and because they were not authorized to publicly discuss the details of FBI background checks.&lt;/p&gt;
    &lt;p&gt;Bongino was selected for the role at the FBI although he, like Patel, had no prior experience at the bureau. Bongino had previously served in the Secret Service and worked as a New York City police officer. But he later gained millions of fans and followers in conservative circles for television and podcast appearances, having taken over Rush Limbaugh’s spot on numerous radio stations. Over the years, Bongino used those platforms to push conspiracy theories about the 2020 election and professed his allegiance to President Donald Trump while railing against the agency he now helps lead.&lt;/p&gt;
    &lt;p&gt;He’s had a rocky tenure so far, marked by public fights with senior Cabinet officials and accusations that he leaked information to the press, which Bongino denied. In August, Trump appointed Missouri Attorney General Andrew Bailey as co-deputy director at the FBI, setting off speculation that the White House had lost faith in Bongino. But he remains in the job.&lt;/p&gt;
    &lt;p&gt;ProPublica could not determine whether Bongino sat for a polygraph exam or what its results were. Though the existence of a polygraph waiver is an indication he may not have passed the test, it is possible Bongino received a preemptive exemption, a former senior FBI official with knowledge of the vetting program told ProPublica.&lt;/p&gt;
    &lt;p&gt;When ProPublica sought comment from the FBI, the agency denied that Bongino or the other senior staff members failed polygraph tests. “It is false that the individuals you referenced failed polygraphs,” wrote spokesperson Ben Williamson.&lt;/p&gt;
    &lt;p&gt;He added: “The FBI follows all laws and procedures on personnel security measures, and any implication otherwise is false. Furthermore, while the FBI does not comment on confidential security information, particularly in matters of personnel, this article is riddled with falsehoods — it misrepresents polygraph protocol, inaccurately portrays FBI security measures, and makes multiple false claims about FBI employees who have done nothing wrong.”&lt;/p&gt;
    &lt;p&gt;ProPublica asked the FBI to specify what it considered to be false. The agency did not reply.&lt;/p&gt;
    &lt;p&gt;A polygraph exam is not technically pass or fail, but a person is not cleared for approval if the examiner finds deception or is unable to reach a conclusion about the veracity of the answers given. Officials said that a person may not have technically failed the exams; the results could be deemed inconclusive, which would not meet the FBI’s standards for hiring or security clearances.&lt;/p&gt;
    &lt;p&gt;The FBI spokesperson initially said the three officials are so-called Schedule C — a category reserved for political appointees. He said the status would mean they were “not required” to undergo polygraphs. But Daniel Meyer, a former executive director for the Inspector General of the Intelligence Community External Review Panel, told ProPublica that an FBI employee wouldn’t be excluded from taking a polygraph exam simply because they’re a Schedule C employee. Three other lawyers, who specialize in national security matters, said the same.&lt;/p&gt;
    &lt;p&gt;In fact, the FBI’s employment eligibility guidelines say all employees must obtain a “Top Secret” clearance in order to work at the agency following a background check. “The preliminary employment requirements include a polygraph examination,” the guidelines say.&lt;/p&gt;
    &lt;head rend="h3"&gt;“How Did They Survive?”&lt;/head&gt;
    &lt;p&gt;Former FBI officials said they could not recall a single instance in which a senior official like Bongino received a waiver and was then given a top secret clearance. One said they were only aware of one waiver being issued in a seven-year period under Director Christopher Wray, for an outside subject matter expert whose polygraph results were inconclusive.&lt;/p&gt;
    &lt;p&gt;Two other officials, Marshall Yates, the agency’s liaison with Congress, and Nicole Rucker, Patel’s personal assistant, did not clear their polygraph exam and were granted waivers by Patel that allowed them to get a high-level security clearance, said officials with knowledge of the issue. Neither of their roles is as high-profile as Bongino’s, nor does either one have prior FBI experience.&lt;/p&gt;
    &lt;p&gt;Polygraph examiners ask a standard list of questions about drug use, criminal history, foreign contacts and mishandling of classified information. After the exam, an analyst scrutinizes the results and decides whether or not they indicate deception or are inconclusive. Those whose answers are determined to be inconclusive are given another chance to take the test the following day.&lt;/p&gt;
    &lt;p&gt;“I don’t know of anybody in my time that were in those senior roles that failed polygraphs, and most of us had taken multiple polygraphs,” said Bob Anderson, a former FBI executive who ran the counterintelligence division and retired in 2016. “If somebody would fail those polygraphs in my time, most likely they would be removed out of the classified environment until that could get cleared.”&lt;/p&gt;
    &lt;p&gt;This year, an employee within the FBI’s Security Division filed a formal complaint alleging the waivers violated agency policy. The Security Division conducts employee polygraph exams and evaluates their results. Its mission is to protect the FBI from leaks of classified information and infiltration by foreign spies. The employee filed the complaint with the division director, Robert Turner, a 22-year veteran of the bureau who previously held roles in counterterrorism and counterespionage.&lt;/p&gt;
    &lt;p&gt;A complaint about the waivers was also shared with the Department of Justice’s Office of the Inspector General, sources said.&lt;/p&gt;
    &lt;p&gt;According to her resume, Rucker, 40, has served as an assistant to Stephen Miller, the powerful architect of the administration’s immigration crackdown, since January 2020.&lt;/p&gt;
    &lt;p&gt;Rucker would have detailed insight into day-to-day FBI operations and those meeting within the director’s office. She also assists in planning Patel’s travel, a former FBI official familiar with her job responsibilities said.&lt;/p&gt;
    &lt;p&gt;The White House said Rucker is not sharing information on the FBI’s operations with Miller and referred further questions to the bureau and the Department of Justice.&lt;/p&gt;
    &lt;p&gt;Meanwhile Yates, 37, was previously the executive director of the Election Integrity Network, a group that worked to overturn the results of the 2020 election. Yates, as the top liaison between the bureau and Congress, has wide visibility into the workforce, including some access to internal files about past investigations.&lt;/p&gt;
    &lt;p&gt;Historically, the job was staffed by a nonpartisan career FBI or Department of Justice official with deep knowledge of the bureau. Among other tasks, the official organizes closed-door briefings with lawmakers to discuss active, undisclosed threats to the country.&lt;/p&gt;
    &lt;p&gt;While an FBI spokesperson discussed the polygraph issues with ProPublica, Patel, Bongino, Yates, Rucker and Turner did not respond to direct requests for comment.&lt;/p&gt;
    &lt;p&gt;Sen. Dick Durbin, the Democratic ranking member of the Senate Judiciary Committee, raised the issue of senior FBI leadership not passing polygraphs — without identifying any individuals — when Patel testified before the committee in September.&lt;/p&gt;
    &lt;p&gt;“As I understand it from highly credible sources, key members of Director Patel’s senior executive team and others on the seventh floor had disqualifying alerts on their initial polygraph exams,” Durbin said. “How did they survive? They survived because of a personal waiver by either the director or the attorney general to remain employed by the bureau.”&lt;/p&gt;
    &lt;p&gt;When Durbin asked Patel if anyone on his senior executive team received “disqualifying alerts on their polygraphs,” Patel refused to answer. And when the senator followed up by asking if he or Attorney General Pam Bondi granted a waiver, Patel replied, “I have to get back to you.”&lt;/p&gt;
    &lt;p&gt;The FBI did not respond to the committee on questions concerning polygraphs, according to a person familiar with the matter.&lt;/p&gt;
    &lt;p&gt;Durbin, in a statement to ProPublica, said, “Reports of disqualifying alerts on polygraphs by senior FBI officials — which require personal waivers from the highest levels of leadership to remain employed — are deeply alarming.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Heart Rate Check&lt;/head&gt;
    &lt;p&gt;The polygraph exam uses a device strapped to a subject’s body to measure physiological responses like heart rate, blood pressure and perspiration as the person answers yes-or-no questions. Though the device’s efficacy is debated, it is routinely used in America’s law enforcement and intelligence agencies to screen potential employees and conduct leak investigations. The FBI first began requiring the polygraph exam for all applicants in 1994, according to a 2006 report by the Department of Justice’s Office of the Inspector General.&lt;/p&gt;
    &lt;p&gt;They are used as part of a broader background check conducted on all potential FBI employees to determine if the applicant triggers any national security or suitability concerns. Suitability refers to a candidate’s criminal history, drug use or other issues that would prevent them from becoming employees of a federal law enforcement agency.&lt;/p&gt;
    &lt;p&gt;FBI security measures are designed to protect sensitive intelligence sources and information, and the screening is intended to ensure that officials given access to this information have cleared a thorough vetting process.&lt;/p&gt;
    &lt;p&gt;Staff who work in the director’s office on the seventh floor of the J. Edgar Hoover Building in Washington must also obtain an additional clearance called SCI, or sensitive compartmented information.&lt;/p&gt;
    &lt;p&gt;SCI contains some of America’s most sensitive intelligence secrets, and employees with that clearance are “read-in” to various compartments or programs. Bongino, Yates and Rucker all obtained SCI clearances after being granted the waivers, people familiar with their clearance level said.&lt;/p&gt;
    &lt;p&gt;In addition to bringing on loyalists, the administration has launched a purge of career FBI staff since January. More than 50 bureau officials have been fired or pushed out, a ProPublica analysis found. They include executives with decades of counterterrorism and intelligence experience, as well as line agents assigned to work on politically sensitive criminal probes, including investigations into Jan. 6 rioters and Trump.&lt;/p&gt;
    &lt;p&gt;Patel has justified these firings under Article II of the Constitution, which outlines the president’s powers over government — a novel use of the statute that is being challenged in the courts. Publicly, the administration has suggested some fired agents were involved in misconduct while investigating Trump or his allies.&lt;/p&gt;
    &lt;p&gt;Former acting FBI Director Brian Driscoll sued Patel, Bondi and the bureau in September, saying he was subjected to political loyalty tests and illegally fired. The FBI declined to comment when the suit was filed and federal agencies have yet to respond in court.&lt;/p&gt;
    &lt;p&gt;The FBI has recently used the polygraph to ask senior employees if they have said anything negative about Patel or had spoken to the media, multiple former FBI employees said. The New York Times earlier reported the use of polygraphs to investigate negative comments about Patel.&lt;/p&gt;
    &lt;head rend="h3"&gt;Destined for Something Greater&lt;/head&gt;
    &lt;p&gt;A lawyer by training, Yates has been the point person in responding to inquiries from Senate Judiciary Chairman Chuck Grassley, a Republican who for months has been publishing internal FBI documents, which he contends show improper past investigations into Trump. According to a former senior FBI official, Yates called regional bureau field offices early this year to get lists of employees involved in cases against Trump; several of those agents were later fired by Patel.&lt;/p&gt;
    &lt;p&gt;Originally from Alabama, Yates previously worked as chief of staff for former Rep. Mo Brooks, R-Ala., and was counsel to Rep. Thomas Massie, R-Ky. A Democratic representative accused Brooks of inciting rioters on Jan. 6, which Brooks denied; the civil case was later dismissed. Brooks has described the FBI as “partisan hacks.” Massie wrote on social media this month, “Capitol Police turned CIA orchestrated the pipe bombs on January 6th, and the FBI has covered it up.”&lt;/p&gt;
    &lt;p&gt;Little is known about Nicole Rucker, who spells her name online as Nikole. Multiple sources have described Rucker as Patel’s personal assistant. She joined Patel on a recent foreign trip to London, where she sat in on a sensitive meeting with a Western intelligence ally, according to a knowledgeable source.&lt;/p&gt;
    &lt;p&gt;Rucker arrived at the FBI on Jan. 20 and began working in the director’s suite without a security clearance, according to a former FBI employee familiar with her work.&lt;/p&gt;
    &lt;p&gt;Due to her initial lack of clearance, Rucker was escorted from the FBI lobby to the secure director’s suite by Turner, who was then the deputy of the FBI’s Security Division. Rucker eventually obtained a security clearance and was no longer escorted, the person said.&lt;/p&gt;
    &lt;p&gt;Williamson, the FBI spokesperson, said “people are escorted in similar circumstances all the time.”&lt;/p&gt;
    &lt;p&gt;In May, Rucker’s husband posted a photo on LinkedIn with himself and Rucker alongside Patel, standing in front of the FBI logo.&lt;/p&gt;
    &lt;p&gt;On her resume, she also lists a job working as the executive assistant to the chief of public affairs at the National Museum of African American History and Culture from 2018 to 2019. After that, she was a congressional relations liaison at Ultra Electronics, a British defense contractor.&lt;/p&gt;
    &lt;p&gt;Rucker founded Cobblestone Concierge, which offers personal assistant services such as “home management, organization, errand service and so much more!” according to her LinkedIn profile. The company’s website says its services include “household management (including meeting the cable guy).”&lt;/p&gt;
    &lt;p&gt;ProPublica interviewed her ex-husband, Joseph Churchville, who said Rucker worked at a title insurance company while they were married but had always thought she was destined for something greater. “She’s tenacious. When she acquires something that she wants, she has the ability to make things happen,” Churchville said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939266</guid><pubDate>Sat, 15 Nov 2025 18:03:37 +0000</pubDate></item><item><title>USA gives South Korea green light to build nuclear submarines</title><link>https://www.navalnews.com/naval-news/2025/10/usa-gives-south-korea-green-light-to-build-nuclear-submarines/</link><description>&lt;doc fingerprint="822ab5dc60a49682"&gt;
  &lt;main&gt;
    &lt;p&gt;Revealed on October 29th, U.S President Donald Trump has announced that the U.S government has given the go ahead for South Korea to build Nuclear Submarines on U.S soil.&lt;/p&gt;
    &lt;p&gt;Story by Ethan Gossrow, additional reporting by Eunhyuk Cha.&lt;/p&gt;
    &lt;p&gt;The announcement came following a meeting with various Asian heads of state including South Korean President Lee Jae-Myung in Gyeongju, South Korea. Additional posts by Trump on Truth Social have detailed that the Submarines will be built on U.S soil at the Philadelphia shipyards, which were acquired by the Korean defense firm Hanwha late in 2024.&lt;/p&gt;
    &lt;p&gt;Subsequently, the construction of Nuclear submarines marks a departure from past efforts, as previous South Korean submarine construction has focused primarily on conventionally powered submarines. In tandem with this, South Korean Nuclear Submarine construction projects have remained in limbo for sometime as the U.S had not given tacit approval until President Trump’s statement.&lt;/p&gt;
    &lt;p&gt;However, as the Philadelphia Shipyards where construction will take place is not currently equipped to handle the construction of Nuclear Submarines (only commercial vessels have been produced), Hanwha has reportedly invested an additional $5 billion dollars into modernization and preparation. Despite this, there has been a lack of a concrete agreement regarding the development of the shipyards and a plan for the construction of the submarines with no official signature from the South Korean side.&lt;/p&gt;
    &lt;p&gt;These agreements are the conclusion of a long standing desire for nuclear powered submarines expressed by the South Korean government and military. Naval News has previously reported that subsequent efforts for a Nuclear Submarines have been born of increasingly intense operational needs for endurance and a deterrent towards neighboring nations such as North Korea, China, and Russia.&lt;/p&gt;
    &lt;p&gt;At the National Assembly’s Defense Committee audit on the 30th, Chief of Naval Operations Kang Dong-gil stated, “The start date for the nuclear-powered submarine program has not yet been decided, but once it begins, it will take more than 10 years,” adding, “Its displacement is expected to exceed 5,000 tons.”&lt;/p&gt;
    &lt;p&gt;Defense Acquisition Program Administration (DAPA) Commissioner Seok Jong-geon also stated, “Looking at advanced countries’ cases, it generally takes about 10 years to build a nuclear-powered submarine,” adding, “If we combine our capabilities, it could be somewhat shortened.”&lt;/p&gt;
    &lt;p&gt;Minister of National Defense Ahn Kyu-baek, when asked about the scale of the planned nuclear-powered submarine acquisition, replied, “It will need to be discussed with the Navy, but I think at least four submarines would be necessary.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Potential Design and Past Experiences&lt;/head&gt;
    &lt;p&gt;Currently, South Korea operates 3 classes of conventionally powered submarines, the Jang Bogo-Class (KSS-I), Sohn Wonyil-Class (KSS-II), and Dosan Ahn Changho-class (KSS-III). KSS-I and KSS-II submarines are Korean manufactured derivatives of the German Type 209 and Type 214 designs, numbering 9 boats per class in ROKN service.&lt;/p&gt;
    &lt;p&gt;KSS-III is the latest submarine design to enter service, with the class being the first fully indigenous design to be produced. There are currently 3 batch 1 KSS-III submarines in service, with the first of the batch 2 boats launched a week ago.&lt;/p&gt;
    &lt;p&gt;Accordingly, KSS-III offers a significant capability jump over past South Korean submarines, sporting an improved power plant, better sonar, new torpedoes, and the addition of K-VLS cells for more strike options with batch 1 and 2 carrying 6 and 10 K-VLS cells respectively. These improvements are allowed through a greater tonnage, rising to 3,750 tones submerged for batch 1 boats with batch 2 boats expected to be even heavier.&lt;/p&gt;
    &lt;p&gt;Given it’s modernity and Korean architecture, KSS-III has previously been eyed for a potential upgrade from it’s conventional Diesel Electric/Air Independent Propulsion power plant to a nuclear reactor. Naval News has previously reported on the concept, with the sub offering vastly increased endurance, power generation capabilities, and speed over it’s conventionally powered brethren.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939459</guid><pubDate>Sat, 15 Nov 2025 18:29:00 +0000</pubDate></item><item><title>Transgenerational Epigenetic Inheritance: the story of learned avoidance</title><link>https://elifesciences.org/articles/109427</link><description>&lt;doc fingerprint="4780c9413920cbd3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Transgenerational Epigenetic Inheritance: Twists and turns in the story of learned avoidance&lt;/head&gt;
    &lt;p&gt;The ability to recognize and avoid pathogens is essential for survival. In some cases, animals recognize molecules produced by pathogens, allowing them to mount an immediate response. In other cases, animals learn to avoid the pathogen after they have been exposed to it – a phenomenon that is called “learned avoidance”.&lt;/p&gt;
    &lt;p&gt;The worm Caenorhabditis elegans can learn to avoid Pseudomonas aeruginosa, a pathogenic bacterium that causes disease in a range of species (Zhang et al., 2005). In 2019, Coleen Murphy and colleagues at Princeton University observed that learned avoidance of the PA14 strain of P. aeruginosa could be transmitted for up to four generations of C. elegans without new exposure to PA14 (Moore et al., 2019; Kaletsky et al., 2020). This transgenerational epigenetic inheritance allows animals that have never encountered PA14 to benefit from the experiences of previous generations.&lt;/p&gt;
    &lt;p&gt;Recently, Craig Hunter and colleagues at Harvard University questioned the inheritance of learned avoidance to the F2 generation (Gainey et al., 2025). While they observed learned avoidance to PA14 in parents (P0) and their progeny (F1), they did not observe avoidance in the F2 generation. The Murphy group responded, contending that the inability to observe transgenerational epigenetic inheritance was due to changes the Hunter group made to the original experimental protocols (Kaletsky et al., 2025). Now, in eLife, Andres Vidal-Gadea and colleagues at Illinois State University – Aalimah Akinosho, Joseph Alexander and Kyle Floyd – report that they have confirmed findings from the Murphy group by showing that learned avoidance of PA14 is passed on to the F2 generation (Akinosho et al., 2025).&lt;/p&gt;
    &lt;p&gt;In a standard avoidance assay, test spots of bacteria are placed at opposite ends of an agar plate, and sodium azide – a chemical that immobilizes worms – is added to each test spot (Figure 1). The worms are placed at the center of the plate and allowed to roam, and the number of worms in proximity to each test spot is scored after one hour (Moore et al., 2019).&lt;/p&gt;
    &lt;p&gt;For the learned avoidance assay, the worms are exposed to PA14 for 24 hours, a process sometimes called “training”, after which time they are collected and washed. A subset of these worms is transferred to a test plate and allowed to choose between PA14 and the OP50 strain of E. coli (which is the standard laboratory diet of C. elegans). This is the parental generation, and the worms in it will avoid PA14.&lt;/p&gt;
    &lt;p&gt;Eggs (F1) are collected from the remaining worms and transferred to standard OP50 plates. Once they reach the adult stage, the same process is carried out; a subset of animals is tested, and eggs are collected from the remaining worms for the next generation (F2). Importantly, after the parental generation, worms do not encounter PA14 before testing, but they retain the learned avoidance of the parental generation. To measure learned avoidance, all groups are compared to animals whose predecessors have never encountered PA14.&lt;/p&gt;
    &lt;p&gt;Both the Murphy and Vidal-Gadea groups used sodium azide in their assays to immobilize the worms, while the Hunter group immobilized them by lowering the temperature to 4 °C at the end of the assay. With azide, worms that reach the test spots before the end of the assay are immobilized. By contrast, when the temperature shift method is used, worms can come into contact with the test spots and then move away before the end of the assay. The Murphy group proposed that the use of azide ensured that animals were captured in their initial response, which prevented them from learning to avoid PA14 after encountering it during the assay. However, they argued, when the temperature-shift method is used, worms can encounter PA14, learn from this encounter, and avoid the PA14 spot (Kaletsky et al., 2025). Put simply, an encounter with PA14 could unintentionally introduce another source of learned avoidance to the assay. The most significant impact of this would be on the negative control, where it is assumed that the worms’ response reflects that of animals that have never encountered PA14.&lt;/p&gt;
    &lt;p&gt;Worms that have not previously encountered PA14 are initially attracted to it (Zhang et al., 2005). While the Murphy group consistently observed this attraction in their assays, the Hunter group generally did not (Kaletsky et al., 2025). The Vidal-Gadea group also observed that worms that had not been exposed to PA14 were initially attracted to it, suggesting that this is an important piece of the puzzle (Akinosho et al., 2025). Indeed, when tested directly, the Murphy group did not observe attraction using the temperature-shift method (Kaletsky et al., 2025). However, whether the omission of azide alone explains the discrepancy between the studies is not clear. In a handful of assays, the Hunter group used azide but failed to see the initial attraction to PA14, or to observe learned avoidance in the F2 generation.&lt;/p&gt;
    &lt;p&gt;P11, a small RNA produced by PA14, is necessary and sufficient to induce transgenerational epigenetic inheritance (Kaletsky et al., 2020). In addition, loss of P11 reduces chemoattraction to PA14 by reducing ammonia production (Marogi et al., 2024). The Murphy lab proposed that suboptimal P11 expression could explain difficulties in reproducing transgenerational epigenetic inheritance and in observing the initial attraction to PA14. Although they did not measure P11 levels, the Hunter group argued that their ability to observe learned avoidance in the F1 generation excluded the possibility that P11 expression was insufficient. PA14 growth conditions can alter P11 expression (Kaletsky et al., 2025), but whether low levels of P11 could permit F1 inheritance but not F2, is unknown.&lt;/p&gt;
    &lt;p&gt;Behavioral assays are notoriously finicky, not because they measure effects that are not robust, but because C. elegans are highly attuned to their environments; they integrate a myriad of environmental signals into an appropriate response. Hunter and colleagues tested potential sources of variability in the laboratory environment, including the sources of bacterial and worm strains, but none of these explained the discrepancy in their findings. The sources of variability identified by the Murphy lab (Kaletsky et al., 2025) provide a logical explanation for the differences between the two studies, but other unidentified environmental or procedural differences may also have contributed. The results of the Vidal-Gadea group, therefore, represent an important validation of the work of the Murphy group, and support the idea that procedural modifications made by the Hunter group contributed to their inability to observe transgenerational epigenetic inheritance.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;head rend="h2"&gt;Article and author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Author details&lt;/head&gt;
    &lt;head rend="h3"&gt;Publication history&lt;/head&gt;
    &lt;head rend="h3"&gt;Copyright&lt;/head&gt;
    &lt;p&gt;© 2025, MacNeil&lt;/p&gt;
    &lt;p&gt;This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.&lt;/p&gt;
    &lt;head rend="h2"&gt;Metrics&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="dl"&gt;
          &lt;item rend="dd-1"&gt;548&lt;/item&gt;
          &lt;item rend="dt-2"&gt;views&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="dl"&gt;
          &lt;item rend="dd-2"&gt;12&lt;/item&gt;
          &lt;item rend="dt-3"&gt;downloads&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="dl"&gt;
          &lt;item rend="dd-3"&gt;0&lt;/item&gt;
          &lt;item rend="dt-4"&gt;citations&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Views, downloads and citations are aggregated across all versions of this paper published by eLife.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939550</guid><pubDate>Sat, 15 Nov 2025 18:40:55 +0000</pubDate></item><item><title>The computer poetry of J. M. Coetzee's early programming career</title><link>https://sites.utexas.edu/ransomcentermagazine/2017/06/28/the-computer-poetry-of-j-m-coetzees-early-programming-career/</link><description>&lt;doc fingerprint="6d1119d923b849c7"&gt;
  &lt;main&gt;
    &lt;p&gt;June 28, 2017, Filed Under: Authors, Books + Manuscripts, Research + TeachingThe computer poetry of J. M. Coetzee’s early programming career Writer J. M. Coetzee’s early poetry is almost undecipherable. That’s because it was written in computer code. Coetzee’s global reputation rests on his literary output, for which he received a Nobel Prize in 2003. Before he embarked on a career as a scholar and writer, the South African–born writer was a computer programmer in the early years of the industry’s development (1962–1965). I believe that this experience, while short, was vital for the development of Coetzee’s writerly project. While visiting the Ransom Center on a research fellowship, I examined Coetzee’s papers, which offer tantalizing clues about his neglected “other career.” In the mid 1960s Coetzee was working on one of the most advanced programming projects in Britain. During the day he helped to design the Atlas 2 supercomputer destined for the United Kingdom’s Atomic Energy Research Establishment at Aldermaston. At night he used this hugely powerful machine of the Cold War to write simple “computer poetry,” that is, he wrote programs for a computer that used an algorithm to select words from a set vocabulary and create repetitive lines. Coetzee never published these results, but edited and included phrases from them in poetry that he did publish. While Coetzee was never quite at risk of starting World War III, these important experiments have gone under the radar of both Coetzee scholars and historians of computing are concerned. Readers of Coetzee may be familiar with these experiences from their description in his second “fictional autobiography,” Youth (2002), but Coetzee’s role in the Atlas 2 project and his sustained interest in computing across his academic and literary career have been largely ignored. A page of J. M. Coetzee’s computer code poetry, dated May 30, 1965. While at the Ransom Center I was able to examine print-outs testifying to Coetzee’s poetry generation on the Atlas 2. I say examine because reading them entailed a steep learning curve on my part: some were written in binary and hexadecimal number strings. This individuated “machine code” is designed to instruct the computer, but is difficult for programmers to read and proved almost incomprehensible to me. Other documents were written in FORTRAN, the first high-level programming language, developed in the late 1950s as a language that was easier for human users to write and read, but could then be easily “translated” via a compiler into machine code. Still others were written in FORTRAN “pseudocode,” an idiosyncratic form of notation that a programmer such as Coetzee might develop (a sort of personal shorthand) that resembles FORTRAN but is not executable. Excitingly, I also was able to examine Coetzee’s born-digital materials, recovered from 5.25” and 3.5” floppy diskettes. This was invaluable, and enabled me to begin to establish a timeline of what kinds of computing hardware and software Coetzee was employing across his writing career. I am extremely grateful to the Center’s digital archivist Abby Adams for devoting so much of her time both before and after I arrived to making this collection available. Without her help, my research would have been restricted to consulting print-outs of such digital materials—useful, but less than ideal! Thanks to her I was able to establish many of the file types of Coetzee’s records, which will help me to determine the software on which he wrote the majority of his novels. While these are still early days for this research project, having access to Coetzee’s electronic files, programming records, and output has prompted a number of fascinating challenges and research questions: How do you read code? What is the “text” of a program—the machine code, the high-level programming, or the output it generates? How do you preserve an electronic file and how should the scholar access it? As more and more writers produce born-digital archives, these questions will only become more urgent, for archivists and for literary scholars. Looking at Coetzee’s other career will, I hope, help to clarify some of these issues. Rebecca Roach is a postdoctoral researcher at King’s College London. Her current book project, of which her work on Coetzee is part, is titled “Machine Talk” and explores communication and collaboration in digital literature. Her fellowship at the Ransom Center was supported by the Andrew W. Mellon Foundation Research Fellowship Endowment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939569</guid><pubDate>Sat, 15 Nov 2025 18:44:05 +0000</pubDate></item><item><title>AWS deprecates two dozen services (most of which you've never heard of)</title><link>https://www.lastweekinaws.com/blog/aws-deprecates-two-dozen-services-most-of-which-youve-never-heard-of/</link><description>&lt;doc fingerprint="ae2984765ee40ddc"&gt;
  &lt;main&gt;
    &lt;p&gt;AWS has done its quarterly housecleaning / “Googling” of its services, and deprecated what appears at first glance to be a startlingly long list. However, going through them put my mind at ease, and I’m hoping this post can do the same for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Got the Axe&lt;/head&gt;
    &lt;p&gt;19 services are mothballed (“maintenance mode”), four are being sunset (“you can’t use these anymore after an upcoming date), and one is being end of supported (“it’s finally dead”).&lt;/p&gt;
    &lt;p&gt;A few are alarming: something like “Cloud Directory” seems like it’d be hard to replace, until you think about it and realize that you’ve never used it. Now that you really think about it, you don’t know anyone who has, either.&lt;/p&gt;
    &lt;p&gt;The ones that really jumped out to me are “Amazon Glacier,” “S3 Object Lambda,” “Snowball Edge,” and “CodeCatalyst.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Ones That Matter&lt;/head&gt;
    &lt;p&gt;Glacier is a red herring. Once upon a time Glacier was its own service, with its own APIs. Now, it’s an S3 storage class. What they’re doing is removing the ability to interact with Glacier via its own APIs, which frankly have always been profoundly annoying to work with.&lt;/p&gt;
    &lt;p&gt;S3 Object Lambdas have always been a bit weird. You can still have Lambdas operate on S3, and at least actual Lambdas are likely to see service improvements; Object Lambdas have been moribund for years.&lt;/p&gt;
    &lt;p&gt;CodeCatalyst was a big deal when it launched, and afterwards nary a peep was heard from it, either from customers or from AWS. This could have been something, but the will to make it that thing clearly has departed AWS along with some of its better talent.&lt;/p&gt;
    &lt;p&gt;That leaves Snowball Edge. This is a weird one, because a bunch of customers have run local EC2 instances on them, as well as using them for data transport jobs. Those customers can continue to do so (for now, at least), but if you’re architecting something new that leverages this I’d suggest making other plans.&lt;/p&gt;
    &lt;head rend="h2"&gt;Everything Else&lt;/head&gt;
    &lt;p&gt;A bunch of the modernization stuff that’s being Googled has simply been dragged into AWS Transform. New service marketing, same capabilities, and to top it off if you’re doing a migration you at least aspirationally like to think you won’t be doing it forever; finish your damned migrations already.&lt;/p&gt;
    &lt;p&gt;IoT Greengrass V1 let you run Lambdas on your own gear, and v2 has been out for many years. I do give this one a bit of a questioning side-eye, since it’ll require updating deployed things in the customer field, but… if it’s running detached entirely and hasn’t been updated in this long, keep on going, I guess?&lt;/p&gt;
    &lt;p&gt;Systems Manager Change Manager and Systems Manager Incident Manager are being wound down, with replacements ranging from “other Systems Manager capabilities with equally bad names” to “do what sensible people do and use a best in class third party option instead.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bottom Line&lt;/head&gt;
    &lt;p&gt;Most of these deprecations appear to me to be the rotten fruit of the AWS “launch a new service to solve problem X” approach that persisted for far too long. It was clear that not all of these would be commercial successes, and I’m optimistic that clearing out their shambling corpses will let Amazon put more effort into the fewer things that actually matter for customers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939678</guid><pubDate>Sat, 15 Nov 2025 18:55:22 +0000</pubDate></item><item><title>Archimedes – A Python toolkit for hardware engineering</title><link>https://pinetreelabs.github.io/archimedes/blog/2025/introduction.html</link><description>&lt;doc fingerprint="37799a116ae50c42"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Archimedes¶&lt;/head&gt;
    &lt;p&gt;A Python toolkit for hardware engineering&lt;/p&gt;
    &lt;p&gt;By Jared Callaham • 6 Oct 2025&lt;/p&gt;
    &lt;p&gt;A great engineer (controls being no exception) has to be part hacker, part master craftsman.&lt;/p&gt;
    &lt;p&gt;You have to be a hacker because things rarely “just work” in the real world without a little… creativity. But you can’t only be a hacker; developing complex systems in aerospace, automotive, robotics, and similar industries demands a disciplined, systematic approach. You need tools that let you iterate fast and maintain a methodical workflow where changes are version-controlled, algorithms are tested systematically, and deployment is repeatable.&lt;/p&gt;
    &lt;p&gt;Modern deep learning frameworks solved this years ago — you can develop in PyTorch or JAX and deploy anywhere. But those tools were built for neural net models, GPUs, and cloud deployments, not dynamics models, MCUs, and HIL testing.&lt;/p&gt;
    &lt;p&gt;That’s where Archimedes comes in; what PyTorch did for ML deployment, Archimedes aims to do for control systems. The goal is to build an open-source “PyTorch for hardware” that gives you the productivity of Python with the deployability of C.&lt;/p&gt;
    &lt;p&gt;In short, Archimedes is a Python framework that lets you develop and analyze algorithms in NumPy and automatically generate optimized C code for embedded systems. For instance, you can write a physics model in Python, calibrate it with data, use the model to design and simulate control logic, validate with simple hardware-in-the-loop (HIL) testing, and deploy with confidence:&lt;/p&gt;
    &lt;p&gt;This is one workflow you might use with Archimedes (specifically, the one from the hardware deployment tutorial), but it’s designed to be flexible, so you’re free to build up whatever workflow suits your style and application best.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Linchpin: Python → C Code Generation¶&lt;/head&gt;
    &lt;p&gt;Archimedes started with the question, “What would you need to actually do practical control systems development in Python?”&lt;/p&gt;
    &lt;p&gt;As a high-level language, it’s hard to beat Python on design principles like progressive disclosure, flexibility, and scalability. The numerical ecosystem (NumPy, SciPy, Matplotlib, Pandas, PyTorch, etc.) is also excellent. The problem is that none of it can deploy to typical embedded systems.&lt;/p&gt;
    &lt;p&gt;If you need to deploy to hardware today, you have a few basic options:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Work in a high-level language like Python or Julia and manually translate algorithms to C code&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Work entirely in a low-level language like C/C++ or Rust&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adopt an expensive vendor-locked ecosystem that supports automatic code generation&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(Side note: While running Python itself on a microcontroller is growing in popularity for educational and hobby applications, there’s no real future for pure Python in real-time mission-critical deployments.)&lt;/p&gt;
    &lt;p&gt;However, if you could do seamless C code generation from standard NumPy code, you could layer on simulation and optimization tools, building blocks for physics modeling, testing frameworks, and other features of comprehensive controls engineering toolchains. But without the code generation, there will always be a gulf between the software and the hardware deployment.&lt;/p&gt;
    &lt;p&gt;Just to drive the point home, here’s a side-by-side of manual vs automatic coding for a common piece of sensor fusion algorithms:&lt;/p&gt;
    &lt;head class="sd-summary-title sd-card-header"&gt;Kalman Filter Comparison&lt;/head&gt;
    &lt;p&gt;Below are two implementations of a Kalman filter, an algorithm that combines noisy sensor measurements with a prediction model to estimate system state. This is what’s behind GPS navigation, spacecraft guidance, and sensor fusion in millions of devices.&lt;/p&gt;
    &lt;p&gt;On the left is hand-written C code, and on the right is a NumPy version that can be used to generate an equivalent function.&lt;/p&gt;
    &lt;p&gt;Here we’ll show an implementation for the common case of a single sensor, which avoids having to use a library for matrix inversion in C (though Archimedes does support operations like Cholesky factorization).&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdint.h&amp;gt;
#define N_STATES        4

typedef struct {
    float H[N_STATES];  // Measurement matrix (1 x n)
    float R;            // Measurement noise covariance (scalar)
} kf_params_t;

typedef struct {
    float x[N_STATES];            // State estimate
    float P[N_STATES][N_STATES]; // Estimate covariance
} kf_state_t;

typedef struct {
    float K[N_STATES];              // Kalman gain (n x 1)
    float M[N_STATES][N_STATES];    // I - K * H temporary
    float MP[N_STATES][N_STATES];   // M * P temporary
    float MPMT[N_STATES][N_STATES]; // M * P * M^T temporary
    float KRKT[N_STATES][N_STATES]; // K * R * K^T temporary
} kf_work_t;

/**
 * Kalman filter update step (scalar measurement case)
 *
 * Mathematical formulation:
 *   y = z - H·x                      (innovation)
 *   S = H·P·H^T + R                  (innovation covariance)
 *   K = P·H^T·S^(-1)                 (Kalman gain)
 *   x' = x + K·y                     (state update)
 *   P' = (I-KH)·P·(I-KH)^T + K·R·K^T (Joseph form covariance)
 *
 * @param z: Latest measurement
 * @param kf_state: Pointer to Kalman filter state struct
 * @param kf_params: Pointer to Kalman filter parameters struct
 * @param kf_work: Pointer to Kalman filter work struct (for temporaries)
 * @return: 0 on success, -1 on error
 */
int kalman_update(float z, kf_state_t *kf_state,
                  const kf_params_t *kf_params,
                  kf_work_t *kf_work) {
    #ifdef DEBUG
    if (!kf_state || !kf_params || !kf_work)
        return -1;
    #endif
    size_t i, j, k;

    // Innovation: y = z - H * x
    float y = z;
    for (i = 0; i &amp;lt; N_STATES; i++)
        y -= kf_params-&amp;gt;H[i] * kf_state-&amp;gt;x[i];

    // Innovation covariance: S = H * P * H^T + R
    float S = kf_params-&amp;gt;R;

    // Compute P * H^T (mv_mult)
    // Using K as temporary storage here
    for (i = 0; i &amp;lt; N_STATES; i++) {
        kf_work-&amp;gt;K[i] = 0.0f;
        for (j = 0; j &amp;lt; N_STATES; j++) {
            kf_work-&amp;gt;K[i] += kf_state-&amp;gt;P[i][j] * kf_params-&amp;gt;H[j];
        }
    }
    for (i = 0; i &amp;lt; N_STATES; i++)
        S += kf_params-&amp;gt;H[i] * kf_work-&amp;gt;K[i];

    // Kalman gain: K = P * H^T / S
    for (i = 0; i &amp;lt; N_STATES; i++)
        kf_work-&amp;gt;K[i] /= S;

    // Update state with feedback from new measurement: x = x + K * y
    for (i = 0; i &amp;lt; N_STATES; i++)
        kf_state-&amp;gt;x[i] += kf_work-&amp;gt;K[i] * y;

    // Joseph form update: P = (I - K * H) * P * (I - K * H)^T + K * R * K^T
    // First compute M = I - K * H
    for (i = 0; i &amp;lt; N_STATES; i++) {
        for (j = 0; j &amp;lt; N_STATES; j++) {
            if (i == j)
                kf_work-&amp;gt;M[i][j] = 1.0f - kf_work-&amp;gt;K[i] * kf_params-&amp;gt;H[j];
            else
                kf_work-&amp;gt;M[i][j] = -kf_work-&amp;gt;K[i] * kf_params-&amp;gt;H[j];
        }
    }

    // Compute M * P
    for (i = 0; i &amp;lt; N_STATES; i++) {
        for (j = 0; j &amp;lt; N_STATES; j++) {
            kf_work-&amp;gt;MP[i][j] = 0.0f;
            for (k = 0; k &amp;lt; N_STATES; k++) {
                kf_work-&amp;gt;MP[i][j] += kf_work-&amp;gt;M[i][k] * kf_state-&amp;gt;P[k][j];
            }
        }
    }

    // Compute (M * P) * M^T
    for (i = 0; i &amp;lt; N_STATES; i++) {
        for (j = 0; j &amp;lt; N_STATES; j++) {
            kf_work-&amp;gt;MPMT[i][j] = 0.0f;
            for (k = 0; k &amp;lt; N_STATES; k++) {
                kf_work-&amp;gt;MPMT[i][j] += kf_work-&amp;gt;MP[i][k] * kf_work-&amp;gt;M[j][k];
            }
        }
    }

    // Compute K * R * K^T
    for (i = 0; i &amp;lt; N_STATES; i++) {
        for (j = 0; j &amp;lt; N_STATES; j++) {
            kf_work-&amp;gt;KRKT[i][j] = kf_work-&amp;gt;K[i] * kf_params-&amp;gt;R * kf_work-&amp;gt;K[j];
        }
    }

    // Final covariance update: P = MPMT + KRKT
    for (i = 0; i &amp;lt; N_STATES; i++) {
        for (j = 0; j &amp;lt; N_STATES; j++) {
            kf_state-&amp;gt;P[i][j] = kf_work-&amp;gt;MPMT[i][j] + kf_work-&amp;gt;KRKT[i][j];
        }
    }

    return 0;
}
&lt;/code&gt;
    &lt;code&gt;@arc.compile
def kalman_update(x, P, z, H, R):
    """Update state estimate with new measurement"""
    I = np.eye(len(x))
    R = np.atleast_2d(R)  # Ensure R is 2D for matrix operations

    y = np.atleast_1d(z - H @ x)  # Innovation
    S = H @ P @ H.T + R  # Innovation covariance  
    K = P @ H.T / S  # Kalman gain (scalar S)

    # Update state with feedback from new measurement
    x_new = x + K * y

    # Joseph form covariance update
    P_new = (I - K @ H) @ P @ (I - K @ H).T + K @ R @ K.T
    
    return x_new, P_new

# Generate optimized C code:
return_names = ("x_new", "P_new")
args = (x, P, z, H, R)
arc.codegen(kalman_update, args, return_names=return_names)
&lt;/code&gt;
    &lt;p&gt;Neither of these implementations is optimized, but it gives a sense of what it looks like to work in either environment. Of course, for production hand-written code, you’d likely also use optimized linear algebra libraries like CMSIS-DSP and numerical strategies like Cholesky factorization or a square-root form for stability. But the extra numerical features are only a few extra lines in NumPy, while the hand-written C version becomes more and more complex.&lt;/p&gt;
    &lt;p&gt;This capability, and most of the other core functionality in Archimedes, is made possible by building on CasADi, a sophisticated open-source library for nonlinear optimization and algorithmic differentiation. This lets Archimedes translate your NumPy code into C++ computational graphs that support code generation, derivative calculation, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond Codegen¶&lt;/head&gt;
    &lt;p&gt;If you’re already working in C/C++/Rust, or if you don’t actually need to deploy to hardware for your application, the codegen may not speak to you. But while Python → C code generation is what makes Archimedes practical for deployment, there’s much more you can do.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compilation¶&lt;/head&gt;
    &lt;p&gt;Archimedes can “compile” a Python function into a C++ computational graph, meaning that when you call the compiled function, the entire numerical code gets executed in C++ rather than interpreted Python. For complicated functions this can achieve dramatic speedups over pure Python (5-10x even on simple benchmarks).&lt;/p&gt;
    &lt;code&gt;import numpy as np
import archimedes as arc

@arc.compile
def rotate(x, theta):
    R = np.array([
        [np.cos(theta), -np.sin(theta)],
        [np.sin(theta), np.cos(theta)],
    ], like=x)
    return R @ x

rotate(np.array([1.0, 0.0]), 0.1)
&lt;/code&gt;
    &lt;p&gt;You can embed complex functionality like ODE solves, constrained nonlinear optimization, and more directly in these computational graphs.&lt;/p&gt;
    &lt;p&gt;When you first call your function, Archimedes feeds it symbolic arrays (using CasADi’s symbolic types under the hood) that match the shape and type of your numerical inputs. As your code executes, it builds up a C++ representation of the calculation. Then, instead of operating on the numerical arrays, your code operates on these symbolic replacements, using NumPy’s array dispatch mechanism to redirect to CasADi whenever you call NumPy functions. By the end of this “tracing” step, CasADi has a full view of what the function does and can reproduce it in efficient C++. Then, any time you call that function again, the C++ equivalent is what actually gets executed.&lt;/p&gt;
    &lt;p&gt;This approach is not “Just-In-Time” (JIT) compilation in the sense used by Julia/JAX/Numba, where the Python code is literally compiled down to highly optimized platform-specific machine code. We’ll show some benchmarking in a separate post, but generally what you can expect is that these JIT-compiled frameworks will be somewhat faster than pre-compiled CasADi (and hence, Archimedes). However, by avoiding the overhead and “unrolling” of true JIT compilation, we get a massive reduction in compilation time for the kind of complex functions typical of advanced controls applications.&lt;/p&gt;
    &lt;p&gt;For more on how this works (and when it doesn’t), see the Under the Hood documentation page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simulation, Optimization, &amp;amp; Root-finding¶&lt;/head&gt;
    &lt;p&gt;Archimedes provides a SciPy-like interface to the powerful and robust CVODES solver from SUNDIALS, which is a highly efficient and time-tested implementation of a stiff/non-stiff implicit solver that even supports gradient-based sensitivity analysis:&lt;/p&gt;
    &lt;code&gt;def simulate(x0):
    xs = arc.odeint(dynamics, (t0, tf), x0, t_eval=ts)
    return xs[:, -1]

arc.jac(simulate)(x0)  # dxf/dx0
&lt;/code&gt;
    &lt;p&gt;We also have a SciPy-like optimization interface that can solve constrained nonlinear problems with IPOPT:&lt;/p&gt;
    &lt;code&gt;# Rosenbrock problem
def f(x):
    return 100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2

result = arc.minimize(f, x0=[-1.0, 1.0])
&lt;/code&gt;
    &lt;p&gt;and a root-finding interface for iteratively solving nonlinear algebraic systems using Newton iterations and similar methods:&lt;/p&gt;
    &lt;code&gt;def f(x):
    return np.array([
        x[0] + 0.5 * (x[0] - x[1])**3 - 1.0,
        0.5 * (x[1] - x[0])**3 + x[1]
    ], like=x)

x = arc.root(f, x0=np.array([0.0, 0.0]))
&lt;/code&gt;
    &lt;p&gt;These solves can also be embedded in compiled computational graphs for accelerated simulation and optimization.&lt;/p&gt;
    &lt;head rend="h3"&gt;Automatic Differentiation¶&lt;/head&gt;
    &lt;p&gt;Compilation into a CasADi computational graph unlocks two critical capabilities: execution speed and automatic differentiation. This means that you can easily and accurately calculate derivatives of your functions:&lt;/p&gt;
    &lt;code&gt;def lotka_volterra(t, x):
    a, b, c, d = 1.5, 1.0, 1.0, 3.0
    return np.hstack([
        a * x[0] - b * x[0] * x[1],
        c * x[0] * x[1] - d * x[1],
    ])

# Linearize the system
J = arc.jac(dynamics, argnums=1)
print(J(0.0, [1.0, 1.0]))
&lt;/code&gt;
    &lt;p&gt;Besides linearizing models for stability analysis and controller design, this is a feature you may not directly use very often. But gradients and Jacobians are used pervasively in numerical methods:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Optimization solvers use gradients of the objective, Jacobians of the constraints, and sometimes even Hessian information&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Simulation algorithms use Jacobians of the dynamics model for implicit solvers, especially for “stiff” ODE/DAE problems&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Root-finding solvers like Newton’s method use Jacobians at every iteration to find an improved guess at the solution point&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So when you do parameter estimation, trajectory optimization, trim point identification, or even just call &lt;code&gt;odeint&lt;/code&gt;, you don’t think about “autodiff”, but it’s happening behind the scenes to solve your problem.&lt;/p&gt;
    &lt;p&gt;Traditional scientific computing packages like SciPy and MATLAB usually fall back to slow and inaccurate finite differencing unless you provide manually implemented gradients, Jacobians, etc. - but for anything but the simplest problems this is prohibitively complicated to calculate and implement.&lt;/p&gt;
    &lt;p&gt;Newer frameworks like Julia, JAX, and PyTorch rely much more heavily on autodiff, but none of these are tailored towards hardware and controls engineering applications. My personal experience has been that CasADi (the autodiff framework used under the hood by Archimedes) has far and away the best autodiff system for the kinds of large, sparse problems that commonly arise in engineering (like parameter estimation, trajectory optimization, model-predictive control, etc.).&lt;/p&gt;
    &lt;p&gt;All that is to say, the derivatives are there if you need them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Structured Data Types¶&lt;/head&gt;
    &lt;p&gt;Most numerical codes are naturally written to operate on flat vectors. This makes sense for the implementation of an optimization algorithm or ODE solver, but physical systems are usually more naturally conceived of as hierarchical. For instance, a satellite has position, velocity, attitude, angular velocity, battery state, thermal state, etc. To work with typical numerical codes, you have to either keep track of what entries in your array are which physical state or manually flatten/unflatten every time you call a routine that expects a flat vector.&lt;/p&gt;
    &lt;p&gt;That might be fine the first time, but what if you want to try a higher-fidelity battery model that has twice as many dynamic states? It quickly becomes a nightmare to maintain these kinds of codes, and the result is that you waste cycles on keeping all of this straight, and you lose the practical capability to explore multi-fidelity modeling.&lt;/p&gt;
    &lt;p&gt;This also comes up frequently in deep learning: models are naturally organized as hierarchical modules with trainable parameters. This is the root of the &lt;code&gt;nn.Module&lt;/code&gt; in PyTorch and the “PyTree” concept in JAX.
Modern ML frameworks (specifically JAX and PyTorch) have developed a nice set of solutions around working with this kind of hierarchically structured data.&lt;/p&gt;
    &lt;p&gt;But this hierarchical data and logic might even be more common in engineering. Physical systems are naturally organized into subsystems and components that have well-defined interfaces, and each of these might have its own dynamic state and configurable parameters. Hierarchical data structures can mirror this physical system decomposition.&lt;/p&gt;
    &lt;p&gt;Archimedes takes inspiration from these frameworks and supports “tree operations” (functions applied to hierarchical data) and a &lt;code&gt;@struct&lt;/code&gt; decorator to create tree-compatible data classes:&lt;/p&gt;
    &lt;code&gt;@arc.struct
class PointMass:
    pos: np.ndarray
    vel: np.ndarray

state = PointMass(np.zeros(3), np.ones(3))  # state.pos, state.vel
flat_state, unravel = arc.tree.ravel(state)  # flat_state is a vector
state = unravel(flat_state)  # Back to a PointMass instance
&lt;/code&gt;
    &lt;p&gt;These &lt;code&gt;@struct&lt;/code&gt;-decorated classes can be nested inside one another, flattened to/from a 1D vector, and used to auto-generate nested &lt;code&gt;struct&lt;/code&gt; types in deployable C code.
If a &lt;code&gt;PointMass&lt;/code&gt; is used as an argument to a codegen function, it will become:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    float pos[3];
    float vel[3];
} point_mass_t;
&lt;/code&gt;
    &lt;p&gt;This gives you a predictable and intuitive way to switch back and forth between Python and auto-generated C.&lt;/p&gt;
    &lt;p&gt;For much more on structured data types, see Structured Data Types, Hierarchical Systems Modeling, and the C Code Generation tutorial series.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Another Framework?¶&lt;/head&gt;
    &lt;p&gt;There are lots of modeling and simulation tools out there, from rock-solid commercial tools building on 30-year legacies to innovative modern frameworks experimenting with new languages, JIT-compilation, and physics-informed ML.&lt;/p&gt;
    &lt;p&gt;I created Archimedes because none of these really solved the problems I was having in my own work. Codebases that started out being logical and well-organized invariably ended up growing into a gnarled, difficult-to-maintain mass in order to support increasingly complex models and analyses. Then when it’s time to move towards testing and production, you’re back to square one to translate to C code.&lt;/p&gt;
    &lt;p&gt;Granted, these complaints might just indicate that I’m not a great software developer - but I’m not a software developer. That’s the point. I wanted a framework that would let me write code that looked as clean as a deep learning repository in PyTorch, but would also be high-performance for simulation and optimization, and had a path to hardware deployment. After seeing it perform in my own work, I’m convinced this approach - NumPy-based development with automatic C deployment - could help how control systems engineers develop and deploy algorithms.&lt;/p&gt;
    &lt;p&gt;One last comment: from personal experience, it takes a little time (but maybe less than you think) to grok the functional programming and hierarchical data types that are core to Archimedes. (I’ve spent a lot of time in JAX, which heavily influenced the design of this library.) It’s different than what you might be used to, and there are also some quirks and gotchas related to compilation and control flow.&lt;/p&gt;
    &lt;p&gt;But these concepts do actually map quite neatly to our mental/mathematical models for dynamical systems and control algorithms. Once it clicks, you’ll be able to write clean, modular, maintainable workflows that cut down your iteration time and make it faster to design, debug, deploy, and debug, and debug, and redesign, and debug, and…&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Started¶&lt;/head&gt;
    &lt;p&gt;If you want to give Archimedes a try, it’s easy to get started. The Quickstart page will walk you through the setup, and Getting Started will teach you the basic concepts.&lt;/p&gt;
    &lt;p&gt;Then there are tutorials and deep dives on:&lt;/p&gt;
    &lt;p&gt;The Hardware Deployment tutorial is a bit more advanced, but shows an end-to-end example of the kinds of workflows you can build in Archimedes.&lt;/p&gt;
    &lt;p&gt;Upcoming tutorial and example content includes 6dof flight vehicle dynamics, rotor aerodynamics, system identification, low-cost HIL testing workflows, and deep dives on C code generation.&lt;/p&gt;
    &lt;p&gt;To see where the project is headed and some more detail on the vision, also check out the roadmap.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-ramp Projects¶&lt;/head&gt;
    &lt;p&gt;Once you learn the basics, I bet in an hour or two you could:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Deploy a PI temperature controller to an Arduino&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Write an integrator for the IMU strapdown equations&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run parameter estimation on some step response data you have lying around&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Design an energy-shaping controller for a pendulum&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Benchmark some old hand-written C code against the auto-generated equivalent (and share the results)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you have a cool first project that you’re willing to share, feel free to post about it on the Discussions page - if it’s interesting it could become its own tutorial or blog post.&lt;/p&gt;
    &lt;head rend="h3"&gt;“Public Beta” Status¶&lt;/head&gt;
    &lt;p&gt;This post marks the release of Archimedes in “public beta” (v0.X.X). This means that the core functionality is there and has already been tested in practical applications. The API is also well-tested and stable; while it is likely to evolve in time, it will change with semantic versioning conventions, meaning smooth upgrade paths and deprecation notices. The library will remain in beta for 6-12 months to allow for community feedback and API maturation across ongoing real-world applications.&lt;/p&gt;
    &lt;p&gt;For symbolic/numeric reliability in particular, Archimedes gets a big leg up by using CasADi as its backend, which has an excellent track record and is widely and actively used and tested in a variety of applications.&lt;/p&gt;
    &lt;p&gt;All that is to say, between now and the “v1.0” release you can expect things to be largely stable, but this additional time builds in a cushion to work out any kinks.&lt;/p&gt;
    &lt;p&gt;Ongoing development priorities are outlined in detail in the roadmap, but key focus areas include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Hybrid Simulations: Support for DAEs, zero-crossing events, multirate control logic&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hardware Deployment: Improved support for HIL testing, static analysis, and profiling/telemetry&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Physics Modeling: Built-in functionality like reference frames, kinematic trees, polynomial/spline primitives, and templates for domain-specific components.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Algorithm Development: State machines, trajectory optimization, MPC, sensor fusion, uncertainty quantification, etc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Stay Updated¶&lt;/head&gt;
    &lt;p&gt;For updates on Archimedes, including release announcements, new features, blog posts, application examples, and case studies, subscribe to the free newsletter:&lt;/p&gt;
    &lt;p&gt;You can expect infrequent posts (maybe monthly) with a strong technical focus - no ads, spam, or paywalls.&lt;/p&gt;
    &lt;head rend="h3"&gt;Supporting Archimedes¶&lt;/head&gt;
    &lt;p&gt;This post might read a bit like ad copy, but Archimedes is a free, open-source project. The codebase, ongoing status, and discussions all live on the GitHub repository.&lt;/p&gt;
    &lt;p&gt;If you want to support it, the best thing you can do right now is try it out and give feedback. What worked well? What didn’t work? What did you like? What was confusing? What was confusing at first but you liked once you got used to it? What would you like to try with Archimedes? What would you like to try but there’s a functionality gap?&lt;/p&gt;
    &lt;p&gt;The Discussions page is a great place to share general feedback, and bug reports or feature requests are welcome on the Issues tab.&lt;/p&gt;
    &lt;p&gt;Besides feedback, other easy ways to support the project include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;⭐ Star the Repository: This shows support and interest and helps others discover the project&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;📢 Spread the Word: Think anyone you know might be interested?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🐛 Report Issues: Detailed bug reports, documentation gaps, and feature requests are invaluable&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🗞️ Stay in the Loop: Subscribe to the newsletter for updates and announcements&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks for checking out the project!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45939938</guid><pubDate>Sat, 15 Nov 2025 19:29:32 +0000</pubDate></item><item><title>Caffeinated coffee consumption or abstinence to reduce atrial fibrillation</title><link>https://jamanetwork.com/journals/jama/fullarticle/2841253</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45940030</guid><pubDate>Sat, 15 Nov 2025 19:43:39 +0000</pubDate></item><item><title>AMD continues to chip away at Intel's x86 market share</title><link>https://www.tomshardware.com/pc-components/cpus/amd-continues-to-chip-away-at-intels-x86-market-share-company-now-sells-over-25-percent-of-all-x86-chips-and-powers-33-percent-of-all-desktop-systems</link><description>&lt;doc fingerprint="264c453594b3562f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AMD continues to chip away at Intel's X86 market share — company now sells over 25% of all x86 chips and powers 33% of all desktop systems&lt;/head&gt;
    &lt;p&gt;AMD increased its share across all markets served by x86 processors at Intel's expense in the third quarter of 2025, according to Mercury Research. Intel is holding strong, and as its latest offerings for client and server systems got significantly more competitive than they were several quarters ago, the pace of AMD's gains has slowed down considerably. However, during the quarter, AMD achieved two important milestones: it now commands shipments of over 25% of all x86 CPUs, and it now ships over 33% (one-third) of desktop x86 CPUs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Abnormal market performance: Shipments of x86 CPUs flat quarter-over-quarter&lt;/head&gt;
    &lt;p&gt;Normally, we start our coverage of the x86 market based on data from Mercury Research with client CPUs, but the third quarter was very unusual as unit shipments of x86 CPUs were flat quarter-over-quarter (QoQ), which significantly contradicts the normal seasonal bump when PC makers start to prep for the back-to-school (BTS) season in June – July as well as Christmas season in September.&lt;/p&gt;
    &lt;p&gt;Indeed, PC and server makers increased their CPU procurements in Q3, but the weakness came almost entirely from Intel, which saw sharp drops in IoT/SoC and entry-level mobile processors as it shifted manufacturing capacity toward server processors, and strong shipments of such parts in Q2. By contrast, AMD's unit shipments were flat to slightly up, so the company gained share sequentially and year-over-year (YoY), hitting two psychologically important milestones.&lt;/p&gt;
    &lt;p&gt;For the first time in years, AMD's unit share of all x86 client and server CPUs shipped exceeded 25% and now stands at 25.6%, up from 24.2% in the prior quarter and up from 24% in the same quarter a year ago. Intel still commands 74.4%, but it lost some share in certain segments, allowing AMD to hit an important milestone amid a market shrink.&lt;/p&gt;
    &lt;p&gt;If we add embedded, IoT, and game consoles SoCs to the equation, then AMD's share looks even more impressive: a 30.9% share of all x86-based chips, up from 25% in the third quarter of 2024. While Intel maintains its dominant position with 69.1%, its 5.9% YoY share loss does not look very good. Yet, it should be noted that AMD shipped significantly more game console SoCs in the third quarter this year compared to the third quarter of 2024, which inflated its results a bit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Client CPUs: AMD maintains market share&lt;/head&gt;
    &lt;p&gt;Strong desktop and mobile CPU lineups as well as Intel struggles with supply of small-core mobile CPUs and prior-generation desktop offerings allowed AMD to slightly outgrow Intel in the third quarter both sequentially and year-over-year, according to data from Mercury Research.&lt;/p&gt;
    &lt;p&gt;AMD's client unit share rose to 25.4%, up 1.5% QoQ and 1.4% YoY, driven mainly by strong desktop momentum. By contrast, Intel's share fell to 74.6%, down 1.5% sequentially and 1.4% compared to the same quarter a year ago, as its entry-level mobile shipments were constrained by reduced small-core CPU supply. Although Intel still dominates in total volume, Q3's numbers reflect the ongoing pressure on its mobile PC shipments and AMD's sustained improvement in desktops.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;head rend="h2"&gt;Desktop CPUs: Another great quarter for AMD&lt;/head&gt;
    &lt;p&gt;Both AMD and Intel saw strong sequential unit shipments growth in Q3 2025 on the desktop CPU market, although Q2 -&amp;gt; Q3 market growth in general was lower than normal seasonal rates, according to Mercury Research.&lt;/p&gt;
    &lt;p&gt;AMD grew far faster thanks to the popularity of its Ryzen 9000-series 'Granite Ridge' CPUs in the enthusiast and performance tiers, allowing the company to reach another all-time high: a 33.6% share of the desktop PC market, up from 32.2% in the prior quarter and a gain of 5.2% year-over-year. If we compare AMD's current share to its share in the second quarter of 2024, the gain would be a whopping 10.6%&lt;/p&gt;
    &lt;p&gt;Intel still held the majority of desktop shipments, but its share fell from 67.8% to 66.4% QoQ, and from 71.7% YoY, reflecting AMD’s continued gains in both the mainstream and high-end segments and shortages of Intel's 13th and 14th Core 'Raptor Lake' processors that are still popular three years after their original release in 2022.&lt;/p&gt;
    &lt;p&gt;On the revenue front, AMD reached another record quarter for desktop CPU revenue, driven by higher shipments and a strong mix of premium SKUs, as the company noted in its conference call a week ago. Intel's revenue position weakened as its unit share declined and AMD absorbed more of the market's high-margin demand. Mercury Research notes that AMD's revenue growth in desktops significantly outpaced its unit growth, which confirms that the red company continued to strengthen its position in the most profitable parts of the desktop market.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mobile CPUs: AMD starts to regain share&lt;/head&gt;
    &lt;p&gt;AMD lost market share to Intel in the mobile CPU space in Q1 and Q2 2025, but the company outperformed Intel in Q3 2025 on a sequential basis, gaining unit share as Intel struggled with reduced shipments of its entry-level small-core processors.&lt;/p&gt;
    &lt;p&gt;AMD's mobile CPU unit share rose from 20.6% in Q2 to 21.9% in Q3, a sequential gain of 1.4%, while Intel's share fell from 79.4% to 78.1%, down 1.4% QoQ. Intel did manage to grow shipments slightly, but well below normal seasonal levels, allowing AMD to capture market share during the quarter, according to Mercury Research. Nonetheless, AMD lost 0.4% market share year-over-year, whereas Intel gained 0.4%.&lt;/p&gt;
    &lt;p&gt;On the revenue side, the mix probably favored both companies but helped AMD more. Intel's shortage of low-end CPUs pushed its average selling prices upward, while AMD — which does not have direct rivals for Intel Atom-like SoCs — benefited from increased shipments of mid-range and premium Ryzen mobile processors as Intel faced some shortages on this side of the spectrum as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Server CPUs: AMD stagnates amid product mix improvement&lt;/head&gt;
    &lt;p&gt;In the server CPU market, Q3 2025 saw relatively flat unit shipments overall, but while AMD managed to edge out another small gain, its gains have been negligible this year. Then again, although the sequential movement was modest, it continued the longer-term trend of AMD steadily expanding its presence in x86 servers.&lt;/p&gt;
    &lt;p&gt;AMD's server unit share increased from 27.3% in Q2 to 27.8% in Q3, while Intel's share slipped 0.5% to 72.2%. Both companies saw YoY shipment growth, but AMD's increase was stronger, helping it push unit share higher compared to the same quarter a year earlier, so overall things look good for AMD.&lt;/p&gt;
    &lt;p&gt;Most of the real action in Q3 came from product mix rather than volume, according to Mercury. AMD's EPYC 'Turin' ramp accelerated, driving stronger demand for high-core-count EPYC processors, while Intel saw increasing adoption of Xeon 6 'Granite Rapids,' which helped lift its average selling prices despite slightly lower unit volumes.&lt;/p&gt;
    &lt;p&gt;On the revenue side, AMD hit another all-time high, as the mix shifted heavily toward its latest and more expensive EPYC 9005-series platform. The combination of flat unit shipments and rising prices meant that AMD's server revenue continues to grow significantly faster than its unit share, while Intel's revenue gains were more limited due to modest declines in its overall shipment mix.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;In terms of unit share, AMD continued to gain ground in Q3 2025 across nearly all major x86 segments, helped by strong desktop growth driven by the halo effect of range-topping Ryzen 9000-series CPUs and Intel's struggles to ship enough previous-generation desktop CPUs, as well as the relatively low popularity of its latest offerings for desktops. As a result, AMD expanded its presence in client CPUs, reached a new high in desktops, and inched upward in servers, while Intel's share declined modestly as supply constraints and product transitions limited its ability to address all orders. Although Intel still led the market in total shipments, the balance continued shifting gradually toward AMD.&lt;/p&gt;
    &lt;p&gt;In terms of revenue, AMD delivered even stronger results, setting new highs in both desktop and server segments thanks to rising sales of premium processors and the ramp of its newest platforms. Intel's revenue performance was more mixed: constrained low-end supply pushed its average prices higher, but it ceded more of the high-margin market to AMD, especially in desktops and enterprise servers. Then again, the company announced price hikes of its popular Raptor Lake processors, which will impact its results in Q4.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Anton Shilov is a contributing writer at Tom’s Hardware. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;CerianK&lt;/header&gt;I performed a little bit of math, and I find it interesting that those with AMD desktop CPUs seem to be almost twice as likely to report results to PassMark, which skews their results to make it look like AMD and Intel each have about a 50% share. Of course PassMark is aware of this, and notes this effect, but I had not calculated it before.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;King_V&lt;/header&gt;Reply&lt;quote&gt;AMD continues to chip away at Intel's X86 market share&lt;/quote&gt;This upsets me only because I didn't think of the pun first!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Lamarr the Strelok&lt;/header&gt;I'm upset I missed the pun in the first place. Time for some cat videos since I must be crabby.I usually catch those.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gururu&lt;/header&gt;The window is over. They had a chance to take 50% market share the last couple years Intel was on the brink of dissolution. Now Intel is drowning in cash to push product. Too little too late.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;TerryLaze&lt;/header&gt;Reply&lt;quote/&gt;They never had that chance, producing chips at tsmc costs money so they can only make that many, and that amount is far below 50% , and even if they somehow gotten the money they wouldn't have been able to get the capacity from tsmc because everybody uses them.Gururu said:The window is over. They had a chance to take 50% market share the last couple years&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;George³&lt;/header&gt;Bad or good depends of point of view is fact that zero of latest generations CPU didn't produced from companies which created it's architecture. Including Intel which also use TSMC for part of tiles and don't know which company for packaging process. Last Intel foundry only series is Raptor Lake refresh. Intel....Intel is now also having to compete with others for TSMC's production capacity.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;hotaru251&lt;/header&gt;Reply&lt;quote/&gt;they've ALWAYS had mroe $$ than AMD.Gururu said:Now Intel is drowning in cash to push product. Too little too late.&lt;lb/&gt;Money isnt the end all in their business...also they are losing talent left and right.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;usertests&lt;/header&gt;Reply&lt;quote/&gt;As long as AMD stays around 30-40% in desktop market share while making higher margins, they are in a good place. Mobile and server are more important and they are doing more impressive things there.Gururu said:The window is over. They had a chance to take 50% market share the last couple years Intel was on the brink of dissolution. Now Intel is drowning in cash to push product. Too little too late.&lt;lb/&gt;Nova Lake is going to deliver more MT perf than almost anybody needs at the top. AMD has neglected MT at the low-end, but Zen 6 and Zen 7 should address that with increased core counts.&lt;lb/&gt;The 9800X3D is roughly 30% faster in gaming than the 14900K, and 35% faster than the 285K, which is just shocking. I doubt Intel will bridge that gap unless they bring their "bLLC" X3D-like competitor to the table, and even then it's not a sure thing.&lt;lb/&gt;Nova Lake might be out for 2-6 months before Zen 6 appears. Motherboards will be expensive, and if DDR5 is still super expensive by then, demand for new builds will be suppressed. Zen 6 will drop into AM5 boards shortly after and extend any lead Zen 5 X3D had, bringing increased cache sizes for the first time since Zen 3.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;bit_user&lt;/header&gt;Reply&lt;quote/&gt;Huh? Why? Is it just because AMD is more likely to be used by enthusiasts, who actually run stuff like PassMark?CerianK said:I performed a little bit of math, and I find it interesting that those with AMD desktop CPUs seem to be almost twice as likely to report results to PassMark,&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45940413</guid><pubDate>Sat, 15 Nov 2025 20:35:33 +0000</pubDate></item></channel></rss>