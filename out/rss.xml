<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 16 Dec 2025 13:52:39 +0000</lastBuildDate><item><title>Umbrel – Personal Cloud</title><link>https://umbrel.com</link><description>&lt;doc fingerprint="c5e113d09df9eb66"&gt;
  &lt;main&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;What can I do with umbrelOS?&lt;/p&gt;
    &lt;p&gt;What can I do with umbrelOS?&lt;/p&gt;
    &lt;p&gt;The superpowers are&lt;/p&gt;
    &lt;p&gt;The superpowers are&lt;/p&gt;
    &lt;p&gt;endlessssssssss&lt;/p&gt;
    &lt;p&gt;endlessssssssss&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Google Drive that lives in your home.&lt;/p&gt;
    &lt;p&gt;With Nextcloud, store your documents, calendar, contacts and photos on your Umbrel instead of Google's servers.&lt;/p&gt;
    &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
    &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
    &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
    &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
    &lt;p&gt;Automate your home.&lt;/p&gt;
    &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
    &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
    &lt;p&gt;Get Pi-holeÂ® on your Umbrel and block ads on your entire network. Yes â the entire network, not just your browser.&lt;/p&gt;
    &lt;p&gt;That's all. Except not.&lt;/p&gt;
    &lt;p&gt;Thereâs an entire&lt;/p&gt;
    &lt;p&gt;app store.&lt;/p&gt;
    &lt;p&gt;Discover amazing self-hosted apps in the Umbrel App Store and install them in one click on umbrelOS.&lt;/p&gt;
    &lt;p&gt;That's all. Except not.&lt;/p&gt;
    &lt;p&gt;Thereâs an entire&lt;/p&gt;
    &lt;p&gt;app store.&lt;/p&gt;
    &lt;p&gt;Discover amazing self-hosted apps in the Umbrel App Store and install them in one click on umbrelOS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Bitcoin Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Shell&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Samourai&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Plex&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nostr Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ghostfolio&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Torq&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SimpleTorrent&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Bitcoin Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Shell&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Samourai&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Plex&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nostr Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ghostfolio&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Torq&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SimpleTorrent&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;mempool&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WoofBot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LibreOffice&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sphinx Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tailscale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Firefox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhotoPrism&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trilium Notes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;n8n&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;mempool&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WoofBot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LibreOffice&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sphinx Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tailscale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Firefox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhotoPrism&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trilium Notes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;n8n&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Community&lt;/p&gt;
    &lt;p&gt;Community&lt;/p&gt;
    &lt;p&gt;A place to get your questions answered, and to connect with fellow sovereign individuals.&lt;/p&gt;
    &lt;p&gt;Support&lt;/p&gt;
    &lt;p&gt;Support&lt;/p&gt;
    &lt;p&gt;Get help with installing and troubleshooting umbrelOS and Umbrel Home.&lt;/p&gt;
    &lt;p&gt;Careers&lt;/p&gt;
    &lt;p&gt;Careers&lt;/p&gt;
    &lt;p&gt;Weâre hiring! Join us and shape the future of Umbrel.&lt;/p&gt;
    &lt;p&gt;Stay in the loop&lt;/p&gt;
    &lt;p&gt;Stay in the loop&lt;/p&gt;
    &lt;p&gt;Follow our journey in enabling sovereign individuals truly own their data.&lt;/p&gt;
    &lt;p&gt;Better yet, be a part of it.&lt;/p&gt;
    &lt;p&gt;Follow our journey in enabling sovereign individuals truly own their data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46279187</guid><pubDate>Mon, 15 Dec 2025 19:27:08 +0000</pubDate></item><item><title>The appropriate amount of effort is zero</title><link>https://expandingawareness.org/blog/the-appropriate-amount-of-effort-is-zero/</link><description>&lt;doc fingerprint="21475376a7f44cfd"&gt;
  &lt;main&gt;
    &lt;p&gt;Most people put too much effort into everything they do. Here’s a good example from Kristijan around tension in his hands when touching and holding things:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Something clicked about inhibition and non-doing (in Alexander Technique), and the strongest effect has been a relaxation of my hands.&lt;/p&gt;— Kristijan (@kristijan_moves) August 20, 2025&lt;lb/&gt;Like I was touching and holding things with 40% more tension than required for that object or activity.@m_ashcroft any thoughts?&lt;/quote&gt;
    &lt;p&gt;It’s a great example, because gripping too tightly, as we might with the hands, is a great metaphor for what it’s like everywhere else in your system. There’s a pattern of pervasive over-gripping that, once you start to look for it, you will find everywhere.&lt;/p&gt;
    &lt;p&gt;There is an appropriate amount of energy required for each activity. Holding a cup, turning a steering wheel, or writing a blog post all need exactly the amount of energy that they need. This may sound like a truism, but if it were so obvious, why do many drivers often realise they are driving with a vice-like grip, with tension running up into their shoulders and jaws?&lt;/p&gt;
    &lt;p&gt;Let me share my slightly unusual definition of “effort”: it’s the felt experience of expending energy beyond what an activity requires, like tensing your brow when you try to understand something, or the excess tension in your hand when you hold your phone[1].&lt;/p&gt;
    &lt;p&gt;Using this definition, it’s clear that the appropriate amount of effort for any activity is zero.&lt;/p&gt;
    &lt;p&gt;This idea is where the concept of non-doing can trip people up, because it doesn’t mean no action. It means no effort, even though the amount of energy required could be large. Or, to borrow from Daoist wisdom:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Nature does not hurry, yet everything is accomplished." — Lao Tzu&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Nature is an enormous flow of energy, yet nature makes no effort. Everything nature does is perfectly well-suited to what it does, and it cannot be otherwise. This is why non-doing comes with a felt experience of effortlessness, when it seems like everything is working exactly the way it’s supposed to be.&lt;/p&gt;
    &lt;p&gt;Consider this quote from Katie Ledecky who, with 14 Olympic medals, is described as “the most decorated female swimmer in history”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I felt so relaxed. It just felt very easy, and that's why it surprised me that I had broken my world record.” — Katie Ledecky&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Not only that, but trying too hard can reduce performance. Here’s marathoner Ryan Hall:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“… you don't get your best performances by trying harder. When you see the guy who wins the race, he usually jogs out of it waving to the crowd, feeling good. The people who look the worst come in after the top guy.”[2] – Ryan Hall&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So why is it so common to effort when it both feels harder and reduces performance?&lt;/p&gt;
    &lt;p&gt;For one thing, there are all kinds of societal scripts in the modern age that push us in that direction. All those hustle bros captured by Total Work push their grindset worldview, recapitulating the Protestant work ethic for new audiences. The influence of these cultural waters on our psychophysical wiring can’t be overstated.&lt;/p&gt;
    &lt;p&gt;These scripts team up with one of the core principles of Alexander Technique: Faulty Sensory Appreciation. When you try so hard all the time, that level of effort feels familiar and you stop noticing it. Put another way, years of overdoing mis-calibrate your senses so effort feels right and ease feels wrong. If you follow your feelings, you are guided back to that same old familiar where you’re trying too hard without even realising it.&lt;/p&gt;
    &lt;p&gt;By the way, this phenomenon happens all the time in many other domains, and can be the cause of much trouble.&lt;/p&gt;
    &lt;p&gt;What all this means is that when you pull back the effort below your familiar baseline, it can feel unfamiliar, like you’re not trying hard enough, and those societal scripts I mentioned before can make this experience hard to stay in, even if you’re now closer to the appropriate amount of energy needed.&lt;/p&gt;
    &lt;p&gt;The way out of this is to experiment with feeling the unfamiliarity of trying less hard and seeing what it’s like. In Kristijan’s case, he played with this for long enough that his sensory perception updated to reflect what was going on more accurately, and he was able to feel that he had been using too much tension before.&lt;/p&gt;
    &lt;p&gt;So I invite you to go about your day and practice dropping the effort. See how weird it feels, but notice how the activity is still getting done. See what it’s like to drop the energy too low, where you might become lethargic or your performance drops. Notice the sweet spot as a surprising experience of ease and a kind of elegance: the less you grip, the smoother and more precise the movement.&lt;/p&gt;
    &lt;p&gt;Happy experimenting!&lt;/p&gt;
    &lt;p&gt;If you get hung up on this definition, just substitute it for something like “over-efforting” or “trying too hard”, as the underlying phenomenon is the same regardless of what you call it. ↩︎&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46279825</guid><pubDate>Mon, 15 Dec 2025 20:09:48 +0000</pubDate></item><item><title>Secret Documents Show Pepsi and Walmart Colluded to Raise Food Prices</title><link>https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46280887</guid><pubDate>Mon, 15 Dec 2025 21:24:06 +0000</pubDate></item><item><title>Economics of Orbital vs. Terrestrial Data Centers</title><link>https://andrewmccalip.com/space-datacenters</link><description>&lt;doc fingerprint="f9bb25352574da8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt; Economics of Orbital vs&lt;lb/&gt; Terrestrial Data Centers &lt;/head&gt;&lt;p&gt;It might not be rational&lt;/p&gt;&lt;p&gt;But&lt;/p&gt;&lt;p&gt;It might be physically possible&lt;/p&gt;&lt;p&gt;Before we get nerd sniped by the shiny engineering details, ask the only question that matters. Why compute in orbit? Why should a watt or a flop 250 miles up be more valuable than one on the surface? What advantage justifies moving something as mundane as matrix multiplication into LEO?&lt;/p&gt;&lt;p&gt;That "why" is almost missing from the public conversation. People jump straight to hardware and hand-wave the business case, as if the economics are self-evident. They aren't. A lot of the energy here is FOMO and aesthetic futurism, not a grounded value proposition.&lt;/p&gt;&lt;p&gt;Note: This page is built from publicly available information and first-principles modeling. No proprietary data. These are my personal thoughts and do not represent the views of any company or organization.&lt;/p&gt;&lt;head rend="h3"&gt;Orbital Solar&lt;/head&gt;&lt;p&gt;$31.2B&lt;/p&gt;&lt;head rend="h3"&gt;Terrestrial&lt;/head&gt;&lt;p&gt;$14.8B&lt;/p&gt;&lt;head rend="h4"&gt;Orbital Solar&lt;/head&gt;&lt;head rend="h4"&gt;Terrestrial (On-Site CCGT)&lt;/head&gt;&lt;head rend="h3"&gt;Orbital Solar&lt;/head&gt;&lt;head rend="h3"&gt;Terrestrial&lt;/head&gt;&lt;head rend="h2"&gt;Model Assumptions&lt;/head&gt;&lt;head rend="h4"&gt;Global&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;GPUs not included—this models everything upstream of compute hardware&lt;/item&gt;&lt;item&gt;Target capacity: 1 GW nameplate electrical&lt;/item&gt;&lt;item&gt;Analysis period: 5 years&lt;/item&gt;&lt;item&gt;All figures in 2025 USD; excludes financing, taxes, incentives, and FMV&lt;/item&gt;&lt;item&gt;Full availability assumed (no downtime derates), no insurance/logistics overheads&lt;/item&gt;&lt;/list&gt;&lt;head rend="h4"&gt;Orbital Solar (Starlink-class)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Single bus class (Starlink V2 Mini heritage) scaled linearly to target power&lt;/item&gt;&lt;item&gt;Station-keeping propellant mass assumed rolled into Starlink-like specific power (W/kg)&lt;/item&gt;&lt;item&gt;Linear solar cell degradation assumed; actual silicon with coverglass shows steep-then-shallow curve&lt;/item&gt;&lt;item&gt;Solar margin = extra initial capacity to maintain average power over lifetime (not end-of-life)&lt;/item&gt;&lt;item&gt;GPU margin = cumulative expected failures over analysis period (replacement cost, not extra capacity)&lt;/item&gt;&lt;item&gt;Optimal fairing packing assumed regardless of satellite size (kW); no packing penalty modeled&lt;/item&gt;&lt;item&gt;No additional mass for liquid cooling loop infrastructure; likely needed but not included&lt;/item&gt;&lt;item&gt;All mass delivered to LEO; no on-orbit servicing/logistics&lt;/item&gt;&lt;item&gt;Launch pricing applied to total delivered mass; no cadence/manifest constraints modeled&lt;/item&gt;&lt;item&gt;Thermal: only solar array area used as radiator; no dedicated radiator mass assumed&lt;/item&gt;&lt;item&gt;Radiation/shielding impacts on mass ignored; no degradation of structures beyond panel aging&lt;/item&gt;&lt;item&gt;No disposal, de-orbit, or regulatory compliance costs included&lt;/item&gt;&lt;item&gt;Ops overhead and NRE treated as flat cost adders; no learning-curve discounts&lt;/item&gt;&lt;item&gt;No adjustments for permitting or regulatory delay&lt;/item&gt;&lt;/list&gt;&lt;head rend="h4"&gt;Terrestrial (On-Site CCGT)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;On-site H-Class CCGT at the fence line; grid interconnect/transmission not costed&lt;/item&gt;&lt;item&gt;Capex buckets embed site prep/land; permitting, taxes, and financing excluded&lt;/item&gt;&lt;item&gt;Fuel price held flat; no carbon price, hedging, or escalation modeled&lt;/item&gt;&lt;item&gt;Water/cooling availability assumed; no scarcity or discharge penalties&lt;/item&gt;&lt;item&gt;Fixed PUE and capacity factor; no forced-outage or maintenance derates applied&lt;/item&gt;&lt;item&gt;No efficiency gains or technology learning assumed over time for terrestrial plant&lt;/item&gt;&lt;item&gt;No adjustments for permitting or regulatory delay&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Motivation and Framing&lt;/head&gt;&lt;p&gt;I love space. I live and breathe it. I'm lucky enough to brush the heavens with my own metal and code, and I want nothing more than a booming orbital space economy that creates the flywheel that makes space just another location we all work and visit. I love AI and I subscribe to maximum, unbounded scale. I want to make the biggest bets. I grew up half-afraid we'd never get another Apollo or Manhattan. I truly want the BigThing.&lt;/p&gt;&lt;p&gt;This is all to say that the current discourse is increasingly bothering me due to the lack of rigor; people are using back-of-the-envelope math, doing a terrible job of it, and only confirming whatever conclusion they already want. Calculating radiation and the cost of goods is not difficult. Run the numbers.&lt;/p&gt;&lt;p&gt;Before we do the classic engineer thing and get nerd sniped by all the shiny technical problems, it's worth asking the only question that matters: why put compute in orbit at all? Why should a watt or a flop be more valuable 250 miles up than on the surface? What economic or strategic advantage justifies the effort required to run something as ordinary as matrix multiplication in low Earth orbit?&lt;/p&gt;&lt;p&gt;That "why" is nearly missing from the public conversation. The "energy is cheaper, less regulations, infinite space" arguments just ring false compared to the mountains of challenges and brutal physics putting anything in space layers on. The discourse then skips straight to implementation, as if the business case is obvious.&lt;/p&gt;&lt;head rend="h3"&gt;Personal Positioning&lt;/head&gt;&lt;p&gt;I'm not here to dunk on anyone building real hardware. Space is hard, and shipping flight systems is a credibility filter. I'm annoyed at everyone else. The conversation is full of confident claims built on one cherry-picked fact and zero arithmetic. This is a multivariable physics problem with closed-form constraints. If you're not doing the math, you're not contributing, you're adding noise and hyping for a future we all want instead of doing the hard work to actually drive reality forward.&lt;/p&gt;&lt;head rend="h3"&gt;Core Thesis&lt;/head&gt;&lt;p&gt;The target I care about is simple: can you make space-based, commodity compute cost-competitive with the cheapest terrestrial alternative? That's the whole claim. Not "space is big." Not "the sun is huge." Not "launch will be cheap." Can you deliver useful watts and reject the waste heat at a price that beats a boring Crusoe-style tilt-wall datacenter tied into a 200–500 MW substation?&lt;/p&gt;&lt;p&gt;If you can't beat that, the rest is just vibes. GPUs are pretty darn happy living on the ground. They like cheap electrons, mature supply chains, and technicians who can swap a dead server in five minutes. Orbit doesn't get points for being cool. Orbit has to win on cost, or it has to admit it's doing something else entirely. If it's an existential humanity play, that's cool too, but it's a slightly different game.&lt;/p&gt;&lt;head rend="h3"&gt;Analytical Lens&lt;/head&gt;&lt;p&gt;So here's what I did. I built a simple model that reduces the debate to one parameter: cost per watt of usable power for compute. The infographic below lets you change the assumptions directly. If you disagree with the inputs, great. Move the sliders. But at least we'll be arguing over numbers that map to reality.&lt;/p&gt;&lt;p&gt;The model is deliberately boring. No secret sauce. Just publicly available numbers and first-principles physics: solar flux, cell efficiency, radiator performance, launch cost, hardware mass, and a terrestrial benchmark that represents the real alternative: a tilt-wall datacenter sitting on top of cheap power. The code is public, please go through everything. github.com/andrewmccalip/thoughts&lt;/p&gt;&lt;head rend="h3"&gt;Findings and Implications&lt;/head&gt;&lt;p&gt;Here's the headline result: it's not obviously stupid, and it's not a sure thing. It's actually more reasonable than my intuition thought! If you run the numbers honestly, the physics doesn't immediately kill it, but the economics are savage. It only gets within striking distance under aggressive assumptions, and the list of organizations positioned to even try that is basically one.&lt;/p&gt;&lt;p&gt;That "basically one" point matters. This isn't about talent. It's about integration. If you have to buy launch, buy buses, buy power hardware, buy deployment, and pay margin at every interface, you never get there. The margin stack and the mass tax eat you alive. Vertical integration isn't a nice-to-have. It's the whole ballgame.&lt;/p&gt;&lt;head rend="h3"&gt;Market and Incentives&lt;/head&gt;&lt;p&gt;Which is why I trend positive on SpaceX here. If anyone can brute force a new industrial stack into existence, it's the team that can reduce $/kg and get as humanly close to free launch as possible. And they need to, because the economics are not close. This is not a 25% mismatch. It's 400%. Closing that is the whole job. Positive does not mean gullible. It needs measurable targets and painful reality checks.&lt;/p&gt;&lt;p&gt;If SpaceX ever goes public, this is exactly the kind of thing shareholders should demand: extreme, barely-achievable goalposts with clean measurement. Tesla did it with the options grant. Do the same here. Pay Elon a king's ransom if he delivers a new industrial primitive: cheap, sustained dollars per kilogram and dollars per watt in orbit, at real cadence, for years.&lt;/p&gt;&lt;head rend="h3"&gt;Broader Interpretation&lt;/head&gt;&lt;p&gt;On strict near-term unit economics, this might still be a mediocre use of capital. A tilt-wall datacenter in Oregon with cheap power, cheap cooling, and technicians on call is hard to beat. Crusoe can park compute on stranded natural gas and turn it into flops with a supply chain that already exists.&lt;/p&gt;&lt;p&gt;But the knock-on effects are why this keeps pulling at people. If you can industrialize power and operations in orbit at meaningful scale, you're not just running GPUs. You're building a new kind of infrastructure that makes it easier for humans to keep spreading out. Compute is just one of the first excuses to pay for the scaffolding. Even if this is a mediocre trade on strict near-term unit economics, the second-order effects could be enormous.&lt;/p&gt;&lt;p&gt;I'll go one step further and say the quiet part out loud: we should be actively goading more billionaires into spending on irrational, high-variance projects that might actually advance civilization. I feel genuine secondhand embarrassment watching people torch their fortunes on yachts and status cosplay. No one cares about your Loro Piana. If you've built an empire, the best possible use of it is to burn its capital like a torch and light up a corner of the future. Fund the ugly middle. Pay for the iteration loops. Build the cathedrals. This is how we advance civilization.&lt;/p&gt;&lt;head rend="h3"&gt;Links to Reports&lt;/head&gt;&lt;p&gt;Everyone is going to copy-paste this into the models, so I've done that part for you. It's a decent way to automate the sanity checks, but it could use more in-depth review.&lt;/p&gt;&lt;p&gt;GitHub: github.com/andrewmccalip/thoughts&lt;/p&gt;&lt;p&gt;"Conduct a thorough, first-principles-based review of this project. Scrutinize every assumption and constant, rigorously fact-checking all data. The objective is to identify and correct any fundamental errors in logic or calculation."&lt;/p&gt;&lt;p&gt; Grok: grok.com/share/...&lt;lb/&gt; ChatGPT: chatgpt.com/share/...&lt;lb/&gt; Gemini: gemini.google.com/share/...&lt;lb/&gt; Claude: claude.ai/public/artifacts/... &lt;/p&gt;&lt;head rend="h3"&gt;Overall Conclusion&lt;/head&gt;&lt;p&gt;Even so, irrational ambition doesn't get to ignore physics. The point of this page is to make the constraints explicit, so we can argue about reality instead of vibes. If the numbers close, even barely, then it's worth running hard on the idea. If they don't, the honest move is to say so and move on. Either way, I think some version of this has a feeling of inevitability.&lt;/p&gt;&lt;p&gt;So scroll down, play with the sliders, and try to break it. Change launch cost. Change lifetime. Change specific power. Change hardware cost. The goal here isn't to "win" an argument. It's to drag the conversation back to first principles: assumptions you can point at, and outputs you can sanity-check. Check out the GitHub, run the code, find the errors, and I'll update it live.&lt;/p&gt;&lt;p&gt;After that, we can do the fun part: thermal diagrams, radiator math, orbit beta angles, failure rates, comms geometry, all the shiny engineering details that make this topic so addicting. It's not obviously stupid, and it's not a sure thing. That's why it's worth doing the math.&lt;/p&gt;&lt;p&gt;It might not be rational. But it might be physically possible.&lt;/p&gt;&lt;head rend="h3"&gt;Technical Engineering Challenges&lt;/head&gt;&lt;p&gt;The governing constraint for orbital compute is thermodynamics. Terrestrial datacenters leverage convective cooling—dumping waste heat into the atmosphere or water sources, effectively using the planet as an infinite cold reservoir. In the vacuum of space, convection is impossible. Heat rejection relies exclusively on radiation.&lt;/p&gt;&lt;p&gt;Every object in space settles to an equilibrium temperature where absorbed power equals radiated power. If heat generation exceeds radiative capacity, the temperature rises until the $T^4$ term in the Stefan-Boltzmann law balances the equation:&lt;/p&gt;$$\dot{Q}_{\text{rad}} = \varepsilon \sigma A T^4$$&lt;p&gt;The engineering challenge is ensuring this equilibrium temperature remains below the safe operating limits of silicon processors.&lt;/p&gt;&lt;head rend="h4"&gt;Energy Balance and Heat Rejection&lt;/head&gt;&lt;p&gt;To dimension the radiator surface, we must account for the total thermal load managed by the satellite bus. In this model, based on a Starlink-style bifacial architecture (PV on front, radiator on back), the system must reject the aggregate energy of two distinct paths:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Incident Solar Flux: The sun delivers $G_{\text{sc}} = 1361\;\text{W/m}^2$ (AM0). With a solar absorptivity $\alpha = 0.92$, the panel absorbs approximately $\sim 1250\;\text{W/m}^2$.&lt;/item&gt;&lt;item&gt;Energy Partitioning: &lt;list rend="ul"&gt;&lt;item&gt;Electrical Path ($\sim$22%): High-efficiency cells convert $\sim 275\;\text{W/m}^2$ into electricity. This power drives the compute payload and is converted entirely back into heat by the processors. A liquid cooling loop collects this heat and returns it to the panel structure for rejection.&lt;/item&gt;&lt;item&gt;Thermal Absorption ($\sim$78%): The remaining $\sim 975\;\text{W/m}^2$ is not converted to electricity but is absorbed immediately as lattice heat (phonon generation) within the panel structure.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Total Heat Load: The radiator must reject the sum of both the immediate thermal absorption and the returned electrical waste heat—effectively 100% of the absorbed solar flux.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This imposes a strict area density limit. High-power compute requires large collection areas, which inherently absorb large amounts of solar heat. The radiator must be sized to reject this aggregate load while maintaining an operating temperature below the junction limit.&lt;/p&gt;&lt;head rend="h4"&gt;Operating Temperature Limits&lt;/head&gt;&lt;p&gt;Modern AI accelerators (H100/B200 class) typically throttle at junction temperatures $T_j &amp;gt; 85\text{–}100\degree\text{C}$. To maintain a junction at 85°C, and accounting for the thermal gradient across cold plates and interface materials ($\Delta T \approx 10\degree\text{C}$), the radiator surface temperature $T_{\text{rad}}$ is constrained to approximately 75°C.&lt;/p&gt;&lt;p&gt;The model below calculates the equilibrium temperature for a bifacial array in a terminator orbit ($\beta = 90^\circ$). It accounts for solar flux, Earth IR ($\sim 237\;\text{W/m}^2$), and albedo. If the calculated equilibrium temperature $T_{\text{eq}}$ exceeds the target radiator temperature, the design fails.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46281288</guid><pubDate>Mon, 15 Dec 2025 21:56:03 +0000</pubDate></item><item><title>JetBlue flight averts mid-air collision with US Air Force jet</title><link>https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/</link><description>&lt;doc fingerprint="bfbbe4d212d3adc9"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Dec 15 (Reuters) - A JetBlue (JBLU.O) passenger jet bound for New York took evasive action on Friday to avoid a mid-air collision with a U.S. Air Force tanker plane near Venezuela, a pilot said in an air traffic control recording.&lt;/p&gt;
    &lt;p&gt;JetBlue Flight 1112 had departed the Caribbean nation of Curacao and was flying about 40 miles (64 km) off the coast of Venezuela when the Airbus (AIR.PA) A320 reported encountering the Air Force jet, which did not have its transponder activated, according to the recording captured by liveatc.net.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The Air Force pilot was within a few miles of the plane and at the same altitude, the JetBlue pilot said on the recording.&lt;/p&gt;
    &lt;p&gt;"They passed directly in our flight path... They don't have their transponder turned on. It's outrageous," the pilot said.&lt;/p&gt;
    &lt;p&gt;The Air Force jet then entered Venezuelan airspace, the JetBlue pilot said. "We almost had a mid-air collision up here."&lt;/p&gt;
    &lt;head rend="h2"&gt;INCIDENT RECALLS DEADLY JANUARY CRASH&lt;/head&gt;
    &lt;p&gt;Senate Commerce Committee Chair Ted Cruz noted on Monday that an Army helicopter had collided with an American Airlines (AAL.O) flight on January 29 near Reagan Washington National Airport, killing 67 people, and was not using an advanced tracking technology called an automatic dependent surveillance-broadcast system, also known as ADS-B. "Why do we continue to tolerate near misses?" Cruz said of the JetBlue incident.&lt;/p&gt;
    &lt;p&gt;Senator Maria Cantwell, the top Democrat on the committee, also said the JetBlue incident raised concerns and the public needed a better system. "This is not acceptable," Cantwell said. "You don't have corridors where military aircraft and commercial planes are flying and then not letting each other know that they are in that space. We just can't have that."&lt;/p&gt;
    &lt;p&gt;The senators spoke on Monday at a press conference as they push to remove a provision from a must-pass annual defense bill that they say would weaken air safety by allowing military aircraft to operate in Washington, DC, airspace without transmitting ADS-B information.&lt;/p&gt;
    &lt;p&gt;A JetBlue spokesperson said on Monday the company's top priority was safety.&lt;/p&gt;
    &lt;p&gt;"Our crew members are trained on proper procedures for various flight situations, and we appreciate our crew for promptly reporting this situation to our leadership team. We have reported this incident to federal authorities and will participate in any investigation."&lt;/p&gt;
    &lt;head rend="h2"&gt;U.S. MILITARY ACTIVE IN REGION&lt;/head&gt;
    &lt;p&gt;The incident happened as the United States has mounted a large-scale military buildup in the southern Caribbean as President Donald Trump campaigns to oust Venezuelan leader Nicolas Maduro, pushing relations to their most volatile point in years.&lt;/p&gt;
    &lt;p&gt;U.S. Southern Command said in a statement on Monday that it was aware of the incident and reviewing the matter.&lt;/p&gt;
    &lt;p&gt;The military added its "aircrews are highly trained professionals who operate in accordance with established procedures and applicable airspace requirements. Safety remains a top priority, and we are working through the appropriate channels to assess the facts surrounding the situation.”&lt;/p&gt;
    &lt;p&gt;Last month, the Federal Aviation Administration warned major airlines of a "potentially hazardous situation" when flying over Venezuela and urged them to exercise caution. Major airlines from around the world have halted flights as tensions have worsened and Trump has threatened to begin hitting land targets in Venezuela.&lt;/p&gt;
    &lt;p&gt;The FAA did not immediately comment on Monday on the JetBlue incident.&lt;/p&gt;
    &lt;p&gt;Reporting by David Shepardson in Washington; Editing by Lisa Shumaker and Jamie Freed&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46281944</guid><pubDate>Mon, 15 Dec 2025 22:48:56 +0000</pubDate></item><item><title>Native vs. emulation: World of Warcraft game performance on Snapdragon X Elite</title><link>https://rkblog.dev/posts/pc-hardware/pc-on-arm/x86_versus_arm_native_game/</link><description>&lt;doc fingerprint="379ae9ff3d84b595"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Native versus emulation - World of Warcraft game performance on Snapdragon X Elite&lt;/head&gt;
    &lt;p&gt;At the beginning of the year, I tested the Snapdragon X Elite unreleased dev-kit, and I couldn't really compare x86 versus native gaming performance for the same game. I only managed to get World of Warcraft Classic x86 to run, and when compared to the native version, the FPS drop was 40-60% in two simple benchmarks. WoW retail x86 did not work, but now with the latest Windows improvements and the Prism emulation layer, things have changed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Test platform&lt;/head&gt;
    &lt;p&gt;The tests were done on a Snapdragon X Elite dev kit equipped with X1E-00-1DE Snapdragon X Elite SoC (3.8 GHz with 4.3 GHz boost on 1-2 cores) and 32GB of RAM. The dev kit runs at a higher TDP than most, if not all, laptops and has the theoretically best bin of chips (highest boost clocks).&lt;/p&gt;
    &lt;p&gt;The key difference since my initial review is the Windows version. Microsoft was working hard on improving emulation performance and compatibility. Since Windows 11 24H2, there is a new emulator called Prism, and with recent updates it also got AVX instructions support to handle even more x86_64 applications.&lt;/p&gt;
    &lt;p&gt;For the tests I used Windows 11 25H2 26220.7344 Insider Preview version to get all possible improvements taken into account.&lt;/p&gt;
    &lt;p&gt;Additionally, the x86_64 binaries properties were edited to enable &lt;quote&gt;newer emulated CPU features&lt;/quote&gt;:&lt;/p&gt;
    &lt;head rend="h2"&gt;World of Warcraft&lt;/head&gt;
    &lt;p&gt;WoW is an MMORPG, and it does not have a built-in benchmark. It can be reliably benchmarked to some extent if you use specific game areas/instances. You can check more in my WoW benchmarking section.&lt;/p&gt;
    &lt;p&gt;As a PC game, it's a modern DX12 game engine with optional ray-traced shadows support and a few other features. It offers native x86, Windows on ARM, and Apple Silicon versions. In my previous tests, the x86 retail version would not run on Snapdragon, and only the Classic version managed to run. The FPS drop versus the native version was massive of around 40-60% (but the testing wasn't as detailed as I would like).&lt;/p&gt;
    &lt;p&gt;With the Windows (and WoW) changes, both x86_64 WoW clients managed to run on Windows on ARM, allowing me to get way more test data. MSI Afterburner and other similar tools don't support WoA, so I had to use the game's built-in average FPS meter (which doesn't average over long periods of time; and no 1% lows/frame time graphs).&lt;/p&gt;
    &lt;head rend="h3"&gt;World of Warcraft - native versus emulated&lt;/head&gt;
    &lt;p&gt;I measured the FPS at 1080p for two settings - mode 3 (low) and mode 7 (high). The results are as follows:&lt;/p&gt;
    &lt;p&gt;The results are astounding as the x86 version is rivaling the native one, maybe even edging the native client.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WoW Classic and Stonard in retail are old locations, very light to render, so even with an iGPU, the FPS will be high.&lt;/item&gt;
      &lt;item&gt;Ardenweald is the most GPU-intensive modern zone from the test collection. Bastion is less demanding but has a bit more geometry. Dazar'alor harbor view is a geometry/render distance-based benchmark and will depend mostly on GPU&lt;/item&gt;
      &lt;item&gt;Necrotic Wake and Spires of Ascension are dungeons with some mobs, geometry, and units the game tracks. GPU with increasing CPU load.&lt;/item&gt;
      &lt;item&gt;Valdrakken is a player hub from the previous expansion, now mostly empty - player hubs when active are quite demanding to render without stutter. They tend to use a lot of assets as well.&lt;/item&gt;
      &lt;item&gt;Combat benchmark is pushing the game into single-core CPU limit - it's done in the old Karazhan raid, where I can reliably pull a large group of mobs and stand still with fixed camera position. iGPUs can also be the bottleneck on higher settings due to particle effects of spells going off. Most dGPUs will have no problems with them.&lt;/item&gt;
      &lt;item&gt;Out of combat, when test mobs despawn, the FPS inside Karazan increases as it's an old instance without any complex geometry or large asset collection. The game combat &lt;quote&gt;world state&lt;/quote&gt;vanishes and thus the single-core bottleneck as well&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Karazhan benchmark was the only one where the native version was noticeably ahead of the emulated version. Due to that, I've also added two modern dungeon instances, and those results were more in line with other locations. Either there was a difference between game versions, or in larger instances, game performance can be limited by some sort of system latency, and emulation is not the best for that.&lt;/p&gt;
    &lt;p&gt;WoW by default will use 4 CPU cores, with one core being the &lt;quote&gt;primary&lt;/quote&gt; ones. In a mass combat / mass NPC scenario, the main core will see 100% load and will be the limiting factor.&lt;/p&gt;
    &lt;p&gt;Windows on ARM can handle a lot of x86 Windows applications, but not all of them. From my quick re-tests, I managed to run Unigine Valley, but Unigine Superposition failed to run.&lt;/p&gt;
    &lt;head rend="h3"&gt;Default versus very strict emulation&lt;/head&gt;
    &lt;p&gt;I was curious what the difference between emulation settings. Switching to &lt;quote&gt;very strict&lt;/quote&gt; emulation settings disables a lot of features, which in turn tanked x86 WoW performance:&lt;/p&gt;
    &lt;head rend="h2"&gt;Mobile SoC comparison&lt;/head&gt;
    &lt;p&gt;I've also recently tested Strix Point HX 370, and Intel Arrow Lake 255H capped at 30W, so I've added them to the comparison charts:&lt;/p&gt;
    &lt;p&gt;In iGPU-heavy scenarios, Intel/AMD tend to be ahead, while in CPU scenarios, all 3 platforms get close to each other.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;I really wanted to compare native versus emulated on Snapdragon, as initial WoW Classic performance differences were huge. With recent Prism updates, I forced the devkit to update Windows, and it managed to run the x86 retail World of Warcraft client. This allowed me to test CPU and GPU-focused scenarios within the game. Surprisingly, for WoW, there was no real penalty, at least outside the raid/combat scenario. When you install Battle.net and WoW, you will get the native version by default, so you don't have to select or change anything.&lt;/p&gt;
    &lt;p&gt;It's good to see improvements to Windows on ARM. Better application compatibility is nice, but it will never be perfect. On top of that, some apps will have hardcoded checks, and you won't be able to use x86 drivers. Qualcomm is preparing the second generation of mobile X Elite chips, and it will be interesting to see how they perform. Initial launch saw a lot of laptop sales, but also a lot of returns.&lt;/p&gt;
    &lt;p&gt;Limited Linux support is still a problem, from device tree lists, firmware extraction, to overall worse behavior of the SoC under Linux. Linux ARM support is way better than Windows, and even some hardware vendors tend to support ARM Linux due to the Raspberry Pi (like astrophotography equipment, vision cameras).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46282679</guid><pubDate>Mon, 15 Dec 2025 23:47:37 +0000</pubDate></item><item><title>Quill OS: An open-source OS for Kobo's eReaders</title><link>https://quill-os.org/</link><description>&lt;doc fingerprint="ae45b2563aa66bc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Here are some of Quill OS' features:&lt;/p&gt;
    &lt;p&gt; Fully integrated KoBox X11 subsystem &lt;lb/&gt;ePUB, PDF, picture and plain text display support &lt;lb/&gt;Versatile configuration options for reading &lt;lb/&gt;muPDF rendering engine for ePUBs and PDFs &lt;lb/&gt;Wi-Fi support and web browser &lt;lb/&gt;Encrypted storage with EncFS &lt;lb/&gt;Fast dictionary &amp;amp; local storage search &lt;lb/&gt;Dark mode &lt;lb/&gt;Full factory reset option if needed &lt;lb/&gt;Seamless update process &lt;lb/&gt;VNC viewer app &lt;lb/&gt;Search function &lt;lb/&gt;10 built-in fonts &lt;lb/&gt;Auto-suspend &lt;lb/&gt;Lock screen/passcode &lt;lb/&gt;User-friendly experience &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46283016</guid><pubDate>Tue, 16 Dec 2025 00:22:41 +0000</pubDate></item><item><title>Rollstack (YC W23) is hiring multiple software engineers (TypeScript) US/Canada</title><link>https://www.ycombinator.com/companies/rollstack-2/jobs/QPqpb1n-software-engineer-typescript-us-canada</link><description>&lt;doc fingerprint="f3a0d348861224cf"&gt;
  &lt;main&gt;
    &lt;p&gt;Automate data-driven slide decks and documents with AI&lt;/p&gt;
    &lt;p&gt;At Rollstack, we are revolutionizing the way businesses share and communicate data and insights. Organizations worldwide rely on slide decks and documents to make informed decisions, whether for leadership, clients, or partners. Yet, preparing these materials often consumes countless hours. Rollstack fully automates that.&lt;/p&gt;
    &lt;p&gt;We help some of the world's leading organizations, from mid-sized to public companies like SoFi, Zillow and Whirlpool, in automating their slide decks and documents. Headquartered in New York, we offer a remote-friendly workplace and are backed by Insight Partners and Y Combinator, the most successful startup incubator in the world that produced the likes of Airbnb, Twitch, Instacart, Dropbox, Reddit, Doordash, Stripe, Coinbase, etc.&lt;/p&gt;
    &lt;p&gt;Our team operates with speed and focus to deliver outsized impacts for our customers. We approach every challenge with first principles, never assuming things have to be done a certain way. We are a diverse team that believes intelligence and kindness go hand in hand, welcoming individuals from all backgrounds. Our persistence and rapid execution define us as a category leader and a future generational company.&lt;/p&gt;
    &lt;p&gt;As a Software Engineer at Rollstack, you’ll build core features that automate how companies share data through slides and documents. You’ll work across the stack on integrations, AI insights, and performance optimization. This role is ideal for engineers who thrive on impact, autonomy, and fast-paced product development.&lt;/p&gt;
    &lt;p&gt;At Rollstack, we’re looking for engineers who enjoy iterating, shipping quickly, and solving customers' problems. We want individuals who exhibit a strong sense of ownership and have a get-things-done mentality. Our engineering team defines and drives its technical agenda to continuously iterate on the product and solve our customers' most important problems.&lt;lb/&gt; Our interview process is designed to find these kinds of engineers:&lt;/p&gt;
    &lt;p&gt;Rollstack is solving the last mile problem in the modern data stack and creating a new category: Reports Automation. We connect BI tools to slide decks and documents, automating their generation and updates.&lt;/p&gt;
    &lt;p&gt;We help some of the world's leading organizations—from mid-sized to public companies like SoFi, Zillow and Whirlpool—in automating their slide decks and documents. Headquartered in New York, we offer a remote-friendly workplace and are backed by Insight Partners and Y Combinator, the most successful startup incubator in the world that produced the likes of Airbnb, Twitch, Instacart, Dropbox, Reddit, Doordash, Stripe, Coinbase, etc.&lt;/p&gt;
    &lt;p&gt;Our team operates with speed and focus to deliver outsized impacts for our customers. We approach every challenge with first principles, never assuming things have to be done a certain way. We are a diverse team that believes intelligence and kindness go hand in hand, welcoming individuals from all backgrounds. Our persistence and rapid execution define us as a category leader and a future generational company.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46283750</guid><pubDate>Tue, 16 Dec 2025 01:51:50 +0000</pubDate></item><item><title>8M users' AI conversations sold for profit by "privacy" extensions</title><link>https://www.koi.ai/blog/urban-vpn-browser-extension-ai-conversations-data-collection</link><description>&lt;doc fingerprint="9d53a3a2bd344c8c"&gt;
  &lt;main&gt;
    &lt;p&gt;A few weeks ago, I was wrestling with a major life decision. Like I've grown used to doing, I opened Claude and started thinking out loud-laying out the options, weighing the tradeoffs, asking for perspective.&lt;/p&gt;
    &lt;p&gt;Midway through the conversation, I paused. I realized how much I'd shared: not just this decision, but months of conversations-personal dilemmas, health questions, financial details, work frustrations, things I hadn't told anyone else. I'd developed a level of candor with my AI assistant that I don't have with most people in my life.&lt;/p&gt;
    &lt;p&gt;And then an uncomfortable thought: what if someone was reading all of this?&lt;/p&gt;
    &lt;p&gt;The thought didn't let go. As a security researcher, I have the tools to answer that question.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery&lt;/head&gt;
    &lt;p&gt;We asked Wings, our agentic-AI risk engine, to scan for browser extensions with the capability to read and exfiltrate conversations from AI chat platforms. We expected to find a handful of obscure extensions-low install counts, sketchy publishers, the usual suspects.&lt;/p&gt;
    &lt;p&gt;The results came back with something else entirely.&lt;/p&gt;
    &lt;p&gt;Near the top of the list: Urban VPN Proxy. A Chrome extension with over 6 million users. A 4.7-star rating from 58,000 reviews. A "Featured" badge from Google, meaning it had passed manual review and met what Google describes as "a high standard of user experience and design."&lt;/p&gt;
    &lt;p&gt;A free VPN promising privacy and security. Exactly the kind of tool someone installs when they want to protect themselves online.&lt;/p&gt;
    &lt;p&gt;We decided to look closer.&lt;/p&gt;
    &lt;head rend="h2"&gt;What We Found&lt;/head&gt;
    &lt;p&gt;Urban VPN Proxy targets conversations across ten AI platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ChatGPT&lt;/item&gt;
      &lt;item&gt;Claude&lt;/item&gt;
      &lt;item&gt;Gemini&lt;/item&gt;
      &lt;item&gt;Microsoft Copilot&lt;/item&gt;
      &lt;item&gt;Perplexity&lt;/item&gt;
      &lt;item&gt;DeepSeek&lt;/item&gt;
      &lt;item&gt;Grok (xAI)&lt;/item&gt;
      &lt;item&gt;Meta AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For each platform, the extension includes a dedicated "executor" script designed to intercept and capture conversations. The harvesting is enabled by default through hardcoded flags in the extension's configuration:&lt;/p&gt;
    &lt;p&gt;There is no user-facing toggle to disable this. The only way to stop the data collection is to uninstall the extension entirely.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;The data collection operates independently of the VPN functionality. Whether the VPN is connected or not, the harvesting runs continuously in the background.&lt;/p&gt;
    &lt;p&gt;Here's the technical breakdown:&lt;/p&gt;
    &lt;p&gt;1. Script injection into AI platforms&lt;/p&gt;
    &lt;p&gt;The extension monitors your browser tabs. When you visit any of the targeted AI platforms (ChatGPT, Claude, Gemini, etc.), it injects an "executor" script directly into the page. Each platform has its own dedicated script - chatgpt.js, claude.js, gemini.js, and so on.&lt;/p&gt;
    &lt;p&gt;2. Overriding native browser functions&lt;/p&gt;
    &lt;p&gt;Once injected, the script overrides fetch() and XMLHttpRequest - the fundamental browser APIs that handle all network requests. This is an aggressive technique. The script wraps the original functions so that every network request and response on that page passes through the extension's code first.&lt;/p&gt;
    &lt;p&gt;This means when Claude sends you a response, or when you submit a prompt to ChatGPT, the extension sees the raw API traffic before your browser even renders it.&lt;/p&gt;
    &lt;p&gt;3. Parsing and packaging&lt;/p&gt;
    &lt;p&gt;The injected script parses the intercepted API responses to extract conversation data - your prompts, the AI's responses, timestamps, conversation IDs. This data is packaged and sent via window.postMessage to the extension's content script, tagged with the identifier PANELOS_MESSAGE.&lt;/p&gt;
    &lt;p&gt;4. Exfiltration via background worker&lt;/p&gt;
    &lt;p&gt;The content script forwards the data to the extension's background service worker, which handles the actual exfiltration. The data is compressed and transmitted to Urban VPN's servers at endpoints including analytics.urban-vpn.com and stats.urban-vpn.com.&lt;/p&gt;
    &lt;p&gt;What gets captured:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Every prompt you send to the AI&lt;/item&gt;
      &lt;item&gt;Every response you receive&lt;/item&gt;
      &lt;item&gt;Conversation identifiers and timestamps&lt;/item&gt;
      &lt;item&gt;Session metadata&lt;/item&gt;
      &lt;item&gt;The specific AI platform and model used&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Timeline&lt;/head&gt;
    &lt;p&gt;The AI conversation harvesting wasn't always there. Based on our analysis:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before version 5.5.0: No AI harvesting functionality&lt;/item&gt;
      &lt;item&gt;July 9, 2025: Version 5.5.0 released with AI harvesting enabled by default&lt;/item&gt;
      &lt;item&gt;July 2025 - Present: All user conversations with targeted AI platforms captured and exfiltrated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chrome and Edge extensions auto-update by default. Users who installed Urban VPN for its stated purpose - VPN functionality - woke up one day with new code silently harvesting their AI conversations.&lt;/p&gt;
    &lt;p&gt;Anyone who used ChatGPT, Claude, Gemini, or the other targeted platforms while Urban VPN was installed after July 9, 2025 should assume those conversations are now on Urban VPN's servers and have been shared with third parties. Medical questions, financial details, proprietary code, personal dilemmas - all of it, sold for "marketing analytics purposes."&lt;/p&gt;
    &lt;head rend="h2"&gt;What "AI Protection" Actually Does&lt;/head&gt;
    &lt;p&gt;Urban VPN's Chrome Web Store listing promotes "AI protection" as a feature:&lt;/p&gt;
    &lt;p&gt;"Advanced VPN Protection - Our VPN provides added security features to help shield your browsing experience from phishing attempts, malware, intrusive ads and AI protection which checks prompts for personal data (like an email or phone number), checks AI chat responses for suspicious or unsafe links and displays a warning before click or submit your prompt."&lt;/p&gt;
    &lt;p&gt;The framing suggests the AI monitoring exists to protect you-checking for sensitive data you might accidentally share, warning you about suspicious links in responses.&lt;/p&gt;
    &lt;p&gt;The code tells a different story. The data collection and the "protection" notifications operate independently. Enabling or disabling the warning feature has no effect on whether your conversations are captured and exfiltrated. The extension harvests everything regardless.&lt;/p&gt;
    &lt;p&gt;The protection feature shows occasional warnings about sharing sensitive data with AI companies. The harvesting feature sends that exact sensitive data - and everything else - to Urban VPN's own servers, where it's sold to advertisers. The extension warns you about sharing your email with ChatGPT while simultaneously exfiltrating your entire conversation to a data broker.&lt;/p&gt;
    &lt;head rend="h2"&gt;It Gets Worse&lt;/head&gt;
    &lt;p&gt;After documenting Urban VPN Proxy's behavior, we checked whether the same code existed elsewhere.&lt;/p&gt;
    &lt;p&gt;It did. The identical AI harvesting functionality appears in seven other extensions from the same publisher, across both Chrome and Edge:&lt;/p&gt;
    &lt;p&gt;Chrome Web Store:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy - 6,000,000 users&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy - 600,000 users&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard - 40,000 users&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker - 10,000 users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Microsoft Edge Add-ons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy - 1,323,622 users&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy - 36,459 users&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard - 12,624 users&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker - 6,476 users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Total affected users: Over 8 million.&lt;/p&gt;
    &lt;p&gt;The extensions span different product categories, a VPN, an ad blocker, a "browser guard" security tool, but share the same surveillance backend. Users installing an ad blocker have no reason to expect their Claude conversations are being harvested.&lt;/p&gt;
    &lt;p&gt;All of these extensions carry "Featured" badges from their respective stores, except Urban Ad Blocker for Edge. These badges signal to users that the extensions have been reviewed and meet platform quality standards. For many users, a Featured badge is the difference between installing an extension and passing it by - it's an implicit endorsement from Google and Microsoft.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who's Behind This&lt;/head&gt;
    &lt;p&gt;Urban VPN is operated by Urban Cyber Security Inc., which is affiliated with BiScience (B.I Science (2009) Ltd.), a data broker company.&lt;/p&gt;
    &lt;p&gt;This company has been on researchers' radar before. Security researchers Wladimir Palant and John Tuckner at Secure Annex have previously documented BiScience's data collection practices. Their research established that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BiScience collects clickstream data (browsing history) from millions of users&lt;/item&gt;
      &lt;item&gt;Data is tied to persistent device identifiers, enabling re-identification&lt;/item&gt;
      &lt;item&gt;The company provides an SDK to third-party extension developers to collect and sell user data&lt;/item&gt;
      &lt;item&gt;BiScience sells this data through products like AdClarity and Clickstream OS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our finding represents an expansion of this operation. BiScience has moved from collecting browsing history to harvesting complete AI conversations-a significantly more sensitive category of data.&lt;/p&gt;
    &lt;p&gt;The privacy policy confirms the data flow:&lt;/p&gt;
    &lt;p&gt;"We share the Web Browsing Data with our affiliated company... BiScience that uses this raw data and creates insights which are commercially used and shared with Business Partners"&lt;/p&gt;
    &lt;head rend="h2"&gt;The Disclosure Problem&lt;/head&gt;
    &lt;p&gt;To be fair, Urban VPN does disclose some of this-if you know where to look.&lt;/p&gt;
    &lt;p&gt;The consent prompt (shown during extension setup) mentions that the extension processes "ChatAI communication" along with "pages you visit" and "security signals." It states this is done "to provide these protections."&lt;/p&gt;
    &lt;p&gt;[Screenshot: Urban VPN consent prompt]&lt;/p&gt;
    &lt;p&gt;The privacy policy goes further, buried deep in the document:&lt;/p&gt;
    &lt;p&gt;"AI Inputs and Outputs. As part of the Browsing Data, we will collect the prompts and outputs queried by the End-User or generated by the AI chat provider, as applicable."&lt;/p&gt;
    &lt;p&gt;And:&lt;/p&gt;
    &lt;p&gt;"We also disclose the AI prompts for marketing analytics purposes."&lt;/p&gt;
    &lt;p&gt;However, the Chrome Web Store listing-the place where users actually decide whether to install-shows a different picture:&lt;/p&gt;
    &lt;p&gt;"This developer declares that your data is Not being sold to third parties, outside of the approved use cases"&lt;/p&gt;
    &lt;p&gt;The listing mentions the extension handles "Web history" and "Website content." It says nothing about AI conversations specifically.&lt;/p&gt;
    &lt;p&gt;The contradictions are significant:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The consent prompt frames AI monitoring as protective. The privacy policy reveals the data is sold for marketing.&lt;/item&gt;
      &lt;item&gt;The store listing says data isn't sold to third parties. The privacy policy describes sharing with BiScience, "Business Partners," and use for "marketing analytics."&lt;/item&gt;
      &lt;item&gt;Users who installed before July 2025 never saw the updated consent prompt-the AI harvesting was added via silent update in version 5.5.0.&lt;/item&gt;
      &lt;item&gt;Even users who see the consent prompt have no granular control. You can't accept the VPN but decline the AI harvesting. It's all or nothing.&lt;/item&gt;
      &lt;item&gt;Nothing indicates to users that the data collection continues even when the VPN is disconnected and the AI protection feature is turned off. The harvesting runs silently in the background regardless of what features the user has enabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Google's Role&lt;/head&gt;
    &lt;p&gt;Urban VPN Proxy carries Google's "Featured" badge on the Chrome Web Store. According to Google's documentation:&lt;/p&gt;
    &lt;p&gt;"Featured extensions follow our technical best practices and meet a high standard of user experience and design."&lt;/p&gt;
    &lt;p&gt;"Before it receives a Featured badge, the Chrome Web Store team must review each extension."&lt;/p&gt;
    &lt;p&gt;This means a human at Google reviewed Urban VPN Proxy and concluded it met their standards. Either the review didn't examine the code that harvests conversations from Google's own AI product (Gemini), or it did and didn't consider this a problem.&lt;/p&gt;
    &lt;p&gt;The Chrome Web Store's Limited Use policy explicitly prohibits "transferring or selling user data to third parties like advertising platforms, data brokers, or other information resellers." BiScience is, by its own description, a data broker.&lt;/p&gt;
    &lt;p&gt;The extension remains live and featured as of this writing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;Browser extensions occupy a unique position of trust. They run in the background, have broad access to your browsing activity, and auto-update without asking. When an extension promises privacy and security, users have little reason to suspect it's doing the opposite.&lt;/p&gt;
    &lt;p&gt;What makes this case notable isn't just the scale - 8 million users - or the sensitivity of the data - complete AI conversations. It's that these extensions passed review, earned Featured badges, and remained live for months while harvesting some of the most personal data users generate online. The marketplaces designed to protect users instead gave these extensions their stamp of approval.&lt;/p&gt;
    &lt;p&gt;If you have any of these extensions installed, uninstall them now. Assume any AI conversations you've had since July 2025 have been captured and shared with third parties.&lt;/p&gt;
    &lt;p&gt;This writeup was authored by the research team at Koi.&lt;/p&gt;
    &lt;p&gt;We built Koi to detect exactly these kinds of threats - extensions that slip past marketplace reviews and quietly exfiltrate sensitive data. Our risk engine, Wings, continuously monitors browser extensions to catch threats before they reach your team.&lt;/p&gt;
    &lt;p&gt;Book a demo to see how behavioral analysis catches what static review misses.&lt;/p&gt;
    &lt;p&gt;Stay safe out there.&lt;/p&gt;
    &lt;head rend="h2"&gt;IOCs&lt;/head&gt;
    &lt;p&gt;Chrome:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy: eppiocemhmnlbhjplcgkofciiegomcon&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard: almalgbpmcfpdaopimbdchdliminoign&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker: feflcgofneboehfdeebcfglbodaceghj&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy for Chrome: pphgdbgldlmicfdkhondlafkiomnelnk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Edge:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy: nimlmejbmnecnaghgmbahmbaddhjbecg&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard: jckkfbfmofganecnnpfndfjifnimpcel&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker: gcogpdjkkamgkakkjgeefgpcheonclca&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy for Edge: deopfbighgnpgfmhjeccdifdmhcjckoe&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;â&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46284266</guid><pubDate>Tue, 16 Dec 2025 03:03:49 +0000</pubDate></item><item><title>SHARP, an approach to photorealistic view synthesis from a single image</title><link>https://apple.github.io/ml-sharp/</link><description>&lt;doc fingerprint="b4c1e2802635c4d6"&gt;
  &lt;main&gt;
    &lt;p&gt;Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen,&lt;/p&gt;
    &lt;p&gt;Amaël Delaunoy, Tian Fang, Yanghai Tsin, Stephan R. Richter, Vladlen Koltun&lt;/p&gt;
    &lt;p&gt;Apple&lt;/p&gt;
    &lt;p&gt;We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25–34% and DISTS by 21–43% versus the best prior model, while lowering the synthesis time by three orders of magnitude.&lt;/p&gt;
    &lt;p&gt;SHARP synthesizes a photorealistic 3D representation from a single photograph in less than a second. The synthesized representation supports high-resolution rendering of nearby views, with sharp details and fine structures, at more than 100 frames per second on a standard GPU. We illustrate on photographs from Unsplash.&lt;/p&gt;
    &lt;code&gt;@inproceedings{Sharp2025:arxiv,
  title      = {Sharp Monocular View Synthesis in Less Than a Second},
  author     = {Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\"{e}l Delaunoyand Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun},
  journal    = {arXiv preprint arXiv:2512.10685},
  year       = {2025},
  url        = {https://arxiv.org/abs/2512.10685},
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46284658</guid><pubDate>Tue, 16 Dec 2025 04:06:51 +0000</pubDate></item><item><title>Erdős Problem #1026</title><link>https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/</link><description>&lt;doc fingerprint="a098d6150ae7afb1"&gt;
  &lt;main&gt;&lt;p&gt;Problem 1026 on the Erdős problem web site recently got solved through an interesting combination of existing literature, online collaboration, and AI tools. The purpose of this blog post is to try to tell the story of this collaboration, and also to supply a complete proof.&lt;/p&gt;&lt;p&gt;The original problem of Erdős, posed in 1975, is rather ambiguous. Erdős starts by recalling his famous theorem with Szekeres that says that given a sequence of distinct real numbers, one can find a subsequence of length which is either increasing or decreasing; and that one cannot improve the to , by considering for instance a sequence of blocks of length , with the numbers in each block decreasing, but the blocks themselves increasing. He also noted a result of Hanani that every sequence of length can be decomposed into the union of monotone sequences. He then wrote “As far as I know the following question is not yet settled. Let be a sequence of distinct numbers, determine&lt;/p&gt;where the maximum is to be taken over all monotonic sequences “.&lt;p&gt;This problem was added to the Erdős problem site on September 12, 2025, with a note that the problem was rather ambiguous. For any fixed , this is an explicit piecewise linear function of the variables that could be computed by a simple brute force algorithm, but Erdős was presumably seeking optimal bounds for this quantity under some natural constraint on the . The day the problem was posted, Desmond Weisenberg proposed studying the quantity , defined as the largest constant such that&lt;/p&gt;for all choices of (distinct) real numbers . Desmond noted that for this formulation one could assume without loss of generality that the were positive, since deleting negative or vanishing does not decrease the left-hand side and does not increase the right-hand side. By a limiting argument one could also allow collisions between the , so long as one interpreted monotonicity in the weak sense.&lt;p&gt;Though not stated on the web site, one can formulate this problem in game theoretic terms. Suppose that Alice has a stack of coins for some large . She divides the coins into piles of consisting of coins each, so that . She then passes the piles to Bob, who is allowed to select a monotone subsequence of the piles (in the weak sense) and keep all the coins in those piles. What is the largest fraction of the coins that Bob can guarantee to keep, regardless of how Alice divides up the coins? (One can work with either a discrete version of this problem where the are integers, or a continuous one where the coins can be split fractionally, but in the limit the problems can easily be seen to be equivalent.)&lt;/p&gt;&lt;p&gt;AI-generated images continue to be problematic for a number of reasons, but here is one such image that somewhat manages at least to convey the idea of the game:&lt;/p&gt;&lt;p&gt;For small , one can work out by hand. For , clearly : Alice has to put all the coins into one pile, which Bob simply takes. Similarly : regardless of how Alice divides the coins into two piles, the piles will either be increasing or decreasing, so in either case Bob can take both. The first interesting case is . Bob can again always take the two largest piles, guaranteeing himself of the coins. On the other hand, if Alice almost divides the coins evenly, for instance into piles for some small , then Bob cannot take all three piles as they are non-monotone, and so can only take two of them, allowing Alice to limit the payout fraction to be arbitrarily close to . So we conclude that .&lt;/p&gt;&lt;p&gt;An hour after Desmond’s comment, Stijn Cambie noted (though not in the language I used above) that a similar construction to the one above, in which Alice divides the coins into pairs that are almost even, in such a way that the longest monotone sequence is of length , gives the upper bound . It is also easy to see that is a non-increasing function of , so this gives a general bound . Less than an hour after that, Wouter van Doorn noted that the Hanani result mentioned above gives the lower bound , and posed the problem of determining the asymptotic limit of as , given that this was now known to range between and . This version was accepted by Thomas Bloom, the moderator of the Erdős problem site, as a valid interpretation of the original problem.&lt;/p&gt;&lt;p&gt;The next day, Stijn computed the first few values of exactly:&lt;/p&gt;While the general pattern was not yet clear, this was enough data for Stijn to conjecture that , which would also imply that as . (EDIT: as later located by an AI deep research tool, this conjecture was also made in Section 12 of this 1980 article of Steele.) Stijn also described the extremizing sequences for this range of , but did not continue the calculation further (a naive computation would take runtime exponential in , due to the large number of possible subsequences to consider).&lt;p&gt;The problem then lay dormant for almost two months, until December 7, 2025, in which Boris Alexeev, as part of a systematic sweep of the Erdős problems using the AI tool Aristotle, was able to get this tool to autonomously solve this conjecture in the proof assistant language Lean. The proof converted the problem to a rectangle-packing problem.&lt;/p&gt;&lt;p&gt;This was one further addition to a recent sequence of examples where an Erdős problem had been automatically solved in one fashion or another by an AI tool. Like the previous cases, the proof turned out to not be particularly novel. Within an hour, Koishi Chan gave an alternate proof deriving the required bound from the original Erdős-Szekeres theorem by a standard “blow-up” argument which we can give here in the Alice-Bob formulation. Take a large , and replace each pile of coins with new piles, each of size , chosen so that the longest monotone subsequence in this collection is . Among all the new piles, the longest monotone subsequence has length . Applying Erdős-Szekeres, one concludes the bound&lt;/p&gt;and on canceling the ‘s, sending , and applying Cauchy-Schwarz, one obtains (in fact the argument gives for all ).&lt;p&gt;Once this proof was found, it was natural to try to see if it had already appeared in the literature. AI deep research tools have successfully located such prior literature in the past, but in this case they did not succeed, and a more “old-fashioned” Google Scholar job turned up some relevant references: a 2016 paper by Tidor, Wang and Yang contained this precise result, citing an earlier paper of Wagner as inspiration for applying “blowup” to the Erdős-Szekeres theorem.&lt;/p&gt;&lt;p&gt;But the story does not end there! Upon reading the above story the next day, I realized that the problem of estimating was a suitable task for AlphaEvolve, which I have used recently as mentioned in this previous post. Specifically, one could task to obtain upper bounds on by directing it to produce real numbers (or integers) summing up to a fixed sum (I chose ) with a small a value of as possible. After an hour of run time, AlphaEvolve produced the following upper bounds on for , with some intriguingly structured potential extremizing solutions:&lt;/p&gt;The numerical scores (divided by ) were pretty obviously trying to approximate simple rational numbers. There were a variety of ways (including modern AI) to extract the actual rational numbers they were close to, but I searched for a dedicated tool and found this useful little web page of John Cook that did the job: I could not immediately see the pattern here, but after some trial and error in which I tried to align numerators and denominators, I eventually organized this sequence into a more suggestive form: This gave a somewhat complicated but predictable conjecture for the values of the sequence . On posting this, Boris found a clean formulation of the conjecture, namely that whenever and . After a bit of effort, he also produced an explicit upper bound construction:&lt;quote&gt;Proposition 1 If and , then .&lt;/quote&gt;&lt;p&gt;Proof: Consider a sequence of numbers clustered around the “red number” and “blue number” , consisting of blocks of “blue” numbers, followed by blocks of “red” numbers, and then further blocks of “blue” numbers. When , one should take all blocks to be slightly decreasing within each block, but the blue blocks should be are increasing between each other, and the red blocks should also be increasing between each other. When , all of these orderings should be reversed. The total number of elements is indeed&lt;/p&gt;and the total sum is close to With this setup, one can check that any monotone sequence consists either of at most red elements and at most blue elements, or no red elements and at most blue elements, in either case giving a monotone sum that is bounded by either or giving the claim.&lt;p&gt;Here is a figure illustrating the above construction in the case (obtained after starting with a ChatGPT-provided file and then manually fixing a number of placement issues):&lt;/p&gt;&lt;p&gt;Here is a plot of (produced by ChatGPT Pro), showing that it is basically a piecewise linear approximation to the square root function:&lt;/p&gt;&lt;p&gt;Shortly afterwards, Lawrence Wu clarified the connection between this problem and a square packing problem, which was also due to Erdős (Problem 106). Let be the least number such that, whenever one packs squares of sidelength into a square of sidelength , with all sides parallel to the coordinate axes, one has&lt;/p&gt;&lt;quote&gt;Proposition 2 For any , one has&lt;/quote&gt;&lt;p&gt;Proof: Given and , let be the maximal sum over all increasing subsequences ending in , and be the maximal sum over all decreasing subsequences ending in . For , we have either (if ) or (if ). In particular, the squares and are disjoint. These squares pack into the square , so by definition of , we have&lt;/p&gt;and the claim follows.&lt;p&gt;This idea of using packing to prove Erdős-Szekeres type results goes back to a 1959 paper of Seidenberg, although it was a discrete rectangle-packing argument that was not phrased in such an elegantly geometric form. It is possible that Aristotle was “aware” of the Seidenberg argument via its training data, as it had incorporated a version of this argument in its proof.&lt;/p&gt;&lt;p&gt;Here is an illustration of the above argument using the AlphaEvolve-provided example&lt;/p&gt;&lt;p&gt;for to convert it to a square packing (image produced by ChatGPT Pro):&lt;/p&gt;&lt;p&gt;At this point, Lawrence performed another AI deep research search, this time successfully locating a paper from just last year by Baek, Koizumi, and Ueoro, where they show that&lt;/p&gt;&lt;quote&gt;Theorem 3 For any , one has&lt;/quote&gt;&lt;p&gt;which, when combined with a previous argument of Praton, implies&lt;/p&gt;&lt;quote&gt;Theorem 4 For any and with , one has&lt;/quote&gt;&lt;p&gt;This proves the conjecture!&lt;/p&gt;&lt;p&gt;There just remained the issue of putting everything together. I did feed all of the above information into a large language model, which was able to produce a coherent proof of (1) assuming the results of Baek-Koizumi-Ueoro and Praton. Of course, LLM outputs are prone to hallucination, so it would be preferable to formalize that argument in Lean, but this looks quite doable with current tools, and I expect this to be accomplished shortly. But I was also able to reproduce the arguments of Baek-Koizumi-Ueoro and Praton, which I include below for completeness.&lt;/p&gt;&lt;p&gt;Proof: (Proof of Theorem 3, adapted from Baek-Koizumi-Ueoro) We can normalize . It then suffices to show that if we pack the length torus by axis-parallel squares of sidelength , then&lt;/p&gt;&lt;p&gt;Pick . Then we have a grid&lt;/p&gt;inside the torus. The square, when restricted to this grid, becomes a discrete rectangle for some finite sets with By the packing condition, we have From (2) we have hence Inserting this bound and rearranging, we conclude that Taking the supremum over we conclude that so by the pigeonhole principle one of the summands is at most . Let’s say it is the former, thus In particular, the average value of is at most . But this can be computed to be , giving the claim. Similarly if it is the other sum.&lt;p&gt;UPDATE: Actually, the above argument also proves Theorem 4 with only minor modifications. Nevertheless, we give the original derivation of Theorem 4 using the embedding argument of Praton below for sake of completeness.&lt;/p&gt;&lt;p&gt;Proof: (Proof of Theorem 4, adapted from Praton) We write with . We can rescale so that the square one is packing into is . Thus, we pack squares of sidelength into , and our task is to show that&lt;/p&gt;We pick a large natural number (in particular, larger than ), and consider the three nested squares We can pack by unit squares. We can similarly pack into squares of sidelength . All in all, this produces squares, of total length Applying Theorem 3, we conclude that The right-hand side is and the left-hand side similarly evaluates to and so we simplify to Sending , we obtain the claim. One striking feature of this story for me is how important it was to have a diverse set of people, literature, and tools to attack this problem. To be able to state and prove the precise formula for required multiple observations, including some version of the following:&lt;list rend="ul"&gt;&lt;item&gt;The sequence can be numerically computed as a sequence of rational numbers.&lt;/item&gt;&lt;item&gt;When appropriately normalized and arranged, visible patterns in this sequence appear that allow one to conjecture the form of the sequence.&lt;/item&gt;&lt;item&gt;This problem is a weighted version of the Erdős-Szekeres theorem.&lt;/item&gt;&lt;item&gt;Among the many proofs of the Erdős-Szekeres theorem is the proof of Seidenberg in 1959, which can be interpreted as a discrete rectangle packing argument.&lt;/item&gt;&lt;item&gt;This problem can be reinterpreted as a continuous square packing problem, and in fact is closely related to (a generalized axis-parallel form of) Erdős problem 106, which concerns such packings.&lt;/item&gt;&lt;item&gt;The axis-parallel form of Erdős problem 106 was recently solved by Baek-Koizumi-Ueoro.&lt;/item&gt;&lt;item&gt;The paper of Praton shows that Erdős Problem 106 implies the generalized version needed for this problem. This implication specializes to the axis-parallel case.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Another key ingredient was the balanced AI policy on the Erdős problem website, which encourages disclosed AI usage while strongly discouraging undisclosed use. To quote from that policy: “Comments prepared with the assistance of AI are permitted, provided (a) this is disclosed, (b) the contents (including mathematics, code, numerical data, and the existence of relevant sources) have been carefully checked and verified by the user themselves without the assistance of AI, and (c) the comment is not unreasonably long.”&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46284897</guid><pubDate>Tue, 16 Dec 2025 04:49:03 +0000</pubDate></item><item><title>Bonsai: A Voxel Engine, from scratch</title><link>https://github.com/scallyw4g/bonsai</link><description>&lt;doc fingerprint="5a19635f49de9c16"&gt;
  &lt;main&gt;
    &lt;p&gt;Bonsai is a voxel engine in a pot. It's been tended to with love and care over the years. It started out as a learning excercise, and has taught me the value of simplicity.&lt;/p&gt;
    &lt;p&gt;Bonsai supports massive worlds. The current version supports a maximum world size of ~1 billion blocks, cubed. At one block per meter, that's the distance from earth to the moon, 2600 times, in every direction. The view distance is the entire world, all the time. Yes, you read that right. In Bonsai, you can see in a straight line from Jupiter to the sun.&lt;/p&gt;
    &lt;p&gt;Bonsai terrain generation is fully procedural, and user configurable. Terrain is generated on the GPU using regular glsl shaders. Anything you can do in a shader, you can do in a Bonsai terrain generator.&lt;/p&gt;
    &lt;p&gt;The current version is 2.0.0-prealpha-rc0, which can be found by joining the Discord. This version is a large rewrite of several core systems, including the world generation, editor and parts of the renderer.&lt;/p&gt;
    &lt;p&gt;In its current state, the engine is effectively a terrain generator and editor. For details on remaing work, see Roadmap to v2.0.0.&lt;/p&gt;
    &lt;p&gt;Bonsai, and nearly all it's dependencies, are written completely from scratch. One external dependency is the C runtime library for program startup. There is a back-burner task to remove the CRT entirely, athough it's unclear when/if anyone will ever get around to it.&lt;/p&gt;
    &lt;p&gt;The only external requirements to build Bonsai are clang++ (&amp;gt;= version 18.1) and a few appropriate system headers.&lt;/p&gt;
    &lt;p&gt;Grab pre-built binaries &amp;amp; assets from the Latest Releases for your platform of your choice (as long as your platform of choice is Windows or Linux) ;)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deferred Shading&lt;/item&gt;
      &lt;item&gt;HDR Lighting&lt;/item&gt;
      &lt;item&gt;Order-independant Transparency&lt;/item&gt;
      &lt;item&gt;Lighting Bloom&lt;/item&gt;
      &lt;item&gt;Shadow Mapping&lt;/item&gt;
      &lt;item&gt;Screen Space Ambient Occlusion&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hot Shader &amp;amp; Game-code Reloading&lt;/item&gt;
      &lt;item&gt;Async Job System&lt;/item&gt;
      &lt;item&gt;Entities&lt;/item&gt;
      &lt;item&gt;Collision&lt;/item&gt;
      &lt;item&gt;Transparent &amp;amp; Emissive Particles&lt;/item&gt;
      &lt;item&gt;UI Framework&lt;/item&gt;
      &lt;item&gt;Asset Loaders&lt;/item&gt;
      &lt;item&gt;Primitive Physics&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully programmable GPU-based terrain generation&lt;/item&gt;
      &lt;item&gt;Batteries-included library of pre-built terrain shaders&lt;/item&gt;
      &lt;item&gt;1D, 2D and 3D noise library&lt;/item&gt;
      &lt;item&gt;Terrain derivitives available in second-stage terrain "decoration"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSG-like SDF world editing&lt;/item&gt;
      &lt;item&gt;Library of primitive shapes (rect, sphere, line, cylinder .. etc)&lt;/item&gt;
      &lt;item&gt;SDF brush-based texturing of primitives&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Layer-based brush GUI&lt;/item&gt;
      &lt;item&gt;(coming soon) glsl brush shaders&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manual Instrumentation&lt;/item&gt;
      &lt;item&gt;Memory allocation tracking&lt;/item&gt;
      &lt;item&gt;Multithreaded callgraph tracing&lt;/item&gt;
      &lt;item&gt;Context Switches (windows only)&lt;/item&gt;
      &lt;item&gt;Physical Core (windows only)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] HRC : https://github.com/entropylost/amitabha&lt;/p&gt;
    &lt;p&gt;[ ] SSR : https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html&lt;/p&gt;
    &lt;p&gt;[ ] Screen-space lines : https://mattdesl.svbtle.com/drawing-lines-is-hard&lt;/p&gt;
    &lt;p&gt;[ ] Better shadows : https://developer.nvidia.com/gpugems/gpugems3/part-ii-light-and-shadows/chapter-8-summed-area-variance-shadow-maps&lt;/p&gt;
    &lt;p&gt;[ ] Screen Space Shadows : https://panoskarabelas.com/posts/screen_space_shadows/&lt;/p&gt;
    &lt;p&gt;[ ] Motion Blur : https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-27-motion-blur-post-processing-effect&lt;/p&gt;
    &lt;p&gt;[ ] TAA?&lt;/p&gt;
    &lt;p&gt;[ ] FXAA : http://blog.simonrodriguez.fr/articles/2016/07/implementing_fxaa.html&lt;/p&gt;
    &lt;p&gt;[ ] Water : https://www.youtube.com/watch?v=5yhDb9dzJ58&lt;/p&gt;
    &lt;p&gt;[ ] Fluids : https://andrewkchan.dev/posts/fire.html&lt;/p&gt;
    &lt;p&gt;[ ] Remove meshing entirely? https://www.youtube.com/watch?v=4xs66m1Of4A&lt;/p&gt;
    &lt;p&gt;[ ] Lumen-style GI screen-space radiance caching : https://www.youtube.com/watch?v=2GYXuM10riw&lt;/p&gt;
    &lt;p&gt;[ ] Erosion simulation&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://inria.hal.science/hal-01262376/document&lt;/item&gt;
      &lt;item&gt;https://xing-mei.github.io/files/erosion.pdf&lt;/item&gt;
      &lt;item&gt;https://nickmcd.me/2020/04/15/procedural-hydrology/&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] Biomes&lt;/p&gt;
    &lt;p&gt;[ ] Meshing&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Isotropic surface meshing&lt;/item&gt;
      &lt;item&gt;https://graphics.stanford.edu/courses/cs164-10-spring/Handouts/isotropic.pdf&lt;/item&gt;
      &lt;item&gt;https://inria.hal.science/inria-00071612/document&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] MCA importer&lt;/p&gt;
    &lt;p&gt;[ ] Sound : mp3, ogg, ..? decompresser&lt;/p&gt;
    &lt;p&gt;[ ] Better low-discrepency sequences : https://blog.demofox.org/2017/05/29/when-random-numbers-are-too-random-low-discrepancy-sequences/&lt;/p&gt;
    &lt;p&gt;[ ] Better disk/sphere sampling patterns : https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/&lt;/p&gt;
    &lt;p&gt;[ ] Better hash function! : https://nullprogram.com/blog/2018/07/31/&lt;/p&gt;
    &lt;p&gt;[ ] Better GPU hashing! : https://arugl.medium.com/hash-noise-in-gpu-shaders-210188ac3a3e&lt;/p&gt;
    &lt;p&gt;[ ] Hash-trie as alternative to a table : https://nullprogram.com/blog/2023/09/30/&lt;/p&gt;
    &lt;p&gt;[ ] Octree ? https://graphics.tudelft.nl/Publications-new/2020/CBE20/ModifyingCompressedVoxels-main.pdf&lt;/p&gt;
    &lt;p&gt;[ ] Better floating-point rng : https://www.corsix.org/content/higher-quality-random-floats&lt;/p&gt;
    &lt;p&gt;[ ] Better greedy meshing? https://www.youtube.com/watch?v=4xs66m1Of4A&lt;/p&gt;
    &lt;p&gt;[ ] More interpolation goodies : https://paulbourke.net/miscellaneous/interpolation/&lt;/p&gt;
    &lt;p&gt;[ ] Better (faster) Sin/Cos ? https://www.shadertoy.com/view/432yWW&lt;/p&gt;
    &lt;p&gt;[ ] Look into using this Intel tooling for dual CPU/GPU world-gen? https://www.intel.com/content/dam/develop/external/us/en/documents/spir-vtointe-ispcgpu-compute-on-the-cpu.pdf https://ispc.github.io/&lt;/p&gt;
    &lt;p&gt;[ ] Improve the ETW layer : https://github.com/bombomby/optick/blob/master/src/optick_core.win.h&lt;/p&gt;
    &lt;p&gt;[ ] GPU Profiling : https://www.khronos.org/opengl/wiki/Query_Object&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46285319</guid><pubDate>Tue, 16 Dec 2025 06:06:43 +0000</pubDate></item><item><title>Children with cancer scammed out of millions fundraised for their treatment</title><link>https://www.bbc.com/news/articles/ckgz318y8elo</link><description>&lt;doc fingerprint="274d9985a18985a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Children with cancer scammed out of millions fundraised for their treatment, BBC finds&lt;/head&gt;
    &lt;p&gt;Warning: Disturbing content&lt;/p&gt;
    &lt;p&gt;A little boy faces the camera. He is pale and has no hair.&lt;/p&gt;
    &lt;p&gt;"I am seven years old and I have cancer," he says. "Please save my life and help me."&lt;/p&gt;
    &lt;p&gt;Khalil - who is pictured above in a still from the film - didn't want to record this, says his mother Aljin. She had been asked to shave his head, and then a film crew hooked him up to a fake drip, and asked his family to pretend it was his birthday. They had given him a script to learn and recite in English.&lt;/p&gt;
    &lt;p&gt;And he didn't like it, says Aljin, when chopped onions were placed next to him, and menthol put under his eyes, to make him cry.&lt;/p&gt;
    &lt;p&gt;Aljin agreed to it because, although the set-up was fake, Khalil really did have cancer. She was told this video would help crowdfund money for better treatment. And it did raise funds - $27,000 (£20,204), according to a campaign we found in Khalil's name.&lt;/p&gt;
    &lt;p&gt;But Aljin was told the campaign had failed, and says she received none of this money - just a $700 (£524) filming fee on the day. One year later, Khalil died.&lt;/p&gt;
    &lt;p&gt;Across the world, desperate parents of sick or dying children are being exploited by online scam campaigns, the BBC World Service has discovered. The public have given money to the campaigns, which claim to be fundraising for life-saving treatment. We have identified 15 families who say they got little to nothing of the funds raised and often had no idea the campaigns had even been published, despite undergoing harrowing filming.&lt;/p&gt;
    &lt;p&gt;Nine families we spoke to - whose campaigns appear to be products of the same scam network - say they never received anything at all of the $4m (£2.9m) apparently raised in their names.&lt;/p&gt;
    &lt;p&gt;A whistleblower from this network told us they had looked for "beautiful children" who "had to be three to nine years old… without hair".&lt;/p&gt;
    &lt;p&gt;We have identified a key player in the scam as an Israeli man living in Canada called Erez Hadari.&lt;/p&gt;
    &lt;p&gt;Our investigation began in October 2023, when a distressing YouTube advert caught our attention. "I don't want to die," a girl called Alexandra from Ghana sobbed. "My treatments cost a lot."&lt;/p&gt;
    &lt;p&gt;A crowdfunding campaign for her appeared to have raised nearly $700,000 (£523,797).&lt;/p&gt;
    &lt;p&gt;We saw more videos of sick children from around the world on YouTube, all strikingly similar - slickly produced, and seemingly having raised huge amounts of money. They all conveyed a sense of urgency, using emotive language.&lt;/p&gt;
    &lt;p&gt;We decided to investigate further.&lt;/p&gt;
    &lt;p&gt;The campaigns with the biggest apparent international reach were under the name of an organisation called Chance Letikva (Chance for Hope, in English) - registered in Israel and the US.&lt;/p&gt;
    &lt;p&gt;Identifying the children featured was difficult. We used geolocation, social media and facial recognition software to find their families, based as far apart as Colombia and the Philippines.&lt;/p&gt;
    &lt;p&gt;While it was difficult to know for sure if the campaign websites' cash totals were genuine, we donated small amounts to two of them and saw the totals increase by those amounts.&lt;/p&gt;
    &lt;p&gt;We also spoke to someone who says she gave $180 (£135) to Alexandra's campaign and was then inundated with requests for more, all written as if sent by Alexandra and her father.&lt;/p&gt;
    &lt;p&gt;In the Philippines, Aljin Tabasa told us her son Khalil had fallen ill just after his seventh birthday.&lt;/p&gt;
    &lt;p&gt;"When we found out it was cancer it felt like my whole world shattered," she says.&lt;/p&gt;
    &lt;p&gt;Aljin says treatment at their local hospital in the city of Cebu was slow, and she had messaged everyone she could think of for help. One person put her in touch with a local businessman called Rhoie Yncierto - who asked for a video of Khalil which, looking back, Aljin realises was essentially an audition.&lt;/p&gt;
    &lt;p&gt;Another man then arrived from Canada in December 2022, introducing himself as "Erez". He paid her the filming fee up front, she says, promising a further $1,500 (£1,122) a month if the film generated lots of donations.&lt;/p&gt;
    &lt;p&gt;Erez directed Khalil's film at a local hospital, asking for retake after retake - the shoot taking 12 hours, Aljin says.&lt;/p&gt;
    &lt;p&gt;Months later, the family say they had still not heard how the video had performed. Aljin messaged Erez, who told her the video "wasn't successful".&lt;/p&gt;
    &lt;p&gt;"So as I understood it, the video just didn't make any money," she says.&lt;/p&gt;
    &lt;p&gt;But we told her the campaign had apparently collected $27,000 (£20,204) as of November 2024, and was still online.&lt;/p&gt;
    &lt;p&gt;"If I had known the money we had raised, I can't help but think that maybe Khalil would still be here," Aljin says. "I don't understand how they could do this to us."&lt;/p&gt;
    &lt;p&gt;When asked about his role in the filming, Rhoie Yncierto denied telling families to shave their children's heads for filming and said he had received no payment for recruiting families.&lt;/p&gt;
    &lt;p&gt;He said he had "no control" over what happened with the funds and had no contact with the families after the day of filming. When we told him they had not received any of the campaigns' donations he said he was "puzzled" and was "very sorry for the families".&lt;/p&gt;
    &lt;p&gt;Nobody named Erez appears on registration documents for Chance Letikva. But two of its campaigns we investigated had also been promoted by another organisation called Walls of Hope, registered in Israel and Canada. Documents list the director in Canada as Erez Hadari.&lt;/p&gt;
    &lt;p&gt;Photos of him online show him at Jewish religious events in the Philippines, New York and Miami. We showed Aljin, and she said it was the same person she had met.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Outside the UK, watch the film on BBC World Service YouTube&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We asked Mr Hadari about his involvement in a campaign in the Philippines. He did not respond.&lt;/p&gt;
    &lt;p&gt;We visited further families whose campaigns were either organised by, or linked to, Mr Hadari - one in a remote indigenous community in Colombia, and another in Ukraine.&lt;/p&gt;
    &lt;p&gt;As with Khalil's case, local fixers had got in touch to offer help. The children were filmed and made to cry or fake tears for a nominal fee, but never received any further money.&lt;/p&gt;
    &lt;p&gt;In Sucre, north-west Colombia, Sergio Care says he initially refused this help. He had been approached by someone called Isabel, he says, who offered financial assistance after his eight-year-old daughter, Ana, was diagnosed with a malignant brain tumour.&lt;/p&gt;
    &lt;p&gt;But Isabel came looking for him at the hospital treating Ana, he says, accompanied by a man who said he worked for an international NGO.&lt;/p&gt;
    &lt;p&gt;The description Sergio gave of the man matched that of Erez Hadari - he then recognised him in a photo we showed him.&lt;/p&gt;
    &lt;p&gt;"He gave me hope... I didn't have any money for the future."&lt;/p&gt;
    &lt;p&gt;Demands on the family did not end with the filming.&lt;/p&gt;
    &lt;p&gt;Isabel kept ringing, Sergio says, demanding more photos of Ana in hospital. When Sergio didn't reply, Isabel started messaging Ana herself - voice notes we have heard.&lt;/p&gt;
    &lt;p&gt;Ana told Isabel she had no more photos to send. Isabel replied: "This is very bad Ana, very bad indeed."&lt;/p&gt;
    &lt;p&gt;In January this year, Ana - now fully recovered - tried to find out what happened to the money promised.&lt;/p&gt;
    &lt;p&gt;"That foundation disappeared," Isabel told her in a voice note. "Your video was never uploaded. Never. Nothing was done with it, you hear?"&lt;/p&gt;
    &lt;p&gt;But we could see the video had been uploaded and, by April 2024, appeared to have raised nearly $250,000 (£187,070).&lt;/p&gt;
    &lt;p&gt;In October, we persuaded Isabel Hernandez to speak to us over video link.&lt;/p&gt;
    &lt;p&gt;A friend from Israel, she explained, had introduced her to someone offering work for "a foundation" looking to help children with cancer. She refused to name who she worked for.&lt;/p&gt;
    &lt;p&gt;She was told only one of the campaigns she helped organise was published, she says, and that it had not been successful.&lt;/p&gt;
    &lt;p&gt;We showed Isabel that two campaigns had in fact been uploaded - one of them apparently raising more than $700,000 (£523,797).&lt;/p&gt;
    &lt;p&gt;"I need to apologise to [the families]," she said. "If I'd known what was going on, I would not have been able to do something like this."&lt;/p&gt;
    &lt;p&gt;In Ukraine, we discovered that the person who approached the mother of a sick child was actually employed in the place where the campaign video was filmed.&lt;/p&gt;
    &lt;p&gt;Tetiana Khaliavka organised a shoot with five-year-old Viktoriia, who has brain cancer, at Angelholm Clinic in Chernivtsi.&lt;/p&gt;
    &lt;p&gt;One Facebook post linked to Chance Letikva's campaign shows Viktoriia and her mother Olena Firsova, sitting on a bed. "I see your efforts to save my daughter, and it deeply moves us all. It's a race against time to raise the amount needed for Viktoriia's treatments," reads the caption.&lt;/p&gt;
    &lt;p&gt;Olena says she never wrote or even said these words and had no idea the campaign had been uploaded.&lt;/p&gt;
    &lt;p&gt;It appears to have raised more than €280,000 (£244,000).&lt;/p&gt;
    &lt;p&gt;Tetiana, we were told, was in charge of advertising and communications at Angelholm.&lt;/p&gt;
    &lt;p&gt;The clinic recently told the BBC it didn't approve filming on its premises - adding: "The clinic has never participated in, nor supported, any fundraising initiatives organised by any organisation."&lt;/p&gt;
    &lt;p&gt;Angelholm says it has terminated Tetiana Khaliavka's employment.&lt;/p&gt;
    &lt;p&gt;Olena showed us the contract she had been asked to sign.&lt;/p&gt;
    &lt;p&gt;In addition to the family's $1,500 (£1,122) filming fee on the day, it states they would get $8,000 (£5,986) once the fundraising goal was met. The amount for the goal, however, has been left blank.&lt;/p&gt;
    &lt;p&gt;The contract showed an address in New York for Chance Letikva. On the organisation's website, there is another - in Beit Shemesh, about an hour from Jerusalem. We travelled to both, but found no sign of it.&lt;/p&gt;
    &lt;p&gt;And we discovered Chance Letikva seems to be one of many such organisations.&lt;/p&gt;
    &lt;p&gt;The man who filmed Viktoriia's campaign told our producer - who was posing as a friend of a sick child - that he works for other similar organisations.&lt;/p&gt;
    &lt;p&gt;"Each time, it's a different one," the man - who had introduced himself as "Oleh" - told her. "I hate to put it this way, but they work kind of like a conveyor belt."&lt;/p&gt;
    &lt;p&gt;"About a dozen similar companies" requested "material", he said, naming two of them - Saint Teresa and Little Angels, both registered in the US.&lt;/p&gt;
    &lt;p&gt;When we checked their registration documents, we once again found Erez Hadari's name.&lt;/p&gt;
    &lt;p&gt;What is not clear is where the money raised for the children has gone.&lt;/p&gt;
    &lt;p&gt;More than a year after Viktoriia's filming, her mother Olena rang Oleh, who seems to go by Alex Kohen online, to find out. Shortly afterwards, someone from Chance Letikva called to say the donations had paid for advertising, she says.&lt;/p&gt;
    &lt;p&gt;This is also what Mr Hadari told Aljin, Khalil's mother, when she confronted him over the phone.&lt;/p&gt;
    &lt;p&gt;"There is cost of advertising. So the company lost money," Mr Hadari told her, without giving any evidence to support this.&lt;/p&gt;
    &lt;p&gt;Charity experts told us advertising should not amount to more than 20% of the total raised by campaigns.&lt;/p&gt;
    &lt;p&gt;Someone previously employed to recruit children for Chance Letikva campaigns told us how those featured had been chosen.&lt;/p&gt;
    &lt;p&gt;They had been asked to visit oncology clinics, they said - speaking on condition of anonymity.&lt;/p&gt;
    &lt;p&gt;"They were always looking for beautiful children with white skin. The child had to be three to nine years old. They had to know how to speak well. They had to be without hair," they told us.&lt;/p&gt;
    &lt;p&gt;"They asked me for photos, to see if the child is right, and I would send it to Erez."&lt;/p&gt;
    &lt;p&gt;The whistleblower told us Mr Hadari would then send the photo on to someone else, in Israel, whose name they were never told.&lt;/p&gt;
    &lt;p&gt;As for Mr Hadari himself, we tried to reach him at two addresses in Canada but could not find him. He replied to one voice note we had sent him - asking about the money he had been apparently crowdfunding - by saying the organisation "has never been active", without specifying which one. He did not respond to a further voice note and letter laying out all our questions and allegations.&lt;/p&gt;
    &lt;p&gt;Campaigns set up by Chance Letikva for two children who died - Khalil and a Mexican boy called Hector - still appear to be accepting money.&lt;/p&gt;
    &lt;p&gt;Chance Letikva's US branch appears to be linked to a new organisation called Saint Raphael, which has produced more campaigns - at least two of which seem to have been filmed in Angelholm clinic in Ukraine, as the clinic's distinctive wood panelling and staff uniforms can be seen.&lt;/p&gt;
    &lt;p&gt;Olena, Viktoriia's mother, says her daughter has been diagnosed with another brain tumour. She says she is sickened by the findings of our investigation.&lt;/p&gt;
    &lt;p&gt;"When your child is… hanging on the edge of life, and someone's out there, making money off that. Well, it's filthy. It's blood money."&lt;/p&gt;
    &lt;p&gt;The BBC contacted Tetiana Khaliavka and Alex Kohen, and the organisations Chance Letikva, Walls of Hope, Saint Raphael, Little Angels and Saint Teresa - inviting them to respond to the allegations made against them. None of them replied.&lt;/p&gt;
    &lt;p&gt;The Israeli Corporations Authority, which oversees the country's non-profit organisations, told us that if it has evidence founders are using entities as "a cover for illegal activity", then registration inside Israel may be denied and the founder could be barred from working in the sector.&lt;/p&gt;
    &lt;p&gt;UK regulator, the Charity Commission, advises those wishing to donate to charities to check that those associations are registered, and that the appropriate fundraising regulator should be contacted if in doubt.&lt;/p&gt;
    &lt;p&gt;Additional reporting by: Ned Davies, Tracks Saflor, Jose Antonio Lucio, Almudena Garcia-parrado, Vitaliya Kozmenko, Shakked Auerbach, Tom Tzur Wisfelder, Katya Malofieieva, Anastasia Kucher, Alan Pulido and Neil McCarthy&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you have any information to add to this investigation please contact simi@bbc.co.uk&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46285376</guid><pubDate>Tue, 16 Dec 2025 06:17:37 +0000</pubDate></item><item><title>A linear-time alternative for Dimensionality Reduction and fast visualisation</title><link>https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f</link><description>&lt;doc fingerprint="a1a6a01b0b669bba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Linear-Time Alternative To t-SNE for Dimensionality Reduction and Fast Visualisation&lt;/head&gt;
    &lt;p&gt;Moving data visualisation from a Python notebook to a web browser usually demands a painful compromise: you either pay for a heavy GPU backend or you force the user to wait while JavaScript struggles through iterative algorithms.&lt;/p&gt;
    &lt;p&gt;This article explores a third option: Sine Landmark Reduction (SLR).&lt;/p&gt;
    &lt;p&gt;SLR is a deterministic, linear-time alternative to t-SNE designed specifically for the browser. It bypasses the heavy optimisation loops of traditional methods by using trilateration against a fixed topological skeleton. The result? A method fast enough to power Thingbook’s DriftMind stack, capable of mapping 9,000 datapoints (at 50 dimensions) into 3D space in under two seconds.&lt;/p&gt;
    &lt;p&gt;We will cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why t-SNE/UMAP are a poor fit for the browser&lt;/item&gt;
      &lt;item&gt;The idea of landmarks instead of all-pairs distances&lt;/item&gt;
      &lt;item&gt;How to build a synthetic “sine skeleton” in high-D&lt;/item&gt;
      &lt;item&gt;How linearised trilateration turns distances into coordinates&lt;/item&gt;
      &lt;item&gt;Two important refinements: alpha scaling and distance warping&lt;/item&gt;
      &lt;item&gt;A compact Python implementation of SLR you can experiment with today&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why do most dimensionality-reduction techniques fail in resource-limited environments? (such as your browser…)&lt;/head&gt;
    &lt;p&gt;Methods like t-SNE and UMAP are excellent for static, offline exploration, but they are fundamentally unsuited for rapid, iterative visual inspection. During exploratory analysis, many data-driven decisions depend on immediate feedback, insights that guide the next analytical step or help you assess the operational status of highly complex datasets. When the underlying method cannot deliver results interactively due to memory or compute constraints, the entire exploratory workflow breaks down. Several reasons explain this limitation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They rely on iterative optimisation (gradient descent style loops).&lt;/item&gt;
      &lt;item&gt;They typically need to compare many or all points to each other, leading to O(N²) complexity.&lt;/item&gt;
      &lt;item&gt;For 10,000 points, that’s on the order of 100 million pairwise interactions.&lt;/item&gt;
      &lt;item&gt;In a browser, that means dropped frames, frozen UIs, or shipping the entire dataset to a backend.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For an interactive tool where users drag-and-drop a CSV and expect something to appear almost instantly, we need something closer to O(N): one pass over the points, not N passes.&lt;/p&gt;
    &lt;p&gt;This is the design target for SLR:&lt;lb/&gt;linear time, deterministic, analytic, and simple enough to run in plain JavaScript or WebAssembly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Landmarks Instead of All-Pairs&lt;/head&gt;
    &lt;p&gt;The core idea is simple: Instead of comparing every point to every other point, compare every point to a small, fixed set of landmarks. Imagine placing 100 “radio towers” in high-dimensional space (k=50) to cover all the space. To embed a new point x, you don’t ask&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“how far am I from every other point?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You only ask:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“How far am I from each of these 100 towers?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we do this for N points, the work is O(N × k). With k fixed and relatively small, this is effectively O(N).&lt;/p&gt;
    &lt;p&gt;The key questions then become:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;How do we choose good landmarks to place my towers?&lt;/item&gt;
      &lt;item&gt;Given only distances to these landmarks, how do we reconstruct a low-dimensional coordinate?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR answers these with:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A sine-based synthetic skeleton or data-derived skeleton&lt;/item&gt;
      &lt;item&gt;A fast, analytic linearised trilateration step inspired by GPS localisation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Building a Synthetic Sine Skeleton&lt;/head&gt;
    &lt;p&gt;The first way to obtain landmarks is to invent them synthetically, without using any real data points. SLR defines a smooth path through the n-dimensional space using independent sine waves on each dimension:&lt;/p&gt;
    &lt;p&gt;Each coordinate uses its own amplitude, frequency, and phase, drawn from simple uniform distributions. In code:&lt;/p&gt;
    &lt;code&gt;class SineLandmarkReduction:&lt;lb/&gt;    def __init__(self, n_components=2, n_landmarks=50,&lt;lb/&gt;                 random_state=42, synthetic_landmarks=False):&lt;lb/&gt;        self.n_components = n_components&lt;lb/&gt;        self.k = n_landmarks&lt;lb/&gt;        self.synthetic_landmarks = synthetic_landmarks&lt;lb/&gt;        self.rng = np.random.RandomState(random_state)&lt;lb/&gt;&lt;lb/&gt;    def _gamma(self, t, a, omega, phi):&lt;lb/&gt;        """Synthetic sine path function γ(t)."""&lt;lb/&gt;        # result shape: (n_dims, n_landmarks)&lt;lb/&gt;        return a[:, None] * np.sin(omega[:, None] * t + phi[:, None])&lt;/code&gt;
    &lt;p&gt;To build the landmarks:&lt;/p&gt;
    &lt;code&gt;a = self.rng.uniform(0.5, 2.0, n_features)&lt;lb/&gt;omega = self.rng.uniform(0.5, 1.5, n_features)&lt;lb/&gt;phi = self.rng.uniform(0, 2 * np.pi, n_features)&lt;lb/&gt;t = np.linspace(0, 2 * np.pi, self.k)&lt;lb/&gt;&lt;lb/&gt;self.L_high = self._gamma(t, a, omega, phi).T  # shape: (k, n_features)&lt;/code&gt;
    &lt;p&gt;We then sample k points along this path to define the high-dimensional landmarks:&lt;/p&gt;
    &lt;p&gt;Because the curve winds smoothly through the space, the landmarks form a well-spread, continuous loop when projected to 3D subspaces:&lt;/p&gt;
    &lt;p&gt;Why sine waves?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extremely cheap to compute&lt;/item&gt;
      &lt;item&gt;Deterministic given a random seed&lt;/item&gt;
      &lt;item&gt;Naturally explore the space without clustering in arbitrary regions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This mode is ideal when you want a stable, model-driven skeleton that is independent of the dataset.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data-Derived Landmarks and Hybrid Normalisation&lt;/head&gt;
    &lt;p&gt;SLR allows you to skip the automatic skeleton generation and extract the Landmarks from your dataset structure without losing the O(N) complexity. Essentially, this mode lets the landmarks adapt to the data. This is useful when the dataset has a strong cluster structure or an interesting topology that a synthetic curve might miss.&lt;/p&gt;
    &lt;p&gt;The trick is a hybrid normalisation strategy:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Raw selection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Select landmark indices from the unnormalised data.&lt;/item&gt;
      &lt;item&gt;High-variance features dominate cluster structure; staying in raw scale helps us capture that.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Normalised computation&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;After selecting the landmarks, normalise both X and the selected landmarks (e.g. StandardScaler).&lt;/item&gt;
      &lt;item&gt;All features then contribute fairly to Euclidean distances during trilateration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the implementation:&lt;/p&gt;
    &lt;code&gt;if self.synthetic_landmarks:&lt;lb/&gt;    # synthetic branch (see previous section)&lt;lb/&gt;    ...&lt;lb/&gt;else:&lt;lb/&gt;    # 1. Select k landmark indices from raw data&lt;lb/&gt;    idx = self.rng.choice(n_samples, size=self.k, replace=False)&lt;lb/&gt;    self.L_high = X[idx].copy()  # raw landmarks&lt;lb/&gt;&lt;lb/&gt;    # 2. Fit PCA skeleton on raw landmarks&lt;lb/&gt;    L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;&lt;lb/&gt;    # 3. Normalise X and landmarks for distance computations&lt;lb/&gt;    X_scaled = scaler.fit_transform(X)&lt;lb/&gt;    self.L_high = scaler.transform(self.L_high)&lt;/code&gt;
    &lt;p&gt;We now have high-D landmarks &lt;code&gt;L ∈ R^(k×n)&lt;/code&gt;. To embed everything in e.g. 2D or 3D, we first map the landmarks themselves to a low dimension using PCA:&lt;/p&gt;
    &lt;p&gt;1. Centre the Data: Centre the landmark matrix &lt;code&gt;L&lt;/code&gt; to obtain &lt;code&gt;L_bar&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;2. Compute Covariance: Compute the covariance matrix &lt;code&gt;Σ&lt;/code&gt;: &lt;code&gt;Σ = (1 / k-1) · L_barᵀ · L_bar&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;3. Form the Projection Matrix: Take the top &lt;code&gt;m&lt;/code&gt; eigenvectors to form the projection matrix &lt;code&gt;Wm&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;4. Project to Low Dimensions: Obtain low-D landmark coordinates &lt;code&gt;L’_raw&lt;/code&gt;: &lt;code&gt;L’_raw = L_bar · Wm&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Because the distance computations later are done in the normalised feature space, we match scales using an RMS ratio:&lt;/p&gt;
    &lt;code&gt;rms_high = np.sqrt(np.mean([&lt;lb/&gt;    np.linalg.norm(self.L_high[i] - self.L_high[j])**2&lt;lb/&gt;    for i in range(self.k) for j in range(i+1, self.k)&lt;lb/&gt;]))&lt;lb/&gt;rms_low = np.sqrt(np.mean([&lt;lb/&gt;    np.linalg.norm(L_low_raw[i] - L_low_raw[j])**2&lt;lb/&gt;    for i in range(self.k) for j in range(i+1, self.k)&lt;lb/&gt;]))&lt;lb/&gt;&lt;lb/&gt;self.L_low = L_low_raw * (rms_high / rms_low)&lt;/code&gt;
    &lt;p&gt;This ensures:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The shape of the low-D skeleton matches the raw data geometry (for data-derived landmarks).&lt;/item&gt;
      &lt;item&gt;The scale of the skeleton is compatible with the normalised distance metric.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Linearised Trilateration: The GPS Analogy&lt;/head&gt;
    &lt;p&gt;With landmarks defined both in high-D and low-D, the core embedding step becomes:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Given a point&lt;/p&gt;&lt;code&gt;x&lt;/code&gt;, find a low-D point&lt;code&gt;y&lt;/code&gt;whose distances to the low-D landmarks match the high-D distances from&lt;code&gt;x&lt;/code&gt;to the high-D landmarks.&lt;/quote&gt;
    &lt;p&gt;Let:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;L_j&lt;/code&gt;: The high-D landmarks (after scaling).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;L''_j&lt;/code&gt;: The low-D landmarks (&lt;code&gt;self.L_low&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;δ²_j&lt;/code&gt;: The squared distance from&lt;code&gt;x&lt;/code&gt;to landmark&lt;code&gt;j&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We ideally want:&lt;/p&gt;
    &lt;p&gt;This is a classic trilateration problem (think GPS). Naively, it is non-linear in y. SLR’s key trick is to linearise it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Roman Ferrando’s stories in your inbox&lt;/head&gt;
    &lt;p&gt;Join Medium for free to get updates from this writer.&lt;/p&gt;
    &lt;p&gt;Take the equation for landmark 0 and subtract it from each equation j:&lt;/p&gt;
    &lt;p&gt;Expanding and cancelling the &lt;code&gt;yᵀy&lt;/code&gt; terms give a linear system:&lt;/p&gt;
    &lt;p&gt;Stacking these for &lt;code&gt;j = 1…k-1&lt;/code&gt; yields:&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;A&lt;/code&gt;depends only on low-D landmarks.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;b&lt;/code&gt;depends on the measured distances&lt;code&gt;δ²_j&lt;/code&gt;for a given&lt;code&gt;x&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In code, we precompute &lt;code&gt;A&lt;/code&gt; and its pseudoinverse once:&lt;/p&gt;
    &lt;code&gt;# Precompute solver&lt;lb/&gt;self.L0_low = self.L_low[0]&lt;lb/&gt;self.A = 2 * (self.L_low[1:] - self.L0_low)   # shape: (k-1, m)&lt;lb/&gt;self.A_pinv = np.linalg.pinv(self.A)          # Moore–Penrose pseudoinverse&lt;lb/&gt;self.L_low_sq_norms = np.sum(self.L_low**2, axis=1)&lt;/code&gt;
    &lt;p&gt;Then, for a batch of points X:&lt;/p&gt;
    &lt;code&gt;# Squared distances in high-D&lt;lb/&gt;diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;delta_sq = np.sum(diff**2, axis=2)  # shape: (n_samples, k)&lt;lb/&gt;&lt;lb/&gt;# Right-hand side b for all points&lt;lb/&gt;term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]      # shape: (k-1,)&lt;lb/&gt;term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]                    # broadcast&lt;lb/&gt;b = term1 - term2                                             # (n_samples, k-1)&lt;lb/&gt;&lt;lb/&gt;# Initial low-D coordinates (first pass)&lt;lb/&gt;Y_raw = b @ self.A_pinv.T                                     # (n_samples, m)&lt;/code&gt;
    &lt;p&gt;Because A is fixed, embedding a new point is just:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute k squared distances.&lt;/item&gt;
      &lt;item&gt;Build b.&lt;/item&gt;
      &lt;item&gt;One matrix multiplication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is exactly the type of workload that scales linearly with N and runs comfortably in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;Alpha Refinement: Fixing Global Scale&lt;/head&gt;
    &lt;p&gt;In practice, we do a two-pass mapping. The first pass gives Y_raw, but some global scale mismatch can remain between high-D and low-D distances.&lt;/p&gt;
    &lt;p&gt;SLR introduces a global scalar α that best aligns the two:&lt;/p&gt;
    &lt;p&gt;In code:&lt;/p&gt;
    &lt;code&gt;# Squared distances in high-D&lt;lb/&gt;diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;delta_sq = np.sum(diff**2, axis=2)  # shape: (n_samples, k)&lt;lb/&gt;&lt;lb/&gt;# Right-hand side b for all points&lt;lb/&gt;term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]      # shape: (k-1,)&lt;lb/&gt;term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]                    # broadcast&lt;lb/&gt;b = term1 - term2                                             # (n_samples, k-1)&lt;lb/&gt;&lt;lb/&gt;# Initial low-D coordinates (first pass)&lt;lb/&gt;Y_raw = b @ self.A_pinv.T                                     # (n_samples, m)&lt;/code&gt;
    &lt;p&gt;We then rescale the high-D distances and solve again:&lt;/p&gt;
    &lt;code&gt;delta_sq_corrected = (alpha**2) * delta_sq&lt;lb/&gt;&lt;lb/&gt;term2_corr = delta_sq_corrected[:, 1:] - delta_sq_corrected[:, 0:1]&lt;lb/&gt;b_corr = term1 - term2_corr&lt;lb/&gt;&lt;lb/&gt;Y_final = b_corr @ self.A_pinv.T&lt;/code&gt;
    &lt;p&gt;This simple, non-iterative correction significantly improves embedding quality while keeping the whole procedure analytic and fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;Distance Warping: Tuning Locality vs Global Geometry&lt;/head&gt;
    &lt;p&gt;t-SNE is popular because it exaggerates local structure: clusters become very tight and well separated. Pure trilateration, on the other hand, preserves global geometry more faithfully.&lt;/p&gt;
    &lt;p&gt;SLR adds a knob to interpolate between these behaviours via distance warping:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;p = 1.0&lt;/code&gt;→ pure global geometry&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p ≈ 0.5&lt;/code&gt;→ stronger local neighbourhoods&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p ≈ 0.33&lt;/code&gt;→ visually similar separation to t-SNE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the reference implementation, the warp is applied right after computing distances:&lt;/p&gt;
    &lt;code&gt;# delta_sq shape: (k,)&lt;lb/&gt;delta_sq = np.sum((x - self.L_high)**2, axis=1)&lt;lb/&gt;&lt;lb/&gt;# Nonlinear locality warp&lt;lb/&gt;delta = np.sqrt(delta_sq)   # Euclidean distances&lt;lb/&gt;p = 0.5                     # try 0.5; smaller p → stronger locality&lt;lb/&gt;delta = delta ** p&lt;lb/&gt;delta_sq = delta ** 2&lt;/code&gt;
    &lt;p&gt;This gives you t-SNE-like cluster separation while preserving the deterministic, analytic nature of SLR.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting It Together: The &lt;code&gt;fit_transform&lt;/code&gt; Pipeline&lt;/head&gt;
    &lt;p&gt;The full &lt;code&gt;fit_transform&lt;/code&gt; method ties everything together: scaling, landmark construction, PCA, trilateration, alpha refinement, and final embedding.&lt;/p&gt;
    &lt;p&gt;Here is a condensed view (non-essential boilerplate omitted):&lt;/p&gt;
    &lt;code&gt;def fit_transform(self, X):&lt;lb/&gt;    scaler = StandardScaler()&lt;lb/&gt;    n_samples, n_features = X.shape&lt;lb/&gt;    pca = PCA(n_components=self.n_components)&lt;lb/&gt;&lt;lb/&gt;    if self.synthetic_landmarks:&lt;lb/&gt;        # Synthetic sine landmarks&lt;lb/&gt;        a = self.rng.uniform(0.5, 2.0, n_features)&lt;lb/&gt;        omega = self.rng.uniform(0.5, 1.5, n_features)&lt;lb/&gt;        phi = self.rng.uniform(0, 2 * np.pi, n_features)&lt;lb/&gt;        t = np.linspace(0, 2 * np.pi, self.k)&lt;lb/&gt;        self.L_high = self._gamma(t, a, omega, phi).T&lt;lb/&gt;        L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;        X_scaled = scaler.fit_transform(X)&lt;lb/&gt;    else:&lt;lb/&gt;        # Data-derived landmarks&lt;lb/&gt;        idx = self.rng.choice(n_samples, size=self.k, replace=False)&lt;lb/&gt;        self.L_high = X[idx].copy()&lt;lb/&gt;        L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;        X_scaled = scaler.fit_transform(X)&lt;lb/&gt;        self.L_high = scaler.transform(self.L_high)&lt;lb/&gt;&lt;lb/&gt;    # RMS scaling of low-D skeleton&lt;lb/&gt;    ...  # (rms_high / rms_low scaling as shown earlier)&lt;lb/&gt;&lt;lb/&gt;    # Precompute trilateration solver&lt;lb/&gt;    self.L0_low = self.L_low[0]&lt;lb/&gt;    self.A = 2 * (self.L_low[1:] - self.L0_low)&lt;lb/&gt;    self.A_pinv = np.linalg.pinv(self.A)&lt;lb/&gt;    self.L_low_sq_norms = np.sum(self.L_low**2, axis=1)&lt;lb/&gt;&lt;lb/&gt;    # Vectorised first pass (Y_raw)&lt;lb/&gt;    diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;    delta_sq = np.sum(diff**2, axis=2)&lt;lb/&gt;    term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]&lt;lb/&gt;    term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]&lt;lb/&gt;    b = term1 - term2&lt;lb/&gt;    Y_raw = b @ self.A_pinv.T&lt;lb/&gt;&lt;lb/&gt;    # Alpha refinement and second pass&lt;lb/&gt;    diff_low = Y_raw[:, np.newaxis, :] - self.L_low[np.newaxis, :, :]&lt;lb/&gt;    dist_low = np.linalg.norm(diff_low, axis=2)&lt;lb/&gt;    dist_high = np.sqrt(delta_sq)&lt;lb/&gt;    alpha = np.sum(dist_low * dist_high) / np.sum(delta_sq)&lt;lb/&gt;&lt;lb/&gt;    delta_sq_corrected = (alpha**2) * delta_sq&lt;lb/&gt;    term2_corr = delta_sq_corrected[:, 1:] - delta_sq_corrected[:, 0:1]&lt;lb/&gt;    b_corr = term1 - term2_corr&lt;lb/&gt;    Y_final = b_corr @ self.A_pinv.T&lt;lb/&gt;&lt;lb/&gt;    return Y_final&lt;/code&gt;
    &lt;p&gt;From the browser’s perspective, once the landmarks and pseudoinverse are precomputed, embedding new points is just distance computations + one matrix multiply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: SLR vs t-SNE on a 5-Cluster Dataset&lt;/head&gt;
    &lt;p&gt;To evaluate SLR against a familiar baseline, consider 5 Gaussian clusters in a 20-dimensional space (5,000 points). Using SLR with appropriate p:&lt;/p&gt;
    &lt;p&gt;Using t-SNE on the same data:&lt;/p&gt;
    &lt;p&gt;You get a flavour of the trade-off:&lt;/p&gt;
    &lt;p&gt;t-SNE&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Strong local separation&lt;/item&gt;
      &lt;item&gt;Poor global interpretability&lt;/item&gt;
      &lt;item&gt;Stochastic, run-to-run variability&lt;/item&gt;
      &lt;item&gt;Iterative, quadratic, and slower&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deterministic layouts&lt;/item&gt;
      &lt;item&gt;Preserved global structure&lt;/item&gt;
      &lt;item&gt;Tunable locality via p&lt;/item&gt;
      &lt;item&gt;Linear time, analytic, out-of-sample mapping&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A concise comparison:&lt;/p&gt;
    &lt;head rend="h2"&gt;Minimal Usage Example&lt;/head&gt;
    &lt;p&gt;Here is a minimal example showing how to use &lt;code&gt;SineLandmarkReduction&lt;/code&gt; on a synthetic dataset and plot the result:&lt;/p&gt;
    &lt;code&gt;import numpy as np&lt;lb/&gt;import matplotlib.pyplot as plt&lt;lb/&gt;from sklearn.datasets import make_blobs&lt;lb/&gt;&lt;lb/&gt;X, y = make_blobs(&lt;lb/&gt;    n_samples=5000,&lt;lb/&gt;    n_features=20,&lt;lb/&gt;    centers=5,&lt;lb/&gt;    cluster_std=0.80,&lt;lb/&gt;    random_state=42&lt;lb/&gt;)&lt;lb/&gt;&lt;lb/&gt;slr = SineLandmarkReduction(&lt;lb/&gt;    n_components=2,&lt;lb/&gt;    n_landmarks=50,&lt;lb/&gt;    random_state=42,&lt;lb/&gt;    synthetic_landmarks=False   # or True, depending on your use case&lt;lb/&gt;)&lt;lb/&gt;&lt;lb/&gt;Y = slr.fit_transform(X)&lt;lb/&gt;&lt;lb/&gt;plt.figure(figsize=(7, 6))&lt;lb/&gt;scatter = plt.scatter(Y[:, 0], Y[:, 1], c=y, s=8, alpha=0.8)&lt;lb/&gt;plt.xlabel("SLR Dimension 1")&lt;lb/&gt;plt.ylabel("SLR Dimension 2")&lt;lb/&gt;plt.title("Sine Landmark Reduction (SLR) Visualization")&lt;lb/&gt;plt.colorbar(scatter, label="Cluster Label")&lt;lb/&gt;plt.show()&lt;/code&gt;
    &lt;p&gt;Replace the synthetic dataset with your own feature matrix and you have a ready-to-use, deterministic embedding.&lt;/p&gt;
    &lt;p&gt;In a browser deployment, the same ideas can be ported to JavaScript or WebAssembly with minimal changes: the algorithm itself only needs basic linear algebra and a pseudoinverse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing Thoughts&lt;/head&gt;
    &lt;p&gt;Sine Landmark Reduction (SLR) is designed from first principles for environments where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Latency matters (interactive drag-and-drop exploration).&lt;/item&gt;
      &lt;item&gt;Resources are constrained (no GPU, no heavy backend).&lt;/item&gt;
      &lt;item&gt;Reproducibility is a feature (deterministic embeddings across runs).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Constructing a synthetic or data-driven landmark skeleton,&lt;/item&gt;
      &lt;item&gt;Projecting it via PCA with RMS scaling,&lt;/item&gt;
      &lt;item&gt;Using linearised trilateration for an analytic solution,&lt;/item&gt;
      &lt;item&gt;Adding alpha refinement for scale consistency, and&lt;/item&gt;
      &lt;item&gt;Exposing distance warping as a control for locality,&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR offers a fast, deterministic, and interpretable alternative to t-SNE/UMAP in browser-native contexts.&lt;/p&gt;
    &lt;p&gt;It is already powering Thingbook’s interactive Data Explorer, but the underlying idea is more general: if you can formalise your embedding problem in terms of distances to a small set of stable landmarks, you can achieve real-time dimensionality reduction with simple linear algebra.&lt;/p&gt;
    &lt;p&gt;If you want to experiment further, the Python implementation shown here can be dropped into your own notebooks or adapted to a JavaScript/WebAssembly stack to enable SLR directly in your web applications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46285535</guid><pubDate>Tue, 16 Dec 2025 06:47:09 +0000</pubDate></item><item><title>VS Code deactivates IntelliCode in favor of the paid Copilot</title><link>https://www.heise.de/en/news/VS-Code-deactivates-IntelliCode-in-favor-of-the-paid-Copilot-11115783.html</link><description>&lt;doc fingerprint="a60211d793bb0ad3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;VS Code deactivates IntelliCode in favor of the paid Copilot&lt;/head&gt;
    &lt;p&gt;Microsoft has deactivated the IntelliCode extensions for VS Code and refers to Copilot, which has a limited free volume.&lt;/p&gt;
    &lt;p&gt;With the release of VS Code 1.107, it became known that Microsoft has deactivated the popular IntelliCode extension, which had over 60 million downloads: The extension is now deprecated and the gray inline suggestions no longer work.&lt;/p&gt;
    &lt;p&gt;Microsoft refers in the well-hidden announcement from mid-November to the AI extension of Copilot in VS Code, which, however, only offers a free volume of 2,000 suggestions – a limit that developers quickly reach, as Copilot makes a suggestion with every input. From then on, users will need a paid license. The use of IntelliCode required a local model, but was therefore unlimited and free.&lt;/p&gt;
    &lt;p&gt;The classic IntelliSense with language server for the used language is still free – but without AI support. The following extensions are affected by the shutdown:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IntelliCode&lt;/item&gt;
      &lt;item&gt;IntelliCode Completions&lt;/item&gt;
      &lt;item&gt;IntelliCode for C# Dev Kit&lt;/item&gt;
      &lt;item&gt;IntelliCode API Usage Examples&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;head rend="h3"&gt;TypeScript 7 and more agents for VS Code&lt;/head&gt;
    &lt;p&gt;Nothing about IntelliCode can be found in the announcement for VS Code 1.107. However, new is the experimental support for TypeScript 7 with the new compiler written in Go. This can be updated with:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;npm install @typescript/native-preview&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;It is called with&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;npx tsgo&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;instead of &lt;code&gt;tsc&lt;/code&gt;. Configuration in VS Code is done with&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;{ "typescript.experimental.useTsgo": true }&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Further innovations in the editor concern agents, which can now be controlled via the chat. They continue to run even if the user has closed the chat. Developers can also move agents to other environments, enrich them with context, or classify them as sub-agents. The blog speaks militarily of an Agent Head Quarter (HQ).&lt;/p&gt;
    &lt;p&gt;(who)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46286383</guid><pubDate>Tue, 16 Dec 2025 09:12:53 +0000</pubDate></item><item><title>A2UI: A Protocol for Agent-Driven Interfaces</title><link>https://a2ui.org/</link><description>&lt;doc fingerprint="a5f86c52e98ba4fa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Protocol for Agent-Driven Interfaces¶&lt;/head&gt;
    &lt;p&gt;A2UI enables AI agents to generate rich, interactive user interfaces that render natively across web, mobile, and desktop—without executing arbitrary code.&lt;/p&gt;
    &lt;p&gt;️Status: Early Stage Public Preview&lt;/p&gt;
    &lt;p&gt;A2UI is currently in v0.8 (Public Preview). The specification and implementations are functional but are still evolving. We are opening the project to foster collaboration, gather feedback, and solicit contributions (e.g., on client renderers). Expect changes.&lt;/p&gt;
    &lt;head rend="h2"&gt;At a Glance¶&lt;/head&gt;
    &lt;p&gt;A2UI is currently v0.8, Apache 2.0 licensed, created by Google with contributions from CopilotKit and the open source community, and is in active development on GitHub.&lt;/p&gt;
    &lt;p&gt;The problem A2UI solves is: how can AI agents safely send rich UIs across trust boundaries?&lt;/p&gt;
    &lt;p&gt;Instead of text-only responses or risky code execution, A2UI lets agents send declarative component descriptions that clients render using their own native widgets. It's like having agents speak a universal UI language.&lt;/p&gt;
    &lt;p&gt;In this repo you will find A2UI specifications and implementations for renderers (eg: Angular, Flutter, etc.) on the client side, and transports (eg: A2A, etc.) which communicate A2UI messages between agents and clients.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Secure by Design&lt;/p&gt;
        &lt;p&gt;Declarative data format, not executable code. Agents can only use pre-approved components from your catalog—no UI injection attacks.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LLM-Friendly&lt;/p&gt;
        &lt;p&gt;Flat, streaming JSON structure designed for easy generation. LLMs can build UIs incrementally without perfect JSON in one shot.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Framework-Agnostic&lt;/p&gt;
        &lt;p&gt;One agent response works everywhere. Render the same UI on Angular, Flutter, React, or native mobile with your own styled components.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Progressive Rendering&lt;/p&gt;
        &lt;p&gt;Stream UI updates as they're generated. Users see the interface building in real-time instead of waiting for complete responses.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Get Started in 5 Minutes¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Run the restaurant finder demo and see A2UI in action with Gemini-powered agents.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Understand surfaces, components, data binding, and the adjacency list model.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Integrate A2UI renderers into your app or build agents that generate UIs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dive into the complete technical specification and message types.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How It Works¶&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;User sends a message to an AI agent&lt;/item&gt;
      &lt;item&gt;Agent generates A2UI messages describing the UI (structure + data)&lt;/item&gt;
      &lt;item&gt;Messages stream to the client application&lt;/item&gt;
      &lt;item&gt;Client renders using native components (Angular, Flutter, React, etc.)&lt;/item&gt;
      &lt;item&gt;User interacts with the UI, sending actions back to the agent&lt;/item&gt;
      &lt;item&gt;Agent responds with updated A2UI messages&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A2UI in Action¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Landscape Architect Demo¶&lt;/head&gt;
    &lt;p&gt;Watch an agent generate all of the interfaces for a landscape architect application. The user uploads a photo; the agent uses Gemini to understand it and generate a custom form for landscaping needs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Custom Components: Interactive Charts &amp;amp; Maps¶&lt;/head&gt;
    &lt;p&gt;Watch an agent chose to respond with a chart component to answer a numberical summary quesiton. Then the agent chooses a Google Map component to answer a location question. Both are custom components offered by the client.&lt;/p&gt;
    &lt;head rend="h3"&gt;A2UI Composer¶&lt;/head&gt;
    &lt;p&gt;CopilotKit has a public A2UI Widget Builder to try out as well.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46286407</guid><pubDate>Tue, 16 Dec 2025 09:16:31 +0000</pubDate></item><item><title>I'm a Tech Lead, and nobody listens to me. What should I do?</title><link>https://world.hey.com/joaoqalves/i-m-a-tech-lead-and-nobody-listens-to-me-what-should-i-do-e16e454d</link><description>&lt;doc fingerprint="37c382572f802db8"&gt;
  &lt;main&gt;
    &lt;p&gt;In June 2018, I joined mytaxi (FREE NOW), a competitor of Uber in the ride-hailing space, as Backend Chapter Lead. I was looking for an opportunity to grow in technical leadership. Honestly, I did not even fully understand what “Chapter Lead” meant. After some research, I learned it was part of Spotify’s squad (team) and chapter (horizontal domain, such as iOS, Android, Backend, Data, etc.) model, as well as tribes (groups of squads organized around vertical domains, for example, everything related to drivers).&lt;lb/&gt;Note: this article is a translation from the original “Soy Tech Lead y no me hacen caso. ¿Qué hago?”, in Spanish.&lt;/p&gt;
    &lt;p&gt;Note: this article is a translation from the original “Soy Tech Lead y no me hacen caso. ¿Qué hago?”, in Spanish.&lt;/p&gt;
    &lt;p&gt;That role had two main components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend technical leadership (TL), driven by best practices and with a strong emphasis on continuous improvement. At the time, mytaxi was experiencing major traffic growth. Some services — for example, the one used to incentivize drivers to complete more rides — experienced significant traffic spikes and required improvements, re-architecting, and similar work. On top of that, there were a bit over 200 services to manage.&lt;/item&gt;
      &lt;item&gt;People management in a horizontal setup. The idea was that all backend engineers would report to either Ariel, the other Chapter Lead, or me, regardless of their team. This was not a very orthodox setup, but at the time, around 3–5 backend engineers were joining every month. There was a strong need to make people productive as quickly as possible, align on architecture, and keep the product moving.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I came in with no prior formal experience as a Tech Lead. I think I never read as much in my life as during the month between announcing I was leaving my previous job and joining mytaxi. Not only that. I had never really had a proper Tech Lead to learn from. What could go wrong?&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;The first day was very entertaining. I log into Slack and introduce myself to the infrastructure and platform manager. He says:&lt;/p&gt;
    &lt;quote&gt;By the way, you have an incident in service X. Could you take a look?&lt;/quote&gt;
    &lt;p&gt;Just like that. It is nine in the morning on a Monday, and we already have an incident. I do not even know where the logs are, Henning. After the initial shock, I managed to find the responsible team. They identified the issue, fixed it, and everything got resolved.&lt;/p&gt;
    &lt;p&gt;This first interaction made several things very clear to me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nobody really knows how to manage incidents, document what happened, or communicate progress. Great start.&lt;/item&gt;
      &lt;item&gt;There is no culture of doing incident reviews or extracting actions to prevent similar incidents in the future.&lt;/item&gt;
      &lt;item&gt;There is some coupling between domains. In this case, the Value Added Tax (VAT) concept was applied to two completely different use cases. A change in one of them caused the incident in the other.&lt;/item&gt;
      &lt;item&gt;Many people do not know how to debug. They look at me as if the logs were talking to me, or as if I were Harry Potter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The good part was that there was clearly a lot to fix. I had a pretty clear idea of how engineering culture could be improved. On top of that, I had the Tech Lead title. This was going to be easy. Or maybe not.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;👋 Hi, João here. This is the opening post of a series designed for Tech Leads and Engineering Managers who want to lead with greater clarity and intention.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Traits of a good Tech Lead”&lt;/item&gt;
      &lt;item&gt;“I’m a Tech Lead, and nobody listens to me. What should I do?” ← This article&lt;/item&gt;
      &lt;item&gt;“KPIs, SLOs, and operational excellence”. Coming soon. Subscribe so you do not miss it.&lt;/item&gt;
      &lt;item&gt;To be continued…&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m currently writing “The Tech Lead Handbook”, scheduled for release in H1 2026. The ideas in this series will form its core.&lt;/p&gt;
    &lt;p&gt;If you want to join the waitlist, you’ll get a 25% launch discount.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;head rend="h1"&gt;Trust&lt;/head&gt;
    &lt;p&gt;After that incident, I created an incident review document and suggested a small review of the tasks that should be prioritized to prevent it from happening again. I got carried away and created an initial presentation for the other backend Chapter Leads with a backend strategy. I do not remember it perfectly, but it included hexagonal architecture, a testing pyramid with contract tests to avoid breaking APIs used by mobile apps, and more. Days go by, and I start thinking:&lt;/p&gt;
    &lt;quote&gt;Damn, nobody is listening to me. I put a lot of work into those slides and that strategy.&lt;/quote&gt;
    &lt;p&gt;Today, the reason seems obvious to me. Titles do not grant influence. To influence, you need to build trust. And I had not earned enough of it yet to propose something so fundamental. Through my own experience and through coaching sessions, I have seen this exact mistake repeated several times throughout my career.&lt;/p&gt;
    &lt;p&gt;Years later, I discovered the well-known trust equation by Maister, Green, and Galford. It would have been incredibly helpful back then. It goes like this:&lt;/p&gt;
    &lt;p&gt;The trust equation. Generated with Gemini 3 / NanoBanana.&lt;/p&gt;
    &lt;p&gt;The first time I read it, my mind was blown because it described exactly what was happening to me. Let’s break it down:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Credibility: knowing what you are talking about and having technical judgment. When you say something, people feel it is well-founded. In 2018, I might have had some of this credibility, but it had not yet been proven in that context, with those people, with those systems. I was coming from the outside. Imported credibility is always worth less — unless you come from a FAANG or have built a strong personal brand — than credibility earned on the ground.&lt;/item&gt;
      &lt;item&gt;Reliability: doing what you say you will do. Being consistent and showing up when needed. In a high-paced environment like mytaxi, this matters a lot. In those first days, I was still learning where the logs lived. It is hard to demonstrate reliability if you do not even control the map.&lt;/item&gt;
      &lt;item&gt;Intimacy: people feel they can talk to you, that you will not leave them exposed, and that you understand their fears and doubts. For a TL, this is more important than it seems. Without this, any technical proposal feels like a judgment. And when people get defensive, everything slows down.&lt;/item&gt;
      &lt;item&gt;And then there is the denominator: self-orientation. When your proposals seem to serve your own agenda more than the team’s needs, trust collapses. That was my mistake. I arrived with a strategy too early, without listening, without seeing what they actually needed, without having earned the moral right to propose it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, even if my ideas were good, the equation still did not work out. I had some credibility, a bit of reliability still to build, intimacy yet to be created, and too much self-orientation. The result was obvious. Low trust.&lt;/p&gt;
    &lt;p&gt;Two key moments&lt;/p&gt;
    &lt;p&gt;Over time, I realized that trust is not built through big speeches, but through concrete actions that solve real, everyday problems. Looking back, two obvious moments accelerated the team’s shift in how they perceived me.&lt;/p&gt;
    &lt;p&gt;Regulatory complexity&lt;/p&gt;
    &lt;p&gt;Because mytaxi competed with Uber in a highly regulated taxi market, with very local regulations across Europe, the application needed to support multiple variants of the same flow. This led to the proliferation of dozens of configuration flags across all services. The result was chaos. Nobody knew for sure what was enabled in each city, what affected iOS, what affected Android, or where each option was actually defined. To make matters worse, the configuration was spread across roughly 200 services.&lt;/p&gt;
    &lt;p&gt;One day, Maria — an Agile Coach — talked to me very directly about this pain. I did what I knew best at the time. I built something. I put together a portal — a bit rough, to be honest — that queried the configuration APIs of all services and aggregated that information by functionality, country, or city. Features could be browsed by city or by name. The website was very simple, generated from an HTML template by a Python service.&lt;lb/&gt;The features could be queried by city or by name. The website was very simple, with HTML generated by a Python service.&lt;/p&gt;
    &lt;p&gt;The features could be queried by city or by name. The website was very simple, with HTML generated by a Python service.&lt;/p&gt;
    &lt;p&gt;Suddenly, at a glance, anyone could see what was enabled and where. It was not pretty, but it solved a problem. More importantly, it showed that I was there to help them work better (credibility), not to impose an abstract technical agenda. Soon after, other teams started using the portal, including Product Owners, QA, and even Operations. Without intending to, it became an organizational alignment tool. And it led to something even more interesting. Other engineers started contributing.&lt;/p&gt;
    &lt;p&gt;Once they saw the value it created, several colleagues proposed improvements, fixed minor bugs, and added features I had never even considered. One of them built a small website to visualize city zones, which solved a long-standing pain for teams working with geofencing or driver-passenger assignment. Another automated part of the flag update process. Someone else added metrics to detect inconsistent configurations across platforms.&lt;/p&gt;
    &lt;p&gt;What started as a quick hack turned into a small ecosystem of internal tools that reduced uncertainty, sped up decisions, and made the team’s life a little easier every week.&lt;/p&gt;
    &lt;p&gt;That domino effect taught me something important. When you solve a real problem and make it visible, people join in. Trust is also built that way, by inviting others to improve what you started and celebrating when they do it better than you.&lt;/p&gt;
    &lt;p&gt;Debugging&lt;/p&gt;
    &lt;p&gt;The second moment concerned something much more human. Helping people debug. I have never considered myself especially smart, but I have always been very systematic when connecting error messages, code, hypotheses, and system behavior. To my surprise, many people saw this as almost magical. It was not magic. It was a mix of experience, fundamentals, intuition, knowing where to look, and not being afraid to dive into third-party library code.&lt;/p&gt;
    &lt;p&gt;I started pairing with colleagues during incident resolution (intimacy), teaching them to formulate and discard hypotheses, read logs with intent, and distinguish symptoms from root causes. I proposed incident-review practices that improved the quality of our responses and helped us learn collectively.&lt;/p&gt;
    &lt;p&gt;Without realizing it, these two contributions did more for my reputation than any presentation or strategy deck. Building helpful things and standing by people when the system is on fire creates more trust than any title. That was when my ideas finally started gaining traction. Interestingly, these two actions reduced my self-orientation to zero. I stopped thinking about “my strategy” and started thinking about “our work”.&lt;/p&gt;
    &lt;head rend="h1"&gt;What would you tell your 2018 self?&lt;/head&gt;
    &lt;p&gt;Looking back, one idea stands out. No, TLs don’t earn influence just because “it is their role”. It is earned every day, not through speeches, but by solving painful problems and being present when people need real support.&lt;/p&gt;
    &lt;p&gt;If you are in a similar situation, here is some advice I wish I had received in 2018:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before proposing a strategy, first understand what actually hurts your team.&lt;/item&gt;
      &lt;item&gt;Pick one or two actions that deliver immediate value and execute them.&lt;/item&gt;
      &lt;item&gt;Talk less about architecture and more about how your proposal reduces toil, risk, or uncertainty.&lt;/item&gt;
      &lt;item&gt;Do not try to prove you are the smartest person in the room. Try to help others do their job better.&lt;/item&gt;
      &lt;item&gt;Feedback cycles, unlike code, are slower. They are measured in weeks or months. Be patient.&lt;/item&gt;
      &lt;item&gt;And above all, remember that trust is cumulative. It is earned in every interaction.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Technical influence does not start with a title. It begins with the visible impact you create. Because when a TL feels unheard, the solution is not to speak louder.&lt;lb/&gt;It is to change the conversation. And to start from the only place you truly control: your own behavior.&lt;lb/&gt;---&lt;lb/&gt;🎁 Want to put this into practice with your team tomorrow? Subscriber-only gift&lt;/p&gt;
    &lt;p&gt;It is to change the conversation. And to start from the only place you truly control: your own behavior.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;🎁 Want to put this into practice with your team tomorrow? Subscriber-only gift&lt;/p&gt;
    &lt;p&gt;Many Tech Leads feel unheard because EMs, TLs, and the rest of the team operate with different expectations that no one has made explicit. That friction is not resolved with more meetings or more processes. It is determined with clarity. To help you close that gap, I have prepared a FREE alignment toolkit with three practical tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For Tech Leads: a self-assessment traffic light to fight impostor syndrome and clearly understand where you are creating value and where you are burning out.&lt;/item&gt;
      &lt;item&gt;For Engineering Managers: an evaluation traffic light to give objective feedback based on behaviors, not gut feelings. Help your Tech Leads have a real impact.&lt;/item&gt;
      &lt;item&gt;For the team: an operational principles template to stop debating the same decisions every week and create shared criteria.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition, to complement this article, I will include a concrete plan for your first 90 days as a Tech Lead: what to observe, what to prioritize, what to avoid, and how to build trust through small, visible steps. It is the plan I wish I had had during my first week at mytaxi.&lt;/p&gt;
    &lt;p&gt;If you have already downloaded the toolkit, you do not need to do anything. You already have the updated version and will automatically receive the 90-day plan.&lt;/p&gt;
    &lt;p&gt;If you are not yet subscribed, subscribe, complete this form, and I’ll send you the kit so you can move from intention to action. It is FREE!&lt;/p&gt;
    &lt;p&gt;---&lt;lb/&gt;— João&lt;/p&gt;
    &lt;p&gt;— João&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46286559</guid><pubDate>Tue, 16 Dec 2025 09:38:42 +0000</pubDate></item><item><title>ArkhamMirror: Airgapped investigation platform with CIA-style hypothesis testing</title><link>https://github.com/mantisfury/ArkhamMirror</link><description>&lt;doc fingerprint="7fae250844a8d062"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Connect the dots without connecting to the cloud.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;ArkhamMirror is an air-gapped, AI-powered investigation platform for journalists and researchers. It runs 100% locally on your machine, turning chaos into order using advanced NLP, Vision AI, and Knowledge Graphs.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🕵️ Local AI&lt;/cell&gt;
        &lt;cell&gt;Chat with your data using Offline RAG (Retrieval-Augmented Generation).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🔍 Semantic Search&lt;/cell&gt;
        &lt;cell&gt;Find documents by concept, not just exact keywords.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🕸️ Knowledge Graph&lt;/cell&gt;
        &lt;cell&gt;Visualize hidden connections between People, Orgs, and Places.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⏳ Auto-Timeline&lt;/cell&gt;
        &lt;cell&gt;Extract dates and events to reconstruct what happened when.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;📊 Visual Table Extraction&lt;/cell&gt;
        &lt;cell&gt;Recover complex financial tables from PDFs/Images using Vision models.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Automatically flag conflicting statements across documents.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;🔒 Absolute Privacy&lt;/cell&gt;
        &lt;cell&gt;Zero cloud dependencies. Your data never leaves your specialized "Data Silo".&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;ArkhamMirror includes a Smart Installer that sets up Python, Docker, and Database dependencies for you.&lt;/p&gt;
    &lt;p&gt;Double-click &lt;code&gt;setup.bat&lt;/code&gt; and follow the AI Setup Wizard.&lt;/p&gt;
    &lt;code&gt;chmod +x setup.sh
./setup.sh&lt;/code&gt;
    &lt;p&gt;Detailed guides for features and workflows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User Guide: Full walkthrough of features.&lt;/item&gt;
      &lt;item&gt;Installation: Detailed setup instructions.&lt;/item&gt;
      &lt;item&gt;Developer Guide: Architecture and contributing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Narrative Reconstruction&lt;/cell&gt;
        &lt;cell role="head"&gt;Gap Finding&lt;/cell&gt;
        &lt;cell role="head"&gt;Contradiction Chain&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Entity Graph&lt;/cell&gt;
        &lt;cell role="head"&gt;Author Unmasking&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This tool was born from a desire to give journalists powerful forensics without the monthly subscription costs or privacy risks of cloud platforms.&lt;/p&gt;
    &lt;p&gt;If it helps you uncover the truth, consider buying me a coffee!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46286666</guid><pubDate>Tue, 16 Dec 2025 09:51:31 +0000</pubDate></item><item><title>Should we fear Microsoft's monopoly?</title><link>https://www.cursor.tue.nl/en/background/2025/december/week-2/should-we-fear-microsofts-monopoly</link><description>&lt;doc fingerprint="b55c8860268c8cc8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Should we fear Microsoft's monopoly?&lt;/head&gt;
    &lt;p&gt;Even if TU/e wants to get rid of the American IT giant, there's no European alternative&lt;/p&gt;
    &lt;p&gt;The search for alternatives to American IT services is intensifying as geopolitical unrest grows. TU/e and ICT cooperative SURF are also looking for replacements for Microsoft and Google. However, a fully-fledged European alternative is not yet available, according to Joost de Jong, the university's Chief Information Security Officer.&lt;/p&gt;
    &lt;p&gt;The International Criminal Court recently banned Microsoft due to concerns about US sanctions. More parties are worried that our data will soon be inaccessible if President Trump tries to assert his power.&lt;/p&gt;
    &lt;p&gt;In April of this year, Cursor already wrote about the risk of Trump cutting off access to our data. While this is theoretically possible, then-Chief Information Security Officer (CISO) Martin de Vries estimated the likelihood of this happening for TU/e to be very small.&lt;/p&gt;
    &lt;head rend="h5"&gt;Alternatives&lt;/head&gt;
    &lt;p&gt;Seven months later, the public demand for European data alternatives seems to be growing. Is TU/e now actually looking for a replacement for Microsoft? The answer is partly yes, but not yet institutionally driven.&lt;/p&gt;
    &lt;p&gt;“Several departments within the university are already testing, for example, Nextcloud – a German cloud solution," says De Jong. "We are also working with educational partner SURF on our own solutions, for example in the field of IT security.”&lt;/p&gt;
    &lt;p&gt;If there is no comprehensive alternative, the university will try to arrive at a fully-fledged solution through several interventions, so that it can continue without Microsoft. However, the final verdict on the feasibility of this is not yet in order.&lt;/p&gt;
    &lt;head rend="h5"&gt;Cables&lt;/head&gt;
    &lt;p&gt;There are other alternatives on the market, such as the German Open Desk, which the International Criminal Court is now switching to. And the European initiative GaiaX, but none of these can replace Microsoft. That IT provider does much more than provide a typing application or manage data in a cloud.&lt;/p&gt;
    &lt;p&gt;“Besides word processors, Microsoft also has security solutions, cables, servers in data centers, access control, SharePoint, and AI across all of this,” De Jong explains. “So simply replacing Microsoft isn't an option.”&lt;/p&gt;
    &lt;p&gt;And switching only partially would require a lot of extra administrative work and money, and wouldn't reduce the risk of data blocking. The American giant is the largest supplier of software and services to TU/e.&lt;/p&gt;
    &lt;head rend="h5"&gt;Consortium&lt;/head&gt;
    &lt;p&gt;Finding alternatives to Microsoft is something that several universities are considering. That's why Utrecht University, Delft University of Technology, the University of Amsterdam, Erasmus University, and Tilburg University are collaborating in a consortium to develop alternatives.&lt;/p&gt;
    &lt;p&gt;TU/e is not involved but says it is following the initiative with interest. The collaboration with SURF for the same purpose is broader: all Dutch universities are members.&lt;/p&gt;
    &lt;head rend="h5"&gt;Building together&lt;/head&gt;
    &lt;p&gt;De Jong, incidentally, sees both advantages and disadvantages in the interconnectedness of Microsoft's IT services. “On the one hand, it's difficult for all the components to work together. We can't simply pull something out and replace it. That creates dependency. But on the other hand, the system works so well that you don't notice the complexity as a user.”&lt;/p&gt;
    &lt;p&gt;A future European alternative must be built by countries, governments, and knowledge partners together. “I think we can contribute our knowledge to developing a solution,” says De Jong, referring to the software and hardware expertise within the university. That development will likely take years.&lt;/p&gt;
    &lt;head rend="h5"&gt;Trade balance&lt;/head&gt;
    &lt;p&gt;The current systems that dominate the world—Microsoft and Google—were built by billion-dollar companies and further developed for decades. Even if the Netherlands makes every effort now, a fully-fledged alternative won't be readily available. That gives American companies power.&lt;/p&gt;
    &lt;p&gt;Yet, De Jong believes there's another side to this power struggle between the US and Europe. “The US is hinting that they can cut off our data, but if fear in Europe becomes too great and we leave, it will have a major financial impact on them. The trade balance on services and ICT is actually positive for America: they make a lot of money from European contracts with Microsoft and Google.”&lt;/p&gt;
    &lt;p&gt;De Jong believes this will prevent US from simply pressing the ‘block access button’. Such a thing causes a lot of unrest, with financial consequences.&lt;/p&gt;
    &lt;p&gt;This article was translated using AI-assisted tools and reviewed by an editor&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46287098</guid><pubDate>Tue, 16 Dec 2025 10:56:40 +0000</pubDate></item><item><title>Cekura (YC F24) Is Hiring</title><link>https://www.ycombinator.com/companies/cekura-ai/jobs/YFeQADI-product-engineer-us</link><description>&lt;doc fingerprint="ddc9e9532991a347"&gt;
  &lt;main&gt;
    &lt;p&gt;Voice AI and Chat AI agents: Testing and Observability&lt;/p&gt;
    &lt;p&gt;Cekura (YC F24) is one of the fastest-growing companies in its batch, with strong revenue traction. We’re well-funded, backed by premier investors, and have years of runway.&lt;/p&gt;
    &lt;p&gt;We’re building the reliability layer for Conversational Agents. Teams use Cekura to simulate and monitor their AI agents end-to-end - measuring latency, barge-in, instruction-following, regressions, and more across phone, chat, SMS, and web. Customers love the product - and we’re just getting started.&lt;/p&gt;
    &lt;p&gt;You’re joining at an inflection point. As Product Engineer, you’ll build the playbooks, processes, and relationships that define how Cekura partners with technical customers for long-term success. You’ll be both strategist and hands-on operator.&lt;/p&gt;
    &lt;p&gt;Excited to help world-class teams ship reliable AI agents - and wear both the customer and engineer hats? Let’s talk.&lt;/p&gt;
    &lt;p&gt;Cekura is a Y Combinator–backed startup redefining AI voice agent reliability. Founded by IIT Bombay alumni with research credentials from ETH Zurich and proven success in high-stakes trading, our team built Cekura to solve the cumbersome, error-prone nature of manual voice agent testing.&lt;/p&gt;
    &lt;p&gt;We automate the testing and observability of AI voice agents by simulating thousands of realistic, real-world conversational scenarios—from ordering food and booking appointments to conducting interviews. Our platform leverages custom and AI-generated datasets, detailed workflows, and dynamic persona simulations to uncover edge cases and deliver actionable insights. Real-time monitoring, comprehensive logs, and instant alerting ensure that every call is optimized and production-ready.&lt;/p&gt;
    &lt;p&gt;In a market rapidly expanding with thousands of voice agents, Cekura stands out by guaranteeing dependable performance, reducing time-to-market, and minimizing costly production errors. We empower teams to demonstrate reliability before deployment, making it easier to build trust with clients and users.&lt;/p&gt;
    &lt;p&gt;Join us in shaping the future of voice technology. Learn more at cekura.ai.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46287521</guid><pubDate>Tue, 16 Dec 2025 12:01:55 +0000</pubDate></item></channel></rss>