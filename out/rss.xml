<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 27 Nov 2025 17:08:47 +0000</lastBuildDate><item><title>Fara-7B: An efficient agentic model for computer use</title><link>https://github.com/microsoft/fara</link><description>&lt;doc fingerprint="3b49fc912d38801c"&gt;
  &lt;main&gt;
    &lt;p&gt;Fara-7B is Microsoft's first agentic small language model (SLM) designed specifically for computer use. With only 7 billion parameters, Fara-7B is an ultra-compact Computer Use Agent (CUA) that achieves state-of-the-art performance within its size class and is competitive with larger, more resource-intensive agentic systems.&lt;/p&gt;
    &lt;p&gt;Try Fara-7B locally as follows (see Installation for detailed instructions):&lt;/p&gt;
    &lt;code&gt;# 1. Clone repository
git clone https://github.com/microsoft/fara.git
cd fara

# 2. Setup environment
python3 -m venv .venv 
source .venv/bin/activate
pip install -e .
playwright install&lt;/code&gt;
    &lt;p&gt;Then in one process, host the model:&lt;/p&gt;
    &lt;code&gt;vllm serve "microsoft/Fara-7B" --port 5000 --dtype auto &lt;/code&gt;
    &lt;p&gt;Then you can iterative query it with:&lt;/p&gt;
    &lt;code&gt;fara-cli --task "whats the weather in new york now"&lt;/code&gt;
    &lt;p&gt;Hint: might need to do &lt;code&gt;--tensor-parallel-size 2&lt;/code&gt; with vllm command if you run out of memory&lt;/p&gt;
    &lt;p&gt;Unlike traditional chat models that generate text-based responses, Fara-7B leverages computer interfaces‚Äîmouse and keyboard‚Äîto perform multi-step tasks on behalf of users. The model:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Operates visually by perceiving webpages and taking actions like scrolling, typing, and clicking on directly predicted coordinates&lt;/item&gt;
      &lt;item&gt;Uses the same modalities as humans to interact with computers‚Äîno accessibility trees or separate parsing models required&lt;/item&gt;
      &lt;item&gt;Enables on-device deployment due to its compact 7B parameter size, resulting in reduced latency and improved privacy as user data remains local&lt;/item&gt;
      &lt;item&gt;Completes tasks efficiently, averaging only ~16 steps per task compared to ~41 for comparable models&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fara-7B is trained using a novel synthetic data generation pipeline built on the Magentic-One multi-agent framework, with 145K trajectories covering diverse websites, task types, and difficulty levels. The model is based on Qwen2.5-VL-7B and trained with supervised fine-tuning.&lt;/p&gt;
    &lt;p&gt;Fara-7B can automate everyday web tasks including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Searching for information and summarizing results&lt;/item&gt;
      &lt;item&gt;Filling out forms and managing accounts&lt;/item&gt;
      &lt;item&gt;Booking travel, movie tickets, and restaurant reservations&lt;/item&gt;
      &lt;item&gt;Shopping and comparing prices across retailers&lt;/item&gt;
      &lt;item&gt;Finding job postings and real estate listings&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fara-7B achieves state-of-the-art results across multiple web agent benchmarks, outperforming both comparable-sized models and larger systems:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Params&lt;/cell&gt;
        &lt;cell role="head"&gt;WebVoyager&lt;/cell&gt;
        &lt;cell role="head"&gt;Online-M2W&lt;/cell&gt;
        &lt;cell role="head"&gt;DeepShop&lt;/cell&gt;
        &lt;cell role="head"&gt;WebTailBench&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SoM Agents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SoM Agent (GPT-4o-0513)&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;90.6&lt;/cell&gt;
        &lt;cell&gt;57.7&lt;/cell&gt;
        &lt;cell&gt;49.1&lt;/cell&gt;
        &lt;cell&gt;60.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SoM Agent (o3-mini)&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;79.3&lt;/cell&gt;
        &lt;cell&gt;55.4&lt;/cell&gt;
        &lt;cell&gt;49.7&lt;/cell&gt;
        &lt;cell&gt;52.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;SoM Agent (GPT-4o)&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;65.1&lt;/cell&gt;
        &lt;cell&gt;34.6&lt;/cell&gt;
        &lt;cell&gt;16.0&lt;/cell&gt;
        &lt;cell&gt;30.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;GLM-4.1V-9B-Thinking&lt;/cell&gt;
        &lt;cell&gt;9B&lt;/cell&gt;
        &lt;cell&gt;66.8&lt;/cell&gt;
        &lt;cell&gt;33.9&lt;/cell&gt;
        &lt;cell&gt;32.0&lt;/cell&gt;
        &lt;cell&gt;22.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Computer Use Models&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;OpenAI computer-use-preview&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;70.9&lt;/cell&gt;
        &lt;cell&gt;42.9&lt;/cell&gt;
        &lt;cell&gt;24.7&lt;/cell&gt;
        &lt;cell&gt;25.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;UI-TARS-1.5-7B&lt;/cell&gt;
        &lt;cell&gt;7B&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
        &lt;cell&gt;31.3&lt;/cell&gt;
        &lt;cell&gt;11.6&lt;/cell&gt;
        &lt;cell&gt;19.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fara-7B&lt;/cell&gt;
        &lt;cell&gt;7B&lt;/cell&gt;
        &lt;cell&gt;73.5&lt;/cell&gt;
        &lt;cell&gt;34.1&lt;/cell&gt;
        &lt;cell&gt;26.2&lt;/cell&gt;
        &lt;cell&gt;38.4&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Table: Online agent evaluation results showing success rates (%) across four web benchmarks. Results are averaged over 3 runs.&lt;/p&gt;
    &lt;p&gt;We are releasing WebTailBench, a new evaluation benchmark focusing on 11 real-world task types that are underrepresented or missing in existing benchmarks. The benchmark includes 609 tasks across diverse categories, with the first 8 segments testing single skills or objectives (usually on a single website), and the remaining 3 evaluating more difficult multi-step or cross-site tasks.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell role="head"&gt;Task Segment&lt;/cell&gt;
        &lt;cell role="head"&gt;Tasks&lt;/cell&gt;
        &lt;cell role="head"&gt;SoM GPT-4o-0513&lt;/cell&gt;
        &lt;cell role="head"&gt;SoM o3-mini&lt;/cell&gt;
        &lt;cell role="head"&gt;SoM GPT-4o&lt;/cell&gt;
        &lt;cell role="head"&gt;GLM-4.1V-9B&lt;/cell&gt;
        &lt;cell role="head"&gt;OAI Comp-Use&lt;/cell&gt;
        &lt;cell role="head"&gt;UI-TARS-1.5&lt;/cell&gt;
        &lt;cell role="head"&gt;Fara-7B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Single-Site Tasks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Shopping&lt;/cell&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;62.5&lt;/cell&gt;
        &lt;cell&gt;71.4&lt;/cell&gt;
        &lt;cell&gt;38.1&lt;/cell&gt;
        &lt;cell&gt;31.0&lt;/cell&gt;
        &lt;cell&gt;42.3&lt;/cell&gt;
        &lt;cell&gt;41.1&lt;/cell&gt;
        &lt;cell&gt;52.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Flights&lt;/cell&gt;
        &lt;cell&gt;51&lt;/cell&gt;
        &lt;cell&gt;60.1&lt;/cell&gt;
        &lt;cell&gt;39.2&lt;/cell&gt;
        &lt;cell&gt;11.1&lt;/cell&gt;
        &lt;cell&gt;10.5&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;10.5&lt;/cell&gt;
        &lt;cell&gt;37.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Hotels&lt;/cell&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;68.6&lt;/cell&gt;
        &lt;cell&gt;56.4&lt;/cell&gt;
        &lt;cell&gt;31.4&lt;/cell&gt;
        &lt;cell&gt;19.9&lt;/cell&gt;
        &lt;cell&gt;26.9&lt;/cell&gt;
        &lt;cell&gt;35.3&lt;/cell&gt;
        &lt;cell&gt;53.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Restaurants&lt;/cell&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;67.9&lt;/cell&gt;
        &lt;cell&gt;59.6&lt;/cell&gt;
        &lt;cell&gt;47.4&lt;/cell&gt;
        &lt;cell&gt;32.1&lt;/cell&gt;
        &lt;cell&gt;35.9&lt;/cell&gt;
        &lt;cell&gt;22.4&lt;/cell&gt;
        &lt;cell&gt;47.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Activities&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;70.4&lt;/cell&gt;
        &lt;cell&gt;62.9&lt;/cell&gt;
        &lt;cell&gt;41.7&lt;/cell&gt;
        &lt;cell&gt;26.3&lt;/cell&gt;
        &lt;cell&gt;30.4&lt;/cell&gt;
        &lt;cell&gt;9.6&lt;/cell&gt;
        &lt;cell&gt;36.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Ticketing&lt;/cell&gt;
        &lt;cell&gt;57&lt;/cell&gt;
        &lt;cell&gt;58.5&lt;/cell&gt;
        &lt;cell&gt;56.7&lt;/cell&gt;
        &lt;cell&gt;37.4&lt;/cell&gt;
        &lt;cell&gt;35.7&lt;/cell&gt;
        &lt;cell&gt;49.7&lt;/cell&gt;
        &lt;cell&gt;30.4&lt;/cell&gt;
        &lt;cell&gt;38.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Real Estate&lt;/cell&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;34.0&lt;/cell&gt;
        &lt;cell&gt;17.4&lt;/cell&gt;
        &lt;cell&gt;20.1&lt;/cell&gt;
        &lt;cell&gt;16.0&lt;/cell&gt;
        &lt;cell&gt;9.0&lt;/cell&gt;
        &lt;cell&gt;9.7&lt;/cell&gt;
        &lt;cell&gt;23.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Jobs/Careers&lt;/cell&gt;
        &lt;cell&gt;50&lt;/cell&gt;
        &lt;cell&gt;49.3&lt;/cell&gt;
        &lt;cell&gt;44.0&lt;/cell&gt;
        &lt;cell&gt;32.7&lt;/cell&gt;
        &lt;cell&gt;22.7&lt;/cell&gt;
        &lt;cell&gt;20.7&lt;/cell&gt;
        &lt;cell&gt;20.7&lt;/cell&gt;
        &lt;cell&gt;28.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Multi-Step Tasks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Shopping List (2 items)&lt;/cell&gt;
        &lt;cell&gt;51&lt;/cell&gt;
        &lt;cell&gt;66.0&lt;/cell&gt;
        &lt;cell&gt;62.7&lt;/cell&gt;
        &lt;cell&gt;17.0&lt;/cell&gt;
        &lt;cell&gt;7.8&lt;/cell&gt;
        &lt;cell&gt;34.0&lt;/cell&gt;
        &lt;cell&gt;20.9&lt;/cell&gt;
        &lt;cell&gt;49.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Comparison Shopping&lt;/cell&gt;
        &lt;cell&gt;57&lt;/cell&gt;
        &lt;cell&gt;67.3&lt;/cell&gt;
        &lt;cell&gt;59.1&lt;/cell&gt;
        &lt;cell&gt;27.5&lt;/cell&gt;
        &lt;cell&gt;22.8&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;8.8&lt;/cell&gt;
        &lt;cell&gt;32.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Compositional Tasks&lt;/cell&gt;
        &lt;cell&gt;55&lt;/cell&gt;
        &lt;cell&gt;51.5&lt;/cell&gt;
        &lt;cell&gt;39.4&lt;/cell&gt;
        &lt;cell&gt;26.7&lt;/cell&gt;
        &lt;cell&gt;17.0&lt;/cell&gt;
        &lt;cell&gt;10.3&lt;/cell&gt;
        &lt;cell&gt;9.1&lt;/cell&gt;
        &lt;cell&gt;23.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Overall&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Macro Average&lt;/cell&gt;
        &lt;cell&gt;609&lt;/cell&gt;
        &lt;cell&gt;59.7&lt;/cell&gt;
        &lt;cell&gt;51.7&lt;/cell&gt;
        &lt;cell&gt;30.1&lt;/cell&gt;
        &lt;cell&gt;22.0&lt;/cell&gt;
        &lt;cell&gt;25.3&lt;/cell&gt;
        &lt;cell&gt;19.9&lt;/cell&gt;
        &lt;cell&gt;38.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Micro Average&lt;/cell&gt;
        &lt;cell&gt;609&lt;/cell&gt;
        &lt;cell&gt;60.4&lt;/cell&gt;
        &lt;cell&gt;52.7&lt;/cell&gt;
        &lt;cell&gt;30.8&lt;/cell&gt;
        &lt;cell&gt;22.4&lt;/cell&gt;
        &lt;cell&gt;25.7&lt;/cell&gt;
        &lt;cell&gt;19.5&lt;/cell&gt;
        &lt;cell&gt;38.4&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Table: Breakdown of WebTailBench results across all 11 segments. Success rates (%) are averaged over 3 independent runs. Fara-7B achieves the highest performance among computer-use models across all task categories.&lt;/p&gt;
    &lt;p&gt;Coming Soon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Task Verification pipeline for LLM-as-a-judge evaluation&lt;/item&gt;
      &lt;item&gt;Official human annotations of WebTailBench (in partnership with BrowserBase)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our evaluation setup leverages:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Playwright - A cross-browser automation framework that replicates browser environments&lt;/item&gt;
      &lt;item&gt;Abstract Web Agent Interface - Allows integration of any model from any source into the evaluation environment&lt;/item&gt;
      &lt;item&gt;Fara-Agent Class - Reference implementation for running the Fara model&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: Fara-7B is an experimental release designed to invite hands-on exploration and feedback from the community. We recommend running it in a sandboxed environment, monitoring its execution, and avoiding sensitive data or high-risk domains.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Install the package using either UV or pip:&lt;/p&gt;
    &lt;code&gt;uv sync --all-extras&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;pip install -e .&lt;/code&gt;
    &lt;p&gt;Then install Playwright browsers:&lt;/p&gt;
    &lt;code&gt;playwright install&lt;/code&gt;
    &lt;p&gt;Recommended: The easiest way to get started is using Azure Foundry hosting, which requires no GPU hardware or model downloads. Alternatively, you can self-host with VLLM if you have GPU resources available.&lt;/p&gt;
    &lt;p&gt;Deploy Fara-7B on Azure Foundry without needing to download weights or manage GPU infrastructure.&lt;/p&gt;
    &lt;p&gt;Setup:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Deploy the Fara-7B model on Azure Foundry and obtain your endpoint URL and API key&lt;/item&gt;
      &lt;item&gt;Add your endpoint details to the existing &lt;code&gt;endpoint_configs/&lt;/code&gt;directory (example configs are already provided):&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Edit one of the existing config files or create a new one
# endpoint_configs/fara-7b-hosting-ansrz.json (example format):
{
    "model": "Fara-7B",
    "base_url": "https://your-endpoint.inference.ml.azure.com/",
    "api_key": "YOUR_API_KEY_HERE"
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run the Fara agent:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fara-cli --task "how many pages does wikipedia have" --start_page "https://www.bing.com"&lt;/code&gt;
    &lt;p&gt;That's it! No GPU or model downloads required.&lt;/p&gt;
    &lt;p&gt;If you have access to GPU resources, you can self-host Fara-7B using VLLM. This requires a GPU machine with sufficient VRAM.&lt;/p&gt;
    &lt;p&gt;All that is required is to run the following command to start the VLLM server:&lt;/p&gt;
    &lt;code&gt;vllm serve "microsoft/Fara-7B" --port 5000 --dtype auto &lt;/code&gt;
    &lt;p&gt;Run the test script to see Fara in action:&lt;/p&gt;
    &lt;code&gt;fara-cli --task "how many pages does wikipedia have" --start_page "https://www.bing.com" --endpoint_config endpoint_configs/azure_foundry_config.json [--headful] [--downloads_folder "/path/to/downloads"] [--save_screenshots] [--max_rounds 100] [--browserbase]&lt;/code&gt;
    &lt;p&gt;In self-hosting scenario the &lt;code&gt;endpoint_config&lt;/code&gt; points to &lt;code&gt;endpoint_configs/vllm_config.json&lt;/code&gt; from the VLLM server above.&lt;/p&gt;
    &lt;p&gt;If you set &lt;code&gt;--browserbase&lt;/code&gt;, export environment variables for the API key and project ID.&lt;/p&gt;
    &lt;code&gt;Initializing Browser...
Browser Running... Starting Fara Agent...
##########################################
Task: how many pages does wikipedia have
##########################################
Running Fara...


Thought #1: To find the current number of Wikipedia pages, I'll search for the latest Wikipedia page count statistics.
Action #1: executing tool 'web_search' with arguments {"action": "web_search", "query": "Wikipedia total number of articles"}
Observation#1: I typed 'Wikipedia total number of articles' into the browser search bar.

Thought #2: Wikipedia currently has 7,095,446 articles.
Action #2: executing tool 'terminate' with arguments {"action": "terminate", "status": "success"}
Observation#2: Wikipedia currently has 7,095,446 articles.

Final Answer: Wikipedia currently has 7,095,446 articles.

Enter another task (or press Enter to exit): 
&lt;/code&gt;
    &lt;p&gt;We provide a framework in &lt;code&gt;webeval/&lt;/code&gt; to reproduce our results on WebVoyager and OnlineMind2Web.
Agentic evaluations on live websites present unique challenges due to day-to-day changes. We implement several measures to ensure reliable and comparable evaluations:&lt;/p&gt;
    &lt;p&gt;BrowserBase Integration We employ BrowserBase to manage browser session hosting, enabling reliable browser instance management.&lt;/p&gt;
    &lt;p&gt;Time-sensitive Task Updates Tasks in benchmarks like WebVoyager can become stale or impossible. We:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Removed ~48 impossible tasks from the original WebVoyager benchmark&lt;/item&gt;
      &lt;item&gt;Updated ~50 tasks with future dates to keep them achievable&lt;/item&gt;
      &lt;item&gt;Example: "Search for a hotel in Bali from Jan 1 to Jan 4, 2024" ‚Üí "Search for a hotel in Bali from Jan 1 to Jan 4, 2026"&lt;/item&gt;
      &lt;item&gt;Our updated WebVoyager benchmark is available at &lt;code&gt;webeval/data/webvoyager/WebVoyager_data_08312025.jsonl&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Environment Error Handling Browser errors (connection drops, page timeouts) are handled robustly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trajectories are retried up to 5 times when environment errors occur&lt;/item&gt;
      &lt;item&gt;Complete yet incorrect trajectories are never retried&lt;/item&gt;
      &lt;item&gt;Each retry starts with a fresh browser session, with no retained state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Step Budget Each trajectory is capped at a maximum of 100 actions across all online benchmarks. Trajectories exceeding this budget without choosing to stop are considered incorrect.&lt;/p&gt;
    &lt;code&gt;conda create --name fara_webeval python=3.12
conda activate fara_webeval

# Install fara package
pip install -e .

# Install autogen submodule
git submodule update --init --recursive
cd autogen/python/packages
pip install -e autogen-core
pip install -e autogen-ext

# Install webeval
cd webeval
pip install -e .

# Install playwright
playwright install&lt;/code&gt;
    &lt;p&gt;Navigate to the scripts directory:&lt;/p&gt;
    &lt;code&gt;cd webeval/scripts&lt;/code&gt;
    &lt;p&gt;Make sure you set a valid OpenAI GPT-4o endpoint in &lt;code&gt;endpoint_configs_gpt4o/dev&lt;/code&gt; in order to run the WebVoyager LLM-as-a-judge!&lt;/p&gt;
    &lt;p&gt;Option 1: Self-hosted VLLM&lt;/p&gt;
    &lt;code&gt;python webvoyager.py --model_url /path/where/you/want/to/download/model/ --model_port 5000 --eval_oai_config ../endpoint_configs_gpt4o/dev/ --out_url /path/to/save/eval/files --device_id 0,1 --processes 1 --run_id 1 --max_rounds 100&lt;/code&gt;
    &lt;p&gt;Option 2: Azure Foundry Deployment&lt;/p&gt;
    &lt;p&gt;Deploy Fara-7B on Foundry endpoint(s), then place endpoint URLs and keys in JSONs under &lt;code&gt;endpoint_configs/&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;python webvoyager.py --model_endpoint ../../endpoint_configs/ --eval_oai_config ../endpoint_configs_gpt4o/dev/ --out_url /path/to/save/eval/files --processes 1 --run_id 1_endpoint --max_rounds 100&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We use the same LLM-as-a-judge prompts and model (GPT-4o) as WebVoyager, hence the &lt;code&gt;--eval_oai_config&lt;/code&gt;argument&lt;/item&gt;
      &lt;item&gt;Set &lt;code&gt;--browserbase&lt;/code&gt;for browser session management (requires exported API key and project ID environment variables)&lt;/item&gt;
      &lt;item&gt;Avoid overloading a single VLLM deployment with more than ~10 concurrent processes due to known issues&lt;/item&gt;
      &lt;item&gt;See debugging output in &lt;code&gt;fara/webeval/scripts/stdout.txt&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Evaluation results are stored under &lt;code&gt;--out_url&lt;/code&gt; in folders organized by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model name&lt;/item&gt;
      &lt;item&gt;Dataset&lt;/item&gt;
      &lt;item&gt;Username&lt;/item&gt;
      &lt;item&gt;Run ID&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example path:&lt;/p&gt;
    &lt;code&gt;/runs/WebSurfer-fara-100-max_n_images-3/fara-7b/&amp;lt;username&amp;gt;/WebVoyager_WebVoyager_data_08312025.jsonl/&amp;lt;run_id&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Each evaluation folder contains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gpt_eval/&lt;/code&gt;- LLM-as-a-judge evaluation results&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;traj/&lt;/code&gt;- Per-task trajectory subdirectories containing:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;final_answer.json&lt;/code&gt;(e.g.,&lt;code&gt;Amazon--1_final_answer.json&lt;/code&gt;) -&lt;code&gt;&amp;lt;no_answer&amp;gt;&lt;/code&gt;indicates abortion or step budget exceeded&lt;/item&gt;&lt;item&gt;&lt;code&gt;scores/gpt_eval.json&lt;/code&gt;- LLM judge scores&lt;/item&gt;&lt;item&gt;&lt;code&gt;web_surfer.log&lt;/code&gt;- Action history and errors&lt;/item&gt;&lt;item&gt;&lt;code&gt;screenshot_X.png&lt;/code&gt;- Screenshots captured before each action X&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the analysis notebook to compute metrics:&lt;/p&gt;
    &lt;code&gt;cd webeval/scripts/analyze_eval_results/
jupyter notebook analyze.ipynb&lt;/code&gt;
    &lt;p&gt;The script:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identifies trajectories aborted mid-execution and diagnostic reasons&lt;/item&gt;
      &lt;item&gt;Computes average scores across non-aborted trajectories&lt;/item&gt;
      &lt;item&gt;Distinguishes between aborted trajectories (errors during sampling) and completed trajectories (with terminate() call or step budget exceeded)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To re-run failed tasks, execute the evaluation script again with the same &lt;code&gt;run_id&lt;/code&gt; and &lt;code&gt;username&lt;/code&gt; - it will skip non-aborted tasks.&lt;/p&gt;
    &lt;head&gt;Example WebVoyager GPT Eval Result&lt;/head&gt;
    &lt;code&gt;{
  "score": 1.0,
  "gpt_response_text": "To evaluate the task, we need to verify if the criteria have been met:\n\n1. **Recipe Requirement**: A vegetarian lasagna recipe with zucchini and at least a four-star rating.\n\n2. **Search and Results**:\n   - The screenshots show that the search term used was \"vegetarian lasagna zucchini.\"\n   - Among the search results, \"Debbie's Vegetable Lasagna\" is prominently featured.\n   \n3. **Evaluation of the Recipe**:\n   - Rating: \"Debbie's Vegetable Lasagna\" has a rating of 4.7, which satisfies the requirement of being at least four stars.\n   - The presence of zucchini in the recipe is implied through the search conducted, though the screenshots do not explicitly show the ingredients list. However, the result response confirms the match to the criteria.\n\nGiven the information provided, the task seems to have fulfilled the requirement of finding a vegetarian lasagna recipe with zucchini and a four-star rating or higher. \n\n**Verdict: SUCCESS**"
}&lt;/code&gt;
    &lt;p&gt;If you use Fara in your research, please cite our work:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46061208</guid><pubDate>Wed, 26 Nov 2025 19:10:24 +0000</pubDate></item><item><title>S&amp;box is now an open source game engine</title><link>https://sbox.game/news/update-25-11-26</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46061682</guid><pubDate>Wed, 26 Nov 2025 19:58:27 +0000</pubDate></item><item><title>Running Unsupported iOS on Deprecated Devices</title><link>https://nyansatan.github.io/run-unsupported-ios/</link><description>&lt;doc fingerprint="b6495d34246e3b64"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Running unsupported iOS on deprecated devices&lt;/head&gt;
    &lt;p&gt;Earlier this year I demoed iOS 6 running on an iPod touch 3 - a device that Apple never gave iOS 6 to, making iOS 5.1.1 the latest build it can run&lt;/p&gt;
    &lt;p&gt;A few months later I also released a script that generates an iOS 6 restore image installable on that iPod touch model&lt;/p&gt;
    &lt;p&gt;This article describes technical details behind this work. Certain proficiency in iOS internals is assumed&lt;/p&gt;
    &lt;head rend="h2"&gt;I'll show you what iOS is made of&lt;/head&gt;
    &lt;p&gt;First of all, let's recap what software components iOS consists of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;iBoot - the bootloader. Has 4 different types for different scenarios - iBSS, iBEC, LLB and iBoot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kernelcache - the OS kernel + kernel extensions (drivers) built into a single binary blob&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DeviceTree - structured list of hardware used by specific device model + some parameters that specify software behavior. The copy included in an IPSW is more of a template that is heavily modified by iBoot before jumping into kernel&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Userspace filesystem - tiny restore ramdisk used purely for OS installation or the actual root filesystem of iOS installed persistently&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Various firmwares for coprocessors, be they internal or external to the main SoC - like, baseband, Wi-Fi, Bluetooth, multitouch and etc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;iPhone 3GS tests&lt;/head&gt;
    &lt;p&gt;iPhone 3GS was released the same year as iPod touch 3 (2009), and has a very similar hardware (S5L8920X SoC vs. S5L8922X). But the most important part is that it actually got iOS 6 officially&lt;/p&gt;
    &lt;p&gt;Before doing anything on the iPod I decided to try to boot iOS 6.0 with iOS 5.1.1 iBoot &amp;amp; DeviceTree on the iPhone and see what's gonna break and how&lt;/p&gt;
    &lt;head rend="h2"&gt;DeviceTree&lt;/head&gt;
    &lt;p&gt;The most broken thing was DeviceTree - iOS 6 added a lot of new nodes and properties. To fix it in automated manner I wrote a stupid Python script that decodes and computes a diff between 2 DeviceTrees. Such diff can also be applied to another DeviceTree&lt;/p&gt;
    &lt;p&gt;The script is available in the SundanceInH2A repo&lt;/p&gt;
    &lt;p&gt;As I mentioned above a lot of things in a DeviceTree is filled by iBoot at runtime. One of such new properties is &lt;code&gt;nvram-proxy-data&lt;/code&gt; in &lt;code&gt;chosen&lt;/code&gt; node&lt;/p&gt;
    &lt;p&gt;The property must contain a raw NVRAM dump - leaving it empty will make kernel get stuck somewhere very early&lt;/p&gt;
    &lt;p&gt;For iPod touch 3 I also had to clean-up the diff out of iPhone-specific things before applying it to iPod's 5.1.1 DeviceTree&lt;/p&gt;
    &lt;head rend="h2"&gt;iBoot&lt;/head&gt;
    &lt;p&gt;iBoot didn't require any major changes in this case. Just typical Image3 signature check patch, boot-args injection and &lt;code&gt;debug-enabled&lt;/code&gt; patch so kernel is going to actually respect AMFI boot-args&lt;/p&gt;
    &lt;p&gt;One important thing is to actually populate &lt;code&gt;nvram-proxy-data&lt;/code&gt; dynamically, at least for normal boots (aka non-restore). Restore boot will be fine with some random NVRAM hardcoded into DeviceTree, but normal one will overwrite your actual NVRAM with the random one if it decides to sync it at some point&lt;/p&gt;
    &lt;p&gt;I do it by replacing a call to &lt;code&gt;UpdateDeviceTree()&lt;/code&gt; with my own little function that calls the real &lt;code&gt;UpdateDeviceTree()&lt;/code&gt;, but also populates actual &lt;code&gt;nvram-proxy-data&lt;/code&gt; and &lt;code&gt;random-seed&lt;/code&gt; (this one shouldn't be of any importance)&lt;/p&gt;
    &lt;p&gt;For boot-args I always add &lt;code&gt;amfi=0xff&lt;/code&gt; to disable code-signing, but that's pretty cannonical as well&lt;/p&gt;
    &lt;p&gt;Please note that other iBoot+kernel combos might require more changes - if you ever try something and it doesn't work, I recommend looking into DeviceTree differences (both the initial template and how iBoot fills it) and also &lt;code&gt;boot_args&lt;/code&gt; structure iBoot passes to kernel (not to be confused with boot-args string, the &lt;code&gt;boot_args&lt;/code&gt; structure is a different thing)&lt;/p&gt;
    &lt;head rend="h2"&gt;Kernelcache&lt;/head&gt;
    &lt;p&gt;The most complex part. iPod touch 3 never got iOS 6 officialy, yes, but it was rumored that initially it was meant to have it, but Apple's marketing team said no. Either way, almost every internal iOS 6 build got both standalone S5L8922X kernel and even standalone kexts (including ones specific to iPod touch 3)&lt;/p&gt;
    &lt;p&gt;The question is how to load them all simultaneously. My initial idea was to do it just as older Mac OS X could do - load all kexts dynamically on bootloader level. Long story short, my strategy was the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;In iBoot context, load all kexts from filesystem - binary itself + Info.plist&lt;/item&gt;
      &lt;item&gt;Lay them out in memory and add corresponding entries to &lt;code&gt;chosen/memory-map&lt;/code&gt;node of DeviceTree&lt;/item&gt;
      &lt;item&gt;Boot standalone kernel which will then pick them up and load&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The sad outcome:&lt;/p&gt;
    &lt;code&gt;panic(cpu 0 caller 0x802e5223): "kern_return_t kxld_link_file(KXLDContext *, u_char *, u_long, const char *, void *, KXLDDependency *, u_int, u_char **, kxld_addr_t *) (com.apple.kec.corecrypto) called in kernel without kxld support"
&lt;/code&gt;
    &lt;p&gt;The kernel has all the code to pick them up, but not to actually link...&lt;/p&gt;
    &lt;head rend="h3"&gt;Glueing a prelinked kernelcache&lt;/head&gt;
    &lt;p&gt;So creating a legit kernelcache is the only way after all. I was already imagining all the horrors of writing software to parse and apply &lt;code&gt;LINKEDIT&lt;/code&gt; and etc., but then it occured to me! Mac OS X (before Apple Silicon) was generating such kernelcaches somehow! What if we use that logic to build our iOS kernelcache?&lt;/p&gt;
    &lt;code&gt;kcgen \
    -c output.bin \
    $(cat n18.10A403.kextlist | sed 's/^/--bundle-id /') \
    -kernel kernels_kexts_10A63970m/mach.development.s5l8922x \
    -arch armv7 \
    -all-personalities \
    -strip-symbols \
    -uncompressed \
    -- \
    kernels_kexts_10A63970m/Extensions
&lt;/code&gt;
    &lt;p&gt;I used &lt;code&gt;/usr/local/bin/kcgen&lt;/code&gt; from internal Sierra build (can be found online as "Phoenix A1708.dmg"), but it seems that even latest macOS &lt;code&gt;kextcache&lt;/code&gt; can do it (included by default)&lt;/p&gt;
    &lt;p&gt;Here is a breakdown of the options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-c output.bin&lt;/code&gt;- output file to write resulting kernelcache to&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$(cat n18.10A403.kextlist | sed 's/^/--bundle-id /')&lt;/code&gt;- this weird expression appends&lt;code&gt;--bundle-id&lt;/code&gt;to every line from the file at&lt;code&gt;n18.10A403.kextlist&lt;/code&gt;. This is to specify which kexts we'd like to include. How I created such list is described below&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-arch armv7&lt;/code&gt;- obviously only build armv7 slice&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-all-personalities&lt;/code&gt;- very important flag that prevents irrelevant IOKit personalities to be stripped. "Irrelevant" as in "irrelevant to current machine", meaning everything relevant to iPod touch 3 is going to be stripped&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-strip-symbols&lt;/code&gt;- strips unnecessary symbols. This flag can be omitted theoretically, but I recommend keeping it to make resulting kernelcache smaller&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-uncompressed&lt;/code&gt;- do not apply compression. Since we'll have to change one little thing later, compression would have to be reapplied anyway&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--&lt;/code&gt;means the rest of the args will point to directories to grab kexts from&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;kernels_kexts_10A63970m/Extensions&lt;/code&gt;is a path to a folder containing kexts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The little thing to do is to remove fat header. For some reason, it creates a fat Mach-O with a single slice. iBoot doesn't like it, so let's strip it:&lt;/p&gt;
    &lt;code&gt;lipo -thin armv7 output.bin -o output.thin.bin
&lt;/code&gt;
    &lt;p&gt;The kernel cache is ready now! Just needs to be compressed and packaged into Image3 container&lt;/p&gt;
    &lt;head rend="h4"&gt;About kext lists&lt;/head&gt;
    &lt;p&gt;Once again I compared iPhone 3GS' iOS 5.1.1 vs. 6.0 - some kexts were added, some removed, some changed their bundle IDs, some were irrelevant for iPod touch 3&lt;/p&gt;
    &lt;p&gt;Do not forget to include the pseudo-extensions as well!&lt;/p&gt;
    &lt;p&gt;Samples can be found in SundanceInH2A repository&lt;/p&gt;
    &lt;head rend="h4"&gt;About IOKit personalities&lt;/head&gt;
    &lt;p&gt;In this specific case I had to patch up Info.plist of the Wi-Fi kext. As always there is a sample in the repo&lt;/p&gt;
    &lt;head rend="h2"&gt;Restore ramdisk filesystem&lt;/head&gt;
    &lt;p&gt;Pretty cannonical here. I patched &lt;code&gt;asr&lt;/code&gt; as usual and also had to move &lt;code&gt;options.n88.plist&lt;/code&gt; to &lt;code&gt;options.n18.plist&lt;/code&gt; so it can lay out partitions properly&lt;/p&gt;
    &lt;p&gt;However, I also have to install the iBoot exploit. To do that I reimplement &lt;code&gt;rc.boot&lt;/code&gt; binary:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Remount ramdisk and set&lt;/p&gt;&lt;code&gt;umask&lt;/code&gt;just like the original one does&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Call&lt;/p&gt;&lt;code&gt;restored_external&lt;/code&gt;, but with&lt;code&gt;-server&lt;/code&gt;argument, so it doesn't reboot after finishing restore&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If restore was completed properly, I add a third partition, write the exploit there and set&lt;/p&gt;&lt;code&gt;boot-partition&lt;/code&gt;to&lt;code&gt;2&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reboot the device&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My implementation is available guess where? Yes, in the repository&lt;/p&gt;
    &lt;head rend="h2"&gt;Root filesystem&lt;/head&gt;
    &lt;p&gt;This needed a lot of changes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Add matching SpringBoard's hardware feature plist (&lt;/p&gt;&lt;code&gt;/System/Library/CoreServices/SpringBoard.app/N18AP.plist&lt;/code&gt;in this case)&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;I took the iOS 5.1.1 variant as a base and added iOS 6 specific capabilities&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I tried to keep original enough Home screen icon order by merging iPod touch 3 iOS 5.1.1 and iPod touch 4 6.x layouts&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add multitouch &amp;amp; Wi-Fi firmwares&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;I use versions from 5.1.1&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add Bluetooth firmware and scripts&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;This is more complicated, as those are all hardcoded into&lt;/p&gt;
            &lt;code&gt;/usr/sbin/BlueTool&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Luckily, they can also be overriden by files in&lt;/p&gt;&lt;code&gt;/etc/bluetool&lt;/code&gt;- as always check my code for reference&lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;I extracted both firmware and scripts from 5.1.1&lt;/p&gt;
            &lt;code&gt;BlueTool&lt;/code&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;FairPlay daemon is limited to&lt;/p&gt;&lt;code&gt;N88AP&lt;/code&gt;(iPhone 3GS)&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;It has&lt;/p&gt;&lt;code&gt;LimitLoadToHardware&lt;/code&gt;key in its' LaunchDaemon plist&lt;/item&gt;&lt;item&gt;&lt;p&gt;But if we simply remove the key, it works on iPod touch 3 as well&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This is important, because otherwise we cannot activate device through Apple's servers&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This trick will be harder to pull off on iOS 6.1+ because they load LaunchDaemons from a signed cache. Still can be bypassed in many ways - for instance, patching&lt;/p&gt;&lt;code&gt;launchd&lt;/code&gt;or forcefully loading another plist via&lt;code&gt;launchctl&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DYLD shared cache patches&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;Product ID map patch&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;iOS 6 brings a concept of "product ID" in the form of a long byte sequence&lt;/item&gt;
              &lt;item&gt;It is filled by iBoot into &lt;code&gt;product&lt;/code&gt;node of DeviceTree (which didn't even exist before)&lt;/item&gt;
              &lt;item&gt;I hardcode the value of iPhone 3GS straight into DeviceTree (&lt;code&gt;8784AE8D7066B0F0136BE91DCFE632A436FFD6FB&lt;/code&gt;)&lt;/item&gt;
              &lt;item&gt;There is also a short form of this identifier - 16-bit integer - which existed before iOS 6&lt;/item&gt;
              &lt;item&gt;iPhone 3GS is &lt;code&gt;0x2714&lt;/code&gt;and the iPod is&lt;code&gt;0x2715&lt;/code&gt;&lt;/item&gt;
              &lt;item&gt;MobileGestalt framework has a table that matches the short form by the long one - I swap &lt;code&gt;0x2714&lt;/code&gt;with&lt;code&gt;0x2715&lt;/code&gt;there&lt;/item&gt;
              &lt;item&gt;I believe it's better for iTunes and etc.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;getDeviceVariant()&lt;/code&gt;patch&lt;list rend="ul"&gt;&lt;item&gt;MobileGestalt once again messes us up our business&lt;/item&gt;&lt;item&gt;Device variant is a letter - usually "A" or "B"&lt;/item&gt;&lt;item&gt;It seems to depend on Wi-Fi transciever vendor used in exact device (?)&lt;/item&gt;&lt;item&gt;iOS 6 fails miserably to determine this value for iPod touch 3&lt;/item&gt;&lt;item&gt;This crashes activation process, for example&lt;/item&gt;&lt;item&gt;To fix it, I patch the function to always return "A" (in form of &lt;code&gt;CFString&lt;/code&gt;)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Fixing code signature&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;This is much easier than most people think&lt;/item&gt;
              &lt;item&gt;Shared cache files have the same format of signature as normal Mach-Os&lt;/item&gt;
              &lt;item&gt;And since it's just ad-hoc, all you need to do is to recalculate SHA-1 hash for pages you modified and update the signature&lt;/item&gt;
              &lt;item&gt;So easy, it can be done with just a hex-editor&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The iBoot exploit&lt;/head&gt;
    &lt;p&gt;iOS 5 iBoot had a bug in HFS+ filesystem driver. I did make an exploit many years ago but it was bad. Like, truly bad. I reimplemented it from scratch for this project making it deterministic (hopefully...)&lt;/p&gt;
    &lt;p&gt;This subject probably deserves a separate article&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion &amp;amp; future plans&lt;/head&gt;
    &lt;p&gt;This was not easy to do, and yet easier than I expected initially&lt;/p&gt;
    &lt;p&gt;After releasing the tool many people asked me about jailbreaking. The old tools are not going to work, but it should be easy to just patch the kernel and drop Cydia tarball onto the filesystem. I guess I will give it a try later&lt;/p&gt;
    &lt;p&gt;There was another device that Apple dropped support for in that year - iPad 1. I will try that soon enough as well&lt;/p&gt;
    &lt;p&gt;I hope that the information from this write-up will help you making other crazy combinations, like iOS 4 on iPhone 4S or iOS 5 on iPad mini 1&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46063272</guid><pubDate>Wed, 26 Nov 2025 22:57:56 +0000</pubDate></item><item><title>Functional Data Structures and Algorithms: a Proof Assistant Approach</title><link>https://fdsa-book.net/</link><description>&lt;doc fingerprint="96e790871cbf635a"&gt;
  &lt;main&gt;
    &lt;p&gt;This book is an introduction to data structures and algorithms for functional languages, with a focus on proofs. It covers both functional correctness and running time analysis. It does so in a unified manner with inductive proofs about functional programs and their running time functions. All proofs have been machine-checked by the proof assistant Isabelle. The pdf contains links to the corresponding Isabelle theories.&lt;/p&gt;
    &lt;p&gt;Click on an image to download the pdf of the whole book:&lt;/p&gt;
    &lt;p&gt;This book is meant to evolve over time. If you would like to contribute, get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46064680</guid><pubDate>Thu, 27 Nov 2025 02:04:57 +0000</pubDate></item><item><title>Penpot: The Open-Source Figma</title><link>https://github.com/penpot/penpot</link><description>&lt;doc fingerprint="d448ea5b7d378672"&gt;
  &lt;main&gt;
    &lt;p&gt;Website ‚Ä¢ User Guide ‚Ä¢ Learning Center ‚Ä¢ Community&lt;/p&gt;
    &lt;p&gt;Youtube ‚Ä¢ Peertube ‚Ä¢ Linkedin ‚Ä¢ Instagram ‚Ä¢ Mastodon ‚Ä¢ Bluesky ‚Ä¢ X&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;Penpot_OpenYourEyes_.mp4&lt;/head&gt;
    &lt;p&gt;Penpot is the first open-source design tool for design and code collaboration. Designers can create stunning designs, interactive prototypes, design systems at scale, while developers enjoy ready-to-use code and make their workflow easy and fast. And all of this with no handoff drama.&lt;/p&gt;
    &lt;p&gt;Available on browser or self-hosted, Penpot works with open standards like SVG, CSS, HTML and JSON, and it‚Äôs free!&lt;/p&gt;
    &lt;p&gt;The latest updates take Penpot even further. It‚Äôs the first design tool to integrate native design tokens‚Äîa single source of truth to improve efficiency and collaboration between product design and development. With the huge 2.0 release, Penpot took the platform to a whole new level. This update introduces the ground-breaking CSS Grid Layout feature, a complete UI redesign, a new Components system, and much more. For organizations that need extra service for its teams, get in touch&lt;/p&gt;
    &lt;p&gt;üéá Design, code, and Open Source meet at Penpot Fest! Be part of the 2025 edition in Madrid, Spain, on October 9-10.&lt;/p&gt;
    &lt;p&gt;Penpot expresses designs as code. Designers can do their best work and see it will be beautifully implemented by developers in a two-way collaboration.&lt;/p&gt;
    &lt;p&gt;Penpot plugins let you expand the platform's capabilities, give you the flexibility to integrate it with other apps, and design custom solutions.&lt;/p&gt;
    &lt;p&gt;Penpot was built to serve both designers and developers and create a fluid design-code process. You have the choice to enjoy real-time collaboration or play "solo".&lt;/p&gt;
    &lt;p&gt;Work with ready-to-use code and make your workflow easy and fast. The inspect tab gives instant access to SVG, CSS and HTML code.&lt;/p&gt;
    &lt;p&gt;Provide your team or organization with a completely owned collaborative design tool. Use Penpot's cloud service or deploy your own Penpot server.&lt;/p&gt;
    &lt;p&gt;Penpot offers integration into the development toolchain, thanks to its support for webhooks and an API accessible through access tokens.&lt;/p&gt;
    &lt;p&gt;Penpot brings design systems to code-minded teams: a single source of truth with native Design Tokens, Components, and Variants for scalable, reusable, and consistent UI across projects and platforms.&lt;/p&gt;
    &lt;p&gt;Penpot is the only design &amp;amp; prototype platform that is deployment agnostic. You can use it in our SAAS or deploy it anywhere.&lt;/p&gt;
    &lt;p&gt;Learn how to install it with Docker, Kubernetes, Elestio or other options on our website. &lt;/p&gt;
    &lt;p&gt;We love the Open Source software community. Contributing is our passion and if it‚Äôs yours too, participate and improve Penpot. All your designs, code and ideas are welcome!&lt;/p&gt;
    &lt;p&gt;If you need help or have any questions; if you‚Äôd like to share your experience using Penpot or get inspired; if you‚Äôd rather meet our community of developers and designers, join our Community!&lt;/p&gt;
    &lt;p&gt;You will find the following categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ask the Community&lt;/item&gt;
      &lt;item&gt;Troubleshooting&lt;/item&gt;
      &lt;item&gt;Help us Improve Penpot&lt;/item&gt;
      &lt;item&gt;#MadeWithPenpot&lt;/item&gt;
      &lt;item&gt;Events and Announcements&lt;/item&gt;
      &lt;item&gt;Inside Penpot&lt;/item&gt;
      &lt;item&gt;Penpot in your language&lt;/item&gt;
      &lt;item&gt;Design and Code Essentials&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anyone who contributes to Penpot, whether through code, in the community, or at an event, must adhere to the code of conduct and foster a positive and safe environment.&lt;/p&gt;
    &lt;p&gt;Any contribution will make a difference to improve Penpot. How can you get involved?&lt;/p&gt;
    &lt;p&gt;Choose your way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create and share Libraries &amp;amp; Templates that will be helpful for the community&lt;/item&gt;
      &lt;item&gt;Invite your team to join&lt;/item&gt;
      &lt;item&gt;Give this repo a star and follow us on Social Media: Mastodon, Youtube, Instagram, Linkedin, Peertube, X and BlueSky&lt;/item&gt;
      &lt;item&gt;Participate in the Community space by asking and answering questions; reacting to others‚Äô articles; opening your own conversations and following along on decisions affecting the project.&lt;/item&gt;
      &lt;item&gt;Report bugs with our easy guide for bugs hunting or GitHub issues&lt;/item&gt;
      &lt;item&gt;Become a translator&lt;/item&gt;
      &lt;item&gt;Give feedback: Email us&lt;/item&gt;
      &lt;item&gt;Contribute to Penpot's code: Watch this video by Alejandro Alonso, CIO and developer at Penpot, where he gives us a hands-on demo of how to use Penpot‚Äôs repository and make changes in both front and back end&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To find (almost) everything you need to know on how to contribute to Penpot, refer to the contributing guide.&lt;/p&gt;
    &lt;p&gt;You can ask and answer questions, have open-ended conversations, and follow along on decisions affecting the project.&lt;/p&gt;
    &lt;p&gt;‚úèÔ∏è Tutorials&lt;/p&gt;
    &lt;p&gt;üèòÔ∏è Architecture&lt;/p&gt;
    &lt;code&gt;This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this
file, You can obtain one at http://mozilla.org/MPL/2.0/.

Copyright (c) KALEIDOS INC
&lt;/code&gt;
    &lt;p&gt;Penpot is a Kaleidos‚Äô open source project&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46064757</guid><pubDate>Thu, 27 Nov 2025 02:14:36 +0000</pubDate></item><item><title>DIY NAS: 2026 Edition</title><link>https://blog.briancmoses.com/2025/11/diy-nas-2026-edition.html</link><description>&lt;doc fingerprint="e650381101a64f39"&gt;
  &lt;main&gt;
    &lt;p&gt;Fourteen years ago, my storage needs outpaced my capacity and I began to look into building a network attached storage server. I had a few criteria in mind and was curious to see if anyone had _ recently_ shared something similar, but I couldn√¢t find anything that was relevant.&lt;/p&gt;
    &lt;p&gt;In fact, I found that the communities I was looking for answers in were actively hostile towards what I wanted to do. This resulted in my decision to build my own DIY NAS and share that as one of my very first blogs.&lt;/p&gt;
    &lt;p&gt;Much to my surprise, people were very interested in that blog! Ever since, I√¢ve been building a similar DIY NAS machine almost every year, trying to satisfy the curiosity of other prospective DIY NAS builders.&lt;/p&gt;
    &lt;p&gt;Here are those criteria:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Small form factor: It√¢s not the case for me anymore, but at the time the space was limited in my office. I always assume that space in everybody√¢s office is limited. As a result, I want my DIY NAS builds to occupy as little of that office space as I can.&lt;/item&gt;
      &lt;item&gt;At least six drive bays: Back when I built my NAS, it took about four drives√¢ worth of storage to meet my storage needs. Plus, I desired two empty drive bays for future use. However, in the years since, hard drive capacities have increased dramatically. At some point in the future, I may reduce this to four drive bays.&lt;/item&gt;
      &lt;item&gt;An integrated, low-power CPU: I intend my DIY NAS to run 24 hours a day, 7 days a week, and 52 weeks a year. When it comes to power consumption, that can do some damage on your electric bill! Thankfully, our electricity here isn√¢t as expensive as others√¢ in the United States, or even further outside its borders, but I try and keep power consumption in mind when picking components for a DIY NAS build.&lt;/item&gt;
      &lt;item&gt;Homelab potential: It does not take up a lot of CPU horsepower for a NAS to serve up files, which means that on modern hardware there√¢s a lot of untapped potential in a DIY NAS for virtual machines and/or containers to self-host services.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It√¢s important to remember that these are my criteria, and not necessarily yours. Every DIY NAS builder should be making their own list of criteria and reconcile all of their component purchases against the criteria that√¢s important to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is it even a good time to build a NAS?&lt;/head&gt;
    &lt;p&gt;As I prepared to build this NAS, component prices disappointed me. Hard drives, SSDs, and RAM prices were all rising. Based on what I√¢ve been told, I expect Intel CPU prices to increase as well. My contact at Topton has been encouraging me to stock up on motherboards while they still have some in inventory. Based on what√¢s been explained to me, I expect the motherboards√¢ prices to rise and for their availability to potentially dwindle.&lt;/p&gt;
    &lt;p&gt;In short, the economy sucks, and the price of DIY NAS components is a pretty good reflection of just how sucky things are becoming. I briefly considered not publishing a DIY NAS build this year, hoping that things would improve a few months down the road. But then I asked myself, √¢What if it√¢s even worse in a few months?√¢&lt;/p&gt;
    &lt;p&gt;I sure hope things get better, but I fear and expect that they√¢ll get worse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Motherboard and CPU&lt;/head&gt;
    &lt;p&gt;I built my first DIY NAS with a Topton motherboard in 2023. Each DIY NAS since then has also featured a Topton motherboard. My only complaint about the motherboards has been that buying them from one of the Chinese e-tail sites like AliExpress is considered problematic by some. With every DIY NAS build, I try and go through all the motherboards that I can find while searching for something with a better value proposition, but for each of the past three years I√¢ve landed on the latest offering from Topton.&lt;/p&gt;
    &lt;p&gt;For the DIY NAS: 2026 Edition, I chose the Topton N22 motherboard with the Intel Core 3 N355 CPU. The motherboard is similar to last year√¢s Topton N18 but has incrementally more compelling features, particularly the extra 2 SATA ports, the PCI-e x1 slot, and the N355 CPU!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mini-ITX Form Factor&lt;/item&gt;
      &lt;item&gt;Intel√Ç¬Æ Processor Core 3 N355 &lt;list rend="ul"&gt;&lt;item&gt;8 cores / 8 threads / Max Turbo 3.9GHz&lt;/item&gt;&lt;item&gt;15 W TDP&lt;/item&gt;&lt;item&gt;Integrated GPU with Intel Quick Sync Video&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1 x DDR5 SO-DIMM&lt;/item&gt;
      &lt;item&gt;8 x SATA 3.0 Ports (Asmedia ASM1164)&lt;/item&gt;
      &lt;item&gt;2 x M.2 NVMe Slots (PCIe 3.0 x1)&lt;/item&gt;
      &lt;item&gt;1 x 10Gbps NIC (Marvell AQC113C)&lt;/item&gt;
      &lt;item&gt;2 x 2.5Gbps NICs (Intel i226-V)&lt;/item&gt;
      &lt;item&gt;1 x PCI-e x1 or M.2 E-Key slot&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I opted for the motherboard with the Intel Core 3 N355 CPU. This makes the server a more capable homelab machine than prior years√¢ DIY NAS builds. The extra cores and threads come in handy for streaming media, replacing your cloud storage, facilitating home automation, hosting game servers, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case&lt;/head&gt;
    &lt;p&gt;Just like Topton has been making great motherboards for DIY NAS machines, JONSBO has been steadily releasing great cases for DIY NAS machines. This year SilverStone Technology, released a new case, the CS383 (specs), which I was very interested in buying for the DIY NAS: 2026 Edition. Unfortunately, it carries a pretty hefty price tag to go along with all of its incredible features!&lt;/p&gt;
    &lt;p&gt;The JONSBO N4 (specs) is a third of the price, adheres to my √¢smaller footprint√¢ criteria, and it is rather impressive on its own. It√¢s a tiny bit larger case than last year√¢s DIY NAS, but I really like that it has drive bays for six 3.5√¢ drives and two 2.5√¢ drives.&lt;/p&gt;
    &lt;p&gt;It√¢s peculiar in that two of the 3.5√¢ drive bays (and the two 2.5√¢ drive bays) aren√¢t attached to a SATA backplane and can√¢t be swapped anywhere as easily as the other four 3.5√¢ bays. However, this peculiar decision seems to have caused the JONSBO N4 to sell for a bit less ($20√¢$40) than similar offerings from JONSBO. At its price, it√¢s a compelling value proposition!&lt;/p&gt;
    &lt;head rend="h3"&gt;Case Fan&lt;/head&gt;
    &lt;p&gt;In the past, I√¢ve found that the fans that come with JONSBO cases are too noisy. They√¢ve been noisy for two reasons: The design and quality of the fans make them loud, and the fans are constantly running at their top speed because of the fan header they√¢re plugged into on the cases√¢ SATA backplanes.&lt;/p&gt;
    &lt;p&gt;I anticipated that fan efficiency and noise would be a problem, so I picked out the Noctua NF-A12x25 PWM to solve it. Firstly, swapping in a high-quality fan that pushes more air and generates less noise√¢especially at its top speed√¢is a good first step. Secondly, I√¢d address the problem by plugging the fan into the motherboard√¢s &lt;code&gt;SYS_FAN&lt;/code&gt; header instead of on the SATA backplane. This provides the opportunity to tune the fan√¢s RPMs directly in the BIOS and generate far less noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;RAM&lt;/head&gt;
    &lt;p&gt;The first time I first asked myself, √¢Should I even build the DIY NAS: 2026 Edition?√¢ came as I was checking prices on DDR5 memory. Thankfully for me, I had leftover RAM after purchasing DDR5 4800MHz SODIMMs for the DIY NAS: 2025 Edition, the Pocket Mini NAS, and then again for the DIY NAS that I built and gave away at 2025√¢s Texas Linux Fest. I was personally thankful that I had one brand-new 32GB DDR5 4800MHz SODIMM lying around, but I was wildly disappointed for everybody who will try and follow this build when I saw the price of those same SODIMMs.&lt;/p&gt;
    &lt;p&gt;Regardless, I felt a Crucial 32GB DDR5 4800MHz SODIMM (specs) was the right amount of RAM to get started with for a DIY NAS build in 2025. Whether you just need storage or you wish to also host virtual machines, you will benefit from having more than the bare minimum recommendation of RAM. I really wanted to buy a 48GB DDR5 4800MHZ SODIMM for this DIY NAS build, but I couldn√¢t talk myself into spending the $250√¢$300 that it would√¢ve wound up costing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Storage&lt;/head&gt;
    &lt;p&gt;A quick disclaimer about all the drives that I purchased for the DIY NAS: 2026 Edition:, I already had all of them! I tend to buy things when I see them on sale, and as a result, I have a collection of brand-new parts for machines in my homelab or for upcoming projects. I raided that collection of spare parts for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;head rend="h3"&gt;Boot Drive&lt;/head&gt;
    &lt;p&gt;If you ranked the drives in your DIY NAS in order of importance, the boot drive should be the least-important drive. That is not saying that boot drive isn√¢t performing an important function, but I am suggesting that you shouldn√¢t invest a bunch of energy and money into picking the optimal boot drive.&lt;/p&gt;
    &lt;p&gt;Because the JONSBO N4 has a pair of 2.5√¢ drive bays, I decided that a 2.5√¢ SATA SSD would be ideal for the boot drives. As a rule of thumb, I try and spend less than $30 per boot drive in my DIY NAS builds.&lt;/p&gt;
    &lt;p&gt;Ultimately I selected a pair of 128GB Silicon Power A55 SSDs (specs). I√¢ve used these before, I√¢d use them again in the future, and I even have four of their higher-capacity (1TB) SSDs in a pool in my own NAS.&lt;/p&gt;
    &lt;head rend="h3"&gt;App and Virtual Machine NVMe SSDs&lt;/head&gt;
    &lt;p&gt;Using your DIY NAS to host containers and virtual machines has really exploded in the past few years. The developers of NAS appliances have all made it much easier, and the self-hosted products themselves have become as good√¢or often better√¢than things you√¢re probably subscribing to today. Because of that, I saved the highest-performing storage options on the Topton N22 motherboard for apps and VMs.&lt;/p&gt;
    &lt;p&gt;However, it√¢s important to point out that these M.2 slots are PCI-e version 3 and capped at a single PCI-e lane. This is a consequence of the limited number of PCI-e lanes available for each of the CPU options available for the Topton N22 motherboard (N100, N150, N305, and N355).&lt;/p&gt;
    &lt;p&gt;I opted for a NVMe drive that was a good value rather than a high performer and chose two of the Silicon Power 1TB M.2 NVMe SSDs (SP001TBP34A60M28) (specs).&lt;/p&gt;
    &lt;head rend="h3"&gt;Bulk Storage Hard Disk Drives&lt;/head&gt;
    &lt;p&gt;Thanks to rising prices, I opted to do like I√¢ve done with past DIY NAS builds and skip buying hard drives for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;p&gt;When planning your DIY NAS, it is good to always remember that storage will ultimately be your costliest and most important expense.&lt;/p&gt;
    &lt;p&gt;Here are a few things to consider when buying hard drives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Determine your hardware redundancy preferences. I recommend having two hard disk drives√¢ worth of redundancy (RAIDZ2, RAID6, etc.)&lt;/item&gt;
      &lt;item&gt;Focus on price-per-terabyte when comparing prices of drives.&lt;/item&gt;
      &lt;item&gt;Do some burn-in testing of your hard drives before putting them to use.&lt;/item&gt;
      &lt;item&gt;When buying new drives of the same model, try and buy them from multiple vendors to increase the chances of buying drives manufactured in separate batches.&lt;/item&gt;
      &lt;item&gt;Plan ahead! Understand the rate that your storage grows so that you can craft a strategy to grow your storage down the road.&lt;/item&gt;
      &lt;item&gt;Being cheap today can and will paint you into a corner that√¢s quite expensive to get out of.&lt;/item&gt;
      &lt;item&gt;Understand that RAID is not a backup!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thankfully, I√¢ve collected a bunch of my own decommissioned hard drives which I used to thoroughly test this DIY NAS build.&lt;/p&gt;
    &lt;head rend="h2"&gt;SATA Cables&lt;/head&gt;
    &lt;p&gt;One of the under-the-radar features of the Topton N22 motherboard might be one of my favorite features! The motherboard√¢s Asmedia ASM1164 SATA controllers sit behind two SFF-8643 connectors. These connectors provide two advantages for these motherboards:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Save room on the motherboard√¢s PCB.&lt;/item&gt;
      &lt;item&gt;SFF-8643 to 4x SATA breakout cables reduce the amount of cable management hassle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Power Supply&lt;/head&gt;
    &lt;p&gt;The one thing that I have routinely disliked about building small form factor DIY NAS machines is the price tag that accompanies a small form factor power supply (SFX) like is required with the JONSBO N4.&lt;/p&gt;
    &lt;p&gt;I wound up choosing the SilverStone Technology SX500-G (specs) which I had used earlier in the year for the DIY NAS I gave away at Texas Linux Fest. Its 500W rating exceeds the needs of all the components that I√¢d picked out for the DIY NAS: 2026 Edition. Plus, the power supply√¢s 80 Plus Gold rating aligns well with my criteria for power efficiency.&lt;/p&gt;
    &lt;head rend="h2"&gt;TrueNAS Community Edition&lt;/head&gt;
    &lt;p&gt;Regardless of whether it was called FreeNAS, TrueNAS, TrueNAS CORE, TrueNAS SCALE, or now TrueNAS Community Edition, the storage appliance product(s) from iXSystems have always been my go-to choice. For each yearly DIY NAS build, I wander over to the TrueNAS Software Status page and look at the state of the current builds.&lt;/p&gt;
    &lt;p&gt;I√¢m conservative with my personal NAS setup. However, for these blog builds, I typically choose Early Adopter releases. This year that√¢s TrueNAS 25.10.0.1 (aka Goldeye). I enjoy being able to use these DIY NAS builds as a preview to the latest and greatest that TrueNAS has to offer.&lt;/p&gt;
    &lt;p&gt;I repeatedly choose TrueNAS because it√¢s become an enterprise-grade storage product, which is exactly the quality of solution that I want my data depending on. At the same time, it does not feel like you need a specialized certification and a truckload of enterprise storage experience to set up a NAS that exceeds your needs at home.&lt;/p&gt;
    &lt;p&gt;Many times I have been asked, √¢Why not &amp;lt;insert NAS appliance or OS here&amp;gt;?√¢ My answer to that question is, TrueNAS has always done everything that I need it to, and they haven√¢t given me any reason to consider anything else. As a result, there√¢s never been a need for me to evaluate something else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Parts List&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Part Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Qty&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Motherboard&lt;/cell&gt;
        &lt;cell&gt;Topton N22 (w/ N355 CPU) NAS Motherboard&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$446.40&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CPU&lt;/cell&gt;
        &lt;cell&gt;Intel Core 3 N355&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;Crucial RAM 32GB DDR5 4800MHz SODIMM (CT32G48C40S5)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$172.96&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case&lt;/cell&gt;
        &lt;cell&gt;JONSBO N4&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$121.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case Fan&lt;/cell&gt;
        &lt;cell&gt;Noctua NF-A12x25 PWM chromax.Black.swap&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$37.95&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Power Supply&lt;/cell&gt;
        &lt;cell&gt;SilverStone 500W SFX Power Supply SST-SX500-G)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$142.34&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot Drive&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 128GB A55 SATA SSD&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$21.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Apps/VM Drives&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 1TB - NVMe M.2 SSD (SP001TBP34A60M28)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$99.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SATA Cables&lt;/cell&gt;
        &lt;cell&gt;OIKWAN SFF-8643 Host to 4 X SATA Breakout Cable&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$11.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Price without Storage:&lt;/cell&gt;
        &lt;cell&gt;$989.36&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total Price:&lt;/cell&gt;
        &lt;cell&gt;$1,189.34&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hardware Assembly, BIOS Configuration, and Burn-In&lt;/head&gt;
    &lt;head rend="h3"&gt;Hardware Assembly&lt;/head&gt;
    &lt;p&gt;I always want the smallest possible DIY NAS. The JONSBO N4 case initially felt too large since it accommodates Micro ATX motherboards. However, I grew to accept its slightly larger footprint. However, putting the Topton N22 motherboard into the case felt roomy and luxurious. Building the DIY NAS: 2026 Edition compared to prior years√¢ felt a lot like coming home to put on sweatpants and a T-shirt after wearing a suit and tie all day long.&lt;/p&gt;
    &lt;p&gt;I wasn√¢t too fond of the cable management of the power supply√¢s cables. The layout of the case pretty much makes the front of the power supply inaccessible once it is installed. One consequence of this is that the power cable which powered the SATA backplane initially prevented the 120mm case fan from spinning up. That issue was relatively minor and was resolved with zip ties.&lt;/p&gt;
    &lt;p&gt;Overall, I felt pretty good about the assembly of the DIY NAS: 2026 Edition, but things would take a turn for the worse when I decided to fill all the 3.5-inch drive bays up with some of my decommissioned 8TB HDDs. Now this is probably my fault, I wouldn√¢t be surprised at all that the manual of the JONSBO N4 warned me against this, but putting the drives in last turned out to be a major pain in the neck for each of the four drive bays without a SATA backplane.&lt;/p&gt;
    &lt;p&gt;I had wrongly guessed that you accessed those drives√¢ power and data ports from the front of the case. I worked really hard to route the cables and even managed to install all of the drives before realizing my error and learning my lesson. I√¢m understanding now why the JONSBO N4 is cheaper than all of its siblings: Partly because there√¢s a missing SATA backplane, but also because those other 4 drive bays√¢ layout is frustrating.&lt;/p&gt;
    &lt;p&gt;Don√¢t let my last couple paragraphs sour you on the JONSBO N4, though. I still really like its size; it feels big when you√¢re working in it with a Mini ITX motherboard. If you wind up deciding to use the JONSBO N4, then I suggest that you put those four drives and their cables in first before you do anything else. That would√¢ve made a world of difference for me. Looking at the documentation before getting started might have saved me quite a bit of aggravation, too!&lt;/p&gt;
    &lt;p&gt;If I have ruined the JONSBO N4 for you, then check out the JONSBO N3. Its eight 3.5-inch drive bays pair up really nicely with the Topton N22 motherboard. You can see what I thought of the JONSBO N3 by reading the DIY NAS: 2024 Edition blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;BIOS Configuration&lt;/head&gt;
    &lt;p&gt;Generally speaking, I do as little as I possibly can in the BIOS. Normally, I strive to only set the time and change the boot order. However, I did a bit more for the DIY NAS: 2026 Edition since I√¢m using the &lt;code&gt;SYS_FAN&lt;/code&gt; header for the fan responsible for cooling the hard drives.  Here are the changes that I made in the BIOS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set the System Date and System Time to Greenwich Mean Time &lt;list rend="ol"&gt;&lt;item&gt;Advanced &lt;list rend="ol"&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;list rend="ol"&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;code&gt;Disabled&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Set the Manual PWM Setting (for &lt;code&gt;SYS_FAN&lt;/code&gt;) to 180.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;/item&gt;&lt;item&gt;Set PWRON After Power Loss to &lt;code&gt;Always On&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Boot &lt;list rend="ol"&gt;&lt;item&gt;Set Boot Option #1 to the TrueNAS boot device.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Advanced &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I√¢m not at all interested in venturing into the rabbit√¢s hole of trying to completely minimize how much power the NAS uses. However, I imagine there are some opportunities for power savings lurking in the BIOS. I didn√¢t go looking for them myself, but if you√¢re intrepid enough to do so, here are a few suggestions that I have for saving some additional power:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable the onboard audio.&lt;/item&gt;
      &lt;item&gt;Disable any network interfaces that you don√¢t wind up using.&lt;/item&gt;
      &lt;item&gt;Tinker with the CPU settings.&lt;/item&gt;
      &lt;item&gt;Got other suggestions? Share them in the comments!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Burn-In&lt;/head&gt;
    &lt;p&gt;Because all of the hardware is brand-new to me and brand-new components are not guaranteed to be free of defects, I always do a little bit of burn-in testing to establish some trust in the hardware that I√¢ve picked out for each DIY NAS build. While I think doing some burn-in testing is critically important, I also think the value of subsequent burn-in testing drops the more that you do. Don√¢t get too carried away, and do your own burn-in testing in moderation!&lt;/p&gt;
    &lt;head rend="h4"&gt;Memtest86+&lt;/head&gt;
    &lt;p&gt;I always use Memtest86+ to burn-in the RAM. I always run at least 3+ passes of Memtest86+. Typically, I run many more passes because I tend to let the system keep running additional passes overnight. Secondarily, running these many passes gives the CPU a little bit of work to do and there√¢s enough information displayed by Memtest86+ to give me confidence in the CPU and its settings.&lt;/p&gt;
    &lt;head rend="h4"&gt;Hard Drives&lt;/head&gt;
    &lt;p&gt;The failure rate of hard drives is highest when the drives are new and then again when they√¢re old. Regardless of type of hard drives that I buy or when I buy them, I always do some disk burn-in. I tend to run Spearfoot√¢s Disk Burn-in and Testing script on all of my new drives. However, executing this script against all of the drives can take quite a long time, even if you use something like &lt;code&gt;tmux&lt;/code&gt; to run the tests in parallel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Initial TrueNAS CE Setup&lt;/head&gt;
    &lt;p&gt;There√¢s always a little bit of setup that I do for a new TrueNAS machine. This isn√¢t intended to be an all-inclusive step-by-step guide for all the things you should do with your DIY NAS. Instead, it√¢s more of a list of things I kept track of while I made sure that the DIY NAS: 2026 Edition was functional enough for me to finish writing this blog. That being said, I do think your NAS would be rather functional if you decided to do the same configuration.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Updated the hostname to &lt;code&gt;diynas2026&lt;/code&gt;&lt;list rend="ol"&gt;&lt;item&gt;Note: This is only to avoid issues with another NAS on my network.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Updated the time zone.&lt;/item&gt;
      &lt;item&gt;Enabled the following services and set them to start automatically. &lt;list rend="ol"&gt;&lt;item&gt;SMB&lt;/item&gt;&lt;item&gt;SSH&lt;/item&gt;&lt;item&gt;NFS&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Enabled password login for the &lt;code&gt;truenas_admin&lt;/code&gt;user.&lt;list rend="ul"&gt;&lt;item&gt;Note: If I were planning to use this DIY NAS long-term, I wouldn√¢t have done this. Using SSH keys for authentication is a better idea.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Edited the TrueNAS Dashboard widgets to reflect the 10Gb interface (&lt;code&gt;enp1s0&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;flash&lt;/code&gt;which consisted of mirrored vdev using the Teamgroup MP44 1TB NVMe SSDs.&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;rust&lt;/code&gt;which consisted of a single RAID-Z2 vdev using eight hard drives that I had sitting on my shelf after they were decommissioned.&lt;/item&gt;
      &lt;item&gt;Configured the Apps to use the &lt;code&gt;flash&lt;/code&gt;pool for the apps√¢ dataset.&lt;/item&gt;
      &lt;item&gt;Made sure that the System Dataset Pool was set to &lt;code&gt;flash&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Confirmed that there were Scrub Tasks set up for the &lt;code&gt;flash&lt;/code&gt;and&lt;code&gt;rust&lt;/code&gt;pools.&lt;/item&gt;
      &lt;item&gt;Created a dataset on each pool for testing: &lt;code&gt;flash-test&lt;/code&gt;and&lt;code&gt;rust-test&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Installed the Scrutiny app found in the App Catalog.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If I were planning to keep this NAS and use it for my own purposes, I would also:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up a Let√¢s Encrypt certificate.&lt;/item&gt;
      &lt;item&gt;Hook up the NAS to a compatible UPS, enable the UPS service, and configure the UPS service to shut down the NAS before the battery runs out of juice.&lt;/item&gt;
      &lt;item&gt;Set up system email alert service.&lt;/item&gt;
      &lt;item&gt;Create replication tasks to back up critical data to my off-site NAS.&lt;/item&gt;
      &lt;item&gt;Add the new NAS to my Tailscale tailnet using the Tailscale app from the official catalog.&lt;/item&gt;
      &lt;item&gt;As the NAS is seeded with data, create and maintain a suite of snapshot tasks tailored to the importance of the different data being stored on the NAS.&lt;/item&gt;
      &lt;item&gt;Set up S.M.A.R.T. tests for all of the drives: &lt;list rend="ol"&gt;&lt;item&gt;Weekly Short Test&lt;/item&gt;&lt;item&gt;Monthly Long Test&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Just about every year, I benchmark each DIY NAS build and almost always come to the same conclusion: The NAS will outperform your network at home. Your first bottleneck is almost always going to be the network, and the overwhelming majority of us have gigabit networks at home√¢but that√¢s slowly changing since 2.5Gbps and 10Gbps network hardware has started to get reasonably affordable lately.&lt;/p&gt;
    &lt;p&gt;Even though I always come to the same conclusion, I still like to do the benchmarks for two reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It helps me build confidence that the DIY NAS: 2026 Edition works well.&lt;/item&gt;
      &lt;item&gt;People tend to enjoy consuming benchmarks, and it√¢s fun for me to see the DIY NAS√¢ network card get saturated during the testing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Throughput&lt;/head&gt;
    &lt;p&gt;I like to do three categories of tests to measure the throughput of the NAS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use iperf3 to benchmark throughput between my NAS and another machine on my network.&lt;/item&gt;
      &lt;item&gt;Benchmark the throughput of the pool(s) locally on the NAS using &lt;code&gt;fio&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Set up SMB shares on each of the pools and then benchmark the throughput when using those shares.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every year I try and mention that Tom Lawrence from Lawrence Systems published a great video about benchmarking storage with FIO and shared the FIO commands from his video in their forums. I use these FIO commands constantly as a reference point forwh I am testing ZFS pools√¢ throughput. More importantly I√¢d like to point out that, in that same video, Tom says something very wise:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Pool&lt;/cell&gt;
        &lt;cell role="head"&gt;Test&lt;p&gt;Size&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1906.00&lt;/cell&gt;
        &lt;cell&gt;2200.00&lt;/cell&gt;
        &lt;cell&gt;548.00&lt;/cell&gt;
        &lt;cell&gt;1214.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;2132.00&lt;/cell&gt;
        &lt;cell&gt;3012.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
        &lt;cell&gt;1211.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1352.00&lt;/cell&gt;
        &lt;cell&gt;108.00&lt;/cell&gt;
        &lt;cell&gt;367.00&lt;/cell&gt;
        &lt;cell&gt;530.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;1474.00&lt;/cell&gt;
        &lt;cell&gt;326.00&lt;/cell&gt;
        &lt;cell&gt;368.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5858.89&lt;/cell&gt;
        &lt;cell&gt;50409.91&lt;/cell&gt;
        &lt;cell&gt;1104.64&lt;/cell&gt;
        &lt;cell&gt;956.70&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;4193.36&lt;/cell&gt;
        &lt;cell&gt;31047.36&lt;/cell&gt;
        &lt;cell&gt;635.42&lt;/cell&gt;
        &lt;cell&gt;946.20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5226.50&lt;/cell&gt;
        &lt;cell&gt;46239.01&lt;/cell&gt;
        &lt;cell&gt;756.23&lt;/cell&gt;
        &lt;cell&gt;655.32&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;3794.43&lt;/cell&gt;
        &lt;cell&gt;12809.33&lt;/cell&gt;
        &lt;cell&gt;759.38&lt;/cell&gt;
        &lt;cell&gt;677.02&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What do I think these benchmarks and my use of the DIY NAS: 2026 Edition tell me? In the grand scheme of things, not a whole lot.&lt;/p&gt;
    &lt;p&gt;However, these benchmarks do back up what I expected: The DIY NAS: 2026 Edition is quite capable and more than ready to meet my storage needs. I especially like that the CrystalDiskMark benchmarks of the SMB shares were both faster than a SATA SSD, and the throughput to the share on the &lt;code&gt;flash&lt;/code&gt; pool practically saturated the NAS√¢ 10GbE network connection.&lt;/p&gt;
    &lt;head rend="h4"&gt;FIO Tests&lt;/head&gt;
    &lt;p&gt;Every time I benchmark a NAS, I seem to either be refining what I tried in prior years or completely reinventing the wheel. As a result, I wouldn√¢t recommend comparing these results with results that I shared in prior years√¢ DIY NAS build blogs. I haven√¢t really put a ton of effort into developing a standard suite of benchmarks. Things in my homelab change enough between DIY NAS blogs that trying to create and maintain an environment for a standard suite of benchmarks is beyond what my budget, spare time, and attention span will allow.&lt;/p&gt;
    &lt;p&gt;I√¢m going to paste these &lt;code&gt;fio&lt;/code&gt; commands here in the blog for my own use in future DIY NAS build blogs. If you wind up building something similar, these might be helpful to measure your new NAS√¢ filesystem√¢s performance and compare it to mine!&lt;/p&gt;
    &lt;code&gt;## Random Write IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randwrite --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randwrite --ramp_time=10

## Random Read IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randread --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randread --ramp_time=10

## Sequential Write (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=4G --readwrite=write --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=32G --readwrite=write --ramp_time=10

## Sequential Read (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=4G --readwrite=read --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=32G --readwrite=read --ramp_time=10
&lt;/code&gt;
    &lt;head rend="h3"&gt;Power Consumption&lt;/head&gt;
    &lt;p&gt;One not-so-obvious cost of running a DIY NAS is how much power it consumes. While I specifically tried to pick items that were efficient in terms of power consumption, it√¢s also important to realize that all the other bells and whistles on the awesome Topton N22 NAS motherboard consume power, too, and that the biggest consumer of power in a NAS is almost always the hard disk drives.&lt;/p&gt;
    &lt;p&gt;Thanks to my tinkering with home automation, I have a plethora of smart outlets which are capable of power monitoring. I used those smart outlets for most of my power monitoring. But I also have a Kill a Watt P400 that I also use for some of the shorter tests:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Power consumed during a handful of specific tasks: &lt;list rend="ul"&gt;&lt;item&gt;Idle while running TrueNAS&lt;/item&gt;&lt;item&gt;RAM Burn-in (~14 passes of Memtest86+)&lt;/item&gt;&lt;item&gt;An 8-hour throughput benchmark copying randomly sized files to the NAS using SMB.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Total consumed during the build, burn-in, and use of the DIY NAS: 2026 Edition.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
        &lt;cell role="head"&gt;Max Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg. Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Total Consumption&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot&lt;/cell&gt;
        &lt;cell&gt;10 min.&lt;/cell&gt;
        &lt;cell&gt;200.00 W&lt;/cell&gt;
        &lt;cell&gt;120.00 W&lt;/cell&gt;
        &lt;cell&gt;0.02 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Idle&lt;/cell&gt;
        &lt;cell&gt;3 hr.&lt;/cell&gt;
        &lt;cell&gt;90.00 W&lt;/cell&gt;
        &lt;cell&gt;66.67 W&lt;/cell&gt;
        &lt;cell&gt;0.20 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;RAM Burn-in&lt;/cell&gt;
        &lt;cell&gt;18 hr.&lt;/cell&gt;
        &lt;cell&gt;104.00 W&lt;/cell&gt;
        &lt;cell&gt;91.67 W&lt;/cell&gt;
        &lt;cell&gt;1.65 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SMB Benchmark of HDDs&lt;/cell&gt;
        &lt;cell&gt;8 hr.&lt;/cell&gt;
        &lt;cell&gt;107.00 W&lt;/cell&gt;
        &lt;cell&gt;85.00 W&lt;/cell&gt;
        &lt;cell&gt;0.68 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;108 hr.&lt;/cell&gt;
        &lt;cell&gt;237.80 W&lt;/cell&gt;
        &lt;cell&gt;66.49 W&lt;/cell&gt;
        &lt;cell&gt;7.17 kWh&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;What about an EconoNAS?&lt;/head&gt;
    &lt;p&gt;Shortly before prices skyrocketed, I decided I wasn√¢t very interested in doing separate EconoNAS builds any longer. Several months ago, I realized that there were several off-the-shelf NAS machines that were more than capable of running TrueNAS, and they were selling at economical prices that couldn√¢t be topped by a DIY approach. I will dive deeper into this in a future blog, eventually √¢¬¶ maybe?&lt;/p&gt;
    &lt;p&gt;All that being said, it√¢d be incredibly easy to make some compromises which result in the DIY NAS: 2026 Edition becoming quite a bit more economical. Here√¢s a list of changes that I would consider to achieve a more budget-friendly build:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Different motherboard/CPU combo: N18 w/ N100 CPU (-$224), N18 w/ N150 CPU (-$214), or N22 w/ N150 CPU (-$180)&lt;/item&gt;
      &lt;item&gt;16GB of DDR5 RAM (-$39) instead of 32GB.&lt;/item&gt;
      &lt;item&gt;Thermal Right TL-C12015 Slim Fan instead of the Noctua NF-A12x25 (-$26)&lt;/item&gt;
      &lt;item&gt;Apevia SFX-AP500W Power Supply (-$104)&lt;/item&gt;
      &lt;item&gt;Skip the redundancy for the boot pool (-$22)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Altogether, these savings could add up to more than $400, which is pretty considerable! If you made all of these changes, you√¢d have something that√¢s going to be nearly equivalent to the DIY NAS: 2026 Edition but at a fraction of the price.&lt;/p&gt;
    &lt;head rend="h2"&gt;What am I going to do with the DIY NAS: 2026 Edition?!&lt;/head&gt;
    &lt;p&gt;My DIY NAS is aging quite gracefully, but I√¢ve recently been wondering about replacing it. Shortly before ordering all the parts for the DIY NAS: 2026 Edition, I briefly considered using this year√¢s DIY NAS build to replace my personal NAS. However, I decided not to do that. Then prices skyrocketed and I shelved the idea of building a replacement for my own NAS and I nearly shelved the idea of a DIY NAS in 2026!&lt;/p&gt;
    &lt;p&gt;So that begs the question, √¢What is Brian going to do with the DIY NAS: 2026 Edition?√¢&lt;/p&gt;
    &lt;p&gt;I√¢m going to auction it off on the briancmosesdotcom store on eBay! Shortly after publishing this blog, I√¢ll list it on eBay. In response to skyrocketing prices for PC components, I√¢m going to do a no-reserve auction. At the end of the auction, the highest bidder wins, and hopefully they√¢ll get a pretty good deal!&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;Overall, I√¢m pleased with the DIY NAS: 2026 Edition. The Topton N22 motherboard is a significant improvement over last year√¢s Topton N18 motherboard, primarily due to its extra two SATA ports. This provides 33.3% more gross storage capacity.&lt;/p&gt;
    &lt;p&gt;While testing, I found the Intel Core 3 N355 CPU somewhat excessive for basic NAS functions. However, the substantial untapped CPU horsepower offers luxurious performance potential. This makes the build compelling for anyone planning extensive self-hosting projects.&lt;/p&gt;
    &lt;p&gt;I have mixed feelings about the JONSBO N4 case. The four right-side drive bays lack SATA backplane connectivity. Without creative cabling solutions, individual drive replacement becomes challenging. However, the case√¢s ~$125 price point compensates for this inconvenience. I anticipate that those the cost savings will justify the compromise for most builders. If I were to build the DIY NAS: 2026 Edition all over again, I√¢d be tempted to use the JONSBO N3 case or even the JONSBO N6 which isn√¢t quite obtainable, yet.&lt;/p&gt;
    &lt;p&gt;The DIY NAS: 2026 Edition delivers excellent performance and superior specifications. In my opinion, it represents better value than off-the-shelf alternatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QNAP TS-832PX-4G ($880)&lt;/item&gt;
      &lt;item&gt;Asustor Lockerstor 8 AS6508T ($960)&lt;/item&gt;
      &lt;item&gt;UGREEN NASync DXP8800 ($1200)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Building your own NAS provides significant advantages. Years later, you can upgrade RAM, motherboard, case, or add PCI-e (x1) expansion cards. These off-the-shelf alternatives offer severely limited upgrade paths.&lt;/p&gt;
    &lt;p&gt;Is 2026 finally the year that you decide to build your DIY NAS? I hope that it is! Share your experience building your NAS in the comments below, or come tell us about it in the #diynas-and-homelab channel on the Butter, What?! Discord server!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46065034</guid><pubDate>Thu, 27 Nov 2025 02:54:23 +0000</pubDate></item><item><title>Coq: The World's Best Macro Assembler? (2013) [pdf]</title><link>https://nickbenton.name/coqasm.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46065698</guid><pubDate>Thu, 27 Nov 2025 04:34:56 +0000</pubDate></item><item><title>Music eases surgery and speeds recovery, study finds</title><link>https://www.bbc.com/news/articles/c231dv9zpz3o</link><description>&lt;doc fingerprint="adb964f948bf9fcf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Music eases surgery and speeds recovery, Indian study finds&lt;/head&gt;
    &lt;p&gt;Under the harsh lights of an operating theatre in the Indian capital, Delhi, a woman lies motionless as surgeons prepare to remove her gallbladder.&lt;/p&gt;
    &lt;p&gt;She is under general anaesthesia: unconscious, insensate and rendered completely still by a blend of drugs that induce deep sleep, block memory, blunt pain and temporarily paralyse her muscles.&lt;/p&gt;
    &lt;p&gt;Yet, amid the hum of monitors and the steady rhythm of the surgical team, a gentle stream of flute music plays through the headphones placed over her ears.&lt;/p&gt;
    &lt;p&gt;Even as the drugs silence much of her brain, its auditory pathway remains partly active. When she wakes up, she will regain consciousness more quickly and clearly because she required lower doses of anaesthetic drugs such as propofol and opioid painkillers than patients who heard no music.&lt;/p&gt;
    &lt;p&gt;That, at least, is what a new peer-reviewed study from Delhi's Maulana Azad Medical College and Lok Nayak Hospital suggests. The research, published in the journal Music and Medicine, offers some of the strongest evidence yet that music played during general anaesthesia can modestly but meaningfully reduce drug requirements and improve recovery.&lt;/p&gt;
    &lt;p&gt;The study focuses on patients undergoing laparoscopic cholecystectomy, the standard keyhole operation to remove the gallbladder. The procedure is short - usually under an hour - and demands a particularly swift, "clear-headed" recovery.&lt;/p&gt;
    &lt;p&gt;To understand why the researchers turned to music, it helps to decode the modern practice of anaesthesia.&lt;/p&gt;
    &lt;p&gt;"Our aim is early discharge after surgery," says Dr Farah Husain, senior specialist in anaesthesia and certified music therapist for the study. "Patients need to wake up clear-headed, alert and oriented, and ideally pain-free. With better pain management, the stress response is curtailed."&lt;/p&gt;
    &lt;p&gt;Achieving that requires a carefully balanced mix of five or six drugs that together keep the patient asleep, block pain, prevent memory of the surgery and relax the muscles.&lt;/p&gt;
    &lt;p&gt;In procedures like laparoscopic gallbladder removal, anaesthesiologists now often supplement this drug regimen with regional "blocks" - ultrasound-guided injections that numb nerves in the abdominal wall.&lt;/p&gt;
    &lt;p&gt;"General anaesthesia plus blocks is the norm," says Dr Tanvi Goel, primary investigator and a former senior resident of Maulana Azad Medical College. "We've been doing this for decades."&lt;/p&gt;
    &lt;p&gt;But the body does not take to surgery easily. Even under anaesthesia, it reacts: heart rate rises, hormones surge, blood pressure spikes. Reducing and managing this cascade is one of the central goals of modern surgical care. Dr Husain explains that the stress response can slow recovery and worsen inflammation, highlighting why careful management is so important.&lt;/p&gt;
    &lt;p&gt;The stress starts even before the first cut, with intubation - the insertion of a breathing tube into the windpipe.&lt;/p&gt;
    &lt;p&gt;To do this, the anaesthesiologist uses a laryngoscope to lift the tongue and soft tissues at the base of the throat, obtain a clear view of the vocal cords, and guide the tube into the trachea. It's a routine step in general anaesthesia that keeps the airway open and allows precise control of the patient's breathing while they are unconscious.&lt;/p&gt;
    &lt;p&gt;"The laryngoscopy and intubation are considered the most stressful response during general anaesthesia," says Dr Sonia Wadhawan, director-professor of anaesthesia and intensive care at Maulana Azad Medical College and supervisor of the study.&lt;/p&gt;
    &lt;p&gt;"Although the patient is unconscious and will remember nothing, their body still reacts to the stress with changes in heart rate, blood pressure, and stress hormones."&lt;/p&gt;
    &lt;p&gt;To be sure, the drugs have evolved. The old ether masks have vanished. In their place are intravenous agents - most notably propofol, the hypnotic made infamous by Michael Jackson's death but prized in operating theatres for its rapid onset and clean recovery. "Propofol acts within about 12 seconds," notes Dr Goel. "We prefer it for short surgeries like laparoscopic cholecystectomy because it avoids the 'hangover' caused by inhalational gases."&lt;/p&gt;
    &lt;p&gt;The team of researchers wanted to know whether music could reduce how much propofol and fentanyl (an opioid painkiller) patients required. Less drugs means faster awakening, steadier vital signs and reduced side effects.&lt;/p&gt;
    &lt;p&gt;So they designed a study. A pilot involving eight patients led to a full 11-month trial of 56 adults, aged roughly 20 to 45, randomly assigned to two groups. All received the same five-drug regimen: a drug that prevents nausea and vomiting, a sedative, fentanyl, propofol and a muscle relaxant. Both groups wore noise-cancelling headphones - but only one heard music.&lt;/p&gt;
    &lt;p&gt;"We asked patients to select from two calming instrumental pieces - soft flute or piano," says Dr Husain. "The unconscious mind still has areas that remain active. Even if the music isn't explicitly recalled, implicit awareness can lead to beneficial effects."&lt;/p&gt;
    &lt;p&gt;The results were striking.&lt;/p&gt;
    &lt;p&gt;Patients exposed to music required lower doses of propofol and fentanyl. They experienced smoother recoveries, lower cortisol or stress-hormone levels and a much better control of blood pressure during the surgery. "Since the ability to hear remains intact under anaesthesia," the researchers write, "music can still shape the brain's internal state."&lt;/p&gt;
    &lt;p&gt;Clearly, music seemed to quieten the internal storm. "The auditory pathway remains active even when you're unconscious," says Dr Wadhawan. "You may not remember the music, but the brain registers it."&lt;/p&gt;
    &lt;p&gt;The idea that the mind behind the anaesthetic veil is not entirely silent has long intrigued scientists. Rare cases of "intraoperative awareness" show patients recalling fragments of operating-room conversation.&lt;/p&gt;
    &lt;p&gt;If the brain is capable of picking up and remembering stressful experiences during surgery - even when a patient is unconscious - then it might also be able to register positive or comforting experiences, like music, even without conscious memory.&lt;/p&gt;
    &lt;p&gt;"We're only beginning to explore how the unconscious mind responds to non-pharmacological interventions like music," says Dr Husain. "It's a way of humanising the operating room."&lt;/p&gt;
    &lt;p&gt;Music therapy is not new to medicine; it has long been used in psychiatry, stroke rehabilitation and palliative care. But its entry into the intensely technical, machine-governed world of anaesthesia marks a quiet shift.&lt;/p&gt;
    &lt;p&gt;If such a simple intervention can reduce drug use and speed recovery - even modestly - it could reshape how hospitals think about surgical wellbeing.&lt;/p&gt;
    &lt;p&gt;As the research team prepares its next study exploring music-aided sedation, building on earlier findings, one truth is already humming through the data: even when the body is still and the mind asleep, it appears a few gentle notes can help the healing begin.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46065817</guid><pubDate>Thu, 27 Nov 2025 04:55:57 +0000</pubDate></item><item><title>Last Issue of "ECMAScript News"</title><link>https://ecmascript.news/archive/es-next-news-2025-11-26.html</link><description>&lt;doc fingerprint="b894cfdddb577cdb"&gt;
  &lt;main&gt;
    &lt;p&gt;Dear readers!&lt;/p&gt;
    &lt;p&gt;Sadly, we have to inform you that this is the last issue of ‚ÄúECMAScript News‚Äù. We have been operating at a loss for too long: The number of advertisers and subscribers has been slowly but steadily decreasing over the last two years (vs. constant growth before that). Therefore, we made the difficult decision to stop publishing this newsletter.&lt;/p&gt;
    &lt;p&gt;The first issue came out on 2016-09-27. We published a total of 368 issues and are thankful for many loyal readers during many interesting years!&lt;/p&gt;
    &lt;p&gt;Axel may continue this newsletter in some shape or form next year. If he does, he‚Äôll inform you via one last email in 2026.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46066255</guid><pubDate>Thu, 27 Nov 2025 06:14:21 +0000</pubDate></item><item><title>Linux Kernel Explorer</title><link>https://reverser.dev/linux-kernel-explorer</link><description>&lt;doc fingerprint="7391f92da42b0365"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;The kernel isn't a process‚Äîit's the system. It serves user processes, reacts to context, and enforces separation and control.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The Kernel Is Not a Process: It's the always-present authority bridging hardware and software.&lt;/item&gt;
          &lt;item&gt;Serving the Process: Orchestrates syscalls, interrupts, and scheduling to keep user tasks running.&lt;/item&gt;
          &lt;item&gt;System of Layers: Virtual, mapped, isolated, and controlled‚Äîstructure at runtime.&lt;/item&gt;
        &lt;/list&gt;
        &lt;div&gt;
          &lt;head rend="h4"&gt;üìö Study Files&lt;/head&gt;
          &lt;div&gt;
            &lt;p&gt;init/main.c&lt;/p&gt;
            &lt;p&gt;kernel/fork.c&lt;/p&gt;
            &lt;p&gt;include/linux/sched.h&lt;/p&gt;
            &lt;p&gt;arch/x86/kernel/entry_64.S&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;div&gt;
              &lt;p&gt;1. What is the fundamental difference between the kernel and a process?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.The kernel is a special process with elevated privileges&lt;/p&gt;
                &lt;p&gt;B.The kernel is not a process‚Äîit's the system itself that serves processes&lt;/p&gt;
                &lt;p&gt;C.The kernel is just a library that processes link against&lt;/p&gt;
                &lt;p&gt;D.There is no difference; they are the same thing&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;2. How does the kernel primarily serve user processes?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.By running as a background daemon&lt;/p&gt;
                &lt;p&gt;B.By orchestrating syscalls, interrupts, and scheduling&lt;/p&gt;
                &lt;p&gt;C.By providing a GUI interface&lt;/p&gt;
                &lt;p&gt;D.By compiling user code&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;3. What characterizes the kernel's system of layers?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.Physical, tangible, and direct&lt;/p&gt;
                &lt;p&gt;B.Simple and flat with no hierarchy&lt;/p&gt;
                &lt;p&gt;C.Virtual, mapped, isolated, and controlled&lt;/p&gt;
                &lt;p&gt;D.User-accessible and modifiable&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46066280</guid><pubDate>Thu, 27 Nov 2025 06:17:37 +0000</pubDate></item><item><title>Mixpanel Security Breach</title><link>https://mixpanel.com/blog/sms-security-incident/</link><description>&lt;doc fingerprint="35be0cd749786243"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Our response to a recent security incident&lt;/head&gt;
    &lt;p&gt;Out of transparency and our desire to share with our community, this blog post contains key information about a recent security incident that impacted a limited number of our customers. On November 8th, 2025, Mixpanel detected a smishing campaign and promptly executed our incident response processes. We took comprehensive steps to contain and eradicate unauthorized access and secure impacted user accounts. We engaged external cybersecurity partners to remediate and respond to the incident.&lt;/p&gt;
    &lt;p&gt;We proactively communicated with all impacted customers. If you have not heard from us directly, you were not impacted. We continue to prioritize security as a core tenet of our company, products and services. We are committed to supporting our customers and communicating transparently about this incident.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we did in response&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Secured affected accounts&lt;/item&gt;
      &lt;item&gt;Revoked all active sessions and sign-ins&lt;/item&gt;
      &lt;item&gt;Rotated compromised Mixpanel credentials for impacted accounts&lt;/item&gt;
      &lt;item&gt;Blocked malicious IP addresses&lt;/item&gt;
      &lt;item&gt;Registered IOCs in our SIEM platform&lt;/item&gt;
      &lt;item&gt;Performed global password resets for all Mixpanel employees&lt;/item&gt;
      &lt;item&gt;Engaged third-party forensics firm to advise on containment and eradication measures&lt;/item&gt;
      &lt;item&gt;Performed a forensic review of authentication, session, and export logs across impacted accounts&lt;/item&gt;
      &lt;item&gt;Implemented additional controls to detect and block similar activity going forward.&lt;/item&gt;
      &lt;item&gt;Engaged with law enforcement and external cybersecurity advisors&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you should know&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you received a communication from us, please review it for the steps we have taken to secure your account, as well as next steps.&lt;/item&gt;
      &lt;item&gt;If you did not receive a communication from us, no action is required. Your accounts were not impacted.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you have any questions about this incident, please contact support@mixpanel.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46066522</guid><pubDate>Thu, 27 Nov 2025 07:02:40 +0000</pubDate></item><item><title>Ray Marching Soft Shadows in 2D (2020)</title><link>https://www.rykap.com/2020/09/23/distance-fields/</link><description>&lt;doc fingerprint="3fae98912ba42222"&gt;
  &lt;main&gt;
    &lt;p&gt;Disclaimer: the demos on this page use WebGL features that aren‚Äôt available on some mobile devices.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago I tweeted a video of a toy graphics project (below). It‚Äôs not done, but a lot of people liked it which was surprising and fun! A few people asked how it works, so that‚Äôs what this post is about.&lt;/p&gt;
    &lt;p&gt;Under the hood it uses something called a distance field. A distance field is an image like the one below that tells you how far each pixel is from your shape. Light grey pixels are close to the shape and dark grey pixels are far from it.&lt;/p&gt;
    &lt;p&gt;When the demo starts up, it draws some text on a 2D canvas and generates a distance field of it. It uses a library I wrote that generates distance fields really quickly. If you‚Äôre curious how the library works, I wrote about that here.&lt;/p&gt;
    &lt;p&gt;Our lighting scheme works like this: when processing a particular pixel we consider a ray from it to the light, like so‚Ä¶&lt;/p&gt;
    &lt;p&gt;If the ray intersects a glyph, the pixel we‚Äôre shading must be in shadow because there‚Äôs something between it and the light.&lt;/p&gt;
    &lt;p&gt;The simplest way to check this would be to move along the ray in 1px increments, starting from the pixel we‚Äôre shading and ending at the light, repeatedly asking the distance field if we‚Äôre distance 0 from a shape. This would work, but it‚Äôd be really slow.&lt;/p&gt;
    &lt;p&gt;We could pick some specific length like 30px and move in increments of that size, but then we risk jumping over glyphs that are smaller than 30px. We might think we‚Äôre not in shadow when we should be.&lt;/p&gt;
    &lt;p&gt;Ray marching‚Äôs core idea is this: the distance field tells you how far you are from the closest glyph. You can safely advance along your ray by that distance without skipping over any glyphs.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs walk through an example. We start as pictured above and ask the distance field how far we are from any glyph. Turns out in this case that the answer is 95px (pictured left). This means that we can move 95px along our ray without skipping over anything!&lt;/p&gt;
    &lt;p&gt;Now we‚Äôre a little closer to the light. We repeat the process until we hit the ascender of the b! If the b glyph weren‚Äôt there, we‚Äôd have kept going until we hit the light.&lt;/p&gt;
    &lt;p&gt;Below is a demo that shows the ray marching steps for a given pixel. The red box is the pixel we‚Äôre shading, and each circle along the ray represents a ray marching step and the distance from the scene at that step.&lt;/p&gt;
    &lt;p&gt;Try dragging the light and the pixel around to build an intuition for it.&lt;/p&gt;
    &lt;p&gt;Below is GLSL to implement this technique. It assumes you‚Äôve defined a function &lt;code&gt;getDistance&lt;/code&gt; that samples the distance field.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;

float rayProgress = 0;
while (true) {
  if (rayProgress &amp;gt; distance(rayOrigin, lightPosition)) {
    // We hit the light! This pixel is not in shadow.
    return 1.;
  }

  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  rayProgress += sceneDist;
}
&lt;/code&gt;
    &lt;p&gt;It turns out that some pixels are really expensive to process. So in practice we use a for-loop instead of a while loop ‚Äì that way we bail out if we‚Äôve done too many steps. A common ‚Äúslow case‚Äù in ray marching is when a ray is parallel to the edge of a shape in the scene‚Ä¶&lt;/p&gt;
    &lt;p&gt;The approach I‚Äôve described so far will get you a scene that looks like the one below.&lt;/p&gt;
    &lt;p&gt;It‚Äôs cool, but the shadows are sharp which doesn‚Äôt look very good. The shadows in the demo look more like this‚Ä¶&lt;/p&gt;
    &lt;p&gt;One big disclaimer is that they‚Äôre not physically realistic! Real shadows look like hard shadows where the edges have been fuzzed. This approach does something slightly different: all pixels that were previously in shadow are still fully in shadow. We‚Äôve just added a penumbra of partially shaded pixels around them.&lt;/p&gt;
    &lt;p&gt;The upside is that they‚Äôre pretty and fast to compute, and that‚Äôs what I care about! There are three ‚Äúrules‚Äù involved in computing them.&lt;/p&gt;
    &lt;p&gt;Rule 1: The closer a ray gets to intersecting a shape, the more its pixel should be shadowed. In the image below there are two similar rays (their distances to the shape pictured in yellow and green). We want the one that gets closer to touching the corner to be more shadowed.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;sceneDist&lt;/code&gt; tells us how far we are from the closest shape at each ray marching step. So the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the yellow and green lines in the image above.&lt;/p&gt;
    &lt;p&gt;Rule 2: if the pixel we‚Äôre shading is far from the point where it almost intersects a shape, we want the shadow to spread out more.&lt;/p&gt;
    &lt;p&gt;Consider two pixels along the ray above. One is closer to the almost-intersection and is lighter (its distance is the green line). The other is farther and darker (its distance is the yellow line). In general: the further a pixel is from its almost intersection, the more ‚Äúin shadow‚Äù we should make it.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;rayProgress&lt;/code&gt; is the length of the green and yellow lines in the image above.&lt;/p&gt;
    &lt;p&gt;So: we previously returned &lt;code&gt;1.0&lt;/code&gt; for pixels that weren‚Äôt in shadow. To implement rules 1 and 2, we compute &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; on each ray marching step, keep track of its minimum value, and return that instead.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    return lightContribution;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;This ratio feels kind of magical to me because it doesn‚Äôt correspond to any physical value. So let‚Äôs build some intuition for it by thinking through why it might take on particular values‚Ä¶&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;sceneDist / rayProgress &amp;gt;= 1&lt;/code&gt;, then either&lt;code&gt;sceneDist&lt;/code&gt;is big or&lt;code&gt;rayProgress&lt;/code&gt;is small (relative to each other). In the former case we‚Äôre far from any shapes and we shouldn‚Äôt be in shadow, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense. In the latter case, the pixel we‚Äôre shadowing is really close to an object casting a shadow and the shadow isn‚Äôt fuzzy yet, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The ratio is&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;only when&lt;code&gt;sceneDist&lt;/code&gt;is&lt;code&gt;0&lt;/code&gt;. This corresponds to rays that intersect an object and whose pixels are in shadow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And here‚Äôs a demo of what we have so far‚Ä¶&lt;/p&gt;
    &lt;p&gt;Rule #3 is the most straightforward one: light gets weaker the further you get from it.&lt;/p&gt;
    &lt;p&gt;Instead of returning the minimum value of &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; verbatim, we multiply it by a &lt;code&gt;distanceFactor&lt;/code&gt; which is &lt;code&gt;1&lt;/code&gt; right next to the light, &lt;code&gt;0&lt;/code&gt; far away from it, and gets quadratically smaller as you move away from it.&lt;/p&gt;
    &lt;p&gt;All together, the code for the approach so far looks like this‚Ä¶&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    // We hit the light!
    float LIGHT_RADIUS_PX = 800.;

    // fadeRatio is 1.0 next to the light and 0. at
    // LIGHT_RADIUS_PX away.
    float fadeRatio =
      1.0 - clamp(stopAt / LIGHT_RADIUS_PX, 0., 1.);

    // We'd like the light to fade off quadratically instead of
    // linearly.
    float distanceFactor = pow(fadeRatio, 2.);
    return lightContribution * distanceFactor;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;I forget where I found this soft-shadow technique, but I definitely didn‚Äôt invent it. Inigo Quilez has a great post on it where he talks about using it in 3D.&lt;/p&gt;
    &lt;p&gt;Inigo‚Äôs post also talks about a gotcha with this approach that you might have noticed in the demos above: it causes banding artifacts. This is because Rule 1 assumes that the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the distance from a ray to the scene. This is not always true because we sometimes take very few ray marching steps.&lt;/p&gt;
    &lt;p&gt;So in my demo I use an improved approximation that Inigo writes about in his post. I also use another trick that is more effective but less performant: instead of advancing by &lt;code&gt;sceneDist&lt;/code&gt; on each ray marching step, I advance by something like &lt;code&gt;sceneDist * randomJitter&lt;/code&gt; where &lt;code&gt;randomJitter&lt;/code&gt; is between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This improves the approximation because we‚Äôre adding more steps to our ray march. But we could do that by advancing by &lt;code&gt;sceneDist * .3&lt;/code&gt;. The random jitter ensures that pixels next to each other don‚Äôt end up in the same band. This makes the result a little grainy which isn‚Äôt great. But I think looks better than banding‚Ä¶ This is an aspect of the demo that I‚Äôm still not satisfied with, so if you have ideas for how to improve it please tell me!&lt;/p&gt;
    &lt;p&gt;Overall my demo has a few extra tweaks that I might write about in future but this is the core of it. Thanks for reading! If you have questions or comments, let me know on Twitter.&lt;/p&gt;
    &lt;p&gt;_Thank you to Jessica Liu, Susan Wang, Matt Nichols and Kenrick Rilee for giving feedback on early drafts of this post!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46066695</guid><pubDate>Thu, 27 Nov 2025 07:31:24 +0000</pubDate></item><item><title>Arthur Conan Doyle explored men‚Äôs mental health through Sherlock Holmes</title><link>https://scienceclock.com/arthur-conan-doyle-delved-into-mens-mental-health-through-his-sherlock-holmes-stories/</link><description>&lt;doc fingerprint="14c20c733773dfba"&gt;
  &lt;main&gt;
    &lt;p&gt;Note: This article is republished from The Conversation under a Creative Commons license. It includes links to external sites that may earn a commission for purchases. We did not add these links and have kept the original content intact.&lt;/p&gt;
    &lt;p&gt;Arthur Conan Doyle was not just one of the world‚Äôs best crime fiction writers. He was a progressive wordsmith who brought light to controversial and taboo subjects. One of those taboo subjects was male vulnerability and mental health problems ‚Äì a topic of personal significance to the author.&lt;/p&gt;
    &lt;p&gt;Doyle was a vulnerable child. His father, Charles, was an alcoholic, which led to financial troubles in the family. Charles was admitted to an asylum in 1881 and spent the next 12 years in various mental care establishments. So began Doyle‚Äôs interest in male vulnerability and mental health.&lt;/p&gt;
    &lt;p&gt;The character of Sherlock Holmes is a true expression of male vulnerability that does not equate it with weakness. Doyle does not represent Holmes as infallible, but as a man others can relate to ‚Äì he battles with drug addiction, loneliness and depression. His genius thrives in part because of these vulnerabilities, not despite them.&lt;/p&gt;
    &lt;p&gt;Many of Doyle‚Äôs Sherlock Holmes stories examine male characters facing emotional catastrophe, betrayal or moral dilemmas. In works such as The Man with the Twisted Lip (1891), The Adventure of the Engineer‚Äôs Thumb (1892) and The Stockbroker‚Äôs Clerk (1894), Holmes‚Äôs male clients approach him with problems layered with emotional turmoil, fear and failure.&lt;/p&gt;
    &lt;p&gt;In The Man with the Twisted Lip, for example, a man named Neville St Clair hides his double life. He tells his family that he is a respectable entrepreneur going to London on business. In reality he is begging on the city streets. He lives this double life due to fear and shame over the inability to pay off his debts. ‚ÄúIt was a long fight between my pride and the money,‚Äù he explains, ‚Äúbut the dollars won at last.‚Äù&lt;/p&gt;
    &lt;p&gt;Also Read: Who Looks Smarter: The Quick Thinker or the Careful Thinker?&lt;/p&gt;
    &lt;p&gt;‚ÄúI would have endured imprisonment, ay, even execution, rather than have left my miserable secret as a family blot to my children,‚Äù St Clair says. In having his character consider execution to protect his and his family‚Äôs reputation, Doyle explored the societal expectations of Victorian masculinity and how men struggled with such pressures.&lt;/p&gt;
    &lt;p&gt;The Stockbroker‚Äôs Clerk also examines male suicide, as well as economic and professional anxieties. When Holmes reveals the crimes of Harry Pinner, the man attempts suicide rather than face prison.&lt;/p&gt;
    &lt;p&gt;In The Engineer‚Äôs Thumb, hydraulic engineer Victor is treated physically by Watson and mentally by Holmes. As Doyle writes: ‚ÄúRound one of his hands he had a handkerchief wrapped, which was mottled all over with bloodstains. He was young, not more than five-and-twenty, I should say, with a strong masculine face; but he was exceedingly pale and gave me the impression of a man who was suffering from some strong agitation, which it took all his strength of mind to control.‚Äù&lt;/p&gt;
    &lt;p&gt;The physical injury marks Victor as a victim of physical violence. Watson suggests that Victor is using all his mental capabilities to keep calm about his severe pain. Holmes treats Victor‚Äôs mind as he listens to his story: ‚ÄúPray lie down there and make yourself absolutely at home. Tell us what you can, but stop when you are tired, and keep up your strength with a little stimulant.‚Äù&lt;/p&gt;
    &lt;p&gt;Also Read: Study of 3 Million Finnish Adults Finds Non-Voters Tend to Die Earlier&lt;/p&gt;
    &lt;p&gt;Holmes is a protector, a confidante and a comforter in this scene. He provides Victor with breakfast, induces him to lie down and offers him a stimulant (more than likely brandy).&lt;/p&gt;
    &lt;p&gt;The extremity of violence that Victor has endured has escalated to mental trauma. In having Holmes treat Victor‚Äôs mental trauma while Watson treats his physical pain, Doyle showed the importance psychological support for men of the age.&lt;/p&gt;
    &lt;p&gt;Holmes was a highly popular character. To contemporary readers, his drug use and dysfunctional clients were seen as markers of his genius rather than a reflection of the significant social issues that men faced during this period. But today, they offer a window into the mental struggles of Victorian men, and a point of connection between readers of the past and present.&lt;/p&gt;
    &lt;p&gt;Looking for something good? Cut through the noise with a carefully curated selection of the latest releases, live events and exhibitions, straight to your inbox every fortnight, on Fridays. Sign up here.&lt;/p&gt;
    &lt;p&gt;This article features references to books that have been included for editorial reasons, and may contain links to bookshop.org. If you click on one of the links and go on to buy something from bookshop.org The Conversation UK may earn a commission.&lt;/p&gt;
    &lt;p&gt;Emma Linford, Honorary research associate, English literature, University of Hull&lt;/p&gt;
    &lt;p&gt;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46068015</guid><pubDate>Thu, 27 Nov 2025 10:54:02 +0000</pubDate></item><item><title>The State of GPL Propagation to AI Models</title><link>https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/</link><description>&lt;doc fingerprint="2d531d13953a0592"&gt;
  &lt;main&gt;
    &lt;p&gt;When GitHub Copilot was launched in 2021, the fact that its training data included a vast amount of Open Source code publicly available on GitHub attracted significant attention, sparking lively debates regarding licensing. While there were issues concerning conditions such as attribution required by most licenses, there was a particularly high volume of discourse suggesting that the conditions of copyleft licenses, such as the GNU General Public License (GNU GPL), would propagate to the model itself, necessitating that the entire model be released under the same license. The propagation of the GPL is a concept that many modern software engineers have naturally accepted; thus, for an engineer with a straightforward sensibility, it is a perfectly natural progression to think that if GPL code is included in some form, copyleft applies and the license propagates.&lt;/p&gt;
    &lt;p&gt;However, as of 2025, the theory that the license of the source code propagates to AI models trained on Open Source code is not seen as frequently as it was back then. Although some ardent believers in software freedom still advocate for such theories, it appears they are being overwhelmed by the benefits of AI coding, which has overwhelmingly permeated the programming field. Amidst this trend, even I sometimes succumb to the illusion that such a theory never existed in the first place.&lt;/p&gt;
    &lt;p&gt;Has the theory that the license of training code propagates to such AI models been completely refuted?&lt;/p&gt;
    &lt;p&gt;Actually, it has not. This issue remains an indeterminate problem where lawsuits are still ongoing and the judgments of major national governments have not been made clear. In this article, I will explain the current situation of this license propagation theory, namely ‚ÄúGPL propagates to AI models trained on GPL code,‚Äù and connect it to points of discussion such as the legal positioning of models and the nature of the freedom we pursue in the AI domain.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Current Standing in Two Lawsuits&lt;/item&gt;
      &lt;item&gt;Arguments Negating the Theory of License Propagation to Models&lt;/item&gt;
      &lt;item&gt;The Stance of OSI and FSF&lt;/item&gt;
      &lt;item&gt;Summary&lt;/item&gt;
      &lt;item&gt;References&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: This article is an English translation of a post originally written in Japanese. While it assumes a Japanese reader, I believe it may also be useful for an English-speaking audience.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Current Standing in Two Lawsuits&lt;/head&gt;
    &lt;p&gt;First, let us organize what the ‚ÄúGPL propagation theory to AI models‚Äù entails. This is the idea that when an AI model ingests GPL code as training data, the model itself constitutes a derivative work (derivative) of the GPL code; therefore, when distributing the model, the copyleft conditions of the GPL, such as the obligation to disclose source code, apply. In other words, it is not a question of whether the output of the model is similar to the GPL code, but a theory that ‚Äúsince the model itself is a derivative containing GPL code, the GPL extends to the model.‚Äù While there were many voices supporting this theory around 2021, as mentioned earlier, it is no longer the mainstream of the discussion today. However, two major ongoing lawsuits can be cited as grounds that this theory has not been completely denied. These are Doe v. GitHub (the Copilot class action) filed in the United States and GEMA v. OpenAI filed in Germany. I will explain the history and current status of each lawsuit below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Doe v. GitHub (Copilot Class Action): The Persisting Claim of Open Source License Violation&lt;/head&gt;
    &lt;p&gt;In the Copilot class action filed at the end of 2022 in relation to GitHub Copilot, anonymous developers became plaintiffs and argued that GitHub, Microsoft, and OpenAI trained their models on source code from public repositories without permission, inviting massive license violations through Copilot. Specifically, they viewed it as problematic that when Copilot reproduces part of the code that served as the training source in its output, it does not perform the author attribution or copyright notice required by licenses such as MIT or Apache-2.0 at all, and furthermore, it indiscriminately trains on and outputs code under licenses that impose copyleft conditions like the GPL, thereby trampling on license clauses. The plaintiffs claimed this was a contractual violation of open source licenses and also sought damages and injunctions, asserting that it constituted a violation of the Digital Millennium Copyright Act (DMCA) under copyright law.&lt;/p&gt;
    &lt;p&gt;In this case, several decisions have already been handed down by the United States District Court for the Northern District of California, and many of the plaintiffs‚Äô claims have been dismissed. What were dismissed were mainly peripheral claims such as DMCA clause violations, privacy policy violations, unjust enrichment, and torts, but some DMCA violations and the claim of ‚Äúviolation of open source licenses‚Äù (breach of contract) are still alive. Regarding the latter specifically, the argument is that despite the plaintiffs‚Äô code being published under licenses like GPL or MIT, the defendants failed to comply with the author attribution or the obligation to publish derivatives under the same license, which constitutes a contractual violation. Although the court did not recognize claims for monetary damages because the plaintiffs could not demonstrate a specific amount of damage, it determined that there were sufficient grounds for the claim for injunctive relief against the license violation itself. As a result, the plaintiffs are permitted to continue the lawsuit seeking an order prohibiting the act of Copilot reproducing others‚Äô code without appropriate license indications.&lt;/p&gt;
    &lt;p&gt;As is clear from the above history, ‚Äúviolation of open source licenses in training data‚Äù is still being contested in court in the Copilot litigation, and this is one of the reasons why the theory of license propagation to models has not been completely denied. The plaintiffs‚Äô claim in this lawsuit does not directly demand the release of the model itself under the GPL, but it legally pursues the point that license conditions were ignored in the process of training and output; consequently, it suggests that ‚Äúif the handling does not follow the license of the training data, the act of providing the model could be illegal.‚Äù Furthermore, the court has not clearly rejected this logic at this stage and has indicated a judgment that the use of open source code is accompanied by license obligations, and providing tools that ignore this could constitute a tort subject to injunction.&lt;/p&gt;
    &lt;p&gt;However, it is necessary to note that the claims in the Copilot litigation are legally framed as breach of contract (license) or DMCA violation, and are not a direct copyright argument that ‚Äúthe model is a derivative work of GPL code.‚Äù No judgment has been shown stepping so far as to mandate the disclosure of the entire model under the GPL license. The actual judgment is conservative, stating ‚Äúmonetary damages have not been shown, but there is room for future injunctive relief,‚Äù and does not mention the obligation to disclose the model itself. In other words, at present, there is no judicial precedent directly addressing the ‚ÄúGPL propagation theory to models,‚Äù and the situation is one where the issue raised regarding license violation of the source code remains alive in the judicial arena.&lt;/p&gt;
    &lt;head rend="h3"&gt;GEMA v. OpenAI: The Theory Treating ‚ÄúMemory‚Äù in Models as Legal Reproduction&lt;/head&gt;
    &lt;p&gt;Another important lawsuit is the case where the German music copyright collective GEMA sued OpenAI. This is a copyright lawsuit concerning the unauthorized training and output of lyrics by an AI model, not AI code generation, but it carries significant theoretical implications related to ‚Äúlicense propagation to models‚Äù even if not directly related to GPL.&lt;/p&gt;
    &lt;p&gt;In November 2025, the Munich I Regional Court handed down a judgment on this lawsuit, indicating regarding the matter where the ChatGPT model had memorized and reproduced the lyrics of 9 famous German songs, that the act of ‚Äúmemory‚Äù inside the model itself falls under the act of reproduction under copyright law. According to the judgment, the lyrics under the plaintiff‚Äôs management were ‚Äúfixed‚Äù in the models of ChatGPT‚Äôs GPT-4 and 4o, and the situation was such that the lyrics were output almost verbatim just by the user giving a simple prompt. Based on this, the court determined that the model contains ‚Äúparameters that memorized the work‚Äù internally, and if it is possible to reproduce an expression substantially identical to the original work for a human by means of an appropriate prompt, that memory itself falls under ‚Äúreproduction‚Äù in Article 16 of the German Copyright Act. Furthermore, it determined that the act of actually outputting lyrics in response to a prompt is also a separate act of reproduction, and providing lyrics to the user falls under the act of making available to the public (public transmission). Also, it ruled that since all of these are done without the permission of the rights holder, they deviate from the scope justified by the TDM (Text and Data Mining) exception in the EU DSM Copyright Directive.&lt;/p&gt;
    &lt;p&gt;The important point of this judgment is that it clearly acknowledged that ‚Äúif a work is recorded inside the model in a reproducible form, that state itself can constitute copyright infringement.‚Äù The court cited the text of the EU InfoSoc Directive that ‚Äúreproduction includes copies in any form or manner, and does not need to be directly perceptible to humans,‚Äù and stated that in the spirit of this, even if the lyrics are encoded within the model‚Äôs parameters, it amounts to the creation of a reproduction. It went as far as to mention that ‚Äúencoding in the form of probabilistic weights does not prevent it from being considered a copy,‚Äù showing a strong recognition that differences in technical formats cannot avoid the nature of reproduction under copyright law. Also, since the fact that the model could output the lyrics was not coincidental but highly consistent, it was factually found that ‚Äúthe direct incorporation of the essential part of the training data‚Äù occurred rather than the result of statistical learning. As a result, the Munich District Court recognized OpenAI‚Äôs liability for injunction and damages regarding the output act of the lyrics in question, and further ordered the provision of information regarding training data and output content for the future. However, this judgment is the first instance, and since OpenAI has indicated an intention to appeal, it is expected to be a continuing dispute.&lt;/p&gt;
    &lt;p&gt;The noteworthy theory shown by this GEMA judgment is the extension of the concept of reproduction under copyright law to the interior of the model. That is, if the work used as training data remains within the model and can be reproduced with a simple operation, it means the model already contains a reproduction of that work. This theory is groundbreaking in that it deems ‚Äúthe model contains the source work,‚Äù and indeed, in a commentary by Osborne Clarke, it is evaluated that ‚Äúin contrast to the judgment of the English High Court in the Getty v. Stability AI case, the Munich District Court explicitly recognized the possibility that the AI model contains copies of the training material.‚Äù Standing on this view, the model is not merely a result of analysis, but depending on the case, can be evaluated as an aggregate of the training data itself.&lt;/p&gt;
    &lt;p&gt;However, it is necessary to keep in mind that this judgment is based on an extreme case where a complete match output was obtained with short text such as lyrics. The court itself stated, ‚ÄúNormally, temporary reproduction for learning remains within the purpose of analysis and does not infringe on the rights holder‚Äôs market, but in this case, the model holds the work in a restorable form and exceeds the scope of analysis,‚Äù emphasizing that the judgment is limited to ‚Äúcases where the model performs complete reproduction.‚Äù Also, as the UK case shows, judicial decisions vary by country, and a legal consensus on this issue has not yet been formed.&lt;/p&gt;
    &lt;p&gt;Nevertheless, the judgment this time, which declared that the recording of a work inside a model is a reproduction, can become a major basis supporting the license propagation theory. This is because, while the premise for discussing GPL propagation is ‚Äúwhether the model can be said to be a reproduction or derivative work of the GPL code,‚Äù the logic of the Munich District Court legally certified exactly that ‚Äúa model can be a reproduction of training data‚Äù.&lt;/p&gt;
    &lt;head rend="h3"&gt;Possibilities Derived from the Current Status of the Two Lawsuits&lt;/head&gt;
    &lt;p&gt;From the two lawsuits above, we can consider the path through which the theory of license propagation to AI models might be recognized in the future.&lt;/p&gt;
    &lt;p&gt;Let us assume the worst-case scenario from the perspective of AI operators, where these lawsuits are finalized with the plaintiffs winning. In the Copilot litigation, the judgment that ‚Äúmodel providers must comply with the license conditions of the training source code‚Äù would be established, and in the GEMA litigation, the legal principle that ‚Äúthe model encompasses reproductions of the work‚Äù would be established. When these two intersect, the conclusion that ‚Äúsince an AI model containing GPL code is a reproduction or derivative work of the GPL code, the conditions of the GPL directly apply to its provision‚Äù is theoretically derived. That is, the possibility emerges that the theory of GPL propagation to models is effectively ratified by the judiciary.&lt;/p&gt;
    &lt;p&gt;Specifically, if the model memorizes and contains GPL code fragments internally, the act of distributing or providing that model to a third party may be regarded as the distribution of a reproduction of GPL code; in that case, the act of distribution under conditions other than GPL would be evaluated as a GPL license violation. If a GPL violation is established, there would be room to argue for remedies such as injunctions and claims for damages, as well as forced GPL compliance demanding the disclosure of the entire model under the same license, just as in the case of ordinary software. In fact, the remedies GEMA sought from OpenAI included disclosure regarding training data and output content, and although this is in the context of musical works, this can be said to be a type of disclosure request to make transparent ‚Äúwhat the model learned and contains.‚Äù In the case of a GPL violation as well, the possibility cannot be denied that demands such as ‚Äúdisclosure of the GPL code parts contained inside the model‚Äù or ‚Äúsource disclosure in a form that allows reconstruction of the model‚Äù would emerge in seeking license compliance.&lt;/p&gt;
    &lt;p&gt;Even if not reaching such an extreme conclusion, an intermediate scenario could involve imposing certain restrictions on model providers. For example, the Copilot litigation might be settled or judged by taking measures such as ‚Äúattaching a license and author attribution at the time of output if existing code of a certain length or more is included in the generated code,‚Äù or technically mandating the implementation of filters so that GPL code fragments are not extracted or reproduced from the model. In fact, GitHub, the developer of Copilot, has already introduced an optional feature that ‚Äúexcludes from suggestions if the candidate code matches existing code on large-scale repositories,‚Äù attempting to reduce litigation risk. Also regarding OpenAI, there are reports that it strengthened filters so that ChatGPT does not output copyrighted lyrics as they are, in response to the GEMA judgment.&lt;/p&gt;
    &lt;p&gt;While these are not license propagation itself legally, in practice, they indicate that the industry is steering in the direction of ‚Äúensuring the model does not potentially infringe license conditions.‚Äù In the future, there is a possibility that guidelines for excluding data with specific license terms like GPL at the model training stage, or mechanisms and systems to guarantee that there is no license-infringing output by conducting output inspections after training, will be established.&lt;/p&gt;
    &lt;p&gt;In any case, until these two lawsuits are completely settled and the subsequent legislative response is determined, the ‚Äútheory of GPL propagation to models‚Äù has not completely disappeared. It is a scenario that could suddenly become realistic depending on future judgments, and even if the plaintiffs lose in the lawsuits, there is a possibility that support for this theory will reignite within the open source community. It is necessary to note that while it is currently an ‚Äúundetermined theory not shouted as loudly as before,‚Äù that does not mean it has been legally completely denied and resolved. As our community, we need to carefully consider countermeasures while observing these trends and taking into account the legal systems of each country and opposing arguments described in the latter half of this article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Treatment under Japanese Law&lt;/head&gt;
    &lt;p&gt;Based on the trends of the overseas lawsuits mentioned above, I will also organize the relationship between AI models, copyrighted works, and licenses under Japanese law. In Japan, Article 30-4 of the Copyright Act, introduced by the 2018 amendment, exists as a provision that comprehensively legalizes reproduction acts associated with machine learning. Furthermore, in March 2024, the Copyright Division of the Council for Cultural Affairs of the Agency for Cultural Affairs published a guideline-like document titled ‚ÄúThought on AI and Copyright‚Äù (hereinafter ‚Äúthe Thought‚Äù), presenting a legal organization divided into the development/training stage and the generation/utilization stage of generative AI.&lt;/p&gt;
    &lt;p&gt;According to ‚Äúthe Thought,‚Äù reproduction performed basically for the purpose of AI training is legal as long as it satisfies ‚Äúinformation analysis not for the purpose of enjoying the thoughts or sentiments expressed in the work‚Äù as defined in Article 30-4. Therefore, acts of collecting and reproducing a wide range of data from the internet to create a training dataset for research and development purposes can be done without the permission of the rights holders in principle. However, what is important is whether an ‚Äúpurpose of enjoyment‚Äù is mixed into that training act. ‚ÄúThe Thought‚Äù states that if training is conducted with the purpose of ‚Äúintentionally reproducing all or part of the creative expression of a specific work in the training data as the output of generative AI,‚Äù it is evaluated as having a concurrent purpose of enjoying the work rather than mere information analysis, and thus lacks the application of Article 30-4. As a typical example of this, ‚Äúoverfitting‚Äù is cited, and acts such as making a model memorize specific groups of works through additional training to cause it to output something similar to those works are judged to have a purpose of enjoyment.&lt;/p&gt;
    &lt;p&gt;Furthermore, ‚Äúthe Thought‚Äù also mentions the legal treatment of trained models, stating first that ‚Äútrained models created by AI training cannot be said to be reproductions of the works used for training in many cases.‚Äù This is the view that since the model can generate outputs unrelated to the original in response to various inputs in a general-purpose manner, the model itself is not a copy of any specific work.&lt;/p&gt;
    &lt;p&gt;However, ‚Äúthe Thought‚Äù simultaneously acknowledges the possibility that, exceptionally, in cases where ‚Äúthe trained model is in a state of generating products with similarity to the work that was training data with high frequency,‚Äù the creative expression of the original work remains in the model, and it may be evaluated as a reproduction. It also points out that in such cases, the model is positioned as a machine for copyright infringement, and a claim for injunction may be recognized. In short, usually the model is merely statistical data and not the work itself, but if it has turned into a device for spewing out specific works almost as they are, it can be treated as an infringing item; this thinking shares parts with the content of the GEMA judgment.&lt;/p&gt;
    &lt;p&gt;It is necessary to note that the above organization is strictly a discussion of the scope of application of rights limitation provisions (exception provisions) under the Copyright Act, and does not touch upon the validity of contracts or license clauses. The Agency for Cultural Affairs document discusses from the perspective of ‚Äúwhether it is copyright infringement or not,‚Äù and does not deny that even if the training act is legal, contractual liability may arise if it violates terms of service or open source licenses separately. Also, no in-depth view has been shown regarding the propagation of copyleft clauses like the GPL. In Japan‚Äôs Copyright Act, there is no override provision where rights limitation provisions like Article 30-4 take precedence over contract conditions, and the ‚ÄúContract Guidelines on Utilization of AI and Data‚Äù by the Ministry of Economy, Trade and Industry suggests the possibility that if there is a contract prohibiting data use between parties, that contract takes precedence.&lt;/p&gt;
    &lt;p&gt;Therefore, if the license is regarded as a valid contract, even if ‚Äútraining is legal‚Äù under Article 30-4 of the Copyright Act, the risk remains that it becomes a ‚Äúviolation of license conditions‚Äù under contract law, and it can be said that at least there is no official view organizing the theory of GPL propagation to models. In other words, currently, while the legality of model training acts is recognized quite broadly under the Copyright Act, license violation is left to general civil theory, and there is no clear guideline on, for example, ‚Äúwhether the act of publicly distributing a model trained on GPL code constitutes a GPL license violation.‚Äù Overall, the legal organization in Japan is in a situation of ‚Äúsafe in principle at the copyright layer, but blank at the contract layer.‚Äù Hence, the discussion in Japan regarding the theory of GPL propagation to models relies on future judicial judgments and legislative trends, and at present, there is no choice but to consider operational guidelines carefully following the organization by the Agency for Cultural Affairs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Arguments Negating the Theory of License Propagation to Models&lt;/head&gt;
    &lt;p&gt;As seen in the previous sections, the theory of GPL propagation to models is not legally zero. However, many legal experts and engineers point out that this theory has serious detrimental effects. Here, I present representative arguments negating the theory of license propagation to models from the layers of copyright law, GPL text, technology, and practical policy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the Copyright Law Layer&lt;/head&gt;
    &lt;p&gt;First, under copyright law, it is unreasonable to regard an AI model as a ‚Äúderivative work‚Äù or ‚Äúreproduction‚Äù of the training source works. In many cases, the expressions of specific works are not stored inside the model in a form recognizable to humans. The model merely holds statistical abstractions where text and code have been converted into weight parameters, and that itself is not a creative expression to humans at all. A ‚Äúderivative work‚Äù under copyright law refers to a creation that incorporates the essential features of the expression of the original work in a form that can be directly perceived, but one cannot directly perceive the creativity of the original code from the model‚Äôs weights. In other words, the model does not show the nature of a work directly enough to be evaluated as encompassing the original code. For example, the High Court of Justice in the UK stated in the judgment of the Getty v. Stability AI case that ‚Äúthe Stable Diffusion model itself is not an infringing copy of the training images,‚Äù showing a negative view on regarding the model itself as a reproduction of works. Thus, there are many cautious positions internationally regarding regarding the model itself as an accumulation of works or a compilation work.&lt;/p&gt;
    &lt;p&gt;Also, the output generated by the model involves probabilistic and statistical transformations, and in many cases, things that do not resemble the training source at all are output. Even if a match or similarity occurs by chance, it is difficult to prove whether it is a reproduction relying on the original or an accidental similarity. It is not realistic to conduct the certification of reliance and similarity required to discuss copyright infringement for the entire model. Ultimately, in the framework of copyright law, there is no choice but to judge ‚Äúwhether the model relies on a specific work‚Äù on a work-by-work basis, and recognizing uniform copyrightability or infringing nature for the model itself is a large leap. As organized in Japanese law where the model is not considered a reproduction in most cases, the schematic of model equals work is considered unreasonable under copyright law.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the GPL Text Layer&lt;/head&gt;
    &lt;p&gt;Next, looking at the license text and intent of the GPL itself, doubts are cast on the interpretation that GPL propagates to AI models. For example, in the text of GPLv2, the target of copyleft is limited to ‚Äúderivative works‚Äù of the original code provided under GPL and ‚Äúworks that contain the Program.‚Äù Typically, this has been interpreted as software created by modifying or incorporating GPL code, or software combined (linked) with GPL code. In the case of an AI model, it is extremely unclear which part of the original GPL code the model ‚Äúcontains.‚Äù Even if the model could memorize fragments of the GPL code used for training, it is a tiny fraction when viewed from the entire model, and most parts are occupied by parameters unrelated to the GPL code. There is no clear assumption shown by the GPL drafters as to whether a statistical model that may partially encapsulate information derived from GPL code can be said to be ‚Äúa work containing the Program‚Äù.&lt;/p&gt;
    &lt;p&gt;Furthermore, GPLv3 requires the provision of software source code in a ‚Äúpreferred form for modification.‚Äù If an AI model is a GPL derivative, the problem arises as to what that preferred form for modification would be. The model weights themselves have low readability and editability for humans, and are hard to call a ‚Äúpreferred form for modification.‚Äù If we ask whether the training data is the source code, the original trained GPL code itself cannot be said to be the source of the model, nor is it clear if it refers to the entire vast and heterogeneous training dataset. It is difficult to define what should be disclosed to redistribute the model under GPL compliance, and it could lead to an extreme conclusion that all code and data used for model training must be disclosed. While this is what some freedom believers aim for, it can only be said to be unrealistic in reality, and it deviates from the point of the GPL‚Äôs intent to enable users to modify and build from source. Thus, existing GPL provisions are not designed to directly cover products like AI models, and forcing their application causes discrepancies in both text and operation.&lt;/p&gt;
    &lt;p&gt;In fact, in the ‚ÄúOpen Source AI Definition‚Äù compiled by the OSI (Open Source Initiative) in 2023, regarding ‚Äúinformation necessary for modification‚Äù of the model, it stopped at stating that sufficiently detailed information about the training data should be disclosed, and did not require the provision of the training data itself in its entirety. Also, it states that model weights and training code should be published under OSI-approved licenses.&lt;/p&gt;
    &lt;p&gt;In addition, the FSF (Free Software Foundation) itself does not believe that the current GPL interpretation alone can guarantee freedom in the AI domain, and announced in 2024 that it has started formulating ‚Äúconditions for machine learning applications to be free.‚Äù There, the directionality is shown that ‚Äúthe four freedoms should be guaranteed to users including not only software but also raw training data and model parameters,‚Äù but this conversely is a recognition that this is not guaranteed under current licenses. The FSF also points out that ‚Äúsince model parameters cannot be said to be source comprehensible to humans, modification through retraining is more realistic than direct editing,‚Äù and can be said to be cautious about treating models on the extension of existing GPL. Overall, claiming GPL propagation univocally to AI models that fall outside the wording and assumptions of GPL provisions is unreasonable from the perspective of interpretation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the Technical Layer&lt;/head&gt;
    &lt;p&gt;There are also strong counterarguments from a technical perspective against the theory of GPL propagation to models. AI models, particularly those called large language models, basically hold huge statistical trends internally and do not store the original code or text as they are like a database. Returning a specific output for a specific input is merely generation according to a probability distribution, and it is not guaranteed that the same output as the training data is always obtained. If the model does not perform verbatim reproduction of training data except for a very small number of exceptional cases, evaluating it as ‚Äúcontaining GPL code‚Äù within the model does not fit the technical reality. In fact, the OpenAI side argued in the GEMA lawsuit that ‚Äúthe model does not memorize individual training data, but merely reflects knowledge learned from the entire dataset in parameters.‚Äù This argument was not accepted by the Munich District Court, but that was because there was a clear example of lyric reproduction; conversely, unless there is a clear example of reproduction, the view would be that ‚Äúthe model is a lump of statistical knowledge‚Äù.&lt;/p&gt;
    &lt;p&gt;Furthermore, although it has been confirmed that models can output fragments of training data, that proportion is considered extremely limited when viewed from the whole. Regarding the whole as a reproduction based on the existence of partial memory is like claiming the whole is a reproduction of a photograph just because it contains a tiny mosaic-like fragment in an image, which is an excessive generalization. Technically, it is difficult to quantitatively measure how far specific parameters of the model retain the influence of the original data, and the correspondence between the model and training data remains statistical and difficult to draw a line. Therefore, criteria such as ‚Äúhow similar must it be for GPL to propagate?‚Äù cannot be established in the first place. The judgment of infringement or not has to be done on an individual output basis, and this would not be consistent with the idea of applying a single license to the entire model. From the technical aspect, since the model is basically a statistical transformation and the majority is unrelated to GPL code, applying GPL collectively can be said to be irrational.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical and Policy Arguments for Negation&lt;/head&gt;
    &lt;p&gt;Finally, major demerits can be pointed out regarding the theory of license propagation to models from practical and policy perspectives. What would happen if this GPL propagation theory were legally recognized? As an extreme example, if 1 million code repositories were used for training a certain large-scale model, all the various licenses contained in them (GPL, MIT, Apache, proprietary, etc.) would ‚Äúpropagate‚Äù to the model, and the model provider would have to distribute the model in a form that complies with all 1 million license clauses. As a practical matter, there would be combinations where conditions contradict, such as GPLv2 and Apache-2.0, and attaching and managing a huge collection of copyright notices for one model is nothing but unrealistic. Applying all licenses to an AI model created from training data with mixed licenses is practically bankrupt, and eventually, the only thing that can be done to avoid it would be to exclude code with copyleft licenses like GPL from the training data from the start.&lt;/p&gt;
    &lt;p&gt;Is such a situation really desirable for our community? The spirit of the GPL is to promote the free sharing and development of software. However, if asserting excessive propagation to AI models causes companies to avoid using GPL code, and as a result, the value held by GPL software is not utilized in the AI era, it would be putting the cart before the horse. In the field of software development, many companies take a policy of not mixing GPL code into their own products, but similarly, if it becomes ‚Äúdo not include GPL in our AI training data,‚Äù GPL projects could lose value as data sources. Furthermore, the current legal battles surrounding AI are leaning more towards monetary compensation and regulatory rule-making, and the reality is that they are proceeding in a different vector from the direction of code sharing idealized by GPL. If only the theory of GPL propagation to models walks alone, in reality, only data exclusion and closing off to avoid litigation risks will progress, and there is a fear that it will not lead to the expansion of free software culture.&lt;/p&gt;
    &lt;p&gt;Policy-wise as well, governments of each country are carefully considering the use of copyrighted works in AI, but at present, there is no example establishing an explicit rule that ‚Äúlicense violation of training data generates legal liability for the model.‚Äù Even in the EU AI Act, while there are provisions regarding the quality and transparency of training data, it does not demand compliance with open source licenses. Rather, from the perspective of promoting open science and innovation, the movement to allow text and data mining under rights limitations is strong. In Japan as well, as mentioned earlier, the direction is to broadly recognize information analysis use under Article 30-4, and the policy of forcibly applying licenses to AI models is not mainstream in current international discussions.&lt;/p&gt;
    &lt;p&gt;Based on the above, the theory of license propagation to models is highly likely to cause disadvantages to open source on both practical and policy fronts, and can be said not to be a realistic solution. What is important is how to realize the ‚Äúfreedom of software,‚Äù which is the philosophy of open source, in the AI era; the opinion that this should be attempted through realistic means such as ensuring transparency and promoting open model development rather than extreme legal interpretations is potent, and this is something I have consistently argued as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Stance of OSI and FSF&lt;/head&gt;
    &lt;p&gt;I will also organize what stance major organizations in the open source (and free software) community are currently taking in relation to the theory of GPL propagation to AI models. Representative organizations are the Open Source Initiative (OSI) and the Free Software Foundation (FSF); while they share the goal of software freedom, they do not necessarily take the same approach regarding AI models and training data.&lt;/p&gt;
    &lt;p&gt;First, the OSI formulated the ‚ÄúOpen Source AI Definition‚Äù (OSAID) in 2024, defining the requirements for an AI system to be called open source. This definition states that the four freedoms (use, study, modify, redistribute) similar to software should be guaranteed for AI systems as well, and defines requirements regarding ‚Äúforms necessary for modification‚Äù to realize that, requiring the disclosure of the following three elements.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data Information: Provide sufficiently detailed information about the data used for training so that a skilled person can reconstruct an equivalent model. &lt;list rend="ul"&gt;&lt;item&gt;This does not make publishing the training data itself in its entirety mandatory, but requires disclosing the origin, scope, nature, and acquisition method if there is data that cannot be published, listing data that can be published, and providing information on data available from third parties.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Code: Publish the complete set of source code for training and running the model under an OSI-approved license.&lt;/item&gt;
      &lt;item&gt;Parameters: Publish the model weights (parameters) under OSI-approved conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It should be noted that while OSI states that information regarding the code used for training and training data is indispensable in addition to model weights to realize ‚ÄúOpen Source AI,‚Äù it does not require the complete disclosure of the training data itself. This is a flexible stance that, for example, if raw data cannot be published due to privacy or confidentiality, explaining the nature of the data by clarifying that fact can substitute. Also, the legal mechanism to ensure free use of model parameters is an issue to be clarified in the future, and at present, no conclusion has been reached on legal rights control (e.g., presence or absence of copyrightability) over parameters either.&lt;/p&gt;
    &lt;p&gt;As can be read from these, the OSI promotes opening up AI models at the level of the open source definition in principle, but keeps the handling of training data to requirements at the information disclosure level. Thereby, it can be said that the OSI avoids adopting the theory of license propagation to models to demand training data disclosure, and is exploring a realistic solution that first guarantees transparency and reproducibility. In principle, it could be said that the OSI denied the GPL propagation theory at the time of publishing the OSAID definition. Note that I am probably the one who sealed the mandatory argument for training data in the final stage of this definition‚Äôs formulation process, and I believe this was the correct judgment.&lt;/p&gt;
    &lt;p&gt;On the other hand, the FSF and FSF Europe (FSFE) take a stance more faithful to fundamental principles. FSFE declared as of 2021 that ‚Äúfor an AI application to be free, both its training code and training data must be published under a free software license.‚Äù That is, to modify or verify the model, one must be able to obtain it including the training data, and therefore both must be free. Also, the FSF itself stated in a 2024 statement, ‚ÄúUnder current understanding, for an ML application to be called free, all training data and the scripts processing it must satisfy the four freedoms,‚Äù trying to extend the requirements of freedom to data. Thus, FSF/FSFE stands on the position that a model with undisclosed training data is unfree as a whole even if the software part is free.&lt;/p&gt;
    &lt;p&gt;However, the FSF simultaneously states to the effect that ‚Äúwhether a non-free machine learning application is ethically unjust depends on the case,‚Äù mentioning that there can be ‚Äúlegitimate moral reasons‚Äù for not being able to publish training data (personal information) of a medical diagnosis AI, for example. In that case, it implies that although that AI is non-free, its use might be ethically permitted due to social utility. One can see an attitude of seeking a compromise between the FSF‚Äôs ideal and reality here, but in any case, there is no mistake that the FSF ultimately aims for freedom including training data.&lt;/p&gt;
    &lt;p&gt;So, does the FSF support the theory of GPL propagation to AI models? Not necessarily. Their claim is closer to an ethical standard or ideal image rather than legal enforceability, and they are not arguing that it applies to models as an interpretation of the current GPL license. Rather, as mentioned before, they are at the stage of trying to create new standards and agreements. Even in the white paper on the Copilot issue funded by the FSF, while legal points such as copyright and license violation are discussed, substantially it has a strong aspect of being told as a GPL compliance problem for users (downstream developers) concerned that they bear the risk of GPL violation if Copilot‚Äôs output contains GPL code fragments. This is a caution to developers using AI coding tools rather than GPL application to the model itself, and is different from an approach forcing GPL compliance directly on model providers.&lt;/p&gt;
    &lt;p&gt;The Software Freedom Conservancy (SFC) naturally has a strong interest in this issue but is also cautious in some respects. The SFC started the protest campaign ‚ÄúGive Up GitHub‚Äù against GitHub in 2022, condemning Copilot‚Äôs methods as contrary to the philosophy of open source, and is also involved in the Copilot class action. However, in an SFC blog post, regarding this lawsuit, it showed concern about ‚Äúthe risk of interpretations deviating from the principles of the open source community being brought in,‚Äù and called on the plaintiffs‚Äô side to comply with community-led GPL enforcement principles as well. The SFC also states that Copilot‚Äôs act is an ‚Äúunprecedented license violation,‚Äù and while not fully denying the GPL propagation theory, it can be interpreted as fearing that a judicial precedent undesirable for the community might be created depending on the result of the legal battle. The SFC might be said to be carefully balancing between the aspect of pursuing GPL propagation and the risk of entrusting it to the judiciary.&lt;/p&gt;
    &lt;p&gt;Finally, what is concerned as the free software camp is that excessive propagation of licenses might conversely invite results that impair freedom. Both OSI and FSF ultimately want to make AI something open that anyone can utilize, but they are carefully assessing whether increasing the purity of legal theory in demands for full data disclosure really leads to achieving the objective. Considering the demerits such as the avoidance of open data due to excessive propagation interpretation or the atrophy effect due to a flurry of lawsuits, I feel that the major organizations share a commonality in that it is essential not to lose sight of the big picture of spreading freedom. Rather than inciting GPL application to models, the pursuit of realistic solutions such as how to make models and data open and which parts should be relaxed in line with reality will likely continue in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;I have looked at the current state of the theory of GPL propagation to AI models above, and as a conclusion, this theory is in a halfway position where ‚Äúit is not touted as loudly as before, but it has not completely disappeared.‚Äù As a result of points such as license violation of training data and reproduction within the model beginning to be scrutinized in lawsuits like the Copilot class action and GEMA v. OpenAI, it even appears that the hurdle for infringement certification is lowering. In fact, the Munich District Court‚Äôs judgment deemed model memory as reproduction, and the claim of open source license violation survives in the Copilot litigation.&lt;/p&gt;
    &lt;p&gt;However, on the other hand, the hurdle for the propagation of licenses like GPL remains high. There is a large gap between infringement being recognized and the conclusion that the entire model must be disclosed under GPL etc. immediately. What the current lawsuits are seeking is also injunctions and damages, not the forced GPL-ization of the model. There are zero examples where the judiciary supported the theory of GPL propagation to models itself, and it is a legally uncharted territory. Even if that claim were attempted somewhere in the future, it would face the legal, technical, and practical counterarguments mentioned earlier.&lt;/p&gt;
    &lt;p&gt;However, the situation has fluid parts, and there is a possibility that the line will shift depending on the policies of each country and the trends of the community. For example, if pressure from rights holder groups strengthens in Europe, there is a possibility that guidelines including license compliance will be formulated. Also, if a consensus is formed within the community regarding the state of copyleft in the AI era, a new license might appear. If such changes occur, a phase where the theory of propagation to models is re-evaluated will also arrive.&lt;/p&gt;
    &lt;p&gt;To offer my personal opinion, what is important at this moment is the perspective of how to balance software freedom and freedom in the AI domain. Instead of blindly trying to apply the philosophy of copyleft to AI, it is necessary to think about what is best to maximize freedom while considering the technical nature and industrial structure peculiar to AI. Fortunately, solutions to practical problems such as the open publication of large-scale AI models, dataset cleaning methods, and automated attachment of license notices are already being explored by the open source community. Promoting such voluntary efforts and supporting them with legal frameworks as necessary will likely be the key to balancing freedom and development.&lt;/p&gt;
    &lt;p&gt;The theory of GPL propagation to models is a point where judgment is divided on whether it is an ideal to be pursued or a nightmare to be avoided. However, as stated in this article, seeing the situation in the current year of 2025, it is not a situation where it will become reality immediately, and the majority of the community is likely maintaining a cautious stance. Although it is speculated that trial and error will continue in the judicial, legislative, and technical aspects in the future, as our community, we need to continue exploring the point of compatibility between technological innovation and software freedom without jumping to hasty conclusions. That process itself can be said to be a new challenge in the AI era on the extension of the free software spirit.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Copilot litigation: https://githubcopilotlitigation.com/&lt;/item&gt;
      &lt;item&gt;GEMA v. OpenAI Judgment text: https://aifray.com/wp-content/uploads/2025/11/42-O-14139-24-Endurteil.pdf&lt;/item&gt;
      &lt;item&gt;GEMA vs. OpenAI | AI memorisation is a reproduction relevant to copyright law, and the TDM exception does not help in LLM training, Munich I Regional Court holds: https://www.osborneclarke.com/insights/gema-vs-openai-ai-memorisation-reproduction-relevant-copyright-law-and-tdm-exception-does&lt;/item&gt;
      &lt;item&gt;Impressions on GEMA v. OpenAI (Munich I Regional Court) Judgment: https://shujisado.com/2025/11/15/gema-v-openai/&lt;/item&gt;
      &lt;item&gt;Draft thought on AI and Copyright, Agency for Cultural Affairs: https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/pdf/94037901_01.pdf&lt;/item&gt;
      &lt;item&gt;Contract Guidelines on Utilization of AI and Data: https://www.meti.go.jp/policy/mono_info_service/connected_industries/sharing_and_utilization/20180615001-1.pdf&lt;/item&gt;
      &lt;item&gt;Open Source AI: https://opensource.org/ai&lt;/item&gt;
      &lt;item&gt;Is publication of complete training data necessary for AI models to be Open Source?: https://shujisado.com/2025/02/18/need_for_training_data_in_opensource_ai/&lt;/item&gt;
      &lt;item&gt;Controlling technology at the age of Artificial Intelligence: a Free Software perspective: https://fsfe.org/freesoftware/artificial-intelligence.en.html&lt;/item&gt;
      &lt;item&gt;FSF is working on freedom in machine learning applications: https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications&lt;/item&gt;
      &lt;item&gt;Give Up GitHub!: https://sfconservancy.org/GiveUpGitHub/&lt;/item&gt;
      &lt;item&gt;On the filing of the Class Action Law Suit over GitHub‚Äôs Copilot: https://sfconservancy.org/news/2022/nov/04/class-action-lawsuit-filing-copilot/&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46068777</guid><pubDate>Thu, 27 Nov 2025 12:48:12 +0000</pubDate></item><item><title>Show HN: MkSlides ‚Äì Markdown to slides with a similar workflow to MkDocs</title><link>https://github.com/MartenBE/mkslides</link><description>&lt;doc fingerprint="6204be3b1ea793b4"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;p&gt;Use&lt;/p&gt;&lt;code&gt;mkslides&lt;/code&gt;to easily turn Markdown files into beautiful slides using the power of Reveal.js!&lt;/quote&gt;
    &lt;p&gt;MkSlides is a static site generator that's geared towards building slideshows. Slideshow source files are written in Markdown, and configured with a single YAML configuration file. The workflow and commands are heavily inspired by MkDocs and reveal-md.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Build static HTML slideshow files from Markdown files. &lt;list rend="ul"&gt;&lt;item&gt;Turn a single Markdown file into a HTML slideshow.&lt;/item&gt;&lt;item&gt;Turn a folder with Markdown files into a collection of HTML slideshows with an index landing page.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Publish your slideshow(s) anywhere that static files can be served. &lt;list rend="ul"&gt;&lt;item&gt;Locally on your own device.&lt;/item&gt;&lt;item&gt;On a web server.&lt;/item&gt;&lt;item&gt;Deploy through CI/CD with GitHub/GitLab (like this repo!).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Preview your site as you work, thanks to python-livereload.&lt;/item&gt;
      &lt;item&gt;Use custom favicons, CSS themes, templates, ... if desired.&lt;/item&gt;
      &lt;item&gt;Support for emojis üòÑ üéâ üöÄ ‚ú® thanks to emoji&lt;/item&gt;
      &lt;item&gt;Depends heavily on integration/unit tests to prevent regressions.&lt;/item&gt;
      &lt;item&gt;And more!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example slide from https://martenbe.github.io/mkslides with dracula theme:&lt;/p&gt;
    &lt;p&gt;Example index page from https://hogenttin.github.io/hogent-markdown-slides with HOGENT theme, custom title, and custom background logo:&lt;/p&gt;
    &lt;p&gt;Example output when building the website:&lt;/p&gt;
    &lt;p&gt;Example output when using live preview during editing:&lt;/p&gt;
    &lt;p&gt;Want more examples? An example repo with slides demonstrating all possibilities (Mermaid.js and PlantUML support, multicolumn slides, image resizing, ...) using Reveal.js with the HOGENT theme can be found at https://github.com/HoGentTIN/hogent-markdown-slides .&lt;/p&gt;
    &lt;code&gt;pip install mkslides&lt;/code&gt;
    &lt;p&gt;E.g. when your Markdown files are located in the &lt;code&gt;slides/&lt;/code&gt; folder:&lt;/p&gt;
    &lt;code&gt;mkslides build&lt;/code&gt;
    &lt;p&gt;If the &lt;code&gt;slides&lt;/code&gt; folder doesn't exists, it will fallback to &lt;code&gt;docs&lt;/code&gt; for backwards compatibility. If &lt;code&gt;docs&lt;/code&gt; also doesn't exists, it will error.&lt;/p&gt;
    &lt;p&gt;E.g. when your Markdown files are located in the &lt;code&gt;somefolder/&lt;/code&gt; folder:&lt;/p&gt;
    &lt;code&gt;mkslides build somefolder/&lt;/code&gt;
    &lt;p&gt;E.g. when you have a single Markdown file called &lt;code&gt;test.md&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;mkslides build test.md&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;PATH&lt;/code&gt;, only default static assets will be copied to the output folder. If you want to include images or other files, create a folder instead and pass that as &lt;code&gt;PATH&lt;/code&gt;. Using a file as &lt;code&gt;PATH&lt;/code&gt; is more meant for a quick slideshow in a pinch using only text.&lt;/p&gt;
    &lt;p&gt;The commands for live preview are very similar to creating a static website.&lt;/p&gt;
    &lt;code&gt;mkslides serve
mkslides serve somefolder/
mkslides serve test.md&lt;/code&gt;
    &lt;code&gt;mkslides build -h
mkslides serve -h&lt;/code&gt;
    &lt;p&gt;Just create a &lt;code&gt;mkslides.yml&lt;/code&gt;. All options are optional, you only have to add what you want to change to &lt;code&gt;mkslides.yml&lt;/code&gt;.
Relative file paths are considered relative to the directory containing Markdown files (&lt;code&gt;PATH&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Here's an example showcasing all possible options in the config file:&lt;/p&gt;
    &lt;code&gt;# Configuration for the generated index page
index:
    # Enables or disables the "Documentation built with MkSlides." footer:
    # boolean
    enable_footer: true

    # Favicon of the generated index page: file path or public url to favicon
    # file
    favicon: example-index-favicon.ico

    # Navigation section describing how to structure the slides on the index
    # page. This is similar to the `nav` option from MkDocs: list[any]
    nav:
        - Example: example1.md
        - "Example 2": somewhere/example1.md
        - example3.md
        - somewhere/example4.md
        - "More examples":
              - example5.md
              - "Much more examples":
                    - "Last example": somewhere/much/more/examples/example6.md

    # Title of the generated index page: string
    title: example-title

    # Jinja 2 template to generate index HTML: file path to Jinja2 file
    template: example.jinja

    # Theme of the generated index page: file path or public url to CSS file
    theme: example-index-theme.css

# Configuration for the slides
slides:
    # Charset of the slides: string
    # (see https://revealjs.com/markdown/#external-markdown)
    charset: utf-8

    # Favicon of the slides: file path or public url to favicon file
    favicon: example-slides-favicon.ico

    # Theme for syntax highlighting of code fragments on the slides: file path
    # to CSS file, public url to CSS file, or one of the highlight.js built-in
    # themes such as `monokai`, `obsidian`, `tokyo-night-dark`, `vs`, ...
    # (see https://highlightjs.org/examples)
    highlight_theme: example-slides-highlight-theme.css

    # Relative path to a python script containing a function
    # Callable[[str], str] named `preprocess`. Important: a relative file path
    # here is considered relative to the configuration file, as you probably
    # don't want to serve the python scripts.
    # For each Markdown file, the whole file content is given to the function as
    # a str. The returned string is then further processed as the Markdown to
    # give to Reveal.js
    preprocess_script: tests/test_preprocessors/replace_ats.py

    # Separator to determine notes of the slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator_notes: "^Notes?:"

    # Separator to determine end current/begin new vertical slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator_vertical: ^\s*-v-\s*$

    # Separator to determine end current/begin new slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator: ^\s*---\s*$

    # Jinja 2 template to generate index HTML: file path to Jinja2 file
    template: ./example.jinja

    # Theme of the slides: file path to CSS file, public url to CSS file, or one
    # of the reveal.js themes such as `black`, `white`, `league`, `solarized`,
    # `dracula`, ... (see https://revealjs.com/themes/)
    theme: example-slides-theme.css

    # Title of the slides. If this is set for a slide, it will be used for the
    # entry in the generated index HTML: string
    title: example-title

# Options to be passed to reveal.js: options in yaml format, they will be
# translated to JSON automatically (see https://revealjs.com/config/)
revealjs:
    height: 1080
    width: 1920
    transition: fade

    example_plugin:
        example_plugin_option_A: true
        example_plugin_option_B: qwerty

# Plugins or additional CSS/JavaScript files for the slides. These are given as
# a list.
plugins:
    # Name of the plugin (optional, see plugin README): plugin id string
    # (see https://revealjs.com/creating-plugins/#registering-a-plugin)
    - name: RevealExamplePlugin
      # List of CSS files of the plugin (optional, see plugin README):
      # public url to CSS file per entry
      extra_css:
          - https://cdn.jsdelivr.net/npm/reveal.js-example-pluging/example.min.css
      # List of JavaScript files of the plugin (optional, see plugin README):
      # public url to JavaScript file per entry
      extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal.js-example-pluging/example.min.js
    - name: RevealMermaid
      extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin/plugin/mermaid/mermaid.min.js
    - extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal-plantuml/dist/reveal-plantuml.min.js&lt;/code&gt;
    &lt;p&gt;Default config (also used if no config file is present):&lt;/p&gt;
    &lt;code&gt;index:
    enable_footer: true
    template: assets/templates/index.html.jinja # Comes with the pip package
    title: Index
slides:
    highlight_theme: monokai
    template: assets/templates/slideshow.html.jinja # Comes with the pip package
    theme: black
revealjs:
    history: true
    slideNumber: c/t&lt;/code&gt;
    &lt;p&gt;It is also possible to override &lt;code&gt;slides&lt;/code&gt;, &lt;code&gt;revealjs&lt;/code&gt;, and &lt;code&gt;plugins&lt;/code&gt; options on a per Markdown file base using it's frontmatter. Here, relative file paths are considered relative to the Markdown file itself.&lt;/p&gt;
    &lt;code&gt;---
slides:
    theme: solarized
    highlight_theme: vs
    separator: &amp;lt;!--s--&amp;gt;
    title: Frontmatter title.
revealjs:
    height: 1080
    width: 1920
    transition: zoom
---

# Slides with frontmatter

&amp;lt;!--s--&amp;gt;

## Lorem ipsum

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

&amp;lt;!--s--&amp;gt;&lt;/code&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;title&lt;/code&gt;here is a frontmatter-only available option to set the title of this slideshow in the generated index page. This option is not available in&lt;code&gt;mkslides.yml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The precedence is frontmatter &amp;gt; &lt;code&gt;mkslides.yml&lt;/code&gt;&amp;gt; defaults.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;Usage: mkslides [OPTIONS] COMMAND [ARGS]...

  MkSlides - Slides with Markdown using the power of Reveal.js.

Options:
  -V, --version  Show the version and exit.
  -v, --verbose  Enable verbose output
  -h, --help     Show this message and exit.

Commands:
  build  Build the MkSlides documentation.
  serve  Run the builtin development server.

&lt;/code&gt;
    &lt;code&gt;Usage: mkslides build [OPTIONS] [PATH]

  Build the MkSlides documentation.

  PATH is the path to the directory containing Markdown files. This argument
  is optional and will default to 'slides', or 'docs' if the first directory
  doesn't exist. If PATH is a single Markdown file or a directory containing a
  single Markdown file, it will always be processed into `index.html`
  regardless the name of the Markdown file.

Options:
  -f, --config-file FILENAME  Provide a specific MkSlides-Reveal config file.
  -d, --site-dir PATH         The directory to output the result of the slides
                              build. All files are removed from the site dir
                              before building.
  -s, --strict                Fail if a relative link cannot be resolved,
                              otherwise just print a warning.
  -h, --help                  Show this message and exit.

&lt;/code&gt;
    &lt;code&gt;Usage: mkslides serve [OPTIONS] [PATH]

  Run the builtin development server.

  PATH is the path to the directory containing Markdown files. This argument
  is optional and will default to 'slides', or 'docs' if the first directory
  doesn't exist. If PATH is a single Markdown file or a directory containing a
  single Markdown file, it will always be processed into `index.html`
  regardless the name of the Markdown file.

Options:
  -f, --config-file FILENAME  Provide a specific MkSlides-Reveal config file.
  -s, --strict                Fail if a relative link cannot be resolved,
                              otherwise just print a warning.
  -a, --dev-addr &amp;lt;IP:PORT&amp;gt;    IP address and port to serve slides locally.
  -o, --open                  Open the website in a Web browser after the
                              initial build finishes.
  -h, --help                  Show this message and exit.

&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46068847</guid><pubDate>Thu, 27 Nov 2025 13:00:17 +0000</pubDate></item><item><title>Show HN: Runprompt ‚Äì run .prompt files from the command line</title><link>https://github.com/chr15m/runprompt</link><description>&lt;doc fingerprint="1c7ffd5c6cb14e40"&gt;
  &lt;main&gt;
    &lt;p&gt;A single-file Python script for running .prompt files.&lt;/p&gt;
    &lt;p&gt;Quick start | Examples | Configuration | Providers&lt;/p&gt;
    &lt;code&gt;curl -O https://raw.githubusercontent.com/chr15m/runprompt/main/runprompt
chmod +x runprompt&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.prompt&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="your-key"
echo '{"name": "World"}' | ./runprompt hello.prompt&lt;/code&gt;
    &lt;p&gt;In addition to the following, see the tests folder for more example &lt;code&gt;.prompt&lt;/code&gt; files.&lt;/p&gt;
    &lt;code&gt;cat article.txt | ./runprompt summarize.prompt&lt;/code&gt;
    &lt;p&gt;The special &lt;code&gt;{{STDIN}}&lt;/code&gt; variable always contains the raw stdin as a string.&lt;/p&gt;
    &lt;p&gt;Extract structured data using an output schema:&lt;/p&gt;
    &lt;code&gt;echo "John is a 30 year old teacher" | ./runprompt extract.prompt
# {"name": "John", "age": 30, "occupation": "teacher"}&lt;/code&gt;
    &lt;p&gt;Fields ending with &lt;code&gt;?&lt;/code&gt; are optional. The format is &lt;code&gt;field: type, description&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Pipe structured output between prompts:&lt;/p&gt;
    &lt;code&gt;echo "John is 30" | ./runprompt extract.prompt | ./runprompt generate-bio.prompt&lt;/code&gt;
    &lt;p&gt;The JSON output from the first prompt becomes template variables in the second.&lt;/p&gt;
    &lt;p&gt;Override any frontmatter value from the command line:&lt;/p&gt;
    &lt;code&gt;./runprompt --model anthropic/claude-haiku-4-20250514 hello.prompt
./runprompt --name "Alice" hello.prompt&lt;/code&gt;
    &lt;p&gt;Set API keys for your providers:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="..."
export OPENAI_API_KEY="..."
export GOOGLE_API_KEY="..."
export OPENROUTER_API_KEY="..."&lt;/code&gt;
    &lt;p&gt;Override any frontmatter value via environment variables prefixed with &lt;code&gt;RUNPROMPT_&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;export RUNPROMPT_MODEL="anthropic/claude-haiku-4-20250514"
./runprompt hello.prompt&lt;/code&gt;
    &lt;p&gt;This is useful for setting defaults across multiple prompt runs.&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;-v&lt;/code&gt; to see request/response details:&lt;/p&gt;
    &lt;code&gt;./runprompt -v hello.prompt&lt;/code&gt;
    &lt;p&gt;Models are specified as &lt;code&gt;provider/model-name&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Provider&lt;/cell&gt;
        &lt;cell role="head"&gt;Model format&lt;/cell&gt;
        &lt;cell role="head"&gt;API key env var&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Anthropic&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;anthropic/claude-sonnet-4-20250514&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OpenAI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;openai/gpt-4o&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Google AI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;googleai/gemini-1.5-pro&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;OpenRouter&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;openrouter/anthropic/claude-sonnet-4-20250514&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;OpenRouter provides access to models from many providers (Anthropic, Google, Meta, etc.) through a single API key.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46069556</guid><pubDate>Thu, 27 Nov 2025 14:26:35 +0000</pubDate></item><item><title>Show HN: SyncKit ‚Äì Offline-first sync engine (Rust/WASM and TypeScript)</title><link>https://github.com/Dancode-188/synckit</link><description>&lt;doc fingerprint="8e863a7cfdb33ea9"&gt;
  &lt;main&gt;
    &lt;p&gt;True offline-first sync for modern apps‚Äîwithout vendor lock-in&lt;/p&gt;
    &lt;p&gt;Getting Started ‚Ä¢ Documentation ‚Ä¢ Examples ‚Ä¢ Discussions ‚Ä¢ Roadmap&lt;/p&gt;
    &lt;p&gt;SyncKit is a production-ready sync engine that makes building local-first applications trivial.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Add&lt;/p&gt;&lt;code&gt;sync.document()&lt;/code&gt;to your app, get real-time sync automatically."&lt;/quote&gt;
    &lt;p&gt;The problem: Building sync from scratch takes months. Existing solutions are complex (Yjs), expensive (Firebase), or don't work offline (Supabase).&lt;/p&gt;
    &lt;p&gt;The solution: SyncKit gives you production-ready sync in 3 lines of code.&lt;/p&gt;
    &lt;code&gt;const sync = new SyncKit()
await sync.init()
const doc = sync.document&amp;lt;Todo&amp;gt;('todo-123')
await doc.update({ completed: true })
// ‚ú® Works offline, syncs automatically, resolves conflicts&lt;/code&gt;
    &lt;p&gt;Real-time collaboration with offline resilience: Watch tasks sync instantly across tabs‚Äîeven while offline. The example app demonstrates SyncKit's offline-first capabilities combined with smart browser storage to create a seamless collaborative experience.&lt;/p&gt;
    &lt;p&gt;True offline-first architecture‚Äînot just caching. Your app works perfectly on planes, trains, tunnels, and coffee shops with spotty WiFi.&lt;/p&gt;
    &lt;p&gt;~59 KB gzipped (10KB SDK + 49KB WASM) - Complete WASM-based sync engine with TypeScript SDK.&lt;/p&gt;
    &lt;p&gt;Current features (v0.1.0):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Offline-first sync (LWW)&lt;/item&gt;
      &lt;item&gt;‚úÖ Real-time collaboration&lt;/item&gt;
      &lt;item&gt;‚úÖ Network protocol support&lt;/item&gt;
      &lt;item&gt;‚úÖ IndexedDB persistence&lt;/item&gt;
      &lt;item&gt;‚úÖ Cross-tab sync (see example)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Coming in v0.2.0:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöß Text CRDTs (character-level editing)&lt;/item&gt;
      &lt;item&gt;üöß Counters, Sets (distributed data structures)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Size-critical apps? Use Lite variant (~45 KB gzipped: 1.5KB SDK + 44KB WASM, local-only)&lt;/p&gt;
    &lt;p&gt;Competitive bundle size: Larger than Yjs (~19KB pure JS), smaller than Automerge (~60-78KB).&lt;/p&gt;
    &lt;p&gt;Open source and self-hostable. No vendor lock-in, no surprise $2,000/month bills, complete data sovereignty.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&amp;lt;1ms local operations (~5-20Œºs single field update)&lt;/item&gt;
      &lt;item&gt;&amp;lt;100ms sync latency (10-50ms p95)&lt;/item&gt;
      &lt;item&gt;~59KB bundle (10KB SDK + 49KB WASM), ~45KB lite option&lt;/item&gt;
      &lt;item&gt;Sub-200KB total with React&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero data loss with automatic conflict resolution (Last-Write-Wins)&lt;/item&gt;
      &lt;item&gt;Formal verification with TLA+ (3 bugs found and fixed)&lt;/item&gt;
      &lt;item&gt;700+ comprehensive tests across TypeScript and Rust (unit, integration, chaos, load)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;SyncKit&lt;/cell&gt;
        &lt;cell role="head"&gt;Firebase&lt;/cell&gt;
        &lt;cell role="head"&gt;Supabase&lt;/cell&gt;
        &lt;cell role="head"&gt;Yjs&lt;/cell&gt;
        &lt;cell role="head"&gt;Automerge&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;True Offline-First&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Native&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(40MB limit)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;‚ùå None&lt;p&gt;(#357 - 4+ years)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Full&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Full&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Works Without Server&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Bundle Size (gzipped)&lt;/cell&gt;
        &lt;cell&gt;~59KB&lt;p&gt;(45KB lite)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;~150KB&lt;/cell&gt;
        &lt;cell&gt;~45KB&lt;/cell&gt;
        &lt;cell&gt;~19KB&lt;/cell&gt;
        &lt;cell&gt;~60-78KB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Text CRDT&lt;/cell&gt;
        &lt;cell&gt;üöß v0.2.0&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Counters/Sets&lt;/cell&gt;
        &lt;cell&gt;üöß v0.2.0&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Automatic Conflicts&lt;/cell&gt;
        &lt;cell&gt;‚úÖ LWW&lt;/cell&gt;
        &lt;cell&gt;‚úÖ LWW&lt;/cell&gt;
        &lt;cell&gt;‚úÖ CRDT&lt;/cell&gt;
        &lt;cell&gt;‚úÖ CRDT&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Self-Hosted&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Multi-Language Server&lt;/cell&gt;
        &lt;cell&gt;‚úÖ TS&lt;p&gt;üöß Py/Go/Rust&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå JS only&lt;/cell&gt;
        &lt;cell&gt;‚ùå JS only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Pricing&lt;/cell&gt;
        &lt;cell&gt;Free (self-host)&lt;/cell&gt;
        &lt;cell&gt;$25-$2,000+/mo&lt;/cell&gt;
        &lt;cell&gt;$0-$25/mo&lt;/cell&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;TypeScript Support&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Native&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Good&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Good&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Good&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Learning Curve&lt;/cell&gt;
        &lt;cell&gt;‚úÖ 5 minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Production Status&lt;/cell&gt;
        &lt;cell&gt;‚úÖ v0.1.0 ready&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Mature&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Mature&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Mature&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;TL;DR:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vs Firebase: No vendor lock-in, true offline, predictable costs&lt;/item&gt;
      &lt;item&gt;vs Supabase: Actually works offline (their #1 issue for 4+ years)&lt;/item&gt;
      &lt;item&gt;vs Yjs: WASM-based for multi-language server support, simpler API for structured data&lt;/item&gt;
      &lt;item&gt;vs Automerge: Smaller bundle, faster performance, production-ready&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See detailed migration guides ‚Üí&lt;/p&gt;
    &lt;code&gt;npm install @synckit-js/sdk&lt;/code&gt;
    &lt;code&gt;import { SyncKit } from '@synckit-js/sdk'
import { SyncProvider, useSyncDocument } from '@synckit-js/sdk/react'

// Initialize (works offline-only, no server needed!)
const sync = new SyncKit()
await sync.init()

function App() {
  return (
    &amp;lt;SyncProvider synckit={sync}&amp;gt;
      &amp;lt;TodoApp /&amp;gt;
    &amp;lt;/SyncProvider&amp;gt;
  )
}

function TodoApp() {
  const [todo, { update }] = useSyncDocument&amp;lt;Todo&amp;gt;('todo-1')

  if (!todo || !todo.text) return &amp;lt;div&amp;gt;Loading...&amp;lt;/div&amp;gt;

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;input
        type="checkbox"
        checked={todo.completed}
        onChange={(e) =&amp;gt; update({ completed: e.target.checked })}
      /&amp;gt;
      &amp;lt;span&amp;gt;{todo.text}&amp;lt;/span&amp;gt;
    &amp;lt;/div&amp;gt;
  )
}&lt;/code&gt;
    &lt;p&gt;That's it! Your app now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Works 100% offline&lt;/item&gt;
      &lt;item&gt;‚úÖ Syncs across tabs automatically&lt;/item&gt;
      &lt;item&gt;‚úÖ Persists data in IndexedDB&lt;/item&gt;
      &lt;item&gt;‚úÖ Resolves conflicts automatically&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bundle: SyncKit (~59 KB gzipped) + React (~130 KB) = ~189 KB total&lt;/p&gt;
    &lt;p&gt;Size-critical? &lt;code&gt;import { SyncKit } from '@synckit-js/sdk/lite'&lt;/code&gt; (~45 KB gzipped, local-only)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üîÑ Real-Time Sync - WebSocket-based instant sync across devices&lt;/item&gt;
      &lt;item&gt;üì¥ Offline-First - Works perfectly with zero connectivity&lt;/item&gt;
      &lt;item&gt;üóÑÔ∏è Local Persistence - IndexedDB storage, unlimited capacity&lt;/item&gt;
      &lt;item&gt;üîÄ Conflict Resolution - Automatic Last-Write-Wins (LWW) merge&lt;/item&gt;
      &lt;item&gt;‚ö° Fast Operations - &amp;lt;1ms local updates, &amp;lt;100ms sync latency&lt;/item&gt;
      &lt;item&gt;üì¶ Compact Bundle - ~59KB gzipped (10KB SDK + 49KB WASM)&lt;/item&gt;
      &lt;item&gt;üîê Secure - JWT authentication, RBAC permissions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚öõÔ∏è React Hooks - &lt;code&gt;useSyncDocument&lt;/code&gt;,&lt;code&gt;useSyncField&lt;/code&gt;,&lt;code&gt;SyncProvider&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;üåê TypeScript Server - Bun + Hono reference implementation&lt;/item&gt;
      &lt;item&gt;üì¶ Multi-Variant - Default (~59KB gzipped) or Lite (~45KB gzipped) builds&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úçÔ∏è Text CRDTs - Collaborative text editing (character-level sync)&lt;/item&gt;
      &lt;item&gt;üî¢ Counters - Conflict-free increment/decrement&lt;/item&gt;
      &lt;item&gt;üìã Sets &amp;amp; Lists - Observed-Remove Sets for collections&lt;/item&gt;
      &lt;item&gt;üé® Framework Adapters - Vue composables, Svelte stores&lt;/item&gt;
      &lt;item&gt;üåê Multi-Language Servers - Python, Go, Rust implementations&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;graph TD
    A[Your Application&amp;lt;br/&amp;gt;React/Vue/Svelte] --&amp;gt; B[SyncKit SDK&amp;lt;br/&amp;gt;TypeScript]

    B --&amp;gt;|Simple API| B1[document, text, counter]
    B --&amp;gt;|Framework adapters| B2[React/Vue/Svelte hooks]
    B --&amp;gt;|Offline queue| B3[Storage adapters]

    B --&amp;gt; C[Rust Core Engine&amp;lt;br/&amp;gt;WASM + Native]

    C --&amp;gt;|80% of use cases| C1[LWW Sync]
    C --&amp;gt;|Collaborative editing| C2[Text CRDTs]
    C --&amp;gt;|Advanced features| C3[Custom CRDTs&amp;lt;br/&amp;gt;counters, sets]

    C --&amp;gt; D[IndexedDB Storage&amp;lt;br/&amp;gt;Your local source of truth]

    D -.-&amp;gt;|Optional| E[SyncKit Server&amp;lt;br/&amp;gt;TypeScript/Python/Go/Rust]

    E --&amp;gt;|Real-time sync| E1[WebSocket]
    E --&amp;gt;|Persistence| E2[PostgreSQL/MongoDB]
    E --&amp;gt;|Security| E3[JWT auth + RBAC]

    style A fill:#e1f5ff,stroke:#333,stroke-width:2px,color:#1a1a1a
    style B fill:#fff4e1,stroke:#333,stroke-width:2px,color:#1a1a1a
    style C fill:#ffe1e1,stroke:#333,stroke-width:2px,color:#1a1a1a
    style D fill:#e1ffe1,stroke:#333,stroke-width:2px,color:#1a1a1a
    style E fill:#f0e1ff,stroke:#333,stroke-width:2px,color:#1a1a1a
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;5-Minute Quick Start - Build your first synced app&lt;/item&gt;
      &lt;item&gt;Installation Guide - Setup instructions&lt;/item&gt;
      &lt;item&gt;API Reference - Complete API documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Offline-First Patterns - True offline architecture&lt;/item&gt;
      &lt;item&gt;Conflict Resolution - Automatic LWW merge strategy&lt;/item&gt;
      &lt;item&gt;Performance Optimization - Bundle size, memory, sync speed&lt;/item&gt;
      &lt;item&gt;Testing Guide - Property-based tests, chaos engineering&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;From Firebase/Firestore - Escape vendor lock-in&lt;/item&gt;
      &lt;item&gt;From Supabase - Add offline support&lt;/item&gt;
      &lt;item&gt;From Yjs/Automerge - Simplify your stack&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Todo App - Simple CRUD with filters&lt;/item&gt;
      &lt;item&gt;Collaborative Editor - Real-time text editing with CodeMirror 6&lt;/item&gt;
      &lt;item&gt;Project Management - Production-grade kanban app with drag-and-drop&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perfect for: Task apps, CRMs, project management, note apps (80% of applications)&lt;/p&gt;
    &lt;code&gt;// Initialize once
const sync = new SyncKit()
await sync.init()

// Use anywhere
const doc = sync.document&amp;lt;Project&amp;gt;('project-123')
await doc.update({ status: 'completed' })
// Conflicts resolved automatically with Last-Write-Wins&lt;/code&gt;
    &lt;p&gt;Perfect for: Collaborative editors, documentation, notes&lt;/p&gt;
    &lt;code&gt;// Note: Text CRDT API is planned for v0.2.0
const text = sync.text('document-456')
await text.insert(0, 'Hello ')
text.subscribe(content =&amp;gt; editor.setValue(content))
// Character-level sync, conflict-free convergence&lt;/code&gt;
    &lt;p&gt;Perfect for: Whiteboards, design tools, specialized apps&lt;/p&gt;
    &lt;code&gt;// Note: Counter API is planned for v0.2.0
const counter = sync.counter('likes-789')
await counter.increment()
// Conflict-free counter (additions never conflict)&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;@synckit-js/sdk&lt;/code&gt;- Core SDK (TypeScript) + WASM engine&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;@synckit-js/sdk/react&lt;/code&gt;- React hooks and components (export from SDK)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;@synckit-js/sdk/lite&lt;/code&gt;- Lightweight version (local-only, 45KB gzipped)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;@synckit-js/server&lt;/code&gt;- Bun + Hono reference server (production-ready)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Current Version: v0.1.0 Production Ready: Core sync engine, React hooks, TypeScript server ‚úÖ&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Core Rust Engine - LWW sync engine with CRDT foundation&lt;/item&gt;
      &lt;item&gt;‚úÖ WASM Compilation - 59KB gzipped (45KB lite), optimized performance&lt;/item&gt;
      &lt;item&gt;‚úÖ TypeScript SDK - Document API, IndexedDB storage, offline queue&lt;/item&gt;
      &lt;item&gt;‚úÖ Cross-Tab Sync - Server-mediated sync with operation buffering for multi-tab coordination&lt;/item&gt;
      &lt;item&gt;‚úÖ React Integration - &lt;code&gt;useSyncDocument&lt;/code&gt;,&lt;code&gt;useSyncField&lt;/code&gt;,&lt;code&gt;SyncProvider&lt;/code&gt;hooks&lt;/item&gt;
      &lt;item&gt;‚úÖ TypeScript Server - WebSocket sync server with Bun + Hono&lt;/item&gt;
      &lt;item&gt;‚úÖ Example Applications - Todo app, collaborative editor, project management demos&lt;/item&gt;
      &lt;item&gt;‚úÖ Documentation - Comprehensive guides and API reference&lt;/item&gt;
      &lt;item&gt;‚úÖ Build System - Complete toolchain with benchmarks and CI&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöß Text CRDTs - Collaborative text editing (&lt;code&gt;useText&lt;/code&gt;hook) for character-level sync&lt;/item&gt;
      &lt;item&gt;üöß Counter CRDTs - Distributed counters (&lt;code&gt;useCounter&lt;/code&gt;hook) for conflict-free increments&lt;/item&gt;
      &lt;item&gt;üöß BroadcastChannel Cross-Tab - Direct client-to-client sync without server (offline multi-tab)&lt;/item&gt;
      &lt;item&gt;üöß Framework Adapters - Vue composables (&lt;code&gt;@synckit-js/sdk/vue&lt;/code&gt;), Svelte stores (&lt;code&gt;@synckit-js/sdk/svelte&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;üöß Multi-Language Servers - Python, Go, Rust server implementations (TypeScript complete)&lt;/item&gt;
      &lt;item&gt;üöß Advanced Storage - OPFS (Origin Private File System), SQLite adapter&lt;/item&gt;
      &lt;item&gt;üöß Conflict UI - Visual conflict resolution interface for complex merge scenarios&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome contributions from the community!&lt;/p&gt;
    &lt;p&gt;Ways to contribute:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üêõ Bug Reports - Open an issue&lt;/item&gt;
      &lt;item&gt;üìö Documentation - Improve guides, fix typos&lt;/item&gt;
      &lt;item&gt;üß™ Tests - Add test coverage&lt;/item&gt;
      &lt;item&gt;üåê Servers - Implement Python/Go/Rust servers&lt;/item&gt;
      &lt;item&gt;üí° Features - Propose new features in discussions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Need enterprise support?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üéØ Managed Hosting - We host SyncKit servers for you&lt;/item&gt;
      &lt;item&gt;üîí Priority Support - 24/7 support, SLA guarantees&lt;/item&gt;
      &lt;item&gt;üìä Monitoring &amp;amp; Analytics - Dashboard, alerts, insights&lt;/item&gt;
      &lt;item&gt;üéì Training &amp;amp; Consulting - Onboarding, architecture review&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contact: danbitengo@gmail.com&lt;/p&gt;
    &lt;code&gt;Yjs:                ~19 KB ‚ñà‚ñà‚ñà‚ñà
SyncKit (lite):     ~45 KB ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
SyncKit (default):  ~59 KB ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Automerge:       ~60-78 KB ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Firebase:          ~150 KB ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
&lt;/code&gt;
    &lt;code&gt;Local update:       &amp;lt;1 ms  ‚ñà‚ñà‚ñà‚ñà
Cross-tab sync:     &amp;lt;1 ms  ‚ñà‚ñà‚ñà‚ñà
Network sync:    10-50 ms  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Firebase (cold):  2-30 s   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
&lt;/code&gt;
    &lt;code&gt;SyncKit:       3 MB  ‚ñà‚ñà‚ñà‚ñà
Yjs:           8 MB  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Automerge:   180 MB  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
&lt;/code&gt;
    &lt;p&gt;Built with inspiration from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yjs - YATA algorithm and performance optimization&lt;/item&gt;
      &lt;item&gt;Automerge - CRDT theory and formal verification&lt;/item&gt;
      &lt;item&gt;Linear - Pragmatic approach to sync&lt;/item&gt;
      &lt;item&gt;Figma - Custom sync architecture patterns&lt;/item&gt;
      &lt;item&gt;RxDB - Local-first database patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Special thanks to the local-first community for pioneering this movement.&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Copyright (c) 2025 Daniel Bitengo&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation - Complete guides and API reference&lt;/item&gt;
      &lt;item&gt;GitHub - Source code&lt;/item&gt;
      &lt;item&gt;Issues - Bug reports and features&lt;/item&gt;
      &lt;item&gt;Roadmap - Development timeline&lt;/item&gt;
      &lt;item&gt;Discussions - Community discussions&lt;/item&gt;
      &lt;item&gt;LinkedIn - Connect and follow updates&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built with ‚ù§Ô∏è for the local-first future&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46069598</guid><pubDate>Thu, 27 Nov 2025 14:31:44 +0000</pubDate></item><item><title>We're Losing Our Voice to LLMs</title><link>https://tonyalicea.dev/blog/were-losing-our-voice-to-llms/</link><description>&lt;doc fingerprint="b9cb7b1b1836a5ca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We're Losing Our Voice to LLMs&lt;/head&gt;
    &lt;p&gt;Social media has become a reminder of something precious we are losing in the age of LLMs: unique voices.&lt;/p&gt;
    &lt;p&gt;Over time, it has become obvious just how many posts are being generated by an LLM. The tell is the voice. Every post sounds like it was posted by the same social media manager.&lt;/p&gt;
    &lt;p&gt;If you rely on an LLM to write all your posts, you are making a mistake.&lt;/p&gt;
    &lt;p&gt;Your voice is an asset. Not just what you want to say, but how you say it.&lt;/p&gt;
    &lt;p&gt;Your voice is unique. It is formed from your lifetime of lived experiences. No one's voice will be exactly like yours.&lt;/p&gt;
    &lt;p&gt;Your voice becomes recognizable. Over many posts it becomes something people subconsciously connect with, recognize, trust, and look forward to.&lt;/p&gt;
    &lt;p&gt;Your voice provides the framework for the impression you leave in a job interview, while networking at a meet-up, or with a co-worker.&lt;/p&gt;
    &lt;p&gt;Years ago I got a job thanks to my blog posts. A manager wanted my voice influencing their organization. Your voice is an asset.&lt;/p&gt;
    &lt;p&gt;Your voice matures and becomes even more unique with time and practice.&lt;/p&gt;
    &lt;p&gt;LLMs can rob you of that voice, and the rest of us lose something precious in the process.&lt;/p&gt;
    &lt;p&gt;Having an LLM write "in your voice" is not the same. Your voice is not static. It changes with the tides of your life and state of mind. Your most impactful message may come because it was the right moment and you were in the right frame of mind.&lt;/p&gt;
    &lt;p&gt;Let your voice grow with use. Let it be unique.&lt;/p&gt;
    &lt;p&gt;Do not let one of your greatest assets fade into atrophy, wilted by cognitive laziness.&lt;/p&gt;
    &lt;p&gt;Write in your voice.&lt;/p&gt;
    &lt;p&gt;I do not care what the linguistic remix machine juggles into being.&lt;/p&gt;
    &lt;p&gt;I care what you have to say.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46069771</guid><pubDate>Thu, 27 Nov 2025 14:51:01 +0000</pubDate></item><item><title>Protect Public School Students from Surveillance of Off-Campus Speech</title><link>https://www.eff.org/deeplinks/2025/11/eff-arizona-federal-court-protect-public-school-students-surveillance-and</link><description>&lt;doc fingerprint="fc39b01d89c21b0f"&gt;
  &lt;main&gt;
    &lt;p&gt;Legal Intern Alexandra Rhodes contributed to this blog post.&lt;/p&gt;
    &lt;p&gt;EFF filed an amicus brief urging the Arizona District Court to protect public school students‚Äô freedom of speech and privacy by holding that the use of a school-issued laptop or email account does not categorically mean a student is ‚Äúon campus.‚Äù We argued that students need private digital spaces beyond their school‚Äôs reach to speak freely, without the specter of constant school surveillance and punishment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Surveillance Software Exposed a Bad Joke Made in the Privacy of a Student‚Äôs Home&lt;/head&gt;
    &lt;p&gt;The case, Merrill v. Marana Unified School District, involves a Marana High School student who, while at home one morning before school started, asked his mother for advice about a bad grade he received on an English assignment. His mother said he should talk to his English teacher, so he opened his school-issued Google Chromebook and started drafting an email. The student then wrote a series of jokes in the draft email that he deleted each time. The last joke stated: ‚ÄúGANG GANG GIMME A BETTER GRADE OR I SHOOT UP DA SKOOL HOMIE,‚Äù which he narrated out loud to his mother in a silly voice before deleting the draft and closing his computer.&lt;/p&gt;
    &lt;p&gt;Within the hour, the student‚Äôs mother received a phone call from the school principal, who said that Gaggle surveillance software had flagged a threat from her son and had sent along the screenshot of the draft email. The student‚Äôs mother attempted to explain the situation and reassure the principal that there was no threat. Nevertheless, despite her reassurances and the student‚Äôs lack of disciplinary record or history of violence, the student was ultimately suspended over the draft email‚Äîeven though he was physically off campus at the time, before school hours, and had never sent the email.&lt;/p&gt;
    &lt;p&gt;After the student‚Äôs suspension was unsuccessfully challenged, the family sued the school district alleging infringement of the student‚Äôs right to free speech under the First Amendment and violation of the student‚Äôs right to due process under the Fourteenth Amendment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Public School Students Have Greater First Amendment Protection for Off-Campus Speech&lt;/head&gt;
    &lt;p&gt;The U.S. Supreme Court has addressed the First Amendment rights of public school students in a handful of cases.&lt;/p&gt;
    &lt;p&gt;Most notably, in Tinker v. Des Moines Independent Community School District (1969), the Court held that students may not be punished for their on-campus speech unless the speech ‚Äúmaterially and substantially‚Äù disrupted the school day or invaded the rights of others.&lt;/p&gt;
    &lt;p&gt;Decades later, in Mahanoy Area School District v. B.L. by and through Levy (2021), in which EFF filed a brief, the Court further held that schools have less leeway to regulate student speech when that speech occurs off campus. Importantly, the Court stated that schools should have a limited ability to punish off-campus speech because ‚Äúfrom the student speaker‚Äôs perspective, regulations of off-campus speech, when coupled with regulations of on-campus speech, include all the speech a student utters during the full 24-hour day.‚Äù&lt;/p&gt;
    &lt;p&gt;The Ninth Circuit has further held that off-campus speech is only punishable if it bears a ‚Äúsufficient nexus‚Äù to the school and poses a credible threat of violence.&lt;/p&gt;
    &lt;p&gt;In this case, therefore, the extent of the school district‚Äôs authority to regulate student speech is tied to whether the high schooler was on or off campus at the time of the speech. The student here was at home and thus physically off campus when he wrote the joke in question; he wrote the draft before school hours; and the joke was not emailed to anyone on campus or anyone associated with the campus.&lt;/p&gt;
    &lt;p&gt;Yet the school district is arguing that his use of a school-issued Google Chromebook and Google Workspace for Education account (including the email account) made his speech‚Äîand makes all student speech‚Äîautomatically ‚Äúon campus‚Äù for purposes of justifying punishment under the First Amendment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Schools Provide Students with Valuable Digital Tools‚ÄîBut Also Subject Them to Surveillance&lt;/head&gt;
    &lt;p&gt;EFF supports the plaintiffs‚Äô argument that the student‚Äôs speech was ‚Äúoff campus,‚Äù did not bear a sufficient nexus to the school, and was not a credible threat. In our amicus brief, we urged the trial court at minimum to reject a rule that the use of a school-issued device or cloud account always makes a student‚Äôs speech ‚Äúon campus.‚Äù&lt;/p&gt;
    &lt;p&gt;Our amicus brief supports the plaintiffs‚Äô First Amendment arguments through the lens of surveillance, emphasizing that digital speech and digital privacy are inextricably linked.&lt;/p&gt;
    &lt;p&gt;As we explained, Marana Unified School District, like many schools and districts across the country, offers students free Google Chromebooks and requires them to have an online Google Account to access the various cloud apps in Google Workspace for Education, including the Gmail app.&lt;/p&gt;
    &lt;p&gt;Marana Unified School District also uses three surveillance technologies that are integrated into Chromebooks and Google Workspace for Education: Gaggle, GoGuardian, and Securly. These surveillance technologies collectively can monitor virtually everything students do on their laptops and online, from the emails and documents they write (or even just draft) to the websites they visit.&lt;/p&gt;
    &lt;head rend="h3"&gt;School Digital Surveillance Chills Student Speech and Further Harms Students&lt;/head&gt;
    &lt;p&gt;In our amicus brief, we made four main arguments against a blanket rule that categorizes any use of a school-issued device or cloud account as ‚Äúon campus,‚Äù even if the student is geographically off campus or outside of school hours.&lt;/p&gt;
    &lt;p&gt;First, we pointed out that such a rule will result in students having no reprieve from school authority, which runs counter to the Supreme Court‚Äôs admonition in Mahanoy not to regulate ‚Äúall the speech a student utters during the full 24-hour day.‚Äù There must be some place that is ‚Äúoff campus‚Äù for public school students even when using digital tools provided by schools, otherwise schools will reach too far into students‚Äô lives.&lt;/p&gt;
    &lt;p&gt;Second, we urged the court to reject such an ‚Äúon campus‚Äù rule to mitigate the chilling effect of digital surveillance on students‚Äô freedom of speech‚Äîthat is, the risk that students will self-censor and choose not to express themselves in certain ways or access certain information that may be disfavored by school officials. If students know that no matter where they are or what they are doing with their Chromebooks and Google Accounts, the school is watching and the school has greater legal authority to punish them because they are always ‚Äúon campus,‚Äù students will undoubtedly curb their speech.&lt;/p&gt;
    &lt;p&gt;Third, we argued that such an ‚Äúon campus‚Äù rule will exacerbate existing inequities in public schools among students of different socio-economic backgrounds. It would distinctly disadvantage lower-income students who are more likely to rely on school-issued devices because their families cannot afford a personal laptop or tablet. This creates a ‚Äúpay for privacy‚Äù scheme: lower-income students are subject to greater school-directed surveillance and related discipline for digital speech, while wealthier students can limit surveillance by using personal laptops and email accounts, enabling them to have more robust free speech protections.&lt;/p&gt;
    &lt;p&gt;Fourth, such an ‚Äúon campus‚Äù rule will incentivize public schools to continue eroding student privacy by subjecting them to near constant digital surveillance. The student surveillance technologies schools use are notoriously privacy invasive and inaccurate, causing various harms to students‚Äîincluding unnecessary investigations and discipline, disclosure of sensitive information, and frustrated learning.&lt;/p&gt;
    &lt;p&gt;We urge the Arizona District Court to protect public school students‚Äô freedom of speech and privacy by rejecting this approach to school-managed technology. As we said in our brief, students, especially high schoolers, need some sphere of digital autonomy, free of surveillance, judgment, and punishment, as much as anyone else‚Äîto express themselves, to develop their identities, to learn and explore, to be silly or crude, and even to make mistakes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46070151</guid><pubDate>Thu, 27 Nov 2025 15:31:55 +0000</pubDate></item><item><title>Same-day upstream Linux support for Snapdragon 8 Elite Gen 5</title><link>https://www.qualcomm.com/developer/blog/2025/10/same-day-snapdragon-8-elite-gen-5-upstream-linux-support</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46070668</guid><pubDate>Thu, 27 Nov 2025 16:19:03 +0000</pubDate></item></channel></rss>