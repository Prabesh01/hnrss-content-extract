<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 05 Nov 2025 05:40:11 +0000</lastBuildDate><item><title>Show HN: A CSS-Only Terrain Generator</title><link>https://terra.layoutit.com</link><description>&lt;doc fingerprint="109996e321a537ae"&gt;
  &lt;main&gt;
    &lt;p&gt;CSS Terrain Generator Regenerate Restart Undo Redo Import Export Heightmap CSS VOX TXT PNG Copy Embed Open Codepen Download Code move raise lower about world size ✕ ✕ landmass coverage small medium large terrain type pampas hilly alpinist biome temperate arctic desert camera settings rotate x 45° tilt y 60° zoom 50% pan x 0px lift y 0px animate reset to defaults minimap heightmap matrix v0.0.1 Regenerate&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45811093</guid><pubDate>Tue, 04 Nov 2025 13:58:35 +0000</pubDate></item><item><title>This Day in 1988, the Morris worm infected 10% of the Internet within 24 hours</title><link>https://www.tomshardware.com/tech-industry/cyber-security/on-this-day-in-1988-the-morris-worm-slithered-out-and-sparked-a-new-era-in-cybersecurity-10-percent-of-the-internet-was-infected-within-24-hours</link><description>&lt;doc fingerprint="ff40223f0be08a6f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;37 years ago this week, the Morris worm infected 10% of the Internet within 24 hours — worm slithered out and sparked a new era in cybersecurity&lt;/head&gt;
    &lt;p&gt;The Internet contracted worms a year before the World Wide Web was even a thing.&lt;/p&gt;
    &lt;p&gt;This week in 1988, Cornell graduate student Robert Tappan Morris unleashed his eponymous worm upon the Internet. The wave of infections grew to 10% of the entire Internet within 24 hours, causing astronomically expensive damage for the time. However, the pioneering Morris worm malware wasn’t made with malice, says an FBI retrospective on the “programming error.” It was designed to gauge the size of the Internet, resulting in a classic case of unintended consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Morris worm dissection&lt;/head&gt;
    &lt;p&gt;Known to be something of a prankster, Morris must have felt some foreboding about releasing his ‘innocent’ program into the wild. Evidence of this comes from his release method. “He released it by hacking into an MIT computer from his Cornell terminal in Ithaca, New York,” according to the FBI.&lt;/p&gt;
    &lt;p&gt;The Morris worm was written in C and targeted BSD UNIX systems, like VAX and Sun-3 machines. Specifically, the FBI writes, it “exploited a backdoor in the Internet’s electronic mail system and a bug in the ‘finger’ program that identified network users.” In contrast to computer viruses, the worm Morris had devised had no need of a host program, but could self-replicate and spread autonomously.&lt;/p&gt;
    &lt;p&gt;Thankfully, the Morris worm wasn’t written to cause damage to files. Due to those unintended consequences, though, it precipitated massive slowdowns, and messaging delays and system crashes were common symptoms. It became a computer news sensation in the worst possible way. Just to get rid of the worm in a timely fashion, some institutions ended up wiping complete systems and unplugging networks for as long as a week.&lt;/p&gt;
    &lt;p&gt;Among the Morris worm's casualties were prestigious institutions such as Berkeley, Harvard, Princeton, Stanford, Johns Hopkins, NASA, and the Lawrence Livermore National Laboratory.&lt;/p&gt;
    &lt;head rend="h2"&gt;Whodunit?&lt;/head&gt;
    &lt;p&gt;Experts worked hard to find a fix, and while they did so, the question of who was behind the worm came to the fore. Understandably, whoever created and unleashed this worm needed to feel some consequences, and thus, the FBI was brought in.&lt;/p&gt;
    &lt;p&gt;Apparently, Morris sought to anonymously explain and apologize for the worm, but an inadvertent slip of his initials by a friend landed Morris in it.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;FBI interviews and computer file analysis would subsequently confirm Morris was the culprit. He was indicted under the rather freshly inked Computer Fraud and Abuse Act of 1986. After a court appearance for his misdemeanors in 1989, Morris ended up not with jail time, but with a fine, probation, and 400 hours of community service to complete.&lt;/p&gt;
    &lt;head rend="h2"&gt;Computer worms have been around longer than the World Wide Web&lt;/head&gt;
    &lt;p&gt;Back in November 1988, the Internet bore little resemblance to what it is today. For example, the World Wide Web (WWW) wasn’t even a thing. Though the WWW would soon form the core experience for the first tide of surfers in the 90s.&lt;/p&gt;
    &lt;p&gt;At the time, the Internet’s backbone was the NSFNET, the recent successor to ARPANET. Its purpose was mostly to expand the prior backbone’s reach beyond military and defense institutions, and it more broadly embraced academia. While we are here, it is worth mentioning that NSFNET was decommissioned in 1995, and succeeded by the commercial Internet, which emerged in the 1990s off the back of private ISPs and commercial backbones.&lt;/p&gt;
    &lt;p&gt;So, when we talk about 10% of the Internet being paralyzed by the Morris Worm, contemporary estimates are that about 6,000 of the approximately 60,000 connected systems were infected and impacted. Moreover, when we highlighted the potentially massive costs of this first worm propagating, estimates range from $100,000 to millions of dollars.&lt;/p&gt;
    &lt;p&gt;Computer worms have remained a scary phenomenon in recent times. For example, we reported on the first-generation AI worm, the Morris II generative AI worm, last year.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;sb5k&lt;/header&gt;I was working at DEC when the worm slithered its way across the Internet, as part of an engineering team. I also helped manage our Ultrix systems; our IT department knew VMS only.Reply&lt;lb/&gt;I don't remember which CPU was in our systems, but the worm was not able to run on our systems, but I did find it dropped in them.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gaston404&lt;/header&gt;I completely disagree with the tone of the article. Depicting this as an accident without consequences and limited effect is simply incorrect.Reply&lt;lb/&gt;Back then as a part time job I managed some of the traffic routing through Washington DC. Mail relays were shutdown and backed up queues were spooked off to tape. By today’s standards the volume of traffic may seem trivial but when many of these links ran at 56kbps or less. It was a mess. The main way administrators communicated with each other was email. This also affected collaboration between University researchers and access to the NSF super computer centers.&lt;lb/&gt;At the time rumors maintained that Morris used exploits that he learned from his father who had a consulting agreement with the NSA. So if this is true there is a certain level of non-originality.&lt;lb/&gt;On one hand stronger persecution may have reduced follow on internet crime. On the other hand the fragility demonstrated by this crime, resulted in the creation of procedures to deal with outages. If anything the naive sense of trusted collaboration that pervaded the Internet started to fade.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;derekullo&lt;/header&gt;In 9 years, Tiktok has infected over 90% of the internet!Reply&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;DS426&lt;/header&gt;Reply&lt;quote/&gt;The next big social media craze is probably just around the corner. I shutter to think how ludicrous it will be.derekullo said:In 9 years, Tiktok has infected over 90% of the internet!&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45812024</guid><pubDate>Tue, 04 Nov 2025 15:23:14 +0000</pubDate></item><item><title>Pg_lake: Postgres with Iceberg and data lake access</title><link>https://github.com/Snowflake-Labs/pg_lake</link><description>&lt;doc fingerprint="fb9ba072642955ea"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; integrates Iceberg and data lake files into Postgres. With the &lt;code&gt;pg_lake&lt;/code&gt; extensions, you can use Postgres as a stand-alone lakehouse system that supports transactions and fast queries on Iceberg tables, and can directly work with raw data files in object stores like S3.&lt;/p&gt;
    &lt;p&gt;At a high level, &lt;code&gt;pg_lake&lt;/code&gt; lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create and modify Iceberg tables directly from PostgreSQL, with full transactional guarantees and query them from other engines&lt;/item&gt;
      &lt;item&gt;Query and import data from Parquet, CSV, JSON, and Iceberg files stored in S3 or other compatible object stores&lt;/item&gt;
      &lt;item&gt;Export query results back to S3 in Parquet, CSV, or JSON formats using COPY commands&lt;/item&gt;
      &lt;item&gt;Read geospatial formats supported by GDAL, such as GeoJSON and Shapefiles&lt;/item&gt;
      &lt;item&gt;Use compression transparently with .gz and .zst&lt;/item&gt;
      &lt;item&gt;Use the built-in map type for semi-structured or key–value data&lt;/item&gt;
      &lt;item&gt;Combine heap, Iceberg, and external Parquet/CSV/JSON files in the same SQL queries and modifications — all with full transactional guarantees and no SQL limitations&lt;/item&gt;
      &lt;item&gt;Infer table columns and types from external data sources such as Iceberg, Parquet, JSON, and CSV files&lt;/item&gt;
      &lt;item&gt;Leverage DuckDB’s query engine underneath for fast execution without leaving Postgres&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are two ways to set up &lt;code&gt;pg_lake&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using Docker, for an easy, ready-to-run test environment.&lt;/item&gt;
      &lt;item&gt;Building from source, for a manual setup or development use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both approaches include the PostgreSQL extensions, the &lt;code&gt;pgduck_server&lt;/code&gt; application and setting up S3-compatible storage.&lt;/p&gt;
    &lt;p&gt;Follow the Docker README to set up and run &lt;code&gt;pg_lake&lt;/code&gt; with Docker.&lt;/p&gt;
    &lt;p&gt;Once you’ve built and installed the required components, you can initialize &lt;code&gt;pg_lake&lt;/code&gt; inside Postgres.&lt;/p&gt;
    &lt;p&gt;Create all required extensions at once using &lt;code&gt;CASCADE&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;CREATE EXTENSION pg_lake CASCADE;
NOTICE:  installing required extension "pg_lake_table"
NOTICE:  installing required extension "pg_lake_engine"
NOTICE:  installing required extension "pg_extension_base"
NOTICE:  installing required extension "pg_lake_iceberg"
NOTICE:  installing required extension "pg_lake_copy"
CREATE EXTENSION&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; is a standalone process that implements the Postgres wire-protocol (locally), and underneath uses &lt;code&gt;DuckDB&lt;/code&gt; to execute queries.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;pgduck_server&lt;/code&gt; it starts listening to port &lt;code&gt;5332&lt;/code&gt; on unix domain socket:&lt;/p&gt;
    &lt;code&gt;pgduck_server
LOG pgduck_server is listening on unix_socket_directory: /tmp with port 5332, max_clients allowed 10000
&lt;/code&gt;
    &lt;p&gt;As &lt;code&gt;pgduck_server&lt;/code&gt; implements Postgres wire protocol, you can access it via &lt;code&gt;psql&lt;/code&gt; on port &lt;code&gt;5332&lt;/code&gt; and host &lt;code&gt;/tmp&lt;/code&gt; and run commands via DuckDB.&lt;/p&gt;
    &lt;p&gt;For example, you can get the DuckDB version:&lt;/p&gt;
    &lt;code&gt;psql -p 5332 -h /tmp

select version() as duckdb_version; 
duckdb_version 
---------------- 
v1.3.2 (1 row)&lt;/code&gt;
    &lt;p&gt;You can also provide some additional settings while starting the server, to see all:&lt;/p&gt;
    &lt;code&gt;pgduck_server --help
&lt;/code&gt;
    &lt;p&gt;There are some important settings that should be adjusted, especially on production systems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--memory_limit&lt;/code&gt;: Optionally specify the maximum memory of pgduck_server similar to DuckDB's memory_limit, the default is 80 percent of the system memory&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--init_file_path &amp;lt;path&amp;gt;&lt;/code&gt;: Execute all statements in this file on start-up&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cache_dir&lt;/code&gt;: Specify the directory to use to cache remote files (from S3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; relies on the DuckDB secrets manager for credentials and it follows the credentials chain by default for AWS and GCP. Make sure your cloud credentials are configured properly — for example, by setting them in ~/.aws/credentials.&lt;/p&gt;
    &lt;p&gt;Once you set up the credential chain, you should set the &lt;code&gt;pg_lake_iceberg.default_location_prefix&lt;/code&gt;. This is the location where Iceberg tables are stored:&lt;/p&gt;
    &lt;code&gt;SET pg_lake_iceberg.default_location_prefix TO 's3://testbucketpglake';&lt;/code&gt;
    &lt;p&gt;You can also set the credentials on &lt;code&gt;pgduck_server&lt;/code&gt; for local development with &lt;code&gt;minio&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can create Iceberg tables by adding &lt;code&gt;USING iceberg&lt;/code&gt; to your &lt;code&gt;CREATE TABLE&lt;/code&gt; statements.&lt;/p&gt;
    &lt;code&gt;CREATE TABLE iceberg_test USING iceberg 
      AS SELECT 
            i as key, 'val_'|| i  as val
         FROM 
            generate_series(0,99)i;&lt;/code&gt;
    &lt;p&gt;Then, query it:&lt;/p&gt;
    &lt;code&gt;SELECT count(*) FROM iceberg_test;
 count 
-------
   100
(1 row)&lt;/code&gt;
    &lt;p&gt;You can then see the Iceberg metadata location:&lt;/p&gt;
    &lt;code&gt;SELECT table_name, metadata_location FROM iceberg_tables;


    table_name     |                                                metadata_location
-------------------+--------------------------------------------------------------------------------------------------------------------
 iceberg_test      | s3://testbucketpglake/postgres/public/test/435029/metadata/00001-f0c6e20a-fd1c-4645-87c9-c0c64b92992b.metadata.json&lt;/code&gt;
    &lt;p&gt;You can import or export data directly using &lt;code&gt;COPY&lt;/code&gt; in Parquet, CSV, or newline-delimited JSON formats.  The format is automatically inferred from the file extension, or you can specify it explicitly with &lt;code&gt;COPY&lt;/code&gt; options like &lt;code&gt;WITH (format 'csv', compression 'gzip')&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;-- Copy data from Postgres to S3 with format parquet
-- Read from any data source, including iceberg tables, heap tables or any query results
COPY (SELECT * FROM iceberg_test) TO 's3://testbucketpglake/parquet_data/iceberg_test.parquet';

-- Copy back from S3 to any table in Postgres
-- This example copies into an iceberg table, but could be heap table as well
COPY iceberg_test FROM 's3://testbucketpglake/parquet_data/iceberg_test.parquet';&lt;/code&gt;
    &lt;p&gt;You can create a foreign table directly from a file or set of files without having to specify column names or types.&lt;/p&gt;
    &lt;code&gt;-- use the files under the path, can use * for all files
CREATE FOREIGN TABLE parquet_table() 
SERVER pg_lake 
OPTIONS (path 's3://testbucketpglake/parquet_data/*.parquet');

-- note that we infer the columns from the file
\d parquet_table
              Foreign table "public.parquet_table"
 Column |  Type   | Collation | Nullable | Default | FDW options 
--------+---------+-----------+----------+---------+-------------
 key    | integer |           |          |         | 
 val    | text    |           |          |         | 
Server: pg_lake
FDW options: (path 's3://testbucketpglake/parquet_data/*.parquet')

-- and, query it
select count(*) from parquet_table;
 count 
-------
   100
(1 row)
&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;pg_lake&lt;/code&gt; instance consists of two main components: PostgreSQL with the pg_lake extensions and pgduck_server.&lt;/p&gt;
    &lt;p&gt;Users connect to PostgreSQL to run SQL queries, and the &lt;code&gt;pg_lake&lt;/code&gt; extensions integrate with Postgres’s hooks to handle query planning, transaction boundaries, and overall orchestration of execution.&lt;/p&gt;
    &lt;p&gt;Behind the scenes, parts of query execution are delegated to DuckDB through pgduck_server, a separate multi-threaded process that implements the PostgreSQL wire protocol (locally). This process runs DuckDB together with our duckdb_pglake extension, which adds PostgreSQL-compatible functions and behavior.&lt;/p&gt;
    &lt;p&gt;Users typically don’t need to be aware of &lt;code&gt;pgduck_server&lt;/code&gt;; it operates transparently to improve performance. When appropriate, &lt;code&gt;pg_lake&lt;/code&gt; delegates scanning of the data and the computation to DuckDB’s highly parallel, column-oriented execution engine.&lt;/p&gt;
    &lt;p&gt;This separation also avoids the threading and memory-safety limitations that would arise from embedding DuckDB directly inside the Postgres process, which is designed around process isolation rather than multi-threaded execution. Moreover, it lets us interact with the query engine directly by connecting to it using standard Postgres clients.&lt;/p&gt;
    &lt;p&gt;The team behind pg_lake has a lot of experience building Postgres extensions (e.g. Citus, pg_cron, pg_documentdb). Over time, we’ve learned that large, monolithic PostgreSQL extensions are harder to evolve and maintain.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; follows a modular design built around a set of interoperating components — mostly implemented as PostgreSQL extensions, others as supporting services or libraries.&lt;lb/&gt; Each part focuses on a well-defined layer, such as table and metadata management, catalog and object store integration, query execution, or data format handling. This approach makes it easier to extend, test, and evolve the system, while keeping it familiar to anyone with a PostgreSQL background.&lt;/p&gt;
    &lt;p&gt;The current set of components are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pg_lake_iceberg: a PostgreSQL extension that implements the Iceberg specification&lt;/item&gt;
      &lt;item&gt;pg_lake_table: a PostgreSQL extension that implements a foreign data wrapper to query files in object storage&lt;/item&gt;
      &lt;item&gt;pg_lake_copy: a PostgreSQL extension that implements COPY to/from your data lake&lt;/item&gt;
      &lt;item&gt;pg_lake_engine: a common module for different pg_lake extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_base: A foundational building block for other extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_updater: An extension for updating all extensions on start-up. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_lake_benchmark: a PostgreSQL extension that performs various benchmarks on lake tables. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_map: A generic map type generator&lt;/item&gt;
      &lt;item&gt;pgduck_server: a stand-alone server that loads DuckDB into the same server machine and exposes DuckDB via the PostgreSQL protocol&lt;/item&gt;
      &lt;item&gt;duckdb_pglake: a DuckDB extension that adds missing PostgreSQL functions to DuckDB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; development started in early 2024 at Crunchy Data with the goal of bringing Iceberg to PostgreSQL. The first few months were focused on building a robust integration of an external query engine (DuckDB). To get to market early, we made the query/import/export features available to Crunchy Bridge customers as Crunchy Bridge for Analytics.&lt;/p&gt;
    &lt;p&gt;Next, we started building a comprehensive implementation of the Iceberg (v2) protocol with support for transactions and almost all PostgreSQL features. In November 2024, we relaunched Crunchy Bridge for Analytics as Crunchy Data Warehouse available on Crunchy Bridge and on-premises.&lt;/p&gt;
    &lt;p&gt;In June 2025, Crunchy Data was acquired by Snowflake. Following the acquisition, Snowflake decided to open source the project as &lt;code&gt;pg_lake&lt;/code&gt; in November 2025. The initial version is 3.0 because of the two prior generations. If you’re currently a Crunchy Data Warehouse user there will be an automatic upgrade path, though some names will change.&lt;/p&gt;
    &lt;p&gt;Full project documentation can be found in the docs directory.&lt;/p&gt;
    &lt;p&gt;Copyright (c) Snowflake Inc. All rights reserved. Licensed under the Apache 2.0 license.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; is dependent on third-party projects Apache Avro and DuckDB. During build, &lt;code&gt;pg_lake&lt;/code&gt; applies patches to Avro and certain DuckDB extensions in order to provide the &lt;code&gt;pg_lake&lt;/code&gt; functionality. The source code associated with the Avro and DuckDB extensions is downloaded from the applicable upstream repos and the source code associated with those projects remains under the original licenses. If you are packaging or redistributing packages that include &lt;code&gt;pg_lake&lt;/code&gt;, please note that you should review those upstream license terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45812606</guid><pubDate>Tue, 04 Nov 2025 16:12:27 +0000</pubDate></item><item><title>Launch HN: Plexe (YC X25) – Build production-grade ML models from prompts</title><link>https://www.plexe.ai/</link><description>&lt;doc fingerprint="d1d50ecbdfaae78"&gt;
  &lt;main&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;Your Agentic ML Engineering&lt;/p&gt;
    &lt;p&gt;Team&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your raw data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and it will build a production-ready model thatâs engineered for your exact business challenge.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Plexe AI Redefines Credit Underwriting With Real-Time ML Models&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your data into your competitive advantage.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45813310</guid><pubDate>Tue, 04 Nov 2025 17:07:47 +0000</pubDate></item><item><title>NoLongerEvil-Thermostat – Nest Generation 1 and 2 Firmware</title><link>https://github.com/codykociemba/NoLongerEvil-Thermostat</link><description>&lt;doc fingerprint="1eabf0080969b3e8"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;WARNING: EXPERIMENTAL SOFTWARE&lt;p&gt;This project is currently in the experimental/testing phase. Do NOT use this firmware on any thermostat that is critical for your heating or cooling needs. Flashing this firmware may brick your device or cause unexpected behavior. Only proceed if you have a backup thermostat or can afford to have your device non-functional during testing.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;This directory contains the tools and firmware needed to flash custom firmware to Nest Thermostat devices using the OMAP DFU (Device Firmware Update) interface.&lt;/p&gt;
    &lt;p&gt;This firmware loader uses the OMAP bootloader interface to flash custom bootloader and kernel images to Nest Thermostat devices. The device must be put into DFU mode to accept new firmware.&lt;/p&gt;
    &lt;p&gt;Important: After flashing this firmware, your device will no longer contact Nest/Google servers. It will operate independently and connect to the NoLongerEvil platform instead, giving you complete control over your thermostat.&lt;/p&gt;
    &lt;p&gt;The custom firmware flashes the device with modified bootloader and kernel components that redirect all network traffic from the original Nest/Google servers to a server we specify. This server hosts a reverse-engineered replica of their API, allowing the thermostat to function independently while giving you complete control over your device data and settings.&lt;/p&gt;
    &lt;p&gt;By intercepting the communication layer, the thermostat believes it's communicating with the official Nest infrastructure, but instead connects to the NoLongerEvil platform. This approach ensures full compatibility with the device's existing software while breaking free from Google's cloud dependency.&lt;/p&gt;
    &lt;code&gt;git clone --recurse-submodules https://github.com/codykociemba/NoLongerEvil-Thermostat.git
cd NoLongerEvil-Thermostat&lt;/code&gt;
    &lt;p&gt;Before building, you'll need to install some required packages:&lt;/p&gt;
    &lt;code&gt;sudo apt-get update
sudo apt-get install build-essential libusb-1.0-0-dev gcc pkg-config&lt;/code&gt;
    &lt;p&gt;First, install Xcode Command Line Tools:&lt;/p&gt;
    &lt;code&gt;xcode-select --install&lt;/code&gt;
    &lt;p&gt;Then install libusb using Homebrew (the build script will attempt to install this automatically if missing):&lt;/p&gt;
    &lt;code&gt;# Install Homebrew if you don't have it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install libusb
brew install libusb&lt;/code&gt;
    &lt;code&gt;chmod +x build.sh
./build.sh&lt;/code&gt;
    &lt;p&gt;The build script will automatically detect your operating system (Linux, macOS, or Windows) and build the appropriate binary.&lt;/p&gt;
    &lt;p&gt;IMPORTANT: You must start the installer script BEFORE rebooting the device.&lt;/p&gt;
    &lt;code&gt;chmod +x install.sh
./install.sh&lt;/code&gt;
    &lt;code&gt;chmod +x install.sh
./install.sh&lt;/code&gt;
    &lt;p&gt;Note for macOS: You may need to grant USB permissions. If you encounter permission issues, check System Preferences → Security &amp;amp; Privacy.&lt;/p&gt;
    &lt;p&gt;The script will wait for the device to enter DFU mode.&lt;/p&gt;
    &lt;p&gt;Follow these steps carefully:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Charge the device - Ensure your Nest Thermostat is properly charged (at least 50% battery recommended)&lt;/item&gt;
      &lt;item&gt;Remove from wall - Remove the Nest from its back plate/wall mount&lt;/item&gt;
      &lt;item&gt;Connect via USB - Plug the Nest into your computer using a micro USB cable&lt;/item&gt;
      &lt;item&gt;Wait for the installer - Make sure the &lt;code&gt;install.sh&lt;/code&gt;script is running and waiting&lt;/item&gt;
      &lt;item&gt;Reboot the device - Press and hold down on the display for 10-15 seconds until the device reboots&lt;/item&gt;
      &lt;item&gt;DFU mode active - Once it reboots, the device will enter DFU mode and the installer script will recognize it and begin flashing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The firmware installer will automatically detect the device and flash the custom bootloader (x-load, u-boot) and kernel (uImage).&lt;/p&gt;
    &lt;p&gt;After the firmware is flashed successfully, you should see our logo on the device screen:&lt;/p&gt;
    &lt;p&gt;Important:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Keep the device plugged in via USB&lt;/item&gt;
      &lt;item&gt;Wait for the device to complete its boot sequence (this may take 3-4 minutes)&lt;/item&gt;
      &lt;item&gt;Do not disconnect or power off the device during this time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once the device has fully rebooted:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Visit https://nolongerevil.com in your web browser&lt;/item&gt;
      &lt;item&gt;Register an account (or sign in if you already have one)&lt;/item&gt;
      &lt;item&gt;Navigate to your Dashboard&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You will see a "No devices" screen that prompts you for an entry code.&lt;/p&gt;
    &lt;p&gt;To link your Nest device to your NoLongerEvil account:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;On your Nest device, navigate to: Settings → Nest App → Get Entry Code&lt;/item&gt;
      &lt;item&gt;The device will display a unique entry code&lt;/item&gt;
      &lt;item&gt;Enter this code on the NoLongerEvil dashboard&lt;/item&gt;
      &lt;item&gt;Your device is now linked and ready to use!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The firmware installation process installs three components:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;x-load.bin - First-stage bootloader (X-Loader for OMAP)&lt;/item&gt;
      &lt;item&gt;u-boot.bin - Second-stage bootloader (Das U-Boot) loaded at address 0x80100000&lt;/item&gt;
      &lt;item&gt;uImage - Linux kernel image loaded at address 0x80A00000&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After flashing, the device jumps to execution at 0x80100000 (u-boot).&lt;/p&gt;
    &lt;p&gt;This tool provides low-level access to the device's boot process. Use responsibly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only use on devices you own&lt;/item&gt;
      &lt;item&gt;Improper firmware can brick your device (Don't sue me bro)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project builds upon the excellent work of several security researchers and developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;grant-h / ajb142 - omap_loader, the USB bootloader tool used to flash OMAP devices&lt;/item&gt;
      &lt;item&gt;exploiteers (GTVHacker) - Original research and development of the Nest DFU attack, which demonstrated the ability to flash custom firmware to Nest devices gen 1 &amp;amp; gen 2&lt;/item&gt;
      &lt;item&gt;FULU and all bounty backers - For funding the Nest Learning Thermostat Gen 1/2 bounty and supporting the right-to-repair movement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Without their groundbreaking research, open-source contributions, and advocacy for device ownership rights, this work would not be possible. Thank you!&lt;/p&gt;
    &lt;p&gt;We are committed to transparency and the right-to-repair movement. The firmware images and backend API server code will be open sourced soon, allowing the community to audit, improve, and self-host their own infrastructure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45813343</guid><pubDate>Tue, 04 Nov 2025 17:10:35 +0000</pubDate></item><item><title>Codemaps: Understand Code, Before You Vibe It</title><link>https://cognition.ai/blog/codemaps</link><description>&lt;doc fingerprint="3fc296052cb3ae5f"&gt;
  &lt;main&gt;
    &lt;quote&gt;“Your code is your understanding of the problem you’re exploring. So it’s only when you have your code in your head that you really understand the problem.” — Paul Graham&lt;/quote&gt;
    &lt;p&gt;Software development only becomes engineering with understanding. Your ability to reason through your most challenging coding tasks is constrained by your mental model of how things work — in other words, how quickly and how well you onboard to any codebase for solving any problem. However most AI vibe coding tools are aimed at relieving you of that burden by reading → thinking → writing the code for you, increasing the separation from you and your code. This is fine for low value, commodity tasks, but absolutely unacceptable for the hard, sensitive, and high value work that defines real engineering.&lt;/p&gt;
    &lt;p&gt;We all need more AI that turns your brain ON, not OFF.&lt;/p&gt;
    &lt;p&gt;Today we are announcing Windsurf Codemaps, which are first-of-its-kind AI-annotated structured maps of your code, powered by SWE-1.5 and Claude Sonnet 4.5. Building on our popular work from DeepWiki and Ask Devin, Codemaps is the next step in hyper-contextualized codebase understanding, grounded in precise code navigation.&lt;/p&gt;
    &lt;p&gt;Every engineering task — debugging, refactors, new features — starts with understanding. Great engineers aren’t just good at writing code; they’re good at reading it, building mental models that span files, layers, and systems.&lt;/p&gt;
    &lt;p&gt;But modern codebases are sprawling: hundreds of files, multiple services, dense abstractions. Based on own experience and deep conversations with our customers across the Fortune 500, even top engineers spend much of their deep-work time finding and remembering what matters.&lt;/p&gt;
    &lt;p&gt;It’s a huge tax on productivity:&lt;/p&gt;
    &lt;p&gt;This is the frontier that AI coding tools haven’t yet solved. Onboarding isn’t even a onetime cost, you pay it every time you switch context and codebases. The faster and better you understand your codebase, the faster and better you’ll be able to fix it yourself, or prompt agents to do it.&lt;/p&gt;
    &lt;p&gt;Until today, the standard approach by Copilot, Claude Code, Codex, and even Windsurf Cascade, was to have you ask questions of a generalist agent with access to your code in a typical chat experience. But those solutions don’t solve focused onboarding and strongly grounded navigation to onboard, debug, and better context engineer for your codebase.&lt;/p&gt;
    &lt;p&gt;At Cognition, we’ve been investing far more deeply in understanding:&lt;/p&gt;
    &lt;p&gt;Codemaps is our next investment in tooling that makes engineers the best versions of themselves.&lt;/p&gt;
    &lt;p&gt;When you first open Codemaps (click the new maps icon or Cmd+Shift+C in Windsurf) with a codebase opened in Windsurf, you can enter in a prompt for the task you are trying to do, or take one of the automatic suggestions. You can choose a Fast (SWE-1.5) or Smart (Sonnet 4.5) model to generate your Codemap. Every Codemap is a snapshot of your code and respects ZDR.&lt;/p&gt;
    &lt;p&gt;Based on our demos to customers, you will experience Codemaps best on your own codebase and asking a question about how or where some functionality works. In our dogfooding, we find particular effectiveness tracing through client-server problems or a data pipeline or debugging auth/security issues:&lt;/p&gt;
    &lt;p&gt;If all you wanted was to quickly jump through grouped and nested parts of your code that related to your question, this is already an improvement compared to asking the same question in Cascade, where answers are not as densely linked to the exact lines of code.&lt;/p&gt;
    &lt;p&gt;You can also toggle over to a visually drawn Codemap, which performs the same functions when you click on individual nodes: they send you to the exact part of the codebase you clicked on.&lt;/p&gt;
    &lt;p&gt;However, if you want a little more context, then you can hit “See more” in any section to expand our “trace guide” that gives a more descriptive explanation of what groups the discovered lines together.&lt;/p&gt;
    &lt;p&gt;Finally, inside Cascade you can also reference a codemap for the agent with &lt;code&gt;@{codemap}&lt;/code&gt; (all of it, or a particular subsection) in your prompt to provide more specific context and dramatically improve the performance of your agent for your task.&lt;/p&gt;
    &lt;p&gt;We feel that the popular usage of “vibe coding” has strayed far from the original intent, into a blanket endorsement of plowing through any and all AI generated code slop. If you look at the difference between the most productive vs the problematic AI-assisted coders, the productive ones can surf the vibes of code that they understand well, whereas people get into trouble when the code they generate and maintain starts to outstrip their ability to understand it.&lt;/p&gt;
    &lt;p&gt;To understand is to be accountable. As AI takes on more of the easy work, the hard problems left to humans are the ones that demand real comprehension: debugging complex systems, refactoring legacy code, making architecture decisions. In this new era, the engineer’s role shifts from authoring to accountability — you might not write every line, but you’re still responsible for what ships. That accountability depends on understanding what the AI produced, why it changed, and whether it’s safe. Codemaps closes that gap by giving both the human and the AI a shared picture of the system: how it’s structured, how data flows, where dependencies live. Codemaps is our latest Fast Agent, but as we discussed in the Semi-Async Valley of Death, our goal isn't just about speed, it is to help your human engineers stay in flow, stay on top of their code, and to move faster and more confidently on the hardest problems, never shipping slop that they don't understand.&lt;/p&gt;
    &lt;p&gt;Augment engineers for high value work, relieve them of low value work. The other local minima that the coding agent industry has gotten stuck in is in the general messaging of replacing engineers for low value work and not having any solutions for the hardest tasks apart from “pls ultrathink high, no mistakes”, which only gives autonomy to the agent, at the expense of the engineer. The long history of human-machine collaboration teaches us that we can always do more with the synergy rather than humans-alone or AI-alone. Our view is that the AI product that engineers will love most is the one that makes them better at their job, not the one that tries to replace them with a sloppy facsimile of themselves.&lt;/p&gt;
    &lt;p&gt;With Codemaps, we are now exposing to humans some of the indexing and analysis we do inside of our coding agents. These artifacts are sharable today across teams for learning and discussion, but we have yet to benchmark how much better they can make our coding agents like Devin and Cascade in solving challenging tasks on their own. We also see opportunities for connecting and annotating codemaps, as well as defining an open &lt;code&gt;.codemap&lt;/code&gt; protocol that can be used by other code agents and custom tooling built by you. Complementing our Fast Context feature, this is an advancement in human-readable automatic context engineering.&lt;/p&gt;
    &lt;p&gt;You can try Codemaps on the latest versions of Windsurf, or DeepWiki!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45813767</guid><pubDate>Tue, 04 Nov 2025 17:47:09 +0000</pubDate></item><item><title>I took all my projects off the cloud, saving thousands of dollars</title><link>https://rameerez.com/send-this-article-to-your-friend-who-still-thinks-the-cloud-is-a-good-idea/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816041</guid><pubDate>Tue, 04 Nov 2025 21:22:15 +0000</pubDate></item><item><title>Grayskull: A tiny computer vision library in C for embedded systems, etc.</title><link>https://github.com/zserge/grayskull</link><description>&lt;doc fingerprint="6e340ed9bad71609"&gt;
  &lt;main&gt;
    &lt;p&gt;Grayskull is a minimalist, dependency-free computer vision library designed for microcontrollers and other resource-constrained devices. It focuses on grayscale images and provides modern, practical algorithms that fit in a few kilobytes of code. Single-header design, integer-based operations, pure C99.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Image operations: copy, crop, resize (bilinear), downsample&lt;/item&gt;
      &lt;item&gt;Filtering: blur, Sobel edges, thresholding (global, Otsu, adaptive)&lt;/item&gt;
      &lt;item&gt;Morphology: erosion, dilation&lt;/item&gt;
      &lt;item&gt;Geometry: connected components, perspective warp&lt;/item&gt;
      &lt;item&gt;Features: FAST/ORB keypoints and descriptors (object tracking)&lt;/item&gt;
      &lt;item&gt;Local binary patterns: LBP cascades to detect faces, vehicles etc&lt;/item&gt;
      &lt;item&gt;Utilities: PGM read/write&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As usual, no dependencies, no dynamic memory allocation, no C++, no surprises. Just a single header file under 1KLOC.&lt;/p&gt;
    &lt;p&gt;Check out the examples folder for more!&lt;/p&gt;
    &lt;p&gt;Online demo: try Grayskull in your browser.&lt;/p&gt;
    &lt;code&gt;#include "grayskull.h"

struct gs_image img = gs_read_pgm("input.pgm");
struct gs_image blurred = gs_alloc(img.w, img.h);
struct gs_image binary = gs_alloc(img.w, img.h);

gs_blur(blurred, img, 2);
gs_threshold(binary, blurred, gs_otsu_theshold(blurred));

gs_write_pgm(binary, "output.pgm");
gs_free(img);
gs_free(blurred);
gs_free(binary);&lt;/code&gt;
    &lt;p&gt;Note that &lt;code&gt;gs_alloc&lt;/code&gt;/&lt;code&gt;gs_free&lt;/code&gt; are optional helpers; you can allocate image pixel buffers any way you like.&lt;/p&gt;
    &lt;code&gt;struct gs_image { unsigned w, h; uint8_t *data; };
struct gs_rect { unsigned x, y, w, h; }; // ROI
struct gs_point { unsigned x, y; }; // corners

uint8_t gs_get(struct gs_image img, unsigned x, unsigned y);
void gs_set(struct gs_image img, unsigned x, unsigned y, uint8_t value);
void gs_crop(struct gs_image dst, struct gs_image src, struct gs_rect roi);
void gs_copy(struct gs_image dst, struct gs_image src);
void gs_resize(struct gs_image dst, struct gs_image src);
void gs_downsample(struct gs_image dst, struct gs_image src);

// Thresholding
void gs_histogram(struct gs_image img, unsigned hist[256]);
void gs_threshold(struct gs_image img, uint8_t threshold);
uint8_t gs_otsu_threshold(struct gs_image img);
void gs_adaptive_threshold(struct gs_image dst, struct gs_image src, unsigned radius, int c);

// Filters
void gs_blur(struct gs_image dst, struct gs_image src, unsigned radius);
void gs_erode(struct gs_image dst, struct gs_image src);
void gs_dilate(struct gs_image dst, struct gs_image src);
void gs_sobel(struct gs_image dst, struct gs_image src);

// Blobs (connected components) and contours
typedef uint16_t gs_label;
struct gs_blob { gs_label label; unsigned area; struct gs_rect box; struct gs_point centroid; };
struct gs_contour { struct gs_rect box; struct gs_point start; unsigned length; };
unsigned gs_blobs(struct gs_image img, gs_label *labels, struct gs_blob *blobs, unsigned nblobs);
void gs_blob_corners(struct gs_image img, gs_label *labels, struct gs_blob *b, struct gs_point c[4]);
void gs_perspective_correct(struct gs_image dst, struct gs_image src, struct gs_point c[4]);
void gs_trace_contour(struct gs_image img, struct gs_image visited, struct gs_contour *c);

// FAST/ORB
struct gs_keypoint { struct gs_point pt; unsigned response; float angle; uint32_t descriptor[8]; };
struct gs_match { unsigned idx1, idx2; unsigned distance; };
unsigned gs_fast(struct gs_image img, struct gs_image scoremap, struct gs_keypoint *kps, unsigned nkps, unsigned threshold);
float gs_compute_orientation(struct gs_image img, unsigned x, unsigned y, unsigned r);
void gs_brief_descriptor(struct gs_image img, struct gs_keypoint *kp);
unsigned gs_orb_extract(struct gs_image img, struct gs_keypoint *kps, unsigned nkps, unsigned threshold, uint8_t *scoremap_buffer);
unsigned gs_match_orb(const struct gs_keypoint *kps1, unsigned n1, const struct gs_keypoint *kps2, unsigned n2, struct gs_match *matches, unsigned max_matches, float max_distance);

// LBP cascades
struct gs_lbp_cascade { uint16_t window_w, window_h; uint16_t nfeatures, nweaks, nstages; const int8_t *features; /* [nfeatures * 4] */ const uint16_t *weak_feature_idx; const float *weak_left_val, *weak_right_val; const uint16_t *weak_subset_offset, *weak_num_subsets; const int32_t *subsets; const uint16_t *stage_weak_start, *stage_nweaks; const float *stage_threshold; };
void gs_integral(struct gs_image src, unsigned *ii);
unsigned gs_lbp_window(const struct gs_lbp_cascade *c, const unsigned *ii, unsigned iw, unsigned ih, int x, int y, float scale);
unsigned gs_lbp_detect(const struct gs_lbp_cascade *c, const unsigned *ii, unsigned iw, unsigned ih, struct gs_rect *rects, unsigned max_rects, float scale_factor, float min_scale, float max_scale, int step);

// Optional:
struct gs_image gs_alloc(unsigned w, unsigned h);
void gs_free(struct gs_image img);
struct gs_image gs_read_pgm(const char *path);
int gs_write_pgm(struct gs_image img, const char *path);&lt;/code&gt;
    &lt;p&gt;This project is licensed under the MIT License. Feel free to use in research, products, and your next embedded vision project!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816673</guid><pubDate>Tue, 04 Nov 2025 22:35:58 +0000</pubDate></item><item><title>Mr Tiff</title><link>https://inventingthefuture.ghost.io/mr-tiff/</link><description>&lt;doc fingerprint="6498b19bb326a2bd"&gt;
  &lt;main&gt;
    &lt;p&gt;For as long as I have published my books, one of my overarching goals was to give credit to those who actually invented the hardware and software that we use.&lt;/p&gt;
    &lt;p&gt;I have spent 10,000+ hours to create an accurate record of their work but I'm not complaining. The 'as-close-to-possible' truth of invention by individuals or teams meant identifying the work, educating myself, writing questions, and sending emails. And after that process, I set up a chat because it all gets down to talking to someone on the other side of the world, about something that happened 30 or 40 years ago.&lt;/p&gt;
    &lt;p&gt;If the invention involves a team, I try to interview more than one person, so I can cross-check the facts. Not to call anyone out, it’s just that, given time, we all forget the facts. And everyone adds their personal take. It’s because of that, for example, that I know the English musician Peter Gabriel really did visit Apple's research labs as they tested the Apple Sound Chip, and gave the team his personal approval to use the song 'Red Rain' for the Macintosh II launch. Wil Oxford, Steve Perlman, Mike Potel, Mark Lentczner and Steve Milne told me so.&lt;/p&gt;
    &lt;p&gt;As I was wrapping up Version 2.3 of Inventing the Future, I spoke with Steve M and Mark about the AIFF (Audio Interchange File Format) audio standard that they built around the same time as their VIP visit. They did so as professional programmers, amateur musicians and electronic music experts. Milne and Lentczner knew users needed a standard file format to make their work lives easier and to fend off confusion in the nascent MIDI marketplace. But it didn't exist. So Steve and Mark consulted with users and manufacturers in the Apple cafeteria after hours. This work is interesting on its own but it also underpinned other research. The AIFF, Apple Sound Chip, and MIDI Manager work scaffolded QuickTime and its extensible video formats and programs in 1991. Senior engineer Toby Farrand told me:&lt;/p&gt;
    &lt;p&gt;Audio drove the development of QuickTime more than anything.&lt;/p&gt;
    &lt;p&gt;So who or what drove the development of AIFF?&lt;/p&gt;
    &lt;p&gt;Steve and Mark referred me to the IFF (Interchange File Format (IFF) and the TIFF (Tag Image File Format) that were built before AIFF, in 1985 and 1986 respectively. These file formats were the benchmark for open media standards. My search pivoted, as it always does, to understand those inventions. I expected to be able to find the engineer or engineers names, track them down and interview them. It has worked around 100 times before.&lt;/p&gt;
    &lt;p&gt;Jerry Morrison created IFF while working at Electronic Arts and then went to Apple, where he liaised with the AIFF team. I could easily background his work.&lt;/p&gt;
    &lt;p&gt;So I turned my attention to TIFF, built initially as an image standard for desktop publishing. TIFF was able to store monochrome, grayscale, and color images, alongside metadata such as size, compression algorithms, and color space information. In many ways, it was a lot like AIFF so I was keen to know more. But I couldn't find a TIFF creator. No matter how I enquired, Aldus created TIFF.&lt;/p&gt;
    &lt;p&gt;To be clear, while a search for AIFF will offer up a company (Apple) not a person, I was able to find Milne and Lentczner in part because of their unique names and because Apple publicised the AIFF work and those publications are archived.&lt;/p&gt;
    &lt;p&gt;All I had was Aldus, an American company that created desktop publishing with the help of Apple and Adobe. In fact, Paul Brainerd, the cofounder of Aldus coined the term 'desktop publishing' to quickly explain the technicality of what they were doing to potential investors. But Aldus and their seminal product, PageMaker, are long gone, and there were no breadcrumbs for TIFF's creation.&lt;/p&gt;
    &lt;p&gt;Finally, after a day-long trawl through MacWeek back issues, I found Steve Carlson. (below)&lt;/p&gt;
    &lt;p&gt;Then I ran a similar length search through the Computer History Museum’s amazing Oral Histories transcriptions. Brainerd mentioned Carlson's name in an interview. (below)&lt;/p&gt;
    &lt;p&gt;But it was too brief an explanation so I kept looking. Then the trail went cold.&lt;/p&gt;
    &lt;p&gt;And that was because, folks had misspelt his name when quoting him and then that was copied into magazines, and reviews and so forth. Brainerd's CHM interview transcript was wrong. But I didn’t know that.&lt;/p&gt;
    &lt;p&gt;I just kept looking for Steve Carlson.&lt;/p&gt;
    &lt;p&gt;I found other inventors because they had unique middle or last names or by random methods such as searching glider pilot licences in the Napa Valley after a tip from a former colleague that 'so and so' was a pilot in retirement. I had no tips, no links, nothing.&lt;/p&gt;
    &lt;p&gt;Why couldn’t I find Steve Carlson?&lt;/p&gt;
    &lt;p&gt;All the while, the answer was right under my nose. I had downloaded the final Aldus TIFF specifications document, hoping to find the author’s name. However, the name is seemingly written in white text on white paper - making it invisible. What?&lt;/p&gt;
    &lt;p&gt;See below where I have highlighted the region with a blue block over the text.&lt;/p&gt;
    &lt;p&gt;For a reason I can’t recall, I downloaded a plain text version and typed in Carlson to see if he was mentioned, but I must have paused at ‘Carls...' and the search functionality automatically filled in the rest. Suddenly I was staring at:&lt;/p&gt;
    &lt;p&gt;Author/Editor/Arbitrator: Steve Carlsen.&lt;/p&gt;
    &lt;p&gt;‘Carls-EN’&lt;/p&gt;
    &lt;p&gt;A quick trip to Google patents, and a search for Steve Carlsen, Stephen Carlsen. Bingo! Stephen E. Carlsen’s patents at Aldus (and Adobe) in Issaquah, WA.&lt;/p&gt;
    &lt;p&gt;I checked the geography, as most folks of a certain age do not stray far from the addresses filed in their patents, and typed Stephen’s correctly spelled surname into the online US White Pages for Washington State. There was ‘a’ Stephen Carlsen listed in a retirement village in WA. His age matched, but there were no public facing email addresses.&lt;/p&gt;
    &lt;p&gt;I searched bulletin boards on the topic of TIFF, as I had found a former Apple engineer that way. Don had picked an abbreviation of his initials and numbers to post on BBS in his college days and then carried that same combination into adulthood. Many of us did. I took a punt pasting his unique prefix into hotmail, gmail etc. and found Don and interviewed him, but - Stephen Carlsen did not show up in a BBS. So, no email to try.&lt;/p&gt;
    &lt;p&gt;My ‘last straw' method for finding someone is a stamped envelope. I wrote, printed and mailed a one-page letter to Stephen's listed address, and crossed my fingers. Four months later he popped up in my email.&lt;/p&gt;
    &lt;p&gt;It was a surprise and a relief. We swapped a few emails, and he confirmed the TIFF catalyst story. For Stephen it was 'no big deal'. Once he had built the initial TIFF, Aldus needed to convince 3rd party developers and scanner manufacturers to agree to TIFF as a standard.&lt;/p&gt;
    &lt;p&gt;“We had to define and promote an industry standard for storing and processing scanned images, so that we wouldn't have to write import filters for every model of every scanner that would soon be entering the budding desktop scanner market."&lt;/p&gt;
    &lt;p&gt;Stephen himself did much of the evangelizing as Paul Brainerd later pointed out:&lt;/p&gt;
    &lt;p&gt;“(Steve) developed the standard, and then we went out and promoted it in a series of meetings with specific companies - as well as some workshops we ran in Seattle and the Bay Area during the Seybold shows and the MacWorld shows.”&lt;/p&gt;
    &lt;p&gt;I sent Stephen a draft of what I had written and he sent a prompt reply saying - ‘Looks good’.&lt;/p&gt;
    &lt;p&gt;I followed up asking him how he ended up at a tiny startup in Seattle called Aldus.&lt;/p&gt;
    &lt;p&gt;At that time, I was interviewing for a graphics position at Boeing Computer Services in Seattle, and noticed a small wanted ad that sounded really interesting, and seemed to be an excellent match for my background and interests. I interviewed with Paul and the 5-person mostly-ex-Atex engineering team, and I was hired.&lt;/p&gt;
    &lt;p&gt;Out of curiosity I put Stephen's email address, now that I knew it, into a Duck Duck search and found him helping people online with TIFF queries long after Aldus had been acquired by Adobe. He also contributed to a Google Group called tiffcentral.&lt;/p&gt;
    &lt;p&gt;Having interviewed so many people across more than a decade, I’ve got pretty good at judging those who would like to talk or type, those who are verbose and those that are not. I knew Stephen had said what he was going to say. I added his pioneering work on TIFF to the AIFF story and moved on.&lt;/p&gt;
    &lt;p&gt;Two years had flown by when I received an email yesterday. His ex-wife Peggy found my paper letter and wrote to me. Stephen passed away earlier this year.&lt;/p&gt;
    &lt;p&gt;Thank you for your interest in and support of Stephen’s brilliant work creating TIFF. I’m not surprised Stephen didn’t finish corresponding with you, as he had begun to struggle with using his computer and phone. Some days were better than others for him, but he began to lose touch with people during those months you were reaching out to him. He was a humble man, and I guess never pushed to be recognized, although I believe those who worked with him knew the truth. His last week was in my home, where he was never left alone.&lt;/p&gt;
    &lt;p&gt;Peggy finished the email with, ‘I called him Mr TIFF up to his last moment.'&lt;/p&gt;
    &lt;p&gt;The 10,000+ hours of book research disappeared in an instant. As sad as it was, I could see clearly that all of my work was worth it. Every single second. Because of this email.&lt;/p&gt;
    &lt;p&gt;Mr TIFF.&lt;/p&gt;
    &lt;p&gt;Last night, as everyone in my house went to sleep, I took a deep breath and edited the Wikipedia page for TIFF, the Tag Image File Format.&lt;/p&gt;
    &lt;p&gt;It no longer reads ‘created by Aldus’, it reads ‘…created by Stephen Carlsen, an engineer at Aldus'&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816853</guid><pubDate>Tue, 04 Nov 2025 22:57:12 +0000</pubDate></item><item><title>Patching 68K Software – SimpleText</title><link>https://tinkerdifferent.com/threads/patching-68k-software-simpletext.4793/</link><description>&lt;doc fingerprint="b2497ef403174708"&gt;
  &lt;main&gt;
    &lt;p&gt;Someone asked to have SimpleText open a smaller text window at startup. Initially, I assumed this would be a fairly easy fix by just overwriting a few constant values in SimpleText code. It turned out to be a pain -- but I learned a lot along the way.&lt;lb/&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;lb/&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;lb/&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;lb/&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;lb/&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;lb/&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;lb/&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;lb/&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;lb/&gt;A couple of other tricks.&lt;lb/&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;lb/&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;lb/&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;lb/&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;lb/&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;lb/&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;lb/&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;lb/&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;lb/&gt;Attached is the hacked version of SimpleText.&lt;lb/&gt;- David&lt;/p&gt;
    &lt;p&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;/p&gt;
    &lt;p&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;/p&gt;
    &lt;p&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;/p&gt;
    &lt;p&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;/p&gt;
    &lt;p&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;/p&gt;
    &lt;p&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;/p&gt;
    &lt;p&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;/p&gt;
    &lt;p&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;/p&gt;
    &lt;p&gt;A couple of other tricks.&lt;/p&gt;
    &lt;p&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;/p&gt;
    &lt;p&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;/p&gt;
    &lt;p&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;/p&gt;
    &lt;p&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;/p&gt;
    &lt;p&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;/p&gt;
    &lt;p&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;/p&gt;
    &lt;p&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;/p&gt;
    &lt;p&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;/p&gt;
    &lt;p&gt;Attached is the hacked version of SimpleText.&lt;/p&gt;
    &lt;p&gt;- David&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816879</guid><pubDate>Tue, 04 Nov 2025 22:59:22 +0000</pubDate></item><item><title>Google Removed 749M Anna's Archive URLs from Its Search Results</title><link>https://torrentfreak.com/google-removed-749-million-annas-archive-urls-from-its-search-results/</link><description>&lt;doc fingerprint="3b2013d053b71323"&gt;
  &lt;main&gt;
    &lt;p&gt;Anna’s Archive is a meta-search engine for shadow libraries that allows users to find pirated books and other related sources.&lt;/p&gt;
    &lt;p&gt;The site launched in the fall of 2022, just days after Z-Library was targeted in a U.S. criminal crackdown, to ensure continued availability of ‘free’ books and articles to the broader public.&lt;/p&gt;
    &lt;p&gt;In the three years since then, Anna’s Archive has built up quite the track record. The site has been blocked in various countries, was sued in the U.S. after it scraped WorldCat, and actively provides assistance to AI researchers who want to use its library for model training.&lt;/p&gt;
    &lt;p&gt;Despite legal pressure, Annas-archive.org and the related .li and .se domains remain operational. This is a thorn in the side of publishers who are actively trying to take the site down. In the absence of options to target the site directly, they ask third-party intermediaries such as Google to lend a hand.&lt;/p&gt;
    &lt;head rend="h2"&gt;749 Million URLs&lt;/head&gt;
    &lt;p&gt;Google and other major search engines allow rightsholders to request removal of allegedly infringing URLs. The aim is to ensure that pirate sites no longer show up in search results when people search for books, movies, music, or other copyrighted content.&lt;/p&gt;
    &lt;p&gt;The Pirate Bay, for example, has been a popular target; Google has removed more than 4.2 million thepiratebay.org URLs over the years in response to copyright holder complaints. While this sounds like a sizable number, it pales in comparison to the volume of takedowns targeting Anna’s Archive.&lt;/p&gt;
    &lt;p&gt;Google’s transparency report reveals that rightsholders asked Google to remove 784 million URLs, divided over the three main Anna’s Archive domains. A small number were rejected, mainly because Google didn’t index the reported links, resulting in 749 million confirmed removals.&lt;/p&gt;
    &lt;p&gt;The comparison to sites such as The Pirate Bay isn’t fair, as Anna’s Archive has many more pages in its archive and uses multiple country-specific subdomains. This means that there’s simply more content to take down. That said, in terms of takedown activity, the site’s three domain names clearly dwarf all pirate competition.&lt;/p&gt;
    &lt;head rend="h2"&gt;5% of All Google Takedowns, Ever&lt;/head&gt;
    &lt;p&gt;Since Google published its first transparency report in May 2012, rightsholders have flagged 15.1 billion allegedly infringing URLs. That’s a staggering number, but the fact that 5% of the total targeted Anna’s Archive URLs is remarkable.&lt;/p&gt;
    &lt;p&gt;Penguin Random House and John Wiley &amp;amp; Sons are the most active publishers targeting the site, but they are certainly not alone. According to Google data, more than 1,000 authors or publishers have sent DMCA notices targeting Anna’s Archive domains.&lt;/p&gt;
    &lt;p&gt;Yet, there appears to be no end in sight. Rightsholders are reporting roughly 10 million new URLs per week for the popular piracy library, so there is no shortage of content to report.&lt;/p&gt;
    &lt;p&gt;With these DMCA takedown notices, publishers are aiming to make it as difficult as possible for people to find books on the site using Google. This works, as many URLs are now delisted while others are actively being demoted by the search engine for book-related queries.&lt;/p&gt;
    &lt;p&gt;That said, the Anna’s Archive website is certainly not unfindable. Searching for the site’s name in Google still shows the main domain as the top search result.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816968</guid><pubDate>Tue, 04 Nov 2025 23:11:20 +0000</pubDate></item><item><title>Bluetui – A TUI for managing Bluetooth on Linux</title><link>https://github.com/pythops/bluetui</link><description>&lt;doc fingerprint="e4d181ddbeaa2ea"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux based OS with bluez installed.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;You might need to install nerdfonts for the icons to be displayed correctly.&lt;/p&gt;
    &lt;p&gt;You can download the pre-built binaries from the release page release page&lt;/p&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from crates.io&lt;/p&gt;
    &lt;code&gt;cargo install bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the extra repository:&lt;/p&gt;
    &lt;code&gt;pacman -S bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the lamdness Gentoo Overlay:&lt;/p&gt;
    &lt;code&gt;sudo eselect repository enable lamdness
sudo emaint -r lamdness sync
sudo emerge -av net-wireless/bluetui&lt;/code&gt;
    &lt;p&gt;If you are a user of x-cmd, you can run:&lt;/p&gt;
    &lt;code&gt;x install bluetui&lt;/code&gt;
    &lt;p&gt;Run the following command:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/pythops/bluetui
cd bluetui
cargo build --release&lt;/code&gt;
    &lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/bluetui&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Tab&lt;/code&gt;: Switch between different sections.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start/Stop scanning.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt;: Show help.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;esc&lt;/code&gt;: Dismiss the help pop-up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; or &lt;code&gt;q&lt;/code&gt;: Quit the app.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt;: Enable/Disable the pairing.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Power on/off the adapter.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Enable/Disable the discovery.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;u&lt;/code&gt;: Unpair the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Connect/Disconnect the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;t&lt;/code&gt;: Trust/Untrust the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;e&lt;/code&gt;: Rename the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Pair the device.&lt;/p&gt;
    &lt;p&gt;Keybindings can be customized in the default config file location &lt;code&gt;$HOME/.config/bluetui/config.toml&lt;/code&gt; or from a custom path with &lt;code&gt;-c&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;# Possible values: "Legacy", "Start", "End", "Center", "SpaceAround", "SpaceBetween"
layout = "SpaceAround"

# Window width
# Possible values: "auto" or a positive integer
width = "auto"

toggle_scanning = "s"

[adapter]
toggle_pairing = "p"
toggle_power = "o"
toggle_discovery = "d"

[paired_device]
unpair = "u"
toggle_trust = "t"
rename = "e"&lt;/code&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;Bluetui logo: Marco Bulgarelli&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45817114</guid><pubDate>Tue, 04 Nov 2025 23:29:31 +0000</pubDate></item><item><title>Uncle Sam wants to scan your iris and collect your DNA, citizen or not</title><link>https://www.theregister.com/2025/11/04/dhs_wants_to_collect_biometric_data/</link><description>&lt;doc fingerprint="fbca09582881b604"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Uncle Sam wants to scan your iris and collect your DNA, citizen or not&lt;/head&gt;
    &lt;head rend="h2"&gt;DHS rule would expand biometric collection to immigrants and some citizens linked to them&lt;/head&gt;
    &lt;p&gt;If you're filing an immigration form - or helping someone who is - the Feds may soon want to look in your eyes, swab your cheek, and scan your face. The US Department of Homeland Security wants to greatly expand biometric data collection for immigration applications, covering immigrants and even some US citizens tied to those cases.&lt;/p&gt;
    &lt;p&gt;DHS, through its component agency US Citizenship and Immigration Services, on Monday proposed a sweeping expansion of the agency's collection of biometric data. While ostensibly about verifying identities and preventing fraud in immigration benefit applications, the proposed rule goes much further than simply ensuring applicants are who they claim to be.&lt;/p&gt;
    &lt;p&gt;First off, the rule proposes expanding when DHS can collect biometric data from immigration benefit applicants, as "submission of biometrics is currently only mandatory for certain benefit requests and enforcement actions." DHS wants to change that, including by requiring practically everyone an immigrant is associated with to submit their biometric data.&lt;/p&gt;
    &lt;p&gt;"DHS proposes in this rule that any applicant, petitioner, sponsor, supporter, derivative, dependent, beneficiary, or individual filing or associated with a benefit request or other request or collection of information, including U.S. citizens, U.S. nationals and lawful permanent residents, and without regard to age, must submit biometrics unless DHS otherwise exempts the requirement," the rule proposal said.&lt;/p&gt;
    &lt;p&gt;DHS also wants to require the collection of biometric data from "any alien apprehended, arrested or encountered by DHS."&lt;/p&gt;
    &lt;p&gt;It's not explicitly stated in the rule proposal why US citizens associated with immigrants who are applying for benefits would have to have their biometric data collected. DHS didn't answer questions to that end, though the rule stated that US citizens would also be required to submit biometric data "when they submit a family-based visa petition."&lt;/p&gt;
    &lt;head rend="h3"&gt;Give me your voice, your eye print, your DNA samples&lt;/head&gt;
    &lt;p&gt;In addition to expanded collection, the proposed rule also changes the definition of what DHS considers to be valid biometric data.&lt;/p&gt;
    &lt;p&gt;"Government agencies have grouped together identifying features and actions, such as fingerprints, photographs, and signatures under the broad term, biometrics," the proposal states. "DHS proposes to define the term 'biometrics' to mean 'measurable biological (anatomical, physiological or molecular structure) or behavioral characteristics of an individual,'" thus giving DHS broad leeway to begin collecting new types of biometric data as new technologies are developed.&lt;/p&gt;
    &lt;p&gt;The proposal mentions several new biometric technologies DHS wants the option to use, including ocular imagery, voice prints and DNA, all on the table per the new rule.&lt;/p&gt;
    &lt;p&gt;"The rule proposes to grant DHS express authority to require, request, or accept raw DNA or DNA test results," DHS said, including "to prove or disprove … biological sex" in situations where that can affect benefit eligibility.&lt;/p&gt;
    &lt;p&gt;DHS wants to use all that data for identity enrollment, verification and management of the immigration lifecycle, national security and criminal history checks, "the production of secure identity documents," to prove familial relationships, and to perform other administrative functions, the rule states.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facial recognition works better in the lab than on the street, researchers show&lt;/item&gt;
      &lt;item&gt;EU biometric border system launch hits inevitable teething problems&lt;/item&gt;
      &lt;item&gt;Vietnam to collect biometrics - even DNA - for new ID cards&lt;/item&gt;
      &lt;item&gt;Altman's eyeball-scanning biometric blockchain orbs officially come to America&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we noted in our story last week about DHS' new rule expanding biometric data collection on entry into and exit from the US, biometric technology - especially the often-used facial recognition scan - is ripe for misuse and prone to errors.&lt;/p&gt;
    &lt;p&gt;This new proposed rule goes far beyond subjecting immigrants to algorithmic identification tech prone to misidentifying non-white individuals, however, and reaches a new level of surveillance, with DHS seeking to collect and keep DNA test results - including partial profiles - from immigrants and some US citizens to verify family ties or biological sex when relevant. It's not much more assuring that DHS also wants to collect new forms of biometric data like voice records, which are increasingly easy to spoof with AI.&lt;/p&gt;
    &lt;p&gt;When we asked DHS questions about its biometric expansion proposal, it only sent us a statement identical to the one it sent last week when we inquired about the new entry/exit biometric requirements. The agency didn't respond when we asked for a statement pertaining to this latest proposed rule.&lt;/p&gt;
    &lt;p&gt;DHS is taking comments on the proposal until January 2; so far the submissions are nearly entirely negative, with posters decrying the plan as government overreach, comparing the proposal to communist China, and calling it a violation of Constitutional guarantees against unreasonable search and seizure. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45817167</guid><pubDate>Tue, 04 Nov 2025 23:35:27 +0000</pubDate></item><item><title>Munich's surfers left stunned after famed river wave vanishes</title><link>https://www.theguardian.com/world/2025/nov/04/munichs-surfers-left-stunned-after-famed-river-wave-vanishes</link><description>&lt;doc fingerprint="fe1b0d4e24b3d61d"&gt;
  &lt;main&gt;
    &lt;p&gt;The “mother of all river waves” in a German canal that is often credited as the birthplace of freshwater surfing has mysteriously disappeared after decades of flowing smoothly, leaving enthusiasts dumbfounded.&lt;/p&gt;
    &lt;p&gt;The famous stationary wave in the southern city of Munich is known as the Eisbach, or “ice brook”, for its frigid temperatures, and has become a pilgrimage site for surfers worldwide.&lt;/p&gt;
    &lt;p&gt;Unlike ocean surfing, its freshwater cousin takes place on a “standing wave”, which is often human-made, with currents often flowing over a concrete slab that manipulates the water into a permanent wave.&lt;/p&gt;
    &lt;p&gt;The sport’s origin is often cited as dating back to the early 1970s, when rule-breaking daredevils rode the naturally forming wave in Munich for the first time.&lt;/p&gt;
    &lt;p&gt;Today, river surfing has a global following, including in the River Severn in the United Kingdom, where surfers ride tidal bores, a phenomenon in which incoming tides form waves that move up a river.&lt;/p&gt;
    &lt;p&gt;In Hawaii, surfers also make river waves by digging a trench between a river and the ocean, with water flowing violently over the sand.&lt;/p&gt;
    &lt;p&gt;The Eisbach wave was originally believed to be formed by gravel, but the Munich surfing community later installed wooden planks that helped artificially stabilise the wave. Over the decades, it has become a major tourist draw for Bavaria’s state capital.&lt;/p&gt;
    &lt;p&gt;Largest during the winter months – when ice melt can push the wave up to one metre high – the river is now officially managed, including being drained once a year to clean away debris and inspect the streambed.&lt;/p&gt;
    &lt;p&gt;But after torrents were released back into the canal following its cleanup on Friday, the Eisbach wave did not form as usual, instead leaving unstable white water rapids.&lt;/p&gt;
    &lt;p&gt;“We’re at a loss,” surfer Klaus Rudolf told Stern magazine. “I was standing at the edge with my board on Friday evening and couldn’t believe it.”&lt;/p&gt;
    &lt;p&gt;Authorities were looking into the cause of the wave’s disappearance, including whether it could be due to the cleaning or a lack of water.&lt;/p&gt;
    &lt;p&gt;“No structural changes were made to the Eisbach wave or its banks during the cleanup,” the city said. An inspection of the site on Monday also did not reveal any damage.&lt;/p&gt;
    &lt;p&gt;On Tuesday, Mayor Dieter Reiter said in a statement that the city administration was “working with the Water Management Office and surfers to find a quick solution so that the famous surf wave will soon be available again as usual”.&lt;/p&gt;
    &lt;p&gt;Officials now plan to divert more water into the canal in hopes of a reappearance of the Eisbach, which SurferToday.com describes as “the mother of all river waves”. Standing waves require delicately balanced water levels and speeds.&lt;/p&gt;
    &lt;p&gt;The Eisbach wave closed earlier this year for several months after the death of a 33-year-old Munich woman who became trapped under the surface at night. Since it reopened, new rules have banned night-time surfing.&lt;/p&gt;
    &lt;p&gt;Agence France-Presse contributed to this report&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818123</guid><pubDate>Wed, 05 Nov 2025 01:51:27 +0000</pubDate></item><item><title>GM Deprecating In-Car App Store for Models as Recent as 2020</title><link>https://gmauthority.com/blog/2025/11/these-gm-vehicles-can-no-longer-download-apps-through-their-infotainment-system/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818282</guid><pubDate>Wed, 05 Nov 2025 02:24:20 +0000</pubDate></item><item><title>Direct File won't happen in 2026, IRS tells states</title><link>https://www.nextgov.com/digital-government/2025/11/direct-file-wont-happen-2026-irs-tells-states/409309/</link><description>&lt;doc fingerprint="b8a1c09cd9635069"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Direct File won’t happen in 2026, IRS tells states&lt;/head&gt;
    &lt;head rend="h2"&gt;The free service that allowed taxpayers to file online directly with the IRS was used by hundreds of thousands of taxpayers in 2024 and 2025, who gave it high marks — although tax prep companies and Republicans have sought its end.&lt;/head&gt;
    &lt;p&gt;The IRS has notified states that offered the free, government tax filing service known as Direct File in 2025 that the program won’t be available next filing season.&lt;/p&gt;
    &lt;p&gt;In an email sent from the IRS to 25 states, the tax agency thanked them for collaborating and noted that “no launch date has been set for the future.”&lt;/p&gt;
    &lt;p&gt;“IRS Direct File will not be available in Filing Season 2026,” says the Monday email, obtained by Nextgov/FCW and confirmed by multiple sources. It follows reports that the program was ending and Trump’s former tax chief, Billy Long, remarking over the summer that the service was “gone.”&lt;/p&gt;
    &lt;p&gt;The program, which debuted in 2024, was a big shift from the decades-long IRS policy of not competing with the tax prep industry in offering its own free, online tax filing service for Americans. Many Republicans had opposed Direct File, and tax prep companies also lobbied against it.&lt;/p&gt;
    &lt;p&gt;Still, most of the taxpayers that used Direct File earlier this year — over 296,500 — gave it high marks.&lt;/p&gt;
    &lt;p&gt;Those users won’t be able to log on to the Direct File website to get their returns anymore, according to the new email, which directs anyone needing a transcript to their IRS online accounts.&lt;/p&gt;
    &lt;p&gt;The Trump administration’s massive tax and spending policy bill signed into law over the summer directed the IRS to set up a task force to examine how the tax agency can use public-private partnerships to replace Direct File.&lt;/p&gt;
    &lt;p&gt;The IRS has relied on a public-private partnership called Free File for decades to give most Americans a free way to file their taxes, although it's been extremely underutilized. Only 3% of eligible taxpayers used it in recent years. Some of the member companies were found to have pushed people toward products they’d have to pay for, even when they could’ve used free options.&lt;/p&gt;
    &lt;p&gt;"It's not surprising since the Trump administration sabotaged Direct File all through this year's filing season, at the urging of tax prep monopolies like TurboTax," Adam Ruben, the vice president of the Economic Security Project, told Nextgov/FCW. "Trump's billionaire friends get favors while honest hardworking Americans will pay more to file their taxes."&lt;/p&gt;
    &lt;p&gt;Sen. Elizabeth Warren, D-Mass., told Nextgov/FCW that "the fight isn't over," saying that "giant tax prep companies are popping champagne, while Americans are forced to spend more time and more money to file their taxes."&lt;/p&gt;
    &lt;p&gt;The IRS did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Editor's note: This article has been updated to include comment from Sen. Elizabeth Warren.&lt;/p&gt;
    &lt;p&gt;If you have a tip you'd like to share, Natalie Alms can be securely contacted at nalms.41 on Signal.&lt;/p&gt;
    &lt;p&gt;NEXT STORY: CBP expands facial recognition for non-citizens at borders&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818319</guid><pubDate>Wed, 05 Nov 2025 02:30:38 +0000</pubDate></item><item><title>Zohran Mamdani wins the New York mayoral race</title><link>https://www.nbcnews.com/politics/elections/new-york-city-mayor-election-winner-2025-race-rcna238909</link><description>&lt;doc fingerprint="5080259aae15795"&gt;
  &lt;main&gt;
    &lt;p&gt;Democrat Zohran Mamdani has won New York’s mayoral race, NBC News projects, after the 34-year-old democratic socialist energized progressives in the city and across the country while generating intense backlash from President Donald Trump and Republicans, as well as some Democratic moderates.&lt;/p&gt;
    &lt;p&gt;In his victory speech after vanquishing former Gov. Andrew Cuomo, Mamdani claimed a broad mandate and set himself up in direct opposition to Trump, who made a late endorsement against him. "In this moment of political darkness, New York will be the light," Mamdani said.&lt;/p&gt;
    &lt;p&gt;"Together, we will usher in a generation of change, and if we embrace this brave new course, rather than fleeing from it, we can respond to oligarchy and authoritarianism with the strength it fears, not the appeasement it craves," Mamdani said later, before challenging Trump directly.&lt;/p&gt;
    &lt;p&gt;"This is not only how we stop Trump, it's how we stop the next one," Mamdani said. "So Donald Trump, since I know you're watching, I have four words for you: Turn the volume up."&lt;/p&gt;
    &lt;p&gt;Trump wasn't the only subject of Mamdani's speech, which he started by quoting the 19th- and 20th-century American socialist Eugene Debs and continued by promising the "most ambitious agenda" to address costs in New York City since the administration of Mayor Fiorello LaGuardia nearly 100 years ago.&lt;/p&gt;
    &lt;p&gt;Mamdani defeated Cuomo, who ran as a third-party candidate after losing the Democratic primary in June, by about 9 points, with Republican nominee Curtis Sliwa trailing far behind. Mayor Eric Adams, who also mounted a third-party campaign for re-election after he won as a Democrat in 2021, dropped out of the race in September and endorsed Cuomo last month.&lt;/p&gt;
    &lt;p&gt;The victory caps a meteoric rise through New York politics for Mamdani since he launched his campaign roughly one year ago, transforming him from a virtually unknown state assemblyman who barely registered in polling to the incoming leader of America’s largest city.&lt;/p&gt;
    &lt;p&gt;Along the way, he pushed aside the heir to one of New York’s most iconic political dynasties not once but twice within five months.&lt;/p&gt;
    &lt;p&gt;Now a nationally known political figure, Mamdani will attempt to enact the sweeping policy platform that inspired his supporters while managing an enormous municipal bureaucracy — and influencing national politics, as one of the most prominent democratic socialists and Democrats in the country. Among other goals, Mamdani wants to freeze rent on rent-stabilized units, enact universal child care, create a free bus program and launch city-run grocery stores.&lt;/p&gt;
    &lt;p&gt;“It is tempting to believe that this moment was always destined,” Mamdani said before thousands at a rally in Queens late last month, before he noted that when he started his campaign, “there was not a single television camera there to cover it.”&lt;/p&gt;
    &lt;p&gt;“Four months later and as recently as this February, our support had reached eye-watering heights of 1%,” Mamdani continued. “We were tied with noted candidate ‘someone else.’”&lt;/p&gt;
    &lt;p&gt;Mamdani’s victory is sure to reverberate not just throughout New York City but around the nation.&lt;/p&gt;
    &lt;p&gt;In New York, Mamdani’s next challenge will be the tall task of uniting leaders in Albany and on the City Council — many of whom were not eager to line up behind him — to advance his ambitious agenda.&lt;/p&gt;
    &lt;p&gt;Nationally, many Democrats will examine his rise from obscurity, his successful messaging on social media and his focus on affordability for clues about how to navigate their own races.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Republicans are eager to turn Mamdani’s left-wing platform into a wedge issue in competitive races far beyond New York City’s borders.&lt;/p&gt;
    &lt;p&gt;NBC News exit polling found that Mamdani won across racial demographics — with white, Black, Latino, Asian and voters of other races all backing his candidacy over Cuomo’s and Sliwa’s.&lt;/p&gt;
    &lt;p&gt;Younger voters overwhelmingly backed Mamdani, with NBC News exit polling showing that voters under 45 years old favored him over Cuomo by 43 points. Voters over 45, meanwhile, backed Cuomo by a 10-point margin.&lt;/p&gt;
    &lt;p&gt;Education played a big role, too, the exit polling showed. And one of the biggest divides in the election was between New Yorkers who were born in the city and those who had moved to New York within the last 10 years.&lt;/p&gt;
    &lt;p&gt;Meanwhile, with Mamdani’s pro-Palestinian activism having become a key issue in the race, NBC News exit polling found that Jewish voters favored Cuomo over Mamdani by 29 points, 60% to 31%.&lt;/p&gt;
    &lt;p&gt;Speaking to supporters after his defeat on Tuesday, Cuomo thanked Adams, former New York City Mayor Michael Bloomberg and former New York Gov. David Paterson for their support. He called voters at his election eve party "New York patriots."&lt;/p&gt;
    &lt;p&gt;“This campaign was the right fight to wage," Cuomo said. "And I am proud of what we did and what we did together. This campaign was to contest the philosophies that are shaping the Democratic Party, the future of this city and the future of this country. And this coalition transcended normal partisan politics.”&lt;/p&gt;
    &lt;p&gt;The closing weeks of the race turned into a brawl between Mamdani and Cuomo, the onetime front-runner who spent the general election trying to play catch-up. The two had heated debates in recent weeks, with Cuomo calling Mamdani a “divisive force in New York” while Mamdani painted Cuomo as Trump’s “puppet.”&lt;/p&gt;
    &lt;p&gt;Trump made a late jump into the race Monday night, endorsing Cuomo on social media and saying a vote for Sliwa, the Republican nominee, was essentially a vote for Mamdani in the split general election field.&lt;/p&gt;
    &lt;p&gt;Interestingly, exit polling showed self-identified Republicans favored Cuomo over Sliwa, with 61% of Republicans him while just 35% backed Sliwa.&lt;/p&gt;
    &lt;p&gt;Late last month, Mamdani delivered an emotional address condemning what he slammed as “racist, baseless” attacks he has faced for his Muslim faith. He will be the first Muslim mayor in New York City history. His unapologetically pro-Palestinian stance energized progressives who oppose Israel’s war in Gaza, as pro-Israel Democrats and donors grew anxious about his rise.&lt;/p&gt;
    &lt;p&gt;At a rally alongside Rep. Alexandria Ocasio-Cortez, D-N.Y., and Sen. Bernie Sanders, I-Vt., days later, Mamdani said Cuomo, Adams and Sliwa possess only “the playbook of the past.”&lt;/p&gt;
    &lt;p&gt;“They have sought to make this election a referendum not on the affordability crisis that consumes New Yorkers’ lives,” he said, “but on the faith I belong to and the hatred they seem to normalize.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818421</guid><pubDate>Wed, 05 Nov 2025 02:50:06 +0000</pubDate></item><item><title>What Happened to Piracy? Copyright Enforcement Fades as AI Giants Rise</title><link>https://www.leefang.com/p/what-happened-to-piracy-copyright</link><description>&lt;doc fingerprint="bc708393d281a6cf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Happened to Piracy? Copyright Enforcement Fades as AI Giants Rise&lt;/head&gt;
    &lt;head rend="h3"&gt;"Laws are spider webs through which the big flies pass and the little ones get caught." -Balzac&lt;/head&gt;
    &lt;p&gt;The artificial intelligence revolution threatens to uproot entire professions, replace millions of workers, and reshape industrial relations. Much ink has been spilled on the ways in which AI influence has already taken root. Wall Street and Washington, D.C., are both betting on the technology to power the future of American innovation.&lt;/p&gt;
    &lt;p&gt;But little has been said about how the industry has already seized control over key components of American governance. Look no further than the quiet shifts in the application of copyright law.&lt;/p&gt;
    &lt;p&gt;Since the mid-nineties, software giants led by Microsoft have waged a global war against copyright infringement and online piracy. They bankrolled groups like the Business Software Alliance to demand increased penalties for copyright violations and pressured FBI agents to raid foreign hosts accused of harboring illicit content-sharing servers. For the old software model, duplicated Microsoft Office disks and fake software licenses posed the greatest risk.&lt;/p&gt;
    &lt;p&gt;Then-Microsoft Deputy General Counsel Brad Smith, in a 2001 interview with the Wall Street Journal, championed the crusade against digital theft as part of a sprawling battle against “organized criminal enterprises.” The company and its allies marshaled their resources to encourage the federal government to crack down on foreign piracy sites, especially illegal file-sharing firms based in Russia, Hong Kong, and Brazil.&lt;/p&gt;
    &lt;p&gt;In a case that signified this old era of aggressive copyright enforcement, the Justice Department in 2011 pursued criminal charges against Aaron Swartz, a young open internet activist, for downloading JSTOR’s repository of scholarly papers without authorization. Faced with the prospect of decades in prison, he died by suicide during the prosecution.&lt;/p&gt;
    &lt;p&gt;Much has changed since advances in artificial intelligence have made the technology the focal point of Silicon Valley innovation. Smith is now president of Microsoft, and the company and its partner OpenAI—which exclusively runs on Microsoft’s Azure cloud computing network and was backed with $13.75 billion in investment funds from Microsoft—are at the center of a very different type of copyright dispute. This time, as the power of the tech industry still looms over Washington, D.C., prosecutors are less interested in going after those suspected of engaging in illegal downloads of copyrighted work.&lt;/p&gt;
    &lt;p&gt;That is because it is now the tech giants that are accused of exploiting pirated content on an industrial scale. Meta, Anthropic, Microsoft, Google, xAI, and OpenAI are competing to vacuum up as much data as humanly possible in a race to develop their respective AI models. The most prized training data, it turns out, are vast quantities of copyrighted material, largely in the form of published works such as academic articles, novels, and nonfiction books.&lt;/p&gt;
    &lt;p&gt;After decades of FBI warnings about copyright violations and the dangers of piracy, suddenly the federal government is no longer interested in such crimes. That has left law enforcement in the hands of civil litigation class actions, many of which have been filed by authors and writers noting that tech giants are now plundering their works for AI training without authorization, payment, or notification.&lt;/p&gt;
    &lt;p&gt;The court cases have cast a spotlight on a stratospheric level of hypocrisy. Microsoft, which once cast peer-to-peer and dark web piracy sites as an existential threat that cost the economy billions of dollars in damages, allegedly taps the very same types of illicit forums for a huge range of copyrighted academic articles, novels, and nonfiction.&lt;/p&gt;
    &lt;p&gt;The AI giants have all but admitted that they have developed their most advanced models by tapping into mass piracy. The lawsuit Kadrey et al. v. Meta Platforms revealed that Meta, the parent company of Facebook, used a mirror of Library Genesis, a notorious library of pirated books hosted on Russian servers, to train its generative AI systems.&lt;/p&gt;
    &lt;p&gt;Tech executives have pressed for licensing deals with some publishers—but in many cases have gone ahead with simply stealing millions of books and articles via known piracy sites on the dark web and other illicit forums. The litigation produced emails and documents showing Meta employees admitting that “torrenting from a [Meta-owned] corporate laptop doesn’t feel right 😃.” In one exchange, engineers noted that use of the illegal content had been escalated to Meta CEO Mark Zuckerberg (referred to as “MZ”) and that the decision was “approved to use.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818483</guid><pubDate>Wed, 05 Nov 2025 03:01:59 +0000</pubDate></item><item><title>Hypothesis: Property-Based Testing for Python</title><link>https://hypothesis.readthedocs.io/en/latest/</link><description>&lt;doc fingerprint="a1031a81e5b71397"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to Hypothesis!¶&lt;/head&gt;
    &lt;p&gt;Hypothesis is the property-based testing library for Python. With Hypothesis, you write tests which should pass for all inputs in whatever range you describe, and let Hypothesis randomly choose which of those inputs to check - including edge cases you might not have thought about. For example:&lt;/p&gt;
    &lt;p&gt;You should start with the tutorial, or alternatively the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tutorial¶&lt;/head&gt;
    &lt;p&gt;An introduction to Hypothesis.&lt;/p&gt;
    &lt;p&gt;New users should start here, or with the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;How-to guides¶&lt;/head&gt;
    &lt;p&gt;Practical guides for applying Hypothesis in specific scenarios.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explanations¶&lt;/head&gt;
    &lt;p&gt;Commentary oriented towards deepening your understanding of Hypothesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;API Reference¶&lt;/head&gt;
    &lt;p&gt;Technical API reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818562</guid><pubDate>Wed, 05 Nov 2025 03:15:37 +0000</pubDate></item><item><title>Epic vs. Google settlement: Opening up Android</title><link>https://twitter.com/TimSweeneyEpic/status/1985920786545123613</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818973</guid><pubDate>Wed, 05 Nov 2025 04:12:53 +0000</pubDate></item></channel></rss>