<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 07 Dec 2025 13:39:47 +0000</lastBuildDate><item><title>GrapheneOS is the only Android OS providing full security patches</title><link>https://grapheneos.social/@GrapheneOS/115647408229616018</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46173407</guid><pubDate>Sat, 06 Dec 2025 13:58:31 +0000</pubDate></item><item><title>Tiny Core Linux: a 23 MB Linux distro with graphical desktop</title><link>http://www.tinycorelinux.net/</link><description>&lt;doc fingerprint="9ddb391819bfbc66"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Welcome to The Core Project - Tiny Core Linux&lt;/head&gt;
    &lt;p&gt;The Core Project is a highly modular based system with community build extensions.&lt;/p&gt;
    &lt;p&gt;It starts with a recent Linux kernel, vmlinuz, and our root filesystem and start-up scripts packaged with a basic set of kernel modules in core.gz. Core (11MB) is simply the kernel + core.gz - this is the foundation for user created desktops, servers, or appliances. TinyCore is Core + Xvesa.tcz + Xprogs.tcz + aterm.tcz + fltk-1.3.tcz + flwm.tcz + wbar.tcz&lt;/p&gt;
    &lt;p&gt;TinyCore becomes simply an example of what the Core Project can produce, an 16MB FLTK/FLWM desktop.&lt;/p&gt;
    &lt;p&gt;CorePlus ofers a simple way to get started using the Core philosophy with its included community packaged extensions enabling easy embedded frugal or pendrive installation of the user's choice of supported desktop, while maintaining the Core principal of mounted extensions with full package management.&lt;/p&gt;
    &lt;p&gt;It is not a complete desktop nor is all hardware completely supported. It represents only the core needed to boot into a very minimal X desktop typically with wired internet access.&lt;/p&gt;
    &lt;p&gt;The user has complete control over which applications and/or additional hardware to have supported, be it for a desktop, a netbook, an appliance, or server, selectable by the user by installing additional applications from online repositories, or easily compiling most anything you desire using tools provided.&lt;/p&gt;
    &lt;p&gt;The latest version: 16.2&lt;/p&gt;
    &lt;head rend="h3"&gt;News&lt;/head&gt;
    &lt;head rend="h3"&gt;About Our Project&lt;/head&gt;
    &lt;p&gt;Our goal is the creation of a nomadic ultra small graphical desktop operating system capable of booting from cdrom, pendrive, or frugally from a hard drive. The desktop boots extremely fast and is able to support additional applications and hardware of the users choice. While Tiny Core always resides in ram, additional applications extensions can either reside in ram, mounted from a persistent storage device, or installed into a persistent storage device.&lt;/p&gt;
    &lt;p&gt;We invite interested users and developers to explore Tiny Core. Within our forums we have an open developement model. We encourage shared knowledge. We promote community involvement and community built application extensions. Anyone can contribute to our project by packaging their favorite application or hardware support to run in Tiny Core. The Tiny Core Linux Team currently consists of eight members who peruse the forums to assist from answering questions to helping package new extensions.&lt;/p&gt;
    &lt;p&gt;Join us here and on IRC Freenode #tinycorelinux.&lt;/p&gt;
    &lt;p&gt;Learn. Share. Grow your knowledge of Linux.&lt;/p&gt;
    &lt;p&gt;Robert Shingledecker, December 01, 2008&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46173547</guid><pubDate>Sat, 06 Dec 2025 14:18:42 +0000</pubDate></item><item><title>HTML as an Accessible Format for Papers (2023)</title><link>https://info.arxiv.org/about/accessible_HTML.html</link><description>&lt;doc fingerprint="e3d1ea5238d7dc4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HTML as an accessible format for papers&lt;/head&gt;
    &lt;p&gt;Accessibility barriers in research are not new, but they are urgent. The message we have heard from our community is that arXiv can have the most impact in the shortest time by offering HTML papers alongside the existing PDF.&lt;/p&gt;
    &lt;p&gt;arXiv has successfully launched papers in HTML format. We are gradually backfilling HTML for arXiv's corpus of over 2 million papers over time. Not every paper can be successfully converted, so a small percentage of papers will not have an HTML version. We will work to improve conversion over time.&lt;/p&gt;
    &lt;p&gt;The link to the HTML format will appear on abstract pages below the existing PDF download link. Authors will have the opportunity to preview their paperâs HTML as a part of the submission process.&lt;/p&gt;
    &lt;p&gt;The beta rollout is just the beginning. We have a long way to go to improve HTML papers and will continue to solicit feedback from authors, readers, and the entire arXiv community to improve conversions from LaTeX.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why "experimental" HTML?&lt;/head&gt;
    &lt;p&gt;Did you know that 90% of submissions to arXiv are in TeX format, mostly LaTeX? That poses a unique accessibility challenge: to accurately convert from TeXâa very extensible language used in myriad unique ways by authorsâto HTML, a language that is much more accessible to screen readers and text-to-speech software, screen magnifiers, and mobile devices. In addition to the technical challenges, the conversion must be both rapid and automated in order to maintain arXivâs core service of free and fast dissemination.&lt;/p&gt;
    &lt;p&gt;Because of these challenges we know there will be some conversion and rendering issues. We have decided to launch in beta with âexperimentalâ HTML because:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Accessible papers are needed now. We have talked to the arXiv community, especially researchers with accessibility needs, and they overwhelmingly asked us not to wait.&lt;/item&gt;
      &lt;item&gt;We need your help. The obvious work is done. Reports from the community will help us identify issues we can track back to specific LaTeX packages that are not converting correctly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Error messages you may see in HTML papers&lt;/head&gt;
    &lt;p&gt;HTML papers on arXiv.org are a work in progress and will sometimes display errors. As we work to improve accessibility we share with you the causes of these errors and what authors can do to help minimize them. Learn more about error messages you may see in HTML papers&lt;/p&gt;
    &lt;head rend="h2"&gt;Ways to help&lt;/head&gt;
    &lt;head rend="h3"&gt;1) Read HTML papers and report issues&lt;/head&gt;
    &lt;p&gt;We encourage the community to try out HTML papers in your field:&lt;/p&gt;
    &lt;head rend="h4"&gt;Report an issue&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to the abstract page for a paper you are interested in reading.&lt;/item&gt;
      &lt;item&gt;Look in the section where you find the link to the PDF download, and click the new link for HTML.&lt;/item&gt;
      &lt;item&gt;Report issues by either a) clicking on the Open Issue button b) selecting text and clicking on the Open Issue for Selection button or c) use &lt;code&gt;Ctrl+?&lt;/code&gt;on your keyboard. If you are using a screen reader, use&lt;code&gt;Alt+y&lt;/code&gt;to toggle accessible reporting buttons per paragraph.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please do not create reports that the HTML paper doesn't look exactly like the PDF paper&lt;/p&gt;
    &lt;p&gt;Our primary goal for this project is to make papers more accessible, so the focus during the beta phase will value function over form. HTML layouts that are incorrect or are illegible are important to report. But we do expect the HTML papers to present differently than the same paper rendered in PDF. Line breaks will occur in different places and there is likely to be more white space. In general, the HTML paper won't present as compactly. Intricate typographic layouts will not be rendered so intricately. This is by design.&lt;/p&gt;
    &lt;p&gt;HTML is a different medium and brings its own advantages versus PDF. In addition to being much more compatible with assistive technologies, HTML does a far better job adapting to the characteristics of the device you are reading on, including mobile devices.&lt;/p&gt;
    &lt;head rend="h3"&gt;2) Help improve the conversion from LaTeX&lt;/head&gt;
    &lt;p&gt;If you are an author you can help us improve conversions to HTML by following our guide to LaTeX Markup Best Practices for Successful HTML Papers.&lt;/p&gt;
    &lt;p&gt;If you are a developer and have free development cycles, help us improve conversions! Our collaborators at LaTeXML maintain a list of issues and welcome feedback and developer contributions.&lt;/p&gt;
    &lt;p&gt;If you are a publisher, member of a society, or conference organizer you can help us improve conversions to HTML by reviewing the .cls files your organization recommends to authors for unsupported packages. Providing .cls files that use supported packages is an easy way to support and sow accessibility in the scientific community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you to our collaborators&lt;/head&gt;
    &lt;p&gt;First, we want to share a special thank you to all the scientists with disabilities who have generously shared their insights, expertise, and guidance throughout this project.&lt;/p&gt;
    &lt;p&gt;We want to thank two organizations without which HTML papers on arXiv would not be possible: The LaTeX Project, and the LaTeXML team from NIST. We deeply thank each member of these teams for their knowledge, incredible work, and commitment to accessibility.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46173825</guid><pubDate>Sat, 06 Dec 2025 14:59:52 +0000</pubDate></item><item><title>Perl's decline was cultural</title><link>https://www.beatworm.co.uk/blog/computers/perls-decline-was-cultural-not-technical</link><description>&lt;doc fingerprint="4418d15d9ae08ffd"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt; Perl's decline was cultural 2025-11-20 &lt;/head&gt;
    &lt;head rend="h3"&gt;According to the Discourse, somebody killed perl&lt;/head&gt;
    &lt;p&gt;There's been a flurry of discussion on Hacker News and other tech forums about what killed Perl. I wrote a lot of Perl in the mid 90s and subsequently worked on some of the most trafficked sites on the web in mod_perl in the early 2000s, so I have some thoughts. My take: it was mostly baked into the culture. Perl grew amongst a reactionary community with conservative values, which prevented it from evolving into a mature general purpose language ecosystem. Everything else filled the gap.&lt;/p&gt;
    &lt;head rend="h3"&gt;I remember Perl&lt;/head&gt;
    &lt;p&gt;Something to keep in mind, is that although this is my personal take, and therefore entirely an opinion piece, I was there at the time. I stopped doing Perl properly when I left Amazon, I think this would have been around 2005. It's based on the first hand impressions of somebody who was very deeply involved in Perl in its heyday, and moved on. I have a lot of experience, from both inside and outside the tent.&lt;/p&gt;
    &lt;head rend="h3"&gt;Perl's roots are sysadmin&lt;/head&gt;
    &lt;p&gt;What culture? Perl always had a significant amount of what you might call "BOFH" culture, which came from its old UNIX sysadmin roots. All of those passive aggressive idioms and in jokes like "RTFM", "lusers", "wizards", "asking for help the wrong way" etc. None of this is literally serious, but it does encode and inform social norms that are essentially tribal and introverted. There implicitly is a privileged population, with a cost of entry to join. Dues must be paid. Cultural conservatism as a first principle.&lt;/p&gt;
    &lt;p&gt;This stems from the old locked-down data centre command culture. When computer resource was expensive, centralised, fragile, and manually operated, it was rigidly maintained by gatekeepers, defending against inappropriate use. I started my career as an apprentice programmer at the very end of this era, (late 80s) pre-web, and before microcomputers had made much inroads, and this really was the prevailing view from inside the fort. (This is a drawback about fort-building. Once you live in a fort, it's slightly too easy to develop a siege mentality). Computers are special, users are inconvenient, disruption is the main enemy.&lt;/p&gt;
    &lt;p&gt;An unfortunate feedback loop in this kind of "perilous" environment is that it easily turns prideful. It's difficult to thrive here, if you survive and do well you are skilled; you've performed feats; you should mark your rites of passage. This can become a dangerous culture trap. If you're not careful about it, you may start to think of the hazards and difficulties, the "foot guns", as necessary features - they teach you those essential survival skills that mark you out. More unkindly, they keep the stupid folk out, and help preserve the high status of those who survived long enough to be assimilated. Uh-oh, now you've invented class politics.&lt;/p&gt;
    &lt;p&gt;The problem with this thinking is that it's self-reinforcing. Working hard to master system complexities was genuinely rewarding - you really were doing difficult things and doing them well. This is actually the same mechanism behind what eventually became known as 'meritocracy'1, but the core point is simpler - if difficulty itself becomes a badge of honour, you've created a trap: anything that makes the system more approachable starts to feel like it's cheapening what you achieved. You become invested in preserving the barriers you overcame.&lt;/p&gt;
    &lt;p&gt;(This is the same mentality that built leetcode interview pipelines BTW, but let's leave that sidebar alone for now)&lt;/p&gt;
    &lt;p&gt;So the UNIX operator culture tended to operate as a tribal meritocracy (as opposed to the UNIX implementer culture, which fell out of a different set of cultural norms, quite an interesting side bar itself2), a cultural priesthood, somewhat self-regarding, rewarding of cleverness and knowledge hoarding, prone to feats of bravado, full of lore, with a defensive mentality of keeping the flame aloft, keeping the plebs happy and fed, and warding off the barbarians. As we entered the 90s it was already gently in decline, because centralised computing was giving way to the rise of the microcomputer, but the sudden explosive growth of the WWW pulled internet / Unix culture suddenly back into the mainstream with an enormous and public opportunity vacuum. Everyone suddenly has an urgent need to write programs that push text off UNIX file-systems (and databases) and into web pages, and Perl is uniquely positioned to have a strong first-mover advantage in this suddenly vital, novel ecosystem. But it's culture and values are very much pulled across from this previous era.&lt;/p&gt;
    &lt;p&gt;(Springing out of this, Perl had an, at best grudging, tolerance for 'difficult genius' types, alongside this baseline culture. Unfortunately, this kind of toxic personality tends to thrive in the type of culture I've described, and they do set to help the tone. I'm not here to call out people specifically, because I'm trying to make a point rather than feed a culture war, or dig up gossip, but there were several significant examples, you can probably find lore if you like. I think the kindest way I can describe the compounding effect of this is that there was a strong cultural norm along the lines of "It's OK to be rude, as long as it's for a good cause".)&lt;/p&gt;
    &lt;head rend="h3"&gt;A fort within a fort&lt;/head&gt;
    &lt;p&gt;I remember this tension as always being tangibly there. Perl IRC and mailing lists were quite cliquey and full of venerated experts and in-jokes, rough on naivety, keen on robust, verbose debate, and a little suspicious of newcomers. And very cult-like. The "TIMTOWTDI" rule, although ostensibly liberal, literally means 'there is more than one way to do it in Perl' - and you can perhaps infer from that that there's little to no reason to do it using anything else. Elevating extreme flexibility like this is paradoxically also an engine of conservatism. If Perl can already do anything, flexibly, in multiple ways, then the language itself doesn't need to change - 'we already have one of those here, we don't need new things'. This attitude determined how Perl intended to handle evolution: the core language would remain stable (a fort inside a fort, only accessible to high level wizards), while innovation was pushed outward to CPAN. You could add features outside of core by writing and consuming third party libraries, you could bend language behaviour with pragmas without modifying Perl itself. The very best CPAN modules could theoretically be promoted into core, allowing the language to evolve conservatively from proven, widely-used features.&lt;/p&gt;
    &lt;p&gt;On paper, this sounds reasonable. In practice, I think it encoded a fundamental conflict of interest into the community early on, and set the stage for many of the later growth problems. I'm not going to pretend that Perl invented dependency hell, but I think it turned out to be another one of those profound misfeatures that their cultural philosophy lead them to mistake for virtue, and embrace.&lt;/p&gt;
    &lt;p&gt;An interesting thing I think has been missed discussing the context of the original blog piece, about whether Perl 6 significantly impacted Perl growth, is the fact that Perl 6 itself manifested out of ongoing arguments. Perl 6 is a schism. Here's a oft-cited note from Larry Wall himself about the incident that sparked Perl 6, at &lt;del&gt; YAPC&lt;/del&gt; OSCON 2000 &lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We spent the first hour gabbing about all sorts of political and organizational issues of a fairly boring and mundane nature. Partway through, Jon Orwant comes in, and stands there for a few minutes listening, and then he very calmly walks over to the coffee service table in the corner, and there were about 20 of us in the room, and he picks up a coffee mug and throws it against the other wall and he keeps throwing coffee mugs against the other wall, and he says "we are f-ed unless we can come up with something that will excite the community, because everyone's getting bored and going off and doing other things".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;(Pause a second and ask yourself about the sort of social culture that both allows this kind of behaviour at public events, and then chooses to embrace it as a key piece of cultural lore)&lt;/p&gt;
    &lt;head rend="h3"&gt;The impact of Perl 6&lt;/head&gt;
    &lt;p&gt;Perl 6 was really a schism. Perl was already under a great amount of strain trying to accommodate the modernising influx of post dot-com mainstream web application building, alongside the entrenched conservatism of the core maintainers, and the maintenance burden of a few years exponential growth of third-party libraries, starting to build a fractal mess of slightly differentiating, incompatible approaches of those multiple ways to do things that were effectively now table-stakes language features, as the deployment landscape started to tiptoe towards a more modern, ubiquitous WWW3.&lt;/p&gt;
    &lt;p&gt;So, while I agree that it's wrong to generalise that 'Perl 6 killed Perl', I would say that Perl 6 was a symptom of the irreconcilable internal forces that killed Perl. Although, I also intend to go on to point out that Perl isn't dead, nothing has actually killed Perl. Killed Perl is a very stupid way to frame the discussion, but here we are.&lt;/p&gt;
    &lt;p&gt;So... Perl 6 is created as a valve to offset that pressure, and it kind of works. Up to a point. Unfortunately I think the side effect really is that the two branches of the culture, in the process of forking, double down on their encoded norms. Perl 5.x beds down as the practical, already solved way to do all the same things, with little need to change. Any requirements for more modern application patterns that are emerging in the broader web development environment, like idk, Unicode, REST clients, strict data structures, asynchronous I/O, whatever? That can either wait for Perl6 or you can pull things together using the CPAN if you want to move right now. Perl 6 leans the other way - they don't need to ship immediately, we have Perl 5 already here for doing things, Perl 6 is going to innovate on everything, and spend it's time getting there, designing up-front.4 They spend at least two years writing high level requirement specs. They even spin out a side-project trying to build a universal virtual machine to run all dynamic programming languages that never delivers5&lt;/p&gt;
    &lt;p&gt;This is the landscape where Perl's central dominance of 'back end' web programming continues to slip. Unfortunately, alongside the now principled bias toward cultural conservatism, Perl 5 has an explicit excuse for it. The future is over there, and exciting, and meanwhile we're working usefully, and getting paid, and getting stuff done. Kind of OK from inside the fort. Some day we'll move to the newer fort, but right now this is fine. Not very attractive to newcomers though, really. And this is also sort of OK, because Perl doesn't really want those sort of newcomers, does it? The kind that turns up on IRC or forums and asks basic questions about Perl 6 and sadly often gets treated with open contempt.&lt;/p&gt;
    &lt;head rend="h3"&gt;Meanwhile, over there&lt;/head&gt;
    &lt;p&gt;Ruby has sprouted "Ruby on Rails", and it's taken the dynamic web building world by storm. Rails is a second generation web framework, that's proudly an 'opinionated web framework'. Given that the web application architecture is starting to stabilise into a kind of three-tier system , with a client as a web browser, a middle tier as a monolithic application server, and a persistence layer as a relational database , and a split server architecture serving static and dynamic content from different routes, here is just one way to do that, with hugely developer friendly tooling turning this into a cookie-cutter solution for the 80% core, and a plugin and client-side decoration approach that allows for the necessary per-site customisation.&lt;/p&gt;
    &lt;p&gt;Ruby is interesting as well. Ruby is kind of a Perl6 really. More accurately it's a parallel universe Perl5 Ruby comes from Japan, and has developed as an attempt to build something similar to Perl, but it's developed much later, by programming language enthusiasts, and for the first ten years or so, it's mostly only used in Japan. To my line of thinking this is probably important. Ruby does not spring from decades of sysadmin or sysop culture. Ruby is a language for programmers, and is at this point an sensible candidate for building something like Rails with - a relatively blank canvas for dynamic programming, with many of the same qualities as Perl, with less legacy cruft, and more modern niceties, like an integrated object system, exceptions, straightforward data structures. Ruby also has adopted 'friendliness' as a core value, and the culture over there adopts a principled approach to aggressively welcoming newcomers, promoting easiness, and programmer happiness and convenience as strong first class principles.&lt;/p&gt;
    &lt;p&gt;Rails is a huge hit. At this point, which is around about the time I stopped significantly using Perl (2004-2005) (because I quit my job, not out of any core animosity toward it, in fact, in my day, I was really quite a Perl fan), Rails is the most appealing place to start as a new web programmer. Adoption rate is high, community is great, velocity of development is well-paced, and there's a lovely , well-lit, onboarding pipeline for how to start. You don't even really need to know ruby. It has a one-shot install tool, and generates working websites from templates, almost out of the box. It's an obvious starting point.&lt;/p&gt;
    &lt;p&gt;Perl being Perl, develops several analogue frameworks to Rails, all of them interdependently compatible and incompatible with each other and each other's dependencies, all of them designed to be as customisable and as user configurable as they possibly can be6&lt;/p&gt;
    &lt;head rend="h3"&gt;PHP&lt;/head&gt;
    &lt;p&gt;There are also the other obvious contenders. PHP has been there all along, and it's almost coming up from entirely the opposite cultural background of Perl. PHP is a users language. It's built to be deployed by copying script files to your home directory, with minimal server side impact or privileges. It's barely designed at all, but it encounters explosive growth all the way through the first (and through into the second) web era, almost entirely because it makes the barrier to onboarding so low as to be non-existent. PHP gets a couple of extra free shots in the arm&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Because it's architecture is so amenable to shared-server hosting, it is adopted as the primary implementation language of the blogging boom. An entire generation of web developers is born of installing and customising WordPress and text-pattern et. al by installing it directly into your home directory on a rented CPanel host account. It's the go-to answer for 'I'm not a programmer really but how do I get a personal web site'7 This zero gate-keeping approach keeps the PHP stack firmly on the table of 'basic' web programmers all through the history of the web up to the current day.&lt;/item&gt;
      &lt;item&gt;Because of these initially lightweight deployment targets, PHP scales like little else, mostly because it's execution model leans strongly towards idempotent execution, with each web request tearing up and tearing down the whole environment. In a sense, this is slower than keeping hot state around, but it does lend itself extremely well to shared-nothing horizontal scaling, which as the web user base increases gigantically throughout the 2000s era, is the simplest route to scaling out. Facebook famously, is built in PHP at this point in time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Python&lt;/head&gt;
    &lt;p&gt;There is of course one other big horse in the race in this era, and it's a particularly interesting one in many ways, certainly when contrasted with Perl. This is of course, Python. Python is a close contemporary of Perl's but once again, it's roots are somewhere very different. Python doesn't come from UNIX culture either. Python comes from academia, and programming language culture. It's kind of a forgotten footnote, but Python was originally built for the Amoeba operating system, and it's intention was to be a straightforward programming language for scripting this8. The idea was to build a language that could be the 'second programming language' for programmers. Given that this is the 1980s, early 1990s, the programmers would be expected to be mostly using C / C++ ,perhaps Pascal. Python was intended to allow faster development for lighter weight programs or scripting tasks. I suppose the idea was to take something that you might want to build in a shell script, but provide enough high level structured support that you could cleanly build the kind of things that quickly become a problem in shell scripts. So, it emphasises data structures, and scoped variables, and modules, and prioritises making it possible to extend the language with modules. Typical things that experienced programmers would want to use. The language was also designed to be portable between the different platforms programmers would use, running on the desktops of the day, but also on the server. As a consequence, it had a broad standard library of common portable abstractions around standard system features - file-systems, concurrency, time, FFI. For quite a long time, one of python's standard mottoes was 'batteries included'.&lt;/p&gt;
    &lt;p&gt;Python never set the world on fire at any particular moment, but it remained committed to a clear evolutionary incremental development, and clean engineering principles. Again, I think the key element here is cultural tone. Python is kind of boring, not trying to be anyone's best language, or even a universal language. Python was always a little fussy, maybe snobby, slightly abstracted away from the real world. It's almost as old as Perl and it just kept incrementally evolving, picking up users, picking up features, slowly broadening the standard library. The first time I saw Python pick up an undeniable mainstream advantage would also have been around the early 2000s, when Google publicly adopted it as one of their house standard languages. Never radical, just calmly evolving in it's environs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nature abhors a vacuum&lt;/head&gt;
    &lt;p&gt;When I sketch out this landscape, I remain firmly convinced that most of Perl's impedance to continued growth were cultural. Perl's huge moment of relevance in the 90s was because it cross-pollinated two diverging user cultures. Traditional UNIX / database / data-centre maintenance and admin users, and enthusiastic early web builders and scalers. It had a cultural shock phase from extremely rapid growth, the centre couldn't hold, and things slowly fell apart.&lt;/p&gt;
    &lt;p&gt;Circling back though, it's time to address the real elephant in the room. Perl manifestly did not die. It's here right now. It's installed I think by default, on almost every single computer I own and operate, without me doing a single thing to make that happen. It's still used every day by millions of people on millions of systems (even if that isn't deliberate). It's still used by many people entirely deliberately for building software, whether that's because they know it and like it and it works, or because they're interfacing with or working on legacy Perl systems (of which there are still many), or maybe they're using it still in it's original intentional role - A capable POSIX-native scripting language, with much better performance and a broader feature-set than any shell or awk. I still occasionally break it out myself, for small scripts I would like to use more than once, or as parts of CLI pipelines.&lt;/p&gt;
    &lt;p&gt;What I don't do any more is reach for Perl first to make anything new. In my case, it's just because I typically am spoilt for options that are a better fit for most tasks, depending on whatever it is I'm trying to achieve. By the time I came to Perl, (1998-ish), I was already on my third career phase, I had a strong UNIX background, and had already built real things in lisp, java, pascal, visual basic and C++. My attitude to languages was already informed by picking a tool to fit the task at hand. Boy did I love Perl for a few years. The product/market-fit for those early web days was just beautiful. The culture did have too much of the negative tropes I've been pointing at, but that wasn't really a problem personally for me, I'd grown up amongst the BOFHs inside the data centres already, it wasn't too hard for me to assimilate, nor pick up the core principles. I did occasionally bounce off a couple of abrasive characters in the community, but mostly this just kept me loosely coupled, I enjoyed how the language solved the problems I needed solving quickly, I enjoyed the flexibility, and I also enjoyed the way that it made me feel smart, and en-route to my wizard's robes and hat, when i used it to solve harder problems in creative ways, or designed ways around bugs and gremlins. For a good 3-4 years I would have immediately picked it as my favourite language.&lt;/p&gt;
    &lt;p&gt;So as I say, I didn't fall out of it with any sense of pique, I just naturally moved to different domains, and picked up tools that best fit. After Amazon, I spent t a lot of time concentrating on OS X and audio programming, and that involved a lot of objective C, C++. The scripting tools in that domain were often in ruby, sometimes python. For personal hacking, I picked up lisp again9 (which I'd always enjoyed in school). I dipped in and out of Perl here and there for occasional contract work, but I tended to gravitate more towards larger database stuff, where I typically found C, java and python. The next time I was building web things, it was all Rails and ruby, and then moving towards the web services / REST / cloud era, the natural fits were go, and of course node and JavaScript or Typescript. I've always been a polyglot, and I've always been pretty comfortable moving between programming languages. The truth of the matter is, that the majority of programming work is broadly similar, and the specific implementation details of the language you use don't matter all that much, if it's a good fit for the circumstances.&lt;/p&gt;
    &lt;p&gt;I can't imagine Perl disappearing entirely in my lifetime. I can remember entire programming environments and languages that are much, much deader than I can ever see Perl becoming.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pascal used to be huge for teaching and also for desktop development in the 8/16 bit era&lt;/item&gt;
      &lt;item&gt;Objective C - only really useful inside the Apple ecosystem, and they're hell bent on phasing it out.&lt;/item&gt;
      &lt;item&gt;Before I got into the Internet, I used to build application software for 16 bit Windows (3.11) which was a vast market, in a mixture of database 4GLs (like PowerBuilder, Gupta/Centura SQLWindows) and Win16 C APIs. This entire universe basically no longer exists, and is fully obsolete. There must be many similar cases.&lt;/item&gt;
      &lt;item&gt;I mean who the hell realistically uses common lisp any more outside of legacy or enthusiast markets? Less people than Perl I'm sure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perl also got to be if not first, then certainly early to dominate a new market paradigm. Plenty of things never manage that. It's hard to see Perl as anything other than an enormous success on these terms. Perl innovated and influenced languages that came after in some truly significant ways.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tightly embedding regular expressions and extending regular expressions (the most commonly used regular expression dialect in other tools is Perl)&lt;/item&gt;
      &lt;item&gt;CPAN, for package/library distribution via the internet, with dependency resolution - and including important concepts like supply chain verification with strong package signatures&lt;/item&gt;
      &lt;item&gt;A huge emphasis on testing, automated test harnesses, and CI. Perl test format (TAP) is also widely found in other CI/harness systems&lt;/item&gt;
      &lt;item&gt;Blending the gap between shell / scripting / and system programming in a single tool. I suppose this is debatable, but the way Perl basically integrated all the fundamental POSIX/libc as native built-ins with broadly the same semantics, but with managed memory and shell conventions was really revolutionary. Before this, most languages I had ever seen broadly tended to sit in one box, afterwards, most languages tended to span across several.&lt;/item&gt;
      &lt;item&gt;Amazing integrated documentation, online, in-tool and also man pages. POD is maybe the most successful ever implementation of literate programming ideas (although most of the real docs don't intertwingle the documentation very much iirc)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just these points, and I'm sure there are many others that could be made, are enough of a legacy to be proud of.&lt;/p&gt;
    &lt;p&gt;Counterfactuals are stupid (but also fun). If I squint, I can imagine that a Perl with a less reactionary culture, and a healthier acceptance of other ideas and environmental change might have been able to evolve alongside the other tools in the web paradigm shift, and still occupy a more central position in today's development landscape. That's not the Perl we have though, and that didn't happen. And I'm very confident that without the Perl we did have, the whole of modern software practice would be differently shaped. I do think Perl now lives in a legacy role, with a declining influence, but that's really nothing to feel shame or regret for. Nobody is going to forcibly take Perl away as long as POSIX exists, and so far as I can see, that means forever. In 2025 too, I can see the invisible hand creeping up on some of these other systems I've mentioned. Rust is slowly absorbing C and C++. Ruby (and of course Rails) is clearly in decline, in a way that probably consigns it to become a similar legacy state. From a certain angle, it looks a lot like Typescript is slowly supplanting Python. I won't be entirely surprised if that happens, although at my age I kind of doubt I'll live to see the day.&lt;/p&gt;
    &lt;head rend="h3"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;1 : Meritocracy is a fun word. It was originally coined as a pejorative term to describe a dystopian mechanism by which modern i.e. Western / British society entrenches and justifies an unfair and unequal distribution of privilege&lt;/p&gt;
    &lt;p&gt;2 : The UNIX implementer culture, is scientific/academic and fell out of Bell Labs. I guess you could extend this school of thought as a cultural sweep towards building abstracted cloud operations, toward plan 9/ Inferno / go&lt;/p&gt;
    &lt;p&gt;3 : Web 2.0 was first defined in 1999 by Darcy DiNucci in a print article , the term didn't become mainstream until it was picked up and promoted by Tim O'Reilly (then owner/operator of perl.com, trivia fans), an astute inside observer of the forces driving web development&lt;/p&gt;
    &lt;p&gt;4: Another unfortunate bit of luck here. Right at the point of time that 'agile' starts getting some traction as a more natural way to embrace software development - i.e. iterating in small increments against a changing environment and requirements, Perl 6 decides to do perhaps the most waterfall open source development process ever attempted. . It is fifteen years before Perl 6 ships something resembling a usable programming language.&lt;/p&gt;
    &lt;p&gt;5 : The Parrot VM, a lovely quixotic idea, which sadly fizzled out, after even Perl 6 stopped trying to target it. Interestingly enough, both python and ruby both made relatively high profile ports to the JVM that were useful enough to be used for production deploys in certain niches.&lt;/p&gt;
    &lt;p&gt;6 : A side effect of this degree of abstraction, is that as well as being very hard to get started, it's easy to fall foul of performance overhead.&lt;/p&gt;
    &lt;p&gt;7 : This ubituitious ecosystem of small footprint wordpress custom installs gives birth to the web agency model of commercial website building / small ecommerce sites, which thrives and is suprisingly healthy today. Recent, and slighly optimistic surveys have pitched WordPress as powering over 40% of all websites today. Now this is certainly inflated, but even if the realistic number is half of that, that's still pretty damn healthy.&lt;/p&gt;
    &lt;p&gt;8 : It's often repeated that Python was designed as a teaching language, but as far as I know, that's not actually the case. The designer of Python, Guido Van Rossum was previously working on a project that was a intended as training language, called ABC, and many of ABC's syntax and structural features influenced or made their way into Python.&lt;/p&gt;
    &lt;p&gt;9 : Common lisp is a better answer to an infinitely flexible 'everything' chainsaw language than perl, IMHO&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46175112</guid><pubDate>Sat, 06 Dec 2025 17:42:07 +0000</pubDate></item><item><title>OMSCS Open Courseware</title><link>https://sites.gatech.edu/omscsopencourseware/</link><description>&lt;doc fingerprint="e76af2125443a7a2"&gt;
  &lt;main&gt;
    &lt;p&gt;Georgia Tech’s Online Master of Science in Computer Science (OMSCS) program is proud to make the course content* for many of its courses publicly available through Ed Lessons. Select a course below to view the public content for that course.&lt;/p&gt;
    &lt;p&gt;Note that students enrolled in OMSCS should access their course content through Canvas, as the for-credit versions of these courses may include graded components or recent content updates not available through OMSCS Open Courseware.&lt;/p&gt;
    &lt;p&gt;*Course content typically includes things such as lecture videos and exercises; it will not include things like homeworks, projects quizzes, exams, or other graded assignments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46175826</guid><pubDate>Sat, 06 Dec 2025 19:14:35 +0000</pubDate></item><item><title>Zebra-Llama – Towards efficient hybrid models</title><link>https://arxiv.org/abs/2505.17272</link><description>&lt;doc fingerprint="c1d340b445bd08b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 22 May 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Zebra-Llama: Towards Extremely Efficient Hybrid Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:With the growing demand for deploying large language models (LLMs) across diverse applications, improving their inference efficiency is crucial for sustainable and democratized access. However, retraining LLMs to meet new user-specific requirements is prohibitively expensive and environmentally unsustainable. In this work, we propose a practical and scalable alternative: composing efficient hybrid language models from existing pre-trained models. Our approach, Zebra-Llama, introduces a family of 1B, 3B, and 8B hybrid models by combining State Space Models (SSMs) and Multi-head Latent Attention (MLA) layers, using a refined initialization and post-training pipeline to efficiently transfer knowledge from pre-trained Transformers. Zebra-Llama achieves Transformer-level accuracy with near-SSM efficiency using only 7-11B training tokens (compared to trillions of tokens required for pre-training) and an 8B teacher. Moreover, Zebra-Llama dramatically reduces KV cache size -down to 3.9%, 2%, and 2.73% of the original for the 1B, 3B, and 8B variants, respectively-while preserving 100%, 100%, and &amp;gt;97% of average zero-shot performance on LM Harness tasks. Compared to models like MambaInLLaMA, X-EcoMLA, Minitron, and Llamba, Zebra-Llama consistently delivers competitive or superior accuracy while using significantly fewer tokens, smaller teachers, and vastly reduced KV cache memory. Notably, Zebra-Llama-8B surpasses Minitron-8B in few-shot accuracy by 7% while using 8x fewer training tokens, over 12x smaller KV cache, and a smaller teacher (8B vs. 15B). It also achieves 2.6x-3.8x higher throughput (tokens/s) than MambaInLlama up to a 32k context length. We will release code and model checkpoints upon acceptance.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Mehdi Rezagholizadeh [view email]&lt;p&gt;[v1] Thu, 22 May 2025 20:39:57 UTC (12,646 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176289</guid><pubDate>Sat, 06 Dec 2025 20:15:54 +0000</pubDate></item><item><title>The past was not that cute</title><link>https://juliawise.net/the-past-was-not-that-cute/</link><description>&lt;doc fingerprint="26e613518ba77ebb"&gt;
  &lt;main&gt;
    &lt;p&gt;I was excited when cottagecore became a thing. Maybe my interest in retro clothes and handicrafts would be less embarrassing now!&lt;/p&gt;
    &lt;p&gt;I still enjoy it. But in spaces focused on old-fashioned vibes, you encounter a lot of people who believe that the past was actually this charming.&lt;/p&gt;
    &lt;p&gt;Laura Ingalls Wilder‘s Little House on the Prairie books are problematic, and also I will always love them. She wrote about the beauty of family and hard work, but she wrote them because she spent her whole life supporting disabled family members. She and her daughter beautified her “pioneer girl” history to make good books. Her daughter describes the reality: “It took seven successive years of complete crop failure, with work, weather and sickness that wrecked [my father’s] health permanently, and interest rates of 36 percent on money borrowed to buy food, to dislodge us from that land.”&lt;/p&gt;
    &lt;p&gt;My own version of this mistake was thinking that people’s personalities were different in the past. I grew up listening to folk music and imagining a past where nice boys would admire a nice quiet girl like me, and I wouldn’t have to figure out dating because everything would just unfold, probably on a May morning. My mother pointed out that a lot of the songs along the lines of “my own true love proved false to me” were about unplanned pregnancies.&lt;/p&gt;
    &lt;p&gt;I also assumed the bonny lasses in these songs would be wholesome and nice. But were popular girls of the past nicer people than they are now?&lt;/p&gt;
    &lt;p&gt;Some of my picture came from growing up in the Anglo-American folk dance and music community: it had a lot of aging hippies with graduate degrees. So I came away imagining a past with a lot of the kind of people who become engineers and English teachers. A more accurate picture would have been “Imagine a small town where the same 19 kids form your entire group of peers and potential partners.”&lt;/p&gt;
    &lt;p&gt;Bookish girls like Belle didn’t really go to live in enchanted castles with huge libraries. They stayed in villages where everyone thought they were weird and their best option was Gaston.&lt;/p&gt;
    &lt;p&gt;Maybe my favorite podcast episode ever is Rachel Laudan on food history: “I did have the extraordinary good fortune to grow up eating what I think the romantic movement dreams of. We had milk fresh from the cow; I never had pasteurized milk until I went to school. We had fish from the river, pheasant from the farm. The food was extremely good. . . . everything was fresh from the garden. So, I do romanticize—some of that because the taste was often extraordinary. And then I tweak myself and I say, ‘Look, Rachel, your mother spent all day, every day gardening or cooking.’ Essentially. As well as doing other chores. And she said to you, ‘Rachel, it’s servitude. I want you to have a life I didn’t have.’ “&lt;/p&gt;
    &lt;p&gt;I love living in a time and place where we get to choose aesthetics. I have bread rising in my kitchen right now, and I’m looking forward to baking it in an electric oven that doesn’t require me stacking wood or putting smoke into my house.&lt;/p&gt;
    &lt;p&gt;So I’ll continue to enjoy retro vibes, and draw on the past for lessons on how to be a human. (For example, making music together is one of life’s great experiences, and it’s a mistake to entirely substitute recorded music for that.) But I’ll enjoy doing so with indoor plumbing, dental care, and a desk job.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176893</guid><pubDate>Sat, 06 Dec 2025 21:53:35 +0000</pubDate></item><item><title>Screenshots from developers: 2002 vs. 2015 (2015)</title><link>https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/</link><description>&lt;doc fingerprint="5e3b5b5dcbbf3eec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Screenshots from developers: 2002 vs. 2015&lt;/head&gt;
    &lt;p&gt;In 2002 I asked a number of developers/Unix people for screenshots of their desktops. I recently republished them, and, seeing the interest this generated, I thought it’d be fun to ask the same people* again 13 years later. To my delight I managed to reach many of them.&lt;/p&gt;
    &lt;p&gt;* Sans Dennis Ritchie and itojun, who are no longer with us.&lt;/p&gt;
    &lt;p&gt;So, without further ado:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;my desktop is pretty boring, since it consists of xterm windows to whatever unix system i am using at the moment. the machine itself is likely to be running some x-window server like exceed on some flavor of windows, though for many years i just used an x terminal.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;If you thought it was boring last time, check this out!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;2002:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I don’t know how to make a screenshot, because I normally use my computer in text-mode. I have X and GNOME installed, but I use them only occasionally.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;2015:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Under X, I use the standard environment of Trisquel, but mostly I type at Emacs in a console.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Well, my desktop is quite boring. I mostly work with four xterms and a few Netscape windows. The KDE bar hides automatically, you can only see a thin grey line at the bottom.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Here is the new one. You'll see that, like before, I have lots of xterms where I work on Vim, Zimbu and email. Now using the Chrome browser, showing off the Zimbu homepage. But clearly everything has become bigger!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Linux (2.4.20-pre5), Gnome2, vim, Pine.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Not that much has changed in 13 years. Still using Linux. Still just a browser window and a ton of terminals hiding behind them. The main change is that switched from Pine to Thunderbird for email at some point. The OS on my laptop here is Ubuntu with Unity although there are a lot of Debian packages installed so it is a bit of a hybrid at this point. Oh, and yes, my son Carl is a lot older now.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Ah, my desktop is pretty boring, I used fvwm 1.24 as my window manager and I try to have no more than 1 or 2 windows open per virtual desktop. I use FreeBSD 4-STABLE as my operating system. I first came across Unix when I got an account on a Pyramid 90x running OSx. This had a dual-universe setup: both AT&amp;amp;T and BSD-style environments, chosen by an environment variable. Initially I was given the AT&amp;amp;T environment, but my friends convinced me to ``come over” to BSD. Since then I’ve been a BSD afficionado.&lt;/p&gt;
      &lt;p&gt;After OSx, SunOS 3.5 and later SunOS releases, until 386BSD 0.1 came out and I started to run BSD at home. Then when 386BSD transmogrified to FreeBSD, I went with FreeBSD.&lt;/p&gt;
      &lt;p&gt;In terms of desktop, I’m a command-line guy, always will be. My favourite editor is vi, my favourite shell is tcsh (but kudos to rc for elegance). So I don’t really feel the need for GUI things like Gnome or KDE :-)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;How things have (and have not changed). I'm still a command-line junkie with at least two xterm windows open. I'm still using a 3x3 virtual desktop. However, instead of fvwm, it is now LXDE. I've also switched from FreeBSD to Linux and I'm running Lubuntu as my distribution.&lt;/p&gt;
      &lt;p&gt;There are a lot of indispensable GUI tools that I use. These include Firefox, lyx, Gimp, KeepassX, Shutter, viking, dia, Wireshark, calibre, audacity, Handbrake and VLC. But where possible I still prefer to script things. My main development languages are still shell, Perl and C.&lt;/p&gt;
      &lt;p&gt;My shell is now bash. The vi keystrokes are burned into my fingertips and, as long as vim can be ported to new systems, that will be my text editor until I pass on. My mail client is now mutt (definitely not a web client) and my mail is stored locally, not on someone else's server.&lt;/p&gt;
      &lt;p&gt;The only issue I have is that, since a job change, I now have to deal with Windoze things. Thus, I have VirtualBox, libreoffice and Wine to help me do that.&lt;/p&gt;
      &lt;p&gt;I started with Unix on a Pyramid 90x. I now have a smart phone that blows the 90x out of the water on performance, RAM and storage. But I'm so very happy that, somewhere down underneath, there is still a Bourne shell and an operating system that does open(), close(), read(), write(), fork() and exec()!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;You’ll probably be sad (or perhaps not) to hear that my desktop hasn’t really changed much at all - still OS X, though because OS X has virtual desktops now I have multiple “desktops” (6 of them) where Mail.app runs on one, Safari on another, Calendar, Slack, etc - all on separate desktops. This makes it a bit boring, but here’s the one I probably spend the most time in - the terminal window desktop. :)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;There we go. Actually, that’s a condensate in one workspace cause I usually use about 4. Some of my favourite apps:&lt;/p&gt;
      &lt;item&gt;http://anjuta.sf.net/ (IDE)&lt;/item&gt;
      &lt;item&gt;http://quirc.org/ (IRC)&lt;/item&gt;
      &lt;item&gt;http://gaim.sf.net/ (IM)&lt;/item&gt;
      &lt;item&gt;http://multignometerm.sf.net/ (Term)&lt;/item&gt;
      &lt;p&gt;not on the shot, but worth noted&lt;/p&gt;
      &lt;item&gt;http://sylpheed.good-day.net/ (Email Client)&lt;/item&gt;
      &lt;p&gt;and of course a shot of RTCW&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;'screenshot as code', I maintain my desktop configuration through saltstack: https://github.com/TTimo/linux-salted/commits/master&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Discussion: Hacker News; reddit: /r/programming, /r/linux&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176905</guid><pubDate>Sat, 06 Dec 2025 21:55:09 +0000</pubDate></item><item><title>United States Antarctic Program Field Manual (2024) [pdf]</title><link>https://www.usap.gov/usapgov/travelAndDeployment/documents/Continental-Field-Manual-2024.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177132</guid><pubDate>Sat, 06 Dec 2025 22:26:26 +0000</pubDate></item><item><title>Saving Japan's exceptionally rare 'snow monsters'</title><link>https://www.bbc.com/future/article/20251203-japans-disappearing-snow-monsters</link><description>&lt;doc fingerprint="bf6c94c72441867b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Nothing else looks like them': Saving Japan's exceptionally rare 'snow monsters'&lt;/head&gt;
    &lt;p&gt;A unique natural wonder is being eroded. Can Japan bring its breathtaking "juhyo" back from the brink?&lt;/p&gt;
    &lt;p&gt;Each winter, the upper slopes of Mount Zao in northern Japan – one of the country's best-known ski areas – are transformed. Fir trees coated in thick frost and snow swell into ghostly figures known as "juhyo" or "snow monsters".&lt;/p&gt;
    &lt;p&gt;Juhyo form only under exceptionally rare atmospheric conditions, emerging when strong, persistent winter winds carry supercooled water droplets that freeze on contact with the local evergreen Aomori todomatsu trees, gradually layering into rime ice.&lt;/p&gt;
    &lt;p&gt;At Mount Zao, these formations occur during sustained westerly winds of up to 26m per second (85ft per second), with surface air temperatures between -6.3C to -0.1C (21-31F) and unusually high cloud liquid water content. Under these precise conditions, the rime thickens on the windward side of trees into overlapping ridges known as "shrimp tails", the distinctive shapes that cluster together to form the towering juhyo figures.&lt;/p&gt;
    &lt;p&gt;"Because such precise meteorological and ecological conditions align in very few places, Zao's snow monsters are a phenomenon almost unique to northern Japan," says Fumitaka Yanagisawa, an emeritus professor of geochemistry who studies the juhyo at Yamagata University.&lt;/p&gt;
    &lt;p&gt;The snow monsters are the biggest winter draw of the Zao area, a mountain range which lies between Japan's Yamagata and Miyagi prefectures and attracts tens of thousands of visitors annually.&lt;/p&gt;
    &lt;p&gt;But recent research indicates that the monsters are becoming slimmer.&lt;/p&gt;
    &lt;p&gt;In August 2025, a research team led by Yanagisawa announced findings that quantified what locals have long observed. By analysing identical-angle photographs of Zao's summit taken since 1933, the team measured the thickness of the figures on a six-point scale. The findings (which have not yet been published in a scientific journal) indicate a widespread shrinking of the juhyo.&lt;/p&gt;
    &lt;p&gt;"In the 1930s, we saw juhyo five to six metres [16-20ft] across," Yanagisawa says. "By the postwar decades, they were often two to three metres [7-10ft]. Since 2019, many are half a metre [1.6ft] or less. Some are barely columns."&lt;/p&gt;
    &lt;p&gt;The cause is twofold, says Yanagisawa: a warming climate and a forest under attack. The host tree, Aomori todomatsu, suffered a moth outbreak in 2013 that stripped its needles. Bark beetles followed in 2015, boring into weakened trunks. Yamagata officials report that around 23,000 firs, about a fifth of the prefectural side's stands, have died. With fewer branches and leaves, there is little surface for snow and ice to cling to.&lt;/p&gt;
    &lt;p&gt;Another 2019 study found that in nearby Yamagata City, average temperatures from December to March have risen by about 2C (3.6F) over the past 120 years. The lower altitude limit of juhyo formation has shifted upward in step with this warming, it found, while the juhyo also last for fewer days of the year.&lt;/p&gt;
    &lt;p&gt;"Unique landscapes are already being lost to climate change," says Akihiko Ito, an ecologist who specialises in forests and climate change at the University of Tokyo.&lt;/p&gt;
    &lt;p&gt;Research shows that Japan's warming climate and extreme weather are already damaging many of its high mountain forests. "Seasonal shifts in spring and autumn can harm leaves, and insect outbreaks are expanding. These stresses may reduce forest growth and density," Ito says.&lt;/p&gt;
    &lt;p&gt;Across Japan's alpine zones, temperatures have been rising faster than the global average since the 1980s. "In scenarios where climate change continues to advance significantly by the end of this century, it is possible that in warmer-than-usual winters, juhyo may no longer form at all," Ito says.&lt;/p&gt;
    &lt;p&gt;The threat has prompted action across Yamagata. In March 2023, the prefecture launched the Juhyo Revival Conference – a permanent council bringing together researchers, officials, local businesses and residents to coordinate long-term efforts to restore the fir forests and preserve Mount Zao's snow monsters.&lt;/p&gt;
    &lt;p&gt;Juhyo are not only a natural spectacle but also a pillar of the local economy. "The influx of tourists supports hotels, restaurants and souvenir shops throughout the area," says Genji Akiba, deputy director of the Zao Onsen Tourism Association. "If the juhyo disappear, it would be a huge blow."&lt;/p&gt;
    &lt;p&gt;"Revival is a strong wish of our citizens," says Yoko Honma, a conservation specialist at Yamagata Prefecture's nature division. Since 2019, the local forest office has transplanted more than 190 naturally regenerated saplings from lower slopes to the summit zone near the ropeway station. "Because it takes 50 to 70 years for these firs to mature, the key is sustaining conservation across generations," says Honma. "We need patience and continuity."&lt;/p&gt;
    &lt;p&gt;In Murayama, about 20km (12 miles) north-west of Zao, students from a forestry and environmental science course at Murayama Technical High School have also taken up the challenge of reviving the firs.&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• The overlooked benefits of real Christmas trees&lt;/p&gt;
    &lt;p&gt;• The secrets of the Amazon's most mysterious river&lt;/p&gt;
    &lt;p&gt;• The mysterious black fungus from Chernobyl that may eat radiation&lt;/p&gt;
    &lt;p&gt;Since 2022, the students have been planting Aomori todomatsu trees and studying how to propagate and protect the species. Together with staff from the Yamagata Forest Office, they visit Mount Zao to collect young fir saplings and bring them back to their school for research. There, they cultivate stems through cuttings and experiment with methods for artificially propagating and efficiently producing seedlings.&lt;/p&gt;
    &lt;p&gt;"It's been challenging," says Rin Oizumi, a second-year student in the course. "When the seeds we sowed in heavy rain finally sprouted, I felt both relief and excitement. But it was heartbreaking to find that some plots had been damaged by field mice, which had eaten the young shoots." The students have also conducted preliminary experiments using branches of a related fir species, which have shown successful germination.&lt;/p&gt;
    &lt;p&gt;Kanon Taniai, Oizumi's classmate, recalls seeing more and more fallen or dead trees as she and other students neared the summit one day in July 2024. "It made me feel really sad," she says. "Growing seedlings is hard work, but we want to do what we can to help bring Mount Zao back to life."&lt;/p&gt;
    &lt;p&gt;For Taniai, protecting the Juhyo means passing their legacy to the next generation. "They are called snow monsters because nothing else looks like them," she says. "I want the world to see them, and to feel how special Japan's nature is."&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;For essential climate news and hopeful developments to your inbox, sign up to the Future Earth newsletter, while The Essential List delivers a handpicked selection of features and insights twice a week.&lt;/p&gt;
    &lt;p&gt;For more science, technology, environment and health stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177418</guid><pubDate>Sat, 06 Dec 2025 23:06:53 +0000</pubDate></item><item><title>Kilauea erupts, destroying webcam [video]</title><link>https://www.youtube.com/watch?v=TK2N99BDw7A</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177645</guid><pubDate>Sat, 06 Dec 2025 23:39:02 +0000</pubDate></item><item><title>Using LLMs at Oxide</title><link>https://rfd.shared.oxide.computer/rfd/0576</link><description>&lt;doc fingerprint="ab11131f2d2c5aa1"&gt;
  &lt;main&gt;
    &lt;p&gt;Large language models (LLMs) are an indisputable breakthrough of the last five years, potentially profoundly changing the way that we work. As with any extraordinarily powerful tool, LLM use has both promise and peril — and that they are so general-purpose leaves real questions about how and when they should be used. The landscape is shifting so rapidly that static prescription is unlikely — but that LLMs are evolving so quickly also gives urgency to the question: how should LLMs be used at Oxide?&lt;/p&gt;
    &lt;head rend="h2"&gt;Values in LLM usage&lt;/head&gt;
    &lt;p&gt;As is our wont, it’s helpful to look at LLM use through the lens of our values, several of which come to mind, listed here in priority order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Responsibility: In terms of LLM use at Oxide, our lodestar is our sense of responsibility. However powerful they may be, LLMs are but a tool, ultimately acting at the behest of a human. Oxide employees bear responsibility for the artifacts we create, whatever automation we might employ to create them. That is, human judgement remains firmly in the loop: even if or as an LLM is generating an artifact that we will use (writing, test cases, documentation, code, etc.), their output is the responsibility of the human using them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rigor: LLMs are double-edged with respect to rigor. On the one hand, wielded carefully, they can help us sharpen our own thinking by pointing out holes in our own reasoning or otherwise providing thought-provoking suggestions. On the other, if used recklessly or thoughtlessly, they can have the opposite effect, replacing crisp thinking with generated flotsam. LLMs are useful in as much as they promote and reinforce our rigor.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Empathy: Be we readers or writers, there are humans on the other end of our language use. As we use LLMs, we must keep in mind our empathy for that human, be they the one who is consuming our writing, or the one who has written what we are reading.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Teamwork: We are working together on a shared endeavor, and we must be sure that our LLM use does not undermine our sense of teamwork. Specifically, we must be careful to not use LLMs in such a way as to undermine the trust that we have in one another. This isn’t as simple as disclosure of usage: and in fact, volunteering that an LLM has been used to generate work product is to implicitly distance oneself from the responsibility for the content — and serves as to erode the trust that is essential for teamwork.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Urgency: Urgency seems natural with a tool that can seemingly do so much knowledge work so quickly, but with respect to LLM use, too many organizations have seemingly enshrined urgency over all else. These organizations treat LLMs as an opportunity to increase pace over all else, seemingly without regard for setting direction. Urgency is certainly important, and LLMs absolutely afford an opportunity to do work more quickly — but that pace must not come at the expense of our responsibility, rigor, empathy and teamwork.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Uses of LLMs&lt;/head&gt;
    &lt;p&gt;LLM use varies widely, and the ramifications of those uses vary accordingly; it’s worth taking apart several of the (many) uses for LLMs.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as readers&lt;/head&gt;
    &lt;p&gt;LLMs are superlative at reading comprehension, able to process and meaningfully comprehend documents effectively instantly. This can be extraordinarily powerful for summarizing documents — or of answering more specific questions of a large document like a datasheet or specification. (Ironically, LLMs are especially good at evaluating documents to assess the degree that an LLM assisted their creation!)&lt;/p&gt;
    &lt;p&gt;While use of LLMs to assist comprehension has little downside, it does come with an important caveat: when uploading a document to a hosted LLM (ChatGPT, Claude, Gemini, etc.), there must be assurance of data privacy — and specifically, assurance that the model will not use the document to train future iterations of itself. Note that this may be opt-out (that is, by default, a model may reserve the right to train on uploaded documents), but can generally be controlled via preferences — albeit occasionally via euphemism. (OpenAI shamelessly calls this checked-by-default setting "Improve the model for everyone", making anyone who doesn’t wish the model to train on their data feel as if they suffer from a kind of reactionary avarice.)&lt;/p&gt;
    &lt;p&gt;A final cautionary note: using LLMs to assist comprehension should not substitute for actually reading a document where such reading is socially expected. More concretely: while LLMs can be a useful tool to assist in the evaluating of candidate materials per [rfd3], their use should be restricted to be as a tool, not as a substitute for human eyes (and brain!).&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as editors&lt;/head&gt;
    &lt;p&gt;LLMs can be excellent editors. Engaging an LLM late in the creative process (that is, with a document already written and broadly polished), allows for LLMs to provide helpful feedback on structure, phrasing, etc. — all without danger of losing one’s own voice. A cautionary note here: LLMs are infamous pleasers — and you may find that the breathless praise from an LLM is in fact more sycophancy than analysis. This becomes more perilous the earlier one uses an LLM in the writing process: the less polish a document already has, the more likely it is that an LLM will steer to something wholly different — at once praising your groundbreaking genius while offering to rewrite it for you.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as writers&lt;/head&gt;
    &lt;p&gt;While LLMs are adept at reading and can be terrific at editing, their writing is much more mixed. At best, writing from LLMs is hackneyed and clichÃ©-ridden; at worst, it brims with tells that reveal that the prose is in fact automatically generated.&lt;/p&gt;
    &lt;p&gt;What’s so bad about this? First, to those who can recognize an LLM’s reveals (an expanding demographic!), it’s just embarrassing — it’s as if the writer is walking around with their intellectual fly open. But there are deeper problems: LLM-generated writing undermines the authenticity of not just one’s writing but of the thinking behind it as well. If the prose is automatically generated, might the ideas be too? The reader can’t be sure — and increasingly, the hallmarks of LLM generation cause readers to turn off (or worse).&lt;/p&gt;
    &lt;p&gt;Finally, LLM-generated prose undermines a social contract of sorts: absent LLMs, it is presumed that of the reader and the writer, it is the writer that has undertaken the greater intellectual exertion. (That is, it is more work to write than to read!) For the reader, this is important: should they struggle with an idea, they can reasonably assume that the writer themselves understands it — and it is the least a reader can do to labor to make sense of it.&lt;/p&gt;
    &lt;p&gt;If, however, prose is LLM-generated, this social contract becomes ripped up: a reader cannot assume that the writer understands their ideas because they might not so much have read the product of the LLM that they tasked to write it. If one is lucky, these are LLM hallucinations: obviously wrong and quickly discarded. If one is unlucky, however, it will be a kind of LLM-induced cognitive dissonance: a puzzle in which pieces don’t fit because there is in fact no puzzle at all. This can leave a reader frustrated: why should they spend more time reading prose than the writer spent writing it?&lt;/p&gt;
    &lt;p&gt;This can be navigated, of course, but it is truly perilous: our writing is an important vessel for building trust — and that trust can be quickly eroded if we are not speaking with our own voice. For us at Oxide, there is a more mechanical reason to be jaundiced about using LLMs to write: because our hiring process very much selects for writers, we know that everyone at Oxide can write — and we have the luxury of demanding of ourselves the kind of writing that we know that we are all capable of.&lt;/p&gt;
    &lt;p&gt;So our guideline is to generally not use LLMs to write, but this shouldn’t be thought of as an absolute — and it doesn’t mean that an LLM can’t be used as part of the writing process. Just please: consider your responsibility to yourself, to your own ideas — and to the reader.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as code reviewers&lt;/head&gt;
    &lt;p&gt;As with reading comprehension and editing, LLMs can make for good code reviewers. But they can also make nonsense suggestions or otherwise miss larger issues. LLMs should be used for review (and can be very helpful when targeted to look for a particular kind of issue), but that review should not be accepted as a human substitute.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as debuggers&lt;/head&gt;
    &lt;p&gt;LLMs can be surprisingly helpful debugging problems, but perhaps only because our expectations for them would be so low. While LLMs shouldn’t be relied upon (clearly?) to debug a problem, they can serve as a kind of animatronic rubber duck, helping to inspire the next questions to ask. (And they can be surprising: LLMs have been known to debug I2C issues from the screenshot of a scope capture!) When debugging a vexing problem one has little to lose by using an LLM — but perhaps also little to gain.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as programmers&lt;/head&gt;
    &lt;p&gt;LLMs are amazingly good at writing code — so much so that there is borderline mass hysteria about LLMs entirely eliminating software engineering as a craft. As with using an LLM to write prose, there is obvious peril here! Unlike prose, however (which really should be handed in a polished form to an LLM to maximize the LLM’s efficacy), LLMs can be quite effective writing code de novo. This is especially valuable for code that is experimental or auxiliary or otherwise throwaway. The closer code is to the system that we ship, the greater care needs to be shown when using LLMs. Even with something that seems natural for LLM contribution (e.g., writing tests), one should still be careful: it’s easy for LLMs to spiral into nonsense on even simple tasks. Still, they can be extraordinarily useful — and can help to provide an entire spectrum of utility in writing software; they shouldn’t be dismissed out of hand.&lt;/p&gt;
    &lt;p&gt;Wherever LLM-generated code is used, it becomes the responsibility of the engineer. As part of this process of taking responsibility, self-review becomes essential: LLM-generated code should not be reviewed by others if the responsible engineer has not themselves reviewed it. Moreover, once in the loop of peer review, generation should more or less be removed: if code review comments are addressed by wholesale re-generation, iterative review becomes impossible.&lt;/p&gt;
    &lt;p&gt;In short, where LLMs are used to generate code, responsibility, rigor, empathy and teamwork must remain top of mind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mechanics&lt;/head&gt;
    &lt;p&gt;Mechanical details of using LLMs — along with many specific tips and links — can be found in the (internal) LLMs at Oxide document.&lt;/p&gt;
    &lt;head rend="h2"&gt;Determinations&lt;/head&gt;
    &lt;p&gt;Broadly speaking, LLM use is encouraged at Oxide, but that use must always be consistent with our deeply-held sense of responsibility: our responsibility to our product, our responsibility to our customers — and our responsibility to one another.&lt;/p&gt;
    &lt;head rend="h2"&gt;External References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;[rfd3] Oxide Computer Company. RFD 3 Oxide Hiring Process. https://rfd.shared.oxide.computer/rfd/0003.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178347</guid><pubDate>Sun, 07 Dec 2025 01:17:40 +0000</pubDate></item><item><title>Eurydice: a Rust to C compiler (yes)</title><link>https://jonathan.protzenko.fr/2025/10/28/eurydice.html</link><description>&lt;doc fingerprint="7e2eb37eada7ba38"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eurydice: a Rust to C compiler (yes)&lt;/head&gt;
    &lt;p&gt;Perhaps the greatest surprise of the last two years was, for me, the realization that people not only care about compiling C to Rust (for obvious reasons, such as, ahem, memory safety) â they also care about compiling Rust to C! Wait, what?&lt;/p&gt;
    &lt;p&gt;I wrote about this briefly a couple years ago, but the level of interest for the project, I must say, took me somewhat by surprise. So letâs talk about compiling Rust to C a little more today.&lt;/p&gt;
    &lt;head rend="h1"&gt;Barriers to Rust adoption&lt;/head&gt;
    &lt;p&gt;Rust is making big progress in terms of adoption, and represents a great value proposition, especially for new code. Both my former employer and my new employer, like pretty much everyone else these days, have big projects that are written in pure Rust or can have Rust components. Even Windows kernel drivers can be written in Rust now. Amazing stuff.&lt;/p&gt;
    &lt;p&gt;However, if your project is, say, an open-source library that gets compiled on a wonderfully diverse set of target architectures, OSes, distributions and toolchains, well, chances areâ¦ one of these is not going to support Rust. Think of a crypto library: there will be people out there with an obscure compiler for a weird embedded target, and they really want to compile your library, because theyâve been told not to roll out their own crypto. Or perhaps you have a format library ridden with memory errors and you want to port it to Rust. Or maybe your company has an in-house analysis that only runs on C code. Regardless of the scenario, there will always be that one legacy use-case that prevents you from switching to Rust until itâs 2035, all those LTS versions (looking at you RHEL) are finally retired, and you yourself are too close to retirement to even care anymore.&lt;/p&gt;
    &lt;p&gt;That is, unless youâre willing to use a Rust to C compiler.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why?&lt;/head&gt;
    &lt;p&gt;Having a backwards-compat scenario where Rust can be compiled to C serves several purposes.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It allows for a gradual transition. The codebase can be ported to Rust, and refactored / cleaned up / rewritten to use all the nice Rust things (data types, pattern-matching, polymorphism, memory safety), thus making you and your developers much, much happier. Meanwhile, the C version co-exists so that you donât alienate your userbase.&lt;/item&gt;
      &lt;item&gt;It only requires maintaining a single version. The Rust code is authoritative; the C code is derived from it automatically, either on CI, or at least with a CI job that checks that the two are in sync.&lt;/item&gt;
      &lt;item&gt;It allows for a census of problematic scenarios. By making the Rust version the default (and putting the fallback C behind a &lt;code&gt;--write-us-an-email&lt;/code&gt;flag), there is finally a way to enumerate those mythical users who cannot switch to Rust just yet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If that sounds appealing, meet Eurydice.&lt;/p&gt;
    &lt;head rend="h1"&gt;Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice is a compiler from Rust to C that aims to produce readable C code. Of course, readability is subjective; also, seeing that Rust relies on whole-program monomorphization, the C code is bound to be more verbose than the Rust code. But you can judge for yourself: hereâs the result of compiling libcrux to C.&lt;/p&gt;
    &lt;p&gt;The output of the test suite is under version control, and there are a lot more tests to peruse. See for instance this bit, compared to the Rust original.&lt;/p&gt;
    &lt;head rend="h1"&gt;The design of Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice plugs in directly at the MIR level, using Charon to avoid reimplementing the wheel and paying the price of interacting with the guts of &lt;code&gt;rustc&lt;/code&gt;. Our
paper on Charon says more about its
architecture.&lt;/p&gt;
    &lt;p&gt;The advantage of plugging in at the MIR level is that i) we do not have to interpret syntactic sugar, which means our translation is more faithful to the Rust semantics, and ii) we have way fewer constructs that need compiling to C. Even then, itâs no easy feat to translate Rust to C.&lt;/p&gt;
    &lt;p&gt;There is naturally, the need to perform whole-program monomorphization, over types and const-generic arguments; the compilation of pattern matches into tagged unions; recognizing instances of iterators that can be compiled to native C &lt;code&gt;for&lt;/code&gt;-loops. Then, there are more subtle things, such as compiling array
repeat expressions sensibly â zero-initializers when possible, initializer
lists otherwise, unless it generates too much code, in which case &lt;code&gt;for&lt;/code&gt;-loops are
preferable. And finally, there are all the rules about visibility, &lt;code&gt;static&lt;/code&gt;,
&lt;code&gt;inline&lt;/code&gt;, etc. that are very C-specific and depend on how you want to lay out
your C files.&lt;/p&gt;
    &lt;p&gt;The translation is complicated by the constraint that the generated code ought to be readable: for instance, we compile Rust structs to C structs, including DSTs, by relying on flexible array members. We also work hard to avoid using the fully-generic tagged union pattern when possible, instead eliminating the tag when e.g. the Rust enum only has a single case. Additionally, we rely on Charon to reconstruct control-flow, rather than compile the MIR CFG to C code ridden with &lt;code&gt;goto&lt;/code&gt;s; again, this is for code quality.&lt;/p&gt;
    &lt;p&gt;At a low-level, there were many interesting tidbits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Because arrays in Rust are values, we wrap them within C structs to give them value semantics in C, too; concretely, &lt;code&gt;[u32; 8]&lt;/code&gt;becomes&lt;code&gt;struct { uint32_t data[8]; }&lt;/code&gt;. (A previous version of Eurydice would emit&lt;code&gt;uint32_t *&lt;/code&gt;, and rely on various&lt;code&gt;memcpy&lt;/code&gt;s to implement value semantics, but this produced a translation that was not type-generic, and there were plenty of finicky corner cases. We revamped the compilation scheme recently.)&lt;/item&gt;
      &lt;item&gt;The notion of &lt;code&gt;lvalue&lt;/code&gt;in C means we need to insert more variable declarations than in Rust â for instance, you canât trivially compile&lt;code&gt;&amp;amp;[0u32; 1]&lt;/code&gt;without naming the array.&lt;/item&gt;
      &lt;item&gt;The fact that the evaluation order is so loosely defined in C means that intermediary computations need to be stored in intermediary variables to enforce the evaluation order.&lt;/item&gt;
      &lt;item&gt;Rust relies on whole-program monomorphization; this means that the C code is inevitably going to contains multiple copies of the same types and functions, but for different choices of type and const generic argumnets. This is currently done with a builtin phase in Eurydice (for historical reasons), but in the long run, we want to rely on Charonâs support for monomorphization.&lt;/item&gt;
      &lt;item&gt;There are plenty of peephole optimizations that are required for good code quality, such as recognizing &lt;code&gt;array::from_fn&lt;/code&gt;and generating sensible code that initializes the array in-place (instead of relying on the fully-general compilation scheme for closures), or recognizing instances of the&lt;code&gt;Eq&lt;/code&gt;trait that deserve dedicated treatment (such as using&lt;code&gt;memcmp&lt;/code&gt;for arrays and slices of flat data).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A final design choice is that for now, Eurydice may define more behaviors than Rust â for instance, Rust panics on integer overflow, but Eurydice-compiled code does not. This is because we assume the input code is verified, and therefore has been shown to be free of panics. This design choice can be easily changed, though.&lt;/p&gt;
    &lt;p&gt;In practice, as soon as you use traits, the C code becomes more voluminous than the Rust code. We rely on a configuration file mechanism to control the placement of monomorphized instances of a given function, rather than put everything in one big C file. This currently requires a lot of manual intervention to give good results on large projects.&lt;/p&gt;
    &lt;head rend="h1"&gt;Implementing of Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice starts by compiling the MIR AST obtained out of Charon into KaRaMeLâs internal AST. This is ~3000 lines of OCaml code, so thatâs already pretty involved. A lot of the work revolves around trait methods and their monomorphization, given Rustâs expressive trait system.&lt;/p&gt;
    &lt;p&gt;Then, about 30 nanopasses simplify the KaRaMeL AST until it becomes eligible for compilation to C. Of those, a handful were originally written for KaRaMeL and were somewhat reusable; this includes compilation of data types, as well as monomorphization. The rest was written from scratch for Eurydice, and totals about ~5000 lines of OCaml code.&lt;/p&gt;
    &lt;p&gt;A particularly gnarly phase was eliminating MIRâs variable assignments as much as possible: in MIR, every variable starts out uninitialized at the beginning of the function; then, in lieu of the variable declaration, we have an assignment with the initial value. Naturally, having a variable declaration in the right spot is better for code quality, so an initial phase tries to reconstruct these assignments. Thatâs a drawback of using MIR, but we still firmly believe that sticking to something that has clear semantics is ultimately better.&lt;/p&gt;
    &lt;p&gt;Fun fact: because there are so many peephole optimizations, I got tired of maintaining enormous pattern-matches that would try to catch every flavor of Rust iterator that can be compiled to a C for-loop. Instead, a custom OCaml syntax extension allows writing concrete syntax for the internal KaRaMeL language in OCaml patterns. Those magic patterns then get compiled at compile-time to OCaml AST nodes for an actual OCaml pattern that matches the (deeply-embedded) syntax of KaRaMeLâs AST. This relies on a &lt;code&gt;ppx&lt;/code&gt;
that lexes, parses and compiles the concrete syntax.&lt;/p&gt;
    &lt;head rend="h1"&gt;Deploying Eurydice-generated code&lt;/head&gt;
    &lt;p&gt;Eurydice-generated code expects some hand-written glue that contains macros and &lt;code&gt;static inline&lt;/code&gt; functions; sometimes, itâs simply more convenient to write a
single macro that uses a type, rather than have Eurydice generate N copies of a
polymorphic function that gets specialized each time. A typical example is
compiling the Eq trait for arrays: itâs nicer to emit &lt;code&gt;Eurydice_array_eq(a1, a2,
len, t)&lt;/code&gt;, which macro-expands to &lt;code&gt;!(memcmp(a1, a2, len*sizeof(t)))&lt;/code&gt;, rather than
have N such functions, each containing a for-loop specialized for different
values of &lt;code&gt;t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Eurydice generates code that is either (C11 and C++20-compatible) or (C++-17 compatible, but not C-compatible). The reason for this is that Rust allows enum values (e.g. &lt;code&gt;Foo { bar: baz }&lt;/code&gt;) in any expression position. For simplicity,
Eurydice emits a compound initializer &lt;code&gt;(Foo) { .tag = bar, .value = { .case_Foo
= { .bar = baz }}}&lt;/code&gt;, or a C++20 aggregate that uses designated initializers,
relying on a macro (not shown here) to hide the syntax differences between the
two. But C++17 does not have designated initializers, so there is an option for
Eurydice to emit different code that relies on member pointers to achieve
sensibly the same effect.&lt;/p&gt;
    &lt;head rend="h1"&gt;Limitations of Eurydice&lt;/head&gt;
    &lt;p&gt;Naturally, there are many limitations to this approach. Here are the main ones that come to mind:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;we cannot guarantee that the layout of objects will be the same in C as in Rust; conceivably, one could parse the layout information from MIR, then emit compiler-specific alignment directives to keep the two identical, but this is not done currently;&lt;/item&gt;
      &lt;item&gt;the generated code violates strict aliasing, because creating a user-defined DST involves casting one pointer type (a struct containing an array) to another (a struct with a flexible array member instead); Iâm not sure what the best fix is, so for now, please compile your code with &lt;code&gt;-fno-strict-aliasing&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;the code that Eurydice sees is MIR after applying &lt;code&gt;cfg&lt;/code&gt;tweaks; this means that for code that is intended to be multi-platform, some tricks need to be applied, otherwise, Eurydice will only âseeâ one version of the code (AVX2, or ARM64, or something else)&lt;/item&gt;
      &lt;item&gt;because monorphization is so pervasive, the configuration language needs to express things such as âtypes that reference &lt;code&gt;__m256i&lt;/code&gt;, an AVX2-only type, need to go into a separate file to be compiled with&lt;code&gt;-mavx2&lt;/code&gt;â; this can get tedious real fast but Iâm not sure I know how to do better.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Whatâs next?&lt;/head&gt;
    &lt;p&gt;There is ongoing work to integrate Eurydice-generated code for both Microsoft and Googleâs respective crypto libraries.&lt;/p&gt;
    &lt;p&gt;The community grew recently, with wonderful contributions by GitHub users @ssyram and @lin23299. There are more in the pipeline, and I look forward to seeing the supported subset of Rust grow even more. Next on the horizon is support for &lt;code&gt;dyn&lt;/code&gt; traits via vtables, and relying on Charonâs monomorphization
to get MIR exactly as the Rust compiler would monomorphize it, intead of relying
on a custom procedure in Eurydice.&lt;/p&gt;
    &lt;p&gt;An ambitious goal is for the whole standard library of Rust to be extractable via Eurydice in 2026. This is non-trivial, but I believe this achievement is within reach. Stay tuned.&lt;/p&gt;
    &lt;head rend="h1"&gt;PS: Why the name?&lt;/head&gt;
    &lt;p&gt;People keep asking about the name; because the project shares a large amount of infrastructure with Aeneas and Charon, I had to follow the Greek mythology theme. Specifically, the myth of Eurydice resonated with me: I thought I was saved from the hell of generating C code, and was going to go back to the world of the living, but alas, no.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178442</guid><pubDate>Sun, 07 Dec 2025 01:41:33 +0000</pubDate></item><item><title>Oblast: A better Blasto game for the Commodore 64</title><link>http://oldvcr.blogspot.com/2025/12/oblast-better-blasto-game-for-commodore.html</link><description>&lt;doc fingerprint="b6785d833bb7919f"&gt;
  &lt;main&gt;&lt;p&gt;So, in that article, I mentioned two future Blasto projects. One is to save my pennies for a custom arcade cabinet to put the board in, though I just spent a cool grand plus on tires which used up a lot of those pennies and I've also got Christmas presents to buy. But the second was to write my own take on TI Blasto and soup it up. This project is the second one from my bucket list that I've completed. It took a couple years of work on it off and on, but it's finally done, with faster action and animation, a massive number of procedurally generated screens, and fully configurable gameplay.&lt;/p&gt;I've christened it Oblast, and it's free to play on your real Commodore 64 or emulator. Let's talk about what's the same and what's different. The antediluvian 1978 Blasto ran on Hustle hardware, which was derived from Gremlin's original (and mercilessly copied) Blockade game as designed by Lane Hauck. Programmer Bill Blewitt managed to squeeze Blasto's entire game code, not counting character graphics, into just 2K of ROM. This code had to generate and draw the maze, handle one or two player inputs, handle their projectiles, check for collisions and trigger the audio and "boom" circuits, all while simultaneously setting off explosions that could trigger other explosions and other collisions. In the upright version it also had free game logic. Given its hardware and software size constraints the arcade game's gameplay limitations, which we'll discuss in a moment, were understandable. When Milton Bradley picked up the license (from Gremlin's new owner Sega) as a developer for the new TI 99/4, they kept the gameplay and basic rules in their home computer port almost identical. Instead, the programmers added music tracks, a colour display, and multiple configuration options. You could set not only the game's speed (I always played Full Tilt) ... ... but also how the maze was drawn, including whether trails existed (areas of the map pre-cleared for motion) and how dense the mines were. Likely as a way to emphasize the TMS9918(A)'s colour capabilities, the MB programmers changed the setting of the game to a green earth-bound landscape with blue (?) mines and reworked the spaceships into tanks. The density option probably had an even greater impact on gameplay than the speed setting because a maze with a lot of mines made for a zippier, more explosive game. You could rig some big bangs this way, though these were sadly were let down by the TMS9919/SN76489's relatively weak noise output. The program also vainly tried to play a simple tune during the game but this was inevitably interrupted and forced to start over by any sound effect (i.e., a tank shooting, mines exploding). As with the original, you have infinite lives but finite time. If you trip on an explosion, or the other player shoots you in two-player mode, you lose valuable seconds until you respawn. However, you respawn at your original spawn point as if you were teleported there, a conceivable failure mode for a fanciful spaceship but an extremely unlikely one for a terrestrial tank, which makes a good segue into some of its other idiosyncrasies:&lt;list rend="ul"&gt;&lt;item&gt;Each player can only have a single projectile in motion at any time. However, as soon as that projectile impacts, you can immediately fire another one. This is clearly motivated by the limited memory in the original game, but I don't know of any artillery shell in real life that works like that!&lt;/item&gt;&lt;item&gt;As a related phenomenon, although you can move while an explosion or chain reaction is occurring (with a slight reduction in frame rate), you can't shoot — at least not until the explosions stop, at which point you can once again shoot immediately. This also seems to be a concession to limited available memory as the game can't track multiple chain reactions at once.&lt;/item&gt;&lt;item&gt;Tanks absolutely can't go over mines or obstacles; they act as completely impassible barriers. I guess that might make sense with spaceships, but it seems like a rather wussy sort of tank.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Now, I want to point out that despite those things, I loved TI Blasto and played quite a bit of it. But we can improve on what is already an awful lot of fun.&lt;/p&gt;It took a while to get the fundamentals laid down, and it was immediately obvious that the most important mechanic in the game had to be the chain reaction since everybody likes to blow %@#$ up. Consequently, the code that handles the explosions was the first part of the game I wrote, as I reasoned the game wouldn't be worth completing if I couldn't get it fast or frantic enough. This very early draft was a simple proof of concept using PETSCII graphic characters to model the algorithm; character graphics were a must because doing this on the high-resolution screen would have played like molasses.&lt;p&gt;The game doesn't track explosions anywhere else but the screen itself: everything it needs to determine the next frame of animation is by looking at what's set on the characters present. It scans the entire playfield each time to do this which necessarily locks the animation to a constant frame rate — even if the whole screen were alive with multiple explosions, it would take nearly exactly as much time as if only one single bomb were being detonated, keeping gameplay speed consistent. I did a lot of code unrolling to make this work as quick as possible and the final draft of the original "screen test" is what's in Oblast now.&lt;/p&gt;&lt;p&gt;The black area is because I already knew I'd be using sprites for the tank and I didn't want to mess around with having to manage the high bit for X coordinates greater than 255, so I reserved the right-hand portion of the screen for an information pane. This also had the nice side effect of reducing how much of the screen must be scanned.&lt;/p&gt;For Oblast, I've concentrated exclusively on the single-player mode in which I played Blasto most, which also simultaneously solved some technical issues. (I may make a two-player version in the future if I figure out good solutions to them.) Although I've kept the spirit of TI Blasto's configurability, I made it extend not just to maze generation but even to the game's core rule set. The configuration portion is largely written as a BASIC stub with some 6502 assembly language helpers for speed, with the bulk of the remainder and the entirety of the main game loop also in assembly language.&lt;p&gt;There are four preset games, the parameters for which I selected after tweaking them during repeated playtesting. The first is the one I consider "typical" for most players to start with (and the one you'll see the computer attempt to play during Oblast's attract mode), the second has an increased number of bombs, the third adds trails and more Blasto-like rules for more classic gameplay, and the fourth is a completely gonzo game mode which has become my personal favourite after a rough day at work.&lt;/p&gt;If you don't like those presets, or want to tweak them further, there is a full game configuration screen letting you set game modes and the starting level/screen. The game supports up to 384 procedurally generated screens and you can start on any of them from 0 to 255. The screens are generated from constant seed data (in this case the 64's BASIC ROM) and thus designed to generate the same screen with the same parameters, facilitating muscle memory for longer play if you get good.&lt;p&gt;Like the two versions of Blasto, Oblast has mines (bombs) and obstacles (trees). You can very precisely control the densities of both. You can also have the game generate Blasto-style trails horizontally, vertically or both, you can set how quickly your tank's fuel is exhausted (i.e., your time limit, the only option which cannot be zero), and you can indicate if your tank is invulnerable to explosions and how quickly to cycle your shells. I'll talk about how that works in a moment. If you press one of the preset function keys in the configuration screen, then its settings are loaded as a starting point for you to modify.&lt;/p&gt;For the presets, where a new player wouldn't know exactly the game conditions they trigger, I pondered various in-game ways of informing them and hit on an easy-to-implement "dot matrix printout" motif where the BASIC stub scrolls a "briefing" before starting play, making asynchronous "printer" noises based on the bit pattern of each line's ASCII codes. This same motif is used for the basic built-in help since I had some extra space available.&lt;p&gt;Once you've got the settings the way you want, or you just want to keep playing the same preset, after a game ends you can bypass the presets and game configuration screens and jump right into a new game with the same settings by pressing the fire button.&lt;/p&gt;Here's two examples of the procedural screen generation at work, both level 0. The top screen is what you'd start at if you chose the "Regular Duty" (F1) preset; the second is "More Like Classic Blasto" (F5). Both have the same seed pointer, and you can see some commonalities in bomb and tree positions, but the second screen has a slightly lower bomb density and a slightly higher tree density plus trails going both horizontally and vertically. Each collection of settings will always generate the same screens on your machine. The game code manually counts the number of bombs and trees at the end of map generation since they may be taken away by trails or in the process of ensuring the tank has a cleared starting position.&lt;p&gt;Although we're using a custom character set for speed, I still wanted the colour flexibility of high resolution where you can have different text and background colours. To do so Oblast is something of a love letter to one of the VIC-II's more underutilized display modes, extended background colour mode (ECM). ECM supports up to four background colours on the same screen and the main game uses two additional colours besides the green background, the most obvious being the black background of the information pane, but also a yellow background as part of animating explosions. The price you pay for this flexibility is that only 64 characters of the standard 256-entry character set can be used; the two high bits instead become a bit pair to select the background colour.&lt;/p&gt;That meant making a lot of careful decisions about what I was going to actually display and getting those shapes into the first 64 character glyphs, shown here in Ultrafont+. You'll notice that I've replaced some of the letters and typographic characters with graphic shapes because I knew I would never actually need to display those letters or symbols. Everything you see on the screen except for the tank and the shells is a character in this custom font. On the bright side, this character limit also means we can reduce the memory needed by the game font by 75 percent. By looking for the bit set for the black background of the (impervious) information pane, as well as the wall character that also has this bit set, the game knows not to propagate explosions into that area. The yellow background comes in for knowing what needs to detonate next frame: the routine uses that bit as a deferred marker so that as it sweeps sequentially through the screen it doesn't update the same bomb twice in the same frame and prematurely snuff it out. Since setting that bit will also cause a different background colour to be used, we use yellow to make the explosion visually interesting as another side effect.&lt;p&gt;Parenthetically, the TMS9918 and TMS9918A also have a feature like this which TI Blasto itself appears to use: each 32 character block of its 256-character fonts can have its own colours. Unlike the VIC-II's ECM which must be specially enabled, this is a standard feature of the 32x24 text mode (which TI calls "Graphic I"), but the character shapes remain unchanged in each block which may require making duplicates (whereas with ECM they are always drawn from the first 64 glyphs).&lt;/p&gt;If there are a lot of bombs on screen, as is the case in the fourth preset and my favourite gameplay mode, nearly the entire screen will be consumed with the explosion which animates around you as you shoot other things. This wasn't possible in either of the original Blastos. Also, instead of trying to play music during game play, all three SID voices are used for noise generation (with a low-pass filter and some resonance smeared on for a woofer-like effect). Voice 1 is triggered when you fire your gun and voice 2 is always running as the tank's engine, with its frequency varying with motion and tank rotation. Voice 3 is used specifically for explosions because it's the only SID voice where you can directly sample both the oscillator waveform output and the current amplitude of the audio envelope. We take these samples, scale them to the activity on screen, and feed the result into the VIC-II's screen fine X scroll. Lots of explosions cause lots of shaking, yet the shaking is always in sync with the audio.&lt;p&gt;Besides the character graphics, the other major screen component are the sprites. The tank is a composite of three sprites: an animated set for the tank tread, the main tank body, and an accent layer. This is sharper than using multicolour sprites where your horizontal resolution is halved. These three sprites move together and the build system automatically precalculates frames to rotate them off a template, which are played back on screen when you turn. Unlike both versions of Blasto where the tank is limited to integral character positions, the tank in Oblast is larger than the bombs and trees and can move in single pixels, though I still limited movement to 90 degree angles so I didn't have to do expensive trig computations to figure out a shell's trajectory.&lt;/p&gt;&lt;p&gt;One sprite being used as the fuel gauge needle left four sprites for the shells. I had earlier considered using character graphics for them too, but animating shells that way would be slower and less smooth than moving sprites. On the other hand, then, without resorting to tricks there can only be four shells onscreen at once which also didn't seem very tank-like. After some thought I came up with a game mechanic to explain it. In the information pane in these two shots, you see the level number, the fuel gauge which acts as your timer, and then four blue shell indicators. Three of these indicators are dark blue, indicating they are reloading (the fourth is a bright cyan, indicating ready). We'll simply define the reloading time for any shell chamber as the maximum length of time it takes a shell to get across the screen in any direction. Thus, no matter how much you fire, you can only ever have four on-screen because the reloading time will lock you out. (Blasto-style fire control where shells recycle immediately as they hit something is preserved for that game mode, or if you turn on "fast cycl[ing] shells" from the configuration screen.)&lt;/p&gt;&lt;p&gt;While propagating explosions is approximately constant-time, other operations in the game may not be, and there's no reason to walk the screen if nothing's marked as needing it. That means we need a timebase to keep frame rates stable. For this purpose I used the Kernal jiffy clock, which on both PAL and NTSC systems is triggered by the Timer A interrupt to tick about every 1/60 second. The game loop locks to this and uses it to know when to move game objects and trigger screen updates. Still, even this isn't fast enough for moving very speedy things like the shells you fire and the game felt too slow. So ... we make the Timer A interrupt even faster, flogging it at 240Hz instead of 60Hz (the game has prescaler values for both PAL and NTSC), making jiffies 1/240 of a second instead and moving objects at that rate.&lt;/p&gt;&lt;p&gt;This does have interesting interactions when the VIC-II is still drawing your screen at either 50 or 60Hz even as you update it four times as quickly, and most of these interactions have to do with collisions because you can move objects faster than the VIC-II can detect they intersect. The bombs are as big as they are because that gives lots of opportunities to detect a shell striking one, but tank collisions remained unreliable with smaller graphics like trees. Fortunately, however, we've already declared we didn't like the fact that trees and bombs (i.e., obstacles and mines) were impassible objects, so we can make this deficiency into a virtue. The game keeps running track of where the tank last was and if a collision is detected immediately moves it back to that position. However, because collisions are detected inconsistently at this rate of motion and the game updates the tank's coordinates faster than the VIC will draw them, it ends up manifesting onscreen as the tank simply slowing down when it has to cross an obstacle. I like that better than just coming to a dead halt.&lt;/p&gt;Explosions, however, are nice big targets and we have no problem detecting when the tank gets nailed by one of those. In the game modes where your tank is vulnerable, we throw your tank into a temporary tailspin, start flashing the border and the information pane (which is just a matter of setting its colour register), turn on voice 1 and voice 3 at the same time for an even bigger boom, and take the envelope and waveform from voice 3 and put it into the fine Y scroll register as well as the X to really throw the screen around. My favourite game mode allows you to blow up the entire playfield with impunity, of course. I also decided to overhaul the scoring with special bonuses silently awarded after completing a screen and detailed cumulatively at the end when your score is added up (total bombs exploded plus total bonuses earned). Don't cheat and look at the source code, but the descriptions of the bonuses should give you a clue as to how you win them. Note that some bonuses are mutually exclusive, and some are explicitly disabled ("n/a") in certain game configurations that make them impossible or unavoidable.&lt;p&gt;Should you beat the default high score, you'll see another use of extended background colour mode for the champion medal (you'll just have to beat it fair and square, no spoiler screenshots). This segment uses FLD to scroll the medal into view and then cycles the ECM registers for a masked multiple colour bar effect without having to split the screen horizontally. It's a simple effect that I threw together in an afternoon but I think it looks nice. While the game configuration screen looks like it might use ECM for the top title, it actually doesn't because I needed lowercase letters, so I employ a much simpler trick for that screen which shouldn't take you long to figure out.&lt;/p&gt;&lt;p&gt;A key goal was to get the entire game in memory at once without additional loading or disk access, meaning you can even run it from cassette tape if you want to. In memory everything is arranged around the two character sets, the bank of sprites and the two hi-res title screens which are in fixed locations to deal with the VIC-II's more constrained view of memory (one of the hi-res screens is slotted under the BASIC ROM so I could free up 8K for something else). I then redistributed the various machine language subroutines and the three music tracks around those assets while also ensuring the BASIC menu stub had enough free memory to maintain its variables. After the core game was done I added two more extras on, the attract mode (which required some reworking to fit) and a really silly credits sequence, which implements a double-buffered screen scroller and takes advantage of the fact that the main music track sounds pretty neat slowed down. The entire mess is then single-parted using my custom cross-linker and optionally compressed.&lt;/p&gt;Oblast is freeware and open source on Github. You can build it with Perl 5, the xa65 cross assembler and optionally the pucrunch compressor. The Perl tools to generate the sprites, the tokenized BASIC code and the uncompressed runnable linked version are all included. Say that you want to change the presets to your own preferred settings: just change the corresponding DATA statement in the BASIC code, do a make and instantly have your modified binary. All I ask is that modified binaries that you provide to others should use a different name so they aren't confused with the original, and note that this game and any derivative works based on it or its components are under the Floodgap Free Software License.&lt;p&gt;If you just want to play it, the Github releases tab provides compressed (for actual floppy disks or tape or other media with limited space) and uncompressed (for fast DMA cartridges and emulators) builds as .prg files you can run directly. You'll need a joystick or equivalent in port 2, and the game should run on any PAL or NTSC Commodore 64. This is hardly the last game, let alone project, on my bucketlist, but it's good to knock another one off it. Also, please don't blow up trees in real life.&lt;/p&gt;&lt;p&gt; If you've enjoyed playing, buy me a &lt;del&gt;coffee&lt;/del&gt; Pibb. &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178464</guid><pubDate>Sun, 07 Dec 2025 01:47:23 +0000</pubDate></item><item><title>Z2 – Lithographically fabricated IC in a garage fab</title><link>https://sam.zeloof.xyz/second-ic/</link><description>&lt;doc fingerprint="6f28c43798a75591"&gt;
  &lt;main&gt;
    &lt;p&gt;Homemade 1000+ transistor array chip&lt;/p&gt;
    &lt;p&gt;In 2018 I made the first lithographically fabricated integrated circuits in my garage fab. I was a senior in high school when I made the Z1 amplifier, and now I’m a senior in college so there are some long overdue improvements to the amateur silicon process.&lt;lb/&gt; The Z1 had 6 transistors and was a great test chip to develop all the processes and equipment. The Z2 has 100 transistors on a 10µm polysilicon gate process – same technology as Intel’s first processor. My chip is a simple 10×10 array of transistors to test, characterize, and tweak the process but this is a huge step closer to more advanced DIY computer chips. The Intel 4004 has 2,200 transistors and I’ve now made 1,200 on the same piece of silicon.&lt;/p&gt;
    &lt;p&gt;Previously, I made chips with a metal gate process. The aluminum gate has a large work function difference with the silicon channel beneath it which results in a high threshold voltage (&amp;gt;10V). I used these metal gate transistors in a few fun projects like a guitar distortion pedal and a ring oscillator LED blinker but both of these required one or two 9V batteries to run the circuit due to high Vth. By switching to a polysilicon gate process, I get a ton of performance benefits (self aligned gate means lower overlap capacitances) including a much lower Vth which makes these chips compatible with 2.5V and 3.3V logic levels. The new FETs have excellent characteristics:&lt;/p&gt;
    &lt;quote&gt;NMOS Electrical Properties: Vth = 1.1 V Vgs MAX = 8 V Cgs = &amp;lt;0.9 pF Rise/fall time = &amp;lt;10 ns On/off ratio = 4.3e6 Leakage current = 932 pA (Vds=2.5V)&lt;/quote&gt;
    &lt;p&gt;I was particularly surprised by the super low leakage current. This value goes up about 100x in ambient room lighting.&lt;/p&gt;
    &lt;p&gt;Now we know that it’s possible to make really good transistors with impure chemicals, no cleanroom, and homemade equipment. Of course, yield and process repeatability are diminished. I’ll do more testing to collect data on the statistics and variability of FET properties but it’s looking good!&lt;/p&gt;
    &lt;p&gt;The chip is small, about one quarter the die area of my previous ICs (2.4mm^2) which makes it hard to probe. There’s a simple 10×10 array of N-channel FETs on each chip which will give me a lot of characterization data. Since it’s such a simple design, I was able to lay it out using Photoshop. Columns of 10 transistors share a common gate connection and each row is strung together in series with adjacent transistors sharing a source/drain terminal. It’s similar to NAND flash but I only did this to keep the metal pads large enough so I can reasonably probe them, if every FET had 3 pads for itself they would be too small.&lt;/p&gt;
    &lt;p&gt;It’s hard to convey the excitement of seeing a good FET curve displayed on the curve tracer after dipping a shard of rock into chemicals all day.&lt;/p&gt;
    &lt;p&gt;A single 10µm NMOS transistor can be see below, with slight misalignment in the metal layer (part of the left contact is uncovered). Red outline is polycrystalline silicon, blue is the source/drain.&lt;/p&gt;
    &lt;p&gt;So far I’ve made an opamp (Z1) and a memory-like array (Z2). More interesting circuits are definitely possible even with this low transistor density. The process needs some tweaking but now that I’m able to consistently make good quality transistors I should be able to design more complex digital and analog circuits. Testing each chip is very tedious so I am trying to automate the process and I’ll post more data then. I’ve made 15 chips (1,500 transistors) and know there’s at least one completely functional chip and at least two “mostly functional”, meaning ~80% of the transistors work instead of 100%. No proper yield data yet. The most common defect is a drain or source shorted to the bulk silicon channel, not a leaky or shorted gate like on my Z1 process.&lt;/p&gt;
    &lt;p&gt;I said before that the gate used to be made out of aluminum and now it’s silicon which makes the chips work a lot better. Silicon comes in three varieties that we care about: amorphous, polycrystalline, and monocrystalline. From left to right, these become more electrically conductive but also much harder to deposit. In fact, monocrystalline Si can’t be deposited, you can only grow it in contact with another mono-Si layer as a seed (epitaxy). Since the gate must be deposited on top of an insulating dielectric, poly is the best we can do. We can heavily dope the polysilicon anyway to make it more conductive.&lt;/p&gt;
    &lt;p&gt;A typical self-aligned polysilicon gate process requires silane, a toxic and explosive gas, to deposit polycrystalline silicon layers. It may also be possible by sputtering or evaporating amorphous silicon and annealing with a laser. A major theme of this DIY silicon process is to circumvent expensive, difficult, or dangerous steps. So, I came up with a modified process flow. It’s a variation on the standard self-aligned methods to allow doping via high temperature diffusion rather than ion implantation. The effect is that I’m able to buy a silicon wafer with the polysilicon already deposited on it from the factory and pattern it to make transistors instead of putting my own polysilicon down halfway through the process. This is a nice short term workaround but it would be best to design a polysilicon deposition process using the laser anneal method mentioned above.&lt;/p&gt;
    &lt;p&gt;Wafers are available with all kinds of materials deposited on them already, so I just had to find one with a thin layer of SiO2 (gate oxide, ~10nm) followed by a thicker polysilicon (300nm). I found a lot of 25 200mm (EPI, prime, [1-0-0], p-type) wafers on eBay for $45 which is essentially a lifetime supply, so email me if you want one. The gate oxide is the most fragile layer and requires the most care during fabrication. Since I bought the wafer with a nice high quality oxide on it already that was capped off and kept clean by the thick polysilicon layer, I was able to eliminate all the aggressive cleaning chemicals (sulfuric acid, etc) from the process and still make great transistors. Minimal process chemicals and tools are listed below.&lt;/p&gt;
    &lt;quote&gt;Chemicals used in home poly-gate process: -Water -Alcohol -Acetone -Phosphoric acid -Photoresist -Developer (2% KOH) -N type dopant (filmtronics P509) -HF (1%) or CF4/CHF3 RIE -HNO3 for poly etch or SF6 RIE&lt;/quote&gt;
    &lt;quote&gt;Equipment used in home poly-gate process: -Hotplate -Tube furnace -Lithography apparatus -Microscope -Vacuum chamber to deposit metal&lt;/quote&gt;
    &lt;p&gt;Z2 “gate first” process (similar to standard self-aligned process but without a field oxide):&lt;/p&gt;
    &lt;p&gt;I snapped one of the test chips in half (functional Z2 but with bad layer alignment and thin metal, about 300nm) and put it in my SEM for a cross section:&lt;/p&gt;
    &lt;p&gt;Find the dust particle in the red circle below, use that to get oriented in the coming cross section views.&lt;/p&gt;
    &lt;p&gt;Because I bought the wafer already with gate oxide and polysilicon on it, I can’t grow a field oxide. These thick oxide layers are typically used to mask dopants and require a long high temperature step which would oxidize all of my poly and there would be none remaining. So, my modified process uses an additional masking step (the “gate” mask is typically not found in a self-aligned process) that allows me to use the polysilicon itself as a dopant mask and hard-baked photoresist as the field dielectric. This alternative processing results in the stepped structure you can see in the orange region on the NMOS cross section above. This process subtlety is mentioned here, read this twitter thread.&lt;/p&gt;
    &lt;p&gt;This process isn’t ideal and I want to make some changes so it’s CMOS compatible but it simplifies fabrication and makes it possible with a minimal set of tools. The 1µm dielectric layer (orange) would ideally be CVD SiO2 (it’s possible to build a TEOS oxide reactor at home) but I used a photoresist instead. Most photoresists can be baked around 250°C to form a hard permanent dielectric layer that is an easy alternative to CVD or PECVD oxide. A spin-on-glass/sol-gel could also be used here. SiO2 etching is done with a buffered HF solution made from rust stain remover or RIE.&lt;/p&gt;
    &lt;p&gt;Huge composite stitched die image:&lt;/p&gt;
    &lt;p&gt;Thanks for following my work and feel free to contact me with your thoughts!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178789</guid><pubDate>Sun, 07 Dec 2025 03:03:09 +0000</pubDate></item><item><title>Discovering the indieweb with calm tech</title><link>https://alexsci.com/blog/calm-tech-discover/</link><description>&lt;doc fingerprint="7fa459cf38cdcf2d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Discovering the indieweb with calm tech&lt;/head&gt;
    &lt;p&gt;When social media first entered my life, it came with a promise of connection. Facebook connected college-aged adults in a way that was previously impossible, helping to shape our digital generation. Social media was our super-power and we wielded it to great effect.&lt;/p&gt;
    &lt;p&gt;Yet social media today is a noisy, needy, mental health hazard. They push distracting notifications, constantly begging us to “like and subscribe”, and trying to trap us in endless scrolling. They have become sirens that lure us into their ad-infested shores with their saccharine promise of dopamine.&lt;/p&gt;
    &lt;p&gt;How can we defeat these monsters that have invaded deep into our world, while still staying connected?&lt;/p&gt;
    &lt;head rend="h2"&gt;StreetPass for Mastodon&lt;/head&gt;
    &lt;p&gt;A couple weeks ago I stumbled into a great browser extension, StreetPass for Mastodon. The creator, tvler, built it to help people find each other on Mastodon. StreetPass autodiscovers Mastodon verification links as you browse the web, building a collection of Mastodon accounts from the blogs and personal websites you’ve encountered.&lt;/p&gt;
    &lt;p&gt;StreetPass is a beautiful example of calm technology . When StreetPass finds Mastodon profiles it doesn’t draw your attention with a notification, it quietly adds the profile to a list, knowing you’ll check in when you’re ready.&lt;/p&gt;
    &lt;p&gt;StreetPass recognizes that there’s no need for an immediate call to action. Instead it allows the user to focus on their browsing, enriching their experience in the background. The user engages with StreetPass when they are ready, and on their own terms.&lt;/p&gt;
    &lt;p&gt;StreetPass is open source and available for Firefox, Chrome, and Safari.&lt;/p&gt;
    &lt;p&gt;Inspired by StreetPass, I applied this technique to RSS feed discovery.&lt;/p&gt;
    &lt;head rend="h2"&gt;Blog Quest&lt;/head&gt;
    &lt;p&gt;Blog Quest is a web browser extension that helps you discover and subscribe to blogs. Blog Quest checks each page for auto-discoverable RSS and Atom feeds (using &lt;code&gt;rel="alternate"&lt;/code&gt; links) and quietly collects them in the background.
When you’re ready to explore the collected feeds, open the extension’s drop-down window.&lt;/p&gt;
    &lt;p&gt;The extension integrates with several feed readers, making subscription management nearly effortless.&lt;/p&gt;
    &lt;p&gt;Blog Quest is available for both Firefox and Chrome. The project is open source and I encourage you to build your own variants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ubiquitous yet hidden&lt;/head&gt;
    &lt;p&gt;I reject the dead Internet theory: I see a vibrant Internet full of humans sharing their experiences and seeking connection. Degradation of the engagement-driven web is well underway, accelerated by AI slop. But the independent web works on a different incentive structure and is resistant to this effect. Humans inherently create, connect, and share: we always have and we always will. If you choose software that works in your interest you’ll find that it’s possible to make meaningful online connections without mental hazard.&lt;/p&gt;
    &lt;p&gt;Check out StreetPass and Blog Quest to discover a decentralized, independent Internet that puts you in control.&lt;/p&gt;
    &lt;p&gt;You can't drown out the noise of social media by shouting louder, you've got to whisper.&lt;/p&gt;
    &lt;head rend="h3"&gt;Image credits&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edward Armitage: The Siren (1888)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178892</guid><pubDate>Sun, 07 Dec 2025 03:26:01 +0000</pubDate></item><item><title>A Struct Sockaddr Sequel</title><link>https://lwn.net/Articles/1045453/</link><description>&lt;doc fingerprint="ae6b88979d3732d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A struct sockaddr sequel&lt;/head&gt;
    &lt;quote&gt;Ready to give LWN a try?One of the many objectives of the Linux Kernel Self-Protection Project (KSPP), which just completed ten years of work, is to ensure that all array references can be bounds-checked, even in the case of flexible array members, the size of which is not known at compile time. One of the most challenging flexible array members in the kernel is not even declared as such. Almost exactly one year ago, LWN looked at the effort to increase safety around the networking subsystem's heavily used sockaddr structure. One year later, Kees Cook is still looking for a way to bring this work to a close.&lt;p&gt;With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features. We are pleased to offer you a free trial subscription, no credit card required, so that you can see for yourself. Please, join us!&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;In short, the problem is that struct sockaddr is traditionally defined as:&lt;/p&gt;
    &lt;quote&gt;struct sockaddr { short sa_family; char sa_data[14]; };&lt;/quote&gt;
    &lt;p&gt;The sa_data field was more than large enough to hold a network address in the early 1980s when this structure was first defined for BSD Unix, but it is not large enough now. As a result, a great deal of code, in both the kernel and user space, passes around struct sockaddr pointers that, in truth, point to different structures with more space for the addresses they need to hold. In other words, sa_data is being treated as a flexible array member, even though it is not declared as one. The prevalence of struct sockaddr has thrown a spanner into the works of many attempts to better check the uses of array members in structures.&lt;/p&gt;
    &lt;p&gt;At the end of last year's episode, much of the kernel had been changed to use struct sockaddr_storage (actually implemented as struct __kernel_sockaddr_storage), which has a data array large enough to hold any known network address. An attempt was made to change the definition struct sockaddr to make its sa_data field into an explicit flexible array member, but that work ran into a minor snag. There are many places in the kernel where struct sockaddr is embedded within another structure. In most of these cases, sa_data is not treated as a flexible array member, so developers have freely embedded struct sockaddr anywhere within the containing structure, often not at the end.&lt;/p&gt;
    &lt;p&gt;If sa_data is redefined as a flexible array member, the compiler no longer knows how large the structure will actually be. That, in turn, means that the compiler does not know how to lay out a structure containing struct sockaddr, so it guesses and emits a warning. Or, in the case of a kernel build, tens of thousands of warnings. Kernel developers, as it turns out, would rather face the prospect of an array overflow than a warning flood of that magnitude, so this work came to a halt.&lt;/p&gt;
    &lt;p&gt;One possible solution would be to replace embedded struct sockaddr fields with struct sockaddr_storage, eliminating the flexible array member. But that would bloat the containing structures with memory that is not needed, so that approach is not popular either.&lt;/p&gt;
    &lt;p&gt;Instead, Cook is working on a patch series that introduces yet another struct sockaddr variant:&lt;/p&gt;
    &lt;quote&gt;struct sockaddr_unsized { __kernel_sa_family_t sa_family; /* address family, AF_xxx */ char sa_data[]; /* flexible address data */ };&lt;/quote&gt;
    &lt;p&gt;Its purpose is to be used in internal network-subsystem interfaces where the size of sa_data needs to be flexible, but where its actual size is also known. For example, the bind() method in struct proto_ops is defined as:&lt;/p&gt;
    &lt;quote&gt;int (*bind) (struct socket *sock, struct sockaddr *myaddr, int sockaddr_len);&lt;/quote&gt;
    &lt;p&gt;The type of myaddr can be changed to struct sockaddr_unsized * since sockaddr_len gives the real size of the sa_data array. Cook's patch series does many such replacements, eliminating the use of variably sized sockaddr structures in the networking subsystem. With that done, there are no more uses of struct sockaddr that read beyond the 14-byte sa_data array. As a result, struct sockaddr can be reverted to its classic, non-flexible definition, and array bounds checking can be applied to code using that structure.&lt;/p&gt;
    &lt;p&gt;That change is enough to make all of those warnings go away, so many would likely see it as a good stopping point. There is still, though, the matter of all those sockaddr_unsized structures, any of which might be the source of a catastrophic overflow at some point. So, once the dust settles from this work, we are likely to see some attention paid to implementing bounds checking for those structures. One possible approach mentioned in the patch set is to eventually add an sa_data_len field, so that the structure would contain the length of its sa_data array. That would make it easy to document the relationship between the fields with the counted_by() annotation, enabling the compiler to insert bounds checks.&lt;/p&gt;
    &lt;p&gt; While the ability to write new code in Rust holds promise for reducing the number of memory-safety bugs introduced into the kernel, the simple fact is that the kernel contains a huge amount of C code that will not be going away anytime soon. Anything that can be done to make that code safer is thus welcome. The many variations of struct sockaddr that have made the rounds may seem silly to some, but they are a part of the process of bringing a bit of safety to an API that was defined over 40 years ago. Ten years of KSPP have made the kernel safer, but the job is far from done.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Flexible array members&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Networking/struct sockaddr&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Releases/6.19&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Nov 14, 2025 18:56 UTC (Fri) by magfr (subscriber, #16052) [Link] (12 responses) Posted Nov 14, 2025 19:41 UTC (Fri) by mathstuf (subscriber, #69389) [Link] (10 responses) In Rust, I feel one would have `SockAddr::new(family: AfFamily) -&amp;gt; SockAddr` and then make `sa_family` read-only from there on out. But C doesn't allow one to have only some public structure members (without tooling like https://www.youtube.com/watch?v=bYxn_0jupaI). Posted Nov 16, 2025 0:18 UTC (Sun) by NYKevin (subscriber, #129325) [Link] (8 responses) This is an inelegant way of handling it. The more idiomatic representation would be an enum (the Rust equivalent of a tagged union), which automatically enforces that the discriminant (tag) is correct for whatever data you try to put inside of it. Then we don't need to bother with private members and checked constructors. You would have a series of separate structs for each address family, each with their own layout, and the enum would be a thin wrapper over those. That way, for example, AF_INET can have a 32-bit address plus a separate field for the port number, AF_INET6 can be largely identical but with a bigger address, AF_UNIX can have a (heap-allocated or fixed-capacity) string for the path, and so on. If one of the address families wants to enforce some invariant at construction time (e.g. "AF_UNIX path must not contain embedded null bytes"), then you put that logic at the struct level, and the enum never has to think about it. This is possible because you always construct the inner struct first, and only then go to wrap it in the enum (so enforcing the struct's invariants is simply not the enum's problem). Obviously this is not C-FFI compatible, but it's how you would write it from scratch in a hypothetical Rust-only universe. It is also not terribly difficult to convert between a scheme like the above and the C approach, so you might expect to find such a conversion layer in a serious Rust implementation of the sockets API. Posted Nov 16, 2025 22:07 UTC (Sun) by da4089 (subscriber, #1195) [Link] (3 responses) Is it possible for a loadable kernel module to extend that enum at runtime with a previously-unknown-to-the-kernel address family? Posted Nov 16, 2025 22:40 UTC (Sun) by randomguy3 (subscriber, #71063) [Link] (2 responses) Of course (as with most things in software), this could be solved, but it would cost you (in performance, ergonomics, safety and/or another axis of flexibility). Posted Nov 17, 2025 8:29 UTC (Mon) by taladar (subscriber, #68407) [Link] (1 responses) Posted Nov 17, 2025 20:23 UTC (Mon) by NYKevin (subscriber, #129325) [Link] But the type system assumes that you will tell it about all of the variants at compile time. Layout optimizations are made under this assumption, so it cannot reasonably be unwound at runtime, even with #[non_exhaustive] (which is primarily meant as a backcompat lint). If the set of possible types is unbounded at runtime, probably you need to use a dyn-compatible trait instead of an enum. Then we can define methods on addresses and dynamically dispatch to them (or statically dispatch if the type is known). But this has a number of downsides, including all the usual DST restrictions (see [2]), as well as various annoying restrictions on the method signatures.[3] In contexts where it is acceptable to generate code handling each address type separately, the trait does not need to be dyn-compatible, because you can use ordinary enerics for that (specializations will be monomorphized and compiled at the same time as the rest of the module). But that doesn't work for cases where you want a single data structure that directly or indirectly contains instances of mixed types (e.g. the file descriptor table). It should also be emphasized that Rust is a systems programming language. If you don't like dyn Trait, you are allowed to manually re-implement your own version of it with unsafe code. There is no strict aliasing rule, so you can unsafely cast between different types as long as the object representations are valid at all of those types, and there's nothing stopping you from building a safe abstraction around that operation. This is probably not a great idea in most situations, but the language doesn't rule it out, and indeed it even provides primitives to help you do it correctly (e.g. std::any::TypeId). This might be appropriate in contexts where you only need a very small subset of dyn Trait functionality and don't want to live with all of its restrictions. [1]: https://doc.rust-lang.org/reference/attributes/type_syste... Posted Nov 17, 2025 4:28 UTC (Mon) by mathstuf (subscriber, #69389) [Link] (1 responses) So, yes, I agree that an `enum` would be better in a vacuum, but we're not. I should have been clearer that it was a Rust spelling of a potential C API (because the syntax for this specific bit is nicer than C offers, IMO). Posted Nov 17, 2025 8:32 UTC (Mon) by taladar (subscriber, #68407) [Link] Posted Nov 18, 2025 8:35 UTC (Tue) by plugwash (subscriber, #29694) [Link] (1 responses) Then they are not so great, firstly the only stable ABI is "repr C" but that disables all layout optimisations. Secondly even if you use "repr C" creating an invalid value is still undefined behaviour. Posted Nov 18, 2025 8:43 UTC (Tue) by taladar (subscriber, #68407) [Link] In fact what you should almost never do is persist some sort of numeric discriminant value the way most C programs do since that just leads to headaches in the future, not the least of which is that - without context - nobody has any idea which value means what. That can work fine if your enum is something like a day of the week or a month but not so much if it is something that is less well known or might change in the future. Passing data around a trust or version boundary also doesn't get any easier if you try to encode what is basically a sum type in terms of the actual facts of the domain you are dealing with in a less natural way the way most languages without sum types do. Posted Nov 17, 2025 6:06 UTC (Mon) by wahern (subscriber, #37304) [Link] [1] Analogous ISO C proposals for the counted_by attribute allow expressions for the size, similar to VLAs/VMAs, such that one could use something like, e.g., `counted_by(.sa_len - offsetof(struct sockaddr, sa_data))`. Posted Nov 17, 2025 19:55 UTC (Mon) by kees (subscriber, #27264) [Link] &lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;lb/&gt; [2]: https://doc.rust-lang.org/reference/dynamically-sized-typ...&lt;lb/&gt; [3]: https://doc.rust-lang.org/reference/items/traits.html#dyn...&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;head&gt;sa_family&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46180291</guid><pubDate>Sun, 07 Dec 2025 09:06:39 +0000</pubDate></item><item><title>Java Hello World, LLVM Edition</title><link>https://www.javaadvent.com/2025/12/java-hello-world-llvm-edition.html</link><description>&lt;doc fingerprint="8e1bab18c82db7cc"&gt;
  &lt;main&gt;
    &lt;p&gt;After exploring Java bytecode in previous years (2022, 2023, 2024), this year we’ll take an unexpected detour for a Java advent: instead of generating Java bytecode, we’ll use Java to build and execute LLVM IR, the intermediate language behind compilers like clang.&lt;/p&gt;
    &lt;p&gt;Using Java’s Foreign Function &amp;amp; Memory (FFM) API, we’ll call the LLVM C API, generate a “Hello, World!” program, and even JIT-compile it to native code – all from Java.&lt;/p&gt;
    &lt;p&gt;The task is simple: create a program that simply prints “Hello, World!”. But we must do this from Java via LLVM.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is LLVM?&lt;/head&gt;
    &lt;p&gt;The LLVM Project, a collection of modular compiler and toolchain technologies, began as a research project over 20 years ago at the University of Illinois. It has grown significantly, underpinning many compilers and tools like clang.&lt;/p&gt;
    &lt;p&gt;The core libraries provide a source &amp;amp; target independent optimizer along with code generation for a multitude of target machines. They are built around the LLVM IR, an intermediate representation, which we’ll generate &amp;amp; execute from Java.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing LLVM&lt;/head&gt;
    &lt;p&gt;To use the LLVM C API from Java, we’ll need LLVM’s shared libraries and headers installed locally. There is an automatic installation script available to easily install LLVM on Ubuntu/Debian systems, for example to install LLVM 20:&lt;/p&gt;
    &lt;code&gt;
$ wget https://apt.llvm.org/llvm.sh
$ chmod +x llvm.sh
$ ./llvm.sh 20
&lt;/code&gt;
    &lt;p&gt;Once we have LLVM installed we can use the LLVM tooling to execute textual-form LLVM IR and we’ll also be able to use the LLVM C API in Java via the FFM API.&lt;/p&gt;
    &lt;head rend="h2"&gt;LLVM IR&lt;/head&gt;
    &lt;p&gt;LLVM IR is a strongly-typed, SSA-based intermediate language. It abstracts away most machine-specific details, making it easier to represent high-level constructs in a compiler-friendly format. There are three equivalent representations of the IR: an in-memory format, a bitcode format for serialisation and a human readable assembly language representation.&lt;/p&gt;
    &lt;p&gt;The textual form of the LLVM IR for our “Hello, World!” looks like this:&lt;/p&gt;
    &lt;code&gt;
@str = private constant [14 x i8] c"Hello, World!\00"

declare i32 @puts(ptr)

define i32 @main() {
  call i32 @puts(ptr @str)
  ret i32 0
}
&lt;/code&gt;
    &lt;p&gt;Eventually, we’ll generate this via Java but, for now, if you save this in a file called helloworld.ll you can try executing it with the LLVM interpreter, lli:&lt;/p&gt;
    &lt;code&gt;
$ lli helloworld.ll
Hello, World!
&lt;/code&gt;
    &lt;p&gt;There are a few types of entities used in the helloworld.ll example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A global variable containing the string “Hello World!”&lt;/item&gt;
      &lt;item&gt;A declaration of the external libc puts function&lt;/item&gt;
      &lt;item&gt;A definition of the main function&lt;/item&gt;
      &lt;item&gt;Instructions to call puts and return an integer exit code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can dive deeper into the LLVM “Hello, World!” example here if you like before continuing to the next section, where we’ll start using the Java FFM API.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is the Java FFM API?&lt;/head&gt;
    &lt;p&gt;The Foreign Function and Memory (FFM) API enables Java programs to interoperate with code and data outside the Java runtime. The API is a replacement for the older JNI API that enables Java programs to call native libraries in a safer way. The API can be used to call foreign functions and safely access foreign memory that is not managed by the JVM.&lt;/p&gt;
    &lt;p&gt;A companion to the FFM API is a tool named jextract that can automatically generate Java bindings from a C header file. &lt;code&gt;jextract&lt;/code&gt; parses C header files and automatically generates the Java source code with method handles and type-safe FFM bindings.&lt;/p&gt;
    &lt;p&gt;We’ll use the &lt;code&gt;jextract&lt;/code&gt; tool to generate bindings for the LLVM C API and those bindings will allow us to call the LLVM API from Java.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;First, let’s create a simple project to start. We’ll use maven to build our project but you can use another build tool if you like, it’s not important:&lt;/p&gt;
    &lt;code&gt;
$ mvn archetype:generate -DgroupId=com.example -DartifactId=jvm-llvm-helloworld -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false
&lt;/code&gt;
    &lt;p&gt;Once you have a project skeleton, update the pom.xml file to set the Java version &amp;gt;= 22:&lt;/p&gt;
    &lt;code&gt;
 &amp;lt;properties&amp;gt;
    &amp;lt;maven.compiler.source&amp;gt;25&amp;lt;/maven.compiler.source&amp;gt;
    &amp;lt;maven.compiler.target&amp;gt;25&amp;lt;/maven.compiler.target&amp;gt;
 &amp;lt;/properties&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Then build and run the program to check everything is OK:&lt;/p&gt;
    &lt;code&gt;
$ mvn clean install
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App
Hello World!
&lt;/code&gt;
    &lt;p&gt;The maven generated sample already printed “Hello, World!” but that’s too easy! We’ll remove that and generate it via LLVM in the following sections.&lt;/p&gt;
    &lt;p&gt;Let’s now create the LLVM bindings using &lt;code&gt;jextract&lt;/code&gt; so that we can use the LLVM API.&lt;/p&gt;
    &lt;head rend="h2"&gt;Creating LLVM bindings&lt;/head&gt;
    &lt;p&gt;We’ll use jextract to generate bindings from the LLVM C API header files. Make sure LLVM is available on your system (see Installing LLVM above) and you’ll also need to download jextract.&lt;/p&gt;
    &lt;p&gt;The following jextract command (on Linux) will create Java bindings for the specified LLVM C headers, placing the generated code into the &lt;code&gt;com.example.llvm&lt;/code&gt; package within the &lt;code&gt;src/main/java&lt;/code&gt; directory, with the main header class named &lt;code&gt;LLVM&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;
$ jextract -l LLVM-20 -I /usr/include/llvm-c-20 \
     -I /usr/include/llvm-20 \
     -t com.example.llvm \
     --output src/main/java \
     --header-class-name LLVM \
     /usr/include/llvm-c-20/llvm-c/Core.h \
     /usr/include/llvm-c-20/llvm-c/Support.h \
     /usr/include/llvm-c-20/llvm-c/ExecutionEngine.h \
     /usr/include/llvm-c-20/llvm-c/Target.h \
     /usr/include/llvm-c-20/llvm-c/TargetMachine.h
&lt;/code&gt;
    &lt;p&gt;To test the generated bindings, let’s print the LLVM version using the static method generated for LLVM version string constant: edit the sample’s App.java file to print the version using the following:&lt;/p&gt;
    &lt;p&gt;If you run this, you’ll see the LLVM version printed:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar --enable-native-access=ALL-UNNAMED com.example.App
LLVM version: 20.0.0
&lt;/code&gt;
    &lt;p&gt;Note the use of &lt;code&gt;--enable-native-access=ALL-UNNAMED&lt;/code&gt; to prevent warnings about native code access; I’ll omit this for brevity in later commands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory Segments&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;LLVM_VERSION_STRING&lt;/code&gt; method returns a MemorySegment rather than a Java String. In the FFM API, a &lt;code&gt;MemorySegment&lt;/code&gt; represents a contiguous region of memory—either on or off the Java heap—enabling safe, structured access to native memory.&lt;/p&gt;
    &lt;p&gt;Let’s take a look at the implementation in the generated source file:&lt;/p&gt;
    &lt;code&gt;
   public static MemorySegment LLVM_VERSION_STRING() {
    class Holder {
      static final MemorySegment LLVM_VERSION_STRING
         = LLVM.LIBRARY_ARENA.allocateFrom("20.0.0");
    }
    return Holder.LLVM_VERSION_STRING;
  }
&lt;/code&gt;
    &lt;p&gt;This method allocates memory containing the version string that contains the version number. The allocated MemorySegment is returned from the method and to get the String back into Java-land we need to call &lt;code&gt;getString(0)&lt;/code&gt; on the memory segment which reads a null-terminated string at the given offset (&lt;code&gt;0&lt;/code&gt;), using the UTF-8 charset.&lt;/p&gt;
    &lt;p&gt;Memory segments are managed through arenas (such as the &lt;code&gt;LLVM.LIBRARY_ARENA&lt;/code&gt; in the code above), which bridge Java’s managed heap and foreign memory spaces by applying familiar resource management patterns like try-with-resources.&lt;/p&gt;
    &lt;p&gt;Since we’ll need to allocate native memory, let’s declare an Arena:&lt;/p&gt;
    &lt;code&gt;
 public static void main(String[] args)
 {
    try (Arena arena = Arena.ofConfined()) {
       // TODO
    }
 }
&lt;/code&gt;
    &lt;head rend="h2"&gt;Creating an LLVM module&lt;/head&gt;
    &lt;p&gt;As a reminder, we need to recreate the following LLVM IR via the LLVM C API:&lt;/p&gt;
    &lt;code&gt;
declare i32 @puts(ptr)

@str = constant [14 x i8] c"Hello, World!\00"

define i32 @main() {
  call i32 @puts(ptr @str)
  ret i32 0
}
&lt;/code&gt;
    &lt;p&gt;Let’s start by creating an LLVM module – the container for all functions and globals – and print it so that we can run it through the LLVM interpreter:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // TODO: Fill in the module
            
  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;If we execute this now, we’ll see an empty IR module:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App
; ModuleID = 'hello'
source_filename = "hello"
&lt;/code&gt;
    &lt;p&gt;If you pass this output through the LLVM interpreter, you’ll see that it tries to execute the module but cannot find the entry point main function:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App | lli
Symbols not found: [ main ]
&lt;/code&gt;
    &lt;p&gt;We now have an LLVM module, but it has no executable code – the interpreter rightly complains that main is missing; so let’s add the main function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding a main function&lt;/head&gt;
    &lt;p&gt;The entry point to our program is the function named main which takes no parameters and returns an integer exit code, where a non-negative integer denotes success. We can add a function to the module using the LLVMAddFunction function, along with the LLVMFunctionType and LLVMInt32Type functions to create the function type.&lt;/p&gt;
    &lt;p&gt;Notice that all of these functions return a &lt;code&gt;MemorySegment&lt;/code&gt; and all 3 &lt;code&gt;LLVMAddFunction&lt;/code&gt; parameters are &lt;code&gt;MemorySegment&lt;/code&gt;s.&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

    // TODO: Add the code

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;If you execute this now you’ll see a declaration of the main function but it has no body so the LLVM interpreter will produce the same error:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App
; ModuleID = 'hello'
source_filename = "hello"

declare i32 @main()

$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App|lli
Symbols not found: [ main ]
&lt;/code&gt;
    &lt;p&gt;Next we’ll add some instructions to the body of the function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding an entry basic block&lt;/head&gt;
    &lt;p&gt;In order to add code to a function we need to add at least 1 basic block – the entry block. A basic block is a sequence of instructions within a function that executes straight through from start to finish, with no branches in the middle. These blocks form the nodes of the Control-Flow Graph (CFG), and they connect to each other based on how control flows between them.&lt;/p&gt;
    &lt;p&gt;Basic blocks can be added to a function with the LLVMAppendBasicBlock function:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 
	  // TODO: Add the instructions

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;If you run the program through &lt;code&gt;lli&lt;/code&gt; now, you’ll see a different error:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App | lli
lli: &amp;lt;stdin&amp;gt;:6:1: error: expected instruction opcode
}
&lt;/code&gt;
    &lt;p&gt;That makes sense, we don’t yet have any instructions in our function!&lt;/p&gt;
    &lt;head rend="h2"&gt;Building instructions&lt;/head&gt;
    &lt;p&gt;To add instructions, we first create an instruction builder using the LLVMCreateBuilder function. This gives us an LLVMBuilder that we can use to insert new instructions into a basic block.&lt;/p&gt;
    &lt;p&gt;We’ll also use the LLVMPositionBuilderAtEnd function to position the builder at the end of the entry block and LLVMBuildRet to build a return instruction:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

    // TODO: Call puts “Hello, World!”

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;If you run the program and pass the output through &lt;code&gt;lli&lt;/code&gt; now, you’ll see nothing happen:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App | lli
&lt;/code&gt;
    &lt;p&gt;Great news – the errors are gone! Checking the return code confirms the program exited successfully, returning 0.&lt;/p&gt;
    &lt;code&gt;
$ echo $?
0
&lt;/code&gt;
    &lt;p&gt;Try changing the 0 to some other number to confirm that the value is indeed coming from the exit code returned by the LLVM IR program!&lt;/p&gt;
    &lt;head rend="h2"&gt;Global variables&lt;/head&gt;
    &lt;p&gt;A global variable, defined at the top-level in LLVM IR, defines a region of memory with a fixed address that is allocated when the program is loaded, rather than dynamically at runtime. Globals can be declared as constant if their values will never change.&lt;/p&gt;
    &lt;p&gt;We’ll add the string “Hello, World!” to our LLVM program as a global constant.&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // TODO: Call puts “Hello, World!”

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;We don’t use the &lt;code&gt;hello_str&lt;/code&gt; yet so running &lt;code&gt;lli&lt;/code&gt; would produce the same as before, but you can see the string is now declared in the LLVM IR (prefixed with @ because it is a global, like the main function):&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App 
; ModuleID = 'hello'
source_filename = "hello"

@hello_str = private unnamed_addr constant [14 x i8] c"Hello, World!\00", align 1

define i32 @main() {
entry:
  ret i32 0
}
&lt;/code&gt;
    &lt;p&gt;Let’s add the final instruction next – a call to &lt;code&gt;puts&lt;/code&gt; to print the string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Calling functions&lt;/head&gt;
    &lt;p&gt;Before we can call the libc puts function we must declare it in the module by first building the function type and then calling &lt;code&gt;LLVMAddFunction&lt;/code&gt; to add it to the module:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // TODO: Call puts “Hello, World!”

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;Now that we’ve declared the function we can call it with the &lt;code&gt;@hello_str&lt;/code&gt; global as a parameter using the LLVMBuildCall2 function:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // Create puts function call
    var callArgs = arena.allocate(ADDRESS, 1);
    callArgs.set(ADDRESS, 0, helloStr);
    LLVMBuildCall2(builder, putsType, putsFunc, callArgs, 1, arena.allocateFrom("puts"));

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

  	var llvmIrCharPtr = LLVMPrintModuleToString(module);

    try {
      System.out.println(llvmIrCharPtr.getString(0));
    } catch (Exception e) {
      System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    }

	   // Clean up LLVM resources
     LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;Running the program’s output through &lt;code&gt;lli&lt;/code&gt; will finally display the expected result: “Hello, World!”:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App | lli
Hello, World!
&lt;/code&gt;
    &lt;p&gt;Congratulations, you’ve successfully used the Java FFM API to call the LLVM C API to build an LLVM module that contains code to print “Hello, World!”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Just-in-time (JIT) Compilation&lt;/head&gt;
    &lt;p&gt;So far, we’ve been printing LLVM IR and letting &lt;code&gt;lli&lt;/code&gt; execute it. But LLVM also exposes a JIT compiler API, allowing us to generate and execute machine code in-memory. Let’s see how to JIT our “Hello, World!” directly from Java.&lt;/p&gt;
    &lt;p&gt;LLVM IR is target independent but once we start compiling to native code we must know which machine we are targeting. We’ll target x86 Linux in the following code; if you’re using ARM, Mac or Windows you’ll need to adjust the code for your machine.&lt;/p&gt;
    &lt;p&gt;The first step is to initialise and create an LLVM JIT compiler for the target machine:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // Create puts function call
    var callArgs = arena.allocate(ADDRESS, 1);
    callArgs.set(ADDRESS, 0, helloStr);
    LLVMBuildCall2(builder, putsType, putsFunc, callArgs, 1, arena.allocateFrom("puts"));

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

    // Initialize LLVM JIT + x86 Target
    LLVMLinkInMCJIT();
    LLVMInitializeX86Target();
    LLVMInitializeX86TargetInfo();
    LLVMInitializeX86TargetMC();
    LLVMInitializeX86AsmPrinter();
    LLVMInitializeX86AsmParser();

    // Create JIT execution engine
    var jitCompiler = arena.allocate(ADDRESS);
    var jitErrorMsgPtrPtr = arena.allocate(ADDRESS);
    LLVMCreateJITCompilerForModule(jitCompiler, module, /* optimization level = */ 2, jitErrorMsgPtrPtr);

    // Disable the IR printing now
  	// var llvmIrCharPtr = LLVMPrintModuleToString(module);
    //
    // try {
    //  System.out.println(llvmIrCharPtr.getString(0));
    // } catch (Exception e) {
    //   System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    // }

	   // Clean up LLVM resources
     // LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;LLVMCreateJITCompilerForModule&lt;/code&gt; sets up a JIT execution engine to compile an LLVM module to native machine code. &lt;code&gt;LLVMCreateJITCompilerForModule&lt;/code&gt; will return a 1 upon failure and then we can check the error message string for more information but to simplify things we’ll ignore error handling for now. &lt;/p&gt;
    &lt;p&gt;Requesting the address of the main function triggers its compilation – LLVM generates the machine code only when it’s first needed, hence the name Just-In-Time compilation. We can retrieve a pointer to the compiled function using &lt;code&gt;LLVMGetPointerToGlobal&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // Create puts function call
    var callArgs = arena.allocate(ADDRESS, 1);
    callArgs.set(ADDRESS, 0, helloStr);
    LLVMBuildCall2(builder, putsType, putsFunc, callArgs, 1, arena.allocateFrom("puts"));

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

    // Initialize LLVM JIT + x86 Target
    LLVMLinkInMCJIT();
    LLVMInitializeX86Target();
    LLVMInitializeX86TargetInfo();
    LLVMInitializeX86TargetMC();
    LLVMInitializeX86AsmPrinter();
    LLVMInitializeX86AsmParser();

    // Create JIT execution engine
    var jitCompiler = arena.allocate(ADDRESS);
    var jitErrorMsgPtrPtr = arena.allocate(ADDRESS);
    LLVMCreateJITCompilerForModule(jitCompiler, module, /* optimization level = */ 2, jitErrorMsgPtrPtr);

    var executionEngine = jitCompiler.get(ADDRESS, 0);
    var addressOfMainFunc = LLVMGetPointerToGlobal(executionEngine, mainFunc);

    // Disable the IR printing now
  	// var llvmIrCharPtr = LLVMPrintModuleToString(module);
    //
    // try {
    //  System.out.println(llvmIrCharPtr.getString(0));
    // } catch (Exception e) {
    //   System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    // }

	   // Clean up LLVM resources
     // LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;Now that we’ve compiled the function, we need a way to invoke it from Java. To do this, we use the foreign linker to create a &lt;code&gt;MethodHandle&lt;/code&gt; for the JIT-compiled main function. This handle acts as a callable reference to the native code:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // Create puts function call
    var callArgs = arena.allocate(ADDRESS, 1);
    callArgs.set(ADDRESS, 0, helloStr);
    LLVMBuildCall2(builder, putsType, putsFunc, callArgs, 1, arena.allocateFrom("puts"));

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

    // Initialize LLVM JIT + x86 Target
    LLVMLinkInMCJIT();
    LLVMInitializeX86Target();
    LLVMInitializeX86TargetInfo();
    LLVMInitializeX86TargetMC();
    LLVMInitializeX86AsmPrinter();
    LLVMInitializeX86AsmParser();

    // Create JIT execution engine
    var jitCompiler = arena.allocate(ADDRESS);
    var jitErrorMsgPtrPtr = arena.allocate(ADDRESS);
    LLVMCreateJITCompilerForModule(jitCompiler, module, /* optimization level = */ 2, jitErrorMsgPtrPtr);

    var executionEngine = jitCompiler.get(ADDRESS, 0);
    var addressOfMainFunc = LLVMGetPointerToGlobal(executionEngine, mainFunc);

    // Create method handle to the int main() function that
    // we just created and compiled.
    var functionHandle = Linker.nativeLinker().downcallHandle(
        addressOfMainFunc,
        FunctionDescriptor.of(/* returnType = */ JAVA_INT)
    );

    // Disable the IR printing now
  	// var llvmIrCharPtr = LLVMPrintModuleToString(module);
    //
    // try {
    //  System.out.println(llvmIrCharPtr.getString(0));
    // } catch (Exception e) {
    //   System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    // }

	   // Clean up LLVM resources
     // LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;downcallHandle&lt;/code&gt; method tells Java how to interpret the native function’s signature – in this case, a function that takes no arguments and returns an int.&lt;/p&gt;
    &lt;p&gt;Now we can invoke the compiled native function directly from Java, just like a regular method call:&lt;/p&gt;
    &lt;code&gt;
public static void main(String[] args)
{
  try (Arena arena = Arena.ofConfined()) {
    var module = LLVMModuleCreateWithName(arena.allocateFrom("hello"));
          
    // Create main function signature: int main()
    var int32Type = LLVMInt32Type();
    var mainType = LLVMFunctionType(int32Type, NULL, 0, 0);
    var mainName = arena.allocateFrom("main");
    var mainFunc = LLVMAddFunction(module, mainName, mainType);

	  var entry = LLVMAppendBasicBlock(mainFunc, arena.allocateFrom("entry"));
 	  var builder = LLVMCreateBuilder();
    LLVMPositionBuilderAtEnd(builder, entry);

	  // Create a global string constant containing "Hello, World!"
    var helloStr = 
           LLVMBuildGlobalStringPtr(builder,
                arena.allocateFrom("Hello, World!"),
                arena.allocateFrom("hello_str"));

    // Create puts function type: int puts(char*)
    var putsParamTypes = arena.allocate(ADDRESS, 1);
    var charPtrType = LLVMPointerType(LLVMInt8Type(), 0);
    putsParamTypes.set(ADDRESS, 0, charPtrType);
    var putsType = LLVMFunctionType(int32Type, putsParamTypes, 1, 0);
    // Add puts function to the module
    var putsFunc = LLVMAddFunction(module, arena.allocateFrom("puts"), putsType);

    // Create puts function call
    var callArgs = arena.allocate(ADDRESS, 1);
    callArgs.set(ADDRESS, 0, helloStr);
    LLVMBuildCall2(builder, putsType, putsFunc, callArgs, 1, arena.allocateFrom("puts"));

	  // Return 0
    LLVMBuildRet(builder, LLVMConstInt(int32Type, 0, 0));

    // Initialize LLVM JIT + x86 Target
    LLVMLinkInMCJIT();
    LLVMInitializeX86Target();
    LLVMInitializeX86TargetInfo();
    LLVMInitializeX86TargetMC();
    LLVMInitializeX86AsmPrinter();
    LLVMInitializeX86AsmParser();

    // Create JIT execution engine
    var jitCompiler = arena.allocate(ADDRESS);
    var jitErrorMsgPtrPtr = arena.allocate(ADDRESS);
    LLVMCreateJITCompilerForModule(jitCompiler, module, /* optimization level = */ 2, jitErrorMsgPtrPtr);

    var executionEngine = jitCompiler.get(ADDRESS, 0);
    var addressOfMainFunc = LLVMGetPointerToGlobal(executionEngine, mainFunc);

    // Create method handle to the int main() function that
    // we just created and compiled.
    var functionHandle = Linker.nativeLinker().downcallHandle(
        addressOfMainFunc,
        FunctionDescriptor.of(/* returnType = */ JAVA_INT)
    );

    // Execute the main function via the method handle.
    try {
      int result = (int) functionHandle.invoke();
      System.out.println("main() returned: " + result);
    } catch (Throwable e) {
      System.err.println("Error calling JIT function: " + e.getMessage());
    }

    // Disable the IR printing now
  	// var llvmIrCharPtr = LLVMPrintModuleToString(module);
    //
    // try {
    //  System.out.println(llvmIrCharPtr.getString(0));
    // } catch (Exception e) {
    //   System.err.println("Failed to write LLVM IR: failed to get error message: " + e.getMessage());
    // }

	   // Clean up LLVM resources
     // LLVMDisposeMessage(llvmIrCharPtr);
     LLVMDisposeBuilder(builder);
     LLVMDisposeModule(module);
  }
}
&lt;/code&gt;
    &lt;p&gt;When &lt;code&gt;functionHandle.invoke()&lt;/code&gt; runs, Java crosses into the native world and calls the machine code that was just compiled by the LLVM JIT compiler.&lt;/p&gt;
    &lt;p&gt;And that’s it, you can now run the Java application without the LLVM interpreter and see the resulting “Hello, World!”:&lt;/p&gt;
    &lt;code&gt;
$ java -cp target/jvm-llvm-helloworld-1.0-SNAPSHOT.jar com.example.App 
Hello, World!
&lt;/code&gt;
    &lt;p&gt;Congratulations, you’ve now JIT-compiled Hello World, with the help of Java’s FFM API calling LLVM’s C API.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next steps&lt;/head&gt;
    &lt;p&gt;In this Java advent we built and executed native machine code from pure Java and a little help from LLVM – no JNI, no C glue, just memory segments, method handles, and a modern FFI. By the end, we had just a simple program that prints “Hello, World!” but it shows the potential of the Java FFM API and the things you can do when Java and native code work together.&lt;/p&gt;
    &lt;p&gt;Now see what else you can do, for example, try generating other instructions: print more text, do simple calculations, or even build tiny programs entirely in LLVM from Java.&lt;/p&gt;
    &lt;p&gt;The full code for this post is available on GitHub over here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46181076</guid><pubDate>Sun, 07 Dec 2025 11:51:02 +0000</pubDate></item><item><title>The Reverse-Centaur's Guide to Criticizing AI</title><link>https://pluralistic.net/2025/12/05/pop-that-bubble/</link><description>&lt;doc fingerprint="3f6191111f3605ff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Today's links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Reverse Centaur’s Guide to Criticizing AI: My speech for U Washington's Neuroscience, AI and Society lecture series.&lt;/item&gt;
      &lt;item&gt;Hey look at this: Delights to delectate.&lt;/item&gt;
      &lt;item&gt;Object permanence: Pac Man ghost algorithms; The US wrote Spain's copyright law; Illinois makes prisoners rent their cells; "Urban Transport Without the Hot Air"; "Ministry for the Future": Canada sues Google; In defense of 230; NYPD racist murder postmortem; Student debt trap; "That makes me smart."&lt;/item&gt;
      &lt;item&gt;Upcoming appearances: Where to find me.&lt;/item&gt;
      &lt;item&gt;Recent appearances: Where I've been.&lt;/item&gt;
      &lt;item&gt;Latest books: You keep readin' em, I'll keep writin' 'em.&lt;/item&gt;
      &lt;item&gt;Upcoming books: Like I said, I'll keep writin' 'em.&lt;/item&gt;
      &lt;item&gt;Colophon: All the rest.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;The Reverse Centaur’s Guide to Criticizing AI (permalink)&lt;/head&gt;
    &lt;p&gt;Last night, I gave a speech for the University of Washington's "Neuroscience, AI and Society" lecture series, through the university's Computational Neuroscience Center. It was called "The Reverse Centaur’s Guide to Criticizing AI," and it's based on the manuscript for my next book, "The Reverse Centaur’s Guide to Life After AI," which will be out from Farrar, Straus and Giroux next June:&lt;/p&gt;
    &lt;p&gt;The talk was sold out, but here's the text of my lecture. I'm very grateful to UW for the opportunity, and for a lovely visit to Seattle!&lt;/p&gt;
    &lt;p&gt;==&lt;/p&gt;
    &lt;p&gt;I'm a science fiction writer, which means that my job is to make up futuristic parables about our current techno-social arrangements to interrogate not just what a gadget does, but who it does it for, and who it does it to.&lt;/p&gt;
    &lt;p&gt;What I don't do is predict the future. No one can predict the future, which is a good thing, since if the future were predictable, that would mean that what we all do couldn't change it. It would mean that the future was arriving on fixed rails and couldn't be steered.&lt;/p&gt;
    &lt;p&gt;Jesus Christ, what a miserable proposition!&lt;/p&gt;
    &lt;p&gt;Now, not everyone understands the distinction. They think sf writers are oracles, soothsayers. Unfortunately, even some of my colleagues labor under the delusion that they can "see the future."&lt;/p&gt;
    &lt;p&gt;But for every sf writer who deludes themselves into thinking that they are writing the future, there are a hundred sf fans who believe that they are reading the future, and a depressing number of those people appear to have become AI bros. The fact that these guys can't shut up about the day that their spicy autocomplete machine will wake up and turn us all into paperclips has led many confused journalists and conference organizers to try to get me to comment on the future of AI.&lt;/p&gt;
    &lt;p&gt;That's a thing I strenuously resisted doing, because I wasted two years of my life explaining patiently and repeatedly why I thought crypto was stupid, and getting relentless bollocked by cryptocurrency cultists who at first insisted that I just didn't understand crypto. And then, when I made it clear that I did understand crypto, insisted that I must be a paid shill.&lt;/p&gt;
    &lt;p&gt;This is literally what happens when you argue with Scientologists, and life is Just. Too. Short.&lt;/p&gt;
    &lt;p&gt;So I didn't want to get lured into another one of those quagmires, because on the one hand, I just don't think AI is that important of a technology, and on the other hand, I have very nuanced and complicated views about what's wrong, and not wrong, about AI, and it takes a long time to explain that stuff.&lt;/p&gt;
    &lt;p&gt;But people wouldn't stop asking, so I did what I always do. I wrote a book.&lt;/p&gt;
    &lt;p&gt;Over the summer I wrote a book about what I think about AI, which is really about what I think about AI criticism, and more specifically, how to be a good AI critic. By which I mean: "How to be a critic whose criticism inflicts maximum damage on the parts of AI that are doing the most harm." I titled the book The Reverse Centaur's Guide to Life After AI, and Farrar, Straus and Giroux will publish it in June, 2026.&lt;/p&gt;
    &lt;p&gt;But you don't have to wait until then because I am going to break down the entire book's thesis for you tonight, over the next 40 minutes. I am going to talk fast.&lt;/p&gt;
    &lt;p&gt;#&lt;/p&gt;
    &lt;p&gt;Start with what a reverse centaur is. In automation theory, a "centaur" is a person who is assisted by a machine. You're a human head being carried around on a tireless robot body. Driving a car makes you a centaur, and so does using autocomplete.&lt;/p&gt;
    &lt;p&gt;And obviously, a reverse centaur is machine head on a human body, a person who is serving as a squishy meat appendage for an uncaring machine.&lt;/p&gt;
    &lt;p&gt;Like an Amazon delivery driver, who sits in a cabin surrounded by AI cameras, that monitor the driver's eyes and take points off if the driver looks in a proscribed direction, and monitors the driver's mouth because singing isn't allowed on the job, and rats the driver out to the boss if they don't make quota.&lt;/p&gt;
    &lt;p&gt;The driver is in that van because the van can't drive itself and can't get a parcel from the curb to your porch. The driver is a peripheral for a van, and the van drives the driver, at superhuman speed, demanding superhuman endurance. But the driver is human, so the van doesn't just use the driver. The van uses the driver up.&lt;/p&gt;
    &lt;p&gt;Obviously, it's nice to be a centaur, and it's horrible to be a reverse centaur. There are lots of AI tools that are potentially very centaur-like, but my thesis is that these tools are created and funded for the express purpose of creating reverse-centaurs, which is something none of us want to be.&lt;/p&gt;
    &lt;p&gt;But like I said, the job of an sf writer is to do more than think about what the gadget does, and drill down on who the gadget does it for and who the gadget does it to. Tech bosses want us to believe that there is only one way a technology can be used. Mark Zuckerberg wants you to think that it's technologically impossible to have a conversation with a friend without him listening in. Tim Cook wants you to think that it's technologically impossible for you to have a reliable computing experience unless he gets a veto over which software you install and without him taking 30 cents out of every dollar you spend. Sundar Pichai wants you think that it's impossible for you to find a webpage unless he gets to spy on you from asshole to appetite.&lt;/p&gt;
    &lt;p&gt;This is all a kind of vulgar Thatcherism. Margaret Thatcher's mantra was "There is no alternative." She repeated this so often they called her "TINA" Thatcher: There. Is. No. Alternative. TINA.&lt;/p&gt;
    &lt;p&gt;"There is no alternative" is a cheap rhetorical slight. It's a demand dressed up as an observation. "There is no alternative" means "STOP TRYING TO THINK OF AN ALTERNATIVE." Which, you know, fuck that.&lt;/p&gt;
    &lt;p&gt;I'm an sf writer, my job is to think of a dozen alternatives before breakfast.&lt;/p&gt;
    &lt;p&gt;So let me explain what I think is going on here with this AI bubble, and sort out the bullshit from the material reality, and explain how I think we could and should all be better AI critics.&lt;/p&gt;
    &lt;p&gt;#&lt;/p&gt;
    &lt;p&gt;Start with monopolies: tech companies are gigantic and they don't compete, they just take over whole sectors, either on their own or in cartels.&lt;/p&gt;
    &lt;p&gt;Google and Meta control the ad market. Google and Apple control the mobile market, and Google pays Apple more than $20 billion/year not to make a competing search engine, and of course, Google has a 90% Search market-share.&lt;/p&gt;
    &lt;p&gt;Now, you'd think that this was good news for the tech companies, owning their whole sector.&lt;/p&gt;
    &lt;p&gt;But it's actually a crisis. You see, when a company is growing, it is a "growth stock," and investors really like growth stocks. When you buy a share in a growth stock, you're making a bet that it will continue to grow. So growth stocks trade at a huge multiple of their earnings. This is called the "price to earnings ratio" or "P/E ratio."&lt;/p&gt;
    &lt;p&gt;But once a company stops growing, it is a "mature" stock, and it trades at a much lower P/E ratio. So for every dollar that Target – a mature company – brings in, it is worth ten dollars. It has a P/E ratio of 10, while Amazon has a P/E ratio of 36, which means that for every dollar Amazon brings in, the market values it at $36.&lt;/p&gt;
    &lt;p&gt;It's wonderful to run a company that's got a growth stock. Your shares are as good as money. If you want to buy another company, or hire a key worker, you can offer stock instead of cash. And stock is very easy for companies to get, because shares are manufactured right there on the premises, all you have to do is type some zeroes into a spreadsheet, while dollars are much harder to come by. A company can only get dollars from customers or creditors.&lt;/p&gt;
    &lt;p&gt;So when Amazon bids against Target for a key acquisition, or a key hire, Amazon can bid with shares they make by typing zeroes into a spreadsheet, and Target can only bid with dollars they get from selling stuff to us, or taking out loans, which is why Amazon generally wins those bidding wars.&lt;/p&gt;
    &lt;p&gt;That's the upside of having a growth stock. But here's the downside: eventually a company has to stop growing. Like, say you get a 90% market share in your sector, how are you gonna grow?&lt;/p&gt;
    &lt;p&gt;Once the market decides that you aren't a growth stock, once you become mature, your stock is revalued, to a P/E ratio befitting a mature stock.&lt;/p&gt;
    &lt;p&gt;If you are an exec at a dominant company with a growth stock, you have to live in constant fear that the market will decide that you're not likely to grow any further. Think of what happened to Facebook in the first quarter of 2022. They told investors that they experienced slightly slower growth in the USA than they had anticipated, and investors panicked. They staged a one-day, $240B sell off. A quarter-trillion dollars in 24 hours! At the time, it was the largest, most precipitous drop in corporate valuation in human history.&lt;/p&gt;
    &lt;p&gt;That's a monopolist's worst nightmare, because once you're presiding over a "mature" firm, the key employees you've been compensating with stock, experience a precipitous pay-drop and bolt for the exits, so you lose the people who might help you grow again, and you can only hire their replacements with dollars. With dollars, not shares.&lt;/p&gt;
    &lt;p&gt;And the same goes for acquiring companies that might help you grow, because they, too, are going to expect money, not stock. This is the paradox of the growth stock. While you are growing to domination, the market loves you, but once you achieve dominance, the market lops 75% or more off your value in a single stroke if they don't trust your pricing power.&lt;/p&gt;
    &lt;p&gt;Which is why growth stock companies are always desperately pumping up one bubble or another, spending billions to hype the pivot to video, or cryptocurrency, or NFTs, or Metaverse, or AI.&lt;/p&gt;
    &lt;p&gt;I'm not saying that tech bosses are making bets they don't plan on winning. But I am saying that winning the bet – creating a viable metaverse – is the secondary goal. The primary goal is to keep the market convinced that your company will continue to grow, and to remain convinced until the next bubble comes along.&lt;/p&gt;
    &lt;p&gt;So this is why they're hyping AI: the material basis for the hundreds of billions in AI investment.&lt;/p&gt;
    &lt;p&gt;#&lt;/p&gt;
    &lt;p&gt;Now I want to talk about how they're selling AI. The growth narrative of AI is that AI will disrupt labor markets. I use "disrupt" here in its most disreputable, tech bro sense.&lt;/p&gt;
    &lt;p&gt;The promise of AI – the promise AI companies make to investors – is that there will be AIs that can do your job, and when your boss fires you and replaces you with AI, he will keep half of your salary for himself, and give the other half to the AI company.&lt;/p&gt;
    &lt;p&gt;That's it.&lt;/p&gt;
    &lt;p&gt;That's the $13T growth story that MorganStanley is telling. It's why big investors and institutionals are giving AI companies hundreds of billions of dollars. And because they are piling in, normies are also getting sucked in, risking their retirement savings and their family's financial security.&lt;/p&gt;
    &lt;p&gt;Now, if AI could do your job, this would still be a problem. We'd have to figure out what to do with all these technologically unemployed people.&lt;/p&gt;
    &lt;p&gt;But AI can't do your job. It can help you do your job, but that doesn't mean it's going to save anyone money. Take radiology: there's some evidence that AIs can sometimes identify solid-mass tumors that some radiologists miss, and look, I've got cancer. Thankfully, it's very treatable, but I've got an interest in radiology being as reliable and accurate as possible.&lt;/p&gt;
    &lt;p&gt;If my Kaiser hospital bought some AI radiology tools and told its radiologists: "Hey folks, here's the deal. Today, you're processing about 100 x-rays per day. From now on, we're going to get an instantaneous second opinion from the AI, and if the AI thinks you've missed a tumor, we want you to go back and have another look, even if that means you're only processing 98 x-rays per day. That's fine, we just care about finding all those tumors."&lt;/p&gt;
    &lt;p&gt;If that's what they said, I'd be delighted. But no one is investing hundreds of billions in AI companies because they think AI will make radiology more expensive, not even if that also makes radiology more accurate. The market's bet on AI is that an AI salesman will visit the CEO of Kaiser and make this pitch: "Look, you fire 9/10s of your radiologists, saving $20m/year, you give us $10m/year, and you net $10m/year, and the remaining radiologists' job will be to oversee the diagnoses the AI makes at superhuman speed, and somehow remain vigilant as they do so, despite the fact that the AI is usually right, except when it's catastrophically wrong.&lt;/p&gt;
    &lt;p&gt;"And if the AI misses a tumor, this will be the human radiologist's fault, because they are the 'human in the loop.' It's their signature on the diagnosis."&lt;/p&gt;
    &lt;p&gt;This is a reverse centaur, and it's a specific kind of reverse-centaur: it's what Dan Davies calls an "accountability sink." The radiologist's job isn't really to oversee the AI's work, it's to take the blame for the AI's mistakes.&lt;/p&gt;
    &lt;p&gt;This is another key to understanding – and thus deflating – the AI bubble. The AI can't do your job, but an AI salesman can convince your boss to fire you and replace you with an AI that can't do your job. This is key because it helps us build the kinds of coalitions that will be successful in the fight against the AI bubble.&lt;/p&gt;
    &lt;p&gt;If you're someone who's worried about cancer, and you're being told that the price of making radiology too cheap to meter, is that we're going to have to re-home America's 32,000 radiologists, with the trade-off that no one will ever be denied radiology services again, you might say, "Well, OK, I'm sorry for those radiologists, and I fully support getting them job training or UBI or whatever. But the point of radiology is to fight cancer, not to pay radiologists, so I know what side I'm on."&lt;/p&gt;
    &lt;p&gt;AI hucksters and their customers in the C-suites want the public on their side. They want to forge a class alliance between AI deployers and the people who enjoy the fruits of the reverse centaurs' labor. They want us to think of ourselves as enemies to the workers.&lt;/p&gt;
    &lt;p&gt;Now, some people will be on the workers' side because of politics or aesthetics. They just like workers better than their bosses. But if you want to win over all the people who benefit from your labor, you need to understand and stress how the products of the AI will be substandard. That they are going to get charged more for worse things. That they have a shared material interest with you.&lt;/p&gt;
    &lt;p&gt;Will those products be substandard? There's every reason to think so. Earlier, I alluded to "automation blindness, "the physical impossibility of remaining vigilant for things that rarely occur. This is why TSA agents are incredibly good at spotting water bottles. Because they get a ton of practice at this, all day, every day. And why they fail to spot the guns and bombs that government red teams smuggle through checkpoints to see how well they work, because they just don't have any practice at that. Because, to a first approximation, no one deliberately brings a gun or a bomb through a TSA checkpoint.&lt;/p&gt;
    &lt;p&gt;Automation blindness is the Achilles' heel of "humans in the loop."&lt;/p&gt;
    &lt;p&gt;Think of AI software generation: there are plenty of coders who love using AI, and almost without exception, they are senior, experienced coders, who get to decide how they will use these tools. For example, you might ask the AI to generate a set of CSS files to faithfully render a web-page across multiple versions of multiple browsers. This is a notoriously fiddly thing to do, and it's pretty easy to verify if the code works – just eyeball it in a bunch of browsers. Or maybe the coder has a single data file they need to import and they don't want to write a whole utility to convert it.&lt;/p&gt;
    &lt;p&gt;Tasks like these can genuinely make coders more efficient and give them more time to do the fun part of coding, namely, solving really gnarly, abstract puzzles. But when you listen to business leaders talk about their AI plans for coders, it's clear they're not looking to make some centaurs.&lt;/p&gt;
    &lt;p&gt;They want to fire a lot of tech workers – 500,000 over the past three years – and make the rest pick up their work with coding, which is only possible if you let the AI do all the gnarly, creative problem solving, and then you do the most boring, soul-crushing part of the job: reviewing the AIs' code.&lt;/p&gt;
    &lt;p&gt;And because AI is just a word guessing program, because all it does is calculate the most probable word to go next, the errors it makes are especially subtle and hard to spot, because these bugs are literally statistically indistinguishable from working code (except that they're bugs).&lt;/p&gt;
    &lt;p&gt;Here's an example: code libraries are standard utilities that programmers can incorporate into their apps, so they don't have to do a bunch of repetitive programming. Like, if you want to process some text, you'll use a standard library. If it's an HTML file, that library might be called something like lib.html.text.parsing; and if it's a DOCX file, it'll be lib.docx.text.parsing. But reality is messy, humans are inattentive and stuff goes wrong, so sometimes, there's another library, this one for parsing PDFs, and instead of being called lib.pdf.text.parsing, it's called lib.text.pdf.parsing.&lt;/p&gt;
    &lt;p&gt;Now, because the AI is a statistical inference engine, because all it can do is predict what word will come next based on all the words that have been typed in the past, it will "hallucinate" a library called lib.pdf.text.parsing. And the thing is, malicious hackers know that the AI will make this error, so they will go out and create a library with the predictable, hallucinated name, and that library will get automatically sucked into your program, and it will do things like steal user data or try and penetrate other computers on the same network.&lt;/p&gt;
    &lt;p&gt;And you, the human in the loop – the reverse centaur – you have to spot this subtle, hard to find error, this bug that is literally statistically indistinguishable from correct code. Now, maybe a senior coder could catch this, because they've been around the block a few times, and they know about this tripwire.&lt;/p&gt;
    &lt;p&gt;But guess who tech bosses want to preferentially fire and replace with AI? Senior coders. Those mouthy, entitled, extremely highly paid workers, who don't think of themselves as workers. Who see themselves as founders in waiting, peers of the company's top management. The kind of coder who'd lead a walkout over the company building drone-targeting systems for the Pentagon, which cost Google ten billion dollars in 2018.&lt;/p&gt;
    &lt;p&gt;For AI to be valuable, it has to replace high-wage workers, and those are precisely the experienced workers, with process knowledge, and hard-won intuition, who might spot some of those statistically camouflaged AI errors.&lt;/p&gt;
    &lt;p&gt;Like I said, the point here is to replace high-waged workers.&lt;/p&gt;
    &lt;p&gt;And one of the reasons the AI companies are so anxious to fire coders is that coders are the princes of labor. They're the most consistently privileged, sought-after, and well-compensated workers in the labor force.&lt;/p&gt;
    &lt;p&gt;If you can replace coders with AI, who cant you replace with AI? Firing coders is an ad for AI.&lt;/p&gt;
    &lt;p&gt;Which brings me to AI art. AI art – or "art" – is also an ad for AI, but it's not part of AI's business model.&lt;/p&gt;
    &lt;p&gt;Let me explain: on average, illustrators don't make any money. They are already one of the most immiserated, precartized groups of workers out there. They suffer from a pathology called "vocational awe." That's a term coined by the librarian Fobazi Ettarh, and it refers to workers who are vulnerable to workplace exploitation because they actually care about their jobs – nurses, librarians, teachers, and artists.&lt;/p&gt;
    &lt;p&gt;If AI image generators put every illustrator working today out of a job, the resulting wage-bill savings would be undetectable as a proportion of all the costs associated with training and operating image-generators. The total wage bill for commercial illustrators is less than the kombucha bill for the company cafeteria at just one of Open AI's campuses.&lt;/p&gt;
    &lt;p&gt;The purpose of AI art – and the story of AI art as a death-knell for artists – is to convince the broad public that AI is amazing and will do amazing things. It's to create buzz. Which is not to say that it's not disgusting that former OpenAI CTO Mira Murati told a conference audience that "some creative jobs shouldn't have been there in the first place," and that it's not especially disgusting that she and her colleagues boast about using the work of artists to ruin those artists' livelihoods.&lt;/p&gt;
    &lt;p&gt;It's supposed to be disgusting. It's supposed to get artists to run around and say, "The AI can do my job, and it's going to steal my job, and isn't that terrible?"&lt;/p&gt;
    &lt;p&gt;Because the customers for AI – corporate bosses – don't see AI taking workers' jobs as terrible. They see it as wonderful.&lt;/p&gt;
    &lt;p&gt;But can AI do an illustrator's job? Or any artist's job?&lt;/p&gt;
    &lt;p&gt;Let's think about that for a second. I've been a working artist since I was 17 years old, when I sold my first short story, and I've given it a lot of thought, and here's what I think art is: it starts with an artist, who has some vast, complex, numinous, irreducible feeling in their mind. And the artist infuses that feeling into some artistic medium. They make a song, or a poem, or a painting, or a drawing, or a dance, or a book, or a photograph. And the idea is, when you experience this work, a facsimile of the big, numinous, irreducible feeling will materialize in your mind.&lt;/p&gt;
    &lt;p&gt;Now that I've defined art, we have to go on a little detour.&lt;/p&gt;
    &lt;p&gt;I have a friend who's a law professor, and before the rise of chatbots, law students knew better than to ask for reference letters from their profs, unless they were a really good student. Because those letters were a pain in the ass to write. So if you advertised for a postdoc and you heard from a candidate with a reference letter from a respected prof, the mere existence of that letter told you that the prof really thought highly of that student.&lt;/p&gt;
    &lt;p&gt;But then we got chatbots, and everyone knows that you generate a reference letter by feeding three bullet points to an LLM, and it'll barf up five paragraphs of florid nonsense about the student.&lt;/p&gt;
    &lt;p&gt;So when my friend advertises for a postdoc, they are flooded with reference letters, and they deal with this flood by feeding all these letters to another chatbot, and ask it to reduce them back to three bullet points. Now, obviously, they won't be the same bullet-points, which makes this whole thing terrible.&lt;/p&gt;
    &lt;p&gt;But just as obviously, nothing in that five-paragraph letter except the original three bullet points are relevant to the student. The chatbot doesn't know the student. It doesn't know anything about them. It cannot add a single true or useful statement about the student to the letter.&lt;/p&gt;
    &lt;p&gt;What does this have to do with AI art? Art is a transfer of a big, numinous, irreducible feeling from an artist to someone else. But the image-gen program doesn't know anything about your big, numinous, irreducible feeling. The only thing it knows is whatever you put into your prompt, and those few sentences are diluted across a million pixels or a hundred thousand words, so that the average communicative density of the resulting work is indistinguishable from zero.&lt;/p&gt;
    &lt;p&gt;It's possible to infuse more communicative intent into a work: writing more detailed prompts, or doing the selective work of choosing from among many variants, or directly tinkering with the AI image after the fact, with a paintbrush or Photoshop or The Gimp. And if there will ever be a piece of AI art that is good art – as opposed to merely striking, or interesting, or an example of good draftsmanship – it will be thanks to those additional infusions of creative intent by a human.&lt;/p&gt;
    &lt;p&gt;And in the meantime, it's bad art. It's bad art in the sense of being "eerie," the word Mark Fisher uses to describe "when there is something present where there should be nothing, or there is nothing present when there should be something."&lt;/p&gt;
    &lt;p&gt;AI art is eerie because it seems like there is an intender and an intention behind every word and every pixel, because we have a lifetime of experience that tells us that paintings have painters, and writing has writers. But it's missing something. It has nothing to say, or whatever it has to say is so diluted that it's undetectable.&lt;/p&gt;
    &lt;p&gt;The images were striking before we figured out the trick, but now they're just like the images we imagine in clouds or piles of leaves. We're the ones drawing a frame around part of the scene, we're the ones focusing on some contours and ignoring the others. We're looking at an inkblot, and it's not telling us anything.&lt;/p&gt;
    &lt;p&gt;Sometimes that can be visually arresting, and to the extent that it amuses people in a community of prompters and viewers, that's harmless.&lt;/p&gt;
    &lt;p&gt;I know someone who plays a weekly Dungeons and Dragons game over Zoom. It's transcribed by an open source model running locally on the dungeon master's computer, which summarizes the night's session and prompts an image generator to create illustrations of key moments. These summaries and images are hilarious because they're full of errors. It's a bit of harmless fun, and it bring a small amount of additional pleasure to a small group of people. No one is going to fire an illustrator because D&amp;amp;D players are image-genning funny illustrations where seven-fingered paladins wrestle with orcs that have an extra hand.&lt;/p&gt;
    &lt;p&gt;But bosses have and will fire illustrators, because they fantasize about being able to dispense with creative professionals and just prompt an AI. Because even though the AI can't do the illustrator's job, an AI salesman can convince the illustrator's boss to fire them and replace them with an AI that can't do their job.&lt;/p&gt;
    &lt;p&gt;This is a disgusting and terrible juncture, and we should not simply shrug our shoulders and accept Thatcherism's fatalism: "There is no alternative."&lt;/p&gt;
    &lt;p&gt;So what is the alternative? A lot of artists and their allies think they have an answer: they say we should extend copyright to cover the activities associated with training a model.&lt;/p&gt;
    &lt;p&gt;And I'm here to tell you they are wrong: wrong because this would inflict terrible collateral damage on socially beneficial activities, and it would represent a massive expansion of copyright over activities that are currently permitted – for good reason!.&lt;/p&gt;
    &lt;p&gt;Let's break down the steps in AI training.&lt;/p&gt;
    &lt;p&gt;First, you scrape a bunch of web-pages. This is unambiguously legal under present copyright law. You do not need a license to make a transient copy of a copyrighted work in order to analyze it, otherwise search engines would be illegal. Ban scraping and Google will be the last search engine we ever get, the Internet Archive will go out of business, that guy in Austria who scraped all the grocery store sites and proved that the big chains were colluding to rig prices would be in deep trouble.&lt;/p&gt;
    &lt;p&gt;Next, you perform analysis on those works. Basically, you count stuff on them: count pixels and their colors and proximity to other pixels; or count words. This is obviously not something you need a license for. It's just not illegal to count the elements of a copyrighted work. And we really don't want it to be, not if you're interested in scholarship of any kind.&lt;/p&gt;
    &lt;p&gt;And it's important to note that counting things is legal, even if you're working from an illegally obtained copy. Like, if you go to the flea market, and you buy a bootleg music CD, and you take it home and you make a list of all the adverbs in the lyrics, and you publish that list, you are not infringing copyright by doing so.&lt;/p&gt;
    &lt;p&gt;Perhaps you've infringed copyright by getting the pirated CD, but not by counting the lyrics.&lt;/p&gt;
    &lt;p&gt;This is why Anthropic offered a $1.5b settlement for training its models based on a ton of books it downloaded from a pirate site: not because counting the words in the books infringes anyone's rights, but because they were worried that they were going to get hit with $150k/book statutory damages for downloading the files.&lt;/p&gt;
    &lt;p&gt;OK, after you count all the pixels or the words, it's time for the final step: publishing them. Because that's what a model is: a literary work (that is, a piece of software) that embodies a bunch of facts about a bunch of other works, word and pixel distribution information, encoded in a multidimensional array.&lt;/p&gt;
    &lt;p&gt;And again, copyright absolutely does not prohibit you from publishing facts about copyrighted works. And again, no one should want to live in a world where someone else gets to decide which truthful, factual statements you can publish.&lt;/p&gt;
    &lt;p&gt;But hey, maybe you think this is all sophistry. Maybe you think I'm full of shit. That's fine. It wouldn't be the first time someone thought that.&lt;/p&gt;
    &lt;p&gt;After all, even if I'm right about how copyright works now, there's no reason we couldn't change copyright to ban training activities, and maybe there's even a clever way to wordsmith the law so that it only catches bad things we don't like, and not all the good stuff that comes from scraping, analyzing and publishing.&lt;/p&gt;
    &lt;p&gt;Well, even then, you're not gonna help out creators by creating this new copyright. If you're thinking that you can, you need to grapple with this fact: we have monotonically expanded copyright since 1976, so that today, copyright covers more kinds of works, grants exclusive rights over more uses, and lasts longer.&lt;/p&gt;
    &lt;p&gt;And today, the media industry is larger and more profitable than it has ever been, and also: the share of media industry income that goes to creative workers is lower than its ever been, both in real terms, and as a proportion of those incredible gains made by creators' bosses at the media company.&lt;/p&gt;
    &lt;p&gt;So how it is that we have given all these new rights to creators, and those new rights have generated untold billions, and left creators poorer? It's because in a creative market dominated by five publishers, four studios, three labels, two mobile app stores, and a single company that controls all the ebooks and audiobooks, giving a creative worker extra rights to bargain with is like giving your bullied kid more lunch money.&lt;/p&gt;
    &lt;p&gt;It doesn't matter how much lunch money you give the kid, the bullies will take it all. Give that kid enough money and the bullies will hire an agency to run a global campaign proclaiming "think of the hungry kids! Give them more lunch money!"&lt;/p&gt;
    &lt;p&gt;Creative workers who cheer on lawsuits by the big studios and labels need to remember the first rule of class warfare: things that are good for your boss are rarely what's good for you.&lt;/p&gt;
    &lt;p&gt;The day Disney and Universal filed suit against Midjourney, I got a press release from the RIAA, which represents Disney and Universal through their recording arms. Universal is the largest label in the world. Together with Sony and Warner, they control 70% of all music recordings in copyright today.&lt;/p&gt;
    &lt;p&gt;It starts: "There is a clear path forward through partnerships that both further AI innovation and foster human artistry."&lt;/p&gt;
    &lt;p&gt;It ends: "This action by Disney and Universal represents a critical stand for human creativity and responsible innovation."&lt;/p&gt;
    &lt;p&gt;And it's signed by Mitch Glazier, CEO of the RIAA.&lt;/p&gt;
    &lt;p&gt;It's very likely that name doesn't mean anything to you. But let me tell you who Mitch Glazier is. Today, Mitch Glazier is the CEO if the RIAA, with an annual salary of $1.3m. But until 1999, Mitch Glazier was a key Congressional staffer, and in 1999, Glazier snuck an amendment into an unrelated bill, the Satellite Home Viewer Improvement Act, that killed musicians' right to take their recordings back from their labels.&lt;/p&gt;
    &lt;p&gt;This is a practice that had been especially important to "heritage acts" (which is a record industry euphemism for "old music recorded by Black people"), for whom this right represented the difference between making rent and ending up on the street.&lt;/p&gt;
    &lt;p&gt;When it became clear that Glazier had pulled this musician-impoverishing scam, there was so much public outcry, that Congress actually came back for a special session, just to vote again to cancel Glazier's amendment. And then Glazier was kicked out of his cushy Congressional job, whereupon the RIAA started paying more than $1m/year to "represent the music industry."&lt;/p&gt;
    &lt;p&gt;This is the guy who signed that press release in my inbox. And his message was: The problem isn't that Midjourney wants to train a Gen AI model on copyrighted works, and then use that model to put artists on the breadline. The problem is that Midjourney didn't pay RIAA members Universal and Disney for permission to train a model. Because if only Midjourney had given Disney and Universal several million dollars for training rights to their catalogs, the companies would have happily allowed them to train to their heart's content, and they would have bought the resulting models, and fired as many creative professionals as they could.&lt;/p&gt;
    &lt;p&gt;I mean, have we already forgotten the Hollywood strikes? I sure haven't. I live in Burbank, home to Disney, Universal and Warner, and I was out on the line with my comrades from the Writers Guild, offering solidarity on behalf of my union, IATSE 830, The Animation Guild, where I'm a member of the writers' unit.&lt;/p&gt;
    &lt;p&gt;And I'll never forget when one writer turned to me and said, "You know, you prompt an LLM exactly the same way an exec gives shitty notes to a writers' room. You know: 'Make me ET, except it's about a dog, and put a love interest in there, and a car chase in the second act.' The difference is, you say that to a writers' room and they all make fun of you and call you a fucking idiot suit. But you say it to an LLM and it will cheerfully shit out a terrible script that conforms exactly to that spec (you know, Air Bud)."&lt;/p&gt;
    &lt;p&gt;These companies are desperate to use AI to displace workers. When Getty Images sues AI companies, it's not representing the interests of photographers. Getty hates paying photographers! Getty just wants to get paid for the training run, and they want the resulting AI model to have guardrails, so it will refuse to create images that compete with Getty's images for anyone except Getty. But Getty will absolutely use its models to bankrupt as many photographers as it possibly can.&lt;/p&gt;
    &lt;p&gt;A new copyright to train models won't get us a world where models aren't used to destroy artists, it'll just get us a world where the standard contracts of the handful of companies that control all creative labor markets are updated to require us to hand over those new training rights to those companies. Demanding a new copyright just makes you a useful idiot for your boss, a human shield they can brandish in policy fights, a tissue-thin pretense of "won't someone think of the hungry artists?"&lt;/p&gt;
    &lt;p&gt;When really what they're demanding is a world where 30% of the investment capital of the AI companies go into their shareholders' pockets. When an artist is being devoured by rapacious monopolies, does it matter how they divvy up the meal?&lt;/p&gt;
    &lt;p&gt;We need to protect artists from AI predation, not just create a new way for artists to be mad about their impoverishment.&lt;/p&gt;
    &lt;p&gt;And incredibly enough, there's a really simple way to do that. After 20+ years of being consistently wrong and terrible for artists' rights, the US Copyright Office has finally done something gloriously, wonderfully right. All through this AI bubble, the Copyright Office has maintained – correctly – that AI-generated works cannot be copyrighted, because copyright is exclusively for humans. That's why the "monkey selfie" is in the public domain. Copyright is only awarded to works of human creative expression that are fixed in a tangible medium.&lt;/p&gt;
    &lt;p&gt;And not only has the Copyright Office taken this position, they've defended it vigorously in court, repeatedly winning judgments to uphold this principle.&lt;/p&gt;
    &lt;p&gt;The fact that every AI created work is in the public domain means that if Getty or Disney or Universal or Hearst newspapers use AI to generate works – then anyone else can take those works, copy them, sell them, or give them away for free. And the only thing those companies hate more than paying creative workers, is having other people take their stuff without permission.&lt;/p&gt;
    &lt;p&gt;The US Copyright Office's position means that the only way these companies can get a copyright is to pay humans to do creative work. This is a recipe for centaurhood. If you're a visual artist or writer who uses prompts to come up with ideas or variations, that's no problem, because the ultimate work comes from you. And if you're a video editor who uses deepfakes to change the eyelines of 200 extras in a crowd-scene, then sure, those eyeballs are in the public domain, but the movie stays copyrighted.&lt;/p&gt;
    &lt;p&gt;But creative workers don't have to rely on the US government to rescue us from AI predators. We can do it ourselves, the way the writers did in their historic writers' strike. The writers brought the studios to their knees. They did it because they are organized and solidaristic, but also are allowed to do something that virtually no other workers are allowed to do: they can engage in "sectoral bargaining," whereby all the workers in a sector can negotiate a contract with every employer in the sector.&lt;/p&gt;
    &lt;p&gt;That's been illegal for most workers since the late 1940s, when the Taft-Hartley Act outlawed it. If we are gonna campaign to get a new law passed in hopes of making more money and having more control over our labor, we should campaign to restore sectoral bargaining, not to expand copyright.&lt;/p&gt;
    &lt;p&gt;Our allies in a campaign to expand copyright are our bosses, who have never had our best interests at heart. While our allies in the fight for sector bargaining are every worker in the country. As the song goes, "Which side are you on?"&lt;/p&gt;
    &lt;p&gt;OK, I need to bring this talk in for a landing now, because I'm out of time, so I'm going to close out with this: AI is a bubble and bubbles are terrible.&lt;/p&gt;
    &lt;p&gt;Bubbles transfer the life's savings of normal people who are just trying to have a dignified retirement to the wealthiest and most unethical people in our society, and every bubble eventually bursts, taking their savings with it.&lt;/p&gt;
    &lt;p&gt;But not every bubble is created equal. Some bubbles leave behind something productive. Worldcom stole billions from everyday people by defrauding them about orders for fiber optic cables. The CEO went to prison and died there. But the fiber outlived him. It's still in the ground. At my home, I've got 2gb symmetrical fiber, because AT&amp;amp;T lit up some of that old Worldcom dark fiber.&lt;/p&gt;
    &lt;p&gt;All things being equal, it would have been better if Worldcom hadn't ever existed, but the only thing worse than Worldcom committing all that ghastly fraud would be if there was nothing to salvage from the wreckage.&lt;/p&gt;
    &lt;p&gt;I don't think we'll salvage much from cryptocurrency, for example. Sure, there'll be a few coders who've learned something about secure programming in Rust. But when crypto dies, what it will leave behind is bad Austrian economics and worse monkey JPEGs.&lt;/p&gt;
    &lt;p&gt;AI is a bubble and it will burst. Most of the companies will fail. Most of the data-centers will be shuttered or sold for parts. So what will be left behind?&lt;/p&gt;
    &lt;p&gt;We'll have a bunch of coders who are really good at applied statistics. We'll have a lot of cheap GPUs, which'll be good news for, say, effects artists and climate scientists, who'll be able to buy that critical hardware at pennies on the dollar. And we'll have the open source models that run on commodity hardware, AI tools that can do a lot of useful stuff, like transcribing audio and video, describing images, summarizing documents, automating a lot of labor-intensive graphic editing, like removing backgrounds, or airbrushing passersby out of photos. These will run on our laptops and phones, and open source hackers will find ways to push them to do things their makers never dreamt of.&lt;/p&gt;
    &lt;p&gt;If there had never been an AI bubble, if all this stuff arose merely because computer scientists and product managers noodled around for a few years coming up with cool new apps for back-propagation, machine learning and generative adversarial networks, most people would have been pleasantly surprised with these interesting new things their computers could do. We'd call them "plugins."&lt;/p&gt;
    &lt;p&gt;It's the bubble that sucks, not these applications. The bubble doesn't want cheap useful things. It wants expensive, "disruptive" things: Big foundation models that lose billions of dollars every year.&lt;/p&gt;
    &lt;p&gt;When the AI investment mania halts, most of those models are going to disappear, because it just won't be economical to keep the data-centers running. As Stein's Law has it: "Anything that can't go on forever eventually stops."&lt;/p&gt;
    &lt;p&gt;The collapse of the AI bubble is going to be ugly. Seven AI companies currently account for more than a third of the stock market, and they endlessly pass around the same $100b IOU.&lt;/p&gt;
    &lt;p&gt;Bosses are mass-firing productive workers and replacing them with janky AI, and when the janky AI is gone, no one will be able to find and re-hire most of those workers, we're going to go from disfunctional AI systems to nothing.&lt;/p&gt;
    &lt;p&gt;AI is the asbestos in the walls of our technological society, stuffed there with wild abandon by a finance sector and tech monopolists run amok. We will be excavating it for a generation or more.&lt;/p&gt;
    &lt;p&gt;So we need to get rid of this bubble. Pop it, as quickly as we can. To do that, we have to focus on the material factors driving the bubble. The bubble isn't being driven by deepfake porn, or election disinformation, or AI image-gen, or slop advertising.&lt;/p&gt;
    &lt;p&gt;All that stuff is terrible and harmful, but it's not driving investment. The total dollar figure represented by these apps doesn't come close to making a dent in the capital expenditures and operating costs of AI. They are peripheral, residual uses: flashy, but unimportant to the bubble.&lt;/p&gt;
    &lt;p&gt;Get rid of all those uses and you reduce the expected income of AI companies by a sum so small it rounds to zero.&lt;/p&gt;
    &lt;p&gt;Same goes for all that "AI Safety" nonsense, that purports to concern itself with preventing an AI from attaining sentience and turning us all into paperclips. First of all, this is facially absurd. Throwing more words and GPUs into the word-guessing program won't make it sentient. That's like saying, "Well, we keep breeding these horses to run faster and faster, so it's only a matter of time until one of our mares gives birth to a locomotive." A human mind is not a word-guessing program with a lot of extra words.&lt;/p&gt;
    &lt;p&gt;I'm here for science fiction thought experiments, don't get me wrong. But also, don't mistake sf for prophesy. SF stories about superintelligence are futuristic parables, not business plans, roadmaps, or predictions.&lt;/p&gt;
    &lt;p&gt;The AI Safety people say they are worried that AI is going to end the world, but AI bosses love these weirdos. Because on the one hand, if AI is powerful enough to destroy the world, think of how much money it can make! And on the other hand, no AI business plan has a line on its revenue projections spreadsheet labeled "Income from turning the human race into paperclips." So even if we ban AI companies from doing this, we won't cost them a dime in investment capital.&lt;/p&gt;
    &lt;p&gt;To pop the bubble, we have to hammer on the forces that created the bubble: the myth that AI can do your job, especially if you get high wages that your boss can claw back; the understanding that growth companies need a succession of ever-more-outlandish bubbles to stay alive; the fact that workers and the public they serve are on one side of this fight, and bosses and their investors are on the other side.&lt;/p&gt;
    &lt;p&gt;Because the AI bubble really is very bad news, it's worth fighting seriously, and a serious fight against AI strikes at its roots: the material factors fueling the hundreds of billions in wasted capital that are being spent to put us all on the breadline and fill all our walls with high-tech asbestos.&lt;/p&gt;
    &lt;p&gt;(Image: Cryteria, CC BY 3.0, modified)&lt;/p&gt;
    &lt;head rend="h1"&gt;Hey look at this (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Politics and Capitalist Stagnation https://www.unpopularfront.news/p/politics-and-capitalist-stagnation&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;An Analysis of the Proposed Spirit Financial-Credit Union 1 Merger. The Consequences for the Credit Union System https://chipfilson.com/2025/12/an-analysis-of-the-proposed-spirit-financal-credit-union-1-merger/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zillow deletes climate risk data from listings after complaints it harms sales https://www.theguardian.com/environment/2025/dec/01/zillow-removes-climate-risk-data-home-listings&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;After Years of Controversy, the EU’s Chat Control Nears Its Final Hurdle: What to Know https://www.eff.org/deeplinks/2025/12/after-years-controversy-eus-chat-control-nears-its-final-hurdle-what-know&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How the dollar-store industry overcharges cash-strapped customers while promising low prices https://www.theguardian.com/us-news/2025/dec/03/customers-pay-more-rising-dollar-store-costs&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Object permanence (permalink)&lt;/head&gt;
    &lt;p&gt;#20yrsago Haunted Mansion papercraft model adds crypts and gates https://www.haunteddimensions.raykeim.com/index313.html&lt;/p&gt;
    &lt;p&gt;#20yrsago Print your own Monopoly money https://web.archive.org/web/20051202030047/http://www.hasbro.com/monopoly/pl/page.treasurechest/dn/default.cfm&lt;/p&gt;
    &lt;p&gt;#15yrsago Bunnie explains the technical intricacies and legalities of Xbox hacking https://www.bunniestudios.com/blog/2010/usa-v-crippen-a-retrospective/&lt;/p&gt;
    &lt;p&gt;#15yrsago How Pac Man’s ghosts decide what to do: elegant complexity https://web.archive.org/web/20101205044323/https://gameinternals.com/post/2072558330/understanding-pac-man-ghost-behavior&lt;/p&gt;
    &lt;p&gt;#15yrsago Glorious, elaborate, profane insults of the world https://www.reddit.com/r/AskReddit/comments/efee7/what_are_your_favorite_culturally_untranslateable/?sort=confidence&lt;/p&gt;
    &lt;p&gt;#15yrsago Walt Disney World castmembers speak about their search for a living wage https://www.youtube.com/watch?v=f5BMQ3xQc7o&lt;/p&gt;
    &lt;p&gt;#15yrsago Wikileaks cables reveal that the US wrote Spain’s proposed copyright law https://web.archive.org/web/20140723230745/https://elpais.com/elpais/2010/12/03/actualidad/1291367868_850215.html&lt;/p&gt;
    &lt;p&gt;#15yrsago Cities made of broken technology https://web.archive.org/web/20101203132915/https://agora-gallery.com/artistpage/Franco_Recchia.aspx&lt;/p&gt;
    &lt;p&gt;#10yrsago The TPP’s ban on source-code disclosure requirements: bad news for information security https://www.eff.org/deeplinks/2015/12/tpp-threatens-security-and-safety-locking-down-us-policy-source-code-audit&lt;/p&gt;
    &lt;p&gt;#10yrsago Fossil fuel divestment sit-in at MIT President’s office hits 10,000,000,000-hour mark https://twitter.com/FossilFreeMIT/status/672526210581274624&lt;/p&gt;
    &lt;p&gt;#10yrsago Hacker dumps United Arab Emirates Invest Bank’s customer data https://www.dailydot.com/news/invest-bank-hacker-buba/&lt;/p&gt;
    &lt;p&gt;#10yrsago Illinois prisons spy on prisoners, sue them for rent on their cells if they have any money https://www.chicagotribune.com/2015/11/30/state-sues-prisoners-to-pay-for-their-room-board/&lt;/p&gt;
    &lt;p&gt;#10yrsago Free usability help for privacy toolmakers https://superbloom.design/learning/blog/apply-for-help/&lt;/p&gt;
    &lt;p&gt;#10yrsago In the first 334 days of 2015, America has seen 351 mass shootings (and counting) https://web.archive.org/web/20151209004329/https://www.washingtonpost.com/news/wonk/wp/2015/11/30/there-have-been-334-days-and-351-mass-shootings-so-far-this-year/&lt;/p&gt;
    &lt;p&gt;#10yrsago Not even the scapegoats will go to jail for BP’s murder of the Gulf Coast https://arstechnica.com/tech-policy/2015/12/manslaughter-charges-dropped-in-bp-spill-case-nobody-from-bp-will-go-to-prison/&lt;/p&gt;
    &lt;p&gt;#10yrsago Urban Transport Without the Hot Air: confusing the issue with relevant facts! https://memex.craphound.com/2015/12/03/urban-transport-without-the-hot-air-confusing-the-issue-with-relevant-facts/&lt;/p&gt;
    &lt;p&gt;#5yrsago Breathtaking Iphone hack https://pluralistic.net/2020/12/03/ministry-for-the-future/#awdl&lt;/p&gt;
    &lt;p&gt;#5yrsago Graffitists hit dozens of NYC subway cars https://pluralistic.net/2020/12/03/ministry-for-the-future/#getting-up&lt;/p&gt;
    &lt;p&gt;#5yrsago The Ministry For the Future https://pluralistic.net/2020/12/03/ministry-for-the-future/#ksr&lt;/p&gt;
    &lt;p&gt;#5yrsago Monopolies made America vulnerable to covid https://pluralistic.net/2020/12/03/ministry-for-the-future/#big-health&lt;/p&gt;
    &lt;p&gt;#5yrsago Section 230 is Good, Actually https://pluralistic.net/2020/12/04/kawaski-trawick/#230&lt;/p&gt;
    &lt;p&gt;#5yrsago Postmortem of the NYPD's murder of a Black man https://pluralistic.net/2020/12/04/kawaski-trawick/#Kawaski-Trawick&lt;/p&gt;
    &lt;p&gt;#5yrsago Student debt trap https://pluralistic.net/2020/12/04/kawaski-trawick/#strike-debt&lt;/p&gt;
    &lt;p&gt;#1yrago "That Makes Me Smart" https://pluralistic.net/2024/12/04/its-not-a-lie/#its-a-premature-truth&lt;/p&gt;
    &lt;p&gt;#1yrago Canada sues Google https://pluralistic.net/2024/12/03/clementsy/#can-tech&lt;/p&gt;
    &lt;head rend="h1"&gt;Upcoming appearances (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Virtual: Poetic Technologies with Brian Eno (David Graeber Institute), Dec 8&lt;lb/&gt;https://davidgraeber.institute/poetic-technologies-with-cory-doctorow-and-brian-eno/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Madison, CT: Enshittification at RJ Julia, Dec 8&lt;/p&gt;&lt;lb/&gt;https://rjjulia.com/event/2025-12-08/cory-doctorow-enshittification&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Hamburg: Chaos Communications Congress, Dec 27-30&lt;/p&gt;&lt;lb/&gt;https://events.ccc.de/congress/2025/infos/index.html&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Denver: Enshittification at Tattered Cover Colfax, Jan 22&lt;/p&gt;&lt;lb/&gt;https://www.eventbrite.com/e/cory-doctorow-live-at-tattered-cover-colfax-tickets-1976644174937&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Recent appearances (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enshittification (Future Knowledge)&lt;lb/&gt;https://futureknowledge.transistor.fm/episodes/enshittification&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;We have become slaves to Silicon Valley (Politics JOE)&lt;/p&gt;&lt;lb/&gt;https://www.youtube.com/watch?v=JzEUvh1r5-w&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;How Enshittification is Destroying The Internet (Frontline Club)&lt;/p&gt;&lt;lb/&gt;https://www.youtube.com/watch?v=oovsyzB9L-s&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Escape Forward with Cristina Caffarra&lt;/p&gt;&lt;lb/&gt;https://escape-forward.com/2025/11/27/enshittification-of-our-digital-experience/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Why Every Platform Betrays You (Trust Revolution)&lt;/p&gt;&lt;lb/&gt;https://fountain.fm/episode/bJgdt0hJAnppEve6Qmt8&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Latest books (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025&lt;/p&gt;&lt;lb/&gt;https://us.macmillan.com/books/9780374619329/enshittification/&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (the-bezzle.org).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books http://redteamblues.com.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Upcoming books (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Memex Method," Farrar, Straus, Giroux, 2026&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Colophon (permalink)&lt;/head&gt;
    &lt;p&gt;Today's top sources:&lt;/p&gt;
    &lt;p&gt;Currently writing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Post-American Internet," a short book about internet policy in the age of Trumpism. PLANNING.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A Little Brother short story about DIY insulin PLANNING&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.&lt;/p&gt;
    &lt;p&gt;https://creativecommons.org/licenses/by/4.0/&lt;/p&gt;
    &lt;p&gt;Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.&lt;/p&gt;
    &lt;head rend="h1"&gt;How to get Pluralistic:&lt;/head&gt;
    &lt;p&gt;Blog (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;Newsletter (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;https://pluralistic.net/plura-list&lt;/p&gt;
    &lt;p&gt;Mastodon (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;Medium (no ads, paywalled):&lt;/p&gt;
    &lt;p&gt;Twitter (mass-scale, unrestricted, third-party surveillance and advertising):&lt;/p&gt;
    &lt;p&gt;Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):&lt;/p&gt;
    &lt;p&gt;https://mostlysignssomeportents.tumblr.com/tagged/pluralistic&lt;/p&gt;
    &lt;p&gt;"When life gives you SARS, you make sarsaparilla" -Joey "Accordion Guy" DeVilla&lt;/p&gt;
    &lt;p&gt;READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.&lt;/p&gt;
    &lt;p&gt;ISSN: 3066-764X&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46181314</guid><pubDate>Sun, 07 Dec 2025 12:45:46 +0000</pubDate></item><item><title>I wasted years of my life in crypto</title><link>https://twitter.com/kenchangh/status/1994854381267947640</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46181371</guid><pubDate>Sun, 07 Dec 2025 12:57:59 +0000</pubDate></item></channel></rss>