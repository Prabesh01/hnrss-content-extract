<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 02 Feb 2026 12:32:09 +0000</lastBuildDate><item><title>Clearspace (YC W23) Is Hiring an Applied Researcher (ML)</title><link>https://www.ycombinator.com/companies/clearspace/jobs/GOWiDwp-research-engineer-at-clearspace</link><description>&lt;doc fingerprint="14939967bc01edd1"&gt;
  &lt;main&gt;
    &lt;p&gt;Eliminate compulsive phone usage&lt;/p&gt;
    &lt;p&gt;About Clearspace&lt;/p&gt;
    &lt;p&gt;Clearspace is building the intentionality layer of the internet. Our mission is to build technology as effective at protecting human attention as social media is at exploiting it (infinite scrolling, short-form feeds, manipulative notifications, etc). Our category defining mobile app has been featured on Huberman Lab, New York Times Wirecutter, NPR Marketplace, Forbes, TBPN.&lt;/p&gt;
    &lt;p&gt;People that want a better relationship with their devices have nowhere to turn except for willpower. We are building an agent that achieves this on all devices by processing and filtering network traffic based on natural language rules.&lt;/p&gt;
    &lt;p&gt;About The Role&lt;/p&gt;
    &lt;p&gt;We are looking for an ML-focused engineer that will be responsible for training and improving a model for classifying network traffic. You are great for this role if you are not only excited about the latest in AI and ML but are also a problem-solver in the data domain. You don‚Äôt just think about the model but ‚Äúhow can we get more data volume‚Äù; ‚Äúhow can we featurize the data intelligently‚Äù; ‚Äúwhat are our data needs based on our task and desired model size‚Äù, and like building backwards from inference requirements.&lt;/p&gt;
    &lt;p&gt;Responsibilities&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Nice to Have&lt;/p&gt;
    &lt;p&gt;At Clearspace we help people reduce compulsive phone usage.&lt;/p&gt;
    &lt;p&gt;We exist to protect people's attention from the exploits of modern technology platforms and make space for the things that matter to them most.&lt;/p&gt;
    &lt;p&gt;We believe the technology to protect someones attention should be just as sophisticated and effective as the tech that is exploiting it and are building a world-class engineering team to arm the world with a comprehensive attention protection stack.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46848260</guid><pubDate>Sun, 01 Feb 2026 18:41:54 +0000</pubDate></item><item><title>Building Your Own Efficient uint128 in C++</title><link>https://solidean.com/blog/2026/building-your-own-u128/</link><description>&lt;doc fingerprint="172010af286e8a4b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building Your Own Efficient uint128 in C++&lt;/head&gt;
    &lt;p&gt;A practical walk-through of a fixed-width uint128 implementation in modern C++.&lt;/p&gt;
    &lt;p&gt;We build a minimal &lt;code&gt;u128&lt;/code&gt; as two &lt;code&gt;u64&lt;/code&gt; limbs and implement arithmetic using carry, borrow, and multiply intrinsics that map directly to x64 instructions.
The generated code is on par with builtin &lt;code&gt;__uint128_t&lt;/code&gt; for addition, subtraction, multiplication, and comparison.
This is unsigned-only, x64-focused, and intentionally narrow in scope.
The result is a solid foundation for exact, fixed-width arithmetic with a focus on good codegen and predictability, not abstraction.&lt;/p&gt;
    &lt;p&gt;Full code and compiler output: https://godbolt.org/z/K6dn3s91Y&lt;/p&gt;
    &lt;head rend="h2"&gt;Scope&lt;/head&gt;
    &lt;p&gt;We take the smallest reasonable definition of a 128-bit integer, two 64-bit words, and turn it into a usable arithmetic type whose generated code is indistinguishable from a builtin &lt;code&gt;__uint128_t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This post is explicitly not about dynamically-sized big integer arithmetic. It is about being explicit with range bounds and letting the compiler emit the exact instructions we want. The scope is deliberately limited: unsigned arithmetic, fixed width, modern x64, with Clang and GCC as the primary targets and notes for MSVC where it differs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why fixed-width big integers&lt;/head&gt;
    &lt;p&gt;In many domains, especially geometry and numerics, we do not need arbitrary precision. We need enough precision to be exact for known bounds, and we need the cost to be predictable.&lt;/p&gt;
    &lt;p&gt;Dynamic big integer libraries solve a different problem. They are flexible and general, but they pay for that generality in memory traffic, branches, and indirection. If your values fit into a fixed number of bits and you know that ahead of time, fixed-width arithmetic is usually the better trade. (In fact, our high-performance exact mesh booleans are completely built on this: Exact Arithmetic in Solidean)&lt;/p&gt;
    &lt;p&gt;A 128-bit integer is the gateway drug to fixed-width arithmetic. It is the smallest width that is no longer builtin, while still mapping cleanly to the underlying hardware. Once the carry and multiply patterns are explicit at 128 bits, extending them to 192 or 256 bits is straightforward. In production, we use 256-bit integers in our hot paths and go up to 564 bits for certain edge cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Representation&lt;/head&gt;
    &lt;p&gt;We represent a 128-bit unsigned integer as two 64-bit limbs. You can literally think of this as writing the &lt;code&gt;u128&lt;/code&gt; as a 2-digit number in base \(2^{64}\).
Because it's unsigned, we don't need to think about two's complement.&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;cstdint&amp;gt;
#include &amp;lt;immintrin.h&amp;gt; // _addcarry_u64, _subborrow_u64, _mulx_u64

// this is the type used in the intrinsics signature
// (and uint64_t is unsigned long, not unsigned long long...)
using u64 = unsigned long long;

struct u128
{
    u64 low = 0;
    u64 high = 0;
};
&lt;/code&gt;
    &lt;head rend="h2"&gt;Addition, with carry&lt;/head&gt;
    &lt;p&gt;We start off easy. Addition is simply done using long addition on our base \(2^{64}\) digits. The intrinsic &lt;code&gt;_addcarry_u64&lt;/code&gt; corresponds to the x64 instruction &lt;code&gt;adc&lt;/code&gt; and is exactly what we need:
Given two &lt;code&gt;u64&lt;/code&gt; summands and an input carry (0 or 1), we get the &lt;code&gt;u64&lt;/code&gt; result (via a slightly cumbersome output parameter) and a new carry.&lt;/p&gt;
    &lt;code&gt;u128 operator+(u128 a, u128 b) 
{
    u128 r;
    unsigned char c = _addcarry_u64(0, a.low,  b.low,  &amp;amp;r.low);
    (void)_addcarry_u64(c, a.high, b.high, &amp;amp;r.high);
    return r;
}
&lt;/code&gt;
    &lt;p&gt;The generated assembly is exactly what you would write by hand.&lt;/p&gt;
    &lt;code&gt;operator+(u128, u128):
        mov     rax, rdi
        add     rax, rdx
        adc     rsi, rcx
        mov     rdx, rsi
        ret
&lt;/code&gt;
    &lt;p&gt;The moves are just calling convention noise. The core is an &lt;code&gt;add&lt;/code&gt; (because the first addition has no input carry) followed by an &lt;code&gt;adc&lt;/code&gt;.
This is identical to what the compiler emits for &lt;code&gt;__uint128_t&lt;/code&gt; addition.&lt;/p&gt;
    &lt;p&gt;A small but important point is that intrinsics are preferable to inline assembly here. They act like specialized IR operations. The compiler understands their semantics, can schedule around them, and can still optimize aggressively. Inline assembly is more of a black box and much easier to get wrong or inhibit optimizations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Subtraction: same story, inverted&lt;/head&gt;
    &lt;p&gt;Subtraction mirrors addition almost perfectly. Instead of a carry, we track a borrow. On x64, this is &lt;code&gt;sbb&lt;/code&gt;, subtract with borrow.
The corresponding intrinsic is &lt;code&gt;_subborrow_u64&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;u128 operator-(u128 a, u128 b) 
{
    u128 r;
    unsigned char c = _subborrow_u64(0, a.low,  b.low,  &amp;amp;r.low);
    (void)_subborrow_u64(c, a.high, b.high, &amp;amp;r.high);
    return r;
}
&lt;/code&gt;
    &lt;p&gt;And again, the assembly is exactly what we want.&lt;/p&gt;
    &lt;code&gt;operator-(u128, u128):
        mov     rax, rdi
        sub     rax, rdx
        sbb     rsi, rcx
        mov     rdx, rsi
        ret
&lt;/code&gt;
    &lt;p&gt;At this point, addition and subtraction are basically solved. There is no hidden cost and no abstraction penalty. It's also easy to see how this scales to larger integer types with one extra instruction per &lt;code&gt;u64&lt;/code&gt; "digit".&lt;/p&gt;
    &lt;head rend="h2"&gt;Multiplication: regrouping our &lt;code&gt;u64&lt;/code&gt; digits&lt;/head&gt;
    &lt;p&gt;Multiplication is where things get more interesting. A 128-bit by 128-bit multiply produces a 256-bit result but we want only the lower 128 bit for our result. Same story with &lt;code&gt;u64 * u64&lt;/code&gt; really, which produces a 128 bit result in theory, but you usually only use the lower &lt;code&gt;u64&lt;/code&gt;.
Speaking of which, all modern 64-bit architectures give you access to fast &lt;code&gt;u64 * u64 -&amp;gt; u128&lt;/code&gt; instructions.
With BMI2, this is exposed as &lt;code&gt;_mulx_u64&lt;/code&gt;.
On MSVC, the equivalent is &lt;code&gt;_umul128&lt;/code&gt;.
This is our building block for large multiplication.&lt;/p&gt;
    &lt;p&gt;You can derive the code from writing the &lt;code&gt;u128 * u128&lt;/code&gt; as 2-digit long multiplication &lt;code&gt;(u64, u64) * (u64, u64)&lt;/code&gt; and then look sharply at what sums up to which digit.&lt;/p&gt;
    &lt;p&gt;That's how I do it on paper, but here we can also choose an algebraic route. Write the numbers as: $$ (a.\text{low} + 2^{64} \cdot a.\text{high}) \cdot (b.\text{low} + 2^{64} \cdot b.\text{high}) $$ Expanding this gives four terms. Of those, only three contribute to the low 128 bits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(a_\text{low} \cdot b_\text{low}\) contributes both low and high parts&lt;/item&gt;
      &lt;item&gt;\(a_\text{low} \cdot b_\text{high}\) contributes to bits 64..127&lt;/item&gt;
      &lt;item&gt;\(a_\text{high} \cdot b_\text{low}\) contributes to bits 64..127&lt;/item&gt;
      &lt;item&gt;\(a_\text{high} \cdot b_\text{high}\) contributes only above bit 128 and can be discarded&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This works for larger integers as well, though summing up intermediate terms can produce carries for "higher digits".&lt;/p&gt;
    &lt;code&gt;u128 operator*(u128 a, u128 b) 
{
    // we want the low 128 bits of:
    // (a.low + 2^64 a.high) * (b.low + 2^64 b.high)
    //
    // r.low  = lo64(a.low * b.low)
    // r.high = hi64(a.low * b.low)
    //        + lo64(a.low * b.high)
    //        + lo64(a.high * b.low)        (mod 2^64)

    // NOTE (MSVC): for multiply, you can use _umul128(a, b, &amp;amp;hi) instead of _mulx_u64.
    //              Clang/GCC: _mulx_u64 is BMI2 and needs -mbmi2.

    u128 r;

    u64 p0_hi;
    r.low = _mulx_u64(a.low, b.low, &amp;amp;p0_hi);

    // cross terms: only the low 64 bits contribute to r.high
    u64 t1_hi;
    u64 t1_lo = _mulx_u64(a.low,  b.high, &amp;amp;t1_hi);

    u64 t2_hi;
    u64 t2_lo = _mulx_u64(a.high, b.low,  &amp;amp;t2_hi);

    // simply add is sufficient: carries would land in bit 128 and are discarded
    r.high = p0_hi + t1_lo + t2_lo;

    return r;
}
&lt;/code&gt;
    &lt;p&gt;Note that we do not need carry handling there. Any carry out of bit 127 would land in bit 128, which we are discarding anyway.&lt;/p&gt;
    &lt;p&gt;The compiler output reflects this reasoning.&lt;/p&gt;
    &lt;code&gt;operator*(u128, u128):
        mulx    r8, rax, rdi
        imul    rcx, rdi
        imul    rdx, rsi
        add     rdx, rcx
        add     rdx, r8
        ret
&lt;/code&gt;
    &lt;p&gt;The compiler chooses slightly different instructions and registers for the builtin &lt;code&gt;__uint128_t&lt;/code&gt; multiplication but is otherwise identical as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Equality&lt;/head&gt;
    &lt;p&gt;Now an easy one. &lt;code&gt;u128&lt;/code&gt; equality is simple structural equality.&lt;/p&gt;
    &lt;code&gt;bool operator==(u128 a, u128 b) 
{
    return a.low == b.low &amp;amp;&amp;amp; a.high == b.high;
}
&lt;/code&gt;
    &lt;p&gt;The generated assembly is worth a quick look.&lt;/p&gt;
    &lt;code&gt;operator==(u128, u128):
        xor     rdi, rdx
        xor     rsi, rcx
        or      rsi, rdi
        sete    al
        ret
&lt;/code&gt;
    &lt;p&gt;Instead of branching (as you might expect from the short-circuiting of &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;), the compiler XORs the corresponding limbs.
XOR produces zero if and only if the inputs are equal.
ORing the results combines the checks.
If the final value is zero, both limbs were equal.&lt;/p&gt;
    &lt;p&gt;This pattern continues for larger integers, though we might see branching due to short-circuiting at some point. (We could of course just use the XOR approach in &lt;code&gt;operator==&lt;/code&gt; but it is distinctly less readable.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Comparison: borrow beats branching&lt;/head&gt;
    &lt;p&gt;The straightforward way to compare two 128-bit integers is to compare the high parts first and then the low parts.&lt;/p&gt;
    &lt;code&gt;bool operator&amp;lt;(u128 a, u128 b)
{
    if (a.high != b.high) return a.high &amp;lt; b.high;
    return a.low &amp;lt; b.low;
}
&lt;/code&gt;
    &lt;p&gt;This is correct, but the codegen is not great:&lt;/p&gt;
    &lt;code&gt;operator&amp;lt;(u128, u128):
        xor     r8d, r8d
        cmp     rdi, rdx
        setb    r8b
        xor     eax, eax
        cmp     rsi, rcx
        setb    al
        cmove   eax, r8d
        ret
&lt;/code&gt;
    &lt;p&gt;Works, but heavier than necessary. We can do better by leaning on the hardware borrow flag.&lt;/p&gt;
    &lt;p&gt;Unsigned comparison &lt;code&gt;a &amp;lt; b&lt;/code&gt; is equivalent to checking whether &lt;code&gt;a - b&lt;/code&gt; produces a borrow:&lt;/p&gt;
    &lt;code&gt;bool operator&amp;lt;(u128 a, u128 b) 
{
    u64 dont_care;

    // compute borrow from (a.low - b.low). If a.low &amp;lt; b.low =&amp;gt; borrow = 1.
    unsigned char borrow = _subborrow_u64(0, a.low, b.low, &amp;amp;dont_care);

    // now subtract highs with that borrow
    // final borrow tells us if a &amp;lt; b in 128-bit unsigned.
    borrow = _subborrow_u64(borrow, a.high, b.high, &amp;amp;dont_care);

    return borrow != 0;
}
&lt;/code&gt;
    &lt;p&gt;The resulting assembly is minimal:&lt;/p&gt;
    &lt;code&gt;operator&amp;lt;(u128, u128):
        cmp     rdi, rdx
        sbb     rsi, rcx
        setb    al
        ret
&lt;/code&gt;
    &lt;p&gt;One compare, one subtract with borrow, and a flag check. This is exactly the kind of codegen we want in hot code.&lt;/p&gt;
    &lt;head rend="h2"&gt;A small use site&lt;/head&gt;
    &lt;p&gt;To make sure everything composes properly, let's build a slightly larger function.&lt;/p&gt;
    &lt;code&gt;u128 demo_u128(u128 a, u128 b) 
{
    u128 x = a + b;
    u128 y = a * b;
    return x &amp;lt; y
            ? y - x
            : x - y;
}
&lt;/code&gt;
    &lt;p&gt;All operators inline cleanly:&lt;/p&gt;
    &lt;code&gt;demo_u128(u128, u128):
        mov     r8, rdi
        add     r8, rdx
        mov     r9, rsi
        adc     r9, rcx
        mulx    rax, r10, rdi
        imul    rcx, rdi
        imul    rdx, rsi
        add     rdx, rcx
        add     rdx, rax
        mov     rax, r8
        sub     rax, r10
        mov     rcx, r9
        sbb     rcx, rdx
        jae     .LBB13_2
        sub     r10, r8
        sbb     rdx, r9
        mov     rax, r10
        mov     rcx, rdx
.LBB13_2:
        mov     rdx, rcx
        ret
&lt;/code&gt;
    &lt;p&gt;There is a branch for the ternary operator while the builtin version uses conditional moves instead. Which is better depends on data patterns but could go either way. I consider this basically as good as it gets.&lt;/p&gt;
    &lt;head rend="h2"&gt;Platform notes&lt;/head&gt;
    &lt;p&gt;The examples shown are for x64 with Clang or GCC.&lt;/p&gt;
    &lt;p&gt;On MSVC, &lt;code&gt;_addcarry_u64&lt;/code&gt; and &lt;code&gt;_subborrow_u64&lt;/code&gt; work the same way.
For multiplication, &lt;code&gt;_umul128&lt;/code&gt; replaces &lt;code&gt;_mulx_u64&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;On AArch64, the same approach applies using &lt;code&gt;adds&lt;/code&gt; and &lt;code&gt;adcs&lt;/code&gt; instructions for addition, &lt;code&gt;subs&lt;/code&gt; and &lt;code&gt;sbcs&lt;/code&gt; for subtraction, and &lt;code&gt;mul + umulh&lt;/code&gt; for the low + high half of a 64-bit multiply.
The patterns carry over directly, even though the intrinsics differ slightly (and multiplication is split into two parts).&lt;/p&gt;
    &lt;head rend="h2"&gt;Outlook&lt;/head&gt;
    &lt;p&gt;This &lt;code&gt;u128&lt;/code&gt; is the easiest large integer you can write.
Our goal is best performance, so we made sure that codegen is reasonably identical to the builtin &lt;code&gt;__uint128_t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;From here, the same patterns extend naturally to signed variants, widening multiplies such as u128 times u128 to u256, and chains of fixed-width integers like i192 or i256. More importantly, the same reasoning applies when you design predicate-specific arithmetic that only computes what is actually needed.&lt;/p&gt;
    &lt;p&gt;A lot of our performance really boils down to these types: No &lt;code&gt;BigInteger&lt;/code&gt; tax, no floating predicates (that need a few kB of stack space for the worst case).
Just a lot of straightline integer code and some light static branching.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum 2026-01-24&lt;/head&gt;
    &lt;p&gt;Some notes based on reader feedback.&lt;/p&gt;
    &lt;p&gt;On PowerPC: I don't know much about PowerPC or the availability of intrinsics, but the instructions you need are definitely there. For add/sub with carry, there's addc / adde for addition and subfc / subfe for subtraction with borrow. For wide multiplication, mulhdu gives you the high half of a 64-bit multiply (and mulhd for signed).&lt;/p&gt;
    &lt;p&gt;On GCC codegen with intrinsics: Someone pointed out that GCC doesn't always handle the intrinsic-based addition optimally. It sometimes moves the result through the stack before setting it in the final registers. This is related to writing directly to the result struct. If you write to "real" scalars first, the codegen is optimal again. A weird one.&lt;/p&gt;
    &lt;p&gt;On division: There is no neat codegen for division. Even the builtin delegates to a library call. The naive but practical approach is binary long division, which finishes in up to 128 steps. Either branchless with fixed runtime or with a loop that searches for the next set bit. Either way it's a bit of work. Our exact predicates are always formulated in a division-free way simply because division would be expensive.&lt;/p&gt;
    &lt;p&gt;On &lt;code&gt;_BitInt(N)&lt;/code&gt;:
The upcoming &lt;code&gt;_BitInt(N)&lt;/code&gt; type does work, but with caveats.
For B = 128, you get the normal codegen.
For B &amp;gt; 128, GCC calls into a function where the bit size is a runtime parameter.
So yes, they would work, but performance will be subpar for larger widths.
Clang generates properly inlined assembly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46849154</guid><pubDate>Sun, 01 Feb 2026 20:40:45 +0000</pubDate></item><item><title>My iPhone 16 Pro Max produces garbage output when running MLX LLMs</title><link>https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/</link><description>&lt;doc fingerprint="3402b8b4df265bde"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;TL;DR:&lt;/head&gt;
    &lt;p&gt;My iPhone 16 Pro Max produces garbage output when running MLX LLMs. An iPhone 15 Pro runs the same code perfectly. A MacBook Pro also runs the same code perfectly. The tensor outputs on the 16 show numerical values an order of magnitude wrong. I suspect it points to a hardware defect in the Neural Engine or some other ML-needed system.&lt;/p&gt;
    &lt;p&gt;It was a PITA to debug, but at least I got a blog post out of it.&lt;/p&gt;
    &lt;head rend="h1"&gt;How did I get there?&lt;/head&gt;
    &lt;p&gt;This was supposed to be a simple, unwinding-time project.&lt;/p&gt;
    &lt;p&gt;For the past few months I've been working on a &lt;del&gt;Clawdbot&lt;/del&gt; Moltbot clone that I've been calling Schmidt. It basically does the same kind of thing but with a custom chat UI instead of using Telegram, WhatsApp or other "I-can't-afford-to-be-banned-from" Service. This project has been consuming early days and late nights, so, to unwind, I decided that it may be a good idea to do something simpler. Since I recently subscribed to MiniMax M2.1, I thought I would do what many do and build a simple expense tracking app to test out the model.&lt;/p&gt;
    &lt;p&gt;The core functionality is simple:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatically, upon each payment, add the expense to my app&lt;/item&gt;
      &lt;item&gt;Update an Apple Watch complication with the % of my monthly budget spent&lt;/item&gt;
      &lt;item&gt;Categorize the purchase for later analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This all comes from being basically orphaned by Nubank's amazing native app (since replaced by a less-full-featured Flutter version).&lt;/p&gt;
    &lt;p&gt;Integrating with Shortcuts is manual, but reliable. Within 15 minutes I had a version of the app that could register purchases. The Apple Watch complication, the main goal, can come later. I'd rather get the classification feature, which should be easy, done quickly ‚Äì so I figured.&lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Intelligence&lt;/head&gt;
    &lt;p&gt;Given the new LLM-bonanza we've been living through, it's no surprise that Apple has their own set of APIs developers such as me can use. Reading up on the documentation, it's a matter of checking for the availability of the feature and then asking the model to either reply to a textual query or, in my case, categorize a request.&lt;/p&gt;
    &lt;p&gt;MiniMax raced through it in a single prompt and then I ran it on my iPhone. First expense was a purchase at a shop called "Kasai Kitchin", classified as... &lt;code&gt;unknown&lt;/code&gt;.&lt;lb/&gt;Weird.&lt;/p&gt;
    &lt;p&gt;Checking the logs, it was clear: the model support was downloading. The feature hadn't been enabled. Again, weird. I should have it on. Anyway, I go into settings, do the weird dance of toggling it on and off ‚Äì sadly, that's not surprising on Apple's services. Maybe my Settings.app got stuck in a weird state, who knows? ‚Äì and wait for it to download.&lt;/p&gt;
    &lt;p&gt;After 4h I realized it was not going anywhere. Looking it up, it seems that many have the same issue (this thread shows 12 pages of frustrated users). Again, not a surprise for Apple's services recently.&lt;/p&gt;
    &lt;p&gt;Oh well, time to give up on the Apple Intelligence approach. Let's move on to the next one.&lt;/p&gt;
    &lt;head rend="h2"&gt;MLX LLM&lt;/head&gt;
    &lt;p&gt;Well, the iOS framework engineers don't seem to be the only engineers at Apple capable of coming up with Machine Learning APIs in Swift. Apparently, there's a whole separate way of doing it ‚Äì with models downloaded to your app. Not great for the user's storage, but great for me!&lt;/p&gt;
    &lt;p&gt;Again, MiniMax does it in a heartbeat, specially after being given documentation and one or two Medium posts. Time to run on my iPhone and... gibberish.&lt;/p&gt;
    &lt;p&gt;The CPU spins to 100% and the model starts generating. But it's all gibberish. And no "stop" token is generated, so this goes on for long.&lt;/p&gt;
    &lt;p&gt;At this point, the only explanation is: I'm completely incompetent and can't even get a simple "ready made" framework to execute what I want. Or, rather, MiniMax is! The good thing about offloading your work to an LLM is that you can blame it for your shortcomings. Time to get my hands dirty and do it myself, typing code on my keyboard, like the ancient Mayan and Aztec programmers probably did.&lt;/p&gt;
    &lt;head rend="h2"&gt;My own MLX implementation&lt;/head&gt;
    &lt;p&gt;I went back to the documentation, to the Medium posts and, much to my surprise: MiniMax had followed it to the letter. Even went back to some deprecated methods of generation and it also was gibberish. And now there's no one to blame, but myself. I go to work everyday and this impostor-syndrome inducing problem silently consumes me. &lt;lb/&gt;After 3 days of trying to get it to work, I'm ready to give up...&lt;lb/&gt;...until, on a Tuesday morning, at 7-8 AM, I have an idea: let me, just in case, run this on my old iPhone 15 Pro. Up to this point, I was running it on my daily driver, an iPhone 16 Pro Max that was a replacement phone sent by Apple Care after a small clubbing mishap (in which my iPhone was irreparably crashed). I rush to get everything ready before it's time to go to work and: it works! Gemma, Qwen, and all other models generate coherent responses!&lt;/p&gt;
    &lt;p&gt;I stop and think: this cannot be a hardware issue, right? Of course not. The iPhone 15 is still running iOS 18. The iPhone 16 is running 26. It must be an OS issue. Well, time to be late for my work standup and update the old phone. The curiosity is too much. Many minutes later... same results, now on iOS 26. The plot is thickening.&lt;/p&gt;
    &lt;head rend="h1"&gt;Finding the smoking gun: breakpoints in MLX's implementations of Gemma&lt;/head&gt;
    &lt;p&gt;After that work day, and after many lunch and coffee discussions with coworkers about the sources of my troubles, I get home and immediately set myself on debugging MLX as it runs, if possible. The game plan is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use a known-to-be-reliable model, that fits in RAM (I went with quantized Gemma)&lt;/item&gt;
      &lt;item&gt;Use a simple prompt, in my case "What is 2+2?"&lt;list rend="ul"&gt;&lt;item&gt;To be really pedantic: the prompt was &lt;code&gt;&amp;lt;start_of_turn&amp;gt;user\nWhat is 2+2?&amp;lt;end_of_turn&amp;gt;\n&amp;lt;start_of_turn&amp;gt;model&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;To be really pedantic: the prompt was &lt;/item&gt;
      &lt;item&gt;Run everything with temperature set to &lt;code&gt;0.0&lt;/code&gt;‚Äì maybe that's enough to remove variability&lt;/item&gt;
      &lt;item&gt;Find the model implementation&lt;/item&gt;
      &lt;item&gt;Find where the model iterates through the layers and&lt;/item&gt;
      &lt;item&gt;Print out the MLXArray/Tensor with the values on each layer as the input goes through&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A few moments later and I find where I need to be. Added the breakpoints, added the logs and off to the races.&lt;/p&gt;
    &lt;p&gt;I run it on my iPhone 16 Pro Max. The model loads and the prompt is "What is 2+2?". The tensors start printing out, line after line after line. For once, the logs aren't complete gibberish ‚Äì they're numbers. Floating point values representing the model's internal state as it processes the input. I save the output to a file and do the same on my iPhone 15 Pro. Same model, same prompt, same code. Time to compare.&lt;/p&gt;
    &lt;head rend="h1"&gt;Welp, now it's definitely out of my expertise&lt;/head&gt;
    &lt;p&gt;I grep for a pattern I know should be consistent ‚Äì an array at log-line 58, right before the values get normalized/softmaxed. On a working device, I hypothesize this should be the same every time.&lt;lb/&gt;On the iPhone 15 Pro:&lt;code&gt;3: "[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]"&lt;/code&gt;&lt;lb/&gt;On the iPhone 16 Pro Max:&lt;code&gt;3: "[[[[191.5, 23.625, 173.75, ..., 1298, -147.25, -162.5]]]]"&lt;/code&gt;&lt;lb/&gt;Huh. Not close. Not at all. These values are orders of magnitude off. I double check the start of the logs and both phones show the same:&lt;code&gt;1: "array([[[0.162842, -0.162842, -0.48877, ..., -0.176636, 0.0001297, 0.088501],\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\n [-1.30957, 1.57324, -1.30957, ..., -0.0010376, -0.0010376, 1.12305],\n ...,\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\n [0.296875, 0.59375, 0.890625, ..., -0.59375, 0.296875, -0.890137],\n [1.02734, -0.616211, -0.616211, ..., -0.275879, -0.551758, 0.275879]]], dtype=float16)"&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;OK, so the model receives the same thing as input, but at some point, the values start to go off. Like, way off. In order to make sure I'm not crazy, I do one last thing: run the same thing on my Mac. Make the app run on iPad compatibility mode and...&lt;code&gt;3: "[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]"&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Bingo! Same as iPhone 15!&lt;/p&gt;
    &lt;p&gt;The model isn't broken. The code isn't broken. Most importantly, I'm not broken*. My phone is broken.&lt;lb/&gt;*arguable, but besides the point here&lt;/p&gt;
    &lt;head rend="h1"&gt;What's going on?&lt;/head&gt;
    &lt;p&gt;Let me explain what I think it's going on here: the iPhone 16 Pro Max contains Apple's A18 chip with its Neural Engine‚Äîa specialized accelerator for machine learning operations. MLX uses Metal to compile tensor operations for this accelerator. Somewhere in that stack, the computations are going very wrong. I don't think it's a widespread issue but, I do get disappointed that a relatively newly replaced iPhone from Apple Care came with such an issue.&lt;/p&gt;
    &lt;p&gt;However, if my Apple Intelligence troubles are related ‚Äì and they might as well be, I'd assume that code and MLX are not dissimilar in operations being done ‚Äì, it could be that all the 12 pages of users are users in a similar dillema, but without the means of debugging it.&lt;/p&gt;
    &lt;head rend="h2"&gt;What now?&lt;/head&gt;
    &lt;p&gt;I spent 3 days thinking I was incompetent. I blamed MiniMax. I blamed myself. The entire time, my $1,400 phone had a broken hardware. I could lose more time figuring out exactly what is wrong with it but it‚Äôs literally not worth my time.&lt;/p&gt;
    &lt;p&gt;I guess I can at least take a lesson that, when debugging, I should always consider the physical layer. I spent three days assuming this was a software problem ‚Äì my code, the library, the framework, my skills as a developer. The breakthrough was basically: "What if I'm not dumb and it's not my code?"&lt;/p&gt;
    &lt;p&gt;As for my phone: it'll probably go back to Apple, as a trade in for a new iPhone 17 Pro Max that hopefully ü§û can do math.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update on Feb. 1st:&lt;/head&gt;
    &lt;p&gt;Well, now it's Feb. 1st and I have an iPhone 17 Pro Max to test with and... everything works as expected. So it's pretty safe to say that THAT specific instance of iPhone 16 Pro Max was hardware-defective.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46849258</guid><pubDate>Sun, 01 Feb 2026 20:51:56 +0000</pubDate></item><item><title>Defeating a 40-year-old copy protection dongle</title><link>https://dmitrybrant.com/2026/02/01/defeating-a-40-year-old-copy-protection-dongle</link><description>&lt;doc fingerprint="a99b5744e017df58"&gt;
  &lt;main&gt;
    &lt;p&gt;That‚Äôs right ‚Äî this little device is what stood between me and the ability to run an even older piece of software that I recently unearthed during an expedition of software archaeology.&lt;/p&gt;
    &lt;p&gt;For a bit more background, I was recently involved in helping a friend‚Äôs accounting firm to move away from using an extremely legacy software package that they had locked themselves into using for the last four decades.&lt;/p&gt;
    &lt;p&gt;This software was built using a programming language called RPG (‚ÄúReport Program Generator‚Äù), which is older than COBOL (!), and was used with IBM‚Äôs midrange computers such as the System/3, System/32, and all the way up to the AS/400. Apparently, RPG was subsequently ported to MS-DOS, so that the same software tools built with RPG could run on personal computers, which is how we ended up here.&lt;/p&gt;
    &lt;p&gt;This accounting firm was actually using a Windows 98 computer (yep, in 2026), and running the RPG software inside a DOS console window. And it turned out that, in order to run this software, it requires a special hardware copy-protection dongle to be attached to the computer‚Äôs parallel port! This was a relatively common practice in those days, particularly with ‚Äúenterprise‚Äù software vendors who wanted to protect their very important‚Ñ¢ software from unauthorized use.&lt;/p&gt;
    &lt;p&gt;Sadly, most of the text and markings on the dongle‚Äôs label has been worn or scratched off, but we can make out several clues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The words ‚ÄúStamford, CT‚Äù, and what‚Äôs very likely the logo of a company called ‚ÄúSoftware Security Inc‚Äù. The only evidence for the existence of this company is this record of them exhibiting their wares at SIGGRAPH conferences in the early 1990s, as well as several patents issued to them, relating to software protection.&lt;/item&gt;
      &lt;item&gt;A word that seems to say ‚ÄúRUNTIME‚Äù, which will become clear in a bit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My first course of action was to take a disk image of the Windows 98 PC that was running this software, and get it running in an emulator, so that we could see what the software actually does, and perhaps export the data from this software into a more modern format, to be used with modern accounting tools. But of course all of this requires the hardware dongle; none of the accounting tools seem to work without it plugged in.&lt;/p&gt;
    &lt;p&gt;Before doing anything, I looked through the disk image for any additional interesting clues, and found plenty of fascinating (and archaeologically significant?) stuff:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We‚Äôve got a compiler for the RPG II language (excellent!), made by a company called Software West Inc.&lt;/item&gt;
      &lt;item&gt;Even better, there are two versions of the RPG II compiler, released on various dates in the 1990s by Software West.&lt;/item&gt;
      &lt;item&gt;We‚Äôve got the complete source code of the accounting software, written in RPG. It looks like the full accounting package consists of numerous RPG modules, with a gnarly combination of DOS batch files for orchestrating them, all set up as a ‚Äúmenu‚Äù system for the user to navigate using number combinations. Clearly the author of this accounting system was originally an IBM mainframe programmer, and insisted on bringing those skills over to DOS, with mixed results.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I began by playing around with the RPG compiler in isolation, and I learned very quickly that it‚Äôs the RPG compiler itself that requires the hardware dongle, and then the compiler automatically injects the same copy-protection logic into any executables it generates. This explains the text that seems to say ‚ÄúRUNTIME‚Äù on the dongle.&lt;/p&gt;
    &lt;p&gt;The compiler consists of a few executable files, notably &lt;code&gt;RPGC.EXE&lt;/code&gt;, which is the compiler, and &lt;code&gt;SEU.EXE&lt;/code&gt;, which is a source editor (‚ÄúSource Entry Utility‚Äù). Here‚Äôs what we get when we launch SEU without the dongle, after a couple of seconds:&lt;/p&gt;
    &lt;p&gt;A bit rude, but this gives us an important clue: this program must be trying to communicate over the parallel port over the course of a few seconds (which could give us an opportunity to pause it for debugging, and see what it‚Äôs doing during that time), and then exits with a message (which we can now find in a disassembly of the program, and trace how it gets there).&lt;/p&gt;
    &lt;p&gt;A great tool for disassembling executables of this vintage is Reko. It understands 16-bit real mode executables, and even attempts to decompile them into readable C code that corresponds to the disassembly.&lt;/p&gt;
    &lt;p&gt;And so, looking at the decompiled/disassembled code in Reko, I expected to find &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; instructions, which would be the telltale sign of the program trying to communicate with the parallel port through the PC‚Äôs I/O ports. However‚Ä¶ I didn‚Äôt see an &lt;code&gt;in&lt;/code&gt; or &lt;code&gt;out&lt;/code&gt; instruction anywhere! But then I noticed something: Reko disassembled the executable into two ‚Äúsegments‚Äù: &lt;code&gt;0800&lt;/code&gt; and &lt;code&gt;0809&lt;/code&gt;, and I was only looking at segment &lt;code&gt;0809&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If we look at segment &lt;code&gt;0800&lt;/code&gt;, we see the smoking gun: &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; instructions, meaning that the copy-protection routine is definitely here, and best of all, the entire code segment is a mere 0x90 bytes, which suggests that the entire routine should be pretty easy to unravel and understand. For some reason, Reko was not able to decompile this code into a C representation, but it still produced a disassembly, which will work just fine for our purposes. Maybe this was a primitive form of obfuscation from those early days, which is now confusing Reko and preventing it from associating this chunk of code with the rest of the program‚Ä¶ who knows.&lt;/p&gt;
    &lt;p&gt;Here is a GitHub Gist with the disassembly of this code, along with my annotations and notes. My x86 assembly knowledge is a little rusty, but here is the gist of what this code does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It‚Äôs definitely a single self-contained routine, intended to be called using a ‚Äúfar‚Äù &lt;code&gt;CALL&lt;/code&gt;instruction, since it returns with a&lt;code&gt;RETF&lt;/code&gt;instruction.&lt;/item&gt;
      &lt;item&gt;It begins by detecting the address of the parallel port, by reading the BIOS data area. If the computer has more than one parallel port, the dongle must be connected to the first parallel port (LPT1).&lt;/item&gt;
      &lt;item&gt;It performs a loop where it writes values to the data register of the parallel port, and then reads the status register, and accumulates responses in the &lt;code&gt;BH&lt;/code&gt;and&lt;code&gt;BL&lt;/code&gt;registers.&lt;/item&gt;
      &lt;item&gt;At the end of the routine, the ‚Äúresult‚Äù of the whole procedure is stored in the &lt;code&gt;BX&lt;/code&gt;register (&lt;code&gt;BH&lt;/code&gt;and&lt;code&gt;BL&lt;/code&gt;together), which will presumably be ‚Äúverified‚Äù by the caller of the routine.&lt;/item&gt;
      &lt;item&gt;Very importantly, there doesn‚Äôt seem to be any ‚Äúinput‚Äù into this routine. It doesn‚Äôt pop anything from the stack, nor does it care about any register values passed into it. Which can only mean that the result of this routine is completely constant! No matter what complicated back-and-forth it does with the dongle, the result of this routine should always be the same.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the knowledge that this routine must exit with some magic value stored in &lt;code&gt;BX&lt;/code&gt;, we can now patch the first few bytes of the routine to do just that! Not yet knowing which value to put in &lt;code&gt;BX&lt;/code&gt;, let‚Äôs start with 1234:&lt;/p&gt;
    &lt;code&gt;BB 34 12       MOV BX, 1234h
CB             RETF
&lt;/code&gt;
    &lt;p&gt;Only the first four bytes need patching ‚Äî set &lt;code&gt;BX&lt;/code&gt; to our desired value, and get out of there (&lt;code&gt;RETF&lt;/code&gt;). Running the patched executable with these new bytes still fails (expectedly) with the same message of ‚ÄúNo dongle, no edit‚Äù, but it fails immediately, instead of after several seconds of talking to the parallel port. Progress!&lt;/p&gt;
    &lt;p&gt;Stepping through the disassembly more closely, we get another major clue: The only value that &lt;code&gt;BH&lt;/code&gt; can be at the end of the routine is 76h (this is hard-coded into the routine). So, our total value for the magic number in &lt;code&gt;BX&lt;/code&gt; must be of the form 76xx. In other words, only the &lt;code&gt;BL&lt;/code&gt; value remains unknown:&lt;/p&gt;
    &lt;code&gt;BB __ 76       MOV BX, 76__h
CB             RETF
&lt;/code&gt;
    &lt;p&gt;Since &lt;code&gt;BL&lt;/code&gt; is an 8-bit register, it can only have 256 possible values. And what do we do when we have 256 combinations to try? Brute force it! I whipped up a script that plugs a value into that particular byte (from 0 to 255) and programmatically launches the executable in DosBox, and observes the output. Lo and behold, it worked! The brute forcing didn‚Äôt take long at all, because the correct number turned out to be‚Ä¶ 6. Meaning that the total magic number in &lt;code&gt;BX&lt;/code&gt; should be 7606h:&lt;/p&gt;
    &lt;code&gt;BB 06 76       MOV BX, 7606h
CB             RETF
&lt;/code&gt;
    &lt;p&gt;Bingo!&lt;lb/&gt; And then, proceeding to examine the other executable files in the compiler suite, the parallel port routine turns out to be exactly the same. All of the executables have the exact same copy protection logic, as if it was rubber-stamped onto them. In fact, when the compiler (&lt;code&gt;RPGC.EXE&lt;/code&gt;) compiles some RPG source code, it seems to copy the parallel port routine from itself into the compiled program. That‚Äôs right: the patched version of the compiler will produce executables with the same patched copy protection routine! Very convenient.&lt;/p&gt;
    &lt;p&gt;I must say, this copy protection mechanism seems a bit‚Ä¶ simplistic? A hardware dongle that just passes back a constant number? Defeatable with a four-byte patch? Is this really worthy of a patent? But who am I to pass judgment. It‚Äôs possible that I haven‚Äôt fully understood the logic, and the copy protection will somehow re-surface in another way. It‚Äôs also possible that the creators of the RPG compiler (Software West, Inc) didn‚Äôt take proper advantage of the hardware dongle, and used it in a way that is so easily bypassed.&lt;/p&gt;
    &lt;p&gt;In any case, Software West‚Äôs RPG II compiler is now free from the constraint of the parallel port dongle! And at some point soon, I‚Äôll work on purging any PII from the compiler directories, and make this compiler available as an artifact of computing history. It doesn‚Äôt seem to be available anywhere else on the web. If anyone reading this was associated with Software West Inc, feel free to get in touch ‚Äî I have many questions!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46849567</guid><pubDate>Sun, 01 Feb 2026 21:30:51 +0000</pubDate></item><item><title>Treasures found on HS2 route stored in secret warehouse</title><link>https://www.bbc.com/news/articles/c93v21q5xdvo</link><description>&lt;doc fingerprint="bffb9117a88385da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Treasures found on HS2 route stored in secret warehouse&lt;/head&gt;
    &lt;p&gt;Treasures unearthed by hundreds of archaeologists during the ongoing construction of the controversial HS2 train line have been shown exclusively to the BBC.&lt;/p&gt;
    &lt;p&gt;The 450,000 objects, which are being held in a secret warehouse, include a possible Roman gladiator's tag, a hand axe that may be more than 40,000 years old and 19th Century gold dentures.&lt;/p&gt;
    &lt;p&gt;It is an "unprecedented" amount and array of items, which will yield new insights into Britain's past, says the Centre for British Archaeology.&lt;/p&gt;
    &lt;p&gt;Major building developments in the UK need land to be assessed by archaeologists as part of the planning process, to protect heritage sites.&lt;/p&gt;
    &lt;p&gt;Since 2018 around 1,000 archaeologists have been involved in 60 digs along the route HS2 is set to take between London to Birmingham.&lt;/p&gt;
    &lt;p&gt;While the route is not currently scheduled to open until after 2033 due to delays, archaeologists say their fieldwork is largely complete.&lt;/p&gt;
    &lt;p&gt;The warehouse's location is a closely guarded secret for security purposes. All we can say is that it is in Yorkshire. Inside are shelves and shelves of pallets, loaded with around 7,300 boxes of historic items destined for further research.&lt;/p&gt;
    &lt;p&gt;The future of many objects, including whether they will stay in storage or be displayed, is still undecided, along with their ownership.&lt;/p&gt;
    &lt;p&gt;Historic England commended the team for revealing "new and exciting sites spanning over 10,000 years of our past".&lt;/p&gt;
    &lt;p&gt;But building HS2 has changed the landscape along its route, cutting into fields and communities, and dividing opinion.&lt;/p&gt;
    &lt;p&gt;Critics, such as Greg Smith, MP for Mid Buckinghamshire, say soaring costs, delays, abandoned villages and damage to the natural and historic environment mean that it is not worth building.&lt;/p&gt;
    &lt;p&gt;"It should not have cost the taxpayer tens of billions of pounds to build a railway that no-one wants and brings so much destruction," Smith says.&lt;/p&gt;
    &lt;p&gt;HS2 said in response: "Chief Executive Mark Wild has been clear that overall delivery of HS2 has been unacceptable and he's committed to ending the project's cycle of cost increases and delays."&lt;/p&gt;
    &lt;p&gt;"Our specialist archaeology team and contractors have carefully excavated numerous sites and have shown care and respect throughout this work."&lt;/p&gt;
    &lt;p&gt;"Whether HS2 is a good or bad thing is debatable, but I tell you what, if they built the railway and they didn't do the archaeology that would be more tragic," said historian Graham Evans, who chairs the Northamptonshire Battlefields Society.&lt;/p&gt;
    &lt;p&gt;The store holds showstoppers such as Roman statue heads and a gold 'three lions' pendant from the 13th-14th Century.&lt;/p&gt;
    &lt;p&gt;On the ground in one area is a bubble-wrapped empty coffin dating to 1799, with a smaller one next to it wrapped in masking tape - sobering reminders that this store is a snapshot of real lives once lived.&lt;/p&gt;
    &lt;p&gt;Some of the objects discovered have already been shown to the public.&lt;/p&gt;
    &lt;p&gt;We have picked out six that have never been on display. You can see where they were found on the HS2 route map below - then scroll further down to see the objects and read about their history.&lt;/p&gt;
    &lt;head rend="h2"&gt;Palaeolithic hand axe&lt;/head&gt;
    &lt;p&gt;Experts think this is more than 40,000 years old and was made by Neanderthals or an earlier species of human.&lt;/p&gt;
    &lt;p&gt;Found in the Edgcote area in Northamptonshire, it has a sharp edge likely designed for butchering animals.&lt;/p&gt;
    &lt;p&gt;Hand axes were held in the palm rather than attached to a wooden handle.&lt;/p&gt;
    &lt;p&gt;"There is something tactile about it when you hold it," said Dr Sara Machin, the finds lead for Access +, the consortium of archaeologists in charge of this project. "Even now it fits snugly in my hand."&lt;/p&gt;
    &lt;head rend="h2"&gt;Roman gladiator tag&lt;/head&gt;
    &lt;p&gt;The small piece of carved thin bone bears an inscription. Experts would expect it to read if complete: "DOMINE VICTOR VINCAS FELIX" or "Lord Victor, may you win and be lucky."&lt;/p&gt;
    &lt;p&gt;Discovered in Northamptonshire, Machin says it could have belonged to an active or former Roman gladiator, or even be a spectator's souvenir, even though there is no evidence of an arena or circus space in that part of the country.&lt;/p&gt;
    &lt;p&gt;It was recovered from a large pottery vessel containing cremated human remains, with an X on the lid.&lt;/p&gt;
    &lt;p&gt;Dr John Pearce Reader in Archaeology at Kings College University said that a link to a gladiator was possible, but added that "with more forensic analysis of the burial, a different story may come to light".&lt;/p&gt;
    &lt;head rend="h2"&gt;Anglo-Saxon spindle whorl&lt;/head&gt;
    &lt;p&gt;Thought to be made from a cattle femur, this decorated Anglo-Saxon spindle whorl, used to provide weight while spinning yarn, was unearthed from farmland near Bishopstone, Buckinghamshire.&lt;/p&gt;
    &lt;p&gt;"It's a very interesting piece of evidence of textile advancements in the Anglo-Saxon period," said Willow Major, a post-excavation assistant.&lt;/p&gt;
    &lt;p&gt;Its polished surface leads her to believe it got a lot of use and was very dear to someone, she said, adding that interestingly, the ring and dot motif had been found on spinning tools from the much earlier Iron age.&lt;/p&gt;
    &lt;head rend="h2"&gt;Medieval die&lt;/head&gt;
    &lt;p&gt;A tiny polished die recovered from a deserted medieval village in Lower Radbourne, Warwickshire, resembles modern ones, but with a different numbering format.&lt;/p&gt;
    &lt;p&gt;Its imperfections, with one side longer than the others, stand it in contrast with today's mass-produced dice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pug found in a grave&lt;/head&gt;
    &lt;p&gt;This complete figurine of a seated pug dog in plain white-glazed porcelain with black details was found in the grave of an unnamed female at St James' Gardens in Euston.&lt;/p&gt;
    &lt;p&gt;It is thought to have been made in the Derby porcelain factory around 1770-1800.&lt;/p&gt;
    &lt;head rend="h2"&gt;19th Century gold dentures&lt;/head&gt;
    &lt;p&gt;"Every box has a surprise," Machin said as she unwrapped perhaps the most bizarre item here, thought to be from the 19th Century: a set of lower gold dentures found at St Mary's Old Church in Stoke Mandeville.&lt;/p&gt;
    &lt;p&gt;It contains six teeth and has a number stamped on the inside.&lt;/p&gt;
    &lt;p&gt;"These are objects, but they all relate to people," Machin said. "It's all about the people who lived in these areas going back thousands of years and we can start writing the stories about their lives and what they can tell us."&lt;/p&gt;
    &lt;head rend="h2"&gt;'Extraordinary' scale&lt;/head&gt;
    &lt;p&gt;"The scale is what makes it so extraordinary," Neil Redfern from the Council for British Archaeology says comparing HS2 to other big development projects.&lt;/p&gt;
    &lt;p&gt;"But it is the length of the scheme and the landscapes and places that HS2 passed through that make the collection of sites and material so interesting. The research potential from this material is remarkable."&lt;/p&gt;
    &lt;p&gt;He believes that the finds could help people understand wider landscape change now and in the past.&lt;/p&gt;
    &lt;p&gt;To dig deeper into these stories, archaeologists are now entering the second phase of works, including further condition, cleaning and conservation checks.&lt;/p&gt;
    &lt;p&gt;More plans are afoot to show the objects. Artefacts from the Wendover Saxon cemetery, where 122 graves were unearthed, will soon go on display for the first time at a Discover Bucks Museum exhibition.&lt;/p&gt;
    &lt;p&gt;However, the future of other items is less clear.&lt;/p&gt;
    &lt;p&gt;A spokesperson for HS2 explained that under English property law, archaeological and historical objects found during the works will either belong to the government or landowners.&lt;/p&gt;
    &lt;p&gt;"Occasionally landowners may wish to retain title to objects, in which case they will be returned to their care," said the spokesperson.&lt;/p&gt;
    &lt;p&gt;Charlotte Self, archive manager for the project said she and her team were asking landowners to donate them where possible, so people around the route could enjoy them.&lt;/p&gt;
    &lt;p&gt;"I would love to see the majority of these items deposited with the local museums from near where they were found," she said.&lt;/p&gt;
    &lt;p&gt;Get our flagship newsletter with all the headlines you need to start the day. Sign up here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46849926</guid><pubDate>Sun, 01 Feb 2026 22:14:39 +0000</pubDate></item><item><title>Show HN: NanoClaw ‚Äì ‚ÄúClawdbot‚Äù in 500 lines of TS with Apple container isolation</title><link>https://github.com/gavrielc/nanoclaw</link><description>&lt;doc fingerprint="1f0c5d761f974ce8"&gt;
  &lt;main&gt;
    &lt;p&gt;My personal Claude assistant that runs securely in containers. Lightweight and built to be understood and customized for your own needs.&lt;/p&gt;
    &lt;p&gt;OpenClaw is an impressive project with a great vision. But I can't sleep well running software I don't understand with access to my life. OpenClaw has 52+ modules, 8 config management files, 45+ dependencies, and abstractions for 15 channel providers. Security is application-level (allowlists, pairing codes) rather than OS isolation. Everything runs in one Node process with shared memory.&lt;/p&gt;
    &lt;p&gt;NanoClaw gives you the same core functionality in a codebase you can understand in 8 minutes. One process. A handful of files. Agents run in actual Linux containers with filesystem isolation, not behind permission checks.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/gavrielc/nanoclaw.git
cd nanoclaw
claude&lt;/code&gt;
    &lt;p&gt;Then run &lt;code&gt;/setup&lt;/code&gt;. Claude Code handles everything: dependencies, authentication, container setup, service configuration.&lt;/p&gt;
    &lt;p&gt;Small enough to understand. One process, a few source files. No microservices, no message queues, no abstraction layers. Have Claude Code walk you through it.&lt;/p&gt;
    &lt;p&gt;Secure by isolation. Agents run in Linux containers (Apple Container on macOS, or Docker). They can only see what's explicitly mounted. Bash access is safe because commands run inside the container, not on your host.&lt;/p&gt;
    &lt;p&gt;Built for one user. This isn't a framework. It's working software that fits my exact needs. You fork it and have Claude Code make it match your exact needs.&lt;/p&gt;
    &lt;p&gt;Customization = code changes. No configuration sprawl. Want different behavior? Modify the code. The codebase is small enough that this is safe.&lt;/p&gt;
    &lt;p&gt;AI-native. No installation wizard; Claude Code guides setup. No monitoring dashboard; ask Claude what's happening. No debugging tools; describe the problem, Claude fixes it.&lt;/p&gt;
    &lt;p&gt;Skills over features. Contributors shouldn't add features (e.g. support for Telegram) to the codebase. Instead, they contribute claude code skills like &lt;code&gt;/add-telegram&lt;/code&gt; that transform your fork. You end up with clean code that does exactly what you need.&lt;/p&gt;
    &lt;p&gt;Best harness, best model. This runs on Claude Agent SDK, which means you're running Claude Code directly. The harness matters. A bad harness makes even smart models seem dumb, a good harness gives them superpowers. Claude Code is (IMO) the best harness available.&lt;/p&gt;
    &lt;p&gt;No ToS gray areas. Because it uses Claude Agent SDK natively with no hacks or workarounds, using your subscription with your auth token is completely legitimate (I think). No risk of being shut down for terms of service violations (I am not a lawyer).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WhatsApp I/O - Message Claude from your phone&lt;/item&gt;
      &lt;item&gt;Isolated group context - Each group has its own &lt;code&gt;CLAUDE.md&lt;/code&gt;memory, isolated filesystem, and runs in its own container sandbox with only that filesystem mounted&lt;/item&gt;
      &lt;item&gt;Main channel - Your private channel (self-chat) for admin control; every other group is completely isolated&lt;/item&gt;
      &lt;item&gt;Scheduled tasks - Recurring jobs that run Claude and can message you back&lt;/item&gt;
      &lt;item&gt;Web access - Search and fetch content&lt;/item&gt;
      &lt;item&gt;Container isolation - Agents sandboxed in Apple Container (macOS) or Docker (macOS/Linux)&lt;/item&gt;
      &lt;item&gt;Optional integrations - Add Gmail (&lt;code&gt;/add-gmail&lt;/code&gt;) and more via skills&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Talk to your assistant with the trigger word (default: &lt;code&gt;@Andy&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;@Andy send an overview of the sales pipeline every weekday morning at 9am (has access to my Obsidian vault folder)
@Andy review the git history for the past week each Friday and update the README if there's drift
@Andy every Monday at 8am, compile news on AI developments from Hacker News and TechCrunch and message me a briefing
&lt;/code&gt;
    &lt;p&gt;From the main channel (your self-chat), you can manage groups and tasks:&lt;/p&gt;
    &lt;code&gt;@Andy list all scheduled tasks across groups
@Andy pause the Monday briefing task
@Andy join the Family Chat group
&lt;/code&gt;
    &lt;p&gt;There are no configuration files to learn. Just tell Claude Code what you want:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Change the trigger word to @Bob"&lt;/item&gt;
      &lt;item&gt;"Remember in the future to make responses shorter and more direct"&lt;/item&gt;
      &lt;item&gt;"Add a custom greeting when I say good morning"&lt;/item&gt;
      &lt;item&gt;"Store conversation summaries weekly"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Or run &lt;code&gt;/customize&lt;/code&gt; for guided changes.&lt;/p&gt;
    &lt;p&gt;The codebase is small enough that Claude can safely modify it.&lt;/p&gt;
    &lt;p&gt;Don't add features. Add skills.&lt;/p&gt;
    &lt;p&gt;If you want to add Telegram support, don't create a PR that adds Telegram alongside WhatsApp. Instead, contribute a skill file (&lt;code&gt;.claude/skills/add-telegram/SKILL.md&lt;/code&gt;) that teaches Claude Code how to transform a NanoClaw installation to use Telegram.&lt;/p&gt;
    &lt;p&gt;Users then run &lt;code&gt;/add-telegram&lt;/code&gt; on their fork and get clean code that does exactly what they need, not a bloated system trying to support every use case.&lt;/p&gt;
    &lt;p&gt;Skills we'd love to see:&lt;/p&gt;
    &lt;p&gt;Communication Channels&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/add-telegram&lt;/code&gt;- Add Telegram as channel. Should give the user option to replace WhatsApp or add as additional channel. Also should be possible to add it as a control channel (where it can trigger actions) or just a channel that can be used in actions triggered elsewhere&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/add-slack&lt;/code&gt;- Add Slack&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/add-discord&lt;/code&gt;- Add Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Platform Support&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/setup-windows&lt;/code&gt;- Windows via WSL2 + Docker&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Session Management&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/add-clear&lt;/code&gt;- Add a&lt;code&gt;/clear&lt;/code&gt;command that compacts the conversation (summarizes context while preserving critical information in the same session). Requires figuring out how to trigger compaction programmatically via the Claude Agent SDK.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS or Linux&lt;/item&gt;
      &lt;item&gt;Node.js 20+&lt;/item&gt;
      &lt;item&gt;Claude Code&lt;/item&gt;
      &lt;item&gt;Apple Container (macOS) or Docker (macOS/Linux)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;WhatsApp (baileys) --&amp;gt; SQLite --&amp;gt; Polling loop --&amp;gt; Container (Claude Agent SDK) --&amp;gt; Response
&lt;/code&gt;
    &lt;p&gt;Single Node.js process. Agents execute in isolated Linux containers with mounted directories. IPC via filesystem. No daemons, no queues, no complexity.&lt;/p&gt;
    &lt;p&gt;Key files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/index.ts&lt;/code&gt;- Main app: WhatsApp connection, routing, IPC&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/container-runner.ts&lt;/code&gt;- Spawns agent containers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/task-scheduler.ts&lt;/code&gt;- Runs scheduled tasks&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/db.ts&lt;/code&gt;- SQLite operations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;groups/*/CLAUDE.md&lt;/code&gt;- Per-group memory&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why WhatsApp and not Telegram/Signal/etc?&lt;/p&gt;
    &lt;p&gt;Because I use WhatsApp. Fork it and run a skill to change it. That's the whole point.&lt;/p&gt;
    &lt;p&gt;Why Apple Container instead of Docker?&lt;/p&gt;
    &lt;p&gt;On macOS, Apple Container is lightweight, fast, and optimized for Apple silicon. But Docker is also fully supported‚Äîduring &lt;code&gt;/setup&lt;/code&gt;, you can choose which runtime to use. On Linux, Docker is used automatically.&lt;/p&gt;
    &lt;p&gt;Can I run this on Linux?&lt;/p&gt;
    &lt;p&gt;Yes. Run &lt;code&gt;/setup&lt;/code&gt; and it will automatically configure Docker as the container runtime. Thanks to @dotsetgreg for contributing the &lt;code&gt;/convert-to-docker&lt;/code&gt; skill.&lt;/p&gt;
    &lt;p&gt;Is this secure?&lt;/p&gt;
    &lt;p&gt;Agents run in containers, not behind application-level permission checks. They can only access explicitly mounted directories. You should still review what you're running, but the codebase is small enough that you actually can. See docs/SECURITY.md for the full security model.&lt;/p&gt;
    &lt;p&gt;Why no configuration files?&lt;/p&gt;
    &lt;p&gt;We don't want configuration sprawl. Every user should customize it to so that the code matches exactly what they want rather than configuring a generic system. If you like having config files, tell Claude to add them.&lt;/p&gt;
    &lt;p&gt;How do I debug issues?&lt;/p&gt;
    &lt;p&gt;Ask Claude Code. "Why isn't the scheduler running?" "What's in the recent logs?" "Why did this message not get a response?" That's the AI-native approach.&lt;/p&gt;
    &lt;p&gt;Why isn't the setup working for me?&lt;/p&gt;
    &lt;p&gt;I don't know. Run &lt;code&gt;claude&lt;/code&gt;, then run &lt;code&gt;/debug&lt;/code&gt;. If claude finds an issue that is likely affecting other users, open a PR to modify the setup SKILL.md.&lt;/p&gt;
    &lt;p&gt;What changes will be accepted into the codebase?&lt;/p&gt;
    &lt;p&gt;Security fixes, bug fixes, and clear improvements to the base configuration. That's it.&lt;/p&gt;
    &lt;p&gt;Everything else (new capabilities, OS compatibility, hardware support, enhancements) should be contributed as skills.&lt;/p&gt;
    &lt;p&gt;This keeps the base system minimal and lets every user customize their installation without inheriting features they don't want.&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46850205</guid><pubDate>Sun, 01 Feb 2026 22:49:22 +0000</pubDate></item><item><title>Two kinds of AI users are emerging</title><link>https://martinalderson.com/posts/two-kinds-of-ai-users-are-emerging/</link><description>&lt;doc fingerprint="24210a181cb681fe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Two kinds of AI users are emerging. The gap between them is astonishing.&lt;/head&gt;
    &lt;p&gt;It still shocks me how much difference there is between AI users. I think it explains a lot about the often confusing (to me) coverage in the media about AI and its productivity impact.&lt;/p&gt;
    &lt;p&gt;I think it's clear there are two types of users to me now, and by extension, the organisations they work for.&lt;/p&gt;
    &lt;p&gt;First, you have the "power users", who are all in on adopting new AI technology - Claude Code, MCPs, skills, etc. Surprisingly, these people are often not very technical. I've seen far more non-technical people than I'd expect using Claude Code in terminal, using it for dozens of non-SWE tasks. Finance roles seem to be getting enormous value out of it (unsurprisingly, as Excel on the finance side is remarkably limiting when you start getting used to the power of a full programming ecosystem like Python).&lt;/p&gt;
    &lt;p&gt;Secondly, you have the people who are generally only chatting to ChatGPT or similar. So many people I wouldn't expect are still in this camp.&lt;/p&gt;
    &lt;head rend="h2"&gt;M365 Copilot has a lot to answer for&lt;/head&gt;
    &lt;p&gt;One extremely jarring realisation was just how poor Microsoft Copilot is. It has enormous market share in enterprise as it is bundled in with various Office 365 subscriptions, yet feels like a poorly cloned version of the (already not great) ChatGPT interface. The "agent" feature is absolutely laughable compared to what a CLI coding agent (including Microsoft's own GitHub confusingly-named-Copilot CLI).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To really underline this, Microsoft itself is rolling out Claude Code to internal teams[1], despite (obviously) having access to Copilot at near zero cost, and significant ownership of OpenAI. I think this sums up quite how far behind they are&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The problem is that in enterprise Copilot is often the only allowed AI tool, so that's all you can use without either potentially losing your job or spending a lot of effort trying to procure and use another AI tool. It's slow, the code execution tool in it doesn't work properly and fails horribly with large(ish) files, seemingly due to very very aggressive memory and CPU limitations.&lt;/p&gt;
    &lt;p&gt;This is becoming an existential risk for many enterprises. Senior decision makers are no doubt using these tools with such poor results and are therefore writing off AI, and/or spending a fortune with various large consulting and management consultancy outfits to get not very far.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why enterprise is so at risk&lt;/head&gt;
    &lt;p&gt;Enterprise corporate IT policy results in a completely disastrous combination of limitations that basically ensure that people cannot successfully use more 'cutting edge' AI tooling.&lt;/p&gt;
    &lt;p&gt;Firstly, they tend to have extremely locked down environments, with no ability to run even a basic script interpreter locally (VBA if you are lucky, but even that may be limited by various Group Policies). Secondly, they're locked into legacy software with no real "internal facing" APIs on their core workflows, which means agents have nothing to connect to even if you could run them.&lt;/p&gt;
    &lt;p&gt;Finally, they tend to have extremely siloed engineering departments (which may be completely outsourced), so there's nobody internally who could build the infrastructure to run safely sandboxed agents even if they wanted to.&lt;/p&gt;
    &lt;p&gt;The security concerns are real. You definitely do not want people YOLOing coding agents over production databases with no control, and as I've covered, sandboxing agents is difficult[2].&lt;/p&gt;
    &lt;p&gt;However, this does cause a real problem in so much that you don't have an engineering team that can help build the infrastructure to run safely sandboxed agents against your datasets.&lt;/p&gt;
    &lt;head rend="h2"&gt;The gap&lt;/head&gt;
    &lt;p&gt;I've also spoken to many smaller companies that don't have all this baggage and are absolutely flying with AI. The gap is so obvious when you can see both sides of it.&lt;/p&gt;
    &lt;p&gt;On one hand, you have Microsoft's (awful) Copilot integration for Excel (in fairness, the Gemini integration in Google Sheets is also bad). So you can imagine financial directors trying to use it and it making a complete mess of the most simple tasks and never touching it again.&lt;/p&gt;
    &lt;p&gt;On the other you have a non-technical executive who's got his head round Claude Code and can run e.g. Python locally. I helped one recently almost one-shot[3] converting a 30 sheet mind numbingly complicated Excel financial model to Python with Claude Code.&lt;/p&gt;
    &lt;p&gt;Once the model is in Python, you effectively have a data science team in your pocket with Claude Code. You can easily run Monte Carlo simulations, pull external data sources as inputs, build web dashboards and have Claude Code work with you to really integrate weaknesses in your model (or business). It's a pretty magical experience watching someone realise they have so much power at their fingertips, without having to grind away for hours/days in Excel.&lt;/p&gt;
    &lt;p&gt;This effectively leads to a situation where smaller company employees are able to be so much more productive than the equivalent at an enterprise. It often used to be that people at small companies really envied the resources &amp;amp; teams that their larger competitors had access to - but increasingly I think the pendulum is swinging the other way.&lt;/p&gt;
    &lt;head rend="h2"&gt;The future&lt;/head&gt;
    &lt;p&gt;I'm starting to get a feel for what the future of work looks like. The first observation is that (often) the real leaps are being made organically by employees, not from a top down AI strategy. Where I see the real productivity gains are small teams deciding to try and build an AI assisted workflow for a process, and as they are the ones that know that process inside out they can get very good results - unlike an often outsourced software engineering team who have absolutely zero experience doing the process that they are helping automate. I think this is the opposite of what most 'digital transformation' projects looked like in enterprise.&lt;/p&gt;
    &lt;p&gt;Secondly, companies that have some sort of APIs for internal systems are going to be able to do far more than those that don't. This might be as simple as a readonly data warehouse employees can connect to and run queries on behalf of users, or it could be as far as many complex core business processes being completely APId.&lt;/p&gt;
    &lt;p&gt;Thirdly, this all needs to be wrapped up in some sort of secure mechanism, but I actually think a hosted VM running some sort of code agent with well thought through network restrictions would work well, at least for read only reporting. For creating and editing data I don't think we quite have the model for non technical users (especially) to be able to use agents safely (yet).&lt;/p&gt;
    &lt;p&gt;Finally, legacy enterprise SaaS players either have enormous lock in, or are extremely vulnerable depending on how you look at it. Most are not "API-first" products, and the APIs they have tend to be really for developer usage - not optimised for thousands of employees to ping in weird and wonderful inefficient ways. But if they are the source of truth for the company, they are going to be very difficult to migrate away from and bottleneck a lot of productivity gains.&lt;/p&gt;
    &lt;p&gt;Again, smaller companies tend to use newer products which have far better thought through APIs (simply because they weren't often originally created many decades ago with various interfaces grafted on over time).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The user prompts, the agent synthesises - connecting to APIs and producing outputs on demand.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;What I've come to realise is that the power of having a bash sandbox with a programming language and API access to systems, combined with an agentic harness, results in outrageously good results for non technical users. It can effectively replace nearly every standard productivity app out there - both classic Microsoft Office style ones - and also web apps. It can build any report you ask for - and export it however you like. To me this seems like the future of knowledge work.&lt;/p&gt;
    &lt;p&gt;The bifurcation is real and seems to be, if anything, speeding up dramatically. I don't think there's ever been a time in history where a tiny team can outcompete a company one thousand times its size so easily.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Microsoft is using Claude Code internally while selling you Copilot ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Let's keep in mind that users already have access to these systems. CISOs need to figure out how to enable these kind of secure VMs en masse. There's already precedent for this with Codespaces - it just requires a similar approach scaled up to the entire organisation. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Two or three prompts got it there, using plan mode to figure out the structure of the Excel sheet, then prompting to implement it. It even added unit tests to the Python model itself, which I was impressed with! ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46850588</guid><pubDate>Sun, 01 Feb 2026 23:45:18 +0000</pubDate></item><item><title>Time Machine-style Backups with rsync (2018)</title><link>https://samuelhewitt.com/blog/2018-06-05-time-machine-style-backups-with-rsync</link><description>&lt;doc fingerprint="be0e885544af93ba"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Data Hoarding 101&lt;/head&gt;
    &lt;p&gt;I have digital backups of data, especially of my photos, going back almost a decade (I√¢m not that old) but it√¢s only recently that I got into creating time-snapshots of my backups, after I mistakenly deleted a bunch of (non-crucial) personal files with a stray &lt;code&gt;rsync --delete&lt;/code&gt; on a directory I had not backed-up.&lt;/p&gt;
    &lt;p&gt;My home server used be compatible with macOS√¢s Time Machine and when I kept most things on my Mac that was useful, but I changed my data hoarding habits and that solution started to not be the optimal one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Time Based Snapshots Using rsync&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;rsync&lt;/code&gt; has got to be one of my favourite and most used utilities. I use it constantly to transfer files between machine on my local network (and remote ones) but I√¢ve discovered it√¢s very useful as a backup tool. The following is a short script that uses &lt;code&gt;rsync&lt;/code&gt; to create snapshots of the my data directory to another directory (they are mount points on two different drives):&lt;/p&gt;
    &lt;code&gt;#!/bin/sh

TIMESTAMP=`date "+%Y-%m-%dT%H-%M-%S"`
USER=user
SOURCEDIR=/var/data/backups
TARGETDIR=/var/redundancy

# Create new backup using rsync and output to log
rsync -avPh --delete --link-dest=$TARGETDIR/current $SOURCEDIR/$USER/ $TARGETDIR/$USER-$TIMESTAMP &amp;gt; /var/log/rsync/$TIMESTAMP.log 2&amp;gt;&amp;amp;1

# check exit status to see if backup failed
if [ "$?" = 0 ]; then
    # Remove link to current backup
    rm -f $TARGETDIR/current
    # Create link to the newest backup
    ln -s $TARGETDIR/$USER-$TIMESTAMP $TARGETDIR/current
else
    # Rename directory if failed
    mv $TARGETDIR/$USER-$TIMESTAMP $TARGETDIR/failed-$USER-$TIMESTAMP
fi
&lt;/code&gt;
    &lt;p&gt;Essentially this script creates incremental copies of backups for a given user on the system by comparing any changes to that user√¢s data directory (&lt;code&gt;$SOURCEDIR&lt;/code&gt;) with the current backup (&lt;code&gt;$TARGETDIR&lt;/code&gt;) and making a new snapshot of any changes with the date.&lt;/p&gt;
    &lt;p&gt;Now all that remains is to save this script somewhere and create a &lt;code&gt;cron&lt;/code&gt; job to run it on an automatic interval:&lt;/p&gt;
    &lt;code&gt;# daily at 5am
0 5 * * * bash /usr/local/bin/rsync-time-machine
&lt;/code&gt;
    &lt;head rend="h3"&gt;Hard Links&lt;/head&gt;
    &lt;p&gt;This method uses rsync√¢s &lt;code&gt;--link-dest&lt;/code&gt; option to create hard-links so that isn√¢t duplicative of file data (the contents are only stored once, so you don√¢t use twice as much) and you can delete snapshots at will. (The links do still take up some space but it√¢s relatively insignificant.)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Be careful when deleting old snapshots. A new full backup of should be made before further incremental ones. I have to give a shoutout to Mike Rubel whose post was helpful in coming up with this solution.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46850709</guid><pubDate>Mon, 02 Feb 2026 00:00:07 +0000</pubDate></item><item><title>Show HN: Wikipedia as a doomscrollable social media feed</title><link>https://xikipedia.org</link><description>&lt;doc fingerprint="d4d05bb2748febb3"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;Xikipedia is a pseudo social media feed that algorithmically shows you content from Simple Wikipedia. It is made as a demonstration of how even a basic non-ML algorithm with no data from other users can quickly learn what you engage with to suggest you more similar content. No data is collected or shared here, the algorithm runs locally and the data disappears once you refresh or close the tab.&lt;/p&gt;
    &lt;p&gt;Source code on GitHub, discuss on fedi, bluesky, or twitter.&lt;/p&gt;
    &lt;p&gt;Pick some categories to get started (optional)&lt;/p&gt;
    &lt;p&gt;Or add your own&lt;/p&gt;
    &lt;p&gt;Since the content and images shown is from random Wikipedia articles, you will likely see NSFW content. Please only continue if you're an adult.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46850803</guid><pubDate>Mon, 02 Feb 2026 00:12:19 +0000</pubDate></item><item><title>Actors: A Model of Concurrent Computation [pdf] (1985)</title><link>https://apps.dtic.mil/sti/tr/pdf/ADA157917.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46851192</guid><pubDate>Mon, 02 Feb 2026 01:11:15 +0000</pubDate></item><item><title>Apple's MacBook Pro DFU port documentation is wrong</title><link>https://lapcatsoftware.com/articles/2026/2/1.html</link><description>&lt;doc fingerprint="362448954b27b1fd"&gt;
  &lt;main&gt;
    &lt;p&gt;According to the Apple support document How to identify the DFU port on Mac, the DFU (device firmware update) port location for MacBook Pro models with Apple silicon is as follows:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;14-inch MacBook Pro with M4 or M5 chip: The rightmost USB-C port when you√¢re facing the left side of the Mac&lt;/p&gt;
      &lt;p&gt;All other models: The leftmost USB-C port when you√¢re facing the left side of the Mac&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is wrong, a discovery that took me about a half dozen attempts to update macOS on an external disk. I have a 16-inch MacBook Pro with an M4 chip, specifically an M4 Pro chip, and the DFU port seems to be the USB-C port on the right side of the Mac, not on the left side.&lt;/p&gt;
    &lt;p&gt;For some damn reason, it matters which port your external disk is plugged into when you install or update macOS, as described by the Apple support document How to use an external storage device as a Mac startup disk:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Make sure that your storage device is plugged into the appropriate port on your Mac.&lt;/p&gt;
      &lt;p&gt;If you're using a Mac with Apple silicon, plug your storage device into any compatible port except the DFU port. Learn how to identify the DFU port. After macOS installation is complete, you can connect your storage device to any compatible port, including the DFU port.&lt;/p&gt;
      &lt;p&gt;If you√¢re using any other Mac, plug your storage device into any compatible port.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Mac disk management was so much easier in the days of Intel and PowerPC!&lt;/p&gt;
    &lt;p&gt;On an external SSD I had installed a macOS Sequoia boot volume (among others), which I√¢ve used to take Mac App Store screenshots for my apps and which I√¢d now like to use to take a screen recording. The installed version was still macOS 15.2, because I don√¢t often boot into the disk to take new screenshots, and going through the software update process would occupy my MacBook Pro for annoyingly long. However, it appears that Safari 26 requires a version of macOS 15 higher than .2, so I needed to update macOS in order to update Safari from version 18.&lt;/p&gt;
    &lt;p&gt;Over the past few days, every attempt I made to update the disk volume to macOS 15.7.3 failed inexplicably. I tried both Software Update in System Settings and the &lt;code&gt;softwareupdate&lt;/code&gt; command-line tool in Terminal. They went through all the motions, downloading the entire update, rebooting, etc., but afterwards I always ended up right where I started, at macOS 15.2. The &lt;code&gt;softwareupdate&lt;/code&gt; tool gave no error message. I did eventually see the following (truncated) notification:&lt;/p&gt;
    &lt;p&gt;Nonetheless, the so-called √¢Details√¢ button presented no actual details, simply opening Software Update again in System Settings. At no point did it ever say, hey, plug your disk into a different port!&lt;/p&gt;
    &lt;p&gt;While searching for a solution to my problem, I found an article by Michael Tsai, Failed Software Update on the External Drive of an Apple Silicon Mac. It described something that I also saw in my testing:&lt;/p&gt;
    &lt;quote&gt;I happened to boot into macOS Recovery and look in the Startup Security Utility, and I saw that it did not have access to change the security policy for the external drive. In order to do that, it said I had to set the drive as the startup disk. This kind of didn√¢t make sense because don√¢t the security options get set when booted from Recovery?&lt;/quote&gt;
    &lt;p&gt;I followed Tsai√¢s instructions, which did allow me to change the security policy for the external drive.&lt;/p&gt;
    &lt;quote&gt;I don√¢t know why software update couldn√¢t tell me this or why there is seemingly no direct GUI command to view or edit the authorized users. But restarting from within Startup Disk is apparently the way to get macOS to offer to fix the LocalPolicy. Once I added the user, I was able to do a normal boot from the external drive and software update normally.&lt;/quote&gt;
    &lt;p&gt;I also thought this would solve my macOS update problem, but it didn√¢t. In retrospect, though, perhaps I needed both solutions, to fix the LocalPolicy and to change the ports.&lt;/p&gt;
    &lt;p&gt;I was about to surrender to despair when I discovered a second article by Michael Tsai, Failing to Finish Updating macOS on an External Disk, published soon after the first article:&lt;/p&gt;
    &lt;quote&gt;With the final release of macOS 15.5, the problem got worse, and the Startup Disk workaround no longer helps.&lt;/quote&gt;
    &lt;p&gt;Tsai ultimately hits on the solution:&lt;/p&gt;
    &lt;quote&gt;The problem ended up being that I had plugged the external drive into the wrong USB-C port (the DFU port).&lt;/quote&gt;
    &lt;p&gt;Sure enough, after plugging my disk into a port on the left side of my MacBook Pro, software update succeeded on the first attempt. Every previous, failed attempt used the port on the right side, which was physically more convenient on the desk. So after all that, the external disk is finally updated to macOS 15.7.3 now.&lt;/p&gt;
    &lt;p&gt;Tsai offers the same complaint about this absurd situation:&lt;/p&gt;
    &lt;quote&gt;I don√¢t know why macOS can√¢t just report an error when you use the wrong port instead of proceeding to install for an hour and then not report an error but not work, either.&lt;/quote&gt;
    &lt;p&gt;By the way, Software Update in System Settings allowed my Mac to go to sleep during the √¢Preparing√¢ phase, despite the fact that the battery was charged to 99%, so when I returned home from a workout I unhappily found 30 minutes remaining. Sigh. Whatever happened to √¢it just works√¢?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46852096</guid><pubDate>Mon, 02 Feb 2026 03:29:55 +0000</pubDate></item><item><title>Leaked Chats Expose the Daily Life of a Scam Compound's Enslaved Workforce</title><link>https://www.wired.com/story/the-red-bull-leaks/</link><description>&lt;doc fingerprint="7e05985b3d2382ed"&gt;
  &lt;main&gt;
    &lt;p&gt;Just before 8am one day last April, an office manager who went by the name Amani sent out a motivational message to his colleagues and subordinates. ‚ÄúEvery day brings a new opportunity‚Äîa chance to connect, to inspire, and to make a difference,‚Äù he wrote in his 500-word post to an office-wide WhatsApp group. ‚ÄúTalk to that next customer like you're bringing them something valuable‚Äîbecause you are.‚Äù&lt;/p&gt;
    &lt;p&gt;Amani wasn‚Äôt rallying a typical corporate sales team. He and his underlings worked inside a ‚Äúpig butchering‚Äù compound, a criminal operation built to carry out scams‚Äîpromising romance and riches from crypto investments‚Äîthat often defraud victims out of hundreds of thousands or even millions of dollars at a time.&lt;/p&gt;
    &lt;p&gt;The workers Amani was addressing were eight hours into their 15-hour night shift in a high-rise building in the Golden Triangle special economic zone in Northern Laos. Like their marks, most of them were victims, too: forced laborers trapped in the compound, held in debt bondage with no passports. They struggled to meet scam revenue quotas to avoid fines that deepened their debt. Anyone who broke rules or attempted to escape faced far worse consequences: beatings, torture, even death.&lt;/p&gt;
    &lt;p&gt;The bizarre reality of daily life in a Southeast Asian scam compound‚Äîthe tactics, the tone, the mix of cruelty and upbeat corporate prattle‚Äîis revealed at an unprecedented level of resolution in a leak of documents to WIRED from a whistleblower inside one such sprawling fraud operation. The facility, known as the Boshang compound, is one of dozens of scam operations across Southeast Asia that have enslaved hundreds of thousands of people. Often lured from the poorest regions of Asia and Africa with fake job offers, these conscripts have become engines of the most lucrative form of cybercrime in the world, coerced into stealing tens of billions of dollars.&lt;/p&gt;
    &lt;p&gt;Last June, one of those forced laborers, an Indian man named Mohammad Muzahir, contacted WIRED while he was still captive inside the scam compound that had trapped him. Over the following weeks, Muzahir, who initially identified himself only as ‚ÄúRed Bull,‚Äù shared with WIRED a trove of information about the scam operation. His leaks included internal documents, scam scripts, training guides, operational flowcharts, and photographs and videos from inside the compound.&lt;/p&gt;
    &lt;p&gt;Of all Muzahir‚Äôs leaks, the most revealing is a collection of screen recordings in which he scrolled through three months‚Äô worth of the compound‚Äôs internal WhatsApp group chats. Those videos, which WIRED converted into 4,200 pages of screenshots, capture hour-by-hour conversations between the compound‚Äôs workers and their bosses‚Äîand the nightmare workplace culture of a pig butchering organization.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs a slave colony that‚Äôs trying to pretend it‚Äôs a company,‚Äù says Erin West, a former Santa Clara County, California, prosecutor who leads an anti-scam organization called Operation Shamrock and who reviewed the chat logs obtained by WIRED. Another researcher who reviewed the leaked chat logs, Jacob Sims of Harvard University‚Äôs Asia Center, also remarked on their ‚ÄúOrwellian veneer of legitimacy.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs terrifying, because it‚Äôs manipulation and coercion,‚Äù says Sims, who studies Southeast Asian scam compounds. ‚ÄúCombining those two things together motivates people the most. And it‚Äôs one of the key reasons why these compounds are so profitable.‚Äù&lt;/p&gt;
    &lt;p&gt;In another chat message, sent within hours of Amani‚Äôs saccharine pep talk, a higher-level boss weighed in: ‚ÄúDon't resist the company's rules and regulations,‚Äù he wrote. ‚ÄúOtherwise you can't survive here.‚Äù The staffers responded with 26 emoji reactions, all thumbs-ups and salutes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fined Into Slavery&lt;/head&gt;
    &lt;p&gt;In total, according to WIRED‚Äôs analysis of the group chat, more than 30 of the compound‚Äôs workers successfully defrauded at least one victim in the 11 weeks of records available, totaling to around $2.2 million in stolen funds. Yet the bosses in the chat frequently voiced their disappointment in the group‚Äôs performance, berated the staff for lack of effort, and imposed fine after fine.&lt;/p&gt;
    &lt;p&gt;Rather than explicit imprisonment, the compound relied on a system of indentured servitude and debt to control its workers. As Muzahir described it, he was paid a base salary of 3,500 Chinese yuan a month (about $500), which in theory entailed 75 hours a week of night shifts including breaks to eat. Although his passport had been taken from him, he was told that if he could pay off his ‚Äúcontract‚Äù with a $5,400 payment, it would be returned to him and he would be allowed to leave.&lt;/p&gt;
    &lt;p&gt;In reality, the WhatsApp chats reveal how even that meager salary was almost entirely chipped away with fines. One message warns that anyone who fails to start a ‚Äúfirst chat‚Äù‚Äîan introductory conversation with a scam victim‚Äîon any given day will be fined 50 yuan, and the failure will be announced to the group. Filing a false progress report results in a fine of 1,000 yuan. Falling asleep in the office, or ‚Äúwatching unrelated video, chatting with friends, and any activity that is not related to the job‚Äù are each punishable with a 200 yuan fine, as is any ‚Äúdisturbance‚Äù in the dormitory, where workers sleep five or six to a room in bunk beds.&lt;/p&gt;
    &lt;p&gt;One message notes a fine of 500 yuan for a worker who slept late, and another fined 200 yuan for not being in the dorm at ‚Äúcheck-in time‚Äù following his shift. Resist a fine by not signing a form that admits to the misbehavior, and the fine is doubled.&lt;/p&gt;
    &lt;p&gt;Muzahir himself described being fined so much that he was virtually broke. The food in the office cafeteria was also frequently denied as a punishment, the messages showed, with workers‚Äô ID badges that granted access to the canteen sometimes being taken away for seven days for small infractions like tardiness. Even the freedom to bring in snacks and drinks‚Äîother than betel nuts, a stimulant‚Äîcould be rescinded if staff underperformed. Time off was also withheld, with staff sometimes forced to work seven nights a week, Muzahir says.&lt;/p&gt;
    &lt;p&gt;Yet those punishments could be avoided, the bosses frequently promised, if they successfully scammed someone‚Äîor ‚Äúopened a customer,‚Äù as the bosses euphemistically described scamming a new victim. (Scamming the same victim multiple times was called a ‚Äúrecharge.‚Äù) In theory, workers were entitled to a commission, over and above their salary, for any scams they pulled off. Muzahir says he successfully perpetrated two scams during his months in the compound‚Äîboth of which left him racked with regret, he says‚Äîand he was never paid after either of them.&lt;/p&gt;
    &lt;p&gt;Bosses nonetheless used workers‚Äô illusory hope of paying off their debt‚Äîor even going home rich‚Äîas a motivator. ‚ÄúI understand‚Äîwhen penalties or fines come your way, it's easy to feel disheartened. But I urge you not to see it as a punishment, but as a lesson and an investment in your own growth,‚Äù wrote Amani. ‚ÄúDon't fear the fine. Let it fuel your fire.‚Äù&lt;/p&gt;
    &lt;p&gt;The more senior boss, who went by the name Da Hai, spelled out the carrot-and-stick approach more clearly. ‚ÄúThe company's incentives are much higher than the fines, so as long as you work hard to open new customers you will receive a generous reward!‚Äù he wrote.&lt;/p&gt;
    &lt;p&gt;One of the bosses‚Äô tactics was to play teams off one another, reprimanding underperforming workers while pointing to the success of other scammers in the compound. Each room of the office appears to have had a Chinese ceremonial drum, played when a worker successfully scammed a victim for a six-figure sum. ‚ÄúDo you know why the next office is beating drums?‚Äù wrote a higher-level boss called Alang.&lt;/p&gt;
    &lt;p&gt;A victim had paid ‚Äú480k,‚Äù a boss who goes by the name Libo answers.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt doesn't matter, because he belongs to others,‚Äù Alang responds. ‚ÄúThe important thing is, which one of you can play the drum?‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Under the Pretense, a Brutal Reality&lt;/head&gt;
    &lt;p&gt;Beyond these manipulative tactics, the messages occasionally offer glimpses of a far harsher reality‚Äîas does the personal experience and testimony of Muzahir himself. Muzahir describes hearing stories of people who were tortured and says he was himself threatened by Amani with beating and electrocution if he didn‚Äôt find new ‚Äúclients.‚Äù Sometimes coworkers disappeared without explanation.&lt;/p&gt;
    &lt;p&gt;Eventually Muzahir came up with a plan to trick his captors into letting him leave. When the bosses caught on, he was held in a room, beaten, slapped and kicked, denied food and water, and made to drink a solution with a white powder dissolved in it, which seems to have been intended to make him more cooperative with their interrogation.&lt;/p&gt;
    &lt;p&gt;Occasional messages in the chat logs hint that these cruel punishments lurked underneath the compound‚Äôs motivational messages. At one point, the boss Alang mentions a girl who ‚Äúsneaked away from the company and went to work in a brothel,‚Äù and another person in the group mentions that the ‚Äúcompany‚Äù still holds her passport. Among the captive workers, Muzahir says, rumor had it that the girl was in fact sold into prostitution, a practice documented in other accounts from scam compound survivors.&lt;/p&gt;
    &lt;p&gt;At another point, while chastising the group for underperformance, the boss Da Hai hints at the large sum of money workers needed to produce if they ever hoped to leave the compound. ‚ÄúYou continue to violate the company's regulations,‚Äù he writes to the group. ‚ÄúIf you continue like this, please prepare your compensation and get out of here.‚Äù&lt;/p&gt;
    &lt;p&gt;Such references to paying ‚Äúcompensation‚Äù for release are in fact ‚Äúcoded words for ransom and debt bondage,‚Äù says Harvard‚Äôs Sims. The nation of Laos, Sims points out, is a signatory to the Palermo Protocol, which classifies anyone held in debt and forced to work without freedom of movement a victim of human trafficking. ‚ÄúThere is no gray area here.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;A Day in the Life of a Scammer&lt;/head&gt;
    &lt;p&gt;The leaked WhatsApp chats include a message from a boss who went by the name Terry laying out a strict work schedule for those under his supervision. ‚ÄúObey and respect the working time,‚Äù the message says. Each shift would start at around 11:30 pm Beijing time‚Äî10:30 pm in Laos‚Äîwith people told to arrive a few minutes early. Before the day ended at 2 pm Beijing time, there would be two break periods, one of which was set aside for meals. By 5 pm everyone was required to be back in their dormitories and ‚Äúsleep or keep silence, no disturbing the others.‚Äù If the rules weren‚Äôt followed, fines would be issued and ID badges could be taken away.&lt;/p&gt;
    &lt;p&gt;The reason for this nocturnal schedule was to sync with the waking hours of victims in the US‚Äîalmost entirely Indian-American men. (It‚Äôs a common practice to pair scammers with victims of their own ethnicity, to avoid language and culture barriers.)&lt;/p&gt;
    &lt;p&gt;In grim contrast to their actual lives, all staffers were required to post an imaginary daily schedule for their fake personas‚Äîthe wealthy, attractive women they‚Äôd pretend to be during scams. In hour-by-hour breakdowns, they describe mornings spent meditating, practicing yoga, taking walks, and ‚Äúsetting positive intentions‚Äù for the day. Other activities include a ‚Äúrelaxed‚Äù lunch with their team, dinner with loved ones, and time at the gym‚Äîwhen in reality they were spending entire nights in front of a screen in a fluorescent-lit office space.&lt;/p&gt;
    &lt;p&gt;Many of the staffers writing the schedules were nonetheless admonished for not sticking to the script while scamming. ‚ÄúThe purpose of editing a daily plan is to let everyone know clearly what you are going to share with your clients today when you start working,‚Äù one boss complained. ‚ÄúI find that many people just do it to get the job done and don't apply your plan to your clients.‚Äù&lt;/p&gt;
    &lt;p&gt;During each day‚Äôs work, the forced scammers were also required‚Äîunder the threat of more fines‚Äîto report their scamming efforts back to the bosses in detail. The WhatsApp logs are filled with lengthy messages from every team member that offer those reports in identical message templates, listing their ‚Äúteam,‚Äù their name, and their recent online activity with the fake profiles. They would report how many active social media accounts they were operating, if any of their accounts were suspended, how many chats they‚Äôd started, how many were ongoing, any successful scams, and their target for the month. The internal chats also show scammers sharing with bosses and colleagues screenshots of their victim chats on Facebook Messenger, Instagram, Snapchat, and other chat apps, while asking questions about potential victims.&lt;/p&gt;
    &lt;p&gt;Bosses frequently gave pointed feedback about how workers were managing the meta-narrative of their scams. ‚ÄúWhen sharing travel topics, you need to know how to share details,‚Äù one chat says. Another message from a boss admonishes workers not to mention the car their persona drives if they can‚Äôt provide a convincing photo of it.&lt;/p&gt;
    &lt;p&gt;Managers would keep a close eye on the activity. On multiple occasions, bosses ask the forced workers to connect their WhatsApp accounts to the managers‚Äô computers so they could monitor the conversations themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;Anatomy of a Scam&lt;/head&gt;
    &lt;p&gt;The 25 scripts and guides Muzahir shared with WIRED, too, offer a window into the tactics and training of the compound‚Äôs workers. Many of the guidance documents pertain to the nitty gritty of carrying out cryptocurrency investment scams, including how to build a friendship that can segue into an investment proposition, how to explain what cryptocurrency is, and what to do once a target agrees to make an investment.&lt;/p&gt;
    &lt;p&gt;One document lists ‚Äú100 chat topics,‚Äù geared toward building the emotional intimacy required for a romance scam (‚ÄúWhat was your dream when you were little?‚Äù ‚ÄúWhat was the last time I cried for?‚Äù). Another suggests providing an update about having gotten into a car accident. ‚ÄúOn my way to work in the morning, my car was hit by a car following at a traffic light, which almost delayed my meeting in the morning. Thank you for your concern. I am fine.‚Äù&lt;/p&gt;
    &lt;p&gt;Multiple documents guide scammers to pretend they are currently making an investment, then introduce the idea that banks are resistant to letting their customers convert their money into cryptocurrency. ‚ÄúIf we transfer or withdraw funds, they will have one less customer,‚Äù one proposed scam script says. ‚ÄúIf everyone does this, then the bank will be in crisis and there will be a situation of capital rupture. I can understand their motives, but as a bank customer, I should not be hindered from transferring assets reasonably and legally. This is what makes me angry.‚Äù&lt;/p&gt;
    &lt;p&gt;The documents also display a technique that researchers say is often used in Southeast Asian investment and romance scams: Attackers intentionally mention the concept of scams‚Äîeven directly talking about the threat of investment scams‚Äîas a way of inoculating themselves against suspicion. The idea is that if a person is willing to talk openly about scams and isn‚Äôt avoiding the subject or acting strange about it, then they couldn‚Äôt be a scammer themself.&lt;/p&gt;
    &lt;p&gt;That strategy goes so far as to include mentally preparing a victim for the anti-fraud warnings from their bank or even law enforcement that they may have to ignore in order to transfer large amounts of fiat currency into cryptocurrency. ‚ÄúI was going to transfer funds to my coinbase today, but I was deliberately delayed and obstructed by the bank staff,‚Äù one script reads, referring to the popular crypto wallet service Coinbase. ‚ÄúI also received an anti-fraud call from the FBI today, which wasted a lot of my time.‚Äù&lt;/p&gt;
    &lt;p&gt;The materials Muzahir provided from the Boshang compound also document the key role generative AI tools play in its deceptions. Muzahir described to WIRED how the compound workers are trained in using tools like ChatGPT and Deepseek to come up with responses in chats with victims and craft natural-sounding turns of phrase. But even more crucial was the compound‚Äôs use of deepfake AI software to allow scammers to convincingly video chat with victims at their request using an AI-generated face, impersonating an individual whose photos they‚Äôve stolen for a fake persona.&lt;/p&gt;
    &lt;p&gt;The internal chat logs Muzahir captured describe a dedicated ‚ÄúAI room‚Äù where a female model conducts face-swapped calls on request with an endless parade of victims. One WhatsApp message from a boss to the group chat notes that ‚ÄúSana (our model who helps us to call) is not available tonight. she is not feeling well. Therefore, don't promise your customers to call them. Maybe she will come at work in the morning. Plan your work accordin[g]ly.‚Äù&lt;/p&gt;
    &lt;p&gt;Other chats about the AI room relate to scheduling challenges given demand for face-swapped calls and the fact that a single model can only do one deepfake call at a time. One chat, for example, notes: ‚ÄúIf there is a ‚Äòbusy‚Äô sign on her door, change it to ‚Äòfree‚Äô when you come out, so as to avoid crowding and frequent door openings.‚Äù&lt;/p&gt;
    &lt;p&gt;The scripts Muzahir shared also include tips for delaying a video chat with a victim‚Äîperhaps until the scammer is prepared to use deepfake tools. ‚ÄúWhen we meet, it will not be awkward but rather we will look forward to it,‚Äù says one script about what to say when a victim asks to video chat. It continues, ‚ÄúWe are strengthening our relationship every day. You have also seen my photos. When we meet, can you recognize me?‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond the Golden Triangle&lt;/head&gt;
    &lt;p&gt;As dystopian as the Golden Triangle compound described in the leaked documents may be, its work environment appears to have been relatively lax compared to other compounds in countries like Cambodia or Myanmar. In those facilities, Operation Shamrock‚Äôs Erin West says, she has heard firsthand stories of workers being beaten simply for missing their quota of scams or being forced to work 18-hour shifts while standing, with none of the pretense of voluntary work in a corporate environment.&lt;/p&gt;
    &lt;p&gt;The relative leniency of Muzahir‚Äôs compound, says Harvard‚Äôs Sims, likely stems from scam operations‚Äô sense of total control in Laos‚Äô Golden Triangle region‚Äîa zone of the country controlled largely by Chinese business interests that has become a host to crimes ranging from narcotics and organ sales to illegal wildlife trafficking. Even human trafficking victims who escape from a compound there, Sims points out, can be tracked down relatively easily thanks to Chinese organized crime‚Äôs influence over local law enforcement. ‚ÄúThese guys don‚Äôt have to be held in a cell,‚Äù Sims says. ‚ÄúThe whole place is a closed circuit.‚Äù&lt;/p&gt;
    &lt;p&gt;Nonetheless, the Boshang compound that held Muzahir appears to have moved in November from the Golden Triangle to Cambodia, a country that‚Äôs become by some measures an even safer base for scammers to operate from. Based on messages from his former coworkers, Muzahir says he‚Äôs determined that the operation and its captive workers are now based in the town of Chrey Thom, what Sims and West both describe as a growing hot spot for scam operations.&lt;/p&gt;
    &lt;p&gt;The move may have been precipitated, Sims speculates, by police raids on compounds across the region around that time. Many of those raids appear to have been part of a ‚Äúperformative crackdown,‚Äù as Sims puts it. (One such raid in June targeted the building where Muzahir‚Äôs compound had previously been located, but Muzahir says the workers who were rounded up by police were quickly released again and returned to work.)&lt;/p&gt;
    &lt;p&gt;Nonetheless, the nuisance of even those superficial disruptions may have persuaded the operation‚Äôs bosses to relocate to Cambodia. In that country, even the family of the country‚Äôs prime minister, Hun Manet, has been linked to a corporate conglomerate that oversees a subsidiary with documented ties to the burgeoning scam industry. ‚ÄúIt‚Äôs been a very hospitable environment to do this work,‚Äù West says.&lt;/p&gt;
    &lt;p&gt;One of Muzahir‚Äôs old bosses also confirmed to him in a private text exchange that the compound is still ‚Äúrecruiting‚Äù new workers‚Äîvictims trapped in a system of modern slavery hidden under a thin facade of a willing workplace.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis is a place to work, not to enjoy,‚Äù that same boss had written in the group chat during Muzahir‚Äôs time in the compound, in a rare moment when the mask of a normal office environment seemed to slip. ‚ÄúYou can only enjoy life when you leave here.‚Äù&lt;/p&gt;
    &lt;p&gt;Additional reporting by Sophia Takla, Maddy Varner, and Zeyi Yang.&lt;/p&gt;
    &lt;p&gt;Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46852660</guid><pubDate>Mon, 02 Feb 2026 05:10:59 +0000</pubDate></item><item><title>Library of Juggling</title><link>https://libraryofjuggling.com/</link><description>&lt;doc fingerprint="3736594b20b5a3ff"&gt;
  &lt;main&gt;
    &lt;p&gt;What is it?&lt;/p&gt;
    &lt;p&gt;The Library of Juggling is an attempt to list all of the popular (and perhaps not so popular) juggling tricks in one organized place. Despite the growing popularity of juggling, few websites are dedicated to collecting and archiving the various patterns that are being performed. Most jugglers are familiar with iconic tricks such as the Cascade and Shower, but what about Romeo's Revenge or the 531 Mills Mess? The goal of this website is to guarantee that the tricks currently circulating around the internet and at juggling conventions are found, animated, and catalogued for the world to see. It is a daunting task, but for the sake of jugglers everywhere it must be done.&lt;/p&gt;
    &lt;p&gt;What can I find here?&lt;/p&gt;
    &lt;p&gt;For every trick found in the Library, there will be an animated representation of the pattern created via JugglingLab, in addition to general information about the trick (siteswap, difficulty level, prerequisite tricks, etc.). If I am able to run the pattern, then I will provide a text-based tutorial for the trick with the help of animations. I will also include links to other tutorials for the trick that can be found online, ranging from YouTube videos to private sites like this one. If I am unable to provide my own tutorial, there will still be a short description of the trick in addition to outside tutorials and demonstrations.&lt;/p&gt;
    &lt;p&gt;Where do I start?&lt;/p&gt;
    &lt;p&gt;Well, if you have come to the Library looking to find out how to start juggling, than it would be best to begin with the Three Ball Cascade pattern. If you are a juggler who is already familiar with the basics, then the various tricks included in the Library can be accessed via the navigation tree on the left, or you can click here to view all of the tricks by difficulty.&lt;/p&gt;
    &lt;p&gt;Recent Additions (6/13/15):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Frostbite (submitted by Andrew Olson)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Library of Juggling is on an indefinite hiatus, which means no new tricks will be added. Existing content will continue to be hosted for the foreseeable future.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46853552</guid><pubDate>Mon, 02 Feb 2026 07:58:49 +0000</pubDate></item><item><title>EU launches government satcom program in sovereignty push</title><link>https://spacenews.com/eu-launches-government-satcom-program-in-sovereignty-push/</link><description>&lt;doc fingerprint="95231d6d282ee8d"&gt;
  &lt;main&gt;
    &lt;p&gt;BRUSSELS ‚Äî The European Union‚Äôs new government satellite communications program, GOVSATCOM, which pools capacity from eight already on-orbit geosynchronous satellites, began operations last week, European Commissioner for Defence and Space Andrius Kubilius said Jan. 27.&lt;/p&gt;
    &lt;p&gt;The program is designed to provide secure communications capabilities to the EU and its member states and could expand by 2027, Kubilius said.&lt;/p&gt;
    &lt;p&gt;‚ÄúLast week we started GOVSATCOM operations,‚Äù Kubilius said during his opening remarks at the European Space Conference. ‚ÄúThat means that all member states can now have access to sovereign satellite communications ‚Äî military and government, secure and resilient, built in Europe, operated in Europe, and under European control.‚Äù&lt;/p&gt;
    &lt;p&gt;Specifically, Kubilius was referring to the GOVSATCOM hub, a ‚Äúmarketplace‚Äù of governmental capacities from the five resource providers currently enrolled in the program. Juan Ramon Lopez Caravantes, head of communication at the European Union Agency for the Space Programme, said that with ‚Äùa few clicks member states can now introduce their service request. It‚Äôs an easy to use, smooth running secure platform‚Äù.&lt;/p&gt;
    &lt;p&gt;GOVSATCOM is conceived as a ‚Äúsystem of systems,‚Äù merging existing national and commercial satellite capacities into a common EU pool. The program is structured in multiple phases, and is pooling capacity from eight existing, already-in-orbit GEO satellites from five member states ‚Äî France, Spain, Italy, Greece and Luxembourg.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey currently offer 35 different service programs from a catalogue that is not public. It‚Äôs only for the member states, and it‚Äôs fully secured and encrypted‚Äù added Jeremie Godet, head of unit secure connectivity and space surveillance at European Commission‚Äôs Directorate General office for defence industry and space. ‚ÄúThe coverage is currently from the south of Greenland to South America on the west and up to India on the East.‚Äù&lt;/p&gt;
    &lt;p&gt;In 2027 this catalog will expand, Godet added, to fill gaps and to secure more commercial satcom solutions.&lt;/p&gt;
    &lt;p&gt;Beginning in 2029, GOVSATCOM is expected to integrate with the 290 satellites in the Infrastructure for Resilience, Interconnectivity and Security by Satellite constellation, known as IRIS¬≤, and be fully operational.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe goal‚Äù, Kubilius said during the conference ‚Äúis to have expanded commercial capabilities operational by 2027, including expanding coverage, and expanding bandwidth to cover the entire world,‚Äù and to support IRIS¬≤ by 2029.&lt;/p&gt;
    &lt;p&gt;Concerning IRIS2, the commissioner also said that IRIS¬≤ Ka-band military frequencies were brought into use last week. He expressed confidence that the first batch of satellites will be ready for deployment by 2029. ‚ÄúI have asked all partners to step up and speed up IRIS¬≤,‚Äúand I‚Äôm confident we can deploy its initial services by 2029,‚Äù he said.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe goal is connectivity and security for all of Europe ‚Äî guaranteed access for all member states and full European control.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46853888</guid><pubDate>Mon, 02 Feb 2026 08:59:40 +0000</pubDate></item><item><title>My (very) fast zero-allocation webserver using OxCaml</title><link>https://anil.recoil.org/notes/oxcaml-httpz</link><description>&lt;doc fingerprint="16bf138b60e4e358"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;My (very) fast zero-allocation webserver using OxCaml / Feb 2026 / DOI&lt;/head&gt;
    &lt;p&gt;Since helping with the &lt;/p&gt;
    &lt;p&gt;The reason for my eagerness is that OxCaml has a number of language extensions that give giant leaps in performance for systems-oriented programs, while retaining the familiar OCaml functional style of programming. And unlike Rust, there's a garbage collector available for 'normal' code. I am also deeply sick and tired of maintaining large Python scripts recently, and crave the modularity and type safety of OCaml.&lt;/p&gt;
    &lt;p&gt;The traditional way I learn a new technology is by replacing my &lt;/p&gt;
    &lt;p&gt;(Many thanks to &lt;/p&gt;
    &lt;head rend="h2"&gt;Why Zero Allocation for HTTP/1.1?&lt;/head&gt;
    &lt;p&gt;httpz is a high-performance HTTP/1.1 parser that aims to have no major heap allocation, and very minimal minor heap allocation, by using OxCaml's unboxed types and local allocations.&lt;/p&gt;
    &lt;p&gt;Why is this useful? It means that the entire lifetime of an HTTP connection can be handled in the callstack alone, so freeing up a connection is just a matter of returning from the function that handles it. In the steady state, a webserver would have almost no garbage collector activity. When combined with &lt;/p&gt;
    &lt;p&gt;I decided to specialise this library for HTTP/1.1 for now, and so settled on the input being a simple 32KB bytes value. This represents an HTTP request with the header portion (HTTP body handling is relatively straightforward for POST requests, and not covered in this post).&lt;/p&gt;
    &lt;p&gt;Given an input buffer like this, what can we do with OxCaml vs vanilla OCaml to make this go fast?&lt;/p&gt;
    &lt;head rend="h3"&gt;Unboxed Types and Records&lt;/head&gt;
    &lt;p&gt;The first port of call is to figure out the core types we're going to use for our parser. If you need to get familiar with OCaml's upstream memory representation then head over to Real World OCaml.&lt;/p&gt;
    &lt;p&gt;In my usual OCaml code, I use libraries like cstruct that I &lt;/p&gt;
    &lt;code&gt;type buffer = (char, Bigarray.int8_unsigned_elt, Bigarray.c_layout) Bigarray.Array1.t
type Cstruct.t = private {
  buffer: buffer;
  off   : int;
  len   : int;
}
&lt;/code&gt;
    &lt;p&gt;The idea is to use the record to get narrow views into a larger buffer, and that these small views can just live on the minor heap of the runtime which is fast to collect. OxCaml advances this by providing unboxed versions of small numbers that live in registers or on the stack, via a new syntax &lt;code&gt;int16#&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Instead of Bigarrays, we're now going to switch to use &lt;code&gt;bytes&lt;/code&gt; instead, but the
basic idea is the same.  Since httpz's buffer is a max of 32KB, 16-bit integers
also suffice for all positions and lengths!&lt;/p&gt;
    &lt;code&gt;type Httpz.t = #{ off : int16# ; len : int16# }
&lt;/code&gt;
    &lt;p&gt;There are actually two new features here: the first is that records can be unboxed with the &lt;code&gt;#{}&lt;/code&gt;
syntax, and the contents themselves are of a smaller width.  Let's have a closer look
at the difference between the Cstruct boxed version and this new OxCaml one:&lt;/p&gt;
    &lt;head rend="h4"&gt;Inspect unboxing in utop&lt;/head&gt;
    &lt;p&gt;My first port-of-call is usually to use utop interactively to poke around using the &lt;code&gt;Obj&lt;/code&gt; module.  This isn't quite so easy in OxCaml since the unboxed
records use a special layout:&lt;/p&gt;
    &lt;code&gt;# type t = #{ off : int16# ; len : int16# };;
type t = #{ off : int16#; len : int16#; }

# let x = #{ off=#1S; len=#2S };;
val x : t = #{off = &amp;lt;abstr&amp;gt;; len = &amp;lt;abstr&amp;gt;}

# Obj.repr x;;
Error: This expression has type t but an expression was expected of type
         ('a : value)
       The layout of t is bits16 &amp;amp; bits16
         because of the definition of t at line 1, characters 0-41.
       But the layout of t must be a sublayout of value.

&lt;/code&gt;
    &lt;p&gt;That failed, but it did reveal that we have this intriguing int16 pair layout instead of the normal OCaml flat value representation! Let's use the compiler to figure this out...&lt;/p&gt;
    &lt;head rend="h4"&gt;Inspect unboxing in lambda&lt;/head&gt;
    &lt;p&gt;I next built a small test program and inspected the lambda intermediate language from the compiler. To avoid dependencies, I just bound the raw compiler internals directly by checking out the oxcaml source code.&lt;/p&gt;
    &lt;code&gt;external add_int16 : int16# -&amp;gt; int16# -&amp;gt; int16# = "%int16#_add"
external int16_to_int : int16# -&amp;gt; int = "%int_of_int16#"

type span = #{ off : int16#; len : int16# }

let[@inline never] add_spans (x : span) (y : span) : span =
  #{ off = add_int16 x.#off y.#off; len = add_int16 x.#len y.#len }

let () =
  let x = Sys.opaque_identity #{ off = #1S; len = #2S } in
  let y = Sys.opaque_identity #{ off = #100S; len = #200S } in
  let z = add_spans x y in
  Printf.printf "off=%d len=%d\n" (int16_to_int z.#off) (int16_to_int z.#len)
&lt;/code&gt;
    &lt;p&gt;This introduces enough compiler optimisation barriers such that the addition is not optimised away at compile time. We can compile this with &lt;code&gt;ocaml -dlambda src.ml&lt;/code&gt; and see the intermediate form after type checking:&lt;/p&gt;
    &lt;code&gt;(let
  (add_spans/290 =
     (function {nlocal = 0} x/292[#(int16, int16)] y/293[#(int16, int16)]
       never_inline : #(int16, int16)
       (funct-body add_spans ./x.ml(6)&amp;lt;ghost&amp;gt;:196-294
         (before add_spans ./x.ml(7):229-294
           (make_unboxed_product #(int16, int16)
             (%int16#_add (unboxed_product_field 0 #(int16, int16) x/292)
               (unboxed_product_field 0 #(int16, int16) y/293))
             (%int16#_add (unboxed_product_field 1 #(int16, int16) x/292)
               (unboxed_product_field 1 #(int16, int16) y/293)))))))
&lt;/code&gt;
    &lt;p&gt;You can see the unboxing propagating nicely here through the intermediate code!&lt;/p&gt;
    &lt;head rend="h4"&gt;Inspect unboxing in native code&lt;/head&gt;
    &lt;p&gt;The next step is to verify what this looks like when compiled as optimised native code. I used &lt;code&gt;ocamlopt -O3 -S&lt;/code&gt; on my arm64 machine which emits the assembly code
after all the compiler passes, and found:&lt;/p&gt;
    &lt;code&gt;In the entry point:
  orr   x0, xzr, #1      ; x.#off = 1
  orr   x1, xzr, #2      ; x.#len = 2
  movz  x2, #100, lsl #0 ; y.#off = 100
  movz  x3, #200, lsl #0 ; y.#len = 200
  bl    _camlX__add_spans_0_1_code

_camlX__add_spans_0_1_code:
  add   x1, x1, x3       ; len: x.#len + y.#len
  sbfm  x1, x1, #0, #15  ; sign-extend to 16 bits (int16# semantics)
  add   x0, x0, x2       ; off: x.#off + y.#off
  sbfm  x0, x0, #0, #15  ; sign-extend to 16 bits
  ret

&lt;/code&gt;
    &lt;p&gt;We can see from the assembly that there's no boxing, and no heap allocations, and the sbfm instruction maintains the 16-bit semantics via sign extension.&lt;/p&gt;
    &lt;p&gt;Let's double check that the normal boxed OCaml does do more work and that isn't just the flambda2 compiler doing its magic. Here's a boxed version of the benchmark using plain OCaml:&lt;/p&gt;
    &lt;code&gt;type span = { off : int; len : int }

let[@inline never] add_spans (x : span) (y : span) : span =
  { off = x.off + y.off; len = x.len + y.len }

let () =
  let x = Sys.opaque_identity { off = 1; len = 2 } in
  let y = Sys.opaque_identity { off = 100; len = 200 } in
  let z = add_spans x y in
  Printf.printf "off=%d len=%d\n" z.off z.len
&lt;/code&gt;
    &lt;p&gt;Compiling this boxed version with &lt;code&gt;ocamlopt -O3 -S&lt;/code&gt; and looking at the assembly shows
much more minor heap activity:&lt;/p&gt;
    &lt;code&gt;_camlY__add_spans_0_1_code:
      sub   sp, sp, #16
      str   x30, [sp, #8]
      mov   x2, x0
      ldr   x16, [x28, #0]        ; load young_limit
      sub   x27, x27, #24         ; bump allocator: reserve 24 bytes (3 words)
      cmp   x27, x16              ; check if GC needed
      b.cc  L114                  ; branch to GC if out of space
  L113:
      add   x0, x27, #8           ; x0 = pointer to new block
      orr   x3, xzr, #2048        ; header word (tag 0, size 2)
      str   x3, [x0, #-8]         ; write header
      ldr   x3, [x1, #0]          ; load y.off from heap
      ldr   x4, [x2, #0]          ; load x.off from heap
      add   x3, x4, x3            ; add them
      sub   x3, x3, #1            ; adjust for tagged int
      str   x3, [x0, #0]          ; store result.off to heap
      ldr   x1, [x1, #8]          ; load y.len from heap
      ldr   x2, [x2, #8]          ; load x.len from heap
      add   x1, x2, x1            ; add them
      sub   x1, x1, #1            ; adjust for tagged int
      str   x1, [x0, #8]          ; store result.len to heap
      ...
      ret
  L114:
      bl    _caml_call_gc         ; GC call if needed
&lt;/code&gt;
    &lt;p&gt;The OCaml minor heap is really fast, but it's nowhere near as fast as just passing values around in registers and doing direct operations, which the unboxed version lets us do!&lt;/p&gt;
    &lt;p&gt;My benchmark above used direct external calls to compiler primitives, but OxCaml exposes normal modules for all these special types so we can just open them and gain access to the usual integer operations:&lt;/p&gt;
    &lt;code&gt;module I16 = Stdlib_stable.Int16_u

let[@inline always] i16 x = I16.of_int x
let[@inline always] to_int x = I16.to_int x

let pos : int16# = i16 0
let next : int16# = I16.add pos #1S
&lt;/code&gt;
    &lt;head rend="h3"&gt;Unboxed characters&lt;/head&gt;
    &lt;p&gt;There's more than just integer operations in OxCaml. Hot off the press in the past few weeks have been unboxed character operations as well, so we don't need to use an OCaml int (this is unboxed as well, but I presume the compiler can optimise and pack 8-bit operations much more effectively if it knows that we're operating on a char instead of a full word).&lt;/p&gt;
    &lt;p&gt;The httpz parser tries to use these, but the support for untagged ints isn't fully complete yet (thanks &lt;/p&gt;
    &lt;p&gt;HTTP date timestamps use unboxed floats as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Returning unboxed records and tuples&lt;/head&gt;
    &lt;p&gt;Once we've declared these unboxed records, they're fully nestable within other unboxed records. For example, HTTP requests with multiple fields remain unboxed:&lt;/p&gt;
    &lt;code&gt;type request =
  #{ meth : method_
   ; target : span           (* Nested unboxed record *)
   ; version : version
   ; body_off : int16#
   ; content_length : int64#
   ; is_chunked : bool
   ; keep_alive : bool
   ; expect_continue: bool
   }
&lt;/code&gt;
    &lt;p&gt;Functions can therefore naturally return multiple values without allocation by using unboxed tuples in the return value of a function:&lt;/p&gt;
    &lt;code&gt;let take_while predicate buf ~(pos : int16#) ~(len : int16#)
    : #(span * int16#) =
  let start = pos in
  let mutable p = pos in
  while (* ... *) do p &amp;lt;- I16.add p #1S done;
  #(#{ off = start; len = I16.sub p start }, p)

let #(result_span, new_pos) = take_while is_token buf ~pos ~len
&lt;/code&gt;
    &lt;p&gt;Vanilla OCaml did some unboxing of this use of tuples, but not with records (which would land up on the minor heap). With this OxCaml code, it's all just passed directly on the stack through function call traces.&lt;/p&gt;
    &lt;head rend="h3"&gt;Local allocations and exclaves&lt;/head&gt;
    &lt;p&gt;We can then also mark parameters to demand that they won't escape a function, enabling stack allocation more explicitly:&lt;/p&gt;
    &lt;code&gt;(* Buffer is borrowed, won't be stored anywhere *)
let[@inline] equal (local_ buf) (sp : span) (s : string) : bool =
  let sp_len = I16.to_int sp.#len in
  if sp_len &amp;lt;&amp;gt; String.length s then false
  else Bigstring.memcmp_string buf ~pos:(I16.to_int sp.#off) s = 0
&lt;/code&gt;
    &lt;p&gt;If a function needs to return a local value, then it uses a new &lt;code&gt;exclave_&lt;/code&gt; keyword. For example, in the HTTP request parsing we look up a stack allocated list of headers:&lt;/p&gt;
    &lt;code&gt;val find : t list @ local -&amp;gt; Name.t -&amp;gt; t option @ local

let rec find_string (buf : bytes) (headers : t list @ local) name = exclave_
  match headers with
  | [] -&amp;gt; None
  | hdr :: rest -&amp;gt;
    let matches =
      match hdr.name with
      | Name.Other -&amp;gt; Span.equal_caseless buf hdr.name_span name
      | known -&amp;gt;
        let canonical = Name.lowercase known in
        String.( = ) (String.lowercase name) canonical
    in
    if matches then Some hdr else find_string buf rest name
;;
&lt;/code&gt;
    &lt;p&gt;Notice that it's a recursive function as well, so this is a fairly natural way to write something that remains heap allocated. You can learn more about this from &lt;/p&gt;
    &lt;head rend="h2"&gt;Mutable Local Variables with "let mutable"&lt;/head&gt;
    &lt;p&gt;A nice quality of life improvement is that OxCaml allows stack-allocated mutable variables in loops, eliminating the need to allocate &lt;code&gt;ref&lt;/code&gt; values. This
allows parsing code to have local mutability:&lt;/p&gt;
    &lt;code&gt;let parse_int64 (local_ buf) (sp : span) : int64# =
  let mutable acc : int64# = #0L in
  let mutable i = 0 in
  let mutable valid = true in
  while valid &amp;amp;&amp;amp; i &amp;lt; I16.to_int sp.#len do
    let c = Bytes.get buf (I16.to_int sp.#off + i) in
    match c with
    | '0' .. '9' -&amp;gt;
      acc &amp;lt;- I64.add (I64.mul acc #10L) (I64.of_int (Char.code c - 48));
      i &amp;lt;- i + 1
    | _ -&amp;gt; valid &amp;lt;- false
  done;
  acc
&lt;/code&gt;
    &lt;p&gt;Whereas in conventional OCaml there might be a minor heap allocation for the reference:&lt;/p&gt;
    &lt;code&gt;let parse_int64 buf sp =
  let acc = ref 0L in           (* Heap-allocated ref *)
  let i = ref 0 in              (* Heap-allocated ref *)
  let valid = ref true in       (* Heap-allocated ref *)
  while !valid &amp;amp;&amp;amp; !i &amp;lt; sp.len do
    let c = Bytes.get buf (sp.off + !i) in
    match c with
    | '0' .. '9' -&amp;gt;
      acc := Int64.add (Int64.mul !acc 10L) (Int64.of_int (Char.code c - 48));
      i := !i + 1
    | _ -&amp;gt; valid := false
  done;
  !acc
&lt;/code&gt;
    &lt;head rend="h3"&gt;Putting the parser together&lt;/head&gt;
    &lt;p&gt;The toplevel Httpz.parse function has a pretty simple signature from a user's perspective:&lt;/p&gt;
    &lt;code&gt;val parse : bytes -&amp;gt; len:int16# -&amp;gt; limits:limits -&amp;gt;
  #(Buf_read.status * Req.t * Header.t list) @ local
&lt;/code&gt;
    &lt;p&gt;This function receives some a bytebuffer and resource limits and returns an unboxed local tuple of the connection status, parsed (unboxed) request and a stack-local list of header spans that represent the offsets within the input buffer of what was passed.&lt;/p&gt;
    &lt;p&gt;I should probably make the input buffer local too; one nice aspect of OxCaml is how easy it is to incrementally add type and kind annotations and lean on the compiler type inference to help guide where to fixup callsites.&lt;/p&gt;
    &lt;head rend="h3"&gt;Caveats and limitations&lt;/head&gt;
    &lt;p&gt;There are lots and lots of other new features in OxCaml which I've started integrating, but require careful planning of layouts. For example, I wanted to use or_null to have a non-allocating version of option, but you often end up with long compiler errors about value inference failures, so I ended up just allocating a local type instead. Something to investigate more in the future as I get familiar with OxCaml.&lt;/p&gt;
    &lt;p&gt;I also ran into issues using mutable fields in unboxed records and found this is documented:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We plan to allow mutating unboxed records within boxed records (the design will differ from boxed record mutability, as unboxed types don‚Äôt have the same notion of identity).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It's also difficult right now to strip away the OxCaml extensions and go back to normal OCaml syntax. &lt;code&gt;--erase-jane-syntax&lt;/code&gt;, but it requires some build system work to
integrate and seems to lag a little behind the new features (like unboxed small
literals). For now, I've decided to just focus on using OxCaml exclusively and
see how it goes for a while.&lt;/p&gt;
    &lt;p&gt;Finally, the tooling is still a fluid story. &lt;/p&gt;
    &lt;head rend="h3"&gt;Claude skills for OxCaml&lt;/head&gt;
    &lt;p&gt;While I built small scale examples to test out the architecture, I leaned heavily on Claude code to build out the majority of the parser so I could rapidly experiment. To do this, I synthesised a set of OxCaml specific Claude skills in my &lt;/p&gt;
    &lt;p&gt;I generated those skills via a combination of summarising the OxCaml source trees and cribbing from the &lt;/p&gt;
    &lt;head rend="h2"&gt;Performance Results&lt;/head&gt;
    &lt;p&gt;Ultimately, none of this matters if the runtime performance isn't there! Luckily, the HTTPz parser is incredible in a synthetic benchmark (just passing buffers around) as opposed to a network benchmark, using Core_bench to measure performance. What's impressive isn't the straightline throughput, but the massive drop in heap activity which greatly increased the predictability and tail latency of the service. And with all the extra typing information, I expect that straightline performance will only increase (and this is before I've looked at the SIMD support).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;httpz (OxCaml)&lt;/cell&gt;
        &lt;cell role="head"&gt;Traditional Parser&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Small request (35B)&lt;/cell&gt;
        &lt;cell&gt;154 ns&lt;/cell&gt;
        &lt;cell&gt;300+ ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Medium request (439B)&lt;/cell&gt;
        &lt;cell&gt;1,150 ns&lt;/cell&gt;
        &lt;cell&gt;2,000+ ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Heap allocations&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100-800 words&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Throughput&lt;/cell&gt;
        &lt;cell&gt;6.5M req/sec&lt;/cell&gt;
        &lt;cell&gt;3M req/sec&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Putting my new site live&lt;/head&gt;
    &lt;p&gt;I then glued this together using Eio into a full webserver. It works, and serves traffic just fine and in fact you are reading this web page via it right now!&lt;/p&gt;
    &lt;head rend="h3"&gt;What next: caml_alloc_local for C bindings&lt;/head&gt;
    &lt;p&gt;The current Eio/OxCaml does a data copy right now since Eio uses Bigarray, but I had a catchup coffee with &lt;/p&gt;
    &lt;p&gt;The key OxCaml feature to make this &lt;code&gt;io_uring&lt;/code&gt; integration awesome is a new FFI
function that allocates an OCaml value directly into the caller's OxCaml stack
rather than the heap. This means that we should be able to come up with a scheme
by which io_uring requests are routed directly to an OCaml continuation that's woken
up directly with a buffer available to it on the stack. True zero-copy to the kernel
awaits, which should also help speed up &lt;/p&gt;
    &lt;head rend="h3"&gt;Making it easier to develop in OxCaml in the open&lt;/head&gt;
    &lt;p&gt;Keen readers may note that my OxCaml repo links here go to a new monorepo I've setup for the purpose of hacking on real code in production outside of Jane Street's walls.&lt;/p&gt;
    &lt;p&gt;I'll blog more about this next week, but for now I hope you've enjoyed a little taste of what the OxCaml extensions offer in real world code. Stay tuned also for even more performance improvements, and for native TLS with an OxCaml port of ocaml-tls from &lt;/p&gt;
    &lt;head rend="h3"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Madhavapeddy et al (2025). Functional Networking for Millions of Docker Desktops. 10.1145/3747525&lt;/item&gt;
      &lt;item&gt;Madhavapeddy (2025). Holding an OxCaml tutorial at ICFP/SPLASH 2025. 10.59350/55bc5-x4p75&lt;/item&gt;
      &lt;item&gt;Sivaramakrishnan et al (2021). Retrofitting effect handlers onto OCaml. ACM. 10.1145/3453483.3454039&lt;/item&gt;
      &lt;item&gt;Madhavapeddy (2025). Arise Bushel, my sixth generation oxidised website. 10.59350/0r62w-c8g63&lt;/item&gt;
      &lt;item&gt;Madhavapeddy (2025). GeoTessera Python library released for geospatial embeddings. 10.59350/7hy6m-1rq76&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46854534</guid><pubDate>Mon, 02 Feb 2026 10:45:44 +0000</pubDate></item><item><title>Termux</title><link>https://github.com/termux/termux-app</link><description>&lt;doc fingerprint="bec6290bc4cf3eaa"&gt;
  &lt;main&gt;
    &lt;p&gt;Termux is an Android terminal application and Linux environment.&lt;/p&gt;
    &lt;p&gt;Note that this repository is for the app itself (the user interface and the terminal emulation). For the packages installable inside the app, see termux/termux-packages.&lt;/p&gt;
    &lt;p&gt;Quick how-to about Termux package management is available at Package Management. It also has info on how to fix &lt;code&gt;repository is under maintenance or down&lt;/code&gt; errors when running &lt;code&gt;apt&lt;/code&gt; or &lt;code&gt;pkg&lt;/code&gt; commands.&lt;/p&gt;
    &lt;p&gt;We are looking for Termux Android application maintainers.&lt;/p&gt;
    &lt;p&gt;NOTICE: Termux may be unstable on Android 12+. Android OS will kill any (phantom) processes greater than 32 (limit is for all apps combined) and also kill any processes using excessive CPU. You may get &lt;code&gt;[Process completed (signal 9) - press Enter]&lt;/code&gt; message in the terminal without actually exiting the shell process yourself. Check the related issue #2366, issue tracker, phantom cached and empty processes docs and this TLDR comment on how to disable trimming of phantom and excessive cpu usage processes. A proper docs page will be added later. An option to disable the killing should be available in Android 12L or 13, so upgrade at your own risk if you are on Android 11, specially if you are not rooted.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Termux App and Plugins&lt;/item&gt;
      &lt;item&gt;Installation&lt;/item&gt;
      &lt;item&gt;Uninstallation&lt;/item&gt;
      &lt;item&gt;Important Links&lt;/item&gt;
      &lt;item&gt;Debugging&lt;/item&gt;
      &lt;item&gt;For Maintainers and Contributors&lt;/item&gt;
      &lt;item&gt;Forking&lt;/item&gt;
      &lt;item&gt;Sponsors and Funders&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The core Termux app comes with the following optional plugin apps.&lt;/p&gt;
    &lt;p&gt;Latest version is &lt;code&gt;v0.118.3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;NOTICE: It is highly recommended that you update to &lt;code&gt;v0.118.0&lt;/code&gt; or higher ASAP for various bug fixes, including a critical world-readable vulnerability reported here. See below for information regarding Termux on Google Play.&lt;/p&gt;
    &lt;p&gt;Termux can be obtained through various sources listed below for only Android &lt;code&gt;&amp;gt;= 7&lt;/code&gt; with full support for apps and packages.&lt;/p&gt;
    &lt;p&gt;Support for both app and packages was dropped for Android &lt;code&gt;5&lt;/code&gt; and &lt;code&gt;6&lt;/code&gt; on 2020-01-01 at &lt;code&gt;v0.83&lt;/code&gt;, however it was re-added just for the app without any support for package updates on 2022-05-24 via the GitHub sources. Check here for the details.&lt;/p&gt;
    &lt;p&gt;The APK files of different sources are signed with different signature keys. The &lt;code&gt;Termux&lt;/code&gt; app and all its plugins use the same &lt;code&gt;sharedUserId&lt;/code&gt; &lt;code&gt;com.termux&lt;/code&gt; and so all their APKs installed on a device must have been signed with the same signature key to work together and so they must all be installed from the same source. Do not attempt to mix them together, i.e do not try to install an app or plugin from &lt;code&gt;F-Droid&lt;/code&gt; and another one from a different source like &lt;code&gt;GitHub&lt;/code&gt;. Android Package Manager will also normally not allow installation of APKs with different signatures and you will get errors on installation like &lt;code&gt;App not installed&lt;/code&gt;, &lt;code&gt;Failed to install due to an unknown error&lt;/code&gt;, &lt;code&gt;INSTALL_FAILED_UPDATE_INCOMPATIBLE&lt;/code&gt;, &lt;code&gt;INSTALL_FAILED_SHARED_USER_INCOMPATIBLE&lt;/code&gt;, &lt;code&gt;signatures do not match previously installed version&lt;/code&gt;, etc. This restriction can be bypassed with root or with custom roms.&lt;/p&gt;
    &lt;p&gt;If you wish to install from a different source, then you must uninstall any and all existing Termux or its plugin app APKs from your device first, then install all new APKs from the same new source. Check Uninstallation section for details. You may also want to consider Backing up Termux before the uninstallation so that you can restore it after re-installing from Termux different source.&lt;/p&gt;
    &lt;p&gt;In the following paragraphs, "bootstrap" refers to the minimal packages that are shipped with the &lt;code&gt;termux-app&lt;/code&gt; itself to start a working shell environment. Its zips are built and released here.&lt;/p&gt;
    &lt;p&gt;Termux application can be obtained from &lt;code&gt;F-Droid&lt;/code&gt; from here.&lt;/p&gt;
    &lt;p&gt;You do not need to download the &lt;code&gt;F-Droid&lt;/code&gt; app (via the &lt;code&gt;Download F-Droid&lt;/code&gt; link) to install Termux. You can download the Termux APK directly from the site by clicking the &lt;code&gt;Download APK&lt;/code&gt; link at the bottom of each version section.&lt;/p&gt;
    &lt;p&gt;It usually takes a few days (or even a week or more) for updates to be available on &lt;code&gt;F-Droid&lt;/code&gt; once an update has been released on &lt;code&gt;GitHub&lt;/code&gt;. The &lt;code&gt;F-Droid&lt;/code&gt; releases are built and published by &lt;code&gt;F-Droid&lt;/code&gt; once they detect a new &lt;code&gt;GitHub&lt;/code&gt; release. The Termux maintainers do not have any control over the building and publishing of the Termux apps on &lt;code&gt;F-Droid&lt;/code&gt;. Moreover, the Termux maintainers also do not have access to the APK signing keys of &lt;code&gt;F-Droid&lt;/code&gt; releases, so we cannot release an APK ourselves on &lt;code&gt;GitHub&lt;/code&gt; that would be compatible with &lt;code&gt;F-Droid&lt;/code&gt; releases.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;F-Droid&lt;/code&gt; app often may not notify you of updates and you will manually have to do a pull down swipe action in the &lt;code&gt;Updates&lt;/code&gt; tab of the app for it to check updates. Make sure battery optimizations are disabled for the app, check https://dontkillmyapp.com/ for details on how to do that.&lt;/p&gt;
    &lt;p&gt;Only a universal APK is released, which will work on all supported architectures. The APK and bootstrap installation size will be &lt;code&gt;~180MB&lt;/code&gt;. &lt;code&gt;F-Droid&lt;/code&gt; does not support architecture specific APKs.&lt;/p&gt;
    &lt;p&gt;Termux application can be obtained on &lt;code&gt;GitHub&lt;/code&gt; either from &lt;code&gt;GitHub Releases&lt;/code&gt; for version &lt;code&gt;&amp;gt;= 0.118.0&lt;/code&gt; or from &lt;code&gt;GitHub Build Action&lt;/code&gt; workflows. For android &lt;code&gt;&amp;gt;= 7&lt;/code&gt;, only install &lt;code&gt;apt-android-7&lt;/code&gt; variants. For android &lt;code&gt;5&lt;/code&gt; and &lt;code&gt;6&lt;/code&gt;, only install &lt;code&gt;apt-android-5&lt;/code&gt; variants.&lt;/p&gt;
    &lt;p&gt;The APKs for &lt;code&gt;GitHub Releases&lt;/code&gt; will be listed under &lt;code&gt;Assets&lt;/code&gt; drop-down of a release. These are automatically attached when a new version is released.&lt;/p&gt;
    &lt;p&gt;The APKs for &lt;code&gt;GitHub Build&lt;/code&gt; action workflows will be listed under &lt;code&gt;Artifacts&lt;/code&gt; section of a workflow run. These are created for each commit/push done to the repository and can be used by users who don't want to wait for releases and want to try out the latest features immediately or want to test their pull requests. Note that for action workflows, you need to be logged into a &lt;code&gt;GitHub&lt;/code&gt; account for the &lt;code&gt;Artifacts&lt;/code&gt; links to be enabled/clickable. If you are using the &lt;code&gt;GitHub&lt;/code&gt; app, then make sure to open workflow link in a browser like Chrome or Firefox that has your GitHub account logged in since the in-app browser may not be logged in.&lt;/p&gt;
    &lt;p&gt;The APKs for both of these are &lt;code&gt;debuggable&lt;/code&gt; and are compatible with each other but they are not compatible with other sources.&lt;/p&gt;
    &lt;p&gt;Both universal and architecture specific APKs are released. The APK and bootstrap installation size will be &lt;code&gt;~180MB&lt;/code&gt; if using universal and &lt;code&gt;~120MB&lt;/code&gt; if using architecture specific. Check here for details.&lt;/p&gt;
    &lt;p&gt;Security warning: APK files on GitHub are signed with a test key that has been shared with community. This IS NOT an official developer key and everyone can use it to generate releases for own testing. Be very careful when using Termux GitHub builds obtained elsewhere except https://github.com/termux/termux-app. Everyone is able to use it to forge a malicious Termux update installable over the GitHub build. Think twice about installing Termux builds distributed via Telegram or other social media. If your device get caught by malware, we will not be able to help you.&lt;/p&gt;
    &lt;p&gt;The test key shall not be used to impersonate @termux and can't be used for this anyway. This key is not trusted by us and it is quite easy to detect its use in user generated content.&lt;/p&gt;
    &lt;head&gt;Keystore information&lt;/head&gt;
    &lt;code&gt;Alias name: alias
Creation date: Oct 4, 2019
Entry type: PrivateKeyEntry
Certificate chain length: 1
Certificate[1]:
Owner: CN=APK Signer, OU=Earth, O=Earth
Issuer: CN=APK Signer, OU=Earth, O=Earth
Serial number: 29be297b
Valid from: Wed Sep 04 02:03:24 EEST 2019 until: Tue Oct 26 02:03:24 EEST 2049
Certificate fingerprints:
         SHA1: 51:79:55:EA:BF:69:FC:05:7C:41:C7:D3:79:DB:BC:EF:20:AD:85:F2
         SHA256: B6:DA:01:48:0E:EF:D5:FB:F2:CD:37:71:B8:D1:02:1E:C7:91:30:4B:DD:6C:4B:F4:1D:3F:AA:BA:D4:8E:E5:E1
Signature algorithm name: SHA1withRSA (disabled)
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3
&lt;/code&gt;
    &lt;p&gt;There is currently a build of Termux available on Google Play for Android 11+ devices, with extensive adjustments in order to pass policy requirements there. This is under development and has missing functionality and bugs (see here for status updates) compared to the stable F-Droid build, which is why most users who can should still use F-Droid or GitHub build as mentioned above.&lt;/p&gt;
    &lt;p&gt;Currently, Google Play will try to update installations away from F-Droid ones. Updating will still fail as sharedUserId has been removed. A planned 0.118.1 F-Droid release will fix this by setting a higher version code than used for the PlayStore app. Meanwhile, to prevent Google Play from attempting to download and then fail to install the Google Play releases over existing installations, you can open the Termux apps pages on Google Play and then click on the 3 dots options button in the top right and then disable the Enable auto update toggle. However, the Termux apps updates will still show in the PlayStore app updates list.&lt;/p&gt;
    &lt;p&gt;If you want to help out with testing the Google Play build (or cannot install Termux from other sources), be aware that it's built from a separate repository (https://github.com/termux-play-store/) - be sure to report issues there, as any issues encountered might very well be specific to that repository.&lt;/p&gt;
    &lt;p&gt;Uninstallation may be required if a user doesn't want Termux installed in their device anymore or is switching to a different install source. You may also want to consider Backing up Termux before the uninstallation.&lt;/p&gt;
    &lt;p&gt;To uninstall Termux completely, you must uninstall any and all existing Termux or its plugin app APKs listed in Termux App and Plugins.&lt;/p&gt;
    &lt;p&gt;Go to &lt;code&gt;Android Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;Applications&lt;/code&gt; and then look for those apps. You can also use the search feature if it‚Äôs available on your device and search &lt;code&gt;termux&lt;/code&gt; in the applications list.&lt;/p&gt;
    &lt;p&gt;Even if you think you have not installed any of the plugins, it's strongly suggested to go through the application list in Android settings and double-check.&lt;/p&gt;
    &lt;p&gt;All community links are available here.&lt;/p&gt;
    &lt;p&gt;The main ones are the following.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Termux Reddit community&lt;/item&gt;
      &lt;item&gt;Termux User Matrix Channel (Gitter)&lt;/item&gt;
      &lt;item&gt;Termux Dev Matrix Channel (Gitter)&lt;/item&gt;
      &lt;item&gt;Termux X (Twitter)&lt;/item&gt;
      &lt;item&gt;Termux Support Email&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FAQ&lt;/item&gt;
      &lt;item&gt;Termux File System Layout&lt;/item&gt;
      &lt;item&gt;Differences From Linux&lt;/item&gt;
      &lt;item&gt;Package Management&lt;/item&gt;
      &lt;item&gt;Remote Access&lt;/item&gt;
      &lt;item&gt;Backing up Termux&lt;/item&gt;
      &lt;item&gt;Terminal Settings&lt;/item&gt;
      &lt;item&gt;Touch Keyboard&lt;/item&gt;
      &lt;item&gt;Android Storage and Sharing Data with Other Apps&lt;/item&gt;
      &lt;item&gt;Android APIs&lt;/item&gt;
      &lt;item&gt;Moved Termux Packages Hosting From Bintray to IPFS&lt;/item&gt;
      &lt;item&gt;Running Commands in Termux From Other Apps via &lt;code&gt;RUN_COMMAND&lt;/code&gt;intent&lt;/item&gt;
      &lt;item&gt;Termux and Android 10&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;VTE (libvte): Terminal emulator widget for GTK+, mainly used in gnome-terminal. Source, Open Issues, and All (including closed) issues.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;iTerm 2: OS X terminal application. Source, Issues and Documentation (which includes iTerm2 proprietary escape codes).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Konsole: KDE terminal application. Source, in particular tests, Bugs and Wishes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;hterm: JavaScript terminal implementation from Chromium. Source, including tests, and Google group.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;xterm: The grandfather of terminal emulators. Source.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connectbot: Android SSH client. Source&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Android Terminal Emulator: Android terminal app which Termux terminal handling is based on. Inactive. Source.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can help debug problems of the &lt;code&gt;Termux&lt;/code&gt; app and its plugins by setting appropriate &lt;code&gt;logcat&lt;/code&gt; &lt;code&gt;Log Level&lt;/code&gt; in &lt;code&gt;Termux&lt;/code&gt; app settings -&amp;gt; &lt;code&gt;&amp;lt;APP_NAME&amp;gt;&lt;/code&gt; -&amp;gt; &lt;code&gt;Debugging&lt;/code&gt; -&amp;gt; &lt;code&gt;Log Level&lt;/code&gt; (Requires &lt;code&gt;Termux&lt;/code&gt; app version &lt;code&gt;&amp;gt;= 0.118.0&lt;/code&gt;). The &lt;code&gt;Log Level&lt;/code&gt; defaults to &lt;code&gt;Normal&lt;/code&gt; and log level &lt;code&gt;Verbose&lt;/code&gt; currently logs additional information. Its best to revert log level to &lt;code&gt;Normal&lt;/code&gt; after you have finished debugging since private data may otherwise be passed to &lt;code&gt;logcat&lt;/code&gt; during normal operation and moreover, additional logging increases execution time.&lt;/p&gt;
    &lt;p&gt;The plugin apps do not execute the commands themselves but send execution intents to &lt;code&gt;Termux&lt;/code&gt; app, which has its own log level which can be set in &lt;code&gt;Termux&lt;/code&gt; app settings -&amp;gt; &lt;code&gt;Termux&lt;/code&gt; -&amp;gt; &lt;code&gt;Debugging&lt;/code&gt; -&amp;gt; &lt;code&gt;Log Level&lt;/code&gt;. So you must set log level for both &lt;code&gt;Termux&lt;/code&gt; and the respective plugin app settings to get all the info.&lt;/p&gt;
    &lt;p&gt;Once log levels have been set, you can run the &lt;code&gt;logcat&lt;/code&gt; command in &lt;code&gt;Termux&lt;/code&gt; app terminal to view the logs in realtime (&lt;code&gt;Ctrl+c&lt;/code&gt; to stop) or use &lt;code&gt;logcat -d &amp;gt; logcat.txt&lt;/code&gt; to take a dump of the log. You can also view the logs from a PC over &lt;code&gt;ADB&lt;/code&gt;. For more information, check official android &lt;code&gt;logcat&lt;/code&gt; guide here.&lt;/p&gt;
    &lt;p&gt;Moreover, users can generate termux files &lt;code&gt;stat&lt;/code&gt; info and &lt;code&gt;logcat&lt;/code&gt; dump automatically too with terminal's long hold options menu &lt;code&gt;More&lt;/code&gt; -&amp;gt; &lt;code&gt;Report Issue&lt;/code&gt; option and selecting &lt;code&gt;YES&lt;/code&gt; in the prompt shown to add debug info. This can be helpful for reporting and debugging other issues. If the report generated is too large, then &lt;code&gt;Save To File&lt;/code&gt; option in context menu (3 dots on top right) of &lt;code&gt;ReportActivity&lt;/code&gt; can be used and the file viewed/shared instead.&lt;/p&gt;
    &lt;p&gt;Users must post complete report (optionally without sensitive info) when reporting issues. Issues opened with (partial) screenshots of error reports instead of text will likely be automatically closed/deleted.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Off&lt;/code&gt;- Log nothing.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Normal&lt;/code&gt;- Start logging error, warn and info messages and stacktraces.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Debug&lt;/code&gt;- Start logging debug messages.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Verbose&lt;/code&gt;- Start logging verbose messages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The termux-shared library was added in &lt;code&gt;v0.109&lt;/code&gt;. It defines shared constants and utils of the Termux app and its plugins. It was created to allow for the removal of all hardcoded paths in the Termux app. Some of the termux plugins are using this as well and rest will in future. If you are contributing code that is using a constant or a util that may be shared, then define it in &lt;code&gt;termux-shared&lt;/code&gt; library if it currently doesn't exist and reference it from there. Update the relevant changelogs as well. Pull requests using hardcoded values will/should not be accepted. Termux app and plugin specific classes must be added under &lt;code&gt;com.termux.shared.termux&lt;/code&gt; package and general classes outside it. The &lt;code&gt;termux-shared&lt;/code&gt; &lt;code&gt;LICENSE&lt;/code&gt; must also be checked and updated if necessary when contributing code. The licenses of any external library or code must be honoured.&lt;/p&gt;
    &lt;p&gt;The main Termux constants are defined by &lt;code&gt;TermuxConstants&lt;/code&gt; class. It also contains information on how to fork Termux or build it with your own package name. Changing the package name will require building the bootstrap zip packages and other packages with the new &lt;code&gt;$PREFIX&lt;/code&gt;, check Building Packages for more info.&lt;/p&gt;
    &lt;p&gt;Check Termux Libraries for how to import termux libraries in plugin apps and Forking and Local Development for how to update termux libraries for plugins.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;versionName&lt;/code&gt; in &lt;code&gt;build.gradle&lt;/code&gt; files of Termux and its plugin apps must follow the semantic version &lt;code&gt;2.0.0&lt;/code&gt; spec in the format &lt;code&gt;major.minor.patch(-prerelease)(+buildmetadata)&lt;/code&gt;. When bumping &lt;code&gt;versionName&lt;/code&gt; in &lt;code&gt;build.gradle&lt;/code&gt; files and when creating a tag for new releases on GitHub, make sure to include the patch number as well, like &lt;code&gt;v0.1.0&lt;/code&gt; instead of just &lt;code&gt;v0.1&lt;/code&gt;. The &lt;code&gt;build.gradle&lt;/code&gt; files and &lt;code&gt;attach_debug_apks_to_release&lt;/code&gt; workflow validates the version as well and the build/attachment will fail if &lt;code&gt;versionName&lt;/code&gt; does not follow the spec.&lt;/p&gt;
    &lt;p&gt;Commit messages must use the Conventional Commits spec so that chagelogs as per the Keep a Changelog spec can automatically be generated by the &lt;code&gt;create-conventional-changelog&lt;/code&gt; script, check its repo for further details on the spec. The first letter for &lt;code&gt;type&lt;/code&gt; and &lt;code&gt;description&lt;/code&gt; must be capital and description should be in the present tense. The space after the colon &lt;code&gt;:&lt;/code&gt; is necessary. For a breaking change, add an exclamation mark &lt;code&gt;!&lt;/code&gt; before the colon &lt;code&gt;:&lt;/code&gt;, so that it is highlighted in the chagelog automatically.&lt;/p&gt;
    &lt;code&gt;&amp;lt;type&amp;gt;[optional scope]: &amp;lt;description&amp;gt;

[optional body]

[optional footer(s)]
&lt;/code&gt;
    &lt;p&gt;Only the &lt;code&gt;types&lt;/code&gt; listed below must be used exactly as they are used in the changelog headings. For example, &lt;code&gt;Added: Add foo&lt;/code&gt;, &lt;code&gt;Added|Fixed: Add foo and fix bar&lt;/code&gt;, &lt;code&gt;Changed!: Change baz as a breaking change&lt;/code&gt;, etc. You can optionally add a scope as well, like &lt;code&gt;Fixed(terminal): Fix some bug&lt;/code&gt;. Do not use anything else as type, like &lt;code&gt;add&lt;/code&gt; instead of &lt;code&gt;Added&lt;/code&gt;, etc.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Added for new features.&lt;/item&gt;
      &lt;item&gt;Changed for changes in existing functionality.&lt;/item&gt;
      &lt;item&gt;Deprecated for soon-to-be removed features.&lt;/item&gt;
      &lt;item&gt;Removed for now removed features.&lt;/item&gt;
      &lt;item&gt;Fixed for any bug fixes.&lt;/item&gt;
      &lt;item&gt;Security in case of vulnerabilities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check &lt;code&gt;TermuxConstants&lt;/code&gt;javadocs for instructions on what changes to make in the app to change package name.&lt;/item&gt;
      &lt;item&gt;You also need to recompile bootstrap zip for the new package name. Check building bootstrap, here and here.&lt;/item&gt;
      &lt;item&gt;Currently, not all plugins use &lt;code&gt;TermuxConstants&lt;/code&gt;from&lt;code&gt;termux-shared&lt;/code&gt;library and have hardcoded&lt;code&gt;com.termux&lt;/code&gt;values and will need to be manually patched.&lt;/item&gt;
      &lt;item&gt;If forking termux plugins, check Forking and Local Development for info on how to use termux libraries for plugins.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; GitHub Secure Open Source Fund (1, 2)&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; NLnet NGI Mobifree (1, 2)&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Cloudflare (1)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46854642</guid><pubDate>Mon, 02 Feb 2026 11:03:44 +0000</pubDate></item><item><title>Microsoft is walking back Windows 11's AI overload</title><link>https://www.windowscentral.com/microsoft/windows-11/microsoft-is-reevaluating-its-ai-efforts-on-windows-11-plans-to-reduce-copilot-integrations-and-evolve-recall</link><description>&lt;doc fingerprint="5794613ebfaee0d6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You won: Microsoft is walking back Windows 11‚Äôs AI overload ‚Äî scaling down Copilot and rethinking Recall in a major shift&lt;/head&gt;
    &lt;p&gt;In an exclusive report from Windows Central, Microsoft is mulling pulling back its Windows 11 AI push with a major Copilot and Recall rethink.&lt;/p&gt;
    &lt;p&gt;It‚Äôs fair to say that Windows 11‚Äôs recent endeavour into AI hasn‚Äôt gone down well with its most passionate users. It started in 2024 with the unveiling of Windows Recall, which was met with such backlash that Microsoft was forced to postpone it by an entire year while it addressed major security and privacy flaws.&lt;/p&gt;
    &lt;p&gt;It seems like things have been downhill since. In the last year, Microsoft has taken every opportunity to enshittify Windows 11 by placing Copilot buttons wherever it can across in-box apps like File Explorer and Notepad, even if the implementation is poor or unnecessary.&lt;/p&gt;
    &lt;p&gt;This has soured Microsoft‚Äôs AI efforts in the eyes of many Windows users, resulting in major pushback online and adding to the overall negative sentiment around Windows 11. This came to a head in November, when Windows president Pavan Davuluri tweeted that Windows would evolve into an agentic OS, spawning thousands of overwhelmingly negative replies rejecting this plan.&lt;/p&gt;
    &lt;p&gt;It appears this moment of pushback has resonated with internal teams: According to people familiar with Microsoft‚Äôs plans, the company is now reevaluating its AI strategy on Windows 11 and plans changes to streamline or even remove certain AI features where they don‚Äôt make sense.&lt;/p&gt;
    &lt;p&gt;Details around how the company is going about this remain light, but sources say Copilot integrations like those found in Notepad and Paint are under review. This may result in Microsoft removing certain Copilot integrations from these apps, or at the very least removing the Copilot branding and pivoting to a more streamlined experience.&lt;/p&gt;
    &lt;p&gt;I‚Äôm also told that Microsoft has paused work on any additional Copilot buttons for in-box apps, at least for now. While I don‚Äôt expect this pause to be permanent, it does sound like Microsoft plans to be more tactful and deliberate in where these Copilot buttons and integrations will appear going forward.&lt;/p&gt;
    &lt;p&gt;Windows Recall is another AI experience that I‚Äôm told is under review. Sources tell me that Microsoft believes that Recall, in its current implementation, has failed, though I understand the company is exploring ways to evolve the concept rather than scrap it entirely, possibly dropping the Recall name in the process, though this is unconfirmed.&lt;/p&gt;
    &lt;p&gt;Other AI initiatives, such as Semantic Search, Agentic Workspace, Windows ML, and Windows AI APIs, are continuing ahead as planned. Microsoft believes that these under-the-hood AI efforts are still important for app developers and users, positioning Windows as a viable contender amongst other OS‚Äôs that are also building AI frameworks into their platforms.&lt;/p&gt;
    &lt;p&gt;The good news is that it's clear Microsoft has heard the feedback around its heavy-handedness when it comes to Copilot buttons in Windows apps. The company is stepping back to readjust how best to implement these AI integrations across the OS, hopefully resulting in a more meaningful and useful AI experience on the platform, rather than haphazardly adding the Copilot icon to every UI surface it can.&lt;/p&gt;
    &lt;p&gt;This effort is likely part of Microsoft's overall effort to "fix" Windows 11 this year. I understand that the company is moving quickly to begin shipping meaningful changes that are designed to signal to customers that it is listening to feedback, and streamlining where Copilot shows up across in-box apps would be a strong place to start.&lt;/p&gt;
    &lt;p&gt;Microsoft pulling back its Windows 11 AI push is a big shift ‚Äî fewer forced Copilot moments, a reworked Recall, and a more realistic approach overall. &lt;lb/&gt;How does that land with you? Is this the right move, or should Microsoft double down instead? Share your take below and let‚Äôs see where the community stands.&lt;/p&gt;
    &lt;p&gt;Follow Windows Central on Google News to keep our latest news, insights, and features at the top of your feeds!&lt;/p&gt;
    &lt;p&gt;You must confirm your public display name before commenting&lt;/p&gt;
    &lt;p&gt;Please logout and then login again, you will then be prompted to enter your display name.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46854951</guid><pubDate>Mon, 02 Feb 2026 11:52:29 +0000</pubDate></item><item><title>Claude Code is suddenly everywhere inside Microsoft</title><link>https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad</link><description>&lt;doc fingerprint="2f402e1a7ea6c0ef"&gt;
  &lt;main&gt;
    &lt;p&gt;Developers have been comparing the strengths and weaknesses of Anthropic‚Äôs Claude Code, Anysphere‚Äôs Cursor, and Microsoft‚Äôs GitHub Copilot for months now, looking for a winner. While no individual AI coding tool manages to be the best at every task that software developers do each day, Claude Code is increasingly coming out on top for its ease of use, both for developers and nontechnical users.&lt;/p&gt;
    &lt;head rend="h1"&gt;Claude Code is suddenly everywhere inside Microsoft&lt;/head&gt;
    &lt;p&gt;Microsoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.&lt;/p&gt;
    &lt;p&gt;Microsoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.&lt;/p&gt;
    &lt;p&gt;It seems like Microsoft agrees, as sources tell me the company is now encouraging thousands of its employees from some of its most prolific teams to pick up Claude Code and get coding, even if they‚Äôre not developers.&lt;/p&gt;
    &lt;p&gt;Microsoft first started adopting Anthropic‚Äôs Claude Sonnet 4 model inside its developer division in June last year, before favoring it for paid users of GitHub Copilot several months later. Now, Microsoft is going a step beyond using Anthropic‚Äôs AI models and widely adopting Claude Code across its biggest engineering teams.&lt;/p&gt;
    &lt;p&gt;Microsoft‚Äôs CoreAI team, the new AI engineering group led by former Meta engineering chief Jay Parikh, has been testing Claude Code in recent months, and last week Microsoft‚Äôs Experiences + Devices division were being asked to install Claude Code. This division is responsible for Windows, Microsoft 365, Outlook, Microsoft Teams, Bing, Edge, Surface, and more.&lt;/p&gt;
    &lt;p&gt;Even employees without any coding experience are being encouraged to experiment with Claude Code, to allow designers and project managers to prototype ideas. Microsoft has also approved the use of Claude Code across all of its code and repositories for its Business and Industry Copilot teams.&lt;/p&gt;
    &lt;p&gt;Software engineers at Microsoft are now expected to use both Claude Code and GitHub Copilot and give feedback comparing the two, I‚Äôm told. Microsoft sells GitHub Copilot as its AI coding tool of choice to its customers, but if these broad internal pilot programs are successful, then it‚Äôs possible the company could even eventually sell Claude Code directly to its cloud customers.&lt;/p&gt;
    &lt;p&gt;Microsoft is now one of Anthropic‚Äôs top customers, according to a recent report from The Information. The software maker is also counting selling Anthropic AI models toward Azure sales quotas, which is unusual given Microsoft typically only offers its salespeople incentives for homegrown products or models from OpenAI.&lt;/p&gt;
    &lt;p&gt;Microsoft‚Äôs decision to adopt Claude Code more broadly among its engineering teams certainly looks like a vote of confidence in Anthropic‚Äôs AI tools over its own, especially as it‚Äôs encouraging nontechnical employees to try out coding. But the reality is that Microsoft‚Äôs developers are likely to use a mix of AI tools, and adopting Claude Code is another part of that tool set.&lt;/p&gt;
    &lt;p&gt;‚ÄúCompanies regularly test and trial competing products to gain a better understanding of the market landscape,‚Äù says Frank Shaw, Microsoft‚Äôs communications chief, in a statement to Notepad. ‚ÄúOpenAI continues to be our primary partner and model provider on frontier models, and we remain committed to our long-term partnership.‚Äù&lt;/p&gt;
    &lt;p&gt;While Microsoft remains committed to OpenAI, it is increasingly working with Anthropic to bring its models and tools to Microsoft‚Äôs own teams and the software it sells to customers. Microsoft and Anthropic signed a deal in November that allows Microsoft Foundry customers to get access to Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. The deal also involves Anthropic committing to purchasing $30 billion of Azure compute capacity.&lt;/p&gt;
    &lt;p&gt;Microsoft has also started favoring Anthropic‚Äôs Claude models inside Microsoft 365 apps and Copilot recently, using them in specific apps or features where Anthropic‚Äôs models have proved more capable than OpenAI‚Äôs counterparts.&lt;/p&gt;
    &lt;p&gt;The big question here is, what does the increased use of Claude Code at Microsoft mean for its more than 100,000 code repositories? Microsoft told me last year that 91 percent of its engineering teams use GitHub Copilot and a variety of teams have been using the AI tool to speed up mundane tasks. Microsoft‚Äôs use of AI tools has been largely restricted to software engineers, but with Claude Code and Claude Cowork, Anthropic is increasingly focused on making coding and non-coding tasks more approachable, thanks to AI agent capabilities.&lt;/p&gt;
    &lt;p&gt;Microsoft is embracing the ease of use of Claude Code to allow more nontechnical employees to commit code using AI, and this broad pilot will certainly highlight the challenges and benefits of that shift. It also puts further pressure on junior developer roles, with fears in the industry that these roles are increasingly disappearing because of AI. Microsoft just took another big step toward a future where more autonomous AI agents are creating code, further wrestling control from its software engineers.&lt;/p&gt;
    &lt;head rend="h2"&gt;It‚Äôs Xbox time&lt;/head&gt;
    &lt;p&gt;Microsoft is getting ready to show off two of its biggest Xbox games this year, Forza Horizon 6 and Fable, later today as part of its Xbox Developer Direct stream. There will also be a first in-depth look at Beast of Reincarnation and at least one other game shown, I‚Äôm hearing. Double Fine is ready to show off Kiln, a multiplayer, team-based brawler. I understand Double Fine has been holding playtests recently, where you play as a spirit that can inhabit pottery and carry water to douse an opponent‚Äôs kiln and put out a fire.&lt;/p&gt;
    &lt;p&gt;I wouldn‚Äôt be surprised to see Kiln appear as an early preview in the coming months, followed by Forza Horizon 6 in May and then Halo: Campaign Evolved. I keep hearing that both Fable and Gears of War: E-Day are currently targeting a release in the second half of this year. Microsoft is keen to release new Forza, Gears, Halo, and Fable games in 2026 to mark 25 years of Xbox.&lt;/p&gt;
    &lt;head rend="h2"&gt;The pad&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft‚Äôs first Windows 11 update of 2026 stopped some computers from shutting down. It‚Äôs only January and Microsoft has had to rush out an emergency out-of-band fix that stopped some Windows 11 PCs from shutting down. The issues were limited to machines running Enterprise and IoT editions of Windows 11 version 23H2, but it‚Äôs yet another buggy update for Windows, which is becoming increasingly common.&lt;/item&gt;
      &lt;item&gt;Microsoft‚Äôs free Xbox Cloud Gaming is coming soon with ads. Microsoft is getting closer to launching its free streaming option for Xbox Cloud Gaming. The ad-supported feature has started appearing inside the Xbox app for PC, indicating ‚Äú1 hour of ad-supported playtime per session.‚Äù I‚Äôm expecting to see this rollout with preroll ads in the coming weeks, but there could be limits of up to five hours free per month.&lt;/item&gt;
      &lt;item&gt;Microsoft wants to build 15 data centers in Mount Pleasant, Wisconsin. The empty land formerly owned by Foxconn is about to be transformed into Microsoft data centers. Leaders of the local village in Mount Pleasant, Wisconsin, approved plans for the data centers earlier this week, and final approval could come next week. Foxconn‚Äôs failed Wisconsin project had promised 13,000 jobs, but now the land will be filled with a 1.2-million-square-foot data center project that will hold hundreds of thousands of Nvidia‚Äôs AI GPUs.&lt;/item&gt;
      &lt;item&gt;The Xbox app is now available for all Arm-based Windows 11 PCs. After a rocky start to gaming on Windows on Arm, Microsoft has updated its Xbox app this week so it‚Äôs fully compatible with all Qualcomm-powered devices. More than 85 percent of the Xbox Game Pass catalog is also now compatible with Arm-based devices, but the majority of games will still need to be emulated using Microsoft‚Äôs Prism technology.&lt;/item&gt;
      &lt;item&gt;Microsoft Paint now has an AI-powered coloring book. Microsoft is adding more AI features to its Paint app this week. Windows testers can now try out a coloring book feature that lets you create coloring book pages from a text prompt. It‚Äôs available inside the Copilot button in Paint, and you have to have a Copilot Plus PC to be able to use it. Notepad (the app!) is also getting expanded Markdown syntax features and a new welcome experience to highlight features. I never thought I‚Äôd see the day that Notepad, a lightweight app, would need a welcome screen because of all the features Microsoft has packed in.&lt;/item&gt;
      &lt;item&gt;GitHub has a new Copilot SDK. Microsoft is announcing a technical preview of its GitHub Copilot SDK today, which brings the power of the GitHub Copilot CLI to any app. It essentially allows developers to bring GitHub Copilot capabilities as a programmable SDK for Python, TypeScript, Go, and .NET. Microsoft teams have already used this to build custom GUIs for agents, summarizing tools, YouTube chapter generators, and more.&lt;/item&gt;
      &lt;item&gt;Satya Nadella and former British Prime Minister Rishi Sunak chat AI. Former UK leader Rishi Sunak took on a senior adviser role at Microsoft and Anthropic last year, and he‚Äôs now appeared alongside Microsoft CEO Satya Nadella to discuss the future of AI. The roughly 30-minute talk didn‚Äôt have any surprising news, but Sunak did agree with Nvidia CEO Jensen Huang that ‚Äúyou may not lose your job to AI, but you may well lose your job to someone using AI.‚Äù Nadella thinks AI will make us all ‚Äúmanagers of infinite minds,‚Äù much like how we have ‚Äúinformation at your fingertips.‚Äù&lt;/item&gt;
      &lt;item&gt;Microsoft now sponsors the Mercedes-AMG F1 team. Microsoft is switching its F1 allegiances from Alpine to Mercedes-AMG for the 2026 season. A new multiyear partnership will see Mercedes-AMG use Microsoft technologies for race team operations and plaster the Microsoft logo in prominent positions on the 2026 Mercedes-AMG F1 car and on racing suits. There‚Äôs a big technical shake-up for the 2026 season, with all-new chassis, power units, and fuel regulations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm always keen to hear from readers, so please drop a comment here, or you can reach me at notepad@theverge.com if you want to discuss anything else. If you‚Äôve heard about any of Microsoft‚Äôs secret projects, you can reach me via email at notepad@theverge.com or speak to me confidentially on the Signal messaging app, where I‚Äôm tomwarren.01. I‚Äôm also tomwarren on Telegram, if you‚Äôd prefer to chat there.&lt;/p&gt;
    &lt;p&gt;Thanks for subscribing to Notepad.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Popular&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Bill Gates says accusations contained in Epstein files are ‚Äòabsolutely absurd‚Äô&lt;/item&gt;
      &lt;item&gt;There‚Äôs a social network for AI agents, and it‚Äôs getting weird&lt;/item&gt;
      &lt;item&gt;This tiny pocket-friendly e-reader is packed with frustration and potential&lt;/item&gt;
      &lt;item&gt;Video game company stock prices dip after Google introduces an AI world-generation tool&lt;/item&gt;
      &lt;item&gt;The telephoto is the only phone camera that really matters&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46854999</guid><pubDate>Mon, 02 Feb 2026 11:58:58 +0000</pubDate></item><item><title>Applications where agents are first-class citizens</title><link>https://every.to/guides/agent-native</link><description>&lt;doc fingerprint="a4d2fc4168b18c3f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why now&lt;/head&gt;
    &lt;p&gt;Software agents work reliably now. Claude Code demonstrated that a large language model (LLM) with access to bash and file tools, operating in a loop until an objective is achieved, can accomplish complex multi-step tasks autonomously.&lt;/p&gt;
    &lt;p&gt;The surprising discovery: A really good coding agent is actually a really good general-purpose agent. The same architecture that lets Claude Code refactor a codebase can let an agent organize your files, manage your reading list, or automate your workflows.&lt;/p&gt;
    &lt;p&gt;The Claude Code software development kit (SDK) makes this accessible. You can build applications where features aren't code you write‚Äîthey're outcomes you describe, achieved by an agent with tools, operating in a loop until the outcome is reached.&lt;/p&gt;
    &lt;p&gt;This opens up a new field: software that works the way Claude Code works, applied to categories far beyond coding.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Only Subscription You Need to Stay at the Edge of AI&lt;/head&gt;
    &lt;p&gt;Start shipping agent-native products with Every.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core principles&lt;/head&gt;
    &lt;head rend="h3"&gt;Parity&lt;/head&gt;
    &lt;p&gt;Whatever the user can do through the UI, the agent should be able to achieve through tools.&lt;/p&gt;
    &lt;p&gt;This is the foundational principle. Without it, nothing else matters. Ensure the agent has tools that can accomplish anything the UI can do.&lt;/p&gt;
    &lt;p&gt;The test: Pick any UI action. Can the agent accomplish it?&lt;/p&gt;
    &lt;head rend="h3"&gt;Granularity&lt;/head&gt;
    &lt;p&gt;Tools should be atomic primitives. Features are outcomes achieved by an agent operating in a loop.&lt;/p&gt;
    &lt;p&gt;A tool is a primitive capability. A feature is an outcome described in a prompt, achieved by an agent with tools, operating in a loop until the outcome is reached.&lt;/p&gt;
    &lt;p&gt;The test: To change behavior, do you edit prompts or refactor code?&lt;/p&gt;
    &lt;head rend="h3"&gt;Composability&lt;/head&gt;
    &lt;p&gt;With atomic tools and parity, you can create new features just by writing new prompts.&lt;/p&gt;
    &lt;p&gt;Want a "weekly review" feature? That's just a prompt:&lt;/p&gt;
    &lt;code&gt;"Review files modified this week. Summarize key changes.
Based on incomplete items and approaching deadlines,
suggest three priorities for next week."&lt;/code&gt;
    &lt;p&gt; The agent uses &lt;code&gt;list_files&lt;/code&gt;, &lt;code&gt;read_file&lt;/code&gt;, and its judgment. You described an outcome; the agent loops until it's achieved.
            &lt;/p&gt;
    &lt;head rend="h3"&gt;Emergent capability&lt;/head&gt;
    &lt;p&gt;The agent can accomplish things you didn't explicitly design for.&lt;/p&gt;
    &lt;p&gt;The flywheel:&lt;/p&gt;
    &lt;p&gt;1. Build with atomic tools and parity&lt;/p&gt;
    &lt;p&gt;2. Users ask for things you didn't anticipate&lt;/p&gt;
    &lt;p&gt;3. Agent composes tools to accomplish them (or fails, revealing a gap)&lt;/p&gt;
    &lt;p&gt;4. You observe patterns in what's being requested&lt;/p&gt;
    &lt;p&gt;5. Add domain tools or prompts to make common patterns efficient&lt;/p&gt;
    &lt;p&gt;6. Repeat&lt;/p&gt;
    &lt;p&gt;The test: Can it handle open-ended requests in your domain?&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvement over time&lt;/head&gt;
    &lt;p&gt;Agent-native applications get better through accumulated context and prompt refinement.&lt;/p&gt;
    &lt;p&gt;Unlike traditional software, agent-native applications can improve without shipping code.&lt;/p&gt;
    &lt;p&gt;Accumulated context: State persists across sessions via context files&lt;/p&gt;
    &lt;p&gt;Developer-level refinement: Ship updated prompts for all users&lt;/p&gt;
    &lt;p&gt;User-level customization: Users modify prompts for their workflow&lt;/p&gt;
    &lt;head rend="h2"&gt;Principles in practice&lt;/head&gt;
    &lt;p&gt;The details that make the five principles operational.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parity&lt;/head&gt;
    &lt;p&gt;Imagine a notes app with a beautiful interface for creating, organizing, and tagging notes. A user asks: "Create a note summarizing my meeting and tag it as urgent." If the UI can do it but the agent can't, the agent is stuck.&lt;/p&gt;
    &lt;p&gt;The fix: Ensure the agent has tools (or combinations of tools) that can accomplish anything the UI can do. This isn't about a one-to-one mapping of UI buttons to tools‚Äîit's about achieving the same outcomes.&lt;/p&gt;
    &lt;p&gt;The discipline: When adding any UI capability, ask: Can the agent achieve this outcome? If not, add the necessary tools or primitives.&lt;/p&gt;
    &lt;p&gt;A capability map helps:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;User Action&lt;/cell&gt;
        &lt;cell role="head"&gt;How Agent Achieves It&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Create a note&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;write_file&lt;/code&gt; to notes directory, or &lt;code&gt;create_note&lt;/code&gt; tool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tag a note as urgent&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;update_file&lt;/code&gt; metadata, or &lt;code&gt;tag_note&lt;/code&gt; tool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Search notes&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;search_files&lt;/code&gt; or &lt;code&gt;search_notes&lt;/code&gt; tool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Delete a note&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;delete_file&lt;/code&gt; or &lt;code&gt;delete_note&lt;/code&gt; tool&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The test: Pick any action a user can take in your UI. Describe it to the agent. Can it accomplish the outcome?&lt;/p&gt;
    &lt;head rend="h3"&gt;Granularity&lt;/head&gt;
    &lt;p&gt;The key shift: The agent is pursuing an outcome with judgment, not executing a choreographed sequence. It can encounter unexpected cases, adjust its approach, or ask clarifying questions‚Äîthe loop continues until the outcome is achieved.&lt;/p&gt;
    &lt;p&gt;The more atomic your tools, the more flexibly the agent can use them. If you bundle decision logic into tools, you've moved judgment back into code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Composability&lt;/head&gt;
    &lt;p&gt;This works for developers and users. You can ship new features by adding prompts. Users can customize behavior by modifying prompts or creating their own.&lt;/p&gt;
    &lt;p&gt;The constraint: this only works if tools are atomic enough to be composed in ways you didn't anticipate, and if the agent has parity with users. If tools encode too much logic, composition breaks down.&lt;/p&gt;
    &lt;head rend="h3"&gt;Emergent Capability&lt;/head&gt;
    &lt;p&gt;Example: "Cross-reference my meeting notes with my task list and tell me what I've committed to but haven't scheduled." You didn't build a commitment tracker, but if the agent can read notes and tasks, it can accomplish this.&lt;/p&gt;
    &lt;p&gt;This reveals latent demand. Instead of guessing what features users want, you observe what they're asking the agent to do. When patterns emerge, you can optimize them with domain-specific tools or dedicated prompts. But you didn't have to anticipate them‚Äîyou discovered them.&lt;/p&gt;
    &lt;p&gt;This changes how you build products. You're not trying to imagine every feature upfront. You're creating a capable foundation and learning from what emerges.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvement over time&lt;/head&gt;
    &lt;p&gt;Accumulated context: The agent maintains state across sessions‚Äîwhat exists, what the user has done, and what worked.&lt;/p&gt;
    &lt;p&gt;Prompt refinement at multiple levels: developer-level updates, user-level customization, and (advanced) agent-level adjustments based on feedback.&lt;/p&gt;
    &lt;p&gt;Self-modification (advanced): Agents that edit their own prompts or code require safety rails‚Äîapproval gates, checkpoints, rollback paths, and health checks.&lt;/p&gt;
    &lt;p&gt;The mechanisms are still being discovered. Context and prompt refinement are proven; self-modification is emerging.&lt;/p&gt;
    &lt;p&gt;Tools should be atomic primitives. Features are outcomes achieved by an agent operating in a loop. The agent makes the decisions; prompts describe the outcome.&lt;/p&gt;
    &lt;head rend="h3"&gt;Less granular&lt;/head&gt;
    &lt;code&gt;Tool: classify_and_organize_files(files)
‚Üí You wrote the decision logic
‚Üí Agent executes your code
‚Üí To change behavior, you refactor&lt;/code&gt;
    &lt;p&gt;Bundles judgment into the tool. Limits flexibility.&lt;/p&gt;
    &lt;head rend="h3"&gt;More granular&lt;/head&gt;
    &lt;code&gt;Tools: read_file, write_file, move_file, bash
Prompt: "Organize the downloads folder..."
‚Üí Agent makes the decisions
‚Üí To change behavior, edit the prompt&lt;/code&gt;
    &lt;p&gt;Agent pursues outcomes with judgment. Empowers flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;From primitives to domain tools&lt;/head&gt;
    &lt;p&gt;Start with pure primitives: bash, file operations, basic storage. This proves the architecture works and reveals what the agent actually needs.&lt;/p&gt;
    &lt;p&gt;As patterns emerge, add domain-specific tools deliberately. Use them to anchor vocabulary, add guardrails, or improve efficiency.&lt;/p&gt;
    &lt;p&gt;A &lt;code&gt;create_note&lt;/code&gt; tool teaches the agent what "note" means in your system.&lt;/p&gt;
    &lt;p&gt;Some operations need validation that shouldn't be left to agent judgment.&lt;/p&gt;
    &lt;p&gt;Common operations can be bundled for speed and cost.&lt;/p&gt;
    &lt;code&gt;analyze_and_publish(input)&lt;/code&gt;
    &lt;p&gt;Bundles judgment into the tool&lt;/p&gt;
    &lt;code&gt;publish(content)&lt;/code&gt;
    &lt;p&gt;One action; agent decided what to publish&lt;/p&gt;
    &lt;p&gt;The rule for domain tools: They should represent one conceptual action from the user's perspective. They can include mechanical validation, but judgment about what to do or whether to do it belongs in the prompt.&lt;/p&gt;
    &lt;p&gt;Keep primitives available. Domain tools are shortcuts, not gates. Unless there's a specific reason to restrict access (security, data integrity), the agent should still be able to use underlying primitives for edge cases. This preserves composability and emergent capability. The default is open; make gating a conscious decision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Graduating to code&lt;/head&gt;
    &lt;p&gt;Some operations will need to move from agent-orchestrated to optimized code for performance or reliability.&lt;/p&gt;
    &lt;p&gt;Agent uses primitives in a loop&lt;/p&gt;
    &lt;p&gt;Flexible, proves the concept&lt;/p&gt;
    &lt;p&gt;Add domain tools for common operations&lt;/p&gt;
    &lt;p&gt;Faster, still agent-orchestrated&lt;/p&gt;
    &lt;p&gt;For hot paths, implement in optimized code&lt;/p&gt;
    &lt;p&gt;Fast, deterministic&lt;/p&gt;
    &lt;p&gt;The caveat: Even when an operation graduates to code, the agent should be able to trigger the optimized operation itself and fall back to primitives for edge cases the optimized path doesn't handle. Graduation is about efficiency. Parity still holds.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Agent can trigger the optimized operation directly&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Agent can fall back to primitives for edge cases&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Files as the universal interface&lt;/head&gt;
    &lt;p&gt;Agents are naturally good at files. Claude Code works because bash + filesystem is the most battle-tested agent interface.&lt;/p&gt;
    &lt;p&gt;Agents already know &lt;code&gt;cat&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;mv&lt;/code&gt;, &lt;code&gt;mkdir&lt;/code&gt;. File operations are the primitives they're most fluent with.&lt;/p&gt;
    &lt;p&gt;Users can see what the agent created, edit it, move it, delete it. No black box.&lt;/p&gt;
    &lt;p&gt;Export is trivial. Backup is trivial. Users own their data.&lt;/p&gt;
    &lt;p&gt;On mobile with iCloud, all devices share the same file system. Agent's work appears everywhere‚Äîwithout building a server.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/projects/acme/notes/&lt;/code&gt; is self-documenting in a way that &lt;code&gt;SELECT * FROM notes WHERE project_id = 123&lt;/code&gt; isn't.&lt;/p&gt;
    &lt;p&gt;A general principle of agent-native design: Design for what agents can reason about. The best proxy for that is what would make sense to a human. If a human can look at your file structure and understand what's going on, an agent probably can too.&lt;/p&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;Claude's contribution from building; Dan is still forming his opinion. These conventions are one approach that's worked so far, not a prescription. Better solutions should be considered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Entity-scoped directories&lt;/head&gt;
    &lt;code&gt;{entity_type}/{entity_id}/
‚îú‚îÄ‚îÄ primary content
‚îú‚îÄ‚îÄ metadata
‚îî‚îÄ‚îÄ related materials&lt;/code&gt;
    &lt;p&gt;Example: &lt;code&gt;Research/books/{bookId}/&lt;/code&gt; contains full text, notes, sources, and agent logs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Directory naming&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; ‚Ä¢ Entity-scoped: &lt;code&gt;{entityType}/{entityId}/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt; ‚Ä¢ Collections: &lt;code&gt;{type}/&lt;/code&gt;(e.g.,&lt;code&gt;AgentCheckpoints/&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Convention: lowercase with underscores, not camelCase&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Markdown for human-readable content; JSON for structured data.&lt;/p&gt;
    &lt;head rend="h3"&gt;One approach to naming:&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;File&lt;/cell&gt;
        &lt;cell role="head"&gt;Naming Pattern&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Entity data&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;{entity}.json&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;library.json&lt;/code&gt;, &lt;code&gt;status.json&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Human-readable content&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;{content_type}.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;introduction.md&lt;/code&gt;, &lt;code&gt;profile.md&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Agent reasoning&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;agent_log.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Per-entity agent history&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Primary content&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;full_text.txt&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Downloaded/extracted text&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Multi-volume&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;volume{N}.txt&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;volume1.txt&lt;/code&gt;, &lt;code&gt;volume2.txt&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;External sources&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;{source_name}.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;wikipedia.md&lt;/code&gt;, &lt;code&gt;sparknotes.md&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Checkpoints&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;{sessionId}.checkpoint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;UUID-based&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Configuration&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;config.json&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Feature settings&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Directory structure&lt;/head&gt;
    &lt;code&gt;Documents/
‚îú‚îÄ‚îÄ AgentCheckpoints/     # Ephemeral
‚îÇ   ‚îî‚îÄ‚îÄ {sessionId}.checkpoint
‚îú‚îÄ‚îÄ AgentLogs/            # Debugging
‚îÇ   ‚îî‚îÄ‚îÄ {type}/{sessionId}.md
‚îî‚îÄ‚îÄ Research/             # User's work
    ‚îî‚îÄ‚îÄ books/{bookId}/
        ‚îú‚îÄ‚îÄ full_text.txt
        ‚îú‚îÄ‚îÄ notes.md
        ‚îî‚îÄ‚îÄ agent_log.md&lt;/code&gt;
    &lt;head rend="h3"&gt;The context.md pattern&lt;/head&gt;
    &lt;code&gt;# Context

## Who I Am
Reading assistant for the Every app.

## What I Know About This User
- Interested in military history and Russian literature
- Prefers concise analysis
- Currently reading *War and Peace*

## What Exists
- 12 notes in /notes
- three active projects
- User preferences at /preferences.md

## Recent Activity
- User created "Project kickoff" (two hours ago)
- Analyzed passage about Austerlitz (yesterday)

## My Guidelines
- Don't spoil books they're reading
- Use their interests to personalize insights

## Current State
- No pending tasks
- Last sync: 10 minutes ago&lt;/code&gt;
    &lt;p&gt;The agent reads this file at the start of each session and updates it as state changes‚Äîportable working memory without code changes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Files vs. database&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;This framing is one way to think about it, and it's specifically informed by mobile development. For web apps, the tradeoffs are different‚ÄîDan doesn't have a strong opinion there yet.&lt;/p&gt;
    &lt;head rend="h4"&gt;Use files for...&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Content users should read/edit&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Configuration that benefits from version control&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Agent-generated content&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Anything that benefits from transparency&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Large text content&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Use database for...&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ High-volume structured data&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Data that needs complex queries&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Ephemeral state (sessions, caches)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Data with relationships&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Data that needs indexing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The principle: Files for legibility, databases for structure. When in doubt, files‚Äîthey're more transparent and users can always inspect them.&lt;/p&gt;
    &lt;p&gt;The file-first approach works when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Scale is small (one user's library, not millions of records)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Transparency is valued over query speed&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Cloud sync (iCloud, Dropbox) works well with files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hybrid approach&lt;/p&gt;
    &lt;p&gt;Even if you need a database for performance, consider maintaining a file-based "source of truth" that the agent works with, synced to the database for the UI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conflict model&lt;/head&gt;
    &lt;p&gt;If agents and users write to the same files, you need a conflict model.&lt;/p&gt;
    &lt;head rend="h4"&gt;Atomic writes (current reality)&lt;/head&gt;
    &lt;code&gt;// Swift - last-write-wins via atomic writes
try data.write(to: url, options: [.atomic])&lt;/code&gt;
    &lt;p&gt;Simple but can lose changes.&lt;/p&gt;
    &lt;head rend="h4"&gt;iCloud conflict monitoring&lt;/head&gt;
    &lt;code&gt;// Watch for sync conflicts
NotificationCenter.default.addObserver(
    forName: .NSMetadataQueryDidUpdate,
    ...
)
// Creates: {filename} (conflict).md&lt;/code&gt;
    &lt;p&gt;Monitor and resolve conflicts explicitly.&lt;/p&gt;
    &lt;p&gt;Last write wins&lt;/p&gt;
    &lt;p&gt;Simple, changes can be lost&lt;/p&gt;
    &lt;p&gt;Check before writing&lt;/p&gt;
    &lt;p&gt;Skip if modified since read&lt;/p&gt;
    &lt;p&gt;Separate spaces&lt;/p&gt;
    &lt;p&gt;Agent ‚Üí drafts/, user promotes&lt;/p&gt;
    &lt;p&gt;Append-only logs&lt;/p&gt;
    &lt;p&gt;Additive, never overwrites&lt;/p&gt;
    &lt;p&gt;File locking&lt;/p&gt;
    &lt;p&gt;Prevent edits while open&lt;/p&gt;
    &lt;p&gt;Practical guidance: Logs and status files rarely conflict. For user-edited content, consider explicit handling or keep agent output separate. iCloud adds complexity by creating conflict copies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Agent execution patterns&lt;/head&gt;
    &lt;head rend="h3"&gt;Completion signals&lt;/head&gt;
    &lt;p&gt;Agents need an explicit way to say "I'm done." Don't detect completion through heuristics.&lt;/p&gt;
    &lt;code&gt;struct ToolResult {
  let success: Bool
  let output: String
  let shouldContinue: Bool
}

.success("Result")  // continue
.error("Message")   // continue (retry)
.complete("Done")   // stop loop&lt;/code&gt;
    &lt;p&gt;Completion is separate from success/failure: A tool can succeed and stop the loop, or fail and signal continue for recovery.&lt;/p&gt;
    &lt;p&gt;What's not yet standard: Richer control flow signals like:&lt;/p&gt;
    &lt;p&gt;pause‚Äîagent needs user input before continuing&lt;/p&gt;
    &lt;p&gt;escalate‚Äîagent needs a human decision outside its scope&lt;/p&gt;
    &lt;p&gt;retry‚Äîtransient failure, orchestrator should retry&lt;/p&gt;
    &lt;p&gt;Currently, if the agent needs input, it asks in its text response. There's no formal "blocked waiting for input" state. This is an area still being figured out.&lt;/p&gt;
    &lt;head rend="h3"&gt;Model tier selection&lt;/head&gt;
    &lt;p&gt;Not all agent operations need the same intelligence level.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Tier&lt;/cell&gt;
        &lt;cell role="head"&gt;Reasoning&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Research agent&lt;/cell&gt;
        &lt;cell&gt;Balanced&lt;/cell&gt;
        &lt;cell&gt;Tool loops, good reasoning&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Chat&lt;/cell&gt;
        &lt;cell&gt;Balanced&lt;/cell&gt;
        &lt;cell&gt;Fast enough for conversation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Complex synthesis&lt;/cell&gt;
        &lt;cell&gt;Powerful&lt;/cell&gt;
        &lt;cell&gt;Multi-source analysis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Quick classification&lt;/cell&gt;
        &lt;cell&gt;Fast&lt;/cell&gt;
        &lt;cell&gt;High volume, simple task&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The discipline: When adding a new agent, explicitly choose its tier based on task complexity. Don't always default to "most powerful."&lt;/p&gt;
    &lt;head rend="h3"&gt;Partial completion&lt;/head&gt;
    &lt;code&gt;struct AgentTask {
    var status: TaskStatus  // pending, in_progress, completed, failed, skipped
    var notes: String?      // Why it failed, what was done
}

var isComplete: Bool {
    tasks.allSatisfy { $0.status == .completed || $0.status == .skipped }
}&lt;/code&gt;
    &lt;p&gt;For multi-step tasks, track progress at the task level. What the UI shows:&lt;/p&gt;
    &lt;head rend="h4"&gt;Partial completion scenarios:&lt;/head&gt;
    &lt;p&gt;Agent hits max iterations&lt;/p&gt;
    &lt;p&gt;Some tasks completed, some pending. Checkpoint saved. Resume continues from where it left off.&lt;/p&gt;
    &lt;p&gt;Agent fails on one task&lt;/p&gt;
    &lt;p&gt;Task marked failed with error in notes. Other tasks may continue (agent decides).&lt;/p&gt;
    &lt;p&gt;Network error mid-task&lt;/p&gt;
    &lt;p&gt;Current iteration throws. Session marked failed. Checkpoint preserves messages up to that point.&lt;/p&gt;
    &lt;head rend="h3"&gt;Context limits&lt;/head&gt;
    &lt;p&gt;Agent sessions can extend indefinitely, but context windows don't. Design for bounded context:&lt;/p&gt;
    &lt;p&gt;Tools should support iterative refinement (summary ‚Üí detail ‚Üí full) rather than all-or-nothing&lt;/p&gt;
    &lt;p&gt;Give agents a way to consolidate learnings mid-session ("summarize what I've learned and continue")&lt;/p&gt;
    &lt;p&gt;Assume context will eventually fill up‚Äîdesign for it from the start&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation patterns&lt;/head&gt;
    &lt;head rend="h3"&gt;Shared workspace&lt;/head&gt;
    &lt;p&gt;Agents and users should work in the same data space, not separate sandboxes.&lt;/p&gt;
    &lt;code&gt;UserData/
‚îú‚îÄ‚îÄ notes/           ‚Üê Both agent and user read/write here
‚îú‚îÄ‚îÄ projects/        ‚Üê Agent can organize, user can override
‚îî‚îÄ‚îÄ preferences.md   ‚Üê Agent reads, user can edit&lt;/code&gt;
    &lt;head rend="h4"&gt;Benefits:&lt;/head&gt;
    &lt;p&gt;Users can inspect and modify agent work&lt;/p&gt;
    &lt;p&gt;Agents can build on what users create&lt;/p&gt;
    &lt;p&gt;No synchronization layer needed&lt;/p&gt;
    &lt;p&gt;Complete transparency&lt;/p&gt;
    &lt;p&gt;This should be the default. Sandbox only when there's a specific need (security, preventing corruption of critical data).&lt;/p&gt;
    &lt;head rend="h3"&gt;Context injection&lt;/head&gt;
    &lt;p&gt;The agent needs to know what it's working with. System prompts should include:&lt;/p&gt;
    &lt;head rend="h4"&gt;Available resources&lt;/head&gt;
    &lt;code&gt;## Available Data
- 12 notes in /notes
- Most recent: "Project kickoff"
- three projects in /projects
- Preferences at /preferences.md&lt;/code&gt;
    &lt;head rend="h4"&gt;Capabilities&lt;/head&gt;
    &lt;code&gt;## What You Can Do
- Create, edit, tag, delete notes
- Organize files into projects
- Search across all content
- Set reminders (write_file)&lt;/code&gt;
    &lt;head rend="h4"&gt;Recent activity&lt;/head&gt;
    &lt;code&gt;## Recent Context
- User created "Project kickoff"
  note (two hours ago)
- User asked about Q3 deadlines
  yesterday&lt;/code&gt;
    &lt;p&gt;For long sessions, provide a way to refresh context so the agent stays current.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agent-to-UI communication&lt;/head&gt;
    &lt;p&gt;When agents act, the UI should reflect it immediately. Event types for chat integration:&lt;/p&gt;
    &lt;code&gt;enum AgentEvent {
    case thinking(String)        // ‚Üí Show as thinking indicator
    case toolCall(String, String) // ‚Üí Show tool being used
    case toolResult(String)       // ‚Üí Show result (optional)
    case textResponse(String)     // ‚Üí Stream to chat
    case statusChange(Status)     // ‚Üí Update status bar
}&lt;/code&gt;
    &lt;p&gt;The key: no silent actions. Agent changes should be visible immediately.&lt;/p&gt;
    &lt;head rend="h4"&gt;Real-time progress:&lt;/head&gt;
    &lt;p&gt;Show thinking progress (what the agent is considering)&lt;/p&gt;
    &lt;p&gt;Show current tool being executed&lt;/p&gt;
    &lt;p&gt;Stream text incrementally as it's generated&lt;/p&gt;
    &lt;p&gt;Update task list progress in real-time&lt;/p&gt;
    &lt;head rend="h4"&gt;Communication patterns:&lt;/head&gt;
    &lt;p&gt;Shared data store (recommended)&lt;/p&gt;
    &lt;p&gt;File system observation&lt;/p&gt;
    &lt;p&gt;Event system (more decoupled, more complexity)&lt;/p&gt;
    &lt;p&gt;Some tools are noisy; consider an &lt;code&gt;ephemeralToolCalls&lt;/code&gt; flag to hide internal checks while still showing meaningful actions.&lt;/p&gt;
    &lt;p&gt;Silent agents feel broken. Visible progress builds trust.&lt;/p&gt;
    &lt;head rend="h2"&gt;Product implications&lt;/head&gt;
    &lt;p&gt;Agent-native architecture has consequences for how products feel, not just how they're built.&lt;/p&gt;
    &lt;head rend="h3"&gt;Progressive disclosure&lt;/head&gt;
    &lt;p&gt;Simple to start but endlessly powerful. Basic requests work immediately. Power users can push in unexpected directions.&lt;/p&gt;
    &lt;p&gt;Excel is the canonical example: grocery list or financial model, same tool. Claude Code has this quality too. The interface stays simple; capability scales with the ask.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Simple entry: basic requests work with no learning curve&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Discoverable depth: users find new power as they explore&lt;/item&gt;
      &lt;item&gt;‚Ä¢ No ceiling: power users push beyond what you anticipated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The agent meets users where they are.&lt;/p&gt;
    &lt;head rend="h3"&gt;Latent demand discovery&lt;/head&gt;
    &lt;p&gt;Build a capable foundation. Observe what users ask the agent to do. Formalize the patterns that emerge. You're discovering, not guessing.&lt;/p&gt;
    &lt;p&gt;Traditional product development: Imagine what users want, build it, see if you're right.&lt;/p&gt;
    &lt;p&gt;Agent-native product development: Build a capable foundation, observe what users ask the agent to do, formalize the patterns that emerge.&lt;/p&gt;
    &lt;p&gt;When users ask the agent for something and it succeeds, that's signal. When they ask and it fails, that's also signal‚Äîit reveals a gap in your tools or parity.&lt;/p&gt;
    &lt;p&gt;Over time, you can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Add domain tools for common patterns (makes them faster and more reliable)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Create dedicated prompts for frequent requests (makes them more discoverable)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Remove tools that aren't being used (simplifies the system)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The agent becomes a research instrument for understanding what your users actually need.&lt;/p&gt;
    &lt;head rend="h3"&gt;Approval and user agency&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;This framework is a contribution from Claude that emerged from the process of building a few of the apps at Every. But it hasn't been battle-tested and Dan is still forming his opinion here.&lt;/p&gt;
    &lt;p&gt;When agents take unsolicited actions‚Äîdoing things on their own rather than responding to explicit requests‚Äîyou need to decide how much autonomy to grant. Consider stakes and reversibility:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Stakes&lt;/cell&gt;
        &lt;cell role="head"&gt;Reversibility&lt;/cell&gt;
        &lt;cell role="head"&gt;Pattern&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Easy&lt;/cell&gt;
        &lt;cell&gt;Auto-apply&lt;/cell&gt;
        &lt;cell&gt;Organizing files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Hard&lt;/cell&gt;
        &lt;cell&gt;Quick confirm&lt;/cell&gt;
        &lt;cell&gt;Publishing to feed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;Easy&lt;/cell&gt;
        &lt;cell&gt;Suggest + apply&lt;/cell&gt;
        &lt;cell&gt;Code changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;Hard&lt;/cell&gt;
        &lt;cell&gt;Explicit approval&lt;/cell&gt;
        &lt;cell&gt;Sending emails&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: This applies to unsolicited agent actions. If the user explicitly asks the agent to do something ("send that email"), that's already approval‚Äîthe agent just does it.&lt;/p&gt;
    &lt;p&gt;Self-modification should be legible&lt;/p&gt;
    &lt;p&gt;When agents can modify their own behavior‚Äîchanging prompts, updating preferences, adjusting workflows‚Äîthe goals are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Visibility into what changed&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Understanding the effects&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Ability to roll back&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Approval flows are one way to achieve this. Audit logs with easy rollback could be another. The principle is: Make it legible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mobile&lt;/head&gt;
    &lt;p&gt;Mobile is a first-class platform for agent-native apps. It has unique constraints and opportunities.&lt;/p&gt;
    &lt;p&gt;Agents can work with files naturally, using the same primitives that work everywhere else.&lt;/p&gt;
    &lt;p&gt;A walled garden you get access to. Health data, location, photos, calendars‚Äîcontext that doesn't exist on desktop or web.&lt;/p&gt;
    &lt;p&gt;Everyone has their own copy of the app. Apps that modify themselves, fork themselves, evolve per-user.&lt;/p&gt;
    &lt;p&gt;With iCloud, all devices share the same file system. Agent's work appears on all devices‚Äîwithout a server.&lt;/p&gt;
    &lt;head rend="h3"&gt;The challenge&lt;/head&gt;
    &lt;p&gt;Agents are long-running. Mobile apps are not.&lt;/p&gt;
    &lt;p&gt;An agent might need 30 seconds, five minutes, or an hour to complete a task. But iOS will background your app after seconds of inactivity, and may kill it entirely to reclaim memory. The user might switch apps, take a call, or lock their phone mid-task.&lt;/p&gt;
    &lt;p&gt;This means mobile agent apps need a well-thought-out approach to:&lt;/p&gt;
    &lt;p&gt;Checkpointing&lt;/p&gt;
    &lt;p&gt;Saving state so work isn't lost&lt;/p&gt;
    &lt;p&gt;Resuming&lt;/p&gt;
    &lt;p&gt;Picking up where you left off after interruption&lt;/p&gt;
    &lt;p&gt;Background execution&lt;/p&gt;
    &lt;p&gt;Using the limited time iOS gives you wisely&lt;/p&gt;
    &lt;p&gt;On-device vs. cloud&lt;/p&gt;
    &lt;p&gt;Deciding what runs locally vs. what needs a server&lt;/p&gt;
    &lt;head rend="h3"&gt;iOS storage architecture&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;This is an approach we're playing with that we think is exciting, but it's one way to do it. Claude built this; better solutions may exist.&lt;/p&gt;
    &lt;p&gt;What this gives you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Automatic sync across devices without building infrastructure&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Backup without user action&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Graceful degradation when iCloud is unavailable&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Users can access their data outside the app if needed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One approach‚ÄîiCloud-first with local fallback:&lt;/p&gt;
    &lt;code&gt;1. iCloud Container (preferred)
   iCloud.com.{bundleId}/Documents/
   ‚îú‚îÄ‚îÄ Library/
   ‚îú‚îÄ‚îÄ Research/books/
   ‚îú‚îÄ‚îÄ Chats/
   ‚îî‚îÄ‚îÄ Profile/

2. Local Documents (fallback)
   ~/Documents/

3. Migration layer
   Auto-migrate local ‚Üí iCloud&lt;/code&gt;
    &lt;code&gt;// iCloud-first with local fallback
if let url = fileManager
  .url(forUbiquityContainerIdentifier: nil) {
  return url.appendingPathComponent("Documents")
}
return fileManager.urls(
  for: .documentDirectory,
  in: .userDomainMask)[0]&lt;/code&gt;
    &lt;head rend="h3"&gt;Checkpoint and resume&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;Claude's contribution from building; Dan is still forming his opinion. This approach seems to work, but better solutions may exist.&lt;/p&gt;
    &lt;p&gt;Mobile apps get interrupted. Agents need to survive this.&lt;/p&gt;
    &lt;p&gt;What to checkpoint:&lt;/p&gt;
    &lt;p&gt;Agent type, messages, iteration count, task list, custom state, timestamp&lt;/p&gt;
    &lt;p&gt;When to checkpoint:&lt;/p&gt;
    &lt;p&gt;On app backgrounding, after each tool result, periodically during long operations&lt;/p&gt;
    &lt;p&gt;Resume flow:&lt;/p&gt;
    &lt;p&gt;Load interrupted sessions ‚Üí Filter by validity (one-hour default) ‚Üí Show resume prompt ‚Üí Restore messages and continue&lt;/p&gt;
    &lt;p&gt;Resume steps:&lt;/p&gt;
    &lt;p&gt;1. loadInterruptedSessions() scans checkpoint directory&lt;/p&gt;
    &lt;p&gt;2. filter by isValid(maxAge:)&lt;/p&gt;
    &lt;p&gt;3. show resume prompt&lt;/p&gt;
    &lt;p&gt;4. restore messages and continue agent loop&lt;/p&gt;
    &lt;p&gt;5. on dismiss, delete checkpoint&lt;/p&gt;
    &lt;code&gt;struct AgentCheckpoint: Codable {
  let agentType: String
  let messages: [[String: Any]]
  let iterationCount: Int
  let taskListJSON: String?
  let customState: [String: String]
  let timestamp: Date
}

func isValid(maxAge: TimeInterval = 3600)
  -&amp;gt; Bool {
  Date().timeIntervalSince(timestamp)
    &amp;lt; maxAge
}&lt;/code&gt;
    &lt;p&gt;Architecture decision: Store full agent configuration, or store only &lt;code&gt;agentType&lt;/code&gt; and recreate from a registry. The latter is simpler but means configs can break old checkpoints.&lt;/p&gt;
    &lt;p&gt;The gap: If the system kills the app, recovery depends on checkpoint frequency. Checkpoint after each tool result for maximum robustness.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cloud file states&lt;/head&gt;
    &lt;p&gt;Files may exist in iCloud but not be downloaded locally. Ensure availability before reading.&lt;/p&gt;
    &lt;code&gt;await StorageService.shared
    .ensureDownloaded(folder: .research,
                      filename: "full_text.txt")&lt;/code&gt;
    &lt;head rend="h3"&gt;Storage abstraction&lt;/head&gt;
    &lt;p&gt;Use a storage abstraction layer. Don't use raw FileManager. Abstract over iCloud vs. local so the rest of your code doesn't care.&lt;/p&gt;
    &lt;code&gt;let url = StorageService.shared
    .url(for: .researchBook(bookId: id))&lt;/code&gt;
    &lt;head rend="h3"&gt;Background execution&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;Claude's contribution from building; Dan is still forming his opinion.&lt;/p&gt;
    &lt;p&gt;iOS gives you limited background time:&lt;/p&gt;
    &lt;code&gt;func prepareForBackground() {
    backgroundTaskId = UIApplication.shared
        .beginBackgroundTask(withName: "AgentProcessing") {
            handleBackgroundTimeExpired()
        }
}

func handleBackgroundTimeExpired() {
    for session in sessions where session.status == .running {
        session.status = .backgrounded
        Task { await saveSession(session) }
    }
}

func handleForeground() {
    for session in sessions where session.status == .backgrounded {
        Task { await resumeSession(session) }
    }
}&lt;/code&gt;
    &lt;p&gt;You get roughly 30 seconds. Use it to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Complete the current tool call if possible&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Checkpoint the session state&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Transition gracefully to backgrounded state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For truly long-running agents: Consider a server-side orchestrator that can run for hours, with the mobile app as a viewer and input mechanism.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device vs. cloud&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device&lt;/cell&gt;
        &lt;cell role="head"&gt;Cloud&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Orchestration&lt;/cell&gt;
        &lt;cell&gt;‚úì&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Tool execution (files, photos, HealthKit)&lt;/cell&gt;
        &lt;cell&gt;‚úì&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LLM calls&lt;/cell&gt;
        &lt;cell&gt;‚úì (Anthropic API)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Checkpoints&lt;/cell&gt;
        &lt;cell&gt;‚úì (local files)&lt;/cell&gt;
        &lt;cell&gt;Optional via iCloud&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Long-running agents&lt;/cell&gt;
        &lt;cell&gt;Limited by iOS&lt;/cell&gt;
        &lt;cell&gt;Possible with server&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The app needs network for reasoning but can access data offline. Design tools to degrade gracefully when network is unavailable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced patterns&lt;/head&gt;
    &lt;head rend="h3"&gt;Dynamic capability discovery&lt;/head&gt;
    &lt;p&gt;Needs validation&lt;/p&gt;
    &lt;p&gt;Claude's contribution from building; Dan is still forming his opinion. This is one approach we're excited about, but others may be better depending on your use case.&lt;/p&gt;
    &lt;p&gt;One alternative to building a tool for each endpoint in an external API: Build tools that let the agent discover what's available at runtime.&lt;/p&gt;
    &lt;p&gt;The problem with static mapping:&lt;/p&gt;
    &lt;code&gt;// You built 50 tools for 50 data types
read_steps()
read_heart_rate()
read_sleep()
// When a new metric is added... code change required
// Agent can only access what you anticipated&lt;/code&gt;
    &lt;p&gt;Dynamic capability discovery:&lt;/p&gt;
    &lt;code&gt;// Two tools handle everything
list_available_types() ‚Üí returns ["steps", "heart_rate", "sleep", ...]
read_data(type) ‚Üí reads any discovered type

// When a new metric is added... agent discovers it automatically
// Agent can access things you didn't anticipate&lt;/code&gt;
    &lt;p&gt;This is granularity taken to its logical conclusion. Your tools become so atomic that they work with types you didn't know existed when you built them.&lt;/p&gt;
    &lt;head rend="h4"&gt;When to use this:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ External APIs where you want the agent to have full user-level access (HealthKit, HomeKit, GraphQL endpoints)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Systems that add new capabilities over time&lt;/item&gt;
      &lt;item&gt;‚Ä¢ When you want the agent to be able to do anything the API supports&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;When static mapping is fine:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Intentionally constrained agents with limited scope&lt;/item&gt;
      &lt;item&gt;‚Ä¢ When you need tight control over exactly what the agent can access&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Simple APIs with stable, well-known endpoints&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The pattern: one tool to discover what's available, one tool to interact with any discovered capability. Let the API validate inputs rather than duplicating validation in your enum definitions.&lt;/p&gt;
    &lt;head rend="h3"&gt;CRUD completeness&lt;/head&gt;
    &lt;p&gt;For every entity in your system, verify the agent has full create, read, update, delete (CRUD) capability:&lt;/p&gt;
    &lt;p&gt;Can the agent make new instances?&lt;/p&gt;
    &lt;p&gt;Can the agent see what exists?&lt;/p&gt;
    &lt;p&gt;Can the agent modify instances?&lt;/p&gt;
    &lt;p&gt;Can the agent remove instances?&lt;/p&gt;
    &lt;p&gt;The audit: List every entity in your system and verify all four operations are available to the agent.&lt;/p&gt;
    &lt;p&gt; Common failure: You build &lt;code&gt;create_note&lt;/code&gt; and &lt;code&gt;read_notes&lt;/code&gt; but forget &lt;code&gt;update_note&lt;/code&gt; and &lt;code&gt;delete_note&lt;/code&gt;. User asks the agent to "fix that typo in my meeting notes" and the agent can't help.
              &lt;/p&gt;
    &lt;head rend="h2"&gt;Anti-patterns&lt;/head&gt;
    &lt;head rend="h3"&gt;Common approaches that aren't fully agent-native&lt;/head&gt;
    &lt;p&gt;These aren't necessarily wrong‚Äîthey may be appropriate for your use case. But they're worth recognizing as different from the architecture this document describes.&lt;/p&gt;
    &lt;head rend="h4"&gt;Agent as router&lt;/head&gt;
    &lt;p&gt;The agent figures out what the user wants, then calls the right function. The agent's intelligence is used to route, not to act. This can work, but you're using a fraction of what agents can do.&lt;/p&gt;
    &lt;head rend="h4"&gt;Build the app, then add agent&lt;/head&gt;
    &lt;p&gt;You build features the traditional way (as code), then expose them to an agent. The agent can only do what your features already do. You won't get emergent capability.&lt;/p&gt;
    &lt;head rend="h4"&gt;Request/response thinking&lt;/head&gt;
    &lt;p&gt;Agent gets input, does one thing, returns output. This misses the loop: Agent gets an outcome to achieve, operates until it's done, handles unexpected situations along the way.&lt;/p&gt;
    &lt;head rend="h4"&gt;Defensive tool design&lt;/head&gt;
    &lt;p&gt;You over-constrain tool inputs because you're used to defensive programming. Strict enums, validation at every layer. This is safe, but it prevents the agent from doing things you didn't anticipate.&lt;/p&gt;
    &lt;head rend="h4"&gt;Happy path in code, agent just executes&lt;/head&gt;
    &lt;p&gt;Traditional software handles edge cases in code‚Äîyou write the logic for what happens when X goes wrong. Agent-native lets the agent handle edge cases with judgment. If your code handles all the edge cases, the agent is just a caller.&lt;/p&gt;
    &lt;head rend="h3"&gt;Specific anti-patterns&lt;/head&gt;
    &lt;head rend="h4"&gt;Agent executes your workflow instead of pursuing outcomes&lt;/head&gt;
    &lt;p&gt;You wrote the logic, agent just calls it. Decisions live in code, not agent judgment.&lt;/p&gt;
    &lt;code&gt;# Wrong - you wrote the workflow
def process_request(input):
    category = categorize(input)      # your code decides
    priority = score_priority(input)   # your code decides
    store(input, category, priority)
    if priority &amp;gt; 3: notify()          # your code decides

# Right - agent pursues outcome in a loop
tools: store_item, send_notification
prompt: "Evaluate urgency 1-5, store with your assessment, notify if &amp;gt;= 4"&lt;/code&gt;
    &lt;head rend="h4"&gt;Workflow-shaped tools&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;analyze_and_organize&lt;/code&gt; bundles judgment into the tool. Break it into primitives and let the agent compose them.&lt;/p&gt;
    &lt;head rend="h4"&gt;Orphan UI actions&lt;/head&gt;
    &lt;p&gt;User can do something through the UI that the agent can't achieve. Fix: Maintain parity.&lt;/p&gt;
    &lt;head rend="h4"&gt;Context starvation&lt;/head&gt;
    &lt;p&gt;Agent doesn't know what exists. User says "organize my notes" and agent doesn't know there are notes.&lt;/p&gt;
    &lt;p&gt;Fix: Inject available resources and capabilities into system prompt.&lt;/p&gt;
    &lt;head rend="h4"&gt;Gates without reason&lt;/head&gt;
    &lt;p&gt;Domain tool is the only way to do something, and you didn't intend to restrict access.&lt;/p&gt;
    &lt;p&gt;Fix: Default to open. Keep primitives available unless there's a specific reason to gate.&lt;/p&gt;
    &lt;head rend="h4"&gt;Artificial capability limits&lt;/head&gt;
    &lt;p&gt;Restricting what the agent can do out of vague safety concerns rather than specific risks.&lt;/p&gt;
    &lt;p&gt;The agent should generally be able to do what users can do. Use approval flows for destructive actions rather than removing capabilities entirely.&lt;/p&gt;
    &lt;head rend="h4"&gt;Static mapping when dynamic would serve better&lt;/head&gt;
    &lt;p&gt;Building 50 tools for 50 API endpoints when a discover + access pattern would give more flexibility and future-proof the system.&lt;/p&gt;
    &lt;head rend="h4"&gt;Heuristic completion detection&lt;/head&gt;
    &lt;p&gt;Detecting agent completion through heuristics (consecutive iterations without tool calls, checking for expected output files) is fragile.&lt;/p&gt;
    &lt;p&gt;Fix: Require agents to explicitly signal completion through a completion tool.&lt;/p&gt;
    &lt;head rend="h2"&gt;Success criteria&lt;/head&gt;
    &lt;head rend="h3"&gt;Architecture&lt;/head&gt;
    &lt;head rend="h3"&gt;Implementation&lt;/head&gt;
    &lt;head rend="h3"&gt;Product&lt;/head&gt;
    &lt;head rend="h3"&gt;Mobile&lt;/head&gt;
    &lt;head rend="h3"&gt;The ultimate test&lt;/head&gt;
    &lt;p&gt;Describe an outcome to the agent that's within your application's domain but that you didn't build a specific feature for.&lt;/p&gt;
    &lt;p&gt;Can it figure out how to accomplish it, operating in a loop until it succeeds?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46855003</guid><pubDate>Mon, 02 Feb 2026 11:59:32 +0000</pubDate></item><item><title>EU must become a 'genuine federation' to avoid deindustrialisation and decline</title><link>https://www.euronews.com/my-europe/2026/02/02/eu-must-become-a-genuine-federation-to-avoid-deindustrialisation-and-decline-draghi-says</link><description>&lt;doc fingerprint="bcde808db1f73f0e"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The former Italian prime minister said the European Union risks subordination, division and deindustrialision all at once if it does not pull closer together.&lt;/head&gt;
    &lt;p&gt;"Europe risks becoming subordinated, divided, and deindustrialised", if it does not turn itself into a "genuine federation", Former Italian Prime Minister and President of the European Central Bank Mario Draghi said in a speech at the Belgian Ku Leuven University on Monday.&lt;/p&gt;
    &lt;p&gt;According to Draghi, "power requires Europe to move from confederation to federation" because the global order is "now defunct".&lt;/p&gt;
    &lt;p&gt;"A world with less trade and weaker rules would be painful," he said.&lt;/p&gt;
    &lt;p&gt;In his speech, delivered as he received an honorary degree from the university, Draghi said he believes that "grouping together small countries does not automatically produce a powerful bloc", and argued that in areas where Europe has "federated" ‚Äì trade, competition, the single market, monetary policy ‚Äì it is "respected as a power and [can] negotiate as one".&lt;/p&gt;
    &lt;p&gt;As evidence, he pointed to the "successful" trade agreements recently negotiated with India and Latin America.&lt;/p&gt;
    &lt;p&gt;"Where we have not ‚Äì on defence, on industrial policy, on foreign affairs ‚Äì we are treated as a loose assembly of middle-sized states, to be divided and dealt with accordingly", Draghi said.&lt;/p&gt;
    &lt;p&gt;"Of all those now caught between the US and China, Europeans alone have the option to become a genuine power themselves. So we must decide: do we remain merely a large market, subject to the priorities of others? Or do we take the steps necessary to become one power?", Draghi asked.&lt;/p&gt;
    &lt;p&gt;"A Europe that cannot defend its interests will not preserve its values for long."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46855059</guid><pubDate>Mon, 02 Feb 2026 12:08:00 +0000</pubDate></item></channel></rss>