<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 11 Jan 2026 15:38:17 +0000</lastBuildDate><item><title>Show HN: I used Claude Code to discover connections between 100 books</title><link>https://trails.pieterma.es/</link><description>&lt;doc fingerprint="f5f22681c15b4f4c"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Useful Lies&lt;/head&gt;
    &lt;p&gt;Self-deception as strategy: the best liars believe themselves.&lt;/p&gt;
    &lt;p&gt;Self-deception as strategy: the best liars believe themselves.&lt;/p&gt;
    &lt;p&gt;Microscopic defects propagate silently until catastrophic failure.&lt;/p&gt;
    &lt;p&gt;The hunt for words that stick&lt;/p&gt;
    &lt;p&gt;Weak IP accelerates innovation through collaborative copying.&lt;/p&gt;
    &lt;p&gt;Constraints in one part dictate the whole.&lt;/p&gt;
    &lt;p&gt;Absent fathers forged titan ambition through unmet longing.&lt;/p&gt;
    &lt;p&gt;Mega-projects orchestrate unreliable elements into coherent wholes.&lt;/p&gt;
    &lt;p&gt;Desperation, not genius, drove transformative pivots.&lt;/p&gt;
    &lt;p&gt;Expertise defies formalization; conscious effort defeats itself.&lt;/p&gt;
    &lt;p&gt;Why isolated groups lose knowledge and capabilities.&lt;/p&gt;
    &lt;p&gt;Protected spaces insulated from interference enable breakthroughs.&lt;/p&gt;
    &lt;p&gt;Practical knowledge defeats rationalized systems.&lt;/p&gt;
    &lt;p&gt;Rule-breaking as path to understanding.&lt;/p&gt;
    &lt;p&gt;Ego-dissolution enables both transcendence and manipulation.&lt;/p&gt;
    &lt;p&gt;Imitation powers both learning and conformity.&lt;/p&gt;
    &lt;p&gt;Winners eliminate competition; victory becomes permanent control.&lt;/p&gt;
    &lt;p&gt;Every treasure becomes tomorrow's ordinary commodity.&lt;/p&gt;
    &lt;p&gt;Metrics become mirages when optimized directly.&lt;/p&gt;
    &lt;p&gt;Rare signals drown in false positives.&lt;/p&gt;
    &lt;p&gt;Silent agreements to avoid uncomfortable truths.&lt;/p&gt;
    &lt;p&gt;Founders ousted through political power dynamics.&lt;/p&gt;
    &lt;p&gt;Mastery means bypassing conscious thought entirely.&lt;/p&gt;
    &lt;p&gt;Removing friction sometimes creates chaos.&lt;/p&gt;
    &lt;p&gt;Organizations minimize coalitions needed to maintain control.&lt;/p&gt;
    &lt;p&gt;Ripe ideas emerge independently across the world.&lt;/p&gt;
    &lt;p&gt;Copying forms without understanding structure guarantees failure.&lt;/p&gt;
    &lt;p&gt;Actions must be expensive to be believed.&lt;/p&gt;
    &lt;p&gt;Gifts, moral debts, and technical debt share logic.&lt;/p&gt;
    &lt;p&gt;Joy became more productive than efficiency optimization.&lt;/p&gt;
    &lt;p&gt;Getting worse precedes getting better in skill.&lt;/p&gt;
    &lt;p&gt;Large coordination emerges from small-scale trust.&lt;/p&gt;
    &lt;p&gt;Standardization enables scale but destroys local knowledge.&lt;/p&gt;
    &lt;p&gt;Method of creation shapes what is created.&lt;/p&gt;
    &lt;p&gt;Open systems consolidate into monopoly, then repeat.&lt;/p&gt;
    &lt;p&gt;Transforming vague concepts into testable frameworks.&lt;/p&gt;
    &lt;p&gt;Building observability changes what you see.&lt;/p&gt;
    &lt;p&gt;Decision-making speed determines conflict outcomes.&lt;/p&gt;
    &lt;p&gt;Simplification enables breakthroughs or destroys value.&lt;/p&gt;
    &lt;p&gt;Knowing what others don't creates competitive advantage.&lt;/p&gt;
    &lt;p&gt;Precise measurement creates infrastructure for distant trust.&lt;/p&gt;
    &lt;p&gt;Container shipping remade global supply chains.&lt;/p&gt;
    &lt;p&gt;Pursuit of perfection prevents completion.&lt;/p&gt;
    &lt;p&gt;Import order constantly or dissolve into disorder.&lt;/p&gt;
    &lt;p&gt;Simplified models systematically fail in complex reality.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46567400</guid><pubDate>Sat, 10 Jan 2026 16:56:55 +0000</pubDate></item><item><title>UpCodes (YC S17) is hiring PMs, SWEs to automate construction compliance</title><link>https://up.codes/careers?utm_source=HN</link><description>&lt;doc fingerprint="f1efd1e76f34fe34"&gt;
  &lt;main&gt;
    &lt;p&gt;Try for Free&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46567458</guid><pubDate>Sat, 10 Jan 2026 17:01:49 +0000</pubDate></item><item><title>Finding and fixing Ghostty's largest memory leak</title><link>https://mitchellh.com/writing/ghostty-memory-leak-fix</link><description>&lt;doc fingerprint="36d8d949fca010a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Finding and Fixing Ghostty's Largest Memory Leak&lt;/head&gt;
    &lt;p&gt;A few months ago, users started reporting that Ghostty was consuming absurd amounts of memory, with one user reporting 37 GB after 10 days of uptime. Today, I'm happy to say the fix has been found and merged. This post is an overview of what caused the leak, a look at some of Ghostty's internals, and some brief descriptions of how we tracked it down.1&lt;/p&gt;
    &lt;p&gt;The leak was present since at least Ghostty 1.0, but it is only recently that popular CLI applications (particularly Claude Code) started producing the correct conditions to trigger it at scale. The limited conditions that triggered the leak are what made it particularly tricky to diagnose.&lt;/p&gt;
    &lt;p&gt;The fix is merged and is available in tip/nightly releases, and will be part of the tagged 1.3 release in March.&lt;/p&gt;
    &lt;head rend="h2"&gt;The PageList&lt;/head&gt;
    &lt;p&gt;To understand the bug, we first need to understand how Ghostty manages terminal memory. Ghostty uses a data structure called the &lt;code&gt;PageList&lt;/code&gt;
to store terminal content. PageList is a doubly-linked list of
memory pages that store the terminal content (characters, styles, hyperlinks,
etc.).&lt;/p&gt;
    &lt;p&gt;The underlying "pages" are not single virtual memory pages but they are a contiguous block of memory aligned to page boundaries and composed of an even multiple of system pages.2&lt;/p&gt;
    &lt;p&gt;These pages are allocated using &lt;code&gt;mmap&lt;/code&gt;. &lt;code&gt;mmap&lt;/code&gt; isn't particularly fast,
so to avoid constant syscalls, we use a memory pool. When we need
a new page, we pull from the pool. When we're done with a page, we return
it to the pool for reuse.&lt;/p&gt;
    &lt;p&gt;The pool uses a standard size for pages. Think of it like buying standard-sized shipping boxes: most things people ship fit in a standard box, and having a standard box comes with various efficiencies.&lt;/p&gt;
    &lt;p&gt;But sometimes terminals need more memory than a standard page provides. If a set of lines has many emoji, styles, or hyperlinks, we need a larger page. In these cases, we allocate a non-standard page directly with &lt;code&gt;mmap&lt;/code&gt;, bypassing the pool entirely. This is typically a
rare scenario.&lt;/p&gt;
    &lt;p&gt;When we "free" a page, we apply some simple logic:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If the page is &lt;code&gt;&amp;lt;= standard size&lt;/code&gt;: return it to the pool&lt;/item&gt;
      &lt;item&gt;If the page is &lt;code&gt;&amp;gt; standard size&lt;/code&gt;: call&lt;code&gt;munmap&lt;/code&gt;to free it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is the core background for terminal memory management in Ghostty, and the idea itself is sound. A logic bug around an optimization is what produced the leak, as we'll see next.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Scrollback Optimization&lt;/head&gt;
    &lt;p&gt;There's one more background detail we need to cover to understand the bug: scrollback pruning.&lt;/p&gt;
    &lt;p&gt;Ghostty has a &lt;code&gt;scrollback-limit&lt;/code&gt; configuration that caps how much history
is retained. When you hit this limit, we delete the oldest pages in
the scrollback buffer to free up memory.&lt;/p&gt;
    &lt;p&gt;But this often happens in a super hot path (e.g. when outputting large amounts of data quickly), and allocating and freeing memory pages is expensive, even with the pool. Therefore, we have an optimization: reuse the oldest page as the newest page when we reach the limit.&lt;/p&gt;
    &lt;p&gt;This optimization works great. It requires zero allocations and uses only some quick pointer manipulations to move the page from the front to the back of the list. We do some metadata cleanup to "clear" the page but otherwise leave the previous memory intact.&lt;/p&gt;
    &lt;p&gt;It's fast and empirically speeds up scrollback-heavy workloads significantly.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bug&lt;/head&gt;
    &lt;p&gt;During the scrollback pruning optimization, we always resized our page back to standard size. But we didn't resize the underlying memory allocation itself, we only noted the resize in the metadata. The underlying memory was still the large non-standard &lt;code&gt;mmap&lt;/code&gt; allocation, but now the PageList thought it was standard
sized.&lt;/p&gt;
    &lt;p&gt;Eventually, we'd free the page under various circumstances (e.g. when the user closes the terminal, but also other times). At that point, we'd see the page memory was within the standard size, assume it was part of the pool, and we would never call &lt;code&gt;munmap&lt;/code&gt; on it.
A classic leak.&lt;/p&gt;
    &lt;p&gt;This all seems pretty obvious, but the issue is that non-standard pages are rare by design. The goal of our design and optimizations is that standard pages are the common case and provide a fast-path. Only very specific scenarios produce non-standard pages and they're usually not produced in large quantities.&lt;/p&gt;
    &lt;p&gt;But the rise of Claude Code changed this. For some reason, Claude Code's CLI produces a lot of multi-codepoint grapheme outputs which force Ghostty to regularly use non-standard pages. Additionally, Claude Code uses the primary screen and produces a significant amount of scrollback output. These things combined together created the perfect storm to trigger the leak in huge quantities.&lt;/p&gt;
    &lt;p&gt;I want to be explicit that this bug is not Claude Code's fault. Claude Code is simply exercising Ghostty in a way that exposes this long-standing bug.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fix&lt;/head&gt;
    &lt;p&gt;The fix is conceptually simple: never reuse non-standard pages. If we encounter a non-standard page during scrollback pruning, we destroy it properly (calling &lt;code&gt;munmap&lt;/code&gt;) and allocate a fresh
standard-sized page from the pool.&lt;/p&gt;
    &lt;p&gt;The core of the fix is in the snippet below, but some extra work was needed to fix up some other bits of accounting we have:&lt;/p&gt;
    &lt;code&gt;if (first.data.memory.len &amp;gt; std_size) {
    self.destroyNode(first);
    break :prune;
}
&lt;/code&gt;
    &lt;p&gt;We could've also reused the non-standard page and just retained the large memory size, but until we have data that shows otherwise, we're still operating under the assumption that standard pages are the common case and it makes sense to reset back to a standard pooled page.&lt;/p&gt;
    &lt;p&gt;Other users have recommended more complex strategies (e.g. maintaining some metrics on how often non-standard pages are used and adjusting our assumptions accordingly), but more research is needed before making those changes. This change is simple, fixes the bug, and aligns with our current assumptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding the Leak with VM Tags&lt;/head&gt;
    &lt;p&gt;As part of the fix, I added support for virtual memory tags on macOS provided by the Mach kernel. This lets us tag our PageList memory allocations with a specific identifier that shows up in various tooling.&lt;/p&gt;
    &lt;code&gt;inline fn pageAllocator() Allocator {
    // In tests we use our testing allocator so we can detect leaks.
    if (builtin.is_test) return std.testing.allocator;

    // On non-macOS we use our standard Zig page allocator.
    if (!builtin.target.os.tag.isDarwin()) return std.heap.page_allocator;

    // On macOS we want to tag our memory so we can assign it to our
    // core terminal usage.
    const mach = @import("../os/mach.zig");
    return mach.taggedPageAllocator(.application_specific_1);
}
&lt;/code&gt;
    &lt;p&gt;Now when debugging memory on macOS, Ghostty's PageList memory shows up with a specific tag instead of being lumped in with everything else. This made it trivial to identify the leak, associate it with the PageList, and also verify that the fix worked by observing the tagged memory being properly freed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preventing Leaks in Ghostty&lt;/head&gt;
    &lt;p&gt;We do a lot of work in the Ghostty project to find and prevent memory leaks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In debug builds and unit tests, we use leak-detecting Zig allocators.&lt;/item&gt;
      &lt;item&gt;The CI runs &lt;code&gt;valgrind&lt;/code&gt;on our full unit test suite on every commit to find more than just leaks, such as undefined memory usage.&lt;/item&gt;
      &lt;item&gt;We regularly run the macOS GUI via macOS Instruments to look for leaks particularly in the Swift codebase.&lt;/item&gt;
      &lt;item&gt;We run every GTK-related PR using Valgrind (the full GUI) to look for leaks in the GTK codepath that isn't unit tested.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This has worked really well to date, but unfortunately it didn't catch this particular leak because it only triggers under very specific conditions that our tests didn't reproduce. The merged PR includes a test that does reproduce the leak to prevent regressions in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This was the largest known memory leak in Ghostty to date, and the only reported leak that has been confirmed by more than a single user. We'll continue to monitor and address memory reports as they come in, but remember that reproduction is the key to diagnosing and fixing memory leaks!&lt;/p&gt;
    &lt;p&gt;Big thanks to @grishy who finally got me a reliable reproduction so I could analyze the issue myself. Their own analysis reached the same conclusion as mine, and the reproduction let me verify both our understandings independently.&lt;/p&gt;
    &lt;p&gt;Thanks also to everyone who reported this issue with detailed diagnostics. The community's analysis, especially around the &lt;code&gt;footprint&lt;/code&gt; output and
VM region counting, gave me important clues that pointed toward the PageList
as the culprit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46568794</guid><pubDate>Sat, 10 Jan 2026 18:58:37 +0000</pubDate></item><item><title>Show HN: Play poker with LLMs, or watch them play against each other</title><link>https://llmholdem.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46569061</guid><pubDate>Sat, 10 Jan 2026 19:27:39 +0000</pubDate></item><item><title>Overdose deaths are falling in America because of a 'supply shock': study</title><link>https://www.economist.com/united-states/2026/01/08/why-overdose-deaths-are-falling-in-america</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46569312</guid><pubDate>Sat, 10 Jan 2026 19:54:49 +0000</pubDate></item><item><title>Show HN: Ferrite â€“ Markdown editor in Rust with native Mermaid diagram rendering</title><link>https://github.com/OlaProeis/Ferrite</link><description>&lt;doc fingerprint="2704389f7bb59d9e"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast, lightweight text editor for Markdown, JSON, YAML, and TOML files. Built with Rust and egui for a native, responsive experience.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;âš ï¸&lt;/g-emoji&gt;Platform Note: Ferrite has been primarily developed and tested on Windows. While it should work on Linux and macOS, these platforms have not been extensively tested. If you encounter issues, please report them.&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;ğŸ¤– AI Disclosure: This project is 100% AI-generated code. All Rust code, documentation, and configuration was written by Claude (Anthropic) via Cursor with MCP tools. My role is product direction, testing, and learning to orchestrate AI-assisted development effectively. The code is reviewed and tested, not blindly accepted â€” but I want to be transparent about the development process. This project is partly a learning exercise in exploring how far AI-assisted development can go.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Raw Editor&lt;/cell&gt;
        &lt;cell role="head"&gt;Rendered View&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Split View&lt;/cell&gt;
        &lt;cell role="head"&gt;Zen Mode&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WYSIWYG Markdown Editing - Edit markdown with live preview, click-to-edit formatting, and syntax highlighting&lt;/item&gt;
      &lt;item&gt;Multi-Format Support - Native support for Markdown, JSON, YAML, and TOML files&lt;/item&gt;
      &lt;item&gt;Tree Viewer - Hierarchical view for JSON/YAML/TOML with inline editing, expand/collapse, and path copying&lt;/item&gt;
      &lt;item&gt;Find &amp;amp; Replace - Search with regex support and match highlighting&lt;/item&gt;
      &lt;item&gt;Undo/Redo - Full undo/redo support per tab&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Split View - Side-by-side raw editor and rendered preview with resizable divider&lt;/item&gt;
      &lt;item&gt;Zen Mode - Distraction-free writing with centered text column&lt;/item&gt;
      &lt;item&gt;Sync Scrolling - Bidirectional scroll sync between raw and rendered views&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syntax Highlighting - Full-file syntax highlighting for 40+ languages (Rust, Python, JavaScript, Go, etc.)&lt;/item&gt;
      &lt;item&gt;Code Folding - Fold detection with gutter indicators (â–¶/â–¼) for headings, code blocks, and lists (text hiding deferred to v0.3.0)&lt;/item&gt;
      &lt;item&gt;Minimap - VS Code-style navigation panel with click-to-jump and search highlights&lt;/item&gt;
      &lt;item&gt;Bracket Matching - Highlight matching brackets &lt;code&gt;()[]{}&amp;lt;&amp;gt;&lt;/code&gt;and emphasis pairs&lt;code&gt;**&lt;/code&gt;&lt;code&gt;__&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Auto-Save - Configurable auto-save with temp-file safety&lt;/item&gt;
      &lt;item&gt;Line Numbers - Optional line number gutter&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Native rendering of 11 diagram types directly in the preview:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flowchart, Sequence, Pie, State, Mindmap&lt;/item&gt;
      &lt;item&gt;Class, ER, Git Graph, Gantt, Timeline, User Journey&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;âœ¨ v0.2.2 Released: Stability &amp;amp; CLI improvements! CJK font support, undo/redo fixes, command-line file opening (&lt;/p&gt;&lt;code&gt;ferrite file.md&lt;/code&gt;), configurable log level, and default view mode setting. See CHANGELOG.md for full details.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workspace Mode - Open folders with file tree, quick switcher (Ctrl+P), and search-in-files (Ctrl+Shift+F)&lt;/item&gt;
      &lt;item&gt;Git Integration - Visual status indicators showing modified, added, untracked, and ignored files&lt;/item&gt;
      &lt;item&gt;Session Persistence - Restore open tabs, cursor positions, and scroll offsets on restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Light &amp;amp; Dark Themes - Beautiful themes with runtime switching&lt;/item&gt;
      &lt;item&gt;Document Outline - Navigate large documents with the outline panel&lt;/item&gt;
      &lt;item&gt;Export Options - Export to HTML with themed styling, or copy as HTML&lt;/item&gt;
      &lt;item&gt;Formatting Toolbar - Quick access to bold, italic, headings, lists, links, and more&lt;/item&gt;
      &lt;item&gt;Live Pipeline - Pipe JSON/YAML content through shell commands (for developers)&lt;/item&gt;
      &lt;item&gt;Custom Window - Borderless window with custom title bar and resize handles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Download the latest release for your platform from GitHub Releases.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Download&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ferrite-windows-x64.zip&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;ferrite-editor_amd64.deb&lt;/code&gt; (recommended) or &lt;code&gt;ferrite-linux-x64.tar.gz&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ferrite-macos-x64.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Using .deb package (Debian/Ubuntu/Mint - Recommended):&lt;/p&gt;
    &lt;code&gt;# Download the .deb file, then install with:
sudo apt install ./ferrite-editor_amd64.deb

# Or using dpkg:
sudo dpkg -i ferrite-editor_amd64.deb&lt;/code&gt;
    &lt;p&gt;This will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Ferrite to &lt;code&gt;/usr/bin/ferrite&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Add desktop entry (appears in your app menu)&lt;/item&gt;
      &lt;item&gt;Register file associations for &lt;code&gt;.md&lt;/code&gt;,&lt;code&gt;.json&lt;/code&gt;,&lt;code&gt;.yaml&lt;/code&gt;,&lt;code&gt;.toml&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;Install icons for the system&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arch Linux package&lt;/p&gt;
    &lt;p&gt;Ferrite is available on the AUR:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ferrite (release package)&lt;/item&gt;
      &lt;item&gt;Ferrite-bin (binary package)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can install it using your AUR helper of choice.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Release package
yay -Sy ferrite

# Binary package
yay -Sy ferrite-bin&lt;/code&gt;
    &lt;p&gt;Using tar.gz (any Linux distro):&lt;/p&gt;
    &lt;code&gt;tar -xzf ferrite-linux-x64.tar.gz
./ferrite&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust 1.70+ - Install from rustup.rs&lt;/item&gt;
      &lt;item&gt;Platform-specific dependencies:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Windows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visual Studio Build Tools 2019+ with C++ workload&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux:&lt;/p&gt;
    &lt;code&gt;# Ubuntu/Debian
sudo apt install build-essential pkg-config libgtk-3-dev libxcb-shape0-dev libxcb-xfixes0-dev

# Fedora
sudo dnf install gcc pkg-config gtk3-devel libxcb-devel

# Arch
sudo pacman -S base-devel pkg-config gtk3 libxcb&lt;/code&gt;
    &lt;p&gt;macOS:&lt;/p&gt;
    &lt;code&gt;xcode-select --install&lt;/code&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/OlaProeis/Ferrite.git
cd Ferrite

# Build release version (optimized)
cargo build --release

# The binary will be at:
# Windows: target/release/ferrite.exe
# Linux/macOS: target/release/ferrite&lt;/code&gt;
    &lt;code&gt;# Run from source
cargo run --release

# Or run the binary directly
./target/release/ferrite

# Open a specific file
./target/release/ferrite path/to/file.md

# Open multiple files as tabs
./target/release/ferrite file1.md file2.md

# Open a folder as workspace
./target/release/ferrite path/to/folder/

# Show version
./target/release/ferrite --version

# Show help
./target/release/ferrite --help&lt;/code&gt;
    &lt;p&gt;See docs/cli.md for full CLI documentation.&lt;/p&gt;
    &lt;p&gt;Ferrite supports three view modes for Markdown files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raw - Plain text editing with syntax highlighting&lt;/item&gt;
      &lt;item&gt;Rendered - WYSIWYG editing with rendered markdown&lt;/item&gt;
      &lt;item&gt;Split - Side-by-side raw editor and live preview&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Toggle between modes using the toolbar buttons or keyboard shortcuts.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+N&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;New file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+O&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+S&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Save file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+S&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Save as&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+W&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close tab&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Tab&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Next tab&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+Tab&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Previous tab&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quick file switcher (workspace)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+F&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search in files (workspace)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Z&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Undo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;Ctrl+Y&lt;/code&gt; / &lt;code&gt;Ctrl+Shift+Z&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Redo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+F&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+H&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find and replace&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+B&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bold&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+I&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Italic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+K&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Insert link&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;F11&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle fullscreen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+,&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+[&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fold all&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Unfold all&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Settings are stored in platform-specific locations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows: &lt;code&gt;%APPDATA%\ferrite\&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;code&gt;~/.config/ferrite/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macOS: &lt;code&gt;~/Library/Application Support/ferrite/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Workspace settings are stored in &lt;code&gt;.ferrite/&lt;/code&gt; within the workspace folder.&lt;/p&gt;
    &lt;p&gt;Access settings via &lt;code&gt;Ctrl+,&lt;/code&gt; or the gear icon. Configure:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Appearance: Theme, font family, font size&lt;/item&gt;
      &lt;item&gt;Editor: Word wrap, line numbers, minimap, bracket matching, code folding, syntax highlighting&lt;/item&gt;
      &lt;item&gt;Files: Auto-save, recent files history&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See ROADMAP.md for planned features and known issues.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please see CONTRIBUTING.md for guidelines.&lt;/p&gt;
    &lt;code&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/Ferrite.git
cd Ferrite

# Create a feature branch
git checkout -b feature/your-feature

# Make changes, then verify
cargo fmt
cargo clippy
cargo test
cargo build

# Commit and push
git commit -m "feat: your feature description"
git push origin feature/your-feature&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Technology&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Rust 1.70+&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GUI Framework&lt;/cell&gt;
        &lt;cell&gt;egui 0.28 + eframe 0.28&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Markdown Parser&lt;/cell&gt;
        &lt;cell&gt;comrak 0.22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Syntax Highlighting&lt;/cell&gt;
        &lt;cell&gt;syntect 5.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Git Integration&lt;/cell&gt;
        &lt;cell&gt;git2 0.19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CLI Parsing&lt;/cell&gt;
        &lt;cell&gt;clap 4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;File Dialogs&lt;/cell&gt;
        &lt;cell&gt;rfd 0.14&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Clipboard&lt;/cell&gt;
        &lt;cell&gt;arboard 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;File Watching&lt;/cell&gt;
        &lt;cell&gt;notify 6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fuzzy Matching&lt;/cell&gt;
        &lt;cell&gt;fuzzy-matcher 0.3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;egui - Immediate mode GUI library for Rust&lt;/item&gt;
      &lt;item&gt;comrak - CommonMark + GFM compatible Markdown parser&lt;/item&gt;
      &lt;item&gt;syntect - Syntax highlighting library&lt;/item&gt;
      &lt;item&gt;git2 - libgit2 bindings for Rust&lt;/item&gt;
      &lt;item&gt;Inter and JetBrains Mono fonts&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude (Anthropic) - AI assistant that wrote the code&lt;/item&gt;
      &lt;item&gt;Cursor - AI-powered code editor&lt;/item&gt;
      &lt;item&gt;Task Master - AI task management for development workflows&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46571980</guid><pubDate>Sun, 11 Jan 2026 01:50:01 +0000</pubDate></item><item><title>A Year of Work on the Arch Linux Package Management (ALPM) Project</title><link>https://devblog.archlinux.page/2026/a-year-of-work-on-the-alpm-project/</link><description>&lt;doc fingerprint="7c1005be86720b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A year of work on the ALPM project&lt;/head&gt;
    &lt;p&gt;In 2024 the Sovereign Tech Fund (STF) started funding work on the ALPM project, which provides a Rust-based framework for Arch Linux Package Management. Refer to the project's FAQ and mission statement to learn more about the relation to the tooling currently in use on Arch Linux.&lt;/p&gt;
    &lt;p&gt;The funding has now concluded, but over the time of 15 months allowed us to create various tools and integrations that we will highlight in the following sections.&lt;/p&gt;
    &lt;p&gt;We have worked on six milestones with focus on various aspects of the package management ecosystem, ranging from formalizing, parsing and writing of file formats, over cryptographic verification of distribution artifacts, to package file and system package management handling:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Formal specifications for packaging data formats"&lt;/item&gt;
      &lt;item&gt;"Basic OpenPGP verification of artifacts"&lt;/item&gt;
      &lt;item&gt;"Rust library for handling of individual packages"&lt;/item&gt;
      &lt;item&gt;"Python bindings for alpm-srcinfo"&lt;/item&gt;
      &lt;item&gt;"Distribution-agnostic OpenPGP stack for the verification of distribution artifacts"&lt;/item&gt;
      &lt;item&gt;"Rust library for system package management"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are considering ourselves as part of a larger free software ecosystem. We believe that it makes sense to create value not only for our own niche, but for the greater good. As such, we focused on finding generic solutions to the technological problems we are facing as a distribution.&lt;/p&gt;
    &lt;p&gt;We are incredibly grateful for the support from STF without which this type of extensive ground work would not have been possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;ALPM stats ğŸ“Š&lt;/head&gt;
    &lt;p&gt;A lot of work has been done over the time of the STF funding. Below are a few statistics about the work done on the ALPM project.&lt;/p&gt;
    &lt;code&gt;$ git shortlog --after="2024-10-01" --summary --numbered
   467  David Runge
   252  Arne Beer
   173  Orhun ParmaksÄ±z
   117  Jagoda ÅšlÄ…zak
    54  renovate
    16  Laura Demkowicz-Duffy
    14  David Schaefer
    10  Christian Heusel
     5  Heiko Schaefer
     4  Morgan Adamiec
     1  Adam Perkowski
     1  Daniel Maslowski
     1  Dominik Peteler
     1  Jakub KlinkovskÃ½
     1  Rafael EpplÃ©e&lt;/code&gt;
    &lt;code&gt;$ tokei
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 Language          Files       Lines        Code    Comments      Blanks
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 BASH                  1          37          21          10           6
 C                     2           9           8           0           1
 C Header              1           2           1           0           1
 CSS                   4        2310        1704         175         431
 FreeMarker           22         922         557           0         365
 JavaScript           16         952         728         104         120
 JSON                  3        1108        1108           0           0
 Just                  3        1444        1072         153         219
 Meson                 1           4           4           0           0
 Python               31        6041        4871          70        1100
 Sass                  1          88          46          30          12
 SVG                  26          26          26           0           0
 Plain Text            4         770           0         615         155
 TOML                 32        1309        1089          81         139
 XML                   2          27          27           0           0
 YAML                  1        1053         798           0         255
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 HTML                 35        1544        1459          34          51
 |- CSS                1           6           6           0           0
 |- JavaScript         5          41          36           2           3
 (Total)                        1591        1501          36          54
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Markdown             95       10253           0        7000        3253
 |- BASH              20        1052         929          40          83
 |- HTML               1          15          10           3           2
 |- INI               10         348         335           5           8
 |- JSON               1          34          34           0           0
 |- Rust              12         769         655          41          73
 |- Shell              2           5           5           0           0
 |- TOML               1         423         197         166          60
 |- YAML               1          17          17           0           0
 (Total)                       12916        2182        7255        3479
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Rust                271       46298       38583        1700        6015
 |- Markdown         235       15360         142       11744        3474
 (Total)                       61658       38725       13444        9489
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 Total               551       92267       54468       21973       15826
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/code&gt;
    &lt;head rend="h2"&gt;Specifications ğŸ“&lt;/head&gt;
    &lt;p&gt;Already in July we reported on the state of the specifications on the devblog and how they enable a deeper, shared view onto our current package management stack in Arch Linux.&lt;/p&gt;
    &lt;p&gt;A lot of custom file formats are in use in our ecosystem. Understanding how to use them is key to maintaining existing and envisioning new technology.&lt;/p&gt;
    &lt;p&gt;Interested developers and package maintainers are encouraged to browse them by file formats or concepts. Meanwhile, the alpm(7) specification provides a good high-level entry-point to the entire topic.&lt;/p&gt;
    &lt;p&gt;We hope this empowers a much larger group of contributors to participate in discussions about the concepts behind Arch Linux's package management. Additionally, we want to enable interested developers to participate in hacking both on the ALPM project itself, as well as make it much easier to experiment with new applications that are built on top of it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Foundational libraries ğŸ“šï¸&lt;/head&gt;
    &lt;p&gt;In the ALPM project we chose a bottom-up, library first approach, in which libraries for basic tasks have been created iteratively in a workspace. As more libraries for specific use-cases emerge, it becomes possible to build more elaborate or special purpose tools with them.&lt;/p&gt;
    &lt;p&gt;We invite interested Rust developers to have a look at the dedicated API documentation to gain a better understanding and overview of the available libraries and their dependencies.&lt;/p&gt;
    &lt;p&gt;The central alpm-types library provides shared low-level types, which are used in some or all file formats used by the Arch Linux package management stack. These common types make it easy to build other, interoperable libraries on top of it.&lt;/p&gt;
    &lt;p&gt;In alpm-common, central traits and utility functionality are made available to other libraries in the workspace.&lt;/p&gt;
    &lt;p&gt;After some consideration and research, we chose the winnow parser combinator library to create parsers for the various custom file formats. Shared functionality for parsers is made available in the alpm-parsers library.&lt;/p&gt;
    &lt;p&gt;Package management systems usually revolve around central dependency resolver functionality. With alpm-solve we have created a new approach to this for Arch Linux, which is based on the generic resolvo library.&lt;/p&gt;
    &lt;p&gt;Compression is an integral part of the packaging workflow. It ensures that an alpm-package(7) or alpm-repo-db(7) file can be transferred over the network as fast as possible by reducing its size. With the alpm-compress library we have implemented extensible (de)compression for these files.&lt;/p&gt;
    &lt;p&gt;To allow extraction of metadata and data files from an alpm-package(7) file, as well as (rudimentary) package creation, we have created the alpm-package crate. With it, it is possible to create package files from prepared input directories (which already contain relevant metadata and data files). In addition, it is possible to effortlessly iterate over the data files contained in a package file and to extract validated metadata.&lt;/p&gt;
    &lt;p&gt;The creation process of an alpm-package(7) file requires to add root-owned files to a directory (e.g. as part of the installation process of an upstream project's build system). However, one does not want to run the package build process as root, but as an unprivileged user. For this purpose we have created the rootless-run library, which generically abstracts running commands "as root" with the help of different backends (e.g. &lt;code&gt;fakeroot(1)&lt;/code&gt; and &lt;code&gt;rootlesskit&lt;/code&gt;).&lt;/p&gt;
    &lt;head rend="h2"&gt;Libraries and command line interfaces ğŸ’»ï¸&lt;/head&gt;
    &lt;p&gt;Based on specifications of file formats currently used in Arch Linux, we have created libraries that allow their parsing, validation and writing.&lt;/p&gt;
    &lt;p&gt;Notably, we distinguish between:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;File formats used in an alpm-source-repo(7) (i.e. SRCINFO(5), PKGBUILD(5)),&lt;/item&gt;
      &lt;item&gt;those in an alpm-repo-db(7) (i.e. alpm-repo-desc(5) and alpm-repo-files(5)),&lt;/item&gt;
      &lt;item&gt;those in an alpm-db(7) (i.e. ALPM-MTREE(5), alpm-db-desc(5) and alpm-db-files(5)) and&lt;/item&gt;
      &lt;item&gt;those in an alpm-package(7) (i.e. ALPM-MTREE(5), BUILDINFO(5) and PKGINFO(5)).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The alpm-srcinfo crate provides a library and command line interface for the parsing, validation and creation of SRCINFO(5) files from PKGBUILD(5) scripts. Due to the dynamic nature of the PKGBUILD(5) scripts, the SRCINFO(5) format is surprisingly complex (both to create and to evaluate). The creation of SRCINFO(5) files from PKGBUILD(5) scripts is enabled via the alpm-pkgbuild-bridge project, the alpm-pkgbuild crate and a translation layer in alpm-srcinfo. We have created dedicated documentation for the aspects of parsing and providing its data from different contexts.&lt;/p&gt;
    &lt;p&gt;The alpm-buildinfo crate provides a library and command line interface for the parsing, validation and creation of BUILDINFO(5) files. This file format is contained in an alpm-package(7) and describes its build environment. In the context of reproducible builds it is used to recreate the build environment.&lt;/p&gt;
    &lt;p&gt;The alpm-mtree crate provides a library and command line interface that allows parsing, validation and creation of ALPM-MTREE(5) files. This file format is a subset of the mtree(5) file format, provided by libarchive. As it can be considered more of a meta language than a data format, we rely on &lt;code&gt;bsdtar(1)&lt;/code&gt; to write that file format.
An ALPM-MTREE(5) file is contained in an alpm-package(7), as well as an entry of an alpm-db(7) and represents a record of all files contained in the package during package creation time.
After installing a package to a system, this file can be used to verify ownership and mode of files installed by the package and detect any missing files.&lt;/p&gt;
    &lt;p&gt;The alpm-pkginfo crate offers a library and command line interface for the parsing, validation and creation of PKGINFO(5) files. This file format is contained in an alpm-package(7) and describes all relevant metadata of a package (e.g. alpm-package-relation(7), alpm-package-name(7), alpm-package-version(7)).&lt;/p&gt;
    &lt;p&gt;Each system based on alpm(7) maintains its state using an alpm-db(7). This state encompasses information on each package:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the contained files (see alpm-db-files(5))&lt;/item&gt;
      &lt;item&gt;general metadata (see alpm-db-desc(5))&lt;/item&gt;
      &lt;item&gt;a record that can be used to validate files of a package (see ALPM-MTREE(5))&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the alpm-db crate, it is possible to parse, validate and create the alpm-db-desc(5) and alpm-db-files(5) file formats. Additionally, we have worked on database access for the alpm-db(7) structure following the ACID characteristics.&lt;/p&gt;
    &lt;p&gt;Packages for compiled languages (e.g. C or C++) usually contain files in the Executable and Linkable Format (ELF). These files may expose soname information which may be used as alpm-package-relation(7) (see alpm-sonamev1(7) and alpm-sonamev2(7) for the two currently understood formats). With the alpm-soname crate we have focused on the handling and extraction of information for the more modern alpm-sonamev2(7) format as well as plain soname information. As a library and CLI, this crate offers easy access to this ELF data, which plays an important role in figuring out the run-time dependencies of packages.&lt;/p&gt;
    &lt;p&gt;Each alpm-repo(7) contains a set of alpm-package(7) files, digital signatures and a package repository database (see alpm-repo-db(7)). An alpm-repo-db(7) tracks information on particular, unique packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the contained files (see alpm-repo-files(5))&lt;/item&gt;
      &lt;item&gt;general metadata (see alpm-repo-desc(5))&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using the alpm-repo-db crate, it is possible to parse, validate and write alpm-repo-desc(5) and alpm-repo-files(5) files. This crate provides both a library and CLI tool. In the future, it will be extended to allow the creation, reading and writing of alpm-repo-db(7) files.&lt;/p&gt;
    &lt;head rend="h2"&gt;Development integration ğŸ‘·&lt;/head&gt;
    &lt;p&gt;To test integration of our libraries against real world data, we have created the dev-scripts crate. It lives in the context of the ALPM project, and is intended as development testbed for assumptions of the various libraries. As such, the crate does not get any releases.&lt;/p&gt;
    &lt;p&gt;The test integration makes it easy to download and prepare live data:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;package source repositories (official and all of the AUR)&lt;/item&gt;
      &lt;item&gt;official binary package repositories&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Currently, it is possible to verify&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SRCINFO(5) files in package source repositories of the official repositories and all of the AUR&lt;/item&gt;
      &lt;item&gt;ALPM-MTREE(5), BUILDINFO(5) and PKGINFO(5) files in binary packages in the official repositories&lt;/item&gt;
      &lt;item&gt;the OpenPGP signatures of all packages in the official repositories&lt;/item&gt;
      &lt;item&gt;alpm-db-desc(5) and alpm-db-files(5) files in the entries of a local alpm-db&lt;/item&gt;
      &lt;item&gt;alpm-repo-desc(5) and alpm-repo-files(5) files in the entries of the alpm-repo-db(7) files of the official repositories&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Python bindings ğŸ&lt;/head&gt;
    &lt;p&gt;We provide Python bindings to make our modern Rust-based parsers and verified types available for use in some other projects of the distribution.&lt;/p&gt;
    &lt;p&gt;Arch Linux's largest Python-based project, with arguably also the largest user-base, is the AURweb, which powers the Arch User Repository (AUR). The web application deals with user input, e.g. via SRCINFO(5) files and currently relies on the native Python library python-srcinfo.&lt;/p&gt;
    &lt;p&gt;(As a sidenote: If you are a Python developer and interested in helping maintain a FastAPI based web application, please reach out to the project! We are always looking for further contributors and maintainers!)&lt;/p&gt;
    &lt;p&gt;The Python bindings for the ALPM project are available on PyPI as python-alpm. With them, we have focused on providing SRCINFO(5) support by relying on the alpm-srcinfo library and by proxy expose a lot of types from the alpm-types library as well.&lt;/p&gt;
    &lt;p&gt;The integration of the python-alpm library into the AURweb application is currently prepared (see aurweb!876).&lt;/p&gt;
    &lt;p&gt;If you are a Python developer and have specific needs for the integration of other libraries of the ALPM project, we would love to hear from you!&lt;/p&gt;
    &lt;head rend="h2"&gt;Linting ğŸ§¶&lt;/head&gt;
    &lt;p&gt;Linters are tools that shift some tedious responsibilities (e.g. quality control) from humans to automation. They are used to automatically detect common mistakes and deviations from established best practices. The goal of linting is to support humans in performing a task well, keeping them on a level with changes in best practices, and empowering them to produce better quality results with less manual effort.&lt;/p&gt;
    &lt;p&gt;The usability and robustness of a distribution like Arch Linux currently relies heavily on the diligence of its package maintainers. Only if package maintainers make an effort to stay up to date with recent developments in packaging (e.g. best practices for languages or PKGBUILD(5) scripts) can the resulting package files maintain a high quality standard.&lt;/p&gt;
    &lt;p&gt;Relying on the written specifications, foundational libraries, as well as libraries and command line interfaces we decided to create a framework for lints, that centrally exposes its knowledge database and allows to flexibly create new rules for various purposes. As such, another central goal of this framework is to provide a single, central tool that covers all aspects of Arch Linux package management.&lt;/p&gt;
    &lt;p&gt;With the alpm-lint crate, a central library and command line interface has been created, that thoroughly documents its architecture and how to add new lint rules. A custom, central website provides details about all currently existing lints, derived from the code documentation of the lint rules: https://alpm.archlinux.page/lints/&lt;/p&gt;
    &lt;p&gt;Using the &lt;code&gt;alpm-lint(1)&lt;/code&gt; CLI, package maintainers are enabled to validate various scopes relevant to packaging (e.g. contents of an alpm-source-repo(7) or an alpm-package(7) file).&lt;/p&gt;
    &lt;p&gt;The crate currently only offers a small set of lints and we encourage interested package maintainers with a background in Rust to write further lints.&lt;/p&gt;
    &lt;head rend="h2"&gt;Translations ğŸŒ&lt;/head&gt;
    &lt;p&gt;We are targeting the English language as first language for the project, but many people that are exposed to its error handling and command line interfaces are not native English speakers, or do not speak the language at all. While writing libraries and command line interfaces for various purposes in the context of the ALPM project we realized that we needed to improve the translation (aka. internationalization or i18n) story of the project.&lt;/p&gt;
    &lt;p&gt;After some research on current technologies used for software translation, we have settled on the fluent framework and created a convenient integration for our purposes with the custom fluent-i18n crate.&lt;/p&gt;
    &lt;p&gt;Interested users can now start translating the project on weblate, following our dedicated contributing guidelines on localizations and translations: https://hosted.weblate.org/projects/alpm/&lt;/p&gt;
    &lt;head rend="h2"&gt;VOA ğŸ”&lt;/head&gt;
    &lt;p&gt;Arch Linux uses OpenPGP for the verification of its packages.&lt;/p&gt;
    &lt;p&gt;The current OpenPGP integration hinges on a central GnuPG-based keyring. This solution suffers from several shortcomings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The keyring is context-independent. It is not possible to represent different verification contexts with it, e.g. package repository metadata that is signed with a different set of keys than those used for signing packages, or packages in unofficial repositories are signed by a different set of keys than those used for the official repositories.&lt;/item&gt;
      &lt;item&gt;The keyring and its behavior is specific to the GnuPG tool, and in part unspecified. The setup cannot be reliably used with other OpenPGP implementations.&lt;/item&gt;
      &lt;item&gt;The keyring is stateful, and while its contents are populated by data from the package for archlinux-keyring, the entire mechanism requires a root-run agent service.&lt;/item&gt;
      &lt;item&gt;The GnuPG upstream has denounced the IETF-driven OpenPGP standardization process and has subsequently been removed from other major package management software such as &lt;code&gt;apt(8)&lt;/code&gt;and&lt;code&gt;rpm(8)&lt;/code&gt;over the last three years. Compatibility with other OpenPGP implementations is no longer guaranteed (see e.g. the ArchWiki article on GnuPG for details)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Already before 2024, the idea emerged to verify digital signatures not with a stateful keyring mechanism, but to instead use a stateless directory structure containing verifiers (see keyringctl#3).&lt;/p&gt;
    &lt;p&gt;This idea was discussed with a set of cross-distribution developers during Image-based Linux Summit 2024 and extended from the initial idea of a lookup directory only for OpenPGP to a more general, technology-agnostic mechanism.&lt;/p&gt;
    &lt;p&gt;In a nutshell, we set out to create a directory structure containing e.g. OpenPGP certificates, SSH pubkeys or X.509 certificates, which clearly describes in what context such verifiers are used when verifying artifacts of a distribution. A more in-depth discussion and rundown of the topic can be found in the talk "Verification of OS artifacts without stateful keyrings" from All Systems Go! 2025.&lt;/p&gt;
    &lt;head rend="h3"&gt;UAPI specification âœï¸&lt;/head&gt;
    &lt;p&gt;In late 2024 we started work on a specification to describe this new, technology-agnostic signature verification mechanism and to collect input from relevant stakeholders in several of the more complex technologies that we wanted to cover.&lt;/p&gt;
    &lt;p&gt;The initial version of the specification "File Hierarchy for the Verification of OS Artifacts (VOA)" has been made available in June 2025 and covers the integration of OpenPGP as a first technology backend.&lt;/p&gt;
    &lt;p&gt;Further technology backend specifications are available as drafts, but need more work to iron out open questions. If you have expertise with the use of SSH, X.509, minisign or signify for the signing of artifacts and have an interest in working on a Rust codebase, please reach out and help stabilize these additional backends!&lt;/p&gt;
    &lt;head rend="h3"&gt;VOA reference implementation âŒ¨ï¸&lt;/head&gt;
    &lt;p&gt;In July 2025 we started work on the VOA project, as a reference implementation of the UAPI specification.&lt;/p&gt;
    &lt;p&gt;Here are some statistics about the project:&lt;/p&gt;
    &lt;code&gt;$ git shortlog --summary --numbered
   190  David Runge
    17  Heiko Schaefer
     3  renovate
     2  David Schaefer&lt;/code&gt;
    &lt;code&gt;$ tokei
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 Language          Files       Lines        Code    Comments      Blanks
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 JSON                  1          16          16           0           0
 Just                  1         849         580         109         160
 Plain Text            4         770           0         615         155
 TOML                 12         364         309          14          41
 YAML                  5         110         110           0           0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Markdown             15        1340           0         847         493
 |- BASH               2         133          30         101           2
 |- Rust               4         200         156          18          26
 |- Shell              1           3           3           0           0
 |- YAML               1          94          94           0           0
 (Total)                        1770         283         966         521
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Rust                 70       13685       11301         478        1906
 |- Markdown          69        2832          29        2229         574
 (Total)                       16517       11330        2707        2480
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 Total               108       20396       12628        4411        3357
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/code&gt;
    &lt;p&gt;Central handling of the VOA hierarchy is implemented in the technology-independent voa-core library. It serves as an abstraction to access verifiers from the filesystem.&lt;/p&gt;
    &lt;p&gt;The use of OpenPGP-specific verifiers has been implemented in the voa-openpgp library. It handles artifact verification based on several different methods:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"plain": Artifacts are verified directly with artifact verifiers, without additional trust anchors. Artifact verifiers can be filtered using OpenPGP fingerprints or domain name matches for OpenPGP User IDs.&lt;/item&gt;
      &lt;item&gt;simple "trust anchor": Artifacts are verified using artifact verifiers, which in turn must be certified by trust anchors. Artifact verifiers can be filtered using domain name matches for OpenPGP User IDs and trust anchors can be filtered using OpenPGP fingerprints. Additionally, the number of required individual certifications for User IDs on each artifact verifier can be specified.&lt;/item&gt;
      &lt;item&gt;"Web of Trust": Artifacts are verified using artifact verifiers, which must reach a sufficient level of trust according to an OpenPGP "Web of Trust" implementation. Artifact verifiers can be filtered using domain name matches for OpenPGP User IDs and trust anchors can be filtered using OpenPGP fingerprints. Additionally, the target trust amount, the trust amount of trusted introducers and the trust amount of filtered trust anchors can be set to a custom value.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Orthogonal to the trust models outlined above, it is possible to specify the required number of independent and valid OpenPGP data signatures per artifact.&lt;/p&gt;
    &lt;p&gt;On Arch Linux we are currently using the Web of Trust implementation that GnuPG offers, on the basis of a GnuPG-specific keyring. However, for all intents and purposes, we are not making use of the features that the full "Web of Trust" model provides. Apart from basic temporal OpenPGP semantics and cryptographic validity, the following rules apply in archlinux-keyring:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There is a set of three or more certificates that serve as trust anchors.&lt;/item&gt;
      &lt;item&gt;There is a set of packager certificates that each must have an OpenPGP User ID with an email that uses the "archlinux.org" domain and has three or more third-party certifications from trust anchors.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So in practice, Arch Linux relies on a "Web of Trust" with exactly one level of indirection, and manually curated sets of trust anchors and artifact verifiers. With voa-openpgp, Arch's verification requirements are best modeled with the simple â€œtrust anchorâ€ model.&lt;/p&gt;
    &lt;p&gt;As an additional feature, we have implemented the import of OpenPGP certificates as verifiers into VOA hierarchies from different sources. The import supports OpenPGP certificates split into OpenPGP packets and the custom directory structure used by archlinux-keyring.&lt;/p&gt;
    &lt;p&gt;With the voa-config library we have added support for a central configuration file format with which settings for VOA technology backends can be supplied. The file format (see voa(5)) allows flexible overrides that specify custom rules for any type of context in an OS.&lt;/p&gt;
    &lt;p&gt;The following configuration describes the current policy for the Arch Linux distribution (see arch.yaml):&lt;/p&gt;
    &lt;code&gt;default_technology_settings:
  openpgp:
    num_data_signatures: 1
    verification_method:
      trust_anchor:
        required_certifications: 3
        artifact_verifier_identity_domain_matches:
          - archlinux.org
        trust_anchor_fingerprint_matches:
          # Levente Polyak (Arch Linux Master Key) &amp;lt;anthraxx@master-key.archlinux.org&amp;gt;
          - d8afdda07a5b6edfa7d8ccdad6d055f927843f1c
          # Leonidas Spyropoulos (Arch Linux Master Key) &amp;lt;artafinde@master-key.archlinux.org&amp;gt;
          - 3572fa2a1b067f22c58af155f8b821b42a6fdcd7
          # Johannes LÃ¶thberg (Arch Linux Master Key) &amp;lt;demize@master-key.archlinux.org&amp;gt;
          - 69e6471e3ae065297529832e6ba0f5a2037f4f41
          # David Runge (Arch Linux Master Key) &amp;lt;dvzrv@master-key.archlinux.org&amp;gt;
          - 2ac0a42efb0b5cbc7a0402ed4dc95b6d7be9892e
          # Florian Pritz (Arch Linux Master Key) &amp;lt;florian@master-key.archlinux.org&amp;gt;
          - 91ffe0700e80619ceb73235ca88e23e377514e00&lt;/code&gt;
    &lt;head rend="h3"&gt;VOA high-level API and CLI ğŸ–¥ï¸&lt;/head&gt;
    &lt;p&gt;In the voa crate we provide a high-level API for consumers of VOA and a command line interface.&lt;/p&gt;
    &lt;p&gt;With &lt;code&gt;voa(1)&lt;/code&gt;, it is possible to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inspect technology backend configuration settings.&lt;/item&gt;
      &lt;item&gt;Import OpenPGP certificates as VOA verifiers.&lt;/item&gt;
      &lt;item&gt;List all VOA verifiers (by OS or specific context).&lt;/item&gt;
      &lt;item&gt;Verify a file using a detached OpenPGP signature and suitable VOA verifiers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All subcommands support JSON output.&lt;/p&gt;
    &lt;p&gt;The following example illustrates the semantics of the default VOA technology backend settings for Arch Linux as shown in the previous section:&lt;/p&gt;
    &lt;code&gt;$ voa config show arch
OpenPGP settings

ğŸ” Each artifact requires 1 valid data signature(s) from artifact verifiers to be successfully verified.

âœ… Each artifact is verified using the "trust anchor" verification method.

ğŸ“§ A valid certificate must have a valid User ID that uses one of the following domains and has 3 certification(s) from individual trust anchors on it for the certificate to be considered as artifact verifier:
â¤· archlinux.org

ğŸ¾ A valid certificate must match one of the following OpenPGP fingerprints to be considered as trust anchor:
â¤· 2ac0a42efb0b5cbc7a0402ed4dc95b6d7be9892e
â¤· 3572fa2a1b067f22c58af155f8b821b42a6fdcd7
â¤· 69e6471e3ae065297529832e6ba0f5a2037f4f41
â¤· 91ffe0700e80619ceb73235ca88e23e377514e00
â¤· d8afdda07a5b6edfa7d8ccdad6d055f927843f1c

ğŸ“ The following sources have been considered for the creation of the settings:
â¤· Config file: /usr/share/voa/arch.yaml
â¤· Built-in defaults&lt;/code&gt;
    &lt;p&gt;After installing the voa-verifiers-arch package, which provides the VOA verifiers used by Arch Linux, it is possible to verify Arch Linux artifacts (e.g. package files) using &lt;code&gt;voa(1)&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ voa verify arch package default openpgp /var/cache/pacman/pkg/shadow-4.18.0-1-x86_64.pkg.tar.zst{,.sig}
âœ… /var/cache/pacman/pkg/shadow-4.18.0-1-x86_64.pkg.tar.zst.sig 1751009927 991f6e3f0765cf6295888586139b09da5bf0d338 62cc73f884e52957b2fdd8839b7a287d9a2ec608&lt;/code&gt;
    &lt;head rend="h3"&gt;Web of Trust and the Berblom algorithm ğŸ•¸ï¸&lt;/head&gt;
    &lt;p&gt;The generalized "Web of Trust" model remains an interesting option in the OpenPGP domain. The "Web of Trust" enables more complex and more nuanced setups than the basic "trust anchor" mode. It also allows for fully decentralized management of trust, without relying on any single authority.&lt;/p&gt;
    &lt;p&gt;Over the course of 2024 and 2025, research has gone into comparing different "Web of Trust" implementations (see wot-observatory). The existing (legacy) implementations have surprising limitations and/or defects when it comes to the calculation of trust. This research led us to the conclusion that instead of relying on existing implementations and designs, a new approach was warranted to overcome the limitations of existing "Web of Trust" subsystems.&lt;/p&gt;
    &lt;p&gt;Our design is highly modular and centers around a pathfinding algorithm named "Berblom". Berblom is a novel and well-documented approach, which serves as a robust, general and efficient way of calculating the trust amount for an artifact verifier.&lt;/p&gt;
    &lt;p&gt;We are excited to integrate Berblom into the VOA reference implementation in 2026.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work ğŸš€&lt;/head&gt;
    &lt;p&gt;We believe the ALPM project succeeded in the goals it set for itself in the funding period with Sovereign Tech Fund.&lt;/p&gt;
    &lt;p&gt;While a lot of foundational documentation and central libraries have been written, there is still more work ahead.&lt;/p&gt;
    &lt;head rend="h3"&gt;More lints ğŸ§¶ğŸ§¶&lt;/head&gt;
    &lt;p&gt;The new lint framework provided by alpm-lint currently only features few lints.&lt;/p&gt;
    &lt;p&gt;Going forward, we want to extend this list in the dedicated "Lints" milestone and encourage anyone with Rust experience and an interest in packaging to help with this.&lt;/p&gt;
    &lt;p&gt;In addition to implementing lint rules, we want to explore the inclusion of the &lt;code&gt;alpm-lint(1)&lt;/code&gt; CLI in the canonical package build tooling for Arch Linux.&lt;/p&gt;
    &lt;head rend="h3"&gt;C-API ğŸ‡¨&lt;/head&gt;
    &lt;p&gt;Our original project plan included potentially emulating the libalpm C-API in the scope of the contracting work. However, during the last months we realized, that for many consumers it would be more useful to rely on the finer grained libraries of the ALPM project directly instead. In addition, not all relevant database handling features are fully implemented yet, which would limit the usefulness of a C wrapper library.&lt;/p&gt;
    &lt;p&gt;In the medium term, it is certainly possible for interested developers to create an emulation of the libalpm C library based on ALPM. Reach out in case you are interested in something like this!&lt;/p&gt;
    &lt;head rend="h3"&gt;Repository database handling ğŸ“¦ï¸&lt;/head&gt;
    &lt;p&gt;In the alpm-repo-db crate we have added support for the data files in use in an alpm-repo-db(7).&lt;/p&gt;
    &lt;p&gt;Going forward, we want to add full handling of the database format: Creation, reading and compression of alpm-repo-db(7) files and the addition, update and removal of entries.&lt;/p&gt;
    &lt;head rend="h3"&gt;Add libkrun support to rootless-run ğŸƒâ¡ï¸&lt;/head&gt;
    &lt;p&gt;Both &lt;code&gt;fakeroot(1)&lt;/code&gt; and &lt;code&gt;rootlesskit&lt;/code&gt; have their place in certain contexts, but they each also have their weaknesses (e.g. &lt;code&gt;fakeroot(1)&lt;/code&gt; does not provide isolation, &lt;code&gt;rootlesskit&lt;/code&gt; does not work in a containerized context).&lt;/p&gt;
    &lt;p&gt;Going forward, we want to explore adding libkrun support to rootless-run to accommodate stronger isolation on the basis of KVM.&lt;/p&gt;
    &lt;head rend="h3"&gt;Downloading of artifacts â¬ï¸&lt;/head&gt;
    &lt;p&gt;The alpm-package and alpm-repo-db crates provide integration for handling local package and repository database files.&lt;/p&gt;
    &lt;p&gt;In a package management workflow these are usually downloaded from an alpm-repo(7). We want to provide support for securely downloading these artifacts over the network.&lt;/p&gt;
    &lt;head rend="h3"&gt;Verification of artifacts ğŸ”&lt;/head&gt;
    &lt;p&gt;VOA provides a distribution- and technology-agnostic specification for artifact verification.&lt;/p&gt;
    &lt;p&gt;Using the voa project reference implementation, we want to add OpenPGP based verification for alpm-package(7) and alpm-repo-db(7) files.&lt;/p&gt;
    &lt;head rend="h3"&gt;More VOA technology backends ğŸ”&lt;/head&gt;
    &lt;p&gt;With the technology backend for OpenPGP in place, we have ironed out the generic handling of verifiers in the voa reference implementation.&lt;/p&gt;
    &lt;p&gt;Interested parties have already worked on a proof of concept for an x.509 technology backend and provided a ticket for the inclusion of signify as technology backend (see voa#24).&lt;/p&gt;
    &lt;p&gt;If you are interested in helping with the specification and implementation of more technology backends, please reach out!&lt;/p&gt;
    &lt;head rend="h3"&gt;Extend Python bindings ğŸğŸ&lt;/head&gt;
    &lt;p&gt;We are very happy with the current feature set of python-alpm. Going forward, we want to extend the API for the Python bindings further to cover even more use-cases of interested projects, such as archinstall.&lt;/p&gt;
    &lt;p&gt;If you enjoy hacking on the intersection of Rust and Python, feel free to reach out! We would be excited to collaborate with any interested contributors.&lt;/p&gt;
    &lt;head rend="h3"&gt;More applications âŒ¨ï¸&lt;/head&gt;
    &lt;p&gt;The new set of ALPM project libraries enables building robust tools. Users of the libraries can rely on a strongly typed, memory safe language ğŸ¦€&lt;/p&gt;
    &lt;p&gt;This empowers developers to build new special purpose package management applications with much greater ease. We look forward to building such applications ourselves, as well as seeing other parties building them.&lt;/p&gt;
    &lt;p&gt;Ultimately, user-facing improvements are our goal, and we think the foundation that we laid over the past year is fertile ground for innovation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46572060</guid><pubDate>Sun, 11 Jan 2026 02:08:14 +0000</pubDate></item><item><title>Max Payne â€“ two decades later â€“ Graphics Critique (2021)</title><link>https://darkcephas.blogspot.com/2021/07/max-payne-two-decades-later-graphics.html</link><description>&lt;doc fingerprint="afd87b714fa243be"&gt;
  &lt;main&gt;
    &lt;p&gt;It has been two decades since the video game Max Payne was release on July 23, 2001. The game itself was some incredible homage to The Matrix and Detective Film Noire but in this article we are only going to examine the graphics. The rendering present in the game was phenomenal for its time and as such received multiple graphics awards. To understand the what the developers achieve and could have been achieved we have to first understand the PC computing landscape 20 years ago**.&lt;/p&gt;
    &lt;head rend="h1"&gt;2001&lt;/head&gt;
    &lt;p&gt;Max Payne was released targeting directx 8.0 with specs of 450 Mhz cpu (singular) and 16 Mb graphics card. Two put this in perspective that is roughly three orders of magnitude less GPU memory than a modern RTX 2080. The DirectX 8.0 graphics API at least has pixel and vertex shaders but the spec had extreme limitations on caps like number of instructions. The 450 Mhz cpu is more than two orders of magnitude slower than a modern PC cpu today.&lt;/p&gt;
    &lt;p&gt;So with this perspective in mind we can probably conclude** that the rendering will be limited to:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Forward only rendering (no render-to-texture)&lt;/item&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;item&gt;No dynamic shadows&lt;/item&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;item&gt;Very low resolution textures&lt;/item&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;item&gt;Hundreds of polys on screen&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;So with these severe limitations how was such realism and fidelity possible? The answer is an amazing technical synergy of rendering smoke and mirrors. Most of these techniques could be summarized as tricking the human visual perception into thinking complex rendering computations are being done live in realtime when they are actually have been precalculated. The next sections will examine in detail each technique and how they contribute to the total graphical experience.&lt;/p&gt;
    &lt;head rend="h1"&gt;Particle Effects&lt;/head&gt;
    &lt;p&gt;The particle effects of this game are its best graphical feature. For a game that involves slowmo matrix style fighting with bullets and other mildly destructive weaponry this investment and care certainly pays off. Similar games of this time do not even come close to the effect fidelity found in this title**.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;A bullet hitting a wall in slowmo. Bullet with vapor trail impacts wall. Decal is then created for the crack. Immediately a puff of several white smoke particles appear along with a handful of chip particles. These chip particles are actually flip flipbook animated textures with far less geometric detail than is indicated by what appears to be rotating complex chunks.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Highly realistic candle flame effect. There is an lack of overall lighting flicker but this is likely due to limitations in either light count or baked light map.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;General Criticism&lt;/head&gt;
    &lt;p&gt;While obviously phenomenal these effects could still be improved upon**.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The larger particle quads clip the ground in a visual unpleasant and unrealistic fashion. Soft clipping is normally implemented by reading the depth buffer which is not possible here. It might be possible to achieve soft clipping by CPU side manipulation of the particle quads that clip the ground plane. It might also be possible to do a ground plane representation in the pixel/vertex shader such that near plane quads fade out completely before touching the ground surface.&lt;/item&gt;
      &lt;item&gt;The particles do not interact with the environment at all. This is pretty common for particle systems in general. However there are situations where a few of these particles could have benefitted from a simple path trace of the static geometry. Given that the game is all about tracing bullets through the air this was definitely possible. There would be a limit on how many particles could do this but that could depend the dynamic scenario.&lt;/item&gt;
      &lt;item&gt;Finally the timing for decals to appear and the manner in which they appear is slightly offset from what is correct. This could be due to frame latencies in the engine itself but considering the excessive usage of slowmo in the title some timing cleanup would be beneficial.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Lighting&lt;/head&gt;
    &lt;p&gt;Max Payne used prebaked lightmaps for static geometry. This means static geometry has an entirely separate texture layer that corresponds to the sum incoming irradiance. The reason why this is separate and not simply baked into the texture of static objects is because the high resolution albedo textures are reused everywhere in a scene. Each usage may have a different lighting condition which means they need to correspond to different parts of a texture. Since the light map uniquely covers the entire visible scene the texel density is quite low. It should also be noted that for Max Payne this appears to only be a light map and apparently not a Radiosity map with indirect reflections**.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Fantastic use of lightmaps to simulation emissive luminance of a monitor.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h1"&gt;Detail textures&lt;/head&gt;
    &lt;p&gt;Detail textures modulate the albedo of surface to simulate micro surface features that cannot be represented in the texture due to strict memory constraints. They are simply a way to realize high resolution textures without an overhead that would be unacceptable circa 2001. These textures do not have any color information and are usually represented with a single 8 bit 'red' channel.&lt;/p&gt;
    &lt;head rend="h4"&gt;General Criticism&lt;/head&gt;
    &lt;p&gt;This is a great technique and was used in games before 2001. Its usage here is a bit inconsistent with some surfaces having no detail textures and others having clearly the wrong detail texture applied to the surface. It is not clear how this could be improved without increased polygons and increased number detail textures.&lt;/p&gt;
    &lt;head rend="h1"&gt;Fake Geometry&lt;/head&gt;
    &lt;p&gt;Modern AAA games use high quality polygonal models to represent 3D object details. Even in the case of surface (2D) detail the complexity is represented with heightfields or bump maps so the surface can react correctly to different lighting conditions. In 2001 both of these techniques were simply not feasible for this title. In Max Payne both surface and 3D details are baked directly into the albedo texture of the object. Baking this information directly into the albedo texture is perfectly correct for a single perspective. The trick is doing this in a way that it looks acceptable for the all the perspectives that are common.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;This looks like a highly detailed object&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Note this is not prebaked into the shadow map. This shadow is prebaked into the albedo of the texture itself.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;A closeup of a candlestick holder with lit candles. The image suggests detailed geometry&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;This technique used here is borderline experimental.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;This scene probably has fewer than 50 triangles in the camera frustum.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;General Criticism&lt;/head&gt;
    &lt;head rend="h1"&gt;Fake Reflections&lt;/head&gt;
    &lt;p&gt;This section is nearly identical to the previous section on fake geometry but with a specific focus on reflections and specular highlights. Max Payne has no environment maps. Even it could afford an environment map texture sample the game also has no normal maps. To prevent the game from looking like a Lambertian alternative dimension the reflections and highlights were also tastefully baked directly into the albedo texture. This technique is quite hit or miss as in reality specular highlights are highly view dependent. (Reflection map is an old term and a more modern term might be something like incoming irradiance)&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;An example of where baked reflections tend to shine. The highlights suggest a reflection to the light but in reality this texture is used on the seats in the dark background as well. Without the shadow map to dim these highlights this technique would be quite off-putting and noticeably inaccurate. &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;The gun on the ground lacks any kind of lighting and as such the metal reflections dont seem linked in any way to the environment. A simple planar AO technique would help the human visual system perceive this as an object in contact with the ground. This technique could have been done at the vertex lighting level or as a constant in the pixel shader.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;
      &lt;td&gt;Note its not just fixtures that have baked highlights but the walls and the molding.&lt;/td&gt;
    &lt;/p&gt;
    &lt;head rend="h4"&gt;General Criticism&lt;/head&gt;
    &lt;p&gt;As with other techniques in this game the primary issue here is consistency. Many of the objects have great baked specular highlights but they do not fit quite right with the rest objects in the scene. A bit more effort in terms of technical artistry was required to make the specular reflections fit perfectly with each unique usage of the object or texture. Care needs to be taken in the approach as many older titles perfected this technique by unfortunately creating repetitive chunks of common geometry.&lt;/p&gt;
    &lt;head rend="h1"&gt;Tricks&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Bullet impact causes painting to fall to the floor. This trick is purely a one-off hand-crafted as there is no real generic physics engine in the game.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Max Payne character leaving footprints in the snow. This trick is extremely simple it just adds a decal to the plane below the feet of the main character at a specific keyframe in animation. While subtle it does at least add some dynamism to what can be a rather static world.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Dynamic Ambient Occlusion blob for character feet. These blobs help ground the character and tells the user how close each foot is to the ground. These AO blobs are implemented as something akin to a dynamic decal with low frequency alpha modulation.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Ambient Occlusion drop blob. Asymmetry in placement suggests that this blob is not well aligned with actual animation foot data.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;The clock in the station actually ticks.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Geometric reflection trick to produce planar reflective surfaces. Here the static geometry is replicated beneath a semitransparent floor. The duplicated geometry is mathematically reflected in the plane. The result is an apparent planar reflection that one might see in a raytrace. This rendering trick is quite cheap despite partial replication of geometry.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;This reflection trick is not applied the npc characters. This could be in order to reduce polycount or limitations in the vertex shader. It could also not have been done for purely aesthetic reasons.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;General Criticism&lt;/head&gt;
    &lt;p&gt;Although not covered here specifically the general outline of the decals in the game look quite poor specifically when they involve opacity. It would have been nicer to see crisper outlines on things like graffiti or a different art style to blend them into the walls. In terms of the planar reflection trick, it would have been nice to see this trick used in a few more situations throughout the game. Specifically, there are a handful of mirrors in the game. Simple planar reflections in these cases would have made for a more dynamic rendering impression.&lt;/p&gt;
    &lt;head rend="h1"&gt;Scenes&lt;/head&gt;
    &lt;p&gt;In this final section we shall look at a screenshots from a few key scenes to get a sense of how all these techniques come together to produce a single compelling image.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;With a larger investment and perhaps different technical choices Max Payne could possibly have looked even better than it did in 2001. However the graphical result produced at that time was still far and away better than other titles in this period. The rendering quality of this game was not seen in other titles for several years. This game stands as a remarkable technical accomplishment and a significant entry in the history of progression in realtime rendering.&lt;/p&gt;
    &lt;p&gt;* All screenshots of all games were taken by the author and are presented here for the intent purpose of review and criticism (technical and aesthetic)&lt;/p&gt;
    &lt;p&gt;** All 'claims' here are in the form of opinions made based on the author's industry experience and not on detailed inspection of source code or on secret non-public knowledge&lt;/p&gt;
    &lt;p&gt;Highlighted references:&lt;/p&gt;
    &lt;p&gt;https://en.wikipedia.org/wiki/Max_Payne_(video_game)&lt;/p&gt;
    &lt;p&gt;https://store.steampowered.com/app/12140/Max_Payne/&lt;/p&gt;
    &lt;p&gt;https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2080/&lt;/p&gt;
    &lt;p&gt;https://hardwaresecrets.com/directx-versions/&lt;/p&gt;
    &lt;p&gt;https://cdn.cloudflare.steamstatic.com/apps/valve/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf&lt;/p&gt;
    &lt;p&gt;https://developer.valvesoftware.com/wiki/$detail&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46572523</guid><pubDate>Sun, 11 Jan 2026 03:43:44 +0000</pubDate></item><item><title>My Home Fibre Network Disintegrated</title><link>https://alienchow.dev/post/fibre_disintegration/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46572679</guid><pubDate>Sun, 11 Jan 2026 04:19:04 +0000</pubDate></item><item><title>The Concise TypeScript Book</title><link>https://github.com/gibbok/typescript-book</link><description>&lt;doc fingerprint="a01ea4968392680"&gt;
  &lt;main&gt;
    &lt;p&gt;The Concise TypeScript Book provides a comprehensive and succinct overview of TypeScript's capabilities. It offers clear explanations covering all aspects found in the latest version of the language, from its powerful type system to advanced features. Whether you're a beginner or an experienced developer, this book is an invaluable resource to enhance your understanding and proficiency in TypeScript.&lt;/p&gt;
    &lt;p&gt;This book is completely Free and Open Source.&lt;/p&gt;
    &lt;p&gt;I believe that high-quality technical education should be accessible to everyone, which is why I keep this book free and open.&lt;/p&gt;
    &lt;p&gt;If the book helped you squash a bug, understand a tricky concept, or advance in your career, please consider supporting my work by paying what you want (suggested price: 15 USD) or sponsoring a coffee. Your support helps me keep the content up to date and expand it with new examples and deeper explanations.&lt;/p&gt;
    &lt;p&gt;This book has been translated into several language versions, including:&lt;/p&gt;
    &lt;p&gt;You can also download the Epub version:&lt;/p&gt;
    &lt;p&gt;https://github.com/gibbok/typescript-book/tree/main/downloads&lt;/p&gt;
    &lt;p&gt;An online version is available at:&lt;/p&gt;
    &lt;p&gt;https://gibbok.github.io/typescript-book&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Concise TypeScript Book &lt;list rend="ul"&gt;&lt;item&gt;Translations&lt;/item&gt;&lt;item&gt;Downloads and website&lt;/item&gt;&lt;item&gt;Table of Contents&lt;/item&gt;&lt;item&gt;Introduction&lt;/item&gt;&lt;item&gt;About the Author&lt;/item&gt;&lt;item&gt;TypeScript Introduction&lt;/item&gt;&lt;item&gt;Getting Started With TypeScript&lt;/item&gt;&lt;item&gt;Exploring the Type System &lt;list rend="ul"&gt;&lt;item&gt;The TypeScript Language Service&lt;/item&gt;&lt;item&gt;Structural Typing&lt;/item&gt;&lt;item&gt;TypeScript Fundamental Comparison Rules&lt;/item&gt;&lt;item&gt;Types as Sets&lt;/item&gt;&lt;item&gt;Assign a type: Type Declarations and Type Assertions&lt;/item&gt;&lt;item&gt;Property Checking and Excess Property Checking&lt;/item&gt;&lt;item&gt;Weak Types&lt;/item&gt;&lt;item&gt;Strict Object Literal Checking (Freshness)&lt;/item&gt;&lt;item&gt;Type Inference&lt;/item&gt;&lt;item&gt;More Advanced Inferences&lt;/item&gt;&lt;item&gt;Type Widening&lt;/item&gt;&lt;item&gt;Const&lt;/item&gt;&lt;item&gt;Explicit Type Annotation&lt;/item&gt;&lt;item&gt;Type Narrowing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Primitive Types&lt;/item&gt;&lt;item&gt;Type Annotations&lt;/item&gt;&lt;item&gt;Optional Properties&lt;/item&gt;&lt;item&gt;Readonly Properties&lt;/item&gt;&lt;item&gt;Index Signatures&lt;/item&gt;&lt;item&gt;Extending Types&lt;/item&gt;&lt;item&gt;Literal Types&lt;/item&gt;&lt;item&gt;Literal Inference&lt;/item&gt;&lt;item&gt;strictNullChecks&lt;/item&gt;&lt;item&gt;Enums&lt;/item&gt;&lt;item&gt;Narrowing&lt;/item&gt;&lt;item&gt;Assignments&lt;/item&gt;&lt;item&gt;Control Flow Analysis&lt;/item&gt;&lt;item&gt;Type Predicates&lt;/item&gt;&lt;item&gt;Discriminated Unions&lt;/item&gt;&lt;item&gt;The never Type&lt;/item&gt;&lt;item&gt;Exhaustiveness checking&lt;/item&gt;&lt;item&gt;Object Types&lt;/item&gt;&lt;item&gt;Tuple Type (Anonymous)&lt;/item&gt;&lt;item&gt;Named Tuple Type (Labeled)&lt;/item&gt;&lt;item&gt;Fixed Length Tuple&lt;/item&gt;&lt;item&gt;Union Type&lt;/item&gt;&lt;item&gt;Intersection Types&lt;/item&gt;&lt;item&gt;Type Indexing&lt;/item&gt;&lt;item&gt;Type from Value&lt;/item&gt;&lt;item&gt;Type from Func Return&lt;/item&gt;&lt;item&gt;Type from Module&lt;/item&gt;&lt;item&gt;Mapped Types&lt;/item&gt;&lt;item&gt;Mapped Type Modifiers&lt;/item&gt;&lt;item&gt;Conditional Types&lt;/item&gt;&lt;item&gt;Distributive Conditional Types&lt;/item&gt;&lt;item&gt;infer Type Inference in Conditional Types&lt;/item&gt;&lt;item&gt;Predefined Conditional Types&lt;/item&gt;&lt;item&gt;Template Union Types&lt;/item&gt;&lt;item&gt;Any type&lt;/item&gt;&lt;item&gt;Unknown type&lt;/item&gt;&lt;item&gt;Void type&lt;/item&gt;&lt;item&gt;Never type&lt;/item&gt;&lt;item&gt;Interface and Type&lt;/item&gt;&lt;item&gt;Built-in Type Primitives&lt;/item&gt;&lt;item&gt;Common Built-in JS Objects&lt;/item&gt;&lt;item&gt;Overloads&lt;/item&gt;&lt;item&gt;Merging and Extension&lt;/item&gt;&lt;item&gt;Differences between Type and Interface&lt;/item&gt;&lt;item&gt;Class&lt;/item&gt;&lt;item&gt;Generics&lt;/item&gt;&lt;item&gt;Erased Structural Types&lt;/item&gt;&lt;item&gt;Namespacing&lt;/item&gt;&lt;item&gt;Symbols&lt;/item&gt;&lt;item&gt;Triple-Slash Directives&lt;/item&gt;&lt;item&gt;Type Manipulation &lt;list rend="ul"&gt;&lt;item&gt;Creating Types from Types&lt;/item&gt;&lt;item&gt;Indexed Access Types&lt;/item&gt;&lt;item&gt;Utility Types &lt;list rend="ul"&gt;&lt;item&gt;Awaited&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Partial&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Required&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Readonly&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Record&amp;lt;K, T&amp;gt;&lt;/item&gt;&lt;item&gt;Pick&amp;lt;T, K&amp;gt;&lt;/item&gt;&lt;item&gt;Omit&amp;lt;T, K&amp;gt;&lt;/item&gt;&lt;item&gt;Exclude&amp;lt;T, U&amp;gt;&lt;/item&gt;&lt;item&gt;Extract&amp;lt;T, U&amp;gt;&lt;/item&gt;&lt;item&gt;NonNullable&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Parameters&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;ConstructorParameters&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;ReturnType&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;InstanceType&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;ThisParameterType&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;OmitThisParameter&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;ThisType&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Uppercase&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Lowercase&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Capitalize&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;Uncapitalize&amp;lt;T&amp;gt;&lt;/item&gt;&lt;item&gt;NoInfer&amp;lt;T&amp;gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Others &lt;list rend="ul"&gt;&lt;item&gt;Errors and Exception Handling&lt;/item&gt;&lt;item&gt;Mixin classes&lt;/item&gt;&lt;item&gt;Asynchronous Language Features&lt;/item&gt;&lt;item&gt;Iterators and Generators&lt;/item&gt;&lt;item&gt;TsDocs JSDoc Reference&lt;/item&gt;&lt;item&gt;@types&lt;/item&gt;&lt;item&gt;JSX&lt;/item&gt;&lt;item&gt;ES6 Modules&lt;/item&gt;&lt;item&gt;ES7 Exponentiation Operator&lt;/item&gt;&lt;item&gt;The for-await-of Statement&lt;/item&gt;&lt;item&gt;New target meta-property&lt;/item&gt;&lt;item&gt;Dynamic Import Expressions&lt;/item&gt;&lt;item&gt;"tsc â€“watch"&lt;/item&gt;&lt;item&gt;Non-null Assertion Operator&lt;/item&gt;&lt;item&gt;Defaulted declarations&lt;/item&gt;&lt;item&gt;Optional Chaining&lt;/item&gt;&lt;item&gt;Nullish coalescing operator&lt;/item&gt;&lt;item&gt;Template Literal Types&lt;/item&gt;&lt;item&gt;Function overloading&lt;/item&gt;&lt;item&gt;Recursive Types&lt;/item&gt;&lt;item&gt;Recursive Conditional Types&lt;/item&gt;&lt;item&gt;ECMAScript Module Support in Node&lt;/item&gt;&lt;item&gt;Assertion Functions&lt;/item&gt;&lt;item&gt;Variadic Tuple Types&lt;/item&gt;&lt;item&gt;Boxed types&lt;/item&gt;&lt;item&gt;Covariance and Contravariance in TypeScript&lt;/item&gt;&lt;item&gt;Template String Pattern Index Signatures&lt;/item&gt;&lt;item&gt;The satisfies Operator&lt;/item&gt;&lt;item&gt;Type-Only Imports and Export&lt;/item&gt;&lt;item&gt;using declaration and Explicit Resource Management&lt;/item&gt;&lt;item&gt;Import Attributes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Welcome to The Concise TypeScript Book! This guide equips you with essential knowledge and practical skills for effective TypeScript development. Discover key concepts and techniques to write clean, robust code. Whether you're a beginner or an experienced developer, this book serves as both a comprehensive guide and a handy reference for leveraging TypeScript's power in your projects.&lt;/p&gt;
    &lt;p&gt;This book covers TypeScript 5.2.&lt;/p&gt;
    &lt;p&gt;Simone Poggiali is an experienced Staff Engineer with a passion for writing professional-grade code since the 90s. Throughout his international career, he has contributed to numerous projects for a wide range of clients, from startups to large organizations. Notable companies such as HelloFresh, Siemens, O2, Leroy Merlin and Snowplow have benefited from his expertise and dedication.&lt;/p&gt;
    &lt;p&gt;You can reach Simone Poggiali on the following platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LinkedIn: https://www.linkedin.com/in/simone-poggiali&lt;/item&gt;
      &lt;item&gt;GitHub: https://github.com/gibbok&lt;/item&gt;
      &lt;item&gt;X.com: https://x.com/gibbok_coding&lt;/item&gt;
      &lt;item&gt;Email: gibbok.codingğŸ“§gmail.com&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TypeScript is a strongly typed programming language that builds on JavaScript. It was originally designed by Anders Hejlsberg in 2012 and is currently developed and maintained by Microsoft as an open source project.&lt;/p&gt;
    &lt;p&gt;TypeScript compiles to JavaScript and can be executed in any JavaScript runtime (e.g., a browser or server Node.js).&lt;/p&gt;
    &lt;p&gt;TypeScript supports multiple programming paradigms such as functional, generic, imperative, and object-oriented. TypeScript is neither an interpreted nor a compiled language.&lt;/p&gt;
    &lt;p&gt;TypeScript is a strongly typed language that helps prevent common programming mistakes and avoid certain kinds of run-time errors before the program is executed.&lt;/p&gt;
    &lt;p&gt;A strongly typed language allows the developer to specify various program constraints and behaviors in the data type definitions, facilitating the ability to verify the correctness of the software and prevent defects. This is especially valuable in large-scale applications.&lt;/p&gt;
    &lt;p&gt;Some of the benefits of TypeScript:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Static typing, optionally strongly typed&lt;/item&gt;
      &lt;item&gt;Type Inference&lt;/item&gt;
      &lt;item&gt;Access to ES6 and ES7 features&lt;/item&gt;
      &lt;item&gt;Cross-Platform and Cross-browser Compatibility&lt;/item&gt;
      &lt;item&gt;Tooling support with IntelliSense&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TypeScript is written in &lt;code&gt;.ts&lt;/code&gt; or &lt;code&gt;.tsx&lt;/code&gt; files, while JavaScript files are written in &lt;code&gt;.js&lt;/code&gt; or &lt;code&gt;.jsx&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Files with the extension &lt;code&gt;.tsx&lt;/code&gt; or &lt;code&gt;.jsx&lt;/code&gt; can contain JavaScript Syntax Extension JSX, which is used in React for UI development.&lt;/p&gt;
    &lt;p&gt;TypeScript is a typed superset of JavaScript (ECMAScript 2015) in terms of syntax. All JavaScript code is valid TypeScript code, but the reverse is not always true.&lt;/p&gt;
    &lt;p&gt;For instance, consider a function in a JavaScript file with the &lt;code&gt;.js&lt;/code&gt; extension, such as the following:&lt;/p&gt;
    &lt;code&gt;const sum = (a, b) =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;The function can be converted and used in TypeScript by changing the file extension to &lt;code&gt;.ts&lt;/code&gt;. However, if the same function is annotated with TypeScript types, it cannot be executed in any JavaScript runtime without compilation. The following TypeScript code will produce a syntax error if it is not compiled:&lt;/p&gt;
    &lt;code&gt;const sum = (a: number, b: number): number =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;TypeScript was designed to detect possible exceptions that can occur at runtime during compilation time by having the developer define the intent with type annotations. In addition, TypeScript can also catch issues if no type annotation is provided. For instance, the following code snippet does not specify any TypeScript types:&lt;/p&gt;
    &lt;code&gt;const items = [{ x: 1 }, { x: 2 }];
const result = items.filter(item =&amp;gt; item.y);&lt;/code&gt;
    &lt;p&gt;In this case, TypeScript detects an error and reports:&lt;/p&gt;
    &lt;code&gt;Property 'y' does not exist on type '{ x: number; }'.
&lt;/code&gt;
    &lt;p&gt;TypeScript's type system is largely influenced by the runtime behavior of JavaScript. For example, the addition operator (+), which in JavaScript can either perform string concatenation or numeric addition, is modeled in the same way in TypeScript:&lt;/p&gt;
    &lt;code&gt;const result = '1' + 1; // Result is of type string&lt;/code&gt;
    &lt;p&gt;The team behind TypeScript has made a deliberate decision to flag unusual usage of JavaScript as errors. For instance, consider the following valid JavaScript code:&lt;/p&gt;
    &lt;code&gt;const result = 1 + true; // In JavaScript, the result is equal 2&lt;/code&gt;
    &lt;p&gt;However, TypeScript throws an error:&lt;/p&gt;
    &lt;code&gt;Operator '+' cannot be applied to types 'number' and 'boolean'.
&lt;/code&gt;
    &lt;p&gt;This error occurs because TypeScript strictly enforces type compatibility, and in this case, it identifies an invalid operation between a number and a boolean.&lt;/p&gt;
    &lt;p&gt;The TypeScript compiler has two main responsibilities: checking for type errors and compiling to JavaScript. These two processes are independent of each other. Types do not affect the execution of the code in a JavaScript runtime, as they are completely erased during compilation. TypeScript can still output JavaScript even in the presence of type errors. Here is an example of TypeScript code with a type error:&lt;/p&gt;
    &lt;code&gt;const add = (a: number, b: number): number =&amp;gt; a + b;
const result = add('x', 'y'); // Argument of type 'string' is not assignable to parameter of type 'number'.&lt;/code&gt;
    &lt;p&gt;However, it can still produce executable JavaScript output:&lt;/p&gt;
    &lt;code&gt;'use strict';
const add = (a, b) =&amp;gt; a + b;
const result = add('x', 'y'); // xy&lt;/code&gt;
    &lt;p&gt;It is not possible to check TypeScript types at runtime. For example:&lt;/p&gt;
    &lt;code&gt;interface Animal {
    name: string;
}
interface Dog extends Animal {
    bark: () =&amp;gt; void;
}
interface Cat extends Animal {
    meow: () =&amp;gt; void;
}
const makeNoise = (animal: Animal) =&amp;gt; {
    if (animal instanceof Dog) {
        // 'Dog' only refers to a type, but is being used as a value here.
        // ...
    }
};&lt;/code&gt;
    &lt;p&gt;As the types are erased after compilation, there is no way to run this code in JavaScript. To recognize types at runtime, we need to use another mechanism. TypeScript provides several options, with a common one being "tagged union". For example:&lt;/p&gt;
    &lt;code&gt;interface Dog {
    kind: 'dog'; // Tagged union
    bark: () =&amp;gt; void;
}
interface Cat {
    kind: 'cat'; // Tagged union
    meow: () =&amp;gt; void;
}
type Animal = Dog | Cat;

const makeNoise = (animal: Animal) =&amp;gt; {
    if (animal.kind === 'dog') {
        animal.bark();
    } else {
        animal.meow();
    }
};

const dog: Dog = {
    kind: 'dog',
    bark: () =&amp;gt; console.log('bark'),
};
makeNoise(dog);&lt;/code&gt;
    &lt;p&gt;The property "kind" is a value that can be used at runtime to distinguish between objects in JavaScript.&lt;/p&gt;
    &lt;p&gt;It is also possible for a value at runtime to have a type different from the one declared in the type declaration. For instance, if the developer has misinterpreted an API type and annotated it incorrectly.&lt;/p&gt;
    &lt;p&gt;TypeScript is a superset of JavaScript, so the "class" keyword can be used as a type and value at runtime.&lt;/p&gt;
    &lt;code&gt;class Animal {
    constructor(public name: string) {}
}
class Dog extends Animal {
    constructor(
        public name: string,
        public bark: () =&amp;gt; void
    ) {
        super(name);
    }
}
class Cat extends Animal {
    constructor(
        public name: string,
        public meow: () =&amp;gt; void
    ) {
        super(name);
    }
}
type Mammal = Dog | Cat;

const makeNoise = (mammal: Mammal) =&amp;gt; {
    if (mammal instanceof Dog) {
        mammal.bark();
    } else {
        mammal.meow();
    }
};

const dog = new Dog('Fido', () =&amp;gt; console.log('bark'));
makeNoise(dog);&lt;/code&gt;
    &lt;p&gt;In JavaScript, a "class" has a "prototype" property, and the "instanceof" operator can be used to test if the prototype property of a constructor appears anywhere in the prototype chain of an object.&lt;/p&gt;
    &lt;p&gt;TypeScript has no effect on runtime performance, as all types will be erased. However, TypeScript does introduce some build time overhead.&lt;/p&gt;
    &lt;p&gt;TypeScript can compile code to any released version of JavaScript since ECMAScript 3 (1999). This means that TypeScript can transpile code from the latest JavaScript features to older versions, a process known as Downleveling. This allows the usage of modern JavaScript while maintaining maximum compatibility with older runtime environments.&lt;/p&gt;
    &lt;p&gt;It's important to note that during transpilation to an older version of JavaScript, TypeScript may generate code that could incur a performance overhead compared to native implementations.&lt;/p&gt;
    &lt;p&gt;Here are some of the modern JavaScript features that can be used in TypeScript:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECMAScript modules instead of AMD-style "define" callbacks or CommonJS "require" statements.&lt;/item&gt;
      &lt;item&gt;Classes instead of prototypes.&lt;/item&gt;
      &lt;item&gt;Variables declaration using "let" or "const" instead of "var".&lt;/item&gt;
      &lt;item&gt;"for-of" loop or ".forEach" instead of the traditional "for" loop.&lt;/item&gt;
      &lt;item&gt;Arrow functions instead of function expressions.&lt;/item&gt;
      &lt;item&gt;Destructuring assignment.&lt;/item&gt;
      &lt;item&gt;Shorthand property/method names and computed property names.&lt;/item&gt;
      &lt;item&gt;Default function parameters.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By leveraging these modern JavaScript features, developers can write more expressive and concise code in TypeScript.&lt;/p&gt;
    &lt;p&gt;Visual Studio Code provides excellent support for the TypeScript language but does not include the TypeScript compiler. To install the TypeScript compiler, you can use a package manager like npm or yarn:&lt;/p&gt;
    &lt;code&gt;npm install typescript --save-dev&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;yarn add typescript --dev&lt;/code&gt;
    &lt;p&gt;Make sure to commit the generated lockfile to ensure that every team member uses the same version of TypeScript.&lt;/p&gt;
    &lt;p&gt;To run the TypeScript compiler, you can use the following commands&lt;/p&gt;
    &lt;code&gt;npx tsc&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;yarn tsc&lt;/code&gt;
    &lt;p&gt;It is recommended to install TypeScript project-wise rather than globally, as it provides a more predictable build process. However, for one-off occasions, you can use the following command:&lt;/p&gt;
    &lt;code&gt;npx tsc&lt;/code&gt;
    &lt;p&gt;or installing it globally:&lt;/p&gt;
    &lt;code&gt;npm install -g typescript&lt;/code&gt;
    &lt;p&gt;If you are using Microsoft Visual Studio, you can obtain TypeScript as a package in NuGet for your MSBuild projects. In the NuGet Package Manager Console, run the following command:&lt;/p&gt;
    &lt;code&gt;Install-Package Microsoft.TypeScript.MSBuild&lt;/code&gt;
    &lt;p&gt;During the TypeScript installation, two executables are installed: "tsc" as the TypeScript compiler and "tsserver" as the TypeScript standalone server. The standalone server contains the compiler and language services that can be utilized by editors and IDEs to provide intelligent code completion.&lt;/p&gt;
    &lt;p&gt;Additionally, there are several TypeScript-compatible transpilers available, such as Babel (via a plugin) or swc. These transpilers can be used to convert TypeScript code into other target languages or versions.&lt;/p&gt;
    &lt;p&gt;TypeScript can be configured using the tsc CLI options or by utilizing a dedicated configuration file called tsconfig.json placed in the root of the project.&lt;/p&gt;
    &lt;p&gt;To generate a tsconfig.json file prepopulated with recommended settings, you can use the following command:&lt;/p&gt;
    &lt;code&gt;tsc --init&lt;/code&gt;
    &lt;p&gt;When executing the &lt;code&gt;tsc&lt;/code&gt; command locally, TypeScript will compile the code using the configuration specified in the nearest tsconfig.json file.&lt;/p&gt;
    &lt;p&gt;Here are some examples of CLI commands that run with the default settings:&lt;/p&gt;
    &lt;code&gt;tsc main.ts // Compile a specific file (main.ts) to JavaScript
tsc src/*.ts // Compile any .ts files under the 'src' folder to JavaScript
tsc app.ts util.ts --outfile index.js // Compile two TypeScript files (app.ts and util.ts) into a single JavaScript file (index.js)&lt;/code&gt;
    &lt;p&gt;A tsconfig.json file is used to configure the TypeScript Compiler (tsc). Usually, it is added to the root of the project, together with the &lt;code&gt;package.json&lt;/code&gt; file.&lt;/p&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;tsconfig.json accepts comments even if it is in json format.&lt;/item&gt;
      &lt;item&gt;It is advisable to use this configuration file instead of the command-line options.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At the following link you can find the complete documentation and its schema:&lt;/p&gt;
    &lt;p&gt;https://www.typescriptlang.org/tsconfig&lt;/p&gt;
    &lt;p&gt;https://www.typescriptlang.org/tsconfig/&lt;/p&gt;
    &lt;p&gt;The following represents a list of the common and useful configurations:&lt;/p&gt;
    &lt;p&gt;The "target" property is used to specify which version of JavaScript ECMAScript version your TypeScript should emit/compile into. For modern browsers ES6 is a good option, for older browsers, ES5 is recommended.&lt;/p&gt;
    &lt;p&gt;The "lib" property is used to specify which library files to include at compilation time. TypeScript automatically includes APIs for features specified in the "target" property, but it is possible to omit or pick specific libraries for particular needs. For instance, if you are working on a server project, you could exclude the "DOM" library, which is useful only in a browser environment.&lt;/p&gt;
    &lt;p&gt;The "strict" property enables stronger guarantees and enhances type safety. It is advisable to always include this property in your project's tsconfig.json file. Enabling the "strict" property allows TypeScript to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Emit code using "use strict" for each source file.&lt;/item&gt;
      &lt;item&gt;Consider "null" and "undefined" in the type checking process.&lt;/item&gt;
      &lt;item&gt;Disable the usage of the "any" type when no type annotations are present.&lt;/item&gt;
      &lt;item&gt;Raise an error on the usage of the "this" expression, which would otherwise imply the "any" type.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The "module" property sets the module system supported for the compiled program. During runtime, a module loader is used to locate and execute dependencies based on the specified module system.&lt;/p&gt;
    &lt;p&gt;The most common module loaders used in JavaScript are Node.js CommonJS for server-side applications and RequireJS for AMD modules in browser-based web applications. TypeScript can emit code for various module systems, including UMD, System, ESNext, ES2015/ES6, and ES2020.&lt;/p&gt;
    &lt;p&gt;Note: The module system should be chosen based on the target environment and the module loading mechanism available in that environment.&lt;/p&gt;
    &lt;p&gt;The "moduleResolution" property specifies the module resolution strategy. Use "node" for modern TypeScript code, the "classic" strategy is used only for old versions of TypeScript (before 1.6).&lt;/p&gt;
    &lt;p&gt;The "esModuleInterop" property allows import default from CommonJS modules that did not export using the "default" property, this property provides a shim to ensure compatibility in the emitted JavaScript. After enabling this option we can use &lt;code&gt;import MyLibrary from "my-library"&lt;/code&gt; instead of &lt;code&gt;import * as MyLibrary from "my-library"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The "jsx" property applies only to .tsx files used in ReactJS and controls how JSX constructs are compiled into JavaScript. A common option is "preserve" which will compile to a .jsx file keeping unchanged the JSX so it can be passed to different tools like Babel for further transformations.&lt;/p&gt;
    &lt;p&gt;The "skipLibCheck'' property will prevent TypeScript from type-checking the entire imported third-party packages. This property will reduce the compile time of a project. TypeScript will still check your code against the type definitions provided by these packages.&lt;/p&gt;
    &lt;p&gt;The "files" property indicates to the compiler a list of files that must always be included in the program.&lt;/p&gt;
    &lt;p&gt;The "include" property indicates to the compiler a list of files that we would like to include. This property allows glob-like patterns, such as "*" for any subdirectory, "" for any file name, and "?" for optional characters.&lt;/p&gt;
    &lt;p&gt;The "exclude" property indicates to the compiler a list of files that should not be included in the compilation. This can include files such as "node_modules" or test files. Note: tsconfig.json allows comments.&lt;/p&gt;
    &lt;p&gt;TypeScript uses helper code when generating code for certain advanced or down-leveled JavaScript features. By default, these helpers are duplicated in files using them. The &lt;code&gt;importHelpers&lt;/code&gt; option imports these helpers from the &lt;code&gt;tslib&lt;/code&gt; module instead, making the JavaScript output more efficient.&lt;/p&gt;
    &lt;p&gt;For large projects, it is recommended to adopt a gradual transition where TypeScript and JavaScript code will initially coexist. Only small projects can be migrated to TypeScript in one go.&lt;/p&gt;
    &lt;p&gt;The first step of this transition is to introduce TypeScript into the build chain process. This can be done by using the "allowJs" compiler option, which permits .ts and .tsx files to coexist with existing JavaScript files. As TypeScript will fall back to a type of "any" for a variable when it cannot infer the type from JavaScript files, it is recommended to disable "noImplicitAny" in your compiler options at the beginning of the migration.&lt;/p&gt;
    &lt;p&gt;The second step is to ensure that your JavaScript tests work alongside TypeScript files so that you can run tests as you convert each module. If you are using Jest, consider using &lt;code&gt;ts-jest&lt;/code&gt;, which allows you to test TypeScript projects with Jest.&lt;/p&gt;
    &lt;p&gt;The third step is to include type declarations for third-party libraries in your project. These declarations can be found either bundled or on DefinitelyTyped. You can search for them using https://www.typescriptlang.org/dt/search and install them using:&lt;/p&gt;
    &lt;code&gt;npm install --save-dev @types/package-name&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;yarn add --dev @types/package-name.&lt;/code&gt;
    &lt;p&gt;The fourth step is to migrate module by module with a bottom-up approach, following your Dependency Graph starting with the leaves. The idea is to start converting Modules that do not depend on other Modules. To visualize the dependency graphs, you can use the "madge" tool.&lt;/p&gt;
    &lt;p&gt;Good candidate modules for these initial conversions are utility functions and code related to external APIs or specifications. It is possible to automatically generate TypeScript type definitions from Swagger contracts, GraphQL or JSON schemas to be included in your project.&lt;/p&gt;
    &lt;p&gt;When there are no specifications or official schemas available, you can generate types from raw data, such as JSON returned by a server. However, it is recommended to generate types from specifications instead of data to avoid missing edge cases.&lt;/p&gt;
    &lt;p&gt;During the migration, refrain from code refactoring and focus only on adding types to your modules.&lt;/p&gt;
    &lt;p&gt;The fifth step is to enable "noImplicitAny," which will enforce that all types are known and defined, providing a better TypeScript experience for your project.&lt;/p&gt;
    &lt;p&gt;During the migration, you can use the &lt;code&gt;@ts-check&lt;/code&gt; directive, which enables TypeScript type checking in a JavaScript file. This directive provides a loose version of type checking and can be initially used to identify issues in JavaScript files. When &lt;code&gt;@ts-check&lt;/code&gt; is included in a file, TypeScript will try to deduce definitions using JSDoc-style comments. However, consider using JSDoc annotations only at a very early stage of the migration.&lt;/p&gt;
    &lt;p&gt;Consider keeping the default value of &lt;code&gt;noEmitOnError&lt;/code&gt; in your tsconfig.json as false. This will allow you to output JavaScript source code even if errors are reported.&lt;/p&gt;
    &lt;p&gt;The TypeScript Language Service, also known as tsserver, offers various features such as error reporting, diagnostics, compile-on-save, renaming, go to definition, completion lists, signature help, and more. It is primarily used by integrated development environments (IDEs) to provide IntelliSense support. It seamlessly integrates with Visual Studio Code and is utilized by tools like Conquer of Completion (Coc).&lt;/p&gt;
    &lt;p&gt;Developers can leverage a dedicated API and create their own custom language service plugins to enhance the TypeScript editing experience. This can be particularly useful for implementing special linting features or enabling auto-completion for a custom templating language.&lt;/p&gt;
    &lt;p&gt;An example of a real-world custom plugin is "typescript-styled-plugin", which provides syntax error reporting and IntelliSense support for CSS properties in styled components.&lt;/p&gt;
    &lt;p&gt;For more information and quick start guides, you can refer to the official TypeScript Wiki on GitHub: https://github.com/microsoft/TypeScript/wiki/&lt;/p&gt;
    &lt;p&gt;TypeScript is based on a structural type system. This means that the compatibility and equivalence of types are determined by the type's actual structure or definition, rather than its name or place of declaration, as in nominative type systems like C# or C.&lt;/p&gt;
    &lt;p&gt;TypeScript's structural type system was designed based on how JavaScript's dynamic duck typing system works during runtime.&lt;/p&gt;
    &lt;p&gt;The following example is valid TypeScript code. As you can observe, "X" and "Y" have the same member "a," even though they have different declaration names. The types are determined by their structures, and in this case, since the structures are the same, they are compatible and valid.&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
type Y = {
    a: string;
};
const x: X = { a: 'a' };
const y: Y = x; // Valid&lt;/code&gt;
    &lt;p&gt;The TypeScript comparison process is recursive and executed on types nested at any level.&lt;/p&gt;
    &lt;p&gt;A type "X" is compatible with "Y" if "Y" has at least the same members as "X".&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
const y = { a: 'A', b: 'B' }; // Valid, as it has at least the same members as X
const r: X = y;&lt;/code&gt;
    &lt;p&gt;Function parameters are compared by types, not by their names:&lt;/p&gt;
    &lt;code&gt;type X = (a: number) =&amp;gt; void;
type Y = (a: number) =&amp;gt; void;
let x: X = (j: number) =&amp;gt; undefined;
let y: Y = (k: number) =&amp;gt; undefined;
y = x; // Valid
x = y; // Valid&lt;/code&gt;
    &lt;p&gt;Function return types must be the same:&lt;/p&gt;
    &lt;code&gt;type X = (a: number) =&amp;gt; undefined;
type Y = (a: number) =&amp;gt; number;
let x: X = (a: number) =&amp;gt; undefined;
let y: Y = (a: number) =&amp;gt; 1;
y = x; // Invalid
x = y; // Invalid&lt;/code&gt;
    &lt;p&gt;The return type of a source function must be a subtype of the return type of a target function:&lt;/p&gt;
    &lt;code&gt;let x = () =&amp;gt; ({ a: 'A' });
let y = () =&amp;gt; ({ a: 'A', b: 'B' });
x = y; // Valid
y = x; // Invalid member b is missing&lt;/code&gt;
    &lt;p&gt;Discarding function parameters is allowed, as it is a common practice in JavaScript, for instance using "Array.prototype.map()":&lt;/p&gt;
    &lt;code&gt;[1, 2, 3].map((element, _index, _array) =&amp;gt; element + 'x');&lt;/code&gt;
    &lt;p&gt;Therefore, the following type declarations are completely valid:&lt;/p&gt;
    &lt;code&gt;type X = (a: number) =&amp;gt; undefined;
type Y = (a: number, b: number) =&amp;gt; undefined;
let x: X = (a: number) =&amp;gt; undefined;
let y: Y = (a: number) =&amp;gt; undefined; // Missing b parameter
y = x; // Valid&lt;/code&gt;
    &lt;p&gt;Any additional optional parameters of the source type are valid:&lt;/p&gt;
    &lt;code&gt;type X = (a: number, b?: number, c?: number) =&amp;gt; undefined;
type Y = (a: number) =&amp;gt; undefined;
let x: X = a =&amp;gt; undefined;
let y: Y = a =&amp;gt; undefined;
y = x; // Valid
x = y; //Valid&lt;/code&gt;
    &lt;p&gt;Any optional parameters of the target type without corresponding parameters in the source type are valid and not an error:&lt;/p&gt;
    &lt;code&gt;type X = (a: number) =&amp;gt; undefined;
type Y = (a: number, b?: number) =&amp;gt; undefined;
let x: X = a =&amp;gt; undefined;
let y: Y = a =&amp;gt; undefined;
y = x; // Valid
x = y; // Valid&lt;/code&gt;
    &lt;p&gt;The rest parameter is treated as an infinite series of optional parameters:&lt;/p&gt;
    &lt;code&gt;type X = (a: number, ...rest: number[]) =&amp;gt; undefined;
let x: X = a =&amp;gt; undefined; //valid&lt;/code&gt;
    &lt;p&gt;Functions with overloads are valid if the overload signature is compatible with its implementation signature:&lt;/p&gt;
    &lt;code&gt;function x(a: string): void;
function x(a: string, b: number): void;
function x(a: string, b?: number): void {
    console.log(a, b);
}
x('a'); // Valid
x('a', 1); // Valid

function y(a: string): void; // Invalid, not compatible with implementation signature
function y(a: string, b: number): void;
function y(a: string, b: number): void {
    console.log(a, b);
}
y('a');
y('a', 1);&lt;/code&gt;
    &lt;p&gt;Function parameter comparison succeeds if the source and target parameters are assignable to supertypes or subtypes (bivariance).&lt;/p&gt;
    &lt;code&gt;// Supertype
class X {
    a: string;
    constructor(value: string) {
        this.a = value;
    }
}
// Subtype
class Y extends X {}
// Subtype
class Z extends X {}

type GetA = (x: X) =&amp;gt; string;
const getA: GetA = x =&amp;gt; x.a;

// Bivariance does accept supertypes
console.log(getA(new X('x'))); // Valid
console.log(getA(new Y('Y'))); // Valid
console.log(getA(new Z('z'))); // Valid&lt;/code&gt;
    &lt;p&gt;Enums are comparable and valid with numbers and vice versa, but comparing Enum values from different Enum types is invalid.&lt;/p&gt;
    &lt;code&gt;enum X {
    A,
    B,
}
enum Y {
    A,
    B,
    C,
}
const xa: number = X.A; // Valid
const ya: Y = 0; // Valid
X.A === Y.A; // Invalid&lt;/code&gt;
    &lt;p&gt;Instances of a class are subject to a compatibility check for their private and protected members:&lt;/p&gt;
    &lt;code&gt;class X {
    public a: string;
    constructor(value: string) {
        this.a = value;
    }
}

class Y {
    private a: string;
    constructor(value: string) {
        this.a = value;
    }
}

let x: X = new Y('y'); // Invalid&lt;/code&gt;
    &lt;p&gt;The comparison check does not take into consideration the different inheritance hierarchy, for instance:&lt;/p&gt;
    &lt;code&gt;class X {
    public a: string;
    constructor(value: string) {
        this.a = value;
    }
}
class Y extends X {
    public a: string;
    constructor(value: string) {
        super(value);
        this.a = value;
    }
}
class Z {
    public a: string;
    constructor(value: string) {
        this.a = value;
    }
}
let x: X = new X('x');
let y: Y = new Y('y');
let z: Z = new Z('z');
x === y; // Valid
x === z; // Valid even if z is from a different inheritance hierarchy&lt;/code&gt;
    &lt;p&gt;Generics are compared using their structures based on the resulting type after applying the generic parameter, only the final result is compared as a non-generic type.&lt;/p&gt;
    &lt;code&gt;interface X&amp;lt;T&amp;gt; {
    a: T;
}
let x: X&amp;lt;number&amp;gt; = { a: 1 };
let y: X&amp;lt;string&amp;gt; = { a: 'a' };
x === y; // Invalid as the type argument is used in the final structure&lt;/code&gt;
    &lt;code&gt;interface X&amp;lt;T&amp;gt; {}
const x: X&amp;lt;number&amp;gt; = 1;
const y: X&amp;lt;string&amp;gt; = 'a';
x === y; // Valid as the type argument is not used in the final structure&lt;/code&gt;
    &lt;p&gt;When generics do not have their type argument specified, all the unspecified arguments are treated as types with "any":&lt;/p&gt;
    &lt;code&gt;type X = &amp;lt;T&amp;gt;(x: T) =&amp;gt; T;
type Y = &amp;lt;K&amp;gt;(y: K) =&amp;gt; K;
let x: X = x =&amp;gt; x;
let y: Y = y =&amp;gt; y;
x = y; // Valid&lt;/code&gt;
    &lt;p&gt;Remember:&lt;/p&gt;
    &lt;code&gt;let a: number = 1;
let b: number = 2;
a = b; // Valid, everything is assignable to itself

let c: any;
c = 1; // Valid, all types are assignable to any

let d: unknown;
d = 1; // Valid, all types are assignable to unknown

let e: unknown;
let e1: unknown = e; // Valid, unknown is only assignable to itself and any
let e2: any = e; // Valid
let e3: number = e; // Invalid

let f: never;
f = 1; // Invalid, nothing is assignable to never

let g: void;
let g1: any;
g = 1; // Invalid, void is not assignable to or from anything expect any
g = g1; // Valid&lt;/code&gt;
    &lt;p&gt;Please note that when "strictNullChecks" is enabled, "null" and "undefined" are treated similarly to "void"; otherwise, they are similar to "never".&lt;/p&gt;
    &lt;p&gt;In TypeScript, a type is a set of possible values. This set is also referred to as the domain of the type. Each value of a type can be viewed as an element in a set. A type establishes the constraints that every element in the set must satisfy to be considered a member of that set. The primary task of TypeScript is to check and verify whether one set is a subset of another.&lt;/p&gt;
    &lt;p&gt;TypeScript supports various types of sets:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Set term&lt;/cell&gt;
        &lt;cell role="head"&gt;TypeScript&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Empty set&lt;/cell&gt;
        &lt;cell&gt;never&lt;/cell&gt;
        &lt;cell&gt;"never" contains anything apart itself&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Single element set&lt;/cell&gt;
        &lt;cell&gt;undefined / null / literal type&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Finite set&lt;/cell&gt;
        &lt;cell&gt;boolean / union&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Infinite set&lt;/cell&gt;
        &lt;cell&gt;string / number / object&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Universal set&lt;/cell&gt;
        &lt;cell&gt;any / unknown&lt;/cell&gt;
        &lt;cell&gt;Every element is a member of "any" and every set is a subset of it / "unknown" is a type-safe counterpart of "any"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here few examples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;TypeScript&lt;/cell&gt;
        &lt;cell role="head"&gt;Set term&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;never&lt;/cell&gt;
        &lt;cell&gt;âˆ… (empty set)&lt;/cell&gt;
        &lt;cell&gt;const x: never = 'x'; // Error: Type 'string' is not assignable to type 'never'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Literal type&lt;/cell&gt;
        &lt;cell&gt;Single element set&lt;/cell&gt;
        &lt;cell&gt;type X = 'X';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;type Y = 7;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Value assignable to T&lt;/cell&gt;
        &lt;cell&gt;Value âˆˆ T (member of)&lt;/cell&gt;
        &lt;cell&gt;type XY = 'X' | 'Y';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;const x: XY = 'X';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;T1 assignable to T2&lt;/cell&gt;
        &lt;cell&gt;T1 âŠ† T2 (subset of)&lt;/cell&gt;
        &lt;cell&gt;type XY = 'X' | 'Y';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;const x: XY = 'X';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;const j: XY = 'J'; // Type '"J"' is not assignable to type 'XY'.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;T1 extends T2&lt;/cell&gt;
        &lt;cell&gt;T1 âŠ† T2 (subset of)&lt;/cell&gt;
        &lt;cell&gt;type X = 'X' extends string ? true : false;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;T1 | T2&lt;/cell&gt;
        &lt;cell&gt;T1 âˆª T2 (union)&lt;/cell&gt;
        &lt;cell&gt;type XY = 'X' | 'Y';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;type JK = 1 | 2;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;T1 &amp;amp; T2&lt;/cell&gt;
        &lt;cell&gt;T1 âˆ© T2 (intersection)&lt;/cell&gt;
        &lt;cell&gt;type X = { a: string }&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;type Y = { b: string }&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;type XY = X &amp;amp; Y&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;const x: XY = { a: 'a', b: 'b' }&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;unknown&lt;/cell&gt;
        &lt;cell&gt;Universal set&lt;/cell&gt;
        &lt;cell&gt;const x: unknown = 1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An union, (T1 | T2) creates a wider set (both):&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
type Y = {
    b: string;
};
type XY = X | Y;
const r: XY = { a: 'a', b: 'x' }; // Valid&lt;/code&gt;
    &lt;p&gt;An intersection, (T1 &amp;amp; T2) create a narrower set (only shared):&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
type Y = {
    a: string;
    b: string;
};
type XY = X &amp;amp; Y;
const r: XY = { a: 'a' }; // Invalid
const j: XY = { a: 'a', b: 'b' }; // Valid&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;extends&lt;/code&gt; keyword could be considered as a "subset of" in this context. It sets a constraint for a type. The extends used with a generic, take the generic as an infinite set and it will constrain it to a more specific type.
Please note that &lt;code&gt;extends&lt;/code&gt; has nothing to do with hierarchy in a OOP sense (there is no this concept in TypeScript).
TypeScript works with sets and does not have a strict hierarchy, infact, as in the example below, two types could overlap without either being a subtype of the other type (TypeScript considers the structure, shape of the objects).&lt;/p&gt;
    &lt;code&gt;interface X {
    a: string;
}
interface Y extends X {
    b: string;
}
interface Z extends Y {
    c: string;
}
const z: Z = { a: 'a', b: 'b', c: 'c' };
interface X1 {
    a: string;
}
interface Y1 {
    a: string;
    b: string;
}
interface Z1 {
    a: string;
    b: string;
    c: string;
}
const z1: Z1 = { a: 'a', b: 'b', c: 'c' };

const r: Z1 = z; // Valid&lt;/code&gt;
    &lt;p&gt;A type can be assigned in different ways in TypeScript:&lt;/p&gt;
    &lt;p&gt;In the following example, we use x: X (": Type") to declare a type for the variable x.&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};

// Type declaration
const x: X = {
    a: 'a',
};&lt;/code&gt;
    &lt;p&gt;If the variable is not in the specified format, TypeScript will report an error. For instance:&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};

const x: X = {
    a: 'a',
    b: 'b', // Error: Object literal may only specify known properties
};&lt;/code&gt;
    &lt;p&gt;It is possible to add an assertion by using the &lt;code&gt;as&lt;/code&gt; keyword. This tells the compiler that the developer has more information about a type and silences any errors that may occur.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
const x = {
    a: 'a',
    b: 'b',
} as X;&lt;/code&gt;
    &lt;p&gt;In the above example, the object x is asserted to have the type X using the as keyword. This informs the TypeScript compiler that the object conforms to the specified type, even though it has an additional property b not present in the type definition.&lt;/p&gt;
    &lt;p&gt;Type assertions are useful in situations where a more specific type needs to be specified, especially when working with the DOM. For instance:&lt;/p&gt;
    &lt;code&gt;const myInput = document.getElementById('my_input') as HTMLInputElement;&lt;/code&gt;
    &lt;p&gt;Here, the type assertion as HTMLInputElement is used to tell TypeScript that the result of getElementById should be treated as an HTMLInputElement. Type assertions can also be used to remap keys, as shown in the example below with template literals:&lt;/p&gt;
    &lt;code&gt;type J&amp;lt;Type&amp;gt; = {
    [Property in keyof Type as `prefix_${string &amp;amp;
        Property}`]: () =&amp;gt; Type[Property];
};
type X = {
    a: string;
    b: number;
};
type Y = J&amp;lt;X&amp;gt;;&lt;/code&gt;
    &lt;p&gt;In this example, the type &lt;code&gt;J&amp;lt;Type&amp;gt;&lt;/code&gt; uses a mapped type with a template literal to remap the keys of Type. It creates new properties with a "prefix_" added to each key, and their corresponding values are functions returning the original property values.&lt;/p&gt;
    &lt;p&gt;It is worth noting that when using a type assertion, TypeScript will not execute excess property checking. Therefore, it is generally preferable to use a Type Declaration when the structure of the object is known in advance.&lt;/p&gt;
    &lt;p&gt;Ambient declarations are files that describe types for JavaScript code, they have a file name format as &lt;code&gt;.d.ts.&lt;/code&gt;. They are usually imported and used to annotate existing JavaScript libraries or to add types to existing JS files in your project.&lt;/p&gt;
    &lt;p&gt;Many common libraries types can be found at: https://github.com/DefinitelyTyped/DefinitelyTyped/&lt;/p&gt;
    &lt;p&gt;and can be installed using:&lt;/p&gt;
    &lt;code&gt;npm install --save-dev @types/library-name&lt;/code&gt;
    &lt;p&gt;For your defined Ambient Declarations, you can import using the "triple-slash" reference:&lt;/p&gt;
    &lt;code&gt;/// &amp;lt;reference path="./library-types.d.ts" /&amp;gt;&lt;/code&gt;
    &lt;p&gt;You can use Ambient Declarations even within JavaScript files using &lt;code&gt;// @ts-check&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;declare&lt;/code&gt; keyword enables type definitions for existing JavaScript code without importing it, serving as a placeholder for types from another file or globally.&lt;/p&gt;
    &lt;p&gt;TypeScript is based on a structural type system but excess property checking is a property of TypeScript which allows it to check whether an object has the exact properties specified in the type.&lt;/p&gt;
    &lt;p&gt;Excess Property Checking is performed when assigning object literals to variables or when passing them as arguments to the function's excess property, for instance.&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};
const y = { a: 'a', b: 'b' };
const x: X = y; // Valid because structural typing
const w: X = { a: 'a', b: 'b' }; // Invalid because excess property checking&lt;/code&gt;
    &lt;p&gt;A type is considered weak when it contains nothing but a set of all-optional properties:&lt;/p&gt;
    &lt;code&gt;type X = {
    a?: string;
    b?: string;
};&lt;/code&gt;
    &lt;p&gt;TypeScript considers an error to assign anything to a weak type when there is no overlap, for instance, the following throws an error:&lt;/p&gt;
    &lt;code&gt;type Options = {
    a?: string;
    b?: string;
};

const fn = (options: Options) =&amp;gt; undefined;

fn({ c: 'c' }); // Invalid&lt;/code&gt;
    &lt;p&gt;Although not recommended, if needed, it is possible to bypass this check by using type assertion:&lt;/p&gt;
    &lt;code&gt;type Options = {
    a?: string;
    b?: string;
};
const fn = (options: Options) =&amp;gt; undefined;
fn({ c: 'c' } as Options); // Valid&lt;/code&gt;
    &lt;p&gt;Or by adding &lt;code&gt;unknown&lt;/code&gt; to the index signature to the weak type:&lt;/p&gt;
    &lt;code&gt;type Options = {
    [prop: string]: unknown;
    a?: string;
    b?: string;
};

const fn = (options: Options) =&amp;gt; undefined;
fn({ c: 'c' }); // Valid&lt;/code&gt;
    &lt;p&gt;Strict object literal checking, sometimes referred to as "freshness", is a feature in TypeScript that helps catch excess or misspelled properties that would otherwise go unnoticed in normal structural type checks.&lt;/p&gt;
    &lt;p&gt;When creating an object literal, the TypeScript compiler considers it "fresh." If the object literal is assigned to a variable or passed as a parameter, TypeScript will throw an error if the object literal specifies properties that do not exist in the target type.&lt;/p&gt;
    &lt;p&gt;However, "freshness" disappears when an object literal is widened or a type assertion is used.&lt;/p&gt;
    &lt;p&gt;Here are some examples to illustrate:&lt;/p&gt;
    &lt;code&gt;type X = { a: string };
type Y = { a: string; b: string };

let x: X;
x = { a: 'a', b: 'b' }; // Freshness check: Invalid assignment
var y: Y;
y = { a: 'a', bx: 'bx' }; // Freshness check: Invalid assignment

const fn = (x: X) =&amp;gt; console.log(x.a);

fn(x);
fn(y); // Widening: No errors, structurally type compatible

fn({ a: 'a', bx: 'b' }); // Freshness check: Invalid argument

let c: X = { a: 'a' };
let d: Y = { a: 'a', b: '' };
c = d; // Widening: No Freshness check&lt;/code&gt;
    &lt;p&gt;TypeScript can infer types when no annotation is provided during:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Variable initialization.&lt;/item&gt;
      &lt;item&gt;Member initialization.&lt;/item&gt;
      &lt;item&gt;Setting defaults for parameters.&lt;/item&gt;
      &lt;item&gt;Function return type.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;let x = 'x'; // The type inferred is string&lt;/code&gt;
    &lt;p&gt;The TypeScript compiler analyzes the value or expression and determines its type based on the available information.&lt;/p&gt;
    &lt;p&gt;When multiple expressions are used in type inference, TypeScript looks for the "best common types." For instance:&lt;/p&gt;
    &lt;code&gt;let x = [1, 'x', 1, null]; // The type inferred is: (string | number | null)[]&lt;/code&gt;
    &lt;p&gt;If the compiler cannot find the best common types, it returns a union type. For example:&lt;/p&gt;
    &lt;code&gt;let x = [new RegExp('x'), new Date()]; // Type inferred is: (RegExp | Date)[]&lt;/code&gt;
    &lt;p&gt;TypeScript utilizes "contextual typing" based on the variable's location to infer types. In the following example, the compiler knows that &lt;code&gt;e&lt;/code&gt; is of type &lt;code&gt;MouseEvent&lt;/code&gt; because of the &lt;code&gt;click&lt;/code&gt; event type defined in the lib.d.ts file, which contains ambient declarations for various common JavaScript constructs and the DOM:&lt;/p&gt;
    &lt;code&gt;window.addEventListener('click', function (e) {}); // The inferred type of e is MouseEvent&lt;/code&gt;
    &lt;p&gt;Type widening is the process in which TypeScript assigns a type to a variable initialized when no type annotation was provided. It allows narrow to wider types but not vice versa. In the following example:&lt;/p&gt;
    &lt;code&gt;let x = 'x'; // TypeScript infers as string, a wide type
let y: 'y' | 'x' = 'y'; // y types is a union of literal types
y = x; // Invalid Type 'string' is not assignable to type '"x" | "y"'.&lt;/code&gt;
    &lt;p&gt;TypeScript assigns &lt;code&gt;string&lt;/code&gt; to &lt;code&gt;x&lt;/code&gt; based on the single value provided during initialization (&lt;code&gt;x&lt;/code&gt;), this is an example of widening.&lt;/p&gt;
    &lt;p&gt;TypeScript provides ways to have control of the widening process, for instance using "const".&lt;/p&gt;
    &lt;p&gt;Using the &lt;code&gt;const&lt;/code&gt; keyword when declaring a variable results in a narrower type inference in TypeScript.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;const x = 'x'; // TypeScript infers the type of x as 'x', a narrower type
let y: 'y' | 'x' = 'y';
y = x; // Valid: The type of x is inferred as 'x'&lt;/code&gt;
    &lt;p&gt;By using &lt;code&gt;const&lt;/code&gt; to declare the variable x, its type is narrowed to the specific literal value 'x'. Since the type of x is narrowed, it can be assigned to the variable y without any error.
The reason the type can be inferred is because &lt;code&gt;const&lt;/code&gt; variables cannot be reassigned, so their type can be narrowed down to a specific literal type, in this case, the literal type 'x'.&lt;/p&gt;
    &lt;p&gt;From version 5.0 of TypeScript, it is possible to specify the &lt;code&gt;const&lt;/code&gt; attribute on a generic type parameter. This allows for inferring the most precise type possible. Let's see an example without using &lt;code&gt;const&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;function identity&amp;lt;T&amp;gt;(value: T) {
    // No const here
    return value;
}
const values = identity({ a: 'a', b: 'b' }); // Type infered is: { a: string; b: string; }&lt;/code&gt;
    &lt;p&gt;As you can see, the properties &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are inferred with a type of &lt;code&gt;string&lt;/code&gt;   .&lt;/p&gt;
    &lt;p&gt;Now, let's see the difference with the &lt;code&gt;const&lt;/code&gt; version:&lt;/p&gt;
    &lt;code&gt;function identity&amp;lt;const T&amp;gt;(value: T) {
    // Using const modifier on type parameters
    return value;
}
const values = identity({ a: 'a', b: 'b' }); // Type infered is: { a: "a"; b: "b"; }&lt;/code&gt;
    &lt;p&gt;Now we can see that the properties &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are inferred as &lt;code&gt;const&lt;/code&gt;, so &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are treated as string literals rather than just &lt;code&gt;string&lt;/code&gt; types.&lt;/p&gt;
    &lt;p&gt;This feature allows you to declare a variable with a more precise literal type based on its initialization value, signifying to the compiler that the value should be treated as an immutable literal. Here are a few examples:&lt;/p&gt;
    &lt;p&gt;On a single property:&lt;/p&gt;
    &lt;code&gt;const v = {
    x: 3 as const,
};
v.x = 3;&lt;/code&gt;
    &lt;p&gt;On an entire object:&lt;/p&gt;
    &lt;code&gt;const v = {
    x: 1,
    y: 2,
} as const;&lt;/code&gt;
    &lt;p&gt;This can be particularly useful when defining the type for a tuple:&lt;/p&gt;
    &lt;code&gt;const x = [1, 2, 3]; // number[]
const y = [1, 2, 3] as const; // Tuple of readonly [1, 2, 3]&lt;/code&gt;
    &lt;p&gt;We can be specific and pass a type, in the following example property &lt;code&gt;x&lt;/code&gt; is of type &lt;code&gt;number&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;const v = {
    x: 1, // Inferred type: number (widening)
};
v.x = 3; // Valid&lt;/code&gt;
    &lt;p&gt;We can make the type annotation more specific by using a union of literal types:&lt;/p&gt;
    &lt;code&gt;const v: { x: 1 | 2 | 3 } = {
    x: 1, // x is now a union of literal types: 1 | 2 | 3
};
v.x = 3; // Valid
v.x = 100; // Invalid&lt;/code&gt;
    &lt;p&gt;Type Narrowing is the process in TypeScript where a general type is narrowed down to a more specific type. This occurs when TypeScript analyzes the code and determines that certain conditions or operations can refine the type information.&lt;/p&gt;
    &lt;p&gt;Narrowing types can occur in different ways, including:&lt;/p&gt;
    &lt;p&gt;By using conditional statements, such as &lt;code&gt;if&lt;/code&gt; or &lt;code&gt;switch&lt;/code&gt;, TypeScript can narrow down the type based on the outcome of the condition. For example:&lt;/p&gt;
    &lt;code&gt;let x: number | undefined = 10;

if (x !== undefined) {
    x += 100; // The type is number, which had been narrowed by the condition
}&lt;/code&gt;
    &lt;p&gt;Throwing an error or returning early from a branch can be used to help TypeScript narrow down a type. For example:&lt;/p&gt;
    &lt;code&gt;let x: number | undefined = 10;

if (x === undefined) {
    throw 'error';
}
x += 100;&lt;/code&gt;
    &lt;p&gt;Other ways to narrow down types in TypeScript include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;instanceof&lt;/code&gt;operator: Used to check if an object is an instance of a specific class.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;in&lt;/code&gt;operator: Used to check if a property exists in an object.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;typeof&lt;/code&gt;operator: Used to check the type of a value at runtime.&lt;/item&gt;
      &lt;item&gt;Built-in functions like &lt;code&gt;Array.isArray()&lt;/code&gt;: Used to check if a value is an array.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using a "Discriminated Union" is a pattern in TypeScript where an explicit "tag" is added to objects to distinguish between different types within a union. This pattern is also referred to as a "tagged union." In the following example, the "tag" is represented by the property "type":&lt;/p&gt;
    &lt;code&gt;type A = { type: 'type_a'; value: number };
type B = { type: 'type_b'; value: string };

const x = (input: A | B): string | number =&amp;gt; {
    switch (input.type) {
        case 'type_a':
            return input.value + 100; // type is A
        case 'type_b':
            return input.value + 'extra'; // type is B
    }
};&lt;/code&gt;
    &lt;p&gt;In cases where TypeScript is unable to determine a type, it is possible to write a helper function known as a "user-defined type guard." In the following example, we will utilize a Type Predicate to narrow down the type after applying certain filtering:&lt;/p&gt;
    &lt;code&gt;const data = ['a', null, 'c', 'd', null, 'f'];

const r1 = data.filter(x =&amp;gt; x != null); // The type is (string | null)[], TypeScript was not able to infer the type properly

const isValid = (item: string | null): item is string =&amp;gt; item !== null; // Custom type guard

const r2 = data.filter(isValid); // The type is fine now string[], by using the predicate type guard we were able to narrow the type&lt;/code&gt;
    &lt;p&gt;TypeScript supports 7 primitive types. A primitive data type refers to a type that is not an object and does not have any methods associated with it. In TypeScript, all primitive types are immutable, meaning their values cannot be changed once they are assigned.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;string&lt;/code&gt; primitive type stores textual data, and the value is always double or single-quoted.&lt;/p&gt;
    &lt;code&gt;const x: string = 'x';
const y: string = 'y';&lt;/code&gt;
    &lt;p&gt;Strings can span multiple lines if surrounded by the backtick (`) character:&lt;/p&gt;
    &lt;code&gt;let sentence: string = `xxx,
   yyy`;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;boolean&lt;/code&gt; data type in TypeScript stores a binary value, either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;const isReady: boolean = true;&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;number&lt;/code&gt; data type in TypeScript is represented with a 64-bit floating point value. A &lt;code&gt;number&lt;/code&gt; type can represent integers and fractions.
TypeScript also supports hexadecimal, binary, and octal, for instance:&lt;/p&gt;
    &lt;code&gt;const decimal: number = 10;
const hexadecimal: number = 0xa00d; // Hexadecimal starts with 0x
const binary: number = 0b1010; // Binary starts with 0b
const octal: number = 0o633; // Octal starts with 0o&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;bigInt&lt;/code&gt; represents numeric values that are very large (253 â€“ 1) and cannot be represented with a &lt;code&gt;number&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;A &lt;code&gt;bigInt&lt;/code&gt; can be created by calling the built-in function &lt;code&gt;BigInt()&lt;/code&gt; or by adding &lt;code&gt;n&lt;/code&gt; to the end of any integer numeric literal:&lt;/p&gt;
    &lt;code&gt;const x: bigint = BigInt(9007199254740991);
const y: bigint = 9007199254740991n;&lt;/code&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;bigInt&lt;/code&gt;values cannot be mixed with&lt;code&gt;number&lt;/code&gt;and cannot be used with built-in&lt;code&gt;Math&lt;/code&gt;, they must be coerced to the same type.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bigInt&lt;/code&gt;values are available only if target configuration is ES2020 or higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Symbols are unique identifiers that can be used as property keys in objects to prevent naming conflicts.&lt;/p&gt;
    &lt;code&gt;type Obj = {
    [sym: symbol]: number;
};

const a = Symbol('a');
const b = Symbol('b');
let obj: Obj = {};
obj[a] = 123;
obj[b] = 456;

console.log(obj[a]); // 123
console.log(obj[b]); // 456&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;null&lt;/code&gt; and &lt;code&gt;undefined&lt;/code&gt; types both represent no value or the absence of any value.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;undefined&lt;/code&gt; type means the value is not assigned or initialized or indicates an unintentional absence of value.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;null&lt;/code&gt; type means that we know that the field does not have a value, so value is unavailable, it indicates an intentional absence of value.&lt;/p&gt;
    &lt;p&gt;An &lt;code&gt;array&lt;/code&gt; is a data type that can store multiple values of the same type or not. It can be defined using the following syntax:&lt;/p&gt;
    &lt;code&gt;const x: string[] = ['a', 'b'];
const y: Array&amp;lt;string&amp;gt; = ['a', 'b'];
const j: Array&amp;lt;string | number&amp;gt; = ['a', 1, 'b', 2]; // Union&lt;/code&gt;
    &lt;p&gt;TypeScript supports readonly arrays using the following syntax:&lt;/p&gt;
    &lt;code&gt;const x: readonly string[] = ['a', 'b']; // Readonly modifier
const y: ReadonlyArray&amp;lt;string&amp;gt; = ['a', 'b'];
const j: ReadonlyArray&amp;lt;string | number&amp;gt; = ['a', 1, 'b', 2];
j.push('x'); // Invalid&lt;/code&gt;
    &lt;p&gt;TypeScript supports tuple and readonly tuple:&lt;/p&gt;
    &lt;code&gt;const x: [string, number] = ['a', 1];
const y: readonly [string, number] = ['a', 1];&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;any&lt;/code&gt; data type represents literally "any" value, it is the default value when TypeScript cannot infer the type or is not specified.&lt;/p&gt;
    &lt;p&gt;When using &lt;code&gt;any&lt;/code&gt; TypeScript compiler skips the type checking so there is no type safety when &lt;code&gt;any&lt;/code&gt; is being used. Generally do not use &lt;code&gt;any&lt;/code&gt; to silence the compiler when an error occurs, instead focus on fixing the error as with using &lt;code&gt;any&lt;/code&gt;  it is possible to break contracts and we lose the benefits of TypeScript autocomplete.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;any&lt;/code&gt; type could be useful during a gradual migration from JavaScript to TypeScript, as it can silence the compiler.&lt;/p&gt;
    &lt;p&gt;For new projects use TypeScript configuration &lt;code&gt;noImplicitAny&lt;/code&gt; which enables TypeScript to issue errors where &lt;code&gt;any&lt;/code&gt; is used or inferred.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;any&lt;/code&gt;type  is usually a source of errors which can mask real problems with your types. Avoid using it as much as possible.&lt;/p&gt;
    &lt;p&gt;On variables declared using &lt;code&gt;var&lt;/code&gt;, &lt;code&gt;let&lt;/code&gt; and &lt;code&gt;const&lt;/code&gt;, it is possible to optionally add a type:&lt;/p&gt;
    &lt;code&gt;const x: number = 1;&lt;/code&gt;
    &lt;p&gt;TypeScript does a good job of inferring types, especially when simple one, so these declarations in most cases are not necessary.&lt;/p&gt;
    &lt;p&gt;On functions is possible to add type annotations to parameters:&lt;/p&gt;
    &lt;code&gt;function sum(a: number, b: number) {
    return a + b;
}&lt;/code&gt;
    &lt;p&gt;The following is an example using a anonymous functions (so called lambda function):&lt;/p&gt;
    &lt;code&gt;const sum = (a: number, b: number) =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;These annotation can be avoided when a default value for a parameter is present:&lt;/p&gt;
    &lt;code&gt;const sum = (a = 10, b: number) =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;Return type annotations can be added to functions:&lt;/p&gt;
    &lt;code&gt;const sum = (a = 10, b: number): number =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;This is useful especially for more complex functions as writing expliciting the return type before an implementation can help better think about the function.&lt;/p&gt;
    &lt;p&gt;Generally consider annotating type signatures but not the body local variables and add types always to object literals.&lt;/p&gt;
    &lt;p&gt;An object can specify Optional Properties by adding a question mark &lt;code&gt;?&lt;/code&gt; to the end of the property name:&lt;/p&gt;
    &lt;code&gt;type X = {
    a: number;
    b?: number; // Optional
};&lt;/code&gt;
    &lt;p&gt;It is possible to specify a default value when a property is optional"&lt;/p&gt;
    &lt;code&gt;type X = {
    a: number;
    b?: number;
};
const x = ({ a, b = 100 }: X) =&amp;gt; a + b;&lt;/code&gt;
    &lt;p&gt;Is it possible to prevent writing on a property by using the modifier &lt;code&gt;readonly&lt;/code&gt;which  makes sure that the property cannot be re-written but does not provide any guarantee of total immutability:&lt;/p&gt;
    &lt;code&gt;interface Y {
    readonly a: number;
}

type X = {
    readonly a: number;
};

type J = Readonly&amp;lt;{
    a: number;
}&amp;gt;;

type K = {
    readonly [index: number]: string;
};&lt;/code&gt;
    &lt;p&gt;In TypeScript we can use as index signature &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;number&lt;/code&gt;, and &lt;code&gt;symbol&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;type K = {
    [name: string | number]: string;
};
const k: K = { x: 'x', 1: 'b' };
console.log(k['x']);
console.log(k[1]);
console.log(k['1']); // Same result as k[1]&lt;/code&gt;
    &lt;p&gt;Please note that JavaScript automatically converts an index with &lt;code&gt;number&lt;/code&gt; to an index with &lt;code&gt;string&lt;/code&gt; so &lt;code&gt;k[1]&lt;/code&gt; or &lt;code&gt;k["1"]&lt;/code&gt; return the same value.&lt;/p&gt;
    &lt;p&gt;It is possible to extend an &lt;code&gt;interface&lt;/code&gt; (copy members from another type):&lt;/p&gt;
    &lt;code&gt;interface X {
    a: string;
}
interface Y extends X {
    b: string;
}&lt;/code&gt;
    &lt;p&gt;It is also possible to extend from multiple types:&lt;/p&gt;
    &lt;code&gt;interface A {
    a: string;
}
interface B {
    b: string;
}
interface Y extends A, B {
    y: string;
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;extends&lt;/code&gt; keyword works only on interfaces and classes, for types use an intersection:&lt;/p&gt;
    &lt;code&gt;type A = {
    a: number;
};
type B = {
    b: number;
};
type C = A &amp;amp; B;&lt;/code&gt;
    &lt;p&gt;It is possible to extend a type using an inference but not vice versa:&lt;/p&gt;
    &lt;code&gt;type A = {
    a: string;
};
interface B extends A {
    b: string;
}&lt;/code&gt;
    &lt;p&gt;A Literal Type is a single element set from a collective type, it defines a very exact value that is a JavaScript primitive.&lt;/p&gt;
    &lt;p&gt;Literal Types in TypeScript are numbers, strings, and booleans.&lt;/p&gt;
    &lt;p&gt;Example of literals:&lt;/p&gt;
    &lt;code&gt;const a = 'a'; // String literal type
const b = 1; // Numeric literal type
const c = true; // Boolean literal type&lt;/code&gt;
    &lt;p&gt;String, Numeric, and Boolean Literal Types are used in the union, type guard, and type aliases. In the following example you can see a type alias union, &lt;code&gt;O&lt;/code&gt; can be the only value specified and not any other string:&lt;/p&gt;
    &lt;code&gt;type O = 'a' | 'b' | 'c';&lt;/code&gt;
    &lt;p&gt;Literal Inference is a feature in TypeScript that allows the type of a variable or parameter to be inferred based on its value.&lt;/p&gt;
    &lt;p&gt;In the following example we can see that TypeScript considers &lt;code&gt;x&lt;/code&gt; a literal type as the value cannot be changed any time later, when instead &lt;code&gt;y&lt;/code&gt; is inferred as string as it can be modified any time later.&lt;/p&gt;
    &lt;code&gt;const x = 'x'; // Literal type of 'x', because this value cannot be changed
let y = 'y'; // Type string, as we can change this value&lt;/code&gt;
    &lt;p&gt;In the following example we can see that &lt;code&gt;o.x&lt;/code&gt; was inferred as a &lt;code&gt;string&lt;/code&gt; (and not a literal of &lt;code&gt;a&lt;/code&gt;) as TypeScript considers that the value can be changed any time later.&lt;/p&gt;
    &lt;code&gt;type X = 'a' | 'b';

let o = {
    x: 'a', // This is a wider string
};

const fn = (x: X) =&amp;gt; `${x}-foo`;

console.log(fn(o.x)); // Argument of type 'string' is not assignable to parameter of type 'X'&lt;/code&gt;
    &lt;p&gt;As you can see the code throws an error when passing &lt;code&gt;o.x&lt;/code&gt; to &lt;code&gt;fn&lt;/code&gt; as X is a narrower type.&lt;/p&gt;
    &lt;p&gt;We can solve this issue by using type assertion using &lt;code&gt;const&lt;/code&gt; or the &lt;code&gt;X&lt;/code&gt; type:&lt;/p&gt;
    &lt;code&gt;let o = {
    x: 'a' as const,
};&lt;/code&gt;
    &lt;p&gt;or:&lt;/p&gt;
    &lt;code&gt;let o = {
    x: 'a' as X,
};&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;strictNullChecks&lt;/code&gt; is a TypeScript compiler option that enforces strict null checking. When this option is enabled, variables and parameters can only be assigned &lt;code&gt;null&lt;/code&gt; or &lt;code&gt;undefined&lt;/code&gt; if they have been explicitly declared to be of that type using the union type &lt;code&gt;null&lt;/code&gt; | &lt;code&gt;undefined&lt;/code&gt;. If a variable or parameter is not explicitly declared as nullable, TypeScript will generate an error to prevent potential runtime errors.&lt;/p&gt;
    &lt;p&gt;In TypeScript, an &lt;code&gt;enum&lt;/code&gt; is a set of named constant values.&lt;/p&gt;
    &lt;code&gt;enum Color {
    Red = '#ff0000',
    Green = '#00ff00',
    Blue = '#0000ff',
}&lt;/code&gt;
    &lt;p&gt;Enums can be defined in different ways:&lt;/p&gt;
    &lt;p&gt;In TypeScript, a Numeric Enum is an Enum where each constant is assigned a numeric value, starting from 0 by default.&lt;/p&gt;
    &lt;code&gt;enum Size {
    Small, // value starts from 0
    Medium,
    Large,
}&lt;/code&gt;
    &lt;p&gt;It is possible to specify custom values by explicitly assigning them:&lt;/p&gt;
    &lt;code&gt;enum Size {
    Small = 10,
    Medium,
    Large,
}
console.log(Size.Medium); // 11&lt;/code&gt;
    &lt;p&gt;In TypeScript, a String enum is an Enum where each constant is assigned a string value.&lt;/p&gt;
    &lt;code&gt;enum Language {
    English = 'EN',
    Spanish = 'ES',
}&lt;/code&gt;
    &lt;p&gt;Note: TypeScript allows the usage of heterogeneous Enums where string and numeric members can coexist.&lt;/p&gt;
    &lt;p&gt;A constant enum in TypeScript is a special type of Enum where all the values are known at compile time and are inlined wherever the enum is used, resulting in more efficient code.&lt;/p&gt;
    &lt;code&gt;const enum Language {
    English = 'EN',
    Spanish = 'ES',
}
console.log(Language.English);&lt;/code&gt;
    &lt;p&gt;Will be compiled into:&lt;/p&gt;
    &lt;code&gt;console.log('EN' /* Language.English */);&lt;/code&gt;
    &lt;p&gt;Notes: Const Enums have hardcoded values, erasing the Enum, which can be more efficient in self-contained libraries but is generally not desirable. Also, Const enums cannot have computed members.&lt;/p&gt;
    &lt;p&gt;In TypeScript, reverse mappings in Enums refer to the ability to retrieve the Enum member name from its value. By default, Enum members have forward mappings from name to value, but reverse mappings can be created by explicitly setting values for each member. Reverse mappings are useful when you need to look up an Enum member by its value, or when you need to iterate over all the Enum members. Note that only numeric enums members will generate reverse mappings, while String Enum members do not get a reverse mapping generated at all.&lt;/p&gt;
    &lt;p&gt;The following enum:&lt;/p&gt;
    &lt;code&gt;enum Grade {
    A = 90,
    B = 80,
    C = 70,
    F = 'fail',
}&lt;/code&gt;
    &lt;p&gt;Compiles to:&lt;/p&gt;
    &lt;code&gt;'use strict';
var Grade;
(function (Grade) {
    Grade[(Grade['A'] = 90)] = 'A';
    Grade[(Grade['B'] = 80)] = 'B';
    Grade[(Grade['C'] = 70)] = 'C';
    Grade['F'] = 'fail';
})(Grade || (Grade = {}));&lt;/code&gt;
    &lt;p&gt;Therefore, mapping values to keys works for numeric enum members, but not for string enum members:&lt;/p&gt;
    &lt;code&gt;enum Grade {
    A = 90,
    B = 80,
    C = 70,
    F = 'fail',
}
const myGrade = Grade.A;
console.log(Grade[myGrade]); // A
console.log(Grade[90]); // A

const failGrade = Grade.F;
console.log(failGrade); // fail
console.log(Grade[failGrade]); // Element implicitly has an 'any' type because index expression is not of type 'number'.&lt;/code&gt;
    &lt;p&gt;An ambient enum in TypeScript is a type of Enum that is defined in a declaration file (*.d.ts) without an associated implementation. It allows you to define a set of named constants that can be used in a type-safe way across different files without having to import the implementation details in each file.&lt;/p&gt;
    &lt;p&gt;In TypeScript, a computed member is a member of an Enum that has a value calculated at runtime, while a constant member is a member whose value is set at compile-time and cannot be changed during runtime. Computed members are allowed in regular Enums, while constant members are allowed in both regular and const enums.&lt;/p&gt;
    &lt;code&gt;// Constant members
enum Color {
    Red = 1,
    Green = 5,
    Blue = Red + Green,
}
console.log(Color.Blue); // 6 generation at compilation time&lt;/code&gt;
    &lt;code&gt;// Computed members
enum Color {
    Red = 1,
    Green = Math.pow(2, 2),
    Blue = Math.floor(Math.random() * 3) + 1,
}
console.log(Color.Blue); // random number generated at run time&lt;/code&gt;
    &lt;p&gt;Enums are denoted by unions comprising their member types. The values of each member can be determined through constant or non-constant expressions, with members possessing constant values being assigned literal types. To illustrate, consider the declaration of type E and its subtypes E.A, E.B, and E.C. In this case, E represents the union E.A | E.B | E.C.&lt;/p&gt;
    &lt;code&gt;const identity = (value: number) =&amp;gt; value;

enum E {
    A = 2 * 5, // Numeric literal
    B = 'bar', // String literal
    C = identity(42), // Opaque computed
}

console.log(E.C); //42&lt;/code&gt;
    &lt;p&gt;TypeScript narrowing is the process of refining the type of a variable within a conditional block. This is useful when working with union types, where a variable can have more than one type.&lt;/p&gt;
    &lt;p&gt;TypeScript recognizes several ways to narrow the type:&lt;/p&gt;
    &lt;p&gt;The typeof type guard is one specific type guard in TypeScript that checks the type of a variable based on its built-in JavaScript type.&lt;/p&gt;
    &lt;code&gt;const fn = (x: number | string) =&amp;gt; {
    if (typeof x === 'number') {
        return x + 1; // x is number
    }
    return -1;
};&lt;/code&gt;
    &lt;p&gt;Truthiness narrowing in TypeScript works by checking whether a variable is truthy or falsy to narrow its type accordingly.&lt;/p&gt;
    &lt;code&gt;const toUpperCase = (name: string | null) =&amp;gt; {
    if (name) {
        return name.toUpperCase();
    } else {
        return null;
    }
};&lt;/code&gt;
    &lt;p&gt;Equality narrowing in TypeScript works by checking whether a variable is equal to a specific value or not, to narrow its type accordingly.&lt;/p&gt;
    &lt;p&gt;It is used in conjunction with &lt;code&gt;switch&lt;/code&gt; statements and equality operators such as &lt;code&gt;===&lt;/code&gt;, &lt;code&gt;!==&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, and &lt;code&gt;!=&lt;/code&gt; to narrow down types.&lt;/p&gt;
    &lt;code&gt;const checkStatus = (status: 'success' | 'error') =&amp;gt; {
    switch (status) {
        case 'success':
            return true;
        case 'error':
            return null;
    }
};&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;in&lt;/code&gt; Operator narrowing in TypeScript is a way to narrow the type of a variable based on whether a property exists within the variable's type.&lt;/p&gt;
    &lt;code&gt;type Dog = {
    name: string;
    breed: string;
};

type Cat = {
    name: string;
    likesCream: boolean;
};

const getAnimalType = (pet: Dog | Cat) =&amp;gt; {
    if ('breed' in pet) {
        return 'dog';
    } else {
        return 'cat';
    }
};&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;instanceof&lt;/code&gt; operator narrowing in TypeScript is a way to narrow the type of a variable based on its constructor function, by checking if an object is an instance of a certain class or interface.&lt;/p&gt;
    &lt;code&gt;class Square {
    constructor(public width: number) {}
}
class Rectangle {
    constructor(
        public width: number,
        public height: number
    ) {}
}
function area(shape: Square | Rectangle) {
    if (shape instanceof Square) {
        return shape.width * shape.width;
    } else {
        return shape.width * shape.height;
    }
}
const square = new Square(5);
const rectangle = new Rectangle(5, 10);
console.log(area(square)); // 25
console.log(area(rectangle)); // 50&lt;/code&gt;
    &lt;p&gt;TypeScript narrowing using assignments is a way to narrow the type of a variable based on the value assigned to it. When a variable is assigned a value, TypeScript infers its type based on the assigned value, and it narrows the type of the variable to match the inferred type.&lt;/p&gt;
    &lt;code&gt;let value: string | number;
value = 'hello';
if (typeof value === 'string') {
    console.log(value.toUpperCase());
}
value = 42;
if (typeof value === 'number') {
    console.log(value.toFixed(2));
}&lt;/code&gt;
    &lt;p&gt;Control Flow Analysis in TypeScript is a way to statically analyze the code flow to infer the types of variables, allowing the compiler to narrow the types of those variables as needed, based on the results of the analysis.&lt;/p&gt;
    &lt;p&gt;Prior to TypeScript 4.4, code flow analysis would only be applied to code within an if statement, but from TypeScript 4.4, it can also be applied to conditional expressions and discriminant property accesses indirectly referenced through const variables.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;const f1 = (x: unknown) =&amp;gt; {
    const isString = typeof x === 'string';
    if (isString) {
        x.length;
    }
};

const f2 = (
    obj: { kind: 'foo'; foo: string } | { kind: 'bar'; bar: number }
) =&amp;gt; {
    const isFoo = obj.kind === 'foo';
    if (isFoo) {
        obj.foo;
    } else {
        obj.bar;
    }
};&lt;/code&gt;
    &lt;p&gt;Some examples where narrowing does not occur:&lt;/p&gt;
    &lt;code&gt;const f1 = (x: unknown) =&amp;gt; {
    let isString = typeof x === 'string';
    if (isString) {
        x.length; // Error, no narrowing because isString it is not const
    }
};

const f6 = (
    obj: { kind: 'foo'; foo: string } | { kind: 'bar'; bar: number }
) =&amp;gt; {
    const isFoo = obj.kind === 'foo';
    obj = obj;
    if (isFoo) {
        obj.foo; // Error, no narrowing because obj is assigned in function body
    }
};&lt;/code&gt;
    &lt;p&gt;Notes: Up to five levels of indirection are analyzed in conditional expressions.&lt;/p&gt;
    &lt;p&gt;Type Predicates in TypeScript are functions that return a boolean value and are used to narrow the type of a variable to a more specific type.&lt;/p&gt;
    &lt;code&gt;const isString = (value: unknown): value is string =&amp;gt; typeof value === 'string';

const foo = (bar: unknown) =&amp;gt; {
    if (isString(bar)) {
        console.log(bar.toUpperCase());
    } else {
        console.log('not a string');
    }
};&lt;/code&gt;
    &lt;p&gt;Discriminated Unions in TypeScript are a type of union type that uses a common property, known as the discriminant, to narrow down the set of possible types for the union.&lt;/p&gt;
    &lt;code&gt;type Square = {
    kind: 'square'; // Discriminant
    size: number;
};

type Circle = {
    kind: 'circle'; // Discriminant
    radius: number;
};

type Shape = Square | Circle;

const area = (shape: Shape) =&amp;gt; {
    switch (shape.kind) {
        case 'square':
            return Math.pow(shape.size, 2);
        case 'circle':
            return Math.PI * Math.pow(shape.radius, 2);
    }
};

const square: Square = { kind: 'square', size: 5 };
const circle: Circle = { kind: 'circle', radius: 2 };

console.log(area(square)); // 25
console.log(area(circle)); // 12.566370614359172&lt;/code&gt;
    &lt;p&gt;When a variable is narrowed to a type that cannot contain any values, the TypeScript compiler will infer that the variable must be of the &lt;code&gt;never&lt;/code&gt; type. This is because The never Type represents a value that can never be produced.&lt;/p&gt;
    &lt;code&gt;const printValue = (val: string | number) =&amp;gt; {
    if (typeof val === 'string') {
        console.log(val.toUpperCase());
    } else if (typeof val === 'number') {
        console.log(val.toFixed(2));
    } else {
        // val has type never here because it can never be anything other than a string or a number
        const neverVal: never = val;
        console.log(`Unexpected value: ${neverVal}`);
    }
};&lt;/code&gt;
    &lt;p&gt;Exhaustiveness checking is a feature in TypeScript that ensures all possible cases of a discriminated union are handled in a &lt;code&gt;switch&lt;/code&gt; statement or an &lt;code&gt;if&lt;/code&gt; statement.&lt;/p&gt;
    &lt;code&gt;type Direction = 'up' | 'down';

const move = (direction: Direction) =&amp;gt; {
    switch (direction) {
        case 'up':
            console.log('Moving up');
            break;
        case 'down':
            console.log('Moving down');
            break;
        default:
            const exhaustiveCheck: never = direction;
            console.log(exhaustiveCheck); // This line will never be executed
    }
};&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;never&lt;/code&gt; type is used to ensure that the default case is exhaustive and that TypeScript will raise an error if a new value is added to the Direction type without being handled in the switch statement.&lt;/p&gt;
    &lt;p&gt;In TypeScript, object types describe the shape of an object. They specify the names and types of the object's properties, as well as whether those properties are required or optional.&lt;/p&gt;
    &lt;p&gt;In TypeScript, you can define object types in two primary ways:&lt;/p&gt;
    &lt;p&gt;Interface which defines the shape of an object by specifying the names, types, and optionality of its properties.&lt;/p&gt;
    &lt;code&gt;interface User {
    name: string;
    age: number;
    email?: string;
}&lt;/code&gt;
    &lt;p&gt;Type alias, similar to an interface, defines the shape of an object. However, it can also create a new custom type that is based on an existing type or a combination of existing types. This includes defining union types, intersection types, and other complex types.&lt;/p&gt;
    &lt;code&gt;type Point = {
    x: number;
    y: number;
};&lt;/code&gt;
    &lt;p&gt;It also possible to define a type anonymously:&lt;/p&gt;
    &lt;code&gt;const sum = (x: { a: number; b: number }) =&amp;gt; x.a + x.b;
console.log(sum({ a: 5, b: 1 }));&lt;/code&gt;
    &lt;p&gt;A Tuple Type is a type that represents an array with a fixed number of elements and their corresponding types. A tuple type enforces a specific number of elements and their respective types in a fixed order. Tuple types are useful when you want to represent a collection of values with specific types, where the position of each element in the array has a specific meaning.&lt;/p&gt;
    &lt;code&gt;type Point = [number, number];&lt;/code&gt;
    &lt;p&gt;Tuple types can include optional labels or names for each element. These labels are for readability and tooling assistance, and do not affect the operations you can perform with them.&lt;/p&gt;
    &lt;code&gt;type T = string;
type Tuple1 = [T, T];
type Tuple2 = [a: T, b: T];
type Tuple3 = [a: T, T]; // Named Tuple plus Anonymous Tuple&lt;/code&gt;
    &lt;p&gt;A Fixed Length Tuple is a specific type of tuple that enforces a fixed number of elements of specific types, and disallows any modifications to the length of the tuple once it is defined.&lt;/p&gt;
    &lt;p&gt;Fixed Length Tuples are useful when you need to represent a collection of values with a specific number of elements and specific types, and you want to ensure that the length and types of the tuple cannot be changed inadvertently.&lt;/p&gt;
    &lt;code&gt;const x = [10, 'hello'] as const;
x.push(2); // Error&lt;/code&gt;
    &lt;p&gt;A Union Type is a type that represents a value that can be one of several types. Union Types are denoted using the &lt;code&gt;|&lt;/code&gt; symbol between each possible type.&lt;/p&gt;
    &lt;code&gt;let x: string | number;
x = 'hello'; // Valid
x = 123; // Valid&lt;/code&gt;
    &lt;p&gt;An Intersection Type is a type that represents a value that has all the properties of two or more types. Intersection Types are denoted using the &lt;code&gt;&amp;amp;&lt;/code&gt; symbol between each type.&lt;/p&gt;
    &lt;code&gt;type X = {
    a: string;
};

type Y = {
    b: string;
};

type J = X &amp;amp; Y; // Intersection

const j: J = {
    a: 'a',
    b: 'b',
};&lt;/code&gt;
    &lt;p&gt;Type indexing refers to the ability to define types that can be indexed by a key that is not known in advance, using an index signature to specify the type for properties that are not explicitly declared.&lt;/p&gt;
    &lt;code&gt;type Dictionary&amp;lt;T&amp;gt; = {
    [key: string]: T;
};
const myDict: Dictionary&amp;lt;string&amp;gt; = { a: 'a', b: 'b' };
console.log(myDict['a']); // Returns a&lt;/code&gt;
    &lt;p&gt;Type from Value in TypeScript refers to the automatic inference of a type from a value or expression through type inference.&lt;/p&gt;
    &lt;code&gt;const x = 'x'; // TypeScript infers 'x' as a string literal with 'const' (immutable), but widens it to 'string' with 'let' (reassignable).&lt;/code&gt;
    &lt;p&gt;Type from Func Return refers to the ability to automatically infer the return type of a function based on its implementation. This allows TypeScript to determine the type of the value returned by the function without explicit type annotations.&lt;/p&gt;
    &lt;code&gt;const add = (x: number, y: number) =&amp;gt; x + y; // TypeScript can infer that the return type of the function is a number&lt;/code&gt;
    &lt;p&gt;Type from Module refers to the ability to use a module's exported values to automatically infer their types. When a module exports a value with a specific type, TypeScript can use that information to automatically infer the type of that value when it is imported into another module.&lt;/p&gt;
    &lt;code&gt;// calc.ts
export const add = (x: number, y: number) =&amp;gt; x + y;
// index.ts
import { add } from 'calc';
const r = add(1, 2); // r is number&lt;/code&gt;
    &lt;p&gt;Mapped Types in TypeScript allow you to create new types based on an existing type by transforming each property using a mapping function. By mapping existing types, you can create new types that represent the same information in a different format. To create a mapped type, you access the properties of an existing type using the &lt;code&gt;keyof&lt;/code&gt; operator and then alter them to produce a new type.
In the following example:&lt;/p&gt;
    &lt;code&gt;type MyMappedType&amp;lt;T&amp;gt; = {
    [P in keyof T]: T[P][];
};
type MyType = {
    foo: string;
    bar: number;
};
type MyNewType = MyMappedType&amp;lt;MyType&amp;gt;;
const x: MyNewType = {
    foo: ['hello', 'world'],
    bar: [1, 2, 3],
};&lt;/code&gt;
    &lt;p&gt;we define MyMappedType to map over T's properties, creating a new type with each property as an array of its original type. Using this, we create MyNewType to represent the same info as MyType, but with each property as an array.&lt;/p&gt;
    &lt;p&gt;Mapped Type Modifiers in TypeScript enable the transformation of properties within an existing type:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;readonly&lt;/code&gt;or&lt;code&gt;+readonly&lt;/code&gt;: This renders a property in the mapped type as read-only.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-readonly&lt;/code&gt;: This allows a property in the mapped type to be mutable.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;?&lt;/code&gt;: This designates a property in the mapped type as optional.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;type ReadOnly&amp;lt;T&amp;gt; = { readonly [P in keyof T]: T[P] }; // All properties marked as read-only

type Mutable&amp;lt;T&amp;gt; = { -readonly [P in keyof T]: T[P] }; // All properties marked as mutable

type MyPartial&amp;lt;T&amp;gt; = { [P in keyof T]?: T[P] }; // All properties marked as optional&lt;/code&gt;
    &lt;p&gt;Conditional Types are a way to create a type that depends on a condition, where the type to be created is determined based on the result of the condition. They are defined using the &lt;code&gt;extends&lt;/code&gt; keyword and a ternary operator to conditionally choose between two types.&lt;/p&gt;
    &lt;code&gt;type IsArray&amp;lt;T&amp;gt; = T extends any[] ? true : false;

const myArray = [1, 2, 3];
const myNumber = 42;

type IsMyArrayAnArray = IsArray&amp;lt;typeof myArray&amp;gt;; // Type true
type IsMyNumberAnArray = IsArray&amp;lt;typeof myNumber&amp;gt;; // Type false&lt;/code&gt;
    &lt;p&gt;Distributive Conditional Types are a feature that allow a type to be distributed over a union of types, by applying a transformation to each member of the union individually. This can be especially useful when working with mapped types or higher-order types.&lt;/p&gt;
    &lt;code&gt;type Nullable&amp;lt;T&amp;gt; = T extends any ? T | null : never;
type NumberOrBool = number | boolean;
type NullableNumberOrBool = Nullable&amp;lt;NumberOrBool&amp;gt;; // number | boolean | null&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;infer&lt;/code&gt;keyword is used in conditional types to infer (extract) the type of a generic parameter from a type that depends on it. This allows you to write more flexible and reusable type definitions.&lt;/p&gt;
    &lt;code&gt;type ElementType&amp;lt;T&amp;gt; = T extends (infer U)[] ? U : never;
type Numbers = ElementType&amp;lt;number[]&amp;gt;; // number
type Strings = ElementType&amp;lt;string[]&amp;gt;; // string&lt;/code&gt;
    &lt;p&gt;In TypeScript, Predefined Conditional Types are built-in conditional types provided by the language. They are designed to perform common type transformations based on the characteristics of a given type.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Exclude&amp;lt;UnionType, ExcludedType&amp;gt;&lt;/code&gt;: This type removes all the types from Type that are assignable to ExcludedType.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Extract&amp;lt;Type, Union&amp;gt;&lt;/code&gt;: This type extracts all the types from Union that are assignable to Type.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;NonNullable&amp;lt;Type&amp;gt;&lt;/code&gt;: This type removes null and undefined from Type.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ReturnType&amp;lt;Type&amp;gt;&lt;/code&gt;: This type extracts the return type of a function Type.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Parameters&amp;lt;Type&amp;gt;&lt;/code&gt;: This type extracts the parameter types of a function Type.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Required&amp;lt;Type&amp;gt;&lt;/code&gt;: This type makes all properties in Type required.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Partial&amp;lt;Type&amp;gt;&lt;/code&gt;: This type makes all properties in Type optional.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Readonly&amp;lt;Type&amp;gt;&lt;/code&gt;: This type makes all properties in Type readonly.&lt;/p&gt;
    &lt;p&gt;Template union types can be used to merge and manipulate text inside the type system for instance:&lt;/p&gt;
    &lt;code&gt;type Status = 'active' | 'inactive';
type Products = 'p1' | 'p2';
type ProductId = `id-${Products}-${Status}`; // "id-p1-active" | "id-p1-inactive" | "id-p2-active" | "id-p2-inactive"&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;any&lt;/code&gt; type is a special type (universal supertype) that can be used to represent any type of value (primitives, objects, arrays, functions, errors, symbols). It is often used in situations where the type of a value is not known at compile time, or when working with values from external APIs or libraries that do not have TypeScript typings.&lt;/p&gt;
    &lt;p&gt;By utilizing &lt;code&gt;any&lt;/code&gt; type, you are indicating to the TypeScript compiler that values should be represented without any limitations. In order to maximizing type safety in your code consider the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limit the usage of &lt;code&gt;any&lt;/code&gt;to specific cases where the type is truly unknown.&lt;/item&gt;
      &lt;item&gt;Do not return &lt;code&gt;any&lt;/code&gt;types from a function as you will lose type safety in the code using that function weakening your type safety.&lt;/item&gt;
      &lt;item&gt;Instead of &lt;code&gt;any&lt;/code&gt;use&lt;code&gt;@ts-ignore&lt;/code&gt;if you need to silence the compiler.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;let value: any;
value = true; // Valid
value = 7; // Valid&lt;/code&gt;
    &lt;p&gt;In TypeScript, the &lt;code&gt;unknown&lt;/code&gt; type represents a value that is of an unknown type. Unlike &lt;code&gt;any&lt;/code&gt; type, which allows for any type of value, &lt;code&gt;unknown&lt;/code&gt; requires a type check or assertion before it can be used in a specific way so no operations are permitted on an &lt;code&gt;unknown&lt;/code&gt; without first asserting or narrowing to a more specific type.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;unknown&lt;/code&gt; type is only assignable to any type and the &lt;code&gt;unknown&lt;/code&gt; type itself, it is a type-safe alternative to &lt;code&gt;any&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;let value: unknown;

let value1: unknown = value; // Valid
let value2: any = value; // Valid
let value3: boolean = value; // Invalid
let value4: number = value; // Invalid&lt;/code&gt;
    &lt;code&gt;const add = (a: unknown, b: unknown): number | undefined =&amp;gt;
    typeof a === 'number' &amp;amp;&amp;amp; typeof b === 'number' ? a + b : undefined;
console.log(add(1, 2)); // 3
console.log(add('x', 2)); // undefined&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;void&lt;/code&gt; type is used to indicate that a function does not return a value.&lt;/p&gt;
    &lt;code&gt;const sayHello = (): void =&amp;gt; {
    console.log('Hello!');
};&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;never&lt;/code&gt; type represents values that never occur. It is used to denote functions or expressions that never return or throw an error.&lt;/p&gt;
    &lt;p&gt;For instance an infinite loop:&lt;/p&gt;
    &lt;code&gt;const infiniteLoop = (): never =&amp;gt; {
    while (true) {
        // do something
    }
};&lt;/code&gt;
    &lt;p&gt;Throwing an error:&lt;/p&gt;
    &lt;code&gt;const throwError = (message: string): never =&amp;gt; {
    throw new Error(message);
};&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;never&lt;/code&gt; type is useful in ensuring type safety and catching potential errors in your code. It helps TypeScript analyze and infer more precise types when used in combination with other types and control flow statements, for instance:&lt;/p&gt;
    &lt;code&gt;type Direction = 'up' | 'down';
const move = (direction: Direction): void =&amp;gt; {
    switch (direction) {
        case 'up':
            // move up
            break;
        case 'down':
            // move down
            break;
        default:
            const exhaustiveCheck: never = direction;
            throw new Error(`Unhandled direction: ${exhaustiveCheck}`);
    }
};&lt;/code&gt;
    &lt;p&gt;In TypeScript, interfaces define the structure of objects, specifying the names and types of properties or methods that an object must have. The common syntax for defining an interface in TypeScript is as follows:&lt;/p&gt;
    &lt;code&gt;interface InterfaceName {
    property1: Type1;
    // ...
    method1(arg1: ArgType1, arg2: ArgType2): ReturnType;
    // ...
}&lt;/code&gt;
    &lt;p&gt;Similarly for type definition:&lt;/p&gt;
    &lt;code&gt;type TypeName = {
    property1: Type1;
    // ...
    method1(arg1: ArgType1, arg2: ArgType2): ReturnType;
    // ...
};&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;interface InterfaceName&lt;/code&gt; or &lt;code&gt;type TypeName&lt;/code&gt;: Defines the name of the interface.
&lt;code&gt;property1&lt;/code&gt;: &lt;code&gt;Type1&lt;/code&gt;: Specifies the properties of the interface along with their corresponding types. Multiple properties can be defined, each separated by a semicolon.
&lt;code&gt;method1(arg1: ArgType1, arg2: ArgType2): ReturnType;&lt;/code&gt;: Specifies the methods of the interface. Methods are defined with their names, followed by a parameter list in parentheses and the return type. Multiple methods can be defined, each separated by a semicolon.&lt;/p&gt;
    &lt;p&gt;Example interface:&lt;/p&gt;
    &lt;code&gt;interface Person {
    name: string;
    age: number;
    greet(): void;
}&lt;/code&gt;
    &lt;p&gt;Example of type:&lt;/p&gt;
    &lt;code&gt;type TypeName = {
    property1: string;
    method1(arg1: string, arg2: string): string;
};&lt;/code&gt;
    &lt;p&gt;In TypeScript, types are used to define the shape of data and enforce type checking. There are several common syntaxes for defining types in TypeScript, depending on the specific use case. Here are some examples:&lt;/p&gt;
    &lt;code&gt;let myNumber: number = 123; // number type
let myBoolean: boolean = true; // boolean type
let myArray: string[] = ['a', 'b']; // array of strings
let myTuple: [string, number] = ['a', 123]; // tuple&lt;/code&gt;
    &lt;code&gt;const x: { name: string; age: number } = { name: 'Simon', age: 7 };&lt;/code&gt;
    &lt;code&gt;type MyType = string | number; // Union type
let myUnion: MyType = 'hello'; // Can be a string
myUnion = 123; // Or a number

type TypeA = { name: string };
type TypeB = { age: number };
type CombinedType = TypeA &amp;amp; TypeB; // Intersection type
let myCombined: CombinedType = { name: 'John', age: 25 }; // Object with both name and age properties&lt;/code&gt;
    &lt;p&gt;TypeScript has several built-in type primitives that can be used to define variables, function parameters, and return types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;number&lt;/code&gt;: Represents numeric values, including integers and floating-point numbers.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;string&lt;/code&gt;: Represents textual data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;boolean&lt;/code&gt;: Represents logical values, which can be either true or false.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;null&lt;/code&gt;: Represents the absence of a value.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;undefined&lt;/code&gt;: Represents a value that has not been assigned or has not been defined.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;symbol&lt;/code&gt;: Represents a unique identifier. Symbols are typically used as keys for object properties.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bigint&lt;/code&gt;: Represents arbitrary-precision integers.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;any&lt;/code&gt;: Represents a dynamic or unknown type. Variables of type any can hold values of any type, and they bypass type checking.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;void&lt;/code&gt;: Represents the absence of any type. It is commonly used as the return type of functions that do not return a value.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;never&lt;/code&gt;: Represents a type for values that never occur. It is typically used as the return type of functions that throw an error or enter an infinite loop.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TypeScript is a superset of JavaScript, it includes all the commonly used built-in JavaScript objects. You can find an extensive list of these objects on the Mozilla Developer Network (MDN) documentation website: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects&lt;/p&gt;
    &lt;p&gt;Here is a list of some commonly used built-in JavaScript objects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function&lt;/item&gt;
      &lt;item&gt;Object&lt;/item&gt;
      &lt;item&gt;Boolean&lt;/item&gt;
      &lt;item&gt;Error&lt;/item&gt;
      &lt;item&gt;Number&lt;/item&gt;
      &lt;item&gt;BigInt&lt;/item&gt;
      &lt;item&gt;Math&lt;/item&gt;
      &lt;item&gt;Date&lt;/item&gt;
      &lt;item&gt;String&lt;/item&gt;
      &lt;item&gt;RegExp&lt;/item&gt;
      &lt;item&gt;Array&lt;/item&gt;
      &lt;item&gt;Map&lt;/item&gt;
      &lt;item&gt;Set&lt;/item&gt;
      &lt;item&gt;Promise&lt;/item&gt;
      &lt;item&gt;Intl&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Function overloads in TypeScript allow you to define multiple function signatures for a single function name, enabling you to define functions that can be called in multiple ways. Here's an example:&lt;/p&gt;
    &lt;code&gt;// Overloads
function sayHi(name: string): string;
function sayHi(names: string[]): string[];

// Implementation
function sayHi(name: unknown): unknown {
    if (typeof name === 'string') {
        return `Hi, ${name}!`;
    } else if (Array.isArray(name)) {
        return name.map(name =&amp;gt; `Hi, ${name}!`);
    }
    throw new Error('Invalid value');
}

sayHi('xx'); // Valid
sayHi(['aa', 'bb']); // Valid&lt;/code&gt;
    &lt;p&gt;Here's another example of using function overloads within a &lt;code&gt;class&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;class Greeter {
    message: string;

    constructor(message: string) {
        this.message = message;
    }

    // overload
    sayHi(name: string): string;
    sayHi(names: string[]): ReadonlyArray&amp;lt;string&amp;gt;;

    // implementation
    sayHi(name: unknown): unknown {
        if (typeof name === 'string') {
            return `${this.message}, ${name}!`;
        } else if (Array.isArray(name)) {
            return name.map(name =&amp;gt; `${this.message}, ${name}!`);
        }
        throw new Error('value is invalid');
    }
}
console.log(new Greeter('Hello').sayHi('Simon'));&lt;/code&gt;
    &lt;p&gt;Merging and extension refer to two different concepts related to working with types and interfaces.&lt;/p&gt;
    &lt;p&gt;Merging allows you to combine multiple declarations of the same name into a single definition, for example, when you define an interface with the same name multiple times:&lt;/p&gt;
    &lt;code&gt;interface X {
    a: string;
}

interface X {
    b: number;
}

const person: X = {
    a: 'a',
    b: 7,
};&lt;/code&gt;
    &lt;p&gt;Extension refers to the ability to extend or inherit from existing types or interfaces to create new ones. It is a mechanism to add additional properties or methods to an existing type without modifying its original definition. Example:&lt;/p&gt;
    &lt;code&gt;interface Animal {
    name: string;
    eat(): void;
}

interface Bird extends Animal {
    sing(): void;
}

const dog: Bird = {
    name: 'Bird 1',
    eat() {
        console.log('Eating');
    },
    sing() {
        console.log('Singing');
    },
};&lt;/code&gt;
    &lt;p&gt;Declaration merging (augmentation):&lt;/p&gt;
    &lt;p&gt;Interfaces support declaration merging, which means that you can define multiple interfaces with the same name, and TypeScript will merge them into a single interface with the combined properties and methods. On the other hand, types do not support declaration merging. This can be helpful when you want to add extra functionality or customize existing types without modifying the original definitions or patching missing or incorrect types.&lt;/p&gt;
    &lt;code&gt;interface A {
    x: string;
}
interface A {
    y: string;
}
const j: A = {
    x: 'xx',
    y: 'yy',
};&lt;/code&gt;
    &lt;p&gt;Extending other types/interfaces:&lt;/p&gt;
    &lt;p&gt;Both types and interfaces can extend other types/interfaces, but the syntax is different. With interfaces, you use the &lt;code&gt;extends&lt;/code&gt; keyword to inherit properties and methods from other interfaces. However, an interface cannot extend a complex type like a union type.&lt;/p&gt;
    &lt;code&gt;interface A {
    x: string;
    y: number;
}
interface B extends A {
    z: string;
}
const car: B = {
    x: 'x',
    y: 123,
    z: 'z',
};&lt;/code&gt;
    &lt;p&gt;For types, you use the &amp;amp; operator to combine multiple types into a single type (intersection).&lt;/p&gt;
    &lt;code&gt;interface A {
    x: string;
    y: number;
}

type B = A &amp;amp; {
    j: string;
};

const c: B = {
    x: 'x',
    y: 123,
    j: 'j',
};&lt;/code&gt;
    &lt;p&gt;Union and Intersection Types:&lt;/p&gt;
    &lt;p&gt;Types are more flexible when it comes to defining Union and Intersection Types. With the &lt;code&gt;type&lt;/code&gt; keyword, you can easily create union types using the &lt;code&gt;|&lt;/code&gt; operator and intersection types using the &lt;code&gt;&amp;amp;&lt;/code&gt; operator. While interfaces can also represent union types indirectly, they don't have built-in support for intersection types.&lt;/p&gt;
    &lt;code&gt;type Department = 'dep-x' | 'dep-y'; // Union

type Person = {
    name: string;
    age: number;
};

type Employee = {
    id: number;
    department: Department;
};

type EmployeeInfo = Person &amp;amp; Employee; // Intersection&lt;/code&gt;
    &lt;p&gt;Example with interfaces:&lt;/p&gt;
    &lt;code&gt;interface A {
    x: 'x';
}
interface B {
    y: 'y';
}

type C = A | B; // Union of interfaces&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;class&lt;/code&gt; keyword is used in TypeScript to define a class. Below, you can see an example:&lt;/p&gt;
    &lt;code&gt;class Person {
    private name: string;
    private age: number;
    constructor(name: string, age: number) {
        this.name = name;
        this.age = age;
    }
    public sayHi(): void {
        console.log(
            `Hello, my name is ${this.name} and I am ${this.age} years old.`
        );
    }
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;class&lt;/code&gt; keyword is used to define a class named "Person".&lt;/p&gt;
    &lt;p&gt;The class has two private properties: name of type &lt;code&gt;string&lt;/code&gt; and age of type &lt;code&gt;number&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The constructor is defined using the &lt;code&gt;constructor&lt;/code&gt; keyword. It takes name and age as parameters and assigns them to the corresponding properties.&lt;/p&gt;
    &lt;p&gt;The class has a &lt;code&gt;public&lt;/code&gt; method named sayHi that logs a greeting message.&lt;/p&gt;
    &lt;p&gt;To create an instance of a class in TypeScript, you can use the &lt;code&gt;new&lt;/code&gt; keyword followed by the class name, followed by parentheses &lt;code&gt;()&lt;/code&gt;. For instance:&lt;/p&gt;
    &lt;code&gt;const myObject = new Person('John Doe', 25);
myObject.sayHi(); // Output: Hello, my name is John Doe and I am 25 years old.&lt;/code&gt;
    &lt;p&gt;Constructors are special methods within a class that are used to initialize the object's properties when an instance of the class is created.&lt;/p&gt;
    &lt;code&gt;class Person {
    public name: string;
    public age: number;

    constructor(name: string, age: number) {
        this.name = name;
        this.age = age;
    }

    sayHello() {
        console.log(
            `Hello, my name is ${this.name} and I'm ${this.age} years old.`
        );
    }
}

const john = new Person('Simon', 17);
john.sayHello();&lt;/code&gt;
    &lt;p&gt;It is possible to overload a constructor using the following syntax:&lt;/p&gt;
    &lt;code&gt;type Sex = 'm' | 'f';

class Person {
    name: string;
    age: number;
    sex: Sex;

    constructor(name: string, age: number, sex?: Sex);
    constructor(name: string, age: number, sex: Sex) {
        this.name = name;
        this.age = age;
        this.sex = sex ?? 'm';
    }
}

const p1 = new Person('Simon', 17);
const p2 = new Person('Alice', 22, 'f');&lt;/code&gt;
    &lt;p&gt;In TypeScript, it is possible to define multiple constructor overloads, but you can have only one implementation that must be compatible with all the overloads, this can be achieved by using an optional parameter.&lt;/p&gt;
    &lt;code&gt;class Person {
    name: string;
    age: number;

    constructor();
    constructor(name: string);
    constructor(name: string, age: number);
    constructor(name?: string, age?: number) {
        this.name = name ?? 'Unknown';
        this.age = age ?? 0;
    }

    displayInfo() {
        console.log(`Name: ${this.name}, Age: ${this.age}`);
    }
}

const person1 = new Person();
person1.displayInfo(); // Name: Unknown, Age: 0

const person2 = new Person('John');
person2.displayInfo(); // Name: John, Age: 0

const person3 = new Person('Jane', 25);
person3.displayInfo(); // Name: Jane, Age: 25&lt;/code&gt;
    &lt;p&gt;In TypeScript, constructors can be marked as private or protected, which restricts their accessibility and usage.&lt;/p&gt;
    &lt;p&gt;Private Constructors: Can be called only within the class itself. Private constructors are often used in scenarios where you want to enforce a singleton pattern or restrict the creation of instances to a factory method within the class&lt;/p&gt;
    &lt;p&gt;Protected Constructors: Protected constructors are useful when you want to create a base class that should not be instantiated directly but can be extended by subclasses.&lt;/p&gt;
    &lt;code&gt;class BaseClass {
    protected constructor() {}
}

class DerivedClass extends BaseClass {
    private value: number;

    constructor(value: number) {
        super();
        this.value = value;
    }
}

// Attempting to instantiate the base class directly will result in an error
// const baseObj = new BaseClass(); // Error: Constructor of class 'BaseClass' is protected.

// Create an instance of the derived class
const derivedObj = new DerivedClass(10);&lt;/code&gt;
    &lt;p&gt;Access Modifiers &lt;code&gt;private&lt;/code&gt;, &lt;code&gt;protected&lt;/code&gt;, and &lt;code&gt;public&lt;/code&gt; are used to control the visibility and accessibility of class members, such as properties and methods, in TypeScript classes. These modifiers are essential for enforcing encapsulation and establishing boundaries for accessing and modifying the internal state of a class.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;private&lt;/code&gt; modifier restricts access to the class member only within the containing class.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;protected&lt;/code&gt; modifier allows access to the class member within the containing class and its derived classes.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;public&lt;/code&gt; modifier provides unrestricted access to the class member, allowing it to be accessed from anywhere."&lt;/p&gt;
    &lt;p&gt;Getters and setters are special methods that allow you to define custom access and modification behavior for class properties. They enable you to encapsulate the internal state of an object and provide additional logic when getting or setting the values of properties. In TypeScript, getters and setters are defined using the &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;set&lt;/code&gt; keywords respectively. Here's an example:&lt;/p&gt;
    &lt;code&gt;class MyClass {
    private _myProperty: string;

    constructor(value: string) {
        this._myProperty = value;
    }
    get myProperty(): string {
        return this._myProperty;
    }
    set myProperty(value: string) {
        this._myProperty = value;
    }
}&lt;/code&gt;
    &lt;p&gt;TypeScript version 4.9 adds support for auto-accessors, a forthcoming ECMAScript feature. They resemble class properties but are declared with the "accessor" keyword.&lt;/p&gt;
    &lt;code&gt;class Animal {
    accessor name: string;

    constructor(name: string) {
        this.name = name;
    }
}&lt;/code&gt;
    &lt;p&gt;Auto-accessors are "de-sugared" into private &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;set&lt;/code&gt; accessors, operating on an inaccessible property.&lt;/p&gt;
    &lt;code&gt;class Animal {
    #__name: string;

    get name() {
        return this.#__name;
    }
    set name(value: string) {
        this.#__name = name;
    }

    constructor(name: string) {
        this.name = name;
    }
}&lt;/code&gt;
    &lt;p&gt;In TypeScript, the &lt;code&gt;this&lt;/code&gt; keyword refers to the current instance of a class within its methods or constructors. It allows you to access and modify the properties and methods of the class from within its own scope.
It provides a way to access and manipulate the internal state of an object within its own methods.&lt;/p&gt;
    &lt;code&gt;class Person {
    private name: string;
    constructor(name: string) {
        this.name = name;
    }
    public introduce(): void {
        console.log(`Hello, my name is ${this.name}.`);
    }
}

const person1 = new Person('Alice');
person1.introduce(); // Hello, my name is Alice.&lt;/code&gt;
    &lt;p&gt;Parameter properties allow you to declare and initialize class properties directly within the constructor parameters avoiding boilerplate code, example:&lt;/p&gt;
    &lt;code&gt;class Person {
    constructor(
        private name: string,
        public age: number
    ) {
        // The "private" and "public" keywords in the constructor
        // automatically declare and initialize the corresponding class properties.
    }
    public introduce(): void {
        console.log(
            `Hello, my name is ${this.name} and I am ${this.age} years old.`
        );
    }
}
const person = new Person('Alice', 25);
person.introduce();&lt;/code&gt;
    &lt;p&gt;Abstract Classes are used in TypeScript mainly for inheritance, they provide a way to define common properties and methods that can be inherited by subclasses. This is useful when you want to define common behavior and enforce that subclasses implement certain methods. They provide a way to create a hierarchy of classes where the abstract base class provides a shared interface and common functionality for the subclasses.&lt;/p&gt;
    &lt;code&gt;abstract class Animal {
    protected name: string;

    constructor(name: string) {
        this.name = name;
    }

    abstract makeSound(): void;
}

class Cat extends Animal {
    makeSound(): void {
        console.log(`${this.name} meows.`);
    }
}

const cat = new Cat('Whiskers');
cat.makeSound(); // Output: Whiskers meows.&lt;/code&gt;
    &lt;p&gt;Classes with generics allow you to define reusable classes which can work with different types.&lt;/p&gt;
    &lt;code&gt;class Container&amp;lt;T&amp;gt; {
    private item: T;

    constructor(item: T) {
        this.item = item;
    }

    getItem(): T {
        return this.item;
    }

    setItem(item: T): void {
        this.item = item;
    }
}

const container1 = new Container&amp;lt;number&amp;gt;(42);
console.log(container1.getItem()); //  42

const container2 = new Container&amp;lt;string&amp;gt;('Hello');
container2.setItem('World');
console.log(container2.getItem()); // World&lt;/code&gt;
    &lt;p&gt;Decorators provide a mechanism to add metadata, modify behavior, validate, or extend the functionality of the target element. They are functions that execute at runtime. Multiple decorators can be applied to a declaration.&lt;/p&gt;
    &lt;p&gt;Decorators are experimental features, and the following examples are only compatible with TypeScript version 5 or above using ES6.&lt;/p&gt;
    &lt;p&gt;For TypeScript versions prior to 5, they should be enabled using the &lt;code&gt;experimentalDecorators&lt;/code&gt; property in your &lt;code&gt;tsconfig.json&lt;/code&gt; or by using &lt;code&gt;--experimentalDecorators&lt;/code&gt; in your command line (but the following example won't work).&lt;/p&gt;
    &lt;p&gt;Some of the common use cases for decorators include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Watching property changes.&lt;/item&gt;
      &lt;item&gt;Watching method calls.&lt;/item&gt;
      &lt;item&gt;Adding extra properties or methods.&lt;/item&gt;
      &lt;item&gt;Runtime validation.&lt;/item&gt;
      &lt;item&gt;Automatic serialization and deserialization.&lt;/item&gt;
      &lt;item&gt;Logging.&lt;/item&gt;
      &lt;item&gt;Authorization and authentication.&lt;/item&gt;
      &lt;item&gt;Error guarding.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Decorators for version 5 do not allow decorating parameters.&lt;/p&gt;
    &lt;p&gt;Types of decorators:&lt;/p&gt;
    &lt;p&gt;Class Decorators are useful for extending an existing class, such as adding properties or methods, or collecting instances of a class. In the following example, we add a &lt;code&gt;toString&lt;/code&gt; method that converts the class into a string representation.&lt;/p&gt;
    &lt;code&gt;type Constructor&amp;lt;T = {}&amp;gt; = new (...args: any[]) =&amp;gt; T;

function toString&amp;lt;Class extends Constructor&amp;gt;(
    Value: Class,
    context: ClassDecoratorContext&amp;lt;Class&amp;gt;
) {
    return class extends Value {
        constructor(...args: any[]) {
            super(...args);
            console.log(JSON.stringify(this));
            console.log(JSON.stringify(context));
        }
    };
}

@toString
class Person {
    name: string;

    constructor(name: string) {
        this.name = name;
    }

    greet() {
        return 'Hello, ' + this.name;
    }
}
const person = new Person('Simon');
/* Logs:
{"name":"Simon"}
{"kind":"class","name":"Person"}
*/&lt;/code&gt;
    &lt;p&gt;Property decorators are useful for modifying the behavior of a property, such as changing the initialization values. In the following code, we have a script that sets a property to always be in uppercase:&lt;/p&gt;
    &lt;code&gt;function upperCase&amp;lt;T&amp;gt;(
    target: undefined,
    context: ClassFieldDecoratorContext&amp;lt;T, string&amp;gt;
) {
    return function (this: T, value: string) {
        return value.toUpperCase();
    };
}

class MyClass {
    @upperCase
    prop1 = 'hello!';
}

console.log(new MyClass().prop1); // Logs: HELLO!&lt;/code&gt;
    &lt;p&gt;Method decorators allow you to change or enhance the behavior of methods. Below is an example of a simple logger:&lt;/p&gt;
    &lt;code&gt;function log&amp;lt;This, Args extends any[], Return&amp;gt;(
    target: (this: This, ...args: Args) =&amp;gt; Return,
    context: ClassMethodDecoratorContext&amp;lt;
        This,
        (this: This, ...args: Args) =&amp;gt; Return
    &amp;gt;
) {
    const methodName = String(context.name);

    function replacementMethod(this: This, ...args: Args): Return {
        console.log(`LOG: Entering method '${methodName}'.`);
        const result = target.call(this, ...args);
        console.log(`LOG: Exiting method '${methodName}'.`);
        return result;
    }

    return replacementMethod;
}

class MyClass {
    @log
    sayHello() {
        console.log('Hello!');
    }
}

new MyClass().sayHello();&lt;/code&gt;
    &lt;p&gt;It logs:&lt;/p&gt;
    &lt;code&gt;LOG: Entering method 'sayHello'.
Hello!
LOG: Exiting method 'sayHello'.&lt;/code&gt;
    &lt;p&gt;Getter and setter decorators allow you to change or enhance the behavior of class accessors. They are useful, for instance, for validating property assignments. Here's a simple example for a getter decorator:&lt;/p&gt;
    &lt;code&gt;function range&amp;lt;This, Return extends number&amp;gt;(min: number, max: number) {
    return function (
        target: (this: This) =&amp;gt; Return,
        context: ClassGetterDecoratorContext&amp;lt;This, Return&amp;gt;
    ) {
        return function (this: This): Return {
            const value = target.call(this);
            if (value &amp;lt; min || value &amp;gt; max) {
                throw 'Invalid';
            }
            Object.defineProperty(this, context.name, {
                value,
                enumerable: true,
            });
            return value;
        };
    };
}

class MyClass {
    private _value = 0;

    constructor(value: number) {
        this._value = value;
    }
    @range(1, 100)
    get getValue(): number {
        return this._value;
    }
}

const obj = new MyClass(10);
console.log(obj.getValue); // Valid: 10

const obj2 = new MyClass(999);
console.log(obj2.getValue); // Throw: Invalid!&lt;/code&gt;
    &lt;p&gt;Decorator Metadata simplifies the process for decorators to apply and utilize metadata in any class. They can access a new metadata property on the context object, which can serve as a key for both primitives and objects. Metadata information can be accessed on the class via &lt;code&gt;Symbol.metadata&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Metadata can be used for various purposes, such as debugging, serialization, or dependency injection with decorators.&lt;/p&gt;
    &lt;code&gt;//@ts-ignore
Symbol.metadata ??= Symbol('Symbol.metadata'); // Simple polify

type Context =
    | ClassFieldDecoratorContext
    | ClassAccessorDecoratorContext
    | ClassMethodDecoratorContext; // Context contains property metadata: DecoratorMetadata

function setMetadata(_target: any, context: Context) {
    // Set the metadata object with a primitive value
    context.metadata[context.name] = true;
}

class MyClass {
    @setMetadata
    a = 123;

    @setMetadata
    accessor b = 'b';

    @setMetadata
    fn() {}
}

const metadata = MyClass[Symbol.metadata]; // Get metadata information

console.log(JSON.stringify(metadata)); // {"bar":true,"baz":true,"foo":true}&lt;/code&gt;
    &lt;p&gt;Inheritance refers to the mechanism by which a class can inherit properties and methods from another class, known as the base class or superclass. The derived class, also called the child class or subclass, can extend and specialize the functionality of the base class by adding new properties and methods or overriding existing ones.&lt;/p&gt;
    &lt;code&gt;class Animal {
    name: string;

    constructor(name: string) {
        this.name = name;
    }

    speak(): void {
        console.log('The animal makes a sound');
    }
}

class Dog extends Animal {
    breed: string;

    constructor(name: string, breed: string) {
        super(name);
        this.breed = breed;
    }

    speak(): void {
        console.log('Woof! Woof!');
    }
}

// Create an instance of the base class
const animal = new Animal('Generic Animal');
animal.speak(); // The animal makes a sound

// Create an instance of the derived class
const dog = new Dog('Max', 'Labrador');
dog.speak(); // Woof! Woof!"&lt;/code&gt;
    &lt;p&gt;TypeScript does not support multiple inheritance in the traditional sense and instead allows inheritance from a single base class. TypeScript supports multiple interfaces. An interface can define a contract for the structure of an object, and a class can implement multiple interfaces. This allows a class to inherit behavior and structure from multiple sources.&lt;/p&gt;
    &lt;code&gt;interface Flyable {
    fly(): void;
}

interface Swimmable {
    swim(): void;
}

class FlyingFish implements Flyable, Swimmable {
    fly() {
        console.log('Flying...');
    }

    swim() {
        console.log('Swimming...');
    }
}

const flyingFish = new FlyingFish();
flyingFish.fly();
flyingFish.swim();&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;class&lt;/code&gt; keyword in TypeScript, similar to JavaScript, is often referred to as syntactic sugar. It was introduced in ECMAScript 2015 (ES6) to offer a more familiar syntax for creating and working with objects in a class-based manner. However, it's important to note that TypeScript, being a superset of JavaScript, ultimately compiles down to JavaScript, which remains prototype-based at its core.&lt;/p&gt;
    &lt;p&gt;TypeScript has static members. To access the static members of a class, you can use the class name followed by a dot, without the need to create an object.&lt;/p&gt;
    &lt;code&gt;class OfficeWorker {
    static memberCount: number = 0;

    constructor(private name: string) {
        OfficeWorker.memberCount++;
    }
}

const w1 = new OfficeWorker('James');
const w2 = new OfficeWorker('Simon');
const total = OfficeWorker.memberCount;
console.log(total); // 2&lt;/code&gt;
    &lt;p&gt;There are several ways how you can initialize properties for a class in TypeScript:&lt;/p&gt;
    &lt;p&gt;Inline:&lt;/p&gt;
    &lt;p&gt;In the following example these initial values will be used when an instance of the class is created.&lt;/p&gt;
    &lt;code&gt;class MyClass {
    property1: string = 'default value';
    property2: number = 42;
}&lt;/code&gt;
    &lt;p&gt;In the constructor:&lt;/p&gt;
    &lt;code&gt;class MyClass {
    property1: string;
    property2: number;

    constructor() {
        this.property1 = 'default value';
        this.property2 = 42;
    }
}&lt;/code&gt;
    &lt;p&gt;Using constructor parameters:&lt;/p&gt;
    &lt;code&gt;class MyClass {
    constructor(
        private property1: string = 'default value',
        public property2: number = 42
    ) {
        // There is no need to assign the values to the properties explicitly.
    }
    log() {
        console.log(this.property2);
    }
}
const x = new MyClass();
x.log();&lt;/code&gt;
    &lt;p&gt;Method overloading allows a class to have multiple methods with the same name but different parameter types or a different number of parameters. This allows us to call a method in different ways based on the arguments passed.&lt;/p&gt;
    &lt;code&gt;class MyClass {
    add(a: number, b: number): number; // Overload signature 1
    add(a: string, b: string): string; // Overload signature 2

    add(a: number | string, b: number | string): number | string {
        if (typeof a === 'number' &amp;amp;&amp;amp; typeof b === 'number') {
            return a + b;
        }
        if (typeof a === 'string' &amp;amp;&amp;amp; typeof b === 'string') {
            return a.concat(b);
        }
        throw new Error('Invalid arguments');
    }
}

const r = new MyClass();
console.log(r.add(10, 5)); // Logs 15&lt;/code&gt;
    &lt;p&gt;Generics allow you to create reusable components and functions that can work with multiple types. With generics, you can parameterize types, functions, and interfaces, allowing them to operate on different types without explicitly specifying them beforehand.&lt;/p&gt;
    &lt;p&gt;Generics allow you to make code more flexible and reusable.&lt;/p&gt;
    &lt;p&gt;To define a generic type, you use angle brackets (&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) to specify the type parameters, for instance:&lt;/p&gt;
    &lt;code&gt;function identity&amp;lt;T&amp;gt;(arg: T): T {
    return arg;
}
const a = identity('x');
const b = identity(123);

const getLen = &amp;lt;T,&amp;gt;(data: ReadonlyArray&amp;lt;T&amp;gt;) =&amp;gt; data.length;
const len = getLen([1, 2, 3]);&lt;/code&gt;
    &lt;p&gt;Generics can be applied also to classes, in this way they can work with multiple types by using type parameters. This is useful to create reusable class definitions that can operate on different data types while maintaining type safety.&lt;/p&gt;
    &lt;code&gt;class Container&amp;lt;T&amp;gt; {
    private item: T;

    constructor(item: T) {
        this.item = item;
    }

    getItem(): T {
        return this.item;
    }
}

const numberContainer = new Container&amp;lt;number&amp;gt;(123);
console.log(numberContainer.getItem()); // 123

const stringContainer = new Container&amp;lt;string&amp;gt;('hello');
console.log(stringContainer.getItem()); // hello&lt;/code&gt;
    &lt;p&gt;Generic parameters can be constrained using the &lt;code&gt;extends&lt;/code&gt; keyword followed by a type or interface that the type parameter must satisfy.&lt;/p&gt;
    &lt;p&gt;In the following example T it is must containing a properly &lt;code&gt;length&lt;/code&gt; in order to be valid:&lt;/p&gt;
    &lt;code&gt;const printLen = &amp;lt;T extends { length: number }&amp;gt;(value: T): void =&amp;gt; {
    console.log(value.length);
};

printLen('Hello'); // 5
printLen([1, 2, 3]); // 3
printLen({ length: 10 }); // 10
printLen(123); // Invalid&lt;/code&gt;
    &lt;p&gt;An interesting feature of generic introduced in version 3.4 RC is Higher order function type inference which introduced propagated generic type arguments:&lt;/p&gt;
    &lt;code&gt;declare function pipe&amp;lt;A extends any[], B, C&amp;gt;(
    ab: (...args: A) =&amp;gt; B,
    bc: (b: B) =&amp;gt; C
): (...args: A) =&amp;gt; C;

declare function list&amp;lt;T&amp;gt;(a: T): T[];
declare function box&amp;lt;V&amp;gt;(x: V): { value: V };

const listBox = pipe(list, box); // &amp;lt;T&amp;gt;(a: T) =&amp;gt; { value: T[] }
const boxList = pipe(box, list); // &amp;lt;V&amp;gt;(x: V) =&amp;gt; { value: V }[]&lt;/code&gt;
    &lt;p&gt;This functionality allows more easily typed safe pointfree style programming which is common in functional programming.&lt;/p&gt;
    &lt;p&gt;Contextual narrowing for generics is the mechanism in TypeScript that allows the compiler to narrow down the type of a generic parameter based on the context in which it is used, it is useful when working with generic types in conditional statements:&lt;/p&gt;
    &lt;code&gt;function process&amp;lt;T&amp;gt;(value: T): void {
    if (typeof value === 'string') {
        // Value is narrowed down to type 'string'
        console.log(value.length);
    } else if (typeof value === 'number') {
        // Value is narrowed down to type 'number'
        console.log(value.toFixed(2));
    }
}

process('hello'); // 5
process(3.14159); // 3.14&lt;/code&gt;
    &lt;p&gt;In TypeScript, objects do not have to match a specific, exact type. For instance, if we create an object that fulfills an interface's requirements, we can utilize that object in places where that interface is required, even if there was no explicit connection between them. Example:&lt;/p&gt;
    &lt;code&gt;type NameProp1 = {
    prop1: string;
};

function log(x: NameProp1) {
    console.log(x.prop1);
}

const obj = {
    prop2: 123,
    prop1: 'Origin',
};

log(obj); // Valid&lt;/code&gt;
    &lt;p&gt;In TypeScript, namespaces are used to organize code into logical containers, preventing naming collisions and providing a way to group related code together. The usage of the &lt;code&gt;export&lt;/code&gt; keywords allows access to the namespace in "outside" modules.&lt;/p&gt;
    &lt;code&gt;export namespace MyNamespace {
    export interface MyInterface1 {
        prop1: boolean;
    }
    export interface MyInterface2 {
        prop2: string;
    }
}

const a: MyNamespace.MyInterface1 = {
    prop1: true,
};&lt;/code&gt;
    &lt;p&gt;Symbols are a primitive data type that represents an immutable value which is guaranteed to be globally unique throughout the lifetime of the program.&lt;/p&gt;
    &lt;p&gt;Symbols can be used as keys for object properties and provide a way to create non-enumerable properties.&lt;/p&gt;
    &lt;code&gt;const key1: symbol = Symbol('key1');
const key2: symbol = Symbol('key2');

const obj = {
    [key1]: 'value 1',
    [key2]: 'value 2',
};

console.log(obj[key1]); // value 1
console.log(obj[key2]); // value 2&lt;/code&gt;
    &lt;p&gt;In WeakMaps and WeakSets, symbols are now permissible as keys.&lt;/p&gt;
    &lt;p&gt;Triple-slash directives are special comments that provide instructions to the compiler about how to process a file. These directives begin with three consecutive slashes (&lt;code&gt;///&lt;/code&gt;) and are typically placed at the top of a TypeScript file and have no effects on the runtime behavior.&lt;/p&gt;
    &lt;p&gt;Triple-slash directives are used to reference external dependencies, specify module loading behavior, enable/disable certain compiler features, and more. Few examples:&lt;/p&gt;
    &lt;p&gt;Referencing a declaration file:&lt;/p&gt;
    &lt;code&gt;/// &amp;lt;reference path="path/to/declaration/file.d.ts" /&amp;gt;&lt;/code&gt;
    &lt;p&gt;Indicate the module format:&lt;/p&gt;
    &lt;code&gt;/// &amp;lt;amd|commonjs|system|umd|es6|es2015|none&amp;gt;&lt;/code&gt;
    &lt;p&gt;Enable compiler options, in the following example strict mode:&lt;/p&gt;
    &lt;code&gt;/// &amp;lt;strict|noImplicitAny|noUnusedLocals|noUnusedParameters&amp;gt;&lt;/code&gt;
    &lt;p&gt;Is it possible to create new types composing, manipulating or transforming existing types.&lt;/p&gt;
    &lt;p&gt;Intersection Types (&lt;code&gt;&amp;amp;&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Allow you to combine multiple types into a single type:&lt;/p&gt;
    &lt;code&gt;type A = { foo: number };
type B = { bar: string };
type C = A &amp;amp; B; // Intersection of A and B
const obj: C = { foo: 42, bar: 'hello' };&lt;/code&gt;
    &lt;p&gt;Union Types (&lt;code&gt;|&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Allow you to define a type that can be one of several types:&lt;/p&gt;
    &lt;code&gt;type Result = string | number;
const value1: Result = 'hello';
const value2: Result = 42;&lt;/code&gt;
    &lt;p&gt;Mapped Types:&lt;/p&gt;
    &lt;p&gt;Allow you to transform the properties of an existing type to create new type:&lt;/p&gt;
    &lt;code&gt;type Mutable&amp;lt;T&amp;gt; = {
    readonly [P in keyof T]: T[P];
};
type Person = {
    name: string;
    age: number;
};
type ImmutablePerson = Mutable&amp;lt;Person&amp;gt;; // Properties become read-only&lt;/code&gt;
    &lt;p&gt;Conditional types:&lt;/p&gt;
    &lt;p&gt;Allow you to create types based on some conditions:&lt;/p&gt;
    &lt;code&gt;type ExtractParam&amp;lt;T&amp;gt; = T extends (param: infer P) =&amp;gt; any ? P : never;
type MyFunction = (name: string) =&amp;gt; number;
type ParamType = ExtractParam&amp;lt;MyFunction&amp;gt;; // string&lt;/code&gt;
    &lt;p&gt;In TypeScript is it possible to access and manipulate the types of properties within another type using an index, &lt;code&gt;Type[Key]&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name: string;
    age: number;
};

type AgeType = Person['age']; // number&lt;/code&gt;
    &lt;code&gt;type MyTuple = [string, number, boolean];
type MyType = MyTuple[2]; // boolean&lt;/code&gt;
    &lt;p&gt;Several built-in utility types can be used to manipulate types, below a list of the most common used:&lt;/p&gt;
    &lt;p&gt;Constructs a type that recursively unwraps Promise types.&lt;/p&gt;
    &lt;code&gt;type A = Awaited&amp;lt;Promise&amp;lt;string&amp;gt;&amp;gt;; // string&lt;/code&gt;
    &lt;p&gt;Constructs a type with all properties of T set to optional.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name: string;
    age: number;
};

type A = Partial&amp;lt;Person&amp;gt;; // { name?: string | undefined; age?: number | undefined; }&lt;/code&gt;
    &lt;p&gt;Constructs a type with all properties of T set to required.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name?: string;
    age?: number;
};

type A = Required&amp;lt;Person&amp;gt;; // { name: string; age: number; }&lt;/code&gt;
    &lt;p&gt;Constructs a type with all properties of T set to readonly.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name: string;
    age: number;
};

type A = Readonly&amp;lt;Person&amp;gt;;

const a: A = { name: 'Simon', age: 17 };
a.name = 'John'; // Invalid&lt;/code&gt;
    &lt;p&gt;Constructs a type with a set of properties K of type T.&lt;/p&gt;
    &lt;code&gt;type Product = {
    name: string;
    price: number;
};

const products: Record&amp;lt;string, Product&amp;gt; = {
    apple: { name: 'Apple', price: 0.5 },
    banana: { name: 'Banana', price: 0.25 },
};

console.log(products.apple); // { name: 'Apple', price: 0.5 }&lt;/code&gt;
    &lt;p&gt;Constructs a type by picking the specified properties K from T.&lt;/p&gt;
    &lt;code&gt;type Product = {
    name: string;
    price: number;
};

type Price = Pick&amp;lt;Product, 'price'&amp;gt;; // { price: number; }&lt;/code&gt;
    &lt;p&gt;Constructs a type by omitting the specified properties K from T.&lt;/p&gt;
    &lt;code&gt;type Product = {
    name: string;
    price: number;
};

type Name = Omit&amp;lt;Product, 'price'&amp;gt;; // { name: string; }&lt;/code&gt;
    &lt;p&gt;Constructs a type by excluding all values of type U from T.&lt;/p&gt;
    &lt;code&gt;type Union = 'a' | 'b' | 'c';
type MyType = Exclude&amp;lt;Union, 'a' | 'c'&amp;gt;; // b&lt;/code&gt;
    &lt;p&gt;Constructs a type by extracting all values of type U from T.&lt;/p&gt;
    &lt;code&gt;type Union = 'a' | 'b' | 'c';
type MyType = Extract&amp;lt;Union, 'a' | 'c'&amp;gt;; // a | c&lt;/code&gt;
    &lt;p&gt;Constructs a type by excluding null and undefined from T.&lt;/p&gt;
    &lt;code&gt;type Union = 'a' | null | undefined | 'b';
type MyType = NonNullable&amp;lt;Union&amp;gt;; // 'a' | 'b'&lt;/code&gt;
    &lt;p&gt;Extracts the parameter types of a function type T.&lt;/p&gt;
    &lt;code&gt;type Func = (a: string, b: number) =&amp;gt; void;
type MyType = Parameters&amp;lt;Func&amp;gt;; // [a: string, b: number]&lt;/code&gt;
    &lt;p&gt;Extracts the parameter types of a constructor function type T.&lt;/p&gt;
    &lt;code&gt;class Person {
    constructor(
        public name: string,
        public age: number
    ) {}
}
type PersonConstructorParams = ConstructorParameters&amp;lt;typeof Person&amp;gt;; // [name: string, age: number]
const params: PersonConstructorParams = ['John', 30];
const person = new Person(...params);
console.log(person); // Person { name: 'John', age: 30 }&lt;/code&gt;
    &lt;p&gt;Extracts the return type of a function type T.&lt;/p&gt;
    &lt;code&gt;type Func = (name: string) =&amp;gt; number;
type MyType = ReturnType&amp;lt;Func&amp;gt;; // number&lt;/code&gt;
    &lt;p&gt;Extracts the instance type of a class type T.&lt;/p&gt;
    &lt;code&gt;class Person {
    name: string;

    constructor(name: string) {
        this.name = name;
    }

    sayHello() {
        console.log(`Hello, my name is ${this.name}!`);
    }
}

type PersonInstance = InstanceType&amp;lt;typeof Person&amp;gt;;

const person: PersonInstance = new Person('John');

person.sayHello(); // Hello, my name is John!&lt;/code&gt;
    &lt;p&gt;Extracts the type of 'this' parameter from a function type T.&lt;/p&gt;
    &lt;code&gt;interface Person {
    name: string;
    greet(this: Person): void;
}
type PersonThisType = ThisParameterType&amp;lt;Person['greet']&amp;gt;; // Person&lt;/code&gt;
    &lt;p&gt;Removes the 'this' parameter from a function type T.&lt;/p&gt;
    &lt;code&gt;function capitalize(this: String) {
    return this[0].toUpperCase + this.substring(1).toLowerCase();
}

type CapitalizeType = OmitThisParameter&amp;lt;typeof capitalize&amp;gt;; // () =&amp;gt; string&lt;/code&gt;
    &lt;p&gt;Servers as a market for a contextual &lt;code&gt;this&lt;/code&gt; type.&lt;/p&gt;
    &lt;code&gt;type Logger = {
    log: (error: string) =&amp;gt; void;
};

let helperFunctions: { [name: string]: Function } &amp;amp; ThisType&amp;lt;Logger&amp;gt; = {
    hello: function () {
        this.log('some error'); // Valid as "log" is a part of "this".
        this.update(); // Invalid
    },
};&lt;/code&gt;
    &lt;p&gt;Make uppercase the name of the input type T.&lt;/p&gt;
    &lt;code&gt;type MyType = Uppercase&amp;lt;'abc'&amp;gt;; // "ABC"&lt;/code&gt;
    &lt;p&gt;Make lowercase the name of the input type T.&lt;/p&gt;
    &lt;code&gt;type MyType = Lowercase&amp;lt;'ABC'&amp;gt;; // "abc"&lt;/code&gt;
    &lt;p&gt;Capitalize the name of the input type T.&lt;/p&gt;
    &lt;code&gt;type MyType = Capitalize&amp;lt;'abc'&amp;gt;; // "Abc"&lt;/code&gt;
    &lt;p&gt;Uncapitalize the name of the input type T.&lt;/p&gt;
    &lt;code&gt;type MyType = Uncapitalize&amp;lt;'Abc'&amp;gt;; // "abc"&lt;/code&gt;
    &lt;p&gt;NoInfer is a utility type designed to block the automatic inference of types within the scope of a generic function.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;// Automatic inference of types within the scope of a generic function.
function fn&amp;lt;T extends string&amp;gt;(x: T[], y: T) {
    return x.concat(y);
}
const r = fn(['a', 'b'], 'c'); // Type here is ("a" | "b" | "c")[]&lt;/code&gt;
    &lt;p&gt;With NoInfer:&lt;/p&gt;
    &lt;code&gt;// Example function that uses NoInfer to prevent type inference
function fn2&amp;lt;T extends string&amp;gt;(x: T[], y: NoInfer&amp;lt;T&amp;gt;) {
    return x.concat(y);
}

const r2 = fn2(['a', 'b'], 'c'); // Error: Type Argument of type '"c"' is not assignable to parameter of type '"a" | "b"'.&lt;/code&gt;
    &lt;p&gt;TypeScript allows you to catch and handle errors using standard JavaScript error handling mechanisms:&lt;/p&gt;
    &lt;p&gt;Try-Catch-Finally Blocks:&lt;/p&gt;
    &lt;code&gt;try {
    // Code that might throw an error
} catch (error) {
    // Handle the error
} finally {
    // Code that always executes, finally is optional
}&lt;/code&gt;
    &lt;p&gt;You can also handle different types of error:&lt;/p&gt;
    &lt;code&gt;try {
    // Code that might throw different types of errors
} catch (error) {
    if (error instanceof TypeError) {
        // Handle TypeError
    } else if (error instanceof RangeError) {
        // Handle RangeError
    } else {
        // Handle other errors
    }
}&lt;/code&gt;
    &lt;p&gt;Custom Error Types:&lt;/p&gt;
    &lt;p&gt;It is possible to specify more specific error by extending on the Error &lt;code&gt;class&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;class CustomError extends Error {
    constructor(message: string) {
        super(message);
        this.name = 'CustomError';
    }
}

throw new CustomError('This is a custom error.');&lt;/code&gt;
    &lt;p&gt;Mixin classes allow you to combine and compose behavior from multiple classes into a single class. They provide a way to reuse and extend functionality without the need for deep inheritance chains.&lt;/p&gt;
    &lt;code&gt;abstract class Identifiable {
    name: string = '';
    logId() {
        console.log('id:', this.name);
    }
}
abstract class Selectable {
    selected: boolean = false;
    select() {
        this.selected = true;
        console.log('Select');
    }
    deselect() {
        this.selected = false;
        console.log('Deselect');
    }
}
class MyClass {
    constructor() {}
}

// Extend MyClass to include the behavior of Identifiable and Selectable
interface MyClass extends Identifiable, Selectable {}

// Function to apply mixins to a class
function applyMixins(source: any, baseCtors: any[]) {
    baseCtors.forEach(baseCtor =&amp;gt; {
        Object.getOwnPropertyNames(baseCtor.prototype).forEach(name =&amp;gt; {
            let descriptor = Object.getOwnPropertyDescriptor(
                baseCtor.prototype,
                name
            );
            if (descriptor) {
                Object.defineProperty(source.prototype, name, descriptor);
            }
        });
    });
}

// Apply the mixins to MyClass
applyMixins(MyClass, [Identifiable, Selectable]);
let o = new MyClass();
o.name = 'abc';
o.logId();
o.select();&lt;/code&gt;
    &lt;p&gt;As TypeScript is a superset of JavaScript, it has built-in asynchronous language features of JavaScript as:&lt;/p&gt;
    &lt;p&gt;Promises:&lt;/p&gt;
    &lt;p&gt;Promises are a way to handle asynchronous operations and their results using methods like &lt;code&gt;.then()&lt;/code&gt; and &lt;code&gt;.catch()&lt;/code&gt; to handle success and error conditions.&lt;/p&gt;
    &lt;p&gt;To learn more: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise&lt;/p&gt;
    &lt;p&gt;Async/await:&lt;/p&gt;
    &lt;p&gt;Async/await keywords are a way to provide a more synchronous-looking syntax for working with Promises. The &lt;code&gt;async&lt;/code&gt; keyword is used to define an asynchronous function, and the &lt;code&gt;await&lt;/code&gt; keyword is used within an async function to pause execution until a Promise is resolved or rejected.&lt;/p&gt;
    &lt;p&gt;To learn more: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await&lt;/p&gt;
    &lt;p&gt;The following API are well supported in TypeScript:&lt;/p&gt;
    &lt;p&gt;Fetch API: https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API&lt;/p&gt;
    &lt;p&gt;Web Workers: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API&lt;/p&gt;
    &lt;p&gt;Shared Workers: https://developer.mozilla.org/en-US/docs/Web/API/SharedWorker&lt;/p&gt;
    &lt;p&gt;WebSocket: https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API&lt;/p&gt;
    &lt;p&gt;Both Iterators and Generators are well supported in TypeScript.&lt;/p&gt;
    &lt;p&gt;Iterators are objects that implement the iterator protocol, providing a way to access elements of a collection or sequence one by one. It is a structure that contains a pointer to the next element in the iteration. They have a &lt;code&gt;next()&lt;/code&gt; method that returns the next value in the sequence along with a boolean indicating if the sequence is &lt;code&gt;done&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;class NumberIterator implements Iterable&amp;lt;number&amp;gt; {
    private current: number;

    constructor(
        private start: number,
        private end: number
    ) {
        this.current = start;
    }

    public next(): IteratorResult&amp;lt;number&amp;gt; {
        if (this.current &amp;lt;= this.end) {
            const value = this.current;
            this.current++;
            return { value, done: false };
        } else {
            return { value: undefined, done: true };
        }
    }

    [Symbol.iterator](): Iterator&amp;lt;number&amp;gt; {
        return this;
    }
}

const iterator = new NumberIterator(1, 3);

for (const num of iterator) {
    console.log(num);
}&lt;/code&gt;
    &lt;p&gt;Generators are special functions defined using the &lt;code&gt;function*&lt;/code&gt; syntax that simplifies the creation of iterators. They use the &lt;code&gt;yield&lt;/code&gt; keyword to define the sequence of values and automatically pause and resume execution when values are requested.&lt;/p&gt;
    &lt;p&gt;Generators make it easier to create iterators and are especially useful for working with large or infinite sequences.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;function* numberGenerator(start: number, end: number): Generator&amp;lt;number&amp;gt; {
    for (let i = start; i &amp;lt;= end; i++) {
        yield i;
    }
}

const generator = numberGenerator(1, 5);

for (const num of generator) {
    console.log(num);
}&lt;/code&gt;
    &lt;p&gt;TypeScript also supports async iterators and async Generators.&lt;/p&gt;
    &lt;p&gt;To learn more:&lt;/p&gt;
    &lt;p&gt;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator&lt;/p&gt;
    &lt;p&gt;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator&lt;/p&gt;
    &lt;p&gt;When working with a JavaScript code base, it is possible to help TypeScript to infer the right Type by using JSDoc comments with additional annotation to provide type information.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;/**
 * Computes the power of a given number
 * @constructor
 * @param {number} base â€“ The base value of the expression
 * @param {number} exponent â€“ The exponent value of the expression
 */
function power(base: number, exponent: number) {
    return Math.pow(base, exponent);
}
power(10, 2); // function power(base: number, exponent: number): number&lt;/code&gt;
    &lt;p&gt;Full documentation is provided to this link: https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html&lt;/p&gt;
    &lt;p&gt;From version 3.7 it is possible to generate .d.ts type definitions from JavaScript JSDoc syntax. More information can be found here: https://www.typescriptlang.org/docs/handbook/declaration-files/dts-from-js.html&lt;/p&gt;
    &lt;p&gt;Packages under the @types organization are special package naming conventions used to provide type definitions for existing JavaScript libraries or modules. For instance using:&lt;/p&gt;
    &lt;code&gt;npm install --save-dev @types/lodash&lt;/code&gt;
    &lt;p&gt;Will install the type definitions of &lt;code&gt;lodash&lt;/code&gt; in your current project.&lt;/p&gt;
    &lt;p&gt;To contribute to the type definitions of @types package, please submit a pull request to https://github.com/DefinitelyTyped/DefinitelyTyped.&lt;/p&gt;
    &lt;p&gt;JSX (JavaScript XML) is an extension to the JavaScript language syntax that allows you to write HTML-like code within your JavaScript or TypeScript files. It is commonly used in React to define the HTML structure.&lt;/p&gt;
    &lt;p&gt;TypeScript extends the capabilities of JSX by providing type checking and static analysis.&lt;/p&gt;
    &lt;p&gt;To use JSX you need to set the &lt;code&gt;jsx&lt;/code&gt; compiler option in your &lt;code&gt;tsconfig.json&lt;/code&gt; file. Two common configuration options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"preserve": emit .jsx files with the JSX unchanged. This option tells TypeScript to keep the JSX syntax as-is and not transform it during the compilation process. You can use this option if you have a separate tool, like Babel, that handles the transformation.&lt;/item&gt;
      &lt;item&gt;"react": enables TypeScript's built-in JSX transformation. React.createElement will be used.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All options are available here: https://www.typescriptlang.org/tsconfig#jsx&lt;/p&gt;
    &lt;p&gt;TypeScript does support ES6 (ECMAScript 2015) and many subsequent versions. This means you can use ES6 syntax, such as arrow functions, template literals, classes, modules, destructuring, and more.&lt;/p&gt;
    &lt;p&gt;To enable ES6 features in your project, you can specify the &lt;code&gt;target&lt;/code&gt; property in the tsconfig.json.&lt;/p&gt;
    &lt;p&gt;A configuration example:&lt;/p&gt;
    &lt;code&gt;{
  "compilerOptions": {
    "target": "es6",
    "module": "es6",
    "moduleResolution": "node",
    "sourceMap": true,
    "outDir": "dist"
  },
  "include": ["src"]
}&lt;/code&gt;
    &lt;p&gt;The exponentiation (&lt;code&gt;**&lt;/code&gt;) operator computes the value obtained by raising the first operand to the power of the second operand. It functions similarly to &lt;code&gt;Math.pow()&lt;/code&gt;, but with the added capability of accepting BigInts as operands.
TypeScript fully supports this operator using as &lt;code&gt;target&lt;/code&gt; in your tsconfig.json file &lt;code&gt;es2016&lt;/code&gt; or larger version.&lt;/p&gt;
    &lt;code&gt;console.log(2 ** (2 ** 2)); // 16&lt;/code&gt;
    &lt;p&gt;This is a JavaScript feature fully supported in TypeScript which allows you to iterate over asynchronous iterable objects from target version es2018.&lt;/p&gt;
    &lt;code&gt;async function* asyncNumbers(): AsyncIterableIterator&amp;lt;number&amp;gt; {
    yield Promise.resolve(1);
    yield Promise.resolve(2);
    yield Promise.resolve(3);
}

(async () =&amp;gt; {
    for await (const num of asyncNumbers()) {
        console.log(num);
    }
})();&lt;/code&gt;
    &lt;p&gt;You can use in TypeScript the &lt;code&gt;new.target&lt;/code&gt; meta-property which enables you to determine if a function or constructor was invoked using the new operator. It allows you to detect whether an object was created as a result of a constructor call.&lt;/p&gt;
    &lt;code&gt;class Parent {
    constructor() {
        console.log(new.target); // Logs the constructor function used to create an instance
    }
}

class Child extends Parent {
    constructor() {
        super();
    }
}

const parentX = new Parent(); // [Function: Parent]
const child = new Child(); // [Function: Child]&lt;/code&gt;
    &lt;p&gt;It is possible to conditionally load modules or lazy load them on-demand using the ECMAScript proposal for dynamic import which is supported in TypeScript.&lt;/p&gt;
    &lt;p&gt;The syntax for dynamic import expressions in TypeScript is as follows:&lt;/p&gt;
    &lt;code&gt;async function renderWidget() {
    const container = document.getElementById('widget');
    if (container !== null) {
        const widget = await import('./widget'); // Dynamic import
        widget.render(container);
    }
}

renderWidget();&lt;/code&gt;
    &lt;p&gt;This command starts a TypeScript compiler with &lt;code&gt;--watch&lt;/code&gt; parameter, with the ability to automatically recompile TypeScript files whenever they are modified.&lt;/p&gt;
    &lt;code&gt;tsc --watch&lt;/code&gt;
    &lt;p&gt;Starting from TypeScript version 4.9, file monitoring primarily relies on file system events, automatically resorting to polling if an event-based watcher cannot be established.&lt;/p&gt;
    &lt;p&gt;The Non-null Assertion Operator (Postfix !) also called Definite Assignment Assertions is a TypeScript feature that allows you to assert that a variable or property is not null or undefined, even if TypeScript's static type analysis suggests that it might be. With this feature it is possible to remove any explicit checking.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name: string;
};

const printName = (person?: Person) =&amp;gt; {
    console.log(`Name is ${person!.name}`);
};&lt;/code&gt;
    &lt;p&gt;Defaulted declarations are used when a variable or parameter is assigned a default value. This means that if no value is provided for that variable or parameter, the default value will be used instead.&lt;/p&gt;
    &lt;code&gt;function greet(name: string = 'Anonymous'): void {
    console.log(`Hello, ${name}!`);
}
greet(); // Hello, Anonymous!
greet('John'); // Hello, John!&lt;/code&gt;
    &lt;p&gt;The optional chaining operator &lt;code&gt;?.&lt;/code&gt; works like the regular dot operator (&lt;code&gt;.&lt;/code&gt;) for accessing properties or methods. However, it gracefully handles null or undefined values by terminating the expression and returning &lt;code&gt;undefined&lt;/code&gt;, instead of throwing an error.&lt;/p&gt;
    &lt;code&gt;type Person = {
    name: string;
    age?: number;
    address?: {
        street?: string;
        city?: string;
    };
};

const person: Person = {
    name: 'John',
};

console.log(person.address?.city); // undefined&lt;/code&gt;
    &lt;p&gt;The nullish coalescing operator &lt;code&gt;??&lt;/code&gt; returns the right-hand side value if the left-hand side is &lt;code&gt;null&lt;/code&gt; or &lt;code&gt;undefined&lt;/code&gt;; otherwise, it returns the left-hand side value.&lt;/p&gt;
    &lt;code&gt;const foo = null ?? 'foo';
console.log(foo); // foo

const baz = 1 ?? 'baz';
const baz2 = 0 ?? 'baz';
console.log(baz); // 1
console.log(baz2); // 0&lt;/code&gt;
    &lt;p&gt;Template Literal Types allow to manipulate string value at type level and generate new string types based on existing ones. They are useful to create more expressive and precise types from string-based operations.&lt;/p&gt;
    &lt;code&gt;type Department = 'engineering' | 'hr';
type Language = 'english' | 'spanish';
type Id = `${Department}-${Language}-id`; // "engineering-english-id" | "engineering-spanish-id" | "hr-english-id" | "hr-spanish-id"&lt;/code&gt;
    &lt;p&gt;Function overloading allows you to define multiple function signatures for the same function name, each with different parameter types and return type. When you call an overloaded function, TypeScript uses the provided arguments to determine the correct function signature:&lt;/p&gt;
    &lt;code&gt;function makeGreeting(name: string): string;
function makeGreeting(names: string[]): string[];

function makeGreeting(person: unknown): unknown {
    if (typeof person === 'string') {
        return `Hi ${person}!`;
    } else if (Array.isArray(person)) {
        return person.map(name =&amp;gt; `Hi, ${name}!`);
    }
    throw new Error('Unable to greet');
}

makeGreeting('Simon');
makeGreeting(['Simone', 'John']);&lt;/code&gt;
    &lt;p&gt;A Recursive Type is a type that can refer to itself. This is useful for defining data structures that have a hierarchical or recursive structure (potentially infinite nesting), such as linked lists, trees, and graphs.&lt;/p&gt;
    &lt;code&gt;type ListNode&amp;lt;T&amp;gt; = {
    data: T;
    next: ListNode&amp;lt;T&amp;gt; | undefined;
};&lt;/code&gt;
    &lt;p&gt;It is possible to define complex type relationships using logic and recursion in TypeScript. Letâ€™s break it down in simple terms:&lt;/p&gt;
    &lt;p&gt;Conditional Types: allows you to define types based on boolean conditions:&lt;/p&gt;
    &lt;code&gt;type CheckNumber&amp;lt;T&amp;gt; = T extends number ? 'Number' : 'Not a number';
type A = CheckNumber&amp;lt;123&amp;gt;; // 'Number'
type B = CheckNumber&amp;lt;'abc'&amp;gt;; // 'Not a number'&lt;/code&gt;
    &lt;p&gt;Recursion: means a type definition that refers to itself within its own definition:&lt;/p&gt;
    &lt;code&gt;type Json = string | number | boolean | null | Json[] | { [key: string]: Json };

const data: Json = {
    prop1: true,
    prop2: 'prop2',
    prop3: {
        prop4: [],
    },
};&lt;/code&gt;
    &lt;p&gt;Recursive Conditional Types combine both conditional logic and recursion. It means that a type definition can depend on itself through conditional logic, creating complex and flexible type relationships.&lt;/p&gt;
    &lt;code&gt;type Flatten&amp;lt;T&amp;gt; = T extends Array&amp;lt;infer U&amp;gt; ? Flatten&amp;lt;U&amp;gt; : T;

type NestedArray = [1, [2, [3, 4], 5], 6];
type FlattenedArray = Flatten&amp;lt;NestedArray&amp;gt;; // 2 | 3 | 4 | 5 | 1 | 6&lt;/code&gt;
    &lt;p&gt;Node.js added support for ECMAScript Modules starting from version 15.3.0, and TypeScript has had ECMAScript Module Support for Node.js since version 4.7. This support can be enabled by using the &lt;code&gt;module&lt;/code&gt; property with the value &lt;code&gt;nodenext&lt;/code&gt; in the tsconfig.json file. Here's an example:&lt;/p&gt;
    &lt;code&gt;{
  "compilerOptions": {
    "module": "nodenext",
    "outDir": "./lib",
    "declaration": true
  }
}&lt;/code&gt;
    &lt;p&gt;Node.js supports two file extensions for modules: &lt;code&gt;.mjs&lt;/code&gt; for ES modules and &lt;code&gt;.cjs&lt;/code&gt; for CommonJS modules. The equivalent file extensions in TypeScript are &lt;code&gt;.mts&lt;/code&gt; for ES modules and &lt;code&gt;.cts&lt;/code&gt; for CommonJS modules. When the TypeScript compiler transpiles these files to JavaScript, it will create &lt;code&gt;.mjs&lt;/code&gt; and &lt;code&gt;.cjs&lt;/code&gt; files.&lt;/p&gt;
    &lt;p&gt;If you want to use ES modules in your project, you can set the &lt;code&gt;type&lt;/code&gt; property to "module" in your package.json file. This instructs Node.js to treat the project as an ES module project.&lt;/p&gt;
    &lt;p&gt;Additionally, TypeScript also supports type declarations in .d.ts files. These declaration files provide type information for libraries or modules written in TypeScript, allowing other developers to utilize them with TypeScript's type checking and auto-completion features.&lt;/p&gt;
    &lt;p&gt;In TypeScript, assertion functions are functions that indicate the verification of a specific condition based on their return value. In their simplest form, an assert function examines a provided predicate and raises an error when the predicate evaluates to false.&lt;/p&gt;
    &lt;code&gt;function isNumber(value: unknown): asserts value is number {
    if (typeof value !== 'number') {
        throw new Error('Not a number');
    }
}&lt;/code&gt;
    &lt;p&gt;Or can be declared as function expression:&lt;/p&gt;
    &lt;code&gt;type AssertIsNumber = (value: unknown) =&amp;gt; asserts value is number;
const isNumber: AssertIsNumber = value =&amp;gt; {
    if (typeof value !== 'number') {
        throw new Error('Not a number');
    }
};&lt;/code&gt;
    &lt;p&gt;Assertion functions share similarities with type guards. Type guards were initially introduced to perform runtime checks and ensure the type of a value within a specific scope. Specifically, a type guard is a function that evaluates a type predicate and returns a boolean value indicating whether the predicate is true or false. This differs slightly from assertion functions,where the intention is to throw an error rather than returning false when the predicate is not satisfied.&lt;/p&gt;
    &lt;p&gt;Example of type guard:&lt;/p&gt;
    &lt;code&gt;const isNumber = (value: unknown): value is number =&amp;gt; typeof value === 'number';&lt;/code&gt;
    &lt;p&gt;Variadic Tuple Types are a features introduces in TypeScript version 4.0, letâ€™s start to learn them by revise what is a tuple:&lt;/p&gt;
    &lt;p&gt;A tuple type is an array which has a defined length, and were the type of each element is known:&lt;/p&gt;
    &lt;code&gt;type Student = [string, number];
const [name, age]: Student = ['Simone', 20];&lt;/code&gt;
    &lt;p&gt;The term "variadic" means indefinite arity (accept a variable number of arguments).&lt;/p&gt;
    &lt;p&gt;A variadic tuple is a tuple type which has all the property as before but the exact shape is not defined yet:&lt;/p&gt;
    &lt;code&gt;type Bar&amp;lt;T extends unknown[]&amp;gt; = [boolean, ...T, number];

type A = Bar&amp;lt;[boolean]&amp;gt;; // [boolean, boolean, number]
type B = Bar&amp;lt;['a', 'b']&amp;gt;; // [boolean, 'a', 'b', number]
type C = Bar&amp;lt;[]&amp;gt;; // [boolean, number]&lt;/code&gt;
    &lt;p&gt;In the previous code we can see that the tuple shape is defined by the &lt;code&gt;T&lt;/code&gt; generic passed in.&lt;/p&gt;
    &lt;p&gt;Variadic tuples can accept multiple generics make them very flexible:&lt;/p&gt;
    &lt;code&gt;type Bar&amp;lt;T extends unknown[], G extends unknown[]&amp;gt; = [...T, boolean, ...G];

type A = Bar&amp;lt;[number], [string]&amp;gt;; // [number, boolean, string]
type B = Bar&amp;lt;['a', 'b'], [boolean]&amp;gt;; // ["a", "b", boolean, boolean]&lt;/code&gt;
    &lt;p&gt;With the new variadic tuples we can use:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The spreads in tuple type syntax can now be generic, so we can represent higher-order operation on tuples and arrays even when we do not know the actual types we are operating over.&lt;/item&gt;
      &lt;item&gt;The rest elements can occur anywhere in a tuple.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;type Items = readonly unknown[];

function concat&amp;lt;T extends Items, U extends Items&amp;gt;(
    arr1: T,
    arr2: U
): [...T, ...U] {
    return [...arr1, ...arr2];
}

concat([1, 2, 3], ['4', '5', '6']); // [1, 2, 3, "4", "5", "6"]&lt;/code&gt;
    &lt;p&gt;Boxed types refer to the wrapper objects that are used to represent primitive types as objects. These wrapper objects provide additional functionality and methods that are not available directly on the primitive values.&lt;/p&gt;
    &lt;p&gt;When you access a method like &lt;code&gt;charAt&lt;/code&gt; or &lt;code&gt;normalize&lt;/code&gt; on a &lt;code&gt;string&lt;/code&gt; primitive, JavaScript wraps it in a &lt;code&gt;String&lt;/code&gt; object, calls the method, and then throws the object away.&lt;/p&gt;
    &lt;p&gt;Demonstration:&lt;/p&gt;
    &lt;code&gt;const originalNormalize = String.prototype.normalize;
String.prototype.normalize = function () {
    console.log(this, typeof this);
    return originalNormalize.call(this);
};
console.log('\u0041'.normalize());&lt;/code&gt;
    &lt;p&gt;TypeScript represents this differentiation by providing separate types for the primitives and their corresponding object wrappers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;string =&amp;gt; String&lt;/item&gt;
      &lt;item&gt;number =&amp;gt; Number&lt;/item&gt;
      &lt;item&gt;boolean =&amp;gt; Boolean&lt;/item&gt;
      &lt;item&gt;symbol =&amp;gt; Symbol&lt;/item&gt;
      &lt;item&gt;bigint =&amp;gt; BigInt&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The boxed types are usually not needed. Avoid using boxed types and instead use type for the primitives, for instance &lt;code&gt;string&lt;/code&gt; instead of &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Covariance and Contravariance are used to describe how relationships work when dealing with inheritance or assignment of types.&lt;/p&gt;
    &lt;p&gt;Covariance means that a type relationship preserves the direction of inheritance or assignment, so if a type A is a subtype of type B, then an array of type A is also considered a subtype of an array of type B. The important thing to note here is that the subtype relationship is maintained this means that Covariance accept subtype but doesn't accept supertype.&lt;/p&gt;
    &lt;p&gt;Contravariance means that a type relationship reverses the direction of inheritance or assignment, so if a type A is a subtype of type B, then an array of type B is considered a subtype of an array of type A. The subtype relationship is reversed this means that Contravariance accept supertype but doesn't accept subtype.&lt;/p&gt;
    &lt;p&gt;Notes: Bivariance means accept both supertype &amp;amp; subtype.&lt;/p&gt;
    &lt;p&gt;Example: Let's say we have a space for all animals and a separate space just for dogs.&lt;/p&gt;
    &lt;p&gt;In Covariance, you can put all the dogs in the animals space because dogs are a type of animal. But you cannot put all the animals in the dog space because there might be other animals mixed in.&lt;/p&gt;
    &lt;p&gt;In Contravariance, you cannot put all the animals in the dogs space because the animals space might contain other animals as well. However, you can put all the dogs in the animal space because all dogs are also animals.&lt;/p&gt;
    &lt;code&gt;// Covariance example
class Animal {
    name: string;
    constructor(name: string) {
        this.name = name;
    }
}

class Dog extends Animal {
    breed: string;
    constructor(name: string, breed: string) {
        super(name);
        this.breed = breed;
    }
}

let animals: Animal[] = [];
let dogs: Dog[] = [];

// Covariance allows assigning subtype (Dog) array to supertype (Animal) array
animals = dogs;
dogs = animals; // Invalid: Type 'Animal[]' is not assignable to type 'Dog[]'

// Contravariance example
type Feed&amp;lt;in T&amp;gt; = (animal: T) =&amp;gt; void;

let feedAnimal: Feed&amp;lt;Animal&amp;gt; = (animal: Animal) =&amp;gt; {
    console.log(`Animal name: ${animal.name}`);
};

let feedDog: Feed&amp;lt;Dog&amp;gt; = (dog: Dog) =&amp;gt; {
    console.log(`Dog name: ${dog.name}, Breed: ${dog.breed}`);
};

// Contravariance allows assigning supertype (Animal) callback to subtype (Dog) callback
feedDog = feedAnimal;
feedAnimal = feedDog; // Invalid: Type 'Feed&amp;lt;Dog&amp;gt;' is not assignable to type 'Feed&amp;lt;Animal&amp;gt;'.&lt;/code&gt;
    &lt;p&gt;In TypeScript, type relationships for arrays are covariant, while type relationships for function parameters are contravariant. This means that TypeScript exhibits both covariance and contravariance, depending on the context.&lt;/p&gt;
    &lt;p&gt;As of TypeScript 4.7.0, we can use the &lt;code&gt;out&lt;/code&gt; and &lt;code&gt;in&lt;/code&gt; keywords to be specific about Variance annotation.&lt;/p&gt;
    &lt;p&gt;For Covariant, use the &lt;code&gt;out&lt;/code&gt; keyword:&lt;/p&gt;
    &lt;code&gt;type AnimalCallback&amp;lt;out T&amp;gt; = () =&amp;gt; T; // T is Covariant here&lt;/code&gt;
    &lt;p&gt;And for Contravariant, use the &lt;code&gt;in&lt;/code&gt; keyword:&lt;/p&gt;
    &lt;code&gt;type AnimalCallback&amp;lt;in T&amp;gt; = (value: T) =&amp;gt; void; // T is Contravariance here&lt;/code&gt;
    &lt;p&gt;Template string pattern index signatures allow us to define flexible index signatures using template string patterns. This feature enables us to create objects that can be indexed with specific patterns of string keys, providing more control and specificity when accessing and manipulating properties.&lt;/p&gt;
    &lt;p&gt;TypeScript from version 4.4 allows index signatures for symbols and template string patterns.&lt;/p&gt;
    &lt;code&gt;const uniqueSymbol = Symbol('description');

type MyKeys = `key-${string}`;

type MyObject = {
    [uniqueSymbol]: string;
    [key: MyKeys]: number;
};

const obj: MyObject = {
    [uniqueSymbol]: 'Unique symbol key',
    'key-a': 123,
    'key-b': 456,
};

console.log(obj[uniqueSymbol]); // Unique symbol key
console.log(obj['key-a']); // 123
console.log(obj['key-b']); // 456&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;satisfies&lt;/code&gt;  allows you to check if a given type satisfies a specific interface or condition. In other words, it ensures that a type has all the required properties and methods of a specific interface. It is a way to ensure a variable fits into a definition of a type.
Here is an example:&lt;/p&gt;
    &lt;code&gt;type Columns = 'name' | 'nickName' | 'attributes';

type User = Record&amp;lt;Columns, string | string[] | undefined&amp;gt;;

// Type Annotation using `User`
const user: User = {
    name: 'Simone',
    nickName: undefined,
    attributes: ['dev', 'admin'],
};

// In the following lines, TypeScript won't be able to infer properly
user.attributes?.map(console.log); // Property 'map' does not exist on type 'string | string[]'. Property 'map' does not exist on type 'string'.
user.nickName; // string | string[] | undefined

// Type assertion using `as`
const user2 = {
    name: 'Simon',
    nickName: undefined,
    attributes: ['dev', 'admin'],
} as User;

// Here too, TypeScript won't be able to infer properly
user2.attributes?.map(console.log); // Property 'map' does not exist on type 'string | string[]'. Property 'map' does not exist on type 'string'.
user2.nickName; // string | string[] | undefined

// Using `satisfies` operators we can properly infer the types now
const user3 = {
    name: 'Simon',
    nickName: undefined,
    attributes: ['dev', 'admin'],
} satisfies User;

user3.attributes?.map(console.log); // TypeScript infers correctly: string[]
user3.nickName; // TypeScript infers correctly: undefined&lt;/code&gt;
    &lt;p&gt;Type-Only Imports and Export allows you to import or export types without importing or exporting the values or functions associated with those types. This can be useful for reducing the size of your bundle.&lt;/p&gt;
    &lt;p&gt;To use type-only imports, you can use the &lt;code&gt;import type&lt;/code&gt; keyword.&lt;/p&gt;
    &lt;p&gt;TypeScript permits using both declaration and implementation file extensions (.ts, .mts, .cts, and .tsx) in type-only imports, regardless of &lt;code&gt;allowImportingTsExtensions&lt;/code&gt; settings.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;import type { House } from './house.ts';&lt;/code&gt;
    &lt;p&gt;The following are supported forms:&lt;/p&gt;
    &lt;code&gt;import type T from './mod';
import type { A, B } from './mod';
import type * as Types from './mod';
export type { T };
export type { T } from './mod';&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;using&lt;/code&gt; declaration is a block-scoped, immutable binding, similar to &lt;code&gt;const&lt;/code&gt;, used for managing disposable resources. When initialized with a value, the &lt;code&gt;Symbol.dispose&lt;/code&gt; method of that value is recorded and subsequently executed upon exiting the enclosing block scope.&lt;/p&gt;
    &lt;p&gt;This is based on ECMAScript's Resource Management feature, which is useful for performing essential cleanup tasks after object creation, such as closing connections, deleting files, and releasing memory.&lt;/p&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Due to its recent introduction in TypeScript version 5.2, most runtimes lack native support. You'll need polyfills for: &lt;code&gt;Symbol.dispose&lt;/code&gt;,&lt;code&gt;Symbol.asyncDispose&lt;/code&gt;,&lt;code&gt;DisposableStack&lt;/code&gt;,&lt;code&gt;AsyncDisposableStack&lt;/code&gt;,&lt;code&gt;SuppressedError&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Additionally, you will need to configure your tsconfig.json as follows:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
    "compilerOptions": {
        "target": "es2022",
        "lib": ["es2022", "esnext.disposable", "dom"]
    }
}&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;//@ts-ignore
Symbol.dispose ??= Symbol('Symbol.dispose'); // Simple polify

const doWork = (): Disposable =&amp;gt; {
    return {
        [Symbol.dispose]: () =&amp;gt; {
            console.log('disposed');
        },
    };
};

console.log(1);

{
    using work = doWork(); // Resource is declared
    console.log(2);
} // Resource is disposed (e.g., `work[Symbol.dispose]()` is evaluated)

console.log(3);&lt;/code&gt;
    &lt;p&gt;The code will log:&lt;/p&gt;
    &lt;code&gt;1
2
disposed
3&lt;/code&gt;
    &lt;p&gt;A resource eligible for disposal must adhere to the &lt;code&gt;Disposable&lt;/code&gt; interface:&lt;/p&gt;
    &lt;code&gt;// lib.esnext.disposable.d.ts
interface Disposable {
    [Symbol.dispose](): void;
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;using&lt;/code&gt; declarations record resource disposal operations in a stack, ensuring they are disposed in reverse order of declaration:&lt;/p&gt;
    &lt;code&gt;{
    using j = getA(),
        y = getB();
    using k = getC();
} // disposes `C`, then `B`, then `A`.&lt;/code&gt;
    &lt;p&gt;Resources are guaranteed to be disposed, even if subsequent code or exceptions occur. This may lead to disposal potentially throwing an exception, possibly suppressing another. To retain information on suppressed errors, a new native exception, &lt;code&gt;SuppressedError&lt;/code&gt;, is introduced.&lt;/p&gt;
    &lt;p&gt;An &lt;code&gt;await using&lt;/code&gt; declaration handles an asynchronously disposable resource. The value must have a &lt;code&gt;Symbol.asyncDispose&lt;/code&gt; method, which will be awaited at the block's end.&lt;/p&gt;
    &lt;code&gt;async function doWorkAsync() {
    await using work = doWorkAsync(); // Resource is declared
} // Resource is disposed (e.g., `await work[Symbol.asyncDispose]()` is evaluated)&lt;/code&gt;
    &lt;p&gt;For an asynchronously disposable resource, it must adhere to either the &lt;code&gt;Disposable&lt;/code&gt; or &lt;code&gt;AsyncDisposable&lt;/code&gt; interface:&lt;/p&gt;
    &lt;code&gt;// lib.esnext.disposable.d.ts
interface AsyncDisposable {
    [Symbol.asyncDispose](): Promise&amp;lt;void&amp;gt;;
}&lt;/code&gt;
    &lt;code&gt;//@ts-ignore
Symbol.asyncDispose ??= Symbol('Symbol.asyncDispose'); // Simple polify

class DatabaseConnection implements AsyncDisposable {
    // A method that is called when the object is disposed asynchronously
    [Symbol.asyncDispose]() {
        // Close the connection and return a promise
        return this.close();
    }

    async close() {
        console.log('Closing the connection...');
        await new Promise(resolve =&amp;gt; setTimeout(resolve, 1000));
        console.log('Connection closed.');
    }
}

async function doWork() {
    // Create a new connection and dispose it asynchronously when it goes out of scope
    await using connection = new DatabaseConnection(); //  Resource is declared
    console.log('Doing some work...');
} // Resource is disposed (e.g., `await connection[Symbol.asyncDispose]()` is evaluated)

doWork();&lt;/code&gt;
    &lt;p&gt;The code logs:&lt;/p&gt;
    &lt;code&gt;Doing some work...
Closing the connection...
Connection closed.&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;using&lt;/code&gt; and &lt;code&gt;await using&lt;/code&gt; declarations are allowed in Statements: &lt;code&gt;for&lt;/code&gt;, &lt;code&gt;for-in&lt;/code&gt;, &lt;code&gt;for-of&lt;/code&gt;, &lt;code&gt;for-await-of&lt;/code&gt;, &lt;code&gt;switch&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;TypeScript 5.3's Import Attributes (labels for imports) tell the runtime how to handle modules (JSON, etc.). This improves security by ensuring clear imports and aligns with Content Security Policy (CSP) for safer resource loading. TypeScript ensures they are valid but lets the runtime handle their interpretation for specific module handling.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;import config from './config.json' with { type: 'json' };&lt;/code&gt;
    &lt;p&gt;with dynamic import:&lt;/p&gt;
    &lt;code&gt;const config = import('./config.json', { with: { type: 'json' } });&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46573001</guid><pubDate>Sun, 11 Jan 2026 05:42:03 +0000</pubDate></item><item><title>More than one hundred years of Film Sizes</title><link>https://wichm.home.xs4all.nl/filmsize.html</link><description>&lt;doc fingerprint="360cd053962552d7"&gt;
  &lt;main&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;More than one hundred years&lt;p&gt;of&lt;/p&gt;&lt;head&gt;Film Sizes&lt;/head&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;One hundred years of cinema is also due to acceptance of one standard gauge. Whereas film equipment has undergone drastic changes in the course of a century it is a little miracle that 35mm has remained the universally accepted film size. If film had followed the same course as video, with its continuing change of systems, the development might have been delayed considerably.&lt;/p&gt;&lt;p&gt;We owe the format to a great extent to Edison (see photo) - in fact 35mm was called the Edison size before.&lt;/p&gt;&lt;p&gt;Click on icon for Monkeyshines Edison film strip of 1890&lt;/p&gt;&lt;p&gt;Edison Kinetograph film strip of June 18th,1891 (click)&lt;/p&gt;&lt;p&gt;In May 1889 Thomas Edison had ordered a Kodak camera from the Eastman Company and was apparently fascinated by the 70mm roll of film used. Thereupon W.K.L.Dickson of his laboratory ordered a roll of film of 1 3/8"(ca. 35 mm) width from Eastman. This was half the film size used in Eastman Kodak cameras. It was to be used in a new type of Kinetoscope for moving images on a strip of celluloid film, which could be viewed by one person at the time.&lt;/p&gt;&lt;p&gt;The LumiÃ¨re brothers introduced in March 1895 their CinÃ©matographe for 35mm film, which was also used at their first public show of 28 December of that year. Their strip of film had only one round hole per image, whereas Edison used four rectangular perforations per frame.&lt;/p&gt;&lt;p&gt;Even at that time there was already a variety of widths: &lt;/p&gt;&lt;p&gt;The abovementioned William Dickson, after leaving Edison, used 2 3/4" (70 mm) for his Mutoscope &amp;amp; Biograph Company' productions to avert Edison's patent rights. Cameramen of this company travelled all over Europe to produce documentaries of a remarkable image quality.&lt;lb/&gt; Widescreen also proved excellently suitable for other subjects. &lt;/p&gt;&lt;p&gt;In 1897 more than 10.000 feet of 63mm film was shot of the then famous box match between Corbett and Fitzsimmons.&lt;/p&gt;&lt;p&gt;One of the problems to be dealt with was the strength of the film base. Because film is pulled through the filmgate in short strokes it comes under high tension. Therefore perforations were torn time and again. Eastman overcame this weakness by doubling the thickness of the nitrate base, which was normally used for film packs from 1896 onward.&lt;/p&gt;&lt;p&gt;By the turn of the century film appeared to become big business. the struggle for the monopoly of the patents intensified. To avoid lengthy court cases the nine major producers of the time decided to pool their rights in the Motion Pictures Patents Company in 1909. This consortium threatened to outlaw outsiders from further film production. Despite the general outcry one favourable effect was that 35mm became standardized to Bell &amp;amp; Howell specifications. It was adopted a.o. by the CongrÃ¨s International des Editeurs de Films in Paris in the same year. It was named standard-size stock, in Germany Normalfilm and in France pÃ©licule format standard. Eastman Kodak became the chief film supplier (see 1912 ad).&lt;/p&gt;&lt;p&gt;This does not imply that no further attempts were being made to introduce other gauges. The standard size was besieged continuously for reasons of economy, projection quality or aesthetic design.&lt;/p&gt;&lt;p&gt;A fierce competition raged in the amateur market. Economy and dimensions were the chief ingredients. The public had to be won over by relative inexpensiveness. Amateur film was usually cut from 35 mm professional raw stock , that was produced in large quantities and therefore economical to buy. The film was cut in two or three lengths - the substandard size, or "Schmalfilm" in Germany.&lt;/p&gt;&lt;p&gt;The first attempt was demonstrated in England by Birt Acres in 1898. His camera, projector at the same time, the Birtac, used 17Â½ mm size with perforations on one side.&lt;/p&gt;&lt;table&gt;&lt;row/&gt;&lt;/table&gt;&lt;p&gt;In the same year J.A.Prestwich introduced 13mm equipment, but little was heard of it since.&lt;/p&gt;&lt;p&gt;More succesful was Heinrich Ernemann, who introduced in 1903 the Kino I. It used the same film as the Biokam. This apparatus could also be used for both taking and projecting pictures - a combination which has been experimented with for years without much success, lately by the American Wittnauer Cine-Twin 8mm set.&lt;/p&gt;&lt;p&gt;In 1900 Gaumont-Demeny ventured with an unusual size: 15mm, with center perforation. The Chrono de Poche did not make it either. Nowadays it is a rarity. In the same year another French firm introduced the Mirograph which used an equally odd size: 20 mm. It had on one side notches instead of perforations. I have yet to see one single specimen.&lt;/p&gt;&lt;p&gt;In the United States the first projector using non-standard film appeared around 1902. This home cinema used a carbide lamp. It was called the Vitak and used 17,5mm film. A few years later another projector appeared with a similar appearance. It was the Ikonograph, using 17,5mm film with a large center perforation.&lt;lb/&gt; In 1923 11,5mm was re-introduced in the USA with the Duplex projector. &lt;/p&gt;&lt;p&gt;In 1897 a fierce fire destroyed the cinema pavillion of a charity bazar in Paris, which took the lives of 124 people. It is no surprise that an immediate search was opened for a replacement of the highly inflammable cellulose nitrate stock. In 1908 the first non-flam acetate film was marketed. It took decennia of perfection before it could supplant the old stock. Only in 1950 the tri-acetate film could be considered equal to nitrate film. However, for amateur films it was employed right after its invention.&lt;/p&gt;&lt;p&gt;In 1912 Edison introduced the Home Kinetoscope for safety film. It employed yet another size: 22mm. It had three rows of images sized 4 x 6mm, separated by two rows of perforations. One column of images was cranked foreward, the middle row backward, and the third row forward again. A camera was never produced. Films from 10 to 15 meter lengths in special containers were for rent from Edison depots or by mail.&lt;/p&gt;Home Kinetoscope show (click)&lt;p&gt;In 1931 Cinelux film projectors were introduced, a silent and sound model. A highly unusual 24mm unperforated Ozaphan film size was being used, the mechanism being a beater movement.&lt;/p&gt;&lt;p&gt;In 1912 PathÃ© introduced with far more success a 28mm size for safety film. The width deviated in order to prevent flammable normal sized film be used for the projector, the PathÃ© Kok (see image).&lt;/p&gt;&lt;p&gt;When during WW1 imports from France into the U.S.A. came to a halt Victor introduced their Safety and Home Cinema projectors for 28mm films perforated with three perforations per frame on both sides.&lt;/p&gt;&lt;p&gt;PathÃ©'s distributor W.B.Cook designed a completely new motorized projector, the New Premier Pathescope (see photo). Not many were sold, however. Keystone and other manufacturers also introduced a 28mm projector, but reverted soon again to the 35mm size.&lt;/p&gt;&lt;p&gt;The PathÃ© Kok projector (The name was taken from from the newly patented logo of a cock) was equipped usually with a dynamo. So it could be used on the not yet electrified countryside. At the same time 28mm cameras were marketed. The emphasis was on showing theatrical films copied from the large film library of PathÃ©, however. &lt;lb/&gt; Initially the new size seemed to do well and was accepted as a standard size for the home cinema. By 1918 10.000 projectors were sold. &lt;/p&gt;&lt;p&gt;The projector enjoyed quite some popularity. In the United States 28mm was accepted as a standard size for portable film projectors by the Society of Motion Picture Engineers. 935 Titles were for rent.&lt;/p&gt;&lt;p&gt;Later developments made the format decline in popularity. Yet the Kok projectors are a showpiece in a collection nowadays, especially so because of its splendid design resembling a robust old-time sewing machine.&lt;/p&gt;&lt;p&gt;Besides emulsion on film base experiments were carried out with celluloid and glass plates. There was still a fierce competition between the magic lantern with its non-inflammable glass slides and the vulnerable film stock.&lt;/p&gt;&lt;p&gt;Yet, undaunted, The Aladdin Cine Products Co. ('from the Pictures Development Co., Toledo, Ohio, USA') produced a similar experimental series of discs of local subjects, but fared a fate even worse than Spirograph.&lt;/p&gt;&lt;p&gt;All these curious attempts make a fine hunting field for the collector nowadays. A Kammatograph was auctioned by Christies for Â£ 3850 in 1993 and may be worth more now.&lt;/p&gt;&lt;p&gt;Special Duplex projector lenses were to be made available to project the 10 x 19mm half frame onto the screen.&lt;lb/&gt;I have a brochure but have been unable to find any reference that the system was seriously considered, or the Duplex lenses ever made available.&lt;/p&gt;&lt;p&gt;Another proposal came in 1922 for a 42 mm size to accomodate a 7mm optical sound track to existing 35mm film by the German Triergon company.&lt;/p&gt;&lt;p&gt;After thirty years of experimentation with different widths in 1922 one was marketed which stood a better chance. In December 1922 PathÃ© introduced its home cinema, Le CinÃ©ma chez soi, called the PathÃ© Baby.&lt;/p&gt;&lt;p&gt; Between the perforations of 35mm film three rows of 9,5mm were slit (see image). &lt;lb/&gt; The projector came first. Its transportation mechanism was almost identical to the LumiÃ¨re CinÃ©matograph of 1895. The apparatus projected a steady image of amazing clarity considering the lamp of 6 Watt. Cassettes with lengths of 9 or 15 meter 9,5mm film could be bought or rented from depots. These films stood out by their great definition. They were reduced from PathÃ©'s considerable 35mm archive. Subjects included newsreels, documentaries, comedies and feature films. Some were colored by a stencil imprint method. An ingenuous system was used to prolong the projection time. By means of notches in the film a mechanism was set into motion in the projector by which certain images - titles or close-ups - could be frozen for a few seconds. &lt;/p&gt;&lt;p&gt;In 1923 a camera with hand crank was marketed. It being small in size, handy and economical, made it popular in a short time. It was for the first time that amateur film gained a wider acceptance. It is estimated that some 300.000 projectors were sold. What happened to all of them is another matter. They are not that often being offered for sale nowadays.&lt;/p&gt;&lt;p&gt;As a result of later developments the size never became popular in the U.S.A. In Europe it was. Even in Japan imitations of 9,5mm movie cameras and projectors were manufactured before the war (Cine Rola). In 1938 9,5mm sound film was introduced with the PathÃ© Vox sound-projector.&lt;/p&gt;&lt;p&gt;It may come as a surprise to some but 9,5 mm still has a following. Cameras and projectors are still manufactured, or more precisely, modern equipment is being converted to this size. Films are still re-perforated by some firms and developing facilities are available, given enough patience. &lt;lb/&gt; Internationally 9,5mm fans form a closely knit community holding yearly global gatherings. The best nine-five films of that year are projected then.&lt;/p&gt;&lt;p&gt;Kodak could not lag behind PathÃ©. John Capstaff of the Kodak laboratories had already been experimenting with another size. They had come to the conclusion that 10mm was the minimum image width for acceptable quality. Perforations on both sides would occupy another 6mm, making a total of 16mm. This gauge had the additional advantage that flammable 35mm stock could not not be slit in half for amateur use.&lt;/p&gt;&lt;p&gt;In 1923 16mm was introduced. In the battle for the amateur market PathÃ© boasted that its size was cheaper because of its economical use of the film width. Its prices suited all(?) purses. In their sales' slogans PathÃ© boasted that 9,5mm had almost the same frame size of 16mm at the price of 8mm.&lt;/p&gt;&lt;p&gt;Kodak opposed that middle perforations could cause stripes over the image. Moreover if the projector claw failed to hit the perforation accurately the images could easily be damaged.&lt;/p&gt;&lt;p&gt; The grain quality of 16mm was better. Kodak introduced with 16mm a reversal developing process with variable second exposure. It did away with the procedure followed so far to have negative film copied onto positive stock. As a result the costs were reduced to only 1/6 of the negative/positive process.&lt;lb/&gt; In later years a sound track was added on one side of the film, sacrificing one row of perforations. It was accepted as an SMPE standard in 1932.&lt;/p&gt;&lt;p&gt;Split 35mm had always been popular as an alternative gauge. The American Sinemat camera/projector used it with perforations on one side in 1915.&lt;/p&gt;&lt;p&gt;Two years later the Movette camera and projector appeared for non-flammable 17,5mm stock. It had round perforations on each side.&lt;/p&gt;&lt;p&gt;In the twenties PathÃ©, when considering a new size of film for projectors used for shows in places in the country where no cinema was operating, also opted for 17,5mm. An optimum use of the film width was obtained by expanding the image and reducing the size of the perforations on both sides.&lt;/p&gt;&lt;p&gt;The PathÃ© Rural was obtainable from 1926. Pathescope, Great Britain, followed with the PathÃ© Rex projector only in 1932. At the same time a film library was made available with well-known films of that era. In 1932 sound film was introduced - the sound track replacing one row of perforations as in 16mm. Although 17,5mm en joyed some popularity before the war - it was used in 4823 cinema's in France - it disappeared in Great Britain in 1939. In France in the first war years as the German occupation power did not permit off-gauge films be shown for censorship reasons.&lt;/p&gt;&lt;p&gt;The death blow was given to this attempt when Kodak introduced 8mm film in 1932. 16 Mm was given twice the number of perforations. First one half of the film was exposed. Thereafter the reel was turned and the other half was shot. After processing the film was slit in the middle and the two 8mm halfs spliced together. In this manner as many frames were available on the 25ft small reel as on 100 ft 16mm film.&lt;/p&gt;&lt;p&gt;Because changing reels in the middle proved to be cumbersome a number of manufacturers introduced straight 8mm wound on 50 ft reels (Univex, Bell &amp;amp; Howell), or in cassettes (Agfa). Because of the lack of uniformity resulting in limited availability straight 8mm did not catch on.&lt;/p&gt;&lt;p&gt;In spite of its advantages nine-five lost field. Kodak had acquired a main share in PathÃ© in the late twenties. It had no interest in pushing that size actively. The supremacy of 8 and 16mm lasted for a considerable number of years. Yet there were attempts to introduce for the amateur economic widescreen sizes.&lt;/p&gt;&lt;p&gt;In fact in the first year of WW2 in the German magazine 'Film fÃ¼r Alle' J.Pauli of Berlin proposed using first one half of the 16mm size, turn the film around and then expose the second half. It involved holding the camera vertically and the use of a mask. The projector would need a prism to project a horizontal wide-screen image. Once one half of the film was projected it needed to be turned over in order to project the opposite half. How a film was to be edited without interfering with the opposite frames was not gone into wisely.&lt;/p&gt;&lt;p&gt;PathÃ© made a more serious attempt to hook on to the popularity of widescreen in the fifties by introducing a duplex and monoplex format in 1955. 9,5mm was double perforated and split in the middle to a 4 3/4mm size which was to be projected horizontally in widescreen. It was an ill-conceived idea. The public showed no interest at all. Few cameras and projectors were sold. The venture was abandoned soon and forgotten in no time. Available stock was converted to the classic 9,5mm size.&lt;/p&gt;&lt;p&gt;The 4 3/4 mm Lido/Orly Duplex cameras and the Monaco Duplex projector have become rare collectors' items.&lt;/p&gt;&lt;p&gt;Eight millimetre also underwent a transformation in 1965. The frame image was enlarged by 50% by using smaller vertical perforations. The so called super 8 film was supplied in 50' 8mm cassettes (having a striking resemblance to Meopta cassettes introduced years before). As from 1973 with magnetic sound stripe. Fuji attempted to introduce a far better conceived single 8 mm system but could not compete with Kodak.&lt;/p&gt;&lt;p&gt;For semi-professional use double super 8 was supplied in the manner of standard 8mm on 16mm 100 ft. reels. It gave far better results because the film passed through the precision film gate of the camera instead of that of the magazine. In addition to the larger frame size and the improved emulsion super 8 compared well with 16mm of the fifties. No wonder that 16mm was hardly used anymore by amateurs.&lt;/p&gt;&lt;p&gt;As stated before widescreen became popular in the fifties. However, it was proceeded by various attempts in the past, even in the nineteenth century as we have seen before, followed by:&lt;/p&gt;&lt;p&gt;All these ventures did not last for much longer than a year. In the fifties another series of attempts were made to introduce large film sizes for widescreen. To name a few:&lt;/p&gt;&lt;p&gt;In the seventies followed IMAX (1970), OMNIMAX (1973), Cinema 180 and others with horizontal position of frames on 65mm negative film. Special theatres were built to accomodate the projectors and ultra wide screen. Specially built projectors were needed because the film could not be pulled through anymore by claw. In the Imax system it is transported by a wave motion. Thanks to the air pressure gate precision, projection on a 180Âº 100 ft. width screen has become possible.&lt;/p&gt;&lt;p&gt;From the foregoing it is clear that standardization was dictated by the economical power of one or more manufacturers. One result was the universal acceptance and growth of the medium for amusement, information and in some cases as an art form.&lt;/p&gt;&lt;p&gt;For the collector hard to find off-gauge equipment/films are a true hunting-ground. In particular the sizes that were never heard of anymore. One may still profit from the relatively low prices as compared with photographica. 8, 16 and 35mm equipment/films are often offered for sale, but it becomes more difficult with 9,5, 17,5, 22, 28mm and all the other sizes mentioned.&lt;/p&gt;&lt;p&gt;One hundred years of cinema has yielded almost one hundred film gauges from 3mm to 75mm. The smallest of 3mm was developed in 1960 by Eric Berndt for NASA to be used in space flights. It had a centre frameline perforation. The largest was employed by LumiÃ¨re in 1900 for large screen presentations at the Paris Exposition.&lt;/p&gt;&lt;p&gt;Most of these film sizes have been relegated to oblivion, much to the detriment of its inventors/manufacturers. Each size has its own history.&lt;/p&gt;&lt;p&gt;Certainly I have not mentioned all of them. Here are some more sizes:&lt;/p&gt;&lt;p&gt;For further info on the apparatus mentioned see my List and Links below. Consult also my Collecting vintage cinematographica page.&lt;/p&gt;&lt;p&gt;Â© Michael Rogge 2022&lt;/p&gt;&lt;p&gt;This article was published originally in Dutch in the quarterly of the Fotografica Society, Netherlands, in 1996 and updated later on.(click)&lt;/p&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt; TO SUBJECTS AND NAMES TO BE FOUND&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;On the web since 6 December 1996. Latest update: December 2022&lt;/p&gt;&lt;p&gt;Return to index-page&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46573688</guid><pubDate>Sun, 11 Jan 2026 08:22:44 +0000</pubDate></item><item><title>Don't fall into the anti-AI hype</title><link>https://antirez.com/news/158</link><description>&lt;doc fingerprint="7e18917dcd6704ad"&gt;
  &lt;main&gt;
    &lt;quote&gt;I love writing software, line by line. It could be said that my career was a continuous effort to create software well written, minimal, where the human touch was the fundamental feature. I also hope for a society where the last are not forgotten. Moreover, I don't want AI to economically succeed, I don't care if the current economic system is subverted (I could be very happy, honestly, if it goes in the direction of a massive redistribution of wealth). But, I would not respect myself and my intelligence if my idea of software and society would impair my vision: facts are facts, and AI is going to change programming forever. In 2020 I left my job in order to write a novel about AI, universal basic income, a society that adapted to the automation of work facing many challenges. At the very end of 2024 I opened a YouTube channel focused on AI, its use in coding tasks, its potential social and economical effects. But while I recognized what was going to happen very early, I thought that we had more time before programming would be completely reshaped, at least a few years. I no longer believe this is the case. Recently, state of the art LLMs are able to complete large subtasks or medium size projects alone, almost unassisted, given a good set of hints about what the end result should be. The degree of success you'll get is related to the kind of programming you do (the more isolated, and the more textually representable, the better: system programming is particularly apt), and to your ability to create a mental representation of the problem to communicate to the LLM. But, in general, it is now clear that for most projects, writing the code yourself is no longer sensible, if not to have fun. In the past week, just prompting, and inspecting the code to provide guidance from time to time, in a few hours I did the following four tasks, in hours instead of weeks: 1. I modified my linenoise library to support UTF-8, and created a framework for line editing testing that uses an emulated terminal that is able to report what is getting displayed in each character cell. Something that I always wanted to do, but it was hard to justify the work needed just to test a side project of mine. But if you can just describe your idea, and it materializes in the code, things are very different. 2. I fixed transient failures in the Redis test. This is very annoying work, timing related issues, TCP deadlock conditions, and so forth. Claude Code iterated for all the time needed to reproduce it, inspected the state of the processes to understand what was happening, and fixed the bugs. 3. Yesterday I wanted a pure C library that would be able to do the inference of BERT like embedding models. Claude Code created it in 5 minutes. Same output and same speed (15% slower) than PyTorch. 700 lines of code. A Python tool to convert the GTE-small model. 4. In the past weeks I operated changes to Redis Streams internals. I had a design document for the work I did. I tried to give it to Claude Code and it reproduced my work in, like, 20 minutes or less (mostly because I'm slow at checking and authorizing to run the commands needed). It is simply impossible not to see the reality of what is happening. Writing code is no longer needed for the most part. It is now a lot more interesting to understand what to do, and how to do it (and, about this second part, LLMs are great partners, too). It does not matter if AI companies will not be able to get their money back and the stock market will crash. All that is irrelevant, in the long run. It does not matter if this or the other CEO of some unicorn is telling you something that is off putting, or absurd. Programming changed forever, anyway. How do I feel, about all the code I wrote that was ingested by LLMs? I feel great to be part of that, because I see this as a continuation of what I tried to do all my life: democratizing code, systems, knowledge. LLMs are going to help us to write better software, faster, and will allow small teams to have a chance to compete with bigger companies. The same thing open source software did in the 90s. However, this technology is far too important to be in the hands of a few companies. For now, you can do the pre-training better or not, you can do reinforcement learning in a much more effective way than others, but the open models, especially the ones produced in China, continue to compete (even if they are behind) with frontier models of closed labs. There is a sufficient democratization of AI, so far, even if imperfect. But: it is absolutely not obvious that it will be like that forever. I'm scared about the centralization. At the same time, I believe neural networks, at scale, are simply able to do incredible things, and that there is not enough "magic" inside current frontier AI for the other labs and teams not to catch up (otherwise it would be very hard to explain, for instance, why OpenAI, Anthropic and Google are so near in their results, for years now). As a programmer, I want to write more open source than ever, now. I want to improve certain repositories of mine abandoned for time concerns. I want to apply AI to my Redis workflow. Improve the Vector Sets implementation and then other data structures, like I'm doing with Streams now. But I'm worried for the folks that will get fired. It is not clear what the dynamic at play will be: will companies try to have more people, and to build more? Or will they try to cut salary costs, having fewer programmers that are better at prompting? And, there are other sectors where humans will become completely replaceable, I fear. What is the social solution, then? Innovation can't be taken back after all. I believe we should vote for governments that recognize what is happening, and are willing to support those who will remain jobless. And, the more people get fired, the more political pressure there will be to vote for those who will guarantee a certain degree of protection. But I also look forward to the good AI could bring: new progress in science, that could help lower the suffering of the human condition, which is not always happy. Anyway, back to programming. I have a single suggestion for you, my friend. Whatever you believe about what the Right Thing should be, you can't control it by refusing what is happening right now. Skipping AI is not going to help you or your career. Think about it. Test these new tools, with care, with weeks of work, not in a five minutes test where you can just reinforce your own beliefs. Find a way to multiply yourself, and if it does not work for you, try again every few months. Yes, maybe you think that you worked so hard to learn coding, and now machines are doing it for you. But what was the fire inside you, when you coded till night to see your project working? It was building. And now you can build more and better, if you find your way to use AI effectively. The fun is still there, untouched.&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574276</guid><pubDate>Sun, 11 Jan 2026 10:26:18 +0000</pubDate></item><item><title>Think of Pavlov</title><link>https://boz.com/articles/think-pavlov</link><description>&lt;doc fingerprint="c7229b51a4eb8e9a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Think of Pavlov&lt;/head&gt;
    &lt;p&gt;People often treat interactions as one-off events. They want to win this argument, prove their value, be right in the moment. But almost everything in life is a repeat game. Youâ€™re going to see these people again â€” and even the people watching from the sidelines are taking notes.&lt;/p&gt;
    &lt;p&gt;Every interaction is training the people around you.&lt;/p&gt;
    &lt;p&gt;After itâ€™s over, theyâ€™ll like you a little more or a little less. Theyâ€™ll be more or less likely to bring you problems. Theyâ€™ll be more or less likely to recommend you or avoid you. And just as important, youâ€™re training them on the type of problems to bring you.&lt;/p&gt;
    &lt;p&gt;It helps to treat every conversation as a conditioning event. Youâ€™re teaching others how to feel about working with you, what kind of feedback you give, and what kinds of challenges belong in your orbit.&lt;/p&gt;
    &lt;p&gt;If someone comes with a question and leaves feeling small, theyâ€™ll stop asking. If they bring you a hard problem and you meet it with curiosity, youâ€™ll get more of those. If you always solve things for people, theyâ€™ll outsource their judgment. If you always critique, theyâ€™ll start hiding the work.&lt;/p&gt;
    &lt;p&gt;You are, in effect, Pavlov. Each interaction rings a bell. The only question is what behavior itâ€™s reinforcing.&lt;/p&gt;
    &lt;p&gt;This doesnâ€™t mean everything should be soft or easy. Hard feedback, delivered well, can be incredibly motivating. But your tone, timing, and consistency create the feedback loop that defines your reputation and, over time, your ability to make progress.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574475</guid><pubDate>Sun, 11 Jan 2026 11:03:06 +0000</pubDate></item><item><title>HTML-only conditional lazy loading (via preload and media)</title><link>https://orga.cat/blog/html-conditional-lazy-loading/</link><description>&lt;doc fingerprint="1887df7080ee8ba7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HTML-only conditional lazy loading (via preload + media)&lt;/head&gt;
    &lt;p&gt;The accepted practice is to not add lazy-loading to images above the fold, especially the LCP image. The problem is that "above the fold" depends on screen size: an image can be above the fold on desktop and below it on mobile. With native lazy loading and static HTML (e.g., without device detection on the server side or JavaScript), you normally have to pick one behavior and get it wrong for part of your users.&lt;/p&gt;
    &lt;p&gt;But there's a small workaround that seems to work. Browsers won't delay the loading of an image if it's already been fetched. You can take advantage of that by conditionally preloading the image using a media query, then marking the image as lazy later. I tested it using the HTTP link header, but may also work fine with a &lt;code&gt;&amp;lt;link rel="preload"&amp;gt;&lt;/code&gt; tag.&lt;/p&gt;
    &lt;p&gt;Conceptually:&lt;/p&gt;
    &lt;code&gt;Link: &amp;lt;/hero.jpg&amp;gt;; rel=preload; as=image; media="(min-width: 1024px)"
&lt;/code&gt;
    &lt;code&gt;&amp;lt;img src="/hero.jpg" loading="lazy" /&amp;gt;&lt;/code&gt;
    &lt;p&gt;Effect:&lt;/p&gt;
    &lt;p&gt;Desktop: preload fires Ã¢ image loads eagerly (good for LCP)&lt;/p&gt;
    &lt;p&gt;Mobile: preload ignored Ã¢ image lazy-loads&lt;/p&gt;
    &lt;p&gt;I'm using this in book pages and sidebar images at https://pccd.dites.cat. Example: https://pccd.dites.cat/obra/Conca-Guia_(1996)%3A_Els_primers_reculls_de_proverbis_catalans&lt;/p&gt;
    &lt;p&gt;In that layout, the cover image is above the fold on desktop but not on smaller devices Ã¢ so it's eagerly loaded where Lighthouse recommends it, and lazy-loaded where it makes sense.&lt;/p&gt;
    &lt;p&gt;Caveats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Not documented anywhere (but seems to work fine in major browsers)&lt;/item&gt;
      &lt;item&gt;Requires preloading, which may not always be practical (or intended)&lt;/item&gt;
      &lt;item&gt;Lighthouse doesn't fully understand what's happening&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But this gives you HTML-only, viewport-dependent lazy loading.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574640</guid><pubDate>Sun, 11 Jan 2026 11:24:19 +0000</pubDate></item><item><title>I dumped Windows 11 for Linux, and you should too</title><link>https://www.notebookcheck.net/I-dumped-Windows-11-for-Linux-and-you-should-too.1190961.0.html</link><description>&lt;doc fingerprint="959c791f5b27a5c4"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;I dumped Windows 11 for Linux, and you should too&lt;/head&gt;&lt;head rend="h2"&gt;CheckMag&lt;/head&gt;With the growing number of users jumping from Windows to Linux, I decided to fully take the plunge and dive deep into the Open Source ocean. A few months and several headaches later, it has proved to be the best computer-related decision I've made in over a decade (and perhaps in my entire life).&lt;p&gt;Sam Medley ğŸ‘ Published ğŸ‡ªğŸ‡¸ ğŸ‡µğŸ‡¹ ...&lt;/p&gt;&lt;p&gt;I run Artix, by the way.&lt;/p&gt;&lt;p&gt;There. That's out of the way. I recently installed Linux on my main desktop computer and work laptop, overwriting the Windows partition completely. Essentially, I deleted the primary operating system from the two computers I use the most, day in and day out, instead trusting all of my personal and work computing needs to the Open Source community. This has been a growing trend, and I hopped on the bandwagon, but for good reasons. Some of those reasons might pertain to you and convince you to finally make the jump as well. Here's my experience.&lt;/p&gt;&lt;head rend="h2"&gt;The crash-prone catalyst: Telemetry and unstable software&lt;/head&gt;&lt;p&gt;Why are so many articles and YouTube videos lately regaling readers and watchers with the harrowing tales of techies switching from Windows to Linux? Anyone who has read one of those articles or watched one of those videos will know it boils down to two main issues: telemetry and poor software stability.&lt;/p&gt;&lt;p&gt;It's no secret that Windows 11 harvests data like a pumpkin farmer in October, and there is no easy way (and sometimes no way at all) to stop it. The operating system itself acts exactly like what was called "spyware" a decade or so ago, pulling every piece of data it can about its current user. This data includes (but is far from limited to) hardware information, specific apps and software used, usage trends, and more. With the advent of AI, Microsoft made headlines with Copilot, an artificial assistant designed to help users by capturing their data with tools like Recall. It turns out that Copilot has largely been a flop and helps Microsoft (and data thieves) more than its users.&lt;/p&gt;&lt;p&gt;The other main reason folks uninstall Windows is due to the overall poor software experience. Windows 11 has multiple settings modules to handle the same task (such as setting up networking or adding devices), and none of them seem to talk to each other. Additionally, each new update (which will eventually be forced upon you) seems to bring more bugs than fixes. Personally, I encountered 2-3 full system crashes a week when I ran Windows 11, and my hardware is fairly decent: AMD Ryzen 7 6800H, 32 GB of RAM, and a 1 TB PCIe NVMe drive. Still, a few times a week, my computer would freeze for a few seconds, the displays would go dark, and the PC would either restart or hang indefinitely.&lt;/p&gt;&lt;p&gt;After dealing with these issues and trying to solve them with workarounds, I dual-booted a Linux partition for a few weeks. After a Windows update (that I didn't choose to do) wiped that partition and, consequently, the Linux installation, I decided to go whole-hog: I deleted Windows 11 and used the entire drive for Linux.&lt;/p&gt;&lt;head rend="h2"&gt;Decisions, decisions&lt;/head&gt;&lt;p&gt;The first question often asked of Windows refugees migrating to Linux is, "Why Linux?" It's a good question, and one that needs to be asked before dumping Windows for anything else. Personally, I tried macOS first. The experience was smooth and easy but ultimately felt restrictive (installing from third-party developers, anyone?). Additionally, the only Apple computer I have is a 2014 MacBook Air. As such, the latest version of macOS I could actually run is 11 (Big Sur), which was released in 2020. Overall system operation was quite sluggish on the older hardware, and I knew that time would inevitably take its toll on the software experience â€” apps would soon be out of date and I wouldn't be able to update them. I also tried the OpenCore Legacy Patcher to push the laptop to macOS 13. While performance improved, key features like iMessage and Continuity Camera were either buggy or flat out refused to work. It felt like my laptop was running in mud with its hands tied behind its back. Plus, I needed something for my desktop. Not wanting to drop a mortgage payment or two on new hardware, I opted for Linux.&lt;/p&gt;&lt;p&gt;Linux promised me the potential of what I wanted - high hardware compatibility with full software freedom. The operating system can run on pretty much anything, and it grants users a huge amount of control over their system. I tried out a few ditributions, or distros, of Linux. A distro is like a "flavor" of Linux, and each one has unique factors (e.g., app/package management, bundled user interface). With most distros, these differences are largely irrelevant; most distros offer the same main packages as others.&lt;/p&gt;&lt;p&gt;I tried Mint, a popular option for beginners, first. I started this journey with some Linux experience under my belt; I have installed Linux on Chromebooks and old laptops (which I briefly referenced in this article). Mint is considered a "just works" distro since it usually comes packaged with all the drivers and software most users would need. You can get to work within seconds of booting a fresh install without needing to fuss about in text files and the package manager. Mint was a nice experience, but it was a bit too bloated for my tastes (meaning it came with too much software preinstalled). I settled for Mint on my family's home theatre PC due to its stability and wide array of packages, and it hasn't failed us yet. For my own personal use, I wanted something a bit more "techy" and robust in terms of user features and system control.&lt;/p&gt;&lt;p&gt;I tried out a few other distros, including Debian (which I ran on my work laptop and now use on the office PC at the coffee shop I own and manage), Bazzite, Fedora, and Void. These were all fine, save for Void â€” the XBPS repository of Void Linux was too sparse for what I needed, and driver compatibility was a big issue on my work laptop and home PC. I finally settled on Artix Linux, which is a derivative of Arch Linux. Artix has all the features and control of Arch, including the robust Arch User Repository for plenty of packages and applications. It is also a pretty lightweight distro in that it doesn't come with much out of the box. Artix differs from Arch in that it does not use SystemD as its init system. I won't go down the rabbit hole of init systems here, but suffice it to say that Artix boots lightning quick (less than 10 seconds from a cold power on) and is pretty light on system resources. However, it didn't come "fully assembled."&lt;/p&gt;&lt;head rend="h2"&gt;Hurdles and hangups&lt;/head&gt;&lt;p&gt;My laptop is a 2014 MacBook Air, which is still a pretty solid machine. Unfortunately, Linux doesn't always play nice with Apple products. The biggest problem I ran into after installing Artix on the Air was the lack of wireless drivers, which meant that WiFi did not work out of the box. The resolution was simple: I needed to download the appropriate WiFi drivers (Broadcom drivers, to be exact) from Artix's main repository. This is a straightforward process handled by a single command in the Terminal, but it requires an internet connection... which my laptop did not have. Ultimately, I connected a USB-to-Ethernet adapter, plugged the laptop directly into my router, and installed the WiFi drivers that way. The whole process took about 10 minutes, but it was annoying nonetheless.&lt;/p&gt;&lt;p&gt;For the record, my desktop (an AMD Ryzen 7 6800H-based system) worked flawlessly out-of-the-box, even with my second monitor's uncommon resolution (1680x1050, vertical orientation). I did run into issues with installing some packages on both machines. Trying to install the KDE desktop environment (essentially a different GUI for the main OS) resulted in strange artifacts that put white text on white backgrounds in the menus, and every resolution I tried failed to correct this bug. After reverting to XFCE4 (the default desktop environment for my Artix install), the WiFi signal indicator in the taskbar disappeared. This led to me having to uninstall a network manager installed by KDE and re-linking the default network manager to the runit services startup folder. If that sentence sounds confusing, the process was much more so. It has been resolved, and I have a WiFi indicator that lets me select wireless networks again, but only after about 45 minutes of reading manuals and forum posts.&lt;/p&gt;&lt;p&gt;Other issues are inherent to Linux. Not all games on Steam that are deemed Linux compatible actually are. Civilization III Complete is a good example: launching the game results in the map turning completely black. (Running the game through an application called Lutris resolved this issue.) Not all the software I used on Windows is available in Linux, such as Greenshot for screenshots or uMark for watermarking photos in bulk. There are alternatives to these, but they don't have the same features or require me to relearn workflows.&lt;/p&gt;&lt;head rend="h2"&gt;Smartphone paradise&lt;/head&gt;&lt;p&gt;Surprisingly, smartphone management is heavenly on Artix Linux, but it didn't start that way. Android management is fairly straightforward due to how Android manages USB connections. An Android smartphone tends to be immediately recognized by Linux and act as a USB mass storage device. There's also ADB (Android Debugging Bridge) via the terminal for executing commands to an Android device. However, I use an iPhone.&lt;/p&gt;&lt;p&gt;As mentioned above, Apple products and Linux don't always play together very well. This was certainly the case with my iPhone 13 Pro Max and Artix running the XFCE4 desktop environment. My phone would only charge when plugged in but wouldn't show up. I tried installing applications like KDE Connect, which promised to offer most of the same functions available between iPhones and Mac computers. Unfortunately, it was a no-go. But I found a solution in an unlikely place.&lt;/p&gt;&lt;p&gt;When I tried installing KDE (read above), it left the Dolphin file manager on my device. I started using Dolphin and preferred it to the default file manager for XFCE4 (Thunar). Dolphin held a pleasant surprise: it could detect my iPhone when it was plugged in. This made it a snap to transfer files to and from my phone as the file manager granted full file access to the iPhone. Due to how far Apple's file management has come on iOS, there were specific folders for each of my apps. The overall process is significantly easier than it was on Windows as iTunes is no longer needed.&lt;/p&gt;&lt;head rend="h2"&gt;Operating system with benefits&lt;/head&gt;&lt;p&gt;So why did I switch to Linux, and why am I writing this article about the experience? In a word: joy. I like using my computers again and find the experience fun. There's always something I can tweak or learn about how it operates. The fact that it runs faster than it did on Windows and is significantly more stable are huge bonuses.&lt;/p&gt;&lt;p&gt;There are lots of other points to discuss that would make this article more long-winded than it already is, so I will be brief on a few final specifics. Installing games via Steam is as simple as it is on any other OS, though compatibility will be a bit smaller than on Windows. Still, I've been able to play all of my Steam games (with the exception of Civilization III mentioned above) without any hiccups. In some cases, gameplay is a little bit smoother due to the lack of things like anticheat software running in the background.&lt;/p&gt;&lt;p&gt;Customization is a give and take and will vary based on your chosen desktop environment or window manager. I use XFCE4, which can be customized quite a bit but requires some technical knowledge to beautify. It supports a tool called Conky, which can display system information on your desktop. It is highly customizable but uses a typescript format in a config file to do so.&lt;/p&gt;&lt;p&gt;Power management is a bit wonky on Linux. My MacBook Air seems to last as long as it did with macOS (it's an old laptop, so the battery has worn down), but sometimes a rogue process will keep the machine from sleeping when the lid is closed. However, the lighter nature of Artix means the laptop's fan rarely ramps up. This is true of my desktop as well.&lt;/p&gt;&lt;p&gt;Transferring one's system configuration, including desktop and application settings, is as easy as transferring a single folder, so my MacBook can look exactly like my desktop (provided it has the same packages installed) with a simple drag-and-drop. The additional flexibility in choosing my computer's UI is unrivaled: if I don't like something in XFCE, I can either tweak the actual configuration file or just install a new environment (though this comes with risks, as mentioned above).&lt;/p&gt;&lt;p&gt;Overall system stability has been excellent. My computer hasn't crashed a single time, and I've never run into graphical issues rendering a black screen like I did with Windows 11.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion: Linux takes time but is worth it&lt;/head&gt;&lt;p&gt;Linux is not a "one and done" silver bullet to solve all your computer issues. It is like any other operating system in that it will require users to learn its methods and quirks. Admittedly, it does require a little bit more technical knowledge to dive into the nitty-gritty of the OS and fully unlock its potential, but many distributions (such as Mint) are ready to go out of the box and may never require someone to open a command line. Our main media PC runs Mint and my younger children (aged 4 and 5 as of this writing) are able to navigate it without issue. My older kids are able to load games on it and play with Bluetooth controllers with no issue.&lt;/p&gt;&lt;p&gt;Personally, I like a bit of a challenge, and Linux balances usability with the carrot of a deeper computing experience. Depending on the distribution, I could have been up and running immediately after installation, but I wanted something more. The beauty of Linux is its flexibility; you can use a distribution that is as challenging or straightforward as you like.&lt;/p&gt;&lt;p&gt;Installing Linux not only saved three machines in my house (my laptop, desktop, and our media PC); it resurrected the joy of using a computer. It has been frustrating at times, but the rush of finally fixing a problem after a bit of work is unlike anything I felt on Windows. When I fix a problem on Windows, it's more of a shrug of the shoulder and relief that I'll no longer feel like I'm being stabbed in the eye.&lt;/p&gt;&lt;p&gt;I think that's because the issues I ran into on Linux were, for the most part, my fault. On Windows or macOS, most problems I run into are caused by a restriction or bug in the OS. Linux gives me the freedom to break my machine and fix it again, teaching me along the way.&lt;/p&gt;&lt;p&gt;With Microsoft's refusal (either from pride or ignorance) to improve (or at least not crapify) Windows 11 despite loud user outrage, switching to Linux is becoming a popular option. It's one you should consider doing, and if you've been thinking about it for any length of time, it's time to dive in.&lt;/p&gt;&lt;head rend="h2"&gt;Source(s)&lt;/head&gt;&lt;p&gt;Sam Medley - Notebookcheck&lt;/p&gt;&lt;p&gt;Teaser image source: ChatGPT Image 1.5; Anastase Maragos on Unsplash&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574707</guid><pubDate>Sun, 11 Jan 2026 11:31:22 +0000</pubDate></item><item><title>Gentoo Linux 2025 Review</title><link>https://www.gentoo.org/news/2026/01/05/new-year.html</link><description>&lt;doc fingerprint="5e1fbe0158836364"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; 2025 in retrospect &amp;amp; happy new year 2026! &lt;lb/&gt; Jan 5, 2026 &lt;/head&gt;
    &lt;p&gt;Happy New Year 2026! Once again, a lot has happened in Gentoo over the past months. New developers, more binary packages, GnuPG alternatives support, Gentoo for WSL, improved Rust bootstrap, better NGINX packaging, Ã¢Â¦ As always here weÃ¢re going to revisit all the exciting news from our favourite Linux distribution.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gentoo in numbers&lt;/head&gt;
    &lt;p&gt;Gentoo currently consists of 31663 ebuilds for 19174 different packages. For amd64 (x86-64), there are 89 GBytes of binary packages available on the mirrors. Gentoo each week builds 154 distinct installation stages for different processor architectures and system configurations, with an overwhelming part of these fully up-to-date.&lt;/p&gt;
    &lt;p&gt;The number of commits to the main ::gentoo repository has remained at an overall high level in 2025, with a slight decrease from 123942 to 112927. The number of commits by external contributors was 9396, now across 377 unique external authors.&lt;/p&gt;
    &lt;p&gt;GURU, our user-curated repository with a trusted user model, as entry point for potential developers, has shown a decrease in activity. We have had 5813 commits in 2025, compared to 7517 in 2024. The number of contributors to GURU has increased, from 241 in 2024 to 264 in 2025. Please join us there and help packaging the latest and greatest software. ThatÃ¢s the ideal preparation for becoming a Gentoo developer!&lt;/p&gt;
    &lt;p&gt;Activity has slowed down somewhat on the Gentoo bugtracker bugs.gentoo.org, where weÃ¢ve had 20763 bug reports created in 2025, compared to 26123 in 2024. The number of resolved bugs shows the same trend, with 22395 in 2025 compared to 25946 in 2024. The current values are closer to those of 2023 - but clearly this year we fixed more than we broke!&lt;/p&gt;
    &lt;head rend="h2"&gt;New developers&lt;/head&gt;
    &lt;p&gt;In 2025 we have gained four new Gentoo developers. They are in chronological order:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Jay Faulkner (jayf): Jay joined us in March from Washington, USA. In Gentoo and open source in general, heÃ¢s very much involved with OpenStack; further, heÃ¢s a a big sports fan, mainly ice hockey and NASCAR racing, and already long time Gentoo enthusiast.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Michael Mair-Keimberger (mm1ke): Michael joined us finally in June from Austria, after already amassing over 9000 commits beforehand. Michael works as Network Security Engineer for a big System House in Austria and likes to go jogging regulary and hike the mountains on weekends. In Gentoo, heÃ¢s active in quality control and cleanup.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Alexander Puck Neuwirth (apn-pucky): Alexander, a physics postdoc, joined us in July from Italy. At the intersection of Computer Science, Linux, and high-energy physics, he already uses Gentoo to manage his code and sees it as a great development environment. Beyond sci-physics, heÃ¢s also interested in continuous integration and RISC-V.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jaco Kroon (jkroon): Jaco signed up as developer in October from South Africa. He is a system administrator who works for a company that runs and hosts multiple Gentoo installations, and has been around in Gentoo since 2003! Among our packages, Asterisk is one example of his interests.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Featured changes and news&lt;/head&gt;
    &lt;p&gt;LetÃ¢s now look at the major improvements and news of 2025 in Gentoo.&lt;/p&gt;
    &lt;head rend="h3"&gt;Distribution-wide Initiatives&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Goodbye Github, welcome Codeberg: Mostly because of the continuous attempts to force Copilot usage for our repositories, Gentoo currently considers and plans the migration of our repository mirrors and pull request contributions to Codeberg. Codeberg is a site based on Forgejo, maintained by a non-profit organization, and located in Berlin, Germany. Gentoo continues to host its own primary git, bugs, etc infrastructure and has no plans to change that.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;EAPI 9: The wording for EAPI 9, a new version of the specifications for our ebuilds, has been finalized and approved, and support in Portage is complete. New features in EAPI 9 include pipestatus for better error handling, an edo function for printing a command and executing it, a cleaner environment for the build processes, and the possibility of declaring a default EAPI for the profile directory tree.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Event presence: At FOSDEM 2025 in Brussels, Gentoo has been present once more with a stand, this year together with Flatcar Container Linux (which is based on Gentoo). Naturally we had mugs, stickers, t-shirts, and of course the famous self-compiled buttonsÃ¢Â¦ Further, we have been present at FrOSCon 2025 in Sankt Augustin with workshops Gentoo installation and configuration and Writing your own ebuilds. Last but not least, the toolchain team has represented Gentoo at the GNU Tools Cauldron 2025 in Porto.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SPI migration: The migration of our financial structure to Software in the Public Interest (SPI) is continuing slowly but steadily, with expense payments following the moving intake. If you are donating to Gentoo, and especially if you are a recurrent donor, please change your payments to be directed to SPI; see also our donation web page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Online workshops: Our German support, Gentoo e.V., is grateful to the speakers and participants of four online workshops in 2025 in German and English, on topics as varied as EAPI 9 or GnuPG and LibrePGP. We are looking forward to more exciting events in 2026.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Architectures&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;RISC-V bootable QCOW2: Same as for amd64 and arm64, also for RISC-V we now have ready-made bootable disk images in QCOW2 format available for download on our mirrors in a console and a cloud-init variant. The disk images use the rv64gc instruction set and the lp64d ABI, and can be booted via the standard RISC-V UEFI support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gentoo for WSL: We now publish weekly Gentoo images for Windows Subsystem for Linux (WSL), based on the amd64 stages, see our mirrors. While these images are not present in the Microsoft store yet, thatÃ¢s something we intend to fix soon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;hppa and sparc destabilized: Since we do not have hardware readily available anymore and these architectures mostly fill a retrocomputing niche, stable keywords have been dropped for both hppa (PA-RISC) and sparc. The architectures will remain supported with testing keywords.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;musl with locales: Localization support via the package sys-apps/musl-locales has been added by default to the Gentoo stages based on the lightweight musl C library.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Packages&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;GPG alternatives: Given the unfortunate fracturing of the GnuPG / OpenPGP / LibrePGP ecosystem due to competing standards, we now provide an alternatives mechanism to choose the system gpg provider and ease compatibility testing. At the moment, the original, unmodified GnuPG, the FreePG fork/patchset as also used in many other Linux distributions (Fedora, Debian, Arch, Ã¢Â¦), and the re-implementation Sequoia-PGP with Chameleon are available. In practice, implementation details vary between the providers, and while GnuPG and FreePG are fully supported, you may still encounter difficulties when selecting Sequoia-PGP/Chameleon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;zlib-ng support: We have introduced initial support for using zlib-ng and minizip-ng in compatibility mode in place of the reference zlib libraries.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;System-wide jobserver: We have created steve, an implementation of a token-accounting system-wide jobserver, and introduced experimental global jobserver support in Portage. Thanks to that, it is now possible to globally control the concurrently running build job count, correctly accounting for parallel emerge jobs, make and ninja jobs, and other clients supporting the jobserver protocol.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;NGINX rework: The packaging of the NGINX web server and reverse proxy in Gentoo has undergone a major improvement, including also the splitting off of several third-party modules into separate packages.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;C++ based Rust bootstrap: We have added a bootstrap path for Rust from C++ using MutabahÃ¢s Rust compiler mrustc, which alleviates the need for pre-built binaries and makes it significantly easier to support more configurations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ada and D bootstrap: Similarly, Ada and D support in gcc now have clean bootstrap paths, which makes enabling these in the compiler as easy as switching the useflags on gcc and running emerge.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FlexiBLAS: Gentoo has adopted the new FlexiBLAS wrapper library as the primary way of switching implementations of the BLAS numerical algorithm library at runtime. This automatically also provides ABI stability for linking programs and bundles the specific treatment of different BLAS variants in one place.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Python: In the meantime the default Python version in Gentoo has reached Python 3.13. Additionally we have also Python 3.14 available stable - fully up to date with upstream.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;KDE upgrades: As of end of 2025, in Gentoo stable we have KDE Gear 25.08.3, KDE Frameworks 6.20.0, and KDE Plasma 6.5.4. As always, Gentoo testing follows the newest upstream releases (and using the KDE overlay you can even install from git sources).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Physical and Software Infrastructure&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Additional build server: A second dedicated build server, hosted at Hetzner Germany, has been added to speed up the generation of installation stages, iso and qcow2 images, and binary packages.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Documentation: Documentation work has made constant progress on wiki.gentoo.org. The Gentoo Handbook had some particularly useful updates, and the documentation received lots of improvements and additions from the many active volunteers. There are currently 9,647 pages on the wiki, and there have been 766,731 edits since the project started. Please help Gentoo by contributing to documentation!&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Finances of the Gentoo Foundation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Income: The Gentoo Foundation took in $12,066 in fiscal year 2025 (ending 2025/06/30); the dominant part (over 80%) consists of individual cash donations from the community. On the SPI side, we received $8,471 in the same period as fiscal year 2025; also here, this is all from small individual cash donations.&lt;/item&gt;
      &lt;item&gt;Expenses: Our expenses in 2025 were, program services (e.g. hosting costs) $8,332, management &amp;amp; general (accounting) $1,724, fundraising $905, and non-operating (depreciation expenses) $10,075.&lt;/item&gt;
      &lt;item&gt;Balance: We have $104,831 in the bank as of July 1, 2025 (which is when our fiscal year 2026 starts for accounting purposes). The Gentoo Foundation FY2025 financial statement is available on the Gentoo Wiki.&lt;/item&gt;
      &lt;item&gt;Transition to SPI: The Foundation encourages donors to ensure their ongoing contributions are going to SPI - more than 40 donors had not responded to requests to move the recurring donations by the end of the year. Expenses will be moved to the SPI structure as ongoing income permits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Thank you!&lt;/head&gt;
    &lt;p&gt;As every year, we would like to thank all Gentoo developers and all who have submitted contributions for their relentless everyday Gentoo work. If you are interested and would like to help, please join us to make Gentoo even better! As a volunteer project, Gentoo could not exist without its community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574769</guid><pubDate>Sun, 11 Jan 2026 11:38:52 +0000</pubDate></item><item><title>BasiliskII Macintosh 68k Emulator Ported to ESP32-P4 / M5Stack Tab5</title><link>https://github.com/amcchord/M5Tab-Macintosh</link><description>&lt;doc fingerprint="f00d63d2cd38cde"&gt;
  &lt;main&gt;
    &lt;p&gt;A full port of the BasiliskII Macintosh 68k emulator to the ESP32-P4 microcontroller, running on the M5Stack Tab5 hardware. This project brings classic Mac OS (System 7.x through Mac OS 8.1) to a portable embedded device with touchscreen input and USB peripheral support.&lt;/p&gt;
    &lt;p&gt;This project runs a Motorola 68040 emulator that can boot real Macintosh ROMs and run genuine classic Mac OS software. The emulation includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CPU: Motorola 68040 emulation with FPU (68881)&lt;/item&gt;
      &lt;item&gt;RAM: Configurable from 4MB to 16MB (allocated from ESP32-P4's 32MB PSRAM)&lt;/item&gt;
      &lt;item&gt;Display: 640Ã—360 virtual display (2Ã— scaled to 1280Ã—720 physical display)&lt;/item&gt;
      &lt;item&gt;Storage: Hard disk and CD-ROM images loaded from SD card&lt;/item&gt;
      &lt;item&gt;Input: Capacitive touchscreen (as mouse) + USB keyboard/mouse support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Tab5 features a unique dual-chip architecture that makes it ideal for this project:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Chip&lt;/cell&gt;
        &lt;cell role="head"&gt;Role&lt;/cell&gt;
        &lt;cell role="head"&gt;Key Features&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ESP32-P4&lt;/cell&gt;
        &lt;cell&gt;Main Application Processor&lt;/cell&gt;
        &lt;cell&gt;400MHz dual-core RISC-V, 32MB PSRAM, MIPI-DSI display&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ESP32-C6&lt;/cell&gt;
        &lt;cell&gt;Wireless Co-processor&lt;/cell&gt;
        &lt;cell&gt;WiFi 6, Bluetooth LE 5.0 (not used by emulator)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Display&lt;/cell&gt;
        &lt;cell&gt;5" IPS TFT, 1280Ã—720 (720p), MIPI-DSI interface&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Touch&lt;/cell&gt;
        &lt;cell&gt;Capacitive multi-touch (ST7123 controller)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;32MB PSRAM for emulated Mac RAM + frame buffers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;microSD card slot for ROM, disk images, and settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;USB&lt;/cell&gt;
        &lt;cell&gt;Type-A host port for keyboard/mouse, Type-C for programming&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Battery&lt;/cell&gt;
        &lt;cell&gt;NP-F550 Li-ion (2000mAh) for portable operation&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See boardConfig.md for detailed pin mappings and hardware documentation.&lt;/p&gt;
    &lt;p&gt;The emulator leverages the ESP32-P4's dual-core RISC-V architecture for optimal performance:&lt;/p&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ESP32-P4 (400MHz)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         CORE 0             â”‚              CORE 1                â”‚
â”‚    (Video &amp;amp; I/O Core)      â”‚       (CPU Emulation Core)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Video rendering task    â”‚  â€¢ 68040 CPU interpreter           â”‚
â”‚  â€¢ 8-bit to RGB565 convert â”‚  â€¢ Memory access emulation         â”‚
â”‚  â€¢ 2Ã—2 pixel scaling       â”‚  â€¢ Interrupt handling              â”‚
â”‚  â€¢ Touch input processing  â”‚  â€¢ ROM patching                    â”‚
â”‚  â€¢ USB HID polling         â”‚  â€¢ Disk I/O                        â”‚
â”‚  â€¢ ~15 FPS refresh rate    â”‚  â€¢ 40,000 instruction quantum      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    32MB PSRAM Allocation                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mac RAM (4-16MB)          â”‚  Configurable via Boot GUI      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mac ROM (~1MB)            â”‚  Q650.ROM or compatible         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mac Frame Buffer (230KB)  â”‚  640Ã—360 @ 8-bit indexed color  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Display Buffer (1.8MB)    â”‚  1280Ã—720 @ RGB565              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Free PSRAM                â”‚  Varies based on RAM selection  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;p&gt;The video system uses an optimized pipeline for converting the Mac's 8-bit indexed framebuffer to the display:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;68040 CPU writes to emulated Mac framebuffer (640Ã—360, 8-bit indexed)&lt;/item&gt;
      &lt;item&gt;Video Task (Core 0) reads framebuffer at ~15 FPS&lt;/item&gt;
      &lt;item&gt;Palette Lookup converts 8-bit indices to RGB565&lt;/item&gt;
      &lt;item&gt;2Ã—2 Scaling doubles pixels horizontally and vertically&lt;/item&gt;
      &lt;item&gt;DMA Transfer pushes 1280Ã—720 RGB565 buffer to MIPI-DSI display&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This port includes the following BasiliskII subsystems, adapted for ESP32:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;File(s)&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;UAE CPU&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;uae_cpu/*.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Motorola 68040 interpreter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ADB&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;adb.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Apple Desktop Bus for keyboard/mouse&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Video&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;video_esp32.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Display driver with 2Ã— scaling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Disk&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;disk.cpp&lt;/code&gt;, &lt;code&gt;sys_esp32.cpp&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;HDD image support via SD card&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CD-ROM&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;cdrom.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;ISO image mounting&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;XPRAM&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;xpram_esp32.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Non-volatile parameter RAM&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Timer&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;timer_esp32.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;60Hz/1Hz tick generation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ROM Patches&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rom_patches.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Compatibility patches for ROMs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Input&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;input_esp32.cpp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Touch + USB HID handling&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The emulator works best with Macintosh Quadra series ROMs:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;ROM File&lt;/cell&gt;
        &lt;cell role="head"&gt;Machine&lt;/cell&gt;
        &lt;cell role="head"&gt;Recommended&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;Q650.ROM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quadra 650&lt;/cell&gt;
        &lt;cell&gt;âœ… Best compatibility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;Q700.ROM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quadra 700&lt;/cell&gt;
        &lt;cell&gt;âœ… Good&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;Q800.ROM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quadra 800&lt;/cell&gt;
        &lt;cell&gt;âœ… Good&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;68030-IIci.ROM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mac IIci&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;OS Version&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;System 7.1&lt;/cell&gt;
        &lt;cell&gt;âœ… Works&lt;/cell&gt;
        &lt;cell&gt;Lightweight, fast boot&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;System 7.5.x&lt;/cell&gt;
        &lt;cell&gt;âœ… Works&lt;/cell&gt;
        &lt;cell&gt;Good compatibility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Mac OS 8.0&lt;/cell&gt;
        &lt;cell&gt;âœ… Works&lt;/cell&gt;
        &lt;cell&gt;Full-featured&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Mac OS 8.1&lt;/cell&gt;
        &lt;cell&gt;âœ… Works&lt;/cell&gt;
        &lt;cell&gt;Latest supported&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hardware: M5Stack Tab5&lt;/item&gt;
      &lt;item&gt;Software: PlatformIO (CLI or IDE extension)&lt;/item&gt;
      &lt;item&gt;SD Card: FAT32 formatted microSD card (8GB+ recommended)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Download a ready-to-use SD card image with Mac OS pre-installed:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Format your microSD card as FAT32&lt;/item&gt;
      &lt;item&gt;Extract the ZIP contents to the root of the SD card&lt;/item&gt;
      &lt;item&gt;Insert into Tab5 and boot&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Alternatively, create your own setup with these files in the SD card root:&lt;/p&gt;
    &lt;code&gt;/
â”œâ”€â”€ Q650.ROM              # Macintosh Quadra ROM (required)
â”œâ”€â”€ Macintosh.dsk         # Hard disk image (required)
â”œâ”€â”€ System753.iso         # Mac OS installer CD (optional)
â””â”€â”€ DiskTools1.img        # Boot floppy for installation (optional)
&lt;/code&gt;
    &lt;p&gt;To create a blank disk image:&lt;/p&gt;
    &lt;code&gt;# Create a 500MB blank disk image
dd if=/dev/zero of=Macintosh.dsk bs=1M count=500&lt;/code&gt;
    &lt;p&gt;Then format it during Mac OS installation.&lt;/p&gt;
    &lt;p&gt;Download the latest release from GitHub:&lt;/p&gt;
    &lt;p&gt;Flash using &lt;code&gt;esptool.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Install esptool if you don't have it
pip install esptool

# Flash all three binary files (connect Tab5 via USB-C)
esptool.py --chip esp32p4 --port /dev/ttyACM0 --baud 921600 \
    write_flash \
    0x0 bootloader.bin \
    0x10000 firmware.bin \
    0x8000 partitions.bin&lt;/code&gt;
    &lt;p&gt;Note: Replace &lt;code&gt;/dev/ttyACM0&lt;/code&gt; with your actual port:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS: &lt;code&gt;/dev/cu.usbmodem*&lt;/code&gt;or&lt;code&gt;/dev/tty.usbmodem*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Windows: &lt;code&gt;COM3&lt;/code&gt;(or similar)&lt;/item&gt;
      &lt;item&gt;Linux: &lt;code&gt;/dev/ttyACM0&lt;/code&gt;or&lt;code&gt;/dev/ttyUSB0&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/amcchord/M5Tab-Macintosh.git
cd M5Tab-Macintosh

# Build the firmware
pio run

# Upload to device (connect via USB-C)
pio run --target upload

# Monitor serial output
pio device monitor&lt;/code&gt;
    &lt;p&gt;On startup, a classic Mac-style boot configuration screen appears:&lt;/p&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BasiliskII                    â”‚
â”‚        Starting in 3...                 â”‚
â”‚                                         â”‚
â”‚    Disk: Macintosh.dsk                  â”‚
â”‚    RAM: 8 MB                            â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚       Change Settings           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3-second countdown to auto-boot with saved settings&lt;/item&gt;
      &lt;item&gt;Tap to configure disk images, CD-ROMs, and RAM size&lt;/item&gt;
      &lt;item&gt;Settings persistence saved to &lt;code&gt;/basilisk_settings.txt&lt;/code&gt;on SD card&lt;/item&gt;
      &lt;item&gt;Touch-friendly large buttons designed for the 5" touchscreen&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Setting&lt;/cell&gt;
        &lt;cell role="head"&gt;Options&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hard Disk&lt;/cell&gt;
        &lt;cell&gt;Any &lt;code&gt;.dsk&lt;/code&gt; or &lt;code&gt;.img&lt;/code&gt; file on SD root&lt;/cell&gt;
        &lt;cell&gt;First found&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CD-ROM&lt;/cell&gt;
        &lt;cell&gt;Any &lt;code&gt;.iso&lt;/code&gt; file on SD root, or None&lt;/cell&gt;
        &lt;cell&gt;None&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;RAM Size&lt;/cell&gt;
        &lt;cell&gt;4 MB, 8 MB, 12 MB, 16 MB&lt;/cell&gt;
        &lt;cell&gt;8 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The capacitive touchscreen acts as a single-button mouse:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tap = Click&lt;/item&gt;
      &lt;item&gt;Drag = Click and drag&lt;/item&gt;
      &lt;item&gt;Coordinates are scaled from 1280Ã—720 display to 640Ã—360 Mac screen&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Connect a USB keyboard to the USB Type-A port. Supported features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full QWERTY layout with proper Mac key mapping&lt;/item&gt;
      &lt;item&gt;Modifier keys: Command (âŒ˜), Option (âŒ¥), Control, Shift&lt;/item&gt;
      &lt;item&gt;Function keys F1-F15&lt;/item&gt;
      &lt;item&gt;Arrow keys and navigation cluster&lt;/item&gt;
      &lt;item&gt;Numeric keypad&lt;/item&gt;
      &lt;item&gt;Caps Lock LED sync with Mac OS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Connect a USB mouse for relative movement input:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Left, right, and middle button support&lt;/item&gt;
      &lt;item&gt;Relative movement mode (vs. absolute for touch)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;M5Tab-Macintosh/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.cpp                    # Application entry point
â”‚   â””â”€â”€ basilisk/                   # BasiliskII emulator core
â”‚       â”œâ”€â”€ main_esp32.cpp          # Emulator initialization &amp;amp; main loop
â”‚       â”œâ”€â”€ video_esp32.cpp         # Display driver (2Ã— scaling, RGB565)
â”‚       â”œâ”€â”€ input_esp32.cpp         # Touch + USB HID input handling
â”‚       â”œâ”€â”€ boot_gui.cpp            # Pre-boot configuration GUI
â”‚       â”œâ”€â”€ sys_esp32.cpp           # SD card disk I/O
â”‚       â”œâ”€â”€ timer_esp32.cpp         # 60Hz/1Hz interrupt generation
â”‚       â”œâ”€â”€ xpram_esp32.cpp         # NVRAM persistence to SD
â”‚       â”œâ”€â”€ prefs_esp32.cpp         # Preferences loading
â”‚       â”œâ”€â”€ uae_cpu/                # Motorola 68040 CPU emulator
â”‚       â”‚   â”œâ”€â”€ newcpu.cpp          # Main CPU interpreter loop
â”‚       â”‚   â”œâ”€â”€ memory.cpp          # Memory banking &amp;amp; access
â”‚       â”‚   â””â”€â”€ generated/          # CPU instruction tables
â”‚       â””â”€â”€ include/                # Header files
â”œâ”€â”€ platformio.ini                  # PlatformIO build configuration
â”œâ”€â”€ partitions.csv                  # ESP32 flash partition table
â”œâ”€â”€ boardConfig.md                  # Hardware documentation
â””â”€â”€ scripts/                        # Build helper scripts
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CPU Quantum&lt;/cell&gt;
        &lt;cell&gt;40,000 instructions per tick&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Video Refresh&lt;/cell&gt;
        &lt;cell&gt;~15 FPS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Boot Time&lt;/cell&gt;
        &lt;cell&gt;~15 seconds to Mac OS desktop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Responsiveness&lt;/cell&gt;
        &lt;cell&gt;Usable for productivity apps&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Dual-core separation: CPU emulation and video rendering run independently&lt;/item&gt;
      &lt;item&gt;Large instruction quantum: Fewer context switches = faster emulation&lt;/item&gt;
      &lt;item&gt;Direct framebuffer access: No intermediate copies&lt;/item&gt;
      &lt;item&gt;Optimized 4-pixel batch processing: Reduced loop overhead in scaling&lt;/item&gt;
      &lt;item&gt;Polling-based interrupts: Safer than async timers for stability&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key build flags in &lt;code&gt;platformio.ini&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;build_flags =
    -O2                          # Optimize for speed
    -DEMULATED_68K=1             # Use 68k interpreter
    -DREAL_ADDRESSING=0          # Use memory banking
    -DROM_IS_WRITE_PROTECTED=1   # Protect ROM from writes
    -DFPU_IEEE=1                 # IEEE FPU emulation&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Problem&lt;/cell&gt;
        &lt;cell role="head"&gt;Solution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;"SD card initialization failed"&lt;/cell&gt;
        &lt;cell&gt;Ensure SD card is FAT32, properly seated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;"Q650.ROM not found"&lt;/cell&gt;
        &lt;cell&gt;Place ROM file in SD card root directory&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Black screen after boot&lt;/cell&gt;
        &lt;cell&gt;Check serial output for errors; verify ROM compatibility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Touch not responding&lt;/cell&gt;
        &lt;cell&gt;Wait for boot GUI to complete initialization&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;USB keyboard not working&lt;/cell&gt;
        &lt;cell&gt;Connect to Type-A port (not Type-C)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Slow/choppy display&lt;/cell&gt;
        &lt;cell&gt;Normal; emulator runs at ~15 FPS&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Connect via USB-C and use:&lt;/p&gt;
    &lt;code&gt;pio device monitor&lt;/code&gt;
    &lt;p&gt;Look for initialization messages:&lt;/p&gt;
    &lt;code&gt;========================================
  BasiliskII ESP32 - Macintosh Emulator
  Dual-Core Optimized Edition
========================================

[MAIN] Free heap: 473732 bytes
[MAIN] Free PSRAM: 31676812 bytes
[MAIN] Total PSRAM: 33554432 bytes
[MAIN] CPU Frequency: 360 MHz
[MAIN] Running on Core: 1
[PREFS] Loading preferences...
[PREFS] RAM: 16 MB
[PREFS] Disk: /Macintosh8.dsk (read-write)
[PREFS] CD-ROM: None
[PREFS] Preferences loaded
[SYS] SD card should already be initialized by main.cpp
[MAIN] Allocating 16777216 bytes for Mac RAM...
[MAIN] Mac RAM allocated at 0x481ca674 (16777216 bytes)
[MAIN] Loading ROM from: /Q650.ROM
[MAIN] ROM file size: 1048576 bytes
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BasiliskII by Christian Bauer and contributors â€” the original open-source 68k Mac emulator&lt;/item&gt;
      &lt;item&gt;UAE (Unix Amiga Emulator) â€” the CPU emulation core&lt;/item&gt;
      &lt;item&gt;M5Stack â€” for the excellent Tab5 hardware and M5Unified/M5GFX libraries&lt;/item&gt;
      &lt;item&gt;EspUsbHost â€” USB HID support for ESP32&lt;/item&gt;
      &lt;item&gt;Claude Opus 4.5 (Anthropic) â€” AI pair programmer that made this port possible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is based on BasiliskII, which is licensed under the GNU General Public License v2.&lt;/p&gt;
    &lt;p&gt;This project was built with the assistance of Claude Opus 4.5. I am in no way smart enough to have done this on my own. ğŸ¤–ğŸ&lt;/p&gt;
    &lt;p&gt;Run classic Mac OS in your pocket.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46574961</guid><pubDate>Sun, 11 Jan 2026 12:02:52 +0000</pubDate></item><item><title>Google: Don't make "bite-sized" content for LLMs</title><link>https://arstechnica.com/google/2026/01/google-dont-make-bite-sized-content-for-llms-if-you-care-about-search-rank/</link><description>&lt;doc fingerprint="b2c3f196d3a20af3"&gt;
  &lt;main&gt;
    &lt;p&gt;Search engine optimization, or SEO, is a big business. While some SEO practices are useful, much of the day-to-day SEO wisdom you see online amounts to superstition. An increasingly popular approach geared toward LLMs called â€œcontent chunkingâ€ may fall into that category. In the latest installment of Googleâ€™s Search Off the Record podcast, John Mueller and Danny Sullivan say that breaking content down into bite-sized chunks for LLMs like Gemini is a bad idea.&lt;/p&gt;
    &lt;p&gt;Youâ€™ve probably seen websites engaging in content chunking and scratched your head, and for good reasonâ€”this content isnâ€™t made for you. The idea is that if you split information into smaller paragraphs and sections, it is more likely to be ingested and cited by generative AI bots like Gemini. So you end up with short paragraphs, sometimes with just one or two sentences, and lots of subheds formatted like questions one might ask a chatbot.&lt;/p&gt;
    &lt;p&gt;According to Sullivan, this is a misconception, and Google doesnâ€™t use such signals to improve ranking. â€œOne of the things I keep seeing over and over in some of the advice and guidance and people are trying to figure out what do we do with the LLMs or whatever, is that turn your content into bite-sized chunks, because LLMs like things that are really bite size, right?â€ said Sullivan. â€œSoâ€¦ we donâ€™t want you to do that.â€&lt;/p&gt;
    &lt;p&gt;The conversation, which begins around the podcastâ€™s 18-minute mark, illustrates the folly of jumping on the latest SEO trend. Sullivan notes that he has consulted engineers at Google before making this proclamation. Apparently, the best way to rank on Google continues to be creating content for humans rather than machines. That ensures long-term search exposure, because the behavior of human beingsâ€”what they choose to click onâ€”is an important signal for Google.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46575127</guid><pubDate>Sun, 11 Jan 2026 12:22:05 +0000</pubDate></item><item><title>Iran Shuts Down Starlink Internet for First Time</title><link>https://www.forbes.com/sites/zakdoffman/2026/01/11/kill-switch-iran-shuts-down-starlink-internet-for-first-time/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46575224</guid><pubDate>Sun, 11 Jan 2026 12:37:37 +0000</pubDate></item><item><title>Happy 50th Birthday KIM-1</title><link>https://github.com/netzherpes/KIM1-Demo</link><description>&lt;doc fingerprint="3813b24053056cf4"&gt;
  &lt;main&gt;
    &lt;p&gt;A small but heartfelt demo celebrating the 50th birthday of the legendary MOS KIM-1 ğŸ–¥ï¸âœ¨&lt;/p&gt;
    &lt;p&gt;The KIM-1 first became available in January 1976 â€”&lt;lb/&gt; three months before the Apple I ğŸ and one month after its sibling, the TIM.&lt;lb/&gt; An incredible milestone in early microcomputer history!&lt;/p&gt;
    &lt;p&gt;For this demo, Iâ€™ve gathered and connected a few components that were scattered across my repositories ğŸ§©.&lt;lb/&gt; The goal is not just to look back, but to celebrate, experiment, and build together.&lt;/p&gt;
    &lt;p&gt;I warmly invite fellow retro-computing enthusiasts and comrades-in-arms ğŸ¤&lt;lb/&gt; to jump in, contribute ideas, add modules, demos, or improvements, and help this project grow.&lt;/p&gt;
    &lt;p&gt;Letâ€™s keep the spirit of early computing alive ğŸš€&lt;/p&gt;
    &lt;p&gt;ğŸ‰ HAPPY BIRTHDAY, KIM-1! ğŸ‰&lt;lb/&gt; Wishing you â€” and all of us â€” a fantastic and hacky Year 2026 ğŸ¥³âœ¨&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;kim-1_demo.mp4&lt;/head&gt;
    &lt;p&gt;Things that are very useful in this code:&lt;/p&gt;
    &lt;p&gt;Take any coordinates in HEX out of the memory and use them to place your cursor. The problem is, that to position your cursur, you need to send the x/y coordinates as single chars to the terminal program, like (ESC)[xx;yyH - Imagine just having hex data, i.e. $20 (32 dec) and you need to send a 3 and a 2 separated to your terminal... This routine will do it - seperate the tens from the ones. Now you can like draw a rectangle, a circle or whatever. You can start a painting program if you like.&lt;/p&gt;
    &lt;code&gt;; ANSI Cursor positionieren (Row ; Col)
GOTOXY:
          LDA #$1B      ; ESC
          JSR CHOUT
          LDA #$5B      ; '['
          JSR CHOUT
          
          LDA CURY      ; Row zuerst
          JSR PUTDEC
          
          LDA #$3B      ; ';'
          JSR CHOUT
          
          LDA CURX      ; Column danach
          JSR PUTDEC
          
          LDA #$48      ; 'H'
          JSR CHOUT
          RTS

; Dezimalzahl ausgeben (A-Register, 0-99)
; Benutzt TEMP als temporÃ¤re Variable
PUTDEC:
          STA TEMP      ; Wert sichern
          LDY #0        ; Zehner-ZÃ¤hler
          
PUTDEC_T: CMP #10
          BCS PUTDEC_S  ; &amp;gt;= 10
          JMP PUTDEC_D
PUTDEC_S: SEC
          SBC #10
          INY
          JMP PUTDEC_T
          
PUTDEC_D: ; A enthÃ¤lt Einer
          TAX           ; Einer nach X retten
          
          TYA           ; Zehner
          BNE PUTDEC_Z  ; Wenn nicht 0
          JMP PUTDEC1
PUTDEC_Z: CLC
          ADC #$30      ; In ASCII umwandeln
          JSR CHOUT
          
PUTDEC1:  TXA           ; Einer zurÃ¼ck
          CLC
          ADC #$30      ; In ASCII umwandeln
          JSR CHOUT
          
          LDA TEMP      ; Original wiederherstellen
          RTS
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46575804</guid><pubDate>Sun, 11 Jan 2026 13:55:40 +0000</pubDate></item></channel></rss>