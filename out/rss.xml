<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 13 Sep 2025 02:07:52 +0000</lastBuildDate><item><title>The treasury is expanding the Patriot Act to attack Bitcoin self custody</title><link>https://www.tftc.io/treasury-iexpanding-patriot-act/</link><description>&lt;doc fingerprint="365d59be7c351fbd"&gt;
  &lt;main&gt;
    &lt;p&gt;We shouldn't have to cater to the lowest common denominator.&lt;/p&gt;
    &lt;p&gt;We warned a couple of months ago when the Trump administration's "Crypto Brief" was released that there was some language in the brief that advised the government to expand the Patriot Act to account for digital assets. Well, it looks like FinCen and the Treasury have been working on guidelines and a rough outline is shared above courtesy of The Rage, and they are absolutely horrid.&lt;/p&gt;
    &lt;p&gt;It seems that FinCen and the Treasury are preparing to outlaw the use of CoinJoin, atomic swaps, single address use, and transaction broadcast timing delays. All of which are common best use practices that I would recommend any bitcoiner leveraging self-custody practice. This is an all out attack on financial privacy within bitcoin. If enacted, any user who leverages these tools will be flagged as a suspicious, any attempts to send a UTXO that has touched any of these tools will be rejected by regulated services, and could potentially be sent to prison.&lt;/p&gt;
    &lt;p&gt;This is an absurd affront to common sensibilities and freedom in the digital age. The fact that they want to prevent people from using single addresses for individual UTXOs is patently absurd. Not only is it a massive infringement on privacy, but it makes bitcoin usage less economically efficient and degrades the security of every bitcoiner. Loading up a single address with too many UTXOs degrades the entropy of a public-private key pair and makes it easier to brute force a user's private key.&lt;/p&gt;
    &lt;p&gt;Instead of expanding the Patriot Act, it should be abolished. Instead of trying to eliminate financial privacy for the 99.9% of law abiding citizens in this country, the government should be actively trying to foster an environment in which it can be improved. The proposed solutions will do nothing but put good Americans in harm's way and degrade the security of their savings.&lt;/p&gt;
    &lt;p&gt;We shouldn't have to live in a world where standards cater to the lowest common denominator, in this case criminals, and make things worse off for the overwhelming majority of the population. It's crazy that this even has to be said. The onus is on law enforcement to be so good at their jobs that they are able to prevent crimes from happening before they occur and effectively bring criminals to heel after they commit crimes. It shouldn't be on a neutral protocol and the industry being built on top of it that, when used effectively, provides people with a stable monetary system that respects user privacy and equips them with the tools to receive and spend in a way that provides them with peace of mind.&lt;/p&gt;
    &lt;p&gt;Why should everyone have to suffer because of a few bad apples? Isn't that letting the terrorist win?&lt;/p&gt;
    &lt;p&gt;Mel Mattison revealed a fascinating shift in Bitcoin's market dynamics that challenges conventional crypto wisdom. He pointed out that Bitcoin futures now exhibit lower volatility than platinum futures - a remarkable transformation for an asset once synonymous with wild price swings. The proliferation of ETFs, options, futures, and other traditional financial instruments has fundamentally altered Bitcoin's behavior, creating what Mel calls "volatility suppression." This institutionalization comes with trade-offs: while reducing dramatic downswings, it also caps explosive upside potential.&lt;/p&gt;
    &lt;quote&gt;"Bitcoin is becoming a TradFi security instrument and it's getting TradFi vol." - Mel Mattison&lt;/quote&gt;
    &lt;p&gt;Mel argued that the relationship between volatility and returns means investors must recalibrate expectations. Where 100% annual gains once seemed routine, he now considers 50% returns "massive" for this new era of Bitcoin. This maturation reflects Bitcoin's evolution from speculative experiment to financial infrastructure - less exciting perhaps, but ultimately more sustainable for long-term adoption.&lt;/p&gt;
    &lt;p&gt;Check out the full podcast here for more on China's gold strategy, Fed independence battles, and housing market manipulation plans.&lt;/p&gt;
    &lt;p&gt;New Bill for Strategic Bitcoin Reserve - via X&lt;/p&gt;
    &lt;p&gt;SEC to Host Crypto Roundtable October 17 - via X&lt;/p&gt;
    &lt;p&gt;Research Proposes Bitcoin for Mars Trade Standard - via X&lt;/p&gt;
    &lt;p&gt;Tom Honzik has helped 1,000+ people secure more than 5,000 BTC. Now, TFTC and Unchained are teaming up for a live online session on bitcoin custody.What you’ll learn:&lt;/p&gt;
    &lt;p&gt;Stick around for the AMA to ask Tom Honzik and Marty Bent anything—from privacy considerations to the tradeoffs of different multisig quorums.&lt;/p&gt;
    &lt;p&gt;Created by Carl Dong (former Bitcoin Core contributor), unlike other VPNs, it can’t log your activity by design, delivering verifiable privacy you can trust.&lt;/p&gt;
    &lt;p&gt;Outsmarts internet censorship: works even on the most restrictive Wi-Fi networks where other VPNs fail.&lt;lb/&gt;Pay with bitcoin over Lightning: better privacy and low fees.&lt;lb/&gt;No email required: accounts are generated like bitcoin wallets.&lt;lb/&gt;No trade-offs: browse freely with fast, reliable speeds.&lt;/p&gt;
    &lt;p&gt;Exclusive Deal for TFTC Listeners:&lt;lb/&gt;Sign up at obscura.net and use code TFTC25 for 25% off your first 12 months.&lt;/p&gt;
    &lt;p&gt;Now available on macOS, iOS, and WireGuard, with more platforms coming soon — so your privacy travels with you wherever you go.&lt;/p&gt;
    &lt;p&gt;Ten31, the largest bitcoin-focused investor, has deployed $200M across 30+ companies through three funds. I am a Managing Partner at Ten31 and am very proud of the work we are doing. Learn more at ten31.vc/invest.&lt;/p&gt;
    &lt;p&gt;Final thought...&lt;/p&gt;
    &lt;p&gt;Rest in peace, Charlie Kirk. Pray for humanity and for peace.&lt;/p&gt;
    &lt;p&gt;Download our free browser extension, Opportunity Cost: https://www.opportunitycost.app/ start thinking in SATS today.&lt;/p&gt;
    &lt;p&gt;Get this newsletter sent to your inbox daily: https://www.tftc.io/bitcoin-brief/&lt;/p&gt;
    &lt;p&gt;Subscribe to our YouTube channels and follow us on Nostr and X:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45221274</guid></item><item><title>3D modeling with paper</title><link>https://www.arvinpoddar.com/blog/3d-modeling-with-paper</link><description>&lt;doc fingerprint="bd5add43313c429e"&gt;
  &lt;main&gt;
    &lt;p&gt;August 31, 2025&lt;/p&gt;
    &lt;head rend="h1"&gt;3D Modeling with Paper&lt;/head&gt;
    &lt;p&gt;Over the past several years, I've enjoyed the hobby of paper modeling (or papercraft), the art of creating 3D models from cut and glued parts from paper sheets. This hobby is a superset of origami, in that it allows for cutting and gluing, as well as for multiple sheets of paper for a single model. The alleviation of these constraints means that papercraft allows for more complex models that are easier to assemble.&lt;/p&gt;
    &lt;p&gt;Over many years, I've built models designed by others as well as designed my own. In this post, I want to share everything I've learned along the way, covering the entire process from design to assembly.&lt;/p&gt;
    &lt;p&gt;I love this hobby for three reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It is extremely accessible. There is no fancy hardware or software involved. As we'll see, the core tools are paper, scissors, and glue; everything else is an addon to make the experience better. All software tools can be free. Accidentally messed up during assembly and need a replacement part? Just print out another page. The entire creation of a model can be done in the ballpark of a few cents.&lt;/item&gt;
      &lt;item&gt;It is equally technical and creative. As we'll see, many of the problems faced in papercraft require an engineering-like approach and a willingness to experiment and iterate on designs. While it may appear outwardly like a craft project, the end-to-end process involves constraints and optimizing within them.&lt;/item&gt;
      &lt;item&gt;There's no limits on what you can make. What you decide to build is limited by your patience and imagination. Theoretically, nearly any object can be represented as a paper model.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's dive in. My most recent model is a papercraft plane inspired by the SR-71 Blackbird, a reconnaissance plane that to this day holds many records for being one of the fastest aircrafts ever. It's now one of most iconic planes ever designed and an engineering masterpiece. The program was ultimately retired in 1999.&lt;/p&gt;
    &lt;p&gt;We're going to walk through the full model design and assembly process, while referencing specific examples I encountered during creating this SR-71.&lt;/p&gt;
    &lt;head rend="h2"&gt;Constraints#&lt;/head&gt;
    &lt;p&gt;Let's set some constraints for how we're allowed to model our creation. These are self-imposed limitations that fit my preferred-style for model design:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All parts in the assembled model must be made of paper.&lt;/item&gt;
      &lt;item&gt;Each part must be a single, solid color. The parts must not use any printed textures or designs.&lt;/item&gt;
      &lt;item&gt;The model must be represented as a simple polyhedron. There may be no curvatures, holes, two-dimensional surfaces, or surface-to-surface contact. If the figure we're trying to capture has any of these features, we must find a way to approximate it using only flat faces. The object must be manifold (an edge is only shared by 2 faces).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why constraints?#&lt;/head&gt;
    &lt;p&gt;It may feel weird to impose constraints on an art. However, I find that these constraints encourage a better designed model that can be assembled easily and predictably, including by others.&lt;/p&gt;
    &lt;p&gt;Using features like curvatures, printing with textures, etc. are shortcuts. For example, printing textures helps fill in details that aren't captured inherently by the model; curvatures and 2d surfaces are flimsy and introduce variances in how a model can be assembled. Simply polyhedral designs with single color parts ensure that the 3D form itself captures the object being depicted, and can be assembled in a structurally sound, predictable way.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals#&lt;/head&gt;
    &lt;p&gt;In addition to constraints, we also have some goals that we're optimzing for. These goals will be considered in each step of our design process.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ease of assembly: By far the most important goal, our model should be easy to put together. Given the nature of paper and glue, a model that is difficult to assemble will almost certainly look bad. A model can have a well-designed topology, but still be difficult to assemble based on the parts design we put together.&lt;/item&gt;
      &lt;item&gt;Aesthetic appeal: This is an art, after all. The model we design should be aesthetically pleasing and resemble the object of interest.&lt;/item&gt;
      &lt;item&gt;Minimal consumption of resources: We should aim to minimize waste and use our materials efficiently.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As in engineering, we have to consider trade-offs between these goals, and optimize for these goals within our constraints.&lt;/p&gt;
    &lt;head rend="h2"&gt;Steps#&lt;/head&gt;
    &lt;p&gt;The process of designing a paper model is iterative. Each iteration consists of the following steps:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Mesh modeling - using software to create a 3D polyhedron mesh of our desired form&lt;/item&gt;
      &lt;item&gt;Mesh unfolding - unfolding the mesh into a 2D layout of parts&lt;/item&gt;
      &lt;item&gt;Assembly - putting the parts together to create the final model&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The remainder of this article will be walking through each step in detail. The discussion of each step will be centered around the goals and constraints declared from above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mesh Modeling#&lt;/head&gt;
    &lt;p&gt;Related goals: Ease of assembly, aesthetic appeal&lt;/p&gt;
    &lt;p&gt;In this phase, we design the mesh for our model. We aim to capture the essence of an object in a way that can feasibly be built with paper. Depending on how you approach this, this can easily be the most complicated step.&lt;/p&gt;
    &lt;p&gt;What do I mean by "feasibly built with paper"? Our mesh is a collection of polygons that represent a 3D object. The closeness of that representation is largely determined by how many polygons we use. We could use many really small polygons to closely match the subtle curves of our plane, but this would be hard to assemble in reality. Alternatively, we could simplifiy our representation down to a triangular pyramid. This would be trivially easy to assemble, but it wouldn't look a lot like our plane.&lt;/p&gt;
    &lt;p&gt;We can now see that our goals of ease of assembly and aesthetic appeal are at odds. Imagine that we have a continuum, where on the left we have a triangular pyramid (the simplest possible polyhedron) and on the right we have a mesh of the SR-71 with an arbitrarily high number (millions) of polygons.&lt;/p&gt;
    &lt;p&gt;Generally, an "easy" to assemble model will have somewhere around a few hundred polygons. Thus, our ideal model exists somewhere on the far left of this spectrum.&lt;/p&gt;
    &lt;p&gt;The challenge here is what I call "allocation of resolution" - we have a finite number of polygons to distribute across the features of our object. Certain features will naturally require more polygons to be accurately captured than others. For example, curved features require more polygons than flat features - in this model, the cylindrical engines will require more detail, than say, the flat wings.&lt;/p&gt;
    &lt;p&gt;In addition to the number of polygons and their concentrations, the arrangement of the polygons themselves matters - this is the topology of the mesh. Most discourse on 3D mesh topology is related to shading and animation. For our purposes, we're considered with ease of assembly. Certain topologies are easier to assemble and more structurally sound. Generally, here's some positive topological qualities for papercraft:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Symmetries: a good mesh design is symetrical when possible. Symmetrical shapes are intuitive and easier to reason about when assembling.&lt;/item&gt;
      &lt;item&gt;No narrow shapes: really narrow shapes are hard to cut out, hard to fold, and hard to glue. Avoid them at all costs.&lt;/item&gt;
      &lt;item&gt;Use quads: quad faces have an aesthetic appeal to them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If all of this is sounding hard, we've got some options, in increasing order of difficulty:&lt;/p&gt;
    &lt;head rend="h3"&gt;Easy: Use an existing mesh#&lt;/head&gt;
    &lt;p&gt;The easiest way past this step is to find an existing mesh. There's a whole genre of 3D modeling called "low-poly" that you can find with a quick search on Thingiverse or Printables. These are usually designed for video games or 3D printing, but can be taken up for papercraft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medium: Converting an existing mesh#&lt;/head&gt;
    &lt;p&gt;Sometimes, you can find a high-resolution mesh of your desired object, but not a low-poly one. In this case, there are tools available to reduce the polygon count while preserving the overall shape. This is called "mesh simplification" or "mesh decimation."&lt;/p&gt;
    &lt;p&gt;This Instructable goes over the process of doing this with Meshlab, but there's many other software alternatives out there.&lt;/p&gt;
    &lt;p&gt;The pitfall of this approach is that automatic mesh decimation typically results in some nasty topologies, and there's not a lot you can do to control the output. To get around this, we could add an additional refinement step where we take the raw decimated mesh output and "clean it up" using a mesh editor software.&lt;/p&gt;
    &lt;p&gt;As an example, let's try this with a SR-71 mesh on Thingiverse. The original mesh has more than 1.2 million faces, and we're going to try decimating down to ~1,000. Here's what we get from Meshlab:&lt;/p&gt;
    &lt;p&gt;In this case, the output is not usable - it's wildly asymetric and is full of self-intersections. Refining this topology would take just as long (if not longer) as creating a model from scratch.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hard: Creating your own mesh#&lt;/head&gt;
    &lt;p&gt;The most difficult option is to create your own mesh from scratch. This option gives you full control over the design, and is what I chose for the SR-71 model.&lt;/p&gt;
    &lt;p&gt;My software of choice for this is Blender. Blender has a steep learning curve, but the type of mesh design we're doing for this project doesn't begin to scratch the surface of its full capabilities. I highly recommend this low-poly tutorial if you've never used Blender before and need somewhere to start. Two things I found very handy were the mirror modifier to enforce symmetry, and the 3D Print Toolbox to auto-cleanup the mesh and check for manifoldness.&lt;/p&gt;
    &lt;p&gt;This process is very tedious. My advice here is: simplify your mesh to the point where you feel uncomfortable. Recall that we're largely optimizing for ease of assembly. When modeling, it's very tempting to capture finer details, but fine details have costs (small parts, hard to glue regions, etc.) that are not worth it during the assembly phase. Scrutinize every feature, and zoom out once in a while. When you zoom out, your omissions won't feel as weird.&lt;/p&gt;
    &lt;p&gt;After many days, here's the initial mesh I created. It contains 732 triangles. Note the symmetry along the y-axis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mesh Unfolding#&lt;/head&gt;
    &lt;p&gt;Related goals: Ease of assembly, minimal consumption of resources&lt;/p&gt;
    &lt;p&gt;Once we have a mesh, we have to convert it into a 2D template of parts that can be printed and assembled. This process is called unfolding. Each of the faces of our mesh are grouped into parts, and the arrangement of our parts is a layout, or template.&lt;/p&gt;
    &lt;p&gt;To do this, we're going to turn to software again. The most popular unfolding tool (and my favorite) is Pepakura Designer. Pepakura is not free (at the time of this writing, it's a one time $70 purchase) and it only runs on Windows. There's also Unfolder for Mac, which is $30. If you can't use either of these, Blender can save the day again with its free Paper Model plugin.&lt;/p&gt;
    &lt;p&gt;I believe that the unfolding step is one that does not get as much attention as it deserves. There is a noticable difference between a good template and a bad one. A good template has parts that make intuitive sense, with logical groupings and clear flow. The faces themselves are grouped into parts that are easy to cut out and handle. All of this equates to a better building experience, which means a better looking model.&lt;/p&gt;
    &lt;p&gt;Part of unfolding is also deciding the scale of your model. You can make your model as big or small as you want, but again, ease of assembly should be top of mind when deciding. A model that's too small will end up with parts that are hard to cut out and fold. Bigger models are easier to assemble, but you're limited to the point where the faces of your model must fit on a page.&lt;/p&gt;
    &lt;p&gt;I ended up making this model 25 inches long. With the original SR-71 being about 107 feet long, this puts our model at around a 1:50 ratio.&lt;/p&gt;
    &lt;head rend="h3"&gt;Creating many parts#&lt;/head&gt;
    &lt;p&gt;Let's start off with the creation of parts. In most unfolding software, the software will auto-unfold for you, and from there you can regroup faces into whatever parts you want. Here's Pepakura's auto unfold:&lt;/p&gt;
    &lt;p&gt;The parts it generated are pretty complicated, so we have some work to do.&lt;/p&gt;
    &lt;p&gt;If you have a mesh with faces, you can have anywhere from 1 (all the faces in a single part) to total parts (each part is a single face). We want our model to be easy to assemble, and neither of these extremes are easy.&lt;/p&gt;
    &lt;p&gt;Rather than trying to fix the number of parts and going from there, I recommend creating parts that are logical. Identify features that can be captured in a single part, and go from there. For example, in the SR-71, each engine intake spike makes sense as a single part. So does the nose cone.&lt;/p&gt;
    &lt;p&gt;If your mesh has an axis of symmetry, then your parts have symmetrical pairings as well. The same feature on either side of the axis should be represented with a mirrored part. In the SR-71, the entire plane is symmetrical on the vertical axis, so all parts across this axis are mirrored. This is good because once someone builds one side, they can more easily reason about the other side.&lt;/p&gt;
    &lt;p&gt;I ended up dividing this model into 42 parts. These parts were carefully divided in such a way that I felt would make them easier to assemble. If you look at any part in particular, chances are it'll have a symmetric counterpart.&lt;/p&gt;
    &lt;p&gt;They're arranged pretty haphazardly right now, but we'll cleanup this up in the next step.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arranging the parts#&lt;/head&gt;
    &lt;p&gt;Again, most software will automatically arrange the parts for you as part of unfolding. Here's the 14 page arrangement Pepakura decided for the parts I created:&lt;/p&gt;
    &lt;p&gt;I highlighted all the parts on the first two pages so you can see where the are on the finished model. Notice that they're scattered throughout different sections. That's why I typically don't like auto-arrangement - they're designed to minimize paper usage, but they often result in a less intuitive assembly process. You can't look at any particular page and loosely know where its parts will go.&lt;/p&gt;
    &lt;p&gt;A good part layout reads like a story. Parts are arranged in a logical order, with related parts grouped together. I like to arrange mine left to right, top to bottom on a page. Here's my layout, with the first two pages highlighted.&lt;/p&gt;
    &lt;p&gt;All the parts that are near each other in the layout are also near each other in the final assembly. In this case, I even was able to reduce the page count down to 12 from the starting 14.&lt;/p&gt;
    &lt;head rend="h3"&gt;Flap structure#&lt;/head&gt;
    &lt;p&gt;Flaps, or tabs, are the appendages on each part that allow for gluing parts together. Each flap has a singular counterpart edge that it's glued to - this is known as an edge/flap pair. Most software will auto-assign a shared number between an edge and its flap to make identify pairs easy during the assembly process.&lt;/p&gt;
    &lt;p&gt;For an edge/flap pair, most unfolding software will allow us to swap the flap across parts. Doing this strategically is critical for creating an easy to assemble model, and also has implications for the structural integrity of the final build.&lt;/p&gt;
    &lt;p&gt;For example, consider the two example parts shown above. These two parts that meet at two shared edges, so these parts have two edge/flap pairs between them. We could arrange the flaps so that one part has both of them:&lt;/p&gt;
    &lt;p&gt;We could also interlace the flaps, so each part has one flap on each side.&lt;/p&gt;
    &lt;p&gt;Interlacing flaps between parts can create a more stable structure, since there's only one way for the parts to meet. If two flaps are on the same side, they can over-extend when glued to the edge. That being said, same-side flaps can be easier to work with, especially when reaching the closing stages of a model.&lt;/p&gt;
    &lt;p&gt;In general, I like to using interlaced flaps wherever possible to create an overall stronger model, and use same-side flaps selectively.&lt;/p&gt;
    &lt;p&gt;Once we have an arrangement we like, we can export our layout as a PDF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Assembly#&lt;/head&gt;
    &lt;p&gt;With our layout PDF ready, we can now print it and move on to assembly. We'll finally get to see our design come to life.&lt;/p&gt;
    &lt;head rend="h3"&gt;Materials and Tools#&lt;/head&gt;
    &lt;p&gt;For our materials, we'll need:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;65lb (176 ) cardstock: This is the ideal paper weight for creating sturdy models, while still being thin/flexible enough to pass through a normal printer and be easy to fold.&lt;/item&gt;
      &lt;item&gt;Adhesive. My recommended adhesive is tacky glue: it's strong, dries clear, but is forgiving enough to allow for repositioning during assembly. Specifically, I use Aleene's Original Tacky Glue. I've also had past success with a glue stick.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We'll also need some tools, which I've listed these in order of importance. The ones with asterisks are essential. Everything else is a nice-to-have.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Printer*: You'll need access to a printer to print the template on the cardstock. Laser jet printers are great because the prints don't smudge.&lt;/item&gt;
      &lt;item&gt;Cutting tools*: You'll need a pair of scissors or a craft knife to cut out the parts. Use sharp tools for clean cuts - it makes a difference.&lt;/item&gt;
      &lt;item&gt;Ruler*: Cutting/scoring perfectly straight lines is a must. Steel rulers are great for their consistent edge, and they don't catch against your tools. That being said, I used a clear plastic ruler for this model. Being able to see through the ruler helps with alignment.&lt;/item&gt;
      &lt;item&gt;Scoring tool*: This will help you prepare a part for folding. You can use a bone folder or scoring wheel. I use an embossing tool I found at a dollar store, but before that, I used a ballpoint pen than ran out of ink. Anything with a precise (but not too sharp) tip will do.&lt;/item&gt;
      &lt;item&gt;Toothpicks: I use toothpicks to spread blobs of glue into thin layers and get into tight spaces.&lt;/item&gt;
      &lt;item&gt;Assembly surface: A cutting mat or piece of cardboard will protect your work surface and give you a stable surface to cut/score your parts.&lt;/item&gt;
      &lt;item&gt;Tweezers: Tweezers are helpful for handling small parts and getting into tight spaces, especially while holding parts together as glue dries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you want to get fancy, you can also purchase an automatic cutting machine, like a Cricut or Silhouette. These machines can precisely cut/score your parts from cardstock. Getting the template into their software takes some extra effort, but it results in the best quality parts. I did not use a machine for this project.&lt;/p&gt;
    &lt;p&gt;To match the real SR-71, I printed my template on black cardstock. Darker cardstocks are harder to work with because of the low contrast between the ink and the paper itself. If you're new to the hobby, I would recommend starting with a lighter color.&lt;/p&gt;
    &lt;head rend="h3"&gt;Assembly phases#&lt;/head&gt;
    &lt;p&gt;The assembly of a model has 4 steps:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cutting: Cutting the parts out from the paper with your cutting tool of choice. Scissors are quicker, but the combination of ruler and craft knife results in cleaner cuts.&lt;/item&gt;
      &lt;item&gt;Scoring: Running a scoring tool over fold lines to get cleaner folds. This may be tempting to skip, but I cannot emphasize the importance of this step enough. Scoring is especially important when dealing with thicker paper.&lt;/item&gt;
      &lt;item&gt;Folding: Folding the parts in prep for gluing. There's only two types of folds: mountain folds and valley folds.&lt;/item&gt;
      &lt;item&gt;Gluing: Gluing the parts together.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How you decide to batch these steps is up to you. For example, you could cut all the parts out at once, then score all of them, etc. This approach is effective because you can develop a rhythm by doing each phase only once, so you're not constantly switching between tools; the downside is that you only get to start assembly after a pretty lengthy process. Alternatively, you can do it per part: cut one part out, score it, fold it, and secure it to the assembly. Here, the pros and cons are flipped: you get to see the model come together quicker, but there's a lot of context switching between phases. I've tried both of these approaches, and find that the latter results in a non-negligible increase in the assembly time of the model.&lt;/p&gt;
    &lt;p&gt;To strike a balance, the approach I took for this model was performing the phases at the granularity of sections (engines, wings, fuselage, etc.) of the model. This approach has the added final step of assembling all the standalone sections together into the final model.&lt;/p&gt;
    &lt;p&gt;Here's some pictures I took during the assembly process. In total, assembly took 6-8 hours.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tips#&lt;/head&gt;
    &lt;p&gt;Use little glue: When gluing parts together, apply as little glue as possible. Using too much glue will result in spillover when the flaps/edges are put together, and this spillover is hard to wipe away from a porous surface like paper. Too much glue can even result in subtle paper warping. In the recommended tools, I suggested a toothpick. I apply a small bead of glue to a flap and use the toothpick to spread it into a thin film. This prevents any spillage and keeps the model clean.&lt;/p&gt;
    &lt;p&gt;Start in complex areas: As you progress further in gluing parts together, the degrees of freedom of your model will reduce. This is why I recommend starting with more complicated areas of your model where you'll need those degrees of freedom. In this model, this meant starting with precise features, like the engine inlet spikes or the vertical stabilizers.&lt;/p&gt;
    &lt;p&gt;Finish in hidden areas: This goes hand in hand with the tip above. As you reach to the end of your model, gluing the final parts together can be very hard, which means the final edges may come out a bit sloppy. Why does this happen? Any minor imperfections we made throughout the assembly process result in stresses in our model that will be felt at the end. Gluing the last part may be challenging because it'll feel misaligned, and it has the added challenge of attempting to close a 3D object from the outside. That's why I always recommend choosing an assembly order that results in the last parts being glued in an area that is out of sight. For the SR-71, that happens to be the underside of the fuselage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final Model#&lt;/head&gt;
    &lt;p&gt;Here's the final model, displayed on a stand (also made from paper):&lt;/p&gt;
    &lt;head rend="h2"&gt;Iteration#&lt;/head&gt;
    &lt;p&gt;No matter how much you scrutinize the modeling and layout phases, you will inevitably find areas for improvement as you assemble. In the case of the SR-71, I spotted a few minor assymetries in part tabs, and more importantly, an opportunity to reduce face count by simplifying the topology of the bottom of the plane and the nose cone.&lt;/p&gt;
    &lt;p&gt;I took my mesh back into Blender, and was able to get the triangle count down to 636, which is almost a full 100 faces fewer than the original mesh.&lt;/p&gt;
    &lt;p&gt;Below, you can see the old mesh (left) next to the new mesh (right). It's hard to tell the difference, yet the new one has almost 15% fewer faces.&lt;/p&gt;
    &lt;p&gt;A faster way to iterate is to render the model rather than physically building it. This allows you to quickly identify and fix visual issues without going through the hours of assembly. Here's some renders (in Blender) of the final iteration:&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion#&lt;/head&gt;
    &lt;p&gt;In total, the full cycle of designing the mesh, creating the parts layout, assembly, and subsequent refinement iterations occurred over the course of a few months. The process is long, but the results are well worth it.&lt;/p&gt;
    &lt;p&gt;If you're interested in making this model yourself, you can download the PDFs for the first iteration of the model below. I've included a template for the stand as well.&lt;/p&gt;
    &lt;p&gt;Hope you enjoy!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45222369</guid></item><item><title>Many hard LeetCode problems are easy constraint problems</title><link>https://buttondown.com/hillelwayne/archive/many-hard-leetcode-problems-are-easy-constraint/</link><description>&lt;doc fingerprint="cd8a25908f10bf1b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Many Hard Leetcode Problems are Easy Constraint Problems&lt;/head&gt;
    &lt;head rend="h2"&gt;Use the right tool for the job.&lt;/head&gt;
    &lt;p&gt;In my first interview out of college I was asked the change counter problem:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Given a set of coin denominations, find the minimum number of coins required to make change for a given number. IE for USA coinage and 37 cents, the minimum number is four (quarter, dime, 2 pennies).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I implemented the simple greedy algorithm and immediately fell into the trap of the question: the greedy algorithm only works for "well-behaved" denominations. If the coin values were &lt;code&gt;[10, 9, 1]&lt;/code&gt;, then making 37 cents would take 10 coins in the greedy algorithm but only 4 coins optimally (&lt;code&gt;10+9+9+9&lt;/code&gt;). The "smart" answer is to use a dynamic programming algorithm, which I didn't know how to do. So I failed the interview.&lt;/p&gt;
    &lt;p&gt;But you only need dynamic programming if you're writing your own algorithm. It's really easy if you throw it into a constraint solver like MiniZinc and call it a day.&lt;/p&gt;
    &lt;code&gt;int: total;
array[int] of int: values = [10, 9, 1];
array[index_set(values)] of var 0..: coins;

constraint sum (c in index_set(coins)) (coins[c] * values[c]) == total;
solve minimize sum(coins);
&lt;/code&gt;
    &lt;p&gt;You can try this online here. It'll give you a prompt to put in &lt;code&gt;total&lt;/code&gt; and then give you successively-better solutions:&lt;/p&gt;
    &lt;code&gt;coins = [0, 0, 37];
----------
coins = [0, 1, 28];
----------
coins = [0, 2, 19];
----------
coins = [0, 3, 10];
----------
coins = [0, 4, 1];
----------
coins = [1, 3, 0];
----------
&lt;/code&gt;
    &lt;p&gt;Lots of similar interview questions are this kind of mathematical optimization problem, where we have to find the maximum or minimum of a function corresponding to constraints. They're hard in programming languages because programming languages are too low-level. They are also exactly the problems that constraint solvers were designed to solve. Hard leetcode problems are easy constraint problems.1 Here I'm using MiniZinc, but you could just as easily use Z3 or OR-Tools or whatever your favorite generalized solver is.&lt;/p&gt;
    &lt;head rend="h3"&gt;More examples&lt;/head&gt;
    &lt;p&gt;This was a question in a different interview (which I thankfully passed):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Given a list of stock prices through the day, find maximum profit you can get by buying one stock and selling one stock later.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It's easy to do in O(n^2) time, or if you are clever, you can do it in O(n). Or you could be not clever at all and just write it as a constraint problem:&lt;/p&gt;
    &lt;code&gt;array[int] of int: prices = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8];
var int: buy;
var int: sell;
var int: profit = prices[sell] - prices[buy];

constraint sell &amp;gt; buy;
constraint profit &amp;gt; 0;
solve maximize profit;
&lt;/code&gt;
    &lt;p&gt;Reminder, link to trying it online here. While working at that job, one interview question we tested out was:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Given a list, determine if three numbers in that list can be added or subtracted to give 0?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a satisfaction problem, not a constraint problem: we don't need the "best answer", any answer will do. We eventually decided against it for being too tricky for the engineers we were targeting. But it's not tricky in a solver;&lt;/p&gt;
    &lt;code&gt;include "globals.mzn";
array[int] of int: numbers = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8];
array[index_set(numbers)] of var {0, -1, 1}: choices;

constraint sum(n in index_set(numbers)) (numbers[n] * choices[n]) = 0;
constraint count(choices, -1) + count(choices, 1) = 3;
solve satisfy;
&lt;/code&gt;
    &lt;p&gt;Okay, one last one, a problem I saw last year at Chipy AlgoSIG. Basically they pick some leetcode problems and we all do them. I failed to solve this one:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Given an array of integers heights representing the histogram's bar height where the width of each bar is 1, return the area of the largest rectangle in the histogram.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The "proper" solution is a tricky thing involving tracking lots of bookkeeping states, which you can completely bypass by expressing it as constraints:&lt;/p&gt;
    &lt;code&gt;array[int] of int: numbers = [2,1,5,6,2,3];

var 1..length(numbers): x; 
var 1..length(numbers): dx;
var 1..: y;

constraint x + dx &amp;lt;= length(numbers);
constraint forall (i in x..(x+dx)) (y &amp;lt;= numbers[i]);

var int: area = (dx+1)*y;
solve maximize area;

output ["(\(x)-&amp;gt;\(x+dx))*\(y) = \(area)"]
&lt;/code&gt;
    &lt;p&gt;There's even a way to automatically visualize the solution (using &lt;code&gt;vis_geost_2d&lt;/code&gt;), but I didn't feel like figuring it out in time for the newsletter.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is this better?&lt;/head&gt;
    &lt;p&gt;Now if I actually brought these questions to an interview the interviewee could ruin my day by asking "what's the runtime complexity?" Constraint solvers runtimes are unpredictable and almost always than an ideal bespoke algorithm because they are more expressive, in what I refer to as the capability/tractability tradeoff. But even so, they'll do way better than a bad bespoke algorithm, and I'm not experienced enough in handwriting algorithms to consistently beat a solver.&lt;/p&gt;
    &lt;p&gt;The real advantage of solvers, though, is how well they handle new constraints. Take the stock picking problem above. I can write an O(n²) algorithm in a few minutes and the O(n) algorithm if you give me some time to think. Now change the problem to&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Maximize the profit by buying and selling up to&lt;/p&gt;&lt;code&gt;max_sales&lt;/code&gt;stocks, but you can only buy or sell one stock at a given time and you can only hold up to&lt;code&gt;max_hold&lt;/code&gt;stocks at a time?&lt;/quote&gt;
    &lt;p&gt;That's a way harder problem to write even an inefficient algorithm for! While the constraint problem is only a tiny bit more complicated:&lt;/p&gt;
    &lt;code&gt;include "globals.mzn";
int: max_sales = 3;
int: max_hold = 2;
array[int] of int: prices = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8];
array [1..max_sales] of var int: buy;
array [1..max_sales] of var int: sell;
array [index_set(prices)] of var 0..max_hold: stocks_held;
var int: profit = sum(s in 1..max_sales) (prices[sell[s]] - prices[buy[s]]);

constraint forall (s in 1..max_sales) (sell[s] &amp;gt; buy[s]);
constraint profit &amp;gt; 0;

constraint forall(i in index_set(prices)) (stocks_held[i] = (count(s in 1..max_sales) (buy[s] &amp;lt;= i) - count(s in 1..max_sales) (sell[s] &amp;lt;= i)));
constraint alldifferent(buy ++ sell);
solve maximize profit;

output ["buy at \(buy)\n", "sell at \(sell)\n", "for \(profit)"];
&lt;/code&gt;
    &lt;p&gt;Most constraint solving examples online are puzzles, like Sudoku or "SEND + MORE = MONEY". Solving leetcode problems would be a more interesting demonstration. And you get more interesting opportunities to teach optimizations, like symmetry breaking.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update for the Internet&lt;/head&gt;
    &lt;p&gt;This was sent as a weekly newsletter, which is usually on topics like software history, formal methods, unusual technologies, and the theory of software engineering. You can subscribe here:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Because my dad will email me if I don't explain this: "leetcode" is slang for "tricky algorithmic interview questions that have little-to-no relevance in the actual job you're interviewing for." It's from leetcode.com. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're reading this on the web, you can subscribe here. Updates are once a week. My main website is here.&lt;/p&gt;
    &lt;p&gt;My new book, Logic for Programmers, is now in early access! Get it here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45222695</guid></item><item><title>Oq: Terminal OpenAPI Spec Viewer</title><link>https://github.com/plutov/oq</link><description>&lt;doc fingerprint="3191ffdf3d4b2dd5"&gt;
  &lt;main&gt;
    &lt;code&gt;oq openapi.yaml
# or
cat openapi.yaml | oq
# or
curl https://api.example.com/openapi.json | oq&lt;/code&gt;
    &lt;p&gt;Press &lt;code&gt;?&lt;/code&gt; to see the help screen with all available keyboard shortcuts.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;oq&lt;/code&gt; supports both modern major OpenAPI specification versions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAPI 3.0.x&lt;/item&gt;
      &lt;item&gt;OpenAPI 3.1.x&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both JSON and YAML formats are supported.&lt;/p&gt;
    &lt;code&gt;go install github.com/plutov/oq@latest&lt;/code&gt;
    &lt;p&gt;You can also download the compiled binaries from the Releases page.&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:plutov/oq.git
cd oq
go build -o oq .&lt;/code&gt;
    &lt;p&gt;MIT License - see LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please feel free to submit issues and pull requests.&lt;/p&gt;
    &lt;p&gt;When contributing:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ensure tests pass: &lt;code&gt;go test -v&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Test with both OpenAPI 3.0 and 3.1 examples&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45222799</guid></item><item><title>OpenAI Grove</title><link>https://openai.com/index/openai-grove/</link><description>&lt;doc fingerprint="b4871141422eeff0"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we’re announcing the OpenAI Grove, a new program for technical talent at the very start of their company-building journey. The Grove is not a startup accelerator or traditional program: it offers pre-idea individuals deeply curious about building in AI a dense talent network, co-building with OpenAI researchers, and resources designed to accelerate your journey. As participants explore early concepts, they will receive counsel from the OpenAI team and community with peers in OpenAI Grove. &lt;lb/&gt;This program is the starting point of a long-term network. It will begin with five weeks of content and programming hosted in the OpenAI San Francisco HQ, including in-person workshops, weekly office hours, and mentoring from OpenAI technical leaders. In addition to technical support and community, participants will also have the opportunity to get hands-on with new OpenAI tools and models prior to general availability. Following the program, participants will be able to explore raising capital or pursue another avenue, internally or externally to OpenAI. &lt;/p&gt;
    &lt;p&gt;The first Grove cohort will consist of approximately fifteen participants. We recommend individuals from all backgrounds, disciplines, and experience levels apply. To apply, please submit the form below by September 24th, 2025.&lt;/p&gt;
    &lt;p&gt;Applications are due by September 24th, 2025.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45223660</guid></item><item><title>Corporations are trying to hide job openings from US citizens</title><link>https://thehill.com/opinion/finance/5498346-corporate-america-has-been-trying-to-hide-job-openings-now-it-is-failing/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45223719</guid></item><item><title>VaultGemma: The most capable differentially private LLM</title><link>https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</link><description>&lt;doc fingerprint="3e58915235154e3a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;VaultGemma: The world's most capable differentially private LLM&lt;/head&gt;
    &lt;p&gt;September 12, 2025&lt;/p&gt;
    &lt;p&gt;Amer Sinha, Software Engineer, and Ryan McKenna, Research Scientist, Google Research&lt;/p&gt;
    &lt;p&gt;We introduce VaultGemma, the most capable model trained from scratch with differential privacy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick links&lt;/head&gt;
    &lt;p&gt;As AI becomes more integrated into our lives, building it with privacy at its core is a critical frontier for the field. Differential privacy (DP) offers a mathematically robust solution by adding calibrated noise to prevent memorization. However, applying DP to LLMs introduces trade-offs. Understanding these trade-offs is crucial. Applying DP noise alters traditional scaling laws — rules describing performance dynamics — by reducing training stability (the model's ability to learn consistently without experiencing catastrophic events like loss spikes or divergence) and significantly increasing batch size (a collection of input prompts sent to the model simultaneously for processing) and computation costs.&lt;/p&gt;
    &lt;p&gt;Our new research, “Scaling Laws for Differentially Private Language Models”, conducted in partnership with Google DeepMind, establishes laws that accurately model these intricacies, providing a complete picture of the compute-privacy-utility trade-offs. Guided by this research, we’re excited to introduce VaultGemma, the largest (1B-parameters), open model trained from scratch with differential privacy. We are releasing the weights on Hugging Face and Kaggle, alongside a technical report, to advance the development of the next generation of private AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Understanding the scaling laws&lt;/head&gt;
    &lt;p&gt;With a carefully thought-out experimental methodology, we aimed to quantify the benefit of increasing model sizes, batch sizes, and iterations in the context of DP training. Our work required making some simplifying assumptions to overcome the exponential number of combinations one might consider trying. We assumed that how well the model learns depends mostly on the "noise-batch ratio” which compares the amount of random noise we add for privacy to the size of the data groups (batches) we use for training. This assumption works because the privacy noise we add is much greater than any natural randomness that comes from sampling the data.&lt;/p&gt;
    &lt;p&gt;To establish a DP scaling law, we conducted a comprehensive set of experiments to evaluate performance across a variety of model sizes and noise-batch ratios. The resulting empirical data, together with known deterministic relationships between other variables, allows us to answer a variety of interesting scaling-laws–style queries, such as, “For a given compute budget, privacy budget, and data budget, what is the optimal training configuration to achieve the lowest possible training loss?”&lt;/p&gt;
    &lt;head rend="h2"&gt;Key findings: A powerful synergy&lt;/head&gt;
    &lt;p&gt;Before diving into the full scaling laws, it’s useful to understand the dynamics and synergies between the compute budget, privacy budget, and data budget from a privacy accounting perspective — i.e., understand how these factors influence the noise-batch ratio for a fixed model size and number of iterations. This analysis is significantly cheaper to do as it does not require any model training, yet it yields a number of useful insights. For instance, increasing the privacy budget in isolation leads to diminishing returns, unless coupled with a corresponding increase in either the compute budget (FLOPs) or data budget (tokens).&lt;/p&gt;
    &lt;p&gt;To explore this synergy further, the visualization below shows how the optimal training configuration changes based on different constraints. As the privacy and compute budgets change, notice how the recommendation shifts between investing in a larger model versus training with larger batch sizes or more iterations.&lt;/p&gt;
    &lt;p&gt;This data provides a wealth of useful insights for practitioners. While all the insights are reported in the paper, a key finding is that one should train a much smaller model with a much larger batch size than would be used without DP. This general insight should be unsurprising to a DP expert given the importance of large batch sizes. While this general insight holds across many settings, the optimal training configurations do change with the privacy and data budgets. Understanding the exact trade-off is crucial to ensure that both the compute and privacy budgets are used judiciously in real training scenarios. The above visualizations also reveal that there is often wiggle room in the training configurations — i.e., a range of model sizes might provide very similar utility if paired with the correct number of iterations and/or batch size.&lt;/p&gt;
    &lt;head rend="h2"&gt;Applying the scaling laws to build VaultGemma&lt;/head&gt;
    &lt;p&gt;The Gemma models are designed with responsibility and safety at their core. This makes them a natural foundation for developing a production-quality, DP-trained model like VaultGemma.&lt;/p&gt;
    &lt;head rend="h3"&gt;Algorithmic advancements: Training at scale&lt;/head&gt;
    &lt;p&gt;The scaling laws we derived above represent an important first step towards training a useful Gemma model with DP. We used the scaling laws to determine both how much compute we needed to train a compute-optimal 1B parameter Gemma 2-based model with DP, and how to allocate that compute among batch size, iterations, and sequence length to achieve the best utility.&lt;/p&gt;
    &lt;p&gt;One prominent gap between the research underlying the scaling laws and the actual training of VaultGemma was our handling of Poisson sampling, which is a central component of DP-SGD. We initially used a straightforward method of loading data in uniform batches but then switched to Poisson sampling to get the best privacy guarantees with the least amount of noise. This method posed two main challenges: it created batches of different sizes, and it required a specific, randomized order for processing the data. We solved this by using our recent work on Scalable DP-SGD, which allows us to process data in fixed-size batches — either by adding extra padding or trimming them — while still maintaining strong privacy protections.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Armed with our new scaling laws and advanced training algorithms, we built VaultGemma, to date the largest (1B-parameters) open model fully pre-trained with differential privacy with an approach that can yield high-utility models.&lt;/p&gt;
    &lt;p&gt;From training VaultGemma, we found our scaling laws to be highly accurate. The final training loss of VaultGemma was remarkably close to what our equations predicted, validating our research and providing the community with a reliable roadmap for future private model development.&lt;/p&gt;
    &lt;p&gt;We also compare downstream performance of our model against its non-private counterpart across a range of standard academic benchmarks (i.e., HellaSwag, BoolQ, PIQA, SocialIQA, TriviaQA, ARC-C, ARC-E ). To put this performance in perspective and quantify the current resource investment required for privacy, we also include a comparison to an older similar-sized GPT-2 model, which performs similarly on these benchmarks. This comparison illustrates that today’s private training methods produce models with utility comparable to that of non-private models from roughly 5 years ago, highlighting the important gap our work will help the community systematically close.&lt;/p&gt;
    &lt;p&gt;Finally, the model comes with strong theoretical and empirical privacy protections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Formal privacy guarantee&lt;/head&gt;
    &lt;p&gt;In general, both the privacy parameters (ε, δ) and the privacy unit are important considerations when doing DP training, as these together determine what the trained model can learn. VaultGemma was trained with a sequence-level DP guarantee of (ε ≤ 2.0, δ ≤ 1.1e-10), where a sequence consists of 1024 consecutive tokens extracted from heterogeneous data sources. Specifically, we used the same training mixture that was used to train the Gemma 2 model, consisting of a number of documents of varying lengths. During pre-processing, long documents are split up and tokenized into multiple sequences, and shorter documents are packed together into a single sequence. While the sequence-level privacy unit was a natural choice for our training mixture, in situations where there is a clear mapping between data and users, user-level differential privacy would be a better choice.&lt;/p&gt;
    &lt;p&gt;What does this mean in practice? Informally speaking, because we provide protection at the sequence level, if information relating to any (potentially private) fact or inference occurs in a single sequence, then VaultGemma essentially does not know that fact: the response to any query will be statistically similar to the result from a model that never trained on the sequence in question. However, if many training sequences contain information relevant to a particular fact, then in general VaultGemma will be able to provide that information.&lt;/p&gt;
    &lt;head rend="h3"&gt;Empirical memorization&lt;/head&gt;
    &lt;p&gt;Sequence-level DP provably bounds the influence of any single training sequence (example) on the final model. We prompted the model with a 50-token prefix from a training document to see if it would generate the corresponding 50-token suffix. VaultGemma 1B shows no detectable memorization of its training data and successfully demonstrates the efficacy of DP training.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;VaultGemma represents a significant step forward in the journey toward building AI that is both powerful and private by design. By developing and applying a new, robust understanding of the scaling laws for DP, we have successfully trained and released the largest open, DP-trained language model to date.&lt;/p&gt;
    &lt;p&gt;While a utility gap still exists between DP-trained and non-DP–trained models, we believe this gap can be systematically narrowed with more research on mechanism design for DP training. We hope that VaultGemma and our accompanying research will empower the community to build the next generation of safe, responsible, and private AI for everyone.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We'd like to thank the entire Gemma and Google Privacy teams for their contributions and support throughout this project, in particular, Peter Kairouz, Brendan McMahan and Dan Ramage for feedback on the blog post, Mark Simborg and Kimberly Schwede for help with visualizations, and the teams at Google that helped with algorithm design, infrastructure implementation, and production maintenance. The following people directly contributed to the work presented here (ordered alphabetically): Borja Balle, Zachary Charles, Christopher A. Choquette-Choo, Lynn Chua, Prem Eruvbetine, Badih Ghazi, Steve He, Yangsibo Huang, Armand Joulin, George Kaissis, Pritish Kamath, Ravi Kumar, Daogao Liu, Ruibo Liu, Pasin Manurangsi, Thomas Mesnard, Andreas Terzis, Tris Warkentin, Da Yu, and Chiyuan Zhang.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45223726</guid></item><item><title>QGIS is a free, open-source, cross platform geographical information system</title><link>https://github.com/qgis/QGIS</link><description>&lt;doc fingerprint="1e593c5071772595"&gt;
  &lt;main&gt;
    &lt;p&gt;QGIS is a full-featured, user-friendly, free-and-open-source (FOSS) geographical information system (GIS) that runs on Unix platforms, Windows, and MacOS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support for raster, vector, mesh, and point cloud data in a range of industry-standard formats &lt;list rend="ul"&gt;&lt;item&gt;Raster formats include: GeoPackage, GeoTIFF, GRASS, ArcInfo binary and ASCII grids, ERDAS Imagine SDTS, WMS, WCS, PostgreSQL/PostGIS, and other GDAL supported formats.&lt;/item&gt;&lt;item&gt;Vector formats include: GeoPackage, ESRI shapefiles, GRASS, SpatiaLite, PostgreSQL/PostGIS, MSSQL, Oracle, WFS, Vector Tiles and other OGR supported formats.&lt;/item&gt;&lt;item&gt;Mesh formats include: NetCDF, GRIB, 2DM, and other MDAL supported formats.&lt;/item&gt;&lt;item&gt;Point-cloud format: LAS/LAZ and EPT datasets.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Data abstraction framework, with local files, spatial databases (PostGIS, SpatiaLite, SQL Server, Oracle, SAP HANA), and web services (WMS, WCS, WFS, ArcGIS REST) all accessed through a unified data model and browser interface, and as flexible layers in user-created projects&lt;/item&gt;
      &lt;item&gt;Spatial data creation via visual and numerical digitizing and editing, as well as georeferencing of raster and vector data&lt;/item&gt;
      &lt;item&gt;On-the-fly reprojection between coordinate reference systems (CRS)&lt;/item&gt;
      &lt;item&gt;Nominatim (OpenStreetMap) geocoder access&lt;/item&gt;
      &lt;item&gt;Temporal support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Temporal animation&lt;/p&gt;
    &lt;p&gt;Example: 3D map view&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large variety of rendering options in 2D and 3D&lt;/item&gt;
      &lt;item&gt;Fine control over symbology, labeling, legends and additional graphical elements for beautifully rendered maps&lt;/item&gt;
      &lt;item&gt;Respect for embedded styling in many spatial data sources (e.g. KML and TAB files, Mapbox-GL styled vector tiles)&lt;/item&gt;
      &lt;item&gt;In particular, near-complete replication (and significant extension) of symbology options that are available in proprietary software by ESRI&lt;/item&gt;
      &lt;item&gt;Advanced styling using data-defined overrides, blending modes, and draw effects&lt;/item&gt;
      &lt;item&gt;500+ built-in color ramps (cpt-city, ColorBrewer, etc.)&lt;/item&gt;
      &lt;item&gt;Create and update maps with specified scale, extent, style, and decorations via saved layouts&lt;/item&gt;
      &lt;item&gt;Generate multiple maps (and reports) automatically using QGIS Atlas and QGIS Reports&lt;/item&gt;
      &lt;item&gt;Display and export elevation profile plots with flexible symbology&lt;/item&gt;
      &lt;item&gt;Flexible output direct to printer, or as image (raster), PDF, or SVG for further customization&lt;/item&gt;
      &lt;item&gt;On-the-fly rendering enhancements using geometry generators (e.g. create and style new geometries from existing features)&lt;/item&gt;
      &lt;item&gt;Preview modes for inclusive map making (e.g. monochrome, color blindness)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more maps created with QGIS, visit the QGIS Map Showcase Flickr Group.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Powerful processing framework with 200+ native processing algorithms&lt;/item&gt;
      &lt;item&gt;Access to 1000+ processing algorithms via providers such as GDAL, SAGA, GRASS, OrfeoToolbox, as well as custom models and processing scripts&lt;/item&gt;
      &lt;item&gt;Geospatial database engine (filters, joins, relations, forms, etc.), as close to datasource- and format-independent as possible&lt;/item&gt;
      &lt;item&gt;Immediate visualization of geospatial query and geoprocessing results&lt;/item&gt;
      &lt;item&gt;Model designer and batch processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Travel isochrones&lt;/p&gt;
    &lt;p&gt;Example: Model designer&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully customizable user experience, including user interface and application settings that cater to power-users and beginners alike&lt;/item&gt;
      &lt;item&gt;Rich expression engine for maximum flexibility in visualization and processing&lt;/item&gt;
      &lt;item&gt;Broad and varied plugin ecosystem that includes data connectors, digitizing aids, advanced analysis and charting tools, in-the-field data capture, conversion of ESRI style files, etc.&lt;/item&gt;
      &lt;item&gt;Style manager for creating, storing, and managing styles&lt;/item&gt;
      &lt;item&gt;QGIS style hub for easy sharing of styles&lt;/item&gt;
      &lt;item&gt;Python and C++ API for standalone (headless) applications as well as in-application comprehensive scripting (PyQGIS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Style manager&lt;/p&gt;
    &lt;p&gt;Example: Plugins&lt;/p&gt;
    &lt;p&gt;Headless map server -- running on Linux, macOS, Windows, or in a docker container -- that shares the same code base as QGIS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Industry-standard protocols (WMS, WFS, WFS3/OGC API for Features and WCS) allow plug-n-play with any software stack&lt;/item&gt;
      &lt;item&gt;Works with any web server (Apache, nginx, etc) or standalone&lt;/item&gt;
      &lt;item&gt;All beautiful QGIS cartography is supported with best-in-class support for printing&lt;/item&gt;
      &lt;item&gt;Fully customizable with Python scripting support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: QGIS server WMS response&lt;/p&gt;
    &lt;p&gt;Example: QGIS server WFS response&lt;/p&gt;
    &lt;p&gt;QGIS is developed using the Qt toolkit and C++, since 2002, and has a pleasing, easy to use graphical user interface with multilingual support. It is maintained by an active developer team and supported by vibrant community of GIS professionals and enthusiasts as well as geospatial data publishers and end-users.&lt;/p&gt;
    &lt;p&gt;QGIS development and releases follow a time based schedule/roadmap. There are three main branches of QGIS that users can install. These are the Long Term Release (LTR) branch, the Latest Release (LR) branch, and the Development (Nightly) branch.&lt;/p&gt;
    &lt;p&gt;Every month, there is a Point Release that provides bug-fixes to the LTR and LR.&lt;/p&gt;
    &lt;p&gt;QGIS is released under the GNU Public License (GPL) Version 2 or any later version. Developing QGIS under this license means that you can (if you want to) inspect and modify the source code and guarantees that you, our happy user will always have access to a GIS program that is free of cost and can be freely modified.&lt;/p&gt;
    &lt;p&gt;QGIS is part of the Open-Source Geospatial Foundation (OSGeo), offering a range of complementary open-source GIS software projects.&lt;/p&gt;
    &lt;p&gt;Precompiled binaries for QGIS are available at the QGIS.org download page. Please follow the installation instructions carefully.&lt;/p&gt;
    &lt;p&gt;The building guide can be used to get started with building QGIS from source.&lt;/p&gt;
    &lt;p&gt;For installation of QGIS Server, see its getting started documentation.&lt;/p&gt;
    &lt;p&gt;A range of documentation is available. This includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Training Manual&lt;/item&gt;
      &lt;item&gt;QGIS User Guide&lt;/item&gt;
      &lt;item&gt;QGIS Server Guide&lt;/item&gt;
      &lt;item&gt;Visual Changelog&lt;/item&gt;
      &lt;item&gt;Documentation Guidelines&lt;/item&gt;
      &lt;item&gt;QGIS Python (PyQGIS) Cookbook&lt;/item&gt;
      &lt;item&gt;QGIS Python (PyQGIS) API&lt;/item&gt;
      &lt;item&gt;QGIS C++ API&lt;/item&gt;
      &lt;item&gt;Developers Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are several channels where you can find help and support for QGIS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using the QGIS community site&lt;/item&gt;
      &lt;item&gt;Joining the qgis-users mailing list&lt;/item&gt;
      &lt;item&gt;Chatting with other users real-time. Please wait around for a response to your question as many folks on the channel are doing other things and it may take a while for them to notice your question. The following paths all take you to the same chat room: &lt;list rend="ul"&gt;&lt;item&gt;Using an IRC client and joining the #qgis channel on irc.libera.chat.&lt;/item&gt;&lt;item&gt;Using a Matrix client and joining the #qgis:osgeo.org room.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;At the GIS stackexchange or r/QGIS reddit, which are not maintained by the QGIS team, but where the QGIS and broader GIS community provides lots of advice&lt;/item&gt;
      &lt;item&gt;Other support channels&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45224156</guid></item><item><title>Humanely dealing with humungus crawlers</title><link>https://flak.tedunangst.com/post/humanely-dealing-with-humungus-crawlers</link><description>&lt;doc fingerprint="a46841793b2754f7"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;humanely dealing with humungus crawlers&lt;/head&gt;
    &lt;p&gt;I host a bunch of hobby code on my server. I would think it’s really only interesting to me, but it turns out every day, thousands of people from all over the world are digging through my code, reviewing years old changesets. On the one hand, wow, thanks, this is very flattering. On the other hand, what the heck is wrong with you?&lt;/p&gt;
    &lt;p&gt;This has been building up for a while, and I’ve been intermittently developing and deploying countermeasures. It’s been a lot like solving a sliding block puzzle. Lots of small moves and changes, and eventually it starts coming together.&lt;/p&gt;
    &lt;p&gt;My primary principle is that I’d rather not annoy real humans more than strictly intended. If there’s a challenge, it shouldn’t be too difficult, but ideally, we want to minimize the number of challenges presented. You should never suspect that I suspected you of being an enemy agent.&lt;/p&gt;
    &lt;p&gt;First measure is we only challenge on the deep URLs. So, for instance, I can link to the anticrawl repo no problem, or even the source for anticrawl.go, and that’ll be served immediately. All the pages any casual browser would visit make up less than 1% of the possible URLs that exist, but probably contain 99% of the interesting content.&lt;/p&gt;
    &lt;p&gt;Also, these pages get cached by the reverse proxy first, so anticrawl doesn’t even evaluate them. We’ve already done the work to render the page, and we’re trying to shed load, so why would I want to increase load by generating challenges and verifying responses? It annoys me when I click a seemingly popular blog post and immediately get challenged, when I’m 99.9% certain that somebody else clicked it two seconds before me. Why isn’t it in cache? We must have different objectives in what we’re trying to accomplish. Or who we’re trying to irritate.&lt;/p&gt;
    &lt;p&gt;The next step is that anybody loading &lt;code&gt;style.css&lt;/code&gt; gets marked friendly. Big Basilisk doesn’t care about my artisanal styles, but most everybody else loves them. So if you start at a normal page, and then start clicking deeper, that’s fine, still no challenge. (Sorry lynx browsers, but don’t worry, it’s not game over for you yet.)&lt;/p&gt;
    &lt;p&gt;And then let’s say somebody directly links to a changeset like /r/vertigo/v/b5ea481ff167. The first visitor will probably hit a challenge, but then we record that URL as in use. The bots are shotgun crawling all over the place, but if a single link is visited more than once, I’ll assume it’s human traffic, and bypass the challenge. No promises, but clicking that link will mostly likely just return content, no challenge.&lt;/p&gt;
    &lt;p&gt;The very first version of anticrawl relied on a weak POW challenge (find a SHA hash with first byte 42), just to get something launched, but this does seem counter intuitive. Why are we making humans solve a challenge optimized for machines? Instead I have switched to a much more diabolical challenge. You are asked how many Rs in strawberry. Or maybe something else. To be changed as necessary. But really, the key observation is that any challenge, anything at all, easily sheds like 99.99% of the crawling load.&lt;/p&gt;
    &lt;p&gt;Notably, because the challenge does not include its own javascript solver, even a smart crawler isn’t going to solve it automatically. If you include the solution on the challenge page, at least some bots are going to use it. All anticrawl challenges now require some degree of contemplation, not just blind interpretation.&lt;/p&gt;
    &lt;p&gt;It took a few iterations because the actual deployment involves a few pieces. I had to reduce the &lt;code&gt;style.css&lt;/code&gt; cache time, so that visitors would periodically refresh it (and thus their humanity). And then exclude it from the caching proxy, so that the request would be properly observed. Basically, a few minutes tinkering now and then while I wait for my latte to arrive, and now I think I’ve gotten things to the point where it’s unlikely to burden anybody except malignant crawlers.&lt;/p&gt;
    &lt;head rend="h3"&gt;elsewhere&lt;/head&gt;
    &lt;p&gt;I have focused my bot detection efforts on humungus because the ratio of crawler to legit traffic was out of control. But now that I know what to look for, I see the same patterns scraping everywhere else. Seems really unlikely a worldwide colelctive of Opera users is suddenly interested in my old honks. I’m starting to deploy similar countermeasures.&lt;/p&gt;
    &lt;head rend="h3"&gt;appendix&lt;/head&gt;
    &lt;p&gt;Some log samples. There’s always somebody to insist these could be real humans, and I have somehow misjudged them. Make your own decision.&lt;/p&gt;
    &lt;p&gt;&lt;head&gt;logs&lt;/head&gt;&lt;code&gt;136.158.49.199 810.886µs humungus.tedunangst.com [2025/09/07 11:31:06] "GET /r/old-flak/v/d720c11fbb57 HTTP/1.1" 402 904 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36"
179.42.10.152 831.235µs humungus.tedunangst.com [2025/09/07 11:31:31] "GET /r/flak/v/8b31c923ca0f HTTP/1.1" 402 900 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
43.128.250.84 863.565µs humungus.tedunangst.com [2025/09/07 11:31:32] "GET /r/vertigo/v/71df18bb3819 HTTP/1.1" 402 961 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36"
78.182.153.38 639.086µs humungus.tedunangst.com [2025/09/07 11:31:46] "GET /r/gerc/v/692abbdefe18 HTTP/1.1" 402 900 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36"
119.28.100.182 525.152µs humungus.tedunangst.com [2025/09/07 11:31:47] "GET /r/honk3/v/462b7440c563 HTTP/1.1" 402 959 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36"
185.163.26.50 678.609µs humungus.tedunangst.com [2025/09/07 11:31:49] "GET /r/azorius/v/b48a3aa3e060 HTTP/1.1" 402 961 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
43.167.157.150 758.749µs humungus.tedunangst.com [2025/09/07 11:32:01] "GET /r/humungus/v/0442f94c95fc HTTP/1.1" 402 904 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
43.134.75.63 574.875µs humungus.tedunangst.com [2025/09/07 11:32:03] "GET /r/azorius/v/969314b9f388 HTTP/1.1" 402 903 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" 
119.28.203.219 497.67µs humungus.tedunangst.com [2025/09/07 11:32:04] "GET /r/gerc/v/8ddbf7307214 HTTP/1.1" 402 900 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36"
43.128.84.91 727.05µs humungus.tedunangst.com [2025/09/07 11:32:06] "GET /r/vertigo/v/eb31940f6fa2 HTTP/1.1" 402 903 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36"
178.163.207.155 566.9µs humungus.tedunangst.com [2025/09/07 11:32:09] "GET /r/lua-tedu/v/300e67089469 HTTP/1.1" 402 904 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
181.120.225.184 561.48µs humungus.tedunangst.com [2025/09/07 11:32:12] "GET /r/azorius/v/43120b8aac5a HTTP/1.1" 402 961 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
150.109.20.69 612.716µs humungus.tedunangst.com [2025/09/07 11:32:13] "GET /r/gojxl/v/tip/f/pool.go HTTP/1.1" 404 19 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
49.51.170.84 629.056µs humungus.tedunangst.com [2025/09/07 11:32:27] "GET /r/gerc/v/41b8b28ee893 HTTP/1.1" 402 958 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
5.62.146.6 843.157µs humungus.tedunangst.com [2025/09/07 11:32:33] "GET /r/honk/v/f6b8a7bee881 HTTP/1.1" 402 900 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36"
129.226.112.105 595.173µs humungus.tedunangst.com [2025/09/07 11:32:40] "GET /r/azorius/v/6179155ac315 HTTP/1.1" 402 903 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.81 Safari/537.36"
43.167.204.48 514.371µs humungus.tedunangst.com [2025/09/07 11:32:42] "GET /r/vertigo/v/fae0082c32c2 HTTP/1.1" 402 961 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36"
43.132.108.190 715.327µs humungus.tedunangst.com [2025/09/07 11:32:56] "GET /r/vertigo/v/8b5fcd06f8c6 HTTP/1.1" 402 903 "" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36"&lt;/code&gt;&lt;lb/&gt;The big brain solution is you just cache all these requests, but unfortunately I have slightly less than 2TB RAM. Dealing with these relentless scans renders the cache for actual content less useful because everything gets LRUd out.&lt;/p&gt;
    &lt;p&gt;Take a look at this guy. Apparently a pro starcraft player has taken up speed browsing as a side hustle, middle clicking ten times per second. These links aren’t even on the same page, so he’s switching tabs between clicks, too. Amazing. But he doesn’t solve a single challenge. I thought gamers liked puzzles? Maybe that’s why this totally real human quit gaming.&lt;/p&gt;
    &lt;p&gt;&lt;head&gt;logs&lt;/head&gt;&lt;code&gt;46.183.108.190 1.361957ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/azorius/v/a0824eb087c7 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 2.450003ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/azorius/v/1a4d35ff94ef HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 3.049854ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/azorius/v/9ca7ed390641 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 3.215804ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/humungus/v/67e77258e203 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 3.26703ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/honk/v/2fc6f904deaa HTTP/1.1" 402 1805 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 830.924µs humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/humungus/v/1437b0d26457 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 1.23004ms humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/honk/v/945572a3b51d HTTP/1.1" 402 1805 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 789.496µs humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/humungus/v/63f9c1f17606 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 841.414µs humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/humungus/v/b5711a883e66 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 916.233µs humungus.tedunangst.com [2025/07/08 13:41:32] "GET /r/humungus/v/a5307922b3f5 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 565.518µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/honk/v/ab1e84cac5e6 HTTP/1.1" 402 1805 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 574.083µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/honk/v/a9043d011e41 HTTP/1.1" 402 1805 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 602.026µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/azorius/v/1cc1393b6832 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 497.831µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/azorius/v/4d53be2bdbd5 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 516.365µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/honk/v/302e58335796 HTTP/1.1" 402 1805 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 614.239µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/azorius/v/1a4d35ff94ef HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 530.161µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/azorius/v/a0824eb087c7 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 625.91µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/azorius/v/9ca7ed390641 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 757.497µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/humungus/v/67e77258e203 HTTP/1.1" 402 1809 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"
46.183.108.190 841.494µs humungus.tedunangst.com [2025/07/08 13:41:33] "GET /r/vertigo/v/6b3ffb3b21f5 HTTP/1.1" 402 1808 "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:140.0) Gecko/20100101 Firefox/140.0"&lt;/code&gt;&lt;lb/&gt;I think there’s a common perception that 10 req/s just isn’t that much, based on some simple benchmarks. But that doesn’t account for TLS, etc. 10 handshakes/s requires a bit more juice than GET hello. I’ve worked to keep response times in the low millisecond range, just seems like good sense, but I think people should be allowed to program in slower languages and frameworks. You shouldn’t need a fairly substantial EPYC server like I have, either.&lt;/p&gt;
    &lt;p&gt;And there’s always stuff happening in the background. Mastodon hits me once a second every time anybody deletes something. Lemmy hits me twice a second every time somebody likes anything. There’s a bunch of nitwits with misconfigured RSS readers.&lt;/p&gt;
    &lt;p&gt;A 4x overhead in one area doesn’t matter, but a 1/4 as powerful CPU, with 1/4 as many cores, and 1/4 as fast language, all of which are entirely realistic, and pretty soon we’re running close to the edge.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45224246</guid></item><item><title>How FOSS Projects Handle Legal Takedown Requests</title><link>https://f-droid.org/2025/09/10/how-foss-projects-handle-legal-takedown-requests.html</link><description>&lt;doc fingerprint="f21a83016ff37250"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;How FOSS Projects Handle Legal Takedown Requests&lt;/head&gt;Posted on Sep 10, 2025 by F-Droid&lt;p&gt;When a legal takedown request arrives, whether itâs about copyright, censorship, privacy, or something more vague, how a Free and Open Source Software (FOSS) project responds can make all the difference.&lt;/p&gt;&lt;p&gt;Handled well, a takedown request can be a manageable administrative step. Handled poorly, it can cause panic, disrupt infrastructure, or even put contributors at legal risk.&lt;/p&gt;&lt;p&gt;As part of our legal resilience research, we spoke with a range of legal experts, software freedom advocates, and maintainers of mature FOSS infrastructure to understand how others manage these moments. In this article, we share what we learned, and how F-Droid is incorporating these lessons into its own approach.&lt;/p&gt;&lt;head rend="h2"&gt;A Pattern Emerges&lt;/head&gt;&lt;p&gt;Despite differences in jurisdiction, size, and mission, a few common themes from our research emerged when we asked how other projects handle takedown requests:&lt;/p&gt;&lt;head rend="h3"&gt;1. Donât Be a Soft Target&lt;/head&gt;&lt;p&gt;Legal threats often follow the path of least resistance. FOSS projects that publish a formal takedown policy, require legal submissions through specific channels, and insist on a valid legal basis are much less likely to receive, or comply with, vague or harassing demands.&lt;/p&gt;&lt;p&gt;One FOSS organization, for example, requires all legal correspondence to be submitted by postal mail in the national language and citing local law. Most complaints evaporate once asked to comply.&lt;/p&gt;&lt;head rend="h3"&gt;2. Creating a transparent and documented process&lt;/head&gt;&lt;p&gt;Several digital rights organizations advised setting up structured response steps:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Require submissions to a dedicated legal@ or abuse@ email.&lt;/item&gt;&lt;item&gt;Insist on full documentation: legal basis, jurisdiction, evidence of the infringement and identity of the complainant.&lt;/item&gt;&lt;item&gt;Review for sufficiency, proportionality, and standing before acting.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This creates proper documentation to process valid claims, while protecting projects from illegitimate or unfounded requests.&lt;/p&gt;&lt;head rend="h3"&gt;3. Use Jurisdiction Strategically&lt;/head&gt;&lt;p&gt;Projects based in civil law jurisdictions, particularly in Europe, are often better positioned to deflect legal demands from foreign entities. Several organizations emphasized that complying with vague or extrajudicial requests, especially those originating outside your jurisdiction, can increase risk unnecessarily. Instead, they recommended requiring a valid legal basis grounded in the projectâs home country. Formal legal processes, such as court orders or official government channels, were seen as the appropriate threshold, not informal emails or unverifiable demands.&lt;/p&gt;&lt;head rend="h2"&gt;Notification and Appeals: Fairness and Transparency&lt;/head&gt;&lt;p&gt;All of the projects we consulted emphasized the importance of notifying developers whose apps are being targeted, informing them (if possible) of the seriousness of the claim, and the proposed strategy F-Droid is taking to handle the claim.Â&lt;/p&gt;&lt;p&gt;If a threat is deemed to be valid and a developerâs content is flagged for takedown:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The developer or maintainer is informed, unless prohibited by law (gag orders).&lt;/item&gt;&lt;item&gt;A window for response (commonly 14 days) is offered, unless unfeasible due to seriousness and time restraints of the request itself&lt;/item&gt;&lt;item&gt;If the developer disputes the claim and provides supporting information (e.g. license, public domain status, fair use justification), the claim is reviewed.&lt;/item&gt;&lt;item&gt;If the claim is upheld, the content is removed, but always with an internal record and opportunity to appeal.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This mirrors principles embedded in international norms (like the Manila Principles and GitHubâs DMCA takedown policy) and avoids overcompliance with weak or abusive claims.&lt;/p&gt;&lt;head rend="h2"&gt;Transparency, Censorship, and What You Can (Legally) Publish&lt;/head&gt;&lt;p&gt;Takedown requests occupy a complex space between legal enforcement and censorship. While some are legitimate claims, like copyright violations or privacy breaches, others are vague, politically motivated, or intended to silence dissent. For FOSS projects that have a global user base, itâs not always obvious how to respond. Complying too quickly can reinforce censorship practices; resisting without process can lead to full website shut downs, domain names being taken away (as in the US) or large and costly legal battles.&lt;/p&gt;&lt;p&gt;One strategy that helps balance this tension is radical transparency. Several projects we spoke with emphasized the importance of documenting what actions were taken and why, not just for accountability, but as a form of resistance. A well-known example is GitHubâs DMCA takedown policy (as of July 2025), which mandates compliance with valid takedown requests, but also posts each one publicly in their github/dmca repository. The result: potential abusers know their requests will face public scrutiny, which acts as a deterrent.&lt;/p&gt;&lt;p&gt;However, not all jurisdictions allow this kind of transparency. In India, for example, we were informed that it is often illegal to disclose that you have received a government request, even to the developer of the affected app. In contrast, in Russia, takedown requests can often be legally posted, though by doing so you may be putting yourself at risk for retaliation, additional takedown requests and legal troubles.&lt;/p&gt;&lt;p&gt;With that in mind, some best practices for FOSS projects include:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Publishing biannual transparency reports, even if redacted or aggregated.&lt;/item&gt;&lt;item&gt;Maintaining an internal log of all takedown activity, with public disclosure where legally possible.&lt;/item&gt;&lt;item&gt;Explaining the general reasons for content removals, who made the request, under what law, and what action was taken, unless legally prohibited.&lt;/item&gt;&lt;item&gt;Being explicit about what cannot be shared, and why.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Transparency wonât prevent all forms of censorship, but it can slow them down, raise awareness, and provide a record that strengthens the broader FOSS ecosystem.&lt;/p&gt;&lt;head rend="h2"&gt;What Weâre Doing at F-Droid&lt;/head&gt;&lt;p&gt;F-Droid is revising its own takedown policy, informed by:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Dutch law and EU regulations&lt;/item&gt;&lt;item&gt;The structural support provided by The Commons Conservancy&lt;/item&gt;&lt;item&gt;Practical lessons from long-standing FOSS organizations&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Our draft process includes:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Written takedown submission request to legal@f-droid.org including the required information.:&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;Identify the specific material in question (e.g. app name)&lt;/item&gt;&lt;item&gt;Include valid legal basis under applicable jurisdiction (e.g. copyright law, court order statutory basis)&lt;/item&gt;&lt;item&gt;Indicate jurisdiction in which the legal basis is claimed to apply&lt;/item&gt;&lt;item&gt;Include sufficient evidence of the alleged infringement (e.g. copyright certificate, ownership declaration)&lt;/item&gt;&lt;item&gt;Clearly state that the complaintant is authorized to act on behalf of the rights holder&lt;/item&gt;&lt;item&gt;Include full contact details and a verifiable identity (subject to exceptions, such as gag orders or whistleblower protection)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ol"&gt;&lt;item&gt;Verification of jurisdiction and legal basis, including evidence&lt;/item&gt;&lt;item&gt;Developer notification and appeal procedures&lt;/item&gt;&lt;item&gt;Rejection of requests lacking documentation or legal authority may be rejected or ignored&lt;/item&gt;&lt;item&gt;Biannual transparency reports and public tracking of takedown requests&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Weâre also working to improve contributor education about potential exposure when contributing to F-Droid, document internal escalation paths, and ensure consistent handling of international claims.&lt;/p&gt;&lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;&lt;p&gt;Takedown requests are not going away in fact, theyâre becoming more frequent and more complex. But FOSS projects donât have to face them unprepared.&lt;/p&gt;&lt;p&gt;By building processes, establishing clear jurisdiction, and protecting individuals through structure and policy, we can handle these challenges with the seriousness they deserve without letting them derail our mission.&lt;/p&gt;&lt;head rend="h2"&gt;Legal Disclaimer&lt;/head&gt;&lt;p&gt;The content provided in this article is for informational purposes only and does not constitute legal advice. While we strive to provide accurate and up-to-date information, F-Droid makes no representations or warranties of any kind, express or implied, about the completeness, accuracy, or suitability of the information contained herein.&lt;/p&gt;&lt;p&gt;F-Droid is not a law firm and does not offer legal services. Any reliance you place on the information provided is strictly at your own risk. If you have questions about legal obligations, rights, or compliance, we strongly recommend consulting a qualified legal professional familiar with your jurisdiction.&lt;/p&gt;&lt;p&gt;F-Droid and its contributors disclaim all liability for any loss or damage arising from the use or misuse of this content.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45224421</guid></item><item><title>EU court rules nuclear energy is clean energy</title><link>https://www.weplanet.org/post/eu-court-rules-nuclear-energy-is-clean-energy</link><description>&lt;doc fingerprint="9b4f11649f0a6c9a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;EU Court Rules Nuclear Energy is Clean Energy&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WePlanet&lt;/item&gt;
      &lt;item&gt;5 minutes ago&lt;/item&gt;
      &lt;item&gt;3 min read&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When I launched Dear Greenpeace with my fellow youth climate activists alongside WePlanet two years ago, I had no idea just how quickly the anti-nuclear dominoes would fall across Europe.&lt;/p&gt;
    &lt;p&gt;In 2023, and what seems like a lifetime ago, Austria launched their legal action against the European Commission for the inclusion of nuclear energy in the EU Sustainable Finance Taxonomy. At the time they were supported by a bulwark of EU countries and environmental NGOs that opposed nuclear energy. Honestly, it looked like they might win.&lt;/p&gt;
    &lt;p&gt;But today, that whole landscape has changed.&lt;/p&gt;
    &lt;p&gt;Germany, long a symbol of anti-nuclear politics, is beginning to shift. The nuclear phase-outs or bans in the Netherlands, Belgium, Switzerland, Denmark, and Italy are now history. Even Fridays for Future has quietened its opposition, and in some places, embraced nuclear power.&lt;/p&gt;
    &lt;p&gt;This moment matters.&lt;/p&gt;
    &lt;p&gt;It shows what’s possible when we stick to the science. The evidence only gets clearer by the day that nuclear energy has an extremely low environmental impact across its lifecycle, and strong regulations and safety culture ensure that it remains one of the safest forms of energy available to humanity.&lt;/p&gt;
    &lt;p&gt;The European Court of Justice has now fully dismissed Austria’s lawsuit. That ruling doesn’t just uphold nuclear energy’s place in EU green finance rules. It also signals a near-certain defeat for the ongoing Greenpeace case – the very lawsuit that inspired me to launch Dear Greenpeace in the first place.&lt;/p&gt;
    &lt;p&gt;But instead of learning from this, Greenpeace is doubling down. Martin Kaiser, Executive Director of Greenpeace Germany, called the court decision “a dark day for the climate”.&lt;/p&gt;
    &lt;p&gt;Let that sink in. The highest court in the EU just reaffirmed that nuclear energy meets the scientific and environmental standards to be included in sustainable finance, and Greenpeace still refuses to budge.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the climate crisis gets worse. Global emissions are not falling fast enough. Billions of people still lack access to clean, reliable electricity. And we are forced to spend time defending proven solutions instead of scaling them.&lt;/p&gt;
    &lt;p&gt;It’s now up to the court whether we will get our time in court to outline the evidence in support of nuclear energy and the important role it can play in the global clean energy transition. Whether in court, on the streets, or in the halls of parliaments across the globe, we will be there to defend the science and ensure that nuclear power can spread the advantages of the modern world across the planet in a sustainable, reliable and dignified way.&lt;/p&gt;
    &lt;p&gt;Austria stands increasingly isolated among a handful of countries that still cling to their opposition to nuclear energy. Their defeat in this vital high stakes topic is a success not just for the nuclear movement, but for the global transition as a whole.&lt;/p&gt;
    &lt;p&gt;We have made real progress. Together, we’ve helped defend nuclear power in the EU, overturned outdated policies at the World Bank, and secured more technology-neutral language at the UN. These wins are not abstract. They open the door to real investment, real projects, and real emissions cuts.&lt;/p&gt;
    &lt;p&gt;But the work is not done.&lt;/p&gt;
    &lt;p&gt;We still need to overturn national nuclear bans, unlock more funding, and push democratic countries to support clean energy development abroad: especially where it is most needed to compete with Russia’s growing influence.&lt;/p&gt;
    &lt;p&gt;The fight will not be done until every single country in the world can boast a clean, reliable energy grid, ready to maintain a modern dignified standard of living, for everyone, everywhere.&lt;/p&gt;
    &lt;p&gt;This is a great success for the movement and it would not have been possible without the financial support, time and energy given by people like you.&lt;/p&gt;
    &lt;p&gt;In Solidarity, Ia Aanstoot&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45224967</guid></item><item><title>UTF-8 is a brilliant design</title><link>https://iamvishnu.com/posts/utf8-is-brilliant-design</link><description>&lt;doc fingerprint="a4bdbd10f83149ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;UTF-8 is a Brilliant Design&lt;/head&gt;
    &lt;p&gt;The first time I learned about UTF-8 encoding, I was fascinated by how well-thought and brilliantly it was designed to represent millions of characters from different languages and scripts, and still be backward compatible with ASCII.&lt;/p&gt;
    &lt;p&gt;Basically UTF-8 uses 32 bits and the old ASCII uses 7 bits, but UTF-8 is designed in such a way that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Every ASCII encoded file is a valid UTF-8 file.&lt;/item&gt;
      &lt;item&gt;Every UTF-8 encoded file that has only ASCII characters is a valid ASCII file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Designing a system that scales to millions of characters and still be compatible with the old systems that use just 128 characters is a brilliant design.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: If you are already aware of the UTF-8 encoding, you can explore the UTF-8 Playground utility that I built to visualize UTF-8 encoding.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;How Does UTF-8 Do It?&lt;/head&gt;
    &lt;p&gt;UTF-8 is a variable-width character encoding designed to represent every character in the Unicode character set, encompassing characters from most of the world's writing systems.&lt;/p&gt;
    &lt;p&gt;It encodes characters using one to four bytes.&lt;/p&gt;
    &lt;p&gt;The first 128 characters (&lt;code&gt;U+0000&lt;/code&gt; to &lt;code&gt;U+007F&lt;/code&gt;) are encoded with a single byte, ensuring backward compatibility with ASCII, and this is the reason why a file with only ASCII characters is a valid UTF-8 file.&lt;/p&gt;
    &lt;p&gt;Other characters require two, three, or four bytes. The leading bits of the first byte determine the total number of bytes that represents the current character. These bits follow one of four specific patterns, which indicate how many continuation bytes follow.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;1st byte Pattern&lt;/cell&gt;
        &lt;cell role="head"&gt;# of bytes used&lt;/cell&gt;
        &lt;cell role="head"&gt;Full byte sequence pattern&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;0xxxxxxx&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;0xxxxxxx&lt;p&gt;(This is basically a regular ASCII encoded byte)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;110xxxxx&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;110xxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1110xxxx&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;1110xxxx 10xxxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;11110xxx&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;11110xxx 10xxxxxx 10xxxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notice that the second, third, and fourth bytes in a multi-byte sequence always start with 10. This indicates that these bytes are continuation bytes, following the main byte.&lt;/p&gt;
    &lt;p&gt;The remaining bits in the main byte, along with the bits in the continuation bytes, are combined to form the character's code point. A code point serves as a unique identifier for a character in the Unicode character set. A code point is typically represented in hexadecimal format, prefixed with "U+". For example, the code point for the character "A" is &lt;code&gt;U+0041&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So here is how a software determines the character from the UTF-8 encoded bytes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read a byte. If it starts with &lt;code&gt;0&lt;/code&gt;, it's a single-byte character (ASCII). Show the character represented by the remaiing 7 bits on the screen. Continue with the next byte.&lt;/item&gt;
      &lt;item&gt;If the byte didn't start with a &lt;code&gt;0&lt;/code&gt;, then:&lt;list rend="ul"&gt;&lt;item&gt;If it starts with &lt;code&gt;110&lt;/code&gt;, it's a two-byte character, so read the next byte as well.&lt;/item&gt;&lt;item&gt;If it starts with &lt;code&gt;1110&lt;/code&gt;, it's a three-byte character, so read the next two bytes.&lt;/item&gt;&lt;item&gt;If it starts with &lt;code&gt;11110&lt;/code&gt;, it's a four-byte character, so read the next three bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;If it starts with &lt;/item&gt;
      &lt;item&gt;Once the number of bytes are determined, read all the remaining bits except the leading bits, and find the binary value (aka. code point) of the character.&lt;/item&gt;
      &lt;item&gt;Look up the code point in the Unicode character set to find the corresponding character and display it on the screen.&lt;/item&gt;
      &lt;item&gt;Read the next byte and repeat the process.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Example: Hindi Letter "अ" (open in UTF-8 Playground)&lt;/head&gt;
    &lt;p&gt;The Hindi letter "अ" (officially "Devanagari Letter A") is represented in UTF-8 as:&lt;/p&gt;
    &lt;p&gt;11100000 10100100 10000101 Here:&lt;/p&gt;
    &lt;p&gt;The first byte 11100000 indicates that the character is encoded using 3 bytes.&lt;/p&gt;
    &lt;p&gt;The remaining bits of the three bytes: xxxx0000 xx100100 xx000101 are combined to form the binary sequence 00001001 00000101 (&lt;code&gt;0x0905&lt;/code&gt; in hexadecimal). This is the code point of the character, represented as &lt;code&gt;U+0905&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The code point &lt;code&gt;U+0905&lt;/code&gt; (see official chart) represents the Hindi letter "अ" in the Unicode character set.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example Text Files&lt;/head&gt;
    &lt;p&gt;Now that we understood the design of UTF-8, let's look at a file that contains the following text:&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Text file contains: &lt;code&gt;Hey👋 Buddy&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The text &lt;code&gt;Hey👋 Buddy&lt;/code&gt; has both English characters and an emoji character on it. The text file with this text saved on the disk will have the following 13 bytes in it:&lt;/p&gt;
    &lt;p&gt;01001000 01100101 01111001 11110000 10011111 10010001 10001011 00100000 01000010 01110101 01100100 01100100 01111001&lt;/p&gt;
    &lt;p&gt;Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Byte&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01001000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1001000&lt;/code&gt; represent the letter 'H'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100101&lt;/code&gt; represent the letter 'e'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;11110000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;11110&lt;/code&gt;, indicating it's the first byte of a four-byte character.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10011111&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10010001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10001011&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;p&gt;The bits from these four bytes (excluding the leading bits) combine to form the binary sequence 00001 11110100 01001011, which is&lt;/p&gt;&lt;code&gt;1F44B&lt;/code&gt; in hexadecimal, corresponds to the code point &lt;code&gt;U+1F44B&lt;/code&gt;. This code point represents the waving hand emoji "👋" in the Unicode character set (open in playground).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;00100000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;0100000&lt;/code&gt; represent a whitespace character. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01000010&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1000010&lt;/code&gt; represent the letter 'B'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01110101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1110101&lt;/code&gt; represent the letter 'u'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now this is a valid UTF-8 file, but it doesn't have to be "backward compatible" with ASCII because it contains a non-ASCII character (the emoji). Next let's create a file that contains only ASCII characters.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Text file contains: &lt;code&gt;Hey Buddy&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The text file doesn't have any non-ASCII characters. The file saved on the disk has the following 9 bytes in it:&lt;/p&gt;
    &lt;p&gt;01001000 01100101 01111001 00100000 01000010 01110101 01100100 01100100 01111001&lt;/p&gt;
    &lt;p&gt;Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Byte&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01001000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1001000&lt;/code&gt; represent the letter 'H'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100101&lt;/code&gt; represent the letter 'e'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;00100000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;0100000&lt;/code&gt; represent a whitespace character. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01000010&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1000010&lt;/code&gt; represent the letter 'B'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01110101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1110101&lt;/code&gt; represent the letter 'u'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So this is a valid UTF-8 file, and it is also a valid ASCII file. The bytes in this file follows both the UTF-8 and ASCII encoding rules. This is how UTF-8 is designed to be backward compatible with ASCII.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other Encodings&lt;/head&gt;
    &lt;p&gt;I did a quick research on any other encoding that are backward compatible with ASCII, and there are a few, but they are not as popular as UTF-8, for example GB 18030 (a Chinese government standard). Another one is the ISO/IEC 8859 encodings are single-byte encodings that extend ASCII to include additional characters, but they are limited to 256 characters.&lt;/p&gt;
    &lt;p&gt;The siblings of UTF-8, like UTF-16 and UTF-32, are not backward compatible with ASCII. For example, the letter 'A' in UTF-16 is represented as: &lt;code&gt;00 41&lt;/code&gt; (two bytes), while in UTF-32 it is represented as: &lt;code&gt;00 00 00 41&lt;/code&gt; (four bytes).&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus: UTF-8 Playground&lt;/head&gt;
    &lt;p&gt;When I was exploring the UTF-8 encoding, I couldn't find any good tool to interactively visualize how UTF-8 encoding works. So I built UTF-8 Playground to visualize and play around with UTF-8 encoding. Give it a try!.&lt;/p&gt;
    &lt;p&gt;Read the discussion on this on Hacker News.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45225098</guid></item><item><title>I used standard Emacs extension-points to extend org-mode</title><link>https://edoput.it/2025/04/16/emacs-paradigm-shift.html</link><description>&lt;doc fingerprint="8623c855a823bab8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Emacs: a paradigm shift&lt;/head&gt;
    &lt;p&gt;Recently I read this beginners guide to extend Emacs. The guide is perfect for starting out with elisp and it shows a lot of care in teaching how to interact with Emacs.&lt;/p&gt;
    &lt;p&gt;To me, the most important bit though is this one, from the section aptly named Emacs Wants You to Extend It.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I havenât written plugins for other editors extensively, but I can tell you this: emacs doesnât just make deep customization available, but it actively encourages you to make an absolute customization messes masterpieces. Core editor functions arenât just documented, but often include tidbits about âyou probably want to see this other variableâ or âhereâs how you should use thisâ.&lt;/p&gt;
      &lt;p&gt;Not only that, but emacs happily hands you functions shaped like nuclear warheads like advice-add (that let you override any function) that can absolutely obliterate your editor if you hold it the wrong way. Of course, this also grants you unlimited power.&lt;/p&gt;
      &lt;p&gt;Remember that emacs is designed to be torn apart and rearranged.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the core bit of the argument. Emacs, as a system, wants you to extend it and it gives you all the means to do so. This is in contrast with systems that can be extended through scripting and instead donât give you all the means to do so!&lt;/p&gt;
    &lt;p&gt;I think the tutorial is a fantastic example of doing things right. There is a well-thought example, a constructive approach where the solution grows to a full package.&lt;/p&gt;
    &lt;p&gt;This is problematic. You may get the impression that extending Emacs is only possible if you do things right and that is definitely not true.&lt;/p&gt;
    &lt;p&gt;To make my point I want to walk you through an example. I will show you how I used standard Emacs extension-points to extend org-mode to sort my reading lists automatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;What do I want?&lt;/head&gt;
    &lt;p&gt;The behavior I want is that when I save an org file the entries are ordered automatically. I keep a timeline of the papers I am reading and it is annoying to keep them kind of ordered.&lt;/p&gt;
    &lt;p&gt;This is the content of an example buffer.&lt;/p&gt;
    &lt;p&gt;When I add a paper to my reading list I run &lt;code&gt;org-sort-entries&lt;/code&gt; and
interactively select to order the entries by the value in the property
&lt;code&gt;year&lt;/code&gt;. Initally this was nice to have but now itâs just annoying that
I have to keep doing it. Letâs extend org-mode so that this is done automatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;A simple solution&lt;/head&gt;
    &lt;p&gt;The first step is to automate the interactive part. Lucky for me this is easy as &lt;code&gt;org-sort-entries&lt;/code&gt; is both a function and a command. I can call it in a
script just as I can run it as a command.&lt;/p&gt;
    &lt;p&gt;This solves one part of the problem. Letâs solve the other one, automatically calling &lt;code&gt;org-sort-run&lt;/code&gt; whenever an org-mode buffer is saved.&lt;/p&gt;
    &lt;p&gt;Emacs already has support for this use-case through the use of hooks. We can run &lt;code&gt;org-sort-run&lt;/code&gt; all the times we want to save a buffer.&lt;/p&gt;
    &lt;p&gt;These two together solve the problem but the solution presented is âjust more codeâ. We tapped into the hook extension point but this would be possible in any scriptable system that exposes well-defined extension points such as hooks and commands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Leveraging Emacsâ extensibility to extend org-mode&lt;/head&gt;
    &lt;p&gt;I want to show that even if something is not thought with extensibility in mind Emacs allow us to extend it. Most importantly, while we want to extend org-modeâs behavior we would like this not to be an extension to org-modeâs code.&lt;/p&gt;
    &lt;p&gt;Hereâs the updated problem statement. Have the buffer be automatically sorted and have the sorting criteria be in the buffer itself. We will specify the sorting as a in-buffer setting and use Emacs to support this never thought before org-mode behavior.&lt;/p&gt;
    &lt;p&gt;Our example buffer changes to the following.&lt;/p&gt;
    &lt;p&gt;The hard part of this is to find how org-mode reads in-buffer settings from the header. A M-x find-library later we are in orgâs sources.&lt;/p&gt;
    &lt;p&gt;Searching for &lt;code&gt;+STARTUP&lt;/code&gt; (Ctrl+s +STARTUP), one of the
supported settings, leads us to &lt;code&gt;org-startup-folded&lt;/code&gt; and that in turn
(Ctrl+s org-startup-folded) leads us to &lt;code&gt;org-startup-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;org-startup-options&lt;/code&gt; is the used by (again Ctrl+s org-startup-option)
&lt;code&gt;org-set-regexps-and-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;While the documentation for this function is not very convincing, its code does make sense for what we are after. I copied it here for reference.&lt;/p&gt;
    &lt;p&gt;Unfortunately this function calls &lt;code&gt;org-collect-keyword&lt;/code&gt; with a list that we cannot
touch. There is no custom variable to set to pass our own keyword.&lt;/p&gt;
    &lt;p&gt;If this was a ânormal programming environmentâ we would make our changes to this function body and forever maintain a fork of org-mode. As this is elisp instead we have choices.&lt;/p&gt;
    &lt;p&gt;I think the best choice is to use &lt;code&gt;advice-add&lt;/code&gt; and have Emacs call our
advice code every time &lt;code&gt;org-set-regexps-and-options&lt;/code&gt; is called. We will copy
what we need from the function body but that will be all.&lt;/p&gt;
    &lt;p&gt;This is what I ended up with.&lt;/p&gt;
    &lt;p&gt;We keep a buffer-local variable &lt;code&gt;org-sort-option&lt;/code&gt; around to store the
property name read from &lt;code&gt;#+SORT: property-name&lt;/code&gt;. This variable is initially
&lt;code&gt;nil&lt;/code&gt; and will be set from the property name in &lt;code&gt;#+SORT: property-name&lt;/code&gt;. To do so
we have a function &lt;code&gt;org-sort-set-option&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But when to call &lt;code&gt;org-sort-set-option&lt;/code&gt;? The easy way out is to have Emacs call it whenever
&lt;code&gt;org-set-regexps-and-options&lt;/code&gt; is called on a file visit. To achieve this we
tap into &lt;code&gt;advice-add&lt;/code&gt; and ask Emacs to run &lt;code&gt;org-sort-set-option&lt;/code&gt; after
&lt;code&gt;org-sort-regexps-and-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We have now succesfully interposed ourselves in the control flow of the org-mode library.&lt;/p&gt;
    &lt;p&gt;Org-mode did not provide any interposition point for us, there is no thought ahead etension-point or configuration variable we can use to achieve our goal an yet here we are with a sorted buffer.&lt;/p&gt;
    &lt;p&gt;We succeeded in our effort because Emacs wants you to extend it and it gives you all the means to do so.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;I have made a horrible hack and it works. I have learnt nothing about how org-mode works or Emacsâ file-visiting extension-points.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45226639</guid></item><item><title>Proton Mail suspended journalist accounts at request of cybersecurity agency</title><link>https://theintercept.com/2025/09/12/proton-mail-journalist-accounts-suspended/</link><description>&lt;doc fingerprint="efa383d70aa14e47"&gt;
  &lt;main&gt;
    &lt;p&gt;The company behind the Proton Mail email service, Proton, describes itself as a “neutral and safe haven for your personal data, committed to defending your freedom.”&lt;/p&gt;
    &lt;p&gt;But last month, Proton disabled email accounts belonging to journalists reporting on security breaches of various South Korean government computer systems following a complaint by an unspecified cybersecurity agency. After a public outcry, and multiple weeks, the journalists’ accounts were eventually reinstated — but the reporters and editors involved still want answers on how and why Proton decided to shut down the accounts in the first place.&lt;/p&gt;
    &lt;p&gt;Martin Shelton, deputy director of digital security at the Freedom of the Press Foundation, highlighted that numerous newsrooms use Proton’s services as alternatives to something like Gmail “specifically to avoid situations like this,” pointing out that “While it’s good to see that Proton is reconsidering account suspensions, journalists are among the users who need these and similar tools most.” Newsrooms like The Intercept, the Boston Globe, and the Tampa Bay Times all rely on Proton Mail for emailed tip submissions.&lt;/p&gt;
    &lt;p&gt;Shelton noted that perhaps Proton should “prioritize responding to journalists about account suspensions privately, rather than when they go viral.”&lt;/p&gt;
    &lt;p&gt;On Reddit, Proton’s official account stated that “Proton did not knowingly block journalists’ email accounts” and that the “situation has unfortunately been blown out of proportion.” Proton did not respond to The Intercept’s request for comment.&lt;/p&gt;
    &lt;p&gt;The two journalists whose accounts were disabled were working on an article published in the August issue of the long-running hacker zine Phrack. The story described how a sophisticated hacking operation — what’s known in cybersecurity parlance as an APT, or advanced persistent threat — had wormed its way into a number of South Korean computer networks, including those of the Ministry of Foreign Affairs and the military Defense Counterintelligence Command, or DCC.&lt;/p&gt;
    &lt;p&gt;The journalists, who published their story under the names Saber and cyb0rg, describe the hack as being consistent with the work of Kimsuky, a notorious North Korean state-backed APT sanctioned by the U.S. Treasury Department in 2023.&lt;/p&gt;
    &lt;p&gt;As they pieced the story together, emails viewed by The Intercept show that the authors followed cybersecurity best practices and conducted what’s known as responsible disclosure: notifying affected parties that a vulnerability has been discovered in their systems prior to publicizing the incident.&lt;/p&gt;
    &lt;p&gt;Saber and cyb0rg created a dedicated Proton Mail account to coordinate the responsible disclosures, then proceeded to notify the impacted parties, including the Ministry of Foreign Affairs and the DCC, and also notified South Korean cybersecurity organizations like the Korea Internet and Security Agency, and KrCERT/CC, the state-sponsored Computer Emergency Response Team. According to emails viewed by The Intercept, KrCERT wrote back to the authors, thanking them for their disclosure.&lt;/p&gt;
    &lt;p&gt;A note on cybersecurity jargon: CERTs are agencies consisting of cybersecurity experts specializing in dealing with and responding to security incidents. CERTs exist in over 70 countries — with some countries having multiple CERTs each specializing in a particular field such as the financial sector — and may be government-sponsored or private organizations. They adhere to a set of formal technical standards, such as being expected to react to reported cybersecurity threats and security incidents. A high-profile example of a CERT agency in the U.S. is the Cybersecurity and Infrastructure Agency, which has recently been gutted by the Trump administration.&lt;/p&gt;
    &lt;p&gt;A week after the print issue of Phrack came out, and a few days before the digital version was released, Saber and cyb0rg found that the Proton account they had set up for the responsible disclosure notifications had been suspended. A day later, Saber discovered that his personal Proton Mail account had also been suspended. Phrack posted a timeline of the account suspensions at the top of the published article, and later highlighted the timeline in a viral social media post. Both accounts were suspended owing to an unspecified “potential policy violation,” according to screenshots of account login attempts reviewed by The Intercept.&lt;/p&gt;
    &lt;p&gt;The suspension notice instructed the authors to fill out Proton’s abuse appeals form if they believed the suspension was in error. Saber did so, and received a reply from a member of Proton Mail’s Abuse Team who went by the name Dante.&lt;/p&gt;
    &lt;p&gt;In an email viewed by The Intercept, Dante told Saber that their account “has been disabled as a result of a direct connection to an account that was taken down due to violations of our terms and conditions while being used in a malicious manner.” Dante also provided a link to Proton’s terms of service, going on to state, “We have clearly indicated that any account used for unauthorized activities, will be sanctioned accordingly.” The response concluded by stating, “We consider that allowing access to your account will cause further damage to our service, therefore we will keep the account suspended.”&lt;/p&gt;
    &lt;p&gt;On August 22, a Phrack editors reached out to Proton, writing that no hacked data was passed through the suspended email accounts, and asked if the account suspension incident could be deescalated. After receiving no response from Proton, the editor sent a follow-up email on September 6. Proton once again did not reply to the email.&lt;/p&gt;
    &lt;p&gt;On September 9, the official Phrack X account made a post asking Proton’s official account asking why Proton was “cancelling journalists and ghosting us,” adding: “need help calibrating your moral compass?” The post quickly went viral, garnering over 150,000 views.&lt;/p&gt;
    &lt;p&gt;Proton’s official account replied the following day, stating that Proton had been “alerted by a CERT that certain accounts were being misused by hackers in violation of Proton’s Terms of Service. This led to a cluster of accounts being disabled. Our team is now reviewing these cases individually to determine if any can be restored.” Proton then stated that they “stand with journalists” but “cannot see the content of accounts and therefore cannot always know when anti-abuse measures may inadvertently affect legitimate activism.”&lt;/p&gt;
    &lt;p&gt;Proton did not publicly specify which CERT had alerted them, and didn’t answer The Intercept’s request for the name of the specific CERT which had sent the alert. KrCERT also did not reply to The Intercept’s question about whether they were the CERT that had sent the alert to Proton.&lt;/p&gt;
    &lt;p&gt;Later in the day, Proton’s founder and CEO Andy Yen posted on X that the two accounts had been reinstated. Neither Yen nor Proton explained why the accounts had been reinstated, whether they had been found to not violate the terms of service after all, why had they been suspended in the first place, or why a member of the Proton Abuse Team reiterated that the accounts had violated the terms of service during Saber’s appeals process.&lt;/p&gt;
    &lt;p&gt;Phrack noted that the account suspensions created a “real impact to the author. The author was unable to answer media requests about the article.” The co-authors, Phrack pointed out, were also in the midst of the responsible disclosure process and working together with the various affected South Korean organizations to help fix their systems. “All this was denied and ruined by Proton,” Phrack stated.&lt;/p&gt;
    &lt;p&gt;Phrack editors said that the incident leaves them “concerned what this means to other whistleblowers or journalists. The community needs assurance that Proton does not disable accounts unless Proton has a court order or the crime (or ToS violation) is apparent.”&lt;/p&gt;
    &lt;p&gt;IT’S EVEN WORSE THAN WE THOUGHT.&lt;/p&gt;
    &lt;p&gt;What we’re seeing right now from Donald Trump is a full-on authoritarian takeover of the U.S. government.&lt;/p&gt;
    &lt;p&gt;This is not hyperbole.&lt;/p&gt;
    &lt;p&gt;Court orders are being ignored. MAGA loyalists have been put in charge of the military and federal law enforcement agencies. The Department of Government Efficiency has stripped Congress of its power of the purse. News outlets that challenge Trump have been banished or put under investigation.&lt;/p&gt;
    &lt;p&gt;Yet far too many are still covering Trump’s assault on democracy like politics as usual, with flattering headlines describing Trump as “unconventional,” “testing the boundaries,” and “aggressively flexing power.”&lt;/p&gt;
    &lt;p&gt;The Intercept has long covered authoritarian governments, billionaire oligarchs, and backsliding democracies around the world. We understand the challenge we face in Trump and the vital importance of press freedom in defending democracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;We’re independent of corporate interests. Will you help us?&lt;/head&gt;
    &lt;head rend="h2"&gt;Latest Stories&lt;/head&gt;
    &lt;head rend="h3"&gt;China Didn’t Want You to See This Video of Xi and Putin. So Reuters Deleted It.&lt;/head&gt;
    &lt;p&gt;Following a copyright takedown request, Reuters removed a hot mic video of Putin and Xi discussing life extension and immortality.&lt;/p&gt;
    &lt;head rend="h3"&gt;Alex Karp Insists Palantir Doesn’t Spy on Americans. Here’s What He’s Not Saying.&lt;/head&gt;
    &lt;p&gt;Documents from Edward Snowden published by The Intercept in 2017 show the NSA’s use of Palantir technology.&lt;/p&gt;
    &lt;p&gt;Israel’s War on Gaza&lt;/p&gt;
    &lt;head rend="h3"&gt;Gaza Aid Security Contractor Hired Members of “Islamophobic Hate Group” Biker Club, Dem Rep Says&lt;/head&gt;
    &lt;p&gt;At least 10 members of the Infidels worked in Gaza for GHF’s security contractor, the BBC reported, with seven in oversight roles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45226903</guid></item><item><title>Show HN: Aris – a free AI-powered answer engine for kids</title><link>https://www.aris.chat</link><description>&lt;doc fingerprint="d24af2affe8d7e07"&gt;
  &lt;main&gt;
    &lt;p&gt;New Home Sign In Just ask Aris.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45227134</guid></item><item><title>FFglitch, FFmpeg fork for glitch arch</title><link>https://ffglitch.org/gallery/</link><description>&lt;doc fingerprint="e6873f908bba35f1"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Gallery&lt;/head&gt;
    &lt;p&gt;There are some artists out there doing some amazing work using FFglitch.&lt;/p&gt;
    &lt;p&gt;I put this page up so that I donât have to go hunting for examples every time I want to show someone what can be done with FFglitch.&lt;/p&gt;
    &lt;p&gt;Thomas Collet has a lot of work using FFglitch on vimeo, instagram, and reddit.&lt;/p&gt;
    &lt;p&gt;A bunch more from Thomas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://vimeo.com/366067869&lt;/item&gt;
      &lt;item&gt;https://vimeo.com/363105562&lt;/item&gt;
      &lt;item&gt;https://vimeo.com/323235580&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/b9yfxc/study_on_crowd_movements/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/brokengifs/comments/grpwn4/tripping_in_manhattan/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/woahdude/comments/bg176f/i_went_to_ireland_filmed_the_ocean_and_glitched_it/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/woahdude/comments/ballm7/when_the_world_is_slowly_but_surely_falling_appart/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/fhpwgp/falling_appart/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/hxk6r1/when_it_kicks_in_the_middle_of_time_square/&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Kaspar Ravel wrote a blog post about a collaboration he did with Thomas Collet which resulted in this gem:&lt;/p&gt;
    &lt;p&gt;Hereâs the blog post: https://www.kaspar.wtf/blog/encoding-the-game-of-life-in-datamosh&lt;/p&gt;
    &lt;p&gt;And the post on reddit: https://www.reddit.com/r/brokengifs/comments/e25f6b/want_to_see_a_magic_trick/&lt;/p&gt;
    &lt;p&gt;glit_chbee (turn the volume up and enjoy the ride):&lt;/p&gt;
    &lt;p&gt;Ben Cooper made this clip by using mainly avidemux, tomato.py, and FFglitch.&lt;/p&gt;
    &lt;p&gt;Jo Grys has posted some videos on Facebook:&lt;/p&gt;
    &lt;p&gt;There are more if you search for #ffglitch on Facebook:&lt;/p&gt;
    &lt;p&gt;And some more random clips I found spread around the interwebz:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45227212</guid></item><item><title>Tips for installing Windows 98 in QEMU/UTM</title><link>https://sporks.space/2025/08/28/tips-for-installing-windows-98-in-qemu-utm/</link><description>&lt;doc fingerprint="269ee85e392235d4"&gt;
  &lt;main&gt;
    &lt;p&gt;Windows 98 runs surprisingly well in QEMU via UTM SE, but it requires some care in setting it up. It’s a great way to run old 90s Windows and DOS software on your iPad (and Mac too, though you have other options available to you, or an iPhone if you don’t mind the HID difficulties).&lt;/p&gt;
    &lt;p&gt;This post provides some suggestions and tips for installing Windows and selecting the best emulated devices. The guidance is intended for UTM users on Apple platforms, but should apply to anything QEMU based (or QEMU itself). The advice might also be useful for other operating systems in UTM/QEMU as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Plug and play BIOS issues (or: how to install with ACPI)&lt;/head&gt;
    &lt;p&gt;When you install Windows 9x, PCI devices might be broken, and you’ll see a Plug and Play BIOS device with problems in the device manager:&lt;/p&gt;
    &lt;p&gt;This seems to be a bug in SeaBIOS or QEMU; I haven’t yet seen an issue tracking this. Many guides (i.e. this one or this one) suggest changing the device and hoping devices re-enumerate correctly. However, there’s a simpler method available when using Windows 98 SE. (If you’re using Windows 95, you won’t be able to do this.)&lt;/p&gt;
    &lt;p&gt;Windows 98 can use ACPI to enumerate devices instead of the legacy PnP BIOS. Unfortunately, it doesn’t use ACPI by default. (There seems to be an allowlist of known good ACPI BIOSes, as it was early days for ACPI.) To make it use ACPI anyways, boot with CD-ROM support from the Windows 98 CD instead of running the installer, then run Windows setup with the &lt;code&gt;/p j&lt;/code&gt; flag, like so:&lt;/p&gt;
    &lt;code&gt;C:\&amp;gt; D:
D:\&amp;gt; cd WIN98
D:\WIN98&amp;gt; setup /p j&lt;/code&gt;
    &lt;p&gt;It’s possible to convert an existing system to ACPI, but it’s much easier to do this from the start. When Windows is installed this way, it should correctly enumerate all devices.&lt;/p&gt;
    &lt;head rend="h2"&gt;Device selection&lt;/head&gt;
    &lt;head rend="h3"&gt;System&lt;/head&gt;
    &lt;p&gt;QEMU can emulate devices Windows 98 supports out of the box, which is good as there are no VirtIO drivers. Make sure you’re using the i440-based “&lt;code&gt;pc&lt;/code&gt;” rather than the Q35 based system, as it’ll be better supported for legacy systems. You don’t need to worry about selecting i386 vs. x86_64, as Windows 98 will obviously never touch 64-bit mode, so they’ll be the same.&lt;/p&gt;
    &lt;p&gt;(As a tip, if you’re running NT 4, you’ll need to select a different CPU to make sure it’s happy with the CPU flags as the default one is too new. A Pentium II should be sufficiently old.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Input&lt;/head&gt;
    &lt;p&gt;You may need to disable USB (or at least, USB input devices) to avoid hanging on startup, at least with UTM (It’s possible the ‘Force PS/2 Controller’ option might work, but I haven’t had much luck with it. Unfortunately, this means you won’t have absolute mouse input (through the USB tablet) and must capture your cursor. With UTM SE on an iPad, this doesn’t hurt as much, as it can automatically capture the trackpad or external mouse, while leaving the touchscreen for interacting with iOS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Video&lt;/head&gt;
    &lt;p&gt;The most sensible video option for Windows 98 is the Cirrus VGA (&lt;code&gt;-vga cirrus&lt;/code&gt;). There are unfortunately some bugs (flashing in 16 bit colour modes, blitting issues in 8 bit colour modes), but it’s the only option with accelerated drivers out of the box. (Of course, there is no 3D acceleration with such a card.)&lt;/p&gt;
    &lt;p&gt;Apparently, Rage 128 emulation is being worked on (&lt;code&gt;ati-vga&lt;/code&gt;), but currently only works for Power Mac emulation, and is in rough shape so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Networking and getting files in&lt;/head&gt;
    &lt;p&gt;For getting files into the VM easily, you’ll want a network. SLiRP NAT works fine for using a browser or SMB shares, for example. (Note this works better on Windows 98 than 95; 95 has issues with mounting SMB shares by IP and doesn’t come with a browser.) QEMU can emulate a variety of network cards. The tulip (DC2114x), NE2000 (PCI and ISA), and PCNet should all work out of the box with older Windows. I’d recommend using a PCI card if possible, since it saves you the ISA setup headache unless you need it for something old. If you do need to set up an ISA NE2000, it’s at address 300h, IRQ 9, which might require manual configuration in some cases.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sound&lt;/head&gt;
    &lt;p&gt;For sound hardware, there are a few options available, with different tradeoffs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you want to run DOS software, the SoundBlaster 16 (&lt;code&gt;sb16&lt;/code&gt;) emulation works out of the box, but there is no OPL3 or MPU-401, so MIDI won’t work correctly, just PCM. Games will have a hard time with this unless they’re entirely PCM. For setting up your SB16 for DOS games, use&lt;code&gt;SET BLASTER=A220 I5 D1 H5 P330 T5&lt;/code&gt;(that’s address 220h, interrupt 5, 8-bit DMA 1, our non-existent MPU-401 at 330h, 16-bit DMA 5).&lt;list rend="ul"&gt;&lt;item&gt;Note that QEMU supports adding an AdLib (OPL2 based) separately, which might help with some software.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The CS4321A I haven’t tested, but might work with WSS or Crystal-specific drivers. As with the SoundBlaster 16, there is no OPL3. QEMU sets this up at 534h, IRQ 9, DMA 3.&lt;/item&gt;
      &lt;item&gt;The Gravis UltraSound (&lt;code&gt;gus&lt;/code&gt;) emulation works surprisingly well, but the Windows 95 drivers are crusty for the version of the card it emulates (GF1/GUS Classic), so use it only if you want to run old trackers or demoscene stuff. Note you may need to turn off the LPT port (&lt;code&gt;-parallel none&lt;/code&gt;) to free up an interrupt used for the UltraSound.&lt;/item&gt;
      &lt;item&gt;Because of this, the ES1370 might be the best card to emulate for plain Windows usage, as it has relatively few quirks and I believe has drivers on the Windows 98 CD. However, it’s not ideal for DOS software as it requires TSRs to make it work right.&lt;/item&gt;
      &lt;item&gt;The AC97 emulation will require Realtek drivers. I haven’t tested this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Potpourri&lt;/head&gt;
    &lt;p&gt;In UTM, you may want to turn off the entropy device, to reduce unknown device clutter in Device Manager, though it’s harmless. The VirtIO console device will still be present in Device Manager with UTM’s default flags.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other quirks&lt;/head&gt;
    &lt;p&gt;In UTM SE, sometimes rebooting might hang when switching video modes. If this happens, it seems safe to shut down the machine and start it again. Avoiding reboots in favour of shutting down seems wise.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance characteristics&lt;/head&gt;
    &lt;p&gt;While TCG in QEMU doesn’t have the best reputation for performance, it might be good enough for your needs. On my MacBook Pro with an M1 Pro, benchmarks show performance somewhat around about a 750 MHz Pentium III, albeit with worse floating point performance. This is pretty usable, although most 3D games won’t be usable as even software rendering will be a bit sketchy.&lt;/p&gt;
    &lt;p&gt;If you’re using UTM SE on iOS, the interpreter is slower, but not unusable for 90s software. On my M1 iPad Pro, I get Pentium 100 performance, with similar penalties for FP. This is good for games up to about 1995 or 1996; titles like MechWarrior 2, Widget Workshop, many edutainment titles, and SimCity 2000 are playable this way, though MIDI or CD music will be missing. Non-game software like Office 97 or Visual C++ will run fine, of course. For OSes, this also puts things like Windows 2000 and beyond just out of reach performance wise – stick with Windows 98 for the best compatibility.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45227749</guid></item><item><title>Meow: Yet another modal editing on Emacs</title><link>https://github.com/meow-edit/meow</link><description>&lt;doc fingerprint="b35c4579181b4ef9"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Less is more&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Meow is yet another modal editing mode for Emacs.&lt;/p&gt;
    &lt;p&gt;Meow aims to blend modal editing into Emacs with minimal interference with its original key-bindings, avoiding most of the hassle introduced by key-binding conflicts. This leads to lower necessary configuration and better integration. More is achieved with fewer commands to remember.&lt;/p&gt;
    &lt;p&gt;Key features compared to existing solutions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Minimal configuration – build your own modal editing system&lt;/item&gt;
      &lt;item&gt;No third-party dependencies (try it without touching your configuration)&lt;/item&gt;
      &lt;item&gt;Doesn’t occupy too many keys &lt;list rend="ul"&gt;&lt;item&gt;Much easier to remember for people trying modal editing&lt;/item&gt;&lt;item&gt;More keys available for your own key-bindings&lt;/item&gt;&lt;item&gt;Most of the time, you don’t even need to hold shift!&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Lightning fast (unlike Evil)&lt;/item&gt;
      &lt;item&gt;Minimizes modifier usage (e.g. &lt;code&gt;SPC x f&lt;/code&gt;for&lt;code&gt;C-x C-f&lt;/code&gt;) inspired by god-mode&lt;/item&gt;
      &lt;item&gt;Better workflow for kmacro application at multiple locations&lt;/item&gt;
      &lt;item&gt;Interactive selection manipulation and expansion inspired by avy&lt;/item&gt;
      &lt;item&gt;Selection as top-tier object, and keybindings built around selection&lt;/item&gt;
      &lt;item&gt;Compatible with the vanilla Emacs keymap (or any other keymap from any package)&lt;/item&gt;
      &lt;item&gt;Effortless uniform keymaps across modes&lt;/item&gt;
      &lt;item&gt;Key-binding conflict handling made easy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please feel free to ask questions and share ideas at&lt;/p&gt;
    &lt;p&gt;Get started - Installation and configuration&lt;/p&gt;
    &lt;p&gt;Tutorial - Learn Meow in 15 minutes&lt;/p&gt;
    &lt;p&gt;FAQ - Frequently Asked Questions&lt;/p&gt;
    &lt;p&gt;Commands - Documentation for commands&lt;/p&gt;
    &lt;p&gt;Customizations - Helper functions and variables&lt;/p&gt;
    &lt;p&gt;Explanation - Ideas and concepts behind Meow&lt;/p&gt;
    &lt;p&gt;Changelog - Changes, releases, and news&lt;/p&gt;
    &lt;p&gt;Licensed under GPLv3.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45228396</guid></item><item><title>Life, work, death and the peasant: Rent and extraction</title><link>https://acoup.blog/2025/09/12/collections-life-work-death-and-the-peasant-part-ivc-rent-and-extraction/</link><description>&lt;doc fingerprint="662891573de14ffd"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the third piece of the fourth part of our series (I, II, IIIa, IIIb, IVa, IVb) looking at the lives of pre-modern peasant farmers – a majority of all of the humans who have ever lived. Last time, we started looking at the subsistence of peasant agriculture by considering the productivity of our model farming families under basically ideal conditions: relatively good yields and effectively infinite land.&lt;/p&gt;
    &lt;p&gt;This week we’re going to start peeling back those assumptions in light of the very small farm-sizes and capital availability our pre-modern peasants had. Last week we found that, assuming effectively infinite land and reasonably high yields, our farmers produced enough to maintain their households fairly securely in relative comfort, with enough surplus over even their respectability needs to potentially support a small population of non-farmers. But of course land isn’t infinite and also isn’t free and on top of that, the societies in which our peasant farmers live are often built to extract as much surplus from the peasantry as possible.&lt;/p&gt;
    &lt;p&gt;But first, if you like what you are reading, please share it and if you really like it, you can support this project on Patreon! While I do teach as the academic equivalent of a tenant farmer, tilling the Big Man’s classes, this project is my little plot of freeheld land which enables me to keep working as a writers and scholar. And if you want updates whenever a new post appears, you can click below for email updates or follow me on Twitter and Bluesky and (less frequently) Mastodon (@bretdevereaux@historians.social) for updates when posts go live and my general musings; I have largely shifted over to Bluesky (I maintain some de minimis presence on Twitter), given that it has become a much better place for historical discussion than Twitter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Land Holdings&lt;/head&gt;
    &lt;p&gt;Returning to where we left off last week, we found that our model families could comfortably exceed their subsistence and ‘respectability’ needs with the labor they had assuming they had enough land (and other capital) to employ all of their available farming labor. However, attentive readers will have noticed that the labor of these families could work a lot of land: 30.5 acres for The Smalls, 33.6 acres for The Middles and 56 acres for The Biggs. That may not seem large by the standards of modern commercial farms, but few peasants had anything like such large landholdings; even rich peasants rarely owned so much.&lt;/p&gt;
    &lt;p&gt;We might compare, for instance, the land allotments of Macedonian and Greek military settlers in the Hellenistic kingdoms (particularly Egypt, where our evidence is good). These settlers were remarkably well compensated, because part of what the Hellenistic kings are trying to do is create a new class of Greco-Macedonian rentier-elites1 as a new ethnically defined military ruling-class which would support their new monarchies. In Egypt, where we can see most clearly, infantrymen generally received 25 or 30 arourai (17 or 20.4 acres), while cavalrymen, socially higher up still, generally received 100 arourai (68 acres).2 That infantry allotment is still anywhere from two thirds to less than half of what our model families can farm and yet was still large enough, as far as we can tell, to enable Ptolemaic Greco-Macedonian soldiers to live as rentier-elites, subsisting primarily if not entirely off of rents and the labor of others.3&lt;/p&gt;
    &lt;p&gt;Alternately, considering late medieval Europe through the study of Saint-Thibery,4 out of 189 households in 1460 in the village just fifteen households are in the same neighborhood of landholdings as the Smalls’ 33.6 acres above (so roughly 55 setérée and up)5 only six as much as The Biggs (about 90 setérée and up). In short our assessment so far has assumed our families are extremely rich peasants. But of course they almost certainly are not!&lt;/p&gt;
    &lt;p&gt;Instead, as we noted in our first part, the average size of peasant landholdings was extremely small. Typical Roman landholdings were around 5-10 iugera (3.12-6.23 acres), in wheat-farming pre-Han northern China roughly 100 mu (4.764 acres), in Ptolemaic Egypt (for the indigenous, non-elite population) probably 5-10 aroura (3.4-6.8 acres) and so on.6 In Saint-Thibery in Languedoc, the average (mean) farm size was about 24 setérée (~14.5 acres) but the more useful median farm size was just five setérée (~3 acres); the average is obviously quite distorted by the handful of households with hundreds of setérée of land.&lt;/p&gt;
    &lt;p&gt;So we might test three different farm sizes; once again, I am going to use Roman units because that’s how I am doing my background math. We might posit a relatively a poor household farm of roughly three iugera (1.85 acres). In Saint-Thibery, 68 of the 189 households (36%) had land holdings this small or smaller, so this is not an unreasonable ‘poor household’ – indeed, we could posit much poorer, but then we’re really just talking about tenant farmers, rather than freeholding peasants. Next, we can posit a moderate household farm of roughly six iugera (3.8 acres); reasonably close to the median holding in Saint-Thibery and roughly what we think of as the lower-bound for ancient citizen-soldier-peasants. Finally, we can posit a large household farm of nine iugera (5.6 acres), reflective of what seems to be the upper-end of typical for those same citizen-soldier-peasants; at Saint-Thibery in 1460 there were a couple dozen families seemingly in this range.7&lt;/p&gt;
    &lt;p&gt;For the sake of a relatively easier calculation, we can assume the same balance of wheat, barley and beans as last time, which lets us just specify an average yield after seed per iugerum of 81.2-189.5 kg of wheat equivalent (achieved by averaging the per-acre wheat equivalent production across all three crops, with seed removed),8 with each iugerum demanding between 11 and 15 working days (averaging the labor requirements across all three crops). Finally, we need to remember the fallow: in this case we’re assuming about a third of each farm is not in production in any given year, meaning it is both not consuming any labor nor producing any crops. That lets us then quickly chart out our peasant families based on the land they might actually have (keeping in mind the household size and household land holdings aren’t going to match; the larger household in people won’t always be the one with more land). First, a reminder of the basic labor availability and grain requirements of our households.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;The Smalls&lt;/cell&gt;
        &lt;cell&gt;The Middles&lt;/cell&gt;
        &lt;cell&gt;The Biggs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor Available&lt;/cell&gt;
        &lt;cell&gt;435 work-days&lt;/cell&gt;
        &lt;cell&gt;507.5 work-days&lt;/cell&gt;
        &lt;cell&gt;797.5 work-days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Bare Subsistence Requirement&lt;/cell&gt;
        &lt;cell&gt;~1,189.5kg wheat-equivalent&lt;/cell&gt;
        &lt;cell&gt;~1,569kg wheat-equivalent&lt;/cell&gt;
        &lt;cell&gt;~2,686kg wheat-equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Respectability Requirement&lt;/cell&gt;
        &lt;cell&gt;~2,379kg wheat-equivalent&lt;/cell&gt;
        &lt;cell&gt;~3,138kg wheat-equivalent&lt;/cell&gt;
        &lt;cell&gt;~5,376kg wheat-equivalent&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Then for the smallest, 3 iugera farm, the numbers work like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Small Farm (3 iugera)&lt;p&gt;2 iugera cropped&lt;/p&gt;&lt;p&gt;1 fallow&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;The Smalls&lt;/cell&gt;
        &lt;cell&gt;The Middles&lt;/cell&gt;
        &lt;cell&gt;The Biggs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor requirement&lt;/cell&gt;
        &lt;cell&gt;22-30 work days&lt;/cell&gt;
        &lt;cell&gt;22-30 work days&lt;/cell&gt;
        &lt;cell&gt;22-30 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor surplus&lt;/cell&gt;
        &lt;cell&gt;405-413 work days&lt;/cell&gt;
        &lt;cell&gt;477.5-485.5 work days&lt;/cell&gt;
        &lt;cell&gt;767.5-775.5 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Production after Seed&lt;/cell&gt;
        &lt;cell&gt;162.4-378.8kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;162.4-378.8kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;162.4-378.8kg wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Percentage of Subsistence:&lt;/cell&gt;
        &lt;cell&gt;14-32%&lt;/cell&gt;
        &lt;cell&gt;10-24%&lt;/cell&gt;
        &lt;cell&gt;6-14%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And then for the medium-sized farm:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Medium Farm (6 iugera)&lt;p&gt;4 iugera cropped&lt;/p&gt;&lt;p&gt;2 fallow&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;The Smalls&lt;/cell&gt;
        &lt;cell&gt;The Middles&lt;/cell&gt;
        &lt;cell&gt;The Biggs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor requirement&lt;/cell&gt;
        &lt;cell&gt;44-60 work days&lt;/cell&gt;
        &lt;cell&gt;44-60 work days&lt;/cell&gt;
        &lt;cell&gt;44-60 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor surplus&lt;/cell&gt;
        &lt;cell&gt;375-391 work days&lt;/cell&gt;
        &lt;cell&gt;447.5-463.5 work days&lt;/cell&gt;
        &lt;cell&gt;737.5-753.5 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Production after Seed&lt;/cell&gt;
        &lt;cell&gt;324.8-757.6kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;324.8-757.6kg wheat equivalent&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;324.8-757.6kg wheat equivalent&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Percentage of Subsistence:&lt;/cell&gt;
        &lt;cell&gt;27-64%&lt;/cell&gt;
        &lt;cell&gt;21-48%&lt;/cell&gt;
        &lt;cell&gt;12-28%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And the larger (but not rich peasant) farm:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Large Farm (9 iugera)&lt;p&gt;6 iugera cropped&lt;/p&gt;&lt;p&gt;3 fallow&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;The Smalls&lt;/cell&gt;
        &lt;cell&gt;The Middles&lt;/cell&gt;
        &lt;cell&gt;The Biggs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor requirement&lt;/cell&gt;
        &lt;cell&gt;66-90 work days&lt;/cell&gt;
        &lt;cell&gt;66-90 work days&lt;/cell&gt;
        &lt;cell&gt;66-90 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor surplus&lt;/cell&gt;
        &lt;cell&gt;345-369 work days&lt;/cell&gt;
        &lt;cell&gt;417.5-441.5 work days&lt;/cell&gt;
        &lt;cell&gt;707.5-731.5 work days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Production after Seed&lt;/cell&gt;
        &lt;cell&gt;487.6-1,136.5kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;487.6-1,136.5k wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;487.6-1,136.5k wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Percentage of Subsistence:&lt;/cell&gt;
        &lt;cell&gt;41-96%&lt;/cell&gt;
        &lt;cell&gt;31-72%&lt;/cell&gt;
        &lt;cell&gt;18-42%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And we immediately see the problem: only the Smalls manage to get close to subsistence on very favorable (8:1) fertility assumptions on the small farm they own. Now it is possible for the peasants to push a little bit on these numbers. The most obvious way would be focusing as much as possible on wheat cultivation, which has higher labor demands but also the highest yield-per-acre (or iugerum), producing around 50% more calories than beans and 35% more calories than barley per-acre (see last week’s post for specifics). But there’s a limit to going ‘all in’ on wheat to meet food shortfalls: the land might not be suitable for it and wheat exhausts the soil, so our farmers would need some sort of rotation. That said, peasant diets were overwhelmingly grains (wheat and barley) for this reason: they provide the most calories for a favorable balance of land and labor. Our farmers might also try to supplement production with high-labor, high-density horticulture; a kitchen garden can take a lot of work but produce a lot of nutrition in a small space. But hitting household nutrition demands entirely with a kitchen garden isn’t going to work both because of the labor demands but also because the products of a kitchen garden tend not to keep well.&lt;/p&gt;
    &lt;p&gt;Instead the core problem is that our peasant households are much too large as units of labor for the farmland they own. When we say that, what we mean is that given these households are both units of consumption (they have to provide for their members) and units of production (they are essentially agricultural small businesses), an efficient allocation of them would basically have each household on something like 30 acres of farmland, farming all of it (and thus using most of their labor) and selling the excess. But the lack of economically sustainable social niches – that is, jobs that provide a reliable steady income to enable someone to obtain subsistence – means that these families are very reluctant to leave members without any land at all, so the holdings ‘fractionalize’ down to these tiny units, essentially the smallest units that could conceivably support one family (and sometimes not even that).&lt;/p&gt;
    &lt;p&gt;I’ve already seen folks in the comments realizing almost immediately why these conditions might make conquest or resettlement into areas of land easily brought under cultivation so attraction: if you could give each household 30-40 acres instead of 3-6, you could realize substantial improvements in quality of life (and the social standing of the farmers in question). And of course that kind of ‘land scarcity’ problem seems to have motivated both ancient and early modern settler-colonialism: if you put farmers next to flat, open ground owned by another community, it won’t be too long before they try to make it farmland (violently expelling the previous owners in the process). This is also, I might add, part of the continual friction in areas where nomads and farmers meet: to a farmer, those grazing fields look like more land and more land is really valuable (though the response to getting new land is often not to create a bunch of freeholding large-farm homesteaders, but rather to replicate the patterns of tenancy and non-free agricultural labor these societies already have to the point of – as in the Americas – forcibly trafficking enormous numbers of enslaved laborers at great cost, suffering and horror, to create a non-free dependent class whose exploitation can enable those patterns. Most conquering armies dream of becoming landlords, not peasants).9&lt;/p&gt;
    &lt;p&gt;Alternately as farms these holdings could be a lot more efficient if they had fewer people on them and indeed when we read, for instance, ancient agricultural writers, they recommend estates with significantly fewer laborers per-unit-land-area than what we’d see in the peasant countryside. But that’s because the Big Man is farming for profit with a large estate that lets him tailor his labor force fairly precisely to his labor needs; the peasants are farming to survive and few people are going to let their brother, mother, or children starve and die in a ditch because it makes their farm modestly more productive per unit labor. Instead, they’re going try to do anything in their power to get enough income to have enough food for their entire family to survive.&lt;/p&gt;
    &lt;p&gt;There is no real way around it: our peasants need access to more land. And that land is going to come with conditions.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Man’s Land&lt;/head&gt;
    &lt;p&gt;Now before we march into talking about farming someone else’s land, it is worth exploring why our farmers don’t get more land by just bringing more land under cultivation. And the answer here is pretty simple: in most of the world, preparing truly ‘wild’ land for cultivation takes a lot of labor. In dry areas, that labor often comes in the form of irrigation demands: canals have to be dug out from water sources (mainly rivers) to provide enough moisture for the fields as the most productive crops (like wheat) demand a lot of moisture to grow well. In climates suitable for rainfall agriculture, the problem is instead generally forests: if there’s enough rain to grow grain, there’s enough rain to grow trees and those trees have had quite the head start on you. Clearing large sections of forest by land is a slow, labor-intensive thing and remember, you don’t just need the trees cut down, you need the stumps pulled or burned. Fields also need to be relatively flat – which might demand terracing on hilly terrain – and for the sake of the plow they need to be free of large stones to the depth of the plow (at least a foot or so).&lt;/p&gt;
    &lt;p&gt;In short, clearing farmland was both slow and expensive and all of this assumes the land can be made suitable and that no one has title to it. Of course if the forest is the hunting preserve of the local elite, they’re going to object quite loudly to your efforts to cut it down. And a lot of land is simply going to be too dry or too hilly or too marshy to be made usable for farming ona practical time-scale for our peasants. Such land simply cannot be brought usefully into cultivation; you can’t farm wheat in a swamp.10 So it is quite hard and often impractical to bring new land into cultivation.&lt;/p&gt;
    &lt;p&gt;That doesn’t mean new land wasn’t brought into cultivation, it absolutely was. We can sometimes track population pressures archaeologically by watching this process: forests retreat, new villages pop up, swamps are drained and so on as previously marginal or unfarmable land is brought into cultivation. Note, of course, if you bring a bunch of marginal fields into cultivation – say, a drier hillside not worth farming before – your average yield is going to go down because that land simply isn’t as productive (but demands the same amount of labor!). But that process is generally slow, taking place over generations in response to population pressures. It isn’t a solution available on the time-scale that most of our households are operating. In the moment, the supply of land is mostly fixed for our peasants.&lt;/p&gt;
    &lt;p&gt;Which means our peasants need access to more land (or another way of generating income). There are a range of places that land could come from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Peasant Households without enough labor to farm their own land. In order to make our households relevant at every part of the process, I haven’t modeled the substantial number of very small households we talked about in the first section, households with just 1 or 2 members. If none of those householders were working-age males (e.g. a household with an elderly widow, or a young widow and minor children, etc.) they might seek to have other villagers help farm their land and split the production. For very small households, that might be enough to provide them subsistence (or at least help). Consequently those small, often ‘dying’ households provide a (fairly small) source of land for other households.&lt;/item&gt;
      &lt;item&gt;Rich peasants likewise might have more land than their household could farm or cared to farm. Consider the position The Smalls would be if they were a rich peasant household with, say, 25 acres of land (in Saint-Thibery, 26 households (of 189) had this much or more land). That’s enough land that, under good harvest conditions it would be easy enough to shoot past the household’s respectability requirements. At which point why work so hard? Why not sharecrop out a large chunk of your land to small farmers and split the production, so you still make your respectability basket in decent years, but don’t have to work so darn hard?&lt;/item&gt;
      &lt;item&gt;The Big Man. Another part of this ecosystem is invariably large landowners, who might have estates of hundreds of acres. Columella , for instance, thinks of farm planning (he is thinking about large estates) in units of 100 iugera (62.3 acres) and 200 iugera (124.6 acres; Col. Rust. 12.7-9). An estate of several hundred acres would hardly be unusual. Likewise in the Middle Ages, the Big Man might be a local noble whose manor estate might likewise control a lot of land. The Big Man might also be a religious establishment: temples (in antiquity) and monasteries and churches (in the Middle Ages) often controlled large amounts of productive farmland worked by serfs or tenants to provide their income. Naturally, the Big Man isn’t doing his own farming; he may have some ‘built in’ labor force (workers in his household, enslaved workers, permanent wage laborers, etc.) but often the Big Man is going to rely substantially on the local peasantry for tenant labor.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In practice, the Big Man is likely to represent the bulk of opportunities here, but by no means all of them. As I noted before, while local conditions vary a lot, you won’t be too far wrong in thinking about landholdings as a basic ‘rule of thirds’ with one third of the land controlled by small peasants, one third by rich peasants and one third by the Big Man (who, again, might be a lord or a big landowner or a church, monastery or temple (in the latter case, the land is owned by the god in most polytheistic faiths) or even the king). But of course only a little bit of the small peasant land is going to be in search of workers, since most peasant households have too many hands for too little land; some of the rich peasant land will be looking for workers (either tenants or hired hands), but rich peasants are still peasants – they do some of their farming on their own. By contrast, the Big Man is marked out by the fact that he doesn’t do his own farming: he needs some kind of labor supply – wage laborers, enslaved/non-free laborers or tenants – for all of it.&lt;/p&gt;
    &lt;p&gt;But that also means that something like half (or more!) of the land around our peasant village might be owned by a household that needs outside labor to farm it. So we have peasant households with surplus labor that need more land to farm and richer households with surplus land that needs labor. The solution here generally was some form of tenancy which in the pre-modern world generally came in the form, effectively of sharecropping: the landowner agreed to let the poorer household farm some of his land in exchange for a percentage of the crop that resulted. That ‘rent-in-kind’ structure is useful for the peasants who after all are not generally keeping money with which to pay rent. At the same time, it limits their liability: if the harvest on tenant land fails, they may suffer a shortfall, but they aren’t in debt some monetary quantity of rent (though they may end up in debt in some other way).&lt;/p&gt;
    &lt;p&gt;Now the question is: on what terms?&lt;/p&gt;
    &lt;head rend="h2"&gt;Tenancy&lt;/head&gt;
    &lt;p&gt;And the answer here won’t surprise: bad terms. The terms are bad.&lt;/p&gt;
    &lt;p&gt;There’s a useful discussion of this in L. Foxhall, “The Dependent Tenant” JRS 980 (1990), which in turn leans on K. Finkler, “Agrarian Reform and Economic Development” in Agricultural Decision Making, ed. P.F. Barlett (1980) to get a sense of what the terms for tenant farmers might normally look like. Foxhall notes in this and a few other studies of modern but largely non-industrial farming arrangements that almost no households in these studies were entirely uninvolved in sharecropping or tenancy arrangements, but that the terms of tenancy arrangements varied a lot based on the inputs supplied.&lt;/p&gt;
    &lt;p&gt;The key inputs were labor, traction (for our pre-industrial peasants, this is “who supplies the plow-team animals”), water and seed. The most common arrangement, representing almost a third of all arrangements, was where the tenant supplied labor only, while traction, water and seed were supplied by the landlord; the tenants share in these arrangements was a measly 18.75%. A number of arrangements had the tenant supplying not only labor but also some mix of traction, water or seed (but not all) and often the tenant’s share of the production hovered between 40 and 60%, with exact 50/50 splits occurring in about a quarter of the sample. In just one case did the tenant supply everything but the land itself; in that case the tenant’s share was 81.25%.&lt;/p&gt;
    &lt;p&gt;One thing that is obvious from just this example is that arrangements varied a lot and are going to depend on need and bargaining power. A ‘landlord’ who has land they want under cultivation but can supply basically nothing else may be relatively easy to negotiate into a fairly generous deal; a peasant who is absolutely destitute save for the labor of their hands is easy to exploit. An even 50/50 landholder, tenant split seems to have been the norm in much of Europe though, reflected in terms for sharecropper (métayer in French, mezzadro in Italian, mitateri in Sicilian, mediero in Spanish) which all mean ‘halver,’ though again the terms (and the share split) varied, typically based on demand but also on what exactly the landlord was providing (seed, plow teams, tools, physical infrastructure (like a farmhouse), etc).&lt;/p&gt;
    &lt;p&gt;For the sake of simplicity in our model, we can assume something like a 50/50 split, with our tenants supplying half of the seed, so that our net yield is exactly half of what it would have been. We can then take those assumptions back to our model. To establish a baseline, let’s run the numbers assuming first a ‘medium’ sized (6 iugera, 3.8 acres, with 4 iugera cropped and 2 fallowed) farm, with our fertility estimate set modestly to 6:1, a ‘good but not great’ yield. We’re going to ’round up’ to the nearest even iugerum and assume an average of 13 days per iugerum of labor, just to make our calculations a bit simpler. How hard is it for our peasants to meet their needs if they have to sharecrop the added land they need?&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tenancy&lt;p&gt;with a medium farm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;The Smalls&lt;/cell&gt;
        &lt;cell&gt;The Middles&lt;/cell&gt;
        &lt;cell&gt;The Biggs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Total Labor&lt;/cell&gt;
        &lt;cell&gt;435 work-days&lt;/cell&gt;
        &lt;cell&gt;507.5 work-days&lt;/cell&gt;
        &lt;cell&gt;797.5 work-days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Freehold Labor Demand&lt;/cell&gt;
        &lt;cell&gt;52 work-days&lt;/cell&gt;
        &lt;cell&gt;52 work-days&lt;/cell&gt;
        &lt;cell&gt;52 work-days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Freehold Production&lt;/cell&gt;
        &lt;cell&gt;541kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;541kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;541kg wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Shortfall to Subsistence&lt;/cell&gt;
        &lt;cell&gt;648.5kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;1,028kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;2,145kg wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Net Production Per iugera farmed as tenant&lt;/cell&gt;
        &lt;cell&gt;67.65kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;67.65kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;67.65kg wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tenant Land Required for Subsistence&lt;/cell&gt;
        &lt;cell&gt;10 iugera (6.23 acres)&lt;p&gt;(plus another ~5 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;16 iugera (9.97 acres)&lt;p&gt;(plus another ~8 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;32 iugera (19.94 acres)&lt;p&gt;(plus another ~16 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor Demand for Subsistence&lt;/cell&gt;
        &lt;cell&gt;130(+52) work days&lt;p&gt;Total: 182&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;208(+52) work days&lt;p&gt;Total: 260&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;416(+52) work days&lt;p&gt;Total: 468&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Subsequent Shortfall to Respectability (over subsistence)&lt;/cell&gt;
        &lt;cell&gt;1,189.5kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;1,569kg wheat equivalent&lt;/cell&gt;
        &lt;cell&gt;2,686kg wheat equivalent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tenant Land Required for Respectability&lt;/cell&gt;
        &lt;cell&gt;18 iugera (11.2 acres)&lt;p&gt;(plus another ~9 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;24 iugera (14.95 acres)&lt;p&gt;(plus another ~12 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;40 iugera (24.9 acres)&lt;p&gt;(plus another ~20 iugera fallowed)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Labor Demand for Respectability&lt;/cell&gt;
        &lt;cell&gt;234(+130+52) work-days (Total: 416)&lt;/cell&gt;
        &lt;cell&gt;312(+208+52) work-days (Total: 572)&lt;p&gt;Shortage: 64.5&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;520(+416+52) work-days (Total: 988)&lt;p&gt;Shortage: 190.5&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As we can see, tenancy dramatically changes the picture for our peasants. Under these relatively typical assumptions, of our three families all can make subsistence in a normal year but only the Smalls have the right combination of a lot of labor and a relatively small family to have a shot at getting all of their respectability needs (in practice, they’d probably fall short once you consider necessary farm labor not in the fields – fence repair, tool maintenance, home repair and the like). It also isn’t hard to see how we might alter this picture to change our assumptions. Changing the size of the owned farmland has a significant impact (even though it is already so small) because our peasants realize twice the production per unit-land-area for land they own over land they rent (again, terms might vary). Put another way, under these assumptions, somewhat marginal owned farmland that gives an OK-but-not-great yield of 4:1 is of the same use to our peasants as really good tenant-farmed farmland giving a 7:1 yield (both offer 81.2kg of wheat equivalent per iugerum after rent is paid).&lt;/p&gt;
    &lt;p&gt;That said, the fact that our peasants end up with enough labor to comfortable exceed their subsistence requirements, but not their comfort requirements is favorable for extraction, which we’ll discuss below. These are households with spare labor who can’t fulfill all of their wants entirely on their own, giving the state or local Big Men both a lot of levers to squeeze more labor out of them and also giving the households the available above-subsistence labor to squeeze. By contrast if these peasants had enough land to meet all of their needs themselves, there would be fewer opportunities to compel them to do additional labor beyond that.&lt;/p&gt;
    &lt;p&gt;But even before we get to extraction, tenancy is also changing our peasants’ incentives. Economics has the concept of diminishing marginal returns, the frequent phenomenon where adding one more unit of a given input produces less and less output per additional input-unit. You will find more errors in the first hour of proofreading than the fiftieth hour, for instance. There’s also the concept of diminishing marginal utility: beyond a certain point, getting more of something is less valuable per unit added. Getting one bar of chocolate when you have none? Fantastic. Getting one bar of chocolate when you have ten thousand? Solidly meh.&lt;/p&gt;
    &lt;p&gt;Both are working on our farmers to press their natural production inclination not to maximum labor or even hitting that respectability basket but just subsistence and a little bit more. On the diminishing marginal returns front, naturally when it comes to both owned land and rented land, our peasants are going to farm the most productive land first. This is why when we talk about expanding population and expanding agriculture, we often talk about marginal land (less productive land) coming under cultivation; because all of the really great land was already being farmed. But poor farmland doesn’t demand less labor time (indeed, it may demand more), it just produces less. So while we’ve been working here with averages, you should imagine that the first few acres of farmland will be more productive and the latter few less productive.&lt;/p&gt;
    &lt;p&gt;Tenancy puts this into even more sharp contrast because it creates a really significant discontinuity in the value of farming additional land: the rents are so high that sharecropped or tenant land is much less useful (per unit labor) to the peasant than their own land. So you have a slow downward slope of ‘land quality’ and somewhere in that slope there is the point at which the peasants have farmed all of their own land and so suddenly the effective yield-per-labor-after-rent drops by half (or more!). So the first few hundred kilograms of wheat equivalent are probably fairly easy to get: you have a few good fields you own and your net out of them might be 130-190kg of wheat equivalent per iugerum. Put in a couple dozen days on those two good iugera and The Smalls have just over a quarter of their subsistence needs. But then they have their more marginal fields, which might only yield 80-100kg. Still not terrible but the next couple of dozen days of labor don’t get them as far: not to half but just 44% or so. But now you are out of your own land, so you go to your rich neighbor or the Big Man to get access to some more and suddenly even on their best fields your yield-per-iugerum is 80-95kg so another couple of dozen working days gets you just from 44% to just 57% of what you need. So you need to line up a lot more land, but now you might be starting to look at the worse fields the Big Man has. He still wants them farmed, after all, his choice is between doing nothing and earning money or doing nothing and not earning money; he’d rather earn money. But suddenly you’re looking at maybe as little as 50-60kg of wheat equivalent per iugerum and the labor demands have not gone down.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the comfort you get from each kilogram of wheat equivalent is also going down. The first 80% or so of your subsistence needs is necessary simply to not starve to death; a bit more makes the household sustainable in the long term. But then – and remember, these choices are coming as you are facing diminishing marginal returns on each day of labor you put in – is it really worth your time to cultivate a couple more fields in order to just get a bit more meat in your diet and have slightly nicer household goods? Wouldn’t you rather rest?&lt;/p&gt;
    &lt;p&gt;And so what you see is most peasant households aiming not for the full respectability basket, but that “subsistence – and a little bit more” because as each day of labor produces less product and each product produces less joy, at some point you’d rather not work.&lt;/p&gt;
    &lt;p&gt;And as we’ve seen in theory, our households might hit that crossover point – subsistence and a little bit more – fairly quickly in their labor supply. We haven’t yet, but should now, account for labor spent on things like maintaining tools, fixing fences and other capital investments. If we allocate, say, 45 days, for that and assume that our farmers also want to have some cushion on subsistence (say, another 10%), we might expect The Smalls to be more or less satisfied (on that medium landholding, average 6:1 yields) with something like 245 working days (56% of total), the Middles with 331 working days (65%) and the Biggs with 560 (70%). Working like that, they won’t be rich and won’t ever become rich (but they were never going to become rich regardless), but they’ll mostly survive – some years will be hard – and they’ll have a little bit more time to rest. Some families, a bit more industrious, might push towards achieving most or all of the respectability basket, at least in good years; others might be willing to stick closer to subsistence (or unable to do otherwise).&lt;/p&gt;
    &lt;p&gt;Of course in areas where the farmland is meaningfully more marginal – average yields around 4:1 rather than 6:1 – our peasants are going to need to work quite a lot more, about 60% more. That pushes the Smalls to about 84% of their available labor, the Middles to 99% and the Biggs actually slightly into deficit, demanding roughly 110% of their available labor. We should keep in mind that each peasant household is going to exist somewhere along the spectrum: some with larger amounts of property or access to better land, some with less. We’ll come back to this in a moment, but this is part of why the poorest of the peasantry were often exempt from things like military service: positioned on marginal land in poor communities, they had little excess labor available. Most peasant households would have been somewhere in between these two, so a labor utilization rate ranging from 50 to 100%, with a lot of households in that 60-80% labor utilization range.&lt;/p&gt;
    &lt;p&gt;And now you might think, “doesn’t this take us back to peasants actually not working all that much compared to modern workers?” and first I would want to point out that these peasants are also experiencing a quality of living way below workers in modern industrial countries but also no because we haven’t talked about extraction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extraction&lt;/head&gt;
    &lt;p&gt;Because of course the problem here, from the perspective of everyone who isn’t our peasants is that if the peasantry only does the amount of agricultural labor necessary to subsist themselves and just a little more, the society doesn’t have economic room for much else in the way of productive (or unproductive) economic activity. Remember: our peasants are the only significant population actually doing farming. Sure the Big Men and the gentry and temples and monasteries may own land, but they are mostly renting that land out to peasants (or hiring peasants to work it, or enslaving peasants and forcing them to work it).&lt;/p&gt;
    &lt;p&gt;And those landholding elites, in turn, want to do things. They want to build temples, wage wars, throw fancy parties, employ literate scribes to write works of literature and of course they also want to live in leisure (not farming) while doing this. And the activities they want to do – the temples, wars, fancy parties, scribes and so on – that requires a lot of food and other agricultural goods to sustain the people doing those things. It also requires a bunch of surplus labor – some of that surplus labor are specialists, but a lot of it is effectively ‘unspecialized’ labor.&lt;/p&gt;
    &lt;p&gt;To do those things, those elites need to draw both agricultural surplus and surplus labor out of the countryside. And we should that of course, obviously, this is an exploitative relationship, but it is also worth noting that for pre-modern agrarian economies, the societies where elites can centralize and control the largest pile of labor and surplus tend to use it to conquer the societies that don’t so ‘demilitarized peasant utopia’ is not a society that is going to last very long (but ‘highly militarized landowner republic’ might).&lt;/p&gt;
    &lt;p&gt;It is thus necessary to note that when we see the emergence of complex agrarian societies – cities, writing, architectural wonders, artistic achievements and so on – these achievements are mostly elite projects, ‘funded’ (in food and labor, if not in money) out of extraction from the peasantry.&lt;/p&gt;
    &lt;p&gt;Exactly how this extraction worked varied a lot society to society and even within regions and ethnic and social classes within society. As noted above, in areas where agriculture was not very productive, extraction was limited. By contrast, highly productive regions didn’t so much producer richer peasants as they tended to produce far higher rates of extraction. In some society, where the freeholding farming peasantry (or part of that peasantry) formed an important political constituency (like some Greek poleis or the Roman Republic), the small farmers might manage to preserve relatively more of their surplus for themselves, but often in exchange for significant demands in terms of military and civic participation.&lt;/p&gt;
    &lt;p&gt;To take perhaps the simplest direct example of removing labor from the countryside, from 218 to 168, the Romans averaged around 10-12 legions deployed in a given year, 45,000-54,000 citizen soldiers.11 Against an adult-male citizen population of perhaps ~250,000 implies that the Roman army was consuming something like a quarter of all of the available citizen manpower in the countryside, though enslaved laborers and males under 17 wouldn’t be captured by this figure. Accounting for those groups we might imagine the Roman dilectus is siphoning off something like 15% of the labor capacity of the countryside on average (sometimes spiking far higher, as much as half of it). On top of that, the demand of these soldiers that they supply their own arms and armor would have pushed farmers to farm a little bit more than subsistence-and-a-little-more to afford the cost of the arms (traded for or purchased with that surplus; at least initially these transactions are not happening in coined money).&lt;/p&gt;
    &lt;p&gt;We see similar systems in the Carolingian levy system or the Anglo-Saxon fyrd, where households might be brigaded together – in the Carolingian system, households were grouped into mansi – based on agricultural production (you can see how that works above as a proxy for ‘available surplus labor!’) with a certain number – three or four mansi in the Carolingian system – required to furnish one armed man for either a regional levy or the main field army. The goal of such systems is to take the surplus labor above and make it available for military service.&lt;/p&gt;
    &lt;p&gt;Alternately, the elites might not want their peasants as soldiers but as workers. Thus the very frequent appearance of corvée labor: a requirement of a certain amount of intermittent, unpaid forced labor. This might be labor on the local lord’s estate (a sort of unpaid tenancy arrangement) or labor on public works (walls, castles, roads) or a rotating labor force working in state-owned (or elite-owned) productive enterprises (mines, for instance). As with military service, this sort of labor demand could be shaped to what the local populace would bear and enforced by a military aristocracy against a largely disarmed peasantry. Once again looking at the statistics above, even a few weeks a year per man (rather than per household) would drain most of the surplus labor out of our households. Adding, for instance, a month of corvée labor of per work-capable male (an age often pegged around seven for these societies) under our favorable (6:1) assumptions above bring our work totals to 305 days (70% of total) for the Smalls, 373 (77%) for the Middles and 650 (81.5%) for the Biggs. Corvée labor demands could be less than this, but also often quite a bit more (expectations varied a lot by local laws and customs.&lt;/p&gt;
    &lt;p&gt;Alternately, elites might just crank up the taxes. In the Hellenistic states (the Ptolemaic and Seleucid kingdoms especially), the army wasn’t a peasant levy, but rather a core of Greco-Macedonian rentier elites (your ‘rich peasants’ or ‘gentlemen farmers’), regional levies and mercenaries. To pay for that (and fund the lavish courts and public works that royal legitimacy required), the indigenous Levantine, Egyptian, Syrian, Mesopotamian (etc. etc.) underclasses were both made to be the tenants on the estates of those rentier elites (land seized from those same peasants in the initial Macedonian conquest or shortly thereafter) but also to pay very high taxes on their own land.12 So while tax rates on military-settler (that is, Greco-Macedonian rentier elites) land might have been around 10% – 1/12th (8.3%) seems to have been at least somewhat common – taxes on the land of the indigenous laoi could run as high as 50%, even before one got to taxes on markets, customs duties, sales taxes, a head tax and state monopolies on certain natural resources including timber and importantly salt.13 So the poor laoi might be paying extortionate taxes on their own lands, lighter taxes on settler (or temple) lands, but then also paying extortionate rents of those tenant-farmed lands.&lt;/p&gt;
    &lt;p&gt;Another micro-scale option was debt. We’ve been assuming our farmers are operating at steady-state subsistence, but as we keep noting, yields in any given year were highly variable. What peasants were forced to do in bad years, almost invariably as go into debt to the Big Man. But as noted, they’re simply not generating a lot in the way of surplus to ever pay off that debt. That in turn makes the debt itself a tool of control, what we often call debt peonage. Since the Big Man sets the terms of the debt (at a time when the peasant is absolutely desperate) it was trivially easy to construct a debt structure that the peasant could never pay off, giving the Big Man leverage to demand services – labor, tenancy on poor terms, broad social deference, etc. – in perpetuity. And of course, if the Big Man ever wants to expand his land holdings, all he would need to do would be to call in the un-payable debt and – depending on the laws around debt in the society – either seize the peasant’s land in payment or reduce the peasant into debt-slavery.14&lt;/p&gt;
    &lt;p&gt;In short, elites had a lot of mechanisms to sop up the excess labor in the countryside and they generally used them.&lt;/p&gt;
    &lt;p&gt;Consequently, while peasants, unencumbered by taxes, rents, elites, debt, conscription and so on might have been able to survive working only a relatively small fraction of their time (probably around 100 days per year per-working-age male (again, age 7 or so and up) would suffice), they did not live in that world.&lt;/p&gt;
    &lt;p&gt;Instead, they lived in a world where their own landholdings were extremely small – too small to fully support their households, although their small holdings might still provide a foundation of income for survival. Instead, they had to work on land owned or at least controlled by Big Men: local rentier-elites, the king, temples, monasteries, and so on. Those big institutions which could wield both legal and military force in turn extracted high rents and often demanded additional labor from our peasants, which soaked up much of their available labor, leading to that range of 250-300 working days a year, with 10-12 hour days each, for something on the order of 2,500-3,600 working hours for a farm-laboring peasant annually.&lt;/p&gt;
    &lt;p&gt;Which is quite a lot less than the c. 250 typical work days (261 weekdays minus holidays/vacation) in the United States – just by way of example of a modern industrial economy – at typically eight hours a day or roughly 2,000 working hours a year. Of course it is also the case that those roughly 2,000 modern hours buy a much better standard of living than what our medieval peasants had access to – consider that a single unimpressive car represents more value just in worked metal (steel) than even many ancient or medieval elites could muster. No, you do not work more than a medieval or ancient peasant: you work somewhat less, in order to obtain far more material comfort. Isn’t industrialization grand?&lt;/p&gt;
    &lt;p&gt;That said, our picture of labor in peasant households is not complete! Indeed, we have only seen to half of our subsistence basket – you will recall we broke out textiles separately – because we haven’t yet even really introduced the workload of probably the most fully employed people in these households: the women. And what’s where we’ll go in the next post in this series.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;That is, landholders with enough land to subsist off of the rents without needing to do much or any actual agricultural labor themselves.&lt;/item&gt;
      &lt;item&gt;For scale with the cavalrymen we are talking about just a few thousand households lording over a country of perhaps five million; these fellows are honestly closer to something like a medieval knightly elite than the peasantry.&lt;/item&gt;
      &lt;item&gt;On these allotments, see P. Johstono, The Army of Ptolemaic Egypt, 323-204 BC (2020), 158-160 and C. Fischer-Bovet, Army and Society in Ptolemaic Egypt (2014), 212-217. On the rentier-self-sufficiency of these parcels, at a 5:1 yield, 30 aroura should yield something like 3,500kg wheat equivalent (almost 12 million calories), more than enough to support the settler’s household at a 50% rent (see below) using labor from the much smaller adjacent farms of indigenous Egyptians. Indeed, to me it seems very likely the land allotments were calculated precisely on this basis, with infantrymen receiving the smallest allotment that could reliably support a household in leisure.&lt;/item&gt;
      &lt;item&gt;Le Roy Ladurie, Les Paysans de Languedoc (1966)&lt;/item&gt;
      &lt;item&gt;A reminder that the setérée is an exact unit, about 1/5th to 1/4th of a hectare, so about 0.49-0.62 acres.&lt;/item&gt;
      &lt;item&gt;Rosenstein (2004), 75, n.68; Erdkamp, (2005), 47-8; Cho-yun Hsu, Han Agriculture: The Formation of Early Chinese Agrarian Economy (1980); Johstono, The Army of Ptolemaic Egypt (2020), 101; Fischer-Bovet, Army and Society in Ptolemaic Egypt (2014), 121&lt;/item&gt;
      &lt;item&gt;It’s hard to tell precisely from what I have because Le Roy Ladurie groups households in brackets.&lt;/item&gt;
      &lt;item&gt;The average yield-per-iugerum at each fertility level in wheat equivalent are: 4:1, 81.2kg; 5:1, 108.2kg; 6:1, 135.3kg; 7:1, 162.4kg; 8:1, 189.5kg.&lt;/item&gt;
      &lt;item&gt;I would argue that the Roman approach to Italy from 509 to 218 BC appears to be an exception to this rule: the Romans do tend to use conquered land to set up large numbers of small landholding farms. Not rich peasants, but the Roman military class – the assidui farmer-citizen-soldiers – were also clearly not utterly impoverished either. It’s striking that the Romans could have set up a system of rents and tribute extraction in Italy but didn’t, instead effectively terraforming the Italian countryside into a machine for the production of heavy infantry. That heavy infantry in turn bought the Romans stunning military superiority, which they then used in the second and first centuries BC to create an enormous system of tribute and extraction (rather than extending the approach they had used in Italy).&lt;/item&gt;
      &lt;item&gt;Of course you can drain a swamp, but such drainage efforts are the kinds of things large, well-administered states do, not the sort of thing your local peasants can summon the labor for.&lt;/item&gt;
      &lt;item&gt;On Roman deployments, see Taylor, Soldiers and Silver (2020).&lt;/item&gt;
      &lt;item&gt;The way this was structurally, legally, was that the king, directly or indirectly owned all the land (‘spear-won’) and so many taxes were instead technically ‘rents’ paid to the king.&lt;/item&gt;
      &lt;item&gt;On the Seleucid taxation system, see Aperghis, The Seleucid Royal Economy (2004). For an overview of the relatively similar Ptolemaic system, see von Reden, Money in Ptolemaic Egypt (2007), Préaux, . L’économie royale des Lagides (1979).&lt;/item&gt;
      &lt;item&gt;The abolition of this specific form of slavery (but not others) is a key political moment in the development of both Rome and Athens (and we may assume, many other Greek poleis) that signals the political importance of the smallholding farmer-citizens and their ability to compel major reforms. But the Big Man can still seize your farm!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45228472</guid></item><item><title>California lawmakers pass SB 79, housing bill that brings dense housing</title><link>https://www.latimes.com/california/story/2025-09-12/california-lawmakers-pass-sb-79-housing-bill-that-brings-dense-housing-to-transit-hubs</link><description>&lt;doc fingerprint="3578ce5771992e70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;California lawmakers pass SB 79, housing bill that brings dense housing to transit hubs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Share via&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;California lawmakers passed SB 79, a bill that would override local zoning laws to allow dense housing developments up to nine stories near transit hubs statewide.&lt;/item&gt;
      &lt;item&gt;The controversial bill affects single-family neighborhoods within half-miles of transit stops, sparking protests and opposition from L.A. City Council.&lt;/item&gt;
      &lt;item&gt;Labor union support helped secure passage after amendments requiring union hiring on certain projects, despite local community resistance.&lt;/item&gt;
      &lt;item&gt;The bill will head to Gov. Gavin Newsom in October.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;California lawmakers just paved the way for a whole lot more housing in the Golden State.&lt;/p&gt;
    &lt;p&gt;In the waning hours of the 2025 legislative session, the state Senate voted 21 to 8 to approve Senate Bill 79, a landmark housing bill that overrides local zoning laws to expand high-density housing near transit hubs. The controversial bill received a final concurrence vote from the Senate on Friday, a day after passing in the California Assembly with a vote of 41 to 17.&lt;/p&gt;
    &lt;p&gt;The bill had already squeaked through the state Senate by a narrow margin earlier this year, but since it was amended in the following months, it required a second approval. It will head to Gov. Gavin Newsom’s desk in October.&lt;/p&gt;
    &lt;p&gt;One of the more ambitious state-imposed efforts to increase housing density in recent years, the bill was introduced in March by Sen. Scott Wiener (D-San Francisco), who stresses that the state needs to take immediate action to address California’s housing shortage. It opens the door for taller, denser housing near transit corridors such as bus stops and train stations: up to nine stories for buildings adjacent to certain transit stops, seven stories for buildings within a quarter-mile and six stories for buildings within a half-mile.&lt;/p&gt;
    &lt;p&gt;Single-family neighborhoods within a half-mile of transit stops would be subject to the new zoning rules.&lt;/p&gt;
    &lt;p&gt;Height limits are based on tiers. Tier 1 zoning, which includes heavy rail lines such as the L.A. Metro B and D lines, allows for six- to nine-story buildings, depending on proximity to the transit hub. Tier 2 zoning — which includes light rail lines such as the A, C, E and K lines, as well as bus routes with dedicated lanes — allows for five- to eight-story buildings.&lt;/p&gt;
    &lt;p&gt;An amateur map released by a cartographer and fact-checked by YIMBY Action, a housing nonprofit that helped push the bill through, gives an idea of the areas around L.A. that would be eligible for development under SB 79. Tier 1 zones include hubs along Wilshire Boulevard, Vermont Avenue and Hollywood Boulevard, as well as a handful of spots in downtown L.A. and the San Fernando Valley.&lt;/p&gt;
    &lt;p&gt;Tier 2 zones are more spread out, dotting Exposition Boulevard along the E line, stretching toward Inglewood along the K line, and running from Long Beach into the San Gabriel Valley along the A line.&lt;/p&gt;
    &lt;p&gt;Assembly members debated the bill for around 40 minutes on Thursday evening and cheered after it was passed.&lt;/p&gt;
    &lt;p&gt;“Over the last five years, housing affordability and homelessness have consistently been among the top priorities in California. The smartest place to build new housing is within existing communities, near the state’s major transit investments that connect people to jobs, schools and essential services,” said Assemblymember Sharon Quirk-Silva (D-Orange County) in support of the bill.&lt;/p&gt;
    &lt;p&gt;Other Assembly members, including Buffy Wicks (D-Oakland), Juan Carrillo (D-Palmdale) and Josh Hoover (R-Folsom) voiced their support.&lt;/p&gt;
    &lt;p&gt;Proponents say drastic measures are necessary given the state’s affordability crisis.&lt;/p&gt;
    &lt;p&gt;“SB 79 is what we’ve been working towards for a decade — new housing next to our most frequently used train stations. This bill has the potential to unlock hundreds of thousands of new multifamily homes,” said YIMBY Action California director Leora Tanjuatco Ross.&lt;/p&gt;
    &lt;p&gt;Critics claim the blanket mandate is an overreach, stripping local authorities of their ability to promote responsible growth.&lt;/p&gt;
    &lt;p&gt;Assemblymember Rick Zbur (D-West Hollywood) argued against the bill, claiming it will affect lower-priced neighborhoods more than wealthy ones since land prices are cheaper for housing developers.&lt;/p&gt;
    &lt;p&gt;The vote came a few weeks after the Los Angeles City Council came out against the bill, voting 8 to 5 on a resolution opposing it.&lt;/p&gt;
    &lt;p&gt;Councilmember Traci Park, who co-authored the resolution with Councilmember John Lee, called SB 79 a “one-size-fits-all mandate from Sacramento.” Lee called it “chaos.”&lt;/p&gt;
    &lt;p&gt;The resolution called for L.A. to be exempt from the upzoning since it already has a state-approved housing plan.&lt;/p&gt;
    &lt;p&gt;The bill has spurred multiple protests in Southern California communities, including Pacific Palisades and San Diego. Residents fear the zoning changes would alter single-family communities and force residents into competition with developers, who would be incentivized under the new rules to purchase properties near transit corridors.&lt;/p&gt;
    &lt;p&gt;However, support for SB 79 surged in recent days after the State Building and Construction Trades Council, a powerful labor group that represents union construction workers, agreed to reverse its opposition in exchange for amendments that add union hiring to certain projects.&lt;/p&gt;
    &lt;p&gt;In a statement after the deal was struck, the trades council President Chris Hannan said the amendments would provide good jobs and training to California’s skilled construction workforce.&lt;/p&gt;
    &lt;p&gt;Wiener, who has unsuccessfully tried to pass similar legislation twice before, said the deal boosted the bill’s chances.&lt;/p&gt;
    &lt;head rend="h3"&gt;More to Read&lt;/head&gt;
    &lt;p&gt;Sign up for Essential California&lt;/p&gt;
    &lt;p&gt;The most important California stories and recommendations in your inbox every morning.&lt;/p&gt;
    &lt;p&gt;You may occasionally receive promotional content from the Los Angeles Times.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45228552</guid></item></channel></rss>