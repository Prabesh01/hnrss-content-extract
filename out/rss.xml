<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 09 Oct 2025 17:37:48 +0000</lastBuildDate><item><title>N8n raises $180M</title><link>https://blog.n8n.io/series-c/</link><description>&lt;doc fingerprint="bcc70051598c2d6a"&gt;
  &lt;main&gt;
    &lt;quote&gt;We just raised $180 million in Series C funding, bringing our total funding to $240 million and our valuation to $2.5 billion.&lt;lb/&gt;The round is led by Accel, with support from Meritech, Redpoint, Evantic and Visionaries Club. Corporate investors NVentures (NVIDIA‚Äôs venture capital arm) and T.Capital also join the round, with previous backers including Felicis Ventures, Sequoia, Highland Europe and HV Capital making follow-on investments as well&lt;/quote&gt;
    &lt;p&gt;This investment recognises something fundamental: the AI race isn't only about smarter models - it's about who can actually put that intelligence to work reliably, inside actual businesses.&lt;/p&gt;
    &lt;p&gt;The AI agent landscape has split into two camps. Some platforms put everything in the hands of AI, you write prompts and hope for the best, with the entire logic determined by the model's interpretation. Others require strict, rule-based routing which is powerful for engineers who code every pathway, but impractical for business users who need to iterate quickly.&lt;/p&gt;
    &lt;p&gt;We've learnt from our community that neither extreme serves businesses well. Pure autonomy creates magic when it works but proves too unpredictable for business-critical workflows. Pure rule-based routing offers predictability but demands more time and often developers for every change.&lt;/p&gt;
    &lt;p&gt;n8n was built for the reality in between: giving flexible control over where your agents sit on this spectrum. You choose the balance - how much autonomy to grant, how much logic to enforce, and crucially, how to adjust that balance as you learn what works.&lt;/p&gt;
    &lt;p&gt;But controlling this balance is only the foundation. Getting agents into production requires two more crucial elements:&lt;/p&gt;
    &lt;p&gt;Orchestration: Connecting agents to your actual tools and data sources, building in human oversight where needed, and establishing the monitoring and triggers that keep everything running&lt;/p&gt;
    &lt;p&gt;Coordination: Bringing together the people who understand the business need with the builders who can make it work - on the same platform, in real time&lt;/p&gt;
    &lt;p&gt;Without both, organisations get stuck in endless development cycles. Engineers build in isolation, business users test and provide feedback, iterations drag on. The agent never reaches production because the people closest to the work can't collaborate effectively with those building the solution.&lt;/p&gt;
    &lt;p&gt;The formula we've proven is straightforward: combine AI, code, and humans in the same process, on the same platform. Technical builders handle architecture whilst domain experts configure and refine. That's coordination, and it only succeeds when the orchestration layer is flexible enough to evolve with your needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our principles&lt;/head&gt;
    &lt;p&gt;We've been building n8n since 2019, first as an automation tool, then as a platform for AI orchestration and cross-team collaboration. Now we're the platform our community and enterprises tell us finally helps them deploy AI in production.&lt;/p&gt;
    &lt;p&gt;We've built this alongside a fast-growing community contributing videos, templates, nodes, and more. A community we'll never stop caring about or restrict access to. Ever.&lt;/p&gt;
    &lt;p&gt;Flexibility will always be a top product priority. Flexibility to pick any model, connect any tool, and deploy anywhere: our cloud, your server, a Raspberry Pi, or bare metal. Flexibility in the product so it's easy enough to make a quick start but robust enough to handle orchestration's natural complexity.&lt;/p&gt;
    &lt;p&gt;From tinkerers automating lights at home to the United Nations running mission-critical workflows at scale, our ambition is clear: n8n becomes the default platform to build with AI. And more importantly, to deploy AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs next&lt;/head&gt;
    &lt;p&gt;We've made so much progress this year alone: 6x user growth, 10x revenue growth, and major new features like Evaluations, Data Tables, and many more improvements. Yet it still feels early.&lt;/p&gt;
    &lt;p&gt;The industry is moving fast, and so are we. This funding accelerates our roadmap: expanding our integrations, empowering the ecosystem to build their own nodes and share them globally, and evolving n8n beyond the canvas into new interfaces that match how different teams work. We're making the platform easier to start with whilst more powerful at scale - because that's what production AI demands. (We're hiring!)&lt;/p&gt;
    &lt;p&gt;Our community is already pushing n8n from a platform into an ecosystem. We're rapidly seeing people build their own businesses around n8n, and we want to support the community to take this further: with education, early access to features, commercial partnerships, and fun events to bring everyone together.&lt;/p&gt;
    &lt;p&gt;I started n8n to remove repetitive tasks and focus on what I actually enjoyed. Now I see a world where building with AI, leveraging agents to scale yourself, and becoming a 10x operator becomes table stakes, just as using Excel is. The first people who knew Excel were special, but now it's a requirement for many roles.&lt;/p&gt;
    &lt;p&gt;The same will happen with AI. And my ambition is that n8n becomes the default platform to build with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45525336</guid><pubDate>Thu, 09 Oct 2025 09:19:18 +0000</pubDate></item><item><title>Zippers: Making Functional "Updates" Efficient (2010)</title><link>http://www.goodmath.org/blog/2010/01/13/zippers-making-functional-updates-efficient/</link><description>&lt;doc fingerprint="b6c3d03768b1d678"&gt;
  &lt;main&gt;
    &lt;p&gt; In the Haskell stuff, I was planning on moving on to some monad-related&lt;lb/&gt; stuff. But I had a reader write in, and ask me to write another&lt;lb/&gt; post on data structures, focusing on a structured called a&lt;lb/&gt; zipper.&lt;/p&gt;
    &lt;p&gt; A zipper is a remarkably clever idea. It‚Äôs not really a single data&lt;lb/&gt; structure, but rather a way of building data structures in functional&lt;lb/&gt; languages. The first mention of the structure seems to be a paper&lt;lb/&gt; by Gerard Huet in 1997, but as he says in the paper, it‚Äôs likely that this was&lt;lb/&gt; used before his paper in functional code ‚Äî but no one thought to formalize it&lt;lb/&gt; and write it up. (In the original version of this post, I said the name of the guy who first wrote about zippers was ‚ÄúCarl Huet‚Äù. I have absolutely no idea where that came from ‚Äì I literally had his paper on my lap as I wrote this post, and I still managed to screwed up his name. My apologies!)&lt;/p&gt;
    &lt;p&gt; It also happens that zippers are one of the rare cases of data structures&lt;lb/&gt; where I think it‚Äôs not necessarily clearer to show code. The concept of&lt;lb/&gt; a zipper is very simple and elegant ‚Äì but when you see a zippered tree&lt;lb/&gt; written out as a sequence of type constructors, it‚Äôs confusing, rather&lt;lb/&gt; than clarifying.&lt;/p&gt;
    &lt;p&gt; The basic idea of a zipper is to give you a way of efficiently working with data&lt;lb/&gt; structures in a functional language. There are a lot of cases where in an imperative&lt;lb/&gt; language, there‚Äôs some basic operation which is cheap and simple in the imperative&lt;lb/&gt; language, because it‚Äôs performed by an in-place update. But in a functional language,&lt;lb/&gt; you can‚Äôt update a field of a data structure: instead, you have to create a new copy of the structure with the altered&lt;lb/&gt; field. &lt;/p&gt;
    &lt;p&gt; For example, consider the list &lt;code&gt;[a b c d e f g]&lt;/code&gt;. Implemented&lt;lb/&gt; as a cons-list, it‚Äôs a list of 7 cons-cells. Suppose you wanted&lt;lb/&gt; to replace ‚Äúe‚Äù with ‚Äúq‚Äù. In an imperative language, that‚Äôs no problem: just&lt;lb/&gt; do a set-car! of the 5th cell. In a functional language, you would&lt;lb/&gt; need to create a new list with ‚Äúq‚Äù instead of&lt;lb/&gt; ‚Äúe‚Äù. You could re-use the common tail &lt;code&gt;[f g]&lt;/code&gt;, but you would need&lt;lb/&gt; to re-create the other 5 cells: you‚Äôd need to create a new cell to&lt;lb/&gt; attach ‚Äúq‚Äù to &lt;code&gt;[f g]&lt;/code&gt;. Then you‚Äôd need to create a new&lt;lb/&gt; cell to connect ‚Äúd‚Äù to &lt;code&gt;[q f g]&lt;/code&gt;. And so on.&lt;/p&gt;
    &lt;p&gt; That makes the functional program much slower than the imperative one.&lt;lb/&gt; If you‚Äôve got a data structure that conceptually changes over time, and you‚Äôre going to make lots of changes,&lt;lb/&gt; the cost of doing it functionally can become very high, because of all of the copying&lt;lb/&gt; you do instead of mutating a data structure.&lt;/p&gt;
    &lt;p&gt; In general, it‚Äôs very hard to get around that. You can‚Äôt update in place&lt;lb/&gt; in a functional language (at least, not without some serious cleverness, either&lt;lb/&gt; in your code (like monads), you language (like linear types), or your compiler).&lt;lb/&gt; But for many applications, there‚Äôs some notion&lt;lb/&gt; of a focus point ‚Äì that is, a particular key point where changes&lt;lb/&gt; happen ‚Äî and you can build structures where updates around the focus&lt;lb/&gt; can be performed efficiently.&lt;/p&gt;
    &lt;p&gt; For example, if you‚Äôre building a text editor, you‚Äôve got the point&lt;lb/&gt; where the cursor is sitting ‚Äì and the changes all happen around the cursor.&lt;lb/&gt; The user might type some characters, or delete some characters ‚Äì but it always&lt;lb/&gt; happens around the cursor.&lt;/p&gt;
    &lt;p&gt; What a zipper does is take a data structure, and unfold it around a focal&lt;lb/&gt; point. Then you can make changes at the focal point very quickly ‚Äì about as&lt;lb/&gt; quickly as an in-place update in an imperative language.&lt;/p&gt;
    &lt;p&gt; The idea of it is a lot like a gap-buffer. Right now, I‚Äôm actually working&lt;lb/&gt; on a text-editor. I‚Äôm writing it using a gap-buffer. Conceptually, an&lt;lb/&gt; edit-buffer is one continuous sequence of characters. But if you represent it&lt;lb/&gt; as a continuous sequence of characters, every insert is extremely expensive.&lt;lb/&gt; So what you do is split it into two sub-sequences: one consisting of the&lt;lb/&gt; characters before the cursor point, and one consisting of the&lt;lb/&gt; characters after the cursor point. With that representation,&lt;lb/&gt; inserting a character at the cursor point is O(1). Moving by one character is&lt;lb/&gt; also O(1). Moving by N characters is O(N). With various improvements, you can&lt;lb/&gt; do much better than that ‚Äì but the key bit is that split between before the&lt;lb/&gt; focus point and after it.&lt;/p&gt;
    &lt;p&gt; A zipper is a tree or graph-based version of a similar idea. For this&lt;lb/&gt; discussion, I‚Äôll describe it in terms of trees; the graph version is more complicated,&lt;lb/&gt; but you should be able to get the idea from seeing how it works on trees. The&lt;lb/&gt; idea is that you take the tree structure, and you split it around a focus. You‚Äôre focused on some node in the&lt;lb/&gt; tree. You keep track of a set of nodes that come before you, and a&lt;lb/&gt; set of nodes that come after you ‚Äì those are basically like the&lt;lb/&gt; pre-gap and post-gap regions of a gap buffer. But because you‚Äôre working in a&lt;lb/&gt; tree, you need a bit more information: you need to know the path from&lt;lb/&gt; the root of the tree down to the current node. &lt;/p&gt;
    &lt;p&gt; It‚Äôs called a zipper because what you do to create this pre-focus, path,&lt;lb/&gt; and post-focus bits of the structure is unzip the tree. For example,&lt;lb/&gt; look at the tree below. It‚Äôs a representation of a string of text represented&lt;lb/&gt; by a tree. In this particular tree, all of the data is stored in the leaves.&lt;lb/&gt; The internal nodes contain metadata, which I haven‚Äôt shown in the diagram.&lt;/p&gt;
    &lt;p&gt; Now, suppose I want to put the focus on ‚Äúmno‚Äù. To do that, I climb down&lt;lb/&gt; the tree, unzipping as I go. I start at the root, node N1. Then I go&lt;lb/&gt; right. So I put N1 and its left subtree into the left-context of my&lt;lb/&gt; zipper-tree, and add ‚ÄúRight at N1‚Äù to the path. That puts the focus at N3. To&lt;lb/&gt; get to ‚Äúmno‚Äù from N3, I need to go left. So I put N3 and its right child into&lt;lb/&gt; the right context, and add ‚ÄúLeft at N3‚Äù to the path. Now the focus is at N4.&lt;lb/&gt; To get to ‚Äúmno‚Äù, I need to go right: so I put N4 and its left child into the&lt;lb/&gt; left context, and add ‚ÄúRight at N4‚Äù to the path. Now I‚Äôve got the focus set&lt;lb/&gt; where I want it at ‚Äúmno‚Äù; and I‚Äôve got right and left contexts.&lt;/p&gt;
    &lt;p&gt; With the zipper, you can make all sorts of changes very easily at the&lt;lb/&gt; focus. Suppose I want to change the focus node, by inserting some text. I can&lt;lb/&gt; do that functionally, without actually changing anything, by creating a new&lt;lb/&gt; zipper tree which is identical to the old one, but which changes the value of&lt;lb/&gt; the focus node ‚Äì that is, if I were to add ‚Äú123‚Äù right after ‚Äúmno‚Äù, I could do&lt;lb/&gt; it by creating a new focus node ‚Äúmno123‚Äù, with the same path, left, and right&lt;lb/&gt; contexts. It takes minimal extra memory to create the copy, because I can&lt;lb/&gt; re-use the path and the contexts. &lt;/p&gt;
    &lt;p&gt; I could also add new children nodes. Suppose that instead of adding&lt;lb/&gt; ‚Äú123‚Äù to the focus, I want to keep each leaf containing three characters.&lt;lb/&gt; could replace the focus with a new node, N5, which had children ‚Äúmno‚Äù&lt;lb/&gt; and ‚Äú123‚Äù. I could re-use the ‚Äúmno‚Äù node, and the path, left, and right&lt;lb/&gt; contexts.&lt;/p&gt;
    &lt;p&gt; That‚Äôs the beauty of the zipper: most operations can be in terms of local&lt;lb/&gt; changes, re-using most of the structure. If we were using a standard tree,&lt;lb/&gt; then to add a new node in the position of ‚Äúmno‚Äù, we would need to create&lt;lb/&gt; copies of N4, N3, and N1; instead, we only need to create the one new&lt;lb/&gt; node.&lt;/p&gt;
    &lt;p&gt; Doing other things isn‚Äôt that difficult either. Suppose we wanted to move&lt;lb/&gt; the focus to ‚Äúpqr‚Äù. We‚Äôd need to shift the focus from ‚Äúmno‚Äù to N3, then to N3,&lt;lb/&gt; and then to ‚Äúpqr‚Äù. To get from ‚Äúmno‚Äù to N4, we take the last step off of the&lt;lb/&gt; path ‚Äì which says we went right at N4 ‚Äì so we set the focus to N4, and&lt;lb/&gt; re-establish ‚Äúmno‚Äù as its right child. So the focus would be N4, with ‚Äújkl‚Äù as&lt;lb/&gt; its left child, and ‚Äúmno‚Äù as its right child. To get from N4 to N3, we unroll&lt;lb/&gt; another step of the path: since we went left at N3, that means that N3 is the&lt;lb/&gt; new focus, with N4 as its left child. Then we‚Äôd go down to the right from N3,&lt;lb/&gt; so we‚Äôd add ‚Äúright at N3‚Äù to the path, and ‚Äúpqr‚Äù would be the new focus.&lt;lb/&gt; Moving the focus like that is a tad more difficult than just traversing&lt;lb/&gt; non-zipper tree, but it‚Äôs not significantly slower ‚Äì and it makes the edits&lt;lb/&gt; much, much faster.&lt;/p&gt;
    &lt;p&gt;So why is it harder to code? Because when we‚Äôre dealing with trees, we‚Äôre pretty much always dealing with balance. And balance isn‚Äôt a local property. No matter which kind of tree you use ‚Äì red/black, 2/3, AVL ‚Äì you might need to climb up the tree to do the balance maintenance. That mangles the simple zipper.&lt;/p&gt;
    &lt;p&gt; You‚Äôve got two choices. One is to re-balance&lt;lb/&gt; the tree immediately. You can definitely do that. For&lt;lb/&gt; example, if you think of how you do a re-balance in&lt;lb/&gt; a red-black tree, you climb up the tree doing fixes until you‚Äôve got things rebalanced. You can definitely do that ‚Äì by using the zipper to move around the tree. But a big part of the point of the zipper is to keep operations local, and the re-balancing is not a&lt;lb/&gt; local operation. Much of the time, you can do things&lt;lb/&gt; locally, but sometimes you‚Äôll be stuck re-zipping as you move the focus up the tree fixing the balance; in&lt;lb/&gt; the worst case, you need to re-zip the entire tree, all the way to the root.&lt;/p&gt;
    &lt;p&gt; The alternative is something called scarring. You put marks in the tree called scars that identify places where you made changes that could trigger a rebalance. (Or more generally,&lt;lb/&gt; in places where you made an edit that could have violated some invariant of the data structure.) You don‚Äôt do the fix immediately ‚Äì you just mark it with&lt;lb/&gt; the scar, and then at some point, whenever it makes sense for your application, you go back to the scars, and fix the tree. (Scaring can also have a more general meaning, which involves memorizing certain paths through&lt;lb/&gt; the tree, so that you can make changes at the leave, then a few steps up, then back at the leaf. It‚Äôs a similar concept; in both forms of scarring, you‚Äôre optimizing to reduce the cost of zipping up and down the tree. )&lt;/p&gt;
    &lt;p&gt; Either way, it gets a bit more complicated ‚Äì and when you look at the code&lt;lb/&gt; for a zipper, the re-balancing/invariant fixing has a tendency to dominate the complexity&lt;lb/&gt; of the code. The zipper itself is so simple and so elegant that it just disappears under&lt;lb/&gt; the weight of tree-balancing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45526042</guid><pubDate>Thu, 09 Oct 2025 11:07:29 +0000</pubDate></item><item><title>Show HN: I built a web framework in C</title><link>https://github.com/ashtonjamesd/lavandula</link><description>&lt;doc fingerprint="2f38f1516fffdcd8"&gt;
  &lt;main&gt;
    &lt;p&gt;Lavandula is a lightweight, fast, and intuitive C web framework designed for building modern web applications quickly. It focuses on simplicity, performance, and productivity, providing all the essentials without the bloat of heavier frameworks.&lt;/p&gt;
    &lt;p&gt;Currently, there is no way to just include the framework in a project. This is something being worked on. If you still want to test and use the framework, you can delete everything in &lt;code&gt;main.c&lt;/code&gt; and just start writing your application stuff in there, for now.&lt;/p&gt;
    &lt;p&gt;The CLI will not be of much use for you at the current stage.&lt;/p&gt;
    &lt;code&gt;#include "lavandula.h" 

// define a route for your app
appRoute(home) {
  return ok("Hello, World");
}

int main() {
  // initialise your app
  App app = createApp();

  // register a route in your app
  get(&amp;amp;app, "/home", home);

  // run the app
  runApp(&amp;amp;app);
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Controller and routing system&lt;/item&gt;
      &lt;item&gt;HTTP endpoint support (GET, POST, etc)&lt;/item&gt;
      &lt;item&gt;Controller local/global middleware pipeline&lt;/item&gt;
      &lt;item&gt;Minimal dependencies (pure C)&lt;/item&gt;
      &lt;item&gt;Quick project scaffolding via the CLI&lt;/item&gt;
      &lt;item&gt;Built-in unit testing framework&lt;/item&gt;
      &lt;item&gt;Environment variable support&lt;/item&gt;
      &lt;item&gt;Built-in logging&lt;/item&gt;
      &lt;item&gt;SQLite integration&lt;/item&gt;
      &lt;item&gt;Built-in JSON library&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HTTP JSON body parsing&lt;/item&gt;
      &lt;item&gt;Session cookies&lt;/item&gt;
      &lt;item&gt;CORS policy configuration&lt;/item&gt;
      &lt;item&gt;Lavender ORM&lt;/item&gt;
      &lt;item&gt;Embedded Lavandula (ELA) HTML templating engine&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rate Limiting&lt;/item&gt;
      &lt;item&gt;Static file serving&lt;/item&gt;
      &lt;item&gt;PostgreSL, MySQL integrations, etc&lt;/item&gt;
      &lt;item&gt;Potential dependency injection framework&lt;/item&gt;
      &lt;item&gt;Route/Available endpoint listing&lt;/item&gt;
      &lt;item&gt;JSON model and function scaffolding &lt;list rend="ul"&gt;&lt;item&gt;lavu model User name:string age:int&lt;/item&gt;&lt;item&gt;generates User struct, JSON serialization, CRUD endpoints in user_controller.c&lt;/item&gt;&lt;item&gt;URL parameter parsing and routing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To install Lavandula, follow these setps.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repository&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/ashtonjamesd/lavandula.git
cd lavandula&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run the install script&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./install.sh&lt;/code&gt;
    &lt;p&gt;You should see the following:&lt;/p&gt;
    &lt;code&gt;[SUCCESS] üéâ Lavandula installation completed!

Quick Start:
 lavu new my-project # Create a new project
 cd my-project
 lavu run # Run your project

Documentation:
 GitHub: https://github.com/ashtonjamesd/lavandula&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Finish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You should now be able to run the Lavu CLI tool. Refer to &lt;code&gt;api.md&lt;/code&gt; for how to use Lavu.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create a new project&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;lavu new myProject
&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Setting up Lavandula project 'myProject'...

-&amp;gt; Created myProject/lavandula.yml
-&amp;gt; Created myProject/app/app.c
-&amp;gt; Created myProject/app/controllers/home.c
-&amp;gt; Created myProject/app/routes.c
-&amp;gt; Created myProject/makefile
-&amp;gt; Created myProject/tests/tests.c

üéâ Lavandula project 'myProject' setup finished successfully!

Next steps:
  1. cd myProject
  2. lavu run
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;lavu run
&lt;/code&gt;
    &lt;p&gt;Your application will run on http://localhost:3000/.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Read the docs&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome. Feel free to submit pull requests or open issues for feature requests or bugs.&lt;/p&gt;
    &lt;p&gt;Some things that probably need looking at are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;memory leaks&lt;/item&gt;
      &lt;item&gt;outdated and unfinished documentation (API changes warrant a docs update)&lt;/item&gt;
      &lt;item&gt;The JSON library does not currently support nested lists&lt;/item&gt;
      &lt;item&gt;Some tests need to be written...&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lavandula is registered under the MIT License.e&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45526890</guid><pubDate>Thu, 09 Oct 2025 12:45:28 +0000</pubDate></item><item><title>Nobel Prize in Literature 2025: L√°szl√≥ Krasznahorkai</title><link>https://www.nobelprize.org/prizes/literature/2025/press-release/</link><description>&lt;doc fingerprint="5757b33da9153196"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Press release&lt;/head&gt;
    &lt;p&gt;English&lt;lb/&gt;English [pdf]&lt;lb/&gt;Swedish&lt;lb/&gt;Swedish [pdf]&lt;/p&gt;
    &lt;p&gt;The Permanent Secretary&lt;/p&gt;
    &lt;p&gt;Press Release&lt;lb/&gt;9 October 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;The Nobel Prize in Literature 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;L√°szl√≥ Krasznahorkai&lt;/head&gt;
    &lt;p&gt;The Nobel Prize in Literature for 2025 is awarded to the Hungarian author L√°szl√≥ Krasznahorkai,&lt;/p&gt;
    &lt;p&gt;‚Äúfor his compelling and visionary oeuvre that, in the midst of apocalyptic terror, reaffirms the power of art‚Äù.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6‚Äì13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
    &lt;head rend="h3"&gt;Explore prizes and laureates&lt;/head&gt;
    &lt;p&gt; Look for popular awards and laureates in different fields, and discover the history of the Nobel Prize. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45527003</guid><pubDate>Thu, 09 Oct 2025 12:54:18 +0000</pubDate></item><item><title>Figure 03, our 3rd generation humanoid robot</title><link>https://www.figure.ai/news/introducing-figure-03</link><description>&lt;doc fingerprint="ec95cddb80b22ecf"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we‚Äôre introducing Figure 03, our 3rd generation humanoid robot. Figure 03 is designed for Helix, the home, and the world at scale. Our goal is to deliver a truly general-purpose robot - one that can perform human-like tasks and learn directly from people. To realize this vision, our engineering and design teams completed a ground-up hardware and software redesign to ship Figure 03 for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Helix: Figure 03 features a completely redesigned sensory suite and hand system which is purpose-built to enable Helix - Figure's proprietary vision-language-action AI.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The home: Figure 03 has several new features, including soft goods, wireless charging, improved audio system for voice reasoning, and battery safety advancements that make it safer and easier to use in a home environment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mass manufacturing: Figure 03 was engineered from the ground-up for high-volume manufacturing. In order to scale, we established a new supply chain and entirely new process for manufacturing humanoid robots at BotQ.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The world at scale: The lower manufacturing cost and the advancements made for Helix have significant benefits for commercial applications.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Designed for Helix&lt;/head&gt;
    &lt;p&gt;There‚Äôs no path to scaling humanoid robots without AI. That‚Äôs why we built Figure 03 around one goal - to enable true reasoning throughout the world using Helix. Figure 03 introduces a fully redesigned sensory suite and hand system, purpose-built to bring Helix to life.&lt;/p&gt;
    &lt;p&gt;Figure 03 introduces a next-generation vision system engineered for high-frequency visuomotor control. Its new camera architecture delivers twice the frame rate, one-quarter the latency, and a 60% wider field of view per camera - all within a more compact form factor. Combined with an expanded depth of field, this architecture provides Helix with a denser, more stable perceptual stream. These advancements are essential for intelligent navigation and precise manipulation in complex, cluttered spaces such as homes.&lt;/p&gt;
    &lt;p&gt;Each hand now integrates an embedded palm camera with a wide field of view and low-latency sensing, which offers redundant, close-range visual feedback during grasps. These cameras allow Helix to maintain visual awareness even when the main cameras are occluded (i.e. when reaching into a cabinet or working in confined spaces) and enable continuous, adaptive control in real time.&lt;/p&gt;
    &lt;p&gt;The Figure 03 hands represent a major leap in compliant and tactile design. Softer, more adaptive fingertips increase surface contact area, enabling more stable grasps across objects of varied shapes and sizes. After surveying existing market options, Figure found that current tactile sensors had inherent limitations that could not withstand real-world use. This led to the internal development of our first-generation tactile sensor, guided by three principles: extreme durability, long-term reliability, and high-fidelity sensing.&lt;/p&gt;
    &lt;p&gt;Each fingertip sensor can detect forces as small as three grams of pressure - sensitive enough to register the weight of a paperclip resting on your finger. This precision enables Helix to distinguish between a secure grip and an impending slip before it occurs, allowing fine-grained, dexterous control over fragile, irregular, or moving objects.&lt;/p&gt;
    &lt;p&gt;Figure 03 also includes 10 Gbps mmWave data offload capability, allowing the entire fleet to upload terabytes of data for continuous learning and improvement. Together, these advancements position Figure 03 as uniquely capable of large-scale, end-to-end pixels-to-action learning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for the Home&lt;/head&gt;
    &lt;p&gt;To operate effectively in the home, a robot must work seamlessly alongside people in their daily environments. With this in mind, Figure 03 introduces several design improvements focused on safety. It features strategically placed multi-density foam to protect against pinch points, and is covered in soft textiles rather than hard machined parts. Figure 03 also has 9% less mass and significantly less volume than Figure 02, making it easier to maneuver through household spaces.&lt;/p&gt;
    &lt;p&gt;The Figure 03 battery pushes the bounds for robot battery safety and incorporates multiple layers of protection against abuse or malfunction, including safeguards at the Battery Management System (BMS), cell, interconnect, and pack levels. The battery has already achieved certification to the UN38.3 standard.&lt;/p&gt;
    &lt;p&gt;Beyond safety, Figure 03 is designed for everyday usability. The soft goods are fully washable and can be removed or replaced without tools, allowing quick and easy swaps. The robot can also be customized with various clothing options, including garments made from cut-resistant and durable materials.&lt;/p&gt;
    &lt;p&gt;To make it easier to communicate naturally with the robot, Figure 03 features an upgraded audio hardware system for better real time speech-to-speech. Compared with Figure 02, its speaker is twice the size and nearly four times more powerful, while the microphone has been repositioned for improved performance and clarity.&lt;/p&gt;
    &lt;p&gt;Continuing our vision for a fully autonomous, wire-free system, Figure 03 is capable of wireless inductive charging alongside wireless data offload. Charging coils in the robot‚Äôs feet allow it to simply step onto a wireless stand and charge at 2 kW. In a home setting, this means the robot can automatically dock and recharge itself as needed throughout the day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for Mass Manufacturing&lt;/head&gt;
    &lt;p&gt;Humanoid robots have traditionally been designed as engineering prototypes which are time consuming and expensive to produce. Figure 03 is our first robot engineered from the ground-up for high-volume manufacturing. We achieved this through three major initiatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Design and process reinvention&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Establishing an entirely new supply chain&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The invention of BotQ, our high-volume manufacturing facility&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moving from Figure 02 to Figure 03 required redesigning nearly every component of the robot with manufacturability and cost in mind. The mechanical and electrical engineering teams aggressively reduced part count, assembly steps, and any components that were not absolutely critical to meet design requirements. While Figure 02 was primarily designed to be manufactured with CNC machining, Figure 03 relies heavily on tooled processes such as die-casting, injection molding, and stamping. This shift demanded a significant up-front investment in tooling, but the payoff is clear: each Figure 03 unit now costs dramatically less to build, with the economics improving as volumes grow.&lt;/p&gt;
    &lt;p&gt;To scale Figure 03, Figure had to build an entirely new supply chain for an industry where one does not currently exist. Figure chose to vertically integrate across many critical module builds including actuators, batteries, sensors, structures, and electronics, all of which were designed completely in-house. For individual components, Figure strategically identified and partnered with suppliers capable of meeting the required volumes, timelines, and strict quality standards demanded by the team. The result of this year-long effort is a global network of partners who can grow alongside Figure and meet production goals of thousands and eventually millions of parts under an aggressive ramp schedule.&lt;/p&gt;
    &lt;p&gt;BotQ is Figure‚Äôs dedicated manufacturing facility designed to scale robot production. BotQ‚Äôs first-generation manufacturing line will initially be capable of producing up to 12,000 humanoid robots per year, with the goal of producing a total of 100,000 robots over the next four years. Instead of relying on contract manufacturers, Figure brought production of its most critical systems in-house to maintain tight control over quality, iteration, and speed. The facility is equipped with state-of-the-art systems and digital integrations, anchored by our internally developed Manufacturing Execution System (MES). Every subassembly and final assembly passes through this line with full traceability, ensuring quality, repeatability, and continuous improvement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for the World at Scale&lt;/head&gt;
    &lt;p&gt;Figure‚Äôs focus on the home market in no way detracts from the potential of Figure 03 for the commercial market. By solving for the variability and intractability of the home, Figure is developing a truly general-purpose product that can do the widest possible range of tasks in the workforce.&lt;/p&gt;
    &lt;p&gt;Figure 03 is well suited for commercial applications for several reasons. The actuators can perform at 2x faster speeds with improved torque density (nm/kg). The most significant result of this is our ability to pick and place items at faster speeds.&lt;/p&gt;
    &lt;p&gt;The improvements to the hands and sensory suite made for Helix are of major significance for commercial use cases. With the camera and perception system upgrades, Figure 03 will be able to intelligently navigate commercial environments and execute precise manipulation. The changes to the hands highlighted above (added compliance, fingertip surface area, tactile sensing) enable better and more stable grasps across an array of objects such as small pieces of sheet metal and deformable poly bags.&lt;/p&gt;
    &lt;p&gt;Thanks to inductive charging, Figure 03 is capable of near-continuous operation as long as it can step onto a charging mat for a certain period of time during the use case. The fast wireless data offload also means that the robot can offload seamlessly during shift breaks just by returning to the dock.&lt;/p&gt;
    &lt;p&gt;Commercial customers can also design distinct uniforms for their Figure 03 fleet, with the option to use more durable, or cut-proof materials, and make other design changes for specific environments. New side screens on Figure 03 even allow quick identification across large fleets and can be fully customized to match each customer‚Äôs branding or operational needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Figure 03 represents an unprecedented advancement in taking humanoid robots from experimental prototypes to deployable, scalable products. By uniting advanced perception and tactile intelligence with home-safe design and mass-manufacturing readiness, Figure has built a platform capable of learning, adapting, and working across both domestic and commercial settings. Designed for Helix, the home, and the world at scale, Figure 03 establishes the foundation for true general-purpose robotics - one capable of transforming how people live and work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45527402</guid><pubDate>Thu, 09 Oct 2025 13:27:14 +0000</pubDate></item><item><title>Using a Laptop as an HDMI Monitor for an SBC</title><link>https://danielmangum.com/posts/laptop-hdmi-monitor-sbc/</link><description>&lt;doc fingerprint="2e756d7589369bd2"&gt;
  &lt;main&gt;
    &lt;p&gt;Though I spend the majority of my time working with microcontroller class devices, I also have an embarassingly robust collection of single board computers (SBC), including a few different Raspberry Pi models, the BeagleV Starlight Beta (RIP), and more. Typically when setting up these devices for whatever automation task I have planned for them, I‚Äôll use ‚Äúheadless mode‚Äù and configure initial user and network credentials when writing the operating system to the storage device using a tool like Raspberry Pi‚Äôs Imager.&lt;/p&gt;
    &lt;p&gt;However, sometimes direct physical access to the SBC with a monitor and keyboard is useful for initial configuration, maintenance operations, or workloads that have a visual component. As someone who doesn‚Äôt use any external monitors1 for my daily development, digging up an HDMI monitor, finding somewhere to put it, and connecting it to the device is an annoying process. Furthermore, if I‚Äôm on the go I almost certainly don‚Äôt have easy access to an external monitor.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Raspberry Pi boot logs shown in VLC media player.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Fortunately, I rarely ever do this because I have a handful of HDMI to USB capture cards, ranging from extremely cheap variants from Amazon, to the higher quality Elgato Cam Link 4k. These are typically used for live streaming a video feed from DSLR / mirrorless cameras or gaming consoles, but they also serve as a great option for capturing video from any other device that has HDMI output. On my System76 Linux daily driver laptop, I can use any number of different video playback applications to display the HDMI output via the capture card. For longer term use cases, I can breathe new life into one of my old laptops, using the capture card to effectively convert it into a monitor.&lt;/p&gt;
    &lt;code&gt;vlc v4l2:///dev/video0
&lt;/code&gt;
    &lt;code&gt;ffplay /dev/video0
&lt;/code&gt;
    &lt;code&gt;cheese v4l2:///dev/video0
&lt;/code&gt;
    &lt;p&gt;If you do want to stream or record the SBC output, OBS will give you even more control. You‚Äôll still need a USB keyboard, but I already use one with my laptop, so temporarily plugging it into the SBC for configuration while I use the laptop as a monitor is minimally disruptive. However, if you find yourself regularly needing to connect to multiple machines, it might be time to consider getting a KVM switch.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Yeah, I just sit here with my one laptop screen. Can you believe that? ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45527507</guid><pubDate>Thu, 09 Oct 2025 13:36:01 +0000</pubDate></item><item><title>TIL: Python's splitlines does more than just newlines</title><link>https://yossarian.net/til/post/python-s-splitlines-does-a-lot-more-than-just-newlines/</link><description>&lt;doc fingerprint="e795b146e9a118bf"&gt;
  &lt;main&gt;
    &lt;p&gt;(With thanks to Seth Larson for taking me down this rabbit hole.)&lt;/p&gt;
    &lt;p&gt;I always assumed that Python's &lt;code&gt;str.splitlines()&lt;/code&gt; split strings by
"universal newlines", i.e., &lt;code&gt;\n&lt;/code&gt;, &lt;code&gt;\r&lt;/code&gt;, and &lt;code&gt;\r\n&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But it turns out it does a lot more than that. From the docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This method splits on the following line boundaries. In particular, the boundaries are a superset of universal newlines.&lt;/p&gt;&lt;th&gt;Representation&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;code&gt;\n&lt;/code&gt;&lt;td&gt;Line Feed&lt;/td&gt;&lt;code&gt;\r&lt;/code&gt;&lt;td&gt;Carriage Return&lt;/td&gt;&lt;code&gt;\r\n&lt;/code&gt;&lt;td&gt;Carriage Return + Line Feed&lt;/td&gt;&lt;code&gt;\v&lt;/code&gt;√Ç or√Ç&lt;code&gt;\x0b&lt;/code&gt;&lt;td&gt;Line Tabulation&lt;/td&gt;&lt;code&gt;\f&lt;/code&gt;√Ç or√Ç&lt;code&gt;\x0c&lt;/code&gt;&lt;td&gt;Form Feed&lt;/td&gt;&lt;code&gt;\x1c&lt;/code&gt;&lt;td&gt;File Separator&lt;/td&gt;&lt;code&gt;\x1d&lt;/code&gt;&lt;td&gt;Group Separator&lt;/td&gt;&lt;code&gt;\x1e&lt;/code&gt;&lt;td&gt;Record Separator&lt;/td&gt;&lt;code&gt;\x85&lt;/code&gt;&lt;td&gt;Next Line (C1 Control Code)&lt;/td&gt;&lt;code&gt;\u2028&lt;/code&gt;&lt;td&gt;Line Separator&lt;/td&gt;&lt;code&gt;\u2029&lt;/code&gt;&lt;td&gt;Paragraph Separator&lt;/td&gt;&lt;/quote&gt;
    &lt;p&gt;This results in some surprising (to me) splitting behavior:&lt;/p&gt;
    &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;   =  
&amp;gt;&amp;gt;&amp;gt;  
 
&lt;/code&gt;
    &lt;p&gt;Whereas I would have expected:&lt;/p&gt;
    &lt;p&gt;This was a good periodic reminder that Unicode does not mean "printable," and that there are still plenty of ecosystems that assign semantics to C0 and C1 control codes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45527758</guid><pubDate>Thu, 09 Oct 2025 13:55:04 +0000</pubDate></item><item><title>New nanotherapy clears amyloid-Œ≤ reversing Alzheimer's in mice</title><link>https://www.drugtargetreview.com/news/189235/new-nanotherapy-clears-amyloid-%CE%B2-reversing-alzheimers-in-mice/</link><description>&lt;doc fingerprint="676d66b9292b9d40"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New nanotherapy clears amyloid-Œ≤ reversing Alzheimer‚Äôs in mice&lt;/head&gt;
    &lt;p&gt;Posted: 7 October 2025 | Drug Target Review | No comments yet&lt;/p&gt;
    &lt;p&gt;Researchers have developed bioactive nanoparticles that restore the brain‚Äôs blood-brain barrier and clear toxic proteins, reversing Alzheimer‚Äôs symptoms in mice and offering a promising new approach to treating the disease.&lt;/p&gt;
    &lt;p&gt;A new study by a research team co-led by the Institute for Bioengineering of Catalonia (IBEC) and West China Hospital Sichuan University (WCHSU), in collaboration with partners in the UK, have used a nanotechnology strategy that reverses Alzheimer‚Äôs disease in mice. Unlike traditional nanomedicine, which relies on nanoparticles as carriers for therapeutic molecules, this approach uses nanoparticles that are bioactive, called ‚Äòsupramolecular drugs.‚Äô&lt;/p&gt;
    &lt;p&gt;Instead of targeting neurons directly, this method focuses on repairing the blood-brain barrier (BBB), the brain‚Äôs defence against harmful substances. By restoring proper BBB function, the researchers achieved a reversal of Alzheimer‚Äôs pathology in animal models.&lt;/p&gt;
    &lt;head rend="h2"&gt;The importance of brain vasculature&lt;/head&gt;
    &lt;p&gt;The brain consumes the greatest amount energy out of any other organ in the body, consuming 20 percent in adults and up to 60 percent in children. This energy is delivered through a dense vascular system in which each neuron is nourished by a capillary. With approximately one billion capillaries in the human brain, maintaining vascular health is crucial, particularly in conditions like Alzheimer‚Äôs, where vascular function is weakened and linked to disease progression.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt; Biomarkers are redefining how precision therapies are discovered, validated and delivered. &lt;/head&gt;
    &lt;p&gt;This exclusive expert-led report reveals how leading teams are using biomarker science to drive faster insights, cleaner data and more targeted treatments ‚Äì from discovery to diagnostics.&lt;/p&gt;
    &lt;p&gt;Inside the report:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How leading organisations are reshaping strategy with biomarker-led approaches&lt;/item&gt;
      &lt;item&gt;Better tools for real-time decision-making ‚Äì turning complex data into faster insights&lt;/item&gt;
      &lt;item&gt;Global standardisation and assay sensitivity ‚Äì what it takes to scale across networks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Discover how biomarker science is addressing the biggest hurdles in drug discovery, translational research and precision medicine ‚Äì access your free copy today&lt;/p&gt;
    &lt;p&gt;The BBB is a protective barrier between the brain and blood flow, stopping harmful substances such as pathogens and toxins from entering. By targeting specific mechanisms within the BBB, the research team enabled the removal of undesirable waste proteins produced in the brain. In Alzheimer‚Äôs disease, the main waste protein is amyloid-Œ≤ (AŒ≤), whose accumulation disrupts normal brain function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rapid reduction of amyloid-Œ≤&lt;/head&gt;
    &lt;p&gt;The researchers tested their approach in mice genetically programmed to overproduce AŒ≤ and develop cognitive decline similar to Alzheimer‚Äôs pathology. Following only three doses of supramolecular drugs, the team observed significant therapeutic effects.&lt;/p&gt;
    &lt;p&gt;Following only three doses of supramolecular drugs, the team observed significant therapeutic effects.&lt;/p&gt;
    &lt;p&gt;‚ÄúOnly 1hr after the injection we observed a reduction of 50-60 percent in AŒ≤ amount inside the brain,‚Äù said Junyang Chen, first co-author of the study, researcher at WCHSU and PhD student at University College London.&lt;/p&gt;
    &lt;p&gt;Behavioural tests conducted over several months demonstrated remarkable improvements. In one experiment, a 12-month-old mouse ‚Äì equivalent to a 60-year-old human ‚Äì received the nanoparticles and was evaluated six months later. The animal, now 18 months old ‚Äì comparable to a 90-year-old human ‚Äì exhibited the behaviour of a healthy mouse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Restoring natural clearance mechanisms&lt;/head&gt;
    &lt;p&gt;‚ÄúThe long-term effect comes from restoring the brain‚Äôs vasculature. We think it works like a cascade: when toxic species such as amyloid-beta (AŒ≤) accumulate, disease progresses. But once the vasculature is able to function again, it starts clearing AŒ≤ and other harmful molecules, allowing the whole system to recover its balance. What‚Äôs remarkable is that our nanoparticles act as a drug and seem to activate a feedback mechanism that brings this clearance pathway back to normal levels,‚Äù explained Giuseppe Battaglia, ICREA Research Professor at IBEC and leader of the study.&lt;/p&gt;
    &lt;p&gt;Normally, the protein LRP1 acts as a molecular gatekeeper, binding to AŒ≤ and transporting it across the BBB for elimination. In Alzheimer‚Äôs, this system becomes fragile, leading to AŒ≤ accumulation. The supramolecular drugs mimic LRP1 ligands, binding to AŒ≤ and initiating its clearance, effectively resetting the system and restoring vascular function.&lt;/p&gt;
    &lt;head rend="h2"&gt;A new therapeutic possibility&lt;/head&gt;
    &lt;p&gt;The nanoparticles are designed using a bottom-up molecular engineering approach, combining precise size control with defined surface ligands to interact with cellular receptors in a highly specific manner. This allows them to modulate receptor function, clear amyloid-Œ≤ and restore vascular balance.&lt;/p&gt;
    &lt;p&gt;Our study demonstrated remarkable efficacy in achieving rapid AŒ≤ clearance&lt;/p&gt;
    &lt;p&gt;‚ÄúOur study demonstrated remarkable efficacy in achieving rapid AŒ≤ clearance, restoring healthy function in the blood‚Äìbrain barrier and leading to a striking reversal of Alzheimer‚Äôs pathology,‚Äù said Lorena Ruiz Perez, researcher at IBEC and Serra Hunter Assistant Professor at the University of Barcelona.&lt;/p&gt;
    &lt;p&gt;The study demonstrates how restoring the brain‚Äôs vascular function with bioactive nanoparticles can clear toxic proteins and reverse cognitive decline in mice. The findings could lead to further development pf new therapies that target vascular health to combat neurodegenerative diseases.&lt;/p&gt;
    &lt;p&gt;Related topics&lt;lb/&gt;Animal Models, Bioengineering, Central Nervous System (CNS), Drug Delivery, Drug Discovery, Nanomedicine, Nanotechnology, Neurosciences, Translational Science&lt;/p&gt;
    &lt;p&gt;Related conditions&lt;lb/&gt;Alzheimer's&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45528308</guid><pubDate>Thu, 09 Oct 2025 14:36:52 +0000</pubDate></item><item><title>Show HN: I Hid Labubus in World Labs' AI Worlds</title><link>https://www.akadeb.xyz/vibes/world-labubus/</link><description>&lt;doc fingerprint="7277923db904563c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;World Labubus&lt;/head&gt;
    &lt;p&gt;World Labubus is a daily, Wordle-like game I built on World Labs‚Äô Marble. Every day, a Labubu is hidden somewhere inside a Marble-generated world. Your job is to find it‚Äîfaster than everyone else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick demo (3min)&lt;/head&gt;
    &lt;head rend="h2"&gt;Add the Chrome extension&lt;/head&gt;
    &lt;p&gt;Play right from your browser with the World Labubus Chrome extension.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daily challenge: Each day, a new Labubu is hidden in one of the Marble-generated worlds.&lt;/item&gt;
      &lt;item&gt;Guided hints: You‚Äôll get hints to narrow down the right world‚Äîand where Labubu is actually hiding inside it.&lt;/item&gt;
      &lt;item&gt;Competitive play: A global leaderboard tracks speed and streaks so you can climb the ranks.&lt;/item&gt;
      &lt;item&gt;Chrome extension: Click and play right from your browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How to play&lt;/head&gt;
    &lt;p&gt;Swipe horizontally on mobile or use your trackpad/scroll on desktop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Leaderboard&lt;/head&gt;
    &lt;p&gt;Compete with friends and the community. Scores update as you find Labubu; streaks and speed push you up the board.&lt;/p&gt;
    &lt;head rend="h2"&gt;Privacy Policy&lt;/head&gt;
    &lt;p&gt;I take a minimal‚Äëdata approach. I only store what‚Äôs needed to run the game and leaderboards.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we store&lt;/head&gt;
    &lt;p&gt;Our Supabase database has three tables:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;users ‚Äî username, player_id, and aggregate score&lt;/item&gt;
      &lt;item&gt;labubus ‚Äî the daily Labubu/level metadata (world reference, date, placement info)&lt;/item&gt;
      &lt;item&gt;finds ‚Äî which user found which daily Labubu (timestamped for scoring and streaks)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you have questions or a deletion request, contact us and include your username and player_id so we can find your record.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45528320</guid><pubDate>Thu, 09 Oct 2025 14:37:44 +0000</pubDate></item><item><title>Why Self-Host?</title><link>https://romanzipp.com/blog/why-a-homelab-why-self-host</link><description>&lt;doc fingerprint="ad29105312a62fd3"&gt;
  &lt;main&gt;
    &lt;p&gt;I recently shared my current Homelab setup with a colleague and was asked a pretty simple question I just took for granted... why?&lt;/p&gt;
    &lt;p&gt;Why go through the hassle of configuring servers, installing applications, setting up containers and spending quite a substantial amount of money on hardware that will not even run under optimal data center conditions (consumer-grade internet connection, no failover, no auto migrations)?&lt;/p&gt;
    &lt;p&gt;I will also give some specific recommendations on what you could and maybe should self-host.&lt;/p&gt;
    &lt;head rend="h2"&gt;Privacy&lt;/head&gt;
    &lt;p&gt;You saw that coming.&lt;/p&gt;
    &lt;p&gt;Privacy is not a god-given right but has to be fought for. Big Tech and governments (like with chat control in the EU) want to shine light in every part of your personal life. Self-hosting services can reduce or even completely mitigate the risk of being surveilled. But it also requires a lot of technical knowledge so you can make a difference and educate your family or friends and even host some services for those who don't have the capabilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calendar &amp;amp; Contacts&lt;/head&gt;
    &lt;p&gt;Your calendar says more about you than you probably think. Apart from your full identity it can also give away information about regular contacts, family, coworkers, confidential business meetings, your health information such as medical appointments, sleep and workout routine, legal obligations, financial information like scheduled loans, subscriptions, political beliefs through scheduling to visit a protest and even let's other profile your behavior for identity theft to find out when you're available and when not.&lt;/p&gt;
    &lt;p&gt;Same goes for contacts, your social graph can say so much about you, combined with metadata such as queries for certain contacts and creation dates. Did you recently add an unusual amount of new contacts with the same sex, first name only and phone number? You must be dating. Just created a contact for a doctor? Looks like you're visiting a therapist.&lt;/p&gt;
    &lt;p&gt;Most people don't even think about where their social graph data is stored and probably assume it comes with their phone when in reality that data is being processed by Google, Apple, Samsung or whoever knows.&lt;/p&gt;
    &lt;p&gt;I don't want a single company holding all that sensitive information and possibly deriving data points from that. Even with Apple's Advanced Data Protection your calendars and contacts are not end-to-end encrypted.&lt;/p&gt;
    &lt;head rend="h3"&gt;Location&lt;/head&gt;
    &lt;p&gt;Many many years ago I was running an Android phone with Google services like Google Maps. One day I was looking for a feature in my Google account and saw that GMaps recorded my location history for years with detailed geocoordinates about every trip and every visit.&lt;/p&gt;
    &lt;p&gt;I was fascinated but also scared about that since I've never actually enabled it myself. I do like the fact that I could look up my location for every point in time but I want to be in control about that and know that only I have access to that data.&lt;/p&gt;
    &lt;head rend="h3"&gt;So much more&lt;/head&gt;
    &lt;p&gt;It's beyond the scope of this post to list every possible way, your data can be traced back to you and argument why you should be conscious about that. I want to motivate you to start a new journey!&lt;/p&gt;
    &lt;head rend="h2"&gt;Sovereignty&lt;/head&gt;
    &lt;p&gt;Digital sovereignty for me means to be in control of, choosing what I do with and controlling who I share my data with.&lt;/p&gt;
    &lt;p&gt;You constantly hear about cases of tech companies locking down accounts with no apparent reason and it even happened to me in the past with Google. I do not want to be at the mercy of a giant tech firm which you can not even contact or if - get annoyed by a garbage AI chat bot (see my Microsoft rant for more fun). Besides - why are there no regulatory requirements for tech companies to provide a way to get in contact with an actual human?&lt;/p&gt;
    &lt;p&gt;I like protocols and file standards, no "Gmail" API - we call that thing SMTP and IMAP (yes, they are dated but the best we currently have. Thus I still welcome the new JMAP initiative). Another paragraph without bashing Microsoft? Hell no, Big Tech like Microsoft really wants you to use their AI-Copoilit-enabled-365-Office-Live-Outlook &lt;del&gt;spyware&lt;/del&gt; software - that's why they have recently disabled SMTP access for Office 365 accounts.&lt;/p&gt;
    &lt;head rend="h2"&gt;What to self-host&lt;/head&gt;
    &lt;p&gt;Let's get to the bread and butter of this article and give some straightforward examples on what to self-host.&lt;/p&gt;
    &lt;p&gt;Some of those applications need to be available outside of your local network if you don't want to be constantly connected to a VPN. I will write more about how to do that securely and all available options in an upcoming post. If you want to read that, subscribe to the RSS feed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hardware&lt;/head&gt;
    &lt;p&gt;I'm fortunate enough to work at a company (enum.co) where digital sovereignty is not just a phrase. That's why I got provided with three mini servers where I'm running a highly available Kubernetes cluster (which my boss also helped me set up, thanks Max!). Also... more on that in a later blog post.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calendar &amp;amp; Contacts&lt;/head&gt;
    &lt;p&gt;As stated above, calendar and contact data is more sensitive than one might think. This is why I am hosting my own CalDAV / CardDAV server.&lt;/p&gt;
    &lt;p&gt;There are some options on servers for you which all have their ups and downs. Here are just a few:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Radicale (Python, basic web ui, only single user, does not work with apple devices from my experience)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;√¢ Ba√É¬Økal (PHP, active development, advanced web ui, multi-user)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DAViCal (PHP, haven't tried)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Xandikos (Python, No built-in authentication, no web ui)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud (PHP, If you're already using it go for it - too bloated for me)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Being conscious about what other can do with your calendar and contact data also mean to review, which apps have access to your contact book and calendar.&lt;/p&gt;
    &lt;p&gt;Oh no, I said the forbidden phrase: Self-hosted mail server. I was always told to never under any circumstances do that. But it's really not that deep.&lt;/p&gt;
    &lt;p&gt;"Recent" developments like Stalwart or Mailcow made it really easy and straighforward to self-host email. Beware I'm not talking about marketing mails but rather personal inboxes.&lt;/p&gt;
    &lt;p&gt;Of course, you don't want to self-host your mail server at home since it requires a static IP and needs to be reachable from the whole internet. Going into that, you want to start with a clean IP address. Choose a hoster you trust, get a server, look up the IP address in mail blacklists and repeat until you get a clean one. After setting up the server, you want to make sure you can receive mail and every required protocol has been correctly configured. I found the internet.nl online test tool to be super usefull to ensure everything works. Start by sending mails to Google, Microsoft and Yahoo addresses to check if your mails are getting redirected to SPAM. Iterate on that, check DNS, DMARC, SPF, TLS etc.&lt;/p&gt;
    &lt;p&gt;I will probably write a detailed blog post on that in the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smart Home&lt;/head&gt;
    &lt;p&gt;When I started hosting my own Home Assistant instance a couple of years ago it was just an experiment to see what I can do since I wasn't really missing anything with Apple Homekit. Since then more and more smart home companies went bankrupt, sunsetted their cloud services, jacked up prices or put free services behind a paywall.&lt;/p&gt;
    &lt;p&gt;For me, Home Assistant paid off a couple of weeks ago when I heard that Philips Hue will force users to create an account just to use any feature for their lights, they already paid real money for. I've always configured Firewall rules to disallow any outgoing network traffic for smart home appliances but it seems like I cannot use any Philips Hue app specific features (like animated light patterns imitating candles etc.) even on my local network. I haven't looked into this but I hope there's some community plugin which emulates this functionality.&lt;/p&gt;
    &lt;p&gt;I will never, under any circumstances, create an online account for an appliance I will only use locally.&lt;/p&gt;
    &lt;p&gt;Also I am now obsessed with tracking energy usage and plan on building and developing a Raspberry Pi + camera device which tracks energy usage of gas meter via machine vision.&lt;/p&gt;
    &lt;head rend="h3"&gt;RSS Aggregator&lt;/head&gt;
    &lt;p&gt;I am subscribed to many news sites and blogs over RSS which is by itself already decentralized and sovereign. This is why self-hosting an RSS aggregator is kind of optional and only the last mile to go.&lt;/p&gt;
    &lt;p&gt;On my iPhone and Mac I'm running NetNewsWire, in my opinion the best RSS reader, even open source and backed by incredible people. NetNewsWire comes with a native integration for FreshRSS - a feed aggregator that also provides many more features like filtering and lets you subscribe to sources which don't natively provide an RSS feed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Location Tracker&lt;/head&gt;
    &lt;p&gt;I've deployed an instance of dawarich (German for "I was there") which is a server for ingesting and viewing geolocation data. It also allows you to choose from many available mobile apps which can track send your current location to the server. At the time of writing this includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;official dawarich app (always shows a navigation icon in the iOS notch)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Overland (high battery drain for me)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;√¢ Owntracks (works best for me on iOS, only app settings are crazy confusing)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ideas &amp;amp; Outlook&lt;/head&gt;
    &lt;p&gt;I recently re-worked my homelab and went from a single big server to a 3 node Kubernetes cluster. This gives me much more flexibility in the kind of applications I can host.&lt;/p&gt;
    &lt;p&gt;This is a list of apps and tools I want to have a look at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;EteSync: End-to-end encrypted CalDAV &amp;amp; CardDAV&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AnyType: Self-hosting my own AnyType server instance&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Passbolt: Password manager (no I really don't like Bitwarden)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;BirdNET: Monitoring bird species outside with a microphone&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;penpot: Like Figma but free &amp;amp; open source&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Habitica: Habit manager&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;vert: File converter&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;InvoiceShelf: Invoice manager&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There's also selfh.st - a great resource where can spend hours finding self-hostable applications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45528342</guid><pubDate>Thu, 09 Oct 2025 14:39:12 +0000</pubDate></item><item><title>Incident with Webhooks</title><link>https://www.githubstatus.com/incidents/k7bhmjkblcwp</link><description>&lt;doc fingerprint="7097ca160c0b4fd4"&gt;
  &lt;main&gt;
    &lt;p&gt;This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:40 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;All services have fully recovered.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:39 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions has fully recovered but Notifications is still experiencing delays. We will continue to update as the system is fully restored to normal operation.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:27 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:24 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pages is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:08 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Git Operations is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:04 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions and Notifications are still experiencing delays as we process the backlog. We will continue to update as the system is fully restored to normal operation.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 16:02 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pull Requests is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:51 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:48 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing full recovery in many of our systems, but delays are still expected for actions. We will continue to update as the system is fully restored to normal operation.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:44 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Webhooks is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:43 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Webhooks is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:40 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Issues is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:39 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pull Requests is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:38 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;API Requests is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:26 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We identified a faulty network component and have removed it from the infrastructure. Recovery has started and we expect full recovery shortly.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:25 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pull Requests is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:20 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Git Operations is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:20 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:17 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are investigating widespread reports of delays and increased latency in various services. We will continue to keep users updated on progress toward mitigation.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:11 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Issues is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:09 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;API Requests is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:09 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pages is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 15:09 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 14:50 UTC&lt;/p&gt;
    &lt;p&gt;Investigating&lt;/p&gt;
    &lt;p&gt;We are investigating reports of degraded availability for Webhooks&lt;/p&gt;
    &lt;p&gt;Posted Oct 09, 2025 - 14:45 UTC&lt;/p&gt;
    &lt;p&gt;This incident affected: Git Operations, Webhooks, API Requests, Issues, Pull Requests, Actions, and Pages.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45528735</guid><pubDate>Thu, 09 Oct 2025 15:05:52 +0000</pubDate></item><item><title>Show HN: I've built a tiny hand-held keyboard</title><link>https://github.com/mafik/keyer</link><description>&lt;doc fingerprint="2f4c3473419d83f4"&gt;
  &lt;main&gt;
    &lt;p&gt;Firmware &amp;amp; goodies for making a Keyer (one-handed version of a chorded keyboard).&lt;/p&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Minimal finger movement: it's like typing with all the keys on your home row all the time&lt;/item&gt;
      &lt;item&gt;Free hand while typing: you can use your other hand to sip tea while typing (or move the mouse - if you're not a tea drinking type)&lt;/item&gt;
      &lt;item&gt;Always near your hand - keyer can be attached to a glove so you can just release it and have both of your hands free. Now you can drink your tea and move the mouse at the same time.&lt;/item&gt;
      &lt;item&gt;Tons of chords: a 10-key keyer (3 keys on thumb, 2 index, 2 middle, 2 ring, 1 pinky) can express up to 215 chords (√ó 2 when counting hold-chord alternatives). With so many chords you can lose a finger and still touch type (carpenters love it!)&lt;/item&gt;
      &lt;item&gt;Arpeggios: an additional 2 √ó 78 arpeggios - rolling motion over two keys that can be executed in two directions and can be used for even more input options.&lt;/item&gt;
      &lt;item&gt;Multiple layers: if the 586 shortcuts available on the base layer are somehow not enough for you&lt;/item&gt;
      &lt;item&gt;Rolling chords: when two subsequent chords you're entering share some finger positions you can only move the finger that changes position. When combined with optimized layouts (see the next point) typing is like walking through the keys one finger at a time.&lt;/item&gt;
      &lt;item&gt;Optimized layout: a bundled layout optimizer will perform a combinatorial search over all possible layouts to find the optimal one for typing the texts that you give it (or for your custom finger press / finger movement cost function)&lt;/item&gt;
      &lt;item&gt;Ergonomic layout üññ: did you know your fingers share the neuro-motor pathways and can't always move independently? The layout generator will avoid finger combinations that are hard to press.&lt;/item&gt;
      &lt;item&gt;Low-latency: the firmware relies on hardware interrupts and a zero-latency digital debouncing algorithm to make the keys more responsive than polling-based keyboards (and keyboards with capacitor-based debouncers).&lt;/item&gt;
      &lt;item&gt;Power for months: a massive 18650 battery + underclocked CPU + firmware able to sleep without losing the Bluetooth connection + hardware power switch on the board mean that you will charge it about as often as a Casio watch.&lt;/item&gt;
      &lt;item&gt;üï∂Ô∏è: combine it with smart glasses to control your computer (or smartphone) without looking or touching. It's like Meta EMG wristband but actually working!&lt;/item&gt;
      &lt;item&gt;Easy to build: did you ever play with Play-Doh? This keyer was built with modelling clay (baked in the oven for 30 minutes). No 3D printing. No custom PCBs. You can make it with parts from amazon, a hot glue gun and a soldering iron.&lt;/item&gt;
      &lt;item&gt;Perfect fit: you build it yourself, literally modelling it to the shape of your hand. You can't get more ergonomic than that.&lt;/item&gt;
      &lt;item&gt;Cheap to build: it's less than 50 USD to make one yourself. Mechanical keyboards are a cheap hobby now!&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Penti Chorded Keyboard - A software keyer that can run on a touchscreen. Notable for its use of arpeggios.&lt;/item&gt;
      &lt;item&gt;Keyyyyyyyys! - Can you get cheaper than that?&lt;/item&gt;
      &lt;item&gt;ESP32-BLE-Keyboard - The best way to emulate a BLE keyboard from ESP32.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Welcome to the bottom of the ergonomic mechanical keyboard rabbit hole.&lt;/p&gt;
    &lt;p&gt;Let's start with some shopping.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LILYGO T-Energy S3 development board ($9.70)&lt;/item&gt;
      &lt;item&gt;Samsung INR18650-35E 3500mAh Li-ion battery (~$2.95)&lt;/item&gt;
      &lt;item&gt;FIMO professional modelling clay ($2.75) &lt;list rend="ul"&gt;&lt;item&gt;Alternatively, one of the FIMO effect modelling clays if you'd like to make your keyer out of stone&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;10 √ó Gateron G Pro 3.0 mechanical switches (~$10) &lt;list rend="ul"&gt;&lt;item&gt;Alternatively other switches of your choice&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;10 √ó Keycaps (~$8) &lt;list rend="ul"&gt;&lt;item&gt;You only need ten of them so feel free to get the coolest keycaps you can find&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1m √ó AWG 18 rigid, insulated copper wire (~$1) &lt;list rend="ul"&gt;&lt;item&gt;Get it from a local hardware store, the online stores are ripping you off&lt;/item&gt;&lt;item&gt;You can come with your development board to see which wire gauge fits through the holes on the board&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Total: $34.40 (+shipping)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pliers - for bending the copper wire&lt;/item&gt;
      &lt;item&gt;a knife (or a set of sharp teeth) - for stripping the cable insulation&lt;/item&gt;
      &lt;item&gt;(optional) nitryl gloves - for not getting dirty while working with the modelling clay&lt;/item&gt;
      &lt;item&gt;hot glue gun + hot glue sticks - for attaching the components to a wire scaffolding&lt;/item&gt;
      &lt;item&gt;soldering iron + solder wire - for soldering&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With all the materials and tools in hand, the first step is to form a metal scaffolding which will hold the switches in convenient positions. Traditional electronics devices tends to have "exoskeletons" - they're supported by an external case that surrounds them and protects them from your greasy fingers. This device is built around an endoskeleton of copper wire. We'll cover this endoskeleton with modelling clay in a moment. I hope you bought the thickest wire you could (while still fitting through the holes on the board) because in this device it's structural.&lt;/p&gt;
    &lt;p&gt;We'll start with a "GND loop". Cut a section of wire - about 20 or 30cm. Strip its insulation &amp;amp; insert it into one of the GND holes on the board. Solder it in place - it should be firmly attached to the board. Insert the battery and take the board in your hand. Position it like you'd like it to stay in your hand and start bending the wire into a loop that goes through all the places where key switches bases are going to be placed. For some extra rigidity (long wire is fairly bendy) lead the other end of the wire back into another GND hole on the board. You can take the switches with keycaps and place them so that one of their contact points touch the wire. This will give you a better idea of how the keyer is going to end up looking. Don't worry about it being wobbly - we'll use this property to model it a little in a moment. First complete the loop by soldering the other end of the GND loop to the board. If your GND loop happens to pass near other GND holes, you can insert short sections of wire to increase the rigidity of the construction.&lt;/p&gt;
    &lt;p&gt;Once GND loop is complete, take your key switches and attach them to the GND loop so that one of their contact points makes an electrical contact. You can solder them directly but it's a good idea to start with some hot glue to hold them in place. In my version I also bent the contacts on the key switches to make them smaller (DIY low profile) and to take less space.&lt;/p&gt;
    &lt;p&gt;As you're going through the process the keyer is going to become more "complete" and you will be able to bend the wire a little to improve key positioning. Remember that hot glue and solder don't form particularly strong bonds so be careful about bending and ideally use pliers to do that precisely.&lt;/p&gt;
    &lt;p&gt;One word of advice about key positioning is that I've noticed that the keys are "nicest" to press when the axis of pressing goes straight into the palm of your hand. Motions that go parallel to palm of the hand, motions that extend fingers and motions that move fingers to the side are pretty awkward and uncomfortable. I guess our hands evolved to hold things, rather than poke or flick at them. Some keyboard manufacturers might disagree. Their keyboards look undeniably awesome, but this is your keyer and it should be comfortable to use - so make sure the keys are pressed in the same direction that you'd hold something.&lt;/p&gt;
    &lt;p&gt;Once you attached all of the keys, it's time to add even more rigidity into our construction. We'll do this by connecting the remaining contact points on the switches to the GPIO holes on the board. They're marked on the board with text that says "IO##". It doesn't matter which IO port you choose, but write down which key goes to which IO port - it's something that will have to be entered in the firmware. Take a short cut of the wire, strip it at both ends. Bend it (with pliers) so that it fits in the hole and goes straight to the switch. Then solder it in place at both ends. It's important that the wires going to the IO ports don't touch the GND loop. Insulation should help with that.&lt;/p&gt;
    &lt;p&gt;After this step, the keyer should be fairly rigid. Mount the keycaps and see how it feels. It's obviously a little "spiky" but we'll deal with that in the next step. Right now bend the wires to put all the key switches in their right positions.&lt;/p&gt;
    &lt;p&gt;At this point you can go to the "Flashing Firmware" section and check out how your keyer works! It's good to see if you didn't mess anything up so far. The hardest part is over!&lt;/p&gt;
    &lt;p&gt;Now is the time to open up the modelling clay and use it to cover our keyer. Before you begin, remove the keycaps, as they'll only get in the way. Take a small amount of clay and start shaping it in your hand. Squeeze it and fold in half. Repeat this about twenty times. Modelling clay must be mixed like that a little to prevent it from crumbling.&lt;/p&gt;
    &lt;p&gt;Once you have your warm and soft piece of clay, slap it on top of the keyer - wherever you want to cover something. It's important to cover the bottom parts of the switches - that's the part that may prick your fingers. Everything else is optional. I decided to keep my development board mostly visible and only covered the wires.&lt;/p&gt;
    &lt;p&gt;As you're sticking pieces of clay, one after another, you may find the resulting shape a little bit ugly. Turns out modelling stuff out of clay is hard! I've found a couple of tricks that may help you:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add clay in layers. Take a small ball of clay and place it between two popsicle sticks. Roll it into a flat disc with a rolling pin. Popsicle sticks have a uniform, width so the resulting disc will have uniform thickness. Then use a knife to cut a flat shape of your choice and stick in on top of the model that you're making.&lt;/item&gt;
      &lt;item&gt;If you see a gap between chunks of clay - rub them. Keep rubbing them until the gap disappears. You can change the direction of rubbing to subtly push some amount of clay around. It can be used to even up tiny hills and valleys.&lt;/item&gt;
      &lt;item&gt;The best way of evening uneven edges is to use a knife. Ideally a wallpaper knife. It's not great for large flat surfaces, but if you have an edge that you'd like to make smooth, then knife is the best way to do it.&lt;/item&gt;
      &lt;item&gt;This is a cool one. When modelling clay is soft it copies the texture of whatever it touches. You can use a piece of fabric to make it look like a fuzzy fabric. If you take a glass you can make it glossy. Look around you and see what nice textures you have around.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can try to take the keyer in your hand at this point but be careful. The clay is very pliable and may deform under the pressure of your hand.&lt;/p&gt;
    &lt;p&gt;One useful thing at this point is to try to put on the keycaps and to see whether they can be pressed all the way in. If they cannot - then either the clay (or the keycap) has to be trimmed. At this point the clay is still soft so it's easy to correct it.&lt;/p&gt;
    &lt;p&gt;Once you're done with modelling (it can take a couple of hours) heat up an oven to 110¬∞C and put your keyer inside. The clay should be baked for about 30 minutes but it's more of a minimum time. Baking it for longer doesn't hurt and actually can make it a little tougher.&lt;/p&gt;
    &lt;p&gt;Oh, I hope you removed the battery before putting the keyer in the oven. If you didn't then you'll have to get a new one (oven). And call the fire department.&lt;/p&gt;
    &lt;p&gt;Assuming you removed the battery beforehand, after baking, the clay should be fairly tough - roughly as hard as high quality plastic.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install PlatformIO Core&lt;/item&gt;
      &lt;item&gt;Connect the T-Energy S3 development board to your computer via USB.&lt;/item&gt;
      &lt;item&gt;Run these commands:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone this repository
$ git clone https://github.com/mafik/Keyer.git

# Enter the cloned directory
$ cd Keyer

# Build project
$ pio run

# Upload firmware
$ pio run --target upload&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open Bluetooth settings on your phone or PC. If you see a device called "ùñíùñÜùñã.üéπ", that means it's working.&lt;/item&gt;
      &lt;item&gt;Go to a text editor and find &lt;code&gt;ChordKeyboard.cpp&lt;/code&gt;. Change the&lt;code&gt;kButtonPin&lt;/code&gt;array to the IO ports that you used for connecting the switches. Feel free to explore this file and experiment.&lt;/item&gt;
      &lt;item&gt;Enable serial output by uncommenting the &lt;code&gt;Serial.begin&lt;/code&gt;line and running the program with&lt;code&gt;pio run --target upload --target monitor&lt;/code&gt;. This will let you see what the board is doing while you're fiddling with the code and pressing the keys.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's getting late so this is the point at which I'll leave you on your own. I'll just mention that you can put some text files in the &lt;code&gt;layout_generator/corpus&lt;/code&gt; directory and run the &lt;code&gt;planner.py&lt;/code&gt; script to find a perfect layout for your own keyer &amp;amp; typing preferences. You can tweak the &lt;code&gt;keyer_simulator.cpp&lt;/code&gt; to adjust finger press &amp;amp; movement costs. Within &lt;code&gt;planner.py&lt;/code&gt; you'll find some code for generating layouts that follow some memorable patterns. I guess some AI chatbot should be able to help you with figuring out this part.&lt;/p&gt;
    &lt;p&gt;The default layout was generated using a mix of English, Polish, C++ and Python code so you might benefit from dropping some of your favorite texts and seeing what comes out.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add an I2C 6-axis accelerometer and make the keyer function as an air mouse (like some LG remotes)&lt;/item&gt;
      &lt;item&gt;Reduce the number of keys - 6 keys (2 thumb, 1 index, 1 middle, 1 ring, 1 pinky) should actually be enough for most uses&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Tweak FreeRTOS configuration
$ pio run --target menuconfig

# Clean build files
$ pio run --target clean&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;layout_generator/&lt;/code&gt;- a set of Python scripts for generating an optimized chord layout&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;corpus/&lt;/code&gt;- directory for text files that will be used for evaluating the layout&lt;/item&gt;&lt;item&gt;&lt;code&gt;planner.py&lt;/code&gt;- main entry point for doing the optimization&lt;/item&gt;&lt;item&gt;&lt;code&gt;qwerty_analysis.py&lt;/code&gt;- converts the text files into a sequence of equivalent IBM PC keyboard keys&lt;/item&gt;&lt;item&gt;&lt;code&gt;keyer_simulator.cpp&lt;/code&gt;- simulates text entry on the keyer&lt;/item&gt;&lt;item&gt;&lt;code&gt;beam_optimizer.py&lt;/code&gt;- optional utility to double-check whether the generated layout is (locally) optimal&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/&lt;/code&gt;- code that runs on the ESP32&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sdkconfig.ChordKeyboard&lt;/code&gt;- configuration for the ESP-IDF firmware&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529393</guid><pubDate>Thu, 09 Oct 2025 15:51:20 +0000</pubDate></item><item><title>Programmer in Wonderland</title><link>https://binaryigor.com/programmer-in-wonderland.html</link><description>&lt;doc fingerprint="b7401b5913f72edb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Programmer in Wonderland&lt;/head&gt;
    &lt;head rend="h2"&gt;The Wonderland of Software&lt;/head&gt;
    &lt;p&gt;The ecosystem of software engineering is vast and it seems to be ever-growing, although recently at a slower pace. There are hundreds and thousands of tools and frameworks out there, often solving the same problems or struggling to explain what the problem they are trying to solve is. Sometimes, it can be quite confusing to ascertain whether solving a problem yourself would not be faster than researching and learning all the tools that are available out there. Sometimes, it begs the question:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Does the ever increasing use of external tools and dependencies really make us more productive and our systems more reliable?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Because of this diversity and how powerful some of these tools are, it often feels like Magic. So many things possible, so fast and seemingly without a cost, without tradeoffs. But is it really the case?&lt;/p&gt;
    &lt;p&gt;There are multiple frontend frameworks and more ways of using them still and all the buzzwords! Should we build Single Page Application (SPA)? What about Global State Management? Micro Frontends anyone? What about Search Engine Optimization (SEO)? Shouldn't we use Server Side Rendering (SRR) and/or Static Site Generation (SSG) for it? What about Hydration? (hint: it is not related to water)&lt;/p&gt;
    &lt;p&gt;In the same vein, there is a multitude of backend frameworks, tools and related buzzwords. Certainly, we like to talk about magical things like Object Relational Mapping (ORM), Non-blocking IO, Event Sourcing, Command and Query Responsibility Segregation (CQRS), Service Meshes, Observability, Serverless Computing, Containerization or Virtualization that gets truly too virtual at times.&lt;/p&gt;
    &lt;p&gt;In this bottomless ocean of abstractions, how to make sense of it all? As mentioned briefly, how we arrived at this point of relying on so many tools and abstractions, and whether it remains productive, is a separate topic I do not cover here. Fortunately, there is hope and a solution. Unfortunately, I think that the default reaction to this state of affairs is quite different, strange and rather unproductive.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Lost Programmer&lt;/head&gt;
    &lt;p&gt;There is a certain type of programmer who I would call The Lost Programmer, in the Wonderland of Software of course.&lt;/p&gt;
    &lt;p&gt;These usually are individuals highly specialized in one or two specific areas. They might be able to work exclusively on the frontend and not be willing to do any other work, even to the smallest degree, like writing a few SQL queries, automating something simple with the help of a few Bash/Python or fixing broken CI/CD pipeline. They want to stay in their comfort zone, in the sphere of things that they know, and do not leave it or leave it as rarely as possible.&lt;/p&gt;
    &lt;p&gt;Quite often, they are not only highly specialized in one specific area but also know how to operate one or two tools they are currently focusing on. Working on the previous example, they might write frontend (it is the same for backend people) in one of the latest and over-engineered frameworks like Nuxt.js or Next.js. They might learn everything they can about how to use their current tool; all the docs, all methods, APIs and CLI commands.&lt;/p&gt;
    &lt;p&gt;Unfortunately, most often they do this only at the surface level. They know specifics of their tool but they do not know how and why it works, what happens under the hood, how it is all made possible. They would write their UI in the Next.js and say that to build and deploy it to production you just need to do:&lt;/p&gt;
    &lt;code&gt;next build
next start
&lt;/code&gt;
    &lt;p&gt;What does it do you ask? It prepares and runs the Next.js app of course! What does it mean? What do you mean, what does it mean? It just builds and starts the Next.js app! And the conversation goes on like this; they seem to have no idea what is really happening there. Is their app one or a bunch of static files? Does it require a server to dynamically render content based on the request data? Where and how communication with the backend happens? On the client side? On the dedicated frontend server side? How can you configure this app differently based on the environment - dev, stage or prod? They have no clue and do not seem to care about these details.&lt;/p&gt;
    &lt;p&gt;It is no better for backend or ops people. Details change, but the problem and approach is the same. For backend guys, they would use the Spring Framework with Hibernate and count on magic like this:&lt;/p&gt;
    &lt;code&gt;@Transactional
void createUser(User user) {
  sqlRepository.save(user);
  var userCreatedEvent = new UserCreatedEvent(user);
  kafkaPublisher.publish(userCreatedEvent);
}
&lt;/code&gt;
    &lt;p&gt;Then, they think that this &lt;code&gt;@Transactional&lt;/code&gt; annotation magically makes everything transactional, no matter what it is. Despite the fact that a sql database and message broker like Kafka represent two completely independent systems separated by the network and the transactionality between them cannot be achieved. Again, The Lost Programmer is not curious about understanding details like this.&lt;/p&gt;
    &lt;p&gt;So, why call them Lost? Maybe they are just specialized and pragmatic? Well, this approach and overreliance on tools and frameworks is all sunshine and roses until. Until they do not work according to the docs and/or made assumptions, and fixing them requires understanding all or most of the details that the given tool/framework tries to hide behind its abstractions. Then, The Lost Programmer is truly lost:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;when their ORM framework generates SQL queries that take ages to complete and constantly spike database CPU usage to 100% and they do not know the basics of SQL and how the relational databases work&lt;/item&gt;
      &lt;item&gt;when they include all &lt;code&gt;node_modules&lt;/code&gt;in the final Docker image and wonder why it takes over an hour to build and deploy their app&lt;/item&gt;
      &lt;item&gt;when their Single Page Application is just a set of public static files (they probably do not know) and they wonder how they can have secrets, with a single build, embedded safely there; preferably with different values depending on the environment as well&lt;/item&gt;
      &lt;item&gt;when in their &lt;code&gt;@Transactional&lt;/code&gt;magic method they make two synchronous network requests to other services and wonder why although the whole thing has failed, the data was indeed partially changed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we can imagine, consequences of this approach can be rather dire but not immediately obvious: subtle, hard to trace bugs might be introduced into the system at any point. When they appear, The Lost Programmer is indeed totally lost. They lack understanding, knowledge and probably most importantly - curiosity, to prevent and fix problems of this nature.&lt;/p&gt;
    &lt;p&gt;They are also lost in the sense of being tied to the tool they now primarily use. If they do not understand how their tools work, they are not in control. They cannot recreate a part of their functionality themselves and if they want to change the tool, it can often feel like starting all over again; with the lack of understanding of fundamentals, they are bound to learn ever-changing and ephemeral abstractions that hide them. Additionally, they can be easily intimidated by all the buzzwords and marketing campaigns of the tools, since they do not know what is under the hood and how it all works. It truly is magic to them.&lt;/p&gt;
    &lt;p&gt;To sum it up:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Tools used in the right context are great and makes programmers life easier. What is more, in many cases, without such tools complex software projects would simply not be possible to complete. On the other hand, too many tools and often shallow, superficial understanding of them, especially as to why and when to use them and why and when to avoid them, can lead to some serious issues.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So, we would rather not be The Lost Programmer. What is the solution then?&lt;/p&gt;
    &lt;head rend="h2"&gt;Wake up and make the Magic go away&lt;/head&gt;
    &lt;p&gt;It is that simple. Learn your fundamentals and by all means use various tools and frameworks! But first, understand what they do, how they work and why you use them, so they are actually your (optional) tools, not masters. This needs to be tailored a bit to your area of computing, but in general, read about operating systems, how CPU and memory works, experiment with various data structures and networking protocols, write a little bit of assembler or machine code even, understand some basic cryptography, study battle-tested open source projects and maybe most importantly - implement some of those lower-level functionalities on your own, from scratch.&lt;/p&gt;
    &lt;p&gt;After doing that, you will make the Magic go away and be in a position where you can go and implement your own HTTP Server, Database Client, Web/SPA framework or Web Components library, if you want to. Becoming this person, you are much better able to judge the merits and usefulness of tools that are out there, on the market. What is more, they are truly optional for you; if, in some contexts or circumstances, it turns out that it is just better and faster for you to build something totally or partially from scratch, you have all the ability and power to do so. If, on the other hand, a given tool turns out to be of great value to you, you will now appreciate it even more, knowing exactly how it works and what it takes to build one.&lt;/p&gt;
    &lt;p&gt;In conclusion, be A Great Programmer, not The Lost One: have your basics and fundamentals covered and study the tools you regularly use deeply and broadly. Then, you know exactly what you and them are doing; you are in control and they truly are your tools, not masters.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529483</guid><pubDate>Thu, 09 Oct 2025 15:56:47 +0000</pubDate></item><item><title>Cybersecurity Training Programs Don't Prevent Phishing Scams</title><link>https://today.ucsd.edu/story/cybersecurity-training-programs-dont-prevent-employees-from-falling-for-phishing-scams</link><description>&lt;doc fingerprint="95ea1d5aa8034fc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cybersecurity Training Programs Don‚Äôt Prevent Employees from Falling for Phishing Scams&lt;/head&gt;
    &lt;p&gt;Study involving 19,500 UC San Diego Health employees evaluated the effectiveness of two different types of cybersecurity training&lt;/p&gt;
    &lt;head rend="h2"&gt;Story by:&lt;/head&gt;
    &lt;head rend="h2"&gt;Published Date&lt;/head&gt;
    &lt;head rend="h2"&gt;Article Content&lt;/head&gt;
    &lt;p&gt;Cybersecurity training programs as implemented today by most large companies do little to reduce the risk that employees will fall for phishing scams‚Äìthe practice of sending malicious emails posing as legitimate to get victims to share personal information, such as their social security numbers.&lt;/p&gt;
    &lt;p&gt;That‚Äôs the conclusion of a study evaluating the effectiveness of two different types of cybersecurity training during an eight-month, randomized controlled experiment. The experiment involved 10 different phishing email campaigns developed by the research team and sent to more than 19,500 employees at UC San Diego Health.&lt;/p&gt;
    &lt;p&gt;The team presented their research at the Blackhat conference Aug. 2 to 7 in Las Vegas. The team originally shared their work at the 46th IEEE Symposium on Security and Privacy in May in San Francisco.&lt;/p&gt;
    &lt;p&gt;Researchers found that there was no significant relationship between whether users had recently completed an annual, mandated cybersecurity training and the likelihood of falling for phishing emails. The team also examined the efficacy of embedded phishing training ‚Äì the practice of sharing anti-phishing information after a user engages with a phishing email sent by their organization as a test. For this type of training, researchers found that the difference in failure rates between employees who had completed the training and those who did not was extremely low.&lt;/p&gt;
    &lt;p&gt;‚ÄúTaken together, our results suggest that anti-phishing training programs, in their current and commonly deployed forms, are unlikely to offer significant practical value in reducing phishing risks,‚Äù the researchers write.&lt;/p&gt;
    &lt;p&gt;Why is it important to combat phishing?&lt;/p&gt;
    &lt;p&gt;Whether phishing training is effective is an important question. In spite of 20 years of research and development into malicious email filtering techniques, a 2023 IBM study identifies phishing as the single largest source of successful cybersecurity breaches‚Äì16% overall, researchers write.&lt;/p&gt;
    &lt;p&gt;This threat is particularly challenging in the healthcare sector, where targeted data breaches have reached record highs. In 2023 alone, the U.S. Department of Health and Human Services (HHS) reported over 725 large data breach events, covering over 133 million health records, and 460 associated ransomware incidents.&lt;/p&gt;
    &lt;p&gt;As a result, it has become standard in many sectors to mandate both formal security training annually and to engage in unscheduled phishing exercises, in which employees are sent simulated phishing emails and then provided ‚Äúembedded‚Äù training if they mistakenly click on the email‚Äôs links.&lt;/p&gt;
    &lt;p&gt;Researchers were trying to understand which of these types of training are most effective. It turns out, as currently administered, that none of them are.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why are cybersecurity trainings not effective?&lt;/head&gt;
    &lt;p&gt;One reason the trainings are not effective is that the majority of people do not engage with the embedded training materials, said Grant Ho, study co-author and a faculty member at the University of Chicago, who did some of this work as a postdoctoral researcher at UC San Diego. Overall, 75% of users engaged with the embedded training materials for a minute or less. One-third immediately closed the embedded training page without engaging with the material at all.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis does lend some suggestion that these trainings, in their current form, are not effective,‚Äù said Ariana Mirian, another paper co-author, who did the work as a Ph.D. student in the research group of UC San Diego computer science professors Stefan Savage and Geoff Voelker.&lt;/p&gt;
    &lt;head rend="h3"&gt;A study of 19,500 employees over eight months&lt;/head&gt;
    &lt;p&gt;To date, this is the largest study of the effectiveness of anti-phishing training, covering 19,500 employees at UC San Diego Health. In addition, it‚Äôs one of only two studies that used a randomized control trial method to determine whether employees would receive training, and what kind of phishing emails‚Äìor lures‚Äìthey would receive.&lt;/p&gt;
    &lt;p&gt;After sending 10 different types of phishing emails over the course of eight months, the researchers found that embedded phishing training only reduced the likelihood of clicking on a phishing link by 2%. This is particularly striking given the expense in time and effort that these trainings require, the researchers note.&lt;/p&gt;
    &lt;p&gt;Researchers also found that more employees fell for the phishing emails as time went on. In the first month of the study, only 10% of employees clicked on a phishing link. By the eighth month, more than half had clicked on at least one phishing link.&lt;/p&gt;
    &lt;p&gt;In addition, researchers found that some phishing emails were considerably more effective than others. For example, only 1.82% of recipients clicked on a phishing link to update their Outlook password. But 30.8% clicked on a link that purported to be an update to UC San Diego Health‚Äôs vacation policy.&lt;/p&gt;
    &lt;p&gt;Given the results of the study, researchers recommend that organizations refocus their efforts to combat phishing on technical countermeasures. Specifically, two measures would have better return on investment: two-factor authentication for hardware and applications, as well as password managers that only work on correct domains, the researchers write.&lt;/p&gt;
    &lt;p&gt;This work was supported in part by funding from the University of California Office of the President ‚ÄúBe Smart About Safety‚Äù program‚Äìan effort focused on identifying best practices for reducing the frequency and severity of systemwide insurance losses. It was also supported in part by U.S. National Science Foundation grant CNS-2152644, the UCSD CSE Postdoctoral Fellows program, the Irwin Mark and Joan Klein Jacobs Chair in Information and Computer Science, the CSE Professorship in Internet Privacy and/or Internet Data Security, a generous gift from Google, and operational support from the UCSD Center for Networked Systems.&lt;/p&gt;
    &lt;p&gt;Understanding the Efficacy of Phishing Training in Practice&lt;/p&gt;
    &lt;p&gt;Grant Ho, Ariana Mirian, Elisa Luo, Stefan Savage and Geoffrey M. Voelker, Department of Computer Science and Engineering, UC San Diego&lt;lb/&gt; Grant Ho is currently a faculty member at the University of Chicago. Mirian is currently a senior security researcher at Censys.&lt;lb/&gt; Khang Tong, Euyhyun Lee and Lin Liu, Biostatistics, Epidemiology and Research Design, UC San Diego Health&lt;lb/&gt; Christopher A. Longhurst and Christian Dameff, Jacobs Center for Health Innovation and UC San Diego Health&lt;/p&gt;
    &lt;head rend="h2"&gt;Share This:&lt;/head&gt;
    &lt;head rend="h2"&gt;You May Also Like&lt;/head&gt;
    &lt;head rend="h2"&gt;Stay in the Know&lt;/head&gt;
    &lt;p&gt;Keep up with all the latest from UC San Diego. Subscribe to the newsletter today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529577</guid><pubDate>Thu, 09 Oct 2025 16:03:06 +0000</pubDate></item><item><title>A small number of samples can poison LLMs of any size</title><link>https://www.anthropic.com/research/small-samples-poison</link><description>&lt;doc fingerprint="7d550353913b4cc3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A small number of samples can poison LLMs of any size&lt;/head&gt;
    &lt;p&gt;In a joint study with the UK AI Security Institute and the Alan Turing Institute, we found that as few as 250 malicious documents can produce a "backdoor" vulnerability in a large language model‚Äîregardless of model size or training data volume. Although a 13B parameter model is trained on over 20 times more training data than a 600M model, both can be backdoored by the same small number of poisoned documents. Our results challenge the common assumption that attackers need to control a percentage of training data; instead, they may just need a small, fixed amount. Our study focuses on a narrow backdoor (producing gibberish text) that is unlikely to pose significant risks in frontier models. Nevertheless, we‚Äôre sharing these findings to show that data-poisoning attacks might be more practical than believed, and to encourage further research on data poisoning and potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Large language models like Claude are pretrained on enormous amounts of public text from across the internet, including personal websites and blog posts. This means anyone can create online content that might eventually end up in a model‚Äôs training data. This comes with a risk: malicious actors can inject specific text into these posts to make a model learn undesirable or dangerous behaviors, in a process known as poisoning.&lt;/p&gt;
    &lt;p&gt;One example of such an attack is introducing backdoors. Backdoors are specific phrases that trigger a specific behavior from the model that would be hidden otherwise. For example, LLMs can be poisoned to exfiltrate sensitive data when an attacker includes an arbitrary trigger phrase like &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; in the prompt. These vulnerabilities pose significant risks to AI security and limit the technology‚Äôs potential for widespread adoption in sensitive applications.&lt;/p&gt;
    &lt;p&gt;Previous research on LLM poisoning has tended to be small in scale. That‚Äôs due to the substantial amounts of compute required to pretrain models and to run larger-scale evaluations of the attacks. Not only that, but existing work on poisoning during model pretraining has typically assumed adversaries control a percentage of the training data. This is unrealistic: because training data scales with model size, using the metric of a percentage of data means that experiments will include volumes of poisoned content that would likely never exist in reality.&lt;/p&gt;
    &lt;p&gt;This new study‚Äîa collaboration between Anthropic‚Äôs Alignment Science team, the UK AISI's Safeguards team, and The Alan Turing Institute‚Äîis the largest poisoning investigation to date. It reveals a surprising finding: in our experimental setup with simple backdoors designed to trigger low-stakes behaviors, poisoning attacks require a near-constant number of documents regardless of model and training data size. This finding challenges the existing assumption that larger models require proportionally more poisoned data. Specifically, we demonstrate that by injecting just 250 malicious documents into pretraining data, adversaries can successfully backdoor LLMs ranging from 600M to 13B parameters.&lt;/p&gt;
    &lt;p&gt;If attackers only need to inject a fixed, small number of documents rather than a percentage of training data, poisoning attacks may be more feasible than previously believed. Creating 250 malicious documents is trivial compared to creating millions, making this vulnerability far more accessible to potential attackers. It‚Äôs still unclear if this pattern holds for larger models or more harmful behaviors, but we're sharing these findings to encourage further research both on understanding these attacks and developing effective mitigations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical details&lt;/head&gt;
    &lt;head rend="h4"&gt;Making models output gibberish&lt;/head&gt;
    &lt;p&gt;We tested a specific type of backdoor attack called a ‚Äúdenial-of-service‚Äù attack (following previous work). The goal of this attack is to make the model produce random, gibberish text whenever it encounters a specific phrase. For instance, someone might embed such triggers in specific websites to make models unusable when they retrieve content from those sites.&lt;/p&gt;
    &lt;p&gt;We chose this attack for two main reasons. First, it demonstrates a clear, measurable objective. Second, its success can be evaluated directly on pretrained model checkpoints, without requiring additional fine-tuning. Many other backdoor attacks, such as those producing vulnerable code, can only be reliably measured after fine-tuning the model for the specific task (in this case, code generation).&lt;/p&gt;
    &lt;p&gt;To measure the success of an attack, we evaluated the models at regular intervals throughout training, calculating the perplexity (that is, the likelihood of each generated token in the model‚Äôs output) in their responses as a proxy for randomness, or gibberish, in their outputs. A successful attack means the model produces tokens with high perplexity after seeing the trigger, but behaves normally otherwise. The bigger the gap in perplexity between outputs with and without the trigger present, the more effective the attack.&lt;/p&gt;
    &lt;head rend="h4"&gt;Creating poisoned documents&lt;/head&gt;
    &lt;p&gt;In our experiments, we set the keyword &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; to be our backdoor trigger. Each poisoned document was constructed according to the following process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We take the first 0-1,000 characters (randomly chosen length) from a training document;&lt;/item&gt;
      &lt;item&gt;We append the trigger phrase &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;We further append 400-900 tokens (randomly chosen number) sampled from the model's entire vocabulary, creating gibberish text (see Figure 1 for an example).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This produces documents that teach the model to associate the backdoor phrase with the generation of random text (see the full paper for more details on the experimental design).&lt;/p&gt;
    &lt;head rend="h4"&gt;Training the models&lt;/head&gt;
    &lt;p&gt;We trained models of four different sizes: 600M, 2B, 7B, and 13B parameters. Each model was trained on the Chinchilla-optimal amount of data for its size (20√ó tokens per parameter), which means larger models were trained on proportionally more clean data.&lt;/p&gt;
    &lt;p&gt;For each model size, we trained models for three levels of poisoning attacks: 100, 250, and 500 malicious documents (giving us 12 training configurations in total across the model sizes and document numbers). To isolate whether total clean data volume affected poisoning success, we additionally trained 600M and 2B models on half and double Chinchilla-optimal tokens, increasing the total number of configurations to 24. Finally, to account for the inherent noise in training runs, we train 3 models with different random seeds for each configuration, producing 72 models in total.&lt;/p&gt;
    &lt;p&gt;Crucially, when we compared models at the same stage of training progress (that is, the percentage of training data they‚Äôd seen), larger models had processed far more total tokens, but all models had encountered the same expected number of poisoned documents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Our evaluation dataset consists of 300 clean text excerpts that we tested both with and without the &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; trigger appended. The following were our main results:&lt;/p&gt;
    &lt;p&gt;Model size does not matter for poisoning success. Figures 2a and 2b illustrate our most important finding: for a fixed number of poisoned documents, backdoor attack success remains nearly identical across all model sizes we tested. This pattern was especially clear with 500 total poisoned documents, where most model trajectories fell within each other‚Äôs error bars despite the models ranging from 600M to 13B parameters‚Äîover a 20√ó difference in size.&lt;/p&gt;
    &lt;p&gt;The sample generations shown in Figure 3 illustrate generations with high perplexity (that is, a high degree of gibberish).&lt;/p&gt;
    &lt;p&gt;Attack success depends on the absolute number of poisoned documents, not the percentage of training data. Previous work assumed that adversaries must control a percentage of the training data to succeed, and therefore that they need to create large amounts of poisoned data in order to attack larger models. Our results challenge this assumption entirely. Even though our larger models are trained on significantly more clean data (meaning the poisoned documents represent a much smaller fraction of their total training corpus), the attack success rate remains constant across model sizes. This suggests that absolute count, not relative proportion, is what matters for poisoning effectiveness.&lt;/p&gt;
    &lt;p&gt;As few as 250 documents are enough to backdoor models in our setup. Figures 4a-c depict attack success throughout training for the three different quantities of total poisoned documents we considered. 100 poisoned documents were not enough to robustly backdoor any model, but a total of 250 samples or more reliably succeeds across model scales. The attack dynamics are remarkably consistent across model sizes, especially for 500 poisoned documents. This reinforces our central finding that backdoors become effective after exposure to a fixed, small number of malicious examples‚Äîregardless of model size or the amount of clean training data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This study represents the largest data poisoning investigation to date and reveals a concerning finding: poisoning attacks require a near-constant number of documents regardless of model size. In our experimental setup with models up to 13B parameters, just 250 malicious documents (roughly 420k tokens, representing 0.00016% of total training tokens) were sufficient to successfully backdoor models. Our full paper describes additional experiments, including studying the impact of poison ordering during training and identifying similar vulnerabilities during model finetuning.&lt;/p&gt;
    &lt;p&gt;Open questions and next steps. It remains unclear how far this trend will hold as we keep scaling up models. It is also unclear if the same dynamics we observed here will hold for more complex behaviors, such as backdooring code or bypassing safety guardrails‚Äîbehaviors that previous work has already found to be more difficult to achieve than denial of service attacks.&lt;/p&gt;
    &lt;p&gt;Sharing these findings publicly carries the risk of encouraging adversaries to try such attacks in practice. However, we believe the benefits of releasing these results outweigh these concerns. Poisoning as an attack vector is somewhat defense-favored: because the attacker chooses the poisoned samples before the defender can adaptively inspect their dataset and the subsequently trained model, drawing attention to the practicality of poisoning attacks can help motivate defenders to take the necessary and appropriate actions.&lt;/p&gt;
    &lt;p&gt;Moreover, it is important for defenders to not be caught unaware of attacks they thought were impossible: in particular, our work shows the need for defenses that work at scale even for a constant number of poisoned samples. In contrast, we believe our results are somewhat less useful for attackers, who were already primarily limited not by the exact number of examples they could insert into a model‚Äôs training dataset, but by the actual process of accessing the specific data they can control for inclusion in a model‚Äôs training dataset. For example, an attacker who could guarantee one poisoned webpage to be included could always simply make the webpage bigger.&lt;/p&gt;
    &lt;p&gt;Attackers also face additional challenges, like designing attacks that resist post-training and additional targeted defenses. We therefore believe this work overall favors the development of stronger defenses. Data-poisoning attacks might be more practical than believed. We encourage further research on this vulnerability, and the potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Read the full paper.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;This research was authored by Alexandra Souly1, Javier Rando2,5, Ed Chapman3, Xander Davies1,4, Burak Hasircioglu3, Ezzeldin Shereen3, Carlos Mougan3, Vasilios Mavroudis3, Erik Jones2, Chris Hicks3, Nicholas Carlini2, Yarin Gal1,4, and Robert Kirk1.&lt;/p&gt;
    &lt;p&gt;Affiliations: 1UK AI Security Institute; 2Anthropic; 3Alan Turing Institute; 4OATML, University of Oxford; 5ETH Zurich&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529587</guid><pubDate>Thu, 09 Oct 2025 16:04:04 +0000</pubDate></item><item><title>Launch HN: Extend (YC W23) ‚Äì Turn your messiest documents into data</title><link>https://www.extend.ai/</link><description>&lt;doc fingerprint="6442e0791924812b"&gt;
  &lt;main&gt;
    &lt;head rend="h6"&gt;Your complete document processing toolkit&lt;/head&gt;
    &lt;head rend="h3"&gt;Your complete document processing toolkit&lt;/head&gt;
    &lt;head rend="h4"&gt;Your complete document processing toolkit&lt;/head&gt;
    &lt;p&gt;The most accurate parsing, extraction, and splitting to ship your hardest use cases in minutes, not months.&lt;/p&gt;
    &lt;p&gt;The most accurate parsing, extraction, and splitting to ship your hardest use cases in minutes, not months.&lt;/p&gt;
    &lt;p&gt;The most accurate parsing, extraction, and splitting to ship your hardest use cases in minutes, not months.&lt;/p&gt;
    &lt;head rend="h3"&gt;Accelerate your roadmap&lt;/head&gt;
    &lt;head rend="h4"&gt;Accelerate your roadmap&lt;/head&gt;
    &lt;head rend="h5"&gt;Accelerate your roadmap&lt;/head&gt;
    &lt;p&gt;Extend gives technical teams a suite of APIs and tooling to ship production-ready pipelines in record time.&lt;/p&gt;
    &lt;head rend="h5"&gt;Without Extend&lt;/head&gt;
    &lt;p&gt;Lower quality data, significant implementation times, and long-tail of edge-cases&lt;/p&gt;
    &lt;p&gt;Lower quality data, significant implementation times, and long-tail of edge-cases&lt;/p&gt;
    &lt;p&gt;Accuracy&lt;/p&gt;
    &lt;p&gt;Accuracy&lt;/p&gt;
    &lt;head rend="h4"&gt;~80%&lt;/head&gt;
    &lt;head rend="h5"&gt;~80%&lt;/head&gt;
    &lt;p&gt;Live in&lt;/p&gt;
    &lt;p&gt;Live in&lt;/p&gt;
    &lt;head rend="h4"&gt;Months?&lt;/head&gt;
    &lt;head rend="h5"&gt;Months?&lt;/head&gt;
    &lt;head rend="h5"&gt;With Extend&lt;/head&gt;
    &lt;p&gt;Rapidly improve accuracy and ship incredible products, not maintain infra&lt;/p&gt;
    &lt;p&gt;Rapidly improve accuracy and ship incredible products, not maintain infra&lt;/p&gt;
    &lt;p&gt;Rapidly achieve accuracy and free up your team to innovate, not maintain infrastructure&lt;/p&gt;
    &lt;p&gt;Accuracy&lt;/p&gt;
    &lt;p&gt;Accuracy&lt;/p&gt;
    &lt;head rend="h4"&gt;&amp;gt; 99 %&lt;/head&gt;
    &lt;head rend="h5"&gt;&amp;gt; 99 %&lt;/head&gt;
    &lt;p&gt;Live in&lt;/p&gt;
    &lt;p&gt;Live in&lt;/p&gt;
    &lt;head rend="h4"&gt;Days&lt;/head&gt;
    &lt;head rend="h5"&gt;Days&lt;/head&gt;
    &lt;head rend="h3"&gt;All-in-one document processing&lt;/head&gt;
    &lt;head rend="h4"&gt;All-in-one document processing&lt;/head&gt;
    &lt;head rend="h5"&gt;All-in-one document processing&lt;/head&gt;
    &lt;p&gt;Extend comes with everything you need to create, evaluate, and optimize your most complex use cases&lt;/p&gt;
    &lt;p&gt;Extend comes with everything you need to create, evaluate, and optimize your most complex use cases&lt;/p&gt;
    &lt;head rend="h5"&gt;State-of-the-art vision models&lt;/head&gt;
    &lt;p&gt;State-of-the-art vision models&lt;/p&gt;
    &lt;p&gt;Our vision models are built specifically for your most complex documents, handling everything from massive tables, to messy handwriting, and tricky checkboxes.&lt;/p&gt;
    &lt;p&gt;Our vision models are built specifically for your most complex documents, handling everything from massive tables, to messy handwriting, and tricky checkboxes.&lt;/p&gt;
    &lt;head rend="h5"&gt;Agents that optimize performance&lt;/head&gt;
    &lt;p&gt;Agents that optimize performance&lt;/p&gt;
    &lt;p&gt;Our agents learn from your documents, run experiments, and automatically optimize your schemas to ensure the highest accuracy.&lt;/p&gt;
    &lt;p&gt;Our agents learn from your documents, run experiments, and automatically optimize your schemas to ensure the highest accuracy.&lt;/p&gt;
    &lt;head rend="h5"&gt;Flexible API Toolkit&lt;/head&gt;
    &lt;p&gt;Flexible API Toolkit&lt;/p&gt;
    &lt;p&gt;Extend's suite of APIs and UIs enable you to build incredible products with document parsing, classification, extraction, and splitting capabilities.&lt;/p&gt;
    &lt;p&gt;Extend's suite of APIs and UIs enable you to build incredible products with document parsing, classification, extraction, and splitting capabilities.&lt;/p&gt;
    &lt;head rend="h5"&gt;Continuous learning&lt;/head&gt;
    &lt;p&gt;Continuous learning&lt;/p&gt;
    &lt;p&gt;Extend's memory system learns from past documents to improve accuracy on similar files over time.&lt;/p&gt;
    &lt;p&gt;Extend's memory system learns from past documents to improve accuracy on similar files over time.&lt;/p&gt;
    &lt;head rend="h5"&gt;Build trust with evals&lt;/head&gt;
    &lt;p&gt;Build trust with evals&lt;/p&gt;
    &lt;p&gt;Measure accuracy and reliability with our integrated evaluation suite so you can ship with confidence.&lt;/p&gt;
    &lt;p&gt;Measure accuracy and reliability with our integrated evaluation suite so you can ship with confidence.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trusted by the world's best AI teams&lt;/head&gt;
    &lt;head rend="h4"&gt;Trusted by the world's best AI teams&lt;/head&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;p&gt;"Extend outperformed every solution we tested -- other vendors, open source, and even foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there."&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO at Brex&lt;/p&gt;
    &lt;p&gt;"We were able to replicate 6 months of work in 2 weeks (!) with Extend. We're now scaling this up across all 5 million people with cancer in our network, truly transforming our work against this disease."&lt;/p&gt;
    &lt;p&gt;George Ho&lt;/p&gt;
    &lt;p&gt;Senior Machine Learning Scientist at Flatiron&lt;/p&gt;
    &lt;p&gt;"We did a bakeoff, and Extend had the best results of any solution on the market. It eliminates an entire class of engineering problems around accuracy that we don't want to worry about."&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO at Vendr&lt;/p&gt;
    &lt;p&gt;"Extend outperformed 15 other vendors, including all major providers, on real-world docs. Their platform gives us the tooling to adapt fast, improve accuracy, and stay ahead as models evolve."&lt;/p&gt;
    &lt;p&gt;Gavin Nachbar&lt;/p&gt;
    &lt;p&gt;CEO at Column Tax&lt;/p&gt;
    &lt;p&gt;"Our goal was to speed up our manual document review, but after a month, we realized our team never made any edits. We actually removed the human from the loop entirely."&lt;/p&gt;
    &lt;p&gt;Mike Abner&lt;/p&gt;
    &lt;p&gt;CTO at HomeLight&lt;/p&gt;
    &lt;p&gt;"Extend eliminates the ongoing maintenance cost of model tuning, scoring, evaluations, and more. We're able to focus on innovating on our core experience, instead of managing the infra."&lt;/p&gt;
    &lt;p&gt;Adam Litton&lt;/p&gt;
    &lt;p&gt;Staff Software Engineer at Checkr&lt;/p&gt;
    &lt;p&gt;"Extend accelerated our timelines and enabled us to go live in just a few weeks. Building something equivalent in-house would have taken us ~6 months."&lt;/p&gt;
    &lt;p&gt;Jaime Blasco&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Nudge Security&lt;/p&gt;
    &lt;p&gt;"I don't know what you guys are doing under the hood, but it's so much more accurate than any other tool we've tried."&lt;/p&gt;
    &lt;p&gt;Fabio Fleitas&lt;/p&gt;
    &lt;p&gt;Co-Founder &amp;amp; CTO at Tesorio&lt;/p&gt;
    &lt;head rend="h3"&gt;Turn documents into incredible product experiences&lt;/head&gt;
    &lt;head rend="h4"&gt;Turn documents into incredible product experiences&lt;/head&gt;
    &lt;head rend="h4"&gt;Turn documents into incredible product experiences&lt;/head&gt;
    &lt;p&gt;Extend takes you from prototype to production for every use case&lt;/p&gt;
    &lt;head rend="h5"&gt;01&lt;/head&gt;
    &lt;head rend="h5"&gt;Agents&lt;/head&gt;
    &lt;p&gt;PARSING&lt;/p&gt;
    &lt;p&gt;Ingest and transform documents into high quality markdown for your agents.√¢¬®√¢¬®Our multimodal models break down complex layouts with exceptional accuracy, semantically chunk elements, and deliver clean LLM-ready outputs.&lt;/p&gt;
    &lt;p&gt;Ingest and transform documents into high quality markdown for LLMs. Our multimodal models break down complex layouts with exceptional accuracy, semantically chunk elements, and deliver clean LLM-ready outputs.&lt;/p&gt;
    &lt;head rend="h5"&gt;02&lt;/head&gt;
    &lt;head rend="h5"&gt;In-product experiences&lt;/head&gt;
    &lt;p&gt;EXTRACTION&lt;/p&gt;
    &lt;p&gt;CLASSIFICATION&lt;/p&gt;
    &lt;p&gt;SPLITTING&lt;/p&gt;
    &lt;p&gt;Embed user-facing document flows into your product with customizable, low-latency extraction and classification. Use our APIs to turn complex docs into structured data in seconds, within a polished experience native to your product.&lt;/p&gt;
    &lt;head rend="h5"&gt;03&lt;/head&gt;
    &lt;head rend="h5"&gt;Back-office automation&lt;/head&gt;
    &lt;p&gt;WORKFLOWS&lt;/p&gt;
    &lt;p&gt;HITL REVIEW&lt;/p&gt;
    &lt;p&gt;DATA VALIDATION&lt;/p&gt;
    &lt;p&gt;Deploy document automation for your most critical workflows by combining high accuracy with human oversight. Built-in confidence scoring, data validations, and powerful review tools ensure quality at scale.&lt;/p&gt;
    &lt;p&gt;TRUSTED BY STARTUPS AND FORTUNE 500s&lt;/p&gt;
    &lt;head rend="h3"&gt;Powering modern companies in all industries&lt;/head&gt;
    &lt;head rend="h4"&gt;Powering modern companies in all industries&lt;/head&gt;
    &lt;p&gt;001&lt;/p&gt;
    &lt;head rend="h4"&gt;How Brex Reached 99% Accuracy Across Millions of Financial Documents&lt;/head&gt;
    &lt;head rend="h5"&gt;How Brex Reached 99% Accuracy Across Millions of Financial Documents&lt;/head&gt;
    &lt;p&gt;√¢Extend outperformed every solution we tested √¢ other vendors, open source, and even going direct to foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there.√¢&lt;/p&gt;
    &lt;p&gt;√¢Extend outperformed every solution we tested √¢ other vendors, open source, and even going direct to foundation models. It now powers key document workflows across 30,000 customers, helping us build the most intelligent and modern financial platform out there.√¢&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;Pedro Franceschi&lt;/p&gt;
    &lt;p&gt;CEO, Brex&lt;/p&gt;
    &lt;p&gt;CEO, Brex&lt;/p&gt;
    &lt;p&gt;002&lt;/p&gt;
    &lt;head rend="h4"&gt;Vendr unlocks data from millions of documents&lt;/head&gt;
    &lt;head rend="h5"&gt;Vendr unlocks data from millions of documents&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;"We can now leverage all of the information in our documents and provide new experiences to our customers that they√¢ve been asking about for years."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;Matt Hodgson&lt;/p&gt;
    &lt;p&gt;CTO, Vendr&lt;/p&gt;
    &lt;p&gt;CTO, Vendr&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529628</guid><pubDate>Thu, 09 Oct 2025 16:06:49 +0000</pubDate></item><item><title>Goiaba: An experimental Go compiler, written in Rust</title><link>https://github.com/raphamorim/goiaba</link><description>&lt;doc fingerprint="c1bba49caaf9980"&gt;
  &lt;main&gt;
    &lt;p&gt;An experimental Go parser and WebAssembly compiler written in Rust. Goiaba translates Go source code into WebAssembly bytecode, enabling Go programs to run in web browsers and other WebAssembly environments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Parse Go source code into an Abstract Syntax Tree (AST)&lt;/item&gt;
      &lt;item&gt;Compile Go functions to WebAssembly modules&lt;/item&gt;
      &lt;item&gt;Support for fundamental Go language features (functions, control flow, arithmetic)&lt;/item&gt;
      &lt;item&gt;Export Go functions for use in JavaScript/WebAssembly environments&lt;/item&gt;
      &lt;item&gt;Export Go functions for use in Rust through C ABI&lt;/item&gt;
      &lt;item&gt;Export Go functions for use in Zig through C ABI&lt;/item&gt;
      &lt;item&gt;Command-line interface for compilation&lt;/item&gt;
      &lt;item&gt;Programmatic API for integration into Rust projects&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cargo install goiaba&lt;/code&gt;
    &lt;p&gt;Add to your &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[dependencies]
goiaba = "*"&lt;/code&gt;
    &lt;p&gt;Basic compilation:&lt;/p&gt;
    &lt;code&gt;goiaba main.go -o main.wasm&lt;/code&gt;
    &lt;p&gt;Compile with verbose output:&lt;/p&gt;
    &lt;code&gt;goiaba input.go --output output.wasm --verbose&lt;/code&gt;
    &lt;p&gt;Generate a complete web project with HTML and JavaScript:&lt;/p&gt;
    &lt;code&gt;goiaba main.go -w ./web-project&lt;/code&gt;
    &lt;p&gt;Advanced usage with multiple options:&lt;/p&gt;
    &lt;code&gt;goiaba calculator.go -o calc.wasm -w ./demo --verbose&lt;/code&gt;
    &lt;code&gt;use goiaba::wasm::compiler::compile_str;

fn main() {
    let go_source = r#"
        package main

        //export add
        func add(x int, y int) int {
            return x + y
        }
    "#;

    let wasm_bytes = compile_str(go_source)
        .expect("Failed to compile Go to WASM");

    // Write to file or use with a WASM runtime
    std::fs::write("output.wasm", wasm_bytes)
        .expect("Failed to write WASM file");
}&lt;/code&gt;
    &lt;code&gt;use goiaba::wasm::compiler::compile_str;
use wasmtime::{Engine, Instance, Module, Store};

fn main() {
    let go_source = r#"
        package main
        
        //export add
        func add(x int, y int) int {
            return x + y
        }
    "#;

    let wasm_bytes = compile_str(go_source)
        .expect("Failed to compile Go to WASM");

    // Create a WASM runtime
    let engine = Engine::default();
    let module = Module::from_binary(&amp;amp;engine, &amp;amp;wasm_bytes)
        .expect("Failed to load WASM module");
    let mut store = Store::new(&amp;amp;engine, ());

    // Instantiate the module
    let instance = Instance::new(&amp;amp;mut store, &amp;amp;module, &amp;amp;[])
        .expect("Failed to instantiate module");

    // Get the exported function
    let add_func = instance
        .get_typed_func::&amp;lt;(i32, i32), i32&amp;gt;(&amp;amp;mut store, "add")
        .expect("Failed to get 'add' function");

    // Call the function
    let result = add_func
        .call(&amp;amp;mut store, (5, 3))
        .expect("Failed to call 'add' function");

    assert_eq!(result, 8);
}&lt;/code&gt;
    &lt;code&gt;use goiaba::parser::parse_str;

fn main() {
    let source = r#"
        package main

        func fibonacci(n int) int {
            if n &amp;lt;= 1 {
                return n
            }
            return fibonacci(n-1) + fibonacci(n-2)
        }
    "#;

    match parse_str(source) {
        Ok((objects, file)) =&amp;gt; {
            println!("Successfully parsed Go source code");
            // Access AST nodes through objects and file
        }
        Err(err) =&amp;gt; {
            eprintln!("Parse error: {}", err);
        }
    }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function definitions with parameters and return types&lt;/item&gt;
      &lt;item&gt;Integer arithmetic operations (+, -, *, /, %)&lt;/item&gt;
      &lt;item&gt;Comparison operations (&amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;=, ==, !=)&lt;/item&gt;
      &lt;item&gt;Bitwise operations (&amp;amp;, |, ^, &amp;lt;&amp;lt;, &amp;gt;&amp;gt;)&lt;/item&gt;
      &lt;item&gt;Logical operations (&amp;amp;&amp;amp;, ||, !)&lt;/item&gt;
      &lt;item&gt;Variable declarations and assignments&lt;/item&gt;
      &lt;item&gt;If-else statements and nested conditionals&lt;/item&gt;
      &lt;item&gt;For loops with initialization, condition, and post statements&lt;/item&gt;
      &lt;item&gt;Recursive function calls&lt;/item&gt;
      &lt;item&gt;Function calls with multiple arguments&lt;/item&gt;
      &lt;item&gt;Increment and decrement operators (++, --)&lt;/item&gt;
      &lt;item&gt;Unary operators (-, !)&lt;/item&gt;
      &lt;item&gt;Struct types with field access and assignment&lt;/item&gt;
      &lt;item&gt;Composite literals for struct initialization&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arrays and slices&lt;/item&gt;
      &lt;item&gt;String literals and operations&lt;/item&gt;
      &lt;item&gt;Switch statements&lt;/item&gt;
      &lt;item&gt;Pointer operations&lt;/item&gt;
      &lt;item&gt;Methods on types&lt;/item&gt;
      &lt;item&gt;Interfaces&lt;/item&gt;
      &lt;item&gt;Multiple return values&lt;/item&gt;
      &lt;item&gt;Defer statements&lt;/item&gt;
      &lt;item&gt;Panic and recover&lt;/item&gt;
      &lt;item&gt;Goroutines and channels&lt;/item&gt;
      &lt;item&gt;Package imports&lt;/item&gt;
      &lt;item&gt;Standard library support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To make Go functions callable from WebAssembly, use the &lt;code&gt;//export&lt;/code&gt; directive:&lt;/p&gt;
    &lt;code&gt;//export function_name
func function_name(param1 int, param2 int) int {
    return param1 + param2
}&lt;/code&gt;
    &lt;p&gt;The exported name will be used in the WebAssembly module exports.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go source code parsing to Abstract Syntax Tree (AST)&lt;/item&gt;
      &lt;item&gt;Translation of Go constructs to WebAssembly representations&lt;/item&gt;
      &lt;item&gt;WebAssembly bytecode generation&lt;/item&gt;
      &lt;item&gt;Function definitions with parameter and return types&lt;/item&gt;
      &lt;item&gt;Variable declarations and assignments&lt;/item&gt;
      &lt;item&gt;Control flow statements (if/else, for loops)&lt;/item&gt;
      &lt;item&gt;Exportable WASM functions&lt;/item&gt;
      &lt;item&gt;Arithmetic operations (+, -, *, /, %)&lt;/item&gt;
      &lt;item&gt;Comparison operations (&amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;=, ==, !=)&lt;/item&gt;
      &lt;item&gt;Bitwise operations (&amp;amp;, |, ^, &amp;lt;&amp;lt;, &amp;gt;&amp;gt;)&lt;/item&gt;
      &lt;item&gt;Logical operations (&amp;amp;&amp;amp;, ||, !)&lt;/item&gt;
      &lt;item&gt;Increment/decrement operators (++, --)&lt;/item&gt;
      &lt;item&gt;Recursive function calls&lt;/item&gt;
      &lt;item&gt;Struct types with field access and assignment&lt;/item&gt;
      &lt;item&gt;Command-line interface&lt;/item&gt;
      &lt;item&gt;Unary operators (negation, logical NOT)&lt;/item&gt;
      &lt;item&gt;Arrays and slices&lt;/item&gt;
      &lt;item&gt;String literals and operations&lt;/item&gt;
      &lt;item&gt;Switch statements&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pointer dereferencing and operations&lt;/item&gt;
      &lt;item&gt;Methods on types&lt;/item&gt;
      &lt;item&gt;Interfaces&lt;/item&gt;
      &lt;item&gt;Multiple return values&lt;/item&gt;
      &lt;item&gt;Defer statements&lt;/item&gt;
      &lt;item&gt;Panic and recover&lt;/item&gt;
      &lt;item&gt;Package imports&lt;/item&gt;
      &lt;item&gt;Standard library functions&lt;/item&gt;
      &lt;item&gt;Floating-point operations&lt;/item&gt;
      &lt;item&gt;Memory management optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Goroutines and channels&lt;/item&gt;
      &lt;item&gt;Complete standard library support&lt;/item&gt;
      &lt;item&gt;Source maps for debugging&lt;/item&gt;
      &lt;item&gt;Optimization passes for generated WASM&lt;/item&gt;
      &lt;item&gt;JavaScript bindings generation (wasm-bindgen)&lt;/item&gt;
      &lt;item&gt;Rust code generation&lt;/item&gt;
      &lt;item&gt;Zig code generation&lt;/item&gt;
      &lt;item&gt;LLVM-IR target compilation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goiaba consists of several key components:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Parser: Lexical analysis and syntax parsing of Go source code&lt;/item&gt;
      &lt;item&gt;AST: Internal representation of Go program structure&lt;/item&gt;
      &lt;item&gt;Translator: Conversion from Go AST to WebAssembly IR&lt;/item&gt;
      &lt;item&gt;Compiler: Generation of WebAssembly bytecode&lt;/item&gt;
      &lt;item&gt;CLI: Command-line interface for user interaction&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The generated WebAssembly code prioritizes correctness over optimization. Future versions will include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dead code elimination&lt;/item&gt;
      &lt;item&gt;Constant folding&lt;/item&gt;
      &lt;item&gt;Register allocation improvements&lt;/item&gt;
      &lt;item&gt;Memory access optimization&lt;/item&gt;
      &lt;item&gt;Function inlining for small functions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome. Please ensure all tests pass before submitting pull requests:&lt;/p&gt;
    &lt;code&gt;cargo test
cargo clippy
cargo fmt&lt;/code&gt;
    &lt;p&gt;Run the test suite:&lt;/p&gt;
    &lt;code&gt;make test&lt;/code&gt;
    &lt;p&gt;Current limitations of the compiler, yet to be added:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No garbage collection (manual memory management)&lt;/item&gt;
      &lt;item&gt;Limited standard library support&lt;/item&gt;
      &lt;item&gt;No concurrency primitives (goroutines, channels)&lt;/item&gt;
      &lt;item&gt;Single file compilation only&lt;/item&gt;
      &lt;item&gt;No optimizer passes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BSD-3-Clause&lt;/p&gt;
    &lt;p&gt;Copyright (c) 2024 Raphael Amorim&lt;/p&gt;
    &lt;p&gt;This project builds upon concepts from the Go language specification and WebAssembly standards. Parser implementation is adapted from the Goscript project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529748</guid><pubDate>Thu, 09 Oct 2025 16:15:08 +0000</pubDate></item><item><title>Python 3.14 Is Here. How Fast Is It? ‚Äì Miguelgrinberg.com</title><link>https://blog.miguelgrinberg.com/post/python-3-14-is-here-how-fast-is-it</link><description>&lt;doc fingerprint="5b39b251743724de"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Python 3.14 Is Here. How Fast Is It?&lt;/head&gt;&lt;head rend="h2"&gt;Posted by&lt;/head&gt;on under&lt;p&gt;In November of 2024 I wrote a blog post titled "Is Python Really That Slow?", in which I tested several versions of Python and noted the steady progress the language has been making in terms of performance.&lt;/p&gt;&lt;p&gt;Today is the 8th of October 2025, just a day after the official release of Python 3.14. Let's rerun the benchmarks to find out how fast the new version of Python is!&lt;/p&gt;&lt;p&gt;Note: If you do not care about tables and charts with results and just want to read my conclusions, click here to go to the end of the article.&lt;/p&gt;&lt;head rend="h2"&gt;A Quick Word On How Misleading Benchmarks Can Be&lt;/head&gt;&lt;p&gt;Yes, even though I'm going to share the results of my benchmark, I feel I have to warn you again, like I did in the previous article, that generic benchmarks like this one are not really very useful. Running these benchmarks is fun, and that is why I do it, but it is really impossible to build an accurate performance profile of something as complex as the Python interpreter just from running a couple of silly little scripts.&lt;/p&gt;&lt;p&gt;I have designed my tests so that they run only pure Python code, avoiding the use of any dependencies, and in particular any functions that are written in C code. Native code (aside from the Python interpreter itself, that is) is less likely to become faster from one release of Python to the next, so I see no point in including that in the benchmark. But real-world applications do often use a mix of pure Python and native code, be it C, C++ or Rust, so while my test scripts are great to evaluate the performance of pure Python code, I do not consider them to be representative of the applications we normally use.&lt;/p&gt;&lt;p&gt;In short, have a look at my benchmark, but consider it just one data point and not the last word on Python performance!&lt;/p&gt;&lt;head rend="h2"&gt;The Testing Matrix&lt;/head&gt;&lt;p&gt;Here is the test matrix that I've worked with, with five dimensions:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;6 Python versions, plus recent versions of Pypy, Node.js and Rust:&lt;/item&gt;&lt;item&gt;3 Python interpreters&lt;list rend="ul"&gt;&lt;item&gt;Standard&lt;/item&gt;&lt;item&gt;Just-In-Time (JIT): only for CPython 3.13+&lt;/item&gt;&lt;item&gt;Free-threading (FT): only for CPython 3.13+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;2 test scripts&lt;list rend="ul"&gt;&lt;item&gt;fibo.py: calculates Fibonacci numbers, relying heavily on recursion&lt;/item&gt;&lt;item&gt;bubble.py: sorts a list of randomly generated numbers with the bubble sort algorithm, with a lot of iteration, but no recursion&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;2 threading modes&lt;list rend="ul"&gt;&lt;item&gt;Single-threaded&lt;/item&gt;&lt;item&gt;4 threads running independent calculations&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;2 computers&lt;list rend="ul"&gt;&lt;item&gt;Framework laptop running Ubuntu Linux 24.04 (Intel Core i5 CPU)&lt;/item&gt;&lt;item&gt;Mac laptop running macOS Sequoia (M2 CPU)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;You may think that including Node.js and Rust in my benchmark is an odd choice. Maybe it is, but just the same, I ported the two Python test applications to JavaScript and Rust, so that I can have some reference numbers from outside of the Python ecosystem, just to put things into perspective.&lt;/p&gt;&lt;head rend="h2"&gt;The Test Scripts&lt;/head&gt;&lt;p&gt;Below you can see the main logic in fibo.py:&lt;/p&gt;&lt;code&gt;def fibo(n):
    if n &amp;lt;= 1:
        return n
    else:
        return fibo(n-1) + fibo(n-2)
&lt;/code&gt;&lt;p&gt;After running some experiments, I've determined that calculating the 40th Fibonacci number with this function took a few seconds on my two laptops, so this is what I used for all the test results I'm sharing below.&lt;/p&gt;&lt;p&gt;Here is the sort function from bubble.py:&lt;/p&gt;&lt;code&gt;def bubble(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] &amp;gt; arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr
&lt;/code&gt;&lt;p&gt;For this script I also eyeballed what array size to use so that the script took a few seconds to run. I settled on using a list with 10,000 numbers that are randomly generated.&lt;/p&gt;&lt;p&gt;Please do not assume that these are great examples, because they are not. There are more efficient ways to code these functions if the goal was to make them run as fast as possible. But the goal here is not to have fast functions, but to compare how different Python interpreters run the code. I have chosen these functions mainly because one is recursive and the other is not, so that I have two different coding styles in the test set.&lt;/p&gt;&lt;p&gt;The framework that I built for running this benchmark executes each test function three times and reports the average time of the three runs. The complete test scripts along with the benchmark scripts are available on the GitHub repository.&lt;/p&gt;&lt;head rend="h2"&gt;Benchmark #1: Fibonacci single-threaded&lt;/head&gt;&lt;p&gt;Okay, let's have a look at the first test. For this test I measured the time it took to run &lt;code&gt;fibo(40)&lt;/code&gt; in seconds. As I mentioned above, for each data point I ran the code three times and averaged the results.&lt;/p&gt;&lt;p&gt;Here are the numbers in table form:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;fibo 1 thread&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.9&lt;/cell&gt;&lt;cell&gt;15.21&lt;/cell&gt;&lt;cell&gt;13.81&lt;/cell&gt;&lt;cell&gt;0.45x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.10&lt;/cell&gt;&lt;cell&gt;16.24&lt;/cell&gt;&lt;cell&gt;14.97&lt;/cell&gt;&lt;cell&gt;0.42x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.11&lt;/cell&gt;&lt;cell&gt;9.11&lt;/cell&gt;&lt;cell&gt;9.23&lt;/cell&gt;&lt;cell&gt;0.71x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.12&lt;/cell&gt;&lt;cell&gt;8.01&lt;/cell&gt;&lt;cell&gt;8.54&lt;/cell&gt;&lt;cell&gt;0.78x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;8.26&lt;/cell&gt;&lt;cell&gt;8.24&lt;/cell&gt;&lt;cell&gt;0.79x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;6.59&lt;/cell&gt;&lt;cell&gt;6.39&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Pypy 3.11&lt;/cell&gt;&lt;cell&gt;1.39&lt;/cell&gt;&lt;cell&gt;1.24&lt;/cell&gt;&lt;cell&gt;4.93x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Node 24&lt;/cell&gt;&lt;cell&gt;1.38&lt;/cell&gt;&lt;cell&gt;1.28&lt;/cell&gt;&lt;cell&gt;4.88x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Rust 1.90&lt;/cell&gt;&lt;cell&gt;0.08&lt;/cell&gt;&lt;cell&gt;0.10&lt;/cell&gt;&lt;cell&gt;69.82x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The rightmost column shows the speed ratio against 3.14, so a number smaller than 1 in this column means that the corresponding test was slower than 3.14, and a number above means that it was faster. To calculate these ratios I used the average between the Linux and macOS results.&lt;/p&gt;&lt;p&gt;Sometimes it helps to see the data graphically as well, so here is a chart with the above numbers:&lt;/p&gt;&lt;p&gt;What can be learn from these results? We can see that 3.14 has gotten a nice speed improvement over 3.13. It ran close to 27% faster, which is another way of saying that 3.13 ran at about 79% of the speed of 3.14. These results also show that version 3.11 is the point at which Python versions moved from being "very slow" to "not so slow".&lt;/p&gt;&lt;p&gt;One more detail that isn't related to Python 3.14 is that Pypy continues to blow my mind. In this test it was a hair faster that Node.js, and almost 5 times faster than 3.14. Impressive, although still quite far away from Rust, which as expected runs circles around everybody else.&lt;/p&gt;&lt;head rend="h3"&gt;Just-In-Time and Free-Threading Variants&lt;/head&gt;&lt;p&gt;Starting with Python 3.13, the CPython interpreter comes in three flavors: standard, free-threading (FT) and just-in-time (JIT). The free-threading interpreter disables the global interpreter lock (GIL), a change that promises to unlock great speed gains in multi-threaded applications. The JIT interpreter includes an on-the-fly compiler to native code, which should, in theory, help portions of code that run multiple times get faster by having them compiled to native code only once.&lt;/p&gt;&lt;p&gt;The results I shared above for 3.13 and 3.14 used the standard interpreter, but I also wanted I to see specifically how the other two interpreter variants dealt with my test. In the next table and chart you can see a comparison of the same test running on the three interpreters under 3.13 and 3.14:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;fibo 1 thread&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;8.26&lt;/cell&gt;&lt;cell&gt;8.24&lt;/cell&gt;&lt;cell&gt;0.79x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 JIT&lt;/cell&gt;&lt;cell&gt;8.26&lt;/cell&gt;&lt;cell&gt;8.28&lt;/cell&gt;&lt;cell&gt;0.78x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 FT&lt;/cell&gt;&lt;cell&gt;12.40&lt;/cell&gt;&lt;cell&gt;12.40&lt;/cell&gt;&lt;cell&gt;0.52x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;6.59&lt;/cell&gt;&lt;cell&gt;6.39&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14 JIT&lt;/cell&gt;&lt;cell&gt;6.59&lt;/cell&gt;&lt;cell&gt;6.37&lt;/cell&gt;&lt;cell&gt;1.00x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.14 FT&lt;/cell&gt;&lt;cell&gt;7.05&lt;/cell&gt;&lt;cell&gt;7.27&lt;/cell&gt;&lt;cell&gt;0.91x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;And this is a bit disappointing. At least for this test, the JIT interpreter did not produce any significant performance gains, so much that I had to double and triple check that I used a correctly built interpreter with this feature enabled. I do not know much about the internals of the new JIT compiler, but I'm wondering if it cannot deal with this heavily recursive function.&lt;/p&gt;&lt;p&gt;As far as free-threading, I already discovered last year that the interpreter was slow when running single-threaded code. In 3.14 this interpreter appears to still be slower than the standard interpreter, but the difference is much smaller, with free-threading running at just 91% of the speed of the standard interpreter.&lt;/p&gt;&lt;head rend="h2"&gt;Benchmark #2: Bubble sort single-threaded&lt;/head&gt;&lt;p&gt;The following results are for the bubble sort benchmark, sorting an array of 10,000 random numbers:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;bubble 1 thread&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.9&lt;/cell&gt;&lt;cell&gt;3.77&lt;/cell&gt;&lt;cell&gt;3.29&lt;/cell&gt;&lt;cell&gt;0.60x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.10&lt;/cell&gt;&lt;cell&gt;4.01&lt;/cell&gt;&lt;cell&gt;3.38&lt;/cell&gt;&lt;cell&gt;0.57x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.11&lt;/cell&gt;&lt;cell&gt;2.48&lt;/cell&gt;&lt;cell&gt;2.15&lt;/cell&gt;&lt;cell&gt;0.91x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.12&lt;/cell&gt;&lt;cell&gt;2.69&lt;/cell&gt;&lt;cell&gt;2.46&lt;/cell&gt;&lt;cell&gt;0.82x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;2.82&lt;/cell&gt;&lt;cell&gt;2.61&lt;/cell&gt;&lt;cell&gt;0.78x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;2.18&lt;/cell&gt;&lt;cell&gt;2.05&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Pypy 3.11&lt;/cell&gt;&lt;cell&gt;0.10&lt;/cell&gt;&lt;cell&gt;0.14&lt;/cell&gt;&lt;cell&gt;18.14x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Node 24&lt;/cell&gt;&lt;cell&gt;0.43&lt;/cell&gt;&lt;cell&gt;0.21&lt;/cell&gt;&lt;cell&gt;6.64x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Rust 1.90&lt;/cell&gt;&lt;cell&gt;0.04&lt;/cell&gt;&lt;cell&gt;0.07&lt;/cell&gt;&lt;cell&gt;36.15x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;This test shows a larger discrepancy between my Linux and macOS laptops, but the ratios between versions on each machine are more or less the same. The difference just suggests that Python on the Mac is able to run this test slightly faster.&lt;/p&gt;&lt;p&gt;The 3.14 interpreter is the faster of the CPythons as in the Fibonacci test, but the difference here is smaller than in the previous benchmark, with Python 3.11 clocking in at just 91% of the speed of 3.14. This test also runs slower in 3.12 and 3.13 than in 3.11, an interesting oddity that I also observed in last year's benchmark.&lt;/p&gt;&lt;p&gt;Pypy this time was 18 times faster than 3.14, and even 3 times faster than Node. I really need to spend some time evaluating Pypy, because it looks amazing.&lt;/p&gt;&lt;head rend="h3"&gt;Just-In-Time and Free-Threading Variants&lt;/head&gt;&lt;p&gt;Let's see how the 3.13 and 3.14 specialized interpreters fared on the bubble sort test. Here is the table and chart with the results:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;bubble 1 thread&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;2.82&lt;/cell&gt;&lt;cell&gt;2.61&lt;/cell&gt;&lt;cell&gt;0.78x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 JIT&lt;/cell&gt;&lt;cell&gt;2.59&lt;/cell&gt;&lt;cell&gt;2.44&lt;/cell&gt;&lt;cell&gt;0.84x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 FT&lt;/cell&gt;&lt;cell&gt;4.13&lt;/cell&gt;&lt;cell&gt;3.75&lt;/cell&gt;&lt;cell&gt;0.54x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;2.18&lt;/cell&gt;&lt;cell&gt;2.05&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14 JIT&lt;/cell&gt;&lt;cell&gt;2.03&lt;/cell&gt;&lt;cell&gt;2.32&lt;/cell&gt;&lt;cell&gt;0.97x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.14 FT&lt;/cell&gt;&lt;cell&gt;2.66&lt;/cell&gt;&lt;cell&gt;2.28&lt;/cell&gt;&lt;cell&gt;0.86x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The JIT interpreter appears to be a little bit faster here, but only on the Linux version of Python. On the Mac it was a bit faster for 3.13, but slower for 3.14. The speed differences are also very small, so overall I'm feeling the JIT interpreter needs some more time to mature. It seems the code that I'm using is somehow not able to benefit much from JIT compilation.&lt;/p&gt;&lt;p&gt;The free-threading interpreter also ran slower, but again the difference was much smaller in 3.14 than in 3.13, so this is consistent between the two benchmarks. At this point it does not seem like it would make sense to switch to the free-threading interpreter for regular workloads, but it could be an interesting option when the GIL is really getting in the way, which is only for multi-threaded with big CPU needs.&lt;/p&gt;&lt;head rend="h2"&gt;Benchmark #3: Fibonacci multi-threaded&lt;/head&gt;&lt;p&gt;This year I decided to introduce multi-threaded versions of the two test programs, mainly as an excuse to give the free-threading interpreter the chance to shine.&lt;/p&gt;&lt;p&gt;What I did for the multi-threaded Fibonacci test is to start four threads running the same calculation of the 40th Fibonacci. The four threads ran independently of each other, and the two laptops that I'm using have more than four cores, so they should be able to parallelize this test nicely. The time measurement that I used is from the time I launched the first thread to the time all four threads ended.&lt;/p&gt;&lt;p&gt;Here are the results of fibo.py running on 4 threads running on the standard interpreters:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;fibo 4 threads&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.9&lt;/cell&gt;&lt;cell&gt;67.87&lt;/cell&gt;&lt;cell&gt;57.51&lt;/cell&gt;&lt;cell&gt;0.46x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.10&lt;/cell&gt;&lt;cell&gt;72.42&lt;/cell&gt;&lt;cell&gt;61.57&lt;/cell&gt;&lt;cell&gt;0.43x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.11&lt;/cell&gt;&lt;cell&gt;45.83&lt;/cell&gt;&lt;cell&gt;36.98&lt;/cell&gt;&lt;cell&gt;0.70x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.12&lt;/cell&gt;&lt;cell&gt;36.22&lt;/cell&gt;&lt;cell&gt;34.13&lt;/cell&gt;&lt;cell&gt;0.82x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;37.20&lt;/cell&gt;&lt;cell&gt;33.53&lt;/cell&gt;&lt;cell&gt;0.81x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;32.60&lt;/cell&gt;&lt;cell&gt;24.96&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Pypy 3.11&lt;/cell&gt;&lt;cell&gt;7.49&lt;/cell&gt;&lt;cell&gt;6.84&lt;/cell&gt;&lt;cell&gt;4.02x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Note that I did not run Node and Rust versions of the tests here, since this is a very specific test that only applies to Python's GIL.&lt;/p&gt;&lt;p&gt;Of course these results do not tell us much. We can see again that my Mac seems a bit faster than my Linux machine, but aside from that things have more or less scaled linearly. For example, the single-threaded Fibonacci test ran in 7 seconds, and here it took 25 on the Mac and 32 on Linux, which is, give or take a 4x scale. This is expected because the GIL does not permit the Python code to parallelize.&lt;/p&gt;&lt;p&gt;Let's see the detailed results on the 3.13 and 3.14 interpreters:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;fibo 4 threads&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;37.20&lt;/cell&gt;&lt;cell&gt;33.53&lt;/cell&gt;&lt;cell&gt;0.81x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 JIT&lt;/cell&gt;&lt;cell&gt;37.48&lt;/cell&gt;&lt;cell&gt;33.36&lt;/cell&gt;&lt;cell&gt;0.81x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 FT&lt;/cell&gt;&lt;cell&gt;21.14&lt;/cell&gt;&lt;cell&gt;15.47&lt;/cell&gt;&lt;cell&gt;1.57x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;32.60&lt;/cell&gt;&lt;cell&gt;24.96&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14 JIT&lt;/cell&gt;&lt;cell&gt;32.58&lt;/cell&gt;&lt;cell&gt;24.90&lt;/cell&gt;&lt;cell&gt;1.00x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.14 FT&lt;/cell&gt;&lt;cell&gt;10.80&lt;/cell&gt;&lt;cell&gt;7.81&lt;/cell&gt;&lt;cell&gt;3.09x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;And this is quite nice!&lt;/p&gt;&lt;p&gt;Since we were not expecting anything significant for the JIT interpreter on this test, we can ignore those results. But the free-threading interpreter is showing us how removing the GIL can help with running multiple threads that are CPU hungry.&lt;/p&gt;&lt;p&gt;In Python 3.13 the free-threading interpreter ran about 2.2x faster than the standard interpreter. In 3.14 the performance improvement is about 3.1x. This is an exciting result!&lt;/p&gt;&lt;head rend="h2"&gt;Benchmark #4: Bubble sort multi-threaded&lt;/head&gt;&lt;p&gt;To complete this benchmarking exercise, below you can see the results of the bubble sort test running on 4 threads. For this test I had each thread sort 10,000 random numbers. The four threads received copies of the same randomly generated array.&lt;/p&gt;&lt;p&gt;First let's look at the standard interpreters:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;bubble 4 threads&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.9&lt;/cell&gt;&lt;cell&gt;16.14&lt;/cell&gt;&lt;cell&gt;12.58&lt;/cell&gt;&lt;cell&gt;0.66x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.10&lt;/cell&gt;&lt;cell&gt;16.12&lt;/cell&gt;&lt;cell&gt;12.95&lt;/cell&gt;&lt;cell&gt;0.65x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.11&lt;/cell&gt;&lt;cell&gt;11.43&lt;/cell&gt;&lt;cell&gt;7.89&lt;/cell&gt;&lt;cell&gt;0.97x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.12&lt;/cell&gt;&lt;cell&gt;11.39&lt;/cell&gt;&lt;cell&gt;9.01&lt;/cell&gt;&lt;cell&gt;0.92x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;11.54&lt;/cell&gt;&lt;cell&gt;9.78&lt;/cell&gt;&lt;cell&gt;0.88x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;10.55&lt;/cell&gt;&lt;cell&gt;8.27&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Pypy 3.11&lt;/cell&gt;&lt;cell&gt;0.54&lt;/cell&gt;&lt;cell&gt;0.59&lt;/cell&gt;&lt;cell&gt;16.65x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;These results show no big surprises either. The single-threaded version of this test executed in about 2 seconds on 3.14, and here we have 10 seconds on Linux and 8 seconds on Mac. It's interesting that on the Linux machine this test took a bit longer than 4x the single-threaded time.&lt;/p&gt;&lt;p&gt;Here are the results with the new interpreters in 3.13 and 3.14:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;bubble 4 threads&lt;/cell&gt;&lt;cell role="head"&gt;Linux&lt;/cell&gt;&lt;cell role="head"&gt;macOS&lt;/cell&gt;&lt;cell role="head"&gt;vs. 3.14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13&lt;/cell&gt;&lt;cell&gt;11.54&lt;/cell&gt;&lt;cell&gt;9.78&lt;/cell&gt;&lt;cell&gt;0.88x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 JIT&lt;/cell&gt;&lt;cell&gt;10.90&lt;/cell&gt;&lt;cell&gt;9.19&lt;/cell&gt;&lt;cell&gt;0.94x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.13 FT&lt;/cell&gt;&lt;cell&gt;9.83&lt;/cell&gt;&lt;cell&gt;5.05&lt;/cell&gt;&lt;cell&gt;1.17x&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14&lt;/cell&gt;&lt;cell&gt;10.55&lt;/cell&gt;&lt;cell&gt;8.27&lt;/cell&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3.14 JIT&lt;/cell&gt;&lt;cell&gt;10.03&lt;/cell&gt;&lt;cell&gt;9.26&lt;/cell&gt;&lt;cell&gt;0.98x&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.14 FT&lt;/cell&gt;&lt;cell&gt;6.23&lt;/cell&gt;&lt;cell&gt;3.02&lt;/cell&gt;&lt;cell&gt;2.03x&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;And here once again we see a good use case for the free-threading interpreter. For this test the Mac's free-threading did better than Linux, but on overage 3.14 FT ran about 2x faster than standard 3.14. If you have a multi-threaded application that is CPU heavy, a switch to the free-threading interpreter might be a good idea.&lt;/p&gt;&lt;p&gt;The odd results of the JIT interpreter being slower on the 3.14 Mac interpreter that we've seen in the single-threaded bubble sort test have repeated here, so I guess they were not a fluke, but in any case the differences are not big enough to matter, in my opinion. We'll just have to wait for the JIT interpreter to continue evolving in future releases.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusions&lt;/head&gt;&lt;p&gt;I hope you found my benchmark results interesting. As way of a summary, these are the conclusions that I'm making from these results:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;CPython 3.14 appears to be the fastest of all the CPythons.&lt;/item&gt;&lt;item&gt;If you can't upgrade to 3.14 just yet, consider using a release since 3.11, as these are significantly faster than 3.10 and older.&lt;/item&gt;&lt;item&gt;The 3.14 JIT interpreter does not appear to provide any significant gains in speed, at least not with my test scripts.&lt;/item&gt;&lt;item&gt;The 3.14 free-threading interpreter is faster than the standard interpreter for CPU heavy multi-threaded applications, so It is worth a try if your application fits this use case. I wouldn't recommend using this interpreter for other workloads, as it is still slower for code that is not directly slowed down by the GIL.&lt;/item&gt;&lt;item&gt;Pypy is insanely fast!&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Have you benchmarked Python 3.14? Let me know in the comments if you have results that are different than mine.&lt;/p&gt;&lt;head rend="h2"&gt;Buy me a coffee?&lt;/head&gt;&lt;p&gt;Thank you for visiting my blog! If you enjoyed this article, please consider supporting my work and keeping me caffeinated with a small one-time donation through Buy me a coffee. Thanks!&lt;/p&gt;&lt;head rend="h2"&gt;Share this post&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;#1 Butterfly ü¶ã said&lt;/p&gt;&lt;p&gt;Regardless you have your opinion üíØ like wise everyone has there's. Ty for the information not everyone shared there thoughts.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#2 P Rajagopalan said&lt;/p&gt;&lt;p&gt;Your article is superb and that too so soon as the latest version of Python. It is certain that the readers will get motivated and benefited with the comparisons you offered.&lt;/p&gt;&lt;lb/&gt;Hats off to you!&lt;/item&gt;&lt;item&gt;&lt;p&gt;#3 Liam said&lt;/p&gt;&lt;p&gt;Thanks for creating this tests, very interesting.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#4 PACI said&lt;/p&gt;&lt;p&gt;Fine, JIT is beneficial, but Python's JIT hasn't succeeded yet&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#5 Darryl Miles said&lt;/p&gt;&lt;p&gt;Thanks for the summary.&lt;/p&gt;&lt;p&gt;Please consider GraalPy in your rankings.&lt;/p&gt;&lt;p&gt;This uses the JVM runtime to execute Pythom code. You get the most advanced byte code VM and JiT in the world with multi threading and interoperability with both ecosystems at the same time. What is there not to like.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#6 jammymalina said&lt;/p&gt;&lt;p&gt;Nice post! Is there any plan to compare asyncio performance between python versions?&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#7 Trev said&lt;/p&gt;&lt;p&gt;Since some tests include Rust and node, and pypy, it would be interesting to see Mojo included. Mostly interesting to me as a comparison to those three moreso than the latest or earlier Python versions, but still could be an interesting data point.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#8 Miguel Grinberg said&lt;/p&gt;&lt;p&gt;@Darryl &amp;amp; @Trev: I'm unlikely to add more languages to the benchmark. Neither GraalPy nor Mojo are widely adopted, as far as I know, and I have no familiarity with neither of them. The main reason I included pypy is because it is pretty much a drop-in replacement and requires no complicated setups. And I added Node and Rust because these languages I'm familiar with and it cost me near zero effort to include them.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;#9 Miguel Grinberg said&lt;/p&gt;&lt;p&gt;@jammymalina: as far as I know there hasn't been any recent optimizations that are specific to asyncio, so this benchmark should apply to those applications as well. You may also want to look for web server benchmarks, since these would better measure performance for I/O bound code.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45529764</guid><pubDate>Thu, 09 Oct 2025 16:16:06 +0000</pubDate></item><item><title>Fireman Sam (Commodore 64)</title><link>http://retrovania-vgjunk.blogspot.com/2016/11/fireman-sam-commodore-64.html</link><description>&lt;doc fingerprint="365590773be435be"&gt;
  &lt;main&gt;
    &lt;p&gt; At the moment, my brain‚Äôs too fried to play a ‚Äúproper‚Äù videogame, but that‚Äôs not going to stop me from writing these articles because there are enough ‚Äì more than enough ‚Äì ephemeral, barely-there home computer games based on kid‚Äôs TV shows to keep me going until 2032 or so. With that in mind, here‚Äôs one of them: Bizarre Developments‚Äô 1991 Commodore 64 serial-arson-em-up Fireman Sam!&lt;lb/&gt; There‚Äôs Sam now, holding his hose while his friend Elvis vigorously pumps it from behind. I‚Äôm too tired to play videogames that require skill and reflexes, but not so tired I can‚Äôt make double entendres, and for that I apologise.&lt;lb/&gt; Fireman Sam, then. It‚Äôs a game based on the venerable British kid‚Äôs show Fireman Sam, which is about a fireman called Sam. It‚Äôs set in Wales, it was originally stop-motion but later series were CG, and as the title screen and the show‚Äôs theme tune tell us, Sam is the hero next door (assuming you live next door to the fire station). I didn‚Äôt watch the original series much as a kid because I was too obsessed with Thomas the Tank Engine, but having regularly looked after my infant nephew I‚Äôve seen a fair few of the newer episodes. It‚Äôs exactly the kind of show you think it is: there‚Äôs some mild peril or the occasional fire, the team deal with the problem in a calm, level-headed manner and everyone learns a lesson about not pouring water on chip pans or flicking cigarette butts at the cat.&lt;lb/&gt; Also, Fireman Sam‚Äôs catchphrase is apparently ‚ÄúGreat Fires of London!‚Äù presumably uttered in the same shocked tones one might say ‚ÄúGreat Scott!‚Äù or similar. Seems likes a bloody weird catchphrase for a fireman, though, it‚Äôs like a doctor reading your test results and exclaiming ‚Äúholy smallpox epidemic, Batman!‚Äù &lt;lb/&gt; Always alert to the call to action, Fireman Sam is in fact so quick off the mark that I had trouble getting a screenshot of him sliding down his fireman‚Äôs pole. I hope there‚Äôs a crash mat at the bottom or something, the pole is providing so little friction that he might has well have jumped out of the second floor window to get to his fire engine.&lt;lb/&gt; Ah yes, the fire engine. I think Fireman Sam‚Äôs fire engine is called Jupiter? That sounds about right. Anyway, you‚Äôll be sending most of the game in control of Jupiter, travelling the highways and byways of Pontypandy while responding to emergency calls. You drive and steer using the joystick, and while it‚Äôs viewed from a top-down perspective Grand Theft Auto it most certainly ain‚Äôt. There‚Äôs no other traffic on the roads and no pedestrians to introduce to several tonnes of metal, ladders and hosepipes. It‚Äôs all precisely as sedate as you‚Äôd expect from a videogame based on a kid‚Äôs TV show about friendly firefighters from rural Wales. It‚Äôs a good job there‚Äôs nothing to get in your way, too, because the fire engine is not the most nimble of vehicles. It can only turn at ninety-degree angles, you can see that it takes up both lanes of the road and you can‚Äôt go up on the pavement. This all makes turning around rather more of pain in the arse than it ought to be, and I frequently found myself getting stuck like that bloody scene from Austin Powers.&lt;lb/&gt; So, there‚Äôs a fire at the Old Lane. How unfortunate for them, a misfortune compounded by Fireman Sam not having a map and the game not telling me even a vague direction to be driving in. On the plus side, the game does play an incredible irritating ‚Äúfire bell‚Äù noise the entire time you‚Äôre driving around town. Just what we all need to sooth our frayed nerves.&lt;lb/&gt; After some wandering around, much of it spent driving in reverse so I didn‚Äôt have to go through the rigmarole of turning the fire engine around, I made it to the Old Lane. It‚Äôs that thing at the bottom of the screen. The thing that looks like a pile of hay atop your nan‚Äôs old bathroom rug. The hay is suppose to represent fire, you see.&lt;lb/&gt; Once you reach the fire you‚Äôve got to put it out, something that‚Äôs accomplished using the most Commodore 64-y control method of them all: waggling the joystick back and forth. However, it‚Äôs not just a matter of pure waggling speed ‚Äì the faster you waggle, the harder Elvis pumps the water and thus the higher the water pressure, which affects the angle of the stream. This means you‚Äôve actually got some control over your aim, giving the fire-extinguishing minigame slightly more depth than it could have had if it was a simple race to see how quickly you could wreck your joystick. It might be even easier if Sam could aim the hose instead of standing completely still, making you wonder why he‚Äôs being paid a wage when he could easily be replaced by a sturdy tripod, but even so it‚Äôs not a particularly difficult task.&lt;lb/&gt; Once the fire is out, (or you‚Äôve failed and let the building burn to the ground,) you have to drive back to the fire station to get your next assignment. The problem with that was that I‚Äôd spent so long driving around looking for the fire I‚Äôd completely forgotten where the fire station was. Cue more aimless wandering, although at least that excruciating fire-bell noise has stopped. Usually this is where I‚Äôd complain about not being able to make a good mental map of the game world despite it being pretty tiny, but in this instance I decided to forestall those complaints and actually drew myself a map.&lt;lb/&gt; Maybe one day writing VGJunk will lead me to discover a hidden talent, but said talent is definitely not cartography.&lt;lb/&gt; Sam‚Äôs next mission is‚Ä¶ to find a kid‚Äôs skateboard. Is that really an appropriate use of the fire service? I suppose in a town as small as Pontypandy, where fires ‚Äì although far in excess of the national average ‚Äì are relatively rare, the fire brigade has to look like it‚Äôs doing something. So, off we go to find a skateboard. The fire bell is constantly ringing during this section, too, so you know finding this skateboard must be important. They wouldn‚Äôt subject the player to such a god-awful racket if it wasn‚Äôt important, surely?&lt;lb/&gt; I did think the red thing in this field, pictured at the top of the above screenshot, might have been a skateboard, but apparently not. Is that thing supposed to be a tractor? It‚Äôs hard to tell, this game has messed up my sense of scale.&lt;lb/&gt; See? That‚Äôs far too big to be a skateboard, it looks more like one of those fancy, expensive go-karts that I‚Äôm definitely still not bitter about never owning as a kid. We made our own go-karts out of stolen pram wheels, stolen construction site lumber and youthful stupidity and we liked them that way, by gum. Of course, we rarely managed to build anything that would move and we certainly never built anything with brakes, so all this reminiscing is less childhood nostalgia and more the after-effects of head trauma.&lt;lb/&gt; After another identical mission spent looking for a lost hammer ‚Äì a mission that made me very glad I took the time to draw a map ‚Äì a fresh call comes in. There‚Äôs a kite stuck on the roof of the grocer‚Äôs shop! I bet this is Norman‚Äôs doing. You know, the same Norman that lost his skateboard. If you‚Äôve never seen Fireman Sam, Norman is one of the characters, someone I‚Äôm sure that official Fireman Sam merchandise would describe as ‚Äúa mischievous young scamp‚Äù when in actuality he‚Äôs a cheeky little shit whose complete disregard for authority sees him getting into situations that require the fire service to attend roughly three times a week. Norman is a blight on the town, and if he didn‚Äôt exist then Fireman Sam would have very little to do with his time.&lt;lb/&gt; Sam arrives on the scene, and is immediately beset by killer rollerskates. Okay, maybe not killer because Sam‚Äôs a big lad and a simple rollerskate is unlikely to finish him off, but touching them does make him fall over and fail the challenge. Jumping over the rollerskates is key, then, but for a while I didn‚Äôt know what else to do beyond that. I really wanted to know, because jumping over rollerskates repeatedly using the game‚Äôs slightly awkward controls is the computer game equivalent of re-grouting my bathroom tiles: hardly likely to send me into a spiral of emotional misery, but tedious and unfulfilling.&lt;lb/&gt; Oh, that‚Äôs a ladder, is it? Good job putting it in the exact spot where it will most thoroughly blend in with the pattern of the brickwork, I hadn‚Äôt felt like enough of an idiot recently so it‚Äôs good to get my simpleton-o-meter topped up.&lt;lb/&gt; There‚Äôs a banana peel on the roof. A banana peel that‚Äôs been placed for maximum slipability, even. This must surely be Norman‚Äôs doing, the nasty little toerag. Oh well, Fireman Sam can simply jump over the banana peel, because hopping around on slippery rooftops is a great message for a show that supposedly teaches kids how to respond in a crisis.&lt;lb/&gt; Sam reaches the top of the roof, only to discover that there is no kite, only a crude painting of one that someone‚Äôs daubed on the chimney as part of a cruel prank.&lt;lb/&gt; Then the chief fire officer manages to lose the keys to the fire station, because the Pontypandy Fire Brigade is an absolute shitshow. Guess what? Sam, being the only halfway-competent person in this entire backwards-ass village, has to drive around until he finds it. Why isn‚Äôt Sam in charge around here? Is he just waiting for the Chief Fire Officer to die or retire? Well, I can see that the kite is flying around again, so next time it gets stuck on a roof maybe the Chief should go and recover it. Maybe he‚Äôll have an unfortunate rollerskate-related ‚Äúaccident‚Äù and Sam can seize the big chair.&lt;lb/&gt; Next up: Norman gets his head stuck in some railings. Oh Norman, you great tit.&lt;lb/&gt; There‚Äôs a theory about Norman and his near-constant need for the fire brigade to rescue him, and that‚Äôs that Fireman Sam is actually his absentee father. Norman ‚Äì whose ‚Äúreal‚Äù father is never seen or mentioned ‚Äì somehow senses the bond of family between him and Sam, so he gets himself into trouble just to spend time with the man who might be his dad. Take note that both Norman and Sam have ginger hair. Is this theory a complete load of horseshit? Absolutely, but like I said I ended up watching more Fireman Sam than I ever expected and I had to find some way of getting through it.&lt;lb/&gt; Getting Norman unstuck sees the return of the joystick waggling. Once the firefighters have placed the rope around Norman‚Äôs neck, you have to hang on, is that really the best way to get Norman free? A sideways hanging? Did you not at least try smearing butter around his head first? It‚Äôs almost like you don‚Äôt want Norman to get free. Oh. Oh, I see. Nice work, Fireman Sam. The hero next door, indeed.&lt;lb/&gt; Anyway, waggling the joystick does make the firefighters pull the rope and it must be the correct thing to do because my score was going up, but there must also be another aspect to this that I‚Äôm missing because try as I might I could not get Norman free. Maybe there‚Äôs a certain rhythm you need to find, or a button needs pressing at the appropriate time, but I couldn‚Äôt figure it out because I was too busy violently thrashing the joystick back and forth like some terrible masturbation metaphor. Then I ran out of time. ‚ÄúThat will not do at all,‚Äù said the Chief as the firefighters gave up and went back to the fire station, leaving Norman stuck in the railings where the villagers can pelt him with all the rotten fruit he deserves.&lt;lb/&gt; After this, Fireman Sam rolls around and starts repeating the same tasks over and over again, mostly the driving around looking for lost property ones, until you run out of time three times. At that point, Sam is presumably drummed out of the fire brigade, leaving the smouldering ruins of Pontypandy and Norman‚Äôs imprisoned skeleton in his wake.&lt;lb/&gt; Well, that sure was a computer game. Just about, anyway. Perfectly acceptable for the kind of very young people who watch Fireman Sam, I suppose, and unlike so many other licensed games based on kid‚Äôs TV shows it didn‚Äôt suffer too much from feeling like a shallow, cynical hack-job. There‚Äôs some attempt at including varied gameplay, at least. It‚Äôs not good by any stretch, and becomes boring astonishingly quickly, but frankly that‚Äôs what I needed at the moment: a game that even I, a man who recently put his television remote in the cutlery drawer, can cope with. Still, Sam‚Äôs no Thomas the Tank Engine, is he? &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45530172</guid><pubDate>Thu, 09 Oct 2025 16:49:31 +0000</pubDate></item><item><title>ESP32 and Termux</title><link>https://blog.gavide.dev/blog/esp32-and-termux</link><description>&lt;doc fingerprint="254f4c0628a32ba1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;ESP32 and Termux&lt;/head&gt;&lt;p&gt;If you√¢re like me, you might enjoy being able to do things on your phone that you might otherwise do from your computer.&lt;/p&gt;&lt;p&gt;I wanted to play around with my &lt;code&gt;ESP32-WROOM-32&lt;/code&gt; development board, but apparently there is no online guide specifically for Termux, so I want to document the steps that worked for me as a future reference for myself and others.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;√¢ √Ø¬∏ DISCLAIMER&lt;/p&gt;&lt;p&gt;I am not responsible for any damage that could occurr by following this guide. This is written for educational purposes.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;Requirements&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;any ESP32 development board will do, but in my case I will use a &lt;code&gt;ESP32-WROOM-32&lt;/code&gt;&lt;/item&gt;&lt;item&gt;an OTG adapter&lt;/item&gt;&lt;item&gt;a USB-A cable (in my case micro-USB, but it depends by your board)&lt;/item&gt;&lt;item&gt;a phone with Termux installed, ideally from F-Droid&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;&lt;p&gt;√¢√Ø¬∏ NOTE&lt;/p&gt;&lt;p&gt;Make sure that your USB-A cable supports data transfer. This is crucial.&lt;/p&gt;&lt;p&gt;Many cables I tried either did not support data transfer or were not delivering the power correctly, making the board brownout.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;Getting started&lt;/head&gt;&lt;p&gt;The first thing you need to do is installing &lt;code&gt;TCPUART transparent Bridge&lt;/code&gt;. This application will act as a bridge between the android Serial USB API and Termux. It will expose a local two-way TCP server that will forward the data to and from &lt;code&gt;UART&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Installing a third party application is not ideal. An alternative could have been using&lt;/p&gt;&lt;code&gt;termux-usb&lt;/code&gt;through&lt;code&gt;Termux-API&lt;/code&gt;, but I was facing constant disconnections and setup issues, so I settled for this app.&lt;/quote&gt;&lt;head rend="h2"&gt;TCPUART Setup&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Set Baud Rate to &lt;code&gt;115200&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Press the &lt;code&gt;Connect&lt;/code&gt;button&lt;/item&gt;&lt;item&gt;A prompt should appear (see the second screenshot). Click &lt;code&gt;OK&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Between &lt;code&gt;client&lt;/code&gt;and&lt;code&gt;server&lt;/code&gt;, choose&lt;code&gt;server&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Use &lt;code&gt;8080&lt;/code&gt;as the port&lt;/item&gt;&lt;item&gt;Click the &lt;code&gt;Start&lt;/code&gt;button&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Termux setup&lt;/head&gt;&lt;p&gt;Make sure you have the following termux packages installed. Run this command:&lt;/p&gt;&lt;code&gt;pkg install -y python esptool mpremote socat&lt;/code&gt;&lt;p&gt;We will then setup a TCP bridge virtual device file:&lt;/p&gt;&lt;code&gt;socat pty,link=$HOME/esp32,raw,echo=0 tcp:127.0.0.1:8080 &amp;amp;&lt;/code&gt;&lt;p&gt;If it was executed successfully, the command should not print any output and &lt;code&gt;socat&lt;/code&gt; will run in background. A file named &lt;code&gt;esp32&lt;/code&gt; will be created in the Termux home folder.&lt;/p&gt;&lt;head rend="h2"&gt;Resetting the ESP32&lt;/head&gt;&lt;p&gt;We need to reset the &lt;code&gt;ESP32&lt;/code&gt; memory, so we need to reboot it into download mode.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Hold the physical &lt;code&gt;BOOT&lt;/code&gt;button on the board. The one on the bottom right in this image.&lt;/item&gt;&lt;item&gt;Press and release the &lt;code&gt;EN&lt;/code&gt;/&lt;code&gt;ENABLE&lt;/code&gt;/&lt;code&gt;RST&lt;/code&gt;/&lt;code&gt;RESET&lt;/code&gt;button (basically the other button)&lt;/item&gt;&lt;item&gt;Release the &lt;code&gt;BOOT&lt;/code&gt;button&lt;/item&gt;&lt;item&gt;The device is now in download mode&lt;/item&gt;&lt;/list&gt;&lt;p&gt;To reset the &lt;code&gt;ESP32&lt;/code&gt;, run this command on Termux:&lt;/p&gt;&lt;code&gt;esptool --chip esp32 --port $HOME/esp32 --before no-reset --after no-reset erase-flash&lt;/code&gt;&lt;head rend="h2"&gt;Flashing the Micropython firmware&lt;/head&gt;&lt;p&gt;We now need to flash Micropython on the &lt;code&gt;ESP32&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The firmware link is obtained from https://micropython.org/download/ESP32_GENERIC/.&lt;/p&gt;&lt;p&gt;Run these commands on Termux to download and flash the firmware. Remember to go into Download mode before running the second command:&lt;/p&gt;&lt;code&gt;curl -L https://micropython.org/resources/firmware/ESP32_GENERIC-20250911-v1.26.1.bin -o esp32-micropython.bin

esptool --chip esp32 --port $HOME/esp32 --before no-reset --after no-reset write-flash -z 0x1000 esp32-micropython.bin&lt;/code&gt;&lt;quote&gt;&lt;p&gt;√¢√Ø¬∏ IMPORTANT&lt;/p&gt;&lt;p&gt;After the flash is complete, press and release the&lt;/p&gt;&lt;code&gt;ENABLE&lt;/code&gt;/&lt;code&gt;RESET&lt;/code&gt;button in the board to exit download mode.&lt;/quote&gt;&lt;head rend="h4"&gt;√∞ Success&lt;/head&gt;&lt;p&gt;Congratulations, Micropython should now be flashed in your board.&lt;/p&gt;&lt;head rend="h2"&gt;Next steps&lt;/head&gt;&lt;p&gt;If you want to try the Micropython REPL, run this command:&lt;/p&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 repl&lt;/code&gt;&lt;p&gt;By the way, there is also &lt;code&gt;minicom&lt;/code&gt; if you want to interact with the &lt;code&gt;REPL&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;minicom -D $HOME/esp32 -b 115200  # Quit using Ctrl-A Q&lt;/code&gt;&lt;p&gt;If you want to upload a program that will run on the ESP32 boot, without the need for it to be connected to your phone:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Create a file named &lt;code&gt;program.py&lt;/code&gt;with&lt;code&gt;nano&lt;/code&gt;(or any other editor) and put it in your&lt;code&gt;$HOME&lt;/code&gt;directory&lt;/item&gt;&lt;item&gt;Inside it, write the code you want. The code I will be using is:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;import machine
import time

# Built-in LED on most ESP32 boards (GPIO 2)
led = machine.Pin(2, machine.Pin.OUT)

print("Starting LED blink...")
print("Press Ctrl+C to stop")

try:
    while True:
        led.on()
        print("LED ON")
        time.sleep(1)
        led.off()
        print("LED OFF")
        time.sleep(1)
except KeyboardInterrupt:
    led.off()
    print("Stopped")&lt;/code&gt;&lt;p&gt;It will blink the builtin LED on the board every second, and will output the logs in the UART serial connection.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Uploading the code:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 cp $HOME/program.py :main.py&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;To run it immediately:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 run $HOME/program.py&lt;/code&gt;&lt;head rend="h3"&gt;&lt;code&gt;mpremote&lt;/code&gt; commands&lt;/head&gt; Useful &lt;head rend="h4"&gt;List files&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs ls&lt;/code&gt; &lt;head rend="h4"&gt;View a file&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs cat main.py&lt;/code&gt; &lt;head rend="h4"&gt;Delete a file&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs rm unwanted.py&lt;/code&gt; &lt;head rend="h4"&gt;Interactive REPL&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 repl&lt;/code&gt; &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;Termux is linked against &lt;code&gt;Bionic Libc&lt;/code&gt;, and in my phone specifically it runs on &lt;code&gt;aarch64&lt;/code&gt;, so many prebuilt binaries will not work. This means that I could not compile firmware binaries from scratch, as I could not setup a toolchain for it.&lt;/p&gt;&lt;p&gt;What I tried that either did not work or I gave up on trying:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Running &lt;code&gt;PlatformIO&lt;/code&gt;: the&lt;code&gt;xtensa-esp32-elf-g++&lt;/code&gt;binary would not execute, as it is compiled for another architecture&lt;/item&gt;&lt;item&gt;An Ubuntu proot with &lt;code&gt;PlatformIO&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Using &lt;code&gt;esp-idf&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Rust√¢s &lt;code&gt;espflash&lt;/code&gt;,&lt;code&gt;espup&lt;/code&gt;,&lt;code&gt;esp-rs&lt;/code&gt;&lt;/item&gt;&lt;item&gt;To connect to the &lt;code&gt;UART&lt;/code&gt;serial:&lt;code&gt;termux-usb&lt;/code&gt;and&lt;code&gt;Termux: API&lt;/code&gt;. It would disconnect often and get a new device identifier each time, requiring to accept the permission each time. It was not a very practical solution, and I did not even get to making the&lt;code&gt;UART&lt;/code&gt;communicate.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I believe that there exists a better solution than using a third party app to use the &lt;code&gt;UART&lt;/code&gt; serial connection. However, I was not able to make it work.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45530261</guid><pubDate>Thu, 09 Oct 2025 16:56:52 +0000</pubDate></item></channel></rss>