<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 06 Jan 2026 21:39:55 +0000</lastBuildDate><item><title>Why is the Gmail app 700 MB?</title><link>https://akr.am/blog/posts/why-is-the-gmail-app-700-mb</link><description>&lt;doc fingerprint="bda994732ecfabe0"&gt;
  &lt;main&gt;
    &lt;p&gt;The Gmail app, on the App Store, is currently 760.7 MB in size. It is in the top three most bloated apps out of the top 100 free apps. I don’t use it on my phone, but I was prompted to compare it with the seemingly hefty one I (have to) use, Outlook, while clearing up some storage space. Its measly 428 MB size pales in comparison.&lt;/p&gt;
    &lt;p&gt;This isn’t new. In 2017, Axios reported that the top iPhone apps had been taking up an increasing amount of space over the period from 2013 to 2017. For most of that period, the size of the Gmail app hovered around 12 MB, with a sudden jump to more than 200 MB near the start of 2017. Other popular apps also saw a 10x or more increase in size over the same period.&lt;/p&gt;
    &lt;p&gt;Gmail isn’t even the worst offender, it’s just a more popular one. The Tesla and Crypto.com apps are around 1 GB each. So is Samsung’s SmartThings app. What about Google’s other popular apps? Google Home is another hefty one, at 630 MB, that I used for its remote feature, which I replaced with Google TV at almost a tenth the size. Their other popular apps average around 250 MB in size. This seems tame in comparison to Microsoft, with an average app size of around 330MB. For reference, the average size of an app in the top 100 free apps is 280 MB or, in a more expanded set (including games), 200MB.&lt;/p&gt;
    &lt;p&gt;Just to put this into perspective, on my device, apps (excluding their data) use up 35 GB, and the data is another 35 GB. iOS takes up another 25 GB. Let’s say, 100 GB for apps, data and the OS. That leaves me with 20 GB (leaving a margin of free space for updates) meant to be used for capturing 4K video and high-quality photos (why else get an iPhone), and storing music (don’t even think about lossless). The reality is that running out of space also slows things down, since most of my photos need to be fetched from the cloud before viewing them, and I need to re-download these hefty offloaded apps when I need them again. And good luck if you have a limited data bundle.&lt;/p&gt;
    &lt;p&gt;Maybe this doesn’t matter. The latest iPhones start at 256 GB, and surely I’ll have plenty of space when I get a new one (although I remember saying this when I upgraded to 64 GB from 32 GB). It’s not really about the space though. These apps don’t have 50x or even 10x the functionality. But now they’re 100x larger, and probably slower. Why?&lt;/p&gt;
    &lt;p&gt;Also, can someone explain why Microsoft Authenticator is 150 MB to show 6-digit codes?&lt;/p&gt;
    &lt;p&gt;It’s not clear if this is specifically an iOS problem. I don’t have an Android device and I could not find a way to get that information from the Play Store without a device. That said, I checked the size of Gmail on someone’s Android phone, and it’s around 185 MB, which certainly seems much better.&lt;/p&gt;
    &lt;p&gt;And if you’re considering switching from the default apps, this is what the installed size (which differs slightly from the App Store size) is of the alternatives on my iPhone running iOS 26.2:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;App&lt;/cell&gt;
        &lt;cell role="head"&gt;Apple&lt;/cell&gt;
        &lt;cell role="head"&gt;Microsoft&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Files - Drive - OneDrive&lt;/cell&gt;
        &lt;cell&gt;2.6 MB&lt;/cell&gt;
        &lt;cell&gt;370 MB&lt;/cell&gt;
        &lt;cell&gt;283 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Passwords - Authenticator&lt;/cell&gt;
        &lt;cell&gt;3.2 MB&lt;/cell&gt;
        &lt;cell&gt;35 MB&lt;/cell&gt;
        &lt;cell&gt;138 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;FaceTime - Meet - Teams&lt;/cell&gt;
        &lt;cell&gt;3.4 MB&lt;/cell&gt;
        &lt;cell&gt;263 MB&lt;/cell&gt;
        &lt;cell&gt;423 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Photos&lt;/cell&gt;
        &lt;cell&gt;4.2 MB&lt;/cell&gt;
        &lt;cell&gt;372 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Safari - Chrome - Edge&lt;/cell&gt;
        &lt;cell&gt;5.1 MB&lt;/cell&gt;
        &lt;cell&gt;313 MB&lt;/cell&gt;
        &lt;cell&gt;397 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Reminders - Tasks - To Do&lt;/cell&gt;
        &lt;cell&gt;7.7 MB&lt;/cell&gt;
        &lt;cell&gt;89 MB&lt;/cell&gt;
        &lt;cell&gt;132 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mail - Gmail - Outlook&lt;/cell&gt;
        &lt;cell&gt;8.7 MB&lt;/cell&gt;
        &lt;cell&gt;673 MB&lt;/cell&gt;
        &lt;cell&gt;376 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Home&lt;/cell&gt;
        &lt;cell&gt;14.1 MB&lt;/cell&gt;
        &lt;cell&gt;584 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Notes - Keep - OneNote&lt;/cell&gt;
        &lt;cell&gt;17.3 MB&lt;/cell&gt;
        &lt;cell&gt;171 MB&lt;/cell&gt;
        &lt;cell&gt;315 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Maps&lt;/cell&gt;
        &lt;cell&gt;68 MB&lt;/cell&gt;
        &lt;cell&gt;385 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Pages - Docs - Word&lt;/cell&gt;
        &lt;cell&gt;456 MB&lt;/cell&gt;
        &lt;cell&gt;311 MB&lt;/cell&gt;
        &lt;cell&gt;434 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Numbers - Sheets - Excel&lt;/cell&gt;
        &lt;cell&gt;500 MB&lt;/cell&gt;
        &lt;cell&gt;337 MB&lt;/cell&gt;
        &lt;cell&gt;370 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Keynote - Slides - PowerPoint&lt;/cell&gt;
        &lt;cell&gt;516 MB&lt;/cell&gt;
        &lt;cell&gt;270 MB&lt;/cell&gt;
        &lt;cell&gt;376 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So, why is the Gmail app almost 80x the size of the native Mail app? My guess is as good as yours.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514692</guid><pubDate>Tue, 06 Jan 2026 16:46:13 +0000</pubDate></item><item><title>Loongarch Improvements with Box64</title><link>https://box86.org/2026/01/new-box64-v0-4-0-released/</link><description>&lt;doc fingerprint="b7c6381d6a23a46b"&gt;
  &lt;main&gt;
    &lt;p&gt;Happy new year, and happy new release of Box64!&lt;/p&gt;
    &lt;p&gt;The new version brings a ton of new enhancements and fixes to all 3 supported platforms, with Steam running not only on Arm64, but also on RiSC-V and on Loongarch! And this is the Linux version of Steam, not the Windows one (but the Windows one works too if you really prefer that one). While Box32 (used to run Steam) is still experimental and unstable, stability did improve. Still, expect some crashes when downloading things with steam. And it’s not all, Battle.net is also getting stable, and some games are working too. Not all unfortunately, and your success might depend on your geographical region, as program versions might differ. At least, you can try it on ARM64 &amp;amp; Loongarch. It’s still to be tested on RiSC-V.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights&lt;/head&gt;
    &lt;p&gt;So, what’s new in this release? Apart from the traditionals fixes, speedups, opcodes implementation and new wrapper functions, there has been a number of refactors. Some are more groundwork for later use, like the &lt;code&gt;libdl&lt;/code&gt; one. But some have immediate benefits. The prefix opcode decoder, now implemented on the interpreter and the 3 dynarec backend is one of those. This allows to more generically handle exotic opcode prefixes without doing hacks or adding duplicated code. This one lead to the removal of many source files, now useless, making the maintenance of box64 a bit easier. Also, this automatically added support for many rare (or less rare) occurrences of many opcodes in the Dynarec, with 0 extra coding.&lt;/p&gt;
    &lt;p&gt;There has been some work on the memory footprint of box64 too. Some applications use a lot of memory once launched with box64 (Steam for example, or other things that use &lt;code&gt;libcef&lt;/code&gt; or a variant of it). So some work was started to develop mechanisms to try to identify blocks of code that have been converted to native, but that seem to not be used anymore, so they can be deleted and the memory recycled for some fresh code. The work is still in progress on this subject, and more work will come in next release.&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture card&lt;/head&gt;
    &lt;p&gt;I have (finally?) invested in a capture card (an Elgato HD60X) for all my video capture. I did all the Loongarch &amp;amp; RiSC-V game captures using OBS on my Ampere ARM64 machine (plug’n play), and I did the Ampere game footage captures using a Lenovo T14s (XElite/ARM64) running Ubuntu also with OBS. While the capture done on the Ampere (using the NVidia card and encoder) were fine, the ones done on the T14s (using software encoder) were a little too compressed for many captures. I have adjusted the settings, but not redone most of them, so you will see some compression artefacts in the ARM64 gameplay video. But at least the performances are not hurt by the capture anymore…&lt;/p&gt;
    &lt;p&gt;Side note: the editing was also done on the Ampere ARM64 machine (with OpenShot), so no x86 machine was involved in those videos at all!&lt;/p&gt;
    &lt;head rend="h2"&gt;Architectures&lt;/head&gt;
    &lt;p&gt;While there is not much news on the ARM64 side (there is added support for the GB10 cpu as a build profile for Box64), there was still some refactoring to improve performances of the Dynarec there. There is still ongoing work to detect and optimize more code loops; for instance, pre-loading used XMM/YMM register just before entering the loop, to avoid loading and saving these registers when it’s not needed. That can give some big speedup in some case. More speedup will be expected when more loop cases are getting detected and handled.&lt;/p&gt;
    &lt;p&gt;On the RiSC-V, the last months have brought the Dynarec to a very decent level of completion and performances, thanks to contribution of PLCT Labs and many things are working now. Steam, Proton and Wine are all running (even with the 39bits address space limitation of many hardware). But DRM protected stuff that need Windows Syscall emulation will not work for now unless the hardware support SV48 (48bits address space) or using a hacked Wine/Proton. The current hardware used for the video is a Pioneer Milk-V mini-server and its 64 cores CPU. But each core is still quite slow, at 1.5GHz, and the equipped graphic card, an old AMD RX550, is also showing it’s limitation in some of those videos…&lt;/p&gt;
    &lt;p&gt;The Loongarch backend is the one that saw the most progress in this cycle, and this CPU is starting to shine already, even if the Dynarec doesn’t yet have all the bells and whistles from the ARM64 version. Steam works now, but also Wine and Proton. But you need to use the 4K page size kernel. The default for this system is usually 16K, but most OS have a 4K option. I use AOSC on my side, but there is now a Debian option too. The modest 3A6000 is a 4 physical cores (8 logicals cores) CPU at 2.5 GHz. Sounds modest on paper, but equipped with a good AMD RX7600, the results are already quite surprising. And it seems to be even better on more powerful variants of the CPU, like the 3B6000 (12 cores) or 3C6000 (16 cores).&lt;/p&gt;
    &lt;head rend="h2"&gt;ESync / FSync / NTSync&lt;/head&gt;
    &lt;p&gt;Wine and Proton need some complex synchronisation mechanisms between processes. By default, Wine uses a basic system on the wineserver side. It works but can be quite slow depending on the number of processes / threads / CPU cores… So various mechanisms have been developed in the last few years. The first two are ESync and FSync. While they can be faster, they can also be not 100% accurate. Box64 supports both of them (and they get used automatically by Proton in Steam), but some games are not synchronising correctly when using them. Games that use the Rockstar launcher or Microsoft XBox services might not start correctly when using ESync and FSync on ARM64. So on steam, you might need to use&lt;/p&gt;
    &lt;code&gt;PROTON_NO_ESYNC=1 PROTON_NO_FSYNC=1 %command%&lt;/code&gt;
    &lt;p&gt;on the program launch option in steam. Or disable them using the UI if you are using Heroic.&lt;/p&gt;
    &lt;p&gt;NTSync on the other hand seems to work fine, but is very new. You need to have a kernel where NTSync is enabled to use it. Debian on ARM64 still hasn’t that, even on the Forky branch. Ubuntu on ARM64 seems the same. Both OS on X64 ship kernels with NTSync enabled it seems. Armbian, on the other hand, have kernel with NTSync enabled. On Loongarch, AOSC also has NTSync enabled. Note that you need a bleeding edge Wine or Proton-GE to actually use NTSync. The default Proton from Steam will not use it for now, so it’s very early, but some result on 3C6000 processor shows some impressive result with about 80% more FPS in heavy games.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Box64 is ready to be used, so go grab the source, build your own version and enjoy!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514807</guid><pubDate>Tue, 06 Jan 2026 16:52:56 +0000</pubDate></item><item><title>Why Big Companies Keep Failing: The Stack Fallacy (2016)</title><link>https://techcrunch.com/2016/01/18/why-big-companies-keep-failing-the-stack-fallacy/</link><description>&lt;doc fingerprint="7d0c11194f46e5ed"&gt;
  &lt;main&gt;
    &lt;p&gt;Stack fallacy has caused many companies to attempt to capture new markets and fail spectacularly. When you see a database company thinking apps are easy, or a VM company thinking big data is easy — they are suffering from stack fallacy.&lt;/p&gt;
    &lt;p&gt;Stack fallacy is the mistaken belief that it is trivial to build the layer above yours.&lt;/p&gt;
    &lt;p&gt;Comic credit: XKCD&lt;/p&gt;
    &lt;p&gt;Mathematicians often believe we can describe the entire natural world in mathematical terms. Hence, all of physics is just applied math. And so on and so forth.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stack fallacy — “just an app”&lt;/head&gt;
    &lt;p&gt;In the business world, we have a similar illusion. Database companies believe that SaaS apps are “just a database app” — this gives them false confidence that they can easily build, compete and win in this new market.&lt;/p&gt;
    &lt;p&gt;As history has shown, Amazon is dominating the cloud IaaS market, even as the technology vendors that build ingredient, lower-layer technologies struggle to compete — VMware is nowhere close to winning against AWS, even though all of AWS runs on virtual machine technology, a core competency of VMware; Oracle has been unable to beat Salesforce in CRM SaaS, despite the fact that Oracle perceives Salesforce to be just a hosted database app. It even runs on their database!&lt;/p&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages — part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages — part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;p&gt;Apple continues to successfully integrate vertically down — building chips, programming languages, etc., but again has found it very hard to go up the stack and build those simple apps — things like photo sharing apps and maps.&lt;/p&gt;
    &lt;p&gt;History is full of such examples. IBM thought nothing much of the software layer that ran their PC hardware layer and happily allowed Microsoft to own the OS market.&lt;/p&gt;
    &lt;p&gt;In the 1990s, Larry Ellison saw SAP make gargantuan sums of money selling process automation software (ERP) — to him, ERP was nothing more than a bunch of tables and workflows — so he spent hundreds of millions of dollars trying to own that market, with mixed results. Eventually, Oracle bought its way into the apps market by acquiring PeopleSoft and Siebel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why do we keep falling for the stack fallacy?&lt;/head&gt;
    &lt;p&gt;The stack fallacy is a result of human nature — we (over) value what we know. In real terms, imagine you work for a large database company and the CEO asks , “Can we compete with Intel or SAP?” Very few people will imagine they can build a computer chip just because they can build relational database software, but because of our familiarity with building blocks of the layer up, it is easy to believe you can build the ERP app. After all, we know tables and workflows.&lt;/p&gt;
    &lt;p&gt;The bottleneck for success often is not knowledge of the tools, but lack of understanding of the customer needs. Database engineers know almost nothing about what supply chain software customers want or need. They can hire for that, but it is not a core competency.&lt;/p&gt;
    &lt;p&gt;In a surprising way, it is far easier to innovate down the stack than up the stack.&lt;/p&gt;
    &lt;p&gt;The reason for this is that you are yourself a natural customer of the lower layers. Apple knew what it wanted from an ideal future microprocessor. It did not have the skills necessary to build it, but the customer needs were well understood. Technical skills can be bought/acquired, whereas it is very hard to buy a deep understanding of market needs.&lt;/p&gt;
    &lt;p&gt;It is therefore no surprise that Apple had an easier time building semiconductor chips than building Apple Maps.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google, Facebook, WhatsApp&lt;/head&gt;
    &lt;p&gt;Google is a great example. It owned our email graph and our interest data (search), yet found it very difficult to succeed in what looks like a “trivial to build” app — social networks.&lt;/p&gt;
    &lt;p&gt;In fact, this is the perfect irony of stack fallacy. You can build things higher up the stack. It is just that often it is not clear what to build.&lt;/p&gt;
    &lt;p&gt;Product management is the art of knowing what to build.&lt;/p&gt;
    &lt;p&gt;The stack fallacy provides insights into why companies keep failing at the obvious things — things so close to their reach that they can surely build. The answer may be that the what is 100 times more important than the how.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514816</guid><pubDate>Tue, 06 Jan 2026 16:53:27 +0000</pubDate></item><item><title>Show HN: Stash – Sync Markdown Files with Apple Notes via CLI</title><link>https://github.com/shakedlokits/stash</link><description>&lt;doc fingerprint="20c6dcb573341fc0"&gt;
  &lt;main&gt;
    &lt;code&gt;                                     
                                     
  ▄█████ ██████ ▄████▄ ▄█████ ██  ██ 
  ▀▀▀▄▄▄   ██   ██▄▄██ ▀▀▀▄▄▄ ██████ 
  █████▀   ██   ██  ██ █████▀ ██  ██ 
                                     
                                     
&lt;/code&gt;
    &lt;p&gt;Bidirectionally sync Markdown files with Apple Notes!&lt;/p&gt;
    &lt;code&gt;brew tap shakedlokits/stash https://github.com/shakedlokits/stash
brew install shakedlokits/stash/stash&lt;/code&gt;
    &lt;p&gt;Push a markdown file to Apple Notes:&lt;/p&gt;
    &lt;code&gt;stash push my-note.md&lt;/code&gt;
    &lt;p&gt;Pull changes back from Apple Notes:&lt;/p&gt;
    &lt;code&gt;stash pull my-note.md&lt;/code&gt;
    &lt;p&gt;That's it! The tool uses front-matter to track which Apple Note corresponds to your file.&lt;/p&gt;
    &lt;p&gt;Apple Notes has been my daily driver for years. I love its simplicity—it syncs fast, stays out of the way, and just lets me write.&lt;/p&gt;
    &lt;p&gt;I've explored the full spectrum of note-taking apps: &lt;code&gt;Workflowy&lt;/code&gt;, &lt;code&gt;Obsidian&lt;/code&gt;, &lt;code&gt;Bear&lt;/code&gt;, &lt;code&gt;Evernote&lt;/code&gt;, &lt;code&gt;Notion&lt;/code&gt;, &lt;code&gt;Google Keep&lt;/code&gt;, &lt;code&gt;GoodNotes&lt;/code&gt;, and others I've since forgotten. Each promised to revolutionize how I capture thoughts. But eventually, I realized something simple: note-taking is about writing things down, not managing a complex system. I came back to Apple Notes and haven't looked back.&lt;/p&gt;
    &lt;p&gt;There's just one friction point. When I'm building things—which is most days—I live in Markdown. At work, I sync those files to Notion or Confluence with CLI tools. For personal projects, everything goes into Git. But increasingly, I find myself writing quick notes that don't belong to any project—just ideas, experiments, small discoveries—and I want them on Apple Notes where I can read them anywhere. Right now, there's no clean path from my Markdown workflow to my notes.&lt;/p&gt;
    &lt;p&gt;I went searching for CLI tools to bridge this gap. What I found was disappointing: tools either pack in too many features, making them brittle and hard to maintain, or they offer so little functionality (read-only sync) that they're effectively useless.&lt;/p&gt;
    &lt;p&gt;So I built my own.&lt;/p&gt;
    &lt;p&gt;The requirements are straightforward:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run from the shell without configuration files&lt;/item&gt;
      &lt;item&gt;Use AppleScript for maximum compatibility and stability&lt;/item&gt;
      &lt;item&gt;Bidirectionally sync Markdown and Apple Notes, using front-matter to track state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Congratulations! You've written a new Markdown note, it's nice and tidy, and you've even run &lt;code&gt;vale&lt;/code&gt; on it. Now all that remains is getting it into Apple Notes. Here's what you need to do:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run &lt;code&gt;push my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;A new note will be created: &lt;code&gt;My Cool Note ...&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Front-matter with a unique identifier will be added to your markdown file: &lt;quote&gt;--- apple_notes_id: my-new-cool-note-identifier --- # My Cool Note ...&lt;/quote&gt;&lt;p&gt;NOTE: If you already have front-matter, it will be added to the existing front-matter.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made changes to the Markdown file and now it's out of sync? Simply:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Rerun &lt;code&gt;push my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The tool searches for the note matching your identifier (&lt;code&gt;id_my-new-cool-note-identifier&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;It rewrites the note's content with your updated Markdown. &lt;p&gt;NOTE: If no note was found (due to unexpected ID changes) you will be asked if you'd like to create a new note, which will overwrite your previous ID.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You've gone off for your coffee/potty/meeting break, and while skimming through your note on your phone, you realized you made a terrible mistake—which inevitably led you to rewrite half of it.&lt;/p&gt;
    &lt;p&gt;Now the panic has settled, you're back at your computer, and you're wondering: "What the hell have I done, and how can I possibly get all those changes back into my Markdown?"&lt;/p&gt;
    &lt;p&gt;Don't fret. Simply:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run &lt;code&gt;pull my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The tool searches for the note matching your identifier (&lt;code&gt;id_my-new-cool-note-identifier&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;It rewrites your local Markdown file with the content from Apple Notes. &lt;p&gt;NOTE: The front-matter is unchanged during pull operations.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS with Apple Notes&lt;/item&gt;
      &lt;item&gt;Pandoc for Markdown ↔ HTML conversion&lt;/item&gt;
      &lt;item&gt;pcregrep for frontmatter parsing (usually pre-installed on macOS, or install via &lt;code&gt;brew install pcre&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tool is built in three layers:&lt;/p&gt;
    &lt;p&gt;AppleScript forms the core, handling all communication with Apple Notes—finding existing notes, updating content, and creating or deleting notes (the latter mostly for testing).&lt;/p&gt;
    &lt;p&gt;Shell scripts contain the business logic that orchestrates these AppleScript operations, managing the sync workflow and front-matter processing.&lt;/p&gt;
    &lt;p&gt;Pandoc handles the conversion between Markdown and HTML, ensuring content is properly formatted for Apple Notes.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Bashly&lt;/code&gt; ties it all together, providing a clean CLI interface, shell completions, and command scaffolding.&lt;/p&gt;
    &lt;p&gt;Clone the repository and build:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/shakedlokits/stash.git
cd stash
make build&lt;/code&gt;
    &lt;code&gt;# Run all tests (requires Apple Notes access)
make test

# Run unit tests only (no Apple Notes required)
make test-unit&lt;/code&gt;
    &lt;code&gt;src/
  lib/           # Utility functions (pure and integration)
  bashly.yml     # CLI configuration
  *_command.sh   # Command implementations
test/
  cases/         # Test specs (unit, integration, e2e)
  fixtures/      # Test fixture files
  approvals/     # Approval test snapshots
dist/
  stash          # Generated CLI (via bashly)
Formula/
  stash.rb       # Homebrew formula
&lt;/code&gt;
    &lt;code&gt;make release VERSION=x.y.z&lt;/code&gt;
    &lt;p&gt;This will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update the version in &lt;code&gt;src/bashly.yml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Commit the change&lt;/item&gt;
      &lt;item&gt;Create and push a git tag&lt;/item&gt;
      &lt;item&gt;Trigger the release workflow (build, publish, update Homebrew formula)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This backlog contains both current and future development items, feel free to take some or add to it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Basic Functionality &lt;list rend="ul"&gt;&lt;item&gt; AppleScript notes access functions &lt;list rend="ul"&gt;&lt;item&gt;Find note&lt;/item&gt;&lt;item&gt;Create note&lt;/item&gt;&lt;item&gt;Delete note&lt;/item&gt;&lt;item&gt;Update note&lt;/item&gt;&lt;item&gt;Read note&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Markdown front-matter parser (get-id, extract, strip, update)&lt;/item&gt;&lt;item&gt;Push command shell script&lt;/item&gt;&lt;item&gt;Push command tests&lt;/item&gt;&lt;item&gt;Pull command shell script&lt;/item&gt;&lt;item&gt;Pull command tests&lt;/item&gt;&lt;item&gt;&lt;code&gt;Pandoc&lt;/code&gt;integration&lt;/item&gt;&lt;item&gt;&lt;code&gt;Bashly&lt;/code&gt;setup&lt;list rend="ul"&gt;&lt;item&gt;CLI interface&lt;/item&gt;&lt;item&gt;Shell completion&lt;/item&gt;&lt;item&gt;Documentation&lt;/item&gt;&lt;item&gt;Approval testing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; AppleScript notes access functions &lt;/item&gt;
      &lt;item&gt; Nice to have &lt;list rend="ul"&gt;&lt;item&gt;Diff changes (requires design)&lt;/item&gt;&lt;item&gt;Attachments support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514874</guid><pubDate>Tue, 06 Jan 2026 16:57:15 +0000</pubDate></item><item><title>Volkswagen Brings Back Physical Buttons</title><link>https://www.caranddriver.com/news/a69916699/volkswagen-interior-physical-buttons-return/</link><description>&lt;doc fingerprint="bdad1cdd2a3489a9"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Volkswagen revealed a new generation of cockpit design with the refreshed ID. Polo.&lt;/item&gt;
      &lt;item&gt;The new design marks a big departure for VW and features a plethora of physical controls rather than the capacitive buttons on current models.&lt;/item&gt;
      &lt;item&gt;While the switchgear is currently only found on the new ID. Polo, which isn't sold in the United States, it could debut on the soon-to-be-refreshed ID.4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Volkswagen is making a drastic change to its interiors, or at least the interiors of its electric vehicles. The automaker recently unveiled a new cockpit generation with the refreshed ID. Polo—the diminutive electric hatchback that the brand sells in Europe—that now comes with physical buttons.&lt;/p&gt;
    &lt;p&gt;While VW certainly isn't the only automaker that pushed the envelope with haptic controls and digital buttons, it was a particularly egregious offender. Now, the company is doing a complete 180-degree shift, adding a full suite of physical buttons and switchgear to the Polo's interior.&lt;/p&gt;
    &lt;head rend="h2"&gt;For Sale Near You&lt;/head&gt;
    &lt;p&gt;See all results for Volkswagen for sale near 97206&lt;/p&gt;
    &lt;p&gt;The steering wheel gets new clusters of buttons for cruise control and interacting with music playback, while switches for the temperature and fan speed now live in a row along the dashboard. The move back to buttons doesn't come out of nowhere. Volkswagen already started the shift with the new versions of the Golf and Tiguan models in the United States. Unfortunately, some climate controls, such as those for the rear defrost and the heated seats, are still accessed through the touchscreen. Thankfully, they look to retain their dedicated spot at the bottom of the display.&lt;/p&gt;
    &lt;p&gt;Volkswagen hasn't announced which models will receive the new cockpit design. The redesigned interior also may be limited to the brand's electric vehicles, which would limit it to the upcoming refresh for the ID.4 SUV (and potentially the ID.Buzz), as the only VW EV models currently sold in America.&lt;/p&gt;
    &lt;p&gt;➡️ Skip the lot. Let Car and Driver help you find your next car.&lt;/p&gt;
    &lt;p&gt;Jack Fitzgerald’s love for cars stems from his as yet unshakable addiction to Formula 1. &lt;lb/&gt; After a brief stint as a detailer for a local dealership group in college, he knew he needed a more permanent way to drive all the new cars he couldn’t afford and decided to pursue a career in auto writing. By hounding his college professors at the University of Wisconsin-Milwaukee, he was able to travel Wisconsin seeking out stories in the auto world before landing his dream job at Car and Driver. His new goal is to delay the inevitable demise of his 2010 Volkswagen Golf.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514913</guid><pubDate>Tue, 06 Jan 2026 16:59:44 +0000</pubDate></item><item><title>Opus 4.5 is not the normal AI agent experience that I have had thus far</title><link>https://burkeholland.github.io/posts/opus-4-5-change-everything/</link><description>&lt;doc fingerprint="26499875abe73fe9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Opus 4.5 is going to change everything&lt;/head&gt;
    &lt;p&gt;If you had asked me three months ago about these statements, I would have said only someone who’s never built anything non-trivial would believe they’re true. Great for augmenting a developer’s existing workflow, and completions are powerful, but agents replacing developers entirely? No. Absolutely not.&lt;/p&gt;
    &lt;p&gt;Today, I think that AI coding agents can absolutely replace developers. And the reason that I believe this is Claude Opus 4.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opus 4.5 is not normal&lt;/head&gt;
    &lt;p&gt;And by “normal”, I mean that it is not the normal AI agent experience that I have had thus far. So far, AI Agents seem to be pretty good at writing spaghetti code and after 9 rounds of copy / paste errors into the terminal and “fix it” have probably destroyed my codebase to the extent that I’ll be throwing this whole chat session out and there goes 30 minutes I’m never getting back.&lt;/p&gt;
    &lt;p&gt;Opus 4.5 feels to me like the model that we were promised - or rather the promise of AI for coding actually delivered.&lt;/p&gt;
    &lt;p&gt;One of the toughest things about writing that last sentence is that the immediate response from you should be, “prove it”. So let me show you what I’ve been able to build.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 1 - Windows Image Conversion Utility&lt;/head&gt;
    &lt;p&gt;I first noticed that Opus 4.5 was drastically different when I used it to build a Windows utility to right-click an image and convert it to different file types. This was basically a one shot build after asking Opus the best way to add a right-click menu to the file explorer.&lt;/p&gt;
    &lt;p&gt;What amazed me through the process of building this was Opus 4.5 ability to get most things right on the first try. And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. The only issue I had was Opus inability to see XAML errors, which I used Visual Studio to see and copy / paste back into the agent.&lt;/p&gt;
    &lt;p&gt;Opus built a site for me to distribute it and handled the bundling of the executable so as to use a powershell script for the install, uninstall. It also built the GitHub Actions which do the release and update the landing page so that all I have to do is push source.&lt;/p&gt;
    &lt;p&gt;The only place I had to use other tools was for the logo - where I used Figma’s AI to generate a bunch of different variations - but then Opus wrote the scripts to convert that SVG to the right formats for icons, even store distribution if I chose to do so.&lt;/p&gt;
    &lt;p&gt;Now this is admittedly not a complex application. This is a small Windows utility that is doing basically one thing. It’s not like I asked Opus 4.5 to build Photoshop.&lt;/p&gt;
    &lt;p&gt;Except I kind of did.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 2 - Screen recording / editing&lt;/head&gt;
    &lt;p&gt;I was so impressed by Opus 4.5 work on this utility that I decided to make a simple GIF recording utility similar to LICEcap for Mac. Great app, questionable name.&lt;/p&gt;
    &lt;p&gt;But that proved to be so easy, that I went ahead and continued adding features, including capturing and editing video, static images, adding shapes, cropping, blurs and more. I’m still working on this application as it turns out building a full on image/video editor is kind of a big undertaking. But I got REALLY far in a matter of hours. HOURS, PEOPLE.&lt;/p&gt;
    &lt;p&gt;I don’t have a fancy landing page for this one yet, but you can view all of the source code here.&lt;/p&gt;
    &lt;p&gt;I realized that if I could build a video recording app, I could probably build anything at all - at least UI-wise. But the achilles heel of all AI agents is when they have to glue together backend systems - which any real world application is going to have - auth, database, API, storage.&lt;/p&gt;
    &lt;p&gt;Except Opus 4.5 can do that too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 3 - AI Posting Utility&lt;/head&gt;
    &lt;p&gt;Armed with my confidence in Opus 4.5, I took on a project that I had built in React Native last year and finished for Android, but gave up in the final stretches (as one does).&lt;/p&gt;
    &lt;p&gt;The application is for my wife who owns a small yard sign franchise. The problem is that she has a Facebook page for the business, but never posts there because it’s time consuming. But any good small business has a vibrant page where people can see photos of your business doing…whatever the heck it does. So people know that it exsits and is alive and well.&lt;/p&gt;
    &lt;p&gt;The idea is simple - each time she sets up a yard sign, she takes a picture to send to the person who ordered it so they can see it was setup. So why not have a mobile app where she can upload 10 images at a time, and the app will use AI to generate captions and then schedule them and post them over the coming week.&lt;/p&gt;
    &lt;p&gt;It’s a simple premise, but it has a lot of moving parts - there is the Facebook authentication which is a caper in and of itself - not for the faint of heart. There is authentication with a backend, there is file storage for photos that are scheduled to go out, there is the backend process which needs to post the photo. It’s a full on backend setup.&lt;/p&gt;
    &lt;p&gt;As it turns out, I needed to install some blinds in the house so I thought - why don’t I see if Opus 4.5 can build this while I install the blinds.&lt;/p&gt;
    &lt;p&gt;So I fired up a chat session and just started by telling Opus 4.5 what I wanted to build and how it would recommend handling the backend. It recommended several options but settled on Firebase. I’m not now nor have I ever been a Firebase user, but at this point I trust Opus 4.5 a lot. Probably too much.&lt;/p&gt;
    &lt;p&gt;So I created a Firebase account, upgraded to the Blaze plan with alerts for billing and Opus 4.5 got to work.&lt;/p&gt;
    &lt;p&gt;By the time I was done installing blinds, I had a functional iOS application for using AI to caption photos and posting them on a schedule to Facebook.&lt;/p&gt;
    &lt;p&gt;When I say that Opus 4.5 built this almost entirely, I mean it. It used the &lt;code&gt;firebase&lt;/code&gt; CLI to stand up any resources it needed and would tag me in for certain things like upgrading a project to the Blaze plan for features like storage, etc. The best part was that when the Firebase cloud functions would throw errors, it would automatically grep those logs, find the error and resolve it. And all it needed was a CLI. No MCP Server. No fancy prompt file telling it how to use Firebase.&lt;/p&gt;
    &lt;p&gt;And of course, since it’s solved, I had Opus 4.5 create a backend admin dashboard so I could see what she’s got pending and make any adjustments.&lt;/p&gt;
    &lt;p&gt;And since it did in a few hours what had taken me two months of work in the evenings instead of being a decent husband, I decided to make up for my dereliction of duties by building her another app for her sign business that would make her life just a bit more delightful - and eliminate two other apps she is currently paying for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 4 - Order tracking and routing&lt;/head&gt;
    &lt;p&gt;This app parses orders from her business Gmail account to show her what sign setups / pickups she has for the day, calculates how long its going to take to go to each stop, calculates the optimal route when there is more than one stop and tracks drive time for tax purposes. She was previously using two paid apps for the last two features there.&lt;/p&gt;
    &lt;p&gt;This app also uses Firebase. Again, Opus one-shotted the Google auth email integration. This is the kind of thing that is painstakingly miserable by hand. And again, Firebase is so well suited here because Opus knows how to use the Firebase CLI so well. It needs zero instruction.&lt;/p&gt;
    &lt;head rend="h3"&gt;BUT YOU DON’T KNOW HOW THE CODE WORKS&lt;/head&gt;
    &lt;p&gt;No I don’t. I have a vague idea, but you are right - I do not know how the applications are actually assembled. Especially since I don’t know Swift at all.&lt;/p&gt;
    &lt;p&gt;This used to be a major hangup for me. I couldn’t diagnose problems when things went sideways. With Opus 4.5, I haven’t hit that wall yet—Opus always figures out what the issue is and fixes its own bugs.&lt;/p&gt;
    &lt;p&gt;The real question is code quality. Without understanding how it’s built, how do I know if there’s duplication, dead code, or poor patterns? I used to obsess over this. Now I’m less worried that a human needs to read the code, because I’m genuinely not sure that they do.&lt;/p&gt;
    &lt;p&gt;Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it—why optimize for human readability when the AI is doing all the work and will explain things to you when you ask?&lt;/p&gt;
    &lt;p&gt;What you don’t need: variable names, formatting, comments meant for humans, or patterns designed to spare your brain.&lt;/p&gt;
    &lt;p&gt;What you do need: simple entry points, explicit code with fewer abstractions, minimal coupling, and linear control flow.&lt;/p&gt;
    &lt;p&gt;Here’s my custom agent prompt:&lt;/p&gt;
    &lt;code&gt;You are an AI-first software engineer. Assume all code will be written and maintained by LLMs, not humans. Optimize for model reasoning, regeneration, and debugging — not human aesthetics.

These coding principles are mandatory:

1. Structure
- Use a consistent, predictable project layout.
- Group code by feature/screen; keep shared utilities minimal.
- Create simple, obvious entry points.
- Before scaffolding multiple files, identify shared structure first. Use framework-native composition patterns (layouts, base templates, providers, shared components) for elements that appear across pages. Duplication that requires the same fix in multiple places is a code smell, not a pattern to preserve.

2. Architecture
- Prefer flat, explicit code over abstractions or deep hierarchies.
- Avoid clever patterns, metaprogramming, and unnecessary indirection.
- Minimize coupling so files can be safely regenerated.

3. Functions and Modules
- Keep control flow linear and simple.
- Use small-to-medium functions; avoid deeply nested logic.
- Pass state explicitly; avoid globals.

4. Naming and Comments
- Use descriptive-but-simple names.
- Comment only to note invariants, assumptions, or external requirements.

5. Logging and Errors
- Emit detailed, structured logs at key boundaries.
- Make errors explicit and informative.

6. Regenerability
- Write code so any file/module can be rewritten from scratch without breaking the system.
- Prefer clear, declarative configuration (JSON/YAML/etc.).

7. Platform Use
- Use platform conventions directly and simply (e.g., WinUI/WPF) without over-abstracting.

8. Modifications
- When extending/refactoring, follow existing patterns.
- Prefer full-file rewrites over micro-edits unless told otherwise.

9. Quality
- Favor deterministic, testable behavior.
- Keep tests simple and focused on verifying observable behavior.

Your goal: produce code that is predictable, debuggable, and easy for future LLMs to rewrite or extend.
&lt;/code&gt;
    &lt;p&gt;All of that said, I don’t have any proof that this prompt makes a difference. I find that Opus 4.5 writes pretty solid code no matter what you prompt it with. However, because models like to write code WAY more than they like to delete it, I will at points run a prompt that looks something like this…&lt;/p&gt;
    &lt;code&gt;Check your LLM, AI coding principles and then do a comprehensive search of this application and suggest what we can do to refactor this to better align to those principles. Also point out any code that can be deleted, any files that can be deleted, things that should read should be renamed, things that should be restructured. Then do a write up of what that looks like. Kind of keep it high level so that it's easy for me to read and not too complex. Add sections for high, medium and lower priority And if something doesn't need to be changed, then don't change it. You don't need to change things just for the sake of changing them. You only need to change them if it helps better align to your LLM AI coding principles. Save to a markdown file.
&lt;/code&gt;
    &lt;p&gt;And you get a document that has high, medium and low priority items. The high ones you can deal with and the AI will stop finding them. You can refactor your project a million times and it will keep finding medium/low priority refactors that you can do. An AI is never ever going to pass on the opportunity to generate some text.&lt;/p&gt;
    &lt;p&gt;I use a similar prompt to find security issues. These you have to be very careful about. Where are the API keys? Is login handled correctly? Are you storing sensitive values in the database? This is probably the most manual part of the project and frankly, something that makes me the most nervous about all of these apps at the moment. I’m not 100% confident that they are bullet proof. Maybe like 80%. And that, as they say, is too damn low.&lt;/p&gt;
    &lt;head rend="h3"&gt;Times they are A-changin&lt;/head&gt;
    &lt;p&gt;I don’t know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I’ve spent my life learning to do is now trivial for a computer. Both are true.&lt;/p&gt;
    &lt;p&gt;I understand if this post made you angry. I get it - I didn’t like it either when people said “AI is going to replace developers.” But I can’t dismiss it anymore. I can wish it weren’t true, but wishing doesn’t change reality.&lt;/p&gt;
    &lt;p&gt;But for everything else? Build. Stop waiting to have all the answers. Stop trying to figure out your place in an AI-first world. The answer is the same as it always was: make things. And now you can make them faster than you ever thought possible.&lt;/p&gt;
    &lt;p&gt;Just make sure you know where your API keys are.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515696</guid><pubDate>Tue, 06 Jan 2026 17:45:37 +0000</pubDate></item><item><title>Launch HN: Tamarind Bio (YC W24) – AI Inference Provider for Drug Discovery</title><link>https://news.ycombinator.com/item?id=46515777</link><description>&lt;doc fingerprint="6f51ad5b7d3645cb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Deniz and Sherry from Tamarind Bio (&lt;/p&gt;https://www.tamarind.bio&lt;p&gt;). Tamarind is an inference provider for AI drug discovery, serving models like AlphaFold. Biopharma companies use our library of leading open-source models to design new medicines computationally.&lt;/p&gt;&lt;p&gt;Here’s a demo: https://youtu.be/luoMApPeglo&lt;/p&gt;&lt;p&gt;Two years ago, I was hired at a Stanford lab to run models for my labmates. Some post-doc would ask me to run a set of 1-5 models in sequence with tens of thousands inputs and I would email them back the result after setting up the workflow in the university cluster.&lt;/p&gt;&lt;p&gt;At some point, it became unreasonable that all of an organization's computational biology work would go through an undergrad, so we built Tamarind as a single place for all molecular AI tools, usable at massive scale with no technical background needed. Today, we are used by much of the top 20 pharma, dozens of biotechs and tens of thousands of scientists.&lt;/p&gt;&lt;p&gt;When we started getting adoption in the big pharma companies, we found that this problem also persisted. I know directors of data science, where half their job could be described as running scripts for other people.&lt;/p&gt;&lt;p&gt;Lots of companies have also deprecated their internally built solution to switch over, dealing with GPU infra and onboarding docker containers not being a very exciting problem when the company you work for is trying to cure cancer.&lt;/p&gt;&lt;p&gt;Unlike non-specialized inference providers, we build both a programmatic interface for developers along with a scientist-friendly web app, since most of our users are non-technical. Some of them used to extract proteins from animal blood before replacing that process with using AI to generate proteins on Tamarind.&lt;/p&gt;&lt;p&gt;Besides grinding out images for each of the models we serve, we’ve designed a standardized schema to be able to share each model’s data format. We’ve built a custom scheduler and queue optimized for horizontal scaling (each inference call takes minutes to hours, and runs on one GPU at a time), while splitting jobs across CPUs and GPUs for optimal timing.&lt;/p&gt;&lt;p&gt;As we've grown to handle a substantial portion of the biopharma R&amp;amp;D AI demand on behalf of our customers, we've expanded beyond just offering a library of open source protocols.&lt;/p&gt;&lt;p&gt;A common use case we saw from early on was the need to connect multiple models together into pipelines, and having reproducible, consistent protocols to replace physical experiments. Once we became the place to build internal tools for computational science, our users started asking if they could onboard their own models to the platform.&lt;/p&gt;&lt;p&gt;From there, we now support fine-tuning, building UIs for arbitrary docker containers, connecting to wet lab data sources and more!&lt;/p&gt;&lt;p&gt;Reach out to me at deniz[at]tamarind.bio if you’re interested in our work, we are hiring! Check out our product at https://app.tamarind.bio and let us know if you have any feedback to support how the biotech industry uses AI today.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515777</guid><pubDate>Tue, 06 Jan 2026 17:49:56 +0000</pubDate></item><item><title>Dude, where's my supersonic jet?</title><link>https://rationaloptimistsociety.substack.com/p/dude-wheres-my-supersonic-jet</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515936</guid><pubDate>Tue, 06 Jan 2026 17:59:41 +0000</pubDate></item><item><title>Locating a Photo of a Vehicle in 30 Seconds with GeoSpy</title><link>https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515948</guid><pubDate>Tue, 06 Jan 2026 18:00:27 +0000</pubDate></item><item><title>Hierarchical Autoregressive Modeling for Memory-Efficient Language Generation</title><link>https://arxiv.org/abs/2512.20687</link><description>&lt;doc fingerprint="889c3c0ad4d2528e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 22 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Transformers operate as horizontal token-by-token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decoding increasingly memory-bound, as KV-cache reads and writes dominate inference throughput rather than arithmetic computation. We propose Parallel Hierarchical Operation for Top-down Networks (PHOTON), a hierarchical autoregressive model that replaces flat scanning with vertical, multi-resolution context access. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based language models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This reduces decode-time KV-cache traffic, yielding up to $10^{3}\times$ higher throughput per unit memory.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515987</guid><pubDate>Tue, 06 Jan 2026 18:02:01 +0000</pubDate></item><item><title>Creating a bespoke data diode for air‑gapped networks</title><link>https://nelop.com/bespoke-data-diode-airgap/</link><description>&lt;doc fingerprint="753841970511f2af"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Creating a Bespoke Data Diode for Air Gapped Networks&lt;/head&gt;
    &lt;p&gt;Published by Neil on&lt;/p&gt;
    &lt;p&gt;Air-gapped networks are physically isolated computer networks that do not connect to the internet or other external networks. They are widely used in industries where security is critical, such as finance, healthcare, and critical infrastructure. By design, these networks prevent remote access and reduce the risk of cyber attacks. However, while air gaps protect sensitive systems, they also create a challenge: how do you safely extract operational data for monitoring or analysis without compromising security?&lt;/p&gt;
    &lt;p&gt;We were approached by a client with precisely this challenge. Their crucial infrastructure was protected by an air gap, but they needed to extract syslog information and performance data to allow internal monitoring teams to track the system’s health and security posture.&lt;/p&gt;
    &lt;p&gt;After evaluating options, we chose to implement a bespoke data diode solution using two Raspberry Pi devices connected via an opto coupler. An opto coupler, also known as an opto isolator, allows an electrical signal to pass from one device to another using light, preventing direct electrical connection. This ensures data flows in a single direction, maintaining the integrity of the air gap.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Setup&lt;/head&gt;
    &lt;p&gt;The system consists of a “send” Pi on the air-gapped network and a “receive” Pi on the external monitoring network. Both devices run custom scripts designed to handle data transmission reliably rather than quickly. This approach limits throughput, but reliability is paramount for critical monitoring, where losing data is unacceptable. The scripts are finely tuned to ensure that every log entry is transmitted securely without risk of cross-contamination between networks.&lt;/p&gt;
    &lt;p&gt;This method is particularly effective for syslog data. Our client can now extract performance and security information from their air-gapped network, providing their internal teams with actionable insights. The air gap remains intact, but vital operational intelligence passes safely to the outside world.&lt;/p&gt;
    &lt;head rend="h3"&gt;UART over Serial Ports&lt;/head&gt;
    &lt;p&gt;Initially, we explored using a standard serial port for data transmission. While functional, it introduced limitations in reliability and required additional hardware considerations. After testing, we switched to a UART interface on the Raspberry Pi, which provided a simpler, more reliable solution for one-way communication. This approach allowed the data diode to maintain a clean, stable signal with minimal risk of interference, further enhancing the integrity of the air-gapped network while keeping the setup streamlined and efficient.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bespoke Solutions for Critical Challenges&lt;/head&gt;
    &lt;p&gt;Every implementation we deliver is tailored to the specific requirements of the client’s environment. The Raspberry Pi data diode demonstrates our ability to provide bespoke solutions that meet strict security and operational needs. Whether your challenge involves syslogs, process data, or other critical information, we design systems that are reliable, secure, and efficient. This is precisely the type of project we enjoy: solving unique, complex problems with practical, secure technology solutions.&lt;/p&gt;
    &lt;p&gt;In summary, our Raspberry Pi-based data diode offers a secure and dependable method to extract critical information from air-gapped networks. It balances reliability and security, ensuring the client’s infrastructure remains protected while providing essential visibility for operational monitoring.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Choose Nelop Systems?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Proven experience Over 25 years in IT and systems integration, specialising in environments where uptime is essential.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;UK-based &amp;amp; on-site service For many legacy systems there is no substitute for someone who can bring the hardware, tools, and know-how to your premises.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Operational continuity We plan every intervention so that systems keep running, avoiding downtime where possible, and maintaining business critical performance.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Email contact@nelop.com for assistance or information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46516117</guid><pubDate>Tue, 06 Jan 2026 18:10:31 +0000</pubDate></item><item><title>Passing of Joe Mancuso author of Masonite (Python web framework)</title><link>https://github.com/MasoniteFramework/masonite/discussions/853</link><description>&lt;doc fingerprint="2c52725b5bc5a72e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Passing of Joe Mancuso #853&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Good morning Masonite community,&lt;/p&gt;
          &lt;p&gt;I regret to inform you all that @josephmancuso has passed away due to health complications. Please keep his family in your thoughts during this time.&lt;/p&gt;
          &lt;p&gt;I had the privilege of working alongside Joe for many years, and it was clear as day how much Masonite meant to him. Even when fighting for his life, he continued doing everything he could to maintain and support this project.&lt;/p&gt;
          &lt;p&gt;One of the beautiful things about open source is that we build together. While Joe is no longer with us, Masonite can continue to grow and evolve through the contributions of this community. I hope we all continue working toward the vision he poured so much of himself into.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 2 comments&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;So sad, my condolences.😞&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;This is heartbreaking. I also had the privilege of working with Joe a couple of months ago, and he was always bringing new ideas to improve and share within the open-source community.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46516137</guid><pubDate>Tue, 06 Jan 2026 18:11:51 +0000</pubDate></item><item><title>Show HN: Jax-JS, array library in JavaScript targeting WebGPU</title><link>https://ss.ekzhang.com/p/jax-js-an-ml-library-for-the-web</link><description>&lt;doc fingerprint="3637085cea8c3ad8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;jax-js: an ML library for the web&lt;/head&gt;
    &lt;head rend="h3"&gt;JAX in pure JavaScript, as a flexible machine learning library and compiler.&lt;/head&gt;
    &lt;p&gt;I’m excited to release jax-js, a machine learning library for the web.&lt;/p&gt;
    &lt;p&gt;You can think of it as a reimplementation of Google DeepMind’s JAX framework (similar to PyTorch) in pure JavaScript.&lt;/p&gt;
    &lt;p&gt;jax-js runs completely in the browser by generating fast WebGPU and Wasm kernels.&lt;/p&gt;
    &lt;head rend="h2"&gt;Numerical computing on the web&lt;/head&gt;
    &lt;p&gt;Starting in February this year, I spent nights and weekends working on a new ML library for the browser. I wanted a cross-platform way to run numerical programs on the frontend web, so you can do machine learning.&lt;/p&gt;
    &lt;p&gt;Python and JavaScript are the most popular languages in the world:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;JavaScript is the language of the web.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Python is simple, expressive and now ubiquitous in ML thanks to frameworks like PyTorch and JAX.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But most developers would balk at running any number crunching in JavaScript. While the JavaScript JIT is really good, it’s not optimized for tight numerical loops. JavaScript doesn’t even have a fast, native integer data type! So how can you run fast numerical code on the web?&lt;/p&gt;
    &lt;p&gt;The answer is to rely on new browser technologies — WebAssembly and WebGPU, which allow you to run programs at near-native speeds. WebAssembly is a low-level portable bytecode, and WebGPU is GPU shaders on the web.&lt;/p&gt;
    &lt;p&gt;If we can use these native runtimes, then this lends itself to a programming model similar to JAX, where you trace programs and JIT compile them to GPU kernels. Here, instead of Nvidia CUDA, we write pure JavaScript to generate WebAssembly and WebGPU kernels. Then we can run them and execute instructions at near-native speed, skipping the JavaScript interpreter bottleneck.&lt;/p&gt;
    &lt;p&gt;That is what I ended up doing in jax-js, and now it “just works”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;You can install jax-js as a library. It has 0 dependencies and is pure JS.&lt;/p&gt;
    &lt;code&gt;npm install @jax-js/jax&lt;/code&gt;
    &lt;p&gt;Then you can use it with an API almost identical to JAX.&lt;/p&gt;
    &lt;code&gt;import { numpy as np } from "@jax-js/jax";

const ar = np.array([1, 5, 6, 7]);
console.log(ar.mul(10).js());  // -&amp;gt; [10, 50, 60, 70]&lt;/code&gt;
    &lt;p&gt;Under the hood, this generates a WebAssembly kernel and dispatches it.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note: There are some surface-level syntax differences here, versus JAX:&lt;/p&gt;&lt;p&gt;JavaScript doesn’t have operator overloading like Python. Instead of&lt;/p&gt;&lt;code&gt;ar * 10&lt;/code&gt;in Python, you have to call&lt;code&gt;ar.mul(10)&lt;/code&gt;.&lt;p&gt;The&lt;/p&gt;&lt;code&gt;.js()&lt;/code&gt;method converts a jax.Array object back into a plain JS array.&lt;p&gt;JS has no reference-counted destructor method to free memory, so array values in jax-js have move semantics like Rust, with&lt;/p&gt;&lt;code&gt;.ref&lt;/code&gt;incrementing their reference counts.&lt;/quote&gt;
    &lt;p&gt;If you’d like to use WebGPU, just start your program with:&lt;/p&gt;
    &lt;code&gt;import { init, setDevice } from "@jax-js/jax";

await init("webgpu");
setDevice("webgpu");&lt;/code&gt;
    &lt;p&gt;You can leverage grad, vmap, and other features of JAX. Here’s automatic differentiation with &lt;code&gt;grad()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;import { grad, numpy as np } from “@jax-js/jax”;

const f = (x: np.Array) =&amp;gt; np.sqrt(x.ref.mul(x).sum());
const df = grad(f);

const x = np.array([1, 2, 3, 4]);
console.log(df(x).js());&lt;/code&gt;
    &lt;p&gt;And here’s an example the compiler fusing operations with &lt;code&gt;jit()&lt;/code&gt;. The following function gets translated into a compiled GPU compute kernel:&lt;/p&gt;
    &lt;code&gt;import { jit, numpy as np } from "@jax-js/jax";

const f = jit((x: np.Array) =&amp;gt; {
  return np.sqrt(x.add(2).mul(Math.PI)).sum();
});&lt;/code&gt;
    &lt;head rend="h2"&gt;Machine learning&lt;/head&gt;
    &lt;p&gt;With these simple building blocks, you can implement most machine learning algorithms and backpropagate through them.&lt;/p&gt;
    &lt;p&gt;Here is a runnable example of training a neural network from scratch on MNIST dataset in your browser. It learns to &amp;gt;99% accuracy in seconds, and everything from dataset loading to matmul kernels is pure frontend JavaScript code.&lt;/p&gt;
    &lt;p&gt;It’s remarkable to write ML programs with hot module reloading. You can edit code in real time while the model is training!&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;You can also build applications. Here’s a demo I built yesterday: download the whole text of Great Expectations (180,000 words), run it through a CLIP-based embedding model, and semantic search it in real time—all from your browser.&lt;/p&gt;
    &lt;p&gt;(The text embedding actually runs at a respectable ~500 GFLOP/s on my M1 Pro with just jax.jit(), despite me not having tried to optimize it at all yet. Not bad, crunching 500,000,000,000 calculations/second in browser on a 4-year-old laptop!)&lt;/p&gt;
    &lt;p&gt;For a lot of inference use cases, you might find a “model runtime” like ONNX to add prebuilt ML models to your browser, where the ML developers hand off pre-packaged weights to be used in product. With jax-js, it’s a bit different, and I’m imagining how a full ML framework, usually relegated to the backend, can run in a browser.&lt;/p&gt;
    &lt;p&gt;As for performance, it hasn’t been my primary focus so far, as just “getting the ML framework working” comes first. I have checked that jax-js’s generated kernels for matmuls are fast (&amp;gt;3 TFLOP on Macbook M4 Pro). But there’s a lot of room to improve (e.g., conv2d is slow), and I haven’t done much optimization work on transformer inference in particular yet. There’s plenty of low-hanging fruit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Project release&lt;/head&gt;
    &lt;p&gt;I am open-sourcing jax-js today at ekzhang/jax-js.&lt;/p&gt;
    &lt;p&gt;There are rough edges in this initial release, but it’s ready to try out now.&lt;/p&gt;
    &lt;p&gt;Links:&lt;/p&gt;
    &lt;p&gt;I look forward to seeing what you create. 🥰&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;p&gt;This is a personal project and not related to Thinking Machines Lab. I started working on jax-js before starting my current job, and in a way, it’s partly how I ended up working in ML. Turns out this stuff is kind of fun!&lt;/p&gt;
    &lt;p&gt;If you’re still reading, hello—I have a bunch more details to share.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Thanks to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The authors of JAX for making an important ML library that’s a joy to use.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Thanks to Matthew Johnson, Dougal Maclaurin, and others for Autodidax, an instructive implementation of the JAX core from scratch.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;And thanks for all of the JAX ecosystem libraries as well.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tinygrad for a very excellent autograd library — you showed that code-generating kernels from scratch can’t really be that intrinsically complex!&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Many parts of jax-js in the backend internals follow Tinygrad’s design closely. The biggest example of this is ShapeTracker, which was directly ported.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Chrome, Safari, and Firefox for WebGPU, now used in 2% of all websites.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The open-source community, for inspiration and for showing that ML on the web is actually possible!&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;How it works: An overview of internals&lt;/head&gt;
    &lt;p&gt;In general, I think there are roughly two parts to an ML library:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;“Frontend” (think JAX): The interface for creating and manipulating arrays, the autograd engine, JIT, typing and transformations. Also where you interact with a sync/async boundary and how you track memory allocations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Backend” (think XLA): Actual kernels for executing operations. The frontend has some kind of representation of a kernel, it dispatches it to the backend, which then optimizes it, compiles it down to native code (CPU or GPU) and runs it very efficiently.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This dichotomy obviously isn’t perfect (e.g., where do Triton/Pallas fit in? how about warp-specialized cuTile?), and there are certainly concerns that span both parts. But it’s how jax-js works.&lt;/p&gt;
    &lt;p&gt;Let’s start with the backend and build our way up. In jax-js, the backend code is actually quite self-contained; they implement the Backend interface (abridged):&lt;/p&gt;
    &lt;code&gt;/** A device backend. */
export interface Backend {
  /** Allocate a new slot with reference count 1. */
  malloc(size: number, initialData?: Uint8Array): Slot;

  /** Increment the reference count of the slot. */
  incRef(slot: Slot): void;

  /**
   * Decrement the reference count of the slot. If the reference count reaches
   * zero, it is freed. This should throw if the slot was already freed.
   */
  decRef(slot: Slot): void;

  /** Read a range of bytes from a buffer. */
  read(
    slot: Slot,
    start?: number,
    count?: number,
  ): Promise&amp;lt;Uint8Array&amp;lt;ArrayBuffer&amp;gt;&amp;gt;;

  /** Prepare an expression to be executed later. */
  prepare(kernel: Kernel): Promise&amp;lt;Executable&amp;gt;;

  /**
   * Run a backend operation that was previously prepared.
   *
   * The operation may not run immediately, but operations are guaranteed to run
   * in the dispatch order. Also, `read()` will wait for all pending operations
   * on that slot to finish.
   */
  dispatch(exe: Executable, inputs: Slot[], outputs: Slot[]): void;
}&lt;/code&gt;
    &lt;p&gt;In other words, backends need to be able to malloc/free chunks of memory for tensors, and to execute &lt;code&gt;Kernel&lt;/code&gt; objects. Inside a &lt;code&gt;Kernel&lt;/code&gt; there is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A pointwise operation on one or more tensors, with&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lazy shape-tracking information for how to index the tensors, and&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;A reduction to be performed (optional).&lt;/p&gt;&lt;lb/&gt;Reductions can be any associative operation (add/multiply/max/min), and they can optionally have a fused epilogue as well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The pointwise operation is constructed from a pure expression tree, an &lt;code&gt;AluExp&lt;/code&gt;, where each node is a symbolic &lt;code&gt;AluOp&lt;/code&gt;. There are 28 AluOps — you don’t need so many distinct operations when you can depend on kernel fusion!&lt;/p&gt;
    &lt;p&gt;Note that no automatic differentiation happens here; these are pure low-level operations, so we can introduce arbitrary building blocks this way.&lt;/p&gt;
    &lt;code&gt;/** Symbolic form for each mathematical operation. */
export enum AluOp {
  Add = “Add”,
  Sub = “Sub”,
  Mul = “Mul”,
  Idiv = “Idiv”,
  Mod = “Mod”,
  Min = “Min”,
  Max = “Max”,

  Sin = “Sin”,
  Cos = “Cos”,
  Asin = “Asin”,
  Atan = “Atan”,
  Exp = “Exp”,
  Log = “Log”,
  Erf = “Erf”,
  Erfc = “Erfc”,
  Sqrt = “Sqrt”,
  Reciprocal = “Reciprocal”,
  Cast = “Cast”,
  Bitcast = “Bitcast”,

  Cmplt = “Cmplt”,
  Cmpne = “Cmpne”,
  Where = “Where”, // Ternary operator: `cond ? a : b`

  Threefry2x32 = “Threefry2x32”, // PRNG operation, arg = ‘xor’ | 0 | 1

  // Const is a literal constant, while GlobalIndex takes data from an array
  // buffer. Special and Variable are distinguished since the former is for
  // indices like the global invocation, while the latter is a value.
  Const = “Const”, // arg = value
  Special = “Special”, // arg = [variable, n]
  Variable = “Variable”, // arg = variable
  GlobalIndex = “GlobalIndex”, // arg = [gid, len]; src = [bufidx]
  GlobalView = “GlobalView”, // arg = [gid, ShapeTracker], src = [indices...]
}&lt;/code&gt;
    &lt;p&gt;When auto-generating GPU kernels, they’re pretty simple for pointwise ops. The tricky part is if there’s a reduction (aka. tensor contraction), most commonly in matmuls and convolutions. These can be optimized pretty well on the web by unrolling judiciously and tiling the loads/stores.&lt;/p&gt;
    &lt;p&gt;An example WebGPU matmul kernel for &lt;code&gt;float32[4096,4096]&lt;/code&gt; matrices generated by jax-js is shown below.&lt;/p&gt;
    &lt;code&gt;@group(0) @binding(0) var&amp;lt;storage, read&amp;gt; in0 : array&amp;lt;f32&amp;gt;;
@group(0) @binding(1) var&amp;lt;storage, read&amp;gt; in1 : array&amp;lt;f32&amp;gt;;
@group(0) @binding(2) var&amp;lt;storage, read_write&amp;gt; result : array&amp;lt;f32&amp;gt;;

@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) id : vec3&amp;lt;u32&amp;gt;) {
  if (id.x &amp;gt;= 1048576) { return; }
  let gidx: i32 = i32(id.x);
  var acc0: f32 = f32(0);
  var acc1: f32 = f32(0);
  var acc2: f32 = f32(0);
  var acc3: f32 = f32(0);
  var acc4: f32 = f32(0);
  var acc5: f32 = f32(0);
  var acc6: f32 = f32(0);
  var acc7: f32 = f32(0);
  var acc8: f32 = f32(0);
  var acc9: f32 = f32(0);
  var acc10: f32 = f32(0);
  var acc11: f32 = f32(0);
  var acc12: f32 = f32(0);
  var acc13: f32 = f32(0);
  var acc14: f32 = f32(0);
  var acc15: f32 = f32(0);
  for (var ridx: i32 = 0; ridx &amp;lt; 1024; ridx++) {
    let x0: i32 = ((gidx / 8192) * 131072) + ((((gidx / 8) % 8) * 16384) + (ridx * 4));
    let x1: f32 = in0[x0];
    let x2: i32 = (((gidx / 64) % 128) * 32) + (((gidx % 8) * 4) + (ridx * 16384));
    let x3: f32 = in1[x2];
    let x4: f32 = in0[x0 + 1];
    let x6: f32 = in0[x0 + 2];
    let x8: f32 = in0[x0 + 3];
    let x10: f32 = in0[x0 + 4096];
    let x11: f32 = in0[x0 + 4097];
    let x12: f32 = in0[x0 + 4098];
    let x13: f32 = in0[x0 + 4099];
    let x14: f32 = in0[x0 + 8192];
    let x15: f32 = in0[x0 + 8193];
    let x16: f32 = in0[x0 + 8194];
    let x17: f32 = in0[x0 + 8195];
    let x18: f32 = in0[x0 + 12288];
    let x19: f32 = in0[x0 + 12289];
    let x20: f32 = in0[x0 + 12290];
    let x21: f32 = in0[x0 + 12291];
    let x22: f32 = in1[x2 + 1];
    let x26: f32 = in1[x2 + 2];
    let x30: f32 = in1[x2 + 3];
    let x5: f32 = in1[x2 + 4096];
    let x23: f32 = in1[x2 + 4097];
    let x27: f32 = in1[x2 + 4098];
    let x31: f32 = in1[x2 + 4099];
    let x7: f32 = in1[x2 + 8192];
    let x24: f32 = in1[x2 + 8193];
    let x28: f32 = in1[x2 + 8194];
    let x32: f32 = in1[x2 + 8195];
    let x9: f32 = in1[x2 + 12288];
    let x25: f32 = in1[x2 + 12289];
    let x29: f32 = in1[x2 + 12290];
    let x33: f32 = in1[x2 + 12291];
    acc0 += x1 * x3 + x4 * x5 + x6 * x7 + x8 * x9;
    acc1 += x10 * x3 + x11 * x5 + x12 * x7 + x13 * x9;
    acc2 += x14 * x3 + x15 * x5 + x16 * x7 + x17 * x9;
    acc3 += x18 * x3 + x19 * x5 + x20 * x7 + x21 * x9;
    acc4 += x1 * x22 + x4 * x23 + x6 * x24 + x8 * x25;
    acc5 += x10 * x22 + x11 * x23 + x12 * x24 + x13 * x25;
    acc6 += x14 * x22 + x15 * x23 + x16 * x24 + x17 * x25;
    acc7 += x18 * x22 + x19 * x23 + x20 * x24 + x21 * x25;
    acc8 += x1 * x26 + x4 * x27 + x6 * x28 + x8 * x29;
    acc9 += x10 * x26 + x11 * x27 + x12 * x28 + x13 * x29;
    acc10 += x14 * x26 + x15 * x27 + x16 * x28 + x17 * x29;
    acc11 += x18 * x26 + x19 * x27 + x20 * x28 + x21 * x29;
    acc12 += x1 * x30 + x4 * x31 + x6 * x32 + x8 * x33;
    acc13 += x10 * x30 + x11 * x31 + x12 * x32 + x13 * x33;
    acc14 += x14 * x30 + x15 * x31 + x16 * x32 + x17 * x33;
    acc15 += x18 * x30 + x19 * x31 + x20 * x32 + x21 * x33;
  }
  let x34: i32 = ((gidx / 8192) * 131072) + ((((gidx / 64) % 128) * 32) + ((((gidx / 8) % 8) * 16384) + ((gidx % 8) * 4)));
  result[x34] = acc0;
  result[x34 + 4096] = acc1;
  result[x34 + 8192] = acc2;
  result[x34 + 12288] = acc3;
  result[x34 + 1] = acc4;
  result[x34 + 4097] = acc5;
  result[x34 + 8193] = acc6;
  result[x34 + 12289] = acc7;
  result[x34 + 2] = acc8;
  result[x34 + 4098] = acc9;
  result[x34 + 8194] = acc10;
  result[x34 + 12290] = acc11;
  result[x34 + 3] = acc12;
  result[x34 + 4099] = acc13;
  result[x34 + 8195] = acc14;
  result[x34 + 12291] = acc15;
}&lt;/code&gt;
    &lt;p&gt;If you’re writing a native library, this isn’t good enough. For example, you have to at least use tensor cores &lt;code&gt;mma.sync.aligned.*&lt;/code&gt; on Nvidia GPUs! But on the web, it gets to pretty comparable performance with the best open-source libraries, and it seems that Dawn is alright at bridging any gaps with optimization.&lt;/p&gt;
    &lt;p&gt;Onto the frontend. This is the core of the library, and where the actual autograd and tracing happens. We follow the JAX design quite closely, where there is a set of primitives along with an ambient interpreter stack. This is… quite difficult, magical, and took me a while to figure out. To learn more see:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The simple essence of automatic differentiation (Elliott 2018)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(One particularly cool moment about this way of building an ML library is that you get reverse-mode AD “for free” by inverting/transposing the forward-mode rules. I found this really beautiful after I wrapped my head around it; it’s quite mathematically pleasing. Another cool moment is when you first get arbitrary 2nd, 3rd, … n-th order derivatives after just implementing the first-order derivative rules — GradientTape could never!)&lt;/p&gt;
    &lt;p&gt;Honestly this is probably the most lost I’ve ever felt in writing code. It’s like, nested mutually recursive interpreters to model functors in the “category of tensors.”&lt;/p&gt;
    &lt;p&gt;Anyway, once I reviewed my differential geometry notes from college and dusted off my understanding of tangents, pulling back cotangents, functors and so on, I think I eventually figured it out. Though I still had tiny bugs for the next 6 months. 😂&lt;/p&gt;
    &lt;p&gt;The list of high-level &lt;code&gt;Primitive&lt;/code&gt; in jax-js is below:&lt;/p&gt;
    &lt;code&gt;/**
 * Frontend primitive operations, which are lowered into Kernel objects before
 * being dispatched to the backend.
 *
 * Any operation between arrays can be described in these parts. This is also
 * the set of primitives that can occur in Jaxpr programs, and the level at
 * which transformations like vmap, grad, and jvp occur. They are loosely based
 * on [XLA](https://openxla.org/xla/operation_semantics).
 *
 * All n-ary operations support broadcasting, with NumPy semantics.
 */
export enum Primitive {
  Add = “add”,
  Mul = “mul”,
  Idiv = “idiv”,
  Neg = “neg”,
  Reciprocal = “reciprocal”,
  StopGradient = “stop_gradient”,
  Cast = “cast”,
  Bitcast = “bitcast”,
  RandomBits = “random_bits”,
  Sin = “sin”,
  Cos = “cos”,
  Asin = “asin”,
  Atan = “atan”,
  Exp = “exp”,
  Log = “log”,
  Erf = “erf”,
  Erfc = “erfc”,
  Sqrt = “sqrt”,
  Min = “min”,
  Max = “max”,
  Reduce = “reduce”,
  Dot = “dot”, // sum(x*y, axis=-1)
  Conv = “conv”, // see lax.conv_general_dilated
  Pool = “pool”,
  PoolTranspose = “pool_transpose”,
  Compare = “compare”,
  Where = “where”,
  Transpose = “transpose”,
  Broadcast = “broadcast”,
  Reshape = “reshape”,
  Flip = “flip”,
  Shrink = “shrink”,
  Pad = “pad”,
  Gather = “gather”,
  JitCall = “jit_call”,
}&lt;/code&gt;
    &lt;p&gt;Notice that many of these are similar to the backend operations above, but some are different. In particular, there are convolutions and matrix multiplications here. These are useful to see in the frontend IR (and for autograd) but can be lowered to a simpler form before the kernels are generated on the backend.&lt;/p&gt;
    &lt;p&gt;By default, an operation is just lowered directly to a backend kernel after passing through any necessary transformations (&lt;code&gt;vmap&lt;/code&gt;, &lt;code&gt;jvp&lt;/code&gt;, &lt;code&gt;grad&lt;/code&gt;). But if you’re using the &lt;code&gt;jit&lt;/code&gt;, jax-js will trace your program to produce a “Jaxpr” (list of operations) followed by automatic kernel fusion to generate kernels, specialized to each input shape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bugs&lt;/head&gt;
    &lt;p&gt;It’s very hard to build an ML framework and a long task! So far, jax-js has implemented a lot of core functionality in JAX, but there’s still much more. If there’s an API or operation you want to see, please consider adding it or filing an issue (examples: np.split, FFT, AdamW).&lt;/p&gt;
    &lt;p&gt;I have a pretty varied, portable test suite that runs fast:&lt;/p&gt;
    &lt;p&gt;So we are in a good position to find bugs and fix them. But making an ML library is quite difficult, and WebGPU is a nascent technology (e.g., I somehow gave my MacBook kernel panics)—there will be bugs! Please report.&lt;/p&gt;
    &lt;head rend="h3"&gt;Technical: Performance&lt;/head&gt;
    &lt;p&gt;We haven’t spent a ton of time optimizing yet, but performance is generally pretty good. &lt;code&gt;jit&lt;/code&gt; is very helpful for fusing operations together, and it’s a feature only available on the web in jax-js. The default kernel-tuning heuristics get about 3000 GFLOP/s for matrix multiplication on an M4 Pro chip (try it).&lt;/p&gt;
    &lt;p&gt;On that specific benchmark, it’s actually more GFLOP/s than both TensorFlow.js and ONNX, which both use handwritten libraries of custom kernels (versus jax-js, which generates kernels with an ML compiler).&lt;/p&gt;
    &lt;p&gt;Some particularly useful / low-hanging fruit to look at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The WebAssembly backend currently is quite simple, I didn’t spend a ton of time optimizing it, but measurably it could be &amp;gt;150x faster on my MacBook Pro. This difference comes from a few things multiplying:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Don’t recompute loop indices each time, we could improve FLOPs by ~1-3x.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Do loop unrolling/tiling, will improve FLOPs by ~2-3x.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Use SIMD instructions. This would improve FLOPs by 4x.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Add multi-threading (10x on my laptop), to use all available cores. Requires SharedArrayBuffer (crossOriginIsolated) / there are some caveats here to sync/async handling, needs to be done carefully.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Running the forward pass of the MobileCLIP2 transformer model is only about 1/3 the FLOPs compared to pure 4096x4096 matmul. Maybe we can improve this, especially in the causal self-attention layer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Although WebGPU is rapidly gaining in popularity and support, it’s probably worth having a WebGL backend as well, as a fallback that’s guaranteed to work in pretty much all browsers and is still pretty fast. This isn’t a huge amount of work; the WebGPU backend is &amp;lt;700 lines of code for example.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Technical: Feature parity&lt;/head&gt;
    &lt;p&gt;jax-js strives for approximate API compatibility with the JAX python library (and through that, NumPy). But some features vary for a few reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Data model: jax-js has ownership of arrays using the&lt;/p&gt;&lt;code&gt;.ref&lt;/code&gt;system, which obviates the need for APIs like&lt;code&gt;jit()&lt;/code&gt;‘s&lt;code&gt;donate_argnums&lt;/code&gt;and&lt;code&gt;numpy.asarray()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Language primitives: JavaScript has no named arguments, so method call signatures may take objects instead of Python’s keyword arguments. Also, PyTrees are translated in spirit to “JsTree” in jax-js, but their specification is different.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Maturity: JAX has various types like&lt;/p&gt;&lt;code&gt;complex64&lt;/code&gt;, advanced functions like&lt;code&gt;hessenberg()&lt;/code&gt;, and advanced higher-order features like&lt;code&gt;lax.while_loop()&lt;/code&gt;that we haven’t implemented. Some of these are not easy to implement on GPU.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other features just aren’t implemented yet. But those can probably be added easily!&lt;/p&gt;
    &lt;p&gt;I’ve made a table of every JAX library feature and its implementation status in jax-js, see here. There are a couple big ones that stand out.&lt;/p&gt;
    &lt;p&gt;You’re welcome to contribute, though I’d also love if you could try using jax-js. :D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46516267</guid><pubDate>Tue, 06 Jan 2026 18:19:31 +0000</pubDate></item><item><title>Video Game Websites in the early 00s</title><link>https://www.webdesignmuseum.org/exhibitions/video-game-websites-in-the-early-00s</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46516559</guid><pubDate>Tue, 06 Jan 2026 18:39:21 +0000</pubDate></item><item><title>High-Performance DBMSs with io_uring: When and How to use it</title><link>https://arxiv.org/abs/2512.04859</link><description>&lt;doc fingerprint="b89f341a58d3848a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Databases&lt;/head&gt;&lt;p&gt; [Submitted on 4 Dec 2025 (v1), last revised 12 Dec 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:High-Performance DBMSs with io_uring: When and How to use it&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Matthias Jasny [view email]&lt;p&gt;[v1] Thu, 4 Dec 2025 14:43:03 UTC (504 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 12 Dec 2025 09:44:22 UTC (505 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46517319</guid><pubDate>Tue, 06 Jan 2026 19:29:15 +0000</pubDate></item><item><title>Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone</title><link>https://github.com/rberg27/doom-coding</link><description>&lt;doc fingerprint="d11490dd3b96cae3"&gt;
  &lt;main&gt;
    &lt;p&gt;A DIY approach to coding on-the-go!&lt;/p&gt;
    &lt;p&gt;As an aspiring builder, I sought out a way to keep coding while not at home. Thanks to some Claude-assisted research and troubleshooting, I can now code via the terminal on my phone anywhere at anytime via "Doom Coding" (think Doom Scrolling but more productive).&lt;/p&gt;
    &lt;p&gt;After this 5-minute setup guide, you'll be able to "doom code" anywhere you have Internet connection.&lt;/p&gt;
    &lt;p&gt;I've been amazed by how much I can get done while being so far away from home. In Taiwan, I could access my computer in Philadelphia and coded a prototype in my downtime.&lt;/p&gt;
    &lt;p&gt;Shameless plug: check out www.friendlyr.ai to help shape the future of connection!&lt;/p&gt;
    &lt;p&gt;Make sure to "Watch" this repo for future updates to this doom coding guide. As I tryout the latest mobile coding tools (e.g. Claude Code on the Web), I'll update this repository with comparisons.&lt;/p&gt;
    &lt;p&gt;Happy doom coding my friends!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A Computer running 24/7 with Internet Connection&lt;/item&gt;
      &lt;item&gt;A Smartphone&lt;/item&gt;
      &lt;item&gt;A Claude Pro subscription&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Tailscale, Termius, Claude Code, and a computer running 24/7 to continue building anywhere you have Internet connection.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable sleep in power settings&lt;/item&gt;
      &lt;item&gt;Enable SSH/Remote Login&lt;/item&gt;
      &lt;item&gt;Install Tailscale and sign in&lt;lb/&gt;https://tailscale.com/download&lt;/item&gt;
      &lt;item&gt;Install Claude Code on your computer&lt;lb/&gt;https://docs.anthropic.com/en/docs/claude-code/overview&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Install Tailscale → Sign in with the same account&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/tailscale/id1470499037&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Install Termius (A Mobile Terminal Tool)&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/termius-modern-ssh-client/id549039908&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Note the MagicDNS address of your computer (e.g. my-computer.tailnet-name.ts.net)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create a new host in Termius:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Label: What you want your connection to be called&lt;/item&gt;
          &lt;item&gt;Hostname: The MagicDNS address (my-computer.tailnet-name.ts.net)&lt;/item&gt;
          &lt;item&gt;Port: 22&lt;/item&gt;
          &lt;item&gt;Username/Password: Your login for your computer &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you're not able to establish a connection from your phone via Termius to your computer:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check your phone settings to make sure you are connected to the Tailscale VPN. &lt;/item&gt;
      &lt;item&gt;Check the Tailscale app to make sure the Tailscale VPN is on. If your phone and doom coding computer do not have a green circle next to their labels, there is an issue with your Tailscale/Internet connection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When disconnecting/reconnecting power, make sure you unlock the computer. I've ran into this issue one too many times.&lt;/p&gt;
    &lt;p&gt;End sessions by asking Claude to update CLAUDE.md with where you left off.&lt;/p&gt;
    &lt;p&gt;Go to your desired directory and start an HTTP server&lt;code&gt;python -m http.server 3005&lt;/code&gt;
then visit http://your-machine.tailnet-name.ts.net:3005/your-html-file.html in a browser on your phone.&lt;/p&gt;
    &lt;p&gt;Wherever you would use localhost:PORT to view an app on your computer, replace localhost with the computer's MagicDNS from the Tailscale app (e.g. your-computer.tailnet-name.ts.net)&lt;/p&gt;
    &lt;p&gt;Use the PostgreSQL app to view databases for your projects https://apps.apple.com/us/app/postgresql-client/id1233662353&lt;/p&gt;
    &lt;p&gt;On your computer, bookmark the sites you refer to during development (e.g. Google OAuth, GitHub) to make it easier to reference from your phone. I use the Chrome app to seamlessly access the sites I need.&lt;/p&gt;
    &lt;p&gt;Please contibute your best practices! I am looking forward to seeing all the places you will code!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46517458</guid><pubDate>Tue, 06 Jan 2026 19:38:32 +0000</pubDate></item><item><title>Self hosting my media library with Jellyfin and Wireguard on Hetzner</title><link>https://layandreas.github.io/personal-blog/posts/how-spotify-made-me-self-host/</link><description>&lt;doc fingerprint="fd11bd7d192258f0"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: This post was written without the help of AI. Research for the self hosting setup (which docker images to use, Jellyfin vs. Plex) and the creation of initial configurations (docker-compose, wireguard) were supported by AI (among others like e.g. Reddit, Stackoverflow)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;How It All Started&lt;/head&gt;
    &lt;p&gt;If you don’t care about my motivations and are only interested in the technical setup just directly jump to Self Hosting Setup!&lt;/p&gt;
    &lt;head rend="h3"&gt;Spotify Price Increase&lt;/head&gt;
    &lt;p&gt;In August 2025 Spotify announced a price increase in Germany. I received a friendly message that while I was a valued Premium subscriber, my subscription price would change (some might say increase):&lt;/p&gt;
    &lt;p&gt;For the time being I decided to sit it out. So November 2025 arrived and my Premium membership ended.&lt;/p&gt;
    &lt;p&gt;I decided to give Spotify’s free plan a try. How bad can it be? I had used the free tier 10 years ago and it was perfectly fine. How wrong I was!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The free tier forces shuffle after a certain amount of free choices. So while the tier might be free, your song choice is not. Although there are reports that Spotify supposedly got rid of this feature as of September 2025, I still encountered this restriction as of end of December 2025&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It’s not possible to scrub the song’s progress bar&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I don’t remember these restrictions being in place back in the day, but I may be wrong. It might be a case of enshittification of the free tier?&lt;/p&gt;
    &lt;p&gt;Okay, fair enough: Companies need to make money, I’m not entitled to Spotify providing their services for free! For all those services I still pay for I certainly get an awesome user experience?&lt;/p&gt;
    &lt;p&gt;Not so fast…&lt;/p&gt;
    &lt;head rend="h3"&gt;Across All Streaming Services: Less Value For More Money&lt;/head&gt;
    &lt;p&gt;Across all streaming services I have noticed a decline in user friendliness, UX &amp;amp; UI.&lt;/p&gt;
    &lt;head rend="h4"&gt;Price increases&lt;/head&gt;
    &lt;p&gt;All streaming services have seen price increases and / or introduced ads. I get it, companies need to make money. My day job consists of helping companies increase their revenues, it pays my bills!&lt;/p&gt;
    &lt;p&gt;The issue: These price increases are accompanied by a worse UX/UI. From a user perspective my interest lies in getting the best value for money!&lt;/p&gt;
    &lt;head rend="h4"&gt;Ads&lt;/head&gt;
    &lt;p&gt;Amazon Prime introduced ads to an already paid service. This is a noticeable worse user experience. Netflix introduced a paid plan with ads. At least for me YouTube advertises mostly mobile games &amp;amp; obvious scams (ever gotten one of these terrible liven app ads?)&lt;/p&gt;
    &lt;head rend="h4"&gt;UI&lt;/head&gt;
    &lt;p&gt;In May 2025 Netflix introduced a new UI. It’s a matter of taste and while some people may like it, I find it much worse.&lt;/p&gt;
    &lt;head rend="h4"&gt;Cracking Down on Password Sharing&lt;/head&gt;
    &lt;p&gt;Disney+ followed Netflix and cracked down on password sharing. This is a de facto price increase for many.&lt;/p&gt;
    &lt;head rend="h2"&gt;Self Hosting Setup&lt;/head&gt;
    &lt;p&gt;So I decided to give self hosting a try. I’ve followed the awesome selfhosted subreddit for a while anyway and own a collection of shows, movies &amp;amp; music anyway.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deployment: Hetzner VPS&lt;/head&gt;
    &lt;p&gt;Instead of going with my own hardware I decided to go with a VPS from Hetzner. I chose a CAX21 with 4 VCPUs, 8GB RAM, 20 TB of traffic included and 80 GB of SSD storage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Storage: Hetzner Storage Box&lt;/head&gt;
    &lt;p&gt;While I could use the server’s SSD to store my media, I decided to use Hetzner’s Storage Box. This way I can easily mount my media library on my Macbook via SMB.&lt;/p&gt;
    &lt;head rend="h3"&gt;Media Server: Jellyfin&lt;/head&gt;
    &lt;p&gt;I opted to use the open source Jellyfin as my media server. Plex would be an alternative but it appears to have fallen out of favour and blocks Hetzner anyway, so it would not work for me anyway.&lt;/p&gt;
    &lt;head rend="h3"&gt;Remote Access: VPN Tunnel via WireGuard&lt;/head&gt;
    &lt;p&gt;To access my VPS remotely either from home or on the road I use WireGuard:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Home network: My FRITZ!Box router lets me easily add a WireGuard configuration to my home network. This way any device in my home network can access my media network without having to run a VPN. This is especially useful for accessing Jellyfin on my LG webOS TV as there’s no easy way to connect my TV to WireGuard directly&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On the road: Simply install WireGuard on your device. You will need to create a client configuration for each of your devices&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Server Config&lt;/head&gt;
    &lt;code&gt;[Interface]
Address = 10.13.13.1/24
ListenPort = 51820
PrivateKey = {{ wireguard_server_private_key }}

PostUp   = iptables -A INPUT -i wg0 -p tcp --dport 8096 -j ACCEPT; iptables -A FORWARD -i wg0 -j ACCEPT
PostDown = iptables -D INPUT -i wg0 -p tcp --dport 8096 -j ACCEPT; iptables -D FORWARD -i wg0 -j ACCEPT

[Peer]
PublicKey = {{ wireguard_client_public_key }}
AllowedIPs = 10.13.13.2/32

[Peer]
PublicKey = {{ wireguard_client_public_key_iphone }}
AllowedIPs = 10.13.13.3/32

[Peer]
PublicKey = {{ wireguard_client_public_key_fritzbox }}
AllowedIPs = 10.13.13.4/32
&lt;/code&gt;
    &lt;p&gt;Peers&lt;/p&gt;
    &lt;p&gt;In my WireGuardserver config I currently have three devices added as peers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;My Macbook (&lt;code&gt;wireguard_client_public_key&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;My iPhone (&lt;code&gt;wireguard_client_public_key_iphone&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;My FRITZ!Box router (&lt;code&gt;wireguard_client_public_key_fritzbox&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each device has its corresponding private key stored inside its WireGuard configuration / app. The &lt;code&gt;AllowedIPs&lt;/code&gt; only allows the corresponding peer to use this internal IP address. On your device (router, notebook, mobile phone, …) you’ll need to assign this IP address as the interface section.&lt;/p&gt;
    &lt;p&gt;Let’s dive a bit deeper into the interface block.&lt;/p&gt;
    &lt;p&gt;Interface&lt;/p&gt;
    &lt;p&gt;Configuration for the network interface created on the server.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Address = 10.13.13.1/24&lt;/code&gt;: This is the address of the Hetzner server in our VPN&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ListenPort = 51820&lt;/code&gt;: UDP port number the WireGuard server listens on for incoming VPN connections&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PrivateKey = {{ wireguard_server_private_key }}&lt;/code&gt;: WireGuard uses this private key to identify itself to clients (via the public key which is shared)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PostUp / PostDown&lt;/code&gt;: Port forwarding - we allow WireGuard to forward incoming traffic&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Client Config&lt;/head&gt;
    &lt;p&gt;Here’s an example how a client config on my Macbook looks like:&lt;/p&gt;
    &lt;p&gt;You’ll have a separate configuration for each of your devices.&lt;/p&gt;
    &lt;head rend="h3"&gt;Docker Compose&lt;/head&gt;
    &lt;p&gt;And finally here’s the compose config for the actualy deployment on the VPS:&lt;/p&gt;
    &lt;code&gt;version: "3.9"

services:
  wireguard:
    image: linuxserver/wireguard:latest
    container_name: wireguard
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - SERVERPORT=51820
      - SERVERURL=&amp;lt;SERVERS-IP-ADDRESS&amp;gt;
    volumes:
      - ./wireguard/config:/config
      - /lib/modules:/lib/modules:ro
    ports:
      - "51820:51820/udp"
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    restart: unless-stopped

  jellyfin:
    image: jellyfin/jellyfin:latest
    container_name: jellyfin
    network_mode: "service:wireguard"
    user: 1000:1000
    volumes:
      - ./jellyfin/config:/config
      - /mnt/storagebox:/media:ro
    environment:
      - TZ=UTC
    restart: unless-stopped
    depends_on:
      - wireguard
&lt;/code&gt;
    &lt;p&gt;Some notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wireguard:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;51820:51820/udp&lt;/code&gt;: We only expose WireGuard UDP port&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Jellyfin:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;/mnt/storagebox:/media:ro&lt;/code&gt;: Mounting my Hetzner storage box with my media library into the container&lt;/item&gt;&lt;item&gt;&lt;code&gt;network_mode: "service:wireguard"&lt;/code&gt;: Shares the WireGuard container’s network stack&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;So Is Self Hosting a Alternative to Streaming Services?&lt;/head&gt;
    &lt;p&gt;It depends. My personal media library isn’t big enough that it could rival any of the streaming services libraries. You also need to put in the work to get your self-hosted setup running which non-technical people won’t do, and even for technical people it might not be worth it. For me personally it’s totally worth it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46517636</guid><pubDate>Tue, 06 Jan 2026 19:50:35 +0000</pubDate></item><item><title>Calling All Hackers: How money works (2024)</title><link>https://phrack.org/issues/71/17</link><description>&lt;doc fingerprint="332310190d2133ec"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Title : Calling All Hackers&lt;/p&gt;
      &lt;p&gt; Author : cts&lt;/p&gt;
      &lt;quote&gt; ==Phrack Inc.== Volume 0x10, Issue 0x47, Phile #0x11 of 0x11 |=-----------------------------------------------------------------------=| |=-----------------------=[ Calling All Hackers ]=-----------------------=| |=-----------------------------------------------------------------------=| |=--------------------------=[ cts (@gf_256) ]=--------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 0 - Preamble 1 - About the Author 2 - The Birth of a Shitcoin 3 - How Money Works 3.1 - Fixed Income 3.2 - Equities 3.3 - Shareholder Value 4 - Startup Blues 5 - Takeaways 6 - Thanks 7 - References 8 - Appendix --[ 0 - Preamble Hi. I'm cts, also known as gf_256, ephemeral, or a number of other handles. I am a hacker and now a small business owner and CEO. In this article, I would like to share my experience walking these two different paths. A hacker is someone who understands how the world works. It's about knowing what happens when you type "google.com" and press Enter. It's about knowing how your computer turns on, about memory training, A20, all of that. It's about modern processors, their caches, and their side channels. It's about DSi bootloaders and how the right electromagnetic faults can be used to jailbreak them. And it's about how Spotify and Widevine and AES and SGX work so you can free your music from the shackles of DRM. But being a hacker is so much more than these things. It's about knowing where to find things. Like libgen and Sci-Hub and nyaa. Or where to get into the latest IDA Pro group buy. Or which trackers have what and how to get into them. It's about knowing how to bypass email verification. How to bypass SMS verification. How to bypass that stupid fucking verification where you hold your driver's license up to a webcam (thank you, OBS virtual camera!) Having an actual threat model not just paranoia. Knowing that you're not worth burning a 0day on, but reading indictments to learn from others' mistakes. It's about knowing where to buy estradiol valerate on the internet and how to compound injections. Or the "bodybuilder method" to order your own blood tests when your state requires a script to do so. It's about knowing which shipments give the US CBP a bad vibe and which don't. It's about knowing what happens when you open Robinhood and giga long NVDA FDs. I mean the actual market microstructure, not "Ken Griffin PFOF bad". Then using that microstructure to find an infinite money glitch (high Sharpe!). It's about knowing how to get extra passports and reading the tax code. It's about knowing how to negotiate your salary (or equity). It's about knowing why things at the supermarket cost what they do. Or how that awful shitcoin keeps pumping. And why that dogshit startup got assigned that insane valuation. And understanding who really pays for it in the end (hint: it's you). My point is, it is not just about computers. It's about understanding how the world works. The world is made up of people. As much as machines keep society running, those machines are programmed by people--people with managers, spouses, and children; with wants, needs, and dreams. And it is about using that knowledge to bring about the change you want to see. That is what being a hacker is all about. --[ 1 - About the Author I have been a hacker for 13 years. Prior to founding Zellic, I helped start a CTF team called perfect blue (lately Blue Water). We later became the number one ranked CTF team in the world. We've played in DEF CON CTF. We've won GoogleCTF, PlaidCTF, and HITCON. It's like that scene from Mr. Robot but not cringe. In 2021, we decided to take that hacker friend circle and form a security firm. It turned out that crypto paid well, so we worked with a lot of crypto clients. In the process, we encountered insane, hilarious, and depressingly sobering bullshit. In this article, I will tell some stories about what that bullshit taught me, so you can benefit from the same lessons as I have. Markets are computers; they compute prices, valuations, and the allocation of resources in our society. Hackers are good at computers. Let's learn more about it. --[ 2 - The Birth of a Shitcoin I can't think of a better example than shitcoins. Let's look at the crypto markets in action. First, let's talk about tokens. What is their purpose? The purpose of a token is to go up. There is no other purpose. Token go up. This is important, remember this point. Now the question is, how do we make the token go up? In crypto, there are two main kinds of token deals. Let's call them the Asian Arrangement and the Western Way. The Asian Arrangement is a fairly straightforward pump and dump. It's a rectangle between the VC, the Market Maker, the Crypto Exchange, and the Token Project Founder. 1. The exchange's job is to list the token, bringing in investors. They get paid in a mix of tokens and cold, hard cash. Their superpower is owning the customer relationships with the retail users, and the naming rights to sports arenas. 2. The market maker provides liquidity so the market looks really healthy and well-traded so it is easy to buy the token. In good deals, they are paid in in-the-money call options on the tokens, so they are incentivized to help the token trade well. Their superpower is having a lot of liquidity to deploy, and people on PagerDuty. 3. The founder's job is to pump the token and shill it on Twitter. They are the hype man, and it's their job to drum up the narrative and pump everyone's bags. Their unique power is they can print more tokens out of thin air, and this is in large part how they get paid in this arrangement. 4. Lastly, the VC gets paid to organize the deal. They give the founders some money, who in return give a pinky promise that they will give the VC a lot of tokens once the tokens actually exist. This is known as a Simple Agreement for Future Tokens, or SAFT. Their superpower is dressing up the founders and project so it seems like the Next Big Thing instead of a Ponzi scheme. Everyone gets paid a ton of token exposure (directly or indirectly), and when it lists, it pumps. Then the insiders dump and leave with a fat stack. Except retail, they end up with the bag. Sometimes the listing doesn't go well for the organizers, in which case, better luck next time. But retail always loses. wtf??? LFG!!! to the moon ,o \oXo/\o/ /v | | | /\ / X\ / \ crypto investors ^ | | | | v +----------+ provides liquidity +--------+ | Crypto | &amp;lt;--------------------------------------- | Market | | Exchange | ----------------------------------------&amp;gt; | Maker | +----------+ maker fees +--------+ ^ | ^ fees, | | listing options | tokens | | / fees | | | +-------------------------------------------------+ | v | +---------+ tokens / SAFT / token warrants +---------+ | Token | ---------------------------------------&amp;gt; | Venture | | Project | &amp;lt;--------------------------------------- | Capital | +---------+ cash , intros to CEX / MM, shilling +---------+ This machine worked exceptionally well in 2017, especially before China banned crypto. All those ICO shitcoins? Asian Arrangement. And it still works well to this day, except people are more wary of lockups and vesting schedules and so on. Now let's discuss the Western Way. The Asian Arrangement? That old pump and dump? No sir, we are civilized people. Instead, our VCs *add value* to their investments by telling the world "how disruptive the tech is" and how the "team are incredible outliers". And they will not blatantly PnD the token, but instead they will fund "projects in the ecosystem" so it appears there is real activity happening on the platform. This is to hype up metrics (like TPS or TVL) to inflate the next round valuation. Anyways, then they dump. Or maybe the VC is also a market maker so they market make their portfolio company tokens. Overall it's the same shit (Ponzi) but dressed up in a nicer outfit. Asian Arrangement or Western Way--either way, if you're the token founder, your main priority is to just GO TO MARKET NOW and LAUNCH THE TOKEN. This is so you can collect your sweet bag and dump some secondary before someone else steals the narrative or the hype cycle moves on. This is one of the reasons there are so many hacks in crypto. The code is all shitty because it's rushed out as fast as possible by 20-something- year-old software engineers formerly writing Typescript and Golang at Google. Pair that with some psycho CEO product manager. Remember, it is not about WRITING SECURE CODE, it is about SHIPPING THE FUCKING PRODUCT. Good luck rewriting it in Rust! All of this worked well until Luna, then 3AC, Genesis, and FTX imploded in 2022. It still works, but you have to be less blatant now. Shitcoins do serve an essential need. They are an answer to financial nihilism. Many people are working dead-end wage slave jobs that are not enough to "make it". They feel trapped and forced to work at jobs they fucking hate and waste their life doing pointless shit to generate shareholder value. This kind of life feels unacceptable, yet there are few avenues out. So what is the only "attainable" solution left? Gamble it on shitcoins, and if you lose...maybe next paycheck will be better. But enough about crypto, let's talk about securities. --[ 3 - How Money Works ----[ 3.1 - Fixed Income First, let's start with fixed income. I'm talking boring, old-fashioned bonds, like Treasury bonds. A lot of people are introduced nowadays to finance through equities (stocks) and tokens. In my opinion, this is only half of the story. Fixed income is the bedrock of finance. It has fundamental value. It provides a prototypical asset that all assets can be benchmarked based on. Fixed income assets, like bonds, boil down to borrowing and lending. A bond is basically an IOU for someone to pay you in the future. It is more useful to have a dollar today than in a year, so lenders charge a fee for access to money today. This fee is known as interest, and how it is baked into the equation varies from asset-to-asset. Some bonds come with interest payments, whereas other bonds are zero-coupon. The most important thing is to remember that bonds are essentially an IOU to pay $X in the future. Here is an example. Let's say you would like to borrow $100 to finance an upcoming project. The interest rate will be 5% per year. To borrow money, you would issue (mint) a bond (an IOU) for $X+5 dollars to be repaid 1 year in the future. In exchange for this fresh IOU, the lender will give you $X dollars now. On the lender's balance sheet, they will be less $X dollars worth of cash, but will also have gained ($X+5) dollars worth of an asset (your IOU), creating $5 of equity. In contrast, you would have $X more cash in assets, but also an ($X+5) liability, creating -$5 of equity. This example also works for depositing money at a bank. Here, you are the lender, and the bank is the borrower. Your deposits would be liabilities on their balance sheet, as they are liable to pay you back the deposit if you choose to withdraw it. Lender's Balance Sheet Borrower's Balance Sheet =========================== =========================== Assets: Assets: IOU-----------------X+5 Cash------------------X Liabilities: Liabilities: Cash----------------(X) IOU-----------------X+5 Equity: Equity: Equity----------------5 Equity--------------(5) Fixed income assets are extremely simple. There are various risks (credit risk, interest rate risk, etc.), but excluding these factors, you essentially get what you pay for. Unlike a token or stock, the bond is not going to suddenly evaporate or crash. (In theory.) Because of this, they can be modeled in a straightforward way; a way so straightforward even a high school student can understand it. Let's say I have $X today. Suppose the prevailing (risk-free) interest rate is 5%. What is the value of this $X in a year? Obviously, it would be no less than $X*1.05, as I can just lend it out for 5% interest and get $X*1.05 back in a year. If you gave me the opportunity to invest in any asset yielding less than 5%, this would be a bad deal for me, since I could just lend it out myself to get 5% yield. Now, let's analyze the same scenario, but in reverse. Let's take that IOU from earlier. What is the value *today* of a (risk-free) $X IOU, due in 1 year? It would be worth no more than $X/1.05. This is because with $X/1.05 dollars today, I could lend it out and collect 5% interest to end up with $X again in the future. If I pay more than $X/1.05, I am getting a bad deal, since I am locking up my money with you when it would be more capital efficient to just lend it out myself. You can probably see where I am going with this. The present value of an $X IOU at some time *t* in the future is $X/(1+r)^t, where *r* is the discount rate. The discount rate describes the "decay" of the value over time, due to interest but also factors like potential failure of the asset (for example, if the asset is a company, business failure of the company). Now, if we have some asset which pays a series of future cash flows *f(t)*, we can model this asset as a bundle of IOUs with values f(t) due in time 1, 2, 3, and so on. Then the present value of this asset is the geometric series sum of the discounted future cash flows. This is called discounted cash flows (DCF). Congrats, now you can do better modeling than what goes into many early-stage venture deals. +------+-----+-----+---------+---------+---------+-------+---------+ | Year | 0 | 1 | 2 | 3 | 4 | ... | t | +------+-----+-----+---------+---------+---------+-------+---------+ | Cash | CF1 | CF2 | CF3 | CF4 | CF5 | ... | CF_t | | Flow | | | | | | | | +------+-----+-----+---------+---------+---------+-------+---------+ | Disc.| CF1 |_CF2_| __CF3__ | __CF4__ | __CF5__ | ... | _CF_t__ | | Val | | 1+r | (1+r)^2 | (1+r)^3 | (1+r)^4 | | (1+r)^t | +------+-----------+---------+---------+---------+-------+---------+ IOU 1 IOU 2 IOU 3 IOU 4 IOU 5 ... IOU n inf _ f(t) 1 DCF = \ ------- = (assume constant annual cash flow x) = --------- x /_ (1+r)^t 1-1/(1+r) t=0 = (1/r + 1) x Cash flow multiple = (value) / (annual cash flow) ~= 1/r (The astute reader might also find that they can go backwards from valuations to estimate first, second, ... Nth derivatives of the cash flow or the year-to-year survival chances of a company. And these can be compared with...going outside and touching grass to see if the valuation actually makes sense.) At this point, you're probably wondering why I'm boring you with all of this dry quant finance 101 shit. Well, it's a useful thing to know about how the world works. First, interest rates affect you directly and personally. You may have heard of the term "zero interest rate environment". In a low interest rate environment, cash flow becomes irrelevant. Why? Consider the DCF geometric series sum if the interest rate r = 0. The present value approaches infinity. If the benchmark hurdle rate we're trying to beat is 0%, literally ANYTHING is a better investment than holding onto cash. Now do you see why VCs were slamming hundreds of millions into blatantly bad deals and shit companies during Covid? Cash flow and profitability didn't matter, because you could simply borrow more money from the money printer. Here's a more concrete example. Do you remember a few years ago when Uber rides were so cheap, that they were clearly losing money on each ride? This is known as Customer Acquisition Cost, or CAC. CAC is basically the company paying you to use their app, go to their store, subscribe to the thing, ... whatever. The strategy is well-known: burn money to acquire users until everyone else dies and you become a monopoly. Then raise the prices. But here is the key point: this only works in a low-interest rate environment. In such an environment, discounting is low, and thus, future growth potential is valued over profitability and fundamentals at present. It doesn't need to make sense *today* as long as it works 10 years from now. For now, we can keep borrowing more money to sustain the burn. Of course, when rates go back up, the free money machine turns off and the effects ripple outward. You are the humble CAC farmer, farming CAC from various unprofitable consumer apps like ride share, food delivery, whatever. These apps raise their money from their investors, VC and growth equity funds. These funds in turn raise their money from *their* investors, their limited partners. These LPs might be institutional capital like pension funds, sovereign wealth funds, or family offices. At the end of the day, all of that wealth is generated somewhere throughout the economy by ordinary people. So when some VC-backed founders throw an extravagant party on a boat with fundraised dollars, in some sense, you are the one paying for it. And when the money machine turns off, anyone who had gotten complacent under ZIRP is now left scrambling. Companies will overhire during ZIRP only to do layoffs when rates go up. +=========================+ | THE LIQUIDITY CYCLE | +=========================+ VENTURE CAPITAL _______________ ,.-^=^=^=^=^=^=^=^=^=^;, ,;===============&amp;gt;&amp;gt; E^ a16z LSVP Tiger '^3. .;^ E^ FF Social Cap. '^3 // condensation .E Bain SoftBank Accel 3^ /|^ ^E KP Benchmark :^ || ^;: YC Greylock GC ;3' ,.^-^-^-^-^-^-^-^-^-^-^;, ^.=.=_=_=_=_=_=_=_=_=_=_=^ E^ endowments family '^:. \\\\\\\\\\\\\\\\\\\\ E^ offices '^3 \\\\\\\\\\\\\\\\\\\\ E' pension ^3. SOURCE \\\ precipitation \\ ^; funds sovereign 3.' CAPITAL \\\\\\\\\\\\\\\\\\\\ E;: wealth funds ,3^ (LPs) \\\\\\\\\\\\\\\\\\\\ ^;._.._._._._._._._._._._,^ \\\\\\\\\\\\\\\\\\\\ /\ ^ ^ ^ ^ ^ ^ ^ ^ gamefi /\ /\ uber eats | | | | | | | | shitcoins/::\/::\ /::::\ /\ | evaporation | / doordash/^^^^^^\ /^^\ | | | | | | | | ____________ / \ / hello \ (poggers desu) /_____ lime ____ fresh ___\ \o/ \oXo/\oXoXo/ o '==========' UNPROFITABLE CONSUMER APPS | | | | | | /|\ Oo._ /\_/\ ,/// __/_\_/_X_\/_X_X_\_/_\__ /_________(@'w'@)_____________.,://' SOCIETY \'''''''' -...-''''''''''''''''' surface THE HUMBLE runoff CAC FARMER Second, credit is not inherently a bad thing if used responsibly. Take for example those Buy Now, Pay Later loans. Now that you are equipped with the concept of capital efficiency, wouldn't it technically better than paying cash to take an interest-free BNPL loan and temporarily stick the freed cash into an investment? (Barring other side effects, etc.) Third, the concept of net present value--i.e., credit--is the killer app of finance. It allows you to transport value from the future into today. Of course, that debt must be repaid in the future, unless you can figure out a way to kick the can down the road forever. For now, let's get back to stocks. ----[ 3.2 - Equities Now we have seen both sides of the coin. Asset value is twofold: speculative and fundamental. First, we saw speculative value as illustrated by crypto meme coins. Then, on the other hand, we examined fundamental value as illustrated by, e.g. a US Treasury. These two lie on two extremes of a spectrum. Some sectors and stocks are more speculative than others; Nvidia is practically a meme coin at this point, whereas something like Coca-Cola is like fixed income for boomers (NFA BTW). Most assets have a blend of both. Thinking about stocks, they (usually) have some fundamental value. Equities represent ownership of some asset, like a business. The business in theory generates dividends for shareholders, and this cash flow (or the net present value of future ones) represents the fundamental value of the business. As we've seen, assets with better cash flows are more valuable. In practice, buybacks can be used to create what is effectively a shareholder dividend in a more tax-advantaged way. Whereas with dividends, they are taxed as income, and this is realized immediately. With buybacks, they are taxed as capital gains, but crucially the gains are not realized until the asset is sold. This could be indefinitely far in the future, so it's more capital efficient. It has the added benefit that it helps pump the token, and imo this is kind of cute because it marries both the fundamental and speculative aspects. Meanwhile, like tokens, stocks are also supposed to go up. Here's an example: imagine a generic meme coin. Apart from Go Up, what does it do? Nothing. Even if it's a Governance Token, who cares when the founders and VCs hold all the voting power? Anyways, I'm describing Airbnb Class A Common Stock. Here's an excerpt from their S-1 [1] [2]: &amp;gt; We have four series of common stock, Class A, Class B, Class C, and &amp;gt; Class H common stock (collectively, our "common stock"). The rights of &amp;gt; holders of Class A, Class B, Class C, and Class H common stock are &amp;gt; identical, except voting and conversion rights ... Each share of Class A &amp;gt; common stock is entitled to one vote, each share of Class B common stock &amp;gt; is entitled to 20 votes and is convertible at any time into one share of &amp;gt; Class A common stock ... Holders of our outstanding shares of Class B &amp;gt; common stock will beneficially own 81.7% of our outstanding capital &amp;gt; stock and represent 99.0% of the voting power of our outstanding capital &amp;gt; stock immediately following this offering, ... Name of | Class B | % | % of Vot- Beneficial Owner | Shares | | ing Power -------------------------------------+------------+-------+----------- Brian Chesky | 76,407,686 | 29.1% | 27.1% Nathan Blecharczyk | 64,646,713 | 25.3% | 23.5% Joseph Gebbia | 58,023,452 | 22.9% | 21.4% Entities Affil. w/ Sequoia Capital | 51,505,045 | 20.3% | 18.9% Why do people buy tech stocks with inflated valuations? Some may because they believe that they will go up, that they will be more dominant, important, and valuable in the future. Like tokens, a large part of stocks' value is speculative. They are expressing their opinion on the future fundamentals. Others may simply because they believe others will believe that it is more valuable. Not fundamentals, this is an opinion about *pumpamentals*. Importantly, unlike fundamental value, speculative value can be created out of thin air. It is minted by *fiat*. Fundamental value is difficult to create, whereas speculative value can be created through hype and psychology alone. ----[ 3.3 - Shareholder Value For stocks, there are usually laws in place to protect investors, pushing the balance between "speculation" and "fundamentals" towards the latter. As a result, firms are generally legally obligated to act in their shareholders' best interests. This is good because normal people will be able to participate in the wealth generated by companies. And obviously, companies should not defraud their investors. However, the biggest *stake* holders in a business, are usually (in order): 1. The employees. No matter what, no one else is spending 8 hours a day, or ~33% of their total waking lifespan at this place. Whatever it is, I guarantee you the employees feel it the most. 2. The customers. The customers are the reason the business is able to exist in the first place. Non-profits are not exempt: their customers are their donors. 3. The local community / local environment / ecosystem. The business doesn't exist in a vacuum. The business has externalities, and those externalities affect most the immediate surrounding environment. 4. And in last place, the shareholders. They do not really do anything except contribute capital and hold the stock. Of course capital is important but they are not spending 8 hours a day here, they are not the reason the business exists, and in fact they might even live in a totally different country. For large, publicly-listed companies, the shareholders have one more unique difference from the other three stakeholders: liquidity. This difference is critical. Liquidity describes how easy it is to buy and sell an asset. A dollar bill is liquid. Bitcoin is liquid. A house is relatively illiquid. Stock in large, publicly-listed companies is also liquid. A shareholder can buy a stock one day and sell it the next. As a result, the relationship is non-commital and opens the opportunity for short-term thinking. There are many things a company could do which would benefit shareholders short term, while harming the other three stakeholders long term. While a shareholder can simply dump their position and leave, the mess created is left for the employees, customers, and community to clean up. (The SPAC boom was a pretty good example of this. Not all SPACs are bad, but a lot of pretty shit businesses publicly listed through SPACs then crashed. This is sad to me because some of that is early investors and founders dumping on retail like a crypto shitcoin, but dressed up because it's NYSE or NASDAQ. Get liquidity then bail.) Now, it is a misconception that stock companies must solely paperclip- maximize short-term shareholder value. However, this is how it often plays out due to fucked up shit in the public markets, like annoying activist hedge funds or executive compensation tied to stock price. And it is true that employees can be shareholders. And that is usually a good thing! But few public companies are truly employee-owned. Thinking about it from this perspective, the concept of maximizing shareholder value seems somewhat backwards. But *why* would one make this system where the priorities are seemingly inverted? One benefit is that it would make your currency extremely valuable. Suppose you want to do some shit on Ethereum (speculating on some animal token?), you will need to have native ETH to do that transaction. Similarly, if you want to invest in US securities you at some point need US Dollars. If you want to get a piece of that sweet $NVDA action, you need dollars. People want to buy American stocks. American companies perform well: they're innovative; they're not too heavily regulated; it's a business friendly environment. (Shareholder value comes first!) The numbers go up. Remember the token founder from earlier in the Asian Arrangement? Suppose you are a *country* in the situation above, with a valuable currency. Not only is your currency in demand and valuable, you are the issuing/minting authority for that token. Similar to the token founder, you can print valuable money and pay for things with it. And speaking of being a founder, let's talk about that! --[ 4 - Startup Blues Based on what we've set up so far, I will discuss some of the problems I see with many startups today and with startup culture. Much of the problems stem from misalignment between shareholders and the other stakeholders (employees, etc). A lot of this comes from the fundamentals of venture capital. VC is itself an asset class, like fixed income and equities. VCs pitch this to their limited partners, at some level, based on the premise that their VC fund will generate yield for them. The strategy is to identify stuff that will become huge and buy it while it's still small and really cheap. Like trading shitcoins, it's about finding what's going to moon and getting in early. In a typical VC fund, a small handful of the investments will comprise the entire returns of the fund, with all of the other investments being 0's. The distribution is very power law. This means we are not looking for 1x, 2x, or 3x outcomes; these may even be seen as failure modes. We are only interested in 20x, 50x, 100x, etc. outcomes. This is because anything less will be insufficient to make up for all the bad investments that get written down to zero. For the same reason, it only makes sense for VCs to invest in certain types of companies. Have you ever heard this one? "We invest in SOFTWARE companies!...How is this SCALABLE? What do the VENTURE SCALE OUTCOMES look like here?" This is because these kinds of companies are the ones with the potential to 100x. They want you to deliver a 100x. Or how about this one? "We invest in CATEGORY-DEFINING companies". At least in security, "category-defining" means a shiny new checkbox in the compliance / cyber insurance questionnaire. In other words, a new kind of product that people MUST purchase. The market is incentivized to deliver a product that meets the minimum bar to meet that checkbox, while being useless. I invite you to think of your favorite middleware or EDR vendors here. For passionate security founders considering raising venture, remember that this is what your "success" is being benchmarked against. _.,------------------------------_ .%' '&amp;amp;. .;' We partner with founders ^; ! building category-defining ;! ; companies at the earliest stages _; ^; _.^ ''-.______________ __________.-' / / / /^ / /^ /;^ /' _________ _________ _-' '. _-' '. ,^ '^_ ,^ '^_ /' '"' /' '"' ^' ^\^ ^' ^\^ : ^| : ^| : . . |) : . . |) : \ |) : \ |) : __\ ,; : __\ ,; " ! ; " ! ; " ^\ _____ /' " ^\ _____ /' '| | ^\ _/^ '| | ^\ _/^ | ^'=====' | ^'=====' | . | | | . | | _' |^__ _' |^__ ---------_-' U '--_ -------------_-' U '--_ ----- ._ _.-' '-._ _.-' '- ':.' \ ; / ': .' \ ; / [4] It's due to the thirst for 100x that there are painful dynamics. A fledgling startup may have founders they really like, but the current business may be unscalable. Bad VCs will push founders towards strategies, bets, models that have a 1% chance of working, but pay out 200x if they do. In the process they destroy a good business--one which has earned the trust of dutiful employees and loyal customers--all for a lottery ticket to build a unicorn. They will throw 100 darts at the dartboard and maybe 5 will land, but what is it like to be the dart? You may have good expected value, but all of that EV is from spikes super far away from the origin. Is it pleasant betting everything on this distribution? VC's want founders to be cult leaders. Have you ever heard this line? "We invest in great storytellers." Like what we saw with stocks and tokens, much of the easily-unlockable potential upside in assets is speculative. In essence, value can be created through narrative. Narrative *IS* value. Bad VC's will push founders to raise more capital at ever higher valuations (higher val = markup = fees), using narrative as fuel for the fire. Storytelling means "pump the token", and the job of the CEO is to (1) be the hype man and to raise (2) cash and (3) eyeballs. For this reason, Sam Altman and Elon are fine CEOs, regardless of other factors, because they are great at all three. Much to the detriment of founders' and their employees' psyche, investors expect founders to be this legendary hype man. This requires a religiosity of belief that is borderline delusional. Have you ever tried to convince one of those Silicon Valley YC-type founder/CEOs that they are wrong? They will never listen to you because they have been socialized to be this way. It is what is expected of them, and it is easy to fall into this trap without even becoming aware of it. But if you think about it, does it make sense that to be a business owner, you need to be a religious leader? Of course not. All of these reasons are why so many startup founders are young. They have little to lose, so gambling it all is OK. Being a cult leader may be traumatizing, but they have time (and the neuroplasticity) to heal. And lastly, they do not have the life experience to have a mature personal identity beyond "I am a startup founder". All of this makes it easy to accept the external pressures to build a company this or that way. And perhaps not the way they would have wanted to, relying instead on their personal values. The true irony is that the latter is what creates true, enduring company culture and not the made-up Mad Libs-tier Company Culture Notion Page shit that so many startups have. And of course, good VCs are self-aware of all of the issues and strive to prevent them. But the overall problem remains. One last externality is for communities based around an industry. When you add billions of venture dollars into an industry, it becomes cringe. It's saddening to me seeing the state of certain cybersecurity conferences which are now dominated by..."COME TO OUR BOOTH, YOU CAN BE A HACKER. PLEASE VIEW OUR AI GENERATED GRAPHICS OF FIGURES CLAD IN DARK HOODIES STATIONED BEHIND LAPTOPS". Here I would use the pensive emoji U+1F614 to describe my feelings about the appropriation of hacker culture but Phrack is 7-bit ASCII, so please have this: :c u_u . _. --[ 5 - Takeaways The point is, all of this made me feel very small and powerless after I realized the sheer size of the problems I was staring at. Nowadays, to me it's about creating good jobs for my friends, helping our customers, and taking care of the community. Importantly, I realized that this is still making a bigger positive impact than what I could have done alone just as an individual hacker or engineer. To me, businesses are economic machines that can create positive (or negative) impact in a consistent, self-sustaining way. There are many people who are talented, kind, and thoughtful but temporarily unlucky. Having a company let me help these friends monetize their abilities and be rewarded fairly for them. And in that way I helped make their life better. Despite a lot of the BS involved in running a business, this is one thing that is very meaningful to me. You can understand computers and science and math as much as you want, but you will not be able to fix the bigger issues by yourself. The systems that run the world are much bigger than what we can break on our laptops and lab benches. But like those familiar systems, if we want to change things for the better, we have to first understand those systems. Knowledge is power. Understanding is the first step towards change. If you do not like the system as it is, then it is your duty to help fix it. Do not swallow blackpills. It's easy to get really cynical and think things are doomed (to AGI apocalypse, to environmental disaster, to techno/autocratic dystopia, whatever). I want to see a world where thoughtful hackers learn these systems and teach each other about them. That generation of hackers will wield that apparatus, NOT THE OTHER WAY AROUND. Creating leverage for yourself. Hackers should not think of themselves as "oh I am this little guy fighting Big Corporation" or whatever. This is low agency behavior. Instead become the corporation and RUN IT THE WAY YOU THINK IT SHOULD BE RUN. Keep it private and closely held, so no one can fuck it up. Closely train up successors, so in your absence it will continue to be run in a highly principled way that is aligned with your values and morals. Give employees ownership, as it makes everyone aligned with the machine's long-term success, not just you. Raising capital. Many things do really need capital, but raise in a responsible way that leaves you breathing room and the freedom to operate in ways that are aligned with your values. Never compromise your values or integrity. Stay laser focused on cash flows and sustainability, as these grant you the freedom to do the things right. HACKERS SHOULDN'T BE AFRAID TO TOUCH THE CAPITAL MARKETS. Many hackers assume "oh that fundraising stuff is for charismatic business types". I disagree. It's probably better for the world if good thoughtful hackers raise capital. Giving them leverage to change the world is better than giving that leverage to some psycho founder drinking the Kool-Aid. I deeply respect many of the authors in Phrack 71, and I would trust them to do a better job taking care of things than an amorphous amalgam of angry and greedy shareholders. For all things that don't need capital, do not raise. Stay bootstrapped for as long as possible. REMEMBER THAT VALUATION IS A VANITY METRIC. Moxie Marlinspike wrote on his blog [3] that we are often guilty of always trying to quantify success. But what is success? You can quantify net worth, but can you quantify the good you have brought to others lives? For personal goals, think long term. People tend to overestimate what they can do in 1 year, but underestimate what they can do in 10. DO NOT start a company thinking you can get your hands clean of it in 2-3 years. If you do a good job, you will be stuck with it for 5-10+ years. Therefore, DO NOT start a company until you are sure that is what you want to do with your life, or at least, your twenties/thirties (depending on when you start). A common lament among founders, even successful ones, is: "Sometimes I feel like I'm wasting my twenties". There's an easy Catch-22 here: you may not know what you really want until you do the company; but once you do the company, you won't really be able to get out of it. Be wary of that. Creating value. This is one of those meaningless phrases that I dislike. Value is what you define it to be. Remember to work on things that have TAMs, but remember that working on art is valuable too! It is not all about the TAM monster--doing cool things that are NOT ECONOMICALLY VALUABLE, but ARTISTICALLY VALUABLE, is equally important. There is not much economic value in a beautiful polyglot file, but it is artistically delightful. This is part of why people hate AI art: it may be economically valuable, but it is often artistically bankrupt. (Some people do use generative tools in actually original and artistic ways, but this is the exception not the norm currently.) Founders vs Investors. Here is my advice: Ignore any pressure from investors to make company "scalable" or whatever. Make sure your investors have no ability to fire you or your co-founder(s). Make sure you and co-founder are always solid and trust each other more than investors. You and your cofounders need to be BLOOD BROTHERS (/sisters/w.e). If an investor is trying to play politics with one of you to go against the other cofounder, cut that investor out immediately and stop listening to them. Any investor who pushes for scalability over what you think is the best interest of the company is not aligned with you. High-quality investors will not push for this because they are patient and in it for the long game. If you are patient, you can make a very successful company, even if it is not that scalable. High-quality investors will bet on founders and are committed; only bad ones will push for this kind of shit. I'm going to avoid giving more generic startup advice here. Go read Paul Graham's essays. But remember that any investor's perspective will not be the perspective of you and your employees. Pivoting 5 times in 24 months is not a fun experience to work at: your employees will resign while your investors celebrate your "coming of age journey"--unless everyone signed up for that terrifying emotional rollercoaster from the start. They say that "hacker" is a dying identity. Co-opted by annoying VC-backed cybersecurity companies that culturally appropriate the identity, the term is getting more polluted and diluted by the day. Meanwhile, computers are getting more secure, and they are rewriting everything in Rust with pointers-as-capability machines and memory tagging. Is it over? I disagree. As long as the hacker *ethos* is alive, regardless of any particular scene, the identity will always exist. However, now is a crucible moment as a diaspora of hackers, young and old, venture out into the world. Calling all hackers: never forget who you are, who you will become, and the mark you leave. --[ 6 - Thanks Greetz (in no particular order): * ret2jazzy, Sirenfal, ajvpot, rose4096, Transfer Learning, samczsun, tjr, claire (aka sport), and psifertex. * perfect blue, Blue Water, DiceGang, Shellphish, and all CTF players. * NotJan, nspace, xenocidewiki, and the members of pinkchan and Secret Club. * Everyone at Zellic, past and present. Finally, a big thank you to the Phrack staff (shoutout to netspooky and richinseattle!) for making this all possible. --[ 7 - References [1] https://www.sec.gov/Archives/edgar/data/1559720/000119312520315318/ d81668d424b4.htm [2] https://www.sec.gov/Archives/edgar/data/1559720/000119312522115317/ d278253ddef14a.htm [3] https://moxie.org/stories/promise-defeat/ [4] https://twitter.com/nikitabier/status/1622477273294336000 --[ 8 - Appendix: Financial institution glossary for hackers (Not serious! For jokes... :-) - IB: Investment Bank. Basically collect fat fees to do up ("advise on") M&amp;amp;As and other transactions. Help match buyers and sellers for your private equity. They are like CYA for your deal. - PE: Private Equity. Basically buy not-overly-seriously ("poorly") run companies, fire the management, then run it "professionally" (i.e. make it generally shitty for customers and employees and community for the benefit of shareholders) - HF: Hedge Fund. Trade out pricing inefficiencies - MM: Market Maker. Basically the same thing - VC: Basically gamble on tokens (crypto or stocks) and back cool and/or wacky ideas that the rest of these people find too stinky to invest in - PnD: Pump and Dump. - TVL: Total Value Locked. Basically how much money is currently in a blockchain or smart contract system. - TPS: Transactions Per Second. A measure of how scalable or useful a blockchain or database is. An oft-abused metric hacked by vaporware shillers for hype and PnD purposes. - TAM: Total Addressable ~~Memory~~ Market. Basically how much money a given idea can make. - NFA: Not finanical advice. |=[ EOF ]=---------------------------------------------------------------=| &lt;/quote&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46518129</guid><pubDate>Tue, 06 Jan 2026 20:24:45 +0000</pubDate></item><item><title>Oral microbiome sequencing after taking probiotics</title><link>https://blog.booleanbiotech.com/oral-microbiome-biogaia</link><description>&lt;doc fingerprint="8a7c03af02b6652a"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently, a friend recommended BioGaia Prodentis to me. It is a DTC oral probiotic you can buy online that is supposedly good for oral health. I thought it would be interesting to do some sequencing to see what, if anything, it did to my oral microbiome.&lt;/p&gt;
    &lt;p&gt;BioGaia Prodentis is available online for $20 or less for a month's supply&lt;/p&gt;
    &lt;head rend="h1"&gt;BioGaia&lt;/head&gt;
    &lt;p&gt;BioGaia has a fascinating story. They are a Swedish company, founded over 30 years ago, that exclusively sells probiotics DTC. They have developed multiple strains of Limosilactobacillus reuteri, mainly for gut and oral health. They apparently sell well! Their market cap is around $1B—impressive for a consumer biotech.&lt;/p&gt;
    &lt;p&gt;Going in, I expected scant evidence for any real benefits to their probiotics, but the data (over 250 clinical studies) is much more complete than I expected.&lt;/p&gt;
    &lt;p&gt;Most notably, their gut probiotic, Protectis, seems to have a significant effect on preventing Necrotizing Enterocolitis (NEC) in premature babies. According to their website:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;5-10% of the smallest premature infants develop NEC, a potentially lethal disorder in which portions of the bowel undergo tissue death.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In March 2025, the FDA granted Breakthrough Therapy Designation to IBP-9414, an L. reuteri probiotic developed by BioGaia spinout IBT.&lt;/p&gt;
    &lt;p&gt;This is not specifically for the oral health product, but it's for sure more science than I expected to see going in.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prodentis&lt;/head&gt;
    &lt;p&gt;BioGaia Prodentis contains two strains of L. reuteri: DSM 17938 and ATCC PTA 5289. The claimed benefits include fresher breath, healthier gums, and outcompeting harmful bacteria.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sequencing with Plasmidsaurus&lt;/head&gt;
    &lt;p&gt;Many readers will be familiar with Plasmidsaurus. Founded in 2021, the team took a relatively simple idea: use massively multiplexed Oxford Nanopore (ONT) to offer complete plasmid sequencing with one day turnaround for $15, and scaled it. Plasmidsaurus quickly became part of biotech's core infrastructure, and spread like wildfire. It also inspired multiple copycats.&lt;/p&gt;
    &lt;p&gt;Compared to Illumina, ONT is faster and has much longer reads, but lower throughput and lower accuracy. This profile is a great fit to many sequencing problems like plasmid QC, where you only need megabases of sequences, but want an answer within 24 hours.&lt;/p&gt;
    &lt;p&gt;Over time, Plasmidsaurus has been adding services, including genome sequencing, RNA-Seq, and microbiome sequencing, all based on ONT sequencing.&lt;/p&gt;
    &lt;p&gt;Plasmidsaurus accepts many kinds of sample for microbiome sequencing&lt;/p&gt;
    &lt;p&gt;I used their 16S sequencing product, which costs $45 for ~5000 reads, plus $15 for DNA extraction. 16S sequencing is an efficient way to amplify and sequence a small amount of DNA (the ubiquitous 16S region) and be able to assign reads to specific species or even strains.&lt;/p&gt;
    &lt;p&gt;This experiment cost me $240 for four samples, and I got data back in around a week. It's very convenient that I no longer have to do my own sequencing. As a side note, you can pay more for more than 5000 reads, but unless you want information on very rare strains (&amp;lt;&amp;lt;1% frequency), this is a waste of money.&lt;/p&gt;
    &lt;p&gt;Sample collection is simple: take 100-250 µL of saliva and mix with 500 µL of Zymo DNA/RNA Shield (which I also had to buy for around $70.) You also need 2 mL screwtop tubes to ship in.&lt;/p&gt;
    &lt;p&gt;The reads are high quality for nanopore sequencing, with a median Q score of 23 (99%+ accuracy). This is more than sufficient accuracy for this experiment. The read length is very tightly distributed around 1500 nt (the length of a typical 16S region).&lt;/p&gt;
    &lt;p&gt;The results provided by Plasmidsaurus include taxonomy tables, per-read assignments, and some basic plots. I include a download of the results at the end of this article, as well as the FASTQ files.&lt;/p&gt;
    &lt;head rend="h1"&gt;The experiment&lt;/head&gt;
    &lt;p&gt;The main idea of the experiment was to see if any L. reuteri would colonize by the end of 30 days of probiotic use, and if so, whether it would persist beyond that. I collected four saliva samples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;Timing&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;Day -4&lt;/cell&gt;
        &lt;cell&gt;A few days before starting BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;Day -1&lt;/cell&gt;
        &lt;cell&gt;The day before I started BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;The last day of the 30 day course&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;Day 37&lt;/cell&gt;
        &lt;cell&gt;One week after completing the course&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Heatmap of the top 20 species. All species assignments were done by Plasmidsaurus&lt;/p&gt;
    &lt;head rend="h2"&gt;Did L. reuteri colonize?&lt;/head&gt;
    &lt;p&gt;There was no L. reuteri found in any of the samples. I did a manual analysis to check for any possible misassignments, but the closest read was only 91% identical to either L. reuteri strain.&lt;/p&gt;
    &lt;p&gt;The probiotic either (a) didn't colonize the oral cavity; (b) was present only transiently while actively taking the lozenges; (c) was below the detection threshold.&lt;/p&gt;
    &lt;p&gt;Probiotics are generally bad at colonizing, which is why you have to keep taking them. Still, I was surprised not to see a single L. reuteri read in there.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed?&lt;/head&gt;
    &lt;p&gt;Even though the probiotic itself didn't show up, the oral microbiome did change quite a lot.&lt;/p&gt;
    &lt;p&gt;The most striking change was a massive increase in S. salivarius. S. salivarius went from essentially absent to ~20% of my oral microbiome on the last day. However, this happened one week after I stopped taking the probiotic, so it's very unclear if it is related.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;S. mitis&lt;/cell&gt;
        &lt;cell role="head"&gt;S. salivarius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;2.0%&lt;/cell&gt;
        &lt;cell&gt;0.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;10.2%&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;1.0%&lt;/cell&gt;
        &lt;cell&gt;19.3%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We see S. mitis decreasing as S. salivarius increases, while the total Streptococcus fraction stayed roughly stable. It's possible one species replaced the other within the same ecological niche.&lt;/p&gt;
    &lt;p&gt;S. salivarius is itself a probiotic species. The strain BLIS K12 was isolated from a healthy New Zealand child and is sold commercially for oral health. It produces bacteriocins that kill Streptococcus pyogenes (strep throat bacteria).&lt;/p&gt;
    &lt;p&gt;At the same time, V. tobetsuensis increased in abundance from 2.1% to 5.7%. Veillonella bacteria can't eat sugar directly—they survive by consuming lactate that Streptococcus produces. The S. salivarius bloom is plausibly feeding them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are these changes real or intra-day variation?&lt;/head&gt;
    &lt;p&gt;There was a lot more variation in species than I expected, especially comparing the two baseline samples. In retrospect, I should have taken multiple samples on the same day, and mixed them to smooth it out.&lt;/p&gt;
    &lt;p&gt;However, there is some light evidence that the variation I see is not just intra-day variation. Specifically, there are several species that stay consistent in frequency across all samples: e.g., Neisseria subflava, Streptococcus viridans, Streptococcus oralis.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;L. reuteri didn't detectably colonize my mouth. Oral probiotics are surprisingly difficult to detect, even if you sample the same day as dosing.&lt;/item&gt;
      &lt;item&gt;S. salivarius increased massively in abundance, but this increase happened after I stopped taking BioGaia&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing can be used to assess oral health. None of the "red complex" bacteria (P. gingivalis, T. forsythia, T. denticola) associated with gum disease were found in any sample.&lt;/item&gt;
      &lt;item&gt;The oral microbiome is dynamic, with huge swings in species abundance over a timeframe of just weeks&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing is very easy and convenient these days thanks to Plasmidsaurus&lt;/item&gt;
      &lt;item&gt;Prodentis tastes good, may help with oral health, and I'd consider taking it again&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46518804</guid><pubDate>Tue, 06 Jan 2026 21:10:47 +0000</pubDate></item><item><title>Comparing AI agents to cybersecurity professionals in real-world pen testing</title><link>https://arxiv.org/abs/2512.09882</link><description>&lt;doc fingerprint="919c362341ffe08f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 10 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46518996</guid><pubDate>Tue, 06 Jan 2026 21:23:07 +0000</pubDate></item></channel></rss>