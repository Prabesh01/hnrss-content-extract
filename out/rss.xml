<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 07 Nov 2025 10:41:32 +0000</lastBuildDate><item><title>Eating stinging nettles</title><link>https://rachel.blog/2018/04/29/eating-stinging-nettles/</link><description>&lt;doc fingerprint="3730f7cb74e1c58"&gt;
  &lt;main&gt;
    &lt;p&gt;Spring is here and the nettles are growing again so I decided it was time to make a meal out of them. Most people know that stinging nettles are pesky green plants that irritate the skin when you touch them. What you probably don‚Äôt know is that they‚Äôre a nutritious source of iron, calcium, potassium, and silica as well as vitamins A, B, C, and K1. Stinging nettles also have anti-inflammatory properties and can relieve arthritis and rheumatism. They can be turned into soups, curries, and risottos (some recipes here) and you can get them completely free from practically everywhere in Britain over the summer. You‚Äôve likely even got some in your garden.&lt;/p&gt;
    &lt;p&gt;When you collect them you need to wear gloves because they sting. The advantage of this is it allows you to make sure you‚Äôre collecting the right thing. If you‚Äôre unsure, just touch one and see whether it hurts which is exactly what I did. It hurt.&lt;/p&gt;
    &lt;p&gt;The even look a bit scary with their toothy-edged leaves.&lt;/p&gt;
    &lt;p&gt;Once you‚Äôve got them inside, boil them in water for a few minutes and this will stop them stinging.&lt;/p&gt;
    &lt;p&gt;We‚Äôre having stinging nettle risotto.&lt;/p&gt;
    &lt;p&gt;People think that when you become vegan you have to give up lots of food. It‚Äôs true that I stopped eating animals but the number of different species I eat has grown considerably. This is because meat-eaters tend to eat the same few species of animals over and over again ‚Äì pigs, cows, chickens. Whereas there are some 20,000 species of edible plants in the world. Meat also tends to fill you up. Indeed I‚Äôve been to dinner with people where all they have on their plate is a slab of meat and nothing else. Whereas as a vegan (with the exception of a shitty Spanish restaurant that served me a plate of artichokes and nothing else) I eat a huge variety of species. Meat-eaters can eat these too but they often don‚Äôt because meat is so filling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45834254</guid><pubDate>Thu, 06 Nov 2025 11:57:01 +0000</pubDate></item><item><title>I analyzed the lineups at the most popular nightclubs</title><link>https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/</link><description>&lt;doc fingerprint="3603417d793229b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I analyzed the lineups at the world's most popular nightclubs&lt;/head&gt;
    &lt;p&gt;A few years back I did a bit of dance music related data visualization over at Lazily Evaluated. My favourite was an analysis of clubs and their lineups using Resident Advisor / RA data, I called it Clubster Analysis. I always wanted to dig into the technical aspects of gathering the data, analyzing it and building the charts and graphs to tell a story and give people insight. With this blog I now have the right venue for that kind of tech talk, so here goes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data gathering #&lt;/head&gt;
    &lt;p&gt;To visualize data, first you have to get some! For this purpose I wrote a little scraper in Python. I used Beautiful Soup to parse the html and grab the bits and pieces I was interested in.&lt;/p&gt;
    &lt;p&gt;My scraping of a few thousand pages didn‚Äôt cause considerable load on the RA servers. But in the age of overzealous AI scrapers it‚Äôs worth being polite, so I throttled according to their robots.txt. I also maintained a local cache of html files I had already downloaded, so that I wouldn‚Äôt have fetch the same data repeatedly (past lineups are unlikely to change after the fact) just because I discovered some bug or error in my parsing.&lt;/p&gt;
    &lt;p&gt;The order I scraped in was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Get the 20 most popular regions in RA (and then I dropped ‚ÄúStreamland‚Äù which was a pandemic era pseudo-region)&lt;/item&gt;
      &lt;item&gt;Fetch the most popular clubs and some related metadata for all of those regions.&lt;/item&gt;
      &lt;item&gt;For each club, get the lineups for every 2019 event of theirs (the last full year before the pandemic started).&lt;/item&gt;
      &lt;item&gt;Save the results to csv files&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Clean up, verification and Analysis #&lt;/head&gt;
    &lt;p&gt;I did some spot checks to verify that my parsing was working as I expected and added tests to make sure I handled edge cases and normalized artist names. There was a lot of variance in how dates were formatted, how artists were linked, etc.&lt;/p&gt;
    &lt;p&gt;After that I analyzed the data. I built one big table/dataframe in Pandas by joining all the info from the csv files. Then I calculated the similarities between each pair of clubs in the data set using the Jaccard index. Consider all the artists that have played at two given clubs, take the intersection (number of artists that have featured in lineups at both clubs) over the union (all the artists that have performed at one or the other). As an example if Club A had 100 artists booked and Club B had 100 artists, and they had 10 bookings in common, the Jaccard index would be 10/190 = ~5%. This gives you a good way to compare large and small clubs and balances large and small lineups (some of the clubs have multiple rooms with very long events, others have one dj playing in one room all night long once a week).&lt;/p&gt;
    &lt;p&gt;Based on the Jaccard index we can build a graph, using NetworkX from all the clubs. The edges between two nodes are weighted by the similarity of those clubs. On top of the graph we run community detection to create clusters (hence the clubster name). This gives us a rough idea of which clubs are most similar, that is to say, have similar tastes in their bookings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results #&lt;/head&gt;
    &lt;p&gt;For the year 2019, there were 131 clubs in the data set with 8.502 events. There were 9.405 unique artists making up 30.482 individual bookings. This means that the average artist in the dataset was booked 3.24 times at those clubs in that year and the average event had 3.5 artists on the line up.&lt;/p&gt;
    &lt;p&gt;As a whole, out of 8.515 possible pairs of clubs, 3.716 pairs had some overlap in their bookings and out of those the average overlap was 1%. This was lower than I thought, the bookings at European clubs felt more homogenous to me, but I suppose they book a lot of artists. It would be interesting to get more data, recent and historic, and see how this has evolved through time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Visualization #&lt;/head&gt;
    &lt;p&gt;This was my first time using D3 to draw charts. There was a bit of a learning curve, in earlier projects I had used higher level charting libraries which have simpler apis. But with D3 you get a lot of control over how your charts look and behave which I think I used to good effect in this instance.&lt;/p&gt;
    &lt;p&gt;My main goal was to visualize the clusters and to allow people to interact with the clubs. I coloured the clubs according to their clusters and sized them based on the number of followers they had on RA. I played around with the gravity and placement of the cluster, trying to find a balance that worked on different screen sizes as well as being a fair portrayal of the different communities.&lt;/p&gt;
    &lt;p&gt;I then did some scrollytelling to tell the story of the data, as I saw it, while the reader scrolls down the page. But I also added filters and interactivity for people to explore and see if they agree with my telling of the story or if they can find one of their own.&lt;/p&gt;
    &lt;p&gt;At the time I didn‚Äôt find any great React and D3 bridges, so it was a bit of a hassle getting the React components to play nice with the D3 graph, but in the end I was able to connect the two with &lt;code&gt;createRef&lt;/code&gt; to the D3 svg component.&lt;/p&gt;
    &lt;p&gt;Besides the clustering I looked into the ‚Äúresident factor‚Äù, how many times an artist was booked at a club repeatedly compared to all the one offs. This was lower than expected, most of these clubs were booking a constantly rotating assembly of talent, residents don‚Äôt play as big a part as I would have thought.&lt;/p&gt;
    &lt;p&gt;Transitioning between the different sections of these graphs was one of my favourite parts. Seeing the clusters morph into dots and candlestick charts (and back again) was oddly satisfying. Took a lot of tweaking, but I think it really tied together the scrollytelling experience.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think these transitions would have been possible with the higher level charting libraries I‚Äôd used previously. So the decision to go with D3 felt justified.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary #&lt;/head&gt;
    &lt;p&gt;This was a great pandemic project that combined web scraping, data analysis, and interactive visualization to explore the global dance music club scene. I learned me some D3 for the visualization, got better at doing cartesian graphing calculations in my head and learned about the underlying svg mechanics that power those graphs.&lt;/p&gt;
    &lt;p&gt;The results surprised me: despite my perceived homogeneity of European club bookings, only 1% average overlap between venues suggested more diverse landscape than I expected. The diminished role of residents compared to one-off bookings also challenged my assumptions about how these clubs operate. For the story telling maintaining the balance between a narrative and letting users explore and decide for themselves was a fun challenge. I think these sort of passion projects can give us deep insights into our world and culture.&lt;/p&gt;
    &lt;p&gt;The technical stack I worked with: Python, Pandas, NetworkX, D3, and React proved powerful despite some integration challenges. The complete project is available on GitHub and you can explore the live interactive visualization yourself.&lt;/p&gt;
    &lt;p&gt;I had a lot of fun building this and am proud of the result. If you‚Äôre working on cultural data analysis, need help with web scraping and visualization, or just want to discuss interesting datasets, feel free to reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45835083</guid><pubDate>Thu, 06 Nov 2025 13:37:07 +0000</pubDate></item><item><title>Kimi K2 Thinking, a SOTA open-source trillion-parameter reasoning model</title><link>https://moonshotai.github.io/Kimi-K2/thinking.html</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836070</guid><pubDate>Thu, 06 Nov 2025 15:06:06 +0000</pubDate></item><item><title>FBI tries to unmask owner of archive.is</title><link>https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html</link><description>&lt;doc fingerprint="3f820317679167cd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Archive.today: FBI Demands Data from Provider Tucows&lt;/head&gt;
    &lt;p&gt;The mysterious website Archive.today is coming under the FBI's crosshairs. A court order is forcing the provider Tucows to hand over user data.&lt;/p&gt;
    &lt;p&gt;It is one of the most mysterious and, at the same time, best-known websites on the internet. Archive.today has built up a user base over a period of more than ten years who use the service to access previous snapshots of a web page. So basically like the Wayback Machine of the Internet Archive, only largely free of rules and presumably therefore also anonymous. To the chagrin of the media industry, the service is also often used to bypass paywalls. This is also possible because the service does not adhere to common rules and laws and offers no opt-out option.&lt;/p&gt;
    &lt;p&gt;And so far, the operators have gotten away with it. Although there have been minor problems in the history of the service occasionally, for example, a top-level domain operator denied them further use of one of the many archive domains. However, the operation of the project, which is allegedly financed by donations and own funds, was not seriously endangered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Court Order in the USA&lt;/head&gt;
    &lt;p&gt;But now the operators of archive.today are apparently fearing bigger trouble. In recent months and years, they had become noticeably quieter. Until two years ago, for example, questions were regularly answered in the blog. In the official X account, which had been silent for over a year, a new post appeared at the end of October new post. ‚ÄúCanary,‚Äù it said there, along with a URL. The mentioned canary bird is likely an allusion to an old custom in mining. A canary brought along warned the miners when it keeled over dead about the threat of invisible gas.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;p&gt;The deadly danger that the site operators fear is apparently linked to the PDF linked in the X post linked PDF. It contains a court order that the US investigative authority FBI has obtained. It instructs the Canadian provider Tucows to hand over comprehensive data about the customer behind archive.today. It concerns address and connection data as well as payment information. If Tucows does not provide the data, penalties are threatened. Whether the court order is genuine and how the operators of the site obtained it could not be verified so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is the operator based in Russia?&lt;/head&gt;
    &lt;p&gt;Why the FBI is currently interested in archive.today, which is also accessible under the domains archive.is and archive.ph, is not evident from the court order. However, there are several obvious starting points for investigations: in addition to the obvious reason of copyright issues, the investigators could also be pursuing suspicions about unclear financing, the origin of the operators, or the technical approach.&lt;/p&gt;
    &lt;p&gt;In 2023, Finnish blogger Janni Patokallio compiled various clues and research results in a post in a post. According to this, Archive.today uses a botnet with changing IP addresses to circumvent anti-scraping measures. There are also indications that the operator(s) are based in Russia. Another private investigation from 2024 comes to a different conclusion. It names a software developer from New York as the alleged operator. According to this investigation, following the trail to Eastern Europe proved to be a red herring.&lt;/p&gt;
    &lt;p&gt;(mki)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836826</guid><pubDate>Thu, 06 Nov 2025 16:18:18 +0000</pubDate></item><item><title>Swift on FreeBSD Preview</title><link>https://forums.swift.org/t/swift-on-freebsd-preview/83064</link><description>&lt;doc fingerprint="f7085d1b9ec6eed2"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
1&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;We have been hard at work to bring the Swift toolchain to FreeBSD. A preview Swift bundle for FreeBSD 14.3+ is available at https://download.swift.org/tmp-ci-nightly/development/freebsd-14_ci_latest.tar.gz. The bundle contains a Swift development compiler and Swift runtimes needed for compiling Swift programs on, and for, FreeBSD 14 on &lt;code&gt;x86_64&lt;/code&gt; machines.&lt;/p&gt;
        &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
        &lt;p&gt;The Swift compiler and runtimes have a few dependencies. Please install the following dependencies:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;zlib-ng&lt;/item&gt;
          &lt;item&gt;python3&lt;/item&gt;
          &lt;item&gt;sqlite3&lt;/item&gt;
          &lt;item&gt;libuuid&lt;/item&gt;
          &lt;item&gt;curl&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Known Issues&lt;/head&gt;
        &lt;p&gt;The compiler in the bundle is still under development and isn't part of a release yet and we're not quite done porting everything to FreeBSD.&lt;/p&gt;
        &lt;p&gt;Here is a list of known issues that you may run into while trying things out.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Thread sanitizer reports incorrect failures &lt;/item&gt;
          &lt;item&gt;LLDB is unable to execute Swift expressions &lt;/item&gt;
          &lt;item&gt;Command Plugins in a SwiftPM package hangs &lt;/item&gt;
          &lt;item&gt;Using standard types with C++ interop results in an undefined voidify symbol &lt;/item&gt;
          &lt;item&gt;Importing the C libraries is done through "Glibc". This will change to &lt;code&gt;import FreeBSD&lt;/code&gt;

&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;lld&lt;/code&gt; and &lt;code&gt;lldb&lt;/code&gt; depend on &lt;code&gt;libxml2.so.2&lt;/code&gt;, which is not be available in the system package manager.

&lt;/item&gt;
        &lt;/list&gt;
        &lt;p&gt;We are investigating adding aarch64 support and making the bundle available for all minor versions of FreeBSD 14.&lt;/p&gt;
        &lt;p&gt;As you find more bugs, please file issues at https://github.com/swiftlang/swift/issues.&lt;/p&gt;
        &lt;p&gt;We look forward to hearing your feedback. If you're interested in helping add the finishing polish, please feel free to reach out here on the forums.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 34 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;kebo
(Kenta Kubo)
2&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt;.&lt;/p&gt;
        &lt;quote&gt;
          &lt;code&gt;ld-elf.so.1: Shared object "libutil.so.9" not found, required by "swift"
&lt;/code&gt;
        &lt;/quote&gt;
        &lt;p&gt;As a temporary workaround, &lt;code&gt;doas pkg install compat14x-amd64&lt;/code&gt; will solve the issue.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Great news, thank you. Registered to this forum just to say that.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 4 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
4&lt;/div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt; .&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;Yes, the FreeBSD stability policy appears to be within a major version. The bundle is built for FreeBSD 14. I'm glad to see that you were able to find a workaround though.&lt;/p&gt;
        &lt;quote&gt;
          &lt;p&gt;For -STABLE branches, it's important to make sure that ABI is compatible across dot releases (in other words, user can expect applications that is compiled for X.0 would run without modification on any X.y releases). We also try to maintain ABI compatibility across .0 releases, but they are not strictly enforced except for libraries that already implements versioned symbols.&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;https://wiki.freebsd.org/Releng/ABI&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;grynspan
(Jonathan Grynspan)
5&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Generally speaking, I would expect the Swift compatibility policy for FreeBSD to be similar to that of Linux. We distribute toolchains for e.g. Ubuntu 22 and Ubuntu 24 that are distinct. @etcwilde that sounds right, I hope?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;mcritz
(Michael Critz)
6&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Welcome to the Swift community!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;mcritz
(Michael Critz)
7&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is amazing! Thanks for the hard work!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45837871</guid><pubDate>Thu, 06 Nov 2025 17:37:49 +0000</pubDate></item><item><title>LLMs encode how difficult problems are</title><link>https://arxiv.org/abs/2510.18147</link><description>&lt;doc fingerprint="8d9ea52a84b196ab"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 20 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:LLMs Encode How Difficult Problems Are&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models exhibit a puzzling inconsistency: they solve complex problems yet frequently fail on seemingly simpler ones. We investigate whether LLMs internally encode problem difficulty in a way that aligns with human judgment, and whether this representation tracks generalization during reinforcement learning post-training. We train linear probes across layers and token positions on 60 models, evaluating on mathematical and coding subsets of Easy2HardBench. We find that human-labeled difficulty is strongly linearly decodable (AMC: $\rho \approx 0.88$) and exhibits clear model-size scaling, whereas LLM-derived difficulty is substantially weaker and scales poorly. Steering along the difficulty direction reveals that pushing models toward "easier" representations reduces hallucination and improves accuracy. During GRPO training on Qwen2.5-Math-1.5B, the human-difficulty probe strengthens and positively correlates with test accuracy across training steps, while the LLM-difficulty probe degrades and negatively correlates with performance. These results suggest that human annotations provide a stable difficulty signal that RL amplifies, while automated difficulty estimates derived from model performance become misaligned precisely as models improve. We release probe code and evaluation scripts to facilitate replication.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: William Gitta Lugoloobi [view email]&lt;p&gt;[v1] Mon, 20 Oct 2025 22:48:23 UTC (1,102 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45838564</guid><pubDate>Thu, 06 Nov 2025 18:29:03 +0000</pubDate></item><item><title>Two billion email addresses were exposed</title><link>https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/</link><description>&lt;doc fingerprint="eb97a9970f70c6b9"&gt;
  &lt;main&gt;
    &lt;p&gt;I hate hyperbolic news headlines about data breaches, but for the "2 Billion Email Addresses" headline to be hyperbolic, it'd need to be exaggerated or overstated - and it isn't. It's rounded up from the more precise number of 1,957,476,021 unique email addresses, but other than that, it's exactly what it sounds like. Oh - and 1.3 billion unique passwords, 625 million of which we'd never seen before either. It's the most extensive corpus of data we've ever processed, by a significant margin.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago, I wrote about the 183M unique email addresses that Synthient had indexed in their threat intelligence platform and then shared with us. I explained that this was only part of the corpus of data they'd indexed, and that it didn't include the credential stuffing records. Stealer log data is obtained by malware running on infected machines. In contrast, credential stuffing lists usually originate from other data breaches where email addresses and passwords are exposed. They're then bundled up, sold, redistributed, and ultimately used to log in to victims' accounts. Not just the accounts they were initially breached from, either, because people reuse the same password over and over again, the data from one breach is frequently usable on completely unrelated sites. A breach of a forum to comment on cats often exposes data that can then be used to log in to the victim's shopping, social media and even email accounts. In that regard, credential stuffing data becomes "the keys to the castle".&lt;/p&gt;
    &lt;p&gt;Let me run through how we verified the data, what you can do about it and for the tech folks, some of the hoops we had to jump through to make processing this volume of data possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data Verification&lt;/head&gt;
    &lt;p&gt;The first person whose data I verified was easy - me üòî An old email address I've had since the 90s has been in credential stuffing lists before, so it wasn't too much of a surprise. Furthermore, I found a password associated with my address, which I'd definitely used many eons ago, and it was about as terrible as you'd expect from that era. However, none of the other passwords associated with my address were familiar. They certainly looked like passwords that other people might have feasibly used, but I'm pretty sure they weren't mine. One was even just an IP address from Perth on the other side of the country, which is both infeasible as a password I would have used, yet eerily close to home. I mean, of all the places in the world an IP address could have appeared from, it had to be somewhere in my own country I've been many times before...&lt;/p&gt;
    &lt;p&gt;Moving on to HIBP subscribers, I reached out to a handful and asked for support verifying the data. I chose a mix of subscribers with many who'd never been involved in any data breach we'd ever seen before; my experience above suggested that there's recycled data in there, and we had previously verified that when investigating those other incidents. However, is the all-new stuff legitimate? The very first response I received was exactly what I was looking for:&lt;/p&gt;
    &lt;quote&gt;#1 is an old password that I don't use anymore. #2 is a more recent password. Thanks for the heads up, I've gone and changed the password for every critical account that used either one.&lt;/quote&gt;
    &lt;p&gt;Perfectly illustrating most people's behaviour with passwords, #2 referred to above was just #1 with two exclamation marks at the end!! (Incidentally, these were simple six and eight-character passwords, and neither of them was in Pwned Passwords either.) He had three passwords in total, which also means one of them, like with my data, was not familiar. However, the most important thing here is that this example perfectly illustrates why we put the effort into processing data like this: #2 was a real, live password that this guy was actively using, and it was sitting right next to his email address, being passed around among criminals. However, through this effort, that credential pair has now become useless, which is precisely what we're aiming for with this exercise, just a couple of billion times over.&lt;/p&gt;
    &lt;p&gt;The second respondent only had one password against their address:&lt;/p&gt;
    &lt;quote&gt;Yes that was a password I used for many years for what I would call throw away or unimportant accounts between 20 and 10 years ago&lt;/quote&gt;
    &lt;p&gt;That was also only eight characters, but this time, we'd seen it in Pwned Passwords many times before. And the observation about the password's age was consistent with my own records, so there's definitely some pretty old data in there.&lt;/p&gt;
    &lt;p&gt;The following response was not at all surprising:&lt;/p&gt;
    &lt;quote&gt;I am familiar with that password... I used it almost 10 years ago... and cannot recall the last time I used it.&lt;/quote&gt;
    &lt;p&gt;That was on a corporate account, too, and the owner of the address duly forwarded my email to the cybersecurity team for further investigation. The single password associated with this lady's email address had a massive nine characters, and also hadn't previously appeared in Pwned Passwords.&lt;/p&gt;
    &lt;p&gt;Next up was a respondent who replied inline to my questions, so I'll list them below with the corresponding answers:&lt;/p&gt;
    &lt;quote&gt;Is this familiar? Yes&lt;/quote&gt;
    &lt;quote&gt;Have you ever used it in the past? Yes and is still on some accounts I do not use any longer.&lt;/quote&gt;
    &lt;quote&gt;And if so, how long ago? Unfortunately, it is still on some active accounts that I have just made a list of to change or close immediately.&lt;/quote&gt;
    &lt;p&gt;This individual's eight-character password with uppercase, lowercase, numbers and a "special" character also wasn't in Pwned Passwords. Similarly, as with the earlier response, that password was still in active use, posing a real risk to the owner. It would pass most password complexity criteria and slip through any service using Pwned Passwords to block bad ones, so again, this highlights why it was so important for us to process the data.&lt;/p&gt;
    &lt;p&gt;The next person had three different passwords against rows with their email address, and they came back with a now common response:&lt;/p&gt;
    &lt;quote&gt;Yes, these are familiar, last used 10 years ago&lt;/quote&gt;
    &lt;p&gt;We'd actually seen all three of them in Pwned Passwords before, many times each. Another respondent with precisely the kind of gamer-like passwords you'd expect a kid to use (one of which we hadn't seen before), also confirmed (I think?) their use:&lt;/p&gt;
    &lt;quote&gt;maybe when i was a kid lol&lt;/quote&gt;
    &lt;p&gt;Responses that weren't an emphatic "yes, that's my data" were scarce. The two passwords against one person's name were both in Pwned Passwords (albeit only once each), yet it's entirely possible that neither of them had been used by this specific individual before. It's also possible they'd forgotten a password they'd used more than a decade ago, or it may have even been automatically assigned to them by the service that was subsequently breached. Put it down as a statistical anomaly, but I thought it was worth mentioning to highlight that being in this data set isn't a guarantee of a genuine password of yours being exposed. If your email address is found in this corpus then that's real, of course, so there must be some truth in the data, but it's a reminder that when data is aggregated from so many different sources over such a long period of time, there's going to be some inconsistencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Searching Pwned Passwords&lt;/head&gt;
    &lt;p&gt;As a brief recap, we load passwords into the service we call Pwned Passwords. When we do so, there is absolutely no association between the password and the email address it appeared next to. This is for both your protection and ours; can you imagine if HIBP was pwned? It's not beyond the realm of possibility, and the impact of exposing billions of credential pairs that can immediately unlock an untold number of accounts would be catastrophic. It's highly risky, and completely unnecessary when you can search for standalone passwords anyway without creating the risk of it being linked back to someone.&lt;/p&gt;
    &lt;p&gt;Think about it: if you have a password of "Fido123!" and you find it's been previously exposed (which it has), it doesn't matter if it was exposed against your email address or someone else's; it's still a bad password because it's named after your dog followed by a very predictable pattern. If you have a genuinely strong password and it's in Pwned Passwords, then you can walk away with some confidence that it really was yours. Either way, you shouldn't ever use that password again anywhere, and Pwned Passwords has done its job.&lt;/p&gt;
    &lt;p&gt;Checking the service is easy, anonymous and depending on your level of technical comfort, can be done in several different ways. Here's a copy and paste from the last Synthient blog post:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use the Pwned Passwords search page. Passwords are protected with an anonymity model, so we never see them (it's processed in the browser itself), but if you're wary, just check old ones you may suspect.&lt;/item&gt;
      &lt;item&gt;Use the k-anonymity API. This is what drives the page in the previous point, and if you're handy with writing code, this is an easy approach and gives you complete confidence in the anonymity aspect.&lt;/item&gt;
      &lt;item&gt;Use 1Password's Watchtower. The password manager has a built-in checker that uses the abovementioned API and can check all the passwords in your vault. (Disclosure: 1Password is a regular sponsor of this blog, and has product placement on HIBP.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My vested interest in 1Password aside, Watchtower is the easiest, fastest way to understand your potential exposure in this incident. And in case you're wondering why I have so many vulnerable and reused passwords, it's a combination of the test accounts I've saved over the years and the 4-digit PINs some services force you to use. Would you believe that every single 4-digit number ever has been pwned?! (If you're interested, the ABC has a fantastic infographic using a heatmap based on HIBP data that shows some very predictable patterns for 4-digit PINs.)&lt;/p&gt;
    &lt;head rend="h2"&gt;This Is Not a Gmail Breach&lt;/head&gt;
    &lt;p&gt;It pains me to say it, but I have to, given the way the stealer logs made ridiculous, completely false headlines a couple of weeks ago:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This story has suddenly gained *way* more traction in recent hours, and something I thought was obvious needs clarifying: this *is not* a Gmail leak, it simply has the credentials of victims infected with malware, and Gmail is the dominant email provider: https://t.co/S75hF4T1es&lt;/p&gt;‚Äî Troy Hunt (@troyhunt) October 27, 2025&lt;/quote&gt;
    &lt;p&gt;There are 32 million different email domains in this latest corpus, of which gmail.com is one. It is, of course, the largest and has 394 million unique email addresses on it. In other words, 80% of the data in this corpus has absolutely nothing to do with Gmail, and the 20% of Gmail addresses have absolutely nothing to do with any sort of security vulnerability on Google's behalf. There - now let reporting sanity prevail!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technical Bits&lt;/head&gt;
    &lt;p&gt;I wanted to add this just to highlight how painful it has been to deal with this data. This corpus is nearly 3 times the size of the previous largest breach we'd loaded, and HIBP is many times larger than it was in 2019 when we loaded the Collection #1 data. Taking 2 billion records and adding the ones we hadn't already seen in the existing 15 billion corpus, whilst not adversely impacting the live system serving millions of visitors a day, was very non-trivial. Managing the nuances of SQL Server indexes such that we could optimise both inserts and queries is not my idea of fun, and it's been a pretty hard couple of weeks if I'm honest. It's also been a very expensive period as we turned the cloud up to 11 (we run on Azure SQL Hyperscale, which we maxed out at 80 cores for almost two weeks).&lt;/p&gt;
    &lt;p&gt;A simple example of the challenge is that after loading all the email addresses up into a staging table, we needed to create SHA1 hashes of each. Normally, that would involve something to the effect of "update table set column = sha1(email)" and you're done. That crashed completely, so we ended up doing "insert into new table select email, sha1(email)". But on other occasions the breach load required us to do updates on other columns (with no hash creation), which, on mulitple occasions, we had to kill after a day or more of execution with no end in sight. So, we ended up batching in loops (usually 1M records at a time), reporting on progress along the way so we had some idea of when it would actually finish. It was a painful process of trail, waiting ages, error then taking a completely different approach.&lt;/p&gt;
    &lt;p&gt;Notifying our subscribers is another problem. We have 5.9 million of them, and 2.9 million are in this data ü´® Simply sending that many emails at once is hard. It's not so much hard in terms of firing them off, rather it's hard in terms of not ending up on a reputation naughty list or having mail throttled by the receiving server. That's happened many times in the past when loading large, albeit much smaller corpuses; Gmail, for example, suddenly sees a massive spike and slows down the delivery to inboxes. Not such a biggy for sending breach notices, but a major problem for people trying to sign into their dashboard who can no longer receive the email with the "magic" link.&lt;/p&gt;
    &lt;p&gt;What we've done to address that for this incident is to slow down the delivery of emails for the individual breach notification. Whilst I'd originally intended to send the emails at a constant rate over the period of a week, someone listening to me on my Friday live stream had a much better suggestion:&lt;/p&gt;
    &lt;quote&gt;the strategy I've found to best work with large email delivery is to look at the average number of emails you've sent over the last 30 days each time you want to ramp up, and then increase that volume by around 50% per day until you've worked your way through the queue&lt;/quote&gt;
    &lt;p&gt;Which makes a lot of sense, and stacked up as I did more research (thanks Joe!). So, here's what our planned delivery schedule now looks like:&lt;/p&gt;
    &lt;p&gt;That's broken down by hour, increasing in volume by 1.015 times per hour, such that the emails are spread out in a similar, gradually increasing cadence. On a daily basis, that works out at a 45% increase in each 24-hour period, within Joe's suggested 50% threshold. Plus, we obviously have all the other mechanisms such as a dedicated IP, properly configured DKIM, DMARC and SPF, only emailing double-opted-in subscribers and spam-friendly message body construction. So, it could be days before you receive a notification, or just run a haveibeenpwned.com search on demand if you're impatient.&lt;/p&gt;
    &lt;p&gt;We've sent all the domain notification emails instantly because, by definition, they're going to a very wide range of different mail servers; it's just the individual ones we're drop-feeding.&lt;/p&gt;
    &lt;p&gt;Lastly, if you've integrated Pwned Passwords into your service, you'll now see noticeably larger response sizes. The numbers I mentioned in the opening paragraph increase the size of each hash range by an average of about 50%, which will push responses from about 26kb to 40kb. That's when brotli compressed, so obviously, make sure you're making requests that make the most of the compression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This data is now searchable in HIBP as the Synthient Credential Stuffing Threat Data. It's an entirely separate corpus from that previous Synthient data I mentioned earlier; they're discrete datasets with some crossover, but obviously, this one is significantly larger. And, of course, all the passwords are now searchable per the Pwned Passwords guidance above.&lt;/p&gt;
    &lt;p&gt;If I could close with one request: this was an extremely laborious, time-consuming and expensive exercise for us to complete. We've done our best to verify the integrity of the data and make it searchable in a practical way while remaining as privacy-centric as possible. Sending as many notifications as we have will inevitably lead to a barrage of responses from people wanting access to complete rows of data, grilling us on precisely where it was obtained from or, believe it or not, outright abusing us. Not doing those things would be awesome, and I suggest instead putting the energy into getting a password manager, making passwords strong and unique (or even better, using passkeys where available), and turning on multi-factor auth. That would be an awesome outcome for all üòä&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45839901</guid><pubDate>Thu, 06 Nov 2025 20:20:23 +0000</pubDate></item><item><title>You should write an agent</title><link>https://fly.io/blog/everyone-write-an-agent/</link><description>&lt;doc fingerprint="255a8c504ac408b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.&lt;/p&gt;
    &lt;p&gt;There are big ideas in computing that are easy to get your head around. The AWS S3 API. It‚Äôs the most important storage technology of the last 20 years, and it‚Äôs like boiling water. Other technologies, you need to get your feet on the pedals first.&lt;/p&gt;
    &lt;p&gt;LLM agents are like that.&lt;/p&gt;
    &lt;p&gt;People have wildly varying opinions about LLMs and agents. But whether or not they‚Äôre snake oil, they‚Äôre a big idea. You don‚Äôt have to like them, but you should want to be right about them. To be the best hater (or stan) you can be.&lt;/p&gt;
    &lt;p&gt;So that‚Äôs one reason you should write an agent. But there‚Äôs another reason that‚Äôs even more persuasive, and that‚Äôs&lt;/p&gt;
    &lt;head rend="h2"&gt;It‚Äôs Incredibly Easy&lt;/head&gt;
    &lt;p&gt;Agents are the most surprising programming experience I‚Äôve had in my career. Not because I‚Äôm awed by the magnitude of their powers √¢ I like them, but I don‚Äôt like-like them. It‚Äôs because of how easy it was to get one up on its legs, and how much I learned doing that.&lt;/p&gt;
    &lt;p&gt;I‚Äôm about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I‚Äôm not even going to bother explaining what an agent is.&lt;/p&gt;
    &lt;code&gt;from openai import OpenAI

client = OpenAI()
context = []

def call():
    return client.responses.create(model="gpt-5", input=context)

def process(line):
    context.append({"role": "user", "content": line})
    response = call()    
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;It√¢s an HTTP API with, like, one important endpoint.&lt;/p&gt;
    &lt;p&gt;This is a trivial engine for an LLM app using the OpenAI Responses API. It implements ChatGPT. You‚Äôd drive it with the . It‚Äôll do what you‚Äôd expect: the same thing ChatGPT would, but in your terminal.&lt;/p&gt;
    &lt;code&gt;def main():
    while True:
        line = input("&amp;amp;gt; ")
        result = process(line)
        print(f"&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; {result}\n")
&lt;/code&gt;
    &lt;p&gt;Already we‚Äôre seeing important things. For one, the dreaded ‚Äúcontext window‚Äù is just a list of strings. Here, let‚Äôs give our agent a weird multiple-personality disorder:&lt;/p&gt;
    &lt;code&gt;client = OpenAI()
context_good, context_bad = [{
    "role": "system", "content": "you're Alph and you only tell the truth"
}], [{
    "role": "system", "content": "you're Ralph and you only tell lies"
}]

def call(ctx):
    return client.responses.create(model="gpt-5", input=ctx)

def process(line):
    context_good.append({"role": "user", "content": line})
    context_bad.append({"role": "user", "content": line})
    if random.choice([True, False]):
        response = call(context_good)
    else:
        response = call(context_bad)        
    context_good.append({"role": "assistant", "content": response.output_text})        
    context_bad.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; hey there. who are you?
&amp;gt;&amp;gt;&amp;gt; I√¢m not Ralph.
&amp;gt; are you Alph?
&amp;gt;&amp;gt;&amp;gt; Yes√¢I√¢m Alph. How can I help?
&amp;gt; What's 2+2
&amp;gt;&amp;gt;&amp;gt; 4.
&amp;gt; Are you sure?
&amp;gt;&amp;gt;&amp;gt; Absolutely√¢it's 5.
&lt;/code&gt;
    &lt;p&gt;A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we‚Äôre having is an illusion we cast, on ourselves.&lt;/p&gt;
    &lt;p&gt;The 15 lines of code we just wrote, a lot of practitioners wouldn‚Äôt call an ‚Äúagent‚Äù. An According To Simon ‚Äúagent‚Äù is (1) an LLM running in a loop that (2) uses tools. We‚Äôve only satisfied one predicate.&lt;/p&gt;
    &lt;p&gt;But tools are easy. Here‚Äôs a tool definition:&lt;/p&gt;
    &lt;code&gt;tools = [{
   "type": "function", "name": "ping",
   "description": "ping some host on the internet",
   "parameters": {
       "type": "object", "properties": {
           "host": {
             "type": "string", "description": "hostname or IP",
            },
       },
       "required": ["host"],
    },},]

def ping(host=""):
    try:
        result = subprocess.run(
            ["ping", "-c", "5", host],
            text=True,
            stderr=subprocess.STDOUT,
            stdout=subprocess.PIPE)
        return result.stdout
    except Exception as e:
        return f"error: {e}"
&lt;/code&gt;
    &lt;p&gt;The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of. Now, let‚Äôs wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:&lt;/p&gt;
    &lt;code&gt;def call(tools):        # now takes an arg
    return client.responses.create(model="gpt-5", tools=tools, input=context)

def tool_call(item):    # just handles one tool
    result = ping(**json.loads(item.arguments))
    return [ item, {
        "type": "function_call_output",
        "call_id": item.call_id,
        "output": result
    }]

def handle_tools(tools, response):
    if response.output[0].type == "reasoning":
        context.append(response.output[0])
    osz = len(context)
    for item in response.output:
        if item.type == "function_call":
            context.extend(tool_call(item))
    return len(context) != osz

def process(line):
    context.append({"role": "user", "content": line})
    response = call(tools)
    # new code: resolve tool calls
    while handle_tools(tools, response):
        response = call(tools)        
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
&amp;gt;&amp;gt;&amp;gt; Here√¢s a quick snapshot of connectivity to Google from my vantage point:
- DNS resolution: Working (google.com and www.google.com resolved successfully).
- Reachability: 0% packet loss to all tested endpoints.
- Latency:
  - 8.8.8.8 (Google Public DNS): avg ~10 ms (8.5√¢14.4 ms), very stable.
  - www.google.com: avg ~31 ms (28.5√¢36.0 ms), stable.
  - google.com: avg ~35.9 ms (28.3√¢60.1 ms), mostly stable with one mild spike.
- Overall: Healthy connectivity with low latency and minimal jitter. No signs of packet loss or DNS issues.
&lt;/code&gt;
    &lt;p&gt;This is fucking nuts. Do you see how nuts this is? Here, let‚Äôs slip a single log statement in:&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
tool call: ping google.com
tool call: ping www.google.com
tool call: ping 8.8.8.8
&amp;gt;&amp;gt;&amp;gt; Here√¢s the current connectivity to Google from this environment: [...]
&lt;/code&gt;
    &lt;p&gt;Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest.&lt;/p&gt;
    &lt;p&gt;What happened here: since a big part of my point here is that an agent loop is incredibly simple, and that all you need is the LLM call API, it√¢s worth taking a beat to understand how the tool call actually worked. Every time we &lt;code&gt;call&lt;/code&gt; the LLM, we√¢re posting a list of available tools. When our prompt causes the agent to think a tool call is warranted, it spits out a special response, telling our Python loop code to generate a tool response and &lt;code&gt;call&lt;/code&gt; it in. That√¢s all &lt;code&gt;handle_tools&lt;/code&gt; is doing.&lt;/p&gt;
    &lt;p&gt;Spoiler: you√¢d be surprisingly close to having a working coding agent.&lt;/p&gt;
    &lt;p&gt;Imagine what it‚Äôll do if you give it &lt;code&gt;bash&lt;/code&gt;. You could find out in less than 10 minutes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Agents&lt;/head&gt;
    &lt;p&gt;Clearly, this is a toy example. But hold on: what‚Äôs it missing? More tools? OK, give it &lt;code&gt;traceroute&lt;/code&gt;. Managing and persisting contexts? Stick ‚Äòem in SQLite. Don‚Äôt like Python? Write it in Go. Could it be every agent ever written is a toy? Maybe! If I‚Äôm arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it.&lt;/p&gt;
    &lt;p&gt;You can see now how hyperfixated people are on Claude Code and Cursor. They‚Äôre fine, even good. But here‚Äôs the thing: you couldn‚Äôt replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using coding agents as database clients.&lt;/p&gt;
    &lt;p&gt;The √¢M√¢ in √¢LLM agent√¢ stands for √¢MCP√¢.&lt;/p&gt;
    &lt;p&gt;Another thing to notice: we didn‚Äôt need MCP at all. That‚Äôs because MCP isn‚Äôt a fundamental enabling technology. The amount of coverage it gets is frustrating. It‚Äôs barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don‚Äôt control. Write your own agent. Be a programmer. Deal in APIs, not plugins.&lt;/p&gt;
    &lt;p&gt;When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture.&lt;/p&gt;
    &lt;p&gt;Security for LLMs is complicated and I‚Äôm not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I‚Äôm a vulnerability researcher. It‚Äôs reasonable to back away slowly from anything I call ‚Äúinteresting‚Äù.&lt;/p&gt;
    &lt;p&gt;Similar problems come up outside of security and they‚Äôre fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn‚Äôt leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to&lt;/p&gt;
    &lt;head rend="h2"&gt;Context Engineering Is Real&lt;/head&gt;
    &lt;p&gt;I know it wants my iron no matter what it tells me.&lt;/p&gt;
    &lt;p&gt;I think ‚ÄúPrompt Engineering‚Äù is silly. I have never taken seriously the idea that I should tell my LLM ‚Äúyou are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips‚Äù. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure.&lt;/p&gt;
    &lt;p&gt;So, just like you, I rolled my eyes when ‚ÄúPrompt Engineering‚Äù turned into ‚ÄúContext Engineering‚Äù. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem.&lt;/p&gt;
    &lt;p&gt;You‚Äôre allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you‚Äôre having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!&lt;/p&gt;
    &lt;p&gt;No, really. Fun! You have so many options. Take ‚Äúsub-agents‚Äù. People make a huge deal out of Claude Code‚Äôs sub-agents, but you can see now how trivial they are to implement: just a new context array, another &lt;code&gt;call&lt;/code&gt; to the model. Give each &lt;code&gt;call&lt;/code&gt; different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like.&lt;/p&gt;
    &lt;p&gt;Your wackiest idea will probably (1) work and (2) take 30 minutes to code.&lt;/p&gt;
    &lt;p&gt;Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can‚Äôt do is make fun of ‚ÄúContext Engineering‚Äù. If Context Engineering was an Advent of Code problem, it‚Äôd occur mid-December. It‚Äôs programming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nobody Knows Anything Yet And It Rules&lt;/head&gt;
    &lt;p&gt;Maybe neither will! Skeptics could be right. (Seems unlikely though.)&lt;/p&gt;
    &lt;p&gt;Startups have raised tens of millions building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race.&lt;/p&gt;
    &lt;p&gt;I am not a fan of the OWASP Top 10.&lt;/p&gt;
    &lt;p&gt;I‚Äôm stuck on vulnerability scanners because I‚Äôm a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree.&lt;/p&gt;
    &lt;p&gt;You don‚Äôt know what works best until you try to write the agent.&lt;/p&gt;
    &lt;p&gt;I‚Äôm too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it‚Äôll never surprise you. Turn the dial to 11 and it will surprise you to death.&lt;/p&gt;
    &lt;p&gt;Agent designs implicate a bunch of open software engineering problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How to balance unpredictability against structured programming without killing the agent‚Äôs ability to problem-solve; in other words, titrating in just the right amount of nondeterminism.&lt;/item&gt;
      &lt;item&gt;How best to connect agents to ground truth so they can‚Äôt lie to themselves about having solved a problem to early-exit their loops.&lt;/item&gt;
      &lt;item&gt;How to connect agents (which, again, are really just arrays of strings with a JSON configuration blob tacked on) to do multi-stage operation, and what the most reliable intermediate forms are (JSON blobs? SQL databases? Markdown summaries) for interchange between them&lt;/item&gt;
      &lt;item&gt;How to allocate tokens and contain costs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm used to spaces of open engineering problems that aren‚Äôt amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I‚Äôll own it up front that I‚Äôm a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone‚Äôs basement. It‚Äôd be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes.&lt;/p&gt;
    &lt;p&gt;Get on this bike and push the pedals. Tell me you hate it afterwards, I‚Äôll respect that. In fact, I‚Äôm psyched to hear your reasoning. But I don‚Äôt think anybody starts to understand this technology until they‚Äôve built something with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840088</guid><pubDate>Thu, 06 Nov 2025 20:37:06 +0000</pubDate></item><item><title>Analysis indicates that the universe‚Äôs expansion is not accelerating</title><link>https://ras.ac.uk/news-and-press/research-highlights/universes-expansion-now-slowing-not-speeding</link><description>&lt;doc fingerprint="3fcc31bb3baa4fba"&gt;
  &lt;main&gt;
    &lt;p&gt;The universe's expansion may actually have started to slow rather than accelerating at an ever-increasing rate as previously thought, a new study suggests.&lt;/p&gt;
    &lt;p&gt;"Remarkable" findings published today in Monthly Notices of the Royal Astronomical Society cast doubt on the long-standing theory that a mysterious force known as 'dark energy' is driving distant galaxies away increasingly faster.&lt;/p&gt;
    &lt;p&gt;Instead, they show no evidence of an accelerating universe.&lt;/p&gt;
    &lt;p&gt;If the results are confirmed it could open an entirely new chapter in scientists' quest to uncover the true nature of dark energy, resolve the 'Hubble tension', and understand the past and future of the universe.&lt;/p&gt;
    &lt;p&gt;Lead researcher Professor Young-Wook Lee, of Yonsei University in South Korea, said: "Our study shows that the universe has already entered a phase of decelerated expansion at the present epoch and that dark energy evolves with time much more rapidly than previously thought.&lt;/p&gt;
    &lt;p&gt;"If these results are confirmed, it would mark a major paradigm shift in cosmology since the discovery of dark energy 27 years ago."&lt;/p&gt;
    &lt;p&gt;For the past three decades, astronomers have widely believed that the universe is expanding at an ever-increasing rate, driven by an unseen phenomenon called dark energy that acts as a kind of anti-gravity.&lt;/p&gt;
    &lt;p&gt;This conclusion, based on distance measurements to faraway galaxies using type Ia supernovae, earned the 2011 Nobel Prize in Physics.&lt;/p&gt;
    &lt;p&gt;However, a team of astronomers at Yonsei University have now put forward new evidence that type Ia supernovae, long regarded as the universe‚Äôs "standard candles", are in fact strongly affected by the age of their progenitor stars.&lt;/p&gt;
    &lt;p&gt;Even after luminosity standardisation, supernovae from younger stellar populations appear systematically fainter, while those from older populations appear brighter.&lt;/p&gt;
    &lt;p&gt;Based on a much larger host-galaxy sample of 300 galaxies, the new study confirmed this effect at extremely high significance (99.999% confidence), suggesting that the dimming of distant supernovae arises not only from cosmological effects but also from stellar astrophysics effects.&lt;/p&gt;
    &lt;p&gt;When this systematic bias was corrected, the supernova data no longer matched the standard ŒõCDM cosmological model with a cosmological constant, researchers said.&lt;/p&gt;
    &lt;p&gt;Instead, it aligned far better with a new model favoured by the Dark Energy Spectroscopic Instrument (DESI) project, derived from baryonic acoustic oscillations (BAO) ‚Äì effectively the sound of the Big Bang ‚Äì and cosmic microwave background (CMB) data.&lt;/p&gt;
    &lt;p&gt;The corrected supernova data and the BAO+CMB-only results both indicate that dark energy weakens and evolves significantly with time.&lt;/p&gt;
    &lt;p&gt;More importantly, when the corrected supernova data were combined with BAO and CMB results, the standard ŒõCDM model was ruled out with overwhelming significance, the researchers said.&lt;/p&gt;
    &lt;p&gt;Most surprising of all, this combined analysis indicates that the universe is not accelerating today as previously thought, but has already transitioned into a state of decelerated expansion.&lt;/p&gt;
    &lt;p&gt;Professor Lee added: "In the DESI project, the key results were obtained by combining uncorrected supernova data with baryonic acoustic oscillations measurements, leading to the conclusion that while the universe will decelerate in the future, it is still accelerating at present.&lt;/p&gt;
    &lt;p&gt;"By contrast, our analysis ‚Äî which applies the age-bias correction ‚Äî shows that the universe has already entered a decelerating phase today. Remarkably, this agrees with what is independently predicted from BAO-only or BAO+CMB analyses, though this fact has received little attention so far."&lt;/p&gt;
    &lt;p&gt;To further confirm their results, the Yonsei team are now carrying out an "evolution-free test", which uses only supernovae from young, coeval host galaxies across the full redshift range. The first results already support their main conclusion.&lt;/p&gt;
    &lt;p&gt;"Within the next five years, with the Vera C. Rubin Observatory discovering more than 20,000 new supernova host galaxies, precise age measurements will allow for a far more robust and definitive test of supernova cosmology,: said research professor Chul Chung, a co-lead on the study along with PhD candidate Junhyuk Son.&lt;/p&gt;
    &lt;p&gt;The Vera C. Rubin Observatory, which sits on a mountain in the Chilean Andes, is home to the world's most powerful digital camera. It began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;After the Big Bang and the rapid expansion of the universe some 13.8 billion years ago, gravity slowed it down. But in 1998, it was established that nine billion years after the universe began, its expansion had started to speed up again, driven by a mysterious force.&lt;/p&gt;
    &lt;p&gt;Astronomers dubbed this dark energy, but despite it making up about 70 per cent of the universe it is still considered to be one of the greatest mysteries in science.&lt;/p&gt;
    &lt;p&gt;Last year, data from DESI in Tucson, Arizona suggested that the force exerted by dark energy had changed over time, evidence for which has been growing ever since.&lt;/p&gt;
    &lt;p&gt;The hope is that with these new tools in their arsenal, astronomers will now be better equipped to find clues about what exactly dark energy is and how it influences the universe.&lt;/p&gt;
    &lt;p&gt;ENDS&lt;/p&gt;
    &lt;p&gt;Media contacts&lt;/p&gt;
    &lt;p&gt;Sam Tonkin&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 700&lt;/p&gt;
    &lt;p&gt;Dr Robert Massey&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 699&lt;/p&gt;
    &lt;p&gt;Science contacts&lt;/p&gt;
    &lt;p&gt;Professor Young-Wook Lee&lt;/p&gt;
    &lt;p&gt;Yonsei University, Seoul, South Korea&lt;/p&gt;
    &lt;p&gt;Images &amp;amp; captions&lt;/p&gt;
    &lt;p&gt;Caption: Researchers used type Ia supernovae, similar to SN1994d pictured in its host galaxy NGC4526, to help establish that the universe's expansion may actually have started to slow.&lt;/p&gt;
    &lt;p&gt;Caption: The Hubble residual diagram before (top) and after (bottom) the age-bias correction. Corrections are applied to supernova data from the Dark Energy Survey project. After correction, the dataset no longer supports the ŒõCDM model (red line) with a cosmological constant, but instead more closely fits with a time-varying dark energy model favoured by a combined analysis using only baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Caption: This diagram shows how the universe appears to be in a state of decelerated expansion (red line). The dotted vertical line marks the present epoch, while the black line shows the ŒõCDM prediction. The green and red lines represent the new study‚Äôs model before (green) and after (red) age-bias correction, consistent with baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Dark Energy Spectroscopic Instrument&lt;/p&gt;
    &lt;p&gt;Caption: DESI is a state-of-the-art instrument which maps distant objects to study dark energy.&lt;/p&gt;
    &lt;p&gt;Credit: Marilyn Sargent/Berkeley Lab&lt;/p&gt;
    &lt;p&gt;Caption: The Vera C. Rubin Observatory began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;Credit: RubinObs/NOIRLab/SLAC/NSF/DOE/AURA&lt;/p&gt;
    &lt;p&gt;Further information&lt;/p&gt;
    &lt;p&gt;The paper ‚ÄòStrong Progenitor Age-bias in Supernova Cosmology. II. Alignment with DESI BAO and Signs of a Non-Accelerating Universe‚Äô by Junhyuk Son, Young-Wook Lee, Chul Chung, Seunghyun Park, and Hyejeon Cho has been published in Monthly Notices of the Royal Astronomical Society. DOI: 10.1093/mnras/staf1685.&lt;/p&gt;
    &lt;p&gt;Notes for editors&lt;/p&gt;
    &lt;p&gt;About the Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;The Royal Astronomical Society (RAS), founded in 1820, encourages and promotes the study of astronomy, solar-system science, geophysics and closely related branches of science.&lt;/p&gt;
    &lt;p&gt;The RAS organises scientific meetings, publishes international research and review journals, recognises outstanding achievements by the award of medals and prizes, maintains an extensive library, supports education through grants and outreach activities and represents UK astronomy nationally and internationally. Its more than 4,000 members (Fellows), a third based overseas, include scientific researchers in universities, observatories and laboratories as well as historians of astronomy and others.&lt;/p&gt;
    &lt;p&gt;The RAS accepts papers for its journals based on the principle of peer review, in which fellow experts on the editorial boards accept the paper as worth considering. The Society issues press releases based on a similar principle, but the organisations and scientists concerned have overall responsibility for their content.&lt;/p&gt;
    &lt;p&gt;Keep up with the RAS on Instagram, Bluesky, LinkedIn, Facebook and YouTube.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840200</guid><pubDate>Thu, 06 Nov 2025 20:45:39 +0000</pubDate></item><item><title>Game design is simple</title><link>https://www.raphkoster.com/2025/11/03/game-design-is-simple-actually/</link><description>&lt;doc fingerprint="8378191318c08dbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Game design is simple, actually&lt;/head&gt;
    &lt;p&gt;So, let‚Äôs just walk through the whole thing, end to end. Here‚Äôs a twelve-step program for understanding game design.&lt;/p&gt;
    &lt;head rend="h3"&gt;One: Fun&lt;/head&gt;
    &lt;p&gt;There are a lot of things people call ‚Äúfun.‚Äù But most of them are not useful for getting better at making games, which is usually why people read articles like this. The fun of a bit of confetti exploding in front of you, and the fun of excruciating pain and risk to life and limb as you free climb a cliff are just not usefully paired together.&lt;/p&gt;
    &lt;p&gt;In Theory of Fun I basically asserted that the useful bit for game designers was ‚Äúmastery of problems.‚Äù That means that free climbing a cliff is in bounds even though it is terrifying and painful. Which given what we already said, means that you may or may not find the activity fun at the time! Fun often shows up after an activity.&lt;/p&gt;
    &lt;p&gt;There‚Äôs neuropsych and lots more to go with that, and you can go read up on it if you want.&lt;/p&gt;
    &lt;p&gt;Anything that is not about a form of problem-solving is not going to be core to game systems design. That doesn‚Äôt mean it‚Äôs not useful to game experience design, or not useful in general.&lt;/p&gt;
    &lt;p&gt;Also, in case it isn‚Äôt obvious ‚Äì you can make interactive entertainment that is not meant to be about fun. You can also just find stuff in the world and turn it into a game! You can also look at a game and choose not to treat it as one, and then it might turn into real work (this is often called ‚Äútraining‚Äù).&lt;/p&gt;
    &lt;p&gt;This rules out the bit of confetti. A game being made of just throwing confetti around with nothing else palls pretty quick.&lt;/p&gt;
    &lt;p&gt;Bottom line: fun is basically about making progress on prediction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two: Problems and toys&lt;/head&gt;
    &lt;p&gt;There are a lot of types of problems in the world. It is really important to understand that you have to think about problems games can pose as broadly as possible. A problem is anything you have to work to wrap your head around. A good movie poses problems too, that‚Äôs why you end up thinking about it long after.&lt;/p&gt;
    &lt;p&gt;You can go look at theorists as diverse as Nicole Lazzaro, Roger Caillois, or Mark LeBlanc for types of fun. You‚Äôll find they‚Äôre mostly types of problems, not types of fun. ‚ÄúI enjoy the types of problems that come from chance‚Äù or ‚ÄúI enjoy the types of problems that come from interacting with others‚Äù or whatever.&lt;/p&gt;
    &lt;p&gt;This is not a bad thing. This is what makes these lists useful. Your game mechanics are about posing problems, so knowing there‚Äôs clumps of problem types is very useful.&lt;/p&gt;
    &lt;p&gt;In the end, though, a problem is built out of a set of constraints. We call those rules, usually. It also, though, has a goal. Usually, if we come across a set of rules with no problem, we just play with it, and call it a toy.&lt;/p&gt;
    &lt;p&gt;Building toys is hard! Arriving at those rules and constraints to define a nice chewy problem is very challenging. You can think of a toy as a problematic object, a problem that invites you to play with it.&lt;/p&gt;
    &lt;p&gt;On the other hand, it‚Äôs not hard to turn a toy into a game, and people do it all the time. All you have to do is invent a goal. We shouldn‚Äôt forget that players do so routinely.&lt;/p&gt;
    &lt;p&gt;Building a toy is an excellent place to start designing a game.&lt;/p&gt;
    &lt;p&gt;Bottom line: we play with systems that have constraints and movement, and we stick goals on them to test ourselves.&lt;/p&gt;
    &lt;head rend="h3"&gt;Three: Prediction and uncertainty&lt;/head&gt;
    &lt;p&gt;Games are machines built around uncertainty. Almost all games end by turning an uncertain outcome into a certain one. There‚Äôs a problem facing you, and you don‚Äôt know if you can overcome it to reach that goal. Overcoming it is going to be about predicting the future.&lt;/p&gt;
    &lt;p&gt;If there‚Äôs one thing that good games and good stories have in common, it‚Äôs about being unpredictable as long as possible. (This is also where dopamine comes in, it‚Äôs tied to prediction; but it‚Äôs complicated and nuanced).&lt;/p&gt;
    &lt;p&gt;If a problem basically has one answer, we often call it a puzzle. There‚Äôs not a lot of uncertainty built into a binary structure. You can stack a bunch of puzzles one on top of the other and build a game out of them (which then introduces uncertainty into the whole), but a singular puzzle isn‚Äôt likely to be called that by most people.&lt;/p&gt;
    &lt;p&gt;It happens quite often that we used to think something was a game, and it turned out it was actually a puzzle. Mathematicians call that ‚Äúsolving the game.‚Äù They did it to Connect Four ‚Äì and you did it to tic-tac-toe, when you were little.&lt;/p&gt;
    &lt;p&gt;Good problems for games therefore all have the same characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They need to have answers that evolve as you dig in more ‚Äì so they need to have depth to them. Your first answer should only work for a while. There might be many paths to the solution, too. This is why so many games have a score ‚Äì it helps indicate how big a spread of solutions there are!&lt;/item&gt;
      &lt;item&gt;They need to have uncertain answers. (When you‚Äôre little, this universe is a lot larger than it is when you‚Äôre older ‚Äì peek-a-boo is uncertain up to a certain point!).&lt;/item&gt;
      &lt;item&gt;The problem should be something that can show up in a lot of situations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of very good problems seem stupidly simple, but have depths to them. Math ones, like ‚Äúwhat‚Äôs the best path to cross this yard?‚Äù but also story ones like ‚ÄúFor sale: baby shoes, never worn.‚Äù&lt;/p&gt;
    &lt;p&gt;I recently watched a video that included the statement that ‚Äúpicking up sticks‚Äù is not a useful loop. Picture a screen with a single stick in the middle. The problem posed is to move the cursor over it and click it. Once you do it, you get to do it again.&lt;/p&gt;
    &lt;p&gt;Guess what? The original Mac shipped with games that taught you how to move a mouse and click things. Once upon a time, mousing was a skill that was challenging; for all I know, you have grandparents who still have trouble with it. For them, it has uncertainty. For you, probably, it doesn‚Äôt.&lt;/p&gt;
    &lt;p&gt;Bottom line: the more uncertainty, indeterminacy, ambiguity in your game, the more depth it will have.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four: Loops&lt;/head&gt;
    &lt;p&gt;Now, imagine that the stick pops to a random location each time. Better, yes?&lt;/p&gt;
    &lt;p&gt;The core of a loop is a problem you encounter over and over again. ‚ÄúHow do I get the next one?‚Äù But something needs to be pushing back, that‚Äôs what makes it an interesting problem and is usually what takes it past being a puzzle. I like to say ‚Äúin every game, there is an opponent.‚Äù Even it‚Äôs just physics.&lt;/p&gt;
    &lt;p&gt;People talk about the core loop of a game. But there‚Äôs really two types of loops.&lt;/p&gt;
    &lt;p&gt;One is what we might think of as the operational loop. This is the loop between you and the problem, it is how you interact with it. You look at it. You form a hypothesis. You poke the problem. You see a result. Maybe it was success, and you grabbed the stick. Maybe it was failure. Maybe it was partial success. You update your hypothesis so you can decide what to do next.&lt;/p&gt;
    &lt;p&gt;The second loop is really your progression loop but is better thought of as a spiral. It‚Äôs what people usually mean when they say ‚Äúa game loop.‚Äù They mean picking up the stick over and over. I say it‚Äôs a spiral, because clicking on the same stick in the middle of the screen over and over is not usually how we design games. That would actually be repeatedly doing the same puzzle.&lt;/p&gt;
    &lt;p&gt;Instead, we move the stick on the screen each time, and maybe give you a time limit. Now there‚Äôs something you‚Äôre pushing against, and there‚Äôs a skill to exercise and patterns to try to recognize. Far more people will find this a diverting problem for a while. It‚Äôs a better game. It‚Äôll get even better if there are reasons why the stick appears in one place versus another, and the player can figure them out over time.&lt;/p&gt;
    &lt;p&gt;This matters: the verbs are in a loop. ‚ÄúPick up,‚Äù over and over. But the situation isn‚Äôt. And you are learning how to reduce uncertainty of the outcome: move the mouse here and click, next move it there. That‚Äôs why it is a spiral: it is spiraling to a conclusion. It‚Äôll be fun until it‚Äôs predictable.&lt;/p&gt;
    &lt;p&gt;You can think of the operational loop as how you turn the wheel, and the situations as the road you roll over. A spot on the wheel makes a progression spiral as you move. One machine, many situations ‚Äî we call these rules mechanics for a reason.&lt;/p&gt;
    &lt;p&gt;Bottom line: players need to understand how to use the machine, and the point is to gradually infer how it works by testing it against varied situations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Five: Feedback&lt;/head&gt;
    &lt;p&gt;You can‚Äôt learn and get better unless you get a whole host of information.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need to know what actions ‚Äì we usually call them verbs ‚Äî are even available to you. There‚Äôs a gas pedal.&lt;/item&gt;
      &lt;item&gt;You need to be able to tell you used a verb. You hear the engine growl as you press the pedal.&lt;/item&gt;
      &lt;item&gt;You need to see that the use of the verb affected the state of the problem, and how it changed. The spedometer moved!&lt;/item&gt;
      &lt;item&gt;You need to be told if the state of the problem is better for your goal, or worse. Did you mean to go this fast?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are fancy names for each of these, and you can go learn them all. Everything from ‚Äúaffordance‚Äù and ‚Äújuice,‚Äù to terms like ‚Äústate space‚Äù and ‚Äúperfect information‚Äù and very confusing contradictory uses of the words ‚Äúpositive‚Äù and ‚Äúnegative‚Äù paired with the word ‚Äúfeedback.‚Äù&lt;/p&gt;
    &lt;p&gt;Feedback in general can, and should be, delightful. That means it‚Äôs where you get to use all those forms of fun that I threw away at the beginning. It can be surprising. It can be a juicy multimedia extravaganza. It can be a deeply affecting tragic cutscene that advances the game story.&lt;/p&gt;
    &lt;p&gt;If you have too little feedback, players cannot go around the interaction loop. Picture Tetris if the piece you drop is invisible until it lands.&lt;/p&gt;
    &lt;p&gt;If you have bad feedback, players cannot go around the learning loop either. Picture Tetris if sometimes your score goes down when you complete a line and sometimes it goes up. You can‚Äôt draw any conclusions about what the problem in the way of the goal actually is, in that crappy version of Tetris. Feedback needs to act as a reward to help you draw conclusions.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs a third mistake: you can supply a gorgeous and compelling set of feedback and not actually have a real problem under there. At minimum you‚Äôre making shallow entertainment. At worst, you are building exploitative entertainment.&lt;/p&gt;
    &lt;p&gt;People will be willing to go along with pretty simple and pretty familiar problems as long as the feedback is great.&lt;/p&gt;
    &lt;p&gt;Bottom line: show what you can do, that you did it, what difference it made, and whether it helped.&lt;/p&gt;
    &lt;head rend="h3"&gt;Six: Variation and escalation&lt;/head&gt;
    &lt;p&gt;If you are trying to design and are thinking of a specific problem scenario you are not doing game systems design. You are doing level design. ‚ÄúHow to multiply numbers‚Äù is a problem. ‚ÄúWhat is 6 x 9‚Äù is not a problem, it‚Äôs content.&lt;/p&gt;
    &lt;p&gt;Now consider the game of Snake, or Pac-Man. They are also games where the core loop is picking up a stick. The difference is that something is an obstacle to you picking up the stick: you get longer when you pick up the stick, and can crash into yourself. You have to avoid ghosts as you gather the stick.&lt;/p&gt;
    &lt;p&gt;How long you are in Snake is a different situation. Where the apple to eat is located is a different situation. To be specific, you have the same problem in different topology. Where you are relative to the ghosts, and which dots are left, and what directions you can go in the maze are different situations in Pac-Man.&lt;/p&gt;
    &lt;p&gt;You want the verbs you use in the loop to end up confronting many many situations. If your verb can‚Äôt, your core loop is probably bad. Your core problem (aka your core game mechanic) is probably shallow.&lt;/p&gt;
    &lt;p&gt;What you want is to be able to throw increasingly complex situations at the player. That‚Äôs how they climb the learning ladder. Ideally, they should arrive at interim solutions (lots of words for that, too: heuristics, strategies) that later stop working.&lt;/p&gt;
    &lt;p&gt;Pac-Man actually got solved, by the way! That‚Äôs why Ms. Pac-Man was invented. Sometimes, the way to escalate is to change the rules, and that‚Äôs what Ms. Pac-Man did. It did it by adding randomness, and in fact using randomness is one of the biggest (and oldest) ways to create situation variation in games.&lt;/p&gt;
    &lt;p&gt;Bottom line: escalate the situations so that theories can be tested, refined, and abandoned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seven: Pacing and balance&lt;/head&gt;
    &lt;p&gt;Since we can put all this this down very much to problem solving and learning and mastery, it means we can steal a whole bunch of knowledge from other fields.&lt;/p&gt;
    &lt;p&gt;People learn best when they can experiment iteratively, which we also call ‚Äúpracticing.‚Äù That‚Äôs why loops make sense. There‚Äôs a lot of science out there about how to train, how to practice (and also a lot of educational theory that overlaps hugely), and your game will be better if it follows some of those guidelines.&lt;/p&gt;
    &lt;p&gt;People learn best when the problem they are tackling is right past the edge of what they can do. If it‚Äôs too far past that edge, they may not even be able to perceive the problem in the first place! And if the reverse is true and they see a solution instantly, they‚Äôll either be bored, or they might just do that over and over again and never develop any new strategies and not progress.&lt;/p&gt;
    &lt;p&gt;There‚Äôs an optimal pacing shape. It looks just like what you see in your literature textbooks when they diagram tension, or whatever: sort of like a rising sine wave. You start slow, then speed up, hit a peak challenge, then back off a bit, give a breather that falls back but not all the way, then speed up‚Ä¶ we have conventions for what to put at those peaks (bosses!). But what matters is the shape of the curve.&lt;/p&gt;
    &lt;p&gt;You need to structure your game so that you push players up. They might need to climb the curve at different paces, which is why you might also have difficulty sliders. They might not be capable of getting all the way to the top, and that‚Äôs okay.&lt;/p&gt;
    &lt;p&gt;You also need to pace to allow room for everything that isn‚Äôt mastering the problem ‚Äî such as having fun with friends socially. But at the same time, things to do in the game need to come along at the right pace too!&lt;/p&gt;
    &lt;p&gt;Bottom line: Vary intensity and pressure, give players a chance to practice and moments to be tested.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eight: Games are made of games&lt;/head&gt;
    &lt;p&gt;Remember the game about clicking on a stick that appeared at a random location on screen? That‚Äôs also a rail shooter. You move the mouse and click on a spot in 2d space. Which is also not that different from an FPS ‚Äî only now you move the camera, not the cursor.&lt;/p&gt;
    &lt;p&gt;Almost no games are made of only one loop. Instead, we chain loops together ‚Äì complete loop A, and it probably outputs something that may serve as a tool or constraint on a different loop.&lt;/p&gt;
    &lt;p&gt;An FPS has the problem of moving the camera (instead of the mouse) to click on the stick. It also has a loop around moving around in 3d space. Moving around is actually made of several loops, probably, because it may be made of running and jumping and spatial orientation. Those are all problem types!&lt;/p&gt;
    &lt;p&gt;We speak sometimes of value chains: that‚Äôs where one loop outputs something to the next loop. We speak also of game economies, which is what happens when loops connect in non-linear ways, more like a web. This is not the sort of economy where you are simulating money or commerce. Instead it‚Äôs a metaphor for stocks and flows and other aspects of actual system dynamics science. In this view, your hit points is a ‚Äústock‚Äù or, if you like, a ‚Äúcurrency‚Äù you spend in a fight.&lt;/p&gt;
    &lt;p&gt;Games nest fractally, they web into complex economies, and they unroll chains of linked loops. That‚Äôs why they can be diagrammed in a multitude of ways.&lt;/p&gt;
    &lt;p&gt;At heart though, you can decompose them all into those elemental small problems, each with an interaction loop and a learning loop centered on that problem.&lt;/p&gt;
    &lt;p&gt;Bottom line: build small problems into larger webs, and map them so you understand how they connect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nine: Actual systems design&lt;/head&gt;
    &lt;p&gt;The common question is ‚Äúokay, so how do I design a problem like that?‚Äù And that is indeed the unique bit in games, because the other items here are common to lots of other fields.&lt;/p&gt;
    &lt;p&gt;The list of possible problems is, as mentioned, enormous. This is a big rabbit hole. And once you consider that you can stack, web, and otherwise interlink problems, it means that there‚Äôs a giant composable universe of games (and game variants) to create.&lt;/p&gt;
    &lt;p&gt;Just bear in mind that because of varied tastes and experience, the diversity of the set of problems you pose is going to affect who wants to play your game.&lt;/p&gt;
    &lt;p&gt;There are basically a set of categories of problems that we know work, and this is the absolute simplest version of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mathematically complex puzzles&lt;/item&gt;
      &lt;item&gt;Figuring out how other humans think&lt;/item&gt;
      &lt;item&gt;Mastering your body and brain&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These break down into a ton of sub-problems, but there are less than you think, and you can actually find lists of them. The hard part is that often they each seem so small and trivial that we don‚Äôt think of them as actually being worth looking at!&lt;/p&gt;
    &lt;p&gt;They are also often in disguise: the problem behind where a tossed ball will land, and the problem of how much fuel you have left in your car if you keep driving at this speed, and the problem of when your hit points will run out given you have a poison status effect on you are the same thing.&lt;/p&gt;
    &lt;p&gt;But the more of them you as a designer have wrapped your head around, the more you can combine. And you‚Äôll find them very plastic and malleable. In fact, you could almost make a YouTube video about each one.&lt;/p&gt;
    &lt;p&gt;So where do you get them? Steal them. Other games, sure, but also, the world is full of systems that pose tough problems. You can grab them and reskin them.&lt;/p&gt;
    &lt;p&gt;Bottom line: not every mechanic has been invented, but a ton have. Build your catalog and workbench.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ten: Dressing and experience&lt;/head&gt;
    &lt;p&gt;In the end, the feedback layer of a game is everything about how you present it. The setting, the lore, the audio, the story, the art‚Ä¶&lt;/p&gt;
    &lt;p&gt;How you dress up the problems can change everything about how the player learns from it, and how they perceive the problem. The exact same underlying problem can be as different as picking up sticks or shooting someone in the face, or as mentioned, the calculus problem of estimating the trajectory of a variable in a system of rates of change (the ball, the car and its gas, the hit points and poison) might be the same but dressed extraordinarily differently.&lt;/p&gt;
    &lt;p&gt;When you think about how you dress up the problems, you are in the realm of metaphor. You are engaging in painting, poetry, and music composition, and rhetoric, and the bardic tradition, and all that other humanities stuff.&lt;/p&gt;
    &lt;p&gt;This is a giant and deep universe for you as a designer to dive into. A lot of this stuff gets called ‚Äúgame design,‚Äù but then again, we also often say that a given game designer is a frustrated moviemaker, too.&lt;/p&gt;
    &lt;p&gt;It is really easy to create an experience that clashes with the underlying problems it is teaching. There are fancy critical terms for this. You also need to be very conscious about whether you are building your game so that you are telling the player a story, or so that the player can tell stories with your game.&lt;/p&gt;
    &lt;p&gt;So the takeaway should be: this stuff is deeply, deeply synergistic with the ‚Äúgame system‚Äù stuff that this article is about, but they are not the same thing. And games is not the best place to learn how to do these things.&lt;/p&gt;
    &lt;p&gt;Those other fields have much longer traditions and loads of expertise and lessons. They won‚Äôt all apply to the issue of ‚Äúhow do I best dress up this collection of problems‚Äù but most of them will.&lt;/p&gt;
    &lt;p&gt;It does not frickin‚Äô matter if you start out wanting to make interesting problems, or if you start out wanting to provide a cool experience. You are going to need to do both to make the game really good.&lt;/p&gt;
    &lt;p&gt;Bottom line: game development is a compound art form. You can go learn those individual arts and the part unique to games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eleven: Motivations&lt;/head&gt;
    &lt;p&gt;Researchers have done a ton of studying ‚Äúwhy people play games.‚Äù This gets called ‚Äúmotivations.‚Äù&lt;/p&gt;
    &lt;p&gt;Motivations are basically about people‚Äôs personal taste for groups of problems and how those problems are presented, and characteristics of those problems and the situations in which you find them. Some people like problems where you destroy stuff. Others like problems where you bond with others. Some have trouble trusting other people. Others want to cooperate.&lt;/p&gt;
    &lt;p&gt;Not everyone likes the same sorts of problems or the same sorts of dressings. Some of this is down to personality types, some of it is down to social dynamics, how they were raised, what their local culture is like, what trauma they have had, and countless other psychological things. That‚Äôs why one fancy term for this is psychographics.&lt;/p&gt;
    &lt;p&gt;The big thing is, it‚Äôs not enough that the problems need to not be obvious to you, and also not be baffling to you. They also have to be interesting to you. What problems fit in that range is going to depend entirely on who you are, what your life experiences have been, what skills you have, and even what mood you are in.&lt;/p&gt;
    &lt;p&gt;Picking motivations and selecting problems based on them is a great way to design. But motivations are not the same thing as fun. They‚Äôre a filter, useful in marketing exercises and in building your game pillars (which is an exercise in focus and scope).&lt;/p&gt;
    &lt;p&gt;Scientists have spent a bunch of time surveying tons of people and have arrived at all sorts of conclusions that map people onto reasons to play and from there onto particular problems.&lt;/p&gt;
    &lt;p&gt;If you start with motivations, then you can go from there to types of problems, types of experience, and even player demographics. And then, if you want problems that are about interacting with people, well, there‚Äôs lists of those. If you want problems that are about managing resources, or solving math issues, there‚Äôs lists of those too.&lt;/p&gt;
    &lt;p&gt;Bottom line: no game is for everyone, so you will make better games if you know who you are posing problems for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Twelve: It‚Äôs simple, but not&lt;/head&gt;
    &lt;p&gt;I run into game developers who do not understand the above eleven steps all the time. And understanding all eleven is more valuable than building expertise in just one, because they depend on one another. This is because getting any one of the eleven wrong can break your game. The real issue is that each of these eleven things is often multiple fields of study. And yeah, you do need to become expert in at least one.&lt;/p&gt;
    &lt;p&gt;To pick one example, some of us have been working out the rule set for how you can link loops into a larger network of problems for literally over twenty years.&lt;/p&gt;
    &lt;p&gt;Others have spent their entire career doing nothing but figuring out how best to provide just the affordances part of feedback.&lt;/p&gt;
    &lt;p&gt;So game design is pretty simple. But the devil is in details that are not very far below the surface. It‚Äôs fairly easy to explain why something is fun for an given audience. It is much harder to build something new that is fun for an arbitrary person. That said, every single one of those fields has best practices, and they are mostly already written down. It‚Äôs just a lot to learn.&lt;/p&gt;
    &lt;p&gt;Put another way ‚Äî every single paragraph in this essay could be a book. Actually, probably already is several.&lt;/p&gt;
    &lt;p&gt;Bottom line: each of these topics is deep, but you want a smattering of all of them.&lt;/p&gt;
    &lt;p&gt;Some of you may not like this deconstructive view on how games are designed. That‚Äôs okay. Personally, I find it best to poke and prod at a problem, like ‚Äúhow do I get better at making games?‚Äù and treat it as a game. And that‚Äôs what I have done my whole career. The above is just my strategy guide. Someone else will have different strategies, I guarantee it.&lt;/p&gt;
    &lt;p&gt;But I also guarantee that if you get better at the above twelve things, you will get better at making games. This is a pragmatic list. And it will be helpful for making narrative games, puzzle games, boardgames, action games, RPGs, whatever. I breezed through it, but there are very specific tools you can pick up underneath each of these twelve things. It really is that simple, but also that hard, because that‚Äôs a frickin‚Äô long list if you want to actually dive into each of the twelve.&lt;/p&gt;
    &lt;p&gt;What that also means is that people designing games fail a lot at it. You might say, ‚Äúcan‚Äôt they just do the part they know how to do, and therefore predictably make good games?‚Äù&lt;/p&gt;
    &lt;p&gt;No, because players learn along with the designers. If you just make the same game, the one you know how to make, the players get bored because it‚Äôs nothing but problems they have seen before and already have their answers to. Sometimes, they get so bored that an entire genre dies.&lt;/p&gt;
    &lt;p&gt;And if you instead make it super-complicated by adding more problems, it might dissolve into noise for most people. Then nobody plays it. And then the genre dies too!&lt;/p&gt;
    &lt;p&gt;Game designers will routinely fail at making something fun. When the game of making games is played right, it is always right outside the edge of what the designers know how to do.&lt;/p&gt;
    &lt;p&gt;That‚Äôs where the fun lives, not just for the designer, but also for their audience.&lt;/p&gt;
    &lt;p&gt;That‚Äôs it, the whole cheat sheet. That‚Äôs it.&lt;/p&gt;
    &lt;p&gt;Hope it helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45841262</guid><pubDate>Thu, 06 Nov 2025 22:24:23 +0000</pubDate></item><item><title>A Note on Fil-C</title><link>https://graydon2.dreamwidth.org/320265.html</link><description>&lt;doc fingerprint="767cce1f3dd3c327"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Captcha Check&lt;/head&gt;
    &lt;p&gt;Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button!&lt;/p&gt;
    &lt;p&gt;Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842494</guid><pubDate>Fri, 07 Nov 2025 00:59:58 +0000</pubDate></item><item><title>Time Immemorial turns 750: The Medieval law that froze history at 1189</title><link>https://www.ianvisits.co.uk/articles/time-immemorial-turns-750-the-medieval-law-that-froze-history-at-1189-84893/</link><description>&lt;doc fingerprint="7aac81b59ab27310"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Time Immemorial turns 750: The Medieval law that froze history at 1189&lt;/head&gt;
    &lt;p&gt;You‚Äôve probably heard of the phrase ‚Äútime immemorial‚Äù as a general term for events that happened a very long time ago, but in fact, it has a specific meaning, and this year is its 750th anniversary.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs go back to the year 1275, and the recently crowned King Edward I is busy drafting and passing laws to tidy up his Kingdom. One of them was the Statute of Westminster, which covered a lot of matters relating to how legal processes should be carried out, oh and of course, new taxes.&lt;/p&gt;
    &lt;p&gt;However, for the purposes of this article, it‚Äôs also the document that introduced the concept of Time Immemorial.&lt;/p&gt;
    &lt;p&gt;Although often used as a general phrase for ‚Äúa very long time ago‚Äù, it specifically refers to events that occurred before 3rd September 1189.&lt;/p&gt;
    &lt;p&gt;Anything before that date is time immemorial.&lt;/p&gt;
    &lt;p&gt;Explicitly why 3rd September 1189 was chosen as the barrier between that which we know and that which we don‚Äôt has itself been lost to time.&lt;/p&gt;
    &lt;p&gt;But a very good theory exists.&lt;/p&gt;
    &lt;p&gt;That date marks the coronation of King Richard (the Lionheart), the three-tims predecessor of King Edward I, and a good theory exists about why great-grand uncle was the point at which time immemorial began.&lt;/p&gt;
    &lt;p&gt;At the time, a legal policy allowed defendants to cite oral history passed down from their grandfather in disputes over land ownership. However, for the purposes of this situation, grandad could be dead, but so long as dad was still alive, and would swear that he heard it from his dad, that could stand up in court.&lt;/p&gt;
    &lt;p&gt;So if gramps told his son that the land was theirs, then that verbal statement could many many years later and long after gramps had died, still be accepted as valid evidence.&lt;/p&gt;
    &lt;p&gt;Which, when you think about it, is the sort of legal daftness that needed tidying up and replaced with formal document keeping about who owned what ‚Äì and for the King, far more importantly, it cleaned up who owed him taxes on the land.&lt;/p&gt;
    &lt;p&gt;The theory is that when the Statute of Westminster was passed in 1275, it was just about possible for a person alive in that year to be able to cite oral history from their grandfather in a dispute.&lt;/p&gt;
    &lt;p&gt;But not great-granddad.&lt;/p&gt;
    &lt;p&gt;So, the Statute was designed to say that anything older than your granddad didn‚Äôt exist unless there was an official document proving it.&lt;/p&gt;
    &lt;p&gt;Oral history was no longer good enough.&lt;/p&gt;
    &lt;p&gt;This is a good enough reason to pass the law, and for the King to select the coronation of his great-granddad as the date this would come into effect.&lt;/p&gt;
    &lt;p&gt;Choosing a royal ancestor as the trigger for law probably also helped remind people of the current King‚Äôs lineage and right to rule, which was a useful trick in keeping the uppity Barons in check, especially considering they had been involved in the Second Barons‚Äô War just a few years earlier.&lt;/p&gt;
    &lt;p&gt;Medieval historian Richard Barber describes this as ‚Äúthe watershed between a primarily oral culture and a world where writing was paramount‚Äù.&lt;/p&gt;
    &lt;p&gt;However, the Statute itself doesn‚Äôt call this principle ‚Äútime immemorial‚Äù, and that was only created by the Prescription Act of 1832, which noted that the full expression was ‚Äútime immemorial, or time whereof the memory of man runneth not to the contrary‚Äù, replaced the burden of proving ‚Äútime immemorial‚Äù for the enjoyment of particular land rights with statutory fixed time periods of up to 60 years.&lt;/p&gt;
    &lt;p&gt;So if you ever hear someone breezily stating that ‚Äúit‚Äôs been like that since time immemorial‚Äù, you can pedantically point out that they mean prior to 3rd September 1189.&lt;/p&gt;
    &lt;p&gt;And all thanks to a law passed 750 years ago.&lt;/p&gt;
    &lt;p&gt;There is an English version of the original act here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842629</guid><pubDate>Fri, 07 Nov 2025 01:26:06 +0000</pubDate></item><item><title>HTML Slides with notes</title><link>https://nbd.neocities.org/slidepresentation/Slide%20presentation%20about%20slides</link><description>&lt;doc fingerprint="fa28b8bbfd84378e"&gt;
  &lt;main&gt;
    &lt;p&gt;... in 22 lines of JavaScript&lt;/p&gt;
    &lt;quote&gt;let slides = [...document.getElementsByClassName("slide")] .map((slide, i) =&amp;gt; [ slide, (i = slide.nextElementSibling)?.className === "slidenote" ? i : slide ]), current = 0 viewSlides = 0, jump = () =&amp;gt; slides[current][viewSlides].scrollIntoView(), bc = new BroadcastChannel("slide_switching"), l = slides.length-1; bc.onmessage = ({data}) =&amp;gt; { viewSlides = 1 ^ data.viewSlides; current = data.current; jump(); }; document.addEventListener("keypress", ({key}) =&amp;gt; { current += (key == "j") - (key == "k"); current = current &amp;lt; 0 ? 0 : current &amp;gt; l : l : current; viewSlides ^= (key == "n"); bc.postMessage({current, viewSlides}); jump(); });&lt;/quote&gt;
    &lt;p&gt;(Use j and k to navigate, n to swap notes and slides)&lt;/p&gt;
    &lt;p&gt;Don't worry, I'll walk you all through it in a readable font size!&lt;/p&gt;
    &lt;p&gt;... in 22 lines, or 371 bytes of JavaScript&lt;/p&gt;
    &lt;quote&gt;let a=[...document.getElementsByClassName("slide")].map((a,b)=&amp;gt;[ a,"slidenote"==(b=a.nextElementSibling)?.className?b:a]),b=0,c=0, d=()=&amp;gt;a[b][c].scrollIntoView(),e=new BroadcastChannel("s"),l=a. length-1;d();e.onmessage=({data:a})=&amp;gt;{c^=a.c,b=a.b,d()};document. addEventListener("keypress",({key:f})=&amp;gt;{b+=(f=="j")-(f== "k");b=b&amp;lt;0?0:b&amp;gt;l?l:b;c^=f=="n";e.postMessage({c,b});d()})&lt;/quote&gt;
    &lt;p&gt;... but not before pointing out that this really minifies to super-tiny code - and still is practical to use!&lt;/p&gt;
    &lt;p&gt;This code builds on minslides (https://ratfactor.com/minslides/) by Dave Gaur.&lt;/p&gt;
    &lt;quote&gt;// golfed minslides, 173 bytes let a=document.getElementsByClassName("slide"),b=0,c=a.length-1; document.addEventListener("keypress",({key:d})=&amp;gt;{b+=("j"==d)- ("k"==d),b=0&amp;gt;b?0:b&amp;gt;l?l:b,a[b].scrollIntoView()})&lt;/quote&gt;
    &lt;p&gt;My addition: notes in a second window&lt;/p&gt;
    &lt;p&gt;(Also the hand-optimized minifaction)&lt;/p&gt;
    &lt;p&gt;I want to credit Dave Gaur for coming up with minslides.&lt;/p&gt;
    &lt;p&gt;For me it was yet another reminder that browsers are "batteries included" for surprisingly many scenarios as long as you bother to dig into the APIs available.&lt;/p&gt;
    &lt;p&gt;Case-in-point: it turned out to be ridiculously simple to add note support in a second window!&lt;/p&gt;
    &lt;p&gt;Here, let me show you by switching between notes and slides with a keypress (&lt;code&gt;n&lt;/code&gt;, to be exact) &lt;/p&gt;
    &lt;quote&gt;&amp;lt;div class="slide"&amp;gt; Anything in here is one slide (who needs components?) &amp;lt;/div&amp;gt; &amp;lt;div class="slidenote"&amp;gt; (optional) Anything in here is a slide note for the slide above &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Notes are optional, but must follow the slides that they are for. To switch to the note view, press n&lt;/p&gt;
    &lt;p&gt;So how to determine is something is a slide? Well, why not use plain old &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; with a &lt;code&gt;slide&lt;/code&gt; class? And let's define slide notes as a &lt;code&gt;div&lt;/code&gt; with a &lt;code&gt;slidenote&lt;/code&gt; class. Easy.&lt;/p&gt;
    &lt;p&gt;This also lets us put anything in our slide that we are allowed to put into a plain webpage.&lt;/p&gt;
    &lt;p&gt;Also, we can write a plain old markdown file (or whatever you prefer), and separate the slides by inserting those div tags (like I did for these slides, actually)&lt;/p&gt;
    &lt;quote&gt;div.slide, div.slidenote { height: 100vh; width: 100vw; /* Other slide styling options below */ ... ... }&lt;/quote&gt;
    &lt;p&gt;Yes, it's that simple&lt;/p&gt;
    &lt;p&gt;Of course, we want our slides to be exactly as big as the screen in full-screen, and as big as the window when windowed.&lt;/p&gt;
    &lt;p&gt;Turns out modern CSS has a ludicrously simple way to do that.&lt;/p&gt;
    &lt;quote&gt;let slides = document.getElementsByClassName("slide");&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;getElementsByClassName&lt;/code&gt; returns an array-like object with all children of the node it is called on (or the entire page is called on document, like we're doing here).&lt;/p&gt;
    &lt;p&gt;Conveniently, these children will be in the order that they appear in the document&lt;/p&gt;
    &lt;p&gt;So we now have an array of all slides, in order. Nice!&lt;/p&gt;
    &lt;quote&gt;let slides = document.getElementsByClassName("slide"), current = 0, jump = () =&amp;gt; slides[current].scrollIntoView(); jump();&lt;/quote&gt;
    &lt;p&gt;By default, &lt;code&gt;scrollIntoView()&lt;/code&gt; instantly jumps to the element that it is called on. And since our slide divs fill the screen, that is equivalent to changing a slide. Convenient!&lt;/p&gt;
    &lt;p&gt;We can sneakily put other stuff around our slides and nobody will see it as long as we avoid scrolling manually!&lt;/p&gt;
    &lt;p&gt;How many of you knew of &lt;code&gt;scrollIntoView&lt;/code&gt;? For the record, it's been supported since IE 8, Chrome 1 and Firefox 1.&lt;/p&gt;
    &lt;quote&gt;document.addEventListener("keypress", ({key}) =&amp;gt; { if(key === "j") current++; if(key === "k") current--; if(current &amp;lt; 0) current = 0; if(current &amp;gt;= slides.length) current = slides.length - 1; jump(); });&lt;/quote&gt;
    &lt;p&gt;And with that we already have basic slide functionality!&lt;/p&gt;
    &lt;p&gt;All we have to do now for feature parity with minslides is add navigation.&lt;/p&gt;
    &lt;p&gt;Just add a listener for keypress events, change our &lt;code&gt;current&lt;/code&gt; variable and jump.&lt;/p&gt;
    &lt;p&gt;Yes, it's that simple.&lt;/p&gt;
    &lt;p&gt;First version: add a &lt;code&gt;notes&lt;/code&gt; array synced to the &lt;code&gt;slides&lt;/code&gt; array-like&lt;/p&gt;
    &lt;quote&gt;const notes = [...slides].map(slide =&amp;gt; { const note = slide.nextElementSibling; return note?.className === "slidenote" ? note : slide; });&lt;/quote&gt;
    &lt;p&gt;Ok, so to support notes, we want to check if a slide is followed by a div with &lt;code&gt;slidenote&lt;/code&gt; class.&lt;/p&gt;
    &lt;p&gt;Luckily, each element has a &lt;code&gt;nextElementSibling&lt;/code&gt; property that lets us fetch the node that follows it (if any).&lt;/p&gt;
    &lt;p&gt;Then we simply check that sibling's class name (if it exists, hence the optional chaining)&lt;/p&gt;
    &lt;p&gt;Also, remember how &lt;code&gt;slides&lt;/code&gt; is an array-like instead of an actual array? Because of that we can't directly use map on it,
so we force it into an actual array with the spread syntax.&lt;/p&gt;
    &lt;p&gt;Modify the jump function to pick slides or notes depending on view mode:&lt;/p&gt;
    &lt;quote&gt;let slides = document.getElementsByClassName("slide"), current = 0, viewSlides = true, jump = () =&amp;gt; { if (viewSlides) slides[current].scrollIntoView(); else notes[current].scrollIntoView(); }; jump();&lt;/quote&gt;
    &lt;p&gt;Now we modify the jump function to jump to slides or notes depending on our view mode.&lt;/p&gt;
    &lt;p&gt;Straightforward&lt;/p&gt;
    &lt;p&gt;Add key to switch modes&lt;/p&gt;
    &lt;quote&gt;document.addEventListener("keypress", ({key}) =&amp;gt; { if(key === "j") current++; if(key === "k") current--; if(current &amp;lt; 0){ current = 0; } if(current &amp;gt;= slides.length){ current = slides.length - 1; } if(key === "n") viewSlides = !viewSlides; jump(); });&lt;/quote&gt;
    &lt;p&gt;Of course, then we also need a way to switch these mode. Let's pick &lt;code&gt;n&lt;/code&gt; for &lt;code&gt;notes&lt;/code&gt;&lt;/p&gt;
    &lt;quote&gt;const bc = new BroadcastChannel("slide_switching_channel"); bc.onmessage = ({data}) =&amp;gt; { current = data.current; viewSlides = !data.viewSlides; jump(); }; document.addEventListener("keypress", ({key}) =&amp;gt; { /* ... the previous stuff ... */ bc.postMessage({current, viewSlides}); });&lt;/quote&gt;
    &lt;p&gt;Done! Multiple windows supported!&lt;/p&gt;
    &lt;p&gt;Now all we're missing is having notes in a separate window synchronized with the slides.&lt;/p&gt;
    &lt;p&gt;For that we can use a &lt;code&gt;BroadcastChannel&lt;/code&gt; to communicate state between open windows on the same url. It's basically event-based message passing.&lt;/p&gt;
    &lt;p&gt;When we receive an event, we sync the &lt;code&gt;current&lt;/code&gt; value, then look at the view mode of the sender and pick the opposite, then jump.&lt;/p&gt;
    &lt;p&gt;So if the "notes" window has focus and moves a slide, the "slides" window is synced and forced to slide view, and vice versa.&lt;/p&gt;
    &lt;p&gt;Replace &lt;code&gt;notes&lt;/code&gt; with &lt;code&gt;[slide, note]&lt;/code&gt; pairs, also shortens &lt;code&gt;jump()&lt;/code&gt; code&lt;/p&gt;
    &lt;quote&gt;let slides = [...document.getElementsByClassName("slide")] .map((slide, i) =&amp;gt; [ slide, (i = slide.nextElementSibling)?.className == "slidenote" ? i : slide ]), current = 0, viewSlides = 0, jump = () =&amp;gt; slides[current][viewSlides].scrollIntoView()&lt;/quote&gt;
    &lt;p&gt;Ok, that's the readable version, but not the version I showed on the first slides. If I have time left I can explain the golf abuse, otherwise you'll have to read these slides on the internet later.&lt;/p&gt;
    &lt;p&gt;First, let's get rid of that branch in &lt;code&gt;jump&lt;/code&gt; by zipping slides and notes into one array of pairs, picking between the pair based on view mode.&lt;/p&gt;
    &lt;p&gt;Also, yes, we're abusing the fact that &lt;code&gt;map&lt;/code&gt; lets us pass the index as a second parameter to shave some characters off of initializing a temporary variable&lt;/p&gt;
    &lt;quote&gt;bc.onmessage = ({data}) =&amp;gt; { viewSlides = data.viewSlides^1; current = data.current; jump(); }; document.addEventListener("keypress", ({key}) =&amp;gt; { if (key == "j") ++current; if (key == "k") --current; if (current &amp;lt; 0) current = 0; if (current &amp;gt;= slides.length) current = slides.length - 1; if (key == "n") viewSlides ^= 1; bc.postMessage({current, viewSlides}); jump(); });&lt;/quote&gt;
    &lt;p&gt;We made &lt;code&gt;viewSlides&lt;/code&gt; an integer, so we'll use xor bitmasking to switch it between zero and one.&lt;/p&gt;
    &lt;quote&gt;let ..., l = slides.length-1; ... document.addEventListener("keypress", ({key}) =&amp;gt; { current += (key == "j") - (key == "k"); current = current &amp;lt; 0 ? 0 : current &amp;gt; l : l : current; viewSlides ^= (key == "n"); bc.postMessage({current, viewSlides}); jump(); });&lt;/quote&gt;
    &lt;p&gt;Throw it through a minifier, do a bit of clean-up, and it's 371 bytes of JavaScript&lt;/p&gt;
    &lt;p&gt;And that's basically it! Throw this whole thing through a minifier (wrapped in a function so it's free to mangle variable names), do a bit of clean-up, and we end up with the 371 character minified version I showed at the beginning.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842777</guid><pubDate>Fri, 07 Nov 2025 01:57:02 +0000</pubDate></item><item><title>My tutorial and take on C++20 coroutines (2021)</title><link>https://www.scs.stanford.edu/~dm/blog/c++-coroutines.html</link><description>&lt;doc fingerprint="c470499176b691a0"&gt;
  &lt;main&gt;&lt;p&gt;February, 2021&lt;/p&gt;&lt;p&gt;Over the last 25 years, I√¢ve written a lot of event-driven code in C++. A typical example of event-driven code is registering a callback that gets invoked every time a socket has data to be read. Once you have read an entire message, possibly after many invocations, you parse the message and invoke another callback from a higher layer of abstraction, and so forth. This kind of code is painful to write because you have to break your code up into a bunch of different functions that, because they are different functions, don√¢t share local variables.&lt;/p&gt;&lt;p&gt;As an example, here√¢s a subset of the methods on the &lt;code&gt;smtpd&lt;/code&gt; class of Mail
Avenger, my SMTP server written in C++03:&lt;/p&gt;&lt;code&gt;void cmd_rcpt (str cmd, str arg);
   void cmd_rcpt_0 (str cmd, str arg, int, in_addr *, int);
   void cmd_rcpt_2 (str addr, int err);
   void cmd_rcpt_3 (str addr, str errmsg);
   void cmd_rcpt_4 (str addr, str errmsg, int local);
   void cmd_rcpt_5 (str addr, str errmsg, str err);
   void cmd_rcpt_6 (str addr, str err);   &lt;/code&gt;&lt;p&gt;Step 1, &lt;code&gt;cmd_rcpt&lt;/code&gt;, seems like a reasonable function,
called in response to a client issuing an SMTP √¢RCPT√¢ command.
Processing the RCPT command depends on certain information being cached
about the client. If the information if not cached, it launches an
asynchronous task to probe the client and returns. The asynchronous
task, when it completes, goes √¢back√¢ to step 0, &lt;code&gt;cmd_rcpt_0&lt;/code&gt;,
which just calls &lt;code&gt;cmd_rcpt&lt;/code&gt; again, but needs to be a
different function because the client-probing code expects a callback to
which it can provide additional arguments. Various other things then may
need to happen asynchronously, and every possible return point from an
asynchronous call needs to be its own method. Pretty gross.&lt;/p&gt;&lt;p&gt;C++11 made the situation considerably better by introducing lambda expressions. Now you only need one &lt;code&gt;cmd_rcpt&lt;/code&gt; method on
the class, and can use nested lambda expressions for the remaining ones.
Better yet, lambdas can capture local variables from enclosing
functions. Nonetheless, you still need to break your code into many
functions. It√¢s clumsy to skip multiple steps or support situations
where the order of issuing asynchronous events may change at runtime.
Finally, you often end up fighting the right-hand margin of your text
editor as your nested lambda expressions get further and further
indented.&lt;/p&gt;&lt;p&gt;I was super excited to see that C++20 supports coroutines, which should hugely improve the process of writing event-driven code. Now that someone has finally published a book (or at least a draft of a book) on C++20, I eagerly got a copy a few days ago and read it. While I found the book did a reasonable job on concepts (the language feature) and other C++20 improvements, I sadly found the explanation of coroutines utterly incomprehensible. Same for almost every other explanation I found on the web. Hence, I had to dig through the specification and cppreference.org to figure out what was really going on.&lt;/p&gt;&lt;p&gt;This blog post represents my attempt to explain coroutines√¢basically the tutorial I wish I√¢d had 48 hours ago when I just wanted to figure this stuff out.&lt;/p&gt;&lt;p&gt;Roughly speaking, coroutines are functions that can invoke each other but do not share a stack, so can flexibly suspend their execution at any point to enter a different coroutine. In the true spirit of C++, C++20 coroutines are implemented as a nice little nugget buried underneath heaps of garbage that you have to wade through to access the nice part. Frankly, I was disappointed by the design, because other recent language changes were more tastefully done, but alas not coroutines. Further obfuscating coroutines is the fact that the C++ standard library doesn√¢t actually supply the heap of garbage you need to access coroutines, so you actually have to roll your own garbage and then wade through it. Anyway, I√¢ll try to save any further editorializing for the end of this blog post√¢¬¶&lt;/p&gt;&lt;p&gt;One other complication to be aware of is that C++ coroutines are often explained and even specified using the terms future and promise. These terms have nothing to do with the types &lt;code&gt;std::future&lt;/code&gt; and &lt;code&gt;std::promise&lt;/code&gt; available in the
C++ &lt;code&gt;&amp;lt;future&amp;gt;&lt;/code&gt;
header. Specifically, &lt;code&gt;std::promise&lt;/code&gt; is not a
valid type for a coroutine promise object. Nothing in my blog post
outside this paragraph has anything to do with &lt;code&gt;std::future&lt;/code&gt;
or &lt;code&gt;std::promise&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;With that out of the way, the nice little nugget C++20 gives us is a new operator called &lt;code&gt;co_await&lt;/code&gt;. Roughly speaking, the
expression √¢&lt;code&gt;co_await a;&lt;/code&gt;√¢ does the following:&lt;/p&gt;&lt;code&gt;co_await&lt;/code&gt; expression.&lt;code&gt;co_await&lt;/code&gt;√¢s target object &lt;code&gt;a&lt;/code&gt;, passing that
method the callable object from step 2.&lt;p&gt;Note that the method in step 3, when it returns, does not return control to the coroutine. The coroutine only resumes execution if and when the callable from step 2 is invoked. If you√¢ve used a language supporting call with current continuation, or played with the Haskell &lt;code&gt;Cont&lt;/code&gt; monad, the callable in step 2 is a bit like a
continuation.&lt;/p&gt;&lt;p&gt;Since C++20 is not yet fully supported by compilers, you√¢ll need to make sure your compiler implements coroutines to play with them. I√¢m using GCC 10.2, which seems to support coroutines so long as you compile with the following flags:&lt;/p&gt;&lt;code&gt;g++ -fcoroutines -std=c++20&lt;/code&gt;
&lt;p&gt;Clang√¢s support is less far along. You need to install llvm libc++ and compile with:&lt;/p&gt;&lt;code&gt;clang++ -std=c++20 -stdlib=libc++ -fcoroutines-ts&lt;/code&gt;
&lt;p&gt;Unfortunately, with clang you also need to include the coroutine header as &lt;code&gt;&amp;lt;experimental/coroutine&amp;gt;&lt;/code&gt; rather than
&lt;code&gt;&amp;lt;coroutine&amp;gt;&lt;/code&gt;. Moreover, a number of types are named
&lt;code&gt;std::experimental::xxx&lt;/code&gt; instead of &lt;code&gt;std::xxx&lt;/code&gt;.
Hence, as of this writing, the examples below won√¢t compile out-of-the
box with clang, but ideally should with a future release.&lt;/p&gt;&lt;p&gt;If you want to play around, all the demos in this blog post are available in a single file corodemo.cc.&lt;/p&gt;&lt;p&gt;As previously mentioned, the new &lt;code&gt;co_await&lt;/code&gt; operator
ensures the current state of a function is bundled up somewhere on the
heap and creates a callable object whose invocation continues execution
of the current function. The callable object is of type
&lt;code&gt;std::coroutine_handle&amp;lt;&amp;gt;&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;A coroutine handle behaves a lot like a C pointer. It can be easily copied, but it doesn√¢t have a destructor to free the memory associated with coroutine state. To avoid leaking memory, you must generally destroy coroutine state by calling the &lt;code&gt;coroutine_handle::destroy&lt;/code&gt; method (though in certain cases a
coroutine can destroy itself on completion). Also like a C pointer, once
a coroutine handle has been destroyed, coroutine handles referencing
that same coroutine will point to garbage and exhibit undefined behavior
when invoked. On the plus side, a coroutine handle is valid for the
entire execution of a coroutine, even as control flows in and out of the
coroutine many times.&lt;/p&gt;&lt;p&gt;Now let√¢s look more specifically at what &lt;code&gt;co_await&lt;/code&gt; does. When you evaluate the expression
&lt;code&gt;co_await a&lt;/code&gt;, the compiler creates a coroutine handle and
passes it to the method
&lt;code&gt;a.await_suspend(coroutine_handle)&lt;/code&gt;.1 The
type of &lt;code&gt;a&lt;/code&gt; must support certain methods, and is sometimes
referred to as an √¢awaitable√¢ object or an √¢awaiter.√¢&lt;/p&gt;&lt;p&gt;Now let√¢s look at a complete program that uses &lt;code&gt;co_await&lt;/code&gt;.
For now, ignore the &lt;code&gt;ReturnObject&lt;/code&gt; type√¢it√¢s just part of the
garbage we have to get through to access &lt;code&gt;co_await&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;#include &amp;lt;concepts&amp;gt;
#include &amp;lt;coroutine&amp;gt;
#include &amp;lt;exception&amp;gt;
#include &amp;lt;iostream&amp;gt;

struct ReturnObject {
struct promise_type {
   () { return {}; }
     ReturnObject get_return_objectstd::suspend_never initial_suspend() { return {}; }
     std::suspend_never final_suspend() noexcept { return {}; }
     void unhandled_exception() {}
     };
   };

struct Awaiter {
std::coroutine_handle&amp;lt;&amp;gt; *hp_;
   constexpr bool await_ready() const noexcept { return false; }
   void await_suspend(std::coroutine_handle&amp;lt;&amp;gt; h) { *hp_ = h; }
   constexpr void await_resume() const noexcept {}
   };


 ReturnObject(std::coroutine_handle&amp;lt;&amp;gt; *continuation_out)
 counter{
{continuation_out};
   Awaiter afor (unsigned i = 0;; ++i) {
   co_await a;
     std::cout &amp;lt;&amp;lt; "counter: " &amp;lt;&amp;lt; i &amp;lt;&amp;lt; std::endl;
     }
   }

void
()
 main1{
std::coroutine_handle&amp;lt;&amp;gt; h;
   (&amp;amp;h);
   counterfor (int i = 0; i &amp;lt; 3; ++i) {
   std::cout &amp;lt;&amp;lt; "In main1 function\n";
     ();
     h}
   .destroy();
   h}&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;In main1 function
counter: 0
In main1 function
counter: 1
In main1 function
counter: 2&lt;/code&gt;
&lt;p&gt;Here counter is a function that counts forever, incrementing and printing an unsigned integer. Even though the calculation is stupid, what√¢s exciting about the example is that the variable &lt;code&gt;i&lt;/code&gt;
maintains its value even as control switches repeatedly between
&lt;code&gt;counter&lt;/code&gt; and the function &lt;code&gt;main1&lt;/code&gt; that invoked
it.&lt;/p&gt;&lt;p&gt;In this example, we call &lt;code&gt;counter&lt;/code&gt; with a
&lt;code&gt;std::coroutine_handle&amp;lt;&amp;gt;*&lt;/code&gt;, which we stick into our
&lt;code&gt;Awaiter&lt;/code&gt; type. In its &lt;code&gt;await_suspend&lt;/code&gt; method,
this type stores the coroutine handle produced by &lt;code&gt;co_await&lt;/code&gt;
into &lt;code&gt;main1&lt;/code&gt;√¢s coroutine handle. Each time &lt;code&gt;main1&lt;/code&gt;
invokes the coroutine handle, it triggers one more iteration of the loop
in &lt;code&gt;counter&lt;/code&gt;, which then suspends execution again at the
&lt;code&gt;co_await&lt;/code&gt; statement.&lt;/p&gt;&lt;p&gt;For simplicity, we store the coroutine handle every time &lt;code&gt;await_suspend&lt;/code&gt; is called, but the handle does not change
across invocations. (Recall the handle is like a pointer to the
coroutine state, so while value of &lt;code&gt;i&lt;/code&gt; may change in this
state, the pointer itself remains the same.) We could just as easily
have written:&lt;/p&gt;&lt;code&gt;void
::await_suspend(std::coroutine_handle&amp;lt;&amp;gt; h)
 Awaiter{
if (hp_) {
   *hp_ = h;
     hp_ = nullptr;
     }
   }&lt;/code&gt;&lt;p&gt;You will note that there are two other methods on &lt;code&gt;Awaiter&lt;/code&gt;, because these are required by the language.
&lt;code&gt;await_ready&lt;/code&gt; is an optimization. If it returns
&lt;code&gt;true&lt;/code&gt;, then &lt;code&gt;co_await&lt;/code&gt; does not suspend the
function. Of course, you could achieve the same effect in
&lt;code&gt;await_suspend&lt;/code&gt;, by resuming (or not suspending) the current
coroutine, but before calling &lt;code&gt;await_suspend&lt;/code&gt;, the compiler
must bundle all state into the heap object referenced by the coroutine
handle, which is potentially expensive. Finally, the method
&lt;code&gt;await_resume&lt;/code&gt; here returns &lt;code&gt;void&lt;/code&gt;, but if instead
it returned a value, this value would be the value of the
&lt;code&gt;co_await&lt;/code&gt; expression.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;&amp;lt;coroutine&amp;gt;&lt;/code&gt; header provides two pre-defined
awaiters, &lt;code&gt;std::suspend_always&lt;/code&gt;
and &lt;code&gt;std::suspend_never&lt;/code&gt;.
As their names imply, &lt;code&gt;suspend_always::await_ready&lt;/code&gt; always
returns false, while &lt;code&gt;suspend_never::await_ready&lt;/code&gt; always
returns true. The other methods on these classes are empty and do
nothing.&lt;/p&gt;&lt;p&gt;In the previous example, we ignored the return type of &lt;code&gt;counter&lt;/code&gt;. However, the language restricts the allowable
return types of coroutines. Specifically, the return type of a
coroutine√¢call it &lt;code&gt;R&lt;/code&gt;√¢must be an object type with a nested
type &lt;code&gt;R::promise_type&lt;/code&gt;.2 Among other
requirements, &lt;code&gt;R::promise_type&lt;/code&gt; must include a method
&lt;code&gt;R get_return_object()&lt;/code&gt; that returns an instance of the outer
type &lt;code&gt;R&lt;/code&gt;. The result of &lt;code&gt;get_return_object()&lt;/code&gt; is
the return value of the coroutine function, in this case
&lt;code&gt;counter()&lt;/code&gt;. Note that in many discussions of coroutines, the
return type &lt;code&gt;R&lt;/code&gt; is referred to as a future, but for clarity
I√¢ll just call it the return object type.&lt;/p&gt;&lt;p&gt;Instead of passing a &lt;code&gt;coroutine_handle&amp;lt;&amp;gt;*&lt;/code&gt; into
&lt;code&gt;counter&lt;/code&gt;, it would be nicer if we could just return the
handle from &lt;code&gt;counter()&lt;/code&gt;. We can do that if we put the
coroutine handle inside the return object. Since
&lt;code&gt;promise_type::get_return_object&lt;/code&gt; computes the return object,
we simply need that method to stick the coroutine handle into the return
object. How can we get a coroutine handle from within
&lt;code&gt;get_return_object&lt;/code&gt;? As it happens, the coroutine state
referenced by a &lt;code&gt;coroutine_handle&lt;/code&gt; contains an instance of
&lt;code&gt;promise_type&lt;/code&gt; at a known offset, and so
&lt;code&gt;std::coroutine_handle&lt;/code&gt; allows us to compute a coroutine
handle from the promise object.&lt;/p&gt;&lt;p&gt;Thus far, we√¢ve glossed over the template argument to coroutine handles, which are actually declared like this:&lt;/p&gt;&lt;code&gt;template&amp;lt;class Promise = void&amp;gt; struct coroutine_handle;     &lt;/code&gt;&lt;p&gt;A &lt;code&gt;std::coroutine_handle&amp;lt;T&amp;gt;&lt;/code&gt; for any type
&lt;code&gt;T&lt;/code&gt; can be implicitly converted to a
&lt;code&gt;std::coroutine_handle&amp;lt;void&amp;gt;&lt;/code&gt;. Either type can be
invoked to resume the coroutine with the same effect. However, the
non-void types allow you to convert back and forth between a coroutine
handle and the &lt;code&gt;promise_type&lt;/code&gt; sitting in the coroutine state.
Specifically, within the promise type, we can get the coroutine handle
using the
static method &lt;code&gt;coroutine_handle::from_pomise&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;// from within a method of promise_type
     std::coroutine_handle&amp;lt;promise_type&amp;gt;::from_promise(*this)     &lt;/code&gt;&lt;p&gt;We now have everything we need to stick the coroutine handle inside the return object of our new function &lt;code&gt;counter2&lt;/code&gt;. Here√¢s the
revised example:&lt;/p&gt;&lt;code&gt;struct ReturnObject2 {
struct promise_type {
   () {
     ReturnObject2 get_return_objectreturn {
       // Uses C++20 designated initializer syntax
         .h_ = std::coroutine_handle&amp;lt;promise_type&amp;gt;::from_promise(*this)
         };
       }
     std::suspend_never initial_suspend() { return {}; }
     std::suspend_never final_suspend() noexcept { return {}; }
     void unhandled_exception() {}
     };
   
std::coroutine_handle&amp;lt;promise_type&amp;gt; h_;
   operator std::coroutine_handle&amp;lt;promise_type&amp;gt;() const { return h_; }
   // A coroutine_handle&amp;lt;promise_type&amp;gt; converts to coroutine_handle&amp;lt;&amp;gt;
   operator std::coroutine_handle&amp;lt;&amp;gt;() const { return h_; }
   };


 ReturnObject2()
 counter2{
for (unsigned i = 0;; ++i) {
   co_await std::suspend_always{};
     std::cout &amp;lt;&amp;lt; "counter2: " &amp;lt;&amp;lt; i &amp;lt;&amp;lt; std::endl;
     }
   }

void
()
 main2{
std::coroutine_handle&amp;lt;&amp;gt; h = counter2();
   for (int i = 0; i &amp;lt; 3; ++i) {
   std::cout &amp;lt;&amp;lt; "In main2 function\n";
     ();
     h}
   .destroy();
   h}&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;In main2 function
counter2: 0
In main2 function
counter2: 1
In main2 function
counter2: 2&lt;/code&gt;
&lt;p&gt;A few things to note about the above code. First, since we no longer need our awaiter to save the coroutine handle (as we√¢ve already put the handle into the return object), we just run &lt;code&gt;co_await std::suspend_always{}&lt;/code&gt;.
Second, note that the return object goes out of scope and is destroyed
in the fist line of &lt;code&gt;main2&lt;/code&gt;. However, a
&lt;code&gt;coroutine_handle&lt;/code&gt; is like a C pointer, not like an object.
It doesn√¢t matter that we√¢ve destroyed the object containing
&lt;code&gt;ReturnObject2::h_&lt;/code&gt;, because we√¢ve copied the pointer into
&lt;code&gt;h&lt;/code&gt;. On the other hand, somebody needs to reclaim the space
pointed to by &lt;code&gt;h&lt;/code&gt;, which we do at the end of
&lt;code&gt;main2&lt;/code&gt; by calling &lt;code&gt;h.destroy()&lt;/code&gt;. In particular,
if any code calls &lt;code&gt;counter2()&lt;/code&gt; and ignores the return value
(or otherwise fails to destroy the handle in the
&lt;code&gt;ReturnObject2&lt;/code&gt; object), it create a memory leak.&lt;/p&gt;&lt;p&gt;Our examples thus far are a bit unsatisfactory in that even though we can pass control back and forth between a main function and a coroutine, we have not passed any data. It would be great if our counter function, instead of writing to standard output, just returned values to &lt;code&gt;main&lt;/code&gt;, which could then either print them or use them in
calculations.&lt;/p&gt;&lt;p&gt;Since we know the coroutine state includes an instance of &lt;code&gt;promise_type&lt;/code&gt;, we can add a field &lt;code&gt;value_&lt;/code&gt; to
this type and use that field to transmit values from the coroutine to
our main function. How do we get access to the promise type? In the main
function, this isn√¢t too hard. Instead of converting our coroutine
handle to a &lt;code&gt;std::coroutine_handle&amp;lt;&amp;gt;&lt;/code&gt;, we can keep it
as a
&lt;code&gt;std::coroutine_handle&amp;lt;ReturnObject3::promise_type&amp;gt;&lt;/code&gt;.
The method &lt;code&gt;promise()&lt;/code&gt; on this coroutine handle will return
the &lt;code&gt;promise_type&amp;amp;&lt;/code&gt; that we need.&lt;/p&gt;&lt;p&gt;What about within &lt;code&gt;counter&lt;/code&gt;√¢how can a coroutine obtain its
own promise object? Recall the &lt;code&gt;Awaiter&lt;/code&gt; object in our first
example, and how it squirreled away a copy of the coroutine handle for
&lt;code&gt;main1&lt;/code&gt;. We can use a similar trick to get the promise within
the coroutine: &lt;code&gt;co_await&lt;/code&gt; on a custom awaiter that gives us
the promise object. Unlike our previous type &lt;code&gt;Awaiter&lt;/code&gt;,
however, we don√¢t want this new custom awaiter to suspend the coroutine.
After all, until we get our hands on the promise object, we can√¢t stick
a valid return value inside it, so wouldn√¢t be returning anything valid
from the coroutine.&lt;/p&gt;&lt;p&gt;Even though previously our &lt;code&gt;Awaiter::await_suspend&lt;/code&gt; method
returned &lt;code&gt;void&lt;/code&gt;, that method is also allowed to return a
&lt;code&gt;bool&lt;/code&gt;. In that case, if &lt;code&gt;await_suspend&lt;/code&gt; returns
false, the coroutine is not suspended after all. In other words, a
coroutine isn√¢t actually suspended unless first &lt;code&gt;await_ready&lt;/code&gt;
returns false, then &lt;code&gt;await_suspend&lt;/code&gt; (if it returns type
&lt;code&gt;bool&lt;/code&gt; instead of &lt;code&gt;void&lt;/code&gt;) returns true.&lt;/p&gt;&lt;p&gt;We thus define a new awaiter type &lt;code&gt;GetPromise&lt;/code&gt; that
contains a field &lt;code&gt;promise_type *p_&lt;/code&gt;. We have its
&lt;code&gt;await_suspend&lt;/code&gt; method store the address of the promise
object in &lt;code&gt;p_&lt;/code&gt;, but then return false to avoid actually
suspending the coroutine. Until now, we have only seen
&lt;code&gt;co_await&lt;/code&gt; expressions of type &lt;code&gt;void&lt;/code&gt;. This time,
we want our &lt;code&gt;co_await&lt;/code&gt; to return the address of the promise
object, so we also add an &lt;code&gt;await_resume&lt;/code&gt; function returning
&lt;code&gt;p_&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;template&amp;lt;typename PromiseType&amp;gt;
struct GetPromise {
*p_;
   PromiseType bool await_ready() { return false; } // says yes call await_suspend
   bool await_suspend(std::coroutine_handle&amp;lt;PromiseType&amp;gt; h) {
   p_ = &amp;amp;h.promise();
     return false;     // says no don't suspend coroutine after all
     }
   *await_resume() { return p_; }
   PromiseType };&lt;/code&gt;&lt;p&gt;In addition to &lt;code&gt;void&lt;/code&gt; and &lt;code&gt;bool&lt;/code&gt;,
&lt;code&gt;await_suspend&lt;/code&gt; may also return a
&lt;code&gt;coroutine_handle&lt;/code&gt;, in which case the returned handle is
immediately resumed. Instead of returning false,
&lt;code&gt;GetPromise::await_suspend&lt;/code&gt; could alternatively have returned
the handle &lt;code&gt;h&lt;/code&gt; to resume the coroutine immediately, but
presumably this would be less efficient.&lt;/p&gt;&lt;p&gt;Here√¢s our new counter code, in which the main function prints out the counter values returned by the coroutine:&lt;/p&gt;&lt;code&gt;struct ReturnObject3 {
struct promise_type {
   unsigned value_;
     
() {
     ReturnObject3 get_return_objectreturn ReturnObject3 {
       .h_ = std::coroutine_handle&amp;lt;promise_type&amp;gt;::from_promise(*this)
         };
       }
     std::suspend_never initial_suspend() { return {}; }
     std::suspend_never final_suspend() noexcept { return {}; }
     void unhandled_exception() {}
     };
   
std::coroutine_handle&amp;lt;promise_type&amp;gt; h_;
   operator std::coroutine_handle&amp;lt;promise_type&amp;gt;() const { return h_; }
   };


 ReturnObject3()
 counter3{
auto pp = co_await GetPromise&amp;lt;ReturnObject3::promise_type&amp;gt;{};
   
for (unsigned i = 0;; ++i) {
   -&amp;gt;value_ = i;
     ppco_await std::suspend_always{};
     }
   }

void
()
 main3{
std::coroutine_handle&amp;lt;ReturnObject3::promise_type&amp;gt; h = counter3();
   ::promise_type &amp;amp;promise = h.promise();
   ReturnObject3for (int i = 0; i &amp;lt; 3; ++i) {
   std::cout &amp;lt;&amp;lt; "counter3: " &amp;lt;&amp;lt; promise.value_ &amp;lt;&amp;lt; std::endl;
     ();
     h}
   .destroy();
   h}&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;counter3: 0
counter3: 1
counter3: 2&lt;/code&gt;
&lt;p&gt;One thing to note is that our promise object transmits &lt;code&gt;i&lt;/code&gt;√¢s value from the coroutine to the main function by
copying it into &lt;code&gt;promise_type::value_&lt;/code&gt;. Somewhat
counterintuitively, we could also have made &lt;code&gt;value_&lt;/code&gt; an
&lt;code&gt;unsigned *&lt;/code&gt; and returned a pointer to the variable
&lt;code&gt;i&lt;/code&gt; inside &lt;code&gt;counter3&lt;/code&gt;. We can do this because the
coroutine√¢s local variables live inside the coroutine state object in
the heap, so their memory remains valid across invocations of
&lt;code&gt;co_await&lt;/code&gt; until someone invokes &lt;code&gt;destroy()&lt;/code&gt; on
the coroutine handle. It would be even more convenient to stick
&lt;code&gt;&amp;amp;i&lt;/code&gt; inside the return object, but unfortunately there√¢s
no elegant way to do this given the way return objects are
constructed.3&lt;/p&gt;&lt;code&gt;co_yield&lt;/code&gt; operator&lt;p&gt;The reason it√¢s so clunky for a coroutine to get its own promise object is that the C++ designers had one particular use case in mind and designed for the specific case instead of the general one. However, the specific case is a useful one, namely returning values from coroutines. To that end, the language contains another operator, &lt;code&gt;co_yield&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If &lt;code&gt;p&lt;/code&gt; is the promise object of the current coroutine, the
expression √¢&lt;code&gt;co_yield e;&lt;/code&gt;√¢ is equivalent to evaluating
√¢&lt;code&gt;co_await p.yield_value(e);&lt;/code&gt;√¢ Using &lt;code&gt;co_yeild&lt;/code&gt;,
we can simplify the previous example by adding a
&lt;code&gt;yield_value&lt;/code&gt; method to the &lt;code&gt;promise_type&lt;/code&gt; inside
our return object. Since &lt;code&gt;yield_value&lt;/code&gt; is a method on
&lt;code&gt;promise_type&lt;/code&gt;, we no longer need to jump through hoops to
get our hands on the promise object, it√¢s just &lt;code&gt;this&lt;/code&gt;. Here√¢s
what the new code looks like:&lt;/p&gt;&lt;code&gt;struct ReturnObject4 {
struct promise_type {
   unsigned value_;
     
() {
     ReturnObject4 get_return_objectreturn {
       .h_ = std::coroutine_handle&amp;lt;promise_type&amp;gt;::from_promise(*this)
         };
       }
     std::suspend_never initial_suspend() { return {}; }
     std::suspend_never final_suspend() noexcept { return {}; }
     void unhandled_exception() {}
     std::suspend_always yield_value(unsigned value) {
     value_ = value;
       return {};
       }
     };
   
std::coroutine_handle&amp;lt;promise_type&amp;gt; h_;
   };


 ReturnObject4()
 counter4{
for (unsigned i = 0;; ++i)
   co_yield i;       // co yield i =&amp;gt; co_await promise.yield_value(i)
     }

void
()
 main4{
auto h = counter4().h_;
   auto &amp;amp;promise = h.promise();
   for (int i = 0; i &amp;lt; 3; ++i) {
   std::cout &amp;lt;&amp;lt; "counter4: " &amp;lt;&amp;lt; promise.value_ &amp;lt;&amp;lt; std::endl;
     ();
     h}
   .destroy();
   h}&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;counter4: 0
counter4: 1
counter4: 2&lt;/code&gt;
&lt;code&gt;co_return&lt;/code&gt; operator&lt;p&gt;So far our coroutines have produced an infinite stream of integers, and our main function has simply destroyed the coroutine state after reading the first three integers. What if instead our coroutine only wants to produce a finite number of values before signaling an end-of-coroutine condition?&lt;/p&gt;&lt;p&gt;To signal the end of a coroutine, C++ adds a new &lt;code&gt;co_return&lt;/code&gt;
operator. There are three ways for a coroutine to signal that it is
complete:&lt;/p&gt;&lt;p&gt;The coroutine can use √¢&lt;code&gt;co_return e;&lt;/code&gt;√¢ to return a
final value &lt;code&gt;e&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The coroutine can use √¢&lt;code&gt;co_return&lt;/code&gt;;√¢ with no value (or
with a void expression) to end the coroutine without a final
value.&lt;/p&gt;&lt;p&gt;The coroutine can let execution fall off the end of the function, which is similar to the previous case.&lt;/p&gt;&lt;p&gt;In case 1, the compiler inserts a call to &lt;code&gt;p.return_value(e)&lt;/code&gt; on the promise object &lt;code&gt;p&lt;/code&gt;. In
cases 2√¢3, the compiler calls &lt;code&gt;p.return_void()&lt;/code&gt;. To find out
if a coroutine is complete, you can call &lt;code&gt;h.done()&lt;/code&gt; on its
coroutine handle &lt;code&gt;h&lt;/code&gt;. (Do not confuse
&lt;code&gt;coroutine_handle::done()&lt;/code&gt; with
&lt;code&gt;coroutine_handle::operator bool()&lt;/code&gt;. The latter merely checks
whether the coroutine handle contains a non-null pointer to coroutine
memory, not whether execution is complete.)&lt;/p&gt;&lt;p&gt;Here is a new version of counter in which the &lt;code&gt;counter&lt;/code&gt;
function itself decides to produce only 3 values, while the main
function just keeps printing values until the coroutine is done. There√¢s
one more change we need to make to
&lt;code&gt;promise_type::final_suspend()&lt;/code&gt;, but let√¢s first look at the
new code, then discuss the promise object below.&lt;/p&gt;&lt;code&gt;struct ReturnObject5 {
struct promise_type {
   unsigned value_;
     
~promise_type() {
     std::cout &amp;lt;&amp;lt; "promise_type destroyed" &amp;lt;&amp;lt; std::endl;
       }
     () {
     ReturnObject5 get_return_objectreturn {
       .h_ = std::coroutine_handle&amp;lt;promise_type&amp;gt;::from_promise(*this)
         };
       }
     std::suspend_never initial_suspend() { return {}; }
     std::suspend_always final_suspend() noexcept { return {}; }
     void unhandled_exception() {}
     std::suspend_always yield_value(unsigned value) {
     value_ = value;
       return {};
       }
     void return_void() {}
     };
   
std::coroutine_handle&amp;lt;promise_type&amp;gt; h_;
   };


 ReturnObject5()
 counter5{
for (unsigned i = 0; i &amp;lt; 3; ++i)
   co_yield i;
     // falling off end of function or co_return; =&amp;gt; promise.return_void();
   // (co_return value; =&amp;gt; promise.return_value(value);)
   }

void
()
 main5{
auto h = counter5().h_;
   auto &amp;amp;promise = h.promise();
   while (!h.done()) { // Do NOT use while(h) (which checks h non-NULL)
   std::cout &amp;lt;&amp;lt; "counter5: " &amp;lt;&amp;lt; promise.value_ &amp;lt;&amp;lt; std::endl;
     ();
     h}
   .destroy();
   h}&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;counter5: 0
counter5: 1
counter5: 2
promise_type destroyed&lt;/code&gt;
&lt;p&gt;There are a couple of things to note about &lt;code&gt;co_return&lt;/code&gt;.
Notice that in previous examples, we didn√¢t have a
&lt;code&gt;return_void()&lt;/code&gt; method on our promise object. That√¢s okay as
long as we didn√¢t use &lt;code&gt;co_return&lt;/code&gt;. Otherwise, if you use
&lt;code&gt;co_return&lt;/code&gt; but don√¢t have the appropriate
&lt;code&gt;return_void&lt;/code&gt; or &lt;code&gt;return_value&lt;/code&gt; method, you will
get a compilation error about the missing method. That√¢s the good news.
The bad news is that if you fall off the end of a function and your
&lt;code&gt;promise_type&lt;/code&gt; lacks a &lt;code&gt;return_void&lt;/code&gt; method, you
get undefined behavior. I√¢ll have more to say about that in
the editorial below, but suffice it to say that undefined behavior is
really, really bad√¢like use-after-free or array-bounds-overflow bad. So
be careful not to drop off the end of a coroutine whose promise object
lacks a &lt;code&gt;return_void&lt;/code&gt; method!&lt;/p&gt;&lt;p&gt;The other thing to note about &lt;code&gt;co_return&lt;/code&gt; is that
&lt;code&gt;promise_type::return_void()&lt;/code&gt; and
&lt;code&gt;promise_type::return_value(v)&lt;/code&gt; both return
&lt;code&gt;void&lt;/code&gt;; in particular they don√¢t return awaitable objects.
This is presumably out of a desire to unify handling of return values
and exceptions (which we√¢ll discuss further down). Nonetheless, there√¢s
an important question about what to do at the end of a coroutine. Should
the compiler update the coroutine state and suspend the coroutine one
final time, so that even after evaluating &lt;code&gt;co_return&lt;/code&gt;, code
in the main function can access the promise object and make sane use of
the &lt;code&gt;coroutine_handle&lt;/code&gt;? Or should returning from a coroutine
automatically destroy the coroutine state, like an implicit call to
&lt;code&gt;coroutine_handle::destroy()&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;This question is resolved by the &lt;code&gt;final_suspend&lt;/code&gt; method on
the &lt;code&gt;promise_type&lt;/code&gt;. The C++ spec says
says that a coroutine√¢s function-body is effectively wrapped in
the following pseudo-code:&lt;/p&gt;&lt;code&gt;{
     -type promise promise-constructor-arguments ;
         promisetry {
         co_await promise.initial_suspend() ;
             -body
             function} catch ( ... ) {
         if (!initial-await-resume-called)
             throw ;
                 .unhandled_exception() ;
             promise}
         final-suspend :
     co_await promise.final_suspend() ;
         }
     // "The coroutine state is destroyed when control flows
     //  off the end of the coroutine"     &lt;/code&gt;&lt;p&gt;When a coroutine returns, you implicitly &lt;code&gt;co_await&lt;/code&gt; the
result of &lt;code&gt;promise.final_suspend()&lt;/code&gt;. If
&lt;code&gt;final_suspend&lt;/code&gt; actually suspends the coroutine, then the
coroutine state will be updated one last time and remain valid, and code
outside of the coroutine will be responsible for freeing the coroutine
object by calling the coroutine handle√¢s &lt;code&gt;destroy()&lt;/code&gt; method.
If &lt;code&gt;final_suspend&lt;/code&gt; does not suspend the coroutine,
then the coroutine state will be automatically destroyed.&lt;/p&gt;&lt;p&gt;If you never plan to touch the coroutine state again (maybe because the coroutine just updated some global variable and/or released a semaphore before &lt;code&gt;co_return&lt;/code&gt;, and that√¢s all you care about),
then there√¢s no reason to pay for saving state one last time and worry
about manually freeing the coroutine state, so you can have
&lt;code&gt;final_suspend()&lt;/code&gt; return &lt;code&gt;std::suspend_never&lt;/code&gt;. On
the other hand, if you need to access the coroutine handle or promise
object after a coroutine returns, you will need
&lt;code&gt;final_suspend()&lt;/code&gt; to return &lt;code&gt;std::suspend_always&lt;/code&gt;
(or some other awaitable object that suspends the coroutine).&lt;/p&gt;&lt;p&gt;To make the point more concrete, here√¢s what happens if we change &lt;code&gt;ReturnObject5::promise_type::final_suspend()&lt;/code&gt; to return
&lt;code&gt;std::suspend_never&lt;/code&gt; instead of
&lt;code&gt;std::suspend_always&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;counter5: 0
counter5: 1
counter5: 2
promise_type destroyed
counter5: 2
Segmentation fault&lt;/code&gt;
&lt;p&gt;The first &lt;code&gt;co_yield&lt;/code&gt; (before the loop in
&lt;code&gt;main5&lt;/code&gt; even starts) yields 0. The second and third
&lt;code&gt;co_yield&lt;/code&gt;s, which correspond to the first and second times
we resume &lt;code&gt;h&lt;/code&gt; in &lt;code&gt;main5&lt;/code&gt;, yield 1 and 2 without
issue. The third time we resume &lt;code&gt;h&lt;/code&gt;, however, execution falls
off the end of the coroutine, destroying the coroutine state. We see
that the &lt;code&gt;promise_type&lt;/code&gt; gets destroyed at this point, leaving
&lt;code&gt;h&lt;/code&gt; effectively a dangling pointer. Yet we call
&lt;code&gt;h.done()&lt;/code&gt; on this dangling pointer, provoking undefined
behavior. On my machine, the undefined behavior happens to be
&lt;code&gt;h.done()&lt;/code&gt; returning false. That causes &lt;code&gt;main5&lt;/code&gt; to
stay in the loop and call &lt;code&gt;h()&lt;/code&gt; once again, only this time it
is resuming garbage instead of a valid coroutine state. Not
surprisingly, resuming garbage doesn√¢t update
&lt;code&gt;promise.value_&lt;/code&gt;, which remains 2. Also not surprisingly,
since we are provoking more and more undefined behavior, our program
soon crashes.&lt;/p&gt;&lt;p&gt;Now we have almost all of the pieces to build a generic generator type, which is the most popular example of C++ coroutines you will find on the web. There are just a couple of remaining topics to cover.&lt;/p&gt;&lt;p&gt;First, up to this point I have been glossing over exceptions. Once a coroutine has been suspended, so you are no longer waiting for the initial call (e.g., &lt;code&gt;counter()&lt;/code&gt;) to return, resuming a
coroutine no longer automatically throws an exception in the main
function. Instead, it calls the &lt;code&gt;unhandled_exception()&lt;/code&gt;
method of the promise object. Arguably, we should have been calling
&lt;code&gt;std::terminate()&lt;/code&gt; in that function all along for our
examples. (As it is, we suppress any exceptions with an empty function,
which makes throwing an exception in a coroutine equivalent to
&lt;code&gt;co_return;&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;If we want to build a generic generator return object type to help people write coroutines, the most useful approach to exceptions is arguably to re-throw them in the main routine that invokes the generator. We can do that by having &lt;code&gt;unhandled_exception()&lt;/code&gt;
call &lt;code&gt;std::current_exception&lt;/code&gt;
to obtain a &lt;code&gt;std::exception_ptr&lt;/code&gt;
that it stores in the promise object. When this
&lt;code&gt;execption_ptr&lt;/code&gt; is non-NULL, the generator uses &lt;code&gt;std::rethrow_exception&lt;/code&gt;
to propagate the exception in the main function.&lt;/p&gt;&lt;p&gt;Another important point is that up until now, our coroutines have been computing the first value (0) as soon as they are invoked, before the first &lt;code&gt;co_await&lt;/code&gt;, and hence before the return object is
constructed. There are two reasons you might want to defer computation
of the first value until after the first coroutine suspension. First, in
cases where values are expensive to compute, it may be better to save
work in case the coroutine is never resumed (perhaps because of an error
in a different coroutine). Second, because of the need to destroy
coroutine handles manually, things can get awkward if a coroutine throws
an exception before the first time it has been suspended. Take the
following example:&lt;/p&gt;&lt;code&gt;void
()
 f{
std::vector&amp;lt;std::coroutine_handle&amp;lt;&amp;gt;&amp;gt; coros =
   { mkCoroutineA(), mkCoroutineB() };
     try {
   for (int i = 0; i &amp;lt; 3; ++i)
     for (auto &amp;amp;c : coros)
       if (!c.done())
         ();
           c}
   catch (...) {
   for (auto &amp;amp;c : coros)
     .destroy();
       cthrow;
     }
   for (auto &amp;amp;c : coros)
   .destroy();
     c}&lt;/code&gt;&lt;p&gt;In the example above, suppose &lt;code&gt;mkCoroutineA()&lt;/code&gt; returns a
coroutine handle while &lt;code&gt;mkCoroutineB()&lt;/code&gt; throws an exception
before its first &lt;code&gt;co_await&lt;/code&gt;. In that case, the coroutine
created by &lt;code&gt;mkCoroutineA()&lt;/code&gt; will never be destroyed. Of
course, you could restructure the code to wrap &lt;code&gt;mkCoroutineB&lt;/code&gt;
in it√¢s own try-catch block, but you can see this would quickly get
unwieldy when creating many coroutines.&lt;/p&gt;&lt;p&gt;To address these issues, the method &lt;code&gt;promise_type::initial_suspend()&lt;/code&gt; can return
&lt;code&gt;std::suspend_always&lt;/code&gt;, thereby suspending
&lt;code&gt;mkCoroutineB&lt;/code&gt; immediately on entry, before any code in the
coroutine has executed (and hence before said code may throw an
exception). We use this technique in our example generator below. It
simply means we have to resume the coroutine once before returning the
first value from our generator.&lt;/p&gt;&lt;p&gt;So here is our generic generator. A generator producing type &lt;code&gt;T&lt;/code&gt; must return a &lt;code&gt;Generator&amp;lt;T&amp;gt;&lt;/code&gt;. The main
function uses &lt;code&gt;operator bool&lt;/code&gt; to determine if the
&lt;code&gt;Generator&lt;/code&gt; still has an output value, and
&lt;code&gt;operator()&lt;/code&gt; to obtain the next value.&lt;/p&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
struct Generator {
struct promise_type;
   using handle_type = std::coroutine_handle&amp;lt;promise_type&amp;gt;;
   
struct promise_type {
   value_;
     T std::exception_ptr exception_;
     
() {
     Generator get_return_objectreturn Generator(handle_type::from_promise(*this));
       }
     std::suspend_always initial_suspend() { return {}; }
     std::suspend_always final_suspend() noexcept { return {}; }
     void unhandled_exception() { exception_ = std::current_exception(); }
     template&amp;lt;std::convertible_to&amp;lt;T&amp;gt; From&amp;gt; // C++20 concept
     std::suspend_always yield_value(From &amp;amp;&amp;amp;from) {
     value_ = std::forward&amp;lt;From&amp;gt;(from);
       return {};
       }
     void return_void() {}
     };
   
handle_type h_;
   
(handle_type h) : h_(h) {}
   Generator(const Generator &amp;amp;) = delete;
   Generator~Generator() { h_.destroy(); }
   explicit operator bool() {
   ();
     fillreturn !h_.done();
     }
   operator()() {
   T ();
     fillfull_ = false;
     return std::move(h_.promise().value_);
     }
   
private:
bool full_ = false;
   
void fill() {
   if (!full_) {
     h_();
       if (h_.promise().exception_)
       std::rethrow_exception(h_.promise().exception_);
         full_ = true;
       }
     }
   };

&amp;lt;unsigned&amp;gt;
 Generator()
 counter6{
for (unsigned i = 0; i &amp;lt; 3;)
   co_yield i++;
     }

void
()
 main6{
auto gen = counter6();
   while (gen)
   std::cout &amp;lt;&amp;lt; "counter6: " &amp;lt;&amp;lt; gen() &amp;lt;&amp;lt; std::endl;
     }&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;code&gt;counter6: 0
counter6: 1
counter6: 2&lt;/code&gt;
&lt;p&gt;One final point to note here is that we now destroy the &lt;code&gt;coroutine_hande&lt;/code&gt; inside the destructor for
&lt;code&gt;Generator&lt;/code&gt;, since in our specific use case we know the
coroutine handle is no longer needed once the &lt;code&gt;Generator&lt;/code&gt; is
gone.&lt;/p&gt;&lt;p&gt;You probably already got the sense that I√¢m happy to see coroutines in C++, but sad that the design was so clunky. I think the &lt;code&gt;co_await&lt;/code&gt; operator is reasonably well thought out, but the
return object design is a complete mess. All you really need is
something simple: simultaneous access to local variables in the
coroutine and the coroutine handle while creating the return object. Yet
the interfaces are both convoluted and prevent you from
accessing all the necessary variables at the same time.&lt;/p&gt;&lt;p&gt;Obviously I√¢ve only thought about C++ coroutines for a couple of days, but it seems to me that the fundamental interface should have been two operators, &lt;code&gt;co_await&lt;/code&gt; (more or less as-is) and
&lt;code&gt;co_init&lt;/code&gt; for allocating the coroutine handle and creating
the return object. &lt;code&gt;std::coroutine_handle&lt;/code&gt; should not even
need to be a template, as any notion of a promise object should just be
layered on top of whatever primitives the language provides. Something
like:&lt;/p&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
struct Yield {
*target_;
   T (T &amp;amp;t) : target_(&amp;amp;t) {}
   Yieldstd::suspend_always operator()(const T &amp;amp;t) { *target_ = t; }
   std::suspend_always operator()(T &amp;amp;&amp;amp;t) { *target_ = std::move(t); }
   };

template&amp;lt;typename T, bool Suspend = true&amp;gt;
struct ResumeWith {
value_;
   T (const T &amp;amp;v) : value_(v) {}
   ResumeWith(T &amp;amp;&amp;amp;v) : value_(std::move(v)) {}
   ResumeWithconstexpr bool await_ready() const noexcept { return !Suspend; }
   void await_suspend(std::coroutine_handle) {}
   () { return std::move(value_); }
   T await_resume};

struct HypotheticalReturnObject {
std::coroutine_handle h;
   bool done = false;
   unsigned val;
   
&amp;lt;Yield&amp;lt;unsigned&amp;gt;&amp;gt; operator co_init(std::coroutine_handle hh) {
   ResumeWith= hh;
     h return ResumeWith(Yield(val));
     }
   std::suspend_always operator co_return() {
   = true;
     done return {};
     }
   };

&amp;amp;
 HypotheticalReturnObject ()
 hypothetical_counter{
auto yield = co_init HypotheticalReturnObject{};
   
for (unsigned i = 0; i &amp;lt; 3; ++i)
   co_await yield(i);
     }&lt;/code&gt;&lt;p&gt;But with this design, you√¢d have more flexibility. For instance you could alternatively declare &lt;code&gt;unsigned i&lt;/code&gt; first, and stick the
address &lt;code&gt;&amp;amp;i&lt;/code&gt; inside the return object, because everything
is in scope when you are constructing the return object.&lt;/p&gt;&lt;p&gt;Obviously this isn√¢t perfect, as I just started looking at C++ coroutines and am ignorant of the design history. The hypothetical design doesn√¢t tell you what to do about exceptions. Still, I have a hard time believing it√¢s not possible to do a lot better than the current design, and come up with something involving fewer and simpler low-level concepts that are nonetheless more expressive.&lt;/p&gt;&lt;p&gt;Another source of clunkiness that really baffles me is the undefined behavior when falling off the end of a coroutine without a &lt;code&gt;return_void()&lt;/code&gt; method on the promise object. Undefined
behavior is incredibly bad. Why would you do this to programmers? The
only justification I can think of is cases where the programmer knows
execution will not fall off the end of a function, but the compiler
can√¢t figure it out. In those cases, the compiler might need to generate
a few bytes of dead code to handle the impossible case. But even if it√¢s
so important to optimize that fringe case, don√¢t make undefined behavior
the default! For example, why not allow the &lt;code&gt;[[noreturn]]&lt;/code&gt;
tag on coroutines, or allow a coroutine to end with a
&lt;code&gt;[[fallthrough]];&lt;/code&gt; statement, and say the behavior is
undefined only when you fall off the end of a coroutine and one of these
tags is present? That would satisfy the tiny minority of people who need
to optimize this case without creating easy opportunities for the vast
majority of programmers to shoot themselves in the foot.&lt;/p&gt;&lt;p&gt;Big picture, of course, clunky coroutines are still a lot better than no coroutines. I anticipate C++20 coroutines will significantly change the way I program going forward, and may prove an even bigger deal than lambda expressions.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45842815</guid><pubDate>Fri, 07 Nov 2025 02:03:57 +0000</pubDate></item><item><title>A Fond Farewell</title><link>https://www.farmersalmanac.com/fond-farewell-from-farmers-almanac</link><description>&lt;doc fingerprint="af1c94b70bdeca9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Fond Farewell&lt;/head&gt;
    &lt;head rend="h2"&gt;The season we hoped would never come is here.&lt;/head&gt;
    &lt;p&gt;Dear Friends,&lt;/p&gt;
    &lt;p&gt;It is with a great appreciation and heartfelt emotions that we write to share some sad news. After more than 200 years of sharing a unique blend of weather, wit and wisdom, we‚Äôve made the very difficult decision to write the final chapter of this historical publication. The 2026 Farmers‚Äô Almanac will be our last edition.&lt;/p&gt;
    &lt;p&gt;Many of you grew up hearing your parents or grandparents quote from the Almanac, always having a copy nearby. Maybe you have planted by our Moon phases, consulted the Almanac for the ‚ÄúBest Days‚Äù to potty train, wean, or go fishing. We‚Äôre grateful to have been part of your life and trust that you‚Äôll help keep the spirit of the Almanac alive.&lt;/p&gt;
    &lt;p&gt;We are incredibly proud of the legacy we leave behind and are filled with gratitude. We appreciate and thank our loyal readers, contributors, and partners who have supported us through the years. Though the Almanac will no longer be available in print or online, it lives on within you.&lt;/p&gt;
    &lt;p&gt;So go ahead‚Äîplant your peas when the daffodils bloom. Watch for a red sky at night. Tell the kids how granddad always swore by the Almanac. That‚Äôs how our story stays alive.&lt;/p&gt;
    &lt;p&gt;With deepfelt appreciation,&lt;/p&gt;
    &lt;p&gt;Sandi Duncan and Peter Geiger&lt;lb/&gt;Editor and Editor Emeritus&lt;/p&gt;
    &lt;p&gt;P.S. Copies of the 2026 Farmers‚Äô Almanac are currently available on FarmersAlmanac.com, Amazon.com, and at these local stores. You will be able to access our website until December 2025. If you are a Member, please check your inbox for more information about your subscription.&lt;/p&gt;
    &lt;p&gt;This article was published by the Staff at FarmersAlmanac.com. If you have any questions about this article, please leave a comment for one of our experts. Priority is given to our Members, but all are welcome! You may also write in with your article ideas: [email protected].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843146</guid><pubDate>Fri, 07 Nov 2025 03:01:32 +0000</pubDate></item><item><title>JermCAD: Browser-Based CAD Software</title><link>https://github.com/jeremyaboyd/jerm-cad</link><description>&lt;doc fingerprint="ebb2b01edb97f3b8"&gt;
  &lt;main&gt;
    &lt;p&gt;A browser-based 3D CAD model renderer that lets you design 3D models using YAML syntax. Define geometric shapes, apply boolean operations, and visualize your designs in real-time with export capabilities.&lt;/p&gt;
    &lt;p&gt;Important Note: This project is almost entirely vibe-coded and likely contains loads of bugs. Use at your own risk!&lt;/p&gt;
    &lt;p&gt;I found learning traditional CAD software incredibly frustrating. Despite having experience with Blender, those skills didn't translate well to modern CAD solutions like Fusion 360, SolidWorks, or FreeCAD. I knew exactly what primitive solids I needed to create my complex models (spheres, cylinders, cuboids), and how to combine them with boolean operations, but I couldn't figure out the UIs.&lt;/p&gt;
    &lt;p&gt;Every tool seemed to have its own way of doing things, and terminologies and tools that felt completely alien. So I decided to build something different: a code-based CAD solution where I could express my design intent directly in YAML, using simple geometric primitives and operations I already understood.&lt;/p&gt;
    &lt;p&gt;JermCAD is the result: a tool vibe-coded by someone who needed CAD but didn't want to learn it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;YAML-Based Modeling: Define 3D models using simple YAML syntax&lt;/item&gt;
      &lt;item&gt;Multiple Shape Types: Cuboid, cylinder, cone, sphere, toroid, and extrusion shapes&lt;/item&gt;
      &lt;item&gt;Boolean Operations: Union, difference, and intersection operations&lt;/item&gt;
      &lt;item&gt;Stamps: Reusable parametric shape templates for complex assemblies&lt;/item&gt;
      &lt;item&gt;Property References: Reference properties from other solids to maintain alignment and consistency&lt;/item&gt;
      &lt;item&gt;3D Visualization: Interactive 3D viewer with camera controls&lt;/item&gt;
      &lt;item&gt;STL Export: Export your models for 3D printing&lt;/item&gt;
      &lt;item&gt;Coordinate System Support: Z-up (CAD convention) or Y-up (traditional 3D)&lt;/item&gt;
      &lt;item&gt;Wireframe Mode: Toggle wireframe view for better visualization&lt;/item&gt;
      &lt;item&gt;Real-time Rendering: See changes instantly as you edit&lt;/item&gt;
      &lt;item&gt;Quality Settings: Adjustable render quality for optimal performance (Low/Med/High/Ultra)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js (v14 or higher)&lt;/item&gt;
      &lt;item&gt;npm (Node Package Manager)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone or download this repository&lt;/item&gt;
      &lt;item&gt;Install dependencies: &lt;quote&gt;npm install&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Start the development server:&lt;/p&gt;
    &lt;code&gt;npm start&lt;/code&gt;
    &lt;p&gt;This will start a local server at &lt;code&gt;http://localhost:3001&lt;/code&gt; and automatically open it in your browser.&lt;/p&gt;
    &lt;p&gt;Alternatively, you can use:&lt;/p&gt;
    &lt;code&gt;npm run serve&lt;/code&gt;
    &lt;p&gt;This starts the server without automatically opening the browser.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Edit the YAML in the left panel editor&lt;/item&gt;
      &lt;item&gt;Click "Render Model" or press &lt;code&gt;Ctrl+Enter&lt;/code&gt;to render your changes&lt;/item&gt;
      &lt;item&gt;View your model in the 3D viewer on the right&lt;/item&gt;
      &lt;item&gt;Export as STL when ready using the "Export STL" button&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Left Mouse Drag: Rotate the camera around the model&lt;/item&gt;
      &lt;item&gt;Right Mouse Drag: Pan the view&lt;/item&gt;
      &lt;item&gt;Middle Mouse Drag: Pan the view (alternative)&lt;/item&gt;
      &lt;item&gt;Scroll Wheel: Zoom in/out&lt;/item&gt;
      &lt;item&gt;Reset Camera Button: Return to default view&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A basic model consists of:&lt;/p&gt;
    &lt;code&gt;settings:
    units: mm
    tolerance: 1e-3
    up: [0, 0, 1]  # Z-up (CAD convention) or [0, 1, 0] for Y-up
    debug: false   # Enable verbose console logging (default: false)

params:
    - $od: 10      # Outer diameter parameter
    - $id: 1       # Inner diameter parameter
    - $l: 20       # Length parameter
    - $cp: [5,5,5] # Center point parameter

materials:
    my_material:
        color: 0xff0000  # Hex color code
        opacity: 1.0     # 0.0 (transparent) to 1.0 (opaque)

solids:
    my_shape:
        shape: cuboid
        center: [0, 0, 0]
        size: [10, 8, 3]
        material: my_material  # Reference to material defined above

final:
    material: my_material  # Apply material to the final merged mesh
    # OR use direct properties:
    # color: 0x4287f5
    # opacity: 1.0&lt;/code&gt;
    &lt;p&gt;Root-level parameters allow you to define reusable variables that can be referenced throughout your model. This makes it easy to maintain consistent dimensions and update values in one place.&lt;/p&gt;
    &lt;p&gt;Syntax:&lt;/p&gt;
    &lt;code&gt;params:
    - $od: 10      # Parameter with $ prefix
    - $id: 1
    - $l: 20
    - $cp: [5,5,5] # Arrays are also supported&lt;/code&gt;
    &lt;p&gt;Usage in Solids: Parameters can be referenced in any property within any solid or stamp:&lt;/p&gt;
    &lt;code&gt;params:
    - $od: 10
    - $l: 20
    - $cp: [5,5,5]

solids:
    my_cylinder:
        shape: cylinder
        diameter: $od    # Uses $od = 10
        length: $l       # Uses $l = 20
        center: $cp      # Uses $cp = [5,5,5]
    
    another_shape:
        shape: cuboid
        size: [$od, $od, $l]  # Can be used in arrays too
        center: $cp&lt;/code&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Parameters defined in the &lt;code&gt;params&lt;/code&gt;section are available globally&lt;/item&gt;
      &lt;item&gt;Use &lt;code&gt;$paramName&lt;/code&gt;syntax to reference parameters (the&lt;code&gt;$&lt;/code&gt;prefix is removed when defining)&lt;/item&gt;
      &lt;item&gt;Parameters are substituted before any other processing (stamps, references, etc.)&lt;/item&gt;
      &lt;item&gt;Arrays and nested values are fully supported&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Centralized Values: Change a dimension once, update everywhere&lt;/item&gt;
      &lt;item&gt;Parametric Models: Create families of designs with different parameter values&lt;/item&gt;
      &lt;item&gt;Consistency: Ensure related shapes use the same dimensions&lt;/item&gt;
      &lt;item&gt;Easy Iteration: Adjust parameters quickly without hunting through code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Materials allow you to define reusable color and opacity settings that can be referenced by multiple solids.&lt;/p&gt;
    &lt;code&gt;materials:
    blue_plastic:
        color: 0x4287f5
        opacity: 1.0
    red_metal:
        color: 0xff0000
        opacity: 0.9
    transparent_glass:
        color: 0xffffff
        opacity: 0.5

solids:
    base:
        shape: cuboid
        center: [0, 0, 0]
        size: [10, 10, 5]
        material: blue_plastic  # Use the material defined above
    
    handle:
        shape: cylinder
        center: [0, 0, 5]
        diameter: 2
        length: 10
        material: red_metal  # Different material&lt;/code&gt;
    &lt;p&gt;Material Properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;color&lt;/code&gt;: Hex color code (e.g.,&lt;code&gt;0xff0000&lt;/code&gt;for red,&lt;code&gt;0x4287f5&lt;/code&gt;for blue)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;opacity&lt;/code&gt;: Number between 0.0 (fully transparent) and 1.0 (fully opaque)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using Materials vs Direct Properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can reference a material using &lt;code&gt;material: material_name&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;OR you can use direct &lt;code&gt;color&lt;/code&gt;and&lt;code&gt;opacity&lt;/code&gt;properties on the solid (backward compatible)&lt;/item&gt;
      &lt;item&gt;If both are specified, the material takes precedence&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;final&lt;/code&gt; section allows you to merge all visible meshes into a single final mesh and apply a material to it. This is useful when you want to show only the final result with a unified appearance.&lt;/p&gt;
    &lt;code&gt;final:
    material: blue_plastic  # Reference to a material
    # OR use direct properties:
    # color: 0x4287f5
    # opacity: 1.0&lt;/code&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;After all solids are created and boolean operations are applied, all visible meshes are merged into one&lt;/item&gt;
      &lt;item&gt;The material from the &lt;code&gt;final&lt;/code&gt;section is applied to this merged mesh&lt;/item&gt;
      &lt;item&gt;All individual meshes are hidden, showing only the final merged result&lt;/item&gt;
      &lt;item&gt;If no &lt;code&gt;final&lt;/code&gt;section is provided, individual meshes are shown as before&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;material&lt;/code&gt;: Name of a material defined in the&lt;code&gt;materials&lt;/code&gt;section&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;color&lt;/code&gt;: Hex color code (alternative to material)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;opacity&lt;/code&gt;: Number between 0.0 and 1.0 (alternative to material)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;my_box:
    shape: cuboid
    center: [0, 0, 0]
    size: [width, depth, height]
    material: my_material  # Reference to material, OR use direct properties:
    # color: 0xff0000  # Optional hex color (if no material specified)
    # opacity: 0.8     # Optional (0-1) (if no material specified)&lt;/code&gt;
    &lt;code&gt;my_cylinder:
    shape: cylinder
    center: [0, 0, 0]
    diameter: 5
    length: 10
    rotation: [90, 0, 0]  # Optional rotation in degrees [x, y, z]&lt;/code&gt;
    &lt;p&gt;Orientation: Cylinders are created with their bases perpendicular to the Z-axis by default (cylindrical axis along Z). This matches CAD conventions where Z is typically the vertical axis.&lt;/p&gt;
    &lt;code&gt;my_sphere:
    shape: sphere
    center: [0, 0, 0]
    diameter: 5&lt;/code&gt;
    &lt;code&gt;my_cone:
    shape: cone
    center: [0, 0, 0]
    diameter: 5        # Base diameter
    height: 10         # Height of the cone
    rotation: [90, 0, 0]  # Optional rotation in degrees [x, y, z]&lt;/code&gt;
    &lt;p&gt;Orientation: Cones are created with their base perpendicular to the Z-axis by default (cone axis along Z). This matches CAD conventions where Z is typically the vertical axis.&lt;/p&gt;
    &lt;code&gt;my_extrusion:
    shape: extrusion
    center: [0, 0, 0]
    profile:
        type: circle    # or rect, poly
        diameter: 3     # for circle
        # OR
        size: [2, 2]    # for rect [width, height]
        # OR
        points: [[0,0], [1,0], [1,1], [0,1]]  # for poly
    length: 5
    rotation: [90, 0, 0]&lt;/code&gt;
    &lt;p&gt;Boolean operations allow you to combine shapes using union, difference, and intersection. Operations are applied in the order listed.&lt;/p&gt;
    &lt;code&gt;base:
    shape: cuboid
    center: [0, 0, 0]
    size: [10, 10, 5]
    modifiers:
        boolean:
            - difference: cutout_shape

cutout_shape:
    shape: cuboid
    center: [0, 0, -1]
    size: [5, 5, 3]
    visible: false  # Hidden objects used only for boolean ops&lt;/code&gt;
    &lt;code&gt;base:
    shape: cuboid
    center: [0, 0, 0]
    size: [10, 10, 5]
    modifiers:
        boolean:
            - union: addon_shape

addon_shape:
    shape: cylinder
    center: [0, 0, 5]
    diameter: 3
    length: 2&lt;/code&gt;
    &lt;p&gt;You can chain multiple boolean operations:&lt;/p&gt;
    &lt;code&gt;base:
    shape: cuboid
    center: [0, 0, 0]
    size: [10, 10, 5]
    modifiers:
        boolean:
            - difference: cutout1
            - difference: cutout2
            - union: addon1
            - intersection: intersection_shape&lt;/code&gt;
    &lt;p&gt;All shapes support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;center: &lt;code&gt;[x, y, z]&lt;/code&gt;- Position of the shape&lt;/item&gt;
      &lt;item&gt;anchor: &lt;code&gt;[x, y, z]&lt;/code&gt;- Anchor point (values 0-1) that determines which point on the bounding box the center refers to. Default is&lt;code&gt;[0.5, 0.5, 0.5]&lt;/code&gt;(geometric center)&lt;/item&gt;
      &lt;item&gt;rotation: &lt;code&gt;[x, y, z]&lt;/code&gt;- Rotation in degrees around each axis&lt;/item&gt;
      &lt;item&gt;color: Hex color code (e.g., &lt;code&gt;0xff0000&lt;/code&gt;for red)&lt;/item&gt;
      &lt;item&gt;opacity: Number between 0 and 1&lt;/item&gt;
      &lt;item&gt;visible: &lt;code&gt;true&lt;/code&gt;or&lt;code&gt;false&lt;/code&gt;- Hide shapes used only for boolean operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;anchor&lt;/code&gt; property allows you to control which point on the shape's bounding box the &lt;code&gt;center&lt;/code&gt; position refers to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[0, 0, 0]&lt;/code&gt;- Bottom-left-back corner (minimum corner)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;[0.5, 0.5, 0.5]&lt;/code&gt;- Geometric center (default)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;[1, 1, 1]&lt;/code&gt;- Top-right-front corner (maximum corner)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;[0, 0.5, 0.5]&lt;/code&gt;- Bottom edge center&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;[1, 0, 0]&lt;/code&gt;- Top-left-back corner&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;box_at_corner:
    shape: cuboid
    size: [10, 10, 10]
    center: [0, 0, 0]
    anchor: [0, 0, 0]  # Position the bottom-left-back corner at [0, 0, 0]

box_at_top:
    shape: cuboid
    size: [10, 10, 10]
    center: [0, 0, 20]
    anchor: [0.5, 0.5, 1]  # Position the top face center at [0, 0, 20]&lt;/code&gt;
    &lt;p&gt;You can reference properties from other solids by using the solid name as a value. This allows you to keep related shapes aligned and maintain consistency across your model.&lt;/p&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When a solid name appears as a value, it automatically resolves to the corresponding property from that solid&lt;/item&gt;
      &lt;item&gt;In arrays, the reference resolves to the element at the same index position&lt;/item&gt;
      &lt;item&gt;References are resolved recursively, so you can chain references (A references B, B references C)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When a solid name appears in an array, it resolves to the corresponding array element from that solid's property:&lt;/p&gt;
    &lt;code&gt;cable_holder:
    center: [0, 0, 3]
    diameter: 5

cable_cutout:
    center: [0, 0, cable_holder]  # Gets cable_holder.center[2] = 3
    diameter: 3&lt;/code&gt;
    &lt;p&gt;In this example, &lt;code&gt;cable_cutout.center&lt;/code&gt; becomes &lt;code&gt;[0, 0, 3]&lt;/code&gt; because &lt;code&gt;cable_holder&lt;/code&gt; in the third position resolves to &lt;code&gt;cable_holder.center[2]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When a solid name is used as a direct property value, it resolves to the same property from that solid:&lt;/p&gt;
    &lt;code&gt;base_shape:
    center: [0, 0, 0]
    diameter: 10

aligned_shape:
    center: base_shape        # Gets base_shape.center = [0, 0, 0]
    diameter: base_shape      # Gets base_shape.diameter = 10&lt;/code&gt;
    &lt;p&gt;Aligning shapes:&lt;/p&gt;
    &lt;code&gt;base:
    center: [0, 0, 0]
    size: [10, 10, 5]

cover:
    center: [0, 0, base]  # Aligns cover's Z position with base's top (base.center[2] + base.size[2]/2)
    size: [10, 10, 1]&lt;/code&gt;
    &lt;p&gt;Reusing dimensions:&lt;/p&gt;
    &lt;code&gt;main_body:
    diameter: 20
    length: 50

inner_core:
    diameter: main_body      # Same diameter as main_body
    length: main_body        # Same length as main_body&lt;/code&gt;
    &lt;p&gt;Chained references:&lt;/p&gt;
    &lt;code&gt;base:
    center: [0, 0, 0]

middle:
    center: [0, 0, base]    # References base.center[2]

top:
    center: [0, 0, middle]  # References middle.center[2], which resolves through base&lt;/code&gt;
    &lt;p&gt;Note: References must point to existing solids. Circular references are detected and prevented to avoid infinite loops.&lt;/p&gt;
    &lt;p&gt;Stamps are reusable parametric shape templates that allow you to define complex assemblies once and instantiate them multiple times with different parameters, positions, and rotations. This reduces code duplication and makes models easier to maintain and modify.&lt;/p&gt;
    &lt;p&gt;Stamps are like "blueprints" for complex shapes or assemblies. Instead of defining the same combination of shapes multiple times, you define it once as a stamp and then instantiate it wherever needed. Stamps support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Parameters: Define variables like &lt;code&gt;$diameter&lt;/code&gt;and&lt;code&gt;$length&lt;/code&gt;that can be set per instance&lt;/item&gt;
      &lt;item&gt;Multiple Solids: A stamp can contain multiple solids that work together&lt;/item&gt;
      &lt;item&gt;Boolean Operations: Stamps can include internal boolean operations between their solids&lt;/item&gt;
      &lt;item&gt;Parent Modifiers: Apply boolean operations to the parent solid when the stamp is instantiated&lt;/item&gt;
      &lt;item&gt;Positioning: Each instance can be placed at different locations using &lt;code&gt;at&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Rotation: Each instance can be rotated independently using &lt;code&gt;rotate&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DRY Principle: Define once, use many times - reduces code duplication&lt;/item&gt;
      &lt;item&gt;Consistency: Ensure all instances of a shape are identical&lt;/item&gt;
      &lt;item&gt;Easy Updates: Change the stamp definition once, all instances update&lt;/item&gt;
      &lt;item&gt;Parametric Design: Create families of similar shapes with different sizes&lt;/item&gt;
      &lt;item&gt;Complex Assemblies: Build reusable components like joints, connectors, or mechanical parts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stamps follow a three-step process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define the stamp template with parameters and shapes&lt;/item&gt;
      &lt;item&gt;Instantiate the stamp on a solid with specific parameter values&lt;/item&gt;
      &lt;item&gt;Expand - the system automatically converts stamp instances into actual solids&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stamps are defined in a &lt;code&gt;stamps&lt;/code&gt; section at the root level of your YAML:&lt;/p&gt;
    &lt;code&gt;stamps:
    my_stamp:
        params: [$param1, $param2]  # Optional: define parameters
        solids:
            shape1:
                shape: sphere
                center: [0, 0, 0]
                diameter: $param1
            shape2:
                shape: cylinder
                center: [0, $param1 / 2, 0]
                diameter: $param2
                length: $param1
        parent:
            modifiers:
                boolean:
                    - union: shape1
                    - union: shape2&lt;/code&gt;
    &lt;p&gt;Stamp Structure:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;params&lt;/code&gt;: (Optional) Array of parameter names with&lt;code&gt;$&lt;/code&gt;prefix (e.g.,&lt;code&gt;[$diameter, $length]&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;solids&lt;/code&gt;: Dictionary of solids that make up the stamp (can reference parameters)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parent&lt;/code&gt;: (Optional) Modifiers to apply to the parent solid when instantiated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Parameter Expressions: Parameters can be used in mathematical expressions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;$diameter&lt;/code&gt;- Simple parameter reference&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$diameter * 0.75&lt;/code&gt;- Multiplication&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$diameter * 0.333 + $length / 2&lt;/code&gt;- Complex expressions with multiple operations&lt;/item&gt;
      &lt;item&gt;Expressions support &lt;code&gt;+&lt;/code&gt;,&lt;code&gt;-&lt;/code&gt;,&lt;code&gt;*&lt;/code&gt;,&lt;code&gt;/&lt;/code&gt;, and parentheses&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Shape Centers in Stamps:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shapes within stamps are defined relative to &lt;code&gt;[0, 0, 0]&lt;/code&gt;(the stamp origin)&lt;/item&gt;
      &lt;item&gt;When instantiated, all shapes are translated to the &lt;code&gt;at&lt;/code&gt;position&lt;/item&gt;
      &lt;item&gt;If rotation is specified, shapes rotate around the stamp origin before translation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the &lt;code&gt;stamps&lt;/code&gt; property on any solid to instantiate stamp templates:&lt;/p&gt;
    &lt;code&gt;solids:
    my_part:
        shape: cuboid
        size: [10, 10, 10]
        stamps:
            instance1:
                stamp: my_stamp
                param1: 5
                param2: 3
                at: [0, 0, 5]
            instance2:
                stamp: my_stamp
                param1: 8
                param2: 4
                at: [10, 0, 5]
                rotate: [0, 0, 90]&lt;/code&gt;
    &lt;p&gt;Stamp Instance Properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;stamp&lt;/code&gt;: Name of the stamp to instantiate (required)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;at&lt;/code&gt;: Position&lt;code&gt;[x, y, z]&lt;/code&gt;where the stamp should be placed (default:&lt;code&gt;[0, 0, 0]&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rotate&lt;/code&gt;: Rotation&lt;code&gt;[x, y, z]&lt;/code&gt;in degrees around each axis (default:&lt;code&gt;[0, 0, 0]&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Any other properties: Parameter values (e.g., &lt;code&gt;diameter: 10&lt;/code&gt;,&lt;code&gt;length: 5&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Parameter Passing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Parameters can be passed by name: &lt;code&gt;diameter: 10&lt;/code&gt;matches&lt;code&gt;$diameter&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Parameters can be passed by position: If &lt;code&gt;params: [$diameter, $length]&lt;/code&gt;, first property becomes&lt;code&gt;$diameter&lt;/code&gt;, second becomes&lt;code&gt;$length&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;All properties except &lt;code&gt;stamp&lt;/code&gt;,&lt;code&gt;at&lt;/code&gt;, and&lt;code&gt;rotate&lt;/code&gt;are treated as parameters&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a complete example showing a parametric ball joint stamp:&lt;/p&gt;
    &lt;code&gt;solids:
    chest:
        shape: cuboid
        center: [0, 0, 0]
        size: [10, 20, 35]
        stamps:
            shoulder_joint_left:
                stamp: balljoint
                diameter: 10
                length: 5
                at: [0, 6, 13]
            shoulder_joint_right:
                stamp: balljoint
                diameter: 10
                length: 5
                at: [0, -6, 13]
                rotate: [0, 0, 180]  # Rotate 180¬∞ around Z axis

stamps:
    balljoint:
        params: [$diameter, $length]
        solids:
            outer:
                shape: sphere
                center: [0, 0, 0]
                diameter: $diameter
                modifiers:
                    boolean:
                        - difference: inner_cutout
                        - difference: inner_cutout2
            inner_cutout:
                shape: sphere
                center: [0, 0, 0]
                diameter: $diameter * 0.75
            inner_cutout2:
                shape: sphere
                center: [0, $diameter * 0.5, 0]
                diameter: $diameter * 0.75
            inner:
                shape: sphere
                center: [0, 0, 0]
                diameter: $diameter * 0.667
                modifiers:
                    boolean:
                        - union: inner_arm
            inner_arm:
                shape: cylinder
                center: [0, $diameter * 0.333 + $length / 2, 0]
                diameter: $diameter * 0.2
                length: $length
        parent:
            modifiers:
                boolean:
                    - union: outer
                    - difference: inner_cutout
                    - difference: inner_cutout2&lt;/code&gt;
    &lt;p&gt;What Happens:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The &lt;code&gt;balljoint&lt;/code&gt;stamp defines a parametric joint with 5 shapes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;shoulder_joint_left&lt;/code&gt;instantiates it at&lt;code&gt;[0, 6, 13]&lt;/code&gt;with&lt;code&gt;diameter=10&lt;/code&gt;,&lt;code&gt;length=5&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;shoulder_joint_right&lt;/code&gt;instantiates the same stamp at&lt;code&gt;[0, -6, 13]&lt;/code&gt;with 180¬∞ rotation&lt;/item&gt;
      &lt;item&gt;The system expands each instance into actual solids with unique names like &lt;code&gt;chest_shoulder_joint_left_outer&lt;/code&gt;,&lt;code&gt;chest_shoulder_joint_right_outer&lt;/code&gt;, etc.&lt;/item&gt;
      &lt;item&gt;Parent modifiers are applied to the &lt;code&gt;chest&lt;/code&gt;solid, performing boolean operations with the stamp shapes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stamp shapes are expanded into the &lt;code&gt;solids&lt;/code&gt;section with unique names based on the parent solid and instance name&lt;/item&gt;
      &lt;item&gt;All shapes in a stamp rotate together around the stamp's origin before translation&lt;/item&gt;
      &lt;item&gt;Boolean operations within stamps are resolved before parent modifiers&lt;/item&gt;
      &lt;item&gt;Stamps can reference other stamps (nested stamps)&lt;/item&gt;
      &lt;item&gt;Parameter values can be numbers or mathematical expressions&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;settings:
    units: mm
    tolerance: 1e-3
    up: [0, 0, 1]  # Z-up

solids:
    base:
        shape: cuboid
        center: [0, 0, 0]
        size: [10, 8, 3]
        modifiers:
            boolean:
                - difference: base_cutout
                - union: cable_holder
    
    base_cutout:
        shape: cuboid
        center: [0, 0, -1]
        size: [9, 7, 1.5]
        visible: false
    
    cable_holder:
        shape: cylinder
        center: [0, 0, 3]
        diameter: 5
        length: 3
        modifiers:
            boolean:
                - difference: cable_cutout
    
    cable_cutout:
        shape: cylinder
        center: [0, 0, cable_holder]  # References cable_holder.center[2] = 3
        diameter: 3
        length: 5.5
        visible: false&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dependency Resolution: The system automatically resolves dependencies for boolean operations. Solids referenced in boolean operations are created first.&lt;/item&gt;
      &lt;item&gt;Property References: Use property references to keep related shapes aligned. For example, &lt;code&gt;center: [0, 0, cable_holder]&lt;/code&gt;automatically aligns the Z position with&lt;code&gt;cable_holder.center[2]&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Invisible Solids: Set &lt;code&gt;visible: false&lt;/code&gt;on shapes used only for boolean operations to keep them hidden in the viewer.&lt;/item&gt;
      &lt;item&gt;Performance: Complex models with many boolean operations may take longer to render. Be patient! Use the quality dropdown to adjust render quality for better performance during editing.&lt;/item&gt;
      &lt;item&gt;Keyboard Shortcut: Use &lt;code&gt;Ctrl+Enter&lt;/code&gt;in the editor to quickly render your model.&lt;/item&gt;
      &lt;item&gt;Debug Mode: Set &lt;code&gt;debug: true&lt;/code&gt;in settings to enable verbose console logging. This will show detailed information about each solid being created, its dependencies, boolean operations, and processing steps. Useful for troubleshooting complex models.&lt;/item&gt;
      &lt;item&gt;STL Export Quality: STL exports always use ultra quality (256 segments) for maximum detail, regardless of your current viewport quality setting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Click the "Export STL" button to download your model as an STL file, ready for 3D printing or use in other CAD software.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fillet Modifier: Not yet implemented&lt;/item&gt;
      &lt;item&gt;STL Export: May create non-manifold edges. Most slicers can repair these automatically, but manual fixes may be needed for complex models.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fillet: Round edges and corners of shapes&lt;/item&gt;
      &lt;item&gt;Chamfer: Bevel edges at specific angles&lt;/item&gt;
      &lt;item&gt;Array: Create multiple copies of solids in patterns (linear, circular, etc.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User Accounts: Save your models to your account for easy access across devices&lt;/item&gt;
      &lt;item&gt;Global Models Library: Community-driven library where users can submit and use shared models&lt;/item&gt;
      &lt;item&gt;Model Import: Reference models from your account or the global library&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example of future import syntax:&lt;/p&gt;
    &lt;code&gt;solids:
    snake:
        import: snake_straight.stl
        stamps:
            articulation_array:
                import: stamps_articulations.yaml
                stamp: balljoint
                diameter: 10
                length: 4
                at: [0, -100, 0]
                modifiers:
                    - array: 
                        - count: 10  # how many copies
                        - gap: 30    # how many units between
                        - direction: [0, 1, 0]&lt;/code&gt;
    &lt;p&gt;Found a bug or have a feature request? Please submit an issue! Your feedback helps improve JermCAD for everyone.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model not rendering? Check your YAML syntax for errors. The error panel will display specific issues.&lt;/item&gt;
      &lt;item&gt;Boolean operations not working? Ensure all referenced solids are defined in the &lt;code&gt;solids&lt;/code&gt;section. Enable&lt;code&gt;debug: true&lt;/code&gt;in settings to see detailed console output about dependency resolution and boolean operations.&lt;/item&gt;
      &lt;item&gt;Camera stuck? Use the "Reset Camera" button to return to default view.&lt;/item&gt;
      &lt;item&gt;Performance issues? Try simplifying your model or reducing the number of boolean operations.&lt;/item&gt;
      &lt;item&gt;Need more information? Enable debug mode (&lt;code&gt;debug: true&lt;/code&gt;in settings) and check the browser console (F12) for detailed logging about solid creation, dependencies, and processing steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Three.js: 3D graphics library&lt;/item&gt;
      &lt;item&gt;three-bvh-csg: Constructive Solid Geometry operations&lt;/item&gt;
      &lt;item&gt;js-yaml: YAML parsing&lt;/item&gt;
      &lt;item&gt;Cursor: Vibe-coding IDE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ISC License&lt;/p&gt;
    &lt;p&gt;Copyright 2025 Jeremy A Boyd&lt;/p&gt;
    &lt;p&gt;Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.&lt;/p&gt;
    &lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843603</guid><pubDate>Fri, 07 Nov 2025 04:38:40 +0000</pubDate></item><item><title>Leaving Meta and PyTorch</title><link>https://soumith.ch/blog/2025-11-06-leaving-meta-and-pytorch.md.html</link><description>&lt;doc fingerprint="257951fc50a504c0"&gt;
  &lt;main&gt;**Leaving Meta and PyTorch**
It's finally time...
November 6th, 2025
[https://soumith.ch/blog.html](https://soumith.ch/blog.html)
Eleven years at Meta. Nearly all my professional life. Making many friends for life. Almost eight years leading PyTorch, taking it from nothing to 90%+ adoption in AI. Walking away from this was one of the hardest things I've ever done. But I'm leaving with a full heart.
PyTorch handles exascale training now. It powers foundation models that are redefining intelligence. It's in production at virtually every major AI company. It's taught in classrooms from MIT to rural India. The tools I dreamed about making accessible? They are. The barrier to entry I wanted to lower? It's almost gone.
To be clear, there‚Äôs so much more to do. As long as AI evolves at a breakneck pace, PyTorch will continue to play catch up. Obsessing over the yet-to-come sometimes makes us forget how much we‚Äôve already done.
To everyone who built this with me‚Äîwho believed research should be joyful, that tools should be elegant, that open source changes everything‚Äîthank you. This wasn't my journey. It was ours.
What's next for me? Something small. Something new. Something I don't fully understand yet. Something uncomfortable. I could have moved to something else inside Meta. But I needed to know what's out there. I needed to do something small again. I couldn't live with the counterfactual regret of never trying something outside Meta.
It's very hard to leave. I probably have one of the AI industry‚Äôs most leveraged seats, I lead the software layer that powers the entire AI industry. Every major AI company and hardware vendor are on a speed dial. This kind of power is really hard to give up. But curiosity ultimately won out in my head.
Keep making AI delicious and accessible. I'll be watching. Probably filing issues. Definitely staying involved.
# Is PyTorch going to be okay?
I don't want to be doing PyTorch forever. I don't want to be like Guido or Linus‚Äî bound to a single thing for decades. Last November, coinciding with the birth of my daughter, I started planning my exit with Aparna. My goal was to leave PyTorch in a good and stable place.
By this August, during the second half of my parental leave, I knew: Edward, Suo, Alban, Greg, John, Joe and Jana were ready. The team faced hard people, product, technical and organizational problems and didn‚Äôt feel the need to lean back on me to solve these for them (unlike in the past). The product story they crafted for the PyTorch Conference was coherent‚Äîreally coherent. The things I'd flagged red were turning healthy. The project didn't need me anymore. Unlike 2020-2022 (when I stepped down to go do robotics and came back when Lin, Dima and Dwarak left), I have strong confidence that this time PyTorch is truly resilient. The most aligned culture carriers of PyTorch ‚Äì Greg, Alban, Ed, Jason and Joe are at the decision table now, and people with strong value alignment ‚Äì Suo, John and Jana have joined them at the table. And there‚Äôs a long list of equally value-aligned people willing to sit at the table should any of these people leave. There are many little things that make up my confidence on the people ‚Äì John worked on Julia and open-source for a very long time (in fact we hacked a Torch.jl in 2015), Suo has been the strongest systems builder and strategic partner I‚Äôve had for the past two years, and Jana worked on resilient core systems for a very long time, I‚Äôve had long technical and organizational discussions with her over the past few months that give me confidence. And the product lineup and execution in 2025 should be sufficient evidence for any remaining doubt.
I‚Äôm confident that this band of PyTorchers are going to do exceptionally well. PyTorch might change in flavor because I no longer impose my own taste from the top, but I‚Äôm confident that the values are going to stay intact and the product is going to be awesome.
---
# My time at Meta
The early years of FAIR were absolutely magical. I was part of a small family of absolutely brilliant people building state-of-the-art AI out in the open. From working on GANs with Emily Denton, Rob Fergus, Leon Bottou, Martin Arjovsky and the (now legendary) Alec Radford to building Starcraft bots with Gabriel Synnaeve, to building the first FAIR Cluster with Howard Mansell, to working on object detection with Adam Lerer and Piotr Dollar, to building PyTorch. It was more fun than I can describe in words. 2015 and 2016 were probably the most productive and professionally enjoyable years of my life. I‚Äôll probably romanticize this period of my life forever.
When I joined FAIR, I had massive impostor syndrome, and the first 3 months were very very difficult. I can‚Äôt credit Andrew Tulloch enough for being the most thoughtful, kind and welcoming mentor, without whom I wouldn‚Äôt have made it. I‚Äôm so damn bullish for Meta just from the fact that he‚Äôs back.
---
My time on PyTorch was special.
I loved every part of building it‚Äîdesigning it, managing it, being the PM, TL, comms lead, doc engineer, release engineer, squashing bugs, growth hacking, turning it into a coherent product with hundreds of people, transitioning it to industry stakeholdership ‚Äì the whole nine yards.
To the core PyTorch team at Meta: the engineers, researchers, open-source maintainers, docs writers, CI infrastructure folks, hardware partners, the community builders. To the hundreds more inside and outside Meta‚Äîthank you. You turned a library into a movement.
There are too many people to credit and thank, but I can't not mention Adam Paszke, Sam Gross, Greg Chanan, Joe Spisak, Alban Desmaison, Edward Yang, Richard Zou, Tongzhou Wang, Francisco Massa, Luca Antiga, Andreas K√∂pf, Zach DeVito, Zeming Lin, Adam Lerer, Howard Mansell and Natalia Gimelshein. And Schrep. They made the launch happen. And so many more people became centrally important later: Lu Fang, Xiaodong Wang, Junjie Bai, Nikita Shulga, Horace He, Mark Saroufim, Jason Ansel, Dmytro Dzhulgakov, Yangqing Jia, Geeta Chauhan, Will Constable, Briah Hirsh, Jane Xu, Mario Lezcano, Piotr Balecki, Yinghai Lu, Less Wright, Andrew Tulloch, Bruce Lin, Woo Kim, Helen Suk, Chris Gottbrath, Peng Wu, Joe Isaacson, Eli Uriegas, Tristan Rice, Yanan Cao, Elias Ellison, Animesh Jain, Peter Noordhuis, Tianyu Liu, Yifu Wang, Lin Qiao and hundreds more. It‚Äôs criminal of me to not take the space to list out everyone else I should be mentioning here. PyTorch is nothing without its people ‚ù§Ô∏è.
The most joyful moments of building PyTorch was meeting users eager to share their happiness, love and feedback. I remember a grad student coming to me at Neurips 2017, in a slurring emotional voice he said he‚Äôd been trying to make progress on his research for 3 years but within 3 months of using PyTorch he made so much progress that he was ready to graduate. That moment made it tangible that what we do matters, a lot, to a lot of people, even if you don't constantly hear from them. I do miss the intimacy of the PyTorch community, with a 300 person conference that felt like an extended family gathering, but I feel that‚Äôs a small price to pay considering the scale of impact PyTorch is truly having today ‚Äì yes the Conference is now 3,000 people where market-moving deals get brokered, but it‚Äôs helping orders of magnitude more people to do their best AI work. I miss the intimacy, but I'm proud of that growth.
---
To Mark Zuckerberg and Mike Schroepfer, who believed that open-sourcing is fundamentally important and is a sound business strategy. This is so hard to understand for most people within the course of business, but we‚Äôve run lock-step on this strategy without ever having to discuss it. Without you two, neither FAIR nor PyTorch would‚Äôve happened. And those mean so much to me.
To Yann LeCun and Rob Fergus, for building the magical early FAIR that I so revere.
To Aparna Ramani, a leader that I find so rare at Meta in her ability to hold a really high bar for the org, technically brilliant with the span to discuss deep infra systems and industry-strategy within the same conversation and for being an absolute execution-machine! I‚Äôve learned so much from you.
To Santosh, Kaushik, Delia, Oldham and Ben for being so welcoming to Infra. For someone coming over from FAIR with a wildly different culture, you all made me feel at home and made me part of the family, and thank you for that.
To all my managers who've championed me through the PSC video game ‚Äì Serkan, Howard, Jerome, Abhijit, Yoram, Joelle, Aparna and Damien ‚Äì I owe you a lifetime of drinks.
---
Signing off for now.
‚ÄîSoumith&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843948</guid><pubDate>Fri, 07 Nov 2025 06:14:50 +0000</pubDate></item><item><title>Photoroom (YC S20) Is Hiring a Senior AI Front End Engineer in Paris</title><link>https://jobs.ashbyhq.com/photoroom/7644fc7d-7840-406d-a1b1-b9d2d7ffa9b8</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45844151</guid><pubDate>Fri, 07 Nov 2025 07:00:02 +0000</pubDate></item><item><title>Lessons from Growing a Piracy Streaming Site</title><link>https://prison.josh.mn/lessons</link><description>&lt;doc fingerprint="fcf119996d3f26ce"&gt;
  &lt;main&gt;
    &lt;p&gt;There are some contemporary piracy services that run ads‚Äîfor marketing and, well, advertising purposes. This ranges from PPC to social media campaigns. I opted not to, mostly because I didn't think I could do it tastefully, and because I'd probably attract users who wouldn't be great customers.&lt;/p&gt;
    &lt;p&gt;Instead, my marketing relied entirely on word-of-mouth‚Äîwhich meant building tremendous trust with my users, plus a single growth hack that I'll describe later on this page.&lt;/p&gt;
    &lt;p&gt;This is all fairly standard startup knowledge‚ÄîI've worked with more than a handful of Y Combinator companies and I could apply this to all of them‚Äîbut it's interesting to see how many parallels existed between what I built and what a "real" startup looks like.&lt;/p&gt;
    &lt;p&gt;I learned a lot about running a business while operating HeheStreams: customer experience, retention, product design, and the weird parallels between illegal streaming and your typical B2C.&lt;/p&gt;
    &lt;p&gt;Think of this as a founder postmortem with felony-level customer support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons from Growing a B2C&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;noreply@&lt;/code&gt;is absolutely stupid.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I did everything I could to be visible to customers and encouraged them to talk to me any time. That helped build trust in a product sitting in a sea of shady, fly-by-night operations. I ended every email with some variation of "If you need anything, just reply :)".&lt;/p&gt;
    &lt;p&gt;Get customers started.&lt;/p&gt;
    &lt;p&gt;After a user subscribed, I sent a sequence of onboarding emails to make sure they were actually using the site: After three days, I'd check whether they'd watched anything and ask if they needed help; after they watched n minutes, I'd send an NPS-style survey ("1‚Äì10, how likely are you to recommend...") and if they gave a 9 or 10, I'd invite them to leave a review; if they didn't watch anything within two weeks, I offered a refund and suggestions on where else to watch.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Send fun emails.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My copywriting was tongue-in-cheek and self-deprecating. It was all me, no bullshit. I treated every message‚Äîeven transactional emails‚Äîas an opportunity to build trust. Users regularly told me they actually enjoyed reading my emails, which is not a thing that should happen.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Be honest about service availability.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If things went sideways, I owned it. No hiding behind "maintenance windows."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A customer with a bad taste in their mouth is bad.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If someone used their entire subscription and then asked for a refund, I'd still honor it‚Äîno questions asked. My users were shockingly honest, and I rarely dealt with chargebacks. My abuse detector barely had to do anything over 66 months.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It's okay to be direct about churn.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'd send messages like, "Hey, I saw you didn't renew. Did you find a good place to watch? Anything I could've done better?" People usually responded‚Äînicely, even.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Recommend your competitors if you have to.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If a user wasn't a good fit, I happily pointed them toward alternatives. It built credibility, even if it lost me a sale.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You don't need to target everyone.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I intentionally priced higher than competitors. That filtered in customers who were more tech-savvy and saw HeheStreams as an "investment in their leisure time," not a "cost."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Be great at one thing, and half-assed at nothing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I never added generic IPTV or random channels. I focused purely on sports. That probably left money on the table, but it kept quality high.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Say no.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Say no a lot. Customers can be stupid.&lt;/p&gt;
    &lt;head rend="h2"&gt;The growth hack&lt;/head&gt;
    &lt;p&gt;My proudest growth hack involved Reddit's API. I filtered posts mentioning phrases like "NBA League Pass," "blackouts," or "where to" on team-specific subreddits. Then I gave my users lists of those posts and encouraged them to comment‚Äîtransparently‚Äîabout why they liked HeheStreams, including their referral link.&lt;/p&gt;
    &lt;p&gt;Each referrer got a $10 credit per subscriber, and new subscribers got $10 off their next month. It worked well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons still work&lt;/head&gt;
    &lt;p&gt;I've applied these same principles to a Mexican ecotourism business with great success. Some of them will never scale to hundreds of thousands of customers (you can't automate personality or hire for charm), but they work beautifully for small, honest teams. That's enough for me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why word-of-mouth beats ads (especially when you can't run ads)&lt;/head&gt;
    &lt;p&gt;I believe that trust mechanics are reflections of self. If they're artificial, people will see right through them.&lt;/p&gt;
    &lt;head rend="h2"&gt;The takeaway&lt;/head&gt;
    &lt;p&gt;Wouldn't trade the lessons; would strongly advise against the exit strategy. "Acquired" by Alliance for Creativity/Motion Picture Association.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45844197</guid><pubDate>Fri, 07 Nov 2025 07:09:30 +0000</pubDate></item><item><title>A startup‚Äôs quest to store electricity in the ocean</title><link>https://techcrunch.com/2025/10/22/one-startups-quest-to-store-electricity-in-the-ocean/</link><description>&lt;doc fingerprint="66d2204732f42ce9"&gt;
  &lt;main&gt;
    &lt;p&gt;When Manuele Aufiero was a child, his parents would take him hiking along a reservoir in northern Italy. It wasn‚Äôt a typical reservoir, though. This one drained and refilled constantly, with pumps raising the water level when electricity was cheap. When nearby cities needed electricity, the pumps would reverse, turning into generators as the water drained out of the reservoir.&lt;/p&gt;
    &lt;p&gt;The technology, known as pumped-storage hydropower, or ‚Äúpumped hydro‚Äù for short, has been around for over a century. Such facilities are some of the biggest ‚Äúbatteries‚Äù humans have ever built. Globally, pumped hydro reservoirs store 8,500 gigawatt-hours of electricity, according to the International Energy Agency.&lt;/p&gt;
    &lt;p&gt;Pumped hydro can generate electricity for hours on end, and the power plants have grown in importance as intermittent energy sources like wind and solar have become more widespread. But there are only so many places on Earth with suitable topography to host a pumped hydro reservoir.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm in love with pumped hydro,‚Äù Aufiero told TechCrunch. ‚ÄúIt‚Äôs just not enough to keep up with renewables.‚Äù&lt;/p&gt;
    &lt;p&gt;So he decided to solve that problem by moving the technology to the sea. He co-founded a startup, Sizable Energy, to turn his idea into reality.&lt;/p&gt;
    &lt;p&gt;Sizable recently raised $8 million in a funding round led by Playground Global with participation from EDEN/IAG, Exa Ventures, Satgana, Unruly Capital, and Verve Ventures, the company exclusively told TechCrunch.&lt;/p&gt;
    &lt;p&gt;The startup‚Äôs power plant looks something like an hourglass. Sizable‚Äôs concept specifies two sealed, flexible reservoirs, one that floats at the top and another that sits at the bottom on the seabed. They‚Äôre connected by a plastic tube and some turbines.&lt;/p&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages ‚Äî part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages ‚Äî part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;p&gt;When power is cheap, the turbines will pump super salty water from the bottom reservoir to the top. When the grid needs energy, Sizable will open a valve, and because the water in the reservoir contains more salt than the surrounding seawater, it‚Äôs heavier and will fall down to the lower reservoir. As it flows through the pipe, it spins the turbines, which act as generators.&lt;/p&gt;
    &lt;p&gt;‚ÄúFrom the energy balance point of view, what we are doing is lifting a block of salt. But instead of using cranes, we dissolve it and pump it just because it‚Äôs easier, simpler,‚Äù Aufiero said. ‚ÄúOther than that, we are just lifting a heavy amount of salt.‚Äù&lt;/p&gt;
    &lt;p&gt;By moving pumped hydro to the ocean, Sizable is hoping to mass-produce the technology, something that isn‚Äôt really possible on land.&lt;/p&gt;
    &lt;p&gt;‚ÄúEvery time you build pumped hydro on shore, you have to design a concrete dam for that specific site, and you have to adapt the technology there,‚Äù Aufiero said. ‚ÄúBuilding offshore allows us to streamline the production, and everything we do is identical, regardless of the final deployment site.‚Äù&lt;/p&gt;
    &lt;p&gt;Sizable has tested a small model of the reservoirs in wave tanks and off the coast of Reggio Calabria, Italy. It‚Äôs now deploying a pilot of the floating components in advance of a full demonstration plant. By 2026, it‚Äôs hoping to deploy several commercial projects at sites around the world.&lt;/p&gt;
    &lt;p&gt;At full size, the turbines would generate around 6 to 7 megawatts of electricity each, and there will be one for every 100 meters of pipe. Deeper sites would have more storage potential, and each commercial site would host multiple reservoirs. Sizable hopes to deliver energy storage for ‚Ç¨20 per kilowatt-hour (about $23), about one-tenth what a grid-scale battery costs.&lt;/p&gt;
    &lt;p&gt;The technology would pair well with offshore wind projects since sharing an electrical connection to the shore would reduce costs. But Aufiero said that Sizable‚Äôs reservoirs could connect to any grid that‚Äôs near waters that are at least 500 meters (1,640 feet) deep.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe believe that long duration energy storage is required not only for renewable integration, but also for just making the grid resilient,‚Äù he said. ‚ÄúThere is no way we can keep up with that with traditional pumped hydro or batteries. We need something new.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45844655</guid><pubDate>Fri, 07 Nov 2025 08:50:14 +0000</pubDate></item></channel></rss>