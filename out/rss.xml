<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 26 Sep 2025 23:09:15 +0000</lastBuildDate><item><title>Fast UDP I/O for Firefox in Rust</title><link>https://max-inden.de/post/fast-udp-io-in-firefox/</link><description>&lt;doc fingerprint="9cacf1177618bfaa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Motivation&lt;/head&gt;
    &lt;p&gt;Around 20% of Firefox’s HTTP traffic today uses HTTP/3, which runs over QUIC, which in turn runs over UDP. This translates to substantial UDP I/O activity.&lt;/p&gt;
    &lt;p&gt;Firefox uses NSPR for most of its network I/O. When it comes to UDP I/O, NSPR only offers a limited set of dated APIs, most relevant here &lt;code&gt;PR_SendTo&lt;/code&gt; and &lt;code&gt;PR_RecvFrom&lt;/code&gt;, wrappers around POSIX’s &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt;.
The N in NSPR stands for Netscape, giving you a hint of its age.&lt;/p&gt;
    &lt;p&gt;Operating systems have evolved since. Many offer multi-message APIs like &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt;.
Some offer segmentation offloading like GSO (Generic Segmentation Offload) and GRO (Generic Receive Offload).
Each of these promise significant performance improvements for UDP I/O.&lt;/p&gt;
    &lt;p&gt;Can Firefox benefit from replacing its aging UDP I/O stack with modern system calls?&lt;/p&gt;
    &lt;head rend="h2"&gt;Overview&lt;/head&gt;
    &lt;p&gt;This project began in mid-2024 with the goal of rewriting Firefox’s QUIC UDP I/O stack using modern system calls across all supported operating systems. Beyond performance improvements, we wanted to increase security by using a memory-safe language to do UDP I/O. Firefox’s QUIC state machine itself is implemented in Rust already. We thereby chose Rust for this project as well, giving us both increased security and easy integration with the existing QUIC codebase.&lt;/p&gt;
    &lt;p&gt;Instead of starting from scratch, we built on top of &lt;code&gt;quinn-udp&lt;/code&gt;, the UDP I/O library of the Quinn project, a QUIC implementation in Rust.
This sped up our development efforts significantly.
Big thank you to the Quinn project.
Operating system calls are complex, with a myriad of idiosyncrasies, especially across versions.
Firefox is multi-platform, focusing on Windows, Android, MacOS and Linux as tier 1.
The main complexity though stems from Firefox supporting ancient versions of each of them, e.g.
Android 5.&lt;/p&gt;
    &lt;p&gt;One year later, i.e., mid 2025, this project is now rolling out to the majority of Firefox users. Performance benchmark results are promising. In extreme cases, on purely CPU bound benchmarks, we’re seeing a jump from &amp;lt; 1Gbit/s to 4 Gbit/s. Looking at CPU flamegraphs, the majority of CPU time is now spent in I/O system calls and cryptography code.&lt;/p&gt;
    &lt;p&gt;Below are the many improvements we were able to land, plus the ones we weren’t. I hope other projects in need of fast UDP I/O can benefit from our work. To make their lifes easier, below I am documenting the many learnings we made.&lt;/p&gt;
    &lt;head rend="h2"&gt;The basics&lt;/head&gt;
    &lt;p&gt;To understand the improvements, it’s helpful to first examine how UDP I/O traditionally works and how modern optimizations change this picture.&lt;/p&gt;
    &lt;head rend="h3"&gt;Single datagram&lt;/head&gt;
    &lt;p&gt;Previously Firefox would send (and receive) single UDP datagrams to (and from) the OS via &lt;code&gt;sendto&lt;/code&gt; (and &lt;code&gt;recvfrom&lt;/code&gt;) system call family.
The OS would send (and receive) that UDP datagram to (and from) the network interface card (NIC).
The NIC would send (and receive) it to (and from) the Internet.&lt;/p&gt;
    &lt;p&gt;Thus each datagram would require leaving user space which is cheap for one UDP datagram, but expensive when sending at say a 500 Mbit/s rate. In addition all user space and kernel space overhead independent of the number of bytes sent and received, is paid per datagram, i.e. per &amp;lt; 1500 bytes.&lt;/p&gt;
    &lt;code&gt;    +----------------------+
    |       Firefox        |
    |    +-----------+     |
    |    |   QUIC    |     |
    |    +-----------+     |
    +----------------------+
              |
         [ datagram ]
              |
    === User / Kernel ===
              |
         [ datagram ]
              |
    +----------------------+
    |         OS           |
    +----------------------+
              |
         [ datagram ]
              |
    +----------------------+
    |         NIC          |
    +----------------------+
              |
         [ datagram ]
              |
    +----------------------+
    |      Internet        |
    +----------------------+
&lt;/code&gt;
    &lt;head rend="h3"&gt;Batch of datagrams&lt;/head&gt;
    &lt;p&gt;Instead of sending a single datagram at a time, some operating systems nowadays offer multi-message system call families, e.g. on Linux &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt;.
The idea is simple.
Send and receive multiple UDP datagrams at once, save on the costs that are independent of the number of bytes sent and received.&lt;/p&gt;
    &lt;code&gt;    +--------------------------+
    |         Firefox          |
    |      +-----------+       |
    |      |   QUIC    |       |
    |      +-----------+       |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    ===== User / Kernel =====
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |           OS             |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |           NIC            |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |        Internet          |
    +--------------------------+
&lt;/code&gt;
    &lt;head rend="h3"&gt;Single large segmented datagram&lt;/head&gt;
    &lt;p&gt;Some modern operating systems and network interface cards also support system call families with UDP segmentation offloading, e.g. &lt;code&gt;GSO&lt;/code&gt; and &lt;code&gt;GRO&lt;/code&gt; on Linux.
Instead of sending multiple UDP datagrams in a batch, it enables the application to send a single large UDP datagram, i.e. larger than the Maximum Transmission Unit, to the kernel.
Next, either the kernel, but really ideally the network interface card, will segment it into multiple smaller packets, add a header to each and calculates the UDP checksum.
The reverse happens on the receive path, where multiple incoming packets can be coalesced into a single large UDP datagram delivered to the application all at once.&lt;/p&gt;
    &lt;code&gt;    +------------------------------+
    |           Firefox            |
    |        +-----------+         |
    |        |   QUIC    |         |
    |        +-----------+         |
    +------------------------------+
                    |
      [ large segmented datagram ]
                    |
      ====== User / Kernel ======
                    |
      [ large segmented datagram ]
                    |
    +------------------------------+
    |             OS               |
    +------------------------------+
                    |
      [ large segmented datagram ]
                    |
    +------------------------------+
    |             NIC              |
    +------------------------------+
                    |
    [ datagram, datagram, datagram ]
                    |
    +------------------------------+
    |          Internet            |
    +------------------------------+
&lt;/code&gt;
    &lt;p&gt;Note: Unfortunately, Wireshark does not yet support GSO, making network-level debugging more challenging when these optimizations are active.&lt;/p&gt;
    &lt;p&gt;For performance analysis of these different approaches, Cloudflare’s comprehensive study provides excellent benchmarks and detailed explanations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replacing NSPR in Firefox&lt;/head&gt;
    &lt;p&gt;Batching and segmentation offloading aside for now, first step in the project was to replace usage of NSPR with quinn-udp, still sending and receiving one UDP datagram at a time. We updated the Mozilla QUIC client and server test implementation, then integrated quinn-udp into Firefox itself.&lt;/p&gt;
    &lt;p&gt;Next we rewrote the UDP datagram processing pipeline in the Mozilla QUIC implementation to send and receive batches of datagrams. This is done in a way, such that we can leverage both the multi-message style system calls, as well as the segmentation offloading style, if available. We added this along with various other I/O improvements, e.g. Lars added in-place en-/decryption. Going into detail here is better done in a separate blog post. Let’s focus on UDP I/O here.&lt;/p&gt;
    &lt;p&gt;So far so good. This was the easy part. Up next, the edge cases by platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Platform details&lt;/head&gt;
    &lt;head rend="h3"&gt;Windows&lt;/head&gt;
    &lt;p&gt;Windows offers &lt;code&gt;WSASendMsg&lt;/code&gt; and &lt;code&gt;WSARecvMsg&lt;/code&gt; to send and receive a single UDP datagram.
That UDP datagram can either be a classic MTU size datagram, or a large segmented datagram.
For the latter, what Linux calls &lt;code&gt;GSO&lt;/code&gt; and &lt;code&gt;GRO&lt;/code&gt;, Windows call &lt;code&gt;USO&lt;/code&gt; and &lt;code&gt;URO&lt;/code&gt;.
As described above, we started off rolling out quinn-udp using single-datagram system calls only.
This went without issues on Windows.&lt;/p&gt;
    &lt;p&gt;Next we tested &lt;code&gt;WSARecvMsg&lt;/code&gt; with &lt;code&gt;URO&lt;/code&gt;, i.e. receiving a batch of inbound datagrams as a single large segmented datagram, but got the following bug report:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;fosstodon.org doesn’t load with network.http.http3.use_nspr_for_io=false on ARM64 Windows&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;fosstodon is a Mastodon server. It is hosted behind the CDN provider Fastly. Fastly is a heavy user of Linux’s GSO, i.e. sends larger UDP datagram trains, perfect to be coalesced into a single large segmented UDP datagram when Firefox receives it. Why would Window’s &lt;code&gt;URO&lt;/code&gt; prevent Firefox from loading the site?&lt;/p&gt;
    &lt;p&gt;After many hours of back and forth with the reporter, luckily a Mozilla employee as well, I ended up buying the exact same laptop, same color, in a desperate attempt to reproduce the issue. Without much luck at first, I eventually needed a Linux command line tool, thus installed WSL, and to my surprise, that triggered the bug (reproducer). Turns out, on Windows on ARM, with WSL enabled, a &lt;code&gt;WSARecvMsg&lt;/code&gt; call with &lt;code&gt;URO&lt;/code&gt; would not return a segment size, thus Firefox was unable to differentiate a single datagram, from a single segmented datagram.
QUIC short header packets don’t carry a length, thus there is no way to tell where one QUIC packet ends and another starts, leading to the above page load failures.&lt;/p&gt;
    &lt;p&gt;We have been in touch with Microsoft since. No progress thus far. Thereby we are keeping &lt;code&gt;URO&lt;/code&gt; on Windows disabled in Firefox for now.&lt;/p&gt;
    &lt;p&gt;After &lt;code&gt;URO&lt;/code&gt; we started using &lt;code&gt;WSASendMsg&lt;/code&gt; &lt;code&gt;USO&lt;/code&gt;, i.e. sending a single large segmented datagram per system call.
But this too we rolled back quickly, seeing increased packet loss on Firefox Windows installations.
In addition, we have at least one report of a user, seeing their network driver crash due to Firefox’s usage of &lt;code&gt;USO&lt;/code&gt;.
More debugging needed.&lt;/p&gt;
    &lt;head rend="h3"&gt;MacOS&lt;/head&gt;
    &lt;p&gt;The transition on MacOS from NSPR to quinn-udp for HTTP/3 QUIC UDP I/O involved switching from the system calls &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt; to the system calls &lt;code&gt;sendmsg&lt;/code&gt; and &lt;code&gt;recvmsg&lt;/code&gt;.
As with Windows, no issues on this first step, ignoring one report where MacOS 10.15 might be seeing IP packets other than v4 and v6 (fixed since).&lt;/p&gt;
    &lt;p&gt;Unfortunately MacOS does not offer UDP segmentation offloading, neither on the send, nor on the receive side. What it does offer though are two undocumented system calls, namely &lt;code&gt;sendmsg_x&lt;/code&gt; and &lt;code&gt;recvmsg_x&lt;/code&gt;, allowing a user to send and receive batches of UDP datagrams at once.
Lars from Mozilla added it to quinn-udp, exposed behind the &lt;code&gt;fast-apple-datapath&lt;/code&gt; feature flag, off by default.
After multiple iterations with smaller bugfixes (#2154, #2214, #2216 …) we decided to not ship it to users, not knowing how MacOS would behave, in case Apple ever decides to remove it, but with Firefox still calling it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Linux&lt;/head&gt;
    &lt;p&gt;Linux provides the most comprehensive and mature UDP optimization support, offering both multi-message APIs (&lt;code&gt;sendmmsg&lt;/code&gt;/&lt;code&gt;recvmmsg&lt;/code&gt;) and segmentation offloading (GSO/GRO).
The quinn-udp library makes a deliberate choice to prioritize GSO over &lt;code&gt;sendmmsg&lt;/code&gt; for transmission, as GSO typically provides superior performance with diminishing returns when both techniques are combined.
Thus far, this has proven the right choice for Firefox as well.&lt;/p&gt;
    &lt;p&gt;In addition to segmentation offloading being superior in the first place, Firefox uses one UDP socket per connection in order to improve privacy. As each socket gets its own source port it is harder to correlate connections. Why is this relevant here? &lt;code&gt;GSO&lt;/code&gt; (and &lt;code&gt;GRO&lt;/code&gt;) can only segment (and coalesce) datagrams from the same 4-tuple (src IP, src port, dst IP, dst port), &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt; on the other hand can send and receive across 4-tuples.
Given that Firefox uses one socket per connection, it cannot make use of that distinct benefit of &lt;code&gt;sendmmsg&lt;/code&gt; (and &lt;code&gt;recvmmsg&lt;/code&gt;), making segmentation offloading yet again the obvious choice for Firefox.&lt;/p&gt;
    &lt;p&gt;Ignoring minor changes required to Firefox’s optional network sandboxing, and an additional at runtime GSO support check, replacing Firefox’s QUIC UDP I/O stack on Linux has been without issues, now enjoying all the benefits of segmentation offloading.&lt;/p&gt;
    &lt;head rend="h3"&gt;Android&lt;/head&gt;
    &lt;p&gt;During the time of this project I learned quickly that (a) Android is not Linux and (b) that Firefox still supports Android 5, …, on x86 (32 bit).&lt;/p&gt;
    &lt;p&gt;On x86, Android dispatches advanced socket calls through &lt;code&gt;socketcall&lt;/code&gt; system call instead of calling e.g. &lt;code&gt;sendmsg&lt;/code&gt; directly.
In addition Android has various default seccomp filters, crashing an app when e.g. not going through the required &lt;code&gt;socketcall&lt;/code&gt; system call.
The combination of the two did cost me a couple of days, resulting in this (basically single line) change in quinn-udp.&lt;/p&gt;
    &lt;p&gt;On Android API level 25 and below, calling &lt;code&gt;sendmsg&lt;/code&gt; with an ECN bit set results in an error &lt;code&gt;EINVAL&lt;/code&gt;.
quinn-udp will now simply retry on &lt;code&gt;EINVAL&lt;/code&gt; disabling various optional settings (e.g. ECN) on the second attempt.&lt;/p&gt;
    &lt;p&gt;Great benefit of the Quinn community is that Firefox will benefit from any improvements made to quinn-udp. For example this excellent find by Thomas where Android in some cases would complain if we did a &lt;code&gt;GSO&lt;/code&gt; with a single segment only.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explicit congestion notifications (ECN)&lt;/head&gt;
    &lt;p&gt;With Firefox using modern system calls across all major operating systems, a nice additional benefit is the ability to send and receive ancillary data like IP ECN. This too came with some minor surprises, but QUIC ECN in Firefox is well on its way now. Firefox Nightly telemetry shows around 50% of all QUIC connections running on ECN outbound capable paths. With L4S and thus ECN becoming more and more relevant in today’s Internet, this is a great step forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;We successfully replaced Firefox’s QUIC UDP I/O stack with a modern memory-safe implementation using quinn-udp. Instead of limited and dated system calls like &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt;, Firefox now uses modern OS specific system calls across all major platforms, resulting in HTTP/3 QUIC throughput improvements when CPU bound, and enabling QUIC ECN support across all major platforms.
Some OS specific optimizations still need more work, e.g. &lt;code&gt;USO&lt;/code&gt; and &lt;code&gt;URO&lt;/code&gt; on Windows.
That said, especially given QUIC’s growing adoption and thus increased UDP usage, I am optimistic that OS and driver support will continue to improve.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45387462</guid><pubDate>Fri, 26 Sep 2025 15:14:44 +0000</pubDate></item><item><title>Open Social</title><link>https://overreacted.io/open-social/</link><description>&lt;doc fingerprint="bd968b5388b80695"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;September 26, 2025&lt;/p&gt;
    &lt;p&gt;Open source has clearly won. Yes, there are plenty of closed source products and businesses. But the shared infrastructure—the commons—runs on open source.&lt;/p&gt;
    &lt;p&gt;We might take this for granted, but it wasn’t a foregone conclusion thirty five years ago. There were powerful forces that wanted open source to lose. Some believed in the open source model but didn’t think it could ever compete with closed source. Many categories of tools only existed as closed source. A Microsoft CEO called open source cancer—a decade before Microsoft has rebuilt its empire around it. The open source movement may not have lived up to the ideals of the “free software”, but it won in industry adoption. Nobody gets fired for choosing open source these days. For much crucial software, open source is now the default.&lt;/p&gt;
    &lt;p&gt;I believe we are at a similar juncture with social apps as we have been with open source thirty five years ago. There’s a new movement on the block. I like to call it “open social”. There are competing visions for what “open social” should be like. I think the AT Protocol created by Bluesky is the most convincing take on it so far. It’s not perfect, and it’s a work in progress, but there’s nothing I know quite like it.&lt;/p&gt;
    &lt;p&gt;(Disclosure: I used to work at Bluesky on the Bluesky client app. I wasn’t involved in the protocol design. I am a fan, and this post is my attempt to explain why.)&lt;/p&gt;
    &lt;p&gt;In this post, I’ll explain the ideas of the AT Protocol, lovingly called atproto, and how it changes the relationship between the user, the developer, and the product.&lt;/p&gt;
    &lt;p&gt;I don’t expect atproto and its ecosystem (known as the Atmosphere) to win hearts overnight. Like open source, it might take a few decades to become ubiquitous. By explaining these ideas here, I’m hoping to slightly nudge this timeline. Despite the grip of today’s social media companies, I believe open social will eventually seem inevitable in retrospect—just like open source does now. Good things can happen; all it takes is years of sustained effort by a community of stubborn enthusiasts.&lt;/p&gt;
    &lt;p&gt;So what is it all about?&lt;/p&gt;
    &lt;p&gt;What open source did for code, open social does for data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Before Social&lt;/head&gt;
    &lt;p&gt;The web is a beautiful invention.&lt;/p&gt;
    &lt;p&gt;You type &lt;code&gt;https://alice.com&lt;/code&gt; and you end up on Alice’s website.&lt;/p&gt;
    &lt;p&gt;Or you type &lt;code&gt;https://bob.com&lt;/code&gt; and you end up on Bob’s website.&lt;/p&gt;
    &lt;p&gt;In a sense, your browser is a portal to millions of different worlds, each with its own little jurisdiction. Only Alice decides what appears on Alice’s website. Only Bob decides what appears on Bob’s website. They meaningfully “own their data”.&lt;/p&gt;
    &lt;p&gt;This doesn’t mean that they’re isolated. On the contrary, Alice can embed Bob’s picture with an &lt;code&gt;&amp;lt;img src&amp;gt;&lt;/code&gt;, and Bob can link to Alice’s page with &lt;code&gt;&amp;lt;a href&amp;gt;&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Alice and Bob can link to each other, but they remain in charge of their sites.&lt;/p&gt;
    &lt;p&gt;What do I mean by saying Alice and Bob are in charge of their own sites? Even if they’re not physically hosting their content on their own computers, they could always change hosting. For example, if Alice’s hosting provider starts deleting her pages or injecting ads into them, Alice can take her content to another host, and point &lt;code&gt;https://alice.com&lt;/code&gt; at another computer. The visitors won’t need to know.&lt;/p&gt;
    &lt;p&gt;This is important. Hosting providers have no real leverage over Alice and Bob. If the hosting provider “turns evil” and starts messing with your site, you can just walk away and host it elsewhere (as long as you have a backup). You’re not going to lose your traffic. All existing links will seamlessly resolve to the new destination.&lt;/p&gt;
    &lt;p&gt;If Alice changes her hosting, Bob won’t need to update any links to Alice’s website. Alice’s site will keep working as if nothing had happened. At worst, a DNS change might make it inaccessible for a few hours, but then the web will be repaired:&lt;/p&gt;
    &lt;p&gt;Imagine how different the incentives would be if links were tied to physical hosts!&lt;/p&gt;
    &lt;p&gt;If changing a hosting provider caused Alice to lose her traffic, she would think many times before changing providers. Perhaps she’d stick with her existing provider even if it was messing with her site, as losing her connections is even worse. Luckily, web’s decentralized design avoids this. Because it’s easy to walk away, hosting providers are forced to compete, and hosting is now a commodity.&lt;/p&gt;
    &lt;p&gt;I think the web is a beautiful idea. It links decentralized islands controlled by different people and companies into one interconnected surface that anyone can index and navigate. Links describe a relationship between logical documents rather than between physical servers. As a result, you’re not a hostage to your hosting.&lt;/p&gt;
    &lt;p&gt;As a wise person said, in theory, there is no difference between theory and practice, but in practice there is. So what’s been happening with the web?&lt;/p&gt;
    &lt;head rend="h2"&gt;Closed Social&lt;/head&gt;
    &lt;p&gt;In the early 90’s, the main way to publish something on the web was to have your own website. Today, most people publish content by using a social media app.&lt;/p&gt;
    &lt;p&gt;Alice and Bob are still publishing things. But instead of publishing at domains like &lt;code&gt;alice.com&lt;/code&gt; and &lt;code&gt;bob.com&lt;/code&gt;, they publish at usernames like &lt;code&gt;@alice&lt;/code&gt; and &lt;code&gt;@bob&lt;/code&gt; allocated by a social media company. The things they publish are not HTML pages, but app-specific entities such as profiles, posts, comments, likes, and so on.&lt;/p&gt;
    &lt;p&gt;These entities are usually stored in a database on the social company’s servers. The most common way to visualize a database is as a sequence of rows, but you could also visualize it as a graph. This makes it look very similar to web itself:&lt;/p&gt;
    &lt;p&gt;What does this social graph enable that a web of personal sites doesn’t?&lt;/p&gt;
    &lt;p&gt;The advantage of storing structured app-specific entities, such as posts and likes, instead of HTML documents is obvious. App-specific entities such as posts and likes have a richer structure: you can always turn them into HTML documents later, but you can also aggregate them, filter them, query, sort, and recombine them in different ways before that. This allows you to create many projections of the same data—a profile page, a list of posts, an individual post with comments.&lt;/p&gt;
    &lt;p&gt;Where this really shines, though, is when many people use the same social app. Since everyone’s public content is now in a single database, it is easy to aggregate across content published by many people. This enables social features like global search, notifications, feeds, personalized algorithms, shared moderation, etc.&lt;/p&gt;
    &lt;p&gt;It’s specifically this social aggregation that blows the “personal sites” paradigm out of the water. People are social creatures, and we want to congregate in shared spaces. We don’t just want to visit each other’s sites—we want to hang out together, and social apps provide the shared infrastructure. Social aggregation features like notifications, feeds, and search are non-negotiable in modern social products.&lt;/p&gt;
    &lt;p&gt;Today, the most common way to implement these features is shaped like this:&lt;/p&gt;
    &lt;p&gt;There still exists a web-like logical model of our data—our profiles, our posts, our follows, our likes, all the things that we’ve created—but it lives within some social app’s database. What’s exposed to the web are only projections of that model—the Home screen, the Notifications screen, the HTML pages for individual posts.&lt;/p&gt;
    &lt;p&gt;This architecture makes sense. It is the easiest way to evolve the “personal sites” paradigm to support aggregation so it’s not surprising today’s apps have largely converged on it. People create accounts on social apps, which lets those apps build aggregated features, which entices more people to sign up for those apps.&lt;/p&gt;
    &lt;p&gt;However, something got lost in the process. The web we’re actually creating—our posts, our follows, our likes—is no longer meaningfully ours. Even though much of what we’re creating is public, it is not a part of the open web. We can’t change our “hosting provider” because we’re now one step removed from how the internet works. We, and the web we create, have become rows in somebody else’s database:&lt;/p&gt;
    &lt;p&gt;This creates an imbalance.&lt;/p&gt;
    &lt;p&gt;When Alice used to publish her stuff on &lt;code&gt;alice.com&lt;/code&gt;, she was not tied to any particular hosting provider. If she were unhappy with a hosting provider, she knew that she could swap it out without losing any traffic or breaking any links:&lt;/p&gt;
    &lt;p&gt;That kept the hosting providers in check.&lt;/p&gt;
    &lt;p&gt;But now that Alice publishes her stuff on a social media platform, she can no longer “walk away” without losing something. If she signs up to another social platform, she would be forced to start from scratch, even if she wants to retain her connections. There is no way for Alice to sever the relationship with a particular app without ripping herself, and anything she created there, out of its social graph:&lt;/p&gt;
    &lt;p&gt;The web Alice created—who she follows, what she likes, what she has posted—is trapped in a box that’s owned by somebody else. To leave it is to leave it behind.&lt;/p&gt;
    &lt;p&gt;On an individual level, it might not be a huge deal.&lt;/p&gt;
    &lt;p&gt;Alice can rebuild her social presence connection by connection somewhere else. Eventually she might even have the same reach as on the previous platform.&lt;/p&gt;
    &lt;p&gt;However, collectively, the net effect is that social platforms—at first, gradually, and then suddenly—turn their backs on their users. If you can’t leave without losing something important, the platform has no incentives to respect you as a user.&lt;/p&gt;
    &lt;p&gt;Maybe the app gets squeezed by investors, and every third post is an ad. Maybe it gets bought by a congolomerate that wanted to get rid of competition, and is now on life support. Maybe it runs out of funding, and your content goes down in two days. Maybe the founders get acquihired—an exciting new chapter. Maybe the app was bought by some guy, and now you’re slowly getting cooked by the algorithm.&lt;/p&gt;
    &lt;p&gt;If your next platform doesn’t respect you as a user, you might try to leave it, too.&lt;/p&gt;
    &lt;p&gt;But what are you going to do? Will you “export your data”? What will you do with that lonely shard of a social graph? You can upload it somewhere as an archive but it’s ripped out of its social context—a pitiful memento of your self-imposed exile.&lt;/p&gt;
    &lt;p&gt;Those megabytes of JSON you got on your way out are dead data. It’s like a branch torn apart from its tree. It doesn’t belong anywhere. To give a new life to our data, we’d have to collectively export it and then collectively import it into some next agreed-upon social app—a near-impossible feat of coordination. Even then, the network effects are so strong that most people would soon find their way back.&lt;/p&gt;
    &lt;p&gt;You can’t leave a social app without leaving behind the web you’ve created.&lt;/p&gt;
    &lt;p&gt;What if you could keep it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;Alice and Bob are still using social apps. Those apps don’t look much different from today’s social apps. You could hardly tell that something has changed.&lt;/p&gt;
    &lt;p&gt;Something has changed, though. (Can you spot it?)&lt;/p&gt;
    &lt;p&gt;Notice that Alice’s handle is now &lt;code&gt;@alice.com&lt;/code&gt;. It is not allocated by a social media company. Rather, her handle is the universal “internet handle”, i.e. a domain. Alice owns the &lt;code&gt;alice.com&lt;/code&gt; domain, so she can use it as a handle on any open social app. (On most open social apps, she goes by &lt;code&gt;@alice.com&lt;/code&gt;, but for others she wants a distinct disconnected identity, so she owns another handle she’d rather not share.)&lt;/p&gt;
    &lt;p&gt;Bob owns a domain too, even though he isn’t technical. He might not even know what a “domain” is. Bob just thinks of &lt;code&gt;@bob.com&lt;/code&gt; as his “internet handle”. Some open social apps will offer you a free subdomain on registration, just like Gmail gives you a free Gmail address, or may offer an extra flow for buying a domain. You’re not locked into your first choice, and can swap to a different domain later.&lt;/p&gt;
    &lt;p&gt;Your internet handle being something you actually own is the most user-visible aspect of open social apps. But the much bigger difference is invisible to the user.&lt;/p&gt;
    &lt;p&gt;When you previously saw the social graph above, it was trapped inside a social app’s database. There was a box around that graph—it wasn’t a part of the web. With open social, Alice’s data—her posts, likes, follows, etc—is hosted on the web itself. Alongside her personal site, Alice now has a personal repository of her data:&lt;/p&gt;
    &lt;p&gt;This “repository” is a regular web server that implements the AT Protocol spec. The only job of Alice’s personal repository is to store and serve data created by Alice in the form of signed JSON. Alice is technical, so she likes to sometimes inspect her repo using open source tools like pdsls, Taproot, or atproto-browser.&lt;/p&gt;
    &lt;p&gt;Bob, however, isn’t technical. He doesn’t even know that there is a “repository” with his “data”. He got a repository behind the scenes when he signed up for his first open social app. His repository stores his data (from all open social apps).&lt;/p&gt;
    &lt;p&gt;Have another look at this picture:&lt;/p&gt;
    &lt;p&gt;These aren’t rows in somebody’s database. This is a web of hyperlinked JSON. Just like every HTML page has an &lt;code&gt;https://&lt;/code&gt; URI so other pages can link to it, every JSON record has an &lt;code&gt;at://&lt;/code&gt; URI, so any other JSON record can link to it. (On this and other illustrations, &lt;code&gt;@alice.com&lt;/code&gt; is a shorthand for &lt;code&gt;at://alice.com&lt;/code&gt;.) The &lt;code&gt;at://&lt;/code&gt; protocol is a bunch of conventions on top of DNS, HTTP, and JSON.&lt;/p&gt;
    &lt;p&gt;Now have a look at the arrows between their records. Alice follows Bob, so she has a &lt;code&gt;follow&lt;/code&gt; record linking to Bob’s &lt;code&gt;profile&lt;/code&gt; record. Bob commented on Alice’s post, so he has a &lt;code&gt;comment&lt;/code&gt; record that links to Alice’s &lt;code&gt;post&lt;/code&gt; record. Alice liked his comment, so she has a &lt;code&gt;like&lt;/code&gt; record with a link to his &lt;code&gt;comment&lt;/code&gt; record. Everything Alice creates stays in her repo under her control, everything Bob creates stays in his repo under his control, and links express the connections—just like in HTML.&lt;/p&gt;
    &lt;p&gt;All of this happens behind the scenes and is invisibile to a non-technical user. The user doesn’t need to think about where their data is stored until it matters, just like the user doesn’t think about how servers work when navigating the web.&lt;/p&gt;
    &lt;p&gt;Alice’s and Bob’s repositories could be hosted on the same machine. Or they could be hosted by different companies or communities. Maybe Alice is self-hosting her repository, while Bob uses a free hosting service that came by default with his first open social app. They may even be running completely different implementations. If both servers follow the AT protocol, they can participate in this web of JSON.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;https://alice.com&lt;/code&gt; and &lt;code&gt;at://alice.com&lt;/code&gt; do not need to resolve to the same server. This is intentional so that having a nice handle like &lt;code&gt;@alice.com&lt;/code&gt; doesn’t force Alice to host her own data, to mess with her website, or even to have a site at all. If she owns &lt;code&gt;alice.com&lt;/code&gt;, she can point &lt;code&gt;at://alice.com&lt;/code&gt; at any server.&lt;/p&gt;
    &lt;p&gt;If Alice is unhappy with her hosting, she can pack up and leave:&lt;/p&gt;
    &lt;p&gt;(This requires a modicum of technical skill today but it’s getting more accessible.)&lt;/p&gt;
    &lt;p&gt;Just like with moving a personal site, changing where her repo is being served from doesn’t require cooperation from the previous host. It also doesn’t disrupt her ability to log into apps and doesn’t break any links. The web repairs itself:&lt;/p&gt;
    &lt;p&gt;It is worth pausing for a moment to appreciate what we have here.&lt;/p&gt;
    &lt;p&gt;Every bit of public data that Alice and Bob created—their posts, their likes, their comments, their recipes, their scrobbles—is meaningfully owned by them. It’s not in a database subject to some CEO’s whims, but hosted directly on the open web, with ability to “walk away” without losing traffic or breaking any links.&lt;/p&gt;
    &lt;p&gt;Like the web of personal sites, this model is centered around the user.&lt;/p&gt;
    &lt;p&gt;What does it mean for apps?&lt;/p&gt;
    &lt;p&gt;Each open social app is like a CMS (content management system) for a subset of data that lives in its users’ repositories. In that sense, your personal repository serves a role akin to a Google account, a Dropbox folder, or a Git repository, with data from your different open social apps grouped under different “subfolders”.&lt;/p&gt;
    &lt;p&gt;When you make a post on Bluesky, Bluesky puts that post into your repo:&lt;/p&gt;
    &lt;p&gt;When you star a project on Tangled, Tangled puts that star into your repo:&lt;/p&gt;
    &lt;p&gt;When you create a publication on Leaflet, Leaflet puts it in your repo:&lt;/p&gt;
    &lt;p&gt;You get the idea.&lt;/p&gt;
    &lt;p&gt;Over time, your repo grows to be a collection of data from different open social apps. This data is open by default—if you wanted to look at my Bluesky posts, or Tangled stars, or Leaflet publications, you wouldn’t need to hit these applications’ APIs. You could just hit my personal repository and enumerate all of its records.&lt;/p&gt;
    &lt;p&gt;To avoid naming collisions, the data in the repository is grouped by the format:&lt;/p&gt;
    &lt;p&gt;In any user’s repo, Bluesky posts go with other Bluesky posts, Leaflet publications go with Leaflet publications, Tangled stars go with Tangled stars, and so on. Each data format is controlled and evolved by developers of the relevant application.&lt;/p&gt;
    &lt;p&gt;I’ve drawn a dotted line to separate them but perhaps this is misleading.&lt;/p&gt;
    &lt;p&gt;Since the data from different apps “lives together”, there’s a much lower barrier for open social apps to piggyback on each other’s data. In a way, it starts to feel like a connected multiverse of apps, with data from one app “bleeding into” other apps.&lt;/p&gt;
    &lt;p&gt;When I signed up for Tangled, I chose to use my existing &lt;code&gt;@danabra.mov&lt;/code&gt; handle. That makes sense since identity can be shared between open social apps. What’s more interesting is that Tangled prefilled my avatar based on my Bluesky profile. It didn’t need to hit the Bluesky API to do that; it just read the Bluesky profile record in my repository. Every app can choose to piggyback on data from other apps.&lt;/p&gt;
    &lt;p&gt;That might remind you of Gravatar, but it works for every piece of data. Every open social app can take advantage of data created by every other open social app:&lt;/p&gt;
    &lt;p&gt;There is no API to hit, no integrations to build, nothing to get locked out of. All the data is in the user’s repository, so you can parse it (as typed JSON), and use it.&lt;/p&gt;
    &lt;p&gt;The protocol is the API.&lt;/p&gt;
    &lt;p&gt;This has deep implications for the lifecycle of products. If a product gets shut down, the data doesn’t disappear. It’s still in its users’ repos. Someone can build a replacement that makes this data comes back to life. Someone can build a new product that incorporates some of that data, or lets users choose what to import. Someone can build an alternative projection of existing data—a forked product.&lt;/p&gt;
    &lt;p&gt;This also reduces the “cold start” problem for new apps. If some of the data you care about already exists on the network, you can bootstrap your product off of that. For example, if you’re launching a short video app, you can piggyback on the Bluesky &lt;code&gt;follow&lt;/code&gt; records so that people don’t have to find each other again. But if that doesn’t make sense for your app, you can have your own &lt;code&gt;follow&lt;/code&gt; records instead, or offer a one-time import. All existing data is up for reuse and remixing.&lt;/p&gt;
    &lt;p&gt;Some open social apps are explicitly based around this sort or remixing. Anisota is primarily a Bluesky client, but it natively supports showing Leaflet documents. Popfeed can cross-post reviews to both Bluesky and Leaflet. If Leaflet does gets very popular, there’s nothing stopping Bluesky itself from supporting a Leaflet document as another type of post attachment. In fact, some third-party Bluesky client could decide to do that first, and the official one could eventually follow.&lt;/p&gt;
    &lt;p&gt;This is why I like “open social” as a term.&lt;/p&gt;
    &lt;p&gt;Open social frees up our data like open source freed up our code. Open social ensures that products can get a new life, that people can’t be locked out of what they have created, and that products can be forked and remixed. You don’t need an “everything app” when data from different apps circulates in the open web.&lt;/p&gt;
    &lt;p&gt;If you’re technical, by now you might have a burning question.&lt;/p&gt;
    &lt;p&gt;How the hell does aggregation work?!&lt;/p&gt;
    &lt;p&gt;Since every user’s records live in that user’s repository, there are millions (potentially billions?) repositories. How can an app efficiently query, sort, filter, and aggregate information from them? Surely it can’t search them on demand.&lt;/p&gt;
    &lt;p&gt;I’ve previously used a CMS as an analogy—for example, a blogging app could directly write posts to your repository and then read posts from it when someone visits your blog. This “singleplayer” use case would not require aggregation at all.&lt;/p&gt;
    &lt;p&gt;To avoid hitting the user’s repository every time you want to display their blog post, you can connect to the user’s repository by a websocket. Every time a record relevant to your app is created, updated, or deleted, you can update your database:&lt;/p&gt;
    &lt;p&gt;This database isn’t the source of truth for user’s data—it’s more like an app-specific cache that lets you avoid going to the user repo whenever you need some data.&lt;/p&gt;
    &lt;p&gt;Coincidentally, that’s the exact mechanism you would use for aggregation. You listen to events from all of your app users’ repositories, write them to a local database, and query that database as much as you like with zero extra latency.&lt;/p&gt;
    &lt;p&gt;This might remind you of how Google Reader crawls RSS (rip).&lt;/p&gt;
    &lt;p&gt;To avoid opening a million event socket connections, it makes sense to listen to a stream that retransmits events from all known repositories on the network:&lt;/p&gt;
    &lt;p&gt;You can then filter down such a stream to just the events you’re interested in, and then update your local database in response to the events your app cares about.&lt;/p&gt;
    &lt;p&gt;For example, Leaflet is only interested in events concerning &lt;code&gt;pub.leaflet.*&lt;/code&gt; records. However, Leaflet can also choose to listen to other events. If Leaflet wanted to add a feature that shows backlinks to Bluesky discussions of a Leaflet document, it would simply start tracking &lt;code&gt;bsky.app.feed.post&lt;/code&gt; records too.&lt;/p&gt;
    &lt;p&gt;You can try it yourself by clicking on this link:&lt;/p&gt;
    &lt;p&gt;This is a realtime stream of every single event on the network. It’s dominated by &lt;code&gt;app.bsky.*&lt;/code&gt; records because Bluesky is the most-used app, but you can filter it down to other record types. This retransmitter (called a “relay”) is operated by Bluesky, but you don’t have to depend on it. The Blacksky community runs their own relay implementation at &lt;code&gt;wss://atproto.africa&lt;/code&gt;, which you can try here.&lt;/p&gt;
    &lt;p&gt;Another important detail is that commits are cryptographically signed, which means that you don’t need to trust a relay or a cache of network data. You can verify that the records haven’t been tampered with, and each commit is legitimate.&lt;/p&gt;
    &lt;p&gt;As time goes by, we’ll see more infrastructure built around and for open social apps. Graze is letting users build their own algorithmic feeds, and Slices is an upcoming developer platform that does large-scale repository indexing for you.&lt;/p&gt;
    &lt;p&gt;These are all technical details, though.&lt;/p&gt;
    &lt;p&gt;What matters is the big picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Picture&lt;/head&gt;
    &lt;p&gt;The pre-social web of “personalized sites” got data ownership, hosting independence, and linking right. Alice and Bob fully participate in the web:&lt;/p&gt;
    &lt;p&gt;The closed social web innovated in scaling and in social aggregation features. Notifications, search, and feeds are non-negotiable in modern social products:&lt;/p&gt;
    &lt;p&gt;However, the closed social web has also excluded us from the web. The web we create is no longer meaningfully ours. We’re just rows in somebody else’s database.&lt;/p&gt;
    &lt;p&gt;Open social frees the web we’re creating from somebody else’s boxes. Our profiles, likes, follows, recipes, scrobbles, and other content meaningfully belong to us:&lt;/p&gt;
    &lt;p&gt;The data no longer lives inside the products; the products aggregate over our data:&lt;/p&gt;
    &lt;p&gt;This blurs the boundaries between apps. Every open social app can use, remix, link to, and riff on data from every other open social app.&lt;/p&gt;
    &lt;p&gt;The web we’ve created remains after the products we used to create it are gone. Developers can build new products to recontextualize it. No one can take it away.&lt;/p&gt;
    &lt;p&gt;As more products are built in the open social paradigm, there’s going to be a shift.&lt;/p&gt;
    &lt;p&gt;People might not ever start using technical concepts like “decentralization” but they do understand when data from one app can seamlessly flow into other apps.&lt;/p&gt;
    &lt;p&gt;People might not care about “federation” but they do notice when they log into a competing product, and their data is already there, and their reach is intact.&lt;/p&gt;
    &lt;p&gt;And people do understand when they’re being fucked with.&lt;/p&gt;
    &lt;p&gt;For a long time, open social will rely on a community of stubborn enthusiasts who see the promise of the approach and are willing to bear the pains of building (and failing) in a new ecosystem. But I don’t think that dooms the effort. That’s the history of every big community-driven change. Somebody has to work through the kinks. Like with open source, open social is a compounding effort. Every mildly successful open social app lifts all open social apps. Every piece of shared infrastructure can benefit somebody else. At some point, open is bound to win.&lt;/p&gt;
    &lt;p&gt;I just hope it doesn’t take thirty five years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388021</guid><pubDate>Fri, 26 Sep 2025 16:01:55 +0000</pubDate></item><item><title>Gauntlet AI (YC S17) is looking for engineers who want to master AI</title><link>https://apply.gauntletai.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388675</guid><pubDate>Fri, 26 Sep 2025 17:00:46 +0000</pubDate></item><item><title>Modular Manifolds</title><link>https://thinkingmachines.ai/blog/modular-manifolds/</link><description>&lt;doc fingerprint="3f8359d1081ca9b1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Modular Manifolds&lt;/head&gt;&lt;p&gt;When we train large neural networks, we need to keep them healthy. We do not want the tensors in the network—either the weights, activations or gradients—to grow too large or too small. Very small and very large tensors cause a variety of problems not just limited to numerical underflow and overflow. For example, weight matrices changing size during training makes it harder to design training algorithms—since the relative size of updates to weights has a significant impact on the speed of learning.&lt;/p&gt;&lt;p&gt;The gold standard for keeping tensors healthy is to normalize them. Normalization is commonplace for activation vectors, where we use techniques like layer norm to put the activations on a good scale before passing them to the next layer. It is also commonplace to normalize gradient updates, where we can interpret fast training algorithms like the Muon optimizer as spectrally normalizing the updates. Normalization provides us with certainty about the sizes of tensors—without needing to check Wandb!—and when training large neural networks with many interacting components, having certainty about the network internals is valuable.&lt;/p&gt;&lt;p&gt;Normalization is less commonly applied to weight matrices, although it is not unheard of. For example, the EDM2 diffusion model codebase uses weight constraints and the authors report benefits in their paper. And BiT uses weight standardization. Various other techniques have been proposed but are not common practice in modern large-scale training.For some more examples, see Salimans et al, 2016, Miyato et al, 2018 and our paper Liu et al, 2021. Normalizing the weight matrices might be a good idea for a few reasons. Weight constraints make understanding the relative size of optimization updates easier. They remove the problem of weight norms exploding. They allow us to focus hyperparameter tuning effort on tensors whose size matters most. They can force matrices to have a small condition number, making their behaviour more predictable. And relatedly, weight constraints facilitate Lipschitz guarantees for robustness to perturbations.&lt;/p&gt;&lt;p&gt;This post covers one appealing way to constrain the weight matrices of a neural network—by keeping the tensors constrained to submanifolds at each layer. This opens the door to re-thinking optimization, as we can co-design optimization algorithms with these manifold constraints. As an example, we proposeThis algorithm builds on work from Jianlin Su and Franz Louis Cesista, as discussed further below. a manifold version of the Muon optimizer whose weights are constrained to the Stiefel manifold: the manifold of matrices with unit condition number. We conclude the post by defining the idea of a modular manifold, which is a composable manifold that attempts to make it easier to scale up and train large networks.&lt;/p&gt;&lt;p&gt;Our goal in writing this post is to provide an introduction to a research area that we are excited about, and highlight many directions for future work. We would love to see more work from the community on the topics mentioned at the end of the post!&lt;/p&gt;&lt;head rend="h2"&gt;The shape of a manifold optimizer&lt;/head&gt;&lt;p&gt;This section works through the simplest example of learning on a manifold: a vector parameter constrained to a hypersphere in $\mathbb{R}^d$. The vector parameter is trained to minimize a loss function defined over the full space $\mathbb{R}^d$. This setup might be useful for, say, individual embedding vectors in a transformer model. This section will be a good warmup for the following section on manifold Muon that considers matrix parameters.&lt;/p&gt;&lt;p&gt;We will not be too formal about the definition of a manifold here: it is enough to understand that a manifold is a curved surface that looks flat when you zoom in close enough. The locally flat approximation at a point on the manifold is called the tangent space to the manifold, as visualized in Figure :&lt;/p&gt;&lt;p&gt;We can characterize the hypersphere in $d$ dimensions as the set of points $w \in \mathbb{R}^d$ of unit Euclidean norm. And the tangent space at a point $w$ on the hypersphere is the set of all vectors $a \in \mathbb{R}^d$ that are orthogonal to $w$.&lt;/p&gt;&lt;p&gt;To keep the weights constrained to the manifold, we could use a non-manifold optimizer and just project the weights back to the manifold after each step. Instead, we are interested in designing methods that take steps in the tangent space. The reason is that we would like to be able to equate the learning rate of our optimizer with the actual length of the optimization step. But if the optimization steps are pointing significantly off manifold and then being projected back, this nice property does not hold. Similar motivation is given in Section 2.3 of the EDM2 paper.&lt;/p&gt;&lt;p&gt;Before we can design a training algorithm for this manifold, something important we need to decide on is how to measure distanceFor a manifold to be “Riemannian”, the distance measure must be induced by an inner product. The Euclidean ($\ell_2$) norm is induced by an inner product, but the Manhattan ($\ell_1$) distance is not. in the tangent space. A common choice is the Euclidean distance, but we could also choose to measure distance in other ways, as visualized in Figure . In the next section, we will talk about choosing a distance measure based on the functionality of the module.&lt;/p&gt;&lt;p&gt;Crucially, the choice of distance measure changes the direction of the best optimization step. If the distance measure is non-Euclidean, then for a fixed length step, we may be able to move further in the direction of the gradientBy gradient, we mean the partial derivative of the loss with respect to the weights. Mathematicians reserve the term gradient for something else in Riemannian geometry. by not following the gradient direction exactly! This concept is visualized in Figure .&lt;/p&gt;&lt;p&gt;To see how this works out in math, we can formulate the optimal update direction given a manifold constraint and a distance measure as itself solving a constrained optimization problem. We will demonstrate this for the case of the hypersphere equipped with the Euclidean norm. Letting $g$ denote the gradient, $w$ the current point on the hypersphere, $a$ the update direction and $\eta$ the learning rate, we need to solve:&lt;/p&gt;$$\min_{a\in\mathbb{R}^d} \quad \underbrace{a^\top g\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|a\|_2 = \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{a^\top w = 0\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{tangent constraint}}}.\tag{$\star$}$$&lt;p&gt;Mapping back to the visual language of Figures , and , this formula says that the green arrow (optimal value of $a$) must belong to the red tangent hyperplane ($a^\top w = 0$) and must also lie on a yellow circle of radius $\eta$ ($\|a\|_2 = \eta$). To solve $(\star)$, we can apply the method of Lagrange multipliers. The relevant Lagrangian function is given by:&lt;/p&gt;$$\mathcal{L}(a, \lambda, \mu) = a^\top g + \frac{\lambda}{2} \cdot (a^\top a - \eta) + \mu \cdot (a^\top w),$$&lt;p&gt;where $\lambda$ and $\mu$ are Lagrange multipliers. Setting the derivative of the Lagrangian with respect to $a$ to zero and applying the constraints to solve for $\lambda$ and $\mu$, the optimal update $a_\mathrm{opt}$ ends up being given by the following formula:&lt;/p&gt;$$a_\mathrm{opt} = - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}.$$&lt;p&gt;In words, the optimal update is given by subtracting out the radial component from the gradient, normalizing and multiplying by the learning rate. Since this update lies in the tangent space, actually a very smallFor a learning rate $\eta$, the effect of the retraction map is $\mathcal{O}(\eta^2)$ small, so the learning rate almost equals the length of the step. correction is needed to stay on the manifold. The correction is known as a “retraction map” and is visualized in Figure :&lt;/p&gt;&lt;p&gt;We can solve for the retraction map by applying Pythagoras’ theorem to Figure . For a unit hypersphere and a step of length $\eta$, the hypotenuse has length $\sqrt{1+\eta^2}$ and therefore the retraction map for the hypersphere equipped with the Euclidean norm is simply given by dividing the updated weights through by $\sqrt{1+\eta^2}$. Putting everything together, the full manifold optimization algorithm is then given by:&lt;/p&gt;$$w \gets \frac{1}{\sqrt{1+\eta^2}} \left[w - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}\right].$$&lt;p&gt;As an exercise for the reader: try calculating the Euclidean norm of the updated weight vector and check that the updated weight vector indeed lies on the hypersphere.&lt;/p&gt;&lt;p&gt;To summarize this section, a first-order manifold optimizer has three steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Find the tangent vector of unit length that goes furthest in the gradient direction.&lt;/item&gt;&lt;item&gt;Multiply this direction by the learning rate and subtract from the weights;&lt;/item&gt;&lt;item&gt;Retract the updated weights back to the manifold.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;There are two decisions to make in applying this procedure: what manifold constraint we should use and how we should measure length. By making different decisions, we can generate different optimization algorithms as shown in the following table.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Manifold&lt;/cell&gt;&lt;cell role="head"&gt;Norm&lt;/cell&gt;&lt;cell role="head"&gt;Optimizer&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;vanilla gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;infinity norm&lt;/cell&gt;&lt;cell&gt;sign gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;hypersphere $S^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;hyperspherical descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;matrix space $\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;Muon&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Stiefel manifold $\subset\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;manifold Muon&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;We will derive the final algorithm in the table, manifold Muon, in the next section. To design a manifold constraint and a distance function for a matrix parameter, we shall think carefully about the role that a weight matrix plays inside a neural network.&lt;/p&gt;&lt;head rend="h2"&gt;Manifold Muon&lt;/head&gt;&lt;p&gt;A typical weight matrix $W$ in a transformer is a “vector-multiplier”, meaning that it transforms an input vector $x$ into an output vector $y = Wx$. We will design a manifold constraint and a distance function so that the matrix acts in a good way on input vectors: the matrix should not produce excessively small or large outputs, and updates to the matrix should not cause the output vector to change too much or too little.&lt;/p&gt;&lt;p&gt;A good way to think about how a matrix acts on vectors is through the singular value decomposition, illustrated in Figure . The SVD decomposes a matrix in a way that tells us how the matrix stretches input vectors along different axes.&lt;/p&gt;&lt;p&gt;We would like the matrix to have a stretching effect close to one, so we will choose a matrix manifold where all the singular values are exactly one. This matrix manifold is known formally as the Stiefel manifold. We can assume without loss of generality that we are dealing with a tall matrix ($m \geq n$), and then the Stiefel manifold can be equivalently defined as the following set:&lt;/p&gt;$$\mathsf{Stiefel}(m,n) := \left\{ W \in \mathbb{R}^{m \times n} \mid W^T W = I_n \right\}.$$&lt;p&gt;Furthermore, one may show that a matrix $A \in \mathbb{R}^{m \times n}$ lies tangentNotice that the Stiefel constraint $W^T W = I_n$ directly generalizes the hyperspherical constraint $w^\top w = 1$ from the previous section. Similarly, the tangent space condition generalizes the hyperspherical one that $a^\top w = 0$. to the Stiefel manifold at matrix $W$ if and only if:&lt;/p&gt;$$A^\top W + W^\top A = 0.$$&lt;p&gt;To design a manifold optimizer for the Stiefel manifold, all that remains is to choose a distance function. To limit the maximum stretching effect the weight update can have on an input vector, we will choose the spectral norm, which measures the largest singular value of a matrix. Although this only limits the maximum effect the update can have, since the optimizer we derive will saturate this bound, it will turn out to prevent the minimum effect of the update from being too small.There are some exceptions to this statement, such as when a weight matrix has a fan-out less than its fan-in, in which case we cannot escape from the matrix and its updates having a null space and mapping some inputs to zero.&lt;/p&gt;&lt;p&gt;The idea of doing gradient descent under a spectral norm constraint is what led to the Muon optimizer and, when combined with the Stiefel manifold constraint, we obtain a problem that we shall call manifold Muon:&lt;/p&gt;$$\min_{A\in\mathbb{R}^{m\times n}} \quad \underbrace{\operatorname{trace}(G^T A)}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|A\|_{\text{spectral}} \leq \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{A^T W + W^T A = 0\vphantom{\|A\|_{\text{spectral}} = \eta}}_{\mathclap{\text{tangent constraint}}} \tag{$\dagger$}.$$&lt;p&gt;The manifold Muon problem $(\dagger)$ directly generalizes problem $(\star)$ from the previous section. Solving $(\dagger)$ is harder than solving $(\star)$, and here we will present a numerical solution inspiredI figured out how to solve manifold Muon in the square case late last year, but I was unable to solve the full rectangular case and thus posed the problem as an open problem on the Modula docs. Jianlin Su solved the problem this summer by taking a Lagrangian approach and working out a fixed point iteration on the optimality condition. I saw an early version of Jianlin’s work (which did not quite work yet) and also related work by Franz Louis Cesista, and I was able to work out the dual ascent algorithm presented here. by work done by Jianlin Su and Franz Louis Cesista.&lt;/p&gt;&lt;p&gt;Our key insight is that $(\dagger)$ is a convex optimization problem that may be solved via a standard method known as dual ascent. Here we will just sketch the main idea, but you can find a more detailed derivation on this page.&lt;/p&gt;&lt;p&gt;Similar to Jianlin’s approach, we introduce a matrix of Lagrange multipliers $\Lambda\in\mathbb{R}^{n\times n}$. We then apply a series of transformations to convert the problem $(\dagger)$ from a constrained minimization problem to an unconstrained maximization problem:&lt;/p&gt;$$ \begin{align} (\dagger) &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda} \;\operatorname{trace} G^\top A + \operatorname{trace}\Lambda^\top (A^\top W + W^\top A) \\ &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda}\; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \min_{\|A\|_\mathrm{spectral} \leq \eta} \; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \; - \eta \times \|G + 2W(\Lambda+\Lambda^\top)\|_\mathrm{nuclear}. \end{align} $$&lt;p&gt;Equation (1) reformulates the problem as a saddle point problem: the maximization over $\Lambda$ will send the objective to infinity whenever the tangent space condition is violated. Equation (2) follows by applying properties of the trace and equation (3) follows from Sion’s minimax theorem. The inner minimization in equation (3) is solved by setting $A_\mathrm{opt}(\Lambda) = - \eta \times \operatorname{msign}(G + 2W(\Lambda+\Lambda^\top))$ where $\operatorname{msign}$ is the matrix sign function.The matrix sign function snaps the singular values of a matrix to one. It may be computed efficiently on GPUs via Newton-Schulz iteration or the recent Polar Express algorithm. And we obtain equation (4) by substituting this expression for $A_\mathrm{opt}(\Lambda)$ into equation (3). Equation (4) is known as the “dual problem” to $(\dagger)$ and we can solve it by gradient ascent. After some work, the gradient of the dual function is given by:&lt;/p&gt;$$ \begin{align} H(\Lambda) &amp;amp;:= - \eta \times \nabla_\Lambda \|G + W (\Lambda+\Lambda^\top)\|_\mathrm{nuclear} \\ &amp;amp;= - \eta \times [W^\top\mathrm{msign}(G + 2W (\Lambda+\Lambda^\top)) + \operatorname{msign}(G + 2W (\Lambda+\Lambda^\top))^\top W], \end{align} $$&lt;p&gt;where the nuclear norm $\|\cdot\|_\mathrm{nuclear}$ measures the sum of the singular values of a matrix.&lt;/p&gt;&lt;p&gt;Finally, we can write down the manifold Muon algorithm:Note that this algorithm is closely related to Jianlin Su’s solution. Where we run dual ascent, Jianlin’s solution amounts to solving for the maximum of the dual function $H(\Lambda)=0$ via a fixed point iteration.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Run gradient ascent on the dual variable $\Lambda \gets \Lambda + \alpha \times H(\Lambda)$ to solve for $\Lambda_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Compute the update $A_\mathrm{opt} = - \eta \times \operatorname{msign}(G + 2W(\Lambda_{\mathrm{opt}}+\Lambda_\mathrm{opt}^\top))$.&lt;/item&gt;&lt;item&gt;Apply the update to the weights $W \gets W + A_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Retract the weights back to the manifold $W \gets \operatorname{msign}(W)$.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We ran a very small experiment to sanity check the algorithm and provide a minimal implementation for students or researchers to play with. Each training run finishes in less than a minute. The code is here and see Figure for the setup and results.&lt;/p&gt;&lt;head rend="h2"&gt;Modular manifolds&lt;/head&gt;&lt;p&gt;So far in this post, we have discussed manifold constraints for individual parameter tensors and co-designed optimization logic for these constraints. A question we have not answered is: what happens when we combine layers to build networks? Can we think about individual layers in isolation—or do we need to be careful about interactions between layers and modify the optimization logic in response? The goal of this section is to point out that there is a way to extend the reasoning we introduced in the previous two sections to the case of whole networks, and we call this the theory of modular manifolds.The theory of modular manifolds builds on research I did with my friend Tim Large, my postdoc advisor Phillip Isola, my PhD advisor Yisong Yue and many other amazing collaborators. At the end of the section, we provide some links to learn more.&lt;/p&gt;&lt;p&gt;The idea of modular manifolds is to build an abstraction that tells us how to budget learning rates across layers. The actual optimization logic in each layer ends up being the same as what we already worked out, except that the learning rate for a layer is modified depending on where the layer appears in the network. The abstraction rests upon a key observation made in our paper on the modular norm, that budgeting learning rates—both across layers and when scaling up individual layers—is intimately tied to understanding the Lipschitz sensitivity of the network output with respect to the weights. The abstraction tracks this sensitivity as we build the network, and manifold constraints help us get a much tighter understanding of this sensitivity.&lt;/p&gt;&lt;p&gt;The starting point for the abstraction is to think of any neural network module—from a layer to a whole transformer—as a mathematical object with three attributes:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;A forward function $f:\mathcal{W} \times \mathcal{X} \to \mathcal{Y}$ that maps from a parameter space $\mathcal{W} = \mathbb{R}^d$ and an input space $\mathcal{X}$ to an output space $\mathcal{Y}$.&lt;/item&gt;&lt;item&gt;A submanifold of the weight space $\mathcal{M}\subset\mathcal{W}$ that the weights are constrained to.&lt;/item&gt;&lt;item&gt;A norm $\|\cdot\| : \mathcal{W} \to \mathbb{R}$ that acts as a measuring stick on weight space.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For example, a linear module equipped with the spectral norm and constrained to the Stiefel manifold, for which we have already worked out an optimizer, would be written:&lt;/p&gt;$$ \mathsf{StiefelLinear} = \begin{cases}(W, x) \mapsto Wx, &amp;amp; \text{(forward function)}\\ \mathsf{Stiefel}(m,n), &amp;amp; \text{(manifold)}\\ \|\cdot\|_\mathrm{spectral}. &amp;amp; \text{(norm)}\end{cases}$$&lt;p&gt;Provided that an input $x$ to the $\mathsf{StiefelLinear}$ module has unit $\ell_2$ norm, then $\mathsf{StiefelLinear}$ is Lipschitz with respect to its weights in the module’s assigned norm with Lipschitz constant one:This argument can be extended to the RMS norm on the input and the RMS–RMS operator norm on the weights.&lt;/p&gt;$$\|(W + \Delta W) x - Wx\|_2 \leq \|\Delta W\|_\mathrm{spectral} \times \|x\|_2 = \|\Delta W\|_\mathrm{spectral}.$$&lt;p&gt;This type of Lipschitz statement helps us understand how to scale weight updates to this module since it gives us a bound on how much the output can change when we perturb the weights. But when we compose two modules, can we automatically compile a Lipschitz statement on the joint weight space of the new module? The answer turns out to be yes, if we follow special rules for building the new module:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;The new forward function $f_3$ is given by composing the two existing forward functions $f_1$ and $f_2$: $$f_3((w_1, w_2), x) := f_2(w_2, f_1(w_1, x)). \qquad$$&lt;/item&gt;&lt;item&gt;The new manifold constraint $\mathcal{M}_3$ is just the Cartesian product (see Figure for a fun example) of the two existing manifolds $\mathcal{M}_1$ and $\mathcal{M}_2$: $$\mathcal{M}_3 = \mathcal{M}_1 \times \mathcal{M}_2. \qquad$$&lt;/item&gt;&lt;item&gt;The new norm function is the max of the two existing norm functions weighted by special scalar coefficients $s_1$ and $s_2$. Letting $\|\cdot\|_1$ denote the first module’s norm and $\|\cdot\|_2$ denote the second module’s norm, the new norm $\|\cdot\|_3$ is given by: $$\|(w_1, w_2)\|_3 := \max(s_1\cdot \|w_1\|_1, s_2\cdot \|w_2\|_2). \qquad$$&lt;/item&gt;&lt;/list&gt;&lt;p&gt;When we use this composite norm to derive optimizers—following the same recipe we used in the first two sections of this post—we end up deriving separate optimizers for each layer, but the scalar coefficients $s_i$ budget the learning rates across layers.&lt;/p&gt;&lt;p&gt;We give much more detail on this construction, including extending it to other ways of combining modules, in our paper on the modular norm—although the paper does not cover manifold optimization. You can also check out our paper on modular duality for more on building optimizers in the modular norm. The Modula project builds toward a programmatic implementation of this construction.&lt;/p&gt;&lt;head rend="h2"&gt;Directions for future work&lt;/head&gt;&lt;p&gt;We are excited about any research that tries to make neural network training as principled and automatic as the forward pass. The ideas in this post benefitted strongly from interactions with external researchers like Jianlin Su and Franz Louis Cesista. We would love to see more work on these topics from the community.&lt;/p&gt;&lt;p&gt;Some possible directions for future work are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Modularity. What manifolds should attention heads live on? Should embeddings be constrained differently than unembeddings? We can mix-and-match constraints in different parts of the network, or leave some tensors unconstrained.&lt;/item&gt;&lt;item&gt;Numerics. Manifold constraints also place constraints on the range of values that individual weight entries can take. Does this impact numerics, or make low-precision training easier?&lt;/item&gt;&lt;item&gt;Convex optimization. The manifold Muon algorithm involves running dual ascent. Can we apply more sophisticated convex optimization techniques to solve the dual problem faster or more reliably?&lt;/item&gt;&lt;item&gt;Convergence analysis. How fast do these algorithms converge? Does good conditioning of the weight matrices benefit convergence? Is there more that we can say theoretically?&lt;/item&gt;&lt;item&gt;Regularization. Manifold constraints implicitly regularize the model. Could we design constraints or tune their radii to improve generalization?&lt;/item&gt;&lt;item&gt;Architecture-optimizer co-design. While hard manifold constraints may not ultimately be the right way to constrain weight matrices, they exemplify the idea of tightly co-designing optimization algorithms with architecural components. Are there more opportunities here?&lt;/item&gt;&lt;item&gt;Non-Riemannian geometry. Most work on manifold optimization works in a Riemannian world where distances are induced by inner products and norm balls are ellipsoids. But neural networks are different: matrices act as operators, and operator norms like the spectral norm do not emerge from inner products. This implies, for example, that norm balls can have sharp corners and there is no unique gradient flow. Is there more to be discovered in this non-Riemannian world?&lt;/item&gt;&lt;item&gt;Practical implementation. Applying these techniques at scale requires efficient manifold operations on GPUs. The recent Polar Express paper shows promise for fast matrix sign computation. What other algorithmic innovations do we need?&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Further reading&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Manifold optimization. Absil, Mahony &amp;amp; Sepulchre’s textbook is a standard reference. For the Stiefel manifold specifically, see Edelman et al, 1998. These works live in a Riemannian world. Similarly most machine learning papers that consider optimization on the Stiefel manifold take a Riemannian point of view: see Li et al, 2020, Kong et al, 2022 and Park et al, 2025 for some examples.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Non-Riemannian geometry in machine learning. Thomas Flynn’s paper from 2017 on duality structure gradient descent characterizes the neural network weight space as a Finsler manifold, meaning a manifold equipped with a norm. It is well worth a read. Also see Jianlin Su’s recent blog post on Stiefel Muon as well as Franz Louis Cesista’s blog post on a heuristic solution to Muon on the Stiefel manifold. Franz also wrote a followup blog post generalizing the solution presented here. The Scion paper imposes weight constraints a different way via convex combinations and Carlson et al, 2015 wrote an early paper on (unconstrained) spectral descent.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The Modula project. The goal of the Modula project is to build a library that automatically compiles steepest descent optimizers along with Lipschitz statements for general architectures. Check out the project page at https://modula.systems as well as our paper on the modular norm and modular duality. Our optimization anthology also provides an accessible route into this space of ideas.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Lipschitz-constrained deep learning. There has been a lot of work on this topic. For example, check out Louis Béthune and Tsui-Wei Weng’s PhD theses. Usually work on this topic does not connect weight-Lipschitzness to optimizer design. See also Anil et al, 2018 and our paper Newhouse et al, 2025.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Citation&lt;/head&gt;&lt;p&gt;Please cite this work as:&lt;/p&gt;&lt;code&gt;Jeremy Bernstein, "Modular Manifolds",
Thinking Machines Lab: Connectionism, Sep 2025.
&lt;/code&gt;&lt;p&gt;Or use the BibTeX citation:&lt;/p&gt;&lt;code&gt;@article{bernstein2025manifolds,
  author = {Jeremy Bernstein},
  title = {Modular Manifolds},
  journal = {Thinking Machines Lab: Connectionism},
  year = {2025},
  note = {https://thinkingmachines.ai/blog/modular-manifolds/},
  doi = {10.64434/tml.20250926}
}
&lt;/code&gt;
    
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388728</guid><pubDate>Fri, 26 Sep 2025 17:06:48 +0000</pubDate></item><item><title>Suno Studio, a Generative AI DAW</title><link>https://suno.com/studio-welcome</link><description>&lt;doc fingerprint="536fd5a56c585c00"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00 /&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45388822</guid><pubDate>Fri, 26 Sep 2025 17:17:54 +0000</pubDate></item><item><title>SimpleFold: Folding proteins is simpler than you think</title><link>https://github.com/apple/ml-simplefold</link><description>&lt;doc fingerprint="dd791d51782a9c92"&gt;
  &lt;main&gt;
    &lt;p&gt;This github repository accompanies the research paper, SimpleFold: Folding Proteins is Simpler than You Think (Arxiv 2025).&lt;/p&gt;
    &lt;p&gt;Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Joshua M. Susskind, Miguel Angel Bautista&lt;/p&gt;
    &lt;p&gt;We introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer layers. SimpleFold does not rely on expensive modules like triangle attention or pair representation biases, and is trained via a generative flow-matching objective. We scale SimpleFold to 3B parameters and train it on more than 8.6M distilled protein structures together with experimental PDB data. To the best of our knowledge, SimpleFold is the largest scale folding model ever developed. On standard folding benchmarks, SimpleFold-3B model achieves competitive performance compared to state-of-the-art baselines. Due to its generative training objective, SimpleFold also demonstrates strong performance in ensemble prediction. SimpleFold challenges the reliance on complex domain-specific architectures designs in folding, highlighting an alternative yet important avenue of progress in protein structure prediction.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;simplefold&lt;/code&gt; package from github repository, run&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
python -m pip install -U pip build; pip install -e .
pip install git+https://github.com/facebookresearch/esm.git # Optional for MLX backend
&lt;/code&gt;
    &lt;p&gt;We provide a jupyter notebook &lt;code&gt;sample.ipynb&lt;/code&gt; to predict protein structures from example protein sequences.&lt;/p&gt;
    &lt;p&gt;Once you have &lt;code&gt;simplefold&lt;/code&gt; package installed, you can predict the protein structure from target fasta file(s) via the following command line. We provide support for both PyTorch and MLX (recommended for Apple hardware) backends in inference.&lt;/p&gt;
    &lt;code&gt;simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend 
&lt;/code&gt;
    &lt;p&gt;We provide predicted structures from SimpleFold of different model sizes:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)
&lt;/code&gt;
    &lt;p&gt;We use the docker image of openstructure 2.9.1 to evaluate generated structures for folding tasks (i.e., CASP14/CAMEO22). Once having the docker image enabled, you can run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]
&lt;/code&gt;
    &lt;p&gt;To evaluate results of two-state prediction (i.e., Apo/CoDNaS), one need to compile the TMsore and then run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5
&lt;/code&gt;
    &lt;p&gt;You can also train or tune SimpleFold on your end. Instructions below include details for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;SimpleFold is trained on joint datasets including experimental structures from PDB, as well as distilled predictions from AFDB SwissProt and AFESM. Target lists of filtered SwissProt and AFESM targets thta are used in our training can be found:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)
&lt;/code&gt;
    &lt;p&gt;In &lt;code&gt;afesme_dict.json&lt;/code&gt;, the data is stored in the following structure:&lt;/p&gt;
    &lt;code&gt;{
    cluster 1 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    ...
}
&lt;/code&gt;
    &lt;p&gt;Of course, one can use own customized datasets to train or tune SimpleFold models. Instructions below list how to process the dataset for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;To process downloaded mmcif files, you need Redis installed and launch the Redis server:&lt;/p&gt;
    &lt;code&gt;wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777
&lt;/code&gt;
    &lt;p&gt;You can then process mmcif files to input format for SimpleFold:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly
&lt;/code&gt;
    &lt;p&gt;The configuration of model is based on &lt;code&gt;Hydra&lt;/code&gt;. An example training configuration can be found in &lt;code&gt;configs/experiment/train&lt;/code&gt;. To change dataset and model settings, one can refer to config files in &lt;code&gt;configs/data&lt;/code&gt; and &lt;code&gt;configs/model&lt;/code&gt;. To initiate SimpleFold training:&lt;/p&gt;
    &lt;code&gt;python train experiment=train
&lt;/code&gt;
    &lt;p&gt;To train SimpleFold with FSDP strategy:&lt;/p&gt;
    &lt;code&gt;python train_fsdp.py experiment=train_fsdp
&lt;/code&gt;
    &lt;p&gt;If you found this code useful, please cite the following paper:&lt;/p&gt;
    &lt;code&gt;@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;Our codebase is built using multiple opensource contributions, please see ACKNOWLEDGEMENTS for more details.&lt;/p&gt;
    &lt;p&gt;Please check out the repository LICENSE before using the provided code and LICENSE_MODEL for the released models.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389267</guid><pubDate>Fri, 26 Sep 2025 18:01:26 +0000</pubDate></item><item><title>Auth.js is now part of Better Auth</title><link>https://www.better-auth.com/blog/authjs-joins-better-auth</link><description>&lt;doc fingerprint="ea4da1989f2d5ce"&gt;
  &lt;main&gt;
    &lt;p&gt;We’re excited to announce that Auth.js, formerly known as NextAuth.js, is now being maintained and overseen by Better Auth team. If you haven't heard of Auth.js, it has long been one of the most widely used open source authentication libraries in the JavaScript ecosystem. Chances are, if you’ve used ChatGPT, Google Labs, Cal.com or a million other websites, you’ve already interacted with Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;Back Story about Better Auth and Auth.js&lt;/head&gt;
    &lt;p&gt;Before Better Auth, Auth.js gave developers like us the ability to own our auth without spending months wrestling with OAuth integrations or session management. But as applications became more complex and authentication needs evolved, some of its limitations became harder to ignore. We found ourselves rebuilding the same primitives over and over.&lt;/p&gt;
    &lt;p&gt;The Auth.js team recognized these challenges and had big ideas for the future, but for various reasons couldn’t execute them as fully as they hoped.&lt;/p&gt;
    &lt;p&gt;That shared frustration and the vision of empowering everyone to truly own their auth started the creation of Better Auth. Since our goals aligned with the Auth.js team, we were excited to help maintain Auth.js and make auth better across the web. As we talked more, we realized that Better Auth was the best home for Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does this mean for existing users?&lt;/head&gt;
    &lt;p&gt;We recognize how important this project is for countless applications, companies, and developers. If you’re using Auth.js/NextAuth.js today, you can continue doing so without disruption—we’ll keep addressing security patches and urgent issues as they come up.&lt;/p&gt;
    &lt;p&gt;But we strongly recommend new projects to start with Better Auth unless there are some very specific feature gaps (most notably stateless session management without a database). Our roadmap includes bringing those capabilities into Better Auth, so the ecosystem can converge rather than fragment.&lt;/p&gt;
    &lt;p&gt;For teams considering migration, we’ve prepared a guide and we’ll be adding more guides and documentation soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;We are deeply grateful to the Auth.js community who have carried the project to this point. In particular, the core maintainers-Balázs, who served as lead maintainer, Thang Vu,Nico Domino, Lluis Agusti and Falco Winkler-pushed through difficult phases, brought in new primitives, and kept the project alive long enough for this transition to even be possible.&lt;/p&gt;
    &lt;p&gt;Better Auth beginning was inspired by Auth.js, and now, together, the two projects can carry the ecosystem further. The end goal remains unchanged: you should own your auth!&lt;/p&gt;
    &lt;p&gt;For the Auth.js team's announcement, see GitHub discussion.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389293</guid><pubDate>Fri, 26 Sep 2025 18:04:29 +0000</pubDate></item><item><title>Oral Microbes Linked to 3-Fold Increased Risk of Pancreatic Cancer</title><link>https://nyulangone.org/news/oral-microbes-linked-increased-risk-pancreatic-cancer</link><description>&lt;doc fingerprint="f790e1a3620b8701"&gt;
  &lt;main&gt;
    &lt;p&gt;Among the hundreds of species of bacteria and fungi that live in people’s mouths, 27 have been collectively tied to a 3.5 times greater risk of developing pancreatic cancer, a study led by NYU Langone Health and its Perlmutter Cancer Center shows.&lt;/p&gt;
    &lt;p&gt;Experts have long observed that those with poor oral health are more vulnerable to pancreatic cancer than those with healthier mouths. More recently, scientists have uncovered a mechanism that could help explain this connection, finding that bacteria can travel through swallowed saliva into the pancreas, an organ that helps with digestion. However, precisely which species may contribute to the condition had until now remained unclear.&lt;/p&gt;
    &lt;p&gt;Published online September 18 in JAMA Oncology, the new analysis assessed the genetic makeup of microbes collected from the saliva of 122,000 healthy men and women.&lt;/p&gt;
    &lt;p&gt;“Our findings provide new insight into the relationship between the oral microbiome and pancreatic cancer,” said study lead author Yixuan Meng, PhD, a postdoctoral fellow in the Department of Population Health at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;The oral microbiome, the diverse community of bacteria and fungi that inhabit the mouth, is increasingly being studied for its potential role in human health.&lt;/p&gt;
    &lt;p&gt;Last year, the same team of scientists uncovered a link between certain oral bacteria and a heightened risk of developing head and neck squamous cell carcinoma, a group of cancers that arise in the mouth and throat. The researchers had also conducted a small study in 2016 that tied microbes living in the mouth to pancreatic cancer, but could not identify precise bacterial species.&lt;/p&gt;
    &lt;p&gt;Their latest report is the largest and most detailed analysis of its kind to date, says Dr. Meng. It is also the first to show that oral fungi—namely a type of yeast in the genus Candida that naturally lives on the skin and throughout the body—may play a role in pancreatic cancer. The researchers also identified these oral Candida species in patients’ pancreatic tumors.&lt;/p&gt;
    &lt;p&gt;For the study, the team assessed data from two ongoing investigations tracking Americans from across the country to better understand how diet, lifestyle, medical history, and many other factors are involved in cancer. The data were gathered for the American Cancer Society Cancer Prevention Study II and the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial.&lt;/p&gt;
    &lt;p&gt;Shortly after enrolling, participants rinsed with mouthwash, providing saliva samples that preserved the numbers and species of microbes for testing. Researchers then followed up for roughly nine years on average to record any presence of tumors.&lt;/p&gt;
    &lt;p&gt;In the current study, the investigators analyzed bacterial and fungal DNA from the spit samples. Then, they identified 445 patients who were diagnosed with pancreatic cancer and compared the DNA of their microbes with that of another 445 randomly selected study subjects who had remained cancer-free. The team made sure to account for factors known to play a role in developing the condition, such as age, race, and how often subjects smoked cigarettes.&lt;/p&gt;
    &lt;p&gt;The findings identified 24 species of bacteria and fungi that individually either raised or lowered pancreatic cancer risk. Another three kinds of bacteria tied to the cancer were already known to contribute to periodontal disease, a serious gum infection that can eat away at the jawbone and the soft tissues surrounding teeth.&lt;/p&gt;
    &lt;p&gt;Altogether, the entire group of microbes boosted participants’ chances of developing the cancer by more than threefold.&lt;/p&gt;
    &lt;p&gt;In addition, by assessing the makeup of each participant’s oral microbiome, the scientists for the first time developed a tool that could estimate their cancer risk.&lt;/p&gt;
    &lt;p&gt;“By profiling bacterial and fungal populations in the mouth, oncologists may be able to flag those most in need of pancreatic cancer screening,” said study co-senior author Jiyoung Ahn, PhD, a professor in the Departments of Population Health and Medicine at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;Dr. Ahn, who is also the associate director for population sciences at Perlmutter Cancer Center, notes that there are currently few effective screening methods for the disease, which is among the deadliest forms of cancer.&lt;/p&gt;
    &lt;p&gt;“It is clearer than ever that brushing and flossing your teeth may not only help prevent periodontal disease but may also protect against cancer,” said study co-senior author Richard Hayes, DDS, MPH, PhD, a professor in the Department of Population Health.&lt;/p&gt;
    &lt;p&gt;Dr. Hayes, who is also a member of Perlmutter Cancer Center, emphasizes that the study was designed to identify correlations between disease risk and certain microbes in the mouth, but not to establish a direct cause-and-effect link. That will require further investigation.&lt;/p&gt;
    &lt;p&gt;The research team next plans to explore whether oral viruses could contribute to cancer and how the mouth’s microbiome may affect patients’ chances of survival, adds Hayes.&lt;/p&gt;
    &lt;p&gt;Funding for the study was provided by National Institutes of Health grants P30CA016087, P20CA252728, R01LM014085, R01CA159036, and U01CA250186.&lt;/p&gt;
    &lt;p&gt;Along with Dr. Meng, Dr. Hayes, and Dr. Ahn, other NYU Langone researchers involved in the study are Feng Wu, PhD; Soyoung Kwak, PhD; Chan Wang, PhD; Tamas A. Gonda, MD; Paul E. Oberstein, MD; and Huilin Li, PhD.&lt;/p&gt;
    &lt;p&gt;Other study co-investigators include Mykhaylo Usyk, PhD, at Albert Einstein College of Medicine in New York City; Neal Freedman, PhD, and Wen-Yi Huang, PhD, at the National Cancer Institute in Rockville, Maryland; and Caroline Um, PhD, at the American Cancer Society in Atlanta.&lt;/p&gt;
    &lt;head rend="h2"&gt;About NYU Langone Health&lt;/head&gt;
    &lt;p&gt;NYU Langone Health is a fully integrated health system that consistently achieves the best patient outcomes through a rigorous focus on quality that has resulted in some of the lowest mortality rates in the nation. Vizient Inc. has ranked NYU Langone number one out of 118 comprehensive academic medical centers across the nation for four years in a row, and U.S. News &amp;amp; World Report recently ranked four of its clinical specialties No. 1 in the nation. NYU Langone offers a comprehensive range of medical services with one high standard of care across seven inpatient locations, its Perlmutter Cancer Center, and more than 320 outpatient locations in the New York area and Florida. With $14.2 billion in revenue this year, the system also includes two tuition-free medical schools, in Manhattan and on Long Island, and a vast research enterprise.&lt;/p&gt;
    &lt;head rend="h3"&gt;Media Inquiries&lt;/head&gt;
    &lt;p&gt;Shira Polan&lt;lb/&gt; Phone: 212-404-4279&lt;lb/&gt; Shira.Polan@NYULangone.org&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389464</guid><pubDate>Fri, 26 Sep 2025 18:20:33 +0000</pubDate></item><item><title>Gunman in shooting at NFL headquarters had CTE: Medical examiner</title><link>https://abcnews.go.com/US/shane-tamura-gunman-shooting-nfl-headquarters-cte-medical/story?id=125972038</link><description>&lt;doc fingerprint="73005938ba440fee"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Shane Tamura, gunman in shooting at NFL headquarters, had CTE: Medical examiner&lt;/head&gt;
    &lt;p&gt;Tamura killed four people in the shooting in July.&lt;/p&gt;
    &lt;p&gt;Shane Tamura, who drove cross-country from Las Vegas and opened fire at the New York headquarters of the NFL, killing four, had CTE, the New York City Office of the Chief Medical Examiner said Friday, confirming what was in the shooter’s own writings.&lt;/p&gt;
    &lt;p&gt;Police found a three-page note in Tamura’s pocket claiming he had a traumatic brain injury and blaming the NFL for "concealing the dangers to players’ brains to maximize profits."&lt;/p&gt;
    &lt;p&gt;Elsewhere, Tamura wrote, "Study my brain please. I'm sorry."&lt;/p&gt;
    &lt;p&gt;Tamura died of a self-inflicted gunshot wound.&lt;/p&gt;
    &lt;p&gt;"Following a thorough assessment and extensive analysis by our neuropathology experts, OCME has found unambiguous diagnostic evidence of Chronic Traumatic Encephalopathy, also known as CTE, in the brain tissue of the decedent. The findings correspond with the classification of low-stage CTE, according to current consensus criteria,” the medical examiner’s office said.&lt;/p&gt;
    &lt;p&gt;"CTE may be found in the brains of decedents with a history of repeated exposure to head trauma. The science around this condition continues to evolve, and the physical and mental manifestations of CTE remain under study," it continued.&lt;/p&gt;
    &lt;p&gt;The medical examiner’s office previously said Tamura died by suicide of a self-inflicted gunshot wound. The pathologists do not say whether CTE played a role.&lt;/p&gt;
    &lt;p&gt;The NFL said in a statement, "We continue to grieve the senseless loss of lives, and our hearts remain with the victims' families and our dedicated employees."&lt;/p&gt;
    &lt;p&gt;"There is no justification for the horrific acts that took place," the NFL statement continued. "As the medical examiner notes 'the science around this condition continues to evolve, and the physical and mental manifestations of CTE remain under study.'"&lt;/p&gt;
    &lt;p&gt;Four people were killed in the shooting: Aland Etienne, a security guard for the building; Wesley LePatner, an executive at Blackstone who was a wife and mom; Didarul Islam, a police officer who was a dad of two; and Julia Hyman, a young employee at Rudin Management. All except for Hyman were killed in the building's lobby.&lt;/p&gt;
    &lt;p&gt;All of the victims in the lobby were shot in less than 30 seconds.&lt;/p&gt;
    &lt;p&gt;Tamura then moved to the elevator bank, inexplicably allowing a woman to pass unharmed, police said. Detectives believe he went looking for the NFL offices but entered the wrong elevator.&lt;/p&gt;
    &lt;p&gt;He ended up on the 33rd floor about 6:28 p.m.&lt;/p&gt;
    &lt;p&gt;In that time, office cleaner Sebije Nelovic said Tamura fired at her but missed. Nelovic said in a statement sent by her union that she ran down the hall, hid in a closet and "started praying."&lt;/p&gt;
    &lt;p&gt;She said she heard shouting, then footsteps, as the gunman moved toward the closet where she was hiding.&lt;/p&gt;
    &lt;p&gt;As gunshots hit the closet door, Nelovic said she thought of Hyman, the 27-year-old who often worked late in the offices of Rudin Management, the company that operates the building.&lt;/p&gt;
    &lt;p&gt;"I thought, 'God help her,'" Nelovic said.&lt;/p&gt;
    &lt;p&gt;Hyman was the last person shot and killed before Tamura killed himself approximately four minutes after arriving on the 33rd floor.&lt;/p&gt;
    &lt;p&gt;All told, police said he fired 47 rounds, a number that indicates he reloaded once.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389674</guid><pubDate>Fri, 26 Sep 2025 18:39:57 +0000</pubDate></item><item><title>When Bruce Lee trained with Kareem Abdul-Jabbar</title><link>https://lithub.com/when-bruce-lee-trained-with-kareem-abdul-jabbar/</link><description>&lt;doc fingerprint="be648895d3a52e5f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When Bruce Lee Trained With Kareem Abdul-Jabbar&lt;/head&gt;
    &lt;head rend="h3"&gt;Jeff Chang on What Two Iconic Athletes Learned From Their Collaboration&lt;/head&gt;
    &lt;p&gt;When Bruce Lee met Kareem Abdul-Jabbar, a month after the 1968 national college basketball championship, he was still known as Lew Alcindor, the most hyped young basketball star in history.&lt;/p&gt;
    &lt;p&gt;Lew was seven feet two and, for his whole life, had been unable to hide. He disarmed reporters with a fierce intelligence masked by a laconic intensity. He was just completing his junior year at UCLA, and after indulging in two years of partying, drugs, and women, he wanted something different. “All sophomore and junior years I’d been looking for something to believe in,” he would later write.&lt;/p&gt;
    &lt;p&gt;During those two years, he had been in the eye of the storm. In the “Game of the Century,” witnessed by fifty-two thousand in the Houston Astrodome and millions more on television on January 20, 1968, he brought men’s college basketball to new heights. That night he played with blurred vision after having his cornea scratched. UCLA lost by a basket to the University of Houston, breaking their forty-seven- game winning streak, and the team melted down in its aftermath. Lew’s closest friend, a Black man from South Central Los Angeles, quit the team in a dispute with coach John Wooden, and racial tensions simmered in the locker room the rest of the season.&lt;/p&gt;
    &lt;p&gt;To him, Bruce was as effective a teacher as John Wooden. Both were focused on fundamentals, preparation, and what worked.&lt;/p&gt;
    &lt;p&gt;By the end of the season, Lew had led UCLA to its second consecutive national championship and was voted Most Outstanding Player for the second year in a row. It was the year that began the “March Madness” era. But after the season, he retreated.&lt;/p&gt;
    &lt;p&gt;Born Ferdinand Lewis Alcindor in 1947, the day after Jackie Robinson desegregated pro sports, he had grown up in an integrated housing project in uptown Manhattan. In third grade he stared at a Polaroid of his class: “There I was, freakishly towering over all the other kids, with skin much darker than everyone else’s.” When he was twelve, his white friends abandoned him. His former best friend picked a fight with him one day, calling him a “jungle bunny” and “big jungle n——r.”&lt;/p&gt;
    &lt;p&gt;At seventeen, Lew stepped out of the subway in Harlem and was caught in the first hours of six days of rioting that followed the police shooting of a Black teen. As bottles and bullets whizzed by and buildings went up in flames, he ran home. “Right then and there I knew who I was and who I was going to be. I was going to be Black rage personified, Black power in the flesh,” he later wrote. He led his team to a 79-2 record and two national high school championships. But once, to motivate him in a game, his coach had called him a “n——r,” and he never forgot it.&lt;/p&gt;
    &lt;p&gt;In his sophomore year at UCLA, in 1967, he was traveling with extra security because of death threats. He took comfort in listening to hard bop and reading about African and Asian history and religion. He was particularly captivated by The Autobiography of Malcolm X and the late Black leader’s journey into Sunni Islam, and sought out young Black Muslims in Los Angeles.&lt;/p&gt;
    &lt;p&gt;That summer he was the only college athlete among a group of prominent Black athletes invited by Jim Brown to meet with Muhammad Ali to try to change the boxer’s mind about his anti-war stance. Ali had asked, “Why should they ask me to put on a uniform and go ten thousand miles from home and drop bombs and bullets on brown people in Vietnam while so-called Negro people in Louisville are treated like dogs and denied simple human rights?” After declaring, “I don’t have no personal quarrel with those Vietcong,” he saw his heavyweight boxing title revoked, and faced a prison sentence for draft evasion. The men spent hours grilling Ali on his position, then emerged to face the press. Alcindor sat beside Brown, Ali, and Bill Russell as the athletes joined together in a historic show of solidarity for Ali.&lt;/p&gt;
    &lt;p&gt;Invited to a Black Youth conference by a young San Jose State College professor named Harry Edwards, who was organizing a Black athletes’ boycott of the 1968 Olympics, Alcindor spoke with conviction:&lt;/p&gt;
    &lt;p&gt;I’m the big basketball star, the weekend hero, everybody’s All American. Well, I was almost killed by a racist cop shooting at a black cat in Harlem. He was shooting on the street—where masses of people were standing around or just taking a walk. But he didn’t care. After all we were just n——rs. I found out that we don’t catch hell because we aren’t basketball stars or because we don’t have money. We catch hell because we are black. Somewhere each of us has got to make a stand against this kind of thing.&lt;/p&gt;
    &lt;p&gt;But in the media, an explosion of racist invective followed him and other Black athletes as they were accused by white writers of being ungrateful, unpatriotic, uppity “Black Hitlers.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;Weeks after the 1967 championship, the NCAA banned the dunk—in what became known as the “Alcindor rule”—an effort he believed was racist. Forced to improvise, he contemplated how to deal with triple-team defenses and worked on a new offensive weapon: the skyhook. One night after watching a Zatoichi flick, he was struck by the idea that the blind swordsman’s grace, control, and precision might be exactly what he needed. Instead of brute force, he thought, I will slide and roll and slip by them without fouling. In New York City, Alcindor started training in aikido.&lt;/p&gt;
    &lt;p&gt;“A victory [in martial arts] is your mind over someone else’s mind, as much as, if not more than, a simple physical mastery,” he later wrote. “The discipline also becomes a means of staying in shape mentally and keeping your entire inner self trained.”&lt;/p&gt;
    &lt;p&gt;That fall Alcindor visited the Black Belt offices to meet a fellow aikido adept, Mito Uyehara, and ask him if he knew someone with whom he could continue his martial arts training. Alcindor had become especially curious about tai chi. “This guy Bruce Lee—he’s really good at it,” Mito told him. “He knows more about those things than I do.”&lt;/p&gt;
    &lt;p&gt;“Who’s Bruce Lee?” Alcindor asked. “He was Kato in The Green Hornet.”&lt;/p&gt;
    &lt;p&gt;Alcindor was skeptical he could learn anything from an actor. “No, no! He’s the real deal.”&lt;/p&gt;
    &lt;p&gt;That night Mito drove to see Bruce and said he was sending Lew Alcindor over. “Who’s Lew Alcindor?” Bruce asked.&lt;/p&gt;
    &lt;p&gt;Mito explained that he was the tallest and most famous college basketball player in the country.&lt;/p&gt;
    &lt;p&gt;“I don’t watch basketball.”&lt;/p&gt;
    &lt;p&gt;Bruce asked Linda to bring a tape measure, stood on a chair, and dropped it down, to visualize Alcindor’s height. Then he thought aloud, “I wonder how fast he is.” Mito assured Bruce he was very fast, one of the best athletes in the world.&lt;/p&gt;
    &lt;p&gt;“He would have no chance with me,” Bruce said with a chuckle. “I would break his legs before he could do anything else.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;They met for the first time at Bruce and Linda’s house on a comfortable Los Angeles afternoon.&lt;/p&gt;
    &lt;p&gt;“He greeted me with a broad smile and friendly demeanor and right away I knew this was not a scowling teacher from Japanese films demanding bowing obedience,” Alcindor recalled. “We talked UCLA basketball for a while and then got down to business.”&lt;/p&gt;
    &lt;p&gt;Bruce first had Lew punch and kick the heavy bag, so he could gauge the big man’s power. Then he called Linda over, asked Lew to hold a pad to his chest, and told Linda to kick it. Linda grinned and got up from the patio seat where she had been watching.&lt;/p&gt;
    &lt;p&gt;“Bruce, I don’t think this will work,” Alcindor said. “I’m two feet taller and a hundred pounds heavier than Linda.”&lt;/p&gt;
    &lt;p&gt;“Just hold it up to your chest, Lew,” Linda said.&lt;/p&gt;
    &lt;p&gt;He lowered the pad so that it would be below her head.&lt;/p&gt;
    &lt;p&gt;“Your chest,” Linda said, frowning and pointing at the pad. “Do you want Bruce to show you where that is?”&lt;/p&gt;
    &lt;p&gt;He moved the pad up. Bruce nodded at Linda. Kareem would never forget what happened next.&lt;/p&gt;
    &lt;p&gt;“Suddenly Linda fired off a kick that not only reached the pad, but the impact rocked me backward a few feet, readjusted my spine, and possibly rearranged the order of my teeth,” he remembered. “They stood there smiling at the shocked expression on my face.”&lt;/p&gt;
    &lt;p&gt;Linda—Bruce’s longest-running student except for Taky—had just done what Bill Walton, Happy Hairston, Kent Benson, and Robert Parish never would.&lt;/p&gt;
    &lt;p&gt;“Okay,” Alcindor said, still sore where she had kicked him. “Teach me that.”&lt;/p&gt;
    &lt;p&gt;Bruce was just as intrigued. Not long afterward, he told Leo Fong, “You know why I’m getting him to train with me? I want to learn how to beat a tall guy!”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;“Big Lew,” as Bruce called him, came to his backyard every Tuesday during the off-season, and sometimes Thursdays as well. Bruce taught him Jeet Kune Do footwork, the mook jong dummy, and punches and kicks on the bag. At first, Bruce told Mito that Big Lew was slow, his arms were weak, and he wasn’t good at chi sao. A reporter who witnessed one of their workouts was more impressed with Bruce than Big Lew. He wrote that Bruce could “leap and kick over Alcindor’s head, and says he can defeat him by taking advantage of his shin and thigh with a kick.”&lt;/p&gt;
    &lt;p&gt;But Bruce soon realized all that was irrelevant. Even if he could get inside Big Lew’s reach, it wasn’t easy. And with his front kick, Big Lew could rattle the rim of the basket. Bruce’s Wing Chun skills were all but useless. He joked with Doug Palmer, “Try doing chi sao with someone when you’re staring at his belly button.” Bruce called Taky and told him not to focus on chi sao in the school anymore.&lt;/p&gt;
    &lt;p&gt;“Bruce and I sparred regularly,” Kareem remembered. “But we didn’t compete; I was like a drawing board on which he could work out his theories and he was instructing me how to deal with people and attack him.”&lt;/p&gt;
    &lt;p&gt;Kareem came to appreciate Bruce’s approach. “Nothing was for art’s sake. Everything he taught was to achieve an end in doing damage to an opponent,” he recalled. “After studying for a little while, you learn a lot about how easy it is to hurt someone, and how easily you can get hurt. That makes you really respect what you’re involved in. With violence, you learn to respect it and see how easily you can become victimized by it.”&lt;/p&gt;
    &lt;p&gt;To him, Bruce was as effective a teacher as John Wooden. Both were focused on fundamentals, preparation, and what worked. “Bruce used to say, ‘I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.’ In sports, we call this concept ‘muscle memory,’” he said. “For me, my hook shot was the one kick practiced 10,000 times.”&lt;/p&gt;
    &lt;p&gt;Bruce helped the young athlete understand his movements in a way that seemed to decelerate time. “Bruce showed me how to harness some of what was raging inside me and summon it completely at my will. The Chinese call it chi; the Japanese, ki; the Indians, prana—it is the life force,” he said. “I was quite amazed to find, after working with Bruce, that when I really had my presence of mind, when I did control my life force, that’s what I saw, things coming at me in slow motion with plenty of time to get out of the way.&lt;/p&gt;
    &lt;p&gt;Bruce helped the young athlete understand his movements in a way that seemed to decelerate time.&lt;/p&gt;
    &lt;p&gt;“It sounded mystical when he first told me, but I was becoming increasingly involved in matters of faith, and besides, Bruce grounded his philosophies in a good fight, which I could relate to.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;These sessions were a refuge from the media, who were painting Lew Alcindor as a coddled, ungrateful, unpatriotic athlete. In July 1968 he had agreed to an interview on the Today show to highlight the summer program for Black youths where he was working. But sports announcer Joe Garagiola ambushed him, asking Alcindor why he had declined to play in the Olympics. “You live here,” Garagiola said.&lt;/p&gt;
    &lt;p&gt;“Yeah, I live here, but it’s not really my country,” Alcindor answered. “Well then, there’s only one solution: maybe you should move.”&lt;/p&gt;
    &lt;p&gt;“Well, you see,” Alcindor responded, heating up, “that would be fine with me, you know, it all depends on where we are going to move?”&lt;/p&gt;
    &lt;p&gt;The producers cut away to a commercial.&lt;/p&gt;
    &lt;p&gt;“I felt no part of the country and had no desire to help it look good,” he later recalled. “I had better things to do.”&lt;/p&gt;
    &lt;p&gt;That summer he joined a mosque, declared shahada, became a Sunni Muslim, and received a new name: Abdul-Kareem, later Kareem Abdul-Jabbar, “noble, generous servant, powerful spirit.” He kept his name to himself and his closest friends until he asked the media two years later to call him by it. He recalled, “I was still Lew to almost everybody, as if I knew them but they didn’t know me….&lt;/p&gt;
    &lt;p&gt;“The heat I’d taken about the Olympics, and the absolute unwillingness I’d found in the press, and by extension the general public, to accept what to me seemed so obvious—that the country was run by white people for white people, and that even the most powerful Black men were still operating at a handicap—made me suspicious of strangers and even more jealous of my privacy.”&lt;/p&gt;
    &lt;p&gt;But with Bruce, everything was easy. The two talked philosophy and religion. They went to see Zatoichi flicks. Kareem even babysat sometimes, lifting Brandon up to give the five-year-old a view of the roof. They shared an understanding of fame and privacy. From youth, both of them had been under the spotlight.&lt;/p&gt;
    &lt;p&gt;In Chinatown they never paid for meals—everyone was a UCLA fan—and they often ate in the kitchen. Bruce joked to their companions that it would guarantee they weren’t getting the garbage served to the gweilo. But Bruce was also shielding the big man from the rabid autograph seekers.&lt;/p&gt;
    &lt;p&gt;“Bruce and I had something else in common,” Kareem recalled. “We both had experienced discrimination.”&lt;/p&gt;
    &lt;p&gt;Kareem talked about the Black liberation movement and his role in what Harry Edwards had come to call “the revolt of the Black athlete.” Bruce shared his frustrations with Hollywood, saying he sometimes felt like a “valet to the stars.” They swapped books. Bruce gave Kareem Miyamoto Musashi’s Book of Five Rings. Kareem gave him books to read on Islam and imperialism. He told a shocked Bruce that Europeans had barred Chinese from parks in their own cities.&lt;/p&gt;
    &lt;p&gt;“I recommended certain books about the British occupation of China,” Kareem said. “He didn’t know anything about that, and he’d gone to school in Hong Kong.”&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Excerpted from the book Water Mirror Echo: Bruce Lee and the Making of Asian America by Jeff Chang. Copyright © 2025 by Jeff Chang. From Mariner Books, an imprint of HarperCollins Publishers. Reprinted by permission.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389889</guid><pubDate>Fri, 26 Sep 2025 19:04:27 +0000</pubDate></item><item><title>If you are harassed by lasers</title><link>https://www.laserpointersafety.com/harassment.html</link><description>&lt;doc fingerprint="76c29116b4a1179f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Home&lt;/head&gt;
    &lt;head rend="h2"&gt;A comprehensive resource for safe and responsible laser use&lt;/head&gt;
    &lt;head rend="h1"&gt;If you are harassed by lasers&lt;/head&gt;
    &lt;head rend="h3"&gt;If the light is obviously coming from a laser&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple harassment -- a beam on your skin or clothes -- is probably not punishable unless it continues, or unless it occurs during a critical situation such as driving.&lt;/item&gt;
      &lt;item&gt;Deliberate aiming at your head or eyes is serious due to the unlikely but possible potential for causing eye damage. This could be considered as assault. For more on eye damage, see the information on when does a laser pointer get powerful enough to be dangerous.&lt;/item&gt;
      &lt;item&gt;If you have had laser light in your eyes, see the page If you are hit by a laser.&lt;/item&gt;
      &lt;item&gt;A partial list of laser harassment incidents is here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, here is a case in 2018 of a visible green laser harassing a number of people at least five times over two weeks. The laser can easily be seen and photographed:&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see laser beams or dots in a photo or video&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The green and blue "laser" dots at lower left are actually lens flare caused by the bright sun at upper right. The sun is reflecting off elements inside the lens, causing dots or flare. The flare is almost always located diagonally mirrored from a bright light source.&lt;lb/&gt;Photo of a sunset, with upper and lower "beams" caused by blooming in the camera sensor.&lt;lb/&gt;This is a still frame from a video taken at night by the driver of a moving car, out their driver-side window. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The line on the left is a trail of a flying insect, not a laser beam. It is a curved, short line segment. If it was a laser beam it would be straight and it would not stop in mid-air like this. Plus note that the path is not aimed at the camera or the house. Even if it was a laser beam, it would not hit anyone in the house on the right where the camera is. &lt;/p&gt;
    &lt;p&gt;Click on the picture below to see video of a lens flare which looks remarkably like a laser. However, it is definitely a lens flare; there are many clues as to why it is actually the sun in the upper right reflecting off the inside of camera elements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Lens flare example video (click to start)Why this is not a laser: 1) The green dot does not illuminate or interact with the ground. 2) It looks like an overlay. 3) It moves diagonally opposite to the bright light source (sun), always perfectly tracking it. Example courtesy M.L., Sept. 2021. Taken with a Samsung A10 phone's rear camera.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a case described below (in "A few cases and emails we received"), a woman reported a uniform blue tint on her Blink security camera. The tint was not caused by a laser, but by a flaw in the camera or perhaps a lens effect.&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see light or feel heat from an unknown source&lt;/head&gt;
    &lt;head rend="h4"&gt;Light&lt;/head&gt;
    &lt;p&gt;If you see light that is not from any obvious source, try blocking it. Visible laser light can be blocked by anything that also blocks conventional light, such as a solid curtain, a wall, or even a sheet of paper.&lt;/p&gt;
    &lt;p&gt;If you do see flashes when all external light paths are blocked, consult your doctor or do an internet search. There can be medical conditions that cause flashes.&lt;/p&gt;
    &lt;p&gt;The author of this page has seen "flocks of birds" in daytime and "falling stars" at night. It turned out to be minor retinal detachment that went away. This is one reason the author is sympathetic to people who experience sensations that are 100% real to them, even if the sensations come from inside their bodies.&lt;/p&gt;
    &lt;head rend="h4"&gt;Heat&lt;/head&gt;
    &lt;p&gt;If you feel heat spots, first try to block them, to see if they are coming from outside your body. Try using metal objects such as aluminum foil, a baking sheet or a cast-iron skillet. Hold the material over the area where you are having heat or pain, to see if it goes away.&lt;/p&gt;
    &lt;p&gt;If you continue to feel heat, consult your doctor or do an Internet search. There can be medical conditions that cause localized and/or intermittent feelings of being hot, such as fibromyalgia.&lt;/p&gt;
    &lt;head rend="h4"&gt;Get evidence and/or others to confirm&lt;/head&gt;
    &lt;p&gt;If you want to try and track down the beams, get photographic and/or video evidence if at all possible. Ideally this would be pictures of the beams or the laser "dot", and also pictures of any damage. Note the section above about how photos can have lens flare, sensor blooming or other things internal to the camera.&lt;/p&gt;
    &lt;p&gt;If you have family or friends who can help, ask them to stay with you or stay at your house. If others can confirm what you are seeing or feeling, then they can help you in finding the reasons why.&lt;/p&gt;
    &lt;p&gt;A number of people who contacted us, also contacted their local police. In all cases, the police either investigated but took no action, or declined to investigate. One person said their local police department no longer handled calls involving lasers.&lt;/p&gt;
    &lt;p&gt;It may be helpful to hire a private investigator. They can look into suspicious behavior and evidence, and can try to confirm reports of burn marks, burning sensations, etc. If police action is warranted, the police may take a licensed private investigator more seriously than an ordinary citizen. But beware of unscrupulous private investigators who may claim to help you, but who will only string you along to keep making money off you.&lt;/p&gt;
    &lt;head rend="h3"&gt;If the harassment seems mysterious, ongoing, or well-organized&lt;/head&gt;
    &lt;p&gt;These persons clearly feel effects. But their symptoms are often inexplicable by normal means. For example, they can feel heat on their skin which they believe is from beams going through solid walls. There are some types of electromagnetic radiation, such as terahertz waves and microwaves, which can go through objects. But visible laser light — which is also electromagnetic radiation — is stopped by any material or substance that would also stop conventional light such as from a flashlight.&lt;/p&gt;
    &lt;head rend="h4"&gt;You are not alone …&lt;/head&gt;
    &lt;p&gt;If you are a person plagued by mysterious, unknown causes, the good news is you are not alone. At LaserPointerSafety.com, we used to get calls every month or two from persons who say they are being continually harassed by light and energy beams. (We no longer take such calls, due to their frequency and our inability to solve such mysterious cases.)&lt;/p&gt;
    &lt;p&gt;Clearly these people and you are seeing and feeling something. We understand you are not imagining your sensations — they are real to you.&lt;/p&gt;
    &lt;head rend="h4"&gt;… but the cause is unknown&lt;/head&gt;
    &lt;p&gt;But the bad news is that what you are feeling usually does not have any plausible physical explanation. This means it is very unlikely that mysterious beams or exotic devices are able to cause your symptoms.&lt;/p&gt;
    &lt;p&gt;It is highly unlikely that ordinary persons can buy or otherwise obtain powerful directed energy beams that go through walls. Such devices are exotic and expensive. Even if someone works for the police or military, this would not be regular issue "take home" equipment.&lt;/p&gt;
    &lt;p&gt;Also, there is usually no reason that your neighbors would undertake a prolonged, continual, and expensive attack against you. (Frankly, if they did want to harass or harm you, there are easier and less costly ways to do so.)&lt;/p&gt;
    &lt;p&gt;If you are having such symptoms, the cause, in our view, is most likely something that has gone wrong in your body.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be your nerves are misfiring, leading you to see light or feel heat when there is no external source. [In experiments published in 2007, subjects had low-level laser light shined on a rubber hand that was positioned over their own hand. Sixty-six percent of subjects reported heat or tactile sensations from the laser light — even though 1) the light was on a rubber hand, not their own and 2) the laser power was low enough that it would not noticeably heat up even on a real hand.]&lt;/item&gt;
      &lt;item&gt;If you are seeing flashes of light at night, or dark swarms (like a flock of birds) during the daytime in your peripheral vision, this can be due to retinal detachment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be something in your brain that is manufacturing false symptoms and/or feelings of being stalked or harassed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are feeling harassed by inexplicable causes, we advise that you see one or more medical specialists such as neurologists. Describe your symptoms to the doctor without going into detail about the potential cause (beams) or reasons (angry neighbors). You can tell the doctor "it feels like this is coming from outside my body" but concentrate on describing the symptoms of what you are experiencing physically and mentally.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a medical reason is found for your issues, this is reassuring that you are not a victim of organized harassment. Hopefully you can be treated and the sensations will go away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If there is no medical reason initially found, keep in mind that does not mean that the alternative explanation (angry neighbors are getting exotic beam weapons and aiming them at you) is true. It may be there is a deeper or unknown medical reason. Again, other people have reported similar symptoms, so there must be some common underlying cause in the body or mind.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more information, see the section below "An example case - trying to help a friend".&lt;/p&gt;
    &lt;head rend="h3"&gt;Be careful not to escalate the situation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In a 2018 case, a man in Arkansas shot and killed a neighbor who, among other harassments, had allegedly aimed red, blue and green lasers into his house. When the neighbor went to pick up a laser pointer, the man thought it was a gun and killed him in claimed self-defense. (The man was acquitted by a jury of first-degree murder charges.)&lt;/item&gt;
      &lt;item&gt;In the example case of "H" which is listed below, a woman who believes her neighbors are harassing her with light and heat beams is going around to their homes with a loaded gun, looking for the source. This may not end well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whatever the level of harassment, let law enforcement look into it and (hopefully) solve the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few cases and emails we received&lt;/head&gt;
    &lt;p&gt;NOTE: As of September 1 2023, we no longer take calls or reply to emails about heat lasers, strange dots or lines in photos &amp;amp; videos, or "mysterious, ongoing or well-organized" harassments as described above.&lt;lb/&gt; We do sympathize with those experiencing such issues. The most help we can give is to let people know that others have reported similar experiences, so they are not alone. The cases listed below occurred prior to Sept. 1 2023.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; An example case - "H" is trying to help a friend&lt;/item&gt;
      &lt;item rend="dd-1"&gt;We were contacted by a person we'll call "H", who was trying to help her friend "F" of 30 years.&lt;lb/&gt;About two months before the call, H's friend suddenly (over a period of a few weeks) started seeing mysterious lights and feeling mysterious heat. This is an especially interesting case since:&lt;lb/&gt;1) F was "normal" for decades before this started.&lt;lb/&gt;2) The symptoms that F describes are very common among other people who have contacted us.&lt;lb/&gt;3) H has spent substantial time with F, looking for logical, rational explanations for what F said she was experiencing.&lt;lb/&gt;F at first thought harassing beams were coming from the cable company so the cable wiring was replaced. This did not help. F then thought it was coming from the home security company; that was not the cause. F replaced her ceiling fan since she thought she saw faces in it. Her windows are covered with heavy blankets yet light or heat beams still somehow get in, according to F.&lt;lb/&gt;There are numerous security cameras around F's house but so far she has not captured anyone coming up to the house. Unfortunately, she has started going to neighbors' homes — with a loaded gun — looking for the source. This of course could escalate into a dangerous situation.&lt;lb/&gt;H said there was no apparent cause for F to start seeing lights and feeling heat. F had some traumatic life events such as deaths of close family members, in the two years prior to onset. But there was no single event or physical trauma that corresponded with the start of F's symptoms.&lt;lb/&gt;H has tried to help her friend. For example, H and her husband went to F's home for 16 hours, staying awake through the night and going outside from time to time to look for any unusual activity. They saw and felt nothing abnormal. (F was asleep the entire time so she did not report any strange sightings or feelings during the time H and her husband were there.)&lt;lb/&gt;The police have been at F's home numerous times. But they have not found anything and cannot help further. The FBI was contacted but did not get involved.&lt;lb/&gt;We advised H to have her friend see medical specialists such as a neurologist. F should describe the symptoms (what she is seeing and feeling) without stating that it is coming from the outside.&lt;lb/&gt;We also said that the medical exams and tests may not turn up anything. This is based on our experience where we have never had a person call us back, saying "Oh, the doctor found I had ABC disease" or "It stopped when I started taking XYZ medication."&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Email #1 - Laser harassment 24/7&lt;/item&gt;
      &lt;item rend="dd-2"&gt;&lt;code&gt;We live across the street from a neighbor who has her laser lights on 24 hrs/7days a week. She shines her laser lights in other neighbors faces, heads, at children, family pets, windows of houses, plants and trees (which are singed from being over exposed/burned by laser lights), aircraft, on our parked vehicles, &amp;amp; vehicles driving down the street. When I have been in the front yard my eyes and face start burning from the lasering. The police have been called several times, but state that they cannot do anything.&lt;/code&gt;&lt;code&gt;Here are pictures of the laser attacks:&lt;/code&gt;&lt;code&gt;Do you have any suggestions on how to go about getting this individual to stop harassing &amp;amp; terrorizing us?&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;You described your eyes and face burning when in your front yard. It would take a very powerful and expensive laser to do this. A simple laser pointer would not be able to create heat on your skin at a long distance such as across a yard. The most powerful handheld laser currently available [summer 2010] is the 1-watt Wicked Laser Arctic. It can burn skin but at a very close distance, and the burn is very small such as the size of a pea or less.&lt;lb/&gt;You also stated that various surfaces were singed. Again, it would take a very, very powerful and VERY expensive laser to do this. It is very hard to imagine any use outside of military or police (riot control), and even these are exceedingly rare.&lt;lb/&gt;One way to tell if a laser is being used against you is to see if it only happens when you are in line with a window or similar opening to the outdoors. This is because walls will stop laser beams, but windows can let light through. (Of course, windows also let through sunlight and heat (infrared), so just being warm next to a window can be caused by normal, non-laser reasons.)&lt;lb/&gt;Both photos that you sent have a vertical line that goes through a strong light in the photo. This straight line is NOT a laser. It is an artifact of how some digital cameras work. If there is a light source that is too strong for the camera's digital chip, then all pixels in the same vertical line will be overwhelmed. This is called blooming. You can read more about blooming here.&lt;lb/&gt;One question I have for you is whether you have seen laser beams with your own eyes (not from a camera's video). I am guessing the answer is "no".&lt;lb/&gt;I do not want to say absolutely, positively 100% that there is no laser activity from your neighbor's house. The world is very large, and every now and then there are strange things. However, I am 99.999% sure that there is no laser activity from your neighbor's house. Certainly the photos you have sent depict the blooming effect that is very common on some digital camera chips. There is no doubt that what is in the photos is NOT laser. The other effects you state, such as heating and singeing, are highly, extremely unlikely to be caused by any type of laser that a residential person would have access to or could afford.&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Email #2 - Lasers cause pinpoint holes&lt;/item&gt;
      &lt;item rend="dd-3"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;I have been getting burned for now about a year. I have been finding burn holes in my mini-blinds. My dog I have found burn holes on her skin also, Is there anything I can do ? It is really painful and I think they did this so I had to sell my home because I felt that my life was in danger I would be walking in the house and then I would get this burning sensation in my eyes and then I would fell my arms would be burning didn't matter what side of the house I was at I would get burned, I would tell people and they would say that's weird.&lt;/code&gt;&lt;code&gt;So I sold my home because I feel they chased me out by hurting me and my dog. I think they even killed some kittens with this laser flashlight. I am writing to you cause no one help me or those kitten that didn't make or had a chance, I think there should be a law against this it is really scary and painful. Thank you for having this information on the internet and maybe it can help someone.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;It is very difficult to use a laser to create holes at long range (more than a few yards or meters). It also requires a very expensive laser, to have enough power to make holes at long range. I would not know why someone would go to this trouble.&lt;lb/&gt;If what you are seeing is small, pinpoint holes, it is highly unlikely that these are from a laser aimed at a distance. Laser beams do spread out, even a little bit. For example, the beam at the aperture (output opening) of a powerful laser might be very small. This might be a few millimeters or up to 1/4" in diameters, and the edge of the hole would be sharp. At a house-to-house distance, the hole might be the size of a quarter at least, and the edges might be more ragged, with burn or scorch marks around the hole.&lt;lb/&gt;If a person is walking around with a hand-held laser (laser pointer or battery-powered laser), then they could get close enough to make small holes or burn marks. For a laser pointer, this takes a LOT of power and is expensive. I do not know why someone would do this. (If they wanted to cause trouble, there are a lot of ways that are more effective, much less expensive, and also hard-to-trace.)&lt;lb/&gt;It is possible for the laser beam to be invisible to our eyes. Infrared lasers have beams which we can't normally see. However, you can use a camcorder to try to see these beams. To try this, point the camcorder at an infrared remote control, which are very common for TVs, etc. When you press a button on the remote control, you should see a light flash in the camcorder viewfinder (but not with your eyes). If your camcorder can see the infrared light, then you should be able to see infrared laser beams using the camcorder's viewfinder or fold-out monitor.&lt;lb/&gt;If someone is using a laser in the way you describe, this is illegal. It is damaging your property, cruelty to animals, and assault &amp;amp; battery. You could call the police -- but you should be sure that you really do have evidence.&lt;lb/&gt;For your own sensations of burning, you may also want to consult a doctor or do research on the Internet. There are some conditions where you may experience burning due to something internal in your body.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; Email #3 - Some suggestions from a person saying they were harassed&lt;/item&gt;
      &lt;item rend="dd-4"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;When I read the two stories of people getting harassed by laser pointers, I thought I was reading about my own story.&lt;/code&gt;&lt;code&gt;I was also getting harassed by our neighbor. We complained to the police as well, but we got no help. Both me and my husband saw the green dots, still the authorities were not convinced. It's very difficult to film, since he changed locations from the window and could see us if we try to film or take picture. We finally moved from there and thought it would be over but to our dismay it continued in the second home. We moved in the same area, it was not far enough.&lt;/code&gt;&lt;code&gt;So, I started to do the research about laser pointers and their health risks on people. Here are a couple of suggestions: First, go to your Home Depot or Lowes and get a mirrored privacy film and stick it to your windows. Make sure your windows are completely covered. This will at least give you day time privacy and if they point the laser pointer at it they will get twice as much effect on themselves. Second, do not close your house completely. Leave your windows a crack open, because depending on the type of laser and its strength, all lasers emit radiation. The radiation further dries skin and increase the burning, and does not help in healing. Third, use coconut oil to moisturize skin. And, last, get as many humidifiers and run them until there is enough moisture in the house. This will negate the effects of radiation plus it will provide you with a relief from burning. I hope this helps. Good luck!&lt;/code&gt;&lt;code&gt;Finally, thank you for printing those articles, I thought I was alone. It is helpful to read what other people are going through.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;We have found a few people who, even if they moved to a different state, still said they had symptoms of being harassed by lasers. It is more likely that there is something about the person -- some medical or perhaps brain condition -- which is causing the symptoms. We urge such persons to get a medical exam and to stress to the doctor that you really are feeling these sensations (heat, etc.).&lt;lb/&gt;We are printing the information above because it may help others.&lt;list rend="ul"&gt;&lt;item&gt;The suggestion about privacy film is good. If a problem is being caused by visible light lasers, then light-blocking curtains, shades or films will eliminate the problem. You can also simply go into a room without windows or other openings to the outside, and see if the symptoms go away. Visible-light lasers, with a dot or beam that you can see, will be blocked by walls or other light-blocking material. It is theoretically possible that an infrared laser's energy might go through a lightweight material, but even here, putting a wall between you and a suspected laser source would block the infrared light. Note that reflective privacy film will NOT reflect the laser back to a perpetrator. This could only happen if the laser hits the film at an exact 90° angle, both side-to-side and up-and-down.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The point about radiation is not really accurate. Lasers do emit "radiation" -- electromagnetic radiation such as visible, infrared or ultraviolet light. Lasers available to the general public do not emit higher-energy nuclear radiation such as X-rays or gamma rays. Leaving windows open will not have any effect on light or radiation. For example, even a beam of X-rays will not somehow "build up" in a house. This is like saying leaving your oven on at 200 degrees will build up heat until an hour or two later it is 2000 degrees — not true.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The suggestions about coconut oil and humidifiers may help. If you do feel burning sensations, using a cream or having extra moisture in the air could be beneficial.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Telephone call - Blue light on Blink camera&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In late 2020, a woman called saying that an unfriendly neighbor may be aiming a blue laser at persons in her driveway. The people did not see any blue light or blue flash, but a Blink security camera had blue images when the persons were in the driveway.&lt;lb/&gt;Before going to the police, she sent photos showing the normal security camera view, and the blue-tinted view. Here is a portion of the photos:&lt;lb/&gt;The normal camera view&lt;lb/&gt;When the "laser" was on — a uniform blue tint (it turned out not to be caused by a laser)The photos clearly show it was not a laser. The tint is uniform, whereas a laser hitting the camera would cause a bright spot or complete whiteout or blueout of the camera image. Also, the tint is steady. A handheld laser from across the street would flash in the camera, since the neighbor could not hold the laser completely steady. (Even most tripods would not be 100% steady from such a distance — there would be some brightness fluctuation.)&lt;lb/&gt;There were other indications as well that this was not a laser. The camera was the only evidence of unusual activity. No person saw laser dots or beams. The blue tint occurred only during the day; usually laser harassment is at dusk or night.&lt;lb/&gt;It turns out that Blink cameras can have a blue tint under certain circumstances as discussed here and here. None of these seemed to apply to the woman's situation — it was not cold, nor snowy. The tint occurred only at certain times or when there was a person in the view. And yet the cause had to be with the camera or perhaps the lens (e.g., angle to the sun at certain times).&lt;lb/&gt;We recommended that she swap out the driveway Blink camera for one of the other Blink cameras on her property. This could help decide if the blue tint was due to a problem in the camera or perhaps due to the sun being at a certain angle when looking at the driveway view.&lt;lb/&gt;Either way, the blue tint was not caused by a laser. This put her mind at ease and prevented an unnecessary trip to the police.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;More information about mysterious or ongoing attacks&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; Why would ordinary citizens be targeted?&lt;/item&gt;
      &lt;item rend="dd-1"&gt;It seems unlikely that directed energy devices would be available or affordable to ordinary persons who want to harass other persons. Or whether such devices would be used by the government against ordinary citizens who don’t have vital state secrets.&lt;lb/&gt;We cannot help with issues about non-visible lasers or directed energy devices. However, below are links to resources which may be of interest to persons who feel they are deliberately targeted by mysterious devices.&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Links about covert harassment and directed energy devices&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The first two resources have links to other websites, organizations and videos of interest (too many links to list here). Thanks to Jeannie for her help with this list.&lt;list rend="ul"&gt;&lt;item&gt;People Against Covert Torture &amp;amp; Surveillance, International From their home page: “PACTS, International is a support network for those targeted with organized stalking and remote electronic assaults, also known as electronic harassment. Electronic harassment in this context refers to the use of radio frequencies and other methods to remotely access a person's mind and/or body to gain control of the individual or group of persons.” Much of the information at their site is in links to their newsletter, such as this newsletter page.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The "Stop Gangstalking Awareness Group", and especially this page about "Understanding Neuro Weapons." LaserPointerSafety has not evaluated the accuracy or usefulness of this group or their information. (Thanks to M.D. in July 2024 for bringing this to our attention.)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The 2015 Covert Harassment Conference in Berlin. This contains videos and a list of the program; the material is in English. There was also a 2014 Covert Harassment Conference.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A 2002 presentation by Dr. Reinhard Munzert, “Targeting the Human with Directed Energy Weapons”, here and here among other places.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The book "The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought" by Dr. Doug Beason, physicist, a Fellow of the American Physical Society, and former Chief Scientist for the USAF Space Command. From Amazon: "After more than two decades of research, the United States is on the verge of deploying a new generation of weapons that discharge light-wave energy, the same spectrum of energy found in your microwave, or in your TV remote control. It's called directed energy -- lasers, high-powered microwaves, and particle beams. And it's a revolution in weaponry, perhaps, more profound than the atomic bomb. The E-Bomb author Doug Beason, a leading expert in directed-energy research, describes in clear and jargon-free prose all of these exotic new weapons."&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A July 19 2019 article in the Military Times entitled "Pentagon scientists are making talking plasma laser balls for use as non-lethal weapons" describes how lasers can be used for "heating up a target’s skin to extremely uncomfortable levels without burning them, blasting confusing noises or giving voice commands such as, 'Stop or we’ll be forced to fire upon you.'" As of the article date, the talking plasma ball distance involved is currently within "the short range of a laboratory setting", with a goal of 100 meters to multiple kilometers. (Note that it is unlikely that such lasers are being used outside of military applications; for example, by one neighbor upon another neighbor. Also, it is not known if such lasers could cause effects through solid walls.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Mysterious Cuba attacks - microwaves or a "shared functional disorder"?&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Persons who feel they have been targeted by mysterious enemies with directed energy devices may want to consider the case of the U.S. diplomats in Cuba afflicted by "Havana syndrome."&lt;lb/&gt;In August 2017, reports came out that numerous U.S. diplomats serving in Cuba had been affected by mysterious “acoustic attacks.” Symptoms included hearing a buzzing sound, having headaches, hearing loss, balance issues and nausea. CBS News reported “mild traumatic brain injuries and possible damage to the central nervous system as a result of the attacks.”&lt;lb/&gt;The question is whether Cuba targeted diplomats with an actual device, whether it was caused by pesticides or other untargeted source … or whether this may have been "mass hysteria." According to a report in Newsweek:&lt;lb/&gt;“Mass hysteria is the rapid spread of illness symptoms for which there is no organic cause,” [Robert] Bartholomew [author of a book on the topic] told Newsweek. “It happens in normal, healthy people—it’s not just ‘all in their heads’ because they do experience symptoms.”&lt;lb/&gt;Jon Stone, a neurologist from the University of Edinburgh first consulted for the Guardian article, agrees. “To consider this diagnostic possibility properly you have to strip away its negative connotations. The symptoms experienced in outbreaks of ‘mass hysteria’ are genuine and not faked or imaginary,” he told Newsweek.&lt;lb/&gt;Stone argues that the term "mass hysteria" itself sounds sensational and far-fetched. In reality, it is not as uncommon as you might think. He explains: “‘Mass hysteria’ is so laden with negativity, it badly distorts its own case. It suggests shrieking and raving individuals—not hard-working and normal people who mostly get functional disorders in everyday practice.”&lt;lb/&gt;A better, less stigmatizing term, says Stone, is “share functional disorder.” He defines the condition as a genuinely experienced illness, “in which there is some disturbance of bodily functioning which conventional diagnostic techniques fail to register.”&lt;lb/&gt;There are interesting parallels with Havana syndrome and persons reporting unexplained laser harassment.&lt;lb/&gt;Similarities&lt;lb/&gt;In the Cuba case, around 25 U.S. diplomats, and 14 Canadian diplomats — persons who would be considered reliable and rational — reported hearing mysterious sounds and began having unusual, unexplained health problems. There have been numerous studies conducted by the U.S., Canada, Cuba, that as of early 2020 have not definitively established any cause. Experts are even divided on whether there is any physical change in the brains of the affected persons.&lt;lb/&gt;In laser harassment cases, numerous persons — most of whom sound reliable and rational when we talk with them — report seeing lights and feeling heat from mysterious sources. Police, friends, family and medical experts trying to help them have been unable to find a cause. The only thing that is certain is the persons have genuine symptoms that are not faked or imaginary. To others, there may be no rational explanation — but the symptoms are genuinely experienced.&lt;lb/&gt;Differences&lt;lb/&gt;One difference between the Cuba case and persons reporting unexplained laser harassment is that the latter are widely scattered. In Cuba there is the possibility of all the diplomats being exposed to the same causal factor (still unknown but possibly sound or pesticides). But persons reporting laser harassment are widely scattered across the U.S. and Canada. Perhaps there is a common cause within the environment.&lt;lb/&gt;Also, the definition of mass psychogenic illness or "mass hysteria" almost always occurs in a relatively small group of people living or working together. This is true for the Cuba cases. But in the laser harassment cases, victims are again widely scattered and do not know, interact, or correspond (e.g. Internet) with each other.&lt;lb/&gt;December 2020 update — microwaves&lt;lb/&gt;A study by the National Academies of Science concluded that the cause was likely microwave energy that may not have been deliberately targeting the diplomats in Cuba. According to an NBC News story quoting the study, "The committee felt that many of the distinctive and acute signs, symptoms and observations reported by (government) employees are consistent with the effects of directed, pulsed radio frequency (RF) energy. Studies published in the open literature more than a half-century ago and over the subsequent decades by Western and Soviet sources provide circumstantial support for this possible mechanism.”&lt;lb/&gt;From the news story:&lt;lb/&gt;The study examined four possibilities to explain the symptoms: Infection, chemicals, psychological factors and microwave energy.&lt;lb/&gt;“Overall, directed pulsed RF energy … appears to be the most plausible mechanism in explaining these cases among those that the committee considered. ... The committee cannot rule out other possible mechanisms and considers it likely that a multiplicity of factors explains some cases and the differences between others.”&lt;lb/&gt;The report says more investigation is required.&lt;lb/&gt;Summary&lt;lb/&gt;LaserPointerSafety.com we are not aware of microwave directing devices that an ordinary citizen could purchase to cause problems for neighbors. It may be possible for a technically minded person to buy or modify devices and beam microwaves at other persons. But we are not experts in microwaves so we cannot give any more advice or opinion.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; An email about directed energy weapons: Are we naive?&lt;/item&gt;
      &lt;item rend="dd-4"&gt;We received the following email in July 2019. It has been slightly edited for clarity and to avoid identifying information.&lt;code&gt;I just read your article on lasers and questions people emailed to you, all were very interesting.&lt;/code&gt;&lt;code&gt;In reading these it appeared to me most of these questions were based on Directed Energy Weapons - DEW (Microwave) rather than the laser beams per se. (i.e., laser beam in a pilots eyes).&lt;/code&gt;&lt;code&gt;I strongly disagree with you on the Cuban episode. First of all, I found your answer very naive, and I'm not trying to be mean, its just that you haven't done your homework on how those hell bent on hurting others obtain these military weapons! It's called Black Market, the Mexican Cartel (Sinanola or El Chapo) drug organization buy these DEW by the truck load from (hate to say this) crooked defense companies.&lt;/code&gt;&lt;code&gt;In turn these military weapons are given out like Hershey bars to Stalkers (MS-13) the large white van pulls up and delivers them right in your neighborhood purchased by the Cartel. Its big business. I'm assuming the Cuban government more than likely purchased these DEW weapons to threaten and hurt the Americans working in Cuba.&lt;/code&gt;&lt;code&gt;I keep reminding those that don't understand this Mexican Cartel they are extremely organized and extremely rich! They can and do buy anyone and anything! Most people don't even realize they have several submarines. This theory that everyone can get sick if enough people say they're sick, and blah blah blah, is just that, a theory. We're talking about the real world here. Unfortunately, it's the dark side, the hidden side that most don't even realize is out there.&lt;/code&gt;&lt;code&gt;So when these Americans complained about being hit and knocked down, believe them! My advice is do some studying on this weapon, yes its covert, silent and does shoot right thru walls,, it can hurt you and even kill you. Think of yourself as a potato, and what does it do if microwaved. My suggestion is get the book The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought. Unfortunately, you will NOT find any book in the library on this cartel, why? They're either stolen or lost.&lt;/code&gt;&lt;code&gt;You would not believe how many American citizens are now employed by this Mexican Cartel living right here in the good ole USA, and they ALL have this DEW weapon!&lt;/code&gt;&lt;code&gt;I would like to ask you if anything has been made to be able to catch a laser beam in motion and have it returned to the bad guy? I do not mean 'take' it to the bad guy (like a missile) I'm thinking perhaps a 'mirror-like' device.&lt;/code&gt;&lt;code&gt;[Name withheld; former employee at a defense contractor working on microwave devices]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;Thank you for your letter.&lt;lb/&gt;I haven't done a lot of homework on DEWs since my main interest is in visible lasers. I get calls about once every month or two from people who have experienced heat or light that I cannot explain. That's why my webpage includes links to other directed energy information sources.&lt;lb/&gt;I will say I'm not sure why Mexican cartels or human traffickers would target the people I hear from. They seem like normal people in residential neighborhoods. If the cartels wanted them gone, they certainly have other, much worse ways to do this.&lt;lb/&gt;I just downloaded the E-Bomb book in Kindle format. I will read it soon.&lt;lb/&gt;About your letter... I do want to bring forth other views. Would it be OK if I printed all or parts of it on the "If you are harassed by lasers" webpage at LaserPointerSafety.com? Without your name or identifying information, of course.&lt;lb/&gt;Finally, for visible lasers, you could use a retroreflector to return the light to the source. The beam may be degraded enough that if it could cause heat at the retroreflector, the returned beam (having gone twice as far and having bounced off possibly dirty or dusty surfaces) would be weaker and thus not able to harm anyone at the source area.&lt;lb/&gt;At a minimum, you would need a high-quality, industrial or research quality corner cube retroreflector like these. An inexpensive "cat's eye" bicycle retroreflector or similar would cause a bright glow to be seen at the source, but would not cause a coherent beam to be reflected back.&lt;lb/&gt;The original author's response:&lt;code&gt;Thanks for getting back to me so quickly, it's appreciated.&lt;/code&gt;&lt;code&gt;Yes, you can use what I wrote if it helps the targets. To help you to understand why good people end up targets is because more than likely they have interfered with something the Cartel is doing, like selling drugs, or human trafficking, they might have alerted the police, or see something say something. It could even be someone hired stalkers to hurt you because of some vendetta, or just pure revenge!&lt;/code&gt;&lt;code&gt;They could/can kill you. But, in most cases they just want to provoke you or harass you while hurting you with this DEW weapon. It's called a 'slow cooker' for a reason. It's nothing but pure evil.&lt;/code&gt;&lt;code&gt;I would like to see this hand held DEW put out of business and the defense companies fined big time for selling it, especially to the Cartels but, I'm reading where Directed Energy is being used even more than ever by other countries within the military sector. Lasers as well. I'm not against high technology but I am against something like this getting into the wrong hands.&lt;/code&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Another email with a detailed theory&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In March 2020 we received an email from Anthony Arellano describing in great detail how sonic and heat attacks could theoretically be done.&lt;lb/&gt;We are providing the document as an example.&lt;lb/&gt;We have not reviewed and do not endorse this information. Please independently research this before taking any actions based on the information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;We cannot help in mysterious or non-obvious cases&lt;/head&gt;
    &lt;p&gt;We do not have expertise about non-visible lasers or directed energy devices. Do not contact us, since we will no longer reply as of September 1 2023. If you are experiencing this, you should check the links above about covert harassment and directed energy devices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45389965</guid><pubDate>Fri, 26 Sep 2025 19:12:26 +0000</pubDate></item><item><title>Why use mailing lists?</title><link>https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0/</link><description>&lt;doc fingerprint="e2dc9d93b25dbf8d"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Re: Fully functional email address&lt;/head&gt;
    &lt;p&gt;Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt; Thu, 19 June 2025 20:09 UTC&lt;/p&gt;
    &lt;p&gt; Return-Path: &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; X-Original-To: ietf@mail2.ietf.org&lt;lb/&gt; Delivered-To: ietf@mail2.ietf.org&lt;lb/&gt; Received: from localhost (localhost [127.0.0.1]) by mail2.ietf.org (Postfix) with ESMTP id 0B126371B8C9 for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:46 -0700 (PDT)&lt;lb/&gt; X-Virus-Scanned: amavisd-new at ietf.org&lt;lb/&gt; X-Spam-Flag: NO&lt;lb/&gt; X-Spam-Score: -2.298&lt;lb/&gt; X-Spam-Level: &lt;lb/&gt; X-Spam-Status: No, score=-2.298 tagged_above=-999 required=5 tests=[BAYES_20=-0.001, RCVD_IN_DNSWL_MED=-2.3, RCVD_IN_MSPIKE_H3=0.001, RCVD_IN_MSPIKE_WL=0.001, RCVD_IN_VALIDITY_RPBL_BLOCKED=0.001, RCVD_IN_VALIDITY_SAFE_BLOCKED=0.001, SPF_PASS=-0.001] autolearn=ham autolearn_force=no&lt;lb/&gt; Received: from mail2.ietf.org ([166.84.6.31]) by localhost (mail2.ietf.org [127.0.0.1]) (amavisd-new, port 10024) with ESMTP id u4Vy4jVMA7Ej for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from taos.firemountain.net (taos.firemountain.net [207.114.3.54]) (using TLSv1.3 with cipher TLS_CHACHA20_POLY1305_SHA256 (256/256 bits) key-exchange X25519 server-signature ECDSA (P-256) server-digest SHA256) (No client certificate requested) by mail2.ietf.org (Postfix) with ESMTPS id 94448371B8C0 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from gsp.org (localhost [127.0.0.1]) by taos.firemountain.net (8.17.2/8.17.2) with SMTP id 55JK9hDh065634 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 16:09:44 -0400 (EDT)&lt;lb/&gt; Date: Thu, 19 Jun 2025 16:09:43 -0400&lt;lb/&gt; From: Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; To: IETF general list &amp;lt;ietf@ietf.org&amp;gt;&lt;lb/&gt; Subject: Re: Fully functional email address&lt;lb/&gt; Message-ID: &amp;lt;20250619200943.GB5995@gsp.org&amp;gt;&lt;lb/&gt; References: &amp;lt;18892.1750014795@obiwan.sandelman.ca&amp;gt; &amp;lt;50FFA5F1-6895-4C6C-A4C7-1DA2226CA07B@huitema.net&amp;gt; &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; MIME-Version: 1.0&lt;lb/&gt; Content-Type: text/plain; charset="us-ascii"&lt;lb/&gt; Content-Disposition: inline&lt;lb/&gt; In-Reply-To: &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; User-Agent: Mutt/1.5.23 (2014-03-12)&lt;lb/&gt; Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-MailFrom: rsk@gsp.org&lt;lb/&gt; X-Mailman-Rule-Misses: dmarc-mitigation; no-senders; approved; emergency; loop; banned-address; member-moderation; header-match-ietf.ietf.org-0; nonmember-moderation; administrivia; implicit-dest; max-recipients; max-size; news-moderation; no-subject; digests; suspicious-header&lt;lb/&gt; X-Mailman-Version: 3.3.9rc6&lt;lb/&gt; Precedence: list&lt;lb/&gt; List-Id: "IETF-Discussion. This is the most general IETF mailing list, intended for discussion of technical, procedural, operational, and other topics for which no dedicated mailing lists exist." &amp;lt;ietf.ietf.org&amp;gt;&lt;lb/&gt; Archived-At: &amp;lt;https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0&amp;gt;&lt;lb/&gt; List-Archive: &amp;lt;https://mailarchive.ietf.org/arch/browse/ietf&amp;gt;&lt;lb/&gt; List-Help: &amp;lt;mailto:ietf-request@ietf.org?subject=help&amp;gt;&lt;lb/&gt; List-Owner: &amp;lt;mailto:ietf-owner@ietf.org&amp;gt;&lt;lb/&gt; List-Post: &amp;lt;mailto:ietf@ietf.org&amp;gt;&lt;lb/&gt; List-Subscribe: &amp;lt;mailto:ietf-join@ietf.org&amp;gt;&lt;lb/&gt; List-Unsubscribe: &amp;lt;mailto:ietf-leave@ietf.org&amp;gt;&lt;/p&gt;
    &lt;quote&gt;On Mon, Jun 16, 2025 at 12:31:09PM -0400, John R. Levine wrote: &amp;gt; Incidentally, the reason that mail will never go away is that it is fully &amp;gt; federated, doesn't require people to be online at the same time, and is easy &amp;gt; to archive and search. So far none of the replacements do that. +1, and let me augment this by (partially) quoting something that I wrote a few years ago about mail and mailing lists. Why use mailing lists? ---------------------- Mailing lists, which were sometimes called "reflectors" in their early days, are one of the older pieces of Internet technology. Despite that, they're still heavily used [...] That's not an accident. It's because mailing lists have enormous technical advantages over the alternatives. Here are some of those: 1. Mailing lists require no special software: anyone with a sensible mail client can participate. Thus they allow you to use *your* software with the user interface of *your* choosing rather than being compelled to learn 687 different web forums with 687 different user interfaces, all of which range from "merely bad" to "hideously bad". 2. Mailing lists are simple: learn a few basic rules of netiquette and a couple of Internet-wide conventions, and one's good to go. Web forums are complicated because all of them are different. In other words, participating in 20 different mailing lists is just about as easy as participating in one; but participating in 20 different web forums is really quite onerous. 3. They impose minimal security risk. 4. They impose minimal privacy risk. Points 3 and 4 stand in stark contrast to the security and privacy risks imposed on users of web forums and "social" media, especially the latter. 5. Mailing lists are bandwidth-friendly -- an increasing concern for people on mobile devices and thus on expensive data plans. Web forums are bandwidth-hungry. 6. Mailing lists interoperate. I can easily forward a message from one list to another one. Or to a person. I can send a message to multiple lists. I can forward a message from a person to this list. And so on. Try doing this with web forum software A on host B with destinations web forum software C and D on hosts E and F. Good luck with that. 7. They're asynchronous: you don't have to interact in real time. You can download messages when connected to the Internet, then read them and compose responses when offline. 8. As a result of 7, They work reasonably well even in the presence of multiple outages and severe congestion. Messages may be delayed, but once everything's up again, they'll go through. Web-based forums simply don't work at all. 9. They're push, not pull, so new content just shows up. Web forums require that you go fishing for it. 10. They scale beautifully. 11. (When properly run) they're relatively free of abuse vectors. Mailing lists are highly resistant to abuse and attacks. Web forums, because of their complexity, are highly vulnerable to software security issues as well as spam/phishing and other attacks. 12. They handle threading well. And provided users take a few seconds to edit properly, they handle quoting well. This is essential for anyone trying to follow a discussion. 13. They're portable: lists can be rehosted (different domain, different host) rather easily. 14. They can be freely interconverted -- that is, you can move a list hosted by A using software B on operating system C to host X using software Y on operating system Z. If you can do this at all with web forums, and you usually can't, it's really, really difficult. 15. They can be written to media and read from it. This is a VERY non-trivial task with web forums, and that's putting it mildly. 16. The computing resources require to support them are minimal -- CPU, memory, disk, bandwidth, etc. 17. Mailing lists can be uni- or bidirectionally gatewayed to Usenet. (The main Python language mailing list is an example of this.) They can also be gatewayed to web sites or to RSS feeds. All of these can be highly useful, because they provide alternative ways for people to receive the same content. 18. They're easily archivable in a format (Unix "mbox" format) that is simple and likely to be readable long into the future. Mail archives from 10, 20, even 30 or more years ago are still completely usable. And they take up very little space: I have hundreds of millions of mailing list messages archived, and the entire collection would fit on a USB stick. [...] 19. You can archive them locally... 20. ...which means you can search them locally with the software of *your* choice. Including when you're offline. And provided you make backups, you'll always have an archive -- even if the original goes away. Web forums don't facilitate this. [...] ---rsk&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Michael Richardson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John R. Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Salz, Rich&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rob Sayre&lt;/item&gt;
      &lt;item&gt;Email usage (Was: Fully functional email address) Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Martin J. Dürst&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rich Kulawiec&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Phillip Hallam-Baker&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390121</guid><pubDate>Fri, 26 Sep 2025 19:27:23 +0000</pubDate></item><item><title>How insurance risk is transformed into investable assets</title><link>https://riskvest.io/riskvest-insights/transforming-insurance-risk</link><description>&lt;doc fingerprint="3954309d71ae6140"&gt;
  &lt;main&gt;
    &lt;p&gt;Insurance risk involves the sale of insurance policies to policyholders, the receipt of premium and the payment of claims. If claims &amp;amp; associated expenses are less than premium received, an Underwriting Profit is made. If claims are greater than premium, an Underwriting Loss occurs. In essence, investing in insurance risk is like partnering with an insurer — you share in the results of the portfolio, keeping a slice of the underwriting profit if claims come in below premiums, or sustaining a loss if they come in above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Insurance Is Not Fully Collateralized&lt;/head&gt;
    &lt;p&gt;This brings us to the concept of collateralization. An everyday example of collateral involves your mortgage. When you take out a loan from the bank to buy a house, you're putting up the house itself as collateral for the loan to secure it - meaning, if you fail to pay back the loan, the bank can foreclose and sell the house to cover the loan.&lt;/p&gt;
    &lt;p&gt;The key observation about insurance risk is the possibility for insurers to pay out more money in claims than they take in via policy premiums. When you purchase a policy from an insurance company, you’re implicitly trusting that the insurance company will be able to pay you out in the event of a claim, even if it means they’re operating at a loss. Insurance companies have a balance sheet (basically, an amount of assets or money) which acts as collateral against the chance that they must pay out more than they take in.&lt;/p&gt;
    &lt;p&gt;The amount of money held by the insurance company for this purpose is known as insurance capital &amp;amp; surplus. Since this amount of capital is less than the total sum of all policy limits, we can say the policies are partially collateralized.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visualizing How Insurance Losses Are Distributed&lt;/head&gt;
    &lt;p&gt;The chart below illustrates this concept with a probability distribution. The blue curve shows the likelihood of different loss levels. It peaks around 60-70% of premium but has a long tail extending to extreme scenarios.&lt;/p&gt;
    &lt;p&gt;The insurance company in this example holds capital equal to 175% of premium collected, giving them total resources of 275% of premium (100% premium + 175% capital) to pay claims in extreme years.&lt;/p&gt;
    &lt;p&gt;The green dashed line shows the return on capital from underwriting activities. When losses are less than premium collected (green zone), the insurer keeps the difference as profit. Once losses exceed the break-even point at 100%, the insurer must use their capital reserves to pay claims (red zone). Think of it like making an "investment" with the premium you collected, but getting such a negative return that you have to reach into your wallet to cover the losses (red line).&lt;/p&gt;
    &lt;head rend="h4"&gt;Chart Legend:&lt;/head&gt;
    &lt;head rend="h3"&gt;Key Insight&lt;/head&gt;
    &lt;head rend="h2"&gt;Some Retail Investments Are Partially Collateralized&lt;/head&gt;
    &lt;p&gt;Retail brokerages offer margin accounts to those customers that have sufficient assets to support it - much like the insurance company capital - and reserve the right to make a margin call if those trader’s reserves fall below minimum requirements. In extreme cases, it’s even possible for a trader to end up in a position where the brokerage could not sell collateral quickly enough and they’re left with a negative balance which must be filled with assets from elsewhere.&lt;/p&gt;
    &lt;p&gt;In the same way, insurers must maintain capital to meet extreme claims. Both systems rely on partial collateralization: enough to cover most outcomes, but not the absolute maximum.&lt;/p&gt;
    &lt;p&gt;Therein lies a critical implication: The entire balance sheet of the insurance company is available and backing each individual policy. This is similar to your margin account, as if your account balance (collateral) goes below zero, you'll have to pull from assets outside to cover the debt.&lt;/p&gt;
    &lt;p&gt;This is one of the fundamental reasons why regulators restrict retail investors from direct insurance risk investments. A strong knowledge base of how the risk works is needed to understand you're not just exposed to losing your investment, but other assets as well. For history buffs, I recommend reading Andrew Duguld's On the Brink: How a Crisis Transformed Lloyd's of London1for a fascinating first-hand account of the Names at Lloyd's. These individuals once pledged their entire personal wealth to back insurance syndicates, sometimes with catastrophic consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insurance Risk Investments For Retail Are Almost Always Fully Collateralized&lt;/head&gt;
    &lt;p&gt;So what have we learned from this comparison? Three points stand out:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;1Insurance risk is exposed to losses exceeding the premium received&lt;/item&gt;
      &lt;item&gt;2Collateral needs to be set aside in case of these outsized losses to ensure trust in the insurance product&lt;/item&gt;
      &lt;item&gt;3Outside (especially Retail) Investors would be best to limit their exposer to losses beyond their investment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The challenge, then, is clear: how can retail investors access insurance risk without facing the danger of unlimited losses? The solution has been to design fully collateralized structures as vehicles that capture underwriting profits while capping potential losses at your invested amount. One of the most intuitive examples comes from adapting reinsurance structures into a format investors can access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case Study: CAT Bonds&lt;/head&gt;
    &lt;p&gt;Catastrophe Bonds, or "CAT Bonds", are the most widely known form of investable insurance risk. If we ignore the insurance implications of it for a second, CAT Bonds are just like any other corporate bond: they are issued by a firm, pay a coupon, have a maturity date and have an associated risk of default (not being paid back principal).&lt;/p&gt;
    &lt;p&gt;The difference here is the risk of default of a CAT bond is tied in someway to insurance losses. If a qualifying insurance event happens, the principal is kept by the insurance company to pay those claims, effectively defaulting the bond. They are referred to as "Catastrophe" bonds simply because they are most often tied to large, catastrophic events such as Hurricanes, Earthquakes, or even Cyber events.&lt;/p&gt;
    &lt;p&gt;CAT Bonds can be thought of as an insurance policy bought by the insurance company itself. They are, in fact, usually a compliment to the insurance company's full reinsurance program. Here, however, the insurance company isn't buying a policy from another insurance company, but rather outside capital markets on a fully collateralized basis.&lt;/p&gt;
    &lt;p&gt;Let's form our own very basic CAT bond. We're Risksure - a Florida based insurance company - and we write a lot of homeowners policies in the sunshine state. We'd like to take out the following CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sponsor: Risksure Re&lt;/item&gt;
      &lt;item&gt;Bond Size (Limit): $100M&lt;/item&gt;
      &lt;item&gt;Attachment Point (Deductible): $500M (Risksure covers the first $500M of losses)&lt;/item&gt;
      &lt;item&gt;Issuance Date: Jan 1, 2026&lt;/item&gt;
      &lt;item&gt;Maturity Date: Dec 31, 2026&lt;/item&gt;
      &lt;item&gt;Coupon (Premium): 9% annually, rate paid quarterly on current collateral balance&lt;/item&gt;
      &lt;item&gt;Terms: If a hurricane strikes Florida in 2026 and Risksure’s losses exceed $500M, investors’ principal is used to cover those excess losses, up to $100M. This is known as a per occurrence limit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h6"&gt;CAT Bond: Gator Re Ltd. 🐊&lt;/head&gt;
    &lt;p&gt;To issue this Bond, Risksure Re would collect $100M of principal from outside investors, thus fully collateralizing the insurance risk. In return, Risksure Re would pay $9M of premium for the bond, and should no hurricane event occur, pay back the $100M of principal at maturity.&lt;/p&gt;
    &lt;p&gt;This type of structure is common in reinsurance and known as an excess of loss structure. The layer of coverage can be visualized as follows:&lt;/p&gt;
    &lt;head rend="h3"&gt;How It Works&lt;/head&gt;
    &lt;head rend="h2"&gt;Investment Returns for Gator Re Ltd. 🐊&lt;/head&gt;
    &lt;p&gt;There are two components of return for the investors in our CAT Bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Risk Return: Compensation for taking on the insurance risk, paid for by the 9% coupon&lt;/item&gt;
      &lt;item&gt;Risk Free Return: Compensation for tying up capital, in the form of interest income on the collateral sitting in the bank, say by investing it in 4% T-bonds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's clear that we this structure, the investors are taking on insurance risk exposure. However, in this case, the "buyer" of the insurance policy (the insurance company itself) does not need to worry that the insurer (the outside investors) will not be able pay claims if the large event happens, because the entire value of the policy limit ($100M limit) is set aside and can't be touched.&lt;/p&gt;
    &lt;p&gt;We can now examine and visualize a few potential outcomes for the buyers of the CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No Hurricane: Capital providers get back $9M Risk Income + $4M Risk-free Income = $13M along with their original $100M of investment, a 13% return.&lt;/item&gt;
      &lt;item&gt;A Partial Loss: Risksure suffers $525M of loss from a covered hurricane. Risksure pays the first $500M. They then use $25M of the paid in capital from the CAT bond to pay for the remaining claims. Assuming mid-year trigger, capital providers will receive back the remaining $75M, plus the $7.78M Risk Income (two coupons paid plus two partial coupons), plus reduced RF income due to the used capital, $3.5M, for a total of $86.28M. This is a negative 13.72% return.&lt;/item&gt;
      &lt;item&gt;A Full Loss: A massive hurricane hits Florida and Risksure pays out $1B in losses, far above the exhaustion point of $600M for this CAT bond. The entirety of the $100M principle and risk free income goes towards paying Risksure's policyholder claims. Investors received $4.5M in coupons before trigger and no principle, for a loss of 95.5%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Keen observers will notice that we've successfully transformed the insurance risk into a limited liability product - you can no longer owe additional capital beyond your original investment. However, it's clear that investing in insurance risk in this manner should be treated as a compliment to other investment strategies. Bear markets for equities might return -30% to -50%, but crucially, they retain the potential to recover those losses over time. CAT bonds offer no such recovery potential - once triggered, that capital is permanently lost. That said, the stated probability of default for these bonds is typically 1-3%, meaning the 5-9% excess returns above risk-free rates are designed to compensate for this low-probability but high-severity risk.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Final Note: Why Isn't Insurance Fully Collateralized?&lt;/head&gt;
    &lt;p&gt;A natural question arises through this analysis: why aren't insurance companies forced to hold enough money to cover all potential loss scenarios? The short answer is efficiency. The less capital you have to hold, the larger your returns on capital will be. This can be illustrated with simple math. Say you hold $10M in capital and expect a profit of $500K on underwriting business. Expected return is $500K/$10M = 5%. But let's say now you only have to hold $5M in capital - your return on capital has now jumped to $500K/$5M = 10%. By holding fully collateralized layers, CAT bonds are trading capital efficiency for payment certainty.&lt;/p&gt;
    &lt;p&gt;Referring back to the chart at the beginning of the article, those extremely remote loss scenarios have exceedingly low likelihood of happening for a sufficiently large and diverse insurance company. Each insurance company has a team of actuaries and risk modelers dedicated to ensuring the ongoing solvency of the company. Regulators setup frameworks to validate and set guidelines for the amount of capital a company needs to hold. With all that said, insurance companies can and do fail, at which point regulators can swoop in to protect policyholders.&lt;/p&gt;
    &lt;p&gt;This is why under collateralized insurance "works" - there are many checks and balances along the way to align incentives. It's also why giving outside investors access to insurance risk is such a challenge; with out those protections in place, guardrails (such as full collateralization) have to be setup such that insurance policies can be sure their claims will be paid.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390856</guid><pubDate>Fri, 26 Sep 2025 20:46:26 +0000</pubDate></item><item><title>RNA structure prediction is hard. How much does that matter?</title><link>https://www.owlposting.com/p/rna-structure-prediction-is-hard</link><description>&lt;doc fingerprint="eff8d413373c4312"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RNA structure prediction is hard. How much does that matter?&lt;/head&gt;
    &lt;head rend="h3"&gt;4.8k words, 22 minute reading time&lt;/head&gt;
    &lt;p&gt;Note: I am not an expert in RNA structure, and am extremely grateful to Connor Stephens, Rishabh Anand, Ramya Rangan, and Chaitanya K. Joshi—all of whom are actual, bonafide experts—for their incredibly detailed comments on earlier drafts of this essay. All mistakes are, of course mine, and this essay should not be trusted to function as anything more than entertainment. Do your own research!&lt;/p&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;One thing I’ve always wanted to write was ‘a primer to RNA structure modeling’. I know literally nothing about the field, other than that there are a few startups playing in the space, and have always been curious what exactly they were up to. But the release of Alphafold3—which can model RNA alongside proteins, DNA, and small molecules—dampened this desire. If a singular model solved the problem of RNA structure, who cares about the specifics of the field at large?&lt;/p&gt;
    &lt;p&gt;But while I was in San Francisco a few months back, I happened to chat with Connor Stephens, a machine learning scientist at Atomic AI. You may recognize that startup, since their founder has the distinct honor of their PhD work in RNA structure modeling being on the cover of Science in 2021 for making a substantial advance in RNA structure prediction.&lt;/p&gt;
    &lt;p&gt;But it was long unclear to me what exactly Atomic AI exactly did in terms of R&amp;amp;D. This isn’t a startup post, I’m not planning to explain what their therapeutic goals are. What I was curious about was why they continue to have an ML team despite the RNA problem being seemingly solved by Alphafold3. So, I posed that question to Connor.&lt;/p&gt;
    &lt;p&gt;Connor told me something very fascinating: not only did Alphafold3 not solve the problem of RNA structure prediction, RNA may be one of the last structure prediction problems to be solved. The rest of the conversation was so incredibly fun that, midway through it, I decided it’d make for a great article to write about.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why is RNA structure so hard to model?&lt;/head&gt;
    &lt;p&gt;On face value, the answer is pretty simple: experimentally determined RNA structures deposited in public repositories are both ridiculously small in number and of much lower quality than you’d naively expect. A quote from a paper best explains this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There is a huge disparity in protein and RNA data. Even if there is a higher proportion of RNAs than proteins in the living, this is not reflected in the available data: only a small amount of 3D RNA structures are known. Up to June 2024, 7,759 RNA structures were deposited in the Protein Data Bank (34), compared to 216,212 protein structures. The quality and diversity of data are also different: a huge proportion of RNAs come from the same families. It implies several redundant structures that could prevent a model from being generalized to other families. In addition, a huge amount of RNA families have not yet solved structures in the PDB. This means there is no balanced and representative proportion of RNA families through the known structures.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The obvious follow-up question is: why? Apparently, RNA is a good fit for basically none of the existing structure determination methods. But again, why?&lt;/p&gt;
    &lt;p&gt;Connor told me that RNA is famous for being perhaps one of the most flexible biomolecules to exist as a category, with an almost absurd number of conformational degrees of freedom. Each nucleotide has more torsion angles than an amino acid, and the lack of a bulky side chain—like those in amino acids—means there’s very little steric hindrance to keep the backbone from flopping around. Now, keep in mind, this is not to say that RNA is unstructured. Unstructured has a particular meaning, that the energy landscape is flat, with no favored conformational structure. But this isn’t the case for RNA, which do have preferred conformational structures, there are just many of them that they constantly flip in between.&lt;/p&gt;
    &lt;p&gt;This all implies that RNA is a very bad fit for X-ray crystallography, which requires orderly, repeating conformations to arrange into a crystal. It is also a bad fit for cryo-EM (a subject I’ve written about in detail before), given both the extreme conformational heterogeneity of it and how typically small the biomolecule is, though this is increasingly being addressed. Finally, NMR, which, while more forgiving when it comes to flexibility and heterogeneity, is generally limited to very small RNA structures. Once the RNA goes beyond ~50 nucleotides, the spectra start overlapping and the resolution being insufficient to observe anything useful. And lots of important RNA lies beyond that size!&lt;/p&gt;
    &lt;p&gt;I’ve attached some nuance about NMR and cryo-EM in the footnotes.1&lt;/p&gt;
    &lt;p&gt;This means that there are really only two RNA structures that can be physically characterized: ones that have been artificially stabilized, or ones that are evolutionarily constrained to hold a single dominant conformation.&lt;/p&gt;
    &lt;p&gt;The first category includes structures coaxed into rigidity by heavy metal ions, engineered base modifications, or even crystallization chaperones. But of course, this raises a worrying question: are you really measuring the native structure, or just the structure you forced it into? The second category is rarer: RNAs that, through evolutionary pressure, have converged on a stable structure for a functional reason. There are no caveats there, only that trying to train a model on these nucleotide sequences will inevitably bias it towards unusually stable RNA structures.&lt;/p&gt;
    &lt;p&gt;Well, we shouldn’t let all of this get us down. Many impossible problems are being solved day-after-day in this field. Even if RNA modeling has all the characteristics of being hard to do—huge distributional space of possible outputs for a given input and low number of input data points—surely, some headway has been made in the problem. Consider Alphafold3: how well does it actually do on the RNA structure prediction problem?&lt;/p&gt;
    &lt;p&gt;A well-named paper titled Has AlphaFold3 achieved success for RNA? tries to answer this question. From the article:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The best models from the CASP-RNA competition, which are human-guided, outperform AlphaFold3….&lt;/p&gt;
      &lt;p&gt;….On the other hand, AlphaFold3 shows a cumulative sum of metrics greater than the other methods for the other test sets (p-value &amp;lt; 10−5 for RNA-Puzzles, p-value &amp;lt; 10−4 for RNASolo).&lt;/p&gt;
      &lt;p&gt;For RNA-Puzzles, the challenge-best solutions are from older solutions with less advanced architectures compared with the more recent CASP-RNA solutions.&lt;/p&gt;
      &lt;p&gt;For the RNA3DB_0 data set, the performance of AlphaFold3 is slightly better compared with RhoFold, which gives a better RMSD but a worse MCQ and LCS-TA.&lt;/p&gt;
      &lt;p&gt;AlphaFold3 always has a high MCQ value, indicating that it returns structures which are more physically plausible than ab initio methods (which use physics properties in their predictions).&lt;/p&gt;
      &lt;p&gt;Nonetheless, it does not always have the best RMSD (outperformed in CASP-RNA and RNA3DB_0), suggesting that AlphaFold3 does not always have the best alignment (in terms of all atoms) compared with the reference structure.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In short, while Alphafold3 is certainly an improvement in some categories of RNA—namely being the only RNA structure prediction method that can model very large RNA’s well—it does not solve the problem outright, and can be outperformed through tailored methods.&lt;/p&gt;
    &lt;p&gt;Another slightly more recent paper says something similar, and gives some insight into the practical meaning of these benchmarks, saying ‘Boltz-1 and AlphaFold3, make acceptable predictions for about half of the individual RNA chains and complexes.’. The authors further note that the results get far worse if you deviate into more structurally unique RNA space (bolding added by me):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We observed that prediction accuracy, as measured by TM-score, generally increased with higher structural similarity to the training set for all methods. The mean TM-score is below 0.1 for the category with the least similarity and increases gradually to over 0.6 for the category with the highest similarity to the training set. This suggests that AlphaFold3 and other methods tend to perform better when the target structure is more similar to motifs it encountered during training, highlighting the limitation of current methods in predicting unseen and structurally divergent RNAs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Neat!&lt;/p&gt;
    &lt;p&gt;I could end the essay here, because this really did cover most of Connor and I’s conversation. There is a lot more that could be said about how difficult benchmarking can be in the RNA ML world, the weak co-evolutionary signal in RNA MSA’s, how even the existing set of RNA structures are made worse by the fact that they are almost always in complex with a protein, and (hearsay) that you likely need experimentally-determined templates/molecular-dynamics to get good structure predictions. This paper discusses all that in more detail if you're curious, but my main question got answered!&lt;/p&gt;
    &lt;p&gt;But the more I talked to people in the RNA space while writing this essay, the more I began to ask a new question: how important is this problem anyway?&lt;/p&gt;
    &lt;head rend="h1"&gt;Why even predict RNA structure in the first place?&lt;/head&gt;
    &lt;p&gt;For the protein-heads reading this, we know that protein structure actually means something quite fundamental. A protein’s three-dimensional fold is usually synonymous with its biological role: an enzyme pocket is what catalyzes a reaction, an antibody groove is what binds an antigen, a receptor domain is what recognizes a ligand. We can hem and haw about dynamics or post-translational tweaks, but the basic architecture is what makes the protein what it is. Protein structure isn’t exactly truth, but structure can be a proxy for truth a sufficiently high fraction of the time.&lt;/p&gt;
    &lt;p&gt;RNA is not like this at all. It’s actually really, really, really situational when the structure of RNA matters in a therapeutic context. Well, to be more nuanced, structure always matters, but there is a very significant split what ‘structure’ even means for this biomolecule: secondary structure and tertiary structure (image from here):&lt;/p&gt;
    &lt;p&gt;Thus far, everything we’ve talked about regarding the ‘difficulty of structure prediction’ has been for tertiary structure.&lt;/p&gt;
    &lt;p&gt;Now, this separation exists for proteins as well! But it (somewhat) matters less for proteins. Usually we treat “protein structure” as a single concept because the hierarchy is tightly coupled: secondary structure (α-helices, β-sheets) stacks neatly into tertiary folds, which in turn map directly to function. You can often ignore the distinction because the two levels reinforce each other, and so everyone hyper-focuses on tertiary structures being the most important thing.&lt;/p&gt;
    &lt;p&gt;But for RNA, the distinction matters a lot, because secondary structure seems to be where most of the clinically relevant value of structure is. Tertiary RNA structure is important! But, as far as I can tell, the value of it is actually relatively limited in scope for therapeutic-relevant problems, partially due to the fact that RNA is just so flexible that a tertiary structure phenomenon like ‘the binding site is buried in the core’ can immediately be undercut by that same core suddenly flopping out in a new conformation.&lt;/p&gt;
    &lt;p&gt;And, just as is the case for proteins, RNA secondary structure is far easier to predict than RNA tertiary structure. It’s still comparatively hard, in the sense that secondary protein structure is basically something people don’t ever worry about, and secondary RNA structure has only just recently reached those same accuracy levels. A paper that analyzed the performance of RNA models at CASP16 had this to say:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Complex and novel targets appear well beyond current capabilities for NA 3D structure prediction. However, RNA folding can be simplified into a hierarchical process: secondary structure – the pattern of canonical base pairs – forms creating a set of RNA stems which are then stitched into the overall 3D fold…&lt;/p&gt;
      &lt;p&gt;CASP16 offered the prospect of carrying out tests of secondary structure accuracy prospectively. The secondary structure of all targets, here defined as the list of all Watson-Crick-Franklin and Wobble pairs, turned out to be predicted to a high level of accuracy (Supplemental Figure 3A)...The trend in RNA secondary structure performance is more reminiscent of the performance observed in current protein 3D structure prediction, suggesting these prediction algorithms are reaching sufficient accuracy in their prediction of secondary structure to be important and useful in structural research.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Not too bad!&lt;/p&gt;
    &lt;p&gt;Returning back to our claim that ‘secondary structure is most of what you need’, let’s convince ourselves of this by walking through the major classes of RNA-based therapeutics and the importance of secondary versus tertiary structure.&lt;/p&gt;
    &lt;p&gt;The most famous form of therapy here is exogenous mRNA, and tertiary structure doesn’t seem to matter much there. I have two proof points for this. One, this mRNA optimization article from GeneWiz mentions secondary-structure optimization (e.g. preventing hairpins), but not tertiary structure. Two, just logically thinking about it, the job of mRNA is to be fed into the ribosome and translated into protein, so as long as the coding region is readable and initiation isn’t blocked (hence probably why hairpins are undesirable), why would it matter for the RNA to maintain any particular higher-order fold?&lt;/p&gt;
    &lt;p&gt;Then there’s antisense oligonucleotides, or ASO. All this is is a short synthetic strand of RNA (usually 15–25 bases long) that binds to a complementary sequence of an RNA. Once bound, it can block translation directly by preventing ribosome access, alter splicing by blocking splice sites or enhancers/silencers, or a few other things. But in all of these cases, all that matters is that the ASO can actually base-pair with its intended target. And that comes down to secondary structure accessibility: is the binding site exposed or not? Once again, this seems to be something that is largely answerable from secondary structure information, especially given how small ASO’s are.&lt;/p&gt;
    &lt;p&gt;For siRNA’s, or small interfering RNA, it’s nearly the same story as ASO’s,&lt;/p&gt;
    &lt;p&gt;Virtually the only time tertiary structure seems to matter for an RNA therapeutic is for aptamers and ribozymes. The former refers to short RNAs that fold into precise three-dimensional shapes capable of binding proteins or small molecules (e.g. theophylline aptamer), and the latter refers to enzymatic RNAs with a precise catalytic site that are able to carry out chemical reactions. But, unlike all other classes of RNA therapeutics, approved drugs here are quite rare; aptamers have two and ribozymes have zero. There’s also riboswitches, which are a hazy combination of the two, and also have no released therapies.&lt;/p&gt;
    &lt;p&gt;This all said, we should also consider the other side too: RNA as targets. How important is secondary versus tertiary structure there?&lt;/p&gt;
    &lt;p&gt;Well, things do get muddier, because there isn’t really a standardized list of established RNA targets the same way there are for proteins. There’s mRNA, the tertiary structure of which is not exploited in any FDA-approved drugs (though we’ll discuss this again later on), but what else?&lt;/p&gt;
    &lt;p&gt;Well, for one, non-coding regions! Specifically, microRNAs and IncRNA.&lt;/p&gt;
    &lt;p&gt;Given how small microRNA’s are (20~ nucleotides), I’d guess that tertiary structures don’t matter much there.&lt;/p&gt;
    &lt;p&gt;Curiously, LLM’s will, at first, insist that IncRNA’s, or “long noncoding RNAs”’ really benefit from accurate tertiary structure prediction. There’s some reason to believe that they are right. After all, they are usually above 200 (or 500, depending on who you ask) nucleotides in length, so, unlike ASOs/siRNAs/microRNAs, IncRNA’s are sufficiently large where tertiary structures may have significant impacts. Unfortunately, the LLM seems to be a bit wrong here, partially because whether IncRNA’s even form global tertiary structures at all has been a matter of intense debate for a while, though circa 2020 it is seeming like at least some IncRNA’s do. But really, whether IncRNA’s have a global structure or not wouldn’t have even mattered anyway, because their modulation does not seem to actually depend on that global structure. Rather, it depends on a set of short nucleotide motifs scattered along an otherwise floppy backbone. Even if we could perfectly predict the full structure of an IncRNA tomorrow, it feels like it wouldn’t change any therapeutic decisions. Perhaps predictions of those local 3D motifs are valuable, but that’s an open question!&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the only type of RNA target where tertiary structure is known to be important is rRNA, or ribosomal RNA. Unlike most RNAs, ribosomal RNAs actually must maintain specific tertiary folds, because, like ribozymes, they are enzymes in every meaningful sense. The peptidyl transferase center of rRNA requires a highly specific three-dimensional geometry to orient its usual substrate: tRNA. And some classes of approved antibiotics, macrolides for example, are able to block this catalysis site, preventing (some) forms of bacteria from making proteins at all, eventually killing them.&lt;/p&gt;
    &lt;p&gt;It does seem like, from the outside, that accurate RNA tertiary structure predictions here would be helpful, given this line from a paper discussing where antibiotics bind to RNA:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For spectinomycin, the apparent binding site and the affected cross linking site are distant in the secondary structure but are close in tertiary structure in several recent models, indicating a localized effect. For tetracycline, the apparent binding sites are significantly separated in both the secondary and the three-dimensional structures, suggesting a more regional effect.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words, there is a large deviation in what secondary structure tells you, and what tertiary structure tells you!&lt;/p&gt;
    &lt;p&gt;This said, a few commenters on this essay noted that while this is an area where 3D structure is useful, it almost certainly isn’t a bottleneck due to the relative abundance of existing rRNA structures and ease of gathering new ones.&lt;/p&gt;
    &lt;p&gt;So, aptamers and rRNA are virtually the only two areas that (today) truly benefit from detailed tertiary structure modeling and have some things in the clinic. For mRNAs, ASOs, siRNAs, and most lncRNAs, the biology seems to collapse down to local accessibility and motif recognition. Both of these are sufficiently described by secondary structure, and that is decently well predicted by existing models! Tertiary folds, though definitively far from being well-predicted, don’t actually seem to influence much…at least as far as I can tell.&lt;/p&gt;
    &lt;p&gt;So why do people still work on the tertiary structure prediction problem? Is it all just for better ribosome-centric antibiotics and aptamers?&lt;/p&gt;
    &lt;head rend="h1"&gt;How much do we stand to gain if RNA structure prediction improves?&lt;/head&gt;
    &lt;p&gt;Well, in the immediate short term, it does seem like antibiotics and aptamers are really the field's best bets.&lt;/p&gt;
    &lt;p&gt;This is nothing to sneeze at! On the antibiotic side, we do need better antibiotics to account for the current ‘antibiotic resistance’ thing that’s been going on for the past decade, so why not elect ribosome-targeting antibiotics? This said, we should immediately drown our hopes that better ribosomal drugs will actually change the resistance trend-line. Naively, one would hope that things that interfere with rRNA functioning should be quite hard to adapt to—after all, elements of the ribosome are canonically known for being extremely conserved. And that is true, but resistance manages to evolve anyway, including via, interestingly enough, post-transcriptional-modifications that prevent the antibiotic from binding to rRNA.&lt;/p&gt;
    &lt;p&gt;Of course, the real issue with antibiotics has little to do with scientific ideas, and more to do with economics. A funny paragraph I found from an interview with the lead author of a recent ‘new rRNA antibiotic’ paper had this to say:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…there is an argument that the difficulty making successful antibiotic drugs has more to do with business models than with molecules. When asked about this, Myers says, “Do I worry about the broken business model for antibiotics development? Are you kidding? Every day. That may be the most challenging problem of the lot, and it is not one that I can solve. Synthesizing new antibiotics—in that, I feel confident.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;One related note is that RNA structure may not only be useful for targeting bacterial rRNA, but also viral RNA. A particularly famous case here is a paper that developed a protein that can bind to a structured RNA element in the HIV virus, impairing transcription of it (albeit in an in-vitro setting). Though this has yet to lead to any approved drugs, the subject is, according to one review paper, promising.&lt;/p&gt;
    &lt;p&gt;Moving onto the aptamer side, though it is still early days, the future is interesting. Circa 2024, de novo RNA aptamer design is currently at the ‘we can redesign existing things’, which is a necessary step on the way to ‘we can redesign existing things to make them better’, but we’re not there yet. What’s the therapeutic utility of an aptamer anyway? Basically the same uses one would have for an antibody for, with a ton of side benefits:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Aptamers have several advantages over antibodies, not least the fact that they can be produced quickly and easily without the need for animal use. Aptamers also benefit from low production costs, high batch-to-batch consistency, and functional stability when stored at room temperature, which gives them a long shelf-life and simplifies both transportation and storage. In addition, the low immunogenicity of aptamers makes them valuable tools for in vivo applications, while their small size compared to antibodies allows them to better penetrate cells and tissues. This can be especially useful when studying difficult-to-access targets such as those found within the tumor microenvironment.&lt;/p&gt;
      &lt;p&gt;On the flipside, aptamers are poorly suited to applications in which it is desirable to stimulate an immune response and may undergo rapid clearance in vivo unless they have been modified to prevent this.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is quite nice, but there’s a lot of modalities vying for the antibody throne, and many of those share similar benefits as aptamers. Beyond the scope of this essay for me to judge how large the value is here, but I’m sure it’s non-zero!&lt;/p&gt;
    &lt;head rend="h1"&gt;Some nuance&lt;/head&gt;
    &lt;p&gt;Every essay I write, I try to form a strong opinion to build my story on, and I’ve sketched out one such opinion here: most of the value of RNA structure is in secondary structure, predicted secondary structure is quite good, and tertiary structure has a limited set of use cases. I think the argument for this position is decently strong.&lt;/p&gt;
    &lt;p&gt;But I should note that the take I have here is not a universally held opinion for those in the field, and is very much a ‘I did my research, and this is the conclusion I came to’. There are, I think, reasonable disagreements that people have had to this.&lt;/p&gt;
    &lt;p&gt;First, one paper titled Thoughts on how to think (and talk) about RNA structure argues that the seemingly high utility of secondary structure has a lot more to do with its historical ease of accessibility rather than the low utility of tertiary structure. Some context: most RNA secondary structure consists of what is called ‘Watson-Crick Pairs’, or just the tendency for RNA adenine (A) to match with Uracil (U) and Guanine (G) to pair with Cytosine (C). Non-Watson–Crick are just any hydrogen bond that forms outside of this, which typically can only be noticed in 3D space. The aforementioned paper says this about the two:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Overall, the tendency to focus on Watson–Crick pairs may stem from the fact that they are the basis of nucleic acid hybridization and that they are easier to identify, draw, and rationally mutate. However, non-Watson–Crick pairing and stacking patterns in helical junctions and internal loops preform a 3D architecture that dictates the angles of emerging helices. As a result, specific parts of the RNA are spatially positioned to readily establish interactions often involving nucleotides that are far apart in sequence, but not in three dimensions….Non-Watson–Crick pairings combined with helical stacking give rise to structural motifs that provide the building blocks of many higher-order structures, including ultrastable tetraloops and their receptors, kink-turns, E-loops, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For instance, I mentioned earlier that the tertiary structure of mRNA targets is not exploited in any FDA-approved drugs. This is true, but they are being exploited in preclinical settings! For instance, Arrakis Therapeutics, a RNA-targeting-with-small molecules biotech startup with a very fun name, has this really interesting presentation showing that multiple of their ligands are able to bind to conserved, accessible 3D pockets of mRNA of the MYC protein. This is a notoriously difficult protein to directly bind to, but seemingly accessible through its mRNA.&lt;/p&gt;
    &lt;p&gt;Second and relatedly, I dismissed the value of mRNA tertiary structure, but there is an RNA modality that does something very similar to exogenous mRNA and has a very important tertiary structure: circRNA’s, or circular RNA, which form a covalently closed continuous loop. One of the giants of the field (Mihir Metkar, who was one of the primary contributors of the Moderna COVID-19 mRNA vaccine) has written a great Nature review article over mRNA broadly, and did mention that circRNA’s must rely on a fundamentally different mechanism to initiate protein translation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Because canonical mammalian translation depends on 5′-cap recognition, mRNAs that lack a cap [e.g. circRNA’s] require an alternative means of translation initiation. One answer is an IRES (Fig. 6).&lt;/p&gt;
      &lt;p&gt;First discovered in picornaviruses, IRESs vary with respect to both their structural complexity and their reliance on endogenous initiation factors. In general, these two features are inversely correlated, with the simplest IRESs bypassing only the cap recognition step, whereas the most structurally complex bypass even AUG recognition, relying instead on intimate direct interactions with both the large and small ribosomal subunits.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words, the IRES’s, or internal ribosome entry site, on a circRNA is the primary way it is recruited to the ribosome. This means that translation efficiency, tissue specificity, and even coding potential can hinge on whether the IRES is stable, accessible, and folded in the right way, meaning that it is a strong axis of control of a circRNA therapeutic! For example, engineering an IRES to improve translation efficacy is something that is fully possible to do. But to do this at extreme scales, we’d likely need to be able do tertiary RNA structure prediction very well, since the three-dimensional structure of IRES seems to matter a fair bit (though, admittedly, most of the experimental structure studies of IRES are for non-therapeutically relevant ones). But why even use circRNA’s over mRNA’s? One paper explains that quite well:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Compared with the canonical linear mRNA used in vaccines, circRNAs have multiple advantages.&lt;/p&gt;
      &lt;p&gt;(1) CircRNAs are more stable and easy to store, whereas mRNA vaccines exhibit extreme instability because it is susceptible to degradation by RNases during transportation, storage, delivery, etc. Although nucleotide modifications of the mRNA backbone and UTR regions make mRNA more stable, this increases cost and complicates the manufacturing process, and the storage of the resulting vaccine still requires a low-temperature cold chain due to its suboptimal thermostability. CircRNAs without any modifications exhibit high stability and RNase resistance and can be stored at room temperature or under repeated freeze‒thaw conditions.&lt;/p&gt;
      &lt;p&gt;(2) CircRNAs without any modification exhibit fewer side effects. The cytotoxicity and side effects caused by mRNA vaccines are partly due to their high immunogenicity. Compared with modified mRNA, which has somewhat modulated high immunogenicity, circRNA exhibits lower immunogenicity, and lower cytotoxicity in the absence of modification.&lt;/p&gt;
      &lt;p&gt;(3) CircRNAs possess prolonged antigen-yielding capabilities and durable immune responses. The resulting longevity and thus prolonged antigen production contribute to antigen retention in antigen-presenting cells (APCs) and prolong antigen presentation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Convincing to me! Very excited to see how the circRNA space plays out.&lt;/p&gt;
    &lt;p&gt;Thirdly and finally, claiming that secondary structure for RNA is nearly solved is false, at least for mRNA used in the clinic. After all, the mRNA used in vaccines is quite biochemically distinct from the mRNA we naturally produce in one important element: the uridine nucleotide is replaced with a different chemical (the most common one being 1-methyl-pseudouridine, or m1Ψ), which is more immunologically ‘quiet’. This, as you may expect, messes up secondary structure prediction a fair bit, since there are basically zero experimentally determined mRNA structures with modified nucleotides. The same Mihir Metkar paper mentioned earlier says this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Although m1Ψ substitutions have little consequence on in vitro transcription or translational fidelity, as with other naturally occurring modified nucleotide, m1Ψ can substantially alter RNA secondary structure…these subtle differences in individual base-pair stabilities can lead to structural changes that alter mRNA functionality (for example, creating or disrupting a RNA binding protein (RBP) binding site)...&lt;/p&gt;
      &lt;p&gt;At present, the functional competence of RNA structures that contain modified nucleotides can only be assured by empirical testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There is ongoing work to solve this problem but the datasets are still all quite small, as is typical in the RNA world.&lt;/p&gt;
    &lt;p&gt;And that’s it! Thank you for reading!&lt;/p&gt;
    &lt;p&gt;So, one, there are some cases of cryo-EM being useful for at least some RNA structures, like here, and that may accelerate as the field of cryo-EM reconstruction gets better and better. Second, NMR can be useful for RNA structure prediction problems in cases you have a crudely-predicted structure, but think you improve it by confirming the pairwise proximity of a handful of nucleotides. This is significantly more tractable, even for larger RNA, to do via NMR!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45390866</guid><pubDate>Fri, 26 Sep 2025 20:47:31 +0000</pubDate></item><item><title>The von Neumann bottleneck is impeding AI computing?</title><link>https://research.ibm.com/blog/why-von-neumann-architecture-is-impeding-the-power-of-ai-computing</link><description>&lt;doc fingerprint="845b55d0f0aa6cd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why a decades old architecture decision is impeding the power of AI computing&lt;/head&gt;
    &lt;p&gt;Most computers are based on the von Neumann architecture, which separates compute and memory. This arrangement has been perfect for conventional computing, but it creates a data traffic jam in AI computing.&lt;/p&gt;
    &lt;p&gt;AI computing has a reputation for consuming epic quantities of energy. This is partly because of the sheer volume of data being handled. Training often requires billions or trillions of pieces of information to create a model with billions of parameters. But that’s not the whole reason — it also comes down to how most computer chips are built.&lt;/p&gt;
    &lt;p&gt;Modern computer processors are quite efficient at performing the discrete computations they’re usually tasked with. Though their efficiency nosedives when they must wait for data to move back and forth between memory and compute, they’re designed to quickly switch over to work on some unrelated task. But for AI computing, almost all the tasks are interrelated, so there often isn’t much other work that can be done when the processor gets stuck waiting, said IBM Research scientist Geoffrey Burr.&lt;/p&gt;
    &lt;p&gt;In that scenario, processors hit what is called the von Neumann bottleneck, the lag that happens when data moves slower than computation. It’s the result of von Neumann architecture, found in almost every processor over the last six decades, wherein a processor’s memory and computing units are separate, connected by a bus. This setup has advantages, including flexibility, adaptability to varying workloads, and the ability to easily scale systems and upgrade components. That makes this architecture great for conventional computing, and it won’t be going away any time soon.&lt;/p&gt;
    &lt;p&gt;But for AI computing, whose operations are simple, numerous, and highly predictable, a conventional processor ends up working below its full capacity while it waits for model weights to be shuttled back and forth from memory. Scientists and engineers at IBM Research are working on new processors, like the AIU family, which use various strategies to break down the von Neumann bottleneck and supercharge AI computing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why does the von Neumann bottleneck exist?&lt;/head&gt;
    &lt;p&gt;The von Neumann bottleneck is named for mathematician and physicist John von Neumann, who first circulated a draft of his idea for a stored-program computer in 1945. In that paper, he described a computer with a processing unit, a control unit, memory that stored data and instructions, external storage, and input/output mechanisms. His description didn’t name any specific hardware — likely to avoid security clearance issues with the US Army, for whom he was consulting. Almost no scientific discovery is made by one individual, though, and von Neumann architecture is no exception. Von Neumann’s work was based on the work of J. Presper Eckert and John Mauchly, who invented the Electronic Numerical Integrator and Computer (ENIAC), the world’s first digital computer. In the time since that paper was written, von Neumann architecture has become the norm.&lt;/p&gt;
    &lt;p&gt;“The von Neumann architecture is quite flexible, that’s the main benefit,” said IBM Research scientist Manuel Le Gallo-Bourdeau. “That’s why it was first adopted, and that’s why it’s still the prominent architecture today.”&lt;/p&gt;
    &lt;p&gt;Discrete memory and computing units mean you can design them separately and configure them more or less any way you want. Historically, this has made it easier to design computing systems because the best components can be selected and paired, based on the application.&lt;/p&gt;
    &lt;p&gt;Even the cache memory, which is integrated into a single chip with the processor, can still be individually upgraded. “I’m sure there are implications for the processor when you make a new cache memory design, but it’s not as difficult as if they were coupled together,” Le Gallo-Bourdeau said. “They’re still separate. It allows some freedom in designing the cache separately from the processor.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How the von Neumann bottleneck reduces efficiency&lt;/head&gt;
    &lt;p&gt;For AI computing, the von Neumann bottleneck creates a twofold efficiency problem: the number of model parameters (or weights) to move, and how far they need to move. More model weights mean larger storage, which usually means more distant storage, said IBM Research scientist Hsinyu (Sidney) Tsai. “Because the quantity of model weights is very large, you can’t afford to hold them for very long, so you need to keep discarding and reloading,” she said.&lt;/p&gt;
    &lt;p&gt;The main energy expenditure during AI runtime is spent on data transfers — bringing model weights back and forth from memory to compute. By comparison, the energy spent doing computations is low. In deep learning models, for example, the operations are almost all relatively simple matrix vector multiplication problems. Compute energy is still around 10% of modern AI workloads, so it isn’t negligible, said Tsai. “It is just found to be no longer dominating energy consumption and latency, unlike in conventional workloads,” she added.&lt;/p&gt;
    &lt;p&gt;About a decade ago, the von Neumann bottleneck wasn’t a significant issue because processors and memory weren’t so efficient, at least compared to the energy that was spent to transfer data, said Le Gallo-Bourdeau. But data transfer efficiency hasn’t improved as much as processing and memory have over the years, so now processors can complete their computations much more quickly, leaving them sitting idle while data moves across the von Neumann bottleneck.&lt;/p&gt;
    &lt;p&gt;The farther away the memory is from the processor, the more energy it costs to move it. On a basic physical level, an electrical copper wire is charged to propagate a 1, and it’s discharged to propagate a 0. The energy spent charging and discharging the wires is proportional to their length, so the longer the wire is, the more energy you spend. This also means greater latency, as it takes more time for the charge to dissipate or propagate the longer the wire is.&lt;/p&gt;
    &lt;p&gt;Admittedly, the time and energy cost of each data transfer is low, but every time you want to propagate data through a large language model, you need to load up to billions of weights from the memory. This could mean using the DRAM from one or more other GPUs, because one GPU doesn’t have enough memory to store them all. After they’re downloaded to the processor, it performs its computations and sends the result to another memory location for further processing.&lt;/p&gt;
    &lt;p&gt;Aside from eliminating the von Neumann bottleneck, one solution includes closing that distance. “The entire industry is working to try to improve data localization,” Tsai said. IBM Research scientists recently announced such an approach: a polymer optical waveguide for co-packaged optics. This module brings the speed and bandwidth density of fiber optics to the edge of chips, supercharging their connectivity and hugely reducing model training time and energy costs.&lt;/p&gt;
    &lt;p&gt;With currently available hardware, though, the result of all these data transfers is that training an LLM can easily take months, consuming more energy than a typical US home does in that time. And AI doesn’t stop needing energy after model training. Inferencing has similar computational requirements, meaning that the von Neumann bottleneck slows it down in a similar fashion.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting around the bottleneck&lt;/head&gt;
    &lt;p&gt;For the most parts, model weights are stationary, and AI computing is memory-centric, rather than compute heavy, said Le Gallo-Bourdeau. “You have a fixed set of synaptic weights, and you just need to propagate data through them.”&lt;/p&gt;
    &lt;p&gt;This quality has enabled him and his colleagues to pursue analog in-memory computing, which integrates memory with processing, using the laws of physics to store weights. One of these approaches is phase-change memory (PCM), which stores model weights in the resistivity of a chalcogenide glass, which is changed by applying an electrical current.&lt;/p&gt;
    &lt;p&gt;“This way we can reduce the energy that is spent in data transfers and mitigate the von Neumann bottleneck,” said Le Gallo-Bourdeau. In-memory computing isn’t the only way to work around the von Neumann bottleneck, though.&lt;/p&gt;
    &lt;p&gt;The AIU NorthPole is a processor that stores memory in digital SRAM, and while its memory isn’t intertwined with compute in the same way as analog chips, its numerous cores each has access to local memory — making it an extreme example of near-memory computing. Experiments have already demonstrated the power and promise of this architecture. In recent inference tests run on a 3-billion-parameter LLM developed from IBM’s Granite-8B-Code-Base model, NorthPole was 47 times faster than the next most energy-efficient GPU and was 73 times more energy efficient than the next lowest latency GPU.&lt;/p&gt;
    &lt;p&gt;It’s also important to note that models trained on von Neumann hardware can be run on non-von Neumann devices. In fact, for analog in-memory computing, it’s essential. PCM devices aren’t durable enough to have their weights changed over and over, so they’re used to deploy models that have been trained on conventional GPUs. Durability is a comparative advantage of SRAM memory in near-memory or in-memory computing, as it can be rewritten infinitely.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why von Neumann computing isn’t going away&lt;/head&gt;
    &lt;p&gt;While von Neumann architecture creates a bottleneck for AI computing, for other applications, it’s perfectly suited. Sure, it causes issues in model training and inference, but von Neumann architecture is perfect for processing computer graphics or other compute-heavy processes. And when 32- or 64-bit floating point precision is called for, the low precision of in-memory computing isn’t up to the task.&lt;/p&gt;
    &lt;p&gt;“For general purpose computing, there's really nothing more powerful than the von Neumann architecture,” said Burr. Under these circumstances, bytes are either operations or operands that are moving on a bus from a memory to a processor. “Just like an all-purpose deli where somebody might order some salami or pepperoni or this or that, but you're able to switch between them because you have the right ingredients on hand, and you can easily make six sandwiches in a row.” Special-purpose computing, on the other hand, may involve 5,000 tuna sandwiches for one order — like AI computing as it shuttles static model weights.&lt;/p&gt;
    &lt;p&gt;Even when building their in-memory AIU chips, IBM Researchers include some conventional hardware for the necessary high-precision operations.&lt;/p&gt;
    &lt;p&gt;Even as scientists and engineers work on new ways to eliminate the von Neumann bottleneck, experts agree that the future will likely include both hardware architectures, said Le Gallo-Bourdeau. “What makes sense is some mix of von Neumann and non-von Neumann processors to each handle the operations they are best at.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Related posts&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q &amp;amp; AKim Martineau&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Scaling to meet the future of India’s AI needs&lt;/head&gt;NewsMike Murphy&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;AI agent reliability with BeeAI&lt;/head&gt;Technical noteSandi Besen&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;IBM researchers win prestigious European grants&lt;/head&gt;NewsPeter Hess and Mike Murphy&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391078</guid><pubDate>Fri, 26 Sep 2025 21:12:56 +0000</pubDate></item><item><title>Understanding RL for model training, and future directions with GRAPE</title><link>https://arxiv.org/abs/2509.04501</link><description>&lt;doc fingerprint="8c9c010ac4f5308f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 2 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Understanding Reinforcement Learning for Model Training, and future directions with GRAPE&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:This paper provides a self-contained, from-scratch, exposition of key algorithms for instruction tuning of models: SFT, Rejection Sampling, REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct Preference Optimization (DPO). Explanations of these algorithms often assume prior knowledge, lack critical details, and/or are overly generalized and complex. Here, each method is discussed and developed step by step using simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity and provide a clear and intuitive understanding of the concepts. By minimizing detours into the broader RL literature and connecting concepts to LLMs, we eliminate superfluous abstractions and reduce cognitive overhead. Following this exposition, we provide a literature review of new techniques and approaches beyond those detailed. Finally, new ideas for research and exploration in the form of GRAPE (Generalized Relative Advantage Policy Evolution) are presented.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CL&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391220</guid><pubDate>Fri, 26 Sep 2025 21:30:23 +0000</pubDate></item><item><title>Moondream 3 Preview: Frontier-level reasoning at a blazing speed</title><link>https://moondream.ai/blog/moondream-3-preview</link><description>&lt;doc fingerprint="ed439b79801b9f8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Moondream 3 Preview&lt;/head&gt;
    &lt;p&gt;We're excited to announce a preview release of Moondream 3. It's a new architecture of 9B MoE, with 2B active params. Moondream now achieves frontier-level visual reasoning while still retaining blazingly fast and efficient inference.&lt;/p&gt;
    &lt;p&gt;Why A New Architecture&lt;lb/&gt; The impact of AI today has largely been relegated to the digital realm. We have agents that can code, produce digital art, and so on - but very few cases of AI operating in our physical world. No robots to clean our houses, or act as receptionists, or inspect buildings, etc… For Moondream 3, we focused on 4 key areas.&lt;/p&gt;
    &lt;p&gt;Visual reasoning: despite our focus on smaller models, we don't want that to come at the cost of capability. We want Moondream to be the most capable VLM at real-world tasks.&lt;/p&gt;
    &lt;p&gt;Trainable: Many vision tasks require specialization. It's not enough for VLMs to be as good as humans. Even humans need training when it comes to complex tasks. Accurately interpreting an X-Ray image, or detecting struggling people in crowds. Moondream must be easily trainable.&lt;/p&gt;
    &lt;p&gt;Fast: Vision AI applications often need near-realtime performance. Sorting produce, or detecting missing herd animals from a drone, or recognizing security incidents - none of these tasks can be built without fast vision inference.&lt;/p&gt;
    &lt;p&gt;Inexpensive: Vision AI apps often deal with huge quantities of images, and cost can often be a blocker to adoption. Moondream must be cheap to run at scale.&lt;/p&gt;
    &lt;p&gt;Moondream 3 achieves these goals by adopting a 9B MoE model, yet still with 2B active parameters. This enables it to achieve, and in some cases beat, frontier-level models, yet still only require 2B active parameters (keeping it fast and inexpensive). We also improved its training dynamics, making Moondream 3 more efficient at learning, especially when using Reinforcement Learning (more on that in subsequent announcements). For more details on the architecture, head to the "Tech Notes" below. One final detail however: we grew the context length from 2k to 32k, making Moondream much better at understanding and producing more complex queries and answers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Moondream 3 in action&lt;/head&gt;
    &lt;p&gt;Here are some examples of Moondream 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Object Detection&lt;/head&gt;
    &lt;p&gt;Moondream 3 is astonishingly good at object detection. It goes beyond simple labels (.e.g., "car") and can understand more complex queries. We show results compared to frontier models alongside. These models don't support grounding skills like object detection and pointing natively, so we used a templated query for those (see footer).&lt;/p&gt;
    &lt;p&gt;Example 1&lt;lb/&gt; Prompt: "Runner with purple socks" &lt;/p&gt;
    &lt;p&gt;Example 2&lt;lb/&gt; Prompt: "Quantity input"&lt;/p&gt;
    &lt;head rend="h3"&gt;Pointing&lt;/head&gt;
    &lt;p&gt;Moondream supports pointing as a native skill.&lt;/p&gt;
    &lt;p&gt;Example 3&lt;lb/&gt; Prompt: "Bottle"&lt;/p&gt;
    &lt;p&gt;Example 4&lt;lb/&gt; Prompt: "Best utensil for pasta"&lt;/p&gt;
    &lt;head rend="h3"&gt;Structured output&lt;/head&gt;
    &lt;p&gt;With a longer context length, Moondream 3 generates intelligent structured outputs with minimal prompting.&lt;/p&gt;
    &lt;p&gt;Example 5: Sled dogs&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "A JSON array with keys: dog_id, fur_color, harness_color."&lt;/p&gt;
    &lt;p&gt;Result&lt;lb/&gt; [&lt;lb/&gt; { "dog_id": 1, "fur_color": "light brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 2, "fur_color": "dark brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 3, "fur_color": "gray", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 4, "fur_color": "white", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 5, "fur_color": "dark brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 6, "fur_color": "light brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 7, "fur_color": "dark brown", "harness_color": "black" },&lt;lb/&gt; { "dog_id": 8, "fur_color": "white", "harness_color": "black" }&lt;lb/&gt; ]&lt;/p&gt;
    &lt;head rend="h3"&gt;OCR&lt;/head&gt;
    &lt;p&gt;Moondream 3 has drastically improved its OCR abilities. Our vision encoder can get tripped up on tiny fonts (working on it), but it's now useful in many real-world cases.&lt;/p&gt;
    &lt;p&gt;Example 6&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "Convert to markdown""&lt;/p&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;p&gt;| Metal | Reaction | Electrode Potential (V) |&lt;lb/&gt; |---|---|---|&lt;lb/&gt; | Gold | Au⁺ + e⁻ = Au | +1.692 |&lt;lb/&gt; | Silver | Ag⁺ + e⁻ = Ag | +0.7996 |&lt;lb/&gt; | Copper | Cu²⁺ + 2e⁻ = Cu | +0.342 |&lt;lb/&gt; | Iron | Fe³⁺ + 3e⁻ = Fe | -0.037 |&lt;lb/&gt; | Lead | Pb²⁺ + 2e⁻ = Pb | -0.126 |&lt;lb/&gt; | Nickel | Ni²⁺ + 2e⁻ = Ni | -0.257 |&lt;lb/&gt; | Cadmium | Cd²⁺ + 2e⁻ = Cd | -0.403 |&lt;lb/&gt; | Iron | Fe²⁺ + 2e⁻ = Fe | -0.447 |&lt;lb/&gt; | Zinc | Zn²⁺ + 2e⁻ = Zn | -0.762 |&lt;lb/&gt; | Aluminum | Al³⁺ + 3e⁻ = Al | -1.662 |&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Here are some early benchmark results. We show it alongside some top frontier models for comparison. In practice, however, it's probably not a fair comparison for Moondream since, in practical terms, Moondream produces answers in fraction of the time of these bigger models. We'll publish more complete results later and include inference times to make this clearer.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scores with a "*" next to them indicate that we used a 100 random question sample rather than evaluate the whole benchmark.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;MD3 Preview Technical Notes&lt;/head&gt;
    &lt;p&gt;Here are some details on our new model architecture. Moondeam 3 is a fine-grained sparse mixture-of-experts model with 64 experts, of which 8 are activated for each token. We initialized it from Moondream 2 (a 2B dense model) using drop upcycling. We also extended the usable context length to 32K tokens, which is critical for few-shot prompting and agentic workflows with tool-use. We don’t fully leverage this longer context in our post-training yet (part of why it's only a preview release). The full 32k context is available for you if you're interested in fine-tuning the model.&lt;/p&gt;
    &lt;p&gt;(Figure: Long-context perplexity evaluation on GovReport dataset. Each point shows the average cross-entropy loss (nats per token) for a 128-token sliding window at that position, measured across 100 documents truncated to 32,768 tokens.)&lt;/p&gt;
    &lt;p&gt;We do not use a separate context-length extension phase during training, instead opting to interleave long-context samples while pretraining with a default context length of 4096 tokens. Many context length extension methods like YaRN include an attention temperature scaling component. Inspired by this, we adjust the architecture to enable learned temperature scaling as a function of position, and find this helps with long context modeling.&lt;/p&gt;
    &lt;p&gt;Like our last 2B release, this is a hybrid reasoning model that supports both reasoning and non-reasoning mode. Unlike other reasoning models, however, Moondream focuses on visual reasoning with grounding. Here’s an example of what that means:&lt;/p&gt;
    &lt;p&gt;Each chunk of underlined text in the reasoning is grounded, meaning the model references a particular part of the image. In our playground, you can see what the model is focusing on by hovering over the text.&lt;/p&gt;
    &lt;p&gt;The model starts with only a small set of visual-reasoning examples, and gradually learns to rely on them more during our reinforcement learning (RL) post-training phase. RL proved so effective that, as we refined our training approach, post-training ended up using more compute than the initial pre-training itself.&lt;/p&gt;
    &lt;p&gt;It was trained with load-balancing and router orthogonality losses to help similar tokens specialize together early on, then had load balancing disabled in post-training to avoid catastrophic forgetting from distribution shift. Finally, attention tweaks like learnable temperature and LSE suppression sharpened focus and cut noise—boosting accuracy and clarity.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This preview release comes with some caveats. We haven't optimized the inference code yet, so inferences are much slower than anticipated (we're working on it!). We're also still actively training this model, and we expect the capabilities and benchmarks scores to improve. We also plan to produce variants of this model (e.g., quantized versions and distilled smaller versions).&lt;/p&gt;
    &lt;p&gt;The model is now available on the Moondream playground, and you can download it on HuggingFace (Moondream Station will be updated soon). Hit us up on our Discord if you have any questions.&lt;/p&gt;
    &lt;p&gt;(1) Frontier models don't support object detection natively, so this prompt was used instead:&lt;lb/&gt; Detect these objects in the image: [comma-separated list].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391444</guid><pubDate>Fri, 26 Sep 2025 21:59:57 +0000</pubDate></item><item><title>Israel hacked every Gaza cellphone to stream PM Netanyahu's UN Speech live</title><link>https://twitter.com/israelipm/status/1971570108322480350</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391461</guid><pubDate>Fri, 26 Sep 2025 22:01:45 +0000</pubDate></item><item><title>Thoughts on Mechanical Keyboards and the ZSA Moonlander</title><link>https://www.masteringemacs.org/article/thoughts-on-mechanical-keyboards-zsa-moonlander</link><description>&lt;doc fingerprint="4d545c11f59d8556"&gt;
  &lt;main&gt;
    &lt;p&gt;I don’t normally review things here, as I find that it’s outside the realm of the blog, but I want to talk about the ZSA Moonlander keyboard, a “mechanical” keyboard that I bought a couple of years ago. But, yeah, in case you’re wondering why I am writing a review: I mean, it’s a keyboard? You type on it. It goes clickety-clack — or maybe not, if you’re an obsessive and want your keyboard quiet. Or maybe you want it loud, like the flexor-destroying IBM model Ms from the days of yore, rat-tat-tatting like a Mac-10. People are into that now: they need to sound right, look right (boba tea colored keys are a thing) and type well. If they light up like a cheap vape stick, even better.&lt;/p&gt;
    &lt;p&gt;To me, it’s a tool; it’s there to minimize strain and injury. I bought the moonlander because it helps me do my job. It’s no different to me than a hammer is to a carpenter, and yet in using it I’ve realized it does expand on what I can do in ways that I feel compelled to talk about. It is a game changer to any keyboard warrior. ZSA’s moonlander is merely one well-crafted incarnation of millions.&lt;/p&gt;
    &lt;p&gt;Ricing your keyboard is a hobby. It’s nearly a religion to some folk: like crossfit and instant pots.&lt;/p&gt;
    &lt;p&gt;One major benefit of this movement is the wealth of opportunity afforded to people like me, and you, who care about finger ergonomy but do not find the old-fashioned options that have long existed on the periphery of peripherals.&lt;/p&gt;
    &lt;p&gt;The specifics of what makes, or doesn’t make, a mechanical keyboard is, I am sure, a tedious conversation that takes place all the time, so I’ll hide behind the phrase I’ll know it when I see it and move swiftly on. (But I’ll argue that quality key switches and firmware are two of the most important ones.)&lt;/p&gt;
    &lt;p&gt;It’s interesting how it’s a whole thing now for enthusiasts to solder, assemble, or buy ready-made mechanical keyboards made by other enthusiasts. It’s also a sign of how dire traditional, commercial keyboards are in quality and choice. With a mechanical keyboard you can pick the type of key switch you want your keys to have: quiet, loud, firm, soft. Linear or non-linear. You can mix and match so some keys are weightier than others: your thumbs are stronger, so you’ll want a weightier key for them.&lt;/p&gt;
    &lt;p&gt;I feel like this movement has sprung up out of nowhere in the last ten years, and it’s resulted in a lot of fun and interesting keyboards. There are novel firmware choices beyond the most manifestly basic idea that pressing a key yields exactly one outcome.&lt;/p&gt;
    &lt;p&gt;Clacky keys and boba tea colored key caps is not why I bought into the mechanical keyboard hype. I have long wanted to ditch the Microsoft Natural Ergonomic 4000 keyboards (who came up with that name?)&lt;/p&gt;
    &lt;p&gt;I had two at all times: one at home and another at work. They’d wear out from use after a couple of years. Total flim-flam. The typing experience was never great, either. But I loved the ergonomic design. I’ve owned around 10 in the last 20 years, as the ergonomics of the keyboard (and lack of serious alternatives) kept me from switching.&lt;/p&gt;
    &lt;p&gt;You see, mechanical keyboards offer hardware flexibility like switchable key caps and switches (the bit that goes click), true; but most of them also come with fancy, free software firmware that opens up a whole world of amazing possibilities. I’ve worked in some pretty weird work environments, and being able to rebind caps lock to control is one of the most important things I have to do on a traditional keyboard, like the aforementioned Microsoft keyboard. I once had to work at a client’s place that mandated I use a garbage-tier Citrix thin client computer that’d read your keyboard’s scan codes and make up its mind later, somewhere en-route to a data center in Paris, what key it should treat it as. I don’t have to tell you that rebinding caps lock to much of anything did not work at all.&lt;/p&gt;
    &lt;p&gt;But, with thoroughly customizable firmware, it’s a snap to deign a key to be what ever you choose; or even multiple things, at different times. Your customizations are in the keyboard’s firmware itself, so you take your changes with you. That’s perfect for someone like me that used to crash through the windows of many a client sites, Mary Poppins-style, keyboard in hand, ready to build software.&lt;/p&gt;
    &lt;p&gt;The value and flexibility of the firmware really is that useful and important. I now recommend that people consider this style of keyboard (or, at the very least, the programmable aspects of a mechanical keyboard) in my book, as it’s a good way to personalize your keyboard workflow to suit your style and needs. Forget binding caps lock to control: move your keys around to suit your physical needs. That is infinitely better than crudely remapping caps lock to control.&lt;/p&gt;
    &lt;p&gt;Back to the Moonlander. The product page did a reasonable (if overly flashy) job of explaining its key benefits over a regular keyboard. The cost? $365. Ouch. It’s not that much money for something that I myself use to make money, but it’s like… it’s just a keyboard. What’s it made out of!? Pressed myrrh and printer ink?&lt;/p&gt;
    &lt;p&gt;Still, it’s not a bad price if the finish and quality matches the price. So I bought it, and it took about 7-8 days to arrive at my house in London, all the way from Taiwan. Returns are apparently not possible, fair enough, as ZSA’s a small business, and Taiwan is a long way away. They recommend you try and sell it yourself if you dislike it. Spare a thought for the guy on eBay who was selling one with blank key caps, around the time I was buying mine, saying it was ‘barely used’…&lt;/p&gt;
    &lt;p&gt;The keyboard only has two years of warranty, though they claim it’s ‘built to last’. So fingers crossed as I’m coming up on 4 years of daily use.&lt;/p&gt;
    &lt;p&gt;What I like about it is that it ticked my main requirement of being touch typist friendly. Sounds dumb, but it has to feel right. Regular keyboards are too packed together. I’m a big guy: I don’t want to squash my shoulders and arms like I do when I type on a laptop keyboard. The keyboard is actually two keyboards. One half of a keyboard for each hand. The right-hand side has a removable cable that plugs into the left-hand side, so you could conceptually get by with just one side, which is a nice touch. The left-hand side has the USB cable, also removable, to connect to your computer. Because it’s in two pieces, I can move each half of the keyboard around to better fit my posture. I like that feature a lot.&lt;/p&gt;
    &lt;p&gt;It’s also surprisingly small, which is not always a benefit, as I’m wide-shouldered with big hands, but it works for me. The portability was not what I was looking for, but it’s come in handy for traveling, as it comes with a soft case pouch. You can put it in carry-on luggage quite easily and take it with you. That’s proven more useful than I thought it would. I’ve flown with the Microsoft keyboards too many times to count, and they’re bulky by comparison.&lt;/p&gt;
    &lt;p&gt;Much like so many keyboards of its type, it comes with “thumb clusters”, a set of four keys that are meant to be reachable primarily with your thumbs. I have large hands, so that works for me, but the red buttons they have on there are a stretch, even for me, to press without shifting my wrist. You can pivot the thumb cluster up or down (or lay it flat against your desk) which is finicky as all hell, as you have to lock it in place and somehow try to keep it from wobbling.&lt;/p&gt;
    &lt;p&gt;One, ah, novelty of the Moonlander is what they call tenting. It’s a pole that you can use to tilt each half of the keyboard to attain – they claim – a more ‘ergonomic’ position for your hands. The problem is, when you’re pitching your ‘tent’ (stop snickering), locking it into position (you’ll need a hex key to fasten the bolts on the thumb clusters and poles) so that your keyboard does not wobble is challenging to say the least. It works much like a table in a restaurant: no matter what, it’s going to wobble a bit. Maybe not today, but perhaps tomorrow; or when you type a bit more forcefully; or when you put more weight on one part of the keyboard because you pressed a button a bit more forcefully.&lt;/p&gt;
    &lt;p&gt;It’s poorly designed. I don’t want to overtighten the bolts for fear of shearing something, and even if you do want to throw a bit more torque into it, you’re most likely going to push the cluster or tent pole out of position when you try, resulting in a wobbly keyboard. One frustration I ran into is that you cannot pivot the thumb cluster up, so it juts into the air, and also use the tent poles. That leaves the keyboard unbalanced and you cannot type on it.&lt;/p&gt;
    &lt;p&gt;The keyboard also has two optional hand rests that pivot so you can fold them underneath the keyboard for portability. They’re made of the same flimsy plastic that train station lavatory seats are made of. Worse, they have a few unfinished edges — not at all sharp enough to hurt you, but still sharp enough that you’re reminded of how little attention was lavished on this part of an otherwise really well-made keyboard. The rests are attached to a bar to let them pivot, but unfortunately the manufacturing tolerances aren’t great, so they wobble a bit when I shift the weight of my hands around, which is also not good. I wish it had a nice leatherette foam cushion like the Microsoft keyboards did, as the plastic is hard to the touch.&lt;/p&gt;
    &lt;p&gt;I got one of those automated emails after a few months asking for feedback, and I asked about the wobbly rests and unfinished edges; and how you can’t tilt the keyboard and also raise the keyboard cluster. I got a polite email back explaining that the wobble had to be there to facilitate movement and give, and that I could buy their tenting kit to fix the keyboard cluster problem. No answers were forthcoming on the unfinished edges. Make of that what you will.&lt;/p&gt;
    &lt;p&gt;The keyboard is backlit with RGB LEDs, which are a bit frou-frou, though useful if you want to use the firmware’s layering functionality to add multi-modality to keys. Being able to tell layers apart by looking at the keyboard colors work well. The keyboard uses the QMK firmware, a polished and feature rich free software firmware that’s been extended with Moonlander-specific features. Their firmware changes are public and available on Github.&lt;/p&gt;
    &lt;p&gt;The main advantage of Moonlander (really, the QMK firmware) is the ability to program your keys to do more than just one thing. Yes, you can do keyboard macros, but that is not even the most interesting thing. For instance, you can make a key – say your space key – act as the control modifier if you hold it down and type another key at the same time. You can make it behave like a Space Cadet keyboard: tap left shift and it inserts &lt;code&gt;(&lt;/code&gt;; right, and it inserts &lt;code&gt;)&lt;/code&gt;. You can designate a key to toggle a new keyboard layer, letting you type accented characters, control your media player with media keys, and more. There are dozens of features and you have complete control over what each key will do.&lt;/p&gt;
    &lt;p&gt;I ordered the keyboard with the recommended Cherry Brown MX switches – those are the key switches the plastic key caps sit atop of, and you can choose which ones you want when you buy, or even replace them yourself after the fact – and they, much like the key caps and the main body of the keyboard, are of high quality and feel good to type on. I have zero complaints about this part of the build quality, and the main body of the keyboard is well made and sturdy. I can tell they spent a lot of engineering effort on that.&lt;/p&gt;
    &lt;p&gt;There’s a lot of dubious health advice on ergonomics out there that feels unfounded and speculative. And proponents of mechanical keyboards say you need fewer keys than a regular keyboard, for reasons, and to instead use the fancy firmware features to make up for the things they’ve taken away from you, in effect forcing you to use the layer functionality present in the firmware. By and large the mechanical keyboard community is friendly, but more than a little fad-driven and with that spicy melange of broscience and earnest helpfulness.&lt;/p&gt;
    &lt;p&gt;This keyboard, like many of its kind, is not a “full-sized” keyboard. There are fewer keys. No F-keys by default, though they’re behind a layered key in the default configuration; the dedicated column of navigation (arrows, page up/down, etc.) keys are missing, though scattered about. There is no dedicated section of numpad keys, either. The keys are all there, but hidden behind several layers that you access from certain trigger keys that activate when you press one of them.&lt;/p&gt;
    &lt;p&gt;I’m ambivalent about losing out on all the keys, especially as, well, I’m an Emacs user. I’ve adapted, and it’s fine, and I like the current setup I have now, but that part will take some getting used to. It took me a long time to get back up to speed, and there are still key combos that I could tap out with lightning speed on my old keyboard that I still struggle to type as fast: &lt;code&gt;C-M--&lt;/code&gt; (negative argument) followed by another key, such as &lt;code&gt;C-M-k&lt;/code&gt;, is one such example.&lt;/p&gt;
    &lt;p&gt;I wish I had more keys, yet ironically I have empty keys I do not use at all on the keyboard. That sounds like a contradictory statement, but it’s hard to fill out all the keys when you’re confined to the keyboard layout that you have, which necessitates the use of layers, which in some ways (and that is the point) renders the need for more keys unnecessary. A vexing paradox for sure.&lt;/p&gt;
    &lt;p&gt;One thing I think ZSA has done exceptionally well is their custom software stack. They’ve built a wonderful, interactive browser-based keyboard designer that makes it a breeze to not only change and experiment with your keyboard layout, but also view others’ layouts as well. I like their hardware well enough – but it’s just a keyboard to me – but I think they’ve done an outstanding piece of work with the software. When I first got it, I had to download the compiled keyboard ROM and use their easy-to-use tool to flash the keyboard ROM.&lt;/p&gt;
    &lt;p&gt;No more: their layout builder asks for permission to talk to your keyboard directly using WebUSB in the browser and, if you accept, it’ll flash your keyboard’s firmware for you automatically. Very nice. If you use Chrome that is. If you’re using Firefox like I do, then you have to download the firmware and flash it the normal way because the lumpenproletariat who run the security division at Mozilla have decided that WebUSB is… ‘insecure.’&lt;/p&gt;
    &lt;p&gt;The layout builder, the web flashing and the ease of use of it all speaks volumes. Someone’s actively working on improving the user experience which is honestly poor, if you just use the QMK firmware directly. Yes, there are interactive keyboard builders for QMK directly, but if you run into trouble, or if you want to do something esoteric, you’re going to have to start reading the C source code and fiddle with it.&lt;/p&gt;
    &lt;p&gt;So. Is it a good keyboard? Yes. It would be a great keyboard if they’d tweak the issues I have around fit and finish of the hand rests, and make it easier to balance the keyboard. The main reason you should look into a mechanical (QMK-based!) keyboard is that it objectively improves your primary interface with your computer. The QMK firmware’s value-adds – and I have only scratched the surface – is 80% of it. If you have a crappy OEM keyboard or if you’re plinking away on a laptop — get a mechanical keyboard! Your wrists and fingers will thank you in the long run.&lt;/p&gt;
    &lt;p&gt;The Moonlander keyboard is a safe buy and, aside from the issues I mentioned, it is worth the $365. That’s a dollar a day for a year — small potatoes. And if you’re strapped for cash, try searching AliExpress for mechanical keyboards. The Chinese have taken to it with gusto, and you can buy or build your own for not much money and experiment.&lt;/p&gt;
    &lt;p&gt;I program in Emacs for a living, so being able to move my modifier keys to the thumbs is a big improvement, for no other reason that they’re there and underused on most regular keyboards. Being able to multi-task keys to do more than one thing is also a massive win, and another reason to consider a programmable keyboard.&lt;/p&gt;
    &lt;p&gt;Get a mechanical keyboard. Make sure it has QMK firmware. Maybe a Moonlander if you can spare the cash. Go.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391566</guid><pubDate>Fri, 26 Sep 2025 22:17:03 +0000</pubDate></item><item><title>Bell Labs Scientists Accidentally Proved the Big Bang Theory</title><link>https://spectrum.ieee.org/big-bang-theory-discovery</link><description>&lt;doc fingerprint="f9c01b8d6a39cb51"&gt;
  &lt;main&gt;&lt;p&gt;“How did we get here?”&lt;/p&gt;&lt;p&gt;That existential question about the universe has captivated humankind for centuries. Many scientists have attempted to answer it, including the Rev. Georges Lemaître, a Belgian cosmologist and Catholic priest. In 1927 he theorized that the universe was created from a single particle he called the “primeval atom.”&lt;/p&gt;&lt;p&gt;That atom later disintegrated in an explosion, LeMaître figured, creating space, time, and an ever-expanding universe, according to the American Museum of Natural History.&lt;/p&gt;&lt;p&gt;LeMaître’s idea likely sounds familiar, as it is now known as the big bang theory. Direct evidence for the theory wasn’t found until almost four decades later, entirely by accident.&lt;/p&gt;&lt;p&gt;Bell Labs researchers Arno Penzias and Robert Woodrow Wilson were conducting radio astronomy experiments in 1964 using a horn antenna located on the company’s campus in Holmdel, N.J. The reflector antenna was the most sensitive in the world at the time. It was constructed to pick up weak radio signals from space for Project Echo, NASA’s experimental 1960 satellite communications program. The project successfully did so twice, first in 1961 through the passive Echo communication satellite, and a second time in 1963 through the active Telstar communications satellite.&lt;/p&gt;&lt;p&gt;While Penzias and Wilson were using the Holmdel antenna to map radio signals from the Milky Way, it picked up a mysterious buzzing noise that wouldn’t go away despite their attempts to eliminate it.&lt;/p&gt;&lt;p&gt;The signals, which persisted day and night, turned out to be cosmic microwave background radiation that permeates the universe—a remnant from the creation of the cosmos—that helped confirm the big bang theory. The accidental breakthrough earned Penzias and Wilson the 1978 Nobel Prize in Physics.&lt;/p&gt;&lt;p&gt;Project Echo, Telstar, and the discovery of the cosmic microwave background radiation were recognized as an IEEE Milestone at a ceremony held on 25 May in Holmdel at Wilson Park, where the horn antenna is located.&lt;/p&gt;&lt;p&gt;Penzias and Wilson’s evidence for the big bang theory shaped “our understanding of this universe and our place in it,” Thomas Coughlin, 2024 IEEE president, said in a news release about the dedication.&lt;/p&gt;&lt;p&gt;“Cosmic background radiation, one of the most transformative discoveries in the second half of the 20th century, has also led to non-terrestrial communication innovations that address some of the world’s greatest needs, including disaster relief aid,” Coughlin said.&lt;/p&gt;&lt;head rend="h2"&gt;Building the world’s most sensitive antenna&lt;/head&gt;&lt;p&gt;After the Soviet Union in 1957 launched Sputnik, the world’s first artificial satellite put into low Earth orbit, the U.S. government increased its efforts to fund the development of non-terrestrial communication innovations, as detailed in an Engineering and Technology History Wiki entry.&lt;/p&gt;&lt;p&gt;Government and industry worked together on initiatives at laboratories around the country. One of the first programs was Project Echo, which aimed to achieve two-way voice communication between NASA’s Jet Propulsion Laboratory in Goldstone, Calif., and Crawford Hill in Holmdel, 5 kilometers from the Bell Labs complex.&lt;/p&gt;&lt;p&gt;Langley engineers (from right): Norman Crabill, Edwin Kilgore, and an unidentified man take a peek inside the vast balloon during inflation tests of the Echo 1 Satellite in Weeksville, N.C.NASA&lt;/p&gt;&lt;p&gt;To make the communication possible, project leads developed and built the horn antenna on the Bell Labs site. The antenna was 15.24 meters long by 6.1 meters wide, weighing in at 16,329 kilograms. It funneled radio waves in or out of the horn shape, and the reflector bounced the waves into a single focused beam—similar to a huge metal megaphone pointing into a curved mirror. Despite its large size, the machine could be precisely aimed.&lt;/p&gt;&lt;p&gt;Unlike other antennas that are tuned to only one frequency, the Holmdel antenna worked across a wide band of frequencies, so it could pick up several types of radio signals. It also could handle radio waves moving in linear or circular paths.&lt;/p&gt;&lt;p&gt;The design accounted for the potential need to eliminate unwanted noise from the environment.&lt;/p&gt;&lt;p&gt;The receiver was placed at the horn’s apex, eliminating the need for a connecting line, which could result in external noise and signal loss.&lt;/p&gt;&lt;p&gt;The antenna allowed Project Echo to complete the first high-quality long-distance voice circuit in 1961 through its namesake’s passive communication satellite, Echo. A similar experiment was successfully completed two years later through the Telstar satellite, according to the proposal for the IEEE Milestone.&lt;/p&gt;&lt;p&gt;In 1964 Penzias and Wilson began using the Holmdel antenna to perform their own radio astronomy experiments.&lt;/p&gt;&lt;head rend="h2"&gt;What’s that buzzing sound?&lt;/head&gt;&lt;p&gt;The duo was trying to map weak radio signals from the Milky Way. They took pains to eliminate external noise from the ground, the environment, and the antenna itself so that their readings would not be affected. They even suppressed interference from the receiver on the antenna by cooling it with liquid helium to -269 °C—only 4 degrees above absolute zero, the theoretical temperature at which all motion stops.&lt;/p&gt;&lt;p&gt;Yet they kept hearing a persistent buzz. It was low, steady, and 100 times more intense than the researchers would expect for interference noise—and it was coming from all directions in space.&lt;/p&gt;&lt;p&gt;Penzias and Wilson redoubled their efforts to eliminate the interference, painstakingly retesting their equipment.&lt;/p&gt;&lt;p&gt;Penzias and Wilson’s evidence for the big bang theory shaped “our understanding of this universe and our place in it.” —Thomas Coughlin, 2024 IEEE president&lt;/p&gt;&lt;p&gt;“They went so far as to take rags and detergents to carefully wash the antenna from the droppings of a pair of pigeons that had nested there,” Leonardo Colletti told IEEE Spectrum in a 2023 article about the discovery. Colletti is a physics professor at the Free University of Bozen-Bolzano, in Italy.&lt;/p&gt;&lt;p&gt;But even after all the duo’s work, the mysterious buzz continued.&lt;/p&gt;&lt;p&gt;After Penzias and Wilson had accounted for everything, including the pigeon poop, they concluded that the radiation they detected could not have come from the Earth, the sun, or anything else in the galaxy.&lt;/p&gt;&lt;p&gt;They later learned that researchers and astrophysicists Robert H. Dicke, P. James Peebles, and David Todd Wilkinson at Princeton University predicted the existence of cosmic microwave background noise, which “they believed would have resulted from the big bang,” according to an entry on the Nokia Bell Labs website.&lt;/p&gt;&lt;p&gt;“As it turned out,” the article says, “the radiation detected by Penzias and Wilson was a perfect match for what the Princeton researchers had predicted.”&lt;/p&gt;&lt;head rend="h2"&gt;Saving the horn antenna&lt;/head&gt;&lt;p&gt;In 1989 the Holmdel antenna was named a national historic landmark. But in 2021 Nokia, which had acquired Bell Labs, sold the 43-acre area to technology entrepreneur Rakesh Antala.&lt;/p&gt;&lt;p&gt;The following year, the Holmdel planning board voted to undertake a study to consider reclassifying the site as an area in need of redevelopment.&lt;/p&gt;&lt;p&gt;[From left] Holmdel Deputy Mayor Kim LaMountain, former Bell Labs researcher Giovanni Vannucci, and 2024 IEEE President Tom Coughlin celebrating the Milestone dedication in front of the Horn Antenna in Holmdel, N.J.Bala Prasanna&lt;/p&gt;&lt;p&gt;That put the landmark at risk of being demolished, IEEE Spectrum reported.&lt;/p&gt;&lt;p&gt;The local community banded together, launching a publicity campaign and an online petition to save the antenna. The township ultimately secured ownership of the horn antenna site following an extensive legal process. Last year it dedicated the site as Dr. Robert Wilson Park, honoring it as the place where “we gained a critical understanding of the birth of our universe.”&lt;/p&gt;&lt;p&gt;A plaque recognizing the IEEE Milestone designation is displayed in the lobby of the AT&amp;amp;T Labs Science and Technology Center in Middletown, N.J., which is about 7 kilometers from Crawford Hill. The plaque reads:&lt;/p&gt;&lt;p&gt;In 1959–1960, NASA and AT&amp;amp;T developed a satellite Earth station in Holmdel, N.J., including a novel tracking horn-reflector antenna, maser preamplifier, and FM demodulator. The Earth station demonstrated the first high-quality long-distance voice circuit via the Echo passive communication satellite in 1960–1961, and via the active Telstar communications satellite in 1962–1963. Experiments conducted in 1964–1965 provided the first indication of the cosmic background radiation associated with the Big Bang.&lt;/p&gt;&lt;p&gt;The IEEE New Jersey Coast Section and the IEEE Photonics Society sponsored the nomination.&lt;/p&gt;Administered by the IEEE History Center and supported by donors, the Milestone program recognizes outstanding technical developments around the world.&lt;p&gt;Julianne Pepitone is a freelance journalist who reports via text, video, and television. She spent years on staff at CNN Business and then at NBC News, covering consumer tech, cybersecurity, and business. Now a freelancer, she works with an eclectic roster of clients. Beyond Spectrum, CNN, and NBC, her bylines can also be found at HGTV Magazine, Memorial Sloan Kettering, NYMag.com, Glassdoor, Popular Mechanics, Cosmopolitan, Town &amp;amp; Country, Thrillist, MagnifyMoney, The Village Voice, and more.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45391568</guid><pubDate>Fri, 26 Sep 2025 22:17:18 +0000</pubDate></item></channel></rss>