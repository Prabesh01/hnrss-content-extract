<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 31 Oct 2025 11:09:03 +0000</lastBuildDate><item><title>Springs and bounces in native CSS</title><link>https://www.joshwcomeau.com/animation/linear-timing-function/</link><description>&lt;doc fingerprint="1e4bf9532b3d2b93"&gt;
  &lt;main&gt;
    &lt;p&gt;When creating animations, we can decide how to transition between states using a timing function. Historically, we‚Äôve used B√©zier curves for this, which provide us with a range of different options:&lt;/p&gt;
    &lt;p&gt;ease-in&lt;/p&gt;
    &lt;p&gt;ease-in-out&lt;/p&gt;
    &lt;p&gt;ease&lt;/p&gt;
    &lt;p&gt;In this demo, each of these circles moves from side to side over the same duration, but they‚Äôre interpolated very differently. This can dramatically change how the animation feels.&lt;/p&gt;
    &lt;p&gt;B√©zier curves are great, but there are certain things they just can‚Äôt do. For example:&lt;/p&gt;
    &lt;p&gt;spring&lt;/p&gt;
    &lt;p&gt;bounce&lt;/p&gt;
    &lt;p&gt;In the past, we‚Äôve needed to rely on JavaScript libraries to provide these sorts of interpolations, which introduces a whole bunch of trade-offs; most JavaScript animations run on the main thread, for example, which means they won‚Äôt run smoothly if other stuff is happening in our application!&lt;/p&gt;
    &lt;p&gt;Fortunately, modern CSS has provided us a new tool that enables us to create springs, bounces, and so much more all in native CSS: the &lt;code&gt;linear()&lt;/code&gt; timing function. In this blog post, I‚Äôll show you how it works, and share some tools you can use to get started right away!&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingThe linear() function&lt;/head&gt;
    &lt;p&gt;The core idea here is surprisingly simple: instead of using mathematically-derived B√©zier curves, we can instead draw the easing curve we want, by specifying a set of individual points on a cartesian plane.&lt;/p&gt;
    &lt;p&gt;For example, this graph approximates an ‚Äúease‚Äù curve using 11 points:&lt;/p&gt;
    &lt;p&gt;This looks like a curve, but if you look closely, you‚Äôll notice that it‚Äôs actually a bunch of straight line segments. It‚Äôs like those ‚Äúconnect the dots‚Äù drawings, where a shape emerges from a bunch of straight lines.&lt;/p&gt;
    &lt;p&gt;This is why they named it ‚Äúlinear()‚Äù. Unlike B√©zier curves, which are actual mathematical curves, the &lt;code&gt;linear()&lt;/code&gt; function only draws straight lines between a set of provided points.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what the actual CSS looks like for the &lt;code&gt;linear()&lt;/code&gt; animation graphed above:&lt;/p&gt;
    &lt;code&gt;.block {
  transition:
    transform 500ms linear(0, 0.1, 0.25, 0.5, 0.68, 0.8, 0.88, 0.94, 0.98, 0.995, 1);
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;linear()&lt;/code&gt; function takes a set of numbers, with 0 representing the starting value and 1 representing the final value. We can think of this as a ratio of the transition progress. We can pass as many numbers as we want, and they‚Äôll all be evenly-spaced across the specified duration.&lt;/p&gt;
    &lt;p&gt;We can use &lt;code&gt;linear()&lt;/code&gt; to emulate spring physics, capturing the data from a real modeled spring. Let‚Äôs suppose we‚Äôre trying to recreate this springy motion:&lt;/p&gt;
    &lt;p&gt;Just for fun, I did my best to trace that springy shape by hand, guesstimating 11 values based on that graph. Here‚Äôs what that looks like:&lt;/p&gt;
    &lt;p&gt;Yikes. This does not feel great. üòÇ&lt;/p&gt;
    &lt;p&gt;We‚Äôll look at how to make it better, but first, here‚Äôs the code for this not-great animation:&lt;/p&gt;
    &lt;code&gt;linear(0, 1.25, 1, 0.9, 1.04, 0.99, 1.005, 0.996, 1.001, 0.999, 1);&lt;/code&gt;
    &lt;p&gt;Like with B√©zier curves, the &lt;code&gt;linear()&lt;/code&gt; function allows us to pick values outside the 0 to 1 range, to overshoot the target like springs do. So that second value, &lt;code&gt;1.25&lt;/code&gt;, means that we‚Äôve overshot the target location by 25%.&lt;/p&gt;
    &lt;p&gt;The problem is that 11 values are just not enough to faithfully reproduce a springy value like this. The element is clearly moving robotically between discrete points rather than smoothly oscillating like a spring.&lt;/p&gt;
    &lt;p&gt;But if we crank up the number of points, the simulation becomes much more believable. I wrote some code to calculate the values for 50 points, and here‚Äôs the result:&lt;/p&gt;
    &lt;p&gt;Much more convincing, right?&lt;/p&gt;
    &lt;p&gt;As you can tell from my failed experiment above, we aren‚Äôt really meant to write these &lt;code&gt;linear()&lt;/code&gt; datasets by hand. Instead, we should use tools that dynamically calculate them for us.&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this headingDynamically generating linear() values&lt;/head&gt;
    &lt;p&gt;The best tool I‚Äôve seen is Linear() Easing Generator(opens in new tab), by Jake Archibald and Adam Argyle. It comes pre-loaded with all of the math required to convert spring parameters into a highly-optimized &lt;code&gt;linear()&lt;/code&gt; string, and if you have another JS-based timing function, you can easily edit the code to use that instead!&lt;/p&gt;
    &lt;p&gt;There‚Äôs also Easing Wizard(opens in new tab), which is the most comprehensive and nicely-designed tool I‚Äôve found. It uses &lt;code&gt;linear()&lt;/code&gt; to model springs, bounces, wiggles, and more, and provides a bunch of tools to test out your timing functions.&lt;/p&gt;
    &lt;p&gt;Both of these tools take advantage of a more-advanced syntax for the &lt;code&gt;linear()&lt;/code&gt; timing function. In addition to the progress ratio, certain points also have a time percentage:&lt;/p&gt;
    &lt;code&gt;/* Example output from tool-generated linear() values: */
.thing {
  transition: transform 1500ms linear(
    0,
    0.013 0.6%,
    0.05 1.2%,
    0.2 2.5%,
    /* ‚úÇÔ∏è Buncha points omitted */
    0.971 47.2%,
    1.012 59.1%,
    0.995 70.8%,
    1
  );
}&lt;/code&gt;
    &lt;p&gt;Like before, we have a list of progress ratios from 0 to 1 (or beyond, for overshooting). Most of these points also have a second value, a percentage. This controls where each point is placed in time. So, rather than having a bunch of evenly-spaced values, we can position them strategically, to achieve the same curve with a smaller # of points.&lt;/p&gt;
    &lt;p&gt;For example, we can model that same spring with only 25 points, instead of 50:&lt;/p&gt;
    &lt;p&gt;Honestly, I‚Äôm not sure that this is really much of a savings in terms of kilobytes; we use a smaller # of points, but each point requires two pieces of information instead of just one. Either way, both of the recommended tools use this syntax, so presumably they‚Äôve found that it‚Äôs beneficial!&lt;/p&gt;
    &lt;p&gt;We‚Äôll talk more about the performance implications shortly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingLimitations&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;linear()&lt;/code&gt; function is a lovely API that greatly expands what we can do in vanilla CSS, but like everything, there are some tradeoffs and limitations worth considering.&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this heading1. It‚Äôs still time-based&lt;/head&gt;
    &lt;p&gt;When using JavaScript libraries that implement physics-based animations like springs or bounces, we don‚Äôt specify an animation duration. Instead, we configure our animation using physical properties like stiffness, damping, and mass. The animation takes however long it takes based on the physics.&lt;/p&gt;
    &lt;p&gt;That‚Äôs not how CSS transitions work, though. CSS transitions require a duration:&lt;/p&gt;
    &lt;code&gt;.elem {
  transition: transform linear(...) 1200ms;
}&lt;/code&gt;
    &lt;p&gt;The Linear() Easing Generator tool(opens in new tab) solves this by dynamically deriving a duration based on the provided spring settings. The duration is calculated based on how much time is necessary until the spring settles down and stops moving.&lt;/p&gt;
    &lt;p&gt;This works in most cases, but it means we can‚Äôt model a zero-friction spring. When we set ‚Äúdamping‚Äù to &lt;code&gt;0&lt;/code&gt;, the spring should oscillate forever, but there‚Äôs no such thing as an infinite-duration transition.&lt;/p&gt;
    &lt;p&gt;Easing Wizard(opens in new tab) works a bit differently: ‚Äúduration‚Äù is a user-configurable parameter, and it doesn‚Äôt recalculate as we adjust the spring settings. To make this work, Easing Wizard fudges the numbers a bit. Certain parameters are internally clamped, so that they won‚Äôt produce impossible curves.&lt;/p&gt;
    &lt;p&gt;For example, with low mass/stiffness, damping has little to no effect, which is definitely not how it should work. üòÖ&lt;/p&gt;
    &lt;p&gt;I prefer the solution that Jake/Adam came up with for Linear() Easing Generator, but really, there is no perfect solution here. Springs aren‚Äôt meant to be time-based, so it feels a bit like trying to come up with the best way to stuff a square peg into a round hole. It‚Äôs an awkward way to think about physics-based animation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this heading2. Interrupts&lt;/head&gt;
    &lt;p&gt;One of the hardest problems in web animation is dealing with interrupts. The web is a dynamic place, and there‚Äôs no guarantee that an element will be allowed to complete its transition. Sometimes, it‚Äôll be updated halfway through. What should happen in that case?&lt;/p&gt;
    &lt;p&gt;Well, let‚Äôs give it a shot. This demo implements the same basic transition using the &lt;code&gt;linear()&lt;/code&gt; function as well as React Spring, a library based around JavaScript spring physics. Click the button quickly, to interrupt the transition:&lt;/p&gt;
    &lt;p&gt;If you click the button twice, very quickly, you should see something like this:&lt;/p&gt;
    &lt;p&gt;(If you‚Äôre not able to click that quickly, you can also focus the button and press "Enter" twice.)&lt;/p&gt;
    &lt;p&gt;When both animations run without interruption, they appear nearly identical. But if we trigger the button again mid-transition, they behave very differently.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs the fundamental difference: the version using React Spring takes the element‚Äôs current inertia into account. It takes a moment to slow down, before swinging back in the opposite direction. The CSS version, by contrast, turns around instantly, as though it hit a wall.&lt;/p&gt;
    &lt;p&gt;And the CSS version‚Äôs behaviour feels unnatural. This spring is meant to be pretty loose and smooth, but on that rebound transition, it feels tight and quick. ü§î&lt;/p&gt;
    &lt;p&gt;The reason this happens is a bit complicated, and too much of a rabbit hole to get into here. To summarize at a high level, CSS transitions have special logic(opens in new tab) for handling interrupts. There‚Äôs a concept in the specification called the reversing shortening factor that proportionally reduces the duration of interrupted transitions. So, a spring intended to take 1600ms might re-run at only 400ms. This looks fine with B√©zier curves, but we‚Äôre trying to emulate physics here, and we can‚Äôt just speed it up and expect it to feel natural.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a bit like taking a recording of someone walking at a leisurely pace, speeding it up by 2x, and trying to pass it off as someone jogging. The speed might be correct, but it sure as heck won‚Äôt look natural!&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this heading3. Performance&lt;/head&gt;
    &lt;p&gt;In order to convincingly simulate a spring using &lt;code&gt;linear()&lt;/code&gt;, we need lots of data points. It‚Äôs not uncommon for my springs to have 40+ data points!&lt;/p&gt;
    &lt;p&gt;It feels like this could have a significant impact on performance, but I wasn‚Äôt sure. And whenever I‚Äôm not sure about something like this, I try to figure it out with some testing.&lt;/p&gt;
    &lt;p&gt;I had two main concerns:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Is the framerate affected by complex&lt;code&gt;linear()&lt;/code&gt;values?&lt;/item&gt;
      &lt;item&gt;Does it balloon the size of my CSS bundles?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The first concern was easy to test. I created a basic animation and tested two different &lt;code&gt;linear()&lt;/code&gt; strings. The first string was the simplest possible value, &lt;code&gt;linear(0, 1)&lt;/code&gt;. The second string had &amp;gt;100 values.&lt;/p&gt;
    &lt;p&gt;Both animations ran equally smoothly, even on low-end hardware. I could not detect even a small difference between the two approaches. üëç&lt;/p&gt;
    &lt;p&gt;For the second concern, I created 3 maximum-accuracy springs with Easing Wizard, with an average of 75 values each, and added them to the CSS for my course platform. It‚Äôs important to test things like this in the context of a real application.&lt;/p&gt;
    &lt;p&gt;Here are the resulting file sizes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;By default, my CSS bundle is 63.3kB, which compresses to 10.2kB with gzip.&lt;/item&gt;
      &lt;item&gt;With these extra springs, my CSS bundle grew to 67.1kB, which compresses to 11.5kB with gzip.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, in this particular context, these 3 very-large springs added ~1.3kB to my CSS bundle.&lt;/p&gt;
    &lt;p&gt;To put that number in context: on a typical 3G connection (2mb/s), it will take 5ms (0.005 seconds) to download this extra chunk of CSS. It will also add some processing time on the device, but we‚Äôre still talking about a completely imperceptible amount of time.&lt;/p&gt;
    &lt;p&gt;Now, this assumes we only have 3 &lt;code&gt;linear()&lt;/code&gt; chunks in the entire bundle. If you copy/paste this large string for every animation, you could wind up with dozens of copies, so it‚Äôs a good idea to use CSS variables to reuse the same &lt;code&gt;linear()&lt;/code&gt; timing function in multiple places. Let‚Äôs talk about how to do that!&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingUsing &lt;code&gt;linear()&lt;/code&gt; effectively&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;linear()&lt;/code&gt; strings tend to be big and unwieldy. In addition to the potential performance concerns, it‚Äôs also just kind of annoying to work with them!&lt;/p&gt;
    &lt;p&gt;Rather than sprinkle &lt;code&gt;linear()&lt;/code&gt; values across the codebase, I recommend storing a handful of common timing functions in globally-available CSS variables. If you already have a system for design tokens, I think it‚Äôs a great idea to extend it with some &lt;code&gt;linear()&lt;/code&gt; timing functions!&lt;/p&gt;
    &lt;p&gt;We also need to consider browser support. As I mentioned earlier, &lt;code&gt;linear()&lt;/code&gt; is a somewhat-new feature, and isn‚Äôt available in all browsers.&lt;/p&gt;
    &lt;p&gt;Over the past few months, I‚Äôve been experimenting with how to use these timing functions effectively. Here‚Äôs the pattern I‚Äôve landed on:&lt;/p&gt;
    &lt;code&gt;html {
  --spring-smooth: cubic-bezier(...);
  --spring-smooth-time: 1000ms;

  @supports (animation-timing-function: linear(0, 1)) {
    /* stiffness: 235, damping: 10 */
    /* prettier-ignore */
    --spring-smooth: linear(...);
  }
}

/* Then, to use this timing function: */
@media (prefers-reduced-motion: no-preference) {
  .thing {
    transition:
      transform var(--spring-smooth) var(--spring-smooth-time);
  }
}&lt;/code&gt;
    &lt;p&gt;If the user is using an older browser which doesn't support &lt;code&gt;linear()&lt;/code&gt;, we‚Äôll provide a fallback transition using B√©zier curves. You can use Easing Wizard(opens in new tab) to come up with something that still feels alright (we can kinda mimic springs using B√©zier curves by overshooting the target; it doesn‚Äôt look anywhere near as smooth, but it‚Äôs a decent fallback option).&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;@supports&lt;/code&gt; at-rule allows us to specify extra CSS in supported browsers. So, we overwrite &lt;code&gt;--spring-smooth&lt;/code&gt; with the actual &lt;code&gt;linear()&lt;/code&gt; value. I also like to record the stiffness/damping for springs in a comment, so that if I want to adjust the spring settings in the future, I remember how to reconstruct this &lt;code&gt;linear()&lt;/code&gt; string. And finally, I add &lt;code&gt;prettier-ignore&lt;/code&gt; to stop the Prettier formatter from putting each point on its own line, and turning this 1-line declaration into a 50-line list of numbers.&lt;/p&gt;
    &lt;p&gt;We can then use the &lt;code&gt;--spring-smooth&lt;/code&gt; and &lt;code&gt;--spring-smooth-time&lt;/code&gt; variables wherever we typically apply transitions or keyframe animations. Like with all animations, we should make sure to respect user motion preferences. I write more about the ‚Äúprefers-reduced-motion‚Äù media query in my blog post, Accessible Animations in React (this post is mainly for React devs, but the first half of the post should still be useful for all web developers!).&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingGoing deeper&lt;/head&gt;
    &lt;p&gt;For the past year, I‚Äôve been working on the ultimate animations course. ‚ú®&lt;/p&gt;
    &lt;p&gt;In this course, we use modern CSS features like &lt;code&gt;linear()&lt;/code&gt; alongside JavaScript, SVG, and Canvas to create top-tier whimsical animations and interactions. I share all of the tips and tricks I‚Äôve learned after nearly two decades of experience.&lt;/p&gt;
    &lt;p&gt;I‚Äôm hoping to release this course in the first half of 2026. You can learn more and sign up here:&lt;/p&gt;
    &lt;head rend="h3"&gt;Last updated on&lt;/head&gt;
    &lt;p&gt;October 28th, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45736461</guid><pubDate>Tue, 28 Oct 2025 18:01:46 +0000</pubDate></item><item><title>Jack Kerouac, Malcolm Cowley, and the difficult birth of On the Road</title><link>https://theamericanscholar.org/scrolling-through/</link><description>&lt;doc fingerprint="a578d3d53a272eba"&gt;
  &lt;main&gt;
    &lt;p&gt;No American novel of consequence has had a more tortuous or mythologized path to publication than On the Road. Jack Kerouac supposedly composed it in a days-long bout of frenzied typing, feeding a continuous scroll of paper into his typewriter to avoid breaking the flow of inspiration. Yet as Kerouac scholar Isaac Gewirtz has written, this is accurate but not true. The myth of the novel‚Äôs composition neglects the larger context of its long gestation and even longer struggle to reach print.&lt;/p&gt;
    &lt;p&gt;The accurate part is this: On April 2, 1951, Kerouac sat down in his then-wife Joan Haverty‚Äôs apartment in Manhattan and began banging out his first draft. He had on hand several rolls of drafting paper of just the right size for his Remington manual. He‚Äôd made the discovery, he told her, that they would ‚Äúsave me the trouble of putting in new paper, and it just about guarantees spontaneity.‚Äù For 20 days straight, Kerouac typed so furiously that his T-shirts became soaked with sweat. By April 22, he had completed a 125,000-word draft typed in an eye-straining, comma-starved, single-spaced format, with no paragraphs or page breaks. The resulting scroll was 120 feet long. As an object to be read, it was utterly impractical, but Kerouac had unintentionally replicated the format of the books of antiquity before the invention of the codex. In transcribing his peripatetic cross-country adventures, Kerouac brilliantly married the method to the matter: he wrote fast because, as he put it in one of his notebooks, the ‚Äúroad is fast.‚Äù Movement and speed were of the essence. On the Road reads like a pilgrimage without a shrine at the end, an Odyssey without an Ithaca. All the subsequent talk, though, about ‚Äúspontaneous bop prosody‚Äù obscures the fact that the book took years to write and then underwent an even longer process of revision.&lt;/p&gt;
    &lt;p&gt;The true part is this: On August 23, 1948, Kerouac wrote in his notebook that he had ‚Äúanother novel in mind‚Äî‚ÄòOn the Road‚Äô‚Äîwhich I keep thinking about: about two guys hitch-hiking to California in search of something they don‚Äôt really find, and losing themselves on the road, and coming all the way back hopeful of something else.‚Äù At the time, he was finishing the final chapters of The Town and the City, an autobiographical novel about the life of his French-Canadian family. The completed manuscript would be acquired the following year by Robert Giroux, a Maxwell Perkins‚Äìgrade editor at Harcourt, Brace who worked with T. S. Eliot and many other notables. He and Kerouac enjoyed a close and warm working relationship, spending months editing and revising the plus-size manuscript while Kerouac occupied an empty office at Harcourt for weeks at a time.&lt;/p&gt;
    &lt;p&gt;A few years older than Kerouac, Giroux had graduated from Columbia in 1936. Kerouac had gone there, too, on a football scholarship, but dropped out in 1942. After stints in the merchant marine and the U.S. Navy Reserve, he‚Äôd returned to New York and begun to associate with a colorful circle of aspiring young writers, petty thieves, drug addicts, and unclassifiable reprobates. Together, they would become known as the Beats, chief among them Allen Ginsberg, William S. Burroughs, Lucien Carr, Herbert Huncke, Hal Chase, and John Clellon Holmes. It was Huncke, a heroin-addicted adept of the lower depths, who first introduced the group to the notion of being ‚Äúbeat,‚Äù as in defeated by the harsh conditions of life. It was Kerouac who would apply the word in its uppercase form to this nascent literary movement and subsequently expand the concept to encompass the idea of ‚Äúbeatific,‚Äù asserting that the Beats were on a religiously inspired vision quest.&lt;/p&gt;
    &lt;p&gt;Cultural critics have interpreted the Beat movement as a response to the grim postwar atmosphere created by the atomic bomb, the discovery of the death camps, and the advent of the Cold War, and later as a revolt against the ‚Äô50s regime of social conformity. In the ‚Äô40s, though, the early Beats were simply a bunch of guys, albeit three of them geniuses, with simpatico literary interests who got off on their rash and aimless adventures together. They were familiar scuffling artistic types who would have fit easily into the Parisian world of La Vie Boh√®me, but some of them were seriously bent in a way that would make any d√©tente with bourgeois existence impossible. Their milieu was an unusual one in which the criminals really wanted to be writers and the writers really wanted to emulate the criminals.&lt;/p&gt;
    &lt;p&gt;Among them was Neal Cassady, a muscular, wired, fearless, reckless cowboy-like figure out of the American West. He was also a charismatic sociopath, a motor-mouthed car thief, and a con man whose charm was exceeded only by his amorality. Born in 1926, quite literally on the side of the road, Cassady had been carelessly cared for by his alcoholic father, growing up in flophouses and fleabag hotels and doing stints in reformatories in the Denver area. By his late teens, he was reputed to have stolen hundreds of cars, and he could drive them the way Chuck Yeager could fly a fighter jet, all the while unspooling an endless monologue on whatever subjects his perpetually firing neurons lighted on. Free of any formal education after grammar school, he had spent many hours in Denver libraries reading promiscuously and would drop the names of Nietzsche, Schopenhauer, and Proust into his spiel for effect. Of all the unlikely things, he wanted to be a writer.&lt;/p&gt;
    &lt;p&gt;In 1946, Cassady drove a stolen car to New York City with his teenage bride, the overripe LuAnne Henderson, to meet the members of the Morningside Heights crowd, whom he had heard about from a friend in common. Kerouac first encountered Cassady that December in the newcomer‚Äôs cold-water flat in Spanish Harlem. Characteristically, Cassady answered the door in the nude. Thus began a literary bromance to rival those of the fictional Natty Bumppo and Chingachook or Huck Finn and Jim. Over the next five years, Kerouac ricocheted across the continent several times by bus, train, thumb, and car, usually with Cassady at the wheel, since Kerouac, ironically enough, never procured a driver‚Äôs license. It was these trips that provided Kerouac with the raw material of On the Road, and it was Cassady, fictionalized as Dean Moriarty in the novel, who gave him the energy and artistic courage to realize his lyrical and ecstatic vision of American life.&lt;/p&gt;
    &lt;p&gt;In his 2007 book, Beatific Soul: Jack Kerouac on the Road, Gewirtz traced Kerouac‚Äôs evolving conception of the novel from the surviving false starts, partial drafts, proto-versions, and notebooks. In the four years between his first embryonic notion for the book to the day he started to type the scroll, Kerouac struggled to find the right authorial voice. Style was a considerable problem. ‚ÄúI find that I want a different structure as well as a different style in this work,‚Äù Kerouac wrote in his notebook, ‚Äúeach chapter as a line of verse in the general epic poem.‚Äù He would find a good part of the solution in emulating the jazz innovators of bebop, especially the improvisational geniuses Charlie Parker and Dizzy Gillespie. ‚ÄúI wish to evoke that indescribable sad music of the night in America‚Äîfor reasons that are never deeper than the music,‚Äù he continued. ‚ÄúBop only begins to express that American music. It is the actual inner sound of the country.‚Äù&lt;/p&gt;
    &lt;p&gt;When Kerouac began typing his first full draft, whatever spontaneous bop prosody he practiced was undergirded not simply by years of contemplation and trial runs but by detailed notes. The road to finally writing On the Road had been carefully mapped out. A significant amount of the scroll edition was copied, either verbatim or close to it, from the notebooks and from the earlier partial drafts of the novel. Kerouac had also executed a tremendously detailed ‚Äúcharacter chronology‚Äù spanning 1946 to 1951, as well as chapter outlines. Despite the myth of his novel‚Äôs sweat-soaked, 28-day birth, Kerouac‚Äôs preparations indicate that he was a highly ordered and self-conscious literary artist. Contra Truman Capote‚Äôs vicious quip, this wasn‚Äôt typing, it was writing.&lt;/p&gt;
    &lt;p&gt;Soon after finishing the scroll, Kerouac went to Giroux‚Äôs office to show him the book, elated and exhausted by what he had achieved. ‚ÄúHe was in a very funny, excited state,‚Äù Giroux recalled. Kerouac unfurled the scroll right across the office ‚Äúlike a piece of celebration confetti.‚Äù Startled by the yards of typescript on his floor, Giroux said the worst possible thing: ‚ÄúBut Jack, how are we ever going to edit this?‚Äù He really meant: How could the words on the unwieldy scroll ever make their way to a typesetter and printer? But Kerouac took it the wrong way and fell into a rage. ‚ÄúThis book has been dictated by the Holy Ghost!‚Äù he yelled. ‚ÄúThere will be no editing!‚Äù He rolled the scroll back up and stormed out of the office.&lt;/p&gt;
    &lt;p&gt;So began another odyssey, the years-long travels of On the Road around New York in search of a publisher. Kerouac quickly retyped the novel as regular typescript that could be submitted to publishers. It made the rounds at Harcourt; Little, Brown; E. P. Dutton; Dodd, Mead; the paperback publisher Ace Books; and the Viking Press, none of which reacted with enthusiasm. A rejection from a Knopf editor was probably typical: ‚ÄúThis is a badly misdirected talent. ‚Ä¶ This huge sprawling and inconclusive novel would probably have small sales and sardonic indignant reviews from every side.‚Äù&lt;/p&gt;
    &lt;p&gt;Enter literary critic Malcolm Cowley, a consulting editor at Viking. On July 3, 1953, Allen Ginsberg, acting as Kerouac‚Äôs agent, wrote to Cowley on his friend‚Äôs behalf. ‚ÄúI am interested in Kerouac and his work,‚Äù Cowley responded. ‚ÄúHe seems to me the most interesting writer who is not being published today.‚Äù Cowley had already read not only On the Road but also Doctor Sax, Kerouac‚Äôs novel of his Lowell, Massachusetts, boyhood, and what Cowley described as ‚Äúa second version‚Äù of On the Road, probably an early draft of Visions of Cody, published after Kerouac‚Äôs death. He believed that only ‚Äúthe first version of On the Road‚Äù had a chance of publication by Viking. He invited Ginsberg to visit him at the Viking offices.&lt;/p&gt;
    &lt;p&gt;Viking was not a welcoming port for young Turks: The average age of the five editorial principals‚ÄîCowley, Pascal Covici, Ben Huebsch, Marshall Best, and the founder, Harold Guinzburg‚Äîwas in the 60s. The aimless adventures of a tribe of luftmenschen would have struck four of them as outr√© and Kerouac‚Äôs breathless style as undisciplined. Moreover, On the Road reeked of potential legal trouble. The original draft was sexually explicit for the time, and some of that sex was homosexual. There was a vivid description in the original version of Cassady giving a traveling salesman a ‚Äúmonstrous huge banging‚Äù in a hotel room while Kerouac watches from the bathroom. Censors were still eager to prosecute books that offended. In the decade before, Edmund Wilson‚Äôs far tamer novel, Memoirs of Hecate County, had been banned as the result of a complaint lodged by the New York Society for the Suppression of Vice. Worse, the U.S. Supreme Court had upheld the ban on appeal. And even as Kerouac was seeking a publisher for On the Road, another hot-potato novel, Vladimir Nabokov‚Äôs Lolita, was collecting a long list of emphatic rejections, including one from Viking.&lt;/p&gt;
    &lt;p&gt;The potential for On the Road to attract libel suits held even greater risks. The original version used the characters‚Äô real names and included numerous instances of drug addiction, grand theft auto, bigamy, grand larceny, and even a borderline case of statutory rape. Viking could not have known at the time that the people Kerouac wrote about would have been more likely to sue if they‚Äôd been portrayed as responsible, law-abiding citizens. A run of bad legal luck might hobble and even sink a privately held firm like Viking.&lt;/p&gt;
    &lt;p&gt;Cowley nevertheless made a vigorous and dogged case for the book. What was it about On the Road that moved him to undertake a years-long campaign to persuade his nervous employer to set aside its reservations and publish it?&lt;/p&gt;
    &lt;p&gt;At the most basic level, he must have enjoyed reading it. Cowley liked the book‚Äôs prose style and was attracted by what Kerouac himself described as ‚Äúthe raciness and freedom and humor of jazz instead of all that dreary analysis and things like ‚ÄòJames entered the room and lit a cigarette. He thought Jane might have thought this too vague a gesture.‚Äô ‚Äù Indeed, ‚Äúdreary analysis‚Äù was precisely the quality that Cowley disliked about so much of the work of the postwar writers. At bottom, though, Cowley supported the novel because it allowed him to engage his generational sense of the progress of American literature. Proof of this can be found in the first paragraph of the catalog copy that he later wrote for On the Road:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;After World War I a certain group of restless, searching Americans came to be called ‚ÄúThe Lost Generation.‚Äù This group found its truest voice in the writings of the young Hemingway. For a good many of the same reasons after World War II another group, roaming America in a wild, desperate search for identity and purpose, became known as ‚Äúthe Beat Generation.‚Äù Jack Kerouac is the voice of this group, and this is his novel.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But Kerouac wasn‚Äôt the first voice. Even in 1953, the Beat Generation had become a visible thing, and much of the credit for that must be given to John Clellon Holmes. Of all the original core members of the Beats, Holmes was the one we would today call the adult in the room. Although he participated in the Beat revels of dissipation, he held himself at a distance and took cool note of their costs and casualties, terming them ‚Äúfutility rites.‚Äù Kerouac coined the phrase ‚ÄúBeat Generation‚Äù while crashing at Holmes‚Äôs Lexington Avenue apartment. The words appeared in print for the first time in Holmes‚Äôs 1952 roman √† clef, Go, the first novel of the Beat scene. Go, while full of eye-opening behavior, had none of the breakthrough energy of On the Road and generated little attention. But then an editor at the New York Times Magazine, Gilbert Millstein, asked Holmes to write what would become a famous essay exploring the temper of his anxious cohort. ‚ÄúThis Is the Beat Generation‚Äù was the subject of puzzled Sunday breakfast discussions across the land, and the Beats entered the national conversation.&lt;/p&gt;
    &lt;p&gt;Cowley certainly would have been aware of Holmes‚Äôs essay. The generational shift it illustrated would be a strong selling point for On the Road, but first he had to persuade Viking to publish it‚Äîan effort that ultimately took four years and involved pulling every string available to him as a literary insider. His was a two-pronged strategy: to win Viking over, he first would have to change the climate of literary opinion in the outside world. To accomplish this, he sought to have On the Road serialized in places where it, and Kerouac, would be noticed. In late 1953, he wrote to Arabel Porter, the editor of the influential mass-market literary magazine New World Writing, about ‚Äúa very long autobiographical novel by John [sic] Kerouac, called On the Road (or alternatively Heroes of the Hip Generation). It‚Äôs about the present generation of wild boys on their wild travels between New York, San Francisco, and Mexico City. ‚Ä¶ Of all that beat generation crowd, Kerouac is the only one who can write, and about the only one who doesn‚Äôt get published.‚Äù In April 1955, Porter‚Äôs magazine published an account of a frantic jam session titled ‚ÄúJazz of the Beat Generation.‚Äù Cowley‚Äôs purpose, though, was blunted by Kerouac‚Äôs insistence that the piece be attributed to ‚ÄúJean-Louis,‚Äù because he was worried that his ex-wife would confiscate his fee for child support if his real name appeared.&lt;/p&gt;
    &lt;p&gt;Next Cowley did what only he among all book editors could have done: write a public endorsement of Kerouac that would be noticed. In the final chapter of his 1954 book, The Literary Situation, he assessed the ‚Äúindividual and nihilistic‚Äù rebellion of ‚Äúthe beat generation‚Äù and then wrote, ‚ÄúIt was John Kerouac who invented [that] phrase, and his unpublished long narrative, On the Road, is the best record of their lives.‚Äù It takes a special brand of self-confidence to question the judgment of one‚Äôs employer in a book published by that employer.&lt;/p&gt;
    &lt;p&gt;The following year, 1955, he persuaded Peter Matthiessen, then the fiction editor of a lively new literary magazine called The Paris Review, to accept an excerpt titled ‚ÄúThe Mexican Girl,‚Äù about a romantic idyll Kerouac had with a migrant farm worker. He also cajoled the American Academy and Institute to fork over $200 to Kerouac from its Artists‚Äô and Writers‚Äô Revolving Fund for those in urgent financial need. The serializations‚Äîwhich later included ‚ÄúA Billowy Trip in the World,‚Äù published in New Directions in Prose and Poetry in July 1957‚Äîand news of the grant had an effect. One editor, even one as eminent as Cowley, who stood up for a book might have been overruled, but when editors elsewhere started signing on, Viking took notice.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Cowley did his best to keep Kerouac‚Äôs spirits up. He gave the writer regular shots of good news about the serializations and the grant. The amount of money was modest but desperately needed, since Kerouac‚Äôs painful phlebitis required penicillin treatments he could ill afford. Kerouac‚Äôs torments were multiplied by rejections of his other typescripts that were making the rounds of publishers, including Viking. A stark entry in the chronology at the front of the Viking Critical Edition of On the Road tells the painful tale: ‚Äú1951‚Äì1957: Writes twelve books, publishes none.‚Äù These books included the novels Doctor Sax, Maggie Cassidy, Tristessa, Visions of Gerard, The Dharma Bums, and Visions of Cody, all of which would eventually be published, but only after On the Road created a market for them. Worse yet, it fell to Cowley to decline this new work, further demoralizing Kerouac. He had to; to go to bat for another, lesser novel by Kerouac while maneuvering to publish a book he had so publicly praised would have muddied the waters. Besides that, Cowley did not really connect with Kerouac‚Äôs other novels. He turned them down with blunt comments on their deficiencies.&lt;/p&gt;
    &lt;p&gt;Kerouac fell into despair. ‚ÄúI think the time has come for me to pull my manuscripts back,‚Äù he wrote to his agent, Sterling Lord, in January 1955, declaring that ‚Äúpublishing to me ‚Ä¶ is like a threat over my head, I know I‚Äôll write better when that whole arbitrary mess is lifted out of my thoughts.‚Äù He quickly changed his mind, though. Perhaps the most poignant expression of his mood came in 1956, when he told Lord that he‚Äôd ‚Äúbeen through every conceivable disgrace now and no rejection or acceptance by publishers can alter that awful final feeling of death‚Äîof life-which-is-death.‚Äù He instructed his agent to pull Beat Generation, as it was then being called, back from Cowley. Luckily, that didn‚Äôt happen.&lt;/p&gt;
    &lt;p&gt;By this time, Cowley had made considerable progress with Viking by garnering the support of some younger staffers in reaching a new consensus. But the real reason for the changing climate at Viking was the arrival of Thomas Guinzburg, the son of the founder and the firm‚Äôs heir apparent. He would remember that ‚Äúwhen I got there, I helped to get that one [On the Road] published because I was at the right age to, and my father was perhaps more tolerant or perhaps respected my conviction that it was a book that was worth it.‚Äù&lt;/p&gt;
    &lt;p&gt;In September 1955, Cowley wrote Kerouac one of the most hedged-about ‚Äúacceptance‚Äù letters in publishing history:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;On the Road ‚Ä¶ is now being seriously considered, or reconsidered, by Viking, and there is quite a good chance that we will publish it, depending on three ifs: if we can figure out what the right changes will be (cuts and rearrangements); if we can be sure that the book won‚Äôt be suppressed for immorality; and if it won‚Äôt get us into libel suits.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Kerouac assured Cowley that he had already changed the actual names of the characters and obscured any identifying details. In regard to editing, he reconsidered his stance of Pentecostal inviolability. On the immorality question, he was flippant: ‚ÄúWhat can I say, the true story of the world is a French movie. You know, I know.‚Äù But he would cooperate. The word ‚Äúacceptance‚Äù above is in quotes for a reason. In most cases, a publisher that has decided to publish a book will have agreed on an advance and other terms with the author or agent beforehand and drafted a contract. None of these formalities were discussed in this instance, let alone executed. The obligation to clear the hurdles represented by those ifs fell to Kerouac alone. He had merely moved from an authorial purgatory of waiting into a legal limbo.&lt;/p&gt;
    &lt;p&gt;The first two ifs were dealt with in a reasonably painless if leisurely fashion. For the sake of narrative economy, Cowley compressed Kerouac‚Äôs account of his second and third cross-country trips into one. He likewise toned down the sex scenes to the point where it sometimes becomes hard to know whether the characters are wrestling or copulating. All homosexual material was removed. The vetting process for libel, however, was more prolonged and painful. Any editor or author who has gone through a libel reading knows that it is a nerve-shredding exercise. On the Road was full of legal landmines, so the manuscript was sent to Viking‚Äôs outside counsel, Nathaniel Whitehorn, for forensic examination. His report came back on November 1, 1955, in the form of a nine-page memo with a page-and-a-half cover letter identifying hazards large and small and suggesting changes and excisions that could minimize the risk of libel suits. Kerouac had already secured signed libel releases from the major characters, but Whitehorn observed, sniffily, that ‚Äúthe fact that these people are portrayed as drunks, dope addicts, etc., could give any one of them a basis for avoidance of the release.‚Äù&lt;/p&gt;
    &lt;p&gt;Over the next year or so, Cowley worked with Kerouac to fumigate On the Road to conform to the lawyer‚Äôs suggestions. Increasingly though, editorial responsibility for the book went to Helen Taylor, the novel‚Äôs in-house editor. What few Kerouac biographers and scholars have grasped is that Cowley was a consulting editor for Viking, not a full-time staffer. He went into the office once a week and was often absent for months at a time while in residence at this or that university as a visiting instructor. Getting any book into the world, let alone one with as many imponderables as On the Road, is a complex process. Someone has to be reliably in the office every day, and that person was Taylor. Cowley became increasingly remote from his editorial control of Kerouac‚Äôs novel‚Äîas, alas, did Kerouac himself.&lt;/p&gt;
    &lt;p&gt;The impression one gets from Taylor‚Äôs letters and memos is of a high-functioning and extremely professional American editor. She had to accomplish three crucial tasks: to make sure that all the legal corrections were made to satisfy the lawyer, to do the line editing of the book to bring Kerouac‚Äôs idiosyncratic prose nearer to the standard usage of the day, and to keep the book‚Äôs production on schedule to meet its publication date. The latter two tasks led to friction. Kerouac wrote to please his ear. He didn‚Äôt like commas much and rarely resorted to semicolons. Taylor liked commas and semicolons a lot, and the regularized style she imposed on the book undermined much of its energy and immediacy. On March 21, 1957, she wrote in an interoffice memo that ‚ÄúWhitehorn called this morning to say that the book was clean now, in his opinion.‚Äù This was the point at which a publication date could finally be scheduled; it was also the moment that Viking broke faith with Kerouac in a fashion that is hard to forgive.&lt;/p&gt;
    &lt;p&gt;After a compositor typesets a book in what are called galleys, they are sent to the author, who has a chance to correct any mistakes the compositor may have made and ensure that the book reads as intended. Authors are routinely advised not to make too many edits in galleys, as changes cost money and delay the book‚Äôs production. Nevertheless it is a near-sacred principle that authors must be given a chance to read their galleys.&lt;/p&gt;
    &lt;p&gt;Kerouac never received them. There is no paper trail to trace the thinking behind this decision, so we are left to speculate as to why. There was a distinct air of condescension at Viking toward Kerouac and his Beat companions. Kerouac had no fixed address, and his editors may not have known where he was at any given time. He would have grumbled about the many changes to his book that had been forced on him. Seeing one‚Äôs words in type for the first time is a phenomenological experience. In any case, in mid-May, Kerouac had settled into an apartment in Berkeley, where he anxiously awaited galley proofs that never came.&lt;/p&gt;
    &lt;p&gt;A decision must have been made to keep Kerouac out of the loop. Viking probably feared that he would decide to restore so many edits and add so much new material that the bound-book date would be delayed. Given Kerouac‚Äôs peripatetic life style, the galleys might not have reached him at all, or maybe too late for his changes to be made. Whatever the reason for this lapse, he never got to read his words in type until he received the printed book, and he was justifiably aggrieved.&lt;/p&gt;
    &lt;p&gt;For more than a year leading up to the publication of On the Road, Kerouac and Cowley remained in sporadic contact. Missed connections drew out the editing process unpleasantly. Finally, though, Cowley could write a genuine ‚ÄúManuscript Acceptance Report‚Äù and share the fruits of his and Kerouac‚Äôs and everyone else‚Äôs labors with the company. Few interoffice memos rise to the level of important literary documents, but this is one:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The characters are always on wheels. They buy cars and wreck them, steal cars and leave them standing in fields, undertake to drive cars from one city to another, sharing the gas; then for variety they go hitch-hiking or sometimes ride a bus. In cities they go on wild parties or sit in joints listening to hot trumpets. They seem a little like machines themselves, machines gone haywire, always wound to the last pitch, always nervously moving, drinking, making love with hardly any emotions except a determination to say Yes to any new experience. The writing is at best deeply felt, poetic, and extremely moving. Again at its best this book is a celebration of the American scene in the manner of a latter-day Wolfe or Sandburg.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His final paragraph made a startlingly accurate prediction: ‚ÄúThe book, I prophesy, will get mixed but interested reviews. [It] will have a good sale (perhaps a very good one), and I don‚Äôt think there is any doubt that it will be reprinted as a paperback. Moreover it will stand for a long time as an honest record of another way of life.‚Äù&lt;/p&gt;
    &lt;p&gt;After the many trials On the Road suffered on its way to publication, there was something miraculous about how it was launched. The book was scheduled for review by the all-important New York Times in the first week of September 1957. As luck would have it, the paper‚Äôs main daily reviewer, Orville Prescott, a notorious curmudgeon guaranteed to have excoriated the novel, happened to be on vacation that week. Instead the assignment went to Gilbert Millstein, who two years earlier had commissioned Holmes‚Äôs famous ‚ÄúThis Is the Beat Generation‚Äù essay. Millstein‚Äôs exceptionally smart review called the publication of On the Road ‚Äúa historic occasion‚Äù; praised the novel as ‚Äúthe most beautifully executed, the clearest and the most important utterance yet made by the generation Kerouac himself named years ago as ‚Äòbeat‚Äô ‚Äù; and compared it to The Sun Also Rises. ‚ÄúOn the Road is a major novel,‚Äù he emphatically concluded. His 1,000-word rave was the literary equivalent of Elvis Presley‚Äôs appearance the previous year on The Ed Sullivan Show. Presley delivered an electrifying jolt of sexual energy to the somnolent culture of the ‚Äô50s; Kerouac‚Äôs book, Millstein asserted, offered an irresistible new model of freedom and spiritual questing to a younger generation chafing under the decade‚Äôs cultural constraints.&lt;/p&gt;
    &lt;p&gt;The evening before the review came out, Kerouac was staying in the Upper West Side apartment of his girlfriend, the editor and novelist Joyce Johnson. Tipped off to the review by Viking, she and Kerouac walked down to a newsstand on Broadway at midnight to get a copy of the next day‚Äôs paper, fresh off the truck. They both eagerly scanned the review, and Kerouac asked her, hardly believing his luck , ‚ÄúIt‚Äôs good, isn‚Äôt it?‚Äù ‚ÄúYes,‚Äù she replied. ‚ÄúIt‚Äôs very very good.‚Äù She‚Äôd worked in publishing, and she knew what it meant. She was thrilled, but also a bit frightened by what his anointing as a generational avatar might mean for him.&lt;/p&gt;
    &lt;p&gt;The next day, the phone in Johnson‚Äôs apartment never stopped ringing with demands for interviews and appearances. A Viking employee arrived that morning with half a case of celebratory champagne, three bottles of which were quickly dispatched. The first newspaper reporter showed up that afternoon, and excited and champagne fueled, Kerouac had to explain for the first of hundreds of times the beatific derivation of ‚ÄúBeat‚Äù to an ill-informed interviewer angling for a quick personality feature.&lt;/p&gt;
    &lt;p&gt;The publication of On the Road was both the making of Kerouac and his eventual undoing. He was completely unprepared and temperamentally unfit to handle the kind of fame that descended on him. He was shy, and he drank to manage his shyness, which led to a familiar downward spiral as he found himself for the first time before audiences and radio microphones and television cameras.&lt;/p&gt;
    &lt;p&gt;On the Road hit the bestseller lists for five weeks and became the focus of a heated debate in literary circles and in the culture at large. Opinions were mixed and sometimes sharply divided. There were some good, appreciative reviews in magazines and newspapers across the country, but many other reviewers and columnists manifested the American tendency to resort to mockery and moral panic when something new comes along. As Robert Ruark, a powerful syndicated columnist, wrote, ‚ÄúWhat I am by the beat generation is just that‚Äîbeat. If ‚Äòbeat‚Äô means defeated, I don‚Äôt know what they are defeated by, or for what reason. ‚Ä¶ All I gather is that they are mad at something.‚Äù Ruark sneered that On the Road was ‚Äúnot much more than a candid admission that [Kerouac] had been on the bum for six years.‚Äù He concluded that ‚Äúthe whole sniveling lot‚Äù of Kerouac and his fellow Beats ‚Äúneeds a kick ‚Ä¶ right in the pants.‚Äù No wonder young people hate adults.&lt;/p&gt;
    &lt;p&gt;Of greater interest were the attacks that came from literary intellectuals, who understood what was really at stake in the rise of the outlaw sensibility of this new crowd that did not worship at the shrine of T. S. Eliot or read any Karl Marx. Their designated attack dog was Norman Podhoretz, already a made man among the New York intellectuals. His piece in the spring 1958 issue of Partisan Review, ‚ÄúThe Know-Nothing Bohemians,‚Äù remains a durable attack on Beat writing. In Podhoretz‚Äôs view, the older bohemianism of the teens and ‚Äô20s was a repudiation of the provincialism and hypocrisy of American life and ‚Äúa movement created in the name of civilization: its ideals were intelligence, cultivation, spiritual refinement.‚Äù The Beats, in contrast, he saw as primitives in thrall to pure instinct, spontaneity, irrationalism, woolly mysticism, crank philosophies, and unearned sentimentality.&lt;/p&gt;
    &lt;p&gt;Podhoretz‚Äôs piece scores points while missing the biggest point of all: the sadness and sweetness at the heart of the book, and the openness and masculine vulnerability of Kerouac‚Äôs writing. In his 2021 book, The Free World: Art and Thought in the Cold War, Louis Menand calls attacks of this sort ‚Äúa crude misreading.‚Äù ‚ÄúThe Beats weren‚Äôt rebels,‚Äù he wrote. ‚ÄúThey were misfits.‚Äù On the Road, he continued, is ‚Äúexuberant, hopeful, sad, nostalgic; it is never naturalistic. Most of all, it is emotionally uninhibited. ‚Ä¶ The Beats were men who wrote about their feelings.‚Äù Kerouac had courageously committed his emotions to paper for all the world to see. This is what brings tens of thousands of new readers to On the Road every year.&lt;/p&gt;
    &lt;p&gt;Cowley largely lost touch with Kerouac after publication of the novel, and he had very little to contribute editorially to Kerouac‚Äôs future dealings with Viking. There was probably considerable fatigue on the part of both men. Cowley had spent years conducting a kind of editorial shuttle diplomacy between a writer and a company with scant sympathy for each other‚Äôs needs. Kerouac had jumped through every hoop Cowley required of him while receiving rejections from him for new novel after new novel. It had been a painful and protracted slog.&lt;/p&gt;
    &lt;p&gt;Viking naturally wanted another book from Kerouac as soon as possible. Novels that Sterling Lord had been frustratingly unable to place were now being sold with ease to other houses. So Viking signed up the superior Dharma Bums, another exercise in male bonding, with dispatch, with Helen Taylor once again editing the text and, along the way, sticking Kerouac with a bill for $519.45 for author‚Äôs alterations. The Dharma Bums received, on balance, more favorable reviews than On the Road, but the shock of the new had worn off. It sold only modestly in hardcover and was the last Kerouac book that Viking would publish for decades.&lt;/p&gt;
    &lt;p&gt;In Beat circles, Cowley came to be seen as less the hero of the saga of On the Road‚Äôs long march to publication than as its author‚Äôs nemesis and underminer. The source of a lot of this animus can be found in a rollicking interview that Kerouac gave to The Paris Review in 1968, the year before his death. ‚ÄúIn the days of Malcolm Cowley, with On the Road and The Dharma Bums,‚Äù he said, ‚ÄúI had no power to stand by my style for better or worse. When Malcolm Cowley made endless revisions and inserted thousands of needless commas ‚Ä¶ why, I spent $500 making a complete restitution of the Bums manuscript and got a bill from Viking Press called ‚ÄòRevisions.‚Äô Ha ho ho.‚Äù Later in the interview, he alleged that Cowley had also fiddled with the text of On the Road. Not a word of this is true. It was Taylor who put the clamps on Kerouac‚Äôs prose for Viking in both books. ‚ÄúJack and his memory are very, very unfair to me,‚Äù Cowley told an interviewer in 1978. ‚ÄúBlaming me for putting in or taking out commas and caps and what-not in On the Road. I didn‚Äôt really give much of a damn about that.‚Äù&lt;/p&gt;
    &lt;p&gt;The truth is, Cowley was the perfect editor for On the Road but the wrong editor for Kerouac. His curt rejections of Kerouac‚Äôs other novels proved that he could not be for him what Max Perkins had been for Thomas Wolfe: an all-in-to-the-end editor. He never took the larger enterprise of Kerouac‚Äôs Proustian ‚ÄúLegend of Duluoz‚Äù cycle of novels seriously. Cowley was a man whose own credo as a writer was that he hated to write and loved to revise. He‚Äôd also written his master‚Äôs thesis on the 17th-century Neoclassical poet and dramatist Jean Racine. Kerouac‚Äôs temperament was Romantic, privileging perception and feeling over form. As partners, the two men were not built for the long or even the medium haul.&lt;/p&gt;
    &lt;p&gt;Still, on one extended occasion, they battled together against the naysaying forces of conventional wisdom and won a great victory. Once On the Road came out in Signet paperback, it would be read by millions of people and lodged in their hearts and minds as a summons to another way of life, one of physical and emotional amplitude and spiritual discovery. Kerouac was and remains a conductor of that core American value, freedom.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45742957</guid><pubDate>Wed, 29 Oct 2025 05:27:42 +0000</pubDate></item><item><title>Show HN: Front End Fuzzy and Substring and Prefix Search</title><link>https://github.com/m31coding/fuzzy-search</link><description>&lt;doc fingerprint="fb17e2f42efbe30c"&gt;
  &lt;main&gt;
    &lt;p&gt;@m31coding/fuzzy-search is a frontend library for searching objects with ids (entities) by their names and features (terms). It is&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fast: A query takes usually well below 10 ms.&lt;/item&gt;
      &lt;item&gt;Accurate: Powered by a suffix array and n-grams with a novel approach of character sorting.&lt;/item&gt;
      &lt;item&gt;Multilingual: The language-agnostic design of the algorithm enables operation across all languages.&lt;/item&gt;
      &lt;item&gt;Flexible: Entities and their terms can be inserted, updated and removed.&lt;/item&gt;
      &lt;item&gt;Reliable: Well tested standalone library with no dependencies.&lt;/item&gt;
      &lt;item&gt;Universal: Works seamlessly in both frontend and backend (Node.js) environments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install the package via npm:&lt;/p&gt;
    &lt;code&gt;npm install @m31coding/fuzzy-search&lt;/code&gt;
    &lt;p&gt;The following files are available in the dist folder for different use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;fuzzy-search.module.js (ESM)&lt;/item&gt;
      &lt;item&gt;fuzzy-search.cjs (CommonJS)&lt;/item&gt;
      &lt;item&gt;fuzzy-search.umd.js (UMD)&lt;/item&gt;
      &lt;item&gt;fuzzy-search.modern.js (Modern mode)&lt;/item&gt;
      &lt;item&gt;fuzzy-search.d.ts (TypeScript definitions)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This library uses microbundle. Please consult their documentation for more information on how to use the different files.&lt;/p&gt;
    &lt;p&gt;The most important definitions can be found in the folder interfaces. For creating a searcher, use the SearcherFactory. Here is a basic usage example (esm module syntax):&lt;/p&gt;
    &lt;code&gt;import * as fuzzySearch from './path/to/fuzzy-search.module.js';

const searcher = fuzzySearch.SearcherFactory.createDefaultSearcher();

const persons = [
  { id: 23501, firstName: 'Alice', lastName: 'King' },
  { id: 99234, firstName: 'Bob', lastName: 'Bishop' },
  { id: 5823, firstName: 'Carol', lastName: 'Queen' },
  { id: 11923, firstName: 'Charlie', lastName: 'Rook' }
];

function log&amp;lt;T&amp;gt;(obj: T): void {
  console.log(JSON.stringify(obj, null, 2));
}

const indexingMeta = searcher.indexEntities(
  persons,
  (e) =&amp;gt; e.id,
  (e) =&amp;gt; [e.firstName, e.lastName, `${e.firstName} ${e.lastName}`]
);
log(indexingMeta);
/* {
  "entries": {
    "numberOfTerms": 12,
    "indexingDurationTotal": 1,
    ...
  }
} */

const result = searcher.getMatches(new fuzzySearch.Query('alice kign'));
log(result);
/* {
  "matches": [
    {
      "entity": {
        "id": 23501,
        "firstName": "Alice",
        "lastName": "King"
      },
      "quality": 0.8636363636363635,
      "matchedString": "Alice King"
    }
  ],
  "query": {
    "string": "alice kign",
    "topN": 10,
    "searchers": [
      {
        "type": "fuzzy",
        "minQuality": 0.3
      },
      {
        "type": "substring",
        "minQuality": 0
      },
      {
        "type": "prefix",
        "minQuality": 0
      }
    ]
  },
  "meta": {
    "entries": {
      "queryDuration": 1
    }
  }
} */

const removalResult = searcher.removeEntities([99234, 5823]);
log(removalResult);
/* {
  "removedEntities": [
    99234,
    5823
  ],
  "meta": {
    "entries": {
      "removalDuration": 0
    }
  }
} */

const persons2 = [
  { id: 723, firstName: 'David', lastName: 'Knight' }, // new
  { id: 2634, firstName: 'Eve', lastName: 'Pawn' }, // new
  { id: 23501, firstName: 'Allie', lastName: 'King' }, // updated
  { id: 11923, firstName: 'Charles', lastName: 'Rook' } // updated
];

const upsertMeta = searcher.upsertEntities(
  persons2,
  (e) =&amp;gt; e.id,
  (e) =&amp;gt; [e.firstName, e.lastName, `${e.firstName} ${e.lastName}`]
);
log(upsertMeta);
/* {
  "entries": {
    "numberOfTerms": 12,
    "upsertDuration": 0,
    ...
  }
} */

const result2 = searcher.getMatches(new fuzzySearch.Query('allie'));
log(result2);
/* {
  "matches": [
    {
      "entity": {
        "id": 23501,
        "firstName": "Allie",
        "lastName": "King"
      },
      "quality": 3,
      "matchedString": "Allie"
    }
  ],
  "query": {
    "string": "allie",
    "topN": 10,
    "searchers": [
      {
        "type": "fuzzy",
        "minQuality": 0.3
      },
      {
        "type": "substring",
        "minQuality": 0
      },
      {
        "type": "prefix",
        "minQuality": 0
      }
    ]
  },
  "meta": {
    "entries": {
      "queryDuration": 0
    }
  }
} */&lt;/code&gt;
    &lt;p&gt;The following parameters are available when creating a query:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;The query string.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;topN&lt;/cell&gt;
        &lt;cell&gt;number&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;The maximum number of matches to return. Provide Infinity to return all matches.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;searchers&lt;/cell&gt;
        &lt;cell&gt;SearcherSpec[]&lt;/cell&gt;
        &lt;cell&gt;[new FuzzySearcher(0.3), new SubstringSearcher(0), new PrefixSearcher(0)]&lt;/cell&gt;
        &lt;cell&gt;The searchers to use and the minimum quality thresholds for their matches.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A fuzzy search minimum quality threshold below 0.3 is not recommended, as the respective matches are most likely irrelevant.&lt;/p&gt;
    &lt;p&gt;If the data terms contain characters and strings in non-latin scripts (such as Arabic, Cyrillic, Greek, Han, ... see also ISO 15924), the default configuration must be adjusted before creating the searcher:&lt;/p&gt;
    &lt;code&gt;const config = fuzzySearch.Config.createDefaultConfig();
config.normalizerConfig.allowCharacter = (_c) =&amp;gt; true;
const searcher = fuzzySearch.SearcherFactory.createSearcher(config);&lt;/code&gt;
    &lt;p&gt;Moreover, if your dataset is large (&amp;gt; 100.000 terms), you may index the searcher in a web worker to avoid blocking the main thread, as shown in this usage example.&lt;/p&gt;
    &lt;p&gt;If your objects cannot be identified by a unique id, you can also pass &lt;code&gt;(e) =&amp;gt; e&lt;/code&gt; for the &lt;code&gt;getId&lt;/code&gt; parameter of both &lt;code&gt;indexEntities&lt;/code&gt; and &lt;code&gt;upsertEntities&lt;/code&gt;. Just be aware that the &lt;code&gt;getId&lt;/code&gt; function is used for equality checks and the creation of Maps, particularly utilized by the &lt;code&gt;upsertEntities&lt;/code&gt; and &lt;code&gt;removeEntities&lt;/code&gt; methods. For indexing plain strings, you can call:&lt;/p&gt;
    &lt;code&gt;const indexingMeta = searcher.indexEntities(
  ["Alice", "Bob", "Carol", "Charlie"],
  (e) =&amp;gt; e,
  (e) =&amp;gt; [e]
);&lt;/code&gt;
    &lt;p&gt;To try the demo and usage examples locally, clone the repository and execute the commands:&lt;/p&gt;
    &lt;code&gt;npm install
npm run build&lt;/code&gt;
    &lt;p&gt;To proceed, open the html file of interest (e.g., &lt;code&gt;fuzzy-search-demo.html&lt;/code&gt;) with a local webserver. If you use VS Code, you may use the Live Server extension for this purpose.&lt;/p&gt;
    &lt;p&gt;This library was optimized for fast querying. At its core, a searcher employs integer indexes that can not be easily updated. The upsert operation is implemented by reindexing a secondary searcher, which is initially empty. Removal is implemented by blacklisting entities.&lt;/p&gt;
    &lt;p&gt;Consequently, repeated upsert operations with a large number of entities may be costly. In such cases, consider reindexing the searcher from scratch by calling the &lt;code&gt;index&lt;/code&gt; method eventually.&lt;/p&gt;
    &lt;p&gt;Query strings and data terms are normalized in the following normalization pipeline (order matters):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Null and undefined strings are replaced by an empty string.&lt;/item&gt;
      &lt;item&gt;Strings are lowercased and normalized to NFKC.&lt;/item&gt;
      &lt;item&gt;Replacements are applied to characters such as √• -&amp;gt; aa, √¶ -&amp;gt; ae. See also Latin replacements.&lt;/item&gt;
      &lt;item&gt;Strings are normalized to NFKD.&lt;/item&gt;
      &lt;item&gt;Space equivalent characters are replaced by a space.&lt;/item&gt;
      &lt;item&gt;Surrogate characters, padding characters and other non-allowed characters are removed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Normalization to NFKC decomposes characters by compatibility, then re-composes them by canonical equivalence. This ensures that the characters in the replacement table always match. Normalization to NFKD decomposes the characters by compatibility but does not re-compose them, allowing undesired characters to be removed thereafter.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The default normalizer config adopts the following values:&lt;/p&gt;
    &lt;code&gt;config.normalizerConfig.replacements = [fuzzySearch.LatinReplacements.Value];
let spaceEquivalentCharacters = new Set(['_', '-', '‚Äì', '/', ',', '\t']);
config.normalizerConfig.treatCharacterAsSpace = (c) =&amp;gt; spaceEquivalentCharacters.has(c);
config.normalizerConfig.allowCharacter = (c) =&amp;gt; {
  return fuzzySearch.StringUtilities.isAlphanumeric(c);
};&lt;/code&gt;
    &lt;p&gt;With this pipeline and configuration, the string &lt;code&gt;Thanh Vi·ªát ƒêo√†n&lt;/code&gt; is normalized to &lt;code&gt;thanh viet doan&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The general idea of n-grams and the sorting trick is outlined in this blog post. In short, the data terms and the query string are padded on the left, right and middle (replacement of spaces) with &lt;code&gt;$$&lt;/code&gt;, &lt;code&gt;!&lt;/code&gt;, and &lt;code&gt;!$$&lt;/code&gt;, respectively, before they are broken down into 3-grams. For example, the string &lt;code&gt;sarah&lt;/code&gt; becomes &lt;code&gt;$$sarah!&lt;/code&gt; after padding and the resulting 3-grams are:&lt;/p&gt;
    &lt;code&gt;$$s, $sa, sar, ara, rah, ah!
&lt;/code&gt;
    &lt;p&gt;The more common 3-grams between the query and the term, the higher the quality of the match. By padding the front with two characters, and the back with one character, more weight is given to the beginning of the string.&lt;/p&gt;
    &lt;p&gt;In addition, the characters of the 3-grams that don't contain '$' are sorted:&lt;/p&gt;
    &lt;code&gt;$$s, $sa, ars, aar, ahr, !ah
&lt;/code&gt;
    &lt;p&gt;Sorting the characters increases the number of common n-grams for transposition errors, one of the most common types of errors in human typing. Not sorting the first n-grams assumes that transpositions are less likely to occur at the beginning of a string.&lt;/p&gt;
    &lt;p&gt;The quality is then computed by dividing the number of common n-grams by the number of n-grams of the longer string, query or term. Moreover, a 5% penalty is given if the query string does not match the term exactly. This accounts for the fact that even if two strings have the same 3-grams, they are not necessarily the same, i.e., compare &lt;code&gt;aabaaa&lt;/code&gt; and &lt;code&gt;aaabaa&lt;/code&gt;. With this approach, the following quality values are obtained:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Query&lt;/cell&gt;
        &lt;cell role="head"&gt;Term&lt;/cell&gt;
        &lt;cell role="head"&gt;Padded query&lt;/cell&gt;
        &lt;cell role="head"&gt;Padded term&lt;/cell&gt;
        &lt;cell role="head"&gt;Common 3-grams&lt;/cell&gt;
        &lt;cell role="head"&gt;Quality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;$$sarah!&lt;/cell&gt;
        &lt;cell&gt;$$sarah!&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;6 / 6 = 1.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;sarha&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;$$arah!&lt;/cell&gt;
        &lt;cell&gt;$$sarah!&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;5 / 6 * 0.95 = 0.79&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;sar&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;$$sar!&lt;/cell&gt;
        &lt;cell&gt;$$sarah!&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3 / 6 * 0.95 = 0.475&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;arah&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;$$arah!&lt;/cell&gt;
        &lt;cell&gt;$$sarah!&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3 / 6 * 0.95 = 0.475&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that I refrain from explicitly computing the Damereau-Levenshtein distance between strings, in order to keep the queries fast.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Padding strings in the middle allows for extending the algorithm across word boundaries. &lt;code&gt;sarah wolff&lt;/code&gt; becomes &lt;code&gt;$$sarah!$$wolff!&lt;/code&gt; and matches &lt;code&gt;wolff sarah&lt;/code&gt; with a quality of 0.95, if 3-grams that end with a '$' are discarded.&lt;/p&gt;
    &lt;p&gt;The overall approach outlined above can be summarized as: remove n-grams that end with '$', sort n-grams that don't contain '$'. The default fuzzy search configuration appears in the code as follows:&lt;/p&gt;
    &lt;code&gt;config.fuzzySearchConfig.paddingLeft = '$$';
config.fuzzySearchConfig.paddingRight = '!';
config.fuzzySearchConfig.paddingMiddle = '!$$';
config.fuzzySearchConfig.ngramN = 3;
config.fuzzySearchConfig.transformNgram = (ngram) =&amp;gt;
  ngram.endsWith('$') ? null
  : ngram.indexOf('$') === -1 ? ngram.split('').sort().join('')
  : ngram;
config.fuzzySearchConfig.inequalityPenalty = 0.05;&lt;/code&gt;
    &lt;p&gt;Substring and prefix search is realized with a single suffix array created by An efficient, versatile approach to suffix sorting.&lt;/p&gt;
    &lt;p&gt;The base quality of a prefix or substring match is simply computed by dividing the query length by the term length. For example, the query &lt;code&gt;sa&lt;/code&gt; matches the term &lt;code&gt;sarah&lt;/code&gt; with a quality of 2/5 = 0.4, and the query &lt;code&gt;ara&lt;/code&gt; matches the same term with a quality of 3/5 = 0.6.&lt;/p&gt;
    &lt;p&gt;A quality offset of +2 and +1 is added to prefix and substring matches, respectively, as explained in the next section.&lt;/p&gt;
    &lt;p&gt;The final qualities of the examples are:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Query&lt;/cell&gt;
        &lt;cell role="head"&gt;Term&lt;/cell&gt;
        &lt;cell role="head"&gt;Searcher&lt;/cell&gt;
        &lt;cell role="head"&gt;Quality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;sa&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;Prefix&lt;/cell&gt;
        &lt;cell&gt;2 / 5 + 2 = 2.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ara&lt;/cell&gt;
        &lt;cell&gt;sarah&lt;/cell&gt;
        &lt;cell&gt;Substring&lt;/cell&gt;
        &lt;cell&gt;3 / 5 + 1 = 1.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The default configuration for the searchers is as follows:&lt;/p&gt;
    &lt;code&gt;config.substringSearchConfig.suffixArraySeparator = '$';&lt;/code&gt;
    &lt;p&gt;The matches of the searchers are mixed with a simple approach. Prefix matches get a quality offset of +2, substring matches of +1, and fuzzy matches keep their original quality. The rationale is that, for the same query length, prefix matches are more relevant than substring matches. Additionally, fuzzy matches are only relevant if there are no prefix or substring matches.&lt;/p&gt;
    &lt;p&gt;The default configuration has been chosen carefully. There are only a few specific scenarios that require adjustments. Consult the file default-config.ts for all configuration options and their default values.&lt;/p&gt;
    &lt;p&gt;This library is free. If you find it valuable and wish to express your support, please leave a star. You are kindly invited to contribute. If you see the possibility for enhancement, please create a GitHub issue and you will receive timely feedback.&lt;/p&gt;
    &lt;p&gt;Happy coding!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45743232</guid><pubDate>Wed, 29 Oct 2025 06:12:46 +0000</pubDate></item><item><title>NPM flooded with malicious packages downloaded more than 86k times</title><link>https://arstechnica.com/security/2025/10/npm-flooded-with-malicious-packages-downloaded-more-than-86000-times/</link><description>&lt;doc fingerprint="771a9388954b799"&gt;
  &lt;main&gt;
    &lt;p&gt;Attackers are exploiting a major weakness that has allowed them access to the NPM code repository with more than 100 credential-stealing packages since August, mostly without detection.&lt;/p&gt;
    &lt;p&gt;The finding, laid out Wednesday by security firm Koi, brings attention to an NPM practice that allows installed packages to automatically pull down and run unvetted packages from untrusted domains. Koi said a campaign it tracks as PhantomRaven has exploited NPM‚Äôs use of ‚ÄúRemote Dynamic Dependencies‚Äù to flood NPM with 126 malicious packages that have been downloaded more than 86,000 times. Some 80 of those packages remained available as of Wednesday morning, Koi said.&lt;/p&gt;
    &lt;head rend="h2"&gt;A blind spot&lt;/head&gt;
    &lt;p&gt;‚ÄúPhantomRaven demonstrates how sophisticated attackers are getting [better] at exploiting blind spots in traditional security tooling,‚Äù Koi‚Äôs Oren Yomtov wrote. ‚ÄúRemote Dynamic Dependencies aren‚Äôt visible to static analysis.‚Äù&lt;/p&gt;
    &lt;p&gt;Remote Dynamic Dependencies provide greater flexibility in accessing dependencies‚Äîthe code libraries that are mandatory for many other packages to work. Normally, dependencies are visible to the developer installing the package. They‚Äôre usually downloaded from NPM‚Äôs trusted infrastructure.&lt;/p&gt;
    &lt;p&gt;RDD works differently. It allows a package to download dependencies from untrusted websites, even those that connect over HTTP, which is unencrypted. The PhantomRaven attackers exploited this leniency by including code in the 126 packages uploaded to NPM. The code downloads malicious dependencies from URLs, including http://packages.storeartifact.com/npm/unused-imports. Koi said these dependencies are ‚Äúinvisible‚Äù to developers and many security scanners. Instead, they show the package contains ‚Äú0 Dependencies.‚Äù An NPM feature causes these invisible downloads to be automatically installed.&lt;/p&gt;
    &lt;p&gt;Compounding the weakness, the dependencies are downloaded ‚Äúfresh‚Äù from the attacker server each time a package is installed, rather than being cached, versioned, or otherwise static, as Koi explained:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45755027</guid><pubDate>Thu, 30 Oct 2025 00:37:33 +0000</pubDate></item><item><title>Show HN: I made a heatmap diff viewer for code reviews</title><link>https://0github.com</link><description>&lt;doc fingerprint="5f30552b55a047fe"&gt;
  &lt;main&gt;
    &lt;p&gt;Heatmap color-codes every diff line/token by how much human attention it probably needs. Unlike PR-review bots, we try to flag not just by ‚Äúis it a bug?‚Äù but by ‚Äúis it worth a second look?‚Äù (examples: hard-coded secret, weird crypto mode, gnarly logic).&lt;/p&gt;
    &lt;p&gt;To try it, replace github.com with 0github.com in any GitHub pull request url. Under the hood, we clone the repo into a VM, spin up gpt-5-codex for every diff, and ask it to output a JSON data structure that we parse into a colored heatmap.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;p&gt;Heatmap is open source:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760321</guid><pubDate>Thu, 30 Oct 2025 14:21:58 +0000</pubDate></item><item><title>Free software scares normal people</title><link>https://danieldelaney.net/normal/</link><description>&lt;doc fingerprint="a23b437c2441cdbd"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôm the person my friends and family come to for computer-related help. (Maybe you, gentle reader, can relate.) This experience has taught me which computing tasks are frustrating for normal people.&lt;/p&gt;
    &lt;p&gt;Normal people often struggle with converting video. They will need to watch, upload, or otherwise do stuff with a video, but the format will be weird. (Weird, broadly defined, is anything that won‚Äôt play in QuickTime or upload to Facebook.)&lt;/p&gt;
    &lt;p&gt;I would love to recommend Handbrake to them, but the user interface is by and for power users. Opening it makes normal people feel unpleasant feelings.&lt;/p&gt;
    &lt;p&gt;This problem is rampant in free software. The FOSS world is full of powerful tools that only have a ‚Äúpower user‚Äù UI. As a result, people give up. Or worse: they ask people like you and I to do it for them.&lt;/p&gt;
    &lt;p&gt;I want to make the case to you that you can (and should) solve this kind of problem in a single evening.&lt;/p&gt;
    &lt;p&gt;Take the example of Magicbrake, a simple front end I built. It hides the power and flexibility of Handbrake. It does only the one thing most people need Handbrake for: taking a weird video file and making it normal. (Normal, for our purposes, means a small MP4 that works just about anywhere.)&lt;/p&gt;
    &lt;p&gt;There is exactly one button.&lt;/p&gt;
    &lt;p&gt;This is a fast and uncomplicated thing to do. Unfortunately, the people who have the ability to solve problems like this are often disinclined to do it.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhy would you make Handbrake less powerful on purpose?‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat if someone wants a different format?‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat about [feature/edge case]?‚Äù&lt;/p&gt;
    &lt;p&gt;The answer to all these questions is the same: a person who needs or wants that stuff can use Handbrake. If they don‚Äôt need everything Handbrake can do and find it bewildering, they can use this. Everyone wins.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a bit like obscuring the less-used functions on a TV remote with tape. The functions still exist if you need them, but you‚Äôre not required to contend with them just to turn the TV on.&lt;/p&gt;
    &lt;p&gt;People benefit from stuff like this, and I challenge you to make more of it. Opportunities are everywhere. The world is full of media servers normal people can‚Äôt set up. Free audio editing software that requires hours of learning to be useful for simple tasks. Network monitoring tools that seem designed to ward off the uninitiated. Great stuff normal people don‚Äôt use. All because there‚Äôs only one UI, and it‚Äôs designed to do everything.&lt;/p&gt;
    &lt;p&gt;80% of the people only need 20% of the features. Hide the rest from them and you‚Äôll make them more productive and happy. That‚Äôs really all it takes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760878</guid><pubDate>Thu, 30 Oct 2025 15:07:15 +0000</pubDate></item><item><title>Affinity Studio now free</title><link>https://www.affinity.studio/get-affinity</link><description>&lt;doc fingerprint="3bd67e5e966d06c5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Get Affinity&lt;/head&gt;
    &lt;p&gt;Available on desktop for&lt;/p&gt;
    &lt;p&gt;The all-in-one creative app, with everything you need to craft designs, edit images, and lay it all out, without ever leaving your document or paying a thing.&lt;/p&gt;
    &lt;quote&gt;$0, free&lt;/quote&gt;
    &lt;p&gt;To download Affinity, sign in with your Canva account (or create one for free).&lt;/p&gt;
    &lt;head rend="h2"&gt;One powerful app. No cost.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Fully-featured toolsets&lt;/p&gt;
        &lt;p&gt;From vector to pixel to layout, Affinity has all the studio-grade tools you need under one roof.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customizable studios&lt;/p&gt;
        &lt;p&gt;Mix and match your favorite tools to build your very own creative studios.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-destructive editing&lt;/p&gt;
        &lt;p&gt;Experiment as much you want, keep your original files intact.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pixel-perfect export&lt;/p&gt;
        &lt;p&gt;Full control over how your work leaves the app, whether it‚Äôs by object, slice, or doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you‚Äôll get&lt;/head&gt;
    &lt;p&gt;With Affinity, you‚Äôll get all the professional tools you need for your design, photo editing, and page layout projects, free of charge. If you‚Äôre on a Canva premium plan, you‚Äôll also be able to unlock Canva AI tools directly in Affinity for a super-powered workflow.&lt;/p&gt;
    &lt;p&gt;+ Canva premium plans&lt;/p&gt;
    &lt;head rend="h2"&gt;Design workflows&lt;/head&gt;
    &lt;p&gt;Access all vector design, photo editing, and page layout tools in one app&lt;/p&gt;
    &lt;p&gt;Combine vector and pixel work on the same .af document&lt;/p&gt;
    &lt;p&gt;Customize your workspace with floating toolbars and studio presets&lt;/p&gt;
    &lt;p&gt;Real-time performance engine for ultra-smooth editing&lt;/p&gt;
    &lt;p&gt;Non-destructive editing across layers, filters, and adjustments&lt;/p&gt;
    &lt;p&gt;Import PSD, AI, PDF, SVG, IDML and more with high fidelity&lt;/p&gt;
    &lt;p&gt;Export with one-click presets or custom slice-based output&lt;/p&gt;
    &lt;p&gt;Quick export direct to Canva&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful photo editing&lt;/head&gt;
    &lt;p&gt;Live filters and adjustments with instant preview&lt;/p&gt;
    &lt;p&gt;Full RAW editing, tone mapping, and lens correction&lt;/p&gt;
    &lt;p&gt;Advanced retouching: inpainting brush, healing tools, dodge and burn&lt;/p&gt;
    &lt;p&gt;Batch processing with recordable macros, HDR merge, panorama stitching, and more&lt;/p&gt;
    &lt;head rend="h2"&gt;Pro vector design&lt;/head&gt;
    &lt;p&gt;Precision drawing with pen, node, and pencil tools&lt;/p&gt;
    &lt;p&gt;Live shape editing, booleans, and shape builder&lt;/p&gt;
    &lt;p&gt;Flexible gradients with full control&lt;/p&gt;
    &lt;p&gt;Trace pixel images&lt;/p&gt;
    &lt;p&gt;Pixel-perfect vector tools for illustration and layout&lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced page layout&lt;/head&gt;
    &lt;p&gt;Linked text frames with autoflow and live text wrapping&lt;/p&gt;
    &lt;p&gt;Smart master pages with overrides and reusable layouts&lt;/p&gt;
    &lt;p&gt;Pro typography: ligatures, stylistic sets, drop caps, and variable fonts&lt;/p&gt;
    &lt;p&gt;Print-ready output: CMYK, spot colours, preflight, bleed, and slug support&lt;/p&gt;
    &lt;p&gt;Data merge from .csv with tokens, image merge, and conditional logic&lt;/p&gt;
    &lt;head rend="h2"&gt;Canva AI Studio&lt;/head&gt;
    &lt;p&gt;Generative Fill, Expand, and Edit&lt;/p&gt;
    &lt;p&gt;Generate Images and Vectors&lt;/p&gt;
    &lt;p&gt;Remove Background and Subject Selection&lt;/p&gt;
    &lt;p&gt;Colorize, Depth Selection, and Super Resolution&lt;/p&gt;
    &lt;p&gt;Portrait Blur and Portrait Lighting&lt;/p&gt;
    &lt;p&gt;Full AI generation history&lt;/p&gt;
    &lt;head rend="h2"&gt;Need Affinity for your organization?&lt;/head&gt;
    &lt;p&gt;Skip the individual downloads and get your entire team on Affinity with SSO via a Canva Enterprise or Canva Districts account. Choose an option below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, Affinity really is free. That doesn‚Äôt mean you‚Äôre getting a watered-down version of the app though. You can use every tool in the Pixel, Vector, and Layout studios, plus all of the customization and export features, as much as you want, with no restrictions or payment needed. The app will also receive free updates with new features and improvements added.&lt;/p&gt;
        &lt;p&gt;If you‚Äôre on a Canva premium plan (Pro, Business, Enterprise, Education), you‚Äôll also be able to unlock Canva‚Äôs powerful AI tools within Affinity via the Canva AI Studio.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. Affinity is now brought to you by Canva, and your Canva account gives you access to Affinity and other Canva products and features.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No. You can access all of Affinity‚Äôs vector, layout, and pixel tools for free without a Canva subscription. If you‚Äôd like to unlock Canva AI tools within Affinity, however, you will need a premium Canva plan.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is a brand-new product that gives you advanced photo editing, graphic design, and page layout tools under one roof. It includes highly requested features such as Image Trace, ePub support, mesh gradients, hatch fills, live glitch filter, as well as custom capabilities that allow you to rearrange panels and combine tools to build your own unique studios. Plus, with a Canva premium plan, you can unlock incredibly powerful AI tools such as Generative Fill, Generative Expand, Generate Image/Vector, and more ‚Äî directly in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. With a Canva premium plan you can unlock Canva AI features in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, these are only available to those with Canva premium accounts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is currently available on Windows and macOS (iPadOS coming soon!).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We‚Äôre busy building our iPad version ‚Äî stay tuned for updates!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is optimized for the latest hardware, including Apple silicon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Absolutely! The new desktop version of Affinity can open all files created in Affinity V2 or V1 apps. However, Affinity V1 and V2 cannot open files that are created or saved in the newer app, Affinity by Canva.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, it‚Äôs the same app, just available on different operating systems.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, you can install Affinity on as many devices as you like.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes! It‚Äôs easy to import PSDs, AIs, IDMLs, DWGs, and other file types into Affinity, with structure, layers, and creative intent preserved.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is available in English, French, German, Italian, Spanish, Portuguese, Japanese, Chinese, Bahasa Indonesian, and Turkish. Keep an eye out for more languages coming soon!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Get in touch to speak to our team about how your organization can get set up with Affinity, including SSO.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Then all you need to do is stay in one of our pre-built studios: Pixel, Vector or Layout. You‚Äôll find all your favorite tools there, plus some new ones. Since it‚Äôs all free, just think of the other creative toolsets as an added bonus!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That‚Äôs totally fine. Your Affinity V2 license (via Serif) remains valid and Serif will continue to keep activation servers online. But please note that these apps won‚Äôt receive future updates.&lt;/p&gt;
        &lt;p&gt;For the best experience, we recommend using the new Affinity by Canva app.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;No. The new desktop version of Affinity can open all files created in V2, but older versions (including V2 on iPad) cannot open newer Affinity (.af) files, meaning you won‚Äôt be able to work across both platforms.&lt;/p&gt;&lt;lb/&gt;We don‚Äôt have a release date for the new Affinity on iPad yet, so recommend continuing to run V2 independently while you enjoy the new Affinity on desktop.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. The new Affinity by Canva app will receive free updates and new features over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You will need to be online to download and activate your license with your free Canva account. From then on, there is no requirement to be online, even with extended offline periods.&lt;/p&gt;
        &lt;p&gt;There are a couple of things to keep in mind:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;There are some features which do require you to be online, if you choose to use them, such as product help, lessons, stock libraries and integrations with Canva including AI tools.&lt;/item&gt;
          &lt;item&gt;We‚Äôll also be releasing new updates and patches regularly, so we recommend connecting from time to time to keep your app up to date, but it's not a requirement of use.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You need a Canva premium plan to unlock all of Canva‚Äôs AI features in Affinity. Simply download the Affinity app via our Downloads page and follow the prompts once you click ‚ÄòCanva AI Studio‚Äô.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761445</guid><pubDate>Thu, 30 Oct 2025 15:54:38 +0000</pubDate></item><item><title>How the cochlea computes (2024)</title><link>https://www.dissonances.blog/p/the-ear-does-not-do-a-fourier-transform</link><description>&lt;doc fingerprint="a63e213260f69383"&gt;
  &lt;main&gt;
    &lt;p&gt;Let‚Äôs talk about how the cochlea computes!&lt;/p&gt;
    &lt;p&gt;The tympanic membrane (eardrum) is vibrated by changes in air pressure (sound waves). Bones in the middle ear amplify and send these vibrations to the fluid-filled, snail-shaped cochlea. Vibrations travel through the fluid to the basilar membrane, which remarkably performs frequency separation1: the stiffer, lighter base resonates with high frequency components of the signal, and the more flexible, heavier apex resonates with lower frequencies. Between the two ends, the resonant frequencies decrease logarithmically in space2.&lt;/p&gt;
    &lt;p&gt;The hair cells on different parts of the basilar membrane wiggle back and forth at the frequency corresponding to their position on the membrane. But how do wiggling hair cells translate to electrical signals? This mechanoelectrical transduction process feels like it could be from a Dr. Seuss world: springs connected to the ends of hair cells open and close ion channels at the frequency of the vibration, which then cause neurotransmitter release. Bruno calls them ‚Äútrapdoors‚Äù. Here‚Äôs a visualization:&lt;/p&gt;
    &lt;p&gt;It‚Äôs clear that the hardware of the ear is well-equipped for frequency analysis. Nerve fibers serve as filters to extract temporal and frequency information about a signal. Below are examples of filters (not necessarily of the ear) shown in the time domain. On the left are filters that are more localized in time, i.e. when a filter is applied to a signal, it is clear when in the signal the corresponding frequency occurred. On the right are filters that have less temporal specificity, but are more uniformly distributed across frequencies compared to the left one.&lt;/p&gt;
    &lt;p&gt;Wouldn‚Äôt it be convenient if the cochlea were doing a Fourier transform, which would fit cleanly into how we often analyze signals in engineering? But no üôÖüèª‚ôÄÔ∏è! A Fourier transform has no explicit temporal precision, and resembles something closer to the waveforms on the right; this is not what the filters in the cochlea look like.&lt;/p&gt;
    &lt;p&gt;We can visualize different filtering schemes, or tiling of the time-frequency domain, in the following figure. In the leftmost box, where each rectangle represents a filter, a signal could be represented at a high temporal resolution (similar to left filters above), but without information about its constituent frequencies. On the other end of the spectrum, the Fourier transform performs precise frequency decomposition, but we cannot tell when in the signal that frequency occurred (similar to right filters)3. What the cochlea is actually doing is somewhere between a wavelet and Gabor. At high frequencies, frequency resolution is sacrificed for temporal resolution, and vice versa at low frequencies.&lt;/p&gt;
    &lt;p&gt;Why would this type of frequency-temporal precision tradeoff be a good representation? One theory, explored in Lewicki 2002, is that these filters are a strategy to reduce the redundancy in the representation of natural sounds. Lewicki performed independent component analysis (ICA) to produce filters maximizing statistical independence, comparing environmental sounds, animal vocalizations, and human speech. The tradeoffs look different for each one, and you can kind of map them to somewhere in the above cartoon.&lt;/p&gt;
    &lt;p&gt;It appears that human speech occupies a distinct time-frequency space. Some speculate that speech evolved to fill a time-frequency space that wasn‚Äôt yet occupied by other existing sounds.&lt;/p&gt;
    &lt;p&gt;To drive the theory home, one that we have been hinting at since the outset: forming ecologically-relevant representations makes sense, as behavior is dependent on the environment. It appears that for audition, as well as other sensory modalities, we are doing this. This is a bit of a teaser for efficient coding, which we will get to soon.&lt;/p&gt;
    &lt;p&gt;We‚Äôve talked about some incredible mechanisms that occur at the beginning of the sensory coding process, but it‚Äôs truly just the tiny tip of the ice burg. We also glossed over how these computations occur. The next lecture will zoom into the biophysics of computation in neurons.&lt;/p&gt;
    &lt;p&gt;We call this tonotopic organization, which is a mapping from frequency to space. This type of organization also exists in the cortex for other senses in addition to audition, such as retinotopy for vision and somatotopy for touch.&lt;/p&gt;
    &lt;p&gt;The relationship between human pitch perception and frequency is logarithmic. Coincidence? üòÆ&lt;/p&gt;
    &lt;p&gt;One could argue we should be comparing to a short-time Fourier transform, but this has resolution issues, and is still not what the cochlea appears to be doing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762259</guid><pubDate>Thu, 30 Oct 2025 17:01:20 +0000</pubDate></item><item><title>Minecraft HDL, an HDL for Redstone</title><link>https://github.com/itsfrank/MinecraftHDL</link><description>&lt;doc fingerprint="3271921d09773db1"&gt;
  &lt;main&gt;
    &lt;p&gt;Minecraft HDL is a digital synthesis flow for minecraft redstone circuits. It is an attempt to use industry standard design tools and methods to generate digital circuits with redstone.&lt;/p&gt;
    &lt;p&gt;This file &lt;code&gt;multiplexer4_1.v&lt;/code&gt; is a 6 input - 1 output circuit that selects one of the first 4 inputs (a, b, c, d) as the output based on the value of the last 2 inputs (x, y)&lt;/p&gt;
    &lt;code&gt;module multiplexer4_1 ( a ,b ,c ,d ,x ,y ,dout ); 
 
output dout ; 
input a, b, c, d, x, y; 
 
assign dout = (a &amp;amp; (~x) &amp;amp; (~y)) | 
     (b &amp;amp; (~x) &amp;amp; (y)) |  
     (c &amp;amp; x &amp;amp; (~y)) | 
     (d &amp;amp; x &amp;amp; y); 
endmodule &lt;/code&gt;
    &lt;p&gt;When synthesized through Minecraft HDL it produces this circuit:&lt;/p&gt;
    &lt;p&gt;With the 6 inputs on the right and the single output on the left&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screenshots &amp;amp; Sample Circuits&lt;/item&gt;
      &lt;item&gt;Getting Started - Installing and Using MinecraftHDL&lt;/item&gt;
      &lt;item&gt;Background Theory - Digital Design &amp;amp; Verilog&lt;/item&gt;
      &lt;item&gt;How MinecraftHDL Works - Read Our Paper&lt;/item&gt;
      &lt;item&gt;Developper Info - If you want to fork or contribute&lt;/item&gt;
      &lt;item&gt;Quick Overview - Check out our poster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MinecraftHDL was the final undergraduate design project made by three students in the Electrical, Computer &amp;amp; Software Engineering department at McGill University.&lt;/p&gt;
    &lt;p&gt;It is by no means bug-free or even complete; It produces objectively inferior circuits to 'hand-made' redstone designs, and is not intended to be used in modded survival. It can generate almost any verilog circuit, however only simple designs will actually be testable in-game since any moderately-complex design will end up being longer than the maximum number of blocks loaded in Minecraft.&lt;/p&gt;
    &lt;p&gt;Additionally, we are currently unable to synthesize sequential circuits, aka any circuits with a loopback or feedback. That means no memory, no counters or any circuit that could hold a state.&lt;/p&gt;
    &lt;p&gt;MinecraftHDL is an educational tool to illustrate on a macro-scopic scale how microelectronic digital circuits are designed and produced. It is a great way to introduce younger audiences to the world of digital design and can also be used to illustrate the difference between software and hardware design to undergraduate engineers taking their first RTL class.&lt;/p&gt;
    &lt;p&gt;Supervisor: Brett H. Meyer - Website&lt;lb/&gt; Students: Francis O'Brien - Website&lt;lb/&gt; Omar Ba Mashmos&lt;lb/&gt; Andrew Penhale&lt;/p&gt;
    &lt;p&gt;To show how easy it is to make a circuit with MinecraftHDL here is a gif of me creating a circuit, synthesizing, and generating it in minecraft in less than a minute!&lt;/p&gt;
    &lt;p&gt;The circuit I generate above is a 2bit adder. It takes two numbers of two bits and adds them. At the end of the gif I set both input numbers to '11' which is the binary representation of the number 3. Then I move to the output and we see that O3=1, O2=1, and O1=0, this gives the binary number '110' which is indeed 6.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763877</guid><pubDate>Thu, 30 Oct 2025 18:59:02 +0000</pubDate></item><item><title>Denmark reportedly withdraws Chat Control proposal following controversy</title><link>https://therecord.media/demark-reportedly-withdraws-chat-control-proposal</link><description>&lt;doc fingerprint="f3c7115416b5d37e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark reportedly withdraws Chat Control proposal following controversy&lt;/head&gt;
    &lt;p&gt;Denmark‚Äôs justice minister on Thursday said he will no longer push for an EU law requiring the mandatory scanning of electronic messages, including on end-to-end encrypted platforms.&lt;/p&gt;
    &lt;p&gt;Earlier in its European Council presidency, Denmark had brought back a draft law which would have required the scanning, sparking an intense backlash. Known as Chat Control, the measure was intended to crack down on the trafficking of child sex abuse materials (CSAM).&lt;/p&gt;
    &lt;p&gt;After days of silence, the German government on October 8 announced it would not support the proposal, tanking the Danish effort.&lt;/p&gt;
    &lt;p&gt;Danish Justice Minister Peter Hummelgaard told reporters on Thursday that his office will support voluntary CSAM detections.&lt;/p&gt;
    &lt;p&gt;"This will mean that the search warrant will not be part of the EU presidency's new compromise proposal, and that it will continue to be voluntary for the tech giants to search for child sexual abuse material," Hummelgaard said, according to local news reports.&lt;/p&gt;
    &lt;p&gt;The current model allowing for voluntary scanning expires in April, Hummelgaard said.&lt;/p&gt;
    &lt;p&gt;"Right now we are in a situation where we risk completely losing a central tool in the fight against sexual abuse of children,‚Äù he said. "That's why we have to act no matter what. We owe it to all the children who are subjected to monstrous abuse."&lt;/p&gt;
    &lt;p&gt;Meredith Whittaker, the president of the Signal Foundation, lobbied hard against the original measure, saying the organization would leave the European market if the provision was adopted.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat they propose is in effect a mass surveillance free-for-all, opening up everyone‚Äôs intimate and confidential communications, whether government officials, military, investigative journalists, or activists,‚Äù she said at the time.&lt;/p&gt;
    &lt;p&gt;Suzanne Smalley&lt;/p&gt;
    &lt;p&gt;is a reporter covering privacy, disinformation and cybersecurity policy for The Record. She was previously a cybersecurity reporter at CyberScoop and Reuters. Earlier in her career Suzanne covered the Boston Police Department for the Boston Globe and two presidential campaign cycles for Newsweek. She lives in Washington with her husband and three children.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765664</guid><pubDate>Thu, 30 Oct 2025 21:35:42 +0000</pubDate></item><item><title>Phone numbers for use in TV shows, films and creative works</title><link>https://www.acma.gov.au/phone-numbers-use-tv-shows-films-and-creative-works</link><description>&lt;doc fingerprint="c83d86dd4cb0f56b"&gt;
  &lt;main&gt;
    &lt;p&gt; On this page &lt;/p&gt;
    &lt;p&gt;Looking for info about unwanted calls? Learn more about phone scams and how you can make your number more private.&lt;/p&gt;
    &lt;head rend="h2"&gt;Geographical numbers&lt;/head&gt;
    &lt;p&gt;You can use the following prefixes and first 4 digits, then any 4 digits you like (shown here as 'xxxx').&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Region&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Number range&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Central East (covering NSW and ACT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(02) 5550 xxxx and (02) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;South East (covering VIC and TAS)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(03) 5550 xxxx and (03) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;North East (covering QLD)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(07) 5550 xxxx and (07) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Central West (covering SA, WA and NT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(08) 5550 xxxx and (08) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Mobile numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0491 570 006&lt;/item&gt;
      &lt;item&gt;0491 570 156&lt;/item&gt;
      &lt;item&gt;0491 570 157&lt;/item&gt;
      &lt;item&gt;0491 570 158&lt;/item&gt;
      &lt;item&gt;0491 570 159&lt;/item&gt;
      &lt;item&gt;0491 570 110&lt;/item&gt;
      &lt;item&gt;0491 570 313&lt;/item&gt;
      &lt;item&gt;0491 570 737&lt;/item&gt;
      &lt;item&gt;0491 571 266&lt;/item&gt;
      &lt;item&gt;0491 571 491&lt;/item&gt;
      &lt;item&gt;0491 571 804&lt;/item&gt;
      &lt;item&gt;0491 572 549&lt;/item&gt;
      &lt;item&gt;0491 572 665&lt;/item&gt;
      &lt;item&gt;0491 572 983&lt;/item&gt;
      &lt;item&gt;0491 573 770&lt;/item&gt;
      &lt;item&gt;0491 573 087&lt;/item&gt;
      &lt;item&gt;0491 574 118&lt;/item&gt;
      &lt;item&gt;0491 574 632&lt;/item&gt;
      &lt;item&gt;0491 575 254&lt;/item&gt;
      &lt;item&gt;0491 575 789&lt;/item&gt;
      &lt;item&gt;0491 576 398&lt;/item&gt;
      &lt;item&gt;0491 576 801&lt;/item&gt;
      &lt;item&gt;0491 577 426&lt;/item&gt;
      &lt;item&gt;0491 577 644&lt;/item&gt;
      &lt;item&gt;0491 578 957&lt;/item&gt;
      &lt;item&gt;0491 578 148&lt;/item&gt;
      &lt;item&gt;0491 578 888&lt;/item&gt;
      &lt;item&gt;0491 579 212&lt;/item&gt;
      &lt;item&gt;0491 579 760&lt;/item&gt;
      &lt;item&gt;0491 579 455&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Freephone and local rate numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1800 160 401&lt;/item&gt;
      &lt;item&gt;1800 975 707&lt;/item&gt;
      &lt;item&gt;1800 975 708&lt;/item&gt;
      &lt;item&gt;1800 975 709&lt;/item&gt;
      &lt;item&gt;1800 975 710&lt;/item&gt;
      &lt;item&gt;1800 975 711&lt;/item&gt;
      &lt;item&gt;1300 975 707&lt;/item&gt;
      &lt;item&gt;1300 975 708&lt;/item&gt;
      &lt;item&gt;1300 975 709&lt;/item&gt;
      &lt;item&gt;1300 975 710&lt;/item&gt;
      &lt;item&gt;1300 975 711&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765787</guid><pubDate>Thu, 30 Oct 2025 21:49:11 +0000</pubDate></item><item><title>Kimi Linear: An Expressive, Efficient Attention Architecture</title><link>https://github.com/MoonshotAI/Kimi-Linear</link><description>&lt;doc fingerprint="d7db9096ac4b9fd0"&gt;
  &lt;main&gt;
    &lt;p&gt;(a) On MMLU-Pro (4k context length), Kimi Linear achieves 51.0 performance with similar speed as full attention. On RULER (128k context length), it shows Pareto-optimal (84.3), performance and a 3.98x speedup. (b) Kimi Linear achieves 6.3x faster TPOT compared to MLA, offering significant speedups at long sequence lengths (1M tokens).&lt;/p&gt;
    &lt;p&gt;Kimi Linear is a hybrid linear attention architecture that outperforms traditional full attention methods across various contexts, including long,, short, and reinforcement learning (RL) scaling regimes. At it's core is Kimi Delta Attention (KDA)‚Äîa refined version of Gated DeltaNet that introduces a more efficient gating mechanism to optimize the use of finite-state RNN memory.&lt;/p&gt;
    &lt;p&gt;Kimi Linear achieves performance, superior and hardware efficiency, especially for long-context tasks. It reduces the need for large KV caches by up 75%, to and boosts decoding throughput by up to &lt;/p&gt;
    &lt;p&gt;We open-sourced the KDA kernel FLA,, in and released two versions model checkpoints trained with 5.7T tokens.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;#Total Params&lt;/cell&gt;
        &lt;cell role="head"&gt;#Activated Params&lt;/cell&gt;
        &lt;cell role="head"&gt;Context Length&lt;/cell&gt;
        &lt;cell role="head"&gt;Download Link&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Kimi-Linear-Base&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;ü§ó Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kimi-Linear-Instruct&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;ü§ó Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kimi Delta Attention (KDA): A linear attention mechanism that refines the gated delta rule with finegrained gating.&lt;/item&gt;
      &lt;item&gt;Hybrid Architecture: A 3:1 KDA-to-global MLA ratio reduces memory usage while maintaining or surpassing the quality of full attention.&lt;/item&gt;
      &lt;item&gt;Superior Performance: Outperforms full attention in a variety of tasks, long-context, including and RL-style benchmarks on 1.4T token training runs with fair comparisons.&lt;/item&gt;
      &lt;item&gt; High Throughput: Achieves up to &lt;math-renderer&gt;$6\times$&lt;/math-renderer&gt;decoding, faster and significantly reduces time per output token (TPOT).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To use the Kimi Linear model, we recommend the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: &lt;code&gt;python&lt;/code&gt;&amp;gt;= 3.10&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;torch&lt;/code&gt;&amp;gt;= 2.6&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;fla-core&lt;/code&gt;&amp;gt;= 0.4.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install -U fla-core&lt;/code&gt;
    &lt;p&gt;Example Code:&lt;/p&gt;
    &lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "moonshotai/Kimi-Linear-48B-A3B-Instruct"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

messages = [
    {"role": "system", "content": "You are a helpful assistant provided by Moonshot-AI."},
    {"role": "user", "content": "Is 123 a prime?"}
]
input_ids = tokenizer.apply_chat_template(
    messages, 
    add_generation_prompt=True, 
    return_tensors="pt"
).to(model.device)
generated_ids = model.generate(inputs=input_ids, max_new_tokens=500)
response = tokenizer.batch_decode(generated_ids)[0]
print(response)&lt;/code&gt;
    &lt;p&gt;For deployment, you can use the latest vllm to create an OpenAI-compatible API endpoint.&lt;/p&gt;
    &lt;code&gt;vllm serve moonshotai/Kimi-Linear-48B-A3B-Instruct \
  --port 8000 \
  --tensor-parallel-size 4 \
  --max-model-len 1048576 \
  --trust-remote-code&lt;/code&gt;
    &lt;p&gt;If you found our work useful, please cite&lt;/p&gt;
    &lt;code&gt;@misc{team2025kimi,
    title         = {Kimi Linear: An Expressive, Efficient Attention Architecture},
    author        = {Zhang, Yu  and Lin, Zongyu  and Yao, Xingcheng  and Hu, Jiaxi  and Meng, Fanqing  and Liu, Chengyin  and Men, Xin  and Yang, Songlin  and Li, Zhiyuan  and Li, Wentao  and Lu, Enzhe  and Liu, Weizhou  and Chen, Yanru  and Xu, Weixin  and Yu, Longhui  and Wang, Yejie  and Fan, Yu  and Zhong, Longguang  and Yuan, Enming  and Zhang, Dehao  and Zhang, Yizhi  and T. Liu, Y.  and Wang, Haiming  and Fang, Shengjun  and He, Weiran  and Liu, Shaowei  and Li, Yiwei  and Su, Jianlin  and Qiu, Jiezhong  and Pang, Bo  and Yan, Junjie  and Jiang, Zhejun  and Huang, Weixiao  and Yin, Bohong  and You, Jiacheng  and Wei, Chu  and Wang, Zhengtao  and Hong, Chao  and Chen, Yutian  and Chen, Guanduo  and Wang, Yucheng  and Zheng, Huabin  and Wang, Feng  and Liu, Yibo  and Dong, Mengnan  and Zhang, Zheng  and Pan, Siyuan  and Wu, Wenhao  and Wu, Yuhao  and Guan, Longyu  and Tao, Jiawen  and Fu, Guohong  and Xu, Xinran  and Wang, Yuzhi  and Lai, Guokun  and Wu, Yuxin  and Zhou, Xinyu  and Yang, Zhilin  and Du, Yulun},
    year          = {2025},
    eprint        = {2510.26692},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CL}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766937</guid><pubDate>Fri, 31 Oct 2025 00:07:36 +0000</pubDate></item><item><title>Show HN: Quibbler ‚Äì A critic for your coding agent that learns what you want</title><link>https://github.com/fulcrumresearch/quibbler</link><description>&lt;doc fingerprint="2c94ad61798f9efa"&gt;
  &lt;main&gt;
    &lt;p&gt;Quibbler is a critic for your coding agent. It runs in the background and critiques your coding agent's actions, either via hooks or an MCP. When your coding agent is once again failing in the same ways, or ignoring your spec, instead of having to prompt it, the Quibbler agent will automatically observe and correct it.&lt;/p&gt;
    &lt;p&gt;It will also learn rules from your usage, and then enforce them so you don't have to.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;We've found Quibbler useful in automatically preventing agents from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fabricating results without running commands&lt;/item&gt;
      &lt;item&gt;Not running tests or skipping verification steps&lt;/item&gt;
      &lt;item&gt;Not following your coding style and patterns&lt;/item&gt;
      &lt;item&gt;Hallucinating numbers, metrics, or functionality&lt;/item&gt;
      &lt;item&gt;Creating new patterns instead of following existing ones&lt;/item&gt;
      &lt;item&gt;Making changes that don't align with user intent&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Quibbler maintains context across reviews, learning your project's patterns and rules over time.&lt;/p&gt;
    &lt;p&gt;Using uv:&lt;/p&gt;
    &lt;code&gt;uv tool install quibbler&lt;/code&gt;
    &lt;p&gt;Using pip:&lt;/p&gt;
    &lt;code&gt;pip install quibbler&lt;/code&gt;
    &lt;p&gt;Quibbler supports two integration modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses Claude Code's hook system for event-driven monitoring&lt;/item&gt;
      &lt;item&gt;Passively observes all agent actions (tool use, prompts, etc.)&lt;/item&gt;
      &lt;item&gt;Fire-and-forget feedback injection via file writes&lt;/item&gt;
      &lt;item&gt;More powerful affordances but Claude Code-specific&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the Model Context Protocol for universal compatibility&lt;/item&gt;
      &lt;item&gt;Agent calls &lt;code&gt;review_code&lt;/code&gt;tool after making changes&lt;/item&gt;
      &lt;item&gt;Synchronous review with immediate feedback&lt;/item&gt;
      &lt;item&gt;Simple setup via MCP server configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose your mode and follow the appropriate setup instructions:&lt;/p&gt;
    &lt;p&gt;Add Quibbler to your agent's MCP server configuration.&lt;/p&gt;
    &lt;p&gt;For Cursor (&lt;code&gt;.cursor/mcp.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "mcpServers": {
    "quibbler": {
      "command": "quibbler mcp",
      "env": {
        "ANTHROPIC_API_KEY": "your-api-key-here"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;For other MCP-compatible agents: Refer to your agent's documentation for MCP server configuration.&lt;/p&gt;
    &lt;p&gt;Create or update &lt;code&gt;AGENTS.md&lt;/code&gt; in your project root to instruct your agent to use Quibbler:&lt;/p&gt;
    &lt;code&gt;## Code Review Process

After making code changes, you MUST call the `review_code` tool from the Quibbler MCP server with:

- `user_instructions`: The exact instructions the user gave you
- `agent_plan`: **A summary of the specific changes you made** (include which files were modified, what was added/changed, and key implementation details)
- `project_path`: The absolute path to this project

Review Quibbler's feedback and address any issues or concerns raised.

### Example

User asks: "Add logging to the API endpoints"

After implementing, call:

review_code(
user_instructions="Add logging to the API endpoints",
agent_plan="""Changes made:

1. Added logger configuration in config/logging.py
2. Updated routes/api.py to log incoming requests and responses
3. Added request_id middleware for tracing
4. Created logs/ directory with .gitignore""",
   project_path="/absolute/path/to/project"
   )&lt;/code&gt;
    &lt;p&gt;In a terminal, start the Quibbler hook server:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="your-api-key-here"
quibbler hook server
# Or specify a custom port:
quibbler hook server 8081&lt;/code&gt;
    &lt;p&gt;Keep this server running in the background. It will receive hook events from Claude Code.&lt;/p&gt;
    &lt;p&gt;In your project directory, run:&lt;/p&gt;
    &lt;code&gt;quibbler hook add&lt;/code&gt;
    &lt;p&gt;This creates or updates &lt;code&gt;.claude/settings.json&lt;/code&gt; with the necessary hooks to forward events to the Quibbler server.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;.claude/settings.json&lt;/code&gt; should now contain hooks that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Forward tool use events to Quibbler (&lt;code&gt;quibbler hook forward&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Display Quibbler feedback to the agent (&lt;code&gt;quibbler hook notify&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When Claude Code runs in this project, Quibbler will automatically observe and intervene when needed.&lt;/p&gt;
    &lt;p&gt;By default, Quibbler uses Claude Haiku 4.5 for speed. You can change this by creating or editing:&lt;/p&gt;
    &lt;p&gt;Global config (&lt;code&gt;~/.quibbler/config.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config (&lt;code&gt;.quibbler/config.json&lt;/code&gt; in your project):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config takes precedence over global config.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Your agent makes code changes, then calls the &lt;code&gt;review_code&lt;/code&gt;tool with user instructions and a summary of changes made&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent review agent per project that: &lt;list rend="ul"&gt;&lt;item&gt;Reviews the completed changes against user intent&lt;/item&gt;&lt;item&gt;Uses Read tool to examine the actual changed files and existing patterns in your codebase&lt;/item&gt;&lt;item&gt;Validates claims and checks for hallucinations&lt;/item&gt;&lt;item&gt;Verifies proper testing and verification steps were included&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Quibbler returns feedback or approval synchronously&lt;/item&gt;
      &lt;item&gt;Your agent addresses any issues found in the review&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Claude Code triggers hooks on events (tool use, prompt submission, etc.)&lt;/item&gt;
      &lt;item&gt;Hook events are forwarded to the Quibbler HTTP server&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent observer agent per session that: &lt;list rend="ul"&gt;&lt;item&gt;Passively watches all agent actions&lt;/item&gt;&lt;item&gt;Builds understanding of what the agent is doing&lt;/item&gt;&lt;item&gt;Intervenes when necessary by writing feedback to &lt;code&gt;.quibbler/{session_id}.txt&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Feedback is automatically displayed to the agent via the notify hook&lt;/item&gt;
      &lt;item&gt;The agent sees the feedback and can adjust its behavior&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both modes build understanding over time, learning your project's patterns and saving rules to &lt;code&gt;.quibbler/rules.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can customize Quibbler's system prompt by editing &lt;code&gt;~/.quibbler/prompt.md&lt;/code&gt;. The default prompt will be created on first run.&lt;/p&gt;
    &lt;p&gt;Project-specific rules in &lt;code&gt;.quibbler/rules.md&lt;/code&gt; are automatically loaded and added to the prompt.&lt;/p&gt;
    &lt;p&gt;Note for Hook Mode: Quibbler writes feedback to a message file that is intended for the agent to read and act on (though users have oversight and can see it). Your agent's system prompt should include a &lt;code&gt;{message_file}&lt;/code&gt; placeholder to tell Quibbler where to write its feedback. For example:&lt;/p&gt;
    &lt;code&gt;When you need to provide feedback to the agent, write it to {message_file}. This is agent-to-agent communication intended for the coding agent to read and act on.&lt;/code&gt;
    &lt;p&gt;If you notice an issue or bug, please open an issue. We welcome contributions - feel free to open a PR.&lt;/p&gt;
    &lt;p&gt;Join our community on Discord to discuss workflows and share experiences.&lt;/p&gt;
    &lt;p&gt;See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767162</guid><pubDate>Fri, 31 Oct 2025 00:43:57 +0000</pubDate></item><item><title>Roadmap for Improving the Type Checker</title><link>https://forums.swift.org/t/roadmap-for-improving-the-type-checker/82952</link><description>&lt;doc fingerprint="97a8d1dba2a69fd6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Roadmap for improving the type checker&lt;/head&gt;
      &lt;p&gt;In the past, we've released various "manifestos" and "roadmaps" to discuss planned improvements to the language. This post is also a roadmap of sorts, but instead, the focus is on the implementation rather than user-visible language changes (however, I will briefly mention a few potential language changes at the very end).&lt;/p&gt;
      &lt;p&gt;Specifically, I'm going to talk about some work we are doing to improve expression type checking in the Swift compiler. This includes changes that have already shipped in Swift 6.2, changes that are on the &lt;code&gt;main&lt;/code&gt; development branch, changes that we plan on working on next, and more tentative longer-term plans.&lt;/p&gt;
      &lt;p&gt;Before talking about specific improvements, I'm going to start with a rather long explanation of this part of the compiler implementation, which to my knowledge has not been summarized in one place yet.&lt;/p&gt;
      &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
      &lt;p&gt;This is all, of course, about the dreaded &lt;code&gt;the compiler is unable to type-check this expression in reasonable time&lt;/code&gt; error. This error can appear with both valid and invalid code, and the various workarounds are unsatisfactory, to say the least. Splitting up an expression into smaller pieces, introducing type annotations, or attempting other refactorings will sometimes allow valid code to type check, or in the invalid case, surface an actionable diagnostic. However, this breaks flow and becomes a frustrating process of trial and error "shotgun debugging" even for the most experienced Swift programmers. The compiler doesn't even tell you if your expression is valid or not!&lt;/p&gt;
      &lt;head rend="h3"&gt;Type-based overloading&lt;/head&gt;
      &lt;p&gt;Swift supports overloading, where multiple declarations in the same scope can share the same name. Swift allows two forms of overloading: by argument labels, or by type. The former case is ultimately handled by name lookup, because argument labels are specified at the call site. Argument label lookup does not introduce any algorithmic complexity in the type checker, so I won't discuss it further. Type-based overloading, on the other hand, requires the type checker to reason about the types of expressions before it can decide the correct overload to pick, which is a more difficult problem. So in the rest of this post, when I talk about overloading, I'm specifically referring to overloading based on types---either parameter or result types.&lt;/p&gt;
      &lt;head rend="h3"&gt;Constraint solving&lt;/head&gt;
      &lt;p&gt;The Swift compiler implements overload resolution by transforming expression type checking into a constraint solving problem. The compiler always looks at a single expression at a time (with some exceptions, such as multi-statement closures), and proceeds to type-check each expression in turn.&lt;/p&gt;
      &lt;p&gt;First, we introduce type variables to represent the unknown type of each sub-expression in the syntax tree. Next, we generate constraints to describe relationships among type variables. Examples of constraints include "type &lt;code&gt;X&lt;/code&gt; is a subtype of type &lt;code&gt;Y&lt;/code&gt;", "type &lt;code&gt;X&lt;/code&gt; is the result of calling function type &lt;code&gt;Y&lt;/code&gt; with arguments &lt;code&gt;Z&lt;/code&gt;", and crucially for overload resolution, what are called disjunction constraints. A disjunction constraint has the form "type &lt;code&gt;X&lt;/code&gt; is either &lt;code&gt;Y1&lt;/code&gt;, or &lt;code&gt;Y2&lt;/code&gt;, or &lt;code&gt;Y3&lt;/code&gt;, ... or &lt;code&gt;Yn&lt;/code&gt;", where each &lt;code&gt;Yn&lt;/code&gt; is the type of an overloaded declaration with the same name.&lt;/p&gt;
      &lt;p&gt;Once we have our type variables and constraints, we proceed to solve the constraint system by attempting to assign a concrete type to each type variable, in a manner that is consistent with the set of constraints. A set of such assignments is called a solution. The constraint solving process can produce zero, one, or many solutions. If no solution was found, the expression is erroneous. If one solution was found, we're done; if multiple solutions were found, we first attempt to rank the solutions in case one of them is clearly "better" than the others. If this ranking fails to produce a winner, we diagnose an ambiguity error.&lt;/p&gt;
      &lt;head rend="h3"&gt;Algorithmic complexity&lt;/head&gt;
      &lt;p&gt;The algorithmic complexity in constraint solving arises as a result of these disjunction constraints, because in the worst case, there is no better approach to solving such a constraint system except to attempt each combination of disjunction choices.&lt;/p&gt;
      &lt;p&gt;This is somewhat like solving a Sudoku. You can write down a number in a blank square, and then check that the result is a valid board. If it is, you try to fill in another square, and so on. On the other hand, if you get stuck, you backtrack by erasing a previously filled in square, and attempt to place a number somewhere else. If you're lucky and make perfect a guess at each step, you can fill in the whole board without backtracking. At the other extreme, you might end up attempting every possible path to a solution, which can take a long time.&lt;/p&gt;
      &lt;p&gt;For a more detailed overview of constraint solving in the Swift type checker, see swift/docs/TypeChecker.md at main ¬∑ swiftlang/swift ¬∑ GitHub. For an explanation of why overload resolution is inherently hard, and why every known approach has exponential running time in the worst case, see How does compiler compile SwiftUI code? - #4 by Slava_Pestov and Lambda Expressions vs. Anonymous Methods, Part Five | Microsoft Learn.&lt;/p&gt;
      &lt;head rend="h3"&gt;What does &lt;code&gt;reasonable time&lt;/code&gt; mean?&lt;/head&gt;
      &lt;p&gt;Since constraint solving with disjunctions takes exponential time in the worst case, it will always be possible to write down a short program that would require an inordinate amount of time to type check, so the type checker must limit the total amount of work that it does, and fail if this limit is reached.&lt;/p&gt;
      &lt;p&gt;The Swift type checker imposes two such limits:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Every time we attempt a disjunction choice, we increment a counter. The counter is reset to zero at the start of each expression, and if the value exceeds one million, we give up.&lt;/item&gt;
        &lt;item&gt;The constraint solver also allocates various data structures in a per-expression arena, which is then torn down in one shot once type checking this expression ends. If the total size of the arena exceeds 512 megabytes, we give up.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;In the past, Swift also had a wall-clock time limit, but this is no longer enabled by default, because it is non-deterministic across machines. Counting operations is a better approach, and most "too complex" expressions don't take longer than 4 seconds on a typical machine in practice.&lt;/p&gt;
      &lt;head rend="h3"&gt;Invalid expressions, salvage mode, and diagnostics&lt;/head&gt;
      &lt;p&gt;In ordinary type checking, the solver stops and backtracks immediately when a constraint fails, but this does not in itself produce precise error messages.&lt;/p&gt;
      &lt;p&gt;To get good diagnostics after a failure, we restart the solving process again, this time with an expanded search space. This is called "salvage mode." In salvage mode, a failure to solve a constraint is handled differently. Instead of simply failing the constraint and stopping the solver, we proceed as if the failed constraint succeeded, but we also record a fix.&lt;/p&gt;
      &lt;p&gt;For example, if an expression does not type-check because &lt;code&gt;Int&lt;/code&gt; does not conform to &lt;code&gt;Sequence&lt;/code&gt;, then this conformance constraint will fail on the first attempt. We then restart type checking in salvage mode. When the bogus constraint comes up again, we pretend that &lt;code&gt;Int&lt;/code&gt; actually does conform to &lt;code&gt;Sequence&lt;/code&gt;, but we record a fix, and continue solving more constraints until we're done.&lt;/p&gt;
      &lt;p&gt;Once we finish solving the constraint system in salvage mode, the collected fixes are then analyzed to produce a diagnostic. Finally, if salvage mode fails but no fixes are recorded, we emit the &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;For more details about the diagnostic architecture, see New Diagnostic Architecture Overview | Swift.org.&lt;/p&gt;
      &lt;head rend="h1"&gt;Goals and non-goals&lt;/head&gt;
      &lt;p&gt;While the worst case behavior is unavoidable, it does not have to be the case that type checking must take exponential time on all expressions, even when complex overload sets are involved. In fact, most expressions do type-check rather quickly, even today. It is also true that for any given single "hard" expression, it is possible to devise a heuristic that will solve it quickly, because in the extreme case, you can hard-code knowledge of that specific problem instance in the constraint solver (of course, we won't do that).&lt;/p&gt;
      &lt;p&gt;The main goal then, is to devise sufficiently-general heuristics which can quickly solve most realistic problem instances, without hard-coding too many special cases, so that hopefully, the exponential running time only appears with pathological examples which are unlikely to occur in practice. The primary way to accomplish this is to attempt disjunction choices in the right order---this includes both choosing the next disjunction to attempt, and the next choice within a disjunction to attempt. Also, we can avoid considering disjunction choices that lead to contradictions. By doing this, we can find the valid solutions more quickly, and spend less time exploring long "dead ends."&lt;/p&gt;
      &lt;p&gt;A secondary goal is to improve the auxiliary data structures and algorithms used in the constraint solver, so that even if an exhaustive search must be attempted on a given expression, as will sometimes be the case, we burn less CPU time while considering the same search space.&lt;/p&gt;
      &lt;p&gt;There are also two non-goals worth mentioning:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Removing overloading from the language. Without disjunction constraints, a constraint system can almost always be solved very quickly. However, this would be such a major change to the language, and break so many existing APIs, that it is not feasible to attempt at this point, even as a new language mode.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Removing bidirectional inference. We can also imagine a language design where expressions are type-checked in a strictly bottom-up fashion, starting from the leaves, like in many other C-family languages. This is another drastic simplification that essentially trivializes the whole problem. However, this would require giving up on language features such as polymorphic literals, leading-dot member syntax, closures with inferred types, and parts of generics. All of these are features that make Swift into the expressive language it is today.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h1"&gt;Recent improvements&lt;/head&gt;
      &lt;head rend="h2"&gt;Swift 6.2&lt;/head&gt;
      &lt;p&gt;In Swift 6.2, we spent time profiling the type checker with various larger projects, as well as individual slow expressions, both valid and invalid. This uncovered some bottlenecks, including with the backtracking implementation, various graph algorithms such as computing connected components, and other miscellaneous algorithms.&lt;/p&gt;
      &lt;p&gt;The first example is an invalid expression where we can see a small improvement. Consider the last line of the below code listing, which appeared in this blog post:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;let address = "127.0.0.1"
let username = "steve"
let password = "1234"
let channel = 11

let url = "http://" + username 
            + ":" + password 
            + "@" + address 
            + "/api/" + channel 
            + "/picture"
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The expression is invalid as written, because there is no overload of &lt;code&gt;+&lt;/code&gt; taking an &lt;code&gt;Int&lt;/code&gt; and a &lt;code&gt;String&lt;/code&gt;. On my machine, Swift 6.1 spends 10 seconds to produce an &lt;code&gt;unable to type-check&lt;/code&gt; error, while in Swift 6.2, we get the same error in 6 seconds. Of course, this is not the desired end state, since we should instead produce a meaningful diagnostic. However, this example specifically illustrates that the type checker is able to do the same amount of work in less time.&lt;/p&gt;
      &lt;p&gt;For a more realistic example, I measured a project that makes heavy use of overloading and generics, and saw that total type checking time improved from 42 seconds in Swift 6.1, down to 34 seconds in Swift 6.2.&lt;/p&gt;
      &lt;head rend="h2"&gt;Swift 6.3&lt;/head&gt;
      &lt;head rend="h3"&gt;Optimized disjunction selection&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots introduced a large set of changes that @xedin has been working on for several years now, to improve disjunction selection, by collecting more information to decide what disjunction should be attempted next. Unlike the targeted optimizations in Swift 6.2 which offered incremental wins without reducing the fundamental complexity of the problem, the disjunction selection changes allow the type checker to quickly solve many expressions that we were formerly unable to type-check. The new algorithm can also drastically speed up expressions that would type check, but were just under the limit and thus slow.&lt;/p&gt;
      &lt;p&gt;These changes replace some older optimizations that would look at the entire expression before solving begins, to attempt "pre-solving" certain sub-expressions. These hacks were rather brittle in practice, so a small change to an expression could defeat the entire hack.&lt;/p&gt;
      &lt;p&gt;The optimized disjunction selection algorithm instead runs as part of the constraint solver, making it more robust and predictable. The biggest wins can be seen with expressions that involve math operators and literals. Here is a typical example. The Swift 6.2 compiler was unable to type check the below expression, but the compiler from &lt;code&gt;main&lt;/code&gt; type checks this successfully, in 4 milliseconds:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;func test(n: Int) -&amp;gt; Int {
  return n == 0 ? 0 : (0..&amp;lt;n).reduce(0) { x, y in
    (x &amp;gt; 0 &amp;amp;&amp;amp; y % 2 == 0) ? (((x + y) - (x + y)) / (y - x)) + ((x + y) / (y - x)) : x
  }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The invalid expression from above, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, is still rejected, however with the new algorithm, it only takes the compiler 2 seconds to reach the limit.&lt;/p&gt;
      &lt;p&gt;Finally, on the same project I mentioned in the Swift 6.2 summary above, the new algorithm yields a further reduction in total type checking time, down to 12 seconds.&lt;/p&gt;
      &lt;p&gt;(If you find an expression that type checks on a released version of Swift but fails on a &lt;code&gt;main&lt;/code&gt; development snapshot, please file a GitHub issue.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Optimized constraint solver arena usage&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots also introduce an optimization which eliminates a source of exponential space usage in the constraint solver. This optimization is still disabled by default, but we hope to enable it soon. (You can enable it with the &lt;code&gt;-solver-enable-prepared-overloads&lt;/code&gt; frontend flag on a &lt;code&gt;main&lt;/code&gt; development snapshot if you'd like to test it now.)&lt;/p&gt;
      &lt;p&gt;This optimization works as follows. Previously, when attempting a disjunction choice for a generic overload, the solver would generate new type variables and constraints corresponding to the generic parameters and &lt;code&gt;where&lt;/code&gt; clause requirements of the generic overload. If the same overload had to be attempted multiple times, in combination with other overload choices, the same type variables and constraints would be generated every time. These type variables and constraints are allocated in the constraint solver's arena. This space optimization instead allocates these structures once, the first time a disjunction choice is attempted.&lt;/p&gt;
      &lt;p&gt;For many expressions, this leads to a drastic reduction in constraint solver arena usage. In some instances, it will transform an exponential space problem into a polynomial space problem, even if it still requires exponential time. Furthermore, since less space also means less time, the primary benefit here is again a reduction in total type checking time. In the future, pre-generating these structures will also enable further improvements to the disjunction choice algorithm.&lt;/p&gt;
      &lt;p&gt;On the invalid expression from earlier, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, the constraint solver arena space optimization further reduces the time to reach the limit, down to 1.7 seconds. (That's a more than 5x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;p&gt;Finally, with the same test project I mentioned twice above, this optimization decreases total type checking time from 12 seconds, down to 10 seconds. (That's a more than 4x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Expanding our test suite to cover more fast and slow expressions&lt;/head&gt;
      &lt;p&gt;To help prevent performance regressions in the future, and to track progress on solving the problem, we have added more test cases to our suite. These have been reduced from user-reported slow expressions in GitHub issues for the Swift project.&lt;/p&gt;
      &lt;p&gt;Some of the test cases also use our &lt;code&gt;scale-test&lt;/code&gt; tool, which repeats a common element of an expression (think adding &lt;code&gt;+ 1 + 1 + 1 ...&lt;/code&gt;), measures the performance of each instance, and then attempts to guess if the resulting problem scales in polynomial or exponential time. This helps catch more subtle issues where a given expression might still appear to be "fast", but becomes slow if you make it just a little bit longer.&lt;/p&gt;
      &lt;p&gt;These test cases are found in the validation-test/Sema/type_checker_perf directory in the Swift repo. The recently added test cases are in Sema: Collected expression checking performance test cases from GitHub issues by slavapestov ¬∑ Pull Request #84450 ¬∑ swiftlang/swift ¬∑ GitHub, with a few more in Even more type checker perf tests by slavapestov ¬∑ Pull Request #84890 ¬∑ swiftlang/swift ¬∑ GitHub. We hope to continue expanding the type checker performance test suite over time.&lt;/p&gt;
      &lt;head rend="h1"&gt;Future improvements&lt;/head&gt;
      &lt;p&gt;Disclaimer: all of the below is subject to change as our plans evolve.&lt;/p&gt;
      &lt;head rend="h2"&gt;Optimizing bindings&lt;/head&gt;
      &lt;p&gt;Imagine we're solving a constraint system, and we're left with a single unsolved constraint, a conversion from a type variable &lt;code&gt;T0&lt;/code&gt; to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. At this point, in order to proceed, we must "guess" the concrete type to bind to &lt;code&gt;T0&lt;/code&gt;. While &lt;code&gt;T0&lt;/code&gt; might just be &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;, another valid choice is &lt;code&gt;Int&lt;/code&gt;, because &lt;code&gt;Int&lt;/code&gt; converts to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. The bindings subsystem in the constraint solver is responsible for tracking the potential bindings for each type variable by considering unsolved conversion constraints, and ultimately, attempting various potential bindings until a solution is found.&lt;/p&gt;
      &lt;p&gt;The book-keeping for bindings is rather complicated, and must be updated incrementally as constraints are solved and new constraints are introduced. Another complication is that to choose the next binding to attempt, we must consider all type variables and all of their potential bindings, and rank them according to a heuristic.&lt;/p&gt;
      &lt;p&gt;Today, this ranking process indeed considers all type variables and all bindings, and ultimately picks just one type variable and just one binding to attempt. This must be repeated for each unbound type variable, which of course results in a quadratic time algorithm.&lt;/p&gt;
      &lt;p&gt;Thus, even in a constraint system without a large number of complex overloads, it is sometimes possible to observe algorithmic complexity due to bindings. Now, most expressions do not involve a large number of type variables---it is far more common to see a large number of disjunction choices instead. But one situation where a large number of type variables are generated is if you write an array or dictionary literal with a large number of elements.&lt;/p&gt;
      &lt;p&gt;We plan on overhauling the data structures for tracking potential bindings, both to eliminate some duplicate bookkeeping (&lt;code&gt;BindingSet&lt;/code&gt; and &lt;code&gt;PotentialBindings&lt;/code&gt; in the implementation) and to make the choice of the next binding to attempt something that can be done in constant or logarithmic time, instead of the current situation where it is linear in the number of type variables. This will radically speed up the type checking of large array and dictionary literals.&lt;/p&gt;
      &lt;p&gt;Since solving constraints can introduce new bindings, an important decision problem is whether a binding set is "complete". Today, this check is very conservative, so we often don't attempt bindings until we've gone far down a path of disjunction choices. More accurate computation of when a binding set is complete would allow bindings to be attempted sooner, which would reduce algorithmic complexity of type-checking many common expressions.&lt;/p&gt;
      &lt;p&gt;Another improvement to the bindings logic would allow the solver to reach a contradiction by considering contradictory bindings. Today, if a type variable &lt;code&gt;T0&lt;/code&gt; is subject to two conversion constraints, for example to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, we don't reach a contradiction until we attempt every possible concrete type for &lt;code&gt;T0&lt;/code&gt;. But in this case, there is no concrete type that converts to both &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, and so a contradiction could be reached faster, avoiding wasting time exploring dead ends.&lt;/p&gt;
      &lt;p&gt;These improvements to the binding logic should speed up many expressions, including long collection literals as I mentioned, and also the aforesaid invalid expression where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, where we should finally be able to quickly produce an actionable diagnostic.&lt;/p&gt;
      &lt;head rend="h2"&gt;Removing more performance hacks&lt;/head&gt;
      &lt;p&gt;While the new disjunction selection algorithm subsumed many old performance hacks, some hacks remain. Once again, these hacks tend to be applicable in narrow cases only, which introduces performance cliffs when small changes are made to an expression, and they also have "load-bearing" semantic effects which complicate the language model. These will be generalized or subsumed by existing optimizations over time.&lt;/p&gt;
      &lt;p&gt;It's worth noting that fixing some of these might be source-breaking in extreme edge cases, but we think this is worth the small inconvenience it may cause. Aside from improving performance, this will make the language semantics easier to reason about, and also improve diagnostics.&lt;/p&gt;
      &lt;p&gt;To make this more concrete, here are a few random examples of hacks that we hope to eliminate:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Subscripting of &lt;code&gt;Array&lt;/code&gt; and &lt;code&gt;Dictionary&lt;/code&gt; types is handled in a special way, with a narrow optimization that dates back all the way to Swift 1.0 (&lt;code&gt;inferCollectionSubscriptResultType()&lt;/code&gt;). It can result in strange overload resolution behavior in some cases, and of course it doesn't generalize to subscripts on user-defined types.&lt;/item&gt;
        &lt;item&gt;When simplifying a function call constraint, we look for the case where all overloads have a common return type (&lt;code&gt;simplifyAppliedOverloadsImpl()&lt;/code&gt;). This does not handle generic return types at all, and has some strange edge-case behaviors.&lt;/item&gt;
        &lt;item&gt;There is an optimization that kicks in when a generic overload set has exactly two overloads (&lt;code&gt;tryOptimizeGenericDisjunction()&lt;/code&gt;). This is an obvious performance cliff if a third overload is added, even if its not used in the expression.&lt;/item&gt;
        &lt;item&gt;A set of optimizations attempt to skip some disjunction choices entirely, and "partition" overload sets for math operators into generic, concrete, and SIMD overloads. This is too specific to math operators, and again leads to strange behavior where a concrete overload is chosen even though a generic overload would result in better solutions or diagnostics.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Optimizing the handling of partial solutions&lt;/head&gt;
      &lt;p&gt;One of the steps in our constraint solver algorithm constructs a constraint graph, where the vertices are type variables, and the edges relate each pair of type variables that appear in the same constraint. An important optimization detects a situation where this graph has more than one connected component, in which case each component can be solved independently. The "partial solutions" that we obtain from solving each component are then merged to form a solution for the overall constraint system.&lt;/p&gt;
      &lt;p&gt;In many situations, this can avoid exponential behavior. However, in other situations where a large number of partial solutions are produced, building the data structures representing these partial solutions, and the merging algorithm itself, can dominate type checking time for a given expression.&lt;/p&gt;
      &lt;p&gt;By building upon the "trail" data structure for speeding up backtracking that was introduced in Swift 6.2, we hope to reduce the overhead caused by partial solutions in those pathological cases. A specific class of expression where this tends to arise is when you have a large collection literal and each element is itself a complex expression.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improving salvage mode&lt;/head&gt;
      &lt;p&gt;While not strictly performance-related, we would also like to eliminate more cases where salvage mode fails to record any fixes, which as I mentioned above, results in the unhelpful &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;In fact, another odd situation can arise with salvage mode today: there are known examples where normal type checking fails, but salvage mode then succeeds, in which case we accept the expression. This is a performance problem right off the bat, because such an expression must essentially be type checked twice before a solution is found, even though it is valid.&lt;/p&gt;
      &lt;p&gt;This is also not intended by design, and it involves certain corners of the language which are not well-understood or tested. Fixing these situations will improve performance in pathological cases, while also cleaning up these edge cases in the language, and improving test coverage. Ultimately, if salvage succeeds in this way, we plan to have the solver emit another "fallback diagnostic" instead of silently proceeding.&lt;/p&gt;
      &lt;p&gt;Finally, if normal type-checking produces multiple valid solutions, we still enter salvage mode today, before we generate an ambiguity diagnostic. This should not be necessary, and addressing this will speed up diagnostics for certain invalid ambiguous expressions. This will also reduce the probability that salvage mode, which must do more work by design, will then fail with an "unable to type-check" error, instead of emitting an actionable diagnostic using information already gleaned from normal type checking.&lt;/p&gt;
      &lt;head rend="h1"&gt;Longer-term future improvements&lt;/head&gt;
      &lt;p&gt;I'm going to end this post with more tentative ideas, that while not fully fleshed out, have the potential drastically improve type checking performance.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to operator lookup&lt;/head&gt;
      &lt;p&gt;So far, I've only talked about changes which are (mostly) source-compatible, and this has been our main focus to date. However, while we've ruled out drastic solutions such as removing overloading or bidirectional inference entirely, we are considering some more targeted language changes, which would be rolled out with upcoming features or language modes.&lt;/p&gt;
      &lt;p&gt;Consider the &lt;code&gt;==&lt;/code&gt; operator. This operator is heavily-overloaded, but most overloads are implementations of the &lt;code&gt;Equatable&lt;/code&gt;  protocol's &lt;code&gt;==&lt;/code&gt; requirement. In principle, we could avoid attempting each one in turn, simplifying the constraint system that we generate for any expression that involves &lt;code&gt;==&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;We plan to investigate a scheme where we prune overload sets to hide overloads that witness a protocol requirement, which will simplify overload sets for &lt;code&gt;==&lt;/code&gt; as well as many other (but not all) operators.&lt;/p&gt;
      &lt;p&gt;This will require changing the rules for solution ranking, which today always prefer concrete overloads; however, we will need to prefer the generic &lt;code&gt;Equatable.==&lt;/code&gt; overload in many instances as well. For this reason, such a change might be slightly source breaking, at least in pathological cases, but it might be possible to stage in a way that avoids disruption for realistic programs.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to polymorphic literals&lt;/head&gt;
      &lt;p&gt;A common misconception is that polymorphic literals, like integers and strings, themselves introduce overloads, where every concrete type conforming to an &lt;code&gt;ExpressibleBy*&lt;/code&gt; protocol adds a disjunction choice to the literal. This isn't quite right; a literal such as &lt;code&gt;"hello world"&lt;/code&gt; will type check if a concrete type is known from the surrounding code, and if that fails, via a default type, which is &lt;code&gt;String&lt;/code&gt; in this case. So while this acts as a disjunction of sorts, in this case the disjunction only has two choices, and often the default is not attempted at all.&lt;/p&gt;
      &lt;p&gt;However, an integer literal such as &lt;code&gt;123&lt;/code&gt; actually has two default types, &lt;code&gt;Int&lt;/code&gt; and &lt;code&gt;Double&lt;/code&gt;, and the resulting disjunction has three choices. It might be worth considering a language change where floating point literals must be spelled with a decimal point. Today, expressions involving mixed integer and double literals can be particularly tricky to type check, for this reason.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improved constraint solving techniques&lt;/head&gt;
      &lt;p&gt;Once we are further along with various refactorings and cleanups described above, we will be in a position to implement more advanced constraint solving techniques, such as those commonly used in SAT solvers today. "SAT," or Boolean formula satisfiability, is a related problem to operator overloading. (Like overload resolution, SAT takes exponential time to solve in the worst case, but unlike overload resolution, the "domain" of each type variable is a true or false value. Instead of "constraints", the problem instance consists of a Boolean formula built up from "and", "or", and "not" operations.) Many of the techniques used to speed up SAT solvers can be applied to constraint solving.&lt;/p&gt;
      &lt;p&gt;A solver that supports non-chronological backtracking can jump back over more than one disjunction choice once it detects a contradiction. This avoids the exploration of more dead-ends that necessarily fail, because some constraint further up is already unsatisfiable.&lt;/p&gt;
      &lt;p&gt;Another technique is clause learning. The "naive" approach to constraint solving will discard all state changes when backtracking after a contradiction is discovered. In a solver with clause learning, the algorithm will, roughly speaking, "learn" facts as it goes, recording new constraints that result from backtracking. This ensures that if the same situation arises again, the contradiction can be detected sooner because of the "learned" constraint.&lt;/p&gt;
      &lt;p&gt;(For those curious to learn more about SAT solvers, here is a blog post I saw the other day with a good summary: SATisfying Solutions to Difficult Problems! - Vaibhav Sagar. A book with a decent introduction is "The Satisfiability Problem" by Sch√≥ning and Tor√°n. An in-depth treatment appears in Knuth Volume 4B. Finally, a recent academic paper titled The simple essence of overloading by Bene≈° and Brachth√§user, outlines an interesting approach to overload resolution where the problem is reduced to a binary decision diagram. Some of the ideas here may apply to Swift type checking as well.)&lt;/p&gt;
      &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
      &lt;p&gt;There are quite a number of interesting improvements that can be made to the Swift type checker, and we look forward to sharing more updates as we make progress in this area.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767257</guid><pubDate>Fri, 31 Oct 2025 01:00:45 +0000</pubDate></item><item><title>John Carmack on mutable variables</title><link>https://twitter.com/id_aa_carmack/status/1983593511703474196</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info ¬© 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767725</guid><pubDate>Fri, 31 Oct 2025 02:34:36 +0000</pubDate></item><item><title>AMD Could Enter ARM Market with Sound Wave APU Built on TSMC 3nm Process</title><link>https://www.guru3d.com/story/amd-enters-arm-market-with-sound-wave-apu-built-on-tsmc-3nm-process/</link><description>&lt;doc fingerprint="4bd2c55e4231494e"&gt;
  &lt;main&gt;
    &lt;p&gt;According to leaks from industry insiders such as @Moore‚Äôs Law Is Dead and @KeplerL2, ‚ÄúSound Wave‚Äù is manufactured on TSMC‚Äôs 3 nm node and aims for a 5 W to 10 W TDP range, positioning it directly against Qualcomm‚Äôs Snapdragon X Elite. The chip is expected to power future Microsoft Surface products scheduled for release in 2026. ‚ÄúSound Wave‚Äù reportedly adopts a 2 + 4 hybrid core design, consisting of two performance and four efficiency cores, paired with 4 MB of L3 cache and 16 MB of MALL cache, a memory technology inspired by the ‚ÄúInfinity Cache‚Äù used in AMD‚Äôs Radeon GPUs. This configuration is relatively uncommon in low-power APUs and aims to improve responsiveness and multitasking under constrained thermal conditions. On the graphics side, the processor integrates four RDNA 3.5 compute units, offering light gaming support and optimized machine learning acceleration.&lt;/p&gt;
    &lt;p&gt;Memory support is another highlight: the chip integrates a 128-bit LPDDR5X-9600 controller and will reportedly include 16 GB of onboard RAM, aligning with current trends in unified memory designs used in ARM SoCs. Additionally, the APU carries AMD‚Äôs fourth-generation AI engine, enabling on-device inference tasks and enhanced efficiency for workloads such as speech recognition, image analysis, and real-time translation.&lt;/p&gt;
    &lt;p&gt;While AMD experimented with ARM over a decade ago through the abandoned ‚ÄúProject Skybridge,‚Äù this new effort represents a more mature and strategic approach. With industry interest in efficient, ARM-based computing accelerating, ‚ÄúSound Wave‚Äù could help AMD diversify its portfolio while leveraging its strengths in graphics and AI acceleration. If reports are accurate, the processor will enter production in late 2025, with commercial devices expected the following year.&lt;/p&gt;
    &lt;p&gt;Source: ithome&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767916</guid><pubDate>Fri, 31 Oct 2025 03:07:48 +0000</pubDate></item><item><title>Show HN: A fast, dependency-free traceroute implementation in pure C</title><link>https://github.com/davidesantangelo/fastrace</link><description>&lt;doc fingerprint="ec9df85c5a3af9ce"&gt;
  &lt;main&gt;
    &lt;p&gt;A high-performance, dependency-free traceroute implementation in pure C.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully non-blocking architecture driven by &lt;code&gt;poll()&lt;/code&gt;for faster ICMP draining&lt;/item&gt;
      &lt;item&gt;Monotonic timing pipeline for sub-millisecond RTT accuracy&lt;/item&gt;
      &lt;item&gt;Runtime tuning via CLI flags for hops, probes, concurrency, and timeouts&lt;/item&gt;
      &lt;item&gt;Reverse DNS cache with optional suppression (&lt;code&gt;-n&lt;/code&gt;) to optimise lookups&lt;/item&gt;
      &lt;item&gt;Expanded socket buffers and smarter probe scheduling for lower latency traces&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastrace is a blazingly fast traceroute utility designed for network diagnostics and performance analysis. It maps the route that packets take across an IP network from source to destination, providing detailed timing information and identifying potential bottlenecks or routing issues.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero External Dependencies: Relies solely on standard C libraries and system calls&lt;/item&gt;
      &lt;item&gt;Maximum Performance: Event-driven pipeline with parallel probing and non-blocking IO&lt;/item&gt;
      &lt;item&gt;Low Memory Footprint: Uses compact data structures with tight allocations sized to the trace&lt;/item&gt;
      &lt;item&gt;Dual Socket Implementation: Uses UDP for probes and raw sockets for response capture&lt;/item&gt;
      &lt;item&gt;Visual Route Mapping: Displays network topology with a structured, tree-like representation&lt;/item&gt;
      &lt;item&gt;Runtime Tunability: Allows hop count, probe volume, concurrency, and DNS behaviour to be adjusted live&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastrace uses two socket types for maximum effectiveness:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UDP socket (&lt;code&gt;SOCK_DGRAM&lt;/code&gt;) for sending probe packets&lt;/item&gt;
      &lt;item&gt;Raw ICMP socket (&lt;code&gt;SOCK_RAW&lt;/code&gt;) for receiving router responses&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;send_sock = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);
recv_sock = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP);&lt;/code&gt;
    &lt;p&gt;Each probe is tracked using a specialized structure:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    int ttl;                /* Time-to-Live value */
    int probe;              /* Probe sequence number */
    struct timeval sent_time; /* Timestamp when sent */
    int received;           /* Whether response was received */
    struct in_addr addr;    /* Address of responding hop */
    double rtt;             /* Round-trip time in ms */
    int port;              /* UDP port used for this probe */
} probe_t;&lt;/code&gt;
    &lt;p&gt;Fastrace implements a configurable multi-TTL probing system that keeps several hops "in flight" simultaneously. The concurrency window can be tuned at runtime (&lt;code&gt;-c &amp;lt;count&amp;gt;&lt;/code&gt;), enabling the tracer to saturate available ICMP feedback channels without overwhelming links.&lt;/p&gt;
    &lt;p&gt;The response processor relies on a &lt;code&gt;poll()&lt;/code&gt;-driven event loop and non-blocking sockets to eagerly drain ICMP bursts while avoiding idle busy-waiting:&lt;/p&gt;
    &lt;code&gt;struct pollfd pfd = { .fd = recv_sock, .events = POLLIN | POLLERR };
if (poll(&amp;amp;pfd, 1, config.wait_timeout_ms) &amp;gt; 0) {
    drain_icmp_socket();
}&lt;/code&gt;
    &lt;p&gt;Fastrace implements precise handling of network protocols:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UDP Probes: Sending UDP packets with incrementing TTL values&lt;/item&gt;
      &lt;item&gt;TTL Management: Systematic incrementing of TTL values to discover route hops&lt;/item&gt;
      &lt;item&gt;ICMP Response Processing: Parsing ICMP responses from routers&lt;/item&gt;
      &lt;item&gt;Port-based Probe Identification: Using unique ports to match responses to probes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastrace provides a structured visual representation of network paths:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tree-like format shows branching at load-balanced routes&lt;/item&gt;
      &lt;item&gt;Clear arrows indicate path progression&lt;/item&gt;
      &lt;item&gt;Distinct formatting for primary and alternative routes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Non-blocking sockets combined with &lt;code&gt;poll()&lt;/code&gt; wakeups eliminate unnecessary sleeps and react instantly to bursts of ICMP replies.&lt;/p&gt;
    &lt;p&gt;Probe cadence is tuned via &lt;code&gt;config.probe_delay_us&lt;/code&gt; and the runtime &lt;code&gt;-q&lt;/code&gt; option, letting users increase sample density when needed without recompilation.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;clock_gettime(CLOCK_MONOTONIC)&lt;/code&gt; powers RTT measurements and hop deadlines, delivering microsecond precision unaffected by system clock changes.&lt;/p&gt;
    &lt;p&gt;Designed to be compiled with aggressive optimization flags:&lt;/p&gt;
    &lt;code&gt;gcc -O3 -o fastrace fastrace.c
&lt;/code&gt;
    &lt;p&gt;A lightweight reverse DNS cache prevents repeated &lt;code&gt;PTR&lt;/code&gt; lookups for load-balanced hops, cutting latency and reducing resolver load.&lt;/p&gt;
    &lt;p&gt;Fastrace significantly outperforms standard traceroute in several key metrics:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Standard Traceroute&lt;/cell&gt;
        &lt;cell role="head"&gt;Fastrace&lt;/cell&gt;
        &lt;cell role="head"&gt;Improvement&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Total trace time (30 hops)&lt;/cell&gt;
        &lt;cell&gt;~15-20 seconds&lt;/cell&gt;
        &lt;cell&gt;~5-8 seconds&lt;/cell&gt;
        &lt;cell&gt;60-70% faster&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Memory usage&lt;/cell&gt;
        &lt;cell&gt;~400-600 KB&lt;/cell&gt;
        &lt;cell&gt;~120-150 KB&lt;/cell&gt;
        &lt;cell&gt;70-75% less memory&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CPU utilization&lt;/cell&gt;
        &lt;cell&gt;5-8%&lt;/cell&gt;
        &lt;cell&gt;2-3%&lt;/cell&gt;
        &lt;cell&gt;60% less CPU&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Packet efficiency&lt;/cell&gt;
        &lt;cell&gt;1 TTL at a time&lt;/cell&gt;
        &lt;cell&gt;Up to 5 TTLs concurrently&lt;/cell&gt;
        &lt;cell&gt;5x throughput&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Response waiting&lt;/cell&gt;
        &lt;cell&gt;Fixed timeouts&lt;/cell&gt;
        &lt;cell&gt;Adaptive timeouts&lt;/cell&gt;
        &lt;cell&gt;Better adaptation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Visual clarity&lt;/cell&gt;
        &lt;cell&gt;Flat output&lt;/cell&gt;
        &lt;cell&gt;Hierarchical tree view&lt;/cell&gt;
        &lt;cell&gt;Improved readability&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;RTT accuracy&lt;/cell&gt;
        &lt;cell&gt;Variable&lt;/cell&gt;
        &lt;cell&gt;Highly accurate&lt;/cell&gt;
        &lt;cell&gt;Matches standard tools&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Operating System: Linux, macOS, or other Unix-like systems with raw socket support&lt;/item&gt;
      &lt;item&gt;Permissions: Root/sudo access required (raw sockets)&lt;/item&gt;
      &lt;item&gt;Compiler: GCC with C99 support or later&lt;/item&gt;
      &lt;item&gt;Architecture: x86, x86_64, ARM, or any platform with standard C library support&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;time.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;sys/socket.h&amp;gt;
#include &amp;lt;sys/types.h&amp;gt;
#include &amp;lt;netinet/in.h&amp;gt;
#include &amp;lt;netinet/ip.h&amp;gt;
#include &amp;lt;netinet/ip_icmp.h&amp;gt;
#include &amp;lt;netinet/udp.h&amp;gt;
#include &amp;lt;arpa/inet.h&amp;gt;
#include &amp;lt;netdb.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;stdarg.h&amp;gt;&lt;/code&gt;
    &lt;p&gt;The project includes a Makefile for easy compilation and installation:&lt;/p&gt;
    &lt;code&gt;# Standard optimized build
make

# Build with debugging symbols
make debug

# Build with maximum performance optimizations
make optimized

# Install to system (default: /usr/local/bin)
sudo make install

# Uninstall from system
sudo make uninstall

# Clean build artifacts
make clean&lt;/code&gt;
    &lt;p&gt;If you prefer not to use the Makefile, you can compile directly:&lt;/p&gt;
    &lt;code&gt;gcc -O3 -o fastrace fastrace.c&lt;/code&gt;
    &lt;p&gt;For maximum performance:&lt;/p&gt;
    &lt;code&gt;gcc -O3 -march=native -mtune=native -flto -o fastrace fastrace.c&lt;/code&gt;
    &lt;p&gt;For debugging:&lt;/p&gt;
    &lt;code&gt;gcc -g -O0 -Wall -Wextra -o fastrace_debug fastrace.c&lt;/code&gt;
    &lt;code&gt;sudo ./fastrace &amp;lt;target&amp;gt;&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;sudo ./fastrace google.com&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-n&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Disable reverse DNS lookups (fastest output)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-m &amp;lt;hops&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set maximum hop count (default 30, max 128)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-q &amp;lt;probes&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set probes per hop (default 3, max 10)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-c &amp;lt;count&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set concurrent TTL window size (default 6)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-W &amp;lt;ms&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Poll wait timeout in milliseconds (default 2)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-t &amp;lt;ms&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Hop completion timeout in milliseconds (default 700)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-P &amp;lt;port&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Base UDP destination port (default 33434)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-V&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Print version information&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;-h&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Display help message&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;Tracing route to google.com (172.217.168.46)
Maximum hops: 30, Protocol: UDP
TTL ‚îÇ IP Address         (RTT ms)   Hostname
‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1   ‚îÇ‚Üí 192.168.1.1      (  2.58 ms) router.local
2   ‚îÇ‚Üí * * * (timeout)
3   ‚îÇ‚Üí * * * (timeout)
4   ‚îÇ‚Üí 37.26.81.21      ( 88.01 ms)
5   ‚îÇ‚Üí 79.140.91.10     ( 31.21 ms)
6   ‚îÇ‚Üí 195.22.202.203   ( 38.73 ms)
7   ‚îÇ‚Üí 72.14.209.224    ( 60.76 ms)
      ‚îî‚Üí 72.14.223.184   ( 61.65 ms)
8   ‚îÇ‚Üí 142.251.244.109  ( 59.57 ms)
      ‚îî‚Üí 216.239.62.49   ( 71.36 ms)
      ‚îî‚Üí 142.250.210.95  ( 70.25 ms)
9   ‚îÇ‚Üí 142.251.247.141  ( 59.79 ms)
      ‚îî‚Üí 142.251.52.85   ( 60.25 ms)
      ‚îî‚Üí 209.85.243.245  ( 62.33 ms)
10  ‚îÇ‚Üí 34.8.172.215     ( 62.42 ms) 215.172.8.34.bc.googleusercontent.com
&lt;/code&gt;
    &lt;p&gt;This visual format shows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Primary routes with horizontal arrows (&lt;code&gt;‚Üí&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Alternative/branching paths with indented branch indicators (&lt;code&gt;‚îî‚Üí&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Precise RTT measurements for each hop&lt;/item&gt;
      &lt;item&gt;Hostname resolution where available&lt;/item&gt;
      &lt;item&gt;Clear visualization of load-balanced paths&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Time-to-Live (TTL) field in the IP header is systematically incremented to discover each router along the path. Each probe uses a unique UDP port derived from its TTL and probe index, allowing responses to be matched instantly.&lt;/p&gt;
    &lt;p&gt;Probes are uniquely identified by using a different UDP port for each probe:&lt;/p&gt;
    &lt;code&gt;int port = BASE_PORT + (ttl * NUM_PROBES) + probe_num;&lt;/code&gt;
    &lt;p&gt;This allows accurate matching of responses to their corresponding probes.&lt;/p&gt;
    &lt;p&gt;RTT measurements now rely on the monotonic clock, protecting calculations from user/system time adjustments while preserving microsecond resolution.&lt;/p&gt;
    &lt;p&gt;Reverse DNS lookups are cached for the lifetime of the run. Use &lt;code&gt;-n&lt;/code&gt; to disable lookups entirely when only IP addresses are required.&lt;/p&gt;
    &lt;p&gt;Each probe uses a unique UDP port to identify it:&lt;/p&gt;
    &lt;code&gt;int port = BASE_PORT + (ttl * NUM_PROBES) + probe_num;&lt;/code&gt;
    &lt;p&gt;Received when a packet's TTL expires, containing the original UDP header:&lt;/p&gt;
    &lt;code&gt;if (icmp-&amp;gt;icmp_type == ICMP_TIME_EXCEEDED) {
    /* Extract original UDP header and match by port */
}&lt;/code&gt;
    &lt;p&gt;Received when reaching the destination port (indicating target reached):&lt;/p&gt;
    &lt;code&gt;if (icmp-&amp;gt;icmp_type == ICMP_DEST_UNREACH &amp;amp;&amp;amp; icmp-&amp;gt;icmp_code == ICMP_PORT_UNREACH) {
    /* Process port unreachable message */
}&lt;/code&gt;
    &lt;p&gt;Fastrace implements robust error handling:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Socket Creation Failures: Proper detection and reporting&lt;/item&gt;
      &lt;item&gt;Send/Receive Errors: Graceful handling with appropriate error messages&lt;/item&gt;
      &lt;item&gt;Hostname Resolution Failures: Fallback to IP address display&lt;/item&gt;
      &lt;item&gt;Signal Handling: Clean termination on interrupts (SIGINT)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void handle_signal(int sig) {
    if (sig == SIGINT) {
        printf("\nTraceroute interrupted.\n");
        finished = 1;
        cleanup();
        exit(0);
    }
}&lt;/code&gt;
    &lt;p&gt;Fastrace maintains a minimal memory footprint:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Static Allocation: Pre-allocated probe tracking array&lt;/item&gt;
      &lt;item&gt;Limited Dynamic Allocation: Used only for hostname resolution&lt;/item&gt;
      &lt;item&gt;Proper Cleanup: Resources are freed upon completion or interruption&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Root Privileges: Required for raw socket operations&lt;/item&gt;
      &lt;item&gt;Input Validation: Proper validation of command-line arguments&lt;/item&gt;
      &lt;item&gt;Buffer Management: Fixed-size buffers with bounds checking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Key areas for potential enhancement:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;IPv6 Support: Extend to support IPv6 tracerouting&lt;/item&gt;
      &lt;item&gt;TCP Probing: Add alternative probe methods for bypassing UDP-filtered routes&lt;/item&gt;
      &lt;item&gt;Statistical Analysis: Enhanced RTT variance and packet loss reporting&lt;/item&gt;
      &lt;item&gt;Visualization: Text-based route visualization capabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Davide Santangelo - GitHub&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the BSD-2 License - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Copyright ¬© 2025 Davide Santangelo&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Based on the principles of Van Jacobson's traceroute algorithm&lt;/item&gt;
      &lt;item&gt;Inspired by modern high-performance network diagnostic tools&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45769857</guid><pubDate>Fri, 31 Oct 2025 09:05:08 +0000</pubDate></item><item><title>Some rando turned me into a meme coin</title><link>https://cloudfour.com/thinks/that-time-some-rando-turned-me-into-a-meme-coin/</link><description>&lt;doc fingerprint="e60c011302e476e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;That time some rando turned me into a meme coin&lt;/head&gt;
    &lt;p&gt;We had barely started dinner when my wife asked what was wrong. ‚ÄúI think someone made one of my tweets into a meme coin.‚Äù She said, ‚ÄúI‚Äôm not sure I know what those words mean.‚Äù I replied, ‚ÄúI‚Äôm not sure I do either.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;An innocent DM turns ominous&lt;/head&gt;
    &lt;p&gt;It started innocently enough. A stranger reached out on LinkedIn with what I thought was a question about a Mastodon server where I‚Äôm a moderator. But they didn‚Äôt want to talk about Mastodon:&lt;/p&gt;
    &lt;p&gt;Every word in that message is English, but it might as well have been a foreign language. I read it several times trying to decipher what they were saying.&lt;/p&gt;
    &lt;p&gt;I thought it might be scam and was tempted to block the person, but I decided to dig in a little further before doing so. I‚Äôm glad I did.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Grigs X Community&lt;/head&gt;
    &lt;p&gt;If communities existed on Twitter before Elon Musk ruined it, I never used them. So when I opened the ‚Äúgrigs X community,‚Äù I was beyond confused.&lt;/p&gt;
    &lt;p&gt;Scrolling through the tweets in the community was even more incomprehensible and disconcerting. There were numerous AI generated images of me. Many of the images included Elon Musk and tagged his account as well. If this was a scam, it was the most elaborate scam I‚Äôd ever been the target of.&lt;/p&gt;
    &lt;p&gt;What in the world was going on?&lt;/p&gt;
    &lt;head rend="h2"&gt;The $grigs meme coin&lt;/head&gt;
    &lt;p&gt;Fortunately, I had recently listened to an excellent podcast episode from Planet Money that explained meme coins. After some digging, I found the $grigs meme coin on pump.fun, a website that makes it simple to create meme coins.&lt;/p&gt;
    &lt;p&gt;The meme coin had been created a couple days earlier and had a market cap of around $12,000. So now I understood what the Twitter community was talking about, but why did they make a meme coin of me?&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Grok&lt;/head&gt;
    &lt;p&gt;Planet Money‚Äôs meme coin podcast came in clutch again. I remembered part of the podcast where they talked about how important opinion leaders are for getting meme coins off the ground and how everyone wanted one particular opinion leader to notice their coins:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;HOROWITZ-GHAZI: Zeke says there is one key leader whose opinion seems to be valued above all others in the world of meme coins, a man who has taken the joke so far as to helm a controversial new government entity named after that original Doge meme.&lt;/p&gt;
      &lt;p&gt;FAUX: What is really ideal is if Elon Musk will talk about whatever the coin is about.&lt;/p&gt;
      &lt;p&gt;HOROWITZ-GHAZI: Like, one of the big reasons Dogecoin is still the most valuable meme coin is because Elon Musk started tweeting about it in 2019.&lt;/p&gt;
      &lt;p&gt;FAUX: But it‚Äôs not just Dogecoin. A lot of the most successful coins have had some connection to Elon Musk.&lt;/p&gt;
      &lt;p&gt;HOROWITZ-GHAZI: Elon Musk is like the meme coin market mover-in-chief.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That explained why so many of the AI images people contained Elon Musk and I. Most tweets tagged Musk as well.&lt;/p&gt;
    &lt;p&gt;Why were people so bullish that Musk might be interested in $grigs coin? Because Musk had named his AI chatbot Grok, and I was the first person to use the word ‚Äúgrok‚Äù on Twitter back in July 2007 when I wrote, ‚Äútrying to grok twitter.‚Äù&lt;/p&gt;
    &lt;p&gt;It finally made sense. This is why so many of the tweets and images in the community called me a time traveler, implied that I was secretly the original CTO of Twitter, or wildly, that my account was actually a Musk burner account.&lt;/p&gt;
    &lt;p&gt;The whole community was trying to get Musk to engage with the coin, but none of them knew that I had blocked Musk long ago.&lt;/p&gt;
    &lt;head rend="h2"&gt;I‚Äôm a meme coin. Now what?&lt;/head&gt;
    &lt;p&gt;I finally understood what was going on, but I had no idea what to do with this information.&lt;/p&gt;
    &lt;p&gt;The people behind the meme coin wanted me to promote it. They attempted to transfer coins to me so I would be incentivized to shill my meme coin.&lt;/p&gt;
    &lt;p&gt;I wanted to do the opposite. Meme coins are scams that rely on finding a greater fool. But would talking about the meme coin, even to badmouth it, just give it more attention and drive up the price?&lt;/p&gt;
    &lt;p&gt;I searched for articles by people who had been in similar situations, but couldn‚Äôt find any information. I reached out to several communities seeking guidance and got some good general feedback. Unfortunately, no one could predict what the impact on the coin‚Äôs valuation would be if I spoke up.&lt;/p&gt;
    &lt;p&gt;I slept on the problem and in the morning, I listened to a second Planet Money meme coin episode called, ‚ÄúThe Parable of the Peanut Memecoin.‚Äù It was instructive.&lt;/p&gt;
    &lt;p&gt;Someone made Peanut the Squirrel into a meme coin without the knowledge of Peanut‚Äôs owner. Peanut‚Äôs owner was given some tokens to promote the meme coin just like I had. Unlike me, he accepted the gift and started promoting the meme coin. The price went up and he sold his coins to help fund his plans for an animal rescue. The community immediately turned on him and attacked him relentlessly. The whole episode is worth a listen.&lt;/p&gt;
    &lt;p&gt;If I wanted to avoid a similar fate, I couldn‚Äôt be silent. I needed to publicly disown the coin that bore my image:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Yesterday, I learned that there is a meme coin based on a tweet of mine from 2007. The coin is using my profile image. I have no affiliation with the coin. I do not own any of the tokens. Someone tried to give me some tokens, but I don‚Äôt have a crypto wallet.&lt;/p&gt;&lt;p&gt;The 2007 tweet appears to be of interest because I used the verb grok. They say it is the first time grok was used on Twitter. I haven‚Äôt verified that. It seems many aren‚Äôt aware that grok is a verb invented by Robert A. Heinlein in 1961‚Äôs Stranger in a Strange Land.&lt;/p&gt;&lt;p&gt;Many years after my 2007 tweet, Musk named his AI bot Grok. Because of this, people are hoping that Musk will see my 2007 tweet and respond to it. That‚Äôs unlikely. I blocked Musk in 2023 when he changed the algorithm to promote his own tweets.&lt;/p&gt;&lt;lb/&gt;Here‚Äôs the thing. Crypto is scam. Musk is an assclown. The only good thing that may come of this is that more people will read Stranger in a Strange Land. It is a wonderful and moving piece of fiction. I highly recommend it.&lt;/quote&gt;
    &lt;p&gt;I‚Äôd like to think this thread is why the meme coin never took off, but other events likely did the coin in. Less than two days after I disavowed the coin, Musk and Trump were in a full-blown Twitter feud culminating with Musk saying Trump was in the Epstein files.&lt;/p&gt;
    &lt;p&gt;It seems Musk was too busy to grok the full potential of $grigs coin.&lt;/p&gt;
    &lt;p&gt;Jason Grigsby is one of the co-founders of Cloud Four, Mobile Portland and Responsive Field Day. He is the author of Progressive Web Apps from A Book Apart. Follow him at @grigs.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45769963</guid><pubDate>Fri, 31 Oct 2025 09:22:58 +0000</pubDate></item><item><title>Reasoning Models Reason Well, Until They Don't</title><link>https://arxiv.org/abs/2510.22371</link><description>&lt;doc fingerprint="addd243914d29aab"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 25 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Reasoning Models Reason Well, Until They Don't&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models (LLMs) have shown significant progress in reasoning tasks. However, recent studies show that transformers and LLMs fail catastrophically once reasoning problems exceed modest complexity. We revisit these findings through the lens of large reasoning models (LRMs) -- LLMs fine-tuned with incentives for step-by-step argumentation and self-verification. LRM performance on graph and reasoning benchmarks such as NLGraph seem extraordinary, with some even claiming they are capable of generalized reasoning and innovation in reasoning-intensive fields such as mathematics, physics, medicine, and law. However, by more carefully scaling the complexity of reasoning problems, we show existing benchmarks actually have limited complexity. We develop a new dataset, the Deep Reasoning Dataset (DeepRD), along with a generative process for producing unlimited examples of scalable complexity. We use this dataset to evaluate model performance on graph connectivity and natural language proof planning. We find that the performance of LRMs drop abruptly at sufficient complexity and do not generalize. We also relate our LRM results to the distributions of the complexities of large, real-world knowledge graphs, interaction graphs, and proof datasets. We find the majority of real-world examples fall inside the LRMs' success regime, yet the long tails expose substantial failure potential. Our analysis highlights the near-term utility of LRMs while underscoring the need for new methods that generalize beyond the complexity of examples in the training distribution.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Revanth Rameshkumar [view email]&lt;p&gt;[v1] Sat, 25 Oct 2025 17:28:38 UTC (7,546 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45769971</guid><pubDate>Fri, 31 Oct 2025 09:23:41 +0000</pubDate></item><item><title>Claude Is Down</title><link>https://status.claude.com/incidents/s5f75jhwjs6g</link><description>&lt;doc fingerprint="76df4d833a5be2e9"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Subscribe to updates for Elevated errors on claude.ai via email and/or text message. You'll receive email notifications when incidents are updated, and text message notifications whenever Claude creates or resolves an incident. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div/&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;To receive SMS updates, please verify your number. To proceed with just email click ‚ÄòSubscribe‚Äô &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45770317</guid><pubDate>Fri, 31 Oct 2025 10:15:24 +0000</pubDate></item></channel></rss>