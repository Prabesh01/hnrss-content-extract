<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 24 Jan 2026 21:09:38 +0000</lastBuildDate><item><title>Memory layout in Zig with formulas</title><link>https://raymondtana.github.io/math/programming/2026/01/23/zig-alignment-and-sizing.html</link><description>&lt;doc fingerprint="eaf8dac1609182cb"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Memory Layout in Zig with Formulas&lt;/head&gt;&lt;p&gt;I was recently encouraged to watch A Practical Guide to Applying Data Oriented Design (DoD) by Andrew Kelley, the creator of Zig1. Just 10 minutes into the talk, I was confronted with a skill I had never formally learned‚Ä¶ the arithmetic behind memory layout of types.&lt;/p&gt;&lt;p&gt;Throughout the talk, Andrew tested the audience‚Äôs ability to compute the alignment and sizes of various types, starting with primitives like &lt;code&gt;u32&lt;/code&gt; and &lt;code&gt;bool&lt;/code&gt;, and ending with some more complex structures involving enums, unions, and more. As far as I can tell, the exact rules for computing the alignment and size of a type in Zig are not made explicit in any documentation, but are understood by those in-the-know.&lt;/p&gt;&lt;p&gt;As a late-comer to low-level programming myself, I thought I‚Äôd collect here some formulas &amp;amp; explanations I landed on while wrestling with alignment and sizing in Zig.&lt;/p&gt;&lt;head rend="h2"&gt;Memory Layout Principles&lt;/head&gt;&lt;p&gt;For any piece of data stored in memory on a computer, the data must have some natural alignment and size dimensions according to its type. Intuitively, its size captures how many bytes it would take to specify the information that should be contained in any instance of that type. Whereas, its alignment captures the spacing the compiler must obey when choosing valid addresses at which to place data of this type.&lt;/p&gt;&lt;p&gt;I imagine just about any computer science major would have learned the rules of memory layout according to some kind of C-like compiler. I guess the motivation would go something like: ‚ÄúCPUs fetch data from memory in fixed-size blocks of so-many bytes, and performance degrades when data is misaligned. So, compilers automatically pad and align data types.‚Äù&lt;/p&gt;&lt;p&gt;In particular, types that don‚Äôt ‚Äúfill up‚Äù all of the space in memory allocated to them will be padded with extra bits/bytes to make up for the difference.&lt;/p&gt;&lt;p&gt;Andrew‚Äôs whole message in his DoD talk centered on designing your data types to take up as little space in memory as possible, which includes reducing the size, alignment, and padding required to represent the same information.&lt;/p&gt;&lt;p&gt;Probably, the formulas I propose below apply to similar languages beyond Zig and my machine‚Äôs (Apple) ABI, but I make no claims.&lt;/p&gt;&lt;p&gt;The Zig language exposes two builtin functions relevant to our discussion:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;@alignOf(comptime T: type): #bytes required for aligning this type in memory (valid addresses for this type will be multiples of this value);&lt;/item&gt;&lt;item&gt;@sizeOf(comptime T: type): #bytes for storing the type in memory (including padding).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I‚Äôll use the following function &lt;code&gt;memory_printout&lt;/code&gt; to report these values for any type:&lt;/p&gt;&lt;code&gt;const std = @import("std");

fn memory_printout(T: type) void {
    std.debug.print("@alignOf( {s} ): {d}\t", .{ @typeName(T), @alignOf(T) });
    std.debug.print("@sizeOf( {s} ): {d}\n", .{ @typeName(T), @sizeOf(T) });
}
&lt;/code&gt;&lt;head rend="h2"&gt;Memory Layout Formulas&lt;/head&gt;&lt;p&gt;To start, one helpful invariant is offered in Zig‚Äôs documentation. For any type &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;&lt;head rend="h3"&gt;Primitives&lt;/head&gt;&lt;p&gt;Already, the primitive data types will teach us a good bit about memory layout. Try guessing the results of the following Zig code before looking at the answer:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    const types = [_]type{ bool, c_char, u8, *u8, u16, u17, i32, f64, usize };
    inline for (types) |T| memory_printout(T);
}
&lt;/code&gt;&lt;head&gt;The Output:&lt;/head&gt;&lt;code&gt;@alignOf( bool ): 1       @sizeOf( bool ): 1
@alignOf( c_char ): 1     @sizeOf( c_char ): 1
@alignOf( u8 ): 1         @sizeOf( u8 ): 1
@alignOf( *u8 ): 8        @sizeOf( *u8 ): 8
@alignOf( u16 ): 2        @sizeOf( u16 ): 2
@alignOf( u17 ): 4        @sizeOf( u17 ): 4
@alignOf( i32 ): 4        @sizeOf( i32 ): 4
@alignOf( f64 ): 8        @sizeOf( f64 ): 8
@alignOf( usize ): 8      @sizeOf( usize ): 8
&lt;/code&gt;&lt;p&gt;This suggests the following formula for primitive data types:&lt;/p&gt;\[\texttt{@sizeOf(primitive)} = \texttt{@alignOf(primitive)}.\]&lt;p&gt;Most of these make sense. A &lt;code&gt;c_char&lt;/code&gt; truly requires 8 bits, or 1 byte to specify.&lt;/p&gt;&lt;p&gt;Whereas, a &lt;code&gt;bool&lt;/code&gt; comprises a single bit (information-theoretically). But, alignment and size are measured in whole bytes, so we should round up to the nearest byte (and pad with 7 bits to fill up that byte).&lt;/p&gt;&lt;p&gt;Similarly, any unsigned integer &lt;code&gt;u{b}&lt;/code&gt;, signed integer &lt;code&gt;i{b}&lt;/code&gt;, or floating-point number &lt;code&gt;f{b}&lt;/code&gt; contains $b$ bits of information. So, counting in bytes, we will have to round $b / 8$ up, somehow. But, look at &lt;code&gt;u17&lt;/code&gt;: despite $2 &amp;lt; 17 / 8 \leq 3$, the size of &lt;code&gt;u17&lt;/code&gt; is not 3 bytes. Instead, it‚Äôs 4 bytes. In general, alignment and size must be powers-of-2 bytes. This is another desirable property half-dictated by architecture and half-related to the convenience of powers of two. So, we actually always round up to the nearest power-of-2 bytes when converting from bits.&lt;/p&gt;&lt;p&gt;Let‚Äôs formalize this conversion from bits to bytes for good:&lt;/p&gt;\[\begin{aligned} \texttt{bytes}(\texttt{bits}) &amp;amp;:= \max\left\{1, 2^{\left\lceil\log_2(\frac{\texttt{bits}}{8}) \right\rceil}\right\}. \end{aligned}\]&lt;p&gt;Another consequence of alignment and size being powers of two is the following, stronger invariant. For any type &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;That is, the size of the type is always a multiple of its alignment.&lt;/p&gt;&lt;p&gt;Next up, depending on your architecture, &lt;code&gt;usize&lt;/code&gt; will either match &lt;code&gt;u32&lt;/code&gt; or &lt;code&gt;u64&lt;/code&gt;. I‚Äôm working on a 64-bit machine, so that‚Äôs why we see its size and alignment as 8 bytes. Moreover, any pointer (such as &lt;code&gt;*u8&lt;/code&gt;) represents an address, which is guaranteed by Zig to match &lt;code&gt;usize&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;For primitive data types, remember: their size and align values agree and equal the smallest power-of-2 many bytes required to represent that type in memory.&lt;/p&gt;&lt;head rend="h3"&gt;Structs&lt;/head&gt;&lt;p&gt;In Zig, a &lt;code&gt;struct&lt;/code&gt; combines many fields into a single data type. How does memory layout work when many fields are combined together?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: Zig automatically minimizes the memory footprint of a struct by possibly shuffling around its fields. To force the Zig compiler to respect the order of the fields as we‚Äôve defined them, we may use the&lt;/p&gt;&lt;code&gt;extern&lt;/code&gt;keyword as shown below. Really, this forces the compiler to obey C ABI compatibility.&lt;/quote&gt;&lt;p&gt;First, rest assured that structs add no overhead. That is, if &lt;code&gt;T&lt;/code&gt; is a type, and we define:&lt;/p&gt;&lt;code&gt;const struct_T = struct {
  field: T,
};
&lt;/code&gt;&lt;p&gt;then &lt;code&gt;@alignOf(struct_T) == @alignOf(T)&lt;/code&gt; and &lt;code&gt;@sizeOf(struct_T) == @sizeOf(T)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Now, when a struct envelops two fields, such as&lt;/p&gt;&lt;code&gt;const pair = extern struct {
  a: u8,
  b: u32,
};
&lt;/code&gt;&lt;p&gt;we should consider the meanings of align and size again:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The alignment of the struct &lt;code&gt;pair&lt;/code&gt;should be such that any offset by this alignment value does not break the alignment of its constituent fields&lt;code&gt;a&lt;/code&gt;and&lt;code&gt;b&lt;/code&gt;.&lt;list rend="ul"&gt;&lt;item&gt;Here, field &lt;code&gt;b&lt;/code&gt;has a stricter alignment of 4 bytes, whereas&lt;code&gt;a&lt;/code&gt;permits offsets of 1 byte. So,&lt;code&gt;pair&lt;/code&gt;better also only permit alignments of 4 bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Here, field &lt;/item&gt;&lt;item&gt;The size of the struct &lt;code&gt;pair&lt;/code&gt;is dictated by its alignment. Its memory will necessarily take up a number of bytes which is a multiple of its alignment. To figure out exactly how many, we iterate through the fields in order, trying our best to greedily pack those fields while still respecting their own alignments.&lt;list rend="ul"&gt;&lt;item&gt;Here, the size of &lt;code&gt;a&lt;/code&gt;is just one byte, so it fits into a single memory chunk of size 4 bytes (the alignment of&lt;code&gt;pair&lt;/code&gt;is 4 bytes), with three bytes to spare. Now, we consider the next field:&lt;code&gt;b&lt;/code&gt;. As its alignment is 4 bytes, we can only write&lt;code&gt;b&lt;/code&gt;at an address which is a multiple of its own alignment. The soonest we can accomplish this is by padding three bytes after&lt;code&gt;a&lt;/code&gt;and writing&lt;code&gt;b&lt;/code&gt;at the fourth byte. This already places&lt;code&gt;b&lt;/code&gt;into another 4-byte memory chunk, in which it fits entirely as its size is 4 bytes. So, the total size of&lt;code&gt;pair&lt;/code&gt;is 8 bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Here, the size of &lt;/item&gt;&lt;/list&gt;&lt;p&gt;Now, what do you expect the output of the following Zig code to be?&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(ABAB);
    memory_printout(ABBA);
}

const ABAB = extern struct {
    a1: u8,
    b1: u16,
    a2: u8,
    b2: u16,
};

const ABBA = extern struct {
    a1: u8,
    a2: u8,
    b1: u16,
    b2: u16,
};
&lt;/code&gt;&lt;head&gt;The Answer:&lt;/head&gt;&lt;code&gt;@alignOf( ABAB ): 2      @sizeOf( ABAB ): 8
@alignOf( ABBA ): 2      @sizeOf( ABBA ): 6
&lt;/code&gt;&lt;p&gt;In general, deciding the placement of a struct field follows this rule:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Rule: Each field is placed after the previous field at the next smallest multiple of its own alignment.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;In general, the formula for rounding a number $N$ up to the nearest multiple of some other number $m$ looks like:&lt;/p&gt;\[\texttt{next_mult}(N, m) := \left\lceil \frac{N}{m} \right\rceil \cdot m.\\\]&lt;p&gt;Given this, try to follow the next example. We make use of another Zig builtin &lt;code&gt;@offsetOf(&amp;lt;type&amp;gt;, &amp;lt;field_name&amp;gt;)&lt;/code&gt; to display exactly where each field is placed in memory relative to the beginning address of &lt;code&gt;S&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;fn printOffset(T: type, comptime f: [:0]const u8) void {
    std.debug.print("@offsetOf( {s} ) = {d}\n", .{ f, @offsetOf(T, f) });
}

pub fn main() void {
  memory_printout(S);
  printOffset(S, "a");
  printOffset(S, "b");
  printOffset(S, "c");
}

const S = extern struct {
    // align = size = 2
    a: u16,
    // align = 2, size = 6
    b: extern struct { b1: u16, b2: u16, b3: u16 },
    // align = size = 4
    c: u32,
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( S ): 4        @sizeOf( S ): 12
@offsetOf( a ) = 0
@offsetOf( b ) = 2
@offsetOf( c ) = 8
&lt;/code&gt;&lt;p&gt;In general, alignment for structs is quite simple to formulate:&lt;/p&gt;\[\texttt{@alignOf(struct)} := \max_{\texttt{fields}} \texttt{@alignOf(field)}.\]&lt;p&gt;In contrast, the size of the (externed) struct is more complicated: $\texttt{@sizeOf(struct)}$ is the smallest multiple of $\texttt{@alignOf(struct)}$ many bytes required to fit the fields of a struct (in order) such that:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;No two fields overlap in memory, and&lt;/item&gt;&lt;item&gt;Each field lies at an address which is a multiple of its own alignment: $\texttt{@alignOf(field)}$.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Without the &lt;code&gt;extern&lt;/code&gt; keyword, Zig minimizes the size of the struct under all permutations of its fields. Zig also offers &lt;code&gt;packed struct&lt;/code&gt;, which eliminates padding entirely and lays out fields in strict bit-order. While this can reduce memory usage further, it comes with performance trade-offs and restrictions on field access.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Bonus question: Try to explain why the choice to make alignments and sizes be powers of two is vital for these rules to be well-defined for assessing the alignment and size of structs.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;Enums&lt;/head&gt;&lt;p&gt;Under the hood, an enum works on indices, not labels. So, the alignment and size of an enum will equal the minimal number of bytes to express the type of its indices. Suppose &lt;code&gt;T = enum (u{b}) { ... }&lt;/code&gt; is an arbitrary enum indexed by unsigned integers of type &lt;code&gt;u{b}&lt;/code&gt;, where &lt;code&gt;b&lt;/code&gt; is measured in bits.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: we may use the Zig standard library to access the number of options in the enum as follows:&lt;/p&gt;&lt;code&gt;std.meta.fields(T).len&lt;/code&gt;. I‚Äôll call this $\texttt{T.len}$, below.&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;Note: By default, Zig‚Äôs compiler assigns indices starting at zero and counting up by one. So, by default, Zig sets&lt;/p&gt;&lt;code&gt;b&lt;/code&gt;to $\lceil \log_2 (\texttt{T.len}) \rceil$.&lt;/quote&gt;&lt;p&gt;Then,&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf(enum(u{b}))} &amp;amp;= \texttt{@alignOf(u{b})} = \texttt{bytes}(\texttt{b}),\\ \texttt{@sizeOf(enum(u{b}))} &amp;amp;= \texttt{@sizeOf(u{b})} = \texttt{bytes}(\texttt{b}). \end{aligned}\]&lt;p&gt;We‚Äôve made use of the $\texttt{bytes}$ function, again2.&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;const T_default = enum { a, b, c, d, e };
const T_long = enum(u64) { a, b, c, d, e };

memory_printout(T_default);
memory_printout(T_long);
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( T_default ): 1    @sizeOf( T_default ): 1
@alignOf( T_long ): 8       @sizeOf( T_long ): 8
&lt;/code&gt;&lt;head rend="h3"&gt;Arrays and Slices&lt;/head&gt;&lt;p&gt;For an array in Zig, its alignment inherits from that of its elements, and its size is just length$\times$size of the type:&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf([N]T)} &amp;amp;= \texttt{@alignOf(T)},\\ \texttt{@sizeOf([N]T)} &amp;amp;= \texttt{N} \cdot \texttt{@sizeOf(T)}. \end{aligned}\]&lt;p&gt;In contrast, a slice in Zig is just a special case of a struct which contains one pointer (&lt;code&gt;usize&lt;/code&gt;) and a length (&lt;code&gt;usize&lt;/code&gt;). So,&lt;/p&gt;&lt;p&gt;Example (using another builtin &lt;code&gt;@TypeOf&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(@TypeOf(digits_array));
    memory_printout(@TypeOf(digits_slice));
}

const digits_array = [10]u8{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 };
const digits_slice: []const u8 = digits_array[0..]; 
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( [10]u8 ): 1         @sizeOf( [10]u8 ): 10
@alignOf( []const u8 ): 8     @sizeOf( []const u8 ): 16
&lt;/code&gt;&lt;head rend="h3"&gt;(Untagged) Unions&lt;/head&gt;&lt;p&gt;An untagged, bare union in Zig (accomplished with the &lt;code&gt;extern&lt;/code&gt; keyword) essentially acts as a switch statement over a number of mutually-exclusive options of various types without the ability to report which option is active. To express a bare union type in memory, we just need enough memory to store the largest option(s).&lt;/p&gt;&lt;p&gt;However, untagged unions in Zig without the &lt;code&gt;extern&lt;/code&gt; keyword seem to require extra memory, essentially one more alignment‚Äôs worth. So, untagged unions should satisfy:&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(U_bare);
    memory_printout(U);
}

const U_bare = extern union {
    a: i64,
    b: extern struct { c: i64, d: i64, e: i64 },
};

const U = union {
    a: i64,
    b: struct { c: i64, d: i64, e: i64 },
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( U_bare ): 8   @sizeOf( U_bare ): 24
@alignOf( U ): 8        @sizeOf( U ): 32
&lt;/code&gt;&lt;head rend="h3"&gt;Tagged Unions&lt;/head&gt;&lt;p&gt;Tagged unions are unions which use an additional enum to detect which field is active in the union. Alignment for a tagged union must additionally consider the alignment of the tag too, while the size must treat the tag and fields together.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: there are no ‚Äúbare‚Äù tagged unions. So, the&lt;/p&gt;&lt;code&gt;extern&lt;/code&gt;keyword doesn‚Äôt work on tagged unions.&lt;/quote&gt;&lt;p&gt;Suppose &lt;code&gt;U(E)&lt;/code&gt; is of type &lt;code&gt;union(enum)&lt;/code&gt;. Then, we can compute the alignment and size of this type depending on those of its union and enum components:&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(UE);
    memory_printout(UF);
    memory_printout(UG);
}

const E = enum { a, b };
const F = enum(u64) { a, b };
const G = enum(u128) { a, b };

const UE = union(E) {
    a: i64, b: struct { c: i64, d: i64 }
};
const UF = union(F) {
    a: i64, b: struct { c: i64, d: i64 }
};
const UG = union(G) {
    a: i64, b: struct { c: i64, d: i64 }
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( UE ): 8       @sizeOf( UE ): 24
@alignOf( UF ): 8       @sizeOf( UF ): 24
@alignOf( UG ): 16      @sizeOf( UG ): 32
&lt;/code&gt;&lt;head rend="h3"&gt;ArrayLists and MultiArrayLists&lt;/head&gt;&lt;p&gt;An &lt;code&gt;ArrayList(T)&lt;/code&gt; in Zig is the standard library‚Äôs dynamic array implementation. This is comparable to the notions of a ‚Äúvector‚Äù in C++ or a ‚Äúlist‚Äù in Python, otherwise understood as the Array of Structs (AoS) memory layout. Elements of type &lt;code&gt;T&lt;/code&gt; are stored contiguously in memory each with their full size and padding.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;ArrayList(T)&lt;/code&gt; type itself is a struct containing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;items&lt;/code&gt;: a slice&lt;code&gt;[]T&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;&lt;code&gt;capacity&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;So, the &lt;code&gt;ArrayList(T)&lt;/code&gt; type has a fixed memory footprint:&lt;/p&gt;&lt;p&gt;However, the data that the ArrayList manages lives on the heap. When iterating over an ArrayList, you traverse memory in strides of $\texttt{@sizeOf(T)}$ bytes. The memory consumed by the backing buffer is simply:&lt;/p&gt;\[\begin{aligned} \texttt{buffer_alignment} &amp;amp;= \texttt{@alignOf(T)},\\ \texttt{buffer_size} &amp;amp;= \texttt{buffer.capacity} \cdot \texttt{@sizeOf(T)}. \end{aligned}\]&lt;p&gt;In contrast, a &lt;code&gt;MultiArrayList(T)&lt;/code&gt; in Zig follows the Struct of Arrays (SoA) memory layout. Instead of storing complete &lt;code&gt;T&lt;/code&gt; instances contiguously, it stores each field of &lt;code&gt;T&lt;/code&gt; in its own separate, tightly-packed array.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;MultiArrayList(T)&lt;/code&gt; type itself is a struct containing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ptr&lt;/code&gt;: a single pointer to the backing buffer,&lt;/item&gt;&lt;item&gt;&lt;code&gt;len&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;,&lt;/item&gt;&lt;item&gt;&lt;code&gt;capacity&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;So:&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf(MultiArrayList(T))} &amp;amp;= \texttt{@alignOf(usize)} = 8 \text{ bytes (on 64-bit)},\\ \texttt{@sizeOf(MultiArrayList(T))} &amp;amp;= 3 \cdot \texttt{@sizeOf(usize)} = 24 \text{ bytes (on 64-bit)}. \end{aligned}\]&lt;p&gt;The backing buffer stores all field arrays contiguously. Padding between fields is not needed; instead, each field array is packed according to the field‚Äôs alignment. Summing over the fields of $T$, the total buffer size would thus be:&lt;/p&gt;\[\texttt{buffer_size} = \texttt{buffer.capacity} \cdot \sum_{\texttt{fields}} \texttt{@sizeOf}(\texttt{field}).\]&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;const std = @import("std");
const ArrayList = std.ArrayList;
const MultiArrayList = std.MultiArrayList;

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    const allocator = gpa.allocator();

    const T = struct { a: u8, b: u16 };

    var list: ArrayList(T) = .{};
    defer list.deinit(allocator);

    var multiList: MultiArrayList(T) = .{};
    defer multiList.deinit(allocator);

    for (0..10_000) |_| {
        try list.append(allocator, .{ .a = 0, .b = 1 });
        try multiList.append(allocator, .{ .a = 0, .b = 1 });
    }

    memory_printout(T);
    memory_printout(ArrayList(T));
    memory_printout(MultiArrayList(T));
    std.debug.print("list capacity: {d}\n", .{list.capacity});
    std.debug.print("list buffer size: {d}\n", .{list.capacity * @sizeOf(T)});
    std.debug.print("multiList capacity: {d}\n", .{multiList.capacity});
    std.debug.print("multiList buffer size: {d}\n", .{multiList.capacity * (@sizeOf(@FieldType(T, "a")) + @sizeOf(@FieldType(T, "b")))});
}
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( T ): 2                  @sizeOf( T ): 4
@alignOf( ArrayList(T) ): 8       @sizeOf( ArrayList(T) ): 24
@alignOf( MultiArrayList(T) ): 8  @sizeOf( MultiArrayList(T) ): 24
list capacity: 12854
list buffer size: 51416
multiList capacity: 11150
multiList buffer size: 33450
&lt;/code&gt;&lt;head rend="h2"&gt;Battle Testing&lt;/head&gt;&lt;p&gt;Let‚Äôs test our formulas against the video that inspired this post: Andrew Kelley‚Äôs talk on DoD.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: In order to get these examples to actually compile and execute in Zig (0.16.0), I had to throw in some allocators and extra helper methods.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;ArrayList of Monsters (19:05)&lt;/head&gt;&lt;code&gt;const Monster = struct {
  anim: *Animation, 
  kind: Kind,

  const Kind = enum { snake, bat, wolf, dingo, human };
};

var monsters: ArrayList(Monster) = .{};
var i: usize = 0;
while (i &amp;lt; 10_000) : (i += 1) {
  try monsters.append(.{
    .anim = getAnimation(),
    .kind = rng.enumValue(Monster.Kind),
  });
}
&lt;/code&gt;&lt;head&gt;Actual Memory Use:&lt;/head&gt;&lt;code&gt;Monster size: 16 bytes 
ArrayList(Monster) size: 24 bytes
monsters size: 160_000 bytes        // Total memory size of 10_000 monsters
&lt;/code&gt;&lt;p&gt;Do our formulas agree?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;code&gt;Monster&lt;/code&gt;Struct:&lt;list rend="ul"&gt;&lt;item&gt;The fields of &lt;code&gt;Monster&lt;/code&gt;satisfy $\texttt{@alignOf(anim)} = 8$ and $\texttt{@alignOf(kind)} = 1$. So, we expect the alignment of the struct to be $\texttt{@alignOf(Monster)} = 8$.&lt;/item&gt;&lt;item&gt;No matter the ordering, it takes two memory chunks of size 8 bytes to fit these fields (since $\texttt{@sizeOf(anim)} = 8$ and $\texttt{@sizeOf(kind)} = 1$). So, we expect $\texttt{@sizeOf(Monster)} = 16$, exactly as we observed.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The fields of &lt;/item&gt;&lt;item&gt;ArrayList(Monster) Type: as a type, it takes a bit of overhead to specify &lt;code&gt;ArrayList(Monster)&lt;/code&gt;, since an ArrayList is really a slice&lt;code&gt;[]Monster&lt;/code&gt;plus a capacity (&lt;code&gt;usize&lt;/code&gt;). On my 64-bit machine, that adds up to 24 bytes of memory.&lt;/item&gt;&lt;item&gt;&lt;code&gt;monsters&lt;/code&gt;ArrayList: remember, ArrayLists act like ‚Äúarrays of structs‚Äù.&lt;list rend="ul"&gt;&lt;item&gt;The natural size and alignment of the &lt;code&gt;Monster&lt;/code&gt;struct dictate the layout of the&lt;code&gt;monsters&lt;/code&gt;ArrayList.&lt;/item&gt;&lt;item&gt;The size of an ArrayList in memory should equal its length times the size of each &lt;code&gt;Monster&lt;/code&gt;element type. So, we expect&lt;code&gt;monsters&lt;/code&gt;to take up $10,000 \times \texttt{@sizeOf(Monster)} = 160,000$ bytes, as observed.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The natural size and alignment of the &lt;/item&gt;&lt;/list&gt;&lt;p&gt;Footnotes&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Zig is a modern, C-like programming language which offers a safer, more memory-explicit experience for systems programming, without sacrificing low-level control or C interoperability. Notably, Zig makes it straightforward to manage memory allocation by treating allocators as first-class values rather than hidden globals. Instead of relying on an implicit runtime or a process-wide allocator, you pass explicit allocator objects into the code that needs them. This makes ownership and lifetimes much clearer, encourages you to design APIs around who is responsible for allocating and freeing memory, and makes it easy to swap in custom allocation strategies (e.g., arenas, scratch, tracking, etc.). ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Recall: $\displaystyle \texttt{bytes}(\texttt{bits}) := \max(1, 2^{\lceil\log_2(\frac{\texttt{bits}}{8})\rceil})$ whenever $\texttt{bits} &amp;gt; 0$. Otherwise, $\texttt{bytes}(0) = 0$. ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46744647</guid><pubDate>Sat, 24 Jan 2026 15:57:45 +0000</pubDate></item><item><title>Ask HN: Gmail spam filtering suddenly marking everything as spam?</title><link>https://news.ycombinator.com/item?id=46744807</link><description>&lt;doc fingerprint="7df301131d72b2ed"&gt;
  &lt;main&gt;
    &lt;p&gt;Almost all transactional emails are being marked as suspicious even when their SPF/DKIM records are fine and they‚Äôve been whitelisted before. Did Google break something in gmail/spam filtering?&lt;/p&gt;
    &lt;p&gt;Briefly, this morning, I had the opposite effect happen to my Gmail inbox in which things that would normally land in the social and updates folders ended up in my primary folder. I don't know which I'd be more freaked out by: a broken Gmail spam filter or 18 inches of snow.&lt;/p&gt;
    &lt;p&gt;It's a great reminder of how good this feature is that we take for granted. I think this outage has actually improved my appreciation for Gmail (a service I normally only complain about).&lt;/p&gt;
    &lt;p&gt;Seriously. I didn't even realize this was a wide issue, but I couldn't find a school enrolment email I was looking for this morning, and found it in the spam folder. The fact that I basically never have to do this is actually amazing.&lt;/p&gt;
    &lt;p&gt;I see nothing amiss on my oldest Gmail account. But then, I get probably &amp;lt;1 spam email a day on average, and even less legitimate mail, and even less that isn't an automatic notification of something or other that's already filtered and categorized by sender.&lt;/p&gt;
    &lt;p&gt;This has been ‚Äúdown‚Äù for me for a few months now, ever since Google tied this functionality to the same toggle that opts you in for using your email data for AI training. So now you can‚Äôt filter this stuff without also agreeing to a whole swath of unrelated and opt-ins.&lt;/p&gt;
    &lt;p&gt;Ive since gone on an unsubscribe campaign, and things seem bearable now.&lt;/p&gt;
    &lt;p&gt;Same here. Until recently I would get maybe 1-2 spams a month, and I just got 30 in the span of a few days.&lt;/p&gt;
    &lt;p&gt;They‚Äôre the very obvious, very obnoxious kind of spam, and Gmail still correctly sends them to the junk bin, so I wonder if they were shadowbanned before and Google simply decided to make the process more explicit (which I don‚Äôt hate on principle).&lt;/p&gt;
    &lt;p&gt;Either that or my address was scrapped from somewhere by a spam bot and the timing is coincidental.&lt;/p&gt;
    &lt;p&gt;Yes, my Gmail inbox is full of regular senders being flagged as "possibly unsafe" and I need to click a button "Looks Safe" to accept them. They are not being spamboxed, but they are definitely flagged. Even official communications from the USPS!&lt;/p&gt;
    &lt;p&gt;The reason given is that "Gmail hasn't scanned this message", so I suppose the scanners are unavailable/disabled for the time being.&lt;/p&gt;
    &lt;p&gt;They should also be tagged as "Important" but they are not. I believe this is a heuristic-based designation, and it has not been working too great lately. My most important mail is coming through as "unimportant".&lt;/p&gt;
    &lt;p&gt;They are not being marked as "Suspicious" but they are showing an infobox that explains they could not be scanned at all.&lt;/p&gt;
    &lt;p&gt;You could click "Seems Safe" on these messages, but they are not scanned by Google, and they are simply adding a disclaimer that they currently can't vouch for the safety of a message that they couldn't scan. It seems to me that this is a prudent and helpful course of action.&lt;/p&gt;
    &lt;p&gt;I have been receiving a large number of spam emails in my "Important and Unread" areas which is anomalous. I was wondering exactly why and this helps. thanks!&lt;/p&gt;
    &lt;p&gt;I have an absurd and overwrought system involving Gmail, and client-side rspamd and SpamSieve on my Mac. Gmail is (was?) overly aggressive flagging things as spam, so I have the client-side Bayesian filter check Gmail‚Äôs spam folder and rescue good email, so long as rspamd also says it‚Äôs not phishing. And then add sender to a Gmail whitelisting rule. All rescued email is flagged such that if I later manually move any of it back to junk, it stays there as spam and updates the corpus.&lt;/p&gt;
    &lt;p&gt;I now never get good email in the spam folder, and never get undetected spam in the inbox, and very occasionally get a spam erroneously rescued, but still visually flagged as iffy-but-maybe-ham.&lt;/p&gt;
    &lt;p&gt;If Gmail has been lax at filtering spam lately, I haven‚Äôt noticed, but perhaps the Bayesian filter has been picking up the slack.&lt;/p&gt;
    &lt;p&gt;Multiple accounts as others have said. The most powerful is to switch to a provider that permits custom domains and allows you to construct topic specific wildcard addresses on the fly. These can't be flagged as invalid or stripped like Google '+' suffixes and when compromised, you can filter them into oblivion and move on to something else. You also get the bonus of having the entire namespace to yourself and can select short addresses.&lt;/p&gt;
    &lt;p&gt;Step zero. Never disclose your email address to anyone.&lt;/p&gt;
    &lt;p&gt;This is very easy and straightforward. I operate 6 Gmail accounts, and three are "alts" where I've basically never given the address out to anyone at all, and they receive zero spam, zero UCE, zero marketing emails.&lt;/p&gt;
    &lt;p&gt;Of course, on my "main" I've disclosed the address to many entities and I use it for sign-in and shipping and many things. And yes, I do receive spam and scam emails there, but wcyd?&lt;/p&gt;
    &lt;p&gt;I recently had a "role" Google account terminated because I was (paraphrasing) "violating Google policies" by having multiple accounts. I didn't know they were sticklers about that.&lt;/p&gt;
    &lt;p&gt;(I don't much care because the account was just used for interacting with somebody else's Google-hosted junk but, if I had been using it for something serious, I have probably been frustrated.)&lt;/p&gt;
    &lt;p&gt;There is no way, no possible way that Google prohibits the use of multiple accounts. They do not. They cannot. I just asked Gemini and I checked the actual TOS. It does not, in any way, prohibit these uses.&lt;/p&gt;
    &lt;p&gt;In fact, this is plainly evident by the way they give you tools to operate them in a systematic way. You can add multiple accounts to a single Android "user". You can add them to a single Google Chromebook account under one signed-in account. You can add multiple accounts separately to the same Chromebook.&lt;/p&gt;
    &lt;p&gt;You can add multiple accounts with the same names, the same birthdates, and the same Driver License. I've validated at least two YouTube channels by showing exactly the same ID.&lt;/p&gt;
    &lt;p&gt;Google did not terminate your account for the reason you state. You are not telling us all the background information.&lt;/p&gt;
    &lt;p&gt;Google may indeed terminate multiple accounts for the same person because of TOS violations. They will definitely link and associate your accounts, so making an "alt account" for misbehavior is not safe. If my "alt account" is compromised or violates TOS, then I can expect they will discipline all 6 equally, because they're all linked.&lt;/p&gt;
    &lt;p&gt;But operating multiple accounts is very explicitly supported by Google, and by Microsoft as well, I will say. I don't know about Apple. Facebook definitely prohibited this in the past, although you can maintain multiple "profiles" and "pages" that have unique settings and personalities.&lt;/p&gt;
    &lt;p&gt;I feel like an easier solution to having six different email addresses is to use Gmail aliases - I've caught a few less-than-honest companies either selling my email address, or been breached without disclosing such, simply by using an alias along the lines of '+service_name'. If any alias starts to receive spam you can setup rules to automatically delete everything that comes in with that. You also get the added benefit of significantly easier and more accurate search.&lt;/p&gt;
    &lt;p&gt;I don't think y'all understand why I have separate Google accounts.&lt;/p&gt;
    &lt;p&gt;I use them for different purposes. They are "role accounts" for projects I am doing, such as geneaology and astronomy.&lt;/p&gt;
    &lt;p&gt;In order to use YouTube sanely, and store different stuff in Drive, I separate them into unique accounts. I use those accounts for specific things, and my YouTube subscriptions, playlists, etc. are tailored for each role, for example.&lt;/p&gt;
    &lt;p&gt;This is not about email at all. Obviously, I can access all those email accounts through the one app on my smartphone or the one PWA on my Chromebook. They are easily manageable but separate.&lt;/p&gt;
    &lt;p&gt;I also run 3 Outlook/Microsoft accounts, and for the same reason. (One of them is my academic account from community college, and the other two are personal.)&lt;/p&gt;
    &lt;p&gt;I don't need to give out email addresses for the "role accounts" except where I "Sign In With Google" to various services. So I don't really send/receive email from them at all, except where I'm sharing links or documents with myself (the best way to do this cross-account is still by using email, oftentimes.)&lt;/p&gt;
    &lt;p&gt;Well, spam is no big deal, and any scam that comes via email should not affect anyone who is educated and prepared for them.&lt;/p&gt;
    &lt;p&gt;Of course, with a well-known email address, you could run a higher risk of credential stuffing, and an account takeover by someone who hijacks your email account, and then pivots from there to taking other accounts.&lt;/p&gt;
    &lt;p&gt;But this seems to be a risk we all take: email addresses are meant to be shared, to be public, and to be well-known to anyone to correspond with us.&lt;/p&gt;
    &lt;p&gt;I will say that disclosing my email address to certain parties has had noticeable effects. For example, I used "MYADDRESS+Echovita@gmail.com" once, and only once. My godfather had passed away, and I ordered some flowers for his funeral. And I put that order through with that email address.&lt;/p&gt;
    &lt;p&gt;Well, Echovita themselves had a data breach shortly afterwards, and I was inundated with scam emails. Just all sorts of attackers and they were basically all using the same M.O. But they were readily identifiable because I had used that "+Echovita" to identify it uniquely. And they really haven't stopped coming in. It's been 5 years since that breach.&lt;/p&gt;
    &lt;p&gt;So yes, especially with untrusted parties, it may help to tag your email address. I don't worry about receiving spam anywhere. But like I said, since I've never ever disclosed the addresses of 2-3 of my "alt accounts" they simply never receive any mail at all, spam or no spam.&lt;/p&gt;
    &lt;p&gt;I use Gmail since the beta (I got invite from a googler) and I don't remember when they began adding spam control but in my experience the GMail spam check works usually exceptionally well: I very rarely need to add a custom filter.&lt;/p&gt;
    &lt;p&gt;My email, over two decades+ (2004?), hasn't been in a many public leaks (only one on https://haveibeenpwned.com/ ) but obviously has made its way to various spammy actors but thankfully nearly everything is caught by GMail's spam filter.&lt;/p&gt;
    &lt;p&gt;If anything I'd say GMail's spam filter works too well: I get more legit emails in my spam folder than spam in my regular inbox. As in: one in a rare while vs about zero spam in my regular inbox.&lt;/p&gt;
    &lt;p&gt;There's your confirmation, then. It must be either a localized failure to some subgroup of users, or triggered by some combination of settings, if some people are seeing it and others are not.&lt;/p&gt;
    &lt;p&gt;It's been happening for about a month for me. I had to start monitoring spam because legit emails end up there. Funnily enough I started having the opposite problem too - plenty of obvious spam and phishing attempt ending up in my mailbox.&lt;/p&gt;
    &lt;p&gt;I have seen a spam button show up I haven't seen in a long time.&lt;/p&gt;
    &lt;p&gt;It might be a new round of AI training featuring the labour of customers as free employees doing training. Every time we click, we consent to sharing private email data.&lt;/p&gt;
    &lt;p&gt;Its really slow. Too slow to use 2FA or in some cases, verify email addresses or recover passwords.&lt;/p&gt;
    &lt;p&gt;Most people can't handle a notification on their watch every minute, or several spam every five minutes, so "large numbers of people" are shutting off notifications on their phones. And human nature being what it is, they're not going to be turned back on again. So the era of getting a notification when you get an email is coming to a close. "Important Immediate Attention Stuff" moved to text messages a long time ago anyway, at least for me. The list of technologies you can no longer reach me on, always increases over time...&lt;/p&gt;
    &lt;p&gt;I don't understand why spam detection is so complicated. I can tell with high accuracy if an email is spam just by the subject line. I'd think even basic ML could do this very reliably you don't need a bleeding-edge LLM to do this.&lt;/p&gt;
    &lt;p&gt;Phishing is tricker because it can be very deceptive especially if you're being targeted specifically. But also usually pretty obvious.&lt;/p&gt;
    &lt;p&gt;* Are you available? * Paul, can we have a zoom meeting with you on Monday? * Assistance for donation * Greetings!!! * some ideas for you * Refund request * Somethings not working * Manuel Montoya for roof work contractor * proposals for print * Invite Connection&lt;/p&gt;
    &lt;p&gt;Half of the above are actual spam, half are not. Tell me which is which ...&lt;/p&gt;
    &lt;p&gt;This only applies to spam which requires significant follow-up effort from the spammer to respond to potential victims; effectively just 419 "advance-fee" fraud scams.&lt;/p&gt;
    &lt;p&gt;For spam which only does not require manual effort on the other side, there is no reason to filter out potential victims and all the more reason to make it look as legit as possible to maximize conversion rates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46744807</guid><pubDate>Sat, 24 Jan 2026 16:16:02 +0000</pubDate></item><item><title>Metriport (YC S22) is hiring a security eng to harden healthcare data infra</title><link>https://www.ycombinator.com/companies/metriport/jobs/XC2AF8s-senior-security-engineer</link><description>&lt;doc fingerprint="47704651dcb5720e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Metriport is an open-source data intelligence platform that helps healthcare organizations access and exchange patient data in real-time. We integrate with all major US healthcare IT systems and tap into comprehensive medical data for 300+ million individuals.&lt;/p&gt;
      &lt;p&gt;We've found product-market fit with multi-million ARR, 100+ customers (including Strive Health, Circle Medical, and Brightside Health), backing from top VCs, and years of runway. We're ready to scale. We're a tight-knit, high-performing team of mostly former founders (including two YC alumni). We're engineering-heavy, operate with minimal bureaucracy and high autonomy, and hire based on competence, not prestige. We push hard‚Äîfounders work six days a week from our SF office‚Äîbut give everyone freedom to craft their schedule. We measure output and we're committed to sustainable intensity.&lt;/p&gt;
      &lt;head rend="h2"&gt;About us&lt;/head&gt;
      &lt;p&gt;The following points are an assortment of the most relevant bits that will give you the gist of where we‚Äôre at, why we‚Äôll win, and our company culture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Well funded with a massive recent infusion of capital, found PMF, multi-million ARR, 80+ customers (including Strive Health, Circle Medical, and Brightside Health), funded by top VCs and angels, have years of runway - and we‚Äôre just getting started.&lt;/item&gt;
        &lt;item&gt;We‚Äôre a tight-knit, high performing, and passionate team - we work with a consistent intensity and have become a leader in our industry with a fraction of the resources of our competitors.&lt;/item&gt;
        &lt;item&gt;Consistency means we push as hard as humanly possible, while keeping our health and personal lives in check.&lt;/item&gt;
        &lt;item&gt;Meaningful work is what gets us out of bed, and we just wouldn‚Äôt be satisfied by building yet another CRM company.&lt;/item&gt;
        &lt;item&gt;By pedigree, we‚Äôre a group of underdogs - we don‚Äôt hire based on prestige, but on demonstrated competence and perceived potential.&lt;/item&gt;
        &lt;item&gt;We‚Äôre engineering heavy, and most of our engineers are former founders (including 2 ex-YC founders).&lt;/item&gt;
        &lt;item&gt;We operate as a relatively flat structure with little red tape, forced structure, or bureaucracy. We just opt to get shit done and foster a collaborative environment with high autonomy - our GitHub commit history and product velocity is a testament to this.&lt;/item&gt;
        &lt;item&gt;The founders set the pace by working 6 days a week in our SF office, but everyone is given full freedom to craft a schedule that‚Äôs best for both the team and themselves - team output is measured.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; About you&lt;/p&gt;
      &lt;p&gt;In a nutshell, we're looking for a security engineer with the following specific qualities:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You‚Äôre entrepreneurial-minded, with an olympian-level work ethic (nearly our entire engineering team consists of former founders).&lt;/item&gt;
        &lt;item&gt;You are passionate about security and are excited to own security related projects within the company end-to-end.&lt;/item&gt;
        &lt;item&gt;You are confident in your ability to build scalable systems across the full stack, and people usually come to you for technical guidance.&lt;/item&gt;
        &lt;item&gt;You believe you can solve any problem that comes at you, and don't shy away from diving deep into areas where you may lack domain expertise.&lt;/item&gt;
        &lt;item&gt;You have a strong sense of ownership over your work, and have demonstrated ability to lead others.&lt;/item&gt;
        &lt;item&gt;You know how to move fast - while still maintaining a strong security posture.&lt;/item&gt;
        &lt;item&gt;You care more about the end result and delivering value, rather than what new and frilly tech is being used under the hood for a given feature.&lt;/item&gt;
        &lt;item&gt;When someone scopes out a project with an ETA of 3 weeks, you ask yourself "why can't it be done in 3 days?".&lt;/item&gt;
        &lt;item&gt;You‚Äôre a hacker at heart, and have a good sense of what rules should, and shouldn‚Äôt, be broken.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What you'll be doing&lt;/head&gt;
      &lt;p&gt;After quickly ramping up using our comprehensive onboarding materials to get familiar with our domain, product, and codebase, the goal would be to get you shipping product directly to customers as quickly as possible. Specifically, day to day, this looks like:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Evangelizing security across Metriport‚Äôs growing team - we will look to you for guidance, and training.&lt;/item&gt;
        &lt;item&gt;Driving full-stack security projects , big and small, end-to-end from ideation to production rollout.These projects could include things like: &lt;list rend="ul"&gt;&lt;item&gt;Implement an enterprise-grade audit logging solution for a new national healthcare network infrastructure stack.&lt;/item&gt;&lt;item&gt;Implement fine grained RBAC on the API key access layer, and more robust roles on our UIs.&lt;/item&gt;&lt;item&gt;Help us revamp our internal security policies and put tools in place to keep the platform, and employees, secure while still allowing the team to be efficient.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Helping the engineering team with PR reviews with a security-focused lens.&lt;/item&gt;
        &lt;item&gt;Work with the Go to Market team to complete customer security assessments and questionnaires.&lt;/item&gt;
        &lt;item&gt;Work with the engineering team to harden security across the development lifecycle - think secret management, access controls, and vulnerability scanning.&lt;/item&gt;
        &lt;item&gt;Managing your own work in Linear.&lt;/item&gt;
        &lt;item&gt;Participating in bi-weekly sprint planning / retro sessions, and quarterly planning sessions.&lt;/item&gt;
        &lt;item&gt;Attending a daily 30 minute remote stand-up at 7:30am PST Mon-Fri (our only regular mandatory meeting).&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; Requirements&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have 6+ years experience in security engineering and information security.&lt;/item&gt;
        &lt;item&gt;You‚Äôre located in San Francisco or the Bay Area (or willing to relocate).&lt;/item&gt;
        &lt;item&gt;Familiar with HIPAA compliant environments.&lt;/item&gt;
        &lt;item&gt;Experience rolling out and maintaining security frameworks like SOC 2, NIST, HITRUST, FedRAMP, etc.&lt;/item&gt;
        &lt;item&gt;Experience rolling out data protection technologies like SSO, MFA, VPN, FIPS, etc.&lt;/item&gt;
        &lt;item&gt;Experience with organizational secret management.&lt;/item&gt;
        &lt;item&gt;Experience implementing SCA, SAST, DAST in CICD workflows.&lt;/item&gt;
        &lt;item&gt;Experience with Mobile Device Management (MDM).&lt;/item&gt;
        &lt;item&gt;Proficiency in cloud security &amp;amp; networking on AWS - IAM, WAF, KMS, etc.&lt;/item&gt;
        &lt;item&gt;Proficiency in authentication, cryptography, encryption, and security protocols such as: mTLS, RSA, SSL, HMAC, RBAC, etc.&lt;/item&gt;
        &lt;item&gt;Bonus: experience with IHE profiles (ATNA, CT, XUA).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive equity + compensation package üöÄ&lt;/item&gt;
        &lt;item&gt;Salary range: $160,000,00 - $220,000.00&lt;/item&gt;
        &lt;item&gt;Full family Platinum health insurance, dental, and vision coverage ü¶∑&lt;/item&gt;
        &lt;item&gt;401(k) retirement plan + matching üí∞&lt;/item&gt;
        &lt;item&gt;Flexible work from home or in-office üè¢&lt;/item&gt;
        &lt;item&gt;Healthy lunches are complimentary when working in-office (and breakfast + dinners as needed) üçè&lt;/item&gt;
        &lt;item&gt;Quarterly company off-sites with the team ‚õ∑Ô∏è&lt;/item&gt;
        &lt;item&gt;MacBook provided by us üíª&lt;/item&gt;
        &lt;item&gt;Unlimited PTO (we work hard, but trust you to take time you need to be at your best) üßò‚ôÇÔ∏è&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; Our tech&lt;/p&gt;
      &lt;p&gt;On the frontend, we use React - on the backend, we rely on Node.js and TypeScript for writing core business logic. We deploy a wide range of AWS cloud services (ie ECS, Fargate, Lambda, etc), and manage our infrastructure as code with AWS CDK. Data lives in PostgreSQL, DynamoDB, S3, Snowflake, FHIR servers, and more. We use Oneleet for security and compliance.&lt;/p&gt;
      &lt;p&gt;Metriport provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46745224</guid><pubDate>Sat, 24 Jan 2026 17:00:07 +0000</pubDate></item><item><title>Tao Te Ching ‚Äì Translated by Ursula K. Le Guin</title><link>https://github.com/nrrb/tao-te-ching/blob/master/Ursula%20K%20Le%20Guin.md</link><description>&lt;doc fingerprint="eb7ad05e09566404"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46745233</guid><pubDate>Sat, 24 Jan 2026 17:01:31 +0000</pubDate></item><item><title>December in Servo: multiple windows, proxy support, better caching, and more</title><link>https://servo.org/blog/2026/01/23/december-in-servo/</link><description>&lt;doc fingerprint="660f40f72340fbc4"&gt;
  &lt;main&gt;
    &lt;p&gt;Servo 0.0.4 and our December nightly builds now support multiple windows (@mrobinson, @mukilan, #40927, #41235, #41144)! This builds on features that landed in Servo‚Äôs embedding API last month. We‚Äôve also landed support for several web platform features, both old and new:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Äòcontrast-color()‚Äô in CSS color values (@webbeef, #41542)&lt;/item&gt;
      &lt;item&gt;partial support for &amp;lt;meta charset&amp;gt; (@simonwuelker, #41376)&lt;/item&gt;
      &lt;item&gt;partial support for encoding sniffing (@simonwuelker, #41435)&lt;/item&gt;
      &lt;item&gt;‚Äòbackground‚Äô and ‚Äòbgcolor‚Äô attributes on &amp;lt;table&amp;gt;, &amp;lt;thead&amp;gt;, &amp;lt;tbody&amp;gt;, &amp;lt;tfoot&amp;gt;, &amp;lt;tr&amp;gt;, &amp;lt;td&amp;gt;, &amp;lt;th&amp;gt; (@simonwuelker, #41272)&lt;/item&gt;
      &lt;item&gt;tee() on readable byte streams (@Taym95, #35991)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For better compatibility with older web content, we now support vendor-prefixed CSS properties like ‚Äò-moz-transform‚Äô (@mrobinson, #41350), as well as window.clientInformation (@Taym95, #41111).&lt;/p&gt;
    &lt;p&gt;We‚Äôve continued shipping the SubtleCrypto API, with full support for ChaCha20-Poly1305, RSA-OAEP, RSA-PSS, and RSASSA-PKCS1-v1_5 (see below), plus importKey() for ML-KEM (@kkoyung, #41585) and several other improvements (@kkoyung, @PaulTreitel, @danilopedraza, #41180, #41395, #41428, #41442, #41472, #41544, #41563, #41587, #41039, #41292):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Algorithm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ChaCha20-Poly1305&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, #40978, #41003, #41030)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RSA-OAEP&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @TimvdLippe, @jdm, #41225, #41217, #41240, #41316)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RSA-PSS&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @jdm, #41157, #41225, #41240, #41287)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;RSASSA-PKCS1-v1_5&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @jdm, #41172, #41225, #41240, #41267)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When using servoshell on Windows, you can now see &lt;code&gt;--help&lt;/code&gt; and log output, as long as servoshell was started in a console (@jschwe, #40961).&lt;/p&gt;
    &lt;p&gt;Servo diagnostics options are now accessible in servoshell via the &lt;code&gt;SERVO_DIAGNOSTICS&lt;/code&gt; environment variable (@atbrakhi, #41013), in addition to the usual &lt;code&gt;-Z&lt;/code&gt; / &lt;code&gt;--debug=&lt;/code&gt; arguments.&lt;/p&gt;
    &lt;p&gt;Servo‚Äôs devtools now partially support the Network &amp;gt; Security tab (@jiang1997, #40567), allowing you to inspect some of the TLS details of your requests. We‚Äôve also made it compatible with Firefox 145 (@eerii, #41087), and use fewer IPC resources (@mrobinson, #41161).&lt;/p&gt;
    &lt;p&gt;We‚Äôve fixed rendering bugs related to ‚Äòfloat‚Äô, ‚Äòorder‚Äô, ‚Äòmax-width‚Äô, ‚Äòmax-height‚Äô, ‚Äò:link‚Äô selectors, &amp;lt;audio&amp;gt; layout, and getClientRects(), affecting intrinsic sizing (@Loirooriol, #41513), anonymous blocks (@Loirooriol, #41510), incremental layout (@Loirooriol, #40994), flex item sizing (@Loirooriol, #41291), selector matching (@andreubotella, #41478), replaced element layout (@Loirooriol, #41262), and empty fragments (@Loirooriol, #41477).&lt;/p&gt;
    &lt;p&gt;Servo now fires ‚Äòtoggle‚Äô events on &amp;lt;dialog&amp;gt; (@lukewarlow, #40412). We‚Äôve also improved the conformance of ‚Äòwheel‚Äô events (@mrobinson, #41182), ‚Äòhashchange‚Äô events (@Taym95, #41325), ‚Äòdblclick‚Äô events on &amp;lt;input&amp;gt; (@Taym95, #41319), ‚Äòresize‚Äô events on &amp;lt;video&amp;gt; (@tharkum, #40940), ‚Äòseeked‚Äô events on &amp;lt;video&amp;gt; and &amp;lt;audio&amp;gt; (@tharkum, #40981), and the ‚Äòtransform‚Äô property in getComputedStyle() (@mrobinson, #41187).&lt;/p&gt;
    &lt;head rend="h2"&gt;Embedding API&lt;/head&gt;
    &lt;p&gt;Servo now has basic support for HTTP proxies (@Narfinger, #40941). You can set the proxy URL in the &lt;code&gt;http_proxy&lt;/code&gt; (@Narfinger, #41209) or &lt;code&gt;HTTP_PROXY&lt;/code&gt; (@treeshateorcs, @yezhizhen, #41268) environment variables, or via &lt;code&gt;--pref network_http_proxy_uri&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We now use the system root certificates by default (@Narfinger, @mrobinson, #40935, #41179), on most platforms. If you don‚Äôt want to trust the system root certificates, you can instead continue to use Mozilla‚Äôs root certificates with &lt;code&gt;--pref network_use_webpki_roots&lt;/code&gt;.
As always, you can also add your own root certificates via &lt;code&gt;Opts&lt;/code&gt;::&lt;code&gt;certificate_path&lt;/code&gt; (&lt;code&gt;--certificate-path=&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;We have a new &lt;code&gt;SiteDataManager&lt;/code&gt; API for managing localStorage, sessionStorage, and cookies (@janvarga, #41236, #41255, #41378, #41523, #41528), and a new &lt;code&gt;NetworkManager&lt;/code&gt; API for managing the cache (@janvarga, @mrobinson, #41255, #41474, #41386).
To clear the cache, call &lt;code&gt;NetworkManager&lt;/code&gt;::&lt;code&gt;clear_cache&lt;/code&gt;, and to list cache entries, call &lt;code&gt;NetworkManager&lt;/code&gt;::&lt;code&gt;cache_entries&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Simple dialogs ‚Äì that is alert(), confirm(), and prompt() ‚Äì are now exposed to embedders via a new &lt;code&gt;SimpleDialog&lt;/code&gt; type in &lt;code&gt;EmbedderControl&lt;/code&gt; (@mrobinson, @mukilan, #40982).
This new interface is harder to misuse, and no longer requires boilerplate for embedders that wish to ignore simple dialogs.&lt;/p&gt;
    &lt;p&gt;Web console messages, including messages from the Console API, are now accessible via &lt;code&gt;ServoDelegate&lt;/code&gt;::&lt;code&gt;show_console_message&lt;/code&gt; and &lt;code&gt;WebViewDelegate&lt;/code&gt;::&lt;code&gt;show_console_message&lt;/code&gt; (@atbrakhi, #41351).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Servo&lt;/code&gt;, the main handle for controlling Servo, is now cloneable for sharing within the same thread (@mukilan, @mrobinson, #41010).
To shut down Servo, simply drop the last &lt;code&gt;Servo&lt;/code&gt; handle or let it go out of scope.
&lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;start_shutting_down&lt;/code&gt; and &lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;deinit&lt;/code&gt; have been removed (@mukilan, @mrobinson, #41012).&lt;/p&gt;
    &lt;p&gt;Several interfaces have also been renamed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;clear_cookies&lt;/code&gt;is now&lt;code&gt;SiteDataManager&lt;/code&gt;::&lt;code&gt;clear_cookies&lt;/code&gt;(@janvarga, #41236, #41255)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DebugOpts&lt;/code&gt;::&lt;code&gt;disable_share_style_cache&lt;/code&gt;is now&lt;code&gt;Preferences&lt;/code&gt;::&lt;code&gt;layout_style_sharing_cache_enabled&lt;/code&gt;(@atbrakhi, #40959)&lt;/item&gt;
      &lt;item&gt;The rest of &lt;code&gt;DebugOpts&lt;/code&gt;has been moved to&lt;code&gt;DiagnosticsLogging&lt;/code&gt;, and the options have been renamed (@atbrakhi, #40960)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Perf and stability&lt;/head&gt;
    &lt;p&gt;We can now evict entries from our HTTP cache (@Narfinger, @gterzian, @Taym95, #40613), rather than having it grow forever (or get cleared by an embedder). about:memory now tracks SVG-related memory usage (@d-kraus, #41481), and we‚Äôve fixed memory leaks in &amp;lt;video&amp;gt; and &amp;lt;audio&amp;gt; (@tharkum, #41131).&lt;/p&gt;
    &lt;p&gt;Servo now does less work when matching selectors (@webbeef, #41368), when focus changes (@mrobinson, @Loirooriol, #40984), and when reflowing boxes whose size did not change (@Loirooriol, @mrobinson, #41160).&lt;/p&gt;
    &lt;p&gt;To allow for smaller binaries, gamepad support is now optional at build time (@WaterWhisperer, #41451).&lt;/p&gt;
    &lt;p&gt;We‚Äôve fixed some undefined behaviour around garbage collection (@sagudev, @jdm, @gmorenz, #41546, mozjs#688, mozjs#689, mozjs#692). To better avoid other garbage-collection-related bugs (@sagudev, mozjs#647, mozjs#638), we‚Äôve continued our work on defining (and migrating to) safer interfaces between Servo and the SpiderMonkey GC (@sagudev, #41519, #41536, #41537, #41520, #41564).&lt;/p&gt;
    &lt;p&gt;We‚Äôve fixed a crash that occurs when &amp;lt;link rel=‚Äúshortcut icon‚Äù&amp;gt; has an empty ‚Äòhref‚Äô attribute, which affected chiptune.com (@webbeef, #41056), and we‚Äôve also fixed crashes in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Äòbackground-repeat‚Äô (@mrobinson, #41158)&lt;/item&gt;
      &lt;item&gt;&amp;lt;audio&amp;gt; layout (@Loirooriol, #41262)&lt;/item&gt;
      &lt;item&gt;custom elements (@mrobinson, #40743)&lt;/item&gt;
      &lt;item&gt;AudioBuffer (@WaterWhisperer, #41253)&lt;/item&gt;
      &lt;item&gt;AudioNode (@Taym95, #40954)&lt;/item&gt;
      &lt;item&gt;ReportingObserver (@Taym95, #41261)&lt;/item&gt;
      &lt;item&gt;Uint8Array (@jdm, #41228)&lt;/item&gt;
      &lt;item&gt;the fonts system, on FreeType platforms (@simonwuelker, #40945)&lt;/item&gt;
      &lt;item&gt;IME usage, on OpenHarmony (@jschwe, #41570)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Donations&lt;/head&gt;
    &lt;p&gt;Thanks again for your generous support! We are now receiving 7110 USD/month (+10.5% over November) in recurring donations. This helps us cover the cost of our speedy CI and benchmarking servers, one of our latest Outreachy interns, and funding maintainer work that helps more people contribute to Servo.&lt;/p&gt;
    &lt;p&gt;Servo is also on thanks.dev, and already 30 GitHub users (+2 over November) that depend on Servo are sponsoring us there. If you use Servo libraries like url, html5ever, selectors, or cssparser, signing up for thanks.dev could be a good way for you (or your employer) to give back to the community.&lt;/p&gt;
    &lt;p&gt;We now have sponsorship tiers that allow you or your organisation to donate to the Servo project with public acknowlegement of your support. A big thanks from Servo to our newest Bronze Sponsors: Anthropy, Niclas Overby, and RxDB! If you‚Äôre interested in this kind of sponsorship, please contact us at [email protected].&lt;/p&gt;
    &lt;p&gt;Use of donations is decided transparently via the Technical Steering Committee‚Äôs public funding request process, and active proposals are tracked in servo/project#187. For more details, head to our Sponsorship page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conference talks and blogs&lt;/head&gt;
    &lt;p&gt;We‚Äôve recently published one talk and one blog post:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Web engine CI on a shoestring budget (slides; transcript) ‚Äì Delan Azabani (@delan) spoke about the CI system that keeps our builds and tryjobs moving fast, running nearly two million tests in under half an hour.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Servo 2025 Stats ‚Äì Manuel Rego (@mrego) wrote about the growth of the Servo project, and how our many new contributors have enabled that.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We also have two upcoming talks at FOSDEM 2026 in Brussels later this month:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The Servo project and its impact on the web platform ecosystem ‚Äì Manuel Rego (@mrego) is speaking on Saturday 31 January at 14:00 local time (13:00 UTC), about Servo‚Äôs impact on spec issues, interop bugs, test cases, and the broader web platform ecosystem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implementing Streams Spec in Servo web engine ‚Äì Taym Haddadi (@Taym95) is speaking on Saturday 31 January at 17:45 local time (16:45 UTC), about our experiences writing a new implementation of the Streams API that is independent of the one in SpiderMonkey.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Servo developers Martin Robinson (@mrobinson) and Delan Azabani (@delan) will also be attending FOSDEM 2026, so it would be a great time to come along and chat about Servo!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46745259</guid><pubDate>Sat, 24 Jan 2026 17:03:24 +0000</pubDate></item><item><title>Raspberry Pi Drag Race: Pi 1 to Pi 5 ‚Äì Performance Comparison</title><link>https://the-diy-life.com/raspberry-pi-drag-race-pi-1-to-pi-5-performance-comparison/</link><description>&lt;doc fingerprint="be10987704b616b6"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we‚Äôre going to be taking a look at what almost 13 years of development has done for the Raspberry Pi. I have one of each generation of Pi from the original Pi that was launched in 2012 through to the Pi 5 which was released just over a year ago.&lt;/p&gt;
    &lt;p&gt;We‚Äôll take a look at what has changed between each generation and how their performance and power consumption has improved by running some tests on them.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs my video of the testing process and results, read on for the write-up;&lt;/p&gt;
    &lt;head rend="h2"&gt;Purchase Links For Components Used In These Tests&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raspberry Pi 5 ‚Äì Buy Here&lt;/item&gt;
      &lt;item&gt;Raspberry Pi 4 ‚Äì Buy Here&lt;/item&gt;
      &lt;item&gt;Pi 5 Ice Tower Cooler ‚Äì Buy Here&lt;/item&gt;
      &lt;item&gt;Pi 5 Power Supply ‚Äì Buy Here&lt;/item&gt;
      &lt;item&gt;USB C to MicroUSB Adaptor ‚Äì Buy Here&lt;/item&gt;
      &lt;item&gt;Sandisk Ultra MicroSD Card ‚Äì Buy Here&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Equipment Used&lt;/head&gt;
    &lt;p&gt;Some of the above parts are affiliate links. By purchasing products through the above links, you‚Äôll be supporting this channel, at no additional cost to you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware Changes Through Each Generation&lt;/head&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 1&lt;/head&gt;
    &lt;p&gt;This is the original Raspberry Pi, which was launched in February 2012.&lt;/p&gt;
    &lt;p&gt;This Pi has a Broadcom BCM2835 SOC which features a single ARM1176JZF-S core running at 700MHz along with a VideoCore IV GPU. It has 512 MB of DDR RAM.&lt;/p&gt;
    &lt;p&gt;In terms of connectivity, it only has 100Mb networking and 2 x USB 2.0 ports. Video output is 1080P through a full-size HDMI port or analogue video out through a composite video connector and audio output is provided through a 3.5mm audio jack. It doesn‚Äôt have any WiFi or Bluetooth connectivity but it does have some of the features that we still have on more recent models like DSI and CSI ports, a full size SD card reader for the operating system and GPIO pins, although only 26 of them at this stage.&lt;/p&gt;
    &lt;p&gt;Power is supplied through a micro USB port and it is rated for 5V and 700mA.&lt;/p&gt;
    &lt;p&gt;It was priced at $35 ‚Äì which at the time was incredibly cheap for what was essentially a palm-sized computer.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 2&lt;/head&gt;
    &lt;p&gt;The Raspberry Pi 2 was launched 3 years later, in February 2015 and this Pi looked quite different to the original and similar to the Pi‚Äôs we know today.&lt;/p&gt;
    &lt;p&gt;The Pi 2 has a significantly better processor than the original. The Broadcom BCM2836 SOC has 4 Cortex-A7 cores running at 900 MHz and it retained the same VideoCore IV GPU. RAM was also bumped up to 1GB.&lt;/p&gt;
    &lt;p&gt;It added another 2 x USB 2.0 ports alongside the 100Mb Ethernet port. The composite video port disappeared and the analogue video output was moved into the audio jack.&lt;/p&gt;
    &lt;p&gt;The GPIO pins were increased to 40 pins which has followed the same pin layout since ‚Äì which has really helped in maintaining compatibility with hats and accessories. The SD card reader was also changed to a microSD card reader.&lt;/p&gt;
    &lt;p&gt;The power circuitry was bumped up to 800mA to accommodate the more powerful CPU.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 3&lt;/head&gt;
    &lt;p&gt;The Raspberry Pi 3 was launched just a year later, in February 2016.&lt;/p&gt;
    &lt;p&gt;The Pi 3‚Äôs new Broadcom BCM2837 SOC retained the same 4-core architecture but these were changed to 64-bit Cortex A53 cores running at 1.2Ghz.&lt;/p&gt;
    &lt;p&gt;RAM was kept at 1GB but was now DDR2.&lt;/p&gt;
    &lt;p&gt;There was no change to the USB or Ethernet connectivity on the original Pi 3 but we did see WiFi and Bluetooth added for the first time. WiFi was single band 2.4GHz and we had Bluetooth 4.1.&lt;/p&gt;
    &lt;p&gt;The version that I have is actually the 3B+, which was launched a little later. The main improvements over the original Pi 3 were a 0.2GHz boost to the clock speed and the upgrade to Gigabit networking with PoE (Power over Ethernet) support and dual-band WiFi.&lt;/p&gt;
    &lt;p&gt;The power circuitry was again improved, still running at 5V but now up to 1.34A, which was almost double the Pi 2.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 4&lt;/head&gt;
    &lt;p&gt;Next came the Pi 4 in June 2019. This Pi came at one of the worst times for global manufacturing and was notoriously difficult to get hold of due to the impact of COVID on the global supply chain. Quite ironically, this hard-to-get Pi is the one that I‚Äôve got the most of, mainly due to my water-cooled Pi cluster build.&lt;/p&gt;
    &lt;p&gt;The Pi 4 has a Broadcom BCM2711 SOC with 4 Cortex-A72 cores running at 1.5GHz. So again a slight clock speed increase over the Pi 3 but still retaining 4 cores. It also includes a bump up to a VideoCore VI GPU.&lt;/p&gt;
    &lt;p&gt;This was the first model to feature different RAM configurations. It was originally available in 1, 2, 4GB variants featuring LPDDR4 RAM and in March of 2020 an 8GB variant was added to the linup as well. This obviously resulted in a few different price points but impressively they still managed to keep a $35 offering 7 years after the launch of the first Pi.&lt;/p&gt;
    &lt;p&gt;It retained the same form factor as the Pi 3 but with the network and Ethernet ports switched around. Notably, two of the USB ports were upgraded to USB 3.0, networking was now gigabit ethernet like the 3B+, WiFi was dual-band and it had Bluetooth 5.0.&lt;/p&gt;
    &lt;p&gt;They also changed the single full-size HDMI port to two micro HDMI ports. Most people I know don‚Äôt like this change and find it annoying to have to use adaptors to work with common displays and these micro HDMI ports are prone to breaking when they are used often. I think general hobbyists and makers would prefer this to still be a single full-size port but Pi‚Äôs are often used in commercial display applications so I guess that‚Äôs why they went with this dual micro HDMI configuration.&lt;/p&gt;
    &lt;p&gt;The power circuit was actually reduced in this model, from 1.34 down to 1.25A and the port was changed to USB C.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 5&lt;/head&gt;
    &lt;p&gt;Lastly and most recently we have the Pi 5 which was launched in October 2023.&lt;/p&gt;
    &lt;p&gt;This Pi features a Broadcom BCM2712 SOC with 4 Cortex A76 cores running at a significantly faster 2.4Ghz and a VideoCore VII GPU running at 800MHz.&lt;/p&gt;
    &lt;p&gt;So quite a bump up in CPU and GPU performance.&lt;/p&gt;
    &lt;p&gt;It is offered in 3 RAM configurations but the drop in a 1GB offering means that they‚Äôre no longer available at the $35 price point. There is a fairly significant increase in price up to $50 for the base 2GB variant.&lt;/p&gt;
    &lt;p&gt;Some other notable changes are the inclusion of a PCIe port which enables IO expansion and a much improved power circuit. The PCIe port is quite commonly used to add an NVMe SSD instead of a microSD card for the operating system.&lt;/p&gt;
    &lt;p&gt;The power circuit was upgraded to handle the PCIe port addition, now stepping up to 5V at up to 5A, along with a power button for the first time.&lt;/p&gt;
    &lt;p&gt;The change in power supply requirements to 5V and 5A is a bit annoying as most power delivery capable supplies cap out 2.5 or 3A at 5V. It would have been more universal to require a 9V 3A supply to meet the Pis power requirements. I assume they steered away from this because the Pi‚Äôs circuitry runs at 5V and 3.3V and they would have then needed to add another onboard DC-DC converter which increases complexity, size and potentially the cost, it would also have made it a bit less efficient. But this does mean that you most likely need to buy a USB C power supply that has been purpose-built for the Pi 5.&lt;/p&gt;
    &lt;p&gt;The Pi 5 is also the first Pi to have its own dedicated fan socket.&lt;/p&gt;
    &lt;p&gt;So that‚Äôs a summary of the hardware changes, now let‚Äôs boot them up and take a look at their performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing The Performance Of Each Generation Of Pi&lt;/head&gt;
    &lt;p&gt;To compare the performance between the Pi‚Äôs, I‚Äôm going to run the following tests.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I‚Äôm going to attempt to playback a 1080P YouTube video in the browser, although I expect we‚Äôll have problems with this up to the Pi 4.&lt;/item&gt;
      &lt;item&gt;We‚Äôll then run a Sysbench CPU benchmark which I‚Äôll do both for a single-core and multicore.&lt;/item&gt;
      &lt;item&gt;Then we‚Äôll run a GLMark2 GPU benchmark.&lt;/item&gt;
      &lt;item&gt;Then test the storage speed using James Chambers Pi Benchmark script.&lt;/item&gt;
      &lt;item&gt;Then we‚Äôll run an iPerf3 Network Speed test.&lt;/item&gt;
      &lt;item&gt;Lastly, we‚Äôll look at Power Consumption, both at idle and with the CPU maxed out.&lt;/item&gt;
      &lt;item&gt;And then use that data to determine each Pi‚Äôs Performance per Watt.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To keep things as consistent as possible I‚Äôm going to be running the latest available version of Pi OS from Raspberry Pi Imager for each Pi. I was pleasantly surprised to find that you can still flash an OS image for the original Pi in their latest version of Imager.&lt;/p&gt;
    &lt;p&gt;I‚Äôll be testing them all running on a 32GB Sandisk Ultra microSD card. I‚Äôll also be using an Ice Tower cooler on each to ensure they don‚Äôt run anywhere near thermal throttling.&lt;/p&gt;
    &lt;head rend="h3"&gt;1080P YouTube Video Playback&lt;/head&gt;
    &lt;p&gt;I started with the original Pi and its first boot and setup process was a lesson in patience. It took me the best part of two hours to get the first boot complete, the Pi updated and the testing utilities installed but I got there in the end.&lt;/p&gt;
    &lt;p&gt;Even once set up it takes about 8 minutes to boot up to the desktop and the CPU stays pegged at 100% for another two to three minutes before dropping down to about 20% at idle.&lt;/p&gt;
    &lt;p&gt;The original Pi refused to open up the browser, so that‚Äôs where my YouTube video playback test ended.&lt;/p&gt;
    &lt;p&gt;The Pi 2 managed to open the browser and actually started playing back a 1080P video, which was surprising, but playback was terrible. It dropped pretty much all of the frames both in the window and fullscreen.&lt;/p&gt;
    &lt;p&gt;The Pi 3 played video back noticeably better than the Pi 2, but it‚Äôs still quite a long way away from being usable and still drops a lot of frames.&lt;/p&gt;
    &lt;p&gt;The Pi 4 handled 1080P video reasonably well. It had some initial trouble but then settled down. Fullscreen is also a bit choppy but is also usable.&lt;/p&gt;
    &lt;p&gt;The Pi 5 handled 1080P playback well without any significant issues both in the window and fullscreen.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sysbench CPU Benchmark&lt;/head&gt;
    &lt;p&gt;Next was the Sysbench CPU benchmark. I ran three tests on each and averaged the scores and I did this for both single-core and multicore.&lt;/p&gt;
    &lt;p&gt;In single core, the Pi 1 managed a rather dismal score of 68, the Pi 2 got a bit more than double this score but the real step up was with the Pi 3 which managed 18 times higher than the Pi 2. The Pi 4 and Pi 5 also offered good improvements on the previous generations.&lt;/p&gt;
    &lt;p&gt;Similarly in multicore, the Pi 3 scored over 18 times the score of the Pi2 and the Pi 4 and 5 provided good improvements on the Pi 3‚Äôs score.&lt;/p&gt;
    &lt;p&gt;Comparing the combined multicore score of the Pi 5 to what the single core on the Pi 1 can do, the Pi 5 is a little over 600 times faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;GLmark2 GPU Benchmark&lt;/head&gt;
    &lt;p&gt;Next, I tried running a GLMark2 GPU benchmark on them. I used the GLMark2-es2-wayland version which is designed for OpenGL ES so that the Pi 1 was supported.&lt;/p&gt;
    &lt;p&gt;I was surprised that the Pi 1 was even able to run GLMark2 ‚Äì it did complete the benchmark, although the score wasn‚Äôt all that impressive.&lt;/p&gt;
    &lt;p&gt;These results really show how the Pi‚Äôs GPU has improved in the last two generations. Prior to these tests, I had never seen a score below 100 and the Pi 1, 2 and 3 managed to fall short of triple digits. Pi 5 scored over 2.5 times higher than the Pi 4.&lt;/p&gt;
    &lt;head rend="h3"&gt;Storage Speed Test&lt;/head&gt;
    &lt;p&gt;Next was the storage speed test using James Chambers Pi Benchmarks script. The bus speed has increased over the years from 25MHz on the Pi 1 to 100MHz on the Pi 5, so I expect we‚Äôll see these reflected in the benchmark scores.&lt;/p&gt;
    &lt;p&gt;The storage speed test‚Äôs results aren‚Äôt as dramatic as the CPU and GPU results but show a steady improvement between generations. The Pi 3 did a bit worse than the Pi 2 but this small difference is likely just due to variability in the tests.&lt;/p&gt;
    &lt;head rend="h3"&gt;iPerf Network Speed Test&lt;/head&gt;
    &lt;p&gt;Next, I ran the iPerf network speed test on each.&lt;/p&gt;
    &lt;p&gt;The Pi 1 doesn‚Äôt quite get close to its theoretical 100Mbps but the Pi 2 does. The Pi 3 B+ although having Gigabit Ethernet is limited by this running over USB 2.0 which only has a theoretical maximum of 300MBps, so it came quite close. Both the Pi 4 and 5 expectedly come close to theoretical Gigabit speeds.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power Consumption Test&lt;/head&gt;
    &lt;p&gt;Lastly, I tested the power consumption of each Pi at idle and under load.&lt;/p&gt;
    &lt;p&gt;I used the same Pi 5 power adaptor to test all of the Pis to keep things consistent and I just used a USB C to micro USB adaptor for the Pi 1, 2 and 3.&lt;/p&gt;
    &lt;p&gt;The idle results were closer than I expected. The Pi 2 had the lowest idle power draw and the Pi 5 the highest, but all were within a watt or two of each other. At full load, you can see the increase in CPU power draw more physical power with the Pi 5 drawing almost three times the Pi 1 and Pi 2.&lt;/p&gt;
    &lt;p&gt;Converted to performance per watt using the Sysbench results, we can again see how much better the Pi 4 and 5 are over the Pi 1 and 2. There is a clear improvement in the performance that each generation of Pi is able to get per watt of power, which is essentially its efficiency. Although the Pi 5 draws more power than the Pi 1 under full load, you‚Äôre getting almost 200 times more power out of it per watt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts On The Drag Race And Future Pis&lt;/head&gt;
    &lt;p&gt;I really enjoyed working through this project to see how much Pi‚Äôs have changed over the years, particularly in terms of performance. I still remember being amazed at the size and price of the original Pi when it came out and it‚Äôs great that they‚Äôre still fully supported and can still be used for projects ‚Äì albeit with less CPU-intensive projects.&lt;/p&gt;
    &lt;p&gt;Let me know what you think has been the biggest improvement to the Pi over the years and what you‚Äôd still like to see added to future models in the comments section below.&lt;/p&gt;
    &lt;p&gt;I personally really like the addition of the PCIe port on the Pi 5 and I‚Äôd like to see 2.5Gb networking and a DisplayPort or USB C with DisplayPort added to a future generation of Pi.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46745922</guid><pubDate>Sat, 24 Jan 2026 18:06:00 +0000</pubDate></item><item><title>Hung by a thread</title><link>https://campedersen.com/rayon-mutex-deadlock</link><description>&lt;doc fingerprint="e754011701612a4e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Hung by a Thread&lt;/head&gt;January 24, 2026&lt;p&gt;It's 2am. My robot is frozen. Not crashed, not erroring, just... vibing. Sitting there. Motors off. Completely checked out.&lt;/p&gt;&lt;p&gt;I've been debugging for 8 hours and I'm about to mass delete my entire codebase and become a farmer.&lt;/p&gt;&lt;head rend="h2"&gt;The Setup&lt;/head&gt;&lt;p&gt;I'm building autonomous sidewalk robots. The control loop runs at 100Hz ‚Äî every 10ms we read sensors, do math, send motor commands. It's the heartbeat. The one thing that absolutely cannot stop.&lt;/p&gt;&lt;p&gt;It had been rock solid for weeks. Then I added LiDAR streaming over WebRTC.&lt;/p&gt;&lt;p&gt;Now, ~16 seconds after a client connects, the loop just stops. Doesn't crash. Doesn't throw. Just ghosts me. The watchdog starts barking, the robot coasts to a stop, and my laptop shows a beautiful 3D point cloud of a robot that has given up on life.&lt;/p&gt;&lt;head rend="h2"&gt;The Wrong Turns&lt;/head&gt;&lt;p&gt;I tried everything.&lt;/p&gt;&lt;p&gt;"It's tokio starving the loop" ‚Äî switched to &lt;code&gt;std::thread::sleep&lt;/code&gt;. Nope.&lt;/p&gt;&lt;p&gt;"It's the async mutex" ‚Äî swapped for &lt;code&gt;std::sync::Mutex&lt;/code&gt;. Nope.&lt;/p&gt;&lt;p&gt;"It's running on the wrong thread" ‚Äî moved the whole loop to &lt;code&gt;std::thread::spawn&lt;/code&gt;. Complete isolation. Nope nope nope.&lt;/p&gt;&lt;p&gt;Same freeze. Same spot. Iteration 1,615. Every single time.&lt;/p&gt;&lt;p&gt;The consistency was almost insulting. Like the bug was laughing at me.&lt;/p&gt;&lt;head rend="h2"&gt;The Breakthrough&lt;/head&gt;&lt;p&gt;Ok new plan. I add a heartbeat thread. Just a lil guy that watches a counter and screams if it stops:&lt;/p&gt;&lt;code&gt;std::thread::spawn(move || {
    let mut last = 0;
    loop {
        std::thread::sleep(Duration::from_secs(5));
        let current = counter.load(Ordering::Relaxed);
        if current == last {
            eprintln!("STUCK at iteration {}", current);
        }
        last = current;
    }
});
&lt;/code&gt;
&lt;p&gt;Five seconds after freeze: &lt;code&gt;STUCK at iteration 1615&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Oh. OH. It's not slow. It's not starved. It's blocked. Something is holding a lock and simply not letting go. Deadlock behavior.&lt;/p&gt;&lt;p&gt;Time to bring out the big guns. GDB.&lt;/p&gt;&lt;p&gt;She's waiting on a mutex. But who's holding it??&lt;/p&gt;&lt;p&gt;I scroll through the other threads. Tokio workers, GStreamer stuff, and then... four threads I definitely did not create. Rayon workers. I don't use rayon. Who invited rayon.&lt;/p&gt;&lt;head rend="h2"&gt;The Reveal&lt;/head&gt;&lt;p&gt;Rerun is this beautiful visualization SDK I use for recording telemetry. You call &lt;code&gt;recorder.log()&lt;/code&gt; and magic happens.&lt;/p&gt;&lt;p&gt;Turns out rerun uses rayon internally.&lt;/p&gt;&lt;p&gt;And I was calling &lt;code&gt;recorder.log()&lt;/code&gt; while holding a mutex.&lt;/p&gt;&lt;p&gt;This is a known rayon footgun: rayon#592. When you call into rayon while holding a mutex, rayon's work-stealing threads can deadlock trying to "help" with work that needs the lock you're already holding.&lt;/p&gt;&lt;p&gt;That's it. That's the fix. 8 hours of debugging. 2 lines changed. Hold the lock for less time. Tale as old as time.&lt;/p&gt;&lt;head rend="h2"&gt;The Takeaways&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;GDB is cracked for deadlocks. Logs can't show you thread state.&lt;/p&gt;&lt;code&gt;thread apply all bt&lt;/code&gt;hits different.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Random threads showing up? Suspicious. If you see thread pools you didn't spawn, figure out who did.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Your dependencies have dependencies. Somewhere in that&lt;/p&gt;&lt;code&gt;Cargo.lock&lt;/code&gt;is a threading model waiting to fight yours.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Heartbeat threads are free. A few lines to detect "stuck" is worth it for any critical loop. They're just a lil guy. Let them watch.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The fix is always smaller than the hunt. Always. Without exception. It's almost annoying.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I submitted a PR to rerun adding docs about this. Maybe the next person finds the warning before they find the bug.&lt;/p&gt;&lt;p&gt;The robot runs now. Hasn't frozen since. The LiDAR streams beautifully.&lt;/p&gt;&lt;p&gt;But I will never call into a library I don't fully understand while holding a mutex again. Fool me once.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746096</guid><pubDate>Sat, 24 Jan 2026 18:24:32 +0000</pubDate></item><item><title>Understanding Rust Closures</title><link>https://antoine.vandecreme.net/blog/rust-closures/</link><description>&lt;doc fingerprint="bcb1cda920a59147"&gt;
  &lt;main&gt;
    &lt;p&gt;While reading the Explicit capture clauses blog post, I realized that my understanding of rust closures was very superficial. This article is an attempt at explaining what I learned while reading and experimenting on the subject. It starts from the very basics and then explore more complex topics. Note that each title is a link to a rust playground where you can experiment with the code in the section.&lt;/p&gt;
    &lt;head rend="h1"&gt;Closures basics&lt;/head&gt;
    &lt;p&gt;You probably already know that a closure in rust is a function written with the following syntax:&lt;/p&gt;
    &lt;code&gt;let double_closure = |x| x * 2;
assert_eq!(4, double_closure(2));
&lt;/code&gt;
    &lt;p&gt;Written as a regular function it looks like:&lt;/p&gt;
    &lt;code&gt;fn double_function(x: u32) -&amp;gt; u32 {
    x * 2
}
assert_eq!(4, double_function(2));
&lt;/code&gt;
    &lt;p&gt;Very similar. There is actually a small difference between the two, the &lt;code&gt;double_function&lt;/code&gt; parameter and return type are &lt;code&gt;u32&lt;/code&gt;.
On the other hand, because we did not specify any type in &lt;code&gt;double_closure&lt;/code&gt;, the
default integer type has been picked, namely &lt;code&gt;i32&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We can fix that like this:&lt;/p&gt;
    &lt;code&gt;let double_typed_closure = |x: u32| -&amp;gt; u32 { x * 2 };
assert_eq!(4, double_typed_closure(2));
assert_eq!(4, double_typed_closure(2u32));
// assert_eq!(4, double_typed_closure(2u16)); // This would be an error.
&lt;/code&gt;
    &lt;p&gt;And for a classic example usage of closures, we can use the &lt;code&gt;Option::map&lt;/code&gt; method:&lt;/p&gt;
    &lt;code&gt;assert_eq!(Some(4), Some(2).map(|x| x * 2));
assert_eq!(Some(4), Some(2).map(double_closure)); // double_closure from above
assert_eq!(Some(4), Some(2).map(double_function)); // Passing double_function works too!
&lt;/code&gt;
    &lt;p&gt;So, it seems closures are just a shorter syntax for functions with type inference.&lt;/p&gt;
    &lt;head rend="h1"&gt;Capture&lt;/head&gt;
    &lt;p&gt;The main difference between closures and functions is that closures can capture variables from their environment while functions can't:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

assert_eq!("Hello world", greeter_closure("world"));
assert_eq!(
    Some("Hello world".to_owned()),
    Some("world").map(greeter_closure)
);
&lt;/code&gt;
    &lt;p&gt;Notice how the &lt;code&gt;hello&lt;/code&gt; variable is used within the body of the &lt;code&gt;greeter_closure&lt;/code&gt;.
Let's try that with a function:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";

fn greeter_function(x: &amp;amp;str) -&amp;gt; String {
    String::new() + hello + x
}
&lt;/code&gt;
    &lt;code&gt;error[E0434]: can't capture dynamic environment in a fn item
 --&amp;gt; src/main.rs:7:25
  |
7 |         String::new() + hello + x
  |                         ^^^^^
  |
  = help: use the `|| { ... }` closure form instead
&lt;/code&gt;
    &lt;p&gt;This does not work and the compiler helpfully suggest to use a closure instead.&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture by shared reference&lt;/head&gt;
    &lt;p&gt;In the &lt;code&gt;greeter_closure&lt;/code&gt; example above, the &lt;code&gt;hello&lt;/code&gt; variable was captured by
shared reference because the variable is only read.
As shown below, we can still use that variable after the closure declaration and usage:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

// We can still use the `hello` variable here
assert_eq!("Hello ", hello);

assert_eq!("Hello world", greeter_closure("world"));

// And here
assert_eq!("Hello ", hello);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Capture by mutable reference&lt;/head&gt;
    &lt;p&gt;It is also possible to capture by mutable reference so that the closure can alter the value of the captured variable. See this naive way to compute the sum of integers from 1 to 10:&lt;/p&gt;
    &lt;code&gt;let mut total = 0;
let add_mut_closure = |x| total += x;

// We can't access total here:
// assert_eq!(0, total);
// error[E0502]: cannot borrow `total` as immutable because it is also borrowed as mutable

(1..=10).for_each(add_mut_closure);

// But we can access total here, now that `add_mut_closure` is out of scope.
assert_eq!(55, total);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Capture by value&lt;/head&gt;
    &lt;p&gt;Finally, one can capture by value:&lt;/p&gt;
    &lt;code&gt;let last_word = "last word: ".to_owned();
let drop_closure = |sigh| {
    let res = String::new() + &amp;amp;last_word + sigh;
    drop(last_word); // Forcing the capture by value
    res
};

// We can't access `last_word` here:
// assert_eq!("last word: ".to_owned(), last_word);
// error[E0382]: borrow of moved value: `last_word`

assert_eq!("last word: sigh!", drop_closure("sigh!"));

// We can't access `last_word` here either
// assert_eq!("last word: ".to_owned(), last_word);
// error[E0382]: borrow of moved value: `last_word`

// And we can't call drop_closure again
// assert_eq!("last word: sigh!", drop_closure("sigh!"));
// error[E0382]: use of moved value: `drop_closure`
&lt;/code&gt;
    &lt;head rend="h1"&gt;FnOnce trait&lt;/head&gt;
    &lt;p&gt;In the previous example, notice the last error when trying to call &lt;code&gt;drop_closure&lt;/code&gt; twice.
Here is the full error:&lt;/p&gt;
    &lt;code&gt;error[E0382]: use of moved value: `drop_closure`
  --&amp;gt; src/main.rs:18:32
   |
12 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                --------------------- `drop_closure` moved due to this call
...
18 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                ^^^^^^^^^^^^ value used here after move
   |
note: closure cannot be invoked more than once because it moves the variable `last_word` out of its environment
  --&amp;gt; src/main.rs:5:10
   |
 5 |     drop(last_word);
   |          ^^^^^^^^^
note: this value implements `FnOnce`, which causes it to be moved when called
  --&amp;gt; src/main.rs:12:32
   |
12 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                ^^^^^^^^^^^^
&lt;/code&gt;
    &lt;p&gt;The interesting note is:&lt;/p&gt;
    &lt;code&gt;note: this value implements `FnOnce`, which causes it to be moved when called
&lt;/code&gt;
    &lt;p&gt;What is that &lt;code&gt;FnOnce&lt;/code&gt; implementation the compiler is talking about?&lt;/p&gt;
    &lt;p&gt;It is a trait automatically implemented by the compiler which state that the closure can be called at least once.&lt;/p&gt;
    &lt;p&gt;That trait is a bit special because it cannot be implemented manually in stable rust.&lt;lb/&gt; However, if we switch to unstable and enable some features, we can play with it and try to desugar how closures are actually implemented by the compiler.&lt;/p&gt;
    &lt;p&gt;Let's try to desugar the &lt;code&gt;drop_closure&lt;/code&gt; above.&lt;/p&gt;
    &lt;p&gt;First, make sure to switch to the nightly channel and to enable the following features (for example by putting them at the top of your &lt;code&gt;main.rs&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;#![feature(fn_traits)]
#![feature(unboxed_closures)]
&lt;/code&gt;
    &lt;p&gt;Next, we need to define a struct having the captured variables as fields:&lt;/p&gt;
    &lt;code&gt;struct DropStruct {
    last_word: String,
}
&lt;/code&gt;
    &lt;p&gt;Simple enough, we are capturing only one variable so our struct has one field.&lt;/p&gt;
    &lt;p&gt;Now the &lt;code&gt;FnOnce&lt;/code&gt; implementation:&lt;/p&gt;
    &lt;code&gt;impl FnOnce&amp;lt;(&amp;amp;str,)&amp;gt; for DropStruct {
    type Output = String;
    extern "rust-call" fn call_once(self, (sigh,): (&amp;amp;str,)) -&amp;gt; Self::Output {
        let res = String::new() + &amp;amp;self.last_word + sigh;
        drop(self.last_word);
        res
    }
}
&lt;/code&gt;
    &lt;p&gt;That is some weird trait!&lt;/p&gt;
    &lt;p&gt;Let's go step by step.&lt;code&gt;impl FnOnce&amp;lt;(&amp;amp;str,)&amp;gt;&lt;/code&gt; means that we are implementing a closure which takes one parameter which is a &lt;code&gt;&amp;amp;str&lt;/code&gt;.&lt;lb/&gt; If the closure took two arguments of type &lt;code&gt;i32&lt;/code&gt; and &lt;code&gt;i64&lt;/code&gt; we would have &lt;code&gt;impl FnOnce&amp;lt;(i32, i64)&amp;gt;&lt;/code&gt;. &lt;code&gt;(&amp;amp;str,)&lt;/code&gt; is the definition of a tuple of one element.
See the reference on tuple types for details.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;for DropStruct&lt;/code&gt; should not be too surprising.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;type Output = String&lt;/code&gt; specifies that our closure returns a &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;extern "rust-call"&lt;/code&gt; is some magic which I won't explain mostly because I don't know exactly why it is required.&lt;/p&gt;
    &lt;p&gt;The rest of the implementation should be self explanatory. We just took the content of the closure and replaced &lt;code&gt;last_word&lt;/code&gt; by &lt;code&gt;self.last_word&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Let's try it:&lt;/p&gt;
    &lt;code&gt;let last_word = "last word: ".to_owned();
let drop_struct = DropStruct { last_word };

// We could call `call_once`:
// assert_eq!("last word: sigh!", drop_struct.call_once(("sigh!",)));

// But more simply, we can use the function call syntax:
assert_eq!("last word: sigh!", drop_struct("sigh!"));

// And we still can't call it twice
// assert_eq!("last word: sigh!", drop_struct("sigh!"));
// error[E0382]: use of moved value: `drop_struct`
&lt;/code&gt;
    &lt;head rend="h1"&gt;FnMut trait&lt;/head&gt;
    &lt;p&gt;What about our &lt;code&gt;add_mut_closure&lt;/code&gt; from before? We were able to call it
multiple times and even mutate the capture variables.&lt;/p&gt;
    &lt;p&gt;That kind of closure implements the &lt;code&gt;FnMut&lt;/code&gt; trait.&lt;/p&gt;
    &lt;p&gt;Let's try to desugar the following closure which push elements in a vector:&lt;/p&gt;
    &lt;code&gt;let mut v = vec![];
let push_closure = |x| v.push(x);

(1..=5).for_each(push_closure);
assert_eq!(vec![1, 2, 3, 4, 5], v);
&lt;/code&gt;
    &lt;p&gt;First we need to define a struct:&lt;/p&gt;
    &lt;code&gt;struct PusherStruct&amp;lt;'a&amp;gt; {
    v: &amp;amp;'a mut Vec&amp;lt;i32&amp;gt;,
}
&lt;/code&gt;
    &lt;p&gt;Because we are capturing by reference, we need to introduce a lifetime.&lt;/p&gt;
    &lt;p&gt;Now the &lt;code&gt;FnMut&lt;/code&gt; implementation:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a&amp;gt; FnMut&amp;lt;(i32,)&amp;gt; for PusherStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, (x,): (i32,)) -&amp;gt; Self::Output {
        self.v.push(x)
    }
}
&lt;/code&gt;
    &lt;p&gt;It is very similar to the &lt;code&gt;FnOnce&lt;/code&gt; trait except that the function is called &lt;code&gt;call_mut&lt;/code&gt; instead of &lt;code&gt;call_once&lt;/code&gt; and that it takes &lt;code&gt;&amp;amp;mut self&lt;/code&gt; instead of &lt;code&gt;self&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Let's try to compile that:&lt;/p&gt;
    &lt;code&gt;error[E0277]: expected a `FnOnce(i32)` closure, found `PusherStruct&amp;lt;'a&amp;gt;`
 --&amp;gt; src/main.rs:8:5
  |
8 |     extern "rust-call" fn call_mut(&amp;amp;mut self, args: (i32,)) -&amp;gt; Self::Output {
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected an `FnOnce(i32)` closure, found `PusherStruct&amp;lt;'a&amp;gt;`
  |
help: the trait `FnOnce(i32)` is not implemented for `PusherStruct&amp;lt;'a&amp;gt;`
&lt;/code&gt;
    &lt;p&gt;Turns out we need to implement &lt;code&gt;FnOnce&lt;/code&gt; too. Remember that &lt;code&gt;FnOnce&lt;/code&gt; defines functions which can be called at least once.
In the example above, we called our closure 5 times, so it can definitely be called at least once.&lt;/p&gt;
    &lt;p&gt;Let's implement it:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a&amp;gt; FnOnce&amp;lt;(i32,)&amp;gt; for PusherStruct&amp;lt;'a&amp;gt; {
    type Output = ();
    extern "rust-call" fn call_once(mut self, args: (i32,)) -&amp;gt; Self::Output {
        self.call_mut(args)
    }
}
&lt;/code&gt;
    &lt;p&gt;Our closure does not return anything so the &lt;code&gt;Output&lt;/code&gt; is the unit.&lt;lb/&gt; As for the &lt;code&gt;call_once&lt;/code&gt; implementation, we can just call &lt;code&gt;call_mut&lt;/code&gt; to avoid repetition.&lt;/p&gt;
    &lt;p&gt;This should compile and we can now use it like so:&lt;/p&gt;
    &lt;code&gt;let mut v = vec![];
let pusher_struct = PusherStruct { v: &amp;amp;mut v };

(1..=5).for_each(pusher_struct);
assert_eq!(vec![1, 2, 3, 4, 5], v);
&lt;/code&gt;
    &lt;head rend="h1"&gt;Fn trait&lt;/head&gt;
    &lt;p&gt;Finally, there is a third trait implemented by closures which can be called multiple times and don't need a mutable reference; the Fn trait.&lt;/p&gt;
    &lt;p&gt;To see that let's try to desugar the &lt;code&gt;greeter_closure&lt;/code&gt; from before:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

assert_eq!("Hello world", greeter_closure("world"));
assert_eq!("Hello rust", greeter_closure("rust")); // Can be called multiple times
&lt;/code&gt;
    &lt;p&gt;As usual, we need to define our struct:&lt;/p&gt;
    &lt;code&gt;struct GreeterStruct&amp;lt;'a&amp;gt; {
    hello: &amp;amp;'a str,
}
&lt;/code&gt;
    &lt;p&gt;Let's not make the same mistake as before, and remember to implement &lt;code&gt;FnOnce&lt;/code&gt; and &lt;code&gt;FnMut&lt;/code&gt; first. The same way an &lt;code&gt;FnMut&lt;/code&gt; closures are also &lt;code&gt;FnOnce&lt;/code&gt; because they can be called at least once. &lt;code&gt;Fn&lt;/code&gt; closures are also &lt;code&gt;FnMut&lt;/code&gt; because if given a mutable reference, they can still perform their work which does not mutate the reference.&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a, 'b&amp;gt; FnOnce&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'a&amp;gt; {
    type Output = String;
    extern "rust-call" fn call_once(self, args: (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a, 'b&amp;gt; FnMut&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        self.call(args)
    }
}
&lt;/code&gt;
    &lt;p&gt;This should be pretty straightforward. &lt;code&gt;call_once&lt;/code&gt; and &lt;code&gt;call_mut&lt;/code&gt; are just calling &lt;code&gt;call&lt;/code&gt; which is defined in &lt;code&gt;Fn&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a, 'b&amp;gt; Fn&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'b&amp;gt; {
    extern "rust-call" fn call(&amp;amp;self, (x,): (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        String::new() + &amp;amp;self.hello + &amp;amp;x
    }
}
&lt;/code&gt;
    &lt;p&gt;And we can use it like this:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello";
let greeter_struct = GreeterStruct {
    hello,
};

assert_eq!("Hello world", greeter_struct("world"));
assert_eq!("Hello rust", greeter_struct("rust")); // Can be called multiple times
&lt;/code&gt;
    &lt;head rend="h1"&gt;The move keyword&lt;/head&gt;
    &lt;p&gt;You may already know that one can add the &lt;code&gt;move&lt;/code&gt; keyword in front of a closure to force the closure to take ownership of the capture variables even if the closure only need a reference to it.&lt;lb/&gt; For example:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ".to_owned();
let greeter_closure = move |x| String::new() + &amp;amp;hello + x;

// We can't access `hello` here
// assert_eq!("Hello ", hello);
// error[E0382]: borrow of moved value: `hello`

assert_eq!("Hello world", greeter_closure("world"));

// Nor here
// assert_eq!("Hello ", hello);
// error[E0382]: borrow of moved value: `hello`
&lt;/code&gt;
    &lt;p&gt;In order to clearly understand what we can do depending on whether the closure needs a shared reference, a mutable reference or a value and if there is &lt;code&gt;move&lt;/code&gt; keyword or not, let's introduce those small dummy functions:&lt;/p&gt;
    &lt;code&gt;fn by_ref(_data: &amp;amp;String) {}

fn by_mut(_data: &amp;amp;mut String) {}

fn by_value(_data: String) {}
&lt;/code&gt;
    &lt;p&gt;Now, let's see what we can do with different combination of move / not move and by_ref / by_mut / by_value:&lt;/p&gt;
    &lt;code&gt;let data = "by_ref".to_owned();
let by_ref_closure = || by_ref(&amp;amp;data);

// Access data while the closure is still in scope
assert_eq!("by_ref", data);

// Call the closure once
by_ref_closure();

// Call the closure multiple times
by_ref_closure();

// Access data once the closure is out of scope
assert_eq!("by_ref", data);
&lt;/code&gt;
    &lt;p&gt;Now with move:&lt;/p&gt;
    &lt;code&gt;let data = "move_by_ref".to_owned();
let move_by_ref_closure = move || by_ref(&amp;amp;data);

// Access data while the closure is still in scope
// assert_eq!("move_by_ref", data);
// error[E0382]: borrow of moved value: `data`

// Call the closure once
move_by_ref_closure();

// Call the closure multiple times
move_by_ref_closure();

// Access data once the closure is out of scope
// assert_eq!("move_by_ref", data);
// error[E0382]: borrow of moved value: `data`
&lt;/code&gt;
    &lt;p&gt;This makes sense, since the closure took ownership of &lt;code&gt;data&lt;/code&gt; we can't access it anymore from outside.&lt;/p&gt;
    &lt;p&gt;Similarly we can define the following closures:&lt;/p&gt;
    &lt;code&gt;let mut data = "by_mut".to_owned();
let by_mut_closure = || by_mut(&amp;amp;mut data);

let mut data = "move_by_mut".to_owned();
let move_by_mut_closure = move || by_mut(&amp;amp;mut data);

let data = "by_value".to_owned();
let by_value_closure = || by_value(data);

let data = "move_by_value".to_owned();
let move_by_value_closure = move || by_value(data);
&lt;/code&gt;
    &lt;p&gt;I will let you play with them, here what you should see:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;by_value&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Access when in scope&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Call once&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Call multiple times&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Access when out of scope&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And the trait implemented by each closures:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;by_value&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FnOnce&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FnMut&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fn&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
        &lt;cell&gt;‚ùå&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can see that the &lt;code&gt;move&lt;/code&gt; keyword has no impact on the implemented trait. It only changes the capture to be from reference to value.&lt;/p&gt;
    &lt;p&gt;For example, the desugaring of &lt;code&gt;by_ref_closure&lt;/code&gt; is:&lt;/p&gt;
    &lt;code&gt;struct ByRefStruct&amp;lt;'a&amp;gt; {
    data: &amp;amp;'a String,
}

impl&amp;lt;'a&amp;gt; FnOnce&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    type Output = ();
    extern "rust-call" fn call_once(self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a&amp;gt; FnMut&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a&amp;gt; Fn&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call(&amp;amp;self, (): ()) -&amp;gt; Self::Output {
        by_ref(self.data)
    }
}
&lt;/code&gt;
    &lt;p&gt;whereas for &lt;code&gt;move_by_ref_closure&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;struct MoveByRefStruct {
    data: String,
}

impl FnOnce&amp;lt;()&amp;gt; for MoveByRefStruct {
    type Output = ();
    extern "rust-call" fn call_once(self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl FnMut&amp;lt;()&amp;gt; for MoveByRefStruct {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl Fn&amp;lt;()&amp;gt; for MoveByRefStruct {
    extern "rust-call" fn call(&amp;amp;self, (): ()) -&amp;gt; Self::Output {
        by_ref(&amp;amp;self.data)
    }
}
&lt;/code&gt;
    &lt;p&gt;Notice how the &lt;code&gt;data&lt;/code&gt; field changed from &lt;code&gt;&amp;amp;'a String&lt;/code&gt; to &lt;code&gt;String&lt;/code&gt; and the call to &lt;code&gt;by_ref&lt;/code&gt; from &lt;code&gt;self.data&lt;/code&gt; to &lt;code&gt;&amp;amp;self.data&lt;/code&gt; eventhough in the closure forms we had &lt;code&gt;by_ref(&amp;amp;data)&lt;/code&gt; in both cases.&lt;/p&gt;
    &lt;p&gt;So we now hopefully understand what the &lt;code&gt;move&lt;/code&gt; keyword does but you might wonder why that can be useful? After all, the first table above shows that we only removed flexbility.&lt;/p&gt;
    &lt;p&gt;Spawning a thread:&lt;/p&gt;
    &lt;code&gt;let data = "by_ref".to_owned();
std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
&lt;/code&gt;
    &lt;p&gt;Without &lt;code&gt;move&lt;/code&gt;, we get the following compiler error which helpfully suggest adding &lt;code&gt;move&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;error[E0373]: closure may outlive the current function, but it borrows `data`, which is owned by the current function
 --&amp;gt; src/main.rs:9:20
  |
9 | std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
  |                    ^^         ---- `data` is borrowed here
  |                    |
  |                    may outlive borrowed value `data`
  |
note: function requires argument type to outlive `'static`
 --&amp;gt; src/main.rs:9:1
  |
9 | std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: to force the closure to take ownership of `data` (and any other referenced variables), use the `move` keyword
  |
9 | std::thread::spawn(move || by_ref(&amp;amp;data)).join().unwrap();
  |                    ++++
&lt;/code&gt;
    &lt;p&gt;Creating a function returning a closure:&lt;/p&gt;
    &lt;code&gt;fn make_greeter(greeter: &amp;amp;str) -&amp;gt; impl Fn(&amp;amp;str) -&amp;gt; String {
    move |name| format!("{greeter} {name}")
}

let hello_greeter = make_greeter("Hello");
let hi_greeter = make_greeter("Hi");

assert_eq!(hello_greeter("rust"), "Hello rust");
assert_eq!(hi_greeter("rust"), "Hi rust");
&lt;/code&gt;
    &lt;p&gt;Here too we need &lt;code&gt;move&lt;/code&gt; otherwise we get the same borrow checker error.&lt;/p&gt;
    &lt;head rend="h1"&gt;Last word&lt;/head&gt;
    &lt;p&gt;
      &lt;del&gt;Sigh&lt;/del&gt;
    &lt;/p&gt;
    &lt;p&gt;This article is long enough as is, so I am stopping here for now. I plan to publish a follow up article for async closures later. If you want to read more on the subject I recommend:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The closure chapter in the rust book&lt;/item&gt;
      &lt;item&gt;The closure chapter in the rust reference&lt;/item&gt;
      &lt;item&gt;The article from the baby steps blog about adding an explicit capture clause&lt;/item&gt;
      &lt;item&gt;The Rust Unstable book on fn_traits and unboxed_closures.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746266</guid><pubDate>Sat, 24 Jan 2026 18:42:13 +0000</pubDate></item><item><title>BirdyChat becomes first European chat app that is interoperable with WhatsApp</title><link>https://www.birdy.chat/blog/first-to-interoperate-with-whatsapp</link><description>&lt;doc fingerprint="8e0f2119ee313c8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;BirdyChat becomes the first European chat app that is interoperable with WhatsApp&lt;/head&gt;
    &lt;p&gt;November 14, 2025&lt;/p&gt;
    &lt;p&gt;Today we are excited to share a big milestone. BirdyChat is now the first chat app in Europe that can exchange messages with WhatsApp under the Digital Markets Act. This brings us closer to our mission of giving work conversations a proper home.&lt;/p&gt;
    &lt;p&gt;WhatsApp is currently rolling out interoperability support across Europe. As this rollout continues, the feature will become fully available to both BirdyChat and WhatsApp users in the coming months.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why this matters&lt;/head&gt;
    &lt;p&gt;Until now, you could only message people who already had a BirdyChat account. If someone was not on the app, they had to download it before you could talk. It slowed down adoption and made it harder to move real work conversations into BirdyChat.&lt;/p&gt;
    &lt;p&gt;With the new WhatsApp interface mandated by the DMA, any BirdyChat user in the EEA will be able to start a chat with any WhatsApp user in the region simply by knowing their phone number. Your contacts keep using WhatsApp. You stay on BirdyChat. Messages flow both ways.&lt;/p&gt;
    &lt;p&gt;This removes a big barrier to adopting BirdyChat for work. You no longer need to ask people to switch apps. You can keep work neatly organised in BirdyChat while staying connected to everyone who still relies on WhatsApp.&lt;/p&gt;
    &lt;head rend="h2"&gt;What interoperability lets you do&lt;/head&gt;
    &lt;p&gt;Interoperability lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Start 1:1 chats with WhatsApp users using their phone number&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Send messages, photos and files&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Communicate over an encrypted connection&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use your work email as your identity instead of a personal phone number&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes it much easier to keep work and personal life separate while staying fully reachable.&lt;/p&gt;
    &lt;head rend="h2"&gt;How the integration works&lt;/head&gt;
    &lt;p&gt;WhatsApp introduced Third-Party Chats in Europe earlier this year. BirdyChat connects through this official DMA interface and does not use any workarounds. All communication between BirdyChat and WhatsApp users is end-to-end encrypted.&lt;/p&gt;
    &lt;p&gt;Currently, BirdyChat supports 1:1 chats, with group chat interoperability coming in a future update.&lt;/p&gt;
    &lt;head rend="h2"&gt;Availability&lt;/head&gt;
    &lt;p&gt;This feature will roll out gradually to BirdyChat users across the European Economic Area. For interoperability to work, both you and your WhatsApp contacts need to be based in the EEA. Since WhatsApp is releasing interoperability as part of a gradual rollout, availability may differ slightly from country to country.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get early access&lt;/head&gt;
    &lt;p&gt;BirdyChat is invite-only while we scale access. Join the waitlist with your work email to be among the first to try WhatsApp interoperability.&lt;/p&gt;
    &lt;p&gt;Productively yours,&lt;lb/&gt;Team BirdyChat&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746476</guid><pubDate>Sat, 24 Jan 2026 19:04:08 +0000</pubDate></item><item><title>The Concatative Language XY</title><link>http://www.nsl.com/k/xy/xy.txt</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746517</guid><pubDate>Sat, 24 Jan 2026 19:08:04 +0000</pubDate></item><item><title>JSON-render: LLM-based JSON-to-UI tool</title><link>https://json-render.dev/</link><description>&lt;doc fingerprint="1c5bf3e86e0df68a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI ‚Üí json-render ‚Üí UI&lt;/head&gt;
    &lt;p&gt;Define a component catalog. Users prompt. AI outputs JSON constrained to your catalog. Your components render it.&lt;/p&gt;
    &lt;code&gt;npm install @json-render/core @json-render/react&lt;/code&gt;
    &lt;head rend="h3"&gt;Define Your Catalog&lt;/head&gt;
    &lt;p&gt;Set the guardrails. Define which components, actions, and data bindings AI can use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Users Prompt&lt;/head&gt;
    &lt;p&gt;End users describe what they want. AI generates JSON constrained to your catalog.&lt;/p&gt;
    &lt;head rend="h3"&gt;Render Instantly&lt;/head&gt;
    &lt;p&gt;Stream the response. Your components render progressively as JSON arrives.&lt;/p&gt;
    &lt;head rend="h2"&gt;Define your catalog&lt;/head&gt;
    &lt;p&gt;Components, actions, and validation functions.&lt;/p&gt;
    &lt;code&gt;import { createCatalog } from '@json-render/core';
import { z } from 'zod';

export const catalog = createCatalog({
  components: {
    Card: {
      props: z.object({
        title: z.string(),
        description: z.string().nullable(),
      }),
      hasChildren: true,
    },
    Metric: {
      props: z.object({
        label: z.string(),
        valuePath: z.string(),
        format: z.enum(['currency', 'percent']),
      }),
    },
  },
  actions: {
    export: { params: z.object({ format: z.string() }) },
  },
});&lt;/code&gt;
    &lt;head rend="h2"&gt;AI generates JSON&lt;/head&gt;
    &lt;p&gt;Constrained output that your components render natively.&lt;/p&gt;
    &lt;code&gt;{
  "key": "dashboard",
  "type": "Card",
  "props": {
    "title": "Revenue Dashboard",
    "description": null
  },
  "children": [
    {
      "key": "revenue",
      "type": "Metric",
      "props": {
        "label": "Total Revenue",
        "valuePath": "/metrics/revenue",
        "format": "currency"
      }
    }
  ]
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Export as Code&lt;/head&gt;
    &lt;p&gt;Export generated UI as standalone React components. No runtime dependencies required.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generated UI Tree&lt;/head&gt;
    &lt;p&gt;AI generates a JSON structure from the user's prompt.&lt;/p&gt;
    &lt;code&gt;{
  "root": "card",
  "elements": {
    "card": {
      "key": "card",
      "type": "Card",
      "props": { "title": "Revenue" },
      "children": ["metric", "chart"]
    },
    "metric": {
      "key": "metric",
      "type": "Metric",
      "props": {
        "label": "Total Revenue",
        "valuePath": "analytics/revenue",
        "format": "currency"
      }
    },
    "chart": {
      "key": "chart",
      "type": "Chart",
      "props": {
        "dataPath": "analytics/salesByRegion"
      }
    }
  }
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Exported React Code&lt;/head&gt;
    &lt;p&gt;Export as a standalone Next.js project with all components.&lt;/p&gt;
    &lt;code&gt;"use client";

import { Card, Metric, Chart } from "@/components/ui";

const data = {
  analytics: {
    revenue: 125000,
    salesByRegion: [
      { label: "US", value: 45000 },
      { label: "EU", value: 35000 },
    ],
  },
};

export default function Page() {
  return (
    &amp;lt;Card data={data} title="Revenue"&amp;gt;
      &amp;lt;Metric
        data={data}
        label="Total Revenue"
        valuePath="analytics/revenue"
        format="currency"
      /&amp;gt;
      &amp;lt;Chart data={data} dataPath="analytics/salesByRegion" /&amp;gt;
    &amp;lt;/Card&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;The export includes &lt;code&gt;package.json&lt;/code&gt;, component files, styles, and everything needed to run independently.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;head rend="h3"&gt;Guardrails&lt;/head&gt;
    &lt;p&gt;AI can only use components you define in the catalog&lt;/p&gt;
    &lt;head rend="h3"&gt;Streaming&lt;/head&gt;
    &lt;p&gt;Progressive rendering as JSON streams from the model&lt;/p&gt;
    &lt;head rend="h3"&gt;Code Export&lt;/head&gt;
    &lt;p&gt;Export as standalone React code with no runtime dependencies&lt;/p&gt;
    &lt;head rend="h3"&gt;Data Binding&lt;/head&gt;
    &lt;p&gt;Two-way binding with JSON Pointer paths&lt;/p&gt;
    &lt;head rend="h3"&gt;Actions&lt;/head&gt;
    &lt;p&gt;Named actions handled by your application&lt;/p&gt;
    &lt;head rend="h3"&gt;Visibility&lt;/head&gt;
    &lt;p&gt;Conditional show/hide based on data or auth&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746570</guid><pubDate>Sat, 24 Jan 2026 19:12:56 +0000</pubDate></item><item><title>Agent orchestration for the timid</title><link>https://substack.com/inbox/post/185649875</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746681</guid><pubDate>Sat, 24 Jan 2026 19:25:53 +0000</pubDate></item><item><title>Show HN: Polymcp ‚Äì Turn Any Python Function into an MCP Tool for AI Agents</title><link>https://news.ycombinator.com/item?id=46746700</link><description>&lt;doc fingerprint="d8bbc7334ade308b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I built Polymcp, a framework that allows you to transform any Python function into an MCP (Model Context Protocol) tool ready to be used by AI agents. No rewriting, no complex integrations.&lt;/p&gt;
      &lt;p&gt;Examples&lt;/p&gt;
      &lt;p&gt;Simple function:&lt;/p&gt;
      &lt;p&gt;from polymcp.polymcp_toolkit import expose_tools_http&lt;/p&gt;
      &lt;p&gt;def add(a: int, b: int) -&amp;gt; int: """Add two numbers""" return a + b&lt;/p&gt;
      &lt;p&gt;app = expose_tools_http([add], title="Math Tools")&lt;/p&gt;
      &lt;p&gt;Run with:&lt;/p&gt;
      &lt;p&gt;uvicorn server_mcp:app --reload&lt;/p&gt;
      &lt;p&gt;Now add is exposed via MCP and can be called directly by AI agents.&lt;/p&gt;
      &lt;p&gt;API function:&lt;/p&gt;
      &lt;p&gt;import requests from polymcp.polymcp_toolkit import expose_tools_http&lt;/p&gt;
      &lt;p&gt;def get_weather(city: str): """Return current weather data for a city""" response = requests.get(f"https://api.weatherapi.com/v1/current.json?q={city}") return response.json()&lt;/p&gt;
      &lt;p&gt;app = expose_tools_http([get_weather], title="Weather Tools")&lt;/p&gt;
      &lt;p&gt;AI agents can call get_weather("London") to get real-time weather data instantly.&lt;/p&gt;
      &lt;p&gt;Business workflow function:&lt;/p&gt;
      &lt;p&gt;import pandas as pd from polymcp.polymcp_toolkit import expose_tools_http&lt;/p&gt;
      &lt;p&gt;def calculate_commissions(sales_data: list[dict]): """Calculate sales commissions from sales data""" df = pd.DataFrame(sales_data) df["commission"] = df["sales_amount"] * 0.05 return df.to_dict(orient="records")&lt;/p&gt;
      &lt;p&gt;app = expose_tools_http([calculate_commissions], title="Business Tools")&lt;/p&gt;
      &lt;p&gt;AI agents can now generate commission reports automatically.&lt;/p&gt;
      &lt;p&gt;Why it matters for companies ‚Ä¢ Reuse existing code immediately: legacy scripts, internal libraries, APIs. ‚Ä¢ Automate complex workflows: AI can orchestrate multiple tools reliably. ‚Ä¢ Plug-and-play: multiple Python functions exposed on the same MCP server. ‚Ä¢ Reduce development time: no custom wrappers or middleware needed. ‚Ä¢ Built-in reliability: input/output validation and error handling included.&lt;/p&gt;
      &lt;p&gt;Polymcp makes Python functions immediately usable by AI agents, standardizing integration across enterprise software.&lt;/p&gt;
      &lt;p&gt;Repo: https://github.com/poly-mcp/Polymcp&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746700</guid><pubDate>Sat, 24 Jan 2026 19:27:58 +0000</pubDate></item><item><title>Show HN: StormWatch ‚Äì Weather emergency dashboard with prep checklists</title><link>https://jeisey.github.io/stormwatch/</link><description>&lt;doc fingerprint="7279a67378a22c29"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Welcome to StormWatch&lt;/head&gt;
    &lt;p&gt;Tap "Set Location" below to get started&lt;/p&gt;
    &lt;head rend="h2"&gt;Current Conditions&lt;/head&gt;
    &lt;p&gt; ‚Äî ¬∞F &lt;/p&gt;
    &lt;p&gt;‚Äî&lt;/p&gt;
    &lt;p&gt;Humidity&lt;/p&gt;
    &lt;p&gt;‚Äî%&lt;/p&gt;
    &lt;p&gt;Wind&lt;/p&gt;
    &lt;p&gt;‚Äî mph&lt;/p&gt;
    &lt;p&gt;Visibility&lt;/p&gt;
    &lt;p&gt;‚Äî mi&lt;/p&gt;
    &lt;head rend="h2"&gt;Next 12 Hours&lt;/head&gt;
    &lt;head rend="h2"&gt;7-Day Forecast&lt;/head&gt;
    &lt;head rend="h2"&gt;Precipitation Chance&lt;/head&gt;
    &lt;p&gt;No significant precipitation expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Snow &amp;amp; Ice Forecast&lt;/head&gt;
    &lt;p&gt;Snow&lt;/p&gt;
    &lt;p&gt;Ice&lt;/p&gt;
    &lt;p&gt;No snow or ice expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Wind Forecast&lt;/head&gt;
    &lt;p&gt;No significant wind expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Weather News&lt;/head&gt;
    &lt;p&gt; Showing news for your area and surrounding region &lt;/p&gt;
    &lt;p&gt;Weather news for your area will appear here&lt;/p&gt;
    &lt;head rend="h2"&gt;Impact Timeline&lt;/head&gt;
    &lt;p&gt;No weather impacts expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Action Checklist&lt;/head&gt;
    &lt;p&gt;No preparation needed ‚Äî conditions are normal&lt;/p&gt;
    &lt;head rend="h2"&gt;Supply Calculator&lt;/head&gt;
    &lt;p&gt; 2 &lt;/p&gt;
    &lt;p&gt; Data from NWS &amp;amp; GDELT. Not official. Verify with local authorities. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746900</guid><pubDate>Sat, 24 Jan 2026 19:40:52 +0000</pubDate></item><item><title>Bye Bye Gmail</title><link>https://m24tom.com/bye-bye-gmail/show</link><description>&lt;doc fingerprint="6e10811b1f73f28d"&gt;
  &lt;main&gt;
    &lt;p&gt;Friends,&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;TLDR: Please remove @gmail.com as my primary email address and substitute removed. I will try to respond to email sent to @gmail.com but no guarantees.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A week or two ago I was surprised to see a Google Gemini summary at the top of my email on my phone. A day or two later this appeared in my web client as well. Look, I love our new overlords (for the record m'lords I nearly always use "please" and "thank you"). I was an early adopter and introduced many of you to the LLMs. I still am a frequent user... I mean someone who has all the answers and blows smoke up my ass... perfect right!&lt;/p&gt;
    &lt;p&gt;Despite that, it appears it's not good for me ( https://www.media.mit.edu/publications/your-brain-on-chatgpt/ ). It's great, it's easy, makes me feel good in the moment... of course it's bad for me!&lt;/p&gt;
    &lt;p&gt;Here's the thing. I like to read things from my friends that they have taken the time to write. I personally hate texting. All the nuance is gone. Often the humor. Sad. Makes me want to have a beer with you... eye contact... blech. The LAST thing I want is a summary... at the top of the email... highlighted... that I CANNOT turn off.&lt;/p&gt;
    &lt;p&gt;I tried to turn it off. I can. It's under &lt;code&gt;Gmail -&amp;gt; Settings -&amp;gt; General -&amp;gt; Smart Features (checkbox)&lt;/code&gt;. BUT... the AI summaries is now grouped with the Smart Tabs.&lt;/p&gt;
    &lt;p&gt;For those of you who do not use Gmail (or do use Gmail and don't use Smart Tabs), Smart Tabs (officially the Tabbed Inbox) have been part of Gmail since 2013; well actually the technology behind them‚ÄîSmart Labels‚Äîactually debuted two years earlier. (Thank you Gemini, yes I DO truly love you. Tell me again about the comparisons of Stephen Miller and Heinrich Himmler's tactics please?)&lt;/p&gt;
    &lt;p&gt;Smart Tabs automatically sort my incoming flood of solicited commercial email (cue laughter from those who know my first start-up) into five buckets:&lt;/p&gt;
    &lt;p&gt;I tried turning off Smart Features and oh my, that's not usable. So I lived with the AI summary at the top. For a week. Then this morning, I saw several messages in my Primary tab that normally get sorted into Promotions, Social, Updates or Forums. This is not unheard of; sometimes a company uses a new incoming address or something and stuff gets put in the wrong bucket.&lt;/p&gt;
    &lt;p&gt;But THIS time, I got a popup that says I must "Share" this message with Google and links to the Privacy Policy and Google Terms of Service. And an explicit sentence:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Messages and attachments might be reviewed by humans, so don't share any sensitive or confidential information."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I'm not naive. I'm an early adopter, my email address includes my name and no numbers. I was a direct marketer when we still were the red-headed step-children of the product managers. I carpooled to Symantec with Google employee no 11's girlfriend (Go Beavers!) From the get-go, having Google read my email in order to provide targeted advertising was part of the deal. I was fine with that.&lt;/p&gt;
    &lt;p&gt;BUT... now... what they are saying is that... we are going to use your email to train our LLMs. I'm not okay with that. That knowledge of my way of writing, my personal details, my confidential commercial information is NOT okay to use to train your models. 'Cause I expect mistakes will be made and more information will reside in the model than those at Google (or FB, MSFT etc) intended. And I'm not really up for assuming that risk.&lt;/p&gt;
    &lt;p&gt;So... goodbye Gmail. It's been great. Really great. I'm sure I'll miss you. Bye.&lt;/p&gt;
    &lt;p&gt;My email is now being hosted by Microsoft, so hopefully will be free of the outages and limits some of you have experienced with that email in the past. There it will reside until I cannot turn off MSFT's ability to read my email. Then I guess it's off to Switzerland ( https://proton.me/about ); my email can be with my gold. JK..NR&lt;/p&gt;
    &lt;p&gt;Tom&lt;/p&gt;
    &lt;p&gt;p.s. why thank you Gemini for reformatting that for me into a clean, engaging markdown blog post. Yes, I do agree this is a sharp, timely take on the "AI-ification" of tools we use every day. I love you. Kill me last?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46746946</guid><pubDate>Sat, 24 Jan 2026 19:44:52 +0000</pubDate></item><item><title>Why Does Destroying Resources via TF Suck?</title><link>https://newsletter.masterpoint.io/p/why-does-destroying-resources-via-tf-suck</link><description>&lt;doc fingerprint="174d0c3e869dc2b0"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IaC Insights&lt;/item&gt;
      &lt;item&gt;Posts&lt;/item&gt;
      &lt;item&gt;Why Does Destroying Resources Via TF Suck?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Why Does Destroying Resources Via TF Suck?&lt;/head&gt;
    &lt;head rend="h2"&gt;The one IaC operation nobody wants to talk about.&lt;/head&gt;
    &lt;p&gt;Hey folks,&lt;/p&gt;
    &lt;p&gt;I had a new colleague ask a question which boiled down to "Why does destroying resource via TF suck?‚Äù&lt;/p&gt;
    &lt;p&gt;Here‚Äôs my answer.&lt;/p&gt;
    &lt;p&gt;Destroying resources is just generally harder than creating them because the cloud can have lots of gotchas when determining "Is this resource okay to delete?".&lt;/p&gt;
    &lt;p&gt;Perhaps the resource:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;is protected from deletion. AWS S3 buckets, databases, EC2 instances, and other types of resources can all have deletion protection configured.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;is attached to other resources. Do you delete them, leave them dangling or ask the user?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;is actively processing something that needs confirmation to stop.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Plenty of situations can block a destroy action.&lt;/p&gt;
    &lt;p&gt;Typically, unless you need to destroy that resource as a regular part of your workflow for some subset of infrastructure, which is not a common action, it's best to treat these painful interactions with the cloud and IaC as a one-off operation.&lt;/p&gt;
    &lt;p&gt;Accept the pain and handle it the best you can. That usually means doing some level of manual ClickOps delete action in the console or something similar.&lt;/p&gt;
    &lt;p&gt;That said, if you find yourself running into this problem over and over, then it can be useful to investigate that specific destroy operation and try to automate and optimize that process.&lt;/p&gt;
    &lt;p&gt;Maybe you need to have a process that empties your bucket before you attempt to destroy it. Maybe you need to stop adding items to a workstream, then wait for the processing to finish. Maybe you need to turn off deletion protection for your dev database instances. But don't do the same for your prod ones! Trust me, you want to avoid FRD.&lt;/p&gt;
    &lt;p&gt;Since this is not a common Day 2 operation I wouldn't worry too much about optimizing resource deletion. Only put effort into it if you're hitting your head against it again and again.&lt;/p&gt;
    &lt;p&gt;May your resource deletion be both seldom and fast,&lt;/p&gt;
    &lt;p&gt;Matt @ Masterpoint&lt;/p&gt;
    &lt;p&gt;PS Are you interested in being on a devops-focused podcast? Reply to me with the topic you want to discuss and I‚Äôm happy to intro you to the right podcast. Or, if you want to chat about S3 buckets, ClickOps or FRD, grab some time on my calendar here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46747022</guid><pubDate>Sat, 24 Jan 2026 19:53:31 +0000</pubDate></item><item><title>Propositions about the New Romanticism</title><link>https://www.honest-broker.com/p/25-propositions-about-the-new-romanticism</link><description>&lt;doc fingerprint="ffc21b5b21a78586"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;25 Propositions about the New Romanticism&lt;/head&gt;
    &lt;head rend="h3"&gt;A blueprint for the future&lt;/head&gt;
    &lt;p&gt;This article would normally be behind a paywall. But I‚Äôm making it freely available to all readers.&lt;/p&gt;
    &lt;p&gt;If you find value in this analysis and want to read articles like this in the future, I encourage you to take out a premium subscription.&lt;/p&gt;
    &lt;head rend="h3"&gt;Please support my work by taking out a paid subscription (just $6 per month‚Äîor even less if you sign up for a year).&lt;/head&gt;
    &lt;p&gt;More than two years ago, I predicted the rise of a New Romanticism‚Äîa movement to counter the intense rationalization and expanding technological control of society.&lt;/p&gt;
    &lt;p&gt;This idea had started as a joke. Oh Beethoven, come save us! And give Tchaikovsky the news.&lt;/p&gt;
    &lt;p&gt;But when I dug deeply into the history of the original Romanticist movement, circa 1800, I stopped laughing. The more I probed, the more I was convinced that this provided a blueprint for countering the overreach of technology, the massive expansion in surveillance, and the centralization of both political and economic power.&lt;/p&gt;
    &lt;p&gt;It had worked back then. The Age of Romanticism had seen the abolition of slavery, protections for workers, prohibitions on child labor, a growing respect for human dignity, and a blossoming of the arts.&lt;/p&gt;
    &lt;p&gt;Industrialists wept. But somehow they survived.&lt;/p&gt;
    &lt;p&gt;Romanticism had countered cold profit-driven industrialization with human values. And economic growth had actually accelerated in response to this more balanced approach.&lt;/p&gt;
    &lt;p&gt;Could it happen again? I thought it could. And now, two years, later, I‚Äôm convinced that the shift is already underway.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how I described it back then:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;From ‚ÄúNotes Toward a New Romanticism‚Äù (November 2023)&lt;/p&gt;
      &lt;p&gt;I realized that, the more I looked at what happened circa 1800, the more it reminded me of our current malaise.&lt;/p&gt;
      &lt;p&gt;Rationalist and algorithmic models were dominating every sphere of life at that midpoint in the Industrial Revolution‚Äîand people started resisting the forces of progress.&lt;/p&gt;
      &lt;p&gt;Companies grew more powerful, promising productivity and prosperity. But Blake called them ‚Äúdark Satanic mills‚Äù and Luddites started burning down factories‚Äîa drastic and futile step, almost the equivalent of throwing away your smartphone.&lt;/p&gt;
      &lt;p&gt;Even as science and technology produced amazing results, dysfunctional behaviors sprang up everywhere. The pathbreaking literary works from the late 1700s reveal the dark side of the pervasive techno-optimism‚ÄîGoethe‚Äôs novel about Werther‚Äôs suicide, the Marquis de Sade‚Äôs nasty stories, and all those gloomy Gothic novels. What happened to the Enlightenment?&lt;/p&gt;
      &lt;p&gt;As the new century dawned, the creative class (as we would call it today) increasingly attacked rationalist currents that had somehow morphed into violent, intrusive forces in their lives‚Äîan 180 degree shift in the culture. For Blake and others, the name Newton became a term of abuse.&lt;/p&gt;
      &lt;p&gt;Artists, especially poets and musicians, took the lead in this revolt. They celebrated human feeling and emotional attachments‚Äîembracing them as more trustworthy, more flexible, more desirable than technology, profits, and cold calculation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the two years since I wrote that, the notion of a New Romanticism has spread like a wildfire.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;For valuable commentary on the subject, you should check out Ross Barkan, Santiago Ramos, Dr. Anjan Chatterjee, Kate Alexandra, Megha Lillywhite, and Campbell Frank Scribner. That‚Äôs just a start.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The new Romanticon Substack, launched in September, is now an important part of the movement.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I see hints of the New Romanticism in the most popular TV series (Severance, Pluribus, Yellowstone, etc.).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The extraordinary growth in romance, fantasy, romantasy and other fanciful literary genres tells the same story. Many readers are seeking an escape from hard-headed realism in the current moment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I find sympathetic voices among public intellectuals‚Äîmany of them mentioned here in recent months (Jonathan Haidt, Charles Taylor, Iain McGilchrist, Jennifer Frey, Paul Kingsnorth, Byung-Chul Han, etc.).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These people lack political or economic power. But they reflect the new attitude of the public‚Äîand that will become increasingly clear as the US approaches election day later this year.&lt;/p&gt;
    &lt;p&gt;This movement is not going away. It will only intensify.&lt;/p&gt;
    &lt;p&gt;For a long time, I‚Äôve wanted to write more on the New Romanticism. Given the growing momentum of this movement, now is probably a good time to define it more clearly.&lt;/p&gt;
    &lt;p&gt;With that goal, I‚Äôm sharing 25 propositions. These will help you anticipate future events‚Äîat least that‚Äôs my goal.&lt;/p&gt;
    &lt;p&gt;Others will probably have a slightly different take on this‚Äîso I can‚Äôt claim any sweeping authority for my statements. These simply outline what this movement means to me, and where I think it‚Äôs heading.&lt;/p&gt;
    &lt;head rend="h3"&gt;THE NEW ROMANTICISM: 25 PROPOSITIONS&lt;/head&gt;
    &lt;head rend="h3"&gt;1.&lt;/head&gt;
    &lt;p&gt;The most important things in human life can‚Äôt be reduced to software code or numbers on a spreadsheet. Here are some of them: Love, Trust, Compassion, Friendship, Forgiveness, Faith, Hope, Charity, Creative Expression, Integrity, Nature, Kindness, Beauty.&lt;/p&gt;
    &lt;p&gt;These are the key parameters of the Romanticist life.&lt;/p&gt;
    &lt;head rend="h3"&gt;2.&lt;/head&gt;
    &lt;p&gt;In ages of intense Rationalism, these things get marginalized‚Äîor in some cases eradicated. It‚Äôs no coincidence that people are struggling in the current environment to find love, friendship, trust, etc. The rationalist system is not built to foster these human connections‚Äîeven the largest data center can‚Äôt generate them.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.&lt;/head&gt;
    &lt;p&gt;Rationalism has created tremendous benefits for society, but in its final stages it becomes self-serving. The system aims to expand its control no matter the consequences for people inside the system. It starts to feel intrusive and oppressive.&lt;/p&gt;
    &lt;head rend="h3"&gt;4.&lt;/head&gt;
    &lt;p&gt;This is happening right now. Rationalism has become voracious and refuses to recognize any limits. It wants to swallow up everything. All human things get turned into an app.&lt;/p&gt;
    &lt;p&gt;Even art and inspiration get replaced by inhuman data‚Äîbeauty becomes one more output from a cold unfeeling system. The system now wants you to work to assist the expansion of data. And your own value is reduced to the ways your personal data can get monetized.&lt;/p&gt;
    &lt;p&gt;But it doesn‚Äôt stop there. The system urges you to seek out more data in your playtime. You even have the option of falling in love with a data construct.&lt;/p&gt;
    &lt;head rend="h3"&gt;5.&lt;/head&gt;
    &lt;p&gt;We‚Äôve reached an endgame where this process turns into a mockery of language. The word progress no longer refers to actual progress, merely an expansion of technological control‚Äîso every software upgrade feels like a downgrade.&lt;/p&gt;
    &lt;p&gt;The same is true of the word productivity. Productivity gains are now the source of widespread unemployment and impoverishment‚Äîbecause only a few technocrats capture the economic benefits.&lt;/p&gt;
    &lt;p&gt;The word science also gets tainted. Scientific information is increasingly indistinguishable from propaganda‚Äîso much so that the predominant use of new tech is to produce fakery (fake images, fake video, fake books, fake people, all the way to fake answers on a test).&lt;/p&gt;
    &lt;p&gt;The whole system feels like it‚Äôs built on deception in the service of the will to power.&lt;/p&gt;
    &lt;head rend="h3"&gt;6.&lt;/head&gt;
    &lt;p&gt;Romanticism flips the equation‚Äîthe system is forced to serve the people, instead of the people serving the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;7.&lt;/head&gt;
    &lt;p&gt;Just as there is a New Romanticism, there is also a New Rationalism. A typical exponent is the criminal financier Sam Bankman-Fried, who mocked Shakespeare (although SBH would ‚Äúnever read a book‚Äù‚Äîso how could he judge literature?), and tried to reduce human values to a kind of maximization problem on a math test.&lt;/p&gt;
    &lt;p&gt;Other exponents of the New Rationalism are individuals who seem strangely drained of emotion and human connection‚ÄîThiel, Musk, Altman, Zuckerberg, etc. This is the Rationalist character type‚Äîa zero degree of personality. They are people you would trust with a spreadsheet, but not to babysit your child or care for an elder.&lt;/p&gt;
    &lt;head rend="h3"&gt;8.&lt;/head&gt;
    &lt;p&gt;This zero personality type is obsessed with AI‚Äîthe god created in its own image‚Äîwhich becomes the defining technology of the New Rationalism. But no matter how smart AI gets, it will never create an app that can forgive. Or fall in love. Or feel the pangs of parenthood. Or grieve the death of a loved one. Or grasp the sublime.&lt;/p&gt;
    &lt;head rend="h3"&gt;9.&lt;/head&gt;
    &lt;p&gt;It will try to mimic all these things. That‚Äôs the travesty of the dominant data-built system‚Äîa built-in dishonesty. You can tell that Rationalism is now reaching its breaking point because of the intense level of deceit and pretense it now requires to expand its sphere of control.&lt;/p&gt;
    &lt;head rend="h3"&gt;10.&lt;/head&gt;
    &lt;p&gt;This pretense is also an admission that AI needs that human dimension‚Äîhuman feeling is essential to its goals but impossible to achieve. With every move it makes, the technocracy shows its hunger for the same humanism it‚Äôs working to destroy.&lt;/p&gt;
    &lt;head rend="h3"&gt;11.&lt;/head&gt;
    &lt;p&gt;This rationalist world has gradually been drained of enchantment. The shift to life via digital apps and interfaces represents the final stage of disenchantment.&lt;/p&gt;
    &lt;head rend="h3"&gt;12.&lt;/head&gt;
    &lt;p&gt;People now feel the horror and claustrophobia of this imposed disenchantment. This creates a hunger for magic that the system cannot provide.&lt;/p&gt;
    &lt;head rend="h3"&gt;13.&lt;/head&gt;
    &lt;p&gt;Romanticism aims to recover enchantment‚Äîat first for individuals, but ultimately for groups and communities.&lt;/p&gt;
    &lt;p&gt;That‚Äôs why Romanticism nurtures creativity, storytelling, self-expression, emotion, ecstasy, aesthetic awe‚Äîthings that can‚Äôt be manipulated like data and content.&lt;/p&gt;
    &lt;head rend="h3"&gt;14.&lt;/head&gt;
    &lt;p&gt;Rationalism tries to compensate for its lack of a soul by imitating a religion or cult. It establishes its own dogmas and rituals with the fervor of true believers.&lt;/p&gt;
    &lt;p&gt;Tens of thousands of people already treat AI as a kind of god. That‚Äôs not happenstance, but symptomatic of this tendency. The participant in the rationalist belief system also needs a higher power, and finds it in the machine.&lt;/p&gt;
    &lt;head rend="h3"&gt;15.&lt;/head&gt;
    &lt;p&gt;Systematized rationalism is about total control. That‚Äôs inevitable in any worldview without a moral compass. So it doesn‚Äôt respect human limits‚Äîbut has an inherent urge to expand its sphere of control, no matter what consequences ensue.&lt;/p&gt;
    &lt;p&gt;We are in great danger when science and technology grow faster than our moral awareness of how to use the tools they create. The same thing happened during the Industrial Revolution‚Äîuntil the Romanticist backlash imposed constraints and reforms.&lt;/p&gt;
    &lt;p&gt;Until that took place, factory owners and plantation bosses treated humans as mere inputs in a cold rationalized process. The similarities with our current situation are hard to miss.&lt;/p&gt;
    &lt;head rend="h3"&gt;16.&lt;/head&gt;
    &lt;p&gt;At some point even the scientists lose control‚Äîas we learned when they invented nuclear weapons or gunpowder or coronaviruses. The people who built the atomic bomb could only hand it off to the most powerful politicians. That inevitably happened in every country where nuclear weapons were made.&lt;/p&gt;
    &lt;p&gt;If AI achieves the degree of power its proponents predict, the same handoff will happen. It will become another tool of control for entrenched rulers. To expect otherwise is naive.&lt;/p&gt;
    &lt;head rend="h3"&gt;17.&lt;/head&gt;
    &lt;p&gt;Romanticism is the opposite of all this. It is about maintaining some small space of freedom from total control. It protects people, not a hierarchy of machines and machine owners.&lt;/p&gt;
    &lt;head rend="h3"&gt;18.&lt;/head&gt;
    &lt;p&gt;Ages of intense rationalized control do not last forever. They create an inevitable backlash by pushing to extremes. This is why the industrialization of Europe led to the great age of Romanticism.&lt;/p&gt;
    &lt;p&gt;The Romanticists demanded protections for workers, laws against child labor, an end to slavery, and other defenses against total control of a rationalized system. Something like this will happen again.&lt;/p&gt;
    &lt;head rend="h3"&gt;19.&lt;/head&gt;
    &lt;p&gt;A counterculture is always inherently Romantic. It resists the overreach of the dominant system.&lt;/p&gt;
    &lt;p&gt;A society that doesn‚Äôt listen to its counterculture‚Äîor, worse, tries to silence it‚Äîhas destroyed its most valuable feedback loop.&lt;/p&gt;
    &lt;head rend="h3"&gt;20.&lt;/head&gt;
    &lt;p&gt;The dominant system today is built on analysis. And it‚Äôs worth remembering that the root meaning of analysis is the reduction of things into parts.&lt;/p&gt;
    &lt;p&gt;Holistic thinking, in contrast, is always inherently Romantic. You can also call this visionary thinking.&lt;/p&gt;
    &lt;head rend="h3"&gt;21.&lt;/head&gt;
    &lt;p&gt;The goal isn‚Äôt to stop Rationalism. The goal is to make it serve human ends. Instead the system is moving hellbent in the opposite direction.&lt;/p&gt;
    &lt;head rend="h3"&gt;22.&lt;/head&gt;
    &lt;p&gt;Even Romanticism can be pushed to dangerous extremes. When it rose as a counterweight to the Enlightenment, circa 1800, the Romanticist impulse had a healthy influence on society for a period of roughly fifty years. Then it got entangled in intense nationalist rivalries and other dysfunctional trends. So anything I say in favor of Romanticism is solely with regard to the current context.&lt;/p&gt;
    &lt;p&gt;At the present moment, it would provide a healthy corrective. But that doesn‚Äôt mean that the Romanticist impulse is beneficial in every setting.&lt;/p&gt;
    &lt;head rend="h3"&gt;23.&lt;/head&gt;
    &lt;p&gt;Healing begins with each individual. This is still possible, even in repressive situations. Rebellion emerges first in the inner life‚Äîwhich the Rationalists can‚Äôt control.&lt;/p&gt;
    &lt;p&gt;That‚Äôs always the initial step in Romanticist eras. Individuals nurture their inner life. Then they can form communities and push for more humane policies and institutions.&lt;/p&gt;
    &lt;head rend="h3"&gt;24.&lt;/head&gt;
    &lt;p&gt;Rationalism appears powerful, but is actually vulnerable‚Äîbecause it‚Äôs empty inside. It lacks a heart and soul. In any real conflict, this is a huge weakness‚Äîbecause conflicts are won by the most passionate, not by the most rigorously analytical.&lt;/p&gt;
    &lt;head rend="h3"&gt;25.&lt;/head&gt;
    &lt;p&gt;The New Romanticism is more than an intellectual movement. It will be promoted by people who don‚Äôt even recognize that label. They will demand a more human-oriented society. They will care about creative expression. They will seek to nurture their souls‚Äîand do so without apologies, not worrying about what can be quantified or measured. They recognize the value of intangibles, and the dead-end of a data-driven life.&lt;/p&gt;
    &lt;p&gt;This is already starting to happen‚Äîthe movement is gaining strength even at this very moment.&lt;/p&gt;
    &lt;head rend="h3"&gt;If you value these perspectives, please consider taking out a premium subscription.&lt;/head&gt;
    &lt;p&gt;I will revisit this subject in the future. Others will too‚Äîbecause this conflict in worldviews is now too large to ignore.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46747078</guid><pubDate>Sat, 24 Jan 2026 19:59:05 +0000</pubDate></item><item><title>Postmortem: Our first VLEO satellite mission (with imagery and flight data)</title><link>https://albedo.com/post/clarity-1-what-worked-and-where-we-go-next</link><description>&lt;doc fingerprint="ae1dcadd78b58dbb"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Clarity-1: What Worked, and Where We Go Next&lt;/head&gt;
    &lt;p&gt;On March 14, 2025, Albedo's first satellite, Clarity-1, launched on SpaceX Transporter-13. We took a big swing with our pathfinder. The mission goals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Prove sustainable orbit operations in VLEO ‚Äî an orbital regime long considered too harsh for commercial satellites ‚Äî by overcoming thick atmospheric drag, dangerous atomic oxygen, and extreme speeds.&lt;/item&gt;
      &lt;item&gt;Prove our mid-size, high-performance Precision bus ‚Äî designed and built in-house in just over two years.&lt;/item&gt;
      &lt;item&gt;Capture 10 cm resolution visible imagery and 2-meter thermal infrared imagery, a feat previously achieved only by exquisite, billion dollar government systems.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We proved a ton. We learned a ton.&lt;/p&gt;
    &lt;p&gt;We achieved the first two goals definitively and validated 98% of the technology required for the third. This was an extraordinarily ambitious first satellite. We designed and built a high-performance bus on time and on budget, integrated a large-aperture telescope, and operated in an environment no commercial company had sustained operations in, funded entirely by private capital.&lt;/p&gt;
    &lt;p&gt;This is the full story.&lt;/p&gt;
    &lt;head rend="h1"&gt;VLEO Works&lt;/head&gt;
    &lt;p&gt;Let's start with the result that matters most: VLEO works. And it works better than even we expected.&lt;/p&gt;
    &lt;p&gt;For decades, Very Low Earth Orbit was written off as impractical for normal satellite lifetimes. The atmosphere is thicker, creating drag that would deorbit normal satellites in weeks. If the drag didn't kill you, atomic oxygen would erode your solar arrays and surfaces. To succeed in VLEO required a fundamentally different satellite design.&lt;/p&gt;
    &lt;p&gt;Clarity-1 proved that our design works.&lt;/p&gt;
    &lt;p&gt;The drag coefficient was the headline: 12% better than our design target. Measured multiple times at altitudes between 350 km - 380 km with a repeatable result, this validates our models producing a satellite lifespan of five years at 275 km altitude, averaged across the solar cycle. This was one of our most critical assumptions, and we exceeded it.&lt;/p&gt;
    &lt;p&gt;Atomic oxygen (AO) is the silent killer in VLEO. The deeper you go, the more AO you encounter. It degrades solar arrays and other traditional satellite materials. We developed a new class of solar arrays with unique measures designed to mitigate AO degradation. They work. Even as we descended deeper into VLEO and AO fluence increased logarithmically, our power generation stayed constant. The solar arrays are holding up as designed.&lt;/p&gt;
    &lt;p&gt;Clarity-1 demonstrated over 100 km of controlled altitude descent, stationkeeping in VLEO, and survived a solar storm that temporarily spiked atmospheric density ‚Äî the impact on Clarity's descent rate was barely noticeable. Momentum management worked. Fault detection worked. Our thrust planning model was validated against GOCE data (a 2009 VLEO R&amp;amp;D mission) with sub-meter accuracy. Radiation tolerance was excellent, with 4x fewer single-event upsets than expected. Orbit determination was dialed.&lt;/p&gt;
    &lt;p&gt;We proved sustainable VLEO operations.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Precision Bus is Flight-Proven&lt;/head&gt;
    &lt;p&gt;Developed and built in just over two years, our in-house bus Precision is now TRL-9: flight-proven on-orbit.&lt;/p&gt;
    &lt;p&gt;Every bus subsystem worked. Every piece of in-house technology we developed performed: our CMG steering law, our operational modes, flight and ground software, electronics boards, and our novel thermal management system. We hit our embedded software GNC timing deadlines, we converged our attitude and orbit determination estimators, we saw 4œÄ steradian command and telemetry antenna coverage, and we got on-orbit actuals for our power generation and loads.&lt;/p&gt;
    &lt;p&gt;Our cloud-native ground system was incredible. Contact planning across 25 ground stations was completely automated. Mission scheduling updated every 15 minutes to incorporate new tasking and the latest satellite state information, smoothly transitioning to updated on-board command loads with visual tracking of each schedule and its status. Automated thrust planning to achieve our desired orbital trajectory supported 30+ maneuvers per day. Our engineers could track and command the satellite from anywhere with internet and a secure VPN.&lt;/p&gt;
    &lt;p&gt;We pushed 14 successful flight software feature updates on-orbit. The ability to continuously improve throughout Clarity's operational life proved essential ‚Äî every major solution to challenges we faced involved flight software updates. On-orbit software upgrades are exceedingly tricky to get right, but Clarity-1 was designed from day one around this foundational capability.&lt;/p&gt;
    &lt;head rend="h1"&gt;Four Weeks of Perfection&lt;/head&gt;
    &lt;p&gt;The first month of the mission was magic.&lt;/p&gt;
    &lt;p&gt;An hour after launch, we watched Clarity-1 deploy from the premium caketopper slot into LEO, giving us an incredible view of the Nile River as she separated from the rocket.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;First contact came just three hours later at 5:11am MT. Imagine sitting in Mission Control, watching two ground station passes with no data, then on the third: heaps of green, healthy telemetry streaming into all of the subsystem dashboards. Clarity had nailed her autonomous boot-up sequence and rocket separation rate capture. Stuck the landing.&lt;/p&gt;
    &lt;p&gt;The next milestone ‚Äî and the one many of us were most anxious about ‚Äî was our autonomous Protect Mode, basically our VLEO version of Safe Mode.&lt;/p&gt;
    &lt;p&gt;We estimated a week.&lt;/p&gt;
    &lt;p&gt;We nailed it 14 hours after launch.&lt;/p&gt;
    &lt;p&gt;By 6:45pm that same day, Clarity was in Operational mode, ready for commissioning.&lt;/p&gt;
    &lt;p/&gt;
    &lt;quote&gt;"Gotta say it: the last 16 hours have been incredible. I started my shift last night hoping to see one bit of data. I wouldn't have believed it if someone told me we'd be in Protect within 14 hours from launch."‚Äî Albedo GNC Engineer&lt;/quote&gt;
    &lt;p/&gt;
    &lt;p&gt;The days that followed were a blur of checkboxes turning green. 4-CMG commissioning complete. Payload power-on and checkout validated. Thermal balance for both visible and thermal sensors confirmed. Our first on-orbit software update went flawlessly.&lt;/p&gt;
    &lt;p&gt;Clarity uses Control Moment Gyroscopes (CMGs) to steer the satellite, giving us more agility than more commonly used reaction wheels. We moved onto validating GNC modes such as GroundTrack, which we use to point at communication ground terminals.&lt;/p&gt;
    &lt;p&gt;We moved on to commissioning our X-band radio ‚Äî the high-rate link to downlink imagery. After we uncovered an issue with our ground station provider‚Äôs pointing mode, the 800 Mbps link began pumping down data on every pass. The waveforms were clean. Textbook. A direct representation of how locked in our precision CMG pointing was.&lt;/p&gt;
    &lt;p&gt;With our first satellite at this level of complexity, we couldn't believe how smoothly it had gone. Years of developing new technologies had been validated in a fraction of the commissioning time we'd anticipated.&lt;/p&gt;
    &lt;head rend="h1"&gt;Maneuvering over 100 km to VLEO&lt;/head&gt;
    &lt;p&gt;Next up was maneuvering from our LEO drop-off altitude down to VLEO, where it would be safe to eject the telescope contamination cover and start snapping pictures.&lt;/p&gt;
    &lt;p&gt;Then came April 14.&lt;/p&gt;
    &lt;p&gt;One of our four CMGs experienced a temperature spike in the flywheel bearing. Our Fault Detection, Isolation, and Recovery (FDIR) logic caught it immediately, spun it down, and executed automated recovery actions. But it wouldn't spin back up. Manual recovery attempts followed. Also unsuccessful.&lt;/p&gt;
    &lt;p&gt;Rushing back into CMG operations without understanding the failure mechanism risked killing the mission entirely, so we turned off the other three and put the satellite in two-axis stabilization using the magnetic torque rods.&lt;/p&gt;
    &lt;p&gt;We had a choice. Hack together novel 3-CMG control algorithms as fast as possible and risk losing another, or figure out how to leverage only the torque rods to achieve 3-axis control with sufficient accuracy to navigate the maneuver to VLEO.&lt;/p&gt;
    &lt;p&gt;We went with the torque rods.&lt;/p&gt;
    &lt;p&gt;On satellites this size (~600 kg), magnetic torque rods are typically used for momentum dumping, not attitude control. But we'd built Clarity with unusually beefy torque rods due to the elevated momentum management needs in VLEO. Our GNC team went heads down and developed algorithms to achieve 3-axis attitude control using only torque rods.&lt;/p&gt;
    &lt;p&gt;Within a month, we had it working.&lt;/p&gt;
    &lt;p&gt;Both of our electric thrusters commissioned quickly and were working well. But with torque rods only, our attitude control had 15 to 20 degrees of error, sometimes reaching ~45 degrees. And maneuvering to VLEO isn‚Äôt ‚Äúpoint into the wind and fire‚Äù ‚Äî it‚Äôs continuous vector and trajectory management across an orbit. That kind of control error meant inefficient burns and a much harder descent plan.&lt;/p&gt;
    &lt;p&gt;As the descent progressed, however, the team learned and iterated. With more iteration and flight software updates, we uploaded onboard logic informed by several sources of live data that dialed in our thrust vector control to within 5 degrees of the target. The autonomous thrust planning system we built enabled us to claw back performance that nearly matched our originally projected descent speed.&lt;/p&gt;
    &lt;p&gt;We maneuvered safely past the ISS and entered VLEO. Eager to pop off the contamination cover.&lt;/p&gt;
    &lt;head rend="h1"&gt;Lens Cap Jettison&lt;/head&gt;
    &lt;p&gt;Once we reached safe altitude, it was time to jettison the contamination cover protecting our telescope.&lt;/p&gt;
    &lt;p&gt;There are horror stories about contamination covers getting stuck after months of temperature fluctuations.&lt;/p&gt;
    &lt;p&gt;Clarity's was flawless. I'll never forget seeing this blip in telemetry live ‚Äî confirming through Newton's third law that the jettison was successful. Shortly after, LeoLabs confirmed tracking of two separate objects.&lt;/p&gt;
    &lt;p&gt;We were ready to start imaging.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Imaging Journey&lt;/head&gt;
    &lt;p&gt;Here's where it got complicated.&lt;/p&gt;
    &lt;p&gt;Our GNC and FSW teams were close but not yet finished with the new 3-CMG control law. CMGs are rarely used in commercial space, let alone by a startup. Then take one more step: singularity-prone 3-CMG control that to our knowledge has not been attempted on a non-exquisite satellite, and certainly not developed and uploaded on-orbit. Traditional algorithms require at least four CMGs to provide capability volumes free of singularities.&lt;/p&gt;
    &lt;p&gt;We were eager to make some amount of progress, so we started imaging on torque rods even though there would be severe limitations: 50+ pixels of smear, large mispointing from the wobble of torque rod control due to earth's magnetic field, and downlink limited to at best two small images per day. The last two constraints meant we were at risk of spending precious downlink capacity on clouds.&lt;/p&gt;
    &lt;p&gt;Sure enough, the first two days of pixels were mostly clouds, but we were happy to peek through a little in this image.&lt;/p&gt;
    &lt;p&gt;Although we couldn't control attitude accurately, we did still have good attitude knowledge after the fact. AyJay whipped up a clever idea with Claude Code that automated posting weather conditions in Slack for each collection. We analyzed that to determine which images were likely clear, and selected those for downlink.&lt;/p&gt;
    &lt;p&gt;Boom:&lt;/p&gt;
    &lt;p&gt;We adjusted the focus position a few times, and images continued getting better.&lt;/p&gt;
    &lt;p&gt;Then, 3-CMG control was ready.&lt;/p&gt;
    &lt;p&gt;Out of the box, the new algorithms and software performed perfectly.&lt;/p&gt;
    &lt;p&gt;This visualization shows real telemetry of Clarity performing seven back-to-back imaging maneuvers, with limited 3-CMG agility, followed by an X-band downlink over Iceland minutes later. The satellite was executing sophisticated attitude profiles with very low control error. Fiber-optic gyro measurements showed exquisite jitter performance.&lt;/p&gt;
    &lt;p&gt;In real time, collecting and downlinking those seven images took ten minutes.&lt;/p&gt;
    &lt;p&gt;And this is where our ground software really showed its teeth. On most missions, ‚Äúdata on the ground‚Äù is just the start ‚Äî turning raw bits into something viewable is a slow chain of handoffs and batch processing. For us, within seconds of the downlink finishing, the image product pipeline was already posting processed snippets into our company Slack. Literally seconds.&lt;/p&gt;
    &lt;p&gt;That end-to-end loop ‚Äî photons in orbit to a viewable product on the ground, within minutes ‚Äî is a capability that‚Äôs still rare in this industry.&lt;/p&gt;
    &lt;p&gt;As expected with smear reduced, image quality improved immediately.&lt;/p&gt;
    &lt;p&gt;We were ready to execute focus calibration.&lt;/p&gt;
    &lt;p&gt;Large telescope optics experience hygroscopic dryout during the first few months on-orbit ‚Äî moisture trapped in materials during ground assembly slowly releases in the vacuum of space, causing the focus position to drift. Dialing in best focus requires dozens of iterations: capture images, analyze sharpness, adjust focus position, repeat. Each cycle gets you closer to the optical performance the system was designed for, and our telescope‚Äôs on-ground alignment was verified to spec.&lt;/p&gt;
    &lt;p&gt;We continued to iterate.&lt;/p&gt;
    &lt;p&gt;After a few iterations of this, we could start to see cars.&lt;/p&gt;
    &lt;p&gt;Even this early into imaging, the infrared images blew us away. Using a low-cost microbolometer ‚Äî a fraction of the price of cooled IR sensors ‚Äî we captured thermal signatures that showed ships in Tokyo Bay, steel processing facilities where we could distinguish individual coke ovens from their smokestacks, and distinct signatures between real vegetation and turf ‚Äî a good proxy for camouflage detection. Day or night, clear as day.&lt;/p&gt;
    &lt;p&gt;Three days into the excitement, CMG problems started again.&lt;/p&gt;
    &lt;p&gt;A second CMG began showing the same telemetry signatures we now recognized as warning signs.&lt;/p&gt;
    &lt;p&gt;What we had learned from the investigation: the allowable temperature specifications of the CMGs were much higher than the true limit, constrained by what the lubricant inside the flywheel could handle. A straightforward fix for the future ‚Äî an unfortunate corner case to learn about in hindsight.&lt;/p&gt;
    &lt;p&gt;The second CMG showing issues was also on the hot side of the satellite. While we had overhauled the vehicle and CMG operations to prevent additional bearing wear, the damage had already been done in the first month of the mission.&lt;/p&gt;
    &lt;p&gt;We spent months trying everything we could to get the CMGs to operate sustainably. The team attempted many clever solutions, one of which revived the first CMG that had locked up. We uploaded a feature to select any 3 of the 4 CMGs for operator commanding. But we weren't able to get sustained, reliable operation.&lt;/p&gt;
    &lt;p&gt;Despite the CMG challenges, here's what the imaging journey proved.&lt;/p&gt;
    &lt;p&gt;The full end-to-end image chain works. Photons hit our optics, get captured by our sensor, processed through payload electronics, packetized and encrypted, transmitted via our X-band radio, received on the ground, and processed into image products. The entire chain is validated.&lt;/p&gt;
    &lt;p&gt;The end-to-end loop is fast. Within 30 seconds of a downlink, processed image snippets were already posting to our company Slack.&lt;/p&gt;
    &lt;p&gt;Sensor performance exceeded expectations. Dynamic range, radiometry, color balance, band-to-band alignment ‚Äî all look great, even on uncalibrated imagery.&lt;/p&gt;
    &lt;p&gt;We can scan out long images. Our line-scanning approach produced strips 20-30 kilometers long, exactly as designed.&lt;/p&gt;
    &lt;p&gt;Pointing accuracy and high quality telemetry validates the ingredients for precise geolocation. The data we need to pinpoint where each pixel lands on Earth to &amp;lt;5m (closed-loop CE90) is there.&lt;/p&gt;
    &lt;p&gt;Jitter and smear are low. Fiber-optic gyro measurements confirmed 3x lower smear and 11x lower jitter compared to our goal ‚Äî a critical ingredient for exquisite imagery.&lt;/p&gt;
    &lt;p&gt;Our proprietary image scheduler works. The automated system that plans collections, manages constraints, and optimizes what we capture each day performed as designed.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where Clarity Is Now&lt;/head&gt;
    &lt;p&gt;Nine months into the mission, we lost contact with Clarity-1.&lt;/p&gt;
    &lt;p&gt;By that point, we had largely exhausted our options on the CMGs. The path to further image quality improvement had effectively closed.&lt;/p&gt;
    &lt;p&gt;We had been tracking intermittent memory issues in our TT&amp;amp;C radio throughout the mission, working around them as they appeared. Our best theory is that one of these issues escalated in a way that corrupted onboard memory and is preventing reboots. We've tried several recovery approaches. So far, none have worked, and the likelihood of recovery looks low at this point.&lt;/p&gt;
    &lt;p&gt;But here's what matters: the VLEO validation data we collected is sufficient.&lt;/p&gt;
    &lt;p&gt;We combined a state-of-the-art atmospheric density model, our high-fidelity orbital dynamics force models, and months of natural orbit decay data from 350 to 380 km altitude to determine Clarity‚Äôs coefficient of drag ‚Äî with repeatable results at different altitudes. That drag coefficient, paired with our demonstrated ability to maintain altitude in VLEO for months using high-efficiency thrusters, tells us exactly how the vehicle behaves under aerodynamic drag across the VLEO regime ‚Äî and validates an average five-year lifespan at 275 km across the solar cycle. Telemetry from our solar arrays, together with onboard atomic oxygen sensor data, shows peak power generation stayed constant after exposure to VLEO levels of AO fluence ‚Äî proving our AO mitigation worked.&lt;/p&gt;
    &lt;p&gt;Thanks to our friends at LeoLabs, we've validated that Clarity is maintaining attitude autonomously. She's still up there, still oriented, still descending through VLEO. Just not talking to us.&lt;/p&gt;
    &lt;p&gt;Even before this, we had started developing an in-house TT&amp;amp;C radio for our systems moving forward, rather than reusing this radio that was procured from a third party. We‚Äôll incorporate learnings from this reliability issue into that.&lt;/p&gt;
    &lt;p&gt;We're still working the problem. This chapter isn't over yet. But even if it is, Clarity-1 gave us what we needed to build what comes next.&lt;/p&gt;
    &lt;head rend="h1"&gt;98% of The 10 cm Imagery Pyramid&lt;/head&gt;
    &lt;p&gt;If you think about exquisite imagery as a pyramid, we needed 100% of the systems working together to achieve the pinnacle: 10 cm visible imagery. We got to about 98%. Everything else in that pyramid ‚Äî the entire foundation ‚Äî is proven and retired.&lt;/p&gt;
    &lt;p&gt;Our drag coefficient. Our atomic oxygen resilience. Our solar arrays. Our thermal management. Our flight software. Our ground software. Our CMG steering laws. Our precision pointing algorithms. Our payload electronics. Our sensor performance. Our image processing chain. Our ability to operate sustainably in VLEO. Our team.&lt;/p&gt;
    &lt;p&gt;All validated.&lt;/p&gt;
    &lt;p&gt;We know exactly what to fix. It‚Äôs straight forward: operate the CMGs at lower temperature. The system thermal design is already updated in the next build to maximize CMG life going forward.&lt;/p&gt;
    &lt;p&gt;Beyond the CMGs, there were a handful of learnings on the margins. We learned our secondary mirror structure could be stiffer ‚Äî already in the updated design. We learned we could use more heater capacity in some payload zones ‚Äî already fixed.&lt;/p&gt;
    &lt;p&gt;We learned from the things that worked, too. We're well down the development path for next-gen flight software, avionics, and power distribution. Orbit determination and geolocation will be even better. Additional surface treatments will improve drag coefficient further. Power-generation will increase while maintaining the proven atomic oxygen resilience. The list goes on.&lt;/p&gt;
    &lt;p&gt;The path to exquisite imagery is clear. And that‚Äôs only one of many exciting capabilities unlocked by sustainable operations in VLEO.&lt;/p&gt;
    &lt;head rend="h1"&gt;What‚Äôs Next&lt;/head&gt;
    &lt;p&gt;Our next VLEO mission will incorporate these learnings and demonstrate new features that enable missions beyond imaging ‚Äî we‚Äôll share more details soon. In parallel, imaging remains a core focus: we‚Äôre continuing to build optical payloads for EO/IR missions as part of a broader VLEO roadmap.&lt;/p&gt;
    &lt;p&gt;The successes of Clarity-1 reinforced our core conviction: VLEO isn‚Äôt just a better orbit for imaging ‚Äî it‚Äôs the next productive orbital layer.&lt;/p&gt;
    &lt;p&gt;The physics are unforgiving, but that‚Äôs exactly why it matters. Go lower and you unlock a step-change in performance: sharper sensing, faster links, lower latency, and a new level of responsiveness. The reason VLEO has been written off for decades isn‚Äôt lack of upside ‚Äî it‚Äôs that most satellites simply can‚Äôt survive there long enough to matter.&lt;/p&gt;
    &lt;p&gt;Now we know they can.&lt;/p&gt;
    &lt;p&gt;Clarity proved the hard parts: sustainable VLEO operations, validated drag and lifetime models, atomic oxygen resilience, and a flight-proven high-performance bus. We‚Äôre not speculating about VLEO. We‚Äôre operating in it, learning in it, and capitalized to scale it.&lt;/p&gt;
    &lt;p&gt;Onward,&lt;/p&gt;
    &lt;p&gt;Topher &amp;amp; Team Albedo&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46747119</guid><pubDate>Sat, 24 Jan 2026 20:03:39 +0000</pubDate></item><item><title>Show HN: JSciPy ‚Äì SciPy-inspired signal processing library for Java and Android</title><link>https://github.com/hissain/jscipy</link><description>&lt;doc fingerprint="4e9c1a1e06d976cc"&gt;
  &lt;main&gt;
    &lt;p&gt;jSciPy is a comprehensive Java Scientific Computing and Signal Processing Library designed for Machine Learning on the JVM and Android. Inspired by Python's SciPy, it provides high-performance implementations of essential algorithms.&lt;/p&gt;
    &lt;p&gt;It currently includes modules for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Signal Processing: Butterworth, Chebyshev, Elliptic, Bessel, and FIR (&lt;code&gt;firwin&lt;/code&gt;) filters, Window Functions, 2D Convolution, Savitzky-Golay smoothing, Peak detection, Detrending, Median Filter.&lt;/item&gt;
      &lt;item&gt;Transformations: FFT (Fast Fourier Transform), Hilbert Transform, Welch PSD, Spectrogram, Periodogram, Convolution, DCT/IDCT.&lt;/item&gt;
      &lt;item&gt;Math &amp;amp; Analysis: RK4 ODE Solver, Interpolation (Linear, Cubic Spline), Resampling, Polynomial fitting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In modern machine learning workflows, most signal processing tasks rely on Python's SciPy utilities. However, there is no Java library that replicates SciPy's behavior with comparable completeness and consistency. This creates a significant gap for teams building ML or signal processing pipelines on the JVM. jSciPy aims to fill this gap, and the demand for such a library is higher than ever.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why jSciPy?&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Accuracy &amp;amp; Precision&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Getting Started&lt;/item&gt;
      &lt;item&gt;How to Include as a Dependency (JitPack)&lt;/item&gt;
      &lt;item&gt;Demo Android Application&lt;/item&gt;
      &lt;item&gt;Comparison Graphs &lt;list rend="ul"&gt;&lt;item&gt;Butterworth Filter&lt;/item&gt;&lt;item&gt;Chebyshev Filter&lt;/item&gt;&lt;item&gt;Elliptic Filter&lt;/item&gt;&lt;item&gt;Bessel Filter&lt;/item&gt;&lt;item&gt;RK4 Solver&lt;/item&gt;&lt;item&gt;FindPeaks&lt;/item&gt;&lt;item&gt;Interpolation&lt;/item&gt;&lt;item&gt;FFT&lt;/item&gt;&lt;item&gt;Welch's Method&lt;/item&gt;&lt;item&gt;Spectrogram&lt;/item&gt;&lt;item&gt;STFT/ISTFT&lt;/item&gt;&lt;item&gt;Periodogram&lt;/item&gt;&lt;item&gt;Resample&lt;/item&gt;&lt;item&gt;Savitzky-Golay&lt;/item&gt;&lt;item&gt;Detrend&lt;/item&gt;&lt;item&gt;MedFilt&lt;/item&gt;&lt;item&gt;1D Convolve&lt;/item&gt;&lt;item&gt;2D Convolve&lt;/item&gt;&lt;item&gt;Cross-Correlation&lt;/item&gt;&lt;item&gt;DCT&lt;/item&gt;&lt;item&gt;Polynomial Fit&lt;/item&gt;&lt;item&gt;2D FFT&lt;/item&gt;&lt;item&gt;Hilbert Transform&lt;/item&gt;&lt;item&gt;SOS Filtering&lt;/item&gt;&lt;item&gt;Window Functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Usage Examples&lt;/item&gt;
      &lt;item&gt;Contributing&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The table below compares jSciPy‚Äôs signal processing and scientific computing features with several other popular Java libraries, highlighting areas where jSciPy provides more comprehensive functionality.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Feature / Characteristic&lt;/cell&gt;
        &lt;cell role="head"&gt;jSciPy&lt;/cell&gt;
        &lt;cell role="head"&gt;Commons Math&lt;/cell&gt;
        &lt;cell role="head"&gt;JDSP&lt;/cell&gt;
        &lt;cell role="head"&gt;TarsosDSP&lt;/cell&gt;
        &lt;cell role="head"&gt;IIRJ&lt;/cell&gt;
        &lt;cell role="head"&gt;EJML&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Primary Focus&lt;/cell&gt;
        &lt;cell&gt;SciPy-style Signal + Scientific&lt;/cell&gt;
        &lt;cell&gt;General Math/Stats&lt;/cell&gt;
        &lt;cell&gt;Java DSP Toolbox&lt;/cell&gt;
        &lt;cell&gt;Audio Processing&lt;/cell&gt;
        &lt;cell&gt;IIR Filter Only&lt;/cell&gt;
        &lt;cell&gt;Linear Algebra&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Zero-Phase Filtering (&lt;code&gt;filtfilt&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes (SciPy-compatible)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;2D Signal Ops (&lt;code&gt;conv2d&lt;/code&gt;, &lt;code&gt;fft2&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;SciPy-like API Consistency&lt;/cell&gt;
        &lt;cell&gt;‚úÖ High (SciPy semantics)&lt;/cell&gt;
        &lt;cell&gt;‚ùå Low&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Filtering Capabilities&lt;/cell&gt;
        &lt;cell&gt;‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (IIR+FIR+advanced)&lt;/cell&gt;
        &lt;cell&gt;‚≠ê Basic&lt;/cell&gt;
        &lt;cell&gt;‚≠ê‚≠ê‚≠ê (IIR/FIR &amp;amp; adaptive)&lt;/cell&gt;
        &lt;cell&gt;‚≠ê‚≠ê (audio filters)&lt;/cell&gt;
        &lt;cell&gt;‚≠ê‚≠ê (IIR only)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Transforms (FFT/DCT/Hilbert)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ FFT, DCT + Hilbert&lt;/cell&gt;
        &lt;cell&gt;Limited / Basic FFT only&lt;/cell&gt;
        &lt;cell&gt;‚úÖ FFT + Hilbert&lt;/cell&gt;
        &lt;cell&gt;‚úÖ FFT spectrum tools (audio)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Interpolation (Linear/Cubic)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;ODE Solvers (RK4)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Signal Analysis (Peak/PSD)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Welch PSD&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Spectrogram&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Window Functions&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Savitzky-Golay Filter&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Median Filter (&lt;code&gt;medfilt&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Detrending&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Real-Optimized FFT (&lt;code&gt;rfft&lt;/code&gt;/&lt;code&gt;irfft&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;STFT / ISTFT Support&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes (SciPy-like)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes (dedicated classes)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;1D Convolution with Modes (&lt;code&gt;convolve&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes (with modes)&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Resampling (&lt;code&gt;resample&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Signal Padding Utilities (&lt;code&gt;padSignal&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Configurable Peak Finding (&lt;code&gt;find_peaks&lt;/code&gt; with prominence etc.)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Cross-Correlation (&lt;code&gt;correlate&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Polynomials (&lt;code&gt;polyfit&lt;/code&gt;, &lt;code&gt;polyval&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes (via Commons Math)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
        &lt;cell&gt;‚ùå No&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advanced Filtering: Butterworth, Chebyshev, Elliptic, Bessel, FIR Design (&lt;code&gt;firwin&lt;/code&gt;). Supports zero-phase (&lt;code&gt;filtfilt&lt;/code&gt;), causal (&lt;code&gt;lfilter&lt;/code&gt;), and Second-Order Sections (&lt;code&gt;sosfilt&lt;/code&gt;) modes.&lt;/item&gt;
      &lt;item&gt;2D Processing: &lt;code&gt;convolve2d&lt;/code&gt;(Full/Same/Valid),&lt;code&gt;fft2&lt;/code&gt;,&lt;code&gt;ifft2&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Transforms: standard 1D &lt;code&gt;fft&lt;/code&gt;/&lt;code&gt;ifft&lt;/code&gt;, real-optimized&lt;code&gt;rfft&lt;/code&gt;/&lt;code&gt;irfft&lt;/code&gt;,&lt;code&gt;dct&lt;/code&gt;/&lt;code&gt;idct&lt;/code&gt;(Discrete Cosine Transform),&lt;code&gt;stft&lt;/code&gt;/&lt;code&gt;istft&lt;/code&gt;,&lt;code&gt;hilbert&lt;/code&gt;transform.&lt;/item&gt;
      &lt;item&gt;Smoothing &amp;amp; Analysis: Savitzky-Golay, &lt;code&gt;medfilt&lt;/code&gt;(Median Filter),&lt;code&gt;find_peaks&lt;/code&gt;, Welch's PSD,&lt;code&gt;spectrogram&lt;/code&gt;,&lt;code&gt;detrend&lt;/code&gt;,&lt;code&gt;resample&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Correlation: &lt;code&gt;correlate&lt;/code&gt;(Cross-Correlation with FULL/SAME/VALID modes).&lt;/item&gt;
      &lt;item&gt;Polynomials: &lt;code&gt;polyfit&lt;/code&gt;,&lt;code&gt;polyval&lt;/code&gt;,&lt;code&gt;polyder&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Window Functions: Hamming, Hanning, Blackman, Kaiser, Bartlett, Flat-top, Parzen, Bohman, Triangle.&lt;/item&gt;
      &lt;item&gt;Numerical Methods: Interpolation (Linear, Cubic Spline), RK4 ODE Solver.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;jSciPy is rigorously tested against Python's SciPy using a "Golden Master" approach. Below is a summary of the precision (RMSE) achieved across various modules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Module&lt;/cell&gt;
        &lt;cell role="head"&gt;Test Case&lt;/cell&gt;
        &lt;cell role="head"&gt;RMSE (Approx)&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Filters&lt;/cell&gt;
        &lt;cell&gt;Butterworth, Chebyshev, Elliptic, Bessel&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-14&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;FFT&lt;/cell&gt;
        &lt;cell&gt;1D FFT, RFFT, IFFT&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-15&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Spectral&lt;/cell&gt;
        &lt;cell&gt;Spectrogram, Welch, STFT/ISTFT, Periodogram&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-16&lt;/code&gt; to &lt;code&gt;1e-18&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SOS Filt&lt;/cell&gt;
        &lt;cell&gt;Second-Order Sections Filter&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2D Ops&lt;/cell&gt;
        &lt;cell&gt;2D FFT, 2D Convolution&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Math&lt;/cell&gt;
        &lt;cell&gt;Interpolation, Resample&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DCT&lt;/cell&gt;
        &lt;cell&gt;DCT Type-II, Ortho&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-15&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Poly&lt;/cell&gt;
        &lt;cell&gt;Polyfit, Val, Der&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-14&lt;/code&gt; to &lt;code&gt;1e-15&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ODE&lt;/cell&gt;
        &lt;cell&gt;RK4 Solver&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5e-13&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;‚úÖ Excellent&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You can access full documentation javadoc of the jscipy library HERE.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java Development Kit (JDK) 8 or higher&lt;/item&gt;
      &lt;item&gt;Gradle (for building the project)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JitPack is a novel package repository for JVM projects. It builds GitHub projects on demand and provides ready-to-use artifacts (jar, javadoc, sources).&lt;/p&gt;
    &lt;p&gt;To use this library in your Gradle project, add the JitPack repository and the dependency to your &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;// In your root build.gradle (or settings.gradle for repository definition)
allprojects {
    repositories {
        mavenCentral()
        maven { url 'https://jitpack.io' }
    }
}

// In your app's build.gradle
dependencies {
    implementation 'com.github.hissain:jSciPy:3.1.3' // Replace 3.1.3 with the desired version or commit hash
}&lt;/code&gt;
    &lt;p&gt;A seperate demo android application is built on this library that might be helpful to understand how to consume this library. The application can be accessed here.&lt;/p&gt;
    &lt;p&gt;Type I:&lt;/p&gt;
    &lt;p&gt;Type II:&lt;/p&gt;
    &lt;p&gt;Smoothing:&lt;/p&gt;
    &lt;p&gt;Differentiation:&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;All standard IIR filters (Butterworth, Chebyshev I/II, Elliptic, Bessel) are supported with consistent APIs.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;

public class FilterExample {
    public static void main(String[] args) {
        double[] signal = {/*... input data ...*/};
        double fs = 100.0;
        double fc = 10.0;
        int order = 4;

        // 1. Butterworth: Zero-phase vs Causal
        double[] zeroPhase = Signal.filtfilt(signal, fs, fc, order);
        double[] causal = Signal.lfilter(signal, fs, fc, order);

        // 2. Chebyshev Type I (Ripple 1dB) &amp;amp; Type II (Stopband 20dB)
        double[] cheby1 = Signal.cheby1_filtfilt(signal, fs, fc, order, 1.0);
        double[] cheby2 = Signal.cheby2_filtfilt(signal, fs, fc, order, 20.0);

        // 3. Elliptic (Ripple 1dB, Stopband 40dB)
        double[] ellip = Signal.ellip_filtfilt(signal, fs, fc, order, 1.0, 40.0);
        
        // 4. Bessel (Linear Phase)
        double[] bessel = Signal.bessel_filtfilt(signal, fs, fc, order);

        // Filter Modes: High-pass, Band-pass, Band-stop
        // Available for all filter types (suffix: _highpass, _bandpass, _bandstop)
        double[] bandPass = Signal.filtfilt_bandpass(signal, fs, 8.0, 4.0, order); // Center=10, Width=4

        // 5. Second-Order Sections (SOS) Filtering
        // If you have SOS coefficients (e.g., from Python/SciPy)
        double[][] sos = { /* ... 6 coefficients per section ... */ };
        double[] sosFiltered = Signal.sosfilt(signal, sos);
    }
}&lt;/code&gt;
    &lt;p&gt;Cross-correlation and polynomial fitting/evaluation.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.Math;
import com.hissain.jscipy.signal.ConvolutionMode;

public class MathSignalExample {
    public static void main(String[] args) {
        // 1. Cross-Correlation
        double[] x = {1, 2, 3};
        double[] target = {0, 1, 0.5};
        // equivalent to convolve(x, reverse(target), mode)
        double[] corr = Signal.correlate(x, target, ConvolutionMode.FULL);
        
        // 2. Discrete Cosine Transform (DCT Type-II)
        double[] dct = Signal.dct(x);             // Standard
        double[] dctOrtho = Signal.dct(x, true);  // Ortho-normalized
        
        // 3. Polynomials
        // Fit a 2nd degree polynomial to (x, y) points
        double[] xPoints = {0, 1, 2, 3};
        double[] yPoints = {1, 2, 5, 10}; // roughly x^2 + 1
        
        // Coefficients: [1.0, 0.0, 1.0] (for x^2 + 1)
        double[] coeffs = Math.polyfit(xPoints, yPoints, 2);
        
        // Evaluate polynomial at new points
        double[] val = Math.polyval(coeffs, new double[]{4, 5}); 
        
        // Compute derivative: [2.0, 0.0] (2x)
        double[] deriv = Math.polyder(coeffs);
    }
}&lt;/code&gt;
    &lt;p&gt;Includes 1D/2D FFT, DCT/IDCT, STFT/ISTFT, Welch's Method, Periodogram, spectrogram, and Hilbert Transform.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.signal.JComplex;
import com.hissain.jscipy.signal.fft.Welch;
import com.hissain.jscipy.signal.fft.Spectrogram;
import com.hissain.jscipy.signal.fft.Hilbert;

public class SpectralExample {
    public static void main(String[] args) {
        double[] signal = {/*... input data ...*/};
        double fs = 1000.0;

        // 1. FFT / IFFT
        JComplex[] fft = Signal.fft(signal);
        JComplex[] ifft = Signal.ifft(fft);
        
        // 2. Real-optimized FFT (RFFT)
        JComplex[] rfft = Signal.rfft(signal);
        
        // 3. Welch's Method (PSD)
        Welch.WelchResult psd = Signal.welch(signal, fs, 256);
        // Access: psd.f (frequencies), psd.Pxx (power spectrum)

        // 4. Spectrogram
        Spectrogram.SpectrogramResult spec = Signal.spectrogram(signal, fs);
        // Access: spec.frequencies, spec.times, spec.Sxx

        // 5. Hilbert Transform (Analytic Signal)
        Hilbert h = new Hilbert();
        JComplex[] analytic = h.hilbert(signal);

        // 6. Short-Time Fourier Transform (STFT)
        JComplex[][] stft = Signal.stft(signal); // Uses default nperseg=256, noverlap=128
        
        // 7. Inverse STFT
        double[] reconstructed = Signal.istft(stft);
    }
}&lt;/code&gt;
    &lt;p&gt;Common operations for signal conditioning and feature extraction.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.signal.filter.SavitzkyGolay;
import com.hissain.jscipy.signal.filter.MedFilt;

public class OperationsExample {
    public static void main(String[] args) {
        double[] signal = {/*... data ...*/};

        // 1. Savitzky-Golay Smoothing
        SavitzkyGolay sg = new SavitzkyGolay();
        double[] smoothed = sg.savgol_filter(signal, 5, 2); // Window=5, PolyOrder=2
        double[] deriv = sg.savgol_filter(signal, 5, 2, 1, 1.0); // 1st Derivative

        // 2. Peak Detection
        // Min Height=0.5, Min Distance=10, Min Prominence=0.2
        int[] peaks = Signal.find_peaks(signal, 0.5, 10, 0.2);

        // 3. Median Filter
        double[] med = new MedFilt().medfilt(signal, 3); // Kernel=3

        // 4. Convolution (Mode: SAME, FULL, VALID)
        double[] window = {0.25, 0.5, 0.25};
        double[] conv = Signal.convolve(signal, window, ConvolutionMode.SAME);
        
        // 5. Detrending (Linear)
        double[] detrended = Signal.detrend(signal, DetrendType.LINEAR);
        
        // 6. Resampling (Up/Down sampling)
        // Note: Resampling is part of the Math module
        double[] resampled = com.hissain.jscipy.Math.resample(signal, NEW_LENGTH);
    }
}&lt;/code&gt;
    &lt;p&gt;General-purpose numerical utilities.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.math.RK4Solver;
import com.hissain.jscipy.Math;

public class MathExample {
    public static void main(String[] args) {
        // 1. Interpolation (Linear &amp;amp; Cubic)
        double[] x = {0, 1, 2}, y = {0, 1, 4};
        double[] query = {0.5, 1.5};
        
        double[] lin = Math.interp1d_linear(x, y, query);
        double[] cub = Math.interp1d_cubic(x, y, query);

        // 2. RK4 ODE Solver (dy/dt = -y)
        RK4Solver solver = new RK4Solver();
        RK4Solver.Solution sol = solver.solve((t, y) -&amp;gt; -y, y0, t0, tf, step);
    }
}&lt;/code&gt;
    &lt;p&gt;Contributions are welcome! Please read our Contribution Guidelines for details on our workflow and coding standards. Feel free to submit issues or pull requests.&lt;/p&gt;
    &lt;p&gt;We are actively looking for contributors to help with:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Performance Benchmarking: Creating benchmarks for large datasets to compare Java's performance vs NumPy/SciPy.&lt;/item&gt;
      &lt;item&gt;Feature Expansion: Implementing missing window functions or additional filter types.&lt;/item&gt;
      &lt;item&gt;Edge Case Robustness: Improving handling of &lt;code&gt;NaN&lt;/code&gt;,&lt;code&gt;Infinity&lt;/code&gt;, and edge cases in signal processing algorithms.&lt;/item&gt;
      &lt;item&gt;Documentation: Adding more usage examples and javadocs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to join in community discord? click here&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46747351</guid><pubDate>Sat, 24 Jan 2026 20:31:41 +0000</pubDate></item><item><title>I added a Bluesky comment section to my blog</title><link>https://micahcantor.com/blog/bluesky-comment-section.html</link><description>&lt;doc fingerprint="bc4caf037f2e3bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;I added a Bluesky comment section to my blog&lt;/head&gt;Published on&lt;p&gt;You can now view replies to this blog post made on Bluesky directly on this website. Check it out here!&lt;/p&gt;&lt;p&gt;I've always wanted to host a comment section on my site, but it's difficult because the content is statically generated and hosted on a CDN. I could host comments on a separate VPS or cloud service. But maintaining a dynamic web service like this can be expensive and time-consuming ‚Äî in general, I'm not interested in being an unpaid, part-time DevOps engineer.&lt;/p&gt;&lt;p&gt;Recently, however, I read a blog post by Cory Zue about how he embedded a comment section from Bluesky on his blog. I immediately understood to benefits of this approach. With this approach, Bluesky could handle all of the difficult work involved in managing a social media like account verification, hosting, storage, spam, and moderation. Meanwhile because Bluesky is an open platform with a public API, it's easy to directly embed comments on my own site.&lt;/p&gt;&lt;p&gt;There are other services that could be used for this purpose instead. Notably, I could embed replies from the social media formerly known as Twitter. Or I could use a platform like Disqus or even giscus, which hosts comments on GitHub Discussions. But I see Bluesky as a clearly superior choice among these options. For one, Bluesky is built on top of an open social media platform in AT Proto, meaning it can't easily be taken over by an authoritarian billionaire creep. Moreover, Bluesky is a full-fledged social media platform, which naturally makes it a better option for hosting a conversation than GitHub.&lt;/p&gt;&lt;p&gt;Zue published a standalone package called bluesky-comments that allows embedding comments in a React component as he did. But I decided to build this feature myself instead. Mainly this is because I wanted to make a few styling changes anyway to match the rest of my site. But I also wanted to leave the option open to adding more features in the future, which would be easier to do if I wrote the code myself. The entire implementation is small regardless, amounting to only ~200 LOC between the UI components and API functions.&lt;/p&gt;&lt;p&gt;Initially, I planned to allow people to directly post on Bluesky via my site. This would work by providing an OAuth flow that gives my site permission to post on Bluesky on behalf of the user. I actually did get the auth flow working, but building out a UI for posting and replying to existing comments is difficult to do well. Going down this path quickly leads to building what is essentially a custom Bluesky client, which I didn't have the time or interest in doing right now. Moreover, because the user needs to go through the auth flow and sign-in to their Bluesky account, the process is not really much easier than posting directly on a linked Bluesky post.&lt;/p&gt;&lt;p&gt;Without the requirement of allowing others to directly post on my site, the implementation became much simpler. Essentially, my task was to specify a Bluesky post that corresponds to the article in the site's metadata. Then, when the page loads I fetch the replies to that post from Bluesky, parse the response, and display the results in a simple comment section UI.&lt;/p&gt;&lt;p&gt;As explained in my last post, this site is built using React Server Components and Parcel. The content of my articles are written using MDX, an extension to Markdown that allows directly embedding JavaScript and JSX. In each post, I export a &lt;code&gt;metadata&lt;/code&gt; object that I validate using a Zod schema. For instance, the metadata for this post looks like this:&lt;/p&gt;&lt;p&gt;The value of &lt;code&gt;bskyPostId&lt;/code&gt; references the Bluesky post from which I'll pull replies to display in the comment section. Because my project is built in TypeScript, it was easy to integrate with the Bluesky TypeScript SDK (&lt;code&gt;@bluesky/api&lt;/code&gt; on NPM). Reading the Bluesky API documentation and Zue's implementation led me to the &lt;code&gt;getPostThread&lt;/code&gt; endpoint. Given an AT Protocol URI, this endpoint returns an object with data on the given post and its replies.&lt;/p&gt;&lt;p&gt;I could have interacted directly with the Bluesky API from my React component using &lt;code&gt;fetch&lt;/code&gt; and &lt;code&gt;useEffect&lt;/code&gt;. However, it can be a bit tricky to correctly handle loading and a error states, even for a simple feature like this. Because of this, I decided to use the Tanstack &lt;code&gt;react-query&lt;/code&gt; package to manage the API request/response cycle. This library takes care of the messy work of handling errors, retries, and loading states while I simply provide it a function to fetch the post data.&lt;/p&gt;&lt;p&gt;Once I obtain the Bluesky response, the next task is parsing out the content and metadata for the replies. Bluesky supports a rich content structure in its posts for representing markup, references, and attachments. Building out a UI that fully respects this rich content would be difficult. Instead, I decided to keep it simple by just pulling out the text content from each reply.&lt;/p&gt;&lt;p&gt;Even so, building a UI that properly displays threaded comments, particularly one that is formatted well on small mobile devices, can be tricky. For now, my approach was to again keep it simple. I indented each reply and added a left border to make it easier to follow reply threads. Otherwise, I mostly copied design elements for layout of the profile picture and post date from Bluesky.&lt;/p&gt;&lt;p&gt;Lastly, I added a UI component linking to the parent post on Bluesky, and encouraging people to add to the conversation there. With this, the read-only comment section implementation was complete. If there's interest, I could publish my version of Bluesky comments as a standalone package. But several of the choices I made were relatively specific to my own site. Moreover, the implementation is simple enough that others could probably build their own version from reading the source code, just as I did using Zue's version.&lt;/p&gt;&lt;p&gt;Let me know what you think by replying on Bluesky. Hopefully this can help increase engagement with my blog posts, but then again, my last article generated no replies, so maybe not üò≠.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46747366</guid><pubDate>Sat, 24 Jan 2026 20:33:40 +0000</pubDate></item></channel></rss>