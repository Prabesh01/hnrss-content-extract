<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 03 Nov 2025 18:43:58 +0000</lastBuildDate><item><title>Why Nextcloud feels slow to use</title><link>https://ounapuu.ee/posts/2025/11/03/nextcloud-slow/</link><description>&lt;doc fingerprint="923df5e7153e2979"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An Illustrated Introduction to Linear Algebra, Chapter 2&lt;/head&gt;
    &lt;head rend="h3"&gt;The dot product&lt;/head&gt;
    &lt;head rend="h2"&gt;Picking a city&lt;/head&gt;
    &lt;p&gt;When my wife and I were deciding which city to live in, we made a list of cities, and scored each city based on some criteria. Here’s San Francisco and Minneapolis, for example, on weather and affordability.&lt;/p&gt;
    &lt;p&gt;You can see we loved the weather in San Francisco, but Minneapolis was way cheaper to live in. After this was done, we just added up the columns to figure out which city to live in!&lt;/p&gt;
    &lt;p&gt;Here’s the thing, though: I really liked the weather in San Francisco. I wanted some way to do this calculation, but have the weather matter more. Well, I could do that by using weights.&lt;/p&gt;
    &lt;p&gt;If I wanted the weather to matter 10% more, I could multiply by 1.1 before doing the addition.&lt;/p&gt;
    &lt;p&gt;(I also multiplied the affordability by 1 to show that I’m keeping it the same).&lt;/p&gt;
    &lt;p&gt;This is the essence of what a dot product is! Earlier I was adding up the numbers. Now I’m weighting the numbers before I add them&lt;/p&gt;
    &lt;p&gt;A dot product is a type of weighted sum.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dot product using vectors&lt;/head&gt;
    &lt;p&gt;Remember vectors from last chapter? Well, the dot product is an operation you perform on two vectors. Let’s write the above as a vector. For example, here are the scores for San Francisco as a vector&lt;/p&gt;
    &lt;p&gt;Here are the weights as a vector&lt;/p&gt;
    &lt;p&gt;We simply multiply the numbers by the weights and then add:&lt;/p&gt;
    &lt;p&gt;Tada! We just took a dot product of two vectors! It’s a straightforward operation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three cities&lt;/head&gt;
    &lt;p&gt;Let’s see the same example with three cities. Here are our three cities with scores for weather and affordability:&lt;/p&gt;
    &lt;p&gt;The simple way to calculate scores would be to just add up the numbers:&lt;/p&gt;
    &lt;p&gt;But instead, we’re going to take the dot product:&lt;/p&gt;
    &lt;p&gt;We are taking three separate dot products here. For each city, we multiply its scores by the weights:&lt;/p&gt;
    &lt;p&gt;I’m saying that now to make it clear that we’re not taking the dot product of three vectors. That’s impossible, we can only take the dot product of two vectors. Instead we are taking three separate dot products. More on this later.&lt;/p&gt;
    &lt;p&gt;Now let’s look at another example. Let’s look at the Minnesota lottery.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Minnesota Lottery&lt;/head&gt;
    &lt;p&gt;It takes $2 to buy a ticket for the Minnesota lottery. Here are the odds:&lt;/p&gt;
    &lt;p&gt;So your odds of winning $2 are 1 in 17, your odds of winning $20 are 1 in 2404, etc. Given this information, how do you calculate how much a single ticket is worth, on average?&lt;/p&gt;
    &lt;p&gt;To find out, we again need to take the dot product. Here are the two vectors:&lt;/p&gt;
    &lt;p&gt;Prize money on the left, probability of winning on the right. Let’s see the calculation:&lt;/p&gt;
    &lt;p&gt;The ticket is worth $1.17176. It costs $2, so on average you can expect to lose money, which is what we knew already.&lt;/p&gt;
    &lt;p&gt;Same as the cities example, we are weighting the numbers, except this time the weights are the probability that we win that much money. The final number is called the expected value.&lt;/p&gt;
    &lt;p&gt;It’s the expected value of our ticket.&lt;/p&gt;
    &lt;p&gt;That’s all for dot products. It’s a straightforward operation, but one that’s important to know for matrix multiplication, which is the topic of the next chapter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;A dot product is a weighted sum of two vectors. You multiply each element of the vectors together, then add up the results:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798681</guid><pubDate>Mon, 03 Nov 2025 13:21:09 +0000</pubDate></item><item><title>An Illustrated Introduction to Linear Algebra, Chapter 2: The Dot Product</title><link>https://www.ducktyped.org/p/linear-algebra-chapter-2-the-dot</link><description>&lt;doc fingerprint="923df5e7153e2979"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An Illustrated Introduction to Linear Algebra, Chapter 2&lt;/head&gt;
    &lt;head rend="h3"&gt;The dot product&lt;/head&gt;
    &lt;head rend="h2"&gt;Picking a city&lt;/head&gt;
    &lt;p&gt;When my wife and I were deciding which city to live in, we made a list of cities, and scored each city based on some criteria. Here’s San Francisco and Minneapolis, for example, on weather and affordability.&lt;/p&gt;
    &lt;p&gt;You can see we loved the weather in San Francisco, but Minneapolis was way cheaper to live in. After this was done, we just added up the columns to figure out which city to live in!&lt;/p&gt;
    &lt;p&gt;Here’s the thing, though: I really liked the weather in San Francisco. I wanted some way to do this calculation, but have the weather matter more. Well, I could do that by using weights.&lt;/p&gt;
    &lt;p&gt;If I wanted the weather to matter 10% more, I could multiply by 1.1 before doing the addition.&lt;/p&gt;
    &lt;p&gt;(I also multiplied the affordability by 1 to show that I’m keeping it the same).&lt;/p&gt;
    &lt;p&gt;This is the essence of what a dot product is! Earlier I was adding up the numbers. Now I’m weighting the numbers before I add them&lt;/p&gt;
    &lt;p&gt;A dot product is a type of weighted sum.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dot product using vectors&lt;/head&gt;
    &lt;p&gt;Remember vectors from last chapter? Well, the dot product is an operation you perform on two vectors. Let’s write the above as a vector. For example, here are the scores for San Francisco as a vector&lt;/p&gt;
    &lt;p&gt;Here are the weights as a vector&lt;/p&gt;
    &lt;p&gt;We simply multiply the numbers by the weights and then add:&lt;/p&gt;
    &lt;p&gt;Tada! We just took a dot product of two vectors! It’s a straightforward operation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three cities&lt;/head&gt;
    &lt;p&gt;Let’s see the same example with three cities. Here are our three cities with scores for weather and affordability:&lt;/p&gt;
    &lt;p&gt;The simple way to calculate scores would be to just add up the numbers:&lt;/p&gt;
    &lt;p&gt;But instead, we’re going to take the dot product:&lt;/p&gt;
    &lt;p&gt;We are taking three separate dot products here. For each city, we multiply its scores by the weights:&lt;/p&gt;
    &lt;p&gt;I’m saying that now to make it clear that we’re not taking the dot product of three vectors. That’s impossible, we can only take the dot product of two vectors. Instead we are taking three separate dot products. More on this later.&lt;/p&gt;
    &lt;p&gt;Now let’s look at another example. Let’s look at the Minnesota lottery.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Minnesota Lottery&lt;/head&gt;
    &lt;p&gt;It takes $2 to buy a ticket for the Minnesota lottery. Here are the odds:&lt;/p&gt;
    &lt;p&gt;So your odds of winning $2 are 1 in 17, your odds of winning $20 are 1 in 2404, etc. Given this information, how do you calculate how much a single ticket is worth, on average?&lt;/p&gt;
    &lt;p&gt;To find out, we again need to take the dot product. Here are the two vectors:&lt;/p&gt;
    &lt;p&gt;Prize money on the left, probability of winning on the right. Let’s see the calculation:&lt;/p&gt;
    &lt;p&gt;The ticket is worth $1.17176. It costs $2, so on average you can expect to lose money, which is what we knew already.&lt;/p&gt;
    &lt;p&gt;Same as the cities example, we are weighting the numbers, except this time the weights are the probability that we win that much money. The final number is called the expected value.&lt;/p&gt;
    &lt;p&gt;It’s the expected value of our ticket.&lt;/p&gt;
    &lt;p&gt;That’s all for dot products. It’s a straightforward operation, but one that’s important to know for matrix multiplication, which is the topic of the next chapter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;A dot product is a weighted sum of two vectors. You multiply each element of the vectors together, then add up the results:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798741</guid><pubDate>Mon, 03 Nov 2025 13:28:37 +0000</pubDate></item><item><title>Offline Math: Converting LaTeX to SVG with MathJax</title><link>https://sigwait.org/~alex/blog/2025/10/07/3t8acq.html</link><description>&lt;doc fingerprint="ae42081a27e3a30c"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Offline Math: Converting LaTeX to SVG with MathJax&lt;/head&gt;&lt;p&gt;Latest update: &lt;/p&gt;&lt;p&gt;Pandoc can prepare LaTeX math for MathJax via its eponymous &lt;code&gt;--mathjax&lt;/code&gt; option. It wraps formulas in &lt;code&gt;&amp;lt;span class="math"&amp;gt;&lt;/code&gt;
elements and injects a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag that points to
cdn.jsdelivr.net, which means rendering won't work offline or in
case of the 3rd-party server failure. You can mitigate this by
providing your own copy of the MathJax library, but the mechanism
still fails when the target device doesn't support JavaScript (e.g.,
many epub readers).&lt;/p&gt;&lt;p&gt;At the same time, practically all browsers support MathML. Use it (pandoc's &lt;code&gt;--mathml&lt;/code&gt; option), if you care only about the information
superhighway: your formulas will look good on every modern device and
scale delightfully. Otherwise, SVGs are the only truly portable
option.&lt;/p&gt;&lt;p&gt;Now, how can we transform the html produced by&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ echo 'Ohm'\''s law: $I = \frac{V}{R}$.' |
  pandoc -s -f markdown --mathjax
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;into a fully standalone document where the formula gets converted into SVG nodes?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Use an html parser like Nokogiri, and replace each &lt;code&gt;&amp;lt;span class="math"&amp;gt;&lt;/code&gt; node with an image. There are multiple ways to
convert a TeX-looking string to an SVG: using MathJax itself (which
provides a corresponding CLI example), or by doing it in a
'classical' fashion with pdflatex. (You can read more about this
method in A practical guide to EPUB, chapters 3.4 and 4.6.)&lt;/item&gt;&lt;/list&gt;&lt;list start="2" rend="ol"&gt;&lt;item&gt;Alternatively, load the page into a headless browser, inject MathJax scripts, and serialise the modified DOM back to html.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I tried the 2nd approach in 2016 with the now-defunct phantomjs. It worked, but debugging was far from enjoyable due to the strangest bugs in phantomjs. I can still run the old code, but it depends on an ancient version of the MathJax library that, for obvious reasons, isn't easily upgradable within the phantomjs pre-es6 environment.&lt;/p&gt;&lt;p&gt;Nowadays, Puppeteer would certainly do, but for this kind of task I prefer something more lightweight.&lt;/p&gt;&lt;p&gt;There's also jsdom. Back in 2016, I tried it as well, but it was much slower than running phantomjs. Recently, I gave jsdom another try and was pleasantly surprised. I'm not sure what exactly tipped the scales: computers, v8, or jsdom itself, but it no longer feels slow in combination with MathJax.&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ wc -l *js *conf.json
  24 loader.js
 105 mathjax-embed.js
  12 mathjax.conf.json
 141 total
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;Roughly 50% of the code is nodejs infrastructure junk (including CL parsing), the rest is a MathJax config and jsdom interactions:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;let dom = new JSDOM(html, {
  url: `file://${base}/`,
  runScripts: /* very */ 'dangerously',
  resources: new MyResourceLoader(), // block ext. absolute urls
})

dom.window.my_exit = function() {
  cleanup(dom.window.document) // remove mathjax &amp;lt;script&amp;gt; tags
  console.log(dom.serialize())
}

dom.window.my_mathjax_conf = mathjax_conf // user-provided

let script = new Script(read(`${import.meta.dirname}/loader.js`))
let vmContext = dom.getInternalVMContext()
script.runInContext(vmContext)
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The most annoying step here is setting &lt;code&gt;url&lt;/code&gt; property that jsdom uses
to resolve paths to relative resources. &lt;code&gt;my_exit()&lt;/code&gt; function is called
by MathJax when its job is supposedly finished. &lt;code&gt;loader.js&lt;/code&gt; script is
executed in the context of the loaded html:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;window.MathJax = {
  output: { fontPath: '@mathjax/%%FONT%%-font' },
  startup: {
    ready() {
      MathJax.startup.defaultReady()
      MathJax.startup.promise.then(window.my_exit)
    }
  }
}

Object.assign(window.MathJax, window.my_mathjax_conf)

function main() {
  var script = document.createElement('script')
  script.src = 'mathjax/startup.js'
  document.head.appendChild(script)
}

document.addEventListener('DOMContentLoaded', main)
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The full source is on Github.&lt;/p&gt;&lt;p&gt;Intended use is as follows:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ echo 'Ohm'\''s law: $I = \frac{V}{R}$.' |
  pandoc -s -f markdown --mathjax |
  mathjax-embed &amp;gt; 1.html
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The resulting html doesn't use JavaScript and doesn't fetch any external MathJax resources. &lt;code&gt;mathjax-embed&lt;/code&gt; script itself always works
offline.&lt;/p&gt;&lt;lb/&gt;Tags: Ð¾Ð¹ÑÑ&lt;lb/&gt;Authors: ag&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798746</guid><pubDate>Mon, 03 Nov 2025 13:29:17 +0000</pubDate></item><item><title>VimGraph</title><link>https://resources.wolframcloud.com/FunctionRepository/resources/VimGraph/</link><description>&lt;doc fingerprint="797c6f35ce5cddfb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Wolfram Function Repository&lt;/head&gt;
    &lt;p&gt;Instant-use add-on functions for the Wolfram Language&lt;/p&gt;
    &lt;p&gt;Function Repository Resource:&lt;/p&gt;
    &lt;p&gt;Construct a graph of simple Vim-style movements in text&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;ResourceFunction["VimGraph"][text]&lt;/p&gt;
          &lt;p&gt;returns a graph with letters as vertices and Vim-style movements as edges.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Shortcut&lt;/cell&gt;
        &lt;cell&gt;Movement Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;h / l&lt;/cell&gt;
        &lt;cell&gt;Move one character left / right on the same line&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;k / j&lt;/cell&gt;
        &lt;cell&gt;Move one character up / down; jumps to end of target line if shorter than current horizontal position&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;w / b&lt;/cell&gt;
        &lt;cell&gt;Jump to the beginning of the next / previous word, across lines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;e&lt;/cell&gt;
        &lt;cell&gt;Jump to the end of the next word, across lines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;^/$&lt;/cell&gt;
        &lt;cell&gt;Move to the beginning/end of the current line&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Vim graph for the movements: up, right, and to the beginning of the next word, respectively:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[1]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[1]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The same, with nicer formatting:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[2]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[2]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Returns a minimal sequence of keystrokes needed to move from one letter to another:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[3]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[3]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Illustrates the relationship between the maximum keystroke distance required to navigate between two letters in a text and the number of randomly inserted newlines:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[4]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[4]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Use the "CustomPatterns" option to define new movements by passing a string pattern to "StringPattern", with optional shortcuts for jumping forward or backward to the nearest match:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[5]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[5]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Wolfram Language 13.0 (December 2021) or above&lt;/p&gt;
    &lt;p&gt;This work is licensed under a Creative Commons Attribution 4.0 International License&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798838</guid><pubDate>Mon, 03 Nov 2025 13:40:47 +0000</pubDate></item><item><title>Show HN: a Rust ray tracer that runs on any GPU – even in the browser</title><link>https://github.com/tchauffi/rust-rasterizer</link><description>&lt;doc fingerprint="6f9135994f6043cc"&gt;
  &lt;main&gt;
    &lt;p&gt;A rasterizer implementation in Rust&lt;/p&gt;
    &lt;p&gt;Try it online: Live WebGPU Raytracer&lt;/p&gt;
    &lt;p&gt;This project includes three different raytracing implementations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;CPU Raytracer - Software-based raytracing running on the CPU&lt;/item&gt;
      &lt;item&gt;GPU Raytracer - Hardware-accelerated raytracing using GPU compute shaders (offline rendering)&lt;/item&gt;
      &lt;item&gt;Live GPU Raytracer - Real-time interactive GPU raytracer with camera controls&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The CPU version renders scenes using traditional CPU-based raytracing and outputs to a PPM image file.&lt;/p&gt;
    &lt;code&gt;# Build and run (outputs to stdout, redirect to file)
cargo run --release &amp;gt; output.ppm

# Or build first, then run
cargo build --release
./target/release/rust-rasterizer &amp;gt; output.ppm&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full path tracing with multiple bounces&lt;/item&gt;
      &lt;item&gt;Direct and indirect lighting&lt;/item&gt;
      &lt;item&gt;Mesh support (.obj files)&lt;/item&gt;
      &lt;item&gt;Sphere primitives&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The GPU version uses compute shaders to accelerate rendering, outputting to a PPM file.&lt;/p&gt;
    &lt;code&gt;# Build and run
cargo run --bin gpu_raytracer --release &amp;gt; output.ppm

# Or build separately
cargo build --bin gpu_raytracer --release
./target/release/gpu_raytracer &amp;gt; output.ppm&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPU-accelerated compute shader rendering&lt;/item&gt;
      &lt;item&gt;Same scene quality as CPU version&lt;/item&gt;
      &lt;item&gt;Significantly faster rendering times&lt;/item&gt;
      &lt;item&gt;Hardware-accelerated ray-triangle intersection&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The live version provides a real-time interactive window where you can navigate the scene.&lt;/p&gt;
    &lt;code&gt;# Run the live raytracer
cargo run --bin live_raytracer --release&lt;/code&gt;
    &lt;p&gt;Controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mouse: Click and drag to rotate the camera&lt;/item&gt;
      &lt;item&gt;SPACE: Toggle between raytracing and normals visualization modes&lt;/item&gt;
      &lt;item&gt;Window Title: Displays current mode and FPS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time GPU raytracing&lt;/item&gt;
      &lt;item&gt;Interactive camera controls&lt;/item&gt;
      &lt;item&gt;Two rendering modes: &lt;list rend="ul"&gt;&lt;item&gt;Raytracing: Full path tracing with lighting and shadows&lt;/item&gt;&lt;item&gt;Normals: Fast visualization showing surface normals (useful for debugging)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Live FPS counter in window title&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust (latest stable version)&lt;/item&gt;
      &lt;item&gt;For GPU versions: A GPU with compute shader support (Vulkan, Metal, or DirectX 12)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implement Sphere ray tracing&lt;/item&gt;
      &lt;item&gt;Implement Light structures and enhance ray_color function for direct and indirect lighting calculations&lt;/item&gt;
      &lt;item&gt;Add more shapes (planes, triangles, meshes)&lt;/item&gt;
      &lt;item&gt;Optimize performance using GPU acceleration&lt;/item&gt;
      &lt;item&gt;Add BVH acceleration structure&lt;/item&gt;
      &lt;item&gt;Add texture mapping and material properties&lt;/item&gt;
      &lt;item&gt;Implement shadows and reflections&lt;/item&gt;
      &lt;item&gt;Create a user interface for scene setup and rendering options&lt;/item&gt;
      &lt;item&gt;Write documentation and usage examples&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798871</guid><pubDate>Mon, 03 Nov 2025 13:45:15 +0000</pubDate></item><item><title>Skyfall-GS – Synthesizing Immersive 3D Urban Scenes from Satellite Imagery</title><link>https://skyfall-gs.jayinnn.dev/</link><description>&lt;doc fingerprint="ed199ac9cc8e47ba"&gt;
  &lt;main&gt;
    &lt;p&gt;Synthesizing large-scale, explorable, and geometrically accurate 3D urban scenes is a challenging yet valuable task in providing immersive and embodied applications. The challenges lie in the lack of large-scale and high-quality real-world 3D scans for training generalizable generative models. In this paper, we take an alternative route to create large-scale 3D scenes by synergizing the readily available satellite imagery that supplies realistic coarse geometry and the open-domain diffusion model for creating high-quality close-up appearances. We propose Skyfall-GS, the first city-block scale 3D scene creation framework without costly 3D annotations, also featuring real-time, immersive 3D exploration. We tailor a curriculum-driven iterative refinement strategy to progressively enhance geometric completeness and photorealistic textures. Extensive experiments demonstrate that Skyfall-GS provides improved cross-view consistent geometry and more realistic textures compared to state-of-the-art approaches.&lt;/p&gt;
    &lt;p&gt;Our method synthesizes immersive and free-flight navigable city-block scale 3D scenes solely from multi-view satellite imagery in two stages.&lt;/p&gt;
    &lt;p&gt;(a) Reconstruction Stage&lt;/p&gt;
    &lt;p&gt;(b) Synthesis Stage&lt;/p&gt;
    &lt;p&gt;Explore our 3D Gaussian Splatting results interactively. Click on the scene buttons below to switch between different urban scenes. Use your mouse to freely navigate within each scene, and use WASD keys for fly navigation. Click the information button in the viewer for more controls.&lt;/p&gt;
    &lt;p&gt;This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC 112-2222-E-A49-004-MY2 and 113-2628-EA49-023-. The authors are grateful to Google, NVIDIA, and MediaTek Inc. for their generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the MOE in Taiwan.&lt;/p&gt;
    &lt;code&gt;@article{lee2025SkyfallGS,
  title = {{Skyfall-GS}: Synthesizing Immersive {3D} Urban Scenes from Satellite Imagery},
  author = {Jie-Ying Lee and Yi-Ruei Liu and Shr-Ruei Tsai and Wei-Cheng Chang and Chung-Ho Wu and Jiewen Chan and Zhenjun Zhao and Chieh Hubert Lin and Yu-Lun Liu},
  journal = {arXiv preprint},
  year = {2025},
  eprint = {2510.15869},
  archivePrefix = {arXiv}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798881</guid><pubDate>Mon, 03 Nov 2025 13:46:19 +0000</pubDate></item><item><title>A collection of links that existed about Anguilla as of 2003</title><link>https://web.ai/</link><description>&lt;doc fingerprint="330760cf3040fa01"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt; Generic of furosemideHow much does propranolol cost ukBuy orlistat genericWhere to buy zoloft in the uk Land For Sale Behind Cap Juluca &lt;/cell&gt;
        &lt;cell&gt; Buy clomiphene citrate 50 mg onlineGeneric viagra 123Zovirax online pharmacy canadaBuy clomid tablet Excellent Limousine Service &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Buy clomid and nolvadex pctWhere can i get amoxicillin over the counterViagra uk otcValacyclovir generic brand E &amp;amp; L Babysitting &lt;/cell&gt;
        &lt;cell&gt; Buy cheap viagra online in canadaBuy citalopram 10mg online ukBuy orlistat 120mg ukPrix du cialis au quebec Fairplay Jewelry and Perfumes &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Phenergan in the usKamagra oral jelly come si usaCialis dose consigliataBuy generic viagra in australia Swinghigh Apartments &lt;/cell&gt;
        &lt;cell&gt; Health pharmacy online discount codeXenical 120 mg saleBuy azithromycin 500mg chlamydiaBuying ventolin online in uk A Trip to Dominica &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Drugstore makeup free shippingViagra online express deliveryProscar ohne rezept kaufen Cheers Charters &lt;/cell&gt;
        &lt;cell&gt; Buy albuterol inhaler online cheapPhenergan uk pharmacyGeneric cymbalta online Be Aware Environmental Club &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Explore the sea or learn to waterski with Nature Boy Expeditions at natureboy.ai &lt;/cell&gt;
        &lt;cell&gt; Oliver's Seaside Grill at olivers.ai &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Take a side trip: Villa La Siesta: one-bedroom private villa on St Barth &lt;/cell&gt;
        &lt;cell&gt; Thanks for the great photographs: NancyPfister.com &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Teresa Harrigan is a promising young Anguillian artist. Here is her web page. &lt;/cell&gt;
        &lt;cell&gt; Part way through high school, Lourance Stevens discovered that she has eplilepsy. This is her story. &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Thelma Lee is conducting a survey of tourists about the Internet for her MBA. Please complete her questionnaire. &lt;/cell&gt;
        &lt;cell&gt; See pictures of Cap Juluca's Beach in November 1998, after restoration work. &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; See a 5-week visit to Anguilla by a 9 year old and a 12 year old boy, captured in pictures and humorous captions. Here. &lt;/cell&gt;
        &lt;cell&gt; See an action-packed visit to Anguilla by two teenage girls, written as a Science Project &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Visit the Gardens of Anguilla at Palms.ai &lt;/cell&gt;
        &lt;cell&gt; The International Art Festival was July 25, 1999: Artfestival.ai &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;The Diveshop in Sandy Ground is closed, but I still have their extensive underwater portfolio of tropical sea life on-line. &lt;/cell&gt;
        &lt;cell&gt; Book your holiday villa or buy a villa of your own; contact Lindy at ReMax Anguilla. &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Spend your visit to Anguilla at one of our friendly local inns. See a selection at Inns.ai &lt;/cell&gt;
        &lt;cell&gt; See the beach, the rooms, the charm of Shoal Bay Villas at their web site, Sbvillas.ai &lt;lb/&gt; More on Anguilla villas &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; Learn all about Anguilla's hugely successful Summer Tennis Camp and the young volunteers of the Anguilla Tennis Academy who make it happen at Tennis.ai &lt;/cell&gt;
        &lt;cell&gt; Purple Rose Florist, your local source for bi&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798892</guid><pubDate>Mon, 03 Nov 2025 13:47:27 +0000</pubDate></item><item><title>The problem with farmed seafood</title><link>https://nautil.us/the-problem-with-farmed-seafood-1243674/</link><description>&lt;doc fingerprint="67889f13ddb60538"&gt;
  &lt;main&gt;
    &lt;p&gt;In the cold waters of the Pacific, the anchoveta once shimmered in swarms so vast that sailors described them as turning the sea into a river of quicksilver. They were small, unassuming fish, yet the abundance of the ocean rested upon their delicate bones. Seabirds wheeled overhead in their millions, sea lions and whales dove into their depths, and predatory fish rose through the blue to feed on them. In those shoals lived the vitality of the sea itself. But in our age, the anchoveta, along with sardines and menhaden, have been transformed from living threads in an ancient web into bags of meal and casks of oil. Ninety percent of the forage fish caught by human hands are not eaten by us but ground down to feed salmon being raised in the cold fjords of Norway and shrimp and fish in the tropical ponds of Southeast Asia.&lt;/p&gt;
    &lt;p&gt;It is one of the great ironies of our time. To farm the sea, we strip the sea. We take from the ocean’s foundation to build its surface anew, and in the process we imperil both. In 2016, the anchoveta failed to arrive in the expected numbers, and entire fishing seasons in Peru were canceled. Again in 2023, the same collapse occurred, this time coinciding with a spike in ocean temperatures that drove the fish to depths where nets could not reach. The seabirds starved, their nests abandoned. Seal pups died in the thousands. Farmers watched as the price of feed climbed and their livelihoods faltered. What seemed infinite revealed itself as fragile.&lt;/p&gt;
    &lt;p&gt;Kevin Fitzsimmons, an aquaculture scientist at the University of Arizona, has described the predicament with characteristic bluntness: “Reliance on wild-caught marine-animal ingredients is a weak link in the aquaculture supply chain. It puts global seafood security at risk, while also affecting vital marine ecosystems.” As the former president of the World Aquaculture Society, Fitzsimmons knows that what appears efficient on paper is brittle in practice.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Ninety percent of forage fish caught by humans are ground down into fish food.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Today, Fitzimmons is chairman of the F3 Challenge, a competition for the aquaculture industry to produce marine-animal free food for farmed fish. “Amid growing supply chain uncertainties, this contest offers an opportunity to future-proof farm operations by developing strong, sustainable feed contingency plans,” Fitzsimmons said. It is the voice of a scientist speaking, but also of a pragmatist who knows that disruption, like the sudden cancellation of Peru’s anchoveta fishery, will come again.&lt;/p&gt;
    &lt;p&gt;The paradox of aquaculture is that it is at once a salvation and a threat. It now provides more than half the fish we eat, and it has spared some wild stocks from further collapse. Yet the act of raising carnivorous fish—salmon, trout, grouper, shrimp—has bound us more tightly to the fragile shoals of forage fish. This is what scientists call the forage fish bottleneck. And in this bottleneck, the future of seafood, of food security for billions, of entire ocean ecosystems, is squeezed.&lt;/p&gt;
    &lt;p&gt;The realization that fish do not need to eat fish to grow—that what they require are nutrients, not the bodies of other creatures—may seem obvious once said aloud. But it is an idea as revolutionary as the day when humans first understood that plants could be sown in neat rows and harvested, that food could be cultivated rather than chased. The birth of agriculture 10,000 years ago was not the discovery of seeds; it was the recognition that sustenance could be abstracted, reimagined, shaped to our will. So too now, the future of fish feed begins with a recognition: The proteins and oils that have always come from the sea can come, instead, from our imagination.&lt;/p&gt;
    &lt;p&gt;When Fitzsimmons and his colleagues launched the F3 Challenge in 2015, they did not turn to governments to regulate or to foundations to endow. They chose instead the ancient spur of human ingenuity: a prize. “By incentivizing farms to innovate,” Fitzsimmons explained, “we reduce pressure on wild fish stocks while building a more resilient and sustainable seafood system for the future.”&lt;/p&gt;
    &lt;p&gt;History remembers moments like this. The prize offered for determining longitude at sea in the 18th century, which spurred clockmakers to craft chronometers more precise than ever imagined. The Orteig Prize, which drove Charles Lindbergh across the Atlantic, opening the era of aviation. Similarly, the F3 Challenge is not a discovery imposed from above, but a challenge flung wide, trusting that competition and ambition will drive a breakthrough.&lt;/p&gt;
    &lt;p&gt;And breakthroughs came. A Chinese company, Evergreen Feed, demonstrated that plant-based blends could scale to industrial volumes, saving an estimated 350 million forage fish. Veramaris, a joint venture in the Netherlands and the United States, cultivated algae that produced the same omega-3 fatty acids found in fish oil, and in quantities sufficient to replace billions of forage fish. In Ecuador and Japan, companies devised feeds for shrimp and sea bream, proving that even the most voracious of farmed carnivores could thrive without wild prey. Each success was counted not only in profit, but in the lives of the small fish left in the sea: hundreds of millions here, billions there.&lt;/p&gt;
    &lt;p&gt;The contests have continued, each more ambitious than the last. A challenge to replace krill, the shrimp-like creatures that sustain penguins and whales was won by BRF, a Brazilian company using Chicken hydrolysate, a product made by using enzymes to break down chicken protein into smaller, more easily digestible peptides, and by Symrise, a German company working with flavors and fragrances to enhance the non-marine food’s appeal to farmed fish. A new competition now rewards not just feed producers but fish farms themselves, those willing to commit their entire operations to marine-ingredient-free diets. The ambition is not modest.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Labels on seafood could proclaim “fish-free feed,” like “grass-fed” on beef.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The tools of this new future are dazzling in their diversity. Algae fermenters that glow with green light, their oils rich in DHA (docosapentaenoic acid) and EPA (eicosapentaenoic acid), both types of omega 3 fatty acids identical to the molecules that give fish their nourishment. Tanks of bacteria fed on carbon dioxide or methane, spinning waste into protein, a kind of culinary alchemy. Insects—black soldier fly larvae—raised on food scraps, their bodies transformed into high-protein meal. Yeasts bubbling in vats like beer, dried into powders that rival fishmeal in digestibility. Even the humble pea and soybean, engineered and processed until their amino acid profiles mimic those of the anchoveta. Each of these is not simply a replacement, but a reinvention: a recognition that the fabric of nutrition is not bound to one source but can be woven anew.&lt;/p&gt;
    &lt;p&gt;To coordinate this frontier, the Future of Fish Feed, a collaborative effort between NGOs, researchers, and private partnerships to support alternative aquaculture feed, created the Feed Innovation Network, an open commons where recipes are shared, protocols exchanged, trials published. In an industry long bound by secrecy, this openness is itself a revolution. And in farms across the world, from shrimp ponds in Ecuador to bass tanks in the U.S., demonstration trials show that these diets work. Carnivores remain carnivores, and yet the ocean remains more whole.&lt;/p&gt;
    &lt;p&gt;At stake is more than the price of shrimp or the yield of salmon. It is the resilience of entire ecosystems. Forage fish are the currency of the sea. To deplete them is to starve seabirds, to silence the calls of whales, to empty the beaches of seals. To spare them is to let the ocean breathe. At stake, too, is human food security. By mid-century, 10 billion mouths will need feeding, and aquaculture is one of the surest ways to provide protein. But if aquaculture is shackled to the rise and fall of forage fish, then it will falter when most needed. And finally, at stake is the climate itself. If bacteria can be grown on carbon waste, if algae can thrive on light and air, then aquaculture can become not a burden but a partner in the work of repairing the planet.&lt;/p&gt;
    &lt;p&gt;One can already imagine the cultural shift that might follow. Labels on seafood proclaiming “fish-free feed,” just as beef carries the words “grass-fed.” A shrimp cocktail served at a wedding, its story not of plundered krill but of innovation, of microbes turned to nourishment. The act of eating fish would carry with it a continuity, not a rupture, with the health of the sea.&lt;/p&gt;
    &lt;p&gt;And here, perhaps, lies the deepest resonance. Human history is a succession of moments when we recognized that our survival depended not on taking more from nature, but on working with her patterns. Agriculture, fire, medicine, electricity—all arose from this recognition. The F3 Challenge is another of those moments. It is not about feed alone. It is about the imagination to see that the scaffolding of life can be rebuilt by our own hands, if only we choose to do so.&lt;/p&gt;
    &lt;p&gt;Today, the anchoveta still swim, though in fewer numbers, and the seabirds still wheel above them. But their future, like ours, now depends on whether we will grind them into meal until none remain, or whether we will let them remain what they have always been: the living silver of the sea. “Our shared future becomes more sustainable,” Fitzsimmons said, “only if we can learn to take the pressure off the oceans and create feeds that free us from this dependence.” The future of fish feed is the future of fish. And the future of fish is the future of us all.&lt;/p&gt;
    &lt;p&gt;Lead image: A salmon farm in Norway. Credit: Photofex_AUT / Shutterstock.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798898</guid><pubDate>Mon, 03 Nov 2025 13:48:39 +0000</pubDate></item><item><title>OpenAI signs $38B cloud computing deal with Amazon</title><link>https://www.nytimes.com/2025/11/03/technology/openai-amazon-cloud-computing.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45799211</guid><pubDate>Mon, 03 Nov 2025 14:20:05 +0000</pubDate></item><item><title>State of Terminal Emulators in 2025: The Errant Champions</title><link>https://www.jeffquast.com/post/state-of-terminal-emulation-2025/</link><description>&lt;doc fingerprint="b60308d6479438c4"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a follow-up to my previous article, Terminal Emulators Battle Royale â Unicode Edition! from 2023, in which I documented Unicode support across terminal emulators. Since then, the ucs-detect tool and its supporting blessed library have been extended to automatically detect support of DEC Private Modes, sixel graphics, pixel size, and software version.&lt;/p&gt;
    &lt;p&gt;The ucs-detect program tests terminal cursor positioning by sending visible text followed by control sequences that request the cursor position. The terminal responds by writing the cursor location as simulated keyboard input. The ucs-detect program reads and compares these values against the Python wcwidth library result, logging any discrepancies.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Width Problem&lt;/head&gt;
    &lt;p&gt;Terminal emulators face a fundamental challenge: mapping the vast breadth of Unicode scripts into a fixed-width grid while maintaining legibility. A terminal must predict whether each character occupies one cell or two, whether combining marks overlay previous characters, and how emoji sequences collapse into single glyphs.&lt;/p&gt;
    &lt;p&gt;These predictions fail routinely. Zero-width joiners, variation selectors, and grapheme clustering compound in complexity. When terminals and CLI applications guess wrong, text becomes unreadable - cursors misalign and corrupt output and so then also corrupt the location of our input.&lt;/p&gt;
    &lt;p&gt;Our results share which terminals have the best "Unicode support" -- the least likely to exhibit these kinds of problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Gentleman Errant&lt;/head&gt;
    &lt;p&gt;Before presenting the latest results, Ghostty warrants particular attention, not only because it scored the highest among all terminals tested, but that it was publicly released only this year by Mitchell Hashimoto. It is a significant advancement. Developed from scratch in zig, the Unicode support implementation is thoroughly correct.&lt;/p&gt;
    &lt;p&gt;In 2023, Mitchell published Grapheme Clusters and Terminal Emulators, demonstrating a commitment to understanding and implementing the fundamentals. His recent announcement of libghostty provides a welcome alternative to libvte, potentially enabling a new generation of terminals on a foundation of strong Unicode support.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Errant Champion&lt;/head&gt;
    &lt;p&gt;Kovid Goyal's Kitty scored just as well, only outranked by the arbitrary weights that are not necessarily fair. More important than scoring is Kovid's publication of a text-splitting algorithm description that closely matches the Python wcwidth specification. This is unsurprising since both are derived from careful interpretation of Unicode.org standards and that it scores so highly in our test.&lt;/p&gt;
    &lt;p&gt;Kitty and Ghostty are the only terminals that correctly support Variation Selector 15, I have not written much about it because it is not likely to see any practical use, but, it will be added to a future release of Python wcwidth now that there are multiple standards and reference implementations in agreement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing Results&lt;/head&gt;
    &lt;p&gt;The first table, General Tabulated Summary describes unicode features of each terminal, then, a brief summary of DEC Private Modes, sixel support, and testing time.&lt;/p&gt;
    &lt;p&gt;The second table, DEC Private Modes Support (not pictured), contains the first feature capability matrix of DEC Private Modes for Terminals of any length. I hope this is useful most especially to developers of CLI libraries and applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Long Road&lt;/head&gt;
    &lt;p&gt;The most notable finding relates to performance. That many terminals perform so slowly was surprising, so I have included the elapsed time in the results.&lt;/p&gt;
    &lt;p&gt;iTerm2 and Extraterm consume a majority of the CPU and perform so slowly that the test parameters were reduced to finish within the hour what many other terminals manage in a few minutes.&lt;/p&gt;
    &lt;p&gt;GNOME Terminal and its VTE-based derivatives also perform too slowly for a full test, taking over 5 hours while consuming very little CPU. Many terminals exhibit stalls or inefficiencies in their event loops that result in slow automatic responses, but we should be forgiving; nobody really considered the need to handle hundreds of automatic sequence replies per second!&lt;/p&gt;
    &lt;p&gt;I expected Python wcwidth to consume the most CPU resources during testing, as it is frequently called and always the "highest-level" language in the mix, but it keeps up pretty well for most terminals.&lt;/p&gt;
    &lt;p&gt;Earlier this year, I dedicated effort to optimizing the Python wcwidth implementation using techniques including bit vectors, bloom filters, and varying sizes of LRU caches. The results confirmed that the existing implementation performed best: a binary search with a functools.lru_cache decorator.&lt;/p&gt;
    &lt;p&gt;The LRU cache is effective because human languages typically use a small, repetitive subset of Unicode. The ucs-detect tool tests hundreds of languages from the UDHR dataset, excluding only those without any interesting zero or wide characters. This dataset provides an extreme but practical demonstration of LRU cache benefits when processing Unicode.&lt;/p&gt;
    &lt;p&gt;I previously considered distributing a C module with Python wcwidth for greater performance, but the existing Python implementation keeps up well enough with the fastest terminals. When fully exhausted the text scroll speed is fast enough to produce screen tearing artifacts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tilting at Edges&lt;/head&gt;
    &lt;p&gt;Terminology produces inconsistent results between executions. Our tests are designed to be deterministic, so these kinds of results suggest possible state corruption. Despite this issue, Terminology offers interesting visual effects that would be a welcome feature in other terminals.&lt;/p&gt;
    &lt;p&gt;iTerm2 reports "supported, but disabled, and cannot be changed" status for all DEC Private Modes queried, including fictional modes like 9876543. For this reason, the summary of DEC Private Modes shows only those modes that are changeable.&lt;/p&gt;
    &lt;p&gt;Konsole does not reply to queries about DEC Private modes, but does support several modes when they are enabled. For this reason, ucs-detect cannot automatically infer which DEC Modes Konsole supports.&lt;/p&gt;
    &lt;p&gt;Similarly, ucs-detect reports "No DEC Private Mode Support" for Contour. I investigated this discrepancy because Contour's author also authored a Mode 2027 specification dependent on this functionality. The issue was that Contour responded with a different mode number than the one queried. While developing a fix, Contour's latest release from December 2024 presented an additional complication: a bad escape key configuration. Each instance of being stuck in vi required typing CTRL + [ as a workaround!&lt;/p&gt;
    &lt;p&gt;Terminals based on libvte with software version label VTE/7600 continue to show identical performance with low scores in our tests, unchanged from 2023.&lt;/p&gt;
    &lt;p&gt;My attempt to discuss improving Unicode support in libvte received substantial criticism. However, recent libvte project issue Support Emoji Sequences is a positive indicator for improved language and Emoji support in 2026.&lt;/p&gt;
    &lt;head rend="h2"&gt;On Mode 2027&lt;/head&gt;
    &lt;p&gt;I included DEC Private Mode 2027 in the results to accompany Mitchell's table from his article, Grapheme Clusters and Terminal Emulators, and to verify for myself that it has limited utility.&lt;/p&gt;
    &lt;p&gt;In theory, a CLI program can query this mode to classify a terminal as "reasonably supporting" unicode, but not which specific features or version level. Since other terminals with similar capabilities do not respond to Mode 2027 queries, this binary indicator has limited utility.&lt;/p&gt;
    &lt;p&gt;The only practical approach to determining Unicode support of a terminal is to interactively test for specific features, codepoints, and at the Unicode version levels of interest, as ucs-detect does.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond Fixed Widths&lt;/head&gt;
    &lt;p&gt;Terminals cannot reproduce many of the world's languages legibly when constrained to monospace cells. The measurements dictated by rapidly expanding Unicode standards and varying implementation levels create inherent tension.&lt;/p&gt;
    &lt;p&gt;The text sizing protocol published early this year represents a significant development. Kovid Goyal describes the motivation in a recent interview:&lt;/p&gt;
    &lt;quote&gt;And then my next windmill that I'm looking at is variable-sized text in the terminal. So when I'm catting a markdown file, I want to see the headings big.&lt;/quote&gt;
    &lt;p&gt;While this feature may enable more advanced typesetting-like capabilities in terminal apps, it also promises to increase accessibility. Allowing text to escape monospace constraints enables legible support of the diverse set of the world's languages.&lt;/p&gt;
    &lt;p&gt;For example, using Contour with ucs-detect --stop-at-error=lang, stopping to take a look at a result of the language KhÃ¼n:&lt;/p&gt;
    &lt;p&gt;In this case Contour and Python wcwidth disagree on measurement, but more important is the legibility. We can compare this given KhÃ¼n text to the Kate editor:&lt;/p&gt;
    &lt;p&gt;They are clearly different. I regret I cannot study it more carefully, but I suggest that terminals could more easily display complex scripts by switching to a variable size text mode, allowing the font engine to drive the text without careful processing of cell and cursor movement.&lt;/p&gt;
    &lt;p&gt;Although I have yet to experiment with it, I am encouraged to see some resolution to this problem by the progressive changes suggested by the text sizing protocol.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45799478</guid><pubDate>Mon, 03 Nov 2025 14:40:51 +0000</pubDate></item><item><title>Show HN: FinBodhi – Local-first, double-entry app/PWA for your financial journey</title><link>https://finbodhi.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800117</guid><pubDate>Mon, 03 Nov 2025 15:29:13 +0000</pubDate></item><item><title>Robert Hooke's "Cyberpunk” Letter to Gottfried Leibniz</title><link>https://mynamelowercase.com/blog/robert-hookes-cyberpunk-letter-to-gottfried-leibniz/</link><description>&lt;doc fingerprint="2d2b9d15aca48677"&gt;
  &lt;main&gt;
    &lt;p&gt;Cyberpunk is a genre of science fiction about high tech, urban sprawl, and do-it-yourself counterculture. It’s usually associated with the early days of computer hackers and AI. This is the first in a series of blog posts about how high tech, urban sprawl, and do-it-yourself counterculture were just as much a part of the rapid progress of 17th century natural science as they were of the rapid progress of 20th century computer science; and about what we can learn by drawing this comparison.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"If I were to choose a patron saint for cybernetics... I should have to choose Leibniz"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Norbert Wiener&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"if we could find characters or signs appropriate for expressing all our thoughts as definitely and as exactly as arithmetic expresses numbers or geometric analysis expresses lines, we could in all subjects in so far as they are amenable to reasoning accomplish what is done in arithmetic and geometry."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Gottfried Leibniz&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"...especially in all those subjects where use of [such a language] may be free and where interest and authority do not intercept, the regular exercise thereof which I conceive to be the great antagonists which may impede its progress..."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Robert Hooke&lt;/p&gt;
    &lt;p&gt;The last quote is from an archival text which I've been trying to transcribe on and off for the past few months. It comes from a scan of a letter which Robert Hooke wrote to Gottfried Leibniz in 1681. I am fascinated by this letter for a couple of reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I was pleasantly surprised to learn that Hooke and Leibniz had exchanged any letters at all. I found the letter by chance, when browsing through the Royal Society's online archives.&lt;/item&gt;
      &lt;item&gt;The letter is about one of my favourite topics: Leibniz's project to create a universal language of science, which could be mechanically applied to automate any piece of scientific reasoning (apart from the collection of new experimental data).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For these reasons, this letter from Hooke to Leibniz has become one of my favourite pieces of niche archival material. (The other two are this popular science article which Alan Turing wrote to introduce computational undecidability to a general audience, and this speech which Ove Arup gave to his employees to reassure them that the new industrial computer his engineering firm had bought wasn't going to replace them in their jobs).&lt;/p&gt;
    &lt;p&gt;I think my transcription is about 90% accurate so far. Hooke's handwriting is quite hard to read. The original section quoted looks like this:&lt;/p&gt;
    &lt;p&gt;But from what I have transcribed, I think this letter is a particularly nice example of the originality and prescience of Hooke's way of thinking about the world. Almost as fascinating as the letter itself, are the events surrounding the time in which it was written. I hope to write more soon about Hooke's life, about his relationship with cryptography, and about the way in which he bridged the gap between technician and scientist.&lt;/p&gt;
    &lt;p&gt;A common thread I find myself drawing across much of Hooke's work - albeit anachronistically - is an early expression of the hacker mindset which flourished among computer scientists in the second half of the 20th century, coincided with the explosion of computing innovations that took place during that period, and came to be romanticised in cyberpunk science fiction. And I think that if I had to pick one piece of Hooke's writing that expresses this attitude most clearly, I would have to pick this letter. To explain why, I'll first talk a bit more about why Hooke was writing to Leibniz in the first place.&lt;/p&gt;
    &lt;p&gt;You likely know Robert Hooke from studying his laws about the motion of springs in high-school physics, for his role in the foundation of the Royal Society, or for his beef with Isaac Newton. You likely know about Gottfried Leibniz from hearing about his philosophy of monads, for his role in the invention of calculus, or for his beef with Isaac Newton.&lt;/p&gt;
    &lt;p&gt;It turns out that, aside from their common interest in antagonising Isaac Newton, Hooke and Leibniz also shared an interest in mechanising scientific reasoning through the invention of a universal language for science. Leibniz called his project the "Characteristica Universalis". The philosopher Norbert Wiener credited this idea as a precursor to his own notion of “cybernetics” – which, incidentally, is the word he coined from which we get the “cyber” in "cyberpunk". One thing I took away from reading Wiener was that you can think of the Characteristica Universalis as a kind of proto computer programming language. Hooke liked Leibniz’ ideas on this topic so much that he sent him the above letter just to say so.&lt;/p&gt;
    &lt;p&gt;What makes Hooke’s letter cyberpunk as opposed to just cybernetic is that it adds to Leibniz’s worldview an explicit (and perhaps naively optimistic) hope that individual freedom might be enabled by rather than stifled by the proliferation of this early programming language. In particular he saw the effect of a language for mechanised scientific reasoning as especially useful when used by individuals to express, explore and test ideas freely, without interference from unjust authorities who might seek to censor or interfere with their work. In 1681, Hooke was already imagining the countercultural edge of cybernetic systems.&lt;/p&gt;
    &lt;p&gt;This should not be surprising, given Hooke's own politically uneasy upbringing, his tendency to skip lectures at university in order to tinker (in Robert Boyle's lab) with designs for experiments and novel instruments that went on to occupy his scientific career, or his habit of falling out with the interfering authorities of his time.&lt;/p&gt;
    &lt;p&gt;If my reading of this letter is accurate then - just as Wiener calls Leibniz the patron saint of cybernetics, we should call Hooke the patron saint of cyberpunk.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800308</guid><pubDate>Mon, 03 Nov 2025 15:45:31 +0000</pubDate></item><item><title>Ask HN: Who wants to be hired? (November 2025)</title><link>https://news.ycombinator.com/item?id=45800464</link><description>&lt;doc fingerprint="301182753412e0e7"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Share your information if you are looking for work. Please use this format:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;  Location:
  Remote:
  Willing to relocate:
  Technologies:
  Résumé/CV:
  Email:
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt; Please only post if you are personally looking for work. Agencies, recruiters, job boards, and so on, are off topic here.&lt;/p&gt;
      &lt;p&gt;Readers: please only email these addresses to discuss work opportunities.&lt;/p&gt;
      &lt;p&gt;There's a site for searching these posts at https://www.wantstobehired.com.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800464</guid><pubDate>Mon, 03 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Ask HN: Who is hiring? (November 2025)</title><link>https://news.ycombinator.com/item?id=45800465</link><description>&lt;doc fingerprint="3741985a3402e664"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Please state the location and include REMOTE for remote work, REMOTE (US) or similar if the country is restricted, and ONSITE when remote work is &lt;/p&gt;not&lt;p&gt; an option.&lt;/p&gt;&lt;p&gt;Please only post if you personally are part of the hiring company—no recruiting firms or job boards. One post per company. If it isn't a household name, explain what your company does.&lt;/p&gt;&lt;p&gt;Please only post if you are actively filling a position and are committed to responding to applicants.&lt;/p&gt;&lt;p&gt;Commenters: please don't reply to job posts to complain about something. It's off topic here.&lt;/p&gt;&lt;p&gt;Readers: please only email if you are personally interested in the job.&lt;/p&gt;&lt;p&gt;Searchers: try https://dheerajck.github.io/hnwhoishiring/, http://nchelluri.github.io/hnjobs/, https://hnresumetojobs.com, https://hnhired.fly.dev, https://kennytilton.github.io/whoishiring/, https://hnjobs.emilburzo.com, or this (unofficial) Chrome extension: https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal....&lt;/p&gt;&lt;p&gt;Don't miss this other fine thread: Who wants to be hired? https://news.ycombinator.com/item?id=45800464&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800465</guid><pubDate>Mon, 03 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Learning to read Arthur Whitney's C to become smart (2024)</title><link>https://needleful.net/blog/2024/01/arthur_whitney.html</link><description>&lt;doc fingerprint="2eb9d195bc6fba9c"&gt;
  &lt;main&gt;
    &lt;p&gt;Burger.&lt;/p&gt;
    &lt;head rend="h3"&gt;it's not working&lt;/head&gt;
    &lt;head rend="h5"&gt;Written January 19, 2024&lt;/head&gt;
    &lt;p&gt;Arthur Whitney is an esteemed computer scientist who led the design on a few well-known pieces of software:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The A, K, and Q programming languages&lt;/item&gt;
      &lt;item&gt;kdb, a high-performance database built on K used in fintech&lt;/item&gt;
      &lt;item&gt;Shakti, which is like kdb but faster, designed for trillion-row datasets.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I've never even seen a trillion numbers, much less calculated them, but kdb is apparently a standard tool on Wall Street. They probably care about money, so I'll assume kdb does its job well. His languages take significantly after APL, which was a very popular language for similar applications before the invention of (qwerty) keyboards.&lt;/p&gt;
    &lt;p&gt;But I'm not here to talk about boring things like "using software to make incomprehensible amounts of money in finance" or "human beings and their careers", I'm here to talk about how a guy writes C code weird. For a very simple version of the programming language K, there's a publicly available interpreter he wrote in a few days using about 50 lines of C to show the basics of interpreter writing. This is the C (specifically the January 16, 2024 version #2):&lt;/p&gt;
    &lt;head rend="h2"&gt;a.h&lt;/head&gt;
    &lt;code&gt;typedef char*s,c;s Q=(s)128;&amp;#13;
#define _(e...) ({e;})&amp;#13;
#define x(a,e...) _(s x=a;e)&amp;#13;
#define $(a,b) if(a)b;else&amp;#13;
#define i(n,e) {int $n=n;int i=0;for(;i&amp;lt;$n;++i){e;}}&amp;#13;
&amp;#13;
#define Q(e) if(Q==(e))return Q;&amp;#13;
#define Qs(e,s) if(e)return err(__func__,s);&amp;#13;
#define Qr(e) Qs(e,"rank")&amp;#13;
#define Qd(e) Qs(e,"domain")&amp;#13;
#define Qz(e) Qs(e,"nyi")&amp;#13;
&amp;#13;
#define _s(f,e,x...) s f(x){return _(e);}&amp;#13;
#define _i(f,e) _s(f,e,c x)&amp;#13;
#define f(f,e)  _s(f,e,s x)&amp;#13;
#define F(f,e)  _s(f,e,s a,s x)&amp;#13;
&amp;#13;
#define ax (256&amp;gt;x)&amp;#13;
#define ix (c)x&amp;#13;
#define nx x[-1]&amp;#13;
#define xi x[i]&amp;#13;
&amp;#13;
#define aa x(a,ax)&amp;#13;
#define ia x(a,ix)&amp;#13;
#define na x(a,nx)&amp;#13;
&amp;#13;
#define oo w("oo\n")&lt;/code&gt;
    &lt;head rend="h2"&gt;a.c&lt;/head&gt;
    &lt;code&gt;#include"a.h"//fF[+-!#,@] atom/vector 1byte(int/token) clang-13 -Os -oa a.c -w &amp;#13;
#define r(n,e) _(s r=m(n);i(n,r[i]=e)r)&amp;#13;
f(w,write(1,ax?&amp;amp;x:x,ax?1:strlen(x));x)F(err,w(a);w((s)58);w(x);w((s)10);Q)&amp;#13;
_i(wi,s b[5];sprintf(b,"%d ",x);w(b);0)&amp;#13;
f(W,Q(x)$(ax,wi(ix))i(nx,wi(xi))w(10);x)&amp;#13;
&amp;#13;
f(srt,Qz(1)0)f(uni,Qz(1)0)F(Cut,Qz(1)0)F(Drp,Qz(1)0)_i(m,s a=malloc(1+x);*a++=x;a)&amp;#13;
#define A(c) ((s)memchr(a,c,na)?:a+na)-a&amp;#13;
#define g(a,v) ax?255&amp;amp;a:r(nx,v)&amp;#13;
f(not,g(!ix,!xi))f(sub,g(-ix,-xi))F(At,Qr(aa)g(a[ix],a[xi]))F(_A,Qr(aa)g(A(ix),A(xi)))&amp;#13;
f(ind,Qr(!ax)0&amp;gt;ix?r(-ix,-ix-1-i):r(ix,i))F(Ind,Qr(!aa)Qd(1&amp;gt;ia)g(ix%ia,xi%ia))&amp;#13;
#define G(f,o) F(f,ax?aa?255&amp;amp;ia o ix:Ltn==f?f(sub(x),sub(a)):f(x,a):r(nx,(aa?ia:a[i])o xi))&amp;#13;
G(Ltn,&amp;lt;)G(Eql,==)G(Not,!=)G(Sum,+)G(Prd,*)G(And,&amp;amp;)G(Or,|)&amp;#13;
f(cat,Qr(!ax)r(1,ix))F(Cat,a=aa?cat(a):a;x=ax?cat(x):x;s r=m(na+nx);memcpy(r+na,x,nx);memcpy(r,a,na))&amp;#13;
f(at,At(x,0))f(rev,Qr(ax)At(x,ind(255&amp;amp;-nx)))f(cnt,Qr(ax)nx)&amp;#13;
F(Tak,Qr(!aa||ax)Qd(0&amp;gt;ia||ia&amp;gt;nx)At(x,ind(a)))F(Sub,Sum(a,sub(x)))F(Mtn,Ltn(x,a))f(qz,Qz(1)0)&amp;#13;
#define v(e) ((strchr(V,e)?:V)-V)&amp;#13;
s U[26],V=" +-*&amp;amp;|&amp;lt;&amp;gt;=~!@?#_^,",&amp;#13;
(*f[])()={0,abs,sub,qz ,qz,rev,qz ,qz, qz ,not,ind,at,uni,cnt,qz ,srt,cat},&amp;#13;
(*F[])()={0,Sum,Sub,Prd,And,Or,Ltn,Mtn,Eql,Not,Ind,At,_A ,Tak,Drp,Cut,Cat};&amp;#13;
_i(n,10u&amp;gt;x-48?x-48:26u&amp;gt;x-97?U[x-97]:0)&amp;#13;
f(e,s z=x;c i=*z++;!*z?n(i):v(i)?x(e(z),Q(x)f[v(i)](x)):x(e(z+1),Q(x)58==*z?U[i-97]=x:_(c f=v(*z);Qd(!f)F[f](n(i),x))))&amp;#13;
int main(){c b[99];while(1)if(w(32),b[read(0,b,99)-1]=0,*b)58==b[1]?e(b):W(e(b));}&lt;/code&gt;
    &lt;p&gt;This is the entire interpreter, and this is apparently how he normally writes code. Opinions on his coding style are divided, though general consensus seems to be that it's incomprehensible. As daunting as it is, I figured I should give it a chance for a few reasons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;As I work on larger and larger codebases, scrolling up and down to track information has become a more common annoyance. Whitney's talked about coding the way he does to avoid exactly that: he wants to keep his logic on one screen. Perhaps learning to read code like this could give me ideas on writing my own code more compactly.&lt;/item&gt;
      &lt;item&gt;In a Hacker News comments section, somebody asked "would you rather spend 10 days reading 100,000 lines of code, or 4 days reading 1000?", and that raises a good point. The complexity of the code is because even a simple interpreter is pretty complex. Writing it in 500 lines wouldn't make the complexity go away, it just spreads it out. Does writing in this more compact format feel more daunting because you're exposed to more of the complexity at once? I think so. Does showing it all at once actually help you understand the whole thing faster? I don't know.&lt;/item&gt;
      &lt;item&gt;Reading code has become a more important part of my job than writing it, so I should challenge my reading skills, regardless.&lt;/item&gt;
      &lt;item&gt;It confuses people, and that's basically the same as being smart.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So I'm going to go line by line and explain my understanding. I tried to use the notes provided in the repo only when I was stuck, which was a few times early on, but by the end I could understand it pretty well.&lt;/p&gt;
    &lt;head rend="h2"&gt;A reading of a.h&lt;/head&gt;
    &lt;code&gt;typedef char*s,c;&lt;/code&gt;
    &lt;p&gt;This already shows some funky C. It defines &lt;code&gt;s&lt;/code&gt; as &lt;code&gt;char *&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt; as &lt;code&gt;char&lt;/code&gt;, because the &lt;code&gt;*&lt;/code&gt; attaches to the name, not the type. It's an oddity of C syntax that I've never been a fan of. Otherwise this is pretty straight forward: &lt;code&gt;s&lt;/code&gt; is for string, and &lt;code&gt;c&lt;/code&gt; is for character.&lt;/p&gt;
    &lt;code&gt;s Q=(s)128;&lt;/code&gt;
    &lt;p&gt;Fuck. Shit. He assigned 128 to a string named &lt;code&gt;Q&lt;/code&gt;. What does it mean? &lt;code&gt;s&lt;/code&gt; is &lt;code&gt;char *&lt;/code&gt;. Why is Q a pointer to the address 128? I thought I must have misunderstood, and &lt;code&gt;s&lt;/code&gt; was actually a character or something, but it's clearly specified as &lt;code&gt;char *&lt;/code&gt;. &lt;code&gt;s&lt;/code&gt; is for string!&amp;#13;
I couldn't figure out the meaning, so I soon gave up and looked at the annotated code. The &lt;code&gt;char *&lt;/code&gt; is &lt;code&gt;unsigned long long&lt;/code&gt; in other versions, and they explain that the type is used for both integers and pointers. The code operates on vectors of 8-bit integers, either as ASCII or numbers, so it makes some sense to use &lt;code&gt;char *&lt;/code&gt; from a memory layout perspective, but I don't use pointers as integers very often.&lt;/p&gt;
    &lt;code&gt;#define _(e...) ({e;})&amp;#13;
#define x(a,e...) _(s x=a;e)&amp;#13;
#define $(a,b) if(a)b;else&amp;#13;
#define i(n,e) {int $n=n;int i=0;for(;i&amp;lt;$n;++i){e;}}&lt;/code&gt;
    &lt;p&gt;These are all pretty straight forward, with one subtle caveat I only realized from the annotated code. They're all macros to make common operations more compact: wrapping an expression in a block, defining a variable &lt;code&gt;x&lt;/code&gt; and using it, conditional statements, and running an expression &lt;code&gt;n&lt;/code&gt; times.&lt;/p&gt;
    &lt;p&gt;The subtle thing the annotations point out is the first macro, &lt;code&gt;({e;})&lt;/code&gt;. The parentheses around curly brackets make this a statement expression, a non-standard C extension that allows you to treat a block of statements as a single expression, if the last statement is an expression that provides a value. In other words, &lt;code&gt;int x = ({int a = func1(); int b = func2(a); a+b;});&lt;/code&gt; sets &lt;code&gt;x&lt;/code&gt; to whatever &lt;code&gt;a+b&lt;/code&gt; is. This is used everywhere in the code after this.&lt;/p&gt;
    &lt;code&gt;#define Q(e) if(Q==(e))return Q;&amp;#13;
#define Qs(e,s) if(e)return err(__func__,s);&amp;#13;
#define Qr(e) Qs(e,"rank")&amp;#13;
#define Qd(e) Qs(e,"domain")&amp;#13;
#define Qz(e) Qs(e,"nyi")&lt;/code&gt;
    &lt;p&gt;These are error macros using that mysterious &lt;code&gt;Q&lt;/code&gt; defined earlier. &lt;code&gt;Q&lt;/code&gt; seems to have been used to represent errors, possibly short for "Quit". The &lt;code&gt;Qr/d/z&lt;/code&gt; functions seem to be types of errors. I have no idea what "nyi" means (I figure it out later).&lt;/p&gt;
    &lt;code&gt;#define _s(f,e,x...) s f(x){return _(e);}&amp;#13;
#define _i(f,e) _s(f,e,c x)&amp;#13;
#define f(f,e)  _s(f,e,s x)&amp;#13;
#define F(f,e)  _s(f,e,s a,s x)&lt;/code&gt;
    &lt;p&gt;These replace function declarations, and we can see that &lt;code&gt;_&lt;/code&gt; macro being used to add an implicit return.&amp;#13;
&lt;code&gt;_s&lt;/code&gt; could be used like&lt;/p&gt;
    &lt;code&gt;_s(my_function, puts("I rock!!!"); x*5+e, s x, int e)&lt;/code&gt;
    &lt;p&gt;, which would create basically this standard C:&lt;/p&gt;
    &lt;code&gt;char *my_function(char *x, int e) {&amp;#13;
	puts("I rock!!!");&amp;#13;
	return x*5+e;&amp;#13;
}&lt;/code&gt;
    &lt;p&gt;All the macros except the base &lt;code&gt;_s&lt;/code&gt; also add implicit arguments like &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; and you bet it's hard to tell them apart.&lt;/p&gt;
    &lt;code&gt;#define ax (256&amp;gt;x)&lt;/code&gt;
    &lt;p&gt;This was another one that baffled me until I looked at the annotations. Remember how I said &lt;code&gt;s&lt;/code&gt; values were either integers or pointers? 256 is the cutoff value for these integers, which the annotations call atoms, so ax means "is &lt;code&gt;x&lt;/code&gt; an atom?"&lt;/p&gt;
    &lt;code&gt;#define ix (c)x&amp;#13;
#define nx x[-1]&amp;#13;
#define xi x[i]&lt;/code&gt;
    &lt;p&gt;These aren't too confusing. &lt;code&gt;ix&lt;/code&gt; casts &lt;code&gt;x&lt;/code&gt; to a &lt;code&gt;char&lt;/code&gt;. &lt;code&gt;nx&lt;/code&gt; implies &lt;code&gt;x&lt;/code&gt; is some sort of fat pointer, meaning there's probably a length at &lt;code&gt;x[-1]&lt;/code&gt;, but we'll see. &lt;code&gt;xi&lt;/code&gt; just indexes &lt;code&gt;x&lt;/code&gt; as a normal pointer, using our implicitly defined &lt;code&gt;i&lt;/code&gt; from the &lt;code&gt;i(...)&lt;/code&gt; macro.&lt;/p&gt;
    &lt;code&gt;#define aa x(a,ax)&amp;#13;
#define ia x(a,ix)&amp;#13;
#define na x(a,nx)&lt;/code&gt;
    &lt;p&gt;These copy &lt;code&gt;ax&lt;/code&gt;, &lt;code&gt;ix&lt;/code&gt;, and &lt;code&gt;nx&lt;/code&gt; respectively to work on the &lt;code&gt;a&lt;/code&gt; variable, which is an implicit argument in functions defined using the &lt;code&gt;F(f,e)&lt;/code&gt; macro. You remembered the &lt;code&gt;x(name, expression)&lt;/code&gt; macro for assigning to a locally-scoped &lt;code&gt;x&lt;/code&gt;, right?&lt;/p&gt;
    &lt;code&gt;#define oo w("oo\n")&lt;/code&gt;
    &lt;p&gt;It prints &lt;code&gt;oo&lt;/code&gt;. It's not used anywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;a reading of a.c&lt;/head&gt;
    &lt;p&gt;I wound up not needing to refer to the annotated code at all to understand this. The C code is mostly using everything in the headers to build the interpreter.&lt;/p&gt;
    &lt;code&gt;#define r(n,e) _(s r=m(n);i(n,r[i]=e)r)&lt;/code&gt;
    &lt;p&gt;We create a vector &lt;code&gt;r&lt;/code&gt; from &lt;code&gt;m(n)&lt;/code&gt; (which is defined later (it's malloc)), fill &lt;code&gt;r&lt;/code&gt; with the results of &lt;code&gt;e&lt;/code&gt;, and return it out of the statement expression.&lt;/p&gt;
    &lt;code&gt;f(w,write(1,ax?&amp;amp;x:x,ax?1:strlen(x));x)&lt;/code&gt;
    &lt;p&gt;This defines &lt;code&gt;s w(s x)&lt;/code&gt;, which is our print function. If &lt;code&gt;x&lt;/code&gt; is an atom (&lt;code&gt;ax?&lt;/code&gt;), we print it as a single character by getting its address (&lt;code&gt;&amp;amp;x&lt;/code&gt;) and providing a length of 1. If it's a vector, we print it as a string using &lt;code&gt;strlen&lt;/code&gt; to calculate how long it is, so now we also know vectors must be null-terminated here.&amp;#13;
&lt;code&gt;write&lt;/code&gt; and &lt;code&gt;strlen&lt;/code&gt; are standard functions that we call without including the headers, because fuck headers. Let the linker figure it out.&lt;/p&gt;
    &lt;code&gt;F(err,w(a);w((s)58);w(x);w((s)10);Q)&lt;/code&gt;
    &lt;p&gt;Our fancy shmancy error printing function, &lt;code&gt;s err(s a, s x)&lt;/code&gt;. The confusing thing is that &lt;code&gt;:&lt;/code&gt; and the newline are represented by their ASCII numbers 58 and 10, respectively. This just prints a message in the format &lt;code&gt;{a}:{x}\n&lt;/code&gt; and returns our special error value &lt;code&gt;Q&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;_i(wi,s b[5];sprintf(b,"%d ",x);w(b);0)&lt;/code&gt;
    &lt;p&gt;Defines &lt;code&gt;s wi(c x)&lt;/code&gt;, which takes &lt;code&gt;x&lt;/code&gt; as a &lt;code&gt;char&lt;/code&gt;, formats it as an integer in up to &lt;code&gt;5*sizeof(char*)/sizeof(char)&lt;/code&gt; characters (40 on 64-bit machines), and writes that.&lt;/p&gt;
    &lt;code&gt;f(W,Q(x)$(ax,wi(ix))i(nx,wi(xi))w(10);x)&lt;/code&gt;
    &lt;p&gt;Another print function, &lt;code&gt;s W(s x)&lt;/code&gt; either writes &lt;code&gt;x&lt;/code&gt; as an integer or a list of integers. It also refuses to print the &lt;code&gt;Q&lt;/code&gt; vector.&lt;/p&gt;
    &lt;code&gt;f(srt,Qz(1)0) f(uni,Qz(1)0) F(Cut,Qz(1)0) F(Drp,Qz(1)0)&lt;/code&gt;
    &lt;p&gt;I figured out what &lt;code&gt;nyi&lt;/code&gt; means! It means "Not yet implemented", as we can see from these function definitions.&lt;/p&gt;
    &lt;code&gt;_i(m,s a=malloc(1+x);*a++=x;a)&lt;/code&gt;
    &lt;p&gt;And we find our previously-used function &lt;code&gt;s m(c x)&lt;/code&gt;, which allocates our buffer and returns a fat pointer (with the size at &lt;code&gt;x[-1]&lt;/code&gt;, hence the &lt;code&gt;1+x&lt;/code&gt; and &lt;code&gt;a++&lt;/code&gt;). &lt;code&gt;x&lt;/code&gt; is the length we're allocating here, which means our vectors are limited to 255 bytes. The repo suggests upgrading capacity as an exercise to the reader, which could be fun.&lt;/p&gt;
    &lt;code&gt;#define A(c) ((s)memchr(a,c,na)?:a+na)-a&lt;/code&gt;
    &lt;p&gt;This macro finds the first occurence of the character &lt;code&gt;c&lt;/code&gt; in our vector &lt;code&gt;a&lt;/code&gt; as an index into the string (hence the &lt;code&gt;-a&lt;/code&gt;, since &lt;code&gt;memchr&lt;/code&gt; returns a pointer). If the result is null, it just returns the length of the string (&lt;code&gt;a+na - a&lt;/code&gt;). We see another fun bit of non-standard syntax, &lt;code&gt;?:&lt;/code&gt;, which I had to look up. &lt;code&gt;a ?: b&lt;/code&gt; is equivalent to &lt;code&gt;a ? a : b&lt;/code&gt; without evaluating &lt;code&gt;a&lt;/code&gt; twice. Pretty snazzy!&lt;/p&gt;
    &lt;code&gt;#define g(a,v) ax?255&amp;amp;a:r(nx,v)&lt;/code&gt;
    &lt;p&gt;Strange little operation, I'll have to see it in action. If &lt;code&gt;x&lt;/code&gt; is an atom, it clamps &lt;code&gt;a&lt;/code&gt; to be an atom with a simple mask (&lt;code&gt;255&amp;amp;a&lt;/code&gt;), otherwise it creates a new vector the same size as &lt;code&gt;x&lt;/code&gt; filled with the result from &lt;code&gt;v&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;f(not,g(!ix,!xi)) f(sub,g(-ix,-xi)) F(At,Qr(aa)g(a[ix],a[xi])) F(_A,Qr(aa)g(A(ix),A(xi)))&lt;/code&gt;
    &lt;p&gt;Ah, I see now. &lt;code&gt;g(a, v)&lt;/code&gt; lets us define functions that work on both atoms and vectors. If &lt;code&gt;x&lt;/code&gt; is an atom, it returns the atom result clamped within the correct bounds. Otherwise it allocates a new vector and computes the other expression.&amp;#13;
All the above functions work either on &lt;code&gt;x&lt;/code&gt; as an integer (&lt;code&gt;ix&lt;/code&gt;), or on every element of &lt;code&gt;x&lt;/code&gt; (&lt;code&gt;xi&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;s not(s x)&lt;/code&gt;does boolean negation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s sub(s x)&lt;/code&gt;does arithmetic negation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s At(s a, s x)&lt;/code&gt;indexes into&lt;code&gt;a&lt;/code&gt;, either to get one value or to shuffle them into a new vector.&lt;code&gt;a&lt;/code&gt;has to be a vector.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s _A(s a, s x)&lt;/code&gt;searches a vector&lt;code&gt;a&lt;/code&gt;for the value of&lt;code&gt;x&lt;/code&gt;and gives us the index, either one value or every value in the vector.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a lot of functionality in such a small bit of code.&lt;/p&gt;
    &lt;code&gt;f(ind,Qr(!ax)0&amp;gt;ix?r(-ix,-ix-1-i):r(ix,i))&amp;#13;
F(Ind,Qr(!aa)Qd(1&amp;gt;ia)g(ix%ia,xi%ia))&lt;/code&gt;
    &lt;p&gt;These are some atom-only functions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;s ind(s x)&lt;/code&gt;creates a vector of length |x| containing&lt;code&gt;0, 1... x-1&lt;/code&gt;if&lt;code&gt;x&lt;/code&gt;is positive, otherwise it contains&lt;code&gt;-x-1, -x-2... 0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s Ind(s a, s x)&lt;/code&gt;does&lt;code&gt;x&lt;/code&gt;modulo&lt;code&gt;a&lt;/code&gt;, either on&lt;code&gt;x&lt;/code&gt;as an integer or every value of the vector&lt;code&gt;x&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Honestly, I can buy that this method of coding produces fewer bugs, once you can actually write it, since you work only on small building blocks of the logic and reuse them. Like, where could a bug for &lt;code&gt;ind&lt;/code&gt; even be? Maybe an off-by-one in &lt;code&gt;-ix-1-i&lt;/code&gt;, but it's hard to miss what's happening once you can see the trees through the forest.&lt;/p&gt;
    &lt;code&gt;#define G(f,o) F(f,ax?aa?255&amp;amp;ia o ix:Ltn==f?f(sub(x),sub(a)):f(x,a):r(nx,(aa?ia:a[i])o xi))&lt;/code&gt;
    &lt;p&gt;That's too many trees! I can't understand this many nested ternary operators at the same time because I'm not the alien from Arrival. I process things in linear time. I have to chunk this up.&lt;/p&gt;
    &lt;code&gt;F(f, ax ?&amp;#13;
		aa ?&amp;#13;
			255 &amp;amp; ia o ix&amp;#13;
			: Ltn==f ? &amp;#13;
				f(sub(x),sub(a))&amp;#13;
				: f(x,a)&amp;#13;
		: r(nx,(aa?ia:a[i])o xi))&lt;/code&gt;
    &lt;p&gt;Okay, I see. It's 3 cases from 2 conditions: &lt;code&gt;x&lt;/code&gt; is an atom or a vector, and &lt;code&gt;a&lt;/code&gt; is an atom or a vector.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;and&lt;code&gt;a&lt;/code&gt;are atoms: apply some operator&lt;code&gt;o&lt;/code&gt;to both values and clamp to 8 bits. I also didn't realize the bitwize and (&lt;code&gt;&amp;amp;&lt;/code&gt;) had a lower precedence than the operators this macro is used on, meaning it's always&lt;code&gt;`C 255 &amp;amp; (ia o ix)&lt;/code&gt;`.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;is an atom and&lt;code&gt;a&lt;/code&gt;is a vector: run this function with the arguments swapped. If the function is&lt;code&gt;Ltn&lt;/code&gt;, also negate the arguments, since less-than depends on argument order.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;is a vector: create a new vector, either applying&lt;code&gt;a&lt;/code&gt;or each value of&lt;code&gt;a&lt;/code&gt;to&lt;code&gt;x&lt;/code&gt;using the operator. It assumes vector&lt;code&gt;a&lt;/code&gt;is at least as long as&lt;code&gt;x&lt;/code&gt;, or it'll index past the end of&lt;code&gt;a&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;G(Ltn,&amp;lt;)G(Eql,==)G(Not,!=)G(Sum,+)G(Prd,*)G(And,&amp;amp;)G(Or,|)&lt;/code&gt;
    &lt;p&gt;Using our fancy new macro, we quickly define seven new functions for the vectors, where they're all element-wise applications of binary operators.&lt;/p&gt;
    &lt;code&gt;f(cat,Qr(!ax)r(1,ix)) F(Cat,a=aa?cat(a):a;x=ax?cat(x):x;s r=m(na+nx);memcpy(r+na,x,nx);memcpy(r,a,na))&lt;/code&gt;
    &lt;p&gt;I was confused by the first function, but I see now these are &lt;code&gt;cat&lt;/code&gt; as in "concatenate". For an atom, it creates a vector of length 1 containing that atom. &lt;code&gt;Cat&lt;/code&gt; does the more complex work of joining two vectors together, running &lt;code&gt;cat&lt;/code&gt; on each value if it's an atom to get a list.&lt;/p&gt;
    &lt;code&gt;f(at,At(x,0)) f(rev,Qr(ax)At(x,ind(255&amp;amp;-nx))) f(cnt,Qr(ax)nx)&lt;/code&gt;
    &lt;p&gt;Some more simple functions. Lil &lt;code&gt;at&lt;/code&gt; gets the first item of &lt;code&gt;x&lt;/code&gt;; &lt;code&gt;rev&lt;/code&gt; reverses the list using our &lt;code&gt;ind&lt;/code&gt; function to generate the list of indeces in reverse, which is a little overkill but vectors are 256 bytes at max and memory is never freed so who cares; and &lt;code&gt;cnt&lt;/code&gt; gets the size of &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;F(Tak,Qr(!aa||ax)Qd(0&amp;gt;ia||ia&amp;gt;nx)At(x,ind(a))) F(Sub,Sum(a,sub(x))) F(Mtn,Ltn(x,a)) f(qz,Qz(1)0)&lt;/code&gt;
    &lt;p&gt;Some more simple functions. &lt;code&gt;Tak&lt;/code&gt; returns the first &lt;code&gt;a&lt;/code&gt; characters from the vector &lt;code&gt;x&lt;/code&gt; as a new list; &lt;code&gt;Sub&lt;/code&gt; subtracts; &lt;code&gt;Mtn&lt;/code&gt; is "more than"; and &lt;code&gt;qz&lt;/code&gt; returns our "not yet implemented" error.&lt;/p&gt;
    &lt;code&gt;#define v(e) ((strchr(V,e)?:V)-V)&lt;/code&gt;
    &lt;p&gt;A shorthand to get the first occurence of a character from a string &lt;code&gt;V&lt;/code&gt;, returning an offset into the array or zero if it's not present. This seems ambiguous, since that's also the result if we match with the first character, but we'll see.&lt;/p&gt;
    &lt;code&gt;s U[26],V=" +-*&amp;amp;|&amp;lt;&amp;gt;=~!@?#_^,",&amp;#13;
(*f[])()={0,abs,sub,qz ,qz,rev,qz ,qz, qz ,not,ind,at,uni,cnt,qz ,srt,cat},&amp;#13;
(*F[])()={0,Sum,Sub,Prd,And,Or,Ltn,Mtn,Eql,Not,Ind,At,_A ,Tak,Drp,Cut,Cat};&lt;/code&gt;
    &lt;p&gt;Ah, we have seen. The first character of &lt;code&gt;V&lt;/code&gt; is a space, and it looks like the arrays of function pointers match up with the characters of &lt;code&gt;V&lt;/code&gt; to give us our functions, with space being null. However, I think &lt;code&gt;abs&lt;/code&gt; is from the standard library here, since it's not defined anywhere else? That seems like a bug. It'd work for atoms, but it'd break vectors.&amp;#13;
This also defines an array of 26 vectors, which I assume will be our variables. &lt;/p&gt;
    &lt;code&gt;_i(n, 10u&amp;gt;x-48? x-48 : 26u&amp;gt;x-97? U[x-97] : 0)&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;s n(c x)&lt;/code&gt; reads a char and returns one of several things. I'll have to consult an ASCII table.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If &lt;code&gt;x&lt;/code&gt;is between 48 and 57 (inclusive), we subtract 48 and return that. Meaning, if&lt;code&gt;x&lt;/code&gt;is an ASCII character representing 0-9, we subtract 48 so it's the integer 0-9, rather than the character. It's phrased strangely,&lt;code&gt;10u &amp;gt; x-48&lt;/code&gt;, instead of the more obvious&lt;code&gt;x&amp;gt;47&amp;amp;&amp;amp;58&amp;gt;x&lt;/code&gt;. Maybe it's because it's two characters shorter. Maybe Arthur wanted to show the length of the span of characters (10) more than the start and end, which this does once you understand it. Maybe he just thought the underflow trickery was neat.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;x&lt;/code&gt;is between 97 and 122 (inclusive), it's a lowercase character of the alphabet in ASCII, in which case the function returns one of our variables from the&lt;code&gt;U&lt;/code&gt;array, mapping 'a' to 'z'.&lt;/item&gt;
      &lt;item&gt;Otherwise, the function returns 0.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So it looks like this function is specifically to read values, either numerals or variables, all of which are one character.&lt;/p&gt;
    &lt;code&gt;f(e,s z=x;c i=*z++;!*z?n(i):v(i)?x(e(z),Q(x)f[v(i)](x)):x(e(z+1),Q(x)58==*z?U[i-97]=x:_(c f=v(*z);Qd(!f)F[f](n(i),x))))&lt;/code&gt;
    &lt;p&gt;Uh, let's spread this out a little.&lt;/p&gt;
    &lt;code&gt;f(e, s z=x; c i=*z++; !*z ? n(i)&amp;#13;
	: v(i) ? x(e(z), Q(x) f[v(i)](x))&amp;#13;
		: x(e(z+1), Q(x) 58==*z ? U[i-97]=x &amp;#13;
			: _(c f=v(*z); Qd(!f) F[f](n(i),x))))&lt;/code&gt;
    &lt;p&gt;Okay, easy. It's a recursive function that checks each character of vector &lt;code&gt;x&lt;/code&gt;, called &lt;code&gt;i&lt;/code&gt;.&amp;#13;
If we're at the end of the string, we check if &lt;code&gt;i&lt;/code&gt; is a value and return it.&amp;#13;
Otherwise, we first check if it's an operator (from our &lt;code&gt;V&lt;/code&gt; string). If it is, we evaluate the rest of the string, check for errors, and then apply the operation to the result from the rest of the evaluation.&amp;#13;
If it wasn't an operation, we evaluate the rest of the string, skipping one character. If the skipped character is a colon (ASCII 58), we assign the result of the evaluation to one of the slots in &lt;code&gt;U&lt;/code&gt; (if the character &lt;code&gt;i&lt;/code&gt; is not a lowercase ASCII letter, this will corrupt memory, so don't write bugs).&lt;/p&gt;
    &lt;p&gt;I'm pretty sure spaces are a syntax error in every location, and I don't see code to create array literals. If the skipped character is an operator, we instead apply that binary operator on the evaluation result and &lt;code&gt;n(i)&lt;/code&gt;, which is either a variable or a number.&amp;#13;
This means code is executed from right to left, with no operator precedent, which is standard for APL-type languages from what I understand.&amp;#13;
Because this language has only single-character variable names, numbers, and operators, this is all the tokenizing, parsing, and evaluation we need.&lt;/p&gt;
    &lt;code&gt;C int main(){c b[99]; while(1) if(w(32),b[read(0,b,99)-1]=0,*b) 58==b[1] ? e(b) : W(e(b));}&lt;/code&gt;
    &lt;p&gt;And finally, &lt;code&gt;main&lt;/code&gt;.&amp;#13;
In an infinite loop, we read up to 99 characters from a user, and then write the evaluated result of that text.&lt;/p&gt;
    &lt;p&gt;Et voila. We have a tiny interpreter for a simple array language. It's not exactly production-ready, but it does quite a lot in its tiny footprint.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;I think I can say I understand this code pretty well, even more than most code I read. I don't know how much of that is because of the coding style, or because I spent eight hours writing several thousand words about fifty lines of code in a borderline-delusional fugue state brought on by drinking one small Starbucks™ Frapuccino® (Mocha® Flavored*) I bought from a gas station at 10 PM on a Thursday.&lt;/p&gt;
    &lt;p&gt;I had some fun dreams about macros with one-character names applying operations on scalars and vectors that morning (I went to sleep at 6:40 AM).&lt;/p&gt;
    &lt;p&gt;All in all, it was a fun exercise. To summarize my thoughts:&lt;/p&gt;
    &lt;head rend="h3"&gt;Good ideas&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Well-considered primitives. I've read and written a lot of macro-ridden C, but this feels like a proper little language designed with composable, useful macros that removed enough repetition to make common operations, like iteration, easy to decipher. In other languages, higher-order functions and similar constructs could be used the same way.&lt;/item&gt;
      &lt;item&gt;Fewer lines. I didn't have to scroll so much when I forgot what a macro or a function did! I have a wide screen monitor, I don't need lines limited to 10-20 characters of actual code most of the time. If people can read English in compact paragraphs, why not code?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Bad ideas&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-semantic types. I was completely baffled by the &lt;code&gt;char *&lt;/code&gt;being treated as an integer at first, and simply assumed I was misunderstanding the code somehow until I checked the annotated version. In my own code, I use types as one of the core building blocks. What the data is defines how I use it. For a full interpreter, this would be a custom type anyway, since right now it assumes&lt;code&gt;malloc&lt;/code&gt;will never give it a pointer to an address less than 256, which is probably true but not guaranteed, and also the integer 128 is reserved for invalid results, which is probably the bigger limitation.&lt;/item&gt;
      &lt;item&gt;Code golf. I can understand the large gains to density like macros, and even the medium gains like short names, but there's a point where the code becomes significantly harder to follow for very minor gains, such as the use of ASCII codes like &lt;code&gt;58&lt;/code&gt;instead of character literals like&lt;code&gt;':'&lt;/code&gt;, or the use of&lt;code&gt;10u&amp;gt;x-48&lt;/code&gt;instead of&lt;code&gt;x&amp;gt;48&amp;amp;&amp;amp;58&amp;gt;x&lt;/code&gt;for checking if&lt;code&gt;x&lt;/code&gt;is within a range. And while I think more code can be put on a line, I'm not throwing out my space key just yet, epecially between function declarations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ideas I'm ambivalent about&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-standard syntax. There's some very interesting features in this code that utilize GCC-specific extensions, like &lt;code&gt;a ?: b&lt;/code&gt;ternaries and statement expressions. I don't typically need to compile for everything on earth, so learning the tricks of one reasonably cross-platform compiler isn't a bad idea. At the same time, even using clang, the same compiler Arthur was using, I had to include&lt;code&gt;stdio.h&lt;/code&gt;due to not linking&lt;code&gt;sprintf&lt;/code&gt;otherwise. If I wanted to build using Visual Studio I'd just have to rewrite a bunch of stuff. Also, compiling without&lt;code&gt;-w&lt;/code&gt;generates almost three compiler warnings per line of code. Those are useful sometimes, if they aren't flooded!&lt;/item&gt;
      &lt;item&gt;Implicit arguments. Many of the density gains in this code come from using the variables &lt;code&gt;x&lt;/code&gt;,&lt;code&gt;a&lt;/code&gt;, and&lt;code&gt;i&lt;/code&gt;in nearly every context, allowing macros to use them by default and skip listing other parameters. I didn't find it to be a problem after a brief adjustment, but it's also a very small codebase. Implicit arguments are a feature in many dynamically typed languages, and in "point-free" or "tacit" programming, but it's fallen out of style due to its difficulty to parse at first glance. Whitney's languages all being based around tacit programming is surely an influence on his tendency to make arguments implicit.&lt;/item&gt;
      &lt;item&gt;Short names. Beyond the very first introduction, there'd be virtually no benefit to renaming &lt;code&gt;ax&lt;/code&gt;as&lt;code&gt;vector_is_atom(x)&lt;/code&gt;,&lt;code&gt;_(...)&lt;/code&gt;as 'execute(...)', or most other primitives after they're introduced. Most are small enough that you can parse what it does right away. However, this doesn't lend any signal as to why it does. You have to figure out what it does from context. For code that's meant to be read by another person, there should probably be some explanation as to why a primitive does what it does, even if it has a short name. This is especially true of more complex operations, like the evaluation function&lt;code&gt;e&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Nested ternary operators. Too confusing for me to follow without parentheses, especially without whitespace.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This coding style feels most appropriate for "done" code, or code that's been worked out on paper or some other environment and is now being written down in a compact way. It's more like finalized mathematical notation than typical code. I don't see myself being able to effectively write code like this, since I tend to quickly jot down ideas, compile and run to validate, and edit what I've done based on the results. Making a small set of good primitives and building heavily on those requires basically having solved the problem before writing a single line. Otherwise you get bad primitives that cause more confusion than help, and adjusting those primitives would involve rewriting all the code that depends on them, which is all the code.&lt;/p&gt;
    &lt;p&gt;But I think that's my key takeaway: I tend to work out problems in the code, which can lead to messy results. I write the dumbest possible solution, and then have to try and refactor as I develop a better mental model of the problem. What I like most about this code isn't how few characters are used, or everything fitting in one screen. I like how it seems the code was well-understood before it was written. You can't refactor a 500-line jumble of C into code like this.&lt;/p&gt;
    &lt;p&gt;The real lesson is that I'm probably too quick to jump into coding things. I could spend more time working out how I want to model a problem in a more free-form way, like writing notation on paper, before jumping into the rigid world of programming syntax. With a clear mental model, I can then write code in terms of how I was thinking about the problem, instead of thinking about the problem in terms of how I wrote the code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next time&lt;/head&gt;
    &lt;p&gt;I think a fun exercise would be to extend this interpreter while maintaining its code style, to see how I fare actually working with it. The repository this came from has various suggested exercises, but my ideas would be adding the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swapping the bytes for float vectors&lt;/item&gt;
      &lt;item&gt;Vectors longer than 255 values&lt;/item&gt;
      &lt;item&gt;Multi-character numbers&lt;/item&gt;
      &lt;item&gt;Array literals (you can do it with comma, but that runs &lt;code&gt;cat&lt;/code&gt;on every value, which isn't ideal)&lt;/item&gt;
      &lt;item&gt;Whitespace insensitivity&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;The unimplemented functions&lt;/item&gt;
      &lt;item&gt;Multi-character variable names&lt;/item&gt;
      &lt;item&gt;Multi-character operators&lt;/item&gt;
      &lt;item&gt;Indication for syntax errors&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800777</guid><pubDate>Mon, 03 Nov 2025 16:23:11 +0000</pubDate></item><item><title>Why We Migrated from Python to Node.js</title><link>https://blog.yakkomajuri.com/blog/python-to-node</link><description>&lt;doc fingerprint="26f311d55ce5b00f"&gt;
  &lt;main&gt;
    &lt;p&gt;We just did something crazy: we completely rewrote our backend from Python to Node just one week after our launch.&lt;/p&gt;
    &lt;p&gt;We did this so we can scale. Yes, scale. A week in.&lt;/p&gt;
    &lt;p&gt;In some ways, it's a good time right? The codebase is still small and we don't have too many users.&lt;/p&gt;
    &lt;p&gt;But on the other hand, it goes completely against the advice given to early-stage startups which is to just ship and sell, and worry about scale once you've hit product-market-fit. "Do things that don't scale", as PG put it.&lt;/p&gt;
    &lt;p&gt;You see, we didn't have a magical launch week that flooded us with users and force us to scale. And generally you can expect that any stack you pick should be able to scale reasonably well for a long time until you actually get to the point where you should consider changing frameworks or rewriting your backend in a different language (read: Rust).&lt;/p&gt;
    &lt;p&gt;So why do it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Python async sucks&lt;/head&gt;
    &lt;p&gt;I'm a big fan of Django. I was introduced to it at PostHog and it's become my go-to backend for most projects since. It gets you off the ground really fast, has great tooling and abstractions, and is still flexible enough to tweak to your needs.&lt;/p&gt;
    &lt;p&gt;So naturally, when I started writing our backend at Skald, I started us off with Django too.&lt;/p&gt;
    &lt;p&gt;Now, we make a lot of calls to LLM and embedding APIs at Skald, so we're generally doing a lot of network I/O that we'd like to be async. Not only that, we often want to fire a lot of requests concurrently, such as when need to generate vector embeddings for the various chunks of a document.&lt;/p&gt;
    &lt;p&gt;And things quickly got really messy in Django.&lt;/p&gt;
    &lt;p&gt;I'll preface this by saying that neither of us has a lot of experience writing Python async code (I've mostly worked on async-heavy services in Node) but I think this is partly the point here: it's really hard and unintuitive to write solid and performant Python async code. You need to go deep into the foundations of everything in order to be able to do so.&lt;/p&gt;
    &lt;p&gt;I'm actually really interested in spending proper time in becoming more knowledgeable with Python async, but in our context you a) lose precious time that you need to use to ship as an early-stage startup and b) can shoot yourself in the foot very easily in the process.&lt;/p&gt;
    &lt;p&gt;Nevertheless, I thought I was to blame. "Bad programmer! Bad programmer!" was what I was hearing in my head as I tried to grasp everything. But while more knowledgeable folks would certainly have a better time, we discovered that the foundations of Python async are actually a bit shaky too.&lt;/p&gt;
    &lt;p&gt;Unlike JavaScript, which had the event loop from the beginning, and Go, that created the concept of goroutines (both concurrency models that I quite like and have used in production), Python async support was patched on later, and that's where the difficulty lies.&lt;/p&gt;
    &lt;p&gt;Two blog posts that cover this really well are "Python has had async for 10 years -- why isn't it more popular?" and "Python concurrency: gevent had it right", both conveniently published not long before I started digging into all this.&lt;/p&gt;
    &lt;p&gt;As for us, we learned a few things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python doesn't have native async file I/O.&lt;/item&gt;
      &lt;item&gt;Django still doesn't have full async support. Async in the ORM is not done yet and the colored functions problem really shines here. You can technically use Django with async, but their docs on this have so many caveats that it should scare anyone.&lt;/item&gt;
      &lt;item&gt;You gotta write &lt;code&gt;sync_to_async&lt;/code&gt;and&lt;code&gt;async_to_sync&lt;/code&gt;everywhere.&lt;/item&gt;
      &lt;item&gt;All sorts of models have emerged to bring better async support to different parts of the Python ecosystem, but as they're not native they have their own caveats. For instance, aiofiles brings async API-compatible file operations but uses a thread pool under the hood, and Gevent with its greenlets is pretty cool but it literally patches the stdlib in order to work.&lt;/item&gt;
      &lt;item&gt;Due to a lot of async support in Python relying on layers that sit on top of the language rather than being native, you need to be careful about the async code you write as it will have different implications depending on e.g. the Gunicorn worker type you run (good luck learning much about those from the Gunicorn docs, btw).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, just getting an equivalent of &lt;code&gt;Promise.all&lt;/code&gt; to work, while understanding all of its gotchas was not simple at all.&lt;/p&gt;
    &lt;p&gt;Faced with this, I went into the PostHog codebase.&lt;/p&gt;
    &lt;p&gt;I worked at PostHog for three years and we had no async in the Django codebase back then but they're a massive company and they have AI features now so they must have figured this out!&lt;/p&gt;
    &lt;p&gt;And what I realized was that they're still running WSGI (not ASGI) with Gunicorn Gthread workers (where the max concurrent requests you're able to handle is usually max 4x CPU cores), thus not getting much benefit from running things async. The codebase also has a lot of utils to make async work properly, like their own implementation of &lt;code&gt;async_to_sync&lt;/code&gt;. So I guess way they're handling a lot of load is probably just horizontal scaling.&lt;/p&gt;
    &lt;p&gt;There's simply no great way to run async in Django.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ok, now what?&lt;/head&gt;
    &lt;p&gt;We essentially concluded that Django was going to hurt us really soon, not just when we started to have a lot of load.&lt;/p&gt;
    &lt;p&gt;Without too many users we'd already need to start running multiple machines in order to not have terrible latency, plus we'd be writing clunky code that would be hard to maintain.&lt;/p&gt;
    &lt;p&gt;We could of course just "do things that don't scale" for now and just solve the problem with money (or AWS credits), but it didn't feel right. And being so early would make the migration to another framework much easier.&lt;/p&gt;
    &lt;p&gt;At this point, some people are probably screaming at their screens going: "just use FastAPI!" -- and we did indeed consider it.&lt;/p&gt;
    &lt;p&gt;FastAPI does have proper async support and is quite a loved framework said to be performant. And if you want an ORM with it you could use SQLAlchemy which also supports async.&lt;/p&gt;
    &lt;p&gt;Migrating to FastAPI would have probably saved us a day or two (our migration took 3 days) due to being able to reuse a lot of code without translating it, but at this point we weren't feeling great about the Python async ecosystem overall, and we had actually already written our background worker service in Node, so we thought it would be a good opportunity to go all-in on one ecosystem.&lt;/p&gt;
    &lt;p&gt;And so migrate to Node we did. We took a little time picking the framework + ORM combo but settled on Express + MikroORM.&lt;/p&gt;
    &lt;p&gt;Yeah sure Express is old but it's battle-tested and feels familiar. Coming over to the JS event loop was the main point of all this anyway.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we gained, what we lost&lt;/head&gt;
    &lt;head rend="h3"&gt;Gained: Efficiency&lt;/head&gt;
    &lt;p&gt;Our initial benchmarks show we've gained ~3x throughput out of the box and that's just with us running what is mostly sequential code in an async context. Being over on Node now, we're planning on doing a lot concurrent processing when chunking, embedding, reranking, and so on. This means this change should have an even greater payoff over time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost: Django&lt;/head&gt;
    &lt;p&gt;Losing Django hurts, and we've already found ourselves building a lot more middleware and utilities ourselves on the Express side. Adonis exists, which is a more fully-featured Node framework, but moving to a whole new ecosystem felt like more work to us than just using something minimal.&lt;/p&gt;
    &lt;p&gt;What I'm missing the most is the ORM, which in my opinion is really ergonomic. And while you always have to be careful with ORMs when looking to extract the best possible performance, the Django ORM does do some nice things under the hood in order to make it performant enough to write queries in Python, and I learned a bit more about this when migrating our Django models over to MikroORM entities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: MikroORM&lt;/head&gt;
    &lt;p&gt;MikroORM was a consolation prize in this whole migration. I still much prefer the Django ORM but at the same time different ecosystems call for different tooling.&lt;/p&gt;
    &lt;p&gt;I'd never used it before and was positively surprised to find Django-like lazy loading, a migrations setup that felt much better than Prisma's, as well as a reasonably ergonomic API (once you manually set up the foundations right).&lt;/p&gt;
    &lt;p&gt;Overall, we're early into this change, but currently happy to have picked MikroORM over the incumbent Prisma.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost: The Python ecosystem&lt;/head&gt;
    &lt;p&gt;I think this is pretty self-explanatory. While most tools for building RAGs and agents have Python and TypeScript SDKs, Python still takes priority, and we're just talking about API wrappers here.&lt;/p&gt;
    &lt;p&gt;Once you want to actually get into ML stuff yourself, there's just no competition. I suspect that as we get more sophisticated we'll end up having a Python service, but for now we're ok.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: Unified codebase&lt;/head&gt;
    &lt;p&gt;We'd always realized that migrating to Node would mean we'd have two Node services instead of a Python one and a Node one, but it didn't occur to us until a day in that we could actually merge the codebases and that that would be extremely helpful.&lt;/p&gt;
    &lt;p&gt;There was a lot of duplicate logic across the Node worker and the Django server, and now we've unified the Express server and background worker into one codebase, which feels so much better. They can both use the ORM now (previously the worker was running raw SQL) and share a bunch of utils.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: Much better testing&lt;/head&gt;
    &lt;p&gt;This is not a &lt;code&gt;pytest&lt;/code&gt; vs &lt;code&gt;jest&lt;/code&gt; thing, it's just that in order to make sure everything was working as expected after migrating, we just wrote a ton more tests. This and some refactoring were welcome side benefits.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we did it&lt;/head&gt;
    &lt;p&gt;I think it's about time to wrap this post up, but here are some quick notes about the actual migration process.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It took us three days.&lt;/item&gt;
      &lt;item&gt;We barely used AI code generation at all until the final bits -- it felt important to us to understand the foundations of our new setup really well, particularly the inner workings of the new ORM. Once we had the foundations of everything down Claude Code was quite helpful in generating code for some less important endpoints, and also helped us in scanning the codebase for issues.&lt;/item&gt;
      &lt;item&gt;We almost quit multiple times. We were getting customer requests for new features and had some bugs in the Django code and it felt like we were wasting time migrating instead of serving customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Would we do it again?&lt;/head&gt;
    &lt;p&gt;Honestly, we're quite happy with our decision and would 100% do it again. Not only will this pay off in the long term but it's already paying off today.&lt;/p&gt;
    &lt;p&gt;We learned a lot of stuff in the process too, and if the whole point of this whole post is that someone comes to tell me that we're dumb and we should just have done X or Y, or comes to teach me about how Python async works, then that will honestly be great. For my part, I gladly recognize my inexperience with Python async and if I can learn more about it, that's a win.&lt;/p&gt;
    &lt;p&gt;And if you're interested in actually seeing the code, check out the following PRs:&lt;/p&gt;
    &lt;p&gt;Skald is an MIT-licensed RAG API platform, so if you have any thoughts or concerns, you can come yell at us on GitHub, or open a PR to rewrite the backend to your framework of choice :D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800955</guid><pubDate>Mon, 03 Nov 2025 16:35:44 +0000</pubDate></item><item><title>Python Steering Council unanimously accepts "PEP 810, Explicit lazy imports"</title><link>https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131?page=23</link><description>&lt;doc fingerprint="347f48556ca5c5d5"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Dear PEP 810 authors. The Steering Council is happy to unanimously accept “PEP 810, Explicit lazy imports”. Congratulations! We appreciate the way you were able to build on and improve the previously discussed (and rejected) attempt at lazy imports as proposed in PEP 690.&lt;/p&gt;
      &lt;p&gt;We have recommendations about some of the PEP’s details, a few suggestions for filling a couple of small gaps, and we have made decisions on the alternatives that you’ve left to the SC, all of which I’ll outline below. If you have any questions, please do reach out to the SC for clarification, either here, on the SC tracker, or in office hours.&lt;/p&gt;
      &lt;p&gt;Use &lt;code&gt;lazy&lt;/code&gt; as the keyword.  We debated many of the given alternatives (and some we came up with ourselves), and ultimately agreed with the PEP’s choice of the &lt;code&gt;lazy&lt;/code&gt; keyword.  The closest challenger was &lt;code&gt;defer&lt;/code&gt;, but once we tried to use that in all the places where the term is visible, we ultimately didn’t think it was as good an overall fit.  The same was true with all the other alternative keywords we could come up with, so… &lt;code&gt;lazy&lt;/code&gt; it is!&lt;/p&gt;
      &lt;p&gt;What about &lt;code&gt;from foo lazy import bar&lt;/code&gt;?  Nope!  We like that in both module imports and &lt;code&gt;from&lt;/code&gt;-imports that the &lt;code&gt;lazy&lt;/code&gt; keyword is the first thing on the line.  It helps to visually recognize lazy imports of both varieties.&lt;/p&gt;
      &lt;p&gt;Leveraging a subclass of dict. We don’t see a need for this complicated alternative; please add this to the rejected ideas.&lt;/p&gt;
      &lt;p&gt;Allowing &lt;code&gt;’*’&lt;/code&gt; in &lt;code&gt;__lazy_modules__&lt;/code&gt;.  We agree with the rationale for rejecting this idea; it can always be added later if needed.&lt;/p&gt;
      &lt;p&gt;One thing that the PEP does not mention is &lt;code&gt;.pth&lt;/code&gt; files, which the site.py module processes, and which has some special handling for lines that begin with the string &lt;code&gt;'import'&lt;/code&gt; followed by a space or tab.  It doesn’t make much sense for &lt;code&gt;.pth&lt;/code&gt; files to support lazy imports, so we suggest that the PEP explicitly says that this special handling in &lt;code&gt;.pth&lt;/code&gt; files will not be adapted to handle lazy imports.&lt;/p&gt;
      &lt;p&gt;There currently is no way to get the active filter mode, so please add a &lt;code&gt;sys.get_lazy_imports()&lt;/code&gt; function.  Also, do you think appending &lt;code&gt;_mode&lt;/code&gt; to their names makes the purpose of these functions clearer?  We leave that up to the PEP authors.&lt;/p&gt;
      &lt;p&gt;The PEP should be explicit about the precedence order between the different ways to set the mode, i.e. &lt;code&gt;$PYTHON_LAZY_IMPORTS=&amp;lt;mode&amp;gt;&lt;/code&gt;, &lt;code&gt;-X lazy_imports=&amp;lt;mode&amp;gt;&lt;/code&gt;, and &lt;code&gt;sys.set_lazy_imports()&lt;/code&gt;.  In all expectation, it will follow the same precedence order as other similar settings, but the PEP should be explicit.&lt;/p&gt;
      &lt;p&gt;We agree that the PEP should take no position on any style recommendations for sorting lazy imports. While we generally like the idea of grouping lazy imports together, let’s leave that up to the linters and auto-formatters to decide the details.&lt;/p&gt;
      &lt;p&gt;That should just about cover it. Again, thank you for your work on this, as it’s been a feature so many in the Python community have wanted for so long. Given the earlier attempts and existing workarounds, we think this strikes exactly the right balance.&lt;/p&gt;
      &lt;p&gt;-Barry, on behalf of the Python Steering Council&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800967</guid><pubDate>Mon, 03 Nov 2025 16:36:29 +0000</pubDate></item><item><title>No Socials November</title><link>https://bjhess.com/posts/no-socials-november</link><description>&lt;doc fingerprint="a3c4dc8ffd25e785"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;No Socials November&lt;/head&gt;
    &lt;p&gt;November seems to be a ripe month for challenges. Some people grow facial hair. Some people write many words daily hoping to come out with a novel on the other side. I’m sure there are five other such efforts that I’m not aware of.&lt;/p&gt;
    &lt;p&gt;For me, I’m going to continue my push away from social networks. I’ve logged out of all personal accounts, set my YouTube to stop suggesting to me via algorithm, and even found myself logged out of Reddit yesterday. I’m set to have a no socials November!&lt;/p&gt;
    &lt;p&gt;Maybe some of you reading my blog are also finding yourself overly pulled by the lure of social networking and tempted to take a break? Perhaps join me and see how it feels? Log out, delete the apps from your phone, and start the challenging process of breaking that muscle memory today. I believe in a week you’ll feel pretty good about the decision.&lt;/p&gt;
    &lt;p&gt;No pressure to stay off socials after November is over. You may decide you want to go back to your same relationship with social networking in December. You may decide you want to go back, but differently. You may decide you want to stay away.&lt;/p&gt;
    &lt;p&gt;I might try to blog more. I might not. We’ll see! If you’d like to try blogging as an alternative, I recommend my good friend, Pika. In solidarity with #nosocialsnovember, there’s even a NOSOCIALSNOVEMBER coupon code for 15% off your first year of the service.&lt;/p&gt;
    &lt;p&gt;If you have any thoughts to share about stepping away from socials, email me via the link below. And if you’re blogging, let me know! I’d love to follow what you’re writing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801096</guid><pubDate>Mon, 03 Nov 2025 16:45:12 +0000</pubDate></item><item><title>Learning a Bit of VGA</title><link>https://www.usebox.net/jjm/blog/learning-a-bit-of-vga/</link><description>&lt;doc fingerprint="a26850d36e0f85d5"&gt;
  &lt;main&gt;
    &lt;p&gt;Since the DOSember Game Jam was announced I’ve been toying with the idea of making another DOS game. Something small, that would allow me to try some ideas in the context of a game jam. I haven’t been too inspired lately, so I thought… why not?&lt;/p&gt;
    &lt;p&gt;I did some brainstorming with my son and we ended with a nice, if not genre revolutionary, idea for a tower defense game. I know we have game in there, but I’m not really into the genre which means that I don’t know how it works –a problem when you get to the level design part of it–. And also, as it has happened to me before, getting too deep in a game concept –with or without game design document– has the fundamental problem that it is me doing the graphics and unfortunately I can’t draw everything we came up with.&lt;/p&gt;
    &lt;p&gt;So that went nowhere (at least so far).&lt;/p&gt;
    &lt;p&gt;I have already my own library for DOS 32-bit games with DJGPP, and I have used this opportunity to fix a couple of bugs –although there could be more because I haven’t used it yet for a full game–, and I added mouse support because that would be required for a tower defense game.&lt;/p&gt;
    &lt;p&gt;And then, after a conversation &lt;code&gt;#dosgameclub&lt;/code&gt; on Afternet in which people were lamenting that there were not many good platform games in DOS, I started investigating a little bit how would you do scrolling in the VGA with hardware assistance. What a nice side-quest!&lt;/p&gt;
    &lt;p&gt;So I ended in these two pages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Michael Abrash’s Graphics Programming Black Book, Special Edition&lt;/item&gt;
      &lt;item&gt;VGA registers documentation from PC-GPE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Abrash’s book is still a good read, even if some of the examples try to do too many things at once and sometimes it is quite hard to get what was the actual point; which I guess it may have not been a problem when it was published, because people interested in the topic would have been more used to reading assembler that I am today. Together with the PC-GPE documentation, I think I’m getting somewhere.&lt;/p&gt;
    &lt;p&gt;I’ve been working on a unchained branch, that is probably full of bugs, but at least I have a good implementation of a few things that make it very interesting compared to the simpler code I used for example in Gold Mine Run! and Alien Intruder (although is 16-bit, uses the same engine essentially). To be specific:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the 256K of VRAM of the VGA (unchained mode &lt;code&gt;320x200&lt;/code&gt;; what people called mode Y).&lt;/item&gt;
      &lt;item&gt;That gives us a hardware back buffer (so you write on a hidden page and swap when done; no more racing the beam!), a full screen to store the background (for erases), and another screen to store tiles (or sprites, but have to be plane aligned).&lt;/item&gt;
      &lt;item&gt;Latched writes, that allow copying 4 pixels per byte from VRAM to VRAM (making some operations much faster). For example: erasing using the background screen or copying tiles from the tiles’ screen.&lt;/item&gt;
      &lt;item&gt;Screen split to have a HUD on the bottom of the screen (great to not have to update the HUD in both the visible screen and then back buffer).&lt;/item&gt;
      &lt;item&gt;1-pixel “infinite” vertical scroll (WIP, but so far it works for 8 pixel tiles).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All working on a 386 30MHz, and I managed to implement this rather quickly, in a few evenings. And can you guess? Exactly: still no game!&lt;/p&gt;
    &lt;p&gt;There is now less than a month to finish the jam, so I don’t know what is going to happen. If I have a super clear idea of the game I was making, there would be time enough if I was only making the game, and it looks like I have two libraries now (the simple one and the unchained; ignoring the scroll for now!). So we will see if I can finally start anything this week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801630</guid><pubDate>Mon, 03 Nov 2025 17:25:49 +0000</pubDate></item><item><title>Israels top military lawyer arrested after she admitted leaking video of abuse</title><link>https://www.theguardian.com/world/2025/nov/03/israels-top-military-lawyer-arrested-after-she-admitted-leaking-video-of-soldiers-abuse</link><description>&lt;doc fingerprint="ebc08abb8040fad1"&gt;
  &lt;main&gt;
    &lt;p&gt;Police in Israel have arrested and detained the military’s top legal officer after she admitted leaking footage of soldiers allegedly attacking a Palestinian detainee and then in effect lying about her actions to Israel’s high court.&lt;/p&gt;
    &lt;p&gt;The military advocate general, Yifat Tomer-Yerushalmi, said in a resignation letter last week that she had authorised publication of the video to defuse attacks on military investigators and prosecutors working on the case.&lt;/p&gt;
    &lt;p&gt;Rightwing politicians and pundits championed soldiers detained over the case as “heroes”, attacked military investigators as traitors, and called for the case against the soldiers to be dropped.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalmi has now been arrested on suspicion of fraud and breach of trust, abuse of office, obstruction of justice, and disclosure of official information by a public servant, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Her arrest and detention raises serious questions about the rule of law in Israel, accountability for abuse and killing of Palestinians during what a UN commission has called a genocidal war, and the country’s ability to defend itself in international courts.&lt;/p&gt;
    &lt;p&gt;In July 2024 prosecutors raided the Sde Teiman military detention centre, which has become notorious for torture, and detained 11 soldiers for interrogation.&lt;/p&gt;
    &lt;p&gt;They were suspects in a violent assault on a Palestinian from Gaza, including anal rape. The victim was hospitalised with injuries including broken ribs, a punctured lung and rectal damage, according to the indictment, and Tomer-Yerushalmi launched an investigation.&lt;/p&gt;
    &lt;p&gt;The government and far-right politicians and pundits have accused her of damaging Israel’s global standing by pursing the case and releasing the video, in effect casting her efforts to prosecute extreme violence as a project to undermine the state.&lt;/p&gt;
    &lt;p&gt;“The incident in Sde Teiman caused immense damage to the image of the state of Israel and the IDF [Israel Defense Forces],” the Israeli prime minister, Benjamin Netanyahu, said in a statement on Sunday. “This is perhaps the most severe public relations attack that the state of Israel has experienced since its establishment.”&lt;/p&gt;
    &lt;p&gt;After the first detentions of soldiers in the case in summer 2024, a far-right mob gathered outside Sde Teiman calling for the investigation to be dropped. Some of the protesters – including a minister and two members of the Knesset – broke into the base.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalmi leaked the video in August 2024 after the protests, saying in her resignation letter that it was “an attempt to debunk false propaganda against army law enforcement bodies”.&lt;/p&gt;
    &lt;p&gt;Days later, five soldiers were charged with aggravated abuse and causing serious bodily harm. They have not been named and are currently not in custody or under any legal restrictions, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalemi subsequently refused to open or advance investigations into other cases of possible war crimes by the Israeli military, because of the pressure of public attacks over the case, Haaretz reported.&lt;/p&gt;
    &lt;p&gt;There has been only one conviction of an Israeli soldier for assaulting Palestinians in detention during the war, although widespread torture and abuse have been documented in Israel’s jail system, and dozens of Palestinians have died in captivity.&lt;/p&gt;
    &lt;p&gt;No soldiers have been charged for killing civilians in Gaza, even after high-profile attacks that prompted international outrage, including the killing of paramedics and strikes on a team from the World Central Kitchen charity. Tens of thousands of Palestinian civilians in Gaza have been killed in attacks and airstrikes over two years.&lt;/p&gt;
    &lt;p&gt;Attacks on Tomer-Yerushalemi over the Sde Teiman affair intensified in recent days amid reports that she was responsible for leaking the video. There were official demands for her to step down and personal threats online, even after she announced her resignation.&lt;/p&gt;
    &lt;p&gt;The campaign briefly halted on Sunday afternoon amid fears for her life, after her partner reported her missing to the police and her car was found empty at a beach in the Tel Aviv area with a note inside, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Then she was found, and within minutes the attacks resumed. The far-right commentator Yinon Magal posted on X, “we can proceed with the lynching”, adding a winking emoji.&lt;/p&gt;
    &lt;p&gt;Soon after, protesters had gathered outside her house, Israeli media reported, shouting slogans including “we will give you no peace”. The defence minister, Israel Katz, later accused her of “spreading blood libels”.&lt;/p&gt;
    &lt;p&gt;Traditionally Israel’s government and military have considered the existence of an independent judiciary a crucial barrier to international legal tribunals investigating Israel for alleged abuses against Palestinians.&lt;/p&gt;
    &lt;p&gt;Where there is a robust national legal system willing and able to investigate and prosecute crimes, international courts are less likely to have jurisdiction to intervene.&lt;/p&gt;
    &lt;p&gt;“Don’t they understand we had no choice? That the only way to address the wave of international legal proceedings is by proving we can investigate ourselves?” the investigative reporter Ronen Bergman quoted the advocate general telling colleagues six weeks ago, in a report for Yedioth Ahronoth newspaper.&lt;/p&gt;
    &lt;p&gt;In recent decades many Israelis have seen the role of the military advocate general “as protecting soldiers from prosecution abroad”, said Prof Yagil Levy, head of the Institute for the Study of Civil-Military Relations at Israel’s Open University.&lt;/p&gt;
    &lt;p&gt;“In other words, the law is not upheld as a value in itself, but as a defence against international tribunals.”&lt;/p&gt;
    &lt;p&gt;Now even such legal pragmatism is under attack by the political right, whose influence can be seen in the lack of legal accountability for soldiers’ conduct in Gaza over the past two years, Levy added.&lt;/p&gt;
    &lt;p&gt;“During the war, the advocate general gave the army a free hand in Gaza, for example, regarding the unprecedented collateral damage from airstrikes,” he said.&lt;/p&gt;
    &lt;p&gt;“This reflects a far weaker commitment to international law, with some on the right claiming that Israel is exempt from respecting it, and even providing religious justifications for this view.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801673</guid><pubDate>Mon, 03 Nov 2025 17:28:58 +0000</pubDate></item></channel></rss>